{"title": "Defining and Measuring Disentanglement for non-Independent Factors of Variation", "authors": ["Antonio Almud\u00e9var", "Alfonso Ortega", "Luis Vicente", "Antonio Miguel", "Eduardo Lleida"], "abstract": "Representation learning is an approach that allows to discover and extract the factors of variation from the data. Intuitively, a representation is said to be disentangled if it separates the different factors of variation in a way that is understandable to humans. Definitions of disentanglement and metrics to measure it usually assume that the factors of variation are independent of each other. However, this is generally false in the real world, which limits the use of these definitions and metrics to very specific and unrealistic scenarios. In this paper we give a definition of disentanglement based on information theory that is also valid when the factors of variation are not independent. Furthermore, we relate this definition to the Information Bottleneck Method. Finally, we propose a method to measure the degree of disentanglement from the given definition that works when the factors of variation are not independent. We show through different experiments that the method proposed in this paper correctly measures disentanglement with non- independent factors of variation, while other methods fail in this scenario.", "sections": [{"title": "Introduction", "content": "In the jargon of representation learning, data are considered to be completely defined by factors of variation and nuisances. The difference between them is that the former are relevant for a given task and the latter are not. Ideally, a representation for a given task should contain only information about the factors of variation of that task. For example, if we had a dataset composed of images of fruits and the task was to describe the fruits in the images, the factors of variation could be the type of fruit, the color or the size. On the other hand, nuisances could be the background color in the image or the shadow of the fruit. In multiple works it has been proposed that it is desirable for a representation to be disentangled, i.e., it separates the different factors of variation [1\u20135]. The main reason why it is desirable to have disentangled representations is that they are more understandable by humans, which has different applications. Some of these applications are: (i) interpreting and explaining the representations and predictions [6\u201312], (ii) making fairer predictions by mitigating or eliminating biases in sensitive attributes (such as gender or race) [13-18], or (iii) giving generative models the ability to create new data with concrete attributes [19-27].\n\nThe definition given in the previous paragraph allows us to understand the concept of disentangled representation in an intuitive but imprecise way. Two main questions arise from this definition: what does it exactly mean to separate the factors of variation, and how can we assess whether the different factors of variation are actually separated? As we review in section 2, different works have tried to clear these doubts by proposing that the disentangled representations must satisfy a set of specific properties and methods to measure these properties. Most of these works assume that the different factors of variation are independent of each other and of the nuisances. Therefore, the definitions and metrics they propose are assuming this independence. Most of the datasets where\nPreprint. Under review."}, {"title": "Related Work", "content": "these definitions and metrics are assessed do have their factors of variation independent (or nearly independent) [28\u201333], so the definitions and metrics are valid in these scenarios.\n\nHowever, in the real world it is uncommon for factors of variation to be independent of each other and of the nuisances. In the previous example, it is easy to see that the type of fruit is not independent of the color, the size or the shadow of the fruit. It is very likely to have a red strawberry, but the probability of having a red banana is almost zero. When the factors of variation are independent of each other, understanding the concept of separating them seems obvious. However, it is not so obvious to understand what it means for a representation to separate dependent factors of variation. For example, we might ask whether it is possible to separate a strawberry from the color red and what the implications of this are. If we can separate the factors of variation, we could create an image of a red banana or avoid classifying a yellow strawberry as a banana or a lemon just for the fact that it is yellow. In this paper we focus on defining and measuring disentanglement when the factors of variation are not independent of each other. Our key contributions can be summarized as follows:\n\n\u2022 We redefine the most accepted properties for defining disentanglement from an information theory point of view in order to adapt them to the scenario in which the factors of variation are not independent of each other.\n\n\u2022 We relate these properties to the Information Bottleneck Method, demonstrating that if our representations are sufficient and minimal, then we can guarantee disentanglement.\n\n\u2022 We propose a method for measuring the previous properties when the factors of variation are not independent. We compare our method with others in the literature in two experiments demonstrating that it solves the presented problem."}, {"title": "Definition and Properties of Disentanglement", "content": "Despite being a topic of great interest, there is no general consensus on the definition of disentangled representation. Intuitively, a disentangled representation separates the different factors of variation of the data [2, 3, 34-36]. Originally, disentanglement was evaluated via visual inspection [37]. This served to motivate the importance of disentangled representations and to look for ways to achieve it. However, there is a need to better specify what it means for a representation to be disentangled, as this provides insight into the scope and limitations of their different applications. Likewise, metrics to evaluate the degree of disentanglement are also needed.\n\nAs for definitions of disentanglement, one of the first given in [2] and long the most widely accepted in the literature [38-41], says that a disentangled representation is one in which change in one factor of the representation corresponds to change in a factor of variation, while being relatively invariant to changes in other factors. The main problem with this definition is that it would allow a change in a factor of variation to occur without a change in its factor of the representation. Other authors claim that a disentangled representation is one in which a change in a single factor of variation translates into the change in a single factor of the representation [15, 42]. In contrast to the previous definition, this definition has the problem that a change in a representation factor could occur without a factor of variation having occurred. In addition, the two previous definitions do not ensure that all possible changes in a factor of variation are reflected in the representation.\n\nGiven the problems of different definitions, several papers propose to define disentangled represen- tations based on a list of properties that they must satisfy. [43] and [44] stand out in this purpose by proposing virtually simultaneously three properties that a representation must satisfy in order to have all the advantages traditionally attributed to disentangled representations. Although they refer to the same ideas, the two papers refer to these properties by different names. In this paper we use those of [43]. The properties are: (i) modularity (disentanglement in [44]), that is, each variable in the representation captures at most one factor of variation; (ii) compactness (completeness in [44]), i.e., a factor of variation is captured by only one variable of the representation; and (iii) explicitness (informativeness in [44]), that is, the representation captures all information about the input. The above properties assume that the factors of variation are independent, which is, in general, false, as we have explained. Therefore, in this paper we propose to modify these definitions so that they can be used also in the case where this independence does not exist."}, {"title": "Metrics for Measuring Disentanglement", "content": "Due to the fact that there is no consensus on the definition of disentanglement, there is no consensus on how to measure it. In [45] they organize these methods into three groups according to the principle of their operation. Below we explain an overview of each of these three groups.\n\nIntervention-based Metrics. These methods are based on creating subsets in which their elements have in common a factor of variation while the rest are different. Subsequently, the representations of these elements are obtained and compared in different ways to obtain a score. Some of the methods in this family are \u1e9e-VAE [38], FactorVAE [39] and R-FactorVAE [40]. The main limitation of these is that they measure only modularity, but not compactness and explicitness [46].\n\nInformation-based Metrics. These metrics measure the degree of disentanglement by estimating the mutual information between the factors of variation and each variable in the representation. Some of the most widely used are Mutual information Gap (MIG) [47] or Robust MIG [48]. The main limitation of these methods is that they only evaluate compactness, but not modularity and explicitness. Modifications on these methods have been proposed to also capture modularity [43, 46, 48, 49].\n\nPredictor-based Metrics. These methods train regressors or classifiers to predict the factors of variation from the different variables in the representations. Subsequently, the predictor is analyzed to analyze the usefulness of each variable to predict each factor. The first method of this family proposed was Separated Attribute Predictability (SAP) [15] which, like MIG, measures only compactness. Soon after, as we have already explained, it was proposed to measure disentanglement through different properties. In [44] the properties disentanglement, completeness and informativeness (DCI) and ways to measure them are proposed. Simultaneously, in [43] the properties modularity, compactness and explicitness and ways to measure them are proposed. The proposal of the present work would fall into this group, since we measure each of the properties separately using regressors."}, {"title": "Methods to Obtain Disentangled Representations", "content": "Initially, most schemes for achieving disentangled representations were unsupervised, i.e., without explicitly telling the model which factors of variation to disentangle [50]. Most of these introduce modifications on the Variational Autoencoder (VAE) [37] to try to minimize mutual information between elements in the representation [15, 22, 38\u201340, 47, 51\u201354]. Some others have also relies on Generative Adversarial Networks (GAN) [11, 55\u201358] and a few others on Diffusion Models [59, 60]. However, in [42] they show that unsupervised disentanglement is impossible without inductive biases in the model or the data and that random seeds and hyper-parameters have a greater impact on performance than architecture. From this, a multitude of approaches have been proposed that use labels to indicate to the model the factors of variation to be disentangled [27, 61\u201368]. It is worth noting that, although there are numerous methods that attempt to search for disentanglement in an unsupervised manner, all the metrics described in 2.2 are supervised. There are few papers in the literature that propose unsupervised metrics [69, 70] and they are less used. The methods proposed to measure disentanglement in this work are supervised, i.e., we use the labels of the factors of variation."}, {"title": "Defining Disentanglement for non-Independent Factors of Variation", "content": ""}, {"title": "Problem Statement", "content": "In our representation learning task we have a raw data \u00e6 which is fully explained by a set of factors of variation of that raw data \\(y = \\{y_i\\}_{i=1}^n\\) and a set of nuisances n. The factors of variation y refer to the underlying causes or sources that influence the observed data and that are relevant for a given task. We assume that these factors of variation are conditionally independent of each other given \u00e6, i.e., \\(P(y_i, y_j|x) = P(y_i|x)p(y_j|x)\\) for \\(i \\neq j\\)\\u00b9. On the other hand, the nuisances n refer to the variations present in x that are irrelevant to a given task.\n\nA representation z is a variable that is fully described by the distribution \\(p(z|x)\\). Therefore, we have the Markov chains \\(y \\leftrightarrow x \\leftrightarrow z\\) and \\(y_i \\leftrightarrow x \\rightarrow z\\). The goal of representation learning is to obtain representations of the inputs. A representation z can be viewed as a set of representations such that\n\\u00b9As explained, some papers consider \\(y_i\\) and \\(y_j\\) to be independent, such that \\(p(y_i, y_j) = p(y_i)p(y_j)\\) for \\(i \\neq j\\), but this is not true in most real world scenarios."}, {"title": "Properties of Disentanglement", "content": "As explained in 2.2, the most complete way to define the disentanglement is through the different properties given in [43, 44]. These properties are defined by word in previous works. In the following we define them from an information theory point of view and further adapt them to the case where the factors of variation are not independent of each other. The notation used is that of [43].\n\n\u2022 Modularity (disentanglement in [44]): A variable \\(z_j\\) of the representation z is said to be modular if it captures at most one factor of variation \\(y_i\\). Thus, \\(z_j\\) can be easily understood simply by observing \\(y_i\\). However, it is immediate to see that this definition is convenient only when the factors of variation are independent of each other, which is in general false. Imagine that we have two factors of variation \\(Y_i\\) and \\(y_k\\) dependent on each other, then, according to this definition, \\(z_j\\) could never store all the information about \\(Y_i\\), since \\(Y_k\\) contains information about \\(Y_i\\). Therefore, it would be more accurate to say that a variable \\(z_j\\) is modular when \\(I(z_j;\\tilde{y_i}|Y_i) = 0\\), where \\(\\tilde{y_i} = \\{Y_k\\}_{k\\neq i}\\). This is equivalent to having the Markov chain \\(\\tilde{y_i} \\leftrightarrow Y_i \\leftrightarrow Z_j\\). This implies that once \\(Y_i\\) is known, \\(z_j\\) will be the same regardless of all other factors of variation. Therefore, we have that \\(P(z_j|Y_i) = P(z_j|Y_i, Y_i) = P(z_j|y)\\). Thus, a modular \\(z_j\\) variable can be immediately understood by taking into account the value of a single factor of variation \\(y_i\\). The modularity of a representation refers to how modular its variables are.\n\n\u2022 Compacteness (completeness in [44]): A variable \\(z_j\\) of the representation z is said to be compact if it is the only one that captures a factor of variation \\(y_i\\). Thus, we can modify \\(y_i\\) by manipulating only \\(z_j\\) (in a generative model) or we can discover \\(y_i\\) by observing only \\(z_j\\) (in a classifier). For the same reason as in modularity, this definition is only convenient if the factors of variation are independent of each other. Let \\(y_i\\) and \\(y_k\\) be two dependent factors of variation represented by \\(z_j\\) and \\(z_\\), respectively. Then it is expected that both \\(z_j\\) and \\(z_\\) have information about both \\(y_i\\) and \\(y_k\\). Therefore, we consider it more correct to define a compact representation as the one in which \\(I(y_i; Z_j|z_j) = 0\\), where \\(Z_j = \\{z_k\\}_{k\\neq j}\\). This is equivalent to having the Markov chain \\(z_j \\leftrightarrow z_j \\leftrightarrow Y_i\\). This implies that \\(y_i\\) does not need any variable other than \\(z_j\\) to be explained. In this case, we have that \\(p(y_i|z_j) = p(Y_i|z_j, Z_j) = P(y_i|z)\\). This can be useful for downstream tasks, since if we want to predict \\(y_i\\), we could keep only \\(z_j\\) and ignore the rest. Similarly, in a controllable generative model, it would be sufficient to modify by manipulating only \\(z_j\\) to determine the value of \\(y_i\\). The compactness of a representation refers to how compact its variables are.\n\n\u2022 Explicitness (informativeness in [44]): A representation is said to be explicit if it contains all the information about its factors of variation. This means that \\(I(y_i; x|z) = 0\\), i.e., x provides no information about \\(y_i\\) when z is known. This is equivalent to having the Markov chain \\(x \\leftrightarrow z \\leftrightarrow y_i\\). Thus, we have that \\(p(y_i|z,x) = P(y_i|z)\\). From the definition of representation, we know that \\(p(y_i|z, x) = p(y_i|x)\\), so we can conclude that a representation is explicit if \\(p(y_i|z) = p(y_i|x)\\)."}, {"title": "Connection to Information Bottleneck", "content": "The Information Bottleneck is a generalization of sufficient minimality statistics that aims to achieve a trade-off between accuracy and complexity in the representations [71\u201374]. Specifically, given an input X and a task Y, the objective is that the representation Z contains the maximum possible information about Y and, simultaneously, the minimum possible information about X. Thus, the optimum would be found at the point where Z contains only all the information about Y. This is formalized by maximizing I(Z; Y) and minimizing I(Z; X) jointly. On the one hand, the representation Z that maximizes I(Z; Y) is called sufficient. By the definition of representation, we know by the Data Processing Inequality (DPI) [75] that \\(I(Z; Y) \\leq I(X; Y)\\). Since this is the unique upper bound of I(Z; Y), the sufficient representation satisfies that \\(I(Z; Y) = I(X; Y)\\). Therefore, a sufficient representation satisfies the Markov chain \\(X \\leftrightarrow Z \\leftrightarrow Y\\), i.e., Y is fully described by Z. On the"}, {"title": "Measuring Disentanglement for non-Independent Factors of Variation", "content": "As explained in section 3.2, different works explain that disentanglement can be described by three properties: modularity, compactness, and explicitness. As argued in section 3.3, disentanglement can be more fully described by two properties: sufficiency and minimality. These two properties collect the previous three and also assess whether a representation is invariant to noise, which is a relevant and often overlooked property. Despite the latter, we propose below a method to measure modularity, compactness and explicitness taking into account that the factors of variation may be dependent on each other. The reason for this is because the methods proposed by other authors measure these three properties and, therefore, it is easier to compare our proposal with them. However, in Appendix B, we give a method to measure sufficiency and minimality. In Appendix C we go deeper and give examples in which minimality captures disentanglement better than modularity.\n\n\u00b2Do not confuse \\(\\Leftrightarrow\\), which means if and only if, and \\(\\leftrightarrow\\), which is an arrow of the Markov chain."}, {"title": "Experiment I: Cosine Dependence", "content": "In order to analyze the performance of our proposal and compare it with other methods in the literature, we start by creating a controlled environment in which we know the exact relationship between the factors of variation and the different variables of our representation. To do this, we create different scenarios that allow us to analyze the different properties. For this experiment, we have three factors of variation, i.e., \\(y = \\{y_i\\}_{i=1}^3\\), so that \\(y_1 \\sim \\mathcal{U} [0, \\pi)\\), \\(Y_2 \\sim \\mathcal{U} [0, \\pi)\\) and \\(y_3\\) is defined differently depending on the scenario in Table 1. On the other hand, our representation has m variables, i.e., \\(z = \\{z_j\\}_{j=1}^m\\). Each of the \\(z_j\\) is defined as cosine of values in \\([0, \\pi)\\), so that these values can be recovered due to the bijectivity of the cosine in this domain. The values of the \\(z_j\\) are different in each scenario and are detailed in Table 1. We use mean absolute error as the E function and random forest regressors in Algorithms 1 and 2. Other metrics and regressors could be studied, but it is beyond the scope of this paper, since the idea of this paper is to present the theoretical idea and we believe that these two aspects could be dependent on the context of application."}, {"title": "Experiment II: Conditionally Colored MNIST", "content": "In this second experiment we train a representation learning system so that its output is expected to be disentangled with respect to some given factors of variation. The peculiarity is that we design the dataset so that there is dependence between the factors of variation. The goal of this experiment is to verify in a more realistic scenario that other metrics do not correctly detect disentanglement even though the representations are correctly disentangled. In fact, we demonstrate how we can achieve some of the advantages derived from having disentangled representations and these metrics tell us that there is no disentanglement. To design this dataset, we take the subset of the well-known MNIST dataset [76] containing images corresponding to the digits 0, 1, 2 and 3. Subsequently, we color the digit and the background. Specifically, the digit color can be red or green and the background color can be black or white. The probabilities of each color are different according to the digit and we define them in Table 5. Therefore, we have three factors of variation: digit, background color and digit color and digit is not independent of the other two.\n\nSubsequently, we design a VAE based on [27], which allows us to achieve disentanglement by organizing the latent space distributions according to the factors of variation. Specifically, we choose our latent space (or representation) to be a vector of 64 components, such that the first contains the information about the digit, the second about the digit color, the third about the background color, and the remaining 61 should contain the information about the nuisances. In this case the nuisances refer to the style in which the digit is written. In Appendix D we give details of the architecture, training protocol and latent space distribution.\nOne of the advantages of disentangled representations is that at least part of them can be explained by the factors of variation in a simple way, which is related to modularity. To test whether we have this advantage, we construct a linear regressor to predict each of the first three components from their associated factors of variation. The mean squared errors obtained are \\(1.25e - 3\\) for digit, \\(7.04e - 4\\) for background color and \\(7.50e - 4\\) for digit color. Thus, the first three components can be directly explained from the factors of variation with low error. In Table 6, we observe that Modularity Score gives a value far from the maximum, which is because it calculates the average of all the components without weighting, as explained in section 5. The rest of the metrics agree that modularity is high.\n\nAnother advantage of having disentangled representations is that they allow us to generate data in a controlled manner by specifying the desired factors of variation, which is related to compactness. To test whether our representation provides this advantage, we create representations by independently modifying the first three components of them. The images generated from these representations are shown in Figure 1. As we can see, we are able to generate images with all possible options and control the factors of variation independently. In addition, another advantage of disentangled representations is that they contain all the information about a factor of variation in a small part of the representations, which is also related to compactness. To test this advantage, we train a linear classifier that predicts the factors of variation through their associated component in the representation. The accuracies are 0.9925 for digit, 1 for background color and 1 for digit color. Therefore, we are able to predict with near-zero error all the factors of variation using a single component. Due to all of the above, we would expect compactness to be high. However, we observe in Table 7 that all the metrics except Ind. Compactness give values far from their maximum. This, as we have argued, may be due to the fact that the factors of variation are not independent.\n\nFinally, as we see in Table 8, all metrics agree that all factors of variation can be predicted from the representation, since explicitness is very high."}, {"title": "Conclusion", "content": "In this paper we have presented the idea that the most popular definitions of disentanglement are incomplete, since they do not consider the case in which there is dependence between factors of variation, which is the most common scenario in the real world. Consequently, the metrics used to measure disentanglement are inaccurate when there is some dependence between factors of variation. To address this, we have redefined these properties from the point of view of information theory to adapt them to scenarios where there is dependence between factors of variation. Furthermore, we have related these properties to the information bottleneck method and shown that, if the variables in a representation are sufficient and minimal, then the representation is disentangled. From the definitions we have given, we have proposed methods to measure the different properties that define an disentangled property, which solve the limitations of other metrics when we have dependent factors of variation. Finally, we have presented two experiments which serves to show that our proposal overcomes the presented problem and allows to measure disentanglement even in the case where there is dependence between factors of variation."}, {"title": "Proof of Propositions", "content": "Proposition 1. Let \\(y = \\{y_i\\}_{i=1}^m\\) be some factors of variation and \\(z = \\{z_j\\}_{j=1}^m\\) a representation. Then, \\(z_j\\) is a sufficient representation of \\(y_i\\) if and only if z is explicit and \\(z_j\\) is compact with respect to \\(y_i\\). Equivalently, we have the that\n\\((x\\leftrightarrow z_j \\leftrightarrow Y_i) \\leftrightarrow (\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow Y_i) \\wedge (x \\leftrightarrow z \\leftrightarrow Y_i)\\)\nProof. First, we demonstrate that \\((x\\leftrightarrow z_j \\leftrightarrow Y_i) \\rightarrow (\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow y_i)\\): Given this Markov chain, by the DPI, we have that \\(I(y_i; x) \\leq I(y_i; z_j)\\). Since z is a representation of \u00e6, we also have that \\(I(y_i; z) \\leq I(y_i; x)\\). Therefore, it follows that \\(I(y_i; z) \\leq I(y_i; z_j)\\) On the other hand, by the mutual information chain rule, we have that \\(I(y_i; z) = I(y_i; z_j, Z_j) = I(y_i; z_j) + I(y_i; Z_j|z_j)\\). By the non-negativity of mutual information, we are left with \\(I(y_i; z) > I(y_i; z_j)\\). Therefore, we have that \\(I(y_i; z_j) = I(y_i; z) = I(Y_i; z_j, Z_j)\\) or, equivalently, \\(\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow y_i\\).\n\nSecond, we demonstrate that \\((x\\leftrightarrow z_j \\leftrightarrow Y_i) \\Rightarrow (x \\leftrightarrow z \\leftrightarrow y_i)\\): Since \\(z_j\\) is a representation of x, we have that \\(p(y_i|x, z_j) = p(y_i|x)\\). Moreover, since \\(z_j\\) is sufficient, we have that \\(p(y_i|x, z_j) = p(Y_i|z_j)\\). Putting the above two terms together, we are left with \\(p(y_i|x) = p(Y_i z_j)\\). As we have already shown, if \\(z_j\\) is sufficient, then we have the Markov chain \\((\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow Y_i)\\), so \\(P(Y_i|z) = P(Y_i z_j)\\). Therefore, we are left with \\(p(y_i|z) = p(y_i|x)\\). Finally, since z is a representation of \u00e6, we know that \\(p(y_i|x) = p(y_i|x, z)\\). Putting all of the above together, we are left with \\(P(y_i|x, z) = P(y_i|z)\\) or, equivalently, \\(x \\leftrightarrow z \\leftrightarrow Y_i\\).\n\nFinally, we demonstrate that \\((Zj \\leftrightarrow z_j \\leftrightarrow Y_i) \\wedge (x \\leftrightarrow z \\leftrightarrow Y_i) \\Rightarrow (x \\leftrightarrow z_j \\leftrightarrow y_i)\\): Since \\(z_j\\) and z are representations of \u00e6, we have that \\(p(y_i|x, z_j) = P(y_i|x, z) = p(y_i|x)\\). Furthermore, given the Markov chain \\(x \\leftrightarrow z \\leftrightarrow y_i\\), we know that \\(p(y_i|x, z) = p(y_i|z)\\). Equivalently, given \\(Zj \\leftrightarrow z_j \\leftrightarrow Y_i\\), we have that \\(p(y_i|z_j) = P(Y_i|z_j, Z_j) = p(y_i|z)\\). Recapitulating the above, we are left with \\(p(Y_i z_j) = P(y_i|z) = p(y_i|x, z) = p(y_i|x, z_j)\\). Therefore, we have that \u00e6 \\leftrightarrow z_j \\leftrightarrow Y_i\\$.\n\nProposition 2. Let \\(y = \\{y_i\\}_{i=1}^m\\) some factors of variation and \\(z = \\{z_j\\}_{j=1}^m\\) a representation. If \\(z_j\\) is a minimal representation of \\(y_i\\), then \\(z_j\\) is modular with respect to \\(y_i\\). Equivalently, we have the that\n\\((x \\leftrightarrow Y_i \\leftrightarrow z_j) \\rightarrow (\\tilde{y_i} \\leftrightarrow Y_i \\leftrightarrow z_j)\\)\nProof. Given this Markov chain, by the DPI, we have that \\(I(z_j; x) \\leq I(z_j; y_i)\\). Since \\(z_j\\) is a representation of \u00e6, we also have by DPI that \\(I(z_j;y) \\leq I(z_j;x)\\). Therefore, it follows that \\(I(z_j;y) \\leq I(z_j; Y_i)\\) On the other hand, by the chain rule of mutual information, we have that \\(I(z_j; y) = I(z_j; Y_i, Yi) = I(z_j; Y_i) + I(z_j; Yi|Yi)\\). By the non-negativity of mutual information, we are left with \\(I(z_j; y) \\geq I(z_j; y_i)\\). Therefore, we have that \\(I(z_j; Y_i) = I(z_j; y) = I(z_j; Y_i, Yi)\\) or, equivalently, \\(\\tilde{y_i} \\leftrightarrow Y_i \\leftrightarrow z_j\\).\n\nProposition 3. Let \\(y_i\\) be a factor of variation, n some nuisances and \\(z = \\{z_j\\}_{j=1}^m\\) a representation. If \\(z_j\\) is a minimal representation of \\(y_i\\), then \\(z_j\\) is invariant to nuisances n with respect to \\(y_i\\). Equivalently, we have the that\n\\((x \\leftrightarrow Y_i \\leftrightarrow z_j) \\Rightarrow (n \\leftrightarrow Y_i \\leftrightarrow z_j)\\)\nProof. Given this Markov chain, we know from the DPI that \\(I (z_j; x) \\leq I(z_j; y_i)\\). On the other hand, since \\(z_j\\) is a representation of \u00e6, we have the Markov chain \\((n, y_i) \\leftrightarrow x \\leftrightarrow z_j\\). Equivalently, we have that \\(I (z_j; n, y_i) \\leq I(z_j; x)\\). The chain rule of mutual information tells us that \\(I(z_j; n|y_i) = I(z_j; n, y_i) - I(z_j|y_i)\\). According to the above two points, we are left with \\(I(z_j; n|y_i) \\leq I(z_j; x) - I(z_j|y_i)\\). Therefore, because of the nonnegativity of mutual information, it is only possible that \\(I(z_j; n|y_i) = 0\\) or, equivalently, \\(n \\leftrightarrow Y_i \\leftrightarrow z_j\\)."}, {"title": "Algorithms for Sufficiency and Minimality", "content": "As we have explained in section 3.3, disentanglement can also be measured through sufficiency and minimality. If the variables of a representation are sufficient, then the representation is compact and explicit. Likewise, if the variables of a representation are minimal, then the representation is modular and also invariant to nuisances. For the latter reason, minimality reflects the degree of disentanglement better than modularity since we can have high modularity, but have nuisances that affect the variables of our representation. Despite this, in the paper we have presented algorithms to measure the three classical properties modularity, compactness and sufficiency since this allows us to compare our results with those of other works. However, we can measure sufficiency and minimality in a similar way to the previous three properties. We explain the methods for doing so below.\n\nMinimality As explained, minimality means that \\(I(z_j; Y_i) = I(z_j; x)\\) and, therefore, \\(p(z_j|y_i) = p(z_j|x)\\). In Algorithm 3 we show the details to calculate minimality. As we can see, the only change with respect to Algorithm 1 is in line 9. In this case, we calculate the error between predicting \\(z_j\\) from \\(y_i\\) and the \\(z_j\\) obtained from \u00e6. Also, unlike Algorithm 1, we do not use \\(f^*\\) or \\(f_j\\) to obtain \\(m_{ij}\\). However, we do need them to compute \\(\\alpha_j\\), which is used to obtain the global modularity of the representation.\n\nSufficiency In this case, sufficiency means that \\(I(y_i; x) = I(y_i; z_j)\\) and, therefore, \\(p(y_i|z_j) = p(y_i|x)\\). In Algorithm 4 we show the steps to compute sufficiency. Comparing it with Algorithm 2, here we can totally dispense with g* and gi because we do not need them to obtain \\(s_{ij}\\), since here we calculate the difference between predicting \\(y_i\\) from \\(z_j\\) and the actual \\(y_i\\). Finally, we compute the sufficiency of a representation as the arithmetic mean of its n components, just like compactness and explicitness in Algorithm"}]}