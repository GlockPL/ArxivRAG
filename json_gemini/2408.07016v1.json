{"title": "Defining and Measuring Disentanglement for non-Independent Factors of Variation", "authors": ["Antonio Almud\u00e9var", "Alfonso Ortega", "Luis Vicente", "Antonio Miguel", "Eduardo Lleida"], "abstract": "Representation learning is an approach that allows to discover and extract the factors of variation from the data. Intuitively, a representation is said to be disentangled if it separates the different factors of variation in a way that is understandable to humans. Definitions of disentanglement and metrics to measure it usually assume that the factors of variation are independent of each other. However, this is generally false in the real world, which limits the use of these definitions and metrics to very specific and unrealistic scenarios. In this paper we give a definition of disentanglement based on information theory that is also valid when the factors of variation are not independent. Furthermore, we relate this definition to the Information Bottleneck Method. Finally, we propose a method to measure the degree of disentanglement from the given definition that works when the factors of variation are not independent. We show through different experiments that the method proposed in this paper correctly measures disentanglement with non-independent factors of variation, while other methods fail in this scenario.", "sections": [{"title": "Introduction", "content": "In the jargon of representation learning, data are considered to be completely defined by factors of variation and nuisances. The difference between them is that the former are relevant for a given task and the latter are not. Ideally, a representation for a given task should contain only information about the factors of variation of that task. For example, if we had a dataset composed of images of fruits and the task was to describe the fruits in the images, the factors of variation could be the type of fruit, the color or the size. On the other hand, nuisances could be the background color in the image or the shadow of the fruit. In multiple works it has been proposed that it is desirable for a representation to be disentangled, i.e., it separates the different factors of variation [1\u20135]. The main reason why it is desirable to have disentangled representations is that they are more understandable by humans, which has different applications. Some of these applications are: (i) interpreting and explaining the representations and predictions [6\u201312], (ii) making fairer predictions by mitigating or eliminating biases in sensitive attributes (such as gender or race) [13-18], or (iii) giving generative models the ability to create new data with concrete attributes [19-27].\n\nThe definition given in the previous paragraph allows us to understand the concept of disentangled representation in an intuitive but imprecise way. Two main questions arise from this definition: what does it exactly mean to separate the factors of variation, and how can we assess whether the different factors of variation are actually separated? As we review in section 2, different works have tried to clear these doubts by proposing that the disentangled representations must satisfy a set of specific properties and methods to measure these properties. Most of these works assume that the different factors of variation are independent of each other and of the nuisances. Therefore, the definitions and metrics they propose are assuming this independence. Most of the datasets where"}, {"title": "Related Work", "content": null}, {"title": "Definition and Properties of Disentanglement", "content": "Despite being a topic of great interest, there is no general consensus on the definition of disentangled representation. Intuitively, a disentangled representation separates the different factors of variation of the data [2, 3, 34-36]. Originally, disentanglement was evaluated via visual inspection [37]. This served to motivate the importance of disentangled representations and to look for ways to achieve it. However, there is a need to better specify what it means for a representation to be disentangled, as this provides insight into the scope and limitations of their different applications. Likewise, metrics to evaluate the degree of disentanglement are also needed.\n\nAs for definitions of disentanglement, one of the first given in [2] and long the most widely accepted in the literature [38-41], says that a disentangled representation is one in which change in one factor of the representation corresponds to change in a factor of variation, while being relatively invariant to changes in other factors. The main problem with this definition is that it would allow a change in a factor of variation to occur without a change in its factor of the representation. Other authors claim that a disentangled representation is one in which a change in a single factor of variation translates into the change in a single factor of the representation [15, 42]. In contrast to the previous definition, this definition has the problem that a change in a representation factor could occur without a factor of variation having occurred. In addition, the two previous definitions do not ensure that all possible changes in a factor of variation are reflected in the representation.\n\nGiven the problems of different definitions, several papers propose to define disentangled represen- tations based on a list of properties that they must satisfy. [43] and [44] stand out in this purpose by proposing virtually simultaneously three properties that a representation must satisfy in order to have all the advantages traditionally attributed to disentangled representations. Although they refer to the same ideas, the two papers refer to these properties by different names. In this paper we use those of [43]. The properties are: (i) modularity (disentanglement in [44]), that is, each variable in the representation captures at most one factor of variation; (ii) compactness (completeness in [44]), i.e., a factor of variation is captured by only one variable of the representation; and (iii) explicitness (informativeness in [44]), that is, the representation captures all information about the input. The above properties assume that the factors of variation are independent, which is, in general, false, as we have explained. Therefore, in this paper we propose to modify these definitions so that they can be used also in the case where this independence does not exist."}, {"title": "Metrics for Measuring Disentanglement", "content": "Due to the fact that there is no consensus on the definition of disentanglement, there is no consensus on how to measure it. In [45] they organize these methods into three groups according to the principle of their operation. Below we explain an overview of each of these three groups.\n\nIntervention-based Metrics. These methods are based on creating subsets in which their elements have in common a factor of variation while the rest are different. Subsequently, the representations of these elements are obtained and compared in different ways to obtain a score. Some of the methods in this family are \\u03b2-VAE [38], FactorVAE [39] and R-FactorVAE [40]. The main limitation of these is that they measure only modularity, but not compactness and explicitness [46.\n\nInformation-based Metrics. These metrics measure the degree of disentanglement by estimating the mutual information between the factors of variation and each variable in the representation. Some of the most widely used are Mutual information Gap (MIG) [47] or Robust MIG [48]. The main limitation of these methods is that they only evaluate compactness, but not modularity and explicitness. Modifications on these methods have been proposed to also capture modularity [43, 46, 48, 49].\n\nPredictor-based Metrics. These methods train regressors or classifiers to predict the factors of variation from the different variables in the representations. Subsequently, the predictor is analyzed to analyze the usefulness of each variable to predict each factor. The first method of this family proposed was Separated Attribute Predictability (SAP) [15] which, like MIG, measures only compactness. Soon after, as we have already explained, it was proposed to measure disentanglement through different properties. In [44] the properties disentanglement, completeness and informativeness (DCI) and ways to measure them are proposed. Simultaneously, in [43] the properties modularity, compactness and explicitness and ways to measure them are proposed. The proposal of the present work would fall into this group, since we measure each of the properties separately using regressors."}, {"title": "Methods to Obtain Disentangled Representations", "content": "Initially, most schemes for achieving disentangled representations were unsupervised, i.e., without explicitly telling the model which factors of variation to disentangle [50]. Most of these introduce modifications on the Variational Autoencoder (VAE) [37] to try to minimize mutual information between elements in the representation [15, 22, 38\u201340, 47, 51\u201354]. Some others have also relies on Generative Adversarial Networks (GAN) [11, 55\u201358] and a few others on Diffusion Models [59, 60]. However, in [42] they show that unsupervised disentanglement is impossible without inductive biases in the model or the data and that random seeds and hyper-parameters have a greater impact on performance than architecture. From this, a multitude of approaches have been proposed that use labels to indicate to the model the factors of variation to be disentangled [27, 61\u201368]. It is worth noting that, although there are numerous methods that attempt to search for disentanglement in an unsupervised manner, all the metrics described in 2.2 are supervised. There are few papers in the literature that propose unsupervised metrics [69, 70] and they are less used. The methods proposed to measure disentanglement in this work are supervised, i.e., we use the labels of the factors of variation."}, {"title": "Defining Disentanglement for non-Independent Factors of Variation", "content": null}, {"title": "Problem Statement", "content": "In our representation learning task we have a raw data \u00e6 which is fully explained by a set of factors of variation of that raw data $y = \\{y_i\\}_{i=1}^n$ and a set of nuisances n. The factors of variation y refer to the underlying causes or sources that influence the observed data and that are relevant for a given task. We assume that these factors of variation are conditionally independent of each other given \u00e6, i.e., $P(y_i, y_j|x) = P(y_i|x)p(y_j|x)$ for $i \\neq j$ 1. On the other hand, the nuisances n refer to the variations present in x that are irrelevant to a given task.\n\nA representation z is a variable that is fully described by the distribution p(z|x). Therefore, we have the Markov chains $y \\leftrightarrow x \\leftrightarrow z$ and $y_i \\leftrightarrow x \\rightarrow z$. The goal of representation learning is to obtain representations of the inputs. A representation z can be viewed as a set of representations such that"}, {"title": "Properties of Disentanglement", "content": "As explained in 2.2, the most complete way to define the disentanglement is through the different properties given in [43, 44]. These properties are defined by word in previous works. In the following we define them from an information theory point of view and further adapt them to the case where the factors of variation are not independent of each other. The notation used is that of [43].\n\n\u2022 Modularity (disentanglement in [44]): A variable $z_j$ of the representation z is said to be modular if it captures at most one factor of variation $y_i$. Thus, $z_j$ can be easily understood simply by observing $y_i$. However, it is immediate to see that this definition is convenient only when the factors of variation are independent of each other, which is in general false. Imagine that we have two factors of variation $Y_i$ and $y_k$ dependent on each other, then, according to this definition, $z_j$ could never store all the information about $Y_i$, since $Y_k$ contains information about $y_i$. Therefore, it would be more accurate to say that a variable $z_j$ is modular when $I(z_j;\\tilde{y_i}|Y_i) = 0$, where $\\tilde{y_i} = \\{Y_k\\}_{k\\neq i}$. This is equivalent to having the Markov chain $\\tilde{y_i} \\leftrightarrow Y_i \\leftrightarrow Z_j$. This implies that once $y_i$ is known, $z_j$ will be the same regardless of all other factors of variation. Therefore, we have that $P(z_j|Y_i) = P(z_j|Y_i, \\tilde{Y_i}) = P(z_j|y)$. Thus, a modular $z_j$ variable can be immediately understood by taking into account the value of a single factor of variation $y_i$. The modularity of a representation refers to how modular its variables are.\n\n\u2022 Compacteness (completeness in [44]): A variable $z_j$ of the representation z is said to be compact if it is the only one that captures a factor of variation $y_i$. Thus, we can modify $y_i$ by manipulating only $z_j$ (in a generative model) or we can discover $y_i$ by observing only $z_j$ (in a classifier). For the same reason as in modularity, this definition is only convenient if the factors of variation are independent of each other. Let $y_i$ and $y_k$ be two dependent factors of variation represented by $z_j$ and $z_l$, respectively. Then it is expected that both $z_j$ and $z_l$ have information about both $y_i$ and $y_k$. Therefore, we consider it more correct to define a compact representation as the one in which $I(y_i; Z_j|z_j) = 0$, where $Z_j = \\{z_k\\}_{k\\neq j}$. This is equivalent to having the Markov chain $z_j \\leftrightarrow z_j \\leftrightarrow Y_i$. This implies that $y_i$ does not need any variable other than $z_j$ to be explained. In this case, we have that $p(y_i|z_j) = p(Y_i|z_j, Z_j) = P(y_i|z)$. This can be useful for downstream tasks, since if we want to predict $y_i$, we could keep only $z_j$ and ignore the rest. Similarly, in a controllable generative model, it would be sufficient to modify $y_i$ by manipulating only $z_j$ to determine the value of $y_i$. The compactness of a representation refers to how compact its variables are.\n\n\u2022 Explicitness (informativeness in [44]): A representation is said to be explicit if it contains all the information about its factors of variation. This means that $I(y_i; x|z) = 0$, i.e., x provides no information about $y_i$ when z is known. This is equivalent to having the Markov chain $x \\leftrightarrow z \\leftrightarrow y_i$. Thus, we have that $p(y_i|z,x) = P(y_i|z)$. From the definition of representation, we know that $p(y_i|z, x) = p(y_i|x)$, so we can conclude that a representation is explicit if $p(y_i|z) = p(y_i|x)$."}, {"title": "Connection to Information Bottleneck", "content": "The Information Bottleneck is a generalization of sufficient minimality statistics that aims to achieve a trade-off between accuracy and complexity in the representations [71\u201374]. Specifically, given an input X and a task Y, the objective is that the representation Z contains the maximum possible information about Y and, simultaneously, the minimum possible information about X. Thus, the optimum would be found at the point where Z contains only all the information about Y. This is formalized by maximizing I(Z; Y) and minimizing I(Z; X) jointly. On the one hand, the representation Z that maximizes I(Z; Y) is called sufficient. By the definition of representation, we know by the Data Processing Inequality (DPI) [75] that $I(Z; Y) \\leq I(X; Y)$. Since this is the unique upper bound of I(Z; Y), the sufficient representation satisfies that $I(Z; Y) = I(X; Y)$. Therefore, a sufficient representation satisfies the Markov chain $X \\leftrightarrow Z \\leftrightarrow Y$, i.e., Y is fully described by Z. On the"}, {"title": "Measuring Disentanglement for non-Independent Factors of Variation", "content": "As explained in section 3.2, different works explain that disentanglement can be described by three properties: modularity, compactness, and explicitness. As argued in section 3.3, disentanglement can be more fully described by two properties: sufficiency and minimality. These two properties collect the previous three and also assess whether a representation is invariant to noise, which is a relevant and often overlooked property. Despite the latter, we propose below a method to measure modularity, compactness and explicitness taking into account that the factors of variation may be dependent on each other. The reason for this is because the methods proposed by other authors measure these three properties and, therefore, it is easier to compare our proposal with them. However, in Appendix B, we give a method to measure sufficiency and minimality. In Appendix C we go deeper and give examples in which minimality captures disentanglement better than modularity."}, {"title": "Experiment I: Cosine Dependence", "content": "In order to analyze the performance of our proposal and compare it with other methods in the literature, we start by creating a controlled environment in which we know the exact relationship between the factors of variation and the different variables of our representation. To do this, we create different scenarios that allow us to analyze the different properties. For this experiment, we have three factors of variation, i.e., $y = \\{y_i\\}_{i=1}^3$, so that $y_1 \\sim \\mathcal{U} [0, \\pi), y_2 \\sim \\mathcal{U} [0, \\pi)$ and $y_3$ is defined differently depending on the scenario in Table 1. On the other hand, our representation has m variables, i.e., $z = \\{z_j\\}_{j=1}^m$. Each of the $z_j$ is defined as cosine of values in [0, \u03c0), so that these values can be recovered due to the bijectivity of the cosine in this domain. The values of the $z_j$ are different in each scenario and are detailed in Table 1. We use mean absolute error as the E function and random forest regressors in Algorithms 1 and 2. Other metrics and regressors could be studied, but it is beyond the scope of this paper, since the idea of this paper is to present the theoretical idea and we believe that these two aspects could be dependent on the context of application."}, {"title": "Experiment II: Conditionally Colored MNIST", "content": "In this second experiment we train a representation learning system so that its output is expected to be disentangled with respect to some given factors of variation. The peculiarity is that we design the dataset so that there is dependence between the factors of variation. The goal of this experiment is to verify in a more realistic scenario that other metrics do not correctly detect disentanglement even though the representations are correctly disentangled. In fact, we demonstrate how we can achieve some of the advantages derived from having disentangled representations and these metrics tell us that there is no disentanglement. To design this dataset, we take the subset of the well-known MNIST dataset [76] containing images corresponding to the digits 0, 1, 2 and 3. Subsequently, we color the digit and the background. Specifically, the digit color can be red or green and the background color can be black or white. The probabilities of each color are different according to the digit and we define them in Table 5. Therefore, we have three factors of variation: digit, background color and digit color and digit is not independent of the other two."}, {"title": "Conclusion", "content": "In this paper we have presented the idea that the most popular definitions of disentanglement are incomplete, since they do not consider the case in which there is dependence between factors of variation, which is the most common scenario in the real world. Consequently, the metrics used to measure disentanglement are inaccurate when there is some dependence between factors of variation. To address this, we have redefined these properties from the point of view of information theory to adapt them to scenarios where there is dependence between factors of variation. Furthermore, we have related these properties to the information bottleneck method and shown that, if the variables in a representation are sufficient and minimal, then the representation is disentangled. From the definitions we have given, we have proposed methods to measure the different properties that define an disentangled property, which solve the limitations of other metrics when we have dependent factors of variation. Finally, we have presented two experiments which serves to show that our proposal overcomes the presented problem and allows to measure disentanglement even in the case where there is dependence between factors of variation."}, {"title": "Proof of Propositions", "content": "Proposition 1. Let $y = \\{y_i\\}_{i=1}^m$ be some factors of variation and $z = \\{z_j\\}_{j=1}^m$ a representation. Then, $z_j$ is a sufficient representation of $y_i$ if and only if z is explicit and $z_j$ is compact with respect to $y_i$. Equivalently, we have the that\n\n$(x\\leftrightarrow z_j \\leftrightarrow Y_i) \\leftrightarrow (\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow Y_i) \\wedge (x \\leftrightarrow z \\leftrightarrow Y_i)$\n\nProof. First, we demonstrate that $(x \\leftrightarrow z_j \\leftrightarrow Y_i) \\rightarrow (\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow y_i)$: Given this Markov chain, by the DPI, we have that $I(y_i; x) \\leq I(y_i; z_j)$. Since z is a representation of \u00e6, we also have that $I(y_i; z) \\leq I(y_i; x)$. Therefore, it follows that $I(y_i; z) \\leq I(y_i; z_j)$ On the other hand, by the mutual information chain rule, we have that $I(y_i; z) = I(y_i; z_j, \\tilde{z_j}) = I(y_i; z_j) + I(y_i; \\tilde{z_j}|z_j)$. By the non-negativity of mutual information, we are left with $I(y_i; z) > I(y_i; z_j)$. Therefore, we have that $I(y_i; z_j) = I(y_i; z) = I(Y_i; z_j, \\tilde{z_j})$ or, equivalently, $\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow Y_i$.\n\nSecond, we demonstrate that $(x \\leftrightarrow z_j \\leftrightarrow Y_i) \\Rightarrow (x \\leftrightarrow z \\leftrightarrow y_i)$: Since $z_j$ is a representation of x, we have that $p(y_i|x, z_j) = p(y_i|x)$. Moreover, since $z_j$ is sufficient, we have that $p(y_i|x, z_j) = p(Y_i|z_j)$. Putting the above two terms together, we are left with $p(y_i|x) = p(Y_i|z_j)$. As we have already shown, if $z_j$ is sufficient, then we have the Markov chain $(\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow Y_i)$, so $P(Y_i|z) = P(Y_i| z_j)$. Therefore, we are left with $p(y_i|z) = p(y_i|x)$. Finally, since z is a representation of \u00e6, we know that $p(y_i|x) = p(y_i|x, z)$. Putting all of the above together, we are left with $P(y_i|x, z) = P(y_i|z)$ or, equivalently, $x \\leftrightarrow z \\leftrightarrow Y_i$.\n\nFinally, we demonstrate that $(\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow Y_i) \\wedge (x \\leftrightarrow z \\leftrightarrow Y_i) \\Rightarrow (x \\leftrightarrow z_j \\leftrightarrow y_i)$: Since $z_j$ and z are representations of \u00e6, we have that $p(y_i|x, z_j) = P(y_i|x, z) = p(y_i|x)$. Furthermore, given the Markov chain $x \\leftrightarrow z \\leftrightarrow y_i$, we know that $p(y_i|x, z) = p(y_i|z)$. Equivalently, given $\\tilde{z_j} \\leftrightarrow z_j \\leftrightarrow Y_i$, we have that $p(y_i|z_j) = p(Y_i|z_j, \\tilde{z_j}) = p(y_i|z)$. Recapitulating the above, we are left with $p(Y_i|z_j) = P(y_i|z) = p(y_i|x, z) = p(y_i|x, z_j)$. Therefore, we have that \u00e6 \\leftrightarrow z_j \\leftrightarrow Y_i$.\n\nProposition 2. Let $y = \\{y_i\\}_{i=1}^m$ some factors of variation and $z = \\{z_j\\}_{j=1}^m$ a representation. If $z_j$ is a minimal representation of $y_i$, then $z_j$ is modular with respect to $y_i$. Equivalently, we have the that\n\n$(x \\leftrightarrow Y_i \\leftrightarrow z_j) \\rightarrow (\\tilde{Y_i} \\leftrightarrow Y_i \\leftrightarrow z_j)$\n\nProof. Given this Markov chain, by the DPI, we have that $I(z_j; x) \\leq I(z_j; y_i)$. Since $z_j$ is a representation of \u00e6, we also have by DPI that $I(z_j;y) \\leq I(z_j;x)$. Therefore, it follows that $I(z_j;y) \\leq I(z_j; Y_i)$ On the other hand, by the chain rule of mutual information, we have that $I(z_j; y) = I(z_j; Y_i, \\tilde{Y_i}) = I(z_j; Y_i) + I(z_j; \\tilde{Y_i}|Y_i)$. By the non-negativity of mutual information, we are left with $I(z_j; y) \\geq I(z_j; y_i)$. Therefore, we have that $I(z_j; y_i) = I(z_j; y) = I(z_j; Y_i, \\tilde{Y_i})$ or, equivalently, $\\tilde{Y_i} \\leftrightarrow Y_i \\leftrightarrow z_j$.\n\nProposition 3. Let $y_i$ be a factor of variation, n some nuisances and $z = \\{z_j\\}_{j=1}^m$ a representation. If $z_j$ is a minimal representation of $y_i$, then $z_j$ is invariant to nuisances n with respect to $y_i$. Equivalently, we have the that\n\n$(x \\leftrightarrow Y_i \\leftrightarrow z_j) \\Rightarrow (n \\leftrightarrow Y_i \\leftrightarrow z_j)$\n\nProof. Given this Markov chain, we know from the DPI that $I (z_j; x) \\leq I(z_j; y_i)$. On the other hand, since $z_j$ is a representation of \u00e6, we have the Markov chain $(n, y_i) \\leftrightarrow x \\leftrightarrow z_j$. Equivalently, we have that $I (z_j; n, y_i) \\leq I(z_j; x)$. The chain rule of mutual information tells us that $I(z_j; n|y_i) = I(z_j; n, y_i) - I(z_j|y_i)$. According to the above two points, we are left with $I(z_j; n|y_i) \\leq I(z_j; x) - I(z_j|y_i)$. Therefore, because of the nonnegativity of mutual information, it is only possible that $I(z_j; n|y_i) = 0$ or, equivalently, $n \\leftrightarrow Y_i \\leftrightarrow z_j$."}, {"title": "Algorithms for Sufficiency and Minimality", "content": "As we have explained in section 3.3, disentanglement can also be measured through sufficiency and minimality. If the variables of a representation are sufficient, then the representation is compact and explicit. Likewise, if the variables of a representation are minimal, then the representation is modular and also invariant to nuisances. For the latter reason, minimality reflects the degree of disentanglement better than modularity since we can have high modularity, but have nuisances that affect the variables of our representation. Despite this, in the paper we have presented algorithms to measure the three classical properties modularity, compactness and sufficiency since this allows us to compare our results with those of other works. However, we can measure sufficiency and minimality in a similar way to the previous three properties. We explain the methods for doing so below.\n\nMinimality As explained, minimality means that $I(z_j; Y_i) = I(z_j; x)$ and, therefore, $p(z_j|y_i) = p(z_j|x)$. In Algorithm 3 we show the details to calculate minimality. As we can see, the only change with respect to Algorithm 1 is in line 9. In this case, we calculate the error between predicting $z_j$ from $y_i$ and the $z_j$ obtained from \u00e6. Also, unlike Algorithm 1, we do not use $f^*$ or $f_j$ to obtain $m_{ij}$. However, we do need them to compute $a_j$, which is used to obtain the global modularity of the representation.\n\nSufficiency In this case, sufficiency means that $I(y_i; x) = I(y_i; z_j)$ and, therefore, $p(y_i|z_j) = p(y_i|x)$. In Algorithm 4 we show the steps to compute sufficiency. Comparing it with Algorithm 2, here we can totally dispense with $g^*$ and $g_i$ because we do not need them to obtain $s_{ij}$, since here we calculate the difference between predicting $y_i$ from $z_j$ and the actual $y_i$. Finally, we compute the sufficiency of a representation as the arithmetic mean of its n components, just like compactness and explicitness in Algorithm 2."}, {"title": "Modularity vs. Minimality for Disentanglement", "content": "As argued in section 3.3, minimality allows to capture the modularity and also the invariance to nuisances. This is important because we can say that a variable of a representation is modular and this implies that, once a given factor of variation is known, the rest does not affect it. However, it may be that such a variable is affected by nuisances even though we know its factor of variation. This implies that we may not be able to explain the variable based exclusively on one of the representation factors. This, for example, when using disentangled representations to obtain explainable predictions or representations, would mean that the explanations are not totally reliable. Therefore, one property that disentangled properties should have is invariance to nuisances. This would make it possible to explain a proxy variable based solely on a factor of variation independently of any nuisance. The problem with this property is that it is difficult (or perhaps impossible) to impose and measure because we do not know all the nuisances that affect our data. However, as we have demonstrated in Appendix A, if a variable is a minimal representation, then it is also modular and invariant to nuisances. Therefore, we can explain that variable based solely on a factor of variation independently of all other factors of variation and nuisances. Therefore, it seems to us more appropriate to measure the minimality of the variables of a representation in order to evaluate its disentanglement. To illustrate the above, in Table 9 we describe new scenarios based on the experiment in section 5. Unlike those in Table 1, these contain information about nuisances in different variables of the representations.\n\nIn this case, unlike what we did in section 5, we analyze modularity and minimality of each variable $z_j$. We perform this more detailed analysis to understand better the influence that introducing a nuisance in a variable has on each of the metrics. We show these results in Tables 10 and 11.\n\nThe first thing we can observe comparing Cos11 and Cos1D in Table 11 is that minimality is also not affected by the fact that there are dependent factors of variation, since the values obtained in the two cases are similar. This is desirable, as it makes the measure independent of how the factors of variation relate to each other.\n\nOn the other hand, it is interesting that modularity of $z_4$ is high in all the scenarios despite the fact that this variable does not contain information about any factor of variation. This happens because the prediction of $z_4$ from $y_i$ and from y gives a random value and, therefore, the difference between both predictions does not tend to be too high. However, in Table 11, we see that minimality for $z_4$ is low in all scenarios. This fits with the fact that $z_4$ does not contain information about any factor of variation. It must be noted that the value of $z_4$ will be very low in Algorithms 1 and 3, because it precisely measures how much information about y has $z_4$. Therefore, modularity and minimality of $z_4$ will hardly affect their overall value. However, the modularity does not give us reliable information for each variable in the representation, which may be desirable in different applications.\n\nIn line with the above, we have the cases of CosNuis2I and CosNuis2D. We see that the values of modularity are quite similar for $z_3$ and $z_4$, even though the former contains information about y and the latter does not. However, in Table 11 the minimality is practically null for $z_4$, but not for $z_3$.\n\nThe most problematic case of the above is found in CosNuis3I. We see from Table 10 that modularity for $z_1$ and $z_2$ is lower than for $z_3$, which, in turn, is lower than for $z_4$. However, $z_1$ and $z_2$ contain information on two factors of variation, $z_3$ on two factors of variation and nuisances, and $z_4$ on nuisances exclusively. Therefore, it would be expected that the values of modularity would be higher in $z_1$ and $z_2$ than in $z_3$ and that those of $z_3$ would be higher than those of $z_4$. We see that this problem disappears in the minimality and here we find the expected order. Hence, minimality takes into account the influence of nuisances on the variables of the representations."}, {"title": "Details of Experiment II", "content": "To train our model for the experiment in section 6, we have relied on [27"}]}