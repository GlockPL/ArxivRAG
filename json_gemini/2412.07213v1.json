{"title": "Intellect Seeker: A Personalized Literature Management System with the Probabilistic Model and Large Language Model", "authors": ["Weizhen Bian", "Siyan Liu", "Yubo Zhou", "Dezhi Chen", "Yijie Liao", "Zhenzhen Fan", "Aobo Wang"], "abstract": "Faced with the burgeoning volume of academic literature, researchers often need help with uncertain article quality and mismatches in term searches using traditional academic engines. We introduce IntellectSeeker, an innovative and personalized intelligent academic literature management platform to address these challenges. This platform integrates a Large Language Model (LLM)-based semantic enhancement bot with a sophisticated probability model to personalize and streamline literature searches. We adopted the GPT-3.5-turbo model to transform everyday language into professional academic terms across various scenarios using multiple rounds of few-shot learning. This adaptation mainly benefits academic newcomers, effectively bridging the gap between general inquiries and academic terminology. The probabilistic model intelligently filters academic articles to align closely with the specific interests of users, which are derived from explicit needs and behavioral patterns. Moreover, IntellectSeeker incorporates an advanced recommendation system and text compression tools. These features enable intelligent article recommendations based on user interactions and present search results through concise one-line summaries and innovative word cloud visualizations, significantly enhancing research efficiency and user experience. IntellectSeeker offers academic researchers a highly customizable literature management solution with exceptional search precision and matching capabilities. The code can be found here: https://github.com/LuckyBian/ISY5001", "sections": [{"title": "1 Introduction", "content": "With the overwhelming growth of research documents in digital libraries, finding relevant material has become increasingly time-consuming. This surge in"}, {"title": "2 Related Works", "content": "Literature management systems have evolved significantly, transitioning from traditional document management tools to more innovative and personalized advanced systems. Traditional academic search engines like ScienceDirect, ResearchGate, and Google Scholar offer basic recommendations but often must accurately meet some researchers' needs. Even if these systems work correctly, their suggestions are only sometimes relevant or valuable for the user. It is also essential to be cautious with these platforms, especially for citations and metrics, as they can be manipulated and sometimes have issues with the quality of their indexing [3]. We have noticed a shortage of highly customizable academic literature management systems that can construct targeted literature databases based on individual research interests.\nIn the domain of personalized literature management systems, particularly in recommending academic papers, various methods are employed by recommendation systems to address cold-start scenarios. Standard methods include Content-Based Filtering (CBF), Collaborative Filtering (CF), Link-Based and co-occurrence-based Approaches, and various hybrid methods. In the field of"}, {"title": "3 Proposed System", "content": "Fig. 1 showcases the IntellectSeeker platform, a sophisticated academic tool that blends data scraping, an enhanced search engine, and an interactive interface to revolutionize academic research. A probabilistic model, central to its data scraping mechanism[2], is an essential aspect of Component A. This model adeptly selects scholarly articles to get a personalized database, intelligently aligning the data-gathering process with user-defined preferences. The academic articles that the user needs are accurately selected by considering the user's various preferences and features. Component B, the search engine, excels in query refinement and incorporates an advanced ranking system. This system judiciously assesses factors such as the timeliness of documents, user preferences, and historical user interactions, thereby delivering a well-tailored and pertinent set of documents[30]. Lastly, component C, which focuses on interactive data exploration and recommendation, harnesses the power of large language models (LLMs) to refine and enhance the search experience[31]. This subsystem is adept at interpreting nuanced user queries and translating them into academic lexicon, thus optimizing the search term entries. By analyzing user interactions such as likes and bookmarks, the IntellectSeeker platform contributes to developing a"}, {"title": "3.2 Probabilistic Data Scraping Model", "content": "In academic research, personalization and precision in data retrieval are crucial[33]. Therefore, we designed a probabilistic data scraping model (shown in Figure 2) to create a personalized database[34]. In the IntellectSeeker data crawling model, in addition to the traditional academic search platform's filtering function for factors such as document year and journal[35], it also adds factors such as user preferences to locate user needs accurately. As shown in figure 2, Intellect Seeker allows users to impose restrictions on the data scraping process during the data\nIn the advanced stages of data filtration, the Intellect Seeker platform employs a refined approach, drawing inspiration from decision tree[37] algorithms. This process entails meticulously matching article features with user-specific characteristics, executed via a probabilistic model. The operational essence of this model is encapsulated in the following formula:\n$I = w_p \\cdot S(K_a, K_u) + w_i \\cdot S(K_a, K_i)$\nwhere $I$ is the importance score, $K_a$ represents the article's features, $K_u$ denotes the user's preference features, $K_i$ signifies the user's manually inputted requirements, $w_p$ and $w_i$ are weights for user preferences and manual inputs respectively, and $S$ is the similarity function measuring the overlap between sets of keywords. 'I' represents the calculated importance score, ranging from 0 to 1."}, {"title": "3.3 Search Engine", "content": "Within the IntellectSeeker, the Semantic Enhancement with Large Language Model is a pivotal component crafted to deal with the problems users may encounter with academic language during scholarly searches. This subsystem's architecture and rationale are deeply rooted in understanding the user's query process and the wide range of terminology used across various academic realms. Researchers new to a field may use general terms due to unfamiliarity with the specialized vocabulary, which often leads to irrelevant results when using standard search engines like Google Scholar. To address this issue, we have deployed a semantically enhanced fine-tuned LLM dedicated to tackling this challenge as\nThis approach affords access to an extensive and interactive academic lexicon that is exceptionally professional and knowledge-rich, ensuring that even those researchers new to a field can swiftly acquire relevant academic term replacements, significantly enhancing the accuracy and efficiency of academic searches. The ability of natural language understanding and knowledge of LLM also ensure that it can understand various natural language instructions accurately, catering to different needs. It can transform vague terms into a series of alternatives across various fields or offer exact replacements in specific domains if users ask for them or simply define the domain. Through the LLM, users gain a personalized search experience with consistent, user-friendly, and easy-to-read outputs.\nWe have carried out a series of experiments on different LLMs, including open-source models like Llama2[21] families, Gemma2[38], Mistral-7b[39] and OpenAI model gpt-3.5-turbo[40]. For the OpenAI model, we experimented with different shot instruction strategies and fine-tuning to enhance the performance. We compared all LLMs and finally utilized a finetuned OpenAI GPT-3.5-turbo model based on a set of metrics that more perfectly matches the needs of this system component, providing more stable and comprehensive outputs, especially in the conversion from daily vocabulary to academic vocabulary across various research disciplines. We further crafted a user-friendly dialogue mode and framework through manual construction, which includes setting the format and style of responses, handling specific user requests such as academic term substitutions within designated fields, and addressing the reliability of term explanations."}, {"title": "3.4 Interactive Data Exploration and Recommendation", "content": "Automatic Summarization In the IntellectSeeker platform, a key feature is its sophisticated summarization capability, which employs the SMMRY API[41] to distill voluminous article abstracts into concise statements. This functionality is pivotal for accelerating the research process, particularly for PhD scholars who require rapid filtering and prioritization of relevant literature. Upon the user bookmarking a webpage, the system activates the API, which then scans and truncates the content, eliminating non-essential elements. This process embeds coherent, compressed summaries in saved pages, helping users filter out unwanted documents more quickly.\nInformation Visualization The IntellectSeeker platform has harnessed the power of visualization to enhance user experience during the search process. Upon initiating a query, the platform comprehensively analyzes the search results, aggregating the core terms identified within these documents[32]. Subsequently, it extracts the twenty most frequently occurring terms from this collective pool, weaving them into an informative word cloud. This visual representation serves as a snapshot of the prevalent themes and concepts within the search\nresults, allowing users to ascertain the pertinence of the information retrieved quickly. If discrepancies exist or the results do not align with the intended search criteria, the word cloud provides immediate visual feedback.\nRecommendation The IntellectSeeker platform refines the academic research experience with its recommendation system. Drawing from traditional collaborative filtering methods, it analyzes user interactions such as likes, bookmarks, and clicks to recommend similar literature or connect users with similar research interests[42][43]. Additionally, it incorporates trending articles and recent publications to ensure researchers have access to the most current and influential works[44]. A hybrid algorithm integrates these approaches, weighting each to produce a tailored and dynamic list of literature, thereby streamlining the discovery process for scholars[45]."}, {"title": "4 Implementation", "content": "4.1 Train Semantic Enhancement Model\nData Corpus Construction We built an initial corpus with definitions of system roles and question-and-answer pairs. 0.266k rows of sample pairs were made for academic replacements of daily expressions specifying a particular field; the output was in a fixed format, providing academic replacement words and their definitions. In fine-tuning the models, the dataset was split into 9:1 as a training set and validation set. We manually wrote several prompts to construct this dataset, with academic word definitions sourced from academic databases [46]. These manually written prompts were then used to guide ChatGPT in generating more question-and-answer pairs in the same format defined manually. For the common unrelated questions, we allowed ChatGPT to generate them randomly, add variety to the corpus, and improve the model's adaptability to various input types.\nFine-tuning and Iterative Learning Considering the efficiency and cost of the system, we didn't use open-source LLM with supermassive parameters. Table 1 shows the result of different LLMs, including Llama2 with 7B and 13B, Gemma and Mixtral with the highest MT-bench score. The training methods include fine-tuning, zero-shot, one-shot, and few-shot instructions guide. For those experiments in which the training corpus is not demanded, we use the same validation set as the fine-tuned one to calculate the metrics. For performance comparison, BLEU, ROUGE series and METEOR which are the typical metrics in text conversion like translation are chosen for evaluation.\nThe results demonstrate that the fine-tuned GPT-3.5-turbo model outperforms others in all metrics, achieving a BLEU score of 0.9269, ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.9413, 0.9160, and 0.9355 respectively, and a METEOR score of 0.9553. These results indicate that the fine-tuned GPT-3.5-turbo"}, {"title": "4.2 Improve data Scraping Speed", "content": "In its quest to optimize data scraping efficiency, the IntellectSeeker platform integrates a sophisticated multi-threaded approach, significantly expediting the data retrieval process[47]. This is adeptly complemented by applying advanced Natural Language Processing (NLP) techniques, which are crucial in refining query mappings[48]. These techniques involve strategically removing stop words and implementing lemmatization algorithms, effectively streamlining linguistic data processing. This minimizes the storage requirements and markedly enhances the speed and precision of search operations. Furthermore, the platform adopts an innovative pointer-based storage system meticulously engineered to circumvent the pitfalls of redundant data storage[49]. This system not only preserves the integrity and organization of the stored data but also significantly contributes to the overall efficiency of data management within the platform."}, {"title": "5 Conclusion and Future Work", "content": "IntellectSeeker is a major step forward in scholarly research tools, providing unparalleled ease and precision when browsing vast literature databases. Its core capabilities include sophisticated probabilistic data crawling mechanisms and large language models to improve search precision. While IntellectSeeker significantly enhances literature management, there is room to enhance the capabilities of LLM to include more comprehensive scholarly services, such as advanced question-answering. Further innovations will be made with IntellectSeeker. Future efforts should focus on a deeper analysis of user interactions to create detailed profiles that lead to more targeted search strategies."}]}