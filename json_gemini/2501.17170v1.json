{"title": "Benchmarking Randomized Optimization Algorithms on Binary, Permutation, and Combinatorial Problem Landscapes", "authors": ["Jethro Odeyemi", "Wenjun Zhang"], "abstract": "In this paper, we evaluate the performance of four randomized optimization algorithms-Randomized Hill Climbing (RHC), Simulated Annealing (SA), Genetic Algorithms (GA), and MIMIC (Mutual Information Maximizing Input Clustering)-across three distinct types of problems: binary, permutation, and combinatorial. We systematically compare these algorithms using a set of benchmark fitness functions that highlight the specific challenges and requirements of each problem category. Our study analyzes each algorithm's effectiveness based on key performance metrics, including solution quality, convergence speed, computational cost, and robustness. Results show that while MIMIC and GA excel in producing high-quality solutions for binary and combinatorial problems, their computational demands vary significantly. RHC and SA, while computationally less expensive, demonstrate limited performance in complex problem landscapes. The findings offer valuable insights into the trade-offs between different optimization strategies and provide practical guidance for selecting the appropriate algorithm based on the type of problems, accuracy requirements, and computational constraints.", "sections": [{"title": "I. INTRODUCTION", "content": "OPTIMIZATION problems are central to decision-making processes in a wide array of fields such as operations research [1]-[5], machine learning [6]-[8], economics [9], logistics [10], [11], and engineering design [12]-[15]. The goal in optimization is to determine the values of decision variables that either maximize or minimize an objective function, often while satisfying a set of constraints. In machine learning, optimization is critical during the model training process, where the objective is typically to minimize a loss function [16] that measures the error between predicted and true values. The process of tuning model parameters is often accomplished using gradient-based methods such as gradient descent [17] and its variants (e.g., stochastic gradient descent [18], Adam [19]). These methods are highly efficient for convex problems, but they face significant challenges in more complex scenarios, particularly when the objective function [20] is non-convex, riddled with local minima, or spans a high-dimensional space. To overcome these limitations, random optimization algorithms which uses randomness to explore the solution space more thoroughly have emerged as powerful alternatives. Random optimization techniques are particularly effective for solving binary [21], permutation [22], and combinatorial problems [23], where traditional gradient-based methods may not be applicable or efficient.\nThis study aims to compare the performance of different optimization algorithms across benchmark functions categorized by solution structure into binary, permutation, and combinatorial problems. The final results highlight trade-offs between computational cost, solution quality (fitness), and convergence speed in selecting appropriate optimization algorithms. We show that Genetic Algorithm (GA) and Mutual Information Maximizing Input Clustering (MIMIC) show strengths in binary problems, while MIMIC excels in permutation problems requiring high solution quality. In contrast, GA performs well in combinatorial problems, offering a balance between accuracy and efficiency. Low-computation-cost algorithms like Randomized Hill climbing (RHC) are useful when resources are limited, albeit with lower solution quality.\nThe rest of the paper is organized as follows. In Section 2, we discuss related works, reviewing studies that evaluate optimization algorithms across different problem types. Section 3 introduces the randomized optimization algorithms used in this research, along with their specific characteristics. In Section 4, we classify the fitness problems into binary, permutation, and combinatorial categories, explaining the benchmark problems used for evaluation. Section 5 describes the experimental setup, including the environment and tools used for the experiments. Section 6 presents the results and discussion, focusing on the performance of the algorithms across various types of problems. Finally, Section 7 concludes the paper with key findings and future research directions."}, {"title": "II. RELATED WORKS", "content": "Several studies have explored the performance of optimization algorithms across diverse problem types. For example, Derya (2020) evaluated Stochastic Gradient Descent (SGD), Adaptive Gradient Algorithm (AdaGrad), Adaptive Delta (AdaDelta), Adaptive Moment Estimation (Adam), and Root Mean Square Propagation (RMSProp) algorithms in deep learning [24], focusing on how these algorithms differ in their working principles, strengths, and limitations [25]. There were notable distinctions in their ability to handle noisy gradients, with Adam and RMSProp excelling in adapting learning rates, making them particularly suited for problems involving sparse data and non-convex loss landscapes. In another study, the performance of GA and Simulated Annealing (SA) in maximizing the thermal conductance of harmonic lattices is studied, highlighting the strengths of GA in global exploration, while noting SA's compute efficiency [26]. Similarly, a comparative analysis of Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO) for distance optimization is presented [27].\nIn this study, we analyze optimization challenges within the categories of binary, permutation, and combinatorial problems. In context of permutation problems, a recent investigation explored evolutionary diversity optimization applied to the Traveling Salesperson Problem (TSP) and Quadratic Assignment Problem (QAP) [28]. The study demonstrated that mutation operators for these permutation problems can ensure convergence towards maximally diverse populations, provided the population size is sufficiently small. Additionally, a Binary version of Equilibrium Optimization (BEO) has been proposed for tackling the 0-1 Knapsack discrete optimization problem [29]. Another study introduced the Global Neighborhood Algorithm (GNA), which balances global and local search in optimization [30]."}, {"title": "III. RANDOMIZED OPTIMIZATION ALGORITHMS", "content": "One of the key challenges in optimization lies in selecting the appropriate algorithm for a given problem type. The effectiveness of an algorithm depends on factors like whether the problem involves continuous or discrete variables, whether the landscape is convex or non-convex, and the complexity of the constraints. Therefore, choosing the right algorithm is crucial to balancing exploration and exploitation of the search space, avoiding local minima, and achieving near-optimal solutions, see also [31]. In this section, we explain the four most widely used randomized optimization algorithms: Randomized Hill Climbing (RHC), Simulated Annealing (SA), Genetic Algorithms (GA), and MIMIC (Mutual Information Maximizing Input Clustering). Each of these algorithms introduces randomness in different ways to enhance exploration and avoid getting trapped in local minima."}, {"title": "A. Randomized Hill Climbing (RHC)", "content": "RHC [32] is a local search algorithm that iteratively improves a candidate solution by exploring its neighborhood. The algorithm randomly selects a neighbor of the current solution and moves to that neighbor if it offers a better objective function value. If no better neighbors are found, the algorithm stops. RHC introduces randomness by restarting the search from a random point when it reaches a local optimum, which helps explore different regions of the search space. RHC uses the following working principle, summarized below:\n1) Start: Initialize a random solution x0.\n2) Neighbor Selection: At each iteration, randomly select a neighboring solution x' \u2208 N(x) from the neighborhood of the current solution x.\n3) Move: If the objective function f(x') is better than f(x), move to x', as shown in Equation (1):\n$$x \\leftarrow x'.$$\n4) Restart: When no improvement is found, restart the algorithm from a new random solution.\nAt each iteration t, the update rule is defined as follows (see Equation 2):\n$$x_{t+1} = \\begin{cases} x_t & \\text{if } f(x_t) \\geq f(x') \\\\ x' & \\text{if } f(x') > f(x_t) \\end{cases}$$\nHere, x' \u2208 N(xt) is a randomly selected neighbor of the current solution xt. RHC is simple but can easily get stuck in local minima without proper restarts [33]."}, {"title": "B. Simulated Annealing (SA)", "content": "SA [34] is an extension of hill climbing that introduces a probability of accepting worse solutions to escape local minima. The algorithm is inspired by the annealing process in metallurgy, where materials are slowly cooled to achieve a low-energy configuration. The acceptance of worse solutions is controlled by a temperature parameter T, which decreases over time. As the temperature decreases, the algorithm becomes more focused on exploiting local improvements.\n1) Start: Initialize with a random solution x0 and a high temperature T0.\n2) Neighbor Selection: At each iteration, select a neighboring solution x' \u2208 N(x).\n3) Acceptance Criterion: Move to x' if it improves the objective function (f(x') > f(x)). If f(x') \u2264 f(x), accept x' with probability given by Equation 3:\n$$P(\\text{accept}) = \\exp\\left(\\frac{f(x') - f(x)}{T}\\right)$$\nwhere T is the current temperature.\n4) Cooling Schedule: Reduce the temperature according to a cooling schedule, typically as shown in Equation 4:\n$$T(t) = T_0 \\times a^t,$$\nwhere a \u2208 (0,1) is the cooling factor and t is the iteration number.\nSimulated Annealing allows the search to explore a wide range of solutions at high temperatures and gradually focuses on the best solutions as the temperature decreases."}, {"title": "C. Genetic Algorithms (GA)", "content": "GA [35] are inspired by the process of natural selection, where a population of solutions evolves over time. GAs maintain a population of candidate solutions, which are recombined and mutated to explore the solution space.\n1) Initialization: Generate an initial population P of candidate solutions randomly.\n2) Selection: Select parent solutions from the population based on their fitness f(x). Higher-fitness solutions are more likely to be selected.\n3) Crossover: Combine two parent solutions x1 and x2 to create offspring xchild using a crossover operator. For example, in single-point crossover, the offspring is created as shown in Equation 5:\n$$x_{\\text{child}}[i] = \\begin{cases} x_1[i] & \\text{if } i \\leq \\text{cross-point} \\\\ x_2[i] & \\text{if } i > \\text{cross-point} \\end{cases}$$\n4) Mutation: Apply mutation to the offspring with some probability to introduce randomness and explore new areas of the solution space.\n5) Replacement: Replace the least-fit members of the population with the new offspring.\nThe population evolves over time, and the fittest individuals are selected to produce the next generation. The algorithm terminates after a fixed number of generations or when the population converges."}, {"title": "D. MIMIC (Mutual Information Maximizing Input Clustering)", "content": "MIMIC [36] is a probabilistic optimization algorithm that constructs a probabilistic model of the solution space and uses this model to generate new candidate solutions. MIMIC builds a dependency tree based on mutual information between variables and samples solutions from this model.\n1) Initialization: Generate an initial population P of random solutions.\n2) Model Building: Construct a probabilistic model of the population by estimating the mutual information between variables. This model captures dependencies between decision variables.\n3) Sampling: Generate new solutions by sampling from the probabilistic model. These new solutions are used to explore the search space.\n4) Selection: Retain the top k solutions based on their fitness and use these to update the probabilistic model.\nMIMIC balances exploration and exploitation by using probabilistic models to sample promising regions of the search space, making it highly efficient for large combinatorial problems.\nMutual Information between two variables Xi and Xj is given by Equation 6:\n$$I(X_i; X_j) = \\sum_{X_i, X_j} p(x_i, x_j) \\log \\frac{p(x_i, x_j)}{p(x_i)p(x_j)},$$\nwhere I(Xi; Xj) is the mutual information and p(xi, xj) is the joint probability distribution."}, {"title": "IV. EXPERIMENTS", "content": "The experiments were implemented using Python version 3.11.9 and the mlrose [37] package to apply various search algorithms to randomized optimization problems. All simulations were conducted on a system equipped with an AMD Radeon RX 6800S GPU, 15.6 GB of usable memory, and executed in an interactive notebook environment.\nThe primary objective of this study was to analyze the behavior of different algorithms across separate problem groups, focusing on the quantitative aspects of their performance rather than optimizing hyperparameters. Therefore, we used the default parameters provided in the mlrose library as a baseline and tested slight variations around these defaults."}, {"title": "B. Performance Metrics", "content": "During each run, the following performance metrics were monitored:\n\u2022 Fitness Score: The objective value for each problem, representing how well the algorithm optimized the solution [38].\n\u2022 Time Complexity: The time taken for the algorithm to converge to a solution.\n\u2022 Convergence Behavior: The count of function evaluation (feval) required for the algorithm to converge to an optimal or near-optimal solution.\nTo ensure reliable results, we averaged the values of these metrics over five experiment runs. This averaging reduces the impact of random variations and provides a more robust comparison of algorithmic performance across different problem groups."}, {"title": "V. RESULTS AND DISCUSSION", "content": "For the OneMax problem, where the objective is to maximize the number of 1's in a binary string, the performance of the algorithms reflects their ability to efficiently explore a simple and highly structured search space. Both GA and MIMIC perform exceptionally well, consistently achieving the maximum fitness of 50 across all runs (as seen in Table II). This is because the OneMax problem has a smooth fitness landscape, where small incremental improvements reliably guide the algorithm toward the global optimum. GA's crossover and mutation operators, enable efficient exploitation of this structure, while MIMIC's probabilistic sampling method effectively concentrates on high-quality solutions early [36], resulting in faster convergence, as illustrated in Figures 1c and 1d. On the other hand, RHC shows improvement with more restarts. This limitation arises because, without sufficient restarts, RHC lacks the global exploration required to escape local optima in the binary search space (Figure 1a). Given that the OneMax landscape provides a clear and direct path to the global optimum, SA's probabilistic moves add unnecessary noise, making it less efficient compared to GA and MIMIC, which can better exploit the straightforward nature of the search space (Figure 1b).\nIn the FlipFlop problem, where the objective is to maximize the number of alternating sequences of 1's and O's in a binary string, the performance of the algorithms exhibits both similarities and differences compared to the OneMax problem. GA and MIMIC continue to perform strongly, with GA achieving an reaching a maximum fitness of 43.8 for a population size of 100 and MIMIC closely matching with a fitness of 46.8 at population size of 300 (Table III). This is because both GA and MIMIC are well-suited to explore the more rugged landscape of the FlipFlop problem, which includes more local optima than the smooth OneMax problem, as seen in Figures 2c and 2d. In contrast, RHC struggles significantly more with FlipFlop, achieving only 33.0 fitness without restarts, and improving marginally to 37.6 with 5 restarts, indicating that RHC's inability to effectively escape local optima is even more pronounced in this problem (Table III, Figure 2a). SA, although somewhat improved compared to OneMax, still suffers from inconsistencies in performance due to its probabilistic acceptance of worse solutions, with fitness values fluctuating between 41.2 and 43.0 depending on the cooling schedule (Table III, Figure 2b). This fluctuation shows that while SA's flexibility allows it to explore the more complex landscape, the inherent noise in its search process continues to prevent it from reliably reaching optimal solutions, especially when compared to the more structured approaches of GA and MIMIC.\nIn the FourPeaks problem, where the goal is to balance between finding both long runs of 1's and O's in a binary string, the performance of the algorithms highlights the challenge of navigating a more complex landscape with multiple local optima. GA and MIMIC again perform well, with GA achieving a high average fitness of 85.8 for a population size of 300 (Table IV), and MIMIC close behind at 68.4 with the same population size. As seen in Figures 3c and 3d, both algorithms quickly converge to near-optimal solutions, but GA is notably faster in reaching higher fitness values, demonstrating its advantage in balancing exploration and exploitation for this problem's complex landscape. In contrast, RHC struggles significantly, achieving a maximum fitness of only 6.0 with 10 restarts (Table IV, Figure 3a), as it cannot effectively escape local optima in the FourPeaks landscape, where more global exploration is crucial. SA, while showing better results than RHC, has highly variable performance depending on the cooling schedule, with the best average fitness of 39.8 when using an exponential constant of 0.01 (Table IV, Figure 3b). SA's ability to accept worse solutions helps in this problem, but its stochastic nature introduces instability in performance, making it less reliable than GA or MIMIC.\nIn the SixPeaks problem, where the task is to optimize both peaks of 0's and 1's while rewarding strings that achieve long runs, we observe varying performance across algorithms, particularly highlighting the challenges of balancing exploration and exploitation in this more rugged search space. GA and MIMIC again show strong results, with GA reaching an average fitness of 89.2 with a population size of 200 and MIMIC achieving 75.0 with a population size of 300 (Table V). GA's ability to reach high fitness efficiently, seen in Figure 4c, reflects its success in quickly navigating this problem's dual-peak structure, where the balance between exploration and exploitation is critical. MIMIC also demonstrates strong performance, as shown in Figure 4d, converging steadily with different population sizes, though at a slightly slower pace than GA. Meanwhile, RHC struggles even more in the SixPeaks problem compared to previous benchmarks, with fitness values only reaching an average of 9.4 with 10 restarts, highlighting its severe limitations in overcoming the local optima present in the landscape (Table V, Figure 4c). Compared to the FourPeaks problem, SA's performance drops marginally in SixPeaks due to the higher level of exploration required.\nIn the ContinuousPeaks problem, where the goal is to balance between long sequences of O's and 1's, GA and MIMIC continue to excel, with GA achieving an average fitness of 82.4 for a population size of 200 and MIMIC reaching 80.8 with a population size of 300 (Table VI). GA's efficiency in this problem, as seen in Figure 5c, is due to its ability to exploit the structured peaks in the search space, allowing for rapid convergence to high-quality solutions. MIMIC also performs well, steadily improving with larger population sizes (Figure 5d), although it converges slightly more slowly compared to GA. RHC shows poor performance once again, with an average fitness of only 23.8 even with 10 restarts, underscoring its limitations in escaping local optima in this landscape (Table VI, Figure 5a). Interestingly, SA performs much better in this problem compared to previous benchmarks, achieving an average fitness of 77.2 with an exponential constant of 0.001, likely due to the problem's more defined peaks, which align well with SA's probabilistic exploration mechanism (Table VI, Figure 5b) or possibly due to a sheer stroke of luck."}, {"title": "B. Permutation Problems", "content": "In the Traveling Salesman Problem (TSP), where the goal is to find the shortest possible route through a set of cities, the performance of the algorithms reflects the challenge of navigating a complex, highly constrained search space. RHC performs relatively well, ony behind MIMIC, achieving an average fitness of 16.05 with 0 restarts and 13.75 with 5 restarts (Table VII). This suggests that RHC can escape local optima to some extent with no restarts, but additional restarts do not significantly improve the result. However, with 10 restarts, the average fitness drops to 11.52, showing that excessive restarts can hurt performance in this scenario. GA demonstrates a more consistent convergence pattern than both RHC and SA. With a population size of 100, it achieves an average fitness of 8.80, and with a population size of 200, it improves to 9.30. When the population size is increased to 300, the average fitness is further improved to 9.62. MIMIC outperforms all other algorithms (Figure 6), achieving the highest average fitness of 18.47 with a population size of 100. With a population size of 200, MIMIC achieves a slightly lower average fitness of 17.24, and with a population size of 300, it achieves 16.75. This indicates that MIMIC is highly effective at exploring promising regions of the solution space using its probabilistic model, but larger population sizes can lead to diminishing returns. MIMIC converges faster than GA, particularly with smaller population sizes, and efficiently solves the TSP.\nIn the Queens problem, where the objective is to place queens on a chessboard such that no two queens threaten each other, the results show that all algorithms perform significantly better than in previous permutation problems, reflecting the structured nature of the solution space. MIMIC performs best, with an average fitness of 95.4 for a population size of 300, quickly converging to near-optimal solutions (Table VIII, Figure 7d). This highlights MIMIC's strong ability to capture and exploit dependencies between variables in the Queens problem. GA also perform well, achieving an average fitness of 90.1 with a population size of 100, though it takes longer to converge compared to MIMIC (Figure 7c). SA shows improved performance here compared to the TSP, with an average fitness of 90.6 at an exponential constant of 0.01, although its convergence is less stable, as shown in Figure 7b. The probabilistic acceptance of worse solutions helps SA escape local optima, but it introduces variability, making it less reliable than GA and MIMIC in finding the optimal solution. RHC performs reasonably well for a local search algorithm, reaching an average fitness of 85.6 with 5 restarts, but it still lags behind the other methods, as it struggles to maintain global exploration."}, {"title": "C. Combinatorial Problems", "content": "In the Knapsack problem, where the goal is to maximize the value of selected items while staying within a weight limit, the results demonstrate how each algorithm handles the combinatorial complexity. GA perform the best, with an average fitness of 175.8 for a population size of 300 (Table IX). GA's crossover and mutation operations help it efficiently explore the solution space, as seen in Figure 8c, where the fitness improves steadily, demonstrating its capacity to balance exploration and exploitation effectively. MIMIC also shows strong performance, particularly with a population size of 100, achieving an average fitness of 162.0. However, as shown in Figure 8d, MIMIC's fitness progression tends to plateau after an initial steep climb, especially for larger population sizes, indicating that the algorithm struggles to continue improving beyond a certain point in this combinatorial problem. SA performs moderately well, reaching an average fitness of 111.0 with an exponential constant of 0.001. However, its performance fluctuates, as seen in Figure 8b, where SA either converges rapidly or lags behind, depending on the cooling schedule. RHC performs poorly compared to the other methods, with an average fitness of only 91.2 with 10 restarts. RHC's inability to effectively escape local optima and explore larger portions of the solution space hampers its performance in the more complex search space of the Knapsack problem, a limitation that has been consistent across the other problems analyzed."}, {"title": "D. Cross-Group Performance Analysis of Optimization Algorithms", "content": "In this section, we compare the performance of RHC, SA, GA, and MIMIC across binary, permutation, and combinatorial problem groups, highlighting the distinct trends in efficiency, computational cost, and solution quality that emerge. As seen in Figure 9, MIMIC and GA perform exceptionally well across all problem groups, particularly excelling in the combinatorial group, where MIMIC achieved over 80% of the total possible fitness for the Knapsack problem, and GA reached 86%. For the permutation group, MIMIC showed a similar trend with fitness values hovering around 90% in problems like Queens, while GA exhibited consistent, though slightly slower, performance. The binary group had a simpler fitness landscape, allowing both MIMIC and GA to converge efficiently, although the binary problems generally presented fewer local optima and required less sophisticated search mechanisms than the combinatorial and permutation problems.\nHowever, a deeper comparison reveals trade-offs between solution quality and computational costs. As shown in Figure 10, MIMIC incurs higher computational cost in terms of wall clock time across all groups, particularly in the permutation and combinatorial problems. For example, in the binary problem group, MIMIC's higher wall clock time was more pronounced compared to GA, which maintained moderate time efficiency while still producing competitive fitness results. This highlights MIMIC's strength in consistently achieving high solution quality, albeit at the cost of increased computation, making it more suitable for cases where accuracy is paramount, and computational resources are less constrained. On the other hand, GA demonstrated a more balanced approach across groups, achieving high-quality solutions with significantly lower computational overhead than MIMIC, making it more appropriate for situations where a compromise between solution quality and time efficiency is needed.\nRHC and SA, as expected, struggled to maintain competitive performance across the groups. As shown in Figure 11, SA required the highest number of feval, particularly in binary and permutation problems, reflecting its difficulty in efficiently exploring simpler landscapes where local optima are less challenging to escape. RHC consistently underperformed, achieving less than 60% of the total possible fitness in all groups, with its performance particularly poor in the combinatorial problems. Its inability to explore the search space effectively and its susceptibility to getting trapped in local optima, as shown by the relatively few feval in Figure 11, make it the least effective algorithm across all problem types. We summarise the results of our experiments in Table X."}, {"title": "VI. CONCLUSION", "content": "In this study, we assessed the performance of four optimization algorithms\u2014RHC, SA, GA, and MIMIC-by analyzing their underlying mechanisms and comparing their strengths and weaknesses. These algorithms were tested across three distinct problem categories: binary (including OneMax, FlipFlop, FourPeaks, SixPeaks, and ContinuousPeaks), permutation (Traveling Salesman and N-Queens), and combinatorial (Knapsack). The performance and behavior of each algorithm were evaluated through multiple experimental trials. Results showed that while MIMIC and GA demonstrated superior performance for all problem group, they also came with significantly higher computational costs. Ongoing research aims to develop more efficient algorithms that maintain high performance while reducing computational overhead. Additionally, a specific study was conducted to assess the robustness and resilience of each algorithm in applications such as planning and scheduling. Preliminary work exploring the concept of algorithmic resilience in these contexts can be found in earlier research [39], [40]. Another avenue for future work is to explore how different coding schemes may affect the performance of optimization algorithms. Literature suggests that coding schemes can significantly impact efficiency, as shown in [41]. where a proposed coding scheme reduced the number of iterations by 17%."}]}