{"title": "Revisiting Synthetic Human Trajectories:\nImitative Generation and Benchmarks Beyond Datasaurus", "authors": ["Bangchao Deng", "Xin Jing", "Tianyue Yang", "Bingqing Qu", "Philippe Cudre-Mauroux", "Dingqi Yang"], "abstract": "Human trajectory data, which plays a crucial role in various ap-\nplications such as crowd management and epidemic prevention, is\nchallenging to obtain due to practical constraints and privacy con-\ncerns. In this context, synthetic human trajectory data is generated\nto simulate as close as possible to real-world human trajectories,\noften under summary statistics and distributional similarities. How-\never, the complexity of human mobility patterns is oversimplified by\nthese similarities (a.k.a. \u201cDatasaurus\u201d), resulting in intrinsic biases\nin both generative model design and benchmarks of the gener-\nated trajectories. Against this background, we propose MIRAGE, a\nhuMan-Imitative tRAjectory GenErative model designed as a neural\nTemporal Point Process integrating an Exploration and Preferential\nReturn model. It imitates the human decision-making process in\ntrajectory generation, rather than fitting any specific statistical dis-\ntributions as traditional methods do, thus avoiding the Datasaurus\nissue. Moreover, we also propose a comprehensive task-based eval-\nuation protocol beyond Datasaurus to systematically benchmark\ntrajectory generative models on four typical downstream tasks,\nintegrating multiple techniques and evaluation metrics for each\ntask, to comprehensively assess the ultimate utility of the gener-\nated trajectories. We conduct a thorough evaluation of MIRAGE on\nthree real-world user trajectory datasets against a sizeable collec-\ntion of baselines. Results show that compared to the best baselines,\nMIRAGE-generated trajectory data not only achieves the best sta-\ntistical and distributional similarities with 59.0-71.5% improvement,\nbut also yields the best performance in the task-based evaluation\nwith 10.9-33.4% improvement.", "sections": [{"title": "1 INTRODUCTION", "content": "Human trajectory data is a key ingredient for a wide range of ap-\nplications, including urban planning [79], traffic management [40],\nepidemic analysis [15], predictive policing [62], and location-based\nservices [14]. These applications heavily rely on the quality of hu-\nman mobility models learnt from human trajectory data. However,\nacquiring large-scale real human trajectory data is often challenging\ndue to practical constraints and privacy concerns [32]. Therefore,\nsynthetic human trajectory data has been widely used as an alter-\nnative, where generative models are learnt to generate artificial\ntrajectories that closely resemble real-world human trajectories,\nmaking human trajectory data more readily available.\nIn the current literature, existing works on synthetic human\ntrajectory generation mostly focus on the resemblance under sum-\nmary statistics and distributional similarities [31]. For example,\nthese works measure the resemblance in different aspects of mo-\nbility characteristics such as spatial distribution (e.g. G-Rank) [29],\ntemporal distribution (e.g. stay duration) [44], OD flows (trips per\nOD pair) [74], and user mobility patterns (e.g. I-Rank and DailyLoc)\n[66], using divergence/distance metrics such as Kullback-Leibler\ndivergence (KLD) [4], Jensen-Shannon divergence (JSD) [11, 43],\nearth mover's distance (EMD) [2], Root Mean Squared Error (RMSE)\n[3, 44]. These similarities often serve on one hand as part of the\nmodel design such as the model fitting objective [28], while on\nthe other hand also as the benchmarks for evaluating trajectory\ngenerative models [26, 37, 43, 65]. However, while these similarities\nprovide insights into the differences between real and generated\ndata from various perspectives, they indeed oversimplify the com-\nplexity of human mobility patterns, resulting in intrinsic biases in\nboth generative model design and benchmarks of the generated\ntrajectories. Specifically, datasets that are similar over a number of\nstatistical properties may yield very different patterns, known as"}, {"title": "2 RELATED WORK", "content": "Early works mostly model individual mobility with explicit physical\nmeanings [16, 53] and generate synthetic trajectories under the dis-\ntributions of key characteristics observed in real mobility patterns,\nsuch as trip lengths, start locations, or start times, etc. [39, 48]. As a\nwidely recognized mobility model, the Exploration and Preferential\nReturn model (EPR) [52] unifies exploration and return mobility\npatterns by selecting new locations based on a random walk process\nfor exploration and revisiting previously visited locations based on\ntheir frequency for preferential return. Subsequent studies further\nextend the EPR model by integrating sophisticated spatial or social\ninformation, such as mining the correlation between location ca-\npacity and social network sizes [1], incorporating a nested gravity\nmodel into the EPR model [45], linking mobility to social ties and\nstudying the dynamics of spatial choices based on social behavior\n[58], and integrating the circadian propensity of human mobility\nand Markov-based models into the EPR model [28]. In addition,\nthe EPR model is also shown to be universal in human behavior\nmodeling in general, such as user activities in recommendation\nsystems [42, 55] and human behaviors in cyberspace [24, 25, 78].\nHowever, these models, often reliant on heuristic statistical assump-\ntions, have limitations in accurately modeling the complex mobility\npatterns observed in real-world trajectories.\nRecently, deep learning generative models have been widely\nadopted for mobility trajectory generation. They can flexibly cap-\nture the complex spatiotemporal patterns encoded in real-world\nmobility trajectories without strong prior assumptions. For example,\nSeqGAN [73] is the pioneering work of sequence generation based\non Generative Adversarial Networks (GAN); MoveSim [11] later\nincorporates information about physical distance, temporal period-\nicity, and historical transition matrix of location into a GAN frame-\nwork; TrajGen [7] employs a CNN-based GAN to map mobility\ntrajectories to images and to generate synthetic trajectory images,\nfollowed by a Seq2Seq model to output the synthetic trajectory;\nDeltaGAN [66] adopts a two-stage generative model to simulate\nhuman mobility trajectories, capturing fine-grained timestamps\nand effectively representing temporal irregularities; TS-TrajGen\n[29] combines the A* algorithm [19] with a GAN framework to\ngenerate continuous trajectories on urban road networks; SAVE\n[26] combines VAE and LSTM for mobility trajectory generation.\nIn addition, (neural) temporal point processes [8, 49, 75, 81] are\nalso widely used to model the temporal dynamics of user behaviors.\nIn the context of trajectory generation, VOLUNTEER [37] incorpo-\nrates a two-layer VAE model with a temporal point process to cap-\nture the characteristics of human mobility; ActSTD [76] enhances\nthe dynamic modeling of individual trajectories by utilizing neural\nordinary equations in the continuous location domain; DSTPP [75]\nfurther models the complex spatiotemporal joint distributions us-\ning diffusion models. In this paper, beyond traditional generative\ndeep learning models, we further design and integrate a neural\nEPR model with neural TPPs to imitate the human decision-making\nprocess in trajectory generation."}, {"title": "2.2 Synthetic Mobility Trajectory Benchmarks", "content": "The benchmarks for synthetic mobility trajectories can be classi-\nfied into two categories [31]. First, statistical and distributional\nsimilarities are the most widely used benchmarks, such as Kullback-\nLeibler divergence (KLD) [4], Jensen-Shannon divergence (JSD)\n[11, 43], earth mover's distance (EMD) [2], Root Mean Squared\nError (RMSE) [3, 44], which are used to measure the similarities\nbetween real and generated trajectories in different aspects. For\nexample, typical mobility statistics include the radius of gyration\n[11, 29, 76], the number of distinct locations visited per user per\nday [11, 66], I-Rank (frequency of visiting personal top locations)\n[11, 44], and the number of daily trips per user [44], trip lengths\nbetween consecutive trajectory points or between the origin and\ndestination [11, 18, 29, 56, 65]; spatial distributions characterize the\ndistribution of locations based on factors like visits per location (i.e.\nG-Rank) [11, 29, 43, 60, 65] or location popularity ranking [10, 18];\ntemporal distributions characterize the number of trips per hour of\nthe day [44], stay duration [11, 37, 43] and time intervals between\ncheck-ins [76]. However, while these similarity metrics provide\ninsights into the differences between real and generated data from\nvarious perspectives, they cannot fully reflect the ultimate utility\nof generated trajectories in supporting downstream tasks.\nSecond, benchmarking on downstream tasks recently emerged\nas an evaluation scheme for synthetic mobility trajectories. These\ntasks include road map updating [7], next location prediction [29,\n37, 61], and spreading simulation [11, 65, 76]. However, these works\noften use a heuristically designed downstream task with one specific\ntechnique/algorithm to solve the task, which leads to unknown\nbiases in the utility evaluation. As evidenced in our experiments in\nAppendix A, the performance of different techniques solving the\nsame task varies; heuristically choosing the results of one technique\nas the benchmark is thus untrustworthy. Therefore, we propose\na comprehensive task-based evaluation protocol to systematically\nbenchmark synthetic mobility trajectories."}, {"title": "3 PRELIMINARIES", "content": "Human Trajectory. A trajectory is defined as a time-ordered\nsequence X = {X1, X2, ..., Xn}, where xi = (ti, ki, li) is a presence\nevent defined as a tuple consisting of a timestamp ti, and a semantic\nactivity category ki, and a location (POI) li.\nTrajectory Generation. Given a real-world human trajectory\ndataset, the objective is to generate a new trajectory dataset while\npreserving the fidelity and utility of the original real-world dataset."}, {"title": "3.2 Neural Temporal Point Processes", "content": "Temporal Point Processes. A Temporal Point Process (TPP) is\na stochastic process where its realization is a sequence of discrete\nevents in time, represented as a sequence T = {t1, ..., tn}, which\ncan be equivalently represented as a sequence of strictly positive\ninter-event times ti+1 = (ti+1 \u2013 t\u2081) \u2208 R+. The conditional intensity\n\u03bb*(t), which fully specifies the TPP, represents the instantaneous\nrate of arrival of new events at time t given the history of past\nevents H\u2081 = {tj \u2208 T|tj < t}, where (*) is used as a shorthand"}, {"title": "3.2.2 TPP Parameterization.", "content": "Traditional TPPs often specify a sim-\nple parametric intensity function capturing relatively simple pat-\nterns in event occurrences, such as the Hawkes process [20], which\noften leads to poor results because of its limited flexibility in mod-\neling complex data. In this context, neural TPPs are developed to\nuse neural networks to learn complex dependencies from the his-\ntory of TPPs, and then approximate the intensity function by some\nparametric forms [50]. However, these intensity-based approaches\ncannot achieve flexibility, efficiency, and ease-to-use simultane-\nously [49]. Alternatively, an intensity-free learning model of neural\nTPPs is proposed to use a mixture of log-normal distributions to rep-\nresent the conditional probability density function p* (t) directly,\nand thus bypass the cumbersome intensity function [49]. Due to its\nadvantage of closed-form sampling and likelihood computation, the\nintensity-free approach has been widely adopted in learning neural\nTPPs [12, 17, 36, 66]. We also adopt the intensity-free approach in\nthis work."}, {"title": "4 MIRAGE", "content": "To imitate the human decision-making process in trajectory genera-\ntion, we design MIRAGE as an intensity-free neural Temporal Point\nProcess (TPP) integrating a neural Exploration and Preferential\nReturn (EPR) model. In the following, we first present the overview\nof MIRAGE, followed by the details of individual components."}, {"title": "4.1 Overview", "content": "Figure 1 shows the overview of MIRAGE consisting of two compo-\nnents. To imitate the human decision-making process, a trajectory"}, {"title": "4.2 Trajectory History Encoder", "content": "Representing a human trajectory as a sequence of events {X1, X2, ...,xn}, the trajectory history encoder first encodes individual event xi = (ti, ki, li) to event embedding ei, and then adopts a Gated Recurrent Unit (GRU) to encode the sequence of event embeddings.\nSpecifically, for each event (ti, ki, li), we first encode the timestamp ti by converting it to the log inter-event time log(ti) = log(ti-ti-1).\nThis lossless conversion is to fit the formulation of the intensity-free\nTPP; however, the actual timestamp t\u2081 is still useful in the decoding\nprocess, and we will discuss this point later. We also encode the\ncategory ki and location li using two embedding layers Ek and E1, respectively.\n$e_{t}^{e}=log(t_{i}), e_{k}^{e}=E_{k}k_{i}, e_{l}^{e}=E_{l}l_{i}$  (2)\nThe event embedding e\u00a1 is obtained by concatenating $e_{t}^{e}$, $e_{k}^{e}$ and $e_{l}^{e}$:\n$e_{i}=[e_{t}^{e};e_{k}^{e};e_{l}^{e}]$  (3)\nAfter obtaining a sequence of event embeddings, we then encode it using a recurrent neural network of GRU:\n$h_{i}=g(h_{i-1}, e_{i})$  (4)\nwhere g represents the recurrent updating function of GRU. The\noutput hidden state hi encodes all the trajectory history until ti."}, {"title": "4.3 Probabilistic Event Decoder", "content": "Based on the output hidden state hi, the probabilistic event de-\ncoder generates the probability distribution for the next inter-\nevent time p* (ti+1), activity category p* (ki+1|Ti+1), and location\np* (li+1 Ti+1, ki+1) in a cascading manner, where the latter distribu-\ntion depends on the samples drawn from the former distributions.\nNote that here (*) denotes the conditioning on the trajectory history,\nwhile the conditional probability emphasizes on conditioning on\ndrawn samples."}, {"title": "4.3.1 Time decoder with intensity-free TPP.", "content": "Following the\nintensity-free TPP [49], we use a mixture of log-normal distribu-\ntions to characterize the conditional probability density function\nof inter-event time p(t).\n$p(\\tau | \\omega, \\mu, \\sigma)=\\sum_{m=1}^{M} w_{m} \\frac{1}{\\tau \\sigma_{m} \\sqrt{2\\pi}} exp\\left(-\\frac{\\left(\\log \\tau-\\mu_{m}\\right)^{2}}{2 \\sigma_{m}^{2}}\\right)$ (5)\nwhere M is the number of components of the mixture, wm denotes\nthe weight of each component, \u00b5m and om are the logarithmic mean\nand standard deviation of each component."}, {"title": "4.3.2 Category decoder.", "content": "After obtaining the next inter-event\ntime ti+1, we sample an activity category. In this step, we use a\nslightly different (category) context vector c by replacing the times-\ntamp embedding tomb in the time context vector c with the em-\nbedding of the sampled next event time temb, as follows:\n$c_{k}=[h_{i}; t_{i+1}^{emb}; u_{e m b}]$  (8)\nThis is because the next activity category ki+1 is highly correlated\nwith its corresponding event time ti+1; for example, the activity\ncategory in the noon time should probably be \"food\" (one of the\nnine categories on Foursquare [70]). Then, we compute a categorical\ndistribution conditioned on the category context vector c:\n$p^{*}(k_{i+1} | t_{i+1})=\\operatorname{softmax}(M L P_{\\theta}(c_{k}))$ (9)\nwhere MLP refers to a multi-layer perception with parameters\n$ and softmax transforms its output to a categorical probability\ndistribution. We finally sample a next event category ki+1 from\np* (ki+1 Ti+1). Note that as the next event time ti+1 = ti + Tt+1 can"}, {"title": "4.3.3 Location decoder with neural EPR.", "content": "After obtaining the\nnext event time ti+1 and category ki+1, we sample the next location\nby designing a neural EPR model. Specifically, our location decoder\nfollows a two-step design. First, we sample a binary decision on\ntwo competing modes: exploration (visiting a new location that is\nnot in the trajectory history) or return (visiting a previously visited\nlocation in the trajectory history). Second, based on the sampled\nmode, we then sample a location from the corresponding candidate\nlocations of the mode. We present the detailed design below.\nExploration/Return mode sampling. In this step, we learn to\nsample one mode based on an extended context vector c, by further\nadding the embedding of the sampled next event category kemb to\nthe context vector of category encoder c:\n$c_{l} = [h_{i}; t_{i+1}^{emb}; k_{i+1}^{emb}; u_{e m b}]$ (10)\nSubsequently, we feed this context vector to an MLP followed by a\nsoftmax function, to output a distribution over the two modes of\nexplore and return:\n$p^{*}(z | t_{i+1}, k_{i+1})=\\operatorname{softmax}(M L P_{\\delta}(c_{l}))$ (11)\nFinally, we sample one mode z according to p* (z|ti+1, ki+1). Note\nthat for the first event in a trajectory sequence, the exploration\nmode is selected, because of the empty trajectory history.\nLocation sampling in the exploration mode. In the exploration\nmode z = explore, we compute a categorical distribution over all\npreviously unvisited locations, which is obtained by feeding the\nlocation context vector c to an MLP followed by a softmax function:\n$p^{*}(l_{i+1} | t_{i+1}, k_{i+1}, \\text { explore })=\\operatorname{softmax}(M L P_{\\varphi}(c_{l}))$,\nwhere l # {xj|xj \u2208 X, j < i + 1} (12)\nFrom this, we can sample a previously unvisited location l.\nLocation sampling in the return mode. In the return mode z =\nreturn, we consider the temporal periodicity of human behaviors,\nwhere individuals tend to revisit previously visited locations under\na regular temporal distance, such as returning home daily (with a\ntemporal distance of 24 hours) [52]. Therefore, the return mode is\ndesigned to imitate such revisiting behaviors. Specifically, instead of\nimposing specific constraints or predefined temporal periodicity as\n[68], we use temporal distance embeddings to learn the probability\ndistribution of returning to previously visited locations. We define\nthe temporal distance under an hour granularity between the (i+1)-\nth and j-th events as \u2206+1,j = |ti+1 \u2212 tj| \u2208 Z\u22650. Subsequently, for\nthe next event time ti+1, we obtain its temporal distances to all\nprevious events as follows:\n$\\Delta^{\\prime}=\\left[\\Delta_{i+1,1}, \\Delta_{i+1,2}, \\ldots, \\Delta_{i+1, i}\\right]$ (13)\nWe then define a learnable embedding for each hourly time distance,\nwhich is fed to an MLP followed by softmax to output the categorical\ndistribution of returning to the locations of the previous events:\n$p^{*}(l_{i+1} | t_{i+1}, \\text { return })=\\operatorname{softmax}\\left(M L P_{\\xi}\\left(\\left[\\Delta_{i+1,1}^{e m b}, \\Delta_{i+1,2}^{e m b}, \\ldots, \\Delta_{i+1, i}^{e m b}\\right]\\right)\\right)$,\nwhere l \u2208 {xj|xj \u2208 X, j < i + 1} (14)"}, {"title": "4.3.4 User VAE.", "content": "Additionally, we also train a Variational Autoen-\ncoder (VAE) to learn to generate novel individual preference embed-\ndings on trajectories, to avoid exposing the learnt user preference\nembeddings from the real dataset in the generation process. In the\nsampling stage, the trained user VAE generates individual prefer-\nence embedding from random noises."}, {"title": "4.4 Model Training and Trajectory Generation", "content": "Model Training. The training objective of MIRAGE is to min-\nimize the Negative Log Likelihood (NLL) of all sequences of events\nin a human trajectory dataset D.\n$\\mathcal{L}(D)=-\\sum_{X \\in D} \\sum_{x_{i} \\in X}\\left(\\ln p^{*}(t_{i})+\\ln p^{*}(k_{i} | t_{i})+\\ln p^{*}(l_{i} | t_{i}, k_{i})\\right)$ (16)\nIn the training process, the above conditional probability distribu-\ntion is conditioned on the real data without sampling. After training\nthis objective function, we then train the user VAE on the learnt\nindividual preference embeddings. The complexity of our model is\ndiscussed in Appendix C."}, {"title": "4.4.2 Trajectory Generation.", "content": "Our trajectory generation process\nis conducted via a series of sampling steps without any real data\nas input. Specifically, the user VAE first generates an individual\npreference embedding. Afterward, the trajectory is generated iter-\natively based on the encoded trajectory history as follows: 1) the\ntime decoder samples an inter-event time ti according to p* (ti); 2)\nthe category decoder samples an activity category ki conditioned\non ti according to p* (kilti); and 3) the location decoder samples a\nlocation li conditioned on ti and ki according to p* (li|ti, ki). Note\nthat the initial hidden state ho is learnt during training, and the\ngeneration process terminates until a desired time length."}, {"title": "5 EXPERIMENTS", "content": "We conduct extensive experiments on three user\ntrajectory datasets collected from a location-based social network\nFoursquare [70, 71], in three respective cities Tokyo (TKY), Istanbul\n(IST), and New York City (NYC). Table 1 shows the dataset statistics."}, {"title": "5.1.2 Baselines.", "content": "We consider the following state-of-the-art base-\nlines of three categories: statistical models Semi-Markov [33] and\nTimeGeo [28]; neural TPP RMTPP [9], ERTPP [64], THP [81],\nand LogNormMix [49]; deep learning generative models LSTM\n[27], SeqGAN [73], MoveSim [11], VOLUNTEER [37] and Diff-\nTraj [80]. The details of these baselines are in Appendix D."}, {"title": "5.1.3 Statistical and Distributional Similarity Metrics.", "content": "Following\nprevious works [11, 43], we adopt popular metrics to evaluate the\nresemblance between real and generated trajectories in different\naspects. Distance measures the distance between successive loca-\ntions in a trajectory. Radius of gyration is calculated as the root\nmean squared distance of all locations from the central one in a tra-\njectory. Interval is computed as time intervals between successive\nevents in a trajectory. DailyLoc computes the unique locations\nvisited by users. Category computes the overall distribution of the\nPOI categories. We utilize the Jensen-Shannon divergence (JSD)\n[13] as the similarity metric between the distributions of real and\ngenerated trajectories."}, {"title": "5.2 Task-Based Evaluation Protocol", "content": "We introduce our proposed task-based evaluation protocol to com-\nprehensively benchmark trajectory generative models. Specifically,\nthe ultimate utility of human trajectory generation is to support\ndifferent downstream tasks in practice; subsequently, the bench-\nmark objective is to evaluate whether the generated trajectories\nare similar to real trajectories when being used to conduct differ-\nent downstream tasks. In the current literature, existing works\nall use heuristically designed downstream tasks with one specific\ntechnique to solve a task [7, 11, 29, 37, 76], and thus lack a com-\nprehensive view of utility benchmarks. In particular, heuristically\ndesigned downstream tasks may lead to unknown biases in the util-\nity evaluation, as the performance of different techniques solving\nthe same task often varies (as evidenced by our experiments in Ap-\npendix A), and heuristically regarding the results of one technique\nas the benchmark is thus untrustworthy.\nOur proposed evaluation protocol implements four typical tasks:\nlocation recommendation, next location prediction, semantic loca-\ntion labeling, and epidemic simulation, which model user trajec-\ntory data in four aspects, user preferences on locations, sequential\nmobility patterns, collective traffic patterns, and spatiotemporal\ncontact patterns, respectively. For each task, we choose multiple\nstate-of-the-art techniques to conduct experiments and report the\nresults on multiple metrics, to average out the biases of individual\ntechniques and metrics. We then measure the paired performance\ndiscrepancy between the real and generated trajectories using Mean\nAbsolute Percentage Error (MAPE) and Mean Squared Percentage\nError (MSPE), which serve as final benchmarks to assess the ulti-\nmate utility of the generated trajectories. In the following, we first\npresent our dataset settings, followed by the details of each task."}, {"title": "5.2.1 Dataset Settings.", "content": "Unlike some previous works [29, 37, 76]\nthat use the generated trajectories to augment the real trajectories\n(combining generated and real data in certain proportions) and\nthen perform the downstream tasks, we put one step forward to\ndirectly perform the tasks on the generated trajectories only, with-\nout exposing any real trajectories. Our dataset setting is more strict"}, {"title": "5.2.2 Location Recommendation Task.", "content": "(LocRec) suggests new (pre-\nviously unvisited) locations for users by modeling user preferences\non locations from trajectory data [72]. Following the default setting\nof [77], we transform a trajectory dataset into a set of (user, loca-\ntion, visit_count) triplets and then split them into training/valid/test\ndatasets under a ratio of 8:1:1. To discount the impact of the specific\ntechniques and metrics, we consider five popular recommenda-\ntion algorithms, i.e., BPR [46], DMF [67], LightGCN [22], MultiVAE\n[35], and NeuMF [23] (details in Appendix E), and report their per-\nformance on Mean Reciprocal Rank@N (MRR@N), Normalized\nDiscounted Cumulative Gain@N (NDCG@N), hit@N (where N = 5\nand 10). Finally, we compare the paired performance discrepancy\nbetween the real and generated trajectories (i.e., 30 paired results\nfrom five algorithms and six metrics each) using MAPE and MSPE."}, {"title": "5.2.3 Next Location Prediction Task.", "content": "(NexLoc) forecasts a user's\nnext location in the future by learning the sequential mobility pat-\nterns from historical user trajectories [41]. Specifically, for one\ndataset, we chronologically split each trajectory into training/valid/test"}, {"title": "5.2.4 Semantic Location Labeling Task.", "content": "(SemLoc) assigns a seman-\ntic label (i.e., activity category) to a location based on the collective\ntraffic pattern of the location, extracted from users' trajectory data\n[69]. Specifically, for each location, we extract its weekly temporal\ntraffic pattern with an hour granularity, resulting in a feature vector\nof size 168 where each entry represents the empirical probability\nof all users' visits to this location. For each trajectory dataset, we\nthen split all POIs into training/valid/test datasets under a ratio of\n8:1:1. As a classification problem in nature, we consider five typical\nclassification algorithms, i.e., Decision Tree, Naive Bayes, K-Nearest\nNeighbors, Logistic Regression, and Support Vector Machine, and\nreport their performance on Accuracy, F1-Micro, and F1-Macro\nscores. Finally, we compare the performance discrepancy between\nthe real and generated trajectories using MAPE and MSPE."}, {"title": "5.2.5 Epidemic Simulation Task.", "content": "(EpiSim) simulates the epidemic\nspreading over a contact network characterizing the spatiotemporal\ncontact patterns of user trajectories [59]. The contact network is\nextracted from a trajectory dataset as a dynamic graph of users,\nand a directed edge from a user p to a user q represents that p's"}, {"title": "5.3 Statistical & Distributional Similarity", "content": "Table 2 shows the performance comparison of MIRAGE and base-\nlines on the three datasets. We observe that MIRAGE consistently\nachieves the best performance with the lowest JSD, yielding 59.0%,\n68.9%, and 71.5% improvement (reduction on JSD) over the best-performing baselines on TKY, IST, and NYC datasets, respectively.\nHowever, even though we selected four similarity metrics covering\nthree different aspects of spatial (Distance and Radius), temporal\n(Interval), and user (DailyLoc) distributions, these metrics cannot\nfully reflect the ultimate utility of generated trajectories in support-\ning downstream tasks. For example, the consistent superiority of\nMIRAGE over baselines on these similarity metrics is still biased,\nbecause MIRAGE indeed underperforms some baselines in a few\ncases in our task-based evaluation, as we discuss below."}, {"title": "5.4 Task-Based Evaluation Performance", "content": "Table 3 shows the performance in our proposed task-based evalu-\nation on MAPE (similar results on MSPE, shown in Appendix H).\nEach entry in this Table is the MAPE averaging over all metrics of\nall algorithms solving a task on a dataset, to average out the biases\nof individual techniques and metrics. For example, the MAPE of\nMIRAGE in the LocRec task on the TKY dataset is 0.3485, which\nis computed from 30 paired (real and generated) results from five\nalgorithms and six metrics used in the LocRec task.\nWe observe that MIRAGE achieves the best performance with\nthe smallest MAPE in most cases. In general, compared to the\nbest-performing baselines, our MIRAGE achieves 10.9%, 16.7%, and\n33.4% improvement on TKY, IST, and NYC datasets, respectively. In"}, {"title": "5.5 Ablation Study", "content": "We conduct an ablation study on our proposed method MIRAGE,\nconsidering the following two variants. MIRAGE-noTPP is a vari-\nant of MIRAGE without the neural TPP, where we define a regres-\nsion task to predict the next inter-event from the time context\nvector c. MIRAGE-noEPR is a variant of MIRAGE without neu-\nral EPR, where we directly sample a location from a categorical\ndistribution conditioned on the location context vector c. Tables 4\nand 5 show the results on similarities and task-based evaluation on\nMAPE, respectively (similar results on MSPE in Appendix H).\nWe observe that MIRAGE consistently outperforms MIRAGE-\nnoTPP on both similarities and task-based evaluation by 63.8% and\n31.2% (on average over tasks and datasets), respectively, showing\nthe effectiveness of neural TPPs modeling the event stochasticity\nof human trajectories. Second, MIRAGE outperforms MIRAGE-\nnoEPR in most cases, with an improvement of 50.3% and 19.2% on\nsimilarities and task-based evaluation, respectively, which verifies\nthe usefulness of our neural EPR model. In addition, to further\nshow the utility of the EPR model, we plot the empirical returning\nprobability of users over time, which is defined as the probability of\na user returning to a location a certain period (temporal distance)\nafter the user's first presence at the location [16, 68]. Figure 2\nshows the plots of both real and generated data on NYC. We see\nthat the real trajectory exhibits strong periodicity, which can be\nwell imitated by MIRAGE but not by MIRAGE-noEPR. The plots\nfor baselines are also available in Appendix I. The superiority of\nMIRAGE is also validated on the return probability over sequence\nlengths in Appendix J."}, {"title": "6 CONCLUSIONS AND FUTURE WORKS", "content": "In this paper, by revisiting the existing human trajectory generative\nmodels, we identify their limitations in focusing on the summary\nstatistics and distributional similarities between real and generated\ntrajectories, which could lead to intrinsic biases in both genera-\ntive model design and benchmarks of the generated trajectories.\nAgainst this background, we propose MIRAGE, a huMan-Imitative\ntRAjectory GenErative model designed as an intensity-free neural\nTemporal Point Process integrating a neural Exploration and Prefer-\nential Return model to imitate the human decision-making process\nin trajectory generation. Meanwhile, we also propose a comprehen-\nsive task-based evaluation protocol to systematically benchmark\ntrajectory generative models on four typical downstream tasks,\nintegrating multiple techniques and evaluation metrics for each\ntask, to assess the ultimate utility of the generated trajectories. The\nevaluation results show that MIRAGE-generated trajectory data\nnot only achieves the best statistical and distributional similarities\nwith 59.0-71.5% improvement but also yields the best performance\nin the task-based evaluation with 10.9-33.4% improvement."}]}