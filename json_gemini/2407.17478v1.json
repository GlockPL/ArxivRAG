{"title": "LLM4PM: A case study on using Large Language Models for Process Modeling in Enterprise Organizations", "authors": ["Clara Ziche", "Giovanni Apruzzese"], "abstract": "We investigate the potential of using Large Language Models (LLM) to support process model creation in organizational contexts. Specifically, we carry out a case study wherein we develop and test an LLM-based chatbot, PRODIGY (PROcess moDellIng Guidance for You), in a multinational company, the Hilti Group. We are particularly interested in understanding how LLM can aid (human) modellers in creating process flow diagrams. To this purpose, we first conduct a preliminary user study (n=10) with professional process modellers from Hilti, inquiring for various pain-points they encounter in their daily routines. Then, we use their responses to design and implement PRODIGY. Finally, we evaluate PRODIGY by letting our user study's participants use PRODIGY, and then ask for their opinion on the pros and cons of PRODIGY. We coalesce our results in actionable takeaways. Through our research, we showcase the first practical application of LLM for process modelling in the real world, shedding light on how industries can leverage LLM to enhance their Business Process Management activities.", "sections": [{"title": "Introduction", "content": "Organizations perform business processes to deliver value-adding outcomes to their customers. Hence, Business Process Management (BPM) capabilities, such as process modeling, are a pivotal task in modern enterprises [3]. However, despite decades of efforts [7], process modeling still remains a costly activity due to, e.g., the difficulty of providing clear, up-to-date and easy-to-retrieve documentation [3] to those tasked to carry out such activities\u2014the process modelers. Inspired by recent developments in artificial intelligence (AI), such as large language models (LLM), researchers have proposed various techniques that can facilitate BPM-related tasks (e.g., [6]). Indeed, LLM can elaborate large collections of documents. Hence, by receiving an input from a given user, LLM can quickly produce an output that (i) accounts for existing documentation, while simultaneously (ii) answering the request of the user-i.e., a human. Yet, we found no evidence of practical applications of LLM for BPM in real contexts and, in particular, for process modeling. Hence, there is a need to investigate the effectiveness of such automation in industry [15]. Here, we tackle this challenge and showcase how a large enterprise, Hilti, can benefit from a LLM-powered chatbot which we developed ad-hoc for Hilti for BPM."}, {"title": "Organizational Context and Problem Statement", "content": "Our case organization, Hilti Group, is a multinational company that was founded in 1941 in Schaan, Liechtenstein. It is a world market leader in fastening and demolition technology for construction professionals and provides tools, technologies, software and services to the global construction industry. In 2023, Hilti's workforce consists of about 33.000 employees in more than 120 countries, making it a highly diverse, distributed organization that operates in complex and competitive markets all over the world. The size, complexity and business model of Hilti make it an ideal use case for testing the capabilities of LLM for process modeling: BPM is essential to ensure cooperation and consistent outcomes within Hilti's ecosystem; furthermore, it is crucial for Hilti to optimize customer-facing processes. Hence, a smooth process modelling is pivotal for Hilti."}, {"title": "Research and Methods", "content": "Inspired by Peffers et al. [14], we followed a Design Science Research (DSR) process consisting of four phases depicted in Fig. 2.1 DSR is appropriate given our goal of examining LLMs for process modelling in organizations, as DSR emphasizes the creation of innovative solutions (in our case, PRODIGY) while also considering the context in which these solutions will be applied.\nBackground: DSR is a methodology that focuses on creating and evaluating artifacts to solve complex problems. Such procedure is rooted on the coming together of people, organizations and technology, with the ultimate intention of \"extending the boundaries of human and organizational capabilities\" [8]."}, {"title": "Artifact Definition", "content": "As a preliminary step, we carried out a systematic literature review [20] which we used as a foundation to investigate the state of the art and define the scope"}, {"title": "Artifact Implementation", "content": "We use the results of our interviews alongside those of our investigation of the state of the art to define the requirements of our technical artifact, i.e., the LLM-based chatbot PRODIGY. To develop PRODIGY, we rely on Botpress, a platform to build custom AI chatbots powered by GPT-based LLMs; for our prototype version of PRODIGY, we used GPT-3.5 Turbo, which we found provided satisfactory performance while also requiring less resources to generate an output.\nA crucial aspect of PRODIGY is its reliance on the BPMN Sketch Miner tool [10]. The syntax for this tool is entirely text-based, human-readable and light in terms of token consumption, making it appropriate for our case study. Therefore, we use few-shot prompting to teach PRODIGY to provide an output that matches the format expected by BPMN Sketch Miner. This output serves as the input for the model generation and transformation pipeline of BPMN Sketch Miner [9]. Such a design choice enables users of PRODIGY to directly paste the AI outputs into the online tool and get their model visualized (see Fig. 1).\nFurthermore, we have leveraged retrieval-augmented generation (RAG) [13] to embed Hilti's documentation into PRODIGY. Such documentation included: process descriptions from Hilti's internal documentation repository (anonymised); and information about Hilti's process management, and how to model processes"}, {"title": "Artifact Evaluation", "content": "We conducted a user study with our artifact and process modellers. Our aim was to answer evaluative questions on the quality of PRODIGY for Hilti.\nFirst, the process modellers tested all functionalities of PRODIGY by creating custom prompts, with the intention of simulating their routine tasks. Their inputs and the corresponding AI-generated outputs are fully observable in our repository [1]. Then, we carried out semi-structured interviews during which the participants answered 28 questions. Among these, we ask to give an 1-5 rating to the statement \"Using PRODIGY would make it easier for me to do process modeling tasks.\" The complete questionnaire is provided in our repository [1]."}, {"title": "Dissemination and Communication of the Results", "content": "To conclude our DSR process, we formalized our learnings and made them accessible to interested parties. We documented our observations, analyzed our findings, identified lessons learned, stated limitations, and recommended directions for future work. We shared our learnings within Hilti Group and the wider BPM community in academia and practice some companies reached out to us and expressed their interest about the development process of PRODIGY."}, {"title": "Key Findings and Lessons Learned", "content": "We first summarise the major results of our user studies, and then outline our proposed \"operating model\" for our developed LLM-based chatbot, PRODIGY.\nConfidentiality Statement: To protect the privacy of the participants to our user studies, we cannot reveal the full transcript of their interviews. However, we are able to answer questions about their generic viewpoint on some specific issues."}, {"title": "Preliminary Interviews: what do Hilti process modellers want?", "content": "These open interviews lasted for 60 minutes, and the results shed light on the pain-points and desiderata of our participants. We found that, before modelling a process, 60% spend between 15-60 minutes searching for documentation; and also 60% spend between 5-60 minutes to review such documentation. As a matter of fact, 90% state that it is \"extremely important\" that an LLM-based chatbot has access to Hilti's documentation; however, we also found that, on a 1-10 rating (low to high) scale, the average usefullness of current Hilti's documentation is 6.7-indicating helpfulness, but with huge margins for improvement. Nonetheless, with respect to AI-related concerns, some stated that \"humans may misinterpret the AI's outputs\" or \"AI may negatively impact collaboration with colleagues\" or even about accountability (\u201cthe mindset that [the machine] does everything and we no longer have to worry about it is dangerous\")."}, {"title": "Evaluation: what do Hilti process modellers say about PRODIGY?", "content": "After letting our process modellers use PRODIGY, we collected their feedback via 90-minutes long semi-structured interviews; one participant to the preliminary interviews did not provide feedback since they were not available, so we obtained responses from nine employees. The general opinion was positive. Five of our participants asserted that they would use PRODIGY on a daily or weekly basis (i.e., whenever they have to carry out process-modeling duties). Moreover, six participants asserted that PRODIGY would speed-up their tasks (three remained neutral), and eight believe that PRODIGY makes their tasks easier (one remained neutral). Finally, we report in Fig. 3 the participants' perception on the functionalities we integrated in PRODIGY, showing great appreciation."}, {"title": "Operating model: how should PRODIGY be used in practice?", "content": "During our implementation, we devised an operating model that describes how PRODIGY should be leveraged by real organizations; we have further refined our model (shown in Fig. 4) after receiving the feedback by our interviewees."}, {"title": "Significance and Relevance in Research and Practice", "content": "Besides our key findings we underscore three orthogonal aspects of our research.\nThe perspective of process modellers in organizations. We coalesce the responses not pertaining to AI of our preliminary interviews, and derive an original framework representing dynamics of process modellers' issues at Hilti. This is instructive because, during our literature analysis, we found some works mentioning pitfalls of process modeling (e.g., [16]) but without accounting for context. Our framework (displayed in Fig. 5, and described in the caption of Fig. 5) attempts to rectify this shortcoming, providing guidance for future work.\nEvaluating LLM-/AI-based solutions. Upon further analysing the results of our evaluation interview, we have found that the reception of PRODIGY by our process modellers was highly dependant on their expectations and overall attitude towards AI and IT innovation. Indeed, some participants had \"lower expectations\" and provided prompts that were \"more aligned\" to the expected"}, {"title": "Discussion: Scope and Limitations", "content": "We showcased an exemplary application of an LLM-based chatbot that can assist process modellers in a large organization, Hilti. In doing so, we have carried out a twofold user study with 10 employees of Hilti, and developed an original artifact, PRODIGY. Our research has a number of limitations. For instance, we do not claim that our findings can apply to other organizations\u2014irrespective of their similarity to Hilti. Moreover, we cannot claim that even our own findings can apply to the entirety of Hilti: The participants of our user study are mostly based in Liechtenstein, and therefore cover the global headquarters perspective rather than regional and local perspectives. Furthermore, PRODIGY uses GPT-3.5 Turbo (which is not privacy-compliant), and it relies on BPMN Sketch Miner: if such a tool is taken down, the output of PRODIGY may lose its immediate usefulness. Finally, even our own participants have pointed out some shortcomings of PRODIGY, such as a poor \"knowledge\" of Hilti's documentation. Such a result, however, was expected: the documents that PRODIGY has access to (with RAG) are just a drop in the deluge of files and logs included in Hilti's databases (and we, as researchers, do not have complete access to such data)."}, {"title": "Conclusions", "content": "We have presented the first case study showcasing how LLM can be used for process modeling in large enterprises\u2014specifically, Hilti Group. We follow DSR guidelines and develop an original LLM-based chatbot, PRODIGY, which we test with professional process modellers from Hilti. Our findings revealed that end-users appreciate the functionalities of PRODIGY. However, concerns were raised about the poor alignment of PRODIGY's output with Hilti's specifications. Such a shortcoming underscores the importance of integrating LLM-based solutions with the organization's documentation-which is a task outside the responsibilities of process modellers. Hence, deployment of similar solutions in real contexts should be done with the support of the organization's governance team: it is unrealistic to expect that \"off the shelf\" solutions work properly to drive the process modeling routines of complex and large organizations (see Fig. 6)."}]}