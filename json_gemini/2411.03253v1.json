{"title": "DISCOVERING DATA STRUCTURES: NEAREST NEIGHBOR SEARCH AND BEYOND", "authors": ["Omar Salemohamed", "Laurent Charlin", "Shivam Garg", "Vatsal Sharan", "Gregory Valiant"], "abstract": "We propose a general framework for end-to-end learning of data structures. Our framework adapts to the underlying data distribution and provides fine-grained control over query and space complexity. Crucially, the data structure is learned from scratch, and does not require careful initialization or seeding with candidate data structures. We first apply this framework to the problem of nearest neighbor search. In several settings, we are able to reverse-engineer the learned data structures and query algorithms. For 1D nearest neighbor search, the model discovers optimal distribution (in)dependent algorithms such as binary search and variants of interpolation search. In higher dimensions, the model learns solutions that resemble k-d trees in some regimes, while in others, elements of locality-sensitive hashing emerge. Additionally, the model learns useful representations of high-dimensional data and exploits them to design effective data structures. We also adapt our framework to the problem of estimating frequencies over a data stream, and believe it could be a powerful discovery tool for new problems.", "sections": [{"title": "INTRODUCTION", "content": "Can deep learning models be trained to discover data structures from scratch?\nThere are several motivations for this question. The first is scientific. Deep learning models are increasingly performing tasks once considered exclusive to humans, from image recognition and mastering the game of Go to engaging in natural language conversations. Designing data structures and algorithms, along with solving complex math problems, are particularly challenging tasks. They require searching through a vast combinatorial space with a difficult to define structure. It is therefore natural to ask what it would take for deep learning models to solve such problems. There are already promising signs: these models have discovered fast matrix-multiplication algorithms (Fawzi et al., 2022), solved SAT problems (Selsam et al., 2018), and learned optimization algorithms for various learning tasks (Garg et al., 2022; Aky\u00fcrek et al., 2022; Fu et al., 2023; Von Oswald et al., 2023). In this work, we investigate the problem of data structure discovery, with a focus on nearest neighbor search.\nThe second motivation is practical. Data structures are ubiquitous objects that enable efficient querying. Traditionally, they have been designed to be worst-case optimal and therefore agnostic to the underlying data and query distributions. However, in many applications there are patterns in these distributions that can be exploited to design more efficient data structures. This has motivated recent work on learning-augmented data structures which leverages knowledge of the data distribution to modify existing data structures with predictions (Lykouris & Vassilvitskii, 2018; Ding et al., 2020; Lin et al., 2022a; Mitzenmacher & Vassilvitskii, 2022). In much of this work, the goal of the learning algorithm is to learn distributional properties of the data, while the underlying query algorithm/data structure is hand-designed. Though this line of work clearly demonstrates the potential of leveraging distributional information, it still relies on expert knowledge to incorporate learning into such structures. In our work, we ask if it is possible to go one step further and let deep learning models discover entire data structures and query algorithms in an end-to-end manner."}, {"title": "1.1 FRAMEWORK FOR DATA STRUCTURE DISCOVERY", "content": ""}, {"title": "1.2 SUMMARY OF RESULTS", "content": "We apply this framework to the problem of nearest neighbor (NN) search in both low and high dimensions. Given the extensive theoretical work on this topic, along with its widespread practical applications, NN search is an ideal starting point for understanding the landscape of end-to-end data structure discovery. Beyond NN search, we explore the problem of frequency estimation in streaming data and discuss other potential applications of this framework. Our findings are:"}, {"title": "2 NEAREST NEIGHBOR SEARCH", "content": "Given a dataset $D = {x_1,...,x_N}$ of N points where $x_i \u2208 R^d$ and a query $q \u2208 R^d$, the nearest neighbor $y$ of $q$ is defined as $y = arg min_{x_i\u2208D} dist(x_i,q)$. We mostly focus on the case where $dist(\u00b7)$ corresponds to the Euclidean distance. Our objective is to learn a data structure $D$ for $D$ such that given $q$ and a budget of $M$ lookups, we can output a (approximate) nearest neighbor of $q$ by querying at most $M$ elements in $D$. When $M > N$, $y$ can be trivially recovered via linear search so $D = D$ is sufficient. Instead, we are interested in the case when $M \u226a N$."}, {"title": "2.1 SETUP", "content": "Data-processing Network Recall that the role of the data-processing network is to transform a raw dataset into a data structure. The backbone of our data-processing network is an 8-layer transformer model based on the NanoGPT architecture (Karpathy, 2024). In the case of NN search, we want the data structure to preserve the original inputs and just reorder them appropriately as the answer to the nearest neighbor query should be one of elements in the dataset. The model achieves this by outputting a rank associated with each element in the dataset, which is then used to reorder the elements. More precisely, the transformer takes as input the dataset $D$ and outputs a scalar $o_i \u2208 R$ representing the rank for each point $x_i \u2208 D$. These rankings ${o_1,..., o_N}$ are then sorted using a differentiable sort function, $sort({o_1, o_2 . . ., o_N })$ (Grover et al., 2019; Cuturi et al., 2019; Petersen et al., 2022), which produces a permutation matrix $P$ that encodes the order based on the rankings. By applying $P$ to the input dataset $D$, we obtain $D_p$, where the input data points are arranged in order of their rankings. By learning to rank rather than directly outputting the $log(N)$ lookups given a sorted list."}, {"title": "Query Execution Network", "content": "The role of the query-execution network is to output a (approximate) nearest-neighbor of some query $q$ given a budget of $M$ lookups into the data structure $D$. The query-execution network consists of $M$ MLP query models $Q^1, ..., Q^M$. The query models do not share weights. Each query model $Q^i$ outputs a one-hot vector $m_i \u2208 R^{N+T}$ which represents a lookup position in $D$. To execute the lookup, we compute the value $v_i$ at the position denoted by $m_i$ in $D$ as $v_i = m_i^T D$. In addition to the query $q$, each query model $Q^i$ also takes as input the query execution history $H_i = {(M_1, V_1), ..., (M_{i-1}, V_{i-1})}$ where $H_1 = 0$. The final answer of the network for the nearest-neighbor query is given by $\u0177 = m_i^T D$.\nTo restrict our model to exactly $M$ lookups, we enforce each lookup vector $m_i$ to be a one-hot vector. Enforcing this constraint during training poses a challenge as it is a non-differentiable operation. Instead, during training, our model outputs soft-lookups where $m_i$ is the output of the softmax function and $\u2211_j m_{ij} = 1$. This alone, however, leads to non-sparse queries. To address this, we add noise to the logits before the softmax operation (only during training). This regularizes the query network, encouraging it to produce sparser solutions (see App C.1 for details as to why this occurs). Intuitively, the network learns a function that is robust to noise, and the softmax output becomes robust when the logits are well-separated. Well-separated logits, in turn, lead to sparser solutions. At inference time, we do not add this noise and we ensure the lookup vector $m_i$ is a one-hot vector by applying a hardmax function to the network output instead of a softmax."}, {"title": "Data Generation and Training", "content": "Each training example is a tuple ($D, q, y$) consisting of a dataset $D$, query $q$, and nearest neighbor $y$ generated as follows: (i) sample dataset $D = {x_1,..., x_N }$ from dataset distribution $P_D$, (ii) sample query $q$ from query distribution $P_q$, (iii) compute nearest neighbor $y = arg min_{x_i\u2208D} dist(x_i \u2013 q)$. Unless otherwise specified, dist corresponds to the Euclidean distance. The dataset and query distributions $P_D, P_q$ vary across the different settings we consider and are defined later. Given a training example ($D, q, y$), the data-processing network transforms $D$ into the data structure $D$. Subsequently, the query-execution network, conditioned on $q$, queries the data structure to output $\u0177$. We use SGD to minimize either the squared loss between $y$ and $\u0177$, or the cross-entropy loss between the corresponding vectors encoding their positions. This is an empirical choice, and in some settings one loss function performs better than the other. All models are trained for at most 4 million gradient steps with early-stopping using a batch size of 1024. After training, we test our model on 10k inputs ($D, q, y$) generated in the same way. We describe the exact model architecture and training hyper-parameters in App A.1."}, {"title": "Evaluation and Baselines", "content": "We evaluate our end-to-end model (referred to as E2E) on one-dimensional, two-dimensional, and high-dimensional nearest-neighbor problems. We primarily focus on data structures that do not use extra space, but in Section 2.5, we also explore scenarios with additional space.\nWe compare against suitable NN data structures in each setting (e.g., sorting followed by binary search in 1D), and also against several ablations to study the impact of various model components. The E2E (frozen) model does not train the data-processing network, relying on rankings generated by the initial weights. The E2E (no-permute) model removes the permutation component of the data-processing network so that the transformer has to learn to transform the data points directly. The E2E (non-adaptive) model ablation conditions each query model $Q^i$ on only the query $q$ and not the query history $H_i$. From the $M$ query models, we select the prediction that is closest to the query as the final prediction $\u0177$."}, {"title": "Sorting and searching in 1D (Section 2.2)", "content": "For 1D nearest neighbor search, the data-processing network learns to sort, while the query network simultaneously learns to search over the sorted data. When the data follows a uniform or Zipfian distribution, the query network exploits this structure to outperform binary search. On harder distributions lacking structure, the network adapts by discovering binary search, which is worst-case optimal. Importantly, the model discovers that sorting followed by the appropriate search algorithm is effective for NN search in 1D without explicit supervision for these primitives."}, {"title": "K-d trees in 2D (Section 2.3)", "content": "In 2D, when the data is drawn from a uniform distribution, the model discovers a data structure that outperforms k-d trees. On harder distributions, the learned data structure shows surprising resemblance to a k-d tree. This is striking as a k-d tree is a non-trivial data structure, constructed by recursively partitioning the data and finding the median along alternating dimensions."}, {"title": "Useful representations in high dimensions (Section 2.4)", "content": "For high-dimensional data, the model learns representations that make NN search efficient. For example, with data from a uniform distribution on a 30-dimensional hypersphere, the model partitions the space by projecting onto a pair of vectors, similar to locality-sensitive hashing. When trained on an extended 3-digit MNIST dataset, the model finds features that capture the relative ordering of the digits, sorts the images using these features, and performs a search on the sorted images-all of which is learned jointly from scratch."}, {"title": "Trading off space and query efficiency (Section 2.5)", "content": "An ideal data structure can use extra space to improve query efficiency by storing additional statistics. The learned model demonstrates this behavior, with performance improving monotonically as more space is provided, in both low and high dimensions. Thus, the model learns to effectively trade off space for query efficiency."}, {"title": "Beyond nearest neighbor search (Section 3)", "content": "We also explore the classical problem of frequency estimation, where a memory-constrained model observes a stream of items and must approximate the frequency of a query item. The learned structure exploits the underlying data distribution to outperform baselines like CountMin sketch, demonstrating the broader applicability of the framework beyond nearest neighbor search."}, {"title": "2.2 ONE-DIMENSIONAL DATA", "content": "Uniform Distribution We consider a setting where the data distribution $P_D$ and query distribution $P_q$ correspond to the uniform distribution over (-1,1), N = 100 and M = 7. We plot the accuracy, which refers to zero-one loss in identifying the nearest neighbor, after each lookup in Figure 2 (Left). Recall that $v_i$ corresponds to the output of the i-th lookup. Let $v$ denote the closest element to the query so far: $v^* = arg min_{v\u2208 {v_1,..., v_i}} ||v \u2013 q||_2$. At each lookup index we plot the nearest neighbor accuracy corresponding to $v^*$. We do this for all the methods.\nA key component in being able to do NN search in 1D is sorting. We observe that the trained model does indeed learn to sort. We verify this by measuring the fraction of inputs that are mapped to the correct position in the sorted order, averaged over multiple datasets. The trained model correctly positions approximately 99.5% of the inputs. This is interesting as the model never received explicit feedback to sort the inputs and figured it out in the end-to-end training. The separate sorting function aids the process, but the model still has to learn to output the correct rankings.\nThe second key component is the ability to search over the sorted inputs. Here, our model learns a search algorithm that outperforms binary search, which is designed for the worst case. This is because unlike binary search, our model exploits knowledge of the data distribution to start its search closer to the nearest neighbor, similar to interpolation search (Peterson, 1957). For instance, if the query $q \u2248 1$, the model begins its search near the end of the list (Figure 2 (Center)). The minor sorting error (~ 0.5%) our model makes likely explains its worse performance on the final query.\nTo understand the relevance of different model components, we compare against various ablations. The E2E (frozen) model (untrained transformer) positions only about 9% of inputs correctly, explaining its under-performance. This shows that the transformer must learn to rank the inputs, and that merely using a separate function for sorting the transformer output is insufficient. The E2E (non-adaptive) baseline, lacking query history access, underperforms as it fails to learn adaptive solutions crucial for 1D NN search. The E2E (no-permute) ablation does not fully retain inputs and so we do not measure accuracy for this baseline. We verify this by measuring the average minimum distance between each of the transformer's inputs to its outputs. These ablations highlight the crucial role of both learned orderings and query adaptivity for our model."}, {"title": "Zipfian Distribution", "content": "Prior work has shown that several real-world query distributions follow a Zipfian trend whereby a few elements are queried far more frequently than others, leading to the development of learning-augmented algorithms aimed at exploiting this (Lin et al., 2022b). We consider a setting where $P_D$ is the discrete uniform distribution over {1, ..., 200} and $P_q$ is a Zipfian distribution over {1, ..., 200} skewed towards smaller numbers such that the number i is sampled with probability proportional to $i^{\u2212\u03b1}$. We set \u03b1 = 1.2. Again, in this setting N = 100 and M = 7."}, {"title": "Hard Distribution", "content": "To verify that our model can also learn worst-case optimal algorithms such as binary search, we set $P_D$ to be a \"hard\" distribution, with the property that for any given query there does not exist a strong prior over the position of its nearest neighbor in the sorted data (see App. B.1 for more details). To produce a problem instance, we first sample a dataset from $P_D$. We then generate the query by sampling a point (uniformly at random) from this dataset, and adding standard Gaussian noise to it. The hard distribution generates numbers at several scales, and this makes it challenging to train the model with larger N. Thus, we use N = 15 and M = 3. In general, we find that training models is easier when there is more structure in the distribution to be exploited.\nThe model does indeed discover a search algorithm similar to binary search. In Figure 2 (Right), we show a representative example of the model's search behavior, resembling binary search (see Figure 16 for more examples). The error curve in Figure 14 also closely matches that of binary search.\nIn summary, in all the above settings, starting from scratch, the data-processing network discovers that the optimal way to arrange the data is in sorted order. Simultaneously, the query-execution network learns to efficiently query this sorted data, leveraging the properties of the data distribution."}, {"title": "2.3 TWO-DIMENSIONAL DATA", "content": "Beyond one dimension it is less clear how to optimally represent a collection of points as there is no canonical notion of sorting along multiple dimensions. In fact, we observe in these experiments that different data/query distributions lead to altogether different data structures. This reinforces the value in learning both the data structure and query algorithm together end-to-end.\nUniform Distribution We use a setup similar to 1D, sampling both coordinates independently from the uniform distribution on (-1,1). We set N = 100 and M = 6, and compare to a k-d tree baseline. A k-d tree is a binary tree for organizing points in k-dimensional space, with each node splitting the space along one of the k axes, cycling through the axes at each tree level. Here, our E2E model achieves an accuracy of 75% vs 52% for the k-d tree (Fig. 10 in App. B). The model outperforms the k-d tree as it can exploit distributional information. By studying the permutations, we find that our model learns to put points that are close together in the 2D plane next to each other in the permuted order (see Fig. 4 for an example).\nHard Distribution We also consider the case where we sample both coordinates independently from the hard distribution considered in the 1D setup (see Figure 17 for the corresponding error curve). We observe that the data structure learned by our model is surprisingly similar to a k-d tree (see Fig 5). This is striking as a k-d tree is a non-trivial data structure, requiring recursively partitioning the data and finding the median along alternating dimensions at each level of the tree."}, {"title": "2.4 HIGH-DIMENSIONAL DATA", "content": "High-dimensional NN search poses a challenge for traditional low-dimensional algorithms due to the curse of dimensionality. K-d trees, for instance, can require an exponential number of queries in high dimensions (Kleinberg, 1997). This has led to the development of approximate NN search methods such as locality sensitive hashing (LSH) which have a milder dependence on d (Andoni et al., 2018), relying on hash functions that map closer points in the space to the same hash bucket.\nWe train our model on datasets uniformly sampled from the d-dimensional unit hypersphere. The query is sampled to have a fixed inner-product \u03c1\u2208 [0,1] with a dataset point. When p = 1, the query matches a data point, making regular hashing-based methods sufficient. For p < 1, LSH-based solutions are competitive. We train our model for p = 0.8 and compare it to an LSH baseline when N = 100, M = 6, and d = 30. The LSH baseline partitions $R^{30}$ using K random vectors and buckets each point in the dataset according to its signed projection onto each of the K vectors. To retrieve the nearest neighbor of a query point, the baseline maps the query vector to its corresponding bucket and selects the closest vector among M candidates (refer App D for more details)."}, {"title": "Learning useful representations", "content": "High-dimensional data often contains low-dimensional structure, such as data lying on a manifold, which can be leveraged to improve the efficiency of NN search. ML models are particularly well-suited to exploit these structures. Here, we explore whether our end-to-end learning framework can learn representations that capture such structures. This is a challenging task as it involves jointly optimizing the learned representation, data structure, and query algorithm.\nWe consider the following task: given a dataset of distinct 3-digit handwritten number images, and a query image, find its nearest neighbor in the dataset, which corresponds to the image encoding the closest number to the query image (i.e., nearest is defined over the label space).\nWe generate images of 3-digit numbers by concatenating digits from MNIST (see Figure 13 for image samples). To construct a nearest-neighbor dataset D, we sample N = 50 labels (each label corresponds to a number) uniformly from 0 to 199. For each label, we then sample one of its associated training images from 3-digit MNIST. Additionally, we sample a query label (uniformly over {0, .., 199}) and its corresponding training image and find its nearest neighbor in D, which corresponds to the image with the same label. We emphasize that the model has no label supervision but rather only has access to the query's nearest neighbor. After training, we evaluate the model using the same data generation process but with images sampled from the 3-digit MNIST test set.\nAs both the data-processing and query-execution networks should operate over the same low-dimensional representation we train a CNN feature model $F_\u00a2$ as well. Our setup remains the same as before except now the data-processing network and query-execution network operate on {$F_\u00a2(x_1), ..., F_\u00a2(x_n)$} and $F_\u00a2(q)$, respectively. As the underlying distance metric does not correspond to the Euclidean distance, we minimize the cross-entropy loss instead of the MSE loss. Note that the cross-entropy loss only requires supervision about the nearest neighbor of the query, and does not require the exact metric structure, so it can be used even where the exact metric structure is unknown."}, {"title": "2.5 LEVERAGING EXTRA SPACE", "content": "The previous experiments demonstrate our model's ability to learn useful orderings for efficient querying. However, data structures can also store additional pre-computed information to speed up querying. For instance, with infinite extra space, a data structure could store the nearest neighbor for every possible query, enabling O(1) search. Here, we evaluate if our model can effectively use extra space.\nWe run an experiment where the data and query distribution are uniform over (-1,1) with N = 50, M = 2. We allow the data-processing network to output T\u2208 {0, 21, 22, 23, 24, 25, 26, 27} numbers $b_1,..., b_T \u2208 R$ in addition to the N rankings. We plot the NN accuracy as a function of T in Figure 6 (Right) compared to a simple bucketing baseline. This baseline partitions [-1,1] into T evenly-sized buckets and in each bucket stores $arg min_{xj\u2208D} ||xj - l_i||$ where $l_i$ is the midpoint of the segment corresponding to bucket i. The baseline maps a query to its corresponding bucket and predicts the input stored in that bucket as the nearest-neighbor. Our model's accuracy monotonically increases with extra space demonstrating that the data-processing network learns to pre-compute useful statistics that enable more efficient querying. We provide some insights into the learned solution in App C.4 and show that our model can be trained to use extra space in the high-dimensional case as well (App \u0421.5)."}, {"title": "3 BEYOND NEAREST NEIGHBOR SEARCH", "content": "Many other data structure problems beyond nearest neighbor search can be modeled by our framework. Here, we illustrate this broader applicability by applying the framework to the classical problem of frequency estimation: a memory-constrained model observes a stream of elements, and is subsequently asked to approximate the number of times a query element has appeared (Cormode & Muthukrishnan, 2005; Cormode & Hadjieleftheriou, 2010). In Section 3.2 we describe several other data structure problems that the framework can be applied to."}, {"title": "3.1 FREQUENCY ESTIMATION", "content": "Given a sequence of T elements $e^{(1)}, ..., e^{(T)}$ drawn from some universe, the task is to estimate the frequency of a query element $e_q$ up until time-step T. Specifically, we aim to minimize the mean absolute error between the true count and the estimated count. As in the nearest neighbor setup, the two constraints of interest are the size of the data structure and the number of lookups for query execution. Consequently, our framework can be easily adapted to model this problem. We also choose this problem to highlight the versatility of our framework as it can be applied to streaming settings.\nData processing Network We model the data structure as a k dimensional vector $D$ and use an MLP as the data-processing network which is responsible for writing to $D$. When a new element arrives in our stream, we allow the model to update $M$ values in the data structure. Specifically, when an element arrives at time-step t, the data-processing network outputs M k-dimensional one-hot update position vectors $u_1, ..., u_M$ and M corresponding scalar update values $v_1, ..., v_M$. We then apply the update, obtaining $D_{t+1} = D_t + \u2211_i^M u_i * v_i$. Unlike in the NN setting where we did not constrain the construction complexity of the data structure, here we have limited each update to the data structure to a budget of $M$ lookups. We do so as in the streaming settings updates typically occur often, so it is less reasonable to consider them as a one-time construction overhead cost.\nQuery processing Network Query processing is handled in a similar fashion to NN search \u2013 we have M query MLP models that output lookup positions. Finally, we also train a MLP predictor network \u03c8(v1, ..., vm) that takes in the M values retrieved from the lookups and outputs the final prediction.\nEXPERIMENTS\nZipfian Distribution We evaluate our model in a setting where both the stream and query distributions follow a Zipfian distribution. This simulates a common feature of frequency-estimation datasets where a few \"heavy hitter\" elements are updated or queried more frequently than others (Hsu et al., 2019). For any fixed training instance, the rank order of the elements in the domain is consistent across both the stream and query distributions, but it is randomized across different training instances. As a result, the model cannot rely on knowing which specific elements are more frequent than others; only the overall Zipfian skew is consistent across training instances.\nWe use a data structure of size k = 32 and train our model with M\u2208 {1,2,4} queries. Both the data and query distributions are Zipfian over {1, ..., 1000} with a fixed skew of \u03b1 = 1.2. We evaluate the mean absolute error over streams of length 100 and compare with the CountMinSketch algorithm, a hashing-based method for frequency estimation (Cormode & Muthukrishnan, 2005) (See App. E for an overview). Our model's performance improves with more queries and outperforms CountMinSketch (Figure 9). In this case, CountMinSketch degrades with more queries as for a fixed size memory (k = 32), it is more effective for this distribution to apply a single hash function over the whole memory than to split the memory into k partitions of size k/M and use separate hash functions. We look at the learned algorithm in more detail and find that our model learns an algorithm similar to CountMinSketch, but with an important difference: it uses an update delta of less than 1 when a new item arrives, instead of the delta of 1 used by CountMinSketch. We find that this can be particularly useful when the size of the data structure is small and collisions are frequent. We hypothesize that the better performance of the learned solution is at least partially due to the smaller delta. In Figure 22, we show that we are able to recover the performance of our learned data structure with 1 and 2 queries when we use a smaller delta."}, {"title": "Learning Heavy Hitter Features", "content": "In the previous experiment, the Zipfian distribution shape was fixed across training instances but the rank ordering of elements was random. In some settings, however, it may be possible to predict which elements are more likely to occur in the stream. While the exact elements may vary between streams, frequently occurring items could share features across streams. For instance, Hsu et al. (2019) show that in frequency estimation for network flows, certain types of IP addresses receive much more traffic than others. We simulate such a setting by fixing the rank ordering of the Zipfian distribution. However, instead of using a universe of integer elements {1, ..., K}, we instead use their corresponding 3-digit MNIST images with K = 100 (constructed as in the MNIST NN experiment). Given a stream of integers, we map them to their corresponding MNIST labels and then for each label we sample a corresponding image from the training set. During evaluation, we use images samples from the test set. As the distribution is skewed and the ranking is fixed, images with smaller numbers are sampled much more frequently than those with larger numbers. As in the MNIST NN experiment, we also use a feature-learning CNN model to process the images before passing them to the data-processing and query-execution networks.\nWe compare our model to CountMinSketch with 1-query that is given the underlying labels instead of the images. Our model has a significantly lower error than the baseline (0.15 vs 2.81 averaged over a stream of size 100 (see Fig. 23)) as the latter is distribution-independent. By training from the data-distribution end-to-end, our framework is able to simultaneously learn features of heavy hitters (in this case, clustering images with the same label) and use this information to design an efficient frequency estimation data structure. We investigate the learned structure and find that the model has reserved separate memory positions for heavy hitters, thereby preventing collisions (Fig. 24)."}, {"title": "3.2 OTHER POTENTIAL APPLICATIONS", "content": "Here, we outline several other potential applications of our framework to facilitate future work.\nGraph data structures: Many graph-related problems require an efficient representation to support connectivity or distance queries between vertices. For distance queries, one approach is to use quadratic space to store the distances between all vertex pairs, allowing O(1) query time. Alternatively, one could use no extra space and simply store the graph (which may require significantly less than quadratic space) and run a shortest-path algorithm at query time. The challenge is to find a middle ground: using sub-quadratic space while still answering distance queries faster than a full shortest-path computation (Thorup & Zwick, 2005).\nSparse matrices: Another common problem that can be framed as a data structure problem is that of compressing sparse matrices. Given an M \u00d7 N matrix, on one hand, one could store the full matrix and access elements in O(1) time. However, depending on the number and distribution of 0s in the matrix, different data structures could be designed that use less than O(MN) space. There is an inherent trade-off between how compressed the representation is and the time required to access elements of the matrix to solve various linear algebraic tasks involving the matrix such as matrix-vector multiplication (Bulu\u00e7 et al., 2011; Chakraborty et al., 2018).\nLearning statistical models: Our framework can also handle problems such as learning statistical models like decision trees, where the input to the data-processing network is a training dataset, and the output is a model such as a decision tree. The query algorithm would then access a subset of the model at inference time, such as by doing a traversal on the nodes of the decision tree. This could be used to explore questions around optimal algorithms and heuristics for learning decision tress, which are not properly understood (Blanc et al., 2021; 2022)."}, {"title": "4 RELATED WORK", "content": "Learning-Augmented Algorithms Recent work has shown that traditional data structures and algorithms can be made more efficient by learning properties of the underlying data distribution. Kraska et al. (2018) introduced the concept of learned index structures which use ML models to replace traditional index structures in databases, resulting in significant performance improvements for certain query workloads. By learning the cumulative distribution function of the data distribution the model has a stronger prior over where to start the search for a record, which can lead to provable improvements to the query time over non-learned structures (Zeighami & Shahabi, 2023). Other works augment the data structure with predictions instead of the query algorithm. For example, Lin et al. (2022a) use learned frequency estimation oracles to estimate the priority in which elements should be stored in a treap. Perhaps more relevant to the theme of our work is Dong et al. (2019), which trains neural networks to learn a partitioning of the space for efficient nearest neighbor search using locality sensitive hashing, and the body of work on learned hash functions (Wang et al., 2015; Sabek et al., 2022). While all these works focus on augmenting data structure design with learning, we explore whether data structures can be discovered entirely end-to-end using deep learning.\nNeural Algorithmic Learners There is a significant body of work on encoding algorithms into deep networks. Graves et al. (2014) introduced the Neural Turing Machine (NTM), which uses external memory to learn tasks like sorting and copying. Veli\u010dkovi\u0107 et al. (2019) used graph neural networks (GNNs) to encode classical algorithms such as breadth-first search. These works train deep networks with a great degree of supervision with the aim of encoding known algorithms. For instance, Graves et al. (2014) use the ground truth sorted list as supervision to train the model to sort. There has also been work on learning algorithms in an end-to-end fashion. Fawzi et al. (2022) train a model using reinforcement learning to discover matrix multiplication algorithms, while Selsam et al. (2018) train neural networks to solve SAT problems. Garg et al. (2022) show that transformers can be trained to encode learning algorithms for function classes such as linear functions and decision trees. Our work adds to this line of research on end-to-end learning, focusing on discovering data structures."}, {"title": "5 CONCLUSION", "content": "We began with the question of whether deep learning models can be trained to discover data structures from scratch. This work provides"}]}