{"title": "Logically Constrained Robotics Transformers for Enhanced Perception-Action Planning", "authors": ["Parv Kapoor", "Sai Vemprala", "Ashish Kapoor"], "abstract": "With the advent of large foundation model based planning, there is a dire need to ensure their output aligns with the stakeholder's intent. When these models are deployed in the real world, the need for alignment is magnified due to the potential cost to life and infrastructure due to unexpected faliures. Temporal Logic specifications have long provided a way to constrain system behaviors and are a natural fit for these use cases. In this work, we propose a novel approach to factor in signal temporal logic specifications while using autoregressive transformer models for trajectory planning. We also provide a trajectory dataset for pretraining and evaluating foundation models. Our proposed technique acheives 74.3 % higher specification satisfaction over the baselines.", "sections": [{"title": "I. INTRODUCTION", "content": "Most autonomous robots deployed in the real world need to operate in a safe and reliable manner. This problem is exacerbated for safety critical applications such as autonomous vehicles where failure to respect safety constraints can lead to catastrophic consequences. A key issue with ensuring safety constraints can be attributed to imprecise specification of desired behaviors. Existing methods of encoding behaviors through objectives, such as cost functions or reward functions, can be exploited by underlying algorithms in a suboptimal manner. [1] This allows them to achieve high scores without fully meeting the intended requirements. This problem is only worsened by the recent advent of using Natural Language (NL) to communicate instructions to robots. Due to NL's inherent ambiguity, it is unclear how to use it for encoding precise behavior or constraints in safety critical applications. [2, 3]\nAn alternative is to use specifications written in Temporal logics (TL) that have rich and precise semantics. Additionally, TL specifications provide a tractable way to check if the system achieves the desired behavior. In line with this, there has been significant recent interest in specifying temporal and logical constraints on system behaviors through a continuous- time real-valued TL called signal temporal logic (STL) [4]. STL specifications can be defined over state action trajectories of robots. Additionally, STL is equipped with a score of satisfaction/violation called Robustness that can be used as feedback for generating desired behavior. There exist a large body of work that uses STL specifications to generate behavior through Reinforcement Learning [5, 6], Mixed Integer Convex"}, {"title": "II. PRELIMINARIES AND PROBLEM STATEMENT", "content": "STL is a logic specification language used to define prop- erties of continuous time real valued signals [4]. A signal s is a functions: $\\mathcal{T} \\rightarrow \\mathbb{R}^n$ that maps a time domain $\\mathcal{T} \\subset \\mathbb{R}_{\\geq 0}$ to a real valued vector. Then, an STL formula is defined as:\n$\\varphi := \\mu\\; |\\; \\neg \\varphi\\; | \\;\\varphi \\wedge \\psi \\; |\\; \\varphi\\vee \\psi \\; |\\; \\varphi\\; \\mathcal{U}_{[a,b]}\\; \\psi$\nwhere \u03bc is a predicate on the signal s at time t in the form of \u03bc = \u03bc(s(t)) > 0 and [a,b] is the time interval. The until operator U defines that & must be true until & becomes true within a time interval [a, b].\nGiven a signal st representing a signal starting at time t, the Boolean semantics of satisfaction of st = $ are defined inductively as follows:\n$\\begin{array}{l}\ns_t \\models \\mu \\Leftrightarrow \\mu(s(t)) > 0 \\\\\ns_t \\models \\neg \\varphi \\Leftrightarrow \\neg(s_t \\models \\varphi) \\\\\ns_t \\models \\varphi_1 \\wedge \\varphi_2 \\Leftrightarrow (s_t \\models \\varphi_1) \\wedge (s_t \\models \\varphi_2) \\\\\ns_t \\models F_{[a,b]} (\\varphi) \\Leftrightarrow \\exists t' \\in [t + a, t + b] \\text{ s.t. } s_{t'} \\models \\varphi \\\\\ns_t \\models G_{[a,b]} (\\varphi) \\Leftrightarrow \\forall t' \\in [t + a,t + b] \\text{ s.t. } s_{t'} \\models \\varphi\n\\end{array}$\nConsider a dynamical system with states xt \u2208 Rn and actions at \u2208 Rm at discrete time steps t. The objective is to predict a sequence of state-action pairs {(xt, at)}=0 over a finite horizon T such that the predicted trajectory satisfies a given STL specification 4.\nOur system dynamics are defined by Xt+1 = f(xt,at) where f: Rn \u00d7 Rm \u2192 Rn maps a state action pair (xt \u2208 Rn, at \u2208 Rm) at a given timestep t to the next state Xt+1 \u2208 Rn.\nFor generating trajectories, we utilize a causal transformer model to autoregressively predict the next state-action pair based on the past sequence:\n\\{(X_{t+k}, a_{t+k})\\}_{k=1}^{T-t} = \\text{Transformer}(\\{(x_i,a_i)\\}_{i=0}^{t-1},\\theta) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(1)\nwhere @ represents the parameters of the transformer model. Then, An STL specification is defined over the state and action variables encoding the safety and liveness requirement. A trajectory {(xt, at)}=0 satisfies 6 if:\n\\{(x_t, a_t)\\}_{t=0}^{T} \\models \\varphi \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(2)\nThe goal is to find the parameters @ of the causal trans- former model such that the predicted trajectory {(xt,at)}=0 maximizes the likelihood of satisfying the STL specification \u03c6.\nMathematically, this can be expressed as:\n$\\theta^* = \\arg \\max_{\\theta} Pr(\\{(x_t, a_t)\\}_{t=0}^{T} \\models \\varphi | \\theta) \\\\\n\\text{s.t. } x_{t+1} = f(x_t, a_t) \\forall t \\in \\{0,1,..., T - 1\\}\\\\\nX_0 \\thicksim X_{init}, \\alpha_0 \\thicksim A_{init} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(3)$"}, {"title": "III. METHODOLOGY", "content": "The overall approach is described in Figure 1. We call our model Perception Action Signal TemporaL Transformer (PASTEL). PASTEL takes as input the state, action and spec- ification embeddings and autoregressively predicts the future sequence of states and actions conditioned on the embeddings such that the state trajectory signal satisfies the user specified STL specification. The length of the state-action trajectory is fixed as the horizon of the original specification keeping in line with the original STL semantics."}, {"title": "C. Implementation Details", "content": "Our state and action tokenizers are de- signed to take as input raw states and continuous actions similar to [11]. For the STL specification, we leverage state-of- the-art text tokenizers like Contrastive Language-Image Pre- Training (CLIP) [13] and Bidirectional Encoder Represen- tations from Transformers (BERT) [14]. Due to the natural language like syntax of STL, these tokenizers provide richly grounded features that can be leveraged downstream for tra- jectory predictions.\nDue to STL's rich syntax, there are multiple ways to rep- resent STL specifications as a textual input to the tokenizers. A general technique is to represent the STL specification as an Abstract Syntax Tree and perform different tree traversals (in order, post order, pre order) to generate linear text. Ad- ditional, since STL's temporal operators can be represented in multiple formats (\"F\", \"eventually\", \"finally\"), the search space for tokenization techniques is expanded further. Authors in [15] did an analysis on different expression formats and converged on in order traversal plus word representation for target outputs. However, in our work the logical specifications are provided as input to PASTEL, so arbitary tokenization procedures can significantly impact the predicted state action trajectory. Additionally, since our focus is on motion planning, atomic propositions cannot be represented using words and require mathematical expressions to capture different regions in the space. Due to these reasons, we choose to finetune SOTA pretrained text tokenizers for our framework. Tokenizer fine- tuning is done via training the entire architecture, including the tokenizers, end-to-end, rather than freezing the tokenizer layers and using their outputs downstream.\nFollowing the implementation in [11], we use a decoder- only Transformer model to roll out a sequence of state-action- specification triplets constituting a trajectory. We leverage a causal attention mask to enforce dependence of future state and action tokens on only past state action and specification tokens. We factor in the specification through two key techniques: First, in order to encode emphasis on the specification while generating trajectories, we repeat the specification token and append it to each state action token at each timestep in a trajectory. We call this technique specification conditioned prediction. For this, we use an additional MLP layer to reduce the dimensionality of the feature outputs from STL tokenizer to the embedding space dimension. Second, similar to VLAS we perform a cross attention operation with state, action, specification embeddings acting as Key and Value arrays while the specification embeddings act as Query array. This forces the model to not overfit solely on the state action data and prevents ignoring specification while making predictions.\nPASTEL outputs 3N tokens where N is the time horizon (number of timesteps) of the STL specification, and the prediction involves outputting state, action and specification tokens at each timestep. Since STL specifications encode temporal behavior, the output tokens are made to conform to the different parts of the specification that currently need to be satisfied depending on the timestep.\nOur training objective is carefully designed to account for the expectation of high precision state action trajectory predictions. We use a combination of Mean Absolute Error (MAE) and Mean Squared Error (MSE) loss defined over the state as well as action predictions. Formally,\n$L_{state} = MSE(S_{tobs}, \\hat{S}_{tobs}) + MAE(S_{tobs}, \\hat{S}_{tobs}) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(4)$\n$L_{action} = MSE(a_{t},\\hat{a}_{t}) + MAE(a_{t}, \\hat{a}_{t}) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(5)$\nAdditionally, we also add a specification relevance loss that penalizes deviation from the expected impact of the specification on the predicted trajectory. This loss is defined over the specification embeddings that capture the semantic information about the specification and the cross attention outputs that integrates information from all the input em- beddings. Specifically, we use a cosine similarity measure to quantify how well the instruction is reflected in the final outputs. Formally,\n$L_{spec} = 1 - Cos\\_sim(T_{emb}, C) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(6)$\nwhere Temb represents the mean text embeddings and C represents the mean cross-attention output embeddings:\n$T_{emb} = \\frac{1}{n} \\sum_{i=1}^{n} t_i  \\text{ and }  C = \\frac{1}{n} \\sum_{i=1}^{n} C_i$\nHere, n is the number of embeddings (e.g., batch size), ti are the text embeddings, and ci are the cross-attention output embeddings.\nFinally, our total loss is:\n$L_{total} = L_{state} + L_{act} + L_{spec} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(7)$"}, {"title": "IV. EVALUATION", "content": "Our dataset is generated by leveraging the Mixed Integer Convex Program (MICP) en- codings of STL specifications. We use STLPy [7] to generate a multi specification dataset with varying initial states and complexity of behaviors. STLPy is a framework that takes as input system dynamics, specification description, actuation constraints and state cost functions to generate trajectories that satisfy the given specifications. For a more formal proof of soundness and other details, we refer the readers to [7].\nWe outline the specifications in Table 1. Our environment is a 2D planar environment with multiple goal regions and a single obstacle. The atomic propositions are defined over these regions. The specifications over these atomic propositions are designed to encode different robotic mission patterns [16] such as sequenced visit, stabilization etc. These class of patterns capture a large set of common robot mission requirements as identified in [16].\nOur model has similar architecture and parameter configu- rations as the PACT model. We refer the readers to [11] for more information. The cross attention operation was added on top of the causal attention operation along with an additional layer of normalization over the outputs.\nTable 2 summarizes the benchmarking results for our ex- perimental setup. The % satisfaction is computed out of 100 trajectories generated by the model from 100 randomly sampled states. We observe that for $2 and 43, PASTEL improves satisfaction over baseline by approximately 82.9 and 54.3 percent respectively. For $1, we observe an 85.7 percent performance improvement over baseline. Additionally, all the generated trajectories are smooth and respect the actuation constraints measured separately via examining the generated actions.\nAs can be inferred, PASTEL has medium to high satis- faction for $2 and 3 while the PACT has low to medium satisfaction. We hypothesize this is due to the relative com- plexity of $2 and 3 involving two nested tasks (reaching and staying in a region and reaching two regions) respec- tively which is complex for autoregressive models like PA\u0421\u0422 to infer without additional contextual information. Due to our conditional prediction and cross attention mechanism, the model is able to leverage the specification embeddings to satisfy the task succesfully. However, both PASTEL and PACT's satisfaction percentage drops for $1 which is the most complex specification involving a disjunction operator. This implies that there are multiple possible ways to satisfy the requirement and the underlying dataset reflects the same. Nonetheless, PASTEL still outperforms PACT for $1 rela- tively. Hence, we definitively answer RQ1. Additionally, the generated trajectories satisfy the actuation constraints which was never explicitly encoded into the model design. This implicit effect is due to the loss function defined over the ground truth actions that respect the actuation constraints due to the optimisation problem setup. This lends additional support to the power of autoregressive trajectory generators in generating safe constraint satisfying trajectories.\nFor RQ2, we modified specification text and visualised attention matrix to observe dependence on text. We underline our two key qualitative insights:\n1) The satisfaction drops when the test specification is different than the training one in terms of the atomic propositions encoding the regions.\n2) The attention matrix visualisation highlights the depen- dence of state and action tokens on the specification tokens further substantiating our original hypothesis."}, {"title": "V. RELATED WORK", "content": "Constrained trajectory generation for robots has been a focal point in robotics research, particularly in applications requiring high precision and adherence to strict operational constraints. Traditional methods have relied on optimization- based approaches, such as Mixed-Integer Linear Programming (MILP) and Sequential Quadratic Programming (SQP), which are effective but often computationally intensive and chal- lenging to scale for complex tasks. Sampling-based planners like Rapidly-exploring Random Trees (RRT) [17, 18] and Probabilistic Roadmaps (PRM) [19] have been used to address these issues from primarily a collision-avoidance perspective, introducing probabilistic guarantees for constraint satisfac- tion. Constrained variants of RRT-like methods have also been proposed in the literature [20]. However, these meth- ods can struggle with high-dimensional spaces and intricate constraints, limiting their applicability in real-world scenarios. Another class of techniques involves the usage of control barrier functions: learning safe policies using explicit control barrier functions [21, 22], or constructing CBFs jointly with the policy using neural networks [23, 24].\nData-driven trajectory planning techniques mainly adapt two paradigms: reinforcement learning and imitation learning. While reinforcement learning has been widely used to learn safe policies, the success of these methods often depends on manual reward shaping, which is a laborious and non-trivial ef- fort, as well as the existence of a capable simulator or sandbox that allows for a large number of training episodes. Imitation learning has the potential to reduce sample complexity using a more focused set of demonstrations, for example, in the case of safe trajectory planning, learning only from a set of safe trajectories. Imitation learning can take the form of simple Behavior Cloning [25], which may not generalize to the out-of- distribution scenarios induced by on-policy deployment, and often requires additional training [26]. Other methods such as inverse reinforcement learning [27] can mitigate this challenge but they do not explicitly account for constraints either and rely on implicit extraction of a reward signal apparent in the data.\nIn recent work, reinforcement learning and imitation learn- ing have been posed as sequence modeling problems to leverage the immense efficacy of Transformer models at learning from data. One seminal work was the Decision Transformer [28], which uses a causally masked Transformer conditioned on desired rewards to output optimal trajectories. Similarly, works such as Gato, PACT use Transformer models directly on demonstrations to learn trajectories. Extensions such as ConBAT [29] attempt safe trajectory planning by training on a combination of safe and unsafe demonstrations."}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "In this work, we propose a novel approach to factor in STL specifications in transformer based trajectory planning using specification conditioned prediction and cross attention based mechanism for specification relevance.\nWhile, our initial results are promising our approach cur- rently suffers with specifications with long horizons and complex nested tasks. We plan to remedy this using the STL decomposition techniques proposed in [8] and updating the specification token at each timestep to only focus on the relevant part of the specification. Additionally, we also plan to factor in external feedback in the form of STL robustness sim- ilar to SMART[30]. Finally, we aim to evaluate the feasibility of our technique via field testing on navigation robots."}]}