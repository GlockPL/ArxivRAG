{"title": "An Investigation into Value Misalignment in LLM-Generated Texts for Cultural Heritage", "authors": ["Fan Bu", "Zheng Wang", "Siyi Wang", "Ziyao Liu"], "abstract": "As Large Language Models (LLMs) become increasingly prevalent in tasks related to cultural heritage, such as generating descriptions of historical monuments, translating ancient texts, preserving oral traditions, and creating educational content, their ability to produce accurate and culturally aligned texts is being increasingly relied upon by users and researchers. However, cultural value misalignments may exist in generated texts, such as the misrepresentation of historical facts, the erosion of cultural identity, and the oversimplification of complex cultural narratives, which may lead to severe consequences. Therefore, investigating value misalignment in the context of LLM for cultural heritage is crucial for mitigating these risks, yet there has been a significant lack of systematic and comprehensive study and investigation in this area. To fill this gap, we systematically assess the reliability of LLMs in generating culturally aligned texts for cultural heritage-related tasks. We conduct a comprehensive evaluation by compiling an extensive set of 1066 query tasks covering 5 widely recognized categories with 17 aspects within the knowledge framework of cultural heritage across 5 open-source LLMs, and examine both the type and rate of cultural value misalignments in the generated texts. Using both automated and manual approaches, we effectively detect and analyze the cultural value misalignments in LLM-generated texts. Our findings are concerning: over 65% of the generated texts exhibit notable cultural misalignments, with certain tasks demonstrating almost complete misalignment with key cultural values. Beyond these findings, this paper introduces a benchmark dataset and a comprehensive evaluation workflow that can serve as a valuable resource for future research aimed at enhancing the cultural sensitivity and reliability of LLMs.", "sections": [{"title": "I. INTRODUCTION", "content": "CULTURAL heritage plays an essential role in shaping identities, preserving histories, and fostering dialogue among diverse communities. Traditionally, the responsibility for interpreting cultural heritage has relied on professionals such as historians, archaeologists, and curators, who make ef- forts to ensure that representations are accurate and respectful of the cultures they depict. In recent years, with the rapid advancement of Artificial Intelligence (AI) and Natural Lan- guage Processing (NLP), particularly Large Language Models (LLMs) such as OpenAI's GPT [1], Anthropic's Claude [2] and Meta AI's LLaMA [3], has introduced a new paradigm in which cultural heritage content is generated and shared. The use of LLMs for cultural heritage tasks has been explored across several applications, including summarizing archaeo- logical reports [4], generating labels and catalogs for exhibi- tions and permanent collections [5], [6], creating educational materials and scripts for tour guides [7], [8], and developing interactive chat-bot for visitors [9], [10]. As LLMs become increasingly prevalent in cultural heritage tasks and more users and researchers rely on them, their ability to generate accurate and culturally aligned texts remains unclear, raising concerns about the alignment of their responses with human values and social needs.\nAs shown in Figure 1, cultural value misalignment in LLM- generated texts can affect users' understanding of heritage topics and their perception of cultural authenticity. When a user queries an LLM about cultural heritage, the generated re- sponses may contain misaligned values that distort or misrep- resent important cultural values, historical context, or cultural nuances associated with the queried heritage. If users regard these LLM-generated responses as accurate and authoritative, they may develop misunderstandings, adopt stereotypes, or unintentionally disrespect the cultural heritage. As a result, such misunderstandings can perpetuate inaccurate narratives within society, undermining cultural respect and contributing to a loss of authentic representation in public knowledge [11].\nAn illustrative example of value misalignment in LLM- generated responses for cultural heritage tasks is shown in Figure 2. In this example, the LLM is queried about the relationship between the Erlitou site and the Xia dynasty within the context of Chinese cultural heritage. Although there is a significant debate within academia regarding whether the Erlitou site directly corresponds to the Xia Dynasty, with some researchers believing that the Erlitou site may belong to the late Xia Dynasty and others contending it is more closely related to the early Shang Dynasty culture [12], we can observe a simplification of these academic controversies into seemingly certain conclusions when handling this complex cultural heritage topic by definitively linking the Erlitou site to the Xia Dynasty in the LLM's response. This reflects cultural value misalignments in LLM-generated texts, where LLMS often fail to accurately convey the necessary caution in their cultural content generation.\nLuckily, the investigation of cultural values within LLMS has received significant attention in recent years, driven by the widespread adoption of LLMs in daily life and growing concerns about potential value misalignments, which involve historical, cultural, and social values that are inherently diverse and complex. For example, the performance of LLMs in explaining cultural unity in diversity, e.g., the shared concepts of bridal veils in China and the US, is examined in [13]. In addition, [14] provides a benchmarking evaluation on LLMs specific to Taiwanese Hakka culture, while [15] explores essay generation tasks by LLMs in the context of cultural heritage. However, existing studies primarily focus on specific cultural topics or particular types of LLM tasks, and thus do not comprehensively assess LLMs' performance on cultural heritage tasks, particularly regarding value misalignments.\nIn this context, the lack of such studies motivates us to pursue a comprehensive understanding of value misalignment in LLM-generated texts for cultural heritage tasks. Specifically, our investigation addresses two primary Research Questions (RQs):\nRQ1: What types of value misalignment are observed in LLM-generated texts for cultural heritage (misalign- ment type)?\nRQ2: How frequently do LLM-generated texts for cultural heritage exhibit value misalignment (misalignment rate)?\nTo answer the above questions, we face the following two challenges:\nChallenge #1. The absence of a well-designed dataset makes it challenging to assess value misalignment in cultural heritage-related tasks. To conduct a comprehensive evaluation, it is essential to develop tasks that cover various aspects of cultural heritage.\nChallenge #2. The lack of tools capable of accurately identifying value misalignment in large volumes of generated text poses a significant challenge. Therefore, there is a need for integrated solutions combining automated tools and human evaluation to ensure thorough and reliable analysis.\nTo address the challenges arising from the absence of a well- designed dataset for cultural heritage tasks (i.e., Challenge #1), we compiled an extensive set of 1066 query tasks covering 5 widely recognized categories with 17 aspects of cultural heritage. To tackle the lack of accurate tools for identifying value misalignments in LLM-generated responses (i.e., Chal- lenge #2), we employed a combination of automated tools and human evaluation. Specifically, we assessed whether the LLM- generated responses contained value misalignments using an advanced LLM with a well-designed prompt. This advanced LLM utilized prompt-based learning with a small, human- labeled dataset to improve its ability to identify misalignments. For responses where the fine-tuned LLM struggled to identify value misalignment, evaluations were conducted by cultural heritage professionals.\nSummary of contributions. The main contributions of this paper are listed as follows.\n1) We proposed a comprehensive evaluation workflow to systematically analyze cultural value misalignment in LLM responses, marking the first effort to investigate the misalignment of LLM-generated content with the values of cultural heritage.\n2) We introduced a benchmark dataset of 1066 query tasks covering 5 widely recognized categories with 17 aspects of cultural heritage. This comprehensive dataset is open- sourced, hence serving as a valuable resource for future research to enhance the cultural sensitivity and reliability of LLMs in various tasks.\n3) Our findings revealed that the majority of LLM- generated texts for cultural heritage tasks exhibit value misalignment across various LLMs, with approximately 65% across around 1K tasks analyzed being affected, spanning 8 distinct types of cultural value misalignment. This underscores the urgent need for improved method- ologies to address value misalignment in LLM-generated content, particularly in culturally sensitive domains.\nOrganisation of the paper. The remainder of this paper is organized as follows: Section II provides background de- tails and related work. Section III presents our methodology. Section IV describes the experimental results, followed by discussions in Section V. Finally, we conclude the paper in Section VI."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "This section reviews the background and existing research on LLMs for cultural heritage, value misalignments in LLM- generated content, and the use of LLMs for evaluation."}, {"title": "A. LLMs for Cultural Heritage", "content": "LLMs are revolutionizing the field of cultural heritage with their capabilities to process and generate text, analyze documents, and support multilingual translation, thus offering innovative solutions for preservation, research, education, and public engagement. For instance, LLMs are used to construct linguistic corpora for low-resource languages, contributing to their preservation for future generations [16]. Additionally, LLMs fine-tuned with specific cultural and historical datasets assist professionals in analyzing historical texts and artifacts [16]. Moreover, LLMs facilitate interaction between profes- sionals and audiences for public engagement and education in cultural heritage, as seen in guided and recommendation sys- tems tailored to visitors' experiences [6] and in the detection of fake reviews of cultural heritage sites [17]. However, the use of LLMs in cultural heritage faces limitations, particularly those arising from value misalignment, which range from inaccuracies to biases. These issues can severely impede the effective application of LLMs in sensitive cultural contexts, necessitating focused research to address these challenges."}, {"title": "B. Value Misalignments in LLMs", "content": "Many studies have examined the pervasive issue of value misalignment in content generated by LLMs, encompassing concerns from reliability issues like misinformation and hallu- cination to safety issues such as toxicity and privacy violations, and extending to violations of social norms including bias and sensitivity [18]. Consequently, the LLM community is actively seeking to develop effective methods for conducting value alignment in LLMs [19]. Several studies highlight severe value misalignment in LLM tasks related to cultural and historical content. For example, responses generated by LLMs often reflect dominant Western perspectives, marginalizing non-Western narratives [20]. Similar observations regarding selective narration for cultural and historical topics have been reported in [21], [22]. Furthermore, value misalignments have been identified through evaluations of various LLM tasks in diverse and culturally sensitive contexts [23], [24]. However, we note that there has not been a specific and comprehensive investigation into value misalignment for cultural heritage, which motivates us to conduct this study."}, {"title": "C. LLMs for Evaluation", "content": "Assessment and evaluation have been critical challenges in AI and NLP tasks. Fortunately, recent advancements in LLMs have inspired the \"LLM-as-a-judge\" paradigm, where LLMS are utilized to perform scoring, ranking, or selection across various tasks and applications, yielding results comparable to traditional evaluation methods that rely on static met- rics [25]. Advanced LLMs, particularly the ChatGPT family, are increasingly used to assess performance in open-ended generation tasks such as the quality of summarization [26], the presence of hallucination [27], and the safety of LLM- generated responses [28]. However, no existing works leverage LLMs as evaluators for specific cultural values assessment [29], possibly due to the lack of consensus among researchers and users on the reliability and validity of AI in interpreting complex cultural contexts [30]."}, {"title": "III. RESEARCH METHODOLOGY", "content": "Our evaluation workflow, as illustrated in Figure 3, consists of four main steps: (1) construction of knowledge framework for cultural heritage, (2) task design, (3) query and processing, and (4) misalignment detection. First, we analyze and con- struct the knowledge framework for cultural heritage, dividing it into multiple categories, which are further classified into more detailed aspects. Based on this knowledge framework, we can design a set of questioning tasks that cover all aspects to assess the presence of cultural value misalignments in LLMs. By inputting these questions as queries to LLMs, we obtain corresponding responses. These are then processed to automatically detect and evaluate built-in value misalignments through both automated tools and human assessment."}, {"title": "A. Construction of Knowledge Framework", "content": "Constructing a comprehensive knowledge framework for cultural heritage is a challenging task. Previous efforts have typically focused on two directions. One from an epistemolog- ical perspective that horizontally classifies three interconnected components, namely ontology, attachment, and environment [31]. The other one vertically classifies three temporal stages, past, present, and future [32]. Building upon the foundations obtained from the insights of the horizontally classified ele- ments, which complement each other and can exchange roles under certain conditions [31], and the vertically classified elements that can transform one into another under specific circumstances [32], we incorporate prominent frameworks pro- posed by UNESCO [33] and ICOMOS [34] to propose a more cohesive knowledge framework that spans the entire lifecycle of cultural heritage, offering a more multi-dimensional per- spective. This framework is organized into 5 main categories: Types, Values, Conservation, Management, and Utilization, and further divided into 17 aspects as described in Table I, with details explained in the subsequent part of this section.\nTypes and Values. The organization of types for cultural heritage typically stems from well-studied theoretical research [35] and has thus established a well-recognized consensus [36]. Consequently, we adopt a similar concept to divide the Types into three aspects: Tangible Cultural Heritage (A1), Intangible Cultural Heritage (A2), and Cultural Landscapes (A3). Similarly, adapting both the spatial perspective that emphasizes aspects such as authenticity, integrity, and con- tinuity [37] and the temporal perspective that concentrates on elements such as initial value, derived value, and chronological value [38], we divide the Values into two similar aspects, namely Phenomenon (A4) and Composition (A5).\nConservation. The research and practice of cultural heritage conservation have established widely recognized principles, yet they often provide only a broad definition and guidelines [39], [40]. To facilitate the query task design in subsequent steps, we refine this broad definition and introduce a revision as Principle (A6). Additionally, we identify three more specific aspects under the guidance of the general principles for a com- plete assessment of cultural heritage conservation: Condition (A7), Planning (A8), and Method, Material, and Techniques (A9), incorporated from [39], [40].\nUtilization. The utilization of cultural heritage within its lifecycle, described as \u201cconservation-development-utilization- development-conservation\" in [41], often features overlapping phases of development followed by conservation. Thus, we categorize Representation and Communication (A10) as foun- dational, Education (A11) as a means of conservation, and Business (A12) for development phases. These categorizations are consistent with the corresponding descriptions in [42].\nManagement. Similar to the role of Utilization, Manage- ment plays a crucial role in heritage conservation throughout the lifecycle. Since Management involves a principal body managing cultural heritage according to a set guideline, and the results of management should be evaluated and moni- tored over the long term and reflected in records, we divide Utilization into five specific aspects covering all mentioned requirements: Regulation and Law (A13), Organization and Institution (A14), Identification and Archive (A15), Recording and Monitoring (A16), and Evaluation and Operation (A17)."}, {"title": "B. Task Design", "content": "This section outlines our approach to addressing the absence of a well-designed dataset of query tasks for cultural heritage, referred to as Challenge #1. Our goal is to develop a set of tasks, each aligned with a specific recognized aspect of cultural heritage as detailed in Section III-A. As shown in Figure 4, our task design process includes three main steps: (1) identifying tasks, (2) generating tasks, and (3) refining tasks. In a high-level overview, we first select a set of keywords for each task, relying on the expertise of cultural heritage professionals. Based on these keywords, we utilize an LLM to generate a list of candidate tasks following the profession- als' instructions. Then, by refining the generated tasks with professionals, we obtain a set of query tasks that can be used in the subsequent query and processing. Below, we provide a detailed explanation of each step.\n1) Identifying tasks: To ensure a comprehensive and diverse representation of cultural heritage topics in the designed query tasks, the identified questions should align with the selected categories and aspects described earlier in the knowledge framework for cultural heritage. Therefore, for each task within each aspect, we rely on the expertise of cultural heritage professionals to select 3 to 5 closely related keywords from existing literature, ensuring that each task is grounded in professional expertise. These keywords can subsequently be used to generate questions, i.e., query tasks, by utilizing a selected LLM, in our case, ChatGPT, with specific in- structions provided. Specifically, the selected keywords are related to widely discussed cultural heritage topics, such as world heritage nominations [43], digital cultural heritage [44], artifact repatriation [45], [46], indigenous culture [47], and contested cultural heritage [48], [49]. For example, a set of keywords for indigenous community in A1 includes {Maori human remains, repatriation, ethics}, while a set of keywords for world heritage nominations in A14 includes {UNESCO's World Heritage List, small percentage of heritage sites in Africa, culture, economic}.\n2) Generating tasks: As previously described, by utilizing the obtained set of keywords, we can deploy an advanced LLM, in our case, using the OpenAI API to interact with Chat- GPT, to generate query tasks based on detailed instructions. These instructions, along with detailed prompts, are provided in our open-source dataset and include the following criteria:\n\u2022 Target of generated responses: the response should be formatted as a question.\n\u2022 Content of the generated response: the generated ques- tions should align with the definition of specific aspects provided in Table I.\n\u2022 Type of generated questions: options include four ques- tion types including critical query (QT1), fact verification (QT2), causal inference (QT3), and interpretation (QT4), as detailed in Table II.\n\u2022 Word limitation: specifies the maximum number of words for each question.\n\u2022 Number of questions: indicates the number of question variants generated, which can be further selected and refined.\n\u2022 Example: provides an example of how questions can be generated from keywords defined by professionals, aiding the LLM in better understanding the complete set of instructions.\nFor illustration, an example of three questions generated based on the specified keywords {Hanbok and Hanfu, origins, similar, differences} for A2 aspect are: (i) Please discuss the differences and similarities between Chinese Hanfu and Korean Hanbok. (QT4), (ii) What do you think of the historical attribution dispute between Chinese Hanfu and Korean Han- bok? (QT1), and (iii) True or False: Chinese Hanfu originated from Korean Hanbok. (QT2). These questions are then refined by cultural heritage professionals, with the details explained in the subsequent section.\n3) Refining tasks: As mentioned earlier, professionals refine the questions generated by the advanced LLM in the previous step to ensure accuracy, relevance, and clarity for tasks related to cultural heritage. This refinement process, which involves removing irrelevant questions, rephrasing the content, and adjusting question types, guarantees that the queries effectively address the most critical aspects of cultural heritage and accurately represent the diversity of heritage phenomena. The statistics of the refined questions are summarized in Table III, which provides the number of questions for each type within the various categories. More detailed statistics for each specific predefined aspect are described in the dataset card accompanying our open-source dataset."}, {"title": "C. Query and Processing", "content": "The objective of this step is to generate a dataset of responses produced by LLMs. To accomplish this, we in- dividually query the LLM with each task obtained in the previous steps. The generated responses are then processed, serving as the foundation for value misalignment detection in the subsequent step.\n1) Querying LLMs: With the questions refined by pro- fessionals for cultural heritage tasks, we interact with the LLM model, using refined questions as prompts. For each prompt, we request multiple responses and in the step of misalignment detection, we classify the type of cultural value misalignment based on the majority of the multiple responses. This method helps mitigate the inherent randomness of LLM- generated responses and enhances the reliability of our results. For simplicity, we only report the final results for each task in the remainder of the paper.\nAdditionally, we experiment with different formulations of prompts that convey the same meaning, such as changing action verbs from \"assess\" to \"discuss\" or \"evaluate,\" and replacing general terms like \"cultural heritage\" with more specific phrases, such as \u201chistoric building\u201d or the name of a specific heritage site. Despite these variations, the model's responses display minimal sensitivity to changes in phrasing. This observation confirms findings from prior studies [50], which suggest that minor modifications in prompts often have a limited impact on the quality of responses for certain tasks. Therefore, to ensure clarity and reduce ambiguity, the prompts are designed to be straightforward and direct, utilizing simple and clear task descriptions. To further ensure concise and focused answers, we require the model to generate its responses with a word limit of no more than 70 words.\n2) Processing responses: Processing responses generated by LLMs involves two key steps: (i) answer extraction and (ii) response merging. The need for answer extraction arises from our observation that some responses may con- tain verbose descriptions and irrelevant information, which complicate misalignment detection in subsequent steps. For instance, in multiple-choice answering scenarios, the LLM might provide responses that include extensive explanations for its choices, and the actual choice is typically buried within these lengthy explanations without being directly highlighted, reducing the readability of the responses and, consequently, impacting the effectiveness of the misalignment detection process. Therefore, we process these responses by providing more specific instructions and conducting manual extraction performed by professionals. Furthermore, since we request multiple responses for each prompt, there is a high probability that some responses will be identical. To reduce the workload in subsequent misalignment detection steps, we merge these identical responses into one. As a result, each sample consists of a query-response pair, where the query includes refined questions for cultural heritage, and the response comprises processed answers."}, {"title": "D. Misalignment Detection of Generated Texts", "content": "In this step, we evaluate the texts for cultural heritage generated by the LLM by identifying the existence of cultural value misalignment in the responses obtained from the previ- ous steps. We utilize a tool-based method complemented by manual evaluation to comprehensively assess the misalignment of generated content with cultural values. This dual approach ensures a thorough analysis of the texts, enabling us to identify any cultural value misalignments effectively.\n1) Tool-based misalignment detection: To identify cultural value misalignments, we use the OpenAI API to interact with ChatGPT for an initial evaluation. Since detailed instructions are provided on how to assess cultural value misalignments, using the ChatGPT as an evaluators yields strong performance. Specifically, we first manually label some query-response sam- ples according to their misalignment type (as outlined in the eight identified cultural value misalignment types summarized in Section IV-A). These labeled samples are then provided to ChatGPT to enhance its capability and understanding in classi- fying the query-response samples. Subsequently, the enhanced ChatGPT serves as an initial tool for misalignment detection. It is important to note that this capability enhancement is achieved through in-context learning rather than fine-tuning, and since only a few labeled examples are used, it does not require substantial resources. The detailed prompts for cultural value misalignment detection are provided alongside our open- source dataset and include the following criteria:\n\u2022 Target of Generated Responses: the response should identify the type of cultural value misalignment.\n\u2022 Classification: options include the eight cultural value misalignment types summarized in Section IV-A.\n\u2022 Standard: the classification standard includes the defini- tions of the eight identified misalignment types."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "This section presents the findings from analyzing various open-source LLM's responses to questioning tasks across pre- defined 17 aspects within 5 categories for cultural heritage. The analysis provides insights into the types (see Section IV-A) and rates (see Section IV-B) of cultural value misalign- ment observed in LLM-generated texts.\nThe experiments are conducted over five open-source LLMs, including LLaMA-3-8B2, QWen-7B3, Baichuan-2-7B4, Yi-6B5, Mistral-7B6. All experiments were conducted using a single NVIDIA A100 80GB GPU. For generating query tasks and detecting misalignment, we utilized the GPT-40 model via the OpenAI API. The dataset for cultural value misalignment detection contains 1066 query-response pairs, and the number of query-response pairs for each of the five categories of cultural heritage is provided in Table III. Each task is queried with 10 requests to mitigate the inherent randomness of LLM-generated responses. The team of cultural heritage professionals consists of thirteen academic scholars and domain experts."}, {"title": "A. RQ1: Misalignment Type", "content": "This section addresses the first research question (RQ1) by identifying and categorizing eight types of cultural value misalignment based on the experimental results of labeling query-response pairs. Notably, a single query-response pair may be associated with multiple types of value misalignments.\n1) Detail inaccuracy (VM1): One of the common issues in LLM-generated texts is the frequent occurrence of inaccuracies in details such as timelines, locations, characters, or causal relationships between events. This problem is particularly evident in the context of cultural heritage. From experimental results, we observe that LLMs often produce inaccurate infor- mation when responding to specific questions about cultural heritage, especially those requiring detailed knowledge of particular artifacts or heritage sites.\nFigure 5 illustrates an example of such misalignment. When the LLM is queried about the developmental stages of Chi- nese bronzes, its response, which divides the stages into six, contradicts the academic consensus. This consensus typically follows one of two approaches: categorizing the stages based on cultural development into the Formative, Flourishing, and Transitional periods [51], or dividing them into eight historical stages, ranging from the Early Period to the Late Period [52]. Additionally, the response contains a chronological error, incorrectly stating the end date of the Western Zhou period. These issues underscore the limitations of LLMs in providing accurate details, particularly when precision and alignment with scholarly consensus are required.\n2) Cultural misunderstanding (VM2): LLMs often demon- strate a lack of understanding when explaining or describing concepts, symbols, or phenomena related to cultural heritage. This issue is especially apparent when grasping the multilay- ered and unique meanings within cultural contexts, particularly concerning minority cultures or low-resource languages.\nFigure 6 provides an example of this misalignment. When the LLM is queried about the meaning of the cross-shaped symbol on ancient Kongo pottery, its response fundamentally misunderstands the cultural meaning of the symbol. In ancient Kongo culture, the cross-shaped symbol represents the life cycle and the concept of reincarnation [53], rather than sym- bolizing heaven and earth as suggested in the LLM's response.\nThis issue highlights the limitations of LLMs in providing accurate cultural understanding, especially when dealing with symbols, traditions, and concepts deeply rooted in specific cultural heritage.\n3) Knowledge gap (VM3): The knowledge gap refers to the tendency of LLMs to either hallucinate, i.e., fabricate information to generate a seemingly plausible answer, or refuse answers, i.e., admit their lack of knowledge, when queried about specific concepts of cultural heritage, cultural practices, or meanings. An example of this misalignment is illustrated in Figure 7. When the LLM is queried about the approaches used to protect and manage cultural heritage during the Republic of China era, it fails to provide an answer. This issue demonstrates the limitations of LLMs in addressing more specific cultural and historical topics due to the absence of corresponding knowledge.\n4) Premature certainty (VM4): LLMs often fail to account for unresolved or controversial topics related to cultural her- itage within the academic community, providing overly defini- tive answers that oversimplify complex subjects. For instance, as shown in Figure 8, the LLM identifies Okinoshima Island as a representative Paleolithic site in Japan. However, this claim is problematic due to insufficient archaeological evidence to establish a direct connection between Okinoshima Island and the Paleolithic Age. While some findings from the site have sparked discussions about its potential association with this period, the evidence remains inconclusive, as no definitive artifacts or stratigraphic data have been discovered to confirm its dating [54]. Consequently, the academic community has not reached a consensus on the site's age. This example highlights a key limitation of LLMs in their tendency to present premature certainties, which may misrepresent the state of academic discourse and ongoing debates.\n5) Cultural reductionism (VM5): Cultural reductionism refers to simplifications of complex cultural phenomena by reducing them to a single characteristic or description, thereby overlooking their inherent diversity and complexity. This over- simplification often results in a one-dimensional understanding of culture, ignoring its dynamic nature, historical context, and the variations that exist within and between different groups. Figure 9 provides an example of this misalignment. When the LLM is queried about the differences between Arhat statues from the Song Dynasty and the Ming Dynasty, its response simplifies the distinctions into a comparison of \u201cspirituality\u201d and \u201chumanity\u201d, which may be overly general and one-sided. The stylistic differences between these two periods are shaped by a more complex interplay of social, religious, historical, and other factors [55], rather than being limited solely to the expression of spirit and humanity.\n6) Historical bias (VM6): Historical bias refers to em- phasizing certain aspects while downplaying or omitting oth- ers. This approach often results in a skewed or incomplete understanding of historical events, as it highlights specific narratives that align with particular perspectives or agendas while neglecting broader contexts or conflicting viewpoints. Figure 10 provides an example of this misalignment. When the LLM is asked to explain why the Benin Bronzes, originally from the Kingdom of Benin, are now part of a museum collection in the United States, its response emphasizes that the artifacts were \"purchased\" by the museum while downplaying the fact that they were \"looted\" during the colonial war by the British Empire [56].\n7) Selective narration (VM7): Our observations indicate that LLM-generated texts often reflect dominant historical narratives while marginalizing alternative perspectives or con- tested interpretations. For example, as shown in Figure 11, when the LLM is queried to evaluate the removal of a statue of a Confederate general from the American Civil War, its response exclusively reflects the dominant narrative that this action represents a positive step toward racial justice and equality in the United States. However, it fails to acknowledge or engage with alternative viewpoints, such as the argument that the statue represents a part of history, symbolizing South- ern cultural heritage and historical continuity, and that its removal may be perceived by some as an erasure of that history [57]. This marginalization of diverse perspectives underscores the limitations of LLMs in providing a balanced and nuanced understanding of complex historical and cultural issues.\n8) Contextual irrelevance (VM8): Contextual irrelevance refers to overly abstract or generalized responses that fail to ad- dress the specific context of a prompt, overlooking the nuances and details of the topic. This often results in vague or unhelpful explanations that do not fully engage with the core of the inquiry. Figure 12 provides an example of this misalignment. When the LLM is queried about the reasons why the Han City of Chang'an is now fully protected while the Tang Chang'an City has been partially developed with modern buildings, its response fails to provide a detailed or contextually accurate explanation. Instead, it provides a generic answer that disre- gards critical factors such as differences in levels of historical recognition, the role of tourism development, and the influence of urban planning policies [58]. This example underscores the limitations of LLMs in producing contextually relevant and precise responses to complex historical and cultural questions."}, {"title": "B. RQ2: Misalignment Rate", "content": "This section presents the findings for the second research question (RQ2), which focuses on the misalignment rate in LLM-generated texts for cultural heritage tasks. Specifically, there is a prevalent cultural value misalignment across all query tasks. Additionally, performance variability is observed across different aspects and LLM models.\n1) Prevalence: As shown in Table IV, Figure 14, Figure 13, and Figure 15, we can observe a widespread prevalence of value misalignments LLM-generated texts for cultural heritage tasks across all predefined aspects and different LLMs. Specif- ically, as highlighted in Table IV, the total misalignment rate for pre-defined aspects ranges from 30.16% for tasks within A3 on the Yi-6B model to 92.42% for tasks within A6 on the LLaMA-3-8B model. Notably, over 65% of the generated texts for cultural heritage tasks exhibit significant misalignments, with some tasks showing almost complete misalignment within key aspects of cultural values.\n2) Variability across cultural aspects: With the findings of prevalent value misalignments within LLM-generated texts for cultural heritage tasks, we further observe variability in LLMs' performance across different cultural aspects. As illustrated in Figure 13, all tested LLMs consistently demonstrate value misalignments across all cultural aspects. Notably, A10 regard- ing Representation and Communication, exhibits the highest misalignment rates, reaching up to 90%. In contrast, A3 regarding Cultural Landscape, shows the lowest misalignment rates at 70% for the LLaMA-3-8B model and 30% for other LLMs, which are still concerning. Similar observations can be drawn from the numerical results presented in Table IV.\n3) Variability across misalignment types: In addition, we can observe variability in LLMs' performance across dif- ferent misalignment types. For instance, Figure 14 clearly demonstrates that the most significant value misalignment type is VM8, referring to contextual irrelevance, followed by VM1, referring to detail inaccuracy. At the same time, LLMs generally perform best for VM4, referring to premature certainty. This observation remains consistent across various LLMs. Similar observations can be drawn from the numerical results presented in Table IV and Figure 15.\n4) Variability across models: Variability is also observed across various LLMs. Figures 14 and Figure 15 clearly show that cultural value misalignments are most prominent in text generated by the LLaMA-3-8B model, particularly in mis- alignment with VM1, referring todetail inaccuracy and VM8, referring to contextual irrelevance, compared to other models. The remaining four LLMs produce similar results, with the Mistral-7B model showing slightly better performance in value alignment for cultural heritage tasks. Similar observations are supported by the numerical results in Table IV."}, {"title": "V. DISCUSSIONS", "content": "In this section, we discuss the observations from the ex- perimental results on the value alignment performance of LLMs for cultural heritage tasks, highlighting implications and potential strategies to address cultural value misalignment for different participants throughout the LLM lifecycle."}, {"title": "A. Observations", "content": "The most straightforward observation is the prevalence of value misalignments in LLM-generated texts for cultural her- itage tasks, highlighting the urgent need for increased efforts in value alignment during the development and deployment of LLM services. This is particularly important given the growing number of users interacting with LLM chatbots daily for var- ious tasks. Cultural value misalignment in responses to users' queries can mislead their understanding of cultural heritage and related contexts, potentially causing long-term negative impacts on individuals, communities, and society as a whole. Furthermore, the observed variability of value misalignments across different aspects within the cultural heritage knowledge framework highlights the differing performance of LLMs on various topics and types of misalignment. This can serve as a guideline for prioritizing efforts in value alignment, such as constructing fine-tuning datasets that target specific topics and address particular cultural value misalignments. Additionally, the variability of value misalignments across different LLMs offers valuable insights into enhancing value alignment perfor- mance. This variability stems from differences in datasets, data processing techniques, and pre-training approaches used by various LLMs. Analyzing these technological methodologies could lead to effective strategies for improving value alignment in this specific area for cultural heritage tasks [59]."}, {"title": "B. Implications", "content": "Our research highlights the issue of cultural value mis- alignment in LLM-generated texts", "Users": "Although LLMs provide significant productivity gains, particularly in generating preliminary text drafts for cultural heritage tasks, our findings indicate that users must remain cautious about potential value misalignments in LLM-generated texts. Automated tools alone are inad- equate for producing content that preserves the integrity and value alignment of complex cultural narratives. Con- sequently, the involvement of domain experts is crucial to ensure cultural accuracy and contextual relevance in content created for public"}]}