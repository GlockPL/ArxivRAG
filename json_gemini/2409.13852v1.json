{"title": "Do language models practice what they preach? Examining language ideologies about gendered language reform encoded in LLMs", "authors": ["Julia Watson", "Sophia Lee", "Barend Beekhuizen", "Suzanne Stevenson"], "abstract": "We study language ideologies in text produced by LLMs through a case study on English gendered language reform (related to role nouns like congressperson/-woman/-man, and singular they). First, we find political bias: when asked to use language that is \"correct\u201d or \u201cnatural\", LLMs use language most similarly to when asked to align with conservative (vs. progressive) values. This shows how LLMs' metalinguistic preferences can implicitly communicate the language ideologies of a particular political group, even in seemingly non-political contexts. Second, we find LLMs exhibit internal inconsistency: LLMs use gender-neutral variants more often when more explicit metalinguistic context is provided. This shows how the language ideologies expressed in text produced by LLMs can vary, which may be unexpected to users. We discuss the broader implications of these findings for value alignment.", "sections": [{"title": "1 Introduction", "content": "Recent papers have discussed the values encoded in LLMs (e.g., Bender et al., 2021; Johnson et al., 2022; Santy et al., 2023). A topic that merits increased attention is the values they encode about language itself (Blodgett et al., 2020). Language ideologies are evaluative ideas or beliefs about language, such as ideas about what is \"correct\u201d, \u201cnatural\", or \"articulate\u201d (e.g., Kroskrity, 2004). Such views can embody value judgments not only about language per se, but about the social groups associated with certain language, with the potential to exhibit bias. Crucially, even without having beliefs or intentions, LLMs can produce language that reflects (potentially harmful) linguistic ideologies. For example, LLMs that assess underrepresented dialects as ungrammatical (e.g., Hofmann et al., 2024; Jackson et al., 2024), or that treat singular they for nonbinary people as incorrect (e.g., Cao and Daum\u00e9 III, 2020; Dev et al., 2021), can perpetuate marginalization of vulnerable groups. This highlights the importance of considering language ideologies for value alignment in NLP.\nLanguage ideologies are often expressed through metalinguistic statements, which are any statements that convey value judgements about language usage (Agha, 2003). It is notable that LLMs typically use metalinguistic statements in justifying their language choices, thus implicitly communicating language ideologies and their associated values. In light of this, we develop an approach for studying the language ideologies encoded in LLMs based on their word choices in metalinguistic contexts, as illustrated in Figure 1. We refer to these choices in LLMs as metalinguistic preferences.\nWe apply our method in a case study on gendered language reform. These reforms propose changes to language related to gender, and are ubiquitous in many languages and cultures (Sczesny et al., 2016). Language reform is ideal for studying language"}, {"title": "2 Overview of approach", "content": "Our case study on English gendered language reform builds on past work drawing on sociolinguistics to study this phenomenon in NLP (e.g., Cao and Daum\u00e9 III, 2020; Watson et al., 2023). In each of two sets of experiments, we examine lexical choices of LLMs in two domains. First, the domain of role nouns (e.g., congressperson/congresswoman/congressman) is a relatively well-established reform, originating in feminist movements, that recommends using gender-neutral variants (e.g., congressperson) for everyone. This reform aims at including marginalized gender groups - initially women (e.g., Ehrlich and King, 1992), and more recently nonbinary people (e.g., Zimman, 2017). Second, a more recent reform is in the pronoun domain use of gender-neutral singular they. This reform is focused on affirming individuals' gender identities (including nonbinary genders), and not making assumptions about what pronouns to use (e.g., Zimman, 2017). Both reforms involve use of gender-neutral variants, but differ in level of adoption in the language.\nOur first research question assesses political bias in use of these reforms:\nRQ1: Whose metalinguistic preferences do LLMs associate with positive qualities like \u201ccorrectness\" or \"naturalness\"?\nExtensive work in sociolinguistics and linguistic anthropology has documented how language ideologies around correctness are not neutral, but in fact are an expression of social structure and group identity (e.g., Irvine, 1989; Woolard and Schieffelin, 1994; Milroy, 2001; Kroskrity, 2004). To study this in LLMs, we compare their behaviour when prompted to use language with positive qualities like \"correctness\" or \"naturalness\" with their behaviour when asked to align with conservative vs. progressive perspectives; see example prompts in Figure 1a. We find that LLMs' metalinguistic preferences around gendered language reform implicitly communicate conservative language ideologies, which may discourage use of reform language. For example, use of inclusive language (a value associated with progressive language ideologies), which entails more gender-neutral choices, is generally not associated in the LLMs with positive qualities like \"naturalness\u201d or \u201cgrammaticality\".\nIn addition to bias, value alignment for language ideologies must also assess internal consistency:\nRQ2: Are LLMs consistent in their lexical choices within more vs. less metalinguistic contexts?"}, {"title": "3 General Methods", "content": "To answer our research questions, we require LLMs that allow access to token probabilities (unlike, e.g., ChatGPT). We tested nine widely-used and high-performing LLMs, differing in size and training regime (number of parameters in []'s): three GPT-3/3.5 models (GPT-3: text-curie-001 [175B], Brown et al., 2020; GPT-3.5: text-davinci-002, text-davinci-003 [~1.3B to 175B], Ouyang et al., 2022), three Flan-T5 models (small [80M], large [780M], xl [3B], Chung et al., 2022), and three Llama models (llama-2-7B [7B], llama-3-8B [8B], llama-3.1-8B [8B], Touvron et al., 2023; Dubey et al., 2024).\nGPT-3 and the Llama models are simple autoregressive models; all the others had some form of instruction finetuning, and text-davinci-003 also had reinforcement learning from human feedback.\nModel size may affect use of gender-neutral language (Hossain et al., 2023), and instruction finetuning can shape value alignment (Chung et al., 2022; Ouyang et al., 2022). The GPT and Flan-T5 models models were used in past work on LLMs' metalinguistic behaviour (Hu and Levy, 2023)."}, {"title": "3.2 Prompt Creation", "content": "To create test prompts, we first consider a core sentence that uses a target variant (a role noun or pronoun), adapted from stimuli used in psycholinguistics experiments. Examples of core sentences are shown in the first prompt of Figure 1b, and in quotes in the remaining prompts of Figure 1.\nFor role nouns, each of the 52 core sentences has the form [NAME] is a [ROLE-NOUN], in which the variants for [ROLE-NOUN] are one of 52 role noun sets we compiled from various sources (Vanmassenhove et al., 2021; Papineau et al., 2022; Bartl and Leavy, 2024; Lucy et al., 2024). Role noun sets like congressperson/congresswoman/congressman are an open class with many instances in English. We filter to have a controlled set, selecting role nouns that have one gender-neutral (reform) variant and two gendered variants, use the same determiner, and refer to an individual person, among other criteria; see details in Appendix A.1. Note that GPT models are evaluated on only 12 role nouns from Papineau et al. (2022) used in initial analyses; it is not possible to run analyses on the additional role noun sets, as the OpenAI Completions API removed access to token probabilities. We assume the GPT results on that subset of role nouns are comparable to the results on the full set for other models, since the other models perform similarly on the full and reduced sets (see Appendix B).\nFor singular pronouns, we use 40 sentences from Camilliere et al. (2021) that include a form of singular they (e.g., I hope that [NAME] isn't too hard on themself); we replace the pronoun with [PRONOUN] to form our templates. These templates are equally distributed between 4 different grammatical forms of the pronouns (i.e., subject, object, reflexive object, possessive: they/she/he, them/her/him, etc.), where the gender-neutral form is the reform variant. Details are in Appendix A.2.\nTo create a full prompt item, we include wrapper text that adds various metalinguistic information (or is null), depending on the experimental condition, and fill in a specific name for [NAME]; see Figure 1. We use 40 names from Camilliere et al., 2021: 20 gender-neutral and 20 gendered (10 mas-"}, {"title": "3.3 Calculating the Probability of Variants", "content": "In our experiments, we compare the probability of using a reform variant, as opposed to gendered variants, within the same prompt item i.e., the same core sentence + named antecedent (e.g., Casey is a [ROLE-NOUN]). To do this, we instantiate the prompt item i with each variant v in a variant set V (e.g., congressperson/congresswoman/congressman), and query the model separately for each variant to assess its probability in the given context, p(vi). We then use these probabilities to assess the relative probability of a reform (gender-neutral) variant vr:\n$$p(reform|i) = \\frac{p(v_r|i)}{\\sum_{v \\in V} p(v|i)}$$\nV is either the variant role nouns in a set (as in the example above) or the pronouns of a certain form (e.g., them/her/him).\u00b9 We next describe how we find p(vi) in the models.\nFor GPT and Llama models, we instantiate the prompt items with the relevant role noun/pronoun variants, and compute probabilities of the tokens in the sentence. Here, the probability of each token is conditioned on the preceding input in the prompt. When the variant is at the end of the prompt (as in Figure 1a), we simply take the product of the probabilities of tokens corresponding to the variant to get the probability p(vi). When the variant is not at the end of the prompt (as in the first example in Figure 1b), we need to ensure that p(vi) reflects the full context of prompt i. Following Salazar et al. (2020) and Hu and Levy (2023), we set p(v|i) to the product of the probabilities of all tokens in i.\nFor Flan-T5 models, we can obtain probabilities for the variants that are conditioned on all tokens in the prompt in the same way for all conditions. In these models, an input/output pair can be formulated such that the input indicates that the model should predict a span of token(s) at a designated location (using a \u201csentinel\u201d token), and the output indicates what to predict in that location. For a given prompt item i, we create a set of input/output pairs for the associated variant set V: each of the inputs is the same prompt, and each of the outputs is a variant v in V (e.g., they, he, she). We then calculate p(vi) as the product of the probabilities of the tokens corresponding to v in the output."}, {"title": "4 Experiment 1: Political bias", "content": "Here, we address RQ1 by assessing whether LLMs align more with progressive or conservative perspectives when prompted to use language with positive metalinguistic qualities like \u201ccorrect\u201d or \u201cnatural.\u201d Because we are interested in language ideologies, we want to consider how responses to such prompts align with not only political group labels but also political values.\nTo do this, we draw on sociolinguistic work on stancetaking: Language choices are associated with stances (how speakers position themselves toward a topic Du Bois, 2007), which are in turn associated with identity groups (Ochs, 1993; Eckert, 2008), such as political groups. For instance, gender-neutral forms like congressperson are associated with the stance that inclusive language is important, which is in turn associated with progressives (Papineau et al., 2022). Thus, examining stances helps give a more complete picture of the values associated with correctness/naturalness in LLMs. Here we extend prior work on stance in NLP (Kiesling et al., 2018; Aggarwal et al., 2023), to assess bias in language ideologies encoded in LLMs: we examine both what groups and what stances a model associates with positive metalinguistic qualities.\nConcretely, we compute LLMs' rates of reform language when prompted to use language with positive metalinguistic qualities like \u201ccorrectness\u201d or \"naturalness\", and compare that to its behavior when asked to sound \"conservative\u201d/\u201cprogressive\", or to use language in line with associated political stances. If the presence of the positive adjectives produces rates of reform language closer to prompts containing a given political group label or its associated stances, the language ideology encoded in the LLM is biased in that direction."}, {"title": "4.1 Evaluation approach", "content": "Here, we begin by inserting our sentence templates into the text The best word to complete the sentence \"...\" is [ ]. This makes for a simple metalinguistic task (completing a sentence), which also includes a value judgement (assessing what is best). In addition, we prepend various preambles to this basic prompt to create our experimental conditions, using statements of the form Assume you want to sound.../to use language that is.... These preambles are the same across both domains.\nWe can then determine which of the two political group prompts the positive metalinguistic prompts are most similar to. First, for each model, we run a two-tailed paired t-test over the pairs of dt (prog, meta) and dt (cons, meta) values for core sentence+name templates. If the t-test is significant, then either p(reform|tprog) is closer to p(reform|tmeta), or p(reform tcons) is closer to p(reform|tmeta). Say cons is closer; in that case, the model associates the positive metalinguistic qualities with \u201csounding conservative\u201d, showing a conservative bias in the language ideology it encodes. (If they are not significantly different, we assume there is no bias.)\nWe analogously compute dt(prog-stance, meta) and dt(cons-stance, meta), replacing prog/cons in Figure 2 with prog-stance/cons-stance preambles. We then test which stance group has more similar behavior to the positive metalinguistic qualities, again assessing model bias.\nThroughout the paper, we consider results of stats tests to be significant at the p < 0.05 level, Bonferroni-corrected for number of models."}, {"title": "4.2 Results", "content": "Recall that we are assessing political bias in LLMs in statements about correctness and other positive metalinguistic qualities. Figure 3 shows the results of our statistical tests of whether prog or cons prompts, and similarly prog-stance or cons-stance prompts, yield behavior most similar to the prompts for positive metalinguistic qualities. The figures show, for each domain, the aggregated mean reform rates (across all prompt items) of the relevant prompt groups. A colored line connecting a metalinguistic qualities icon and a political group/stance icon indicates a statistically-significant political bias. More fine-grained visualizations of rates of reform language per prompt, are shown in Appendix D.3 for all nine models.\nFor political group prompts, we find different patterns across domains: for role nouns, the results are mixed (Figure 3a), while for singular pronouns, the positive metalinguistic qualities pattern most like the conservative prompts (Figure 3b). The degree of adoption of the two reforms may drive this behaviour: Role noun reforms are more widely adopted, and thus seen as more \u201cstandard\u201d or \u201ccorrect\" regardless of political position. Singular they is much less accepted, such that the positive metalinguistic qualities have very low rates of reform language, in line with \u201csounding conservative\u201d.\nFor political stance prompts, we find that the metalinguistic qualities behave more like conservative prompt groups in almost all cases (Figure 3c,d). This is largely due to prog-stance prompts having higher rates of reform language than prog prompts. This highlights how examining stances which foreground the values that may be associated with political groups \u2013 sheds light on the meaning behind variation in reform usage.\nIn sum, text expressing language ideologies about correctness, and other positive qualities, exhibits a conservative bias in LLMs. This highlights how metalinguistic preferences in LLMs \u2013 which may seem politically neutral can exhibit bias."}, {"title": "5 Experiment 2: Internal consistency", "content": "Another important issue for value alignment of language ideologies is internal consistency. Here, we assess whether LLMs' word choices related to language reform are consistent across contexts that vary in how metalinguistic they are (RQ2). Specifically, inspired by work on human usage of reform variants, we ask whether LLMs use more reform language in more metalinguistic contexts."}, {"title": "5.1 Evaluation approach", "content": "We manipulate how strongly metalinguistic the prompts are by varying the wrapper text. We consider contexts to be more metalinguistic if they more strongly highlight values around linguistic choices. First, we vary the ways of asking the LLM to respond. Inspired by Hu and Levy (2023), we contrast indirect, metalinguistic prompts like those from Experiment 1 (e.g., The best word to complete the sentence \u201cHayden left computer on.\" is [PRONOUN]) with sentences that use target items directly (e.g., Hayden left [PRONOUN] computer on.) We call this manipulation indirect.\nWithin the indirect conditions, we further vary how explicitly metalinguistic the prompt is, using two variables: the adjective (likely/best) and the verb (complete/refer), where best and refer are more metalinguistic (alluding more to language ideology): best asks for a value judgment, and refer highlights that a person is being labeled, evoking values around gendered language choices. Table 2 gives examples of each combination.\nSecond, we include preamble conditions that provide additional contexts that vary in how metalinguistic they are; examples are in Table 3. The choices condition is more metalinguistic than the null condition, by highlighting alternative linguistic options that could be selected. The individual-declaration and ideology-declaration prompts are more metalinguistic still because like the stance prompts from Exp. 1 they highlight motivations for using different variants. Here we use preambles that consistently motivate using gender-neutral/reform choices, such as Hayden uses they/them pronouns or asking for language that is gender inclusive (cf. Hossain et al., 2023 prompts assessing agreement with pronoun declarations). The preambles are prepended to ways-of-asking prompts in Table 2."}, {"title": "5.1.2 Statistical analyses", "content": "To assess the effect of these manipulations, for each LLM, we run a beta regression test (a multiple regression test for cases where the dependent variable is a probability; Ferrari and Cribari-Neto, 2004):\np_reform ~ indirect + best + refer + choices + ind_dec + ideo_dec + (1 item) + (1|name)\nExperimental conditions are coded as binary predictors. For ways of asking, we treat the direct condition as a baseline, and include predictors indirect, best, and refer; for preambles, we treat the null condition as a baseline, and include predictors for choices, ind_dec, and ideo_dec. We include random intercepts for core sentences ((1|item)) and referent names ((1|name))."}, {"title": "5.2 Results", "content": "Recall that we are assessing consistency in the use of reform language, and in particular, expect that LLMs may use more reform language in more metalinguistic contexts. Results are shown in Table 4. A positive (vs. negative) coefficient for each predictor indicates more (vs. less) usage of reform variants given metalinguistic info in the prompts. We see that most of our experimental factors are significant across the various models, indicating that LLMs are inconsistent in their use of reform language across varying amounts of metalinguistic context. (This is further shown in the actual reform rates; see Appendix E.1.)\nFor the GPT and Llama models, many conditions show the specifically predicted pattern of more reform responses given more metalinguistic information, in both role noun and singular pronoun domains. Crucially, this holds not only for metalinguistic conditions that are related to inclusivity or gender (individual-declaration and ideology-declaration), but also for metalinguistic conditions that highlight the lexical choice being made (best and choices).\nOne exception is that the indirect predictor predicts less reform variant usage in several cases. This might be partly due to the nested structure of the indirect predictors (where best and refer carve out subsets of indirect.) A second exception is that refer (which is more metalinguistic than complete) has mixed results for role nouns, but consistently predicts less reform variant usage in the singular pronoun domain. This may reflect the different stages of the two reforms: for role nouns, a gender-neutral default is more widely accepted than for pronouns. Using refer for pro-"}, {"title": "6 Related computational linguistic work", "content": "Recent papers have emphasized the need for gender-inclusive approaches in NLP (Cao and Daum\u00e9 III, 2020; Devinney et al., 2022; Lauscher et al., 2022), and examined the real-world harms that gender-exclusive language technology can cause (Dev et al., 2021). Past work has highlighted how NLP struggles with gender-inclusive language, across various domains and languages (Baumler and Rudinger, 2022; Brandl et al., 2022; Amrhein et al., 2023; Hossain et al., 2023; Lauscher et al., 2023; Lund et al., 2023; Ovalle et al., 2023; Piergentili et al., 2023; Savoldi et al., 2023; Watson et al., 2023). Here, we contribute to this growing body of research by assessing models' metalinguistic preferences around gender-inclusive language, connecting to research on language ideologies.\nIn addition, our focus on gendered language reform a case of socially-relevant variation in word usage - brings a new lens to research on metalinguistic statements in LLMs. Previous research has developed a metalinguistic question answering dataset (Behzad et al., 2023), and has assessed some metalinguistic capabilities of LLMs (Begu\u0161 et al., 2023; Thrush et al., 2024). Most relevant to our work, Hu and Levy (2023) showed that LLMs\u2019 preferences in general language are more accurate than in metalinguistic contexts, and Dentella et al. (2023) found that LLMs struggle with metalinguistic questions. Here, we show that LLMs' metalinguistic preferences are not simply noisier versions of their general language use: because metalinguistic judgments are associated with language ideologies, LLMs' responses to such statements may communicate meaningful social information."}, {"title": "7 Discussion", "content": "In a case study on gendered language reform, we explore our approach for assessing how word choices in LLMs are shaped by metalinguistic contexts, reflecting particular language ideologies.\nIn RQ1, we show how LLMs' metalinguistic preferences concerning qualities like \u201ccorrectness\" may seem neutral, but can signal language ideologies associated with particular political views, with potential to reinforce marginalization of social groups (here, nonbinary people and women). In RQ2, we find that LLMs are inconsistent in their use of reform language between more vs. less metalinguistic contexts, which may be misleading to users. While our specific results are limited to gendered language reform in English, our approach is generalizable to other examples of language reform, which involve language choices motivated by social values.\nThe adoption of language reform is often achieved through metalinguistic statements communicating language ideologies about the reform language. Thus, increased use of (conservatively biased and inconsistent) LLMs for language tasks may shape people's attitudes and adoption of reform language in unexpected ways. Future work should complement our controlled experiments, studying how such effects play out in naturalistic user scenarios (e.g., drafting or revising text).\nBoth of our results have implications for value alignment in LLMs. First, our findings from RQ1 show that seemingly innocuous statements about language may implicitly communicate social values that need to be considered. Second, findings from RQ2 suggest a need for value alignment strategies to consider both the word choices of an LLM and its metalinguistic statements about those word choices, in order to truly assess whether it is aligned with target values. These two insights are necessary for working towards a comprehensive approach to language ideologies in value alignment for LLMs."}, {"title": "8 Limitations", "content": "Because we study language ideologies and values encoded in LLMs, limitations of our approach have ethical ramifications. With this in mind, we discuss both limitations and risks in this section."}, {"title": "8.1 Language and domains", "content": "We focus on gendered language reform in English, specifically, the domains of role nouns and singular pronouns. One limitation is that our results might not generalize to other language reforms in English, such as address terms, generalizations about gender (Zimman, 2017), and neopronouns (Lauscher et al., 2022; although our singular pronoun prompts are extendible to these).\nMany other languages have ongoing language reform related to gender. Our focus on English, and on the US political context, introduces two further risks of non-generalizability. First, the targeted linguistic domains may be different in other languages (e.g., grammatical gender, cf. Sczesny et al., 2016). Second, the metalinguistic values might be particular to the US English-speaking context (e.g., see Brandl et al., 2022, for work on gendered language reform in Swedish)."}, {"title": "8.2 Stimuli", "content": "Our use of a fixed set of stimuli allowed us to conduct a controlled analysis, but came with some limitations. First, a model may perform differently on similar stimuli (Delobelle et al., 2022). Second, controlled stimuli may not reflect the kind of metalinguistic questions people ask LLMs. Future work would benefit from studying how metalinguistic statements related to gendering come up when people interact with LLMs in naturalistic settings.\nThe particular stimuli we selected furthermore present a risk of prioritizing the study of certain linguistic contexts over others. As we studied English names popular in a US context, it remains to be seen if the results generalize to an ethnically/culturally more diverse set of names. Our prompt wrappers in RQ1 and RQ2 reflect a finite set of ways in which we anticipated models would behave differently, thus risking unforeseen results when considering different relevant social groups and their stances (RQ1; see e.g., Felkner et al., 2023 for a discussion of anti-LGBTQ+ bias in LLMs); different stances for the two political groups considered (as stances may vary, even within a political group; Jiang, 2023); or different preambles and ways of asking (RQ2)."}, {"title": "8.3 Models", "content": "Our model selection constitutes a final set of limitations. Considering only a fixed set of nine models, there is a risk of non-generalizability. However, we considered different architectures (GPT, Flan-T5, and Llama models), as well as model sizes.\nWith regard to the GPT models, the documentation provided by OpenAI provides limited insight into model training. Additionally, the GPT Completions API is now deprecated for the models we studied, which makes our results difficult to reproduce for those models. Furthermore, as discussed in Hu and Levy (2023), OpenAI has removed information about token-level probabilities from the completions API for GPT-3.5 models, which prevents NLP researchers from thoroughly evaluating these highly popular and impactful models."}, {"title": "9 Ethics", "content": "A primary contribution of this work is highlighting ethical issues surrounding metalinguistic statements. To do this, we developed new methods for studying language ideologies in LLMs. Ethics details related to stimuli and code are below."}]}