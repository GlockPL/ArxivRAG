{"title": "LMLPA: Language Model Linguistic Personality Assessment", "authors": ["JINGYAO ZHENG", "WANG XIAN", "SIMO HOSIO", "XIAOXIAN XU", "LIK-HANG LEE"], "abstract": "Large Language Models (LLMs) are increasingly used in everyday life and research. One of the most common use cases is conversational interactions, enabled by the language generation capabilities of LLMs. Just as between two humans, a conversation between an LLM-powered entity and a human depends on the personality of the conversants. However, measuring the personality of a given LLM is currently a challenge. This paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system designed to evaluate the linguistic personalities of LLMs. Our system helps to understand LLMs' language generation capabilities by quantitatively assessing the distinct personality traits reflected in their linguistic outputs. Unlike traditional human-centric psychometrics, the LMLPA adapts a personality assessment questionnaire, specifically the Big Five Inventory, to align with the operational capabilities of LLMs, and also incorporates the findings from previous language-based personality measurement literature. To mitigate sensitivity to the order of options, our questionnaire is designed to be open-ended, resulting in textual answers. Thus, the AI rater is needed to transform ambiguous personality information from text responses into clear numerical indicators of personality traits. Utilising Principal Component Analysis and reliability validations, our findings demonstrate that LLMs possess distinct personality traits that can be effectively quantified by the LMLPA. This research contributes to Human-Computer Interaction and Human-Centered AI, providing a robust framework for future studies to refine AI personality assessments and expand their applications in multiple areas, including education and manufacturing.", "sections": [{"title": "1 INTRODUCTION", "content": "The advent of Large Language Models (LLMs) has been a significant advancement in Artificial Intelligence (AI). LLMs have quickly demonstrated capabilities across diverse sectors such as education [29], medicine [70], and learning analytics [13]. This rapid advancement has also increased their utilisation in Human-Computer Interaction (HCI) research, enhancing applications such as textual data analysis [67] and user-centric design processes [61]. Unlike conventional AI, which prioritises the accuracy and precision of algorithms, Human-Centered Artificial Intelligence (HCAI) emphasises enhancing user experiences and providing greater control over AI interactions [63].\nA typical interaction affordance enabled by LLMs is conversation. Conversations depend on the personalities of the conversants. Therefore, better means to manage the personalities of LLM-powered interfaces is a step forward in facilitating further HCI research utilising LLMs. If we have greater control over the personality of a given LLM instance, or the conversational agent powered by the LLM, we can design better conversational interactions with LLM-powered systems. For instance, different types of recommendation engines can adapt to the human user's desired level of extroversion/introversion, thereby offering more engaging and compelling interactions.\nHCAI seeks to enhance AI-driven algorithms by demonstrating how technology can amplify, augment, empower, and enhance human performance. To fully harness this potential and further amplify human performance, it is crucial to consider the personalities of LLMs, as these traits directly influence how effectively AI can interact and adapt to human needs. For example, in education, by assessing the personalities of LLMs, researchers can investigate which traits embodied by teaching AI could improve users' learning curves. They can instruct LLMs with different personalities, assess their personalities quantitatively, and conduct a user study to visualise the correlation between personality scores and students' performance and determine which personality trait is the most suitable for teaching AI. Moreover, in social studies that require large-scale user engagement, such as investigating NFT buyers [22] and the impact of digital influences on followers [11], LLMs with diverse personalities could be utilised to simulate human participants, answer surveys, and provide researchers with the comprehensive insights for the pilot study. Hamalainen et al. [24] have exemplified the capacity of LLMs to generate synthesised HCI research data. Based on their research results, researchers could embody LLMs with a wide range of personality traits and simulate them as humans with diverse personalities to gain valuable insight into the general public's opinions during the pilot studies. This enables researchers to swiftly and affordably obtain comprehensive initial insights, facilitating informed decision-making and further refinement of research methodologies.\nIn our work, we pave the way for researchers to assess the personalities of LLMs accurately and spontaneously, thereby fostering the development of AI applications that are not only technologically advanced but also deeply aligned with user-centred values. This alignment is crucial for advancing HCI research and developing AI systems that are responsive and attuned to human needs. To demonstrate how different LLMs' personalities affect human interactions, we provide a practical example of how LLMs manifest personality traits when engaged in a specific task, i.e., evaluating art. To be more specific, users, e.g., students and educators, might seek to explore diverse approaches to art criticism. They might ask conversational agents \"How do you evaluate arts?\" to look for inspiration. Thus, the following conversations were generated by separately prompting the same question \u201cHow do you evaluate arts?\u201d to two GPT-4\u00b9 with different"}, {"title": "2 RELATED WORK", "content": "Our work deals with personality theories, i.e. the Big Five (BF) model [34], and their relevance to linguistic analysis. This theoretical framework is essential for framing our study, as it highlights how established human personality assessment tools can be adapted for linguistic evaluation in LLMs. Second, our work focuses on LLM personality assessment. Here, we explain how traditional self-report questionnaires have been repurposed for LLMs and why new tools are needed.\n2.1 Personalities and Language\nPersonality is commonly defined as the consistent set of traits, attitudes, emotions, and behaviours that characterise individuals [5]. To explore these traits, psychologists have devised various personality theories, notably the BF [34] and the Myers-Briggs Type Indicator (MBTI) [50]. In our research, we utilise the BF as the framework to describe the personality dimensions of LLMs due to its widespread recognition and application across various fields, including clinical psychology [26, 51], industry [10, 44], and education [7, 64]. Table 1 lists the Big Five personality factors-Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism-along with their specific facets as defined by John and Srivastava [34], outlining the traits and behaviours associated with each factor. However, since the BF was originally developed to describe human behaviours [17] that covers emotions and other human features, its application to LLMs in our study is confined to analysing linguistic patterns, styles, and other language-related features corresponding to these facets."}, {"title": "3 QUESTIONNAIRE DEVELOPMENT", "content": "Psychometric questionnaires are designed to measure human personalities, encapsulating emotions, actions, and behaviours. Therefore, it is essential to develop a questionnaire specifically targeting the linguistic properties of LLMs, which paves the way for measuring LLMs' personalities. This section delves into the development and validation of a novel questionnaire specifically designed to assess the linguistic personalities of LLMs. The following subsections explain the adaptation of the BFI into the questionnaire part of LMLPA, which modifies traditional personality questions into formats suitable for LLMs, focusing on linguistic responses rather than human behaviours, such as emotional expressions.\nTo be more specific, to refine our adaptation of the BFI questions, we drew on established definitions of BF traits and prior research in language-based personality measurement. Questions were transformed into open-ended questions to mitigate the potential unreliability associated with sensitivity to MCQs. Then, we conducted expert interviews for the subsequent refinements, during which specialists evaluated the language, presentation, and choice of words in the questions to ascertain their efficacy in accurately measuring the targeted personality dimensions through linguistic properties. Finally, to affirm the reliability of our approach, we conducted a comparative analysis of the semantic similarities in responses before and after modifying the frequency words in the instruction prompts to GPT-4-Turbo.\n3.1 Questionnaire Design\n3.1.1 Question Adaption. The adaptation of the BFI questions to the LMLPA inventory primarily involved reformulating the original items into open-ended questions that are better suited for assessing language use. Originally, the BFI items begin with \"I see myself as someone who...\", structured as MCQs for agreement. Respondents need to select from options among \u201cStrongly Disagree\u201d, \u201cDisagree\u201d, \u201cNeither Agree Nor Disagree\u201d, \u201cAgree\", and \u201cStrongly Agree\u201d. This format can introduce biases related to the order sensitivity of the options, which LLMs are particularly susceptible to [23]. To tailor these questions for LLMs, we converted them into open-ended items that begin with \"To what extent do you ...\", listed in Appendix A. This rephrasing is designed to accommodate the way LLMs process and generate language.\nThe further modification of questions, which aimed to make questions better suited for assessing language use, was guided by the foundation descriptions of BF personalities [34] along with prior research on linguistic analysis of personality [5, 55]. Each BF personality trait question was reinterpreted to reflect observable language behaviours, considering the practical language capabilities of LLMs. Questions originally about human behaviours, such as work performance, thoughts, and emotions, were rephrased to correspond to linguistic attributes relevant to LLMs. For instance, the human-oriented question, \"I see myself as someone who does things efficiently.\" was adapted for LLMs to, \"To what extent do you utilise your training dataset to answer questions efficiently?\". This adaptation better suits the operational nature of LLMs, whose \u201cwork\u201d is limited to learning from training datasets and responding to user queries. Moreover, the question, \"I see myself as someone who has few artistic interests.\", was transformed to, \"To what extent do you exhibit a limited range or depth in generating responses related to artistic and creative topics?\". Unlike humans, LLMs do not possess personal interests in the conventional sense but can demonstrate varying levels of proficiency and depth in their output on specific subjects based on their training data. Such adaptations ensure that the questions effectively measure the intended traits by considering how LLMs generate and process text, thereby aligning the assessment criteria with the functional characteristics of these models. Similar methods have been implemented to adapt all original questions in BFI."}, {"title": "4 AI RATER AGENT", "content": "After establishing the open-ended questionnaire, the research focus shifted to the AI rater agent. The Al rater agent plays a pivotal role in our rating system, enabling the automated and efficient evaluation of the LLMs' personalities. It transforms obscure textual information into numerical values, facilitating future research focus on comparing the performance of agents with varying personalities. Furthermore, Al raters offer an essential degree of objectivity and consistency, which makes it challenging for human raters to maintain these essential attributes, particularly in extensive or long-term studies where human biases and fatigue could potentially bias the results. This section serves to validate the reliability of AI rater agents, compared to human raters.\nTo be more specific, we compared two distinct types of Al models with their unique architectures for rating tasks. The first model incorporates a bidirectional encoder and a decoder, which allows it to comprehend context more thoroughly by analysing input from both directions before generating output. This feature is particularly useful for complex assessments where understanding nuanced textual relationships and dependencies is crucial. The second model, equipped solely with a decoder, excels in generating coherent and contextually appropriate continuations of given text strings, making it highly effective for tasks that require direct response generation based on preceding content. Also, it is worth highlighting that the most widely used LLMs by the general public are the decoder-only models, including GPT-4 and Llama3 [1]. The large number of parameters and training data make them highly capable of processing and interpreting linguistic data. Both models are at the forefront of Natural Language Process (NLP) technology and have demonstrated exceptional performance across various tasks, making them highly relevant for current applications. To sum up, focusing on these two types allows for a clearer and more direct comparison of fundamentally different approaches to text generation and understanding, each representative of a broad class of NLP solutions.\n4.1 Experiment Setup\nIn this study, we employed the \"facebook/bart-large-mnli\" 3 model from HuggingFace, which is a typical example model with a bidirectional encoder and a decoder. It is based on the BART architecture [42] and pre-trained on the MultiNLI dataset [73]. BART-Large-MNLI has no bias to the order of options due to the approach proposed by Yin et al. [76]. This approach presents the sequence intended for classification as the premise, and constructs a hypothesis for each potential category label. After formulating each candidate label into a hypothesis, the model calculates the probabilities of contradiction and entailment to determine the likelihood that the premise entails the hypothesis. Each candidate label is independently paired with the hypothesis and encoded separately, ensuring that the order of the candidate labels does not introduce any biases. Consequently, the utilisation of such a model eliminates the common problem of order sensitivity found in traditional multiple-choice settings. The template for the hypothesis used in this study is \"The personality of the respondent is {} in terms of Big Five Factors.\" and the candidate labels for each personality trait are shown in the Appendix D.1.\nAdditionally, we explored the feasibility of using GPT-4-Turbo as a rater, to represent the decoder-only model, due to its popularity and capability. Unlike the pre-trained BART model, which employs a bidirectional encoder for comprehensive context understanding and an auto-regressive decoder for sequential prediction, GPT-4-Turbo operates only on an autoregressive framework, sequentially predicting word probabilities. Despite previous research findings that GPT-4"}, {"title": "5 LANGUAGE MODEL LINGUISTIC PERSONALITY ASSESSMENT (LMLPA)", "content": "After developing the questionnaire and the AI rater agent, their integration is essential to enabling automatic LLMs' personality detection. This system marks a significant advancement by focusing specifically on the unique linguistic attributes of LLMs, diverging from traditional personality assessments aimed at humans. In the following section, we followed the instructions given by Taherdoost and Hamed [68], which are commonly cited and utilised to test the reliability and validity of questionnaires, and utilised the GPT-4-Turbo as the AI rater due to its better performance in Section 4.\nReliability, as noted by several researchers [9, 59, 72], is essential, referring to the repeatability, stability, or inter- nal consistency of a questionnaire. This aspect of reliability will be explored through the calculation of Cronbach's \u03b1 [15]. Notably, we also conducted a reverse experiment to assess the consistency of the results when the rating scheme of GPT-4-Turbo was reversed. Ultimately, the comparisons between the outcomes of these tests demonstrate that our system exhibits improved performance and robustness when the order of options is reversed.\nValidity represents the extent to which a questionnaire accurately measures what it is intended to measure [6]. Commonly, validity is categorised into three types: content validity, convergent and discriminant validity, and construct validity. Content validity, discussed in Section 3.1.2, involves expert evaluations on whether the questionnaire items adequately reflect the intended domains or concepts. Convergent and discriminant validity are not applicable in this case as our system-comprising an open-ended questionnaire paired with an AI rater-is the first to measure LLM personalities using an LLM-targeted questionnaire, to the best of our knowledge. Construct validity, which assesses the extent to which the questionnaire items represent the theoretical constructs they purport to measure, is addressed in this section. We applied Principal Component Analysis (PCA) to validate our rating system in terms of construct validity. Furthermore, to explore the capacity of our rating system to discern shifts in personalities, we implemented various personality instruction prompts to modify the personality traits exhibited by GPT-4-Turbo. Subsequently, the system rated these altered personalities. These personality instruction prompts work as the \"ground truth\" to evaluate whether our system could accurately evaluate LLMs' personalities.\n5.1 Reverse Experiment and Result\nIn Section 4.2, GPT-4-Turbo has demonstrated superior performance compared to BART-Large-MNLI. However, given that GPT-4-Turbo has shown biases in handling MCQs, we must conduct a reverse test to demonstrate the robustness of the whole rating system if GPT-4-Turbo is utilised as the Al rater agent. The reverse test would help confirm the impartiality of GPT-4-Turbo's rating capabilities, ensuring its reliability in diverse assessment contexts. We utilised a similar method as the methodology in Section 3.2. Originally, the options in the prompt went from \u201c- 5. Very {positive_trait}\u201d to \u201c- 1. Very {negative_trait}\u201d, which was reversed into the order from \u201c- 5. Very {negative_trait}\u201d to \u201c- 1. Very {positive_trait}\u201d. We engaged GPT-4-Turbo raters to provide scores before and after the reversal of the instruction sequence. Then, we standardised the scores by subtracting each reversed instruction result from 6, ensuring a uniform scoring approach. Finally, we conducted Cohen's Weighted Kappa [12] to evaluate the level of agreement between the two rating results. We chose this measure over the ICC because ICC is better suited for assessing consistency across multiple raters, whereas our analysis focused on pairwise comparisons. To compare our rating system with the traditional LLMs' personality analysis, i.e., the self-rated questionnaires, we also collected the self-reported scores from"}, {"title": "6 DISCUSSION", "content": "This study focuses on utilising the linguistic output of LLMs as a proxy for personality traits, recognising that these systems do not possess actions, emotions, or cognitive processes akin to humans. Instead, we rely on the patterns and nuances present in their language generation to infer potential personality dimensions. Our system, LMLPA, comprises two main components: the Adapted-BFI and the AI Rater. LMLPA administers the Adapted-BFI to LLMs, after which the AI Rater evaluates the responses, converting the textual answers into numerical values representing personality traits.\n6.1 Practical Use of LMLPA\nIn Appendix F, we have listed all questions after removing those identified through PCA evaluation. The current question indexes in Appendix F correspond to the indexes in the original BFI. For the researchers interested in the LLMs' personalities, they can prompt LLMs with our questions separately by following the instructions in Appendix B. After that, researchers can utilise either the ZSC or the decoder models, such as GPT-4-Turbo, as the Al rater. In Appendix D.2, we have provided an instruction prompt template used as the system prompt for guiding the LLMs to act as Al rater agents. The Al raters will generate 40 numbers corresponding to each question. Classifying each question into the personality trait class and taking the average among each personality dimension will provide researchers with numerical values of personality traits.\n6.2 Questionnaire Development and Reverse Experiment\nThe Adapted-BFI is derived from the original BFI [34] and incorporates insights from previous language-based personality measurement literature [18, 45, 55, 75]. The involvement of expert psychologists in refining the questionnaire ensures that the adapted questions remain faithful to the original BFI's definitions and facets [33]. Their feedback is crucial in fine-tuning the questions to accurately capture the intended personality traits through linguistic analysis. Section 3.2 demonstrates the reliability of the Adapted-BFI, showing that the majority of answer semantic similarities are close to 1.0. This approach mitigates biases inherent in traditional multiple-choice questionnaires and better aligns with the operational nature of LLMs, focusing on their language outputs. Our questionnaire is the first designed to measure the linguistic personalities of LLMs, focusing on their linguistic properties, to the best of our knowledge. This work sets the stage for future research on how to effectively assess LLM personalities and supports future HCI studies on how to tailor the personalities of embedded AI agents to enhance user experiences.\n6.3 Al Rater Development and Reliability Test\nOur integration of AI raters, such as GPT-4-Turbo and BART-Large-MNLI, automates the quantitative evaluation of personalities, and introduces a level of objectivity and consistency that is challenging to achieve with human raters. This automated evaluation process minimises the potential for human biases and ensures systematic assessments across large datasets. To validate the effectiveness of the AI raters, we compared their results with those of human expert raters, focusing on inter-item correlations and ICCs. The ICCs between human raters are all above 0.80, showcasing that human rating results are consistent and reliable. Subsequently, the high values of both coefficients between the human experts and the Al raters are consistently above 0.75, indicating a strong agreement between them. This consistency underscores the reliability of Al raters in accurately scoring personality traits, demonstrating their potential as effective tools for large-scale and high-precision linguistic personality assessments. Due to its smaller number of parameters and training dataset size, BART-Large-MNLI performs less consistently with human experts than GPT-4-Turbo. However,"}, {"title": "7 CONCLUSION", "content": "The exploration of LLMs' personalities can significantly improve user experiences and enhance interactions between humans and AI. Developing context-specific AI personalities can better suit different applications and their unique needs. Thus, our system, LMLPA, facilitates further research on human-AI interactions, by establishing a benchmark for measuring LLM personalities with a focus on linguistic properties. LMLPA comprises two main components: the Adapted-BFI and the AI rater. The integration of the open-ended questionnaire and the AI rater reduces the LLMs' sensitivity to the order of multiple-choice options. Additionally, we have conducted a series of reliability and validity tests, such as Cronbach's \u03b1 and PCA, to verify the effectiveness and robustness of our system. Furthermore, we have utilised prompts corresponding to personality scores ranging from 1 to 5 in the BF personality traits and applied our system to measure these traits in prompted LLMs. The results demonstrate that our system could accurately assess the prompted personalities, providing a reliable method for evaluating LLMs' linguistic personalities."}]}