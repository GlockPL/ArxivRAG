{"title": "R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models", "authors": ["Aladin Djuhera", "Vlad C. Andrei", "Xinyang Li", "Ullrich J. M\u00f6nich", "Holger Boche", "Walid Saad"], "abstract": "Split federated learning (SFL) is a compute-efficient paradigm in distributed machine learning (ML), where components of large ML models are outsourced to remote servers. A significant challenge in SFL, particularly when deployed over wireless channels, is the susceptibility of transmitted model parameters to adversarial jamming that could jeopardize the learning process. This is particularly pronounced for word embedding parameters in large language models (LLMs), which are crucial for language understanding. In this paper, rigorous insights are provided into the influence of jamming LLM word embeddings in SFL by deriving an expression for the ML training loss divergence and showing that it is upper-bounded by the mean squared error (MSE). Based on this analysis, a physical layer framework is developed for resilient SFL with LLMs (R-SFLLM) over wireless networks. R-SFLLM leverages wireless sensing data to gather information on the jamming directions-of-arrival (DoAs) for the purpose of devising a novel, sensing-assisted anti-jamming strategy while jointly optimizing beamforming, user scheduling, and resource allocation. Extensive experiments using BERT and RoBERTa models demonstrate R-SFLLM's effectiveness, achieving close-to-baseline performance across various natural language processing (NLP) tasks and datasets. The proposed methodology further introduces an adversarial training component, where controlled noise exposure significantly enhances the LLM's resilience to perturbed parameters during training. The results show that more noise-sensitive models, such as RoBERTa, benefit from this feature, especially when resource allocation is unfair. It is also shown that worst-case jamming in particular translates into worst-case model outcomes, thereby necessitating the need for jamming-resilient SFL protocols.", "sections": [{"title": "I. INTRODUCTION AND MOTIVATION", "content": "Future 6G networks are anticipated to introduce a substantial leap toward highly integrated and intelligent connectivity at the edge, enabled by artificial intelligence (AI) [1] and machine learning (ML) [2]. However, in this envisioned hyper-connected and AI-assisted network, important questions and stringent requirements on resilience and trustworthiness arise, both from a user and network perspective [3]. This imposes significant design challenges for emerging technologies, such as distributed and collaborative ML (DCML) [4], which may be targeted by adversarial attacks over the wireless medium. For instance, the distributed training of large language models (LLMs) faces unique challenges in ensuring data integrity and model robustness due to highly sensitive word embedding parameters. Much research has focused on addressing these challenges via adversarial AI training methods and model-based solutions [5], [6], and in [7], the authors closely investigated such attack and defense strategies in 6G networks, exposing critical vulnerabilities across all network layers. However, a number of important research questions remain underexplored, such as how these attacks can be orchestrated in practice, and how current and next-generation wireless network architectures, systems, and technologies can introduce proactive defense mechanisms, ideally by-design."}, {"title": "A. Adversarial Poisoning in Wireless Federated LLM Training", "content": "Motivated by the increasing importance of end-user data privacy and associated privacy protection laws [8], DCML has been gradually shifting toward mechanisms such as federated learning (FL) [9] and split FL (SFL) [10]. These have proven to be privacy-preserving as only the respective model parameters, some parts of it or model gradients need to be exchanged. SFL in particular has emerged as a compute-efficient federated protocol, suitable for distributed training of large ML model architectures. Unlike traditional FL, in which the entire model is trained on each client, SFL splits the model, allowing for more compute-intensive parts to be outsourced to a remote server. This approach is particularly advantageous for LLM architectures that cannot be entirely processed at resource-constrained edge devices due to computational and memory limitations [11]. However, the practical realization of (S)FL over wireless networks faces challenges from the inherently unreliable wireless medium, limited bandwidth, and suboptimal resource allocation [12]. In addition, malicious actors such as jammers could target privacy and security aspects of (S)FL systems by intentionally poisoning data and models through adversarial noise. The particular importance of studying adversarial jamming attacks in SFL with LLMs is motivated by recent results from natural language processing (NLP) research [13], [14]. The authors in [13] study the susceptibility of LLMs to word embedding poisoning caused by noisy perturbations and show that by altering even a single word embedding vector, an adversary can subtly manipulate a"}, {"title": "B. Proactive and Resilient-by-Design Anti-Jamming in SFL", "content": "To preemptively safeguard LLM parameter transmissions in SFL against adversarial jamming attacks, proactive and in particular resilient-by-design approaches are needed [17]. This requires a simultaneous co-design of AI, resilience, beam-forming, user scheduling, and resource allocation, thereby integrating resilience from a bottom-up approach, by design. In addition, such proactive defense mechanisms need to be agnostic of the respective jamming capabilities, including physical and spatial features. This is not the case for some more recent works, which tend to impose strong assumptions on the adversary's knowledge and setup. For instance, [18] and [19] only consider single- or few-antenna jammers with common secrets being exchanged between legitimate parties. This essentially excludes so-called worst-case jammers with extensive system knowledge and capabilities [20], [21]. In order to develop universally applicable defense strategies for a wide range of jamming scenarios in SFL, system performance needs to be guaranteed for the worst-case. Thus, we need to generalize toward intelligent and reconfigurable worst-case jammers. In our prior work in [22], we motivated the study of how sensing-assisted network information can be harnessed to enhance existing mitigation schemes without the need for otherwise precise jamming statistics. Therein, we have shown that information on the jamming signal directions-of-arrival (DoAs) can be used to devise MIMO-OFDM anti-jamming strategies with exceptional performance. However, we did not discuss whether such sensing-assisted defense strategies can be straightforwardly applied to enhance the resilience in SFL over wireless networks. In particular, the impact of worst-case jamming needs to be quantified in order to study its influence on LLM model poisoning as compared to conventional jammers. In the subsequent sections, we provide thorough insights on these aspects, including an analysis on the minimum system rate that guarantees a reliable and resilient SFL training."}, {"title": "C. Contributions", "content": "The main contribution of this paper is an analysis and framework for resilient SFL over wireless networks that will help close the gap between adversarial jamming attacks in SFL and LLM model poisoning. We provide insights into how jamming LLM word embeddings affects the global model training and how the latter can be efficiently safeguarded by MIMO signal processing at the availability of sensing-assisted information. In summary, our key contributions include:\n\u2022 We derive an analytical expression for the ML training loss divergence based on a relaxed (L0, L1)-smoothness assumption for LLM transformer architectures in the case of corrupted word embeddings. We show that its upper bound depends on the communication mean squared error (MSE), thereby motivating a wireless approach to resilience in SFL.\n\u2022 We provide a novel analysis on the minimum system rate which guarantees a robust and reliable SFL training over the wireless network, thereby characterizing minimum network conditions based on the outage rate caused by the jammer.\n\u2022 We develop R-SFLLM, a novel, sensing-assisted anti-jamming framework for resilient SFL with LLMs, which leverages the jamming signal's DoAs to devise an anti-jamming strategy formulated as a joint optimization problem for beamforming, user scheduling, and resource allocation while maximizing the sum rate of the SFL participants. In this problem, any explicit knowledge about the jamming statistics is replaced by a surrogate expression that depends only on the jamming DoAs. We provide an efficient solution to the problem using an iterative water-filling approach [23].\n\u2022 In order to benchmark R-SFLLM against worst-case conditions in SFL, we utilize the worst-case jamming strategy in our prior work [22], which minimizes the sum rate instead.\n\u2022 We provide extensive simulations for BERT and ROBERTa models on various datasets, demonstrating near-optimal performance when anti-jamming is enabled and significantly worse outcomes for unprotected scenarios. We show that R-SFLLM introduces an additional adversarial training component as word embeddings are exposed to controlled noise since jamming cannot be mitigated perfectly. This exposure further helps improve the model robustness by teaching it to learn effectively even in the presence of interference [24]."}, {"title": "II. SYSTEM MODEL AND ADVERSARIAL ANALYSIS", "content": "We consider an SFL setup in which a set Q of Q legitimate clients cooperatively train transformer-based LLMs, which consist of embedding, attention and head layers. A natural choice in SFL with LLMs is to partition the model according to these blocks, assigning the embedding layer to the client and the compute-intensive attention and head layers to the server as outlined in Figure 1. This particular partitioning alleviates the computational load at the client while ensuring that word embeddings are processed close to the raw data, thereby enhancing privacy. Further partitioning the embedding block and transmitting intermediate layers instead increases the risk of sensitive information being exposed to adversarial attacks, such as model inversion [25]. During training, each"}, {"title": "A. Wireless R-SFLLM System Model", "content": "user q \u2208 Q first computes the word embeddings $e_q \\in \\mathbb{R}^E$ for its private data points and then maps the embeddings onto uncorrelated zero-mean, unit variance Gaussian symbols, which are then beamformed, power-scaled, and transmitted over the wireless channel to a dedicated server slice for further processing. To this end, we consider a MIMO-OFDM multiple access channel (MAC) in the uplink. Each user q is equipped with $N_T$ antennas and transmits the signal $x_{qnk}$, which is a composite of the binary user scheduling $a_{qnk}$, transmit power $P_{qnk}$, beamforming vector $w_{qnk} \\in \\mathbb{C}^{N_T}$, and word embedding data symbols $s_{qnk}$. The transmissions occur over the resource set $\\mathcal{R}_q = \\mathcal{N}_q \\times \\mathcal{K}_q$ with allocated subcarriers $n \\in \\mathcal{N}_q$ and OFDM symbols $k \\in \\mathcal{K}_q$, with a total of $N$ subcarriers and $K$ symbols available. Each legitimate transmit signal propagates through the channel $H_{qnk} \\in \\mathbb{C}^{N_R \\times N_T}$ to the server, equipped with $N_R$ receive antennas. In this setup, an adversarial jammer aims to impair the SFL training by jamming the word embeddings in the uplink. The legitimate signal is thus corrupted by additive white Gaussian noise (AWGN) $n_{nk} \\sim \\mathcal{N}(0, \\sigma^2 I) \\in \\mathbb{C}^{N_R}$ and by the adversarial jamming signal $u_{nk} \\sim \\mathcal{N}(0, C_{unk}) \\in \\mathbb{C}^{N_J}$, which propagates through the separate jamming channel $G_{nk} \\in \\mathbb{C}^{N_R \\times N_J}$. We define $N_J$ as the number of jamming antennas and corresponding jamming covariance matrix as $C_{unk} \\in \\mathbb{C}^{N_J \\times N_J}$. The receiver performs equalization using the linear filters $v_{qnk} \\in \\mathbb{C}^{1 \\times N_R}$ to estimate the transmitted symbols $\\hat{s}_{qnk}$. In summary, we have:\n\\begin{align}\nx_{qnk} &= a_{qnk} \\cdot \\sqrt{P_{qnk}} w_{qnk} s_{qnk} \\in \\mathbb{C}^{N_T}, \\\\\nz_{nk} &= G_{nk} u_{nk} + n_{nk} \\in \\mathbb{C}^{N_R}, \\\\\ny_{nk} &= \\sum_{q \\in Q} H_{qnk}x_{qnk} + z_{nk} \\in \\mathbb{C}^{N_R}, \\\\\n\\hat{s}_{qnk} &= v_{qnk}^H y_{nk}. \n\\end{align}\nWe further model $H_{qnk}$ and $G_{nk}$ as beamspace channels:\n\\begin{equation}\nH_{qnk} = \\sum_{l=1}^{L_H} \\sum_{a=1}^{N_R} \\sum_{a'=1}^{N_T} b_{H,l} a_{N_R}^H(\\theta_{H,l}) a_{N_T}(\\psi_{H,l}) e^{j2\\pi w_{nk}(v_{H,l}, \\tau_{H,l})}(v_{a,1,q,1})\\\\\\\nG_{nk} = \\sum_{l=1}^{L_G} \\sum_{a=1}^{N_R} \\sum_{a'=1}^{N_J} b_{G,l} a_{N_R}^H(\\theta_{G,l}) a_{N_J}(\\psi_{G,l}) e^{j2\\pi w_{nk}(v_{G,l}, \\tau_{G,l})}. \n\\end{equation}\nHere, $L_H$ and $L_G$ are the number of resolvable paths for each channel, $b_{.,l}$ is the path gain for each resolvable path l, $a_{N_x}(\\theta)$ is the steering vector at each terminal with $N_x$ antennas, $\\theta_{.,l}$ is direction-of-arrival, $\\psi_{.,l}$ is direction-of-departure, and $w_{nk}(v,\\tau) = kv T_s - n \\tau \\Delta f$ is the phase shift caused by the Doppler shift $v$ and propagation delay $\\tau$, with $T_s$ and $\\Delta f$ being the symbol period and subcarrier spacing. Furthermore, the power $P_q$ for each user is limited across all resource elements and the jamming signal equally adheres to a jamming power constraint $P_J$, i.e.\n\\begin{equation}\n\\sum_{(n,k)\\in \\mathcal{R}_q} ||x_{qnk}|| \\leq P_q, \\\\ \n\\sum_{(n,k)\\in \\mathcal{mathcal{R}}_q} \\text{tr}(C_{unk}) \\leq P_J. \n\\end{equation}\nWe further assume that the legitimate parties have precise channel state information (CSI), encompassing the wireless link parameters defined by the set $\\Gamma_q = \\{Q_{qnk}, P_{qnk}, W_{qnk}, v_{qnk}, H_{qnk}, \\sigma^2\\}$. Additionally, the SFL participants are provided with the DoAs of the jamming signal, i.e. $\\Theta_G = \\{\\theta_{l}\\}_{l=1}^{L_G}$. This may be enabled by advanced wireless sensing technologies in future 6G networks, such as integrated sensing and communication (ISAC) and reflective intelligent surfaces (RIS) [26]\u2013[28], to name a few. Further, we assume no restrictions on the particular jamming strategy, hence the jammer is assumed to be in the so-called jammer-dominant regime [20] with more transmit power and antennas than any legitimate party, i.e. $P_j \\gg P_q$ and $N_j > N_{T}, N_R$. In addition, the adversary may possess full system knowledge, including $s_q$. This represents a worst-case jammer assumption. The adversarial jamming introduces corruption not only at the symbol level but also at the decoded message, such that jamming can be modeled as the post-decoding error as follows:\n\\begin{align}\n\\hat{e}_q &= e_q + \\epsilon, \\quad \\text{where } \\epsilon \\sim \\mathcal{N} (0, C_{\\epsilon}), \\\\\\\n\\text{tr}(C_{\\epsilon}) &= MSE(s_q), \\\\\nMSE(s_q) &= \\mathbb{E} [||s_q - \\hat{s}_q||^2] \\\\\n&= \\sum_{(n,k)\\in \\mathcal{R}_q} a_{qnk} \\cdot \\mathbb{E} [|s_{qnk} - \\hat{s}_{qnk}|^2] . \n\\end{align}\nUpon receiving the jammed signal $y_{nk}$, the server slice continues processing the LLM attention and head layers using the corrupted word embeddings $\\hat{e}_q \\neq e_q$. At the end of the forward propagation pass, the server slice computes the training loss metric $\\mathcal{L} : \\mathbb{R}^E \\rightarrow \\mathbb{R}$, which yields the corrupted loss $\\mathcal{L}(\\hat{e}_q)$ and its gradient $\\nabla \\mathcal{L}(\\hat{e}_q)$, using which the backpropagation process is initiated. This procedure is repeated for each transmission of the word embeddings across all global training rounds. We also assume that the jammer is not active in the downlink as the perturbation of gradients has been studied in various federated setups, for which corresponding defense mechanisms exist [29]. Similarly, the client- and server-side model aggregation after each global round are assumed to be unaffected by the adversary as corresponding secure aggregation strategies exist as well [30]. Note that FedAvg [9] is used in this work. Thus, the consideration of only the uplink transmission suffices to study the jamming impact on LLM word embeddings in this setup. Anti-jamming can then be directly applied if necessary conditions are fulfilled, including the assumption that maximizing the signal-to-interference-plus-noise-ratio (SINR) implies maximizing the ML performance. This assumption is verified next. Figure 2 shows the R-SFLLM system architecture, where the SFL protocol is augmented by sensing-assisted jamming DoA information, a necessary component for our anti-jamming framework in Section III."}, {"title": "B. Adversarial Jamming Impact on LLM Training in SFL", "content": "Previous works in FL typically assume the loss function to be convex, twice differentiable, and Lipschitz smooth. While these assumptions may hold true for simpler neural networks as in [12] and [31], more involved architectures such as transfomers generally do not exhibit these properties [32]. The assumption that $\\mathcal{L}$ is Lipschitz smooth is particularly far-reaching as this implies bounded gradients during backpropagation. In [33], it is shown that the standard Lipschitz assumption introduces a large variability along the optimization trajectory. Thus, a relaxed $(\\mathcal{L}_0, \\mathcal{L}_1)$-smoothness needs to be assumed, which generalizes to more complex models, such as LLMs. Based on this generalization, we derive upper bounds on the loss divergence, caused by jammed word embeddings, and show how these relate to the communication MSE.\n1) Assumptions on the Loss Function:\nAssumption 1. The loss function $\\mathcal{L} : \\mathbb{R}^E \\rightarrow \\mathbb{R}$ is twice-differentiable and bounded from below with infimum $\\mathcal{L}^*$.\nAssumption 2. $\\mathcal{L}$ is $(\\mathcal{L}_0, \\mathcal{L}_1)$-smooth coordinate-wisely, i.e. there exist coefficient vectors $\\mathcal{L}_0, \\mathcal{L}_1 \\in \\mathbb{R}^E$ such that for any $x, y \\in \\mathbb{R}^E$ with $||x - y||_2 \\leq ||\\mathcal{L}_1||_1$ it holds for all $j \\in [E] = \\{1,..., E\\}$ that\n\\begin{equation}\n|\\frac{\\mathcal{L}(y) - \\mathcal{L}(x)}{\\partial x_j}| < \\mathcal{L}_{0,j} + \\mathcal{L}_{1,j} \\cdot ||y - x||_2. \n\\end{equation}\nThis is a generalization of the scalar $(\\mathcal{L}_0, \\mathcal{L}_1)$-smoothness:\nDefinition 1. $\\mathcal{L}$ is called $(\\mathcal{L}_0, \\mathcal{L}_1)$-smooth if there exist scalars $\\mathcal{L}_0, \\mathcal{L}_1 \\in \\mathbb{R}$ such that for all $x \\in \\mathbb{R}^E$ it holds that\n\\begin{equation}\n||\\nabla^2 \\mathcal{L}(x)|| \\leq \\mathcal{L}_0 + \\mathcal{L}_1 ||\\nabla \\mathcal{L}(x)||. \n\\end{equation}\nThe coordinate-wise $(\\mathcal{L}_0, \\mathcal{L}_1)$-smoothness implies that smoothness may vary for each coordinate of the input space. This particularly pertains to LLMs as it has been shown in [32] that variance can be observed across mostly every transformer layer, such that each layer coordinate $j$ satisfies an own $(\\mathcal{L}_{0,j}, \\mathcal{L}_{1,j})$ pair. Thus, if the coefficients $\\mathcal{L}_{1,j}$ are non-zero, smoothness is potentially unbounded. In contrast, if all $\\mathcal{L}_{1,j}$ are strictly zero, the original Lipschitz smoothness is recovered. In [32], the following Lemma has been established, relating the coordinate-wise smoothness to the loss divergence.\nLemma 1. [32] Let $\\mathcal{L}$ be $(\\mathcal{L}_0, \\mathcal{L}_1)$-smooth coordinate-wisely. Then for any $x, y \\in \\mathbb{R}^E$ with $||x - y||_2 \\leq ||\\mathcal{L}_1||_1$, we have\n\\begin{equation}\n\\begin{aligned}\n\\mathcal{L}(y) \\leq \\mathcal{L}(x) &+ \\langle \\nabla \\mathcal{L}(x), y \u2013 x \\rangle \\\\\n&+ \\sum_{j=1}^E \\left[\\mathcal{L}_{0,j} + \\frac{\\mathcal{L}_{1,j}}{||y - x||_2} \\langle \\nabla \\mathcal{L}(x), \\frac{y \u2013 x}{||y - x||_2} \\rangle \\right] \\cdot \\frac{|y_j - x_j|^2}{2}. \n\\end{aligned}\n\\end{equation}\n2) Upper Bound on the LLM Loss Divergence: We utilize Lemma 1 to derive the loss divergence upper bound as follows.\nLemma 2. For $x, y \\in \\mathbb{R}^E$, the loss divergence is bounded by\n\\begin{equation}\n|\\mathcal{L}(y) - \\mathcal{L}(x)| \\leq ||\\nabla \\mathcal{L}(x)||_2 \\cdot ||y - x||_2 \n+ ||\\mathcal{L}_0 + \\mathcal{L}_1 \\odot |\\nabla \\mathcal{L}(x)| ||_2 \\cdot ||y - x||_2. \n\\end{equation}\nProof. See Appendix A\nIn (12), the loss gradient $||\\nabla \\mathcal{L}(x)||_2$ might be unbounded, particularly when several coordinates need to be considered. However, common practice in deep learning suggests to bound gradients manually by means of gradient clipping [33] using a clipping threshold $\\tau > 0$, thereby preventing exploding gradients, i.e.\n\\begin{equation}\n\\nabla_{\\tau} \\mathcal{L}(x) = \\begin{cases}\n\\nabla \\mathcal{L}(x) &, \\text{if } ||\\nabla \\mathcal{L}(x)||_2 \\leq \\tau \\\\\n\\frac{\\tau}{||\\nabla \\mathcal{L}(x)||_2} \\nabla \\mathcal{L}(x) &, \\text{otherwise} \n\\end{cases}. \n\\end{equation}"}, {"title": "Corollary 1.", "content": "If gradient clipping is applied, the upper bound on the LLM loss divergence from Lemma 2 simplifies to\n\\begin{equation}\n|\\mathcal{L}(y) - \\mathcal{L}(x)| \\leq \\tau \\cdot ||y - x||_2\n+ ||\\mathcal{L}_0 + \\tau \\mathcal{L}_1 ||_2 \\cdot ||y \u2013 x||_2. \n\\end{equation}\nLemma 2 thus provides an upper bound on the divergence between loss functions for two distinct inputs x and y. This allows us to quantify the impact of adversarial jamming by measuring the loss divergence between legitimate and corrupted inputs. Corollary 1 further refines this upper bound for practical applications by incorporating gradient clipping.\n3) Relating the Model Error to the Communication MSE:\nHaving established the necessary upper bounds on the loss divergence, we now apply those in the context of legitimate and jammed embeddings. To this end, we first show an equivalence between the embedding MSE and the communication MSE in Proposition 1. We then use this equivalence in Proposition 2 to establish a direct relationship between the model error, expressed by the expected loss divergence, and jamming, quantifying the jammer's impact on the training performance."}, {"title": "Proposition 1.", "content": "Let $e_q, \\hat{e}_q \\in \\mathbb{R}^E$ be the true and corrupted word embeddings and let $s_{qnk}, \\hat{s}_{qnk} \\in \\mathbb{C}$ be the corresponding true and corrupted transmit symbols. Then, it holds that\n\\begin{align}\n\\mathbb{E} [||e_q - \\hat{e}_q||^2] &= \\sum_{(n,k)\\in \\mathcal{R}_q} a_{qnk} \\mu_{qnk} \\\\\n&= \\mathbb{E} [||s_q - \\hat{s}_q||^2], \n\\end{align}\nwhere $\\mu_{qnk}$ denotes the expected symbol error per resource allocation, i.e.\n\\begin{equation}\n\\mu_{qnk} = \\mathbb{E} [|s_{qnk} - \\hat{s}_{qnk}|^2]. \n\\end{equation}\n\\begin{equation}\n\\begin{aligned}\n\\mu_{qnk} &= \\left[\\frac{P_{qnk} |v_{qnk}^H H_{qnk} w_{qnk}|^2}{\\alpha_{qnk}^H X_{qnk} \\alpha_{qnk}} - 1\\right]^{-1} v_{qnk}^H X_{qnk} v_{qnk} , \n\\end{aligned}\n\\end{equation}\nwith the expectation being taken over the joint distribution of $\\{s_{qnk}\\}_{(n,k)\\in \\mathcal{R}_q}$, $z_{nk}$ being conditioned on $e_q$, and with the interference-plus-noise covariance matrix $X_{qnk}$, i.e.\n\\begin{equation}\nX_{qnk} = \\sum_{q'\\neq q} H_{q'nk}b_{q'nk}b_{q'nk}^H H_{qnk}^H + C_{z_{nk}}, \n\\end{equation}\nwith the shorthand $b_{qnk} = a_{qnk} \\sqrt{P_{qnk}} w_{qnk}$ and composite noise covariance $C_{z_{nk}}$.\nProof. The proof follows directly from $s_{qnk}$ and $z_{qnk}$ being uncorrelated for all $q,n,k$, and from the assumption that we can recover $\\{s_{qnk}\\}_{(n,k)\\in \\mathcal{R}_q}$ from $e_{qnk}$ and vice versa. $\\Pi$"}, {"title": "Proposition 2.", "content": "Let $\\mathcal{L} : \\mathbb{R}^E \\rightarrow \\mathbb{R}$ satisfy Assumptions 1 and 2 with coordinate-wise smoothness parameters $\\mathcal{L}_0, \\mathcal{L}_1 \\in \\mathbb{R}^E$ and let $e_q, \\hat{e}_q \\in \\mathbb{R}^E$ be the true and corrupted word embeddings with $||e_q - \\hat{e}_q||_2 < ||\\mathcal{L}_1||_1$. Then, it holds that\n\\begin{equation}\n\\mathbb{E} [|\\mathcal{L}(e_q) \u2013 \\mathcal{L}(\\hat{e}_q)|] \\leq ||\\nabla_{e_q} \\mathcal{L}(e_q)||_2 \\cdot \\sqrt{\\mathbb{E} [||s_q - \\hat{s}_q||^2]}\n+ ||u(e_q)||_2 \\cdot \\mathbb{E} [|| s_q - \\hat{s}_q||^2], \n\\end{equation}\nwith the expectation being taken over the joint distribution of $\\{s_{qnk}\\}_{(n,k)\\in \\mathcal{R}_q}$, $z_{nk}$ being conditioned on $e_q$, and with\n\\begin{equation}\nu(e_q) = \\mathcal{L}_0 + \\mathcal{L}_1 \\odot \\nabla_{e_q} \\mathcal{L}(e_q). \n\\end{equation}\nProof. See Appendix B $\\Pi$"}, {"title": "Corollary 2.", "content": "In the case of gradient clipping with $\\tau > 0$, the upper bound in (20) from Proposition 2 further simplifies to\n\\begin{equation}\n\\mathbb{E}[|\\mathcal{L}(e_q) \u2013 \\mathcal{L}(\\hat{e}_q)|] \\leq \\tau \\cdot \u2081\\sqrt{E [||s_q - \\hat{s}_q||^2]}\n+ ||\\mathcal{L}_0 + \\tau \\mathcal{L}_1 ||_2 \\cdot \\mathbb{E} [||s_q - \\hat{s}_q||^2]. \n\\end{equation}\n4) Practical Interpretation of Results: Proposition 2 pro-vides an upper bound on the model error, defined by the expected loss divergence between legitimate and corrupted embeddings, which is directly dependent on the MSE of the wireless communication system. Therein, the proximity condition $||e_q - \\hat{e}_q||_2 \\leq ||\\mathcal{L}_1||_1$ sets a practical constraint on the distance between legitimate and jammed embeddings, which needs to be small enough for the smoothness condition to hold. As outlined in [32], this ensures the stability of the gradient behavior, preventing numerical instabilities and unreliable approximations as gradient-dependent optimization algorithms might struggle to converge. By applying gradient clipping, we ensure that $|| \\nabla_{e_q} \\mathcal{L}(e_q) ||_2$ is bounded by $\\tau$, thereby stabilizing the training process as the assumptions underlying the optimization methods are not violated. In particular, Corollary 2 ensures that the model error does not explode and is only dependent on the $(\\mathcal{L}_0, \\mathcal{L}_1)$-smoothness coefficients, the clipping threshold $\\tau$ and the communication MSE $\\mathbb{E}[||s_q - \\hat{s}_q||^2]$, independent of whether the proximity condition is fulfilled or not. In the context of jamming, this allows for the consideration of arbitrary adversaries, including worst-case scenarios. Hence, even if the resulting jammed word embeddings do not fulfill the proximity condition, for example due to excessive noise or sophisticated attack strategies that may flip the embedding label, our analysis remains applicable, aligning with best practices in deep learning. This new insight thus establishes a formal relationship between the transformer-based LLM architecture, its semantic word embeddings, and the wireless medium, thereby emphasizing the importance of the wireless communication system and its resilience to adversarial jamming in the quality of distributed training. To the best of our knowledge, this is the first formal characterization of such a relationship for practical DCML applications, such as SFL, with LLMs over wireless networks. In particular, we consider a generalized smoothness assumption on the loss function, which is often omitted in previous works but required for a proper analysis. This assumption explains why techniques such as gradient clipping work and may be necessary during training, and how corrupted model inputs affect the loss divergence, a critical measure for the ML training performance. Consequently, as the model error directly depends on the communication MSE, a wireless approach to resilience in SFL is not only justified but required, thus instructing us to maximize the SINR."}, {"title": "C. Minimum System Rate for Reliable SFL with LLMs", "content": "To characterize the minimum system rate, under which the communication link can support SFL reliably, we need to identify outage conditions caused by jamming. To this end, we provide three remarks. In Remark 1, we first derive a lower bound for the per resource allocation symbol error. We use this"}, {"title": "Remark 1.", "content": "Let the resource set for each user q be defined as $\\mathcal{R}_q = \\{(n,k)|a_{qnk} \\neq 0 \\quad \\forall(n,k) \\in R\\}$ with $|\\mathcal{R}_q| = r_q$. For the minimum MSE (MMSE) receive filter $v_{qnk}$ with\n\\begin{equation}\nv_{qnk} = (X_{qnk} + H_{qnk}b_{qnk}b_{qnk}^H H_{qnk}^H)^{-1}H_{qnk}b_{qnk}, \n\\end{equation}\nwe have the following well-known equality for the per resource allocation symbol error $\\mu_{qnk}$:\n\\begin{equation}\n\\mu_{qnk} = \\exp\\{-\\mathcal{I}(s_{qnk}, \\hat{s}_{qnk})\\} = \\exp\\{-\\mathbb{R}_{qnk}\\}. \n\\end{equation}\nUsing (24), we further have $\\mu_q = \\sum_{(n,k)\\in \\mathcal{R}_q} \\exp\\{-\\mathbb{R}_{qnk}\\}$, and then, we can apply Jensen's inequality to obtain\n\\begin{equation}\n\\mu_q \\geq r_q \\cdot \\exp \\left\\{ r_q^{-1} \\sum_{(n,k)\\in \\mathcal{R}_q} -\\mathbb{R}_{qnk} \\right\\} = r_q \\cdot \\exp\\{-r_q^{-1} \\mathbb{R}_q\\}. \n\\end{equation}"}, {"title": "Remark 2.", "content": "In Proposition 2, we require $|| e_q - \\hat{e}_q|| \\leq \\frac{1}{\\mathcal{L}_1} \\nabla_{e_q}, e_q \\in \\mathbb{R}^E$, which further implies that\n\\begin{equation}\n\\mathbb{E}[||e_q - \\hat{e}_q||^2] = \\xi_q \\leq \\mathbb{E} [||\\mathcal{L}_1||^{-2}] = ||\\mathcal{L}_1||^{-2}. \n\\end{equation}\nUsing (25), we may conclude that\n\\begin{equation}\nr_q \\cdot \\exp\\{-\\mathbb{R}_q/r_q\\} \\leq \\mu_q \\leq ||\\mathcal{L}_1||^2. \n\\end{equation}\nFrom here, it is easy to derive a lower bound for $\\mathbb{R}_q$ as\n\\begin{equation}\n\\mathbb{R}_q \\geq r_q \\cdot \\log \\left(r_q ||\\mathcal{L}_1||_2^{-2} \\right) \\stackrel{\\text{def.}}{=} R_{out, 1}, \n\\end{equation}\nwhere $R_{out, 1}$ represents the minimum rate required for Proposition 2 to hold in its expectation."}, {}]}