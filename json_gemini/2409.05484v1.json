{"title": "CRADLE-VAE: ENHANCING SINGLE-CELL GENE PERTURBATION MODELING WITH COUNTERFACTUAL REASONING-BASED ARTIFACT DISENTANGLEMENT", "authors": ["Seungheun Baek", "Soyon Park", "Yan Ting Chok", "Junhyun Lee", "Jueon Park", "Mogan Gim", "Jaewoo Kang"], "abstract": "Predicting cellular responses to various perturbations is a critical focus in drug discovery and personalized therapeutics, with deep learning models playing a significant role in this endeavor. Single-cell datasets contain technical artifacts that may hinder the predictability of such models, which poses quality control issues highly regarded in this area. To address this, we propose CRADLE-VAE, a causal generative framework tailored for single-cell gene perturbation modeling, enhanced with counterfactual reasoning-based artifact disentanglement. Throughout training, CRADLE-VAE models the underlying latent distribution of technical artifacts and perturbation effects present in single-cell datasets. It employs counterfactual reasoning to effectively disentangle such artifacts by modulating the latent basal spaces and learns robust features for generating cellular response data with improved quality. Experimental results demonstrate that this approach improves not only treatment effect estimation performance but also generative quality as well. The CRADLE-VAE codebase is publicly available at https://github.com/dmis-lab/CRADLE-VAE.", "sections": [{"title": "1 Introduction", "content": "Understanding cellular responses to gene perturbations is crucial for identifying potential therapeutic targets. Single-cell technologies such as Perturb-seq [1] have facilitated application of machine learning methodologies in addressing this task due to their high-resolution and high-throughput production of single-cell RNA sequencing (scRNA-seq) data."}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 Disentanglement in Single-cell Perturbation Response Prediction", "content": "Recent advancements in single-cell RNA sequencing technologies have significantly enhanced our understanding of cellular responses to chemical and genetic perturbations [11, 12]. Due to the complexity of studying the phenotypic effects of cellular perturbations and their underlying factors, previous works have focused on leveraging causal learning which aims to understand the mechanisms by which variables influence each other and predicting the outcome of interventions [13]. CPA utilizes a disentanglement strategy based on adversarial approach [14]. Moreover, with VAEs being the primary generative models, studies have focused on disentangling the latent variables that constitute the true distribution of scRNA-seq data. Both sVAE+ [4] and SAMS-VAE [5] utilize sparse mechanism shifts to disentangle gene perturbations."}, {"title": "2.2 Counterfactual Reasoning in Single-cell Perturbation Response Prediction", "content": "Another line of previous work focuses on employing counterfactual reasoning in predicting the outcomes of single-cell gene perturbations. Counterfactual reasoning helps generative models such as VAEs expand their understanding in causal relationships between different factors such as gene-gene interactions. GraphVCI adopted this concept in enhancing the individuality of cellular responses and dynamically modulating the graph regulatory network structure based on different gene perturbations [15]. Similarly, CODEX incorporates the counterfactual reasoning approach in predicting the genetically perturbed scRNA-seq data given the unperturbed data (i.e., control expression profile) along with dosage information and specific interventions as input.\nNone of the previous models have explicitly considered data quality issues caused by scRNA-seq protocols despite being emphasized in biology domain. Our study addresses this by incorporating counterfactual reasoning related to the presence of latent technical artifacts in scRNA-seq data so that the generative model effectively disentangles them during its training process."}, {"title": "3 Methods", "content": ""}, {"title": "3.1 scRNA-seq Dataset", "content": "We define a N-sized scRNA-seq dataset $(x_i, p_i, a_i)_{i=1}^N$ where each data instance includes a gene expression vector $x_i \\in \\mathbb{R}^{D_x}$, a gene perturbation vector $p_i \\in \\{0,1\\}^T$ and an artifact presence label $a_i \\in \\{0,1\\}$ where $D_x$ is the total number of genes used in this task, and T is the number of perturbation types. Each bit in $p_i$ specifies whether its corresponding gene was perturbed prior to obtaining $x_i$. Also, $a_i$ indicates the presence of technical artifacts in $x_i$. In our task's context, $x_i$ is the cellular response when given treatment $p_i$. If $x_i$ passes a predefined quality control criteria, then $a_i = 0$; otherwise, $a_i = 1$."}, {"title": "3.2 Quality Control Criteria", "content": "We elaborate the process of labeling each expression vector with $a_i$ based on our established quality control (QC) criteria. Having adopted the filtering guidelines provided by Scanpy and 10X Genomics, we established the following six QC sub-criteria: UMI counts, number of features, percent of mitochondrial (mt) reads, percent of hemoglobin reads (hb), percent of ribosomal (rb) reads and doublet detection [16, 8]. The first five sub-criteria are determined using data-driven thresholds calculated as scaled median absolute deviation (MAD) [17, 18] while the last criterion is a binary label identified by Scrublet [19]. We used three to five times of the MAD (3\u03c3, 4\u03c3, 5\u03c3) since threshold selection can vary across studies [17, 18], where 3\u03c3 represents the strictest QC cut-off, followed by 4\u03c3 and 5\u03c3."}, {"title": "3.3 CRADLE-VAE", "content": ""}, {"title": "3.3.1 Encoder Module", "content": "The overall architecture of CRADLE-VAE is shown in Figure 2. During training, the encoder part of CRADLE-VAE takes data instance $(x_i, p_i, a_i)$ as input and encodes it into three different latent representations which are latent basal state embedding $z_i^b \\in \\mathbb{R}^{D_z^b}$, latent perturbation effect embedding $z_i^p \\in \\mathbb{R}^{D_z^p}$ and latent artifact embedding $z_i^a \\in \\mathbb{R}^{D_z^a}$ where $D_z$ is the dimension size of latent subspaces. The objective of this module is to disentangle these three latent variables and learn their individual contributions to the observed true data distribution.\nAlgorithm 1 shows CRADLE-VAE's encoding process which inherits the formulation basis from Bereket and Karalet-sos's work. The latent perturbation effect embedding $z_i^p$ is an additive composition of global gene-wise perturbation effects, $e_t$, induced by global sparse latent offsets, $m_t$, which are sampled from parameterized prior Normal distribution and Bernoulli distribution, respectively (Algorithm 1.2, 3, 7). Similarly, the latent artifact embedding $z_i^a$ is a multiplication of $a_i$ and $u$, which is sampled from its own parameterized prior distribution (Algorithm 1.5, 8).\n$z_i^b$ is sampled from a Normal distribution that is parameterized by a neural network $f_{enc}$ taking $x_i$, $z_i^p$ and $z_i^a$ as input (Algorithm 1.12). $1_t$ is the one-hot encoding of the tth gene perturbation treatment while both $f_{emb}$ and $f_{enc}$ are trainable neural networks."}, {"title": "3.3.2 Decoder Module", "content": "During training, the decoder part of CRADLE-VAE takes the latent embeddings ($z_i^b$, $z_i^p$, $z_i^a$) as input and samples $\\hat{x_i}$ from a parameterized Gamma-Poisson distribution. Algorithm 2 shows CRADLE-VAE's decoding process where $f_{dec}$ is a learnable neural network with final softmax layer that outputs the expected frequency for each gene used for parameterizing the Gamma-Poisson distribution. $l_i$ and $\\theta_d$ denote the total number of read counts for the ith cell and learnable inverse dispersion used universally across all cells respectively."}, {"title": "3.3.3 Variational Inference", "content": "Considering the intractability of the data marginal probability $p(X|P, A)$, we define the correlated variational distribution $q(Z|X, P, A)$ by approximating the posterior distribution of latent variables:\n$q(Z^b, M, E, U|X, P, A) = \\prod_{t=1}^T q(e_t|m_t; \\phi)q(m_t; \\phi) \\times q(u; \\phi) \\prod_{i=1}^N q(z|x_i, p_i, a_i, M, E,U; \\phi)$ \\\\(1)\nfor latent basal state embeddings $Z^b \\in \\mathbb{R}^{N \\times D_z^b}$, global latent perturbation masks $M \\in \\{0,1\\}^{T \\times D_z^p}$, global latent perturbation embeddings $E \\in \\mathbb{R}^{T \\times D_z^p}$, global latent artifact embeddings $U \\in \\mathbb{R}^{1 \\times D_z^a}$, gene expression matrix $X \\in \\mathbb{R}^{N \\times D_x}$, gene perturbation matrix $P \\in \\{0,1\\}^{N \\times T}$, and artifact presence labels $A \\in \\{0, 1\\}^N$.\nWe employ stochastic variational inference [20] to approximate the posterior distribution $\\log p(X|P, A)$. The learnable parameters $(\\theta, \\phi)$ of CRADLE-VAE are optimized by maximizing the evidence lower bound (ELBO) which is mathematically expressed as below:\n$\\mathcal{J}_1(\\theta, \\phi) = \\mathbb{E}_{Z^b,M,E,U \\sim q(\\cdot|X,P,A;\\phi)} \\left[\\log \\frac{p(X, Z^b, M, E, U|P, A; \\theta)}{q(Z^b, M, E,U|X, P, A; \\phi)}\\right]$\n \\\\(2)"}, {"title": "3.3.4 Artifact Disentanglement by Counterfactual Reasoning", "content": "We propose to exploit the counterfactual outcome of the same gene perturbation treatment as means to reinforce disentanglement of latent variables related to quality degradation caused by technical artifacts. We add the following modifications to CRADLE-VAE's encoding process $x_i$ is a QC passed gene expression profile (i.e., $a_i = 0$).\nFirst, CRADLE-VAE additionally builds a counterfactual latent artifact embedding $z_{i,c}^a = (1 - a_i)u$ which is opposite to $z_i^a = a_i u$ being zero-scaled (Algorithm 1.9). It is then used for sampling the counterfactual latent basal state embedding $z_{i,c}^b$ from a Normal distribution parameterized by $f_{enc}$ (Algorithm 1.10). Meanwhile, for each QC passed gene expression profile $x_i$, we first sample its counterfactuals from our dataset that share the same gene perturbation treatment but are QC failed. We then compute their median $\\bar{x}_{i,c}$ to feed it along with $z_i^p$ and $z_{i,c}^a$ into the neural network $f_{enc}$, from where we sample the reference counterfactual latent basal state embedding $\\tilde{z}_{i,c}^b$ (Algorithm 1.11).\nWe imposed an auxiliary loss objective that guides $z_{i,c}^b$ to be aligned with $\\tilde{z}_{i,c}^b$. This is done by minimizing the Kullback-Leibler (KL) divergence between the two latent basal state embeddings which is mathematically expressed as follows:\n$\\mathcal{J}_2(\\phi) = -KL \\left[q(Z^b|X, P, A; \\phi)||q(\\tilde{Z}^b|\\tilde{X}, P, A; \\phi)\\right]$\n \\\\(3)\nWe expect the loss objective to provide two benefits for CRADLE-VAE. First, the computed gradients that are back-propagated through $f_{enc}$ to $\\mathcal{N}(\\hat{\\mu}, \\hat{\\sigma})$ exhibit additional supervision to the disentanglement of artifact-related latent variables, facilitating a clearer distinction between QC passed and QC failed cases. Second, the latent basal state embeddings that are encoded by $f_{enc}$ help guide the $f_{dec}$ to generate the data samples that not only correlate with the true cellular responses but are also more likely to pass the QC criteria. We will explore these benefits later through our quantitative experiments and qualitative analysis.\nThe overall learning objective that optimizes the trainable parameters $\\theta, \\phi$ is then defined as follows:\n$\\mathcal{T}(\\theta,\\phi) = \\mathcal{J}_1(\\theta, \\phi) + \\alpha \\mathcal{J}_2(\\phi)$\n \\\\(4)\nwhere $\\alpha$ is the hyperparameter for controlling the alignment intensity of the auxiliary loss objective."}, {"title": "3.3.5 Generative Process", "content": "After training, CRADLE-VAE generates its predicted cellular responses by sampling the latent basal state embedding $z_i^b$ from a normal distribution ($\\mathcal{N}(0, I)$) and combining it with $z_i^p$ and $z_i^a$ sampled from the encoder module's parameterized distributions. Finally, $[z_i^b \\oplus z_i^p \\oplus z_i^a]$ is fed to $f_{dec}$, which generates the read counts for each gene (Algorithm 3.11,12). Note that the global latent artifact embedding $u$ is multiplied by $a_i = 0$ since CRADLE-VAE is used to generate artifact-free gene expression data which is expected to pass the QC criteria (Algorithm 3.6).\nFormally, we define the joint probability distribution over the observed and latent variables as:\np(X,Z^b, Z^p,M, E, U|P, A;\\theta) = \\left(\\prod_{t=1}^T p(m_t)p(e_t)\\right)p(u) \\times \\prod_{i=1}^N p(x_i|z_i^b, p_i, a_i, M, E, U; \\theta)\n \\\\(5)"}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experiment Settings", "content": "We evaluated CRADLE-VAE on four Perturb-seq datasets, i.e. Norman dataset [12], Dixit dataset [1], Replogle dataset [21], and Adamson dataset [22]. We adopted the preprocessing approaches done to Replogle dataset from Lopez et al. and other datasets from Ji et al.. The details of each dataset are shown in Table 1."}, {"title": "4.2 Experimental Results", "content": "Table 2 shows the quantitative results on the four Perturb-seq datasets. According to the results, CRADLE-VAE overall surpassed all of its baselines in the three evaluation metrics that measure the model's ability to accurately predict cellular responses. Moreover, CRADLE-VAE achieved the highest QC Pass Rate across all datasets and QC threshold settings, demonstrating its ability to capture the true data distribution of QC passed gene expression profiles due to additional disentanglement of latent artifacts during its training phase. Notably, despite multi-gene perturbation cellular response prediction being more challenging than that of single-gene perturbation, CRADLE-VAE significantly outperforms the second-best model with a large margin, particularly in the Norman and Dixit datasets, both of which contain multi-gene perturbation scRNA-seq data. This highlights CRADLE-VAE's strong generalizability in out-of-distribution (OOD) gene perturbation treatment scenarios."}, {"title": "4.3 Ablation Study", "content": "To investigate the effects of utilizing causal distribution of artifact disentanglement and our proposed auxiliary loss objective utilizing counterfactual reasoning related to presence of technical artifacts, we conducted experiments on the ablated versions of CRADLE-VAE which are denoted as CRADLE-VAE w/o Causal and CRADLE-VAE w/o CF respectively. The former models the technical artifact as fixed learnable embedding instead of parameterized prior distribution (Algorithm 1.5). The latter removes the KL divergence-based auxiliary loss objective, eliminating the counterfactual reasoning-based approach in aligning the latent basal state embeddings ($\\mathcal{J}_2$).\nAs shown in Table 3, the ablated versions of CRADLE-VAE exhibited performance decline, implying the benefits of employing counterfactual reasoning and causal learning. Particularly, we find that modeling the technical artifact as a learnable embedding (CRADLE-VAE w/o Causal) results in a sharper decline, especially at the 5\u03c3 QC threshold. While setting a higher QC threshold leads to imbalance between the number of QC passed and failed samples, we speculate that distribution-based artifact modeling is more resilient to such issues compared to its embedding-based version. The effect of removing the counterfactual reasoning (CRADLE-VAE w/o CF) is more profound at the 3\u03c3 threshold. This outcome aligns with our assumption that the KL loss objective between the counterfactual latent basal state embeddings aids in the learning of artifact features, particularly when generalization is well-established due to the balanced data instances."}, {"title": "4.4 Distributional Generative Quality Analysis", "content": "To further analyze CRADLE-VAE's generative quality, we visualized the distributions of actual (Replogle) and model-generated gene counts related to the QC criteria, that results from a specific treatment perturbing the POLD3 gene [21]. The rationale behind selecting this particular perturbation is as follows: 1) the number of gene expression profiles treated by this perturbation in the dataset is relatively low (85 compared to the average of 164), 2) only 13% of them passes the QC criteria. This may pose challenges in learning the causal distributions during the training process, especially if the latent effects of technical artifacts are not properly addressed. We expect these challenges to be dealt with the employment of counterfactual reasoning-based artifact disentanglement. Figure 3 shows that CRADLE-VAE exhibits its consistency in robustly generating read counts that satisfy all QC sub-criteria.\nWe move our focus to a critical sub-criterion responsible for a significant decline in data quality. The distribution of hemoglobin counts in the Replogle dataset predominantly exceed the QC threshold, leading to a high QC failure rate. On the contrary, the distribution generated by CRADLE-VAE is shifted below the threshold, implying a marked enhancement in generative data quality. For both the number of genes with positive counts and UMI count, the violin plots in Figure 3 display a skewed distribution compared to the original data, indicating that CRADLE-VAE's generated gene expression profiles yield consistent and higher quality outcomes."}, {"title": "4.5 Disentanglement Effect Analysis", "content": "We investigated the effects of CRADLE-VAE's disentanglement of two important variables which are perturbation and artifact effects. We utilized t-SNE in visualizing the high-dimensional gene expression profiles generated by CRADLE-VAE, and colored them based on which pathway clusters are relevant to each of their gene perturbations. This aligns with a domain-specific assertion stating that perturbation of genes with similar biological roles are expected to show similar expression patterns. Following the method in [12], we grouped them into six pathways for this visualization. As illustrated in Figure 4, CRADLE-VAE appears to form clearer clusters within the same pathway compared to other models, particularly for those related to the pro-growth and megakaryocyte pathways.\nAdditionally, we examined the disentanglement of artifacts by comparing the same generated data with and without artifacts. In Figure 4, the t-SNE visualization within pathways shows distinct clustering based on the presence or absence of artifacts, suggesting that our model successfully disentangles artifact effects. Overall, these findings suggest that our model can meaningfully separate both latent perturbation and artifact variables, as reflected by the well-defined clusters in the visualizations."}, {"title": "5 Conclusion", "content": "Quality issues in scRNA-seq datasets have been overlooked despite the improvements in predicting cellular responses achieved by previous works. We propose a causal inference-based VAE model CRADLE-VAE which has several advantages. During the training process, CRADLE-VAE disentangles not only latent perturbation effects but also the artifacts that inherently degrade data quality. Additionally, the disentanglement of these artifacts is further enhanced by our novel counterfactual reasoning-based approach which employs an auxiliary loss objective used for aligning the counterfactual basal states. As demonstrated in our experiments and analysis, CRADLE-VAE is capable of accurately predicting cellular responses with improved generative quality. We expect that CRADLE-VAE addresses the quality issues of both experimentally measured and model-generated single-cell response data upon gene perturbation, eliminating the need of arbitrary quality control standards for scRNA-seq data analysis."}, {"title": "B Baselines", "content": ""}, {"title": "B.1 SAMS-VAE", "content": "SAMS-VAE is a fully defined VAE-based generative model designed modeling perturbation effects in cells[5]. Similar to CRADLE-VAE, SAMS-VAE specifies prior probability distributions for both the latent perturbation effects and latent basal state. While it also incorporates sparsity in the latent perturbation effects, it does not explicitly address or model the technical artifacts present in the data, thus requiring preprocessing of the scRNA-seq training data."}, {"title": "B.2 SVAE+", "content": "SVAE+ also explicitly addresses sparsity in the data using a mask and embedding mechanism [4]. However, unlike CRADLE-VAE, SVAE+ lacks a mechanism for composing multiple interventions. Instead, it operates by sampling a cell's full latent embedding from a learned prior, which is conditioned on the treatment the cell receives. The differences in how SVAE+ handles the cell's latent state and the variational inference methods it employs set it apart from our model."}, {"title": "B.3 CPA-VAE", "content": "CPA-VAE is the ablated model of SAMS-VAE defined by Bereket and Karaletsos that is identical to SAMS-VAE with all mask components fixed to 1. In another words, it does not incorporate sparsity to the latent perturbation effects. However, it inherits the benefits of the inference improvements to the correlated variational families."}, {"title": "B.4 Conditional VAE", "content": "Conditional VAE ia a deep conditional generative model initially proposed for structured output predictions. [24]. It adopted stochastic neural networks for the task based on the generative model with Gaussian latent variables. We chose it as baselines because it shares the same characteristics like VAE backbone and the incorporation of input omission noise in the reconstruction process to regularize the deep neural networks during training."}, {"title": "C Concept Description", "content": ""}, {"title": "C.1 Perturb-seq", "content": "Perturb-seq is a technique that combines CRISPR-based gene perturbation with single-cell RNA sequencing (scRNA-seq). Perturb-seq combines the flexibility of CRISPR/Cas9 for targeting one or multiple genes with the large-scale capabilities of scRNA-seq to generate comprehensive genomic data. This technique has been applied in both post-mitotic immune cells and proliferating cell lines, allowing researchers to examine how genetic perturbations influence gene expression and cell states at a single-cell level."}, {"title": "C.2 Causal Inference", "content": "In the context of machine learning, causal inference is a method used to understand and model the cause-and-effect relationships between variables rather than just their correlations [13]. Traditional machine learning models focus on finding patterns in data, but these correlations may be influenced by other variables and do not always represent true causal links. Causal inference addresses this limitation by using methods like causal discovery to learn causal graphs and causal effect estimation to quantify the impact of interventions. Causal modeling is divided into three stages: 1) associational causality, which predicts in the i.i.d. setting, 2) interventional causality, which predicts under distribution shifts, and 3) counterfactual causality, which answers counterfactual questions and serves as the main concept we apply in CRADLE-VAE's methodology."}, {"title": "C.3 Counterfactual Reasoning", "content": "Counterfactual reasoning attempts to answer the question of what the model would predict if the action had been different. In machine learning, it involves estimating the probable outcomes that could have occurred if treatment B were taken instead of treatment A. The concept of counterfactual reasoning is particularly relevant in understanding causal relationships. In this paper, we use counterfactual reasoning to ask the counterfactual question: What would the outcome have been if the outcome had not contained technical artifacts, given a treatment (perturbation)?"}, {"title": "C.4 Quality Control Criteria", "content": "The six quality control sub-criteria mentioned in the main text are based on the analysis guides provided by 10X Genomics [8]. The detailed descriptions of each are as follows:\n\u2022 UMI counts refer to the number of Unique Molecular Identifiers (UMIs) detected for each cell in single-cell RNA sequencing (scRNA-seq) experiments. UMIs are short, unique sequences added to each RNA molecule during the library preparation process. Filtering cell barcodes with too few UMIs can reduce noise and improve the accuracy of the data.\n\u2022 Number of features refers to the number of distinct genes or transcripts detected in a single cell. Excluding barcodes with unusually high or low numbers of features helps remove potential multiplets or droplets with ambient RNAs. Like UMI counts, thresholds can be set arbitrarily or based on statistical measures. A high number of features may indicate that a cell is expressing a wide range of genes, which might be expected in healthy, viable cells. Cells with a low number of features might not represent viable cells and are therefore conventionally excluded in the filtering process.\n\u2022 Percent of mitochondrial (mt) reads refers to the RNA transcripts originating from mitochondrial DNA that are captured and sequenced during the experiment. Cells with high mitochondrial RNA levels may be unhealthy or damaged.\n\u2022 Percent of hemoglobin (hb) reads refers to RNA transcripts associated with hemoglobin genes, which are involved in oxygen transport in red blood cells. In non-hematopoietic tissues or experiments where red blood cells are not the focus, a high proportion of hemoglobin reads can be a sign of contamination or an issue with sample preparation.\n\u2022 Percent of ribosomal (rb) reads refers to the proportion of sequencing reads that originate from ribosomal RNA (rRNA) in an RNA-seq dataset. A high percentage of ribosomal reads could indicate that the rRNA depletion step was ineffective. A high proportion of rRNA can dominate the sequencing data, reducing the amount of useful data for analyzing gene expression.\n\u2022 Doublets in scRNA-seq refer to artifacts that occur when two or more cells are captured together in a single droplet or well during the sequencing process. Doublets need to be excluded because they can lead to misleading results, as the combined gene expression profiles from multiple cells can mimic the expression patterns of a single cell type or create hybrid profiles that do not represent any real biological cell state."}, {"title": "D Dataset", "content": ""}, {"title": "D.1 Norman dataset", "content": "The Norman dataset includes gene expression profiles from the K562 leukemia cell line subjected to CRISPR activation (CRISPRa). The original dataset from Norman et al. [12] is publicly available from GEO (GSE133344). For our experiment, we downloaded the processed data provided by Ji et al. [23], and followed their preprocessing step. The preprocessed data included 111,255 cells and 19,018 genes, encompassing 131 multi-gene perturbations and 105 single-gene perturbations, with each perturbation containing approximately 300\u2013700 samples."}, {"title": "D.2 Dixit dataset", "content": "The Dixit dataset contains gene expression profiles from the K562 leukemia cell line perturbed by CRISPR-Cas9 KO. The original dataset from Dixit et al. [1] is publicly available from GEO (GSE90063). For our experiment, we used the processed data from Ji et al. [23], and followed their preprocessing step. The preprocessed data included 103,420 cells and 18,531 genes, with 45 multi-gene perturbations and 10 single-gene perturbations, where number of samples for single-gene perturbations ranged from 4000 to 27000 and multi-gene perturbation samples contained about 60-400 samples."}, {"title": "D.3 Replogle dataset", "content": "The Replogle dataset contains genome-wide perturbations of the K562 leukemia cell line with CRISPR interference (CRISPRi). The original dataset from Replogle et al. [21] is publicly available from the original paper. From the raw data containing 1,989,578 cells with 9,867 perturbations, we preprocessed the data following Lopez et al. [4], which resulted 118,641 cells and 1,187 genes, with 722 single-gene perturbations. Each perturbation contained 20-2000 samples, with mean 144 and median 164."}, {"title": "D.4 Adamson dataset", "content": "The Adamson dataset includes gene expression data from the K562 leukemia cell line with CRISPR interference (CRISPRi). The original dataset from Adamson et al. [22] is publicly available from GEO (GSE90546). We downloaded the processed data from Peidli et al. [25], and followed the preprocessing step from Ji et al. [23], which resulted 62,623 cells and 17,115 genes, with 87 unique single-gene perturbations, each replicated in approximately 100 cells."}, {"title": "E Proof of Theorem", "content": ""}, {"title": "E.1 Derivation of ELBO", "content": "The Evidence Lower Bound (ELBO) is derived from the marginal likelihood p(X | P, A). First, recall that the log marginal likelihood can be expressed as:\n$\\log p(X | P, A) = \\log \\int_{Z,M,E,U} p(X, Z^b, M, E,U | P, A) dZ^b dM dE dU$.\nTo simplify this, we introduce a variational distribution $q(Z^b, M, E, U | X, P, A; \\phi)$ and apply Jensen's inequality:\n$\\log p(X | P, A) \\ge \\mathbb{E}_{q(Z^b,M,E,U|X,P,A;\\phi)} \\left[\\log \\frac{p(X, Z^b, M, E,U | P, A)}{q(Z^b, M, E,U | X, P, A; \\phi)}\\right]$\nHere, the ELBO $\\mathcal{J}_1(\\theta, \\phi)$ is defined as:\n$\\mathcal{J}_1(\\theta, \\phi) = \\mathbb{E}_{q(Z^b,M,E,U|X,P,A;\\phi)} \\left[\\log \\frac{p(X, Z^b, M, E,U | P, A)}{q(Z^b, M, E,U | X, P, A; \\phi)}\\right]$\nExpanding the expectation:\n$\\mathcal{J}_1(\\theta,\\phi) = \\mathbb{E}_{q(Z^b,M,E,U|X,P,A;\\phi)} [\\log p(X, Z^b, M, E,U | P, A; \\theta) - \\log q(Z^b, M, E, U | X, P, A; \\phi)]$ \\\\(6)\n$= \\mathbb{E}_{q(Z^b,M,E,U|X,P,A;\\phi)} [\\log p(X, Z^b, M, E,U | P, A;\\theta)] - \\mathbb{E}_{q(Z^b,M,E,U|X,P,A;\\phi)} [\\log q(Z^b, M, E, U | X, P, A; \\phi)]$. \\\\(7)\nThis ELBO provides a lower bound on the log marginal likelihood $\\log p(X | P, A)$, which is useful for optimizing the variational parameters $\\phi$ and model parameters $\\theta$ in variational inference."}, {"title": "E.2 Proof Using Variational Causal Inference", "content": "We aim to minimize the Kullback\u2013Leibler (KL) divergence between two variational distributions , as given by the following auxiliary loss objective:\n$KL [q(Z^b|X, P, A; \\phi)||q(\\tilde{Z}^b|\\tilde{X}, P, A; \\phi)] = \\mathbb{E}_{q(\\tilde{Z}^b|\\tilde{X},P,A;\\phi)} \\left[\\log \\frac{q(Z^b|X, P, A; \\phi)}{q(\\tilde{Z}^b|\\tilde{X}, P, A; \\phi)}\\right]$, \\\\(8)\nwhere $Z^b$ is the counterfactual latent basal state, $\\tilde{X}$ is the reference counterfactual latent basal state, $P$ is the gene perturbation, $A$ is the artifact presence, $\\phi$ represents the encoder learnable parameters."}, {"title": "F Results", "content": "Additional results that were not shown in the main paper are included in this section. Quantitative evaluation on top 20 results of ATE-p, ATE-R2, and Jaccard are shown in Table 1. Also, proof of concept to check the data qualtiy-quantity tradeoff is done in Table 2."}, {"title": "H Experiment Details", "content": ""}, {"title": "H.1 Norman", "content": "Each model was optimized with the Adam optimizer for 2,000 epochs with a batch size of 512, learning rate of 0.0003, and gradient clipping norm of 100. The data was processed using the NormanOODCombinationDataModule, with 75% of the data allocated for training and 25% for testing. We varied the split seed across 0, 1, 2, 3, 4 to evaluate robustness. Additionally, we considered quality control (QC) thresholds of 3, 4, 5, training the model separately for each threshold and evaluating them all individually. For the model, we used the CRADLEVAE Model with a latent dimension of 200 and one decoder layer. The prior probability of the mask was set to 0.01, and the embedding prior scale to 1. The guide utilized was CRADLEVAE CorrelatedNormalGuide, with 4 layers and 400 hidden units in the embedding encoder, and the basal encoder input was normalized using log standardize. The loss function was defined by CRADLEVAE ELBOLossModule"}]}