{"title": "Automatic answering of scientific questions using the\nFACTS-V1 framework: New methods in research to\nincrease efficiency through the use of AI", "authors": ["Dr. Stefan Pietrusky"], "abstract": "The use of artificial intelligence (AI) offers various possibilities to expand and support educational research. Specifically, the implementation of AI can be used to develop new frameworks to establish new research tools that accelerate and meaningfully expand the efficiency of data evaluation and interpretation [1]. This article presents the prototype of the FACTS-V1 (Filtering and Analysis of Content in Textual Sources) framework. With the help of the application, numerous scientific papers can be automatically extracted, analyzed and interpreted from open access document servers without having to rely on proprietary applications and their limitations. The FACTS-V1 prototype consists of three building blocks. The first part deals with the extraction of texts, the second with filtering and interpretation, and the last with the actual statistical evaluation (topic modeling) using an interactive overview. The aim of the framework is to provide recommendations for future scientific questions based on existing data. The functionality is illustrated by asking how the use of AI will change the education sector. The data used to answer the question comes from 82 scientific papers on the topic of AI from 2024. The papers are publicly available on the peDOCS document server of the Leibniz Institute for Educational Research and Educational Information.", "sections": [{"title": "Introduction", "content": "The possible uses of artificial intelligence (AI) are diverse. How the use of AI will change education in schools and universities is the subject of current discussions in educational research [2] [3]. As with other technologies, there are promising new opportunities, but also concerns that specifically affect those involved [4]. One concrete added value that arises from the use of AI is that new frameworks or research tools can be developed that support scientists in evaluating and interpreting large amounts of data. At a conference on the use of AI in higher education, a participant expressed his concerns after the presentation of a prototype that can automatically create interactive, dynamic learning media. I was told that learners' motivation decreases when they know that the learning media used was created by an AI. Whether and how AI-generated learning media influences motivation"}, {"title": "Methodology", "content": "In order to answer the question of how AI will change education, 82 scientific papers from 2024 were analyzed. The papers are available on the peDOCS document server of the Leibniz Institute for Educational Research and Information and can be downloaded without registration. The search term used was \"artificial intelligence\", which resulted in 500 articles being displayed. FACTS-V1 was used to filter and analyze the content in the text sources. This was created as part of an AI strategy to develop various tools for the education sector. Another tool of this strategy in the field of statistics is ASCVIT, which can be used to automatically record, analyze and interpret numerical and categorical data from data sets [6]. FACTS-V1 consists of a total of three components, the function of which is briefly discussed below.\nThe first component is a bot that searches the peDOCS platform for scientific articles on a given search term, in this case \"artificial intelligence\" and year of publication (2024). The articles published in 2024 are downloaded as a PDF file and the exact source information is extracted and saved in a separate text file. The bot's metadata can be customized, allowing the bot and thus the application to be used in any context. The bot is initialized using the Firefox WebDriver (GeckoDriver), which is set up by Selenium. A WebDriver enables the automation of tasks in a browser. It represents a bridge between code and browser. There are different WebDrivers for the different browsers. Selenium is used to automate actions in the browser. It uses the WebDriver to open the website in Firefox. To configure the bot, the peDOCS page was examined using the developer tool (F12) to identify the classes required for navigation. The search query is made according to the defined search term and the results page is loaded. The bot then extracts the links to the relevant articles. The articles are then processed. The subpage of the articles is opened, and the metadata is checked. Further processing only takes place for publications from 2024. The PDF files are saved locally in a defined directory. The bot automatically recognizes when there are additional pages with search results. When the results of one page have been checked, the next page is called up. When there are no more pages, the process is terminated.\nThe second component of the FACTS-V1 prototype is used to analyze the PDF files collected in the first step. This is achieved by extracting the text, cleaning it and examining it for the defined question using a Large Language Model (LLM), specifically LLama3.1p from Meta. The LLM is installed locally using the Ollama model management system. Communication takes place via the Command Line Interface (CLI). The application first goes through all PDF files. The files are opened and the text is extracted page by page. Unnecessary elements such as page numbers, line breaks and double spaces are removed. The aim of the cleaning is to create a flowing text that is easier for the LLM to read. Since the maximum length of the input context is often limited for LLM, the cleaned text is divided into smaller sections (chunks) of 3500 characters to ensure efficient processing by the model and not to overload it. Each text section is sent to the LLM using a context-related prompt. The model then gives a concise answer to the previously defined question, provided the text section contains relevant information. If the section is not important for the question, a hint (NO ANSWER) is also issued. The results of the analysis are recorded in a text file for each article and section. In addition to the analysis results, files are also created for the cleaned texts. The preparation of the results is clearly structured and therefore easy to understand. The collected data can therefore be quickly used for further analyses.\nIn the last part of the application, the relevant information from the analyzed text data is used for topic modeling using Latent Dirichlet Allocation (LDA). LDA automatically identifies main topics based on word combinations and their frequency [7]. The extracted relevant answers are saved in a .csv file. The sections that are irrelevant to the question are ignored. The answers are represented by a Bag-of-Words model (BoW), which puts the unstructured text data into a numerical form (vector). The vectors of the BoW model are summarized by the Document Term Matrix (DTM). LDA identifies the main topics, 5 by default, in the texts by analyzing the DTM. The results of the LDA topic modeling are visualized using pyLDAvis. The advantage of this open source library is that the results are quickly understandable and interpretable. The interactive visualization is saved in an HTML file so that it can be opened flexibly in a browser."}, {"title": "Results", "content": "Of the 82 scientific papers published on the peDOCS document server on the topic of artificial intelligence in 2024, none contained a section that was not relevant to the research question. The full list of articles analyzed can be found in the appendix. Topic modeling with LDA identified five topics characterized by the 30 most common terms within each topic. The clusters show which words frequently appear together in the analyzed papers (see Fig. 2)). The results are based on a relevance value of 1 (X = 1), since the aim is to interpret the core terms of the clusters. The global importance of a term in the corpus is measured by the saliency metric [10]. The topic-specific relevance of a term is calculated by the relevance metric [11]."}, {"title": "Discussion", "content": "The results of the analysis of 82 articles show that there are already concrete ideas in the scientific discussion about how the use of AI will change education. This is made clear by the visualization created by pyLDAvis and the topics found. The topic of \"Individualization of learning\" (Cluster 1) is the most strongly represented, accounting for almost a third of the entire text corpus (29.2 %), and shows that it is assumed that the use of AI can make learning more individual. The topic of \"Support and new learning paths\" (Cluster 2) has a topic weight of 20.3 % and shows that AI will play an important role in supporting learning processes. With a topic weight of 18.6%, the topic of \"Development of skills\" (Cluster 3) is also important. AI should therefore promote the development of individual and digital skills. The topic of \"New possibilities in teaching\" (Cluster 4) has a topic weight of 17.4%. In the articles analyzed, AI is expected to create new opportunities in teaching by integrating digital tools and innovative methods. The topic of \"critical thinking and ethical competencies\" (cluster 5) has the lowest weight at 14.5 %. The use of AI is intended to promote critical thinking by questioning how this technology works and where the results come from. The result shows that this focus is currently not discussed enough. In the introduction, the concern was described that the use of AI would reduce learners' motivation. The results of the LDA topic modeling show that the term \"motivation\" does not play a role in any of the identified topics in the context of the question and the articles analyzed. One possible interpretation is that it may not be assumed that the use of AI has an impact on motivation. AI will make education more individual by adapting learning media and learning methods to the needs of the learners. In the future, digital and technological competencies will play a more important role. Teaching and learning processes can be made more innovative through the new opportunities that arise. AI will help to break down barriers in education and make teaching more inclusive. The next step must be to make the opportunities that arise from the use of AI visible through concrete applications. The applications must then be used in practice to answer the following questions. How can A\u0399 be used specifically to make education more inclusive and effective? How can ethical questions be resolved when AI is used in education and personal data is collected in the process? If AI is used everywhere, does this lead to dependency? What does the future of education look like in the age of AI? The article has shown that the first version of the FACTS-V1 prototype works. The entire process of data collection, data cleaning, data analysis and data evaluation can be fully automated and can be applied to any context. The application is a concrete example of how the use of AI can establish new research tools and thus support efficiency in educational research. The following chapter summarizes the most important findings and discusses suggestions for future research."}, {"title": "Conclusion", "content": "It is clear that AI will change the field of education. This article uses 82 current scientific papers to show what this change will look like in concrete terms. The heterogeneity of learning groups is still a major problem for teachers. The results of the LDA topic modeling, which was carried out using FACTS-V1, show that scientists expect positive effects from the use of AI, especially in the area of individualization of learning. The use of AI should therefore lead to a fairer educational system by taking differences between learners into account more effectively. For further and deeper analyses, the number of terms per cluster used to interpret a topic could be increased from top 10 to top 20 or 30. However, the loss of relevance must be taken into account here, as lower probabilities or relevance values contribute less to characterizing a topic [11]. To identify unique terms or distinguishing features specific to a topic, the relevance value could be set from 1 to 0, which would display the terms with the highest log-lift value. Alternatively, the default value of 0.6 could be used to combine both approaches (probability/lift-weighted terms). To check how the answer to a question changes over the years, a similar analysis could be carried out with a different publication year and the results of the topic modeling could be compared. In further analyses in other disciplines, the time required could be recorded to document how long certain steps, specifically the text analysis by the LLM, take. Here, different models could be compared to check how the performance of the application improves and whether certain models produce better results. The relevant answers collected in the second step of the prototype could also be statistically evaluated by another method. Automatic clustering using the K-Means algorithm would also be possible. Rule-based categorization, in which keywords are manually defined for each category, is also possible [12]. Clear categories would then already have to be in place. The results of the topic modeling could also be analyzed in more detail. Specifically by identifying frequently occurring n-grams in order to identify trends if necessary. Deeper semantic analyses are also possible by using Named Entity Recognition (NER) to record the topics, actors, technology or organizations [13]. Network diagrams could be used to visualize possible relationships between keywords such as AI and learning content. The examples mentioned illustrate the numerous possibilities that arise from the results of the FACTS-V1 prototype. These findings offer a promising outlook on future developments in the field of education, which can be further advanced through the use of AI."}]}