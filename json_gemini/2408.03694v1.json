{"title": "A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework", "authors": ["Emna Baccour", "Aiman Erbad", "Amr Mohamed", "Mounir Hamdi", "Mohsen Guizani"], "abstract": "The metaverse, envisioned as the next digital frontier for avatar-based virtual interaction, involves high-performance models. In this dynamic environment, users' tasks frequently shift, requiring fast model personalization despite limited data. This evolution consumes extensive resources and requires vast data volumes. To address this, meta-learning emerges as an invaluable tool for metaverse users, with federated meta-learning (FML), offering even more tailored solutions owing to its adaptive capabilities. However, the metaverse is characterized by users heterogeneity with diverse data structures, varied tasks, and uneven sample sizes, potentially undermining global training outcomes due to statistical difference. Given this, an urgent need arises for smart coalition formation that accounts for these disparities. This paper introduces a dual game-theoretic framework for metaverse services involving meta-learners as workers to manage FML. A blockchain-based cooperative coalition formation game is crafted, grounded on a reputation metric, user similarity, and incentives. We also introduce a novel reputation system based on users' historical contributions and potential contributions to present tasks, leveraging correlations between past and new tasks. Finally, a Stackelberg game-based incentive mechanism is presented to attract reliable workers to participate in meta-learning, minimizing users' energy costs, increasing payoffs, boosting FML efficacy, and improving metaverse utility. Results show that our dual game framework outperforms best-effort, random, and non-uniform clustering schemes improving training performance by up to 10%, cutting completion times by as much as 30%, enhancing metaverse utility by more than 25%, and offering up to 5% boost in training efficiency over non-blockchain systems, effectively countering misbehaving users.", "sections": [{"title": "I. INTRODUCTION", "content": "Recently, the concept of metaverse has gained considerable attention, driven by the COVID-19 pandemic's constraints on physical mobility and the interests of major tech companies [3]. Through customizable 3D avatars, users can engage in activities mirroring real-life experiences within this shared virtual reality. The advancement of metaverse technology has substantially reduced the barriers between physical and digital worlds, aided by technologies like digital twins, blockchain, extended reality (XR), and AI algorithms [4]. As this digital frontier evolves, high-performing AI models are required to ensure a seamless user experience and real-time rendering. However, a significant challenge arises from the scarcity of data within each user's individual context and the need for frequent model personalization due to the ever-shifting nature of tasks. These dynamics demand extensive resources, vast data volumes, and high learning time to train robust and adaptive models.\nTo overcome this limitation and enhance model perfor- mance, a collective training approach, Federated Learning (FL), is required, facilitating collaborative model refinement across decentralized devices. The integration of Federated Learning in the metaverse (FL4M) [5] promises enhanced data privacy and security, alongside decentralized machine learning that leverages user-generated data and computational resources for model building. Yet, in the metaverse, effective management of heterogeneous data is crucial to maintain data utility. In FL, data heterogeneity arises due to diverse client data characteristics, often exhibiting non-independent and non-identically distributed (non-IID) properties, affecting model accuracy. This heterogeneity is not limited to data characteristics; indeed, the metaverse has enormous number of users, objects, and interactions, which creates scalability challenges for traditional FL algorithms. Users may have different preferences, devices, and learning tasks, which can create challenges to adapt to the behavior of the avatars, pursue the ever-shifting nature of their tasks, and provide a more personalized experience, especially that FL mainly focuses on learning one ML task across multiple devices [6]. Furthermore, users expect a responsive and adaptive virtual environment, which cannot be achieved through FL that requires long re- training. Addressing these multifaceted heterogeneity aspects is crucial for efficient FL solutions in the metaverse.\nFederated Meta-Learning (FML), known as \"learning to learn\", emerges as a solution to tackle multi-task learning challenges [7], while preserving the benefits of Federated Learning, such as data security and flexibility [8]. Particularly, initialization-based meta-learning algorithms are well known for fast adaptation and strong generalization to new tasks [9]. In other words, it enables a model to adapt swiftly to new tasks by using its prior experience from other tasks in real-time. As an illustrative example, in a vehicular metaverse, distinct users engage within similar virtual environments but with differing tasks and objectives, such as optimizing fuel efficiency and improving driving techniques. FML demonstrates its prowess by seamlessly accommodating these divergent tasks using different data and offering personalized virtual driving models catering to each user's unique needs. Additionally, FML con- siders evolving tasks within the metaverse, such as simulating snowy roads, efficiently personalizing previously generated models with minimal data samples, computation resources, and learning latency.\nHowever, despite its promising benefits, FML comes with new challenges in the metaverse. Specifically, three critical issues must be addressed. First, the metaverse has a vast number of heterogeneous users with diverse data structures, tasks, and sample sizes, making collective training inefficient due to unrelated tasks and leading to low convergence speed with random uniform device selection [7], [10]. Non-uniform device selection widely applied for FL [8] face challenges in FML due to bias, statistical heterogeneity, and high-order information in stochastic gradients. Excluding meta-learners with minimal contributions, as proposed in [11], is not feasible in the metaverse, where users actively seek participation to craft personalized experiences. Therefore, a clustering mech- anism should be wisely designed to group metaverse users based on their tasks and data similarity. Coalition formation games have been introduced in the context of FL to support Hierarchical Federated Learning (HFL) techniques [12] or to optimize communication resource efficiency [13]. Neverthe- less, the high diversity of tasks within the metaverse poses a challenge, making conventional clustering methods unsuitable for direct application. Secondly, some metaverse users may misbehave to selfishly increase their utility, resulting in a bad training experience. Hence, clustering mechanism should consider the presence of unreliable users to create a fair training circumstances among different coalitions in order to minimize the impact on each coalition's training performance. Third, users' devices may be unwilling to engage in metaverse services due to resource allocation concerns, energy consump- tion, and the absence of appropriate incentives. While resource allocation and incentive mechanisms for FL have been the focus of extensive research, particularly for metaverse [14], [15], FML remains underexplored.\nIn this paper, to the best of our knowledge, we are the first to design a framework that manages the usage of feder- ated meta-learning to empower metaverse services. Our novel distributed computing framework integrates FML techniques with blockchain technology [16], [17] to address the unique challenges of the metaverse previously discussed and pave the way for efficient and personalized learning strategies. The framework introduces a dual game mechanism consisting of a cooperative coalition formation game for clustering metaverse meta-learners and a Stackelberg game for resource allocation and incentives, which are novel approaches not explored before in the context of FML. On one hand, the coalition formation game clusters metaverse meta-learners based on their tasks similarities, contributions and reputations, address- ing the inefficiencies caused by statistical heterogeneity and ensuring average reliability of each coalition. On the other hand, the Stackelberg game serves as an incentive mechanism to ensure fair payoff distribution among metaverse users within each coalition according to their contribution. The framework operates in steps process, starting with users requesting per- sonalized meta-models from a metaverse service provider and concluding with the update of different models and reputa- tions of users after each FML round. Throughout training rounds where both games interact, our framework enables efficient meta-training, enhances users contributions and pay-offs, and reduces energy costs while promoting collaboration and fairness among them. Blockchain technology underpins the framework, to securely manage reputations and incentives, track participation, and ensure transparent interactions among metaverse entities. Our contributions are:\n\u2022 We introduce a novel blockchain-based reliable federated meta-learning framework designed to support immersive user experiences in the metaverse. Our framework lever- ages a unique dual game mechanism to address the chal- lenges of tasks heterogeneity and prompt personalization.\n\u2022 We propose a cooperative coalition formation game to cluster metaverse users based on their computation con- tribution, model embedding similarity, and overall rep- utation, which is partly dependent on past contributions to similar tasks. This proposed approach effectively ad- dresses the inefficiencies caused by statistical diversity in the metaverse.\n\u2022 We introduce a novel method that quantifies the impact of users on model performance and tasks completion time as contribution. On these bases, a reputation management scheme is designed based on historical contributions and potential contributions to present tasks, leveraging correlations between past and new tasks.\n\u2022 We formulate a Stackelberg game to incentivize reli- able users to participate in metaverse FML services and improve system utility. This game-theoretic approach ensures optimal resource allocation and fair payoff dis- tribution among FML participants within each coalition.\n\u2022 We present an algorithm, namely Game-Theoretic Fed- erated Meta-Learning (GFML) for the metaverse, that leverages the interaction between the dual games.\n\u2022 Simulation results show that our proposed framework in a metaverse system guarantees better learning performance and resilience against malicious metaverse users. Addi- tionally, users can obtain higher profits compared to the best-effort, random and non-uniform clustering schemes."}, {"title": "II. RELATED WORKS", "content": "The metaverse has gained significant attention, driving research into integrating advanced technologies and AI tech- niques, such as digital twin [4], XR [3], blockchain [18], and semantic learning [19]. Federated learning has particularly garnered interest for its ability to ensure data privacy and leverage user resources in the metaverse [5]. For example, Zhou et al. [15] proposed an optimization framework for FL in mobile augmented reality within the metaverse, focusing on minimizing energy consumption and completion time while improving model accuracy. Kang et al. [18] explored a privacy-preserving FL framework for the industrial metaverse using blockchain. However, these works primarily focused on re- source and time performance, overlooking the critical aspect of data heterogeneity among learners. Zeng et al. [14] presented HFedMS, an FL system for the industrial metaverse that addresses data heterogeneity and learning forgetting through clients regrouping and semantic compression and compen- sation. Most of federated learning efforts in the metaverse, including HFedMS, aim to address the core issue which is data heterogeneity. Nevertheless, the metaverse's heterogene- ity extends beyond data characteristics and user preferences, encompassing system and protocol variations that challenge traditional FL. Furthermore, the dynamic and personalized nature of the metaverse, with users having evolving and diverse tasks, poses additional challenges for FL algorithms, which primarily focus on learning a single task across devices.\nEfficiently addressing these multifaceted heterogeneity is- sues is crucial for enhancing collaborative training perfor- mance within the metaverse's unique ecosystem, which is the focus of this paper. Federated Meta-Learning offers a promis- ing solution by enabling fast adaptation to new tasks and heterogeneous users, increasing learning accuracy for diverse multi-task environments, and allowing diverse metaverse users to handle a wide range of scenarios and contexts. Despite its advantages, FML has not been integrated or adapted for the metaverse, leaving user-specific needs unmet. To our knowl- edge, we are the first to propose the integration and adaptation of FML techniques to cater to the tasks-heterogeneity of users in the metaverse dynamic environment.\nRecent literature shows growing interest in FML, with efforts focusing only on enhancing model convergence and accuracy through optimized loss functions and averaging methods for general applications. Among these mainstream works, Chen et al. introduced FedMeta, an FML method enhancing FL and FedAvg through a Model-Agnostic Meta- Learning (MAML) algorithm [20] for high statistical and systematic challenges. Jiang et al. explored the relationship between MAML and FedAvg, demonstrating improved and stable personalized performance offered by FML [21]. Lin et al. analyzed FML convergence considering adversarial data and strongly convex loss functions [22], while Fallah et al. confirmed FML's convergence in non-convex scenarios with stochastic gradients [7]. The FML algorithms described above frequently face challenges with slow convergence and inef- ficient communication due to random device selection. Non- uniform device selection has been proposed in meta-learning [11], which involves the exclusion of users with minimal contributions to the training. This approach is impractical in metaverse, as users actively seek participation to create personalized experiences. Clustering all active users looking for a customized experience according to their tasks and context similarities, is not explored in the literature. Our paper will not focus on enhancing loss and averaging performance as is common in existing works, where well-established tech- niques prevail. Instead, we aim to bridge a significant gap by proposing a novel method for dynamic clustering tailored to the unique needs of the metaverse.\nAnother critical gap in FML literature is the lack of"}, {"title": "III. FRAMEWORK AND SYSTEM MODEL", "content": "Fig. 1 presents the federated meta-learning process in the metaverse, including the coalition formation phase and the meta-learning execution phase guided by the stackelberg game.\nOur framework introduces a novel integration of federated meta-learning within the metaverse, leveraging blockchain technology for decentralized management of interactions among metaverse Meta-Learners (MMLs). At its core, the framework is designed to ensure reliable and real-time person- alized experiences through a dual game managing metaverse users and their contributions to the FML process. Specifically, the process unfolds in seven sequential steps, beginning with MMLs requesting meta-models from a metaverse Service Provider (MSP) and concluding with the MSP updating the requested models and reputations of MMLs post each FML round. Central to this process is the cooperative coalition for- mation game clustering MMLs based on utility maximization, and a Stackelberg game framework for optimal task allocation and incentives distribution. Blockchain technology underpins the framework, managing the reputations of MMLs through a decentralized and tamper-proof mechanism, securing transac- tions between MMLs and the MSP, and ensuring that incen- tives are distributed fairly and transparently. It also records all interactions, formed coalitions and MMLs' contributions, thereby providing an immutable and trusted history that can be referenced for future coalition formation, tasks allocation, incentives distribution, and reputation updates. Details about this process are introduced as follows:\nStep 1: A set N of metaverse meta-learners request meta- models from the MSP through the blockchain layer. Each MML looks for a good model initialization, i.e., meta-model, that can be quickly re-fined to a high-performing model via one or few gradient descent steps \\(\\tau \\geq 1\\), in order to be used for the personalized tasks and potential new learning tasks. Furthermore, each MML \\(i \\in N\\) has a labeled private dataset \\(D_i = \\{(x, y)\\} \\), where \\((x, y) \\in \\mathcal{X} \\times \\mathcal{V}\\) is a data input following an underlying distribution \\(P\\) with \\(x\\) denoting the sample and \\(y\\) denoting the label. MMLs might opt to join the FML process, offering their data and computing resources in exchange for incentives (Active MMLs), or they might choose to acquire a pre-trained model and perform only the personalization phase (Passive MMLs). Hence, the set \\(N\\) is defined as \\(N = \\{1, ..., N_a\\} \\cup \\{1, ..., N_p\\}\\), where \\(N_a\\) is the number of active MMLs and \\(N_p\\) is the number of passive MMLs. It is worth noting that each active learner i submits its request with its tolerated task completion time \\(T_i^{\\text{max}}\\), maximum and minimum CPU frequency, i.e., \\(\\delta_i^{\\prime}\\) and \\(\\delta_i\\), that it can offer, its location, and its data characteristics.\nStep 2: To evaluate the reliability of active MMLs, the blockchain system calculates composite reputation scores de- rived from the historical contributions of various users in previous tasks. Miners play an essential role in this process by being incentivized to safely record the users' interactions with the metaverse and calculate their composite reputations when needed.\nStep 3: The MSP initiates a blockchain transaction to recruit the MMLs willing to serve for the learning tasks in the metaverse and choose among them a set \\(H = \\{h_1,...,h_M\\}\\) of M heads with lower task completion constraints and superior blockchain-recorded reputations. The heads serve as aggregators for the FML tasks. The transaction contains the requirements of the MSP, such as the reputation threshold \\(R_{th}\\), and the incentives \\(I_{rep}\\) and \\(I_{comp}\\) for reputation and competition contributions, respectively. It also includes the initial model parameters, such as the weights \\(\\Theta\\) of the Deep Neural Network (DNN) in addition to the number of local computational epochs \\(\\tau\\) that should be processed by any active MML.\nStep 4: Due to data heterogeneity and task objectives, MMLs are clustered into M coalitions, i.e., \\(\\Pi = \\{C_1, ..., C_M\\}\\), led by the selected heads using a cooperative coalition forma- tion game. In cooperative games, the MMLs which are self- interested and focus on maximizing their own utilities, exhibit preferences regarding the clusters they wish to join based on their statistical similarity to the head, the incentives they can"}, {"title": "IV. RELIABLE HEADS SELECTION AND COALITION FORMATION", "content": "In order to incentivize users to join the meta-learning coalitions actively, the metaverse service provider attributes rewards to workers that contribute to metaverse services in exchange for their consumed resources.\nRewards can be categorized into basic or reputation incen- tives \\(I_{rep}\\) and competition incentives \\(I_{comp}\\). The MMLs that"}, {"title": "A. Profit function of metaverse meta-learners", "content": "participate in the same meta-learning coalition can receive an equal reward from \\(I_{rep}\\) based on the average reputation of the group. Furthermore, the MMLs compete to maximize their overall reward by offering their local data. Specifically, MML i with a larger dataset and a data distribution \\(P_i\\) similar to the head can earn higher competition profits from \\(I_{comp}\\). Additionally, each MML adopts the dynamic voltage scaling technology, enabling adaptive modification and management of their processing speed to obtain a higher profit. On the other hand, participating with the computing resources costs the MML energy. Hence, each participant's utility is calculated as the difference between the acquired rewards and the con- sumed energy. A rational MML will keep its utility function positive. It is also imperative that each user ensures their task completion time does not exceed the tolerated limit (\\(T_i^{\\text{max}}\\)) required by the head \\(h_j\\). On these bases, the profit or utility function of the MML \\(i \\in C_j\\) is formulated in eq. (10).\n\n\n\\begin{equation}\nU_{MML_{j,i}} = \\bigg(S_{j,i} + \\big(\\frac{Dj,i}{\\sum_{k\\in Cj}|Dj,k|}-1\\big) \\frac{\\delta_j - \\delta_i}{\\bar{\\delta} - \\bar{\\delta}}\\bigg) \\times \\bigg(\\frac{|C_j|}{\\sum_{k\\in C_j}H(R_{j,k})}\\bigg)  \\times (\\frac{I_{rep}}{|C_j|})\\ +\n\\bigg(\\frac{\\delta_j - \\delta_i}{\\bar{\\delta} - \\bar{\\delta}}\\bigg)  \\times (\\frac{Dj,i}{\\sum_{k\\in Cj}|Dj,k|}) \\times  I_{comp}\\ - c^{comp}_{j,i} - c^{comm}_{j,i} \\qquad\n\\text{S.t.}  \\qquad &\\underline{\\delta}  = \\min(\\delta'_i, \\forall i \\in C_j)\\quad \\\n&\\bar{\\delta} = \\max(\\delta_i, \\forall i \\in C_j) \\\n\\end{equation}\nwhere \\(I_{comp}\\) is the competition incentives offered by the MSP to the coalition \\(C_j\\), \\(|C_j|\\) is the number of MMLs participating in the meta-learning task of the coalition \\(C_j\\), \\(\\delta_{j,i}\\) is the computing frequency of the MML i, and \\(|Dj,k|\\) is its data size. \\(H(.)\\) is the reputation function of the active MMLs, which is defined as [28]:\n\n\\begin{equation}\nH(R_{j,i}) =\n\\begin{cases}\n\\gamma + (1 - \\gamma)\\log(1 - \\mu) & \\text{if } R_{th} \\leq R_{j,i}\\\\\n\\gamma e^{(R_{j,i}-R_{th})} & \\text{if } R_{j,i} < R_{th}\n\\end{cases}\n\\end{equation}\n\n\n\\(\\gamma\\) is the default reputation utility, \\(R_{th}\\) is the reputation threshold specified by the metaverse service provider, and \\(R_{j,i}\\) is the reputation of the MML i after joining \\(C_i\\). Furthermore, \\(\\mu\\) is expressed as follows [29]:\n\n\n\\begin{equation}\n\\mu = \\frac{(e - 1)(R_{j,i} - R_{th})}{(R_i - R_{th})}\\qquad\n\\text{S.t.}  \\qquad Ri = \\max(R_{j,k}, \\forall k \\in C_j) \\\n\\end{equation}\n\n\nThe reputation function \\(H(.)\\) implies that when the reputa- tion of an MML i is lower than the reputation threshold, \\(H(.)\\) decreases sharply; otherwise, \\(H(.)\\) noticeably increases. Finally, \\(S_{j,i}\\) is an index that assesses the similarity of data distribution between the MML i and the head of the coalition \\(h_j\\). Specifically, the metaverse environment is composed of users with different data structures and various tasks. To avoid random grouping of users and unstable global training performance caused by statistical heterogeneity, we encourage the collaboration between MMLs with similar data and tasks. Hence, we propose a statistical strategy to increase the utility of users with higher data similarity to its head. The \\(S_{j,i}\\) index compares the embeddings [30] \\(\\omega^i\\) and \\(\\omega^{h_j}\\) of both head \\(h_j\\) and MML i derived from the initial model of the head in the current round k. The embeddings are compared through the cosine similarity, as follows:\n\n\\begin{equation}\nS_{j,i} = \\frac{<\\Delta \\omega^{h_j}, \\Delta \\omega^{i}>}{\\|\\Delta \\omega^{h_j}\\| \\|\\Delta \\omega^{i}\\|}\n\\end{equation}\nAn embedding is a relatively low-dimensional space into which high-dimensional vectors (e.g., images) are transformed. In machine learning, embeddings are the output of Embedding layer, which is the last layer before the head of the model. Embeddings function as task-specific dictionaries that capture some of the semantics of the inputs by placing semantically similar inputs close together in the embedding space. Thus, the similarity between two embeddings can provide insight into the similarity between the two tasks to be learned and, therefore, can help to proactively select the relevant metaverse users that can be trained together led by their head. The em- bedding can be obtained by a simple forward pass through the model with a reduced complexity. Moreover, it is considered a low-dimensional output. Hence, we will neglect its generation and transmission costs.\nThe similarity index \\(S_{j,i}\\) can be calculated by comparing the embeddings of two samples or two small batches of data for higher accuracy. Since the model is gradually fine-tuned and metaverse users potentially generate more data for task training over time, \\(S_{j,i}\\) is re-calculated at the beginning of each x global round. When x is equal to 1, the embeddings are calculated at each round to capture the updates periodi- cally. The head broadcasts its embedding to all the coalition members, enabling the evaluation of their individual utilities. It is worth mentioning that the embeddings are low-dimensional data and less invasive compared to the input data. We also highlight the importance of selecting high-reputation heads in order to guarantee the integrity of the broadcasted embeddings. We finally note that the MMLs do not communicate with each other as their computation decisions are solely driven by their own utilities, regardless of the consequences on other users."}, {"title": "B. Reputation model based on contribution", "content": "In metaverse environment, each MML requests to acquire multiple models and participate in various meta-learning tasks. Hence, it is necessary for the MSP to comprehensively con- sider the long-term contributions of current users and their contributions in historical similar meta-learning tasks, espe- cially as their data undergo continual changes. Additionally, it is impractical to assume that workers will always remain honest; some may maliciously attempt to manipulate their contributions to gain some advantages, such as joining specific coalitions by falsifying the reported similarity to the head's data, misreporting their computational efforts to reduce energy consumption while still claiming high incentives, or disturbing the training to deteriorate the system performance.\nThe contribution of a given MML i during the global round k is determined by two factors: its contribution to model training"}, {"title": "C. Cooperative coalition game formulation", "content": "The proposed federated meta-learning for metaverse in- volves creating disjoint coalitions, imposing the introduction of a cooperative coalition formation game. The two key re- quirements for classifying a coalitional game as a cooperative, also named hedonic game, are as follows [12]:\nCondition 1 (hedonic conditions). A coalition formation game is classified as cooperative when it meets the following two conditions:\n1) The utility of any player depends solely on the members of the coalition to which the player belongs.\n2) The coalitions form as a result of the preferences of the players over their possible coalitions' set.\nProposition 1. Our formulated problem matches the cooper- ative coalition formation game since it satisfies the conditions above.\nProof. First, based on eq. (10), the utility function \\(U_{MML}\\) depends solely on the MMLs in the coalition \\(C_j\\), \\(\\forall i \\in C_j\\), \\(\\forall j \\in M\\). Second, it is clear that a coalition is subject to modification if and only if an MML i, \\(\\forall i \\in C_j\\), would like to join a new coalition \\(C_{j'}\\), \\(\\forall j' \\neq j\\), in order to gain higher incentives based on its data similarity to the head \\(h_{j'}\\), and its contribution in terms of data, computation, and reputation within the new coalition. Before examining how the cooperative game is applied to our proposed model, we introduce several definitions [12].\nDefinition 1. A coalition of metaverse meta-learners is denoted as \\(C_j \\subseteq N^a\\), where j is the index of the coalition head.\nDefinition 2. The set \\(\\Pi = \\{C_1, ..., C_j, ..., C_M\\}\\) is a coali- tional partition that includes all the MMLs in \\(N^a\\), where all M coalitions are disjoint, i.e., \\(C_j \\cap C_{j'} = \\emptyset \\forall j' \\neq j\\) and \\(\\bigcup_{j=1}^{M} C_j = N^a\\).\nWith the existence of M heads, each MML has M options to join any coalition and support the FML training that increases its utility. If all MMLs jointly contribute to the FML training of a single head, a grand coalition is created. A singleton coalition contains just one FL worker responsible for the FL training. When no MML volunteers for the FML training of a specific coalition, this coalition is represented by an empty set. It is worth mentioning that an MML does not participate in a coalition where its utility is negative."}, {"title": "D. Cooperative coalition formation algorithm", "content": "To reach the game's Nash-stability, we introduce the co- operative game formation algorithm, allowing the MMLs to select coalitions that maximize their utilities in the final partition. The process for cooperative coalition formation in the metaverse for meta-learners is outlined in Algorithm 1. The partition \\(\\Pi^k\\) is first initialized to the previous partition \\(\\Pi^{k-1}\\) (line 7). Then, for each coalition \\(C_j\\), a new head is selected based on two criteria: the highest reputation and the lowest requirement in terms of task completion time (line 8 - line 14). Specifically, it is imperative that the heads are trusted to prevent any potential misleading of the training process. This concern arises if a head misbehaves and modifies its embedding, consequently misguiding data similarity to other players. Such behavior could ultimately affect the formation of coalitions. Furthermore, each head should be one of the players presenting a strict constraint in task completion time, so that the algorithm can guarantee to deliver the trained models within the time requirements of most metaverse users. Note that our algorithm will not ensure that all MMLs receive their models within their time requirements; instead, it ensures a trade-off between reputation and completion time (line 12).\nThe rest of the algorithm follows the switch rule outlined in Definition 5. Any MML \\(i \\in C_j\\) can perform a switch operation if and only if it gets higher utility by joining another coalition \\(C_{i'}\\), where \\(j \\neq j'\\). More specifically, based on the updated reputations, the current contribution in terms of data and computation, and the embedding presented by the new head, each MML i computes its utility from its current coalition using eq. (10) (line 19). Moreover, the MML i evaluates its incentives from other coalitions that it can possibly join and rank them according to Definition 3 in order to determine its preference profile (line 21-line 23). If the MML achieves higher gains in another coalition, it leaves its current group and switches to the new one (line 24-line 28). Given any change in the partition, the coalitions are updated, and the Nash-stability is not yet reached (line 29-line 31). This process repeats until no MML has an incentive to leave its current coalition and join another one. At the end, the Nash-stable partition \\(\\Pi^k\\) that maximizes the utilities of all MMLs is returned (line 36).\nGiven any partition \\(\\Pi^k = \\{C_1^k,..., C_h^k,..., C_M^k\\}\\) at a round k, the proposed cooperative"}, {"title": "V. STACKELBERG GAME-BASED INCENTIVE MECHANISM FOR METAVERSE", "content": "The interaction between the MSP and the MMLs is for- mulated as a single-leader multi-followers Stackelberg game. Within this framework, the MSP assumes the role of the leader, strategically determining the optimal competition incentives to encourage MMLs to execute meta-learning tasks. On the other hand, the MMLs, as followers, adapt their computation frequencies to increase their individual profits. The strategies of both the MSP and the MMLs are formulated as follows:\n\u2022 The MML's computing capacities in Stage II: Based on the reward strategy, MML \\(i \\in C_j\\) determines its computing resources that maximize its profit which is given as:\n\n\\begin{equation}\nU_{MML_{j,i}}(\\delta_{j,i}, I^{comp}) = (S_{j,i} + \\big(\\frac{Dj,i}{\\sum_{k\\in Cj}|Dj,k|}-1\\big) \\frac{\\delta_j - \\delta_i}{\\bar{\\delta} - \\bar{\\delta}})\\times\n\\big(\\frac{\\sum_{k\\in Cj}H(R_{j,k})}{|C_j|}\\big)\\times I_{rep}  +\n\\bigg(\\frac{\\delta_j - \\delta_i}{\\bar{\\delta} - \\bar{\\delta}}\\bigg)  \\times (\\frac{Dj,i}{\\sum_{k\\in Cj}|Dj,k|}) \\times  I^{comp}\\ -\nc^{comp}_{j,i} - c^{comm}_{j,i}\n\\end{equation}\nFor each coalition \\(C_j\\), the set of MMLs computing frequencies is \\(\\delta_j = \\{\\delta_{j,1}, \\delta_{j,2}, ..., \\delta_{j,|C_j|}\\}\\), which serve to calculate the computation delays using eq. (7). Accord- ingly, the round k latency of the coalition \\(C_j\\) is:\n\n\\begin{equation}\nT_{round} = max(T^{comp}_{j,i} + T^{comm}_{j,i}, \\forall i\\in C_j)\n\\end{equation}\nEach MML subgame problem is expressed as follows:\nProblem 1 (MML \\(i \\in C_j\\) subgame):\n\n\n\\begin{equation}\nmax_{\\delta_{j,i},}\nU_{MML_{j,i}}(\\delta_{j,i}, I^{comp})\\nonumber\n\\text{subject to} \\qquad & \\underline{\\delta} < \\delta_{j,i} \\leq \\bar{\\delta} \\\\ \n&\\frac{T^{max}_i}{ \\tau } > T^{comp}_{j,i} + T^{comm}_{j,i} \\\\ \n&c^{comp}_{j,i}+c^{comm}_{j,i} <C_{j,i}\\\\n&U_{MML_{j,i}}(\\delta_{j,i}, I^{comp}) > 0\\\\\n\\end{equation}\n\n\nwhere \\(\\underline{\\delta}\\) and \\(\\bar{\\delta}\\) are the minimum and maximum compu- tation capacities that can be offered by each MML.\n\u2022 The MSP's rewarding strategy in Stage I: In Stage I, based on the resources offered by the MMLs, the MSP establishing an incentive strategy aimed at maximizing its utility, which is equal to:\n\n\\begin{equation}\nU_{MSP}(I^{comp}; \\delta_j) = \\eta \\sum_{i=1}^{|C_j|}ln(\\frac{T^{max}_i}{T^{comp}_{j,i}+ T^{comm}_{j,i}}) + \\nonumber\\\nH(R)\\frac{Dj,i}{\\sum_{k\\in Cj}|Dj,k|})\\ \\times I^{comp}_{C_j}\\\\\n-\\bigg(S_{j,i} + \\big(\\frac{Dj,i}{\\sum_{k\\in Cj}|Dj,k|}-1\\big) \\frac{\\delta_j - \\delta_i}{\\bar{\\delta} - \\bar{\\delta}}\\bigg)\\times\n\\frac{\\sum_{k\\in Cj}H(R_{j,k})}{|C_j|}\nI_{rep},\\ \\\n\n\\end{equation}\nwhere \\(\\eta\\) is a profit weight parameter. The utility of the MSP depends on the computing resources the MMLs can offer, their reputations, and the incentives they receive. The ln(.) reflects the MSP diminishing return on the completion time gain of each MML. The MSP subgame problem for coalition \\(C_j\\) is expressed as follows:\nProblem 2 (MSP subgame):\n\n\\begin{equation}\nmax_{I^{comp}} U_{MSP}(I^{comp}; \\delta_j)\\nonumber\n\\text{subject to} \\qquad I^{comp} < I^{comp} < I^{comp}\\\\\n\\end{equation}\nwhere \\(I^{comp}\\) and \\(I^{comp}\\) denote the maximum and minimum competition rewards, respectively."}]}