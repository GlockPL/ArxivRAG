{"title": "EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection", "authors": ["Kanishk Chaturvedi", "Johannes Gasthuber", "Mohamed Abdelaal"], "abstract": "This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT and thin-edge.io for deploying and managing machine learning models on resource-constrained edge devices. We address the challenges of model optimization, deployment, and lifecycle management in edge environments. The framework's efficacy is demonstrated through a visual quality inspection (VQI) use case where images of assets are processed on edge devices, enabling real-time condition updates within an asset management system. Furthermore, we evaluate the performance benefits of different quantization methods, specifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstrating significant inference time reductions compared to FP32 precision. Our results highlight the potential of EdgeMLOps to enable efficient and scalable AI deployments at the edge for industrial applications.", "sections": [{"title": "1 Introduction", "content": "Machine learning (ML) inference at the edge, encompassing on-device computation for tasks like image recognition, natural language processing, and sensor data analysis, offers compelling advantages over cloud-based inference. These include reduced latency, enhanced privacy, and increased availability, particularly crucial for real-time applications and scenarios with limited or intermittent connectivity [Ma24]. Edge inference empowers applications ranging from autonomous vehicles and smart home devices to industrial automation and remote healthcare monitoring, fostering greater responsiveness and efficiency.\nHowever, deploying sophisticated ML models on resource-constrained edge devices presents significant challenges. Edge devices face challenges due to limited computational power, memory, and energy compared to cloud systems. To deploy complex models effectively, they must be optimized and compressed, while also accommodating the diverse architectures and conditions of edge environments.\nTo overcome these challenges, we introduce EdgeMLOps, an architectural framework for operationalizing ML models at the edge. The framework includes two main components, including Cumulocity IoT\u2074 and the open-source thin-edge.io tool. Cumulocity IoT is a robust, cloud-native platform designed to facilitate the management and integration of connected devices and applications. It offers a comprehensive suite of tools for device management,"}, {"title": "2 VQI Use Case", "content": "Power transmission poles are deployable field assets that eventually need renewal. A typical application tracking these assets might already be in place, but field engineers must evaluate the assets periodically. While one might be able to predict life expectancy with historical data, a failure in power transmission has both economic and human impacts and, therefore, needs precise insurance. A more dynamic approach with visual quality inspection could leverage AI models to detect the assets and classify their current quality, thereby enabling a higher and cheaper evaluation frequency. Taking the images and evaluating them could be done by less skilled professionals or even an autonomous vehicle or drone. Especially if only low cellular bandwidth is available, an edge deployment, either to the autonomous field engineer or an edge-based server, might be necessary to give early feedback on the quality of the pictures and alarm corresponding service technicians.\nAs the paper focuses on the IoT architecture and the corresponding technologies involved in preparing and deploying VQI models, the open-source TTPLA dataset [AWW20] has been utilized to train a ResNet50 and ResNet101 segmentation model for inference [C124]. This enables the free sharing of data and models to the community. TTPLA is a public dataset which is a collection of aerial images of transmission towers (TTs) and power lines (PLs)."}, {"title": "3 Preliminaries", "content": "In this section, we provide an overview of the tools and technologies used in EdgeMLOps to facilitate efficient inference at the edge. Specifically, we discuss the capabilities of Cumulocity IoT, thin-edge.io, and the ONNX standard. Cumulocity IoT is a comprehensive cloud platform designed to simplify the complexities of managing and operating Internet of Things (IoT) devices at scale. It supports a wide range of functionalities, including Device Connectivity, which ensures seamless integration and communication across various IoT devices. Streaming Analytics enables real-time data processing and analysis, allowing users to make immediate decisions based on live data streams. The platform also provides Application Enablement, which facilitates the creation and deployment of custom IoT applications tailored to specific business needs. Central to its capabilities is robust Device Management, which enables users to oversee, control, and secure a vast array of IoT devices from a centralized interface.\nAnother critical feature of Cumulocity is its Software Repository, a versatile component that allows users to upload and manage additional software artifacts. This repository is pivotal for deploying updates and new functionalities across connected devices efficiently, ensuring that the latest software is always at the forefront of operations. Furthermore, Cumulocity IoT provides robust security measures, including device authentication, encryption, and"}, {"title": "4 Architecture of EdgeMLOps", "content": "This section describes an end-to-end Edge AI inferencing workflow utilizing Cumulocity IoT, thin-edge, and the ONNX standard. The following outlines each step of the process, from model creation and management to deployment and real-time inferencing at the edge. It highlights the seamless integration of these technologies to enhance IoT operations."}, {"title": "5 Quantization Benchmark", "content": "In this section, we present the results of our experiments performed to compare different quantization algorithms. In general, quantization reduces the precision of weights and activations of a model to reduce its size and resource consumption and accelerate its inference. The drawbacks include the potential loss of accuracy if the model is calibrated incorrectly, which can lead to hard-to-debug problems. Acceleration might require specialized hardware which might not be available on the existing target.\nTo reduce the size of a floating point value, the value is scaled to either eight or lower-bit resolutions. To do that one can either scale symmetrically or asymmetrically. Symmetric quantization linearly reduces the range of the floating point to 8 bits. Asymmetric quantization calculates a custom zero point and thereby shifts the range of possible values. A quantize and corresponding de-quantize step replaces the original element and maintains its input and output shapes. Thereby the caller interaction does not change.\nONNX supports static and dynamic quantization but recommends the type based on the model and use case. The static calculation is favorable while using a well-known data distribution in development and inference, as dynamic quantization can be advantageous if data is not well-known beforehand, but is generally slower than its counterpart. ONNX recommends preprocessing ONNX models before quantization as compute graph optimizations can complicate debugging. Further, model validation can be done similarly to the original as input and output shapes remain identical."}, {"title": "6 Conclusion", "content": "This work presented EdgeMLOps, a framework designed to streamline the deployment and management of ML models on edge devices using Cumulocity IoT and thin-edge.io. The VQI use case demonstrated the practical application of this framework, showcasing its ability to facilitate real-time asset condition monitoring. Our evaluation of quantization methods revealed substantial performance gains on a Raspberry Pi 4, with signed-int8 quantization achieving up to a two-fold reduction in inference time and a four-fold reduction in model size while maintaining acceptable accuracy. These findings underscore the effectiveness of EdgeMLOps in enabling efficient AI at the edge. Future work will explore advanced quantization techniques, federated learning strategies, and expanded application domains to further optimize and broaden the impact of EdgeMLOps in industrial IoT environments."}]}