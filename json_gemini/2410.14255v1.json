{"title": "Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas", "authors": ["Xiang Hu", "Hongyu Fu", "Jinge Wang", "Yifeng Wang", "Zhikun Li", "Renjun Xu", "Yu Lu", "Yaochu Jin", "Lili Pan", "Zhenzhong Lan"], "abstract": "Scientific innovation is pivotal for humanity, and harnessing large language models (LLMS) to generate research ideas could transform discovery. However, existing LLMs often produce simplistic and repetitive suggestions due to their limited ability in acquiring external knowledge for innovation. To address this problem, we introduce an enhanced planning and search methodology designed to boost the creative potential of LLM-based systems. Our approach involves an iterative process to purposely plan the retrieval of external knowledge, progressively enriching the idea generation with broader and deeper insights. Validation through automated and human assessments indicates that our framework substantially elevates the quality of generated ideas, particularly in novelty and diversity. The number of unique novel ideas produced by our framework is 3.4 times higher than without it. Moreover, our method outperforms the current state-of-the-art, generating at least 2.5 times more top-rated ideas based on 170 seed papers in a Swiss Tournament evaluation.", "sections": [{"title": "1 Introduction", "content": "In recent years, LLMs have demonstrated remarkable progress across various challenging tasks, including solving mathematical problems (Romera-Paredes et al., 2024), proving mathematical theory (Wang et al., 2024a), and generating code to solve analytical or computational tasks (Huang et al., 2024). These progresses have opened up new possibilities to utilize LLMs to accelerate research (Wang et al., 2023a), including generating novel research ideas (Si et al., 2024; Wang et al., 2024b; Baek et al., 2024).\nOur work is dedicated to addressing the challenge of employing LLMs to produce high-caliber research ideas, with an emphasis on enhancing their novelty and diversity. Existing studies (Wang et al., 2024b; Si et al., 2024) tackle this challenge by integrating additional knowledge into the idea generation process. Wang et al. (2024b) enrich the process by incorporating co-occurrence entities with existing knowledge, prompting LLMs to generate ideas based on these entities. Si et al. (2024) suggest an iterative approach to retrieve topic-relevant papers through the Semantic Scholar API, utilizing retrieval-augmented generation (RAG) for idea generation. They find that \"LLM-generated ideas are judged as more novel (p < 0.05) than human expert\". However, they also show that \"LLMs lack diversity in idea generation\". We argue that this repetitive problem is due to the constrained scope and lack of direction in knowledge acquisition within these methods.\nBroadening the search scope, both in terms of breadth and depth, presents a significant challenge. The crux of the issue lies in determining which knowledge to retrieve. Traditional methods of en-"}, {"title": "2 Related work", "content": "In the past year, several studies on LLM-based scientific innovation (Yang et al., 2024; Baek et al., 2024; Lu et al., 2024; Wang et al., 2024b; Gu and Krenn, 2024) have been proposed, garnering significant attention from the LLM community. Among these studies, Baek et al. (2024) introduces a research agent that utilizes an external knowledge graph for co-occurrence entity search and integrates retrieved entities into idea generation of LLMs. To avoid generating similar ideas, Lu et al. (2024) treat past generated ideas as negative examples and instruct the LLM on what constitutes a negative example. To explore more external knowledge for innovation, some other works (Wang et al., 2024b; Gu and Krenn, 2024) propose prompting the LLM to generate ideas integrated with external knowledge, such as retrieved external entities or problem-solution pairs.\nConcurrent with our research, Si et al. (2024) introduce AI-Researcher, which, for the first time, demonstrates that LLMs can generate ideas deemed more novel than those written by human experts. In addition, they point out that using LLMs to directly evaluate different dimensions of scientific ideas is unreliable and propose an idea ranking method based on pairwise comparison, achieving an accuracy of 71.4% in distinguishing accepted and rejected submissions on real ICLR 2024 data. Although effective, the above approach often generate repetitive ideas (Si et al., 2024) due the lack of direction in acquiring new knowledge. In contract, our method provide a plan for searching new knowledge and suffer less from the repetitive problem."}, {"title": "2.1 LLM-based Scientific Innovation", "content": "tity and keyword retrieval are not goal-oriented and frequently yield knowledge that is not conducive to fostering innovation.\nIn order to address the above problem, we introduce an iterative planning framework for LLM-based idea generation that specifically targets the enhancement of the novelty and diversity of the ideas produced. Starting with seed ideas that generated using different scientific discovery methods, our framework undergoes multiple iterations of planning and searching. In each iteration, the model is tasked with devising a search plan aimed at identifying papers that will enhance the novelty and diversity of the current set of ideas.\nAs depicted in Fig. 1,the proposed iterative planning framework significantly enhances the quality of ideas generated from recent 170 LLM-related papers (from top conferences like ACL, ICLR, and CVPR). The number of high-quality ideas (as measured by the Swiss Tournament Score (Si et al., 2024)) is at least 2.5 times greater than those produced by other state-of-the-art methods. Moreover, the number of unique novel ideas generated by our iterative planning framework is 3.4 times higher compared to approaches that do not incorporate such a framework."}, {"title": "2.2 Reasoning and Planning", "content": "Reasoning has been proven to be an effective technique for enhancing the problem-solving capabilities of LLMs, and several studies have been conducted to further promote LLMs' reasoning abilities. Wei et al. (2022) propose chain of thought (CoT), which involves guiding LLMs to solve complex problems by generating a step-by-step reasoning process. Later, Wang et al. (2023c) improve CoT by sampling and comparing diverse reasoning pathways to enhance the consistency of the reasoning process. To solve problems harder than the exemplars shown in prompts, Zhou et al. (2023) propose to break down the complex problem into a series of simpler subproblems and then solve them in sequence. Generalizing from Chain of Thought (CoT), Yao et al. (2023a) propose the Tree of Thought (ToT) framework, enabling LLMs to explore multiple reasoning paths and conduct self-evaluations when determining the next action. To enable more effective exploration of the solution space, Xie et al. (2024) enhance the reasoning capabilities of LLMs by introducing Monte Carlo Tree Search (MCTS) with iterative preference learning. These methods significantly enhance the reasoning capabilities of LLMs; however, they seldom consider interacting with the external environment. To address this limitation, Trivedi et al. (2023) integrate CoT with knowledge retrieval, interleaving reasoning with searching to acquire additional external knowledge for knowledge-intensive question answering. Yao et al. (2023b) propose a Re-Act paradigm combining reasoning and acting for solving language reasoning and decision-making tasks. It creates and adjusts high-level plans for acting while also interacting with the external environments to incorporate additional information into reasoning. Later, Aksitov et al. (2023) develop a ReAct-style LLM agent to reason and act"}, {"title": "3 Nova Pipeline", "content": "The pipeline for Nova is illustrated in Fig. 2. Our pipeline streamlines the research process through three stages: initial idea generation, iterative refinement, and detailed completion. It begins with an input paper, which the LLM uses to generate initial ideas by drawing on related literature and scientific discovery techniques. These ideas are then enhanced through iterative planning and search, incorporating new insights. The final step involves detailing the ideas. An example of the whole process is in Fig. 3."}, {"title": "3.1 Initial Seed Idea Generation", "content": "To produce high-quality ideas, we design a multi-source seed idea generation module that initiates with diverse and novel concepts. This module activates the LLM to generate ideas using related literature and scientific discovery techniques upon receiving an input paper. The prompt for initial idea generation is in Tab. 1 (details is in Tab. 9) and an example of an initial seed idea is in Tab. 2.\nTo enrich the knowledge base with the most current insights, we utilize the input paper's references and have designed a knowledge tracking module. This module addresses the shortcomings of previous approaches by monitoring the latest publications. We pinpoint influential recent papers based on user engagement metrics such as likes, comments, and reposts across social media, forums, and GitHub. Furthermore, we harness LLMs to distill summaries of prevailing research trends from these papers, extracting valuable knowledge to enrich our target innovation efforts.\nTo further increase the diversity of the generated ideas, we employ 10 fundamental scientific discovery methods to guide LLMs in generating innovative ideas from an input paper and its as-"}, {"title": "3.2 Iterative Planning and Search for Seed Idea Improvement", "content": "Once an initial seed idea pool is generated, we start to iteratively planning and search new knowledge according to the see idea and generate new idea using the acquired new knowledge."}, {"title": "3.2.1 Planning and Search", "content": "In planning and search step, we guide the LLM to identify key fields for comprehensive and novel knowledge acquisition to enhance further research and idea generation based on the given ideas.\nThis approach, demonstrated through an in-context learning example, leverages the LLM's internal knowledge to determine useful knowledge for new ideas, surpassing traditional entity or keyword-based retrieval methods.\nNew Seed Idea Generation. Once new knowledge is acquired, the new seed idea is generated based on the retrieved papers, the initial seed idea, and given input paper. For each idea, our models generate 10 new seed ideas and then use self-reflection to cut the number down to 3.\nIn each iteration, the old seed ideas are replaced with the newly generated seed ideas. This allows our agent to dive deeper, largely expanding the scope of search. Therefore, in each iteration, we generate 3 times more seed ideas."}, {"title": "3.3 Output Idea Generation", "content": "After finishing T step iteration, we have a final seed idea pool. We then expand the seed idea into the"}, {"title": "4 Experiment", "content": "To validate our proposed iterative planning framework, we perform comprehensive comparisons with state-of-the-art research idea generation methods and conduct an ablation study."}, {"title": "4.1 Experimental Setup", "content": "Data. Our dataset is constructed by collecting high-quality papers from top conferences. The initial corpus comprised 7,805 papers from CVPR 2024, ACL 2024, and ICLR 2024. The keywords related to \"LLM\" are used to filter the initial corpus down to about 2,000 papers. Minimum citation number is used to further cut down the number to 153, with citation thresholds set at 20 for ICLR 2024 and 10 for CVPR 2024 and ACL 2024. We add an additional 17 papers from Hugging Face Daily Papers according to their user ratings. At the end, the dataset consists of 170 papers, each of which is used to generate 100 ideas for subsequent evaluation.\nBaseline. To compare our proposed approach with the state-of-the-art approaches, we choose three leading approaches as the baselines, including AI-Researcher (Si et al., 2024), AI-Scientist (Lu et al., 2024) and Research-Agent (Baek et al., 2024). For AI-researcher and AI-Scientist, we run the original code on our seed papers. For Research-Agent, we"}, {"title": "4.2 Experimental Results", "content": "Clearly, nova achieves a significantly higher Swiss score. 619 and 2521 of the ideas generated by Nova are scored at 4 and 5, significantly surpassing the performance of other agents. By incorporating iterative planning and search for external knowledge retrieval, Nova engages in more effective exploration for innovation. This may significantly enhance the novelty of the generated ideas. Since novelty is often the most important factor in evaluating idea quality, Nova consistently better than other state-of-the-art methods.\nFig. 5 shows that nova generates significantly more diverse ideas. As the number of generated ideas increases, Nova can continuously generate new ideas through iterative planning and search. In Non-Duplicate Percentage, Nova significantly"}, {"title": "4.2.1 Automatic Evaluation Results", "content": "The Swiss Tournament score comparison are shown in Fig. 4. The novelty and diversity comparison are shown in Fig. 5."}, {"title": "4.2.2 Human Evaluation Results", "content": "In our human evaluation, Nova achieves the highest scores for both overall quality and novelty. As shown in Fig. 6, Nova contributes 37.5% of the top 4 ideas, the highest among the four methods. Additionally, Nova has a notably low percentage of the worst 4 ideas, accounting for only 17.53% in terms of overall quality. In Fig. 7, a similar pattern is observed in novelty evaluation.\nOur human and automated evaluations show strong consistency in distinguishing between the top-rated and worst-rated ideas. By comparing the distribution of top-rated ideas in both human and automated evaluations (Fig. 4 and 6), it is evident that human reviewers and the LLM evaluate the performance of the four methods in a similar pattern. In both human and automatic evaluations, our method generates the highest proportion of top-rated ideas, followed by AI-Scientist, ResearchAgent, and finally AI-Researcher. This indicates that our automatic review mechanism effectively captures human reviewers' true preferences."}, {"title": "4.3 Ablation Study", "content": "To assess the effectiveness of planning and search in Nova, we conduct comparisons by gradually removing planning and retrieval components. All methods retrieve the same number of papers, specifically K = 5. Both retrieval and planning are found to significantly enhance the generation of unique and novel ideas. When planning is excluded, the number of unique ideas at step 3 (44.1) is no longer increases compared to step 2 (42.4). This suggests that without planning, relying solely on retrieval based on seed ideas limits access to valuable external knowledge for innovation. This limitation may arise from the restricted scope of search when planning is absent. Obviously, when planning and retrieval are both removed, the number of unique novel ideas increases slightly at step 2 (from 25.3 to 30.6) and stagnates at step 3 (from 30.6 to 31.35), due to no external knowledge are introduced."}, {"title": "5 Conclusion", "content": "In this paper, we propose an LLM-based scientific innovation method, Nova, which introduces iterative planning and search to retrieve external knowledge for innovation. Nova leverages the internal knowledge of LLMs to generate search plans for external knowledge retrieval, significantly enhancing the effectiveness of the retrieval process. Ablation study demonstrates the effect of the iterative planning and search framework on promoting the novelty of generating ideas. The automatic and human evaluations show that Nova significantly and consistently outperforms state-of-the-art scientific innovation methods. In the future, we will explore incorporating a reward function into our iterative planning framework to further enhance external knowledge retrieval."}, {"title": "6 Limitations", "content": "In this work, we investigate using iterative planning and search, mimicking the manner of our human beings, to enhance the innovation capability of existing LLM-based methods. Despite promising findings, some limitations remain in this work, which we discuss below:"}, {"title": "Limited Iterations Steps.", "content": "Although our approach can significantly enhance the novelty and diversity of generated ideas through iteration, we do not see an continues incrasement in generating new ideas after 3 round of iteration."}, {"title": "Planning without Rewards.", "content": "In our planning and search framework, we do not introduce reward functions but only use the internal knowledge of LLMs to generate search plans. This may limit the effectiveness of planning."}, {"title": "We hope these findings inspire future investiga-", "content": "tions into using LLM to comprehensively integrate both internal and external knowledge for LLM-based scientific innovation. We believe addressing each of these shortcomings will lead to exciting feature directions."}, {"title": "7 Ethics Statement", "content": "Publication Policy. The increasing use of AI to generate research ideas poses significant challenges to academic integrity. The growing accessibility of LLMs and the rising usefulness of LLMs in research may lead to deterioration in the overall quality of scholarly content, as individuals may rely on AI for both creativity and submission reviews. Therefore, there is a legitimate concern that students or researchers would exploit these technologies and present low-quality research proposals. To mitigate these risks, it is crucial to hold accountability for outputs generated through AI tools in scientific submissions."}, {"title": "Intellectual Credit.", "content": "Generative AI in the research cycle poses great concerns about intellectual credit on the submitted works. While traditional frameworks were more like a tool for human researchers, LLMs are more potent in a way that plays a more significant role in the scientific research process if used. It is still unclear how intellectual credit should be distributed in the case of AI-driven research. To better attribute credit to AI-supported research, researchers should adopt transparent documentation about their research process, including the extent of AI involvement in generating ideas and developing experiments."}, {"title": "Potential for Misuse.", "content": "AI-generated research ideas, particularly those introducing novel concepts, possess the potential for misuse. This could lead to harmful outcomes. Ideation agents may be exploited to develop adversarial attack strategies or other unethical applications. Therefore, it is important to develop anti-jailbreak mechanisms or safety checks on AI-generated content and the use of generative AI in research."}, {"title": "Idea Homogenization.", "content": "If AI was widely used in scientific research, this would raise concerns about the potential idea of homogenization. The wide adoption of LLMs in research could reflect a narrower set of perspectives or systematic biases compared to human researchers not using AI assistance. Therefore, it is important to recognize the limitations of current LLM-generated ideas, and future work should focus more on enhancing the generation diversity either by improving the models themselves or by refining the ideation process."}, {"title": "Impact on Human Researchers.", "content": "The challenge posed by Al's integration into research should be well recognized because research is fundamentally and historically a community-driven and collaborative effort. It is still unclear on the negative consequences of the introduction of AI in the research process. People should be cautious and aware of the potential decline in human thought and a reduction in opportunities for human collaboration after the introduction of AI in research. Future works should explore other methods of human-AI collaboration. Understanding how LLM should be integrated into the research process will be an ongoing problem."}]}