{"title": "MITIGATING GRAPH Covariate Shift vIA SCORE-BASED OUT-OF-DISTRIBUTION AUGMENTATION", "authors": ["Bohan Wang", "Yurui Chang", "Lu Lin"], "abstract": "Distribution shifts between training and testing datasets significantly impair the model performance on graph learning. A commonly-taken causal view in graph invariant learning suggests that stable predictive features of graphs are causally associated with labels, whereas varying environmental features lead to distribution shifts. In particular, covariate shifts caused by unseen environments in test graphs underscore the critical need for out-of-distribution (OOD) generalization. Existing graph augmentation methods designed to address the covariate shift often disentangle the stable and environmental features in the input space, and selectively perturb or mixup the environmental features. However, such perturbation-based methods heavily rely on an accurate separation of stable and environmental features, and their exploration ability is confined to existing environmental features in the training distribution. To overcome these limitations, we introduce a novel approach using score-based graph generation strategies that synthesize unseen environmental features while preserving the validity and stable features of overall graph patterns. Our comprehensive empirical evaluations demonstrate the enhanced effectiveness of our method in improving graph OOD generalization.", "sections": [{"title": "1 INTRODUCTION", "content": "Deep learning algorithms have become predominant in the analysis of graph-structured data. However, a common limitation of existing methods is the assumption that both training and testing graphs are independently and identically distributed (i.i.d.). This assumption often falls short in real-world scenarios, where shifts in data distribution frequently occur, leading to significant degradation in model performance. As a result, there has been considerable progress in improving graph out-of-distribution (OOD) generalization, evidenced by advancements in invariant graph learning (Chen et al., 2022; Wu et al., 2022; Huang et al., 2024) and graph data augmentation (Rong et al., 2019; Wang et al., 2021; Han et al., 2022; Yao et al., 2022; Sui et al., 2024; Li et al., 2024).\nRecent studies (Gui et al., 2022; Sui et al., 2024) have identified two primary types of distribution shifts. Correlation shifts occur when the statistical relationships between environments and labels differ between the training and testing datasets, assuming that the test environments are represented within the training dataset. Covariate shifts, on the other hand, arise when the test environments are not present in the training dataset. A prevalent causal perspective in graph invariant learning (Chen et al., 2022; Wu et al., 2022) suggests that stable features of graphs, which causally determine labels, remain invariant across different environments, whereas varying environmental features contribute to distribution shifts. Consequently, previous studies (Miao et al., 2022; Chen et al., 2022; Wu et al., 2022) have primarily focused on correlation shifts by isolating invariant stable graph patterns from the environmental features. In this work, we focus on the relatively neglected but challenging problem of covariate shift in graph learning.\nWhile different graph data augmentation techniques have been proposed to generate new data across various domains (Rong et al., 2019; Han et al., 2022; Sui et al., 2024), these methods mainly modify existing data within the training set by mixing or dropping edges, which either have limited environmental exploration ability or could result in invalid data samples (e.g., molecular graphs violating chemical rules). Moreover, indiscriminate augmentations (Rong et al., 2019) can distort stable patterns, resulting in uncontrollable augmented distributions. While controlled augmentations (Sui et al., 2024) have shown promising outcomes, they heavily depend on the accurate separation of stable and environmental patterns, which remains a nontrivial challenge and could be inherently infeasible. These observations prompt an essential inquiry: \"Is it possible to explore the training distribution under control, such that the exploration extends beyond the confines of the training environments while still preserving essential stable patterns?\u201d\nIn response, this work introduces an innovative score-based graph augmentation strategy that mitigates graph covariate shift by improving the exploration of training distribution while preserving stable predictive patterns on the generated graphs. In high level, we formulate the problem of OOD data augmentation as graph generation simultaneously conditioned on graph labels and exploration variables, based on the graph generation hypothesis widely used in prior studies (Wu et al., 2022; Yang et al., 2022; Gui et al., 2022; Chen et al., 2022). Specifically, we employ a score-based diffusion probabilistic model, commonly known as a diffusion model (Song et al., 2020), to effectively capture the data distribution of unlabeled graphs. During the generation phase, we introduce a novel guidance scheme that generates augmented graphs, concurrently retaining predictive stable patterns and incorporating explored environments. Our proposed Out-of-Distribution Diffusion Augmentation (OODA) framework utilizes graph labels to guide the sampling process toward graphs that are highly likely to contain stable patterns. The exploration parameter facilitates exploration beyond the training graph space by flexibly adjusting the discrepancy from the training distribution. The robustness of the score-based diffusion model ensures the validity of the generated graphs, preventing the formation of invalid structures (e.g., non-viable molecules) that could impair downstream classification performance. Furthermore, our guidance scheme eliminates the need to explicitly split graphs into stable and environmental subgraphs. We experimentally validate our method on both synthetic and real-world graph classification tasks under diverse covariate shift settings. Our results demonstrate that OODA outperforms state-of-the-art baselines, including invariant graph learning and graph data augmentation, highlighting its effectiveness in exploring environments under control while preserving stable patterns.\nOur main contributions are summarized as follows:\n\u2022 We propose a novel graph generation-based environment augmentation approach to address covariate distribution shifts in graph learning. Our method enables controlled exploration of environmental patterns while preserving stable patterns, without the need to explicitly separate them.\n\u2022 Our approach can simultaneously generate out-of-distribution (OOD) graph structures, node features, and edge features, making it uniquely capable of handling covariate shifts in both feature and structural distributions, as well as when these shifts occur simultaneously.\n\u2022 Extensive empirical evaluations demonstrate that our framework outperforms state-of-the-art graph OOD generalization methods across diverse tasks, including synthetic, semi-artificial, real-world molecular, and natural language sentiment analysis datasets."}, {"title": "2 RELATED WORK", "content": "Graph-structured data are inherently complex, characterized by the intricate challenges of irregularity and nuanced structural information. This complexity gives rise to graph out-of-distribution (OOD) problems that not only necessitate addressing shifts in feature distributions but also demand attention to variations of structural distributions. In this context, we summarize two principal categories of algorithms for graph OOD robustness: (i) invariant graph learning strategies, which aim to ensure model stability across varying distributions; and (ii) graph data augmentation techniques, designed to enhance model generalizability by simulating diverse distribution scenarios.\nInvariant Graph Learning. The concept of invariant graph learning draws inspiration from seminal works such as those by (Arjovsky et al., 2019; Rosenfeld et al., 2020; Ahuja et al., 2021). This approach aims at identifying stable graph structures (e.g., subgraphs) or representations (predictors) that remain consistent across different environments, thereby enhancing out-of-distribution (OOD) generalization. This is achieved by capturing salient graph features and minimizing empirical risks across varying conditions. For example, DIR (Wu et al., 2022) distinguishes between invariant and environment-specific subgraphs by creating varied interventional distributions on the training distribution. CIGA (Chen et al., 2022) further explores this domain by employing synthetic environments and the graph generation process to identify stable features under various distribution shifts. However, this line of research assumes access to test environments during training, which is an unrealistic assumption given the impracticality of covering all possible test scenarios. Training in limited environments reduces spurious correlations but fails to generalize to new, unseen environments. DISGEN (Huang et al., 2024) gains promising results in disentangling the size factors from graph representations by minimizing the shared information between size- and task-related information, however, the technique is constrained to handle size generalization. In this work, we propose a framework capable of generalizing to unseen environments characterized by differences not only in graph size but also in graph structure, node features, and edge features.\nGraph Data Augmentation. Beyond invariant graph learning, graph data augmentation aims to diversify the training distribution, thereby enhancing the out-of-distribution (OOD) generalization of models. DropEdge (Rong et al., 2019) introduces randomness by selectively removing edges, thus varying the training data's structure. M-Mixup (Wang et al., 2021) enriches the dataset by interpolating diverse and irregular graphs within semantic space. G-Mixup (Han et al., 2022) extends this concept to graph classification, interpolating across different graph generators (graphons) to produce augmented graphs. Adversarial augmentation techniques, such as FLAG (Kong et al., 2022), apply gradient-based perturbations to node features, and AIA (Sui et al., 2024) generates adversarial masks on graphs, both aimed at probing environmental discrepancies. Despite these advancements, overcoming the limitations in environmental exploration caused by modifying graphs within the original training set remains a challenge, indicating ongoing opportunities for innovation in graph data augmentation strategies. Recently, environment-aware augmentation frameworks (Li et al., 2024) have utilized environment information to linearly explore training graph structures and node features, however, they depend heavily on high-quality and sufficiently diverse environment information. In practice, annotating environment labels or capturing diverse environment information is costly and often infeasible. In this work, we introduce a generation-based augmentation method that eliminates the need for accessing environment information."}, {"title": "3 PROBLEM FORMULATION", "content": "Notations. We represent a graph with n nodes as $G = (A, X, E)$, where $A \\in \\mathbb{R}^{n \\times n}$ is the adjacency matrix, $X \\in \\mathbb{R}^{n \\times a}$ denotes a-dimensional node features and $E \\in \\mathbb{R}^{n \\times n \\times b}$ encodes b-dimensional edge features. Without the loss of generality, we focus on the graph classification task where each graph G is associated with a label $Y \\in \\mathcal{Y}$, determined by a predefined labelling rule $G \\rightarrow Y$. Following invariant learning (Ahuja et al., 2021; Chen et al., 2022), we denote the graph dataset as $\\mathcal{D} = \\{(G,Y)\\}_{e \\in \\mathcal{E}_{all}}$, where $(G,Y) \\sim P_e(G, Y)$ is an i.i.d. draw in the environment e sampled from all possible environments $\\mathcal{E}_{all}$. The complete dataset can be partitioned into a training set $\\mathcal{D}_{tr} = \\{(G,Y)\\}_{e \\in \\mathcal{E}_{tr}}$ and a test set $\\mathcal{D}_{te} = \\{(G, Y)\\}_{e \\in \\mathcal{E}_{te}}$, where $\\mathcal{E}_{tr}$ and $\\mathcal{E}_{te}$ index the training and testing environments, respectively. In practice, environment information may not be explicitly given, and we further denote the training distribution as $P_{tr}(G, Y)$ and the testing distribution as $P_{te}(G, Y)$.\nGraph Classification under Covariate Shift. With only observing the training set $\\mathcal{D}_{tr}$ sampled from the training distribution $P_{tr}$ in training environments $\\mathcal{E}_{tr}$, our generalization objective under graph covariate shift is to train an optimal graph classifier $f : \\mathcal{G} \\rightarrow \\mathcal{Y}$ that performs well across any possible environments $\\mathcal{E}_{all} \\supseteq \\mathcal{E}_{tr}$. We formulate this goal as the following minimization problem:\n$\\min_{f} \\mathbb{E}_{e \\in \\mathcal{E}_{all}} \\mathbb{E}_{(G_e, Y_e) \\sim P_e(G,Y)}[l(f(G_e), Y_e)],$ (1)\nwhere $l(.,.)$ denotes the loss function for graph classification and the expectation is with respect to graphs under all possible environments. However in practice, the training environments $\\mathcal{E}_{tr}$ may not cover all environments, causing degraded classification performance when applying the learned classifier in unseen test environments. This covariate shift calls for an effective manner to sufficiently explore unseen data distribution or environments during model training. We summarize and discuss the various types of graph covariate shifts in detail in Appendix A.2.\nIssues in Graph Augmentation via Environmental Exploration. To augment the training distribution for mitigating graph covariate shift, existing solutions often approach Eq. (1) by separating and augmenting the environments: $\\min_{f} \\mathbb{E}_{e \\in \\{\\mathcal{E}_{tr} \\cup \\mathcal{E}_{aug}\\}} \\mathbb{E}_{(G_e,Y_e) \\sim P_e(G,Y)} [l(f(G_e), Y_e)]$, where the augmented environments $\\mathcal{E}_{aug}$ are obtained based on either interpolating explicitly given environmental labels (Li et al., 2024) or perturbing implicitly separated environmental components (Sui et al."}, {"title": "4 SCORE-BASED OUT-OF-DISTRIBUTION GRAPH AUGMENTATION", "content": "In this section, we present the novel score-based graph augmentation framework, OODA, designed to generate augmented graphs that retain predictable stable features while also exploring new environments. We begin by discussing the score-based generative model for unlabeled graphs and then extend the model to handle out-of-distribution scenarios with controlled adaptation. Thereafter, we illustrate the working principles and implementation details of OODA.\nMotivation From the perspective of graph generation, the goal of exploring the training distribution $P_{tr}(G, Y)$ is to generate OOD graph samples from the conditional distribution $P_{tr} (G, Y | y_{ood})$ where $y_{ood}$ represents the OOD exploration condition. We assume an exploration variable $\\Lambda$ controls the extent of exploration within the training distribution $P_{tr}(G, Y)$. The augmented distribution $P_{tr}(G, Y)$ is then modelled by the conditional graph distribution $P_{tr} (G, Y | y_{ood} = 1)$, which can be decomposed as follows:\n$P_{tr} (G, Y | y_{ood} = 1) \\propto p (G) p (Y | G) p (y_{ood} = \\Lambda | G,Y)$ (3)\nExisting graph generation models (Jo et al., 2022; Martinkus et al., 2022; Vignac et al., 2022) cannot directly sample graphs from the conditional distribution in Equation (3), as it is infeasible to enumerate all possible $\\Lambda$ values and their corresponding graphs and labels to compute the normalized probabilities. To overcome this limitation, we propose a novel guidance scheme to direct the score-based generative model (Song et al., 2020) towards the target distribution.\nScore-based Graph Generation $p (G)$ in Equation 3 is the distribution of unlabelled graphs, which can be captured by score-based generative model (Song et al., 2020). The foundational work by (Song et al., 2020) introduced a method for modeling the diffusion process of data into noise and vice versa using stochastic differential equations (SDEs). For graph generation, this diffusion process gradually corrupts graphs into a prior distribution like the normal distribution. The model subsequently samples noise from the prior distribution and learns a score function to denoise the perturbed graphs. Given an unlabeled graph G, we use continuous time $t \\in [0,T]$ to index the diffusion steps $\\{G_t\\}_{t=1}^{T}$ of the graph, where $G_0$ represents the original distribution and $G_T$ follows a prior distribution. The forward diffusion process from the graph to the prior distribution is defined through an It\u00f4 SDE:\n$dG_t = f_t (G_t) dt + g_t dw,$ (4)\nthat incorporates linear drift coefficient $f_t(.) : \\mathcal{G} \\rightarrow \\mathcal{G}$ and scalar diffusion coefficient $g_t : \\mathcal{G} \\rightarrow \\mathbb{R}$ related to the amount of noise corrupting the unlabelled graph at each infinitesimal step t, along with a standard Wiener process w. In contrast, the reverse diffusion employs SDE that factors in the gradient fields or scores of the perturbed graphs $G_t$ for denoising and graph generation from T to 0:\n$dG_t = [f_t (G_t) - g_t^{2}\\nabla_{G_t} \\log p_t (G_t)] dt + g_t dw,$\nwhere $p_t (G_t)$ denotes the marginal distribution at time t in forward diffusion, with $f_t (G_t)$ and $g_t$ representing the drift and diffusion coefficients, respectively. dw here is the reverse-time standard Wiener process, and dt is an infinitesimal negative time step. The score network $s_{\\theta,t} (G_t)$ is trained to approximate the unknown score function $\\nabla_{G_t} \\log p_t (G_t)$. Although the score-based generative model can capture the distribution of unlabeled graphs, it cannot generate the pairs (G, Y) from the OOD distribution. To address this limitation, we introduce a novel OOD guidance scheme designed to generate OOD graphs and their corresponding label from a score-based generative model trained on unlabeled graphs.\nScore-based Graph Generation with OOD Control To explore the training distribution in a controlled manner, we propose a novel OOD-controlled score-based graph generative model capable of generating OOD graph samples and their corresponding labels. The extent of exploration in the generative process is regulated by the hyperparameter $\\Lambda$. An overview is provided in Figure 1. Our approach involves sampling (G, Y) from $P_{tr} (G, Y | y_{ood} = 1)$ and solving the conditional reverse-time SDE:\n$dG_t = [f_t (G_t) - g_t^{2}\\nabla_{G_t} \\log p_t (G_t, Y_G | y_{ood} = 1)] dt + g_t dw$ (5)\nWhere $y_G$ denotes the graph's label and $y_{ood}$ specifies the amount of OOD exploration. To sample explored graph instances from $P_{tr} (G, Y | y_{ood} = \\Lambda)$ using a diffusion model, we note that $\\nabla_{G_t} \\log p_t (G_t, Y_G | y_{ood} = 1) = \\nabla_{G_t} \\log p_t (G_t | Y_G, y_{ood} = \\Lambda)$. The proof is in Appendix A.1. Therefore, the desired conditional reverse-time SDE becomes:\n$dG_t = [f_t (G_t) - g_t^{2}\\nabla_{G_t} \\log p_t (G_t | Y_G, y_{ood} = \\Lambda)] dt + g_t dw$ (6)\nAccording to Equation 3, the conditional score function $\\nabla_{G_t} \\log p_t (G_t | Y_G, y_{ood} = \\Lambda)$ is the sum of three components:\n$\\nabla_{G_t} \\log p_t (G_t | Y_G, y_{ood} = 1) = \\nabla_{G_t} \\log p_t (G_t) + \\nabla_{G_t} \\log p_t (y_G | G_t) + \\nabla_{G_t} \\log p_t (y_{ood} = \\Lambda | G_t,y_G)$ (7)\nBased on Bazhenov et al. (2022); Wu et al. (2023), OOD graphs are those with low likelihood under the original distribution $P_{tr}(G, Y)$. For instance, in the Motif training dataset (Gui et al., 2022), a house motif (stable subgraph) is only connected with wheel graphs, tree graphs or ladder graphs (environmental subgraphs). Consequently, when environmental graphs are explored, the entire graph patterns exist in the low-density region of the original distribution. Inspired by Lee et al. (2023), we model the distribution $p_t (y_{ood} = \\Lambda | G_t,y_G)$ as proportional to the negative exponent of the joint density of $G_t$ and $y_G$, $p_t (G_t, y_G)$:\n$p_t (y_{ood} = \\Lambda | G_t,y_G) \\propto p_t (G_t, Y_G)^{-\\sqrt{\\Lambda}} = p_t (G_t)^{-\\sqrt{\\Lambda}} p_t (Y_G | G_t)^{-\\sqrt{\\Lambda}}$ (8)\nAccordingly, the gradient of the log probability for conditional reverse diffusion is expressed as:\n$\\nabla_{G_t} \\log p_t (G_t | Y_G, y_{ood} = 1) = (1 - \\sqrt{\\Lambda}) \\nabla_{G_t} \\log p_t (G_t) + (1 - \\sqrt{\\Lambda})\\nabla_{G_t} \\log p_t (y_G | G_t)$ (9)\nAs seen in Equation 9, we need to compute the target class probability for the conditional score functions. To achieve this, we train a classifier $\\phi_t$ to predict graph label $y_G$ from the noisy graph $G_t$ at time step t: $\\phi_t(G_t) = y^G$. The output probability of $\\phi_t$ can approximate the distribution $p_t (y_G | G_t)$.\nConsequently, the conditional score function in Equation 6 results in a marginal distribution proportional to $p_t (G_t, y_G)^{1-\\sqrt{\\Lambda}}$. When $\\Lambda = 0$, the marginal distribution in Equation 6 simplifies to $p_t (G_t, y_G)$. The reverse-time diffusion process denoises the perturbed graphs to the augmented distribution $P_{tr} (G, Y | y_{ood} = 0)$, which closely resembles the original distribution $P_{tr} (G, Y)$. As $\\Lambda$ increases, the augmented distribution $P_{tr} (G, Y | y_{ood} = \\lambda)$ becomes more uniform relative to the original data distribution. By adjusting $\\Lambda$, we can flexibly control the dispersion, making the generated graphs more likely to be out-of-distribution. Consequently, we can increase the divergence between $P_{tr} (G, Y | y_{ood} = \\lambda)$ and $P_{tr} (G, Y)$.\nWorking principles of OODA. OODA not only explores controllable environmental features but also preserves stable features. According to Equation 7, the term $\\nabla_{G_t} \\log p_t (y_{ood} = \\Lambda | G_t,y_G)$ directs the reverse diffusion process towards out-of-distribution regions with graphs that exhibit the explored environmental patterns. Additionally, the term $\\nabla_{G_t} \\log p_t (y_G | G_t)$ guides the reverse diffusion process towards regions containing graphs that are highly likely to possess patterns determining the target class. Although we use a classifier to approximate the target class probability $p_t (y_G | G_t)$, the classifier is able to predict the target class even in the presence of noise. By iteratively adding noise, the classifier captures the relationship between the stable patterns in the perturbed graph $G_t$ and the target class. Together, these two terms guide the sampling process to generate graphs that contain desired stable patterns and extend beyond the training environments.\nIn addition to the aforementioned principles, OODA can generate diverse and valid OOD graph instances for the final graph classification problem under distributional shifts. This capability is based on the inherent randomness in the forward processes and the effectiveness of the reverse process in the diffusion model.\nImplementations of OODA. Directly applying this framework to graphs proved inadequate for capturing the intricate relationships between nodes and edges, essential for accurately learning graph distributions (Jo et al., 2022). To overcome this, we simultaneously models the diffusion processes of node features and adjacency matrices of perturbed graphs $\\{G_t = (X_t, A_t)\\}_{t=0}^{T}$ using a set of SDEs for Equation 6:\n$dX_t = [f_{1,t} (X) - (1 - \\sqrt{\\Lambda})g_{1,t}^{2}\\nabla_{X_t} \\log P_t (X_t, A_t) - (1 - \\sqrt{\\Lambda})g_{1,t}^{2}\\nabla_{X_t} \\log p_t (Y_G | X_t, A_t)] dt + g_{1,t} dw_1 \\ dA_t = [f_{2,t} (A) - (1 - \\sqrt{\\Lambda})g_{2,t}^{2}\\nabla_{A_t} \\log P_t (X_t, A_t) - (1 - \\sqrt{\\Lambda})g_{2,t}^{2}\\nabla_{A_t} \\log p_t (Y_G | X_t, A_t)] dt + g_{2,t} dw_2.$ (10)\nwhere $f_t(X, A) = (f_{1,t}(X), f_{2,t}(A))$ and $g_t = (g_{1,t}, g_{2,t})$ representing the drift and diffusion coefficients, respectively. The reverse-time processes are captured by standard Wiener processes $w_1$ and $w_2$, with dt indicating an infinitesimally small negative time step. We train one graph transformer (Dwivedi & Bresson, 2020; Vignac et al., 2022), denoted as $s_{\\theta,t} = (s_{\\theta 1,t}, s_{\\theta 2,t})$ to closely estimate the partial score functions $\\nabla_{X_t} \\log p_t (X_t, A_t)$ and $\\nabla_{A_t} \\log p_t (X_t, A_t)$, facilitating the backward simulation of the equation to simultaneously generate node features and adjacency matrices of unlabelled graphs. Therefore, the denoising graph transformer is only trained with unlabelled graphs without $\\Lambda$ values and graph labels. The graph transformer with perturbed node features $X_t$, adjacency matrices $A_t$ and normalized timestep as input. The timestep t value is treated as a global graph feature, and an embedding layer is used to embed t.\nWe also use a graph transformer model $\\phi_t$ with the same architecture to predict the class label of the noisy graphs $G_t = (X_t, A_t)$ at time step t. The target class j probability $p_t (y_G = j | X_t, A_t)$ is then given by:\n$p_t (y_G = j | X_t, A_t) = \\frac{e^{\\phi_t (X_t, A_t) [j]}}{\\sum_{j=1}^{M}e^{\\phi_t (X_t, A_t) [j]}}$\nOnce both the score transformer and the classifier are trained, we use them to compute the conditional partial scores during the sampling process.\nWe adopt the two popular time-dependent hyperparameters $\\alpha_{1,t}$ and $\\alpha_{2,t}$ for the target class probability predicted by $\\phi_t$. These hyperparameters are defined as follows:\n$\\alpha_{1,t} = 0.1^t \\frac{r_1 ||s_{\\theta 1,t} (G_t)||}{\\|\\nabla_{X_t} \\log P_t (y_G | X_t, A_t)\\|}, \\\\ \\alpha_{2,t} = 0.1^t \\frac{r_2 ||s_{\\theta 2,t} (G_t)||}{\\|\\nabla_{A_t} \\log P_t (Y_G | X_t, A_t)\\|}$ (11)\nwhere $\\alpha_t = (\\alpha_{1,t}, \\alpha_{2,t})$, $r_1$ and $r_2$ are the weights for node features and adjacency matrices respectively, and $\\| \\cdot \\|$ is the entry-wise matrix norm.\nIntuitively, at the early stages of the reverse-time SDEs, the graphs are highly perturbed, resembling the prior noise distribution. Therefore, the classifier cannot accurately approximate the target class probability. Consequently, in the initial denoising steps, we focus more on guiding the reverse-time SDEs towards the OOD distribution. As the reverse-time SDEs progressively denoise the graphs, we introduce guidance to direct the reverse-time SDEs towards regions exhibiting the desired stable patterns and the explored OOD environmental patterns."}, {"title": "5 EXPERIMENTS", "content": "In this section, we first demonstrate the effectiveness of our diffusion models on graph OOD tasks in Section 5.2, then validate the efficacy of our OOD-controlled diffusion process on GOOD-Motif and GOOD-HIV datasets in Section 5.3. We further conduct an ablation study to verify the effectiveness of our diffusion models to generate OOD graphs in Section 5.3"}, {"title": "5.1 EXPERIMENTAL SETTINGS", "content": "Setup. For a fair comparison, we adopt the same evaluation metrics as those used in (Gui et al., 2022). The model that achieves the best performance on the OOD validation sets is then evaluated on the OOD test sets. Furthermore, to ensure fair comparison across all methods, we utilize the same GNN backbones-GIN (Xu et al., 2019) and GIN-Virtual (Xu et al., 2018; Gilmer et al., 2017)\u2014as applied in the GOOD benchmark (Gui et al., 2022) for each dataset. The experimental details, including evaluation metrics and hyperparameter configurations, are summarized in Appendix A.4.\nDatasets. We use synthetic, semi-artificial, and real-world datasets from GOOD (Gui et al., 2022), including GOOD-Motif, GOOD-CMNIST, GOOD-HIV, and GOOD-SST2. Consistent with (Gui et al., 2022), we apply base, size, color, scaffold, and length data splits to introduce diverse covariate shifts in graph structure, node features, and edge features. Detailed descriptions of the datasets are provided in Appendix A.4.\nBaselines. We adopt 16 baselines, which can be divided into the following three specific categories:(i) general generalization algorithms, including ERM, IRM (Arjovsky et al., 2019), Group-DRO (Sagawa et al., 2019), VREx (Krueger et al., 2021), DANN (Ganin et al., 2016), Deep Coral (Sun & Saenko, 2016); (ii) graph generalization algorithms, including DIR (Wu et al., 2022), GSAT (Miao et al., 2022), CIGA (Chen et al., 2022), and (iii) graph data augmentation techniques, including DropNode (Feng et al., 2020), DropEdge (Rong et al., 2019), MaskFeature (Thakoor et al., 2021), FLAG (Kong et al., 2022), M-Mixup (Wang et al., 2021), G-Mixup (Han et al., 2022), AIA (Sui et al., 2024)."}, {"title": "5.2 GRAPH OUT-OF-DISTRIBUTION CLASSIFICATION", "content": "The graph classification performances under covariate shift are presented in Table 1. As shown, OODA consistently outperforms all baseline methods across diverse covariate shifts and different datasets.\nOn the synthetic dataset GOOD-Motif, OODA achieves a performance improvement of 6.59% over ERM under base shift and 9.07% under size shift. For the semi-artificial dataset GOOD-CMNIST, designed for node feature shifts, performance is significantly enhanced by 18.23% compared to the leading graph augmentation method, AIA, and improved by 21.40% over the best graph invariant learning method, DIR. In the real-world molecular dataset GOOD-HIV, where covariate shifts occur in graph structure, node features, and edge features simultaneously, OODA outperforms ERM by 2.09% on scaffold shift and by 6.53% on size shift. For the real-world natural language sentiment analysis dataset GOOD-SST2, while AIA is outperformed by MaskFeature by 0.31%, OODA exceeds MaskFeature by 0.69%.\nThese results demonstrate that no baseline graph invariant learning or graph data augmentation methods consistently outperform each other under various covariate shifts. OODA enhances environmental exploration by generating out-of-distribution (OOD) graphs in a controlled manner while preserving stable features. Consequently, OODA reliably improves performance across different datasets facing various covariate shifts."}, {"title": "5.3 OOD CONTROLLED GRAPH GENERATION", "content": "In this section, we present both qualitative and quantitative experiments to demonstrate the effectiveness of our out-of-distribution diffusion augmentation framework. The experiments are conducted using the GOOD-Motif-base and GOOD-HIV-scaffold datasets."}, {"title": "6 CONCLUSION", "content": "In this work, we proposed OODA, an out-of-distribution graph generation framework based on a score-based diffusion probabilistic model, designed to address covariate shifts in graph learning. Our approach generates OOD graph samples that integrate both explored environmental and stable features, eliminating the need to separate them during training. Furthermore, OODA can simultaneously explore new environments in graph structure, node features, and edge features. While score-based diffusion models demonstrate significant potential in handling diverse covariate shifts, they present scalability challenges when applied to large-scale graphs. Additionally, generating OOD graphs may require careful tuning of hyperparameters in the guidance scheme to balance exploration quality, particularly across different datasets. In this study, we applied minimal hyper-parameter tuning to achieve competitive results. Future work could focus on developing scalable diffusion models and exploring parameter-efficient tuning strategies to further enhance OOD graph generation."}, {"title": "A APPENDIX", "content": ""}, {"title": "A.1 PROOFS", "content": "$\\nabla_{G_t"}, "log p_t (G_t, Y_G | y_{ood} = 1) = \\nabla_{G_t} \\log p_t (G_t | Y_G, y_{ood} = 1)$\nProof:\n$\\log p_t (G_t, Y_G | y_{ood} = \\Lambda) = \\log p_t (G_t, y_G, y_{ood} = \\Lambda) - \\log p_t (y_{ood} = \\Lambda)$\nSince $p_t (y_{ood} = \\Lambda)$ is independent of $G_t, \\nabla_{G_t} \\log p_t (y_{ood} = \\Lambda) = 0$. Therefore,\n$\\nabla_{G_t} \\log p_t (G_t, Y_G | y_{ood} = \\Lambda) = \\nabla_{G_t} \\log p_t (G_t, y_G, y_{ood} = ) $\nAdditionally,\n$\\nabla_{G_t} \\log p_t (G_t, Y_G | y_{ood} = \\Lambda) = \\nabla_{G_t} \\log p_t (G_t | Y_G, y_{ood} = ) $\n$\\log p_t (G_t | Y_G, y_{ood} = 1) = \\log p_t (G_t, Y_G, y_{ood}"]}