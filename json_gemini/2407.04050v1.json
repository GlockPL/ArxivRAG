{"title": "Deep Content Understanding Toward Entity and Aspect Target Sentiment Analysis on Foundation Models", "authors": ["Vorakit Vorakitphan", "Milos Basic", "Guilhaume Leroy Meline"], "abstract": "Introducing Entity-Aspect Sentiment Triplet Extraction (EASTE), a novel Aspect-Based Sentiment Analysis (ABSA) task which extends Target-Aspect-Sentiment Detection (TASD) by separating aspect categories (e.g., food#quality) into predefined entities (e.g., meal, drink) and aspects (e.g., taste, freshness) which add a fine-gainer level of complexity, yet help exposing true sentiment of chained aspect to its entity. We explore the task of EASTE solving capabilities of language models based on transformers architecture from our proposed unified-loss approach via token classification task using BERT architecture to text generative models such as Flan-T5, Flan-Ul2 to Llama2, Llama3 and Mixtral employing different alignment techniques such as zero/few-shot learning, Parameter Efficient Fine Tuning (PEFT) such as Low-Rank Adaptation (LoRA). The model performances are evaluated on the SamEval-2016 benchmark dataset representing the fair comparison to existing works. Our research not only aims to achieve high performance on the EASTE task but also investigates the impact of model size, type, and adaptation techniques on task performance. Ultimately, we provide detailed insights and achieving state-of-the-art results in complex sentiment analysis.", "sections": [{"title": "1. Introduction", "content": "Sentiment Analysis (SA) is the field of Natural Language Processing (NLP) that aims to extract and analyze sentiments, opinions, attitudes and emotions expressed towards certain entities from a textual data. Traditionally, SA focused on detecting the overall polarity e.g., positive, negative or neutral. As such, it brings limited amount of information, often insufficient for most of the real world applications (Liu, 2012). Hence, in the past decade, the research recognized fine-grained SA frequently named as Aspect Based Sentiment Analysis (ABSA) (Pontiki et al., 2014; 2015; 2016) whose task fundamentally consists of detecting two components which are targets and its corresponding sentiments. According to Zhang et al. (2022) the target can be described as either aspect category or aspect term, sentiment can be described as sentiment polarity that often attaches by opinion term. Depending on the motives, not all authors aim to extract these elements simultaneously, but they would rather focus on identifying specific subgroups and the relations among its elements which are consequently leading to the creation of various so called ABSA subtasks.\nHowever, the transformer architectures (Vaswani et al., 2017) with pre-trained knowledge (aka Foundation Models (FMs)) influence most of the NLP tasks to not require a specific architecture to train from scratch on a large corpus of data, but rather the best performing solutions rely on adaptation of FMs (Bommasani et al., 2022) for downstream tasks. Generally, Large Language Models (LLMs) can achieve high performance on a downstream task relying only on their emergent abilities (Zhao et al., 2023), without their weights being updated. Such adaption for a downstream task is called zero- or few-shot learning (Brown et al., 2020) toward the text generation approaches (aka Generative AI or GenAI). In recent years, GenAI including models like Llama2 (Touvron et al., 2023), Llama3 1, Mistral (Jiang et al., 2023), Mixtral (Jiang et al., 2024). These models have gained the popularity in research areas and industries that revolutionized NLP applications by enabling high performance on various tasks through optimized prompting techniques rather than extensive fine-tuning. These models are pre-trained on vast and diverse datasets and can efficiently handle both simple and complex NLP tasks by simply refining prompts. This approach simplifies deployment and enhances adaptability, making instruct models particularly effective for tasks such as classification, text generation, summarization, and translation tasks.\nIn this work, we propose a fine-grainer detection of aspect category into what we called entity (i.e., meal) and"}, {"title": "2. Related Work", "content": "In this section, we highlight relevant research that shares the SoTA target sentiment analysis work. Regarding the ABSA subtasks which have been introduced as a task for SemEval14 (Pontiki et al., 2014) and continued to be present on both SemEval15 (Pontiki et al., 2015) and SemEval16 (Pontiki et al., 2016) competitions, most of complex SA tasks were introduced as compound ABSA subtasks (Zhang et al., 2022) which aims to extract simultaneously multiple elements \u2013 pairs, triplets or quadruplets from a given sentence or a text. Among for our research relevant tasks such as Aspect Category Sentiment Analysis (ACSA), Aspect Sentiment Triplet Extraction (ASTE), and Aspect Sentiment Quad Prediction (ASQP), we highlight Target-Aspect-Sentiment Detection (TASD).\nTarget-Aspect-Sentiment Detection (TASD). TASD aims to extract target, aspect, sentiment triplets. Target Aspect Sentiment Detection was introduced by Wan et al. (2020) and for a review sentence S aims to extract all (t, a, s) triplets:\nTASD(S) = {(t1, a1, 81), ..., (tn, an, Sn)}\nwhere ti stands for target and is a subsequence of S if explicit and NULL if implicit, a\u017c \u2208 {a1, ..., an} stands for aspect and si \u2208 {positive, negative, neutral} for sentiment polarity. For example, in the restaurant review sentence 'The food arrived 20 minutes after I called, cold and soggy.', output of TASD should be {(NULL, SERVICE#GENERAL, negative), (food, FOOD#QUALITY, negative)}\nTo our knowledge, Brun & Nikoulina (2018) and Wan et al. (2020) have addressed this problem using available parsers and domain-specific semantic lexicons and pre-trained BERT-based architecture respectively. In additional, the work of Zhang et al. (2021) defines the TASD as sequence-to-sequence learning problem and solves it in a generative manner using encoder-decoder T5 architecture (Raffel et al., 2019)."}, {"title": "3. Task Definition", "content": "Pontiki et al. (2015) define an entity e, for instance in the domain of restaurants, as either the reviewed entity itself (restaurant), or another relevant entities directly related to it (e.g. food, service, ambience), while the aspect a is a particular attribute (e.g., quality, price, general) of the entity in question. The sentiment polarity s is defined as a polarity of the opinion(s) expressed towards the target. All three pieces of information are extracted from a predefined set of entities e \u2208 {e1, ..., en} and aspects a \u2208 {a1, ..., an } for every specific domain of interest, while sentiment polarity s \u2208 {positive, negative, neutral} remains the same per domain. Wan et al. (2020) combine what Pontiki et al. (2015) defined as entity and aspect into one element as \"aspect\", taking into account only e and a combinations that appear in the analyzed datasets, which might not cover all true possible combinations.\nTherefore, we follow the definitions by Pontiki et al. (2015) and define new ABSA subtask which considers entity and aspect as two different elements. Hence, for a given sentence S extracts all (e, a, s) triplets but taking into account that each of the triplets relates to the corresponding target:\nEASTE(S) = {(t1, \u20ac1, a1, 81), ..., (tn, en, an, Sn)}\nwhere ti stands for target and is a subsequence of S if explicit and NULL if implicit, ei \u2208 {e1,...,en} stands for entity, ai \u2208 {a1,...,an} stands for aspect and si \u2208 {positive, negative, netural} for sentiment polarity. If we take the same restaurant sentence 'The food arrived 20 minutes after I called, cold and soggy.', output of EASTE should be {(NULL, SERVICE, GENERAL, negative), (food, FOOD, QUALITY, negative)}. Hence, we break the aspect into two elements as \"entity\" and \"aspect\" where each of them comes from different, independent dataset and is combined after its individual prediction in what Wan et al. (2020) define as aspect. This scenario of extraction creates"}, {"title": "4. Dataset", "content": "Our work relies on the latest benchmark in this category which is SemEval16 (Pontiki et al., 2016). We adopt the review sentences for restaurants domain. For each given sentence (e, a, s) triplets are annotated where e \u2208 {1,2,... en} stands for entity, a \u2208 {a1, a2, ... an } for aspect category, and s \u2208 {positive, negative, neutral} for sentiment. e, a and s are chosen from different predefined inventories. To each of the triplets, a target term is attached towards which the opinion is expressed. If it is expressed explicitly, the target term is a subset of the words of corresponding review sentence, and NULL if implicitly. The dataset contains 2000 review sentences for train set, and 676 review sentences for test set."}, {"title": "5. Methodology and Experimentation", "content": "In this section, we discuss our experimental settings to explore EASTE task while the token classification tasks were run locally using Apple CPU and MPS devices. For text generative tasks via LLMs like Llama2, Llama3, and Mixtral models, we use API calls for model inference hosted via IBM watsonx.ai2.\n5.1. Classification Approach\nWe solve EASTE task using a proposed unified-loss approach toward token classification task which is applied on a sentence S using BERT architecture. Figure 1 demonstrates our implementation of the unified-loss approach based on token classification where a triple classifier is introduced after a loss function per gate. Each token in S represents {t1, t2, ..., tn}, every t provides single or multiple (entity, aspect, sentiment) triplets where t = {(e1, a1, 81), ..., (en, an, Sn)}. We modify the last linear layer of BERT-based-uncased architecture and consequently adapt model's loss function to obtain three classification results where the losses l are computed as an average loss l(joint). The final loss is calculated as a mean of losses via the additional of loss logits then divided by number of output gate of each entity, aspect, sentiment as following:\nl(joint) = \\frac{l(entity) + l(aspect) + l(sentiment)}{Number\\ of\\ output\\ gates}\nwhere l(entity), l(aspect), l(sentiment) are individual cross entropy losses for entity, aspect and sentiment obtained per token.\n5.2. Text Generation Approach\nIn the Text Generation Task framework, models generate an output in dictionary format from an input prompt4 which consist of input sentence S and instruction Inst. GenAI models for EASTE task aim to capture information on specific triplets containing entities, aspects, and sentiment polarity. For each input sentence S, the model generates {t1, t2, ..., tn} tokens where n varies for different input t as output, then we encode them into text format. Using zero and few-shot learning approaches and fine-tuning for a downstream task, the model is trained"}, {"title": "6. Results Analysis", "content": "The main indicator of model performance in our experimentation is F1 score. For each of methodology settings, we defined a way to calculate F1 score in order to get comparable results. In general, the (e, a, s) triplets are considered predicted correctly if and only if the prediction is attached to the correct corresponding target term.\nSetting 1: As the target term is composed of either one or multiple words if the opinion expressed explicitly towards entity, we consider prediction correct only if 50% or more tokens of the target term are predicted correctly. On the other hand, if the opinion is expressed implicitly we expect model to attach (e, a, s) triplet to cls token.\nSettings 2 and 3: We consider prediction correct only if (e, a, s) triplet is generated attached to correct corresponding target term if opinion expressed explicitly towards an entity, otherwise we expect a target term to be predicted as 'NULL'."}, {"title": "7. Conclusion", "content": "This research introduces EASTE, a novel and complex task for detecting ABSA settings through various NLP techniques. Our results underscore the critical importance of selecting appropriate fine-tuning techniques and prompting strategies tailored to the size and type of LLMs. By employing diverse approaches such as token classification, text generation, and fine-tuning alignments, we assessed model performance across different architectures and sizes. Our findings demonstrate the efficacy of the proposed unified-loss approach in token classification, particularly for less complex tasks like TASD. Additionally, the potential of text generative models combined with advanced prompting strategies is evident. We also highlight the necessity of choosing suitable fine-tuning techniques and model architectures based on task complexity and available resources. This research offers significant contributions to the field of sentiment analysis, providing deeper insights into sophisticated NLP techniques and models for complex sentiment analysis tasks. Our work advances the understanding of deep content analysis for sentiment detection and sets a foundation for future explorations in the realm of natural language processing."}, {"title": "A. Appendix.", "content": "Prompts used in Entity Aspect Sentiment Triplet Extraction (EASTE) task are listed below.\n1. Flan-T5, Tk-Instruct and Flan-UL2 models:\nDefinition: In this task you are given a review sentence and your task is to extract the triplet of information 'entity':'aspect':'sentiment' for each term' (implicit or explicit) the opinion is expressed towards in the given review sentence. The final output should be in shape 'term':'entity':' aspect':'sentiment'. Every implicit 'term' should be classified as 'NULL'.\nExample 1-\nInput: great food, great wine list, great service in a great neighborhood...\nOutput: food:food:quality:positive, wine list:drinks:style_options:positive,\nservice:service:general:positive, neighborhood:location:general:positive\nExample 2-\nInput: Rather than preparing vegetarian dish, the chef presented me with a plate of steamed vegetables (minus sauce, seasoning, or any form or aesthetic presentation).\nOutput: vegetarian dish:food:quality:negative, vegetarian dish:food:\nstyle_options:negative, chef:service:general:negative\nExample 3-\nInput: The chicken lollipop is my favorite, most of the dishes (I have to agree with a previous reviewer) are quite oily and very spicy, especially the Chilli Chicken.\nOutput: chicken lollipop:food:quality:positive, dishes:food:quality:negative,\nChilli Chicken:food:quality:negative\nExample 4-\nInput: Also, they do not take credit card so come with cash!\nOutput: NULL:restaurant:miscellaneous:neutral\nExample 5-\nInput: The appetizers we ordered were served quickly an order of fried oysters and clams were delicious but a tiny portion (maybe 3 of each).\nOutput: fried oysters and clams:food:quality:positive, fried oysters and\nclams:food:style_options:negative, NULL:service:general:positive\nExample 6-\nInput: The service was spectacular as the waiter knew everything about the menu and his recommendations were amazing!\nOutput: service:service:general:positive, waiter:service:general:positive\nExample 7-\nInput: I book a gorgeous white organza tent which included a four course prix fix menu which we enjoyed a lot.\nOutput: white organza tent:ambience:general:positive, four course prix fix menu:food:quality:positive\nExample 8-\nInput: The place is beautiful!"}]}