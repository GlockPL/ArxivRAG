{"title": "Cognitive Evolutionary Learning to Select Feature Interactions for Recommender Systems", "authors": ["Runlong Yu", "Qixiang Shao", "Qi Liu", "Huan Liu", "Enhong Chen"], "abstract": "Feature interaction selection is a fundamental problem in commercial recommender systems. Most approaches equally enumerate all features and interactions by the same pre-defined operation under expert guidance. Their recommendation is unsatisfactory sometimes due to the following issues: (1) They cannot ensure the learning abilities of models because their architectures are poorly adaptable to tasks and data; (2) Useless features and interactions can bring unnecessary noise and complicate the training process. In this paper, we aim to adaptively evolve the model to select appropriate operations, features, and interactions under task guidance. Inspired by the evolution and functioning of natural organisms, we propose a novel Cognitive EvoLutionary Learning (CELL) framework, where cognitive ability refers to a property of organisms that allows them to react and survive in diverse environments. It consists of three stages, i.e., DNA search, genome search, and model functioning. Specifically, if we regard the relationship between models and tasks as the relationship between organisms and natural environments, interactions of feature pairs can be analogous to double-stranded DNA, of which relevant features and interactions can be analogous to genomes. Along this line, we diagnose the fitness of the model on operations, features, and interactions to simulate the survival rates of organisms for natural selection. We show that CELL can adaptively evolve into different models for different tasks and data, which enables practitioners to access off-the-shelf models. Extensive experiments on four real-world datasets demonstrate that CELL significantly outperforms state-of-the-art baselines. Also, we conduct synthetic experiments to ascertain that CELL can consistently discover the pre-defined interaction patterns for feature pairs.", "sections": [{"title": "I. INTRODUCTION", "content": "Accurate targeting of commercial recommender systems is of great importance, in which feature interaction selection plays a key role. Nowadays, feature interaction selection facilitates a variety of applications. For example, with multi-billion dollar business on display advertising, Click-Through Rate (CTR) prediction has received growing interest from both academia and industry communities [1]\u2013[4]. Another emerging application is client identifying in FinTech, i.e., intelligent financial advisors of online bank apps attempt to predict whether users are willing to purchase their recommended portfolios [5]. To support such services, it is necessary to well organize the massive high-dimensional sparse user features. Since research has shown that interaction of feature pairs can provide predictive abilities beyond what those features can provide individually [6], this brings out the fundamental research problem of feature interaction selection.\nDash and Liu [7] proposed a general feature selection framework that consists of four steps, that is: 1) generation strategy; 2) evaluation criteria; 3) stopping condition; 4) result validation. Based on the framework, researchers developed various feature selection methods which usually fall into three categories: 1) filter; 2) wrapper; 3) embedded. The disadvantages of filters and wrappers lie in poor robustness, besides wrappers are inefficient and unsuitable for large-scale datasets or high-dimensional data. In contrast, embedded methods have become more popular because of their reduced computational demands and less overfitting problems [8]. Expert-designed operations to model interactions of feature pairs have always dominated extant embedded methods, e.g., factorization machines (FM) [9] embed each feature into low-dimensional vector and model interactions by the inner product. These shallow models have limited representation capabilities, which inspires implicit deep learning models to improve over FM [10]\u2013[12]. However, these approaches present the same pre-designed modeling architecture for different tasks or datasets, which leads to a limitation that their architectures are poorly adaptable to tasks and data. Besides, previous methods simply enumerate all features and interactions by equal relevance, among which useless features and interactions may bring unnecessary noise and complicate the training process.\nTo this end, we argue that how to adaptively model task-friendly interactions and quantitatively select relevant features and interactions has become a less-studied urgent problem. We expect an ideal feature interaction selection approach should satisfy two desirable abilities: (1) It can evolve to find a proper operation to use for modeling each interaction; (2) It should distinguish which features and interactions to what extent are relevant to the task.\nOne way to implement such an evolution of a model is evolutionary learning [13]\u2013[15]. Evolutionary learning refers to a class of evolutionary algorithms that solve complicated search problems in machine learning [16], which is naturally fit for the feature selection framework [17], [18]. Extant evolution-based feature selection methods perform filters and wrappers [13], which are not practical for massive high-dimensional commercial data. In contrast, we propose an evolution-based embedded method. For the concerned feature interaction selection problem, if we regard the relationship between models and tasks as the relationship between organisms and natural environments, interactions of feature pairs can be analogous to double-stranded deoxyribonucleic acid (DNA), of which relevant features and interactions can be analogous to genomes. It is easy to understand that, different traits confer"}, {"title": "2", "content": "different rates of survival and fitness. The same is true for the selection of features and interactions. A key challenge to accomplishing such evolutionary learning is evaluating the fitness of the model. To cope with the challenge, we propose a fitness diagnosis technique that can reveal the learning abilities of models during training. Compared with previous fitness evaluation techniques, which commonly adopt numerical values to represent the fitness of models, fitness diagnosis can deeply diagnose the abilities of inside components of the model. By doing so, an evolution path can be planned and visualized, thereby enhancing the interpretability of how the model selects operations, features, and interactions that suit the task better.\nAlong this line, this paper presents a Cognitive EvoLutionary Learning (CELL) framework for feature interaction selection, where cognitive ability refers to a property of organisms that allows them to react and survive in diverse environments. The CELL framework consists of three stages of learning, i.e., DNA search, genome search, and model functioning. We summarize the three stages in the following:\n1) Stage I: DNA search. We regard the relationship between features and operations as the relationship between nucleotides and linkages. To explore the fittest operation that generates a task-friendly interaction of each feature pair, we extend the operation set with several types of operations as the search space, which is like linkage rules to bind nucleotides. We diagnose the fitness of the model on operations to simulate the survival rates of organisms for natural selection. To tackle the evaluation-consuming challenge of discrete selection, we relax the search space to be continuous so that operation fitness can be optimized by gradient descent. For each feature pair, we retain the fittest operation to model the interaction.\n2) Stage II: genome search. Since the genome is a small fraction of DNA that contains genetic information and can influence the phenotype of an organism, the genome search discards or weakens some features and interactions contributing little, to prevent extra noise. To discriminate the relevance of features and interactions, we diagnose the fitness of the model on features and interactions. The search space is the relevance fitness parameters represented by real values, indicating the contributions of features and interactions to the task. Mutation, as the source of genetic variations, occurs when the relevance fitness of an interaction drops to a threshold, resulting in the operation of the interaction mutating into other operations. The mutation mechanism can avoid the search results based on DNA search reaching a suboptimum and benefit genetic diversity.\n3) Stage III: model functioning. The model functioning stage utilizes selected relevant features and interactions to capture non-linear interactions further, which is like decoding genes. In this stage, we concatenate retained features and interactions as vectors and then feed them into multilayer perceptrons (MLP), while keeping the relevance fitness as attention units."}, {"title": "3", "content": "We perform extensive experiments on four datasets. Three of them are publicly available advertising datasets for CTR prediction, and the last one is a financial dataset collected from a high-tech bank for identifying clients. To enhance the interpretability of how CELL adaptively selects operations, features, and interactions under task guidance, we visualize the evolution paths of DNA search and genome search. Furthermore, we also conduct synthetic experiments to ascertain that CELL can consistently diagnose to discover the relevant interactions and the pre-defined interaction patterns.\nTo summarize, we make the following contributions:\n1) We propose a nature-inspired feature interaction selection approach named CELL. It can adaptively evolve into different models for different tasks and data, so as to build the architecture under task guidance.\n2) We propose a fitness diagnosis technique that can quantitatively analyze and reveal the learning abilities of models during training. It deeply diagnoses the abilities of inside components of models and interprets the mechanism of interaction modeling and selection.\n3) We use three publicly available advertising datasets and a new dataset collected from a high-tech bank to perform experiments. The experimental results show that CELL outperforms the state-of-the-art feature interaction selection models on these tasks.\nOverview. The remainder of this article is organized as follows. In Section II, we will review some related work of our study. Section III will introduce the notations, problem definition, and basic operations for generating interactions of feature pairs. Then, the framework of our proposed CELL and the three stages of learning processes will be detailed in Section IV. Afterward, Section V will comprehensively evaluate CELL on real-world datasets and synthetic datasets. Finally, conclusions will be drawn in Section VI."}, {"title": "II. RELATED WORK", "content": "The related work of our study can be grouped into three categories, namely feature interaction selection, evolutionary learning, and diagnosis techniques. In this section, we summarize the related work as follows."}, {"title": "A. Feature Interaction Selection", "content": "Since research has shown that interaction of feature pairs can provide predictive abilities beyond what those features can provide individually [6], [13], feature interaction selection based on embedded methods attracts much participation from commercial recommendations, e.g., advertising, client identifying [5], [19]\u2013[22]. In the earlier time, scholars try to design operations to model interactions in an explicit learning way. For example, factorization machines (FM) [9] project each feature into low-dimensional vector and model interactions by the inner product. Field-aware FM (FFM) [23] enables each feature to have multiple latent vectors to interact with features from different fields. However, these models have limited representation capabilities, which inspires implicit deep learning models to improve over FM. For example, Attention FM (AFM) [11] and Neural FM (NFM) [10] stack deep"}, {"title": "3", "content": "neural networks on top of the output of the FM to model higher-order interactions. FNN uses FM to pre-train low-order interactions and then feeds embeddings into an MLP [24]. IPNN (also known as PNN) also uses the interaction results of the FM layer but does not rely on pre-training [25], [26]. Obviously, these models lack good interpretability. Lian et al. argue that implicit deep learning models focus more on high-order cross features but capture little low-order cross features [27]. Therefore, recent advances propose a hybrid network structure, namely Wide&Deep, which combines a shallow component and a deep component with the purpose of learning both memorization and generalization [12], [28], [29]. Wide&Deep framework attracts industry partners from the beginning. As for the first Wide&Deep model proposed by Google, it combines a linear model and an MLP [28]. Later on, DeepFM uses an FM layer to replace the shallow part [12]. Similarly, Deep&Cross [29] and xDeepFM [27] take the outer product of features at the bit- and vector-wise level respectively. Though achieving some success, most of them follow a manner, which uses the pre-designed modeling architecture and equally enumerates all features and interactions, which suffer from two main problems. First, they cannot ensure the learning abilities of models because their architectures are poorly adaptable to tasks and data. Second, useless features and interactions can bring unnecessary noise and complicate the training process."}, {"title": "B. Evolutionary Learning", "content": "Evolutionary learning refers to a class of nature-inspired heuristic algorithms that solve complicated search problems in machine learning [14], [30], [31], which commonly be used in all three parts: preprocessing (e.g., feature selection and resampling), learning (e.g., parameter setting, membership functions, and neural network topology), and postprocessing (e.g., rule optimization, decision tree/support vectors pruning, and ensemble learning) [17], [32]\u2013[34]. Evolutionary learning also refers to evolutionary AutoML concepts, in which different components of models are automatically determined using evolutionary algorithms, such as architecture and hyperparameters [16]. Concepts of evolutionary learning are naturally fit for the feature selection framework [13], [16]\u2013[18]. Previous evolution-based feature selection methods commonly perform filters and wrappers [13], which are not practical for massive high-dimensional commercial data. Recent approaches have employed AutoML to search neural architectures for CTR prediction [35]\u2013[37]. However, they are almost all built on existing work as blocks with complex functionality, such as MLP and FM, where each block is an architecture-level algorithm [35], [36]. In general, for population-based NAS approaches, large population size and massive generations are usually required to address the huge search space issue, e.g., AutoCTR sets population size as 100, and every individual search runs on a single GPU for days [36]. In contrast to searching coarse-grained upper-level architectures, our work searches fine-grained basic-level operations. To the best of our knowledge, CELL is the first work that utilizes the meta-heuristic mutation mechanism for interaction search."}, {"title": "4", "content": "In educational psychology, cognitive diagnosis techniques have been developed to access examinees' skill proficiency and can be roughly divided into two categories: continuous and discrete [38], [39]. These works follow the Monotonicity Theorem that assumes that examinees' proficiency increases monotonously with probabilities of giving the right responses to test items [40]. Furthermore, recent works leverage diagnosis techniques to reveal the proficiency of trial lawyers in legal fields [41]. Also, research shows that one can predict the outcome of e-sports matches through the diagnosis of players [42]. However, previous diagnosis techniques are mostly oriented toward human beings. Our work inherits the idea of both continuous and discrete diagnosis techniques but changes whom to diagnose from examinees to learning models. Noticeable improvement in machine learning benefits from the inspiration of the way of human learning, whereas fitness evaluation of machine learning models comes to a standstill. In contrast, our work provides a fitness diagnosis targeting machine learning models to understand their learning status during training. We diagnose the fitness of the model to simulate the survival rates of organisms for natural selection, thereby an evolution path can be planned and visualized. It interprets the mechanism of interaction modeling and selection."}, {"title": "III. PRELIMINARIES", "content": "In this section, we state the formal problem definition of feature interaction selection and introduce some basic operations for generating interactions of feature pairs."}, {"title": "A. Problem Statement", "content": "We define a general form of feature interaction selection problem. If the dataset consists of $n$ instances $(f, y)$, where $f = [f_1,...,f_m]$ indicates instance features including $m$ fields, and $y \\in \\{1, 0\\}$ indicates an observed user behavior, the feature interaction selection problem can be defined as how to precisely give the predictive result through the learned model $\\hat{y}$: $M(f,g(f)) \\rightarrow [0, 1]$, where $g$ denotes the set of operations between feature pairs, and $g(f)$ denotes the set of interactions. Usually, the prediction model $M$ suffers a Logloss (cross-entropy loss) function [43], given as:\n$L(M) = \\frac{1}{B} \\sum_{t \\in B} y_t log(\\hat{y}_t) + (1 - y_t) log(1 - \\hat{y}_t),$ (1)\nwhere $B$ denotes the set of instance indices in a mini-batch, $\\hat{y}$ denotes the predictive result given through the learned model."}, {"title": "B. Operations", "content": "As the fundamental components in feature interaction selection, operations are regarded as functions where two individual features are converted into an interaction. For the sake of simplicity, we adopt four representative operations, i.e., $g = \\{\\oplus, \\otimes, \\concat, \\boxplus\\}$, to present an instantiation of CELL, which are highly used in previous work [35]\u2013[37]. As shown in the operation set part of Fig. 1, the following operations are available for selection:"}, {"title": "5", "content": "Let a set of continuous variables $\\Theta = \\{\\theta^{(i,j)} | 1 < i < j < m\\}$ parameterize the fitness of the model on operations. Our diagnosis goal is to learn $\\theta^{(i,j)}_{g_k} \\in \\{\\theta_{g_k}^{(i,j)} | g_k \\in g\\}$ for each feature pair $(f_i, f_j)$ of an instance.\nFor an organism, its fitness increase monotonously with probabilities of the DNA decoding vital traits. Analogously, we assume that the fitness of the model increase monotonously with probabilities of interacting feature pairs by suitable operations. Motivated by this, we put forward that $\\Theta^{(i,j)}$ satisfies the following property:\nProposition IV.1. $g_k, g_k' \\in g$, $\\Theta^{(i,j)}$ satisfies $\\theta_{g_k}^{(i,j)} > \\theta_{g_k'}^{(i,j)}$ when $L(M(g_k(f_i, f_j))) < L(M(g_k'(f_i, f_j)))$.\nFor the sake of simplicity, we use $M(g_k(f_i, f_j))$ to denote the learning model that selects the operation $g_k$ to interact the feature pair $(f_i, f_j)$. $L(M)$ is the suffered Logloss function as we mentioned before. The above proposition provides us with a way to optimize the relative value of the model fitness on operations. There are obvious advantages to implementing DNA search with continuous fitness rather than categorical choices. If we search over discrete sets of interactions modeled by candidate operations, it will require much more evaluation. Contrastively, we relax the categorical choices to be continuous so that the set of operations can be optimized with respect to its performance on the validation set by gradient descent. As opposed to inefficient black-box search, the data efficiency of gradient-based optimization allows DNA search to use much fewer computational resources.\nInspired by DARTS algorithm [44], for each feature pair, we adopt a mixed interaction $\\bar{g}(f_i, f_j)$ given by a softmax over all possible operations as:\n$\\bar{g}(f_i, f_j) = \\sum_{g_k \\in g} g_k \\frac{exp(\\theta_{g_k}^{(i,j)})}{\\sum_{g_{k'} \\in g} exp(\\theta_{g_{k'}}^{(i,j)})}$ (2)\nwhere the coefficient of candidate operations is called mixed linkage. We define the linkage response as the weighted sum of all feature pairs interacted by mixed linkages:\n$\\hat{y} = M(w, \\bar{g}(f)) = Sigmoid (\\sum_{1 \\leq i < j \\leq m} w_{i,j} \\cdot \\bar{g}(f_i, f_j))$ (3)\nwhere $w_{i,j}$ is the weight parameter of $\\bar{g}(f_i, f_j)$. If we consider an interaction given by the mixed linkage between a feature pair as a DARTS process, the linkage response of all feature pairs is given by multiple DARTS processes (practically hundreds and thousands of them) that run in parallel.\nAccording to Proposition IV.1, DNA search can optimize $\\Theta$ via the difference between the linkage responses and true labels. We adopt to jointly optimize $\\Theta$ and $w, f$ as a bilevel optimization problem. Hence, our goal is to find $\\Theta^*$ that minimize the validation loss $L_{val}(w^*, f^*, \\Theta^*)$, where $w^*, f^*$ associated with the operations $\\Theta$ are obtained by minimizing the training loss $w^*, f^* = \\arg \\min_{w, f} L_{train}(w, f, \\Theta^*)$. This implies that $\\Theta$ is the upper-level variable and $w, f$ are the lower-level variables:\n$\\min_{\\Theta} L_{val}(w^*(\\Theta), f^*, \\Theta),$ s.t. $w^*(\\Theta), f^* = \\arg \\min_{w, f} L_{train}(w, f, \\Theta).$ (4)\nTo reduce the expensive inner optimization in Eq. (4), we can use a simple approximation that assumes the current $w, f$ are the same as $w^*, f^*$. Related techniques have been used in DARTS [44], meta-learning for model transfer [45], gradient-based hyperparameter tuning [46] and unrolled generative adversarial networks [47].\nThrough the approximation, we can replace $w^*(\\Theta), f^*$ by adapting $w, f$ using only a single training step, without solving the inner optimization completely by training until convergence, given as:\n$\\nabla_{\\Theta} L_{val} (w^*(\\Theta), f^*,\\Theta) \\approx \\nabla_{\\Theta} L_{val} (w - \\xi \\nabla_{w} L_{train}(w, f,\\Theta), f - \\xi \\nabla_{f} L_{train} (w, f,\\Theta), \\Theta),$ (5)\nwhere $\\xi$ is the learning rate. Eq. (5) requires only a forward pass for $w, f$ and a backward pass for $\\Theta$, which is much more efficient. At the end of DNA search, we replace $\\bar{g}(f_i, f_j)$ with the interaction modeled by the fittest operation and obtain a discrete choice of operation, i.e., $g = \\arg \\max_{g_k \\in g} \\theta_{g_k}^{(i,j)}$.\nThe overall time complexity of DNA search is practicable owing to the real-parameter model fitness mechanism and the approximation method. Compared to searching over discrete sets of candidate operations, the complexity is reduced from $O(|w| + 4m^2 |f| |\\Theta|)$ to $O(|w| + 4m^2 |f| + |\\Theta|)$, where $|w| = m \\cdot (m - 1)/2$, $|f| = m \\cdot |f|$, and $|\\Theta| = 2m \\cdot (m - 1)$. Note that Eq. (5) will reduce to $\\nabla_{\\Theta} L_{val}(w, f,\\Theta)$ if $w, f$ are already local optima, because $\\nabla_{w} L_{train}(w, f, \\Theta) = 0$ and $\\nabla_{f} L_{train}(w, f, \\Theta) = 0$."}, {"title": "B. Genome Search", "content": "DNA search provides us a way to select appropriate operations from the operation set to model interactions of feature pairs. Regarding the model as an organism, in DNA search, the nucleotides evolve to be bound by linkages so that nucleotide chains become a double helix structure. Since the genome is a small fraction of DNA that contains genetic information and can influence the phenotype of an organism, our next goal is to find genome regions in DNA.\nFor an organism, if the regions in DNA decodes a phenotype that benefits survival, it will have better fitness; if the phenotype decoded by the regions does not benefit survival, it will have worse fitness. The evolutionary strategy should allow the former (i.e., the genome) to retain phenotype genetic information, which inspires us to formulate the importance of features and interactions with the relevance fitness parameters. Therefore, our intuitive goal here is to discriminate the relevance of features and interactions, so as to enhance the relevant features and interactions, meanwhile, discard or weaken some features and interactions contributing little.\nLet $\\alpha = \\{\\alpha_i | 1 \\leq i \\leq m\\}$ and $\\beta = \\{\\beta_{i,j} | 1 < i < j \\leq m\\}$ denote the relevance fitness parameters of features $f$ and interactions $g(f)$. Our diagnosis goal is to learn $\\alpha_i$ for each feature $f_i$ and $\\beta_{i,j}$ for each interaction $g(f_i, f_j)$ of an instance. We put forward that $\\alpha, \\beta$ satisfy the following property:\nProposition IV.2. Let $\\alpha, \\beta = \\arg \\min_{\\alpha, \\beta} L(M)$. $\\alpha$ satisfies $\\alpha_i > |\\alpha_j|$ when $L(M(f_i, w/o(f_j))) < L(M(w/o(f_i), f_j))$, and $\\beta$ satisfies $\\beta_{k,l} > |\\beta_{i,j}|$ when $L(M(g(f_i, f_j), w/o(g(f_k, f_l)))) < L(M(w/o(g(f_i, f_j)), g(f_k, f_l)))$."}, {"title": "6", "content": "For the sake of simplicity, in the above proposition, we use $L(M(f_i, w/o(f_j)))$ to denote a comparative form of the learning model that selects feature $f_i$ and discards feature $f_j$. Analogously, $L(M(g(f_i, f_j), w/o(g(f_k, f_l))))$ denotes the learning model that selects interaction $g(f_i, f_j)$ and discards feature $g(f_k, f_l)$. Indeed, the core idea of fitness diagnosis in genome search can be viewed as a comparative survival scheme, which enhances the relevant features and interactions but discards or weakens others through the difference between the genome responses and true labels.\nAlong this line, the genome response of the current learning model can be given as follows: $\\hat{y} = M(\\alpha \\cdot f, \\beta \\cdot g(f)) = Sigmoid (\\sum_{i=1}^{m} \\alpha_i f_i + \\sum_{1 < i < j < m} \\beta_{i,j} g(f_i, f_j))$, where the $\\alpha_i$ is the relevance fitness parameter of feature $f_i$, and $\\beta_{i,j}$ is the relevance fitness parameter of interaction $g(f_i, f_j)$. We propose to optimize $\\alpha, \\beta$ simultaneously with feature embeddings. Specifically, feature embeddings are learned by Adam optimizer [48], while $\\alpha, \\beta$ are learned by regularized dual averaging (RDA) optimizer [49], [50]. RDA optimizer is an online optimization method aiming at getting sparse solutions. The reason why we can guarantee sparse solutions of $\\alpha, \\beta$ is because of the truncation mechanism of the RDA optimizer. When the absolute value of the cumulative gradient average value in a certain dimension is less than a threshold, the weight of that dimension will be set to 0, resulting in the sparsity of the relevance fitness parameters [49], [51]. We update $\\alpha, \\beta$ at each gradient step $t$ with data $B_t$ as:\n$\\alpha_{t+1}, \\beta_{t+1} = S_h(\\gamma) ((\\alpha_0, \\beta_0) - \\gamma \\sum_{i=0}^{t} \\nabla_{\\alpha, \\beta} L_{train}(f_i)) (6)$\nwhere $S_h : v \\rightarrow sign(v) \\cdot max \\{|v| - h, 0\\}$ is the soft-thresholding operator, $\\alpha_0, \\beta_0$ are initializers chosen at random, $\\gamma$ is the learning rate, $h(t, \\gamma) = c \\gamma^{1/2} (t \\gamma)^{\\mu}$ is the tuning function, $c$ and $\\mu$ are adjustable hyper-parameters as a trade-off between accuracy and sparsity. To avoid the expensive inner optimization of the gradient of $\\alpha, \\beta$ and feature embeddings, the parameters are updated together using one-level optimization with gradient descent on the training set by descending on $\\alpha, \\beta$ and $f$ based on:\n$\\nabla_f L_{train} (f_{t-1}, \\alpha_{t-1}, \\beta_{t-1})$ and $\\nabla_{\\alpha,\\beta} L_{train} (f_{t-1}, \\alpha_{t-1}, \\beta_{t-1})$. (8)\nIn this setting, $\\alpha, \\beta$ and $f$ can explore their search space freely until convergence. The complexity is $O(m \\cdot |f| + |\\alpha| + |\\beta|)$, where $|f| = m \\cdot |f|$, $|\\alpha| = m$, and $|\\beta| = m \\cdot (m - 1)/2$.\nTo further explore interactions modeled by operations between features, we propose a mutation mechanism, inspired by the source of genetic variations. Mutation probabilistically occurs when the relevance fitness drops to a threshold, resulting in the operation of the interaction mutating into other operations. In general, the mutation mechanism can avoid the search result based on DNA search reaching a suboptimum and benefit the genetic diversity."}, {"title": "Algorithm 1 Cognitive Evolutionary Learning", "content": "Input: Training dataset of $n$ instances $(f, y)$, operation set $g$.\n1: Randomly initialize fitness parameters $\\Theta, \\alpha, \\beta$.\n2: procedure DNA SEARCH($\\Theta$)\n3: while not converged do\n4: Update model fitness $\\Theta$ by descending $\\nabla_{\\Theta} L_{val} (w - $\\xi $\\nabla_{w} L_{train}(w, f, $\\Theta$), f - $\\xi $\\nabla_{f} L_{train} (w, f,$\\Theta$),$\\Theta$)\n5: Update weights $w$ and feature embeddings $f$ by descending $\\nabla_w L_{train}(w, f,\\Theta)$, $\\nabla_f L_{train} (w, f,\\Theta$)\n6: end while\n7: return the selected operations $g = arg $\\max_{g_k \\in g} \\theta_{g_k}^{(i,j)}$\n8: end procedure\n9: procedure GENOME SEARCH($\\alpha, \\beta$)\n10: while not converged do\n11: Update the relevance fitness $\\alpha,$\\beta by descending $\\nabla_{\\alpha,\\beta} L_{train} (f_{t-1}, \\alpha_{t-1}, \\beta_{t-1})$ \u25b7 Use RDA optimizer\n12: Update feature embeddings $f$ by descending $\\nabla_f L_{train} (f_{t-1}, \\alpha_{t-1}, \\beta_{t-1})$\n13: if $\\beta_{i,j} < \\lambda$ for every $\\tau$ steps then\n14: $g_k$ of $g_k(f_i, f_j)$ probabilistically mutates\n15: end if\n16: end while\n17: return the relevance fitness parameters $\\alpha, \\beta$\n18: end procedure\n19: procedure MODEL FUNCTIONING($\\alpha, \\beta$)\n20: while not converged do\n21: Update weights $w$ of the MLP and $f$ by descending $\\nabla_w L_{train}(w, f)$, $\\nabla_f L_{train}(w, f)$\n22: end while\n23: return the final predictive model\n24: end procedure\nWhen $\\beta_{i,j}$ drops to a threshold $\\lambda$ for every $\\tau$ steps, the mutation is applied with probability $1/6$, which means that, to regenerate a new interaction, the operation $g_k$ of the interaction $g_k(f_i, f_j)$ mutates into another operation $g_l$, given as:\n$g_k = \\begin{cases} g_l & \\text{with probability } 1/6, \\text{ if } \\beta_{i,j} < \\lambda,\\\\ g_k, & \\text{otherwise.} \\end{cases}$ (9)\nwhere $g_l$ is randomly selected from the operation set as $g_l = \\{g | g \\in g, g \\neq g_k\\}$. After the mutation, the new interaction $g_l(f_i, f_j)$ replaces the old irrelevant interaction $g_k(f_i, f_j)$ and participates in next $\\tau$ steps of genome search.\nIn certain sense, genome search makes a good balance between exploitation and exploration of interactions, because it enhances relevant features and interactions, meanwhile it remodels irrelevant interactions by mutating their operations."}, {"title": "C. Model Functioning", "content": "Through repeated replication and transcription, the genetic information of DNA translates to make matching protein sequences. In this way, various possible functions could be proposed for an organism. To simulate this natural process, we retrain the model. Relevant features and interactions are"}, {"title": "7", "content": "selected according to their relevance fitness parameters $\\alpha", "MLP": "n$\\hat{y} =Sigmoid(MLP([\\alpha_1\\cdot f_1, ..., \\alpha_m \\cdot f_m, \\beta_{1,2} \\cdot g(f_1, f_2), ..., \\beta_{m-1,m} \\cdot g(f_{m-1}, f_m)", "48": ".", "52": "."}]}