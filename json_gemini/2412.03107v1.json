{"title": "CredID: Credible Multi-Bit Watermark for Large Language Models Identification", "authors": ["Haoyu Jiang", "Xuhong Wang", "Ping Yi", "Shanzhe Lei", "Yilun Lin"], "abstract": "Large Language Models (LLMs) are widely used in complex natural language processing tasks but raise privacy and security concerns due to the lack of identity recognition. This paper proposes a multi-party credible watermarking framework (CredID) involving a trusted third party (TTP) and multiple LLM vendors to address these issues. In the watermark embedding stage, vendors request a seed from the TTP to generate watermarked text without sending the user's prompt. In the extraction stage, the TTP coordinates each vendor to extract and verify the watermark from the text. This provides a credible watermarking scheme while preserving vendor privacy. Furthermore, current watermarking algorithms struggle with text quality, information capacity, and robustness, making it challenging to meet the diverse identification needs of LLMs. Thus, we propose a novel multi-bit watermarking algorithm and an open-source toolkit to facilitate research. Experiments show our CredID enhances watermark credibility and efficiency without compromising text quality. Additionally, we successfully utilized this framework to achieve highly accurate identification among multiple LLM vendors.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) have been extensively applied to complex natural language processing tasks, such as chatbots and programming assistants. However, their powerful generative capabilities pose significant challenges related to security, compliance, and user privacy protection. These challenges primarily stem from the absence of established systems for identity recognition and behavior tracing in AI applications (Wang et al. 2024b).\nWatermarking (Cox et al. 2002) embeds secret information without compromising original data quality, which can be regarded as a key technique to address those concerns. With the rise of LLM technology, embedding watermarks in LLM-generated texts has become an indispensable area of research. Watermarking verifies the origin of text from specific LLMs, thereby enhancing copyright protection, intellectual property preservation, and content authenticity. Furthermore, watermarking aids in tracing content dissemination, preventing misinformation, and ensuring transparency and traceability in compliance with legal and regulatory standards.\nTo address the above limitations, we propose a multi-party credible watermarking framework (CredID), a collaborative architecture involving a Trusted Third Party (TTP) and LLM vendors, as illustrated in Fig. 1. This framework is divided into two stages: embedding and extraction. During the embedding stage, the LLM vendor sends a watermark request to the TTP when a user accesses the LLM. This request includes the LLM name, version, timestamp, and other relevant information, but excludes the user prompt for information protection. The TTP assigns a secret message as an identity identifier for each vendor, then uses a key-encrypted hash algorithm to generate a watermark seed from the entire message and only returns the seed to the vendor. The vendor then uses this seed on its private watermarking process, to generate watermarked LLM response and returns it to the user. During the extraction stage, to extract the watermark message from the target text, the TTP sends the target text and the table of watermark seeds to the vendors, which assess the confidence levels of various seeds and report back to the TTP. The TTP determines the most matching watermark seed based on confidence levels and multi-party voting results, thereby inferring the identity of the target text.\nThe key innovations and advantages of CredID are as follows: (1) Multi-party Participation: This framework is the first to involve multiple parties collaboratively in watermarking. By incorporating multi-party validation, we enhance the robustness of watermark verification and introduce public verification features, thereby reducing the risks of forgery and tampering in watermarking process. (2) Privacy Protection: The interaction between the TTP and LLM vendors is limited to watermark seeds, without disclosing user prompts or model logit outputs to the TTP or other LLM vendors. (3) Flexibility: Our CredID offers high scalability, easily accommodating the private watermarking technologies of different vendors as long as they indeed utilize the randomness of the watermark seeds. It also allows for the flexible upgrading of relevant authentication encryption algorithms and watermarking hash algorithms during the watermark request and seed exchange stages, addressing evolving security threats and technological advancements.\nHowever, the implementation of this framework faces two significant challenges. Firstly, existing watermarking methods do not meet the requirements of practicality and robustness. Mainstream one-bit methods perform well in terms of success rate and robustness but cannot satisfy the diverse information embedding for identity recognition. The few existing multi-bit methods exhibit poor performance in text quality and robustness, especially when subjected to attacks. Secondly, watermarking tools are underdeveloped. Although there are open-source watermarking tools for one-bit methods (Pan et al. 2024), the more critical open-source multi-bit watermarking tools remain disorganized, making it difficult for researchers to reproduce previous work.\nTherefore, to advance LLM identity recognition centered on multi-bit watermarking, this paper contributes in three areas:\n\u2022 Framework: We propose a multi-party credible watermarking framework (CredID) involving a Trusted Third Party (TTP) and LLM vendors. This framework ensures the credibility of the watermark without compromising the privacy of LLM vendors and users. Experimental results demonstrate that our CredID enhances the accuracy and robustness of watermarking techniques.\n\u2022 Algorithm: We have adapted a multi-bit watermarking method to fit the CredID. By introducing a watermark temperature parameter, the method enhances the distinction between the target watermark message and other messages, thereby improving watermark success rates. By encoding messages holistically, we significantly increase the information capacity of the watermark. To improve performance in low-entropy texts, we bypass low-entropy words and use original logits for watermark vocabulary division, thus improving the quality of generated texts. Experimental results demonstrate that our method outperforms existing schemes in success rate, robustness, text quality, and credibility.\n\u2022 Tool: We provide researchers with a user-friendly, open-source multi-bit watermarking toolkit, which includes traditional watermarking frameworks, pipelines for multi-party watermarking frameworks, automated experiment configurations, several watermark datasets, and multiple baseline algorithms. We believe that this toolkit will facilitate broader participation from researchers and the public in advancing LLM watermarking technology."}, {"title": "Related Work", "content": "To apply watermarking for LLMs identification, it is essential to integrate watermarking at the model level rather than the text level (Liu et al. 2024b). Model-level watermarking schemes primarily involve adding watermarks during training (Tang et al. 2023), during token sampling (Hou et al. 2023), or through logit modification (Kirchenbauer et al. 2023b; Zhao et al. 2023). Since participation in the training process affects LLM performance and interference with token sampling limits the randomness of text generation, logit-based methods with better performance have gradually become mainstream (Liu et al. 2024a).\nCurrent logit-based methods add biases to the logit vectors of certain token sets, causing the predicted tokens to exhibit a preference, thereby embedding the watermark. However, most methods (Kirchenbauer et al. 2023a; Zhao et al. 2023; Lee et al. 2024; Munyer et al. 2024) can only embed one-bit information in the text to determine the presence of a watermark, which cannot encode more complex identification information for practical LLM identification.\nOnly a few studies have explored multi-bit watermarking. For instance, (Wang et al. 2024a) balances the probabilities of vocabulary using a proxy language model to embed multi-bit watermarks, but its performance is limited by the proxy model's capabilities and tokenizer compatibility, theoretically making it inapplicable to all LLMs. Methods such as (Fernandez et al. 2023; Yoo, Ahn, and Kwak 2024) randomly divide a fixed proportion of vocabulary to add biases, which may increase the probability of rare high-entropy words, posing a significant threat to the quality of generated texts. Additionally, (Yoo, Ahn, and Kwak 2024) that independently encode each bit of the message are vulnerable to minor text perturbations, making the recovery of the complete message a significant challenge.\nOur proposed CredID addresses text quality issues and significantly enhances the information capacity of the watermark. This approach meets the need for injecting diverse and customized information for LLM identification scenarios, thereby adapting to the proposed credible framework."}, {"title": "Preliminaries", "content": "First, we introduce the necessary notation used in this paper. Consider an LLM that processes a prompt sequence x as input and generates a natural sentence by sequentially outputting corresponding tokens. At the k-th step (k = 1,2,..., K), the input to the LLM consists of the original prompt x and the sequence $s_{:(k-1)} = {v_0,..., v_{k-1}}$, where v \u2208 V and V is the entire vocabulary, predicted by the LLM in the previous k - 1 steps. The LLM then generates a logit vector $l_{[(k-1)} \u2208 R^{|V|}$ over V (where |V| is the number of tokens in the vocabulary), which is transformed into a probability distribution $P_{LLM}(x, S_{:(k-1)}) = (\u2026, P_{LLM}(v|x, S_{:(k-1)}),\u2026)$ via the softmax function. Here, $P_{LLM}(v|x, S_{:(k\u22121)})$ represents the LLM's predicted probability for token v \u2208 V. The next token is sampled based on $P_{LLM} (x, S_{:(k-1)})$.\nThis paper employs a watermarking paradigm that adds watermark logits to the pure logits of the next token generated by the LLM. Based on the watermark message m, the vocabulary V is divided into a watermark token set $V_o$ and a remaining token set $V_r$. By modifying the logits, the prediction is biased towards selecting tokens from $V_o$, achieving the purpose of watermark embedding. Before detailing the process, we formally define the logit modification-based LLM multi-bit watermarking. The multi-bit watermarking algorithm involves embedding and extraction stages:\nEmb: $P \\times M \\rightarrow S, s_w = Emb(LLM, x, m)$, Ext: $S \\rightarrow M, Ext(s_w) = m$,\nwhere P, S, and M represent the prompt space, generated text space, and watermark message space, respectively. m \u2208 M is the message to be embedded, where |M| = n. n is the number of all possible messages for a fixed information bit length, whereas the one-bit watermarking method can be viewed as having a message space of {0, 1}.\nWe need to design a specific watermark logits $\u00ee_{[(k-1)}$ when sampling $v_k$, such that the final logits are: $l_{[(k-1)}^{final} = l_{[(k-1)} + \u00ee_{[(k-1)}$. Applying the softmax operation to the final logits yields the probability distribution of the vocabulary:\n$P_{LLM} (v|x, m, S_{:(k-1)}) = \\frac{exp(l_{[(k-1)}+\u00ee_{[(k-1)})}{\\Sigma_{i\u2208V_b} exp(l_i^{k\u22121)})+\\Sigma_{i\u2208V_o} exp(l_i^{k\u22121)}+\u00ee_i^{k-1})}, n\u2208 V_b,$ $\\frac{exp(l_{[(k-1)})}{\\Sigma_{i\u2208V_b} exp(l_i^{k\u22121)})+\\Sigma_{i\u2208V_o} exp(l_i^{k\u22121)}+\u00ee_i^{k-1})}, \u03b7 \u03b5V_o$.\nConsidering the probability function perspective, Eq. 2 can be rewritten as:\n$P_{LLM} (v|x, m, S_{:(k\u22121)}) = P_{LLM}(v|x, S_{:(k\u22121)}) + \u03b4P_\u03c9 (v|m, S_{:(k\u22121)})$.\n$P_{LLM} (v|x, S_{:(k\u22121)})$ represents the probability of the LLM generating token v given the prompt and previously generated text. $P_w(v|m, S_{:(k\u22121)})$ represents the probability of generating token v during the watermarking phase given the message m and previously generated text.\nThe aim of watermarking method is to design an optimal $P_w$ that not only alters the token selection probabilities during LLM inference but also adheres to the Maximum A Posteriori (MAP) decoding principle. The objective of extracting the watermark message m from the watermark sequence $s_w$ can be formulated as:\n$arg \\underset{m'EM}{max} P_w (m'|s_w)$,\nwhere the watermark probability function $P_w$ is used to measure the likelihood that the watermark message is m' given the watermark sequence $s_w$. An optimal watermark probability function should maximize the probability of generating the message m while significantly differentiating this probability from those of other incorrect messages m'. By reinterpreting the objective of the watermark extraction phase through the lens of entropy using Bayes' theorem, Eq. 4 can be transformed into:\n$\\underset{S}{max} \\{ \\frac{Pw(s|m)}{max_{m'\u2260m} Pw(s|m')} \\}$ $\\rightarrow \\{ \\underset{max}{min_{m'\u2260m}} \\{ \\sum_{k=1}^{K} log Pw (v_k|m, S_{:(k-1)}) - \\sum_{k=1}^{K} log Pw(v_k|m', S_{:(k-1)})\\} \\}$.\nThe above process involves embedding a multi-bit message m into a text sequence s to generate a watermarked text $s_w$, with message extraction based on the MAP principle."}, {"title": "Methodologies", "content": "In this section, we discuss the application scenarios and the main workflow of our scheme.\nConsider a scenario where a model vendor O has trained an LLM f and released it for profit, accepting user requests and returning generated results.\nOur objective is to design a secure and credible watermarking framework to meet the identity recognition requirements of LLMs. Unlike previous LLM watermarking algorithms that typically target a single application entity (either the vendor or the user), our watermarking requires the involvement of an additional TTP during both the embedding and extraction stages to ensure credibility. Our embedding algorithm accommodates diverse information embedding requirements while maintaining usability. The extraction of identity information is a collaborative effort between the TTP and the vendor. Fig. 2 illustrates our CredID with the main workflow as follows:\nTrusted Third Party (TTP). Initially, the TTP assigns a unique secret identity identifier m\u2208 M to each model vendor. Upon receiving a watermark request from O, the TTP processes the vendor's m through a one-way hash function h, producing the watermark parameter $seed_m = h(m)$, which is subsequently returned to the vendor O."}, {"title": "Multi-bit Watermarking Algorithm Design", "content": "We aim to generate the natural text while encoding a specific watermark message m, which means we must balance the semantic quality (e.g. perplexity) of the generated text with the success rate of watermark extraction. First, the watermarked text s should maximize the LLM's generation probability $\\sum_{k=1}^{K} log P_{LLM}(v|x, S_{:(k-1)})$. Second, as described in Eq. 5, the generated text should ensure a high success rate for message extraction. Thus, we combine these two objectives and select the token v that maximizes the objective function at each generation step. The objective function for the logit at each generation phase can be written as:\n$\\underset{v,m'\u2260m}{argmax} \\{ \u03b4 log P_{LLM} (v|x, S_{:(k-1)}) + \\frac{1}{K} \\sum_{k=1}^{K} log P_w (v|m, S_{:(k-1)}) - \\frac{1}{K} \\sum_{k=1}^{K} log P_w (v|m', s_{:(k-1)})\\} $,\nwhere \u03b4, as defined in (Kirchenbauer et al. 2023a), represents the watermark strength. At each token generation stage, it is essential to ensure that high model logits correspond to high watermark logits. This alignment guarantees that the logits, after adding the bias, remain equivalent to the original model logits, thereby preserving the naturalness of the watermarked text generated by the LLM.\nInspired by the work of (Wang et al. 2024a), we simplify the watermark logit by using the mean over the message range $\\frac{1}{|M|}\\sum_{m'\u2208M}log P_w (v|m', s_{:k-1})$ to replace log $P_w (v|m', S_{:(k\u22121)})$. For the message m, we select the token v \u2208 V that maximizes the deviation from the mean, ensuring a high watermark logit. Additionally, we introduce a temperature parameter \u03c4 to control the logit distribution variance across different messages m \u2208 M. Our objective is to achieve the following:\n$arg \\underset{m}{max} \\{ \u03c4 log exp ( l^{k-1} ) - \\frac{1}{|M|} \\sum_{m'\u2260m} l^{k-1} \\} $,\nTypically, \u03c4 is a small value from (0,1], which bias Eq. 7 towards maximizing the difference between $l^{k-1}$ and $l^{k-1}$ for other messages."}, {"title": "Experiments", "content": "Large Language Models. Our experiments were conducted using the open-source models LLaMA-2-7B (Touvron et al. 2023), LLaMA-3-8B (Dubey et al. 2024), Gemma-7B (Team et al. 2024), and Falcon-7B (Almazrouei et al. 2023), with LLaMA-2-7B being the default model due to its popularity. Both beam search and sampling strategies are supported, with beam search being the default decoding algorithm for the LLM and the number of beams set to 4.\nDatasets. We utilize the OpenGen (Krishna et al. 2024), C4 News (Raffel et al. 2020), and Essays (Schuhmann 2024) datasets in experiments. OpenGen consists of 3,000 two-sentence blocks randomly sampled from the WikiText-103 validation set. The C4 dataset contains 15GB of news articles scraped from the internet. The Essays dataset includes student essays from the IvyPanda database. We randomly select fixed-length 200-token prompts from these datasets, using the C4 dataset by default.\nImplementation Details. The default length of the embedded message is 20 bits. The hash scheme is detailed in the Appendix. The default hyperparameters used in our experiments are set to the following: the watermark strength \u03b4 = 1.5, the spike entropy threshold = 1.2, the message temperature \u03c4 = 0.8, and the selected high model logits probability sum threshold \u03c3 = 0.9.\nEvaluation Metrics. We employed the success rate to evaluate the accuracy of fully extracting all bits of the embedded watermark message. Text quality was evaluated using the widely accepted Perplexity (PPL) metric, with the LLaMA-2-13B model serving as the oracle model. Information capacity was quantified by Bits Per Word (BPW), indicating the number of information bits embedded per token."}, {"title": "Main Results", "content": "We investigated the performance of our method on the C4 dataset, comparing it to baselines under different parameter settings by selecting various watermark strengths \u03b4 ranging from 0.5 to 7, and different information capacities. Higher watermark strength results in a higher success rate but reduces text quality. As shown in Fig. 3, our CredID significantly outperforms others in generating high-quality text while maintaining a high success rate in the trade-off between text quality and watermark success rate. Additionally, with increasing information capacity, the success rate of Cyclic-Shift and MPAC drops sharply after reaching their maximum capacity, and the extraction performance of CTWL decreases by more than 20%. Our CredID maintains a 95% success rate and demonstrates excellent performance even when the BPW reaches 0.25. In all cases, our method achieves a superior balance between text quality, watermark success rate, and information capacity.\nTo evaluate the generalizability of our CredID under different settings, we conducted experiments on four models and three datasets while keeping other hyperparameters at their default settings. As shown in Fig. 4, our watermarking maintains relatively consistent performance across various settings, achieving a success rate of nearly 95% when BPW \u2264 0.1, and approximately 90% at BPW = 0.2. Increasing the watermark strength can further improve the success rate. As BPW increases, the number of token carriers allocated per bit of message decreases, leading to a decline in success rate. However, the success rate remains above 70% when embedding 64 watermarking bits with 200 tokens (0.32 BPW) in all three datasets. Further discussion on performance can be found in the Appendix."}, {"title": "Robustness Analysis", "content": "Due to the potential performance degradation of text watermarks under various attack scenarios, we further evaluated the robustness of our CredID against attacks. Fig. 5 compares the success rates of different methods under text editing attacks and text copy-paste scenarios.\nWe conducted three text editing operations at varying proportions: (1) Deletion, which involved randomly deleting tokens; (2) Substitution, where words were replaced using the RoBERTa model (Liu et al. 2019); and (3) Homoglyph, which entailed modifying text by replacing characters with visually similar ones (Gabrilovich and Gontmakher 2002). By exploring the success rate under different destruction ratios, our method demonstrated significantly better performance in resisting attacks with altered lexical distributions compared to baselines.\nFollowing (Kirchenbauer et al. 2023a), which involves blending watermarked text with human-written text to remove watermarks, we selected text segments of a certain length from the C4 dataset and randomly inserted them into 200-token watermarked text. Additionally, we tested 10,000 non-watermarked texts, considering P(m | x) to be less than the threshold $10^{-4}$ as an indication of naturally written human text. During the extraction, we used this threshold and the sliding window technique mentioned in (Wang et al. 2024a) to exclude human-written segments. Under varying text mixing ratios, our method consistently outperformed baseline methods in success rates."}, {"title": "Text Identification Across Multiple LLMs", "content": "To verify whether our CredID can distinguish texts generated by different LLMs and texts written by humans, we established a dataset of 1,000 text samples, each with 200 tokens. Among these, 250 samples are naturally human-written, while the remaining 750 samples are generated by three different LLMs, each producing 250 samples. Different LLMs used distinct hash functions to watermark the texts, embedding a 20-bit binary sequence as the watermark message corresponding to their identities. During detection, watermark message extraction and confidence threshold assessment were performed on the 1,000 texts to match their identities.\nWithout multi-party joint verification, the texts for identification are input into a single LLM to obtain potential watermark messages and extraction confidence. When multi-party joint verification is introduced, each text must be processed through the extraction channels of different LLMs for collective determination. For watermarked texts, we set a confidence threshold of 0.5, where P(m | x) exceeding this threshold ensures the validity of the extracted watermark messages across different model vendors. TTP prioritizes decoding messages based on the highest confidence seed. For texts with incorrectly decoded messages, TTP corrects the results by selecting the vendor with the highest confidence for the seed table."}, {"title": "Conclusion", "content": "In this paper, we introduce the first multi-party credible LLM watermarking framework (CredID), filling the research gap in reliable multi-bit watermarking for LLM identification. We advocate for collaboration between trusted third parties and model vendors to ensure the credibility of watermarking. Our improvements to the multi-bit watermarking enhance information capacity through holistic message encoding and leverage the original model's logits and spike entropy thresholds to maintain high text quality. Extensive experiments demonstrate that our method surpasses existing baselines in watermark extraction success rate, robustness, and text quality, with the collaborative verification framework significantly boosting performance. Additionally, we provide an open-source watermarking toolkit for researchers, achieving practical applicability. We hope our work aids the AI trust community in resolving LLM identification issues and inspires further excellent research in the future."}]}