{"title": "Hybrid deep convolution model for lung cancer detection with transfer learning", "authors": ["Sugandha Saxena", "S. N. Prasad", "Ashwin M Polnaya", "Shweta Agarwala"], "abstract": "Advances in healthcare research have significantly enhanced our understanding of disease mechanisms, diagnostic precision, and therapeutic options. Yet, lung cancer remains one of the leading causes of cancer-related mortality worldwide due to challenges in early and accurate diagnosis. While current lung cancer detection models show promise, there is considerable potential for further improving the accuracy for timely intervention. To address this challenge, we introduce a hybrid deep convolution model leveraging transfer learning, named the Maximum Sensitivity Neural Network (MSNN). MSNN is designed to improve the precision of lung cancer detection by refining sensitivity and specificity. This model has surpassed existing deep learning approaches through experimental validation, achieving an accuracy of 98% and a sensitivity of 97%. By overlaying sensitivity maps onto lung Computed Tomography (CT) scans, it enables the visualization of regions most indicative of malignant or benign classifications. This innovative method demonstrates exceptional performance in distinguishing lung cancer with minimal false positives, thereby enhancing the accuracy of medical diagnoses.", "sections": [{"title": "Introduction", "content": "Accurately detecting diseases remains a significant challenge in the realm of medical research. Among various cancer types, lung cancer is particularly perilous due to its high mortality rate and substantial health impacts [1]-[3]. According to data from India's National Cancer Registry Program, approximately 784,821 individuals die from cancer each year [4]-[5]. Neoplasms, which are characterized by abnormal cell growth, can develop into benign or malignant tumors and nodules in the lungs. Timely detection of lung or pulmonary nodules is essential for improving treatment outcomes and increasing patient survival rate.\nComputed Tomography (CT) scans have become the primary diagnostic technique for detecting lung cancer. These scans offer high resolution, minimal distortion, and enhanced contrast, which allow for detailed examination of the lungs and quicker detection of lung nodules [6]. However, noise in CT scan images can compromise image clarity, posing challenges for radiologists in identifying early-stage lung cancer. \u03a4\u03bf overcome these challenges, deep neural network-based models have been developed, significantly improving the accuracy of cancer detection [7].\nIn recent years, deep learning, a subset of artificial intelligence (AI), has shown tremendous promise in various medical imaging applications. Deep learning has the ability to automatically learn and extract features from large datasets, making it a powerful tool for image analysis and pattern recognition [8],[9]. This technology has revolutionized medical imaging by providing enhanced precision and reliable diagnostic tools, ultimately enhancing early detection and intervention of diseases life threatening diseases like lung cancer [10],[11]. Lakshmanaprabu et al. [12] developed a deep learning model with 94.56% accuracy for categorizing lung CT images as malignant or noncancerous using an Optimal Deep Neural Network (ODNN) and LDA. They used a modified gravitational search algorithm (MGSA) to optimize the ODNN. Lu Y et al. [13] created a CNN model that, when paired with machine learning techniques like Naive Bayes, SVM, and Decision Tree, together with nodule segmentation networks like VGG 16 and Dilated Convolution, achieved 88% accuracy in lung cancer detection. Sannasi Chakravarthy and Rajaguru [14] employed Grey Level Co-occurrence and the Chaotic Crow Search Algorithm (CCSA) by using XGBoost and random forest classifiers along with a preprocessing pipeline containing UNet and ResNet models. Bhatia et al. [15] were able to achieve 84% greater accuracy than they could have with conventional approaches. To segregate lung cancer in X-ray images, Joon et al. [16] employed an active spline model. They also used SVM classification, K-means and fuzzy C-means clustering for feature extraction. Using an ANN model and a dataset of 83 CT images, another study used image processing and machine learning techniques including KNN and RF to classify lung cancer and produced accurate predictions [17].\nLeveraging this technology, we propose a novel deep learning model called MSNN as it is designed specifically for detecting lung cancer from medical images. The model is termed \"hybrid\" because it synergistically combines multiple techniques to enhance its performance in lung cancer detection. It integrates a deep convolutional neural network (CNN) framework, which excels at learning intricate patterns from 512x512 grayscale lung CT scan images. Additionally, it employs transfer learning by leveraging pre-trained networks such as AlexNet, allowing the model to utilize pre-existing knowledge and improve. Furthermore, the extracted deep features are fed into a K-Nearest Neighbor (KNN) classifier for the final classification, effectively combining the strengths of CNNs in feature extraction and KNN in classification. This amalgamation of methodologies ensures superior accuracy and sensitivity, making it a robust tool for lung cancer detection.\nThere are many noteworthy aspects of this model. Firstly, the model uses pre-batch normalization and max pooling layers, strategically employed to reduce model complexity. Secondly, Visualization of sensitivity maps aids in understanding which areas of an image contribute significantly to its classification. Thirdly, the model can identify different shapes of nodules in lung CT scan image. Fourthly, the global average pooling layer (GAP) has been used to overcome the issue of overfitting by reducing the number of parameters. Lastly, the model supports multiple splits of dataset as training and testing for assessing its performance more robustly by training and evaluating on different subsets of the data."}, {"title": "Methodology", "content": "This research utilizes a comprehensive database of lung CT scan images sourced from a private hospital, encompassing a diverse array of cases. The primary objective is to develop a novel convolutional neural network (CNN) framework to accurately identify lung cancer in these scans. The proposed Maximum Sensitivity Neural Network (MSNN) is an advanced architecture meticulously crafted to differentiate between cancerous and noncancerous lung CT images. The innovative MSNN architecture is constructed based on foundational principles from the pre-existing deep neural network, AlexNet [21].\nEach CT scan image serves as an input to the MSNN model, which performs an extensive analysis to classify it as either cancerous or noncancerous. The output is not merely a binary label but also includes a probability score associated with the predicted classification, providing clinicians and researchers with additional insights to enhance the interpretability and utility of the MSNN model in lung cancer diagnosis.\nAlexNet, a renowned deep convolutional neural network (CNN) structure, is known for its efficacy in image classification tasks, including lung cancer detection. However, its extensive depth and significant parameter count make it susceptible to overfitting, especially when dealing with limited datasets. AlexNet's architecture features five convolutional layers, three max-pooling layers, three fully connected layers, and a SoftMax layer for final output classification.\nThe MSNN model has been proposed to address the potential overfitting challenges faced by deep learning models. This model integrates a Global Average Pooling (GAP) layer within its design. The overall flow and architecture of proposed model (figure 1) comprises of five sequential blocks. Blocks 1 to 4 each consist of four layers: convolution (conv), Batch Normalization (BN), Rectified Linear Unit (ReLU), and a max-pooling layer. Block 5 includes a convolutional layer, Batch Normalization, ReLU, a Global Average Pooling (GAP) layer, followed by a fully connected layer and a SoftMax layer. These layers process grayscale images sized at 512x512 pixels, facilitating image classification tasks. The model begins with an input layer that processes 512x512 grayscale CT scan images, followed by a series of convolutional layers (Conv) paired with batch normalization (BN) and rectified linear unit (ReLU) activation layers, which are designed to extract detailed features. Max-pooling layers reduce dimensionality, preserving essential features while minimizing computation. A Global Average Pooling (GAP) layer then condenses spatial information from feature maps into a 1-dimensional vector, enhancing generalization and reducing overfitting risk. The final fully connected (FC) layer and SoftMax (SM) layer classify the image as cancerous or non-cancerous. This architecture effectively integrates convolutional feature extraction with K-Nearest Neighbor (KNN) classification for enhanced accuracy and interpretability in lung cancer detection.\nThe training of the MSNN model involves two main steps: first, distinguishing between malignant and noncancerous lung lesions using CT scan images, and second, extracting features from the deep layers of these images. These features are then input into a K-Nearest Neighbors (KNN) classifier for further classification. Although CNNs are adept at image classification, medical applications often require complex classification where class differences are subtle. Therefore, a supplementary KNN classifier refines the classification process to achieve more precise outcomes. The combination of MSNN and KNN architectures has been meticulously engineered. Initially, preprocessed grayscale CT scan images pass through a series of convolutional, batch normalization, ReLU, and max-pooling layers across blocks 1 to 5. These convolutional layers use various filters to capture a wide range of features, from edges to intricate patterns. After feature extraction by the global average pooling layer, the layer computes average values from the feature maps, resulting in a condensed 1- dimensional vector. This vector is then input to the fully connected layer, where each neuron applies weights to the input values, incorporates bias terms, and calculates a weighted sum. The final sum is directed to the SoftMax layer, which generates class probabilities. Post-feature extraction by the MSNN, the features from the fully connected layer can be seamlessly integrated into the KNN classifier for further analysis.\nThe effectiveness of the KNN classification method depends on the choice of the parameter k. In this research, the optimal k value for the KNN classifier was determined using the elbow method. This technique involves plotting the sum of squared error (SSE) values against different k values and identifying the point on the graph where increasing k no longer significantly affects the SSE. This turning point, known as the \"elbow,\" signifies the optimal k value, which was found to be 3 in this study."}, {"title": "Experimental Results", "content": "The efficacy of MSNN has been demonstrated by several trials and comparisons with other models utilizing datasets of CT images from the lungs."}, {"title": "Dataset and training options:", "content": "The successful classification of test images relies on numerous parameters, making the training of the neural network a pivotal aspect that demands meticulous consideration. The subsequent configuration has been established for the training of MSNN. The ADAM optimization method has been opted for, which iteratively updates the learning coefficients. It independently manages learning rates for each parameter and dynamically adapts these rates during training, thus requiring minimal manual tuning of hyperparameters. The training is conducted with a batch size of 20 and an epoch value of 20 for MSNN. This selection of optimal batch size and epoch value is the outcome of systematic trial and error. The batch size plays a crucial role in balancing the network's convergence rate and accurate estimation [22]. Nevertheless, an excessively large batch size was avoided due to potential time consumption and memory utilization. It's noted that an overly high epoch value may lead to overfitting, while an insufficient epoch value may result in early convergence and termination of training.\nFor this work, lung CT scan images in DICOM format were sourced from A.J Hospital and Research Centre for the assessment of MSNN performance. The dataset encompasses 434 lung CT scan images, comprising 249 images from patients with lung cancer and 185 images from patients with healthy lungs.\nEach image in the dataset is reviewed with the help of a radiologist to manually identify the nodules. The MSNN architecture employs different layers with distinct functions, detailed as follows:\n1. Input layer-The MSNN architecture accepts grayscale CT scan images.\n2. Convolution Layer- In this layer, convolution is performed between the filter size (g) and the input image (f) using equation (1) [23].\n$f(x) * g(x) = \\sum_{x=-\\infty} f (k).g(x \u2013 k)$ (1)\nwhere x and k are spatial variables.\nA smaller filter size may cause an overfitting issue, and a bigger filter size may make underfitting worse. Therefore, this layer makes use of eight filters, each of 6x6 size.\n3. Batch Normalization- The next layer is called the Batch Normalisation (BN) layer, which speeds up training and lessens network sensitivity. For the 'i' unit, normalization is carried out as follows over a batch (v) of m instances using equation (2); each instance corresponds to a single image in the dataset along with its accompanying label.\n$\\mu_{i} = \\Sigma_{r=1}^{m}v_{r}/m$ (2)\nWhere r ranges from 1 to m\nSecondly, compute batch variance [23] by using below equation (3):\n$\\sigma^{2}_{i} = \\Sigma_{r=1}^{m}(v_{r} \u2013 \\mu_{i})^{2}/m$ (3)\nThirdly, compute normalized batch instances [23] by using equation (4):\n$\\nu_{i} = \\nu \u2013 \\mu_{i}/\\sigma_{i}$ (4)\nLastly, scale with learnable parameters yi and \u1e9e\u2081 [23]by using equation (5):\n$\\alpha_{i} = \\gamma_{i} * v + \\beta_{i}$ (5)\n4. ReLU (Rectified Linear Unit) layer-It helps to add nonlinearity to the network by adding a rectifier function which is computing linear operations during convolution [24]. The function works by using equation (6):\nf(x) = 0, x < 0\nf(x) = x, x > 0 (6)\n5. Max pooling layer- Reducing the size of the convolved feature map aids in cutting down on computational expenses.\n6. Global Average pooling (GAP) layer- Applying this layer to the feature maps summarizes the spatial information within each channel by taking the average value across all spatial locations. This operation retains the channel-wise information while discarding the spatial dimensions, resulting in a compressed representation of the feature maps.\n7. Fully Connected (FC) Layer- It helps in classifying the images.\n8. Soft Max (SM)layer- It creates a probability distribution from the last layers output."}, {"title": "Performance Metrics:", "content": "MSNN performance has been evaluated by measuring accuracy[25], precision, sensitivity, specificity, and F-score[26]. True positive (TP), false positive (FP), true negative (TN), and false negative (FN) values were derived from the confusion matrix. Accuracy=$\\frac{TN+TP}{TN+TP+FN+FP}$ (7)\nPrecision=$\\frac{TP}{TP+FP}$ (8)\nRecall=$\\frac{TP}{TP+FN}$ (9)\nF-Score=$\\frac{2*(Precision*Recall)}{Precision+Recall}$ (10)\nSpecificity =$\\frac{TN}{TN+FP}$ (11)"}, {"title": "Discussion", "content": "Table I represents the architecture details of proposed models. Table II compares performance metrics across split1, split2, split3, and split4. It's evident that split 2 exhibits the highest accuracy, precision, recall, specificity, and F-score attributes because the percentage of training data in Split 2 effectively captures the underlying patterns in the dataset. The performance metrics across four data splits (Split1 to Split4) for the Maximum Sensitivity Neural Network (MSNN) reveal interesting insights into the model's efficacy and generalizability. This balance provides the model with enough samples to ensure good generalization without overfitting. Notably, the false positive rate (FPR) is at 0% in split 2, indicating the model's adeptness in distinguishing between positive and negative cases, reducing the misclassification of negatives as positives.\nPerformance comparison of Proposed MSNN with other existing deep learning models has been shown in Table III.\nFrom the results it can be observed that MSNN achieved an accuracy of 98% and sensitivity of 97%. Therefore, it can be concluded that MSNN worked well in the identification of lung cancer because the accuracy reported in [27],[28]is 93%, and 96% respectively. To ensure fair comparison similar datasets are utilized in [27],[28] which are acquired from private hospitals consisting of lung CT scan images of size 512x512.\nTypically, medical data is so big that deep neural networks constantly struggle with overfitting. An average pooling layer, which lowers network complexity, is utilized to solve this issue. Accuracy and loss plots clearly indicate that the proposed model does not overfit the data and therefore exhibits good efficacy. The trade-off between the true positive rate and the false positive rate is shown in figure 6."}, {"title": "Conclusion", "content": "High accuracy is essential, while building a deep learning model for lung cancer diagnosis. As a result, MSNN model with rigorous design has been proposed which gives impressive levels of efficiency. In comparison to previous methods, the proposed model outperformed them with accuracy of 98% and sensitivity of 97%. The suggested model considerably aids in the classification process by successfully extracting features from multiple convolution layers. On the input lung CT scan image, a sensitivity map has been created, showing the nodule area in red. This map makes it easier to distinguish between cancerous and non-cancerous areas of the image. Future work will mostly focus on resolving specific aspects that often need to be adjusted manually\nto obtain high accuracy with a classifier. Fixing this problem could be a major goal of future projects. One possible option is to use Bayesian optimization, which is a method for automatically choosing the best parameters. This strategy would improve the effectiveness of the classifier and expedite the parameter selection procedure."}, {"title": "Data Availability", "content": "In this work, lung CT scan images has been collected from 434 cancer patients from A.J. Institute of Medical Sciences in Mangalore, India. Data available on request from the authors."}, {"title": "Conflicts of Interest", "content": "The authors declare that they have no conflicts of interests."}]}