{"title": "Exploring the Collaborative Co-Creation Process with AI: A Case Study in Novice Music Production", "authors": ["YUE FU", "MICHELE NEWMAN", "LEWIS GOING", "QIUZI FENG", "JIN HA LEE"], "abstract": "Artificial intelligence is reshaping creative domains, yet its co-creative processes, especially in group settings with novice users, remain under explored. To bridge this gap, we conducted a case study in a college-level course where nine undergraduate students were tasked with creating three original music tracks using AI tools over 10 weeks. The study spanned the entire creative journey from ideation to releasing these songs on Spotify. Participants leveraged AI for music and lyric production, cover art, and distribution. Our findings highlight how AI transforms creative workflows: accelerating ideation but compressing the traditional preparation stage, and requiring novices to navigate a challenging idea selection and validation phase. We also identified a new \"collaging and refinement\" stage, where participants creatively combined diverse AI-generated outputs into cohesive works. Furthermore, Al influenced group social dynamics and role division among human creators. Based on these insights, we propose the Human-AI Co-Creation Stage Model and the Human-AI Agency Model, offering new perspectives on collaborative co-creation with AI.", "sections": [{"title": "1 INTRODUCTION", "content": "Artificial intelligence has afforded a new era of creativity, where humans and machines collaborate to produce novel and innovative works. Human-AI co-creation has emerged as a growing field of interest, capturing the attention of researchers and practitioners alike. The goal is to leverage the strengths of both humans and AI to produce creative outcomes that go beyond what either could achieve alone [75]. Such synergy has found applications across various domains, including writing [56], fashion design [25], architecture [68], marketing and advertising [37], visual arts [79], and more.\nIn music production, AI-powered tools have become increasingly popular, supporting both expert musicians [19, 23] and novices [44, 49] in the creative process. A plethora of AI music generation and production tools powered by foundational models [48] have been developed, aiming to facilitate music creation by increasing efficiency, enhancing self-expression, and supporting idea generation. Al music tools can compose melodies [39], harmonize chords [70, 71], transcribe [60], improvise [51], suggest lyrics [74], and assist in mixing and mastering tracks [65]. For novice users, AI lowers barriers to entry, enabling individuals without formal training to engage in music production and express their creativity. Platforms like Suno [9], Google's Magenta [3], and OpenAI's MuseNet [6] advertised they can democratize music creation by providing users with accessible tools that augment their creative capabilities."}, {"title": "2 RELATED WORK", "content": "Co-creation with Al refers to collaborative creative processes where humans and AI systems work together, leveraging respective strengths to achieve a shared creative goal. Human-AI co-creation represents a fundamental shift in how we interact with technology, moving from a tool-based relationship to a collaborative partnership [10].\nTraditionally, music composition and production have relied heavily on human creativity and technical skill. Over the years, researchers in human-computer interaction and music education have explored this domain by developing digital musical tools-ranging from automatic mash-up systems and recording interfaces to gamified learning platforms and tutoring aids [36].\nWith the advent of AI-powered systems, new possibilities have emerged to automate and augment various stages of music creation, sparking discussions about where these tools fit into the creative process [46, 52] and how to ethically define roles and responsibilities for AI [22, 47, 54]. In particular, AI has been proposed as a means to support novice creatives. For instance, neural networks based system complemented by steering tools can restrict generative notes to particular voices and nudge output in high level directions, thereby enhancing a novice's sense of control and ownership [49]. Additionally, novices often lack foundational music knowledge and are deterred by the complexity of traditional production tools, making them prone to reduced motivation [45]. Researchers emphasize tailoring AI solutions to novices' specific needs, preserving enjoyment and intrinsic motivation throughout the creative process [45, 49].\nHowever, previous studies have predominantly examined individual musicians' interactions with single-purpose Al tools in controlled settings [35, 50], leaving a gap in understanding how teams of creators, particularly novices, integrate AI tools across an entire production cycle. As AI evolves from discrete utilities to collaborative partnership [69], it is crucial to investigate how such technologies reshape collaborative processes. Our work explores how novice teams Co-create with AI tools over an extended music production period."}, {"title": "2.2 Introduction of Al Tools Used in the Case Study", "content": "Students in our study used a variety of AI tools. Here, we briefly introduce these tools and their functions to provide context for understanding our findings.\nTraditionally, there are various production elements in music production, such as composition (creating music content, such as melodies and chord progression), arrangement (organizing musical elements), recording (capturing audio), mixing"}, {"title": "2.3 Amabile's Model of Creativity \u2013 Our Theoretical Lens", "content": "In the field of creativity research, scholars have proposed various models-such as the Four C Model [41], the Four P's model [30], the Five A's model [29], as well as stage-based frameworks like design thinking and Pearlman's model [57]-to capture the multifaceted nature of creative processes. Each framework offers unique insights into the origins, dynamics, and outcomes of creative work.\nAmabile's Componential and Stage Model [11-13, 15] is among the most widely recognized and cited in this domain. It explains how creativity emerges from the interplay of (1) domain-relevant skills, (2) creativity-relevant processes, and (3) task motivation. Beyond these components, Amabile's model articulates five key stages of creative work: task identification, preparation, idea generation, idea validation, and outcome. These stages illustrate how individuals or small groups progress from recognizing a creative need to gathering information and skills, generating ideas, evaluating their viability, and deciding whether to accept a solution or loop back for further iteration. Additionally, Amabile emphasizes the role of the environment factors in fostering creativity, suggesting that supportive environment encourages risk-taking, autonomy, and open collaboration [13, 15].\nWe adopt Amabile's model as our primary theoretical lens (see Section 3.4) due to its broad applicability across creative domains and its longstanding influence in creativity research. Our findings illustrate Al's influences on each stage and need for a revision of the current model. Accordingly, we propose an updated version of Amabile's framework that illustrates how involving AI fundamentally transforms people's creative processes."}, {"title": "3 METHODS", "content": "To explore how novice music creators co-create with AI tools over an extended period, we reviewed artifacts, process logs, and presentations by students who participated in a music production with Al course in the Spring of 2024. Additionally, we interviewed nine undergraduate students (out of 20 who attended the course). The interviews were conducted during the summer following the course completion, with each session lasting approximately 55 to 70 minutes. This study was reviewed by our institutional review board (IRB) and deemed exempt."}, {"title": "3.1 Study Context", "content": "The participants were enrolled in a 10-week capstone course at our academic institution, designed to let students explore AI and music creation in the digital age. The course aimed to let students experience through the entire music production process-from initial ideation to final distribution-culminating in the release of their music on platforms such as Spotify and students' group websites.\nStudents were organized into teams of four to six members. Each team was tasked with collaboratively producing three tracks to be released as a single EP (see Figure 1 for a conceptual illustration of students' collaborative co-creation context). The instructors provided an introduction and brief descriptions of various AI tools but gave students the freedom to explore and choose the tools that best suited their creative processes. Throughout the course, students used a variety of AI tools to support different stages of music production, including lyrics writing, composition, melody creation, instrument, mixing and mastering, and for distribution purposes, EP cover and website design. They also incorporated their own singing and vocal recordings, sometimes renting professional recording studios to mix their voices with Al-generated outputs. The course structure included lectures, weekly presentations of each team's progress, and a final presentation showcasing their EP and reflections on the process."}, {"title": "3.2 Participants", "content": "Participants were recruited through the course instructor and teaching assistant after the course had concluded. We reached out to all 20 students who took the course, and nine agreed to participate in the study. Prior to the interviews, participants completed an initial survey to collect demographic information and their prior music production experience. The nine students we interviewed belonged to three teams: four students from the first team (P1, P2, P3, P4 - Team A), three from the second team (P5, P6, P9 -Team B), and two from the third team (P7, P8 - Team C)."}, {"title": "3.3 Procedures and Materials", "content": "We initially collected all the course homework materials from the instructor and teaching assistant. Our research team collectively reviewed students' submissions, including students' production plans, work-in-progress documents, final lyrics and songs, the Spotify EPs, and the websites they created for the course. The research team listened to all songs and analyzed lyrics and musical elements like vocals, instruments, and raps, noting themes and impressions. We met weekly to discuss the material collected and the potential research questions. Then three team members independently drafted semi-structured interview questions based on our agreed research questions. Over the next three weeks, the team discussed and refined interview questions, resulting in a final interview protocol comprising four main parts. The first part asked participants about collaboration dynamics. We explored the students' collaborative roles within their teams and their perceptions of Al's role in production. We also asked about the benefits and challenges faced when incorporating AI into a team setting. The second part asked about students' experiences with the music production process, focusing on how the involvement of AI technologies affected various music production stages and their individual workflow. The third part of the interview protocol explored participants' reflections on the 10-week music-making with Al journey. We asked their perceptions of how Al influenced their self-efficacy, creative expression, sense of ownership, and control and pride over the music pieces. Interviews were designed to last 60 minutes. All interviews were audio-recorded and transcribed. We anonymized and securely stored all audio recordings."}, {"title": "3.4 Data analysis", "content": "We employed an abductive approach to analyze and understand the case by both existing related theories and empirical data collected. The abductive approach is often used in case studies [59] and the process systematically combines theoretical framework, empirical data, and case analysis [26]. The aim of our abductive approach is to provide ideas and a subsequent tentative theory [59].\nWe began analyzing the data and reviewing theories concurrently with the interviews. During the first round of coding, we used Reflexive Thematic Analysis [26]. One team member read the transcripts and revisited the audio recordings multiple times. The teammate extracted quotes and organized them into preliminary themes. The research team met weekly to discuss initial understandings, share insights, and compare interpretations of these quotes and themes. Through an iterative process, we agreed upon themes related to participants' usage, perceptions, and experiences of Al in the music production process. These themes encompassed various aspects such as collaboration dynamics, challenges and benefits of using AI, the influence of AI on creativity and workflow, and participants' perceptions of AI in the music production process.\nAs our analysis progressed, we identified an alignment between the emerging themes and Amabile's Model of Creativity [13], which delineates creative stages. Recognizing this congruence, we integrated Amabile's model as a guiding framework to further structure and interpret our data. During subsequent meetings, the research team discussed how our data both supported and extended Amabile's model. We reached a consensus to adopt the theory for the next phase of analysis. This involved re-examining part of the data with Amabile's model in mind, and coding transcripts according to the creative stages of the model. We remained open to the possibility of modifying the model based on our findings.\nThe research team collaboratively refined the themes to reflect the expanded framework of creativity. Using an online collaborative tool (Figma), one researcher organized related transcript quotes into stages of creativity and human-AI collaboration themes. During a half-day data analysis workshop, four researchers collaboratively mapped participants'"}, {"title": "4 RESULTS", "content": ""}, {"title": "4.1 Collaborative Co-creation Stages with Al", "content": ""}, {"title": "4.1.1 Stage 1: Problem and Task Presentation.", "content": "Defining Creative Vision and Objectives. In the initial stage, AI played little role. Participants focused on defining what they wanted to create, identifying the central theme, vision, and clarifying the message or \"story\" they aimed to convey. They discussed broad questions such as \u201cwhat kind of story [we] want to tell and the feeling [we] want the sound to resonate\u201d (P9). One participant explained, \u201cwe need to come up with the problem statement that we can explore different Al usage in the music production process\" (P3), while another noted the importance of aligning their vision by understanding \u201cwhat we want to express [and] what we lack\" (P4). These discussions not only guided their creative goal but also helped the teams form a collective motivation for the project."}, {"title": "4.1.2 Stage 2: Preparation: Building Up Relevant Information and Skills.", "content": "In a traditional creative process, the preparation stage involves gathering knowledge, researching relevant information, and developing domain skills, which involves a great deal of learning and time-consuming [14, 17, 58]. However, in our case, students advanced quickly from Stage 1 (problem presentation) to Stage 3 (ideation). AI enabled fast idea generation without much preparation, reducing the need for knowledge-building at the outset.\nWhen asked about their production process, none explicitly mentioned a distinct preparation or research phase. Their \"production plan\" documents submitted as class assignments showed an immediate pivot from initial brainstorming to active ideation. While the 10-week capstone structure likely created external pressure to progress quickly, participants repeatedly noted that AI helped them dive into music creation with minimal prior expertise. Interestingly, several participants described using AI generation as a way to build domain knowledge. One student explained:\n\u201cWe would create a sample using software [AI]. Then downloaded it, fed it into [an audio-to-text] AI tool. It [the tool] would read that music clip and generate text based on how it sounded... From there, we put that text into another tool to see what it would generate\" (P8).\nThrough feeding musical snippets into AI and receiving feedback or textual descriptions, students began to understand specific terminology and refine their vocabulary to prompt other Al systems. Another participant mentioned that an Al tool provides sample clips and patterns for the creator to generate and combine ideas, saying it \u201chelped [us] think creatively about what electronic or techno music we wanted to create\" (P7), even though the final tracks did not incorporate that tool's outputs.\nOverall, we observed a blurring of the preparation and ideation stages. Rather than devoting significant time to mastering musical fundamentals, novice users relied on trial-and-error with AI to gain the knowledge needed for creation. This stands in contrast to the long \"warm-up\" periods often noted in creativity literature [12, 67, 73]."}, {"title": "4.1.3 Stage 3: Idea Generation.", "content": "The third stage of creativity involves generating ideas and exploring solutions. However, with AI, participants described a fundamentally altered process. Traditionally, individuals draw from their cognitive pathways and environ- mental resources [14], but Al enabled them to produce music with less reliance on human cognitive and environmental resources. Our data suggest that Al served as a powerful springboard for inspiration, speeding up the ideation process, and a potential source of idea fixation on initial Al's output."}, {"title": "4.1.4 Stage 4: Idea Selection and Validation.", "content": "After generating a plethora of ideas generated by AI in Stage 3, participants moved on to selecting these ideas. As one student succinctly put it, \u201cThe output that Al generates needs to be selected by humans... The final choices are made by humans\u201d (P1) Traditionally, individuals use domain-relevant skills acquired during Stage 2 to evaluate ideas for correctness or appropriateness [14]. However, because participants had little knowledge-building preparation, and AI could quickly produce numerous options, selecting and validating ideas became challenging.\nThe Challenge of Validating Abundant AI-Generated Ideas. Participants frequently felt overwhelmed by the sheer number of AI-generated options, finding it time-consuming to sift through them and decide which ideas merited further development. One participant recalled, \u201cWe spent a large chunk of time trying to find something that we felt fit...And then it did become a little frustrating because we want to make progress on the song\u201d (P8). Another participant mentioned generating a wide range of lyrics then need to filter out subpar content: \u201cThat's not to say I was blindly accepting AI stuff...a lot of the lyrics were just really corny\u201d (P6). Lacking formal rubrics or deep domain expertise, many teams relied on gut feelings and intuition. One participant described hearing a promising AI-generated beat at the fifth iteration and disregarding the rest: \u201cIt just really resonate[d]... We couldn't listen to the sixth or seventh iteration. We just stuck with that fifth one\u201d (P1). Another noted that, \u201cWe tried a lot of stuff with Al but only a small fraction made it into the final song\u201d (P9). For these novice producers, the subjective sense of what \u201csounds good\u201d often served as the default standard."}, {"title": "4.1.5 Stage 5: Collaging, Refining, and Integration with Human-Created Elements (The New Stage Caused by Involving Al).", "content": "As a result of incorporating multiple AI tools and outputs into the creative process, participants introduced a new collaging and refinement stage in which they assembled materials from various Al sources into a cohesive musical work. In our case study, students typically found themselves working with scattered AI outputs often generated from different AI tools-melodies, chord progressions, vocal snippets, and sound effects-none of which fit together seamlessly. Additionally, they often needed to refine and adjust these fragments, then combine them with human-created elements such as raps, vocals, and instrumentation. In this stage, creators had to integrate an assortment of discrete pieces into a cohesive musical composition, much like stitching together diverse elements in a visual collage.\nOne student mentioned, \u201ceveryone may use Al to do some different parts\u201d (P4), and another explained, \u201cwe used a lot of [AI tools], then we combined ideas... I actually spent [a great deal of] time pulling them together\u201d (P2). The same student described in charge of putting teammates' AI-generated chords, beats, or lyrics and then using a digital audio workstation to merge and modify them: \u201cIt starts with a melody...chords from another person...and lyrics from another teammate\u201d (P2). P8 summarized succinctly, \u201cWe blended the outputs\u201d (P8).\nNecessity of Refinement and Adjustment. Integrating AI outputs also demanded refinement of each AI output. One participant said, \u201cAI just produced the idea, and most importantly, it is our work in editing that\u201d (P2). Another explained how they had to alter lyrics for better rhyme or tweak generated chords to suit the group's performance, \u201cIf you want a comprehensive, emotional song, you have to do some refinements by yourself\u201d (P3). Some misalignments, such as slight key differences or awkward transitions, forced participants to manually fix them to meet their musical standards (P2)."}, {"title": "4.1.6 Stage 6: Outcome.", "content": "Amabile's original model posits three possible outcomes for creative efforts: success, failure, or partial progress toward a goal [12]. In our study, AI mitigated the risk of \u201cno reasonable response possibility generated,\u201d [14] providing participants with \u201cpsychological safety\u201d [14] for further exploration. As one student affirmed, \u201cI feel like we succeeded. I don't think I ever would have made a song if I didn't have AI help me\u201d (P6). Even if the first song did not meet everyone's exact expectations, Al frequently offered enough momentum to ensure progress. By the end of the course, each team produced and published three complete EP tracks-an accomplishment that students unanimously viewed as a success. The shared artifacts students created, including published EPs, helped them solicit feedback from peers, friends, and family. This feedback cycle reinforced what Amabile describes as a \u201cprogress loop,\u201d [15] whereby tangible advancement in meaningful work boosts intrinsic motivation and improves creative performance in subsequent iterations.\nDuring this final stage, participants also developed more objective views of Al's limitations, particularly regarding the challenges of integrating and refining its outputs (see Stage 5). These insights prompted them to adapt how they would like to use Al in the next round. In addition, knowledge and experience gained from the initial trial is added to the participant's domain skills. Over this process, students developed confidence and agency, as one remarked, \u201cMaking an album with other people and Al sounded really hard at the beginning, but at the end, we found it wasn't hard with teammates and AI\u201d (P7). Notably, students often decide to rely more on their own rather than Al for future iterations. Collectively, our findings indicate that during this stage, students consciously reassessed the appropriate level of AI involvement, reevaluated their expressive needs, and integrated the domain expertise they had acquired before embarking on future iterations."}, {"title": "4.2 Human-Al Collaboration", "content": "Incorporating Al into the collaborative co-creation process reshaped social dynamics and influenced how students perceived their roles in the creative activity. While some teams treated AI as an additional \"teammate,\" participants acknowledged that AI differs fundamentally from human collaborators. This section details how AI mediated social interactions, how participants conceptualized Al's roles, why they valued human emotional input, and how they retained control over Al's contributions."}, {"title": "4.2.1 Al-Mediated Social Dynamics.", "content": "Sensitivity in Human-Human Collaboration. Creating music as a team involves emotional risk and personal investment, making feedback exchanges especially delicate. One participant described learning \u201cwhen to step in and give feedback and when to let people do their own thing\" (P6), highlighting the tension between honest critique and respecting others' creative autonomy. Many admitted they were too polite to challenge ideas they did not like. \u201cPeople are a little hypocritical...nobody wanted to say bad things\u201d (P5). Another participant observed how each member's different tastes demanded ongoing compromise: \"We each have different interests...there's got to be some compromise there\u201d (P6). Because most were still getting to know each other, they often defaulted to being \"receptive to everyone's ideas\u201d (P6), even at the cost of constructive critique.\nEmotional Ease and Honest Critique with AI. In contrast, participants felt more comfortable offering blunt critiques of AI outputs. One student noted, \u201cIt's easy...you don't have to worry about hurting Al's feelings\u201d (P6). They routinely ignored or modified AI outputs generated by themselves or others without fearing interpersonal conflict. P6 explained, \u201cWhen your teammate shares something [they made]...you have to treat them gently, whereas with Al, it's easy to ignore 90% of what it says\" (P6). A different participant even credited AI for reducing social barriers around sensitive song topics, remarking that \u201ca judgment-free AI allowed us to bring walls down and execute on our vision\u201d (P9). While AI was treated as a creative partner, its emotional neutrality made it easier to critique and reject its suggestions, a stark contrast to human-to-human interactions."}, {"title": "4.2.2 Perceived Roles of Al in Music Production.", "content": "AI as a \"Team Member\" and Co-Creator. Some participants described AI as a creative partner that actively contributed to idea inspiration, lyric composition, and other roles. As one noted, \"It acted as both a songwriter and a lyric writer...like two group members at once\u201d (P2). Another participant referred to AI as \"a fifth person in the room...someone to bounce ideas off of\" (P6). Some teams even anthropomorphized the AI, giving it a name such as \"Strawbae\u201d to signal its perceived membership in the band. However, expectations of Al's ability to maintain a team member role over time in creative collaboration often fell short. According to one student, \u201cWe wanted Strawbae to be a band member, but...we found it was really difficult to give AI that kind of character\", and by the end of the term, they had \"less confidence\" in it than they initially expected (P8).\nAI as Technical Assistant or Domain Expert. Others viewed Al primarily as a powerful assistive tool, filling technical gaps where team members lacked expertise. One student believed AI should \u201cprovide technical support and creative inspiration\u201d (P3), while another admitted they \u201cregard AI as having more expertise than us\u201d (P6), especially in mixing, mastering, or specific stylistic domains. Additionally, P2 admitted AI takes on tasks outside the participants' expertise, such as creating visuals for album art."}, {"title": "4.2.3 Valuing Human's Emotional and Creative Expression.", "content": "Al's Perceived Mechanical Output and Lack of Emotional Depth. Participants frequently criticized AI-generated music as lacking the emotional depth that human-made compositions convey. One student commented, \u201cit lacks a certain amount of rawness you get from music made by humans\" (P8). Another used a metaphor to describe AI outputs as \u201ctoo simple...like orange juice without added ingredients\" (P2), highlighting their view that AI compositions do not capture the emotional nuance that resonates with listeners. A third participant recognized AI's \u201cexcellent technical processing,\u201d yet lamented its inability to supply \"emotional expression, the space where human creativity remains irreplaceable\u201d (P3). Others echoed similar sentiments, describing Al music as \"mechanical and stiff\" or \"formulaic and monotonous\" (P5).\nImportance of Emotional Connection. Students underscored the emotional connection between listeners and creators. One participant explained that listeners \u201cwant to be attached to the real people behind it\u201d (P6), arguing that a composer's lived experience or personal identity shapes how an audience emotionally engages with the work. Another student asked how one could meaningfully relate to an Al-generated piece: \"We relate symphony number five with Beethoven, his own experience and his own idea, his own expressions...But if this song is also written by a certain kind of AI model, maybe it reminds me of Beethoven. How can we relate this piece with the AI model itself?\" (P1).\nSeveral participants stressed the need to retain human emotional involvement, even as AI becomes more capable. One argued that \"final artistic expressions still need deep human involvement and emotional investment\" (P3). One participant summarized succinctly,"}, {"title": "4.2.4 A Conscious Choice to Retain Control.", "content": "Participants repeatedly emphasized the importance of actively monitoring and editing AI-generated content, rather than overrely on it unquestioningly. One student explained how they would \"question each line\" in AI-created lyrics, ultimately scrapping many of them (P6). Another participant noted that \"Al generates better results, but at the end it's mainly us who wrote the prompts and chose...whether to use the end results\" (P7), highlighting their conscious decision to maintain authority over the creative process.\nA key concern emerged around losing artistic ownership if AI tools grew too powerful. One team preferred to use various tools instead of relying on a powerful single \u201cMusic AI\u201d tool because \u201cit could verge on...making its own song\" (P6). Others described Suno's limited parameters as \"challenging to control\" (P7), prompting them to shift toward AI solutions with more adjustable settings over time. As they gained experience, participants stressed the importance of human goals and critical thinking guiding every stage of music creation. \u201cWe can use Al to generate our idea, but never let it replace our thinking...we have to have our own thinking\" (P2). They concluded that humans must ultimately \"select\" from Al outputs (P1), ensuring the final piece reflects their vision rather than an algorithm's."}, {"title": "4.3 Al's Impact on Creative Expression and Self-efficacy", "content": "Participants expressed both positive and negative views regarding Al's influence on their creative expression, praising its ability to boost confidence while also critiquing its constraints on artistry and collaboration."}, {"title": "5 DISCUSSION", "content": ""}, {"title": "5.1 Design Implications for the Human-Al Co-Creation Stage Model", "content": "In this subsection, we connect the results in Section 4.1 and propose a Human-AI Co-creation Stage Model (see Figure2). The model builds on and extends Amabile's original model of creativity [12]. We also discuss the challenges and opportunities AI offer and propose a list of design implications for each stage of the co-creation process."}, {"title": "5.1.1 Protean Roles of Al and Supporting Initial Problem Space Exploration.", "content": "Many students in our study were initially uncertain about Al's potential, often personifying it as a \"fifth teammate\". However, Al is neither human nor strictly confined to any single role [72]. Instead, it can perform multiple functions- from generating chord progressions to synthesizing vocals in our case. Viewing Al as an environmental factor [15, 55] or resource, rather than a discrete collaborator, may offer a more adaptable and efficient framework for creativity. Environmental factors refer to external influences that either support or hinder the creative process. Using this perspective, the presence of AI can impact an individual's intrinsic motivation, access to resources, and ability to engage in creative thinking."}, {"title": "5.1.2 Supporting Preparation and Domain Knowledge Building.", "content": "In our study, the Preparation stage (Stage 2) was often compressed or entirely bypassed, with participants swiftly transitioning from Task Identification (Stage 1) to Idea Generation (Stage 3). We attribute this rapid progression to the availability of powerful AI tools that facilitate quick ideation, thereby reducing the perceived need for an extensive \"warm-up\" or preparatory period. However, the preparation phase and the development of domain knowledge are critical not only for understanding the creative activity initially but also for effectively evaluating ideas during Idea Selection and Validation (Stage 4). The absence of a thorough preparation stage may undermine creative outcomes, as creators under external pressure might favor more predictable, AI-generated solutions without sufficient domain expertise [14].\nDespite these challenges, there is significant potential for AI to support more systematic knowledge and skill exploration. Foundational AI models can provide domain-specific knowledge, sense-making support, and contextual explanations tailored to novices' needs. For example, in the domain of image generation, tools like CreativeConnect [24] enable users to analyze reference images, break down suggested keywords into categories, and recombine elements to create new images with Al assistance. By delivering contextual explanations and tailored domain knowledge, AI can provide a structured preparation phase before engaging in ideation. Moreover, intentionally delaying the introduction of the AI-driven ideation phase to incorporate a \u201ctraining the brain\" period may foster deeper cognitive engagement and mitigate the risk of early cognitive fixation on suboptimal ideas [31]."}, {"title": "5.1.3 Supporting Divergent Inspiration and Preventing Convergent Fixation .", "content": "Students in our study consistently praised AI for its ability to rapidly generate numerous creative ideas, serving as a powerful tool for inspiration and exploration. As multiple studies have noted, AI systems can function effectively as brainstorming aids [43, 64, 77], offering a seemingly endless array of possibilities. However, this capability also tends to drive an early convergence in the ideation process. Traditionally, creative ideas emerge gradually, often following a prolonged incubation phase during which vague ideas evolve into clear, innovative concepts [73]. In contrast, AI frequently delivers near-final or highly refined outputs. This immediate availability of polished ideas can narrow a creator's exploratory range, leading them to focus on perfecting specific prompts rather than venturing into broader, alternative creative pathways.\nAI-enabled creativity also shifts the burden from generating ideas, which traditionally a significant obstacle, to selecting and evaluating them. Participants in our study expressed decision fatigue [33] when confronted with numerous Al-generated options. Without extensive domain knowledge or preparation, they often defaulted to intuitive judgments, such as \"it sounds good\". Creators may gravitate toward a satisficing choice, selecting an adequate option rather than striving for the optimal one, an example of bounded rationality [66]. Being highly subjective, music domain may validate such a gut-level approach. However, over-reliance on intuition risks cognitive biases, akin to System 1 thinking overshadowing more deliberate System 2 reasoning [40] and intuition judgment may not apply to other co-creation domains such as marketing and architecture design."}, {"title": "5.1.4 Challenges in Collaging, Refining, and Integration.", "content": "Our findings reveal a new stage that extends beyond Amabile's original framework: Stage 5, focused on collaging, refining, and integrating AI outputs with human-produced material. Many described the process as time-consuming and technically challenging, with Al outputs often arriving in uneditable formats that impede integration. Consequently, promising ideas are sometimes abandoned simply because they cannot be made to \"fit\u201d with other elements."}, {"title": "5.1.5 Sustaining Progress and Motivation.", "content": "Our results (Section 4.1.6) show all groups completed an EP consisting of three songs, demonstrating involving AI leads to success or at least help human creators gain some progress towards creative goal established in Stage 1 (Task Presentation). By achieving tangible results, creators experience a \"progress loop\" [15], where a sense of accomplishment boost motivation and confidence, prompting them to loop back to Stage 1 for another cycle of ideation. This positive feedback cycle can foster high levels of creativity over multiple iterations."}, {"title": "5.2 Al-mediated Social Dynamics and Roles", "content": "Creativity is often framed as a deeply social process [42], especially in domains like music where improvisation, compo- sition, and performance traditionally hinge on collaboration and interpersonal exchange. The creative collaboration has been proposed to be \"distributed\" among audiences, materials, embodied actions, and the socio-cultural environment, which expand the collaboration concept to beyond direct human collaboration [20]. Our data shows AI can assume dual functions within a creative team-it can appear as a \"teammate\" to whom creators assign a name (e.g., \"Strawbae\"), or it can serve as a environmental factor that shapes the creative environment without behaving as a conventional collaborator, serving as technical tools and socio-cultural contexts.\nThese AI-mediated social dynamics influenced how participants critiqued work and navigated interpersonal relation- ships. While students often hesitated to offer candid, potentially harsh feedback on their peers' contributions, they felt no such inhibitions about criticizing AI output-even when it was co-created by a human teammate. This tendency resonates with findings from AI-mediated communication research [28, 32], where research shows individuals partly blame AI rather than attributing all responsibility to their conversation partners [34]. In group settings, AI can thus function as a buffer or scapegoat, easing interpersonal tensions by absorbing some share of blame or critique.\nAdditionally, our study highlights how AI-driven successes may foster inflated self-assessment among novice creators. Many participants lauded their final works as their own achievements, even if AI played a decisive role in shaping the music or lyrics. This self-attributed success can cultivate optimism and self-efficacy, motivating further experimentation with AI. However, this self-attribution may be somewhat illusory, given that the compressed preparation phase in our study might have left creators with limited domain knowledge, thereby constraining their ability to critically appraise the quality of their outputs."}, {"title": "5.3 Human-Al Agency Model in Co-Creation", "content": "We propose a Human-AI Agency Model (see Figure 3) that positions users in the driver'"}]}