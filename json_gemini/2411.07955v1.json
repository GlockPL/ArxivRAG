{"title": "How to discover short, shorter, and the shortest proofs of unsatisfiability: a branch-and-bound approach for resolution proof length minimization", "authors": ["Konstantin Sidorov", "Koos van der Linden", "Gon\u00e7alo Homem de Almeida Correia", "Mathijs de Weerdt", "Emir Demirovi\u0107"], "abstract": "Modern software for propositional satisfiability problems gives a powerful automated reasoning toolkit, capable of outputting not only a satisfiable/unsatisfiable signal but also a justification of unsatisfiability in the form of resolution proof (or a more expressive proof), which is commonly used for verification purposes. Empirically, modern SAT solvers produce relatively short proofs, however, there are no inherent guarantees that these proofs cannot be significantly reduced. This paper proposes a novel branch-and-bound algorithm for finding the shortest resolution proofs; to this end, we introduce a layer list representation of proofs that groups clauses by their level of indirection. As we show, this representation breaks all permutational symmetries, thereby improving upon the state-of-the-art symmetry-breaking and informing the design of a novel workflow for proof minimization. In addition to that, we design pruning procedures that reason on proof length lower bound, clause subsumption, and dominance. Our experiments suggest that the proofs from state-of-the-art solvers could be shortened by 30-60% on the instances from SAT Competition 2002 and by 25-50% on small synthetic formulas. When treated as an algorithm for finding the shortest proof, our approach solves twice as many instances as the previous work based on SAT solving and reduces the time to optimality by orders of magnitude for the instances solved by both approaches.", "sections": [{"title": "1. Introduction", "content": "For the last two decades, the field of propositional satisfiability has experienced explosive growth, which has led to a wide range of applications of SAT solvers. Some of the common examples include model checking (Prasad et al., 2005), AI planning (Ernst et al., 1997), and combinatorial designs (Zhang, 2021). A trait common to many domains relying on SAT solving is that unsatisfiable formulas have a meaningful domain interpretation (e.g., the correctness properties in verification domains), rather than merely being artifacts of poor modeling. However, as many of these domains have rigorous demands for the results"}, {"title": "2. Preliminaries", "content": "In this section, we establish the main concepts from propositional logic and SAT solving that we need to motivate the problem we address and the approach we propose. Section 2.1 contains the foundational definitions of propositional logic, such as the definition of an unsatisfiable formula. In Section 2.2, we introduce the notion of the resolutional proof system and restate the most important facts involving it."}, {"title": "2.1 Propositional Satisfiability", "content": "We start by introducing propositional formulas in conjunctive normal form, which is a common expectation in modern SAT solvers. Given a Boolean variable x, a literal is either the variable x itself or its negation z. A clause w is a (possibly empty) set of literals: $w = \\{l_1,..., l_k\\}$; a formula F is a set of clauses: $F = \\{w_1,...,w_m\\}$. Since clauses and formulas are commonly interpreted in logical terms, we also use the conjunction/disjunction notation interchangeably with the set notation. For example, the terms $\\{x,y\\}$ and $x \\lor \\bar{y}$ correspond to the same clause, while the terms $\\{\\{x, \\bar{y}\\}, \\{\\bar{x}, z\\}\\}$ and $(x\\lor\\bar{y}) \\land (\\bar{x}\\lor z)$ correspond to the same formula.\nGiven a formula F over variables $x_1,...,x_n$, a model x is a mapping from variables to Boolean values. A model satisfies a clause $\\{l_1,...,l_m\\}$ if at least one of the literals evaluates to true, that is, there is an index j such that either $l_j = x_t$ and $x_t = 1$ or $l_j = \\bar{x_t}$ and $x_t = 0$. By extension, a model satisfies a formula F if it satisfies all its clauses. If a model does not satisfy a clause or a formula, we say that the model falsifies the clause or formula. Finally, we call a formula satisfiable (SAT) if there is a model that satisfies it; otherwise, if all models falsify a formula, we call it unsatisfiable (UNSAT).\nNote. We assume that clauses do not contain repeated variables, because $x \\lor x = x$ and $x \\lor \\bar{x} = \\top$. Thus, any repeated literals can be removed, and any clause with opposite literals can be removed from the formula without loss of generality: if a model satisfies the remaining clause, it also satisfies the entire formula.\nNote. An empty clause $1 = \\emptyset$ is falsified by any model as there are no literals to evaluate to true; by extension, a formula F that contains an empty clause is falsified by any model.\nDetermining the SAT/UNSAT status of a given formula is an NP-complete problem (Cook, 1971; Levin, 1973), which also implies the following asymmetry between SAT and UNSAT statuses: if a formula F is reported to be SAT, this can be verified independently given a satisfying model, however, no similarly simple certificate could support the claim that F is UNSAT. There are, however, a few ways to do it; the next section introduces the certification approach studied in this paper."}, {"title": "2.2 Resolution Proof System", "content": "As stated in the introduction, the UNSAT claim is not trivial to verify. To address this, in this section, we introduce the resolution rule, which is a rule for deriving an implied clause from two given clauses (which themselves may have been derived earlier); in particular, the UNSAT claim in that context corresponds to deriving the empty clause.\nDefinition 1. Given clauses $A = C' \\lor x$ and $B = C'' \\lor \\bar{x}$, a resolution rule is an inference rule that produces a clause $C' \\lor C''$\u2014also denoted as $A \\land B$\u2014from A and B:\n$\\frac{C' \\lor x, \\qquad C'' \\lor \\bar{x}}{C' \\lor C''}$\nThe resulting clause $A \\land B$ is called the resolvent, and the variable x is referred to as pivot variable (or pivot literal, which in this case points to the same entity).\nNote. We can assume that A and B do not contain any other \"polar\" literals other than x and because otherwise, the resolvent would contain those polar literals and therefore would be trivially true (and hence can be discarded right away). For example, $(x \\lor y) \\land (\\bar{x} \\lor \\bar{y}) = y \\lor\\bar{y} = \\top$, where x is the pivot variable. In particular, if any two clauses can be resolved, there is no ambiguity about the pivot choice.\nTheorem 1. The resolution rule is sound in the sense that any model satisfying clauses A and B also satisfies the resolvent clause $A \\land B$, and is (Robinson, 1965) in the sense that an empty clause can be derived from a formula if and only if it is UNSAT.\nDefinition 2. Given an UNSAT formula F, a (resolution) proof (of unsatisfiability) is a sequence of M clauses $(Q_1, ..., Q_M)$ such that $Q_M = \\bot$ and for all $1 < i < M$ either $Q_i \\in F$ (in which case $Q_i$ is referred to as an axiom) or $Q_i = Q_j \\land Q_k$ for some $j, k < i$. The proof length is the number of clauses M in it.\nExample 1. Consider an UNSAT formula $F = \\{\\{x,\\bar{y}\\}, \\{\\bar{x}\\}, \\{y\\}\\}$. The following sequence of resolution steps derives an empty clause:\n$(\\{x,\\bar{y}\\} \\land \\{\\bar{x}\\}) \\land \\{y\\}.\\newline = \\{\\bar{y}\\}\nIn our notation, this corresponds to a proof of length five with the following order of clauses: $\\{x,\\bar{y}\\}, \\{\\bar{x}\\}, \\{y\\}, \\{\\bar{y}\\}, \\bot$. Note that the third and fourth clauses may be swapped without violating the proof definition.\nAnother way to encode the proof structure is to track the clauses derived in the proof and the mapping between the resolvents and their premises. This observation suggests the following equivalent definition of a proof:\nDefinition 3. Given an UNSAT formula F, a proof DAG is a directed acyclic graph with the following structure:\n\u2022 Vertices correspond to clauses over the variables of F and include the clauses of F and the empty clause."}, {"title": "3. Related Work", "content": "One of the simplest observations about the definition of proof is that it may contain irrelevant inferences that do not impact the correctness of the proof. This observation is translated into the proof trimming techniques (Heule et al., 2013), a strategy for proof compression that begins with the proof conclusion (i.e., empty clause), marks inferences directly used to generate the conclusion, then the inferences used to derive those steps, etc., and retaining only the marked inferences. This idea also appears in other proof systems under different aliases, such as tightening in the VIPR certification approach for mixed-integer programming (Cheung et al., 2017). In application to SAT solvers, DRAT-trim (Wetzler et al., 2014) is the state-of-the-art tool for trimming clausal proofs.\nThe next logical step from this idea is to consider local transformations of proofs and apply a local search technique to produce shorter proofs. For the branch-and-bound trees in mixed-integer programming framework, this has been done by Mu\u00f1oz et al. (2023) by going through the subtrees and attempting to trim that subtree or discover a branching direction that derives the dual bound as good as the subtree bound. A similar idea for SAT solving is represented by the RANGER approach from Prestwich and Lynce (2006), which operates on clause sets of fixed size and repeatedly deletes clauses, adds the resolvents of available clauses, or re-introduces the formula clauses, and does so until an empty clause is introduced. The distinction here is that RANGER does not attempt to compress the proof, rather, it seeks to establish a local search approach that could produce an UNSAT verdict.\nLast but not least, one may treat the problem of discovering short proofs as an optimization problem, with the feasible set being defined by the proof system inference rules and the objective function encoding the proof length, typically the number of inference steps. For propositional solving, the seminal work of Peitl and Szeider (2021) introduces this idea by constructing a propositional formula that is true if and only if a given formula F has a proof of length s, and improving the search performance by enforcing the topological sort on the underlying proof DAG in order to break underlying symmetries. However, as we observe in our work, this strategy does not break all symmetries; in particular, this strategy does not account for different derivations of the same clause sets, which we exploit in Section 2.2.\nThese ideas are used for the proof minimization by invoking a SAT solver with increasing values of s until the formula becomes satisfiable, in which case a satisfying model contains the proof clauses. Starting the search with s = 1 is possible, but this work also justifies the choice of a higher starting value for the proof length, which corresponds to the lower bound of the length of a valid proof. Additionally, this work also establishes the resolution number $h_m$ as the largest smallest proof length among the formulas with m clauses, and describes a subset of such formulas that is sufficient to enumerate in order to derive the values of $h_m$.\nSimilar ideas have recently been introduced for tree-like proof systems. For example, Dey et al. (2024) formulate the problem of finding the smallest branch-and-bound tree for 0-1 integer programs as a dynamic program, and compare the optimal tree sizes for various classes of problems against the strong branching variable selection. Another variation on this idea can be found in Sidorov et al. (2024), developing an approach for constructing compact tree proofs of optimality in constrained shortest path problems; the distinctive trait of that work is that it focuses on reasoning in an ad-hoc proof system designed for interpretability, as opposed to a proof system encoding the solver inference steps."}, {"title": "4. Proof Minimization", "content": "This section introduces our methodology for discovering the shortest proofs of UNSAT formulas; we structure our narrative as follows:\n\u2022 Section 4.1 introduces our novel layer list representation and shows via Theorem 2 that this representation breaks all permutation symmetries. More specifically, we demonstrate that any correct proof of the unsatisfiability of a formula maps to exactly one such representation. We also motivate this design of the representation by showing that it improves on the symmetry breaking on DAGs by Fichte et al. (2020), as there are non-equivalent proof DAGs that have the same encodings in our approach.\n\u2022 Section 4.2 gives a high-level overview of the branch-and-bound approach to discovering shortest proofs. The distinctive trait of the search procedure we put forward is that it operates on layer list representations and thus inherits its symmetry-breaking properties. This part also lists the subroutines the algorithm relies upon and the properties it assumes to hold on them.\n\u2022 Section 4.3 introduces the branching scheme that complies with the subproblem representation without introducing the full enumeration of subsets of a given formula.\n\u2022 Section 4.4 shows that the subproblems can be simplified during the search by discarding subsumed clauses, an idea which we capture in the frontier set definition. We also show that this simplification can be used as a pruning strategy as soon as there is a clause that is neither a premise of some resolution step nor a frontier clause.\n\u2022 Section 4.5 establishes the dominance relation on the subproblems. The defining trait of this relation is that if one subproblem dominates another subproblem, then any proof that can be recovered from the latter subproblem corresponds to some proof that (a) can be recovered from the former subproblem and (b) is not longer than the original proof. In terms of the optimization algorithm, it means that dominated subproblems can be ignored without the risk of discarding the optimal solution.\n\u2022 Section 4.6 completes the description of our approach by establishing the lower bound on the proof length via the cardinality of the smallest minimal unsatisfiable subset. We also discuss a procedure that is used to establish a bound on that quantity, which by transitivity is also a valid bound for our problem."}, {"title": "4.1 Layer List Representation", "content": "The proof minimization problem is challenging for, among other reasons, its highly symmetric nature: for example, reordering the clauses without putting premises after the conclusions yields different proofs. Since the previous work has represented the proofs as models of a propositional formula, the established way to break symmetries is to (i) encode the solutions as proof DAGs and (ii) impose the symmetry-breaking constraints of the form \"This sequence is a topological ordering of a DAG with lexicographic ordering on disconnected clauses\" (Fichte et al., 2020). However, we argue that breaking only those symmetries is insufficient because the proofs with the same sets of derived clauses can be encoded by different DAGs; the next example illustrates this issue."}, {"title": "4.2 Branch-and-bound Search, High-level Description", "content": "As observed earlier, we can see the enumeration of the proofs as a recursive procedure on layer list prefixes starting from ($L^0 = F$) and extending any given prefix ($L^0, ..., L^k$) with the next layer $L^{k+1}$ by:\n\u2022 constructing the superset $\\Lambda' := \\{w' \\land w'' : w' \\in L^k, w'' \\in L^0 \\cup L^1 \\cup ... \\cup L^k\\}$,\n\u2022 filtering out clauses $\\Delta^j := \\{w' \\land w'' : w', w'' \\in L^0 \\cup L^1 \\cup ... \\cup L^j\\}$ for all previous layers $j < k$ to restrict the clause set to $\\Lambda := \\Lambda' \\setminus \\Delta^{k-1}$,\n\u2022 and making a recursive call on prefixes ($L^0, ..., L^k, L^{k+1}$) for all non-empty $L^{k+1} \\subseteq \\Lambda$.\nFrom this point, we view the prefixes of layer lists as subproblems of the original proof minimization problem in the following sense. In the original problem, we look for the layer list that starts with $L^0 = F$ and has the fewest clauses across all the layers. Next, we generate the prefixes ($L^0, L^1$) and for each of them we look for the layer list that starts with those ($L^0, L^1$) and has the fewest clauses; the best of those layer lists is going to be the one with fewest clauses in the original problem. With each of those prefixes, we do the same procedure looking for the smallest layer lists with larger fixed prefixes and continue doing so until we exhaust all possible layer lists.\nWe also note that this procedure does not require tracking each layer separately. More specifically, it is sufficient to have the clauses from the previous layer $L^k$, the clauses from the union of all previous layers $\\tilde{L}^k := L^0 \\cup L^1 \\cup ... \\cup L^k$, and the \"filtering\" sets $\\Delta^{k-1}$. Given that, we can collate all the layers, except the last, into a single set in our previous description of the search procedure. The next definition reflects these observations in a data structure used to implement the outlined search procedure.\nDefinition 6. Given a propositional formula F, a subproblem P is a tuple containing:\n\u2022 a set of previous layer clauses Previous[P],\n\u2022 a set of current layer clauses Current[P],\n\u2022 a set of next layer clauses Next[P],\n\u2022 and a set of forgotten clauses Forgotten[P].\nThe first three clause sets are collectively labelled as known clauses:\nKnown[P] = Previous [P] \\cup Current[P] \\cup Next[P].\nThe root subproblem $P_{root}$ is defined as follows: Previous[$P_{root}$] = Current[$P_{root}$] = F and Next[$P_{root}$] = Forgotten[$P_{root}$] = $\\emptyset$.\nThe individual parts of this definition are interpreted as follows. If the formula layer and the first k layers of the layer list are fixed, then Previous[\u00b7] is the union of all constructed layers $\\tilde{L}^{k-1}$, excluding the most recent one, whereas Current[\u00b7] is the most recent complete layer $L^k$. Next[\u00b7] is a subset of the layer $L^{k+1}$ that follows the fixed part of the layer list; we define this part of the subproblem like this to add/discard clauses of the next layer one"}, {"title": "4.3 Subproblem Partitioning", "content": "Given that our search space is represented as a list of sets, it is natural to assume that the branching rule is implemented by enumerating all valid sets for the next list element. However, as pointed out earlier, this amounts to enumerating all subsets of the resolvent clauses without forgotten clauses. This is problematic because the set of resolvent clauses can have a quadratic size with respect to the formula size. Fortunately, the subproblem representation explicitly lists the disposed clauses using the forgotten set; in this subsection, we leverage it to design a branching strategy that generates at most one subproblem per resolvent of a clause in Current[\u00b7] and Current[\u00b7] \u222a Previous[\u00b7]."}, {"title": "4.4 Frontier Pruning", "content": "In this subsection, we introduce a mechanism for simplifying a subproblem without loss of optimality which is based on the idea that clauses subsumed by some other known clause are not helpful for deducing unsatisfiability. We start with embedding this notion in the following definition.\nDefinition 8. A frontier is a set of clauses Frontier[F] of an unsatisfiable propositional formula F that do not contain another clause of that formula:\nFrontier [F] := $\\{w \\in F | \\forall w' \\in F : w' \\not\\subset w\\}$.\nThe relations $\\in_F$ and $\\subseteq_F$ are shorthands for membership and inclusion in the frontier:\nw $\\in_F$ F := w $\\in$ Frontier[F],\n$\\Omega \\subseteq_F$ F := $\\Omega$ \\subseteq Frontier [F].\nIf a proof of an UNSAT formula F only uses clauses of Frontier[F], then this proof is called a frontier proof."}, {"title": "4.5 Pruning by Dominance", "content": "The concept of a frontier is helpful for subproblem simplification and, by extension, for pruning subproblems that have already amassed some redundancy, as in Corollary 2. However, we can also use this notion to introduce the dominance relationship between the subproblems which reflects the reasoning of the form \"any proof of subproblem P can be recovered in another subproblem Q that has already been explored.\u201d\nDefinition 9. Let P and P' be the subproblems for an input formula F. Then P' dominates P (P' \\succ P) if all five of the following conditions hold:\n1. The dominated subproblem uses all the axioms that are used by the dominating subproblem: Axioms[P'] \\subseteq Axioms[P], where Axioms[P] = $F_{used}$ \\cup $F_{corr}$ is the union of axioms used in some derivations $F_{used}$, and $F_{corr}$ \\subseteq F is the \u201ccorrecting\u201d set of axioms such that removing them renders the formula satisfiable: $w \\in F_{corr}$ \\implies F \\setminus \\{w\\} is SAT.\n2. The dominating subproblem can derive the clauses that can be derived in the dominated subproblem: Derivable[P'] \\supseteq Derivable[P], where Derivable[\u00b7] is introduced in Eq. (1).\n3. The frontier of the dominating subproblem contains the frontier of the dominated subproblem: Frontier[Known[P']] \\supseteq Frontier[Known[P]].\n4. Any clause forgotten in the dominating subproblem is forgotten in the dominated subproblem Forgotten[P'] \\subseteq Forgotten[P].\n5. The dominating subproblem contains no more resolution steps than the dominated subproblem: #Known[P'] \\le #Known[P].\nNote. If the input formula F is minimally unsatisfiable, the axiom condition trivially holds, as in this case all axioms must be used in a proof."}, {"title": "4.6 Lower Bounding the Proof Length with UNSAT Clause Subsets", "content": "To complete the definition of the branch-and-bound procedure of Algorithm 1, we need to specify a valid subroutine for deriving proof length lower bounds. We start this by restating the lower bound on the proof length of a minimally unsatisfiable formula from Peitl and Szeider (2021):\nLemma 3 (Lemma 4, Peitl and Szeider (2021)). Suppose that F is a minimally unsatisfiable formula (i.e., excluding any clause from F makes it satisfiable). Then any proof of F has at least 2#F \u2013 1 clauses: all #F formula clauses and at least #F \u2013 1 derived clauses.\nThe key idea of our bounding approach is to generalize this bound to arbitrary formulas. The next lemma presents the resulting expression; the proof can be found in Appendix A.\nLemma 4. Any compatible proof of a subproblem P derives at least\n$\\min\\{#S-1 | S \\subseteq_F Known[P],S is UNSAT\\}$\nclauses not present in P.\nThis idea can be strengthened using Corollary 2 to only consider clause subsets S that include all unused clauses:\nLemma 5. Let P be a subproblem and U $\\subseteq_F$ Known[P] be the set of clauses that have not been used as a premise of a resolution step. Consider a compatible proof L that does not use all of the clauses from U. Then there is another subproblem P' with a compatible proof L' having fewer clauses than L.\nWe can use the same reasoning to bound the number of axioms used in the proof, as any proof has to introduce an unsatisfiable subset of the input formula, and the cardinality of the smallest such set is a valid lower bound on the used axioms. We first define the problem of finding the smallest minimal unsatisfiable subset as follows:\nDefinition 10. Suppose that F is an UNSAT formula and U $\\subseteq$ F is the set of fixed clauses. Then the smallest minimal unsatisfiable subset is defined as the set that has the smallest cardinality among the unsatisfiable subsets of F containing U as a subset:\nSMUS(F; U) := arg $\\min\\{#S | U \\subseteq S \\subseteq F, S is UNSAT\\}$.\nNote. As soon as U $\\subseteq_F$ F, we can assume without loss of generality that any MUS of F can be transformed to a MUS of Frontier[F] without increasing the cardinality; in particular, under that assumption, we have SMUS(F; U) = SMUS(Frontier[F]; U)."}, {"title": "5. Experimental Evaluation", "content": "As our approach can be seen as both the procedure that eventually discovers the shortest proof and as an anytime optimization algorithm operating on resolution proofs, we are able to put forward two distinct experimental hypotheses for each of those viewpoints as follows:\n\u2022 Our approach leverages the layer list representation to reduce the time to arrive at the shortest proofs.\n\u2022 Our approach can enumerate the sets of implied clauses to give enough information to CaDiCaL to discover shorter proofs.\nIn this section, we conduct an extensive empirical evaluation of our approach addressing both our hypotheses: we compare the produced proof length against CaDiCaL on competition formulas and the time to optimality against the baseline approach from Peitl and Szeider (2021) on small, synthetic formulas. Our evaluation supports both hypotheses: for the smaller formulas, our approach is capable of discovering optimal proofs faster (by orders of magnitude in many cases), whereas, for more realistic formulas, our approach discovers substantially shorter proofs than CaDiCaL can discover on its own. An important caveat here is that SAT solvers are designed to produce faster\u2014but not necessarily shorter\u2014 proofs of unsatisfiability; while these two quantities are closely related, shorter proofs do not automatically imply lower runtime."}, {"title": "5.1 Algorithm Configuration", "content": "Aside from the design choices described in Section 4, we have to choose the heuristics for the following algorithm components:"}, {"title": "5.2 Dataset Description", "content": "We run our evaluation on two collections of UNSAT formulas available in Online Appendix 2:\n\u2022 Synthetic instances are the formula obtained from some procedure with input parameters influencing the formula size. Random 3-CNFs are one example, as we can specify both the number of clauses and the number of variables upfront."}, {"title": "5.3 Reference Proofs", "content": "We start with discussing the methodology we used for extracting the resolution proofs from a SAT solver and measuring their lengths. Similarly to the Complete procedure implementation from Section 4.2, we use CaDiCaL 2.0 solver with UNSAT mode enabled. We also request the solver to produce the proofs in LRAT format; the choice of the proof format was dictated by the fact that it contains not only derived clauses but also the clauses used during the unit propagation, which is essential for tracing the resolution sequence leading to a given learned clause."}, {"title": "5.4 Resolution Number Computation", "content": "We start the evaluation of our approach by reproducing the procedure for computing the m-th resolution hardness number, which is defined by Peitl and Szeider (2021) as the largest number of clauses necessary to prove the unsatisfiability of a formula with m clauses. In our notation, this can be formulated as $h_m := \\max_{F:#F=m} \\min\\{#R|R\\in Proofs[F]\\}$.\nThe approach from Peitl and Szeider (2021) improves upon the na\u00efve application of the $h_m$ definition by:"}, {"title": "5.5 Evaluation on Synthetic Formulas", "content": "We start by discussing the instances depending on a single parameter, namely, the pigeonhole formulas, parity formulas, and ordering principle formulas. Tables 2, 3, 4, and 5 compare the proof lengths produced on these formulas by CaDiCaL with the proofs we have discovered with our approach in length-focused configuration, highlighting that even for these well-known formulas there is some room for improvement.\nAmong the other synthetic formulas, the only classes that have been solved to optimality are saturated MUSes and random 3-CNFs. We thus proceed to compare the performance of our approach on these instances against the approach by Peitl and Szeider (2021). To this end, we compare (a) the sets of instances solved by either approach and (b) the time it took both approaches to solve an instance to optimality within the time limit."}, {"title": "5.6 Evaluation on Competition Formulas", "content": "Finally, we evaluate the performance of our approach on the UNSAT instances from SAT Competition 2002; we use the length-focused version of the approach with several changes:\n\u2022 We disable the randomization in order to evaluate how well our procedure is able to navigate the proof space without artificially diversifying it.\n\u2022 We only consider the top 10 clauses after applying the ordering criterion in branching, as it is unreasonable to expect the completeness of this procedure.\n\u2022 We disable the pruning of the subproblems, as the lower-bound pruning is several orders of magnitude away from the discovered proof lengths at best and times out without any meaningful bound at worst, whereas the dominance pruning does not yield any substantial advantage on larger formulas.\n\u2022 We limit the queue size to 104, discarding the subproblems with the largest \u201ctrivial\" lower bound (length of the shortest clause), and earlier subproblems in case of ties."}, {"title": "6. Conclusions", "content": "We propose a novel approach for constructing the shortest resolution proof of a given unsatisfiable propositional formula. In its anytime form, this approach can also discover increasingly tight upper bounds (shorter proofs) and lower bounds (higher under-estimates of the proof length). The proposed approach has derived substantially shorter proofs on"}, {"title": "Appendix A. Proofs", "content": "Proof of Lemma 1. Observe that\nKnown $[P_j]$ = Known[P] $\\cup \\{w_j\\}$\nand\nKnown$[P_{commit}]$ = Known[P].\nSuppose that L is a compatible proof of P that starts with the clauses from Known[P]; the remainder of the proof depends on whether L uses any $w_j$ clauses.\nIf no such clauses are produced in L, then L is also a compatible proof for $P_{commit}$, because extending the forgotten set does not impact any further decisions. However, Known$[P_{commit}]$ only differs from Known [P] by pushing some of the clauses \u201cbackward\u201d. As some prefix of L agrees with P, it must also agree with $P_{commit}$.\nOtherwise, let $w_j$ be the clause used in L with the smallest index j; by take-it-or-leave-it property, that means that the clauses $w_1,...,w_{j-1}$ are not used in the proof. Then $L'$ is a compatible proof of $P_j$, as it starts with the same prefix (up to the current layer) and does not use clauses from the set $\\{w_1,...,w_{j-1},w_j\\}$, which is exactly the definition of $P_j$.\nProof of Theorem 3. Let $(Q_j = L_j \\land R_j)_1^k$ be the suffix proof of F following the introduction of axioms. We describe how to construct a proof $(Q'_j = L'_j \\land R'_j)_1^k$ of Frontier[F] such that $Q'_j \\subseteq Q_j$. As the last clause $Q_k$ of the original proof is empty, so is the last clause $Q'_k$ of the frontier proof.\nGiven a clause $L_j$ of the original proof, let $U_j \\subseteq L_j$ be a clause from the frontier proof included in the corresponding premise of the original proof. More specifically, $U_j \\in_F F$ if $L_j \\in F$ and $U_j = Q'$, if $U_j = Q'_l$ for l < j. Similarly, let $V_j \\subseteq R_j$ be a corresponding clause for another premise of the same step. (Note that this definition only depends on the clauses from the original formula and earlier derivation steps, which leads to a proof by induction.)\nSuppose that the pivot literal is present in both premises $U_j$ and $V_j$; in that case, any literal in $U_j \\land V_j$ is contained either in $U_j \\subseteq L_j$ or in $V_j \\subseteq R_j$, meaning that $U_j \\land V_j \\subseteq L_j \\land R_j = Q_j$. Thus, in that case setting $(L'_j, R'_j) = (U_j, V_j)$ is sufficient to ensure $Q'_j \\subseteq Q_j$.\nOn the other hand, if the pivot literal is missing in (without loss of generality) $U_j$, deriving $Q'_j = U_j$ is sufficient to ensure $Q'_j \\subseteq Q_j$. If $U_j \\in_F F$, then we can introduce it with a bogus derivation $U_j \\land U_j = U_j$. Otherwise, $U_j$ has already been derived by the j-th step by definition of U-clauses, meaning that we can copy this derivation into the j-th step.\nProof of Lemma 2. Consider a compatible proof $L'$ of $P'$; we show that there is a compatible proof L of P that delivers a proof at most as long as $L'$. We assume that the first k layers are fixed by the Previous[P'] and Current[P'] sets. Suppose that the Next[P'] corresponds to the k'-th layer of $L'$; we start the construction by adding all the missing clauses from that layer into the k-th layer of L, which is possible by Definition 9.2."}, {"title": "Appendix B. Algorithm Configuration Experiments", "content": "To generate the dataset for configuring the heuristic parameters, we use the same procedure as used in the main text for the synthetic dataset with fewer generator runs and only include random 3-CNFs, subset cardinality, and graph coloring formulas. We do this to facilitate the algorithm parameter tuning without overfitting the collection used to report the results.\nAll the experiments in this section are executed on the same hardware as the experiments in the main text but with lower resource limits: 5 minutes and 12 GB of RAM per run. The only exception is Section B.4, as those experiments were run with 1-hour time limits; we had to raise the limits for this set of experiments since the 5-minute runs did not show any meaningful difference between the dominance cache clean-up strategies.\nDuring our experiments, we observed that the proof length exhibits little variance with respect to the algorithm configuration. Our explanation of this is that the instances in the validation set are simple enough to accommodate many completion calls, with one of them being likely to yield a good proof regardless of the algorithm configuration. Therefore, to simplify our analysis, we only tune the algorithm for the time-focused runs and use the same configuration for length-focused runs except for the completion procedure (CaDiCaL) and clause ordering (ascending length).\nThroughout the analysis, we evaluate different configurations based on the virtual best time, which is defined for any instance from the validation sample as the fastest time to"}]}