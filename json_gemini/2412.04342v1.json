{"title": "Retrieval-Augmented Machine Translation with Unstructured Knowledge", "authors": ["Jiaan Wang", "Fandong Meng", "Yingxue Zhang", "Jie Zhou"], "abstract": "Retrieval-augmented generation (RAG) introduces additional information to enhance large language models (LLMs). In machine translation (MT), previous work typically retrieves in-context examples from paired MT corpora, or domain-specific knowledge from knowledge graphs, to enhance models' MT ability. However, a large amount of world knowledge is organized in unstructured documents, and might not be fully paired across different languages. In this paper, we study retrieval-augmented MT using unstructured documents. Specifically, we build RAGtrans, the first benchmark to train and evaluate LLMs' retrieval-augmented MT ability. RAGtrans contains 79K MT samples collected via GPT-40 and human translators. Besides, documents from different languages are also provided to supply the knowledge to these samples. Based on RAGtrans, we further propose a multi-task training method to teach LLMs how to use information from multilingual documents during their translation. The method uses existing multilingual corpora to create auxiliary training objectives without additional labeling requirements. Extensive experiments show that the method improves LLMs by 1.58~3.09 BLEU and 1.00~2.03 COMET scores.", "sections": [{"title": "1 Introduction", "content": "Retrieval-augmented generation (RAG) has grown into a practical paradigm in the development of large language models (LLMs). With the help of retrieved information, LLMs could generate more accurate and knowledge-enrich responses (Li et al., 2022; Gao et al., 2023).\nPrevious work brought RAG into machine translation (MT), and could be mainly classified into the following two streams: (1) Retrieving in-context examples (also known as \u201ctranslation memory\u201d): for a source sentence, a few studies retrieve the relevant paired sentences from bilingual corpora to enhance models' translation (Zhang et al., 2018; Bulte and Tezcan, 2019; He et al., 2021; Hoang et al., 2023). Further, Cai et al. (2021) relax the bilingualism limitation, and try to directly retrieve similar target-language translations to enhance models. (2) Retrieving knowledge triplets: the others retrieve relevant information from knowledge graphs to let the models know domain or cultural knowledge w.r.t. the source sentences (Conia et al., 2024; Chen et al., 2024b). Despite the great success that has been achieved, a large amount of world knowledge is organized in unstructured documents, and might not be fully paired across different languages. This unstructured knowledge is neglected by previous work. For example, Wikipedia is the largest publicly available wiki (Vi\u00e9gas et al., 2004), serving as an encyclopedia of world knowledge. Most of its information is listed in documents. Besides, for a piece of specific knowledge, Wikipedia does not always provide it in all languages. Though multilingual information of some general knowledge is provided, their content might be differentiated among different languages (Perez-Beltrachini and Lapata, 2021).\nIn this paper, we study retrieval-augmented MT using unstructured documents. Since we are the first to study this topic and previous datasets do not support the research, we first build a benchmark dataset, named RAGtrans. In detail, RAGtrans is collected based on Wikipedia with three key features: (i) Knowledge-intensive sentences: RAGtrans selects 79K English sentences from Wikipedia as the source sentences, which generally come from the lead paragraphs of different Wikipedia pages, containing knowledge-intensive semantics. Thus, understanding these source sentences tends to require additional knowledge. (ii) Useful relevant documents: To achieve retrieval-"}, {"title": "2 RAGtrans", "content": "In this section, we first discuss how we select English source sentences and their relevant documents from Wikipedia (\u00a7 2.1). Then, we introduce the details of the data translation via GPT-40 and human annotators (\u00a7 2.2). Finally, we give statistical analyses of RAGtrans (\u00a7 2.3), and provide the details of benchmark settings (\u00a7 2.4)."}, {"title": "2.1 Data Selection", "content": "When deciding the source sentences we focus on in this work, there are three requirements that should be met: (1) The source sentences should involve knowledge-intensive semantics, otherwise, they might be trivial to translate and do not need the help of additional knowledge. (2) It should be convenient to collect their relevant documents from existing resources, otherwise, annotating relevant documents is labor-intensive. (3) It should also be possible to collect relevant documents in other languages. This is because world knowledge is recorded in multilingual form. If we restrict the language of the retrieved documents, the practicality of retrieval-augment MT models will decrease.\nAfter carefully comparing existing open-source resources, we decide to select both source sentences and relevant documents from Wikipedia2.\nFormally, we denote an English document on a Wikipedia page as $D^{en} = \\{p^{en}_1, p^{en}_2, ..., p^{en}_D\\}$, where $p^{en}_i$ indicates the i-th paragraph in $D^{en}$. Inspired by Perez-Beltrachini and Lapata (2021), the lead paragraph of a Wikipedia page contains knowledge-intensive semantics and can stand as the summary of the whole document. Thus, we use $p^{en}_1$ from each randomly selected Wikipedia page as a source sentence to meet the requirement (1). In view of the paragraphs on the same Wikipedia page are generally highly related, to meet the requirement (2) for $p^{en}_1$, we randomly select its consecutive paragraphs, i.e., $D^{en} \\backslash \\{p^{en}_1\\}$, as its relevant document. To further collect relevant documents beyond English, i.e., the requirement (3), we exploit the parallel documents in other languages of $D^{en}$ provided by Wikipedia. In this work, we choose Chinese, German, French and Czech, and denote the corresponding parallel documents as $D^{zh}, D^{de}, D^{fr}$ and $D^{cs}$, respectively. Given this, the consecutive paragraphs from $D^l \\backslash \\{p^l_1\\}$ $(l \\in \\{zh, de, fr, cs\\})$ form as the relevant document in other languages.\nTo ensure robustness, for a small number of source sentences, we randomly select documents from the whole Wikipedia to serve as noisy documents. After the above process, we obtain 79K English source sentences, which are further split into training, validation and testing sets with 74.5K, 2.5K and 2K sentences. For each sentence, a (relevant or noisy) document in English, Chinese, German, French or Czech is also provided."}, {"title": "2.2 Translation Annotation", "content": "For a given source sentence, we next collect its translation in the target language conditioned on the corresponding document. In this work, we focus on English-to-Chinese translation, and we collect the Chinese translation for the 79K English sentences. Since the source sentences are lead paragraphs of Wikipedia's English pages (i.e., $p^{en}_1$), one straightforward way is to directly use the counterparts of the Chinese parallel Wikipedia pages (i.e., $p^{zh}_1$) as the translation. However, in Wikipedia, neither the parallel documents nor their lead paragraphs are fully paired across different languages (Perez-"}, {"title": "2.3 Data Statistics", "content": "shows the number of samples w.r.t. different types (relevant or noisy) and different languages"}, {"title": "2.4 Benchmark Settings", "content": "We design three benchmark settings to evaluate the retrieval-augmented MT models: (1) Golden Evaluation: For each testing sample $(s, D^{en}, D^{zh}, D^{de}, t)$, we give the source sentence (s) and a golden relevant document ($D^{en}/D^{zh}/D^{de}$) to the model, and evaluate models' translation. (2) Robustness Evaluation: We give s and an irrelevant document (randomly selected from Wikipedia) to the model, and evaluate its translation. (3) Full Wiki Evaluation: This setting equips the MT models with a retriever, and truly tests models' retrieval-augment MT ability. For a given s, a retriever should first retrieve"}, {"title": "3 Multi-Task Training", "content": "To further enhance LLMs' retrieval-augmented MT ability and the ability to utilize multilingual knowledge, we propose a multi-task training method, named CSC, which involves three designed training objectives, i.e., Cross-lingual information completion, Self-knowledge-enhanced translation and Cross-lingual relevance discrimination. In this section, we first introduce these objectives (\u00a7 3.1) and then discuss how to create their training samples from existing corpora (\u00a7 3.2)."}, {"title": "3.1 Multi-Task Training Objectives", "content": "When developing a retrieval-augment MT model in real applications, it is possible to retrieve information from multilingual knowledge bases for a given source sentence. As a result, the model might receive multiple documents from various languages, extending beyond both the source and target languages. In such a situation, the challenge of effectively refining knowledge from these multilingual documents becomes increasingly significant. To this end, we design three training objectives:\n(1) Cross-lingual information completion. Given a multilingual document mix whose paragraphs might be in different languages, and its truncated summary $\\hat{y}$ in one language (e.g., English), we require LLMs to expand $\\hat{y}$ to a complete summary y. Formally, this objective can be formulated as $\\Theta(y|d_{mix}, \\hat{y})$, where $\\Theta$ denotes the LLMs.\n(2) Self-knowledge-enhanced translation. As revealed by recent RAG studies (Wang et al., 2023b; Liu et al., 2024; Asai et al., 2024), RAG models can achieve better performance with the help of their own knowledge. Inspired by this idea, we design self-knowledge-enhanced translation. Specifically, given a source sentence s, LLMs first generate its relevant document $d^l$ in a specific language $l \\in \\{en, zh, de, fr, cs\\}$ and then incorporate the document to translate s to t, denoted as $\\Theta(t|d^l|s)$.\n(3) Cross-lingual relevance discrimination. Given that the retrieved documents may be in various languages, a crucial capability is to assess the relevance between two texts in different languages. To this end, given a document pair $(d^{l_1}, d^{l_2})$ $(l_1 \\neq l_2)$, $l_1$ and $l_2$ denote the languages of the documents, the model is required to generate the rele-"}, {"title": "3.2 Multi-Task Training Samples", "content": "To create the samples for these training objectives, a principle is to reformulate existing corpora instead of labeling new data to ensure scalability.\n(1) Cross-lingual information completion. To create the multilingual document mix and its summary y, we reformulate the Wikipedia corpus. As revealed by Perez-Beltrachini and Lapata (2021), the lead paragraph in a Wikipedia page could be regarded as its summary. Given this, for an English Wikipedia page $D^{en}$, we extract its lead paragraph (i.e., $p^{en}_1$) as y, and randomly truncate y to $\\hat{y}$. We next construct $d_{mix}$ from the remaining paragraphs $D^{en} = \\{p^{en}_{i>2}\\}$, and the parallel counterparts in other languages, i.e., $D^{zh}, D^{de}, D^{fr}$ and $D^{cs}$ in this work. Since there might be redundant information across parallel paragraphs, we use MMR algorithm (Carbonell and Goldstein, 1998) to select paragraphs from these multilingual paragraphs, i.e., $\\cup_i D^l$, to form $d_{mix}$. MMR is a statistical algorithm that iteratively selects key paragraphs from the given document, at each selection step, it evaluates the relevance and redundancy of the unselected paragraphs in relation to the selected ones to determine which paragraph to select in that step.\n(2) Self-knowledge-enhanced translation. We reformulate previous multilingual MT corpora to create samples. In detail, we use TED talk corpus (Aharoni et al., 2019), where each sentence is provided with multilingual parallel sentences. For an English sentence sen, we input the sentence or its parallel sentences in other languages (i.e., $s^l$) to a LLM $\\Theta$, and prompt $\\Theta$ to generate its relevant knowledge in the corresponding languages, i.e., $\\hat{d}^l$. In this way, $\\hat{d}^l$ could be used as a relevant document to translate sen to other languages.\n(3) Cross-lingual relevance discrimination. We reformulate the parallel Wikipedia documents to create the samples. Intuitively, randomly selected paragraphs from two parallel documents are relevant; while those from different documents are irrelevant. In this way, we create the document pair and the corresponding boolean relevance."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experimental Setup", "content": "Metrics. Following previous work, we adopt BLEU (Papineni et al., 2002) and reference-based"}, {"title": "5 Related Work", "content": "To leverage additional knowledge to enhance MT performance, previous literature typically explores paired sentences (also known as \u201ctranslation memory\") or structured knowledge graphs as the knowledge sources: (1) Paired Sentences: Zhang et al. (2018) utilize a search engine to retrieve sentence pairs whose source sides are similar with the input sentence. Bulte and Tezcan (2019) further design a fuzzy retriever to enhance the model performance. He et al. (2021) design a fast and accurate method to improve the robustness of pairsentence-enhanced MT models. Cai et al. (2021) relax the bilingualism limitation in retrieving paired sentences, and they try to directly retrieve similar target-language sentences to enhance MT models. (2) Knowledge Graphs: A few studies also"}, {"title": "6 Conclusion", "content": "In this paper, we explore the retrieval-augmented MT with unstructured knowledge. To this end, we build RAGtrans dataset with 79K retrieval-augment MT samples to train and evaluate LLMs' retrievalaugmented MT ability. Further, we propose CSC multi-task training method with three designed training objectives to teach LLMs to leverage multilingual knowledge in retrieval-augmented MT. Extensive experiments demonstrate the usability of RAGtrans and the effectiveness of CSC."}, {"title": "Limitations", "content": "While we show LLMs' retrieval-augmented MT ability and the effectiveness of CSC multi-task training method, there are some limitations worth noting: (1) We focus on English-to-Chinese translation in this work, and future work could extend the dataset and the method to other translation directions. (2) For multilingual knowledge bases, we use Wikipedia in some specific languages (e.g., Chinese, English, German, French, and Czech). Future work could extend the multilingual sources to other languages or other sources. (3) During data collection of RAGtrans, a CoT prompt is used in the GPT-40 translation (c.f. Figure 1). However, in the SFT process, we do not use the CoT prompt to train LLMs, and future work could explore the effect of CoT in retrieval-augmented MT."}, {"title": "Ethical Considerations", "content": "We discuss the main ethical considerations of RAGtrans as follows: (1) Licenses. The source sentences and documents are derived from Wikipedia, whose texts are under CC BY-SA and GFDL licenses. We will release the RAGtrans dataset under CC-BY-SA 4.0 license. (2) Compensation. During"}, {"title": "A Details of GPT-40 translation", "content": "Complete Prompt. We provide the system prompt as follows: \u201cYou are a professional translator, and your task is to translate a given input sentence from English to Chinese. In addition to the input sentence, you will be provided with a document that may contain relevant information to aid in the translation. However, be aware that some documents may contain irrelevant or noisy information\u201d. An example of user prompt and model response is shown in Figure 3, where both a (French) document and an English source sentence are provided in the user prompt. We also define a 5-point rating breakdown to align the scoring value between GPT-4o and humans. In the model response, GPT-40 first judges the relevance between the given document and the source sentence, and then provides the corresponding translation.\nQuality Analysis. To figure out the quality of GPT-40 translations, we calculate the reference-free CometKiwi score between the source English sentences and GPT-40 translations. As a result, the average score is 84.48, indicating high translation quality (Rei et al., 2022).\nOther Details. The version of GPT-40 used in this work is GPT-4o-2024-08-06. When calling the official APIs, we set the temperature to 0.1, and set default values for other hyper-parameters."}, {"title": "B Implementation Details", "content": "SFT prompt. The system prompt in SFT is the same as the GPT-40 translator (c.f. Appendix A). The user prompt in SFT is provided as follows: \u201c<document>[doc]</document><input sentence>[sent]</input sentence>\u201d, where <document>, </document>,<input sentence> and </input sentence> are special tokens to indicate the boundaries of the given document (denoted as \u201c[doc]\u201d) and the source sentence (\u201c[sent]\u201d)."}, {"title": "C Scalability of CSC", "content": "As we demonstrate the effectiveness of CSC multi-task training method in experiments, we wonder the upper limit of the improvement brought by"}, {"title": "D Details of Full Wiki Testing", "content": "Retriever. For BM25 retriever, we use the implementation of elasticsearch12 toolkit to retrieve top-3 documents for each source sentence. For BGEm3 retriever, we first use BGE-m3 sentence embedding model13 to calculate the embedding of all documents in knowledge sources, and then use the embedding of source sentence to retrieve top-3 relevant documents via FAISS (Johnson et al., 2019).\nKnowledge Sources. We use Wikipedia dumps (20241001 version) as the knowledge sources, and leverage wikiextractor14 toolkit to extract articles from Wikipedia dumps. Following Karpukhin et al. (2020), we split each article into multiple, disjoint text blocks of 100 words as passages, serving as our basic retrieval units. In the full Wiki evaluation, we build the knowledge sources based on English, Chinese, German, French, Czech, Russian, Korean and Japanese Wikipedia dumps, resulting in tens of millions of retrieval units."}]}