{"title": "Towards Predicting the Success of Transfer-based Attacks by Quantifying Shared Feature Representations", "authors": ["Ashley S. Dale", "Mei Qiu", "Foo Bin Che", "Thomas Bsaibes", "Lauren Christopher", "Paul Salama"], "abstract": "Much effort has been made to explain and improve the success of transfer-based attacks (TBA) on black-box computer vision models. This work provides the first attempt at a priori prediction of attack success by identifying the presence of vulnerable features within target models. Recent work by Chen and Liu (2024) proposed the manifold attack model, a unifying framework proposing that successful TBA exist in a common manifold space. Our work experimentally tests the common manifold space hypothesis by a new methodology: first, projecting feature vectors from surrogate and target feature extractors trained on ImageNet onto the same low-dimensional manifold; second, quantifying any observed structure similarities on the manifold; and finally, by relating these observed similarities to the success of the TBA. We find that shared feature representation moderately correlates with increased success of TBA (p = 0.56). This method may be used to predict whether an attack will transfer without information of the model weights, training, architecture or details of the attack. The results confirm the presence of shared feature representations between two feature extractors of different sizes and complexities, and demonstrate the utility of datasets from different target domains as test signals for interpreting black-box feature representations.", "sections": [{"title": "1. Introduction", "content": "A transfer-based attack (TBA) uses a surrogate model to generate attacks, which are then transferred to a target model [49]. These attacks are leveraged through the transfer of gradients from the surrogate to the target [59], or through query methods which rely on responses from the target to inputs fine-tuned on the surrogate [40]. The primary benefit of this approach is the ability to target black-box models [7], as TBA eliminates the need for information about the target model's gradients and/or weights. Much effort has been made to improve the success of TBA, with continuous contributions of new methodologies [12, 14, 23, 39, 73] and evaluation approaches [38].\nThis work is the first to ask \u201cis it possible to predict the success of a transfer-based attack on a black box model without any a priori knowledge of the attack?\u201d Answering this question is challenging, but valuable as it allows the identification of potential model vulnerabilities. At this time, the only other work (to our knowledge) seeking to predict the success of black box attacks was carried out by Puccetti et al. [50] and also requires information about the nature of the attack. We are the first (to our knowledge) to formulate the question with the stated constraints on a priori information, and the first to answer in the affirmative. Our attempt to answer this question is presented through the form of a new methodology, as visualized in Figure 1 and applied to a toy example.\nThe results presented here challenge the TBA community to better identify and quantify feature representations which make models vulnerable to transfer-based attacks. The discussion section presents several suggestions for future work, as the method presented here promises to allow access to new research directions, and ultimately yielded more questions than answers.\nMain Contributions\nOur main contributions lie in three key areas:\nFirst, because this work is the first to predict transfer-based attack success using minimal information, we introduce criteria for evaluating methodologies that attempt to accomplish this task. These criteria establish a new research direction, enabling the identification of vulnerable models without knowledge of the attacks or model weights."}, {"title": "2. Background", "content": "2.1. Shared Feature Representation through Cross Manifold Embeddings\nTo answer the question of predicting transfer-based attack (TBA) success on a black-box model, we propose that identifying shared feature representations between the target and surrogate models is meaningful for evaluating TBA success. The main challenge of this work is developing a valid method which identifies these features in a black-box context without knowledge of model weights, gradients, training parameters, or architecture. We term the aggregate of feature representations produced by the model's feature extraction backbone in vector form as the model's feature space, differentiating from the model's latent space as encoded by the weights of the feature extraction backbone, where the weights are inaccessible in a black-box model study.\nOur primary hypothesis is that a shared low-dimensional feature space between two models is identifiable using dimensionality reduction methods on samples of the model's feature space. A shared low-dimensional manifold will have a quantifiable shared dimensionality, while disparate manifolds will be or"}, {"title": "2.2. Related Works", "content": "Theory of transfer-based attacks\nVarious explanations for the success of transfer-based attacks have been presented [10, 23, 51]. Most recently, the manifold attack model [11] unified previous explanations by formalizing the concept of shared model feature spaces: for a transfer-based attack to be successful, the adversarial examples must exist in a shared lower-dimensional manifold. The experimental results presented in [11] are limited to demonstrations of the proofs; in this work, we extend this main idea to popular feature extraction backbones used for computer vision tasks.\nShared lower dimensional manifold assumption\nThe strong lottery ticket hypothesis states that multiple lower-dimensional solutions to the same problem can exist within the same model architecture [17]. This motivates techniques such as model weight quantization [78], and model weight pruning and knowledge distillation [31]. The latter two techniques are dimensionality reductions of the model latent space, which naturally extend to methods such as PCA [26], T-SNE [2], and UMAP [1] performed on samples from high dimensional latent spaces to reduce the dimensionality. For linearly separable data, PCA is the uncontested standard. For non-linear spaces, UMAP's original algorithm suggests that distance metrics on UMAP embeddings are meaningful [43], as it attempted to approximate the original high-dimensional space. However, this understanding was later revised [18], and UMAP can now be interpreted as a refinement of the kNN graph [18]. We choose UMAP for this study, as the data is non-linear and the analysis of the manifold requires only the justified use of a distance measure."}, {"title": "Evaluation of Shared Embeddings", "content": "For those cases where the low-dimensional embedding $f(X) \\neq f(X')$, a quantification of the difference between the embeddings is desirable. A geometric distance measure may be used to determine whether the target embedding $f(X')$ and surrogate embedding $f(X)$ overlap on a global scale.\nIn this work we utilize the normalized symmetric Hausdorff distance [64], which is a geometric measure of the scaled maximum distance possible between points of two datasets, with smaller distances implying greater spatial overlap between two sets of points $D_1$ and $D_2$. The symmetric Hausdorff distance is obtained using $H(D_1, D_2) = max{\\hat{H}(D_1, D_2), H(D_2, D_1)}$, where $\\hat{H}(D_1, D_2) = max_{X \\in D_1} {min_{Y \\in D_2} {||X, Y ||}}$ is the directed Hausdorff distance for each point $X \\in D_1$ and $Y \\in D_2$, and $||X, Y ||$ is the Euclidean distance between X and Y [64]. This distance is then normalized by the maximum diagonal of the embedded data so that the maximum distance measurable is 1; a distance of 1 represents the least overlap between two datasets.\nFeature representations in and extracted from a model\nFeature representations within a model are captured by the model weights. In 2014, Zeiler and Fergus found that features are represented hierarchically within the network: early layers contained high frequency components of an image such as textures and edges, and later layers capture low frequency components such as repeating units and objects [77]. The hierarchical feature observation strongly influenced the field of explainable AI by establishing the evaluation of network feature representations in the context of how one layer relates to the next [15, 28, 34, 37, 41, 44, 46, 48, 52, 56, 57, 75, 79], and this intuitive understanding of feature representation in a CNN has persisted without major modification [24, 47, 60].\nHowever, these approaches do not apply to black-box models, where the weights and architecture are not accessible for manipulation. In this work, we leverage the feature vector returned by querying the feature extraction backbone. Although this falls short of a traditional query-based black-box attack, it allows for the search of shared feature representations between models without knowledge of model architecture, weights, and training. Instead of direct inspection of the model weights, the choice of dataset determines which model features are exposed for inspection in the feature vectors returned by the query."}, {"title": "2.3. Criteria for method that predicts TBA Success", "content": "We propose that a predictive method for the success of black-box TBA should meet standards of directionality and sensitivity [19], in addition to being suitable for the problem of attacking black-box models. Accordingly, a good predictive method for TBA success will:\n\u2022 Assume minimal information about the target and surrogate models used for an attack. This requires the method to be agnostic regarding information about training, model weights, gradients, model architectures, etc.\n\u2022 Assume minimal information about the attack. This includes omitting knowledge about how the attack will be performed (e.g. transfer gradient-based or query-based).\n\u2022 Assume minimal information about the problem domain. The method should only require high-level knowledge of a computer vision task, a natural language processing task, etc.\n\u2022 Predict success and failure equally. The method should return only true positives and true negatives, satisfying the principle of directionality.\n\u2022 Appropriately differentiate between strong and weak success for a given attack by being sensitive to changes in the model.\nA method which meets these criteria can be expected to generalize well, and would provide the ability to predict model vulnerabilities to an attack."}, {"title": "3. Experiments", "content": "3.1. Method for Identifying Shared Feature Representations\nThe procedure identifying shared feature representations is depicted in Figure 1 and is summarized as follows:\n1. Select a test dataset that contains the features a practitioner wishes to query from the model.\n2. Select two or more CNN feature extraction backbones (such as ResNet [29], MobileNet [33], etc.) for comparison: one as a surrogate backbone and the other as the target backbone.\n3. Extract a set of feature vectors $D_T$ and $D_S$ from each backbone using the test dataset.\n4. Create a low-dimensional manifold embedding from the feature vectors $D_S$ extracted from the reference backbone using a dimensionality reduction algorithm $f (\u00b7)$.\n5. Project feature vectors $D_T$ extracted from the target backbone onto the same low-dimensional manifold using the dimensionality reduction algorithm $f(\u00b7)$ developed for $D_S$.\n6. Apply an appropriate manifold analysis.\nIn Figure 1, a single dataset is used to sample the latent space manifolds of two feature extractors, resulting in two sets of feature vectors, $D_S$ and $D_T$, which encode the same features differently. The difference in feature encoding is examined by embedding both sets of feature vectors in a single manifold; this manifold is approximated from one of the two sets of feature vectors $X \\in D_S$ and $X' \\in D_T$ via a dimensionality reduction algorithm such as UMAP [43]. Metrics are presented which quantify the overlap of the projections."}, {"title": "3.2. Selection of the test dataset(s)", "content": "Three benchmark datasets were used to probe network performance in different domains, with the implicit assumption that each benchmark has a feature distribution not captured by image instances shared with other datasets [8, 36, 71]. For this work, SI-Score [20], Fashion-MNIST [74], and NWPU-RESISC45 [13] were selected.\nSI-Score [20] is a synthetic dataset with semantic labels designed to test network robustness to object rotation, size, and location. Additionally, objects in SI-Score have been placed on backgrounds which may or may not be commonly found in nature, therefore implicitly testing the inductive bias of a feature extractor. Because the dataset shares the same classes as the original ImageNet dataset used to train the models, there is a strong assumption that the dataset features are present within the model weights without explicitly testing the models using ImageNet.\nThe Fashion-MNIST dataset [74] is a benchmark designed to be as accessible as MNIST [35], but more challenging for object classification tasks. The images were originally 28\u00d728 pixels in size and grayscale, but are resized to \u2248 224 \u00d7 224 pixels to be compatible with the backbone input sizes. Input images are expected to be blurred by the interpolative process, and are therefore dominated by lower frequencies.\nThe NWPU-RESISC45 dataset [13] contains large variations in translation, spatial resolution, view point, object pose, illumination, background, and occlusion. Importantly, the image size is fixed to 256x256 pixels, while the image spatial resolutions vary from 30 m to 0.2 m per pixel. This suggests that there is a broad distribution of frequencies present within this dataset that will stress the models' feature representations at multiple scales. This dataset label space is also completely disjunct from the ImageNet dataset used to train the models, removing any potential intuition regarding feature presence or representation within the model weights."}, {"title": "3.3. Selection of black box models", "content": "The five feature extractor backbones considered in this study demonstrate a progression of approaches in feature extractor design. ResNetv2 [29, 30] and MobileNet [33] use residual blocks and inverted residual blocks, respectively. EfficientNet BO is the result of modifying the MobileNetv2 architecture [58] with the EfficientNet optimization process [65]. The primary differences between Mo"}, {"title": "3.4. Transfer-based Attack Analysis", "content": "A classic Fast Gradient Sign Method (FGSM) attack [25, 45] with the form $x^* = x + \\epsilon \\cdot sign (\\nabla_xJ (\\theta, x, y))$ is used to generate attacks for each model, where x is the original image, $x^*$ is the adversarial image, y is the original label, $\\epsilon$ is the attack strength, $J(\u00b7)$ is the loss, and $\\theta$ signifies the model parameters. Each feature extraction backbone initialized with ImageNet weights was connected to a classification head consisting of a drop out layer, followed by a fully connected layer; the backbone weights were frozen, and only the classification head was trained. Each model was then trained until the training and validation losses converged. The models each achieved an average F1 score of 0.9 \u00b1 0.1 on a held-out test set except for IncepNetv3 [62, 68], which had a maximum F1 score of \u2248 0.6.\nEach model was then attacked using the gradients generated from the FGSM [25] attack with increasing attack strength $\\epsilon$ and evaluated using the F1 score and the average accuracy (AA). The AA for each attack at $\\epsilon$ threshold $\\epsilon = l_x = 8/255 = 0.03$ [38] is also reported. A lower AA value indicates a more successful attack."}, {"title": "4. Results", "content": "In this section, the method of Figure 1 is demonstrated using MobileNet v3 as the target model, and ResNet50 v2 as the surrogate model. Additional results for other surrogate-target model pairs are presented in the Technical Appendix. The results of all surrogate-target model pairs are summarized in the main result shown in Figure 4, which demonstrates the correlation between embedding similarity and attack success."}, {"title": "4.1. Shared feature vector embeddings generated by cross projection", "content": "The cross manifold embeddings of the SI-Score dataset are shown in Figure 1. The Fashion-MNIST and RESISC feature vectors from ResNetv2 50 and MobileNetv3 are shown in Figure 2. When data from the target model clusters tightly on the surrogate manifold projection, only a few neighbors were found in the original surrogate high-dimensional space for the entire set of target feature vectors. This implies that, although every data point was projected successfully (i.e., no NaN values), the high-dimensional feature spaces generated by the target and surrogate models were too disparate to survive the cross projection process. The result is a shared embedding with a Hausdorff distance that approaches H = 1 as fewer neighbors are found. For projections that share many neighbors between the target and surrogate embeddings, the Hausdorff distance approaches zero. This is visualized in Figure 2(f) for RESISC data, with H = 0.22, Figure 2(c) for Fashion-MNIST data with H = 0.12, and Figure 1 for SI-Score with H = 0.09.\nAdditional embeddings are presented in the Technical Appendix for the remaining model and data combinations."}, {"title": "4.2. Application to Transfer-based attacks", "content": "The value of understanding latent space similarity is apparent in the context of transfer-based attacks (TBA). In Figure 3, results for FGSM attacks created by the ResNetv2 surrogate model for the target MobileNetv3 model are shown. The dashed lines represent how the attack performed against the surrogate model for which it was created, and the solid line represents how well the attack transferred to the target model for various strengths. The difference between the dashed line and solid line of a single color represents the change in attack success when applied to the source surrogate model (dashed line) and the target model (solid line).\nA negative correlation is observed, with small Hausdorff distances between embeddings correlating with improved success rate, and Hausdorff distances approaching the maximum correlated with decreased success. This is quantified by the correlation coefficient $\\rho_{H,AA} =  \\frac{E [(H \u2013 \\mu_H) (AA \u2212 \\mu_{AA})]}{(\\sigma_H\\sigma_{AA})} = \u22120.57$ for the set of Hausdorff distances H and the corresponding average accuracy AA. Applying Principal Component Analysis (PCA) [26] to the data in Figure 4 yields eigenvalues [7.13, 0.00]. This indicates that the data variance can be explained by a single component of the PCA projection."}, {"title": "5. Discussion", "content": "These results support the manifold attack theory, where the similarity-or non-similarity-of feature representations motivates vulnerability to transfer-based attacks (TBA) [11]. The correlation observed in Figure 4 is moderate, but present. The following discussion identifies key analysis of the results, and directions for future work.\n5.1. Dimensionality reduction algorithm for generating shared embeddings\nThe best choice of dimensionality reduction algorithm for this method is an open question. The projection of data from one metric space onto another space requires some mathematical assumptions not discussed in detail here, namely the requirement that the spaces must be isometric with a bijection that preserves distances [9]. The dimensionality reduction algorithm for this method should meet these criteria.\nHere, the criteria are assumed to be satisfied in the high-dimensional space of the feature vectors extracted from the CNN backbones, and are supported by empirical results (preservation of some structure during cross embeddings) following the convention of other authors in the field [5, 42, 76]. However, a more rigorous analysis would explicitly determine the Gromov-Hausdorff distance [21, 27] between the various high-dimensional spaces, as well as between UMAP projections, before attempting additional metrics such as the Hausdorff distance.\nDuring implementation, this work resolved differences in dimensionality between the feature spaces of the target and surrogate models by zero-padding the length of the feature vector to the maximum dimensionality of 2048 dimensions. This is justifiable because 1) it preserves all information of the larger-dimensioned feature space, 2) preserves the spatial relationship between values in each feature vector as encoded by the output of various CNN kernels within the feature extraction backbone, and 3) makes use of the same assumption of shared \u201clower-dimensional\" winning lottery ticket as the rest of this work: if both the target model and surrogate model organize information similarly, then the smaller-dimensioned feature vector should contain the same information organized in the same way as the larger-dimensioned feature vector. The zero-padding can be considered to restore higher-dimensions which are unused in the smaller feature vector representation.\nThe alternative to zero padding-truncating feature vectors to a minimum shared dimensionality either by cropping or by enforcing significance in all values of the vector and removing small values-overlooks permutations that preserve spatial relationships, such as cyclical shifts where the shared subspace is in the last 1280 values rather than the first. Compared to truncation, zero-padding may increase distance during the kNN computation, but it will not falsely minimize it.\nImportantly, if the assumption of similar feature organization is incorrect, feature vectors will fail to be neighbors in the kNN embedding of the UMAP algorithm, and the Hausdorff distance will not accurately predict shared feature representations or the success of a transfer-based attack. Our proposed method does not artificially create similar feature representations where none exist, which helps to reduce the likelihood of false positives and ensures that the method adheres to the criteria established earlier in this work.\nFuture work should identify the subspace that minimizes differences between target and surrogate representations to avoid false negatives. A stronger correlation between the cross manifold embeddings and the attack success could well be observed by performing such a subspace alignment between latent spaces with differing dimensions. This approach would maintain the method's validity without introducing forced similarities. Additionally, while UMAP hyperparameters do influence the structure of dimension-reduced embeddings, manifold features remain consistent.\n5.2. Choice of similarity evaluation approach for embeddings\nThe normalized symmetric Hausdorff distance [64] quantifies whether the two data projections $f(X)$ and $f(X')$ are similar on a global scale. This metric fails to consider whether the projections are similar on a local scale. One such measure of local topology is the bottleneck distance [16]; sample calculations of bottleneck distances for MobileNetv3 and ResNetv2 projections are included in the Technical Appendix. Although the bottleneck distance has the desirable property of comparing the stability of data clustering at all scales between the two projections [16], in practice we found the computational burden to outweigh the potential benefits of the method. The bottleneck distances calculated were also not strongly predictive of the success of transfer-based attacks, and had no immediate benefit over the reported Hausdorff distances.\n5.3. Correlation of TBA Success and Shared Feature Representations\nIn Figure 4, a negative correlation between the Hausdorff distance of the shared embeddings and the success of a transfer-based attack is observed. This trend is not linear, and attempts to fit a linear model resulted in an $R^2 = 0.32$ due to the data variance. This variance can be partially attributed to the assumptions imposed on the embeddings, as discussed above in \u00a75.1.\nThe variance may also be attributed to the observed failure of the FGSM attack implemented here to optimally"}, {"title": "6. Conclusion", "content": "A primary contribution of this work is the identification and quantification of similarity in feature representations within black-box models through cross manifold embedding, quantified by the normalized symmetric Hausdorff distance. Previous methods required direct inspection of model parameters [3] and interpretation of weight values [6]. This work avoids such evaluations by placing constraints on the models' latent spaces and the dimensionality reduction techniques used to compare them. Future work should explicitly verify that these constraints are satisfied using methods such as the Gromov-Hausdorff distance [21, 27] or methods yet to be developed.\nHowever, even with unverified assumptions, decreased similarity in feature representation is negatively correlated with increased success of the transfer-based attack by correlation coefficient $\\rho$ = -0.56 for a FGSM attack with fixed attack strength $\\epsilon$ = $l_0$. Because the methodology introduced in this work does not require knowledge of the transfer-based attack, the surrogate model or test model, it becomes possible to predict whether a target-based attack will succeed on a black-box model. The predictive methodology presented here can be further improved by considering the uncertainty introduced by the model prediction heads, leveraging additional attack success evaluation approaches and feature representation similarity, and maximizing the shared semantic information between the latent spaces of target and surrogate models.\nWe encourage the TBA community to develop and improve methodologies that predict the success of transfer-based attacks against black-box models and identify vulnerable feature representations, as outlined in this work. Such methodologies would enable the identification of vulnerable models before deployment, increasing the trustworthiness and reliability of systems that leverage machine learning algorithms."}]}