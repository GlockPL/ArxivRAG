{"title": "LLM-assisted Labeling Function Generation for Semantic Type Detection", "authors": ["Chenjie Li", "Dan Zhang", "Jin Wang"], "abstract": "Detecting semantic types of columns in data lake tables is an important application. A key bottleneck in semantic type detection is the availability of human annotation due to the inherent complexity of data lakes. In this paper, we propose using programmatic weak supervision to assist in annotating the training data for semantic type detection by leveraging labeling functions. One challenge in this process is the difficulty of manually writing labeling functions due to the large volume and low quality of the data lake table datasets. To address this issue, we explore employing Large Language Models (LLMs) for labeling function generation and introduce several prompt engineering strategies for this purpose. We conduct experiments on real-world web table datasets. Based on the initial results, we perform extensive analysis and provide empirical insights and future directions for researchers in this field.", "sections": [{"title": "1 INTRODUCTION", "content": "Semantic type detection is an important task in many data preparation applications, such as data cleaning, schema matching, entity resolution and data discovery [11, 14-16]. Given a table and a set of semantic labels, semantic type detection aims at identifying a type label for each column in the table so that each cell in the column has the same semantic types. This task has attracted significant attention from the database community, and many solutions based on deep learning techniques, especially pre-trained Language Models (PLMs) [7, 11, 16], have been developed to improve overall performance.\nAlthough such PLM-based solutions are effective, they have a high requirement of labeled training instances to perform fine-tuning. Due to the large scale and complex structure of data lake tables, it is rather challenging to acquire high-quality human annotation for semantic type detection [3]. We argue that a weak supervision approach, such as data programming [10], is a good solution to reduce the burdens of training data annotation. In the data programming paradigm, users are asked to design label functions (LF) that provide labels to a subset of data at a much lower"}, {"title": "2 METHODOLOGY", "content": ""}, {"title": "2.1 Overview", "content": "The overall architecture of our proposed pipeline is shown in Figure 1. Similar to previous weak supervision works, it starts with some seed instances that help provide signals to generate LFs. Then we ask LLM to generate LFs based on the provided seed instances. To this end, we conduct few-shot learning by providing some examples of the pairs of instances and LFs generated from them. After obtaining the set of LFs, we use them along with the seed instances to train the label model and obtain the aggregated results. In the current pipeline, we choose the well-known Snorkel [9] framework as the label model. Then given an unlabeled instance, i.e. column from a table, we will feed it to the label model and obtain the labels. Here we could evaluate the quality of the label model by considering the accuracy of labeling a set of unlabeled instances. Finally, we regard the instances obtained from the label model as the training set for an end model."}, {"title": "2.2 Labeling Function Generation with LLM", "content": "Next we introduce how to generate LFs by leveraging the LLMs. We follow previous studies [5, 9] to select the LFs based on the following aspects:\n\u2022 Keyword: This kind of LF assumes that for each given semantic type L, there is a list of common keywords. Once the overlap between the unlabeled column and the list reaches a certain threshold, the column should be given the label L.\n\u2022 Statistical: This kind of LF decides the label of a column based on the pattern of value distributions. The label is assigned if the value distribution of a column satisfies some pre-defined statistical patterns.\n\u2022 Regular Expression: The LF could also be expressed with regular expressions. The label will be assigned if the column values match a provided regular expression.\nThe prompt template for generating is shown in Figure 2. It consists of two components: the system prompt and the user prompt. The system prompt is the general description of the background as well as some necessary instructions for the LLM. For example, our task of semantic type detection needs to specify the input as the given column values and the output as the semantic type of the column. The user prompt aims to provide the necessary contextual information to generate the labeling functions. In our prompt template, we employ the few-shot learning approach and provide some selected examples as demonstrations with the following information: (i) the examples with pairs of column values and ground truth semantic type; (ii) the LF template where the three kinds of LFs introduced above will have different templates; (iii) The question to ask for labeling functions. We randomly selected 5 semantic types and manually wrote a few labeling functions with the 3 kinds of LFs mentioned before. Specifically, within each group, we randomly selected 5 cell values delimited by a special character from that column to be used in the demonstration.\nCompared with previous studies that try to use LLM to generate LFs [4, 19], we improve in the process of prompt construction. Specifically, we include the ground truth of the semantic type label of the given column in the prompt in the above item (i). The reason is that since the task is to generate the labeling function instead of predicting the label, it does not result in the risk of ground truth leakage. Meanwhile, providing the ground truth label could help LLM obtain more information to produce the labeling function as it does not need an additional step to predict the label."}, {"title": "2.3 Stacked Labeling Model", "content": "With the LFs generated by LLMs, the next step is to filter out the LFs with low quality. We use the idea of accuracy and redundancy filter introduced in the previous study [4]. After that, we fit the remaining LFs into the Snorkel label model and aggregate the labeling results. To reach this goal, there is still another challenge to overcome: the space complexity of Snorkel is $O(N * M * d)$, where N is the number of seed instances, M is the number of semantic types, d is the number of remaining LFs. Compared with those in previous studies of data programming [18], the target label set of semantic type detection is up to an order of magnitude larger. As a result, there will also be a much larger number of LFs which will bring significant overhead to the label model.\nIn this work, we use a stacking-based solution to solve this problem. The basic idea is to split the set of semantic type labels into several disjoint groups and train a Snorkel label model for each group. Then the overall computation cost will be significantly reduced. We will also have a routing model stacked on top of the set of label models: when a new unlabeled instance arrives, it sends it to all the label models and decides the label based on the results of all label models. In the current implementation, we choose the label with the highest probability as the result. The next issue to be resolved is how to split the set of labels. Some datasets, such as TURL WikiTables [1], provide the hierarchical structure of the label set which can be directly utilized to create groups. For other general cases, we propose to first get the word embedding of each label and then perform a K-means clustering over the word embeddings, where K target group count."}, {"title": "3 EXPERIMENTS", "content": ""}, {"title": "3.1 Experiment Setup", "content": "We evaluate the proposed framework on widely-used benchmark for semantic type detection. The Viznet dataset 1 is processed in"}, {"title": "3.2 Results", "content": "The step-by-step evaluation results for the Viznet data obtained for the proposed pipeline are shown in Table 1. We directly evaluate the quality of the LLM-generated labeling functions, the output of snorkel inference and final prediction of the end model fine-tuned on the noisy labels obtained from our augmentation process. Although there is a gap in performance between the end model"}, {"title": "3.3 Case Study", "content": "Finally, we conduct a case study to show some specific labeling functions generated by our proposed pipeline in Figure 3. Generally, we observe that the LFs generated by LLM could express reasonable semantics and are comparable with those written by humans. For example, Figure 3a illustrates a keyword-based LF for semantic type ISBN from Viznet dataset. As this column has a simple format (most of the column values are ISBN followed by the product identification number), it provides a very accurate rule to identify columns that belong to the ISBN type. Figure 3b is a statistic-based LF for semantic type year. As shown in the function, LLM could incorporate its internal knowledge with the given semantic type. Specifically, in the return statement it added the frequently mentioned year"}, {"title": "4 CONCLUSION AND FUTURE WORK", "content": "In this paper, we studied the problem of generating labeling functions for the task of semantic type detection. We proposed an end-to-end pipeline that adopted LLM to automatically generate labeling functions for semantic type detection via prompt engineering and train a label model based on Snorkel. We make an extensive set of explorations on the design space and conduct initial experiments on two popular benchmark datasets.\nBased on our initial efforts, we recognize several essential directions for further exploration of this topic. As illustrated by our experimental results, the current explicit labeling functions commonly used in previous data programming studies may not be sufficient for handling more complex tasks like semantic type detection. For this task, as well as related table understanding tasks such as relationship extraction and column population, we need to develop new types of labeling functions that are more powerful yet still explainable. A promising starting point could be building labeling functions based on simple machine learning models, such as logistic regression and decision trees. It is also crucial to improve the scalability of the label models concerning the number of class labels and labeling functions. Our idea of splitting the label space provides a reasonable solution to this problem. It is necessary to explore this approach further by generalizing the problem and developing an efficient algorithm that can identify high-quality splits.\nMoreover, it is beneficial to consider advanced label models developed in recent efforts from the machine learning community as introduced in [17]. Last but not least, although the effectiveness of labeling functions generated in this work is limited, the labeling functions could still provide some useful insights for the semantic labels of columns. So it is also worth investigating how to use the generated labeling function to explain the results of existing solutions for semantic type detection, such as those based on pre-trained language models."}]}