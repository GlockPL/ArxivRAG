{"title": "Simultaneous Computation with Multiple Prioritizations in Multi-Agent Motion Planning", "authors": ["Patrick Scheffe", "Julius Kahle", "Bassam Alrifaee"], "abstract": "Multi-agent path finding (MAPF) in large networks is computationally challenging. An approach for MAPF is prioritized planning (PP), in which agents plan sequentially according to their priority. Albeit a computationally efficient approach for MAPF, the solution quality strongly depends on the prioritization. Most prioritizations rely either on heuristics, which do not generalize well, or iterate to find adequate priorities, which costs computational effort. In this work, we show how agents can compute with multiple prioritizations simultaneously. Our approach is general as it does not rely on domain-specific knowledge. The context of this work is multi-agent motion planning (MAMP) with a receding horizon subject to computation time constraints. MAMP considers the system dynamics in more detail compared to MAPF. In numerical experiments on MAMP, we demonstrate that our approach to prioritization comes close to optimal prioritization and outperforms state-of-the-art methods with only a minor increase in computation time. We show real-time capability in an experiment on a road network with ten vehicles in our Cyber-Physical Mobility Lab.", "sections": [{"title": "Supplementary Materials", "content": "Code github.com/embedded-software-laboratory/p-dmpc\nVideo youtu.be/Mb59zQ3j3s0"}, {"title": "Introduction", "content": ""}, {"title": "1.1 Motivation", "content": "When solving multi-agent planning problems, agents may share objectives or be constrained by each other. Traditional multi-agent path finding (MAPF) is a multi-agent planning problem in which agents move in an environment represented by a graph GM = (VM, \u0415\u043c), consisting of a set of vertices VM, which are locations, and a set of edges EM, which are paths between locations. The objective for each agent i is to move quickly from a start vertex si e VM to a target vertex ti e VM. The constraints for each agent are to avoid collisions with other agents. A collision occurs when two agents i and jat a time k are located at the same vertex v, represented by a tuple (i,j,v,k), or when they traverse the same edge (v \u2013 u) \u0454 \u0190\u043c, represented by a tuple (i, j, v, u, k).\nSolving a MAPF problem optimally is NP-hard (Yu, 2016; Yu & LaValle, 2013). Centralized approaches exploit the problem structure or lazily explore the solution space to increase their computational efficiency (e.g., Barer, Sharon, Stern, & Felner, 2021; Guo & Yu, 2024; Li, Ruml, & Koenig, 2021; Pan, Wang, Bi, Zhang, & Yu, 2024; Sharon, Stern, Felner, & Sturtevant, 2015; Yu, 2020). Prioritized planning (PP), introduced by Erdmann and Lozano-P\u00e9rez (1987), is a computationally more efficient method for MAPF. Instead of solving a MAPF problem optimally, PP divides the problem into multiple subproblems, and each agent solves only its subproblem. Since the subproblems are smaller in size compared to the centralized problem, the computation time is reduced. Additionally, agents can compute the solution in a distributed fashion.\nWhile efficient, PP often produces suboptimal solutions and is not guaranteed to find a solution at all. In the example in Figure 1, out of the six possible prioritizations, only the two in which agent 2 has the lowest priority produce a solution. This is referred to as the incompleteness of PP: while some prioritizations can result in solutions, others may not (Ma, Harabor, Stuckey, Li, & Koenig, 2019). Given an underlying planning method, the prioritization determines the cost of the solution.\nIf we view prioritization and planning as a two-stage optimization, the solution given a prioritization can be seen as a local optimum. In general, for NA agents, there exist up to NA! prioritizations. Let Jp denote the networked cost given a prioritization p. In traditional MAPF, the networked cost is measured in terms of the flowtime, i.e., the sum of travel times of all agents, or the makespan, i.e., the maximum travel time of all agents.\nDefinition 1. The optimal prioritization p* is defined as the prioritization which yields the optimal solution in terms of the networked cost,\n$p^* = \\underset{p}{\\operatorname{argmin}} J_p$.\n(1)\nThe solution given the optimal prioritization is denoted as the global optimum in PP, which notably can be different from the optimal solution to the multi-agent planning prob- lem. A core challenge in PP is finding a prioritization that results in a solution with a low networked cost.\nTo approach the global optimum, traditional approaches rely on heuristics to reduce the networked cost (e.g., Chen et al., 2023; Kloock, Scheffe, Marquardt, et al., 2019; Scheffe,"}, {"title": "1.2 Related Work", "content": "Figure 2 displays the computations of three interacting, sequentially computing agents. The width of a block represents the computation time of each computation.\nWhen selecting the prioritization, heuristics are often consulted. Heuristics aim to im- prove the prioritization mostly for their domain-dependent objective, and are thus less likely to generalize well. The following approaches use objective-based heuristics for prioritization to improve the networked cost. As illustrated in Figure 2a, these approaches solve PP prob- lem using a single prioritization. We first present traditional MAPF approaches (van den Berg & Overmars, 2005; Wu et al., 2020; Zhang, Li, Huang, & Koenig, 2022). In (Wu et al., 2020), the prioritization is determined by the number of possible paths a robot can take to reach its goal. The lower this number is, the higher is a robot's priority. Thereby, the probability for each robot to find a solution is meant to be increased, which directly affects the networked cost. In (van den Berg & Overmars, 2005), robots with longer estimated travel distances receive higher priority to more evenly distribute the travel time among robots. Zhang et al. (2022) proposes a prioritization algorithm based on machine learn- ing, which performs competitively compared to heuristic algorithms. Our previous work (Kloock, Scheffe, Marquardt, et al., 2019) prioritizes agents with the goal of increasing the traffic flow rate at a road intersection through a heuristic based on the remaining time before an agent enters the intersection. In (Yao & Zhang, 2018), automated vehicles approaching an intersection are prioritized using mixed integer programming. Both the prioritization and the vehicle's speed are optimized to minimize the travel time of the vehicles. The algo- rithm in (Chalaki & Malikopoulos, 2022) prioritizes vehicles on intersections using job-shop scheduling and thereby reduces the vehicles' average travel time.\nInstead of finding a good prioritization heuristically, other works optimize the prioriti- zation. As illustrated in Figure 2b, these approaches solve the networked planning problem by exploring multiple prioritizations sequentially. These approaches aim to improve the solution quality by investing computation time. Bennewitz, Burgard, and Thrun (2002) propose a randomized hill-climbing search for finding the optimal prioritization. Beginning at an initial prioritization, priorities of agents are swapped randomly to increase the solution quality. Recomputing the solution in each iteration increases the computation effort. Ma et al. (2019) present an algorithm to lazily explore the space of all possible prioritizations. Whenever a conflict between two agents occurs, both possible prioritizations are added to a"}, {"title": "1.3 Contribution", "content": "In PP, the optimality of the solution depends on the prioritization. To find the optimal prioritization and therefore the global optimum of the PP problem, the set of possible prioritizations and their corresponding solutions to the PP problem needs to be explored. If computation time is limited, such as in real-time applications, the sequential computation of multiple solutions can be intractable. This paper presents an approach that exploits the sequential nature of PP to explore multiple prioritizations simultaneously. Our approach improves the solution quality over sequential computation with a single prioritization while keeping computation time short. We select prioritizations such that (i) we always improve or maintain the solution quality of a previously found prioritization, and (ii) all explored prioritizations are computed simultaneously. The latter requires establishing a Latin square, the general form of a Sudoku puzzle.\nWe illustrate the benefit of our approach in an example with three interacting, sequen- tially computing agents in Figure 2. A block shows the computation time of an agent. Figure 2a shows how approaches based on heuristics solve the PP problem for only a single prioritization. The solution quality strongly depends on the heuristic. Figure 2b shows how the PP problem can be solved multiple times sequentially regarding multiple prioritizations. Even though it can improve solution quality, it prolongs the computation time. In this work, we make use of the fact that in sequential computation the agents idle most of the time: In the example shown in Figure 2a, agents idle two-thirds of the available time. Figure 2c showcases our approach: By utilizing the idle time, we solve the PP problem regarding the three prioritizations from Figure 2b simultaneously.\nApplying our strategy to the example in Figure 1, we always explore a prioritization in which agent 2 has the lowest priority."}, {"title": "1.4 Structure of this Article", "content": "The rest of this article is organized as follows. In Section 2, we formalize time-variant cou- pling and prioritization of agents in a receding horizon planning framework. In Section 3, we formulate requirements for simultaneously computable prioritizations. We further present our algorithm for simultaneous computation, which can both retain prioritizations to uti- lize the predictive nature of receding horizon planning, and explore new prioritizations to increase the likelihood of finding a solution. In particular, the time required for explo- ration spreads across consecutive time steps, which keeps computation time at each time step short. A variant of MAPF is multi-agent motion planning (MAMP), in which the kinodynamic constraints of agents are taken into account during planning. We present our multi-agent motion planner for connected and automated vehicles (CAVs) driving on roads in Section 4. In Section 5, we present a comparison of our approach to state-of-the-art prioritization approaches in numerical experiments with CAVs, and showcase real-time ca- pabilities of our approach in an experiment with ten CAVs in our Cyber-Physical Mobility Lab (CPM Lab)."}, {"title": "2 Preliminaries", "content": "This section provides the background to prioritized receding horizon planning. In PP, agents first receive all predictions from their predecessors, then solve the planning problem, and finally send their predictions to their successors. To determine the predecessors and succes- sors of agents, we couple and prioritize them. The following section introduces our notation and the background on coupling, prioritization, and receding horizon planning."}, {"title": "2.1 Notation", "content": "In this paper, we refer to agents whenever concepts are generally applicable to PP. We assume that states of agents are observable, and therefore we refer to states instead of outputs. The definitions and methods can be transferred to outputs as well, which we omit for brevity. We denote scalars with normal font, vectors with bold lowercase letters, matrices with bold uppercase letters, and sets with calligraphic uppercase letters. For any set S, the cardinality of the set is denoted by |S|. A variable x is marked with a superscript x(i) if it belongs to agent i. The actual value of a variable x at time k is written as x(k), while values predicted for time k + l at time k are written as xk+l|k. A trajectory is denoted by replacing the time argument with (\u00b7) as in x.k.\nWe use graphs as a modeling tool of networked control system (NCS). Every agent is associated with a vertex, so the terms are used synonymously.\nDefinition 2 (Undirected graph). An undirected graph G = (V,E) is a pair of two sets, the set of vertices V = {1, ..., NA} and the set of undirected edges E \u2286 V \u00d7 V. The edge between i and jis denoted by (i \u2013 j).\nDefinition 3 (Directed graph). A directed graph G = (V,\u00bf) is a pair of two sets, the set of vertices V = {1, ..., NA} and the set of directed edges \u2211 \u2286 V \u00d7 V. The edge from i to j is denoted by (i \u2192 j). An oriented graph is a directed graph obtained from an undirected graph by replacing each edge (i \u2013 j) with either (i \u2192 j) or (j \u2192 i)."}, {"title": "2.2 Coupling", "content": "If agents interact via their objectives or constraints, we speak of coupled agents. A coupling graph represents the interaction between agents.\nDefinition 4 (Undirected coupling graph). An undirected coupling graph G(k) = (V,E(k)) is a graph that represents the interaction between agents at time step k. Vertices i e V = {1, ..., NA} represent agents, and edges (i \u2013 j) \u0454 \u0190 represent coupling objectives and constraints between agents.\nThe application in which PP is used determines which coupling objectives and constraints must be considered in an agent's planning problem. For example, in MAPF, coupling constraints are introduced to achieve collision avoidance.\nThe undirected coupling graph can often be determined before planning starts. For ex- ample, in robot applications with a fixed time horizon, the robots' movement range in this time horizon can be used to determine couplings (Scheffe, Xu, & Alrifaee, 2024). Alter- natively, if robots follow fixed paths, the paths' intersections determine couplings between"}, {"title": "2.3 Prioritization", "content": "In PP, we prioritize agents, which results in clear responsibilities considering coupling objec- tives and constraints during planning (Alrifaee, He\u00dfeler, & Abel, 2016; Kuwata, Richards, Schouwenaars, & How, 2007). A fixed or time-invariant prioritization function p: V \u2192 \u039d prioritizes every agent. If p(i) <p(j), then agent i has a higher priority than agent j.\nBy prioritizing, we can orient the edges of an undirected coupling graph to form a directed coupling graph.\nDefinition 5 (Directed coupling graph). A directed coupling graph (k) = (V,\u0108(k)) is an oriented graph obtained from orienting the edges of an undirected coupling graph at time step k. If an edge (i \u2192 j) is directed from agent i to agent j, then agent j is responsible for considering the respective coupling objective and constraint in its planning problem.\nAn edge points towards the vertex with lower priority,\n$(i \\to j) \\in \\hat{\\mathcal{E}} \\leftrightarrow p(i) < p(j) \\land (i - j) \\in \\mathcal{E}$.\n(2)\nThe prioritization function thus constitutes a strict partial order < on the agent set V,\n$i < j \\leftrightarrow p(i) < p(j)$.\n(3)\nThe order is partial, as opposed to total, since a relation exists only for coupled agents. For the strict partial order and thus the orientation of every edge to be well-defined, a valid prioritization function needs to assign pairwise different priorities to vertices that are connected by an edge:\n$p(i) \\neq p(j), \\forall i, j \\in V, \\forall (i - j) \\in \\mathcal{E}, i \\neq j$.\n(4)\nGiven the construction rule in (2), the directed coupling graph $\\hat{\\mathcal{G}}$ resulting from the undi- rected coupling graph G and a valid prioritization function p regarding (4) is a directed acyclic graph (DAG)(Scheffe, Kahle, & Alrifaee, 2023).\nSince in PP, an agent requires its predecessors' plans to consider coupling objectives and constraints, the agents must solve their planning problems in a sequential order. This order, as well as the communication links, are deducible from the directed coupling graph by traversing the graph along its edges."}, {"title": "2.4 Receding Horizon Planning", "content": "A strategy to further reduce computation time in PP is by introducing a fixed time horizon. Instead of solving the MAPF problem from start to end, only a certain number of time steps is considered. The problem is solved repeatedly over the course of time, a practice known as receding horizon planning or online replanning (Li, Tinka, et al., 2021; Scheffe, Pedrosa,"}, {"title": "3 Exploring Multiple Prioritizations Simultaneously", "content": "This section presents the core idea of this paper, which is to improve the solution quality of a given prioritization by exploring multiple other prioritizations simultaneously. We state the requirements for prioritizations with which simultaneous computation is possible in Section 3.1. Building on these requirements, we present the algorithm for selecting a set of prioritizations and simultaneously computing with these prioritizations in Section 3.2. In Section 3.3, we show theoretically that our approach can both retain prioritizations to utilize the predictive nature of receding horizon planning and explore new prioritizations to increase the likelihood of finding a solution."}, {"title": "3.1 Parallelizable Prioritizations", "content": "In this section, we establish the requirements for prioritizations with which simultaneous computation is possible. Our goal of improving the solution quality compared to a given prioritization implies the assumption that an initial valid prioritization according to (4) is given. Finding an initial valid prioritization is simple, e.g., a prioritization that assigns priorities according to unique vertex numbers is valid. Other prioritization algorithms exist (Kuwata et al., 2007; Scheffe et al., 2022; Scheffe, Kahle, & Alrifaee, 2023).\nThe computation order of agents in PP can be structured with agent classes V. Agents belonging to the same agent class can solve their planning problem in parallel. An undirected coupling graph G = (V,E) and a prioritization function p form a directed coupling graph G with (2). By topologically sorting the directed coupling graph, we map agents to classes V according to our Algorithm 1. The algorithm inspects all vertices to find sources, i.e., vertices with no incoming edges (Line 6). All sources can start their computation, so we add them to a class (Line 7). The resulting class is next in solving its planning problem, so it is added to the computation sequence (Line 10). The processed vertices are removed from the set of vertices to process (Line 11). Finally, all edges connected to the processed vertices are removed from the coupling graph (Lines 12 to 14). The loop repeats until all vertices are"}, {"title": "Definition 9 (Computation sequence).", "content": "The set of agent classes V is a countable set with |V| = Nc. The computation sequence defined as\n$(s_z)_{z=1}^{N_c} = (s_1, s_2, ..., s_{N_c})$\n(6)\nwith the domain {1,..., Nc} and the codomain V resembles a permutation of the agent classes in V."}, {"title": "3.2 Simultaneous Computation with Multiple Prioritizations", "content": "This section describes our algorithms for simultaneous computation with multiple priori- tizations. We first present our decentralized algorithm through which every agent obtains the same computation schedule matrix which fulfills (11) and (12). We then show how agents solve PP problems with multiple prioritizations. Finally, we show how agents select a solution for the PP problems.\nOur goal for the computation schedule matrix S is to explore Ne prioritizations in a time step to increase the probability of finding the optimal prioritization according to Problem 1. Algorithm 2 is our decentralized algorithm to find a computation schedule matrix S. We restate that a row sq. \u2208 1 \u00d7 Nc corresponds to a computation sequence q, and a column s.m \u2208 Nc \u00d7 1 corresponds to a time slot m during the networked computation. First, we initialize the computation schedule matrix S with the size Nc \u00d7 Ne and fill the first row s1. with the classes of V in sequence (Lines 1 and 2). Note that this initial row can change from one time step to another as it depends on the initial prioritization. We enforce a common random seed among agents for consistent results of the algorithm (Line 4). The algorithm determines the remaining rows in a loop (Line 5). For each row, the algorithm loops over all Ne columns that need to be populated (Lines 7 and 8). We use the number of available classes in each column that can form a valid computation schedule matrix as a heuristic for the order in which the columns are populated (Line 10). This number of available classes is stored in the options array. It is an array of sets, each containing all elements of V that respect (11) regarding the current row q and that respect (12) regarding the column corresponding to the array index. The next column to populate is the one with the least number of available classes (Line 11). One of these classes is selected at random (Line 15). If all columns are populated with valid entries, we progress to the next row (Line 18). If there is a column for which no classes are available to select from, the current row is invalid with the rest of the computation schedule matrix (Line 12), so we reset the current row (Line 20) and start over.\nWe illustrate Algorithm 2 with an example in Figure 6. The figure contains four agent classes, and depicts the construction of the second row of the computation schedule matrix. Each other row in the figure corresponds either to determining the remaining options of computation classes for each cell (Line 10), or to the random selection of an option (Line 15) from the most constrained cell (Line 11).\nOur Algorithm 2 builds a computation schedule row by row, which is valid according to (11) and (12). A partly built, valid computation schedule can always be completed."}, {"title": "3.3 Initial Prioritization", "content": "The selection of the initial prioritization, and with Algorithm 1 the initial computation sequence as well, determines which prioritizations can possibly be explored. We identified two objectives for selecting the initial prioritization.\nThe time-variance of priorities in receding horizon planning has both advantages and disadvantages. An advantage of time-variance is that situations which dictate varying pri- orities over time to find a solution can be solved, as illustrated by Figure 4. A disadvantage"}, {"title": "4 Motion Planning for CAVs", "content": "MAMP is a variant of MAPF. The evaluation of the approach presented in this paper takes place in the context of MAMP for CAVs. We have the following correspondences between traditional MAPF and our formulation of MAMP for CAVs.\n1. System dynamics: In MAPF, the dynamics of robots are usually abstracted in the graph search problem (e.g., Banfi, Shree, & Campbell, 2020; Li, Tinka, et al., 2021). In our MAMP, we explicitly consider the system dynamics in the planning problem by encoding motion in a motion primitive automaton (MPA).\n2. Objective: In MAPF, the objective of agents is to plan a path to reach a target vertex in the graph representing the environment without collisions. In our MAMP, the objective of agents is to plan motions to stay close to a reference path without collisions. The reference path is the result of a routing layer and does not consider obstacles.\n3. Planning time horizon: In MAPF, the planning time horizon is variable and extends until the agent has reached its target vertex. An agent plans once, and the plan reaches from the agent's start vertex to its target vertex. In our MAMP, the planning time horizon is fixed. This allows for short and predictable computation times. An agent plans at every time step, thereby shifting its planning horizon, an approach known as receding horizon control (RHC).\n4. Environment representation: In MAPF, the environment with its obstacles is encoded in a graph, where vertices represent locations at which agents can stop, and edges represent discretized motions of agents. In our MAMP, the environment with its obstacles is represented by a list of polygons. Each agent is required to avoid these polygons when planning motions.\nThere are works that go beyond traditional MAPF and extend the above-listed cate- gorization; e.g., system dynamics are considered in (Alonso-Mora, Beardsley, & Siegwart, 2018; Le & Plaku, 2018; Luo, Chakraborty, & Sycara, 2016)."}, {"title": "4.1 Motion Planning as an Optimal Control Problem", "content": "This section presents the ordinary differential equations describing the vehicle dynamics and our cost function before both are incorporated into an OCP for motion planning. The variables and equations in this section belong to a single agent i.\nWe refer to the entirety of all agents as an NCS. We control multiple agents in an NCS with a combination of prioritized planning and distributed model predictive control (DMPC) Richards and How (2007). This combination will be referred to as prioritized distributed model predictive control (Kloock, Scheffe, Botz, et al., 2019; Scheffe et al., 2022; Scheffe, Pedrosa, Fla\u00dfkamp, & Alrifaee, 2024; Scheffe, Xu, & Alrifaee, 2024). Finding the agents' control inputs is modeled as an OCP. We denote by agent OCPs the OCPs solved by the agents, and by networked OCP the OCP for the entire prioritized NCS.\nFigure 7 shows an overview of variables for the nonlinear kinematic single-track model (Rajamani, 2006, p. 21). Assuming low velocities, we model no slip on the front and rear wheels, and no forces acting on the vehicle. The resulting equations are\n$\\begin{aligned} \\dot{x}^{(i)}(t) &= v^{(i)}(t) \\cdot \\cos(\\psi^{(i)}(t) + \\beta^{(i)}(t)),\\\\ \\dot{y}^{(i)}(t) &= v^{(i)}(t) \\cdot \\sin(\\psi^{(i)}(t) + \\beta^{(i)}(t)),\\\\ \\dot{\\psi}^{(i)}(t) &= \\frac{v^{(i)}(t)}{L} \\cdot \\tan(\\delta^{(i)}(t)) \\cos(\\beta^{(i)}(t)),\\\\ \\dot{v}^{(i)}(t) &= u_v^{(i)}(t), \\\\ \\dot{\\delta}^{(i)}(t) &= u_{\\delta}^{(i)}(t), \\end{aligned}$\n(23)"}, {"title": "with", "content": "$\\beta^{(i)}(t) = \\arctan(\\frac{L_r}{L} \\tan(\\delta^{(i)}(t)))$,\n(24)\nwhere x(i) \u2208 R and y(i) \u2208 R describe the position of the center of gravity (CG), \u03c8(i) \u2208 [0, 2\u03c0) is the orientation, \u1e9e(i) \u2208 [\u2212\u03c0, \u03c0) is the side slip angle, \u03b4(i) \u03b5 [\u2212\u03c0,\u03c0) and us \u2208 R are the steering angle and its derivative respectively, v(i) \u2208 R and uy \u2208 R are the speed and acceleration of the CG respectively, L is the wheelbase length and Lr is the length from the rear axle to the CG.\nThe system dynamics defined in (23) are compactly written as\n$\\dot{x}^{(i)}(t) := \\frac{dx^{(i)}}{dt}(t) = f(x^{(i)}(t), u^{(i)}(t))$\n(25)\nwith the state vector\n$x^{(i)} = (x^{(i)} \\ y^{(i)} \\ \\psi^{(i)} \\ \\delta^{(i)} \\ v^{(i)})^T \\in \\mathbb{R}^{5}$ ,\n(26)\nthe control input\n$u^{(i)} = (\\dot{\\delta}^{(i)} \\ \\dot{v}^{(i)})^T \\in \\mathbb{R}^{2}$\n(27)\nand the vector field f defined by (23). Transferring (25) to a discrete-time nonlinear system representation yields\n$x_{k+1}^{(i)} = f_d(x_k^{(i)}, u_k^{(i)})$\n(28)\nwith a time step k\u2208 N, the vector field fd:R5 \u00d7 R2 \u2192 R5.\nWe define the cost function for agent i to minimize given a prioritization p in our motion planning problem as\n$J_p^{(i)}(k) = \\sum_{l=1}^{N_p} \\|x_{k+l|k}^{(i)} - r_{k+l|k}^{(i)}\\|_{Q}$ ,\n(29)\nwith the prediction horizon Np \u2208 N, a reference trajectory r(i)\nk+l|k \u2208 R5, and the positive semi- definite, block diagonal matrix\n$Q = \\begin{bmatrix} I_{2x2} & 0_{2x3} \\\\ 0_{3x2} & Q_{3x3} \\end{bmatrix}$.\n(30)\nThe OCP of agent i follows in (31). Since multiple agents are involved in the equation, we will include the agent superscript. We assume a full measurement or estimate of the state x(i) (k) is available at the current time k."}, {"title": "with", "content": "$\\begin{aligned} &\\underset{u}{\\text{minimize }} J_{p}^{(i)}(k) \\\\ &\\text{subject to } \\\\ &x_{k+l+1|k}^{(i)} = f_d(x_{k+l|k}^{(i)}, u_{k+l|k}^{(i)}) \\quad l=0,...,N_p-1, \\\\ &x_{k+l|k}^{(i)} \\in X \\quad l=1,...,N_p-1, \\\\ &x_{k+N_p|k}^{(i)} \\in X_f, \\\\ &x_{k|k}^{(i)} = x^{(i)}(k), \\\\ &u_{k+l|k}^{(i)} \\in U \\quad l=0,...,N_u-1, \\\\ &c^{(i+j)}(x_{k+l|k}^{(i)}, x_{k|k}^{(j)}) \\leq 0 \\quad l=1,...,N_p,\\ j \\in \\mathcal{V}^{(i+)}_{p}(k). \\end{aligned}$\n(31a-g)\nHere, fa: R\" \u00d7 Rm \u2192 Rn is a vector field resembling the discrete-time nonlinear system model withne Nas the number of states and meNas the number of inputs, u(i)\nk = (u(i)\nlk,...u(i)\nlNu\u22121k) is the input trajectory, X is the set of feasible states, Xf is the set of feasible terminal states, and U is the set of feasible inputs. The coupling constraint c(i-1): R\u2033 \u00d7 Rn \u2192 R in (31g) enforces networked constraints among agents. The set of prede- cessors vi\u2190)(k) contains the neighbors of i with higher priority given the prioritization p.\nAn agent i solves its OCP after having received the predictions of all predecessors Vi) Vp (k). Afterwards, it communicates its own prediction to agents in Vi) (k). Since the planning problem requires the predecessors' predictions in (31g), the agents must solve their OCPs in a sequential order. Each agent solves the OCP (31) repeatedly after a time step duration Ts and with updated values for the states and constraints, which establishes the RHC. Only the first input u(i) Ukk of the input trajectory is applied."}, {"title": "4.2 System Modeling with a Motion Primitive Automaton", "content": "This section presents how we model the state-continuous system (28) as an MPA (Frazzoli, Dahleh, & Feron, 2005; Scheffe, Pedrosa, et al., 2023). The MPA incorporates the constraints on system dynamics (31b), on control inputs (31f), and on both the steering angle and the speed (31c) and (31d).\nFrom the system dynamics (23), we derive a finite state automaton which we call MPA and define as follows.\nDefinition 11 (Motion primitive automaton, from (Scheffe, Pedrosa, et al., 2023)). An MPA is a 5-tuple (Q, S, y, Qo, Qf) composed of:\n\u2022 Q is a finite set of automaton states Q;\n\u2022 S is a finite set of transitions S, also called motion primitives (MPs);\n\u2022 \u03b3: Q\u00d7S\u00d7N \u2192 Q is the update function defining the transition from one automaton state to another, dependent on the time step in the horizon;"}, {"title": "4.3 Coupling of Vehicles", "content": "Although coupling all vehicles guarantees that coupling constraints for all vehicles will be considered, it also prolongs computation time and increases the number of prioritizations compared to coupling fewer vehicles. Therefore, we only couple vehicles that can potentially collide within the horizon Np. We couple two vehicles at a time step k if at least one of their reachable sets intersects within the horizon Np.\nDefinition 12 (Reachable set of a time interval, from Scheffe, Xu, and Alrifaee (2024)). The reachable set R(i) of the states of vehicle i between time t\u2081 and time t2 starting from time to is\n$R^{(i)}_{[t_1,t_2] | t_0} = \\bigcup_{t' \\in [t_1,t_2] | t_0} \\{f(\\underbrace{x^{(i)}(t_0)}_{X(t_0)}, \\underbrace{u^{(i)}}_{U}) dt\\}$ .\nThe reachable sets R(2) [k+l,k+l+1]|k over the prediction horizon of a vehicle can be computed offline with the MPA presented in Section 4.2. The set of coupling edges is\n$\\mathcal{E}(k) = \\{(i - j) \\| i,j \\in V, i \\neq j, \\exists l \\in \\{0, ..., N_p - 1\\}\\colon R^{(i)}_{[k+l,k+l+1]|k} \\cap R^{(j)}_{[k+l,k+l+1]|k} \\neq \\emptyset\\} ,$\n(32)\nThis results in a time-variant coupling graph G(k) = (V,E(k))."}, {"title": "4.4 Planning using Monte-Carlo Tree Search in a Model Predictive Control Framework", "content": "It is computationally hard to find the global optimum to the planning problem (31) due to its nonlinearity and nonconvexity. We substitute the system model (31b) with an MPA based on our previous work (Scheffe, Pedrosa, et al., 2023). Our MPA is general instead of tailored towards a specific environment. Therefore, our motion planning is a receding horizon tree search rather than a graph search. Obstacles are included in the state constraints (31c) of"}, {"title": "5 Evaluation", "content": "We evaluate the presented approach for increasing solution quality by exploring multiple prioritizations in the context of multi-agent motion planning for CAVs. In Section 5.1, we describe the experiment setup, a scenario on a road network with up to 20 vehicles. In Sections 5.2 and 5.3, we evaluate the quality of the trajectories of the vehicles in the NCS, and the computation time of the NCS, respectively. In Section 5.4, we demonstrate our approach in an experiment in the CPM Lab, an open-source, remotely-accessible testbed for CAVs (Kloock et al., 2021). In Section 5.5, we discuss the implications of"}]}