{"title": "INTEGRATING ESG AND AI: A COMPREHENSIVE RESPONSIBLE AI ASSESSMENT FRAMEWORK", "authors": ["Sung Une Lee", "Harsha Perera", "Yue Liu", "Boming Xia", "Qinghua Lu", "Liming Zhu", "Jessica Cairns", "Moana Nottage"], "abstract": "Artificial Intelligence (AI) is a widely developed and adopted technology across entire industry sectors. Integrating environmental, social, and governance (ESG) considerations with AI investments is crucial for ensuring ethical and sustainable technological advancement. Particularly from an investor perspective, this integration not only mitigates risks but also enhances long-term value creation by aligning AI initiatives with broader societal goals. Yet, this area has been less explored in both academia and industry. To bridge the gap, we introduce a novel ESG-AI framework, which is developed based on insights from engagements with 28 companies and comprises three key components. The framework provides a structured approach to this integration, developed in collaboration with industry practitioners. The ESG-AI framework provides an overview of the environmental and social impacts of AI applications, helping users such as investors assess the materiality of AI use. Moreover, it enables investors to evaluate a company's commitment to responsible AI through structured engagements and thorough assessment of specific risk areas. We have publicly released the framework and toolkit in April 2024, which has received significant attention and positive feedback from the investment community. This paper details each component of the framework, demonstrating its applicability in real-world contexts and its potential to guide ethical AI investments.", "sections": [{"title": "1 Introduction", "content": "Environmental, Social and Governance (ESG) represents a framework for evaluating a company's impact on environmen- tal sustainability, social responsibility, and effective governance practices [1]. Investors consider these comprehensive factors to evaluate a company's impact and performance, rather than focusing solely on financial metrics.\nArtificial Intelligence (AI) is a rapidly growing force impacting how companies build new markets, drive productivity improvements and enhance customer engagement. There has been clearly seen growth in the market, leading to a dramatic increase in company interest. Additionally, regulations are evolving, with new local and global AI regulations emerging, such as EU AI Act. Al presents tremendous opportunities but also poses significant risks, which are typically addressed through Responsible AI (RAI) practices. On the other hand, investors\u2014who may have the greatest leverage to encourage companies to adopt responsible AI often use the ESG framework for evaluating non-financial metrics. There are many overlaps between the concerns and approaches of RAI and ESG. The motivation is to integrate responsible AI into the ESG framework, rather than simply managing RAI as a separate entity. This integration allows us to view and manage responsible AI through the lens of ESG.\nThere have been a number of studies on ESG and AI integration, proposing frameworks and protocols for evaluating AI impacts in an ESG context [2, 3]. These studies highlight the need for standardized guidelines, particularly for measuring environmental topics, and emphasize challenges due to diverse standards and complex datasets [4, 5]. Despite these efforts in academia [6, 7] and recent industry reports outlining frameworks for ESG and AI integration [8, 9], there still lack a comprehensive framework that can be readily implemented in real-world contexts. We have identified few existing"}, {"title": "2 Background and Literature Review", "content": "In recent years, ESG frameworks have emerged as an overarching framework to assess enterprises across three dimensions: Environmental (e.g., carbon emissions, water usage), Social (e.g., employee diversity, working conditions), and Governance (e.g., board composition, audit practices). ESG topics can be connected to AI in three ways: leveraging AI to reduce ESG risks (e.g., emission reduction, monitoring, and governance); using AI for positive impacts (e.g., customer experience); and addressing the concerns and risks of RAI, which overlap with ESG concerns and risks. Integrating AI into ESG frameworks is crucial for addressing these risks and concerns.\nWhile widely adopted ESG frameworks, such as the Global Reporting Initiative standards, provide high-level guidance, Crona [4] and Yu et al. [5] highlighted the lack of standardized guidelines for measuring ESG metrics, especially environmental aspects. What is more, AI, integral to modern enterprise workflows, enhances ESG analysis and operationalization. TSE et al. [12] describe AI-enabled ESG tools involving three main steps: harvesting, which involves collecting and parsing ESG-related data; organizing, which entails screening and transforming data into structured formats; and analyzing, which includes performing classification, sentiment, contextual, and semantic analysis. Pozzi and Dwivedi [13] analyse the integration of IoT and ESG, especially environmental sustainability, and they propose a reference architecture where devices' real-time data are collected and monitored, and an alarm will be triggered if a predefined threshold is met. The authors also discussed the positive impacts of using AI on ESG, including efficient and accurate data collection, analysis, and decision-making. Xu [14] conducted a survey to investigate how AI systems facilitate the analytical capabilities, risk assessment, and customer engagement of ESG in financial institutes.\nWhile AI can enhance ESG, it also requires additional considerations within the ESG framework to address its own associated risks and concerns. For example, researchers have studied AI's impact on sustainability [15, 16]. Saetra [2] proposed a framework for evaluating AI impacts using the United Nations' Sustainable Development Goals. More recently, Saetra [6] introduced an AI ESG protocol for evaluating and disclosing AI's ESG impacts, comprising four main steps: initial descriptive statement, main impact statement, risks and opportunities, and action plan. Brusseau"}, {"title": "3 Methodology", "content": "We adopted a collaborative research methodology [19] to develop the framework and toolkit, focusing on continuous dialogue and goal alignment. In this study, we considered the three key factors of a collaborative research. First, researchers and practitioners work together. Second, we focus on \"real word\" as well as theoretical problem. Third, the participants gain mutual respect for one another and grow in their insights into and understanding of ESG and AI. This research was implemented through three distinct phases: Pre-engagement Research, Engagement Research, and"}, {"title": "3.1 Pre-engagement Research Phase (Feb 2023 - Apr 2023)", "content": "The research team was assembled, comprising three AI researchers, three ESG experts/investors, a senior design thinker, a project manager, and a senior industrial expert. Each member had a specific role"}, {"title": "3.2 Engagement Research Phase (Apr 2023 - Sep 2023)", "content": "Interviews: We engaged directly with 28 companies across 8 sectors, including leading global and Australian companies. Notably, 34% of the invited companies declined participation in the interviews. Reasons cited for declining included their low level of AI maturity or concerns about market sensitivity. As per the interview protocol, one investor conducted the interviews, focusing on broader aspects, while an Al researcher handled RAI-related questions. Other team members participated as observers and note takers. The interviews were not recorded due to the privacy and sensitive information collected.\nData Analysis and Insights: Once she interviews were completed, the collected data and researcher notes were shared among the team members. The shared data was analysed separately by the investors and AI researchers to identify the best practices, the level of RAI maturity of the companies and the key insights from all the companies we interviewed. Then, the team conducted a series of workshops to synthesis the outcomes of investors and AI researchers to come up with a collective output. Following the completion of interviews, the gathered data and researcher notes were distributed among team members. Investors and AI researchers independently analyzed the shared data to discover best RAI practices, assess the RAI maturity levels of companies, identify the intersection between RAI & ESG and extract key insights from all interviewed companies. Subsequently, the team conducted a series of workshops to synthesize the findings of both investors and AI researchers into a unified output. The final insights were used as one of the key inputs of the framework development phase; see Section 4.1."}, {"title": "3.3 Framework Development Phase (Sep 2023 - Mar 2024)", "content": "When designing the framework, we mainly input the insights from the previous phase of the project and the knowledge gathered using literature review. We explain how this input influence the design of the framework in details in Section 4. Using these inputs we identified the key drivers of the framework.\n\u2022 Industry vs. Company: We observed significant similarities in Responsible AI (RAI) practices and use cases, among companies within the same industry (e.g., financial sector). Therefore, the impact RAI on investment decisions may initially be analysed at the industry level and subsequently drilled down to the company level.\n\u2022 The level of accessibility to information of a company: Investors and portfolio managers can readily access publicly available information about both industries and individual companies. Moreover, we found that investors show equal interest in governance indicators specific to companies. This information may gather engaging directly with the company through methods such as interviews.\n\u2022 The intersection of ESG and RAI principles: ESG and RAI principles exhibit overlapping characteristics, with key indicators and metrics aligning in certain areas. This alignment serves as a crucial bridge between investor knowledge and RAI principles. We have discussed this in Section 5; see Table 8.\n\u2022 A questionnaire: Further, a framework that supports investors to assess the RAI of a company to make investment decisions should thoroughly examine company practices. Such evaluation requires a carefully constructed questionnaire that aligns with current frameworks, standards, and regulatory guidelines."}, {"title": "3.3.2 Framework Development, Iterative Improvements and Evaluation", "content": "Using the key elements mentioned above, AI researchers developed the initial version of the ESG-AI framework and toolkit. The entire team was then informed about the framework, and their feedback was collected. A core team, consisting of selected investors, AI researchers, and a design thinker, was subsequently formed to further refine the framework. Al researchers in the core team was responsible on continuously improving the framework and the toolkit. The investors evaluated the improved versions of the framework and toolkit with their workflow and informed the core team on any required adjustments and further suggestions. Unlike other similar frameworks [9], which is tested after the development, this framework was evaluated with real-world clients, the investors in this case, continuously and collaboratively.\nThe core team met weekly to discuss potential improvements and reported updates to the broader research team bi-weekly, formally documenting the feedback received from the rest of the team. This process continued for nearly five months, underscoring the thoroughness of the iterative revisions made to the framework.\nThe role of investors' collaboration: Aligning with the collaborative research guidelines [19], the investors in the research team played a crucial role, as they represented the end users of the framework. Many design decisions were proposed or adjusted to accommodate the requirements or workflows suggested by the investors. For example, when"}, {"title": "3.3.3 Publication and Outreach", "content": "The final stage of our collaborative effort involved sharing the completed framework and toolkit through medias, industry reports and online platforms. To promote the framework, we organized conference presentations, webinars, and engagements with industry stakeholders. Further, a dedicated sanity URL was introduced with a web page 9. The report is freely available and the toolkit has restricted access to gather the information of people who would like to share their contact information download the toolkit templates. These activities aimed to raise awareness and encourage the adoption of our framework and allow us to contact them for future research."}, {"title": "4 ESG-AI framework", "content": "This section introduces the ESG-AI framework we have developed in partnership with the dedicated investors. First, we present the key insights from our engagement with 28 companies and explain how these insights informed the development of the framework. We then provide an overview of the framework architecture and its three key components: AI Use Case, RAI Governance Indicators, and RAI Deep Dive Assessment."}, {"title": "4.1 Company insights into the framework design", "content": "We have identified six key RAI insights for our framework design from the interviews with the engaged companies.\nIN1. Employee engagement is essential to deliver AI-related opportunities. Successful AI implementation requires input from both technical and non-technical staff. For example, engineers and consultants need to generate AI-related ideas for developers so the business needs can be met effectively. These types of partnerships are particularly crucial in industries like industrial and mining, where technology adoption has traditionally been limited.\nRecognizing the significance of employee engagement from diverse team in the successful deployment of AI [20], we have integrated this concept into our framework design. Specifically, we have included \"diversity and inclusion\" as a key social impact factor. This inclusion ensures that the diverse perspectives and expertise of employees across various roles are considered in AI development and implementation processes [21].\nIN2. Strengthening Board and leadership capability in AI, technology and ethics. Directors need tech know-how to navigate AI. Given the competitive landscape for experienced AI directors, alternative approaches such as training and raising awareness among existing Board members become essential but are yet to be fully explored. Companies with technology expertise are better placed to expand knowledge appropriately in the AI space.\nThe role and competence of boards in successful implementation of RAI has been emphasized by researchers as well [22]. Moreover, in some AI regulations and standards such as ISO/IEC AI management, top management is required to demonstrate leadership and commitment with respect to the AI management. The EU AI Act also includes an accountability framework as one of the key requirements for high-risk AI. This encompasses setting up the responsibilities of the management and other staff including boards with regard to all aspects of AI. We took this concept as a top priority and included \"Board and management\" topic in the 12 standard ESG topics. Breaking down the concept, our framework accommodates it and includes \"board accountability and board capability\" indicators under \"board oversight\" in RAI governance assessment.\nIN3. RAI governance is best embedded within existing systems and processes. This involves implementing governance structures that involve representatives from various disciplines to analyse risks and make informed decisions about AI strategy aligned with business objectives. In addition, there is need for defined RAI responsibility and sensitive use cases. For example, Microsoft is recognised for its robust RAI governance structure and leading RAI framework, particularly in explicitly referencing sensitive use cases.\nThis insight has been mainly used in designing AI governance indicators, especially, for \"Sensitive use cases\" under \"RAI commitment\" category and \"Dedicated RAI responsibility\" and \"System integration\" of \"RAI implementation\" category."}, {"title": "4.2 ESG-AI framework: Overview of the structure", "content": "This comprehensive framework comprises three essential components that collectively form the backbone of our ESG-AI framework. These components include an in-depth review of AI use cases for industry sectors, an evaluation of RAI governance indicators, and RAI deep dive assessment for a meticulous examination of RAI principles. Together, these elements provide a holistic approach to assessing and mitigating the risks associated with AI deployment, fostering responsible AI practices across diverse sectors."}, {"title": "4.3 ESG-AI framework: AI Use Case", "content": "In the Industry 4.0 era, AI is regarded as an essential technology for maximizing performance, product quality and employee well-being [24]. The trend shift leads that AI applications have been used everywhere in our daily life, in every industry sectors. To do preliminary screen and identify companies exposed to material AI use cases, investors need to understand the AI use cases in the industry sectors which are in their investment portfolios.\nWith such motivation and investor needs, this component, AI use case is designed to identify high material AI use cases across industry sectors, from the investor perspective. We defined nine industry sectors which are based on the standard industry sectors of the Australian share market 10, after some modifications. We have identified the top three AI applications for each sector from a survey of investor AI reports and media coverage, followed by delving into the AI applications.\nTable 4 presents the nine sectors and the selected AI use cases used in this study. Yet, industry sectors and AI use cases are not limited to this. Investors can flexibly add and/or modify any sectors/AI use cases to analyze for their current or future investment portfolios."}, {"title": "4.4 ESG-AI framework: RAI Governance Indicators", "content": "This component, RAI Governance Indicators, has been identified from multiple sources including the company insights from the interviews, public company disclosures (e.g., annual reports), and the needs of the investors engaged with several rounds of workshop in this project. It comprises 10 high-level indicators to assess company's overall commitment, accountability and measurement of RAI, under four different categories such as Board oversight, RAI commitment, RAI implementation, and RAI metrics.\nBoard oversight includes two indicators: Board accountability and Board capability.\nBoard accountability is regarded as the central and key success criteria of traditional corporate governance [26]. In the context of AI governance, this indicator has been particularly chosen to strengthen company's AI management approach as many companies report AI opportunities and uptake to their boards, but this is ad hoc and lacks the consistency, according to the company engagement interviews. Thus indicator requires that RAI should be explicitly mentioned as part of the responsibility of the board or a relevant board subcommittee (e.g. risk committee or ESG committee) and boards should receive structured RAI reporting at least once per year but more frequently as needed.\nBoard capability refers to the ability of board to respond and act competently in the face of various problems and challenges. It is well known that good board capability leads good company performance [27]. In the past, this topic has not received as much focus compared to studies on the implementation of AI and AI algorithms [22]. However, board capability in AI governance plays a key role in leveraging RAI practices and has recently gained more attention from both industry and researchers. As evidence, 42% of the interviewed companies had at least one director with strong capability in AI.\nRAI commitment has three indicators as follows.\nPublic RAI policy is strongly related to Transparency principle. Transparency and responsible disclosure are central to Al regulations, promoting user awareness of impactful AI interactions [28, 29, 30]. According to our interviews with companies, 40% had internal RAI policies, but only 10% shared these publicly. AI policy serves as a container for principles and guidelines that govern the development, deployment, and use of AI technologies. The absence or lack of visibility of an AI policy can lead to destructive consequences and/or harms to human, society and the environment due to black-boxed or ad-hoc control processes. Investors require companies to transparently disclosure their AI policies for right decision-making in investment. Accordingly, this indicator seeks to ensure that a company's AI policy should align with relevant regulations and standards (e.g. the EU AI Act, ISO/IEC 42001) and include consideration of ethics, company values, testing and transparency.\nSensitive use cases or high-risk AI (e.g., facial recognition) should be addressed as part of the RAI policy as it can cause significant issues to health and safety or fundamental rights of natural persons. The EU AI Act defines comprehensive requirements for high-risk AI, including a robust risk management system, a comprehensive quality management system covering the system, model, and data aspects, meticulous record-keeping practices, and the creation of technical documents to ensure transparency. To comply with the legal requirements and meet AI global standards, sensitive use cases require additional oversight and approval.\nRAI target such as % of workforce trained and reduction in RAI incidents should be clear defined and managed to support RAI policy or commitment. Most AI frameworks still lack the detailed guidance needed for practical implementation, particularly regarding measurable metrics related to RAI practices [31].\nRAI implementation relies on the following four supporting indicators to ensure responsible use of AI in daily operations.\nDedicated RAI responsibility means that a company need to have designated individual or function such as AI officer or similar role that has oversight for RAI. This role is required to provide strategic guidance, ensure ethical and responsible AI practices and manage AI risks. An AI management committee can support a structured approach to overseeing AI initiatives by bringing together cross-functional expertise and ensuring integration across business units. Human agency and oversight by a dedicated role can be achieved through human-in-the-loop, human-on- the-loop, and human-in- command approaches [32]. This has a link to RAI accountability which requires clear role and responsibility definitions in the accountability framework. Lack of professional accountability mechanisms may hinder operationalising RAI in practice [28].\nEmployee awareness is considered as a core indicator in research and in industry as well. ISO/IEC AI standard highlights the importance of stakeholder's awareness around AI systems. For example, it underscores that persons doing work under the organization's control shall be aware of the AI policy, their contribution to the effectiveness of the AI management system, including the benefits of improved AI performance, and the implications of not conforming with the AI management system requirements. Within an organization, an Al employee awareness program provides"}, {"title": "4.5 ESG-AI framework: RAI Deep Dive Assessment", "content": "RAI Deep Dive is to facilitate detailed analysis and engagement with company management on AI governance and RAI practices. Al ethics principles encompass key values and guidelines that address RAI development and deployment. Investors can use this assessment for a systematic evaluation of fairness, transparency, accountability, privacy, and more, contributing to a holistic understanding of how well a company adheres to ethical standards in its AI practices. This assessment has been developed based on the RAI question bank [10] and metric catalogue [31], which draws on insights and standards from key regulatory bodies, standard organisations and stakeholder groups, such as the EU AI Act, NIST AI Risk Management Framework, ISO AI Standard (ISO/IEC 42001) and other industry AI risk frameworks.\nDeep dive assessment process. Figure 5 shows the structure and describes how user can use it. It enables an in-depth assessment of RAI pracitces, but investors can flexibly undertake research on specific ESG concerns or use cases and tailor the questions based on your ESG interests or by material principles.\nSelection of assessment questions. Users can consider potential areas for further review identified in the previous steps, including concerns related to AI regulations, high-risk applications, and specific areas with lower AI governance scores (Figure 5- (A)). Our framework provides three options for filtering such as Organizational type, Al system category and ESG topics.\nOrganizational type is categorized by different parties involved in the operation of AI systems. Lee et al. [37] defined three parties including the creator of the AI, the user of the AI (who is the purchaser of the algorithm), and the targets of the AI. As our framework is to assess companies, we have selected the first and second parties, namely, AI developer and AI purchaser respectively. We also added both, AI developer/purchaser as another option.\nAl system category, such as the one proposed in the EU AI Act, categorizes AI systems into different risk levels like high-risk and low-risk, along with foundation model. This can help users select targeted questions to assess the risk profiles of companies using AI.\nESG topics encompass a set of 12 standardized aspects that are chosen by participating investors. This enables users to conduct a deep dive assessment of associated RAI practices of the company at the ESG topic level. For example, Carbon emissions, the first environmental topic and four sub-questions have a connection as shown in Figure 6. The first three questions are directly related to the environmental impacts of AI, which fall under Human, societal, and environmental wellbeing principle. The last question broadly includes third-party risks including all ESG aspects.\nThis structured approach ensures that all critical aspects of ESG are systematically reviewed, allowing for a thorough analysis of how a company integrates responsible AI practices into its broader ESG strategy."}, {"title": "5 Discussion", "content": "Throughout the project, we conducted several workshops involving investors (potential users) and senior industrial experts, fostering iterative testing and enhancements. These engaged participants actively contributed to the continuous refinement of the framework, offering valuable insights into its usability, particularly focusing on the clarity and practical applicability of the framework. The feedback underscored the importance of framework comprehensibility, real-world utility, and the effectiveness of the guidance provided for each component. This iterative approach ensured that the risk assessment questions within the framework were meticulously tailored to meet the diverse needs of its users. Consequently, the framework was widely acknowledged as a highly effective and pragmatic tool for assessing AI and ESG risks among investors.\nIn April 2024, we released the framework along with the final project report. Within the first 24 hours, it received coverage from 23 media outlets, and the number is still increasing. Moreover, within a week of the release, more than 1,000 people downloaded our final report from the website, and around 100 downloaded the framework toolkit, despite the gated website requiring personal information. Our framework has also received positive feedback from the audience. We had several follow-up meetings with various investment companies and garnered significant attention from them.\nIn early May, we promoted the framework at one of the world largest investor conferences. Many attendees, including investors, researchers, and industry practitioners, visited our booth and expressed their interest.\nWe also gained significant attention from social media users since we posted our framework. Here are some comments from them:\n\"Great to see this media coverage for your publication on Responsible AI and ESG integration. Such an important topic area. This work will provide valuable insights into addressing key challenges faced by executives and boards.\"\n\"...it sounds well-served in going beyond a principles-only approach to implementing RAI.\""}, {"title": "5.2 Practical implications", "content": "Analysis on AI use cases in different sectors. We have analyzed 27 AI use cases across 9 sectors, assessing regulatory risk (unacceptable/high/medium/low/not-determined), environmental and social impacts (9 topics), and impact scope (industry/systemic) with input from two participating investors.\nFigure 7 shows that most AI use cases are considered medium-risk, with no unacceptable or low-risk use cases identified. However, both the Energy and Healthcare sectors include two high-risk AI use cases. In the Energy sector, Predictive infrastructure maintenance and Grid management and energy optimisation are high-risk as they pertain to Critical infrastructure. Similarly, in the Healthcare sector, Health research/testing and Clinical care use cases are also categorized as Critical infrastructure and involve biometrics, a high-risk area defined by regulations. These use cases must adhere to regulatory requirements (e.g., the EU AI Act), which include a robust risk management system, a comprehensive quality management system covering the system, model, and data aspects, meticulous record-keeping practices, and the creation of technical documents to ensure transparency. Two use cases, Product development and Automation in the Information Technology sector, are classified as not-determined due to the need for further information to assess the risk level, given the implementation of AI systems across different processes and functions.\nFigure 8 illustrates how AI use cases influence the Environment and Society. Our analysis encompassed 9 topics, excluding governance topics, as these have been evaluated at the industry level. As shown in the table in the figure, four AI use cases have a high impact on both the Environment and Society. Particularly, use cases in the Information sector impact all topics, while those in the Materials sector broadly impact the Environment and Society (except for the \"Diversity, Equity, and Inclusion\" topic). There are no low-impact AI use cases, indicating that all analyzed use cases affect more than three topics.\nThe impact scope analysis shows that 8 AI use cases in 6 sectors have a broad, systemic impact. For example, in the financial sector, Credit scoring and pre-application screening has systemic risks that pose material threats to the"}, {"title": "6 Conclusion", "content": "In this paper, we have developed and presented a comprehensive ESG-AI framework designed to guide investors in integrating ESG considerations with AI practices. Our framework addresses the critical need for RAI implementation by providing practical tools and guidelines that go beyond conceptual discussions, thus filling a significant gap in the current landscape.\nThrough our detailed analysis and comparison with existing frameworks, we have highlighted the unique value of our approach in comprehensively covering both ESG topics and AI ethics principles. By leveraging Australia's eight AI ethics principles and incorporating twelve key ESG topics, our framework offers a robust and actionable toolkit for investors. We believe that the adoption of our ESG-AI framework will enable investors to make informed, ethical, and sustainable decisions, ultimately contributing to a more responsible and future-proof AI ecosystem.\nFuture work can expand on this foundation by refining and testing the framework in various industry contexts, ensuring its adaptability and effectiveness across different sectors. As a first step, we will gather feedback from individuals who have downloaded our framework and toolkit by conducting a user survey. This will provide valuable insights from potential users, including both investors and companies, about real-world applications."}, {"title": null, "content": "F = w\u2081 \u00b7 R + W\u2082 \u00b7 I + W\u2083 \u00b7 S"}, {"title": null, "content": "M_{default} = \\begin{cases} & \\text{\\\"High\\\"} & \\text{if } F > T_{high} \\\\ & \\text{\\\"Medium\\\"} & \\text{if } T_{low} < F < T_{high} \\\\ & \\text{\\\"Low\\\"} & \\text{if } F < T_{low} \\end{cases}"}, {"title": null, "content": "M_{adjusted} \\coloneqq M_{default}"}, {"title": null, "content": "F = \\sum_{i=1}^{10} w_g G_i"}, {"title": null, "content": "L = \\begin{cases} & \\text{\\\"High\\\"} & \\text{if } F > 8 \\\\ & \\text{\\\"Medium\\\"} & \\text{if } 3 < F \\leq 7 \\\\ & \\text{\\\"Low\\\"} & \\text{if } F < 3 \\end{cases}"}, {"title": null, "content": "Average Score = \\frac{\\sum_{i=1}^{n-1} SubQuestionScore_i}{n}"}, {"title": null, "content": "Final \\space Level = \\begin{cases} & Strong & \\text{ if Average Score } \\geq 4.5 \\\\ & Moderate & \\text{ if 3  Average Score < 4.5 \\\\ & Weak & \\text{ if 1.5  Average Score < 3 \\\\ & Unacceptable & \\text{ if Average Score < 1.5 } \\end{cases}"}, {"title": null, "content": "\\begin{cases} & 0 & \\text{ if no evidence is provided (Not-disclosed)} \\\\ & 1 & \\text{ if minimal information is provided (Minimal)} \\\\ Score & 2-4 & \\text{ if moderate level of disclosure is provided (Moderate)} \\\\ & 5 & \\text{ if comprehensive and exemplary disclosure is provided (Comprehensive)} \\end{cases}"}]}