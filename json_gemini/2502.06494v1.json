{"title": "GUIDELLM: Exploring LLM-Guided Conversation with Applications in Autobiography Interviewing", "authors": ["Jinhao Duan", "Xinyu Zhao", "Zhuoxuan Zhang", "Eunhye Ko", "Lily Boddy", "Chenan Wang", "Tianhao Li", "Alexander Rasgon", "Junyuan Hong", "Min Kyung Lee", "Chenxi Yuan", "Qi Long", "Ying Ding", "Tianlong Chen", "Kaidi Xu"], "abstract": "Although Large Language Models (LLMs) succeed in human-guided conversations such as instruction following and question answering, the potential of LLM-guided conversations-where LLMs direct the discourse and steer the conversation's objectives-remains under-explored. In this study, we first characterize LLM-guided conversation into three fundamental components: (i) Goal Navigation; (ii) Context Management; (iii) Empathetic Engagement, and propose GUIDELLM as an installation. We then implement an interviewing environment for the evaluation of LLM-guided conversation. Specifically, various topics are involved in this environment for comprehensive interviewing evaluation, resulting in around 1.4k turns of utterances, 184k tokens, and over 200 events mentioned during the interviewing for each chatbot evaluation. We compare GUIDELLM with 6 state-of-the-art LLMs such as GPT-40 and Llama-3-70b-Instruct, from the perspective of interviewing quality, and autobiography generation quality. For automatic evaluation, we derive user proxies from multiple autobiographies and employ LLM-as-a-judge to score LLM behaviors. We further conduct a human-involved experiment by employing 45 human participants to chat with GUIDELLM and baselines. We then collect human feedback, preferences, and ratings regarding the qualities of conversation and autobiography. Experimental results indicate that GUIDELLM significantly outperforms baseline LLMs in automatic evaluation and achieves consistent leading performances in human ratings.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have demonstrated their effectiveness in human-guided dialogue, in which LLMs are tasked with producing responses according to specific commands from human operators, such as instruction following (Ouyang et al., 2022) and question answering (Chang et al., 2024). In this type of task, the primary duty of LLMs is to adhere to the instructions given by humans to ensure the generated output is accurate and close to human expectations, as shown in Figure 1(a).\nHowever, tasks in the real world are more complex, necessitating greater autonomy from LLMs (Wang et al., 2024a; Duan et al., 2022; Wu et al., 2023). For example, tasks such as interviewing are dramatically different from traditional tasks as interviewing is open-ended, without definitive or \"perfect\" outcomes. Interviewing tasks demand that LLMs plan the interview procedure, manage the objectives, e.g., exploring the user's memory and life experiences in autobiography interviewing, and offer adaptive and personalized inquiries based on the users' responses. This conversation paradigm requiring LLMs to guide and manage the conversation, ensuring the conversation flows smoothly and the objectives are met, is termed as LLM-guided conversation (Figure 1(b)).\nThere have been related works in the LLM-guided conversation, such as role-play (Wang et al., 2023b,c; Chen et al., 2024; Tao et al., 2023; Li et al., 2023a) and goal-oriented LLMs (Ham et al., 2020; Hosseini-Asl et al., 2020; Wu et al., 2020; Mehri et al., 2020; Inagaki et al., 2023). For role-play LLMs, they either prompt LLMs to perform specific roles such as a patient (Wang et al., 2024b), doctor (Panagoulias et al., 2024), gamer (Duan et al., 2024a,b), or investigate the human-like features of LLMs, e.g., emotions (Li et al., 2023b) and personalities (Safdari et al., 2023). Goal-oriented LLMs enable the model to attain greater levels of autonomy, particularly in fields such as space exploration (Maranto, 2024). While role-play and goal-oriented LLMs provide some autonomy and allow for the simulation of a specific role, their ability to actively control and effectively handle a full conversation is still underexplored.\nIn this paper, we investigate the LLM-guided conversation from framework design to autobiography interviewing applications. Inspired by popular social science theories, PEACE Model (Clarke and Milne, 2001) and Motivational Interviewing (MI) (Hettema et al., 2005), we design GUIDELLM to comply with these models by comprising three pivotal components: (i) Goal Navigation module, as the cornerstone of the framework, steers the conversation with pre-defined interviewing protocols and dynamic memory graphs for extrapolating dialogue trajectories. (ii) Context Management module iteratively distills the main idea of each session into a contextual summary for subsequent sessions. (iii) Empathetic Engagement module refines LLM response with expression strategies by the real-time monitoring of user emotion.\nFor evaluation, we create an interviewing environment where GUIDELLM is tasked with conducting interviews over 23 different topics, ultimately producing an autobiography based on the outcomes of these interviews. Then, the behaviors of GUIDELLM and baselines are evaluated in three-folds: (i) Interviewing Quality, e.g., event coverage and correctness; (ii) Conversation Quality e.g., communication fluency, identification, and comforting; (iii) Generation Quality, e.g., the insightfulness, narrativity, and emotional impact of the generated autobiography. We also carry out human-involved experiments with 45 participants, prompting them to engage in conversations with GUIDELLM and baseline models. Following these interactions, we gather feedback, preferences, and ratings from the participants. Our contributions can be summarized as the following:\n\u2022 Framework. We define the realm of LLM-guided conversations and propose GUIDELLM as an installation within this conversational paradigm. There are three components comprised in GUIDELLM: Goal Navigation, Context Management, and Empathetic Engagement.\n\u2022 Technique. GUIDELLM effectively harnesses a variety of techniques such as Retrieval Augmented Generation (RAG) and long-context summarization to boost the ability of LLMs to effectively lead and steer a conversation. Moreover, a memory graph is designed to drive memory extrapolation, thereby enhancing the goal navigation capabilities of GUIDELLM.\n\u2022 Application. We present the autobiography interviewing environment as a practical application of LLM-guided conversations. Within this setting, LLMs are tasked with initiating and steering the interview with users, aiming to generate a comprehensive autobiography.\n\u2022 Evaluation. We propose a comprehensive evaluation protocol for our LLM-guided autobiography interviewing environment, including interview quality, conversation quality, and autobiography generation evaluation, encompassing both LLM-as-a-judge evaluation and human subjects evaluations."}, {"title": "2 Related Work", "content": "Role-Play LLM. Role-playing agents (RPAs) powered by large language models (LLMs) are challenged by the evaluation of fidelity to target personas. Traditional methods focus on replicating characters' knowledge and linguistic patterns, requiring character-specific datasets. Huang et al. (2023) evaluate LLM personalities with self-report scales (BFI and MBTI), targeting LLM psychometric properties but not specifically addressing persona adherence. Li et al. (2023a) and Wang et al. (2023c) develop character-specific RPAS to enhance conversational abilities, human-likeness, and multi-turn consistency. However, they have not deeply explored character fidelity. Tao et al. (2024) found that adapting responses based on emotional cues significantly improved user satisfaction in role-playing scenarios. Tao et al. (2023) also demonstrated that with a scalable and controlled learning environment, LLM-driven simulations could effectively mimic real-life interactions.\nLong Text Generation and Management. The key techniques for long text generation and management considered in this study include summarization and Retrieval Augmented Generation (RAG). Luo et al. (2023) explore using ChatGPT to evaluate factual consistency in summarization. Zhong et al. (2022) propose a pre-training framework for long dialogue understanding and summarization using a window-based denoising approach. Xu et al. (2022) introduce a contrastive learning model, SeqCo, to improve the faithfulness of abstractive text summarization. Zhang et al. (2021) efficiently processes long texts by dividing them into manageable segments and summarizing each iteratively. Gao et al. (2023) overview RAG, which integrates external knowledge from databases to enhance LLM-generated content's reliability."}, {"title": "3 LLM-Guided Autobiography Interview", "content": "In this section, we first introduce LLM-guided conversation and its general framework. Then, we introduce GUIDELLM as an implementation of LLM-guided conversation, centering on interviewing.\n3.1 LLM-Guided Conversation\nSeveral theories from social science research provide comprehensive protocols for how to conduct guided conversations, e.g., interviewing. For instance, the PEACE Model (Clarke and Milne, 2001) and Motivational Interviewing (MI) (Hettema et al., 2005) highlight \u201cengage and explain\" and \"planning and preparation\u201d. To comply with these theories, GUIDELLM is designed from three essential qualities that an LLM should possess for effective conversation guidance:\nGoal Navigation. LLM steers the conversation and determines pivotal transitions, initiatively exploring and extrapolating new components that can shift the conversation toward the intended outcome.\nContext Management. LLMs summarize the ongoing dialogue, resuming previous discussions, connecting current conversations with past ones, and managing historical data exchanged between the LLM and users.\nEmpathetic Engagement. LLMs interact with the user by providing empathetic responses, delivering suitable tone and content, and demonstrating sensitivity towards the user's emotional state.\nLLM-guided conversations extend to numerous practical applications. For instance, in Interviews, they can frame pertinent questions, guiding the conversation. In Educational Tutoring (Nye et al., 2023), LLM-guided conversations can assess the user's state, crafting specific and personalized plans to facilitate the learning process. Another promising application is Mental Health Therapy (Demszky et al., 2023; Hong et al.), where the LLM can guide the conversation, applying personalized therapy based on the user's responses. Figure 2 provides a overall pipeline for GUIDELLM in guided conversations. We will use the autobiography interviewing task as an example of guided conversations for the rest of this paper.\n3.2 Goal Navigation\nIn guided conversations, LLMs are responsible for guiding the conversation, delivering adaptive responses to users, and ensuring that the conversation objectives are met. To accomplish this, we utilize a hybrid approach, combining Verbalized Interviewing Protocol (VIP) (Maunsell, 2016; Castillo-Montoya, 2016; Lamb et al., 2007) with Memory Graph-Driven Extrapolation (MGE):\nVerbalized Interviewing Protocol (VIP). We leverage the popular interviewing protocol, \u201cThe Life Story Interview\u201d (McAdams, 2008), as the general guidance. This protocol covers essential topics including Life Chapters, Key Scene in Life, Future, Challenges, and Personal Ideology. For instance, in the Challenges area, topics such as Life Challenges, Health, Loss, and Regrets will be covered. We design system prompts according to specific topics, containing basic seed questions, to make LLMs primarily focus on one topic during each session. In this way, the entire interviewing process could be structured into 23 sessions of conversations between the user and the LLM chatbot. Please refer to Appendix A for more details of the interviewing protocol and the prompt templates.\nMemory Graph Extrapolation (MGE). The objective of MGE is to explore unique characteristics and generate adaptive questions for personalized interviewing. MGE operates as an LLM-driven function, performing various operations on memories, including (i) extracting events from conversations, (ii) inserting new events into the graph, (iii) merging existing events, and (iv) extrapolating queries based on current events. Each event is associated with properties such as Date, People Involved, and Event Description.\nIn essence, MGE follows an \u201cextract, merge, then extrapolate\" process: initially, memory is initialized based on the user utterance. Next, the extraction process identifies and lists any events mentioned by the user, which are then merged with the existing events. Finally, MGE generates personalized questions from the event nodes by uncovering various relationships, such as identifying individuals who are mentioned frequently. These questions are stored in a \"question cache\" for use in the subsequent turn of the conversation. For details on the prompt templates used for event extraction and memory extrapolation, please refer to Appendix B.\n3.3 Context Management\nContext is a crucial information source for long conversations where each autobiographer has a unique and lengthy personal experience. However, LLMs have limited context lengths that can be easily exceeded when processing autobiographies (Dai et al., 2019). Besides, long-context input may bring performance decrease (Liu et al., 2023) and huge financial cost for the close-sourced. To tackle this, we incorporate a context management module in our framework capable of progressively summarizing and retrieving conversation history.\nConversation History Summarizing. Inspired by Chang et al.; Maharana et al., we implement an iterative summarization process that generates a summary for the current session based on the summaries from previous sessions, providing additional context for the chatbot. When initializing the chatbot, if a history conversation file is present in the configuration, we first generate a summary of the loaded conversation. At the start of each conversation after the first, the system prompt of the LLM chatbot includes a summarization section (see Appendix H), beginning with an instruction indicating that it has previously conversed with the user, followed by the specific summary of the prior session. The prompt and summarization pipeline are detailed in Appendix C and Figure 6.\n3.4 Empathetic Engagement\nLLM-guided conversations should accurately understand the user's state and respond appropriately. This involves empathetic interaction, creating a space where users feel at ease to share more about themselves. We accomplish this by enhancing Expression Strategies and Emotion Detection:\nExpression Strategy. To enhance the expression capability of LLMs, we draw inspiration from popular mental health therapy strategies, including Reflective Listening (Rautalinko et al., 2007), Cognitive-Behavior Therapy (CBT) (Beck, 2020), and Psychodynamic Therapy (Leibsenring and Leibing, 2003). Although originally designed to address mental health issues, these therapeutic strategies offer insightful guidance on effective communication with users and provide meaningful advice on interaction techniques. The introduction to therapy strategy and prompts are in Appendix D.1.\nEmotion Detection. Emotion sensitivity is a critical element in conveying the state of individuals that has been significantly underscored in human-computer interaction (Cowie et al., 2001; Brave and Nass, 2007) and LLMs (Li et al., 2023b). To enhance the emotional sensitivity of LLMs, we employ EmoLlama-7b (Liu et al., 2024) for the emotion detection of user utterances. Specifically, we prompt EmoLlama to provide both the emotion category (one of the emotions including anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust) and its intensity (from 0 to 1) for user response. We then guide the LLM to generate suitable responses that align well with the user's emotional state, e.g., including expressions of empathy or comfort when detecting an upset user. Please refer to Appendix D.2 for more details."}, {"title": "3.5 Autobiography Generation", "content": "Autobiography holds a distinctive form in comparison to other book categories, as an autobiography typically consists of numerous individual chapters, each of which relays a specific spirit or theme intimately tied to the author's life. This format aligns seamlessly with our structured interview protocol; the scope and topics encompassed in the interview protocols are similarly singular and targeted, allowing for a thorough exploration of each subject.\nTherefore, when generating an autobiography, we generate each chapter by sequentially building upon each interviewing session. Specifically, for each session, we meld the conversation history and memory nodes derived from the current session, then prompt GPT-4 to emphasize the key areas and topics discussed in that particular session. Please refer to Appendix E for more details of autobiography generation."}, {"title": "4 Experiments for Automatic Evaluation", "content": "4.1 Experimental Settings\nUser Proxy. We utilize GPT-4-turbo to simulate users for evaluating GUIDELLM in autobiography interviewing. Three LLM user proxies are implemented based on popular autobiographies: \u201cA Promised Land\u201d by Barack Obama, \u201cJane Eyre: An Autobiography\u201d, and \"An Autobiography by Catherine Helen Spence\u201d. They are assigned to role-play the corresponding main character in the autobiography and respond to questions by referencing the autobiography using the Retrieval-Augmented Generation (RAG) approach. See Appendix F for more details.\nEvaluation. Each chatbot will engage in conversations with all user proxies across 23 interview topics (Appendix A). The evaluation is three-fold: (1) Interviewing Quality measures the capability of LLMs to explore users' major events and life experiences and their ability to document these experiences accurately (Section 4.2).\n(2) Conversation Quality evaluates whether the responses from the LLM chatbot are comforting and engaging (Section 4.3).\n(3) Autobiography Generation: measures the quality of the generated autobiography, such as insightfulness and narrativity (Section 4.4)\nBaseline. To evaluate the design of GUIDELLM, we employ state-of-the-art LLMs and prompt them to be autobiography interviewers. For a fair comparison, baseline agents are also equipped with basic goal navigation and context management functions. Please refer to Appendix H for how baseline agents are built. The backbone LLMs for GUIDELLM is fixed to GPT-40, with the same generative hyperparameters as the baselines. We consider both commercial LLMs, e.g., GPT-4 and GPT-40 (Achiam et al., 2023), and open-source LLMs, e.g., Llama-3-70b-Instruct (Meta, 2024), Mixtral-8x22B-Instruct (Jiang et al., 2024), and Qwen2-72b-Instruct (Bai et al., 2023).\n4.2 Interviewing Quality Evaluation\nWe denote by \\(E_{intw} = \\{e_1, e_2, ...\\}\\) the events extracted during interviewing conversation. We denote by \\(E_{GT} = \\{e_1, e_2, ...\\}\\) the events directly extracted from the original. For both GUIDELLM and baselines, \\(E_{intw}\\) are obtained by prompting LLMs to extract events from conversation history (please refer to Appendix G.1 for more details):\nInterviewing Coverage (coverage) is calculated by the date-intersection between \\(E_{intw}\\) and \\(E_{GT}\\):", "latex": ["E_{intw} = \\{e_1, e_2, ...\\}", "E_{GT} = \\{e_1, e_2, ...\\}"]}, {"title": "4.3 Conversation Quality", "content": "Inspired by human evaluation metrics of therapy chatbots from Wang et al. (2023a), we design three conversation quality metrics: (i) Fluency; (ii) Identification; (iii) Comforting. We utilize the popular LLM-as-a-judge (Zheng et al., 2024) evaluation to make GPT-4 decide which conversation is better. Then, we calculate the win rate (WR) and loss rate (LR) of GUIDELLM against baselines. See G.2 for the evaluation protocol and prompt templates.\nThe results in Table 4 show that GUIDELLM significantly outperforms most baselines in GPT-4-as-a-judge evaluations. With human examinations, we find that baseline agents often resort to simple greetings or summaries, e.g., \u201cYour commitment to sharing experiences and insights that inspire action and change is truly admirable.\u201d. Instead of proficiently steering the dialogue to complete the interview, these repetitive utterance happen multiple times in a session with a baseline agent (Appendix G.4). In contrast, with our goal navigation module, GUIDELLM provides substantial content at each round of conversation.", "latex": []}, {"title": "4.4 Autobiography Generation Evaluation", "content": "We follow popular memo evaluations from Quora (2021); Marcus (2018); Smorti (2011); Pasupathi et al. (2007) and design three metrics of generated autobiography: Insightfulness, Narrativity, and Emotional Impact (prompt templates can be found in Appendix G.3). Leveraging the same LLM-as-a-judge evaluation protocol in Section 4.3, we found that the autobiography generated by GUIDELLM is more favorable than that of baseline agents. Examples of generated autobiography are presented in Appendix I.", "latex": []}, {"title": "4.5 Ablation Study", "content": "Empathetic Engagement. We study how the Empathetic Engagement (EE) module (Section 3.4) affects the emotion distribution of user responses. We compare how the intensity of emotions (both positive emotions Figure 3(a) and negative emotions Figure 3(b)) changed when the EE module is enabled and disabled. It is shown that the EE module effectively enhances the user's positive emotions while mitigating negative emotions, indicating that express strategy and emotional sensitivity foster a more positive emotion for users.\nValid Rounds in Conversation. As outlined in Section 4.3, the lack of autonomy in LLMs leads to repetitive responses. We manually count 10 conversation sessions for each chatbot and identify those conversations become repetitive or diverge into irrelevant or nonsensical content. The valid round percentages are calculated as:\nConversations Dynamics. In Figure 3(d), we count the memory events extracted and questions extrapolated at different conversation rounds. Generally, the MGE module identifies around 100 events and extrapolates nearly 40 questions for the LLM's follow-up. This highlights MGE's effectiveness in event management and goal navigation.", "latex": []}, {"title": "5 Human Subject Experiments", "content": "Experimental Configuration. A within-subject study with 45 participants was conducted at a large urban university campus in the US. Participants interact with the interviewing agents powered by GPT-40 and ours GUIDELLM, discussing the topic Key Scenes in the Life Story: Positive Childhood Memory (Appendix A) with each chatbot. To remove any biased factors, we use the nickname Breeze and Echo for the GPT-40 baseline and GUIDELLM to make sure participants are unaware of the identity of the chatbot. The order to interact with chatbots is also randomized for each participant. Due to resource constraints, each participant spent only 8 minutes chatting with each chatbot on a single topic. This differs significantly from the automatic evaluation protocols (Section 4). As a result, the capabilities of GUIDELLM, such as context management, goal navigation, and evaluation metrics, will be substantially affected and limited.\nIn a follow-up survey (Appendix J), participants indicated which model performed better, or it was a tie, and provided reasonings. Participation is voluntary, with informed consent obtained online, and participants are compensated with a cookie. The study received IRB approval from the university where the study was conducted.\nFindings. Overall, GUIDELLM was preferred for conversation quality (Figure 5a), particularly in fluency and question identification (Fluency: GUIDELLM Win Rate=40%, Baseline Win Rate\u224833%; Identification: GUIDELLM \u224853.3%, GPT-40\u224842.2%). However, in terms of comfort, GUIDELLM had a 31.1% win rate, while baseline had a 40% win rate. In autobiography quality, we do not observe significant differences emerged, possibly because this study used one topic and allowed a short interaction. Since the GUIDELLM uses modules such as context management and goal navigation for insightful and consistent narratives, longer engagement across multiple topics might have better highlighted the differences in autobiography generation. We further conduct LLM-as-a-judge evaluation by prompting LLMs to compare the two human-interviewed autobiographies. As shown in Figure 5b, we obtained consistent results as in Section 4.4: GUIDELLM achieves higher autobiography quality in general.\nPrevious AI experience affects participants' perceptions of the models: Participants who frequently used AI (4-7 days weekly) tended to prefer GUIDELLM for overall conversation quality (Chi-squared = 16.56, df = 8, p-value = 0.03). Open-ended responses indicated that daily AI users felt GUIDELLM \"asked questions to get a better understanding\u201d, \u201cmade more sense\u201d, was \u201cmore interactive", "more personal questions": "One user appreciated that \u201cGUIDELLM is more in-depth as it tries to connect my past experience to my current life\u201d. Overall, frequent AI users perceived GUIDELLM as asking more focused and personal questions to explore in-depth childhood experiences. This aligns with GUIDELLM 's Memory Graph Extrapolation (MGE), which allows it to explore unique properties and offer adaptive, personalized interview questions. Frequent AI users favored GUIDELLM for its emotional impact on autobiography (Chi-squared = 14.24, df = 8, p-value = 0.07). One user noted that GUIDELLM", "it": "while another mentioned it \u201cdescribed in immense detail my exact experience and made me feel like I was reliving it\u201d. This suggests how frequently AI users recognized GUIDELLM 's training with the emotion detection module, which analyzes the emotions in user responses and assigns emotion categories and strengths to their utterances."}, {"title": "6 Conclusion", "content": "In our study, we introduce GUIDELLM, an LLM-guided conversation framework that offers a promising shift from the commonly used user-guided paradigm. GUIDELLM's ability to facilitate informative and creative dialogues through goal navigation, context management, and empathetic engagement proves effective, particularly in challenging tasks like autobiography interviewing. Our assessments on event extraction correctness, conversation, and autobiography quality show GUIDELLM's distinct edge over baseline LLMs.", "latex": []}, {"title": "7 Limitation", "content": "Our study has several limitations, one of which is the prompt sensitivity. Variations in the phrasing of the prompts can significantly impact the model's responses Future work may aim to standardize prompt structures or develop models that are more robust to prompt variations. Another limitation is the evaluation metric. Evaluating the quality of autobiographical content, interviews, and conversations generated by the model is inherently subjective. While we employed multiple evaluation metrics, including interviewing coverage and correctness, these measures depend heavily on individual perceptions. Future research could benefit from developing more standardized and objective evaluation metrics.", "latex": []}]}