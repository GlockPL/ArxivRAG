{"title": "Overcoming label shift in targeted federated learning", "authors": ["Edvin Listo Zec", "Adam Breitholtz", "Fredrik D. Johansson"], "abstract": "Federated learning enables multiple actors to collaboratively train models without sharing private data. This unlocks the potential for scaling machine learning to diverse applications. Existing algorithms for this task are well-justified when clients and the intended target domain share the same distribution of features and labels, but this assumption is often violated in real-world scenarios. One common violation is label shift, where the label distributions differ across clients or between clients and the target domain, which can significantly degrade model performance. To address this problem, we propose FedPALS, a novel model aggregation scheme that adapts to label shifts by leveraging knowledge of the target label distribution at the central server. Our approach ensures unbiased updates under stochastic gradient descent, ensuring robust generalization across clients with diverse, label-shifted data. Extensive experiments on image classification demonstrate that FedPALS consistently outperforms standard baselines by aligning model aggregation with the target domain. Our findings reveal that conventional federated learning methods suffer severely in cases of extreme client sparsity, highlighting the critical need for target-aware aggregation. FedPALS offers a principled and practical solution to mitigate label distribution mismatch, ensuring models trained in federated settings can generalize effectively to label-shifted target domains.", "sections": [{"title": "Introduction", "content": "Federated learning has become a prominent paradigm in machine learning, enabling multiple clients to collaboratively train models without sharing their data [Kairouz et al., 2021]. Central to this development is the widely-used federated averaging (FedAvg) algorithm, which aggregates model updates from clients, weighted by their data set sizes [McMahan et al., 2017]. This aggregation rule is well-justified when client data is independent and identically distributed (i.i.d.) and has been effective in diverse domains such as healthcare [Sheller et al., 2020], finance risk prediction [Byrd and Polychroniadou, 2020], and natural language processing [Hilmkil et al., 2021].\nThe justification for FedAvg is weaker when clients exhibit systematic data heterogeneity, such as in the case of label shift [Zhao et al., 2018, Woodworth et al., 2020], since the learning objectives of clients differ from the objective optimized by the central server. Consider a federated learning task involving multiple retail stores (clients) where the goal is to predict the sales of different products based on customer purchase history, and deploy the trained model in a new store (target). Each store's sales reflect local preferences, leading to differences in label distributions and empirical risks. When label distributions vary substantially, the performance of FedAvg can be severely hampered [Karimireddy et al., 2020, Zhao et al., 2018]. So, how can models be trained effectively across such heterogeneous clients? Several methods have been proposed to deal with client heterogeneity, such as regularization [Li et al., 2020a, 2021], clustering [Ghosh et al., 2020, Vardhan et al., 2024], and meta-learning approaches [Chen et al., 2018, Jiang et al., 2019, Fallah et al., 2020a]. Still, these studies and prior work in federated learning assume that the target (or test) domain shares the same distribution"}, {"title": "Targeted federated learning under label shift", "content": "Federated learning is a distributed machine learning paradigm wherein a global model $h_{\\theta}$ is trained at a central server by aggregating parameter updates from multiple clients [McMahan et al., 2017]. We focus on classification tasks in which the goal is for $h_{\\theta}$ to predict the most probable label $Y \\in \\{1, ..., K\\}$ for a given input $X \\in \\mathcal{X}$. Each client $i = 1, ..., M$ holds a data set $\\mathcal{D}_i = \\{(X_{i,1}, Y_{i,1}), ..., (X_{i,n_i}, Y_{i,n_i})\\}$ of $n_i$ labeled examples. Due to privacy concerns or limited communication bandwidth, these data sets cannot be shared with other clients or with the central server. Learning proceeds over rounds $t = 1, ..., t_{max}$, each completing three steps: (1) The central server broadcasts the current global model parameters $\\theta_t$ to all clients; (2) Each client $i$ computes updated parameters $\\theta_{i,t}$ based on their local data set $\\mathcal{D}_i$ and sends these updates back to the server; (3) The server aggregates the clients' updates to obtain the new global model $\\theta_{t+1}$.\nClient samples $\\mathcal{D}_i$ are assumed to be drawn i.i.d. from a local distribution $\\mathcal{S}_i(X, Y)$. A common assumption in federated learning is that all client distributions are identical, i.e., $\\forall i, j \\in [M] : \\mathcal{S}_i = \\mathcal{S}_j$. Under this assumption, the learned central model is expected to perform well on average across clients. We can think of this as a special case of an intended target domain $\\mathcal{T}(X, Y)$ which coincides with the marginal distribution of clients, $\\mathcal{S} = \\frac{1}{M} \\sum_{i=1}^{M} \\mathcal{S}_i$, where $N = \\sum_{i=1}^{M} n_i$. But, in general, the target domain $\\mathcal{T}(X, Y)$ may be distinct from individual clients and their aggregate [Bai et al., 2024]. Moreover, clients may exhibit significant heterogeneity in their distributions, $\\mathcal{S}_i \\neq \\mathcal{S}_j$ [Karimireddy et al., 2020, Li et al., 2020b]. We refer to this problem as targeted federated learning.\nWe study targeted federated learning under known label shift, where no samples from the joint distribution $\\mathcal{T}(X, Y)$ are available but the target label distribution $\\mathcal{T}(Y)$ is known to the server.\nLet $\\mathcal{X} \\subset \\mathbb{R}^d$ denote the $d$-dimensional input space and $\\mathcal{Y} = \\{1, ..., K\\}$ the label space. Given a set of clients $\\mathcal{S}_1, ..., \\mathcal{S}_M$ and a target domain $\\mathcal{T}$, our objective is to minimize the expected risk, $R_{\\mathcal{T}}$ of a classifier $h_{\\theta} : \\mathcal{X} \\rightarrow \\mathcal{Y}$, with respect to a loss function $\\ell : \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$ over the target distribution $\\mathcal{T}$,\n```latex\n\\begin{equation}\n\\underset{\\theta}{\\text{minimize}} R_{\\mathcal{T}}(h_{\\theta}) := \\mathbb{E}_{(\\mathbf{X}, Y) \\sim \\mathcal{T}} [\\ell(h_{\\theta}(\\mathbf{X}), Y)] .\n\\end{equation}\n```\nObtaining a good estimate of $\\mathcal{T}(Y)$ is often feasible since it represents aggregate statistics that can be collected without the need for a large dataset. In our retail example, $Y = y$ would represent a sale in a specific product category, and $\\mathcal{T}(y)$ would correspond to the proportion of total sales in that category. A company could estimate these proportions without logging customer features $X$. Our setting differs from domain generalization which lacks a specific target domain [Bai et al., 2024]."}, {"title": "FedPALS: Parameter aggregation to adjust for label shift", "content": "In classical federated learning, all clients and the target domain are assumed i.i.d., and thus, the target risk ((1)) is equal to the expected risk in any client\n```latex\nR_{\\mathcal{T}}(h) = \\mathbb{E}_{(\\mathbf{X}, Y) \\sim \\mathcal{S}_i} [\\ell(h(\\mathbf{X}), Y)] =: R_i(h), \\text{ for all } i = 1, ..., M\n```\nSimilarly, the empirical risk $R_i$ of any client $i$ is identical in distribution (denoted $\\stackrel{d}{=}$) to the empirical risk evaluated on a hypothetical data set $\\mathcal{D}_\\mathcal{T} = \\{(x_{\\mathcal{T},j}, y_{\\mathcal{T},j})\\}_{j=1}^{N_{\\mathcal{T}}}$ drawn from the target domain,\n```latex\nR_i = \\frac{1}{n_i} \\sum_{j=1}^{n_i} \\ell(h(x_{i,j}), y_{i,j}) \\stackrel{d}{=} \\frac{1}{N_{\\mathcal{T}}} \\sum_{j=1}^{N_{\\mathcal{T}}} \\ell(h(x_{\\mathcal{T},j}), y_{\\mathcal{T},j}) =: R_{\\mathcal{T}}\n```\nAs a result, if clients perform a single local gradient descent update, any convex combination of these gradients (updates) is equal in distribution to a classical (centralized) batch update for the target domain, given the previous parameter value,\n```latex\n\\forall \\alpha \\in \\Delta^{M-1}: \\sum_i \\alpha_i \\nabla_{\\theta} R_i(h_{\\theta}) \\stackrel{d}{=} \\nabla_{\\theta} R_{\\mathcal{T}}(h_{\\theta}),\n```\nwhere $\\Delta^{M-1} = \\{\\alpha \\in [0,1]^M : \\sum_i \\alpha_i = 1\\}$ is the simplex over $M$ elements. This property justifies the federated stochastic gradient (FedSGD) and FedAvg principles [McMahan et al., 2017], which aggregate model parameter updates through a convex combination, chosen to give weight to clients proportional to their sample size,\n```latex\n\\mathbf{\\theta}_{t+1}^{FA} = \\sum_{i=1}^{M} \\alpha_i^\\text{FA} \\theta_i, \\text{ where } \\alpha_i^\\text{FA} = \\frac{N_i}{\\sum_{j=1}^{M} N_j}\n```"}, {"title": "Overcoming label shift while controlling variance", "content": "Next, we develop an alternative aggregation strategy that partially overcomes the limitations of FedAvg under label shift (Assumption 1). Under label shift, it holds that\n```latex\n\\forall i: R_{\\mathcal{T}}(h) = \\sum_{y=1}^{K} \\mathcal{T}(y) \\mathbb{E}_{(\\mathbf{X}, y) \\sim \\mathcal{T}} [\\ell(h(\\mathbf{X}), y) | Y = y] \\stackrel{\\text{Ass. 1}}{=} \\sum_{y=1}^{K} \\mathcal{T}(y) \\mathbb{E}_{(\\mathbf{X}, y) \\sim \\mathcal{S}_i} [\\ell(h(\\mathbf{X}), y) | Y = y].\n```\nIn centralized (non-federated) learning under label shift, this insight is often used to re-weight [Lipton et al., 2018b] or re-sample [Japkowicz and Stephen, 2002] the empirical risk in the source domain. This is not an option here since $\\mathcal{T}(Y)$ is not revealed to the clients. For now, assume instead that the target label distribution can be covered by a convex combination of client label distributions. For this, let $\\text{Conv}(\\mathcal{S})$ denote the convex hull of distributions $\\{\\mathcal{S}_i(Y)\\}_{i=1}^{M}$.\nAssumption 2 (Target coverage). For the label marginals $\\mathcal{S}_1(Y), ..., \\mathcal{S}_M(Y), \\mathcal{T}(Y) \\in \\Delta^{K-1}$, the target label distribution $\\mathcal{T}(Y)$ is covered by a convex combination $\\alpha^\\circ$ of client label distributions,\n```latex\n\\mathcal{T} \\in \\text{Conv}(\\mathcal{S}), i.e., \\exists \\alpha^\\circ \\in \\Delta^{M-1} : \\mathcal{T}(y) = \\sum_{i=1}^{M} \\alpha_i^\\circ \\mathcal{S}_i(y) \\forall y \\in [K] .\n```\nNote that, under label shift, Assumption 2 implies that $\\mathcal{T}(X, Y) = \\sum_{i=1}^{M} \\alpha_i \\mathcal{S}_i(X, Y)$, as well. Thus, under Assumptions 1\u20132, we have for any $\\alpha$ satisfying (4),\n```latex\nR(h) = \\sum_{y=1}^{K} \\mathcal{T}(y) \\mathbb{E}_{(\\mathbf{X}, y) \\sim \\mathcal{S}_i} [\\ell(h(\\mathbf{X}), y) | Y = y] \\stackrel{\\text{(4)}}{=} \\sum_{i=1}^{M} \\alpha_i R_{\\mathcal{S}_i}(h).\n```\nBy extension, aggregating client updates with weights $\\alpha$ will be an unbiased estimate of the update.\nProposition 1 (Unbiased SGD update). Consider a single round t of federated learning in the batch stochastic gradient setting with learning rate \u03b7. Each client $i \\in [M]$ is given parameters $\\theta_i$ by the server, computes their local gradient, and returns the update $\\theta_{i,t} = \\theta_t \u2013 \\eta \\nabla_{\\theta} R_i(h_{\\theta_t})$. Let weights $\\alpha$ satisfy $\\mathcal{T}(X,Y) = \\sum \\alpha_i \\mathcal{S}_i(X,Y)$. Then, the aggregate update $\\theta_{t+1} = \\sum_{i=1}^{M} \\alpha_i \\theta_{i,t}$, satisfies\n```latex\n\\mathbb{E}[\\theta_{t+1} | \\theta_t] = \\mathbb{E}[\\theta_{\\mathcal{T}+1} | \\theta_t],\n```\nwhere $\\theta_{\\mathcal{T}+1}$ = $\\theta_{\\mathcal{T}} - \\eta \\nabla_{\\theta} R_{\\mathcal{T}}(h_{\\theta_t})$ is the batch stochastic gradient update for $R_{\\mathcal{T}}$ that would be obtained with a sample from the target domain. A proof is given in Appendix C.\nBy Proposition 1, we are justified in replacing the aggregation step of FedAvg with one where clients are weighted by $\\alpha$. However, Assumption 2 may not hold, and $\\alpha$ may not exist. For instance, if the target marginal is sparse, only clients with the exact same sparsity pattern as $\\mathcal{T}$ can be used in a convex combination $\\alpha\\mathcal{S} = \\mathcal{T}$. That is, if we aim to classify images of animals and $\\mathcal{T}$ contains no tigers, then no clients contributing to the combination can have data containing tigers. At least, since $\\{\\mathcal{S}_i(Y)\\}_{i=1}^{M}, \\mathcal{T}(Y)$ are known to the server, it is straightforward to verify Assumption 2.\nA pragmatic choice when Assumption 2 is violated is to look for the convex combination $\\alpha^\\circ$ that most closely aligns with the target label distribution, and use that in the aggregation step,\n```latex\n\\alpha^\\circ = \\underset{\\alpha \\in \\Delta^{M-1}}{\\text{arg min}} \\|\\mathcal{S}(Y) - \\mathcal{T}(Y)\\|^2 \\text{ and } \\mathbf{\\theta}_{t+1} = \\sum_{i=1}^{M} \\alpha^\\circ \\theta_{i,t}.\n```"}, {"title": "FedPALS in the limits", "content": "In the FedPALS aggregation scheme ((7)), there exists a trade-off between closely matching the target label distribution and minimizing the variance of the model parameters. This trade-off gives rise to two notable limit cases: $\\mathcal{T} \\in \\text{Conv}(\\mathcal{S}), \\lambda \\rightarrow 0$, and $\\lambda \\rightarrow \\infty$. If all source distributions $\\{\\mathcal{S}_i\\}_{i=1}^{M}$ are identical and match the target distribution, this corresponds to the classical i.i.d. setting.\nCase 1: $\\lambda \\rightarrow \\infty \\Rightarrow$ Federated averaging In the limit $\\lambda \\rightarrow \\infty$, as the regularization parameter $\\lambda$ grows large, FedPALS aggregation approaches FedAvg aggregation.\nProposition 2. The limit solution $\\alpha^\\lambda$ to (7), as $\\lambda \\rightarrow \\infty$, is\n```latex\n\\lim_{\\lambda \\rightarrow \\infty} \\alpha_i^\\lambda = \\frac{n_i}{\\sum_{j=1}^{M} n_j} = \\alpha_i^FA \\text{ for } i = 1, ..., M .\n```"}, {"title": "Experiments", "content": "We perform a series of experiments on benchmark data sets to evaluate FedPALS in comparison with baseline federated learning algorithms. The experiments aim to demonstrate the value of the central server knowing the label distributions of the client and target domains when these differ substantially. Additionally, we seek to understand how the parameter $\\lambda$, controlling the trade-off between bias and variance in the FedPALS aggregation scheme, impacts the results. Finally, we investigate how the benefits of FedPALS are affected by the sparsity of label distributions and by the distance $d(\\mathcal{T}, \\mathcal{S}) := \\underset{\\alpha \\in \\mathcal{M}-1}{\\text{min}} \\|\\mathcal{T}(Y) \u2013 \\overline{\\alpha \\mathcal{S}(Y)}\\|_2$ from the target to the convex hull of clients.\nExperimental setup While numerous benchmarks exist for federated learning [Caldas et al., 2018, Ogier du Terrail et al., 2022, Chen et al., 2022] and domain generalization [Gulrajani and Lopez-Paz, 2020, Koh et al., 2021], respectively, until recently none have addressed tasks that combine both settings. To fill this gap, Bai et al. [2024] introduced a benchmark specifically designed for federated domain generalization (DG), evaluating methods across diverse datasets with varying levels of client heterogeneity. In our experiments, we use the PACS [Li et al., 2017] and iWildCAM data sets from this benchmark to model realistic label shifts between the client and target distributions. We modify the PACS dataset to consist of three clients, each missing a label that is present in the other two. Additionally, one client is reduced to one-tenth the size of the others, and the target distribution is made sparse in the same label as that of the smaller client. Further details are given in Appendix A.\nFurthermore, we construct two additional tasks by introducing label shift to standard image classification data sets, Fashion-MNIST [Xiao et al., 2017] and CIFAR-10 [Krizhevsky, 2009]. We apply two label shift sampling strategies: sparsity sampling and Dirichlet sampling. Sparsity sampling involves randomly removing a subset of labels from clients and the target domain, following the data set partitioning technique first introduced in McMahan et al. [2017] and extensively used in subsequent studies [Geyer et al., 2017, Li et al., 2020a, 2022]. Each client is assigned $C$ random labels, with an equal number of samples for each label and no overlap among clients.\nDirichlet sampling simulates realistic non-i.i.d. label distributions by, for each client $i$, drawing a sample $p_i \\sim \\text{Dirichlet}_{K} (\\beta)$, where $p_i(k)$ represents the proportion of samples in client $i$ that have label $k \\in [K]$. We use a symmetric concentration parameter $\\beta > 0$ which controls the sparsity of the client distributions. A smaller $\\beta$ results in more heterogeneous client data sets, while a larger value approximates an i.i.d. setting. This widely-used method for sampling clients was first introduced by Yurochkin et al. [2019]. While prior works have focused on inter-client distribution shifts assuming that client and target domains are equally distributed, we apply these sampling strategies also to the target set, thereby introducing label shift between the client and target data."}, {"title": "Experimental results on benchmark tasks", "content": "We present summary results for three tasks with selected skews and explore detailed results below. Across these tasks, FedPALS consistently outperforms or matches the best-performing baseline. For PACS, Fashion-MNIST and CIFAR-10, we include results for an Oracle FedAvg model, which is trained on clients whose distributions are identical to the target distribution, eliminating any client-target distribution shift (see Appendix A for details on its construction). A FedPALS Oracle would be equivalent since there is no label shift. The Oracle, which enjoys perfect alignment between client and target distributions, achieves superior performance, underscoring the challenges posed by distribution shifts in real-world scenarios where such alignment is absent.\nCIFAR-10/Fashion-MNIST"}, {"title": "Synthetic experiment: effect of projection distance on test error", "content": "When the target distribution $\\mathcal{T}(Y)$ is not covered by the clients, FedPALS finds aggregation weights corresponding to a regularized projection of $\\mathcal{T}$ onto $\\text{Conv}(\\mathcal{S})$. To study the impact of this, we designed a controlled experiment where the distance of the projection is varied. We create a classification task with three classes, $y = \\{0,1,2\\}$, and define $p(X | Y = y)$ for each label $y \\in \\mathcal{Y}$ by a unit-variance Gaussian distribution $\\mathcal{N}(\\mu_y, I)$, with randomly sampled means $\\mu_y \\in \\mathbb{R}^2$. We simulate two clients with label distributions $\\mathcal{S}_1(Y) = [0.5, 0.5, 0.0]^T$ and $\\mathcal{S}_2(Y) = [0.5, 0.0, 0.5]^T$, and $n_1 = 40, n_2 = 18$ samples, respectively. Thus, FedAvg gives larger weight to Client 1. We define a target label distribution $\\mathcal{T}(Y)$ parameterized by $\\delta \\in [0,1]$ which controls the projection distance $d(\\mathcal{T}, \\mathcal{S})$ between $\\mathcal{T}(Y)$ and $\\text{Conv}(\\mathcal{S})$,\n```latex\n\\mathcal{T}_\\delta(Y) := (1 \u2013 \\delta)\\mathcal{T}_{proj}(Y) + \\delta \\mathcal{T}_{ext}(Y),\n```\nwith $\\mathcal{T}_{ext}(Y) = [0, 0.5, 0.5]^\\top \\notin \\text{Conv}(\\mathcal{S(Y)})$ and $\\mathcal{T}_{proj}(Y) = [0.5, 0.25, 0.25]^\\top \\in \\text{Conv}(\\mathcal{S(Y)})$. By varying $\\delta$, we control the projection distance $d(\\mathcal{T}, \\mathcal{S})$ between each $\\mathcal{T}_\\delta$ and $\\text{Conv}(\\mathcal{S})$ from solving (6), allowing us to study its effect on model performance.\nWe evaluate the global model on a test set with $n_{test} = 2000$ samples drawn from the target distribution $\\mathcal{T}(Y)$ for each value of $\\delta$ and record the target accuracy for FedPALS and FedAvg. When $d(\\mathcal{S,T}) = 0$ (i.e., $\\mathcal{T}(Y) \\in \\text{Conv}(\\mathcal{S}))$, the target accuracy is highest, indicating that our method successfully matches the target distribution. As $d(\\mathcal{S,T})$ increases (i.e., $\\mathcal{T}$ moves further away from $\\text{Conv}(\\mathcal{S})$), the task becomes harder and accuracy declines. For all values, FedPALS performs better than FedAvg."}, {"title": "Discussion", "content": "We explored targeted federated learning under label shift, a scenario where client data distributions differ from a target domain with a known label distribution, but no target samples are available. We demonstrated that traditional approaches, such as FedAvg, which assume identical distributions between clients and the target, fail to adapt effectively in this context due to biased aggregation of client updates. To address this, we proposed FedPALS, a novel aggregation strategy that optimally combines client updates to align with the target distribution, ensuring that the aggregated model minimizes target risk. Empirically, across diverse tasks, we showed that under label shift, FedPALS significantly outperforms standard methods like FedAvg, FedProx and SCAFFOLD. Specifically, when the target label distribution lies within the convex hull of the client distributions, FedPALS finds the solution with the largest effective sample size, leading to a model that is most faithful to the target distribution. More generally, FedPALS balances the trade-off between matching the target label distribution and minimizing variance in the model updates. Our experiments further highlight that FedPALS excels in challenging scenarios where label sparsity and client heterogeneity hinder the performance of conventional federated learning methods.\nWe also observed that the choice of the trade-off parameter A is crucial for achieving optimal performance in tasks such as iWildCam, where the label shift assumption may not fully hold. Interestingly, the early performance gains observed during training suggest that dynamically tuning A over time could enhance performance of FedPALS. A promising avenue for future work would be exploring adaptive strategies for dynamically tuning A. Additionally, our weighting approach could be extended to the covariate shift setting, where input distributions vary between clients and the target. This extension is feasible when the central server has access to unlabeled target and client samples, akin to unsupervised domain adaptation in the centralized learning paradigm."}, {"title": "Proofs", "content": null}, {"title": "FedPALS updates", "content": "Proposition 1 (Repeated) (Unbiased SGD update). Consider a single round t of federated learning in the batch stochastic gradient setting with learning rate \u03b7. Each client $i \u2208 [M]$ is given parameters \u03b8t by the server, computes their local"}, {"title": "FedPALS in the limits", "content": "As x\u2192\u221e, because the first term in (7) is bounded, the problem shares solution with\n```latex\n\\underset{\\alpha_1,..., \\alpha_M}{\\text{min}} \\sum_{i=1}^{M} \\frac{\\alpha_i^2}{n_i} \\text{ s.t. } \\sum_{i=1} \\alpha_i = 1, \\forall i: \\alpha_i \\geq 0.\n```\nMoreover, we have the following result.\nProposition 3. The optimization problem\n```latex\n\\text{min} \\sum_i \\frac{\\alpha_i^2}{N_i} \\text{ s.t } \\sum_i \\alpha_i =1 \\alpha_i \\geq 0 \\forall i,\n```\nhas the optimal solution $ \\alpha_i^* = \\frac{N_i}{\\sum N_i} $ where i \u2208 [1, m]\nProof. From the constrained optimization problem we form a Lagrangian formulation\n```latex\n\\mathcal{L}(\\alpha, \\mu, \\tau) = \\sum \\frac{\\alpha_i^2}{N_i} + \\mu (1 \u2013 \\sum \\alpha_i) + \\sum \\tau_i \\alpha_i\n```\nWe then use the KKT-theorem to find the optimal solution to the problem.\n```latex\n\\nabla_{\\alpha} \\mathcal{L}(\\alpha^*) = 0 => \\forall i \\frac{2 \\alpha_i}{N_i} \u2013 \\mu - \\tau = 0\n```\nWe have the additional conditions of primal feasibility, i.e.\nh(\u03b1*) = 0\ng(\u03b1*) \u2264 0\nUsing complementary slackness, tg(\u03b1*) = 0, and that \u315c \u2265 0 we find that \u30f6 = 0. Thus we can write (15) as\n2 \\sum  \u2212\u03bc = 0 \u21d2 \u03bc=2\nCombining this with the primal feasibility condition h(\u03b1*) = 0 we obtain \u03bc = ; which implies = This proves also Proposition 2."}, {"title": "Proofs", "content": null}]}