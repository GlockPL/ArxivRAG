{"title": "A Fault Prognostic System for the Turbine Guide Bearings of a Hydropower Plant\nUsing Long-Short Term Memory (LSTM)", "authors": ["Yasir Saleem Afridi", "Mian Ibad Ali Shah", "Adnan Khan", "Atia Kareem", "Laiq Hasan"], "abstract": "Hydroelectricity, being a renewable source of\nenergy, globally fulfills the electricity demand.\nHence, Hydropower Plants (HPPs) have always\nbeen in the limelight of research. The fast-paced\ntechnological advancement is enabling us to\ndevelop state-of-the-art power generation\nmachines. This has not only resulted in improved\nturbine efficiency but has also increased the\ncomplexity of these systems. In lieu thereof,\nefficient Operation & Maintenance (O&M) of such\nintricate power generation systems has become a\nmore challenging task. Therefore, there has been a\nshift from conventional reactive approaches to\nmore intelligent predictive approaches in\nmaintaining the HPPs. The research is therefore\ntargeted to develop an artificially intelligent fault\nprognostics system for the turbine bearings of an\nHPP. The proposed method utilizes the Long\nShort-Term Memory (LSTM) algorithm in\ndeveloping the model. Initially, the model is\ntrained and tested with bearing vibration data from\na test rig. Subsequently, it is further trained and\ntested with realistic bearing vibration data obtained\nfrom an HPP operating in Pakistan via the\nSupervisory Control and Data Acquisition\n(SCADA) system. The model demonstrates highly\neffective predictions of bearing vibration values,\nachieving a remarkably low RMSE.", "sections": [{"title": "1. INTRODUCTION", "content": "In world energy consumption, hydropower\ncontributes an astonishing 11,300 TWh [1].\nKeeping in view such large share, the optimization\nof hydropower generation and operations becomes\nnotably consequential, encompassing economic\nand societal dimensions.\n\nThe advantages of optimizing hydropower\noperations are multifaceted and extend beyond the\nenhancement of energy production. They\nencompass augmented energy security, mitigation\nof equipment failures and downtimes, extension of\nremaining useful life (RUL) for plant and\nequipment, among others. Notably, machine\ndowntimes resulting from faults trigger an\nexpansion in the demand-supply gap, a scenario\nwith grave consequences. Hence, the necessity for\ncutting-edge Operation and Maintenance (O&M)\nsystems becomes imperative. Nevertheless,\nattaining the aspiration of optimal hydropower\nplant (HPP) operation is far from straightforward.\n\nIn the realm of continuous production systems,\nsuch as electricity generation facilities, the cost\nincurred due to production loss during plant\nunavailability amid faults is exceedingly\nsubstantial. Considering this, well-devised\nmaintenance procedures play a pivotal role in\nsustaining seamless equipment operation\nthroughout its economic lifespan. These\nmaintenance methodologies fall broadly into three\ncategories: corrective, preventive, and predictive\nmaintenance. In the context of Hydropower Plants\n(HPPs), the prevalent maintenance practices\npredominantly\nencompass\ncorrective approaches [2].\npreventive and\n\nThe corrective approach is reactive in nature,\nentailing maintenance actions solely subsequent to\nthe occurrence of faults. This conventional strategy\nfor fault rectification is widely embraced [9]. On\nthe contrary, preventive maintenance involves\nscheduled periodic upkeep of equipment,\nundertaken to diminish the likelihood of its\nmalfunctioning [9]. This proactive method is\nperformed while the equipment is still operational,\nensuring it doesn't encounter unforeseen\nbreakdowns. Conversely, prognostics revolves\naround the anticipation of faults and failures,\naiming to predict when a system or component will\ncease to execute its intended function [9]. Given its\nefficacy in curbing unwarranted downtimes,\nprognostic maintenance has emerged as a focal\npoint of contemporary research efforts."}, {"title": "1.1MACHINE PROGNOSTICS", "content": "Prognostics can be categorized into two primary\ndomains: data-driven approaches and model-\nbased/physics-based approaches [24, 28, 36]. In\nphysics-based methodologies, the development of\nmodels integrates domain expertise along with\nmeasured data through mathematical equations,\nconsidering the underlying physical laws.\nHowever, these physics-based approaches come\nwith certain drawbacks. Firstly, their performance\nheavily hinges on the accuracy and quality of\ndomain knowledge [24]. In practical scenarios,\nobtaining high-caliber domain knowledge can be\nchallenging due to complexities and noisy\noperational conditions, subsequently impacting the\nmodel's robustness. Secondly, many of these\nmodels struggle to perform effectively in real-time\nsettings, thereby curtailing their adaptability [23].\n\nConversely, data-driven models discern patterns\nfrom historical data, enabling informed decisions\nbased\non\nsensor-derived information [27].\nMoreover, the proliferation of advanced computing\ndevices and sophisticated sensors heightens the\nappeal of these data-driven condition monitoring\nsystems [29]. Therefore, this research integrates a\ndata-driven framework that leverages the data\nacquired from sensors as input to the model. Sensor\ndata consists of time series data that are sampled\nand presented sequentially [24]. The data is\nprocessed by an algorithm in two distinct phases:\nfirstly, the model is trained using historical data,\nand subsequently, the model is tested using current\ndata."}, {"title": "1.2USE OF BEARING DATA", "content": "The data is collected through various sensors\nstrategically placed on critical components of\nmachinery. Among these components, bearings\nplay a crucial role, particularly in heavy-load\nmechanical systems like turbines [7, 8, 14, 21].\nBearings are vital for guiding and supporting\nrotating machine shafts. Given the demanding\noperational conditions, even a minor fault in\nbearings can lead to catastrophic consequences for\nthe machinery, resulting in substantial financial\nlosses [2]. Consequently, there exists a paramount\nneed to swiftly detect bearing faults and embrace a\nproactive maintenance approach [6, 20].\nConsidering the pivotal role of bearings in plant\noperations and the frequency of related faults, this\nresearch concentrates on designing a prognostic\nmaintenance system. The objective is to forecast\nbearing faults by analyzing the vibration data\ngathered from embedded sensors. The proposed\nsolution employs an Artificial Intelligence (AI)\nmodel built on the LSTM algorithm. The primary\ngoal is to effectively anticipate and predict faults\noccurring in hydropower turbine bearings."}, {"title": "1.3LITERATURE REVIEW", "content": "Researchers globally have been actively engaged\nin forecasting bearing failures using diverse Al\ntechniques, including Machine Learning (ML)\nalgorithms like Deep Neural Networks (DNNs).\nNumerous studies have applied these methods to\nprognostic maintenance in renewable energy\nsystems. AI stands out in comparison to\nconventional data processing methods due to its\nproficiency in modeling the unpredictable and non-\nstationary characteristics of nonlinear data [23].\nTherefore, comprehensive research has been\nconducted on the application of various ML\nalgorithms, including Artificial Neural Networks\n(ANNs) and DNNs, for predictive maintenance\npurposes. This research encompasses algorithms\nlike Feed Forward Neural Network, Recurrent\nNeural Network (RNN), and Convolutional Neural\nNetwork (CNN), and has been extensively\nexplored [34]. CNNs have the capability to\nautonomously capture features and generate\nmeaningful representations of time series data,\nthereby eliminating the need for manual feature\nengineering [4]. Capability of 1D CNN time-series\nforecasting has been explored in [4]. 1D-CNN and\nBiLSTM implementation tutorial have been\npresented in [38] to predict peak electricity demand\nand price. Recently, deep learning has captured the\ninterest of researchers due to its capability to model\nintricate nonlinear traits, effectively extracting\nintrinsic structures and valuable features from raw\ndata [18]. Literature underscores the remarkable\npotential of deep learning across diverse domains,\nincluding Natural Language Processing (NLP)\n[10], Computer Vision (CV) [11], and Fault\nDiagnosis [12]. Other than the application in CV\nand NLP, various types of transformers have been\nexplored in [36, 37] which are being used to\ninterpret time-series modeling. Similarly, DNNS\nhave shown encouraging outcomes in the\nprediction of renewable energy system prognosis\n[23]. Chen et al. [13] developed a CNN-based deep\nlearning algorithm for carrying out gearbox fault\ndiagnosis.\n\nAs previously mentioned, bearings, being integral\nto rotating machinery, operate under strenuous\nconditions, leading to a relatively high occurrence\nof faults. Any malfunction in bearings can result in\nproduction losses, equipment damage, and\npotential safety risks [14]. However, timely\ndetection of these bearing faults enhances\nmachinery reliability and performance [3].\nNumerous techniques have been explored in the\nliterature to accurately detect bearing faults. In the\nrealm of time series analysis, RNNs exhibit\nfavorable performance. Nevertheless, conventional\nRNNs struggle with extended sequences due to\nissues like gradient vanishing and exploding [15].\nThis challenge is effectively mitigated by LSTM\nnetworks, which excel in managing long-term data\ndependencies [5, 22]. Jiujian Wang et al [25]\ndeveloped a Bidirectional LSTM (BiLSTM) model\nfor estimating the Remaining Useful Life (RUL) of\nbearings using the C-MAPSS turbofan engine\ndataset, by NASA. Cheng-Geng Huang et al [26]\nand Zhao R et al [27] also developed a novel\nprognostics framework based on BILSTM\nnetworks for achieving more accurate estimation of\nRUL and prediction of engineered systems that are\nsubject to complex operational condition.\nLikewise, Jianling Qu et al [3] developed a stacked\nLSTM model for identification and recognition of\nfaults in rolling bearings.\n\nUnlike the models specified earlier in the section,\nthat either uses time-domain features for training\nand testing the model or carry their analysis in\nfrequency domain, this research is focused on\ndeveloping a fault prognostics model that uses raw\nvibration signals generated by the turbine guide\nbearings of a real hydro power project. This will\nnot only help in reducing the need for extensive\ndomain knowledge but will also help in better\ngeneralization of the model.\n\nThe rest of this paper is organized as follows.\nSection 2 provides a detailed description of the\nmethodology including an introduction to the\nLSTM model and its comparison with other\nmodels, section 3 discusses the results generated in\nthe research, whereas section 4 concludes the\npaper."}, {"title": "2. METHODOLOGY", "content": "The research is structured into two main phases.\nFirstly, the developed model undergoes training\nand testing using bearing vibration data generated\nby a test rig. This dataset is sourced from the\nPrognostic Data Repository of NASA. The dataset\nwas made available to be used publicly by the\nCenter of Intelligent Maintenance System (IMS) at\nthe University of Cincinnati [32]. Secondly, the\nmodel is trained and tested with authentic vibration\ndata from bearings collected through the SCADA\nsystem at the Neelum Jhelum Hydro Power Project\n(NJHPP), a 969MW facility operating in Pakistan.\nThe results are assessed using the Root Mean\nSquare Error (RMSE) as an evaluative metric."}, {"title": "2.1. Model Selection (Why LSTM?):", "content": "RNNs were originally introduced to address time\nsequence learning challenges [2,15]. While\nconventional neural networks are structured as\nmultilayer networks capable of mapping input data\nsolely to target vectors, RNNs have the unique\ncapability of retaining information from previous\ninputs throughout the sequence. Like many other\nneural networks, RNNs utilize the backpropagation\nalgorithm for training. However, they encounter a\nchallenge during backpropagation known as\nvanishing gradients [19]. This issue arises as\ngradients shrink when propagated backward\nthrough time, dwindling to a point where their\nimpact on learning becomes minimal.\nConsequently, traditional RNNs face limitations in\ncapturing extended temporal dependencies within\ntime series data. This drawback is mitigated by\nLSTM networks, which employ Forget gates to\ngovern the flow of information between different\ncell states. This mechanism effectively addresses\nthe processing of lengthy sequences within the data\n[17]. Consequently, to effectively capture\nexpressive representations and nonlinear dynamic\nfeatures within time series data, LSTM networks\nexcel over traditional RNNs. This superiority arises"}, {"title": "2.2. Long-Short Term Memory (LSTM)", "content": "The LSTM represents a type of second order RNN\nnetwork structure acknowledged for its capability\nto store sequential short-term memories and\neffectively recall them even after several time-\nsteps [16, 31]. LSTMs incorporate recurrent\nconnections, thereby utilizing the context derived\nfrom previous time steps' neuron activations to\ngenerate an output. Comprising four essential\ncomponents, LSTMs manage information flow.\nThe memory cell, or cell state, is responsible for\ndata retention. The forget gate determines the data\nto be retained or discarded via a sigmoid function.\nThe input gate facilitates the addition of new\ninformation or memory cell updates, while the\noutput gate extracts data from the memory cell.\nThrough a tanh function, the information is\nprocessed, producing meaningful context that\nserves as both an output and an input for the\nsubsequent cell. These gate mechanisms operate\nacross the temporal axis, capturing intricate long-\nterm dependencies at each time step. Refer to\nFigure 2 for an illustration of the fundamental\nLSTM unit architecture.\nDuring each time step t, the hidden state \\(H_t\\)\nundergoes an update by combining information\nfrom various sources, including the data at the\nsame step Xt, the input gate It, the forget gate Ft,\nthe output gate Ot, the memory cell Ct, and the\nhidden state from the previous time step Ht-1. This\nprocess is described by the following equations:\n\n\\(I_t = \\sigma( W_i X_t + V_i h_{t-1} + b_i )\\)\n(1)\n\n\\(F_t = \\sigma( W_\u00a3X_t + V_f H_{t-1} + b_f )\\)\n(2)\n\n\\(O_t = \\sigma( W_oX_t + V_o H_{t-1} + b_o )\\)\n(3)\n\n\\(C_t = F_t C_{t-1} + I_t \\tanh( W_cX_t + V_c\nHt-1+b_c)\\) (4)\n\n\\(H_t = O_t \\tanh(C_t)\\)\n(5)\n\nIn equations (1 to 5), the model parameters denoted\nas \\(W\\in R^{dxk}\\), \\(V \\in R^{dxd}\\), and \\(b \\in R^d\\), are learned\nduring training process and are consistently applied\nacross each time step. Where, the sigmoid\nactivation function is represented by \u03c3, the\nelement-wise product is denoted by , and the\ndimensionality of the hidden layers is defined by a\nhyper parameter k.\n\nThe predicted output, which is the future bearing\nvibration values, is generated through a linear\nregression layer, which is formulated by the\nfollowing equation:\n\n\\(Yi = WrhTi\\)\n(6)\n\nIn Equation 6, the model predicts the sixth value\nusing the first five values (1-5) from the input, and\nsubsequently predicts the seventh value using input\nvalues (2-6), and so on.\n\nThe dimensionality of the output are represented by\n\\(W_r \\in R^{kxz}\\). Wr is the weight matrix associated with\nthe reset gate, having k rows and z columns.\nDuring the model training, cross-entropy serves as\nthe loss function, measuring the disparity between\nthe desired target label distribution p(x) and the\npredicted label distribution q(x). The cross-entropy\nbetween p(x) and q(x) is given by:"}, {"title": "2.3. Data Acquisition and Pre-\nprocessing", "content": "Loss = H(p,q) = \u2212\u2211x p(x)log(q(x)) (7)\n\nThe activation function plays a crucial role in\nallowing the network to capture nonlinear patterns\nwithin the input signal. This ability enhances the\nnetwork's capacity to learn discriminative features\nthat contribute to its overall representation power.\nLSTM, on the other hand, capitalizes on both the\nspatial and temporal attributes present in raw\ntemporal data, mirroring the memory mechanisms\nof the human brain. This unique characteristic,\npositions LSTM-based architectures to potentially\nachieve greater accuracy in the realm of fault\nprognostics.\nDuring this research, two distinct sets of data have\nbeen acquired. The initial set encompasses bearing\nvibration data obtained from a test rig, while the\nsubsequent set encompasses authentic data sourced\nfrom an operational hydro power project located in"}, {"title": "2.3.1. IMS Dataset", "content": "Pakistan. Additional details regarding these\ndatasets are expounded upon in the subsequent\nsections.\nIn the initial phase, the model was trained\nemploying the dataset furnished by the Intelligent\nMaintenance System (IMS) at the University of\nCincinnati [32]. The comprehensive particulars of\nthe IMS Dataset test rig setup are illustrated in\nTable 1."}, {"title": "2.3.2. Neelum-Jehlum Hydropower\nProject Dataset", "content": "Bearing vibration data for a period of twelve\nmonths, recorded by the SCADA system installed\nat 969MW NJHPP Pakistan, have been acquired.\nFour number of units (turbines), each having a\ngeneration capacity of 242.25 MW are installed at\nNJHPP [30]. The data used in this research was\nrecorded from the horizontal vibration runout\nsystem of the Turbine Guide Bearing installed at\nUnit No. 01. The reason being a fault had occurred\nin the Turbine Guide Bearings of Unit 01 during\noperation, hence the data contained both clean and\nfaulty data points.\n\nFurthermore, the reason for acquiring twelve-\nmonth data is to encompass both the lean water\nperiod where turbines face a lot of turbulence and\nthe peak season where turbines normally operate\nseamlessly. Figure 6 shows the plot of the overall\nrecorded data."}, {"title": "2.3.3. Data Preprocessing", "content": "The pre-processing of the data to mitigate concerns\nrelated to noise, data redundancy, and missing\nvalues. Following this, an outlier removal\nprocedure was implemented. Due to the differing\nranges of the data collected from both sources,\nnormalization was performed using the Minmax-\nscaler function outlined in Equation 8.\n\nx' = \\frac{x-\\text{min} (x)}{\\text{max}(x)-\\text{min}(x)} (8)\n\nWhere the original value is represented by x and\nthe normalized value is represented by x'.\nRescaling the data had a dual impact \u2013 not only did\nit contribute to improving the model's ability to\ngeneralize, but it also expedited the learning\nprocess and facilitated faster convergence rates."}, {"title": "2.4. Model Training and Testing", "content": "The IMS dataset consists of three distinct run-to-\nfailure experiments. Following experiment 02 and\nexperiment 03, based on dataset 2 and 3,\nconsecutively, outer-race faults were experienced\nin bearing 1 and bearing 3, respectively. Therefore,\ndataset 02 serves the dual purpose of training and\ntesting the model. Dataset 03, however, is only\nused for testing to provide an additional layer of\nperformance validation."}, {"title": "3. RESULTS AND DISCUSSION", "content": "To begin, the 984 files within dataset 02 are\ndivided into training and testing sets, maintaining a\n70:30 ratio. This allocation dedicates 70% data to\nmodel training and 30% to model testing. The\nmodel's performance is subsequently assessed\nusing dataset 03, which comprises 4448 files. Once\nthe model has undergone training, testing, and fine-\ntuning with the IMS dataset, its evaluation extends\nto bearing vibration data from NJHPP. Table 2\nshowcases the parameters of the developed stacked\nLSTM model.\n\nThe evaluation of the proposed model's\nperformance relies on the Root Mean Square Error\n(RMSE), calculated using equation 9. This choice\nof metric is driven by the consideration that\nsignificant errors can lead to unfavorable outcomes\nin prognostics. Hence, RMSE proves to be a\nvaluable evaluation measure due to its emphasis on\nlarger error values.\n\n\\(RMSE = \\sqrt{ \\frac{1}{n} \\Sigma_{i=1}^n(Y_i \u2013 \\widehat{Y}_i)^2 }\\)\n(9)\n\nWhere, yi represents the actual values and \u0177i\nrepresents the predicted values.\nThe model's performance was evaluated using both\nthe IMS dataset and the Neelum Jhelum dataset.\nThe outcomes demonstrate that the model\neffectively forecasted future bearing vibration\nvalues, yielding remarkably low RMSE scores.\nThe testing conducted on data from two distinct\nsources also affirms the model's ability to\ngeneralize well. Regardless of the data's origin, the\nmodel exhibited efficient predictive capabilities for\nbearing vibrations, thereby mitigating the necessity\nfor extensive domain expertise."}, {"title": "3.1. Test Results \u2013 IMS Dataset", "content": "The model's performance was evaluated against\ndataset 02 and dataset 03. The graphical\nrepresentation of predicted and actual vibration\nvalues is illustrated in Figure 7 (a) and (b), where\nblue indicates actual values and orange denotes\npredicted values. The plot clearly demonstrates the\nmodel's accurate prediction of bearing vibrations,\ntracking the degradation trend until the fault\noccurrence. Additionally, the RMSE values for\ndataset 02 and dataset 03 were calculated as 0.0145\nand 0.0102, respectively.\nThese RMSE values signify a minimal disparity\nbetween actual and predicted bearing vibration\nvalues, validating the precision of the developed\nmodel. Furthermore, during the testing on dataset\n03, the performance of the model was evaluated\nusing other metrices including Mean Absolute\nError (MAE), Normalized Mean Absolute Error\n(NMAE) and Mean Absolute Percentage Error\n(MAPE). The results are depicted in Table 3"}, {"title": "3.2. Test Results \u2013 NJHPP Dataset", "content": "The model's performance was evaluated using data\nfrom the NJHPP, and the outcomes are illustrated\nin Figure 8. This figure displays the graph of the\nactual and predicted vibration values of the\nbearings. The actual vibration values is indicated\nby blue color, whereas the green and red colors\ncorrespond to predictions during the training and\ntesting phases, respectively.\n\nThe plot clearly demonstrates that the model\naccurately predicts both normal and faulty bearing\nvibrations, closely following the observed trends.\nFurthermore, the RMSE of the predicted values for\nthe NJHPP dataset was exceptionally low,\nmeasuring only 0.11. This result indicates the\nmodel's effectiveness in accurately forecasting\nvibration data values, regardless of the data source."}, {"title": "4. CONCLUSION", "content": "The analysis underscores the promising outcomes\nof the developed LSTM model. The remarkable\naccuracy in predicting vibration data not only\nunderscores its efficacy but also diminishes the\nnecessity for profound domain expertise. This\ndiscovery indicates that the model possesses\nsignificant capabilities and adaptability in handling\ndiverse data sources, rendering it a valuable asset\nacross various applications.\nThis research primarily focuses on the\ndevelopment of an LSTM-based model for\nconducting fault prognostics in hydropower plant\nbearings. LSTM holds an advantage over other\nalgorithms due to its capacity to diminish the\nnecessity for expert domain knowledge and\nintricate feature engineering. This advantage arises\nfrom its deep architecture and hierarchical feature\nextraction, which endows the learning model with\nthe potential to effectively discern intrinsic patterns\nwithin time series data. Moreover, the\nincorporation of forget gates in LSTM enables the\ncapture of long-term dependencies. Consequently,\nLSTM adeptly identifies and unveils significant\nfeatures within sensory signals while executing\nbearing fault prognostics in hydropower plants\n(HPPs).\n\nThe proposed model is meticulously trained and\ntested using the IMS dataset derived from a\ndedicated test rig. The outcomes of these tests\nshowcase that the model has achieved remarkably\nlow RMSE values and proficiently projected the\nforthcoming vibration states of the bearings,\naccurately detecting faults as well. In the\nsubsequent research phase, the model's\nperformance is evaluated using real vibration data\ncollected from the SCADA system of the Neelum\nJhelum Hydropower Plant (NJHPP) operating in\nPakistan. Once again, the results underscore that\nthe model has attained a remarkably low RMSE\nvalue and effectively anticipated and traced the\ntrends within bearing vibration data.\n\nGiven that the developed LSTM model\nconsistently attains impressive outcomes by\nprecisely forecasting future bearing vibration\nconditions within a hydropower plant, it holds the\npotential to empower HPP operators to anticipate\nsuch faults in advance. This not only curtails\nmaintenance expenses but also ensures continuous\nplant availability\u2014a crucial aspect, particularly in\ndeveloping nations like Pakistan. In such regions,\nwhere electricity demand outpaces supply and\nunscheduled plant downtimes further jeopardize\nenergy security, this research's findings carry\nsubstantial significance. Additionally, while this\nresearch's scope pertains primarily to hydropower\nprojects, its applicability can extend to other green\nenergy generation ventures, such as wind power\nprojects, considering that bearings also play a\npivotal role in wind turbines."}, {"title": "Statements and Declarations", "content": "In the interest of full transparency, we disclose that\nthe authors have no competing interests related to\nthis research. There are no financial, personal, or\nprofessional conflicts of interest that could\ninfluence the interpretation or presentation of the\nfindings in this manuscript."}, {"title": "Data Availability Statement:", "content": "The data used to support the findings of this study\nhave been deposited in the figshare repository [35].\n(https://doi.org/10.6084/m9.figshare.21290895)."}]}