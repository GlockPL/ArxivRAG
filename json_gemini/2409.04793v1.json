{"title": "Action is the primary key: a categorical framework for episode\ndescription and logical reasoning", "authors": ["Yoshiki FUKADA"], "abstract": "This research presents a computational framework for describing and recognizing episodes and\nfor logical reasoning. This framework, named cognitive-logs, consists of a set of relational and graph\ndatabases. Cognitive-logs record knowledge, particularly in episodes that consist of \"actions\" rep-\nresented by verbs in natural languages and \"participants\" who perform the actions. These objects\nare connected by arrows (morphisms) that link each action to its participant and link cause to effect.\nOperations based on category theory enable comparisons between episodes and deductive inferences,\nincluding abstractions of stories. One of the goals of this study is to develop a database-driven artifi-\ncial intelligence. This artificial intelligence thinks like a human but possesses the accuracy and rigour\nof a machine. The vast capacities of databases (up to petabyte scales in current technologies) enable\nthe artificial intelligence to store a greater volume of knowledge than neural-network based artificial\nintelligences. Cognitive-logs serve as a model of human cognition and designed with references to\ncognitive linguistics. Cognitive-logs also have the potential to model various human mind activities.", "sections": [{"title": "Introduction", "content": "Implementation of logical reasoning on computer systems has been an important research topic in the\nfield of computer science. Logical reasoning processes like \"if A then B\" have been computerized for a\nlong time. A notable achievement in this area is the development of the logic programming language\nProlog[1]. The Prolog language has been successfully applied to various systems, such as expert systems[2].\nRepresentations of knowledge in graphical network has also been a long-standing area of study. Semantic\nnetworks were introduced as directed labelled graphs [3]. Later, a more restricted concept-knowledge\ngraphs was defined[4]. By applying category theory, ontology logs, or ologs, were introduced[5].\nWhile logic programming has a long research history and numerous successful outcomes, its application\nto real-world scenarios has been limited. The challenge in such real-world applications lies in episode\ndescription. In a logic depicted by the \"if A then B\" formula, A and B are not merely objects but\nscenarios, necessitating comparisons of real episodes to these scenarios. No model has yet been developed\nfor making such comparisons between episodes or scenarios.\nThe developments in neural network-based artificial intelligence show significant progress. The in-\nvention of the transformer [6] is a prominent milestone. However, current neural network-based artificial\nintelligences do not yet seem to replicate human thinking. Services that use large-scale language models\nprovide \"wonderful\u201d responses, giving the impression that \u201clogical reasonings in artificial intelligence has\nbeen realized.\" Nevertheless, their learning processes require an enormous amount of data. In contrast,\nhumans are capable of learning from even a single experience. Moreover, these large-scale language\nmodels are \"black boxes,\" hence they lack explainability.\nSome arthropods exhibit amazing intelligences. Even common spiders demonstrate impressive abilities\nin constructing their webs. Human brains have extremely large frontal lobes, with the number of neurons\nbeing 106 times greater than that of arthropods. It is questionable what accounts for the difference in"}, {"title": "Structure of episode recognition", "content": ""}, {"title": "Graphical image", "content": "Consider a most simple episode, \"Bob loves Alice.\" If one draws a graphical network representing this\nepisode, the network may look as follows:\n\u300cBob $\\xrightarrow{\\text{loves}}$ Alice.   (1)\nThis graph well describes our image. An introspection may illustrate such a vector image that point\nfrom the subject to the object. In addition, we (humans) also have vector images for causal relationships,\nwhich point from a cause to its effect. Figure 1 illustrates an example of a causal chain model proposed\nby Croft[8, 9].\nIn category theory, an arrow represents only the mapping between objects and does not involve\ninformation about \"what is love?\". An appropriate conversion of the graph to a category is as follows:\n\u300cBob$\\xrightarrow{\\text{source}}$\u300cloves$\\xrightarrow{\\text{target}}$\u300cAlice.   (2)\nThis form allows the network to involve information concerning \"love.\" However, this structure with\ntwo arrows from an action makes it difficult to apply the functor search described below. This network\nstructure is not symmetric between Bob and Alice. This asymmetry makes it difficult to deal with each\nmember individually."}, {"title": "Action is primary entity", "content": "The motivation of this study is to recreate the thought process of humans. Human cognitions are classified\ninto things-like elements and process-like elements, which correspond to nouns and verbs, respectively [10]."}, {"title": "\u201cdo\u201d-\u201cbe done\u201d decomposition", "content": "In natural languages, the basic components of a sentence are the subject, verb, and object. Although\nthere are wide variations in their grammars, these basic components are common among human natural\nlanguages. This fact implies that the pair of subject and object is a basic unit of our episode recognition.\nAmong the various research items of linguistics, causatives have been attracting the attention of\nresearchers. An example of a typical causative sentence is \"Bob opened the door.\" This sentence can be\ndecomposed into the following two elements: \"Bob let the door open\" and \"The door opened.\" These\ntwo elements are then bounded by a causal relationship (Fig. 1). Such a correspondence between the\ntransitive verb \"let open\" and the intransitive verb \"open\" is a quite common phenomenon among various\nlanguages.\nThe episode \"Bob loves Alice\" may has a hidden causative structure. As a result of Bob's love, Alice\nis in a situation of \"being loved.\" Namely, the action \"loves\" is decomposed into the pair \"loves\" and \"is\nloved.\" This \"do\u201d-\u201cbe done\u201d decomposition enables a symmetric description concerning Bob and Alice.\nAccording to observations of language development of young children [13], children develop indepen-\ndent grammars for each verb after they have acquired uses of single elements. Most of these grammars are\ncombinations of subject-verb, while combinations of subject-verb-object elements seems more advanced.\nThe unit of subject-verb combination is thus an essential unit of episode description."}, {"title": "E-log: categorical episode description", "content": "This section describes the design of an episode description using graphical networks as a straightforward\nimplementation of the considerations above. The networks are organized into categories. The details are\npresented below."}, {"title": "Action and participant", "content": "A natural language reflects human cognition mechanisms. Accordingly, an academic field that seeks to\nunderstand human cognition through linguistics, namely cognitive linguistics, was presented [15]. This\nresearch extensively uses the outcomes of cognitive linguistics. The term \"participants\" in cognitive\nlinguistics is used for subjects and objects.\nAn episode consists of multiple actions and participants who perform these actions. A participant\nusually takes multiple actions. For example, Bob loves not only his wife Alice but also his son Mike. The\nnetwork must depict his distinct loves as \"love1\u201d and \u201clove2.\" Applying the \"do\"-\"be done\" decomposi-\ntion to each love, Alice and Mike act as \"be loved1\" and \"be loved2\" respectively.\nA category consists of domains, co-domains, and arrows, where an arrow points from a domain to\na co-domain. A domain emanates one and only one arrow that belongs to a set of arrows. An action\nhas one and only one participant. The connections between actions and participants are a set of arrows\nlabelled \"who,\" where an arrow points from an action to a participant who performs the action."}, {"title": "Causal relationships", "content": "Alice is loved because Bob loves her. The connection between \"love1\" and \"be loved1\" is a causal\nrelationship. This connection is also represented as an arrow.\nLinguistics studies on number of languages suggest that causality is an essential part of our cognition [12,\n14]. Causal relationships in the real world are complex, involving both necessary conditions and sufficient\nconditions within a cause-and-effect episode. An effect occurs under multiple necessary conditions, but\nan effect occurs due to one and only one sufficient condition. (In other words, the sufficient condition\nis \"the last piece\u201d of the necessary conditions.) Here, an action represents an event. If we assume that\nan event is a necessary condition for anther event, the following arrows can be considered arrows of a\ncategory:\n\u2022 Arrows of \u201ccause-S\u201d (sufficient conditions), where each arrow points from an action to its causal\naction\n\u2022 Arrows of \u201ccause-N\u201d (necessary conditions), where each arrow points from an action to its resultant\naction\nNote that arrows in category theory do not represent time flows or process sequences but mappings.\nArrows of \"cause-S\" point to the past, and arrows of \"cause-N\" point to the future.\nA pair of arrows \"cause-S\" and", "cause-N,": "epresents a causal relationship with a necessary and\nsufficient condition, respectively. The network of Bob and Alice is illustrated in Fig. 2. This study refers\nto such networks as episode-logs or \"e-logs.\""}, {"title": "Trivial causal-relationships", "content": "The events \"Bob loves\" and \"Alice is loved\" are in a \"do\"-\"be done\" relationship. These events are\nconnected by causal-relationships. These actions, \"loves1\u201d and \u201cbe loved1,\" is connected by a pair of\narrows \u201ccause-N\u201d and \u201ccause-S.\u201d This research regards such a causal relationship based on \u201cdo\u201d-\u201cbe\ndone\" decomposition as a \"trivial causal relationship.\"\nIn a trivial relationship, each \"do\" and \"be done\" has the same time-stamp, and an exchange of their\n\"cause-S\" and \"cause-N\u201d arrows preserves the aforementioned preorder relation.\nIt should be noted that a pair of \"do\" and \"be done\" is not always a trivial one. As mentioned above,\nour cognitive image creates vectors that point to an object from a subject. When the vector image is\nstrong, the actions \"do\" and \"be done\" usually have a time lag, like when an arrow shot in an attack hits\nthe target after it was shoot. Such a relation is a non-trivial causal-relationship. The time lag indicates\nwhether the relation is trivial or non-trivial, and the \"do\"-\"be done\" pair represents the vector image."}, {"title": "Nontrivial causal-relationships", "content": "Consider an episode where a robot carried a dolly loaded with a bottle. The e-log for this episode is\nillustrated in Fig 4. Here, the bottle was carried by the dolly, because the dolly was carried. There is\na physical law that \"loaded things are carried when the dolly is carried.\" Reflecting this law of vehicle,\na causal relationship s3 and n3 is applied between \"was carried0\" and \"carried load\" of the dolly. This\ncausal relationship is a typical \"non-trivial\" causal relationship which does not come from a \"do\u201d-\u201cbe\ndone\" decomposition.\nThe relationship between \"was carried1\u201d and \u201ccarried load\" is trivial, and there is another necessary\ncondition that the bottle stays in the dolly. Accordingly, the \"cause-N\" arrow n5 depicts this.\nFigure 5 shows another case of a non-trivial causal relationship. A person, Mr. Bond, was injured due\nto an explosion. The necessary conditions for Mr. Bond's injury were the explosion and his proximity"}, {"title": "Construction of e-log as category", "content": "Consider a category of sets $X \\rightarrow Y$. The arrows must satisfy the requirements of a function. For every\nelement $x \\in X$, there is exactly one arrow emanating from x, but for an element $y \\in Y$, there can be\nseveral arrows pointing to y, or there can be no arrows pointing to y [17].\nThe e-log of \"Bob and Alice\" in Fig. 2 is a category of elements. When converting the e-log into a\ncategory of sets, the above requirements must be satisfied. Namely, \"loves\" must emanate an arrow of\n\"cause-S,\u201d and \u201cis loved\u201d must emanate an arrow of \u201ccause-N,\" This can be achieved by adding a virtual\naction of \"nothing\u201d or \u201cunknown\" and emanating arrows of \"cause\" from these actions into the relevant\nelements. Emanating arrows into the action itself is also a possible choice. Emanating arrows of \"who\u201d\nfrom \"nothing\u201d and \u201cunknown\" into a virtual participant \"nobody\" complete the requirement.\nAs another rule of category theory, each object in a category has an identity morphism. This paper\nonly indicates identity morphisms when it is necessary to be shown.\nBob and Alice are members of the set \"participants,\" and \"nobody\" as well. The actions \"loves,\"\n\u201cis loved,\u201d\u201cnothing\u201d and \u201cunknown\u201d are members of the set \u201cactions.\u201d Thus the e-log can be converted\ninto a category of sets. The structure of e-logs as a category of sets is illustrated in Fig. 6.\nAction as participant In most languages, a verb can be converted to a noun. For example, \"attempt\"\nfunctions both as a verb and a noun. This word is used in the following example:\n\"Bob attempted a criminal act, and Mike blocked Bob's attempt.\"\nThis example shows that we recognize the action \"attempt\" both as an object and as a predicate to\nbe acted upon. Thus, the set of actions is a subset of participants:"}, {"title": "Cognitive-logs as databases", "content": "A relational database [18] satisfies the requirements of a category. A category of sets can be converted\ninto a relational database [19, 20]. A database consists of tables. A domain (object that emanates arrows)\nof the category is a primary key in a table, and its codomains (object where arrows points) are alternate\nkeys of the table. An e-log is converted into a relational database which the primary key is \"actions\"\nand the foreign keys of \u201cwho,\u201d \u201ccause-S,\u201d and \u201ccause-N.\" The relational table for the \"Bob loves Alice\"\nepisode is shown in table 1. The indications in the table using English words are for the clarity of readers.\nIn a realistic implementation, entities are recorded using unique IDs.\nThere are other database that are also categories. One is the \"raw-data link\" (Fig. 7), which provides\nconcrete and detailed features of these objects. The next subsection introduces another database called\n\"be-log,\" which records static relationships such as similarities. The subsequent section introduces \"s-log\"\nwhich represents knowledge of laws and rules. This study calls the set of these networks as \"cognitive-\nlogs.\" Consider an artificial intelligence that uses cognitive-logs. With the spread of social networking\nservices, current databases technology is now able to handle enormous amount of data, even on a petabyte\nscale [21]. This scale of data capacity dwarfs that of any other neural-network-based artificial intelligence.\nThe potential of cognitive-logs is promising."}, {"title": "Similarity, association, classification, and description of char-\nacteristics", "content": ""}, {"title": "Be-logs", "content": "Our basic cognition involves classification, such as \"a pigeon is a bird.\" Such classifications are based on\nsimilarity recognition, which is implemented through associations. These cognitions are mostly expressed\nusing a be-verb and hold a special (more essential) position. Be-logs are categorical networks for similarity,\nassociation, classification, and description of characteristics. The name \"be\" represents be-verbs.\nSimilarity is an essential part of cognition. Our similarity recognition has the following two charac-\nteristics.\n\u2022 Asymmetry: The similarity of A to B is not necessarily equal to the similarity of B to A [22]."}, {"title": "Theory of classification", "content": "This subsection introduces two theories of classification. One is quite rigorous and deductive, while the\nother is intuitive but well-models our cognition. Be-logs effectively depict both theories."}, {"title": "Classification based on characteristics", "content": "A be-log records the characteristics of participants. A set of characteristics defines a class. For example,\nthe class \"birds\" is defined as: having a beak, being covered with feathers, having wings, and laying eggs.\nClassification is hierarchical. The class \"Aves\" (birds) is classified into orders (in biological terminol-\nogy) such as Galliformes (turkeys, chickens, or other heavy-bodied ground-feeding birds), Columbiformes\n(pigeons and doves), and others. Birds in each order retain the characteristics of Aves; namely, the set of\nAves' characteristics is a subset of the set of characteristics for each order. These relationships correspond\nto a tree of classification.\nConsider classes A and B, and their set of characteristics, Ch(A) and Ch(B). If A belongs to B\n(A\u2286B), then Ch(B) is a subset of Ch(A) (Ch(A) \u2265 Ch(B)).\nThis relationship induces a definition of similarity based on characteristics as follows:\n$S_{A\\rightarrow B} = \\frac{|Ch(A) \\cap Ch(B)|}{|Ch(B)|}$   (8)\nwhere $S_{A\\rightarrow B}$ is the similarity indicating that A resembles B, and | | denotes the number of elements in\na set. Using this definition, $S_{A\\rightarrow B} = 1$ means that \u201cA belongs to B\u201d and there is a preorder (A \u2264 B).\nThis similarity definition clarifies the applicability of a syllogism. Since a preorder relation is a category,\n$S_{A\\rightarrow B} = 1$ means $A \\rightarrow B$. A syllogism such as \"A is B. B is C. Therefore, A is C.\" is only applicable when\n$S_{A\\rightarrow B} = 1$ and $S_{B\\rightarrow C} = 1$. This syllogism corresponds to the composition of $A \\rightarrow B$ and $B \\rightarrow C$. This\nsimilarity definition can be extended to other kinds of feature matchings, such as point clouds or images.\nRecent advanced DNA analysis has replaced classical characteristics-based Linnaean taxonomy with\nevolutionary-tree-based classification. However, such characteristics-based classifications seem essential\nin our cognition."}, {"title": "Classification based on prototypes", "content": "An infant may recognize similarities between pigeons, crows, and some other birds, and create a group\nof similar members (birds). Such a process is considered to be an important part of our knowledge\nconstruction. In cognitive linguistics [15], a set of such similar members forms a class, and representative\nmembers (real world examples) of the class are called \u201cprototypes\".\nBetween prototypes, the \"degree of similarity\" can be evaluated. Since similarities are asymmetric,\nsimilarities in a class form a directed and weighted graph. An appropriate graph-analysis can define\na \"centre\" of the class and the \"distance\" from the centre to a prototype. These centre and distance\nconcepts are important in the theory of cognitive linguistics. For example, a \"pigeon\" is close to the\ncentre of \"birds,\" while a \"penguin\" is far.\nIt is possible to extract common features (characteristics) from the prototypes of a class and create a\nclass based on these characteristics. Classification based on prototypes is more primitive than that based\non characteristics."}, {"title": "Equivalence relation based on classification", "content": "Pigeons are birds and crows are also birds; therefore, pigeons and craws are the same as a kind of bird.\nThis kind of cognition can be modelled as an equivalence relation based on classification. A part of a\nbe-log concerning classifications forms a span on participants and classes. A pullback of the composite\nspan yields an equivalence relation (Fig. 9). Such an operation extracts objects that have a common\ncharacteristics, such as \"red objects.\""}, {"title": "Types of be-verbs", "content": "This research regards be-like verbs as verbs that do not indicate an event but a static relationship. For\nsuch a relationship, \u201cdo\u201d-\u201cbe done\u201d decomposition is not appropriate. It is interesting that the verb\n\"be\" has a wide range of uses. It should be noted that be-verbs have another meaning of \"existence\"."}, {"title": "Functor between cognitive-logs", "content": "Similarity recognition is one of our essential cognitive abilities. Recognizing similarity between episodes\nis also possible, and it enables logical reasoning. Abstractions of episodes converting an episode into\na simpler form are also important cognition processes. Functors are powerful tools in category theory.\nThis section shows that a functor between e-logs represents these inference processes.\nConsider e-logs & and E' as categories and a functor F from E to E'. The object function of Fis\ndefined as follow:\nOb(F) : Ob(E) \u2192 Ob(E')\nAnd a morphism function for objects $e_1, e_2 \\in E$ is defined as follow:\nHOMF(e1, e2): $Home(e_1, e_2) \\rightarrow Home'(e'_1, e'_2)$.\nwhere, $e'_1 = F(e_1)$ and $e'_2 = F(e_2)$, respectively.\nFigure 10 illustrates the mapping above. A functor is a structure preserving map. Its exposition can\nbe found in many excellent textbooks."}, {"title": "S-logs or scenario-logs as references", "content": "One of the simplest logical inference might be 1 + 1 = 2. However, this formula is invalid in Boolean\nalgebra. This simple example shows that \"absolute logic\" does not exist; instead we \"refer to rules.\"\nWe perform various complex logical inferences: future prediction based on physical laws, judgement\napplying ethical rules, and constructing a new idea by joining multiple laws and rules. All of these\ninferences are based on \"comparison with laws and rules.\" In a broader sense, laws and rules are \"reference\nscenarios.\" Logical reasoning is implemented as a comparison between an episode and reference scenarios.\nThese episodes and scenarios are represented with e-logs; hence, the comparison between them is a functor.\nCompleteness of a functor represents the similarity between an episode and a scenario.\nConsidering the above, s-logs or scenario-logs are presented as categories that have the same structure\nas e-logs. This definition is not strict. Just as we refer to our own experiences, an e-log that depicts a\nconcrete episode can be used as a reference."}, {"title": "Abstraction of an episode", "content": "Abstraction is one of the useful applications of functors among cognitive-logs. Consider a functor from\nan e-log, which depicts a concrete episode, into an s-log, which depicts an abstract scenario. Abstractions\nof the episodes \"a robot carries a dolly\" into \"a worker carries a cargo\" are illustrated in Fig. 11. In\nthe abstraction shown in Fig. 11a, the dolly and its actions are mapped into the worker and its action\n\"carried,\" respectively. Note that the \"cause\" arrows between these actions are mapped into the identity\nmorphism of \"carried\" for the worker. This abstraction illustrates that the robot carried the bottle, and\nit does not matter what tool was used to carry it."}, {"title": "Arbitrariness of abstraction", "content": "Functors between cognitive-logs often exhibit arbitrariness. Figure 11b depicts another functor that maps\nboth the dolly and the bottle into the cargo. This functor implies that it does not matter what the robot\ncarried. While the functor in Fig. 11a focuses on the bottle, and it does not matter what was used to"}, {"title": "Natural transformation", "content": "A natural transformation is a transformation between functors that preserves the internal structures of\nthe categories. However, no natural transformation can be found between the functors in Fig. 11a and\nFig. 11b. In this study, it was found that natural transformations are seldom seen among functors\nbetween cognitive-logs. As demonstrated above, different functors represent different perspectives of an\nepisode. A natural transformation reflects \"compatibility\" between these perspectives. Even if people\nsee the same scene, individual recognitions may differ."}, {"title": "Functors from s-log into e-log", "content": "An s-log represents abstracted knowledge. Functors from an s-log into an e-log usually omit many items\nin the e-log, i.e., such a functor is faithful but not full. Figure 12 shows such functors from an s-log into\nan e-log. Variation of functors, i.e., arbitrariness, can be seen. These functors may represent cognitions\nof paying attention to specific items in the episode; namely, the functor H and J pay attention to the\ndolly, while the functor K pays attention to the bottle. Among these functors, a natural transformation\nbetween H and J is possible, indicating that their perspectives are essentially the same. Thus, functors\nfrom an s-log into an e-log represent the \"extraction\" of \"core parts\" from an episode or story."}, {"title": "Inferences according to laws", "content": "It is no exaggeration to say that our intelligence evolved for the prediction of the future. If an s-log\ndepicts a law of nature and the e-log of the current situation can find a functor to the s-log, the functor\nmay predict the future."}, {"title": "Comprehension of a story", "content": "Comprehension Here, we define that a story consists of episodes. We recognize a story as a composite\nof many episodes, namely, the story is decomposed into many partial episodes. And each partial episode\nis further decomposed into elemental episodes. In the process of comprehension, these elemental episodes\nare abstracted. Then, abstracted elemental episodes in a group are composed into an abstracted partial\nepisode. These abstracted partial episodes are abstracted ones more. Finally, they are composed into the\nabstracted whole story. Figure 14 illustrates these hierarchical processes.\nAn extracted episode $\\mathscr{E}_n$ of a story can be depicted as a full subcategory of $\\mathscr{E}_{whole}$, where $\\mathscr{E}_{n}^{(i)}$ is\ni-th abstracted partial episode and $\\mathscr{E}_{whole}$ is the e-log of the whole story $[\\mathscr{E}_{n}^{(i)} = \\mathscr{E}_{whole}|_{Ob=X} \\text{ where }\\n X\\subseteq Ob(\\mathscr{E}_{whole})]$. We denote this relation using arrows with a mie line, as follows:\n$\\mathscr{E}_n \\dashv\\hspace{-0.3cm}\\mathscr{E}_{whole}$. (9)\nExtraction of core parts from a story (episode) is an essential process. It is commonly required in the\nprocess of cognitive-logs. Such records always contain unessential items as the background, so \u201cfiltering\u201d\nis required.\nAs described above, an abstraction is depicted as a full functor into an abstract s-log (knowledge of\nconcept, law, or pattern) or e-log (abstract of specific episode) as follows:\n$\\mathscr{S}^{(i)} \\xleftarrow{\\text{full}} \\mathscr{E}_n^{(i)}$ (10)"}, {"title": "Generation of s-logs", "content": "An e-log is a record of episodes, whereas s-logs represent knowledge. Manual installation of s-logs for\nan artificial intelligence, similar to how humans read books, is possible. However, automated knowledge\nacquisition from experiences, i.e., the conversion of an e-log into an s-log is an important process in\nlearning. Basically, s-logs are variants of e-logs, so, their structures are the same. The difference between\ns-logs and e-logs is that an s-log depicts a generalized scenario, whereas an e-log depicts an individual\nepisode. Hence, the description of s-logs must be as follows:\n\u2022 Participants are indicated using classes.\n\u2022 Timestamps are indicated as relative temporal orders.\nThe process to generate an s-log can be as follows: extract a partial e-log from the e-log that contains\nthe specific scenario, perform appropriate abstraction, and overwrite participants and timestamps."}, {"title": "Planning and invention", "content": "Planning and invention are the ultimate goals of applications of cognitive-logs. Such a process can be\nmodelled as an inverse process of story comprehension. It consists of the following steps:\n\u2022 Choose some s-logs from the storage of knowledge (s-logs).\n\u2022 Assemble an s-log so that the scenario ends with a preferable result.\n\u2022 Convert the s-log into an e-log of the plan by assigning each participant in the s-log to a participant\n(existing object) in the e-log.\nSince the number of possible combinations of s-logs will be huge, the computational cost seems high.\nThis is why such creative thinking is difficult."}, {"title": "Functor search and its evaluation", "content": "Cognitive-log is a cognition model. Its realistic manipulation accepts incompleteness of functors. When we\nobserve an episode, we try to understand it. Such an understanding is modelled as searching for a functor\nfrom the e-log into an s-log, where the s-log represents some knowledge. The feeling of \"understanding\"\nis modelled as obtaining high completeness of the functor. Thus, such evaluation of functor represents\nan important process of cognition."}, {"title": "Functor evaluation based on structure", "content": "A functor is a structural matching between categories. Mathematical completeness is the basis of functor\nevaluation. A homomorphism in a category can be represented using a logical matrix whose entries and\noperations are Boolean algebra. Here, we define E as the arrows of \"who,\" S as the arrows of \"cause-S,\u201d\nand N as the arrows of \u201ccause-N.\" Basically, a functor does not differentiate the type of arrows. However,\nthe rule of causality restricts the conversion, namely, an effect occurs after the cause. This relationship\ncan be satisfied by separating the conversions for S and N. The conversions of S and N satisfy the\nfollowing equations:\n$\\sum_{n=1}^{\\infty} (\\acute{S}_e + \\acute{N}_{Tri})^n + I_{ss} = P_s (\\sum_{n=1}^{\\infty} (\\acute{S}_s + \\acute{N}_{Tri})^n) P + I_{ss}$. (15)\n$\\sum_{n=1}^{\\infty} (\\acute{N}_e + \\acute{S}_{Tri})^n + I_{ss} = P_s (\\sum_{n=1}^{\\infty} (\\acute{N}_s + \\acute{S}_{Tri})^n) P + I_{ss}$. (16)\nWhere, the suffix e denotes the e-log and denotes the s-log respectively, Ps is the conversion matrix that\nindicates the mappings between actions. The computation must use Boolean algebra; namely, 1 + 1 = 1.\nIss is an identity matrix that represents the identity morphisms. Since these computations are Boolean,\nthe sums with the identity matrix cannot be removed. NTri and STri are \u201ccause\u201d arrows that belong\nto trivial causal-relationships. Since arrows of \u201ccause-S\u201d and \u201ccause-N\u201d in a trivial causal relationship\nare exchangeable, these exceptional handling are required. The sums of the power series of Ss and Se\nrepresent composites of \"cause\" arrows. Under the rule of causality, the \"cause\" matrices S and N are\nstrictly triangular matrix. Hence, $\\acute{S}^n$ and $\\acute{S}^n$ become zero for finite \u0144 and n. The power series may\nrapidly decay.\nThe conversion of E in a functor from an e-log into an s-log is as follow:\n$\\acute{E}_s = P_E E_e \\acute{P}_E$   (17)\nPE is the conversion matrix that indicates the mappings between participants.\nIf the functor is complete, $\\acute{E}_s = E_s$, $\\acute{S}_s = S_s$. Because the conversions are functions, there is one\nand only one entry of PE and Ps in each column whose value is 1, while the others are zero. Moreover,\nthe converted e-log must satisfy its functional relationship from actions to participants. Namely, if a\nparticipant does not have its morphism function into the s-log, its action(s) cannot have a morphism\nfunction into the s-log. This requirement falls under the following mathematical rule: if $P_E E_e \\acute{P}_E$ has a\ncolumn with all entries being zero, then all entries in the corresponding column (the column number is\nthe same as $P_E E_e \\acute{P}_E$) of Ps must be zero.\nS-logs are built so that all their objects are essential. That means the functor must be surjective. A\nsurjective functor satisfies the following requirement: at least one entry in each row of PE and Ps has to\nbe non-zero.\nIf all objects in the e-log are essential, the functor must be injective. An injective functor satisfies the\nfollowing requirement: at least one entry in each column of PE and Ps has to be non-zero.\nA complete functor satisfies the above rules. Incompleteness of the functor may indicate incom-\npatibility between the e-log and s-log; perhaps the s-log was inadequate. However, the incompleteness\nmay indicate things that are going to happen or hidden events that occurred in the past. An inference\naccording to the laws (\u00a75.6) applies to such a non-surjective functor."}, {"title": "Evaluation based on temporal order", "content": "Actions are linked to raw-data that depict the features of each action. The raw-data includes timestamps\nfor each action. If an effect occurs before its cause", "follow": "n$t_c \\acute{f} = o_{ac} t_a$  (18)\nand\n$o_{ab} t_a \\acute{g} = t_b$.  (19)\nWhere f and g are the \"cause-S\" and \"cause-N\" arrows, respectively, ta, to, and te are arrows from\nactions to their timestamps, and oac and oab are arrows of the order relation between the timestamps\nthat point from the future to the past. There is no causal relation between \"B\" and \"C,\" hence the\ntemporal order between them can be swapped. Conversely, the temporal order between \"A\" and the\nothers cannot be swapped. A consistent functor preserves the commutative relations in eqs. (18) and\n(19). The aforementioned functor evaluations based on eqs. (15) and"}]}