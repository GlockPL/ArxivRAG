{"title": "INTEGRATING LARGE LANGUAGE MODELS FOR GENETIC VARIANT CLASSIFICATION", "authors": ["Youssef Boulaimen", "Gabriele Fossi", "Leila Outemzabet", "Nathalie Jeanray", "Oleksandr Levenets", "St\u00e9phane Gerart", "S\u00e9bastien Vachenc", "Salvatore Raieli", "Joanna Giemza"], "abstract": "The classification of genetic variants, particularly Variants of Uncertain Significance (VUS), poses a significant challenge in clinical genetics and precision medicine. Large Language Models (LLMs) have emerged as transformative tools in this realm. These models can uncover intricate patterns and predictive insights that traditional methods might miss, thus enhancing the predictive accuracy of genetic variant pathogenicity. This study investigates the integration of state-of-the-art LLMs, including GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data alongside structural insights to form a comprehensive analytical framework for variant classification. Our approach evaluates these integrated models using the well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in classification performance. The models were rigorously tested on a set of challenging variants, demonstrating substantial improvements over existing state-of-the-art tools, especially in handling ambiguous and clinically uncertain variants. The results of this research underline the efficacy of combining multiple modeling approaches to significantly refine the accuracy and reliability of genetic variant classification systems. These findings support the deployment of these advanced computational models in clinical environments, where they can significantly enhance the diagnostic processes for genetic disorders, ultimately pushing the boundaries of personalized medicine by offering more detailed and actionable genetic insights.", "sections": [{"title": "Introduction", "content": "The emergence of Next Generation Sequencing (NGS) (reviewed in [21]) has transformed the realm of genomics, enabling the sequencing of millions of DNA fragments. However, the interpretation of the NGS results poses significant challenges as the vast majority of identified variants are of unknown significance (VUS)[9, 8, 7]. An accurate prediction of such variants can pave the way to a better understanding of disease mechanisms, enabling personalized medicine and the discovery of new therapeutic targets.\nOver the years, many computational tools and datasets have been developed to help predict the effects of variants. Early tools like PolyPhen and SIFT used sequence homology and protein structure information to predict the impact of missense mutations [2, 19]. Other models, such as CADD [14], combine multiple annotations into a single score to indicate variant pathogenicity.\nThe promising results of Large Language Models (LLMs) in Natural Language Processing (NLP) tasks have led to their adaptations in the fields of genomics and proteomics. LLMs are complex models that use the Transformer architecture[24]. One particular component of the Transformer architecture is self-attention, which enables the model to weigh the importance of different parts of the input data dynamically. This mechanism allows the models to consider the entire sequence context, making it particularly effective in handling long-range dependencies and interactions within the data. A remarkable example of the high potential of LLMs in proteomics is ESMFold, a protein language model that can predict protein structures using protein sequences[18].\nIn variant effect prediction (VEP), exploiting the capabilities of self-attention can be beneficial as it allows the model to account for not only specific mutations but also the entire genetic background and associated protein sequences, providing a comprehensive view of the molecular context. LLMs such as GPN-MSA, ESM1b, and Alphamissense have shown promise in predicting variant pathogenicity. GPN-MSA is a DNA language model trained on MSA (Multiple Sequence Alignment) of 100 species which leverages evolutionary information in predicting pathogenicity scores for all possible nucleotide substitutions in the genome[3]. ESM1b is a protein language model that predicts the pathogenicity for all 20 possible amino acids, without relying on homology and taking into account all protein isoforms[4]. As for Alphamissense, it is first trained to predict protein structures from the protein sequences and later fine-tuned for pathogenicity prediction[7]. These models are considered as state of the art in VEP.\nWe hypothesize that integrating these models may offer significant advantages. By combining their predictions, we can not only capitalize on their strengths and address their weaknesses but also provide a more comprehensive prediction leveraging both DNA and protein data. We adopted this integrative approach, using machine learning models for the combination of the scores, in order to develop a more accurate and comprehensive tool for predicting variant pathogenicity."}, {"title": "Materials & Methods", "content": "In this study, we utilized the ProteinGym dataset[20], a comprehensive resource developed to facilitate the evaluation of mutation effect predictors. This dataset is divided into two primary benchmarks: substitution benchmark and indel benchmark. For our analysis, we focused exclusively on the substitution benchmark of the ProteinGym dataset (accessed on 3/22/24), which includes approximately 2.7 million missense variants characterized across 217 Deep Mutational Scanning (DMS) assays[11] and encompasses data on 2,525 clinical variants. We examined specifically two distinct segments within this benchmark: the clinical variants substitutions dataset and the raw substitutions dataset. The raw substitution dataset is extensive and contains 61 columns. Crucial to our study are the columns indicating the chromosome and the exact genomic location of each variant, as well as reference and alternative alleles, which detail the nucleotide changes. Also integral to our analysis are the columns detailing the corresponding protein position and the amino acid changes. These are linked via the transcript ID, which connects the genomic data to specific protein transcripts, thereby facilitating cross-references between the genetic and protein data. Moreover, the dataset includes columns that categorize the clinical significance of each variant, classifying them as either pathogenic or benign. The clinical substitutions dataset contains the transcript ID to ensure consistent referencing across the datasets. It records both the position within the protein and the reference and alternate amino acids involved in each substitution. Additionally, it provides the sequences before and after mutations, along with the DMS_bin_score that classifies each protein substitution as benign or pathogenic.\nGPN-MSA's HuggingFace repository (accessed on 3/12/24) provides predictions for all possible SNPs in the human genome. Using the chromosomes and positions of the variants from the raw substitutions dataset, we queried the scores for all three possible nucleotide substitutions using Tabix[17]. The lower the score of GPN, the more pathogenic the variant.\nWe employed the ProteinGym substitution dataset to compute the ESM1b scores, which include reference protein sequences along with detailed mutation information such as positions and the specific amino acids involved. The ESM1b code was sourced from its GitHub repository. This model takes protein sequences as input and produces scores for all 20 possible amino acid substitutions at each position within the sequence, which can lead to extensive output files and considerable processing times. To streamline this process, we modified the ESM1b code to focus on scoring only the specified mutation positions from the dataset. This targeted approach significantly reduced both the output file size and the processing time. The lower the score of ESM1b, the more pathogenic the variant. A Log Likelihood Ratio (LLR) threshold of -7.5 was used to distinguish between pathogenic and benign variants[4].\nFor our analysis, we also utilized predictions from AlphaMissense, accessible through the file AlphaMissense-aa- substitutions.tsv.gz (4/8/2024). This dataset contains predictions for all conceivable single amino acid substitutions within 20,000 UniProt canonical isoforms, totaling approximately 216 million protein variants. Integrating AlphaMis- sense predictions posed significant challenges due to discrepancies in protein identifier systems. AlphaMissense uses UniProt accession numbers, whereas the ProteinGym dataset relies on NCBI's RefSeq protein IDs. To address this, we utilized the UniProt ID mapping tool to align the datasets, successfully mapping 2,415 out of the 2,525 proteins from"}, {"title": "Data Processing", "content": "This analysis differentiated between two types of scores. Firstly, the observed mutation scores, are calculated for mutations that are actually present in the dataset and represent clinically observed mutations in genomic or protein sequences. These scores provide direct insights into the impact of a specific, known mutation for one alternative nucleotide or amino acid (Fig.1.a columns Alt score, Prot Alt score, and AM pathogenicity). These observed mutations have an experimental annotation in the DMS_bin_score column. Secondly, the potential mutation scores, which speculate on the theoretical impact of all conceivable mutations at each position within the genome or protein sequence. For GPN-MSA, this involves generating four potential scores corresponding to the four possible nucleotide changes at each genomic position. In the case of ESM1b and AlphaMissense, scores are generated for each of the 20 possible amino acid substitutions at each position in the protein sequence ((Fig.1.a columns A, T, Ala, Am Ala...). In cases where the reference and alternative alleles or amino acids are identical, a score of zero is assigned, reflecting no change or impact due to the mutation. The potential mutations do not have a pathogenicity classification, except for the one corresponding to the observed mutation.\nThe first step of the data processing was merging the GPN-MSA and ESM1b scores using the transcript ID and protein information from both ProteinGym datasets, thus obtaining a dataset of 59,593 rows. This dataset was used for the preparation of the training and testing sets for the deep learning models. The splitting was performed in a manner that keeps the most ambiguous and difficult-to-predict data points in the test set by selecting a threshold for both scores. After visualizing the distribution (Fig.1), we selected the variants with scores between -5 to -10.\nAlphaMissense scores were added later, resulting in a small reduction of the dataset to 49,554 rows due to the proteins lost during the mapping. A new test set was generated by merging the previous test set with the new dataset containing the 3 scores. Using the threshold resulted in a test set of 16165 rows and a training set of 33,389 rows with balanced proportions of 16,588 pathogenic and 16,801 benign variants.\nThe last step was to assign a threshold for the GPN-MSA scores to enable the comparison between all models. To find the optimal threshold, one approach is to maximize the difference between True Positive Rate (TPR) and False Positive Rate (FPR). This is typically done by calculating TPR and FPR for each possible threshold using the Receiver Operating Characteristic (ROC) curve, and then identifying the point where the difference between TPR and FPR is the greatest. This index corresponds to the optimal threshold from the evaluated thresholds array. For the GPN-MSA scores, this method was used to identify a threshold that optimally differentiates between pathogenic and benign variants, ensuring accurate and clinically relevant comparisons across all models. The threshold found for the GPN-MSA scores was -7 with an optimal FPR of 0.41 and optimal TPR of 0.759. For the other models, AlphaMissense predictions were taken directly from its am_class output, which labels variants as either Pathogenic, Benign or Ambiguous. For ESM1b, variants with a score of -7.5 or below were considered pathogenic as described in the paper[4]."}, {"title": "Model Architectures", "content": "Various machine learning models were used for the training, namely XGBoost (XGB)[6], Random Forest (RF)[5], and Neural Networks. All models were trained using different sets of pathogenicity scores as features and the DMS_bin_score as the target variable. The ensemble models such as XGB and RF were trained using default parameters, as the fine-tuning of such models requires using grid search, which demands extensive amounts of time for limited improvements. As for Neural Networks, several architectures were employed. As the protein and DNA models provide a different number of scores, we decided to explore both Multi-input Neural Networks that take each score separately and Single-input Neural Networks that take all of the scores altogether. The architectures and parameters were explored and the optimal values were selected through a process of trial and error. The architectures and parameters were systematically optimized through an iterative process of trial and error to determine the optimal configuration."}, {"title": "Single input Neural Networks", "content": "The model architecture included a single input layer to handle the scores. This input was passed through a Dense layer with 64 units and a LeakyReLU activation function. A Dropout layer with a rate of 0.5 followed to prevent overfitting. The dropout layer was connected to another Dense layer with 128 units and a LeakyReLU activation function. The final output layer was a single unit Dense layer with a sigmoid activation function for binary classification.\nThe model was compiled using the Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.001 and binary cross-entropy loss function. Training was performed for up to 350 epochs with a batch size of 32. Early Stopping with a patience of 10 epochs and ReduceLROnPlateau with a factor of 0.2 and threshold of 0.0001 were employed to prevent overfitting and adjust the learning rate, respectively[1]."}, {"title": "Multi-input Neural Networks", "content": "The model included three input layers to handle the different scores. Each branch began with a Dense layer of 64 units, followed by Batch Normalization and ReLU activation. The outputs from these three branches were concatenated into a single tensor. This concatenated tensor was then passed through two Dense layers with 256 and 128 units, respectively. Each dense layer was followed by Batch Normalization, ReLU activation, and Dropout with a rate of 0.5 to prevent overfitting. The final output layer was a single unit Dense layer with a sigmoid activation function, appropriate for binary classification tasks. The model was compiled using the Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.01 and the binary cross-entropy loss function. Training was conducted for up to 350 epochs with a batch size of 32. To prevent overfitting and adjust the learning rate during training, Early Stopping with a patience of 50 epochs and ReduceLROnPlateau with a factor of 0.2 and threshold of 0.0001 were utilized."}, {"title": "Case study methodology", "content": "Case studies were conducted on select variants to confirm the model's prediction and showcase its efficiency as described in 3.4. We followed a specific methodology in order to extract the necessary data about these variants. First, we look into the protein information in Uniprot using the UniProt ID in our dataset. We first note the general data about the protein such as the function and the structure. Next, we download the PDB file for the AlphaFold structure of the protein from AlphaFold's website. The PDB file is then used to visualize the protein structure with Pymol. Pymol enables to change the specific residue in a specific position to another residue and observe the changes in the protein structure using the Mutagenesis panel. We use this to obtain the structure for the protein with the mutation we need. This way it is possible to visualize both the wild-type protein's structure as well as the mutated protein. Later we explore the interactions of the WT and mutated residues with the neighbouring structures in a radius of 3.5 Angstroms. This enables us to hypothesize on the possible outcomes of the mutation. Next, we investigate the Disease & Variants section which contains the known diseases the protein is involved in and the variants that are possibly implicated. For the well-annotated and well-studied variants, links for scientific papers are provided which are also investigated. In case the mutation we investigate is not included in the Disease & Variants section, the variant viewer panel in UniProt. This panel contains information on several mutations in the protein such as the effect of the mutation from different databases but also potential diseases in which the mutation can be involved. The main databases used are usually ClinVar, gnomAD, and dbSNP. Finally, we explore the Family & Domains section to check whether the mutation is involved in a functional domain of the protein. This section also provides scientific papers of studies conducted on specific regions of the proteins."}, {"title": "Technical Details", "content": "The computational analysis was conducted using Python 3.8 in a Jupyter Notebook environment. The platform used was a Linux operating system (Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.27). The hardware specifications include a 64-bit processor architecture (x86_64) with 40 physical cores, providing substantial computational power for parallel processing tasks. The system was equipped with 503 GB of total memory (RAM). The total disk space available was 438 GB. A key feature of the setup is the presence of eight NVIDIA Tesla V100-SXM2-32GB GPUs, each with 32 GB of dedicated memory. The CUDA version employed was 12.3, supported by NVIDIA driver version 545.23.08."}, {"title": "Results", "content": "The evaluation of several machine learning models was conducted to assess their effectiveness in predicting the pathogenicity of genetic variants. In this section, we will describe a correlation analysis between the scores of GPN- MSA, ESM1b, and AlphaMissense, benchmarking of the various models and a selection of the optimal set of features. Next, we will compare our best model's performance to state-of-the-art tools to contextualize its performance. Finally, we performed case studies to further showcase our model's utility in real-world applications\nWe utilized a dataset composed of various genetic scores derived from GPN-MSA, ESM1b, and AlphaMissense. These scores were the primary inputs for the predictive models. Four different feature sets were considered as inputs for the predictive models:\n\u2022 Potential scores from GPN-MSA and ESM1b: This feature set contains all four possible predictions from GPN-MSA and twenty predictions from ESM1b. It will test the impact of integrating both DNA and protein data and will also serve as a basis for comparison with other models that will incorporate Alphamissense scores.\n\u2022 Potential scores from GPN-MSA, ESM1b, and AlphaMissense: This feature set contains all four possible predictions from GPN-MSA and twenty predictions from ESM1b and Alphamissense. This feature set will assess the utility of adding Alphamissense scores to the model.\n\u2022 Observed Scores from GPN-MSA, ESM1b, and AlphaMissense: This feature set contains only one score for each model. This score corresponds to the score of the observed mutation in the dataset. Using this feature set we will test the necessity of using all the potential scores.\n\u2022 Observed and Potential Scores from GPN-MSA, ESM1b, and AlphaMissense: This feature set includes the scores for observed mutations for each model alongside all the possible model predictions. Observed scores represent the actual clinical mutations identified in the dataset, reflecting real-world genetic variations with known clinical significance. Potential scores, on the other hand, encompass a broad range of hypothetical mutations that provide a comprehensive view of possible genetic variations. Including both sets of scores in the feature set introduces a duplication of the observed scores, effectively weighting them more heavily in the model. This feature engineering approach is designed to emphasize the real, clinically validated mutations, captured by the observed scores, thereby potentially improving the model's performance.\nThe models were trained on a subset of the data and evaluated on a separate test set specifically chosen to include the most ambiguous and challenging variants. This approach was used to evaluate the model performance as strictly as possible, ensuring that the models are robust and effective even under the most difficult conditions. The test set composition included a balanced mix of 7902 pathogenic and 8263 benign variants."}, {"title": "Correlation Analysis", "content": "The correlation analysis quantified the degree of linear association between the observed scores from GPN-MSA, ESM1b, and AlphaMissense using Pearson correlation coefficients. This analysis provides insights into the prediction trends among these models, evaluating the necessity for an integrated model approach. GPN-MSA and ESM1b show a positive correlation (0.6779), suggesting these models tend to align in their predictions. In contrast, GPN-MSA and AlphaMissense have a negative correlation (-0.7259), and ESM1b and AlphaMissense exhibit an even stronger negative correlation (-0.8104). The negative correlations between AlphaMissense and the other two models (GPN-MSA and ESM1b) are expected, given that AlphaMissense assigns higher scores to pathogenic variants while the other two models assign higher scores to benign variants. The stronger correlation between ESM1b and AlphaMissense is due to their focus on protein-level pathogenicity predictions, while GPN-MSA predicts at the DNA level, explaining its lower correlation with both models. Overall, the results justify the need for an integrated model, as the individual models capture different aspects of the data, providing a more comprehensive and nuanced analysis when combined."}, {"title": "Model performances", "content": "Here we evaluate the performances of the models across the different feature sets. The model performances are detailed in Fig.3. Overall, the choice of the models didn't have a significant impact on the results. However, the evaluation revealed varying performance across the different feature configurations. All models showed similar performance with the GPN+ESM feature set, with accuracies around 0.75 and ROC-AUC just below 0.83. The multi-input neural network and random forest slightly outperformed the XGBoost and single-input neural network in terms of ROC-AUC. The incorporation of AlphaMissense scores improved performance across all models, particularly the Random Forest model with a ROC-AUC of 0.872. The single-input neural network excelled with the Observed Scores configuration, achieving the highest accuracy 0.808 and ROC-AUC of 0.877. The feature set that included both Observed Scores and Potential Scores provided the best overall results, particularly for the multi-input neural network and random forest, both achieving high accuracies and ROC-AUC scores above 0.89."}, {"title": "Performance comparison state of the art models", "content": "Next, we will compare the Multi-input Neural Network model trained on Observed + Potential scores to state-of-the-art tools. This analysis aims to assess the real-world applicability of our approach, particularly in its ability to accurately predict Variants of Uncertain Significance (VUS). By benchmarking our model against existing leading tools, we aim to demonstrate its effectiveness and potential advantages in clinical and research settings. This comparison will help us understand how well our integrated model performs in practical scenarios, ensuring its utility in improving genetic variant classification."}, {"title": "Performance comparison state of the art models: ProteinGym", "content": "In this study, the Multi-input NN model trained on Observed+Potential scores was evaluated alongside AlphaMissense, GPN-MSA, and ESM1b, using the test dataset of 16,165 genetic variants. This dataset was specifically chosen to include the most ambiguous and challenging variants to evaluate model performance as strictly as possible, ensuring robustness and effectiveness under difficult conditions. The models' performance was assessed by comparing their predictions against the experimental annotations provided in the ProteinGym's DMS_bin_score. For the assessment, AlphaMissense predictions were taken directly from its am_class output, which labels variants as either Pathogenic, Benign or Ambiguous. For ESM1b, variants with a score of -7.5 or below were considered pathogenic. The threshold for GPN-MSA was set at -7, as detailed in the Materials and Methods. The initial comparison of the models was performed on all 16,165 variants of the test set (Fig.4a). This comparison aims to provide a baseline comparison of the models on the challenging variants of the test set. The analysis demonstrated that the integrated model outperformed the others, achieving an accuracy of 82.54%. AlphaMissense and ESM1b showed comparable performances with accuracy of 74.58% and 73.84% respectively, while GPN-MSA lagged at 67.03%. For the second analysis, variants classified as ambiguous by AlphaMissense were excluded from the analysis, reducing the test set to 14,435 variants (Fig.4b). This comparison aimed to provide a fairer assessment by considering only two predictions, removing the variants that are difficult for Alphamissense to predict. All models displayed improved accuracy. The integrated model still outperformed AlphaMissense, achieving accuracies of 84.52% and 83.52% respectively. The last analysis focused on the 1,730 variants categorized as ambiguous by AlphaMissense (Fig.4c). Here we will measure how the models perform on a smaller subset of hard-to-predict variants according to AlphaMissense. In this challenging subset, the integrated model again showed robust performance, achieving the highest accuracy of 66.07%. ESM1b and GPN, presented accuracies of 60.69% and 48.38% respectively. It's important to note that we solely relied on accuracy for model evaluation in this study. AlphaMissense outputs three classifications (Pathogenic, Benign, Ambiguous), rendering the calculation of other common metrics like ROC-AUC more complex."}, {"title": "Performance comparison state of the art models: ClinVar", "content": "In addition to the DMS annotation, the ClinVar[15] classifications were added to the test dataset for further comparison. This merge implied the loss of a single row bringing the dataset to 16,164 variants. The ClinVar data provides an array of different classifications. Variants with labels 'Uncertain significance' or 'Conflicting classifications of pathogenicity' were classified as Ambiguous. The other variants were either labeled Benign or Pathogenic. Comparing the models' performances on the ClinVar dataset provides an additional layer of analysis on a clinically relevant dataset, offering valuable insights into the models' effectiveness in handling Variants of Uncertain Significance (VUS).\nFirst, we performed the comparison of each model against the ClinVar classifications Fig.5a. This comparison was motivated by the need to evaluate the overall accuracy of each model. In this analysis, AlphaMissense should have an advantage as it can directly classify ambiguous variants, whereas other models, which only provide benign or pathogenic predictions, would generate false predictions for these ambiguous variants. Despite this, the integrated model still outperformed AlphaMissense in this task. The integrated model achieved an accuracy of 79.16%, AlphaMissense 72.07%, ESM1b 70.93%, and GPN 64.33%.\nNext, we tested the models' performances on clearly classified variants by removing the 715 ambiguous variants of the ClinVar dataset Fig.5b. This analysis was conducted to provide a more straightforward comparison, focusing solely on benign and pathogenic classifications without the complexity introduced by ambiguous variants. This analysis shows an overall better accuracy across all the models compared to Fig.5.a with the integrated model outperforming the other models with an accuracy of 82.82%, followed by AlphaMissense at 74.87%, ESM1b at 74.21%, and GPN at 67.31%.\nSubsequently, the performance of the models on the 715 ambiguous variants of ClinVar was assessed using the DMS_bin_score as the ground truth (Fig.5.c). This task aimed to evaluate how effectively each model discriminates between variants with uncertain significance. The results indicated weaker performances compared to the overall dataset (Fig.5a). Nonetheless, the integrated model again outperformed the other models with an accuracy of 76.22%, showcasing its efficacy in classifying ambiguous variants. AlphaMissense, ESM1b, and GPN showed accuracies of 68.11%, 65.59%, and 60.70%, respectively.\nFinally, the performance of the integrated model, ESM1b, and GPN-MSA was assessed on a small dataset of 83 variants classified as ambiguous by both AM and ClinVar (Fig.5d). This comparison was motivated by the need to evaluate the models on the most challenging subset, where both AlphaMissense and ClinVar classifications had flagged the variants as ambiguous. The DMS_bin_score was used as the ground truth for this evaluation. The integrated model continued to display robust results with 60.24% correct predictions, followed by ESM1b with 55.42% and GPN with 43.37%. Assessing the models on this difficult subset underscores the integrated model's capability to manage the complexities associated with ambiguous genetic data, further validating its robustness and reliability in real-world applications where uncertain classifications are prevalent."}, {"title": "Case studies", "content": "Here we investigate examples of variants classified as VUS by ClinVar and for which our model aligns with DMS_bin_score as opposed to the other three models. These case studies help showcase the utility of our model in real-life scenarios but also prove our model effectively learned underlying data from the state of the art and makes accurate predictions autonomously. We also looked into the cases where all the models' predictions align with the DMS_bin_score except for our model and found no such cases."}, {"title": "Case study of LZTR1", "content": "For the first case study, we focused on the E563Q mutation in the Leucine Zipper-like Transcriptional Regulator 1 (LZTR1). The Leucine Zipper-like Transcriptional Regulator 1 operates within the Golgi apparatus. It acts as a negative regulator of RAS-MAPK signaling by controlling Ras levels and decreasing Ras association with membranes. LZTR1 is also hypothesized to interact with the CUL3 ubiquitin ligase complex, which facilitates the degradation of redundant proteins. Functionally, LZTR1 is believed to act as a tumor suppressor.\nOur model classified the E563Q mutation as pathogenic, which aligns with the experimental annotation from the DMS_bin_score. Interestingly, other predictive models, such as AlphaMissense, ESM1b, and GPN-MSA, classified the mutation as benign. Previously, ClinVar had classified this mutation as \"likely pathogenic,\" but a recent update reclassified it as a variant with Conflicting Interpretations of Pathogenicity. In contrast, dbSNP still categorizes this mutation as \"likely pathogenic.\"\nTo analyze the structural implications of this mutation, we retrieved the protein structure from AlphaFold's website and visualized both the wild-type and mutated sequences using PyMOL[25].\nAs shown in Fig.6, the mutation may lead to the formation of H-bond between N atom of Gln563 and the neighboring alpha helix. In contrast, the wild-type Glu563 cannot form H-bond due to the negatively charged carboxylate of Glu563. This additional interaction between the two alpha helices in the Glu563Gln mutant may reduce the flexibility of the protein's tertiary structure, potentially altering its function.\nFurther support for the pathogenicity of the E563Q mutation comes from a study by Johnston et al. [13] on LZTR1 variants and their role in Noonan syndrome. The study examines a family with the E563Q mutation, where both parents, heterozygous for the mutation, showed no significant phenotypes. However, their two homozygous children"}, {"title": "Case study of KAT6A", "content": "For the second case study, we investigated the E221K mutation in the KAT6A protein. KAT6A is a histone acetyltrans- ferase responsible for acetylating lysine residues in H3 and H4 histones. As part of the MOZ/MORF complex, KAT6A exhibits histone H3 acetyltransferase activity. It also serves as a transcriptional coactivator for RUNX1 and RUNX2, and acetylates p53/TP53, controlling its transcriptional activity via association with PML.\nOur model classified the E221K mutation as benign, which aligns with the DMS_bin_score. Clinvar currently classifies the variant as VUS while the state-of-the-art computational models predict it as pathogenic except for Alphamissense which labels it as ambiguous.\nThe protein does not have a consensus structure, and the Alphafold predictions for the protein show low overall confidence. However, the region surrounding the E221K mutation lies within a high-confidence zone and is located in a coil structure. PyMOL visualization of both WT and mutated residues shows no interaction with neighboring residues (Fig.7), suggesting minimal impact on the protein's overall structure.\nThe E221 residue lies within two functional domains. The first one is a Zinc Finger (ZF) (residues in 206-265). The PRU00146 ZF has no defined function. Zinc fingers typically involve cysteine or histidine residues, while this mutation involves glutamic acid to lysine, which suggests a low likelihood of impacting ZF function. The second domain is an Interaction region with PML (promyelocytic leukemia) containing residues 144-664 [23]. However, structural visualization reveals that the E221K mutation is buried within the protein core and not exposed, making it less likely to participate in significant interactions with adjacent residues [16].\nClinVar initially classified this variant as likely benign but later reclassified it as VUS. According to the authors' submission on ClinVarMiner, this variant has not been reported in individuals affected with KAT6A-related conditions, and the advanced modeling of protein structure and biophysical properties such as structural, functional, and spatial information, amino acid conservation, physicochemical variation, residue mobility, and thermodynamic stability indicate that this missense variant is not expected to disrupt KAT6A protein function. This statement reinforces the hypothesis that such mutation may have a lower impact on the protein function as loops are disordered and may contribute less to the protein function, especially since the mutation's position in 221 does not belong to a functional region."}, {"title": "Conclusion", "content": "This study highlights the potential of combining advanced machine learning models in classifying genetic variants. Our integrated approach consistently outperformed the latest methods in determining the pathogenicity of these variants. The comprehensive evaluation clearly demonstrated the proficiency of the Multi-input Neural Network model in handling both straightforward cases and Variants of Uncertain Significance (VUS).\nOur analysis underscored the importance of feature selection. Combining DNA and protein data using potential scores from GPN-MSA and ESM1b established a solid performance baseline. Adding AlphaMissense's scores significantly boosted the predictive power of all models. This validates the advantage of integrating structural insights from protein data with sequence-based predictions. Using both observed and potential scores together led to the best overall results. The hypothesis that emphasizing observed scores would enhance the model's focus on clinically validated mutations proved to be successful. By adding weight to these observed scores, the model better captured real-world genetic variations, leading to improved accuracy and robustness in classification.\nOur integrated model consistently showed strong performance across various testing scenarios, demonstrating its capability to effectively interpret complex datasets. ESM1b and AlphaMissense consistently outperformed GPN-MSA. This can be due to the fact ESM1b and AlphaMissense are protein-based models whereas GPN-MSA is trained on DNA data, likely because protein data provides critical structural and functional context necessary for accurate variant classification. The improvements seen when excluding variants classified as ambiguous by AlphaMissense, and the corresponding drop in accuracy for those variants, further emphasize the challenges that uncertain classifications pose to predictive tasks.\nIn the comparison with ClinVar's annotations, the extended evaluation highlighted the efficiency of our integrated model in distinguishing variant pathogenicity across both the ProteinGym and ClinVar datasets, which are meticulously curated for experimental validity. The model's robust performance, particularly in handling VUS, makes it potentially useful for clinical and research applications where accurate interpretation of ambiguous genetic data is crucial.\nCase studies further showcased the practical value of our model's predictions. Investigating protein structures and reviewing related literature supported the accuracy of our model and the DMS_bin_score annotations, underlining the model's real-world applicability. This also indicates that our model was effectively trained, capturing underlying information from state-of-the-art models rather than merely replicating their predictions.\nour model is a step forward for characterizing variants of unknown significance and paves the way for identifying new therapeutic targets (or better characterization) or improving models that use NGS data [10, 22]. Looking ahead, it is essential to extend our validations by testing the integrated model on larger and more diverse datasets. Incorporating additional relevant components, such as transcriptomics scores from SpliceAI[12], could further enhance the model's performance. By integrating these scores, we can add another dimension to our model, combining genomic, proteomic, structural, and transcriptomic data, leading to even more accurate and reliable predictions."}]}