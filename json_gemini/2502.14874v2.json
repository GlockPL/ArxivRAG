{"title": "Is Mathematics Obsolete?", "authors": ["Jeremy Avigad"], "abstract": "N/A", "sections": [{"title": "Mathematical Reasoning and Scientific Reasoning", "content": "Displayed prominently in the Vatican, Raphael's fresco, The School of Athens, portrays several\nphilosophers and thinkers of ancient Greece, arrayed around Plato and Aristotle at the center. Plato,\nwhose philosophy of knowledge is based on forms that inhabit an extraterrestrial realm, points to\nthe heavens. Aristotle, who took mathematical and scientific abstractions to be rooted in worldly\nexperience, holds his hand out, open, palm facing downward. With Plato drawing our attention to\nthe pristine beauty of mathematical forms, I imagine Aristotle saying \u201cWhoa there, Romeo, get your\nhead out of the clouds. We have work to do, here on Planet Earth.\"\nThe scene sums up the complementary appeals of mathematical and scientific thought. Mathe-\nmatics deals with abstract objects, like numbers, that are not located in time or space, while science\nis about concrete objects, located in the physical world. Mathematics is supremely rational, relying\non deductive reasoning to pass from axioms and hypotheses to conclusions, whereas science is\nfundamentally empirical, relying on inductive reasoning to pass from data to general laws. Mathe-\nmatical claims are exact, while scientific claims are approximate. Mathematical deduction yields\nabsolute certainty, while scientific induction yields, at best, hypotheses that are supported by the\ndata but can be overturned by future evidence.\nThese contrasts have fascinated philosophers through the ages. Historians classify the early\nmodern philosophers of the seventeenth and eighteenth centuries as rationalists or empiricists; the\nrationalists took knowledge to be grounded in abstract ideas, obtained by reason and independent\nof experience, whereas the empiricists held that the physical world is the ultimate source of all\nour knowledge. These characterizations evolved over the years. In the mid-twentieth century, the\nlogical empiricist movement classified mathematical knowledge as analytic, which is to say, true by\nvirtue of the proper use of language and our shared linguistic framework, in contrast to the synthetic\nknowledge of science.\nWhat is at stake in the philosophical debates is often murky. Sometimes, it is a matter of\nontology, an account of the objects we talk about and how we should talk about them. Sometimes,\nit is a matter of epistemology, sorting out the appropriate ways of justifying claims to knowledge.\nThe philosophical positions, however, often come across as expressions of subjective preference. If\nyou like mathematics, you are prone to view abstract mathematical knowledge as the most pristine\nform of knowledge and facts about the world as nothing more than pale shadows of ideal laws and\nmathematical truths. If you are more scientifically inclined, experience and observation are what\ncounts, and you are more inclined to view mathematics as nothing more than the language we use to\ndescribe them.\nNobody can deny that mathematics and science need each other. One of the reasons we care\nabout mathematics is that it gives us such a powerful means of thinking about the world, and however\nyou feel about mathematics, it's impossible to imagine what contemporary science would look like\nwithout it. In the words of Immanuel Kant, thoughts without content are empty, and intuitions\nwithout concepts are blind. The question as to whether ideas or data come first is a chicken-and-egg\nproblem: we build our conceptual scaffolding to make sense of our experiences, and that scaffolding,\nin turn, determines what can we make of them."}, {"title": "Symbolic and Neural AI", "content": "Given the excitement about neural networks and generative AI, I like to remind people that these\nrepresent only one of the two main approaches to artificial intelligence, nicely described in an article\nby Turing Award winners Yoshua Bengio, Yann LeCun, and Geoffrey Hinton:\nThere are two quite different paradigms for AI. Put simply, the logic-inspired paradigm\nviews sequential reasoning as the essence of intelligence and aims to implement reason-\ning in computers using hand-designed rules of inference that operate on hand-designed\nsymbolic expressions that formalize knowledge. The brain-inspired paradigm views\nlearning representations from data as the essence of intelligence and aims to implement\nlearning by hand-designing or evolving rules for modifying the connection strengths in\nsimulated networks of artificial neurons.\nHistorically, the logic-inspired paradigm was there first. Early in the twentieth century, logicians\nwrote down axioms and rules for mathematical reasoning, and they developed algorithms to decide\nthe truth of mathematical statements and search for mathematical proofs. They also determined\nsome of the fundamental theoretical limits of symbolic reasoning, demonstrating that consistent\nproof systems are necessarily incomplete and that there are classes of mathematical problems with\nno algorithmic solution. These results were well established by the early 1940s, as the first digital\ncomputers were being built. A workshop in 1956, the Dartmouth Summer Research Project on\nArtificial Intelligence, launched AI as a new field of research, and by the end of the decade, a number\nof practitioners had implemented logic-based reasoning algorithms.\nEnthusiasm for symbolic AI ebbed and flowed in the subsequent decades. Rampant optimism in\nthe 1960s gave way to the disappointing realization in the 1970s that simulating intelligent behavior\nwas harder than AI's early proponents had hoped. The Japanese government's Fifth Generation\nComputer Systems project, which aimed to develop massively parallel logic-based platforms as\na basis for expert systems, brought new optimism in the early 1980s but gave way to renewed\nskepticism by the end of the decade. The 1990s thus inaugurated an \u201cAI winter\" in the US, with\nreduced government funding and support. Symbolic AI achieved landmark success in 1997, however,\nwhen IBM's Deep Blue beat the reigning world chess champion, Garry Kasparov, in a six-game\ntournament.\nDespite these ups and downs, in the latter half of the twentieth century, the symbolic worldview\nreigned as the dominant paradigm in our understanding of thinking and reasoning. Cognitive science\nwas a matter of explaining intelligent human behavior by sussing out the symbolic representations\nand rules that give rise to it. Linguistics was a matter of working out the symbolic grammars\nand rules that govern language generation and interpretation. These perspectives guided efforts\nin mechanization. Automated reasoning meant searching for proofs in logical calculi; designing\nan expert system meant encoding knowledge in rules and using them to draw inferences; natural\nlanguage processing meant writing grammars and parsers to analyze and generate sentences;\nimplementing systems of computer vision meant writing algorithms to detect corners, edges, and\nfaces, and using that data to construct symbolic representations of the underlying objects and the\nrelationships between them. In short, the common understanding of intelligence was that it was a\nmatter of processing inputs into logic-based representations and operating on those. This is not to\ndeny that the second half of the twentieth century also saw important advances in machine learning\nand neural networks; both were discussed at the Dartmouth workshop and were active research\nareas in the decades that followed. But despite the vicissitudes of the symbolic approach, the scales\nalways seemed to tip in its favor.\nToward the end of the twentieth century, researchers in artificial intelligence retrenched and\navoided grandiose claims about general intelligence. Practitioners focused on more specialized tasks\nlike image recognition, natural language processing, and hardware and software verification. In this\nenvironment, machine learning, which aims to learn from data rather than hand-crafted rules, began\nto gain traction. Using empirical and statistical methods rather than logical ones, the field addressed\ntasks like classifying inputs and making predictions based on regularities in data.\nThe balance between the two approaches shifted decisively with highly publicized events like\nthe success of IBM's Watson on Jeopardy! in 2011, AlphaGo's defeat of Lee Sudol in 2016, and\nthe arrival of the large language model GPT-3 in 2020. All of a sudden, AI was no longer about"}, {"title": "Is Mathematics Obsolete?", "content": "to researchers like me, who had devoted their lives to the study of logical systems and symbolic\nmethods, the sudden rise of machine learning and neural networks felt like an existential threat.\nOver and over again, we saw them come to dominate fields where symbolic methods once held\nsway. In cognitive science, symbolic models of human cognition gave way to neural models. The\nfifth-generation expert systems of the 1980s gave way to big data, foundation models, and neural\nnetworks. Deep Blue was eclipsed by AlphaZero, and symbolic approaches to language processing\ngave way to LLMs. Symbolic algorithms for image processing were crushed by neural networks.\nThis sea change was poignant at Carnegie Mellon, where I work. In the second half of the\ntwentieth century, Herbert Simon, a Nobel Prize winner in economics and one of the founding fathers\nof AI, played a tremendous role in shaping the scientific vision and direction of the university. Simon\nwas one of the participants in the Dartmouth workshop, where he presented the Logic Theorist, a\nprogram he had written with Allen Newell and Cliff Shaw that could solve problems in propositional\nlogic. At Carnegie Mellon, he helped found the Graduate School of Industrial Administration, the\nSchool of Computer Science, the Department of Psychology, and the Department of Philosophy.\nWhen I arrived in 1996, logic played a prominent role in mathematics, computer science, cognitive\nscience, philosophy, psychology, and linguistics, in no small part due to his influence. However,\nCarnegie Mellon is also a pioneer in machine learning, having founded the first academic department\nof machine learning in 2006 and the first undergraduate major in AI in 2018. On the university web\npages, AI at CMU, you can find a history of AI at Carnegie Mellon, news and events, descriptions of\nvarious degree programs, and sample curricula. Try as you may, you will not find a single occurrence\nof the word \"logic.\"\nIn 2023, the New York Times ran a series of articles designed to help the general public make\nsense of the revolution in AI. The first of the series summarized the history of artificial intelligence\nas follows:\nA group of academics coined the term in the late 1950s as they set out to build a\nmachine that could do anything the human brain could do\u2014skills like reasoning,\nproblem-solving, learning new tasks and communicating using natural language.\nProgress was relatively slow until around 2012, when a single idea shifted the entire\nfield.\nIt was called a neural network.\nThat brief narrative served to sum up a half-century of research in AI, carried out by some of the\nmost talented and accomplished researchers of their time. You can't blame those of us working with\nsymbolic methods for wondering whether our time had come.\nOne might object that the title of this essay is misleading because it conflates mathematics with\nsymbolic AI. The history of mathematics consists of more than two thousand years of some of\nthe most beautiful and creative ideas humankind has ever produced, and mathematicians generally\nchafe at the suggestion that formal reasoning captures the subject's essence. Mathematical thought\nis driven by big ideas, far-reaching intuitions, and deep insights, none of which are captured or\nexplained by the rules of logic. With its goals of developing powerful abstractions, detecting patterns,\nand synthesizing disparate aspects of our experience, mathematics is as amenable to the methods of\nmachine learning as much as it is to the methods of symbolic AI.\nThat said, what distinguishes mathematics among the scholarly disciplines is the level of rigor\nand precision with which mathematicians state and justify their claims. Although the debate over\nthe merits of symbolic AI vs. machine learning is not the same as the debate over the merits of\nmathematical vs. scientific reasoning, both are aligned with the fundamental disagreement between\nPlato and Aristotle as to whether finding the right concepts is a prerequisite to knowledge or whether\nconcepts are only what emerge from empirical data. One might argue that although mathematical\nideas have supported scientific exploration and practical reasoning for centuries, their importance\nhas now diminished. Given our limited cognitive abilities, mathematical abstraction has been a\nvaluable tool, enabling us to squeeze out additional cognitive efficiency in our attempts to navigate a\ncomplex world. But now that we have neural networks to process the data and tell us what to make\nof it, the idealized mathematical representations we have been using are less helpful, pale shadows\nof an underlying complexity that neural networks can manage more directly. One can, therefore,\nargue that symbolic methods are no longer important because mathematical reasoning, as we know\nit, is no longer important. Technology has given us something better.\nThreatened by such an argument, mathematicians may retreat to aesthetics: many of us do\nmathematics not because it is useful, but because we enjoy it, just as we enjoy literature and art. But\naesthetic and pragmatic factors are not so easily separated. Maybe we find thinking abstractly and\nsolving problems so enjoyable precisely because they are so generally useful; in other words, we\nappreciate the power of mathematics even when it is not directed at any practical goal. We might not\nfeel the same way if mathematics were relegated to a pastime, like cricket or chess. Furthermore, an\nappeal to aesthetics doesn't help us solicit support for mathematics from those who do not enjoy it,\nand it certainly doesn't explain why we should require our children to spend so much of their time\nstudying it.\nWe should take these worries seriously. I personally believe that in the age of AI, mathematics\nis as important as it ever has been, but that is not something we can take for granted. Contemporary\nAI offers us dramatically new capacities for reasoning and making decisions, and we cannot assume\nthat methods that served us well before the advent of deep learning are still relevant today. It is\ntherefore important to consider what role mathematics should still play in our lives, if any, and why."}, {"title": "The Value of Mathematics", "content": "Generally, when we ask ChatGPT a question, we care about the answer. Whenever we turn to AI for\nadvice, we should question the wisdom of putting our lives and livelihoods in the hands of a system\nwe don't understand. We should worry about whether the information we get is reliable, aligned\nwith our interests, and likely to help us achieve our goals. We should worry about our safety and\nsecurity, and since our decisions affect others, we should worry about whether the advice we get\nreflects our values and morals. For these reasons, we want AI to be transparent. We want AI to tell\nus not just what to do but also why; we want reasons, explanations, and justification. We expect no\nless from doctors, lawyers, salespeople, financial managers, and contractors, and we ought to expect\nthe same from AI.\nThis highlights one role for mathematics. Mathematical language is designed to enable us to\nexpress ourselves clearly and provide rigorous justification, giving us the means to tell a system\nwhat we want and check the answers to ensure we are getting what we expect. Not everything has\nto be mathematized, but there are plenty of reasoning tasks where mathematical specifications and\nexplanations are called for, and those will not go away just because we have neural networks.\nThis defense of mathematics, however, does not go far enough. It suggests that, in the future,\nthe primary purpose of mathematics is for us to communicate with AI and for AI, which knows all\nthe answers, to put them in terms we can understand. It puts AI, rather than us, at the center of the\ndeliberative process. It fails to recognize that, when we talk about artificial intelligence, what we\ncare about is the ability of mechanized systems to participate in our deliberative processes and help\nus reason about what we want to do and who we want to be.\nImagine you are the mayor of a town with a river running through it, and the town council has\ndetermined that, given recent growth, it is time to build a new bridge. What's a modern mayor to\ndo? You turn to ChatGPT and say, \"Design us a bridge,\" and out come instructions for the builders.\nThe council wants pictures, and ChatGPT obliges with images of the bridge, illuminated by the\nglimmer of sunrise or enveloped in a foggy winter mist. Beautiful! No mathematics is needed.\nExcept maybe you want blueprints for the builders, with precise specifications of the lengths and\nangles. They should also know the requirements the building materials must satisfy and acceptable\nmachining tolerances. Not only do you want numeric data in the output, but you probably want to\nuse numeric specifications in your instructions, such as the volume of traffic you want the bridge to\nsupport and how long you expect it to last. The council will undoubtedly want to know how much it\nwill cost.\nCan you trust the blueprints? The effects of a collapse would be disastrous. Until AI has\nestablished a track record, it would be wise to ask to see the calculations so that engineers can audit\nthem and ensure they meet appropriate safety standards. They may want to check the calculations\nby hand or run simulations and checks using software they are more comfortable with.\nHowever, that is not nearly enough. Building a bridge is a serious undertaking, and there is\na lot to think about. What effect will the bridge have on current traffic patterns, and how will it\nfare with respect to anticipated growth and changes over the coming decades? Should the bridge\ninclude paths and walkways to encourage more people to walk and bike, or is it more critical to\nmeet commercial traffic needs? How will it affect the environment, and how should we weigh\nenvironmental concerns? Will the placement of the bridge benefit some residents and harm others?\nWhat else should you take into account? These questions deserve thoughtful deliberation not just\nfrom the mayor and town council but from all the relevant stakeholders.\nIt's not just that we need to tell AI what we want and to make sure we get it. The point is\nthat we often don't know what we want, and sorting that out requires reasoning and deliberating,\nindividually and with others. And this, in large part, is what mathematics is there for. It provides us\nwith key capacities to reason and deliberate and to come to terms with things like measurements,\ncosts, projections, causes and effects, likelihoods, and uncertainties.\nThis is a fundamental part of the human experience: thinking about the world as it is and as we\nwant it to be, and reasoning about how to get from here to there. Being human requires thinking\nabout what's important to us and reasoning about the consequences of our actions, and being part\nof society requires deliberating with others. Mathematics has evolved over centuries to support\nthis, providing us with ways to express ourselves precisely, to produce complex chains of reasoning\nthat we can reproduce and share with others, to evaluate our assumptions, to record and codify our\nreasoning processes, and to improve them over time. Mathematical concepts and abstractions matter\nto us because they are fundamental to the way we make sense of our experiences and the world\naround us. Ultimately, we are the ones who need to decide what we should do and how we should\ndo it. We have always enlisted technology in our efforts, but as soon as we cede our deliberative\nprocesses to technology, we will have given up something fundamental to what it means to be\nhuman.\nIn short, being rational means not only having goals and values but also deliberating, planning,\nand coordinating with others to attain them. Being able to reason about our goals and values\npresupposes that we can express them to ourselves and to others. For AI to help us, our interactions\nhave to be mediated by the rich network of concepts and ideas we use to make sense of the world,\nand mathematics is an essential part of that network."}, {"title": "Mathematics and AI", "content": "I have argued in an article in the Bulletin of the American Mathematical Society that mathematics is\nundergoing a formal turn, as mathematicians become increasingly interested in symbolic methods\nand formal representations. Several high-profile formalization projects, many of them collaborative,\nhave been carried out using the Lean Theorem Prover and its library Mathlib. The resulting\ndigitization of mathematical content opens up new possibilities for both symbolic and neural AI.\nThe good news is that the value of mathematical and symbolic reasoning has not been lost on the\nmachine-learning community. DeepMind's AlphaProof, using a reinforcement learning algorithm\nrunning on top of Lean, solved three of the six problems in this year's International Mathematics\nOlympiad, ranking it competitive with the world's most elite pre-college problem solvers. There\nhas been considerable interest in improving the ability of AI to carry out mathematical reasoning.\nThere are ongoing debates between researchers as to the extent to which symbolic systems like\nLean are required for a system of AI to acquire mathematical expertise, but many feel that the most\npromising avenues to success require a combination of neural and symbolic methods. Even ML\npurists recognize that obtaining mathematical arguments, explanations, and justifications is a key\ngoal for AI, however that can be achieved.\nIn recent years, therefore, the phrase \u201cAI for mathematics\u201d has come to encompass both symbolic\nand machine-learning methods. My colleagues and I can breathe a sigh of relief; we can also ride\nthe AI wave, at least for now. But we won't always be able to ride it for free; we still need to show\nthat symbolic methods have an important role to play in artificial intelligence.\nLet's hope they do. Ever since Galileo proclaimed, in the seventeenth century, that the book\nof nature is written in the language of mathematics, mathematics has been central not only to the\nscientific method, but to practical decision making in several worldly pursuits, including technology,\neconomics, finance, logistics, and public policy. Now, with the advent of AI, there are two paths\nwe can follow. The first involves carrying out scientific reasoning and decision-making the way we\nhave since Galileo but using AI to do it better, improving our mathematical models and obtaining a\ndeeper understanding of their properties. The second involves bypassing mathematics, leaving AI\nto draw conclusions as it sees fit, and accepting its oracular conclusions. The first path opens up\nexciting opportunities for mathematics and science, because AI offers us new means to discover and\nunderstand phenomena that would otherwise remain opaque to us, to think and reason better, and to\nmake better decisions. If we go down the second path, it will mean turning our back on science,\nrelinquishing agency over our practical decisions, and giving up a vital part of what it means to be\nhuman. Al offers us the choice, but it does not tell us which path to take. It's up to us to get it right."}]}