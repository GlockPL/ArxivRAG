{"title": "A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases", "authors": ["Zhepeng Wang", "Runxue Bao", "Yawen Wu", "Guodong Liu", "Lei Yang", "Liang Zhan", "Feng Zheng", "Weiwen Jiang", "Yanfu Zhang"], "abstract": "Graph neural networks (GNNs) are powerful machine learning models designed to handle irregularly structured data. However, their generic design often proves inadequate for analyzing brain connectomes in Alzheimer's Disease (AD), highlighting the need to incorporate domain knowledge for optimal performance. Infusing AD-related knowledge into GNNs is a complicated task. Existing methods typically rely on collaboration between computer scientists and domain experts, which can be both time-intensive and resource-demanding. To address these limitations, this paper presents a novel self-guided, knowledge-infused multimodal GNN that autonomously incorporates domain knowledge into the model development process. Our approach conceptualizes domain knowledge as natural language and introduces a specialized multimodal GNN capable of leveraging this uncurated knowledge to guide the learning process of the GNN, such that it can improve the model performance and strengthen the interpretability of the predictions. To evaluate our framework, we curated a comprehensive dataset of recent peer-reviewed papers on AD and integrated it with multiple real-world AD datasets. Experimental results demonstrate the ability of our method to extract relevant domain knowledge, provide graph-based explanations for AD diagnosis, and improve the overall performance of the GNN. This approach provides a more scalable and efficient alternative to inject domain knowledge for AD compared with the manual design from the domain expert, advancing both prediction accuracy and interpretability in AD diagnosis.", "sections": [{"title": "Introduction", "content": "Graph neural networks (GNNs) have emerged as robust and versatile algorithms for diverse machine learning tasks involving graph or irregularly structured data, as evidenced by a plethora of studies [24,44,63,12,61,6,33]. In recent years, there has been a discernible surge in research endeavors aimed at extending the applicability of GNNs towards addressing broader scientific and health-related challenges, such as drug prediction [62,28], precision medicine [50,46], brain network analysis [39,38], and protein structure prediction [60,41]."}, {"title": "Method", "content": "Overview. To integrate external knowledge into GNNs, we will fuse the embeddings from graphs and external knowledge guided by their relevance to the prediction. More specifically, we learn a pair of masks to characterize the relevance and use the masked embeddings to fine-tune the prediction model. We first formulate a multimodal GNN denoted as f, which accepts brain connectome data g alongside natural language data K as inputs. In essence, this entails augmenting canonical GNNs with external knowledge data. Subsequently, we undertake the pretraining of f using gathered data. We then identify significant substructures within brain connectomes and pertinent knowledge relevant to prediction tasks. These are delineated by real-valued masks parameterized by \u03b1 and \u03b2. By computing the masks jointly, we facilitate a \"soft\" retrieval mechanism from the knowledge data, wherein the masks function as explanations for both graph-wise and knowledge-wise aspects of predictions made by f. Ultimately, we refine the parameters of f through a process of fine-tuning, leveraging graph augmentation in conjunction with the \"soft\" retrieval outcomes. Specifically, we utilize the computed masks to guide edge sampling, thereby preserving critical information while augmenting data diversity. The design overview is shown in Fig. 2 and further elucidation of our approach follows.\nMultimodal GNN equipped with external knowledge. We propose the integration of canonical GNNs with external knowledge, culminating in a multimodal GNN. Specifically, our multimodal GNN comprises a backbone GNN denoted as f_B and a fusion GNN denoted as f_F. Given the graph data g, the backbone GNN f_B is employed to generate a node embedding E_q = f_B(g). The uncurated domain knowledge K is represented as a collection of language sequences, denoted as K = {k_1, k_2, ..., k_n}, where each knowledge item k_i corresponds to a summarization of domain knowledge. For instance, the abstract of a paper focusing on Alzheimer's Disease (AD) can be considered as a language"}, {"title": null, "content": "sequence k_i within the uncurated domain knowledge K for AD. To integrate K with E_f, we compute E_x = MLP(h(k_i)),\u2200k_i \u2208 K, where a pretrained language model h followed by a multi-layer perceptron MLP is utilized to generate the language embedding. We denote the knowledge embeddings collectively as E_x = {E_x|i = idx(k_i), k_i \u2208 K} with |K| = N. Utilizing E_f and E_x, a fusion graph g_f is constructed by connecting node G with feature E_f to each node i in K with feature E_x. This allows us to modify cross-modal edges to represent retrieval. The final prediction \u0177 for the target task is generated by the fusion GNN f_F, where \u0177 = f_F(g_f). Subsequently, following the forward propagation of the multimodal GNN f as defined, the model can be trained end-to-end using multimodal inputs g and K, leveraging any arbitrary loss function L specific to the target task. The design of our multimodal GNN is illustrated in Fig. 2(a).\nGraph-wise and knowledge-wise importance retrieval using masks. Given the pretrained GNN, we aim to identify the importance score represented by real-value masks of substructures in the graphs and the retrieved knowledge, to indicate the crucial components contributing to the prediction, and the details are shown in Fig. 2(b). Following the fashion in previous works, we define the explanation of predictions on the multimodal input g and K as a subgraph \u011f and a subset K. Since directly sampling them from g and K is computationally prohibitive and indifferentiable, we parameterized the sampling process as two types of learnable masks combined with Gumbel Softmax function [20], i.e., data mask M_d parameterized with \u03b1 on the graph g and knowledge mask M_k parameterized with \u03b2 on the fusion graph g_f. More specifically, for a given mask \u041c (M_d"}, {"title": null, "content": "or M_k) parameterized with \u03d5 (\u03b1 for M_d or \u03b2 for M_k), Gumbel Softmax function is applied to arbitrary entry within M as m_{i,j} =  \\frac{exp [(d_{i,j}+g_{i,j})/\u03c4]}{exp [(d_{i,j}+g_{i,j})]+exp (g'_{i,j})}, where d_{i,j} denotes the entry value indexed with (i,j) in M. g_{i,j} and g'_{i,j} are two independent random noise sampled from Gumbel distribution Gumbel(0, 1) controled by temperature \u03c4.\nGiven graph g = (V_g, W_g), where V_g denotes the node set of g and W_g \u2208 R^{|V_g|\u00d7|V_g|} represents the weighted adjacency matrix of g, the matrix M sampled from M_d is applied to W, to approximate the sampling of edges as W' = M  \u2299 W_g, where  \u2299 is the element-wise matrix multiplication. With W', we sample g' = (V_g, W'), and calculate the node embedding as E_{G'} = f_B(g'). Node embedding E_d is then used together with the knowledge embedding E_x to construct the fusion graph g'_f = (V_f, A_f), where V_f denotes the node set of g'_f and A_f \u2208 R^{|V|-1} represents the unweighted adjacency matrix of g'_f, where all the entries are one. Similarly, for fusion graph g'_f, we apply the sampled mask M_k to A_f to approximate the sampling of edges as A' = M_k  A_f and get the sampled fusion graph g'_f. The final prediction is calculated by f_F(g'_f).\nWe define L_{exp} to learn the masks with hyperparameters \u03bb_1, \u03bb_2, \u03bb_3, \u03bb_4,\nL_{mask} = \u03bb_1L_{mask} + \u03bb_2L_{clf} + \u03bb_3L_{spas} + \u03bb_4L_{disc}. \\qquad (1)\nL_{mask} = - \\sum_{c=1}^{C} 1 [y = c] log P_f(\u0177' = \u0177|g', g'_f) denotes the disagreement between the prediction \u0177 made on the original inputs and the prediction \u0177' made on the sampled inputs. C is the class number in the target task. L_{clf} = \\sum_{c=1}^{C} 1[y = c]log P_f(y' = y|g', g'_f) encourages the consistency between \u0177' and the label y. L_{spas} = \\frac{1}{|M_d|} \\sum_{i, j}\u03c3(M^{d}_{i, j}) + \\frac{1}{|M_k|} \\sum_{i, j}\u03c3(M^{k}_{i, j}) controls the sparsity of the two masks, where \u03c3(\u00b7) represents the sigmoid function. |M_d| and |M_k| are the number of entries in M_d and M_k, respectively. L_{disc} = \\frac{1}{|M_d|} \\sum_{i, j} L_{ent}(\u03c3(M^{d}_{i, j})) + \\frac{1}{|M_k|} \\sum_{i, j} L_{ent}(\u03c3(M^{k}_{i, j})) promotes the discreteness of the two masks, where L_{ent}(\u00b7) is the binary entropy function.\nThis section only considers one pair of M_d and M_k for simplicity. However, we can generalize it to multiple pairs cases. For instance, if genders are provided, we can define M^{female} = {M^{female}_d, M^{female}_k} and M^{male} = {M^{male}_d, M^{male}_k}, and train each pair of masks separately.\nGraph augmentation enhanced by retrieved importance. We propose a graph augmentation method guided by the crucial components in prediction, i.e., the learned masks, to fine-tune the pretrained multimodal GNN f, aiming to enhance model performance. Specifically, during fine-tuning, we employ a threshold T on \u03c3(M) to guide edge sampling as follows: for any arbitrary entry value m_i, we retain the corresponding edge when m_i > T; otherwise, we randomly sample the corresponding edge with a probability of 0.5 for each iteration. A schematic illustration of this process is provided in Fig. 2(c), where m_1 and m_2 are both less than T, while m_3 and m_4 exceed T. Consequently, edges 3 and 4 are retained across both iteration 1 and j, whereas edge 1 exists solely in iteration 1, and edge 2 appears only in iteration j. This methodology can be"}, {"title": null, "content": "uniformly applied to all computed masks, thereby substantially increasing input diversity to f concerning less significant edges, while retaining crucial edges for prediction, as indicated by the entry values within the masks."}, {"title": "Experiments", "content": "Datasets and Settings. We evaluate our approach on two AD datasets, i.e., OASIS [26] and ADNI-D [31]. For each, we include two graph datasets in different modalities, where one is derived from DTI imaging while the other one is derived from fMRI imaging.\n* OASIS contains 815 subjects. 155 subjects are diagnosed with AD and the others are seronegative controls. For each subject, there are 132 regions of interest (ROIs) based on Harvard-Oxford Atlas [8] and AAL Atlas [42]. There are 459 females, including 66 AD patients and 393 seronegative controls, and 356 males, including 89 AD patients and 267 seronegative controls.\n* ADNI-D contains 340 subjects. 154 patients are diagnosed with mild cognitive impairment (MCI), which is the early stage of AD. The others are seronegative controls. For each subject, 85 ROIs are derived from T1-weighted MRI using FreeSurfer (V6.5) [7]. There are 210 females, including 84 MCI patients and 126 seronegative controls, and 130 males, including 70 MCI patients and 60 seronegative controls.\nFor domain knowledge K of AD, we collected 20,108 records related to AD in the last 20 years from PubMed 1. Each record consists of the title and the abstract of a paper. We use BERT-Large [9] to encode K. BERT-Large is pre-trained with whole word masking on the uncased version of the training corpus. We evaluate GCN [24], GINE [63], and GAT [44] as the architecture of both the backbone and fusion GNN within the multimodel GNN (MM-GNN). Given the prior knowledge about the gender distribution of the dataset, we introduce two pairs of masks for graph-wise and knowledge-wise importance retrieval, where one is for males and the other is for females. Please refer to the supplementary materials for training details.\nMain Results. The proposed MM-GNN significantly outperforms the plain version of GNN, and the MM-GNN with fine-tuning further improves the performance."}, {"title": null, "content": "As shown in Table 1, the performance can be improved significantly when the domain knowledge is injected into the inference of GNN. For example, on the two datasets of ADNI-D, compared with vanilla GCN, 10.08%, 19.41% and 24.03% relative improvement is gained in ACC, AUC and F1 on average, respectively. Moreover, the performance can be further enhanced when fine-tuning the multimodal GNN guided by the generated masks. For instance, on the two datasets of ADNI-D, compared with plain MM-GCN, 3.06%, 2.43% and 4.32% relative improvement can be achieved in ACC, AUC and F1 on average, respectively."}, {"title": "Qualitative Analysis on Graph-wise Masks", "content": "To analyze the generated graph-wise masks, we calculate the importance score of each ROI based on the graph-wise mask and highlight the top 10 salient ROIs on the brain saliency maps in Fig. 3. Note that the color in each brain saliency map of Fig. 3 is applied to distinguish different ROIs only.\nAs shown in Fig. 3, it is clear that the salient ROIs are distinct for males and females, which is consistent with the existing studies [37,49]. Moreover, MM-GNNs with different architectures can also show a distinct preference for their prediction even if they are trained on the same dataset. For instance, MM-GCN and MM-GAT share 5 salient ROIs and have 5 unique salient ROIs. Such kinds of insights are usually difficult for human experts to extract but can be automatically captured by our approach."}, {"title": "Qualitative Analysis on Knowledge-wise Masks", "content": "Our approach can automatically adapt its way to employ the domain knowledge to the change in the gender, backbone and dataset. Fig. 4 shows the distribution of values within the knowledge-wise masks, which can be interpreted as the distribution of importance scores of domain knowledge. And we have several observations. First, males and females have different ways to leverage the given domain knowledge for inference. Second, different architectures of MM-GNN show different patterns on the knowledge-wise mask. Compared with MM-GCN, MM-GAT tends to have a more sparse distribution. Last, even when the domain is the same (i.e., AD), our approach can propose different paradigms to leverage the domain knowledge when the dataset is different."}, {"title": "Ablation Study on the Size of Domain Knowledge", "content": "We conducted the ablation study on the size of the domain knowledge, where we randomly sampled 1% and 10% records from the complete set of domain knowledge K to train the MM-GNN. The results are shown in Table 2 and we have two observations. First, the performance improvement is minor and even suffers from degradation when increasing the size of domain knowledge from about 200 (1%) to about 2,000 (10%). Second, the benefits from a larger set of domain knowledge become obvious when increasing the size of domain knowledge to more than 20,000 (100%). Therefore, we can conclude that although the performance may have little improvement when increasing the set of domain knowledge to a moderate size, a noticeable boost in performance can be observed when increasing the size of domain knowledge to a much larger size."}, {"title": "Related Work", "content": "Graph Neural Network (GNN). Deep neural networks (DNNs) have achieved great success in processing data with regular formats, such as the convolutional neural networks for image [57,32,55,68,70,56,51] and recurrent neural networks for sequence data [13,14,35]. However, the irregular structures of graph data pose unique challenges to applying DNNs to handling graph data. Therefore, a great amount of effort has been made to the research to design the graph neural"}, {"title": null, "content": "networks, whose core is the iterative update of node representations by integrating the features of neighboring nodes [5,25,4,16,12,2]. Graph convolutional networks (GCNs) [24], the most popular GNN architecture, are recognized for their simplicity and effectiveness, employing a layer-wise linear transformation matrix in node representation refinement. Graph attention networks (GAT) [44] marks a significant evolution in GNNs, addressing GCNs' limitations by employing an attention mechanism [1,43] to evaluate neighbor significance, which is widely used in applications of natural language processing [22] and computer vision [23,69,53,54,58,48,58,59]. Graph isomorphism Network (GIN) [63] is another critical development in GNN research, focusing on the implementation of permutation invariance to ensure output consistency irrespective of node index order. These breakthroughs in the design of GNN have made it one of the most popular algorithms to handle graph data. GNNs have now been widely used in diverse graph applications such as community detection [36,29,52], disease diagnosis [40] and molecule property prediction [10].\nUnderstanding Graph Data with Large Language Models (LLMs). LLMs have demonstrated significant capability across a variety of tasks, including classification [11,67], question answering [45,65], code generation [47], and named entity recognition [71], etc. However, their proficiency in handling irregularly structured data, especially graph data, is an emerging yet underdeveloped area. The main challenges of applying LLMs to graph data are the lack of a solid method to describe the graph data in natural language without information loss and the effective prompt techniques to elicit the pretrained LLM to generate appropriate responses for graph-related applications. Recent studies [15] have investigated the integration of LLMs with graph data to improve their effectiveness in graph mining tasks. The results show that while LLMs have some ability to handle graph-structured data, they still fall short of specialized graph-oriented models, indicating the need for further development. Moreover, there also emerges works to extend the usage of LLMs to graph tasks like selecting graph processors [66], generating state-of-the-art (SOTA) graph embeddings [64], and creating prompts for graph inputs [21,17,34]. Another relevant application is representation learning on text-attributed graphs (TAGs) [18], which customized the prompts to ask the LLM to generate both predictions and text explanations for each node."}, {"title": "Conclusion", "content": "We introduce a self-guided approach to autonomously integrate domain knowledge into GNNs to harness collected uncurated AD knowledge. Our approach can effectively extract curated knowledge and explanations on graphs for AD and guide the fine-tuning to improve the performance of GNNs. Extensive experiments on real-world AD datasets demonstrate the effectiveness of our method."}]}