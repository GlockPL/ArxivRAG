{"title": "Optimizing Student Ability Assessment: A Hierarchy Constraint-Aware Cognitive Diagnosis Framework for Educational Contexts", "authors": ["Xinjie Sun", "Qi Liu", "Kai Zhang", "Shuanghong Shen", "Fei Wang", "Yan Zhuang", "Zheng Zhang", "Weiyin Gong", "Shijin Wang", "Lina Yang", "Xingying Huo"], "abstract": "Cognitive diagnosis (CD) aims to reveal students' proficiency in specific knowledge concepts. With the increasing adoption of intelligent education applications, accurately assessing students' knowledge mastery has become an urgent challenge. Although existing cognitive diagnosis frameworks enhance diagnostic accuracy by analyzing students' explicit response records, they primarily focus on individual knowledge state, failing to adequately reflect the relative ability performance of students within hierarchies. To address this, we propose the Hierarchy Constraint-Aware Cognitive Diagnosis Framework (HCD), designed to more accurately represent student ability performance within real educational contexts. Specifically, the framework introduces a hierarchy mapping layer to identify students' levels. It then employs a hierarchy convolution-enhanced attention layer for in-depth analysis of knowledge concepts performance among students at the same level, uncovering nuanced differences. A hierarchy inter-sampling attention layer captures performance differences across hierarchies, offering a comprehensive understanding of the relationships among students' knowledge state. Finally, through personalized diagnostic enhancement, the framework integrates hierarchy constraint perception features with existing models, improving the representation of both individual and group characteristics. This approach enables precise inference of students' knowledge state. Research shows that this framework not only reasonably constrains changes in students' knowledge states to align with real educational settings, but also supports the scientific rigor and fairness of educational assessments, thereby advancing the field of cognitive diagnosis.", "sections": [{"title": "1. INTRODUCTION", "content": "Cognitive diagnosis (CD) is a core task in educational data mining, aimed at revealing students' proficiency in specific knowledge concepts (KCs) by analyzing their response logs (Cheng et al., 2019; Wang et al., 2024a). With the widespread adoption of intelligent education applications, the demand for cognitive diagnosis in assessing and improving individual development is increasingly growing (Yao et al., 2023). By analyzing students' interaction data with exercises, cognitive diagnosis models students' abilities and evaluates their knowledge state, thereby enhancing learning efficiency and helping students gain a clearer understanding of their learning progress."}, {"title": "2. RELATED WORKS", "content": "Accurately identifying students' knowledge state in real educational contexts is a highly valuable task. Subsequently, we will introduce relevant research work from two perspectives: cognitive diagnosis and educational hierarchy."}, {"title": "2.1. Cognitive Diagnosis", "content": "Cognitive diagnosis plays a critical role in various fields, including education, gaming, and healthcare. Its core objective is to deeply reveal learners' latent traits and cognitive characteristics by analyzing their testing data, thereby providing a modeling foundation for the interaction between learners and item features (Zhou et al., 2021; Zhang et al., 2024).\nAs one of the foundations of cognitive diagnosis, Item Response Theory (IRT) was initially proposed to describe the relationship between learners' performance on specific tasks and their latent abilities Lord (2012); An and Yung (2014). By mapping item characteristics (e.g. difficulty and discrimination) to learner traits (e.g. ability), IRT models offer an effective statistical method for analyzing individual differences (Stucky and Edelen, 2014; Gyamfi and Acquaye, 2023). However, IRT typically assumes that learners' cognitive traits are unidimensional,"}, {"title": "2.2. Educational Hierarchy", "content": "In the field of education, research related to hierarchy involves multiple key theories and models (Kemp et al., 2019; Kaviyaraj and Uma, 2022; Dlamini and Gerber, 2023). The hierarchy of needs theory proposed by Maslow (1943) emphasizes the impact of different levels of needs on learning motivation; cognitive development theory explores children's cognitive abilities at various developmental stages (Whiteside and Wixon, 1988); and the taxonomy of educational objectives proposed by Bloom et al. (1956) categorizes learning goals into levels such as knowledge, understanding, and application, providing guidance for curriculum design and assessment. Hierarchy analysis is used in educational evaluation and resource allocation, assisting in trade-offs among multi-level factors (Moslem et al., 2023); meanwhile, hierarchy knowledge tracing models analyze students' mastery of knowledge, supporting personalized learning (Sun et al., 2024c; Wang et al., 2024a). Additionally, research on multi-level educational systems investigates the interactions within educational policies and practices, highlighting the importance of systems thinking, while studies on hierarchical learning environments focus on how different learning contexts affect student outcomes (Bernard et al., 2014; D'Mello and Graesser, 2023). These studies provide an important theoretical foundation and practical guidance for understanding hierarchy in education.\nEffective stratification of educational objectives is crucial in the education sector. It not only helps educators and learners better understand learning goals but also enables more effective design and implementation of teaching strategies. Various methods exist to achieve this goal. For instance, Maslow's hierarchy of needs classifies human needs into five levels (Yang et al., 2021), while Gardner's theory of multiple intelligences emphasizes the importance of recognizing and developing students' diverse intelligences (Zhang et al., 2021). Our HCD framework is based on students' relative positions of average scores in prior statistics to conduct an initial hierarchy categorization.\nThe application of educational hierarchy is wide-ranging, covering multiple areas. Banda et al. (2023) explores how different levels of learning objectives affect educational practices in their revised Bloom's taxonomy. Li et al. (2024) developed a machine learning method to automatically label the matching of open educational resources and skill classifications, thereby addressing the labor-intensive issue of manual tagging and publicly released a pre-trained model, enhancing the practicality and policy impact of educational resources. Additionally, Huang and Qiao (2024) effectively improved high school students' computational thinking skills, learning motivation, and self-efficacy by stratifying teaching objectives through the integration of artificial intelligence education and the STEAM model. Weinberger (2010) demonstrates how to effectively apply the principles of stratification in the design of innovative learning experiences. These studies collectively reveal the important role of educational stratification in enhancing teaching effectiveness and learning outcomes."}, {"title": "3. PRELIMINARY", "content": "In this section, we formally define the concept of Hierarchy Constraint-Aware Cognitive Diagnosis. Additionally, we introduce the key components of the HCD framework."}, {"title": "3.1. Problem Definition", "content": "In the framework of hierarchy constraint-aware cognitive diagnosis, we define several core sets: the set of students S, the set of exercises E, the set of knowledge concepts KC, the set of hierarchy levels H, and the set of responses R. Specifically, the students set $S = {S_1, S_2, ..., S_n}$ contains n distinct students, while the exercises set $E = {e_1, e_2, ..., e_m}$ includes m unique exercises. The knowledge concepts set $KC = {kc_1, kc_2, ..., kc_k}$ comprises k different concepts. The hierarchy levels set $H = {h_1, h_2, ..., h_g}$ consists of g levels. The responses set $R = {0, 1}$ is used to evaluate students' answers, where 1 denotes a completely correct response and 0 denotes an incorrect one.\nWe construct the student test record L as a set of triples (s, e, h). Where s represents the student (s \u2208 S), e denotes the exercise (e \u2208 E), and h indicates the level the student is in (h\u2208 H). Additionally, the exercise Q-matrix we use is predetermined (typically annotated by experts) and is denoted as $Q = Q^{m \\times k}$. In this matrix, if exercise $e_i$ is associated with knowledge concept $kc_j$, then $Q_{ij} = 1$; otherwise, $Q_{ij} = 0$.\nBased on these definitions, we provide the specific definition of hierarchy-aware cognitive diagnosis as follows:\nHierarchy Constraint-Aware Cognitive Diagnosis (HCD): Given a student's test records $L = {(S_n, e_1, h_g), (S_n, e_2, h_g), ..., (S_n, e_t, h_g)}$ and the known Q-matrix, the goal is to infer the student's ability levels across various knowledge concepts. By introducing a hierarchy structure, we constrain the ability estimation process to ensure the assessment results remain reasonable and align with real educational contexts."}, {"title": "3.2. Basic Factors", "content": "Before starting the interactive analysis of cognitive diagnosis, it's important to outline some basic factors to help understand the interactions involved.\nFirstly, the personalized knowledge proficiency vector $S^p$ and the hierarchy constrained knowledge proficiency $S^h$ are both vectors of equal length to the number of knowledge concepts. These two vectors are calculated by multiplying the one-hot encoding of the student ID $x_s$ and the one-hot encoding of the hierarchy ID $x_h$ with the trainable knowledge proficiency matrices S and H:\n$S^p = \\sigma(x_s \\times S),$ (1)\n$S^h = \\sigma(x_h \\times H),$ (1)\nwhere $S^p \\in (0,1)^{1\\times k}$ represents the personalized knowledge proficiency of the student, and $S^h \\in (0, 1)^{1\\times k}$ indicates the proficiency of knowledge concepts under hierarchy awareness. The one-hot encoding of the student is denoted as $x_s \\in {0,1}^{1\\times n}$, with the corresponding trainable proficiency matrix given by $S\\in R^{n\\times k}$. Similarly, the one-hot encoding for different hierarchies is represented as $x_h \\in {0, 1}^{1\\times g}$, and its trainable proficiency matrix is $H \\in R^{g\\times k}$. Where $\\sigma(\\cdot)$ denotes the sigmoid activation function.\nSecondly, when addressing the fundamental factors related to exercises, we focus on the difficulty of the knowledge concepts and the discrimination of the questions by one-hot encoding the exercise ID $x_e$. Within the framework of cognitive level research, the Q-matrix serves as one of the key elements to describe the relationship between exercises and knowledge concepts (Tatsuoka, 1983). The knowledge concepts involved in each exercise are typically quantified using this matrix. For a specific exercise e, we can extract its corresponding knowledge concept relevance vector $Q_e$ from the Q-matrix, calculated as follows:\n$Q_e = x_e \\times Q,$ (2)\nwhere $x_e \\in {0, 1}^{1\\times m}$ represents the one-hot encoding of the ID of exercise e, where $Q_e \\in {0, 1}^{1\\times k}$ indicates the knowledge concept relevance vector for that exercise, effectively capturing the association between each exercise and its related knowledge concepts."}, {"title": "4. HCD Framework", "content": "In this section, we will provide a comprehensive overview of the designed two-stage Hierarchy Constraint-Aware Cognitive Diagnosis (HCD) framework based on the formulaic expressions of the cognitive function. Subsequently, we will delve into the key details and implementation mechanisms of the two-stage model within this framework."}, {"title": "4.1. Model Overview", "content": "Typically, a student's performance on an exercise can be represented by the formula:\n$r = CDM(S^\\theta, \\psi_e),$ (3)\nwhere r denotes the student's response (e.g. score or correctness), $S^\\theta$ represents the student's knowledge mastery level, and $ \\psi_e$ consists of parameters related to the exercise (e.g., difficulty $h_{diff} \\in (0,1)^{1\\times k}$ and discrimination $h_{disc} \\in (0,1)$, with k being the number of knowledge concepts). This process is typically based on manually designed cognitive behavior models, such as the item response functions used in IRT.\nTo ensure that the predicted student ability values more accurately reflect the students' true capabilities, we consider relative constraints by comparing their performance with that of other students. For example, a student's ability value should not be excessively elevated due to relatively good performance in a single exam without considering their overall performance, especially when they may be underperforming in other areas. We divide knowledge mastery $\\theta$ into two components:\n$\\theta = F(S^h, S^p),$ (4)\nwhere $S^h$ represents the relative ability characteristics under hierarchy constraints, while $S^p$ denotes the student's personalized absolute performance characteristics. The function F reflects the influence of these two characteristics.\nAs shown in Figure 2, the overall structure of the HCD framework can be divided into two main stages: the Hierarchy Constraint-Aware Modeling Stage and the Personalized Diagnostic Enhancement Stage. In the Hierarchy Constraint-Aware Modeling Stage, we design two attention networks to simulate the impact of hierarchy constraints on knowledge mastery. In the Personalized Diagnostic Enhancement Stage, we integrate personalized knowledge mastery (absoluteness) and knowledge mastery under hierarchy constraints (relativeness) to output predicted scores using the cognitive behavior function. After training with students' logs, we obtain each student's knowledge mastery as the diagnostic result. The following sections will provide a detailed introduction to these two stages."}, {"title": "4.2. Hierarchy Constraint-Aware Modeling", "content": "In the Hierarchy Constraint-Aware Modeling Stage, we designed two hierarchy attention networks to simulate the relationships in knowledge mastery among students both within and across hierarchies. The entire network consists of three components: hierarchy mapping, intra-hierarchy attention layer, and inter-hierarchy attention layer."}, {"title": "4.2.1. Hierarchy Mapping", "content": "Based on the hierarchy information derived from score intervals, valuable prior knowledge can be provided for the assessment process, allowing for more accurate capture of characteristics among students at different levels. This hierarchy information not only enhances the stability and rationality of ability assessments but also strengthens the overall robustness of evaluations, enabling better handling of students at varying levels and avoiding situations of \"not enough\" or \"falling behind.\" To more reasonably assess students' ability levels, we construct prior hierarchy information based on score intervals.\nLet $X = {X_1, X_2, ..., X_n}$ represent the average scores of all students, where $x_i$ denotes the average score of the i-th student. The mean $\\bar{x}$ and standard deviation $\\sigma$ of the average scores are calculated as follows:\n$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} X_i,$ (5)\n$\\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}.$ (5)\nBased on this, we define the score intervals $B = {b_0,b_1,...,b_g}$ and their corresponding label set $L = {l_0, l_1, ..., l_g}$. The mapping function $f: X \\rightarrow L$ is defined as:\n$f(x) = l_j \\quad b_j \\leq X_i < b_{j+1}, \\quad \\forall i \\in [1,n], j \\in [0, g].$ (6)"}, {"title": "4.2.2. One-hot Embedding", "content": "This layer assigns trainable embeddings to each hierarchy entry $h_j$, mapping them to potential knowledge proficiency features based on the student's current level. Let $O \\in R^{n \\times g}$ be the One-Hot encoding matrix, defined as:\n$O_{ij} = \\begin{cases}\n1 & \\text{if Eq.(6)}\\\\\n0 & \\text{otherwise}\n\\end{cases} \\quad \\forall i \\in [1,n], j \\in [0, g \u2013 1],$ (7)\nSubsequently, we convert the One-Hot encoding O into a knowledge concept vector $H_{KCs} \\in R^{n \\times k}$ through a linear transformation, represented as:\n$H_{KCs} = W^O O + b,$ (8)\nwhere $W^O \\in R^{g \\times k}$ is the weight matrix of the linear layer, $b \\in R^k$ is the bias vector, g is the number of hierarchy levels, and k is the number of knowledge concepts."}, {"title": "4.2.3. Intra-Hierarchy Convolution Enhanced Attention Layer (CEA)", "content": "In educational contexts, students at the same level often exhibit significant overall ability similarities. However, despite being classified into the same level, their performances on specific knowledge concepts can vary considerably (Lohman and Nicpon, 2023). A detailed analysis of the performances of students within the same level on identical knowledge concepts is crucial for accurately assessing their mastery of these concepts (Terry et al., 2002). Therefore, focusing on the performances of students at the same level on the same knowledge concepts enhances the model's sensitivity to knowledge mastery and improves the accuracy and effectiveness of educational cognition.\nTo better capture the performances of students at the same level on identical knowledge concepts, we first extract feature representations $C_h \\in R^{G' \\times k}$ using different convolution kernels $K_h$:\n$C_h = C(H_{KCs}; K_h),$ (9)\nwhere C denotes the convolution operation, $H_{KCs}$ is the knowledge concept embedding matrix, and G' is the dimension of the features after convolution.\nSubsequently, we calculate the representations of queries $Q_h \\in R^{G' \\times k}$, keys $K_h \\in R^{G' \\times k}$, and values $V_h \\in R^{G' \\times k}$ for each convolution head h, as follows:\n$Q_h = C_h W_q^h,$\n$K_h = C_h W_k^h,$\n$V_h = C_h W_v^h,$ (10)\nwhere $W_q^h$, $W_k^h$, $W_v^h \\in R^{k \\times k}$ are the trainable weight matrices for queries, keys, and values.\nTo generate the attention output $Z_h$, we perform similarity measurements based on the features generated by convolution:\n$Z_h = \\sigma(\\frac{Q_h K_h^T}{\\sqrt{k}} V_h)$ (11)\nwhere $\\sigma(\\cdot)$ is the Sigmoid function, emphasizing the interdependence among them.\nFinally, we aggregate the attention outputs from all convolution heads to obtain the knowledge feature representation of students within the same level. This aggregation further enhances the expressive capability of the feature representations and helps the model better capture the complex relationships between different knowledge concepts. After aggregation, we need to apply further transformations to the intra-level feature representations to obtain $H_{intra} \\in R^{G \\times k}$. The specific formulas are as follows:\n$H_{intra} = \\frac{1}{H_A} \\sum_{h=1}^{H_A} Z_h$\n$H_{intra} = W_{intra} H_{intra} + b_{intra},$ (12)\nwhere $H_A$ is the number of attention heads, $W_{intra} \\in R^{k \\times k}$ is the weight matrix of the fully connected layer, and $b_{intra} \\in R^k$ is the bias term."}, {"title": "4.2.4. Inter-Hierarchy Random Sample Attention Layer (RSA)", "content": "The CEA module models the interactions among the same knowledge concepts within the same level, but capturing the performance differences among student groups to gain a comprehensive understanding of students' knowledge state remains a significant challenge. This is particularly true in sparse educational datasets, where maintaining reasonable estimates of students' abilities is crucial (Yao et al., 2023). By correlating the hierarchy distributions of different students, we can avoid extreme ability estimation issues.\nIn the inter-level attention mechanism, since students at the same level exhibit significant similarities, we randomly sample one student's features from other levels for interaction to reduce computational complexity. This design not only helps to decrease the computation load but also ensures the acquisition of information from students at different levels, enhancing the model's generalization ability. The specific definitions are as follows:\n$Q_g = W_q H_{intra},$\n$K_g = W_k H_{KCs},$\n$V_g = W_v H_{KCs}$ (13)\nwhere g denotes the current level, and g' represents other levels.\nSubsequently, to highlight the relevance of knowledge between levels and make the ability assessment of students more sensitive, we calculate the attention scores between the queries of level g and the keys of the sampled subset of students at level g' to obtain context-aware representations:\n$Z_g^\\prime = softmax(\\frac{Q_g K_{g'}^T}{\\sqrt{k}} V_g)$ (14)"}, {"title": "4.3. Personalized Diagnosis Enhancement", "content": "In this phase, we integrate hierarchical features with students' personalized knowledge levels. First, each student's personalized characteristics are described by a latent vector $\\theta_{person}$. Then, we adopt an adaptive optimization strategy for personalized weighting, combining hierarchical features with personalized features to form a comprehensive state for the student:\n$\\alpha_{pw} = \\sigma(\\Epsilon_{person}[s]),$\n$\\Theta = \\alpha_{pw} \\Theta_{hierarchy} + (1 - \\alpha_{pw}) \\cdot \\Theta_{person},$ (17)\nwhere $\\Epsilon_{person}$ is a trainable weight matrix, and s is the student index.\nIn this model, we use the basic paradigm of cognitive diagnosis models to predict students' responses to exercises, with the specific formula given by:\nr = $Q_e (\\Theta - h_{e diff}) x h_{disc}$, (18)\nthis approach is applicable to various cognitive diagnosis models, such as IRT, MIRT, DINA and NeuralCD.\nr = $CDM(\\Theta, \\psi_e)$, (19)\nwhere $ \\psi_e$ includes exercise-related parameters such as difficulty $h_{e diff}$ and discrimination $h_{disc}$."}, {"title": "4.4. Objective Function", "content": "To optimize all parameters within the HCD framework, we systematically analyze each response logs record in the test data and employ a cross-entropy loss function to measure the difference between the predicted values $y_i$ and the students' actual response labels r. The specific form of the loss function is as follows:\n$L(y, r) = \u2212 \\sum_i (r_i log(y_i) + (1 \u2212 r_i) log(1 \u2013 y_i))$ . (20)\nWe utilize the Adam optimization algorithm to minimize this loss function. By separately evaluating the outputs based on hierarchical features, personalized features, and existing prediction methods, we are able to capture students' learning state more comprehensively. This multi-level loss setup helps to more accurately identify students' ability differences across various knowledge domains, thereby optimizing the assessment effectiveness. The specific loss function definitions are as follows:\n$loss_h = L(y_{hierarchy}, r),$\n$loss_p = L(y_{person}, r),$\n$loss_i = L(y_{integration}, r),$\n$loss = loss_h + loss_p + loss_i,$ (21)\nwhere $y_{hierarchy}$ represents the prediction based on hierarchical features, $y_{person}$ represents the prediction based on students' personalized learning characteristics, and $y_{integration}$ denotes the output using existing prediction methods. The experimental section will further detail other setup specifics."}, {"title": "5. EXPERIMENTS", "content": "In this section, we will introduce the real dataset used for the experiments and provide detailed descriptions of key aspects of the training process and the selected baseline models. We will then compare the impact of incorporating the HCD features proposed in this study on student performance in relation to the baseline models. To clearly demonstrate the effects of the HCD hierarchy constraints on model performance and knowledge state assessment, we will delve into the following research questions:\n\u2022 RQ1: How does the proposed HCD framework impact student performance prediction compared to existing frameworks?"}, {"title": "5.4. Performance Prediction (RQ1)", "content": "Due to the inability to directly measure students' true knowledge state, evaluating the performance of cognitive diagnosis models is challenging. Although our primary goal is not to directly enhance the predictive performance of the models, indirectly assessing their validity through student performance predictions can still reveal the significance of hierarchy constraint perception (HCD) in cognitive diagnosis.\nTable 3 presents the performance of various classical cognitive diagnosis models combined with HCD. Through analysis, we derive several key conclusions. First, overall, methods that incorporate HCD (such as HCD-IRT) significantly outperform traditional methods (such as IRT), indicating the importance of integrating hierarchy constraint features into cognitive diagnosis. Second, after applying HCD to the NCDM model, we achieved optimal performance in AUC, ACC, and RMSE metrics, further demonstrating that the powerful fitting ability of neural networks can more effectively assess students' knowledge state. Lastly, analysis of the three datasets revealed that HCD exhibits strong adaptability. Whether in the larger PISA-Science dataset or the less interactive PISA-Math dataset, HCD performed well. Even in the relatively smaller PISA-Read dataset, the positive effects of hierarchy constraints were evident, proving the wide applicability of HCD.\nTo validate the effectiveness of two key modules in the HCD framework (CEA and RSA), we conducted ablation experiments. Specifically, we replaced each layer with a simple aggregation layer that merely averages the inputs while keeping the other layers unchanged. Table 3 lists the results under different scenarios, leading to the following conclusions: First, regardless of which layer was replaced, the final performance decreased, indicating that each module contributes to the overall performance and demonstrating their effectiveness in modeling both intra- and inter-layer relationships. Second, when replacing the convolution-enhanced attention layer within the hierarchy, the performance decline was most significant, highlighting the critical importance of accurately modeling the relationships between the same knowledge concepts within the same hierarchy in hierarchy constraint modeling."}, {"title": "5.5. Hierarchy Constraint Aware (RQ2)", "content": "The introduction of hierarchy constraint perception aims to enable existing cognitive diagnosis models to more accurately reflect students' relative ability performance, thus allowing for a more reasonable inference of their ability levels across various knowledge concepts. This constraint helps ensure that assessment results remain within a reasonable range. Figure 3 illustrates the performance effects of hierarchy constraints on two typical datasets, PISA-Read and PISA-Math, using kernel density plots."}, {"title": "5.6. Individual Knowledge State Modeling (RQ3)", "content": "Assessing the accuracy of student knowledge state is crucial for cognitive diagnosis. Figure 3 illustrates the hierarchy constraints under group effects, but the extent to which individuals are influenced by these constraints requires further exploration. We categorized students into six levels (Sun et al., 2024c) and randomly selected one student from each level to visually present their mastery of 11 KCs in the PISA-Math dataset (see Figure 4), which reveals several key observations.\nFirst, there are significant differences in knowledge state among students at different hierarchies. Each student's answering records vary, resulting in diverse levels of knowledge mastery. This indicates that the model has strong discriminative power in capturing students' knowledge state. Second, regardless of the hierarchy, certain knowledge concepts consistently show low mastery. For instance, in the H1 level, several knowledge concepts have mastery levels close to 0.24. This may be due to students not having encountered these knowledge concepts; nevertheless, the powerful fitting capability of the neural network still assigns some level of mastery, demonstrating its explanatory power in cognitive diagnosis, though there may also be some bias. Finally, the analysis found that individual knowledge mastery does not always align with expectations. For example, the average mastery level of students at the H4 level did not accurately reflect their expected position between H3 and H5. This suggests that even with the introduction of hierarchy constraints, not all students' knowledge state can be precisely modeled. The complexity of students' knowledge state is influenced by various factors, such as affect during answering (Spaulding and Breazeal, 2015), incorrect answers, and guessing. Therefore, future work still needs to further optimize cognitive diagnosis models to enhance their capability for accurate modeling of individual knowledge state."}, {"title": "5.7. Interpretability of Diagnostic Results (RQ4)", "content": "In cognitive diagnosis, a student's mastery of specific knowledge concepts significantly impacts their performance. Specifically, if student S1 has a better mastery of knowledge concept k than student S2, then S1 is likely to have a significantly higher probability of success when solving problems related to that knowledge concept compared to S2 (Chen et al., 2017). Based on this logic, we introduce the Degree of Agreement (DOA)"}, {"title": "5.8. Visualized Diagnosis Enhancement (RQ5)", "content": "The interaction between hierarchical abilities features and personalized ability features, as well as which feature has a greater impact on students, is visually illustrated in Figure 6. First, we observe that each student's personalized ability $\\Theta_{person}$ and hierarchical abilities $\\Theta_{hierarchy}$ show significant differences, highlighting the importance of personalized student ability modeling. Second, the influence weights of personalized and hierarchical abilities on students vary. For example, for Student S1, the personalized ability level is higher than the hierarchical abilities level, yet hierarchical abilities plays a greater role in the final student ability $\\Theta$. Conversely, for Student S14, although the hierarchical abilities level is higher, the influence weight of personalized ability on overall ability is greater. This indicates that each student's ability is affected differently by the two features. Finally, we note that the slope of the regression"}, {"title": "5.9. Case Study (RQ6)", "content": "The relationship between a student's cognitive diagnosis results, their abilities, and item difficulty can be quantitatively analyzed using Eq.(19). We randomly selected one student from the PISA-Science dataset along with five items they answered. The left half of Figure 7 displays the student's response results, while the right half presents the model's diagnostic outcomes. The radar chart illustrates the student's mastery of various knowledge concepts alongside the difficulty of the items.\nFrom the figure, it is evident that when a student's knowledge mastery meets the requirements of the item, they are more likely to provide a correct answer. For instance, in item e3, the student's personalized ability $\\Theta_{person}$ and hierarchical ability $\\Theta_{hierarchy}$ are 0.64 and 0.60, respectively, while the overall ability $\\Theta$ = 0.63 and the item's difficulty is 0.41. Since the student's proficiency in the knowledge concepts related to this item exceeds the required level, they successfully answered it. Conversely, in item e1, the student's personalized ability $\\Theta_{person}$ is 0.795, and their hierarchical ability $\\Theta_{hierarchy}$ is 0.37, with an overall ability of $\\Theta$ = 0.60 and the item's difficulty at 0.793. Although the student's personalized ability is higher than the item difficulty, their overall ability falls short of what is needed to solve the item, resulting in an incorrect response. This phenomenon aligns with the student's answers and further illustrates how incorporating hierarchical abilities can significantly enhance the accuracy of predictions regarding student responses."}, {"title": "6. Conclusions and Limitations", "content": "In this paper, we propose a novel Hierarchy Constraint-Aware cognitive Diagnosis (HCD) framework aimed at quantitatively analyzing students' cognitive state. Specifically, we designed a two-stage solution. In the hierarchy constraint awareness modeling phase, we introduced a convolution-enhanced attention network for the same knowledge concepts at the same level, while a feature-sampling attention network was used to simulate the impact of hierarchy constraint awareness on knowledge mastery between levels. In the personalized diagnosis enhancement phase, we combined personalized knowledge proficiency (absoluteness) with the knowledge proficiency influenced by hierarchy constraint awareness (relativeness).\nWithin this framework, we implemented four specific models (i.e., HCD-IRT, HCD-MIRT, HCD-DINA, and HCD-NCDM) and conducted extensive experiments on real-world datasets to validate the effectiveness and interpretability of the HCD framework. Finally, we analyzed and discussed the impact of hierarchy constraints on both student groups and individuals, with the hope that this research will inspire further exploration in related areas."}]}