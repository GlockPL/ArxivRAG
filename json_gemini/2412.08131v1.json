{"title": "DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions", "authors": ["Haiming Yao", "Wei Luo", "Ang Gao", "Tao Zhou", "Xue Wang"], "abstract": "Raman spectroscopy has attracted significant attention in various biochemical detection fields, especially in the rapid identification of pathogenic bacteria. The integration of this technology with deep learning to facilitate automated bacterial Raman spectroscopy diagnosis has emerged as a key focus in recent research. However, the diagnostic performance of existing deep learning methods largely depends on a sufficient dataset, and in scenarios where there is a limited availability of Raman spectroscopy data, it is inadequate to fully optimize the numerous parameters of deep neural networks. To address these challenges, this paper proposes a data generation method utilizing deep generative models to expand the data volume and enhance the recognition accuracy of bacterial Raman spectra. Specifically, we introduce DiffRaman, a conditional latent denoising diffusion probability model for Raman spectra generation. Our approach begins with applying a two-dimensional figure transformation to the Raman spectral data. Following this, we utilize the encoder of a Vector Quantized Variational Autoencoder (VQ-VAE) to compress the Raman figure into a lower-dimensional latent space. We then construct a Conditional Denoising Diffusion Probabilistic Model (DDPM) for representation learning and data augmentation. Ultimately, the decoder of the VQ-VAE is employed to reconstruct the spectrum from its low-dimensional latent representation. Experimental results demonstrate that synthetic bacterial Raman spectra generated by DiffRaman can effectively emulate real experimental spectra, thereby enhancing the performance of diagnostic models, especially under conditions of limited data. Furthermore, compared to existing generative models, the proposed DiffRaman offers improvements in both generation quality and computational efficiency. Our DiffRaman approach offers a well-suited solution for automated bacteria Raman spectroscopy diagnosis in data-scarce scenarios, offering new insights into alleviating the labor of spectroscopic measurements and enhancing rare bacteria identification.", "sections": [{"title": "1. Introduction", "content": "Bacterial infections continue to be a major cause of global death, making the identification of pathogenic bacteria and their susceptibility to antibiotics vital in clinical applications. This is essential for accurately diagnosing diseases caused by bacterial infections and determining treatment strategies. Raman spectroscopy, leveraging molecular vibrations, serves as a potent analytical tool capable of providing intricate molecular fingerprint information, thereby facilitating the analysis of diverse biochemical characteristics. In recent years, its non-destructive, label-free, and rapid detection characteristics have garnered widespread favor, leading to extensive application in the field of bacterial identification. The biochemical phenotypes of various subjects yield distinct spectral fingerprint in their respective Raman spectral data. However, in practical applications, the intricate composition of spectral data poses a significant challenge for direct and accurate identification by the human eye. Furthermore, interpreting the biochemical significance associated with different wavelengths necessitates extensive expert knowledge. Consequently, the automated analysis of spectral data has emerged as a critical concern.\nVarious methods have been proposed to effectively analyze Raman spectroscopy signals and achieve their identification. The Ramanome method proposed utilizes"}, {"title": "Preprint", "content": "specific wavelengths to conduct manual spectral analysis. However, the applicability of this expert knowledge-based approach is confined to particular tasks and lacks generalizability to other contexts. Another potential route involves employing data-driven machine learning methods. Conventional machine learning methods primarily involve extracting signal features pertinent to domain knowledge, followed by the classification of these extracted features using appropriate classifiers. For instance, a partial least squares discriminant analysis method was proposed for the classification of COVID-19 utilizing Raman spectroscopy. Principal component analysis (PCA) is employed for feature extraction, while support vector machines (SVM) are utilized as classifiers to categorize diseases based on Raman spectra. In existing research, other frequently employed methods also include k-nearest neighbors (KNN), discriminant function analysis (DFA), and random forests. Although numerous methods and their variants have been developed, this technical approach still has certain limitations: manually extracted features may loss implicit spectral characteristics, and the constructed classifiers are susceptible to overfitting, noise interference, and other issues.\nOwing to automated representation extraction, deep learning has been extensively applied across various fields. In Raman spectroscopy analysis, it has already demonstrated the capability to surpass the traditional machine learning methods in terms of accuracy, robustness, and generalizability. Various deep neural networks, including convolutional neural networks (CNNs), and recurrent neural networks (RNNs), have been utilized in Raman spectroscopy analysis. Transfer learning-enabled CNN was employed for large-scale bacterial identification. This research has been developed upon in subsequent studies, such as and U-Net. Raman spectroscopy and deep neural networks were employed for the in vitro and intraoperative pathological diagnosis of liver cancer. the authors introduced a two-dimensional (2D) Raman figure technique combined with CNN for tumor diagnosis.\nHowever, due to the extensive number of learnable parameters in deep neural networks, the optimization process for diagnostic models used in bacterial Raman spectroscopy often requires a large and diverse set of bacterial spectral samples to achieve robust performance. Nevertheless, obtaining a substantial amount of bacterial Raman spectroscopy data is not always feasible, such as in the single-cell measurement approach, where collecting a large number of measurements would entail significant labor. Furthermore, as pointed out, in clinical application, each patient may only provide a minimal number of bacterial spectra for diagnosis. Additionally, accurately labeling and organizing a large amount of spectral data also requires more manpower and expertise. Therefore, developing a deep neural network-based diagnostic system with limited available bacterial Raman spectroscopy data is an important issue.\nTo address the issue of data insufficiency, researchers typically employ data augmentation techniques to generate additional data for expansion. For instance, Gaussian noise and various perturbations are applied to the original Raman spectroscopy data. However, the benefits of such generated data are limited, as this approach primarily serves as a regularization method to prevent model overfitting. A more advanced approach involves employing generative models to produce synthetic data that is similar to the real data based on its distribution. Currently, widely used generative models include variational autoencoders (VAEs) and generative adversarial networks (GANs). Among these models, the quality of samples generated by VAEs is limited by Gaussian prior assumptions, whereas the superior data generation capability of GANs has made them a popular solution for addressing data scarcity. For instance, in the field of industrial failure diagnosis, discussed the issue of data scarcity by incorporating GANs. Despite the significant success of GANs, these models are generally regarded as challenging to train and are susceptible to mode collapse due to their adversarial training mechanism.\nGiven the limitations of the aforementioned generative models, we introduce the physically inspired denoising diffusion probabilistic model (DDPM) as an innovative approach for the generation of Raman spectra. This model demonstrates exceptional performance and training stability across various computer vision tasks, including image generation and image editing. Specifically, DDPM generates new samples that follow the distribution of the original data through"}, {"title": "Preprint", "content": "a parameterized Markov process using variational inference. This process employs noise as a medium, treating the chain of noise as a learnable variable. The variable is iteratively degraded until the noise is completely removed, thus restoring the original input or producing synthetic data with accurate statistical characteristics and patterns.\nIn this paper, we propose the DiffRaman, a conditional latent denoising diffusion probabilistic model to synthesize additional Raman spectroscopy data, thereby enhancing the spectral diagnostic accuracy under limited data situations. The original DDPM operates in the data space, requiring substantial memory resources for optimization and inference. To reduce computational load while maintaining generation performance, we introduced an autoencoder to compress the original spectral data into a low-dimensional latent space. We further employed a vector quantization variational autoencoder (VQ-VAE) to enhance the autoencoder's performance. Following this, a diffusion process is executed on the low-dimensional data within the latent discrete space of the VQ-VAE, incorporating a conditional mechanism to regulate the diffusion process and retain the category semantics of the generated data. Finally, the generated low-dimensional data is decoded to produce the new spectrum. To the best of our knowledge, our work represents the initial endeavor to introduce the concept of diffusion generation within the Raman spectroscopy diagnostics community. The primary contributions of this work can be summarized as follows.\n1. We introduced the concept of employing data generation methods in the realm of Raman spectroscopy diagnostics to expand data capacity and enhance the accuracy of diagnostic models with limited data.\n2. We proposed a novel DiffRaman model and introduced DDPM for the first time in the field of Raman spectroscopy for spectral generation.\n3. Extensive experimental analyses conducted on large-scale bacterial Raman spectroscopy datasets indicate that the proposed DiffRaman method enhances diagnostic accuracy with limited data, exhibiting superior performance compared to existing approaches and underscoring its potential for clinical application."}, {"title": "2. DiffRaman Methodology", "content": "To address the challenge of bacterial Raman spectroscopy diagnosis with limited data, we employed a dual-data-pathway approach as shown in Figure 1(a), which involves using both bacterial Raman spectroscopy data collected from real-world experiments and synthetic data generated by DiffRaman. The proposed DiffRaman pipeline encompasses four primary steps as illustrated in Figure 1(b). First, the input Raman spectral data undergoes a transformation phase to convert it into a two-dimensional Raman figure. Subsequently, the VQ-VAE encoder compresses the Raman figure and extracts its latent representation, which is refined into a discrete representation using the Vector Quantization (VQ) mechanism. Thereafter, the DDPM model learns the spectral feature distribution within the compressed latent space(Figure 1(c)). Finally, the decoder reconstructs the diffusion sampling result to produce the newly generated Raman figure and Raman spectrum."}, {"title": "2.2. Data Transformation", "content": "Considering the success of DDPM in the field of two-dimensional image generation, we have developed an effective data transformation method for Raman spectra in this study as shown in Figure 2 (a). The core concept of this method is to convert the original spectral signal into a two-dimensional Raman figure. Specifically, this conversion method involves sequentially filling the original spectral signal into the pixels of the figure. To obtain a figure of size M \u00d7 M, an interpolated signal with a length of $M^2$ is required from the original spectral signal. Let L(i), i = {1, ..., $M^2$}, represent the values of the signal. Let P(j, k), j = {1, ..., M}, {k = 1, ..., M}, denote the pixel intensity of the figure. The conversion method can be expressed by the following formula:\n$P(j, k) = \\frac{L ((j \u2212 1) \\times M + k) \u2013 Min(L)}{Max(L) - Min(L)} \\times 255.$  (1)\nThe pixel values of the resulting 2D Raman figure are normalized to a range between 0 and 255, which is a standard grayscale range for images. It is recommended that M be $2^n$. In this study, we use 32, implying that the length of the spectral signal is $M^2$ = 1024. Therefore, we interpolate the spectral signal to a length of 1024 prior to conversion."}, {"title": "Preprint", "content": "Most importantly, our proposed method involves a bidirectional mapping process, allowing us to convert Raman figure back into Raman spectra.\nSome examples of transformations are shown in Figure 2(b). It is noteworthy that, unlike existing Raman image transformation methods, our approach is directly effective without the need to incorporate additional expert knowledge, such as Spectral Recurrence Plot or Spectral Gramian Angular Field. Furthermore, unlike these aforementioned methods, the resulting Raman figure is of low resolution, which facilitates efficient computation."}, {"title": "2.3. VQ-VAE for latent compression", "content": "Given that the original DDPM is computationally expensive to apply directly in the raw data space, this study employs the dimensionality compression strategy of autoencoders to reduce the Raman figure to a latent space. Specifically, we adopt the VQ-VAE model, which employs discrete latent variable representation, proving to be more effective in numerous generative tasks. Formally, the structure of the VQ-VAE consists of an encoder E, a decoder D, and a codebook B = {$e_n$}$_{n=1}^{N_1}$ \u2208 $R^{N \\times d}$ containing a N latent embedding vectors. Given an input Raman figure P\u2208 $R^{M\\times M}$, the compressed continuous latent variable $z_e$ with shape of m \u00d7 m \u00d7 d is obtained"}, {"title": "Preprint", "content": "through the encoder as $z_e = E(P) \u2208 R^{m\\times m \\times d}$, and the is then quantized into $z_q$ based on its proximity to the embedding vectors in B:\n$z_q(h, w) = e_k \u2208 R^d, k = arg \\min_n ||z_e(h, w) \u2013 e_n||_2$ (2)\nwhere the (h, w) indicates the position in the latent feature. Finally, $z_q$ is input into the decoder D to obtain the reconstructed Raman figure. The VQ-VAE model is trained end-to-end under several constraints. First, the decoder and encoder are optimized using reconstruction loss. Second, the vector quantization (VQ) component is optimized through dictionary learning, utilizing the $l_2$ error to adjust the embedding vector $e_i$ towards the encoder output $z_e$. Finally, a commitment loss is incorporated to ensure that the encoder adheres to the embedding and prevents its output from diverging. Consequently, the overall training objective is formulated as follows:\n$\\mathcal{L}_{vq}(E, B, D) = ||P - D (z_q)||^2 + ||sg[E(P)] - z_q||^2 + \\zeta ||sg [z_q] - E(P)||^2$ (3)\nwhere sg [] denotes the stop-gradient operation, and \u03b6 is a hyperparameter that determines the weight of its contribution to the loss function."}, {"title": "2.4. DDPM for conditional generation", "content": "The learning process of DDPM involves two parameterized Markov chains, designed to generate samples that align with the original data distribution through a finite number of iterations. This process includes forward and reverse diffusion stages. In the forward diffusion process, Gaussian noise is incrementally added to the data, causing its distribution to converge to a specified standard Gaussian prior. Conversely, the reverse diffusion chain begins from this prior and progressively reconstructs the undisturbed data pattern.\nAs shown in Figure 3, the forward diffusion process in DDPM can be modeled as a Markov chain, a mathematical system that transitions between states according to a set of probabilistic rules. In this process, Gaussian noise is incrementally added to the original signal at each time step, producing potential states with a specific variance p. Specifically, The $z_q$ obtained from the pre-trained VQ-VAE is denoted as the initial state $z_{q,0}$. At each time step, the process \u03b2 transitions to a new potential state through the forward noise process, adhering to the Markov principle, which can be described as:\n$q(z_{q,1}, z_{q,2},..., z_{q,T} | z_{q,0}) = \\prod_{t=1}^{T} q(z_{q,t} | z_{q,t-1})$\n$q(z_{q,t} | z_{q,t-1}) = \\mathcal{N} (z_{q,t}; \\sqrt{1 - \u03b2_t} z_{q,t-1}, \u03b2_t I)$ (4)"}, {"title": "Preprint", "content": "where $z_{q,t}$ is the latent state of the system at time step t. The state at time step t is determined solely by the state at time step t \u2212 1, denoted as q($z_{q,t}$ | $z_{q,t-1}$), and is implemented by adding Gaussian noise. This process is characterized by $\\mathcal{N}$ (x; \u03bc, \u03c3), where \u03bc is the mean and \u03c3 is the variance that produces x. Employing the reparameterization trick, the state $z_{q,t}$ at a specific time step t can be directly derived from $z_{q,0}$:\n$q(z_{q,t} | z_{q,0}) = \\sqrt{\\bar{\\alpha}_t} z_{q,0} + \\sqrt{1 - \\bar{\\alpha}_t} \u03b5, \u03b5 \u2208 \\mathcal{N} (0, I)$ (5)\nwhere \u03b1$_t$ = 1 \u2212 \u03b2, and $\\bar{\\alpha}_t$ = $\\prod_{i=1}^{t} \u03b1_i$. It can be observed that when $\\bar{\\alpha}_t$ approaches zero, q($z_{q,t}$ | $z_{q,0}$) will converge to the Gaussian prior distribution $\\mathcal{N}$ (0, I).\nThe objective of the reverse diffusion process in DDPM is to learn the distribution p($z_{q,t-1}$ | $z_{q,t}$), which is equivalent to a denoising process as shown in Figure 3. Additionally, to achieve controllable generation of different types of Raman spectra, we further employ the conditional distribution p($z_{q,t-1}$ | $z_{q,t}$, y) for modeling, given a spectrum type label y. In this context, $z_{q,T}$ can be randomly sampled from $\\mathcal{N}$ (0, I) to generate p($z_{q,0}$ | $z_{q,T}$, y) as the synthetic representation. For this purpose, a neural network parameterized by \u03b8 is applied to approximate this process:\n$p_\u03b8(z_{q,0},...,T, y) = p(z_{q,T}) \\prod_{t=1}^{T} p_\u03b8(z_{q,t-1} | z_{q,t}, y)$ (6)\n$p_\u03b8(z_{q,t-1} | z_{q,t}, y) = \\mathcal{N} (z_{q,t-1}; \u03bc_\u03b8(z_{q,t}, t, y), \u03a3_\u03b8(z_{q,t}, t, y))$\nwhere the $\u03bc_\u03b8(z_{q,t}, t, y)$ and $\u03a3_\u03b8(z_{q,t}, t, y))$ represent the learnable mean and variance functions at the reversed step t, conditioned on the y. The optimization of \u03b8 is achieved by maximizing the variational lower bound of the negative log-likelihood of the data distribution p($z_{q,0}$):\n$\\max_\u03b8 \\mathbb{E}_{q(z_{q,0})} [\\log p_\u03b8 (z_{q,0}, y)]$\n$\\leq \\max_\u03b8 \\mathbb{E}_{q(z_{q,0},...,z_{q,T})} [\\log p_\u03b8 (z_{q,0:T}, y) \u2013 \\log q (z_{q,1:T} | z_{q,0})]$\n$= \\max_\u03b8 \\mathbb{E}_{q(z_{q,0},...,z_{q,T})} [-\\log p (z_{q,T}) + \\mathbb{E}_{t\u22651} [\\log \\frac{p_\u03b8 (z_{q,t-1}|z_{q,t},y)}{q(z_{q,t}|z_{q,t-1})} ]]$ (7)\nAs described in, the above formula can be transformed into the following loss function for optimization:\n$\\mathcal{L}_{DDPM} (\u03b5_\u03b8) = \\mathbb{E}_{z_{q,0}, \u03b5, t, y} ||\u03b5 - \u03b5_\u03b8 (\\sqrt{\\bar{\\alpha}_t}z_{q,0} + \\sqrt{1 - \\bar{\\alpha}_t}\u03b5, t, y)||^2$ (8)\nwhere the $\u03b5_\u03b8 (z_{q,t}, t, y)$ is a trainable U-Net neural network conditioned on the time step t and class label y that can predict the noise $\u03b5_t$."}, {"title": "Preprint", "content": "Algorithm 1 DiffRaman training algorithm\nInput: Spectral data L; Spectral type label y\nHyper-parameters: Reconstruction epoch $E_1$, Diffusion epoch $E_2$, Diffusion step T\nResult: Encoder E, codebook B, Decoder D, and U-Net noise predictor $\u03b5_\u03b8$\n# Stage I: VQ-VAE Training for epoch = 1, ..., $E_1$ do\n| Calculate loss: $\\mathcal{L}_{vq}(E, B, D) \u2190 Eq.(3)$\n| Update the Encoder E, codebook B, Decoder D by backpropagation;\nend\n# Stage II: DDPM Training for epoch = 1, ..., $E_2$ do\n| Sample t ~ Uniform(1,...,T) Calculate loss: $ \\mathcal{L}_{DDPM}(\u03b5_\u03b8) \u2190 Eq.(8)$\n| Update the U-Net noise predictor $\u03b5_\u03b8$ by backpropagation;\nend\nreturn E, B, D, $\u03b5_\u03b8$\nAlgorithm 2 DiffRaman sampling algorithm\nInput: Spectral type label y\nHyper-parameters: Diffusion step T\nResult: Generated Spectral data\nSample $z_{q,T}$ ~ $\\mathcal{N}(0, I)$ for t = T, ..., 1 do\n| Calculate the $z_{q,t-1}$ according to Eq. (9)\nend\nreturn D($z_{q,0}$)"}, {"title": "2.5. Training and Inference", "content": "The training and optimization process of the proposed DiffRaman framework can be divided into two distinct stages. In the first stage, the VQ-VAE is trained using Equation (3). Subsequently, in the second stage, the trained VQ-VAE is utilized to effectively compress the Raman figure into a low-dimensional latent space, and the DDPM is optimized using Equation (8).\nAfter completing the optimization process, the trained system can be employed for spectrum generation. Initially, a sample is randomly drawn from Gaussian distribution $\\mathcal{N}$ (0, I) to serve as $z_{q,T}$ for step T. This data is then processed through the trained model to obtain the predicted noise $\u03b5_\u03b8 (z_{q,t}, t, y)$ conditioned on the time step t and class label y. To derive noise-free data, the process iteratively continues backward to time step 0, where sampling is conducted from t to t - 1 according to the following formula:\n$z_{q,t-1} = \\frac{1}{\\sqrt{\\alpha_t}} (z_{q,t} - \\frac{\u03b2_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \u03b5_\u03b8 (z_{q,t}, t, y)) + \u03c3_t z, z. ~ \\mathcal{N} (0, I)$ (9)\nwhere $\u03c3_t = \\sqrt{\u03b2_t}$. Subsequently, $z_{q,0}$ is fed into the decoder D to obtain the reconstructed Raman figure and spectra. The training and sampling process can be described more compactly by Algorithms 1 and 2."}, {"title": "3. Results and Discussion", "content": "This study utilized two well-recognized bacterial spectral datasets: Bacterial ID and the Bacterial Strains Dataset for the purpose of experimental validation. Detailed information concerning these datasets is as follows."}, {"title": "3.1.1. Bacteria-ID dataset", "content": "We first utilized the large-scale Bacteria-ID dataset. This dataset comprises Raman spectral data from 30 different bacteria and yeasts, encompassing most infections commonly found in intensive care units worldwide. The wave number range of the spectra spans from 381.98 to 1792.4 $cm^{-1}$. The dataset is divided into three subsets: a reference dataset, a fine-tuning dataset, and a test dataset. The reference dataset includes 2000 spectral data for each"}, {"title": "3.1.2. Bacterial Strains dataset", "content": "The bacterial strain dataset represents another comprehensive collection of bacterial Raman spectroscopy data, encompassing 9 strains across 7 species. The authors employed five distinct laser acquisition durations, specifically 0.01, 0.1, 1, 10, and 15 seconds, to measure approximately 250 cells for each strain at each acquisition interval. This procedure yielded around 2,250 spectral samples, culminating in a total of 11,141 single-cell Raman spectra across the five measurement conditions. According to the original paper, acquisition times of 0.01 and 0.1 seconds result in a signal-to-noise ratio (SNR) that is insufficient for reliable diagnosis. Conversely, acquisition times of 10 or 15 seconds result in an excessively high SNR, rendering the diagnostic task overly simplistic and failing to adequately represent measurement noise interference typical of real experimental conditions. Taking these factors into account, we opted for the dataset with a measurement duration of 1 second, and randomly selected 60% of the data for the training set and 40% for the test set. Similarly, to simulate the scenario of limited sample sizes, we only train the model on a selected subset of the training set. For further details regarding the dataset, please refer to."}, {"title": "3.2. Experimental implementation details", "content": "The detailed network architecture of the encoder E, U-Net noise predictor $\u03b5_\u03b8$, and decoder D components within the DiffRaman framework is illustrated in Figure 4. \"Conv2d\" and \"Tconv2d\" denote the two-dimensional convolutional layer and its transposed counterpart, respectively. Here, k signifies the size of the convolutional kernel, s represents the stride utilized in the convolution process, and n denotes the number of convolutional kernels employed in each layer.The total count of latent embedding vectors encompassed within Codebook B amounts to 1024. In training the parameters of DiffRaman, we employed the Adam optimization algorithm with a learning rate of n = 1 \u00d7$10^{-3}$. The maximum number of training iterations for the two stages, $E_1$ and $E_2$, were both set to 600 and 1000. The batch size BS used during training was 32. Additionally, the diffusion steps T, were set to 500, with the variance \u03b2 increasing linearly from 1\u00d7$10^{-4}$ to 0.02. The hyper-parameters of training are shown in Table 1. All experiments were implemented using PyTorch 1.12 and executed on a system equipped with Intel(R) Xeon(R) Gold 5220 CPUs running at 2.20 GHz, along with an NVIDIA 4090 GPU featuring 24 GB of memory.\nIn the experiments, we considered three data generation techniques as comparative methods, including: (1). Data augmentation(DA), which applied various perturbation techniques to the original spectra, such as random Gaussian blur, random Gaussian noise, and random scaling. (2). Conditional Variational Autoencoder (cVAE). (3). Conditional Deep Convolutional Generative Adversarial Networks (CDCGAN). In order to simulate diagnostic scenarios with a limited number of samples, we selected training subsets from two bacterial Raman datasets. For each dataset, we chose two data scales, one containing 300 real samples and the other 600 real samples. To"}, {"title": "Preprint", "content": "ensure class balance, uniform sampling was performed across all bacterial categories. The above four data generation methods\u2014DA, CVAE, CDCGAN, and DiffRaman\u2014were employed to generate new synthetic data based on the selected training subsets. Without further specification, we have chosen the recently advanced SANet as the diagnostic model. To ensure a fair comparison, all the considered generation methods are trained on the same real samples. Additionally, the diagnostic models derived from different generation methods are all trained using an early stopping strategy with a patience of 10 epochs on the test loss for fair comparison."}, {"title": "3.3. Results", "content": "The quality of generated samples is a key factor. This study conducted a comprehensive evaluation from multiple perspectives. Firstly, a visual comparison of the Raman spectra and figures between the generated samples and the real samples was performed. Secondly, to more accurately assess the quality of the generated samples, we employed quantitative evaluation metrics to measure the similarity between the generated samples and the real samples. In this experiment, we utilized 600 real samples and generated an additional 600 synthetic samples using the data synthesis methods.\nBased on these two sets of outcomes, we can infer the following conclusions:\n(1). The samples generated by DA exhibit a high degree of overlap with the overall distribution of real samples and demonstrate diversity. However, this technique relies on primary signal manipulation methods such as simple scaling, Gaussian noise addition, and filtering, which do not accurately reflect the real data distribution. (2). Samples generated by cVAE tend to replicate the average pattern of real samples and lack the capability to generate diverse samples. (3). The generation process of cDCGAN encounters mode collapse due to the limited number of real samples. This not only results in generated samples deviating from the distribution of real samples and being contaminated with noise, but also the diversity of patterns in the generated data is very limited. (4). Conversely, DiffRaman generates samples with a high degree of diversity while ensuring that the overall distribution remains unbiased.\nTo quantitatively assess the quality of the generated signals, we employ similarity evaluation metrics. Specifically, to evaluate the similarity between individual samples, we utilize the Cosine Similarity (COS), which calculates the average cosine similarity between each pair of generated and real samples. To assess the overall similarity of synthetic samples, we use distribution similarity metrics, including Maximum Mean Discrepancy (MMD), Jensen-Shannon Divergence (JS), and Wasserstein Distance (WD). It is noteworthy that these three distribution metrics are all conducted under the assumption of multivariate Gaussian distribution. The higher the COS value, the greater the similarity between the signals; conversely, the lower the values of MMD, JS, and WD, the higher the similarity between the distributions."}, {"title": "Preprint", "content": "similarity. In contrast, DA-generated samples only exhibit similarity in overall distribution but have lower sample similarity, while cVAE-generated spectra have high sample similarity but low overall distribution similarity. cDCGAN performs poorly in both aspects. These results align with the aforementioned qualitative analysis, indicating that DA, CVAE, and CDCGAN generate lower quality data, reducing their usability for subsequent classification tasks."}, {"title": "3.3.2. Spectrum Identification Evaluation", "content": "In this section, we conducted recognition experiments to assess the impact of spectra generated by different methods on the diagnostic model performance under limited sample conditions. Specifically, we employed two distinct processes. The first is the basic method, where the diagnostic model is trained solely on source data (Source). The second process involves training the diagnostic model with both source data and synthetic data, where the synthetic data is generated through the four methods mentioned above: DA,cVAE,CDCGAN, and the proposed DiffRaman. To avoid accidental results when sampling a small number of instances and to ensure the reliability of the findings, the experimental results presented are the mean of five independent trials.\nFirstly, we reported the diagnostic performance on the bacterial ID dataset. This dataset encompasses three diagnostic tasks: (1) the identification of 30 isolates, (2) the classification of the 30 bacterial isolates into 8 empirical treatment groups, and (3) the categorization of Staphylococcus aureus in the dataset into two binary groups based on methicillin susceptibility: methicillin-resistant Staphylococcus aureus (MRSA) and methicillin-susceptible Staphylococcus aureus (MSSA). When using 300 real samples, we generated an additional 600 samples with our DiffRaman method. The improvement in diagnostic results using synthetic samples across the three diagnostic tasks is shown in Figure 7. As shown in the confusion matrix of Figure 7(a), when only 300 real experimental samples are used (10 samples per isolate), the diagnostic model performs poorly on any of the three tasks.In the identification task of 30 isolates, the accuracy of some categories such as Streptococcus pneumoniae type 2, MSSA type 1, and Klebsiella aerogenes was very low, not exceeding 30%, and the overall accuracy was only 46.1%. In the diagnosis task of 8 treatment groups, the accuracy of ciprofloxacin, ceftriaxone, and piperacillin-tazobactam (TZP) did not exceed 30%. In the MSSA/MRSA binary classification task, there was a serious problem of misclassifying MSSA as MRSA. When the diagnostic model was trained using 600 additional samples generated by DiffRaman combined with the original real experimental data, the diagnostic accuracy of the model was significantly improved, and the diagnostic performance of some categories was significantly enhanced. For example, in the identification task of 30 isolates, the diagnostic accuracy of MSSA 1 was increased from 18% to 82%. In the task of classifying eight treatment groups,"}, {"title": "Preprint", "content": "the diagnostic accuracy of ceftriaxone was improved from 22% to 57%. As shown in Figure 7(b), the average overall accuracy of the three tasks for five trials was improved by +14.2%, +3.9%, and +0.7%, respectively, demonstrating its effectiveness.\nFurthermore, we compared the impact of data generated by other models on diagnostic performance. We employed two experimental setups: the first used 300 real samples and 600 generated samples for training the diagnostic model, while the second used 600 real samples and 1200 generated samples for training. The results are reported in Table 3. The conclusions that can be drawn are: (1) Our method outperforms other data generation methods in enhancing the performance of the diagnostic model across the three tasks under both setups, especially in the identification task of 30 isolates, where our method surpasses the next best method (DA) by accuracy rates of 13.7 % and 8.9%.(2) Not all methods can enhance diagnostic accuracy. In the identification task of 30 isolates, the data generated by cVAE and CDCGAN have a negative impact on the diagnostic model. This is due to the low quality of the generated data, which makes it unsuitable for application in downstream identification tasks."}, {"title": "Preprint", "content": "We then present the results obtained on the Bacterial Strains dataset. On this dataset, we also employed the two experimental setups of collecting 300 and 600 real samples. However, we further expanded the experimental settings to explore the impact of varying numbers of generated samples. With 300 real samples, we generated 300 and 600 synthetic samples, respectively. With 600 real samples, we generated 600 and 1200 synthetic samples, respectively. The effects of samples generated by different synthetic methods on diagnostic accuracy are shown in Figure 8. The results demonstrate that under these four settings, the data generated by our DiffRaman method yields the most notable enhancement in diagnostic accuracy. With 300 real samples, the use of 300 and 600 synthetic samples can boost the accuracy from 58.1% to 62.4% and 64.5%, respectively. In contrast, DA only manages to achieve accuracies ranging from 58.1% to 58.5% and 61.4%, cDCGAN from 58.1% to 60.5% and 58.4%, and cVAE shows a subtle improvement in accuracy that does not significantly enhance the reliability in diagnostic applications. The same phenomenon is observed when using 600 real samples to generate 600 and 1200 synthetic samples; our method still achieves the best improvement in accuracy, with increases of +5.9% and 5.7%, outperforming other comparative methods. These results demonstrate that our approach can consistently and effectively improve the diagnostic accuracy of the model under different numbers of synthetic samples generated.\nIn Figure 9, we present the diagnostic confusion matrices achieved by training diagnostic models with 600 synthetic samples and 300 real experimental samples. It can be observed that our method achieves significant accuracy improvements for some challenging-to-identify categories, such as E. coli and A. baumannii. Furthermore, to more intuitively display the quality of the generated data, we provide in Figure 10 the distribution of data generated by four synthetic methods and test data in the latent space of the last layer of the diagnostic model. It can be observed that the diagnostic model obtained using DiffRaman-generated data exhibits the most discriminative feature differentiation ability, effectively separating different categories of bacteria strains. In contrast, the latent feature distributions obtained by other methods show greater overlap between different categories.\nTo summarize, in this section"}]}