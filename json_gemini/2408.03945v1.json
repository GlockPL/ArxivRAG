{"title": "Impacts of Anthropomorphizing Large Language Models in Learning Environments", "authors": ["Kristina Schaaff", "Marc-Andr\u00e9 Heidelmann"], "abstract": "Large Language Models (LLMs) are increasingly being used in learning environments to support teaching-be it as learning companions or as tutors [1]-[3]. With our contribution, we aim to discuss the implications of the anthropomorphization of LLMs in learning environments on educational theory to build a foundation for more effective learning outcomes and understand their emotional impact on learners.\nAccording to the media equation [4], people tend to respond to media in the same way as they would respond to another person. A study conducted by the Georgia Institute of Technology showed that chatbots can be successfully implemented in learning environments. In this study, learners in selected online courses were unable to distinguish the chatbot from a \"real\" teacher [5]. As LLM-based chatbots such as OpenAI's GPT series are increasingly used in educational tools, it is important to understand how the attribution processes to LLM-based chatbots in terms of anthropomorphization affect learners' emotions.", "sections": [{"title": "I. INTRODUCTION", "content": "Large Language Models (LLMs) are increasingly being used in learning environments to support teaching-be it as learning companions or as tutors [1]-[3]. With our contribution, we aim to discuss the implications of the anthropomorphization of LLMs in learning environments on educational theory to build a foundation for more effective learning outcomes and understand their emotional impact on learners.\nAccording to the media equation [4], people tend to respond to media in the same way as they would respond to another person. A study conducted by the Georgia Institute of Technology showed that chatbots can be successfully implemented in learning environments. In this study, learners in selected online courses were unable to distinguish the chatbot from a \"real\" teacher [5]. As LLM-based chatbots such as OpenAI's GPT series are increasingly used in educational tools, it is important to understand how the attribution processes to LLM-based chatbots in terms of anthropomorphization affect learners' emotions."}, {"title": "II. PROBLEM STATEMENT", "content": "We know from learning research that learning and education are closely linked to emotions [6]. Arnold even states that \"education is emotional maturity\" [7]. In particular, negative emotional experiences such as irritation, limit experiences, or feelings of strangeness are given great relevance in qualitative educational research [8]. In this context, the way learners perceive and interact with LLMs-based chatbots in educational environments can have a significant impact on educational experiences and outcomes. The anthropomorphization of these models, which attributes human-like characteristics to them, affects their integration and perception, thereby affecting their educational potential. In our research, we aim to explore the consequences of anthropomorphizing LLM-based chatbots in learning environments, focusing on user interaction, and learning effectiveness. In particular, educational theory and ethical considerations play a role.\nBy supporting both-students and educators-LLM-based chatbots are transforming the educational landscape. The emergence of LLM-based chatbots offers entirely new possibilities, as they are far more powerful than earlier chatbots [9] and are also able to behave empathically [10].\nSimilarly to the factors of anthropomorphism summarized by [11], we identified the following factors as relevant when LLM-based chatbots are used in learning scenarios: The learning agent, i.e., chatbot, the learner itself, and environmental factors which influence the learner (see Figure 1).\nLooking at the agent, several factors can contribute to anthropomorphization. Cognitive intelligence refers to the ability to perceive, reason, and act on problems; to combine efficient, useful, goal-oriented, and autonomous actions with effective output; and to produce and process natural language, imitate human cognitive functions, and mimic human inter-action. Emotional intelligence refers primarily to the ability to perceive one's own and others' emotions and to communi-cate moods, emotions, and feelings [11]-[14]. Characteristics such as personality, in the sense of consistent behavior and adaptation of communication styles and preferences evoking human personality traits [15]; personalization, in the sense of recognizing and responding to a learner's individual prefer-ences, needs, and behaviors [15], [16]; and identity, which is created and shaped by a unique and recognizable character or brand, as well as its name, voice, appearance, and background story [12], [15], are also significant. Moreover, factors such as physical appearance, voice, movement, gestures, and facial expressions [11], [12], [16] can influence anthropomorphism even though they are only relevant if an agent is accompanied by an avatar.\nRegarding the learner, there are several psychological de-terminants, such as emotions, motivation, and cognitive pro-cesses [11], [17], influencing the personality of a learner. The personality determines how a learner perceives an AI and"}, {"title": "III. RESEARCH QUESTIONS & METHODOLOGY", "content": "Learners use LLM-based chatbots to support their learning process. By using these systems, all learning activities can be tracked. This information can be connected with other learning materials that match the learner's level as a starting point for new learning goals. This focus on the learner and their integration into a ubiquitous, real-time, and opaque data structure could pose a problem in terms of educational theory.\nFrom this perspective, the following questions arise: (1) Are LLM-based chatbots able to induce these intense emotions of irritation and strangeness when being anthropomorphized? If so, (2) do these emotions significantly influence the learning outcomes in learning environments using LLM-based chat-bots?\nTo evaluate these questions, we will set up a study based on the factors that contribute to the anthropomorphism of a system. For this study, we will develop two different learning systems: one system integrating the relevant factors of anthropomorphism and one which does not. We will im-plement a decision-making task which allows us to capture the performances as well as the decision-making times of the participants. The two systems will be analyzed in a comparative study with a large cohort of students from IU International University of Applied Sciences. Furthermore, we will evaluate the emotional states of the participants during the task using questionnaires."}, {"title": "IV. SUMMARY & CONCLUSION", "content": "As LLMs continue to evolve, their anthropomorphization will likely play a crucial role in their acceptance and utility in educational contexts. Future research should focus on optimizing the balance between relatability and realism in LLM interactions, developing guidelines for their use, and exploring innovative applications in personalized learning. The anthropomorphization of LLM-based chatbots in learning environments presents both: Opportunities and challenges. While it can enhance engagement and learning effectiveness, it also raises ethical concerns and the potential for negative impacts on user experience, including unrealistic expectations and emotional discomfort.\nIn educational science, it is assumed that strong emotions contribute to the initiation of educational processes in learners. Especially for learning with LLM-based chatbots, the question of the effect of emotions on individual learning is a desider-atum. In our study, we plan to investigate whether and to what extent the anthropomorphization of AI-based systems can evoke such emotions. As educationalists and engineers, we consider both the implications of educational theory and the technical implementation and control options. This interdis-ciplinary approach addresses the highly relevant desideratum of technical-pedagogical development and processing of AI-supported education at universities. Our findings can help educators create more effective educational technologies by creating a better understanding of the balance between mak-ing AI relatable and maintaining realistic expectations of its capabilities."}]}