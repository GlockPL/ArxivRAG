{"title": "BitAbuse: A Dataset of Visually Perturbed Texts for Defending Phishing Attacks", "authors": ["Hanyong Lee", "Chaelyn Lee", "Yongjae Lee", "Jaesung Lee"], "abstract": "Social engineering attacks, such as phishing, often target victims through visually perturbed texts to bypass security systems. The noise contained in these texts functions as an adversarial attack, designed to deceive language models and hinder their ability to accurately interpret the content. However, since it is difficult to obtain sufficient phishing cases, previous studies have used synthetic datasets that do not contain real-world cases. In this study, we propose the BitAbuse dataset, which includes real-world phishing cases, to address the limitations of previous research. Our dataset comprises a total of 325,580 visually perturbed texts. The dataset inputs are drawn from the raw corpus, consisting of visually perturbed sentences and sentences generated through an artificial perturbation process. Each input sentence is labeled with its corresponding ground truth, representing the restored, non-perturbed version. Language models trained on our proposed dataset demonstrated significantly better performance compared to previous methods, achieving an accuracy of approximately 96%. Our analysis revealed a significant gap between real-world and synthetic examples, underscoring the value of our dataset for building reliable pre-trained models for restoration tasks. We release the BitAbuse dataset, which includes real-world phishing cases annotated with visual perturbations, to support future research in adversarial attack defense. Our code and datasets are available at https://github.com/CAU-AutoML/Bitabuse.", "sections": [{"title": "1 Introduction", "content": "Social engineering attacks, including phishing, spam, pretexting, baiting, and tailgating, aim to leak confidential information by exploiting the psychological vulnerabilities of victims (Salahdine and Kaabouch, 2019). Among them, phishing often attacks victims through texts of email, SMS, and URLs. Specifically, these phishing techniques bypass security systems such as spam filtering using visually perturbed (VP) text (Deng et al., 2020; Julis and Alagesan, 2020; Boucher et al., 2022; Unicode Consortium, 2022), in which other characters, typically homoglyphs, replace a part of the characters in the text if the source language is English, that are nearly identical in appearance to the original characters\u00b9. For example, modifying 'Bitcoin' to 'Bitcoin' is an example of this technique.\nBecause phishing attacks based on VP texts can be prevented by restoring them to the original texts, most studies (Suzuki et al., 2019; Sawabe et al., 2019; Pruthi et al., 2019; Imam et al., 2022; Keller et al., 2021) focused on devising an restoration method. Specifically, they modified a non-VP text dataset into a VP text dataset based on their own heuristic rules and then evaluated the performance of their restoration methods based on the synthesized dataset. These approaches are effective for identifying the weaknesses of the restoration methods, but their analysis may be biased toward their own rules because the dataset is created without regard to real-world VP texts. For example, Viper (Eger et al., 2019) always perturbs a fixed portion of characters in a sentence, which is unrealistic. Furthermore, LEGIT (Seth et al., 2023) annotates the legibility of synthetic VP text and introduces a dataset by generating VP text that is applicable to real-world scenarios through a model that ranks transformations according to their readability. Nevertheless, research on VP text in real-world settings remains unexplored.\nAlthough the data synthesizing strategy is helpful in circumventing the difficulty due to the lack of publicized real-world VP texts regarding phishing attacks, building a language model (LM)-based"}, {"title": "2 Related Work", "content": "In the studies involving VP texts, obtaining sufficient data is often difficult because VP texts, usually delivered as spam emails, are not widely shared on the web. In particular, there is a lack of datasets that reflect actual phishing attack situations, and existing datasets are only valid under specific conditions or environments (Elsayed and Shosha, 2018; Suzuki et al., 2019; Yazdani et al., 2020; Almuhaideb et al., 2022), such as internationalized domain names (IDNs.) As a result, conventional studies typically included a data synthesizing procedure with the method for restoring VP texts. Specifically, the dataset for testing the efficacy of their VP text restoration methods is synthesized by heuristic rules set in their own way.\nTwo notable studies regarding VP text data synthesizing are TextBugger (Li et al., 2019) and Viper. TextBugger is devised to generate VP texts using predefined homoglyph pairs and perturbation methods. Its goal is to degrade the performance of LMs by selecting characters in a text and replacing them with VP characters. This is useful for exposing vulnerabilities in security-sensitive tasks such as sentiment analysis (Pang and Lee, 2008) or malicious content detection (Hou et al., 2010). Viper searches for homoglyphs and generates VP texts based on embedding techniques. This method modifies the dataset by replacing characters in the text with VP characters and induces visual disturbance based on the replacement probability.\nRegarding the restoration of VP texts, conventional methods first restore malicious text using SimChar DB-based (Suzuki et al., 2019), OCR-based (Sawabe et al., 2019), Spell Checker-based (Imam et al., 2022), or LM-based methods (Keller et al., 2021) and then detect malicious texts. The SimChar DB-based method automatically collects homoglyphs from the Unicode character set to detect VP characters in IDNs and restores them using a predefined restoration table. OCR-based methods were investigated to detect phishing attacks that deceive users by putting VP characters in IDNs. This method recognizes VP characters as images and converts them into the original characters. The Spell Checker-based method aims to detect images containing malicious text distributed on social networks by considering deformed characters in the text as typos and restoring them using a spell checker. The restoration strategy that combines two LMS, BERT (Devlin et al., 2019) and GPT (Radford et al., 2018), was also considered (Keller et al., 2021).\nA common drawback of conventional studies is that the datasets used for evaluating the restoration performance of phishing attacks contain no real VP texts. As a result, the restoration performance in real-world situations may be over/underestimated, and unstable pre-trained LM models can be obtained. In this study, we create a new dataset that can contribute to phishing attack studies by collecting VP texts used in bitcoinabuse[.]com."}, {"title": "3 BitAbuse", "content": "We collect VP texts used in phishing attacks from the bitcoinabuse[.]com (Bitcoin Abuse, 2023) website. The website bitcoinabuse[.]com is a platform where worldwide users can share content related to Bitcoin fraud, such as emails. The site provides data collected through user participation, making it easy to find phishing email bodies containing VP texts. Additionally, because users directly upload emails after masking personal information, it can be ensured that the data can be collected safely without privacy concerns.\nWe used 262,258 phishing-related emails collected from bitcoinabuse[.]com between May 16,"}, {"title": "4 Experimental Settings", "content": "We tested the restoration performance using Simchar DB (Suzuki et al., 2019), OCR (Sawabe et al., 2019), Spell Checker (Imam et al., 2022), Character BERT-based(El Boukkouri et al., 2020), and GPT-40 mini-based methods (OpenAI, 2023) in the viewpoint of three well-known evaluation mea-"}, {"title": "4.1 Methods", "content": "We tested the restoration performance using five different methods. The SimChar DB-based method checks if there is an alphabetic homoglyph for each character in the Simchar Database and uses it to restore the homoglyph. The OCR-based method was implemented by applying OCR to each character and selecting the character with the highest probability. Spell Checker-based method entailed the segmentation of sentences into individual word units through a rule-based approach, followed by the restoration of each word using a spell checker based on Levenshtein Distance, as documented in the corresponding references (Norvig, 2016; Lison and Tiedemann, 2016).\nCharacter BERT The Character BERT-based method employs a BERT model that processes token sequences at the character level to restore VP characters, inferring them as the original characters through the context of individual characters. In this approach, instead of relying on a standard subword tokenizer-based BERT\u2014which is less effective when tokens contain perturbed characters\u2014a character-level sequence approach is adopted for both input and output. This method is particularly important because attackers often modify characters within tokens to deceive victims, leading to widespread perturbations across most tokens. Stan-"}, {"title": "4.2 Evaluations", "content": "We evaluated each method using the three measures that were used in previous VP text restoration studies: Word Level Accuracy, Word Level Jaccard, and BLEU. Word Level Accuracy is a measure that evaluates whether the restored word matches at each word position. When $N_c$ represents the number of correctly restored words and $N$ represents the total number of words in each sentence, Word Level Accuracy is calculated as\nWord Level Accuracy = $\\frac{N_c}{N}$.\nThe Word Level Jaccard score is calculated by forming the word set $W_p$ from the predicted sentence and the word set $W_l$ from the labeled sentence and then computing the ratio of the size of their intersection to the size of their union. Specifically, the Word Level Jaccard score is defined as\nWord Level Jaccard = $\\frac{|W_p \\cap W_l|}{|W_p \\cup W_l|}$\nThe BLEU score is calculated by constructing the character sequences $C_p$ of the predicted sentence and the character sequences $C_l$ of the labeled sentence and then calculating the precision of the n-grams of the two sequences by\nBLEU = $B \\times exp \\big(\\sum_{n=1}^{N} w_n \\log p_n\\big)$\nwhere N and $w_n$ are the maximum length and the weight of the n-grams, respectively. $p_n$ represents the precision of the n-grams in $C_l$ and $C_p$, and B is the brevity penalty used in the BLEU score calculation. In this paper, N = 4 is used to calculate the BLEU score, and $w_n$ = 1/N is set. The brevity penalty follows the standard BLEU score calculation method."}, {"title": "5 Experimental Results", "content": "We conducted exploratory data analysis on VP words, VP characters, ratios, and so on that may help devise an effective methodology for defending phishing attacks.\nNext, the number of VP sentences according to the occurrence ratio of VP characters to sentence length in the BitCore, BitViper, and BitAbuse datasets is presented as a histogram as in Figure 3 in Appendix D. Figure 1 shows the VP character-word association graph using the Yifan Hu algorithm (Hu, 2005) in Gephi (Bastian et al., 2009). This graph represents the clustering of the VP character-word association of BitCore dataset, where nodes correspond to characters and words subjected to perturbation attacks. The distance between nodes indicates the degree of their relatedness\u00b3. Figure 1(a) illustrates the overall graph, and Figures 1(b)-(e) each represents the graph regarding key characters. Notably, the core of the major clusters is occupied by vowels such as 'a', 'e', 'i', and 'o'. This likely occurs because vowels are frequently used across various words, resulting in strong associations within the graph and positioning them at the center. Specifically, the character 'e' appears to play a more global role within the graph, whereas other characters show stronger relations with words belonging to different clusters.\nTable 2 shows the restoration performance of SimChar DB, OCR, Spell Checker, Character BERT, and GPT-40 mini-based methods on three datasets. Experimental results indicate that the Character BERT-based method significantly outperforms the other three methods. Regarding each dataset, all five methods achieved the best and worst performance for BitCore and BitViper datasets, respectively. Table 3 represents two examples of restoration results regarding five methods."}, {"title": "6 Discussion", "content": "Figure 2 demonstrates the performance of various restoration methods based on the proportion of VP characters. Compared to other methods, the Character BERT-based method performed more effectively as the proportion of VP characters increased. This indicates that the Character BERT-based method can accurately restore VP characters by leveraging contextual information. Conversely, the Spell Checker-based method exhibited a sharp decline in performance as the proportion of VP"}, {"title": "7 Conclusion", "content": "In this study, we created three VP text datasets: BitCore, BitViper, and BitAbuse. Our analysis results show that BitCore and BitViper have significantly different characteristics, and the LM-based reconstruction method demonstrates strong robustness and potential on all three datasets. BitAbuse, a pre-trained model using 325,580 VP sentences, can be downloaded from BitAbuse.4. In future studies, a hybrid approach, such as combining OCR and Character BERT, can be explored to achieve robust performance with insufficient training samples. Internalizing them into LMs may be beneficial for remedying the greedy data consumption nature of LMs and in scenarios where collecting sufficient samples is challenging. In addition, lightweight yet accurate LMs for restoration tasks may be obtained if the bias to the words attacked frequently and vowel characters in real-world phishing attacks is exploited effectively. Lastly, validating the zero-shot performance of BitAbuse model should also be performed."}, {"title": "Limitations", "content": "The VP text restoration experiments conducted in this study did not include additional restoration methods to avoid exceeding the scope of the study. Specifically, a performance comparison between the Character BERT-based and other LM-based restoration methods was not performed. Thus, it is difficult to evaluate the superiority of Character BERT over other modern LMs. Character BERT showed sufficiently good performance, but it will be possible to compare effectiveness and efficiency with methods applying other LMs in the future.\nThe BitAbuse dataset used in this study only includes data related to Bitcoin scams, which limits its ability to reflect a variety of phishing attack scenarios. In addition, phishing attacks may appear in more diverse or complex forms over time, and failure to reflect this diversity may reduce the generalizability of our study. Thus, future studies should aim to construct an extended dataset that includes various phishing attack scenarios and conduct studies comparing different restoration methods.\nAlso, our datasets were created for study purposes to defend against phishing attacks based on VP texts. However, there is a risk that this dataset could be used by non-experts in phishing to learn and execute attacks. For example, WormGPT, recently created on the dark web to generate criminal text, and PoisonGPT, released by Mithril Security, spread contaminated results. These models might use our datasets to develop malicious tools. Consequently, this could lead to the sophistication of phishing attacks, resulting in more victims. In addition, the damage caused by the misuse of such datasets is difficult to hold accountable legally. Currently, many countries lack clear regulations regarding the technological misuse of such datasets, necessitating careful considerations and observations. The datasets and models used in this paper are publicly available, but they should not be used for purposes other than research."}, {"title": "Ethics Statement", "content": "Our datasets were created for study purposes to defend against phishing attacks based on VP texts. However, there is a risk that this dataset could be used by non-experts in phishing to learn and execute attacks. For example, WormGPT, recently created on the dark web to generate criminal text, and PoisonGPT, released by Mithril Security, spread contaminated results. These models might use our datasets to develop malicious tools. Consequently, this could lead to the sophistication of phishing attacks, resulting in more victims. In addition, the damage caused by the misuse of such datasets is difficult to hold accountable legally. Currently, many countries lack clear regulations regarding the technological misuse of such datasets, necessitating careful considerations and observations. The datasets and models used in this paper are publicly available, but they should not be used for purposes other than research."}, {"title": "A Statistics of Raw Dataset", "content": "Table 6 shows brief statistics of the collected email texts. We identified 262,258 phishing-related emails from bitcoinabuse[.]com between May 16, 2017, and January 15, 2022, and extracted the text bodies of these emails. The length of the email bodies averages about 417 characters, ranging from a minimum of 10 characters to a maximum of 2,000 because the platform limits the maximum number of characters to 2,000. The content of phishing-related emails was uploaded from approximately 224 countries, and the country of upload and the language of the collected text may differ.\nTable 7 presents the statistics of the raw corpus after splitting the collected texts into individual sentences and removing meaningless texts, as mentioned in the Data Collection section. The sentence-splitting process was performed using the NLTK library, resulting in a total of 325,580 sentences. In the next step, sentences containing non-ASCII characters were classified as VP sentences, and the classification was manually reviewed to ensure accuracy. After the review, 26,591 sentences were identified as VP sentences, while 298,989 were categorized as non-VP sentences."}, {"title": "B Filtering Non-English Texts", "content": "In our study, we exploited the BERT model with a fully connected classification layer trained to classify English texts from non-English texts. To train our model, we use the Flair library (Akbik et al., 2019). In addition, the learning rate was set to , with 1 learning epoch (the library early stopped training due to the very small learning rate), a batch size of eight, an AdamW optimizer (, , weight_decay = 0), and the AnnealOnPlateau scheduler implemented in the Flair library. Additionally, a single NVIDIA GeForce RTX 3080 GPU was used."}, {"title": "C Regular Expressions", "content": "Table 8 shows the list of regular expressions we used for further preprocessing. The first and fourth, the second and fifth, and the third and sixth columns mean the description of characters, regular expressions, and replaced characters, respectively. R and S in the third and sixth columns mean \u201cRemoved\u201d and \u201cSpace\u201d. For example, No-break Space (U+00A0), En Space (U+2002), Hair Space (U+200A), and Ideographic Space (U+3000) are special space characters and would commonly be replaced with regular space characters. The space after \\u in the regular expression is included intentionally for clarity but is excluded in the actual regular expression. We also release a downloadable list of regular expressions and preprocessing code from https://huggingface.co/datasets/AutoML/\nbitaubse/blob/main/preprocessing.py.\nTable 9 shows example sentences after the preprocessing based on the regular expressions. In three examples of the table, emojis and special characters in the sentence are removed, and unusual characters are replaced with ASCII characters with the same meaning. For example, in the first example in the table, \u201cLeft Black Lenticular Bracket (U+3010)\u201d and \u201cRight Black Lenticular Bracket (U+3011)\u201d were replaced with regular parentheses (U+0028, U+0029). In the second example, unprintable Unicode characters that are presented as a hex value in the red box are removed."}, {"title": "D Statistics of BitAbuse", "content": "We created BitCore, BitViper, and BitAbuse datasets based on the raw corpus. Brief statistics of the three datasets are presented in Table 10. Specifically, BitCore was created by simply selecting 26,591 VP sentences from the raw corpus. Next, BitViper was created by applying the character perturbation procedure of Viper that uses the ICEs method with a probability of 0.2 to 298,989 non-VP sentences of the raw corpus, following the same settings used in the original study for the restoration tasks. Lastly, BitAbuse was created by merging BitCore and BitViper, resulting in the largest dataset of our study that contains both real-world and synthetic VP sentences."}, {"title": "E Statistics and Examples of VP Words and Characters", "content": "We summarized the number of VP word variants and that of attacks on each corresponding word appearing in VP texts in Table 11. VP word variants were frequently found in terms related to Bitcoin scam domains, such as \u201cemail\u201d, \u201csoftware\u201d, \u201cBitcoin\", and \"video\". In contrast, the words most often attacked were common words like \"you\", \"to\", \"and\", \"the\", and \"a\". This indicates that these commonly used words are more likely to be targeted due to their frequent everyday use. Although domain-specific words exhibit a significant number of variants, their attack frequency is relatively low. This suggests that attackers are cautious"}, {"title": "F Experimental Details", "content": "We provide additional details on the experimental settings and methods used in the experiments."}, {"title": "F.1 Character BERT Based Method", "content": "In the experiment shown in Table 2, the training process of Character BERT was configured with a learning rate of 5 \u00d7 10\u22125, a batch size of 32, and ten training epochs. Additionally, the AdamW optimizer was used with settings of ,"}, {"title": "F.2 GPT-40 mini Based Method", "content": "When employing the GPT-40 mini model, we designed a prompt for VP text restoration, as detailed in Table 15. The experiment used OpenAI's batch API, with a total cost of approximately 3.47 USD."}, {"title": "F.3 Experimental Environment", "content": "The implementations were done by using the Pytesseract (Lee, 2024), Pyspellchecker (Barrus, 2024), and Transformers (Wolf et al., 2020) library. The experiment was performed on the computing hardware with an Intel i9-10980XE processor, two NVIDIA GeForce RTX 3090 GPUs, and 128GB of RAM. Additionally, the textual content was rendered using the Noto Sans Runic (Cozens et al., 2024) and GoNotoCurrent font (B, 2024)."}, {"title": "G Performance regarding VP Character Ratio in Each Sentence", "content": "Figures 4 and 5 show the Word Level Jaccard and BLEU performance of each method regarding the VP character ratio in each sentence. As shown in Figure 2, the Character BERT-based method outperformed SimChar DB, OCR, and Spell Checker-based methods. Similar to the experimental results regarding Word Level Accuracy, the Character BERT-based method showed robust performance on both BitCore and BitAbuse datasets, whereas it loses its robustness on BitViper dataset that does not include BitCore dataset."}, {"title": "H Statistics of One-to-Many Corresponding VP Characters", "content": "As mentioned in the Discussion section, simple mapping-based methods like SimChar, used in the experiments, have a fundamental limitation in handling one-to-many VP character relationships, as they can only output a single non-VP character for each VP character. To verify this, we analyzed how frequently one-to-many VP characters appear in the dataset."}]}