{"title": "Analytical Lyapunov Function Discovery: An RL-based Generative Approach", "authors": ["Haohan Zou", "Jie Feng", "Hao Zhao", "Yuanyuan Shi"], "abstract": "Despite advances in learning-based methods, finding valid Lyapunov functions for nonlinear dynamical systems remains challenging. Current neural network approaches face two main issues: challenges in scalable verification and limited interpretability. To address these, we propose an end-to-end framework using transformers to construct analytical Lyapunov functions (local), which simplifies formal verification, enhances interpretability, and provides valuable insights for control engineers. Our framework consists of a transformer-based trainer that generates candidate Lyapunov functions and a falsifier that verifies candidate expressions and refines the model via risk-seeking policy gradient. Unlike Alfarano et al. (2024), which utilizes pre-training and seeks global Lyapunov functions for low-dimensional systems, our model is trained from scratch via reinforcement learning (RL) and succeeds in finding local Lyapunov functions for high-dimensional and non-polynomial systems. Given the analytical nature of the candidates, we employ efficient optimization methods for falsification during training and formal verification tools for the final verification. We demonstrate the efficiency of our approach on a range of nonlinear dynamical systems with up to ten dimensions and show that it can discover Lyapunov functions not previously identified in the control literature.", "sections": [{"title": "1. Introduction", "content": "A Lyapunov function is an energy-based certificate function that decreases over time, which is indispensable for stability verification, especially for nonlinear dynamics Khalil (2002). These functions can also offer valuable insights into system behaviors, aiding in controller design. However, designing a Lyapunov function for nonlinear systems has long been considered more of an 'art' than a science, even for stable dynamics, due to its inherent complexities. Motivated by this challenge, we have witnessed great interest in the development of computational algorithms for Lyapunov function construction. McGough et al. (2010) employed an evolutionary algorithm for the symbolic computation of Lyapunov functions, but the exponential growth search space impedes its scalability. Alternatively, sum-of-squares (SOS) methods, as discussed in Ahmadi & Majumdar (2016); Dai & Permenter (2023), formulated this task via semi-definite programming (SDP), ensuring stability through candidate polynomial functions. Despite the progress of SOS methods, several theoretical results (Ahmadi et al., 2011; Ahmadi, 2012; Ahmadi & El Khadir, 2018) on asymptotic Lyapunov stability show that even some very simple globally asymptotically stable dynamical systems may not agree with a polynomial Lyapunov function of any degree. In addition, SOS methods suffer numerical sensitivity issues in practice.\nRecent advances in deep learning have enabled data-driven neural Lyapunov function with formal verification (Chang et al., 2019; Zhou et al., 2022; Wu et al., 2023; Edwards et al., 2024; Wang et al., 2024; Yang et al., 2024). However, these methods face two key challenges: 1) lack of interpretability and 2) high verification costs Dawson et al. (2023b). Neural networks' black-box nature limits insights into the system dynamical behavior. Additionally, overparameterization and nonlinear activations complicate formal verification, leading to scalability issues. Tools like SMT Chang et al. (2019), MIP Wu et al. (2023), and \u03b1, \u03b2-CROWN Yang et al. (2024) require small, specialized networks to ensure feasible verification times.\nCompared with neural counterparts, analytical Lyapunov functions offer two distinct advantages. First, their symbolic nature offers interpretability, and provides insights for designing stability-guaranteed control policy (Sontag, 1989; Feng et al., 2023a;b; Cui et al., 2023b). Also, they can serve as templates for other systems with similar formulations and potentially incorporate human expert's feedback in the loop. Second, analytical functions enable efficient verification due to their simplicity and symbolic structure, which seamlessly integrate with formal verification tools like SMT solvers. This reduces parameter complexity and eliminates the need to extract symbolic components or manage complex neural network elements like nonlinear activations. Figure 1 highlights the efficiency of verifying analytical expressions compared to neural networks for a 6-D polynomial system.\nIn this work, we aim to address the following question:\nCan neural networks effectively discover valid analytical Lyapunov functions directly from complex system dynamics?\nTo tackle this challenge, we introduce an end-to-end framework designed to find analytical Lyapunov functions for nonlinear dynamical systems given in analytical form. Building on the transformer's ability to model complex dependencies Vaswani et al. (2017) and the success of deep symbolic regression methods Holt et al. (2023), our framework deploys a symbolic transformer Kamienny et al. (2022) for Lyapunov function discovery. The transformer's encoder captures the structural characteristics of system dynamics, while the decoder generates candidate Lyapunov functions by modeling symbolic token distributions. Given the lack of high-quality (local) Lyapunov function datasets, particularly for high-dimensional systems, we propose a reinforcement learning (RL)-based approach to search for Lyapunov function on a per system basis, instead of pre-training like Alfarano et al. (2024). We verify Lyapunov conditions by localized sampling in the neighborhoods of minimizers of the candidate expressions, which are most likely to have violations. The identified counterexamples are then incorporated into the training set for further optimization. Our contributions are summarized as follows:\n\u2022 We introduce the first RL framework for directly discovering analytical Lyapunov functions in a per-system manner, bypassing the need for supervised learning with large-scale datasets.\n\u2022 We propose a novel and efficient policy optimization pipeline integrating global-optimization-based Lyapunov verification, reward design for candidate Lyapunov evaluation, and risk-seeking policy gradient to optimize the transformer, trainable on machines with limited computation resources.\n\u2022 We demonstrate the efficiency of our method on various systems, including non-polynomial dynamics like the pendulum, quadrotor, and power system frequency control. Notably, our approach scales to a 10-D system and discovers a valid local Lyapunov function for power system frequency control with lossy transmission lines, that is previously unknown in the literature."}, {"title": "2. Related Work", "content": null}, {"title": "2.1. Learning-based Lyapunov Function Construction", "content": "The field of learning-based Lyapunov function construction is advancing rapidly. Chang et al. (2019) formulated Lyapunov condition violations as the objective, jointly learning a neural Lyapunov function and a linear controller to guarantee stability for a given system, with stability verified via SMT solvers. Zhou et al. (2022) extended this to unknown dynamics with a neural controller. Dai et al. (2021) and Wu et al. (2023) focused on discrete-time systems, using MIP solvers for stability verification, requiring piecewise linear approximations. Yang et al. (2024) applied \u03b1, \u03b2-CROWN for scalable neural network verification, extending state feedback to output feedback control. However, scalability remains a challenge: SMT solvers handle up to 30 neurons, MIP solvers scale to 200 neurons Dawson et al. (2023a), and \u03b1, \u03b2-CROWN Yang et al. (2024) is limited to a three-layer architecture (16 neurons per layer).\nIn contrast to neural Lyapunov functions, Feng et al. (2024) and Alfarano et al. (2024) derived analytical Lyapunov functions. Feng et al. (2024) combined a neural network with the symbolic regression package PySR (Cranmer, 2023), which approximates the network to produce analytical Lyapunov functions, but the lack of interaction between system dynamics and symbolic regression component limits its potential. Alfarano et al. (2024) pre-trained a transformer on backward- and forward-generated global Lyapunov function datasets, relying on beam search for candidate generation. However, their method cannot adaptively refine the candidate Lyapunov functions if the beam search fails on specific dynamics, and it requires a dataset that is expensive to generate (e.g., thousands of CPU hours for a 5-D dynamics dataset) to achieve adequate generalization during inference. Furthermore, its emphasis on global stability limits its applicability to real-world, nonpolynomial control systems, which typically only admit local stability. Consequently, an RL-based approach that directly searches Lyapunov functions for a given system is indispensable."}, {"title": "2.2. Symbolic Regression with Generative Model", "content": "Symbolic regression is a supervised learning task that seeks to discover an analytical function f : Rn \u2192 R which approximates the output yi \u2208 R from input xi \u2208 Rn.\nRL-based Symbolic Regression. RL-based symbolic regression algorithms (Petersen et al., 2020; Costa et al., 2020; Landajuela et al., 2021) employed generative models, typically RNNs, to generate distributions of symbolic tokens representing mathematical operations and variables, from which analytical expressions are sampled. Rewards, evaluating the quality of the sampled expressions, are measured by fitness metrics like RMSE. Due to the non-differentiable step of converting token sequences into symbolic equations, policy gradients are used to optimize the output distributions. Mundhenk et al. (2021) extended this approach by integrating Genetic Programming (GP) to refine generated expressions, improving framework's overall performance.\nPre-trained Symbolic Regression methods. These methods are inspired by the success of transformers in Natural Language Processing (NLP) tasks. These algorithms contain two steps: 1) pre-train an encoder-decoder network to model p(f|D) on curated datasets by cross-entropy loss, and 2) sample from this distribution during inference via beam search or Monte Carlo Tree Search (MCTS). Methods like (Biggio et al., 2021; Kamienny et al., 2022; Bendinelli et al., 2023) rely on beam search without gradient refinement, often yielding suboptimal results for out-of-distribution data. In contrast, Holt et al. (2023) integrates RL-based policy gradient optimization with end-to-end RMSE loss for both pre-training and inference, allowing gradient refinement for unseen datasets during inference. Further, (Shojaee et al., 2023; Kamienny et al., 2023) enhance decoding process (expression generation) by incorporating MCTS with feedbacks, such as fitting accuracy and equation complexity."}, {"title": "3. Preliminary", "content": null}, {"title": "3.1. Lyapunov Stability", "content": "Our framework searches for analytical Lyapunov functions for autonomous nonlinear dynamical systems at an equilibrium point. Without loss of generality, we assume the origin to be the equilibrium point.\nDefinition 3.1 (Dynamical systems). An n-dimensional autonomous nonlinear dynamical system is formulated as\n$\\frac{dx}{dt} = f(x), x(0) = xo,$\nwhere f: D \u2192 Rn is a Lipschitz-continuous vector field, and DC Rn is an open set containing the origin that defines the state space. Each x(t) \u2208 D is a state vector.\nDefinition 3.2 (Asymptotic stability). A system of (1) is stable at the origin if \u2200 \u20ac > 0, there exists \u03b4 = \u03b4(\u20ac) > 0 such that ||x(0)|| < d \u21d2 ||x(t)|| < \u0454, \u2200t \u2265 0. The origin is asymptotically stable if it is stable and 8 can be chosen such that ||x(0)|| < d \u21d2 lim x(t) = 0 (Khalil, 2002).\nt\u2192\u221e\nDefinition 3.3 (Lie derivative). The Lie derivative of a continuously differentiable scalar function V: D \u2192 R along the trajectory of (1) is given by\n$LfV(x) = \\sum_{i=1}^{n} \\frac{\\DV}{\\dxi} \\frac{dxi}{dt} = \\sum_{i=1}^{n} \\frac{\\\u018fV}{\\dxi} fi(x).$\nProposition 3.4 (Lyapunov functions for asymptotic stability). Let x = 0 be an equilibrium point for (1) and D \u2286 Rn be a domain containing the x = 0. Let V : D \u2192 R be a continuously differentiable function such that\nV(0) = 0 and V(x) > 0 in D\\{0},\nLfV(x) < 0 in D\\{0},\nthen the origin is asymptotically stable.\nDefinition 3.5 (Lyapunov Risk). Consider a candidate Lyapunov function V for system f from Definition 3.1. For a dataset X = {x1,\u2026,xN} where xi \u2208 D, the Lyapunov risk of V Chang et al. (2019) over D is defined by\n$L(V) = \\frac{1}{N} \\sum_{i=1}^{N} (max(0, LfV(xi)) + max(0, -(i))).$"}, {"title": "4. Proposed Framework", "content": "This section introduces our RL-based generative approach, which aims to find an analytical Lyapunov function for a given dynamical system that certifies asymptotic stability following conditions in Proposition 3.4. Successfully identifying such a function guarantees system stability.\nThe framework, visualized in Figure 2, consists of three components: 1) a symbolic transformer, parameterized as $ = {5,0}, for candidate analytical Lyapunov functions generation, where ( and 0 denote the parameters of encoder and decoder, 2) a numerical verifier employing the SHGO Endres et al. (2018) global optimization algorithm for Lyapunov conditions' checking (Proposition 3.4) and counterexamples' feedback, and 3) a risk-seeking policy gradient algorithm optimizing the transformer's parameters based on candidate Lyapunov functions' rewards. To tackle the challenges posed by the exponentially growing search space of complex, high-dimensional systems, our framework integrates Genetic Programming as expert guidance to improve expression quality and training efficiency. We denote XCD as the training set for reward calculation."}, {"title": "4.1. Candidate Lyapunov Function Generation from Symbolic Transformer", "content": "Expression Representation. Inspired by the deep symbolic regression frameworks, we use a symbolic transformer model as the backbone. The transformer takes a dynamical system f(x) as input and generates candidate analytical Lyapunov functions V, such that: V4(x) > 0 and LfV < 0,\u2200x \u2208 D\\{0}. Following the expression representation rules in Lample & Charton (2020), our framework represents symbolic transformer models' input and output as sequences of symbolic tokens. Each mathematical expression can be converted into a symbolic expression tree, a binary tree where internal nodes are symbolic operators and terminal nodes (leaves in the tree) are variables or constants. Symbolic operators can be either unary (i.e. one child), such as sin, cos, or binary (i.e. two children), such as +, x. Furthermore, each symbolic expression tree can be represented as a sequence of node values, either symbolic tokens or numerical coefficients, by its pre-order traversal (i.e. first visiting the parent, then traversing the left child and right child). In this way, each expression obtains a pre-order traversal representation, which can uniquely reconstruct the original expression Petersen et al. (2020). We denote Vo as the ith node value in the pre-order traversal of V's expression tree, and L\u300f as the symbolic library, e.g. {+, \u00d7, log, sin, xj}, where V\u00f8\u2081 is sampled from.\nDynamics Tokenization. By Definition 3.1, the symbolic transformer models' input f(x) is composed by n ordinary differential equations da = f(x) for i = 1,\u2026\u2026,n. Each analytical expression fi(x) can be represented as a sequence of symbolic tokens and numerical coefficients by the pre-order traversal of its expression tree. Concatenated the sequences of pre-order traversal for all fi(x), with SOS (start token) and EOS (end token) as separators, we obtain the tokenized dynamics, which is fed into the encoder of symbolic transformer and encoded as a latent vector F\u2208RP. The numerical coefficients are tokenized in two schemes: an integer is represented as a sequence of digits in base b = 10 (e.g. 123 is tokenized as [1, 2, 3]), and a real number is represented in scientific notation rounded to 4 significant digits (e.g. 3.14 is tokenized as [3, 1, 4, 0, 10\u00b0]). A detailed example is illustrated in Figure 3, Appendix A, where we presents the symbolic representations of the simple pendulum dynamics in sequences of pre-order traversal.\nCandidate Expression Generation. The decoder generates candidate expressions V, in an auto-regressive manner. That is, each token V\u2081 in the pre-order traversal of V is sampled from the symbolic library Ls according to conditional distribution p(Vo\u2081 | V1:(i-1), 4, f(x)), where V1: (4-1) is the first (i - 1) selected symbolic tokens in the pre-order traversal of V. This conditional dependence can be achieved by the decoder which emits a probability distribution & over symbolic library Ls, conditioned on the previously selected tokens and input dynamics. Since analytical expression in its pre-order traversal is inherently hierarchical, we also deploy the hierarchical tree state representation (Petersen et al., 2020; Holt et al., 2023). This method enhances the decoder input by concatenating the representations of the parent and sibling nodes with previously selected outputs and the dynamics. Once the token sampling process for V is complete, we evaluate the function value at origin V(0) and subtract it from V\u2081, ensuring the Lyapunov condition V(0) = 0. Through this process, we can sample a batch of Q candidates V = {V} ~p(V\u00a2\\\u00a2, f(x))}=1, which will be verified according to the Lyapunov conditions."}, {"title": "4.2. Verification and Falsification Feedback", "content": "Leveraging the analytical nature of candidate Lyapunov functions, efficient methods for symbolic expressions, such as root finding Feng et al. (2024), can be applied to Lyapunov condition verification and counterexample generation. In this work, we propose a global-optimization-based numerical verification algorithm, using Simplicial Homology Global Optimization (SHGO) (Endres et al., 2018), that effectively checks the Lyapunov conditions around minimizers and feedback counterexamples into the training set X for reward calculation. SHGO is a constrained global optimization algorithm with theoretical guarantees for convergence. To make the paper self-contained, we present the guarantees in Proposition 4.1. This algorithm identifies the global minimizer over the state space from a set of local minimums, each of which is obtained from a convex subdomain in the feasible search space. Taking advantage of the theoretical results, we employ the SHGO algorithm for counterexample detection in our verification process.\nProposition 4.1 (Convergence Gurantees of SHGO Endres et al. (2018)). For a given continuous objective function f that is adequately sampled by a sampling set of size Ns. If the size of the minimizer pool M extracted from the directed simplex (a convex polyhedron) H is |M|. Then any further increase of the sampling size Ns will not increase |M|.\nThis result shows that if the initial points are adequately sampled, that is, the union of identified locally sub-convex domains initiated from starting points covers the feasible search space, then the minimizer pool M, which contains all local minimum extracted from the directed simplexes, will contain the global minimizer of the feasible search space. Notably, the required sampling size Ns can be unbounded.\nDuring verification, for a candidate V\u266d, SHGO is first applied to identify minimizers x\u2081 and x\u00bd of V, and its negated Lie derivative \u2013 LfVp in the state space D. These minimizers highlight the regions where Lyapunov conditions are most likely to fail. Next, data points x from neighborhoods around these minimizers, B\u2084(x1) and Br(x) where r is a small value relative to ||D||2, are sampled to check Lyapunov conditions, i.e. V\u2084(x) > 0 and \u2212LfVp(x) > 0 for x \u2208 D\\{0}. This localized sampling scheme effectively identifies violations within D. Additional random sampling covering approximately 30% of the total data and condition checking across the state space are performed to complement this localized sampling to capture additional potential violations and provide a global assessment. Identified counterexamples Xce are added to the training set X for reward calculations. Once a candidate Lyapunov function passes this verification process and does not encounter any violation in X, it indicates a numerically valid solution is found, pending the final formal verification. Appendix B details the verification implementation."}, {"title": "4.3. Risk-Seeking Policy Gradient", "content": "The empirical Lyapunov risk L(V6) in Equation (4) quantifies the violation degree of Lyapunov conditions over a given dataset. Following Petersen et al. (2020); Bastiani et al. (2024), we apply the continuous mapping g(x) = +x and define proposed Lyapunov risk reward as:\n$R(V\u2084) = g (L(V\u2084)) = \\frac{1}{1 + C(V)}.$\nwhere L(V) is measured over training set X. The continuous mapping g(x) bounds the reward value to [0, 1]. For candidate expressions that do not incorporate all state variables or are analytically incomplete, we assign their rewards to be 0 to ensure they are effectively penalized.\nGiven the violation measure for each sampled V is non-differentiable with respect to the transformer parameters 4, we employ the risk-seeking policy gradient to update end-to-end. The objective of standard policy gradient Williams (1992) is defined to maximize Jstd() = EV\u3085~p(V+\\$,f(x)) [R(V)], the expectation of the reward function R() for candidates' quality evaluation based on the current parameter 4. This objective is desirable for problems aiming to optimize the average performance of the policy network. In our task, final performance depends on finding at least one valid Lyapunov function that meets the conditions in Proposition 3.4, rather than optimizing for average performance. Consequently, standard policy gradient methods are inadequate due to the misalignment.\nIn our framework, we adopt risk-seeking policy gradient Petersen et al. (2020) that only focuses on maximizing best-case performance. Let Ra($) as the 1 \u2013 a quantile of the distribution of rewards of sampled candidates under the current policy . The learning objective of risk-seeking policy gradient, parameterized by a, is formulated as:\n$Jrisk($, a) = Ev\u2084~p(\\$,f(x)) [-R(V) | R(V) \u2265 Ra($)].\nThis objective aims to optimize only the rewards of high-quality candidates from the top 1 \u2013 a quantile."}, {"title": "4.4. Automated Expert Guidance", "content": "While the risk-seeking policy gradient algorithm effectively optimizes the model, training efficiency can be enhanced by off-the-shelf tools that further explore the function space based on the transformers. Inspired by Mundhenk et al. (2021), we incorporate a Genetic Programming (GP) component (DEAP Fortin et al. (2012)) into the training paradigm.\nThe GP algorithm starts with a batch of initial populations (expression trees) and iteratively refines these populations through evolutionary operations: mutation, selection, and crossover, with a pre-defined metric to evaluate the fitness of populations to the task (e.g. MSE for symbolic regression task). Within our framework, we feed the latest batch of generated candidates {V} ~ p(V$\\$, f(x))}=1 from the decoder into the GP module as the starting population\u00b9, refine these expressions through evolutionary operations with Lyapunov risk reward as the measure of fitness, and obtain a batch of refined expressions. We select an 'elite set' of the refined expressions Vgp = {Van ~ GP(V)}=1, regard them as target expressions, and optimize the transformer model in a supervised learning manner, maximizing the probability that the generated token matches the reference tokens from Vgp, with the following expert guidance loss:\n$L(Vgp) = \\frac{1}{G} \\sum_{j=1}^{ki} - log (p(gp) | VP1:(i-1), f(x)),$\nwhere G is the number of expressions in Vgp, and ki is the complexity (number of symbolic tokens in the pre-order traversal) of Vi Vip. Each expression Vip Vip is weighted by its Lyapunov risk reward in L. Algorithm 1 summarizes the training process, with more details in Appendix D. The GP solutions explore the characteristics of Lyapunov functions that have not been captured by the transformer yet and effectively guide the transformer for higher-quality generation."}, {"title": "5. Experiment", "content": "We validate the proposed algorithm across a variety of nonlinear dynamics by finding their local Lyapunov functions at the equilibrium point to verify their stability, where the systems are autonomous (or closed-loop systems with known feedback control laws). We use dReal Gao et al. (2013) SMT solver for final verification of found Lyapunov functions, with a numerical tolerance error \u20ac = e-\u00b3 and precision d = e-12, over the state space, i.e. V(x) > \u03b4 and LfV(x) < -d over D\\B\u025b(0). The excluded ball Be (0) is to avoid numerical issues, which is a common practice for SMT-based formal verification Chang et al. (2019). Global stability can be determined through further analysis; for instance, if the Lie derivative is a negation of sum-of-squares, it is sufficient to establish global stability."}, {"title": "5.1. Experimental Setting", "content": "Test Dynamics. We categorize our collected test dynamical systems into two kinds: 1). Polynomial Systems, and 2). Non-polynomial Systems, where three polynomial systems are adopted from (Alfarano et al., 2024) (Appendix F.2, F.3) and others come from real-world examples. Detailed information about systems is summarized in Appendix F and G. The dimension of these test systems ranges up to 10.\nImplementation Details of Framework. Detailed explanation for all components in our framework is presented in Appendix A (Transformer), B (Global-optimization-based Numerical Verification), C (Risk-seeking Policy Gradient), and D (Genetic Programming). The symbolic library L\u201d is defined as {+, -, \u00d7, sin, cos, xi} in all tests.\nBaseline Algorithms. We compare our proposed framework against two learning-based algorithms for neural Lyapunov function discovery in continuous nonlinear dynamical systems: 1) Augmented Neural Lyapunov Control (ANLC) Grande et al. (2023), and 2) FOSSIL 2.0 Edwards et al. (2024). Both works train a neural Lyapunov function with the empirical Lyapunov risk loss and employ a counterexample guided inductive synthesis (CEGIS) loop for better generalization over the state space D. Detailed descriptions and baseline setup can be found in Appendix E. We also directly apply the pre-trained model in Alfarano et al. (2024) to our test systems. Limited to global stability and systems with dimension less than 6, their model can only succeed in systems presented in Appendix F.1, F.2, F.3, and G.1."}, {"title": "5.2. Performance Analysis", "content": "Table 1 summarizes the runtime, success rate, and discovered Lyapunov functions for a selection of tested nonlinear systems, ranging from 2-D to 10-D, demonstrating the robustness and scalability of our framework. As dimensionality increases, runtime grows with the exponentially expanding search space, reward calculations, SHGO optimization, and genetic programming.\nUnlike existing methods that produce neural Lyapunov functions, our framework yields interpretable analytical candidates. For example, it correctly identifies the energy function as a valid Lyapunov function for the simple pendulum. Likewise, for the 3-bus power system (Appendix G.3), it discovers the commonly used energy-based storage function for incremental passive systems Weitenberg et al. (2018).\nAnalytical Lyapunov functions can potentially bypass the need for formal verification. In the 3-D Trig system (Appendix G.2), over the state space D = {(x1,x2, x3) \u2208 R\u00b3 | |xi| \u2264 1.5, Vi\u2208 {1,2,3}}, the positive definiteness of the identified Lyapunov function is evident from its formulation. Moreover, the Lie derivative LfV = \u22122x3 x3 sin(2x3) is directly identifiable as non-positive in D, since x sin(x) > 0 for all x \u2208 (\u2212\u03c0,\u03c0). By the invariance principle Khalil (2002), the discovered function certifies the asymptotic stability of origin in state space D. When direct identification is non-trivial, SMT solvers can efficiently verify Lyapunov conditions given analytical formulations' simplicity."}, {"title": "5.3. Newly Discovered Lyapunov Function", "content": "Despite decades of effort in the control community to identify Lyapunov functions, certain stable dynamics still lack a valid Lyapunov function to directly certify their stability. One example is the lossy frequency dynamics in power systems Chiang (1989); Cui & Zhang (2022), where \u201clossy\u201d refers to the consideration of energy losses in transmission lines. For simplicity, we focus on a 2-bus (4-D) lossy system with the equilibrium point set at the origin, with detailed descriptions provided in Appendix G.5. Using the proposed method, we successfully discover two local Lyapunov functions valid in the considered region D = {(\u03b4\u2081, \u03b42, \u03c91, \u03c92) \u0395 R4 | |di| \u2264 0.75 and |wi| < 2 for i = 1,2}:\n$V1 (81, 82, 1,2) = \\sum_{i=1}^{2} w\u00b2 + (sin(82) \u2013 sin(81) + w2)\u00b2,\nV2 (\u03b4\u03b9, \u03b4\u03b5, \u03c91, W2) = \\sum_{i=1}^{2} w + (sin(82) sin(\u03b4\u03b9) \u2013 \u03c9\u03b9).$"}, {"title": "6. Conclusion", "content": "This paper presents an end-to-end framework for analytical Lyapunov function discovery on nonlinear dynamical systems, which employ a symbolic transformer for candidate expressions' generation, with risk-seeking policy gradient together with GP for transformer training. We propose an efficient verification and counter-example generation method in the training process via a global optimization algorithm SHGO, and use SMT solvers for the final Lyapunov function certification. Our framework can be extended to other certificate-function discoveries, such as deriving control barrier functions for safety in given dynamics. More broadly, several promising research directions arise from this work. One direction is efficiently incorporating physical constants such as gravitational acceleration or object mass, which can significantly improve generalization\u2014though directly introducing them as variables might add unnecessary complexity. Another direction involves extending our framework to discover control Lyapunov functions, which are vital for designing stabilizing feedback laws. Finally, since constructing large-scale datasets for local Lyapunov functions remains challenging, leveraging our approach to refine pre-trained models for downstream tasks represents an exciting opportunity to enhance Lyapunov function discovery."}, {"title": "Impact Statements", "content": "This paper advances learning-based Lyapunov function discovery in control theory by proposing a systematic approach to finding Lyapunov functions for any dynamical system. Once a valid Lyapunov function is found, it guarantees system stability in the state space and offers insights for control engineering. Our method can be applied in energy systems, robotics, transportation, and other control systems. While these improvements have the potential to enhance safety and efficiency, we do not foresee specific negative ethical or societal consequences arising directly from our approach."}]}