{"title": "Digital Twinning of a Pressurized Water Reactor Startup Operation and Partial Computational Offloading in In-network Computing-Assisted Multiaccess Edge Computing", "authors": ["Ibrahim Aliyu", "Awwal M. Arigi", "Tai-Won Um", "Jinsul Kim"], "abstract": "This paper addresses the challenge of representing complex human action (HA) in a nuclear power plant (NPP) digital twin (DT) and minimizing latency in partial computation offloading (PCO) in sixth-generation-enabled computing in the network (COIN) assisted multiaccess edge computing (MEC). Accurate HA representation in the DT-HA model is vital for modeling human interventions that are crucial for the safe and efficient operation of NPPs. In this context, DT-enabled COIN- assisted MEC harnesses DT (known as a cybertwin) capabilities to optimize resource allocation and reduce latency effectively. A two-stage approach is employed to address system complexity. First, a probabilistic graphical model (PGM) is introduced to capture HAs in the DT abstraction. In the PGM, HA and NPP asset-twin abstractions form coupled systems that evolve and interact through observable data and control input. Next, the underlying PCO problem is formulated as a multiuser game, where NPP assets can partially offload tasks to COIN and MEC. We propose a decentralized algorithm to optimize offloading decisions, offloading ratios, and resource allocation. The simulation results demonstrate the effectiveness of the proposed method in capturing complex HAs and optimal resource allocation in DT- enabled NPPs.", "sections": [{"title": "I. INTRODUCTION", "content": "ADVANCES in communication, artificial intelligence, and computing have been driving the digital transformation of nuclear power plants (NPPs). These developments have contributed to the emergence of digital twinning that replicates physical objects and their surroundings [1]. Enabling digital twins (DTs) in NPPs enhances energy efficiency, enabling predictive maintenance, autonomous control, and safety analysis [2].\nIn NPPs, human tasks/operations, such as pressurized water reactor (PWR) startup operations, include reactor operations, refueling, maintenance, shutdowns, and chemical control, which can be continuous or periodic. Digital twinning is essen- tial for representing these processes accurately [3]. An accurate DT representation of human actions (HAs) is crucial for their impact on physical processes, safety measures, and critical event responses. The human-machine interface is also vital, covering interactions in control rooms, remote monitoring, diagnostic centers, and field devices.\nImplementing a DT system in NPPs requires a diverse computing and communication infrastructure, from clusters to handheld devices [4]. Sixth-generation (6G) ultra-reliable and low-latency computing (URLLC) capabilities are crucial for mission-critical DT applications [5], and the computing in the network (also known as In-network computing, COIN) paradigm leverages network resources to minimize latency and enhance the quality of service [6]. Integrating a DT with these technologies offers opportunities and challenges for enhancing NPP reliability, availability, and maintainability at reduced costs."}, {"title": "A. Related Work", "content": "1) Digital Twinning of HAs in NPPs: The DT is applied in various industries, including health, meteorology, education, manufacturing, transportation, energy, and business [7], [8]. In the nuclear industry, DT adoption is limited due to high safety and security standards [3]. Nonetheless, research on DT adoption in nuclear systems has increased, focusing on technical challenges [9], [10], [11], safeguards and security [12], applications for advanced reactors [13], [14], and specific applications, such as flow-induced vibration prediction [15]. However, the consideration of HAs and procedures in DT remains largely unexplored.\n2) DT-enabled Task Offloading: The COIN paradigm min- imizes latency and improves the quality of experience using untapped network resources [16], but may increase power consumption, creating a trade-off between delay and energy use. In this context, Partial subtask offloading is essential, especially when COIN coexists with edge computing solu- tions. Furthermore, digital twinning has been transforming"}, {"title": "B. Motivation and Contributions", "content": "The power startup scenario of an NPP involves increas- ing the reactor power (RP) to full capacity, requiring con- stant monitoring and complex manipulations due to disabled automatic and safety functions. Unlike standard full-power operations, this scenario demands more decision-making and poses a higher risk of human error due to changing system parameters and potential instability [4], [3]. Although artificial intelligence techniques have been studied for NPP control, these techniques have not addressed adapting the current systems for DT applications.\nPCO is ideal for NPPs, as it efficiently distributes tasks across COIN nodes (CNs) and edge servers (ESs), balancing latency and energy consumption through partial offloading [23]. This approach enhances overall system performance and operational safety by leveraging sensor data and factory monitoring to detect unusual HAs and support DT solutions.\nMotivated by the aforementioned issues, this study focuses on the complex representation of human actions (HAs) within digital twins (DTs) while minimizing latency in partial compu- tational offloading (PCO) within a 6G-powered COIN-assited MEC(C-MEC). Accurate representation of HAs in DTs is crucial for modeling human interventions that are vital for safely and efficiently operating NPPs. This work is the first to explore the digital twinning of HA in NPPs alongside the underlying DT-based network resource allocation problem in a collaborative C-MEC architecture. The primary contributions include the following:\n\u2022 We formulate the system utility maximization problem, jointly optimizing the digital twinning of HA-related PWR operations and resource allocation in the C-MEC, solving the problem in two stages.\n\u2022 In the first stage, we apply a PGM to capture the intricacies of HAs in the DT abstraction, creating an interconnected system that evolves and interacts via ob- servable data.\n\u2022 In the second stage, we formulate the PCO problem as an exact potential game (EPG) and theoretically prove the existence of a Nash equilibrium (NE).\n\u2022 Within the game, we formulate the offloading ratio and resource allocation (ORRA) problem as a Markov deci- sion process (MDP) and employ the DDQN to predict and maximize future system utilities proactively.\n\u2022 We conduct extensive experiments to evaluate the pro- posed digital twinning of the PWR operation and the underlying C-MEC-based network.\nThe rest of the paper is organized as follows. Section II presents the system model, including the DT-HA, DT- enabled C-MEC, communication, and computational models, and the problem formulation. Next, Section III outlines the proposed approach involving the HAs and procedures using the PGM, and C-MEC resources for optimal communication and computing. Section IV details the evaluation, and finally, Section V concludes the paper."}, {"title": "II. SYSTEM MODEL", "content": "This section presents the system model from the HAS and procedures and the COIN-assisted URLLC-based edge network. In addition, the problem emanating from the complex interaction of the two models is formalized. Fig. 1 illustrates the block diagram of the studied system, consisting of the DT- HA model and C-MEC services in which DT jointly optimised NPP HAs and C-MEC resources. The main notations used in this paper are summarised in Table I"}, {"title": "A. Human Actions and Procedures in Digital Twin Nuclear Power Plants", "content": "1) Analysis of PWR startup operations: This study focuses on the startup operation of a typical Westinghouse three-loop PWR, following the general operating procedures (GOPs) [3]. The key GOPs include reactor coolant system filling and venting, cold shutdown, hot shutdown, hot standby to 2% RP, and power operation and secondary system heat up and startup.\nThe critical part of the startup operation involves increasing the NPP power from 2% to 100% and transitioning the plant to normal conditions for electricity generation. Six major parameters serve as milestones: the pressurizer level (PL), reactor coolant temperature (RCT), reactor coolant pressure (RCP), steam generator (SG) pressure (SGP), SG level (SGL), and RP. These parameters are considered subsystems requiring communication and computing resources to operate.\nBefore reaching 2% power, five GOPs are completed. After reaching 2% power, only two GOPs are necessary: power operation greater than 2% and secondary system heat up and startup. The former provides instructions for increasing the plant load from 2% to 100%, whereas the latter details steps for aligning and starting secondary systems. These procedures involve operating the rod controller, turbine load controller, feedwater (FW) pumps, condenser pumps, SG FW valves, and a synchronizer based on the planned rate of power increase."}, {"title": "2) Operator Task DT Model", "content": "Accurately representing oper- ator activities is crucial for ramping up power to 100%. Human tasks are grouped into monitoring, decision-making, discrete control, and continuous control. The DT-HA model captures operator actions digitally, ensuring consistency and safety. An action profile lists the potential actions with likelihoods based on historical data. Environmental variables account for external conditions, highlighting interactions between the guidelines and such factors as temperature or noise.\nDefinition 1: In the context of the proposed NPP model, the actions of each operator in the DT must precisely mirror real- world actions. For every operator action denoted as h from a set of possible actions H, the state of the DT, represented by yh, is governed by the following relation:\n$Yh = fh(S, A), \\forall h\\in H$   (1)\nwhere S and A represent the state/condition of the physical system and HA or decision-making in the system, respectively. Equation (1) ensures that the DT adheres to the operational guidelines, maintaining the highest standards of safety and operational accuracy.\nThe NPP startup operation depends on PL Pp, RCT Tc, RCP P, SGP P\u2083, SGL L\u2083, and RP Pr.\nWe let $Os (Pp, Tc, Pc, Ps, Ls, Pr)$ be an indicator function for operational constraints during the NPP startup, producing 1 when all operational constraints are met, and 0 otherwise. Similarly, $Ss (Pp, Tc, Pc, Ps, Ls, Pr)$ is an indicator function for safety constraints during the NPP startup, returning 1 when all startup-specific safety constraints are satisfied and 0 otherwise.\nDefinition 2: The general NPP operational constraint must be satisfied to ensure compliance with operational and safety regulations, preventing actions that could jeopardize NPP safety:\n$OS(PO, TO, PO, PO, LO, PO) \\times S(PS, TS, PS, PS, LS, PS) = 1$ (2)\nThe constraint ensures that all decisions align with the opera- tional safety and procedural requirements of the NPP. This ex- pression states that the operational and safety constraints must be satisfied for any given configuration of tasks, resources, and HAs. If either Os or Ss is 0 (i.e., its respective constraints are not met), then the entire operation becomes 0, indicating that the configuration is invalid."}, {"title": "B. COIN-assisted URLLC-based Edge Network Model En- abling NPP DT", "content": "The C-MEC network architecture system model is illus- trated in the lower part of Fig. 1. The model consists of a physical layer comprising subsystems which represent the six major NPP subsystems and network resources, such as COIN- enabled CNs and the ES. This network infrastructure supports the operation of DT services by optimizing resource allocation, enabling the entire system via a real-time interaction mecha- nism.\nWe let M = {1,2,..., M} be a set of M subsystems, K = {1,2,..., K} be a set of K COIN CNs, and R be the ES. The CNs and ES are associated with an access point (AP) to connect the subsystems. Further, URLLC short packet communication is employed between the subsystems and APS to ensure exceptionally reliable performance and low latency on the Internet of Things. The system model is as follows:\n1) Offloading Model in the C-MEC Network: Regarding the time slot model, the subsystems and CNs are fixed within each time point and vary over different time slots. At each time slot t, each subsystem has a computational task characterized Cm\nby Jm = {1m, Tmax}, where 7m = m represents the task complexity (cycle/bits), Im denotes the task size in bits, Cm indicates the required CPU cycles (cycles) to execute the task, and Tmax is the maximum tolerable latency for task Jm.\nThis scenario focuses on partial offloading to use parallel processing for latency reduction. We let Ip = {Amk, m} be the offloading ratio variable, where Amk denotes the portion executed at the CNs, and m = 1 Am represents the portion of the task executed at the ES. Offloading resources are indicated by the variable \u03a6\u2081 = {\u03a6\u03bb, \u03a6\u05d0{ where I and \u05d0 indicate the task execution resource locations at the CNs and ES, respectively. We assume the tasks are generated with high granularity, enabling partial offloading. For the task Jm, Im = XmIm + k\u2208K AmkIm and Cm = XmCm + \u2211k\u2208K>mkCm satisfy 8m + \u03a3\u03ba\u2208K dmk = 1.\n2) C-MEC DT Model: The DT services generate virtual replicas of physical systems, replicating the hardware, appli- cations, and real-time data. The URLLC-based C-MEC DT is defined as DT = {M, \u03a6\u2081}, where {M, \u03a6\u2081} represents a virtual mirror of the system, including M subsystems and PL C-MEC computing resources (CNs and the ES). The DT layer, informed in real time, automates control via such services as data analysis, decision-making, and instant optimization, fo- cusing on tasks that include offloading strategies and resource allocation.\nThe specific DT of each m-th subsystem (service module) is associated with a CN for processing, defined as DTen = (fon, fon), where for denotes the estimated processing rate, and for quantifies the variation from the actual processing rate between the physical subsystem and its DT [24]. In the DT layer, the critical estimated processing rate, for, mirrors subsystem behaviors, driving optimization decisions for device configurations. This rate is the focus of the optimization, with its deviation set as a predetermined percentage for simulations, following established practices [18].\n=Likewise, for the \u2081-th C-MEC computing resource (CNs\nand the ES), its DT (DT) is formulated as DT\n\u03a6\u0399=fon, fom), where from signifies the estimated processing rate\nof the real C-MEC, and fom characterizes the disparity in\nthe processing rate estimation compared to the actual C-MEC.\nThe DT emulation of C-MEC (CNs and ES) provides valuable\ninsight into C-MEC processing rates, facilitating the efficient\nallocation of computing resources and reducing processing\nlatency through the offloading ratio and computing resource\nallocation adjustments."}, {"title": "C. Communication Model", "content": "The AP, with L antennas serving M single-antenna SMS, establishes channel connections with compute resource L represented by hm1 = \u221aImhm, where gm is the large-scale channel coefficient and hm\u2081 is small-scale fading following CN(0, I), where CN(.,.) represents a complex circularly symmetric Gaussian distribution.A channel ma- trix H = [h1, h21\u2026\u2026\u2026, hM\u2081] \u2208 CLXM contains connections from m-th subsystems to the -th AP. Each subsystem has an allocated bandwidth, bm. Match filtering and successive interference cancellation is employed to improve transmission performance [25]. Then, the signal-to- interference-plus-noise at the P\u2081-th AP by the m-th subsystem is defined as $\\gamma_{m\\Phi_{I}} (p, n) = \\frac{Pm||h_{m||}^2}{I_{mo\\mathcal{Z}} (p, n) + N_0}$, where PML denotes the transmission power of the m-th subsystem, No denotes noise power, p = [Pm1]m=1, and Imoz (p, n) by subsystems n > m. Thus, the uplink URLLC transmission rate is expressed as follows [26], [27]:\n$Wm\\Phi_{I} (p, n) \\approx Blog_2 \\Big[1 + \\frac{V_{mL} (P, n)}{N} \\Big[ \\frac{-BV_{mL} (p, n) Q^{-1}(\\epsilon)}{In 2} (3)\nwhere B represents the system bandwidth, e characterizes the likelihood of decoding errors, m\u2081 (p,n) stands for the Signal-to-Noise Ratio (SNR) observed by the m-th sub- system, $Q^{-1}(.)$ denotes the reverse function of Q(x) =\n$\\frac{1}{\\sqrt{2\\pi}}$ e^{-t^2/2} dt$, and Vmo, is the channel dispersion given\nas $Vm_{1} (p, n) = 1 \u2013 \\Big[1 + \\frac{PLIM}{N} \\Big]^{-2}$. The uplink wire- less transmission latency from the m-th subsystem to the IL-th C-MEC resource can be expressed as follows:\n$T_{CO^{L}_{m\\Phi_{I}}} (p, n, \\Phi_{L}) = max \\Big\\{\\frac{PL_{1M}}{W_{m\\Phi_{I}} (p, n)}, \\frac{\\Phi_{L} I_m}{W_{1\\Phi_L} (p, n)}\\Big\\}.$ (4)"}, {"title": "D. Computational Model", "content": "In the computational model, each subsystem generates a granular computation task Jm in which a portion can be executed by the CNs and another portion at the ES. The model is defined as follows:\n1) COIN Node Processing: For the COIN node, the task Jm portion Amk is executed by CNs with the estimated processing rate fon. Thus, the estimated CN execution latency is as follows:\n$T_{cn_{mk}} (\\Lambda_{mk}, f_{cn}) = max_{\\forall k \\epsilon K} \\frac{\\Lambda_{mk}C_m}{f_{cn}^m}$ (5)\nIf the discrepancy between the actual kth CN and its DT can be predetermined, the gap in computing latency between real-world performance and DT predictions can be estimated as follows:\n$\\triangle T_{mk} (\\Lambda_{mk}, f_{cn}) = \\frac{\\Lambda_{mk}C_m f_{mk}}{f_{cn} (f_{cn} - f_{cn})}.$\n(6)\nThus, the actual CN processing time is $T^{en}_{mk}= \\triangle T^{cn}_{mk} + T^{cn}_{m}$.\nThe total latency, including the transmission and computing latency is\n$T^{cn}T_{m} = T^{cn}_{mk} + T^{M L}$ (7)\n2) MEC Processing: The task Jm portion Nm executed by the ES with the estimated processing rate of fem incurs the following latency:\n$T^{em} (N_m, f_{em}) = \\frac{N_m C_m}{f_{em}}$\n(8)\nThe latency gap Tem between the real latency and the DT is estimated as follows:\n$\\triangle T^{em} (N_m, f_{em}) = \\frac{N_m C_m f_{em}}{f_{em} (f_{em} - f_{em})}$ (9)\nThus, the actual latency for task execution at $T^{em}_{m} = \\triangle T^{em} + T^{em}$.\nThe total delay at MEC is\n$T^{em}T = T^{co}_{m} + T^{em}$ (10)"}, {"title": "3) Latency Model", "content": "The total end-to-end (e2e) DT latency within the system includes the CN processing latency, task of- floading transmission latency, and ES processing latency. Thus, the e2e DT latency is expressed as $T^{e2e} = T^{en} + T^{co}_{m} +\n = max_{\\forall k \\epsilon K} \\{\\frac{\\Lambda_{mk}C_m}{f^{ken} \\underline{fken}}}, \\frac{N_mC_m}{f^{kem} - f^{kem}} \\}+  max_{\\forall \\Phi L} \\{\\frac{P_{LIM}}{W_{m\\Phi L} (P,n)} +{\\frac{L_{n}J_{m}}{W_{L \\Phi L} (P,n)}\\} .$\n}\n{W^{km}_{m\\Phi L} (P,n) +\n}\\.\n\\frac {W^{km}_{M\\Phi_{L}}} (P,n)$"}, {"title": "E. Problem Formulation", "content": "We let Sm = {Sm0, Sm1,8m2,...,SmK | Smj \u2208 {0,1}} denote the offloading strategies for subsystem m. The offload- ing strategy profile of all subsystems is denoted as s = {sm | Sm \u2208 Sm,M\u2208 M}, where sm = Smj\n1 suggests that subsystem m accomplishes its task via decision j, otherwise Sm = $m0 = 0. Smo indicates the decision variable for task execution at the ES while Smk are executed at the CN k. From the subsystem perspective, we define the subsystem mutility as the difference between the reduced latency due to offloading and the computational cost as follows:\n$U_m = \\sum_{j \\epsilon KU{0}} S_{mj}[g_t (T^{em} - T^{e2e}) \u2013 p_j p_j C_m ]$ (11)\nwhere gt is the unit gain latency reduction and pj is propor- tional to computing capacity, indicating offloading cost per workload at node j.\nThe primary objective is to maximize the system utility by minimizing the overall system latency, considering HAs and task offloading. The problem formulation is as follows:\nP: $max_{\\varsigma,\\Phi,\\beta, H} \\sum_{M \\epsilon M} U_m$ (12)\ns.t. $\\sum_{j \\epsilon KU{0}} S_{mj} \\le 1$ (12a)\n$\\sum_{MEM} S_{mj} \\le 1$ (12b)\n$\\sum_{MEM} S_{mj}T^{e2e} < T^{max}$ (12c)\n$\\sum_{MEM} \u03b2_m \\le 1$ (12d)\n$Yh = fh(S, A), \\forall th\\epsilon H$ (12e)\n$Os (Pp, Tc, Pc, Ps, Ls, Pr.) \\times S_s (Pp, Tc, Pc, Ps, Ls, Pr) = 1$ (12f)\n$Smj \\epsilon \\{0,1\\},0 < \\Phi, \u03b2 \\le 1,\\forall h \\epsilon H, yn \\epsilon D, Vm \\epsilon M, j\\epsilon KU \\{0\\}$ (12g)\nConstraint (12a) ensures each task is partially offloaded to at most one node. Constraint (12b) manages the associations be- tween the subsystem and COIN node. Constraint (12c) enforce latency requirements and (12d) ensures resource allocation is within CN capacity. Constraint (12e) ensures the DT state matches the current system and HAs and (12f) aligns decisions with operational and safety constraints. Finally, (12g) denotes optimization constraints.\nThe objective function is non-convex due to binary deci- sions, nonlinear relationships, and multiplicative interactions."}, {"title": "III. PROPOSED STRATEGY", "content": "Due to the intractability of problem P, the DT problem is decomposed into three subproblems: offloading ratio optimiza- tion, resource allocation, and HA digital twinning integration.\nWe propose a decentralized game-theoretical approach to rep- resent the DT-HA model and minimize latency in PCO within the C-MEC environment. The PGM captures the intricacies of the DT-HA model, where the DT state reflects the system state and determines HAs, evolving through observable data and control inputs.\nNext, the offloading decision is modeled as a strategic game with HA constraints to determine subsystem utility. As a rational player, each subsystem devises its offloading strategy based on others' strategies. The DDQN refines the ORRA, optimizing PCO decisions, offloading ratios, and resource allocation under a given DT-HA state. Fig. 2 illustrates the proposed scenario, divided into two parts: the DT-HA using the PGM and the C-MEC services, which provide optimal communication and computing resources for efficient DT operation. The operational flow involves four steps: initializing system state information, estimating the digital twin (DT) of the cyber twin and PWR human actions, maximizing user utility via the GT-PCO module, and updating the system with optimal task offloading and resource allocation. This approach enhances automation, accuracy, safety, and efficiency in NPP operations."}, {"title": "A. PGM for Digital Twining of Human Actions Procedures", "content": "The DT-HA model aims to align the DT and HAs/system states accurately. The DT-HA model mirrors operator actions, adhering to standards and historical data for predictive insight. System feedback tracks plant responses, and environmental variables consider external factors. Problem P is reformulated as follows to address the DT-HA problem:\nP1: $min_{h\\epsilon H} \u03b4(yn, fh)$\ns.t. (12f), $\u2200h \\epsilon H, yn \\epsilon D$. (13)\nwhere d(yh, fh) represents the discrepancy function that quan- tifies the difference between the current state yn of the DT and the state predicted by the HAs fh. The P\u2081 problem aims to estimate the expected state due to HAs while minimizing the discrepancy with the actual DT state, adhering to the operational and safety guidelines. Solving P\u2081 identifies the optimal HAs and system configurations that enhance system performance while maintaining the accuracy of the DT.\nNext, P\u2081 is translated to a PGM, where the DT of the NPP uses this model to generate experimental data for calibration and performance evaluation. The calibrated DT operates along- side the physical asset, assimilating the sensed data to update its internal models.\nThe PGM for the DT, proposed by Kapteyn et al. [28], considers the physical asset and its DT, evolving through time. The DT estimates the current and future states of the physical asset based on observational data, providing optimal control inputs to direct the physical asset to the desired states.\nThe proposed model uses six variables: the physical state St, observable data Ot, digital state Dt, control inputs Ut, quantities of interest Qt, and reward Rt. These variables represent the state of physical assets, parameters defining DT models, available information on the physical asset state, actions influencing the digital asset, estimated parameters via model outputs, and the overall performance of the asset-twin system, respectively.\nThe PGM represents the asset-twin system structure by encoding the interaction and evolution of these quantities. The PGM covers the data-to-decision flow from sensing to action. The conditional independence structure of the model allows the factorization of the joint distributions over model variables.\nThe system is modeled using a dynamic Bayesian network with decision nodes, representing the system from the initial time step t = 0 to the current time step t = te and future time step t = tp. The graph nodes are random variables denoting each quantity at discrete time points, with uppercase letters representing variables and lowercase letters denoting their values Dt ~ p(dt). The graph edges encode dependencies between variables via conditional probabilities or deterministic functions.\nThe time evolution of the physical asset states St ~ p(st) is defined as {St} = {S0, S1, S2, S3, S4}, where S0, S1, S2, S3, S4 represent the reactor coolant system filling and venting, cold shutdown, hot shutdown, hot standby, and power generation, respectively. The corresponding digital state Dt ~ p(dt) is given as {Dt} = {D0, D1, D2, D3, D4}. The interaction between the physical asset and its DT is facilitated through the information flow. The information flow in the form of observational data ot, from physical assets to its DT, updates the corresponding digital state in the process. The quantities of interest Qt ~ p(qt) are computed by the updated DT model. For our scenario, the Qt = Ot, reflecting interest in all observable data for system operation. The digital state and computed quantity of interest control the input ut from the DT to the physical asset. The reward for the time step Rt ~ p(rt) is determined by all these quantities. The graphical approach enables defining known or assumed conditional independence. The model encodes the physical and digital state based on the Markov assumption observable through the data. By exploring the conditional independence, the joint distributions over variables can be factorized in the model as follows:\n$P(0_0, . . . , 0_{tc}, . . . , U_0, . . . , U_{tc}) = \\prod_{t=0}^{te} \\Big[ P_{update Qol}(D_{t} | D_{t-1}, U_{t-1} = U_{t-1}, 0_{t-1} = 0_{t}) \\prod_{t=0}^{t} P_{dynamics} (0_t) P_{evaluation} (D_t, U_t = u_t, 0_t = 0_t)\\Big] $ (14)\nwhere\n$P_{update} (D_{t-1}, U_{t-1} = U_{t-1}, 0_{t-1} = 0_{t}) = p(D_t | D_{t-1}, U_{t-1}= u_t)$, (15)\n$P_{dynamics}(0_t) = p(Dt)$, (16)\n$P_{evaluation} = p(D_t, Q_t, U_t = u_t, 0_t = 0_t)$. (17)\nThe state can be predicted for tp by extending the state to include the digital state, quantity of interest, and reward variable. The factors in 14 are conditional probability distri- butions characterizing interactions in the DTs, as suggested by [28]. The Bayesian inference algorithm uses this equation for asset monitoring, prediction, and optimization. A PGM is instantiated for the DT of a PWR NPP to optimize human operations and ensure safety. The PGM calibrates, operates, and updates models to reflect the current state of the NPP.\nThe NPP DT life cycle includes two stages: calibration and operation. The first stage calibrates the DT using the PGM for scalability and repeatability. The second stage involves deploy- ing the calibrated twin to monitor, predict, and optimize NPP operations, maintaining operational parameters. The physical state, S, of the NPP assets corresponds to the stages of GOPs during startup operation. These procedures and their states are captured by creating, calibrating, and evolving the DT"}, {"title": "B. Multisubsystem Computation Offloading Game", "content": "The multiuser computation offloading game can be de- fined as G = {M, (Sm)\u0442\u0435\u043c, (Um)mem, where Sm de- notes the set of offloading strategies for subsystem m, and Um(sm, 8(-m)) represents the utility function, consid- ering the set of offloading strategies. In addition, s-m = (81,..., 8(m-1), S(m+1),\u2026\u2026\u2026,SM) represents the offloading strategies of all subsystem except the mth, where each elects the most advantageous strategy that enhances its individual utility. The game is considered to achieve a state of NE when no subsystem can further improve its utility by altering its offloading choice.\n*Definition 1: A strategy s* = (s1,s2,...,s) is the NE of\nthe game G if it adheres to\nUm (sm, 8m)) \u2265 Um (sm, S-m)),\nVme M, Usm \u2208 Sm. (18)\nBased on [29], the game G is an EPG by formulating the potential function as follows:\n$\\phi(s) =\\sum_{M EM} \\Big[S_{m0} \\sum R_{m0} + (1 - S_{m0})\\sum_{jEK}S_{mj} R_{mj} + \\sum_{M' \\neq m}\\sum JEK R_{m\u2019j}\\Big]$ (19)\nwhere Rmj = gt(Tem \u2013 Tkcn) \u2013 \u0420\u0424jCm. For ease of proof, the expression (sm, 8(\u2212m)) is given as follows:\n$(s_m, S_{(-m)}) = \\sum_{MEM}R_{mo} + (1 - S_{mo})\\Big(\\sum JEK \\sum S_{mj}R_{mj} + \\sum_{m\u2019\\neq m} \\sum \\Big)\\Big],$\n(20)\nRemark 1: Game G with the potential function (s) is an EPG and capable of reaching an NE in a finite number of iterations.\nProof: See Appendix F"}, {"title": "C. Deep Double Q Network for Optimal Offloading Ratio and Resource Allocation", "content": "The joint optimization of the ORRA problem can be refor- mulated to maximize the utility as follows:\nP2: $min_{\\Phi,\\beta} \\sum_{MEM} P_j C_m \u2013 (T^{em} - T^{e2e})$\ns.t. (12c), (12d), $0 \u2264 \\Phi, \u03b2 \u2264 1, \\forall m \u2208 \u039c$. (21)\nFor any time slot (t + 1) given the user offloading request \u00b5(t+1), the optimal offloading ratio (t+1) and resource al- location \u1e9e(t+1) can be solved. However, \u00b5(t+1) is unknown due to the unknown user request transition probabilities. The DDQN is employed to capture the user request model and predict the optimal task offloading ratio and corresponding resource allocation of time slot (t + 1) based on the system state at slot t."}, {"title": "D. Game-Theoretic Offloading Framework", "content": "The game-theoretic offloading framework (Algorithm 1) solves the PCO decision problem (P) using the future optimal ORRA problem (P2) for efficient computation offloading under DT-HA constraint in (P1). The base station (BS) acts as the central hub in its operation, assimilating real-time data, such as connection statuses and subsystem strategies. Initially, service modules (subsystems) lean toward MEC offloading. However, as the iterations progress, the subsystem refines its offloading strategy based on feedback from the BS. This iterative exchange continues until the subsystem seeks no fur- ther updates, indicating an NE. The computational complexity of the game-theoretic offloading framework is represented as\nO(C1 \u00d7 N), where C1 is the iteration count for the DDQN."}, {"title": "IV. NUMERICAL RESULTS", "content": "A. Data-driven Calibration and Evolution of a Digital Twin Human Action Model\nThe data-driven approach uses a state-transition infinite state automation for DT capabilities, including monitoring, prediction, and optimization, ensuring continuous model im- provement. A PGM was employed to represent HAs in an NPP. The model calibration and updates reflect the state of the NPP based on HAs. The DT life cycle includes calibration and operational phases, enabling predictive simulation and autonomous operation according to the guidelines. In NPP operations, the physical state St evolves due to HAs, whereas the digital state Dt models these actions, accounting for subsystem differences. The critical system variables, such as the PL, RCT, RCP, SGP, SGL, and RP, are defined across various operational states, as listed in Table I. Intermediate values are computed using linear interpolation:\nS\n$X = X_1 + \\frac{s}{n}(X_{i+1} - X_i)$ (22)\nwhere xi and xi+1 denote values at states Si and Si+1, respectively, and s is the step out of n steps.\nThis interpolation creates a high-resolution dataset for smooth state transitions. State labels are adjusted based on RP values, enhancing the precision of the NPP DT in monitoring and controlling plant operations. Table II presents the control input mapping and estimated observable data.\nSGL, and SGP increase to 6, 76.6, and 100, respectively. The posterior is updated toP(D2 | D1, O2, Ut = u2). Steps t = 3 and t = 4 calibrate the hot standby and power generation stages. Here, the PL, RCT, and SGL were maintained at 50, 157, 76.6, and 100, respectively. The final stage signifies the energy production and plant operation beyond 2%, focusing on the power increase proportional to the energy production.\nOperation Phase. The calibrated DT is deployed with the NPP during the PWR startup following strict guidelines. This phase demonstrates how the PGM manages uncertainties from calibration and assimilation and extends the capabilities of the DT for planning, predicting, and evaluating human operations. At time steps t = 4 and 5, during power pro- duction, the model uses real NPP data to predict the control inputs, observable data, state, and reward accurately, enhancing system confidence. The DT determines the expected system state and control operations based on operational guidelines. Optimal control inputs are identified through the assimilation and evolution capabilities of the model. The DT dynamically estimates the operational state of the NPP by assimilating the observable data and adjusting the predictions, with the data for each time step described as subsystem readings. For each subsystem m, the observable data Ot at time t is given by the following:\n$O_t = Q_t = \\{O^{m}_{t}\\}^M_{m=1}$ (23)\nwhere M = 6 for simplicity.\nThe digital state update factor update signifies the digital state update at each time step given the previous digital state and control input at time t 1, and the current observable input data:\n$\\alpha^{update} \\approx \\frac {dynamics Assimilation }{0_t}$ (24)\nwhere\n$P^{dynamics} = P(St | St-1, Ut-1 = u_t)$ (25)\n$P^{assimilation} = P(Ot = ot, St)$ (26)\nThe DT update applies the Bayes rule to update the prob- ability distribution P(St | 01:t) given the new observation Ot:\n$P(St | 01:t) = \\frac{P(Ot | St)P(St | 01:t-1)}{P(Ot O1:t-1)}$ (27)\nThe model updates P(Ot = ot, St) using new observations, calculating the likelihood of observed data given the current state and updating the state belief accordingly.\nThe assimilation factor passimilation updates the subsystem parameter:\n$P(Ot | St) = \\prod^n_{i=1} [N(Ot[i]; \u03bc\u03b5, \u03c3\u03c4/\\sqrt{\u03ba}] $ (28)\nwhere N(x; \u03bc, \u03c3\u00b2) represents the normal distribution with mean \u00b5 and variance \u03c3\u00b2. These values are derived from the interpolated dataset, with as the adjusted scale factor (Ap- pendix D). The updated digital state and quantity of interest complete the reward via the evaluation factor evaluation. The reward function considers the control input, state transition, and observable data predictions to evaluate the performance of the DT-HA model.\nFor each control action ut, with a generalized probability P(ut) = 1 (where n is the total number of control actions), the control reward Rcontrol is as follows:\n$R_{control} = \\frac {1}{\u03ba} \u03a3_{i=1}^{k}f(\u03c8)$ (29)\nwhere k denotes the number of configurations, and f(4) is defined as follows:\n$f(\\vi) = \\begin{cases} 1-\\epsilon \\text{if }\\vi \\neq \\gamma_i, \\\\ - \\epsilon \\text{if } \\vi = 0 , \\\\ \\text{otherwise} \\\\ 1 \\end{cases} $ (29)\nwhere, e is a small penalty for zero probability, and represents the baseline probability. This function evaluates the deviation from the baseline probability, with penalties and adjustments ensuring effective control actions. The control reward Rcontrol averages these values, measuring the effective- ness of the control action.\nThe state transition reward (Rstate) for each step is calculated by comparing the derived probabilities to a baseline probability of 1.0:\n$R_{state} = \\frac{1}{\u03ba} \u03a3_{i=1}^{k}f(\u03c8)$ (30)\nwhere f() represents a piecewise function defined as fol- lows:\n$f(\u03c8) = \\begin{cases} 1-0.1 \\text{if } \\psi \\neq 1.0, \\\\ -1.0 \\text{if } \\psi = 0 , \\\\ 1.0 \\text{otherwise} \\\\ \\end{cases} $ (30)\nThis function evaluates the deviation from the baseline probability. If V is not 1.0, the absolute difference |1.0 \u2013 is used and if 4 is 0, a penalty of -1 is applied. Finally, if equals the baseline, 1.0 is added.\nThe observation prediction reward (Robs) for each step is calculated by comparing the derived probabilities to a baseline probability of as follows:\n$R_{obs} = \\frac {1}{\u03ba} \u03a3_{i=1}^{k}f(\u03c8)$ (31)\nwhere f(4%) is defined as follows:\n$f(\\vi) = \\begin{cases} - |\\psi -  || \text{if }\\psi \\neq \\alpha , \\\\ -0.1 \\text{if } \\psi = 0 , \\\\ \\text{otherwise} \\\\ \\alpha  \\end{cases} $ (31)\nThis function evaluates the deviation from the baseline probability. If 4 is not, the absolute difference | - | is used. If is 0, a penalty of -0.1 is applied, and if equals the baseline, is added.\nThis approach ensures that the reward calculations for control, state transition, and observation prediction are flexible and adaptable to various configurations.\nEvaluation. During the operational phase, the DT assimi- lates subsystem data, estimates power generation parameters, and responds with appropriate control inputs. The prediction probabilities of the DT for Dt, Ot, Ut, and Rt are considered.\nFig. 4 illustrates the transition probabilities of the DT for digital states Do to D3, representing the system cooling and venting, cold shutdown, hot shutdown and hot standby (Appendix A). These states mark the calibration phase, after which energy production begins. Beyond state D3, the DT predicts and applies control inputs for energy production during timesteps t\u2081 to tp.\nThe DT state prediction probabilities for Dt were eval- uated using three configurations: P(Dt | Dt\u22121), P(Dt |\nDt-1, Ut-1, Ot), and P(Dt | Dt-1, Dt, Ot). The first con- figuration uses only previous states. The second includes control inputs and current observations, and the third combines past and current states with observable data for comprehen- sive predictions. As depicted in Fig. 4, the DT prediction confidence increases as more data are assimilated. During calibration, probabilities stay below 0.05, indicating initial low knowledge. As operational data are assimilated, the confidence and accuracy of the DT improve, reaching beyond a probability of 0.15.\nNext, the observation prediction probabilities of the DT are evaluated using five configurations: P(Ot | Dt), P(Ot | Dt-1, Dt), P(Ot | Dt-1, Dt, Ot), P(Ot | Ot-1, Dt), and P(Ot+1 Dt+1, Dt). These configurations assess predictions based on the current state, previous and current states, states with current observations, previous observations with the cur- rent state, and future observations based on state transitions, respectively. These configurations monitor the prediction ac- curacy of the DT and demonstrate the system's evolution with data assimilation (Appendix C).\nDuring calibration, the digital state remaining in its current state versus transitioning to the next state is considered. As presented in Fig. 5(a), the model initially has low probabilities for transitioning due to the limited data at calibration. Despite this, the transition probability is higher than remaining in the current state. Beyond calibration, as more data are assimilated, the probabilities for transitioning to the next state increase, improving accuracy.\nIn the prediction evaluation in Fig. 5(b), the model pre- diction confidence improves with increased data assimilation."}, {"title": "Scenarios", "content": "Scenarios P(Ot | Dt, Dt+1, Ot+1) and P(Ot+1 | Dt+1, Dt) exhibit higher probabilities and better accuracy. Conversely, P(Ot+1 | Dt+1, Dt, Ot,Ut) maintains a low probability beyond 2% operation, suggesting overfitting. Thus, except for P(Ot+1 | Dt+1, Dt, Ot, Ut), prediction probabilities signifi- cantly improve beyond 2% operation, indicating the enhanced predictive ability of DTs with more data assimilation, reflect- ing system evolution.\nFurthermore, we evaluate the control input calibration prob- abilities for each control input and the next state (Appendix B). The DT intelligently determines the required control input for all transitions, as illustrated in Fig. 6(a). The control input with the highest probability is activated, ensuring the correct action is triggered to drive the system to the next required state. For the control input prediction probabilities, we consider six configurations: P(ut | St\u22121, St), P(ut | St), P(ut | St-1, St, Ot), P(ut | St, Ot), P(ut | St\u22121, St, Ot), and P(ut | St\u22121, St, Ot\u22121). These configurations assess the influence of the control actions based on the state transitions, next state predictions, states with observable data, and past observable data. Fig. 6(b) presents the activated control inputs over state transitions during prediction. During the operation phase, the DT accurately issues the necessary control actions, maintaining a control input of 5 for energy prediction from t\u2081 to tp.\nFig. 7 presents the reward evaluation. The control reward values (Rcontrol) are low and steady, with a noticeable de- crease at transition 9 before normalizing, indicating occasional low reward but generally moderate uncertainty in predicting control actions. Although the model displays potential for automation, human oversight remains necessary. The observa- tion reward (Robs) values are also moderate, with noticeable changes at transitions 6 and 9, followed by normalization. This finding indicates a stable prediction accuracy for observable data with occasional uncertainty. The model reliably predicts general trends, which is crucial for operational monitoring. Minor variations suggest some variability but overall robust performance. The state reward values (Rstate) are consistently high, peaking around transitions 7 to 9. This demonstrates excellent predictive accuracy for state transitions, making the model dependable for monitoring and planning.\nThe DT model indicates a strong potential for state repli- cation, with moderate success in control and observation predictions. Although the state predictions are highly reliable, the control and observation predictions require refinement for improved accuracy."}, {"title": "B. Performance Evaluation of the Game-theoretic Offloading Framework", "content": "This section presents the numerical results and analysis of the simulation to evaluate the performance of the proposed model. The C-MEC network is considered, where the subsys- tem is randomly distributed in 200 m \u00d7 200 m area with [4, 12] subsystems, [1,10] COIN nodes, and an ES. The large-scale fading from the mth subsystem to the kth AP is modeled as $gm = 10^{(-\\frac {PL(mk)}{10})}$ with path loss PL(dmk) =-35.3 37.6log10(dmk) =-35.3 \u2013 37.6 [24]. The spectral density of the noise is set to -174dBm/Hz [30], and the bandwidth is set to 10 MB. The URLLC decoding error probability is \u20ac = 10-9. Table IV provides additional parameters.\nTo verify the effectiveness of the proposed method, we eval- uated the proposed approach against the following baselines:\n\u2022 The proposed scheme (DDQN-EPG) employs the DDQN to predict the future optimal ORRA in a game-theoretic framework based on an EPG to maximize the user utility in a C-MEC network.\n\u2022 The EPG with random ORRA (EPG-Rand) strategy is based on randomly predicted future ORRA. This baseline offers insight into the overall future system performance when the DDQN is not applied.\n\u2022 The MEC baseline is the conventional MEC network with no COIN capabilities enabled, in which the subsystem can perform the task locally or offload it to the MEC. This baseline allows for a direct comparison between the proposed COIN approach and the standard MEC baseline, highlighting the performance improvement.\nTo ensure a fair performance comparison, we conducted a comprehensive analysis of various aspects. The evalua- tion involved comparing the average system utility across training episodes against the benchmark scenarios. Except for Episode 5, the proposed model consistently achieved the highest average system utility, as presented in Fig. 8(a). In a few episodes, the proposed scheme attains 20% utility over the baseline, demonstrating an effective offloading ratio and resource management via the DDQN.\nFurthermore, the effectiveness of the proposed system model was evaluated by investigating the influence of data- intensive and computationally intensive computing types. For data-intensive tasks (Tasks 1 to 3), the input size (Im ) and required CPU cycles (Cm) of the tasks were uniformly and randomly generated from the ranges of [10-20] MB and [0.1- 0.5] GB, respectively. In the computationally intensive task type, Im and Cm were uniformly and randomly generated from the ranges [1-5] MB and [1-2] GB, respectively. Considering the average system utility, the proposed model consistently outperformed the others, with an increase of 43.0% to 87.9% for data-intensive tasks (1-3) and 36.2% to 87.7% for com- putationally intensive tasks (4\u20136) compared to the second-best MEC model, as presented in Fig. 8(b).\nNext, we evaluated the performance of the proposed model by investigating the influence of varying the numbers of pieces of subsystem and COIN nodes. For subsystem numbers, the proposed method consistently demonstrates superior utility and effectiveness in Fig. 9(a), underscoring a remarkable 47% increment in utility compared to the baselines. Notably, an increase in subsystem beyond six resulted in an overall reduction in the average system utility. Per the COIN node numbers in Fig. 9(b), the proposed model excels with a sig- nificant 64% improvement over the baselines for between five and eight COIN nodes. Although the EPG-Rand significantly improves beyond eight COIN nodes, the proposed model maintains improved performance, underscoring the ability of the proposed approach to enhance the OPG algorithm, making it more efficient for increasing COIN-enabled nodes."}, {"title": "V. CONCLUSION", "content": "This paper investigated integrating DTs for HA (the DT- HA model) with PCO in a 6G-powered C-MEC environment. We proposed a decentralized game-theoretical approach to minimize the PCO latency by optimizing offloading decisions, ratios, and resource allocation. A PGM captured the intricacies of the DT-HA model, guiding HAs through observable data and control inputs. Offloading decisions were modeled as a strategic game, determining the subsystem utility under HA constraints. A DDQN refined the ORRA. The proposed approach effectively captures complex HAs while optimizing resource allocation, ensuring safe and efficient NPP operations. Future work will explore precise control actions from various NPP subsystems under practical operations, enhancing the robustness and applicability of the proposed method while addressing control complexity and security threats."}, {"title": "APPENDIX", "content": "A. State Transition Probabilities\nState transition probabilities define the likelihood of transi- tioning from one state to another represented in matrix form where each entry P(St+1 = j | St = i) denotes the probability of moving from state i to j.\n$\\underline{S_t} = \\begin{bmatrix}  0.4 & 0.6 & 0.0 & 0.0 & 0.0 & 0.0 & ... & 0.0 & 0.0 \\\\  0.0 & 0.4 & 0.6 & 0.0 & 0.0 & 0.0 & ... & 0.0 & 0.0 \\\\  0.0 & 0.0 & 0.4 & 0.6 & 0.0 & 0.0 & ... & 0.0 & 0.0 \\\\  0.0 & 0.0 & 0.0 & 0.4 & 0.6 & 0.0 & ... & 0.0 & 0.0 \\\\  0.0 & 0.0 & 0.0 & 0.0 & 0.4 & 0.6 & ... & 0.0 & 0.0 \\\\  0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.4 & ... & 1.0 & 1.0 \\\\ \\end{bmatrix} $\nB. Control Input\nThe control input distribution Ut assigns equal probabilities to each possible control action. The control input distribution Ut is defined as follows:\n$P(U_t = u_i) = \\frac {1}{n\u2019}$ , i\u2208 {0, 1, 2, ..., n \u2212 1},\nn\u2208N (total number of control actions).\nGiven the control actions, the conditional probability table for control input P(Ut | St\u22121, St) can be generalized as follows: For St-1 = (i, i) where i = 0, 1, 2, 3, 4, 5:\n$P(U_t | (i, i), S_t) = \\begin{cases} 0.4 \\text{if } S_t = (i, i) \\\\ \\text{if } S_t = (i, i + 1) \\\\ 0.6 \\end{cases}  \\land U_t = u_i \\\\ \\land U_t = u_{i+1}$", "label": "U0I"}, {"title": "The PCO", "content": "For St-1 = (i, i + 1) where i = 0, 1, 2, 3:\n$P(U_t | (i, i+1), S_t) = \\begin{cases} 0.4 \\text{if } S_t = (i, i + 1) \\\\ \\text{if } S_t = (i + 1, i + 1) \\\\ 0.4 \\end{cases}  \\land U_t = u_{i+1} \\\\ \\land U_t = u_{i+1}$", "label": "If"}, {"title": "If", "content": "For St-1 = (4,5):\n$P(U_t | (4,5), S_t) = \\begin{cases} 0.4 \\text{if } S_t = (5,5) \\\\ \\land U_t = U_5 \\end{cases} $", "label": "St"}, {"title": "We", "content": "For St-1 = (5,5):\n$P(U_t | (5,5), S_t) = \\begin{cases} 1.0 \\text{if } S_t = (5,5) \\\\ \\land U_t = U_5 \\end{cases} $\nThis representation captures the probabilities of control actions given the previous state St-1 and current state St. Any combination not listed has a probability of 0.\nC. Observable Data Transition Probability\nWe let Ot represent the observable data at time t. Each Ot consists of six key parameters: the PL, RCT, RCP, SGP, SGL, and RP. The probability distribution of the observable data Ot is represented as follows:\n$\\begin{cases} \\frac {1}{n_0} \\text{if } O_t \\in \\{0_0, . . ., 0_4\\}, \\\\ \\text{if } O_t \\in \\{0_5, . . ., 0_p\\}, \\\\ \\end{cases} $", "label": "Then"}, {"title": "We", "content": "P(Ot) = \\begin{cases} \\frac {1}{n_0}f(O_t)  \\\\ \\frac {\\sum _{k > 4} (0k)}{n_0}f(Ok)\\\\ \\end{cases}\nwhere no = 6. The first condition applies during calibra- tion, and the second condition applies beyond state 4 in the operational phase based on design needs. Each Ot at time t includes parameters such as PL, RCT, RCP, SGP, SGL, and RP, with probabilities reflecting system specifications. For instance, the probability of observing [100, 60, 27, 1, 100, 0] is\n Irrelevant observable data can be set to 0."}, {"title": "D. Scaling Factor", "content": "The scaling factor (K) in NPP operations quantifies un- certainty at various operational stages. In the initial states (St = (0,0) and St = (0,1)), the scaling factor is higher (3.5 and 2.5), reflecting greater uncertainty. As the system transi- tions to the intermediate states (St = (1,2) and St = (2,3)), the scaling factor decreases (2.0 and 2.5), indicating increased stability. In more stable states (St = (3,4)), the factor reduces to 1.0. At high power levels (St = (5,5) to St = (5,10)), the factor is 0, reflecting minimal uncertainty. This sequential adjustment captures the dynamic uncertainty across different operational stages of the NPP."}, {"title": "E. Dynamic Estimation", "content": "1) Planning and Optimal Control: At each time step, the DT of the NPP selects optimal control inputs in response to evolving operational conditions. For instance, maintaining the optimal reactor temperature and safe SGP levels can be formulated as a planning problem. In another instance, the DT can ensure safe operation by adjusting the control rod positions dynamically to balance the power output and fuel usage of the reactor. The segment from the current time step te to a future time step tp can be viewed as a partially observable MDP. The goal is to select control inputs utc,..., Utp that maximize the expected future reward. The control policy \u03c0maps from the current belief over the entire history to a control action, as follows [28]:\n$u_t = \u03c0 (p(Do, ..., D_t, Q_0, ..., Q_t | 0_0,..., 0_t, U_0, ..., U_{t-1}))$. (32)\nThe objective is to determine a policy that maximizes the expected accumulated reward:\n$\\pi^* = arg max_{\\pi} \\sum (\\gamma^{t-t_{c-1}}) E[R_t]$, (33)\nwhere \u03b3\u2208 [0,1] denotes a discount factor.If state estimates are accurate, the partially observable MDP is approximated as a fully observable MDP. The expected policy is\nut = \u00f1(d, \u011d), (34)\nwhere d and \u011d represent the best estimates of the current state and quantities of interest. This problem is solved off-line using the value iteration algorithm. The reward function is\nRt(ut, qt) = Rstate (qt) + Rcontrol (Ut) + Robs(Ot), (35)\nwith a discount factor y = 0.6.\n2) Extension to Prediction: The NPP DT formulation is extended to include prediction over future time steps. The prediction regime spans from the current time step, te, to a chosen prediction time step, tp, in the PGM. The target belief state is expanded to predict the digital state, quantities of interest, and reward variables up to the prediction horizon, tp, as follows [28]:"}, {"title": "TP", "content": "$\t P(D_0, . . . , D_{tp}, Q_0, . . . , Q_{tp}, R_0, . . . , R_{tp},  \\text{1-2} + (1 - 2 + ... + ) -\\int \\begin{cases} 1/x & d/dx \\\\ \\end{cases}\nU_{tc+1},..., U_{tp} | 0_0,..., 0_{tc}, U_0,\n.., U_{tc})\n \\prod_{tp}^{t_c} P^{dynamics Qol}_{t}  \\prod_{tp+1}^{t_{Assimilation}} \\phi^{Evaluation}_{Pt}\n* \\\n *P*^{control}_{(36)}\nThe additional required term is the control factor, control, defined according to the control policy as\n$P(ut | dt, qt) = \\begin{cases} 1  \\text{if } \\pi(dt, qt) \\\\\\  Otherwise \\end{cases} $\nThis expression represents the probability of selecting a control action ut given the state dt and quantities of interest qt. The policy (dt, qt) determines the optimal control action. If the selected control action ut matches the policy (dt, qt), the probability p(ut | dt, qt) is 1; otherwise, it is 0. This approach ensures that only the optimal control action has a nonzero probability. In the prediction regime for t = tc + 1,..., tp, the data assimilation factor is omitted and not conditioned on Ot = Ot because future data of are not yet observed. These adjustments and additional control factor enable seamless prediction and monitoring in a single pass of the sum-product algorithm."}, {"title": "F. Proof of Remark", "content": "F. Proof of Remark 1\nThe PCO computation offloading game is formulated un- der DT-HA constraints for the decision-making process of subsystems regarding whether to offload tasks. Based on the definition of EPG in [29], the game G should satisfy the following condition. Subsystem m is considered, which alters its strategy to demonstrate that this game is an EPG and achieves NE as follows:\n$| 0 (t < n) \\text{ if } i = 1,\\\\ 0 \\text{ otherwise.}  \\\\\\end{cases} $ (37)\nFor ease of proof, the expression (sm,8m) is given as follows:\n$(Sm,S-m) = Sm0 \\sum_{MEM}R_{mo}+ \\Big((1-Sm0)(\\sum JEKS_{mj}R_{mj}+ \\sum R_{m\u2019o}) \\Big)$ (38)", "label": "So if"}, {"title": "The", "content": "The relationship between $(sm,8-m) \u2013 $(S'm, 8-m) and Um($m,S-m) - Um (sms-m) is discussed in two cases as follows.\nCase 1: Transitioning from MEC (i.e., Sm0 = 1) offloading to CN nodes (i.e., Smj = 1). Using Eq.38, we deduce that\n$Sm\\frac { (Sm0, s-m- (Smj + s + m} = \u03a3R(mo)\\\\\n|\\\nMEM\n\u2211 R(m\u2019o) \u2013\\\\\nREL\\\n-Sum((s\u201d+mm\")U\u201d+(sm\u2019\u201dsm) (39)\nHence, (39) is established in this case.\nCase 2: Altering strategies only in the CN environment (i.e., from CN j to another CN j'), we have:\n$\\frac {sm}{k} > n \\frac {sm}{m+s\u2019 = Kmj>km'n\u2019k)  -km\u2019) (40)\nThus, (40) is established in this case.\nEquation (38) is established in any case from the above derivations. Hence, game G is an EPG and attains NE in a finite number of iterations.\"\n    }"}]}