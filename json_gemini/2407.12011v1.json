{"title": "Digital Twinning of a Pressurized Water Reactor Startup Operation and Partial Computational Offloading in In-network Computing-Assisted Multiaccess Edge Computing", "authors": ["Ibrahim Aliyu", "Awwal M. Arigi", "Tai-Won Um", "Jinsul Kim"], "abstract": "This paper addresses the challenge of representing complex human action (HA) in a nuclear power plant (NPP) digital twin (DT) and minimizing latency in partial computation offloading (PCO) in sixth-generation-enabled computing in the network (COIN) assisted multiaccess edge computing (MEC). Accurate HA representation in the DT-HA model is vital for modeling human interventions that are crucial for the safe and efficient operation of NPPs. In this context, DT-enabled COIN-assisted MEC harnesses DT (known as a cybertwin) capabilities to optimize resource allocation and reduce latency effectively. A two-stage approach is employed to address system complexity. First, a probabilistic graphical model (PGM) is introduced to capture HAs in the DT abstraction. In the PGM, HA and NPP asset-twin abstractions form coupled systems that evolve and interact through observable data and control input. Next, the underlying PCO problem is formulated as a multiuser game, where NPP assets can partially offload tasks to COIN and MEC. We propose a decentralized algorithm to optimize offloading decisions, offloading ratios, and resource allocation. The simulation results demonstrate the effectiveness of the proposed method in capturing complex HAs and optimal resource allocation in DT-enabled NPPs.", "sections": [{"title": "I. INTRODUCTION", "content": "ADVANCES in communication, artificial intelligence, and computing have been driving the digital transformation of nuclear power plants (NPPs). These developments have contributed to the emergence of digital twinning that replicates physical objects and their surroundings [1]. Enabling digital twins (DTs) in NPPs enhances energy efficiency, enabling predictive maintenance, autonomous control, and safety analysis [2].\nIn NPPs, human tasks/operations, such as pressurized water reactor (PWR) startup operations, include reactor operations, refueling, maintenance, shutdowns, and chemical control, which can be continuous or periodic. Digital twinning is essential for representing these processes accurately [3]. An accurate DT representation of human actions (HAs) is crucial for their impact on physical processes, safety measures, and critical event responses. The human-machine interface is also vital, covering interactions in control rooms, remote monitoring, diagnostic centers, and field devices.\nImplementing a DT system in NPPs requires a diverse computing and communication infrastructure, from clusters to handheld devices [4]. Sixth-generation (6G) ultra-reliable and low-latency computing (URLLC) capabilities are crucial for mission-critical DT applications [5], and the computing in the network (also known as In-network computing, COIN) paradigm leverages network resources to minimize latency and enhance the quality of service [6]. Integrating a DT with these technologies offers opportunities and challenges for enhancing NPP reliability, availability, and maintainability at reduced costs."}, {"title": "A. Related Work", "content": "1) Digital Twinning of HAs in NPPs: The DT is applied in various industries, including health, meteorology, education, manufacturing, transportation, energy, and business [7], [8]. In the nuclear industry, DT adoption is limited due to high safety and security standards [3]. Nonetheless, research on DT adoption in nuclear systems has increased, focusing on technical challenges [9], [10], [11], safeguards and security [12], applications for advanced reactors [13], [14], and specific applications, such as flow-induced vibration prediction [15]. However, the consideration of HAs and procedures in DT remains largely unexplored.\n2) DT-enabled Task Offloading: The COIN paradigm min- imizes latency and improves the quality of experience using untapped network resources [16], but may increase power consumption, creating a trade-off between delay and energy use. In this context, Partial subtask offloading is essential, especially when COIN coexists with edge computing solutions. Furthermore, digital twinning has been transforming"}, {"title": "B. Motivation and Contributions", "content": "The power startup scenario of an NPP involves increasing the reactor power (RP) to full capacity, requiring constant monitoring and complex manipulations due to disabled automatic and safety functions. Unlike standard full-power operations, this scenario demands more decision-making and poses a higher risk of human error due to changing system parameters and potential instability [4], [3]. Although artificial intelligence techniques have been studied for NPP control, these techniques have not addressed adapting the current systems for DT applications.\nPCO is ideal for NPPs, as it efficiently distributes tasks across COIN nodes (CNs) and edge servers (ESs), balancing latency and energy consumption through partial offloading [23]. This approach enhances overall system performance and operational safety by leveraging sensor data and factory monitoring to detect unusual HAs and support DT solutions.\nMotivated by the aforementioned issues, this study focuses on the complex representation of human actions (HAs) within digital twins (DTs) while minimizing latency in partial computational offloading (PCO) within a 6G-powered COIN-assited MEC(C-MEC). Accurate representation of HAs in DTs is crucial for modeling human interventions that are vital for safely and efficiently operating NPPs. This work is the first to explore the digital twinning of HA in NPPs alongside the underlying DT-based network resource allocation problem in a collaborative C-MEC architecture. The primary contributions include the following:\nWe formulate the system utility maximization problem, jointly optimizing the digital twinning of HA-related PWR operations and resource allocation in the C-MEC, solving the problem in two stages.\nIn the first stage, we apply a PGM to capture the intricacies of HAs in the DT abstraction, creating an interconnected system that evolves and interacts via ob- servable data.\nIn the second stage, we formulate the PCO problem as an exact potential game (EPG) and theoretically prove the existence of a Nash equilibrium (NE).\nWithin the game, we formulate the offloading ratio and resource allocation (ORRA) problem as a Markov deci- sion process (MDP) and employ the DDQN to predict and maximize future system utilities proactively.\nWe conduct extensive experiments to evaluate the proposed digital twinning of the PWR operation and the underlying C-MEC-based network."}, {"title": "II. SYSTEM MODEL", "content": "This section presents the system model from the HAS and procedures and the COIN-assisted URLLC-based edge network. In addition, the problem emanating from the complex interaction of the two models is formalized. Fig. 1 illustrates the block diagram of the studied system, consisting of the DT- HA model and C-MEC services in which DT jointly optimised NPP HAs and C-MEC resources. The main notations used in this paper are summarised in Table I"}, {"title": "A. Human Actions and Procedures in Digital Twin Nuclear Power Plants", "content": "1) Analysis of PWR startup operations: This study focuses on the startup operation of a typical Westinghouse three-loop PWR, following the general operating procedures (GOPs) [3]. The key GOPs include reactor coolant system filling and venting, cold shutdown, hot shutdown, hot standby to 2% RP, and power operation and secondary system heat up and startup.\nThe critical part of the startup operation involves increasing the NPP power from 2% to 100% and transitioning the plant to normal conditions for electricity generation. Six major parameters serve as milestones: the pressurizer level (PL), reactor coolant temperature (RCT), reactor coolant pressure (RCP), steam generator (SG) pressure (SGP), SG level (SGL), and RP. These parameters are considered subsystems requiring communication and computing resources to operate.\nBefore reaching 2% power, five GOPs are completed. After reaching 2% power, only two GOPs are necessary: power operation greater than 2% and secondary system heat up and startup. The former provides instructions for increasing the plant load from 2% to 100%, whereas the latter details steps for aligning and starting secondary systems. These procedures involve operating the rod controller, turbine load controller, feedwater (FW) pumps, condenser pumps, SG FW valves, and a synchronizer based on the planned rate of power increase."}, {"title": "2) Operator Task DT Model", "content": "Accurately representing operator activities is crucial for ramping up power to 100%. Human tasks are grouped into monitoring, decision-making, discrete control, and continuous control. The DT-HA model captures operator actions digitally, ensuring consistency and safety. An action profile lists the potential actions with likelihoods based on historical data. Environmental variables account for external conditions, highlighting interactions between the guidelines and such factors as temperature or noise.\nDefinition 1: In the context of the proposed NPP model, the actions of each operator in the DT must precisely mirror real- world actions. For every operator action denoted as h from a set of possible actions H, the state of the DT, represented by yh, is governed by the following relation:\n$Y_h = f_h(S, A), \\forall h \\in H$\nwhere S and A represent the state/condition of the physical system and HA or decision-making in the system, respectively. Equation (1) ensures that the DT adheres to the operational guidelines, maintaining the highest standards of safety and operational accuracy."}, {"title": "Definition 2", "content": "The general NPP operational constraint must be satisfied to ensure compliance with operational and safety regulations, preventing actions that could jeopardize NPP safety:\n$O_S(P_p, T_c, P_c, P_s, L_s, P_r)\\times S_S(P_p, T_c, P_c, P_s, L_s, P_r) = 1$\nThe constraint ensures that all decisions align with the opera- tional safety and procedural requirements of the NPP. This expression states that the operational and safety constraints must be satisfied for any given configuration of tasks, resources, and HAs. If either Os or Ss is 0 (i.e., its respective constraints are not met), then the entire operation becomes 0, indicating that the configuration is invalid."}, {"title": "B. COIN-assisted URLLC-based Edge Network Model En- abling NPP DT", "content": "The C-MEC network architecture system model is illus- trated in the lower part of Fig. 1. The model consists of a physical layer comprising subsystems which represent the six major NPP subsystems and network resources, such as COIN- enabled CNs and the ES. This network infrastructure supports the operation of DT services by optimizing resource allocation, enabling the entire system via a real-time interaction mecha- nism.\nWe let $M = \\{1,2,..., M\\}$ be a set of M subsystems, $K = \\{1,2,..., K\\}$ be a set of K COIN CNs, and R be the ES. The CNs and ES are associated with an access point (AP) to connect the subsystems. Further, URLLC short packet communication is employed between the subsystems and APs to ensure exceptionally reliable performance and low latency on the Internet of Things. The system model is as follows:\n1) Offloading Model in the C-MEC Network: Regarding the time slot model, the subsystems and CNs are fixed within each time point and vary over different time slots. At each time slot t, each subsystem has a computational task characterized by $J_m = \\{l_m, T^{max}_m\\}$, where $l_m = \\frac{C_m}{\\varphi_m}$ represents the task complexity (cycle/bits), Im denotes the task size in bits, Cm indicates the required CPU cycles (cycles) to execute the task, and $T^{max}_m$ is the maximum tolerable latency for task Jm.\nThis scenario focuses on partial offloading to use parallel processing for latency reduction. We let $\\Pi = \\{\\lambda_{mk}, \\eta_m\\}$ be the offloading ratio variable, where $\\lambda_{mk}$ denotes the portion executed at the CNs, and $\\eta_m = 1 - \\sum_{k \\in K} \\lambda_{mk}$ represents the portion of the task executed at the ES. Offloading resources are"}, {"title": "C. Communication Model", "content": "The AP, with L antennas serving M single-antenna SMS, establishes channel connections with compute resource L represented by $h_{ml} = \\sqrt{g_{ml}}h_{ml}$, where $g_{ml}$ is the large-scale channel coefficient and $h_{ml}$, is small-scale fading following CN(0, I), where CN(.,.) represents a complex circularly symmetric Gaussian distribution.A channel ma- trix $H = [h_{1l}, h_{2l}\u2026\u2026\u2026, h_{Ml}] \\in C^{LX M}$ contains connections from m-th subsystems to the l-th AP. Each subsystem has an allocated bandwidth, bm. Match filtering and successive interference cancellation is employed to improve transmission performance [25]. Then, the signal-to- interference-plus-noise at the l-th AP by the m-th subsystem is defined as $\\gamma_{ml} (P, N) = \\frac{P_{ml} ||h_{ml}||^2}{I_{ml} (p,n)+N_0}$, where $P_{ml}$ denotes the transmission power of the m-th subsystem, $N_0$ denotes noise power, $p = [P_{m1}]^{M}_{m=1}$, and $I_{ml} (p, n) = \\sum_{n=1}^{M} P_{n1} ||h_{nl}||^2$ represents the interference imposed"}, {"title": "D. Computational Model", "content": "In the computational model, each subsystem generates a granular computation task Jm in which a portion can be executed by the CNs and another portion at the ES. The model is defined as follows:\n1) COIN Node Processing: For the COIN node, the task Jm portion $\\lambda_{mk}$ is executed by CNs with the estimated processing rate $\\phi^{cn}_k$. Thus, the estimated CN execution latency is as follows:\n$T^{cn}_{mk} (\\lambda_{mk}, \\phi^{cn}_k) = max_{k \\in K} \\frac{\\lambda_{mk}C_m}{\\phi^{cn}_k}$\nIf the discrepancy between the actual kth CN and its DT can be predetermined, the gap in computing latency between real-world performance and DT predictions can be estimated as follows:\n$\\Delta T^{cn}_{mk} (\\lambda_{mk}, \\phi^{cn}_k) = \\frac{\\lambda_{mk}C_m \\phi^{cn}_k}{\\phi^{cn}_k (\\phi^{cn}_k - \\phi^{cn}_k)}$\nThus, the actual CN processing time is $T^{cn}_{mk} = \\Delta T^{cn}_{mk} + T^{cn}_{mk}$. The total latency, including the transmission and computing latency is\n$T^{cn}T_m = T^{cn}_{mk}+T_{ml}^L$\n2) MEC Processing: The task Jm portion $\\eta_{m}$ executed by the ES with the estimated processing rate of $\\phi^{es}_m$ incurs the following latency:\n$T^{es}_m (\\eta_{m}, \\phi^{es}_m) = \\frac{\\eta_{m}C_m}{\\phi^{es}_m}$\nThe latency gap $\\Delta T^{es}_m$ between the real latency and the DT is estimated as follows:\n$\\Delta T^{es}_m (\\eta_{m}, \\phi^{es}_m) = \\frac{\\eta_{m} C_m \\phi^{es}_m}{\\phi^{es}_m (\\phi^{es}_m - \\phi^{es}_m)}$\nThus, the actual latency for task execution at $\\phi^{es}_m$ $T^{es}_m = \\Delta T^{es}_m + T^{es}_m$. The total delay at MEC is\n$T^{es}T_m = T^{co}_{ml} + T^{es}_m$"}, {"title": "E. Problem Formulation", "content": "We let $S_m = \\{s_{m0}, s_{m1},s_{m2},...,s_{mK} | s_{mj} \\in \\{0,1\\}\\}$ denote the offloading strategies for subsystem m. The offload- ing strategy profile of all subsystems is denoted as $s = \\{s_m | s_m \\in S_m,M\\in M\\}$, where $s_{mj} = 1$ suggests that subsystem m accomplishes its task via decision j, otherwise $s_m = s_{m0} = 0$. $s_{m0}$ indicates the decision variable for task execution at the ES while $s_{mk}$ are executed at the CN k. From the subsystem perspective, we define the subsystem mutility as the difference between the reduced latency due to offloading and the computational cost as follows:\n$U_m = \\sum_{j \\in K\\cup \\{0\\}} s_{mj}[g_t (T^{es}_m - T^{e2e}) - P_jP_jC_m]$\nwhere gt is the unit gain latency reduction and pj is propor- tional to computing capacity, indicating offloading cost per workload at node j.\nThe primary objective is to maximize the system utility by minimizing the overall system latency, considering HAs and task offloading. The problem formulation is as follows:\nP: $max_{\\varsigma,\\Phi,\\beta, H} \\sum_{MEM} U_m$\ns.t. $\\sum_{j \\in K\\cup \\{0\\}} s_{mj} \\leq 1$\n$\\sum_{MEM} s_{mj} \\leq 1$\n$s_{mj}T^{e2e} < T^{max}_m$\n$\\sum_{MEM} \\beta_m \\leq 1$\n$Y_h = f_h(S, A), \\forall h \\in H$\n$O_S(P_p, T_c, P_c, P_s, L_s, P_r.)\\times S_S(P_p, T_c, P_c, P_s, L_s, P_r) = 1$\n$s_{mj} \\in \\{0,1\\},0 < \\Phi, \\beta \\leq 1,\\forall h \\in H, y_n \\in D, \\forall m\\in M, j\\in K\\cup \\{0\\}$\nConstraint (12a) ensures each task is partially offloaded to at most one node. Constraint (12b) manages the associations be- tween the subsystem and COIN node. Constraint (12c) enforce latency requirements and (12d) ensures resource allocation is within CN capacity. Constraint (12e) ensures the DT state matches the current system and HAs and (12f) aligns decisions with operational and safety constraints. Finally, (12g) denotes optimization constraints.\nThe objective function is non-convex due to binary deci- sions, nonlinear relationships, and multiplicative interactions."}, {"title": "III. PROPOSED STRATEGY", "content": "Due to the intractability of problem P, the DT problem is decomposed into three subproblems: offloading ratio optimiza- tion, resource allocation, and HA digital twinning integration. We propose a decentralized game-theoretical approach to rep- resent the DT-HA model and minimize latency in PCO within the C-MEC environment. The PGM captures the intricacies of the DT-HA model, where the DT state reflects the system state and determines HAs, evolving through observable data and control inputs.\nNext, the offloading decision is modeled as a strategic game with HA constraints to determine subsystem utility. As a rational player, each subsystem devises its offloading strategy based on others' strategies. The DDQN refines the ORRA, optimizing PCO decisions, offloading ratios, and resource allocation under a given DT-HA state.\nDT-HA using the PGM and the C-MEC services, which provide optimal communication and computing resources for efficient DT operation. The operational flow involves four steps: initializing system state information, estimating the digital twin (DT) of the cyber twin and PWR human actions, maximizing user utility via the GT-PCO module, and updating the system with optimal task offloading and resource allocation. This approach enhances automation, accuracy, safety, and efficiency in NPP operations."}, {"title": "A. PGM for Digital Twining of Human Actions Procedures", "content": "The DT-HA model aims to align the DT and HAs/system states accurately. The DT-HA model mirrors operator actions, adhering to standards and historical data for predictive insight. System feedback tracks plant responses, and environmental"}, {"title": "The P1 problem is reformulated as follows to address the DT-HA problem", "content": "P1: $min_{h\\in H} \\delta(y_n, f_h)$\ns.t. (12f), $\\forall h \\in H, y_n \\in D.$\nwhere $\\delta(y_n, f_h)$ represents the discrepancy function that quan- tifies the difference between the current state yn of the DT and the state predicted by the HAs fh. The P\u2081 problem aims to estimate the expected state due to HAs while minimizing the discrepancy with the actual DT state, adhering to the operational and safety guidelines. Solving P\u2081 identifies the optimal HAs and system configurations that enhance system performance while maintaining the accuracy of the DT.\nNext, P\u2081 is translated to a PGM, where the DT of the NPP uses this model to generate experimental data for calibration and performance evaluation. The calibrated DT operates along- side the physical asset, assimilating the sensed data to update its internal models.\nThe PGM for the DT, proposed by Kapteyn et al. [28], considers the physical asset and its DT, evolving through time. The DT estimates the current and future states of the physical asset based on observational data, providing optimal control inputs to direct the physical asset to the desired states.\nThe proposed model uses six variables: the physical state St, observable data Ot, digital state Dt, control inputs Ut, quantities of interest Qt, and reward Rt. These variables represent the state of physical assets, parameters defining DT models, available information on the physical asset state, actions influencing the digital asset, estimated parameters via model outputs, and the overall performance of the asset-twin system, respectively.\nThe PGM represents the asset-twin system structure by encoding the interaction and evolution of these quantities. The PGM covers the data-to-decision flow from sensing to action. The conditional independence structure of the model allows the factorization of the joint distributions over model variables.\nThe system is modeled using a dynamic Bayesian network with decision nodes, representing the system from the initial time step t = 0 to the current time step t = tc and future time step t = tp. The graph nodes are random variables denoting each quantity at discrete time points, with uppercase letters representing variables and lowercase letters denoting their values Dt ~ p(dt). The graph edges encode dependencies between variables via conditional probabilities or deterministic functions."}, {"title": "B. Multisubsystem Computation Offloading Game", "content": "The multiuser computation offloading game can be de- fined as $G = \\{M, (S_m)_{m\\in M}, (U_m)_{mem}$, where Sm de- notes the set of offloading strategies for subsystem m, and $U_m(s_m, s_{(-m)})$ represents the utility function, consid- ering the set of offloading strategies. In addition, $s_{-m} = (s_1,..., s_{(m-1)}, S_{(m+1)},\u2026\u2026\u2026,S_M)$ represents the offloading strategies of all subsystem except the mth, where each elects the most advantageous strategy that enhances its individual utility. The game is considered to achieve a state of NE when no subsystem can further improve its utility by altering its offloading choice.\nDefinition 1: A strategy $s^* = (s^*_1,s^*_2,...,s^*_M)$ is the NE of the game G if it adheres to\n$U_m (s^*_m, s^*_{-m}) \\geq U_m (s'_m, S^*_{-m}), \\forall m \\in M, \\forall s'_m \\in S_m$.\nBased on [29], the game G is an EPG by formulating the potential function as follows:\n$\\Phi(s) = \\sum_{MEM} S_{m0} [\\sum R_{m0} + (1 - S_{m0}) \\sum_{j\\in K} S_{mj}R_{mj}] + \\sum_{m'\\neq m} \\sum J \\sum R_{m'10}$\nwhere $R_{mj} = g_t(T^{es}_m - T^{kcn}) - P\\Phi_jC_m$. For ease of proof, the expression $\\phi(s_m, s_{(-m)})$ is given as follows:\n$\\Phi(s_m, s_{(-m)}) = S_{m0} [\\sum_{MEM} R_{m0} + (1 - S_{m0}) (\\sum_{j\\in K} S_{mj}R_{mj} + \\sum_{m'\\neq m} \\sum R_{m'10})$\nRemark 1: Game G with the potential function $\\phi(s)$ is an EPG and capable of reaching an NE in a finite number of iterations.\nProof: See Appendix F"}, {"title": "C. Deep Double Q Network for Optimal Offloading Ratio and Resource Allocation", "content": "The joint optimization of the ORRA problem can be refor- mulated to maximize the utility as follows:\nP2: $min_{\\Phi,\\beta} \\sum_{MEM} P_jC_m - (T^{es}_m - T^{e2e})$\ns.t. (12c), (12d), $0 \\leq \\Phi, \\beta \\leq 1, \\forall m \\in \u039c.$\nFor any time slot (t + 1) given the user offloading request \u00b5(t+1), the optimal offloading ratio \u03a6(t+1) and resource al- location \u03b2(t+1) can be solved. However, \u00b5(t+1) is unknown due to the unknown user request transition probabilities. The DDQN is employed to capture the user request model and predict the optimal task offloading ratio and corresponding resource allocation of time slot (t + 1) based on the system state at slot t."}, {"title": "D. Game-Theoretic Offloading Framework", "content": "The game-theoretic offloading framework (Algorithm 1) solves the PCO decision problem (P) using the future optimal ORRA problem (P2) for efficient computation offloading under DT-HA constraint in (P1). The base station (BS) acts as the central hub in its operation, assimilating real-time data, such as connection statuses and subsystem strategies. Initially, service modules (subsystems) lean toward MEC offloading. However, as the iterations progress, the subsystem refines its offloading strategy based on feedback from the BS. This iterative exchange continues until the subsystem seeks no fur- ther updates, indicating an NE. The computational complexity of the game-theoretic offloading framework is represented as O(C1 \u00d7 N), where C1 is the iteration count for the DDQN."}, {"title": "IV. NUMERICAL RESULTS", "content": "A. Data-driven Calibration and Evolution of a Digital Twin Human Action Model\nThe data-driven approach uses a state-transition infinite state automation for DT capabilities, including monitoring, prediction, and optimization, ensuring continuous model im- provement. A PGM was employed to represent HAs in an"}, {"title": "V. CONCLUSION", "content": "This paper investigated integrating DTs for HA (the DT- HA model) with PCO in a 6G-powered C-MEC environment. We proposed a decentralized game-theoretical approach to minimize the PCO latency by optimizing offloading decisions, ratios, and resource allocation. A PGM captured the intricacies of the DT-HA model, guiding HAs through observable data and control inputs. Offloading decisions were modeled as a strategic game, determining the subsystem utility under HA constraints. A DDQN refined the ORRA. The proposed approach effectively captures complex HAs while optimizing resource allocation, ensuring safe and efficient NPP operations. Future work will explore precise control actions from various NPP subsystems under practical operations, enhancing the robustness and applicability of the proposed method while addressing control complexity and security threats."}, {"title": "A. State Transition Probabilities", "content": "State transition probabilities define the likelihood of transi- tioning from one state to another represented in matrix form where each entry P(St+1 = j | St = i) denotes the probability of moving from state i to j.\n$S_t = \\begin{bmatrix} 0.4 & 0.6 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\ 0.0 & 0.4 & 0.6 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\ 0.0 & 0.0 & 0.4 & 0.6 & 0.0 & 0.0 & 0.0 & 0.0 \\\\ 0.0 & 0.0 & 0.0 & 0.4 & 0.6 & 0.0 & 0.0 & 0.0 \\\\ 0.0 & 0.0 & 0.0 & 0.0 & 0.4 & 0.6 & 0.0 & 0.0 \\\\ 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.4 & 1.0 & 1.0 \\end{bmatrix}$"}, {"title": "B. Control Input", "content": "The control input distribution Ut assigns equal probabilities to each possible control action. The control input distribution Ut is defined as follows:\n$P(U_t = u_i) = \\frac{1}{n}, i\\in \\{0, 1, 2, ..., n - 1\\}$,\nn\u2208N (total number of control actions).\nGiven the control actions, the conditional probability table for control input P(Ut | St\u22121, St) can be generalized as follows: For St-1 = (i, i) where i = 0, 1, 2, 3, 4, 5:\n$P(U_t | (i, i), S_t) = \\begin{cases} 0.4 & \\text{if } S_t = (i, i) \\land U_t = u_i \\\\ 0.6 & \\text{if } S_t = (i, i + 1) \\land U_t = u_{i+1} \\end{cases}$\nFor St-1 = (i, i + 1) where i = 0, 1, 2, 3:\n$P(U_t | (i, i+1), S_t) = \\begin{cases} 0.4 & \\text{if } S_t = (i, i + 1) \\land U_t = u_{i+1} \\\\ 0.4 & \\text{if } S_t = (i + 1, i + 1) \\land U_t = u_{i+1} \\end{cases}$\nFor St-1 = (4,5):\n$P(U_t | (4,5), S_t) = \\{0.4 \\text{ if } S_t (5,5) \\land U_t = u_5$\nFor St-1 = (5,5):\n$P(U_t | (5,5), S_t) = \\{1.0 \\text{ if } S_t = (5,5) \\land U_t = u_5$\nThis representation captures the probabilities of control actions given the previous state St-1 and current state St. Any combination not listed has a probability of 0."}, {"title": "C. Observable Data Transition Probability", "content": "We let Ot represent the observable data at time t. Each Ot consists of six key parameters: the PL, RCT, RCP, SGP, SGL, and RP. The probability distribution of the observable data Ot is represented as follows:\n$P(O_t) = \\begin{cases} \\frac{1}{n_o} & \\text{if } O_t \\in \\{O_0, O_1, O_2, O_3, O_4\\} \\\\ \\frac{f(O_t)}{\\sum_{k > 4} f(O_k)} & \\text{if } O_t \\in \\{O_5, O_6,..., O_p\\} \\end{cases}$\nwhere no = 6. The first condition applies during calibra- tion, and the second condition applies beyond state 4 in the operational phase based on design needs. Each Ot at time t includes parameters such as PL, RCT, RCP, SGP, SGL, and RP, with probabilities reflecting system specifications. For instance, the probability of observing [100, 60, 27, 1, 100, 0] is $\\frac{1}{n_o}$. Irrelevant observable data can be set to 0."}, {"title": "D. Scaling Factor", "content": "The scaling factor (\u03ba) in NPP operations quantifies un- certainty at various operational stages. In the initial states (St = (0,0) and St = (0,1)), the scaling factor is higher (3.5 and 2.5), reflecting greater uncertainty. As the system transi- tions to the intermediate states (St = (1,2) and St = (2,3)), the scaling factor decreases (2.0 and 2.5), indicating increased stability. In more stable states (St = (3,4)), the factor reduces to 1.0. At high power levels (St = (5,5) to St = (5,10)), the factor is 0, reflecting minimal uncertainty. This sequential adjustment captures the dynamic uncertainty across different operational stages of the NPP."}, {"title": "E. Dynamic Estimation", "content": "1) Planning and Optimal Control: At each time step", "28": "n$u_t = \\pi (p(D_0", "reward": "n$\\pi^* = arg \\max_{\\pi} \\sum_{t=t_c+1}^{t_p} \\gamma^{(t-t_e-1)} E[R_t", "0,1": "denotes a discount factor.If state estimates are accurate, the partially observable MDP is approximated as a fully observable MDP. The expected policy is\n$u_t = \\tilde{\\pi}(d, \\tilde{q}),$\nwhere d and \u011d represent the best estimates of the current state and quantities of interest. This problem is solved off-line using the value iteration algorithm. The reward function is\n$R_t(u_t, q_t) = R_{state} (q_t) + R_{control} (U_t) + R_{obs}(O_"}]}