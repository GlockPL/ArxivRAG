{"title": "Exploring the Efficacy of Meta-Learning: Unveiling Superior\nData Diversity Utilization of MAML Over Pre-training", "authors": ["Kavita Selva", "Satita Vittayaareekul", "Brando Miranda"], "abstract": "Currently, data and model size dominate the narrative in the training of super-large, power-\nful models. However, there has been a lack of exploration on the effect of other attributes of\nthe training dataset on model performance. We hypothesize that dataset diversity can im-\npact the performance of vision models. Our study shows positive correlations between test\nset accuracy and data diversity, providing an argument for furthering the research of dataset\nattributes beyond size. We analyzed pre-training and model-agnostic meta-learning meth-\nods on twelve popular visual datasets (e.g., Omniglot, CIFAR-FS, Aircraft) and five model\nconfigurations, including MAML variants with different numbers of inner gradient steps\nand supervised learning. We show moderate to strong positive correlations (R-squared:\n0.15-0.42) between accuracy and data diversity and weaker but significant correlations\n(R-squared: 0.2) between loss and diversity. These findings support our hypothesis and\ndemonstrate a promising way for a deeper exploration of how formal data diversity influ-\nences model performance. This initial study highlights the potential of (Task2Vec) data\ndiversity as a valuable measure in the rapidly evolving field of large-scale learning and em-\nphasizes that understanding the dataset is key to building more powerful and generalizable\nmodels.", "sections": [{"title": "1 Introduction", "content": "Current trends in building large, robust vision models emphasize scaling model size and com-\nplexity (Chowdhery et al. (2022), Nostalgebraist (2022), OpenAI (2023), Google (2023)),\nbut other characteristics of datasets, like diversity, are vague and overlooked (David et al.\n(2010), Longpre et al. (2023)). Our study departs from the prevailing focus on data size\n(Hestness et al. (2017), Rosenfeld et al. (2019), Henighan et al. (2020), Kaplan et al. (2020),\nGordon et al. (2021), Hernandez et al. (2021), Jones (2021), Zhai et al. (2022), Hoffmann"}, {"title": "2 Methodology", "content": "We measure training data diversity using the Task2Vec metric (Figure 1) introduced by\nMiranda et al. (2022), which quantifies intrinsic dataset variability in a few-shot learning\nsetting. If tasks are considered as probability distributions, this metric provides an approx-\nimation of the mean distance between these distributions.\nThe Task2Vec diversity coefficient is formally defined as the expected (cosine) distance\nobserved between the Task2Vec embeddings associated with different tasks or data batches\n(Miranda et al. (2023)):\n$div(D) = E_{B1,B2~D}d(f_{B1}, f_{B2})$\nwhere D is the natural language dataset from which we sample batches B1, B2, and $f_{Bi}$\nis the Task2Vec embedding of a batch Bi using the diagonal of the FIM matrix."}, {"title": "3 Results", "content": "Experimental Setup: We analyze pre-training and model-agnostic meta-learning on\ntwelve popular visual datasets (e.g., Omniglot, CIFAR-FS, Aircraft). Our experimental\nsetup uses the exact same architecture and minimally adapts the code of Tian et al. (2020).\nPerformance was measured by test accuracy across configurations.\nFigure 1 depicts the observed relationship for each model. Notably, HO (Higher Order)\nMAML models with 5 and 10 inner gradient steps demonstrate a significantly stronger\npositive correlation between dataset diversity and relative model performance compared to\nthe PT model and FO (First Order) MAML models.\nThis observation is reinforced by the positive R-squared correlation coefficient sug-\ngesting that data diversity generally improves model performance. Significantly higher $R^2$\nvalues were observed for HO MAML 5 and HO MAML 10 models. The HO MAML 10 model\nexhibits the highest $R^2$ of 0.4 and 0.2, for Accuracy and Cross Entropy loss, respectively\n(Table 2). Similar trends were observed for HO MAML 5."}, {"title": "4 Discussion", "content": "We acknowledge a potential confounding factor: an uncontrolled number of data points\nacross training checkpoints. However, the Task2Vec diversity coefficient is designed to cap-\nture intrinsic average information invariant to dataset size. This property, coupled with"}, {"title": "5 Conclusion", "content": "Our research unveils the potential of data diversity as a crucial factor in boosting the perfor-\nmance of vision models beyond the current emphasis on scaling model size and complexity.\nOur analysis showed a positive correlation between data diversity and model performance,\nindicated by a consistent upward trend across all investigated configurations. Notably,\nmeta-learning models demonstrated a significantly stronger positive correlation with diver-\nsity compared to pre-trained approaches. Our findings suggest a paradigm shift towards\n\"quality-aware\" data selection could address the growing computational costs associated\nwith scaling models and contribute to a more efficient and impactful research trajectory in\nexploring more powerful A\u0399."}, {"title": "Appendix B. Methods", "content": "This study employs a rigorous experimental design to investigate the impact of training\nset diversity on model performance, while maintaining control over confounding variables.\nWe adopted a uniform network architecture and fixed hyperparameters across all models\nunder examination. In addition, we ensured the optimization techniques and convergence\ncriteria were consistent for each model. These methodological constraints were established\nto ascertain that any observed differences in performance on the test set were attributable\nto the variation in the diversity of the training datasets, rather than extraneous factors.\nTo assess the influence of dataset diversity on model accuracy, we conducted comparative\nanalyses between two prevalent training methods: Pre-training (PT) and Model-Agnostic\nMeta-Learning (MAML). The selection of these methods was predicated on their relevance\nand common application in the domain of machine learning, particularly in tasks requiring\nthe generalization of models to new data."}, {"title": "Appendix C. Dataset and Features", "content": "Our empirical analysis draws on a suite of established visual datasets that are benchmarks in\nthe machine learning community, frequently utilized in the context of few-shot learning and\nmeta-learning paradigms. The datasets include CIFAR-FS, FC100, Mini-ImageNet, Air-\ncraft, Flower, DTD (Describable Textures Dataset), CUBirds (Caltech-UCSD Birds 200),\nOmniglot, MIO, and a series of datasets designed to embody high degrees of diversity,\nlabeled as hdb7-afto through hdb10-micova. Each dataset is carefully curated to encapsu-\nlate a unique spectrum of diversity, defined by the variety and depth of latent concepts as\nwell as the richness of the feature space present within the data. Such diversity is believed\nto enrich the learning experience of models by exposing them to a vast array of information.\nTo quantify the diversity present within these datasets, we employed the Task2Vec Di-\nversity Coefficient, a metric which reflects the inherent variability of a dataset and enables\na normalized comparison between different training sets. The computation of the diver-\nsity coefficient was facilitated by Resnet18 and Resnet34 models previously trained on the\nImageNet database. This model functions as the computational framework for generating\nthe Fisher Information Matrix (FIM), which is crucial for the derivation of Task2Vec task\nembeddings that are used in quantifying dataset diversity. The results of this quantitative"}, {"title": "Appendix D. Experiments, Results and Discussion", "content": "We assessed the diversity coefficient of 12 publicly available Large Language Model (LLM)\npre-training datasets in this study. The diversity coefficient Our analysis aimed to mea-\nsure the variety and heterogeneity present in these datasets, giving insights into the wide\nrange of linguistic contexts they contain. The datasets we used to evaluate are CIFAR-FS,\nFC100, Aircraft, Flower, DTD, CUBirds, Omniglot, MIO, hdb7-afto, hdb8-cado, hdb9-\ncavdo, hdb10-micova.\nWe followed the method of Task2Vec diversity coefficient introduced by Miranda et al. Miranda\net al. (2022) to calculate the diversity coefficient for each datasets we evaluated. The method\nserves as a quantitative measure to estimate the effective task diversity within a dataset. If\ntasks are considered as probability distributions, this metric provides an approximation of\nthe mean distance between these distributions. Diversity Coefficient equation as follows:\n$div(D) = E_{B1,B2~D}d(f_{B1}, B2)$\nwhere D is the natural language dataset from which we sample batches B1, B2, and $f_{Bi}$ is\nthe Task2Vec embedding of a batch Bi using the diagonal of the FIM matrix $F_{B\u00bf}$Miranda\net al. (2023).\nThe validation process involves synthetic experiments where the ground truth diversity is\npredetermined and known. Specifically, the Task2Vec diversity coefficient is formally defined\nas the expected (cosine) distance observed between the Task2Vec embeddings associated\nwith different tasks or data batches Miranda et al. (2023). This calculation is performed\nwith respect to a consistent probe network in the context of a few-shot learning benchmark\nor dataset. In essence, the metric captures the relational dissimilarity between tasks, con-\ntributing to a more nuanced understanding of the diverse nature of tasks within the dataset.\nIn our experimental setup, we maintained consistency in hyperparameters to isolate the\nimpact of data variations on model performance. Specifically, we used the fixed architec-\nture of resnet12 across all experiments. For pre-trained model, only the last layer is fine\ntuned. To explore the nuances of meta-learning, Model-Agnostic Meta-Learning (MAML)\nunder different configurations is used. MAML was executed in both 1st and 2nd order to\ncapture the intricacies of different meta-learning methodologies. The inner gradient steps\nis chosen as 5 and 10 for each order MAML. As for the hyperparameters we maintained,\nthe MAML outer learning rate (lr) was set to 1e-3, and inner learning rate is set to 1e-\n1.The query set size, which represents the number of samples used for testing the model's\ngeneralization on unseen data, was configured to 15. The support set size was set to 5 to\nspecify the number of samples utilized for training and facilitating the model's adaptation\nto the task at hand. The number of ways, denotes the number of classes present in each\nmeta-learning task, was configured to 5."}, {"title": "D.2 Results", "content": "In all configurations of supervised learning, first order MAML, and higher order MAML, we\nsaw a positive relationship between the diversity coefficient of the dataset and the down-\nstream model performance, measured by test accuracy. In figure 1, we can see the diversity\ncoefficient versus accuracy for the three model settings we explored in this work. In the first\norder and higher order MAML models with inner gradient steps 5 and 10, we see a stronger\nrelationship between the diversity of the training dataset and relative model performance.\nWe see a weaker relationship with regard to the supervised learning model, and both first\norder MAML models with inner gradient steps of 5 and 10.\nWe can also more rigorously quantitatively analyze our results using the $R^2$ correlation\ncoefficient, which explains the proportion of variance in the response variable (accuracy)\nthat can be explained by the predictor variable (dataset diversity). The $R^2$ results are as\nfollows:"}, {"title": "D.3 Discussion", "content": "From these results, we can make some positive claims (strength depending on configuration)\nthat the diversity of the training dataset has an effect on the downstream performance of\nthe model, bolstered by the $R^2$ analysis. This is an interesting finding as it suggests that\nunderstanding and improving the quality of pre-training data can serve to be a useful metric\nwhen attempting to improve the performance of vision models, as opposed to simply the\nmore well-known and more expensive method of improving performance (model size and"}, {"title": "Appendix E. Future Work", "content": "We hope that this research jumpstarts a wider interest in exploring more nuanced methods\nof improving model performance, especially as current trends of focusing on size and scaling\nof models become more and more computationally expensive. With results that highlight\nthe importance of dataset quality in terms of making improvements to downstream model\nperformance, we aim to contribute to the conversation of intentionality in improving model\nperformance with not just model configurations, sizes, and dataset scale, but also giving\nattention to these alternative methods of approaching artificial intelligence questions in\ngeneral.\nIn the future, we would like to extend our work in multiple ways. First, we would like to\nconsider additional datasets with more variance in their diversity coefficient to strengthen\nour understanding of its relationship with downstream performance. We would also like to\ncreate more plots to analyze the data, specifically diversity versus cross entropy loss, as well\nas add additional statistical information like confidence intervals.\nWe also wanted to note that there is a potential confounding factor in this work in that the\nnumber of data points for each checkpoint was not controlled. In the future, we would like\nto explore an idea to deal with the different amount of data points by choosing checkpoints\nwith similar average Task2Vec complexity. In other words, this would involve computing\nthe average Task2Vec complexity of each dataset models were trained on, and seeing if they\nhave similar complexities. We would then choose datasets with similar complexity, defining\nsimilar potentially as a small effect size difference.\nWe also recognize that this work explores only performance on vision models. It would\nbe an interesting extension of this work to evaluate how the diversity of the training set\naffects downstream performance in other applications currently affected by huge scaling of\ndatasets such as language related tasks. Overall, we hope that with our work we have con-\ntributed to the grounding of the understanding of methods to getting a performant model\nthrough explorations of dataset quality.\nMoving forward, we aim to conduct more comprehensive experiments across diverse model\narchitectures, methodologies, and datasets to refine our findings and aims to address the\ngap in exploring the impact of dataset quality on model efficacy, building upon our demon-\nstrated positive correlations between accuracy and data diversity. We also propose to select\ncheckpoints with similar average Task2Vec complexity to control for dataset size in future\nexperiments, to isolate the effect of diversity more precisely."}]}