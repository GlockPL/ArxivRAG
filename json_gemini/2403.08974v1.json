{"title": "Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields", "authors": ["Ashish Sinha", "Ghassan Hamarneh"], "abstract": "Anatomical trees play a central role in clinical diagnosis and treatment planning. However, accurately representing anatomical trees is challenging due to their varying and complex topology and geometry. Traditional methods for representing tree structures, captured using medical imaging, while invaluable for visualizing vascular and bronchial networks, exhibit drawbacks in terms of limited resolution, flexibility, and efficiency. Recently, implicit neural representations (INRs) have emerged as a powerful tool for representing shapes accurately and efficiently. We propose a novel approach for representing anatomical trees using INR, while also capturing the distribution of a set of trees via denoising diffusion in the space of INRs. We accurately capture the intricate geometries and topologies of anatomical trees at any desired resolution. Through extensive qualitative and quantitative evaluation, we demonstrate high-fidelity tree reconstruction with arbitrary resolution yet compact storage, and versatility across anatomical sites and tree complexities. The code will be available here\u00b9.", "sections": [{"title": "1 Introduction", "content": "Motivation for Studying Anatomical Trees. Accurate extraction and analysis of anatomical trees, including vasculature and airways, is crucial for predicting fatal diseases like ischemic heart disease [36] and aiding clinical tasks like surgical planning [30], computational fluid dynamics (CFD) [34], and disease prognosis [1]. However, the application of extracted trees for such purposes may be hindered by their explicit representation as meshes or volumetric grids.\nPrevious Works on Tree Representation. Prior works have utilized discrete and explicit representations, such as medial axis [25], minimal paths [14], grammar [15], voxel grids [42], and meshes [38], to represent anatomical trees. However, all these explicit representations have their own peculiar shortcomings,"}, {"title": "2 Methodology", "content": "Overview. We propose a diffusion-based generative approach comprising two steps. First, we optimize an INR realized as an MLP by overfitting its parameters to each tree in a dataset so that each INR faithfully represents each tree as a neural occupancy field (Fig. 1a). Second, the optimized INRs are flattened into 1D vectors and used to train a denoising diffusion model (DDM) that captures the statistical distribution of the trees (Fig. 1c). The DDM is used to synthesize new INRs, via a reverse diffusion process (Fig. 1b), which represents the occupancy field (or a mesh, if marching cubes [17] is applied) of the tree (Fig. 1d).\nStage 1: Learning per-sample INR. We represent each tree, in a dataset {S}1 of N trees, as a neural occupancy field, or INR, f(x;0) : R3 \u2192 [0, 1], modelled as an MLP and parameterized by \u03b8 \u2208 RD. Note that, unlike prior works [23,40] that involve parameter sharing across the entire dataset, we optimize an INR separately for each tree sample.\nGiven oi(x), the ground truth occupancy of x for Si, we optimize \u03b8i as:\narg min \u2211 || for (j) \u2013 Oi (Xj) ||2. (1)\n\u03b8\u03b5\nxjER3\nSimilar to [21,22], our MLP architecture is a fully-connected network with L layers, of hidden size D, and ReLU activation functions. To learn high-fidelity"}, {"title": "Stage 2: Diffusion on INRs.", "content": "We train a diffusion model on the space of INRs, i.e., the weights and biases {0;}\u21161. Our transformer-based [35] diffusion model D($) is inspired by [5,24], and takes the flattened 1D vectors of \u03b8i as input. However, before passing the input to D($), each i undergoes a layer- by-layer decomposition into k tokens by MLPs [24]. This is essential due to the potential variation in the dimensionality of different layers in \u03b8; and ensures cor- respondence of any element j across all trees Oi, Vi, j. During forward diffusion, we apply noise nt at timestept to each vector \u03b8i to obtain a noisy vector 0.\nFollowing [5,24], the sinusoidal embedding of t along with is fed to a linear projection layer, whose output is concatenated with a learnable positional encoding vector to obtain G. The resultant G is then passed to the transformer,"}, {"title": "3 Datasets, Results, and Implementation Details", "content": "Datasets. We use the following datasets to evaluate our approach: (1) VascuSynth: 120 synthetic 3D vascular trees, ranging from 1 branch to complex trees with multiple branches and bifurcations [9]; (2) IntRA: 103 3D meshes of intracranial vasculature extracted from MRA [38]; (3) BraTS: 40 3D MRI brain scans [20]; (4) HaN-Seg: 20 segmentations of Head&Neck CTA scans [26]; (5) DRIVE: 20 2D retinal fundus color images with vessel segmentation masks [32]; (6) EXACT: One CT scan of a bronchial tree [16]; (7) WBMRA: One whole body MRA; and (8) CoW: One circle of Willis mesh. Our evaluation covers the following aspects.\nFidelity and Compactness. Following [21], we use Chamfer distance (CD) to evaluate the fidelity of INRs in representing anatomical trees and summarize it in Tables 1 and 2. Figure 3 shows that we can achieve higher reconstruction accuracy with a smaller memory footprint. For example, as seen in Table 2 we need 68 MB for volumes and 12 MB for meshes compared to INRs that only occupy 0.75 MB and 0.63 MB, respectively, offering \u2248 90\u00d7 and \u2248 19\u00d7 compression, respectively, with minimal loss of reconstruction accuracy. Similarly, Table 1 shows that 10k parameters of INR are enough to encode the geometry of a 1283 volume of IntRA, resulting in \u2248 220\u00d7 compression."}, {"title": "Space of INR-based Trees.", "content": "Once trees are represented via INRs, we study the space of INRs. The t-SNE plot in Figure 6a illustrates how trees with similar number of bifurcations, i.e. topological complexities, tend to cluster in the 2D t-SNE space. However, we observe cases where trees with the same number of branches are distant, which may be due to how t-SNE projects high-dimensional"}, {"title": "Tree Synthesis.", "content": "Training a DDM on INR-based trees results in a model that captures the tree distribution and can be sampled using DDIM [31] to generate novel trees. First, we show qualitative results of novel INR-based trees generated by our model in Figure 8. Next, since the evaluation of unconditional generation of tree-like structures can be challenging due to lack of direct correspondence to ground truth data, we follow [4,5] to quantitatively assess the samples gen- erated using diffusion. Specifically, we use minimum matching distance (MMD), coverage (COV), and 1-nearest neighbor accuracy (1-NNA) to measure qual- ity, diversity, and plausibility, respectively. Moreover, since the generations are random, we run the evaluation 3 times and report the mean values in Table 3. Additionally, we follow [6,37] and report vessel-based metrics in Figs. 6c and 6d, where we see high similarities in tortuosity and centerline length histograms between ground truth training data and synthesized trees."}, {"title": "INR-based Image Segmentation.", "content": "We present two proof-of-concept experi- ments on how INR representation is leveraged to perform vessel tree segmenta- tion. Figure 7 depicts the evolution of INR-represented segmentation masks as they gradually fit to target vasculature in both CoW and WBMRA."}, {"title": "Implementation Details.", "content": "We used PyTorch and ADAM optimizer with learn- ing rate a 10-3 for all experiments. To fit INRs to trees, we optimize the"}, {"title": "4 Conclusion", "content": "We presented the first work to use implicit neural fields for faithful represen- tation of topologically-complex anatomical trees and learnt their distribution via training a diffusion model in the space of neural fields. We demonstrated quantitatively and qualitatively the advantages of our method: versatility (e.g., 2D/3D; vascular/airway; simple/complex topology), lower memory footprint while achieving highly accurate reconstructions at arbitrary high resolutions; synthesis of plausible trees; and application to segmentation of medical im- ages. Further, our representation is amenable to integration into deep learning pipelines and can be easily transformed into other shape representations. Future work may include integrating our method into more advanced deep segmentation pipelines while encoding semantic annotations of tree parts."}]}