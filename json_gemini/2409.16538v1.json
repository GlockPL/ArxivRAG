{"title": "Source-Free Domain Adaptation for YOLO Object Detection", "authors": ["Simon Varailhon", "Masih Aminbeidokhti", "Marco Pedersoli", "Eric Granger"], "abstract": "Source-free domain adaptation (SFDA) is a challenging problem in object detection, where a pre-trained source model is adapted to a new target domain without using any source domain data for privacy and efficiency reasons. Most state-of-the-art SFDA methods for object detection have been proposed for Faster-RCNN, a detector that is known to have high computational complexity. This paper focuses on domain adaptation techniques for real-world vision systems, particularly for the YOLO family of single-shot detectors known for their fast baselines and practical applications. Our proposed SFDA method Source-Free YOLO (SF-YOLO) relies on a teacher-student framework in which the student receives images with a learned, target domain-specific augmentation, allowing the model to be trained with only unlabeled target data and without requiring feature alignment. A challenge with self-training using a mean-teacher architecture in the absence of labels is the rapid decline of accuracy due to noisy or drifting pseudo-labels. To address this issue, a teacher-to-student communication mechanism is introduced to help stabilize the training and reduce the reliance on annotated target data for model selection. Despite its simplicity, our approach is competitive with state-of-the-art detectors on several challenging benchmark datasets, even sometimes outperforming methods that use source data for adaptation. Our code is available at https://github.com/vs-cv/sf-yolo.", "sections": [{"title": "1 Introduction", "content": "Deep learning models for object detection (OD) have shown impressive performance by leveraging a large amount of labeled data [6, 24, 48, 61]. Yet, they still perform best when the test distribution is close to the training one. However, in real-world applications, there is typically a shift between data from the source (laboratory) and target (operational) domains due to variations in camera capture conditions (pose, illumination, resolution, weather) that can decrease accuracy [8, 43, 49]. Fine-tuning the OD model for the target domain is effective but often too costly due to the need for collecting and annotating data."}, {"title": "2 Related Work", "content": "(a) Unsupervised Domain Adaptation. UDA aims to adapt a source model to perform well in a target (operational) domain using labeled source data and unlabeled target data. UDA methods for OD cover both classification and localization tasks and are typically classified as adversarial feature learning, domain translation, or self-training [43]. Adversarial methods use domain discriminators and adversarial training [14] to confuse the model between the source and target domains, resulting in a domain-invariant representation. Chen et al. [8] first introduced image and instance-level adversarial feature alignment. Saito et al. [49] refined this with strong local and weak global feature alignment, both employing adversarial techniques. Building on these ideas, some works [16, 66] focused on instance-level alignment, emphasizing regions containing objects of interest.\nIn contrast to adversarial image or instance-level alignment methods [3,8, 17,20,23,49], Hsu et al. [19] proposed a center-aware feature alignment method, using the FCOS detector. Alternatively, domain translation methods [12, 29, 49, 53,57,64] typically use image-to-image translation methods like CycleGAN [65], AdaiN [22], FDA [60], or CUT [44] to learn domain-invariant representation by generating source like target images or target like source images. Self-training methods often use a pseudo-labeling strategy [27,36] for supervised fine-tuning of the models in the target domain, but incorrect pseudo-labels can degrade performance. Therefore Kim et al. [28] proposes to use a weak self-training approach to mitigate this, while Khodabandeh et al. [27] refine noisy annotations with an additional classifier. To prevent student-teacher collapse, Lin et al. [39] add an extra domain alignment loss to distinguish between the student and teacher models. However, all of the mentioned methods cannot meet the growing demand for data privacy protection. SFDA has emerged as a new branch of UDA.\n(b) Source-Free Domain Adaptation. SFDA adapts a source model pre-trained on labeled source data using only unlabeled target data, addressing privacy concerns by transmitting the model instead of extensive source-domain data. SFDA methods for OD mostly use MT and a pseudo-labeling strategy [4,37,40,55]. A key challenge of fine-tuning methods for SFDA is their reliance on noisy pseudo-labels. Since inaccurate pseudo-labels can degrade model accuracy, Li et al. [38] first addressed this issue by determining a threshold for eliminating unreliable pseudo-labels using an adaptive entropy minimization approach. Zhang et al. [63] refined this by adapting thresholds per class and improving the localization quality of pseudo-labels. A\u00b2SFOD [10] tackles noisy labels by partitioning the target domain based on detection variance. Huang et al. [21] use self-supervised learning for learning feature representations through historical models and contrastive learning while Vibashan et al. [55] employ instance relation graph networks and a contrastive loss to enhance target representations.\nLi et al. [37], argued that existing SFDA methods do not fully utilize target domain data, limiting their effectiveness. To address this, they proposed LODS, which reduces the model's focus on domain style by enhancing the style of target domain images and using the style difference between the original and enhanced images as a self-supervised signal for adaptation. Most approaches rely on a MT architecture, which is prone to instability, limiting the performance they can reach. Closely related to our method, Liu et al. [40] introduced PETS, which ex-changes teacher and student models each epoch while maintaining an additional"}, {"title": "3 Proposed Method", "content": "Let Ds = (X, Y) represent the labeled data in the source domain where X = {x}1 denotes the image set of the source domain and y = {y} is the corresponding label set containing object locations and category assignments for each image. Ns denotes the total number of source images. The target domain D\u2081 = (X\u2081) is unlabeled and X\u2081 = {x}\u2081 denotes the N\u2081 images of this domain. In SFDA, a source pre-trained model denoted as hs: X \u2192 Vs is initially available to perform adaptation on the unlabeled target domain. However, given the domain shift between the source and target domains, the mapping h, diminishes performance when directly applied to the target domain. Consequently, the primary objective of SFDA is to learn a new mapping ht : Xt \u2192 Yt by adapting the pre-trained source model hs using only the unlabeled target data Xt.\nUsing the mean-teacher paradigm, both teacher, defined as he, and student defined as ho models are instantiated from the source model which is a pre-trained YOLOv5 architecture. Therefore the training loss can be expressed as:\nLdet = AbLbox + AcLcls + AdLobj, (1)\nwhere Lbox and Lcls respectively represent the classification and bounding box regression losses, while Lobj corresponds to the objectiveness loss, which is related to the confidence of object presence. The Ab, c, d terms are weighting hyperparameters that control the relative importance of each loss component in the overall detection loss.\nOur framework works in two steps. First, a Target Augmentation Module is trained to learn a domain-specific data augmentation for the target domain. Then, we use the augmented images to train a student model with the mean teacher paradigm. The student model h\u00f8 gradually distills its acquired knowledge to the teacher model he which learns through exponential moving average (EMA). We also introduce the Student Stabilisation Module (SSM), which effectively stabilizes the training process, leading to improved overall performance. The framework does not increase the basic detector's complexity during inference. This is an important factor for many real-time applications. The overall SF-YOLO training architecture is illustrated in Figure 1 and detailed in Algo-rithm 1. The rest of this section describes the main components of our method.\n(a) Target Augmentation Module. In typical self-training with the teacher-student framework, the teacher and student models take distinct views of images as input to maximize mutual information in a non-trivial manner. Specifically, The teacher model receives weakly-augmented images as input, while the stu-dent model is fed with strongly-augmented images. Here, instead of generat-ing random strong-weak augmentation pairs, we use a network coined \"Target Augmentation Module\" (TAM) to learn the proper augmentation. This aug-mentation module reminisces the style enhancement module from the LODS"}, {"title": "(b) Consistency Learning With Teacher Knowledge", "content": "For each data point x from the target domain Dt we obtain the classification score hals(x), bounding box regression hbox(x) and confidence hobi (x) from the teacher model, and use it as the pseudo-label to train the student model via backpropagation. However, directly learning from ho(x) may lead to overfitting to the teacher model. To address this issue, we introduce a consistency loss that consists of three steps. First, we filter out the low-confidence predictions of the teacher models by setting"}, {"title": "(c) Student Stabilisation Module", "content": "Note that the teacher never directly ob-serves the augmented images, which can often be unrealistic. Instead, it only deals with the real target images. So far our method is similar to the Mean Teacher and Noisy Student paradigm [52]. However, since the student model learns faster, it is more susceptible to making errors. After updating the teacher, those mistakes are reflected in pseudo-labels generation, causing noisier pseudo-labels which can degrade performance for the rest of the training. To mitigate the impact of these errors, the Student Stabilisation Module (SSM) is introduced.\nAs our initial experiments using the target augmented mean-teacher frame-work in Figure 2 shows, although EMA and learned augmentation help to improve the performance of the student model, the result quickly deteriorated to the extent that at epoch 60 the performance of student model is almost like a random detector. We hypothesize that since the student model is updated rapidly using SGD after every batch, it is more likely to make errors. Although an EMA-updated teacher can initially prevent the student from overfitting, it may not be sufficient to stabilize the training. As a remedy once at the end of each epoch, we also update the student weights using the EMA of the teacher model using the following equation:\n\u03c6 = \u03b3\u03c6 + (1 \u2212 \u03b3)\u03b8 (4)\nwhere y is the SSM momentum parameter. This approach confines the student model close to the teacher model, maintaining the quality of pseudo-labels and preventing too much deviation."}, {"title": "(d) Training and Inference", "content": "The overall SF-YOLO learning process is summa-rized in Fig. 1 and Algorithm 1. The adapted teacher model is used for inference,"}, {"title": "4 Results and Discussion", "content": "4.1 Experimental Methodology\n(a) Datasets. The following four datasets are used: Cityscapes [11], Foggy Cityscapes [50], KITTI [15] and Sim10k [25]. For more information about the classes considered on each dataset, the domains, the number of images and in-stances present and other information please refer to the Suppl. Materials.\n(b) Adaptation scenarios. Following prior works [8,10,19,38,42,55,58,62], we conduct experiments on three different benchmark scenarios: Cityscapes \u2192 Foggy Cityscapes (C2F) for normal weather to adverse weather adaptation, KITTI \u2192 Cityscapes (K2C) to address cross-camera adaptation and Sim10K \u2192 Cityscapes (S2C) to evaluate synthetic-to-real adaptation. As in Sim10k dataset only cars are annotated, we follow the literature [8, 10, 12, 35, 37, 38, 55, 58, 62] and only consider the car AP for S2C and K2C scenarios, while for C2F scenario, we use the complete 8 classes.\n(c) Implementation details. We prioritize a realistic setting, using YOLOv5, a widely adopted and efficient one-stage detector. Additionally, as we are first to address the SFDA paradigm for YOLO, we also conduct a preliminary com-parison with baseline UDA approaches [35,41,42,58,64] that also use YOLOv5. First, we train the TAM with the same parameters as proposed by the authors of LODS [37], using Adam [30] optimizer, a learning rate of 0.0001 and a frozen pretrained VGG16 [51] encoder. This module is frozen and used to transform the target images as a data augmentation for the student detection model.\nFor source model training we use the default YOLOv5l settings [24] and train for up to 200 epochs. For our SF-YOLO adaptation, we set the batch size"}, {"title": "4.2 Comparison with State-of-the-Art Methods", "content": "Results in Tables 2 and 3 show the performance of state-of-the-art SFDA meth-ods based on Faster-RCNN. However, since we are the first to address the SFDA paradigm for YOLO and aim to establish a baseline for future research, SF-YOLO is compared with classical UDA methods based on YOLOv5. Note that these UDA methods access both labeled source data and unlabeled target data, while our method only uses unlabeled target data. Despite this more challenging setup, we achieve competitive performance with UDA methods, suggesting that the source data may not be fully exploited. We also compare with PETS [40], an SFDA method originally on based on Faster RCNN that we re-implemented (as we could not find the public code). We indicate the use of source data during adaptation in the Source-free column. Source Only and Oracle (upper bound) are respectively trained with labeled source and target data."}, {"title": "4.3 Ablation Studies", "content": "This section analyses the importance of TAM and SSM in the C2F scenario with YOLOv5l. It shows that learned augmentation offers greater benefits compared to random data augmentation. It also shows that SSM behaves differently from other regularization techniques used to control weight consistency between stu-dent and teacher. Moreover, alignment is found unnecessary in our setting, and SSM is compatible with other architectures, such as Faster R-CNN. For similar ablations with YOLOv5s, see the Suppl. Materials.\n(a) Learned Augmentation vs Random Augmentation. We compare the TAM with weak-strong random augmentations as described in [32]. Weak aug-mentations (image flipping, geometrical transformation) are applied to the im-ages to be processed by the teacher model, while strong augmentations [7] (e.g., color jitter, randomize grayscale and blur) are applied to the images fed to the student model to improve the overall generalization capability. From Table 4 we see that although both techniques improve performance, learned augmentation provides higher gains since it is specific to the target dataset.\n(b) SSM vs Learning Rate. One intuitive way to control the divergence between teacher and student is to restrict the learning speed of the student. In Figure 3a, we present the model performance over training iterations for our approach without SSM over a range of learning rates. As we can see, optimizing the learning rate indeed impacts the best possible outcome. Nonetheless, after"}, {"title": "(c) SSM vs L2 between student and teacher", "content": "Catastrophic forgetting is another perspective from which we can analyze the drift between the student and teacher model. Elastic weight consolidation (EWC) [31] is a popular approach to overcome catastrophic forgetting in continual learning literature, where learning on certain weights is slower based on their importance on previously seen tasks. The original EWC requires the creation of a Fisher information matrix based on data from the source domain which cannot be satisfied in SFDA. Following Barone et al. [2], we use a simplified EWC version that approximates the Fisher information matrix as diagonal Gaussian prior with mean equal to the teacher parameters and 1/\u5165 variance. The final penalty term is:\nRL\u2082 = \u03bb\u00b7 || - ||2 (5)\nand is simultaneously minimized with the detector loss. Figure 4b shows our experiments over different values of \u03bb. First, we can see that the best performance is really sensitive to the choice of A and in some cases, a wrong value can reduce the performance by large a margin. Second, considering the best performing \u03bb, SSM and L\u2082 have a complementary effect in which the overall best model is the combination of both. Nevertheless, the method used for the results in Table 2 and Table 3 did not combine L2 and SSM. Although this combination yielded the best performance, it required extensive hyperparameter tuning. In a real-world SFDA scenario where access to labels in target data is limited, conducting such tuning becomes impractical. Hence, we chose to exclude this combination in favor of a tuning-free SSM approach better suited to practical deployment."}, {"title": "(d) Delaying mean-teacher", "content": "The graph depicted in Figure 4c displays the performance of our method without SSM under different EMA\u2192e momentum values a. Our intuition is that if the student updates the teacher too frequently, then the student does not have enough time to learn a robust representation of the target data, and this can introduce more noise to the teacher. Therefore, we have selected a small value for a. By updating the teacher once every epoch instead of once every batch, we have observed that the training becomes more stable. However, similar to learning rate and L2, the best performance is really sensitive to the choice of \u03bb. Additionally, for the best performing \u5165, we can observe a complementary effect with SSM."}, {"title": "(e) Hyper-parameters sensitivity", "content": "Based on the results presented in Figure 4, it can be observed that SSM produces relatively stable outcomes across a wide"}, {"title": "(f) Feature alignment", "content": "Feature alignment of the source and target domains is typically used in UDA methods to improve generalization by extracting domain-invariant features [8, 19, 49, 57, 66]. Although SFDA doesn't allow direct feature alignment due to the absence of source domain data, our SF-YOLO framework uses a TAM. This module enables the creation of a pseudo-domain Daug = (Xaug) = {TAM(x)}1 representing an augmented version of the target domain Dt. Our findings indicate that aligning target domain features with their augmented counterparts does not enhance performance in our SFDA setting. As a result, we opted against using feature alignment to keep our method simpler."}, {"title": "(g) Faster R-CNN", "content": "To show the compatibility of SSM with other architectures than YOLO, we applied SSM to IRG [55], one of the SOTA methods using Faster R-CNN architecture. Table 5 shows the compatibility of SSM with Faster R-CNN. Utilizing SSM provides a significant gain in performance in all scenarios. It allows to achieve SOTA accuracy for SFDA methods based on Faster R-CNN on K2C, and second and third best on C2F and S2C scenarios, respectively. While the aforementioned methods can reduce drifting, SSM outperforms in most cases and requires minimal fine-tuning, which is crucial for SFDA. Furthermore, we find feature alignment to be unnecessary in our setting, and our proposed SSM is compatible with other architectures, like Faster R-CNN."}, {"title": "5 Conclusion", "content": "We proposed the first approach for SFDA using the YOLO family of single-shot detectors. Our method employs a teacher-student framework with a learned, target domain-specific augmentation and a novel communication mechanism to stabilize training, reducing reliance on annotated target data for model selection, which is crucial for real-world applications. SF-YOLO outperforms all SFDA methods based on Faster R-CNN and even some UDA YOLO-based methods using source data. We present SSM, a simple addition to the MT framework, which improves performance and stability. Our extensive experiments show SSM's com-patibility with existing knowledge preservation techniques. Our primary hypoth-esis behind the success of SSM lies in the online distillation of knowledge between student and teacher, which prevents the drift of models caused by noisy pseudo-labels. SSM is particularly well-suited for source-free (unsupervised) learning scenarios. Unlike conventional semi-/weakly-/unsupervised learning, these sce-narios have no access to source data nor the labeled data from the target domain to ensure the stability of the model and prevent significant drift during training."}]}