{"title": "AI PERSONA: Towards Life-long Personalization of LLMs", "authors": ["Tiannan Wang", "Meiling Tao", "Ruoyu Fang", "Huilin Wang", "Shuai Wang", "Yuchen Eleanor Jiang", "Wangchunshu Zhou"], "abstract": "In this work, we introduce the task of life-long personalization of large language models. While recent mainstream efforts in the LLM community mainly focus on scaling data and compute for improved capabilities of LLMs, we argue that it is also very important to enable LLM systems, or language agents, to continuously adapt to the diverse and ever-changing profiles of every distinct user and provide up-to-date personalized assistance. We provide a clear task formulation and introduce a simple, general, effective, and scalable framework for life-long personalization of LLM systems and language agents. To facilitate future research on LLM personalization, we also introduce methods to synthesize realistic benchmarks and robust evaluation metrics. We will release all codes and data for building and benchmarking life-long personalized LLM systems.", "sections": [{"title": "1 Introduction", "content": "The advent of large language models (LLMs) that can effectively understand and generate human language has marked a transformative era in artificial intelligence. LLMs such as ChatGPT, Gemini, and Claude have shown remarkable capabilities, not only as general chatbot providing useful responses but also as agents that assist hundreds of millions of users in diverse real-world tasks. Mainstream efforts in the AI/LLM community have been focusing on scaling data and compute on pre-training or post-training stages for building stronger LLMs that can better serve the needs of users. Millions of GPUs and billions of dollars are consumed every year for this purpose.\nHowever, a crucial question is: does satisfactory user experience naturally emerges with improved capabilities of LLMs? While it is true that improved reasoning abilities help LLMs solve more complex tasks and improved instruction-following abilities enable LLMs to better understand user intents, current LLM systems are by design incapable of capturing diverse and ever-changing personal profiles of distinct users that are implicitly encoded in life-long human-AI interaction histories. For example, an AI assistant must have rich information of a user's residential address, personal agenda, income and consumption habits, preferences for foods and restaurants, etc., to generate a satisfactory response for a query as simple as \"help me reserve a restaurant for dinner.\" Moreover, many aspects, including personalities, intents, preferences, etc., in user profiles are dynamic and ever-changing in the real world, making it crucial for LLM systems to be capable of constantly adjusting to the changes of user profiles. Therefore, we argue that stronger capabilities of LLMs are not all we need for AGI and life-long personalization of LLMs is another important building block for AI systems that are helpful, satisfactory, and engaging for everyone.\nWhile personalization has been carefully investigated in other domains such as recommendation systems, research on LLM personalization is quite limited and suffers from three major limitations: First, most recent work on LLM personalization are task-specific and the methodology for LLM personalization can not be generalized to other tasks; Second, most existing LLM personalization methods requires training either the entire LLM or a few blocks within the LLM, making them impossible or very costly to scale to real-world applications used by million"}, {"title": "2 Related Work", "content": "of users on a daily basis; Finally, the lack of diverse and realistic benchmarks makes it hard to evaluate new methods. To be specific, most recent work conducts experiments on the LaMP benchmark . However, the tasks in this benchmark such as citation identification and scholarly title generation are very different from queries asked by real-world users and therefore not representative enough. Moreover, recent study has shown that a non-personalized LLMs can also achieve competitive performance on these tasks, suggesting that the benchmark is not suitable for evaluating advanced LLM personalization approaches. In addition, all previous studies consider LLM personalization as a one-time task. However, it is crucial for LLM systems to constantly adjusting to ever-changing user profiles in real-world applications by learning from human-AI interactions.\nIn this paper, we introduce the task of life-long personalization of LLMs and provide a detailed task formulation emphasizing the difference from previous static LLM personalization problems. We present AI PERSONA, a simple, general, effective, and scalable framework to build life-long personalized LLM systems or language agents. Specifically, we define user profiles as learnable dictionaries where the keys are fields representing various aspects of a real-world user, including demographics, personality, usage patterns, and preferences. The values are the users' personal information in the corresponding fields. During inference, a user's AI persona will be dynamically assembled into a part of the prompt/input to the LLM backbone so that it will generate personalized responses. Life-long adaptation of user profiles is achieved by a carefully designed LLM-based persona optimizer, which constantly adjust the AI Persona of the user during the interaction between the user and the LLM system. To the best of our knowledge, the proposed framework is the first method in the literature that can constantly adjust the profiles of each users during the progress of human-AI interaction. Moreover, our approach does not involve model training and only requires to store a lightweight config file for each user, making it scalable for real-world applications with large amount of users.\nTo test the effectiveness of the proposed AI PERSONA framework and facilitate future research, we build PERSONABENCH, a benchmark for (life-long) LLM personalization research. PERSONABENCH consists of diverse and realistic user profiles and user queries generated with a carefully designed LLM-based workflow. Our experiments on PERSONABENCH demonstrates that the proposed AI PERSONA framework2 can effectively learn and adapt to user profiles over time.\nOur contributions can be summarized as follows:\n1. We provide a clear definition of life-long personalization, emphasizing the necessity of continuous adaptation in understanding user needs. To our knowledge, this is the first work to address this task in the literature.\n2. We propose a novel pipeline for generating realistic persona chat data, encompassing diverse persona configurations and authentic user-agent interaction simulations.\n3. We introduce a life-long personalized agent framework, serving as a baseline solution for this task.\n4. We conduct experiments that demonstrate the effectiveness of our methods, showcasing significant improvements in agent performance and adaptability to user personas.\nBy addressing these aspects, our work aims to advance the field of personalized conversational agents, fostering more effective and meaningful user interactions."}, {"title": "2.1 Personalized LLMS", "content": "The personalization of language models (LLMs) has garnered significant interest in industries such as recommendation systems and search, focusing on providing tailored responses that adapt to individual user preference. Recently, this focus has extended to other domains such as research assistants, travel planners, writing assistants, book recommending, shopping counselors, and programming agents."}, {"title": "2.2 Benchmarking Personalized LLMs", "content": "A common approach involves fine-tuning personalized LLMs. integrate persona prediction with response generation, while use LoRA to fine-tune Llama for individual users. To further enhance efficiency, group users and fine-tune LoRA at the group level.\nDespite these advancements, fine-tuning approaches face limitations in maintaining adaptability over time due to the need for frequent retraining, which is impractical in real-world scenarios. To address this, RAG-based personalized LLMs, offer an alternative by leveraging user-specific historical data. For example, introduced a pseudo-RAG approach for incorporating user history, later enhanced by through retriever optimization. Similarly, propose retrieval-based methods to integrate user-authored documents for prompt augmentation. However, the input length constraints still hinder effective personalization when user interactions are lengthy. To address this, some studies have utilized comprehensive user histories to generate summaries based on user interactions. While significant progress has been made, existing approaches rarely consider realistic, life-long adaptation scenarios, leaving room for further exploration in dynamic, long-term personalization.\nWhile benchmarks for LLM agents have been extensively developed, few focus on personalized agents. A significant challenge in this area is the scarcity of realistic data. Existing benchmarks, such as LaMP, utilize public datasets with user identifiers, offering limited user-data associations. LaMP comprises seven tasks, primarily binary classification and single-instance generation, such as Personalized Citation Identification (choosing which paper is likely to be cited) and Personalized Scholarly Title Generation (generating a title from an abstract). However, its minimal reliance on historical user data limits its ability to evaluate true personalization. Notably, these task designs are insufficient since a large language model (LLM) could achieve competitive performance without access to any historical user data about u."}, {"title": "3 AI Persona: Towards Life-long Personalized LLMs", "content": "To overcome these limitations, our proposed data synthesis pipeline generates a broad spectrum of persona configurations and user-agent interactions, simulating realistic conversational scenarios that evolve. This approach not only supports the development of more adaptable agents but also establishes a comprehensive benchmark for evaluating life-long personalization capabilities. By dynamically generating data that reflects diverse user behaviors and preferences, we provide a more robust framework for training and testing personalized LLMs in environments that closely resemble real-world usage."}, {"title": "3.1 Task Formulation", "content": "We will provide a clear definition and task formulation of Life-long personalized LLM in this section. Consider a model or an agent, noted P, which takes the input query x from a user u. A personalized agent should conditioning on not only x but also the profile of u in order to generate satisfactory responses that is tailored to this specific u. In previous setting, particularly in LaMP, the profile of u, Pu, is defined as a set of user's historical data, i.e., the past input and personalized outputs produced by or approved by the user. That is Pu = {(Xu1, Yu1), (Xu2, Yu2), ..., (Xuk, Yuk)}. Through out the evaluation, the Pu is fixed for each u which makes the persona profile static. In this work, we re-define the user profile as learnable dictionaries where the keys are fields representing various aspects of a real-world user and the values are the users' personal information or traits in the corresponding field.\nPu = {(k1, Vu1), (k2, Vu2), ..., (kn, Vun)}, where ki represents the i-th field of user attributes such as demographics, personality, usage patterns, and preferences, and vui denotes the corresponding value reflecting user u's information in that field.\nThe learnable aspect of Pu means that each value Vui is dynamically updated based on the ongoing interactions between the user and the agent P. Mathematically, this is modeled as:\nv(t)\nVui = f\u03b8 (v(t\u22121)ui , (xt, Yt)),"}, {"title": "3.2 Data Generation Pipeline", "content": "where f\u03b8 is the persona optimizer parameterized by \u03b8, and (xt, Yt) is the interaction data at time step t. Note that f\u03b8 can either be a learnable model with trainable parameters or a pre-trained LLM-based agent guided by well-designed prompts. In this work, we opt for the latter approach, keeping \u03b8 fixed and utilizing the LLM's emergent abilities to adapt through prompting rather than parameter updates. This formulation allows Pu to continuously evolve, capturing the latest user behaviors and preferences in real-time.\nIn contrast to static representations, our approach ensures that the user profile remains up-to-date and context-aware, enabling the model to adapt its responses more accurately to the evolving characteristics of the user in a longer life-span.\nThe most challenging aspect of personalization is the scarcity of realistic user data and the difficulty of accessing it. To tackle this problem, we propose a persona chat data generation pipeline, as shown in Figure1, to synthesize real persona profile and generate user-agent conversation data according to each aspect of the persona profile."}, {"title": "3.2.1 Persona Generation", "content": "First we pre-define the necessary fields that a comprehensive persona profile should contain, which are demographics, personality, usage patterns, and preferences.\n\u2022 Demographics: This field captures key factual information about the user's identity and background, including age, gender, nationality, language, and career information or education background. It provides a basic understanding of the user.\n\u2022 Personality: This field defines the user's psychological characteristics and values, reflecting how they typically think, feel, and behave. In our setting, we represent it using MBTI (Myers-Briggs Type Indicator) and interests. Personality traits implicitly influence how users express themselves, respond to different conversational styles, and engage with the agent.\n\u2022 Patterns: This field represents the user's habits and interactions with the personalized agents, such as behavior engagement patterns, usage patterns and purchase pattern. Understanding usage patterns enables the agent to anticipate user needs and provide proactive support, thereby enhancing user experience and engagement.\n\u2022 Preferences: This field encompass the user's preferred interaction styles, formats, and workflows. Capturing preferences helps the agent to personalize responses and recommendations, making interactions more relevant and satisfying for the user.\nTo create more comprehensive and realistic persona profiles, we first ask volunteers from diverse backgrounds (e.g., different professions and life stages) who has a habit to regularly use AI products to complete persona profiles. Using these real personas as seed configurations, we then prompt the LLM to summarize these profiles into brief descriptions as seed hints. With the seed hints and seed configurations in place, we instruct the LLM to generate diverse persona descriptions in a self-instruct manner to generate a large amount of persona hints, then using the seed configurations as in-context exemplars to guide the model in producing diverse, comprehensive and realistic persona data."}, {"title": "3.2.2 Scene generation", "content": "In order to synthesize realistic user-agent chat data, a critical component is to generate realistic and personalized queries. Previous work only focus on chit-chat or role-play scenario. In contrast, our work"}, {"title": "3.2.3 Personalized Query Generation", "content": "After establishing personalized scene descriptions and their contextual information, the next step is to generate realistic and contextually appropriate queries. To achieve this, we employ a user simulator capable of role-playing based on a given persona profile. The user simulator reads the persona profile, current scene description, along with its contextual information to produce relevant and nuanced queries. This approach moves beyond generic role-play or simple chit-chat, instead generating queries that are deeply rooted in realistic scenarios that users may encounter."}, {"title": "3.2.4 Data Filtering and Refinement", "content": "To avoid generating unanswerable or nonsensical queries, the model evaluates whether it can provide a reasonable response, filtering out any queries that fail this criterion. Additionally, to prevent the user simulator from directly revealing persona traits in the query, we conduct a data refinement procedure that neutralizes the query, retaining only the essential information and the intended purpose."}, {"title": "3.3 AI Persona Framework", "content": "Our proposed AI Persona framework is composed of three main components: a Historical Session Manager, a Tool Executor, and a Personalized Chatbot. Each component plays a critical role in enabling life-long personalized interactions with users.\nHistorical Session Manager The Historical Session Manager is responsible for managing and storing conversation histories across multiple sessions for different users. It provides a comprehensive record of user interactions, enabling the system to maintain context and continuity over time. Its core functionalities include initializing, loading, saving, and retrieving conversation sessions, ensuring that"}, {"title": "4 Experiments", "content": "the system can seamlessly recall past interactions to support coherent and context-aware responses.\nTool Executor The Tool Executor is a well-prompted LLM designed to simulate external API execution. It interprets function calls from the Personalized Chatbot and generates appropriate responses based on predefined API descriptions provided in the scene information. Its primary function is to generate realistic and contextually accurate function call responses, bridging the gap between the chatbot and external tools or databases.\nPersonalized Chatbot The Personalized Chat-bot is a well-designed conversational agent that leverages user personas to deliver personalized and context-aware responses. It acts as a versatile agent, capable of dynamically adapting its behavior to align with the user's evolving profile and current context. Its core functionalities include:\n\u2022 Persona-based Interaction: The chatbot generates tailored responses based on the user's persona and query, ensuring that each interaction is relevant and engaging.\n\u2022 Dynamic Persona Updates: The chatbot updates the user's persona profile in real-time as the interaction progresses, reflecting any changes in user preferences, behaviors, or context.\n\u2022 Function Calling: When necessary, the chatbot initiates appropriate function call to external APIs associated with the current scene, enriching the response with precise and contextually appropriate information.\nAs shown in Figure 2, during inference, the framework operates in a sequential manner, integrating all three components to provide a coherent and personalized user experience. Whole process is illustrated in the Algo 1."}, {"title": "4.1 Experiment Setup", "content": "Model updates the persona configuration after every k sessions, allowing it to accumulate more interaction data before making adjustments. Finally, the Historical Session Manager saves the current session data, ensuring that all interactions are recorded for future reference.\nThis multi-step process enables the AI Persona Framework to provide nuanced and adaptive interactions that cater to the user's individual needs, fostering a more engaging and personalized user experience.\nBenchmark Setting Our proposed benchmark, PERSONABENCH, is composed of 200 diverse persona profiles, each paired with 10 common scene settings and 10 persona-specific scene settings. For each persona, we randomly sample 3 to 5 different scenes and prompt the LLM to re-generate scene descriptions, contextual information, and potential function calls. This approach simulates a common scenario where users often ask similar questions about the same topics over time. By incorporating this data type, we aim to assess whether a personalized LLM can learn from previous sessions and improve performance when handling similar scenarios. Additionally, we pre-generate the initial user queries and carefully hand-check each one to ensure a fair comparison. In total, we synthesized over 6,000 data points to construct the benchmark.\nBaselines We compare our proposed AI Persona framework with 3 baselines:\n\u2022 No Persona Access: The model generates responses without any access to the persona configuration, simulating a scenario where the model serves as an AI chatbot.\n\u2022 Golden Persona Access: The model is provided with access to the ground truth persona configuration during inference, enabling it to generate responses that are fully aligned with the user's defined attributes.\n\u2022 Conversations RAG: The model could not maintain or learn the user's persona but it could retrieve conversations in which there exist similar queries to generate responses according to historical interactions.\nEvaluation Metrics We evaluate the models across several key dimensions to measure their ability to align with user personas and efficiently meet user needs:\n\u2022 Persona Satisfaction: We use an LLM as a judge to score the first utterance of each session based on how well the generated responses solve the problem and how well they align with the user's persona. This score reflects if a chatbot can instantly get users' intentions.\n\u2022 Persona Profile Similarity: After the session ends, we evaluate the final saved persona profile by comparing it to the ground truth persona. This measure reflects how accurately the model has updated and maintained the persona throughout the interactions.\n\u2022 Utterance Efficiency: We measure how many utterances are required for the model to fully satisfy the user's needs. Fewer utterances indicate better alignment and understanding of the user's requirements, as the model can meet the user's needs more efficiently with less back-and-forth interaction."}, {"title": "4.3 Procedural Learning of Personalized LLMS", "content": "In this subsection, we illustrate how the performance evolves over time as user-agent interactions progress under different settings: No Persona Access, Ground Truth Persona Access, and Persona Update. The primary goal is to evaluate whether the personalized LLM can improve its responses as it engages in more conversations and accumulates more personal information of the user.\nAs depicted in Figure 3, the x-axis represents the number of sessions, while the y-axis denotes the number of utterances for the user-simulator to be satisfied. We plot three lines, each corresponding to one of the settings. The comparison demonstrates how the availability of persona information and updating mechanisms influences the model's ability to generate more tailored responses over time.\nThe blue learning curve is the Persona Learning setting which showcases a notable improvement over No Persona. The line in the figure reflects a steady decrease in the number of utterances needed for satisfaction and the standard deviation over time as well, demonstrating the effectiveness of persona learning. Remarkably, the performance in the final few sessions under the Persona Learning setting approaches that of the Golden Persona setting, indicating the effectiveness of our proposed method. It shows that with just over ten updates, the model can learn and adapt to the user's persona efficiently.\nTo further evaluate the effectiveness of our persona learning framework, we conducted a pairwise comparison of responses generated by the Persona Learning setting and the Golden Persona setting. Figure 4 presents the results, categorized by session groups (1-10, 11-20, 21-32). The win rate of the \"Persona Learning\" responses steadily increases as the session progresses, demonstrating that our AI persona framework effectively learns and adapts to the user's persona over time.\nThis procedural learning analysis highlights the importance of dynamic persona modeling in personalized LLM systems, emphasizing the advantages of updating user profiles based on cumulative interactions."}, {"title": "4.4 Performance across various Base LLMS", "content": "6.07, while the k = 1 and k = 5 settings achieve scores of 5.88 and 5.23, respectively. Notably, this comparison highlights an interesting finding: more frequent updates (as in the k = 1 setting) and more information in each update (as in the k = 5 setting) do not necessarily result in better learning outcomes. This finding emphasizes the importance of carefully selecting the learning frequency k in the life-long personalization of LLMs.\nThe primary focus of Table 2 is to observe the performance of each model under different persona settings. We observe that our proposed Persona Learning method improves the performance across"}, {"title": "5 Conclusion", "content": "all LLMs. Among them gpt-40 shows the best adaptability of personalization.\nFigure 5 summarize the results, demonstrating the average number of utterances and the personalized response scores across different configurations.\nThe performance differences across base models illustrate that while all LLMs can benefit from persona learning, GPT-40 and Gemini-1.5-pro are better equipped with the ability to adapt and perform in personalized scenarios.\nThis paper introduces the task of life-long personalization for large language models (LLMs) and proposes the AI PERSONA framework, which enables scalable and dynamic adaptation to evolving user's persona without requiring model retraining. We present PERSONABENCH, a synthesized but realistic and diverse benchmark for evaluating personalized LLMs. Experimental results demonstrate the effectiveness of our framework in improving personalized responses and maintaining updated user profiles. Our work provides a novel, generalizable, and efficient solution for continuous LLM personalization, addressing key limitations in existing approaches."}, {"title": "6 Limitations", "content": "Although our proposed AI PERSONA framework are designed to be language-agnostic, the seed data collection and annotation processes in this study were conducted by Chinese native speakers. As a result, the PERSONABENCH is more representative of scenarios and linguistic nuances specific to Chinese users. While our approach can theoretically generalize to other languages and cultural contexts, its current implementation and evaluation are better suited for Chinese language applications. Future work should involve expanding the data collection and annotation processes to include diverse linguistic and cultural backgrounds to fully validate the framework's adaptability across different languages and user demographics."}]}