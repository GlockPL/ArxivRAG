{"title": "U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities", "authors": ["Fnu Neha", "Deepshikha Bhati", "Deepak Kumar Shukla", "Sonavi Makarand Dalvi", "Nikolaos Mantzou", "Safa Shubbar"], "abstract": "Medical imaging is essential in healthcare to provide key insights into patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography (CT), and Ultrasound (US), capture detailed images of organs, tissues, and abnormalities. Effective analysis of these images requires precise segmentation to delineate regions of interest (ROI), such as organs or lesions. Traditional segmentation methods, relying on manual feature-extraction, are labor-intensive and vary across experts. Recent advancements in Artificial Intelligence (AI) and Deep Learning (DL), particularly convolutional models such as U-Net and its variants (U-Net++ and U-Net 3+), have transformed medical image segmentation (MIS) by automating the process and enhancing accuracy. These models enable efficient, precise pixel-wise classification across various imaging modalities, overcoming the limitations of manual segmentation. This review explores various medical imaging techniques, examines the U-Net architectures and their adaptations, and discusses their application across different modalities. It also identifies common challenges in MIS and proposes potential solutions.", "sections": [{"title": "1. Introduction", "content": "Images serve as critical tools for capturing and conveying information about objects, scenes, or concepts through various techniques such as photography, digital imaging, or specialized sensing technologies. In healthcare, medical imaging (MI) holds a pivotal role in both diagnosis and treatment. These images are acquired using non-invasive imaging modalities, including X-rays, Magnetic Resonance Imaging (MRI), Computed Tomography (CT), and Ultrasound (US). Each modality offers distinct advantages and is tailored for specific diagnostic applications, enabling precise visualization and analysis of anatomical structures and physiological processes [1, 2]. For example, MRI scans are invaluable for assessing brain tumors, and CT scans are used to evaluate internal injuries [3, 1]. In contrast to general-purpose imagery, MI demands advanced techniques to capture detailed anatomical and pathological features. These methods are essential for ensuring accurate visualization, interpretation, and analysis, which are critical for effective clinical decision-making and treatment planning.\nOne important aspect of MI is segmentation, which involves identifying and delineating regions of interest (ROI), such as organs or lesions [4]. This process is essential for extracting key information about the shape, size, and volume of these structures. Traditional segmentation methods rely on manual feature-extraction and techniques like thresholding or edge detection [5]. These methods are time-consuming and inefficient, and these are subject to variability due to reliance on expert input. This inconsistency has driven the demand for more advanced, automated methods to enhance the segmentation process.\nThe integration of advanced computational techniques has significantly enhanced MI by enabling the automated interpretation and analysis of complex image data. These innovations streamline diagnostic processes and improve the accuracy of image-based assessments [6]. Deep learning (DL), a subset of AI, uses neural networks with multiple layers to learn patterns from vast datasets. These networks automate tasks which previously required specialized human expertise, such as detecting anomalies in medical images or predicting patient outcomes.\nRecent advancements in DL for Medical Image Segmentation (MIS) have established automatic segmentation as a superior alternative to traditional methods [7, 8, 9]. The popular segmentation techniques are: (1) semantic segmentation: classifies each pixel [9]; (2) instance segmentation: identifies individual objects [10]; (3) panoptic segmentation: combines both semantic and instance segmentation, provide a comprehensive understanding of the image. Panoptic segmentation assigns a label to each pixel while differentiating between instances of objects within the same category [11]. These techniques have achieved remarkable accuracy across various medical imaging datasets, including the International Skin Imaging Collaboration (ISIC) for skin cancer [12], Brain Tumor Segmentation (BraTS) for brain tumors [13], and Kidney Tumor Segmentation (KiTS) for kidney tumors [14].\nAs image-based diagnosis becomes increasingly crucial in clinical practice, encoder-decoder models like U-Net and its variants [15, 16, 17] have gained prominence for their flexibility and strong performance in MIS. The growing emphasis on deep learning (DL) has led to a significant body of research and review articles on MIS, underscoring the pivotal role of DL models in advancing efficient computer-aided diagnosis systems. These evolving models hold the promise of making diagnoses faster, more accurate, and more accessible.\nWhile existing reviews, such as those by Siddique et al. [18] and Azad et al. [19], provide comprehensive overviews of U-Net and its architectural variants across various medical imaging modalities, their focus has primarily been on theoretical advancements and applications. These studies explore the development of U-Net and its use in MIS, with an emphasis on its role in improving diagnostic accuracy. In contrast, our review includes the latest developments in the field and expands on recent advancements in both U-Net architectures and the diverse modalities in which they are applied.\nOur paper extends existing reviews by focusing on the practical integration of U-Net in clinical settings, particularly emphasizing the role of semantic segmentation techniques in improving diagnostic accuracy and treatment planning. We further enhance model interpretability by incorporating predefined semantic features, addressing a key gap between advanced segmentation methods and their real-world healthcare applications. To provide a comprehensive and up-to-date perspective on U-Net-based methods, we include recent review papers and explore a broader spectrum of medical imaging modalities. For each modality, we have included detailed attributes such as Study, Modality, Focus Area, Methodology, and Performance Metrics, offering valuable insights into their specific applications and contributions to medical image segmentation.\nThe key contributions of our paper include:\n1. Overview of Medical Imaging Modalities: A comprehensive exploration of X-ray, MRI, CT, and Ultrasound modalities, focusing on their classifications, applications, and critical roles in medical diagnostics and healthcare.\n2. U-Net and Its Variants: A thorough review of the U-Net architecture, tracing its development, variants, and recent advancements.\n3. Applications Across Modalities: An analysis of U-Net's diverse applications across various medical imaging types, with detailed attributes such as Study, Modality, Focus Area, Methodology, and Performance Metrics for each modality.\n4. Limitations and Future Directions: A discussion of the current limitations in both architectural approaches and modality-specific applications, along with suggestions for future advancements in the field.\n\nThe paper is organized as follows: Section 2 presents the research methodology. Section 3 provides an overview of the common medical imaging modalities. Section 4 discusses U-Net and its variants. Section 5 reviews U-Net's applications across medical images. Section 6 identifies limitations. Section 7 presents the discussion and future directions. Section 8 concludes the review."}, {"title": "2. Research Methodology", "content": "This review explores the application of U-Net in healthcare, focusing on its use across various medical imaging modalities to provide a comprehensive overview. Our research methodology is outlined as follows:\n\u2022 Literature Search: A thorough search was conducted across electronic databases, including PubMed, Elsevier, Scopus, Google Scholar and IEEE Xplore. Top medical imaging conferences, such as Medical Image Computing and Computer-Assisted Intervention (MICCAI), International Symposium on Biomedical Imaging (ISBI), and Information Processing in Medical Imaging (IPMI), were also included to gather relevant materials. The search strategy involved keywords related to U-Net, medical imaging, healthcare applications, and deep learning to ensure comprehensive coverage.\n\u2022 Inclusion and Exclusion Criteria:\n Inclusion: Studies specifically addressing U-Net's implementation in healthcare contexts, including segmentation, classification, and diagnosis.\n Exclusion: Articles not published in English, those lacking full-text availability, and studies unrelated to U-Net or healthcare/medical imaging applications.\n\u2022 Data Retrieval and Screening: As of October 2024, approximately 150 recent publications were retrieved and screened for relevance based on the predefined criteria.\n\u2022 Framework for Literature Categorization A framework was developed to categorize the literature by medical imaging modalities (e.g., x-ray, magnetic resonance imaging, computed tomography and ultrasound scans), highlighting U-Net's versatility across modalities.\n\u2022 Synthesis and Analysis: Findings were synthesized to summarize U-Net's contributions to diagnostic accuracy. The analysis discussed limitations and potential improvements, paving the way for future directions."}, {"title": "2.1. Research Objective", "content": "The primary research objective of this review is to understand, how U-Net and various imaging modalities integrate to manage organ-related diseases, enhancing the effectiveness of diagnostics, treatment recommendations, and overall patient health."}, {"title": "3. Medical Imaging Modalities", "content": "In this section, we will cover key concepts related to various medical imaging modalities or techniques, including X-ray, MRI, CT, and Ultrasound."}, {"title": "3.1. X-Ray", "content": "X-rays are a form of electromagnetic radiation, similar to visible light, with much higher energy and shorter wavelengths [20, 21, 22, 23]. These are essential in the medical field for diagnostic imaging, enabling healthcare professionals to non-invasively visualize the body's internal structures. This technology allows for detailed imaging of bones, organs, and tissues, helping diagnose injuries, detect diseases, and guide treatment decisions accurately and efficiently as shown in Fig. 1.\nThese are produced in an X-ray tube, consisting of a cathode (the negative electrode) and an anode (the positive electrode). When the cathode is heated, it emits electrons, which are then accelerated toward the anode under the influence of a high-voltage potential, typically ranging from 20 to 100 kV. When the high-speed electrons strike the anode, they undergo two processes:\n\u2022 Bremsstrahlung Radiation: The high-energy electrons are decelerated upon interaction with the positive electric field of the anode nucleus, leading to the release of X-ray photons as a result of the energy loss during deceleration.\n\u2022 Characteristic Radiation: When electrons possess sufficient energy, they can eject inner-shell electrons from the atoms of the anode material, typically tungsten. This process creates vacancies that are subsequently filled by outer-shell electrons transitioning to lower energy states, resulting in the emission of characteristic X-rays."}, {"title": "3.1.1. Properties of X-rays", "content": "\u2022 Penetrating Power: X-rays can penetrate body tissues and degree of penetration depends on the energy of the X-rays and the density of the material they pass through.\n\u2022 Detection: X-rays can be detected using film (traditional radiography) or digital detectors (computed radiography or direct digital radiography). These detectors convert X-rays into images by capturing the varying levels of radiation transmitted through the body."}, {"title": "3.1.2. Image Formation", "content": "When X-rays pass through the body, their absorption varies depending on the density and composition of the tissues:\n\u2022 Dense Structures: High-density structures, such as bones, absorb a substantial proportion of X-rays, resulting in their white appearance on radiographic images.\n\u2022 Soft Tissues: Structures like organs and muscles exhibit moderate absorption, appearing as varying shades of gray.\n\u2022 Air: Low-density regions, such as those containing air (e.g., the lungs), absorb minimal X-rays, leading to a dark or black representation on the image."}, {"title": "3.2. Magnetic Resonance Imaging (MRI)", "content": "Magnetic Resonance Imaging (MRI) is a non-invasive medical imaging technique to provide high-resolution images of internal organs and tissues [30, 31, 32, 33]. MRI differentiates itself from X-ray imaging by avoiding the use of ionizing radiation. Instead, MRI works by aligning hydrogen protons in the body using a strong electromagnetic field. These protons are then disrupted by a radiofrequency (RF) pulse, and as they return to their original alignment, they emit energy detected by the scanner to produce detailed images. Its key points are:\n\u2022 Magnetic Field (MF): The MRI machine consists of a large magnet generates a strong MF, ranging from 0.5 and 1.5 Tesla. This MF aligns the protons in the hydrogen atoms of the body's tissues.\n\u2022 Radiofrequency (RF) Pulses: After the alignment of protons within the MF, RF pulses are applied to the targeted region. These RF pulses momentarily disturb the equilibrium alignment of the protons, causing them to shift from their original orientation.\n\u2022 Relaxation: Following the cessation of the RF pulses, the protons gradually realign with the main MF. During this realignment process, they emit energy in the form of RF signals. This phenomenon, referred to as relaxation, varies in rate depending on the specific properties of the tissue being imaged.\n\u2022 Signal Detection: The emitted radio waves are detected by the MRI machine and converted into electrical signals. These signals are then processed by a computer to create images of the scanned area."}, {"title": "3.3. Types of MRI", "content": "MRI can be categorized into several types, each designed to provide specific information about the body's structures and functions as shown in Fig. 2.\n\u2022 Structural MRI:\n T1-weighted MRI: These images provide high-resolution anatomical detail [34]. T1-weighted imaging sequences are particularly effective for highlighting fat-rich tissues and evaluating normal anatomical structures. These sequences generate high-intensity signals for tissues with high fat content, while fluid-filled structures appear with lower signal intensity, providing distinct contrast for diagnostic assessment.\n T2-weighted MRI: T2-weighted imaging is highly sensitive to variations in water content within tissues, making it a valuable tool for detecting pathological conditions such as tumors, inflammatory processes, and edema. [34]. These images enhance the contrast of fluid-rich regions, aiding in precise diagnostic evaluations.\n\u2022 Fluid-Attenuated Inversion Recovery (FLAIR): FLAIR is a specialized MRI sequence that suppresses the signal from cerebrospinal fluid (CSF), making it easier to visualize lesions and abnormalities in the brain [35]. It is particularly useful for detecting white matter lesions.\n\u2022 Diffusion MRI: This technique evaluates the diffusion of water molecules within tissues [36]. It is particularly useful for imaging brain white matter tracts, as it provides insights into the integrity of neural pathways.\n Diffusion Tensor Imaging (DTI): A specialized form of diffusion MRI that characterizes the directionality of water diffusion [37]. DTI allows for the visualization of white matter tracts, which is essential in studying conditions like stroke and multiple sclerosis.\n\u2022 Susceptibility Weighted Imaging (SWI): SWI is an advanced MRI technique that enhances the visualization of blood vessels and detects small hemorrhages by utilizing phase information from the MR signal [38]. It is particularly valuable in identifying vascular malformations and assessing traumatic brain injuries.\n\u2022 Functional MRI (fMRI): fMRI measures brain activity by detecting changes in blood flow related to neural activity [39]. When a brain region is active, it consumes more oxygen, leading to changes in the blood's oxygenation level. fMRI can be used for pre-surgical brain mapping, studying brain functions, and assessing neurological disorders."}, {"title": "3.4. Computed Tomography (CT)", "content": "Computed Tomography (CT) scans use rotating X-ray generators to create detailed cross-sectional images of the body [41, 42, 43]. These rely on the differential absorption of X-rays by various tissues. A CT scanner uses a rotating assembly comprising an X-ray tube and detectors to acquire X-ray projections from multiple angular perspectives. These projections are computationally reconstructed to produce detailed two-dimensional or three-dimensional visualizations of internal anatomical structures. Unlike traditional radiography, which superimposes structures, CT scans produce detailed slices of the subject, often just a few millimeters thick, enabling three-dimensional reconstruction and improved visualization of the said internal structures. CT assigns density-based values called Hounsfield units to voxels, facilitating differentiation of tissues. Contrast-enhanced scans further improve visualization, particularly for blood vessels.\nThe Hounsfield scale is a measurement system used in CT imaging to assess the radiodensity of various materials. It assigns values called Hounsfield units (HU), with water being the reference point at 0 HU. High-density materials, such as bone, are assigned positive HU values, generally ranging from 1000 to 1500 HU, while low-density substances like air are given negative values, around -1000 HU. The radiodensity levels are depicted in grayscale on CT images, where denser structures appear brighter, and less dense structures appear darker. A voxel is a fundamental three-dimensional unit that forms part of the reconstructed image. Smaller voxels contribute to greater image clarity and detail. Tissues that absorb more x-rays, or have higher attenuation, produce bright voxels, while those with lower absorption result in darker voxels. This differentiation is essential for accurately visualizing tissue structures."}, {"title": "3.4.1. Image Planes: Axial, Coronal, and Sagittal", "content": "CT images can be acquired in multiple planes as shown in Fig. 3, including axial, coronal, and sagittal views, which provide different perspectives of the body:\n\u2022 Axial (Transverse) Plane: This is the most common orientation, providing cross-sectional images of the body in horizontal slices [14]. Each slice corresponds to a specific thickness, typically ranging from 1 to 10 mm, allowing for detailed examination of organs and structures.\n\u2022 Coronal Plane: This orientation provides images viewed from the front, slicing the body into anterior and posterior sections [14]. Coronal views are particularly useful for visualizing structures such as the sinuses, heart, and lungs.\n\u2022 Sagittal Plane: These images divide the body into left and right sections, offering insights into the midline structures [14]. Sagittal views help assess spinal alignment and certain anatomical relationships."}, {"title": "3.5. Types of CT Scans and Phases", "content": "CT scans are classified based on their applications and imaging phases as shown in Fig.4:\n\u2022 Non-Contrast CT: This imaging modality, performed without the administration of a contrast agent, is commonly employed as an initial diagnostic tool for evaluating conditions such as fractures, hemorrhages, and neoplasms [14]. It provides essential baseline data regarding tissue density and structural integrity.\n\u2022 Contrast-Enhanced CT: This scan has an iodine-based contrast agent administered intravenously or orally to enhance the visibility of vascular structures and organs [14]. It is essential in oncological assessments, abdominal imaging, and vascular studies. Following are the phases of Contrast-Enhanced CT:\n Arterial Phase: Images are acquired 25-30 seconds after contrast injection, ensuring enhanced visualization of arterial vessels and hypervascular lesions due to their increased contrast enhancement during this phase.\n Venous Phase: Images are acquired 60-90 seconds post-injection, this phase focuses on venous structures and provides valuable information about tumor perfusion and vascular integrity.\n Delayed Phase: Captured 10-15 minutes after contrast administration, this phase assesses the distribution of contrast within tissues, particularly beneficial for evaluating renal function and identifying tumors with varying vascularity."}, {"title": "3.6. Ultrasound(US)", "content": "An ultrasound scan, also known as sonography or ultrasonography, utilizes high-frequency sound waves to generate real-time images of structures inside the body as shown in Fig. 5 [45, 46, 47]. US is widely used for diagnostic purposes, offering a non-invasive, safe, and relatively inexpensive method to visualize tissues, organs, and blood flow."}, {"title": "3.6.1. Working Principle of Ultrasound", "content": "Ultrasound imaging operates on the principle of acoustic reflection, where sound waves are transmitted from a transducer into the body and reflected back from tissues, providing data for image formation [48, 49, 50]. The sound waves propagate through various tissues, and upon encountering interfaces between different tissue types, such as muscle and bone or fluid and soft tissue, they are reflected back toward the transducer. These soundwaves, generated and received by piezoelectric transducers in a probe, create images by interpreting echoes. Denser materials produce stronger echoes, appearing brighter on the image, while the time taken for echoes to return indicates the depth of the structure.\nUltrasound can be employed endoscopically to assess difficult-to-reach organs like the prostate, ovaries, pancreas, and heart valves. The transducer functions both as a transmitter, emitting sound waves, and as a receiver, capturing the returning echoes. The sound waves are typically in the range of 2-20 MHz, above the human hearing range. A gel is applied between the transducer and the skin to eliminate air gaps, which could otherwise interfere with the transmission of sound waves by causing premature reflection. The modality includes various imaging modes, such as A-mode (plots echoes as peaks reflecting depth), B-mode (produces grayscale, two-dimensional images showing depth and density), M-mode (captures motion sequences of structures like the heart), and Doppler or duplex mode (assesses blood flow velocity and direction using frequency shifts). The returning echoes are analyzed based on the time delay (how long the echo takes to return) and intensity (strength of the echo) to create a 2D or 3D image on the US monitor."}, {"title": "3.6.2. Types of US Scans", "content": "US scan has the following types:\n\u2022 Endoscopic (EUS) combines endoscopy and US to obtain high-quality images of internal organs that are close to the gastrointestinal tract [51]. A small US probe is attached to an endoscope, which is inserted through the mouth or rectum to visualize organs such as the pancreas, liver, and lungs. EUS is commonly used to assess digestive diseases, guide biopsies, and evaluate tumors, particularly in the pancreas and esophagus.\n\u2022 Doppler ultrasound is a specialized technique that measures the movement of blood through vessels by detecting changes in the frequency of the reflected sound waves, known as the Doppler effect [52]. It provides critical information about blood flow, including velocity and direction, helping detect conditions such as blockages, clots, or reduced blood flow due to narrowing of the arteries.\n\u2022 Transvaginal ultrasound is a type of pelvic US where a probe is inserted into the female genitalia to obtain detailed images of the uterus, ovaries, cervix, and surrounding structures [53]. This method offers higher resolution than abdominal US due to the closer proximity of the probe to the pelvic organs. It is commonly used for early pregnancy evaluations, diagnosing ovarian cysts, and assessing abnormal bleeding or pelvic pain."}, {"title": "4. U-Net and its variants", "content": "U-Net is a convolutional neural network (CNN) primarily designed for biomedical image segmentation [15]. The architecture was proposed by Ronneberger et al. in 2015 and is widely used for pixel-level tasks due to its ability to capture both global context and fine details. Its symmetric encoder-decoder structure allows it to effectively model complex features while preserving spatial information."}, {"title": "4.1. U-Net Architecture", "content": "The U-Net architecture consists of two main parts: the encoder (contracting path) and the decoder (expanding path) as shown in Fig. 6."}, {"title": "4.1.1. Encoder (Contracting Path)", "content": "The encoder consists of series of convolutional layers followed by max-pooling layers. Each convolutional layer applies a convolution operation with filters of size k \u00d7 k, using optional padding to preserve the spatial dimensions. The output of each convolutional block is subsequently passed through a non-linear activation function, rectified linear unit (ReLU) or Gaussian Error Linear Unit (GeLU). Mathematically, the output of a convolutional layer can be expressed as:\n$$Y = \\sigma(W * X + b)$$\nwhere $X \\in \\mathbb{R}^{H \\times W \\times C}$ denote the input image, where H, W, and C represent the height, width, and number of channels, respectively. W represents the convolutional kernel, b is the bias, * denotes the convolution operation, and $\\sigma$is ReLU/GeLU. After each convolution, a m \u00d7 m max-pooling operation is applied to reduce the spatial resolution by a factor of m."}, {"title": "4.1.2. Bottleneck", "content": "The bottleneck, or bridge, connects the encoder and decoder. It consists of cl, k \u00d7 k convolutions, followed by a ReLU/GeLU activation function. This layer captures the deepest level of feature representations with the smallest spatial dimension."}, {"title": "4.1.3. Decoder (Expanding Path)", "content": "The decoder is structurally symmetric to the encoder and comprises upsampling operations followed by convolutional layers. The upsampling operation doubles the spatial resolution, achieved through either transposed convolution (also known as deconvolution) or interpolation techniques. This can be represented as:\n$$Z = W^T * Y$$\nwhere $W^T$ is the transposed convolution kernel, and Y is the input from the previous layer. After upsampling, the corresponding feature map from the encoder is concatenated to the decoder feature map to preserve spatial information. This is known as a skip connection and is crucial for retaining fine details.\nEach concatenated feature map is then passed through cl, k x k convolutions followed by activation function, progressively reconstructing the spatial resolution while refining the feature map."}, {"title": "4.1.4. Output Layer", "content": "The final layer of the U-Net architecture is a 1\u00d71 convolution which reduces the number of channels to the desired number of output classes. For segmentation tasks, the softmax function is often applied to obtain a probability distribution over the classes for each pixel:\n$$P(c_i|X) = \\frac{exp(s_i)}{\\sum_{i=1}^{C} exp(s_i)}$$\nwhere $s_i$ is the score for class i, and C is the total number of classes."}, {"title": "4.1.5. Loss Function", "content": "For binary segmentation tasks, U-Net uses the binary cross-entropy (BCE) loss:\n$$L_{BCE} = - \\frac{1}{N} \\sum_{i=1}^{N} [y_i log(\\hat{y}_i) + (1 - y_i) log(1 - \\hat{y}_i)]$$\nwhere $y_i$ is the true label, $\\hat{y}_i$ is the predicted probability, and N is the total number of pixels. For multi-class segmentation, CE loss is generalized as:\n$$L_{CE} = - \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{ic} log(\\hat{y}_{ic})$$\nwhere $y_{ic}$ is the one-hot encoded label for class c and $\\hat{y}_{ic}$ is the predicted probability for class c."}, {"title": "4.2. U-Net++", "content": "U-Net++ is an advanced variant of the U-Net architecture proposed by Zhou et al. in 2018 [16]. It enhances semantic segmentation performance by redesigning skip connections and introducing dense convolutional blocks between the encoder and decoder. U-Net++ achieves higher accuracy through nested convolutional pathways that facilitate feature refinement and multi-scale feature fusion."}, {"title": "4.2.1. U-Net++ Architecture", "content": "The architecture of U-Net++ retains the fundamental encoder-decoder structure of the original U-Net and introduces significant modifications in the skip connections. Specifically, it employs nested convolutional pathways, which consist of a series of convolutional blocks connecting encoder and decoder layers at various depths, as illustrated in Fig. 7."}, {"title": "4.2.2. Nested Convolutional Pathways", "content": "In U-Net++, skip connections are redefined to include convolutional blocks that progressively refine features before they are merged with decoder features. Let $X^{i,j}$ denote the feature map at the i-th decoder stage and j-th convolutional layer within the nested pathway. The feature maps are computed recursively as:\n$$X^{i,j} = \\begin{cases} f(X^{i-1,j}, Up(X^{i,j-1})), & \\text{if } j > 0 \\\\ f(X_{enc}), & \\text{if } j = 0 \\end{cases}$$\nwhere:\n\u2022 $X_{enc}$ is the output feature map from the i-th encoder layer.\n\u2022 f() represents a convolutional operation (e.g., convolution followed by batch normalization and activation)."}, {"title": "4.3. U-Net 3+", "content": "U-Net 3+ is an enhanced version of the U-Net [15] and U-Net++ [16] architectures, introduced by Huang et al. in 2020 to enhance multi-scale feature fusion and segmentation accuracy, particularly for pixel-wise prediction tasks [17]. U-Net 3+ introduces two main innovations: full-scale skip connections and deep supervision. These modifications enable the integration of information across all encoder and decoder layers, enhancing the network's ability to capture both high-level semantic information and low-level spatial details."}, {"title": "4.3.1. U-Net 3+ Architecture", "content": "The U-Net 3+ architecture maintains the basic encoder-decoder structure of U-Net and redefines the skip connections. In U-Net 3+, each decoder level aggregates feature maps from all encoder levels via full-scale skip connections. This design facilitates the fusion of features from multiple resolutions, as illustrated in Fig. 8."}, {"title": "4.3.2. Full-Scale Skip Connections", "content": "U-Net 3+ employs full-scale skip connections to aggregate feature maps from all encoder layers into each decoder layer. Let $Z_{i,j}$ represent the feature map at the i-th level of the decoder after fusion with the encoder outputs for level j. The full-scale skip connections are defined by:\n$$Z_{i,j} = concat(E_0, E_1, ..., E_N, D_{i-1,j})$$\nwhere:\n\u2022 $E_k$ is the feature map from the k-th encoder level, $k \\in \\{0,1,..., N\\}$,\n\u2022 $D_{i-1,j}$ is the upsampled feature map from the previous decoder level i - 1, and\n\u2022 concat refers to the concatenation operation across all encoder features and the corresponding decoder feature map.\nThis concatenation allows each decoder layer to access and integrate information from multiple resolution levels, enhancing the model's ability to capture diverse features and improving segmentation precision."}, {"title": "4.3.3. Deep Supervision", "content": "In addition to full-scale skip-connections, U-Net 3+ incorporates a deep supervision mechanism that applies auxiliary output layers to intermediate decoder levels. For each decoder level $D_i$, an auxiliary output $X_{output}^{(i)}$ is generated, and an associated loss is calculated. The total loss function, $L_{total}$, combines the individual losses from all decoder levels, encouraging learning across multiple scales. This is formulated as:\n$$L_{total} = \\sum_{i=1}^{M} \\lambda_i L(X_{output}^{(i)}, Y)$$\nwhere:\n\u2022 Y is the ground truth segmentation map,\n\u2022 L denotes the segmentation loss function, typically pixel-wise cross-entropy,\n\u2022 $X_{output}^{(i)}$ is the predicted segmentation map at the i-th decoder level, and\n\u2022 $\\lambda_i$ are weights for each decoder level's contribution to the total loss."}, {"title": "5. U-Net integration across various medical imaging modalities", "content": "The integration of U-Net architectures in healthcare has transformed the way medical images are analyzed across various modalities, see Fig. 9. Designed specifically for tasks like segmentation, U-Net has proven highly adaptable, consistently delivering precise results in identifying and separating different structures within complex images. This section explores the application of U-Net in various imaging modalities, highlighting its effectiveness in enhancing diagnostic accuracy and supporting clinical decision-making."}, {"title": "5.1. U-Net Integration with X-ray", "content": "X-ray imaging, known for its accessibility and efficiency, gains enhanced diagnostic power through U-Net integration. Table 1 presents a summary of recent studies, applying U-Net in X-ray analysis, outlining focus areas, methodologies, and performance metrics."}, {"title": "5.2. U-Net Integration with MRI", "content": "MRI imaging gains improved segmentation accuracy with U-Net integration. Table 2 summarizes recent studies applying U-Net to MRI analysis."}, {"title": "5.3. U-Net Integration with CT scan", "content": "U-Net integration with CT scans improves segmentation accuracy, supporting more detailed and reliable diagnostic insights. This combination is particularly effective for detecting and delineating complex structures, such as tumors, organs, and tissues, where precise segmentation is critical for treatment planning and assessment. Table 3 summarizes recent work showcasing the advancements in U-Net and CT scan integration across various clinical applications."}, {"title": "5.4. U-Net Integration with Ultrasound", "content": "Ultrasound imaging, valued for its real-time and non-invasive capabilities, benefits from enhanced segmentation accuracy through U-Net integration as shown in the following table 4."}, {"title": "6. Limitations", "content": "U-Net and its variants are widely used in medical image segmentation. This section discusses the limitations of U-Net, U-Net++, and U-Net3+, as well as those of X-ray, MRI, CT, and Ultrasound (US) imaging modalities."}, {"title": "6.1. U-Net", "content": "U-Net's fixed-size convolutional kernels and pooling layers limit its receptive field, reducing the ability to capture long-range dependencies essential for segmenting large or complex structures. Downsampling leads to loss of fine spatial details, and skip-connections do not fully recover this information, affecting segmentation of small or intricate features."}, {"title": "6.2. U-Net++", "content": "U-Net++ enhances feature propagation with nested and dense skip connections, reducing the semantic gap between encoder and decoder features. However, this increases model complexity and the number of parameters significantly, leading to longer training times and greater computational resource requirements, which may be impractical for real-world applications. The higher parameter count elevates the risk of overfitting, especially on small datasets, degrading generalization performance on unseen data."}, {"title": "6.3. U-Net3+", "content": "U-Net3+ incorporates full-scale skip connections and deep supervision to integrate multi-scale features effectively. While this captures both high-level semantic information and low-level spatial details, it significantly increases architectural complexity and computational burden. The intricate architecture with multiple pathways and supervisory signals complicates the interpretability of the model. This makes it harder to analyze the contribution of each component to the final output, which is important for clinical validation and trust in medical applications."}, {"title": "6.4. X-Ray", "content": "X-ray imaging has poor soft-tissue contrast as it relies on differences in tissue density. This limitation makes it difficult to distinguish between soft tissues with similar densities, complicating accurate segmentation of organs or lesions. X-ray images are two-dimensional projections of three-dimensional structures, resulting in overlapping anatomical features and loss of depth information. This projection effect obscures critical details and complicates the segmentation task. Noise and artifacts, such as scatter radiation and motion blur, further degrade image quality and hinder segmentation algorithms."}, {"title": "6.5. MRI", "content": "MRI provides excellent soft-tissue contrast and multi-planar imaging capabilities. However, it is susceptible to artifacts such as magnetic susceptibility near metallic implants, causing signal voids or distortions. High operational costs and specialized equipment limit accessibility, resulting in smaller datasets for training models. Variations in MRI signals between scanners and imaging protocols lead to domain shift problems, affecting model generalization."}, {"title": "6.6. \u0421\u0422", "content": "CT imaging involves exposure to ionizing radiation, raising concerns about cumulative doses, especially for children and patients requiring multiple scans. Artifacts like beam hardening and motion introduce distortions that obscure anatomical details and complicate segmentation. Limited soft-tissue contrast compared to MRI makes differentiating soft tissues challenging without contrast agents."}]}