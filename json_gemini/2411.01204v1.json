{"title": "CLASS-SPECIFIC FEATURE SELECTION\nFOR CLASSIFICATION EXPLAINABILITY", "authors": ["Jes\u00fas S. Aguilar-Ruiz"], "abstract": "Feature Selection techniques aim at finding a relevant subset of features that perform equally or better\nthan the original set of features at explaining the behavior of data. Typically, features are extracted\nfrom feature ranking or subset selection techniques, and the performance is measured by classification\nor regression tasks. However, while selected features may not have equal importance for the task,\nthey do have equal importance for each class.\nThis work first introduces a comprehensive review of the concept of class-specific, with a focus\non feature selection and classification. The fundamental idea of the class-specific concept resides\nin the understanding that the significance of each feature can vary from one class to another. This\ncontrasts with the traditional class-independent approach, which evaluates the importance of attributes\ncollectively for all classes. For example, in tumor prediction scenarios, each type of tumor (class)\nmay be associated with a distinct subset of relevant features. These features possess significant\ndiscriminatory power, enabling the differentiation of one tumor type from others (classes). This\nclass-specific perspective offers a more effective approach to classification tasks by recognizing and\nleveraging the unique characteristics of each class.\nSecondly, classification schemes from one-versus-all and one-versus-each strategies are described,\nand a novel deep one-versus-each strategy is introduced, which offers advantages from the point\nof view of explainability (feature selection) and decomposability (classification). Thirdly, a novel\nclass-specific relevance matrix is presented, from which some more sophisticated classification\nschemes can be derived, such as the three-layer class-specific scheme.\nThe potential for further advancements in this area is wide and will open new horizons for exploring\nnovel research directions in interdisciplinary fields, particularly in complex, multiclass hyperdimen-\nsional contexts.", "sections": [{"title": "1 Introduction", "content": "Feature selection techniques [1, 2] have been widely discussed in the scientific literature as a task prior to classification,\nwhere a subset of variables is extracted from the original set of variables, such that with less information (only relevant\nvariables) similar knowledge (comparable classification performance) is maintained. In many applications, especially\nthose involving datasets containing a high number of variables, the use of feature selection techniques is crucial. This\nis not only because a prediction model can often provide similar or even better results with less information, thus\nimproving the computational efficiency of learning, but also because a smaller subset of variables can enhance our\nunderstanding of the data's behavior, i.e., provide us with greater explainability [3].\nThe genomics boom has led to the emergence of datasets with thousands of variables, exacerbating the well-known\nissue of \"the curse of dimensionality\". Furthermore, transposable elements have further increased dimensionality to the\norder of millions of variables [4]. This new scenario has introduced fresh challenges for existing algorithms and has"}, {"title": "2 Class-specific Feature Selection", "content": ""}, {"title": "2.1 Feature Selection", "content": "The concept of the curse of dimensionality originates from the foundational work of mathematician Richard Bellman in\napproximation theory [5]. It represents the important challenge of uncovering latent structures in variable-rich data\nsets. As the number of explanatory variables increases, so does the complexity of identifying these structures, closely\nlinked to the complex task of feature selection for model fitting. Bellman's articulation of the curse of dimensionality\nencapsulates this exponential increase in complexity, notably apparent in complex problems harboring a multitude of\nvariables, making dimensionality overwhelmingly unmanageable."}, {"title": "2.2 Related work", "content": "Baggenstoss made significant contributions to the development of a class-specific model of behavior, focusing on the\nseparation of attributes by class. In his earlier works [11, 12], he introduced the concept of class-specific modeling,\naimed at estimating low-dimensional probability density functions while maintaining the theoretical effectiveness\nof classification. Subsequent research by Baggenstoss [13, 14, 15] further elaborated the class-specific approach by\nemploying an invertible and differentiable multidimensional transformation to generate new features. This approach\nrepresents a feature extraction procedure rather than a mere selection of existing attributes from the dataset. In this\ncontext, the generated features are class-specifically derived or extracted, signifying that they are not subsets of the\noriginal dataset attributes, but are instead new features created through transformation processes."}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Notation", "content": "Let $D = (E, F, v, w)$ be a dataset, where $E$ is the set of example (or instance) identifiers, $F$ is the set of feature\n(variable) identifiers, $v : E \\times F \\rightarrow \\mathbb{R}$ is the function that assigns a real value to a pair $(e, f)$, where $e \\in E$ and $f \\in F$.\nWithin the field of supervised learning, when $w : E \\rightarrow L$ assigns a class label $c$ to an example $e$, with $L = \\{C_1, . . ., C_L\\}$,\nthen it is a classification problem; otherwise, if $L \\subset \\mathbb{R}$, then it is a regression problem. In absence of example"}, {"title": "3.2 Class-specific approaches", "content": "Let us assume the dataset $D$ contains $L = |L|$ classes, i.e., it is a multiclass problem. Let $D_c = \\{e \\in E | w(e) = c\\}$ be\nthe subset of examples in $D$ that belong to class $c \\in L$. Two main algorithmic approaches can be used to address the\nproblem of class-specific feature selection for multiclass datasets, as described next."}, {"title": "One-versus-All (OvA)", "content": "The method transforms a $L$-class problem into $L$ binary problems in order to determine the most relevant attributes\nfor each class versus the others. The algorithm provides the same class to all the examples in $D \\setminus D_p$ (i.e., negative\nexamples) while maintaining the class of $D_p$ (i.e., positive examples) during binarization process $(binarize)$, and then\ncalculate the measure for each partition of data (class p)."}, {"title": "One-versus-Each (OvE)", "content": "This approach deals with one class against each other (pairwise), and was introduced in [17]. The authors defined a\nmeasurement of how well a class is separated by a feature vector from the remaining classes, by adding the separation\nbetween a class and each other."}, {"title": "4 Discussion", "content": "The most widely adopted approach in class-specific contexts is the OvA technique. From a classification standpoint,\nthere is a substantial difference between opting for an OvA strategy versus an OvE strategy. Although both strategies\nyield the same type of output -a ranking of features where each feature is assigned a quality measure\u2014 the information\nencapsulated within these results differs. Algorithm 1 calculates feature scores based on their ability to discriminate one\nclass against all others collectively, while Algorithm 2 determines how well each feature distinguishes one class from\neach of the others individually, and then the function aggregate compiles these individual scores into a single value.\nTo illustrate how these strategies influence classification, consider a simple example: a dataset $D$ comprising four\nclasses ($L = \\{A, B, C, D\\}$) and nine attributes ($F = \\{f_1,..., f_9\\}$). Without loss of generality, let us suppose that\nall values returned by the function measure fall within the range [0, 1]. The higher the value, the greater the feature"}, {"title": "4.1 Deep one-against-each", "content": "A further step in class-specific selection strategies is to explore pairwise selection in more detail. In the example with\nfour classes, $\\Psi_p$ would contain 3 pairs (see in Algorithm 2 the line marked with *), and the function aggregate would\ncalculate one value from those three. The OvE strategy (Algorithm 2) does not return the discriminating power of a\nfeature for a class against each other, but it computes for a class p all the measures for the pair (p, q), for all q, and then\nan aggregation function returns a single value of merit for class p. However, if we keep and analyze those values, we"}, {"title": "4.2 Class-specific relevance matrix", "content": "The concept of explainability could be enhanced through a more thorough analysis of features from a class-specific\nperspective. From the information collected in Table 3, we can define a novel matrix, which we call the class-specific\nrelevance matrix, and which contains very valuable information on the relevant features among classes. This new matrix\nsignificantly contributes to explainability, suggesting that more sophisticated classification schemes could be designed.\nWhen for all pairs including class p the value is greater than the threshold (in red in Table 3), that feature will appear in\nthe class-specific relevance matrix in the diagonal corresponding to class p, as shown in Table 4. This way, we first\ncalculate all the relevant features in the diagonal: $A \\rightarrow \\{f_9\\}$, $B \\rightarrow \\{f_2, f_5\\}$, $C \\rightarrow \\{\\}$, and $D \\rightarrow \\{f_2, f_5\\}$. To calculate\nthe feature set for any position in the matrix outside the diagonal, for instance (A,B), we start with the join of diagonal\nelements of A and B, i.e., $\\{f_9\\} \\cup \\{ f_2, f_5\\}$, and then the row (A, B) in Table 3 is examined to identify any other feature\nin red, in this case, $\\{f_1\\}$, which is placed in row (A, B) in Table 4. For instance, position (A, D) is empty because the\njoin of A and D is exactly what is indicated in row (A, D) in Table 3.\n\nThe classification scheme presented in Figure 4 can also be inferred from the class-specific relevance matrix shown in\nTable 4. However, from the class-specific relevance matrix it would be possible to further deepen the explainability and\ndesign novel classification schemes. For instance, a potential scheme from Table 4 is introduced in Figure 5, which\nwe call three-layer class-specific classification scheme. A first layer individually separates classes (taken from the\ndiagonal of class-specific relevance matrix), a second layer examines the discriminatory power of pair of classes, and\na third layer integrates all the knowledge for each class. In general, for L classes, the total number of discriminative\nnodes in the three-layer scheme will be $(\\frac{L(L-1)}{2}+L)$.\nIn conclusion, by integrating machine learning explainability with class-specific feature selection, practitioners can\nobtain a comprehensive and detailed insight into the functioning of models, particularly in situations where distinguishing\nbetween multiple classes is paramount. The collaboration of these concepts plays a pivotal role in building machine\nlearning models that are not only accurate but also trustworthy and interpretable."}, {"title": "5 Conclusions", "content": "Undoubtedly, the information provided by class-specific techniques is richer than that provided by class-independent\ntechniques. In fact, a class-independent result could be obtained from a class-specific one. The knowledge inherent\nin the results of class-specific strategies contains a greater level of detail and, therefore, rises to a higher level of\nexplainability.\nSeveral class-specific approaches mentioned in Related Work have built classifier ensembles based on a one-layer\nstructure. However, more sophisticated decomposable structures can be designed, such as the two-layer or three-layer\nclassification schemes. Therefore, class-specific approaches can substantially contribute to decompose the complexity\nof classification models, and thus to better understand and interpret the models. Even when using black-box models\n(e.g., deep learning-based ones) as units of the ensemble, these can use the knowledge from the class-specific relevance\nmatrix to build simpler classifiers, notably reducing the overall complexity of the classification.\nThe potential for advancement in the class-specific topic is highly promising, given the very sparse scientific literature\ncurrently available. Recent research highlights a growing interest in explainability (and its related concepts) within\nArtificial Intelligence, which is likely poised for significant expansion in the near future. Consequently, developing\nmethods that leverage class-specific strategies, especially in the context of multiclass high-dimensional data, could\nfacilitate knowledge transfer across domains. The scientific landscape, therefore, offers vast and appealing opportunities\nfor future research work."}]}