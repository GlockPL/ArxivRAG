{"title": "ERROR BOUNDS FOR DEEP LEARNING-BASED UNCERTAINTY PROPAGATION IN SDES", "authors": ["Chun-Wei Kong", "Jay McMahon", "Luca Laurenti", "Morteza Lahijanian"], "abstract": "Stochastic differential equations are commonly used to describe the evolution of stochastic processes. The uncertainty of such processes is best represented by the probability density function (PDF), whose evolution is governed by the Fokker-Planck partial differential equation (FP-PDE). However, it is generally infeasible to solve the FP-PDE in closed form. In this work, we show that physics-informed neural networks (PINNs) can be trained to approximate the solution PDF using existing methods. The main contribution is the analysis of the approximation error: we develop a theory to construct an arbitrary tight error bound with PINNS. In addition, we derive a practical error bound that can be efficiently constructed with existing training methods. Finally, we explain that this error-bound theory generalizes to approximate solutions of other linear PDEs. Several numerical experiments are conducted to demonstrate and validate the proposed methods.", "sections": [{"title": "1 INTRODUCTION", "content": "Stochastic differential equations (SDEs) are widely used to model the evolution of stochastic processes across various fields like sciences, engineering, economics, and finance. In many of these applications, particularly in safety-critical domains, a key concern is understanding how uncertainty of the process modeled by SDE propagates over space and time. This uncertainty is often represented by a probability density function (PDF) and is governed by the Fokker-Planck partial differential equation (FP-PDE). However, solving the FP-PDE is generally computationally expensive and prone to numerical errors, except in simple cases (Spencer & Bergman, 1993; Drozdov & Morillo, 1996; Tabandeh et al., 2022). Recent advancements suggest using deep-learning frameworks, called physics-informed neural networks (PINNs), to approximate PDE solutions with notable success (Sirignano & Spiliopoulos, 2018; Lu et al., 2021). Despite their effectiveness, PINNs are still subject to approximation errors, a crucial concern in safety-critical systems. In this work, we tackle this challenge by developing a method to approximate the PDF of an SDE using PINNs and rigorously bound the approximation error.\nRecent works on using PINNs to approximate solutions to PDEs typically analyze approximation errors in terms of total error, representing the cumulative error across all space and time (De Ryck & Mishra, 2022b;a; Mishra & Molinaro, 2023; De Ryck et al., 2024). While this approach may be useful in some applications, it is less informative for SDEs and uncertainty propagation in stochastic processes. Moreover, total error bounds are often overly loose, sometimes exceeding the actual errors by several orders of magnitude. Crucially, these bounds do not provide insight into the worst-case approximation error at specific time instances or within particular subsets of space, which is essential in many stochastic systems. For example, in autonomous driving scenarios involving pedestrian crossings, accurately prediction and bounding the probability of collision requires precise reasoning over specific time instances and spatial regions. Loose over-approximations can lead to undesirable behaviors, such as sudden braking.\nIn this work, we show how PINNs can be used to approximate PDFs of processes modeled by SDEs and, more importantly, introduce a method for tightly bounding the approximation error as a function of time and space. Our key insight is that the error is related to the residual of the FP-PDE and is governed by the same equation. Thus, a second PINN can be used to learn the error, with its own error also following the FP-PDE. This leads to a recursive formulation of error functions, each of which can be approximated using a PINN. We establish sufficient training conditions under which this series converges with a finite number of terms. Specifically, we prove that two PINNS are enough to obtain arbitrarily tight error bounds. Additionally, we derive a more practical bound requiring only one error PINN at the cost of losing arbitrary tightness, and provide a method to verify its sufficient condition. Finally, we illustrate and validate these error bounds through experiments on several SDEs, supporting our theoretical claims.\nIn short, the main contribution is five-fold:\n\u2022 a method for approximating the PDF of processes modeled by SDEs using PINNs,\n\u2022 a novel approach to tightly bound the approximation error over time and space through a recursive series of error functions learned by PINNs,\n\u2022 a proof that this recursive process converges with only two PINNs needed for arbitrarily tight bounds,\n\u2022 the derivation of a more practical error bound requiring just one PINN, along with a method to verify its sufficiency, and\n\u2022 validation of the proposed error bounds through experiments on several SDEs."}, {"title": "1.1 RELATED WORK", "content": "Research on approximating solutions to PDEs using PINNs often focuses on estimating the total error, which represents the cumulative error across all time and space. For instance, (Mishra &\nMolinaro, 2023) provide an abstract upper bound on the total error, expressed in terms of training error, the number of training samples, and constants related to the stability of PDEs. Their numerical experiments reveal that this total error bound is loose, exceeding the actual errors by nearly three or-ders of magnitude. Similarly, De Ryck & Mishra (2022a) consider FP-PDE equations deriving from linear stochastic differential equations. They propose an abstract approach to bound the total error in terms of training error and some constants related to the PDEs, but they do not present numerical experiments. In another approach, (De Ryck & Mishra, 2022b) propose a general framework to derive different types of total error bounds for PINNs and operators, while (De Ryck et al., 2024) estimate the total error for Navier-Stokes PDEs. In contrast to these works, this work emphasizes bounding the worst-case error at any specific time. This focus is particularly valuable in practical applications of stochastic systems.\nError analysis is a well-established area focused on demonstrating the approximation capabilities of neural networks. For example, Hornik (1991) proves that a standard multi-layer feed-forward neural network can approximate a target function such that the generalization is arbitrarily small. Yarotsky (2017) considers the worst-case error and shows that deep ReLU neural networks are able to approximate universal functions in the Sobolev space. More recently, deep operator nets (DeepONet) have been suggested to learn PDE operators, with (Lanthaler et al., 2022) proving that for every \u20ac > 0, there exists DeepONets such that the total error is smaller than \u20ac. While these studies establish that the approximation error (whether in terms of average or worst-case) can be made arbitrarily small, they do not address the critical question: what are the error bounds for a given approximate solution? This is the central issue tackled by this work.\nError estimates have also been studied when neural networks are trained as surrogate models for given target functions. For instance, Barron (1994) derives the total error between given the training configurations and the target function. More recently, Yang et al. (2022) propose to estimate the worst-case approximation error given the target function. A fundamental difference between our work and these studies is that we do not have the target function or model."}, {"title": "2 PROBLEM FORMULATION", "content": "The aim of this work is uncertainty propagation with quantified error bounds for continuous time and space stochastic processes using deep neural networks. We specifically focus on stochastic processes described by the following (possibly nonlinear) Stochastic Differential Equations (SDE),\n\n$dx(t) = f(x(t),t)dt + g(x(t), t)dw(t)$,\n\nwhere t\u2208TC R>0 is time, x(t) \u2208 X \u2286 Rn is the state of the system at time t, and w(t) \u2208 Rm is a standard Brownian motion. For \u03a9 = X XT, function f : \u03a9 \u2192 R represents the deterministic evolution of the system, and function g : \u03a9 \u2192 Rnxm is a term that defines the coupling of the noise. We assume that f(x, t) and g(x, t) are locally Lipschitz continuous in x, and denote the i-th dimension of f and (j, k)-th element of g by fi and gjk, respectively. The initial state x(0) is a random variable distributed according to a given probability density function (PDF) po : X \u2192 R\u22650, i.e., x(0) ~ po. We assume that po is bounded and sufficiently smooth\u00b9.\nThe solution to the SDE in equation 1 is a stochastic process a with a corresponding PDF p :\n\u03a9 \u2192 R>o over space and time, i.e., x(t) ~ p(., t) (\u00d8ksendal, 2003). PDF p is governed by the Fokker-Planck (FP) partial differential equation (PDE):\n\n$\\frac{\\partial p(x, t)}{\\partial t} + \\sum_{i=1}^{n} \\frac{\\partial}{\\partial x_i} [f_i p(x,t)] - \\frac{1}{2} \\sum_{i=1,j=1}^{n} \\frac{\\partial^2}{\\partial x_i \\partial x_j} \\Big[\\sum_{k=1}^{m} g_{ik}g_{jk} p(x,t)\\Big] = 0,$ (2)\n\nand must satisfy the initial condition\n\n$p(x, 0) = p_0(x) \\quad \\forall x \\in X$. (3)\n\nTo simplify notation, we denote by D[\u00b7] the differential operator associated with the FP-PDE:\n\n$D[\u00b7]:= \\frac{\\partial}{\\partial t} + \\sum_{i=1}^{n} \\frac{\\partial}{\\partial x_i} [f_i \u00b7] - \\frac{1}{2} \\sum_{i=1,j=1}^{n} \\frac{\\partial^2}{\\partial x_i \\partial x_j} \\Big[\\sum_{k=1}^{m} g_{ik}g_{jk} \u00b7\\Big].$ (3)\n\nThen, equation 2 and equation 3 can be rewritten in a compact form as\n\n$D[p(x, t)] = 0, \\quad \\text{subject to} \\quad p(x, 0) = p_0(x)$. (4)\n\nNote that, since f and g are assumed to be locally Lipschitz continuous, the PDE in equation 4 is well-posed, i.e., there exists a sufficiently smooth and unique solution p (Evans, 2022), (Karatzas &\nShreve, 2014, Ch. 5, Theorem 2.5).\nComputation of p in closed form is generally not possible, and even numerical approaches are limited to simple SDEs (Spencer & Bergman, 1993; Drozdov & Morillo, 1996; Tabandeh et al., 2022). In this work, we focus on using PINNs to approximate p, and crucially, we aim to formally bound the resulting approximation error.\nProblem 1 Given stochastic process x(t) described by the SDE in equation 1, a bounded subset X'CX, and a time interval T, train a neural network p(x,t) that approximates p(x,t), and for every t \u2208 T construct \u0435\u0432 : \u0422 \u2192 R>0 such that\n\n$\\sup_{x \\in X'} |p(x, t) - \\hat{p}(x,t)| \\leq \\epsilon_B(t)$. (5)"}, {"title": "3 APPROXIMATING PDF VIA PINN", "content": "Given the PDE in equation 4, as common in physics-informed deep learning, we approximate p by learning a neural network p(x, t; 0), where 0 represents the parameters of the neural network. For training, spatial-temporal data points {(xj,0);}, {(xj, tj);}=1 C, for some No, \u039d, \u0395\u039d, are sampled, and the loss function is derived from the governing physics in equation 4 as L WoLo + wrLr, where wo, wr \u2208 R+ are the weights, and\n\n$L_o = \\frac{1}{N_o} \\sum_{j=1}^{N_o} ||p_0(x_j) - \\hat{p}(x_i, 0; \\theta)||_2^2, \\qquad L_r = \\frac{1}{N_r} \\sum_{j=1}^{N_r} |D[\\hat{p}(x_j, t_j; \\theta)]|^2.$ (6)\n\nThe loss function in equation 6 quantifies the deviation of the true and approximate solution in terms of the boundary condition (L0) and the infinitesimal variation over space and time (L) (Sirignano &\nSpiliopoulos, 2018). The parameters of p(x, t; 0) are learned by minimizing 0* = arg min L.\nAssumption 1 p is assumed to be at least twice continuously differentiable with respect to x and continuously differentiable with respect to t with bounded derivatives.\nAssumption 1 is present because \u00ea\u00ee is trained by the physics-informed loss in equation 6, in which the second term Lr requires the computation of the first and second derivatives with respect to time and space, respectively. To satisfy Assumption 1, smooth activation functions (e.g., Tanh and Softplus) can to be used in the architecture of p(x, t; 0). For instance, this assumption is satisfied by a fully connected NN with twice differentiable activation functions.\nOur training approach for p follows existing methods to approximate PDE solutions using PINNs; see Appendix B for more details. The key difference is that we provide error bounds on the approximation error as detailed in the next section."}, {"title": "4 BOUNDING APPROXIMATION ERROR", "content": "In this section, we derive bounds for the approximation error e(x,t) := p(x,t) \u2013 p(x,t). We first characterize e(x, t) as a series of approximate solutions to PDEs. Then, we show that, by training just two PINNs under certain sufficient conditions, the series can be bounded, resulting in arbitrary tight bound on e(x,t). While these conditions are feasible, they may be challenging to verify in practice. To that end, we finally introduce a more practical bound that requires training of only one PINN, albeit at the cost of losing arbitrary tightness. All the proofs are provided in the appendix.\nNote that FP-PDE operator D is a linear operator; hence, by applying it to e(x, t), we obtain:\n\n$D[e] = D[p - \\hat{p}] = D[p] \u2013 D[\\hat{p}].$\n\nAs D[p] = 0, we can see that the error is essentially related to the residue of D[p]. Then, we can define the governing PDE of e(x, t) as\n\n$D[e(x, t)] + D[\\hat{p}(x,t)] = 0 \\quad \\text{subject to} \\quad e(x, 0) = p_0(x) - \\hat{p}(x, 0)$. (7)\n\nHence, using a similar approach as in Section 3, a PINN can approximate e(x, t) in equation 7. Based on this, we can define the i-th error and its associated approximation in a recursive manner."}, {"title": "4.1 n-TH ORDER SPACE-TIME ERROR BOUND (n > 2)", "content": "Here, we derive a generalized error bound for e(x,t) with approximation error PINNs \u00eai, where i = 1,..., n for n > 2. Note that an alternative way to express the error bound in Theorem 1 is as an interval e(x, t) \u2208 [ \u2013 \u0435\u0432(t), \u0435\u0432(t)], which is uniform over x for any t \u2208 T. Below, we show that, for n > 2, an error bound that depends on both space and time can be constructed.\nCorollary 1 (Space-time Error Bound) Consider PINNs \u00ea\u00bf(x, t), i = 1, . . ., n, for some n > 2 trained per Def.1 such that an-1 and an satisfy Conditions 16, and define the n-th order temporal error bound to be\n\n$\\epsilon_B(t) = \\hat{e}_{n-1}(t)\\Big( \\frac{1}{1-\\gamma_n(t)}\\Big),$ \n\nwhere \u00ean\u22121(t) is defined in equation 12, and yn (t) = \u00ean(t)/\u00ean-1(t). Then,\n\n$e(x,t) \\in [\\sum_{i=1}^{n-2} e_i(x,t) - \\epsilon_n(t), \\sum_{i=1}^{n-2} e_i(x,t)+\\epsilon_n(t)].$ (20)\n\nThis corollary shows that, even though 2-nd order error approximation is sufficient to obtain a tempo-ral bound (Theorem 1), higher order approximations lead to more information, i.e., space in addition to time, on the error bound."}, {"title": "4.2 FIRST ORDER TEMPORAL ERROR BOUND (n = 1)", "content": "We also present a temporal error bound by learning only the first error approximation function \u00ea1, which removes the dependence on a2 at the cost of losing the arbitrary tightness property.\nCorollary 2 (First order temporal error bound) Let \u00ea\u2081 be trained such that x1(t) < 1 for all te T. Then\n\n$|e(x,t)|  2\\hat{e}_1(t)$. (21)\n\nNote that, while the first-order error bound es (t) is at most twice larger than the arbitrary tight error bound \u0435\u0432 (t) in Theorem 1, it has significant practical uses. Firstly, it only requires training of one PINN, i.e., \u00ea\u2081. Secondly, the condition a1(t) < 1 can be checked during training of \u00ea\u2081 using properties of the FP-PDE as detailed below."}, {"title": "6 CONCLUSION", "content": "We introduced a physics-informed learning method to approximate the PDF of an SDE and bound its error using a series of recursive error functions learned with PINNs. We proved that only a finite number of recursive steps are required to bound the error, with two error terms being sufficient to achieve arbitrarily tight bounds at any time instance. We also developed a more efficient approach by constructing a first order temporal error bound using just one error function, which reduces computation, provides clear termination criteria, and yields bounds at most twice as loose as the tightest ones. This method was validated on several non-Gaussian dynamical systems. In our implementation, we trained the solution and error functions separately but hypothesize that jointly training them could improve performance. Future work will explore this joint training approach."}, {"title": "A PROOFS", "content": null}, {"title": "A.1 PROOF OF LEMMA 1", "content": "Proof 1 From Definition 1, we have that, for all x \u2208 X',\n\n$|p(x,t) - \\hat{p}(x,t)| = |\\sum_{i=1}^{n} \\hat{e}_i (x, t) +e_{n+1}(x, t)| \\leq \\sum_{i=1}^{n} |\\hat{e}_i(x, t)| + |e_{n+1}(x,t)|$\n\n$\\leq \\sum_{i=1}^{n} \\max_{X'} |\\hat{e}_i(x, t)| + \\max_{X'}|e_{n+1}(x,t)| := \\sum_{i=1}^{n} \\hat{e}_{i}(x,t)+ |e_{n+1}(x,t)|.$\n\nFrom the definition of \u03b3i+1 in equation 13, we obtain (omitting t for simplicity of presentation)\n\n$|p(x,t) - \\hat{p}(x,t)| \\leq  \\hat{e}_1 \\Big[1+ \\frac{\\hat{e}_2}{\\hat{e}_1} + \\frac{\\hat{e}_3}{\\hat{e}_2} + \\dots + \\frac{\\hat{e}_{n-1}}{\\hat{e}_{n-2}} + \\frac{e_n}{\\hat{e}_{n-1}}\\Big] = \\hat{e}^*_1 \\Big[1 + \\frac{ \\hat{e}_2}{\\hat{e}_1} + \\gamma_2 \\frac{ \\hat{e}_3}{\\hat{e}_2} + \\dots + \\gamma_2...\\gamma_{n-1} \\frac{\\hat{e}_{n-1}}{\\hat{e}_{n-2}} + \\gamma_2... \\gamma_{n-1} \\frac{e_n}{\\hat{e}_{n-1}}\\Big]$\n\n$: = \\hat{e}^*_1 \\Big[1 + \\gamma_2 + \\gamma_2 \\gamma_3 + \\dots + (\\gamma_2 ...\\gamma_{n-1})+(\\gamma_2... \\gamma_{n-1})  \\frac{e_n}{\\hat{e}_{n-1}}\\Big]$.\n\n$:=\\hat{e}^*_1 \\Big[1 + \\gamma_2 + \\gamma_2 \\gamma_3 + \\dots + (\\gamma_2 ...\\gamma_{n-1})+(\\gamma_2... \\gamma_{n-1})  \\frac{e_{n+1}}{\\hat{e}_{n}}\\Big]$"}, {"title": "A.2 PROOF OF LEMMA 2", "content": "Proof 2 From Definition 1, we have, for i \u2265 0,\n\n$e_i(x,t) = \\hat{e}_i(x, t) + e_{i+1}(x, t)$. (23)"}, {"title": "A.3 PROOF OF LEMMA 3", "content": "Proof 3 For simplicity of presentation, we omit writing the dependent variable t. Assume the con-ditions in equation 16 are satisfied; then it is true that 0 < 2 < 1. Since both \u03b11, 2 < 1, by Lemma 2 and Condition equation 16b, we obtain\n\n$\\frac{\\gamma_1}{\\gamma_2} \\leq \\frac{\\frac{\\alpha_1}{1+\\alpha_1}}{\\frac{\\alpha_2}{1-\\alpha_2}} < \\frac{\\alpha_1}{1-\\alpha_2} < 1,$\n\nproving the RHS of equation 17.\nFor the LHS of equation 17, let ai \u2264 x2 for all 2 < i < n. Since a2 < 1, then by Lemma 2, we have\n\n$\\frac{\\gamma_{i+1}}{\\gamma_{i}} \\leq \\frac{\\alpha_{i-1}}{1+\\alpha_{i}} \\leq \\frac{\\alpha_{i-1}}{1-\\alpha_{i}} \\leq \\frac{\\alpha_{2}}{1-\\alpha_{2}}.$\n\nWhat remains is to show that RHS of equation 28 is  y. From Condition equation 16c, we have\n\n$\\alpha_2(1 + \\alpha_2) < \\alpha_1^2$  $\\longrightarrow \\frac{\\alpha_2}{\\alpha_1} < \\frac{\\alpha_1}{1+\\alpha_2}$. (29)\n\n where equation 30 holds by Condition equation 16b. From equation 30, we obtain\n\n$\\frac{\\alpha_1}{1 - \\alpha_2} < \\frac{\\alpha_1}{1 + \\alpha_2}$.\n\nBy combining Eqs. equation 28 and equation 31, we have\n\n$\\frac{\\gamma_1}{\\gamma_2} < \\frac{\\alpha_1}{1 + \\alpha_2} < \\gamma \\quad 2 \\0$\n\n$\\ue_B = \\hat{\\ue_1} (\\gamma - \\frac{\\frac{e*_{n+1}}{\\hat{e}*_{n-1}}}{1 - \\gamma})$$"}]}