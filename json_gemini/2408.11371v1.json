{"title": "Solving Decision Theory Problems with Probabilistic Answer Set Programming", "authors": ["Damiano Azzolini", "Elena Bellodi", "Rafael Kiesel", "Fabrizio Riguzzi"], "abstract": "Solving a decision theory problem usually involves finding the actions, among a set of possible ones, which optimize the expected reward, possibly accounting for the uncertainty of the environment. In this paper, we introduce the possibility to encode decision theory problems with Probabilistic Answer Set Programming under the credal semantics via decision atoms and utility attributes. To solve the task we propose an algorithm based on three layers of Algebraic Model Counting, that we test on several synthetic datasets against an algorithm that adopts answer set enumeration. Empirical results show that our algorithm can manage non trivial instances of programs in a reasonable amount of time. Under consideration in Theory and Practice of Logic Programming (TPLP).", "sections": [{"title": "1 Introduction", "content": "Logic-based languages are well-suited to model complex domains, since they allow the representation of complex relations among the involved objects. Probabilistic logic languages, such as ProbLog (De Raedt et al. 2007) and Probabilistic Answer Set Programming under the credal semantics (Cozman and Mau\u00e1 2020), represent uncertain data with probabilistic facts (Sato 1995), i.e., facts with an associated probability. The former is based on the Prolog language (Lloyd 1987), while the latter adopts Answer Set Programming (ASP) (Brewka et al. 2011). ASP has been proved effective in representing hard combinatorial tasks, thanks to expressive constructs such as aggregates (Alviano and Faber 2018). Moreover, several extensions have been proposed for"}, {"title": "2 Background", "content": "This section introduces the basic concepts of Answer Set Programming and Probabilistic Answer Set Programming."}, {"title": "2.1 Answer Set Programming", "content": "In the following, we will use the verbatim font to denote code that can be executed with a standard ASP solver. Here we consider a subset of ASP (Brewka et al. 2011). An ASP program (or simply an ASP) is a finite set of disjunctive rules. A disjunctive rule (or simply rule) is of the form\n\nwhere every $h_i$ is an atom and every $b_i$ is a literal. We consider only safe rules, where every variable in the head also appears in a positive literal in the body. This is a standard requirement in ASP. If the head is empty, the rule is called a constraint, if the body is empty and there is only one atom in the head, the rule is called a fact, and if there is only one atom in the head with one or more literals in the body the rule is called normal. A choice rule is of the form 0{a}1 :- b\u2081,...,bn and indicates that the atom a can be selected or not if the body is true. Usually, we will omit 0 and 1 and consider them implicit. ASP allows the use of aggregate atoms (Alviano and Faber 2018) in the body. We consider aggregates of the form #\u03c6{\u20ac0; ... ; \u20acn} dg where g is called guard and can be either a constant or a variable, d is a comparison arithmetic operator, \u03c6 is an aggregate function symbol, and \u20ac0,..., En is a set of expressions where each $e_i$ has the form t1,..., tn : F and each $t_i$ is a term whose variables appear in the conjunction of literals F. An example of aggregate atom is #count{A : p(A)} = 2, that is true if the number of ground substitutions for A that make p(A) true is 2. Here, 2 is the guard, and #count is the aggregate function symbol. The primal graph of a ground answer set program P is such that there is one vertex for each atom appearing in P and there is an undirected edge between two vertices if the corresponding atoms appear simultaneously in at least one rule of P.\nThe semantics of ASP is based on the concept of answer set, also called stable model. With $B_P$ we denote the Herbrand base of an answer set program P, i.e., the set of ground atoms that can be constructed with the symbols in P. A variable is called local to an aggregate if it appears only in the considered aggregate; if instead it occurs in at least one literal not involved in aggregations, it is called global. The grounding of a rule with aggregates proceeds in two steps, by first replacing global variables with ground terms, and then replacing local variables appearing in aggregates with ground terms. An interpretation I of P is a subset of $B_P$. An aggregate is true in an interpretation I if the evaluation of the aggregate function under I satisfies the guards. An interpretation I satisfies a ground rule if at least one of the $h_i$s is true in it when all the $b_i$s are true in it. A model of P is an interpretation that satisfies all the groundings of all the rules"}, {"title": "2.2 Probabilistic Answer Set Programming (PASP)", "content": "PASP extends ASP by representing uncertainty with weights (Lee and Wang 2016) or probabilities (Cozman and Mau\u00e1 2016) associated with facts. Here we consider PASP under the credal semantics (CS) (Cozman and Mau\u00e1 2016). We will use the acronym PASP to also denote a probabilistic answer set program, the intended meaning will be clear from the context.\nPASP allows probabilistic facts of the form (De Raedt et al. 2007) \u03a0\u2081 :: fi where \u03a0\u2081 \u2208 [0,1] and fi is an atom. We only consider ground probabilistic facts. Moreover, we require that probabilistic facts cannot appear in the head of rules, a property called disjoint condition (Sato 1995). Every possible subset of probabilistic facts (there are 2n of them, where n is the number of probabilistic facts) identifies a world w, i.e., an ASP obtained by adding the atom of the selected probabilistic facts to the rules of the program. Each world w is assigned a probability computed as\n\nWith this setting, we have two levels to consider: at the first level, we need to consider the worlds, each with an associated probability. At the second level, for each world we have one or more answer sets. Since a world may have more than one model, in order to assign a probability to queries we need to decide how the probability mass of the world is distributed on its answer sets. We can choose a particular distribution for the answer sets of a world, such as a uniform (Totis et al. 2023) or a distribution that maximizes the entropy (Kern-Isberner and Thimm 2010). However, here we follow the more general path of the credal semantics and we refrain from assuming a certain distribution for the answer sets of a world. This implies that queries are associated with probability"}, {"title": "3 DTProbLog", "content": "DTProbLog extends the ProbLog language with a set D of (possibly non-ground) decision atoms represented with the syntax ? :: d where d is an atom, and a set U of utility attributes of the form u \u2192 r, where r\u2208 R is the reward obtained when the utility atom u is satisfied. In the rest of the paper, we will use the terms utility and reward interchangeably and we will use the notation utility(u,r) in code snippets to denote utility attributes. A set \u03c3 of decision atoms defines a strategy \u03c3. There are $2^{|D|}$ possible strategies. A DTProbLog program is a tuple (P, U, D) where P is a ProbLog program, U is a set of utility attributes, and D a set of decision atoms. Given a strategy \u03c3, adding all decision atoms from \u03c3 to P yields a ProbLog program $P_\u03c3$. The utility of a strategy \u03c3, Util(\u03c3), is given by:\n\nwhere"}, {"title": "4 Second Level Algebraic Model Counting", "content": "Kiesel et al. (2022) introduced Second Level Algebraic Model Counting (2AMC), needed to solve tasks such as MAP inference (Shterionov et al. 2015) and Decision theoretic inference (Van den Broeck et al. 2010), in Probabilistic Logic Programming, and inference in smProbLog (Totis et al. 2023) programs. These problems are characterized by the need for two levels of Algebraic Model Counting (2AMC) (Kimmig et al. 2017).\nThe ingredients of a 2AMC problem are:\n\u2022 a propositional theory II;\n\u2022 a partition (Vi, Vo) of the variables in II;\n\u2022 two commutative semirings (Gondran and Minoux 2008) $R_i = (R^i, \u2295^i, \u2297^i, n_0^i, n_1^i)$ and $R_o = (R^o, \u2295^o, \u2297^o, n_0^o, n_1^o)$;\n\u2022 two weight functions, $w_i$ and $w_o$, associating each literal of the program with a weight; and\n\u2022 a transformation function f mapping the values of $R^i$ to those of $R^o$\nLet us denote with T the tuple (II, Vi, Vo, Ri, Ro, wi, wo, f). The task requires solving:\n\nwhere \u03bc(Vo) is the set of possible assignments to the variables in $V_0$ and $\u03c6(\u03a0 | I_o)$ is the set of possible assignments to the variables in II that satisfy $I_o$. In practice, for every possible assignment of the variables V, we need to solve a first AMC task on the variables Vi. Then, the transformation function maps the obtained values into elements of the outer semiring and we need to solve a second AMC task, this time by considering Vo.\nWithin 2AMC, the DTProbLog task can be solved by considering (Kiesel et al. 2022)\n\u2022 as Vo the decision atoms and as Vi the remaining literals;\n\u2022 as inner semiring the gradient semiring (Eisner 2002) $R_i = (R^2, +, \u2297, (0,0), (0, 1))$ where + is component-wise and $(a_o, b_o) \u2297 (a_1, b_1) = (a_o \u00b7 a_1, a_o \u00b7 b_1 + a_1 \u00b7 b_o)$;\n\u2022 as inner weight function $w_i$ mapping a literal v to (p,0) if v = a where a is a probabilistic fact p :: a, to (1 \u2212 p,0) if v = not a where a is a probabilistic fact p :: a, and all the other literals to (1,r) where r is their utility;\n\u2022 as transformation function $f(p, u) = (u, -\u221e)$ if $p \\neq 0$ and $f(0, u) = (-\u221e, D)$;\n\u2022 as outer semiring $R_o = (R \u00d7 2^{|D|}, \u2295, \u2297, (\u2212\u221e, \u2205), (0, \u2205))$ where $(a_o, b_o) + (a_1, b_1)$ is equal to $(a_o, b_o)$ if $a_o > a_1$, otherwise $(a_1, b_1)$ and $(a_o, b_o) \u2297 (a_1, b_1) = (a_o + a_1, b_o \u222a b_1)$; and\n\u2022 as outer weight function $w_o = (0, {a})$ if a is a decision atom, $(0, \u2205)$ otherwise.\nKiesel et al. (2022) also extended the aspmc tool (Eiter et al. 2021) to solve 2AMC tasks. aspmc converts a program into a tractable circuit (knowledge compilation) by first grounding it and then by generating a propositional formula such that the answer sets of the original program are in one-to-one correspondence with the mod-"}, {"title": "5 Representing Decision Theory Problems with Probabilistic Answer Set Programming", "content": "Following DTProbLog (Van den Broeck et al. 2010), we use utility(a, r) to denote utility attributes where a is an atom and r \u2208 R indicates the utility of satisfying it. For example, with utility(a, -3.3) we state that if a is satisfied we get a utility of -3.3. A negative utility represents, for example, a cost, while a positive utility represents a gain. We use the functor decision to denote decision atoms. For example, with decision a we state that a is a decision atom. A decision atom indicates that we can choose whether to perform or not to perform the specified action. We consider only ground decision atoms.\nDefinition 2\nA decision theory probabilistic answer set program DTPASP is a tuple (P, D,U) where P is a probabilistic answer set program, D is the set of decision atoms, and U is the set of utility attributes.\nSince in PASP queries are associated with a lower and an upper probability, in DT-PASP we need to consider lower and upper rewards and look for the strategies that maximize them. A strategy is, as in DTProbLog, a subset of the possible actions. Having fixed a strategy \u03c3, we obtain a PASP $P_\u03c3$ that generates a set of worlds. Each answer set A of a world $w_\u03c3$ of $P_\u03c3$ is associated with a reward given by the sum of the utilities of the atoms true in it:\n\nLet us call $R(w_\u03c3)$ the minimum of the rewards of an answer set of $w_\u03c3$ and $\\overline{R}(w_\u03c3)$ the maximum of the rewards of an answer set of $w_\u03c3$. That is:\n\nSince we impose no constraints on how the probability mass of a world is distributed among its answer sets, we can obtain the minimum utility from a world by assigning all the mass to the answer set with the minimum reward and the maximum utility from a world by assigning all the mass to the answer set with the maximum reward. The first is"}, {"title": "5.1 Examples", "content": "In this section, we will discuss a practical application of DTPASP to the viral marketing scenario. We consider here the problem of computing the upper strategy, but considerations for the lower strategy are analogous. First, let us introduce a running example that will be discussed multiple times across the paper."}, {"title": "6 Algorithms for Computing the Best Strategy in a DTPASP", "content": "To solve the optimization problems represented in Equation (13), we discuss two different algorithms. We have three different layers of complexity: i) the computation of the possible strategies, ii) the computation of the worlds, and iii) the computation of the answer sets with the highest and lowest reward (Equation (10)). Due to this, the task"}, {"title": "6.1 Implementation in aspmc", "content": "Before discussing the algorithm, let us introduce some concepts.\nDefinition 3\nA tree decomposition (Bodlaender 1988) of a graph G is a pair (T, X), where T is a tree and x is a labeling of V(T) (the set of nodes of T) by subsets of V(G) (the set of nodes of G) s.t. 1) for all nodes v \u2208 V(G) there is t \u2208 V(T) s.t. v \u2208 x(t); 2) for every edge {V1, V2} \u2208 V(E) there exists t \u2208 V(T) s.t. v1, v2 \u2208 x(t); and 3) for all nodes v \u2208 V(G) the set of nodes {t \u2208 V(T) | v \u2208 x(t)} forms a (connected) subtree of T. The width of (T, X) is maxt\u2208v' |x(t)| \u2013 1. The treewidth of a graph is the minimal width of any of its tree decompositions.\nIntuitively, treewidth is a measure of the distance of a graph from being a tree. Accord-ingly, a graph is a tree if and only if it has treewidth 1. The idea behind treewidth is that problems that are simple when their underlying structure is a tree, may also be simple when they are not far from trees, i.e., have low treewidth. Practically, we can use tree decompositions witnessing the low treewidth to decompose problems into smaller subproblems in such cases.\nWe assume that programs have already been translated into equivalent 3AMC in-stances, where the propositional theory is a propositional formula in conjunctive normal"}, {"title": "7 Experiments", "content": "We implemented the two aforementioned algorithms in Python. We integrated the enumeration based algorithm into the open source PASTA solver (Azzolini et al. 2022) that leverages clingo (Gebser et al. 2019) to compute the answer sets. The algorithm based on 3AMC is built on top of aspmc (Eiter et al. 2021) and we call it aspmc3. During the discussion of the results, we denote them as PASTA and aspmc3, respectively. We ran the experiments on a computer with Intel\u00ae Xeon\u00ae E5-2630v3 running at 2.40 GHz with 8 Gb of RAM and a time limit of 8 hours. Execution times are computed with the bash command time and we report the real field. We generated six synthetic datasets for the experiments. In the following examples, we report the aspmc3 version of the code. The programs are the same for PASTA except for the negation symbol: not for PASTA and \\+ for aspmc3. All the probabilities of the probabilistic facts are randomly set. In the following snippets we will use the values 0.1, 0.2, 0.3, and 0.4 for conciseness. Moreover, every PASP obtained from every strategy has at least one answer set per world.\nAs a first test (t1), we fix the number n of probabilistic facts to 2, 5, 10, and 15 and increase the number d of decision atoms from 0 until we get a memory error or reach the timeout. We associate a utility of 2 to qr and -12 to nqr, as in Example 6. We use da/1 for decision atoms and a/1 for probabilistic facts. We identify the different individuals of the programs with increasing integers, starting from 0, and, in each of these, we add a rule qr : - a(j), da(i) if i is even and two rules qr : \u2013 da(i), a(j), \\+ nqr and nqr :- da(i), a(j), \\+ qr, if i is odd, where j = i%n. For example, with n = 2 and d = 4, we have:"}, {"title": "8 Related Work", "content": "This work is inspired to DTProbLog (Van den Broeck et al. 2010). If we only consider normal rules, the decision theory task can be expressed with both DTProbLog and our framework, but our framework is more general, since it admits a large subset of the whole ASP syntax.\nThe possibility of expressing decision theory problems with ASP gathered a lot of research interest in the past years. The author of (Brewka 2002) extended ASP by intro-ducing Logic Programming with Ordered Disjunction (LPODs) based on the use of a new connective called ordered disjunction that specifies an order of preferences among the pos-sible answer sets. This was the starting point for several works: Brewka (2003) proposes a framework for quantitative decision making while Confalonieri and Prade (2011) adopt a possibilistic extension of LPODs. Also Grabo\u015b (2004) adopts LPODs and casts the deci-sion theory problem as a constraint satisfaction problem with the goal of identifying the preferred stable models. Differently from these works, we define uncertainty using prob-abilistic facts, possible actions using decision atoms, and associate weights (utilities) to"}, {"title": "9 Conclusions and Future Works", "content": "In this paper, we discussed how to encode and solve a decision theory task with Proba-bilistic Answer Set Programming under the credal semantics. We proposed the class of decision theoretic probabilistic answer set programs, i.e., probabilistic answer set pro-grams extended with decision atoms, representing the possible actions that can be taken, and utility attributes, representing the rewards that can be obtained. The goal is to find the two sets of decision atoms that yield the highest lower bound and the highest upper bound for the overall utility, respectively. We developed an algorithm based on three layers of Algebraic Model Counting and knowledge compilation and compared it against a naive algorithm based on answer set enumeration. Empirical results show that our approach is able to manage instances of non trivial sizes in a reasonable amount of time. A possible future work consists of proposing a formalization of the decision theory task also for other semantics for probabilistic ASP. Moreover, we could consider deci-sion problems also in the case that the probabilistic facts are annotated with probability intervals, exploiting the results for inference in Azzolini and Riguzzi (2024)."}]}