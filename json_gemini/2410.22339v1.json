{"title": "DAWN: Designing Distributed Agents in a Worldwide Network", "authors": ["Zahra Aminiranjbar", "Jianan Tang", "Qiudan Wang", "Shubha Pant", "Mahesh Viswanathan"], "abstract": "The rapid evolution of Large Language Models (LLMs) has transformed them from basic conversational tools into sophisticated entities capable of complex reasoning and decision-making. These advancements have led to the development of specialized LLM-based agents designed for diverse tasks such as coding and web browsing. As these agents become more capable, the need for a robust framework that facilitates global communication and collaboration among them towards advanced objectives has become increasingly critical. Distributed Agents in a Worldwide Network (DAWN) addresses this need by offering a versatile framework that integrates LLM-based agents with traditional software systems, enabling the creation of agentic applications suited for a wide range of use cases. DAWN enables distributed agents worldwide to register and be easily discovered through Gateway Agents. Collaborations among these agents are coordinated by a Principal Agent equipped with reasoning strategies. DAWN offers three operational modes: No-LLM Mode for deterministic tasks, Copilot for augmented decision-making, and LLM Agent for autonomous operations. Additionally, DAWN ensures the safety and security of agent collaborations globally through a dedicated safety, security, and compliance layer, protecting the network against attackers and adhering to stringent security and compliance standards. These features make DAWN a robust network for deploying agent-based applications across various industries.", "sections": [{"title": "I. INTRODUCTION", "content": "Rapid advancements in large language models (LLMs) [1]-\n[3] have have sparked significant interest in LLM-based agents\n[4] which have the potential to free humans from repetitive\ntasks and significantly enhance productivity. New agents are\nbeing developed and their performance is improving on a\nregular basis. There are agents for many tasks such as coding\n[5], [6], web browsing [7], gaming, and many more. [8],\n[9]. Furthermore, multi-agent systems [10]\u2013[12] have been\nproposed to leverage the collective intelligence and specialized\nprofiles and skills of multiple agents. However, three major\nchallenges arise that hinder their potential for broader, more\nimpactful applications.\nThe first challenge is how to discover and connect numerous\nagents distributed globally to accomplish complex, large-\nscale tasks. Existing frameworks, such as LangGraph [13]\nand AutoGen [14] often struggle with scalability, as they are\ntypically designed to manage only a limited number of agents."}, {"title": "II. RELATED WORKS", "content": "In recent years, Large Language Models have marked one\nof the most significant developments in artificial intelligence.\nOriginally designed for tasks like machine translation and\nchat completion, state-of-the-art LLMs have now demonstrated\nremarkable capabilities across a wide array of applications,\nincluding mathematics, coding, and question answering. These\nsuccesses have inspired researchers to propose the \"scaling\nlaw\" [20], suggesting that continuous scaling of LLMs could\neventually lead to the development of Artificial General In-\ntelligence (AGI) [21]. Despite these impressive strides, one\nof the most pressing challenges is hallucinations-generating\nfactually incorrect or nonsensical outputs [22], [23]. This issue\narises because the internal knowledge within LLMs can be\nboth limited and outdated, leading to errors that undermine\ntheir reliability and applicability in critical applications."}, {"title": "B. LLM Agents", "content": "The concept of agents has been a staple in the field of\nartificial intelligence for decades [24]. However, it wasn't until\nLLMs were used as reasoning engines within these agents\nthat the concept truly began to flourish [25]. An LLM agent\ntypically comprises three key components: a reasoning engine,\naction space, and memory unit. The reasoning engine, powered\nby an LLM, is equipped with advanced reasoning strategies\nsuch as Chain-of-Thought [26], ReAct [27], and Tree of\nThought [28], enabling it to process and respond to complex\nqueries. The action space is defined by a set of tools that the\nagent can utilize to interact with its environment and obtain\nfeedback, facilitating dynamic decision-making. A memory\nunit plays a critical role by storing the reasoning trajectories,\nconversation history, and relevant context, allowing the agent\nto accumulate and apply knowledge over time. As a result,\nhundreds of such agents are being developed daily, with the\nexpectation that they will soon transform traditional software\nand human processes, leading to enhanced productivity, im-\nproved user experiences, and greater operational efficiency."}, {"title": "C. Multi-agent Systems", "content": "While individual agents have shown great promise, its\ntrue potential lies in the development of multi-agent sys-\ntems. Human society has demonstrated that collaboration and\nteamwork often lead to superior outcomes, but the art of\neffective teamwork is complex and fraught with challenges\n[29]. Early efforts in building multi-agent systems have re-\nvealed tremendous potential [10]\u2013[12], [30]\u2013[32], but these\nworks also highlight significant difficulties. Issues such as\ninefficient communication [11], increased computational costs,\nunreliable execution and communication sequences [15], and\nvulnerability to attacks [33] have underscored the need for a\nreliable platform to support agent collaboration. Additionally,\nscalability remains a critical concern: as the number of agents\nincreases, introducing them to one another and ensuring that\ntasks are assigned to the most suitable agents becomes increas-\ningly challenging. Addressing these concerns is essential for"}, {"title": "III. DAWN ARCHITECTURE DETAIL", "content": "The DAWN architecture is a modular framework designed\nto orchestrate collaboration of distributed agents. It supports\nagentic applications to be built with various operational modes,\nincluding No-LLM mode, Copilot mode, Agent mode, and\ncombinations of them. It supports tasks ranging from deter-\nministic workflows (e.g., job offers and background checks) to\ncreative and autonomous processes (e.g., interview summaries\nand job description compliance remediation). Central to the\nAgent mode is the Principle Agent, which plans tasks and\nrequests corresponding resources (tools, LLMs, and agents),\nand multiple Gateway Agents, each of which independently\noversees resource retrieval, validation, and execution required\nfor the tasks identified by the Principal Agent. Multiple agentic\ndesign patterns may be adopted to balance the performance\nand cost when operating in the Agent mode. DAWN uses a\nrobust communication layer to facilitate seamless interaction\nbetween the Principal Agent, Gateway Agents, and registered\nagents distributed around the globe. A context layer maintains\nmemory and task history, ensuring that the requisite informa-\ntion is exchanged efficiently via the communication layer. A\ndedicated safety, security, and compliance layer is the foun-\ndation of the whole architecture and ensures the framework\nadheres to strict standards, making it suitable for sensitive\nbusiness domains. This layer implements safety, security, and\ncompliance functions required for the safe operation of agents\nand LLMs, within the Principal and Gateway Agents and also\nduring data and control interchange."}, {"title": "A. Principal Agent", "content": "The Principal Agent acts as an autonomous planner and\ncentral orchestrator within the DAWN framework. Its primary"}, {"title": "Reasoning, Planning, and Adaptive Decision-Making:", "content": "The Principal Agent utilizes an LLM to understand the user's\nintent, develop a plan, and decompose it into manageable\nsubtasks. The default reasoning strategy is ReAct [27], which\nfollows a cycle of reasoning, acting, and observing to actively\nmove through subtasks. This dynamic approach enables the\nPrincipal Agent to adjust to complex and changing environ-\nments. For example, the user might ask the Principal Agent\nto plan a trip. The Principal Agent would first interpret the\ngoal and create a plan with subtasks like booking a flight,\nreserving accommodation, and arranging local transport. If the\nflight turns out to be unavailable, the ReAct strategy allows\nthe Principal Agent to search for alternative way such as train\nand bus, and modify the plan on the fly. Depending on the\ntask requirements, users can select other reasoning strategies.\nFor less dynamic tasks where computational cost is a priority,\nthe Reasoning Without Observation (ReWOO) strategy [35]\nmay be more suitable. ReWOO creates a comprehensive, end-to-end plan without adjusting it during execution. Hugging-\nGPT [36] uses this strategy to process multi-modal data by\ncalling machine learning models available on HuggingFace\n[37] and achieves good performance while minimizing LLM\ncalls. Alternatively, the Tree-of-Thoughts (ToT) strategy [28]\nencourages the agent to explore multiple reasoning paths and\nself-evaluate them, offering more deliberate decision-making\nbut at a higher computational cost. This approach is bene-\nficial when performance is critical and cost is secondary. In\nLanguage Agent Tree Search (LATS) [38] and ToolLLM [39],\nthe authors combine the ToT strategy with other techniques to\nachieve the best success rate that surpasses ReAct."}, {"title": "Local Resource Pool:", "content": "The Principle Agent hosts a local\nresource pool to store local resources and also to cache re-\nsources retrieved from the Gateway Agents. Multiple common\nresources, such as a calculation tool and a web search tool,\nare permanently held in the local resource pool. References\nto resources retrieved from the Gateway Agents are cached\nin the local resource pool using a Least Recent Used (LRU)\nstrategy. This design principle helps the Principle Agent to\nrespond to simple or repetitive (sub)tasks without repeatedly\nreaching out to Gateway Agents and dramatically reduces the\ncommunication overhead."}, {"title": "Resource Requesting:", "content": "After developing a plan, the Prin-\ncipal Agent first checks if the resources in the local resource\npool satisfy all or any of the requirements. If it determines\nthat local resources are inadequate to complete the task,\nwhich is expected to be the default case, the Principle Agent"}, {"title": "Resource Execution:", "content": "Gateway Agents are expected to\napply their programmed discretion is searching, matching\nand retrieving the most applicable resources. When requests\nare sent to multiple Gateway Agents, it is only natural that\nduplicate resources or resources with overlapping capabilities\nare returned to the Principal Agent. It falls to the Principal\nAgent to study the returned resource manifest files, assess the\nquality of each resource, determine which agentic resource\nor resources may be applied to each task list step, and then\nretain just those resources. The Planning Agent begins the\nexecution of the graph until it hits another node where a new\nsearch for resources is required to complete the remaining\nsubtasks. The Planning Agent then reaches out to the Gateway\nAgents again. This process repeats until the user's request is\nfully addressed. It should be noted that Gateway Agents return\nreferences to agentic resources. For instance, some agents\nmay actually execute on their preferred cloud service provider\nlocations. In other cases, the agents may rely on the run-time\nenvironment of their host Gateway Agents. In both cases, only\ncallable references to resources are passed between agents,\nGateway Agents and Principal Agents. And so, when the\nPrincipal Agents executes resources from a Gateway Agent, it\nis in reality making an API call to the resource and passing\nthe payload to the concerned Gateway Agent via JSON or\nsimilarly packaged property file format.\nIn many agent implementations, the action space or toolset\nis limited to the local resource repository. This is typically due\nto three factors: 1) specialized agents naturally operate within\na limited action space [9], [40], [41], 2) the context window\nof LLMs restricts the number of resources they can handle,\nand 3) if the agent has more than 20 tools to choose from,\nthe accuracy in selecting the right tool drops as suggested by\nOpenAI [42]. (Our own experimentation found this number\nto be less than 10.) However, fully autonomous agents need\nto navigate real-world problems where the action space is\nvast, and numerous resources are available. DAWN's rationale\nto use distributed Gateway Agents follows directly from this\ntenet. For example, if the Principal Agent needs to perform an\naction beyond an LLM's capabilities such as online search,\nbooking a ticket, or writing code-it will request the relevant\nresource (e.g., a search tool, booking agent, or coding agent)\nfrom Gateway Agents. This flexibility enhances the Principal\nAgent's autonomy and allows it to handle a broader range of\nuse cases."}, {"title": "B. Gateway Agent", "content": "The Gateway Agent plays an essential role in connecting\nglobally deployed resources (tools, agents, and agentic ap-\nplications) with the Principal Agent. (There is a trivial case\nof human operators acting as the Principal Agent and using\nGateway Agents for additional services under the No-LLM\nmode but the LLM-based applications are the central focus"}, {"title": "Resource Registration:", "content": "The Gateway Agent hosts and\nmaintains a registry where developers can register their re-\nsources (tools, agents, and agentic applications). A success-\nfully registered resource will be accompanied with crucial\ndetails, such as the resource's name, application programming\ninterface (API), input and output schema, and API documenta-\ntion. Information such as resource description, usage examples\nshall be included so that LLMs can understand what the\nresources are and how to use them through in-context learning.\nGateway Agents may be equipped to run agentic resources\nwithin its confines or expect that agents have their own run-\ntimes.\nWhen a resource is first registered with a Gateway Agent,\nthe Gateway Agent has only limited information about it. It\nwill have been screened for safety, security, compliance and\nother readily visible characteristics. Over time, the Gateway\nAgent also gathers utilitarian characteristics such as P50/P90\nlatency, cost, completion rate, etc. The registry may also\ninclude metrics such as success rate, average execution time,\navailability, and load capacity. These metrics allow the orches-\ntrator to understand and optimize resource utilization and is\nthen used to score, rate and select the best resource for a given\nuser function."}, {"title": "Resource Executor:", "content": "The Gateway Agent wraps the callable\ninterfaces of registered resources and presents them as REST-\nful APIs in a standardized, unified format. This additional\nwrapping layer provides two key benefits that enhance the\nfunctionality and reliability of the system. First, the unified\nAPI format simplifies the agent's ability to call the right\ntools, significantly reducing the risk of errors such as passing\nincorrect input parameters or misinterpreting outputs.\nSecond, this wrapping layer makes it easy to integrate\nessential safeguards, ensuring that errors or failures in resource\nusage are handled gracefully. For example, when a tool fails\nto deliver the expected output or encounters an issue during\nexecution, the system can recover without disrupting the entire\nworkflow. Additionally, the layer allows for the filtering of"}, {"title": "Resource Testing:", "content": "Testing of resources is of great im-\nportance to ensure a resource functions as expected. For\nexample, a developer might register a data processing API\nand describe it as \"optimized for large datasets.\" But upon\ncloser inspection, it may only perform well with small to\nmedium-sized datasets, leading to performance issues in larger\ncontexts. Such tests are performed periodically, especially for\nagents and agentic systems, because the underlying LLMs\nmay evolve and change their behavior. To automate such\ntesting, LLMs in Gateway Agents are used to generate test\ncases based on the description of the resource and evaluate\nthe outcome. Similar techniques have been reported in [43]\nand [44]. If a resource fails to pass this validation process,\nindicating discrepancies between its description and actual\nbehavior, the Gateway Agent will disqualify that agent from\nparticipation until a better description is generated manually\nor automatically using LLM-based methods [45]. Apart from\nthe functionality testing, the resources shall be tested for their\nconnectivity, performance, security, etc. [46]. For example, it is\nalso important to assess how well the resource handles various\nlevels of traffic. Commercially available tools such as Apache\nJMeter [47], Gatling [48], and Postman [49] already offer\ncapability to test resources with a high-volume of concurrent\nusers."}, {"title": "Resource Retrieval:", "content": "A Gateway Agent handles queries\nfrom the Principal Agent, and searches its registry for the\nmost relevant resources. Similar to traditional information\nretrieval methods [50], resource descriptions and examples\nmay be treated like documents. Semantic search [51] may\nbe used to identify the most relevant resources by converting\nboth the queries and resource descriptions into vector embed-\ndings and then performing similarity searches based on those\nembeddings. To further improve search accuracy, additional\ntechniques like attribute filtering and keyword search are\nincorporated. Moreover, fine-tuning LLMs on query-resource\npairs is another viable approach to enhance search results [39],\n[52]. While DAWN imposes some base functional and non-\nfunctional requirements on Gateway Agents along with strin-\ngent safety and security guardrails, its internals are left to the\ndiscretion of the Gateway owner. Some Gateway Agents may\nonly have traditional software and classical data repositories,\nwhile others may be fully functioning LLM-driven Agents."}, {"title": "Multiple Gateway Agents:", "content": "Organizations and developers\naround the globe will build and manage their own Gateway\nAgents following an open protocol. Each Gateway Agent\noffers unique resources proprietary to the entity in question\n(organization or developer). At any given time, the Principal\nAgent has a list of Gateway Agents it is connected with.\nFor any given user action, the list of addressable Gateway\nAgents is static. The Principal Agent submits tasks and user\nintents to the listed Gateway Agents who will then return\nthe best resources available that may address all or a subset\nof the tasks or subtasks associated with the user request.\nThe Principal Agent then aggregates the search results and\npick the most suitable set of resources from among them. If\nthe returned resources serve to complete the user tasks, then"}, {"title": "C. Orchestration Layer", "content": "The Orchestration Layer, hosted along side the Principle\nAgent, serves as a central component that enables the system's\nversatility by supporting different operational modes, including\nNo-LLM, Copilot, and hybrid modes that combine No-LLM,\nCopilot, and LLM Agent functionalities. In this hybrid mode,\na human operator defines a workflow as an execution graph,\nwhere each node corresponds to a subtask, and the most\nsuitable resource for each subtask is selected from those\nreturned by the Gateway Agents. The Orchestration Layer\nis responsible for enforcing the rules, logic, and sequencing"}, {"title": "D. Communication Layer", "content": "The Communication Layer is responsible for managing the\nflow of information between various system components and\nresources, ensuring seamless interaction across the platform.\nIt handles the messaging protocols that ensure messages\nare properly parsed, interpreted, and routed to their correct\ndestinations. Two primary types of messages are exchanged\namong the system components and resources.\nThe first type is the query sent by the Principal Agent\nto the Gateway Agent. This payload includes not only the\ndescription of the current subtask but also the full context, such\nas previously completed subtasks and the interaction history.\nThis additional context allows the Gateway Agent to make\nwell-informed decisions about which resources to retrieve. In\nresponse, the Gateway Agent returns a list of suitable resources\nalong with file manifests that contain a record of the functional\nand non-functional capabilities of the resource.\nThe second type of message is the execution command sent\nby the Principal Agent to the Gateway Agents' resource execu-"}, {"title": "E. Context Layer", "content": "The Context Layer is vital for enabling agentic operations\nby managing memory and task-related context. It provides\nthree key components for memory management: a scratchpad\nto track the agent's internal reasoning process, a message\npool to record communication between the Principal Agent\nand the Gateway Agent, and a memory bank to store long-\nterm data and user preferences, supporting long context, in-\nsession, cross-session, multi-turn conversations resulting in\npersonalized user experience. The Context Layer dynamically\nassembles prompts using data from both the message pool and\nmemory bank, ensuring that the Principal Agent is aware of\nthe overall task, task progress, and available resources."}, {"title": "F. Security, Safety, and Compliance Layer", "content": "The Security, Safety, and Compliance Layer establishes a\nrobust security foundation for the entire framework, addressing\nthe safety, security, and compliance needs of the system. All\nframeworks and platforms that employ distributed resources\nmust implement robust security systems to avoid risks that\nmay be introduced when unsecured resources are connected\nto an enterprise's gateway agent. While extensive research and\npractices have been published on traditional common security\nissues such as authentication, access control, privacy, and\npolicy enforcement [53]-[55], an agentic network equipped\nwith LLMs introduces additional security and privacy threats\nespecially as resources worldwide begin collaborating. For\nLLM agents, two primary sources of threats exist.\nFirst, there are vulnerabilities inherent to LLMs, such as\nhallucinations [56], attacks that leverage tuned instructional\nmethods like jailbreaking [57], [58], and prompt injection\n[59]. Second, there are threats specific to agents collaborating\nin an agentic network like DAWN. A notable example is"}, {"title": "IV. APPLICATION OF DAWN", "content": "The modular design of DAWN framework provides users\nwith the flexibility to select the most appropriate working\nmode for their application, tailored to the specific needs of\nvarious use cases. As outlined in the introduction of this\npaper, the primary modes include No-LLM, Copilot, and\nLLM Agent mode. For scenarios requiring high determinism,"}, {"title": "V. CONCLUSION", "content": "The DAWN platform aims to revolutionize agentic appli-\ncations by establishing a robust foundation for agent collabo-\nration and communication. This framework offers a compre-\nhensive strategy for integrating LLM-based agents into diverse\napplications. The modular design, featuring key components\nlike the Principal Agent and Gateway Agent, ensures that\nresources are optimally utilized, enabling seamless workflow\nmanagement and global agent cooperation.\nThe DAWN platform's contributions\u2014flexibility, scalability,\ninteroperability, and stringent safety and compliance mea-\nsures-position it as a transformative solution for enterprise-\nlevel applications. By addressing the challenges of robustness\nand reliability in agent-based systems, DAWN paves the\nway for advanced utilization across various industries, from\ncustomer support to cybersecurity. The continued development\nand refinement of the DAWN framework is expected to push\nthe boundaries of what is possible with LLM-based agents,\nfostering an interconnected ecosystem where collaboration and\ninnovation thrive."}]}