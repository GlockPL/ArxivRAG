{"title": "TrustDataFilter:Leveraging Trusted Knowledge Base Data for More Effective Filtering of Unknown Information", "authors": ["Jinghong Zhang", "Yidong Cui", "Weilin Wang", "Xianyou Cheng"], "abstract": "With the advancement of technology and changes in the market, the demand for the construction of domain- specific knowledge bases has been increasing, either to improve model performance or to promote enterprise innovation and competitiveness[1]. The construction of domain-specific knowl- edge bases typically relies on web crawlers or existing industry databases[2], leading to problems with accuracy and consistency of the data. To address these challenges, we considered the characteristics of domain data, where internal knowledge is interconnected, and proposed the Self-Natural Language Infer- ence Data Filtering (self-nli-TDF) framework. This framework compares trusted filtered knowledge with the data to be fil- tered, deducing the reasoning relationship between them, thus improving filtering performance[3]. The framework uses plug- and-play large language models for trustworthiness assessment and employs the RoBERTa-MNLI[4] model from the NLI domain for reasoning. We constructed three datasets in the domains of biology, radiation, and science, and conducted experiments using RoBERTa[4], GPT3.5[6], and the local Qwen2 model[5]. The experimental results show that this framework improves filter quality, producing more consistent and reliable filtering results.", "sections": [{"title": "I. INTRODUCTION", "content": "WITH technological advancements and market shifts, the demand for building domain-specific knowledge bases is increasing to enhance model performance, drive innova- tion, and strengthen competitiveness. Expanding knowledge bases into specific domains can significantly improve the accuracy in understanding and responding to user intent[7]. Domain-specific knowledge bases hold substantial potential for knowledge management and reasoning[8].However, con- structing such knowledge bases usually relies on web crawling, data generation, or existing industry databases[2], which can lead to issues with data accuracy and consistency.\nSome recent studies explore methods for constructing domain-specific datasets. Saras\u00faa et al. discussed using large models to automatically generate datasets of any scale and domain[9], although this approach heavily relies on the prior knowledge embedded within the model. Addi et al. filtered higher-confidence data based on data attributes (such as the number of stars on open-source projects) [10], which limits applicability and may not accurately reflect true data quality.\nApple's Alex Fang and colleagues proposed using deep learn- ing models, specifically DFNs, to filter image-text datasets to improve the quality of the data set[11]. However, this approach may cause general embedding similarity methods to fail to capture semantic meaning as effectively as large models, and updates may lag.\nCorrelations within domain-specific data are often over- looked in current filtering research. In response, we focused on the characteristics of domain datasets-specifically the interconnections between internal knowledge, and proposed the self-Natural Language Inference-trust data filter (self-nli- TDF) framework. This framework combines the generaliza- tion capabilities of large language models with NLI models specialized in NLI reasoning. Using internal prior knowledge of large language models, the framework performs reliability filtering for domain datasets.[12] Additionally, it strengthens filtering performance by comparing trusted filtered knowledge with data awaiting filtering to deduce inferential relationships between them [13]. The core of this framework lies in its iterative approach: initially filtering out data with relatively high reliability, then comparing trusted filtered knowledge with unfiltered data to deduce their inferential relationships, ulti- mately enhancing filtering accuracy and consistency.Figure.1 Our contributions are as follows.\n1. Introduction of the self-nli-tdf domain-specific data fil- tering framework: This paper proposes an iterative filtering approach by exploring the interrelationships within domain- specific knowledge bases, combined with high-confidence knowledge from the domain and the internal prior data of large models, creating a dual error detection concept. This approach effectively leverages internal knowledge associations within the domain and the model's prior information, resulting in a 1%-5% accuracy improvement over direct filtering in our dataset.\n2.Mathematical Modeling of Knowledge Reliability: This paper introduces a mathematical model for quantifying the reliability of knowledge within knowledge bases, providing a more precise theoretical foundation for knowledge validation and data filtering, enhancing the scientific rigor of data filter- ing.\n3.A Multi-Level Data Filtering Framework Integrating Gen- eral and Domain-Specific Models: This study combines gen- eral large-scale language models with domain-specific models to construct an efficient data filtering framework. By merging the broad language understanding capabilities of general mod-"}, {"title": "II. PROBLEM FORMULATION", "content": "The study of human judgment in evaluating the correctness of domain-specific problems suggests that humans approach problem solving from multiple perspectives. First, they de- termine whether the description aligns with common sense [20], leveraging prior knowledge within their worldview to assess the issue. Second, they refer to relevant domain-specific materials to derive whether the problem can be inferred from known knowledge. Finally, they synthesize these two results, applying heuristic methods to arrive at the final judgment [21]. This approach provides inspiration for constructing the Self- NLI framework to filter domain-specific data.\nThis perspective also highlights some limitations of existing domain data filtering frameworks:\n1) Local Perspective: Using large language models for data filtering is analogous to the first mode of reasoning, where prior knowledge within the worldview of the model is applied to assess the problem. On the other hand, methods based on deep learning or machine learn- ing training resemble the second mode of reasoning, relying on past training data to draw conclusions. These approaches fail to integrate subjective reasoning with objective knowledge effectively.\n2) Global Perspective Deficiency: Current filtering frame- works often lack a mechanism to fully combine subjec- tive reasoning and objective knowledge validation com- prehensively. They fail to effectively integrate the prior knowledge of the model with factual knowledge within the domain. In practice, combining subjective judgment (i.e. common sense reasoning) with objective verification (i.e., logical inference based on external knowledge) can significantly enhance the accuracy and robustness of data filtering. However, existing frameworks fall short in this regard.\nTo address these shortcomings, we propose the Self-NLI data filtering framework. This framework incorporates a Con- fidence Evaluation module, which utilizes the prior knowledge of large language models to determine whether the data to be filtered are trustworthy. It then applies a Contradiction Evaluation module, using an NLI model to assess whether data can be inferred from known trusted knowledge. Finally, a Decision Evaluation module is employed to make the final filtering judgement. The initial known trusted knowledge, along with the data deemed correct and trustworthy after filtering, is stored in a vector knowledge base as memory. As the filtering process progresses, this memory becomes increasingly enriched, thereby improving filtering performance within the given domain [22].\nConfidence Evaluation\nThe Confidence Evaluation filter $M(L,x,p)$ is a function based on an external large language model $L$, where $x$ represents the data to be evaluated, and $p$ is a prompt containing filtering rules or output formats. The model $L$, equipped with prior knowledge and reasoning capabilities, performs a reliability evaluation on the input data and outputs a reliability label $Y \\in {0,1}$ along with a confidence score $C\\in [0,1]$."}, {"title": "B. Contradiction Evaluation", "content": "Here, $Y = 1$ indicates that the data are reliable, while $Y = 0$ indicates that the data is unreliable. The confidence score $C$ reflects the self-assessed certainty of the model about the outcome of the project. As discussed in recent studies[25], the probability of the model's output label $Y$ is a well- established approach to evaluating confidence, as it captures the uncertainty of the model in generating predictions.\nFor a given input $x$ and prompt $p$, the Confidence Evaluation filter outputs the reliability label $Y$ and the confidence score $C$ as follows:\n$M(L,x,p) = (Y, C)$,\nwhere:\n*  $Y \\in {0,1}$: The reliability result determined by the large language model based on the input data $x$ and the prompt $p$.\n*  $C \\in [0,1]$: The model's confidence score reflecting its certainty in the judgment result $Y$.\nUnlike traditional methods that maximize classification prob- abilities, both $Y$ and $C$ are obtained through the model's rea- soning process, leveraging its prior knowledge and reasoning abilities. Specifically:\n1) When $Y = 1$, the confidence score $C$ reflects the certainty of the model in the data being reliable.\n2) When $Y = 0$, the confidence score $C$ reflects the certainty of the model in the data being unreliable.\nBy allowing the large language model to perform the eval- uation, the Confidence Evaluation filter integrates the model's prior knowledge and reasoning to determine the reliability of input data effectively.\nThe contradiction evaluation $N(I, x, x')$ is a function based on an external NLI (Natural Language Inference)[23] model $I$, where:\n*  $x$: The data to be evaluated.\n*  $x'$: The most similar known trusted data retrieved from the vector database based on cosine similarity.\n*  $I$: A pre-trained NLI model that determines the logical relationship between $x$ and $x'$.\nGiven the input $x$ and $x'$, the NLI model $I$ outputs a relationship label $Y \\in {-1,0,1}$ and a confidence score $C \\in [0,1]$. The definition of the label $Y$ follows the work of Samuel R. Bowman et al. [22], where:\n*  $Y = 1$: Entailment, which means $x'$ logically implies $x$.\n*  $Y = 0$: Contradiction, meaning $x$ contradicts $x'$.\n*  $Y = -1$: Neutral, meaning $x$ and $x'$ are unrelated.\nThe NLI model computes the conditional probability distri- bution for the three possible relationships:\n$p_\\theta(Y = 1 | x, x'), p_\\theta(Y = 0|x,x'), p_\\theta(Y = -1 | x, x'),$\nwhere $p_\\theta$ represents the conditional probability distribution pa- rameterized by $\\theta$. The final relationship label $y_2$ is determined by selecting the label with the highest probability:\n$Y = \\arg \\underset{k\\in{-1,0,1}}{\\text{max}} p_\\theta(Y = k | x, x').$"}, {"title": "C. Decision Evaluation", "content": "The confidence score $C$ is defined as the maximum proba- bility corresponding to the selected label $Y$, expressed as:\n$C = \\underset{k\\in{-1,0,1}}{\\text{max}} p_\\theta(Y = k | x,x').$\nThus, the output of the contradiction filter $N(I,x,x')$ is represented as:\n$N(I,x,x') = (Y, C'),$\nwhere $Y$ is the relationship label between $x$ and $x'$, and $C$ is the confidence score reflecting the NLI model's certainty in the classification result.\nThe Decision Evaluation model $D(y_1, C_1, y_2, C_2)$ is based on a pre-trained decision tree[24] $T$, where $y_1 \\in {0,1}$ represents the result from the Confidence Evaluation mod- ule, with $c_1 \\in [0,1]$ being the associated confidence score. Similarly, $y_2 \\in {-1,0,1}$ represents the result from the Contradiction Evaluation module, with $C_2 \\in [0,1}$ being the corresponding confidence score. Here, $Y_2 = 1$ indicates an entailment relationship, $y_2 = 0$ indicates a contradiction relationship, and $y_2 = -1$ indicates a neutral relationship.\nGiven the input feature vector $x = (Y_1, C_1, Y_2, C_2)$, the pre-trained decision tree model $T$ in the Decision Evaluation module performs a comprehensive judgment and outputs the final result $z \\in {0,1}$. Specifically, $z = 1$ indicates that the knowledge is deemed reliable, while $z = 0$ indicates that the knowledge is unreliable. The decision tree automatically learns the mapping relationship between the input features and the final decision through pre-training.\nThe final output of the Decision Evaluation model is ex- pressed as:\n$z = D(y_1, C_1, Y_2, C_2) = T(x)$,\nwhere $x = (y_1, C_1, Y_2, C_2)$ is the input feature vector, $T$ is the pre-trained decision tree, and $z$ is the final decision result indicating the reliability of the knowledge.\nConceptually, Self-NLI, as a domain-specific data filtering framework based on large language models and natural lan- guage inference models, offers several advantages:\nGenerality: Self-NLI combines the prior knowledge of large language models with the logical reasoning of natural language inference, enabling flexible application to various domain-specific data filtering tasks.\nModularity: The framework's Confidence Evaluation, Con- tradiction Evaluation, and Decision Evaluation modules can be independently replaced and optimized, providing a high degree of modularity.\nConvenience: The framework does not rely on extensive model training; it only requires pre-trained large language models and natural language inference models to perform data filtering tasks effectively.\nThe next section will provide a detailed introduction to the architecture and processing flow of the Self-NLI framework."}, {"title": "III. METHODOLOGY", "content": "In this chapter, (1) we will introduce the static architecture of the self-NLI-DataFilter, outlining its fundamental compo- nents and their relationships.(2) we will describe the dynamic process, illustrating how the system operates to filter and process data step by step. (3) we will elaborate on the key design aspects of the workflow, breaking down the process into four critical steps:\nTrusted Knowledge Matching\nContradiction Evaluation\nConfidence Evaluation\nDecision Tree Evaluation"}, {"title": "overall architecture", "content": "Our complete system architecture is shown in Figure 2. It is structured into two main layers: the business layer and the foundational layer, working together to achieve efficient and accurate data filtering.\nBusiness Layer: The top layer represents the data filtering process, which encompasses steps from preprocessing to final storage. Initially, 5% of the data is selected for annotation to train both the NLI model and the decision tree. Inspired by Van Engelen and Hoos [26], this approach demonstrates that utilizing a small annotated subset can effectively enhance model performance, a common practice in data processing [17]. The remaining data are passed to the Knowledge Match module, which performs vector similarity matching between the data and the trusted knowledge base. The matched items are then processed by the Confidence and Contradiction Eval- uation module, consisting of two steps: confidence evaluation and contradiction evaluation. Confidence evaluation assesses the reliability of the data, while contradiction evaluation deter- mines whether the data conflict with the trusted knowledge in the knowledge base. The results of both evaluations are passed to the Decision Tree Evaluation module, which performs a comprehensive evaluation to determine the trustworthiness of the data. Trusted data is stored in the knowledge base, while untrustworthy data is discarded, ensuring the accuracy of the filtering process.\nFoundational Layer: The bottom layer provides the tech- nical backbone for the system, comprising the training frame- work, vector database, and interfaces for large language mod- els (LLM) and NLI models.The training framework leverages Hugging Face for pre-training and fine-tuning, ensuring the ro- bustness and accuracy of the NLI model and decision tree. The LLM and NLI interfaces are implemented using LangChain, enabling seamless integration for tasks like semantic analysis and contradiction evaluation. The vector database, powered by Milvus, efficiently stores and manages vectorized knowledge data, supporting effective knowledge matching and filtering operations. Together, these components form the foundation that supports the business layer, ensuring a reliable and effi- cient workflow for data filtering."}, {"title": "B. overall process", "content": "Our frame process is shown in Figure 3. It consists of a systematic sequence of stages designed to ensure accurate and efficient knowledge filtering.\nOverall Process: The process begins with the Data to Process stage, where each knowledge item undergoes initial filtering. Subsequently, the knowledge items are passed to the Trusted Knowledge Matching stage, where they are matched with trusted items in the vector knowledge base. If a match is successful, the knowledge item proceeds for further evaluation. If the match fails, the item is temporarily stored in the Process in Next Iteration stage for re-evaluation in subsequent iterations.\nDetailed Steps: For items with a successful match, a con- fidence evaluation and contradiction evaluation are conducted. These evaluations utilize a large language model and an NLI model to assign confidence and contradiction flags along with their corresponding scores. The results of these evaluations are then integrated and passed to the Decision Tree Evaluation stage, where the final outcome is determined. Knowledge items that pass the evaluation are marked as qualified and stored in the knowledge base. Items that do not meet the criteria are marked as not qualified and sent to the discard stage. The process continues until all knowledge items are processed, concluding at the \"End\" stage.\nIterative Improvements: Our framework draws inspiration from certain aspects of the retrieval-augmented generation (RAG) framework, particularly the concept of matching each piece of knowledge with the most relevant reference entry from the vector database [18]. However, unlike RAG, which primarily uses matching for prompt construction, our frame- work focuses on assisting knowledge filtering through natural language inference reasoning. As highlighted by Barnett et al. [27], vector matching accuracy is a significant challenge in RAG systems. Semantic misalignment between queries and indexed vectors can lead to retrieval failures or low-quality results, thereby affecting overall system performance.\nTo address these challenges, we propose an iterative ap- proach to handle unmatched data. Unmatched items are de- ferred to subsequent iterations for re-evaluation. This iterative process incrementally improves the quality of the vector database by integrating validated knowledge, which in turn en- hances matching performance over time. In contrast, standard RAG frameworks typically address unmatched references by either generating a default response or providing a placeholder such as \"I am unable to process this query\" [19]."}, {"title": "C. Trusted Knowledge Matching", "content": "The process of aligning data with a trusted knowledge base is fundamental to effective contradiction evaluation. This process is organized into three critical components: knowledge base construction, vector matching techniques, and dynamic knowledge base expansion.\nKnowledge Base Construction: To begin, we construct a domain-specific knowledge base containing validated and reliable information. For domains with a sufficient amount of trustworthy data, this data is directly vectorized and stored in the database. In specialized domains with limited data availability, 5% of the data is manually marked as trustworthy and incorporated into the knowledge base during filtering. This ensures that even in data-scarce domains, the knowledge base provides a reliable foundation for subsequent filtering and evaluation.\nVector Matching Techniques: Our vector matching is based on the DPR method [28], which employs a Dual- Encoder Architecture to independently encode queries and documents into dense embeddings for fast and precise se- mantic matching. The sentence-transformers/all-MiniLM-L6- v2 model is utilized for vectorization, while the IVF_FLAT indexing technique is used to enhance retrieval efficiency. Co- sine similarity is applied to calculate vector similarity, focusing on semantic alignment between items. A predefined similarity threshold, typically between 0.85 and 0.90, ensures that only highly relevant data items are matched. Items falling below this threshold are marked as \"unmatched\" and temporarily stored for reassessment in subsequent filtering cycles. As related studies highlight [29], cosine similarity does not strictly measure semantic distance, so the threshold is heuristically assigned based on empirical observations.\nDynamic Knowledge Base Expansion: This iterative ap- proach enables continuous refinement of the knowledge base by integrating validated data from each filtering cycle. Un- matched data items are reevaluated in subsequent iterations, allowing for gradual accumulation of trustworthy information. Newly validated data is vectorized and added to the knowl- edge base, improving its semantic coverage and matching performance over time. Unlike static approaches, this strat- egy actively adapts the knowledge base to changing domain requirements and enhances its robustness and scalability. The iterative process ensures that the filtering mechanism evolves with each cycle, leveraging newly added reliable knowledge to improve subsequent filtering precision."}, {"title": "D. Contradiction Evaluation", "content": "Contradiction evaluation is a key process that ensures the consistency and reliability of the knowledge base. This process is structured into three main aspects: its mechanism, outputs, and role in the broader data filtering framework.\nMechanism of Contradiction Evaluation: Contradiction evaluation assesses the MNLI (Multi-Genre Natural Language Inference) [30] relationship between the data to be filtered and the existing trusted knowledge using a pre-trained model. After similarity matching, the system forwards the data to be filtered (referred to as knowledge) and the matched knowledge (matchKnowledge) to the contradiction evaluation module. This module uses a RoBERTa-MNLI model fine-tuned in the MNLI domain to infer the relationship between the two:\nIf the inference result indicates that the trusted knowledge entails the data to be filtered, the information in the data is considered relatively credible. If the result shows a contradic- tion, the knowledge contained in the data is likely erroneous. When the result is neutral, it suggests the knowledge in the data is new or unrelated, making it infeasible to assess credibility based solely on contradiction evaluation. Outputs of Contradiction Evaluation: The system produces two final outputs: contradict_flag, which indicates the inference result, and score_of_contradict, which provides the confidence score. These outputs enable the system to identify data that conflicts with trusted knowledge while retaining novel information that lacks inherent contradictions. This ensures that only consistent data is added to the knowledge base, maintaining its integrity while allowing for dynamic expansion.\nRole in Data Filtering Framework: In the broader context of data filtering, contradiction evaluation acts as a crucial gatekeeping mechanism. By identifying and excluding con- tradictory data, it safeguards the consistency and accuracy of the knowledge base. This process also enables the incremental inclusion of new, potentially valuable information, which may be further evaluated and validated. By systematically incorpo- rating contradiction assessment into the filtering architecture, the framework enhances the reliability of data inclusion, ensuring high-quality knowledge management and enabling intelligent, data-driven decision support.\nThrough contradiction evaluation, the system effectively maintains the consistency of the knowledge base by filtering out contradictory data while retaining novel, non-conflicting information. This filtering mechanism ensures that the knowl- edge base remains accurate and adaptable, providing a solid foundation for efficient knowledge management and depend- able decision-making."}, {"title": "E. Confidence Evaluation", "content": "Confidence evaluation plays a critical role in determining the reliability of data during filtering, ensuring that only trust- worthy information is integrated into the knowledge base. This process is organized into three key aspects: its mechanism, implementation, and role within the data filtering framework.\nMechanism of Confidence Evaluation: Confidence eval- uation assesses the credibility of data by generating two key outputs for each data item: the confidence flag and the confi- dence score. The confidence flag is a binary indicator, where 0 signifies that the data is generally not trustworthy, and 1 signifies that the data is generally trustworthy. The confidence score quantifies the certainty of this judgment, with higher scores indicating a more reliable assessment. Together, these outputs provide a critical foundation for filtering decisions.\nImplementation of Confidence Evaluation: To perform confidence evaluation, the framework uses a large language model as the core component, leveraging a prompt-based framework to guide the model in generating confidence in- dicators. This step primarily relies on the extensive prior knowledge encoded in the pre-trained model to assess data reliability. Studies such as On Reliability and Robustness of Current Estimators [31] have demonstrated the ability of large language models to effectively evaluate the factual reliability of their outputs. Additionally, research on MONITOR [32] provides systematic approaches to assess the consistency of LLMs across various contexts, further supporting their appli- cation in confidence-based tasks. These findings underline the robustness of using pre-trained language models for confidence evaluation, enabling accurate and nuanced data filtering.\nRole in the Data Filtering Framework: Confidence evaluation measures the alignment of the data with known, validated knowledge or patterns, providing a quantitative ba- sis for trustworthiness. Data with high confidence scores is deemed reliable and included in the knowledge base, while data with low scores is flagged for further analysis or excluded. By integrating confidence evaluation, the filtering framework gains an additional layer of quality control, ensuring that only high-confidence information is retained. This mechanism minimizes the risk of incorporating inaccurate or misleading data, significantly boosting the reliability and robustness of the system."}, {"title": "F. Decision Tree Evaluation", "content": "Decision Tree Evaluation serves as the final judgment step in the data filtering process, integrating the outcomes of Confidence Evaluation and Contradiction Evaluation to determine the overall trustworthiness of data. This process can be divided into three main aspects: its mechanism, integration of evaluation standards, and interpretability.\nMechanism of Decision Tree Evaluation: Decision Tree Evaluation relies on the results of prior evaluations, includ- ing confidence_flag, score_of_confidence, contradict_flag, and score_of_contradict. These outputs, represented as integers (int) or floating-point numbers (float), are well suited for processing with a decision tree model. Decision trees are highly effective at handling numerical and categorical features, constructing hierarchical decision structures based on splitting rules such as information gain or Gini impurity. Studies have demonstrated that decision trees perform well on datasets with numerical features while maintaining high interpretability [33]. The decision tree processes these inputs to output a final decision flag: If the flag is 1, the data is deemed trustworthy and incorporated into the knowledge base. If the flag is 0, the data is considered untrustworthy and discarded.\nIntegration of Evaluation Standards: The decision tree seam- lessly combines the outputs of Confidence Evaluation and Contradiction Evaluation to enable a comprehensive assess- ment. By incorporating confidence_flag, score_of_confidence, contradict_flag, and score_of_contradict as input variables, the decision tree flexibly performs hierarchical branching based on various conditions and weightings. This integration allows the model to balance the contributions of each evaluation: in some cases, relying more heavily on confidence scores, while in others prioritizing contradiction levels. For instance, when a data item has a high score_of_confidence but also a high score_of_contradict, the decision tree can recognize these con- flicting signals and autonomously select the most appropriate path to output the final flag value. This multi-dimensional judgment mechanism minimizes the risk of misjudging data credibility based on any single standard, ensuring accurate data filtering and supporting knowledge base quality management and expansion.\nInterpretability of Decision Tree Evaluation: A key strength of the decision tree is its interpretability. During data filtering, the decision path generated by the model reveals the reasoning behind each step, rendering the judgment process transparent. By examining the branching structure, users can clearly understand how various judgment conditions influ- ence the final decision. This transparency facilitates analysis and validation, allowing users to identify potential issues or optimization opportunities within the filtering process more effectively. The decision tree's logical structure thus provides a clear and interpretable standard for determining data reliability, enhancing the precision and reliability of the overall data filtering process.\nConclusion: Through its hierarchical structure and flexi- bility, Decision Tree Evaluation integrates multiple evaluation conditions to provide a robust and accurate judgment mech- anism. It ensures that only trustworthy data is included in the knowledge base while maintaining a transparent decision- making process. This enhances the quality and reliability of data filtering, providing critical support for knowledge base management and dynamic expansion."}, {"title": "IV. DATASET CONSTRUCT", "content": "To demonstrate the effectiveness of self-NLI-DataFilter, our experiments require domain-specific datasets for filtering. However, not all domain datasets are publicly available. In this study, to validate the algorithm's performance, we constructed three experimental domain datasets using three different meth- ods. Each record in the constructed domain datasets consists of a knowledge statement and a flag. The knowledge represents a statement of a knowledge point within the domain, while the"}, {"title": "A. Biological Dataset", "content": "flag serves as an indicator, where 0 denotes incorrect knowl- edge and 1 denotes correct knowledge.The three datasets we constructed are as follows, and their composition is introduced below:\nBiological Dataset: This dataset consists of biological knowledge generated by a large language model under prompt engineering.We adopted the self-instruct[34] approach for data generation. The data includes both correct and incorrect knowledge points based on the model's prior knowledge.\nScience Dataset: This dataset was constructed by extracting knowledge point descriptions from the scientific knowledge base \"allenai/ai2_arc\" Datasets[35] at Hugging Face using a large language model. The ai2_arc dataset comprises 7,787 elementary-level multiple-choice science questions. The large model was utilized to extract correct and incorrect knowledge descriptions to form this dataset.\nRadiation Dataset: This dataset contains data related to nu- clear radiation protection. We collected content from websites, including CBRNResponder, the U.S. Environmental Protection Agency (EPA), FEMA, and the IAEA (International Atomic Energy Agency), using web crawlers. Additionally, we in- cluded academic content from Google Scholar and ScienceDi- rect.Based on the capabilities of large language models in information extraction [36], we used a large language model to organize and refine the domain-specific knowledge points from the collected data. The collected data was segmented and processed to extract knowledge points, forming the dataset.\nThe Biological dataset was constructed to provide a com- prehensive and diverse foundation for domain-specific data filtering experiments. This process can be divided into three key aspects: dataset construction, data generation techniques, and the dataset's advantages.\nDataset Construction: The dataset was created using GPT- 3.5 based on its prior knowledge. We implemented and modi- fied the self-instruction framework to enable the large language model to generate both correct and incorrect biological knowl- edge points based on given topics and subtopics. Through a heuristic approach, we pre-constructed 27 topics (Figure 4), each containing several subtopics, resulting in a total of over 200 knowledge generation themes.\nData Generation Techniques: During the data generation process, we iteratively traversed all combinations of topics and subtopics and employed prompt engineering techniques. Carefully designed prompts guided the model to generate biological knowledge statements that included both accurate and inaccurate knowledge points. This iterative process en- sured both diversity and richness in the generated data. In total, 44.7k knowledge points were generated. The dataset has been open-sourced on Hugging Face under the repository ZhJiHo/biological_domain_dataset.\nAdvantages of the Dataset: This data generation method provides the Biological dataset with several notable strengths. First, the pre-designed 27 topics and over 200 subtopics ensure broad and diverse content, covering themes ranging from macro-level ecology to molecular biology. This breadth pro-"}, {"title": "B. Science Dataset", "content": "vides a reliable foundation for comprehensive filtering experi- ments within the biological domain. Second, the generation of incorrect knowledge points involved an intentional distortion of correct knowledge points. By instructing the model to first produce accurate knowledge and then deliberately creating incorrect versions, the dataset ensures that the incorrect knowl- edge points are sufficiently deceptive. This makes the dataset particularly valuable for testing the reliability and robustness of filtering models under challenging conditions.\nThe Science dataset was constructed to provide a structured and high-quality corpus for domain-specific experiments in the scientific field. This process can be divided into three key aspects: dataset construction, methodology, and dataset significance.\nDataset Construction: The Science dataset was created by extracting knowledge point descriptions from the scientific knowledge base \u201callenai/ai2_arc\" Datasets at Hugging Face. This source contains multiple elementary-level multiple-choice science question datasets. For each question, we combined the question with the correct option to form a correct answer and used a large language model to extract accurate knowledge points from the answer. Similarly, we combined the question with incorrect options to create incorrect answers, tasking the large language model with generating inaccurate knowledge points based on these incorrect answers. Through this process, we transformed the original multiple-choice questions into a domain-specific dataset with pre-labeled correct and incorrect descriptions. In total, 20.3k knowledge points were generated, which we have open-sourced on Hugging Face under the repository ZhJiHo/science_domain_dataset.\nMethodology: This method effectively leverages validated knowledge bases and transforms their high-quality information into structured scientific domain data. By systematically com- bining questions and options, the dataset includes both cor- rect and incorrect knowledge points, ensuring diversity while maintaining semantic and logical clarity. The large language model plays a key role in extracting precise knowledge from correct answers and generating inaccurate knowledge points from incorrect answers, adding authenticity and complexity to the dataset.\nDataset Significance: The resulting dataset provides a rich and challenging corpus for domain-specific experiments. It supports comprehensive evaluations of knowledge filtering frameworks and related methodologies by offering pre-labeled"}, {"title": "C. Radiation Dataset", "content": "data with high semantic clarity and logical consistency. The di- versity and complexity of the dataset make it particularly valu- able for testing filtering models under realistic and demanding conditions, enhancing its utility for advancing domain-specific knowledge management.\nThe Radiation domain dataset was constructed to provide a challenging and authentic resource for evaluating domain- specific knowledge filtering frameworks. This process can be divided into three main aspects: data collection, data processing, and the dataset's purpose and significance.\nData Collection: The dataset was primarily collected by our researchers through web scraping. Initially, radiation- related data was crawled from authoritative official websites, including CBRNResponder, the U.S. Environmental Protection Agency (EPA), FEMA, and the International Atomic Energy Agency (IAEA). Due to the limited volume of data from these sources, additional radiation-related content was scraped from academic papers available on Google Scholar and ScienceDi- rect. Combining data from both official sources and academic literature resulted in the construction of an initial web-scraped domain dataset. Since the original data came from authoritative sources, we assumed the extracted knowledge to be accurate. Furthermore, the reliance on web scraping provides the dataset with a high degree of authenticity and real-world relevance.\nData Processing: In the data processing phase, the scraped text was filtered and segmented into smaller text blocks. A large language model was then employed to extract structured knowledge points from these text slices, transforming raw text into usable knowledge entries. To enrich the dataset, we generated inaccurate knowledge points based on the correct knowledge points, creating a dataset with both accurate and inaccurate entries. Through this process, we constructed ap- proximately 77.9k radiation domain knowledge points, which we have open-sourced on Hugging Face under the repository ZhJiHo/radiation_domain_dataset.\nPurpose and Significance: The Radiation domain was de- deliberately chosen as a relatively niche area. Subsequent exper- iments revealed a noticeable decline in model accuracy within this domain, highlighting the model's limited prior knowledge of radiation-related topics. The primary goal of constructing this dataset is to evaluate the extent to which the self-NLI- DataFilter framework can improve model performance when prior domain knowledge is insufficient. By introducing this specialized dataset, we created a challenging test environment to comprehensively assess the framework's ability to filter and evaluate domain-specific knowledge. This approach not only measures the robustness and adaptability of the framework but also evaluates its potential to enhance performance when supplemented with external domain knowledge. Additionally, it lays a solid foundation for developing more efficient domain- specific knowledge management systems."}, {"title": "V. EXPERIMENT", "content": "Experiment Setup: We prepared three domain-specific datasets: biological", "models": "RoBERTa", "methods": "n*  Basic Filtering: This method directly uses the large lan- guage models to perform filtering without any additional framework or enhancements.\n*  Self-NLI Filtering: This method leverages the framework proposed in this paper", "Filtering": "This method applies an ablation ex- periment", "compared.\nDatasets": "We constructed datasets from three distinct do- mains: biological"}, {"models": "RoBERTa (Liu, Y [4"}]}