{"title": "Investigating Role of Big Five Personality Traits in Audio-Visual Rapport Estimation", "authors": ["Takato Hayashi", "Ryusei Kimura", "Shogo Okada", "Ryo Ishii"], "abstract": "Automatic rapport estimation in social interactions is a central component of affective computing. Recent reports have shown that the estimation performance of rapport in initial interactions can be improved by using the participant's personality traits as the model's input. In this study, we investigate whether this findings applies to interactions between friends by developing rapport estimation models that utilize nonverbal cues (audio and facial expressions) as inputs. Our experimental results show that adding Big Five features (BFFs) to nonverbal features can improve the estimation performance of self-reported rapport in dyadic interactions between friends. Next, we demystify how BFFs improve the estimation performance of rapport through a comparative analysis between models with and without BFFs. We decompose rapport ratings into perceiver effects (people's tendency to rate other people), target effects (people's tendency to be rated by other people), and relationship effects (people's unique ratings for a specific person) using the social relations model. We then analyze the extent to which BFFs contribute to capturing each effect. Our analysis demonstrates that the perceiver's and the target's BFFs lead estimation models to capture the perceiver and the target effects, respectively. Furthermore, our experimental results indicate that the combinations of facial expression features and BFFs achieve best estimation performances not only in estimating rapport ratings, but also in estimating three effects. Our study is the first step toward understanding why personality-aware estimation models of interpersonal perception accomplish high estimation performance.", "sections": [{"title": "1 INTRODUCTION", "content": "The term rapport can be defined as the feeling of being \"in sync\" with a conversational partner [14]. If a machine learning model can estimate the rapport of dyads, the system will be able to provide various types of support according to the estimates. For example, the rapport between students leads to learning gains in peer tutoring [27], so if teachers have access to the estimates, they can support dyads (pairs of students) more selectively. In these cases, dyads are already in a close relationship to some extent. Previous research [3, 9, 13, 20, 24, 26, 32] has addressed rapport estimation in initial interactions, but despite its importance, only a few studies [20, 32] have addressed it in interactions between intimate participants. Thus, we focus here on rapport estimation in dyadic interactions between friends.\nOur final goal is to clarify how to maximize the potential of rapport estimation models by using personality traits in interactions between friends. In general rapport estimation, the input of rapport estimation models is the participant's behavioral features in an interaction, and the output is a value or class indicating the degree of rapport. Among the previous studies on automatic rapport estimation [3, 24], a key finding is that the use of personality trait features based on the five-factor model can improve the estimation performances of rapport in initial interactions. In addition to the empirical evidence, various theoretical findings regarding personality traits and interpersonal perceptions (e.g., rapport) have been reported in the field of social psychology [4, 7, 11, 31]. For example, Cuperman et al. [4] showed that participants with high agreeableness tend to rate rapport toward their conversational partners highly.\nOur first research objective (RO-1) is to clarify whether Big Five features (BFFs) can improve the estimation performance of rapport in interactions between friends. As stated above, it has already been established that adding personality trait features to behavioral features improves the estimation performance of rapport [3, 24]. However, it is unclear whether this finding applies to interactions between friends since the association between personality traits and rapport changes depending on the relationship between participants. For example, according to Tickle-Degnen and Rosenthal, positivity is important for building rapport in initial interactions, but its importance decreases as intimacy among participants increases [28]. Thus, even though extraversion (the Big Five dimension related to positivity) is a strong cue for estimating"}, {"title": "1 INTRODUCTION", "content": "rapport in initial interactions, it may be a weak cue in interactions between friends.\nTo achieve RO-1, we develop personality-aware rapport estimation models (see Fig. 1). Furthermore, we investigate how to use BFFs to achieve higher performance improvement. To this end, we combine the BFFs with audio, facial expressions, and bimodal features, and then compare their performance. We also compare the performance under three conditions: 1) only the BFFs of a perceiver (person who rates rapport) are accessible, 2) only the BFFs of a target (person whose rapport is rated) are accessible, and 3) both the perceiver's and the target's BFFs are accessible.\nThe second research objective (RO-2) is to reveal the role of BFFs in the performance improvement through comparisons between the model with and without BFFs. Our experimental results related to RO-1 show that BFFs substantially improve the rapport estimation performance. The ratings of interpersonal perception consist of three components: (a) people's overall tendencies to rate other people (perceiver effect), (b) people's overall tendencies to be rated by other people (target effect), and (c) people's unique ratings for a specific partner beyond the perceiver and target effects (relationship effect) [15, 16]. These effects represent the different aspects of interpersonal perceptions. Thus, if the estimation performance of rapport ratings improves, the model becomes able to capture any or all of these effects more accurately. At the same time, better capturing each effect leads to better estimation performances of rapport ratings. Hence, we reveal the extent to which performance gains by BFFs can be attributed to capturing each effect.\nTo calculate three effects, we introduce an analysis approach based on a social relations model (SRM) [16, 17], which is a tool for understanding human perception between two individuals. First, we decompose true (human) ratings and the estimates of ratings into the three effects using SRM. Second, to measure how a model can capture these effects, we calculate the Pearson's product-moment correlation coefficient (PCC) and concordance correlation coefficient (CCC) between the true effects and the estimates of effects. Finally, we compare the PCC and CCC for each effect between the model with and without BFFs.\nFor RO-2, we come up with three hypotheses and verify them: 1) the perceiver's BFFs lead models to capture perceiver effects, 2) the target's BFFs lead models to capture target effects, and 3) the combinations of both BFFs lead models to capture relationship"}, {"title": "1 INTRODUCTION", "content": "effects. The first and second hypotheses are based on evidence that the perceiver's Big Five personality traits influence the perceiver's tendency to rate rapport with other people and evidence that the target's Big Five personality traits influence the target's tendency to be rated by other people, respectively [4]. The third hypothesis is based on evidence that the specific combinations of the Big Five personality traits (e.g., both have high agreeableness) lead to uniquely high or low rapport [4].\nThe motivation behind the two research objectives is to reveal findings that help us develop a better rapport estimation model among intimate dyads. RO-1 provides readers with information to judge whether performance gain is worth the cost of collecting Big Five personality traits. As for achieving RO-2, it provides interpretability about the performance gain by BFFs and clarifies which types of BFFs are suitable for obtaining the desired auxiliary information. If the models can capture any or all three effects, an estimate of the rapport ratings supplies the auxiliary information. For example, estimates of target effects are useful for detecting exceptionally undesirable people (i.e., low target effect). Furthermore, beyond the limit of rapport and BFFs, our analysis approach is helpful in analyzing the extent to which model improvements or data extensions have contributed to capturing different aspects of interpersonal perception.\nIn summation, our contributions are delineated as follows:\n\u2022 Our experimental results show that BFFs can improve the estimation performance of self-reported rapport in dyadic interactions between friends.\n\u2022 We introduce an analysis approach using SRM, which reveals the extent to which the model can capture perceiver, target, and relationship effects.\n\u2022 We present evidence that the perceiver's and target's BFFs lead estimation models to accurately capture the perceiver and target effects, respectively.\n\u2022 We demonstrate that the combinations of facial expression and BFFs achieve best estimation performances not only in estimating rapport ratings, but also in estimating three effects.\nSection 2 provides an overview of related works. Section 3 introduces our dataset and analysis results, and Section 4 explains the methods of feature extraction, model, and analysis approach using SRM. In Section 5, we describe the experimental settings. Section 6 shows our experimental results, and in Section 7, we discuss their implications."}, {"title": "2 RELATED WORKS", "content": ""}, {"title": "2.1 Rapport and Machine Learning", "content": "As rapport plays an essential role in building good relationships with others, it is an extensively researched topic in social psychology. Bernieri et al. [2] outlined nonverbal cues indicating rapport in various contexts. Tickle-Degnen and Rosenthal [28] demonstrated that the key nonverbal cues indicating rapport can change depending on the relationship between participants. Harrigan et al. [10] found significant differences of eye movement and gesture between high- and low-rapport doctors. Furthermore, Miles et al. [23] showed that synchrony between two participants is associated with high rapport in both visual and audio cues. Grahe and Bernieri"}, {"title": "2.1 Rapport and Machine Learning", "content": "[8] clarified that visual cues are the most useful for the observer to perceive rapport accurately. Overall, previous studies provide evidence that visual cues are more strongly associated with rapport than audio cues.\nInspired by findings on the relationships between nonverbal cues and rapport, recent researchers in machine learning have addressed automatic rapport estimation. Hayashi et al. [12, 13] proposed a ranking model to rank conversation partners based on the degree of self-reported rapport. Other studies [20, 32] have estimated the rapport between two students in a peer tutoring scenario. As with studies in social psychology, visual features are found to be more useful cues for rapport estimation than audio features [3, 9, 24, 30]. Among the previous studies on rapport estimation, a key finding is that the use of personality trait features based on the five-factor model can improve the estimation performances in initial interactions [3, 24]. Cerekovic et al. [3] showed that a model using features combining social cues and personality traits achieves the best estimation performance of rapport for virtual agents. Similarly, in the task of detecting low rapport in the early stages of group interaction, Muller et al. [24] found that adding personality trait features to facial expression features improves the estimation performance. These two studies formulated rapport estimation as classifying the high/low rapport class. However, in these cases, the estimation results have only a little information about the degree of rapport. Furthermore, there is a risk of adding bias due to the class splitting criteria [21]. Therefore, in this study, we formulate rapport estimation as regression. In addition, in contrast to previous studies investigating initial interactions, we focus on the usefulness of personality traits in friend interactions."}, {"title": "2.2 Interpersonal Perception and Social Relations Model", "content": "The ratings of interpersonal perception consist of three components: perceiver, target, and relationship effects [16]. These effects represent the different aspects of interpersonal perceptions. As an example, take the perception of rapport that John feels for Tom. The perception can be decomposed into three components: a) John's tendencies to rate with other people (John's perceiver effect), b) Tom's tendencies to be rated by other people (Tom's target effect), and c) John's unique ratings for Tom beyond perceiver and target effect (John's relationship effect to Tom).\nThese effects are typically calculated using a social relations model (SRM) [16, 17], which is a tool for analyzing human perception between two individuals. In this section, we explain how to calculate these effects with the settings of a round-robin design, in which the same participant serves as both a perceiver and a target (see table in Fig. 4). According to SRM [16, 17], the rapport score by perceiver i to target j in group k consists of the perceiver effect, the target effect, the relationship effect, and the group average:\n$X_{ijk} = P_i + t_j + g_{ij} + M_{..k}$                                                                                                (1)\nwhere $p_i$ is the perceiver effect for person i; $t_j$ is the target effect for person j; $r_{ij}$ is the relationship effect for i with j; and $M_{..k}$ is the mean of the ratings given by all participants in group k. The perceiver effect represents how the perceiver views other people on average, and the target effect represents how the target is viewed on"}, {"title": "2.2 Interpersonal Perception and Social Relations Model", "content": "average by others. The relationship effect represents the perceiver's unique view toward the target. The perceiver effect ($p_i$) is\n$p_i = \\frac{(n - 1)^2}{n(n-2)} -M_{i.k} + \\frac{n-1}{n(n-2)}M_{.ik} -\\frac{n-1}{n-2}M_{k}$                                                                                           (2)\nand the target effect ($t_i$) is calcurated as\n$t_i = \\frac{(n - 1)^2}{n(n-2)} -M_{.ik} + \\frac{n-1}{n(n-2)}M_{i.k} -\\frac{n-1}{n-2}M_{k}$                                                                                            (3)\nwhere $M_{ik}$ is the mean of the ratings given by participant i in group k. $M_{ik}$ is the mean of the ratings given to participant i in group k, and n is the group size. The relationship effect for perceiver i with target j ($g_{ij}$) is\n$g_{ij} = X_{ijk} - P_i - t_i - M_{..k}$.                                                                                                (4)\nPrevious studies have reported theoretical findings regarding the relationship between personality traits and interpersonal perceptions [4, 7, 11, 31]. Cuperman et al. [4] showed that participants with high agreeableness tend to rate rapport toward their conversational partners highly and to be rated highly by their conversational partners. Wood et al. [31] also reported that participants with high agreeableness tend to rate their friend positively. Furthermore, participants' extraversion and agreeableness are positively correlated with their ratings of friendship satisfaction [11]. Overall, the Big Five dimensions most closely related to interpersonal perception are extraversion and agreeableness, but other dimensions can influence it as well. Inspired by these studies, we hypothesize that personality trait features promote estimation models to capture people's rating tendencies. We introduce SRM to confirm this hypothesis. Our study is the first attempt to use SRM to analyze estimation models."}, {"title": "3 DATA", "content": "To achieve our research objectives, we collected online dyadic interactions between friends. In Section 3.1, we present an overview of our dataset, and in Section 3.2, we analyze the relationship between the Big Five and the three effects of rapport ratings. All recordings were reviewed and approved by our institution's research ethics committee."}, {"title": "3.1 Dataset", "content": "We recruited eight groups consisting of four participants each who were friends with each other through a recruitment agency. There were a total of 32 Japanese participants (16 men, 16 women; 26 in their 20s, 6 in their 30s), and each participant was paired with other participants in the same group (48 dyads). All participants in the same dyads were the same gender. Each dyad conducted three online interactions based on different conversation topics. Each interaction lasted 20 minutes. We used the first interactions for our analysis and experiments because the first are the least restrictive and the most natural interactions. In the first interaction, the dyad introduces themselves (e.g., their favorite foods and artists). For more information about the recording settings and topics, see Section III of [13], as we strictly followed their procedure for collecting initial interactions.\nThe dataset includes participants' rapport ratings for their conversational partners, which was reported after each interaction. We utilized a questionnaire developed by Bernieri et al. [2] to measure self-reported rapport. A previous study translated the questionnaire from English into Japanese, and its internal consistency among items was sufficient (a = 0.92) [18]. The questionnaire comprises 18 items, each of which is rated on an 8-point Likert scale (1 = strongly disagree, 8 = strongly agree). We define the rapport score as the sum of the responses after reversing the values of the negative questions. In addition, at the end of all recordings, participants completed the Japanese Big Five questionnaire [29], which consists of 60 items on a 7-point Likert scale. After reversing the values of the negative questions, we summed the responses along each Big Five dimension; Fig. 3 shows box plots of the rapport score, the three effects, and the Big Five dimensions."}, {"title": "3.2 Data Analysis", "content": ""}, {"title": "3.2.1 Perceiver effect and target effect.", "content": "We calculated the Pearson's product-moment correlation coefficient to estimate the association"}, {"title": "3.2.1 Perceiver effect and target effect.", "content": "between the perceiver/target effects and Big Five dimensions (see Table 1). In a previous study conducting large-scale research on initial interactions (87 dyads), extraversion and agreeableness were significantly associated with perceiver and target effects of rapport perception [4]. Although we found no significant correlations in our data (significance level a = .05), this result may be due to the insufficient sample size (48 dyads). A small positive correlation was observed between the perceiver effects and neuroticism (.25). Extraversion and openness had small positive correlations with the target effects (.21), and conscientiousness had a small negative correlation with the target effects (-.21). Our different results here compared to previous studies [4] may be due to differences in cultural backgrounds or relationships among participants, but we cannot say this for certain. Overall, the findings suggest that the perceiver's and target's Big Five features (BFFs) lead models to capture the perceiver and target effects, respectively."}, {"title": "3.2.2 Relationship effect.", "content": "We present bar plots in Fig. 3 to visualize the relationship effects according to dyads that have specific combinations of Big Five dimensions. For each Big Five dimension, we categorized the perceiver and target into two types (High or Low) using a threshold. The threshold is defined as $M\u00b1SD\u00d70.5$, where M is the mean total responses corresponding to the Big Five dimension and SD is the standard deviation. We focus here on extraversion and agreeableness, as combinations of type in these dimensions lead to unique high or low rapport [4]. In our dataset, dyads with different extraversion types tended to yield negative relationship effects. Furthermore, dyads between a disagreeable perceiver and an agreeable target yielded negative relationship effects. These results suggest that the combination of the perceiver's and target's BFFs leads models to accurately capture the relationship effects."}, {"title": "4 METHOD", "content": ""}, {"title": "4.1 Features Extraction", "content": ""}, {"title": "4.1.1 Audio features.", "content": "We used OpenSMILE [6] to extract audio features from each utterance. Audio features were based on eGeMAPS [5], which is recognized as the default setting in speech emotion recognition. Audio features were 88 dimensions, including pitch and volume. We standardized them across the utterance pool of each participant."}, {"title": "4.1.2 Facial expression features.", "content": "We utilized OpenFace [1] to extract the intensity of 17 action units (AUs) from each frame. Facial expression features included 14 statistics calculated for each AU; thus, they totaled 238 (17 \u00d7 14) dimensions. The 14 statistics were the mean, median, standard deviation, skewness, kurtosis, maximum and minimum, mean of the first and second differences, range, slope, intercept of the linear approximation, and the 25th and 75th percentile values. We standardized the facial expression features across the utterance pool of each participant."}, {"title": "4.1.3 Big Five features (BFFs).", "content": "We utilized responses on the Big Five questionnaire as BFFs. The Big Five questionnaire quantifies the Big Five dimensions of Extraversion, Agreeableness, Conscientiousness, Neuroticism, and Openness. The BFFs had 60 dimensions, which we normalized across the participant pool using min-max normalization."}, {"title": "4.2 Estimation Model", "content": ""}, {"title": "4.2.1 Problem definition.", "content": "The problem was to estimate the perceiver's rapport scores as regression. Take the mapping function $f: X \u2192 y$. The y is the rapport score reported by the perceiver. The X consists of the sequence of perceiver's utterance-level features and BFFs: $X = {U_1, \u2026\u2026, U_T, B}$, where T is the total number of perceiver's utterances. In a unimodal setting, each utterance-level features comprises a single modality with $U_i \u2208 R^{1\u00d7D_U}$, where $D_U$ is the dimension of unimodal features. In a bimodal setting, $D_U$ represents the total dimension of two unimodal features. The $B \u2208 R^{1\u00d7D_B}$ is BFFs, where $D_B$ represents the dimension of BFFs."}, {"title": "4.2.2 Model architecture and training.", "content": "We developed a mapping function f inspired by Poria et al.[25]. Our mapping function is composed of unidirectional long short-term memory networks (LSTM) and fully connected neural networks (FCNN). The perceiver's sequence of utterances ${U_1,, U_T}$ is input to the LSTM, and the output vector corresponding to the last utterance $h_T$ is extracted. We then concatenate $h_T$ and BFFs B, and map this vector to the estimate of rapport score \u0177,\n$h_T = LSTM(U_1,..., U_T),$\n(5)\n$\u0177 = FCNN(h_T\u2295 B).$\n(6)\nThe model is trained by minimizing the mean square error."}, {"title": "4.3 Analytical Approach using Social Relations Model (SRM)", "content": "Related to RO-2, we explain how to investigate the role of BFFs in performance improvement using SRM. As shown in Eq. (1), the rapport score consist of the perceiver, target, relationship effect, and group average. Thus, when the estimation performance of rapport score, the model becomes able to capture any or all of these effects"}, {"title": "4.3 Analytical Approach using Social Relations Model (SRM)", "content": "more accurately. Our approach is designed to demystify the performance improvement of the rapport score based on the variation in the estimation performance of each effect. This approach consists of three steps (see Fig. 4).\nIn the first step, we decompose true (human) rapport scores and estimates of rapport scores into perceiver, target, and relationship effects using SRM. We compute the three effects from the true rapport score according to Eqs. (2)-(4). We define these effects as true effects. We also compute the three effects of the estimated rapport score. We define these effects as the estimates of effects.\nIn the second step, we calculate the Pearson's correlation coefficient (PCC) and concordance correlation coefficient (CCC) between the true effects and the estimates of effects.\nIn the third step, we compare the PCC and CCC for each effect between models with and without BFFs. By comparing the two models, it becomes quantitatively clear how useful the BFFs are in accurately capturing each effect."}, {"title": "5 EXPERIMENTAL SETTINGS", "content": ""}, {"title": "5.1 Evaluation Methods", "content": "We evaluate estimation performances using an eight-fold cross-validation, where each fold corresponds to one group consisting of four participants. The cross-validation ensured that the same participant was not duplicated across the training and test sets. In our data, 96 samples were created from 48 dyads since the rapport rating is bidirectional.\nThe Pearson's correlation coefficient (PCC) and concordance correlation coefficient (CCC) [19] were calculated based on true rapport scores and estimated rapport scores. PCC ($p$) is defined as\n$p = \\frac{\u03c3_{y\u0177}}{\u03c3_y\u03c3_\u0177}$                                                                                                (7)"}, {"title": "5.1 Evaluation Methods", "content": "where $\u03c3_y$ and $\u03c3_\u0177$ are standard deviations of true and estimated rapport scores, respectively. $\u03c3_{y\u0177}$ is their covariance. CCC ($p_c$) is defined as\n$p_c = Cp,$\n(8)\nwhere C is a bias correction factor:\n$C = \\frac{2\u03c3_y\u03c3_\u0177}{\u03c3_y^2 + \u03c3_\u0177^2 + (\u03bc_y \u2013 \u03bc_\u0177)^2}$\n(9)\nThe C is between 0 and 1; the maximum value is realized when two variables have an identical mean and standard deviation. Thus, the CCC is a correlation coefficient that takes into account the similarity of distribution between two variables. Each experiment was performed 30 times based on different random seed values, and we reported the average performance and standard deviation to reduce the influence of the initial model parameters."}, {"title": "5.2 Model Settings", "content": "For training on the estimation models, we set the mini-batch size to 32 and the number of epochs to 50. Dropout was applied to the hidden layer of FCNN with a drop rate of 30%. The learning rate was 1.5e-4 for the models using audio features, 1.0e-4 for the models using facial expression features and bimodal features, and 1.0e-3 for the models using only BFFs to ensure that all models were sufficiently fitted to the training data with 50 epochs. All models were implemented in Pytorch 2.0.1, and all experiments were conducted on NVIDIA GeForce RTX 3090."}, {"title": "6 RESULTS", "content": "Table 2 shows the estimation performance of rapport scores and the perceiver, target, and relationship effects. Bold and underlined values represent the best performances within each modality and"}, {"title": "6 RESULTS", "content": "across modalities, respectively. The standard deviation of the rapport score and relationship effect represents the amount of variation per rapport score; the standard deviation of the perceiver and target effect represents the amount of variation per person. As a naive baseline, we used a model that predicts values randomly within the range of true rapport scores. To test if the performances of each estimation model are significantly better than those of the baseline, we conducted a Mann-Whitney U test (N=30, \u03b1=.05, one-sided test), where N corresponds to the number of random seed values. We also conducted the same statistical test to determine if the performance with Big Five features (BFFs) was significantly better than that without BFFs for each modality; the asterisk denotes this significant differences. In this section, we first report the performance of rapport scores. Then, we review the performance of the three effects. We mainly focus on unimodal models, as these models are the minimal units of bimodal models."}, {"title": "6.1 Estimation Performance of Rapport Scores", "content": "Rows 2 and 3 in Table 2 list the estimation performances of the rapport scores. Overall, models with facial expressions achieved high performances. Conversely, those with audio were low. In both modalities, the statistical test showed that the performances of all models were significantly better than that of the random baseline. Therefore, models were able to sufficiently predict rapport scores.\nThe results also indicate that adding BFFs improves performances. In facial expressions, the model (F + BFF[P+T]) achieved the highest performances across modalities with PCC (.38) and CCC (.21). Furthermore, both of the BFF[P] alone and the BFF[T] alone yielded performance gains. In audio, BFFs also led to better performances. In short, almost all models with BFFs achieved significantly better performances than models without BFFs in both modalities."}, {"title": "6.2 Implicit Estimation Performance of Perceiver, Target, and Relationship Effects", "content": "Next, we examine how BFFs contribute to capturing the three effects. Rows 4 to 9 in Table 2 list the implicit estimation performances of the three effects. The term implicit here denotes that models do not estimate the three effects directly; rather, the estimates are calculated using a post-hoc approach. In both modalities, the results of the statistical test showed that models achieved significantly better performances than the random baseline except in these situations: PCC and CCC for perceiver effects by all models using audio; PCC for target effects by the model (F alone).\nRegarding the perceiver effect, experimental results indicated that adding the perceiver's BFFs improves the performances of perceiver effects. The overall performance of models using facial expression was better than that of the other models. Specifically, model (F + BFF[P+T]) achieved the best performances across all modalities (PCC: .36, CCC: 0.28). Models (A + BFF[P+T]) and (A + BFF[P]) also accomplished the best PCC and CCC within the audio, respectively. Although BFF[T] improved performances in both modalities, the performance gain by BFF[P] was substantially better than that by BFF[T].\nRegarding the target effect, the results indicated that adding the target's BFFs improves the performances of target effects. The overall performance of the audio model was better than that of the other models. The model (A+BFF[P+T]) achieved the highest PCC across modalities (.23), and Model (F+BFF[P+T]) achieved the highest CCC across modalities (.16). In audio, BFF[T] improved performances, although BFF[P] did not. In facial expressions, both BFF [P] and BFF[T] yielded performance gains. However, the performance gain by BFF[T] (PCC: +.16, CCC: +.12) was substantially better than that by BFF[P] (PCC: +.06, CCC: +.07).\nRegarding the relationship effect, the results indicated that adding BFFs improves the performances of relationship effects. The overall performance of models using facial expressions was higher than that of the other models. Model (A+BFF[P]) achieved the highest performances across all modalities (PCC: .45, CCC: .40). BFF[P+T] yielded the best performances within audio; however, it did not yield the best performance within facial expression."}, {"title": "7 DISCUSSION", "content": "We first discuss whether Big Five features (BFFs) can improve the estimation performance of rapport in interactions between friends (RO-1). We then examine the role of BFFs in performance improvement (RO-2). Next, we investigate which Big Five dimensions (BFDs) are effective in rapport estimation. Finally, we touch on the limitations of our study and the versatility of our proposed analytical approach."}, {"title": "7.1 Big Five features improve rapport estimation performance between friends (RO-1).", "content": "The experimental results showed that facial expressions contain rich information for rapport estimation. This finding is in line with a previous study [24] revealing that facial expression features"}, {"title": "7.1 Big Five features improve rapport estimation performance between friends (RO-1).", "content": "yielded better estimation performances of rapport than other non-verbal features (e.g., audio features). The results also highlighted the importance of the BFFs for rapport estimation not only in initial interactions [3, 24] but also in interactions between friends. Specifically, combining the perceiver's and the target's BFFs yields the best performance. This result makes sense because rapport is built among two participants, and their Big Five personality traits influence rapport building [4].\nThe implication of these findings is that collecting the target's Big Five personality traits is useful for estimation models with facial expression to substantially improve their performance. However, practitioners do not always have access to it in practical situations. Therefore, further studies is required to determined actual personality trait can be substituted with personality trait estimated by estimation models (e.g., [22]) for the performance improvement."}, {"title": "7.2 BFFs promote models to capture three effects (RO-2).", "content": "We verify three hypotheses: 1) the perceiver's BFFs lead models to capture perceiver effects, 2) the target's BFFs lead models to capture target effects, and 3) combinations of the two lead models to capture relationship effects.\nFirst, the experimental results showed that BFF[P] lead models to capture perceiver effects, which substantiates our first hypothesis. The performance gain by BFF[P] was better than that by BFF[T]. The results can be explained by evidence that the perceiver's Big Five personality traits are more strongly associated with the perceiver's tendency to rate other people [4, 7]. Furthermore, adding BFF[T] also yielded performance gains. Although it is not clear how the target's BFFs contributed to the performance gain, one possibility is that the perceiver's nonverbal behavior toward a conversation partner with specific Big Five personality traits contains rich information about perceiver effects. The performance gain by adding BFFs [P+T] (e.g., PCC: .16, CCC: .10 in facial expression) is greater than that of models using BFFs [P+T] alone. Thus, nonverbal features and BFFs may have a synergistic effect for capturing perceiver effects.\nSecond, we confirmed that BFF[T] leads models to capture target effects, which supports our second hypothesis. The performance gain by BFF[T] was better than that by BFF[P]. This result is in line with findings showing that the target's Big Five more strongly influences the target's tendency to be rated by other people [4, 7]. Furthermore, BFF[P] also yielded better performances in facial expression. Although we cannot say for certain how the perceiver's BFFs contributed to the performance gain, one possible explanation is that the facial expression by the perceiver with specific Big Five personality traits may be an indicator of target effects.\nFinally, BFF[P+T] leads models to capture relationship effects in audio, which partially confirms our third hypothesis. In audio, BFF[P+T] led to the best PCC and CCC. However, in facial expression, BFF[P+T] did not yielded the best performances. The result imply that the perceiver's audio features and both BFFs are complementary relationship for capture the unique rapport of dyads.\nNext, we focus on relationship between modality and the estimation performances of three effects. On the whole, facial expression lead models better estimation performances of the perceiver and"}, {"title": "7.3 Analysis of Effective Big Five Dimensions", "content": "Fig. 5 shows the relationship between the PCC and BFDs. This analysis focuses only on facial expression features due to their high estimation performances. This analysis also focuses on PCC, as PCC and CCC have a similar ordinal relationship according to the type of features. We investigate the effectiveness of the perceiver's and the target's BFDs for improving the PCC of rapport scores and the corresponding effects. The red dotted line represents the PCC of models with all BFDs. The error bar denotes the standard deviations between 30 random"}]}