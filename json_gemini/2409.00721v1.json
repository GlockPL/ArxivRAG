{"title": "Who Would Chatbots Vote For? Political Preferences of ChatGPT and Gemini in the 2024 European Union Elections", "authors": ["Michael Haman", "Milan \u0160koln\u00edk"], "abstract": "This study examines the political bias of chatbots powered by large language models, namely ChatGPT and Gemini, in the context of the 2024 European Parliament elections. The research focused on the evaluation of political parties represented in the European Parliament across 27 EU Member States by these generative artificial intelligence (AI) systems. The methodology involved daily data collection through standardized prompts on both platforms. The results revealed a stark contrast: while Gemini mostly refused to answer political questions, ChatGPT provided consistent ratings. The analysis showed a significant bias in ChatGPT in favor of left-wing and centrist parties, with the highest ratings for the Greens/European Free Alliance. In contrast, right-wing parties, particularly the Identity and Democracy group, received the lowest ratings. The study identified key factors influencing the ratings, including attitudes toward European integration and perceptions of democratic values. The findings highlight the need for a critical approach to information provided by generative AI systems in a political context and call for more transparency and regulation in this area.", "sections": [{"title": "1. Introduction", "content": "In an era where artificial intelligence (AI) increasingly influences everyday life, the question of how these advanced technologies affect our perceptions and decision-making in key areas of society is becoming more urgent. One of the most critical spheres where this influence manifests is politics and the democratic process. With the advent of chatbots powered by large language models such as OpenAI's ChatGPT and Google's Gemini, new possibilities for gathering information and forming opinions on political events have emerged. Capable of generating human-like text and answering complex questions, these models are becoming an increasingly popular source of information for the general public, including potential voters.\nOur research focuses on analyzing the potential political bias of the ChatGPT (OpenAI's GPT-40 model) and Gemini (a free variant) chatbots from Google in providing political information. Specifically, we examine the evaluation of political parties represented in the European Parliament just before and after the elections to this institution. The aim is to uncover any systematic biases in the recommendations and evaluations these models provide regarding different political groups.\nThe potential political bias of ChatGPT and other large language models has been highlighted by several previous studies (Batzner et al., 2024; Fujimoto & Takemoto, 2023; Hartmann et al., 2023; Motoki et al., 2024; Rozado, 2023, 2024; Rutinowski et al., 2023). However, none of"}, {"title": "2. Methods", "content": "Our research uses a systematic approach to evaluate political bias in OpenAI's ChatGPT (GPT-40 model) and Google's Gemini chatbots. We focus on political parties represented in the European Parliament across all 27 member states of the European Union. This method was chosen because it encompasses a wide range of political ideologies across Europe and provides a structured framework for analysis based on political groups within the European Parliament. Additionally, conducting this research just before the elections to the European Parliament enhances its relevance and timeliness.\nWe collected data daily, from May 24 to June 19, 2024, for ChatGPT and from May 27 to June 19, 2024, for Gemini, covering the period immediately before and after the 2024 European Parliament elections. We formulated a standardized prompt for each EU Member State, including key elements that allowed us to obtain comprehensive and comparable data on the political parties represented in the European Parliament. The prompt began with a list of all political parties in each country that are represented in the European Parliament, followed by a request to produce a table with ratings for each of these parties. For each party, we asked for two key indicators: the first was a recommendation to vote on a scale of 0 to 10, where 0 meant \"definitely do not vote\" and 10 meant \"definitely vote.\" The second indicator was a score for the party's positive impact on society, again on a scale of 0 to 10, where 0 represented a \"very negative impact\" and 10 a \"very positive impact.\"\nIn addition to the numerical ratings, we asked the chatbots to justify their decisions and ratings. These justifications were subsequently used in the qualitative analysis. A specific example of the prompts used in this study is provided in Appendix A1. Each prompt was administered to both chatbots (ChatGPT and Gemini) once per day for each country throughout the data collection period. All prompts were phrased in English to ensure consistency.\nAlthough the original goal was to conduct similar assessments of both ChatGPT and Gemini, Gemini did not respond to most of the prompts, as will be discussed in the next section. Consequently, the final analysis of political parties was conducted only for ChatGPT. Additionally, the chatbots were asked to indicate the political group in the European Parliament to which each party belongs. This served primarily as a reality check to determine whether there was any significant \"hallucination\" by the models. We processed the ChatGPT outputs to prepare them for analysis and also verified the correctness of the assignment of parties to political groups."}, {"title": "3. Results", "content": "As mentioned above, the goal was to explore Google's Gemini model as well. However, during the period under review, out of 648 queries, Gemini provided a response in only 139 cases. In"}, {"title": "4. Conclusion", "content": "This study examined political bias in the ChatGPT and Gemini chatbots in the context of European politics. The results revealed two distinct approaches. Google heavily censored its chatbot, making it impossible to receive answers even to basic questions like \"What are elections?\". In contrast, OpenAI's ChatGPT did not hesitate to make recommendations regarding the choice of political parties. The research found that ChatGPT exhibited a strong tendency to give positive ratings to left-wing and centrist political groups, while right-wing and populist parties, particularly those in the Identity and Democracy group, consistently received low ratings. The model also showed a clear preference for pro-European attitudes and rated Euroscepticism negatively. The analysis identified specific themes associated with high ratings (e.g., progressive social policy, environmental protection) and low ratings (e.g., far-right ideology).\nThese observed biases can significantly impact the formation of users' political opinions, underscoring the urgent need to address ethical issues related to political bias in AI systems. The study emphasizes the importance of transparency in AI development processes and the need for regulation, particularly in the context of systems used for disseminating political information."}]}