{"title": "GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease", "authors": ["Wenjie Kang", "Lize Jiskoot", "Peter De Deyn", "Geert Biessels", "Huiberdina Koek", "Jurgen Claassen", "Huub Middelkoop", "Wiesje Flier", "Willemijn J. Jansen", "Stefan Klein", "Esther Bron"], "abstract": "Deep learning methods based on Convolutional Neural Networks (CNNs) have shown large potential to improve early and accurate diagnosis of Alzheimer's disease (AD) dementia based on imaging data. However, these methods have yet to be widely adopted in clinical practice, possibly due to the limited interpretability of deep learning models. The Explainable Boosting Machine (EBM) is a glass-box model but cannot learn features directly from input imaging data. In this study, we propose a novel interpretable model that combines CNNs and EBMs for the diagnosis and prediction of AD. We develop an innovative training strategy that alternatingly trains the CNN component as a feature extractor and the EBM component as the output block to form an end-to-end model. The model takes imaging data as input and provides both predictions and interpretable feature importance measures. We validated the proposed model on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND) as an external testing set. The proposed model achieved an area-under-the-curve (AUC) of 0.956 for AD and control classification, and 0.694 for the prediction of conversion of mild cognitive impairment (MCI) to AD on the ADNI cohort. The proposed model is a glass-box model that achieves a comparable performance with other state-of-the-art black-box models. Our code is available at: https://anonymous.4open.science/r/GL-ICNN.", "sections": [{"title": "I. INTRODUCTION", "content": "Magnetic Resonance Imaging (MRI) has the potential to aid clinicians in differentiating Alzheimer's disease (AD) dementia from other causes of mild cognitive impairment (MCI), and to help predict those at highest risk of progression to dementia [1]. Convolutional Neural Networks (CNNs) have shown potential to improve diagnostic and prognostic yield from MRIs [2]. However, despite the promising performance of machine learning models, they have yet to be widely adopted in clinical practice [3]. A key reason is that those high-performance machine learning methods using imaging data are considered as black-box models, which are difficult to interpret [4]. While the glass-box models, such as logistic regression are relatively easy for humans to interpret.\nExplainable artificial intelligence (XAI) methods have been used to explain the outputs of CNNs [5]. However, those post-hoc explanation methods have low fidelity [6]. In our previous work, we integrated CNNs with Explainable Boosting Machine (EBM) [7] to build a framework that is both transparent and capable of leveraging high-dimensional brain images (Glo&Loc-EBM) [8]. EBM is an interpretable Generalize Additive Model (GAM) that provides feature importance estimates. However, the proposed framework is not an end-to-end model, which means the feature selection, feature extraction and prediction are in different steps. The complexity of the framework makes it hard to implement because of the high time consumption and task specific training strategy.\nIn this study, we propose an end-to-end interpretable model integrating CNN and EBM. Because it is challenging to train the model like a common CNN, we developed a novel training strategy that trains the model end-to-end by optimizing CNN and EBM components alternatingly in each epoch. The model considers features independently at both the whole-image (global) level and the brain region (local) level. The proposed model is called the Global and Local Interpretable Convolutional Neural Network (GL-ICNN) in the rest of the paper. We validated GL-ICNN on two cohorts, considering AD and control (CN) classification task and prediction of the conversion of MCI to AD task. The interpretable outputs provided by GL-ICNN include individual-level and group-level feature importance, which helps people to understand how the model makes decisions and which brain regions play a role in AD diagnosis."}, {"title": "II. METHODS", "content": "A. GL-ICNN architecture\nIn our previous work [8], we combined the advantages of CNNs in extracting high-dimensional features with the inherent interpretability of EBM. We propose here a more efficient and elegant end-to-end formulation than the Glo&Loc-EBM, which in particular eliminates the compute-intensive feature selection and extraction steps. The novel GL-ICNN features an architecture that integrates multiple CNN backbones along with an EBM block. The CNN component extracts multi-scale features, while the EBM serves as the output block of the GL-ICNN. Additionally, we introduce an innovative training strategy where the CNN and EBM components are trained alternatingly in each epoch.\nThe entire brain image is divided into non-overlapping patches that collectively cover the whole image. A CNN model is trained to take both the whole image (Global) and individual brain regions (Local) as input, with several fully connected layers serving as the output block. This model, referred to as GL-CNN, is included in the comparison study as a black-box model. The CNN architecture consists of a global CNN backbone, which is a DenseNet [9], and local CNN backbones which are based on VGG [10], this architecture was adapted from our previous study [8]."}, {"title": "B. End-to-end GL-ICNN training", "content": "The decision trees in EBM are grown by repeatedly cycling through features with a small learning rate, which forces the model to sequentially consider each feature as an explanation of the current residual rather than greedily selecting the best feature (Algorithm2 in [12]). This particular training procedure of EBM makes it not straightforward to simply combine CNN and EBM in a neural network and rely on the usual back-propagation with stochastic gradient descent optimizer for end-to-end training. To address this, we propose a block coordinate descent approach, alternating between optimization of CNN and EBM weights. The training procedure of the GL-ICNN is shown in Algorithm 1. The hyperparameters, including Nmax and Ntolerate, are optimized using the validation set."}, {"title": "III. EXPERIMENTS", "content": "A. Study materials\nWe included participants with T1-weighted (T1w) MRI scans available at the baseline timepoint from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND) cohorts [13]. The ADNI cohort consists of 335 AD patients, 520 control participants (CN), 231 MCI patients who converted to AD within 3 years (MCIc), and 629 MCI patients who did not convert (MCInc) within 3 years. The PND cohorts includes 198 AD patients, 138 participants with Subjective Cognitive Decline (SCD), 48 MCIc patients, and 91 MCInc patients. The Iris pipeline [14] was used to obtain modulated gray matter (GM) maps. In order to name patches with intuitive names, we named the image patches after the brain regions that highly overlapped with them based on the Hammers brain atlas [15].\nB. Comparison Study\nWe compared the performance of the GL-ICNN against several baseline models, including black-box models such as GL-CNN, VGG, and DenseNet. Additionally, to investigate the added value of the CNN feature extractors compared to simpler handcrafted features, we trained an EBM using brain GM volumes as input (Vol-EBM). And we also investigated the added value of EBM compared to a simpler linear model that also would be interpretable as it allows to compute feature importance straightforwardly from the linear weights. To this end, we trained another glass-box model using the same CNN structure as the GL-CNN, but replaced the output block with a Linear layer (GL-ICNN-L). Furthermore, we compared the performance and computing time of the GL-ICNN with the non-end-to-end Glo&Loc-EBM. We trained the models for five repetitions and recorded the average training time.\nC. Validation of model performance\nWe validated the performance of the proposed model on AD diagnosis and MCI conversion prediction tasks, and on ADNI and PND cohorts. For the validation on ADNI cohort, subjects were randomly split into a training set, a validation set, and a testing set in a ratio of 8:1:1 in a stratified way according to class ratio. We trained the GL-ICNN from scratch on AD-CN task and fine-tuned the model on MCIC-MCInc task. The PND cohort was used as external testing set.\nTo evaluate the performance of proposed models on binary classification tasks, we used Area Under the ROC Curve (AUC). 95% Confidence Intervals (CIs) on the performance metrics were obtained based on 100 repetitions of bootstrapping on the testing set. And 95% CIs of feature importance were obtained based on 100 repetitions of bootstrapping on the training set. We used DeLong's test for determining whether the AUCs of two models were statistically significantly different."}, {"title": "IV. RESULTS", "content": "A. Model performance\nThe performance of the proposed and baseline models is shown in Fig. 2. The AUC of the GL-ICNN is not significantly different from that of the black-box models and the Glo&Loc-EBM on any of the 4 tasks. For AD-CN task on ADNI, the AUC of GL-ICNN (0.956) is significantly higher than the glass-box Vol-EBM (AUC=0.904, p=0.04) and GL-ICNN-L (AUC=0.883, p=0.01). For MCIc-MCInc task on ADNI, the AUC of GL-ICNN (0.694) is not significantly different from that of the other models. The performance of the GL-ICNN demonstrates a level of generalizability comparable to that observed in previous studies using the same cohorts [8], [14]. The total training time for Glo&Loc-EBM on the AD-CN task using the ADNI cohort was 81.3 hours, compared to 7.8 hours for GL-ICNN. This significant reduction is because the end-to-end GL-ICNN eliminates the need for a separate feature selection step and training multiple CNNs for feature extraction.\nB. Feature Importance for Interpretability\nThe group-level feature importance for the training set of the AD-CN task in the ADNI cohort is shown in Fig. 3. We observed that the GL-ICNN based the diagnosis mostly on regions of the temporal lobes, especially all regions containing the hippocampus and amygdala appeared for AD-CN task on ADNI. The brain regions with high feature importance align with prior clinical findings on AD [16]. We plan to collaborate with clinical experts to validate the reliability of the feature importance identified by the GL-ICNN."}, {"title": "V. CONCLUSION", "content": "The main contribution of this work is the introduction of a novel model architecture and training strategy that enables the model to directly take imaging data as input and learn the imaging features in an end-to-end fashion while remaining interpretable. The GL-ICNN achieves a comparable performance with state-of-the-art black-box models. In addition, the GL-ICNN provides the feature importance of brain regions to show how the model makes decisions."}]}