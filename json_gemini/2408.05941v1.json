{"title": "Multimodal Large Language Models for Phishing Webpage Detection and Identification", "authors": ["Jehyun Lee", "Peiyuan Lim", "Bryan Hooi", "Dinil Mon Divakaran"], "abstract": "To address the challenging problem of detecting phishing webpages, researchers have developed numerous solutions, in particular those based on machine learning (ML) algorithms. Among these, brand-based phishing detection that uses models from Computer Vision to detect if a given webpage is imitating a well-known brand has received widespread attention. However, such models are costly and difficult to maintain, as they need to be retrained with labeled dataset that has to be regularly and continuously collected. Besides, they also need to maintain a good reference list of well-known websites and related meta-data for effective performance.\nIn this work, we take steps to study the efficacy of large language models (LLMs), in particular the multimodal LLMs, in detecting phishing webpages. Given that the LLMs are pretrained on a large corpus of data, we aim to make use of their understanding of different aspects of a webpage (logo, theme, favicon, etc.) to identify the brand of a given webpage and compare the identified brand with the domain name in the URL to detect a phishing attack. We propose a two-phase system employing LLMs in both phases: the first phase focuses on brand identification, while the second verifies the domain. We carry out comprehensive evaluations on a newly collected dataset. Our experiments show that the LLM-based system achieves a high detection rate at high precision; importantly, it also provides interpretable evidence for the decisions. Our system also performs significantly better than a state-of-the-art brand-based phishing detection system while demonstrating robustness against two known adversarial attacks.", "sections": [{"title": "I. INTRODUCTION", "content": "Phishing attacks have become increasingly prevalent in our digital world, posing a major threat to individuals, businesses, and governments. According to a recent report from Anti-Phishing Working Group (APWG), nearly 1 million unique phishing webpages were observed for the first quarter of 2024 [1]. In response to this evolving cyber threat, researchers have made significant efforts to develop effective techniques for detecting phishing webpages. In particular, to overcome the limitations of blacklists in detecting new phishing web-pages, numerous solutions utilizing machine learning (ML) approaches have been proposed [2].\nConventional ML-based approaches train a supervised model to learn and differentiate the characteristics of the two classes of webpages, namely benign and phishing, e.g., [3], [4], [5], [6]. However, such approaches face a critical challenge as phishing pages become more sophisticated and reuse resources from benign pages they target [7]. This attacker strategy increases the similarity between phishing and benign pages, making detection increasingly difficult. The similarity of a phishing page to its target legitimate page serves the primary goal of an attacker, as that helps to deceive the victims. It is in this context that the brand-based phishing detection techniques are relevant [8], [9], [10], [11], [12], [13].\nBrand-based phishing detection approaches are developed relying on the empirical evidence that most phishing webpages attempt to imitate popular and trusted brands. As per statistics [9], [10], [1], more than 90% phishing attacks target just a couple of hundreds of brands. Therefore, brand-based phishing detection solutions try to identify the brand that a given webpage tries to imitate or render. Subsequently, if the domain name in the URL is different from the identified brand, then the page is likely to be a phishing page. Brand-based phishing detectors have dual advantages-besides detecting a phishing page, they are also able to identify the targeted brand. Recent brand-based phishing detectors use well-known models from Computer Vision (CV), analyzing a webpage screenshot [14], [8] or the logos on screenshots [9], [10], to identify the brand a webpage is rendering.\nThe models in the most recent brand-based phishing detection proposals, in particular VisualPhishNet [8] and Phishpedia [9], are trained to protect a reference list of well-known brands. This requires labeled dataset of phishing and benign webpages. In fact, Phishpedia also requires the coordinates of the logos on webpages to be indicated in the dataset to train its object (i.e., logo) detection model. Note that datasets must be collected not just once but continuously at regular intervals to retrain the models so that the detection systems adapt to the changing dynamics of phishing attacks and their target (benign) pages over time. Clearly, this process is laborious and costly. Furthermore, maintaining a reference list for effective domain verification with the identified brand is also challenging [15], [12].\nRecent times have witnessed the rise of large language models (LLMs) pretrained on massive datasets and capable of performing multiple downstream tasks. The underlying transformer architecture [16] of the LLMs has enabled the creation of powerful models with billions and even trillions of parameters. Among these, we believe the multimodal LLMs, which can analyze various data types such as text and images, show significant potential for brand-based phishing detection. With their vast knowledge, the multimodal LLMs would have learned about webpage representations of numerous well- known brands. Therefore, these LLMs may have the capability to identify brands of a given webpage, by analyzing the logos present, the theme of the page, the contents, etc.\nIn this study, we take a fresh look at phishing detection and explore the potential of multimodal LLMs in automatically detecting phishing pages through brand recognition. The biggest advantage of having an LLM-based phishing detection system is that it does not require any labeled data. This also allows us to build a solution that is no more limited to one type of data, e.g., logos [9], or HTML contents [4], or screenshots [8]. Furthermore, LLMs offer the opportunity to extract and provide interpretations of results, a capability lacking in existing research proposals. This interpretability could significantly enhance the understanding and effectiveness of phishing detection mechanisms.\nSpecifically, we try to answer the following questions:\n\u2022 How do LLMs perform in detecting phishing webpages and in identifying the targets of the phishing attacks, and how good are they in providing explanations? (Sections V-A, V-B and V-C)\n\u2022 Besides the screenshot, HTML contents are also available from a webpage. What are the gains, synergy, and conflicts due to the different inputs (screenshot/HTML) and their combination in phishing detection performance? (Sections V-A, V-D and V-E)\n\u2022 How does the LLM-based phishing detection system perform in comparison to a state-of-the-art reference- based phishing detection solution? (Section V-F)\n\u2022 Using the APIs of pretrained LLMs for inference tasks comes with a cost. What is the cost incurred in using an LLM-based phishing detection system? (Section V-G)\n\u2022 Recent works have shown that visual-based phishing systems can be evaded using adversarial perturbations [17], [18], [19]. How robust are LLM-based phishing systems in response to these adversarial attacks? (Section VII)\n\u2022 What are the new attack vectors due to the use of the large pretrained models for phishing detection? (Section VIII)\nTo answer the above questions, we first carefully collect a new phishing dataset with manually labeled attack targets. We design and develop a new system that processes given webpages and utilizes multimodal LLMs to, both, detect and identify phishing webpages (Section III). We evaluate three state-of-the-art multimodal LLMs, namely GPT-4, GeminiPro 1.0, and Claude3, on their capability to assist with phishing detection. Our experiments demonstrate that LLMS show promise in detecting phishing pages at high precision, while also providing explanations. Equally importantly, we study the robustness of our system against adversarial phishing samples and observe that the LLM-based design helps in successfully identifying the target brands even in the face of adversarial perturbations.\nWe make the following contributions through this work:\n\u2022 We build an end-to-end pipeline that uses LLMs for phishing detection, identification, and result explanation. During the process, we also define prompts that are effective in achieving high detection accuracy (Section III). We publish the code-base online [20].\n\u2022 We collect, process, and analyze a new dataset to evaluate phishing detection solutions (Section IV). We publish both the dataset and the system for automatically collecting new datasets, so as to make it easier for researchers to gather datasets in future [20].\n\u2022 We carry out comprehensive performance evaluations of the LLM-based phishing detection system using the latest dataset we collected. We evaluate the system using three LLMs, across different input types\u2014HTML, screenshot, and both, and present the results (Section V). We also present a case study on webpages that are wrongly identified (Section VI).\n\u2022 As LLMs offer new capabilities for phishing detection, we also study corresponding relevant aspects:\nWe evaluate the cost of using LLMs for the purpose of phishing detection (Section V-G).\nWe evaluate the robustness of LLM-based phishing detection to recently proposed adversarial attacks against phishing models (Section VII).\nWe discuss new attack vectors arising from the use of LLMs (Section VIII)."}, {"title": "II. RELATED WORKS", "content": "Without being exhaustive, we review some of the relevant existing research works below."}, {"title": "A. HTML-based approaches", "content": "Earlier works have explored the possibility of using HTML in phishing detection. HTML-based approaches have focused on HTML tags for malicious functionalities and having a similar layout to the target webpages and structural characteristics of phishing web pages.\nRosiello et al. proposed DOMAntiPhish [21] that compares the DOM structure of a webpage to the previously stored webpages where a user inputs sensitive information. If the same information is input to a webpage with a similar layout in terms of DOM structure, it is assumed to be a phishing attempt. This study is based on the rationale that a phishing webpage tries to be similar to the target benign webpage. However, it faces limitations against the phishing pages which are only visually similar to the genuine web page but different in DOM structure. Li et al. proposed a stacking model leveraging URL and HTML features [5]. The model introduced HTML string embedding and crafted lightweight features from URLs and HTML scripts to detect phishing pages. Multiple studies have shown the vulnerability of HTML-based solutions [6], [22]. Lee et al. showed that tree-based models are prone to evasion attacks, where attackers can easily manipulate the most relevant features in the model [6]. Subsequently, they proposed a phishing detection system that reduces the reliance on a few specific features by adding noise to the data. Similarly, Chiew et al. proposed a hybrid ensemble feature selection framework for an ML-based phishing detection system [23]. Saleh et al. [24] proposed a method for identifying and detecting phishing attacks by using deep learning models on the textual content of websites."}, {"title": "B. Visual-based approaches", "content": "Visual-based phishing webpage detection uses the visual features or invariants of a webpage to identify and classify it as a phishing website [14], [25], [26], [27], [8], [9], [11], [10]. Such techniques rely on analyzing the layout, design, and images used on a webpage to differentiate between legitimate and malicious websites. In one of the earliest works, Fu et al. [14] proposed a phishing web page detection system by measuring Earth Mover's Distance (EMD) between screenshots of webpages. Their approach directly uses colors and coordinates of an image for building an image signature in contrast to the subsequent studies that used neural networks as the deep learning model made significant advancements.\nLiu et al. [26] proposed a Convolutional Neural Network (CNN) based approach for detecting phishing webpages. They extracted visual features from the captured screenshots of webpages and used a CNN classifier to distinguish between legitimate and phishing pages. VisualPhishNet, proposed by Abdelnabi et al. [8] uses an advanced approach by training a CNN with triplet samples that utilize the multiple webpage screenshots from the same and different brands, with the goal of identifying a webpage that looks similar to a protected website (a small list of legitimate websites).\nLogo-based phishing detection is a type of visual-based technique that specifically focuses on detecting and identifying the logo of a website as part of the phishing detection process. The advancement of models in Computer Vision has helped develop practical solutions in this space. Lin et al. proposed Phishpedia [9], a system that combines Faster-RCNN and Siamese models to detect and identify logos on webpage screenshots. Narwaria et al. proposed a framework for detecting phishing URLs, PhishAOD [28], by analyzing the visual similarity between the logo of the given webpage and that of legitimate ones. They used a deep learning approach to extract features from the logos. Tan et al. proposed a hybrid approach using visual and textual identities of a webpage to overcome the performance limitation of previous visual-only approaches [29]."}, {"title": "C. LLMs for security", "content": "LLMs are currently being explored for solving challenges in the domain of security as well as online trust and safety [30]. AutoCodeRover [31] uses multiple LLMs to locate bugs in codes and generate patches for GitHub issues. He et al. [32] propose using LLMs with prompt-learning capabilities to detect toxic webpage contents. LLMs have also been used for phishing email detection [33], [34]. Finally, in a recent proposal, LLM is utilized to build knowledge-base of brands for brand-based phishing detection solutions [12]."}, {"title": "III. LLM-BASED PHISHING WEBPAGE DETECTION", "content": "In this section, we describe the design of our phishing webpage detection system utilizing LLMs."}, {"title": "A. System design", "content": "A brand-based detection system works in two phases:\n\u2022 Brand identification: Identify the brand of a given webpage, based on its logos, theme, description, etc.\n\u2022 Domain verification: Check whether the domain name of the given page matches the identified brand.\nMuch of the modeling efforts in the recent brand-based phishing detection proposals [8], [9], [10] have been to solve the first challenge of brand identification. The Computer Vision models used in these proposals look for visual similarities with existing well-known brands. Once the brand is identified, the second and final task is cross-checking the URL and matching the domain name with the identified brand. For example, if the brand identified is that of Paypal, the domain name in the URL is expected to be paypal.com, if the webpage is legitimate. However, such a simple comparison comes with pitfalls:\n\u2022 Brand names might change over time (Facebook to Meta).\n\u2022 Brand name and domain name might look legitimately different, or a brand might have aliases or sub-brands (x.com and twitter.com).\n\u2022 Brands may be represented differently in various regions or languages. (e.g., Zuimeitianqi and Zuimei weather)\n\u2022 Often, webpages carry product information (e.g., iPhone, Outlook, etc.) that might be extracted as the best semantic feature by a machine learning model rather than the brand itself. Therefore, there is also a subtle challenge of mapping products to brands.\n\u2022 Models might also extract a trademark instead of a brand name.\n\u2022 As a final point, the list of brands targeted by phishing changes over time [15], [12].\nGiven these challenges, maintaining a static list of domain names corresponding to a set of reference brands is not an effective solution. Considering the above points, we design our system in two phases of brand identification and domain verification and utilize LLMs for both phases.\na) Brand identification: First, a given webpage is introduced into a sandbox environment to ensure safety from potentially malicious content, wherein both a screenshot and HTML content of the page are extracted from the rendered webpage via a web engine. The HTML contents are processed to extract relevant information such as the title, meta description, path of the favicon, text corresponding to the logo images, header and footer texts, etc. Note, we do this preprocessing primarily to reduce the input token size and keep the cost manageable (refer Section V-G). These two outputs, the visual representation via the screenshot and the textual data extracted from the HTML, are subsequently provided to a multimodal LLM. Using an engineered prompt, the LLM is instructed to process these inputs to identify the brand (detailed below in Section III-B). We also instruct the LLM to provide output in a particular format. The output includes the identified brand, the brand-related elements on the page, and, equally importantly, the supporting evidence. The following example illustrates the output from an LLM.\nb) Phishing webpage classification: Once the brand is recognized, the identified brand information is passed through to another LLM. This additional layer of LLM is instructed to compare the identified brand and the domain name in the given URL to carry out domain verification. As LLMs have learned from massive amounts of online data, we believe they are equipped to understand the association between brand name and domain name, overcoming the challenges mentioned above. The final output is a detailed phishing detection result, which encompasses comprehensive insights regarding the identified brand per the input domain name. We demonstrate this in Section V-C."}, {"title": "B. Prompts for brand identification", "content": "We design the prompts to provide instructions along with screenshots and/or HTML information to LLMs, so as to determine the target brand of the given webpage. Besides pinpointing the webpage's target brand, we further extend the task to include the identification of any visible fields soliciting credentials, e.g., passwords or identification numbers, call-to-action buttons, e.g., Login or Click here to proceed, as well as supporting evidence. This comprehensive approach aims to harness LLM's analytical capabilities for subsequent evaluation, if necessary, and explainability of the results.\nTo examine three combinations of input data, we give different prompts to the LLMs depending on the data. Besides, there is a common instruction among all configurations. We first define the prompts for the three input data types: screenshot, HTML contents, and both.\n1. Prompt specifically with (only) webpage screenshot as input\nI want you to act as a webpage brand identifier.\nGiven a screenshot of a webpage. I want you to identify the brand of the webpage from the screenshot alone.\nAdditionally, also note whether fields are asking for sensitive user credentials as well as any call-to-action buttons / links. Examples of sensitive user credentials: email, username, password, phone number, etc. Examples of call-to-action elements: buttons or links that lead to asking for user credentials.\nReturn your response in the following format, and replace everything in [] with your answer:\n1. Brand: [response]\n2. Has Credentials: [Yes/No]\n3. Has Call_To_Action: [Yes/No]\n4. List of credentials: [response if Yes for (2), otherwise NA. Keep within the top 10 fields.]\n5. List of call_to_action: [response if Yes for (3), otherwise NA. Keep within the top 10 fields.]\n6. Confidence Score: [How confident are you when identifying the brand on a scale of 0.00 to 10.00 (in 2 decimal places), 10.00 being absolutely confident, 0.00 being not confident]\n7. Supporting Evidence: [response, keep it within 300 words]\n2. Prompt specifically with information from HTML as input\nI want you to act as a webpage brand identifier.\nGiven the key information from the HTML content of a webpage, I want you to identify the brand of the webpage from this information alone. The key information is extracted from the actual HTML script of the webpage, and this information includes the title of the webpage, the metadata, the favicon, the logo attribute, the footer and header text, and the nav bar. These areas are where the brand information can typically be found. Make good use of this information to identify the brand related to each webpage.\nReturn your response in the following format, and replace everything in [] with your answer::\n1. Brand: [response]\n2. Confidence Score: [How confident are you when identifying the brand on a scale of 0.00 to 10.00 (in 2 decimal places), 10.00 being absolutely confident, 0.00 being not confident]\n3. Supporting Evidence: [response, keep it within 300 words]\n3. Prompt with both screenshot and HTML as input\nI want you to act as a webpage brand identifier.\nGiven a screenshot and key information from the HTML script of a webpage. I want you to identify the brand of the webpage from these two sources alone.\nAdditionally, also note whether there are fields asking for sensitive user credentials as well as any call-to-action buttons/links. Examples of sensitive user credentials: email, username, password, phone number, etc. Examples of call-to-action elements: buttons or links that lead to asking for user credentials.\nResponse format the LLM is instructed to follow is the same as that for screenshot\nThe following is the common prompt that is used along with all the above configurations to provide further instructions and restrict online access for safety purposes.\nPlease adhere strictly to the following rules for your analysis:\n1. Do not interact with the webpage in a live environment or use browser functionalities.\n2. Avoid inspecting the webpage's source code, the website's address bar, SSL certificates, URLs, or any interactive features.\n3. Your analysis should be grounded solely on the given input data.\n4. No additional resources or external validations should be used.\nNote that some pages may include information / logos of other brands, especially pages that use single sign-on features or pages created by website builders."}, {"title": "IV. DATA COLLECTION", "content": "We collected our dataset by crawling the bengin and phishing webpages over a period of three months from Oct. to Dec. 2023. For benign pages, we visited the top-ranked websites from the Tranco list [35]. Specifically, we crawled the top 10,000 ranked domains and those that ranked between 100,000 and 105,000, so as to include a broad spectrum of legitimate webpages that vary in popularity. Of these 15,000 pages, we applied filtering techniques (see Section IV-B) to remove invalid pages, domains such as googleapis.com, etc. Finally, we manually labeled the brands of these legitimate domain names limited by our budget. These processes brought down the labeled benign pages to around 3,000.\nFor webpage crawling, we use Playwright [36] along with Python scripts; the preprocessing of collected data and invalid sample filtering are all implemented in Python. Specifically, we collected the screenshots using Playwright's screenshot API and extracted the essential information in HTML with the BeautifulSoup library of Python. We collected information such as title, favicon path/filename, logo image's alternate text, headers, footers, navigation bar content, paragraph texts, span text from the parsed HTML text, etc.\nWe used OpenPhish [37] for obtaining feeds of phishing URLs. Due to the volatility of phishing pages, authorities' mitigation efforts, and attackers' cloaking techniques, a significant number of phishing webpages collected from a crawler are inaccessible or invalid. On the other hand, adversaries often introduce multiple URLs that provide identical or similar web pages to maximize the success rate and viability of their phishing pages. These duplicated and invalid samples in the dataset often lead to overestimation of detection performance by providing a model with many low-hanging fruits.\nThe following explains the process of obtaining labeled unique phishing webpages."}, {"title": "A. Dealing with anti-cloaking tactics of phishing pages", "content": "a) Preliminary Anti-cloaking test: We performed a preliminary analysis to assess the cloaking behaviors of phishing pages based on previous studies [38], [39]. This targeted experiment involving approximately 150 phishing URLs was conducted to determine the effects in phishing webpage rendering due to differences in environmental variations; specifically, the variations we tested include user-agent string in the browser, user interaction, referrer string, as well as multiple geolocations via VPN.\n\u2022 User-agent: According to our anti-cloaking testing with the environment variations in OSes (e.g., Windows and MacOS), device platforms (i.e., Desktop and Mobile devices), and crawling tools (i.e., Selenium and Playwright), it showed marginal variation between the different configurations, except for the explicit bot-like browser profiles. Consequently, we adopt one of the most popularly used User-Agent strings that results in minimal cloaking, i.e., Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36.\n\u2022 User interaction: We tested different user actions upon opening the web pages, e.g., Page scrolling, Mouse clicking, and Mouse movement. We observed that only the integration of mouse movements showed a pronounced effect in evading cloaking techniques. Specifically, the configuration that had mouse movements recorded no blocking from the phishing pages we visited.\n\u2022 Referrer: We explored four referrers where users may encounter phishing URLs: Google, Facebook, phishing URL's own domain name, and an empty referrer. Our test results highlighted a notable increase in cloaking when no referrer was employed. In contrast, using a self-referential source led to a significant drop in the cloaking behavior."}, {"title": "B. Preprocessing", "content": "a) Invalid sample filtering: We ignore the empty and erroneous samples from the initial gathering based on:\n\u2022 Incomplete samples: Samples with missing HTML scripts, screenshots, certificate info, DNS records, or network resources.\n\u2022 Response Status: Samples with non-200 HTTP response status codes.\n\u2022 Semantic blank: Samples with HTML contents and CSS styles that lead to potentially blank pages.\n\u2022 Duplication: Duplicated samples by applying SHA256 to URLs and HTML contents.\n\u2022 Screenshot-pixel standard deviation: Low standard deviation in grey-scale screenshot indicating a blank page.\n\u2022 Screenshot-edge count: Low canary edge count in grey-scale indicating fewer shapes and text, suggesting a lack of content.\n\u2022 Screenshot-text length: Short text detected by OCR indicating lack of significant contents.\n\u2022 Verification or warning pages: Screenshots that show security or human user verification, e.g., CloudFlare verification, or warnings pages by browser and ISP. Dealing with such techniques, e.g., CAPTCHAs, is complicated and outside the scope of this work [40].\nA small-scale experiment was conducted to establish the threshold values for these metrics. This set includes examples of blank pages (in both white and black), nearly blank screenshots, screenshots with minimal content, and screenshots rich in content. The threshold values obtained from this experiment are used for the final dataset filtering."}, {"title": "C. Brand labeling", "content": "While OpenPhish feeds phishing webpages, we still need to identify and verify the brands targeted by the attack. The verification process involves two stages. First, we used VirusTotal [41], a platform aggregating analyses from multiple security vendors, to evaluate URLs. We selected four vendors- OpenPhish, Google Safe Browsing, Kaspersky, and Trustwave. OpenPhish uses proprietary algorithms and machine learning algorithms; Google Safe Browsing benefits from extensive web crawling; Kaspersky is renowned for its cybersecurity research and development; and Trustwave provides solutions against phishing emails [33]. URL verification was conducted over three consecutive days to account for any changes or updates.\nIn the second stage, three analysts (including only one co-author) conducted manual reviews. They analyzed screenshots of each webpage and compared their respective brands to their URLs. This two-stage approach ensures high accuracy in categorizing samples as phishing or legitimate. To classify a sample as phishing, both of these conditions had to be met: i) a webpage sample is flagged as phishing if all the four security vendors on VirusTotal over the three-day verification period. Previous research suggests that a URL flagged by at least two vendors typically confirms its phishing status, and raising this to four enhances robustness and minimizes false positives [7], ii) the sample was manually verified as phishing."}, {"title": "D. Final Data", "content": "Although we obtained around 377,000 phishing URL links from OpenPhish, based on the above filtering and labeling budget, our eventual set consists of 1,500 phishing pages with their target labels identified. Refer to the Table I for the final numbers. However, we publish both the labeled and unlabeled data online [20] so that researchers can utilize them in the future."}, {"title": "V. EVALUATION: BRAND IDENTIFICATION USING LLM", "content": "In this section, we present the evaluations of the LLM- based phishing detection system. We experiment with three commercial LLMs-Google Gemini Pro-Vision 1.0, OpenAI GPT-4-turbo, and Anthropic Claude3 Opus, as the first and second-phase LLM models in our detection system. Our goal here is to answer the following questions:\nQ1. What is the performance of an LLM-based phishing system? Which multimodal LLM shows better overall performance in phishing detection?\nQ2. Which input data (HTML/screenshot) helps in achieving higher accuracy?\nQ3. Does an LLM have any strengths/weaknesses with a specific input data type for the brand identification task?\nQ4. What is the effectiveness of the second-phase LLM in detecting phishing webpages?\nQ5. Does LLM help in providing interpretation of results?\nQ6. What is the effect of one input data type over the other?\nQ7. How does LLM-based phishing detection perform when compared against a state-of-the-art solution?\nQ8. What is the cost of using LLM for brand identification? How does it vary with the input types?\nDataset: We use the manually labeled and verified benign and phishing webpage dataset (Table I) described in Section IV for the evaluation of brand identification and phishing classification using LLMs."}, {"title": "A. Phishing detection and target brand identification", "content": "a) Overall performance: As mentioned earlier, our proposed system consists of two phases: brand identification and domain verification.\nFigure 2 presents the results for Q1, i.e., phishing detection performance involving both phases.\nLet us analyze the case where HTML contents and screenshots of webpages (both) are given as input to the system. We observe that GPT and Claude3 have similar detection rates (recall) for almost the same precision values. The F1-score achieved by GPT-4 and Claude3 are approximately 0.92 and 0.90, respectively. Gemini lags behind the other two-for Gemini to achieve a similar detection rate (as GPT and Claude), and the precision drops by more than 15%. Consequently, the F1-score of Gemini is lower at \u2248 0.81.\nFigure 2 answers Q2 and Q3 (also revisted later in Section V-D). For Gemini and GPT, providing HTML content and screenshots together results in better precision and recall (and, therefore, the best F1-scores as well) than just either of them. Claude, however, is able to achieve the best performance with just a screenshot. Interestingly, the precision of Gemini drops to a low 63.6% when it is given only HTML as input. We discuss the reasons for misidentification and error cases in later sections below."}, {"title": "B. Effectiveness of domain verification (Q4)", "content": "Next, we evaluate the effectiveness of the second phase of domain verification in the phishing detection system (Q4)."}, {"title": "C. Interpretation of phishing classification (Q5)", "content": "We now demonstrate the explanations provided by LLMs for phishing detection in both phases.\na) Brand identification by first-phase LLM: Since ML- based solutions are prone to false positives, there is a need to provide an interpretation that might better help the user (e.g., a browser warning with an explanation). Therefore, in our design, the first-phase LLM gives the identified brand and supporting evidence as output, which are passed on to the second-phase LLM. The second-phase LLM is instructed to provide the final results along with interpretable evidence. The following example shows the brand identification result from GPT-4 against a real phishing webpage targeting WhatsApp. In this case, we provide both HTML and screenshots as input to the model for analysis. We observe that the LLM considers not only logo images and texts in the header and title, but also the brand color for its decision.\nBrand: WhatsApp\nHas Credentials: Yes\nHas Call-To-Actions: Yes\nList of Credentials fields: Phone number\nList of Call-To-Actions: INSTALL UPDATE\nConfidence Score: 9.50\nSupporting Evidence: The screenshot prominently displays the WhatsApp logo along with a characteristic green color scheme, which is strongly associated with the brand. The title in the HTML information, \"WhatsApp,\u201d the meta description, and headers text also merely state \"WhatsApp,\" reaffirming the identity of the webpage as belonging to WhatsApp.\nb) Phishing classification by second-phase LLM: The second-phase LLM is introduced to resolve the gap between the brand identified (by the first-phase LLM), the domain name, and the actual brand targeted by the attack. The following is an example of the input and output of the second-phase LLM for domain verification. We recall that our instruction specifically asks the LLM not to visit the URL so that our system is not infected via the malicious page (through various means, including new prompt injection attacks that target LLMs as discussed in Section VIII).\nInput\nURL: https://polert.xyz/52Lp/whatsapp.html\nIdentified Brand: WhatsApp\nOutput\nGenuine/Phishing: Phishing\nEvidence: The URL uses the domain \"polert.xyz\" instead of the official domain \"whatsapp.com\", which suggests it is not associated with the official WhatsApp brand and may be suspicious or malicious.\nGenuine URL: https://www.whatsapp.com\nWe observe that the second-phase LLM compares the domain name to the identified brand (given at input), while also suggesting what might be the genuine webpage URL. In other examples, we noticed that the second-phase LLM is also able to correct misleading identification from the first-phase LLM, such as typos due to failed OCR. For example, the webpage of 'Credit Agricole' was wrongly identified by Gemini as 'Credit Agricoole' but the second-phase LLM detected this typo as 'Credit Agricole'. The strict and specific instruction for the second-phase LLM helps to keep the focus on brand and domain matching and correct the LLMs' non- deterministic nature."}, {"title": "D. Exclusive value of each LLM (revisiting Q2 and Q3)", "content": "Earlier, we observed that GPT-4 performed better than the other two LLMs; we now go deeper into the analysis. In particular, we are interested in analyzing the exclusive winning rate of each LLM in detecting phishing pages."}, {"title": "E. Conflict and Synergy from input data (Q6)", "content": "Another interesting question is whether one input type influences the identification result negatively, not just positively (Q6). Table II defines the corner cases of input combinations; e.g., 'Negative SS' category means that a screenshot negatively affects the performance and providing only HTML is better. This helps us to analyze some exceptional cases in which an LLM returns the correct identification only when limited information is given and, in particular, gives a wrong answer when provided with another input type.\nThe left-most column, Negative SS, shows that the brands of around 2.8% of samples in our dataset are correctly identified by Gemini when we give only HTML input, but gets the brand wrong when screenshot is provided as additional input. That is, neither screenshot alone nor screenshot and HTML together help in identifying these samples. In contrast, for nearly 14% of samples, Gemini relies on the screenshots (Relying on SS), which means it returns a correct brand when a screenshot is given (with or without HTML), but the wrong brand when given only HTML information.\nInterestingly, the composition of multiple inputs not only creates synergy but also creates conflict (defined in Table II)."}, {"title": "F. Comparison with state-of-the-art brand-based phishing detection (Q7)", "content": "In this section, we compare the LLM-based phishing detection with a state-of-the-art vision-based phishing detection system, i.e., VisualPhishNet [8"}]}