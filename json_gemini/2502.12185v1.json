{"title": "Large Language Models for Extrapolative Modeling of Manufacturing Processes", "authors": ["Kiarash Naghavi Khanghah", "Anandkumar Patel", "Rajiv Malhotra", "Hongyi Xu"], "abstract": "Conventional predictive modeling of parametric relationships in manufacturing processes is limited by the subjectivity of human expertise and intuition on the one hand and by the cost and time of experimental data generation on the other hand. This work addresses this issue by establishing a new Large Language Model (LLM) framework. The novelty lies in combining automatic extraction of process-relevant knowledge embedded in the literature with iterative model refinement based on a small amount of experimental data. This approach is evaluated on three distinct manufacturing processes that are based on machining, deformation, and additive principles. The results show that for the same small experimental data budget the models derived by our framework have unexpectedly high extrapolative performance, often surpassing the capabilities of conventional Machine Learning. Further, our approach eliminates manual generation of initial models or expertise-dependent interpretation of the literature. The results also reveal the importance of the nature of the knowledge extracted from the literature and the significance of both the knowledge extraction and model refinement components.", "sections": [{"title": "1. Introduction", "content": "Modeling of parametric relationships, i.e., the linkage between process parameters and performance metrics of the process or the product, is critical for control of manufacturing processes. The creation of physics- based simulations for deriving such relationships is often difficult and time-intensive (especially for novel processes) due to incomplete understanding of the underlying multiphysical multidomain interactions and associated constitutive laws. For example, existing models cannot predict the part-scale distribution of grain and void characteristics in electrically-assisted incremental forming of sheet metal due to a lack of models that can capture the non-equilibrium multiaxial thermomechanical conditions imposed on the metal (Bao et al., 2015; Chang et al., 2021; Huang & Log\u00e9, 2016; Shrivastava & Tandon, 2019). Similarly, the ICME Virtual Aluminum Castings (Allison et al., 2006) required models created iteratively across decades before being fully operational. It can also be difficult to construct physics-based models at the appropriate length and time scales. For example, such models can predict post-print sintering in Binder-jet printing on the few- particles scale (Fuchs et al., 2022; Grant et al., 2023; Mao et al., 2023; Mostafaei et al., 2021; Paudel et al., 2021; Sadeghi Borujeni et al., 2022) but cannot capture the part-scale spatial distribution of grain size, voids, cracking, and surface finish for complex geometries. Similarly, linking the nanoscale optical intensification between nanoparticle pairs to part-scale thermal modeling for millions of nanoparticles in printed circuits requires a scaling law, the formulation of which has taken many years and is still incomplete (Cleeman et al., 2022; Devaraj et al., 2020; Devaraj & Malhotra, 2019; Devaraj et al., 2021; Jahangir et al., 2020). The creation of such physics-based models is also affected by subjective interpretations of literature by the"}, {"title": "2. Methodology", "content": null}, {"title": "2.1 Overview of the framework", "content": "The traditional approach to generating physics-based models relies on human interpretation of problems using insights from related literature and prior knowledge (Figure 1a). This method often involves a trial- and-error process to achieve acceptable results, making it prone to human error and particularly challenging for high-dimensional problems. With advancements in machine learning, data-driven models have emerged as an alternative (Figure 1b). However, these models typically function as black boxes, lacking interpretability and struggling with extrapolation (Muckley et al., 2023). Additionally, they do not effectively incorporate well-established physics-based knowledge, relying solely on the provided data.\nTo address these limitations, we propose an LLM-based framework that integrates the strengths of both approaches (Figure 1c). Our framework consists of two key components designed to enhance model interpretability while maintaining the adaptability of data-driven methods. The first component uses RAG to retrieve knowledge on parametric relationships, including textual descriptions or equations, from literature that is potentially related to the target manufacturing process. A detailed explanation of the first component is provided in Section 2.2. The second component involves an LLM that utilizes this retrieved information to generate initial mathematical models. Furthermore, An iterative refinement process, inspired by the work of Shojaee et al. (Shojaee et al., 2024), uses LLMs to refines the equations and enhance their accuracy based on a small experimental dataset. This is possible due to the ability of LLMs to utilize previously generated answers as a hint to improve accuracy at each iteration (Zheng et al., 2023). A detailed explanation of the second component is provided in Section 2.3. The knowledge retrieval component eliminates the need for human interpretation of the literature while the refinement component addresses the known accuracy limitations of LLM methods that are based purely on knowledge retrieval. Existing approaches that generate models without incorporating the knowledge retrieved in the first component (Without RAG) will be compared with our proposed framework (With RAG) in the results section."}, {"title": "2.2. Knowledge retrieval", "content": "RAG is employed to process and retrieve information on parametric relationships from the literature. As shown in Figure 2, research papers (in PDF format) for processes that are potentially related to the process of interest are collected and processed using Llamaparse (LlamaParse). This parses these paper's content into manageable chunks (Sharma et al., 2024), i.e., smaller and more manageable sections, by dividing each larger document into parts. Each chunk is embedded via OpenAI's \u201ctext-embedding-3-small\" model, thus transforming the text into vector representations for similarity-based retrieval. For the process of interest, a query is designed to analyze these vector representations to discern the relationships between process parameters and the resultant process or product performance characteristics of interests, including the qualitative nature of these relationships (e.g., a quadratic increase in output \"A\" due to input \"B\")."}, {"title": "2.3 Model Generation and Iterative Model Refinement", "content": "Figure 3 illustrates the model generation and iterative model refinement component of our framework. First, the retrieved information is formatted and combined with a prompt for the LLM (Prompt Form 1 in Table 2) to generate initial analytical models (Fig. 3a). This prompt consists of information on parametric relationships extracted by the retrieval section followed by an instruction to transform this information into equations, specifically instructing the LLM not to rely on its general knowledge for creating the equations. Feeding this prompt to a pretrained LLM (GPT-40-mini here) yields an initial analytical equation of the parametric relationship. A set of 50 candidate equations is generated to account for potential inaccuracies and LLM hallucination during retrieval (Chen et al., 2024), with each equation created independently from scratch. A temperature parameter ranging randomly between 0.3 and 0.8 is applied to encourage diversity and creativity in equation generation (Peeperkorn et al., 2024; Shojaee et al., 2024). Note that till this point only the functional form of the analytical models is created.\nA small experimental dataset is used to fit the constant coefficients in the model. The dataset is split into a training set for fitting each model's constants and a validation set for evaluating the model accuracy based the Coefficient of determination (R2) and Mean Squared Error (MSE). Twenty top-performing models are selected and ranked based on their R2 scores. If any of the R\u00b2 scores of these top performing models satisfy the success criterion (validation error less than 2%) then the best performing model is selected for use.\nIf the success criterion is unsatisfied then iterative refinement is conducted (as in Figs. 3b-c) by using the prompt update instruction (Raman et al., 2022) shown in Table 2-Prompt Form 2. This prompt includes the twenty top-performing models, their R\u00b2 values, and the initial prompt that also encompasses the information retrieved from the literature. It provides instructions on the significance of previous models based on their R2 values, ensuring that the model generation process prioritizes the most accurate previous models as sources when creating new ones. Additionally, it specifies improvement strategies, such as algebraic manipulation or the introduction of new terms. The prompt update instruction emphasizes generation of models with new functional forms that yield improved R2. The prompt is used by the LLM (GPT-40-mini) along with the experimental training dataset to generate new analytical models, fit their constants, and continue the iterative model refinement process. In each iteration, the top twenty models are updated if any newly generated models surpass the previous batch in terms of the R\u00b2 score. For the testbeds in this work we generate 50 initial models, use 30 experimental points for fitting, select the top 20 models for iterative model refinement. In each refinement iteration, 20 new models are generated."}, {"title": "3. Testbeds and Data Collection", "content": null}, {"title": "3.1 Overview of Process Testbeds", "content": "Three mechanistically different processes were used as the testbeds to evaluate our framework. The first subtractive process is Flow assisted Laser-Induced Plasma Micro-Machining (FLIPMM (Wang et al., 2020), Fig. 4a). In FLIPMM a laser is used to create plasma in a dielectric liquid. The plasma is brought into contact with the workpiece to remove material. The water is continuously flowing to wash out the resulting debris. Our framework was used to model the effects of four process parameters namely laser energy, laser frequency, laser scanning speed, and water speed on four output attributes that include the machined microchannel's width and depth, the material removal rate (MRR) and the heat affected zone (HAZ).\nThe second additive process is Masked Stereolithography (MSLA (Temiz, 2023), Fig. 4c), which is based on photopolymerization of resin. A vat of resin is exposed to shaped UV light source via an LCD screen mask. The exposed resin forms a deposit of solid polymer layer on the build plate such that the deposit's shape replicates the mask's transparent region. The build plate moves up and the shape of the mask is altered as per the desired slice geometry. A new layer solidifies below the previous layer. Layer deposition is repeated till the full part is printed. Our framework was used to model the effects of layer thickness, exposure time, and build orientation on the printing time and ultimate tensile strength of the printed part.\nThe third testbed, i.e., Turn-Assisted Deep Cold Rolling (TADCR (Prabhu, Kulkarni, et al., 2020), Fig. 4b), is a deformation-based technique for improving the fatigue life of metallic components. TADCR plastically deforms the surface of a part to induce compressive surface residual stresses. The workpiece rotates on a lathe and a ball roller compresses the surface. Backrest rollers support the workpiece against the roller's forces. Our framework is used to model the effects of rolling force, ball diameter, initial surface roughness, and number of rolling passes on the output attributes of hardness and roughness of the part."}, {"title": "3.2 Datasets for Model Generation, Validation, and Testing", "content": "The present work used a database of 17 papers related to FLIPMM (Bhandari et al., 2022; Bhandari et al., 2019; Liu et al., 2022; Saxena et al., 2014; Saxena, Malhotra, et al., 2015; Saxena, Wolff, et al., 2015; Tang et al., 2019; Wang et al., 2023; Wang et al., 2022; Wang et al., 2020; Wang et al., 2019; Xie et al., 2020; Zhang et al., 2024; Zhang, Bhandari, et al., 2021; Zhang, Zhang, et al., 2021; Zhang, Liu, et al., 2022; Zhang, Zhang, et al., 2022), 41 papers related to MSLA (Abutaleb et al., 2023; Ahmed et al., 2022; Arslan, 2024; Basson & Bright, 2019; Borra & Neigapula, 2023; de Moraes et al., 2023; Digregorio et al., 2024; Dixon, 2024; Feldmann et al., 2021; Gaikwad et al., 2022; G\u00fcr, 2024; Junk & B\u00e4r, 2023; Kaufmann et al., 2024; Kricke et al., 2023; Leong et al., 2024; Milovanovi\u0107 et al., 2024; Minin et al., 2021; Mondal et al., 2021; Mondal & Willett, 2022; Montanari et al.; Navarrete-Segado et al., 2021, 2022; Nowacki et al., 2021; Orozco-Osorio et al., 2024; Orze\u0142 & Stecu\u0142a, 2022; O\u017c\u00f3g et al., 2022; Pa\u015bnikowska-\u0141ukaszuk et al., 2022; Penchev, 2024; Rafalko et al., 2023; Rahman et al., 2024; Sebben et al., 2024; Sharifi et al., 2024; Temiz, 2023, 2024; Torregrosa-Penalva et al., 2022; Valizadeh et al., 2021; Valizadeh et al., 2023; Williams, 2023; P.-J. Yu et al., 2023; Z. Yu et al., 2023; Zuchowicz et al., 2022), and 10 papers related to TADCR (Ad\u0131yaman & Ayd\u0131n, 2024; Kinner-Becker et al., 2021; Luo et al., 2021; Martins et al., 2022; Noronha et al., 2024; Prabhu, Kulkarni, et al., 2020; Prabhu et al., 2014; Prabhu, Prabhu, et al., 2020; Prabhu et al., 2016; Prabhu, 2014), for knowledge retrieval. The papers were chosen from Google Scholar by a non- expert by using the process name as the search keyword and based on a reading of the abstract by the non- expert for potential relevance. This resulted in papers where the relationship to the considered process might traditionally be considered mechanistically incomplete or tenuous, e.g., papers on LIPMM where there is no water flow or papers that also use magnetic fields to manipulate plasma. Note that the automated choice of the papers for knowledge retrieval is relevant to our future work, but is outside the scope of this paper.\nDetails on the experimental setup and materials for FLIPMM, MSLA, and TADCR can be found in Wang et al. (Wang et al., 2020), Temiz (Temiz, 2023), and Prabhu et al. (Prabhu, Kulkarni, et al., 2020)"}, {"title": "4. Results", "content": null}, {"title": "4.1. Importance of knowledge type, model refinement, and extrapolative accuracy", "content": "Our framework was evaluated for the following scenarios:\nScenario ctx: The retrieval process relies entirely on contextual information to identify descriptive relationships between input and output parameters. The retrieval is conducted using Query Form 1 or Step 2 of Query Form 2 when Step 1 cannot extract an explicit equation. This approach is initially used to generate a model without refinement (Scenario ctx-Initial), leveraging descriptive parametric relationships. If the generated model does not meet the required accuracy threshold, a refinement component is applied to enhance its accuracy (Scenario ctx-Refined).\nScenario Eq+ctx: This scenario uses knowledge retrieval to extract analytical models from the literature, if present, in addition to the descriptive relationships extracted in the previous scenario. Retrieval is conducted using Step 1 of Query Form 2. If the extracted knowledge contains a relevant analytical model the function's extracted form is used as a good guess for initial model. Similar to the previous scenario, here we denote Scenario Eq+ctx \u2013 Initial as the initial model generated by the LLM, and Scenario Eq+ctx \u2013 Refined as the obtained model after iterative refinement. However, in the presented case studies, we will show that Eq+ctx \u2013 Initial models have already met the required accuracies; therefore, Scenario Eq+ctx \u2013 Refined is not activated in these case studies."}, {"title": "4.1.1. Results for FLIPMM process", "content": "Figure 5 shows models derived by our framework for Heat Affected Zone (HAZ) as an exemplar output. Similar information for the other outputs is provided in Figs. A1, A2, and A3 in the Appendix. For Scenario ctx-Initial (Fig. 5a) the derived model does not include interactive effects between inputs and yields a low validation R2 of 0.78 and high validation MSE of 5.2. Model refinement in scenario ctx-Refined (Fig. 5b) increases the model complexity and achieves a drastically higher validation R2 of 0.98 and lower validation MSE of 0.48. Scenario Eq+ctx-Initial (Fig. 5c) achieves an even better validation R2 of 0.99 and validation MSE of 0.0351.\nFigure 6 compares the performance of all scenarios over all the outputs for FLIPMM. The Eq+ctx scenario consistently yields the highest performance in extrapolative testing followed by ctx-Refined and then ctx-Initial. For example, for modeling HAZ ctx-refined has a R2 of 0.928 on the extrapolative testing dataset whereas ctx-Initial has R\u00b2 of only 0.689. Though the difference in R\u00b2 between scenarios ctx-refined and ctx-Initial is not so large for the other model outputs, the R2 for ctx-Refined is always higher than for ctx-Initial.\nTable 3 compares the extrapolative testing performance of our framework to traditional ML models. Our framework significantly outperforms SVR, which yields very low and sometimes negative R\u00b2 values. Our approach also achieves greater R\u00b2 and lower MSE than RFR across the outputs, with the sole exception of the depth output. Further, our framework achieves similar R\u00b2 score as GPR for the Width, HAZ and MRR outputs but outperforms GPR for the Depth output by achieving lower MSE and higher R\u00b2. Thus, our framework achieves better performance more consistently than traditional ML. Additionally, it outperforms the commonly used symbolic regression model (PySR (Cranmer, 2023)), as detailed in the Appendix (Table A3)."}, {"title": "Scenario ctx:", "content": null}, {"title": "(a)", "content": "\\text {HAZ}_{\text {Predicted (Initial) }}=0.2941 P+5.6005 \\cdot \\frac{1}{S S}+166.305 \\cdot \\frac{1}{W S}+0.0414 \\cdot F^{2}"}, {"title": "(b)", "content": "\\text {HAZ}_{\text {Predicted (Refined) }}=0.0013 \\cdot P^{2}+5.5453 \\cdot \\frac{1}{\\sqrt{S S}}+235.051 \\cdot \\frac{1}{W S}-0.1852 \\cdot F^{1.5}+0.131 \\cdot(P \\cdot F)-0.6376 \\cdot\\left(\\frac{1}{\\sqrt{S S W S}}\\right)+0.0011 \\cdot\\left(P \\cdot F^{2}\\right)-0.0002 \\cdot\\left(P^{1.2} \\cdot F \\cdot S S\\right)-0.6521 \\cdot\\left(F^{0.5} \\cdot P^{0.8}\\right)"}, {"title": "Scenario Eq+ctx:", "content": null}, {"title": "(c)", "content": "\\text {HAZ}_{\text {Predicted (Initial) }}=177.52-33.32 \\cdot W S-1.267 \\cdot P-1.282 \\cdot F+1.958 \\cdot S S+0.0844 \\cdot W S \\cdot P-0.0627 \\cdot W S \\cdot F+0.0865 \\cdot P \\cdot F+0.1272 \\cdot S S^{2}+2.0533 \\cdot W S^{2}+0.0113 \\cdot P^{2}+0.0496 \\cdot F^{2}"}, {"title": "4.1.2. Results for MSLA process", "content": "Figure 7 presents analytical models derived by our framework for Printing Time as the exemplar output. The derived models for the additional outputs are shown in Appendix Figure A4. Figure 8 compares the performance of models derived by our framework for the different scenarios and for all the process outputs. In terms of extrapolation, while scenario Eq+ctx-Initial has the best performance, the performance of ctx- Refined outstrips that of ctx-Initial. Specifically, the testing R\u00b2 score for the printing time output is 0.835 for scenario ctx-Refined but only 0.35 for scenario ctx-Initial. Even though the difference between these two scenarios is relatively smaller for the tensile strength output the testing R\u00b2 is still higher for ctx-refined.\nTable 4 compares the extrapolative testing performance of our framework to traditional ML techniques. SVR and GPR underperform significantly by yielding negative R\u00b2 scores, indicating that they cannot even qualitatively capture the parametric relationship. Though RFR performs better, our framework still yields higher R2 and lower MSE. Thus, our framework outperforms traditional ML for the MSLA process as it does for FLIPMM process."}, {"title": "Scenario ctx:", "content": null}, {"title": "(a)", "content": "\\text {Printing-Time}_{\text {Predicted (Initial) }}=2.3802+\\frac{14.8337}{L}+\\frac{1.2479}{E}+0.1218 \\cdot O+0 \\cdot \\frac{1}{L}"}, {"title": "(b)", "content": "\\text {Printing-Time}_{\text {Predicted (Refined) }}=59.4384+\\frac{0.9263}{\\sqrt{L}}+\\frac{1.4472}{E^{2}}+0.0261 \\cdot \\frac{O^{2}}{L}+0.3395 \\cdot \\frac{E \\cdot O}{\\sqrt{L E}}+1.7735 \\cdot \\frac{1}{L}+0.1091 \\cdot \\frac{O}{L}-0.0667 \\cdot E^{1.5}+0 \\cdot\\left(\\frac{1}{L}\\right)^{2}"}, {"title": "Scenario Eq+ctx:", "content": null}, {"title": "(c)", "content": "\\text {Printing-Time}_{\text {Predicted (Initial) }}=-436.00+\\frac{12611.00}{L}+182.00 \\cdot E+17.68 \\cdot O+\\frac{93828.00}{L^{2}}-7.47 \\cdot E^{2}-0.0856 \\cdot O^{2}-\\frac{320.00}{L \\cdot E}-\\frac{95.60}{L \\cdot O}+0.027 \\cdot \\frac{E \\cdot O}{L}"}, {"title": "4.1.3. Results for TADCR process", "content": "Figure 9 presents models derived by our framework for Roughness as an example. The equations for Surface Hardness are presented in Figure A5 of the Appendix. Figure 10 compares the performance of the models derived by different scenarios of our framework for all the modeled process outputs. Again, scenario Eq+ctx-Initial consistently has the best performance on the test dataset with ctx-Refined next followed by ctx-Initial. For example, the R\u00b2 for roughness on the extrapolative dataset is 0.949 for ctx-Refined but only 0.77 for ctx-Initial. While the difference between these two scenarios is relatively smaller for the surface"}, {"title": "Scenario ctx:", "content": null}, {"title": "(a)", "content": "\\text {Roughness}_{\\text {Predicted (Initial) }}=0.9057-0.0298 \\cdot B-0.0000755 \\cdot R+\\frac{0.1126}{I}"}, {"title": "(b)", "content": "\\text {Roughness }_{\\text {Predicted (Refined) }}=0.6043-0.0241 \\cdot B^{1.2}+0.00029 \\cdot R^{1.1}+\\frac{2.0127}{I}+\\frac{0.1126}{I + 0.01}+\\frac{0.0731 \\cdot N^{1.3}}{I + 0.01}+\\frac{0.000742 \\cdot B \\cdot R^{0.75}}{I}-\\frac{0.00859 \\cdot B^{1.2} \\cdot R^{0.5}}{I}"}, {"title": "Scenario Eq+ctx:", "content": null}, {"title": "(c)", "content": "\\text {Roughness }_{\\text {Predicted (Initial) }}=1.7845-0.1307 \\cdot B-0.00079 \\cdot R-0.1023 \\cdot I-0.1515 \\cdot N+0.00006 \\cdot B \\cdot R+0.00691 \\cdot B \\cdot N+0.01104 \\cdot B \\cdot I-0.00002 \\cdot R \\cdot N-0.00005 \\cdot R \\cdot I-0.00052 \\cdot I \\cdot N-3.30 \\times 10^{-9} \\cdot N^{2}"}, {"title": "4.1.4. Summary of observations in this section", "content": "The above results reveal key insights, as follows\nQuestion 1: How do the extrapolative ability and data hunger of our approach compare to traditional ML?\nThe results show that across the range of processes and input-output combinations examined here our framework yields models with high correlation and low error much more consistently than traditional ML. This advantage is realized on the extrapolative test dataset, for which the traditional ML models often exhibit negative R\u00b2 values and very high MSE and are thus unable to capture the parametric relationship. Both our framework and the traditional ML models are trained on the same small experimental dataset. Thus, our framework utilizes experimental data much more efficiently while enabling better predictive capability in extrapolation.\nA potential reason is that our framework's ability to combine descriptive relationships and data allows the resulting models to remain grounded in physical reality much more than a traditional regressor, and thus allows better extrapolation across a broader range of input-output combinations and processes. For example, a descriptive statement extracted from the literature such as \u201cmicrochannel width increases with laser power\" provides a form of physical regularization that allows better extrapolation that trying to derive this trend solely from the data. A formal testing of this hypothesis is part of continuing work by the authors.\nQuestion 2: Is it desirable to retrieve only descriptive relationships or equations and descriptive relationships from the literature?\nThe results show that retrieval of equations and descriptive relationships (scenario Eq+ctx) yields the greatest accuracy in extrapolative testing. Thus, extraction of both equations and descriptive relationships is preferable. The authors encourage the broader manufacturing community to provide equations along with descriptions of parametric relationships in their papers since this is necessary for scenario Eq+ctx."}, {"title": "Question 3", "content": "If scenario Eq+ctx is so accurate then what is the value of the model refinement component?\nPapers in the literature may not provide the closed-form equations necessary for retrieval of equations. It is possible that only descriptive relationships, e.g., descriptions of trends in graphs or of finite element analyses, are available. This is especially true for novel processes where work is still nascent. In such a case scenario Eq+ctx is no longer possible. The results show that scenario ctx-Refined, in which retrieval of descriptive relationships is combined with model refinement, is more accurate in extrapolation than scenario ctx-Intial, in which only knowledge retrieval is used without model refinement. Thus, model refinement is critical when the literature does not contain closed-form equations."}, {"title": "4.2. Significance of Knowledge Retrieval", "content": "This section answers the question Is knowledge retrieval from the literature necessary for our framework?\nWe performed an ablation study in which our framework was used to generate analytical models without using retrieved information from the literature (i.e., without-RAG), thus relying solely on data-driven iterative model refinement. The prompt forms are shown in Table A1 in the Appendix. Table 6 shows the testing R\u00b2 for the initial and refined models without RAG and compares it to the testing R\u00b2 for the with- RAG cases from the previous sections. Results for the validation set, representing interpolative prediction, are in Table A2 of the Appendix.\nTable 6 shows that the models generated without RAG often fail to or struggle to generalize. For instance, for predicting the Heat-Affected Zone (HAZ) in FLIPMM without RAG, the R2 dropped from 0.67 in the initial model to -44.863 after refinement. When RAG was used the R\u00b2 increased from initial value of 0.689 to a refined final value of 0.928. For the other outputs in the FLIPMM process the R2 after refinement was greater with RAG than without RAG. In MSLA, incorporating RAG significantly improved R2 for Printing Time. Without RAG, the initial R\u00b2 score was -0.296 and only a slight improvement to -0.076 was observed after model refinement. Using RAG yielded a higher initial R2 of 0.35 which improved dramatically to 0.835 after refinement. At the same time, the R\u00b2 of the refined with-RAG model for Tensile strength was similar to that of the refined without-RAG model. For both the outputs of the TADCR process, the with- RAG and without-RAG models had similar performance in terms of the R\u00b2 of the refined model.\nThus, the value of the RAG-based knowledge retrieval component of our framework lies in ensuring greater stability and consistency in extrapolative predictions beyond the experimental training data. It is possible that the earlier-described physical regularization via inclusion of RAG-extracted descriptive relationships from the literature (see Section 4.1.4) is the reason for this observation as well."}, {"title": "5. Conclusion", "content": "This paper establishes a novel LLM-based framework for automated modeling of parametric relationships in data-deficient manufacturing processes. The novelty lies in combining RAG-based knowledge retrieval with data-driven iterative model refinement. This framework is evaluated for three manufacturing process testbeds with mechanistically different operational principles.\nThe results show that our framework goes beyond the state-of-the-art use of LLMs for the same purpose by (i) eliminating the need for human intervention such as interpretation of literature, manual problem"}]}