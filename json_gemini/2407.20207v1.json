{"title": "QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval", "authors": ["Hongming Tan", "Shaoxiong Zhan", "Hai Lin", "Hai-Tao Zheng", "Wai Kin (Victor) Chan"], "abstract": "In dense retrieval, embedding long texts into dense vectors can result in information loss, leading to inaccurate query-text matching. Additionally, low-quality texts with excessive noise or sparse key information are unlikely to align well with relevant queries. Recent studies mainly focus on improving the sentence embedding model or retrieval process. In this work, we introduce a novel text augmentation framework for dense retrieval. This framework transforms raw documents into information-dense text formats, which supplement the original texts to effectively address the aforementioned issues without modifying embedding or retrieval methodologies. Two text representations are generated via large language models (LLMs) zero-shot prompting: question-answer pairs and element-driven events. We term this approach QAEA-DR: unifying question-answer generation and event extraction in a text augmentation framework for dense retrieval. To further enhance the quality of generated texts, a scoring-based evaluation and regeneration mechanism is introduced in LLM prompting. Our QAEA-DR model has a positive impact on dense retrieval, supported by both theoretical analysis and empirical experiments.", "sections": [{"title": "I. INTRODUCTION", "content": "Dense retrieval [1], [2] is a information retrieval method that uses text embeddings to find the relevant texts for a given query. In dense retrieval, sentence embeddings transform sentences into semantic vector representations, improving passage retrieval performance over word embeddings.\nA major challenge in dense retrieval is the risk of losing essential information when converting long texts into fixed-length dense vectors, as maintaining the fidelity of sparse representations for long texts often requires very high dimensions [3]. Additionally, this limitation is emphasized in cases where the source texts are inundated with low-quality, noisy text, resulting in inconsistent retrieval quality. On one hand, recent works propose advanced retrievers or sentence embedding models to improve dense retrieval [4]\u2013[9]. On the other hand, input enhancement for retrieval represents a distinct optimization strategy for retrieval tasks, including query transformation and data augmentation [10]. Unlike query transformation [11], [12], data augmentation improves data quality before retrieval, enhancing performance without adding user wait time. However, in text retrieval, data augmentation methods typically focus on generating new query-text pairs for the retriever training [13], rather than directly enhancing the original texts. As a result, current data augmentation methods have not resolved inherent deficiencies in dense retrieval, specifically the loss of key information exacerbated by the presence of low-quality text. To address this issue, it is essential to consider data augmentation specifically applied to the retrieval text itself. Intuitively, we can enhance the original text by implementing text augmentation methods to generate high-quality alternative texts, which concentrate key information to improve semantic similarity with the query.\nTaking inspiration from existing challenges and unexplored optimization strategies, we consider transforming raw texts into more information-dense formats [14] that present essential factual details concisely and directly for better dense retrieval. Specifically, we propose that dense retrieval can be improved through information extraction to generate new text embeddings, a text augmentation strategy that outperforms reliance on original text alone. These generated text embedding vectors achieve high fidelity by condensing information and removing noise, and they show higher similarity with the query vector than the original text vector. To implement this idea, we need to address three issues. (i) The first issue is What information extraction tools can effectively resolve the inherent challenges of key information loss and low-quality text in dense retrieval? To address this issue, we focus on two high-level information extraction methods: question-answer generation (QAG) and event extraction (EE).\nInspired by the longstanding tradition of Question Answering Systems (QAS) [15], QA pairs should be the ideal text format for dense retrieval due to their high accuracy in providing precise responses to users' similar questions. QA pairs are information-dense as they focus on specific points from raw texts, presenting significant factual details directly and succinctly. This QA format aligns well with the query typically centered on a single topic, minimizing redundant information and offering a streamlined retrieval process for targeted inquiry [16]. Additionally, studies indicate that QA pairs and documents can complement each other as knowledge bases [17], suggesting the incorporation of QA pairs into vector databases for enhanced dense retrieval.\nAdditionally, we should consider event extraction as another crucial information extraction method based on knowledge graphs. Event extraction is a particularly information-dense form that extracts structured information from unstructured text to answer the \"5W1H\" questions (who, when, where, what, why, how) [18]. It captures both entities and relationships, aiming to extract high-level information from text and"}, {"title": "II. RELATED WORK", "content": "In this section, we first review dense retrieval along with sentence embedding. Next, we discuss previous input enhancement methods for retrieval. Finally, we introduce some related works on information extraction.\nDense retrieval has become an important research area following the development of pre-trained Transformer language models (PLMs) [2], [19]\u2013[22]. To enhance text retrieval performance, dense retrieval leverages PLM-based text"}, {"title": "III. APPROACH", "content": "In this paper, we focus on text augmentation approach for dense passage retrieval. A retrieval dataset typically comprises three types of data: the corpus, queries, and labeled query-text relationships. Initially, let $C = {t_1,t_2,...,t_n}$ represent a corpus, where each $t_i$ is a text chunk (simplified as text in the following discussion) and $n$ is the total number of texts in corpus. The initial step in dense passage retrieval is to construct a mapping function $\u03a6 : C \u2192 R^d$, where d is the vector dimension, such that semantically similar texts are close in the vector space. Specifically, the function $\u03a6$ uses sentence embedding model to transform all texts into dense vectors (i.e. embedding) stored in a vector database. We denote the resulting vector database as $VDB_{ori}$, where $VDB_{ori} = {v_1, v_2,..., v_n}$ with each vector $v_i \u2208 VDB_{ori}$ corresponding to a text $t_i$ in C. Given a query text q, which is also mapped to a vector $v_q \u2208 R^d$ by $\u03a6$, the retriever calculates the top-k vectors $v_i \u2208 VDB_{ori}$ with the highest similarity to query vector $v_q$, resulting in a subset $S\u2286 VDB_{ori}$, where $|S|$ = k. The vector similarity, denoted as sim($v_q, v_i$), measures the distance between $v_q$ and each vector $v_i$ in $VDB_{ori}$ (e.g., calculating the cosine similarity based on the"}, {"title": "D. Theory in QAEA-DR", "content": "Now, we theoretically explain the effectiveness of QAEA-DR. In the following theoretical analysis, we consider only the case of Texts Remain Independent (TRI) mentioned in Section III-B. It is evident that Texts Merge into One (TMO) can be viewed as a special case of TRI, and we will further discuss their differences in the experimental analysis. Given a text $t_i \u2208 C$, we generate a text set ${t_i^{(j)}}$ including QA pair texts and event texts, where j records the total number of final generated texts. In terms of vector representation, similarly, we combine the QA pair vectors $V_{QA_i}$ and event vectors $V_{EVENT_i}$ into $V_{GEN} = {v_i^{(j)}}$.\nWe first invoke the concept of fidelity of the retrieval process and normalized margin from previous work [3]. Subsequently, without loss of generality, we demonstrate that these generated vectors either maintain or enhance the fidelity of the retrieval process. Theorem III.3 introduces the effectiveness of text augmentation for dense retrieval. Theorem III.4 demonstrates the effectiveness of both QA Pair texts and event texts.\nFidelity refers to the ability of dense vector models to maintain the distinctions made by traditional sparse bag-of-words retrieval models. Unlike sparse representations for exact matching, dense vector models map texts of arbitrary length into a fixed-length vector space, which may result in a loss of fidelity and consequently information loss. Importantly, our QAEA generates information-dense new texts that removes noisy texts and refines key information to improve fidelity. To measure fidelity, we introduce normalized margin to indicate the distinction between the truly relevant text and other texts.\nLet $v_q, v_1$, and $v_2$ be sentence embeddings in $R^d$. The normalized margin is defined as:\n\u03bc(vq, v1, v2) = \\frac{(v_q, v_1 - v_2)}{||v_q|| ||v_1 - v_2||}\n(1)\nThe normalized margin in retrieval models serves as a quantitative measure to evaluate fidelity and provides a comparative perspective on vector similarity. It indicates how distinctly a target text is separated from irrelevant ones in vector space, enhancing retrieval accuracy and relevance. Assuming $v_1$ is the target text vector, we expect a larger normalized margin between $v_1$ and $v_2$ (\u03bc($v_q, v_1, v_2$) > 0), which indicates a greater difference in relevance between the target text and other texts for a given query.\nTheorem III.3 uses normalized margin to demonstrate the effectiveness of text augmentation. The theorem holds under certain constraints, including relevance enhancement, irrelevance consistency, and orthogonality. Under ideal text augmentation, the generated vectors of the target text should exhibit improved query relevance, while those of non-target texts should not be more relevant to the query than the original vectors. Additionally, in sparse retrieval, orthogonal vectors can be achieved by dividing the vocabulary into non-overlapping segments. Similarly, in dense models, we assume that vector representations of different texts are orthogonal when the content is irrelevant.\nTheorem III.3 (Text Augmentation). Given a text $t_i$, let ${v_i^{(j)}}$ represent a set of generated text vectors, where j records the total number of generated texts, and let $v_i$ represent the original text vector. Consider a text $t_1$ most relevant to a query q and a competing text $t_2$, we have generated text vector sets ${v_1^{(j)}}$ and ${v_2^{(j)}}$, respectively. There exists at least"}, {"title": "IV. EXPERIMENT", "content": "Datasets. We utilize four passage retrieval datasets to evaluate our QAEA-DR. Due to the high computational cost of multiple LLM tasks, we used a subset of the complete open datasets for our experiments.\n\u2022\nA Proprietary small-scale Chinese News Passage Retrieval dataset (sCNPR) that we created from real-world news articles and user queries. sCNPR covers diverse topics including economic, social, political, scientific, and entertainment news. SCNPR contains 1083 news texts and 2382 user queries, with an average text length of 655 words."}, {"title": "V. ANALYSIS", "content": "In this section, we conduct the analysis of QAEA-DR framework and evaluate its performance under different conditions and configurations."}, {"title": "VI. CONCLUSION", "content": "In this paper, we introduce QAEA-DR, a novel unified text augmentation framework for dense retrieval. This approach optimizes the original text by generating multiple QA pairs and events via LLM-based information extraction, which concentrates on key information and removes noisy text. As a result, the augmented vector database increases retrieval fidelity and effectively mitigates the issue of losing key information in dense retrieval. We conduct comprehensive experiments to demonstrate the effectiveness and robustness of QAEA-DR, even for datasets mainly comprising short texts. QAEA-DR indicates broader applicability by offering insights into open-domain LLM-based QAG and EE, and serving as a universal text optimizer in Retrieval-Augmented Generation (RAG)."}]}