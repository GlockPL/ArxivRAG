{"title": "Agent-E: From Autonomous Web Navigation to Foundational Design Principles in Agentic Systems", "authors": ["Tamer Abuelsaad", "Deepak Akkil", "Prasenjit Dey", "Ashish Jagmohan", "Aditya Vempaty", "Ravi Kokku"], "abstract": "AI Agents are changing the way work gets done, both in consumer and enterprise domains. However, the design patterns and architectures to build highly capable agents or multi-agent systems are still developing, and the understanding of the implication of various design choices and algorithms is still evolving. In this paper, we present our work on building a novel web agent, Agent-E 1. Agent-E introduces numerous architectural improvements over prior state-of-the-art web agents such as hierarchical architecture, flexible DOM distillation and denoising method, and the concept of change observation to guide the agent towards more accurate performance. We first present the results of an evaluation of Agent-E on Web Voyager benchmark dataset and show that Agent-E beats other SOTA text and multi-modal web agents on this benchmark in most categories by 10-30%. We then synthesize our learnings from the development of Agent-E into general design principles for developing agentic systems. These include the use of domain-specific primitive skills, the importance of distillation and de-noising of environmental observations, the advantages of a hierarchical architecture, and the role of agentic self-improvement to enhance agent efficiency and efficacy as the agent gathers experience.", "sections": [{"title": "1 Introduction", "content": "Recent advancements in large language models have led to significant interest in the development of autonomous agents that can execute complex tasks on the web [Zheng et al., 2024, He et al., 2024, Lutz et al., 2024] and on device [Bai et al., 2024, Wen et al., 2024]. Automation of complex and repet-itive tasks presents an invaluable opportunity to increase individual and organizational efficiency. In addition, robust automation systems will unlock new use cases and experiences by enabling collabora-tion between users and AI agents working together to accomplish sophisticated tasks.\nFigure 1 shows a simplified anatomy of a web agent. A typical web-agent, at its most basic, has two key capabilities: the capability to sense the web page and the capability to act on the web page.\n\u2022 Sensing: Sensing the state of the web-page, for a web agent, typically involves encoding the Doc-ument Object Model (DOM) of the page [Nakano et al., 2022, Lutz et al., 2024], using the acces-sibility tree of the page [He et al., 2024] and/or using screenshots of the page [He et al., 2024].\n\u2022 Acting: The action space can be comprised of simple actions such as navigating to URLs, clicking on elements, and entering text in a field, or composite actions comprising of several simple actions. An example of composite action is used by Lutz et al. [Lutz et al., 2024], which they call \u2018Input'. 'Input' selects a text box, deletes any existing content, inputs text and presses submit button.\nBased on the user's task and the current state of the page, the agent can create a plan i.e., it determines the subsequent next action or series of actions required to complete the task."}, {"title": "2 Agent-E: System Description", "content": "Figure 2 shows the high level architecture of Agent-E. It comprises of two LLM-powered agents: Planner Agent and Browser Navigation Agent, and two executor components: Planner Skills executor and Browser Navigation Skills executor. Each LLM-powered agent has skills associated with it, which are python functions that are described to the LLM for function calling. We do not make any distinction between skills associated with sensing (e.g. Get DOM) and skills associated with acting on the page (e.g. click on element). The executor components execute the function suggested by the LLM and relays the response back to the LLM.\nAgent-E is built using Autogen, the open-source programming framework for building multi-agent collaborative systems [Wu et al., 2023b] and Playwright\u00b2 for browser control. Its architecture leverages the interplay between skills and agents as shown in Figure 2.\nFigure 3 shows a conceptual flow diagram of Agent-E. Given a new user task, the planner decom-poses the task into a sequence of steps that need to be executed. The next step is then delegated to the browser navigation agent for execution. Browser navigation agent is implemented as a nested chat that is freshly instantiated by the Planner for each run (i.e., it does not contain previous steps in its chat history). Browser navigation agent has a set of predefined 'primitive' or foundational skills for observing denoised browser state and controlling the browser instance using Playwright. Figure 4 shows the skills available to the browser navigation agent. The browser navigation agent uses the skills available to it to perform the sub task and return a summary of actions it took to perform the task and/or answer the planner if the task was a question. Figure 5 shows an example communication between planner and the browser navigation agent and Figure 6 shows the browser navigation agent using the primitive skills available to it to perform a related sub task."}, {"title": "2.1 Skills Design for Browser Navigation Agent", "content": "There are two key differences between Agent-E and previous web agent implementations such as Wilbur [Lutz et al., 2024] and WebVoyager [He et al., 2024] in terms of skills .\n\u2022 Sensing Skills: Agent-E supports multiple DOM synthesis techniques that allows the browser navigation agent to choose the approach best suited for the task (see Figure 4). If the task is to summarise information on a page, it can simply use Get DOM with text_only content type. If the task is to identify and execute a search on a page, it can use the content type input fields. If the task is to list all the interactive elements on a page, it can use all_fields. This optimizes the information available to the agent and prevents the problems associated with noisy DOM. Another key difference is our DOM de-noising techniques for all_fields and input_fields attempts to preserve the parent child relationship of elements wherever possible and relevant. This is unlike some of the other previous implementations which uses a flat DOM encoding (e.g. [Lutz et al., 2024]). Further, to make identifying and interacting with HTML elements easier, Agent-E injects a custom identifier attribute (mmid) to each element as part of sensing, similar to [Zhou et al., 2023] and [He et al., 2024].\n\u2022 Action Skills: All the action skills are designed to not only execute an action but also report on any change in state as an outcome of the action, a concept we call 'Change observation'. This is conceptually similar to Reflexion paradigm [Shinn et al., 2024] which uses verbal reinforcement to help agents learn from prior failings. However, a key difference is that change observation is not directly associated or limited to a prior failure. The observation returned can be any type of outcome of the action. For example, a click action may return a response Clicked the element with mmid 25. As a consequence, a popup has appeared with following elements. Such verbal responses nudges the agent towards the correct next step.\nChange Observation capability is implemented by observing changes in selected attributes of"}, {"title": "3 Evaluation", "content": "In this section, we will present quantitative results of how well Agent-E performs in WebVoyager benchmark."}, {"title": "3.1 Introduction to WebVoyager", "content": "WebVoyager [He et al., 2024] is a recent web agent benchmark that consists of web navigation tasks across 15 real websites as shown Figure 7. Each website has about 40-46 tasks resulting in a benchmark dataset of 643 tasks (see Table 1 for example tasks). These tasks could be completed through DOM manipulation (textual) as well as augmenting with image understanding (multi-modal). We chose WebVoyager since it covers a diverse range of tasks across different live, dynamic and representative websites. Other alternative benchmarks either focused solely on single task domain [Yao et al., 2022], used custom created websites that are significantly simpler than real-world versions in terms of DOM complexity [Zhou et al., 2023], or used cached versions of real-websites only supporting a fixed route for the agent and not allowing free form exploration [Deng et al., 2024]. One of the issues with WebVoyager though is that it uses static dates for some of the tasks (e.g. Search a hotel with free WiFi and"}, {"title": "3.2 Evaluation Setup", "content": "The entire benchmark was divided among 5 human evaluators who ran 125-130 tasks each. For each task, the evaluators were instructed to classify the task as pass or fail along with a textual reason in case of failures. They were instructed to mark the task as pass if it was completed successfully in full (in case the task has multiple parts). The evaluators ran the task from India during IST office hours (this may have implications when you interpret or compare measures such as task completion times). For the evaluation, Agent-E was used in autonomous mode (i.e., ask user for input skill was disabled) and used GPT-4-Turbo as the LLM for both planner and browser navigation agent."}, {"title": "3.3 Measures", "content": "We report four important measures that are relevant for comprehensive evaluation of web agent and understanding their practical implementation readiness.\n\u2022 Task success rates: The percentage of tasks that Agent-E performed successfully across websites.\n\u2022 Self-aware vs Oblivious failure rates: Detecting when the task was not completed successfully is of utmost importance, since it can be used for enabling a fallback workflow, to notify the user of failure or use as an avenue to gather human demonstration for the same task. Self-aware failures are failures where agent is aware of its own failure in completing the task and responds with a final message explicitly stating so, e.g. I'm unable to provide a description of the first picture due to limitations in accessing or analyzing visual content. or 'Due to repeated rate limit errors on GitHub while attempting to refine the search...'. The failures could be due to technical reasons or agent deeming the task unachievable since it could not complete the task after repeated attempts. On the other hand, oblivious failures are cases were the agent wrongly answers the question or performs the wrong action (e.g. adds the wrong product to cart or provides a wrong information). For mainstream utility, oblivious failures should be as minimal as possible. For the current evaluation, failures were categorized to self-aware and oblivious failures by manual annotation. However, it would be trivial to employ an LLM critique to automatically do the same task, similar to [Wornow et al., 2024].\n\u2022 Task completion times: The average time required to complete the task, across websites for failed and successful tasks.\n\u2022 Total number of LLM calls: The average number of LLM calls (both planner and browser navigation agent) that was required to perform the task. This includes both successful and failure cases."}, {"title": "3.4 Result: Quantitative", "content": "In this section, we will present quantitative results of how well Agent-E performs in WebVoyager benchmark."}, {"title": "3.5 Result: Qualitative", "content": "In this section, we will present qualitative results of concrete examples showing how different design choices made in Agent-E help perform complex web tasks."}, {"title": "Hierarchical Planner helps error detection and recovery", "content": "The hierarchical architecture allows easily detecting and recovering from errors. The planner agent is prompted to perform verification (by asking questions or asking confirmation) as part of the plan whenever necessary. Figure 8 shows an example instance where the planner agent asks the browser navigation agent for more information (i.e., list the search results), and from the response (i.e., there are no specific search results) identifies that it may have made an error by making the search query too focused. In the example, the planner creates a new plan of action for performing the task. Another common pattern in the evaluation was the planner's ability to detect errors and easily backtrack to a previous page to continue execution. Given that the planner has the URL of the page at each step available to it, it allows the planner to effortlessly backtrack to a previous page by adding it as a step in the plan (e.g., navigate to the search result page using the <url>)."}, {"title": "Support for multiple DOM observation methods", "content": "HTML DOM can be extremely large (e.g., YouTube Homepage with all the DOM elements and their attributes is about 800,000 tokens). Thus, it is important to denoise and encode the DOM such that only task relevant information is presented to the LLM. However, information relevant for a given task is very dependent on the task at the hand. Some tasks may only need a complete textual rep-resentation (e.g., summarise the current page), some tasks may only need input fields and buttons (e.g., search on google). On the other hand, more exploratory tasks, may need a complete represen-tation of the page (e.g., what elements are on this page). Most previous web agent work have used a single DOM representation, e.g. [Zhou et al., 2023] used accessibility tree, multi-modal web agent in [He et al., 2024] used screenshots and [Lutz et al., 2024] used direct encoding and denoising of the HTML DOM. However, in our view, there is no single DOM observation method that suits all the tasks. Thus, Agent-E supports three different DOM representation methods text_only, input_fields, all-fields. This allows Agent-E to flexibly select the DOM representation that it feels is best suited for the task. Also, it allows for backup, that if one does not work as expected, Agent-E can fall back to a different representation. There were numerous examples in our benchmark where this multiple DOM representation was useful. Figure 9 illustrates an example where Agent-E adaptively uses all_fields DOM representation for interaction and text_only for summarization."}, {"title": "Change observation helps grounding", "content": "Change observation is a concept we introduced in which each action execution also observes for changes in the state and returns a linguistic feedback to the LLM. Some typical scenarios where this is useful is where the browser navigation agent tries to click on a navigation item (e.g., click on the soccer link on ESPN.com), however instead of navigating to the relevant section, it may instead open a popup menu that requires further selection. Another common example is when browser navigation agent attempts to set the source airport in a flight booking websites and a list of possible airports open up as a drop down. In both these cases, the interaction is not yet complete, but the browser navigation agent may assume it is (i.e., navigation to soccer section would require clicking on a new link from the popup menu, setting source airport would require selecting one of the option from the drop down). In both these cases, the click skills will return a feedback to the LLM that as a consequence of the click, a menu has appeared where you may need to make further selection. See Figure 6 for an example. Conceptually, the purpose of the change observation is to provide linguistic feedback to the LLM whether the action has been completed without any errors and did it lead to any tangible change in the environment, in order to inform subsequent actions. We also envision efficiency improvements if the change observation can return a list of elements, so that LLM can make subsequent selection without again using Get DOM skill to observe the state of the DOM. Change observation is adjacent to the concept of Reflexion [Shinn et al., 2024]. However, there are nuanced differences between the two. Reflexion paradigm provides feedback of a prior failure. However, change observation is not directly associated or limited to a prior failure. The observation returned can be any outcome of the action. Reflexion uses an LLM to analyse the scalar 'success/failure' signal from an action and current trajectory to produce the verbal feedback to the agent. Reflexion did not provide any tangible improvement when directly applied to web automation in the Webshop [Yao et al., 2022] benchmark."}, {"title": "4 Discussion", "content": "In this section, we will synthesize our learnings from the development and evaluation of Agent-E into a series of agent design principles. We believe these principles can be generalized beyond the domain of web automation."}, {"title": "4.1 Agent Design Principles", "content": "1. Well crafted set of primitive skills can enable powerful use-cases: A well crafted ensem-ble of foundational skills can serve as a building block to support more complex functionalities. LLMs can effectively combine these skills to unlock a broad range of usecases. The analysis of the intended use case is crucial to arrive at the requisite primitive skills. In the case of Agent-E these primitive skills were click, enter text, get DOM, Open URL and Press Keys. These were only a subset of what a user could potentially perform on a page (e.g. we did not support drag, double click, right click, tab management, etc. We considered the primitive skills we enabled in Agent-E to be enough for vast majority of general web automation tasks. Nonetheless, if we were to specialise Agent-E to work on certain websites where right-click to select a functionality is a prominent interaction pattern, we would need to introduce that as a primitive skill.\n2. Consider hierarchical architecture for complex tasks: Hierarchical architecture can be useful in agents with multiple LLM-based components. It allows execution of more complex tasks through a clear separation of roles and responsibilities. Hierarchical architecture excels in scenarios where tasks can be decomposed into sub-tasks that need to be handled at different levels of granularity. Additionally, it aids in the identification of tasks that can be executed in parallel, potentially leading to performance enhancements. It also supports the development and improvement of various components in isolation.\nIt is important to keep in mind that hierarchical architecture may not be suitable for all tasks. In case of Agent-E, if all we had to support were, e.g., navigate to specific URLs or perform simple web search, a hierarchical architecture may be over-complicated. In such cases, a much simpler architecture may suffice.\n3. Perform payload denoising when relevant: Mitigating noise in the payload is critical in creating reliable, cost and time efficient agents. Noise could be in the form of unnecessary or irrelevant information, which could lead to incorrect or sub-optimal performance. It is also important to keep in mind that what is considered noise may be dependent on the task. Simple techniques such as filtering irrelevant data, transforming the data to an easily consumable format, and focusing on key information can contribute to more accurate decision-making by the agent. This is especially important in environments with a high degree of uncertainty or very large input payload. In the case of Agent-E, we performed denoising on the HTML DOM. Further, we provided multiple DOM observation capabilities that the agent could adaptively use given the task requirements.\n4. Provide linguistic feedback of actions: Our exploration into the space of agents capable of performing actions that has tangible consequences suggests that linguistic feedback of actions could be useful to help executor agents to be better aware of the environment and any conse-quence of the actions (e.g., a dialog box appeared as a consequence of the click action). Change observation helps refine the agent's subsequent actions by providing a clear narrative of cause and effect, and also improved awareness of the environment. This could apply in a variety of usecases such as desktop automation or automations in the physical space (e.g robot control).\n5. Support human in the loop architecture when necessary: Supporting human in the loop architecture is critical for agentic systems. Given that agentic systems are so new, users may not trust the system completely. Further, there will arise scenarios where the agent may need to have varying degree of user involvement for a multitude of reasons: e.g., to get more clarification on the task, when there is ambiguity how to proceed, to approve critical actions, perform some mission critical actions that the agent cannot or should not perform, audit the final output and re-invoke if needed, or take over responsibility when agent identifies that it cannot perform the task. Human in the loop architecture could also be leveraged for self-improvement where the agent identifies opportune times to gather human demonstration (e.g. Sorry, I could not do this task. Can you show me how you would do it?. Thus, incorporating mechanisms for human oversight can play a pivotal role in building that trust, and seamless handover.\nHuman in the loop could mean different levels of human involvement. From simple notifications of task progress, human involvement at key decision points, all the way to a handover of an incomplete task to a human.\n6. Analyse, reflect and aggregate past experiences routinely for self-improvement: For Agentic systems to be adopted widely, they need to (gradually) achieve close to human-level performance. In the context of web automation, Agent-E could perform 73.1% of the tasks with an average task completion time of 150-220 second and 25 LLM calls. While very promising, this is not practical for production use-cases in terms of both effectiveness and efficiency.\nA simple agentic solution to improving efficiency is to cache LLM calls. These mechanisms are supported out-of-the-box by agent development frameworks such as Autogen [Wu et al., 2023b]. However, a naive caching may not work well in dynamic contexts (e.g., a web site will continuously change in terms of content, advertisements etc.). A better approach would be to establish offline workflows that routinely analyse, reflects on and aggregates past tasks and human demonstrations to convert them to more classical automation workflows. These classical approach could be re-triggered upon a new task if it matches a workflow that it has encountered in the past, and use the exploratory agentic approach only as a fallback. This would mean the task could be completed faster and cheaper.\n7. Introduce internal and external guardrails into the Agentic System: To ensure safe and effective operation of an agentic system, it's important to introduce various guardrails into its operation. These guardrails can be in the form of rules, guidelines or constitution that the system must adhere to. Some of the guardrails may be external to system, e.g., a task appro-priateness guardrail may filter out inappropriate tasks even before agentic system is invoked. In addition, there could be guardrails intrinsic to the system such as guardrails against prompt injection attacks, and operational guardrails that limits how the agent performs different tasks. In the context of Agent-E, the operational guardrails include domain boundaries within which Agent-E should operate (e.g., intranet of an organisation), task specific boundaries (e.g., Agent-E should only respond to a medical question from authoritative websites) or user-configured bound-aries (e.g., for shopping, use only Amazon)\n8. Choose between generic agent vs. task specific agent: Generic agentic systems by defi-nition can perform a wide range of tasks. However, in many practical implementations, a more focused set of capability may be desirable. For example, Agent-E is a generic web agent that can perform a wide range of tasks on the internet, but not necessarily optimized for any specific task. It would be possible to optimize Agent-E for specific type of tasks (e.g., form filling) or specific websites (e.g., Atlassian Confluence pages) to achieve significantly higher performance. Depending on the use case, an optimized agent may suit better for certain workflows than a generic version."}, {"title": "5 Related Work", "content": "LLM-based Planning and Reasoning Over the last few years, large language models (LLMs) have demonstrated extraordinary abilities in text generation, code generation, and the generation of natural language multi-step reasoning traces. Spurred by these, there has been much work in the use of LLMs to solve multi-step reasoning and planning problems. The many variants of 'chain-of-thought' techniques [Wei et al., 2023, Chu et al., 2023] encourage the LLM to produce a series of tokens with causal decoding that drive towards the solution of problems in math, common-sense reasoning and other similar tasks [Chowdhery et al., 2022, Fu et al., 2023, Li et al., 2023, Mitra et al., 2024].\nWith tool-usage for sensing and acting, LLMs have also been used to drive planning in software environments and embodied agents e.g., [Baker et al., 2022, Wang et al., 2023a, Wang et al., 2023b, Irpan et al., 2022, Bousmalis et al., 2023, Wu et al., 2023a, Bhateja et al., 2023]. Finally, there has been related work investigating the limits of LLMs when it comes to planning and valida-tion. For examples of negative results, see [Valmeekam et al., 2023b, Momennejad et al., 2023, Valmeekam et al., 2023a, Huang et al., 2023, Kambhampati et al., 2024] among others.\nSpecialized Agents for Repetitive Tasks Beyond the examples above, and as described in Section 1, there has been much recent interest in building specialized agents for the web [Zheng et al., 2024, He et al., 2024, Lutz et al., 2024] and on device [Bai et al., 2024, Wen et al., 2024]. Also related is recent work on building agentic workflows to replace robotic process automation [Wornow et al., 2024]. Further afield, the work on building agents and training language models for API usage is also related, given that many software tasks and workflows involve the use of APIs; examples include [Hosseini et al., 2021, Patil et al., 2023, Qin et al., 2024] and many more.\nHierarchical Planning The notion of hierarchical AI planning has been around for five decades or more. Instead of planning directly in the space of low-level primitive actions, planning in a space of 'high-level actions' constrains the size of the plan length (and hence the size of the plan-space), which can result in more effective and efficient search. Examples from prior work include [Tate, 1977, Nau et al., 1991, Marthi et al., 2007] and many more; see [Russell and Norvig, 2009] for more details. Also related is the use of temporal abstractions in planning and in reinforcement learning, for example the use of options in [Sutton et al., 1999, Bacon et al., 2017]. In recent years, multiple papers have proposed the use of hierarchical planning for solving tasks in complex environments or with embodied agents; examples include [Wang et al., 2022, Irpan et al., 2022] and several others."}, {"title": "6 Conclusion", "content": "In this paper, we introduced Agent-E, a novel web agent designed to perform complex web-based tasks that makes use of numerous architectural improvements over prior state-of-the-art web agents such as hierarchical architecture, flexible DOM distillation and denoising method and concept of change observation to guide the agent towards more accurate performance.\nAgent-E was evaluated on the WebVoyager benchmark, achieving a state-of-the-art success rate of 73.2%, a significant improvement over previous text-only and multi-modal web agents. Beyond task success rates, we also reported on additional metrics such as error awareness, task completion times, and the number of LLM calls, providing a more comprehensive evaluation of Agent-E's performance.\nWe presented our learnings in the form of eight general design principles for developing agentic systems that can be applied beyond the realm of web automation."}]}