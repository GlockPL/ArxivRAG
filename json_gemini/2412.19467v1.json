{"title": "OPTIMIZING HELMET DETECTION WITH\nHYBRID YOLO PIPELINES: A\nDETAILED ANALYSIS", "authors": ["Vaikunth M", "Dejey D", "Vishaal C", "Balamurali S"], "abstract": "Helmet detection is crucial for advancing protection levels in public road traffic dynamics.\nThis problem statement translates to an object detection task. Therefore, this paper\ncompares recent You Only Look Once (YOLO) models in the context of helmet detection in\nterms of reliability and computational load. Specifically, YOLOv8, YOLOv9, and the newly\nreleased YOLOv11 have been used. Besides, a modified architectural pipeline that\nremarkably improves the overall performance has been proposed in this manuscript. This\nhybridized YOLO model (h-YOLO) has been pitted against the independent models for\nanalysis that proves h-YOLO is preferable for helmet detection over plain YOLO models.\nThe models were tested using a range of standard object detection benchmarks such as\nrecall, precision, and mAP (Mean Average Precision). In addition, training and testing\ntimes were recorded to provide the overall scope of the models in a real-time detection\nscenario.", "sections": [{"title": "1. INTRODUCTION", "content": "In many countries, traffic accidents involving motorbikes and scooters are among the top causes\nof injury and death. Helmets are widely recognized as one of the most effective ways to prevent\nfatal or severe head injuries. Helmet detection presents an object detection challenge where\nmodels must accurately determine if a rider is wearing a helmet, often in real-time situations.\nWhile traditional computer vision techniques have their merits, they also face limitations in terms\nof processing speed, accuracy, and adaptability to various environments. The emergence of deep\nlearning-based object detection algorithms has transformed this area, particularly with the\nintroduction of the YOLO series of models.\nYOLO's capability for fast, real-time object detection makes it particularly suitable for helmet\ndetection applications. This paper examines the performance of YOLOv8, YOLOv9, and\nYOLOv11, and their hybridized version for identifying helmets on bike and motorbike riders.\nThe YOLO family of models has widely been applied in various object detection tasks due to its\nefficiency in balancing speed and accuracy. Initially proposed by Redmon et al. [1], YOLO\nframes the task of object detection as a single regression problem that significantly reduces the\ntime of detection in comparison to the earlier methods such as Recurrent-Convolutional Neural\nNetwork (R-CNN) or Single Shot Detector (SSD). With each consecutive version of YOLO,"}, {"title": "2. LITERATURE SURVEY", "content": "YOLO models have evolved substantially since their inception. One key work in this area is a\ncomprehensive review of YOLO architectures, tracing their development from YOLOv1 to\nYOLOv8. This study highlights the model's single-stage approach, where object localization and\nclassification are performed simultaneously, making it highly efficient for real-time applications\nsuch as autonomous vehicles and video surveillance [2]. Another notable study proposes\nComplexer-YOLO, which integrates 3D object detection into the YOLO framework using\nsemantic point clouds. This extension enhances the model's performance for real-world tasks like\nautonomous driving by improving detection accuracy in complex environments [3].\nAdditionally, another study emphasizes the integration of YOLO with a sliding innovation filter\nfor object tracking in dynamic environments, addressing challenges like occlusions and\ndisturbances, and showcasing YOLO's adaptability beyond static image detection [4].\nWhile YOLO models excel in speed, other methods offer a different tradeoff between accuracy\nand computational complexity. Faster R-CNN, for instance, is a two-stage object detector that\nsignificantly improves precision by first generating region proposals and then refining them using\nconvolutional neural networks. Though slower, it remains a top choice for tasks where accuracy\nis critical, such as medical imaging and precise localization [5][6]. SSD (Single Shot MultiBox\nDetector), like YOLO, adopts a single-stage approach but focuses on balancing speed with\nimproved accuracy over simpler YOLO versions [7]. Another significant development is\nRetinaNet, which introduces the focal loss function to address the problem of class imbalance,\nthereby boosting accuracy in detecting small objects, a common issue in real-world applications\n[8] L Nkabulo et. al. performed an ensemble of faster R-CNN and YOLO by first passing the\ninput to the YOLO model and then refining the output using faster R-CNN [9] Lastly, Mask R-\nCNN extends Faster R-CNN to not only detect objects but also perform instance segmentation,\nmaking it highly effective in tasks requiring pixel-level precision, such as robotics and\nautonomous systems [10].\nThe above survey has been represented in Table 1 contains the previous highly notable works\nthat have inspired this work and are concerned with object detection. Thus the table highlights the\nkey differences between existing methodology and the methodology proposed in this paper."}, {"title": "3. PROPOSED METHODOLOGY", "content": "The development of the Helmet Detection System follows a systematic approach designed to\nensure high accuracy and robustness. This approach is divided into several key stages, including\ndataset Collection, preprocessing, image augmentation, model training, hyperparameter tuning,\nand model testing as described in Figure 1."}, {"title": "3.1. Dataset Collection", "content": "The process begins with gathering images depicting individuals both wearing and not wearing\nhelmets. The dataset is curated from two main sources: an online database [11] and custom\nimages captured using phone cameras. This variety ensures that the images feature individuals\nfrom different perspectives and under varying lighting conditions, which is crucial for building a\nmodel that performs reliably in real-world scenarios. The total image count exceeds 3500."}, {"title": "3.2. Preprocessing", "content": "Once the dataset is collected, preprocessing is carried out to standardize the images and prepare\nthem for model training. This includes converting all images to RGB format for uniformity and\nresizing them to a consistent resolution. Pixel normalization is also applied to scale the pixel"}, {"title": "3.3. Model Training", "content": "After splitting the data into training and testing sets, the training phase begins. This phase\ninvolves a specific training pipeline that involves the usage of CNNs to feed features into the\nindependent YOLO model. In specific, three CNN models have been used in sequence as shown\nin Figure 1. The first CNN layer is shown in Figure 2 for reference and the subsequent CNN\nlayers, which are otherwise similar to the first, vary only in the number of filters, dimensions, and\npadding. From Figure 2, it is observable that after kernel application, batch normalization\nfollowed by activation is carried out.\nNormalization is a crucial part of creating a robust model since it allows for data of different\ntypes to be brought into a common scale for further processing. Hence, it is a very popular\npreprocessing tool. In the case of a CNN, the hidden layer outputs can be normalized for faster\ntraining. The normalization of input coming from another layer is called batch normalization.\nThis process has also proved to bring stability to the CNN training."}, {"title": "3.4. Hyperparameter Tuning", "content": "Fine-tuning the hyperparameters is a key step in optimizing the model's performance. Important\nparameters, such as the number of epochs, batch size, learning rate, and choice of optimizer are\nadjusted to strike a balance between training efficiency and accuracy. Adam Optimizer is chosen\nfor its adaptive learning rate, which speeds up convergence [13][14]. The learning rate is\ncarefully tuned to ensure effective learning without skipping important minima. Likewise, the\nbatch size and number of epochs are adjusted to improve the model's training speed and\naccuracy."}, {"title": "3.5. Model Testing", "content": "Once trained, the model undergoes thorough testing to validate its performance. Techniques like\nimage fusion are employed to refine detection accuracy by combining outputs from different\nimages and also a data enhancement method to overcome the shortcomings that high noise offers\n[15]. Evaluation metrics, such as precision and recall provide insight into classification\nperformance. Additionally, the Mean Average Precision (mAP) score is used with the\nIntersection over Union (IoU) set to a 50% confidence threshold to assess how well the predicted\nbounding boxes align with the actual helmet regions in the images."}, {"title": "3.6. Individual YOLO Model Description", "content": "All in all, six YOLO models have been used \u2013 h-YOLOv8, h-YOLOv9, h-YOLOv11, and their\ncorresponding independent versions."}, {"title": "3.6.1. YOLOv8", "content": "YOLOv8 focuses heavily on improving multi-object detection accuracy and introducing better\nhandling of small objects within cluttered scenes [16]. Additionally, the model has been\noptimized for edge devices, which means it can deliver high accuracy without requiring extensive\ncomputational resources.\nA key innovation in YOLOv8 is the use of attention mechanisms integrated into the network.\nThese mechanisms allow the model to focus on critical regions in the image, leading to better\ndetection in complex scenes."}, {"title": "3.6.2. YOLOv9", "content": "This model has made significant improvements in terms of global context awareness, which is\ncrucial for tasks like object detection in videos or complex scenes where spatial dependencies\nmatter. YOLOv9 is the first in the series to utilize a hybrid CNN-Transformer backbone, which\nenhances its ability to capture both local and global features of objects. Advancements such as\nthe introduction of GELAN (Generalized Efficient Layer Aggregation Network) and PGI\n(Programmable Gradient Information) significantly improve feature extraction and gradient flow\ncapabilities [17].\nYOLOv9 also introduces a new loss function that better handles the problem of class imbalance,\nimproving its accuracy for datasets with skewed object distributions. The model also benefits\nfrom further improvements in data augmentation techniques and adaptive learning rates, making\nit more resilient to variations in data quality and scale. As will be described in the results and\ndiscussion session, this model proves to be the model with the most mAP score for the utilized\ndata, however with a delay in time taken to achieve said results."}, {"title": "3.6.3. YOLOv11", "content": "YOLOv11 is the newest iteration of the YOLO series of models. It features improved feature\nextraction capabilities on its own due to the enhanced backbone and neck architecture [18]. This\nversion introduces boosted deployment capabilities across various platforms like the cloud and\nsystems supporting NVIDIA GPUs.\nWhile each of these YOLO models offers specific improvements over its predecessor, the\nhybridized approach, which combines the strengths of the pre-CNN, has been employed in this\nstudy. Since the CNN is lightweight, in the sense that it does not contain a massively\ninterconnected network of thousands and thousands of neurons, instead it uses neurons in the\nrange of tens and hundreds [19]. This ensures that although the features are being fed to the\nYOLO model ahead, the pre-CNN does not increase the time taken significantly. However, the\nfeatures fed by the CNN result in higher recall and mAP scores. Hence the trade-off for a small\nincrement in time taken is justifiable for the substantial increase in model scores."}, {"title": "3.7. Testing and Evaluation", "content": "The validity of the proposed models has been judged using some of the standard metrics used for\nthe purpose of object detection in literature. In specific, this work utilizes precision, recall, and\nmAP@50 score. Precision can be defined as the ability of the model to correctly identify positive\ninstances of a particular class. On the other hand, recall measures how many instances of a\nparticular class were correctly detected by the model compared to all the instances of that\nparticular class. Both these metrics are mathematically represented in the equations given below."}, {"title": "4. RESULTS AND DISCUSSION", "content": "Evaluation of the various models has been conducted using the rubrics mentioned in the previous\nsection. From Table 1, it is understood that the h-YOLO models categorically produce better\nprecision, recall, and mAP compared to plain YOLO models. When it comes to training and\ntesting time, as shown in Table 2, plain YOLO models take less time than h-YOLO models.\nWhile tackling a safety enforcement task, as is done in this manuscript, it is important to prefer\nhigher scores over faster times not to say that this priority is absolute though, rather, it varies\ndepending on the problem statement. What this means is that one should prefer the model with\nhigher accuracy only when the accuracy difference between the juxtaposed models is significant.\nHence, the h-YOLO models are preferred over independent YOLO models as the accuracy\ndifference is 2-3\\% which is significant considering the objective of the project can potentially\ndeal with civilian life.\nAs the comparison between the non-hybridized and the hybridized model has been sorted;\nnaturally, the comparison to find the best among the hybridized systems needs to be conducted."}, {"title": "5. CONCLUSIONS", "content": "To encapsulate, helmet detection is an important task in terms of public safety and for\ntechnological advancement in automated systems. The YOLO models gained a stronghold as\nleaders in the arena of real-time object detection. This manuscript is focused on providing a\ncomparative analysis between YOLOv8, YOLOv9, and the latest YOLOv11 and their hybridized\nmodels thereby opening up new avenues of thought regarding speed, accuracy, and\ncomputational load trade-offs in the context of helmet detection applications. The task of\ndetecting helmets or any other safety equipment such as rear-view mirrors or riding shoes for that\nmatter can have a multitude of applications in enforcing road safety laws. Specifically, such\nautomated detections using machine learning algorithms and frameworks can allow the\nconcerned authorities to take action when due. While the implementation of such technology that\ncan detect defaulters is outside the scope of this paper, the first step of detecting helmets with\npractical reliability has been achieved, evidently so by the results expressed in the previous\nsection. Therefore, this paper confirms the following overall reliability of using machine\nlearning frameworks, the superiority of h-YOLO over independent YOLO by 2-3\\% mAP score,\nand the ability of h-YOLOv11 specifically to balance speed and performance. Future work can"}]}