{"title": "Enhancing Hepatopathy Clinical Trial Efficiency: A Secure, Large Language Model-Powered Pre-Screening Pipeline", "authors": ["Xiongbin Gui", "Hanlin Lv", "Xiao Wang", "Longting Lv", "Yi Xiao", "Lei Wang"], "abstract": "Recruitment for cohorts involving complex liver diseases, such as hepatocellular carcinoma and liver cirrhosis, often requires interpreting semantically complex criteria. Traditional manual screening methods are time-consuming and prone to errors. While AI-powered pre-screening offers potential solutions, challenges remain regarding accuracy, efficiency, and data privacy.\nMethods: We developed a novel patient pre-screening pipeline that leverages clinical expertise to guide the precise, safe, and efficient application of large language models. The pipeline breaks down complex criteria into a series of composite questions and then employs two strategies to perform semantic question-answering through electronic health records: 1) Pathway A, Anthropomorphized Experts' Chain of Thought strategy; and 2) Pathway B, Preset Stances within an Agent Collaboration strategy, particularly in managing complex clinical reasoning scenarios. The pipeline is evaluated on three key metrics\u2014precision, time consumption, and counterfactual inference\u2014at both the question and criterion levels.\nResults: Our pipeline achieved high precision (0.921, in criteria level) and efficiency (0.44s per task). Pathway B excelled in complex reasoning, while Pathway A was effective in precise data extraction with faster processing times. Both pathways achieved comparable precision. The pipeline showed promising results in hepatocellular carcinoma (0.878) and cirrhosis trials (0.843).\nConclusions: This data-secure and time-efficient pipeline shows high precision in hepatopathy trials, providing promising solutions for streamlining clinical trial workflows. Its efficiency and adaptability make it suitable for improving patient recruitment. And its capability to function in resource-constrained environments further enhances its utility in clinical settings.", "sections": [{"title": "INTRODUCTION", "content": "In hepatology, the complexity of chronic diseases like cirrhosis, liver failure, and hepatocellular carcinoma demands meticulous patient selection for clinical research [1]. Clinicians must navigate extensive electronic health records (EHRs) to identify patients with specific diagnoses or treatments [2], such as esophageal varices or those undergoing Transjugular Intrahepatic Portosystemic Shunt (TIPS). The challenge deepens when broader categories like autoimmune diseases or prior beta-blocker therapy are involved, requiring comprehensive evaluation [3]. Additionally, determining whether liver cancer is primary or secondary, identifying the causes of liver failure or cirrhosis, or recognizing symptoms like jaundice adds further layers of complexity, necessitating detailed analysis and clinical insight. These tasks expose the limits of current methods. While traditional manual screening and automated approaches have attempted to address these challenges, they fall short in key areas [4].\nBidirectional Encoder Representations from Transformers (BERT) -based tools have been used for subject matching across various diseases while struggling with generalizability [4-7]. Large language models (LLMs), with their superior contextual semantic understanding, offer a promising avenue to overcome these limitations [8 9]. Domain-specific LLMs, fine-tuned on medical corpora or using knowledge graph embeddings, perform well in clinical text summarization [10 11], note generation [12 13], and medical question answering [14]. However, EHR security policies commonly necessitate local LLM deployment, precluding the use of non-open-source models like Chat Generative Pre-Trained Transformer (ChatGPT), Gemini, or Claude. Additionally, we believe the primary challenge lies in the need for strategic support in complex reasoning rather than in domain-specific knowledge [15]. Thus, both domain-specific and general LLMs start from a similar point. Moreover,"}, {"title": "METHODS", "content": "The EHR data used in this study, specifically narrative admission notes, typically included sections such as chief complaint, history of present illness and past medical history (a sample note is provided in the Supplemental Material). These data were obtained from the First Affiliated Hospital of Guangxi University of Chinese Medicine (FAHGUCM). The dataset comprised over 16,000 anonymized admission notes from the Hepatology Department collected over the past 10 years. For detailed analysis, we randomly selected 4,000 records, which was representative of the overall dataset in terms of the distribution of hepatopathy and associated clinical presentations.\nWe manually reviewed the inclusion and exclusion criteria of six real-world clinical trials on hepatopathy, and carefully selected 58 criteria assessable using information typically documented in admission notes. These criteria primarily focused on general health, medical history, and prior treatments, excluding those requiring specific laboratory results or specialized examinations not routinely captured in admission notes (details in Supplemental Table 1). These trials addressed various liver conditions, including chronic liver failure (ChiCTR2100044187 [20]), cirrhosis (NCT04353193 [21], NCT04850534 [22], NCT03911037 [23], NCT01311167 [24]), and hepatocellular carcinoma (NCT04021056 [25]).\nWe deployed four LLMs within an intranet security environment: Qwen1.5-7B-Chat-GPTQ- Int4 [26] (QWEN1.5), Baichuan2-13B-Chat [27] (BAICHUAN), ChatGLM3-6B [28] (GLM) and Qwen2-7B-Instruct-GPTQ-Int4 [26] (QWEN2). The experiments were conducted on Lenovo ST650V2 servers equipped with four NVIDIA GeForce RTX 3090 Turbo GPUs."}, {"title": "Pipeline design", "content": "The core of our approach is a multi-strategy pipeline designed to systematically process narrative admission notes, extracting relevant clinical information and applying logical reasoning. The architecture is detailed in Figure 1.\nCriteria conversion: We employed an external-CoT strategy, leveraging advanced non- open-source LLMs (OpenAI ChatGPT-40, Google Gemini Advanced, and Anthropic Claude 3.5 Sonnet) to decompose complex eligibility criteria into simpler and manageable questions. Each LLM generated question sets from a standardized prompt template (see Supplemental Material), which were subsequently integrated and refined using ChatGPT-40 to produce a comprehensive, non-redundant, and conflict/ambiguity-free final question set.\nQuestion-based assessment: We employed two distinct pathways to address the decomposed questions.\nWe conducted interviews with key individuals to summarize their thought processes, which were then used to develop the corresponding CoT. Each LLM, prompted to act in an independent role illustrated in Figure 1(D), analyzed EHR content and provided assessments for corresponding questions: 1) Clinical Research Coordinator (CRC): Focused on identifying relevant EHR domains using empirical knowledge, followed by targeted data extraction. Employed nuanced terminology comprehension beyond basic keyword matching; 2) Junior Doctor (JD): Conducted comprehensive EHR analysis, extracted pertinent information, and generated inferential responses to clinical issues; 3) Information Engineer (IE): Prioritized extracting key terminology from questions, performed global matching within EHR text, and analyzed semantic negations in identified regions. Additionally, we"}, {"title": "Pathway A: Anthropomorphized Experts' CoT", "content": "We proposed an Agent-Collab framework simulating a mock trial, wherein three agents with distinct roles and stances independently evaluate questions. To enhance efficiency, the evaluation process is limited to a maximum of two rounds. 1) Agent A (Positive Assumption) - \"Proponent\": Begins with a positive stance (e.g., assuming the patient meets the criteria specified in the question) and conducts a thorough analysis of the admission note to support this assumption, providing a conclusion with supporting evidence; 2) Agent B (Negative Assumption) - \"Opponent\": Adopts a negative stance (e.g., assuming the patient does not meet the criteria in the question) and performs an independent analysis of the same admission note, offering a conclusion with supporting reasoning and evidence; 3) Agent C (Adjudicator) - \"Judge\": Acts as the adjudicator, reviewing the conclusions and reasoning from Agents A and B. If both agents agree, Agent C delivers the consensus conclusion. In the case of disagreement, Agent C identifies inconsistencies and prompts a second, more detailed evaluation round, ultimately providing a final judgement on the question."}, {"title": "Pathway B: Preset Stance Agent-Collab", "content": "The pipeline was evaluated on three key metrics\u2014precision, time efficiency, and counterfactual inference rate\u2014at both the question and criterion levels. To establish a gold standard for comparison, clinical experts manually reviewed and annotated the converted question sets from 4,000 admission notes.\nWe assessed the pipeline's performance at both the question and criterion levels, focusing primarily on precision, while also considering recall, F1 score, and accuracy for a comprehensive evaluation. At the criterion level, we aggregated answers to questions using"}, {"title": "Evaluation metrics", "content": "The study was approved by the Ethics Committee of FAHGUCM (Ref. No. 2020-046-02). The requirement for informed consent was waived by the Ethics Committee due to the observational nature of the study, and all data were de-identified and anonymized."}, {"title": "RESULTS", "content": "We automatically generated 87 questions from 58 original criteria, simplifying complex reasoning into straightforward semantic tasks (Supplemental Table 1). The connection between these criteria and specific trials is detailed in Supplemental Table 2. Various prompt templates were used throughout the pipeline, as outlined in the Supplementary Material.\nPathway B (Preset Stance Agent-Collab) achieved the highest precision at 0.892, outperforming the individual roles in Pathway A (Anthropomorphized Experts' CoTs), which ranged from 0.725 (JD) to 0.827 (CRC). The majority vote strategy in Pathway A further improved its overall precision to 0.877 (Table 1).\nBoth pathways demonstrated high annotation consistency, exceeding 97% across all roles and strategies (Figure 2). Additionally, as shown in Figure 3, a substantial proportion of responses achieved precision above 0.85, with 63.2% for Pathway B and 71.3% for Pathway A's majority vote.\nTo better understand the pipeline's performance, we categorized the derived questions into relevant clinical domains (e.g., Diagnosis, Intervention) and further classified tasks by"}, {"title": "Question level assessment", "content": "At the criterion level, precision in Pathway A ranged from 0.787 for JD to 0.893 for CRC, with the majority vote boosting it to 0.922. Pathway B achieved a precision of 0.920, comparable to Pathway A's majority vote (Table 3)."}, {"title": "Criterion level performance", "content": "We evaluated counterfactual inference rates across the pathways. Pathway B had the lowest rate at 0.25%, indicating strong consistency. In Pathway A, the rates varied among roles, with CRC at 0.82%, IE at 0.93%, and JD at 1.78%. The majority vote approach effectively reduced Pathway A's overall counterfactual inference rate to 0.77%, demonstrating the benefit of collective decision-making in minimizing errors."}, {"title": "Counterfactual inference", "content": "To evaluate efficiency, we measured the time spent on question assessment using an optimal concurrency level of 3 to balance speed and resource use. Pathway A showed significantly faster processing times, averaging 0.588 seconds per question for CRC, 0.395 seconds for JD, and 0.340 seconds for IE. In contrast, Pathway B took an average of 2.570 seconds per question (Figure 4).\nSupplementary Figure 1 illustrates the variability in processing times for both pathways across different questions. Pathway B exhibited a wider range due to the possibility of a second evaluation round. Overall, our pipeline demonstrated efficient and manageable processing times. With further optimization, Pathway A could potentially process a single patient's eligibility in approximately 10 seconds."}, {"title": "Time consumption", "content": "We also conducted a preliminary evaluation of other locally deployed LLMs (QWEN1.5, BAICHUAN, and GLM) on a subset of the data. QWEN1.5 generally outperformed the other models. BAICHUAN showed a tendency for over-inference, while GLM faced challenges with constraint adherence.\nFurthermore, we compared the performance of QWEN1.5 and QWEN2 when deployed locally. Interestingly, QWEN1.5 outperformed QWEN2, despite the latter's enhancements in reasoning capabilities. This discrepancy might be attributed to QWEN2's conservative approach, leading to a higher rate of false negatives, or the lack of prompt adaptation for QWEN2 in our specific setting."}, {"title": "Additional research", "content": "In this study, the pipeline combined anthropomorphized experts' CoT with a preset stance Agent-Collab strategy and a locally deployed LLM, effectively addressing the challenges in clinical trial pre-screening for hepatology by achieving acceptable precision and improving efficiency. Notably, the entire pipeline operated on a single consumer-grade server within a fully air-gapped data, internet-isolated environment.\nIn conclusion, we propose a hybrid approach for clinical application: 1) For non-inferential recognition tasks involving explicit diagnoses and interventions, pathway A with majority vote is recommend; 2) For types requiring complex reasoning, Pathway B is more suitable."}, {"title": "DISCUSSION", "content": "The pipeline achieved a competitive average precision of 0.921 at the criterion level, which was achieved within a secure environment with limited resources. Additionally, we assessed the trial-level precision, achieving an average precision of 0.72, considering the limitations of admission notes in determining patient eligibility. Despite these constraints, the pipeline achieved higher precision in hepatocellular carcinoma (0.878) and cirrhosis trials (0.843), indicating its potential utility in hepatopathy trials. Compared to similar studies in Table 4, our pipeline outperformed, even when using a closed-source LLM."}, {"title": "Principle Findings", "content": "For tasks such as identifying hepatocellular carcinoma, cirrhosis, or specific interventions like TIPS, the CoT-based approach delivered high precision (a typical of 0.92, verse traditional manual annotation methods which achieve around 0.81, reflecting a 14% improvement) with minimal processing time (a typical of 0.44 seconds per task, verse traditional manual annotation which take over 10 seconds per task, representing a 95% reduction) [33]. For more complex tasks, such as determining the etiology of liver failure, assessing whether liver cancer is primary, identifying systemic diseases, or verifying HBV antiviral treatment, the Agent-Collab framework provided even higher precision. By leveraging externally defined logic-derived from advanced LLMs or clinical experts\u2014this combination ensured that our method was both efficient and adaptable, effectively handling a wide range of clinical scenarios in hepatopathy research."}, {"title": "Outperforming across multiple diseases in secure environments", "content": "Researchers often view new technologies and standard clinical practices separately. In this study, we integrated proven clinical methods with advanced technologies to effectively address complex problems, yielding promising results.\nPathway A's anthropomorphized experts guided the LLM from general semantic understanding to targeted entity recognition, a critical feature for enhancing the performance of weaker open-source LLMs. Meanwhile, Pathway B's preset stance Agent-Collab strategy effectively managed complex and semantically disordered texts, ensuring accurate outputs.\nBy combining advanced LLM capabilities with clinical expertise, both strategies showed potential for improving the accuracy of complex clinical assessments (Figure 5).\nWhile Pathway B showed marked improvements in complex reasoning and nuanced categorization, Pathway A excelled in tasks involving direct recognition of explicit terms, with its CRC and IE roles demonstrating strong proficiency in precise data extraction for direct match tasks. This contrast highlights their complementary strengths. Although Pathway B is generally more robust, Pathway A offers comparable accuracy with significantly lower resource consumption, making it a practical choice when efficiency is paramount."}, {"title": "Clinical expertise guides LLM application to tackle complex challenges", "content": "Notably, our dataset, which comes from FAHGUCM in China, a regionally influential hospital in hepatopathy (annual outpatient visits reach 50,000, with around 5,000 inpatient admissions). This dataset integrates both Traditional Chinese Medicine (TCM) and Western medicine, included expressions influenced by TCM. While not being the primary focus of our evaluation, these expressions were also tested, and preliminary results suggested that the pipeline can adapt to these diverse medical terminologies. Some natural language expressions in the recorded texts reflect a TCM influence. Although these expressions were not involved in the nano-ranking Q&A, we experimented with incorporating some TCM phrasing in our tests. For example, we used criterion like \"whether the patient has insomnia\", and the corpus was \"\u60a3\u8005\u5bd0\u5dee\" (poor sleep quality) or \"\u5367\u4e0d\u5b89\u5bd0\" (lie unable to sleep) instead of the more commonly seen \"\u60a3\u8005\u5b58\u5728\u5931\u7720\u60c5\u51b5\" (the patient has insomnia condition). The recognition performance was satisfactory, suggesting potential applicability in this area. However, we did not conduct systematic and rigorous testing on these variations."}, {"title": "Exploratory insights on pipeline adaptability in traditional Chinese medicine", "content": "Our study's primary limitation lies in the restricted data dimensions within admission notes, which focus on key sections like chief complaints, current disease history, and past medical history. To address this, we selected criteria from multiple clinical trials related to hepatopathy and manually filtered them to ensure relevance to our dataset. The study was conducted using data from a single center and it requires further external validation to ensure its generalizability.\nDespite these limitations, our approach provides valuable insights into the use of limited EHR data for clinical trial matching. By focusing on likely available data points, we enhance the real-world applicability of our analysis. This focused methodology also facilitates scalability to other settings with similar data limitations. Future work should enhance data collection in EHR systems, improve model robustness for incomplete data, and expand this approach to other medical domains."}, {"title": "Limitations", "content": "We have developed an effective patient pre-screening strategy, showing high precision in hepatopathy trials. Designed to operate efficiently in environments with limited IT resources and stringent security requirements, our pipeline combines different approaches to achieve both precision and efficiency across various clinical tasks. This cost-effective and adaptable solution has the potential to enhance the pre-screening process and improve patient recruitment in clinical trials."}, {"title": "CONCLUSION", "content": "The data analyzed in this study are not publicly available due to privacy or ethical restrictions but can be obtained from the corresponding author upon reasonable request."}, {"title": "Data Availability Statement", "content": "This study was supported by the Second Batch of National TCM Clinical Research Base Construction Units (No. 131 [2018], issued by the National Administration of Traditional Chinese Medicine)."}, {"title": "Financial Support and Sponsorship", "content": "The authors report no conflict of interest."}, {"title": "Conflict of Interests", "content": "The study was approved by the First Affiliated Hospital of Guangxi University of Chinese Medicine (approved Ref. No. 2020-046-02)."}, {"title": "Ethics Approval Statement", "content": "The requirement for informed consent was waived by the Ethics Committee of the First Affiliated Hospital of Guangxi University of Chinese Medicine, due to the retrospective nature of the study, and all clinical data were de-identified and anonymized."}, {"title": "Patient Consent Statement", "content": "Xiongbin Gui: Conceptualization, Methodology, Writing - Original Draft, Formal Analysis\nHanlin Lv: Methodology, Formal Analysis, Software, Writing - Review & Editing\nXiao Wang: Data Curation, Validation, Visualization, Supervision\nLongting Lv: Investigation, Project Administration, Writing - Review & Editing\nYi Xiao: Conceptualization, Funding Acquisition, Writing - Review & Editing, Supervision\nLei Wang: Methodology, Project Administration, Writing - Review & Editing, Supervision"}]}