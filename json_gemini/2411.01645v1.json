{"title": "Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers", "authors": ["Gjergji Kasneci", "Enkelejda Kasneci"], "abstract": "Feature engineering is crucial for optimizing machine learning model performance, particularly in tabular data classification tasks. Leveraging advancements in natural language processing, this study presents a systematic approach to enrich tabular datasets with features derived from large language model embeddings. Through a comprehensive ablation study on diverse datasets, we assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers, including Random Forest, XGBoost, and CatBoost. Results indicate that integrating embeddings with traditional numerical and categorical features often enhances predictive performance, especially on datasets with class imbalance or limited features and samples, such as UCI Adult, Heart Disease, Titanic, and Pima Indian Diabetes, with improvements particularly notable in XGBoost and CatBoost classifiers. Additionally, feature importance analysis reveals that LLM-derived features frequently rank among the most impactful for the predictions. This study provides a structured approach to embedding-based feature enrichment and illustrates its benefits in ensemble learning for tabular data.", "sections": [{"title": "Introduction", "content": "Feature engineering is foundational to machine learning, playing a critical role in determining the performance, interpretability, and scalability of predictive models. Traditional feature engineering methods rely heavily on domain expertise to transform raw data into representations that meaningfully capture relevant patterns. While effective, this approach is often time-intensive and specific to individual applications, limiting its scalability across diverse tasks. The advent of deep learning, particularly in natural language processing (NLP), has introduced powerful new methods for automated feature extraction. These methods, especially contextual embeddings from models like BERT, ROBERTa, and GPT, can capture rich semantic information from textual data, reducing the need for extensive manual preprocessing and enhancing model robustness across domains [10, 25, 35]."}, {"title": "Related Work", "content": "Feature engineering has been extensively studied, with various approaches proposed to automate and enhance the feature creation process [33, 38, 39]. Traditional methods for feature engineering primarily relied on expert knowledge to craft meaningful representations, but automated feature engineering techniques have emerged to reduce human intervention. Techniques like feature selection, construction, and transformation have been employed to improve model accuracy and interpretability [39]. With the advent of deep learning, feature extraction methods began to incorporate non-linear relationships and hierarchical structures within data, leading to more robust predictive features [3].\nThe utilization of deep learning models for feature extraction, particularly in NLP, has gained prominence with models like BERT [10], GPT-2 [25], and their successors, which provide contextual embeddings that capture intricate semantic relationships [26, 36]. These models leverage transformer-based architectures [35], which have revolutionized NLP by enabling self-attention mechanisms that learn contextual dependencies within text sequences. More recent models like ROBERTa [20] and GPT-3 [7] have further refined these architectures, leading to embeddings that capture even finer-grained semantic nuances. In domains beyond NLP, embeddings derived from transformers have also been applied to structured data, leading to innovations in feature engineering and transfer learning across heterogeneous data types [5, 16, 18].\nEnsemble classifiers have been a staple in machine learning competitions and practical applications due to their robustness and excellent performance on tabular data [4, 6, 9, 11, 13]. These classifiers combine multiple models to improve generalization and reduce variance, with methods like bagging, boosting, and stacking being widely adopted. In recent years, researchers have explored hybrid models that combine traditional ensemble techniques with neural networks to leverage both structured data and unstructured embeddings, yielding significant performance gains [12, 15, 27]. Studies have shown that combining traditional features with deep learning-based embeddings can lead to significant performance gains, especially in domains where feature interactions are complex and multi-modal data is involved [1, 2, 18, 22, 29, 30].\nIn parallel, approaches for integrating embeddings into ensemble classifiers have been evaluated for their ability to capture hidden patterns within high-dimensional data [1, 2, 40]. For instance, embedding-based feature engineering has proven effective in applications like sentiment analysis, recommendation systems, and medical diagnostics, where context-rich representations enhance model interpretability and predictive power [29, 37]. Recently, methods like knowledge distillation and transfer learning have been employed to integrate pre-trained embeddings, enhancing the adaptability of ensemble classifiers across tasks and datasets [8, 14, 32].\nAblation studies are essential for understanding the contribution of individual components within a machine learning pipeline [17, 21, 31]. They help in identifying which features or components significantly impact the model's performance, thereby informing feature selection and model"}, {"title": "Feature Enrichment Framework for LLM Embeddings", "content": "Feature enrichment in machine learning involves augmenting the existing feature set with additional features to enhance model performance. This process may integrate both structured and unstructured data sources to enrich the feature space and enable models to capture more complex patterns. In this work, we implement a feature enrichment strategy that combines baseline structured features with embeddings derived from pre-trained language models. To ensure computational efficiency and remain as parsimonious as possible in the enrichment process, we apply Principal Component Analysis (PCA) for initial dimensionality reduction and noise reduction on the embedding dimensions, followed by feature selection to retain only the most informative embedding dimensions."}, {"title": "General Framework and Definitions", "content": "We begin by defining the fundamental concepts and notations used throughout this section.\n\u2022 Let the tabular dataset be represented as $D = \\{(x_i, y_i)\\}_{i=1}^n$, where n is the number of samples. Here, $x_i \\in \\mathbb{R}^p$ denotes the feature vector for the i-th sample, and $y_i$ is the corresponding target label.\n\u2022 The baseline feature matrix $X_{\\text{baseline}} \\in \\mathbb{R}^{n \\times p}$ encompasses all original features for each sample in the dataset.\n\u2022 A set of K pre-trained language models, $M = \\{\u041c_1, \u041c_2,..., M_K\\}$, serves as feature generators. For instance, M\u2081 may correspond to GPT-2, and M2 to RoBERTa.\n\u2022 The transformation function $\\Phi : \\mathbb{R}^P \\rightarrow T$ converts structured baseline features into textual representations suitable for embedding generation, where T denotes the space of textual data.\n\u2022 For each language model $M_k \\in M$, an embedding function $f_{M_k} : T \\rightarrow \\mathbb{R}^{d_k}$ maps textual input to a $d_k$-dimensional embedding vector."}, {"title": "Feature Enrichment Process", "content": "The feature enrichment process consists of three primary stages: (1) transformation of structured data into textual format, (2) embedding generation and initial dimensionality reduction using PCA, and (3) feature selection to retain the most informative embedding dimensions.\nStage 1: Transformation to Textual Representation\nThis stage involves converting structured data into a textual format suitable for input into pre-trained language models [5].\n1. For each feature vector $x_i = [x_{i1}, x_{i2},..., x_{ip}]$, we apply the transformation function $\\phi$ to generate a textual representation:\n$\\phi(x_i) =$ \"Feature1_name: $x_{i1}$, Feature2_name: $x_{i2}$, ..., FeatureP_name: $x_{ip}$\"\n2. We construct a corpus of textual representations for the entire dataset:\n$X_{\\text{text}} = \\{\\phi(x_1),..., \\phi(x_n)\\}$\nStage 2: Embedding Generation and PCA Dimensionality Reduction\nGiven the high dimensionality of embeddings from advanced language models, we apply PCA to remove noise and reduce the embeddings to a manageable size before feature selection.\n3. For each language model $M_k \\in M$, we generate an initial embedding matrix $E_{M_k} \\in \\mathbb{R}^{n \\times D_k}$ by applying the embedding function $f_{M_k}$ to the textual corpus:\n$E_{M_k} = f_{M_k}(X_{\\text{text}})$\nwhere $D_k$ is the original embedding dimension (e.g., 768 for GPT-2).\n4. We apply PCA to reduce each embedding matrix $E_{M_k}$ to a lower dimension d (e.g., d = 50), resulting in a reduced embedding matrix $E^{PCA}_{M_k} \\in \\mathbb{R}^{n \\times d}$.\n$E^{PCA}_{M_k} = PCA(E_{M_k}, n\\_components = d)$\nStage 3: Feature Selection via Random Forest Importance\nTo further enhance computational efficiency and focus on the most informative features, we perform feature selection on the PCA-reduced embeddings.\n5. We train a Random Forest classifier $C_k$ using $E^{PCA}_{M_k}$ to estimate feature importance scores for each embedding dimension.\n6. Based on the importance scores, we select the top m most informative dimensions from each $E^{PCA}_{M_k}$. Let $I_{M_k} \\subset \\{1,...,d\\}$ denote the indices of these top dimensions. The selected embedding matrix is then:\n$E^{\\text{selected}}_{M_k} = E^{PCA}_{M_k}[:, I_{M_k}]$\nFinal Enriched Feature Matrix\nWe construct the final enriched feature matrix $F_{\\text{enriched}}$ by concatenating the baseline features with the selected embedding dimensions from all language models:\n$F_{\\text{enriched}} = [X_{\\text{baseline}} \\; | \\; E^{\\text{selected}}_{M_1} \\; | \\; ... \\; | \\; E^{\\text{selected}}_{M_K}]$\nThis comprehensive approach ensures that we integrate rich contextual information from language models while maintaining computational tractability and model interpretability."}, {"title": "Methodology for Classifier Evaluation and Ablation Study", "content": "This section presents the methodological framework used to assess the efficacy of embedding-based feature enrichment in enhancing ensemble classifiers. We detail the processes of dataset preparation, feature enrichment, classifier training, ablation study design, evaluation metrics, and statistical validation to ensure the robustness and reproducibility of our findings."}, {"title": "Experimental Setup", "content": "In the following, we describe the experimental setup developed to accurately evaluate the effects of embedding-based feature enrichment on classification performance. This approach encompasses dataset selection, preprocessing, feature engineering, and classification model configuration to ensure a systematic and reproducible evaluation process."}, {"title": "Feature Engineering and Enrichment", "content": "Embedding Generation and Dimensionality Reduction. We generated contextual embeddings using two pre-trained language models, namely RoBERTa and GPT-2. The embedding generation and dimensionality reduction process is formalized in three steps as follows:\n1. The step of textual transformation, where the following transformation is applied to each instance $x_i$:\n$\\phi(x_i) = \\text{Concatenate}(\\{f_j: v_{ij}\\}_{j=1}^P)$\nwhere $f_j$ are feature names and $v_{ij}$ are feature values.\n2. The step of embedding generation, where, for each pre-trained language model $M_k$, we map the textual representation of the tabular dataset into the embedding space to obtain the corresponding embedding matrix:\n$X_{\\text{text}} = \\{\\phi(x_1),..., \\phi(x_n)\\}$\n$E_{M_k} = f_{M_k}(X_{\\text{text}})$\nwhere $f_{M_k}$ is the embedding function for model $M_k$.\n3. The step of noise removal through PCA-based dimensionality reduction:\n$E^{PCA}_{M_k} = PCA(E_{M_k}, n\\_components = d)$\nwith d 50 to still have a high coverage of relevant dimensions."}, {"title": "Classifier Selection and Training", "content": "Classifiers. We used three ensemble classifiers, each known for robustness and strong performance on tabular data [4]:\n1. Random Forest Classifier [6]: An ensemble of decision trees utilizing bagging to improve generalization and reduce overfitting.\n2. XGBoost Classifier [9]: An optimized gradient boosting framework known for its efficiency and high performance.\n3. CatBoost Classifier [11]: A gradient boosting library that inherently handles categorical features and employs ordered boosting to mitigate overfitting.\nHyperparameter settings. In this study, classifiers were configured with consistent hyperparameters across all feature subsets and datasets to attribute performance improvements directly to the impact of embedding-based feature enrichment rather than model-specific tuning. By standardizing these settings, we ensure a fair comparison that isolates the contributions of enriched features, highlighting their intrinsic value in boosting model accuracy and feature importance. For this purpose, we used the following hyperparameters: Random Forest with 100 estimators and balanced class weights; XGBoost with default tree depth, learning rate of 0.1, and 'mlogloss' as the evaluation metric; and CatBoost with default parameters and a random seed for reproducibility."}, {"title": "Ablation Study Design", "content": "To thoroughly assess the contribution of embedding-based feature enrichment, we designed a structured ablation study that isolates the effects of various feature subsets on classifier performance. This approach enables a clear comparison between models with baseline features and those enhanced by RoBERTa and GPT-2 embeddings, quantifying their impact on predictive accuracy."}, {"title": "Evaluation Metrics", "content": "To comprehensively assess classifier performance and capture various aspects of predictive accuracy, we employed multiple evaluation metrics, ensuring a robust and nuanced evaluation:\n\u2022 We use Accuracy and Balanced Accuracy to assess general performance and the ability to handle class imbalance, respectively:\n$\\text{Accuracy} = \\frac{1}{n} \\sum_{i=1}^n 1\\{\\hat{y_i} = y_i\\}$\nwhere n is the total number of instances, $\\hat{y_i}$ is the predicted label, and $y_i$ is the true label for instance i.\n$\\text{Balanced Accuracy} = \\frac{1}{C} \\sum_{c=1}^C \\frac{TP_c}{TP_c + FN_c}$"}, {"title": "Statistical Significance Testing", "content": "Paired t-tests were conducted between all pairs of feature subsets for each classifier and dataset combination. The Bonferroni correction was applied to adjust for multiple comparisons, ensuring thus a family-wise significance level of a = 0.05, which overall is way more conservative than using a = 0.05 for each pair-wise comparison."}, {"title": "Implementation Details", "content": "All experiments were implemented in Python 3.8, leveraging the following libraries:\n\u2022 scikit-learn [24] was used for data preprocessing, model training, evaluation metrics, PCA, and feature selection.\n\u2022 XGBoost [9] and CatBoost [11] were employed for the respective classifiers.\n\u2022 Hugging Face Transformers [36] facilitated the generation of contextual embeddings using pre-trained RoBERTa and GPT-2 models."}, {"title": "Performance Evaluation", "content": "This section presents the results of our evaluation of embedding-based feature enrichment on ensemble learning classifiers, specifically Random Forest, XGBoost, and CatBoost, across the eight benchmark datasets presented in Table 1. Based on a detailed ablation study, we evaluated the effects of combining traditional features with embeddings from pre-trained language models, specifically ROBERTa and GPT-2. All results are presented in this section, with further details in the Appendix, Table 2. The integration of these contextual embeddings demonstrated significant improvements in predictive performance, particularly in datasets with limited representativeness, i.e., imbalanced datasets or datasets with limited features or samples."}, {"title": "Overall Performance Trends Across Models and Feature Subsets", "content": "Performance Trends. As shown in Figure 2, in many datasets, feature subsets that incorporate embeddings show clear improvements in both Weighted/Balanced Accuracy, F1, and ROC-AUC Score over the baseline features alone. For example, in the UCI Adult, Pima Indian Diabetes, Titanic and Heart Disease datasets, feature subsets enhanced with GPT-2 and ROBERTa embeddings yield significant gains, especially in combinations with more advanced ensemble classifiers, such as XGBoost and CatBoost. These results suggest that the embedding-based enrichments capture essential information that improve classification. Moreover, XGBoost and CatBoost benefit from the enriched features more often than the Random Forest classifier. This can also be seen in Figure 3, which shows the absolute counts of wins per classifier, per feature subset."}, {"title": "Statistical Significance of Performance Improvements", "content": "To assess whether the integration of contextual embeddings (i.e., GPT-2 and RoBERTa) yields significant improvements in model performance compared to baseline features, we conducted a series of Bonferroni-corrected paired t-tests across all classifiers and datasets used in this study. These t-tests compared different feature subsets to determine if embedding-based enrichments had a statistically significant effect (p < 0.05) on metrics such as accuracy, balanced accuracy, F1 score, and ROC-AUC.\nFigures 10, 11, and 12 from the Appendix illustrate pairwise statistical significance analyses among feature subsets across the eight benchmark datasets. Each subplot shows a matrix of pairwise comparisons, where the value of 1 in dark-colored cells indicates that the differences between feature subsets are statistically significant (p < 0.05, after Bonferroni correction)."}, {"title": "Feature Importance Analysis", "content": "In order to understand the relative impact of different feature subsets on model predictions, we conducted an extensive feature importance analysis, with importance scores derived from the Random Forest, XGBoost, and CatBoost classifiers. Figures 4, 5, and 6 present the top 10 features for the three best-performing feature subsets across three selected datasets, namely the UCI Adult, Pima Indians Diabetes, and Heart Disease.\nAcross classifiers and datasets, embedding-derived features, such as those from GPT-2 and ROBERTa, frequently rank among the most important, which illustrates their significant contribution to classification outcomes. For example, in Figure4, GPT-2 and ROBERTa features appear prominently among the top-10-ranked features for the UCI Adult dataset, indicating that these embeddings effectively capture essential information that complements the original tabular features."}, {"title": "Visualization of Embedding Distributions", "content": "To further illustrate the discriminative power of the generated embeddings, we employed t-distributed Stochastic Neighbor Embedding (t-SNE) [34] to project high-dimensional embedding vectors into a 2D space. Figures 7 and 8 depict the clustering of ROBERTa and GPT-2 embeddings with respect to target classes in the UCI Adult and UCI Heart Disease datasets, respectively.\nThese visualizations reveal clustering patterns corresponding to different target classes, affirming that the embeddings encapsulate discriminative information conducive to accurate classification."}, {"title": "Discussion", "content": ""}, {"title": "Privacy-Preserving Potential of Embeddings", "content": "Privacy Advantages of Embedding-Based Representations. Embedding-based features present an effective approach to privacy-preserving machine learning, particularly beneficial in do-"}, {"title": "Limitations", "content": "The proposed method faces several limitations. First, embeddings from pretrained LLMs like GPT-2 and ROBERTa generate computational overhead, posing scalability challenges for large datasets or real-time applications. The use of 50 PCA components and selecting the top 10 features were based on preliminary experiments; optimal values could vary, thus necessitating further exploration for better efficiency and effectiveness.\nMoreover, embeddings, even after feature selection, remain less interpretable compared to raw features, particularly in sensitive, high-stakes applications. Developing methods to enhance interpretability is crucial. Embeddings can also amplify biases in noisy or inconsistently encoded datasets. For low-diversity datasets, there exists the risk of embedding degeneration, limiting the ability to distinguish between classes ore relevant groups in an unbiased way.\nEmbeddings may also add unnecessary complexity in structured tabular data with minimal contextual information, where their informative value is limited, as seen in some of the datasets used in this study. Future work could further investigate the expected use-case and dataset-specific value of embedding-derived features."}, {"title": "Future Research Directions", "content": "In alignment with the above limitations, we see high potential for research that focuses on the following areas: The development of use-case-specific embedding strategies for structured data, boosting the semantic relevance of embedding-derived features, could be highly impactful. Additionally, adaptive feature-weighting and regularization methods could be integrated to enhance robustness and prevent embedding degeneration in complex datasets or datasets with limited representativeness of features or classes."}, {"title": "Conclusion", "content": "Our findings reveal that embedding-based feature enrichment offers performance benefits for ensemble classifiers, especially for datasets with limited feature diversity or class representation. These gains can be further amplified with more advanced ensemble classifiers such as XGBoost or Cat-Boost. For datasets with comprehensive representation, the performance gains are modest at best, highlighting the selective applicability of this approach. Additionally, embedding-enriched models take full advantage of LLM-derived features, which consistently rank among the most influential in feature importance analysis. Hence, these features may play a critical role in uncovering complex data patterns beyond the reach of the original features.\nThese insights emphasize the potential of contextual embeddings to advance traditional feature engineering, aligning performance improvements with privacy-preserving strategies. We see high potential for research on optimizing embeddings for structured data, refining dimensionality reduction techniques, and exploring additional pre-trained models and embedding dimensions to further enhance generalizability across a broader range of classification tasks."}]}