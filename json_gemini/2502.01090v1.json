{"title": "Classic4Children: Adapting Chinese Literary Classics for Children with Large Language Model", "authors": ["Jiali Chen", "Xusen Hei", "Yuqi Xue", "Zihan Wu", "Jiayuan Xie", "Yi Cai"], "abstract": "Chinese literary classics hold significant cultural and educational value, offering deep insights into morality, history, and human nature. These works often include classical Chinese and complex narratives, making them difficult for children to read. To bridge this gap, we introduce a child-friendly literary adaptation (CLA) task to adapt the Chinese literary classic into engaging and accessible text for children. However, recent large language models (LLMs) overlook children's reading preferences (i.e., vivid character portrayals, concise narrative structures, and appropriate readability), which poses challenges in CLA. In this paper, we propose a method called InstructChild, which augments the LLM with these preferences for adaptation. Specifically, we first obtain the characters' personalities and narrative structure as additional information for fine-grained instruction tuning. Then, we devise a readability metric as the reward to align the LLM with the children's reading level. Finally, a lookahead decoding strategy is applied to improve the readability of the generated text during inference. To support the evaluation of CLA task, we construct the Classic4Children dataset, which comprises both the original and child-friendly versions of the Four Great Classical Novels of Chinese literature. Experimental results show that our InstructChild significantly improves automatic and human evaluation performance.", "sections": [{"title": "1 Introduction", "content": "The Chinese literary classics portray iconic characters and their stories to convey significant cultural and educational value (Hsia, 2016; Legge, 2022). These works are not only a vital part of China's rich literary heritage but also play a crucial role in shaping moral values and cultural understanding, especially for young learners. Given their importance, these classics are a fundamental part of the Chinese educational curriculum, and many children are required to engage with these texts during their schooling years (Luo, 2019). However, these works are frequently written in classical Chinese and involve complex plots and themes, presenting significant challenges for children to read. Traditionally, many writers make much effort to manually transform these complex literary classics into child-friendly versions (M\u00fcller, 2013; Hui, 2024), which is a time-consuming and labor-intensive process. Therefore, we propose the child-friendly literary adaptation (CLA) task, which aims to automatically make content accessible and engaging for children. Promisingly, the recent advanced large language models (LLMs) have performed impressively across various natural language processing tasks, including text style transfer (Reif et al., 2022; Liu et al., 2024a) and text simplification (Valentini et al., 2023; Kew et al., 2023). Nevertheless, such methods simply modify specific stylistic elements (e.g., sentiment, formality, author-style and lexicon) within sentences, which overlook the importance of children's reading preferences, leading to poor performance in the CLA task. Moreover, it is well known that LLMs can capture language patterns from provided examples through in-context learning (Dong et al., 2022). We utilize a carefully crafted prompt with a one-shot human-written example to query GPT-40 (OpenAI, 2023), exploring whether children's reading preferences can be captured by GPT-40, as shown in Fig. 1. Surprisingly, it also fails to produce text similar to human-written content, instead generating an overly lengthy translation of classical Chinese without simplification, which is unsuitable for children. These findings underscore the limitations of current LLMs in effectively adapting literary classics for children.\nScrutinizing the adapted child-friendly text by human writers, we identify three key children's reading preferences that are crucial for effective adaptation. i) Considering that the literary classic often contains numerous characters, vividly portraying each character's personality can help children better remember and distinguish them. As shown in Fig. 1, the green-highlighted words in the adaptation emphasize the different personalities of Tripitaka and the Demon. For instance, Tripitak presents a timid and respectful nature by his trembling response, showcasing his fear and humility in the face of danger. ii) Concise narrative structure, rather than overly detailed or complex plots, is effective in sustaining children's interest in reading. As shown in Fig. 1, the adapted text simplifies the dialogue while maintaining the core storyline. Specifically, several unnecessary details, like \"sent by the Emperor\u201d and \u201cobtained the scriptures\" are removed in Tripitaka's explanation, as they introduce background information and future outcomes that may confuse children. iii) Besides, the adaptation also take into account the children's reading level to ensure appropriate readability, facilitating easier comprehension and engagement with the content (Chitez et al., 2024).\nIn this paper, we propose the InstructChild, a method to effectively adapt Chinese literary classics for children with the LLM. It consists of three"}, {"title": "2 Related Work", "content": "The objective of text style transfer (TST) is to endow text with a different style (e.g., positive \u2192 negative) while preserving its semantic content. The traditional paradigm explicitly divides text into content and style information and then employs a target style for desired text generation (Yuan et al., 2022; Zhu et al., 2023; Zhao et al., 2024a). Specifically, Zhu et al. (2023) address the task of author-style transfer and implement content-style disentanglement and stylization at the discourse level. Zhao et al. (2024a) develop a multi-layer Joint Style-Content Weighed (JSCW) module along with a style consistency loss to ensure both content preservation and consistent style across generated sentences. Recently, LLMs have shown promising results on TST through fine-tuning (Dementieva et al., 2023; Mukherjee et al., 2024), in-context learning (Mai et al., 2023; Chen, 2024) and promt-based editing (Suzgun et al., 2022; Liu et al., 2024b). However, previous methods primarily transfer the text styles related to sentiment and formality. This study adapts Chinese literary classics into a child-friendly style, emphasizing vivid character descriptions and concise narrative structure tailored to children's reading levels."}, {"title": "2.2 Text Simplification", "content": "Text simplification aims to reduce the complexity of the text, which can be categorized into two main branches (i.e., editing operations and lexical-syntactic rules). Specifically, the editing operations simplify the text through various editing techniques, such as replacing difficult words and re-ordering sentence components (Kumar et al., 2020; Mallinson et al., 2020). Moreover, some works introduce the lexical and syntactic rules for simplification (Qiang et al., 2020; Valentini et al., 2023). For instance, Valentini et al. (2023) incorporate the LLM with the lexical simplification model to simplify the children's story. In contrast to text simplification, which aims to simplify vocabulary and syntax, Chinese literary classics often feature classical language that is challenging for children to understand. Our approach involves clearly explaining complex expressions while maintaining children's engagement through vivid character descriptions and an age-appropriate narrative structure."}, {"title": "3 Methodology", "content": "In this section, we introduce InstructChild, a large language model (LLM) based method to facilitate the adaptation of Chinese literary classics into a child-friendly style. This method bridges the gap between the complexity of the original text and the cognitive abilities of children with fine-grained instruction tuning, refinement and a lookahead decoding strategy. Fig. 2 illustrates the proposed InstructChild, and the details of our method are elaborated in the following sections."}, {"title": "3.1 Fine-grained Instruction Tuning", "content": "Inspired by previous studies (Wang et al., 2023; Ouyang et al., 2022; Yuan et al., 2024) that successfully apply well-designed prompts as guidance to generate text with desired attributes, we develop instruction incorporating personality and narrative structure to fine-tune the LLM (i.e., Qwen2-7B-Instruct (Yang et al., 2024)), aiming to adapt text with vivid character portrayals and concise narrative structure. Specifically, they are prepended to input text as the instruction for fine-tuning."}, {"title": "3.1.1 Personality Assessment", "content": "In the field of psychology, the Big Five Personality Traits (BFPT) (Roccas et al., 2002) categorizes personality into five dimensions: openness, conscientiousness, extraversion, agreeableness, and neuroticism. It provides a robust framework for assessing character personality. Technically, we first identify the character names in the original text and filter out the top 50 characters by frequency of occurrence for each literature. Given that large language models (LLMs) have demonstrated the ability to effectively capture the personalities of characters (Zhao et al., 2024b; Wang et al., 2024b), we prompt GPT-40 (OpenAI, 2023) to obtain the personality dimension scores and brief descriptions of characters in the original text. The prompt is shown in the Table 7. Specifically, the score for each personality dimension ranges from 1 to 5, with higher values indicating a stronger presence of that specific dimension. Consequently, we obtain the personality information for each character based on these dimensions with the corresponding score and brief description, as shown in Fig. 2(a)."}, {"title": "3.1.2 Narrative Structure Extraction", "content": "In addition to character personality, the concise narrative structure also distinguishes adapted child-friendly style text from the original literary classic (M\u00fcller, 2013). It can be constructed from the entities and their relationships in the text (Zhao and Zhang, 2024; Xie et al., 2024). Therefore, we also employ the GPT-40 to identify entities and relationships as supplementary information for further fine-tuning. The prompt is shown in the Table 8. These triplets can be integrated into the instructions to guide the LLM in focusing on important narrative elements."}, {"title": "3.1.3 Integrative Instruction for LLM", "content": "The integrative instruction comprises the characters' personalities, narrative structure (i.e., entity-relation triplets) and the original literary texts. Considering that each input literary text typically contains only a limited number of characters, we first identify the character names and then retrieve the corresponding personality information of the character. An exemplar instruction for fine-tuning the large language model is shown in Table 9. The integrative instruction is directly fed into the frozen large language model (i.e., Qwen2-7B-Instruct) with learnable LoRA layers for child-friendly style text adaptation. The language modeling loss can be formulated as:\n$\\mathcal{L}_{l a n}=\\sum_{t=1}^{T}-\\log p\\left(y_{t} \\mid y_{<t}, I n s\\right),$\nwhere $\\log p$ is the negative log-likehood, $Ins$ is the integrative instruction, and $y_{<t}$ represents the words before the $t$-th word."}, {"title": "3.2 Refinement with Readability Metric", "content": "After fine-grained instruction fine-tuning, the LLM can effectively emphasize character personalities and the narration of a concise storyline. However, the instruction tuning phase does not include an explicit mechanism to verify whether the generated text aligns with the children's reading level. Instead, it relies solely on token-wise gradient updates through teacher forcing based on reference texts. Therefore, we design the readability metric tailored for Chinese child-adapted literary classics, namely Red-CN, to assist LLM in generating text with the desired readability. Existing studies (Ouyang et al., 2022; Xu et al., 2023), have demonstrated that supplementing initial instruction tuning with a subsequent reinforcement learning phase can be beneficial, where the model is further refined by the reward function. For our implementation, we utilize the designed readability metric Red-CN as a reward for refinement."}, {"title": "3.2.1 Readability Metric as Reward", "content": "We design the readability metric Red-CN, which takes into account the complexity of Chinese sentences. Inspired by (Valentini et al., 2023; Chitez et al., 2024), we first assess the suitability of Chinese characters and syntax. Specifically, the metric is determined by the proportion of adverbs and conjunctions $r_{a c}$ and the frequency statistics of the character $r_{f}$ based on the collection (Da, 2004) in each sentence. We analyze expert-adapted child-friendly literary classics and find that these two indicators typically cluster around values of 5 and 85 per sentence, respectively. It suggests that excessively low or high values of these indicators are not conducive to optimal reading levels for children. We assign the maximum value of 1.0 when any indicator matches the desired value when each indicator matches its corresponding target value previously mentioned, with the reward decreasing exponentially toward 0 as it deviates from the target values. Thus, we convert these two indicators with the normalized Gaussian distribution $\\mathcal{F}(\\cdot)$ centered at their target values:\n$\\mathcal{F}=\\mathcal{N}(\\hat{r}, \\delta^{2}),$\n$\\hat{r}_{a c}=\\mathcal{F}\\left(r_{a c}\\right), \\hat{r}_{f}=\\mathcal{F}\\left(r_{f}\\right),$\nwhere $\\hat{r}$ is the corresponding target value, $\\delta$ is the standard deviation. $\\hat{r}_{a c}$ and $\\hat{r}_{f}$ are the converted indicators. The rationale behind introducing the Gaussian distribution is to ensure that the reward decreases nonlinearly, in the sense that minor deviations from the target readability lead to slight reductions, whereas more significant deviations result in increasingly larger penalties. More details are shown in the Appendix B.1.1 and B.1.2.\nFurthermore, Xu et al. (2016) suggest that reducing the number of characters contributes to more effective adaptations of literary classics for children. We use the token length of the adapted text as an additional indicator to prevent generating overly verbose text. This indicator is also normalized to the range of [0, 1], using its proportional value relative to the original input text, denoted as $\\hat{r}_{t}$, where higher values represent fewer tokens:\n$\\hat{r}_{t}=\\max \\left(0,1-\\frac{\\text { output\\_len }}{\\text { input\\_len }}\\right),$\nwhere input_len and output_len represent the length of the original text and the generated text, respectively. Finally, following the emphasis by Da (2004) on the strong correlation between character frequency and readability in Chinese, we assign the specific weights to obtain the overall readability metric (i.e., Red-CN), as the reward score $\\hat{r}$:\n$\\hat{r}=0.3 \\hat{r}_{a c}+0.4 \\hat{r}_{f}+0.3 \\hat{r}_{t} .$"}, {"title": "3.2.2 DPO", "content": "The reinforcement learning with the readability metric is used to ensure the LLM generates text aligned with the children's reading level. Specifically, we randomly choose 1,000 instances from the Classic4Children training data and use the top-p sampling method to produce $K$ outputs for each sample, represented as $\\{Y_{1}, Y_{2}, \\ldots, \\hat{Y}_{K}\\}$. Next, we form them as rank pairs based on the readability metric score, ignoring those with a score difference less than 3. The direct preference optimization (DPO) (Rafailov et al., 2023) is employed as a reinforcement learning policy to further optimize the LLM with learnable LoRA layers."}, {"title": "3.3 Lookahead Decoding", "content": "Getting inspiration from (Wang et al., 2023), we devise a lookahead decoding strategy during inference to maximize the LLM's ability to generate text with high readability scores, which extends the traditional strategy with the readability metric, as illustrated in Fig. 2(c). The core idea involves forecasting potential subsequent tokens and then adjusting the selection process toward higher readability scores. Specifically, the LLM first generates $L$ candidate samples at the $t$-th decoding step. Each sample starts at the $(t-1)$-th step and continually generates $n$ subsequent tokens, which can be denoted as $\\hat{y}_{<t-1+n}$. Then, we calculate the readability scores of these candidate samples. The calculation of each sample can be formulated as:\n$\\mathcal{G}\\left(\\hat{y}_{<t-1+n}\\right)=\\hat{r},$\nwhere $\\mathcal{G}(\\cdot)$ denotes an supplementary guidance function during decoding. Consequently, the selection criterion for the $t$-th token can be mathematically expressed as:\n$f\\left(y_{t}\\right)=\\log p\\left(y_{t} \\mid y_{<t}, I n s\\right)+\\lambda \\max \\mathcal{G}\\left(\\hat{y}_{<t-1+n}\\right),$\nwhere $\\lambda$ is the hyperparameter that adjusts the influence of readability on the token selection process."}, {"title": "4 Experiment", "content": "In this paper, we construct Classic4Children, a Chinese child-friendly literary adaptation dataset based on the Four Great Classical Novels of Chinese literature (i.e., Journey to the West, Romance of the Three Kingdoms, Water Margin, Dream of the Red Chamber). Initially, we collect widely recognized versions of the original texts and their corresponding child-adapted editions. Following (Zhu et al., 2023), since there are too many tokens in each chapter of the literary classic, we manually annotate the corresponding paragraph fragments as training samples, with each chapter being divided into multiple"}, {"title": "4.2 Implementation Details", "content": "We train our InstructChild on a Tesla A40 48GB GPU card and it is initialized with Qwen2-7B-Instruct\u00b3. We insert the LoRA layers into each self-attention layer, setting the rank to 8 for optimization. Specifically, the batch size is 24 and we train 3 epochs during the fine-grained instruction tuning. The desired values (i.e., the expectation) of the Gaussian distribution in Eq. 2 are 5 and 85 for $\\hat{r}_{a c}$ and $\\hat{r}_{f}$, respectively. After experimenting with different values for the standard deviation $\\delta$, we set it at half the expectation (i.e., 2.5 and 42.5, respectively). This choice allows the mapping values to be concentrated as closely as possible around the target values. Before the refinement, we randomly sample 1,000 instances from the training set and employ top-p sampling strategy, where the temperature is set to 0.8 and p=0.9 to generate four candidate samples for each input. We maintain those with a score difference greater than 3 for direct preference optimization. For the lookahead decoding strategy, the LLM generates L=5 candidate samples with n=20 subsequent tokens at each decoding step. The hyperparameter $\\lambda$ for the token selection in Eq. 7 is 1."}, {"title": "4.3 Baselines and Ablation Models", "content": "To verify the superiority of our InstructChild, we compare it with three types of baselines. i) Closed-source large language models (LLMs) with large-scale parameters (API-based): GPT-40 (OpenAI, 2023), GLM-4 (GLM et al., 2024), QWen2.5 (Yang et al., 2024), and EAPMT (Wang et al., 2024a). We access these models via API interfaces, which exhibit strong reasoning capabilities across various natural language processing tasks. Specifically, we also ask them to focus on the characters personality and concise narrative structure with a one-shot example. In particular, EAPMT first generates a detailed explanation for each input sentence, encompassing both the literal content and deeper meanings. Then it paraphrases sentences into a child-friendly style format based on the explanation. The prompts for these LLMs is shown in Table 10 and Table 11. ii) Text style transfer (TST) models (TST-based): P&R (Suzgun et al., 2022), StoryTrans (Zhu et al., 2023), and ParaGuide (Horvitz et al., 2024). Specifically, P&R is a training-free few-shot TST model and we utilize the Qwen2 as the backbone. We also expand the Chinese vocabulary for diffusion-based Paraguide and re-trained it for our task. iii) Open-source large language models with relatively moderate parameters (FT-based): Llama2-13B (Touvron et al., 2023), Llama3-8B (Dubey et al., 2024), Qwen2-7B (Yang et al., 2024) and GLM4-9B (GLM et al., 2024). We utilize LORA (Hu et al., 2022) technique to fine-tune these LLMs. Notably, Llama models have been extended with the Chinese vocabulary and further pre-trained on Chinese instruction (Cui et al., 2023)."}, {"title": "4.3.2 Ablation Models", "content": "We conduct ablation experiments to evaluate the effectiveness of various components within our InstructChild method. InstructChild w/o Per and InstructChild w/o Nat: InstructChild without personality information and narrative structure, respectively. InstructChild w/o Ref: InstructChild without refinement stage by reinforcement learning. It does not implement the lookahead decoding strategy for generation, as it is closely tied to the Red-CN metric used during refinement. InstructChild w/o Look: InstructChild without lookahead decoding strategy during inference."}, {"title": "4.4 Evaluation Metric", "content": "Following previous studies (Zhu et al., 2023), we evaluate the performance with BLEU-(1 to 2) (Papineni et al., 2002) and BERTScore (Zhang et al., 2020) metrics. Specifically, we report the recall (BS-R), precision (BS-P) and F1 score (BS-F1) of the BERTScore. They are commonly used for measuring the lexical and semantic similarity in text generation. Moreover, we also use the readability scores in Eq. 5 as an additional metric (i.e., Red-CN) to assess whether the generated text aligns with children's reading levels (higher is better)."}, {"title": "4.4.2 Human Evaluation Criteria", "content": "We also conduct human evaluation for baselines (i.e., GPT-40, StoryTrans and GLM4-9B) and our InstructChild. Specifically, we randomly select 200"}, {"title": "4.5 Results and Analysis", "content": "Table 1 shows the results of baselines and our InstructChild method on Classic4Children dataset. We find that: i) The closed-source LLMs, despite their strong performance in many NLP tasks, do not perform well on the child-friendly literary adaptation (CLA) task. Specifically, our InstructChild scores higher than these LLMs under all evaluation metrics, e.g. \u201c+2.17\u201d and \u201c+4.93\u201d on BS-F1 and Red-CN, respectively, compared to GPT-40, which has over 10 times more parameters. The reason is that these LLMs tend to generate detailed explanations of the original texts and produce excessively lengthy outputs (Chen et al., 2023; Hu et al., 2024; Chen et al., 2024), resulting in suboptimal performance. ii) There is a significant performance gap between existing text style transfer (TST) models and our InstructChild, which indicates that the CLA task is not simply a matter of text style transfer but also requires the consideration of children's reading preference for effective adaptation. These TST models cannot capture the child-friendly style for adaptation and often include words that are too complex for children. By integrating characters' personalities and narrative structure, our InstructChild effectively produces text that is both accessible and engaging for children. iii) Despite our efforts to continually pre-training the Llama models on Chinese instruction datasets, their performance remains considerably distant from the intended reading level. Specifically, Llama3-8B and Llama2-13B score significantly lower than other models on the Red-CN metric. Notably, they tend to generate specific phrases that closely match the reference text, leading to a higher BS-P value. Since they do not fully cover all the content in the reference text, the BS-R value is low. Furthermore, QWen2-7B and GLM4-9B also perform worse than our InstructChild, indicating that straightforward LORA fine-tuning alone for the LLM is insufficient."}, {"title": "4.5.2 Ablation Study", "content": "The results of ablation experiments are shown in Table 1. We observe that: i) By removing personality information and narrative structure from the integrative instruction, there is a decline in performance on all metrics. It demonstrates that this additional information is crucial for the LLM to produce text adaptation more similar to those written by humans. Moreover, although InstructChild w/o Per and InstructChild w/o Nat employ refinement, the drop in readability scores (i.e., Red-CN) indicates that initial instruction tuning can encourage the LLM to further generate sentences that align with the children's reading level. ii) Then we investigate the impact of the refinement with Red-CN metric. Comparing the result of InstructChild and InstructChild w/o Ref, the refinement stage improves performance, particularly on the Red-CN metric. Simultaneously, most traditional natural language generation metrics also improve. It demonstrates that our Red-CN metric is a reasonable measure of children's reading ability in Chinese literary classics. iii) Finally, we notice a slight performance improvement when applying the lookahead decoding strategy. It suggests that this strategy can further encourage the LLM to generate child-friendly style text with appropriate readability during inference."}, {"title": "4.5.3 Human Evaluation Results", "content": "To validate the reliability of our human evaluation, we separately calculate standard deviations of each human evaluation metric, as shown in Table 2. The statistical analysis confirms the faithfulness of our evaluation results. Table 2 also presents the results of the human evaluation. We find that: i) Our InstructChild achieves competitive results on the Flu metric with the much larger LLM (i.e., GPT-40) to generate fluent sentences. For the CP metric, our integrative instruction guides the LLM to simplify or omit certain intricate plots. In contrast, GPT-40 often attempts a more comprehensive paraphrase, which results in higher scores. ii) The CC metric indicates that our model is more likely to generate adapted texts with rich character descriptions. This outcome is attributed to the inclusion of character personality during instruction tuning, making the adapted content more relatable and engaging for children. iii) The NE metric indicates that our model significantly outperforms baselines by producing a more concise narrative structure aligned with the children's reading level. Upon examining the generated outputs, we observe that GPT-40 often provides overly detailed explanations for certain terms, resulting in longer text than the original. This verbosity and inclusion do not align with children's reading preferences."}, {"title": "4.6 Case Study", "content": "Fig. 3 shows the adapted text generated by GPT-40 and our InstructChild. Specifically, InstructChild produces a more concise narrative that emphasizes key characters' traits. It describes Cao Cao's determination and urgency while simplifying his inner monologue. In contrast, GPT-40 solely rewrites the original text, resulting in overly lengthy content with complex words. Moreover, the output of GPT-40 is even longer than the original text, further reducing its readability for children. Although InstructChild performs well on the CLA task, it focuses on the key narrative where Cao Cao's sword ultimately reaches Lv Bu. However, such simplifications can sometimes lead to misunderstandings. We believe that the balance between simplifying character relationships and ensuring the clarity of key details is a crucial direction for future research."}, {"title": "5 Conclusion", "content": "In this paper, we introduce the child-friendly literary adaptation (CLA) task to automatically adapt Chinese literary classics into engaging and age-appropriate text for children. Moreover, we pinpoint three key children's reading preferences (i.e., vivid character portrayals, concise narrative structures, and appropriate readability) for CLA, even state-of-the-art LLMs struggle to capture these preferences for adaptation. Our proposed InstructChild explicitly leverages these preferences to guide the LLM in generating child-friendly text for children. Additionally, we construct the Classic4Children dataset for a comprehensive evaluation. Experimental results show that our InstructChild significantly outperforms the existing LLMs."}, {"title": "6 Limitations", "content": "In this paper, we propose InstructChild to adapt Chinese literary classics into a child-friendly style. Although our method significantly enhances the readability of adapted texts for children, the lookahead decoding strategy incurs substantial computational overhead during inference. Consequently, both the number of subsequent tokens n and candidate samples L must be limited. To mitigate these computational costs, a potential solution is to apply distillation techniques to improve decoding efficiency. Additionally, our CLA task currently focuses on paragraph fragments as training data due to limitations on model input length. In the future, adapting the model to handle the full chapter sequences should be considered. Moreover, we also believe that the balance between simplifying character relationships and ensuring the clarity of key details is a crucial direction for future research."}, {"title": "A Dataset Construction", "content": "We describe the data collection process based on the Four Great Classical Novels of Chinese literature (i.e., Journey to the West, Romance of the Three Kingdoms, Water Margin, Dream of the Red Chamber). Specifically, the original texts are collected from the publicly available website. For the children's adapted versions, we choose the widely acclaimed children's reading series. Following (Zhu et al., 2023), since there are too many tokens in each chapter of the literary classic, we use paragraph fragments as training samples, with each chapter being divided into multiple fragments. Considering that a single chapter in the children's version may correspond to multiple chapters in the original version, we first manually align the chapter IDs of the children's edition with those of the original work. This approach effectively narrows down the scope for subsequent annotation, ensuring more accurate correspondence between the versions. Subsequently, using the text of each paragraph from the children's version as a reference, we manually search for the corresponding text in the original version and constructed them into pairs. Moreover, we filter out paragraphs that lacked a matching counterpart in the original text. This process ensures that the data accurately reflects the intended alignment between the two versions. After this meticulous process, we obtained 819, 744, 742, and 681 data samples for \u201cJourney to the West", "Romance of the Three Kingdoms": "Water Margin\" and \"Dream of the Red Chamber,\" respectively. Finally, the collected data are divided into training and testing samples, comprising 2,686 samples for training and 300 samples for testing, with 75 samples from each literary work are randomly selected for testing.\""}, {"title": "B More Experimental Details", "content": "Inspired by (Chitez et al., 2024), the appropriate proportion of adverbs and conjunctions in sentences plays a crucial role in the readability of Chinese texts. Therefore, we utilize publicly available code for the calculation."}, {"title": "B.1.1 Adverbs and Conjunctions", "content": "Therefore, we utilize publicly available code for the calculation."}, {"title": "B.1.2 Chinese Character Frequency", "content": "In our analysis of Chinese novel and their texts, we encounter difficulties in calculating word frequency. It arises primarily due to the prevalence of character names and proprietary nouns, which are seldom included in common word lists. As a result, these terms often exhibit anomalously low frequency, even they are simple for children to read. Consequently, we calculate the frequency of individual characters for each sentence based on the collection (Da, 2004). Specifically, we use only the top 5000 most frequent Chinese characters from the collection and recalibrate their statistical frequencies for calculation."}, {"title": "B.1.3 Sentence Length", "content": "Furthermore, Xu et al. (2016) suggest that reducing the number of characters contributes to more effective adaptations of literary classics for children. We utilize the sentence length of the adapted text as an additional indicator to prevent generating overly verbose text. This indicator $r_t$ is also normalized to the range of [0, 1], using its proportional value relative to the original input text, where higher values represent fewer tokens:\n$\\hat{r}_{t}=\\max \\left(0,1 - \\frac{\\text { output_len }}{\\text { input_len }}\\right),$"}, {"title": "B.2 Correlation Comparison", "content": "Following (Xu et al., 2023), we report Pearson's correlation coefficients between the automatic metrics (i.e., BERTScore and reward calculation Red-CN) and human evaluation metrics (i.e., Flu, CP, CC and NE, as defined in the Human Evaluation Criteria section) to assess the effectiveness of our reward calculation. The Core results are shown in Table 6, and the p-values of our results are lower than 0.05, which indicates statistical significance. Specifically, we sample 100 generated instances from the model and invite volunteers with good educational backgrounds in Chinese to provide human evaluation results. The experimental results show that all human evaluation metrics exhibit statistically significant correlations with Red-CN, demonstrating the effectiveness of our reward calculation."}, {"title": "B.3 Experiment on Hyperparameter", "content": "We conduct experiments to investigate the sensitivity of hyperparameters during inference, including the number of candidate samples L, the number of subsequent tokens n and the weight $\\lambda$ for the token selection. Specifically, we explore different parameter $\\lambda$ settings, including ($\\lambda$ = 0.5, 1, 2) in Table 5, and find that the fluctuations of the results are minimal. Table 3 and Table 4 show the results of different L and n, respectively. We observe that the model performance has a slight improvement as L and n increase. However, larger values of L and n are computationally costly, as they require the generation of additional future tokens at each step during inference. Therefore, our InstructChild model employs the parameter setting of L = 5 and n = 20 to reduce computational overhead."}]}