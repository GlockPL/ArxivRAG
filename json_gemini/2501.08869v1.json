{"title": "Silent Abandonment in Text-Based Contact Centers: Identifying, Quantifying, and Mitigating its Operational Impacts", "authors": ["Antonio Castellanos", "Galit B. Yom-Tov", "Yair Goldberg", "Jaeyoung Park"], "abstract": "Problem definition: In the quest to improve services, companies offer customers the opportunity to interact with\ntheir agents using texting. Such contact centers face operational challenges distinct from traditional call centers because\nthe measurement of common proxies for customer experience, such as customers' abandonment and willingness to wait\n(patience), are subject to information uncertainty. A main source of such uncertainty is silent abandonment. Silent-\nabandonment customers leave the system while waiting without notifying the system. As a result, the system is unaware\nthat the customers left, and the agent's time is wasted. Furthermore, the system may not be aware (even retrospectively)\nwhether a customer silently abandoned or was served. Our goals are to estimate the magnitude of the silent-abandonment\nphenomenon and develop tools to mitigate its impact on the system.\nMethodology/results: We develop classification models to investigate the magnitude of silent abandonment. A sample of\n17 companies shows that 3%-70% of the customers entering these contact centers abandon silently. A detailed text-based\nanalysis of one company identifies that 71.3% of abandoning customers do so silently and that such behavior reduces agent\nefficiency by 3.2% and system capacity by 15.3%, incurring an estimated annual cost of $5,457 per agent. Separate from\nthis classification, we develop an expectation-maximization (EM) algorithm to accurately estimate customers' patience\nunder information uncertainty and examine covariates influencing its value.\nManagerial implications: We find that companies should use classification models to estimate abandonment scope and\nour EM algorithm to estimate customer patience. We suggest strategies to operationally mitigate the impact of silent\nabandonment by predicting suspected silent-abandonment behavior or changing service design. Specifically, we show\nthat while allowing customers to write while waiting in the queue creates a missing data challenge, it also significantly\nincreases patience and reduces service time, leading to reduced abandonment and lower staffing requirements.", "sections": [{"title": "1. Introduction", "content": "The field of service engineering relies on measuring proxies for customer experience in a service system.\nTwo of the most common operational measures used as such proxies are customer waiting and abandonment\nfrom the queue. Both are crucial performance measures for understanding customers' willingness to wait for\nservice, which in turn is crucial for making operational decisions (Mandelbaum and Zeltyn 2013, Garnett\net al. 2002). Waiting happens when a customer enters the service system, but there is not an available\n1"}, {"title": "2. Literature Review", "content": "The context of this research is contact centers, which are an important part of the service industry's\ndigital revolution. Service companies branch into more accessible and easy-to-use service channels such\nas mobile applications. Technology allows modern-day companies to replace traditional service encounters\n(face-to-face, telephone) with technology-mediated ones (Massad et al. 2006, van Dolen and de Ruyter\n2002), which allow customers and service employees to connect through digital interfaces (Schumann et al."}, {"title": "2.1. Context", "content": "2"}, {"title": "2.2. Scope of Silent Abandonment in Different Contexts", "content": "Sab of customers waiting in a queue is not exclusive to contact centers and appears in other environments\nsuch as ticket queues (Kerner et al. 2017, Kuzu et al. 2019), scheduling systems (Liu 2016), emergency\ndepartments (EDs) (Yefenof et al. 2022), and interactive voice response (IVR) systems (Carmeli et al. 2019).\nIn ticket queues, an arriving customer receives a ticket with their queue number (and possibly estimated\nwait time) (Kerner et al. 2017). The customer may silently abandon either before joining the queue or at\nsome point during the wait. Analogous to contact centers, the Sab is not realized until the customer is called\nfor service and does not show up, and the exact abandonment time is unknown. Kuzu et al. (2019) estimate\nthe scope of abandonment in ticket queues of a bank to be 13.2%-26.1%, depending on the customer class.\nHigh abandonment rates in ticket queues indicate inefficiencies in the service delivery of the company,\npotentially damaging revenue, customer satisfaction, and loyalty (Kuzu et al. 2019).\nSilent abandonment is also conceptually similar to no-show incidents, where a customer fails to arrive\nfor a scheduled appointment without prior notification. No-show incidents are particularly common in\nhealthcare, with rates ranging from 23%-34% (Liu 2016). Healthcare providers can reduce this phenomenon\nby reminding the customer of their future appointment (Geraghty et al. 2008), but cannot eliminate it. Ho\nand Lau (1992) showed that no-shows strongly affect system performance because of capacity loss and\nforced physician idleness. We claim these efficiency problems also happen in contact centers due to Sab.\nOverbooking and appointment-book design policies are used to reduce the idleness resulting from no-shows\nby controlling the number of customers arriving at each time slot (Vissers 1979). Then, when a no-show is\ndetected, the agent is able to serve another customer without delay. We cannot apply such methodologies in\ncontact centers, where arrivals are unscheduled, but an analogy can be made to concurrency policies, where"}, {"title": "2.3. Estimating Customer Patience", "content": "While silent abandonment manifests across various environments, a deeper understanding of its operational\nimpact requires robust methods for customer-patience estimation. Estimating patience is critical to predicting\nabandonment behaviors and designing effective service strategies to mitigate Sab. The literature on estimating\npatience has primarily focused on two environments: call centers and emergency departments. Many studies\nhave developed methods to estimate customer patience in call centers, where service dynamics create right-\ncensored data (see review Dai and He 2011 and references therein as well as Ak\u015fin et al. 2017, Emadi and\nSwaminathan 2018, Ye et al. 2020). For example, Mandelbaum and Zeltyn (2013) assumed that customer-\npatience time, \u03c4, and virtual wait time, W, are exponentially distributed with rates 0 and y, respectively, and\ndeveloped a maximum likelihood estimator for customer patience from right-censored data. In contrast, EDs\nface the additional challenge of left-censored data due to the phenomenon of LWBS. Specifically, Yefenof\net al. (2022)\u2014an important predecessor to this paper-developed maximum likelihood methods to address\ndata censoring when estimating patient patience in EDs. Yet, all the above assumes complete data, whereas\nour EM model takes into account the class uncertainty between Sab and being served."}, {"title": "3. The Scope of Silent Abandonment in Contact Centers and Its Impact on Efficiency", "content": "We posit that the phenomenon of silent abandonment (Sab) is pervasive in contact centers. To substantiate\nthis claim, we collected general metadata from several Western companies and obtained detailed data from\na telecommunications company in the United States, which we refer to as \"XYZ Company.\u201d These datasets\nwere provided by LivePerson Inc., a leading provider of computational infrastructure for the contact-center\nindustry.\nIn this section, we first describe the dynamics of conversations in contact centers and highlight the\nchallenges associated with estimating abandonment probabilities. We demonstrate how customer behavior\nsignificantly influences informational uncertainty. Subsequently, we estimate the true abandonment proba-\nbility by uncovering the prevalence of silent abandonment in our data using an AI-based classification model\napplied to the XYZ dataset."}, {"title": "3.1. The Service Process and the Data Describing It", "content": "To explain how contact centers operate, we stylize several examples of conversations, each representing a\ndistinct service outcome. These conversations are presented in Figure 1, where agent messages are depicted\nin blue and customer messages in orange. The figure outlines four scenarios of conversation dynamics:\n1. Served Customer (Sr): These customers enter the queue, wait, are assigned to an agent, and while\nserved engage in a back-and-forth exchange with the agent. Customers may write their inquiry either while\nwaiting or after being assigned to an agent.\n2. Known Abandonment (Kab): These customers enter the system, wait, and at some point decide to\nclose the communication app, signaling to the system that they have abandoned the service. The system\nrecords their abandonment and its timestamp, ensuring they are not assigned to an agent. Customers in this\ncategory may write an inquiry while waiting.\n3. Served with One Exchange (Sr1): These customers enter the queue, wait, and write an inquiry while\nwaiting. They are then assigned to an agent who responds. However, the service interaction consists solely\nof agent messages, with no further communication from the customer."}, {"title": "3.2. Estimating the Scope of Silent Abandonment", "content": "At the XYZ contact center, 5.1% of customers abandoned the queue by explicitly closing the communication\napp, classifying them as Kab. uSab customers represent 24.4% of all conversations, while the remaining\n70.5% of customers clearly received service and are categorized as Sr.\nIn this section, we develop a classification model to distinguish uSab conversations into the Sr1 and Sab\ncategories. This classification enables us to accurately estimate the true proportion of abandoned customers\nand mitigate bias introduced by the exclusion of Sab customers. Furthermore, the model helps estimate the\ntime required for a service agent to recognize that a Sab customer has abandoned the queue-time that\nconstitutes wasted effort. We further quantify the extent of the agent's wasted effort on such interactions.\nWe propose a detailed examination of conversation transcripts to classify whether uSab customers silently\nabandoned the queue or were served. To this end, we manually labeled a random sample of 650 uSab\nconversations into two groups-Sr1 and Sab-by reviewing the full conversation transcripts. The sample\ncomprised 342 Sr1 conversations and 308 Sab conversations.\nNext, we extracted textual features from the conversation transcripts and metadata features described in\nSection 3.1. To derive textual features, we employed natural language processing (NLP) techniques. We\nbuilt a sparse matrix by tokenizing the transcript of the conversations and filtering words that do not convey\ninformation (like \u201ca\u201d and \u201cthe\u201d) using the English stop words dictionary in scikit-learn (Pedregosa et al.\n2011). For each word in the sparse matrix, we computed its mutual information (Kraskov et al. 2004), which\nmeasures dependencies between attributes, to assess how much information each word contributes to the\nsilent-abandonment tag. (This results in a mutual information matrix.) To reduce dimensionality, we selected\nthe top 50 agent words and top 50 customer words with the highest dependency on the Sab tag according\nto the mutual information matrix. Each selected word was then represented by a variable indicating its\nfrequency of occurrence in the conversation.\nFor model development, we used a random subset of 550 conversations, reserving the remaining 100\nconversations for a final out-of-sample evaluation. The 550-conversation set was randomly divided into\ntraining and test sets, containing 75% and 25% of the conversations, respectively.\nLet \u03c0\u2081 denote the probability that customer i silently abandoned the queue, given that this conversation is\npart of the uSab group. Formally, \u03c0\u2081 = Pr{Sabi|uSabi}.\nWe examined the performance of several AI classification methods: logistic regression (stepwise backward\nand with a ridge penalty), support vector machines (SVM), k-nearest neighbors (k-NN), and classification"}, {"title": "3.3. Discussion: Reducing the Operational Impact of Silent-Abandonment Customers", "content": "We propose three strategies for companies to reduce the Sab-related capacity loss:\n1. Deploying bots to handle suspected Sab customers (e.g., over the 0.47 threshold in our SVM model).\n2. Modifying the concurrency algorithm to optimize agent workloads based on Sab likelihood.\n3. Adjusting prioritization for suspected Sab customers in the service queue.\nThese strategies rely on the company's ability to identify suspected Sab customers in real time, using\npredictions based solely on customers' in-queue attributes\u2014such as wait time, arrival time and day, customer\ndetails (e.g., returning customer), and the text of in-queue messages. A predictive model for this purpose\ncan be developed following the approach outlined in Section 3.2 (see Appendix EC.3 for initial results of\nsuch a model)."}, {"title": "4. Estimating Customer Patience with Silent Abandonment", "content": "So far, we have focused on identifying the Sab customers. However, Sab behavior also degrades data\nquality by creating missing information about abandonment times, rendering existing methods for estimating\ncustomer patience ineffective. Our next goal is to develop estimators for customer patience in contact\ncenters, addressing the dual challenges of the uncertain classification of uSab customers to Sr1 or Sab and"}, {"title": "4.1. The EM Algorithm: Model Assumption and Formulation", "content": "The problem of missing information on uSab customers stems from not knowing whether they received\none-exchange service (Sr1), in which case their patience would be right-censored, or they silently abandoned,\nin which case their patience would be left-censored. Nonetheless, we know that the time these customers\nwaited in the queue, and hence their virtual wait time, is uncensored.\nFollowing the formulation of Yefenof et al. (2022), let \u03c4 be customer-patience time (failure time) and\nassume it has a cumulative distribution function (CDF) F and a probability distribution function (PDF) f.\nAssume that T ~ exp(0). This assumption follows Brown et al. (2005), who showed using call-center data\n(with no delay announcements) that patience distribution has an exponential tail. Let W be the virtual wait\ntime (censoring time)\u2014the time the customer is required to wait by the system\u2014and assume it has a CDF\nG and a PDF g. We know from queueing theory that in overloaded systems, like the contact centers we"}, {"title": "4.1.1. Customer Classes with Complete Data.", "content": "In Table 2, we follow Yefenof et al. (2022) in formally\ndefining three customer classes under the assumption of complete data regarding which customers aban-\ndoned. The table identifies each customer class by type, notation indicator, formal definition of that indicator\n(based on values A and Y), what variable is observed in U, and what variable is censored by U and in what\ndirection."}, {"title": "4.1.2. Customer Classes with Missing Data.", "content": "Due to the problem of missing data on the uSab conver-\nsations, we are not able to categorize all the conversations into just one of the classes we defined in Section\n4.1.1. Therefore, we need to formulate additional class indicators. Let M denote the customer classes in a\nsystem in which there is missing data on which individual customers abandoned. These classes are defined\nin Table 3."}, {"title": "4.1.3. The EM Algorithm Formulation.", "content": "The EM algorithm estimates the following parameters simul-\ntaneously: the rate at which customers lose patience, 0; the probability of informing the system when\nabandoning, q; and the rate of the virtual wait time distribution, y. The optimization problem is defined\nto maximize the likelihood function, which measures the probability that the observations are given from\nthe assumed distributions given the parameters (0,q,y). We write the likelihood of the observed data\nD\u2252 {(U\u00a1, Yi, \u2206i), i = 1, ..., n} as follows:\n$$L(D;0, q, y) = \\prod_{i=1}^{n} {\\{e^{-\\theta U_i}ye^{-\\gamma U_i}\\}^{1-A_i} \\{\\q\\theta e^{-\\theta U_i}e^{-\\gamma U_i}\\}^{\\Upsilon_i\\Delta_i} \\{(1-q)\\int_{0}^{U_i} \\theta e^{-\\theta t} dt \\}ye^{-\\gamma U_i}\\}^{(1-\\Upsilon_i)\\Delta_i}}$$\n$$(2)$$\n\\noindent\\{\\e^{-\\theta U_i}ye^{-\\gamma U_i}\\}^{1-A_i} \\{\\q\\theta e^{-\\theta U_i}e^{-\\gamma U_i}\\}^{\\Upsilon_iX_i} \\{(1-q) (1 - e^{-\\theta U_i}) \\}ye^{-\\gamma U_i}\\}^{(1-\\Upsilon_i)\\Delta_i}.$$\nThe function is formulated following Yefenof et al. (2022): the first part is for the served customer (C\u2081 = 1),\nwhere we multiply the survival function of the customer patience (1 \u2013 Fr (u)) by the PDF of the customer's\nwait time. The second part is for the Kab customer (C) = 1), where we multiply the probability of informing\nwhen abandoning by the PDF of the customer patience and the survival function of the customer's wait time\n(1 \u2013 Gw (u)). Finally, the third part is for the Sab customer (C'= 1), where we multiply the probability of\nnot informing when abandoning by the CDF of the customer patience and the PDF of the customer's wait\ntime.\nHowever, this likelihood function depends on knowing the complete data. Recall that some of the obser-\nvations belong to the class M = 0 since they have missing data in A. Therefore, we cannot find the parameters\nby simply solving the maximization problem. Instead, we need to formulate an EM algorithm (see Algo-\nrithm 1), a well-known computing strategy for dealing with problems of missing data and censoring (Little\nand Rubin 2019). The algorithm estimates the parameters (0, q, y) using Theorems 1 and 2. Specifically, it\nestimates starting parameter values and subsequently iterates between the expectation step (E-step)\u2014using\nTheorem 1\u2014and the maximization step (M-step)\u2014using Theorem 2\u2014and updates these estimators until"}, {"title": "4.2. Validation of the EM Algorithm", "content": "We perform several performance evaluations to validate the use of our EM algorithm in practice. Due to space\nconstraints, most of the validation tests are described in Appendix EC.5. In Appendix EC.5.1, we compare\nthe accuracy of the EM algorithm to previous methods of estimating customer patience, Mandelbaum and\nZeltyn (2013) (Method 1) and Yefenof et al. (2022) (Method 2). These basic comparisons use simulated\ndata and demonstrate that our EM algorithm provides the most accurate estimation of all parameters (\u03b8, \u03b3,\nand q), regardless of the level of load in the system. Here, in Section 4.2.1, we validate the accuracy of\nthe EM estimators using real data, concluding that the EM algorithm is the only method that provides\nan accurate estimation of customer patience in reality. In Appendix EC.5.2, we examine the algorithm's\nsensitivity under the initial conditions. We show that the parameter estimations are stable and do not change\nwhen different initial values are inserted in the EM algorithm. This suggests that one does not need to use\nthe output of the classification model we developed in Section 3.2 (or any model with similar sensitivity and\nspecificity proportions) as starting probabilities in the EM algorithm. (In all tests throughout this paper, we\nset \u20ac = 10-6.)"}, {"title": "4.2.1. Estimating Patience in the XYZ Dataset: Accuracy and Robustness Tests.", "content": "Using the XYZ\ncontact-center dataset described in Section 3, we compare the EM algorithm to four benchmark methods for\nestimating customer patience. The results are presented in Table 4."}, {"title": "5. The Influence of System Design on Customer Behavior and Silent Abandonment", "content": "Referring back to Figure 1, we note that the ambiguity surrounding uSab customers could be resolved by\nrestricting the ability to write while waiting. Under such a policy, the Sr1 customer class would no longer\nexist, as single-interaction services require customers to communicate their issues explicitly. However, the\nSab customer class remains well-defined: customers who abandon the system without a clear indication of\ndoing so would still be categorized as Sab (even when not writing their inquiry).\nIndeed, contact-center infrastructure allows for such restrictions, and some companies opt to implement\nthem. This approach simplifies the analysis of performance measures, eliminates the need for sophisticated\nclassification models, and enables identification of Sab customers based solely on metadata.\nHowever, this raises critical questions: What are the benefits of allowing customers to write while waiting?\nShould companies adopt such restrictions?"}, {"title": "5.1. The Extended EM Algorithm", "content": "Let the patience parameter @ be influenced by k variables denoted by X = [X1, ..., Xk], such that\n$$\\theta | X \\propto e^{-(\\beta_0+\\beta_1 X_1 + ... + \\beta_k X_k)} = e^{-(\\beta_0 + \\beta^T X)}.$$\n$$(7)$$"}, {"title": "5.2. Estimating the Associations of Patience with System Design and Customer Behavior", "content": "We implement the extended EM model to the XYZ database in order to investigate the association between\ncustomer patience and their in-queue behavior. Our main variable of interest is the number of words the\ncustomer types while waiting in the queue. To address the variations in word counts and reduce the influence\nof extreme cases, we categorized this variable in two ways:\n1. Binary variable: Named # Words in Queue: Binary, this variable is defined as \u201c0\u201d if the customer\nwrote up to one word while waiting and \u201c1\u201d otherwise (i.e., for two or more words)."}, {"title": "5.3. Discussion: Enhancing Customer Satisfaction and Reducing Abandonment", "content": "Enhancing customer satisfaction begins with ensuring service is initiated before customers reach the limit of\ntheir patience. To achieve this, we propose two complementary strategies: (1) increasing the time customers"}, {"title": "6. Conclusion", "content": "In this article, we identified and defined the phenomenon of silent abandonment as an important source\nof uncertainty in contact centers. We laid the groundwork for identifying silent abandonment in contact\ncenters by training classification models incorporating text analysis of customer and agent messages, utilizing\nfeatures derived from NLP techniques. Silent abandonment appears to be widespread in the industry, with\n22% of an average company conversations classified as uncertain silent abandonment based on their metadata.\nDetailed analysis of the XYZ dataset revealed that 12.6% of all conversations (or 51.8% of uSab cases) are\nindeed instances of silent abandonment, effectively tripling the rate of abandonment previously considered\nin the company's performance metrics. Additionally, we demonstrated that silent abandonment increases\nagent workload and customer delays. These findings underscore the necessity of revising performance\nmeasurement calculations and operational methods to account for silent abandonment. Future improvements\nto these classification models could involve fine-tuning a large language model (LLM), such as BERT\n(Devlin et al. 2019).\nWe analyzed the implications of silent abandonment on customer-patience estimation and demonstrated\nthe necessity of treating silent abandonment as uncertain left-censored observations to achieve accurate\nestimates. Using an EM algorithm, we estimated customer patience in the XYZ contact center to be 81.1"}]}