{"title": "Evaluating the Posterior Sampling Ability of Plug&Play Diffusion Methods in Sparse-View CT", "authors": ["Liam Moroy", "Guillaume Bourmaud", "Fr\u00e9d\u00e9ric Champagnat", "Jean-Fran\u00e7ois Giovannelli"], "abstract": "Plug&Play (PnP) diffusion models are state-of-the-art methods in computed tomography (CT) reconstruction. Such methods usually consider applications where the sinogram contains a sufficient amount of information for the posterior distribution to be peaked, and consequently are evaluated using image-to-image metrics such as PSNR/SSIM. Instead, we are interested in reconstructing compressible flow images from sinograms having a small number of projections, which results in a posterior distribution no longer peaked or even multimodal. Thus, in this paper, we aim at evaluating the approximate posterior of PnP diffusion models and introduce two posterior evaluation criteria. We quantitatively evaluate three PnP diffusion methods on three different datasets for several numbers of projections. We surprisingly find that, for each method, the approximate posterior deviates from the true posterior when the number of projections decreases.", "sections": [{"title": "Introduction", "content": "Diffusion models learn the prior of an underlying data distribution, which allows to generate new samples [1-6]. Plug&Play (PnP) diffusion models [4, 7-13] employ such prior-encoding models to solve inverse problems. In this paper, we focus on the Sparse-View Computed Tomography (SVCT) [14] measurement model :\n\nyp = Hpx + \u0454,\n\nwhere yp \u2208 Rmp is the measured sinogram with p projections, Hp is a discretized Radon transform matrix of size mp \u00d7 n corresponding to a parallel beam setting, x \u2208 Rn is the image and \u2208 ~ N(0, 1) is the measurement noise. At test time, only yp, Hp, o and the prior-encoding diffusion model are known. In practice, Hp and of depend on the tomograph settings. For this reason, we focus on PnP diffusion models that avoid any extra learning stage specific to the measurement model and/or its parameters, as opposed to conditional diffusion models [15-17].\nThe vast majority of PnP diffusion models for SVCT [9, 10, 18-20] consider applications where the measured sinogram contains a sufficient amount of information for the posterior distribution p(xyp) to be relatively peaked (see Fig. 1). In this case, a point estimation of x is sufficient and image-to-image metrics such as PSNR/SSIM [21] may be employed to evaluate the performances of a given approach. Instead, this paper is motivated by the reconstruction of compressible flow images from measured sinograms having a small number of projections, whether for limited optical access or complexity of the setup, as it is the case of digital holographic interferometry [22], where p = 6. In this context, the posterior distribution p(x|yp) is no longer peaked and may even be multimodal (see Fig. 1). In this case, a point estimation of x is no longer sufficient, and being able to sample the true posterior distribution p(x|yp) is fundamental. PnP diffusion methods are approximate posterior samplers. However, to the best of our knowledge, their ability to sample the true posterior, in SVCT, has not been evaluated as of yet."}, {"title": "Related work", "content": "This work focuses on evaluating the posterior sampling ability of different PnP diffusion methods on SVCT when the posterior is not peaked or even multimodal.\nState-of-the-art SVCT methods [9\u201311, 18, 19, 23-25] are essentially developed and evaluated to deal with cases where the posterior is peaked, which often corresponds to a large number of projections. Let us highlight that the term Ultra Sparse-View CT (USVCT) [18,19,26,27] has emerged to perform CT reconstruction from highly sparse sinograms. However, these works are still limited to sinograms with at least 10 projections, a regime where the posterior is, in the considered applications, still peaked. To the best of our knowledge, this paper is the first attempt to evaluate PnP diffusion methods where the measured sinogram does not contain sufficient information for the posterior distribution to be peaked (see Fig.1).\nAll of the above methods report their results in terms of PSNR and/or SSIM [21]. As these metrics focus on image-to-image comparisons, an actual true posterior sample may obtain a low score when the posterior is not peaked. Thus they are not well suited to evaluate the ability of a given method to sample the true posterior. On some other inverse problems, e.g. inpainting [11, 12, 28], super- resolution [12, 15], generative metrics such as Fr\u00e9chet Inception Distance (FID) [29] and Kernel Inception Distance (KID) [30] are used to evaluate the distribution of reconstructed samples. To the best of our knowledge, such generative metrics have not yet been employed in SVCT and this paper is the first attempt to do so."}, {"title": "Background", "content": "Diffusion models [2-4, 6] aim at sampling from a prior distribution po, by defining a generative process that gradually transforms a sample from a known distribution pr into a sample from po. To do so, the following reverse-time It\u00f4 Stochastic Differential Equation (SDE) [4] is solved:\n\ndx = [f(x, t) - g\u00b2(t)\u2207x log pt(x)] dt + g(t)dw,\n\nwhere f(x, t) is the drift function, g(t) is the diffusion coefficient, w is the standard Wiener process flowing backward in time, and pt is a perturbed version of the prior distribution po: pt(x') =\nfpt(x'|x)po(x)dx (with pt(x'|x) being the perturbation kernel). Throughout the paper, we consider the variance-exploding (VE) SDE settings\u00b9. In practice, the time-dependent prior score function Vx log pt (x) is approximated by a neural network se(x, t) trained over a set of K example images {x(k)}=1 using Denoising Score-Matching [31]. In the rest of the paper, we will refer to se as the time-dependent prior score network. Thus, to (approximately) sample from po, the reverse-time SDE Eq. (2) is simulated with se(x, t) instead of \u2207x log pt (x).\nPnP diffusion models [10-12] aim at sampling from the posterior distribution po(x|y) while avoiding any extra learning stage specific to the measurement model and/or its parameters by leveraging a prior-encoding denoiser represented by the score network se. To do so, the following reverse-time SDE is employed:\n\ndx = [f(x, t) - g\u00b2(t)\u2207x log pt(x|y)] dt + g(t)dw,\n\nand the time-dependent posterior score function is decomposed as follows:\n\nVx log pt (xy) = \u221ax log pt(x) + \u221ax log pt (y|x),\n\n\u2248 Se(xt,t) +x log pt (y x).\n\nBecause of its dependence w.r.t. t, \u2207x log pt (y|x) is not tractable. To circumvent this problem, [10, 32] applies projections onto the measurement subset, [9, 19, 33] solve an optimization problem and [10-12] propose analytical approximations. From this point of view, PnP diffusion methods are \"approximately\" true posterior samplers. In this paper, we focus on evaluating how good these approximations are, on SVCT, and consider three state-of-the-art methods MCG [10], DPS [11], and IG [12]. Their analytical approximations of \u2207x log pt (y|x) are summarized in Tab. 1.\nIt is worth noting that, in the inverse problem literature, several methods [12, 34] are referred to as problem agnostic since the inversion relies on a network whose training is independent of the observation model. These problem agnostic methods are distinct from so-called agnostic methods [35], which train a network to directly map the observations yp to their ground truth x; in this context, agnostic means that the observation model is not explicitly defined but implicitly represented by the pairs (yp, x)."}, {"title": "Posterior evaluation criteria", "content": "In this section, we introduce two simple criteria that will allow us to compare the approximate posterior, i.e. samples from a PnP diffusion method, to the true unknown posterior.\n\u00b9VE-SDE settings: f(x, t) = 0, g\u00b2(t) = r\u00b2(t), pt(x'|x) = N(x, \u03c3\u00b2 (t)I) and o(t) = \u03c3min(\u03c3max/\u03c3min)t"}, {"title": "Experiments", "content": "We consider three datasets:\n1 - The JET 2 dataset [22] contains 5896 compressible flow images of size 260 \u00d7 260 (see Fig. 1). These images are cross-sections of hot air (compressible flow density) expelled by a nozzle and impacting a wall at a given distance [38].\n2 - The Low Dose CT grand challenge 2016 (LDCT) [39] contains 5936 CT images of size 512 \u00d7 512 from 10 patients. We use the 1mm thick scans. The scans are acquired with the same scanner and hyperparameters.\n3 - The Lung Image Database Consortium (LIDC) dataset [40,41] contains 239472 CT images of size 512x 512 from 1018 patients. Unlike LDCT scans, LIDC scans are acquired with different scanners and different hyperparameters (e.g. thickness, tube peak potential energies, tube current range, etc.). In the following experiments, all the images are resized to 128 \u00d7 128 and normalized between [0, 1]. Sinograms are obtained using the torch-Radon library [42]. The noise level added to sinograms is\n2The dataset will be made available."}, {"title": "Prior score network", "content": "For each dataset we train a time-dependent prior score network se. We use a ncsnpp architecture, i.e. a Unet augmented with attention, in VE-SDE continuous settings with \u03c3min = 0.01 and \u03c3max = 1348 similarly to the Pytorch implementation of [4]. The same model is shared between the different PnP diffusion methods to ensure comparable results. On the JET dataset, the images are augmented with random horizontal and vertical flips and random rotation. We trained so on a single NVIDIA TITAN V 12Go, using Adam optimizer with a learning rate of 10-4."}, {"title": "Technical details on PnP diffusion methods", "content": "We consider three state-of-the-art PnP diffusion methods: MCG [10], DPS [11] and IIG [12]. They essentially differ in the respective approximations of \u2207x\u2081 log pt (yp|xt) (see Tab. 1). MCG and DPS have handcrafted weights a(xt, yp) originally defined as aMCG(xt, yp) = 0.1/||H(yp\n- Hpx0(xt))||2 and apps (xt, yp) = 1/||yp - Hpx0(xt)||2. We found these values to be non-optimal and fine-tuned them on each dataset for each value of p. IIG proposes time-dependent weights:\nrt = \u221a\u03c3?/\u03c3? +1 with ot the diffusion noise, we did not modify this scheme. To fairly compare the three methods, in all the experiments, we use the same accelerated ancestral sampler [12, 43] with 100 noise scales with omin = 0.01 and omax = 1348.\nTo improve the numerical stability of MCG and DPS, we implemented the gradient of the time- dependent likelihood term with its closed-form expression (see Tab. 1)."}, {"title": "Quantitative evaluation", "content": "We aim at evaluating the approximate posterior of each PnP diffusion method [10-12] as a function of the number of projections p (in the experiments p = 1,3, 6, 12, 18, 30, 90, 180). To do so, for each dataset, we proceed as follows. We unconditionally sample a set X of 50k images using the time-dependent prior score network se, as explained in Sec. 4. From X, for each value of p, we compute a set of 50k p-projections sinograms, Up, using the SVCT measurement model Eq. (1). Then for each method m \u2208 [10-12], we compute a set of 50k posterior samples, Xp,m, using sinograms of Yp as conditions. To evaluate Eq. (6) we compute the FID [29] and the CMMD [36] between X and Xp,m. To evaluate Eq. (7), we compute the NMC (see Sec. 4) between Yp and Xp,m. We also compute the average PSNR between X and X p,m. Due to the limit of space, we did not include the SSIM, as it follows the same behaviour as the PSNR. The evaluation results are summarized in Tab. 2. Let us highlight that to compute \u2207x\u2081 log Pt (yp|xt), IIG needs to solve a linear system whose size increases with p (see Tab. 1), thus we could only compute the metrics for p = {1, 3, 6, 12, 18}. In theory MCG needs to perform a similar operation (pseudo-inverse), but in practice, as suggested in [10], we use a Filtered Back-Projection [14] (FBP), that significantly speeds-up the sampling.\nOne can see the average PSNR of each method is monotonically increasing with p. This is expected since p controls the amount of information contained in sinograms.\nResults of MCG - The NMC is close to 1 which indicates conditioning sinograms were correctly taken into account during sampling. However, the FID and the CMMD significantly increase when p decreases. This dependency on p is unexpected and shows that MCG's approximate posterior deviates from the true posterior when p decreases.\nResults of DPS - The NMC is close to 1 which indicates conditioning sinograms were correctly taken into account during sampling. The FID and the CMMD are low and only slightly increase when p decreases (except for p = 1). These findings tend to show DPS's posterior is close to the true posterior, even for a low number of projections (except in the extreme case p = 1).\nResults of IG - The FID and the CMMD are very low, but the NMC is quite high and far from 1. This shows IIG does not take correctly into account the conditioning sinogram but produces samples almost indistinguishable from prior samples. This behaviour may be explained by IIG's dynamic weighing scheme rt (see Sec. 5.3) which does not correctly balance the two terms of Eq. (5).\nThis quantitative evaluation shows that DPS's approximate posterior is much closer to the true posterior than the approximate posteriors of MCG and IG. This finding is unexpected as DPS employs a simpler and faster approximation of \u2207 x\u2081 log pt (yp|xt) than MCG and IIG."}, {"title": "Conclusion", "content": "In this work, we introduced two posterior evaluation criteria to assess the approximate posterior of a PnP diffusion method. To the best of our knowledge, this is the first attempt to evaluate SVCT posteriors with generative metrics, and in a non-peaked regime. This lead to a thorough quantitative evaluation of three state-of-the-art methods on three different datasets. Our findings surprisingly show that the approximate posterior tends to deviate from the true posterior when the number of projections decreases. Moreover, the best posterior approximation is obtained by the simplest and fastest method DPS. These findings would not have been possible using traditional image-to-image metrics like PSNR and SSIM."}]}