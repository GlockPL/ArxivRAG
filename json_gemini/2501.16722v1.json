{"title": "Hypergraph Diffusion for High-Order Recommender Systems", "authors": ["Darnbi Sakong", "Thanh Trung Huynh", "Jun Jo"], "abstract": "Recommender systems rely on Collaborative Filtering (CF) to predict user preferences by leveraging patterns in historical user-item interactions. While traditional CF methods primarily focus on learning compact vector embeddings for users and items, graph neural network (GNN)-based approaches have emerged as a powerful alternative, utilizing the structure of user-item interaction graphs to enhance recommendation accuracy. However, existing GNN-based models, such as LightGCN and UltraGCN, often struggle with two major limitations: an inability to fully account for heterophilic interactions, where users engage with diverse item categories, and the over-smoothing problem in multi-layer GNNs, which hinders their ability to model complex, high-order relationships. To address these gaps, we introduce WaveHDNN, an innovative wavelet-enhanced hypergraph diffusion framework. WaveHDNN integrates a Heterophily-aware Collaborative Encoder, designed to capture user-item interactions across diverse categories, with a Multi-scale Group-wise Structure Encoder, which leverages wavelet transforms to effectively model localized graph structures. Additionally, cross-view contrastive learning is employed to maintain robust and consistent representations. Experiments on benchmark datasets validate the efficacy of WaveHDNN, demonstrating its superior ability to capture both heterophilic and localized structural information, leading to improved recommendation performance.", "sections": [{"title": "1. Introduction", "content": "Collaborative Filtering (CF) is a task of identifying or ranking unobserved items that users would like to engage in based on the behaviors and preference records of similar users. Various applications such as social network services [1], streaming platform [2], and retail websites [3] adopt CF to support efficient user decision processes over the excessive quantity of information. By scoring preferences on items based on learning the low-dimensional vector representations of users and items based on the user-item interaction history, conventional CF techniques [4] have gained significant attention from the community due to their effectiveness.\nWith the emergence of graph neural networks(GNNs), recent research has started to project representations by harnessing the topological structures inherent in user-item interaction data to capture graph-based collaborative signals. For instance, LightGCN [5] and UltraGCN [6] introduce simplified graph convolutional networks(GCNs) to tailor general GCNs to recommendation tasks. To further enrich the expressiveness of embeddings, hypergraphs have been introduced in the CF paradigm by its capability to model group-wise relationships between users and items. Unlike ordinary binary graphs, any number of users that have shown their interest in a specific item i are connected with corresponding hyperedge reflecting their multi-way interactions. One of the representative hypergraph-based CF methods, HCCF [7], proposed a self-supervised learning approach to contrast between local and global embeddings to enhance the generalization ability of the model. Despite the advancement of GNN-based methods, existing literature often overlooks heterophilic patterns which are often observed in user-item interaction data. In most practical scenarios, items that one specific user has engaged with are in different categories. To estimate the similarity between item representations, embeddings of items in similar or identical categories are expected to be in proximity, while those in different categories are expected to be far apart. Moreover, capturing high-order multi-hop neighborhood structures is important for learning accurate representations. However, widely adopted stacked multi-layers of HGCN in the existing models often suffer from smoothing problems where embeddings become indistinguishable. To mitigate this, a more nuanced approach is required to naturally balance local and global relationships without stacking layers while considering heterogeneity patterns in interaction graphs [8, 9, 10, 11, 12].\nTo overcome the aforementioned challenges, we introduce a wavelet-based hypergraph diffusion framework for modeling localized structure-aware heterophilic user-item group-wise dependency. More specifically, we fuse two separated channels: Heterophily-aware Collaborative Encoder for heterophilic pattern modeling and Multi-scale Group-wise Structure Encoder for localized structure modeling. In summary, the key contributions of this work are organized as below:\n\u2022 In this work, we propose a wavelet-based hypergraph diffusion model called WaveHDNN to capture both heterophilic patterns and localized topological information via simultaneous learning on two separated encoders."}, {"title": "2. Related Works", "content": "Conventional Collaborative Filtering Methods. Collaborative filtering (CF) is a popular technique in recommender systems, predicting user preferences based on historical user-item interactions [15, 16, 17, 18, 19, 20, 21]. CF methods are categorized into memory-based and model-based approaches. Memory-based methods, like User-Based and Item-Based CF, use similarity measures such as cosine similarity or Pearson correlation [22, 23]. While simple and intuitive, they struggle with scalability and data sparsity in large datasets [24]. Model-based methods, such as Matrix Factorization (MF), project users and items into a shared latent space, offering scalable solutions. BiasMF [25] adds bias terms for users and items, improving on standard MF by capturing individual characteristics. Singular Value Decomposition (SVD) [25] decomposes the user-item interaction matrix into latent factors, and SVD++ [26] incorporates implicit feedback like clicks or views. Non-Negative Matrix Factorization [27] imposes non-negativity constraints, ensuring interpretable, positive representations. To capture non-linear user-item relationships, Neural Collaborative Filtering (NCF) [28] replaces MF's inner product with a neural network, allowing for complex interactions through multi-layer transformations. However, MF and NCF treat user preferences as static, which limits their effectiveness in dynamic environments. Sequence-based models like Recurrent Neural Networks [29] and Transformer-based models [30] address this by modeling the sequential nature of user interactions, accounting for evolving preferences. Despite the rise of complex models, BiasMF and NCF remain foundational techniques in CF, balancing performance and interpretability while often serving as the basis for advanced hybrid models [31, 32, 10, 33, 34].\nGNN-based Collaborative Filtering Methods. Graph structures are widely used to capture user preferences, representing users and interacted items as nodes connected by edges [35, 36, 37, 38]. Conventional methods like Item-Rank [39] assign weights based on random walks, while SimRank [40] computes item-user similarity using common neighbors. More recently, Graph Neural Networks (GNNs) have enhanced Collaborative Filtering (CF) by effectively capturing user-item interactions. NGCF [41] extends GCNs by deepening the propagation process in the user-item graph, and AGCN [42] uses attention mechanisms to emphasize node relatedness. LightGCN [5] simplifies GCNs by focusing on embedding propagation, while UltraGCN [6] further simplifies the model for efficiency. PinSage [43] combines random walks and graph convolutions for large-scale recommendation systems. To address common GNN challenges like over-smoothing, GraphRec [44] introduces attention to focus on important neighbors, and Star-GCN [45] uses a graph auto-encoder for unseen users and items. GCCF [46] incorporates residual networks to mitigate over-smoothing. Despite these advancements, existing models often overlook heterogeneity and higher-order connectivity in user-item graphs. Our proposed model addresses these challenges by using a novel message-passing algorithm to capture high-order relationships [47, 35, 36, 48, 49, 38, 50].\nHGCN-based Collaborative Filtering Methods. Beyond binary user-item connections, group-level relationships often provide valuable high-order information. A hypergraph, where multiple nodes are connected via hyperedges, captures such relationships and has proven effective in offering rich structural insights. Hypergraph Convolutional Networks (HGCNs) [51] extend Graph Neural Networks (GNNs) for Collaborative Filtering (CF), addressing the limitations of traditional graphs by capturing more complex relationships. Building on HGCNs, DHCF [52] employs a divide-and-conquer strategy to learn user and item embeddings simultaneously, while HCCF [7] introduces self-supervised learning with contrastive learning to align global and local embeddings. SHT [53] leverages a hypergraph transformer to incorporate multi-scale neighborhood features, while HypAR [54] provides explainable recommendations using HGCN layers. UPRTH [55] utilizes task-specific hypergraphs with transitional attention, and MHCN [56] enhances social recommendation by capturing high-order user relations via a multi-channel HGCN. Despite these advances, further improvements are possible. Our model propagates permutation equivariant messages through HGCN layers, making embeddings more distinguishable. Additionally, wavelet-transform-inspired"}, {"title": "3. Methodology", "content": "In this section, we introduce our proposed end-to-end framework, namely WaveHDNN, which consists of two individual channels to learn high-order dependencies. First, we capture the heterophilic pattern inherent in collaborative hypergraphs based on the heterophily-aware hypergraph diffusion channel. Second, we leverage the channel based on the wavelet-based hypergraph neural networks to capture the user-item group structural relationship at different local and global scales. We further ensure consistency between the two-faceted representations of users and items through contrastive learning and integrate the final representations to predict user preferences.\n3.  1. Heterophily-aware Collaborative Encoding\nBuilding on the principles of ED-HNN [13], we begin by learning user and item representations through the modeling of heterophilic patterns within collaborative hypergraphs. It is important to note that different types or categories of items are often grouped by specific users, a phenomenon commonly observed in user-item collaborative hypergraphs. To differentiate between items while preserving the common features within the same categories, we propose a novel approach that captures heterogeneity by leveraging Heterophily-aware Hypergraph Diffusion Networks layers. First, we transform the embeddings of users (or items) leveraging a multi-layer perceptron (MLP). By applying MLP before gathering the node features, we enable the model to adapt to complex patterns in data rather than relying on fixed or predefined parameters, which may not generalize well to non-homophilic scenarios. Then the transformed embeddings are fed into the hypergraph convolution layer (HGCN) to aggregate node features. The learned node features are then concatenated with the initial node embeddings to guarantee an equivariant operator so as to pass varying messages to nodes in\n$X^{(1)}_{e} = LN(HConv(MLP_1(X), H)) + X,$\n$X^{(2)}_{u} = LN(HConv(MLP_2(X^{(1)}_{e}), H)) + X^{(1)}_{e}$\nwhere X is embeddings of user and items, $X_{e}$ denotes hyperedge embeddings, $X_{u}$ denotes node embeddings, H is incidence matrix, $MLP_1(\u00b7)$, $MLP_2(\u00b7)$ indicates MLPs, HConv(\u00b7) denotes hypergraph convolution layer, and LN(\u00b7) represents Layer Normalization [63]. The learned node embeddings are then further integrated with their original features to prevent information dilution. Finally, we apply the final MLP to update embeddings.\n3.  2. Multi-scale Group-wise Structure Encoding\nFollowing the localized hypergraph neural network proposed in [14], we propose a wavelet-based multi-scale group-wise relationship aware encoder to capture varied scales of neighborhood structure while preserving heterogeneity in hypergraphs. Wavelet basis enables localized convolution on the vertex domain, meaning that the convolution operation can focus on specific regions of the hypergraph rather than considering the entire graph structure. This is particularly important for hypergraphs where different types of hyperedges exist, and a localized approach can effectively capture the heterogeneity of the data while encapsulating the topological information into embeddings. The wavelet-based hypergraph convolution layer can be expressed as below.\n$X^{(l+1)} = \\Theta \\Lambda \\Theta' X^{(l)} W + X^{(l)}$\nwhere X denotes feature, $\\Lambda$ denotes diagonal weight filter matrix, $\\Theta$ and $\\Theta'$ denote wavelet and its inversed version, and W denotes weight matrix for feature transformation. Unlike wavelet HGCN in [14], we concatenate the current embedding of nodes with its newly learned representations in the layer to avoid signal degradation through multiple layers.\n3.  3. Optimization\nThe two separated channels capture different aspects of user behaviors and keeping the embeddings of the identical users and items learned from each encoder close ensures that diverse perspectives reflect a unified representation. This allows the model to form a consistent and coherent comprehension of user preferences. Besides, if the embeddings from different modules are far apart, it may indicate the features captured by each module are redundant or even conflicting information. To preserve the unique contribution of each encoder, embeddings need to be close in proximity within the vector space. Hence, we adopt a cross-view contrastive learning mechanism under the assumption that the embeddings of corresponding users (or"}, {"title": "4. Evaluation", "content": "In this section, we evaluate the effectiveness of WaveHDNN against selected state-of-the-art baselines. We first describe the experimental setting and then present empirical performance comparison on different datasets. To rationalize the design of the architecture of the model, we conduct an ablation test by replacing each key component of the model.\n4.  1. Experimental Setting\nFor the fairness of the comparison, we perform evaluations on three different real-world datasets: Amazon-books for book recommendations, Steam for game recommendations, and Yelp for business recommendations. The comprehensive statistics of datasets are presented. The varying levels of density in real-world interactions within the selected datasets highlight the robustness of our model across different practical conditions. We divided each dataset into training, validation, and test sets following the 7:1:2 ratio and used an average of 5 times running as the final performance of each model.\n4.  2. Base Models\nWe assess the effectiveness of our WaveHDNN with 5 state-of-the-art baselines that cover GNN-based and Hypergraph-based Recommendation tasks.\n\u2022 LightGCN eliminates the redundant components by preserving only the neighborhood message passing component from NGCF for CF-oriented representation learning.\n\u2022 SGL enhances the LighGCN framework with an augmentation mechanism and self-supervised contrastive learning.\n\u2022 DHCF introduces a divided-and-conquer method with dual-channel hypergraph neural networks to enable disjoined and simultaneous learning of user and item embeddings.\n\u2022 HCCF encodes local and global views of user-item hypergraphs with contrastive learning to learn distinguishable user and item representations.\n\u2022 SHT adopts transformer mechanism and applies hypergraph attention strategy. The model further presents a data augmentation approach by complementing different scopes of view of CF signals.\n\u2022 AutoCF designs automatic data augmentation with generative self-supervised learning to automatically extract significant self-supervised features.\n4.  3. Performance Comparison\nThis section provides a comprehensive analysis of the performance results of all baseline models on three datasets and summarize the comparison between them.\nOverall Comparison. As shown, our proposed WaveHDNN model consistently outperforms all baselines across six evaluation metrics, demonstrating its robustness in various scenarios. Notably, WaveHDNN surpasses the second-best model by 7.24% on the Steam dataset in terms of NDCG@20, a key metric for ranking item relevance within the top 20 recommendations. In sparse datasets like Amazon-books and Yelp, with fewer user-item interactions, WaveHDNN shows significant improvements of 3.92% and 5.45% over the second-best models. These gains emphasize the model's adaptability, even in challenging environments.\nWaveHDNN's superior performance can be attributed to key factors: 1) Learning distinguishable representations through equivariant operator-based hypergraph convolution networks while preserving local and global neighborhood messages. 2) Incorporating different scales of localized features via a combination of hypergraph convolution and wavelet-based hypergraph transform layers for more expressive feature learning. These advantages highlight WaveHDNN's versatility and its ability to adapt to varying\n$L_{CL}^{(i)} = \\sum_{i=0}^I \\sum_{l=0}^L \\sum_{i'=0}^{I} -log(\\frac{exp(s(z_{i,l}, z'_{i,l})/T)}{\\sum_{k=0}^{I'}exp(s(z_{i,l}, z'_{i'l})/T)})$,\n$L_{BPR} = \\sum_{U \\in U} \\sum_{i \\in Z_u} \\sum_{i'\\notin I_u} -log \\sigma (\\hat{y}_{u,i} - \\hat{y}_{u,i'})$\nwhere U denotes a set of users, $i \\in Z_u$ denotes interacted items while $i' \\notin I_u$ denotes items that interaction with user has not been observed. $\\hat{y}$ is the probability that user u might be inclined to engage with item i, which is computed by the dot product between user and item embeddings."}, {"title": "4.4. Ablation Test", "content": "In this section, we evaluate the importance of the main components of our WaveHDNN. To this end, we replace or remove each component to build variation models to showcase how much performance improvement is observed with the proposed components. Results are presented.\nHeterophily-aware Collaborative Encoder. We investigate the impact of integrating a Heterophily-aware Collaborative Encoder on the performance of learning CF-oriented embeddings for users and items. Specifically, we examine how considering heterophily can enhance the model's representational power in CF. To validate this, we design a variant of the WaveHDNN model without the heterophily-aware encoder, isolating its contribution. Our results reveal a noticeable performance gap, demonstrating the encoder's effectiveness in learning embeddings within a heterophiluaware framework. The key improvement comes from the diverse messages passed through the model's learnable message-passing algorithm, which operates in the HGCN-based diffusion layers. These layers help prevent over-smoothing by retaining diverse user-item representations, resulting in more accurate predictions and improved performance.\nMulti-scale Group-wise Structure Encoder. We aim to analyze the role of the Wavelet-based Hypergraph Convolutional Network (HGCN) layer, focusing on its ability to capture multi-scale group-wise structures within a graph. To assess its impact, we build a model variant without the Multi-scale Group-wise Structure Encoder. Experimental results show a significant performance drop when this mechanism is removed, as the model fails to capture complex relationships across neighborhood scales. This degradation underscores the importance of preserving multi-scale structural nuances in the user-item interaction graph. The observed performance decline is linked to the absence of multi-scale aggregation, which is crucial for retaining important feature information. Without this, features from neighboring nodes are overly smoothed or lose significance through message passing layers. In contrast, the Wavelet-based HGCN layer uses varying scaling parameters to integrate information across different levels of granularity, preserving both local and global structures. This helps capture subtle neighborhood interactions, which improves predictive performance and generalization. The multi-scale aggregation also prevents over-smoothing, enriching the learned representations and enhancing accuracy in collaborative filtering predictions."}, {"title": "4.5. Hyper-parameter Studies", "content": "In this section, we analyze the degree of sensitivity of our model on various hyperparameter settings. mong the standard hyperparameters, we focus on the number of HGCN layers and the embedding dimension, as these parameters significantly impact performance variations.\nEffect of number of HGCN layers.. We run our model with various number of HGCN layers to evaluate the influence of the layer depth. We can observe that the different number of HGCN layers of each channel has a high impact on recommendation accuracy. We have conducted experiments on three different datasets and the number of layers selected from [1,2,3,4,5]. The results indicate that increasing the number of layers does not necessarily lead to improved performance. The best performance was observed when the number of layers was set to 3, while performance degraded as the layers increased beyond this point. This phenomenon is attributed to overly distinguishable learned representations resulting from the use of a broader neighborhood scope.\nEffect of embedding dimensions. We have conducted experiment on three different datsets by changing the embedding dimension from [8,16,64,32,128] to check the influence of different embedding sizes. We shows that varying the embedding size does not always guarantee improved accuracy. Contrary to expectations, the performance improvement was not significant as the embedding size increased. If the embedding size is too large, the important information might get diluted across many dimensions. This can make the model struggle to learn meaningful representations, as the critical data may be spread out excessively thinly. Besides, as the embedding size becomes excessively large, the memory and computational time requirements increase, leading to inefficient learning."}, {"title": "5. Conclusion", "content": "In this work, we addressed key limitations in existing Collaborative Filtering (CF) models, particularly those based on Graph Neural Networks (GNNs), which often fail to account for heterophilic patterns and suffer from oversmoothing issues. To tackle these challenges, we proposed a novel wavelet-based hypergraph diffusion model, WaveHDNN, which captures both heterophilic patterns and localized topological information. Our model incorporates two main components: the Heterophily-aware Collaborative Encoder, designed to differentiate message passing for heterogeneous nodes, and the Multi-scale Group-wise Structure Encoder, which leverages wavelet transforms to flexibly tune the spread of information across the hyper-"}]}