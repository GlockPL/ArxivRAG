{"title": "scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers", "authors": ["Dian Meng", "Bohao Xing", "Xinlei Huang", "Yanran Liu", "Yijun Zhou", "Yongjun xiao", "Zitong Yu", "Xubin Zheng"], "abstract": "Single-cell multi-omics (scMulti-omics) refers to the paired multimodal data, such as Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq), where the regulation of each cell was measured from different modalities, i.e. genes and proteins. scMulti-omics can reveal heterogeneity inside tumors and understand the distinct genetic properties of diverse cell types, which is crucial to targeted therapy. Currently, deep learning methods based on attention structures in the bioinformatics area face two challenges. The first challenge is the vast number of genes in a single cell. Traditional attention-based modules struggled to effectively leverage all gene information due to their limited capacity for long-context learning and high-complexity computing. The second challenge is that genes in the human genome are ordered and influence each other's expression. Most of the methods ignored this sequential information. The recently introduced Test-Time Training (TTT) layer is a novel sequence modeling approach, particularly suitable for handling long contexts like genomics data because TTT layer is a linear complexity sequence modeling structure and is better suited to data with sequential relationships. In this paper, we propose scFusionTTT, a novel method for Single-Cell multimodal omics Fusion with TTT-based masked autoencoder. Of note, we combine the order information of genes and proteins in the human genome with the TTT layer, fuse multimodal omics, and enhance unimodal omics analysis. Finally, the model employs a three-stage training strategy, which yielded the best performance across most metrics in four multimodal omics datasets and four unimodal omics datasets, demonstrating the superior performance of our model. The dataset and code will be available on https://github.com/DM0815/scFusionTTT.", "sections": [{"title": "Introduction", "content": "Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq) (Stoeckius et al. 2017) is a technology that can measure transcriptomics and proteomics in individual cells simultaneously. The joint analysis of transcriptomics and proteomics can strengthen critical genetic information from multiple omics and unravel cellular processes.\nAlthough fusing scMulti-omics data can help researchers explore complex biological information, the intrinsic properties of single-cell data, such as high sparsity, noise, and dimensionality mismatch, pose significant computational and analytical hurdles. Therefore, deep learning methods and variational inference methods have emerged as the mainstream techniques for scMulti-omics data analysis to solve above problems. Taking CITE-seq as an example, some series of algorithms have recently been proposed for it. sc-CTCLust (Yuan, Chen, and Deng 2022) fuses transcriptomics and proteomics data utilizing Variational Autoencoders (VAE) (Doersch 2016) and canonical correlation analysis. TotalVI (Steier, Maslan, and Streets 2022) based on variational inferencing takes batch effects and protein background into consideration. Recently, a probabilistic tensor decomposition method (Wang, Wang, and Li 2023) is proposed to fuse scMulti-omics."}, {"title": "Related Work", "content": "Single-cell Multi-omics Fusion\nMulti-omics data provide researchers with a comprehensive understanding of biological systems from various perspectives, as these different omics have complementary roles and collaborate to perform specific biological functions. However, multi-omics data are complex, high-dimensional, and heterogeneous, making it challenging to extract valuable insights from them (Boehm et al. 2022; Miao et al. 2021). Various approaches have been developed to address this challenge, such as multi-kernel learning, Bayesian consensus clustering, machine learning-based dimensionality reduction, similar network fusion, and deep learning methods.\nRNNs and Test-Time Training\nRNN(Sherstinsky 2020) is a type of neural network architecture designed to handle sequential data. However, traditional RNNs like LSTM(Sherstinsky 2020) struggle with long-range dependencies, leading to issues like vanishing gradients. Recent models, such as Mamba(Gu and Dao 2023) and RWKV(Peng et al. 2023), have improved RNNs by enhancing hidden state representations and using chunk-wise parallelism. Despite these advances, RNNs still face challenges when dealing with very long contexts, often showing diminished performance as context length increases.\nTest-Time Training (Sun et al. 2024) introduces a dynamic approach where the model's hidden state is updated during inference through self-supervised learning. This allows the model to adapt to new data on the fly, making it better suited for handling unseen or out-of-distribution inputs. Based on this, TTT layers enhance RNNs in long-context processing by continuously updating the hidden state with incoming data. This approach has demonstrated superior performance in long-context tasks compared to both traditional RNNs (Salehinejad et al. 2017) and Transformers (Vaswani 2017)."}, {"title": "Method", "content": "Problem Definition Denote the CITE-seq samples set S = {XRNA, XADT}, k \u2208 [1,n], where k is the cell number. In the matrix form, XRNA \u2208 Rnxo and XADT \u2208 Rnxp represent tanscriptomics and proteomics data, respectively. In transcriptomics, o is the number of genes, and in proteomics, p is determined by the number of proteins contained in each dataset. The goal of scFusionTTT is to learn a unified representation Zn\u00d7d of transcriptomics and proteomics for each sample in S integrating all the omics. To learn the embedding, we designed a Test-Time Training (TTT)-based RNA and (Antibody-Derived Tag) ADT masked autoencoder, RNA and ADT decoder, and two FusionTTT modules.\nTTT Layer with CITE-seq We leverage the self-supervised reconstruction process of TTT Layer to compress genetic sequence information into the model's weights, as shown in Figure 3B. We introduce this process by taking RNA sequences XRNA = [xt], t \u2208 {1, ..., n} as input. The process begins with an initial hidden state Wo, which is then iteratively refined using self-supervised learning. For each input gene token xt in a single cell, the model computes an output:\nzt = f(xt; Wt) \\tag{1}\nwhere Wt represents the current hidden state, and zt is the updated gene or protein expression. This hidden state Wt is updated by utilizing a gradient descent step on a self-supervised loss l that aims to minimize the difference between the model's expression prediction and the actual expression. The update rule as shown in Figure 3C, also can be expressed as:\nWt = Wt\u22121 - \u03b7\u2207l(Wt\u22121; xt) \\tag{2}\nwhere \u03b7 is the learning rate. TTT layers further utilize a multi-view reconstruction (Chen et al. 2020) to compress more important information. The new self-supervised loss can be described as:\nl(W;xt) = ||f(\u03b8kxt; W) \u2013 \u03b8vxt||2 \\tag{3}\nwhere \u03b8\u03ba and by are the projections for the training view and label view, respectively. The corresponding output rule is as follows:\nzt = f (\u03b8Qxt; Wt) \\tag{4}\nwhere is the projection for the test view. The linear complexity and sequence modeling advantages of the TTT layer enable us to better model gene and protein sequences.\nRNA and ADT Masked Autoencoder The Test-Time Training Block (TTTBlock), composed of the TTTlayer, is the backbone of our RNA and ADT encoder, RNA and ADT decoder, and FusionTTT module in our model. Each encoder consists of two TTTBlocks, an MLP layer, and two Root Mean Square Layer Normalization (RMSNorm) (Zhang and Sennrich 2019) layers as depicted in Figure 3A. The input Xin to the ADT and RNA encoder consists of gene expression embedding XRNA, gene symbol embedding Xsym, protein expression embedding XDT, and protein symbol embedding Xm ADT as shown in Figure 2B, which can be formulated as follows:\nsym\nex\nXin = (XRNA + XRNADT, XADRNA + XADT). \\tag{5}\nWe initially randomly masked gene and protein expression values. Subsequently, the unmasked transcriptomics and proteomics data, that is, the unmasked features Xun, were encoded separately using a TTTBlock based on a self-supervised learning mechanism. The encoding process can be described as follows:\nX = TTTLayer(\u03c8(\u03a7\u03b9\u22121)) + \u03a7\u03b9\u22121,\n\u03a7\u03b9 = MLP(\u03c8(X{)) + X\u00a6. \\tag{6}\nWhere \u03c8 is the RMSNorm function, X0 = Xin as the initial input of our model, and X\u03b9 represents the outputs of the l-th TTTBlock. The overall block structure is similar to a standard self-attention block, with the key difference being that the self-attention is replaced by a TTTlayer, which leverages self-supervised learning to update hidden states. Therefore, the process of Encoder can be described as :\nERNA = ENCRNA(ENA), \\tag{7}\nEADT = ENCADT(EDT). \\tag{8}\nwhere ENC is the encoder, ERNA, Ein EADT, ERNA, and ENDT represent the input to the RNA encoder, the input to the ADT encoder, the output of the RNA encoder, and the output of the ADT encoder, respectively.\nMulti-modalities Information Fusion To generate a unified representation of different modal omics, we introduce a fusion module to TTT. We design a FusionTTT module to integrate the outputs from each sample at the encoder stage and feed them into the fusion module. Given the construction of the TTT module, it is evident that the final token contains the most information. Therefore, we concate the outputs of the two encoders and pass them through the FusionTTT module, resulting in the outputs of the respective modalities.\nFusionTTT (E, Eut) = TTTBlock([Eut, Eut]), \\tag{9}\nwhere [..., ...] is the concatenation operation, Eut and Eout are the outputs of the encoder in their respective modal, which shows that the modalities can be easily extended to more than three modalies. In this experiment, Eut Eur and Eut = Eur. If this fusionTTT module is targeting a modality, then the output of the encoder for that modality is placed later. Due to the sequence modeling capability of TTT, we think that this approach can transfer information from Eout to out. Therefore, ERNA and EADT will be contacted to one sequence, and fed into the two FusionTTT modules, respectively. The process is as follows:\nFTRNA ERA+FusionTTT (EAT, ERA), \\tag{10}\nFTADT = ET+ \u03bb\u00b7 FusionTTT (ERA, ET), \\tag{11}\nwhere X is a learnable hyperparameter.\nA\nRNA and ADT Decoder After each modality has learned the information of the other modalities, we go through the respective modality decoder to reconstruct the initial matrices of the respective modalities. At first, the input of RNA and ADT decoder that can be described as:\nDirna = Era+Ftra \\tag{12}\nDinADT = EADT + FTT \\tag{13}\nNext, RNA and ADT decoders will be used to reconstruct the transcriptomics and proteomics, respectively.\nDout\nDorna = Decrna(Dina), \\tag{14}\nDDT = DECADT(DDT). \\tag{15}\nWhere DEC is the decoder, and DORA, and DDT are the outputs of RNA and ADT decoder, respectively. Of note, we removed the decoder module and just used the results of FusionTTT module as the final representation in stage 2 and stage 3.\nLoss Function The overall training process of scFusionTTT contains three stages, namely, multi-omics pre-training stage, multi-omics fine-tuning stage, and the unimodal omics predicting stage as shown in Figure 2A. In the multi-omics pre-training stage, the loss function for training is defined as:\nL\u2081 = a 1/n \u03a3i=1(XRNA,i - DRNA,i)\u00b2 + \u03b2 1/n \u03a3i=1(XDT - DDT)\u00b2 \\tag{16}\nWhere a and \u03b2 are the hyper-parameters used to determine the loss weights for transcriptomics and proteomics independently, and n is the cell number in experiments. X, XT, D and DDT, are the elements of XRNA, XADT, DINA, and D, which represents gene true expression values, gene predicted values, protein true expression values and protein predicted values, respectively.\nAfter scFusionTTT learned the gene and protein expression information, the model will learn the cell type information in the multi-omics fine-tuning stage utilizing cross-entropy loss, which can be described as follows:\nL2 = 1/n \u03a3 [yi log(\u0177i) + (1 \u2212 yi) log(1 \u2013 \u0177i)]. \\tag{17}\nwhere n is the cell number of CITE-seq data in the training process, yi and \u0177\u2081 are the true cell type labels and predicted cell type labels, respectively.\nFinally, we transfer multi-omic knowledge to transcriptomics in the unimodal omics predicting stage. The loss is calculated as follows:\nL3 = 1/n \u03a3 [yi log(\u0177j) + (1 \u2212 yj) log(1 \u2013 5)]. \\tag{18}\nWhere m is the cell number of transcriptomics data in the training process, yj and \u0177j are the true cell type labels and predicted cell type labels, respectively.\nExperiments\nData Sources and Prepocessing We utilized four CITE-seq datasets, and four RNA-seq datasets at experiments, and detailed information regarding these datasets was provided in Supplementary materials. We applied distinct normalization strategies tailored to each data type: reads per kilobase per million (RPKM) (Conesa et al. 2016) normalization for transcriptomics data, and Centered Log Ratio (CLR) (Aitchison 1982) normalization for the proteomic data to mitigate compositional effects.\nCLR(xi) = log  (Xi/(\u03a0Xi) \\tag{19}\nwhere xi represents the i-th protein expression value in the cell, with n denoting the total number of proteins in a cell,"}, {"title": "Ablation Study", "content": "In this experiment, we analyzed the impact of the TTT-based module. We specifically ablated the FusionTTT module and used the attention-based structure and corresponding element addition mechanism to compare it as shown in Figure 5 evaluated by three main clustering evaluation metrics, whose results demonstrated better performance of our proposed module FusionTTT.\nThe TTT-based model had a better improvement compared to the attention-based structure and had a significant increase compared to the element addition mechanism.\nScalability of ScFusionTTT Due to the specificity of the scFusionTTT, we could easily expand the modalities to three or more modalities, and choose any one of them as the main modality according to scenario requirements.\nHyper-parameter Analysis In this part, we determined the hyper-parameters a and \u03b2, optimal distribution of loss function in our model by gird-search. In addition, the dimension d of final cell representation is set to 128.\nGene and Protein Order Analysis In addition, we also analyzed the effect of gene and protein order on clustering results. We set up three scenarios, gene and protein in order, gene and protein in reverse order, and gene and protein in disrupted order as shown in Figure 6. We observed that there is a significant decrease in the clustering results when we shuffled the gene and protein order, which proved our conjecture that the order information of genes and proteins in the genome is helpful for the final representations."}, {"title": "Conclusion", "content": "In this paper, we propose a single-cell multi-omics fusion model scFusionTTT for clustering. The core idea is to utilize gene and protein order information in the human genome, followed by a TTT-layer updating mechanism that fits the sequence with a cause-and-effect relationship well. The respective representations are obtained from the output of the ADT encoder and RNA encoder. Then, each of the two FusionTTT modules fuses information unique to its respective modality and retains the information of the current modality, to reconstruct the expression matrix. Finally, the outputs of fusion modules will be regarded as the final representations to conduct downstream tasks including clustering.\nThrough experiments on 4 real CITE-seq datasets and 4 real transcriptomics datasets, we demonstrate the superiority of the proposed scFusionTTT method over other state-of-the-art baseline methods across most metrics in 8 datasets. Moreover, evidence from ablation studies and scalability studies demonstrates that scFusionTTT is robust, reliable, and extensible. The weakness of scFusionTTT is that it is not a cross-modal fusion, resulting in a weaker explanation of the relationships between the genes and proteins. Therefore, we will try to use the final representation to do some downstream tasks that reveal biological processes with better interpretation in the near future."}, {"title": "Supplementary Methods", "content": "Sorting Algorithm\nWe first used the dataset from the UCSC Genome Browser to generate a gene order list for the whole human genome. Then, we designed a sorting algorithm to align the experimental genes according to this genome-wide gene order list. Due to the diversity of gene aliases, we put all genes that do not map to the entire gene list table at the top. As for proteins, we sorted them in the order of the genes that are primarily translated into that protein.\nRandom Masking\nThe first stage of our model involves pre-training using self-supervised learning to capture gene and protein expression information. Based on experiments with different masking ratios, we selected a 15 percent masking ratio for our experiment. In stage 2 and stage 3, we just use decoders to decode gene and protein data without masking. Of note, our masking behavior is after sorting genes and proteins. We randomly mask a portion of the gene and protein expression information, allowing the encoder to process only the unmasked portion. In the decoding stage, we combine the masked information from the initial step with the encoder's output and then feed this combined data into the decoder."}]}