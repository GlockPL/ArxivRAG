{"title": "LARGE LANGUAGE MODELS FOR CONSTRUCTING AND OPTIMIZING MACHINE LEARNING WORKFLOWS: A SURVEY", "authors": ["Yang Gu", "Hengyu You", "Jian Cao", "Muran Yu"], "abstract": "Building effective machine learning (ML) workflows to address complex tasks is a primary focus of the Automatic ML (AutoML) community and a critical step toward achieving artificial general intelligence (AGI). Recently, the integration of Large Language Models (LLMs) into ML workflows has shown great potential for automating and enhancing various stages of the ML pipeline. This survey provides a comprehensive and up-to-date review of recent advancements in using LLMs to construct and optimize ML workflows, focusing on key components encompassing data and feature engineering, model selection and hyperparameter optimization, and workflow evaluation. We discuss both the advantages and limitations of LLM-driven approaches, emphasizing their capacity to streamline and enhance ML workflow modeling process through language understanding, reasoning, interaction, and generation. Finally, we highlight open challenges and propose future research directions to advance the effective application of LLMs in ML workflows.", "sections": [{"title": "1 Introduction", "content": "In the era of big data, machine learning (ML) workflows have become essential across various sectors for processing and analyzing large-scale data Xin et al. [2021], Nikitin et al. [2022]. To support the development and sharing of ML workflows, numerous repositories have been established, showcasing diverse paradigms for data analysis. For instance, KNIME offers a repository with over 25,000 workflows and 2,200 components Ordenes and Silipo [2021], providing a comprehensive collection of rigorously tested, practical models complete with detailed specifications. However, despite the availability of these resources, manually constructing and optimizing workflows to meet complex task requirements remains a knowledge-intensive and time-consuming challenge for most people.\nThe advent of Large Language Models (LLMs) has recently revolutionized artificial intelligence (AI) and ML, delivering advanced capabilities in natural language understanding and generation Hollmann et al. [2024], Wang et al. [2024a]. Models such as OpenAI's GPT-4 Achiam et al. [2023] and Meta AI's LLaMA-3 Touvron et al. [2023] have demonstrated exceptional performance across a wide range of natural language processing (NLP) tasks, thanks to their extensive training on large-scale text datasets. Additionally, multimodal LLMs Hu et al. [2024], Tai et al. [2024], Luo et al. [2024], which incorporate various data types like audio and images, allow for richer interactions by processing and generating non-textual information. Their impressive capabilities have led to widespread adoption across multiple domains Gu et al. [2023], Klievtsova et al. [2023], Zhang et al. [2023a]. As ML tasks and workflows become increasingly complex, often involving diverse modalities and domains, the potential of LLMs to automate and enhance these workflows has garnered significant attention from the research community Xiao et al. [2024], Hong et al. [2024]. This progress is also viewed as a pivotal step toward achieving artificial general intelligence (AGI).\nAs illustrated in Fig. 1, an ML workflow, receiving the input of task specification, typically involves a sequence of interconnected steps De Bie et al. [2022], including data and feature engineering, model selection and hyperparameter optimization, and workflow evaluation.\nDespite the significant advancements brought by AutoML Nikitin et al. [2022], An et al. [2023], traditional AutoML frameworks still face notable challenges. First, the iterative nature of the search processes in AutoML-often involving exhaustive model selection and hyperparameter tuning-can be extremely time-consuming and computationally expensive Olson and Moore [2016]. Second, these methods typically struggle to leverage valuable historical and human knowledge from diverse sources effectively. Even with the integration of meta-learning and Bayesian optimization techniques Feurer et al. [2022], Saha et al. [2022], traditional AutoML systems often lack the ability to collaborate seamlessly with human experts, thereby limiting their flexibility and adaptability. Finally, the models generated by AutoML are often criticized for their lack of interpretability, making it difficult for practitioners to understand and trust the decisions made by these systems Shah et al. [2021], Zhang et al. [2023b].\nThese limitations highlight the need for more advanced solutions, where LLMs demonstrate significant potential by incorporating prior knowledge, facilitating human-AI collaboration, and producing more interpretable outcomes. For instance, in hyperparameter optimization Zhang et al. [2023c], Liu et al. [2024a], LLMs can leverage historical data and domain-specific insights to predict optimal configurations, thereby enhancing model performance and reducing the reliance on exhaustive trial-and-error methods. Furthermore, the sophisticated NLP capabilities of LLMs enable them to act as interactive agents or chatbots, capable of generating and adjusting AutoML code based on contextual information provided by users Dakhel et al. [2023], Arteaga Garcia et al. [2024]. Crucially, in the process of conversational construction of ML workflows such as feature engineering Hollmann et al. [2024]\u2014LLMs have shown the ability to generate human-readable and explainable features, offering a level of transparency and guidance that surpasses many traditional black-box AutoML systems Zhang et al. [2024a], Nam et al. [2024].\nHowever, integrating LLMs into ML workflows also presents several challenges. Issues such as reasoning hallucinations, ethical concerns, and the substantial computational demands of deploying large-scale models remain significant barriers to their widespread adoption Bommasani et al. [2021], Hollmann et al. [2024], Yao et al. [2024a]. Additionally, while LLMs have demonstrated impressive results in specific tasks, their effectiveness across the entire spectrum of ML workflow stages still requires thorough investigation Zhang et al. [2023b].\nThis survey provides a comprehensive overview of the current state of research on the application of LLMs in constructing and optimizing ML workflows. To the best of our knowledge, it is the first survey to systematically address every stage of the ML workflow (Fig. 1), distinguishing it from previous reviews, such as Tornede et al. [2023a], which primarily explore the broader opportunities of an integration of LLMs and AutoML. We organize recent papers based on the specific steps in which LLMs have been utilized, as summarized in Table 1. Notably, our focus is on capturing the breadth and possibility of research within the specific context of constructing and optimizing ML workflows, rather than providing an exhaustive examination of all LLM-related methods at each individual stage."}, {"title": "2 Preliminaries", "content": "2.1 Machine Learning Task and Workflow\nML is a subfield of AI that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks Allen [2020]. These tasks range from classification and regression to clustering and reinforcement learning, each designed to identify patterns and make predictions based on data Zhou [2021], LeCun et al. [2015]. The fundamental goal of ML is to create models that generalize well from training data to unseen data, effectively solving the problem at hand Chung et al. [2018]. The ML Workflow, a structured sequence of components Oakes et al. [2024], is designed to systematically and repeatably achieve the task's objective, leading to the development of a robust and effective model.\nThe input of an ML workflow is typically the task specification, encompassing both the dataset definition and task description. The dataset, consisting of input data (features) and output labels (for supervised tasks), serves as the foundation for training the model Saha et al. [2022]. For example, the HousingPrice dataset Harrison Jr and Rubinfeld [1978] may contain a CSV table with 14 columns, where the first 13 columns represent predictive features, and the final column indicates the target variable (housing price). The task description further clarifies the model's objective and evaluation metrics Zhang et al. [2023b], specifying goals such as predicting housing prices using the R2 metric, classifying images with the F1-score metric, or identifying clusters within data using the ARI metric. Importantly, datasets and tasks vary widely in structure and type, encompassing diverse data formats such as numerical values, text, images, and time series Huang et al. [2024].\n2.2 Background on LLMs\nLarge Language Models (LLMs) are advanced neural networks, primarily built on Transformer architectures Vaswani [2017], that excel at processing and generating human-like text. Models such as OpenAI's GPT-4 Achiam et al. [2023], Google's PaLM-2 Anil et al. [2023], and Meta AI's LLaMA-3 Touvron et al. [2023] have revolutionized natural language processing (NLP), achieving state-of-the-art performance across a wide array of tasks, including text generation, translation, summarization, and question answering Minaee et al. [2024]. Moreover, LLMs are increasingly being applied to diverse domains beyond NLP, thanks to their ability to model complex language patterns and generalize across various data types Xiao et al. [2024], Liu et al. [2024b], Yu et al. [2023b].\nLLMs, which often contain tens to hundreds of billions of parameters Zhao et al. [2023], Wang et al. [2024b], are trained on vast textual datasets, enabling them to capture intricate language patterns and generate coherent, contextually accurate text. One of their most notable features is their ability to perform zero-shot and few-shot learning, where they generalize to new tasks with minimal task-specific data or examples Sahoo et al. [2024]. This flexibility significantly reduces the need for retraining, allowing LLMs to handle a wide range of tasks based on just a few instructions. Additionally, LLMs can break down complex tasks into intermediate reasoning steps, as demonstrated by techniques like Chain-of-Thought (CoT) Wei et al. [2022], Tree-of-Thought (ToT) Yao et al. [2024b], and Graph-of-Thought (GoT) prompting Besta et al. [2024]. LLMs can also be augmented with external knowledge sources and tools Zhuang et al. [2024], Fan et al. [2024], enabling them to interact more effectively with users and their environment Xi et al. [2023]. These models can be deployed as LLM-based agents, artificial entities capable of sensing their environment, making decisions, and taking actions autonomously Zhao et al. [2024]. Furthermore, through mechanisms like reinforcement learning with human feedback (RLHF), LLMs can continually improve their performance by incorporating feedback from interactions Wang et al. [2024c].\nWhile fine-tuning and alignment improves their performance and adds different dimensions to their abilities, there are still some important limitations that come up. Training and deploying LLMs is computationally expensive, requiring significant hardware resources, which restricts their accessibility for many organizations Zhang et al. [2024b], Bai et al. [2024]. Another pressing concern is the phenomenon of reasoning hallucinations, where LLMs, despite generating plausible-sounding text, can produce factually incorrect or unfaithful outputs, potentially leading to unreliable decisions in sensitive applications Li et al. [2024], Leiser et al. [2024]. Furthermore, LLMs inherently operate as probabilistic models, often producing different outputs when presented with the same inputs Wang [2024]. While parameters like temperature can be fine-tuned to control this variability, the stochastic nature of LLM responses presents challenges in ensuring consistency and reliability across use cases Gruver et al. [2024]. Moreover, the vast datasets used to train LLMs often include sensitive information, posing ethical risks around data privacy and security, especially in fields like healthcare or finance where confidentiality is paramount Yao et al. [2024a], Yang et al. [2024]. These limitations are important considerations when evaluating the deployment of LLMs in real-world tasks.\nIn this survey, we explore the current research landscape on leveraging LLMs to construct and optimize ML workflows, with a focus on each stage of the workflow. Our goal is to provide researchers and practitioners with a comprehensive understanding of the strengths and limitations of LLMs in this context. By examining the key achievements and identifying the existing challenges, we aim for this survey to serve as a foundation for future research, fostering more effective and integrated applications of LLMs in automating ML workflows."}, {"title": "3 LLMs for Data and Feature Engineering", "content": "Upon receiving the task specification, the first stage in the ML workflow is data and feature engineering, which can be further divided into two key substeps: data preprocessing and feature engineering. Data preprocessing involves cleaning, transforming, and normalizing raw data to ensure consistency and quality for subsequent analysis. Feature engineering focuses on extracting informative and relevant features from the preprocessed data to enhance the performance of learning algorithms. The following subsections will explore how LLMs can support these two crucial processes.\n3.1 Data Preprocessing\nIn many practical scenarios, the qualitative properties of raw data are not often consistent with the requirements of the target application or model Zelaya [2019], Parashar et al. [2023]. Consequently, data preprocessing has become an essential task in the machine learning application development process. Data preprocessing is typically divided into three key aspects: data acquisition, data cleaning, and data augmentation He et al. [2021]. Each aspect plays a crucial role in ensuring the quality and usability of the data before it is fed into machine learning models. The main categorization of LLM-assisted Data Preprocessing methods is illustrated in Fig. 2.\n3.1.1 Data Acquisition\nData acquisition forms the foundation of the machine learning workflow by ensuring that the right data is sourced for model training and validation. This stage is critical because the quality and relevance of the collected data directly impact the final model's performance Zhou et al. [2024]. The goal is to identify and gather datasets that align with the task at hand, which can be a time-consuming and labor-intensive process.\nLLMs have emerged as powerful tools to streamline the data acquisition process by minimizing the need for extensive manual effort and domain-specific expertise. They are capable of interpreting task requirements, identifying pertinent data sources, and generating comprehensive dataset reports, thereby expediting the workflow. Approaches for LLM-assisted data acquisition generally fall into two main categories: dataset recommendation and dataset summarization.\nIn the context of dataset recommendation, some systems harness LLMs to suggest datasets that align with specific task needs. AutoMMLab Yang et al. [2024] employs LLMs for natural language interaction with users, utilizing a \"dataset zoo\" to recommend or retrieve relevant datasets based on task descriptions. This automated selection helps tailor custom datasets to the unique requirements of specialized machine learning tasks. LLMs are also used for dataset summarization, aiding users in understanding data structure and content before further processing. The Virtual Interactive Data Scientist (VIDS) framework Hassan et al. [2023], for example, features ChatGPT-powered agents that extract detailed insights, including dataset structures, column details, and visualization suggestions. Similarly, JarviX Liu et al. [2023] incorporates an \"Insight\" component to automatically gather structured data information such as column names, types, and statistics\u2014and generate LLM-driven summary reports, giving users a quick overview of key dataset characteristics.\nHowever, if relevant datasets are unavailable or if the LLM misinterprets task requirements, the data acquisition process can result in irrelevant or poor-quality data, potentially compromising downstream ML tasks Yang et al. [2018, 2024]. Moreover, when integrating data from multiple heterogeneous sources, manual oversight may be necessary to ensure consistency and compatibility Liu et al. [2023]. These limitations highlight the need for continuous refinement of LLM-driven data acquisition methods to enhance reliability and accuracy.\n3.1.2 Data Cleaning\nData cleaning is a crucial step in the ML workflow, essential for eliminating noise, inconsistencies, and missing values that can impact model performance Jesmeen et al. [2018], Guha et al. [2024]. Traditionally, AutoML systems have relied heavily on rule-based approaches to handle data cleaning tasks such as error detection, imputation, and normalization Neutatz et al. [2022]. However, the introduction of LLMs into the process offers more dynamic and intelligent solutions by automating these tasks with enhanced flexibility. LLM-assisted data cleaning can be grouped into two primary categories: adaptive data imputation and preparation, and context-enhanced cleaning and transformation.\nThe adaptive data imputation and preparation category leverages LLMs to manage missing data and generate preprocessing modules that are tailored to specific tasks. For example, in the AutoM\u00b3L framework Luo et al. [2024], the AFE-LLMimputed component uses prompts to fill in missing values based on contextual understanding, improving data completeness and ensuring datasets are ready for subsequent processing. Similarly, the Text-to-ML method Xu et al. [2024] employs LLMs to automatically generate data preparation modules, including routines for data loading and cleaning. These modules are refined iteratively through feedback, allowing the system to adapt to the unique needs of each task and continuously enhance preprocessing accuracy.\nWhile adaptive methods focus on imputation and basic preparation, context-enhanced cleaning and transformation approaches aim to provide a deeper understanding of the dataset for more accurate cleaning and transformation. In this category, LLMs interpret preliminary data analyses, such as data types, correlations, and statistical summaries, to guide the cleaning process. For instance, in JarviX Liu et al. [2023], LLMs use pre-analyzed data insights stored in a database to inform cleaning recommendations, taking into account both structured and unstructured data characteristics. AutoML-GPT Zhang et al. [2023d] employs a similar strategy by using project-specific descriptions to suggest customized data transformations, recommending operations like image resizing and normalization for computer vision tasks, or tokenization and lowercasing for NLP tasks. Furthermore, the interactive data analysis tool Aliro Choi et al. [2023] enables users to prompt LLMs for preprocessing guidance based on observed data characteristics. For instance, if users identify outliers while exploring a PCA scatterplot, they can engage with Aliro's chat feature to request recommendations for outlier detection methods, along with generated code snippets to effectively manage these outliers.\nDespite the advantages of LLMs in identifying data patterns, they can occasionally misinterpret complex data structures, leading to incorrect or suboptimal cleaning suggestions. Moreover, handling domain-specific anomalies often requires specialized knowledge that LLMs may lack, necessitating manual intervention or targeted domain-specific training to ensure high-quality data preparation.\n3.1.3 Data Augmentation\nData augmentation refers to techniques used to artificially increase the size of the training dataset by creating modified versions of existing data. This step is particularly useful for enhancing model robustness, improving generalization, and avoiding overfitting, especially in scenarios where data is scarce.\nLLMs contribute to data augmentation by generating synthetic data, enriching existing datasets, or suggesting trans-formations that improve model generalization. Language models, when trained on pairs of data (e.g., images) and corresponding descriptive texts (e.g., captions), can learn the association between the textual descriptions and the underlying data. The trained model can then be used to generate desired images based on descriptive text inputs Mumuni and Mumuni [2024]. Recent research highlights the data generation capabilities of Pre-trained Language Models (PLMs) to produce synthetic data for training target models Gao et al. [2023], Yu et al. [2024]. To mitigate the inherent data distribution bias in synthetic datasets generated by a single PLM, FuseGen Zou et al. [2024] collaboratively leverages multiple PLMs to generate higher-quality synthetic datasets without incurring additional queries to individual PLMs, enhancing the reliability of synthetic data. Recently, NVIDIA's Nemotron-4 340B model family Adler et al. [2024] has been incorporated into synthetic data generation pipelines to create datasets for training and advancing models in various sectors, including healthcare, retail, and manufacturing. These developments demonstrate the potential of LLMs to generate meaningful synthetic data across different domains. Although the integration of LLMs for data augmentation in ML workflows is still in its early stages, their ability to generate synthetic data based on learned patterns from existing datasets offers a promising solution, particularly when data is limited for specific ML tasks Geng et al. [2023].\nOne challenge in using LLMs for data augmentation is the potential introduction of bias or irrelevant features into the augmented data. Additionally, ensuring that synthetic data accurately reflects real-world tasks without raising privacy or ethical concerns also remains a complex issue Lin et al. [2023], Xie et al. [2024].\n3.2 Feature Engineering\nWhile machine learning models built on deep neural architectures can automatically learn useful features Bengio et al. [2013], certain application settings still require explicit feature processing before model training to ensure optimal performance. Feature engineering is the process of extracting and refining relevant features from raw input data, which can significantly enhance predictive accuracy Hollmann et al. [2024]. The process typically involves three key subtopics: feature selection, feature extraction, and feature synthesis Mumuni and Mumuni [2024].\n\u2022 Feature Selection - is the process of choosing the most important features that reduce feature redundancy and improve model performance by focusing on the most relevant data attributes.\n\u2022 Feature Extraction - aims to create more robust, representative and compact features by applying specific mapping functions to the raw data.\n\u2022 Feature Synthesis - involves generating new features from existing ones, creating richer representations that can better capture the underlying patterns in the dataset.\n3.2.1 Feature Selection\nFeature selection involves building a subset of features from the original set by eliminating irrelevant or redundant ones He et al. [2021]. This process simplifies the model, reduces the risk of overfitting, and enhances overall performance Parashar et al. [2023]. The selected features are typically diverse and highly correlated with the target variables, ensuring they contribute meaningfully to the model's predictions.\nLLMs are increasingly being employed to automate feature selection by leveraging their ability to understand the semantic context of datasets. In the LMPriors framework Choi et al. [2022], LLMs are prompted to assess whether each candidate feature should be used for predicting the target outcome. Features are selected based on the difference in log probabilities between generating a \"Y\" (Yes) or \"N\" (No) token, crossing a predefined threshold. In contrast, LLM-Select Jeong et al. [2024] uses the generated text output directly, rather than token probabilities, to evaluate and select features. In this approach, LLMs analyze textual descriptions of features and their relationship to the target task, helping to identify the most relevant features that align with the goals of the machine learning model. This semantic-driven approach aids in selecting features that are crucial for predictive performance, thus reducing the complexity of the model. Similarly, in AutoM\u00b3L Luo et al. [2024], the AFE-LLMfilter component effectively filters out irrelevant or redundant attributes. The LLM integrates contextual information, including attributes from diverse datasets, column names from structured tables, modality inference results from MI-LLM (Modality Inference-LLM), and user instructions or task descriptions, into the prompt to enhance the feature selection process.\nHowever, LLMs may inherit undesirable biases from their pretraining data Gallegos et al. [2024], which could result in biased feature selection and performance disparities across subpopulations within the dataset. This concern may be addressed by using LLM-driven feature selection in a human-in-the-loop setup or combining it with traditional data-driven methods Jeong et al. [2024]. Additionally, there is a risk that features selected based on semantic relevance may be statistically weak, potentially diminishing their contribution to model performance.\n3.2.2 Feature Extraction\nFeature extraction is a dimensionality reduction process that transforms the original features using mapping functions to extract informative and non-redundant features based on specific metrics. Unlike feature selection, which retains the original features, feature extraction modifies them to generate new representations. Common approaches for feature extraction include methods like principal component analysis (PCA) Ma\u0107kiewicz and Ratajczak [1993], linear discriminant analysis (LDA) Xanthopoulos et al. [2013], and autoencoders Hinton and Salakhutdinov [2006].\nLLMs have demonstrated significant potential in feature extraction, particularly in handling complex, multimodal datasets and generating semantically meaningful features. In the LLM-based Versatile Graph Learning approach Wei et al. [2024], LLMs are employed to select appropriate feature engineering strategies that capture both the structural and semantic properties of graph data, aligning them with the specific learning task and evaluation metric. Similarly, in the Text-to-ML method Xu et al. [2024], LLMs automate the extraction and transformation of raw features for numerical, text, and image data by generating task-specific code. This code is then validated using automatically generated unit tests and synthetic data produced by LLMs, ensuring consistency in the extracted features across all dimensions.\nA key challenge with LLM-driven feature extraction is ensuring that the generated features accurately represent the underlying data distribution. In some cases, the complexity of the dataset or domain-specific nuances may lead to suboptimal or incorrect feature extraction, which could adversely affect model performance.\n3.2.3 Feature Synthesis\nFeature synthesis involves leveraging the statistical distribution of extracted features to generate new, complementary ones. This approach is particularly useful when the existing features are insufficient to provide an adequate representation of the input data Mumuni and Mumuni [2024]. Traditionally, this process has relied heavily on human expertise for tasks like standardization and feature discretization. However, manually exploring all possible feature combinations is infeasible. As a result, automatic feature construction methods, such as tree-based, genetic algorithm-based and reinforcement learning-based approaches Vafaie and De Jong [1998], Zhang et al. [2019], have been developed and have demonstrated performance comparable to or even better than human-designed features.\nLLMs have proven highly effective in generating semantically and contextually relevant synthetic features, enhancing the feature synthesis process through an interpretable, human-in-the-loop approach. In the Context-Aware Automated Feature Engineering (CAAFE) framework Hollmann et al. [2024], LLMs iteratively generate additional meaningful features for tabular datasets based on the dataset description, as shown in Fig. 3. This approach not only produces Python code for creating new features but also provides explanations of the utility and relevance of the generated features. CAAFE represents a step forward in semi-automated data science tasks, emphasizing the importance of context-aware solutions that extend AutoML systems into more interpretative and human-centered workflows."}, {"title": "4 LLMs for Model Selection and Hyperparameter Optimization", "content": "Model Selection (MS) and Hyperparameter Optimization (HPO) play a pivotal role in the ML workflow", "2019": "while hyperparameter optimization fine-tunes the settings that govern the behavior of the model", "2023": ".", "2013": ".", "2023b": "Xiao et al. [2024", "2024a": ".", "categories": "traditional models", "1986": "and naive Bayes classifiers Rish et al. [2001", "1998": "and recurrent neural networks (RNNs) Hochreiter [1997", "2015": ".", "approaches": "retrieval-based and generation-based model selection.\n4.1.1 Retrieval-based Model Selection\nThe core idea of retrieval-based methods is to first construct a repository of candidate models and then use LLMs to select the most suitable models based on task and model descriptions. In AutoMMLab Yang et al. [2024", "2024": "catalogues candidate models in a model zoo"}, {"2023": "to automatically generate model cards", "2023d": "and HuggingGPT Shen et al. [2024", "2023b": "introduces a two-stage knowledge-based reasoning approach that leverages LLMs to reason and solve tasks by drawing on knowledge from past experiences. In the offline stage", "2022": "introduces a zero-shot AutoDL method that meta-learns a large pre-trained model to select the best deep learning model from candidates", "2024": "Xu et al. [2024"}, {"2024": "proposes an end-to-end ML program synthesis approach that fully automates the generation and optimization of code across the entire ML workflow. Their Contextual Modular Generation framework breaks down the workflow into smaller modules"}, {"2024": "introduces the Verbalized Machine Learning (VML) framework"}, {"2024": "offers a framework that translates user data and descriptions into model parameters. This workflow consists of two key components: the Requirement Generator and the Model Customizer. The Requirement Generator utilizes LLMs to process user input, summarizing the task, analyzing data patterns, and condensing this information into a concise user requirement. This requirement is then processed by the Model Customizer, which determines the target model's architecture. Finally, the Model Customizer encodes the user requirement into a latent variable, which is decoded into model parameters using LoRA-assisted Hu et al. [2021"}, {"2024": "illustrates another generation-based approach, focusing on neural architecture search (NAS). In this framework, LLM-based agents are responsible for configuring both the search space and the search algorithm. These agents leverage their extensive domain knowledge to select appropriate operation modules, matching them to specific learning tasks. By referencing resources like PyG documentation, the agents prepare candidate operations for each module, constructing a search space that aligns with hardware constraints-much like a human expert would. Once the search space is defined, the agent chooses a suitable neural architecture search algorithm based on summarized requirements, effectively guiding the model selection process.\nWhile LLMs offer considerable advantages in automating the model selection process, several challenges and limitations persist. In retrieval-based methods, the dependence on pre-built model repositories limits flexibility, especially when addressing novel or highly specialized tasks. These methods are constrained by the models available in the repository, which may not always be suited to the task at hand. Additionally, the effectiveness of these approaches relies heavily on comprehensive, well-maintained model cards and documentation, which can be labor-intensive to curate and difficult to keep up to date. Managing the context length limitations within LLM prompts also presents a challenge, particularly when dealing with large volumes of model information, which can diminish the quality of the recommendations.\nIn generation-based methods, while LLMs offer the flexibility to create customized models, a key challenge arises from the inherent stochasticity of LLM inference. The randomness in the generation process can lead to variability in the models selected, often resulting in inconsistent or suboptimal choices. Although ModelGPT Tang et al. [2024", "2023": ".", "hallucination,\" where LLMs generate plausible but incorrect models or configurations. This underscores the need for robust validation mechanisms and human oversight to ensure that the selected or generated models are both reliable and effective for their intended tasks.\n4.2 Hyperparameter Optimization\nHyperparameter optimization (HPO), or hyperparameter tuning, is the process of selecting the optimal hyperparameters that enhance a machine learning model's performance. Hyperparameters are configuration parameters set prior to training-such as the maximum depth in decision trees or learning rates in neural networks\u2014and are not learned during training itself. The objective of HPO is to automatically identify the hyperparameter values that maximize a model's performance on a given task Bergstra and Bengio [2012": "."}]}