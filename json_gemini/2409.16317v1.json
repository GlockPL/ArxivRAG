{"title": "A Literature Review of Keyword Spotting Technologies for Urdu", "authors": ["Syed Muhammad Aqdas Rizvi"], "abstract": "This literature review surveys the advancements of keyword spotting (KWS) technologies, specifically focusing on Urdu, Pakistan's low-resource language (LRL), which has complex phonetics. Despite the global strides in speech technology, Urdu presents unique challenges requiring more tailored solutions. The review traces the evolution from foundational Gaussian Mixture Models to sophisticated neural architectures like deep neural networks and transformers, highlighting significant milestones such as integrating multi-task learning and self-supervised approaches that leverage unlabeled data. It examines emerging technologies' role in enhancing KWS systems' performance within multilingual and resource-constrained settings, emphasizing the need for innovations that cater to languages like Urdu. Thus, this review underscores the need for context-specific research addressing the inherent complexities of Urdu and similar URLs and the means of regions communicating through such languages for a more inclusive approach to speech technology.", "sections": [{"title": "1 Introduction", "content": "Progress in the development of speech technologies has included the advancement of KWS; as the sophistication of KWS technologies advances, the need to adapt and innovate for multilingual contexts becomes crucial, especially for LRLs such as Urdu. This literature review aims to offer an exploration of the evolution of emerging techniques to highlight the significant impact of cutting-edge technologies; simultaneously, this review underscores the need for tailored solutions that can enhance speech technologies across diverse linguistic landscapes with resource constraints and phonetic richness, such as for that of Pakistan and Urdu."}, {"title": "2 Evolution and Current Trends in Keyword Spotting Technologies", "content": "KWS relied heavily on Gaussian Mixture Models (GMMs), whose performance was the benchmark in speech recognition technologies. This approach used a mixture of Gaussian distributions to model the variation of speech sounds. However, by 2012, Deep Neural Networks (DNNs) began replacing GMMs, providing a more versatile means of capturing complex patterns in audio signals through deep, layered representations; in particular, the adoption of Recurrent Neural Networks (RNNs), especially those utilizing Long Short-term Memory (LSTM) cells, further enhanced KWS by maintaining contextual information over longer sequences of speech, significantly improving recognition accuracy (Beaufays, 2015). On the other hand, Query-by-Example (QbyE) search techniques\u00b9 have also been an avenue worth exploring. Systems utilizing Subsequence Dynamic Time Warping algorithms used dynamic programming techniques to handle spoken queries across audio documents without requiring external information (Calvo et al., 2014).\nNotwithstanding the need for efficient and effective models, a more recent approach was the development of models like EdgeCRNN\u2014a model designed for real-time keyword spotting on edge devices. EdgeCRNN combined convolutional neural networks (CNNs) with recurrent layers, optimizing the balance between computational efficiency and predictive accuracy, particularly in noisy environments (Wei et al., 2021). Furthermore, work by Yang et al. (2022) employed multi-task learning for KWS with speaker recognition based on realistic usage of KWS systems; one can expect a specific group of users using a specific device; thus, there is reason to develop systems that are not user-agnostic. Their work demonstrated that such an approach yields better results in KWS, which is a significant indication in the context of languages like Urdu, which are phonetically rich. For such languages, where there is room for variations in speech for the same keyword, multi-task approaches such as this may be very successful. Moreover, the integration of end-to-end learning models where the entire model is trained to map from audio waveforms to target keywords directly has also appeared in the landscape. This approach simplified the traditional pipeline, which involved separate feature extraction and classification stages. Models like HEiMDaL focused on detection and capturing the precise localization of keywords within audio streams, utilizing hybrid CNN architectures that were both computationally efficient and effective in real-world scenarios (Kundu et al., 2023).\nMost recently, advancements in KWS have also been driven by the rise of self-supervised learning and transformer models. Methodologies like Self-Supervised Speech Representation Learning (S3RL) use unlabeled data to pre-train models that can be fine-tuned for specific tasks such as KWS. These methods significantly reduce the dependency on large labeled datasets, reducing the investment of time and money required, which is especially promising for LRLs. For example, lightweight transformer models were pre-trained using Auto-Regressive Predictive Coding (APC; learning speech representations via using past frames to predict future frames); these models have been shown to improve the accuracy and efficiency of KWS systems on resource-constrained devices (Gao et al., 2023). Furthermore, advances in unified models that handle keyword spotting and audio tagging on mobile devices using transformer architectures demonstrate the ongoing integration of sophisticated AI techniques into everyday technology. Such models offer a multi-functional approach that accommodates real-world applications like intelligent assistants more holistically and may be better suited for LRLs due to their multi-task approach (Dinkel et al., 2023). Another novel approach uses vision-inspired keyword spotting; the application of models that use dynamic module skipping in streaming conformer encoders, such as those described by Bittar et al. (2024), demonstrates enhancements in keyword spotting by reducing computational demands, thus maintaining efficient performance.\nHowever, despite the global application of advanced keyword-spotting technologies, it is increasingly evident that the benefits of these innovations are not uniformly distributed across all languages, distinctly so in the context of LRLs."}, {"title": "3 Advancements in Multilingual Keyword Spotting Technologies", "content": "Research on LRLs presents unique and language-specific challenges and solutions for integrating KWS in a multilingual framework. Patel et al. (2018) employed both Gaussian Mixture Model-Hidden Markov Model (GMM-HMM) and Deep Neural Network-Hidden Markov Model (DNN-HMM) architectures in a study on Automatic Speech Recognition (ASR) and KWS in the context of Manipuri, a low-resource Indian language. This study is significant as it highlights the effectiveness of advanced modeling techniques in improving keyword detection in an LRL.\nAdapting recent developments in speech technologies, a noteworthy advancement in multilingual KWS for LRLs has been the introduction of cross-lingual speech representation learning, mainly through models like XLS-R (Babu et al., 2021). Via leveraging vast amounts of unlabeled data across numerous languages to learn universal speech representations, XLS-R has demonstrated its effectiveness by achieving remarkable performance in speech recognition tasks across various languages without extensive labeled data in each language. This approach is well-suited for LRLs, as it allows for using pre-trained models that are fine-tuned on smaller, language-specific datasets, significantly reducing the barrier to entry for developing robust KWS systems in less-represented languages.\nIn a similar vein, we also have the angle of transfer learning (a machine learning methodology in which knowledge learned from a task is re-used on a similar task), which has been effectively employed to improve KWS systems in LRLs. A recent study on Urdu speech synthesis used transfer learning to adapt models trained on high-resource languages to Urdu, demonstrating satisfactory results despite the low availability of speech data (Jamal et al., 2022). This study shows that this methodology can be particularly beneficial for languages like Urdu, where collecting and annotating large datasets is challenging. Therefore, by utilizing pre-trained models from related tasks or languages, researchers can accelerate the development of KWS systems for LRLs with reduced resource expenditure and time consumption.\nAs one of the most significant developments in speech technologies, the Massively Multilingual Speech (MMS) project used self-supervised learning to bring modern speech technology to otherwise less-represented languages. It did so by pre-training its models on over 1,000 languages, producing the wave2vec 2.0 embeddings, and bringing modern technology for speech synthesis, ASR, and language identification to many more languages than previously, including LRLs. Notably, the many linguistic differences that catering to several languages accompanies did not hinder results, which exceeded prior work by producing Word Error Rates (WER) as low as 18.7% on the FLEURS-54 benchmark, which is less than half of the previous cutting-edge. However, more work is still needed in improving performance in LRLS such as Urdu, improvement in which was not as significant with a 20.1% WER, marking a mere ~11% reduction from the cutting-edge (Pratap et al., 2023). This can be attributed to the lack of Urdu speech data and specific attention to Urdu's rich phonetics and phonology.\nIndeed, integrating KWS systems into multilingual contexts faces numerous challenges, including handling diverse linguistic features and the need for training data for many languages. This is especially true in regions with high linguistic diversity, like Pakistan. For such regions, developing multilingual models that can operate across multiple languages without significant loss in performance is an avenue to explore for these models to benefit from the shared learning of linguistic features across languages.\nIn light of these developments, it becomes evident that individual languages' unique characteristics and challenges require more focused studies. This is needed to tailor these broad approaches effectively, and Urdu is no exception."}, {"title": "4 Progress and Challenges in Urdu Keyword Spotting", "content": "Initial efforts in Urdu KWS have utilized traditional approaches such as HMMs. One study, in particular, developed an Urdu KWS system based on filler models (a component designed to detect and handle non-words or irrelevant sounds that are not of interest but may appear in the input audio) and a phoneme recognizer using the all-phone model ASR. This system integrated string matching algorithms to refine keyword detection, achieving a high overall system accuracy of 94.59% (Irtza et al., 2014). This work highlights the potential of using domain-specific models and refined training datasets to increase the effectiveness of KWS systems in Urdu.\nDue to Urdu's scarcity of transcribed speech data, researchers have recently explored unsupervised methods to advance KWS technologies. Remarkably, a study presented an unsupervised KWS system that leverages Segmental Dynamic Time Warping and GMMs to identify keywords in speech without needing labeled data. The system used the Phonetically Rich Urdu Speech (PRUS) corpus for training and demonstrated precision rates up to 91.50% for cross-speaker scenarios and 79.20% for same-speaker scenarios (Iqbal et al., 2020). This study attests that unsupervised learning can extract meaningful features from raw speech data of LRLS like Urdu, thus making it a viable approach for such languages.\nDespite these advancements, the development of KWS systems for Urdu is still troubled with challenges, namely, (1) the lack of large, annotated datasets, hindering the application of more complex machine learning models that require extensive training data, and (2) the phonetic diversity of Urdu and its script complexity, posing unique challenges in speech processing."}, {"title": "5 Future Works", "content": "Based on the current development of speech technologies overall, it is clear that the future of tasks such as KWS is best powered by unsupervised setups involving transformers due to the richness of their representations of speech. Such architectures give promising results while mitigating the need to do as much pre-processing for input data. This is especially significant in LRLs like Urdu, which lack as much data as possible. Additionally, contingent on the developments of more lightweight systems that perform similarly well, deployment of such technology in areas reliant on such LRLs for communication is also simplified, allowing for more feasible options for on-device and especially client-server deployments. However, the caveat is the need for a large amount of data, as representation learning through transformer architectures is inherently data-intensive.\nGiven these circumstances, future work should prioritize procuring more data for LRLs. With sufficient data, these languages can benefit more from cutting-edge speech technologies. Doing so can allow for a more refined focus on phonetically rich languages, such as Urdu, when developing models and methodologies in speech technologies. Furthermore, a specific focus on particular tasks like KWS is also a promising direction to see where methodologies such as multi-task learning may be effective regarding specific languages. Lastly, another critical direction is through networks and systems by evaluating modern methods' scale and deployment feasibility. This may require insight into a given area's technological infrastructure and communicating in particular languages to create more tailored and inclusive deployments. Overall, there is excellent potential for multi-faceted research work for KWS and speech technologies for LRLs, like Urdu, and better-resourced languages."}, {"title": "6 Conclusion", "content": "This literature review has discussed technological advancements in KWS, specifically regarding Urdu. As seen through various studies and developments, KWS has transitioned from traditional models like Gaussian Mixture Models and Hidden Markov Models to more advanced techniques involving deep neural networks, multi-task learning, and unsupervised learning.\nNevertheless, developing effective KWS systems in multilingual contexts and for LRLs like Urdu remains challenging. Advancements in cross-lingual speech representation and transfer learning (including fine-tuning) hallmark crucial steps to making modern and complex KWS technologies accessible and effective across such landscapes. Even so, the persistent scarcity of large annotated datasets and the inherent linguistic complexities of LRLs such as Urdu warrants continued innovation and tailored research efforts.\nIn a holistic sense, this review reflects on the broader implications for inclusivity in speech technologies. Ensuring the fair and equitable advancement of KWS systems across diverse landscapes enhances accessibility and enriches the interaction between humans and technology. Current advancements give hope that, with continued research, it is possible to develop adaptable and resource-efficient models that can handle the heterogeneity of the global population despite challenges faced by languages such as Urdu."}]}