{"title": "Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models", "authors": ["Xumeng Wen", "Shun Zheng", "Zhen Xu", "Yiming Sun", "Jiang Bian"], "abstract": "Recent studies have shown that large language models (LLMs), when customized with post-training on tabular data, can acquire general tabular in-context learning (TabICL) capabilities. These models are able to transfer effectively across diverse data schemas and different task domains. However, existing LLM-based TabICL approaches are constrained to few-shot scenarios due to the sequence length limitations of LLMs, as tabular instances represented in plain text consume substantial tokens. To address this limitation and enable scalable TabICL for any data size, we propose retrieval-augmented LLMs tailored to tabular data. Our approach incorporates a customized retrieval module, combined with retrieval-guided instruction-tuning for LLMs. This enables LLMs to effectively leverage larger datasets, achieving significantly improved performance across 69 widely recognized datasets and demonstrating promising scaling behavior. Extensive comparisons with state-of-the-art tabular models reveal that, while LLM-based TabICL still lags behind well-tuned numeric models in overall performance, it uncovers powerful algorithms under limited contexts, enhances ensemble diversity, and excels on specific datasets. These unique properties underscore the potential of language as a universal and accessible interface for scalable tabular data learning.", "sections": [{"title": "1. Introduction", "content": "Tabular data, a prevalent data modality comprising rows that represent distinct data instances and columns that define their features and labels, underpins critical machine learning applications across diverse domains, such as healthcare (Johnson et al., 2016), commerce (Bohanec et al., 2017), and energy (Miller et al., 2020).\nA longstanding challenge of learning on tabular data is addressing the heterogeneity in feature and label spaces. Specifically, it is crucial to account for variable-length feature columns and diverse feature types, such as numerical and categorical data with potentially unbounded values. Furthermore, identical feature values may carry entirely different meanings and significance across distinct feature columns and prediction tasks. Lastly, prediction tasks can vary on a case-by-case basis, encompassing both multi-class classification and regression labels.\nThis heterogeneity challenge has constrained most existing tabular learning approaches to case-by-case optimization or fine-tuning for each new dataset and task. These include early tree-based models (Chen & Guestrin, 2016; Ke et al., 2017; Prokhorenkova et al., 2018), later developments in customized neural architectures (Huang et al., 2020; Arik & Pfister, 2021; Katzir et al., 2021; Gorishniy et al., 2021; 2024), and recent explorations in self-supervised learning and pre-training (Yoon et al., 2020; Somepalli et al., 2021; Ucar et al., 2021; Bahri et al., 2022; Wang & Sun, 2022; Levin et al., 2023; Zhu et al., 2023; Yang et al., 2024; Yan et al., 2024; Ye et al., 2024a;b).\nMotivated by the emergence of in-context learning (ICL) in large language models (LLMs) (Brown et al., 2020), several studies have begun exploring ICL for tabular data, which we refer to as TabICL in this paper for brevity. Research on TabICL has given rise to two independent threads. The first pre-trains Transformer (Vaswani et al., 2017) variants tailored to tabular data using a TabICL objective on synthetic datasets generated from structured causal networks (Hollmann et al., 2023; 2025). The second post-trains a base LLM using instructions derived from extensive, language-represented real-world tabular datasets, enabling both ICL and zero-shot generalization for new tasks (Wen et al., 2024; Gardner et al., 2024).\nThese two paradigms each have unique advantages and limitations: the former using numeric representations is highly efficient but confined to the scope of TabICL, while the"}, {"title": "2. Related Work", "content": "An Overview of Tabular Data Learning Tabular data learning has a long-standing history in machine learning research. Prior to the advent of deep learning (LeCun et al., 2015), tree-ensemble models (Chen & Guestrin, 2016; Ke et al., 2017; Prokhorenkova et al., 2018) were developed and quickly became the preferred choice for various tabular data science competitions. Motivated by the success of automatic representation learning in deep neural networks, researchers began exploring effective neural architectures for tabular data (Huang et al., 2020; Arik & Pfister, 2021; Katzir et al., 2021; Gorishniy et al., 2021). To this day, some practitioners argue for the superiority of tree-based models, and the competition between tree-based and neural tabular models continues (Shwartz-Ziv & Armon, 2022; Gorishniy et al., 2024). However, a significant advantage of neural tabular models is their flexibility to integrate with other advanced learning mechanisms, such as self-supervised learning (Yoon et al., 2020; Somepalli et al., 2021; Ucar et al., 2021; Bahri et al., 2022) and pre-training (Wang & Sun, 2022; Levin et al., 2023; Zhu et al., 2023; Yang et al., 2024; Yan et al., 2024; Ye et al., 2024a). In recent years, breakthroughs in natural language processing (Kenton & Toutanova, 2019; Brown et al., 2020) have led to a trend of combining language models with tabular data learning (Dinh et al., 2022; Hegselmann et al., 2023; Yan et al., 2024; Ye et al., 2024a; Wen et al., 2024; Gardner et al., 2024). In this work, we build upon a prior approach (Wen et al., 2024) that introduces generative tabular learning that post-trains LLMs to follow TabICL or zero-shot prediction instructions. Our key contributions include defining a retrieval-augmented TabICL formulation, developing a universal non-parametric retrieval module, and introducing a retrieval-guided training process."}, {"title": "ICL", "content": "ICL emerged from research on scaling language modeling (Kaplan et al., 2020; Brown et al., 2020), where it was discovered that LLMs could automatically mimic the behavior of a few examples provided in the context as demonstrations. Here we summarize some representative follow-up studies that are closely related to this paper, such as selecting effective ICL examples for natural language tasks (Liu et al., 2021; Xu et al., 2023), conducting ICL-style tuning to enhance ICL performance (Wei et al., 2022; Gu et al., 2023), and understanding the ICL mechanism from the perspectives of Bayesian inference (M\u00fcller et al., 2021; Xie et al., 2022) and gradient descent (Dai et al., 2023). For readers seeking a deeper understanding of ICL, we recommend the comprehensive survey by Dong et al.. However, despite the significant advancements of ICL in language modeling, TabICL has received relatively little attention within the tabular data learning community."}, {"title": "TabICL", "content": "As discussed in the introduction, existing TabICL approaches can be broadly categorized into two groups: the TabPFN series (Hollmann et al., 2023; 2025) and LLM-based variants (Wen et al., 2024; Gardner et al., 2024). Both approaches utilize Transformer (Vaswani et al., 2017) architectures as their backbones but differ in two major aspects. First, the TabPFN series adopts numerical representations, whereas LLM-based approaches employ text representations. These representations offer distinct strengths and limitations: numerical representations are highly efficient but confined to specific tabular predictions, while text representations can accommodate fewer in-context instances yet integrate seamlessly with other LLM functionalities, infrastructures, and application interfaces. Second, TabPFN models are trained on synthetic datasets generated from structured causal networks, whereas LLM-based approaches rely on post-training with real-world datasets. In principle, these two data recipes could be combined to achieve complementary benefits. However, to the best of our knowledge, the TabPFN series has not disclosed its synthesized pre-training datasets, particularly the critical data upgrade from TabPFN-v1 (Hollmann et al., 2023) to TabPFN-v2 (Hollmann et al., 2025). In contrast, LLM-based studies have released fully reproducible pipelines (Wen et al., 2024; Gardner et al., 2024). In this study, we focus on extending the applicability of LLM-based TabICL from zero-shot and few-shot to any-shot settings and explore the potential of leveraging language as a universal interface for data-driven learning."}, {"title": "RAG", "content": "RAG also emerged from language modeling research to alleviate the limitations of LLMs in handling knowledge-intensive language tasks (Lewis et al., 2020). This mechanism enables models to leverage external knowledge bases to supplement their representations, producing more accurate and informed responses. (Gao et al., 2023) conducted an extensive survey of numerous follow-up studies on RAG, categorizing them into three main areas: pre-training, fine-tuning, and inference. In contrast, the application of RAG in tabular data learning remains relatively underexplored. A recent success in this domain is TabR (Gorishniy et al., 2024), which enhances representations for a neural tabular model by extracting nearest neighbors, thereby improving performance. In this study, we demonstrate that RAG can enable LLM-based TabICL to effectively handle large-scale datasets."}, {"title": "3. Formulations of TabICL", "content": "We begin by establishing formulations of the TabICL problem, with a focus on the differences in data representation between TabPFN- and LLM-based methodologies.\nNotations Let $\\mathcal{T}$ denote the family of all tabular learning tasks. A typical task $T \\sim \\mathcal{T}$ is defined as a mapping from an input variable $x_T \\in \\mathbb{R}^{h_x}$ to a label variable $y \\in \\mathbb{R}^{h_y}$, expressed as $T : x_T \\rightarrow y$, where $h_x$ and $h_y$ represent the dimensions of the feature and label spaces, respectively. We denote the joint distribution of $x$ and $y_T$ by $D_T$, such that $(x_T, y_T) \\sim D_T$. In practice, a training dataset is constructed by sampling $N$ observations from $D_T$, which we denote as $D_{train} = \\{(x_i, y_i)\\}_{i=1}^N$. The training set $D_{train}$ serves as an empirical approximation of the underlying distribution $D_T$. The goal of traditional supervised learning is to derive an optimized model based on $D_{train}$ that accurately characterizes the conditional distribution $P(y_{test}|x_{test})$ for new samples $(x_{test}, y_{test}) \\sim D_T$.\nTabICL Similar to ICL in language tasks (Brown et al., 2020), TabICL regards the training set $D_{train}$ as a set of in-context instances. Specifically, TabICL aims to characterize the new conditional distribution $P(y_{test}|x_{test}, D_{train})$, namely the label distribution of a testing example conditioned on its own features and other in-context instances, for any task $T$ and empirical observations sampled from $D_T$. To this end, we need a parameterized model $Q_\\theta$ to maximize the following log-likelihood:\n$\\mathbb{E}_{(x,y) \\sim D_T, T \\sim \\mathcal{T}} [\\log Q_\\theta (y_{test} | x_{test}, D_{train})]. \\qquad (1)$\nIn this way, we stimulate $Q_\\theta$ to perform TabICL for various tasks. During the inference stage, $Q_\\theta(x_{test}, D_{train})$ directly delivers the label distribution of $y_{test}$ for any new task $T' \\sim \\mathcal{T}$ via a forward pass.\nHowever, it is challenging to design $Q_\\theta$ because of the dataset heterogeneity across different tabular learning tasks, namely the feature and label spaces $(\\mathbb{R}^{h_x} \\times \\mathbb{R}^{h_y})$ differ significantly across different tasks. To address this challenge, TabPFN models (Hollmann et al., 2023; 2025) impose maximal limits on feature and prediction dimensions, constructing separate models for classification and regression tasks."}, {"title": "4. TabICL with Retrieval-Augmented LLMS", "content": "To enable scalable TabICL on any-shot settings, we develop a decoupled formulation for equation 2 as\n$\\mathbb{E}_{(x,y),T} [\\log Q_{\\mathcal{L}LM} (S_y (y_{test}) | S_x (x_{test}, \\mathcal{C}_{x_{test}}))],\\newline \\mathcal{C}_{x_{test}} = \\text{TabRAG} (x_{test}, D_{train}),\\qquad (3)$\nwhere $\\mathcal{C}_{x_{test}}$ denotes a set of in-context instances selected to support the prediction of $x_{test}$, with the size fixed as $N_C$, and we use TabRAG to denote the retrieval module for tabular data that accepts a query example, $x_{test}$, and a training set of any scale, $D_{train}$, as inputs.\nOur formulation decouples essential capabilities for scalable TabICL into two distinct modules, addressing the constraint of limited context length. The first module, $Q_{\\mathcal{L}LM}^{\\mathcal{C}_{x_{test}}}$, is responsible for predicting the desired outcomes for a query instance $x_{test}$ based on its highly relevant contexts $\\mathcal{C}_{x_{test}}$. The second module, TabRAG, focuses on identifying the most relevant and supportive reference instances to facilitate predictions by $Q_{\\mathcal{L}LM}$. To achieve competitive TabICL performance across any new task and any-shot settings, our approach offers opportunities for further improvement in three key areas: 1) the design of TabRAG, 2) TabICL of $Q_{\\mathcal{L}LM}$, and 3) the alignment between TabRAG and $Q_{\\mathcal{L}LM}$.\nThe Design of TabRAG The primary challenge in designing TabRAG lies in developing a universal retrieval protocol capable of addressing the inherent heterogeneity of tabular data. This includes accommodating variable-sized feature columns, diverse feature types, inconsistent feature importance, and the presence of noise or irrelevant features. To address these challenges, we propose a non-parametric TabRAG module based on weighted feature-wise similarities as a default retrieval policy, which can be applied to any tabular dataset. Specifically, this requires proper normalization of each feature column and efficient quantification of feature importance, with implementation details provided in Appendix A.1. In the meanwhile, we observe that a non-parametric, universal retrieval policy may select suboptimal in-context instances in certain cases, potentially deteriorating TabICL performance. For instance, as highlighted in case studies of Appendix E, some slightly adjusted retrieval strategies can significantly boost performance in certain cases. Therefore, we recommend integrating our basic TabRAG with domain knowledge and data insights in practical applications to further enhance its effectiveness. We anticipate that \u201cretrieval engineering\u201d could emerge as a critical skill for optimizing LLM-based TabICL, akin to the importance of prompt engineering in transforming natural language processing (Liu et al., 2023).\nTabICL with $Q_{\\mathcal{L}LM}$ Enhancing the foundational TabICL capabilities remains a key objective in advancing tabular learning with LLMs. In this work, we upgrade the base LLM used by Wen et al. from LLaMA-2 (Touvron et al., 2023) to Phi-3 (Abdin et al., 2024), extending the maximum sequence length from 4K to 128K. Our findings demonstrate the clear benefits of leveraging longer contexts, enabling more effective TabICL performance. As this study primarily focuses on highlighting the importance and effectiveness of introducing a retrieval mechanism, we provide a few comparisons of different base LLMs in Appendix D.3. Looking ahead, we anticipate that LLM-based TabICL will continue to benefit from advancements in the LLM field (Liu et al., 2024a), further enhancing scalability and unlocking new opportunities for tabular data applications."}, {"title": "5. Experiments", "content": "We conduct extensive experiments to address the following research questions: 1) How effectively can our retrieval mechanism enhance LLM-based TabICL in leveraging large-scale datasets? 2) How does LLM-based TabICL perform in comparison to numeric-based TabICL models and classic tabular models that are well-tuned on a case-by-case basis? 3) What are the unique strengths, current limitations, and potential future directions for LLM-based TabICL?"}, {"title": "5.1. Experimental Setups", "content": "LLM Post-Training We use real-world tabular datasets to post-train a base LLM using generative tabular learning (GTL) objective as did in (Wen et al., 2024). However, unlike their approach, we adopt Phi-3 (Abdin et al., 2024) as the base LLM, extending the effective context length from 4K to 128K and aligning it with our default retrieval policy. Details of this post-training process are provided in Appendix A.2. For brevity and clearness, we denote our post-trained model as Phi3-GTL and refer to our approach as RAG+Phi3-GTL throughout the remainder of this paper.\nHeld-out Datasets We compile a comprehensive benchmark from the literature (Gorishniy et al., 2021; Grinsztajn et al., 2022; Gorishniy et al., 2024; Wen et al., 2024), ensuring diverse datasets that may favor different learning paradigms. To avoid data leakage, we carefully examine and exclude any datasets used during the training of the Phi3-GTL model. This process results in 29 classification datasets and 40 regression datasets for held-out evaluation, covering a wide range of domains, feature dimensions, types, and distributions. Details of the data construction process are included in Appendix B.\nBaselines We include Phi3-GTL and RAG+KNN as two ablated variants of RAG+Phi3-GTL: the former uses randomly selected in-context instances, while the latter employs the same default retrieval policy but relies on the K-Nearest Neighbors (KNN) algorithm (Fix & Hodges, 1951; Cover & Hart, 1967) for prediction. We compare against TabPFN-v1 (Hollmann et al., 2023), which supports only classification tasks, and TabPFN-v2 (Hollmann et al., 2025), the state-of-the-art TabICL model utilizing numeric representations. In addition, our baselines include other representative tabular models such as XGBoost (Chen & Guestrin, 2016), LightGBM (Ke et al., 2017), CatBoost (Prokhorenkova et al., 2018), MLP, FTT (Gorishniy et al., 2021), and TabR (Gorishniy et al., 2024), all of which are extensively tuned via hyperparameter search for each dataset. We also include several \u201cRAG + X\u201d baselines, where \"X\" represents models trained and inferred on the selected in-context instances using the same retrieval policy as RAG+Phi3-GTL. These include Logistic Regression (LR), TabPFN-v1, TabPFN-v2, and XGBoost. These baselines are designed to highlight the TabICL capability of LLMs given"}, {"title": "The Alignment of TabRAG and $Q_{\\mathcal{L}LM}$", "content": "To fully unleash the TabICL capabilities of LLMs, it is crucial to align them with the in-context selection patterns of a customized TabRAG module. Rather than randomly selecting in-context instances, as in (Wen et al., 2024), we post-train LLMs to adhere to the in-context distributions generated by our default TabRAG policy. This alignment results in improved generalization performance on held-out datasets. These findings emphasize that future post-training of LLM-based TabICL could further benefit from integrating diverse retrieval policies, paving the way for flexible \u201cretrieval engineering\u201d tailored to downstream tabular prediction tasks."}, {"title": "5.2. Scaling with Available Training Instances", "content": "Figure 1 illustrates the performance variations as the size of the training data and the number of in-context instances increase for our approach under two retrieval policies: Random and RAG (our default retrieval policy). It is evident that the RAG policy enables Phi3-GTL to effectively leverage larger training datasets, while the Random policy lacks this capability. Specifically, with the RAG policy, the median prediction error demonstrates a power-law relationship with the number of training instances, expressed as $L(D) = (D_c / D)^\\alpha$. For classification tasks, $L = 1 - AUROC$, $D_c \\sim 6.05e-5$, and $\\alpha \\sim 0.102$, whereas for regression tasks, $L = NMAE$, $D_c \\sim 8.05e-8$, and $\\alpha \\sim 0.053$. This finding highlights a favorable statistical learning characteristic: given a distinguishable feature space and sufficient training instances, the expected prediction error approaches zero.\nMoreover, the RAG policy reduces the number of in-context instances required for accurate predictions. As shown in the right two subplots of Figure 1, the model using the Random policy benefits significantly from an increased number of in-context instances. In contrast, with the RAG policy, performance often saturates as the number of adaptive in-context instances increases. This indicates that, for most datasets, tens of training instances are sufficient to form a supportive context for inferring the label of a test instance."}, {"title": "5.3. Overall Comparison", "content": "Figure 2 presents an overall comparison of all models by illustrating the error distributions across held-out datasets. TabPFN-v2 emerges as the most competitive baseline in terms of the median prediction error. However, its wider error bars indicate sub-optimal performance in certain cases. In contrast, well-tuned tree-based models such as LightGBM and CatBoost, as well as neural models like FTT and TabR, demonstrate more robust performance with narrower error distributions.\nWhen comparing our approach, RAG+Phi3-GTL, with these baselines, we observe significant improvements over its ablated variants, Phi3-GTL and RAG+KNN, underscoring the importance of both retrieval and TabICL components. Furthermore, RAG+Phi3-GTL is among the top-performing of \u201cRAG + X\u201d baselines, even surpassing RAG+TabPFN-v2 in terms of median prediction performance across held-out datasets. This highlights the potential of TabICL based on text representations, which can uncover novel and highly effective ICL algorithms by operating in a text space. Besides, our approach achieves zero NMAE for a specific integer regression task without requiring explicit programming, whereas all numeric models, by default, produce float outputs. Lastly, RAG+Phi3-GTL still lags behind well-tuned baseline models and TabPFN-v2 in overall performance."}, {"title": "5.4. Ensemble Results", "content": "We further explore the potential of RAG+Phi3-GTL by investigating its contribution to ensemble diversity, as shown in Figure 3. When comparing RAG+Phi3-GTL with TabPFN-v2, LightGBM, and CatBoost, we observe that although RAG+Phi3-GTL underperforms the top-performing baselines overall, it exhibits unique strengths in certain scenarios. Moreover, a comparison of Ensemble-All with TabPFN+LightGBM and TabPFN+CatBoost reveals that these unique strengths translate into ensemble diversity, enhancing the robustness of overall ensemble performance. These findings highlight the potential of leveraging language as an alternative interface for tabular data learning, complementing existing tabular learning algorithms."}, {"title": "5.5. Per-dataset Comparisons", "content": "These findings further motivate us to conduct per-dataset comparisons to identify datasets where RAG+Phi3-GTL excels and those where it still underperforms. Figure 4 summarizes these results. We observe that on approximately 17%-20% of datasets, RAG+Phi3-GTL outperforms the state-of-the-art TabICL model, TabPFN-v2, as well as the classic tree-based model, CatBoost, which has been carefully tuned for each dataset. Furthermore, on over 80% of datasets, the performance of RAG+Phi3-GTL falls within a small gap of these two competitive baselines. These results indicate that RAG+Phi3-GTL is already a strong prediction model for most tabular datasets, suggesting that we could not only engage with a well-prepared LLM conversationally but also leverage it to understand tabular data, provide accurate predictions, and offer potential explanations."}, {"title": "Analysis of Failure Cases", "content": "Per-dataset comparison results also prompt an investigation into why the performance of RAG+Phi3-GTL falls short in certain cases. Case studies detailed in Appendix E provide insights into these failure scenarios. In summary, most failure cases are attributed to the limitations of the default retrieval policy, which struggles to extract effective in-context instances due to specific"}, {"title": "5.6. Decision Boundary Analysis", "content": "Figure 5 compares the decision boundaries of various models across four groups of synthetic instances. We observe that RAG+Phi3-GTL produces a distinctive, non-smooth decision boundary, which is entirely different from models relying on numeric representations. This boundary reflects case-by-case generalization from known training instances to unseen regions, leaving more uncertain areas when data samples are sparse.\nIn terms of shape, the decision boundary of RAG+Phi3-GTL bears some resemblance to that of Nearest Neighbors. However, LLM-based TabICL generalizes far beyond a simple rule-based average of neighboring training instances. We hypothesize that this unique behavior arises from the text-based representation of tabular data and the ICL capability of LLMs. These findings also highlight opportunities for further improving LLM-based TabICL. Specifically, to encourage smoother decision boundaries when sufficient training data is available, one approach could involve generating large-scale synthetic data and fine-tuning LLMs to emulate such behaviors."}, {"title": "6. Conclusion", "content": "In this study, we propose a retrieval-augmented approach to extend LLM-based TabICL from zero-shot and few-shot settings to any-shot scenarios. This approach explores the potential of using text representations for tabular data learning, enables the creation of unique decision boundaries, and achieves highly competitive prediction performance across most tabular datasets.\nDespite the unique strengths and promising potentials, we also acknowledge the limitations of this approach at the current stage, such as the absence of a universally effective retrieval policy, challenges in handling certain long-tail data distributions, and sub-optimal performance in several scenarios. Given the demonstrated strengths of this approach, we believe that the potential of LLM-based TabICL is still in its early stages, and these limitations present valuable opportunities for future research and development."}, {"title": "Impact Statement", "content": "This study has the potential to make significant contributions to multiple research communities and practical domains.\nFor the tabular learning community, this study introduces a novel paradigm for performing TabICL by leveraging text representations of tabular data. This paradigm demonstrates the capability to process tabular datasets across diverse domains and scales, from zero-shot and few-shot to any-shot scenarios. By moving beyond numeric-only representations, our approach opens new avenues for integrating tabular learning into broader, more flexible frameworks, making it possible to unify methodologies across heterogeneous datasets. Furthermore, our retrieval-augmented mechanism provides an adaptable framework for balancing performance and scalability, which may inspire future innovations in retrieval strategies and model architectures.\nFor the LLM community, this study demonstrates the potential of LLMs to move beyond traditional language-based applications to data understanding and learning tasks involving structured, numeric data. Our findings reveal that LLMs, when augmented with TabICL capabilities, can generalize effectively to tabular datasets and produce competitive results. This highlights the possibility of extending LLMs to domains where structured data plays a central role, such as finance, healthcare, and agriculture. By bridging the gap between text-based and numeric-based data representations, our approach paves the way for a new class of multimodal LLMs capable of unifying text and tabular data learning.\nThe integration of TabICL capabilities into LLMs may also have ethical and societal implications. On the positive side, these models can democratize access to advanced analytics, enabling users with minimal technical expertise to analyze and understand complex datasets through natural language queries. However, there are potential risks associated with misuse or unintended consequences, such as over-reliance on LLMs for critical decisions, inaccuracies in predictions due to biased training data, and challenges in ensuring transparency and accountability. Researchers and practitioners must prioritize the development of robust evaluation methods, ethical safeguards, and explainability mechanisms to mitigate these risks and ensure responsible deployment."}, {"title": "A. Methodology Details", "content": "A.1. Our Default Retrieval Policy for Tabular Data\nIn this section, we describe our default retrieval policy for selecting in-context instances for a query test case. Our approach employs a non-parametric retrieval mechanism based on the idea of nearest neighbors. The core idea is to identify the nearest context instances for a given test sample by computing distances between the test instance and the context sample pool (the training set). We aggregate importance-weighted feature-wise similarity scores as a instance-level similarity score. This process involves two key components: (1) calculating single-feature distances and (2) aggregating feature distances into instance distances. Below, we elaborate on each component in detail.\nCalculating Single Feature Distances Tabular data typically consists of two types of features: categorical and numerical. To compute distances between samples, we handle each feature type differently:\n\\begin{itemize}\n    \\item Categorical Features: For categorical features, the distance between two samples is defined as 1 if their feature values differ and 0 if they are the same.\n    \\item Numerical Features: For numerical features, we first apply quantile normalization using the statistics of the context pool. Next, we compute the absolute difference between the normalized feature values of the test sample and each context sample. To ensure consistency, we scale these distances to the range [0, 1] using min-max normalization across the context pool.\n\\end{itemize}\nThis approach ensures that the distance for each feature between the test sample and any context sample lies within the range [0, 1], providing a standardized measure of similarity.\nAggregating Feature-level Distances into Instance-level Distances In tabular data, many features may be uninformative, and aggregating feature distances equally can result in selecting context samples that are not representative of important features. To address this, we introduce a parameter-free feature weighting mechanism.\n\\begin{itemize}\n    \\item Feature Importance Scoring: We use Pearson Correlation (Cohen et al., 2009) to measure the linear relationship between each feature and the target label in the context pool. To capture non-linear relationships, we fit decision trees to each feature and evaluate its contribution to target prediction in the context pool. This process does not require parameter optimization; instead, it iteratively identifies the best feature quantile based on prediction metrics. Since we fit a tree on each single feature, the computation is highly efficient. For implementation, we leverage the Python library PPS (Predictive Power Score) (Wetschoreck et al., 2020).\n    \\item Distance Aggregation: To aggregate feature distances into a sample distance, we employ a weighted L2-norm, defined as equation 4.\n\\end{itemize}"}, {"title": "A.2. More Details on Aligning LLMs with Our Default Retrieval Policy", "content": "To enable generative tabular learning (Wen et al., 2024) on data with retrieved contexts, we curated over 300 public datasets from Kaggle, following the collection methodology outlined in their paper. To ensure the integrity of our evaluation, we carefully filtered these datasets to eliminate any potential data contamination between the training and held-out evaluation sets. After filtering, we retained 146 classification datasets and 173 regression datasets. To maximize the utility of these datasets, we expanded each dataset into up to four distinct tasks by designating different columns as task labels. We explored configurations with context sample sizes ranging from 4 to 128, all within a sequence length limit of 16,384 tokens. For each context setting, we randomly selected 16 target samples per task and formatted them using the anonymized template from (Wen et al., 2024). This process yielded a total of over 100,000 data samples for generative tabular learning.\nFor training, we utilized 16 NVIDIA A100 GPUs. We employed a micro-batch size of 1, a learning rate of le-5, and the AdamW optimizer. No warmup or learning rate scheduler was used during training. The entire training process for the Phi-3 Medium base LLM on this dataset took approximately 10 hours."}, {"title": "B. Dataset Construction", "content": "B.1. Post-Training Datasets for LLMs\nWe initially collected all tabular datasets listed in (Wen et al.", "paradigms": "LLMs (Wen et al., 2024), neural tabular models (Gorishniy et al., 2021; 2024), and tree-based models (Grinsztajn et al., 2022). In total, we prepared 29 classification datasets and 40 regression datasets, enabling a thorough assessment of model performance across diverse tabular data tasks. The detailed dataset information and statics can be found in Table 3\nDatasets from GTL (Wen et al., 2024). GTL is a research initiative focused on post-training LLMs for generalizable inference across diverse tabular tasks. A base LLM is continually trained on a comprehensive collection of 350 datasets and evaluated on an additional 50 datasets, encompassing both classification and regression tasks. This extensive pretraining enables GTL to generalize effectively across various tabular domains, delivering robust performance on a wide range of tasks without requiring task-specific fine-tuning. For our evaluation, we retained 16 test datasets after a strict filtering process based on feature quality and task validity. We denote the source tag of these datasets as \u201cLLM\u201d.\nDatasets from FTT (Gorishniy et al., 2021) and TabR (Gorishni"}]}