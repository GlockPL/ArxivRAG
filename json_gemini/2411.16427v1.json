{"title": "Unsupervised Event Outlier Detection in Continuous Time", "authors": ["Somjit Nath", "Yik Chau Lui", "Siqi Liu"], "abstract": "Event sequence data record the occurrences of events in continuous time. Event sequence forecasting based on temporal point processes (TPPs) has been extensively studied, but outlier or anomaly detection, especially without any supervision from humans, is still underexplored. In this work, we develop, to the best our knowledge, the first unsupervised outlier detection approach to detecting abnormal events. Our novel unsupervised outlier detection framework is based on ideas from generative adversarial networks (GANs) and reinforcement learning (RL). We train a \"generator\" that corrects outliers in the data with a \"discriminator\" that learns to discriminate the corrected data from the real data, which may contain outliers. A key insight is that if the generator made a mistake in the correction, it would generate anomalies that are different from the anomalies in the real data, so it serves as data augmentation for the discriminator learning. Different from typical GAN-based outlier detection approaches, our method employs the generator to detect outliers in an online manner. The experimental results show that our method can detect event outliers more accurately than the state-of-the-art approaches.", "sections": [{"title": "Introduction", "content": "Event sequence data are records of the occurrences of different events in continuous time, e.g., natural disasters in a country, or user actions when using an app. They can be represented as individual points on a timeline, with the location of the points indicating the time of the event occurrences. For event sequence data, forecasting and latent structure inference have been the focuses of most previous research. Methods based on Gaussian processes (e.g., [25, 16, 17, 5, 14]), Hawkes processes (e.g., [39, 11, 34, 29, 9]), and more recently deep neural networks (e.g., [6, 19, 33, 24, 38, 41, 35]), have been widely proposed and evaluated.\nIn contrast to forecasting, sometimes the event occurrences themselves can be unexpected, i.e. outliers. Liu & Hauskrecht [15] proposed a semi-supervised method, assuming access to clean data to train a model, to detect these outliers. Although their assumption is common in the literature, unsupervised methods without this assumption would have more practical value, since it is usually hard to get clean data without checking and preprocessing.\nInspired by Generative Adversarial Networks (GANs) [7], we propose to solve this problem by modelling a \u201cgenerator\u201d that tries to find and remove outliers and a \u201cdiscriminator\u201d that tries to distinguish the \"corrected\" data from the real data that can be either normal or abnormal. The key insight is that a generator can either correctly remove the outliers in the real data or incorrectly remove real points in the data. If the former is the case, it will be very difficult for the discriminator to separate the \"corrected\" data from the normal samples in the real data, which, by definition, constitute the majority of the data. Meanwhile, if the latter is the case, it will be relatively easy for the discriminator to separate. This intrinsic contrast between these two cases will be the source of feedback for both the generators and the discriminators to learn. Once learned, the \"generators\u201d can be used in an online manner to detect outliers in unseen event sequences. The discriminator can be trained by standard stochastic gradient descent algorithms. However, gradient descent-based optimization cannot be used for the generator because our case is non-differentiable. There are various ways for handling the non-differentiability, such as Gumbel-softmax [8], cooperative learning [18, 10] and policy gradient methods [31, 23, 27]. We chose the latter approach in this paper, due to its flexibility."}, {"title": "Unsupervised Event Outlier Detection", "content": ""}, {"title": "Problem Formulation", "content": "An event sequence is defined as $S = \\{t_n : t_n \\in T\\}_{N=1}$ where $t_n$ is the time of the occurrence of event n, N is the total number of events, and T denotes the entire time domain. We assume access to a dataset $D = \\{S_i\\}_{i=1}^I$, consisting of I event sequences, where some sequences might be corrupted in the form of the addition of abnormal points. Given an event point at $t_n$ in an event sequence S, the goal is to identify whether the event is an outlier or not, so the output would be a label, $y_n \\in \\{0,1\\}$, assigned to each event point.\nIn order to detect outliers in an unsupervised and online manner, we develop GAN-based approaches to train outlier detectors without any supervision. More specifically, we model a generator that produces \"corrected\" sequences given input sequences from the potentially corrupted data and a discriminator that distinguishes between the \u201creal\u201d and \u201ccorrected\u201d sequences.\nWe sample sequences from the potentially corrupted data as \u201creal\u201d sequences. Since by definition, outliers are supposed to be relatively rare compared to normal data, we can reasonably assume that the majority of the sampled sequences are normal, and if the generator performed an incorrect \"correction\" on the data, e.g., removing a normal point instead of an outlier point from the sequence, then it would be possible for the discriminator to distinguish it from the sampled sequences. In the following sections, we describe our framework in detail. The final algorithm is in Appendix B."}, {"title": "Encoder", "content": "We use an encoder to summarize the information in the past for each sequence, as the occurrence of a new event can be influenced by the events that occurred before it. Since the event times are continuous and irregular, we use an architecture, the continuous-time LSTMs (cLSTM) [19], designed especially for continuous-time event sequences. We can directly use the cLSTM outputs as inputs to the generator. Still, since we wish to detect and remove outliers, information about every point in the past can be crucial for determining the action, so we apply the attention mechanism [4] followed by layer normalization [2] to the latent outputs from the cLSTM with a causal mask to ensure that there is no information leak from the future. Therefore the learned outlier detector can be applied online. This entire architecture, consisting of the cLSTM and attention layer, forms the encoder as shown in Figure 1."}, {"title": "Generator", "content": "For our problem, each generator is modelled as a Reinforcement Learning (RL) agent that tries to identify and remove outliers in continuous-time event sequences. Each sequence $S_i$, before being fed into the RL agent, is first passed through an encoder as we described in the previous section. The final encodings are treated by the RL agent as sequential states of the environment, whose goal is to identify and remove outlier points from the input sequence. Each sequence is treated as an episode, in which the agent makes decisions about making changes to the sequence. To achieve this, we use policy gradient methods, which are effective for parameterizing the optimal policy and exhibit good performance in these types of tasks [36]. For our paper, we use the clip version of Proximal Policy Optimization (PPO) algorithm [27].\nThe RL agent tries to identify and remove outlier points in the sequence. For each point $t_n$ in the sequence, the RL agent takes an action ($a_n \\in \\{0,1\\}$): either to keep $t_n$ ($a_n = 0$) or to remove it ($a_n = 1$). The RL agent thus learns a policy $\\pi$ that defines the probability of a point being an outlier, and if the action sampled from the policy is 1, the point is removed from the sequence. The generated sequence consists of all the points untouched by the RL agent. In this way, by hopefully keeping only the normal points, it generates a new sequence, which is fed into a discriminator to evaluate how \u201creal\u201d it is. The discriminator outputs a reward after the sequence is completed."}, {"title": "Discriminator", "content": "The goal of the discriminator is to distinguish between the generated sequences, $S'$, obtained from the RL agent, and the real sequences, $S_i$, sampled from the dataset D. As mentioned earlier, since the proportion of corrupted sequences in the dataset should be low, the majority of the samples are clean sequences. The discriminator tries to determine whether a given sequence is \u201creal\u201d or \u201cgenerated\" using a non-linear classifier. To prevent the discriminator from dominating over the RL agent, we also add spectral normalization [22] to each layer of the classifier model. The discriminator has the exact same architecture as the generator except without self-attention and layer normalization. However, no weights are shared between them."}, {"title": "Experiments", "content": "In the experiments, we study, despite only having access to unlabeled and potentially corrupted data, whether GAN-RL can still learn outlier detectors without supervision and beat the state-of-the-art approach originally designed for semi-supervised settings (Section 3.1). We also add interesting ablation studies and provide explanation of our model and algorithm choices in Appendix E.\nDatasets To assess the performance, we use four datasets: two synthetic datasets and two real-world datasets. The synthetic datasets were generated by defining intensity functions for clean data. These intensity functions correspond to either an inhomogeneous Poisson process or a Hawkes process. For real-world datasets, we include the followings: MIMIC, used in prior work in event sequence modelling [6, 19], records the admission times of patients in an Intensive Care Unit over a period of 7 years. Taxi [30], used in [35], tracks taxi pick-up and drop-off events in the New York City.\nFor all the datasets, we also define a parameter B, controlling the percentage of clean sequences in the dataset. If \u1e9e is 0.7, it means that 70% of the sequences are clean. For all our experiments, we use a B of 0.8 unless otherwise mentioned. Outliers are generated by sampling from a Poisson process with a constant intensity function. The specific intensity functions (Appendix C.1) and outlier generation mechanism (Appendix C.2) can be found in the Appendix.\nBaseline As unsupervised event outlier detection without access to clean data has not been previously explored, we adapt the state-of-the-art approach for semi-supervised event outlier detection, PPOD, as our main baseline [15], which has demonstrated strong performance when clean data is available. It also leverages the cLSTM architecture but is trained with a negative log-likelihood loss [19] to generate the intensity functions used for scoring points and intervals in the sequences for outliers. As additional baselines, we also include RND, which generates random outlier scores, and LEN, which is based on the inter-event time interval length, from the same paper."}, {"title": "Performance of GAN-RL", "content": "In Figure 2, we present a comprehensive analysis of our RL agents' performance over a series of 10,000 episodes, each representing a complete sequence. For the synthetic datasets, these sequences are chosen randomly from a pool of 1000 generated sequences for training. Meanwhile, for Taxi, we sample from the same training data splits as used in previous work. To gauge the effectiveness of our method against the baseline method, we employ AUROC (Area Under the Receiver Operating Characteristic Curve) scores, computed based on the ground-truth labels not accessible by any of the methods during training. This metric provides valuable insights into the RL agents' ability to distinguish outliers from the norm. Over 10 independent runs, our results consistently demonstrate that our RL agents excel at outlier detection when compared to the baseline method. Another interesting observation worth mentioning is the probability that the real sequence is classified correctly and the probability that the generated is classified as real seems to be around 0.5 which suggests that the RL agent has done a great job in generating real-looking data by removing outliers."}, {"title": "Results on Test Data", "content": "We also highlight test performance across all the datasets across 10 seeds in Table 1. These are computed over 100 test sequences unseen during training. For the real-world datasets, we simply use the test split in the dataset, and for the synthetic datasets, we generate new sequences using seeds different from the ones used in training. These results demonstrate that the improvement in the performance of GAN-RL is applicable to unseen testing data as well, and demonstrates the generalizability of the proposed method."}, {"title": "Conclusion", "content": "In this work, we developed a novel unsupervised event outlier detection framework based on ideas from GANs and RL. RL-based generators are learned to correct outliers in the unlabeled dataset through GAN-based training and then applied to unseen sequences to detect event outliers online. We evaluated our method on both synthetic and real-world datasets with simulated outliers. Compared with the state-of-the-art semi-supervised approaches, our method shows similar or better detection accuracy in all the experiments."}, {"title": "Datasets", "content": "The synthetic datasets are each characterized by their own intensity functions. For simulating these Point Processes, we use Tick [3]. The details are as follows:\n\u2022 Poisson: The intensity function, $x(t) = 1 + sin(2t)$.\n\u2022 Hawkes: we use a kernel with a sum of U exponential decays with intensities $\\alpha = [0.01, 0.02, 0.01]$ and decays $\\beta = [1.0, 3.0, 7.0]$. The intensity function is defined as:\n$x(t) = \\sum_{u=1}^U \\alpha_u \\beta_u exp (-\\beta_u t) 1_{t>0}$"}, {"title": "Outlier Simulation", "content": "We use a Poisson process with a constant intensity function (a) to generate outliers, and then we merge them with the clean sequence to create a corrupted sequence. The value of the intensity function is defined based on the type of dataset being used.\nAs a rule of thumb, we choose a such that the number of outliers in a sequence is around 20 - 30% of the average clean sequence length. The exact values for every dataset are in Table 3."}, {"title": "Sensitivity to the Amount of Corruption in the Data", "content": "The unsupervised nature of the problem setting necessitates the presence of some normal sequences (or sequence segments if we split complete sequences into shorter segments) in the dataset, and this usually should not be an issue as the majority of the data should be clean by definition of outliers. However, if that is not the case we expect GAN-RL to fail because the discriminator would perceive noisy sequences as real. To study the effect of the \u201ccleanness\u201d of the datasets, we plot in Figure 5 the average performance on 100 test sequences. The X-axis is the parameter \u1e9e and increasing B means fewer corrupted sequences. As \u1e9e increases, we notice an improvement in the performance of GAN-RL as the discriminator gets more real sequences and is able to distinguish them better from generated data. However, when \u1e9e = 0.0, we notice that GAN-RL gets an AUROC of around 0.5 suggesting it is purely random. These results demonstrate how much we can relax the assumption of most of the data being clean. From Fig. 5, we see GAN-RL can perform well even with 60% of clean data across all the datasets."}, {"title": "Importance of Attention", "content": "The addition of the attention layer was really crucial to the good performance of GAN-RL. We believe this is because the generator needs to be able to focus on particular time points in the past before being able to make decisions on outliers and this is where adding attention can help. We run an ablation study where we remove the attention layer from the encoder and plot the training performance across the last 10% episodes. We do notice a drop in performance of GAN-RL without attention in Table 2. It is interesting to note that, although removing attention results in worse performance of GAN-RL in general, the amount of decrease can vary from datasets to datasets. Importantly, even without attention, GAN-RL can still outperform the baseline across all datasets, especially on Taxi, suggesting there are merits to our overall framework. Meanwhile, just adding an attention layer on top of cLSTM to the baseline does not improve performance much, if at all."}, {"title": "Utility of GANs", "content": "We look at a simple RL agent that takes actions to generate clean sequences. Instead of using a Discriminator to evaluate the quality of the generated sequence, here, we use the Wasserstein distance between the real and generated sequence as a reward signal. So, essentially, we have a non-learnable reward signal. Figure 6 portrays GAN-RL along with new variation without the discriminator. From the difference in AUROC during training, we can conclude that having a learnable discriminator is very crucial to our method. This further justifies our decision to introduce a GAN based framework for outlier detection."}, {"title": "Learning End-to-End", "content": "For the second ablation, we try to evaluate if we lose any performance by training the encoder directly with the generator or discriminator losses. In Figure 7, we show a variation of GAN-RL with a separate encoder that is trained exactly like the PPOD baseline. Our method is applied on top of it, and hence the method is not end-to-end. When we try to compare it with our method, we see that we do not give up much performance when compared with the method that has a separately trained encoder."}, {"title": "Hyper-Parameter Sensitivity", "content": "In this section, we evaluate the sensitivity to the key hyper-parameters of our method. We believe there are three key hyper-parameters that dictate the learning dynamics. The first is the update frequency which is the number of episodes after which the generator or the discriminator training is switched. This is highlighted in Fig 8 (a), where we see relatively good performance across different values, suggesting our algorithm is quite robust to this hyper-parameter.\nAdditionally, the learning rate of the generator and the discriminator also influence the training dynamics and these are shown in Fig 8 (a) & (b). Here, we notice a very similar trend. Higher values of the learning rate of both the generator and discriminator are quite bad, and we believe this is because of the inter-dependency of the generator and discriminator. For higher values, the discrimiantor for example can take bigger gradient steps in the wrong direction thus messing up the reward structure for the RL agent and this can lead to bad performance overall."}, {"title": "Hyperparameters", "content": "For all the experiments, the hyper-parameters were tuned on final AUROC scores on the training set."}]}