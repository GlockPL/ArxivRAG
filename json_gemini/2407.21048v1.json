{"title": "APTNESS: Incorporating Appraisal Theory and Emotion Support Strategies for Empathetic Response Generation", "authors": ["Yuxuan Hu", "Minghuan Tan", "Chenwei Zhang", "Zixuan Li", "Xiaodan Liang", "Min Yang", "Chengming Li", "Xiping Hu"], "abstract": "Empathetic response generation is designed to comprehend the emotions of others and select the most appropriate strategies to assist them in resolving emotional challenges. Empathy can be categorized into cognitive empathy and affective empathy. The former pertains to the ability to understand and discern the emotional issues and situations of others, while the latter involves the capacity to provide comfort. To enhance one's empathetic abilities, it is essential to develop both these aspects. Therefore, we develop an innovative framework that combines retrieval augmentation and emotional support strategy integration. Our framework starts with the introduction of a comprehensive emotional palette for empathy. We then apply appraisal theory to decompose this palette and create a database of empathetic responses. This database serves as an external resource and enhances the LLM's empathy by integrating semantic retrieval mechanisms. Moreover, our framework places a strong emphasis on the proper articulation of response strategies. By incorporating emotional support strategies, we aim to enrich the model's capabilities in both cognitive and affective empathy, leading to a more nuanced and comprehensive empathetic response. Finally, we extract datasets ED and ET from the empathetic dialogue dataset EMPATHETICDIALOGUES and EXTES based on dialogue length. Experiments demonstrate that our framework can enhance the empathy ability of LLMs from both cognitive and affective empathy perspectives. Our code is released at https://github.com/CAS-SIAT-XinHai/APTNESS.", "sections": [{"title": "1 INTRODUCTION", "content": "Empathy serves as a bedrock in human communication and emotional support, which is a critical component in empathetic response generation. In the field of sociology, empathy can be divided into two categories: cognitive empathy and affective empathy [21]. Cognitive empathy refers to the ability to recognize and understand other people's emotions, without necessarily experiencing their feelings or circumstances firsthand [23]. On the other hand, affective empathy involves forming a deep, heartfelt connection with another's emotions and situations, often through comforting, and responding to their emotions in a meaningful way [13]. The generation of empathetic responses necessitates the utilization of both cognitive and affective empathy skills, see Figure 1.\nIn contemporary society, the demand for emotional support and psychological solace is increasingly prevalent [10, 20]. To meet this demand, artificial intelligence systems capable of engaging in empathetic dialogues have emerged as significant assets. These systems are expected to comprehend users' emotional situations and feelings, providing suitable responses to help users navigate their emotional difficulties and foster psychological comfort.\nSeveral studies have begun to prioritize the distinction between cognitive empathy and affective empathy. For instance, semantic-based approaches, such as the one described in reference [25], strive to accurately understand others' emotions, thereby enhancing cognitive empathy. Methods based on COMET [6] aim to improve the emotional resonance of responses, thus enhancing affective empathy. To further improve these two types of empathetic abilities in LLMs, we propose an empathetic response generation framework named APTNESS, which integrates appraisal theory and emotional support strategies. We believe that appraisal theory provides a cognitive framework for understanding how individuals interpret and respond to emotional stimuli. By incorporating this theory into LLMs, we can equip them with a wealth of external resources on empathetic expressive methods, thereby enhancing their ability to recognize and richly convey the empathy content of user inputs. Furthermore, within the context of [14], comforting an individual can employ different strategies, demonstrating a variety of conversational techniques. We believe that these diverse conversational techniques can assist the model in learning comprehensive empathetic capabilities, potentially leading to more effective and nuanced empathetic responses.\nSpecifically, to ensure the depth and breadth of the external resource we constructed, we introduce an empathetic emotional palette comprising 7 major categories and 23 subcategories of emotions. We then apply appraisal theory, as outlined in Emotion-Bench [5], to decompose these emotions. We follow the step-by-step evaluation process proposed in appraisal theory, breaking down emotions according to their constituent elements: the emotion itself, the factors influencing the emotion, and the situation. Leveraging ChatGPT's capabilities, we generate an external resource focused on empathetic responses. To ensure that these responses effectively address both affective and cognitive empathy while providing richer language expressions, we use a two-stage empathetic response generation method. First, we facilitate dialogue to allow the LLM to generate preliminary responses. Next, we retrieve semantically similar empathetic responses from our external resource APT using semantic retrieval techniques. We then employ our fine-tuned strategy prediction module to gather strategic information. Finally, we combine all the information from these two stages to construct the final response. To validate the effectiveness of our framework, we collect two types of empathetic dialogue data and conduct automated evaluations in a turn-based manner using GPT-4. Experiments with multiple LLMs show that our framework significantly enhances the model's empathetic abilities in both cognitive and affective empathy.\nOur contributions are summarized as follows:\n\u2022 We introduce an empathetic emotional palette to decompose emotions based on appraisal theory, creating a comprehensive empathetic response database.\n\u2022 We introduce APTNESS, a retrieval-augmented framework that utilizes appraisal theories and emotional support response strategies to enhance the empathetic capabilities of LLMs in generating empathetic responses.\n\u2022 We evaluate APTNESS using automated, turn-based methods with GPT-4 on both long and short empathetic dialogue datasets, ED and ET, demonstrating its effectiveness in affective and cognitive empathy."}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 Retrieval Augmented Generation", "content": "With the advent of LLMS, generative language models have taken a prominent position in the AI landscape. Despite their advancements, these models often struggle with issues such as hallucinations, outdated information, and limited data, which can diminish their performance in specific scenarios. To mitigate these issues, retrieval augmented generation can be applied, providing external knowledge that helps these models correct errors and refine responses [3]. The retrieval augment process primarily involves four key stages: query, encoding and retrieval, reranking, and generation. During the query stage, various methods are employed to enhance the richness of the query. Techniques like GRF and Query2doc [16, 28] expand queries by generating subtask documents or pseudo-documents using LLMs; Rewrite-Retrieve-Read [15], on the other hand, leverages transfer learning with smaller models to rewrite queries. The encoding and retrieval phase is the most crucial phase for retrieval augmented generation, directly influencing the quality of the retrieved text. Here, dense retrievers are commonly used. The dual-tower retriever training method introduced by DPR [9] has gained significant traction, with extensions like Contriever [7] applying dense retrievers to unsupervised data. The Tree of Clarifications [11] adapts retrieval processes using techniques such as breadth-first search tree traversal and pruning to refine document retrieval. In the reranking stage, methods such as GENREAD [30] utilize clustering to select diverse prompts that guide the generation of varied external knowledge, while COMBO [31] employs a discriminator trained with silver labels to align generated documents with retrieved ones more effectively. Finally, in the generation phase, before the rise of LLMs, this process predominantly relied on a Reader specifically pretrained for retrieval enhancement, with models like Fid [8] showing strong performance. However, with the emergence of powerful language generation models like ChatGPT and Llama [26], the field has shifted towards using these models for generation through prompt-based methods, leveraging their superior language generation capabilities."}, {"title": "2.2 Empathetic Response Generation", "content": "The objective of the empathetic response generation task is to equip AI models with empathetic capabilities, enabling them to comprehend users' emotional needs and provide suitable emotional support. Numerous studies are being conducted on this task, with different research focusing on various aspects. Some research is centered on using scientific annotations and effective evaluations to aid in training empathetic response models. For instance, EMPATHETICDIALOGUES [20] aims to enrich the corpus of empathetic responses by collecting short empathetic dialogues. ESConv [14] is the first to introduce emotional support strategies into empathetic response tasks, enhancing conversational skills. Building on ESConv, ExTES [32] redefines emotional support strategies, using ChatGPT to generate a more diverse emotional support strategy through self-chat. This results in longer and more diverse conversations in the corpus. Following the emergence of the COMET [6] model pretrained on the commonsense corpus, some studies are beginning to focus on integrating external common knowledge into empathetic response tasks. For example, [22] enriches the common sense information in historical dialogues using COMET, marking the first introduction of external common knowledge into the task. The Global-to-Local Hierarchical Graph Network [18] utilizes graph network models, considering local common knowledge. CASE [34] tries to build upon COMET and ConceptNet [24] and align the user's cognition and affection at both coarse-grained and fine-grained levels with a language model. In the latter part of the ESConv research, some studies are beginning to investigate the integration of emotional support strategies. For example, MISC [27] attempts to focus on including fine-grained emotional understanding and mixed strategies to enrich semantic information in the text. SUPPORTER [33] focuses on the strategy of multi-turn dialogues, using reinforcement learning and introducing coherence rewards and emotional support to guide strategy learning. However, with the rise of LLMs, there has been no research on integrating emotional support strategies into empathetic response dialogues, which is the primary focus of our research. Research on empathetic response has primarily focused on semantics with LLM. For example, Lamb [25] aims to enhance the emotional cognition of models by studying the use of rational reasoning and emotional expression. The method [19] explores the impact of external empathetic knowledge, semantically similar in-context learning, and multi-step thinking on LLMs. In contrast to their research, we propose a framework for empathetic response LLMs that integrates retrieval augmentation and emotional support strategy based on an empathetic appraisal theory. This approach aims to fill the gap in the current research landscape, offering a new perspective on empathetic response tasks in the era of LLMs."}, {"title": "3 METHODOLOGY", "content": "Inspired by appraisal theory, we first introduce a comprehensive empathetic emotional palette and decompose it into situations to create the empathetic response database, APT. We then enhance the empathetic response capabilities of LLMs using retrieval augmentation and strategy integration methods. The structure of the APTNESS framework is depicted in Figure 2."}, {"title": "3.1 Task Formulation", "content": "Formally, given a dialogue history, which comprises alternating utterances between the Speaker and the Listener, defined as $C = {S_1, L_1, S_2, L_2, ..., S_{N_i-1}, L_{N_i}, S_{N_i} }$ of $2N_i \u2013 1$ utterances, where $S_i$ and $L_i$ denote the i-th utterance of the Speaker and the Listener, and $N_i$ represents the total number of utterances of one person in dialogue i. Our aim is to provide an empathetic response, denoted as R, corresponding to $L_{N_i}$."}, {"title": "3.2 The APT Database", "content": "This section describes how we created the Empathetic Response Database APT based on appraisal theory. The database generation procedure is illustrated in the green part of Figure 2."}, {"title": "3.2.1 Appraisal-Theory-based Emotion Decomposition", "content": "Here, we provide a brief overview of the emotional support evaluation theory included in EmotionBench [5]. EmotionBench proposes assessing the empathetic capabilities of LLMs by examining the fluctuation of emotions in specific situations. The creators assembled a dataset, EmotionBench, comprising over 400 different situations, each corresponding to one of eight negative emotions. Additionally, they identified 36 influencing factors across these situations, providing a comprehensive framework for evaluating the empathetic responses of LLMs\nWe believe that the process of decomposition mirrors how humans empathize in daily life: initially considering the emotions of the individual seeking assistance, then reflecting on the factors influencing these emotions, and taking into account the individual's circumstances before formulating a response. This process aligns with EmotionBench's approach to evaluating the emotional support capabilities of LLMs. Therefore, to enhance their capacity to emulate human understanding during empathetic response generation, LLMs must incorporate this process of emotional decomposition when responding to different situations."}, {"title": "3.2.2 Emotional Palette", "content": "To guarantee the diversity and comprehensive coverage of emotions in our empathetic response database, we assert that it should include a broad spectrum of emotions. Given the complexity and variability of human emotions, coupled with our incomplete and evolving understanding of them, there is currently no universally accepted standard for emotion categories. Existing emotion categories range from 4, 6, 8, to even over a dozen or more categories. Drawing on empathetic dialogue research [20] and previous emotion classification literature [2, 29], we develop a comprehensive empathetic emotional palette. This palette includes 7 main categories and 23 subcategories, as detailed in Figure 3."}, {"title": "3.2.3 Construction", "content": "Upon analyzing empathetic dialogues in the EMPATHETICDIALOGUES [20] dataset, we observe that in short conversations, such as those with only two turns, the Listener often provides empathetic responses in the final turn. Consequently, we decide to generate empathetic responses using short dialogues. We construct our database using ChatGPT\u00b9 in two stages. All prompts we used for construction are included in our code.\n(1) In the first stage, we sequentially generate emotional factors and situations for all emotions in our emotional palette using few-shot examples from EmotionBench [5].\n(2) In the second stage, we use the emotional palette, along with the generated factors and situations, to prompt ChatGPT to generate short dialogues with empathetic responses. During the generation process, we encounter issues of repetitive generation when repeatedly prompting ChatGPT to generate empathetic dialogues. Inspired by the significant role of thought chains in LLM reasoning, we decide to have ChatGPT generate dialogues in a step-by-step manner: first generate the initial utterance of an empathetic dialogue; then continue the dialogue to generate the whole empathetic conversation; finally, rethink the emotion, factor, and situation of the dialogue, and regenerate the last turn of the listener with an empathetic response.\nStatistics. After the generation process, our final APT Database is composed of 7 major emotion categories, 23 emotion subcategories, 230 factors, 2,415 situations, and 9,663 dialogues. This comprehensive dataset ensures wide coverage of empathetic scenarios and emotional responses, providing a robust foundation for retrieval augmentation in empathetic response generation systems."}, {"title": "3.3 Two-Stage Empathetic Response Generation", "content": "Drawing inspiration from recent advancements in retrieval augmentation for LLMs, along with research on emotional support"}, {"title": "3.3.1 Empathetic Responses Retrieval", "content": "Merely providing empathetic responses based solely on dialogue history is insufficient for LLMs. This is because the semantic information in the dialogue history is limited, and LLMs can only rely on their conversational abilities to provide responses. Empathetic response generation systems require more external resources to assist LLMs in generating empathetic responses. LLMs complete pre-training with a vast amount of data, embedding diverse forms of knowledge in their weights. Therefore, it is crucial to maximize the empathetic capabilities of these LLMs in the empathetic response generation task. Furthermore, our experiments show that although LLMs exhibit remarkable expressive capabilities, they tend to over-rely on offering suggestions during empathetic response generation, as shown in Table ??. This approach does not align with our expectations, as empathetic responses should display diversity.\nInspired by recent work on retrieval augmentation in LLMs, we aim to enhance the empathetic response capabilities of LLMs using our constructed empathetic response resource, APT. By leveraging this comprehensive external resource, we aspire to stimulate both the affective and cognitive empathetic capabilities and rich response expression of LLMs. We adopt a vectorized semantic retrieval approach, which can generate empathetic responses that resonate with similar emotions and situations. This approach aids LLMs in acquiring empathetic knowledge, thereby improving their ability to provide meaningful and empathetic responses.\nSpecifically, we utilize the dialogue response $G_1$ generated by LLMs for retrieval. The retrieval model we employ is Nomic Embed [17], which is trained on a vast amount of text data. This model uses contrastive learning objectives to map sentences into a vector space. The semantic similarity between two responses is then calculated by comparing their respective vector representations. This method allows us to accurately measure the semantic closeness of different responses, thereby facilitating more effective retrieval of empathetic responses:\n$G_1 = LLM(C)$ (1)\n$EG_1 = Enc(G_1)$ (2)\n$EDatabase = Enc(Database)$ (3)\n$R_1, R_2, R_3, ..., R_K = TopK(\\frac{EG_1EDatabase}{|EG_1||EDatabase|})$ (4)\nwhere Enc represents the sentence encodings of the response, and TopK selects the K responses with the highest similarity between two sentence vectors."}, {"title": "3.3.2 Emotional Support Strategy Integration", "content": "Emotional support strategies represent distinct conversational skills used at each stage of a dialogue. Previous research has demonstrated that incorporating these strategies can effectively guide models in generating empathetic responses [14, 32]. Upon examining the definition of emotional support strategies, we find that the techniques they cover are broad. These strategies can primarily be divided into those aimed at understanding the emotions and situations of the help-seeker, and those focused on providing empathetic assistance. This division corresponds precisely to cognitive empathy and affective empathy. Therefore, we believe that incorporating emotional support strategies can help LLMs develop the skills relevant to both types of empathy, thereby enhancing their empathetic abilities.\nTherefore, our objective is to introduce emotional support strategies as external guidance for LLMs in generating empathetic responses. We believe that strategies should be incorporated only when needed; when not required, the LLM can generate responses according to its own process. To achieve this, we train a LoRA [4] module for strategy prediction within LLMs using datasets labeled with empathetic strategies, such as ESConv [14] and ExTES [32]. Our analysis reveals that most of the data in the 'Others' category of ESConv consist of greetings or closing phrases, prompting us to rename this category as 'Greetings.' Similarly, statements in ExTES without defined strategies also exhibit a consistent theme, leading us to label them as 'Greetings.' In comparison, ExTES contains 17 finely annotated strategies, whereas ESConv has only 8. Furthermore, while ExTES generally has one response corresponding to one strategy, some responses in ESConv correspond to multiple strategies. The prompt we defined for the strategy prediction LORA SFT is shown in Figure 4 and includes three parts: strategy definition, task definition, and dialogue history."}, {"title": "3.3.3 The Augmentation Procedure", "content": "Our framework combines retrieval augmentation with the integration of emotional support strategies: In the first stage, we let the LLM generate a response $G_1$ of the dialogue history C, and then retrieve semantically similar empathetic responses $R_1, R_2, ..., R_K$ and their corresponding dialogue history $H_1, H_2, ..., H_K$. In the second stage, we enhance the LLM's empathetic capabilities by using the emotional support strategy integration module to predict appropriate responses' strategies $S_1, S_2, ..., S_K$ for all dialogue histories C, $H_1, H_2, H_3, ..., H_K$. And a single dialogue history's response may have multiple strategies. Next, we deduplicate it to obtain $S_1, S_2, ..., S_{K'}$ and find the corresponding strategy explanations $f_{def}(S_1), f_{def}(S_2), ..., f_{def}(S_{K'})$. The description of the whole procedure is as shown in Algorithm 1. The prompt we design is as Figure 5. We place the dialogue history C in the 'dialogue' section of the prompt. The generated response $G_1$ and retrieved responses $R_1, R_2, ..., R_K$ are sequentially placed in the 'responses' section of the prompt in the format [Response K] $R_K$ [End of Response K]. The strategies $S_1, S_2, S_3, ..., S_K$, generated by the strategy injection module, are deduplicated and ordered to become $S_1, S_2, S_3, ..., S_{K'}$. These are then placed in the 'strategies' section of the prompt in the format [Strategy $K'$] $S_{K'}$, which is defined as $f_{def}(S_{K'})$ [End of Strategy $K'$]."}, {"title": "3.4 Automatic Evaluation of LLM-based Empathetic Response Generation", "content": ""}, {"title": "3.4.1 Evaluation Metrics", "content": "In the domain of empathetic response generation, the quality assessment of multi-turn conversations still relies on traditional metrics such as BLEU-n and Dist-1/2 [19, 25, 27], which benchmark against real labels. We argue that evaluating LLMs using these metrics is somewhat limited, as the complexity and comprehensiveness of the responses these models produce may significantly deviate from real labels. Consequently, evaluating multi-turn empathetic response generation without the involvement of human experts presents a challenge.\nTo tackle this, we incorporate human evaluation metrics from previous research. Human evaluation metrics from previous research divide into two categories: Empathy, Coherence, Informativity, and Fluency [19, 20, 25], as well as Fluency, Identification, Comforting, Suggestion, and Overall [14, 33]. We select Empathy (Assess how well the response understands and appropriately expresses recognition of the Speaker's feelings and experiences.) as our primary evaluation metric, while Coherence (Evaluate the relevance and logical connection of the response to the dialogue context.), Informativity (Determine the richness and value of the information provided in the response.), Identification (Rate the depth at which the response delves into the Speaker's situation and effectively identifies their problems.), Comforting (Score the proficiency of the response in providing comfort and support.), and Suggestion (Rate the quality of the suggestions offered for addressing the Speaker's issues.) serve as our sub-metrics. Inspired by [12], emotional evaluation metrics are graded on a 7-point scale. To obtain reliable results automatically, we use GPT-4 to assign scores to responses on this scale. The evaluation prompt is illustrated in Figure 6.\""}, {"title": "3.4.2 Turn-based Empathetic Response Evaluation", "content": "In this work, we adopt turn-based empathetic response evaluation. Specifically, for each dialogue $C_i$ with $N_i$ turns, we use all conversation history till the j-th turn plus the query from the Speaker, denoted as $C_{ij}$, together with the generated the response $R_{ij}$ from LLMs. When scoring, GPT-4 assigns a score based on a dialogue history $C_{ij}$ and its response $R_{ij}$. The scoring process is denoted as a function score. Then we average all scores obtained for a complete dialogue as the score of an whole dialogue. Finally, we average all dialogues' scores as the final score $S_C$, the equations are shown as follows:\n$S_C = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{1}{N_i} \\sum_{j=1}^{N_i} score(C_{ij}, R_{ij})$ (5)\nwhere $N_i$ is the number of turns for the i-th dialogue and N is the number of dialogues."}, {"title": "4 EXPERIMENTS", "content": ""}, {"title": "4.1 Setup", "content": "Datasets. We select the longest dialogues from the EMPATHETICDIALOGUES test set and the ExTES dataset to constitute our test sets, which we respectively refer to as ED and ET.\n\u2022 ED. From the EMPATHETICDIALOGUES dataset [20], we extract 30 dialogues, each with 4 turns, forming a short dialogue test set of 120 turns in total.\n\u2022 ET. We select 10 dialogues from the ExTES [32] dataset to form the long dialogue test set. Each dialogue in this set encompasses 12 turns, also totaling 120 turns.\nModels. In our experiments, we select Llama2-7B2, Llama3-8B3, and ChatGPT4 as our baseline models, GPT45 as our automatic evaluation model. We set the temperature to 0.95 and top - p to 0.7 to ensure the richness of the responses and to follow the specified format of our instruction output, which helps reduce errors in following instructions.\nWe use the Nomic Embed encoder [17], specifically version 1.5 from the Ollama library, and employ the LlamaIndex library to construct our Information Retrieval (IR) system. The APT database, which we previously built, serves as the retrieval database. Given our primary focus on empathetic response generation, we extract all responses from the database, totaling 19,896 entries. To avoid exceeding the token limit for LLM input, we set the top-k value to 2.\nFor the experiments involving the fine-tuning of the strategy integration module, we select 10,000 data samples from the ExTES and ESConv datasets, while maintaining the proportion of data for each strategy. Due to the considerable variation in data volumes across different strategies in ExTES, we initially extract 100 data samples from each strategy with fewer data points to address the long tail problem. The models are fine-tuned for 5 epochs with a learning rate of 1e-5 and a batch size of 64. During fine-tuning, we combine the queries and dialogue histories with the prompt, as illustrated in Figure 4.\nMetrics. In our experiments, the evaluation metrics used are Empathy (Emp.), Coherence (Coh.), Informativity (Inf.), Identification (Iden.), Comforting (Comf.), and Suggestion (Sug.). Among these, Empathy is the primary evaluation metric, while the others serve as sub-metrics. We employ a turn-based methodology for automatically evaluating empathetic response generation. The GPT-4 automatic evaluation score scale for all metrics ranges from 1 to 7. The evaluation prompt is shown in Figure 6."}, {"title": "4.2 Main Results", "content": "Comparison of APTNESS against different baselines across different foundation models. We evaluate each of the models discussed above using the two collected datasets.\n\u2022 GEN. This method tests the conversational ability of the LLM by allowing it to directly generate a response $G_1$ to the dialogue history C.\n\u2022 RAG. This method enhances the LLM with retrieval augmentation. Using the APT database, an index is created which allows the LLM to utilize the retrieved responses along with $G_1$ to generate a retrieval-augmented response.\n\u2022 APTNESS. This method generates responses using our proposed APTNESS framework. Integrate retrieval augmentation with the strategy incorporation module, utilizing $G_1$, the retrieved responses $R_1, R_2, ..., R_K$, and the predicted strategy $S_1, S_2, ..., S_K$ and their definitions to jointly create responses.\nTable 1 displays the experimental results on ED and ET. From these results, on the primary evaluation metric, empathy, we observe that: (1) Llama3-8B+APTNESS achieves a score of 6.28 in ED and Llama2-7B+APTNESS reaches 6.50 in ET. Both are the state-of-the-art results achieved by the APTNESS method, corroborating the effectiveness of our approach. (2) Compared to Gen, the RAG method significantly outperforms in empathy, with Llama2-7B-based scores being higher by 0.52 and 0.39 in ED and ET respectively, and Llama3-8B-based scores being higher by 0.50 and 0.27 respectively. This validates the effectiveness of our constructed empathy database, APT, in enhancing the empathetic capabilities of LLMs. (3) We find that Llama3-8B performs better in empathy on ED, scoring 0.06 higher than Llama2-7B, but on ET, Llama2-7B scores 0.06 higher than Llama3-8B. We speculate that this is due to some degradation in the generative capabilities of Llama3-8B in longer dialogues.\nCorrelated Features with Empathy. In our research, we employ the Pearson coefficient to ascertain the correlation between various sub-metrics and the primary evaluation metric Empathy. The Pearson coefficient serves as a quantifiable measure of the linear correlation existing between two distinct data sets. It is calculated as the ratio of the covariance between the two variables to the product of their respective standard deviations [1]. We find that the sub-metric identification has correlations of 0.92 and 0.97 with the empathy on ED and ET respectively, indicating a very strong correlation. The comforting sub-metric has correlations of 0.62 and 0.73 respectively, indicating a strong correlation.\nWe believe these two metrics respectively represent the capability to identify emotions and to comfort others. This observation is in harmony with our classification of empathy into two key components: Cognitive Empathy and Affective Empathy. Our study reveals: (1) Compared to GEN, RAG significantly improves the model's empathy capabilities in both affective and cognitive empathy. We attribute this improvement to our constructed APT database, which contains rich empathetic dialogue materials that help the model better understand the emotional context and generate more nuanced expressions. However, we observe a slight decline in suggestion and informativity when RAG is introduced. We speculate that this may be due to RAG encouraging the LLM to reduce preachy responses and incorporate a wider variety of expressions. (2) Additionally, we observe that APTNESS can further enhance the empathetic abilities of LLMs beyond the improvements seen with RAG alone. We believe that incorporating emotional support strategies introduces additional dialogue techniques, enabling the model to better address issues and provide comforting responses. This finding supports our hypothesis that enhancing empathy requires improvements in both affective and cognitive empathy. With the addition of strategies, suggestion and informativity show some improvement, indicating that the introduction of emotional support strategies can address issues of insufficient expression."}, {"title": "4.3 Effectiveness of Different Strategy Schemes", "content": "To investigate the impact of different strategy annotation schemes on performance, we separately train a LoRA module for Llama3-8B using two empathetic dialogue datasets, ESConv and ExTES, each with different strategy annotation schemes. Specifically, ExTES uses more strategies than ESConv, but each response in ExTES has only one strategy annotated. In contrast, a response in ESConv may have multiple strategies annotated. The experimental results are listed in Table 3.\nWe observe that when the strategy injection module trained with ExTES is used for the APTNESS method, there is an improvement of 0.05, 0.16, and 0.14 on ED for Empathy, Identification, and Comforting, respectively, compared to the module trained with ESConv. On ET, the improvements are 0.22, 0.02, and 0.14 points for Empathy, Identification, and Comforting, respectively. Considering the overall experimental results, we believe that fine-grained strategy annotations are more effective than multiple strategy annotations for integrating emotional support strategies. We posit that finer-grained strategies provide the LLM with more nuanced guidance, enhancing both affective and cognitive empathy, and thereby significantly improving the model's empathetic capabilities."}, {"title": "4.4 Necessity of the Strategy Integration", "content": "In this section, we validate the necessity of the emotional support strategy injection module. We conduct experiments using ChatGPT as the foundation model with the two datasets mentioned above. In these experiments, strategy predictions are generated by ChatGPT itself, rather than using a fine-tuned strategy integration module. The results are shown in Table 4.\nThe results show that on the ED dataset, ChatGPT combined with APTNESS significantly improves empathetic ability, achieving an empathy score increase of 0.25 over RAG. However, on the ET dataset, its performance declines, with empathy and comforting scores decreasing by 0.23 and 0.34, respectively, compared to RAG. We believe this is because, although ChatGPT has the ability to generate strategies, its performance is not stable. This instability may lead to inaccurate responses that negatively impact the LLM's empathetic responses, particularly in comforting. As a result, the LLM's cognitive empathy ability is weakened, ultimately leading to a decrease in overall empathetic capability."}, {"title": "4.5 Case Study", "content": "Table 2 lists the responses from the three methods discussed. GEN can discern emotional issues to some extent but offers only mechanical suggestions, resulting in weak comforting and poor cognitive performance. RAG improves GEN's monotony by providing more fluent and appropriate expressions and the result shows that the LLM no longer lists opinions mechanically like GEN. What's more, it begins to empathically identify and comforting with the dialogue's context as the orange contents. Our proposed framework, APTNESS, fully comprehends the user's feelings, identifies issues more accurately, and offers better support. The phrase \"Remember, you...\" in orange demonstrates APTNESS's superior understanding of the speaker's situation and steadfast emotional support. It enhances empathetic abilities, indicating that the model is more willing to put itself in the speaker's shoes, feeling the speaker's emotions and situation, and comforting the user from these perspectives."}, {"title": "5 CONCLUSION", "content": "In this paper, we present APTNESS, an innovative framework grounded in appraisal theory and emotional support strategies. Our research includes the creation of the APT database, an empathetic response database, and a two-stage empathetic response generation method."}]}