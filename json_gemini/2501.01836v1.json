{"title": "Practical machine learning is learning on small samples", "authors": ["Marina Sapir"], "abstract": "Based on limited observations, machine learning discerns a dependence which is expected to hold in the future. What makes it possible? Statistical learning theory imagines indefinitely increasing training sample to justify its approach. In reality, there is no infinite time or even infinite general population for learning.\nHere I argue that practical machine learning is based on an implicit assumption that underlying dependence is relatively \"smooth\": likely, there are no abrupt differences in feedback between cases with close data points.\nFrom this point of view learning shall involve selection of the hypothesis \"smoothly\" approximating the training set. I formalize this as Practical learning paradigm. The paradigm includes terminology and rules for description of learners. Popular learners (local smoothing, k-NN, decision trees, Naive Bayes, SVM for classification and for regression) are shown here to be implementations of this paradigm.", "sections": [{"title": "Givens, goals and assumptions", "content": "Denote \u03a9 the set of real life objects of interest. For example, this may be patients with skin cancer, or bank clients or engine failures. The objects have two types of properties: hidden (feedback) and manifested, which are called features. The properties are assigned numerical values. Denote X domain of numerical feature vectors for objects in 2. The hidden property has values in a numerical domain denoted by Y.\nThe underlying dependence \u03c6 : X \u2192 Y is what we learn. It is expected to be inexact. There are several reasons for inexactness, for example:\n\u2022 we do not know what the feedback, actually, depends on;\n\u2022 numerical evaluations of features have intrinsic uncertainty;\n\u2022 the objects in \u03a9 and the dependence are changing in time; new objects may somehow be different from what we observed before."}, {"title": "Implicite learning assumptions", "content": "\u2022 Any two observations(X1,Y1), (X2,Y2)with \u201csimilar\u201d features x1, x2 likely have \"similar\" feedback Y1, Y2\u00b7\n\u2022 For any two hypotheses h1, h2, a hypothesis h \u2208 {h1, h2} with lower \u201cinconsistency\" on the set of cases M(h, T) represents the underlying dependence \u03c6 better.\n\u2022 The goal of learning is to find a hypothesis with lowest \u201cinconsistency\" on M(h,T).\nThe assumption explain why we undertake the learning without having an indefinitely increasing training set or a knowledge of all relevant features. I will show that the assumption is sufficient to build efficient learners in many cases.\nBelow, I define the concepts of these assumptions in general terms and show on examples of popular learners how they are interpreted.\nI will overload the notation [.] to mean different things for different types of data.\nFor:\nVector x:\nCase a:\nSequence of cases T:"}, {"title": "Traditional views on ML", "content": "It is interesting to observe that ML problem does not have a general definition. Here are some popular views on the problem."}, {"title": "Is ML an induction?", "content": "It is a common belief that ML is an induction inference.\nThe dictionary says that induction is a method of reasoning from a part to a whole, from particulars to generals, or from an individual to universal."}, {"title": "Is MLa prediction problem?", "content": "ML is sometimes understood as a prediction problem. It is assumed that the goal is to predict values of the inexact dependence 4 on manifested features of some future observations.\nFor example, here is how the prediction problem is formulated in [7]:\nGiven a training set S and data point x of a new observation (x, ?); predict its feedback y.\nThe main issue with this definition is that it does not provide a criterion to evaluate the decision. It appears that to select between the hypotheses we need to know what is not given: the future.\nTherefore, the ML problem can not be formulated as a prediction problem, as it is defined in [7]."}, {"title": "Does Statistical Learning describe ML?", "content": "Statistical Learning (SL) theory is the only commonly accepted theoretical approach to ML.\nThis is how the proponents of the SL theory understand the problem:\nIntuitively, it seems reasonable to request that a learning algorithm, when presented more and more training examples, should eventually \u201cconverge\" to an optimal solution. [6]\nThe \"optimal solution\u201d here means a hypothesis to which the infinitely increasing training set converges."}, {"title": "Practical learning. Main concepts", "content": ""}, {"title": "Definitions", "content": "Definition 1. A Problem statement is the tuple {X,Y, F, v}, where X,Y are domains, F is class of functions X \u2192 Y, u is an optional vector of parameters.\nDefinition 2. Practical learning paradigm is the tuple\n\u039e = (P,T, \u0397, \u03be, \u03bc, \u039b),\nwhere\nP : problem statement{X,Y, F, \u03c5}\nT : independent variable, training set\nH(f,T): baseline cases for f \u2208 F,\nH(f,T) \u2286 Q1 : Q1 \u2208 {T,\u2032f\u00ac}\n\u03be(\u03b1, f) : counterparts for a, a \u2208 H(f,T) :\n\u03be(\u03b1, f) \u2286 Q2 : Q2 \u2208 {T, f\u00af} \\ Q1\n\u03bc(\u03b1, \u03c5) : H(f,T) \u2192 R+, case- inconsistency between a and g(\u03b1, f)\n\u039b(f, \u03a4, \u03c5) : total inconsistency,\n\u03bd\u03b1 \u2208 \u0397(f, T), A(f, T, v) monotonously depends on \u03bc(\u03b1,\u03c5)"}, {"title": "A practical learner includes", "content": "\u2022 interpretation of all terms in the tuple \u039e using formulas and algorithms;\n\u2022 procedure, which, given the problem statement P = {X,Y, F,v} and a training set T, searches the solution\nf = arg min A(h, \u03a4, \u03c5).\nheFo"}, {"title": "Intended meaning", "content": "The practical learning paradigm represents a terminology and rules for description of machine learners. One may notice here some rough approximation to a formal system and a language of a learning logic, which may be developed in a future.\nThe fundamental concepts for each learner are baseline cases and their counterparts. Baseline cases and counterparts belong to different types of cases (if baseline cases are observations, then counterparts are hypothetical cases and vice versa). Counterparts \u03be(\u03b1, f, T) are supposed to be defined as \u201csimilar\u201d to a both in features and feedback. The case inconsistency \u00b5(a,v) evaluates the degree by which this assumption of similarity is violated. Total inconsistency evaluates degree to which the assumption of similarity is violated on the set of all baseline cases. Thus, a learner described within the Practical learning paradigm evaluates the violation of assumed \u201ccloseness\u201d between observations and the hypothetical cases for a given hypothesis. It means, a learner interprets the Implicit learning assumptions in its own way.\nFor example, in empirical risk minimization (ERM) strategy, the baseline cases are observations H(f,T) = T. And for a baseline case a = (xi, Yi), i \u2208 [1,m], its set of counterparts \u03be(\u03b1, f, T) consists of a single hypothetical case of a hypothesis f\n\u03be(\u03b1, f,T) = {(xi, f(xi))}.\nThe case inconsistency is defined as\n\u03bc(\u03b1) = ||Yi \u2212 f(xi) ||\nand total inconsistency as\n\u039b(h,T) = \u2211 \u03bc(\u03b1).\n\u03b1\u2208\u0397(h,T)\nThe ERM learner is the most primitive example of a practical learner, because here each set of counterparts contains only one case and the inconsistency between a baseline case and its counterpart is defined by the distance between feedback of the cases.\ners.\nNext I will show that many popular learning algorithms are, indeed, practical learn-"}, {"title": "Local smoothing is a practical learner", "content": "The problem statement here P = {X,Y, F, xo} has an additional parameter x \u2208 X and, may be, some other parameters. The task is to \u201csmoothly\" approximate a function f\u2208 F in a point xo given estimates of the function values in some points, the training set T = {(xi, Yi), i = 1, . . . m}.\nThe hypotheses class F consists of functions defined on a single point 20. For each hypothesis h \u2208 F there is a single baseline case, the hypothetical case a(h) = (xo, h(xo)).\nThe counterparts \u00a7(a(h)) for a baseline case a(h) are defined as subset of the training set T such that the points [f(a(h))], are in some sense closest to the point 20. A smoothing learner determines how exactly these counterparts are selected, perhaps, using some additional parameters in the problem statement.\nThecase-inconsistency may be defined by the rule:\n\u03bc\u03b1(h)) = |h(xo) \u2013 mean([f(a(h), T)]\u2082)|.\nSince there is only one baseline case, total inconsistency is the same as single case - inconsistency, \u039b(h, T) = \u03bc(\u03b1(h)).\nA smoothing learner searches for a hypothesis minimizing total inconsistency. Obviously, the hypothesis\nh(xo) = mean([(\u03b1(h), T)]2)\nsolves the problem.\nSmoothing assumes that the all counterparts in \u00a7(a(h)) together better represent expected value of the function than the single closest data point, for example, because of inherent measurement uncertainty in x, y.\nEven though smoothing is not typically considered among the machine learning problems, it is an archetypal problem of practical machine learning. A practical learner, whichever problem it solves, does\u201csmoothing\u201d of a sort, finding a less \u201cinconsistent\" approximation of the inexact underlying dependence."}, {"title": "k-NN is a practical learner", "content": "The problem statement P is formulated here with X being a metric space and binary feedback in Y = {0,1}. It also has the additional parameters xo \u2208 X, k \u2208 N. The class of hypotheses here consists of two functions\nF = {ho(xo) = 0, h\u2081(xo) = 1},\nand each function h\u2208 F has a single hypothetical case, which is taken by the learner as a baseline case H(h) = {a(h)} = {(xo, h(xo))}.\nFor the single baseline case a(h) the counterparts \u03be(\u03b1(h), T) are k observations from the training set T with feature vectors closest to the xo."}, {"title": "\u03bc(\u03b1(h)) =", "content": "h(xo) - mean([(a(h))]2)|.\nThe same goes for total inconsistency \u039b(h, T) = \u03bc(\u03b1(h)).\nThe learner selects as a solution f one of two hypotheses in F which minimizes total inconsistency (h, T)."}, {"title": "Decision tree is a practical learner", "content": "In the problem statement of this learner the domain X has only \"ordinal\u201d features: every feature has finite number of ordered values; there are no operations on feature values. The feedback of observations is binary, Y = {0,1}. There is also an additional parameter xo \u2208 X and some other parameters which control the construction of the tree. The class of functions F contains two hypothesis ho(xo) = 0, h\u2081(xo) = 1..\nThe hypothetical case a(h) = (xo, h(xo)) for the hypothesis h is the only baseline case for this hypothesis. The decision tree learner defines the set of counterparts \u03be(\u03b1(h))) not by a formula, but by a certain procedure partitioning the domain X into the subdomains, defined by intervals of features values.\nTo determine the subdomains, the learner starts with whole domain, splits it in two subdomains by a value of some feature. There are certain criteria for stopping the splitting of a given subdomain and declaring it a \"leaf\u201d. Various versions of the learner have different criteria. After a leaf was found, the algorithm switches to the next subdomain which did not undergone all possible splits yet.\nThe set of counterparts \u00a7(\u03b1(h)) is defined by the leaf A(xo), where xo belongs: the learner picks as an counterpart every observation, which has its first component in \u0391(xo):\n\u03b2\u03b5\u03be(\u03b1(h)) \u21d4 (\u03b2 \u2208 T & [\u03b2]1 \u2208 A(xo)).\nThe case - inconsistency between a(h) and \u03be(\u03b1(h)) is\n\u03bc(\u03b1(h)) =\nh(xo) -\nmean [f(x(h))]2\nthe same as for k-NN and smoothing. Total inconsistency for a single baseline case coincides with case - inconsistency: A(T,h) = \u03bc(\u03b1(h)). And the learner picks the hypothesis with the lowest total inconsistency, indeed."}, {"title": "Naive Bayes is a practical learner", "content": "In the problem statement P, the domain X has n-dimensional vectors of nominal values. Denote C\u017c finite set of values of a feature i in X and assume for any i \u2260 j Ci \u2229 Ci = \u00d8.\nY = {0,1}."}, {"title": "The learner designed for the situation when every feature is related with the feedback", "content": "and features compliment each other: perhaps, they were selected (designed) this way. The problem statement has an additional parameter xo \u2208 X.\nThe learner re-defines the problem statement Pas new problem statement P' =\n{X', Y, F', x',}. The domain\nX' = C = UCi.\nInstead of the vector xo, the problem statement P' contains sequence x = {[xo]1,..., [Xo]n}\nof its coordinates. The class of functions F' contains 2 constant functions with values in Y. Each function h \u2208 F' is defined in n points of the sequence xo.\nAccordingly, the training set T for the problem P is transformed into training set T', where every observation (x, y) \u2208 T is transformed into n observations\n{{[x]1, Y), ..., ([x]n, Y)}\nin the new training set T'.\nEach function h \u2208 F' has n hypothetical cases which are taken as baseline cases H(h).\nFor each baseline case a \u2208 H(h), its counterparts are defined by the formula\n\u03be(\u03b1, \u03a4') = {\u03b2 : (\u03b2 \u2208 T')&([\u03b2]\u2081 = [\u03b1]\u2081)}.\nThen the local inconsistency for a baseline case a \u2208 H(h) and its counterparts is defined as\n\u03bc(\u03b1) =\n1\n(\u03b1, \u03a4\u03a3\u0399([\u03b2]2\u2260 [\u03b1]\u2082).\n\u03b2\u03b5\u03be(\u03b1,\u03a4')\nThe total inconsistency for a hypothesis h with baseline cases H(h) is defined by formula\n\u039b(h,T) = \u03a0 \u03bc(\u03b1).\n\u03b1\u2208\u0397(h)\nIt is obvious that (h, T) is monotonous by each \u03bc(\u03b1) from H(h).\nThus, Naive Bayes is a practical learner, and it does not need probabilistic reasoning for its justification."}, {"title": "Linear SVM for classification is a practical learner", "content": "The problem statement contains domains X = R\", Y = {\u22121,1} and an additional parameter w. The class of hypotheses F consists of linear functions f(x) with n variables. For a function f(x) = xTb + a denote\n[f]1 = b, [f]\u2082 = a.\nDenote m the number of elements in the training set T = {(X1,Y1), ..., (Xm, Ym)}."}, {"title": "We will need a fact from linear algebra", "content": "the distance p(xo, f) from a point xo to the hyperplane f(x) = 0 is defined by formula [13]\np(xo, f) = |f(xo)|.\nThe problem is formulated explicitly as minimization of the criterion with some slack variables \u00a2 = {\u03dai, i \u2208 [1, m]}\nLinear SVM\nL(f, T, $) = w || [f]\u2081||\u00b2 +\n1\ns.t. Vi Yif (xi) \u2265 1-6; and\ni\u2208[1:m]\n1\nm\nm\n\u03a3\n(i\u2265 0.\ni=1\n(1)\n(2)\nI need to show that the learner, actually, minimizes what can be called total inconsistency between properly defined baseline cases and their counterparts in accordance with the Practical learning paradigm.\nFor this, I want to simplify the criterion. Let us consider an alternative problem:\nLinear SVM*\ns.t. Vi\nL*(f, T) = w || [f]\u2081||\u00b2 +\n\u0160i = 1 - Yif (xi),\n1\n1\nm\nm\n\u03a3\nif yif (xi) \u2265 1\nif yif (xi) < 1\n(3)\n(4)\nThe slack variables \u03da = {(i, \u2208 [1,m]} are restricted by inequalities (2) in SVM problem, but they determined uniquely for each function f\u2208 F by equalities (4) in SVM*. This is why the criterion (1) of the SVM problem depends of the slack variables \u03da and the criterion in SVM* (3) does not depend on \u03da.\nStatement 1. For a function f \u2208 F, if slack variable \u00c7i, 1 \u2264 i \u2264 m, satisfies (4) it also satisfies (2).\nProof. Suppose, the conditions (4) are true for \u015ai.\nFirst, let us assume yi f(xi) \u2265 1. Then \u011c\u2081 = 0 according with (4). We need to show that in this case both inequalities (2)\nare satisfied.\nYi f(xi) \u2265 1 - Si\nSi\u2265 0.\n(5)\n(6)\nSubstituting 0 for i in (5) we will get what we assumed to be true in this case\n(Yi f(xi) \u2265 1). Substituting 0 in (6) will get trivial formula 0 \u2265 0."}, {"title": "Consider the second case in (4)", "content": "Yi f(xi) < 1, with \u03da\u2081 = 1 Yi f(xi). Substituting this expression instead of \u2081 in (5) we will get\nYi f(xi) \u2265 1 \u2013 (1 \u2013 Yi f (xi))\nwhich leads to trivial inequality yi f(xi) \u2265 Yi f (xi).\nSubstituting expression for \u011ci in (6) we will get\nor\n1\nYi f(xi) \u2265 0\nYi f (xi) \u2264 1,\nwhich is true, because we consider the case Yi f(xi) < 1.\nStatement 2. For any f \u2208 F. for any i \u2208 [1, m], if slack variable \u00c7i satisfy conditions (2), and slack variable \u03da* satisfy conditions (4), then ( \u2264 \u015ai.\nProof. Lets consider the options in (4) again and show that for each of two cases \u2264 \u015ai.\nIf yif (xi) \u2265 1, then * = 0. By (2) \u2081 \u2265 0, therefore (i > in this case.\nIf yif (xi) < 1, then $ = 1 \u2212 yif (xi) from (4). From (2),\n\u00c7i \u2265 1 - Yif (xi) = 6.\nLemma 1. The problems Linear SVM* and Linear SVM are equivalent.\nProof. Let us show that f* with slack variables \u03da*(f) minimizing L*(f, T) minimize\nL(f,T,\u03da(f)) as well.\nThe criterion L(f,T, \u03da(f)) in (1) may have different values for the same function f depending on the slack variables \u03da(f) satisfying (2). By the Statement 1, \u03da*(f) satisfies (2). Therefore, L(f,T, \u03da*(f)) is one of the values this criterion may take for the function f.\nAlso, it is easy to see that\nL(f,T,\u03da*(f)) = L*(f,T)\nas it is defined in (3).\nBy the Statement 2, for any i \u03da(f) \u2264 \u00a2\u00ec(f). Therefore,\nL(f,T, \u010a(f)) \u2265 L(f,T,\u00a2*(f)).\nBy definition, f* is solution of SVM*, therefore for any f \u2208 F\nL*(f,T) > L*(f*,T)."}, {"title": "Now we have for any f \u2208 F for any \u03da(f) satisfying (2)", "content": "L(f,T, \u010a(f)) \u2265 L(f,T,\u00a2*(f))\n= L*(f,T)\n> L*(f*,T)\n= L(f*,T, \u00a2*(f*)).\nSince *(f*) satisfies (2) by the Statement 1, this proves that f* with slack variables defined by (4) provides minimum to the criterion in the problem SVM.\nNow, suppose f' with slack variables \u010a(f') minimize L(f, T, \u010a(f)). Let us show that in this case f' minimizes L*(f,T) as well.\nBy the Statement 2, for every f \u2208 F, for every i, if (i(f) satisfies restrictions (2) and (f) satisfies (4) then\n(f) \u2264 (f).\nBy the Statement 1, in this case \u03da* satisfies restrictions (2) as well. Therefore,\nL(f', T, \u00a2* (f'))\nis a valid value of the criterion of the SVM problem and the criterion achieves minimum when (f') = \u00a2*(f').\nIt means that for any f \u2208 F\nL(f,T, \u03da(f)) \u2265 L(f',T, \u00a2*(f'))\nwhen (f) satisfies (2). In particularly, it is true when \u03da(f) = \u03da*(f). So for any f \u2208 F\nL(f,T, \u00a2*(f)) \u2265 L(f',T,\u00a2*(f')).\nAt the same time for any f\u2208 F\nL(f,T, \u03da*(f)) = L*(f,T).\nIt follows that for any f \u2208 F\nL*(f,T) > L*(f',T).\nThis proves that f' solves the the SVM* problem."}, {"title": "Theorem 1", "content": "A learner solving the problem Linear SVM is a practical learner.\nProof. By the Lemma 1, the problems Linear SVM and Linear SVM* are equivalent. So it is enough to prove the theorem for Linear SVM*.\nFor each hypothesis f \u2208 F, the learner de facto takes training set T as baseline cases\nH(f,T) = T = {A\u00a1 = (Xi, Yi), i \u2208 [1, m]}."}, {"title": "There are two half-spaces of interest in X", "content": "z(f,y) = {x : y f(x) \u2265 1}, y \u2208 {\u22121,1}.\nThe set z(f, y) is one of two half-spaces separated by a hyperplane y f(x) \u2013 1 = 0. For a baseline case ai = (xi, yi) \u2208 Tits set of counterparts \u00a7(ai, f) is determined by Yi :\n\u00a7(ai, f) = {(x, y\u00ec) : x \u2208 z(f, y\u00ec)}\nDenote p(x, z(f, y)) the distance from x to the hyperplane, separating the half- space z(f, x) :\np(x, z(f, y)) = |y f(x) \u2013 1|.\nIf x \u00a3 z(f, z) it means y f(x) < 1. For this case\np(x, z(f, y)) = 1 \u2212 y f(x).\n(7)\nLet us define case - inconsistency by the rule:\n\u03bc(\u03b1\u03b9) =\n0,\np(xi, z(f, Yi))\nif ai \u2208 \u03be(ai, f)\notherwise\nIn view of (7) it can be rewritten as\n\u03bc(\u03b1) =\n{ 1-Yi f (xi)\nif yi f(xi) \u2265 1\notherwise.\nThis shows that for every i \u2208 [1, m]\n\u03bc(\u03b1\u03b9) = \u03b6\u03af\nas defined in (4).\nIt is obvious that L*(f,T) monotonously depends on each \u03bc(\u03b1\u03b9) = \u03b6i.\nIt proves that the learner which solves Linear SVM* problem (and it equivalent Linear SVM problem) is a practical learner.\nThe criterion (3) has two components. The first one, w || [f]\u2081 ||2 depends only on the hypothesis f.\nThis component a(f) = || [f]\u2081||\u00b2 directly evaluates derivative of the hypothesis. The smaller is a(f), the less the hypothesis changes in each point. We can say that this component characterizes inconsistency of the hypothetical cases with each other, while the second component of the criterion, \u2211(i), characterizes inconsistency between the training set and the hypothetical instances. Both together they define the goal of learning, minimization of inconsistency on M(f,T) = TU\u300cf\u00ac, as is specified by the Implicit learning assumptions."}, {"title": "Specifics of this learner is that it ignores small errors", "content": "when f(x) has wrong sign f(x)yi < 0 but |f(x)| < 1 the case inconsistency is equal 0. The designer of the learner assumed all large and only large errors are meaningful for selection of the separating hyperplane: small errors are considered a random noise.\nBut when is this an optimal strategy? If an exact linear separation between classes exists, small errors may occur due to measurements uncertainty, but large errors signal wrong separating hyperplane. Then this approach shall work. However, if the optimal separation on the general population has large errors, occurring rarely, by chance they may appear comparatively more often in a small sample. In this case, one would prefer to ignore the largest errors."}, {"title": "Linear Support vector regression is a practical learner", "content": "The problem statement contains domains X = R\", Y = R. The class of hypotheses F consists of linear functions f(x) with n variables. The problem statement includes two additional parameters \u03b5, \u03bb.\n[5])\nFor the training set T = {1, ..., \u1e9em} the learner minimizes criterion (as defined in\nSV Regression\nwhere\nm\nLsur (f, T) = \u2211 Ve ([i]2 \u2212 f([\u03b2i]1)) + 1||[f]1||\u00b2,\ni=1\nVe(r) =\n{\nif |r| < \u03b5\n0,\n|r| - 6, otherwise\nThe baseline cases here are observations: H(f,T) = T. For a baseline case \u1e9ei = (xi, Yi) its counterparts \u00a7(\u03b2i, f) consists of the single case \u00a7(\u1e9ei, f) = {(xi, f(xi))}, the same as in ERM method. The case-inconsistency is also defined similar to ERM, but with modifier V :\n\u03bc(\u03b2) = V\u03b5(|Yi - f(xi)|).\nThe modifier allows to ignore small errors, as in SVM for classification.\nThe criterion Lsur(f,T) can be called total inconsistency because it monotonously depends on each \u03bc(\u03b2\u2081).\nThe second component in the criterion Lsvr(f,T) is regularization, or measure of inconsistency of the hypothetical instances, the same as in the SVM.\nSo, the linear support vector regression is a practical learner as well."}, {"title": "Advantages of Practical learning theory", "content": "The main advantage of the theory which agrees with practical applications is that it allows to rise practically important questions which are meaningless in statistical learning theory. Here are some of these questions."}, {"title": "Selection of a learner", "content": "Within statistical learning theory learners are incomparable, formulated in different languages. Besides, there is not reason to compare them: any learner which converges to the solution when the training set indefinitely increases is as good as any other such learner.\nIn Practical learning the learners are described in the same language. We saw that differences between learners are explainable by assumptions about the data and the underlying dependence. This allows meaningful comparison of them.\nBesides, learners may be characterized by their robustness toward peculiarities of small samples. Question about robustness of a learner is practically important but is meaningless in statistical learning."}, {"title": "Testing", "content": "Most applied machine learning specialists know that you can not evaluate a decision rule on the same data, on which you obtained it. But the textbooks on machine learning are usually mum about it because it does not make sense in statistical learning theory, when the data are expected to increase indefinitely and the underlying dependence is assumed to be exact.\nPractical learning allows to understand testing as a logical operation necessary in the process of learning."}, {"title": "Outliers", "content": "If we assume, as statistical learning does, that the training set can be increased indefinitely, and eventually will approximate the distribution and the function on data we are learning, there can not be any outliers. Otherwise it is easy to understand that training sample may contain disproportional number of observations which do not fit in the general tendency of the underlying dependence. It makes the question about outliers become critical."}, {"title": "Data sufficiency", "content": "Small sample may be not sufficiantly representative. This is the problem in practical applications, but it does not make sense in statistical learning theory. Practical learning allows to formulate the problem and search for its solution."}, {"title": "Conclusions", "content": "Currently, theoretical machine learning is a statistical learning. Where statistical learning sees approximation of a function with infinitely increasing number of observations, practical learning has to deal with uncertainty in data, non-deterministic dependencies, limited time-frame for learning and all the problems which come from these restrictions.\nI propose to see machine learning not as statistical, but as a logical problem which Peirce called abduction: search for a hypothesis which \u201cexplains\u201d observations the best in terms of some quantifiable inconsistency of a hypothesis and observations. This allows one to approach the real life problems machine learning practitioners are facing.\nImplicit learning assumptions (ILA) are proposed here as an alternative to the assumption of indefinitely increasing training set of the statistical learning. ILA view machine learning as minimization of \u201cinconsistency\u201d on the set of observations and hypothetical cases. The proposed Practical learning paradigm includes terminology and rules to describe practical learners. The paradigm is based on the ILA.\nI demonstrated that such learners as k-NN, Naive Bayes, decision tree, linear SVM for classification, and linear SVM for regression, which appear to have different approaches, justifications and structure, all can be described within Practical learning paradigm. One can say also that each of these learners is a formalization of the ILA, because it minimizes a quantifiable \u201cinconsistency\u201d on the set of all the hypothetical cases and observations.\nThe regularization component in the criteria of SVM and SVR learners nicely fits in the proposed view, because it evaluates inconsistency on the hypothetical cases.\nThe examples shall support the conjecture that practical learning is not a statistical, but a logical problem. In the next articles I plan to show that popular learners for other machine learning problems (clustering, for example) can be explained within the Practical learning paradigm."}]}