{"title": "ITPATCH: An Invisible and Triggered Physical Adversarial Patch against Traffic Sign Recognition", "authors": ["Shuai Yuan", "Hongwei Li", "Xingshuo Han", "Guowen Xu", "Wenbo Jiang", "Tao Ni", "Qingchuan Zhao", "Yuguang Fang"], "abstract": "Physical adversarial patches have emerged as a key adversarial attack to cause misclassification of traffic sign recognition (TSR) systems in the real world. However, existing adversarial patches have poor stealthiness and attack all vehicles indiscriminately once deployed. In this paper, we introduce an invisible and triggered physical adversarial patch (ITPATCH) with a novel attack vector, i.e., fluorescent ink, to advance the state-of-the-art. It applies carefully designed fluorescent perturbations to a target sign, an attacker can later trigger a fluorescent effect using invisible ultraviolet light, causing the TSR system to misclassify the sign and potentially resulting in traffic accidents. We conducted a comprehensive evaluation to investigate the effectiveness of ITPATCH, which shows a success rate of 98.31% in low-light conditions. Furthermore, our attack successfully bypasses five popular defenses and achieves a success rate of 96.72%.", "sections": [{"title": "1 Introduction", "content": "Traffic sign recognition (TSR) plays a pivotal role in autonomous driving by visually detecting and classifying traffic signs to ensure driving safety under various road situations. However, most TSR systems were built atop machine-learning models that are inherently suspected and also shown to be subject to adversarial attacks [1,2], making TSR systems work incorrectly. In particular, these attacks were launched by using adversarial examples (AEs) to introduce subtle perturbations to normal images, and these perturbations could deceive the underlying machine-learning model into making incorrect detection and classification. Numerous efforts have been devoted to investigating AEs in TSR systems, and recent focus has shifted from the digital domain [3-6] to the physical domain [7-18], most of which leverage light signals (e.g., [11, 12]), sound signals (e.g., [13, 14]), and adversarial patches (e.g., [15-18]).\nAmong recently revealed physical AEs, adversarial patches appear to be the most \"notorious\" one due to their cost- efficiency and high attack effectiveness. For example, these physical adversarial patches were achieved by applying conspicuous stickers [15\u201317] or printed perturbations [19-22] to traffic signs, which are easy to deploy with low cost. Moreover, some patches were even generated by simulating natural phenomena, such as shadows [23] or raindrops [24], to make these patches more stealthy and hard to notice.\nUnfortunately, the severeness of physical AEs has not been fully uncovered but only scratches the tip of the iceberg. In general, state-of-the-art physical AEs have two major issues to work properly in practice. First, though attempted to be stealthy, most physical AEs are noticeable to humans and raise conspicuous because they often use bright colors or intricate patterns to trick TSR systems, making them doubtful in practice. Additionally, these patches often fail to blend with surroundings in terms of color, texture, or shape, leading to easy detection. For instance, implementing adversarial patches with shadows [23] requires placing obstacles in front of traffic signs, which further draws attention. Second, state-of-the-art physical AEs for adversarial patches are static ones that cannot be altered once deployed, which limits the attacker's ability to control the attack process. As a result, these patches indiscriminately target all vehicles, which increases the risk of detection by recent countermeasures [25, 26]. Unfortunately, recent approaches can only address either of these two issues, not both. For example, TPatch [27] addresses the second issue at a high cost but fails to solve the first one, and it also faces several limitations in real-world deployments, such as the difficulty of deploying attack devices and the susceptibility of attacks to ambient noise.\nIn this work, surprisingly, we discovered a new attack vector, i.e., fluorescent ink, that can significantly address the aforementioned two challenges and advance the state-of-the-art. Specifically, fluorescent ink is transparent in normal environments, and adversarial patches constructed with fluorescent ink are thus invisible and could remain benign under normal circumstances, making them \u201cunnoticeable\". On the other hand, fluorescent ink exhibits fluorescent effects after absorbing specific wavelengths of light, e.g., invisible ultraviolet (UV) light, which allows adversarial attacks to not only be actively triggered on purpose but also \u201cunnoticeable\".\nAlthough fluorescent ink enables invisible and actively triggered features, designing an effective and robust physical adversarial patch remains non-trivial with the following challenges. First, it is challenging to simulate fluorescent effects and determine the optimal choices of massive factors in fluorescent ink, e.g., color, transparency, and size, for achieving high attack effectiveness. Second, fluorescent effects are easily influenced by real-world environments, including surroundings, ambient light, vehicle distance, and speed.\nTo address the above challenges, we design an invisible and triggered physical adversarial patch (ITPATCH) that leverages the aforementioned fluorescent properties. At a high level, an attacker applies carefully designed fluorescent ink to a target sign and later triggers a fluorescent effect using invisible UV light. The resulting fluorescent perturbations cause the TSR system to misclassify the sign, which could potentially lead to traffic accidents. Figure 1 shows an example of our ITPATCH. In more detail, our methodology consists of four key modules. First, we develop a color-edge fusion method to automatically locate traffic signs, enabling precise application of fluorescent ink to the signs themselves, rather than invalid backgrounds. Second, to effectively simulate fluorescent effects, we model fluorescent perturbations on traffic signs by defining the various critical parameters of fluorescent ink, including colors, intensities, and perturbation sizes. Third, we design goal-based and patch-aware loss functions to achieve high attack success rates with minimal perturbations, supporting three attack goals: hiding attack, generative attack, and misclassification attack. Finally, to improve the robustness of ITPATCH in the physical world, we present several fluorescence-specific transformation methods that simulate fluorescence perturbations for real-world attacks. Table 1 summarizes the state-of-the-art physical adversarial patch approaches and our advancements over them.\nWe perform extensive experiments using 10 TSR models to validate our attacks in both digital and physical settings. The evaluation results show that under low-light conditions, the success rates for both generative and misclassification attacks are above 98.31%, while the success rate for hiding attacks is at least 87.81%. Additionally, we conduct ablation studies to examine the impact of various factors, such as color, size, and shape, and test how real-world environments e.g. ambient light and vehicle speed affect the robustness of ITPATCH. We further evaluate the effectiveness of ITPATCH in two specific attack scenarios. It is worth noting that we test 5 common defense mechanisms and find that ITPATCH can achieve an attack success rate of at least 96.72%.\nOur contributions are summarized as follows.\n\u2022 We are the first to introduce fluorescent ink to construct physical adversarial patches.\n\u2022 We design ITPATCH using fluorescent ink that achieves high stealthiness and triggered attacks.\n\u2022 We extensively evaluate ITPATCH for three attack goals under two scenarios in both digital and physical worlds against five popular defenses."}, {"title": "2 Background and Related Works", "content": "Generally, a TSR system is an indispensable component of an autonomous vehicle. The TSR system provides instructions based on traffic signs to enhance driving safety and efficiency. Usually, the TSR system is divided into two main steps: detection and classification. The goal of traffic sign detection is to determine the location of a traffic sign within an image. Traffic sign classification usually uses the results of traffic sign detection as inputs to distinguish the classes of traffic signs. Next, we briefly describe the popular detectors and classifiers. First, Yolov3 [28] and Yolov5 [29] are classical one-stage detectors that achieve accurate object detection by dividing the image into grids and predicting both bounding boxes and categories. Additionally, there are some popular one-stage object detectors, such as SSD [30], RetinaNet [31], and EfficientNet [32]. In contrast, Faster R-CNN [33] is one of the most popular two-stage detectors. Faster R-CNN first screens high-quality candidate target regions using a region proposition network (RPN), and then performs target classification and localization via a convolutional neural network. Some recent works such as HyperNet [34], R-FCN [35], Mask R-CNN [36], and Cascade R-CNN [37] have also improved the performance of Faster R-CNN.\nSecond, the classifiers usually receive images and a series of bounding boxes of traffic signs as input and then output the classification results of these traffic signs. Models such as VGG [38], GoogleNet [39], ResNet [40], and MobileNet [41] are widely used classifiers in TSR systems.\nExisting detectors and classifiers in TSR systems are vulnerable to carefully constructed AEs. In the real world, physical AEs can cause TSRs to misidentify, potentially leading to serious accidents. Next, we present relevant information about physical AEs."}, {"title": "2.2 Physical Adversarial Examples", "content": "Physical AEs are used to fool machine learning models by making noticeable perturbations to physical systems. Unlike traditional digital AEs [4, 25] where input variations are simply limited by $L_p$-norms, the realization of physical AEs is more constrained.\nAs shown in Figure 2, we categorize the related works into two types based on attack targets: Camera-based AE attacks (a-b) and Traffic-Sign-based (TS-based) AE attacks (c-d). Camera-based AE attacks target cameras and modify sensor data in diverse ways. Li et al. [42] developed an adversarial camera sticker. Zolfi et al. [43] generated a translucent adversarial perturbation on a camera lens. Hu et al. [44] used a specially designed color film in front of a camera to generate AEs. Some methods use lasers to attack cameras. Yan et al. [11] proposed injecting adversarial images by illuminating a camera with a laser to create color stripes. However, the film-based methods assume direct access to the camera, which is unrealistic. Once deployed, these attacks are not selectively triggerable. Laser-based attacks are noticeable, and the light source can be easily traced.\nOn the other hand, TS-based AE attacks target traffic signs. Some researchers [15-17, 22] have added stickers, such as black-and-white or monkey-like designs, to traffic signs to create physical AEs. Other works [19, 45-49] have designed perturbed signs for real-world deployment using printers. Some researchers have explored creating physical AEs by simulating natural phenomena like shadows [23], raindrops [24], and light effects [50,51]. However, as shown in Table 1, these methods launch attacks continuously and indiscriminately once deployed.\nRecent works have tried to address the limitations of TS- based AE attacks. Some studies have explored the use of projected light onto traffic signs to deceive TSR systems. The first type operates using visible light with wavelengths ranging from 400 nm to 800nm. Lovisotto et al. [18] introduced short- lived adversarial perturbations with a projector, while Duan et al. [52] used laser beams directly. However, these light sources are easily tracked, exposing the attacker. Additionally, the projector used in [18] is expensive, costing between $1500 ~ $44379. The second type uses invisible light. Sato et al. [12] proposed an IR laser reflection attack to mislead AV perception modules. However, according to the reports from research organizations [53, 54] and manufacturers [55, 56] most commercial cameras are equipped with IR-Cut filters, making these attacks easily countered. Additionally, Zhu et al. [27] designed a physical adversarial patch triggered by acoustic signals. However, their method is impractical due to the difficulty in using ultrasonic devices and can be defended by physical signal protection mechanisms [57,58]."}, {"title": "3 Threat Model", "content": "(1) Attack scenarios. We consider two attack scenarios where TSR systems are deceived into making incorrect decisions about traffic signs.\n\u2022 Time-specific attack. In this scenario, the attacker uses UV lamps to irradiate traffic signs during specific time windows to trigger the attack, avoiding detection by not activating the attack outside these periods. Based on the National Safety Council (NSC) report [59], the attacker may choose a time between 4 p.m. and 11:59 p.m., when drivers are more likely to be involved in traffic accidents due to reduced visibility.\n\u2022 Vehicle-specific attack. In this scenario, the attacker targets a specific vehicle, initiating the attack only as that vehicle approaches a traffic sign. This ensures that only the targeted vehicle misinterprets the traffic sign, while other vehicles passing before or after the attack are unaffected, reducing the likelihood of detection. This type of attack is brief and stealthy, designed to go unnoticed.\n(2) Attack goals. An attacker's goal is to make the TSR system make wrong decisions against the instructions of traffic signs. As stated in Section 2.1, the TSR system predicts both bounding boxes and categories. Existing work usually only considers misclassification. Based on the output of the TSR system, we conduct a systematic analysis and propose three attacks. For detection, we propose the hiding attack and the generative attack. For classification, the misrecognition attack can be constructed. The specific definitions are as follows.\n\u2022 Hiding attack. An attacker obfuscates a TSR system to cause failure in detecting an existing traffic sign.\n\u2022 Generative attack. An attacker causes a TSR system to detect a forged traffic sign.\n\u2022 Misrecognition attack. An attacker causes a TSR system to misclassify a traffic sign.\n(3) Attacker capabilities. In this work, we assume that the attack is black-box based, i.e., the attacker does not have direct access to the internal details of the target model, such as its architecture, parameters, or gradients. This assumption is highly realistic. Developers typically do not disclose model details in TSR systems, and even if an adversary purchases the same vehicle, they have access only to the model's outputs, with no additional information available.\nWe assume the attacker has the following capabilities.\n\u2022 Direct access to traffic signs. An attacker can physically access traffic signs.\n\u2022 No direct access to a victim's vehicle. An attacker does not have digital or physical access to the victim's vehicle before or during any phase of an attack. The assumption that an attacker makes any changes to the vehicle's camera or the TSR system is impractical in the physical world.\n\u2022 Launching an attack. An attacker has two attack methods. An attacker can launch an attack by either placing a UV lamp by the roadside and controlling it remotely to target the traffic sign, or by driving close to the victim's vehicle and using a UV lamp to target the traffic sign."}, {"title": "4 Feasibility Study", "content": "In this section, we explore the feasibility of using fluorescent ink to attack a TSR system. We introduce the fundamental concepts of fluorescent materials. Following this, we render the fluorescent effect and apply it to traffic signs, which are then analyzed by a TSR system."}, {"title": "4.1 Fluorescent Materials", "content": "Fluorescence [61] occurs in certain molecules, called fluorophores (typically polyaromatic hydrocarbons or heterocycles), through a three-stage process illustrated in the jablonski energy diagram [60] (Figure 3).\nFirst (1), a photon with energy $h\\nu_{ex}$ from an external source with wavelength $\\lambda_{ex}$ (like an incandescent lamp or laser) is absorbed by the fluorophore, creating an excited singlet state $S_1$.\nSecond (2), during its excited state, which lasts a few nanoseconds, the fluorophore undergoes conformational changes and interacts with its environment. These interactions cause energy dissipation, resulting in a relaxed singlet state $S_2$, from which fluorescence emission occurs. Not all molecules return to the ground state $S_0$ via fluorescence. Some molecules are depopulated through processes like collisional quenching and intersystem crossing [62].\nFinally (3), a photon with energy $h\\nu_{em}$ is emitted, returning the fluorophore to its ground state $S_0$. Due to energy dissipation, the emitted photon has lower energy and a longer wavelength than the excitation photon $h\\nu_{Ex}$. The difference, $(h\\nu_{ex}-h\\nu_{em})$, is called the stokes shift [63].\nFluorescent materials can be either solid or liquid. Solid materials like phosphors are difficult to attach to targets and lack stealthiness. This paper focuses on fluorescent ink, which is transparent when not triggered, hard to detect, and easy to apply to targets."}, {"title": "4.2 Fluorescent materials rendering", "content": "In this section, we introduce the main parameters of fluorescent materials and how they render fluorescent effects on the surfaces of objects. The key parameters are fluorescence quantum yield [64], fluorescence excitation spectrum, and fluorescence emission spectrum [65]. The fluorescence quantum yield is the ratio of the number of fluorescence photons emitted to the number of photons absorbed. It measures the efficiency of the fluorescence process. A fluorescence excitation spectrum is obtained by fixing the emission wavelength (typically at the maximum emission intensity) and scanning the excitation wavelength. Since excitation leads to the molecule reaching the excited state upon absorption, the excitation spectrum effectively represents the absorption characteristics. A fluorescence emission spectrum is obtained by fixing the excitation wavelength and scanning the emission wavelength to produce a plot of intensity versus emission wavelength. For instance, if we fix the excitation at wavelength B (350nm) in Figure 4 and scan the emission spectrum between 430nm and 580nm, we obtain the emission spectrum corresponding to wavelength B. It is important to note that illuminating a fluorophore at its excitation maximum produces the greatest fluorescence output. However, illuminating at other wavelengths only affects the intensity of the emitted light, without changing the range or overall shape of the emission profile.\nTo render fluorescent effects on the surface of objects, we use the bidirectional scattering distribution function (BSDF) [66], a general representation of the optical properties of surface reflection and transmission. Utilizing the Ocean light simulator [67], we incorporate the specific parameters mentioned above into the fluorescence BSDF model. Figure 5 shows multiple examples of rendering. The left ball is a control sample without fluorescence, while the right ball represents a fluorophore. Note that this fluorophore is hypothetical and created solely for demonstration purposes."}, {"title": "4.3 TSR with Fluorescent Materials", "content": "To investigate the feasibility of fooling a TSR system, we separately render three common colors, i.e. red, green, and blue, of fluorescent materials onto the surface of a traffic sign and feed the resulting images into the TSR system. The excitation and emission spectra of the fluorescent materials are depicted in Figure 6 (a). The optimal trigger wavelengths for red, blue, and green fluorescent materials are 348 nm, 360nm, and 430 nm, respectively.\nIn this section, we use standard stop signs and manually annotate their locations in images. We then apply different fluorescent materials to the surfaces of these signs and submit the modified images to the Yolov3 model for recognition. The model's confidence scores for detecting stop signs are shown in Figure 6 (b). The results show that fluorescent materials can effectively lower the model's confidence in recognizing stop signs, confirming the feasibility of this attack. Red fluorescent material significantly reduces the confidence score more than green and blue, likely due to the model's sensitivity to longer wavelengths. Green fluorescent material also lowers the confidence score over a wider wavelength range, thanks to its broad excitation spectrum.\nFrom the above experiments, we can draw the following conclusions: First, a TSR system can be successfully attacked using fluorescent materials. However, the success of such an attack is not guaranteed, as the confidence scores are highly sensitive to the wavelength used. Second, various factors-such as fluorescence intensity, perturbation placement, and ambient light-significantly affect the attack's effectiveness. Therefore, the same set of fluorescence parameters cannot be universally applied to different traffic signs. There are still technical challenges to address, which we will discuss in the next section."}, {"title": "5 Methodology", "content": "To implement ITPATCH in the physical world, it is essential to overcome the following challenges:\nChallenge 1: How to accurately model fluorescent ink and determine the most effective attack parameters for ITPATCH?\nChallenge 2: How to enhance the robustness of ITPATCH by leveraging the properties of fluorescent ink, making it more viable for real-world application?\nTo address these challenges, we propose a four-module ITPATCH attack framework, as illustrated in Figure 7. The Automatic Traffic Sign Localization module automatically detects the valid region on a traffic sign for adding perturbations. The Fluorescence Modeling module simulates the application of fluorescent ink by adding colored circles with varying parameters to the identified region, replicating the perturbation effects. The Fluorescence Optimization module optimizes these parameters using goal-based and patch-aware loss functions and employs a particle swarm optimization algorithm to identify the most effective attack configuration. These three modules collectively address Challenge 1.\nTo tackle Challenge 2, the Robustness Improvement module customizes multiple transformation distributions to enhance the real-world robustness of ITPATCH. The following subsections provide a detailed explanation of each step."}, {"title": "5.1 Problem Formulation", "content": "Given an input image $x \\in R^d$ for a traffic sign with the class label $y \\in [1,2, ...,k]$, a DNN-based classifier $f: R^d \\rightarrow R^k$ is trained to derive the predicted label $\\tilde{y}$:\n$\\tilde{y} = \\underset{y}{argmax} f(x) \\qquad (1)$\nwhere $f(x)$ is the confidence score for all k labels. The goal of our proposed method is to add fluorescent ink $\\delta$ to the target object to produce adversarial samples $x_{adv} = x + \\delta$, which causes the model to misclassification:\n$\\underset{y}{argmax} f(x) = \\underset{y}{argmax} f(x_{adv}) \\qquad (2)$\nMeanwhile, the perturbation added to $x_{adv}$ should be minimized to ensure that $x_{adv}$ remains inconspicuous to humans and avoids detection."}, {"title": "5.2 Automatic Traffic Sign Localization", "content": "TSR systems typically predict bounding boxes to mark the approximate locations of traffic signs, but these areas often include extra space, such as background or other elements. Since fluorescent ink can only be applied to the actual surface of the traffic signs, an attacker must precisely locate the valid areas of the signs. Unlike previous approaches that rely on manually marking traffic signs, our goal is to automatically identify the regions of traffic signs in images for precise placement of perturbations. To achieve this, we propose the following three steps: (1) Enhance the contrast of the input image or frame to better distinguish traffic signs from the background. (2) Segment the region by detecting the edges of the traffic signs. (3) Identify the exact location of traffic signs based on their color characteristics.\nHistogram equalization. In the first step, we preprocess the data containing traffic signs. We apply histogram equalization [68] to images that meet the contrast condition (3) to enhance their contrast, which aids in better detection of traffic sign regions. Specifically, histogram equalization is used if the input image x satisfies the following condition:\n$\\frac{P_{99}(t(x(i, j))) - P_{1}(t(x(i, j)))}{\\text{max}(t(x(i, j))) \u2013 \\text{min}(t(x(i, j)))} < T_h \\qquad (3)$\nwhere $t(x(i, j))$ represents the pixel intensity at coordinates $i$ and $j$ in the image $x$. Here, $P_{99}$ and $P_{1}$ are the 99th and 1st percentile of pixel values, respectively, and $T_h$ is a threshold fraction, set to 0.05 as in [69]. $P_{99}$, $P_{1}$ and $T_h$ are adaptive parameters for this process.\nCanny edge detection. In the second step, we find that most of the traffic signs have regular shapes, such as circles, rectangles, and triangles. Different regular shapes correspond to different thresholds. Therefore, we use the canny edge detector [70] with a selected threshold to detect the edge in image x. With customized high and low thresholds, we filter out non-edge information and highlight the edges of traffic signs in the image.\nColor-based detection. In the third step, we identify that the key colors in most traffic signs are yellow, blue, red, and black. We propose a color-based detection algorithm with the following steps. First, we define the lower and upper HSV color space [71] tuples for each color in Table 2. Geometrically, these tuples define boxes in the HSV color space. Voxels in the input image falling inside these boxes are assigned a value of \"255\" in the output array, while those outside are assigned \"0\". Next, we merge the four color masks using a bitwise OR operator. We then apply morphological operations: opening to remove noise and small white specks, and closing to fill gaps. Finally, we compare the areas identified by the two detectors. The larger area is selected as the region A of the traffic sign, and the mask matrix $M_A$ is determined accordingly.\n$M_A = \\begin{cases} 1, & \\text{if } (i, j) \\in A \\\\ 0, & \\text{otherwise} \\end{cases} \\qquad (4)$\nThe results of our localization method, shown in Figure 8, demonstrate its accuracy in identifying both the exterior and interior of traffic signs. By pinpointing different regions of the traffic sign, the method can apply perturbations more precisely within the valid areas."}, {"title": "5.3 Fluorescence Modeling", "content": "After identifying the legal area for perturbation, we aim to simulate the effect of fluorescent ink on a traffic sign, particularly under UV light. We observe that fluorescent ink typically appears semi-transparent and does not fully cover the traffic signs. To achieve this simulation, we follow three main steps: (1) Defining the parameters of the fluorescent ink, (2) Simulate the effect of the fluorescent ink on traffic signs, (3) Consider the interaction between light, traffic signs, and fluorescent ink.\nFluorescence definition. First, we assume that the fluorescent ink is used to draw a circle, then the parameters of circle $C_0$ are defined as follows:\n$\\theta_0 = ((x_0, y_0), r_0, \\gamma_0, \\alpha_0) \\qquad (5)$\ncorresponding to the following aspects of the circle $C_0$:\n\u2022 $(x_0, y_0) \\in [W, H] \\subset R^2$: Coordinates of the circle in an image with width W and height H.\n\u2022 $r_0 \\in [r_{\\text{min}}, r_{\\text{max}}] \\subset R$: Radius of the circle relative to the patch size.\n\u2022 $\\gamma_0 = [R_0, G_0, B_0] \\subset R^3$: RGB color triplet of the circle.\n\u2022 $\\alpha_0 \\in [0, 1] \\in R$: Opacity level of the circle.\nPerturbation function. To use fluorescent ink for physical adversarial attacks, we need to approximate its effect on a traffic sign. Due to the optical properties of fluorescent ink, applying it creates a small patch on the image. This overlay effect can be simulated using alpha blending between the original image and the fluorescent ink, adjusting for size and color.\nMore formally, let x be a 2D image where x(i, j) denotes the pixel at the (i, j) location. We define the perturbation function for a single circle in the image, $\\pi(x; \\theta_0)$, as follows:\n$\\pi(x; \\theta_0) (i, j) = x(i, j) \\cdot (1 - a(i, j)) + a(i, j) \\cdot \\gamma_0 \\qquad (6)$\nIntuitively, each pixel $\\pi(x; \\theta_0)(i, j)$ in the perturbed image is a linear combination of the original pixel and the color $\\gamma_0$, weighted by the position-dependent alpha mask $a_0$. To create our perturbed image, we combine K single-circle $(C_0,..., C_{K-1})$ as follows:\n$\\pi(x; \\Theta) = \\pi(x; \\theta_0) \\circ \\pi(x; \\theta_1) \\circ \u2026 \\circ \\pi(x; \\theta_{K-1}) \\qquad (7)$\nwhere the total parameters $\\Theta = (\\theta_0,..., \\theta_{K-1})$ are the concatenation of the parameters for each circle.\nFluorescence intensity. In addition to the variations caused by fluorescent ink, another crucial factor in our scheme is the relationship between UV light intensity and fluorescence intensity in real-world conditions. UV light intensity impacts the entire traffic sign, making regions with fluorescent material appear brighter. However, the precise relationship between UV light intensity and fluorescence is not well-defined. In this study, UV light intensity primarily affects the illumination of the traffic sign area A, while other components remain unchanged. To model this, we convert the image from RGB to LAB color space [72] and focus on the luminance (L) channel for area A. Different UV light intensities are simulated by scaling the L channel in LAB space by a factor $l_1$. For the region with fluorescent ink, F, the L channel is scaled by a coefficient $l_2$, where $l_2 > l_1$. Specifically, starting with a clean image x in RGB color space, we first convert x to LAB color space:\n$LAB(x) = [L_x, A_x, B_x] \\qquad (8)$\nGiven masks $M_A$ and $M_F$, the value of pixel (i, j) in the adversarial image $x_{adv}$ can be calculated as follows:\n$LAB(x_{adv})(i, j) = \\begin{cases} LAB(x)(i, j) \\cdot [l_1, 1, 1]^T, & (i, j) \\in A  \\land (i, j) \\notin F\\\\ LAB(x)(i, j) \\cdot [l_2, 1, 1]^T, & (i, j) \\in F\\\\ LAB(x)(i, j) \\cdot [1, 1, 1]^T, & (i, j) \\notin A \\end{cases} \\qquad (9)$\nFinally, we convert $x_{adv}$ back to RGB color space. We refer to the entire AE generation process as:\n$x_{adv} = LAB(\\pi(x; \\Theta)) = LAB(\\pi(x; \\theta_0) \\circ \u2026 \\circ \\pi(x; \\theta_{K})) \\qquad (10)$"}, {"title": "5.4 Fluorescence Optimization", "content": "After modeling the fluorescent effect, the next step is to optimize the parameter $\\Theta$ to maximize the attack success rate. Unlike previous adversarial patches that lack stealthiness, the properties of fluorescent ink ensure that ITPATCH remains undetectable when not triggered, as illustrated in Figure 9. Our primary focus is on deceiving detectors, classifiers, or other victim systems during an attack. We consider two main types of loss functions: $l_{opt}$ and $l_{area}$. The full customized loss function is defined as follows:\n$\\underset{\\Theta \\in \\Theta}{min} E_{x \\sim X, t \\sim T} [l_{opt} + \\lambda l_{area}] \\qquad (11)$\nwhere $\\Theta$ is the attack parameters, x represents the input image, and t denotes a random transformation. X and T correspond to their respective distributions, E denotes the expectation, and $\\lambda$ is a weighting factor used to balance the different components of the loss function.\nGoal-based loss. The goal-based loss $l_{opt}$ is tied to the attack objectives, allowing the attacker to apply different $l_{opt}$ depending on the specific attack goals.\nFor a hiding attack, an attacker attempts to eliminate the detection results. Using the output of an object detection model, the attacker can minimize the confidence score of the detector:\n$l_{opt} = \\alpha Pr(objects) Pr(classes) + \\beta IoU_{predicted} \\qquad (12)$\nwhere $Pr(objects)$ and $Pr(classes)$ correspond to the Yolo output, which provides two confidence scores for each cell in the detection grid: (1) Object score: indicates whether a specific cell in the grid contains an object. 2) Class score: reflects the classification confidence for a particular cell. Additionally, the attacker minimizes the \u201cintersection over union\" (IoU) score between the predicted bounding box and the ground truth bounding box. $\\beta$ is a manually set penalty term. This strategy forces the detector to inaccurately predict the bounding box location, resulting in the incorrect detection of the object's position.\nFor Generative Attack, an attacker aims to improve the confidence of bounding boxes by minimizing Equation 13:\n$l_{opt} = -Pr(object) Pr(class) \\qquad (13)$\nThe attacker aims to have the detector recognize the forged traffic signs. To achieve this, the attacker focuses on increasing the detector's confidence in its output and does not need to minimize the IoU score.\nFor Misclassification Attack, an attacker attempts to reduce the original category's score:\n$l_{opt} = -log(p_y) \\qquad (14)$\nwhere p is the vector of probabilities, and $p_y$ denotes the probability of the original category y. As $p_y$ decreases, the probabilities of other categories increase, which can lead to a change in the model's predicted category.\nPatch area loss. To introduce the smallest perturbation possible, we minimize the loss by calculating the area:\n$l_{area} = \\underset{r \\in [r_{\\text{min}}, r_{\\text{max}}]}{min} \\sum_{i=1}^K \\pi r_i^2 \\qquad (15)$\nwhere K is the number of circles and r is the radius of each circle. The goal is to make the perturbation subtle enough that the driver does not notice any anomaly, while the TSR system is led to make an incorrect decision.\nParticle swarm optimization. In the black-box setting with discrete coordinate values in, we need an optimization algorithm capable of global search without relying on gradients. We use particle swarm optimization (PSO) [73], inspired by the way bird flocks search for food. PSO leverages cooperation and information sharing among individuals in a population to find a valid solution efficiently without gradient information. Additionally, PSO is robust to the initial settings, aligning with our use of random initialization for parameters like perturbation position and color. To enhance success rates, we employ the n-random-restarts strategy, allowing us to reinitialize and rerun the PSO up to n \u2013 1 times if the attack fails."}, {"title": "5.5 Robustness Improvement", "content": "There are two challenges to improving the robustness of ITPATCH in the real world. (1) The captured patches may be different from digital patches due to factors such as distance and angle during recording. (2) As the placement time grows, fluorescent inks may be slightly visible even when the attack is not triggered. To address these challenges, we use expectation over transformation (EOT) to handle variability in captured patches and develop a transparency transformation to manage changes in ink visibility over time."}, {"title": "6 Evaluation", "content": "In this section, we evaluate the attack's performance in both digital-world and real-world environments."}, {"title": "6.1 Digital-world Attacks", "content": "Metrics In this section, we define the attack success rate (ASR) Equation 16 to evaluate ITPATCH attacks. ASR measures both the success of the attack and its stealthiness, ensuring that the traffic signs are correctly classified by the model when the attack is not triggered.\n$\\text{ASR} = \\frac{1}{N} \\sum_{i=1}^{N} I_{F(x_{untri})=y \\& F(x_{tri})\\neq y}(x) \\qquad (16)$\nwhere N is the total number of frames or input images, I is the indicator, F represents the model's prediction function, and y is the original prediction label. The indicator I(x) equals 1 if the model's prediction is y when the attack is not triggered, and 0 if the model misclassifies when the"}]}