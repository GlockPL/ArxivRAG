{"title": "FedAT: Federated Adversarial Training for Distributed Insider Threat Detection", "authors": ["R G Gayathri", "Atul Sajjanhar", "Md Palash Uddin", "Yong Xiang"], "abstract": "Insider threats usually occur from within the workplace, where the attacker is an entity closely associated with the organization. The sequence of actions the entities take on the resources to which they have access rights allows us to identify the insiders. Insider Threat Detection (ITD) using Machine Learning (ML)-based approaches gained attention in the last few years. However, most techniques employed centralized ML methods to perform such an ITD. Organizations operating from multiple locations cannot contribute to the centralized models as the data is generated from various locations. In particular, the user behavior data, which is the primary source of ITD, cannot be shared among the locations due to privacy concerns. Additionally, the data distributed across various locations result in extreme class imbalance due to the rarity of attacks. Federated Learning (FL), a distributed data modeling paradigm, gained much interest recently. However, FL-enabled ITD is not yet explored, and it still needs research to study the significant issues of its implementation in practical settings. As such, our work investigates an FL-enabled multiclass ITD paradigm that considers non-Independent and Identically Distributed (non-IID) data distribution to detect insider threats from different locations (clients) of an organization. Specifically, we propose a Federated Adversarial Training (FedAT) approach using a generative model to alleviate the extreme data skewness arising from the non-IID data distribution among the clients. Besides, we propose to utilize a Self-normalized Neural Network-based Multi-Layer Perceptron (SNN-MLP) model to improve ITD. We perform comprehensive experiments and compare the results with the benchmarks to manifest the enhanced performance of the proposed FedAT-driven ITD scheme.", "sections": [{"title": "I. INTRODUCTION", "content": "Insider threats are attacks that originate within the organization from entities that are directly or indirectly associated with the resources of the organization. Though these types of attacks often happen unintentionally, the consequences can be very critical [1]. Due to the nature of the attack, it will be mostly left unnoticed. User behavior analysis requires access to resource log files from the organizations. The data utilized in Insider Threat Detection (ITD) are collected from within the organizations, including logging details, web access patterns, email communications, external device usage, file transfer, etc. ITD is usually performed using conventional Machine Learning (ML)-based methods. However, organizations spread across multiple locations require distributed processing of the data so that the data from all locations contribute to the ITD process. The rarity of insider threats results in skewed class distributions. Moreover, sharing the confidential user data distributed across the various locations to the centralized model can cause privacy concerns. The above-mentioned reasons motivate us to leverage Federated Learning (FL) [2] for effective ITD for an organization that is geographically located in multiple places.\nFL was presented as a deep collaborative (parallel and distributed) learning paradigm to overcome the privacy concerns of the centralized ML approaches [2]. In FL, the end devices (also known as clients or parties, or users) only communicate partial updates of a global neural network model, which are then compiled by a central entity (aka server, aggregator, or coordinator). Since FL never allows to share of user data with outside parties directly, using it is meant to promote privacy for the users. As such, FL-based schemes are being employed in numerous application domains, such as natural language processing [3], Internet of Things (IoT) [4], and health care [5].\nSeveral organizations can cooperatively train a neural network (deep) model for ITD with the help of FL without utilizing shared network data. The performance of the ITD model is enhanced while the training dataset is expanded. On the one hand, according to studies, the volume of training data impacts the efficiency of the ML or Deep Learning (DL)-based detection models [6]. The internal resource logs are highly confidential, and some clients may have fewer data, while the minimal data for each malicious behavior results in weak individual models. Local data collection is not advised in such a case, as the information is very private and sensitive. Each resource has unique user behavior patterns that can be used to train the detection system. However, the model performance would significantly be improved when data from all locations of the organization could be used for training. Therefore, it is impractical to centralize the data for training because of resource constraints, security problems, and privacy considerations. On the other hand, the data residing in multiple locations can have a different sample space in classes, and the heterogeneous datasets stored in the client locations possess a non-Independent and Identically Distributed (non-IID) property. In addition, due to the rarity of insider activities, all the malicious scenarios need not be available in all the locations, leading to class-level data imbalance within the clients. To mitigate these two serious difficulties (clients' data privacy"}, {"title": "II. PRELIMINARIES", "content": "This section provides the background of the key concepts (ITD, FL, and AT) adopted toward the motivation of this paper."}, {"title": "A. Insider Threat Detection in Distributed Setting", "content": "The analysis of insider threats has been researched extensively for many years [7]\u2013[10]. However, the research community could not significantly contribute to this attack in a distributed setting. Due to the rise in attack frequency and the emergence of potential data analysis methods, it now draws more attention. Through FL, many organizations can train DL models collaboratively in parallel for ITD independently. Various institutions with significant employees and resource access logs, as in domains like healthcare, education, and finance, may be among the FL participants in the FL-driven pipeline for ITD. Implementing FL in this way is particularly crucial as the organizations never agree to share the data for privacy and confidentiality reasons. However, such a potential distributed approach for ITD is not yet studied."}, {"title": "B. Federated Learning", "content": "FL is an ML framework that bases data use for ML on data security and privacy [2]. Google came up with the idea first. A server and a set of clients comprise the fundamental building blocks of the FL paradigm. The server does not gather data, rather than it gathers model parameters only. Each client maintains the local training dataset, while the server manages client participation in training. The training data is stored locally by the client and used to train the local model before uploading its parameters to the server. For the subsequent training round, the server computes the average of the collected parameters and shares them with each client for retraining. Various aggregation methods are used to synchronize the client models with the global weights. One of the popular aggregation methods is FedAvg [11] which performs the arithmetic averaging of the client parameters. Another method refers to as FedProx [12] adds a proximal term to the local objective function of the client and performs the same aggregation as of FedAvg."}, {"title": "1) Local Model Update in FL", "content": "The FL strategy seeks to minimize the following overall objective function (F(w)) in a parallel way, where Lk(w) is the kth client's (k\u2208 [1, K]) local objective function and K is the total number of clients participating in the training process.\nminWERd\n$\nF(0) = \\sum_{k=1}^{K} \\frac{N_k}{N} L_k(w),\n$\n(1)\nwhere Nk represents the total number of samples of the kth client, N = \u2211k=1 Nk, and Lk(w) is calculated using the sample (xi) loss, li as follows.\n$\nL_k(w) = \\frac{1}{N_k} \\sum_{i=1}^{N_k} \\ell_i (w, x_i).\n$\n(2)\nIn this way, as the model's weight (w) changes, the FL minimizes the weighted average of the clients' local losses (Lk(w)), hence lowering the cumulative loss function (F(w)). The two most promising federated optimization algorithms, FedAvg and FedProx, are now presented to demonstrate how to minimize the Eq. (1) in our proposed FL-driven ITD setup. FedAvg starts the training process by sending the first global model to a small sample of clients. The retrieved shared global model is then trained in parallel on each client's private data samples, and the trained model is then uploaded to the FL server for aggregation. Until convergence, the training and aggregation procedures are repeated. However, FedProx alters the local objective of Eq. (2) by inserting a proximal factor, as shown below, and then follows the same processes as FedAvg.\n$\nW_{t+1}^{k} \\leftarrow \\underset{w}{\\text{min}} L_k (W_{t+1},t) = L_k(w_{t+1}) + \\frac{\\mu}{2} \\lVert w_{t+1}^{k} - w_{t}\\rVert_2^2,\n$\n(3)\nwhere u represents the regularized coefficient."}, {"title": "2) Global Model Aggregation in FL", "content": "During a global round, all locally trained models are uploaded to the server, and then the global model aggregation is accomplished using the traditional arithmetic mean method. The server specifically calculates the aggregate global model (wt+1) as the weighted"}, {"title": "C. Adversarial Training", "content": "Adversarial samples are data samples that an attacker can design to make the model intentionally make mistakes [13], which are employed for varying purposes, such as developing robust models, and data augmentation [14]. The work in [15] considered adversarial samples as features where the sensitivity to well-generalizing features in the data directly leads to adversarial vulnerability. GAN [16] proved to be an efficient method to generate adversarial samples. The two fundamental models in GAN are the generative model (G), and the discriminative model (D). The G model makes an effort to provide examples that fool the D model. When the GAN has finished training, the D model cannot distinguish between samples produced by the G model and actual data. Technically, G takes a uniform random noise z as input and generates synthetic (fake) data samples that closely mimic the original data distribution; it tries to learn the probability P(X) for input X. D tries to distinguish between the real and fake data samples; it learns the conditional probability P(Y|X) for input X with class labels Y. G is trained to maximize the classification error between the real and the fake data while D is trained to minimize the same. In this way, the GAN training follows a game theory principle of reaching an equilibrium when the generator produces data from the original distribution such that the discriminator fails to identify between real and fake and gives a probability of flipping the coin. The GAN training happens such that G and D converge together. What follows, the below equation depicts the GAN optimization.\n$\n\\underset{G}{\\text{min}} \\underset{D}{\\text{max}} \\mathbb{E}_{x \\sim p_{data} (x)} [\\text{log} D(x)] + \\mathbb{E}_{z \\sim p_z(z)} [1 \u2013 \\text{log} D(G(z))].\n$\n(5)\nConditional GAN (CGAN) [17] is an extended mechanism of the vanilla-GAN. Compared to vanilla-GAN, the condition variable, which is additional information, must be present in the input variables of the generator of the CGAN. Class labels of the actual data are generally used as the conditioning information. ACGAN [18], a variant of CGAN, is capable of controlling the output with additional input. The input to the G model of ACGAN is noise from latent space and the class label from the original dataset to condition the data generation. But the D model of ACGAN considers only the real and synthetic data samples. Like CGAN, the D model of ACGAN predicts whether the given data is real or fake along with the class label. In [19], the authors adopted adversarial techniques to the constraints of the federated environment to align the representations learned among many clients. Although the"}, {"title": "D. Motivation", "content": "FL proved its efficiency in numerous application domains including intrusion detection [20], natural language processing [3], and health care [5] while it is adopted for distributed anomaly detection in numerous domains, such as industrial control, and IoT field. However, there is no existing ITD research that leverages FL in various scenarios (classes). We observe that insider threats are a classical real-world example of the extreme imbalance in classes within and across the clients in an FL setting. Motivated by the success of solution approaches that adopt FL for distributed training and AT for effective data augmentation, we propose a Federated AT (FedAT) for effective ITD in this paper."}, {"title": "III. PROPOSED APPROACH", "content": null}, {"title": "A. Approach Overview", "content": "Insiders are entities associated with the organization having access to one or more organizational resources. The activities of an entity associated with the organization referred to as scenarios (classes) identify the action sequences resulting in the insider threat. Organizations operate from multiple places scattered across different locations. Distributed analysis methods can help build effective threat detection, and FL can be an appropriate choice in this regard. As such, we propose a FedAT-enabled ITD approach that can help work in a real-world distributed setting.\nWe consider an organizational environment that uses data from multiple client locations, where the clients do not contain all the scenarios of data samples. In this way, the data follows a non-IID setting that results in class-level imbalance across the clients. In addition, due to the rarity of the insider threat and the fewer chances of noticing suspicious actions, each client has a class imbalance among the malicious and non-malicious insider scenarios. In particular, let us consider a real-world setting, where there are K clients and an aggregation server S. In addition, let each client have its private dataset. Then, Fig. 1 provides an overall architecture being followed in the proposed FedAT-driven ITD framework.\nAs illustrated in Fig. 1, the overall process is split into the following sequential stages: (i) distributed feature space generation; and (ii) and FedAT followed by the multiclass classification using SNN-MLP. Particularly, in the first stage, the clients perform the feature generation and pre-processing of the heterogeneous resource access files in the respective locations, as shown in Fig. 1. The labeled data in each client results in a drastic class imbalance that hinders the performance of any ML algorithm. The private dataset of the client is the input to the second stage of the FedAT process, including the synthetic data generation and the AT that performs the multiclass classification for insider threat detection. Once the local training (FedAT) is complete, the local model updates are uploaded to the server. The server then performs the model aggregation, and the updated model is broadcasted again to the clients for retraining with FedAT."}, {"title": "B. Distributed Feature Space Generation", "content": "Implementing the cooperative training model with other organizations working in the same field is more important for obtaining a superior DL-based ITD model. The clients of FL are these organizations. The server can be in the cloud. Once FL is completely implemented, each client will automatically connect to the server. Depending on the circumstances, the client can also terminate FL whenever appropriate. All clients do not have to engage in each cycle of learning simultaneously with FL. The input for the ITD is the behavior of the users. The user behavior is extracted from the heterogeneous resource access files obtained from within the organizations. The activi- ties include the logon-logoff details, the email communication, the web access pattern, the external device, file usage, etc. The user behavior pattern specifies the malicious non-malicious action sequence. Any deviation from normal behavior results in suspicious activity. In this work, we follow the feature extraction adopted in [21] and reformulate in our FL setting, while Fig. 2 provides an overview of the non-IID feature generation followed in this work of distributed setting. As seen in Fig. 2, each client performs private feature extraction from the heterogeneous files to generate its private ITD dataset. The set of employee activities that result in a malicious action is referred to as a scenario (class). Each client will have different scenarios present in its dataset, resulting in heterogeneity in"}, {"title": "C. FedAT", "content": "The privacy concerns of the employee data pose a hindrance to effective ITD. FL is among the most effective methods for safeguarding data privacy in ML models. The client's data is kept secure by simply providing the model's updated weights and not the actual data. This strategy, which retrains each client's model using baseline data, addresses the problem of non-IID data. As such, we propose an FL-driven method for distributed ITD. As per the proposed architecture (Fig. 1), there are K clients distributed across various locations. To avoid sharing private data, the clients perform local model building at the client site, and the model parameters are shared with the server. The server conducts model aggregation using promising optimization methods like FedAvg and FedProx. However, the non-IID data residing in the client locations have a drastic class imbalance, which affects the performance of the federated training; hence raises the need to address the class-level data scarcity in the clients, which inspires us to augment the minority samples across the client locations. In addition, when the training data is scarce, the traditional FL models tend to perform poorly and produce higher false alarm rates. To address these issues, we propose to adopt the GAN network to synthesize the minority data samples in the FL setting for effective ITD.\nInspired by the GAN-based FL works, such as Multiple Discriminators-based GAN (MDGAN) [23] and FL-GAN [22] models, which are proposed for protecting the privacy and creating synthetic data, we thoughtfully leverage GAN in this work. In MDGAN, there are multiple D models at the client locations and just one G model at the server. The data from the G model is shared among various clients by distributing the data. In the FL-GAN architecture, the workers (clients) also have G models and D models in addition to the server. FL-GAN distributes data and shares the updates averaged by the server with the clients. However, in our FedAT-driven ITD framework, each client has only one G model to lightweight the client-side computation, which is used to create synthetic insider samples that resemble those produced by standard"}, {"title": "1) Federated Data Augmentation using AT", "content": "AT using synthetic data samples has certain advantages in FL for distributed ITD. When the training data is mixed with other synthetic data that computes different parameters, launching a member inference and inversion attack to get the real dataset or a sample of the dataset becomes difficult. In addition, the order of the parameter transfer and aggregation techniques affects the model's accuracy. With these arguments, we investigate ITD models built using GANs. We design a GAN-based FL setting for ITD using multiclass classification. The approach uses an ACGAN in each client. The client performs two processes: (i) ACGAN training to generate synthetic data, which provides the model to generate data for specific scenarios (classes), and (ii) multiclass classification using our designed SNN-MLP model. Fig. 3 shows that each client has a G model and a Classifier (C) as the D model. The G model generates the synthetic data samples from a Gaussian distribution z and the class labels {y1..yc} of the original samples present in that client. The D (C) model in our ACGAN architecture is a classifier that takes the real and generated data as inputs and provides a classification outcome. Therefore, AT happens to the local clients. The operations of the D model (aka the C model) are performed by the SNN-MLP. The label information from each client is passed on to the server as auxiliary information. This information is used by the other clients in the succeeding training rounds, which helps fine-tune the other local C models in the learning process, resulting in turn in the development of a robust model. Once the GAN training is accomplished, the G model is used to generate synthetic samples for the minority class samples present in the client. These are the adversarial samples merged with the original ones to perform the AT. The classifier performs the"}, {"title": "2) Multiclass Classification using SNN-MLP", "content": "The classical MLP network equipped with the Rectified Linear Unit (ReLU) activation suffers from the vanishing gradient issue as it clips the negative values to 0. It is preferred to have an activation that can contain positive and negative values to control the mean, aids in reducing the variance, and slope greater than one to increase the variance when it is too small. As such, our proposed classifier network is designed with the SNN-based MLP [24], called SNN-MLP, where the Scaled Exponential Linear Unit (SELU) function is employed to fulfill the afore-"}, {"title": "IV. EXPERIMENT AND RESULT ANALYSIS", "content": "In this section, we evaluate the performance of the proposed FedAT-driven distributed ITD paradigm. We first provide the dataset details followed by the training and testing perfor- mance evaluation. We aim to assess the effectiveness of the proposed FedAT scheme using different federated opti- mization methods (FedAvg and FedProx) and compare the results against the benchmark results from the centralized ML approach."}, {"title": "A. Dataset Description", "content": "The lack of real-world ITD data significantly hinders the experimentation. Usual practice demands using either data gathered from actual user data or artificially created data."}, {"title": "B. Benchmark Setup with Centralized ML", "content": "We first use the centralized ML paradigm (where all data from every client are stored in a single device to train the"}, {"title": "C. Classical FL vs FedAT", "content": "In this section, we perform experiments on the classical FL environment and the setup explained in our proposed FedAT-driven ITD architecture, illustrated in Fig 1. As the IID setting is similar to the centralized ML approach for this dataset and the application, we use the non-IID data setting for these experiments, as mentioned in Section III-B. In particular, the CERT datasets are divided among various clients {1,2..K}, and the class-level heterogeneity among the clients is ensured by splitting the data so that each client has one or more scenarios (classes) in the local private data. Splitting the data across multiple clients also reduces each client's private data size. As the number of malicious samples is minimal compared to the non-malicious (normal) data samples, we split the data among fewer clients, K = {3,5}. However, the proposed method is scalable to any number of clients.\nWe consider an FL environment with K clients and a global server, and perform experiments under two schemes on both MLP and SNN-MLP networks: (i) the classical FL [11], and (ii) the proposed FedAT. The classical FL uses the original data distributed across the K clients, whereas the FedAT employs AT-driven synthetic data generation at the local clients to reduce the adverse effects of class imbalance. We use the FedAvg for the model aggregation for both the classical FL and our proposed FedAT. Note that the evaluation also involves using varying communication rounds to study the convergence capability of the model. The quantitative results for the classical FL and our FedAT are given in Table II, and Table III, respectively. These experimental results show that both FL schemes produce stable results for T = 60 communication rounds. In particular, FedAT outperforms the classical FL in terms of all the P (68.16%, and 74.21% on the CERT v4.2 and CERT v5.2 datasets, respectively are achieved by our FedAT while 64.05%, and 51.09% on the CERT v4.2 and CERT v5.2 datasets, respectively by the classical FL), R (67.74%, and 73.68% on the CERT v4.2 and CERT v5.2 datasets, respectively are achieved by our FedAT while 64.00%, and 51.25% on the CERT v4.2 and CERT v5.2 datasets, respectively by the classical FL), and F (67.95%, and 73.94% on the CERT v4.2 and CERT v5.2 datasets, respectively are achieved by our FedAT while 64.02%, and 51.17% on the CERT v4.2 and CERT v5.2 datasets, respectively by the classical FL) metrics. In addition, SNN-MLP proves to be more efficient in FedAT than other combinations of methods for both the CERT v4.2 and v5.2 datasets. Though AT in the centralized ML scheme has a slightly higher performance, the FedAT performs almost equally well in nearly all cases. These results, therefore, clearly show the effectiveness of the FedAT-enabled distributed ITD scheme. In addition, Fig. 6a and Fig. 6b depict the performance metrics and the training loss during each communication round in the classical FL using MLP and the proposed FedAT using SNN-MLP, respectively. To summa- rize, the experiments have shown that by using collaborative training with our proposed FedAT, it is possible to achieve significant results while maintaining the data privacy of the different clients for distributed ITD. As the effective selection of hyperparameters significantly impacts the performance of the FL approaches, we perform experiments with varying numbers of clients, local epochs, and local batch sizes in Section IV-C3 to investigate the performance of the proposed FedAT model under various hyperparameter configurations and identify the appropriate parameters over the class-level heterogeneity."}, {"title": "1) Generator Architecture", "content": "We use the same ACGAN ar- chitecture for centralized ML, classical FL, and our FedAT experiments. The G model is designed with {32, 64, 128} neurons. The G model uses the Gaussian noise and the latent dimension as inputs. The latent dimension provided as input to the G model is equal to the number of features in the dataset. The GAN training is performed for 200 epochs. Once the GAN training is over, the model generates synthetic samples of the insider scenarios resent in the client. We consider the improvement in the performance metrics as the criteria for validating the similarity of the synthetic samples. Since the data generated from the client locations could mimic the original distribution, the FL approaches produce quality results, as seen in Table II, and Table III."}, {"title": "2) How Does SNN Help in Training?", "content": "The performance improvement of using the SNN-MLP is evident from the results, as shown in Table I, Table II, and Table III. The intuition behind the self-normalization in SNN is to maintain the mean and variance of each neural network layer near 0 and 1. Incorporating the SELU activation function, the self-normalizing layer has been demonstrated to produce three unique features. The network's average learning rate is con- trolled by the SELU activation function using positive and negative values. With the help of a continuous curve, the SELU keeps a fixed point in the neural network. The SELU activation function guarantees a zero mean and one variance for the activation output. This enables it to train deeper neural networks without incurring substantial gradient degradation. These characteristics contribute to minimizing the model's invariance."}, {"title": "3) Extended Experiments", "content": "In this part, we study the impact of using different hyperparameters on the FedAT scheme. This experiment comprises varying clients (K), batch size (B), and local epochs (E). In addition, we employ the FedProx FL"}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "In this paper, we have proposed a practical approach for using the FL and AT paradigms in the context of distributed ITD. In particular, we have discussed the need for an FL-enabled solution approach for ITD and GAN-based AT to help reduce the class imbalance in the non-IID dataset of different clients. In addition, our FedAT-based scheme helps build an effective ITD model for all the clients involved in deep cooperative learning without sharing their confidential employee information. We have provided experiments using two public datasets (CERT v4.2 and CERT v5.2), and two federated optimization methods (FedAvg and FedProx), which manifest the supervisor performance of our FedAT scheme over the classical FL strategies. In the future, we plan to redesign our FedAT architecture using heterogeneous learning models for different clients. Furthermore, we would focus on improving the AT model by incorporating mechanisms that can defend against the backdoor and model inversion attacks in FL."}]}