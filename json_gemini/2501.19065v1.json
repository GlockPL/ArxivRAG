{"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "authors": ["Zhixuan Li", "Naipeng Chen", "Seonghwa Choi", "Sanghoon Lee", "Weisi Lin"], "abstract": "Time-series forecasting is crucial for numerous real-world applications including weather prediction and financial market modeling. While temporal-domain methods remain prevalent, frequency-domain approaches can effectively capture multi-scale periodic patterns, reduce sequence dependencies, and naturally denoise signals. However, existing approaches typically train model components for all frequencies under a unified training objective, often leading to mismatched learning speeds: high-frequency components converge faster and risk overfitting, while low-frequency components underfit due to insufficient training time. To deal with this challenge, we propose BEAT (Balanced frEquency Adaptive Tuning), a novel framework that dynamically monitors the training status for each frequency and adaptively adjusts their gradient updates. By recognizing convergence, overfitting, or underfitting for each frequency, BEAT dynamically reallocates learning priorities, moderating gradients for rapid learners and increasing those for slower ones, alleviating the tension between competing objectives across frequencies and synchronizing the overall learning process. Extensive experiments on seven real-world datasets demonstrate that BEAT consistently outperforms state-of-the-art approaches.", "sections": [{"title": "1. Introduction", "content": "Long-term time-series forecasting plays a pivotal role in various real-world applications, such as weather prediction (Zhang et al., 2022), electric load forecasting (Zhou et al., 2021; Gasparin et al., 2022), traffic flow analysis (Jin et al., 2021), and financial market modeling (Lai et al., 2018; Tang et al., 2022). These tasks demand accurate prediction over extended temporal horizons. In recent years, deep learning methods for time-series analysis have achieved significant advancements, characterized by the development of various architectures, including CNN-based (Liu et al., 2022; Wang et al., 2023; Luo & Wang, 2024), MLP-based (Oreshkin et al., 2019; Zeng et al., 2023; Wang et al., 2024a), Transformer-based (Wu et al., 2021; Liu et al., 2021; 2024), and LLM-based (Jin et al., 2024; Jia et al., 2024) approaches. Compared with temporal-domain approaches, frequency-domain methods (Wu et al., 2021; 2023; Zhou et al., 2022b) transform time-series data into the frequency domain, enabling the effective capture of large-scale periodic patterns, reducing sequence dependency lengths, and enhancing robustness through inherent denoising effects.\nDespite these advantages, frequency-domain analysis typically decomposes time-series data into multiple sub-series, such as high-frequency, low-frequency, and potentially additional band-pass segments, each representing a distinct temporal scale. High-frequency sub-series often capture short-term fluctuations or noise, while low-frequency sub-series reflect long-term trends or stable periodic patterns. Existing"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "frequency-domain approaches, such as WPMixer (Murad et al., 2025), simply train all frequency sub-series simultaneously under a unified loss function. However, as illustrated in Figure 1, the following challenges are observed: (1) the high-frequency component of the model tends to converge more rapidly, while the low-frequency component of the model requires more time to be adequately learned; (2) early stopping may result in underfitting of the low-frequency components, even if the high-frequency components are well-learned, whereas prolonged training risks overfitting the high-frequency components. This asynchronous learning pace across different frequencies renders a unified loss function insufficient to optimize all sub-series simultaneously, ultimately leading to suboptimal overall performance. Therefore a critical challenge lies in dynamically evaluating the learning progress of each frequency-specific sub-series and introducing timely adjustments to ensure balanced training for both high-frequency and low-frequency components.\nTo deal with this issue, we propose BEAT (Balanced frEquency Adaptive Tuning), a novel framework that enables real-time monitoring and dynamic adjustment for each frequency sub-series. Specifically, our approach begins by decomposing the ground-truth target series into frequency-specific ones and evaluates whether the model component for a given frequency is converging, overfitting, or underfitting. Consequently, BEAT dynamically modulates the network gradients of the model component for each frequency. For sub-series that converge more quickly and risk overfitting, the framework reduces the back-propagated gradient to decelerate learning. Conversely, for the ones that lag behind, it amplifies the gradients adaptively to accelerate convergence and mitigate underfitting. By overcoming the limitations of a uniform training objective applied across all frequencies, the proposed framework effectively redistributes optimization priorities and synchronizes learning progress across the frequency spectrum.\nOur contributions are as follows:\n\u2022 We perform an in-depth analysis of the optimization conflicts caused by mismatched learning speeds between model components for different frequencies in frequency-based long-range forecasting. We demonstrate how these conflicts negatively influence overall predictive performance with illustrative evidence.\n\u2022 We propose BEAT, a novel training framework that incorporates real-time monitoring to continuously track learning progress and an adaptive adjustment mechanism to effectively regulate the learning pace for different frequencies, achieving a balanced convergence between high- and low-frequency model components.\n\u2022 We evaluate BEAT on multiple challenging datasets and experimental results show that BEAT consistently"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "achieves the best long-range forecasting performance by improving the balance between high- and low-frequency sub-series."}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Temporal-domain Time-Series Forecasting", "content": "In recent years, deep learning has emerged as the leading method for time series modeling. This section provides a technical overview of key deep time series models, categorized into three types according to their backbone architecture: CNN-based, MLP-based, and Transformer-based.\nCNN-based methods. Convolutional neural networks (He et al., 2016; Gu et al., 2018) have gained prominence for their effectiveness in capturing local features and recognizing patterns for many tasks (Jiang et al., 2024a; Li et al., 2022). SCINet (Liu et al., 2022) employs standard convolutions with a hierarchical downsample-convolve-interact framework to capture dynamic temporal dependencies across varying temporal resolutions of time series data. MICN (Wang et al., 2023) integrates different convolutional kernels to model temporal correlations from both local and global perspectives. ModernTCN (Luo & Wang, 2024) enhances traditional TCN (Bai et al., 2018)by employing DW-Conv and ConvFFN to capture cross-time and cross-variable dependencies independently.\nMLP-based methods. Drawing inspiration that outputs depend linearly on their historical values, Multi-Layer Perceptrons (MLP) have emerged as a favored structure for time series modeling. These approaches handle multivariate data as independent univariate sequences and have shown promising results (Zeng et al., 2023). N-BEATS (Oreshkin et al., 2019), as a purely MLP-driven deep learning model for time series, utilizes deep stacks of fully-connected layers with dual residual branches one for backcasting and the other for forecasting - per layer. TimeMixer (Wang et al., 2024a) proposing an MLP-based multiscale mixing framework posits that time series exhibit varying patterns across different sampling scales.\nTransformer-based methods. Motivated by the remarkable success of the Transformer architecture (Vaswani, 2017) in sequence-to-sequence tasks (Li et al., 2023; Jiang et al., 2024b), prevailing it to the domain of time series modeling (Zhou et al., 2022b; 2021; Wu et al., 2021). Autoformer (Wu et al., 2021) pioneers an Auto-Correlation Mechanism. A time delay module is introduced to aggregate similar sub-series from inherent periods instead of focusing on scattered points. Pyraformer (Liu et al., 2021) constructs a multi-resolution C-ary tree and proposes a Pyramidal Attention Mechanism, enabling it to capture both short- and long-temporal dependencies in linear time and space. iTransformer (Liu et al., 2024) further expands the receptive field"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "by tokenizing the entire time series to capture inter-series dependencies."}, {"title": "2.2. Frequency-domain Time-Series Forecasting", "content": "Due to the presence of both high- and low-frequency components, purely time-domain methods may struggle to manage all frequency bands effectively in long-range scenarios compared with frequency-domain approaches. The ability to decompose signals into sub-series across different frequency ranges makes them more suitable for long-horizon forecasting.\nAs a common practice, TimesNet (Wu et al., 2023) applies FFT (Brigham, 1988) to isolate dominant frequencies-those with the highest amplitudes and rearranges 1D time series into 2D representations based on identified periods. Autoformer (Wu et al., 2021) introduces an Auto-Correlation mechanism alongside efficient FFT to treat data as a real discrete-time signal and capture series-wise correlations. FiLM (Zhou et al., 2022a) employs Frequency Enhanced Layers (FEL), merging Fourier analysis with low-rank approximation to retain key low-frequency components and top eigenspaces, thereby reducing noise and expediting training. FITS (Xu et al., 2023) uses a low-pass filter (LPF) to remove high-frequency elements beyond a designated cutoff, shrinking model size while maintaining essential information. From the opposite idea, FEDformer (Zhou et al., 2022b) argues that focusing solely on low-frequency components can miss critical variations in time series data. Consequently, to capture a global perspective, the FED-former randomly selects a fixed number of Fourier components-encompassing both high- and low-frequency ranges. EV-FGN (Yi et al., 2022) uses a two-dimensional DFT on the spatial-temporal plane of embeddings, combined with graph convolutions to jointly model spatial-temporal dependencies in the frequency domain. FreTS (Yi et al., 2024) leverages the DFT to transform data into frequency-domain spectra and introduces frequency-domain MLPs designed for complex inputs by separately modeling real and imaginary parts. FCVAE (Wang et al., 2024c) incorporates both global and local frequency components into the condition of a Conditional Variational Autoencoder (CVAE). TSLANet (Eldele et al., 2024) proposes a lightweight Adaptive Spectral Block (ASB) that replaces self-attention using Fourier-based global and local filters. The recent WPMixer (Murad et al., 2025)employs multi-level wavelet decomposition, combining patching and patch mixer for local and global information respectively, successfully handling complex data behaviors such as sudden spikes and drops. However, WPMixer faces key issues: it simultaneously trains all frequency sub-series under a unified loss function, with high-frequency components learning quickly while low-frequency components lag, risking underfitting and overfitting due to asynchronous learning. In contrast,"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "our model BEAT handles this by decomposing the target into frequency-specific sub-series and evaluating their convergence statuses. It adjusts gradients in real time to achieve synchronization of the learning progress across frequencies, overcomes uniform loss limitations, and improves model efficiency."}, {"title": "3. Methodology", "content": ""}, {"title": "3.1. Task Formulation", "content": "In time series forecasting with one or multiple observed variates, the goal is to predict the future K time steps Y = {Y1, Y2,..., \u0423\u043a} \u2208 RK\u00d7N with N variates, based on the historical observations X = {x1-T,X1\u2212T+1,...,xo} \u2208 RTN with T time steps."}, {"title": "3.2. Overall Architecture", "content": "As shown in Figure 2, the overall architecture of the proposed BEAT is presented. For the input historical time series sequence X, the Reversible Instance Normalization (RevIN) (Kim et al., 2021) is employed for handling the varied mean and variation in the time-series data. Then the normalized data Xnorm is transposed and decomposed by the multi-level wavelet decomposition (Mallat, 1989; Daubechies, 1992; Wang et al., 2018) as approximation XA and detail coefficients XD\u2081, i \u2208 {1,2,..., f} series corresponding to m frequency levels from low to high.\nThen f + 1 frequency-specific networks are utilized for capturing the temporal dependencies across the decomposed sub-series within each coefficient XD, and the approximation XA.\nTo demonstrate our proposed BEAT approach, specifically tailored for frequency-domain methods, we utilize WPMixer (Murad et al., 2025) as an instantiation. The approximation coefficient series at level f is preserved, ensuring a concise and efficient representation.\nNext f +1 Frequency-Specific Monitors (FSM) (as shown in Figure 2 (c)) are designed and deployed for each frequency-specific network to track their optimization statuses during training. Besides, the Dynamical Gradient Balancer (DGB) (presented in Figure 2 (d)) is presented and equipped for each frequency-specific network to modulate their back-propagated gradients during the backward stage for balancing their learning processes to avoid overfitting or underfitting. If one network for a frequency converges over-quick or over-slow, FSM can recognize the inappropriate optimization status and transfer it to DGB for timely adjustment.\nA\nDi\nThe Wavelet Reconstruction module takes all the predicted approximation Ya and detail wavelet coefficient series YD; from all frequency-specific networks for transforming the predicted future time series into the temporal domain as"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "\u0176norm. Finally, the transposition is applied and the RevIN is used for de-normalization, generating the final output \u00dd."}, {"title": "3.3. Frequency-Specific Monitor", "content": "The Frequency-Specific Monitor (FSM) is designed to track the training status of the network for each frequency, supporting the dynamical adjustment of the learning pace for these networks inspired by (Peng et al., 2022). To monitor the learning status for each frequency, it is necessary to compare their prediction with corresponding targets. To this end, we take advantage of the ground-truth sequence Y and utilize the wavelet decomposition to transform Y in the temporal domain as the approximation coefficient series YA and detail coefficient series YD; where i \u2208 {1,2, . . ., f } and f is the wavelet decomposition level. The wavelet decomposition process can be formulated as:\n\\begin{equation}\nA\nDi\nYA,YDf, YDf\u22121,\u06f0\u06f0\u06f0,YD\u2081 = DWT(Y, f, 4), (1)\n\\end{equation}\nwhere the DWT represents the Discrete Wavelet Transform, and & is the wavelet type. Here only the approximation coefficient series at level f is reserved for efficient representation. The wavelet families Coiflets, Daubechies, Biorthogonal,"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "and Symlets are evaluated as potential wavelet types.\nThen we calculate the discrepancy 8 between the predicted and decomposed ground-truth targets for all frequencies, formulated as below:\n\\begin{equation}\n\u03b4\u03b1 = MSE(YA,\u0176A), (2)\n\\end{equation}\n\\begin{equation}\nSD\u2081 = MSE(YD, \u0176D\u2084), i \u2208 {1, 2, ..., f}, (3)\n\\end{equation}\nwhere MSE is the Mean Squared Error to measure the discrepancy. Then the mean value of the discrepancies for all detail coefficient series is calculated by:\n\\begin{equation}\n\u03bc =\nDi\n\u03a3=1 \u03b4\u03b9\nf (4)\n\\end{equation}\nAnd the discrepancy ratios ru, where v \u2208 {1, 2, ..., f + 1}, for all frequencies can be calculated with:\n\\begin{equation}\n\u03a4\u0391 =\n\u03b4\u0391\n\u03bc\n, D\n= D\ndi, i \u2208 {1,2,..., f}.\n(5)\n\u03bc\n\\end{equation}\nThe discrepancy ratio ru quantitatively measures the discrepancy between the predicted and ground-truth coefficient"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "series for each frequency, representing the relative learning speed with the help of normalization using the mean of the discrepancies regarding all detail coefficient series. The mean discrepancy is calculated only for the detail coefficients because they capture high-frequency information, which is more sensitive to prediction errors and crucial for analyzing signal details. The approximation coefficient, representing low-frequency information, is treated separately to avoid dominating the mean value."}, {"title": "3.4. Dynamical Gradient Balancer", "content": "Since the learning processes of different frequency-specific networks are not synchronized, it is essential to adjust the learning speed of these networks dynamically to balance their learning processes in time. To this end, the Dynamical Gradient Balancer (DGB) is presented to modulate the back-propagated gradients based on the calculated discrepancy ratios of all frequencies.\nSpecifically, for a frequency-specific network \u00ba, where v \u2208 {1, 2, ..., f +1}, its network parameters \u03b8\u00ba are updated as follows when applying the Gradient Decent approach:\n\\begin{equation}\n\u03b8\u03b1+1 = \u03b8\u03b1 \u2013 \u03b1\u03bd\u2207\u03b8\u03c5L(\u03b8), (6)\n\\end{equation}\nwhere a is the learning rate, u is the optimization step, and L is the loss of the v-th network. The Vor is the back-propagated gradient, which can be denoted as gu.\nNext, we calculate the gradient modulation coefficient cu for each gu according to the discrepancy ratio ru which reflects the learning status quantitatively of each frequency-specific network. To be specific, the gradient modulation coefficient cu is calculated following:\n\\begin{equation}\nC =\n1\n1+e-0.5(r-1) =1+0.5, if r\u00ae > 1,\nif r < 1. (7)\n\\end{equation}\nThen the back-propagated gradient of each frequency-specific network's parameters can be updated as:\n\\begin{equation}\n0+1 = 0 - a\u011f\u00baL(0), (8)\n\\end{equation}\nwhere g = cg\u00b2 = c\u2207e, representing the modulated gradients, which are appropriate for balancing the learning process among different frequency-specific networks and achieving harmonious convergence. For a network with a faster learning process, where r\u00ba > 0, its back-propagated gradients will be decreased to slow down its learning speed to avoid overfitting and being dominant over the learning. On the contrary, regarding those networks with slower learning processes, where ru < 1, their back-propagated gradi-"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "Algorithm 1 The proposed BEAT framework\nInput: Historical time series data X, wavelet decomposition level f, wavelet type 4, future time steps K, initialized frequency-specific network's parameters \u03b8\u03c5, \u03c5\u2208 {1,2,..., f + 1}, learning rate a.\nfor u = 1 to U do\nSample a mini-batch Bu from X;\nFeed-forward Bu to the model;\nCalculate the loss Lu of the model;\nUse back-propagation to calculate gu for \u03b8\u03c5;\nCalculate discrepancy ratio ru with Eqn. 1, 2, 3, 4, 5;\nCalculate modulation coefficient cu with Eqn. 7;\nUpdate the gradient of u with Eqn. 8.\nend for\nents will be increased to accelerate their learning speed to avoid underfitting."}, {"title": "3.5. Training and Inference", "content": "During training, the proposed BEAT framework is taking effect to balance the learning progress of different frequency-specific networks to avoid overfitting or underfitting. The overall pipeline is shown in Algorithm 1. It is worth noticing that after calculating the loss Lu of the entire model, the gradient gu for the parameters \u03b8\u00ba of each frequency-specific networks are only computed but not updated. The gradient of ou is updated using Equation 8 for applying the gradient modulation coefficient cu on the gradient g\". The loss function used for training is SmoothL1Loss with the default threshold value set as 1. The proposed BEAT framework is only deployed during training and not used during inference, keeping the model efficient."}, {"title": "4. Experiments", "content": ""}, {"title": "4.1. Experimental Settings", "content": "Datasets. We benchmark our method over seven challenging datasets in long-term series forecasting. (1) Weather dataset\u00b9 is collected every 10 minutes throughout 2020, con-"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "taining 21 meteorological indicators such as air temperature and humidity. (2) ETT dataset (Zhou et al., 2021) contains data collected from electricity transformers, including load and oil temperature measurements recorded every 15 minutes from July 2016 to July 2018. There are four sub-datasets in ETT, including ETTh1, ETTh2, ETTm1, and ETTm2. (3) Traffic dataset\u00b2 comprises hourly data from the California Department of Transportation, detailing road occupancy rates measured by various sensors on San Francisco Bay Area freeways. (4) ECL dataset (Li et al., 2019) records hourly for the electricity consumption data from 321 clients. Table 1 provides data statistics of these datasets. Size denotes the number of time points in the (Train, Validation, Test) sets, respectively.\nBaselines. There are nine state-of-the-art baseline methods for long-term time series forecasting are compared, including WPMixer (Murad et al., 2025), TimeMixer (Wang et al., 2024a), iTransformer (Liu et al., 2024), TSMixer (Ekambaram et al., 2023), PatchTST (Nie et al., 2023), Crossformer (Zhang & Yan, 2023), TiDE (Das et al., 2023), and DLinear (Zeng et al., 2023).\nImplementation Details. We develop BEAT using Pytorch (Paszke et al., 2019) based on the TSLib (Wang et al., 2024b) codebase. Following the previous method (Ekambaram et al., 2023), we set the historical time step T as 96 and follow the unified setting for a fair comparison for all experiments. The prediction length K varies within the range of {96, 192, 336, 720}. For each dataset, all experiments are conducted on the same training set and evaluated on the same test set. A single NVIDIA RTX 4090 with 24GB memory is used for all experiments.\nMetrics. The Mean Squared Error (MSE) and Mean Absolute Error (MAE) are employed for evaluation. MSE and MAE are defined as:\n\\begin{equation}\nMSE =\n1\nK\nk=1\nK\n(Yk - Yk)2, (9)\n\\end{equation}\n\\begin{equation}\nMAE =\n1\nK\nk=1\nK\n\u03a3Yk - Yk, (10)\n\\end{equation}\nwhere for the k-th sample in a time series, yk is the ground-truth data and the \u0177k is the predicted one. The lower MSE and MAE indicate better performance."}, {"title": "4.2. Long-Term Time Series Forecasting Results", "content": "Table 2 shows the performance of BEAT and compared methods on the test set of seven challenging datasets sam-"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "pled from the real world. All experiments are under the same setting of historical time step length 96 for fair comparison. As shown in the table, the proposed method BEAT achieves the highest number of first-place rankings across all prediction lengths and datasets.\nSpecifically, our designed frequency-specific learning process monitoring and dynamic gradient adjusting for frequency-decomposition-based approaches outperforms the performance of the existing state-of-the-art frequency-based approach WPMixer, which treats the different decomposed frequencies equally and suffers from learning speed conflict, prone to be over-fitting and under-fitting for frequency-specific networks with different learning processes. Compared with the state-of-the-art Linear-based approach TimeMixer which decomposes time series as different scales and mixes different seasonal and trend series, BEAT archives better performance. Moreover, compared to the Transformer-based model iTransformer, BEAT achieves more first-ranking counts. It is worth noticing that BEAT achieves well performance against counterpart methods on challenging datasets like Weather and ETT that have no clear periodic patterns, resulting in reduced predictability due to their inherent irregularities."}, {"title": "4.3. Ablation Study", "content": "We conduct extensive ablation studies on the test sets of the Weather and ETTh1 datasets to evaluate the effectiveness of the proposed BEAT framework. To be specific, we examine BEAT from the aspect of technical designs, wavelet type, discrepancy calculation design, and gradient modulation design in the following.\nEffect of BEAT. The effect of the designed Frequency-Specific Monitor (FSM) and Dynamical Gradient Balancer (DGB) is evaluated and shown in Table 3. When both FSM and DGB are not employed, the performance is not well since the learning process of networks for different frequencies could conflict. The performance is improved with the proposed FSM and DGB for monitoring and modulating the learning process dynamically, achieving a balanced training"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "between frequencies."}, {"title": "Wavelet Type.", "content": "To evaluate the effect of the wavelet type, four wavelet families are considered, including Coiflets, Daubechies, Biorthogonal, and Symlets. As shown in Table 4, the performance achieves the best on the Weather and ETTh1 datasets when employing Daubechies, and Coiflets wavelet types, respectively, showing specific types should be chosen for different datasets with particular data patterns."}, {"title": "Levels of Decomposition.", "content": "As shown in Table 5, the effect of levels f for the decomposition in the wavelet transform is evaluated. The best performance of BEAT on Weather and ETTh1 datasets is achieved when the levels f are set as 2 and 3, respectively. Setting the level f as 4 and 5 doesn't bring better performance. This is because higher decomposition levels can over-smooth the data or remove essential details, preventing further performance improvements."}, {"title": "Discrepancy Calculation Design.", "content": "To evaluate the effect of the discrepancy calculation metric used in Equations 2 and 3, we conduct experiments on the metric for measuring the discrepancy between the predicted coefficients and the ground-truth ones, reflecting the learning process of networks for different frequencies. As shown in Table 6, using MSE for calculating the discrepancy can achieve the best performance against other metrics including RMSE, R-"}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "Squared, and MAE. MSE outperforms other metrics because by squaring the errors, it disproportionately penalizes larger discrepancies, leading to a more accurate measurement."}, {"title": "Learning Process Modulation Design.", "content": "We conduct experiments to evaluate the performance when applying modulation on the total loss with the average of coefficient c\", where v \u2208 {1, 2, ..., f}, calculated by Equation 7. As shown in Table 7, compared with our proposed DGB, which applies modulation to the back-propagated gradients of networks for corresponding frequencies, modulating the loss is less effective. This is because the modulation affects the entire model and cannot adjust each network individually considering its learning process."}, {"title": "5. Conclusion", "content": "This paper presents BEAT (Balanced frEquency Adaptive Tuning), a novel training framework that continuously monitors and adaptively adjusts the learning pace of each frequency sub-series. By dynamically modulating back-propagated gradients in accordance with real-time convergence feedback, BEAT ensures that both high-frequency and low-frequency model components converge in a balanced manner. Experimental results on a variety of benchmarks demonstrate that BEAT consistently outperforms state-of-the-art baselines, demonstrating the importance of resolving optimization conflicts due to mismatched learning speeds for different frequencies."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here."}, {"title": "BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting", "content": "As we take WPMixer (Murad et al., 2025) as an instantiation for illustrating our proposed framework BEAT, the detailed structure of the Frequency-Specific Network is introduced as follows.\nAfter the decomposition module breaks down the normalized time series into approximation and detail coefficient series, each wavelet coefficient series is transmitted through a separate resolution branch within the model, which consists of a RevIN normalization module, a patching and embedding module, multiple mixer modules, a head module, and a RevIN denormalization module. The total count of multivariate coefficient series or resolution branches in the model is determined as f + 1 due to the presence of f detail and 1 approximation coefficient series."}]}