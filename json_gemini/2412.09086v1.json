{"title": "Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools.", "authors": ["Alfio Ventura", "Nils K\u00f6bis"], "abstract": "This position paper discusses the benefits of longitudinal behavioural research with customised Al tools for exploring the opportunities and risks of synthetic relationships. Synthetic relationships are defined as \"continuing associations between humans and AI tools that interact with one another wherein the Al tool(s) influence(s) humans' thoughts, feelings, and/or actions.\" [1]. These relationships can potentially improve health, education, and the workplace, but they also bring the risk of subtle manipulation and privacy and autonomy concerns. To harness the opportunities of synthetic relationships and mitigate their risks, we outline a methodological approach that complements existing findings. We propose longitudinal research designs with self-assembled AI agents that enable the integration of detailed behavioural and self-reported data.", "sections": [{"title": "Introduction", "content": "Interactions with Al systems have become integral to many people's daily lives. Accruing users at a record-breaking pace, millions of people now interact with large language models (LLMs) like ChatGPT, Claude, or Gemini. Besides such general-purpose language models, there is a growing trend towards LLM-based AI tools aiming to develop sustainable relationships with their users [2]. Prominent examples are Replika and the soon-to-be-released \"Friend AI\" necklace that promises to be \"always listening\" [3]. Enhanced memory functions have enabled these tools to have more dynamic, personal, and persistent conversations with their users compared to previous technologies. They enable people to form synthetic relationships (SRs), defined by Starke and colleagues [1] as \u201ccontinuing associations between humans and AI tools that interact with one another wherein the AI tool(s) influence(s) humans' thoughts, feelings, and/or actions.\""}, {"title": "The Opportunities of Synthetic Relationships", "content": "The growing sophistication of AI tools in universal agents opens up vast opportunities for SRs across various domains. These relationships are perceived as highly personalised, available 24/7, offering a safe space for self-disclosure without fear of judgment [4]. As companions, they might ease loneliness [5] and promote well-being [6]. In mental health, AI-based therapists have shown promise in reducing symptoms of depression and distress [7].\nIn education, AI tutors can tailor learning experiences to individual students' needs, fostering cognitive and socio-emotional development [8]. This personalised support can improve engagement and learning outcomes, particularly for students who struggle in traditional settings. Similarly, Al managers can enhance productivity in professional settings by streamlining decision-making and administrative tasks, freeing human managers to focus on more strategic initiatives [9]."}, {"title": "The Risks of Synthetic Relationships", "content": "However, SRs also pose severe risks alongside these opportunities, stimulating first discussions [1, 10]. These risks are primarily ethical and affect the current state of normative behaviour. Privacy concerns loom large as Al agents gather and store private and intimate personal data, often without explicit user consent. In a world increasingly reliant on digital trust, this vulnerability could corroborate technology company's power and lead to new forms of exploitation. One of these risks is manipulation [1]. AI agents, by design, can influence user behaviour-ranging from \"harmless\" personalised product recommendations to dramatic steering of political opinions. SRs may amplify the effects of generative AI, such as emotional dependence and individualised responses, rendering users particularly susceptible to such influences.\nThere is also growing concern about the impact on human autonomy [10]. As users rely more on Al companions and therapists for emotional or social guidance, they risk ceding control over their personal and professional decisions. Over time, this could erode self-agency, leading to an over-reliance on synthetic relationships that might diminish critical thinking and individual autonomy. SRs may also disrupt social norms and reinforce maladaptive behaviours and cognitions by displaying sycophancy. Generative Al may create individualised echo chambers tailored towards the opinion of the interaction partner, reinforcing their beliefs and behavioural patterns.\nSRs can also compromise our modern social networks. Their permanent availability, perceived safety and unjudgmental nature may make it difficult to argue in favour of human-human relationships over SRs in the future [10]. Ultimately, it is possible that \"human relationships will just seem too hard\" [11]. An interview study indicates that SRs use the same socialising resources as human-human relationships [4], challenging a future in which SRs are primarily supplementary. Replacing human-human relationships with SRs could be a natural consequence [12]. Recent news and discussions around a teen's suicide and the involvement of an SR illustrate how real the influence of SRs can already be today [13]."}, {"title": "The Need for More Longitudinal Studies with Customized AI Agents", "content": "Despite the growing prevalence of SRs, the current body of research is limited in scope as most studies cannot detect the often subtle effects that unfold in synthetic relationships over time. Research has revealed the potential of AI tools to influence human feelings, attitudes, and behaviour. For instance, interview studies show that users often form attachment-like bonds with AI companions [14, 15]. This emotional bond can lead to adverse mental health effects [16]. Other studies found that interactions with opinionated Al assistants can sway participants' writing and opinions [17]. Moreover, AI-generated advice can affect people's ethical behaviour [18].\nThese studies provide important insights into immediate reactions to AI systems and can be regarded as snapshots of one-time interactions. This approach, however, has limitations. For one, such studies might suffer from the risks of experimenter demand effects as the interaction with the AI system is often (made) highly salient. Consequently, people might act in a way that they believe the experimenter wants them to. Also, short-term research designs are inadequate to assess many of the effects of sustained synthetic relationships. In fact, human-human relationship research suggests that understanding many important aspects of relationships requires a more extended scope of time as the effects are often more nuanced and take time to materialise [19, 20].\nA few studies have already employed longitudinal research on ongoing user interactions with AI tools. One study examined how users' relationships with an AI companion evolve, showing that users' experiences and SR developments differ widely [21]. Another study found that AI companions significantly reduce loneliness on par with human interactions, especially when users feel \"heard\" by the chatbot [5].\nThese studies have started to uncover how attitudes towards and experiences with Al tools change over time. However, experimental research with proprietary software cannot provide transparent, reproducible and causal insights into how the design of AI systems in SRs affects people. Additionally, by relying on existing users of such tools, research may suffer from selection bias concerns limiting generalizability. Drawing on non-representative samples can significantly undermine quantitative behavioural insights, limiting the ability to systematically examine synthetic relationships' opportunities and risks. We, therefore, call for more research using a) customisable AI tools and b) implementing longitudinal designs, particularly with behavioural data."}, {"title": "Customizability for Causal Inferences", "content": "For independent, systematic research, control over the AI tool people interact with is paramount. Comprehensively prompted or fine-tuned Al tools offer several key advantages over relying on proprietary software. First, it provides high control over the backend, enabling researchers to tailor AI systems specifically for their studies. This control allows for precise adjustments in how the AI interacts with users, ensuring that variables of interest can be closely monitored and manipulated. Second, custom Al tools allow for the implementation of experimental treatments in ways that proprietary"}, {"title": "Longitudinal Quantitative (Behavioural) Data", "content": "Longitudinal quantitative studies of SRs offer a comprehensive understanding of how users' behaviours evolve over time. Behavioural measures, such as tracking individual interaction frequency or the duration and specific types of engagement (e.g., emotional disclosure and task completion), provide objective data beyond self-reported attitudes or perceptions. These measures can reveal longitudinal patterns in Al reliance, emotional dependency, and habit formation-offering insights that users may not consciously report or even be aware of. For example, users might not recognise an increasing reliance on AI for decision-making, but behavioural data could display this trend more objectively.\nBehavioural data can also enrich qualitative insights by adding measurable depth to users' stated experiences. While qualitative studies can capture the emotional and cognitive nuances of SRs and inspire research questions, quantitative data can validate such findings. By integrating both approaches, researchers can correlate shifts in stated attitudes with actual behaviours, identifying discrepancies and refining our understanding"}, {"title": "Experience Sampling", "content": "Experience sampling is one method that holds particular promise for longitudinal data collection. For a thorough explanation, the work of Csikszentmihalyi and Larson [23] highlights Experience Sampling (ESM)'s ability to track real-time experiences. Such momentary assessment technology captures developing SRs by tracking (self-reported) emotional responses, thoughts and behaviours during user interactions throughout the day. This rich data offers a nuanced qualitative and quantitative understanding of how SRs evolve. Illustrating the power of ESM, a systematic literature review shows that smartphone-based experience sampling is essential for understanding well-being dynamics [24]. Applied to SRs, ESM enables researchers to observe subtle shifts in trust, engagement, and dependency over extended periods, offering crucial insights into how these relationships shape long-term behaviours and attitudes. This strength holds true, even if such subtle changes may not be consciously acknowledged but emerge from ongoing interactions and relationship building."}, {"title": "Exemplary Research Agenda: Experience Sampling in Synthetic Relationships", "content": "A longitudinal study using behavioural methods combined with experience sampling could provide comprehensive insights into both the opportunities and risks of SRs. For example, research questions about patterns of emotional disclosure, frequency and motivation of companionship seeking, or calibration of emotional dependence and trust within SRs can be explored, possibly even with the same data set. By utilising experience sampling's comprehensive usage data, researchers can explore complex dyadic relationship patterns evolving over time. From there, they can draw educated recommendations for the socially beneficial application, design and boundaries of SRs. In the future, this approach could be extended to investigate SRs in hybrid human-Al social networks.\nTwo areas where this methodology could be particularly insightful are (1) assessing the risk of autonomy erosion in decision-making and (2) changes in users' social behaviours with and through AI. In terms of decision making, a combination of behavioural tracking and experience sampling could reveal how AI-driven advice influences users' actions, whether in making purchases, forming opinions, or navigating ethical dilemmas. Over time, such studies could show how AI agents subtly steer user behaviour, shifting the balance between human autonomy and AI-influenced behaviour.\nRegarding social behaviour, monitoring interactions with both AI-human and human-human dyads could suggest whether long-term engagement with Al agents leads to a preference for synthetic interactions over human ones. For example, comprehensive long-term behavioural and emotional data may inform about changes in reliance"}, {"title": "Conclusion", "content": "Longitudinal, quantitative behavioural research is indispensable to fully grasp the opportunities and risks of synthetic relationships. By leveraging customised AI tools and methods such as experience sampling, researchers can capture the complex, evolving dynamics of human-AI interactions over time. Behavioural data, which provides objective insights into user engagement, can enrich our understanding beyond self-reported attitudes, helping to uncover subtle shifts in emotional dependency, decision-making autonomy, and social behaviour. This approach will pave the way for more informed, evidence-based development of Al systems that are both innovative and ethically sound."}, {"title": "Disclosure of Interests", "content": "The authors have no competing interests to declare relevant to this article's content."}]}