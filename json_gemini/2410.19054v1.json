{"title": "INFOGENT: An Agent-Based Framework for Web Information Aggregation", "authors": ["Revanth Gangi Reddy", "Sagnik Mukherjee", "Jeonghwan Kim", "Zhenhailong Wang", "Dilek Hakkani-Tur", "Heng Ji"], "abstract": "Despite seemingly performant web agents on the task-completion benchmarks, most existing methods evaluate the agents based on a presupposition: the web navigation task consists of linear sequence of actions with an end state that marks task completion. In contrast, our work focuses on web navigation for information aggregation, wherein the agent must explore different websites to gather information for a complex query. We consider web information aggregation from two different perspectives: (i) Direct API-driven Access relies on a text-only view of the Web, leveraging external tools such as Google Search API to navigate the web and a scraper to extract website contents. (ii) Interactive Visual Access uses screenshots of the webpages and requires interaction with the browser to navigate and access information. Motivated by these diverse information access settings, we introduce INFOGENT\u00b9, a novel modular framework for web information aggregation involving three distinct components: Navigator, Extractor and Aggregator. Experiments on different information access settings demonstrate INFOGENT beats an existing SOTA multi-agent search framework by 7% under Direct API-Driven Access on FRAMES, and improves over an existing information-seeking web agent by 4.3% under Interactive Visual Access on AssistantBench.", "sections": [{"title": "1 Introduction", "content": "Despite the well-documented success of autonomous web agents (Nakano et al., 2021; Yang et al., 2023; Zhou et al., 2023; Deng et al., 2024), the proposed tasks usually perform goal-oriented web-based tasks involving navigating within a website, interacting with elements like buttons and executing complex workflows. (e.g., booking a flight or scheduling a meeting). However, a critical aspect of web-based tasks, information aggregation"}, {"title": "2 Related work", "content": "Web Navigation with LLMs: Web navigation agents were originally explored in simulated web environments (Shi et al., 2017) and (Liu et al., 2018) which predominantly focused on completing goal-oriented tasks. The simulated environments came equipped with a range of task primitives such as selecting value from a drop down or entering text into an input box, which could be used to achieve the end goal. Subsequent work has focused on extending to more realistic settings (Nakano et al., 2021), such as WebShop (Yao et al., 2022) for e-commerce and RUSS (Xu et al., 2021) for web support. However, these efforts are still limited to a narrow set of domains and websites. In contrast, WebArena (Zhou et al., 2023) and Mind2Web (Deng et al., 2024) were introduced as benchmarks for autonomous web agents that can generalize to a wide variety of tasks on real-world websites. Nevertheless, these approaches were still limited to predominantly language-guided agents, that solely relied on the text elements present within the website raw HTML. Follow-up works, such as VisualWebArena (Koh et al., 2024), SeeACT (Zheng et al., 2024a) and WebVoyager (He et al., 2024), use multimodal agents (Achiam et al., 2023; Team et al., 2023) that leverage screenshots of websites as input for identifying the appropriate HTML elements to act upon. The motivation is that raw HTML contents are too noisy, and context is often too long, while screenshots provide a less noisier view of the webpage. While these methods involve"}, {"title": "3 Information Aggregation Task", "content": "We conceptualize information aggregation for a query as an iterative process involving identifying relevant websites and gathering pertinent information within them, repeated until sufficient data is collected. Actively tracking the aggregated information guides subsequent searches, ensuring comprehensiveness while avoiding redundancy. The success of the process is dependent on the quality and diversity of the collected information.\nWe note that accessibility of web information varies significantly. Some data is easily obtainable through APIs or by scraping web pages (e.g., retrieving \"Billboard Top 100 songs\" from Wikipedia\n). However, other information, such as salary data on Glassdoor, is not directly accessible due to paywalls, or other restrictions. Therefore, we categorize information aggregation tasks into two settings based on the type of access: Direct API-Driven Access and Interactive Visual Access.\nThe former involves retrieving data via APIs or automated tools without interacting with the website, making it efficient when APIs are available. In contrast, Interactive Visual Access requires simulating human browsing to retrieve information from screenshots of webpages that prohibit automatic scraping. We hypothesize that these two ap-"}, {"title": "4 INFOGENT", "content": "INFOGENT, as illustrated in Fig. 1, consists of three core components: A Navigator NG, an Extractor ET, and an Aggregator AG. Given an information-seeking query, the Navigator NG initiates the process by searching the web for relevant sources. Upon identifying a suitable webpage, the Extractor ET takes over the control, which extracts relevant content and forwards it to the Aggregator AG. AG evaluates this content with respect to the information aggregated so far and decides whether to include it. Importantly, AG provides feedback to NG about gaps in the aggregated information, guiding subsequent searches to address deficiencies. NG lacks direct access to the aggregated information, thereby relies on AG's feedback for directions in subsequent iterations. This iterative process continues until AG determines that sufficient information has been gathered and instructs NG to halt. Thus, INFOGENT employs a modular, feedback-driven approach to information aggregation, making it suitable for complex queries requiring diverse sources. Fig. 2 illustrates the"}, {"title": "4.1 Navigator NG", "content": "Recent studies (Yang et al., 2023; Wang et al., 2024) have demonstrated the capabilities of LLMs and LMMs to autonomously plan and execute sequences of thoughts and actions (Yao et al., 2023)"}, {"title": "4.1.1 Direct API-Driven Access", "content": "In this setting, web information can be accessed by querying a search API, which returns a list of relevant urls; the corresponding website content can be retrieved using automated scraping tools. In"}, {"title": "4.1.2 Interactive Visual Access", "content": "Under this setting, information cannot be directly scraped, meaning NG needs to explore the web in a manner similar to human interactions with a browser. Recent work (He et al., 2024; Zheng et al., 2024a) has demonstrated promising results in leveraging powerful Large Multimodal Models (LMMs) (OpenAI, 2023) for web navigation. The navigator here is based on SeeAct (Zheng et al., 2024a), a task-completion agent, capable of finishing web tasks by planning and executing interactive actions on webpages by utilizing screenshots and candidate HTML elements. SeeAct first performs Action Generation to create natural language descriptions of the necessary actions to accomplish a task (e.g., \"Click on search button\"). Subsequently, it engages in Action Grounding to identify appropriate HTML elements (e.g., \u201c[input] Departure City\u201d) and determines the corresponding operations (such as CLICK, TYPE etc.) to execute. For more details on SeeAct, please refer to Zheng et al. (2024a).\nWe augment SeeAct with additional capabilities required to be an effective web navigator for information aggregation. We add GO BACK and AGGREGATE actions, enabling the agent to perform backtracking and to transfer control to ET respectively. The full list of actions is provided in Table 1b. Further, we modify the Action Generation procedure to also condition on the textual feedback F"}, {"title": "4.2 Extractor ET", "content": "Once NG selects a relevant website, ET identifies and extracts up to k relevant paragraphs for the task. Since webpages are often lengthy, using a smaller, cost-efficient model for content processing is more practical. Extraction is favored over summarization for two key reasons: smaller models tend to produce low-quality summaries due to limited capacity, and they are prone to hallucination, introducing information not present in the source. Direct extraction ensures accurate attribution and maintains reliability of the aggregated data.\nIn the Direct API-Driven Access setting, given a website URL, ET scrapes the content and feeds it into an LLM, which is prompted to identify the relevant paragraphs based on the user's task. In contrast, under the Interactive Visual Access setting, where website content cannot be directly scraped due to access restrictions, ET navigates the webpage by scrolling from top to bottom, capturing multiple screenshots. These screenshots are then processed by a multimodal model (OpenAI, 2023), which identifies and extracts the relevant paragraphs. This approach facilitates extraction from web interfaces that are otherwise inaccessible through traditional scraping techniques. For detailed prompts, refer to Table 9 in the Appendix."}, {"title": "4.3 Aggregator AG", "content": "Given the content extracted by ET, presented as a list of paragraphs P, AG's task is to determine whether to incorporate any of the paragraphs into the aggregated information stack S. For each passage $p_i$ in $P$, AG can choose to either add $p_i$ as a new item (ADD($p_i$)), replace an existing item $s_j$ in $S$ with $p_i$ (REPLACE($s_j$, $p_i$))or just ignore $p_i$ if it is irrelevant or redundant. This decision-making process is achieved by prompting an LLM, with detailed prompts in Table 9 in the Appendix. Furthermore, AG provides textual feedback F to NG regarding what information to seek next, which"}, {"title": "5 Experiments", "content": "We test INFOGENT's ability to address complex queries that require accumulating information over multiple webpages. Evaluation is based on the final answer generated by the downstream LLM, leveraging the information aggregated by INFOGENT. We consider evaluation separately for Direct API-Driven access and Interactive Visual Access."}, {"title": "5.1 Direct API-Driven Access", "content": "Here, we employ a tool-based LLM as NG, built upon AutoGPT. To mitigate issues arising from the dynamic and potentially conflicting information on the web, we restrict our search to Wikipedia pages, following prior work Zhu et al. (2024)."}, {"title": "5.1.1 Setup", "content": "Datasets and Metrics: We evaluate our method on the FanOutQA (Zhu et al., 2024) and FRAMES (Krishna et al., 2024) datasets, both comprising complex queries that require accumulating information from multiple webpages. FanOutQA includes 310 multi-hop questions involving multiple entities (for e.g. What is the population of the five smallest countries by GDP in Europe?). FRAMES contains complex questions requiring various reasoning types: numerical (counting, comparisons, calculations), tabular (using statistics from tables or infoboxes), constraints (multiple conditions leading to a unique answer), temporal (timeline reasoning) and post-processing (specific steps after gathering all necessary facts). Excluding numerical questions-whose performance depended significantly on the final answering LLM rather than the aggregation approach-we retained 531 examples. We use the official evaluation metrics for both datasets: FanOutQA employs string accuracy and ROUGE (Chin-Yew, 2004), while FRAMES uses language model to assess whether the generated output matches the gold answer, utilizing the prompt shown in Table 7 in the Appendix.\nBaselines: We compare INFOGENT with MindSearch (Chen et al., 2024), a multi-agent search framework involving a planner and a searcher."}, {"title": "5.1.2 Results", "content": "Table 2 reports results on FRAMES across different reasoning types. Low performance of the closed-book approach highlights the complexity and recency of the questions. INFOGENT significantly outperforms MindSearch on most reasoning types; however, on temporal reasoning, MindSearch performs better, likely due to its code-driven planning in graph construction. Table 3 presents results on FanOutQA. Both INFOGENT and MindSearch outperform the closed-book method, demonstrating the benefit of web search, with INFOGENT consistently surpassing MindSearch. The relatively high performance of the closed-book model may be due to the dataset's release date (Nov 2023) being close to the LLM's knowledge cutoff (Oct 2023), suggesting that the LLM's parametric knowledge might already contain the required facts."}, {"title": "5.2 Interactive Visual Access", "content": "Our Navigator NG in this setting uses the same web browser simulation tool as in SEEACT (Zheng et al., 2024b), built on top of Playwright. The navigator initiates search from the Google homepage."}, {"title": "5.2.1 Setup", "content": "Datasets and Metrics: We use AssistantBench (Yoran et al., 2024), a dataset for evaluating web agents on time-consuming online information-seeking tasks, such as monitoring real estate markets or locating relevant nearby businesses. It comprises 214 realistic tasks (33 dev and 181 test) that require interacting with multiple websites. To assess performance on information-dense websites (Wikipedia) under the interactive visual access setting, we use a human-curated subset of FanOutQA released by Yoran et al. (2024), containing 31 queries with updated answers where closed-book models fail. Following Yoran et al. (2024), answer accuracy is the eval metric for both datasets.\nBaselines: Baselines are same as in in Yoran et al. (2024). RALM-Inst and RALM-1S are zero and one-shot versions of a retrieval-augmented LM that is prompted to use Google Search as a tool (Yao et al., 2023). For web-agent baselines, we consider SEEACT (Zheng et al., 2024a), designed for web task-completion. Our primary comparison is with SPA (See-Plan-Act) (Yoran et al., 2024), which extends SEEACT for information-seeking tasks by incorporating planning and memory modules for information transfer between steps."}, {"title": "5.2.2 Results", "content": "Table 4 presents results on AssistantBench, where INFOGENT outperforms SPA by 6.5% and 4.5% on the dev and test sets respectively, even when using the smaller GPT-4o as backbone. Due to cost considerations, we report results on dev set with GPT-4T, observing a performance gain of 9.3% over SPA. The poor performance of SEEACT confirms that task-completion web agents struggle with web information-seeking tasks. Table 5 summarizes our results on FanOutQA, where INFOGENT improves upon the SPA baseline by 19%. Since navigator is often the point of failure in web tasks, the Extractor"}, {"title": "5.3 Analysis", "content": "5.3.1 Different Models for NG, ET and AG\nWe conduct ablation experiments on INFOGENT under the interactive visual access setting to investigate which component, NG, ET or AG, is most dependent on the underlying model's capabilities. For this study, we evaluate the performance when using GPT-4o mini instead of GPT-40 for each component separately. Table 6 shows the results on the AssistantBench dev set. We see that the navigator is most reliant on the underlying model, with final accuracy dropping to zero when GPT-40 mini is used for NG. In comparison, using GPT-40 mini for both ET and AG results in relatively smaller performance drops of 2.7% and 2.1% respectively.\n5.3.2 Distribution of Actions Taken by NG\nAnalyzing the action frequencies of NG in the Interactive Visual Setting on the AssistantBench test set, we found that 61% instances successfully terminated navigation, while the remainder resulted in timeouts/failures. The top five actions per task, with their average usage, were CLICK (3.40), AGGREGATE (3.02), GO BACK (2.25), TYPE (2.01), and PRESS ENTER (1.32)."}, {"title": "6 Conclusion and Future Work", "content": "In this work, we introduce INFOGENT, a novel modular framework for web information aggregation. Through the use of separate Navigator, Extractor and Aggregator components, our approach can incorporate both tool-based LLMs and interactive web agents to handle different information access settings. Experiments demonstrate INFOGENT's superior performance over a state-of-the-art multi-agent search framework under Direct API-Driven Access and existing information-seeking web agents under Interactive Visual Access settings. Future work will incorporate evaluation on a wider variety of web information aggregation tasks. We also plan to explore measuring the diversity and coverage of aggregated information, and to assess \"information sufficiency\" as a criterion for terminating the information-seeking process."}, {"title": "A Appendix", "content": "A.1 Navigation Failures\nThe Navigator is a critical component of INFOGENT. The dynamic nature of the web, especially with its constant updates and varying structures, makes this a particularly challenging task. Navigation failures manifest in multiple forms, including but not limited to pop-ups, AI-generated overviews, captchas, and other interactive elements. While these features are designed to enhance user experience, they also introduce significant barriers for a web agent attempting to navigate efficiently. These obstacles can disrupt the flow of information gathering, making it difficult to access or retrieve data accurately. Samples of web navigation failures are shown in Figure 4."}, {"title": "A.2 Geo-Navigational Queries", "content": "We particularly observed that INFOGENT struggles with handling geo-navigational queries in AssistantBench. These queries often require precise spatial awareness and the ability to interact with dynamic map interfaces like Google Maps. For example, a query such as \u201cWhich gyms near Tompkins Square Park (within 200m) offer fitness classes before 7am?\u201d demands not only the retrieval of location-based data but also filtering of relevant details based on distance and time constraints.\nIn such cases, the model must effectively parse geographic information and interact with Google Maps to identify specific venues within the given parameters. However, this task relies heavily on the Navigator to accurately traverse and manipulate the map interface, which proves to be a significant challenge for current models. Google Maps' dynamic and interactive nature makes it difficult for web agents like INFOGENT to seamlessly navigate and extract relevant data without human-like intuition. Consequently, handling geo-navigational queries requires sophisticated mechanisms for interpreting spatial data and overcoming the navigational hurdles posed by interactive web platforms. Particularly these queries cause pop-ups like the left one in Figure 4."}]}