{"title": "System 2 thinking in OpenAl's o1-preview model: Near-perfect performance on a mathematics exam", "authors": ["J. C. F. de Winter", "D. Dodou", "Yke Bauke Eisma"], "abstract": "The processes underlying human cognition are often divided into two systems: System 1, which involves fast, intuitive thinking, and System 2, which involves slow, deliberate reasoning. Previously, large language models were criticized for lacking the deeper, more analytical capabilities of System 2. In September 2024, OpenAl introduced the O1 model series, specifically designed to handle System 2-like reasoning. While OpenAl's benchmarks are promising, independent validation is still needed. In this study, we tested the O1-preview model twice on the Dutch \u2018Mathematics B' final exam. It scored a near-perfect 76 and 73 out of 76 points. For context, only 24 out of 16,414 students in the Netherlands achieved a perfect score. By comparison, the GPT-40 model scored 66 and 61 out of 76, well above the Dutch average of 40.63 points. The O1-preview model completed the exam in around 10 minutes, while GPT-40 took 3 minutes, and neither model had access to the exam figures. Although O1-preview had the ability to achieve a perfect score, its performance showed some variability, as it made occasional mistakes with repeated prompting. This suggests that the self-consistency method, where the consensus output is selected, could improve accuracy. We conclude that while OpenAl's new model series holds great potential, certain risks must be considered.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) became widely accessible to the public through the launch of ChatGPT in November 2022 (OpenAI, 2022). This tool has impacted various fields, particularly education and academia. In education, ChatGPT has transformed teaching practices (Dempere et al., 2023; Farrokhnia et al., 2024), while in academic research, many students and scholars now rely on the tool to assist in writing papers and reports (\u010cr\u010dek & Patekar, 2023; De Winter et al., 2023; Gray, 2024; Kobak et al., 2024; Matsui, 2024). Additionally, ChatGPT is being widely used to support the peer review process for academic work (Latona et al., 2024; Liang et al., 2024).\nAt the beginning of 2023, a larger base model compared to the previous GPT-3.5 model was introduced, namely GPT-4 (Achiam et al., 2023). GPT-4, along with further fine-tunings and iterative improvements (such as GPT-4-turbo and GPT-40), continued to lead the LLM rankings for a long period (Chang et al., 2024; OpenAl, 2024c). Other models, such as Claude Sonnet (Anthropic, 2024), Google's Gemini (Google DeepMind, 2024), and Meta's Llama (Meta, 2024),"}, {"title": null, "content": "are close behind and outperform GPT-4 on some benchmarks (Huang & Zhang, 2024; White et al., 2024).\nA common criticism of LLMs, despite their impressive performance already, is that they seem to be reaching a plateau, with further improvements in output quality presumably requiring even larger base models or using more or higher-quality data (Hoffmann et al., 2022; Kaplan et al., 2020). Another frequent critique is that LLMs function as \u201cstochastic parrots\u201d (Bender et al., 2021), meaning they act as autoregressive token generators, where subsequent tokens are conditioned on the previously generated tokens. So far, LLMs often do not demonstrate self-reflection or correction on their output or a deeper understanding of the meaning behind the generated text. Indeed, while LLMs can produce fluent text, they struggle with seemingly basic tasks like counting (Cheng & Yu, 2023), arithmetic (Frenkel & Emara, 2024; Frieder et al., 2024), and reasoning (Frieder et al., 2024; Tang et al., 2024). A clear example is the Tower of Hanoi puzzle (Bubeck et al., 2023). Although LLMs can explain how to solve such puzzles and can generate a computer program to do so, they perform poorly when asked to directly solve even simple versions of the puzzle (Bubeck et al., 2023).\nThe current limitations of LLMs can be better understood through the framework of System 1 and System 2 thinking, as outlined by Evans and Stanovich (2013) and popularized by Kahneman (2011). Traditional computer systems have historically excelled at System 2 processes, i.e., processes that require logic and algorithmic processing. Until the arrival of LLMs, computers struggled with System 1 processes, which are the intuitive and context-sensitive skills that humans excel at. The breakthrough of LLMs concerns their ability to handle System 1-like tasks, such as generating natural language fluently and responding to context. This achievement is noteworthy in light of Moravec's paradox (1988, 1999), which says that tasks humans find intuitive, such as language use, have long been difficult for computers to perform. LLMs have overcome this limitation by excelling at tasks that mimic the automatic, context-driven nature of System 1 thinking.\nHowever, LLMs still lacked the ability to perform System 2 reasoning, which involves higher-order, deliberate thought processes. LLMs neither fully replicate human-like System 2 abilities nor reasoning capabilities of traditional computer systems. The next frontier is to improve LLMs with System 2 capabilities, which would allow them to combine the strengths of both systems: intuitive natural language understanding from System 1 and deep thinking from System 2. This combination would move LLMs closer to functioning like humans, who rely on the interplay of both systems to navigate complex tasks.\nLi et al. (2024) and Feng et al. (2023) provide a theoretical foundation for the fact that chain of thought reasoning is essential for solving mathematical and decision-making problems. Techniques to improve the outputs of LLMs through chain of thought or other forms of internal validation have been previously described by OpenAl (e.g., Lightman et al., 2023) and Google / DeepMind (Uesato et al., 2022; Zelikman et al., 2022). Kamruzzaman and Kim (2024) noted that traditional zero-shot prompting closely mirrors the intuitive processes of System 1, while chain-of-thought (CoT) prompting resembles the more deliberate and analytical reasoning of System 2. As pointed out above, LLMs have struggled with abstract thinking, i.e., System 2 processes. However, this limitation of LLMs has diminished with OpenAl's 01 model, released on September 12, 2024. Unlike previous LLMs (which could benefit, to some extent, from embedding CoT reasoning as part of the prompt), 01 performs CoT reasoning internally. According to various benchmarks conducted by OpenAl, 01 excels in areas such as programming, solving mathematical problems, and tackling complex puzzles, tasks that benefit from the more structured reasoning typically associated with CoT prompting (OpenAI, 2024a)."}, {"title": null, "content": "Although the details of the functioning of o1 are proprietary, it is known that 01 has been trained using reinforcement learning, where it received feedback on the quality of its own reasoning behavior, thereby learning to undergo a thought process. The OpenAl website also mentions that a longer training period and a longer thinking process during output generation result in higher output quality. Thus, the performance of the model does not solely scale with the size of the base model, but also with the amount of computational power applied during training and inference. This new form of scaling could have major implications, as it may be easier to realize, for example, through faster computers or improvements in algorithms."}, {"title": "Method", "content": "We used the exam \u2018VWO Mathematics B 2023' (College voor Toetsen en Examens, 2023a), the official national exam in abstract mathematics used in Dutch high schools. VWO stands for \u201cvoorbereidend wetenschappelijk onderwijs\u201d (\u201cpreparatory scientific education\u201d), which is the highest level of secondary education in the Netherlands. In a previous publication (De Winter, 2023), we applied the same method to English comprehension exams and found that GPT-4 scored between 8.1 and 8.3 on a scale of 1 to 10, placing it in the top 10% of human students.\nIn this study, we used the following LLMs: o1-preview-2024-09-12 (a model with System 2-like reasoning capabilities) and gpt-40-2024-05-13 (a model without these reasoning capabilities). The temperature setting could not be adjusted in o1-preview since it was fixed at 1. To allow for a fairer comparison, we also ran GPT-4o with the default setting of a temperature of 1.\nThe selected final exam consisted of 19 questions and was first input as a textual prompt. Note that, unlike human candidates, the LLM models did not have access to images, as 01-preview is not multimodal. The exam, and thus the prompts we provided to the LLMs, were in Dutch. Example prompts are provided below, for Questions 11, 14, and 16, respectively:\nThe function f is given by f(x) = abs(sin(x) + 1/2*sqrt(3)). In the figure, the graph of f is represented as a solid line. In the figure, the peaks A and B of the graph of fff are indicated. A and B are the peaks corresponding to the first two maxima of f to the right of the y-axis. There exists a sinusoid given by g(x) = a + bsin(x), for which two consecutive peaks coincide with points A and B. The graph of g is shown as a dashed line in the figure. Calculate the exact values of a and b\nThe function f is given by: f(x) = In(x). The function g is given by: g(x) = 1 + e^2 * (1 - In(x)). In figure 2, the graphs of f and g are shown again. For a certain value of q, the line with the equation y = q is also shown. This line The line y = q intersects the graph of g at point A and the graph of f at point B, where point A lies to the left of point B. It is given that AB = 3. Calculate the corresponding value of q. Give your final answer to one decimal place.\nGiven is rectangle OABC with O(0,0), A(8,0), and C(0,4). Points F and E are the midpoints of OA and BC, respectively. Point P(0, p) lies on the negative y-axis. Point D is the intersection of the extension of line segment PF and line segment AC. The line through E and F is the bisector of angle PED. M(4, 2) is the intersection point of AC and EF. Circle c has center M and passes through D. Depending on the position of point P (and thus the value of p), the circle becomes larger or smaller. There is exactly one value of p for which circle c is tangent to both OA and BC. In figure 2, this situation is depicted. Calculate this exact value of p.\nIn the text above, the strikethrough indicates text that was omitted (because the LLMs did not have access to the figures), and the boldface text reflects adjustments compared to the original exam.\nThe 19 prompts were presented individually to the two LLMs using MathWorks MATLAB via the API. The output was then submitted to a colleague (second author), who was asked to evaluate the output according to the official answer key, as available online (College voor Toetsen en Examens, 2023b)."}, {"title": "Results", "content": "The results of o1-preview and GPT-40 are shown in Table 2. 01-preview achieved a perfect score of 76 out of 76. GPT-4o, the state-of-the-art model without reasoning features, achieved a score of 66 out of 76. For comparison, the 16,414 students in the Netherlands who took the same exam scored an average score of 40.63 out of 76. The performance of o1-preview and GPT-40 compared to all the students who completed this exam is shown in Figure 1 (i.e., the first attempt).\nFrom Table 2, it can also be observed that o1-preview used substantially more tokens (a total of 53,971) than GPT-40 (a total of 15,923). Input tokens were not counted here. Additionally, GPT-40 was faster (160.6 seconds) than o1-preview (617.2 seconds) in completing the 19 questions of the exam. The visual output of o1-preview was slightly more concise than that of GPT-40 (13,139 tokens compared to 15,923 tokens). The token usage of o1-preview was largely attributable to reasoning processes that were not visible in the output."}, {"title": "Discussion", "content": "This study showed that a new model from OpenAl, called o1-preview, which exhibits System-2-like reasoning abilities, achieved a perfect score on a Mathematics B final exam for high school students. The scores achieved by o1-preview are generally consistent with the results on various benchmark tests reported by OpenAl (2024c) and have now been independently validated. The perfect score of 76 out of 76 translates to a grade of 10.0, something that only 24 out of 16,416 candidates in the Netherlands achieved. GPT-40, the model without reasoning capabilities, also performed well, with a score of 66 out of 76. In total, 96.1% of students in the Netherlands achieved this score or lower.\nThis performance was obtained in a text-only manner, meaning the model did not have access to the figures in the exam. For some questions, this meant that o1-preview had to 'visualize' the"}, {"title": null, "content": "spatial relationship between lines and points. The Mathematics B exam in the Netherlands is taken by VWO students, the highest level of secondary education in the country, and approximately 45% of VWO students took this exam (Dienst Uitvoering Onderwijs, 2023). Mathematics B is typically chosen by students who are more oriented toward STEM subjects. This makes the 100% performance score by o1-preview all the more impressive. It should also be noted that, according to OpenAl, o1-preview is not the best model. There also exists an 01 model (without the \u201cpreview\u201d suffix) that offers vision capabilities and achieves better scores on benchmarks, but which is not yet accessible to the general public (OpenAI, 2024a).\nThe fact that 01-preview can perfectly complete a final exam implies that people now have access, via an API or the web interface, to a tool that can solve problems at an extraordinarily high level and at a superhuman speed. o1-preview completed the entire exam in 10.3 minutes compared to 2.7 minutes for GPT-40, while human candidates were given 180 minutes. The OpenAl website suggests that the performance of this new System-2-like method of prompting scales well to higher levels of accuracy. This raises important questions regarding the implications of this technology. In particular, we wonder how science will adapt, especially considering that problem solving will become faster and better in the future. A similar question arises for education, where the role of a human teacher is called into question now that a generic problem solver and step-by-step explainer is available via a laptop or mobile phone.\nThe high performance of the o1-preview model also brings safety concerns. If the model is capable of solving difficult problems, as demonstrated in this work, it could potentially also be used to solve malicious tasks. For example, an advanced model might identify vulnerabilities in a computer system and exploit them (e.g., hacking), or generate harmful software (viruses) designed to cause maximum damage (see OpenAl 01 System Card for a detailed risk assessment; OpenAI, 2024b). On the other hand, LLMs with System-2-like reasoning could revolutionize problem-solving in domains such as medicine and engineering, or could offer advanced personalized education or decision-making support. In a different context, an Al-powered robot with System-2-like reasoning could optimize real-time decision-making in industrial environments such as factory floors or warehouses. Such a system could manage goods, reconfigure production lines to meet fluctuating demand, and respond efficiently to equipment failures or supply chain disruptions.\nIn conclusion, the current work has demonstrated that a new generation of LLMs, those capable of reasoning (System 2 processes), lead to a substantial improvement in performance on mathematical problems compared to the previous generation of LLMs. This new technology raises questions about the extent to which Al can mimic or even surpass human cognitive processes. It also prompts discussions about the future of scientific research, education, safety, and potential applications."}, {"title": "Data availability", "content": "A MATLAB script is used to call the API, and a file with all the results and evaluation of the output is available via the following link:\nhttps://doi.org/10.4121/2e663686-f656-4ff2-bb21-567ba4d4f03e"}]}