{"title": "Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support", "authors": ["Devika Venugopalan", "Ziwen Yan", "Conrad Borchers", "Jionghao Lin", "Vincent Aleven"], "abstract": "Caregivers (i.e., parents and members of a child's caring community) are underappreciated stakeholders in learning analytics. Although caregiver involvement can enhance student academic outcomes, many obstacles hinder involvement, most notably knowledge gaps with respect to modern school curricula. An emerging topic of interest in learning analytics is hybrid tutoring, which includes instructional and motivational support. Caregivers assert similar roles in homework, yet it is unknown how learning analytics can support them. Our past work with caregivers suggested that conversational support is a promising method of providing caregivers with the guidance needed to effectively support student learning. We developed a system that provides instructional support to caregivers through conversational recommendations generated by a Large Language Model (LLM). Addressing known instructional limitations of LLMs, we use instructional intelligence from tutoring systems while conducting prompt engineering experiments with the open-source Llama 3 LLM. This LLM generated message recommendations for caregivers supporting their child's math practice via chat. Few-shot prompting and combining real-time problem-solving context from tutoring systems with examples of tutoring practices yielded desirable message recommendations. These recommendations were evaluated with ten middle school caregivers, who valued recommendations facilitating content-level support and student metacognition through self-explanation. We contribute insights into how tutoring systems can best be merged with LLMs to support hybrid tutoring settings through conversational assistance, facilitating effective caregiver involvement in tutoring systems.", "sections": [{"title": "1 Introduction", "content": "Caregiver (i.e., parents and members of a child's caring community) involvement positively contributes to student outcomes, including academic performance and motivation [10]. However, limited research has studied caregiver involvement in learning analytics applications, such as tutoring systems and student dashboards. While tutored students learn at approximately the same rate per practiced problem-solving step, large-scale analyses found notable variation in prior knowledge [14]. If learning rates are near-constant and prior knowledge is variable, more practice opportunities could help close knowledge gaps. Motivational human support beyond cognitive tutoring, which caregivers can provide [10], is needed to help increase opportunities to practice. To do so, our field must study systems and analytics that enhance human support in tutoring system practice; a key idea we investigated was the need for caregivers to receive instructional support, along with guidance on effective tutoring strategies.\nOne emerging topic of interest in learning analytics is hybrid tutoring, where students are supported by an intelligent system and a human tutor [41]. Hybrid tutoring provides both instructional and motivational guidance [41]; this is similar to roles caregivers assert in homework support [10]. However, caregivers often struggle in proving adequate instructional homework support to students [31]. To address this issue, recent research has investigated novel ways in which caregivers can be involved in tutoring systems [27]. One promising direction suggested by this line of work is providing instructional support to caregivers. This can bridge knowledge gaps that caregivers often report regarding modern math curricula [27, 31]. Other guidance can include suggesting effective tutoring practices for caregivers. However, while prior work suggested that caregivers appreciate conversational recommendations [27], they also noted a lack of personalization and contextual relevance in pre-generated messages. The current study addresses generation of caregiver message recommendations in a hybrid tutoring context, in real time.\nLLMs have demonstrated great potential to support learning analytics applications and learners, including conversational support for debugging during problem solving [22], contextual reflection triggers in collaborative learning [26], prediction of self-regulated learning [47], and virtual teaching assistants [19], among others. These advancements promise to improve human learning through conversational tutoring. While promising, a fundamental challenge in the design of these tools is that foundation models are domain-general: they lack expert knowledge on domain-specific instruction. To circumvent this issue, recent research has suggested using instructional material as prompting aids that induce automated tutoring in a domain [36]. Other work has suggested prompting foundation models with pedagogically meaningful guardrails, such as ensuring that answers are withheld, as is practiced in effective human tutoring [30].\nWe study the integration of LLMs into a middle school tutoring system for equation-solving, Lynnette [21], in a hybrid tutoring context, an emerging area of interest in learning analytics [42]. We designed the Caregiver Conversational Support Tool (CCST), which provides personalized, contextually relevant message recommendations through LLMs for caregivers supporting learners in tutoring systems. To our knowledge, this study is the first to evaluate LLM-generated message recommendations based on both contextual information supplied by a tutoring system (e.g., hint use, accuracy, and next viable problem-solving steps) and tutoring principles. The current study presents two angles on developing and evaluating LLM-integrated tutoring systems. First, we describe prompt engineering experiments combining the tutoring system's instructional model, tutoring principles, and LLM instruction. Second, we describe an evaluation study with ten middle school caregivers involved in hybrid tutoring using the CCST, including prototype feedback and perceptions of generated conversational support during live student support. We answer these two primary research questions: RQ1: How can an LLM best generate conversational recommendations for middle school caregivers based on problem-solving context? RQ2: How do middle school caregivers perceive these conversational recommendations?"}, {"title": "2 Background", "content": ""}, {"title": "2.1 Caregiver Support in Learning", "content": "Caregivers play a key role in their child's academic success [10]. As homework increasingly moves online [23], technology-integrated caregiver support offers new involvement opportunities [25]. Yet, research on supporting caregivers with learning analytics is limited, aside from studies on AI acceptance [24]. Previous work has focused on indirect support, like notification features [4]. However, these do not enable caregivers to provide direct instructional assistance during homework, missing the potential for caregivers to actively enhance academic performance [10].\nNotably, different types of caregiver support can have varying impacts on their child's academic performance [7]. Given the importance of effective caregiver involvement in homework [10], there is a research opportunity to explore how learning analytics can support caregivers in enhancing student learning. Many caregivers struggle with homework support due to unfamiliarity with modern curricula or lack of tutoring experience [12, 27]. Providing instructional insights to bridge these gaps is a promising but underexplored approach. Our study addresses this gap by generating chat message recommendations to support caregiver involvement through a tutoring system."}, {"title": "2.2 Conversational Support and Hybrid Tutoring", "content": "Conversational interactions are central to learning and teaching [28, 37]. Effective dialog can guide students through problem-solving processes and provide real-time feedback tailored to their individual needs. Recent research has explored how LLMs can enhance tutoring conversations [17, 30, 36]. For example, Khan Academy developed Khanmigo [13], an LLM-powered tutoring system that uses conversational interactions to assist students across various subjects.\nLLMs offer the potential to enhance hybrid tutoring and support human tutors. Lin et al. [17] utilized prompting and fine-tuning approaches to develop an automated feedback system for tutor training, guiding tutors in delivering effective tutoring strategies during conversations. Despite the potential of LLMs [30, 36], a significant gap remains between these LLM-based systems and traditional intelligent tutoring systems (ITS), which are designed with instructional models that evaluate learner performance and provide adaptive instruction [21]. In contrast, most current LLM applications in education primarily offer feedback based on textual interactions, and rarely incorporate real-time log data to support student learning. This limitation might reduce the ability of LLMs to offer the level of adaptive, data-driven instruction typical for ITS [11]. Our work bridges this gap by integrating LLM strengths with the adaptive capabilities of ITS."}, {"title": "2.3 Large Language Models in Learning Analytics Application", "content": "LLMs have become increasingly relevant in learning analytics [46], demonstrating their effectiveness in various educational tasks, such as providing automated feedback to assist student writing [6]. LLMs can understand natural language in text form (e.g., students' responses to open-ended questions) from the learning process and generate text-based learning support [46]. Notably, recent research employed LLMs for enhancing teaching and learning through dialog-based ITS [36]. These applications of LLMs in education show the potential to tailor instruction, aiding student comprehension, and aligning with learning analytics goals to enhance educational outcomes [8]. Despite their potential, LLMs face limitations and open questions in educational technology applications such as ITS.\nA major concern is their tendency to hallucinate or produce incorrect information [43], which can lead to the dissemination of false or misleading content, confusing students or reinforcing misconceptions [29]. Another concern is that while LLMs can provide correct answers, they often do so without sound instructional principles, which can obstruct students' deeper learning and comprehension. To address these limitations, recent research has increasingly"}, {"title": "3 Computational Methods, Recommendation Design, and Prompt Engineering", "content": "This study aimed to engineer a tool providing LLM-generated conversational recommendations, incorporating content-level support and expert tutoring principles for caregivers helping their student in a tutoring system."}, {"title": "3.1 Tool and Instructional Context", "content": ""}, {"title": "3.1.1 Overview", "content": "The CCST aims to guide caregivers as they support their child during ITS practice. We embedded the CCST in the equation-solving Lynnette tutor [21]. Like most ITS, Lynnette provides students immediate feedback as they work through multi-step equation solving, including error-specific messages and hints. Students can practice equations with Lynnette alone, as with a typical ITS; however, the CCST also provides the opportunity for caregivers to join their child's practice and assist them through a chat panel. The CCST monitors the interaction and provides conversational support to caregivers in the form of (1) message recommendations and (2) problem-solving path previews.\nOne key advancement of the CCST is including intelligence from instructional models into prompting for addressing pedagogical limitations of LLMs [15, 39]. We used problem-solving context and adaptive instruction from Lynnette to generate message recommendations for caregivers helping their student during math practice. Like many ITS, Lynnette features a domain model for assessment, feedback, hints, and other adaptive instructional support. In the CCST, we leverage the same student action recorders used for tutoring that trace student behaviors, to prompt LLMs. We classify types of recorded student behaviors to sample from evidence-based human tutoring [41]. For instance, if the ITS graded the last attempt as incorrect, dialog related to reacting to errors would be sampled."}, {"title": "3.1.2 Caregiver-Student Interaction Design", "content": "As students solve math problems with the Lynnette ITS, the CCST provides a button to notify their caregiver through SMS. This SMS includes a link for the caregiver to open Lynnette in their browser and join their child. The following descriptions highlight the caregiver's interactions with the tool.\nWhen the caregiver joins the problem set, a chat panel appears on both the student's and caregiver's screens. The CCST includes the following features for caregivers (see Figure 1). The first is a real-time display of their child's problem-solving screen. Through synchronization and displaying live problem-solving steps, caregivers can see their child's practice progress. This includes seeing the last submitted graded problem-solving attempt and hint requests. The next feature is instructional guidance through two dropdowns. One dropdown provides suggested next steps in solving the current equation, and is updated as the student submits problem-solving attempts. The second dropdown provides chat message recommendations; caregivers can select and edit these recommendations to send via the chat panel to their child. After each problem solving step attempt and chat interaction, the message recommendations dropdown is updated, as an LLM generates new recommendations based on the current problem-solving context (see Section 3.1.3)."}, {"title": "3.1.3 CCST Features and Modules", "content": "The main components of the CCST can be summarized in three modules: the tutoring system's frontend, its instructional model, and LLM Python server, all of which are visualized in Figure 2. The frontend is where caregivers and students interact with each other and the tutoring system. The underlying instructional model of the tutoring system includes student action recorders that trace student and caregiver behaviors for prompt generation and also aid in adaptive instruction. If the student submits an attempt at solving a problem step, or if either the student or caregiver sends a chat message, relevant contextual information is sent from the client to a backend Python server. This includes the current equation being worked on, the last-attempt accuracy, hint usage, and previous chat messages. The tutoring system's instructional model also constructs solution paths to the current equation based on rules outlining viable transformations [21]. After classifying whether the solution paths lead closer to the final solution from the current state, up to three next steps, ordered based on their proximity to the desired end state of the problem (i.e., a solution for X) are included in the context sent from the client to the backend Python server. The real-time problem-solving context described above, along with additional content (e.g., persona, example responses integrating best practices for tutoring, specifications), are assembled into a prompt (for prompt engineering experiments, see Section 3.2) that invokes the Llama 3 LLM. This prompt captures problem-solving context and instructs the LLM to provide tutoring advice to the caregiver. The LLM is prompted to generate three message responses in a single run to optimize runtime while also providing caregivers with multiple recommendations. These responses are processed and sent back to the client, appearing in a dropdown on the caregiver interface, as shown in Figure 1. For this study, we chose to use the open-source Llama 3 8B Instruct model, which is the smallest version of the Llama models. This decision was motivated by our preference to (1) use an open-source model and (2) use a model that could be locally"}, {"title": "3.2 Prompt Engineering Iterations", "content": "The CCST's caregiver chat message recommendations are generated by invoking the Llama 3 LLM with a prompt integrating contextual information. We defined the following properties as desirable for these messages. First, following tutoring best practices, such as assessing a student's prior knowledge, responding to errors in a way that increases motivation and engagement, and giving effective praise that acknowledges effort [41]. Second, including brief, explana-tory text at the beginning of each message (formatted as [explanation]: message), where [explanation] highlights the main goal of the message. Examples of these explanations are \"Ask to self-explain,\" and \"Praise your child for a correct response.\" Including these explanations at the front of messages allows caregivers to understand the objective of each message recommendation [27]. Third, being contextually relevant to the live tutoring taking place. A key novelty of our approach is integrating user-specific problem-solving context, along with principles of effective tutoring, while generating message recommendations. Rather than having generalized messages, the LLM-generated messages are personalized to the current interaction, taking into account factors like the equation being worked on, hint usage, and the student's accuracy. These are reflected in generated responses, as shown in Table 1.\nWe evaluated our prompt engineering experiments using the CLEAR Framework for Prompt Engineering [20], a method to optimize interactions with LLMs. The five core principles of this framework involve determining whether a prompt is concise, logical (structured and coherent), explicit (clear output specifications), adaptive (customizable), and reflective (continuous evaluation and improvement of prompt). We conducted seven main prompt engineering rounds, iterating upon previous rounds until the quality of generated responses was satisfactory.\nWe grouped the prompts used in the seven rounds into three categories, each which served as responses to shortcom-ings of the previous category. The CLEAR framework does not prescribe specific sample sizes, so we chose to evaluate about 50 to 80 examples of generated responses per prompt experiment.\nThe prompts in Category 1 (prompts 1 - 3) followed zero-shot prompting, in which no examples of desired output were provided. These prompts provide information about the task and formatting guidelines [17, 44]. Limited contextual information (only previously sent chat panel messages) was provided. Prompt 1 instructed the LLM to assume the"}, {"title": "3.3 Prompt Engineering Results", "content": ""}, {"title": "3.3.1 Generated Response Characteristics", "content": "In the following section, we describe the characteristics of generated re-sponses when invoking the LLM with prompts from each of the 3 main categories described in Section 3.2. Each response was evaluated against the 'desirable' standards established in Section 3.2.\nCategory 1: Chat panel messages were recognized, and content from the messages was integrated into the LLM's generated recommendations. It appeared, however, that the LLM would benefit from additional contextual information in the prompt (e.g., the problem being worked on) since the generated responses often seemed to lack context. Some responses also had phrasing that would not be used in normal conversation in this context, as highlighted in this example: \"Ah okay sweetie! I'm here to help. Take a deep breath and let's take a look at the problem together. Which one is giving you trouble? Is it a multiplication or division question? Or maybe it's something with decimals or fractions? Let me see what you're working on and we'll figure it out together!\"\nCategory 2: Chat recommendations integrated best practices for tutoring and closely resembled provided examples. Since little problem-solving context was provided, the recommendations were still not specific to the given problem-solving context, as shown in this example \"Let's try solving the problem together. Can you tell me what you did first?\"\nCategory 3: The recommendations were more specific to the current interaction, appropriately integrated problem-solving context, incorporated best tutoring practices, and included explanatory messages to categorize different types of responses, as evidenced in this example: \"[Ask to self-explain ] Can you walk me through your thinking in this step? Why do you think we should divide both sides by 6?\" Responses generated by Category 3 prompts were evaluated to be the most desirable according to our standards, mentioned in Section 3.2."}, {"title": "3.3.2 Incorporation of Contextual Information", "content": "An objective of this study was to determine how integrating real-time problem-solving context into a prompt allows the LLM to generate personalized, contextually relevant recommendations."}, {"title": "4 Prototyping Study Methods", "content": "The objective of this case study was to explore how LLM-generated conversational recommendations can support caregivers during synchronous collaboration with their child, as their child practices with a tutoring system. Caregivers,"}, {"title": "4.1 Sample", "content": ""}, {"title": "4.1.1 Recruitment and Compensation", "content": "Participants for the two workshops were recruited through an outreach center affiliated with a university in the Northeastern United States. IRB approval for this study was obtained, and informed consent was taken from human subjects. For the remote interviews, caregiver-student dyads were recruited using contacts from prior design interviews in the project, primarily through social media and email lists from local caregiver outreach centers. Remote interviews were conducted after the workshops to reach a satisfactory sample size, determined by reaching saturation of qualitative insights related to our research questions, as is common practice in qualitative research [35]. Participants in the workshops received a $70 Amazon gift card each upon completion of both 2-hour sessions. For remote interviews, each caregiver and student received a $25 Amazon gift card as compensation."}, {"title": "4.1.2 Participation", "content": "A total of ten caregivers participated in the study, with four attending the workshops and six attending remote interviews. The participants were 40% Asian and 60% White, comprising 20% male and 80% female, with an average age of M = 47.9 years (SD = 6.3). The language of participation for all caregivers was primarily English, though one participant with limited English proficiency responded to some questions in Chinese."}, {"title": "4.2 Material and Procedure", "content": ""}, {"title": "4.2.1 Workshop", "content": "The workshop aimed to gather suggestions for improving the design of the CCST based on caregiver needs and explore their perceptions of LLM-generated conversational support in caregiver-student interactions (RQ2)."}, {"title": "4.2.2 Remote Interview", "content": "Each interview session lasted for one hour, and followed the same procedure as the in-person protocol. The student and caregiver were seated in separate rooms and interacted with the tool independently to simulate remote use. Screenshot annotations were omitted due to the challenges of printing and sharing annotations via Zoom. Rather, we asked participants to verbally describe any changes they would like to see and how they would implement them, allowing us to gain insights into the design solutions they envisioned. The sessions were recorded using Zoom's built-in recording feature, capturing both the breakout rooms and the main room."}, {"title": "4.3 Data and Processing", "content": "Following best practices from prior work [47], all audio records of participants' sessions were transcribed using OpenAI Whisper [32] or Zoom's built-in transcription tool. Whisper transcribed and translated utterances in Mandarin Chinese from one participant with limited English proficiency. A research team member fluent in both Mandarin and English reviewed the translations and confirmed that they were of sufficient quality for thematic analysis. Another team member recorded the handwritten notes and drawings from the annotated screenshots into a spreadsheet for further analysis."}, {"title": "4.4 Data Analysis Methods", "content": "The qualitative data (i.e., interview and annotation data) was analyzed using a thematic analysis approach with an open coding scheme. Two research team members independently conducted a first round of inductive open coding to establish initial descriptive codes [45]. A final round of discussion and consolidation of the resulting topic centers was held to eliminate individual coder bias [40]."}, {"title": "5 Prototyping Study Results", "content": "The following sections address RQ2 by presenting themes describing caregiver preferences for conversational support.\nTheme 1: Caregiver preference for content-level support over motivational support.\nCaregivers demonstrated a preference for recommendations providing mathematical guidance rather than motiva-tional support. Six caregivers preferred more direct, content-focused recommendations, two caregivers found both types of support useful, and one caregiver preferred to provide motivational help independently of the system. We identified two subthemes that further highlight the underlying reasons for this preference. Caregivers find content-level messages valuable for providing the support they often feel unequipped to offer: Messages providing"}, {"title": "Theme 2: Caregivers preferred messages that prompt student metacognition (i.e. explanation of thought processes), as it provided them with deeper insights into their child's thinking", "content": "While the CCST generally allowed for live synchronization of student problem-solving steps, allowing the caregiver to see a reflection of their child's screen (see Section 3.1.2), caregivers articulated a desire for more in-depth insight into their child's thinking. Five caregivers preferred messages that prompt students to explain their reasoning process more thoroughly. For example, C6 mentioned asking \"tell me your thought process\" and \"how you're thinking about this.\u201d C4 emphasized the importance of getting more information by looking at the \"work paper\" of the student, which may refer to scratchpad notes students craft before entering problem-solving step attempts (visible to caregivers) into the tutoring system. Similarly, C8 suggested asking \"why does the work help you solve the equation.\" Caregivers noted that understanding student thought processes can allow them to measure knowledge gaps, which in turn allow for more targeted support. As C9 noted, \"Walk me through it and can you explain to me what you did here. I think those are good they reinforce that the need to be able not just to come up with an answer but to explain and to show your work in whatever manner is required.\" Another caregiver C8 added that \"I would say ask them just to speak out their thought process loud, so I know where the mistake is. So, you know, it can be a careless error right and or they just don't know how to do it. So I want to find out why they did it wrong.\"\""}, {"title": "5.1 Technical Feedback and Feasibility of Generated Messages", "content": "Caregivers also provided feedback covering technical aspects of the messages (i.e. length, style), as well as the effective-ness of incorporating problem-solving context. Contextual Information: The inclusion of problem-solving context (see Table 1), specifically, incorporating whether the student used hints or made errors, was recognized and appreciated, since it provided additional opportunities to engage with and understand instructional content. C8 emphasized that \"They [messages] should be based on the mistakes or the steps of which [student] got wrong to have customized.\" C5 expressed \"Oh that's good, 'How about you request a hint and walk me through it?' Cuz he may have just asked me before he hit the hint.", "Length": "Six out of nine caregivers found the messages to be too long, making them hard to process during live tutoring. For example, C6 noted that: \"Like having to read through this text is cumbersome.\u201d Number of Messages: While eight out of nine caregivers felt the number of messages (i.e., three recommendations at a time) was adequate, one parent preferred a narrowing down to only one message. Message Style: Caregiver feedback on tone was mixed. Three out of seven caregivers found the tone of the message recommendations lacking, each citing that the tone is inauthentic and artificial. C5 noted: \"Glad you're focused just seems artificial to me."}, {"title": "6 Discussion", "content": "The objective of the current study is to determine how to effectively generate conversational support for caregivers providing guidance as their child practices with an ITS. We did so by combining the instructional model of a tutoring system and the language abilities of an LLM, aiming to address LLM limitations for instruction identified in prior research [39]. We then determined caregiver perceptions on LLM-generated conversational support by conducting interviews in which we tested the Caregiver Conversational Support Tool (CCST) with middle-school caregivers."}, {"title": "6.1 Conversational Support Message Generation", "content": "RQ1 focused on how tutoring system capabilities and best tutoring practices can be provided to an LLM to generate conversational recommendations. We conducted prompt engineering experiments integrating tutoring system context data (e.g., correctness, problem-solving pathways) with LLM instructions using the open-source Llama 3 LLM.\nRecent research has argued that LLMs lack instructional principles, such as determining a student's prior knowledge, to suffice as tutoring agents [39]. We found that the LLM was able to adequately integrate problem-solving context into generated message recommendations. We also provided the LLM with guidance as to how it could use that data from a tutoring system to provide suggestions in generated responses (see Figure 3). We observed that such instructions, alongside few shot examples on effective tutorial dialog [41], were especially useful for generating message recommendations attuned to student actions. Further, by providing specific solution options as to how the student may solve the equation, we observed no issues related to providing incorrect, hallucinated math advice. While the tutoring system can generate correct solutions without error due to its instructional model, an LLM alone lacks arithmetic abilities [9, 48]. We only observed such hallucinations when limited tutoring system context was given in Category 1 prompts (see Section 3.2). Taken together, we observed that generated messages were not only pedagogically fit for tutorial dialog [41], but also more reliable in terms of arithmetic and tutoring advice."}, {"title": "6.2 Prototyping Study Discussion", "content": "RQ2 focused on caregiver perceptions of conversational recommendations integrating tutoring system and LLM intelligence. Design research employing the CCST with ten middle school caregivers provided tangible insights into how caregivers can be best supported in homework support, which is crucial for student learning [10, 27].\nCaregivers appreciated content-level support and desired further opportunities to engage with content: Caregivers appreciated both content-level and motivational support messages during tutoring but saw greater value in content-level support. They appreciated messages that integrated instructional guidance in messages, including the \u201cSuggested Next Steps,\u201d which provided concrete instructions as to how to solve an equation. These steps were particularly helpful for caregivers who felt less confident in providing accurate math help, as they offered clarity and reassurance, which aligns with prior research on caregiver support needs [27, 31]. Caregivers also valued the integration of real-time problem-solving context (i.e., student hint use and errors) within content-focused messages, especially when it helped them and their child to engage with the content. Future designs should aim to integrate such data-driven"}, {"title": "6.3 Implications", "content": "Caregivers describe lack of instructional support as a key barrier to getting involved with their child's online homework [27]. Hence, one central goal of the CCST was to aid caregivers in bridging knowledge gaps while supporting their child during tutoring system practice. Our results suggest that this instructional support could help caregivers in providing instructional interventions in their child's math homework [10]. The caregivers we interviewed in this study especially favored message recommendations that targeted content-level support, which were informed by tutoring system instruction and log data. Hence, as a broader implication to the field, content-level conversational support through LLMs may augment increasingly common hybrid tutoring scenarios to improve student learning [41]. Moreover, addressing recently identified instructional limitations of LLMs [39], our findings imply that tutoring system instruction and log data collected during practice can be productively integrated into LLMs to help improve the instructional rigor of LLM generations in educational contexts similar to the one studied here.\nFor productive merging of tutoring systems and LLMs, we note that providing tutoring system data into prompting is not enough; it requires instructions and examples as to how these data should be used. Thus, other applications providing context to better inform foundation models should accompany data with explanation when prompting an LLM, for example, by describing tutoring best practices, as done in this study [41]. This method of using an LLM and ITS in conjunction is a key contribution to the present study.\nOur designs and methods may be transferred to other systems supporting learners that are common in learning analytics. For instance, collaborative learning systems, where students work together to solve problems, might benefit from the incorporation of an LLM providing instructional support. It can be challenging for middle-school students to effectively collaborate, even when rule-based support that interprets conversations is present [3], so integrating an LLM that provides suggestions based on instructional context from tutoring systems could guide student collaboration. Our findings may also inform systems involving no live human interaction. For instance, the JeepyTA [19] uses an LLM as a virtual teaching assistant. Although JeepyTA's initial evaluation found it effective in providing information about a course, it lacked capabilities to sustain student motivation and contribute to effective learning, which might be addressed through responsive and motivational message support reported here. Overall, integrating effective tutoring practices and tutoring system intelligence into LLMs may enhance personalized support in online learning. However design research with end-users will be important for sustainable adoption and improved learning. There is also a"}, {"title": "6.4 Limitations and Future work", "content": "We acknowledge three study limitations. First, our hardware and resource limitations of this project limited the speed of message generations when running LLMs, which could be further improved through GPUs. Average latencies for message recommendations in this study were about 25 s, which at times was perceived as too slow by caregivers, especially when reference was given to specific actions in the tutoring system. Future work may investigate how recommendations can better deal with latency, for example, by updating recommendations to include less specific advice if the tutoring system detected the student to have moved on from when the request was first sent. Another point of exploration is using different LLMs beyond Llama 3.\nSecond, our prompt engineering method was purely qualitative, using the CLEAR framework [20]. While this method is suited for quick prompt iterations, future research may study the emerging characteristics of message recommenda-tions through sentence embeddings, including but not limited to, clustering, to refine prompting. Quantitative curation of message recommendation may further be used to fine-tune LLMs toward more desirable output.\nThird, participants may not necessarily be representative of the larger caregiver population. Considering that participants were volunteers, there is a potential bias that these caregivers are especially engaged in homework support. In addition, most were women, and all were either White or Asian. To ensure equity and inclusivity of our tool's use and design, future work could involve recruiting a larger and more diverse sample for design research."}, {"title": "7 Summary and Conclusions", "content": "This study investigated integrating tutoring systems and LLMs to improve conversational support in hybrid tutoring, where caregivers and tutoring systems assist students in problem solving. While previous research highlights the value of caregiver involvement in homework, little learning analytics research has studied how caregivers can be supported in asserting practice support roles. Our results show that using instruction and log data from tutoring systems in prompts enables LLMs to generate contextually relevant messages for hybrid tutors. The LLM adapted its responses based on problem-solving context, and we found that effective prompting requires not just data, but also example responses. Based on design research, caregivers valued content-level message recommendations from our system and especially appreciated those prompting their child to explain their thought process. Such metacognitive prompts show promise in helping caregivers support students in their homework constructively, which not all caregivers do or are able to. A key contribution of this work is demonstrating how LLMs and tutoring systems can work together during problem solving, using real-world data to provide caregivers with effective tutoring guidance. This approach enhances personalized, contextually relevant conversational support, advancing learning with intelligent tutoring systems."}]}