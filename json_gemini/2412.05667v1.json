{"title": "Training neural networks without backpropagation using particles", "authors": ["Deepak Kumar"], "abstract": "Neural networks are a group of neurons stacked together in multiple layers to mimic the biological neurons in a human brain. Neural networks have been trained using the backpropagation algorithm based on gradient descent strategy for several decades. Several variants have been developed to improve the backpropagation algorithm. The loss function for the neural network is optimized through backpropagation, but several local minima exist in the manifold of the constructed neural network. We obtain several solutions matching the minima. The gradient descent strategy cannot avoid the problem of local minima and gets stuck in the minima due to the initialization. Particle swarm optimization (PSO) was proposed to select the best local minima among the search space of the loss function. The search space is limited to the instantiated particles in the PSO algorithm, and sometimes it cannot select the best solution. In the proposed approach, we overcome the problem of gradient descent and the limitation of the PSO algorithm by training individual neurons separately, capable of collectively solving the problem as a group of neurons forming a network.", "sections": [{"title": "1 Introduction", "content": "We are fascinated by exploring the world of biological neurons in the human brain. Many researchers have spent their whole lives decoding and understanding the workings of the human brain. The researchers conceptualized models to propose the workings of the human brain. One of the early proponents is neural networks. Neural networks are a group of neurons stacked together in multiple layers and modeled to mimic the parts of a human brain. A perceptron was used to classify a set of linearly separable classes through adaptive weight updates [3, 4, 9, 10]. However, the perceptron was unable to classify the nonlinearly separable data samples. A multiple layer of perceptrons (MLP) was conceptualized to overcome the problem of classifying the nonlinearly separable data samples. The backpropagation algorithm was developed to update the weights from the top (higher) layer to the bottom (lower) layer using a gradient descent approach in the reverse order [30]. Several variants of backpropagation algorithms are developed. A few are Stochastic gradient descent (SGD), RMSProp, Adam optimizer, and Adamax [8, 18]. One of the difficulties was the vanishing gradient that appeared when the number of layers was higher in a neural network. The activation function was changed from a sigmoid to a rectified linear fashion. The neural node inactive in the forward computation is not updated in the rectified linear activation function. During backpropagation, it helped to reduce the vanishing gradients problem. The backpropagation algorithms settle to a local minimum while optimizing the loss function constructed for the neural network. However, a few approaches smooth the manifold of the function to improve the optimization and choose a better optimal value.\nParticle swarm optimization (PSO) was inspired by the nature of birds flocking and fish schooling [16, 17]. It chooses the best neural network from a set of particles (birds). The particles are introduced in the search space. The birds share the value of the function at a particular location with each"}, {"title": "2 Related Work", "content": "Several approaches have been explored to train neural networks, improving backpropagation or without it. A reward penalty function was introduced to train multiple layer perceptron or neural networks without backpropagation [1]. The global performance of the network is used as an estimate for the gradient instead of an exact gradient in [1]. We need forward and backward passes in backpropagation during training, and the weights are to be transported. The weights of neural networks are updated without transporting the weight information, but changes in the weight values are transported in [20]. A refined version of backpropagation was proposed to work on the network weights. An implicit error feedback is used in place of backpropagation [6]. Another kind of refinement was proposed on backpropagation in terms of linearity. A linear backpropagation approach is replaced by a non-linear backpropagation as part of refinement [12].\nThe helpfulness of forward matrix computation in training the neural network was explored in [32]. A set of random search options to minimize the convex functions was proposed and showed that the backpropagation still holds good as a rule to move forward or accelerate the action [28]. The error propagation with random synaptic weights helps to learn, which approximately aligns with their feedforward synaptic weights. The feedback alignment approach demonstrates similarity with the backpropagation approach [25, 26]. Random feedback will help backpropagation, and the constraints are not required. An exploration of mitigating the exploding and vanishing gradients is also covered [25, 26]. A method is applied to RNN by generating synthetic gradients while performing forward passes. The updates between each step are decoupled in this method to show the decoupled networks can learn independently in [14]. The system in [11] uses Ensemble Kalman Filter particles to update the weights. However, the condition is strict in improving the objective function. A machine learning problem is posed as an inverse problem, and an ensemble Kalman filter is used for non-derivative objective functions [21].\nThe multiple layer networks as autoencoders at each stage to build the representation in the system lead to the proposal of the Neural gradient representation (NGRAD) framework to demonstrate the"}, {"title": "3 Particle Swarm Optimization (PSO)", "content": "Particle swarm optimization (PSO) was proposed for optimizing the weights of a neural network [16]. Literature on all derivative-free optimization algorithms applied to non-derivative functions with several convex and non-convex problems in [29]. PSO is applied to numerous applications for optimizing non-linear functions [17]. PSO evolved by simulating bird flocking and fish schooling. The advantages of PSO are conceptually simple and easy to implement. Particles are deployed in the search space, and each particle is evaluated against an optimization function. The best particle is chosen as a directing agent for the rest. The velocity of each particle is controlled by both the particle's personal and global best. During the movement of the particles, a few of them may reach the global best. Several iterations are required to attain the global best.\nLet $X = x_1, x_2, ..., x_k$ be the particles deployed in the search space of the optimization function, where k is the number of particles and $V = V_1, V_2, ..., V_k$ be the velocities of the respective particles. $X_i, V_i \\in R^n$ for all the k particles. A simple PSO update is as follows.\nVelocity update equation\n$v_i^j = w v_i^{j-1} + C_1 r_1 (x_{bi} - x_i^{j-1}) + C_2 r_2 (x_{bg} - x_i^{j-1}),$ (1)\nwhere w is the weight for the previous velocity; $C_1, C_2$ are constants and $r_1, r_2$ are random values varied in each iteration. $x_{bi}$ is the personal best value for particle i and $x_{bg}$ is the global best value among all the particles. $v_i^j$ is the updated velocity of the ith particle in the jth iteration and $v_i^{j-1}$ is its velocity in the (j \u2013 1)th iteration, $x_i^{j-1}$ is the position of the ith particle after (j \u2013 1)th iteration.\nThe updated velocity is added to the existing position of the particle. The position update equation is\n$x_i^j = x_i^{j-1} + v_i^j$ (2)\nwhere $x_i^j$ is the updated position of the ith particle in the jth iteration."}, {"title": "3.1 Craziness term", "content": "The original PSO paper had removed the craziness term in the velocity update equation because the algorithm looked realistic and sufficient. When PSO was applied in [23] for optimization of convex optimization functions, the particles used to get stuck in particle direction due to the boundary conditions of the convex functions. This is particularly relevant when there is a limited set of directions in the particles to move forward [22]. However, this is not the case when the number of particles is large. The relevance of the craziness term is minimized with the number of particles. Then, [22] introduced the craziness term in the velocity update equation to use less number of particles. With the introduction of the craziness term, the particles started exploring the search space and reached the optimal value in convex optimization functions and non-convex functions with boundary conditions.\n$v_i^j = w v_i^{j-1} + C_1 r_1 (x_{bi} - x_i^{j-1}) + C_2 r_2 (x_{bg} - x_i^{j-1}) + c_3 r_3$ (3)\nwhere $c_3$ is a constant and $r_3 \\in R$ is a random vector similar to a particle position."}, {"title": "4 Neural networks (NN)", "content": "Neural networks are constructed by placing many neurons in multiple layers. Multi-layer perceptron (MLP) is a general way of understanding neural networks. It consists of three layers: the input layer, the hidden layer, and the output layer. There may be one or more hidden layers in a neural network. A simple MLP is shown in Figure 1 with the three layers. The backpropagation is used to train neural networks. We compute the loss function f(x) for a given data during training (which is known as forward pass) and use it as a reference to update the weights of the network (which is known as backward pass) through a variety of gradients."}, {"title": "4.1 Individual neuron node", "content": "The loss function is tightly dependent on the combination of all nodes in a network. If the weights of a neuron change in a node, then it is propagated to all higher-layer nodes in the network. We would like to know the contribution of each node in the network. We can perform this operation by fixing the weights of all nodes except the considered node. We can change the considered node weights and compute the loss function for the network. We observe similar behavior or patterns of local minima in the loss function. Instead of a complete network, we approach individual neurons to find the local or optimal value.\nIn a neural network, we shall isolate a single neuron node. Here, we fix the weights of all other neurons except the isolated node. The weights of the isolated nodes are perturbed or changed randomly based on the principles of PSO. We perform weight changes for 'k' times to match the particle swarm optimization (PSO) approach. In Figure 2, we have placed \u2018k' particles in each neuron node. Now, we have 'k' different weights for the isolated node. We compute the loss function value by plugging in the \u2018k' different weights of the isolated node. We get 'k' different loss values. We shall choose the minimum value and its weight as the better performance of the node. The contribution of other nodes appears in the computation of the loss function and does not involve in the isolated node"}, {"title": "5 Proposed method", "content": "The individual nodes act independently by fixing the weights of all other nodes. The control of the individual nodes is difficult. When all the nodes are updated, we select the best weights for each node and combine them. All the node weights combination forms the best network weights for the problem. Now, we compute the training/validation loss for the data. After the weight update, we will come to know whether the loss has decreased or not. If the loss has been reduced, the new weights are the best weights for the network, or the previous best weights are used as the best weights. If the best weights are rewired back to each node as the global best for each node, then the network sticks to the original best weights and restricts the exploration of the manifold by the nodes. The isolated nodes are unrestricted by any performance control metric. However, the group of all the best weights from all the nodes is evaluated to control the network behavior. The performance measure condition used to select the best weights controls the behavior of the nodes in a grouped form and forces the nodes to reach the best optimal position. The performance measures may be training loss, validation loss, training accuracy, or validation accuracy. Independent/validation data different from the training data exerts more control on the weight update for the network. Figure 3 shows the flowchart of the proposed method in a batch-wise training approach.\nIn batch-wise training, we split training data into several batches and passed them to the network. Each batch of data is new and unseen for the network during training. When PSO particles are updated in the nodes for one batch, the personal and global best are highly likely to change after the update due to the movement of the particles to a new position. The individual best position of each particle is retained and evaluated for the next batch. If the personal best position is best for the new batch, then the personal best position is retained else it is updated with the new position found for the new batch. The concept of the global optimal position is unknown to the node, and the node reaches the global optimal position after several iterations. Now, the PSO particles change their position randomly through some updates. However, the node has already reached the global optimal position, and the updates would have changed the position of the particles, which is not optimal. Since the particles are not restricted, the particles move out of the global optimal position. To check the global optimal position, we compare the loss function value for the next batch with the global optimal position and the updated position of the particles. If the updated position of the particles has a better loss, then the particle position is updated else the previous optimal position is retained without moving to a new position. In this way, the movement of particles after reaching the global optimal position is controlled.\nWhen we split the training data into batches, the loss function fik is divided into batches. Initially, the loss function is set to zero after each epoch. The particles are updated after each batch. So, we have the previous best position and the newly updated position for the next/new batch. We compute the loss function for both the particle positions and compare their loss functions. The final loss function is updated as shown in the equation.\n$f_i = \\begin{cases}\n f_i^{j-1} + f_{ik}(w_{ik}^j), & f_{ik}(w_{ik}^j) < f_{ik}(w_{ik}^{j-1})\\\\\n f_i^{j-1} + f_{ik}(w_{ik}^{j-1}), & otherwise.\n\\end{cases}$ (5)\nwhere $w_{ik}^j$ is the weight of the kth particle in the ith node for the jth batch, $w_{ik}^{j-1}$ is the personal best weight of the kth particle in the ith node for the j \u2013 1th batch, $f_{ik}^{j-1}$ is the loss for the j \u2013 1th batch, and $f_{ik}^j$ is the loss for the $j^{th}$ batch .\nThe proposed method algorithm is presented on the next page. We initialize a neural network with nodes in each layer. Each node in the network gets its particle to explore the search space. There may be 'k' particles in each node that act independently. The random weights are assigned for each particle. In the first batch or epoch, the first particle weight is chosen as the global best weight of a neuron to perform the computation before selecting the best particle position. The training data is split into batches. We set the loss function in each node to zero and the validation loss function to Infinity. The loss function value is set to zero after every epoch. The particle position, the node weight, is used to compute the loss value for the given batch while fixing all the other node weights in the network. We obtain 'k' loss values and select one of them as the global best value for the node. All the nodes are updated similarly, and the global best values are computed for the entire network. Now, we compute the training/validation loss of the independent set to check whether the loss is better and update the global best value and the global best weights. From the next batch, we compute two losses: a loss value for the updated position and a loss value for the personal best position of the particle. We compare both loss values and update the loss and position values depending on the loss values. The comparison is performed when the data is used batch-wise. We do not use comparison when the complete data is utilized in the loss value computation. The comparison provides an overlap between the data batches for a position. The process is repeated for all the batches. The process is repeated for 'n' epochs, or the loss is not updated for certain epochs."}, {"title": "6 Experiments and Results", "content": "We have created synthetic examples to simulate a real dataset and demonstrate the functioning of the proposed method. The complexity of the examples increases with the number of classes and the addition of nonlinearity in the examples. We have used our proposed method on the two real datasets. All the datasets are normalized to zero mean and unit variance except the linearly separable classes dataset. We have also compared the proposed method with the other MLP implementations. The number of epochs is set to 20 when the neural networks are trained for simulated datasets."}, {"title": "6.1 Linearly separable classes", "content": "Two classes are generated in this synthetic example using Gaussian mixtures, as shown in Figure 4. A single perceptron with mean square error (MSE) loss is used as the MLP implementation. The implemented MLP is based on the Pytorch framework with a stochastic gradient descent (SGD) algorithm, which quickly finds the minimal solution. A neural network with 4 nodes in the input layer and 2 in the output layer is constructed to classify the samples. A binary cross-entropy (BCE) loss function is used as the loss function to compute the loss in the PSO-based solutions. The PSO-based solution without the craziness term gets stuck in local minima and doesn't go further to"}, {"title": "6.2 Nonlinearly separable classes", "content": "There are two classes based on four Gaussian mixtures in this synthetic example, and they are nonseparable, as shown in Figure 5, which cannot be solved using a single perceptron. An MLP architecture is needed to solve this generated synthetic data. A neural network with 4 nodes in the input layer and 2 in the output layer is constructed to classify the samples. The MLP implementation has one node as the output node and is trained using MSE loss, whereas the PSO implementation has two nodes in the output layer and is trained using BCE loss. The PSO solution without craziness terms gets stuck in local minima. The MLP using SGD for backpropagation takes extra time to reach a minimal solution. The proposed method using Octave and Python programming languages reaches a minimal solution and follows the gradient descent approach."}, {"title": "6.3 Increased nonlinearity", "content": "There are two nonseparable classes based on nine Gaussian mixtures in this synthetic example, as shown in Figure 6. A two-layer neural network faces difficulty in solving the problem. A three-layer network or a higher number of layers solves the problem. All the approaches use 8 nodes as the input layer, 6 as the hidden layer, and 2 as the output layer. A binary cross-entropy (BCE) loss function"}, {"title": "6.4 Increased number of classes", "content": "There are four nonseparable classes based on nine Gaussian mixtures in this synthetic example, as shown in Figure 7. A three-layer network or a higher number of layers solves the problem. All approaches use 8 nodes as the input layer, 6 as the hidden layer, and 4 as the output layer. A cross-entropy (CE) loss function is used as the loss function to compute the loss in the solutions. The MLP with backpropagation gets stuck in a local minima many times, as shown in Figure 7. However, the proposed method using Octave and Python programming languages follows the gradient descent and reaches a minimal solution. The Gaussian mixture in the middle section of the data is not correctly classified several times because of strong local minima in the solution. The particles manage to move out quickly and reach a better solution."}, {"title": "6.5 Rice dataset", "content": "A set of 3810 rice grain images were collected from the two species (Cammeo and Osmancik) [7]. There are seven morphological features extracted from each image. The morphological features are area, perimeter, major axis length, minor axis length, eccentricity, convex area, and extent. We"}, {"title": "6.6 Dry bean dataset", "content": "A set of 13611 dry bean images were collected from 7 different dry beans (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz, and Sira) [19]. There are 16 features consisting of 12-dimensional features and 4 shape-form features. We perform 13-fold cross-validation on this dataset. We construct a four-layer neural network with 16 nodes in the input layer, 12 in the first hidden layer, 3 in the second hidden layer, and 7 in the output layer, as mentioned in [19]. We use cross entropy (CE) loss to compute the loss and train the neural network. The number of epochs is set to 100."}, {"title": "7 Discussion", "content": "We have proposed a method that does weight updates without backpropagation. We compare the flow rate of loss value between the proposed method and the backpropagation-based MLP architecture. It is confirmed that the proposed method follows the backpropagation approach while improving the loss value. We tested our proposed method on two real datasets to validate the results obtained using MLP architecture. The last three rows of Tables 1 and 2 show the performance metrics close to each other. The neural network for the real datasets has more layers and nodes in each layer compared to the simulated datasets. The performance of the proposed method is similar to that of the backpropagation approach. We used a rectified linear unit (Relu) as a non-linear function for all the nodes while computing the loss value. We replaced a rectified linear unit (Relu) with tangent hyperbolic (Tanh) as a non-linear function. The loss values for two simulated datasets using Relu and Tanh functions are shown in Figure 8. The underlying weight update operation is unaffected by changes in the non-linear functions present in the nodes.\nOne of the main advantages of the proposed method is individual computation by each node. The weight updates in each node are independent and can be performed parallelly without depending on the weight updates of other nodes. It resembles a neuronal firing by a neuron in a brain without much dependencies on the other neurons. In backpropagation, all the weights are updated simultaneously. Here, the weight update is independent of layers and nodes in the proposed method. In backpropagation, we update the weights when there is an error signal, and the weight updates are proportional to the error signal. In the proposed method, the weight updates are random without using an error signal. It may look like a random search and run away from the global optimum value for the network. However, the global best weight of a node restricts the runaway problem through a controlled measure of validation loss. We can construct arbitrary neural network architectures without following standard formats or processes. There may be an individual connection between a lower-layer node and a higher-layer node. The proposed method provides an opportunity to create the possibility of a complex neural network constructed with all sorts of connections between the nodes. The complex connectivity may lead to a close resemblance of brain neuronal activities. We need to study the limitations of arbitrary neural networks by exploring the proposed method.\nOne of the main limitations of the proposed method is the repeated computation of loss values, which increases with the nodes, layers, and data. It is sometimes redundant to compute the loss values repeatedly without any improvements in the loss values. There may be a functional mapping between the loss value and the weights of each node. If we can create the functional mapping between the loss value and the node weights, then the repeated computation may be reduced.\nThere is no clear evidence of backpropagation in the brain when updating the synaptic weights. However, the representation formed in each layer resembles the trained weights of a neural network. Most neural networks are trained using a single global objective function, but biological neural networks rely on self-organization behavior [31]. In our proposed method, each neuron is considered independent and aligns with the global objective. The neuron node receives the performance score and aligns itself in that direction. The neuron doesn't look at the other neuronal nodes for synaptic weight changes and keeps updating its weights. Thus, the weight update doesn't depend on the other nodes in the proposed method. The global best weights constrain and guide the neuron to reach optimal value. We tried to tie the global best weights as part of the correction in each particle within a node. This approach didn't yield fruitful results. Hence, we left individual particles within a node to act independently and use only the performance score for alignment. It is like tuning a filter by turning the knobs and observing the performance. We keep a reference while turning the knobs and choose the best performance. A similar concept is used in the particles to select the best weights. The objective loss function is split into many smaller functions. The smaller objective functions at each neuron may be related to the objective function and more concerned with choosing the best weight for the neuron. A collective behavior of nodes and particles shows the possibility of training a network in the proposed method."}, {"title": "8 Conclusion", "content": "We proposed a method to update the node weights in a neural network. The proposed method overcomes the drawbacks of backpropagation and PSO. However, the proposed method has the drawback of redundant computation. We would like to reduce the computation by exploring the functional mapping between the nodes. In this paper, we explored MLP architecture using the proposed method on the simulated and real datasets. The performance metrics are similar to MLP architecture, which is trained using backpropagation. We would like to explore other neural network architectures like RNN, Transformers, and other networks to identify the limitations of the proposed method."}]}