{"title": "RHIOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms", "authors": ["Luis Roque", "Carlos Soares", "Lu\u00eds Torgo"], "abstract": "We introduce the Robustness of Hierarchically Organized Time Series (RHIOTS) framework, designed to assess the robustness of hierarchical time series forecasting models and algorithms on real-world datasets. Hierarchical time series, where lower-level forecasts must sum to upper-level ones, are prevalent in various contexts, such as retail sales across countries. Current empirical evaluations of forecasting methods are often limited to a small set of benchmark datasets, offering a narrow view of algorithm behavior. RHiOTS addresses this gap by systematically altering existing datasets and modifying the characteristics of individual series and their interrelations. It uses a set of parameterizable transformations to simulate those changes in the data distribution. Additionally, RHiOTS incorporates an innovative visualization component, turning complex, multidimensional robustness evaluation results into intuitive, easily interpretable visuals. This approach allows an in-depth analysis of algorithm and model behavior under diverse conditions. We illustrate the use of RHIOTS by analyzing the predictive performance of several algorithms. Our findings show that traditional statistical methods are more robust than state-of-the-art deep learning algorithms, except when the transformation effect is highly disruptive. Furthermore, we found no significant differences in the robustness of the algorithms when applying specific reconciliation methods, such as MinT. RHIOTS provides researchers with a comprehensive tool for understanding the nuanced behavior of forecasting algorithms, offering a more reliable basis for selecting the most appropriate method for a given problem.", "sections": [{"title": "1 INTRODUCTION", "content": "In time series forecasting, modeling inter-temporal dependencies between observations is a crucial task to capture the dynamics of the underlying process. Furthermore, considering cross-series information, i.e., the relationship between multiple related time series, can enhance the performance of traditional univariate algorithms [22]. Such relationships occur in many real-world situations and often represent hierarchical structures, such as in data concerning Gross Domestic Product [2], epidemics [10], and sales demand [19]. Coherent forecasts [22], which satisfy these hierarchical relations, are often required in such applications. To improve performance, state-of-the-art algorithms for hierarchical time series (HTS) forecasting rely on both the autocorrelation of each time series and the cross-series correlations [16, 33].\nAn important characteristic of HTS forecasting algorithms is their robustness to changes in time series relationships, such as variations in seasonality, trends, cross-series dependencies, and volatility. These phenomena significantly impact predictive performance and may lead to inaccurate forecasts and suboptimal decision-making. Nevertheless, conventional evaluation methodologies, typically based on a small number of datasets and metrics, cannot assess the robustness of HTS forecasting algorithms in dynamic scenarios where relationships between time series and temporal dependencies change over time. We note that the concerns about the adequacy of evaluation methods are not limited to HTS forecasting. In fact, there is a growing discussion on the limitations of empirical evaluations in time series analysis (e.g., anomaly detection [35]). We argue that similar issues can be raised for time series forecasting since both suffer the exact root cause: most papers evaluate algorithms on one or more of a handful of popular benchmark datasets (e.g. [29, 30]).\nThis work introduces the Robustness of Hierarchically Organized Time Series (RHIOTS) framework. RHIOTS is designed to evaluate the robustness of HTS forecasting models and algorithms facing real-world data distribution changes. Our framework systematically quantifies the robustness by imposing controlled realistic transformations, mimicking common patterns observed in actual datasets. These semi-synthetic datasets retain essential characteristics of the original data while introducing new dynamics, serving as a robust baseline to assess algorithmic performance against data variations. RHIOTS has an innovative visualization component,"}, {"title": "2 BACKGROUND AND NOTATION", "content": "We are working with a collection of S related univariate time series, Z = {z\u1d62}, t \u2208 N, i = 1, . . ., S}. The training values can be written as Z\u2081\u1d40 = {z\u1d62 = [z\u1d62,\u2081, z\u1d62,\u2082,\u2026\u2026\u2026, z\u1d62,\u209c] }, where z\u1d62,\u209c \u2208 \u211d denotes the value of time series i at time t and T represents the last training point. When the interpretation is unambiguous and to simplify the notation in specific sections, we refer to z\u1d62 as the observed time series. The training range is denoted by {1, 2, ..., T}, while {T + 1, T + 2, ..., T + \u03c4} is the prediction range and \u03c4 is the forecast horizon. Point predictions are defined as \u1e90\u1d40\u208a\u2081:\u1d40\u208a\u03c4.\nHTS organizes a collection of time series, represented as z\u1d40, within a hierarchical structure denoted by H. The hierarchy H is a tree-like structure, where each node represents a group G\u1d62 or a time series z\u1d62. The root of the tree represents the total aggregate of all the time series in the dataset, denoted as z\u209c. The leaf nodes of the tree represent individual time series z\u1d62. Each time series z\u1d62 is associated with one or more groups G\u1d62 in the hierarchy. Thus, we can write G\u1d62 \u2286 1, ..., S where z\u1d62 = \u2211\u1d62\u2091G\u1d62 z\u1d62. The subset of groups a time series z\u1d62 belongs to is denoted by L\u1d62 = {l : i \u2208 G\u2097}. G denotes the set of all groups, and its cardinality is denoted by |G|.\nThe objective of HTS forecasting is twofold: firstly, to minimize the forecast error for each series within the hierarchy, and secondly, to ensure that forecasts at all levels of the hierarchy are consistent with each other. Formally, the forecast error for a series i over a prediction horizon \u03c4 is defined as E\u1d40\u208a\u2081:\u1d40\u208a\u03c4 = {e\u1d62 =  \u1e90\u1d62,\u209c \u2212 z\u1d62,\u209c | t \u2208 {T + 1, T + 2, . . ., T + \u03c4}}, where \u1e90\u1d62,\u209c denotes the forecasted value and z\u1d62,\u209c denotes the actual value at time t. The consistency constraint requires that for any aggregated level within the hierarchy, represented by a group G\u2097, the aggregated forecasts \u2211\u1d62\u2091G\u2097\u1e90\u1d62,\u1d40\u208a\u2081:\u1d40\u208a\u03c4, should equal the sum of forecasted values for all time series i belonging to that group. This ensures that the forecasts respect the hierarchical structure, maintaining integrity and coherence across all levels of aggregation within the dataset."}, {"title": "3 RELATED WORK", "content": "Hierarchical Time Series Forecasting Methods. Univariate methods like ARIMA and ETS are common for individual time series analysis and can be used for HTS when using simple reconciliation strategies [14]. General approaches like those found in [9, 23, 26, 32] are methods used to forecast a set of time series from the same domain. It means that they are capable of learning relationships among time series. However, these approaches do not incorporate any hierarchical structure, missing out on leveraging it to improve forecasting accuracy.\nAlternatively, several methods explicitly model the hierarchical nature of HTS datasets. Early approaches by [15], followed by refinements in [1, 22], involve fitting and reconciling independent forecasts at all hierarchy levels. Non-linear models (e.g., [13]) improve their ability to capture complex patterns in the data by employing optimization and regularization techniques during the model training process. Another approach uses Gaussian Processes and does not require any reconciliation since the hierarchical structure is an input to the model itself [31].\nEvaluating Hierarchical Time Series Forecasting. The evaluation of HTS forecasting models has received limited attention in recent literature. Exceptions. For example, [13] and [3], compare the performance of state-of-the-art reconciliation models on a limited set of real-world datasets. Despite considering various forecasting models, the fact that the experimental setup does is so limited and does not provide rich data variations, our ability to generalize is limited. Recently, a practical guide addressing concepts like scale, units, sparsity, forecast horizon, multiple evaluation windows, and decision context has been proposed [5]. However, the guide falls short in objectively quantifying performance differences between models beyond basic accuracy assessment on benchmarks.\nTime Series Augmentation. Data augmentation involves generating synthetic data that covers unexplored input space while preserving correct labels [34]. This technique has proven effective in domains such as computer vision, where methods like AlexNet [21] have leveraged augmented data for image classification. On the other side, the unique properties of time series data, such as its temporal dependencies and intricate dynamics, create a set of challenges.\nAutoregressive models, while effective for linear, stationary time series, face limitations with complex data and computational demands [18]. Generative models, including Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), have emerged as powerful tools for augmenting time series data. GANs, particularly TimeGAN, and extensions of this work, create realistic synthetic samples by learning temporal dynamics, albeit with training challenges [25, 34, 36]. VAEs and their conditional variants (CVAEs) generate new data from a latent space, offering potential despite some control issues over the generated samples [8, 11, 12, 34].\nSliding window methods risk overfitting by focusing too narrowly on local patterns, while decomposition methods generate limited variety from extracted dataset features like trends [6].\nSimpler transformations like jittering, scaling, magnitude, and time warping have been shown to help in specific tasks and domains [7, 28]. They are simple to implement and increase data variety. While they may not capture complex patterns, they provide some control over the transformations since they are parametric transformations."}, {"title": "4 RHIOTS", "content": "We introduce RHiOTS, a framework designed to assess the robustness of HTS forecasting algorithms. Traditional evaluations, which primarily focus on predictive accuracy using a limited set of benchmark problems, fail to adequately assess the resilience of an algorithm to minor variations in individual time series or their interrelations. RHiOTS addresses these issues by offering a nuanced analysis of the stability of forecasting algorithms against such changes, providing deeper insights into their robustness and reliability."}, {"title": "4.1 Framework", "content": "RHIOTS serves two primary objectives. The first goal is to provide a comprehensive understanding of the behavior of models. We do this by systematically applying various transformations to the data and then evaluating the performance of models. This process facilitates a detailed assessment of the robustness of each model, controlled by transformation and intensity. It enables practitioners to identify the most effective model for the unique aspects of their problem and potential variations in data properties.\nFor the second goal, RHIOTS aims to support the reliable selection of an appropriate algorithm for a given forecasting task. By analyzing how different algorithms perform across a range of transformed datasets, the framework offers insights into which algorithms are most adaptable and effective under varying conditions. This allows for a more effective and informed comparison of algorithms and improves generalization.\nRHIOTS applies transformations to each individual time series, z\u1d62' = T^(\u03c4)(z\u1d62, \u03b7^(\u03c4)). The transformations are applied to the time series in the leaf nodes of the hierarchy only. The aggregated levels of the hierarchy are recomputed after the transformation, i.e., the total sum of the observations of a specific group (or for the top-level series) is computed based on the transformed individual series, z'_(G\u2097) = \u03a3\u1d62\u2091(z'_(G\u2097)\u2081) .\nThe next step in RHiOTS is to assess the robustness of HTS forecasting models by connecting the variations introduced by time series transformations with the variation in forecasting performance. To quantify the variation in forecasting performance, we compute the forecasting error of the model on the original dataset and the various transformed versions. Given that each transformation represents a type of variation (e.g., jittering represents noise in the measurement of the values), the analysis of the variation of forecasting performance for different versions of a transformation gives a systematic perspective on the robustness of a method to that type of variation (e.g., the robustness of the method to noise)."}, {"title": "4.2 Time Series Transformations", "content": "We apply random-based transformations to the original time series, represented by z'_(i,t) = T (z_(i,0,t), \u03b7), where T denotes a transformation function and \u03b7 indicates its governing parameters. These transformations can affect individual time series components and relationships between series in a dataset. However, they should be smooth and continuous to preserve a meaningful relationship between the original and transformed series. This ensures that similar parameters produce closely related transformed series.\nJittering is a magnitude domain transformation that can be defined as the addition of a random noise component to the values of a time series z'_(i,0,t) = z_(i,t) + \u03b5^(v)_(i,t) where \u03b5^(v)_(i,t) ~ N(0, \u03c3^(v)_(i)\u00b2), the standard deviation \u03c3^(v)_(i) of the added noise is a transformation parameter. Applying jittering to the time series using the addition of i.i.d. Gaussian noise is widely used in the literature to simulate realistic sources of measurement error or irregularity in time series data [17]. For example, consider a retail store where sales data suddenly becomes more erratic due to unexpected external factors such as local construction affecting customer traffic.\nAnother transformation used is scaling, which involves modifying the amplitude of the series by a random scalar value z'_(i,t) = \u03b1z_(i,t) where \u03b1 ~ N(0, \u03c3^(v)_(i)\u00b2). Once again, \u03c3^(v)_(i) defines the standard deviation of the multiplicative effect for each parameter set of the transformation, dataset, and series. Scaling the time series data using a multiplicative factor simulates realistic changes in the magnitude of the time series. For example, consider a retail store experiencing increased variability in sales due to various promotional campaigns executed by the store itself and its competitors\nWe also applied magnitude warping [17]. This method causes a smooth, continuous, nonlinear transformation of time series data. It can be written as z'_(v,t) = z_(i,t)S_(i,t)^(v) where u\u00b2 ~ N(1, \u03c3^(v)_(i)\u00b2). Note that S\u1d62 interpolates a cubic spline with knots u = u\u2081, ..., u\u2096. Each knot u\u2096 comes from a distribution N(1, \u03c3^(v)_(i)\u00b2), with the number of knots k and the standard deviation \u03c3^(v)_(i) as parameters. The cubic spline is fitted to the original data points, and the transformed data is obtained by scaling the original magnitude using the evaluated cubic spline function values. The proposed transformation method modulates the magnitude of the time series, maintaining its overall structure and smoothness. For example, the summer season sales time series of a store near a beach area during unusually high temperatures could experience magnitude warping.\nFinally, the last transformation considered was time warping. Time warping is a process that stretches or compresses the time axis of a time series. Similarly to magnitude warping, we define time warping using a cubic spline to interpolate the values of the time series at a set of evenly spaced time points. The time points can be chosen such that they are spaced more closely together in regions where the time series is stretched and more widely spaced in regions where it is compressed. This will effectively stretch or compress the time axis of the time series while preserving the shape of the time series itself. Time warping is defined as z'_(i,t) = z_(i,t)S^(v)_(u(t))\nwhere u^(v) ~ N(1, \u03c3^(v)_(i)\u00b2). Now, S^(v)_(u(t)) is applied on the time steps. Time warping can potentially impact the seasonality of a time series by stretching or compressing the time axis of the series. This can cause the periodic patterns in the series, such as seasonal cycles or trends, to become more or less prominent, depending on how the time axis is altered. For example, changes in weather cycles could significantly impact the seasonality of specific stores and products."}, {"title": "5 EXPERIMENTS", "content": "The primary objective of our experimental setup is to illustrate how RHIOTS can be used to analyze the robustness of both models and algorithms within the context of Hierarchical Time Series (HTS) forecasting.\nThe first step we are interested in is how different transformations affect the distance between time series in the dataset (Q1). HTS algorithms rely on these dependencies to improve their univariate estimates.\n(1) Models: In selecting models for a specific problem, standard evaluation methods test those models on the available data. The assumption is that existing data is representative of new, unseen data. RHiOTS can be used to test the robustness of those models to variations in the data (e.g., noise). We investigate the effects of different types of perturbations on prediction error (Q2) and how the prediction error of HTS forecasting models changes with manipulation of dependencies across time and between series (Q3). Then, we use RHIOTS to systematically compare the impact of the data transformations on ranking the different algorithms (Q4). This kind of analysis could support the data scientist in choosing the best model not only in terms of standard evaluation methods (e.g., average forecasting performance) but also in terms of their robustness (e.g., robustness of forecasting performance to noise in the data).\n(2) Algorithms: In developing new algorithms, typical benchmarking methods test those algorithms on public datasets available for research. The results of the new algorithm are compared to the results obtained by simple baselines and state-of-the-art algorithms (e.g., the average forecasting accuracy). Thus, we start by comparing the performance of the algorithms using the benchmark method of assessing predictive performance (Q5). Then, we use RHIOTS to assess the relevance of dependencies between time series for algorithm performance (Q6) and to identify the most robust algorithm suitable for a given application domain (Q7). This evaluation process enables researchers to make informed decisions when developing new HTS algorithms and dealing with diverse datasets and application requirements."}, {"title": "5.1 Datasets", "content": "The empirical evaluation uses three public datasets: the Tourism [4] dataset from the Australian Bureau of Statistics, the M5 [24] dataset based on Walmart sales, and the Police [27] dataset from Houston police criminal reports. These datasets encompass various time granularities, frequencies, lengths, and hierarchical structures, illustrating the usefulness of RHiOTS in evaluating the robustness of time series forecasting models in different scenarios.\nTo efficiently conduct the experiments across all datasets and models, we downsampled the M5 dataset by reducing its frequency from daily to weekly. Additionally, for the M5 and Houston datasets, we selected a subset of 500 time series with high count levels. Preliminary experiments indicate that this selection has no significant impact on evaluating the different algorithms using RHiOTS. In the interest of space, we do not discuss them here."}, {"title": "5.2 Transformations and Algorithms", "content": "We utilized four different transformations described in Section 4.2. These transformations were applied to each dataset, and the parameters of each transformation were defined to increase linearly with a slope of 1.\nThe robustness of the following methods was analyzed:\n\u2022 ETS + BU: the ETS method was applied to the bottom time series, and then the naive Bottom-Up (BU) [14] strategy was followed to aggregate the forecasts to the upper hierarchical levels.\n\u2022 ETS + MinT: The ETS method was used as the base forecaster, but this time for all the time series (including the upper levels). To ensure the coherence of the forecasts, we used the Minimum Trace (MinT) reconciliation method proposed by [22].\n\u2022 DeepAR + BU: DeepAR produces probabilistic forecasts based on training an auto-regressive recurrent network model on related time series [9]. The hierarchy of the dataset is handled by representing it as multiple static categorical features to the model. We then use a naive BU reconciliation strategy.\n\u2022 TFT + BU: Temporal Fusion Transformer (TFT) combines recurrent and transformer architectures for complex time series forecasting. TFT uses recurrent layers for local processing and interpretable self-attention layers for long-term dependencies [23]. We also use the naive BU reconciliation strategy after fitting the bottom series with TFT.\n\u2022 GPHF: HTS forecasting model using Gaussian Processes [31]. No reconciliation strategy is needed with this approach as the model already takes into account the hierarchical structure of the data."}, {"title": "5.3 Results and Discussion", "content": "We start by addressing Q1 by evaluating the impact of our proposed transformations (Section 4.2) in the distance distributions between the generated and original datasets. Remember that HTS algorithms rely on the dependencies between time series to improve the univariate estimates. Thus, we are interested in measuring how these relations are disrupted when applying each transformation controlled by its magnitude. Looking at Figure 2, we are systematically generating rich variations of the original datasets. Also, the behavior is consistent across all datasets.\nIf we look closer to Figure 2, for every transformation, the effect is limited and increases with the magnitude of the transformation, as expected. The transformation with the largest effect on the distance is magnitude warping, potentially having a greater impact on the performance of the algorithms that rely on the relations between the series. The jittering transformation reduces the spread of the distribution, i.e., it pushes the number of series that are very similar or dissimilar to each other to be closer to the original mean distance. Finally, as expected, the time warping transformation does not produce a relevant impact in the distance. We are using DTW to measure the distance, which already accounts for time-based warping effects. In this case, we are interested in the fact that although the distance does not change, there are warping effects in the time dimension that could impact performance.\nRegarding Q2, Figure 3 suggests that predictive performance varies significantly by transformation applied. Also, and answering Q3, increasing the magnitude of transformations has not only different effects but, in some cases, opposite ones. Figure 3 lays out a comparative analysis of different HTS forecasting models (columns) in terms of their sensitivity to transformations (rows) in the time series data. We control by different levels of the hierarchy within the Tourism dataset - such as 'bottom', 'purpose', 'region', and so on. Note that as the x-axis increases, the magnitude of the transformation applied also increases. Thus, a flatter line would suggest that a model is less sensitive to that particular transformation, maintaining a consistent performance despite the increasing intensity of data alteration. As anticipated, magnitude warping is the most disruptive transformation, and its impact increases with the magnitude. For all models, we can see that there is a positive slope, i.e., consistently worse results when the parameters of the transformation increase. Interestingly, for jitter, scaling, and time warping, the performance of all models stays flat or actually improves as we increase the magnitude of the transformation (especially for jitter). Comparing the robustness of the different models, we observe that GPHF is the model that shows more consistent behavior, which means less impact in terms of performance.\nRegarding Q4, Figure 4 and the left radar chart on Figure 5 help us compare the robustness of the different models. The classical methods yield better results than the more complex counterparts in most cases. The only exception is when the transformation is too disruptive, such as magnitude warping, where we cannot spot any meaningful difference between the predictive performance of the different models. The radar chart in Figure 4 provides a visualization of the ranking of different forecasting models in handling the most disruptive transformation - magnitude warping across various magnitudes of this transformation. Each axis represents a different set of parameters of the magnitude warping transformation, starting from the original data ('orig') and progressing through increasingly intense transformations ('v0' through 'v5'). The distance from the center indicates the rank of the method performance, with a rank of 1 being the closest to the center (best performance) and higher ranks being further away (worse performance). The extensive crossing of lines as the magnitude increases shows the disruptive effect of the transformation. Thus, we cannot say that there is a model that would be more robust to this transformation when applied to this dataset in particular. We then expanded the visualization to all transformations to have a global perspective on the robustness of the models (see the left radar chart on Figure 5). ETS + MinT method appears to be the most stable model across most transformations (except for magnitude warping, as already discussed). It also seems to suggest that using hierarchical information brings value to the model performance since ETS-BU is consistently worse than ETS + MinT. Most interestingly, classical methods seem to be the most robust when applied to this dataset.\nWhen answering Q5, we start by applying a standard methodology to estimate the forecasting accuracy, which is often used to test algorithms (e.g., to compare a newly proposed algorithm with existing ones). In this analysis, researchers compare the predictive performance of algorithms on a small number of datasets. We reproduce what this analysis would look like, as shown in Table 1. We can see that the results are somewhat consistent for the Tourism and Police datasets. If M5 was not considered, this could lead us to generalize on unreliable information. The main outcome is that we get mixed results, which are hard to generalize. Furthermore, the metrics presented in the table do not assess the robustness of the different algorithms.\nStill, there are some insights that we can extract from this type of standard comparison. First, and contrary to our expectations, the ETS model does not show meaningful differences when using the naive reconciliation strategy or MinT. The global deep learning models performed well on the bottom series, especially TFT, but not on the aggregate-level ones. The GPHF model consistently produces good predictions for aggregated levels, but it is less accurate on the bottom level ones. Once again, can we generalize these results, or are they the result of our experimental setup?\nAfter using RHIOTS across all datasets and averaging the results, we can more confidently answer Q6 and Q7 for all the algorithms. We don't see relevant differences between ETS-BU and ETS-MinT, and thus, using hierarchical information does not seem to produce increased robustness. On the predictive performance of algorithms, we consistently observe simpler algorithms (classical ones) yielding better results across transformations than more complex ones. The radar chart on the right in Figure 5 presents the average ranks of various forecasting algorithms across all datasets and controlled by transformation. It serves as a generalization of the chart on the left of the same figure. The chart shows that deep learning algorithms employing BU strategies, such as DeepAR and TFT, often underperform other approaches. The only exception is when faced with high-intensity magnitude warping. This is expected, as complex algorithms are better equipped to handle such behavior. The underperformance of these algorithms is not simply due to their naive reconciliation strategies, as evidenced by the resilience of the ETS + BU algorithm. GPHF ranks between deep learning algorithms and classical ones. Classical approaches, ETS + BU and ETS + MinT yield the best robustness, making them an appealing choice for use as a baseline when developing any new HTS algorithm."}, {"title": "6 CONCLUSIONS AND FUTURE WORK", "content": "We propose RHiOTS, a novel framework for generating semi-synthetic time series datasets with controlled dependencies. We demonstrate its effectiveness in evaluating the performance of HTS models and algorithms under various conditions. Our empirical study using RHIOTS confirms that model and algorithm performance varies depending on the perturbations applied to the data and provides insights into the expected effects based on the type of perturbation.\nFirst, we show that RHIOTS creates rich variations of the original datasets regarding the correlations between time series. When evaluating models, the predictive performance varies substantially based on the transformation applied. As we increase the magnitude, performance degrades quickly in transformations like magnitude warping, while it improves in cases such as jitter. When evaluating algorithms, we start by applying the conventional benchmark analysis of comparing predictive performance across three datasets. As the results were inconclusive, we extended the approach to use RHIOTS. One takeaway is that we do not see meaningful differences in robustness when applying specific reconciliation methods, such as MinT. The second is that classical algorithms are more robust than more complex deep learning counterparts. Deep learning algorithms only showed more robustness when the transformation was highly disruptive, such as high-intensity magnitude warping. The aggregated findings from our visualizations and analyses suggest that if a single model must be chosen without prior knowledge of potential distortions in a dataset, the ETS model stands out as the most robust option.\nFuture research can focus on developing finer transformation controls, enabling a more targeted analysis of their impact on performance. Meta-learning techniques can help more effectively identify relationships between transformation parameters and model performance. RHIOTS, combined with these research directions, will help build a more comprehensive evaluation framework for hierarchical time series forecasting models."}]}