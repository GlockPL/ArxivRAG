{"title": "PsyDI: Towards a Personalized and Progressively In-depth Chatbot for Psychological Measurements", "authors": ["Xueyan Li", "Xinyan Chen", "Yazhe Niu", "Shuai Hu", "Yu Liu"], "abstract": "In the field of psychology, traditional psychology testing methods are often criticized for their static nature, lack of customization, and diminished engagement, while in-depth counseling-style assessments remain inaccessible to the general public. The challenge of quantifying psychological traits further complicates these assessments. Despite advancements in psychology measurements using large language models (LLMs), most approaches still rely on single-round Q&A interactions. Addressing this gap, we introduce PsyDI, a personalized and progressively in-depth chatbot designed for psychological measurements, exemplified by its application in the Myers-Briggs Type Indicator (MBTI) framework. PsyDI leverages user-related multi-modal information and engages in customized, multi-turn interactions to more accurately discern the user's MBTI type. To overcome the challenge of quantifying absolute values of psychological traits, PsyDI applies a novel training paradigm that implicitly estimates unmeasurable variables by learning the rank of proxy variables, culminating in a robust score model for MBTI assessments. This model enables PsyDI to conduct comprehensive and precise MBTI measurements through multi-turn interactions within a unified estimation context based on LLMs. Through various experiments, we validate the efficacy of both the score model and the PsyDI pipeline, demonstrating its potential to serve as a general framework for psychological assessment. Additionally, the online version, PsyDI Online, has revealed a significant user engagement with over 2,000 visits, collecting extensive data tagged with MBTI types and multi-modal information, which facilitates further insightful analysis.", "sections": [{"title": "Introduction", "content": "Recent progress in general-purpose foundation models, such as large language models (LLMs)(Achiam et al., 2023b; Anthropic, 2023; Touvron et al., 2023) and vision language models (VLMs)(Li et al., 2023; Team et al., 2023; Liu et al., 2024) has shown that artificial intelligence (AI) systems have capabilities to chat, reason, and incorporate relevant context to realize naturalistic interactions. Their advancements provide an opportunity to expand the forms of psychological assessments with AI and make it customized for each user. Traditional techniques often utilize self-report scales and questionnaires for surveys and analysis (Cohen et al., 1996). While this approach can quickly cover a large population, it suffers from relatively weak data reliability and is unable to conduct targeted tests for specific individuals. On the other hand, professional psychological interviews and counseling are not easily accessible to the general public. Correspondingly, due to building upon billions of human natural language knowledge, an LLM-powered system can provide user-specific interaction experience in the psychological dialogue. These agents have the potential to uncover the uncertainties on the surface and dig out the underlying information of different users, then summarizing and analyzing these information based on some professional psychological knowledge injected in prompts or fine-tuning data.\nSeveral recent works attempt to combine neural network techniques with clinical knowledge to improve the performance and generalization on mental disease counseling (Toleubay et al., 2023) and emotional support (Buechel et al., 2018; Cheng et al., 2023) tasks. To enhance the richness of knowledge and the logical reasoning, various methods (Zhang et al., 2024a) have introduced LLMs, fine-tuning them with a variety of specialized psychological data to make them more suitable for these scenarios. Other approaches (Tu et al., 2024a) have adopted role-playing dialogues, guiding LLMs to provide a more immersive psychological dialogue experience. And some of these methods offer an online chat entry for trial, significantly lowering the barrier to entry and promoting wider adoption among the population.\nDespite these advancements, the existing approaches remain confined to the realm of single-turn textual question-answering (Nori et al., 2023). These methods struggle to maintain style and logic consistency across multi-turn dialogues and fail to offer accurate and stable quantitation measurements over multiple instances for the same user (as shown in Table 1). In this paper, we undertake a rigorous investigation to devise a comprehensive framework that not only offers an engaging interactive experience but also delivers reliable quantifiable analysis outcomes (Figure 1). Our exploration starts from a formalization of psychological assessments within the context of multi-turn decision-making processes (Section 2.2). Specifically, psychological assessments with LLMs are conceived as a multi-turn interaction process designed to evaluate specific discrete types or continuous scores of the test taker. These assessments should be presented in a manner that is both engaging and succinct, ensuring its acceptability to the test-taker. We encapsulate these considerations into the following principles: \u2460 A superior psychological assessment should actively and ethically gather and construct the user portrait from multi-modal question-answering formats. \u2461 It should represent a complex skill whose optimal result is highly dependent on the user context, including cultural, linguistic, and individual factors to minimize the biased impact.. 3 It should exhibit comparable or better quantifiable results than existing scales and questionnaires, with rigorous validation and standardization processes.\nBased on the above discussed principle, we introduce a comprehensive psychological assessment framework named PsyDI, and validate its effectiveness on one of the most popular personality assessment: Myers-Briggs Type Indicator (MBTI) (Myers et al., 1962). This framework are primarily composed of two innovative designs: a pipeline and a score model. Firstly, recognizing the scarcity of complete multi-turn MBTI assessment dialogue data, we deem it impractical to design an end-to-end dialogue system. Consequently, drawing inspiration from widely-used psychological scales, we adopt a multi-stage dialogue paradigm and design an MBTI profile to select topics for each stage and quantitatively monitor the user's MBTI predilection. This design leverages the powerful in-context learning abilities of LLMs to construct an engaging multi-turn chat within each stage, while updating the MBTI profile at the end of each stage, effectively decoupling these two components. Furthermore, to ensure accurate adaptive update of MBTI profile, we propose a series of automated data generation scheme and neural network architectures to train a score model, akin to the concept of preference-based reinforcement learning (Wirth et al., 2017). All these components are integrated into a multi-modal and interactive chatbot.\nTo demonstrate the effectiveness of our proposed framework, we initially conduct several quantitative experiments and ablations about several key designs, including comparisons between various LLMs and our score models across diverse datasets. Subsequently, we release an online accessible version of PsyDI and collect data from over 3,000 participants. Based on de-identified data, we perform a series of analysis and visualizations, examining both specific questions and the whole test process. These examinations validate the framework's proficiency in dissecting the underlying characteristics of users. Concurrently, it provides qualitative evidence of PsyDI's capacity for continuous refinement in the assessment of the user's MBTI. Additionally, we extend PsyDI to the emotion analysis scenario to validate its transferability (Appendix E.4).\nThe main contributions of this paper can be summarized as follows:\n\u2022 We introduce PsyDI, an innovative AI agent framework designed to transcend the limitations of static psychological assessments (e.g. MBTI) through a multi-modal, user-oriented dynamic interaction.\n\u2022 To enhance the validity and explanability of PsyDI, we propose a simple yet effective data generation and score model training schemes, with a novel training method that implicitly estimates unmeasurable variables by learning the ranking of proxy variables.\n\u2022 Experimental findings derived from quantitative metrics and qualitative real-world user test, encompassing 3,000 participants, substantiate the potential of PsyDI as a general psychological interaction agent."}, {"title": "Problem Formulation", "content": "To better model the MBTI evaluation, we conceptualize the interaction between LLM agents and the test taker (user) as a Markov Decision Process (MDP) (Sutton & Barto, 2018). This formulation allows us to systematically optimize the sequence of inquiries posed to the user, with the aim of enhancing the accuracy, efficiency and engagement of MBTI evaluations. Formally, the MDP is articulated as $\\mathcal{M} = \\{S, A, P, R, \\gamma\\}$.\nThe states $s$ in the observable state space $S$ are defined as $s = \\{p_1,...,p_n\\}$, where $p_i$ is the i-th textual statement of the user (e.g. I like to talk to different people and share my stories). Additionally, the state space includes a special terminated state $s_{exit}$ representing the user's decision to exit the evaluation process.\nThroughout the process, the agent needs to determine to either persistently delve deeper into user's cognitive preferences through multi-turn iterative question-answer (QA), or to terminate the process and render a forecasted MBTI type of the user. While gathering more question-answers may narrow down the user's authentic MBTI, it is imperative to acknowledge that an extended engagement may engender user dissatisfac-tion. Therefore, the action space $A$ is defined as the union of these two kinds of action set $A = A_q \\cup A_t$.\nHere each $a$ in $A_q$ represents a textual question $a \\in \\{W_1,..., W_L\\}$ and $A_t$ represents the set of termination actions, i.e., all possible MBTI types, where $L$ is the length of the question. Once the user selects an answer, the question together with the answer can be regarded as a more detailed user statement $p'$. Consequently, the state transition for the state $s$ is $s' = s \\oplus p'$, where $\\oplus$ signifies the concatenation of the current state with the new statement $p'$. In the event that the user opts to exit, the state transmutes to $s_{exit}$.\nThe reward function, which maps $S \\times A$ to $R$, is designed to measure the similarity between the predicted MBTI and the user's authentic MBTI. Concurrently, it imposes a penalty for the duration of the interaction and the incidence of user withdrawal. Formally, the reward function is defined as:\n$$r(s_t, a_t) =\\begin{cases}\n    -c, & a \\in A_t, s' = s_{exit} \\\\\n    -|a, m^*|\\cdot t, & a \\in A_q\n\\end{cases}$$\nwhere $|a_t, m^*|$ denotes the measure of similarity between the predicted and the true MBTI type $m^*$, $\\lambda$ is the penalty factor for the cumulative interaction steps $t$ while $c$ is the penalty positive constant for the exit.\nIn summary, the MDP employed in this context is similar to challenges tackled in goal-conditioned reinforce-ment learning (GCRL) (Liu et al., 2022). The purpose of this decision-making process is to achieve a specific objective (goal), i.e., to accurately predict user's MBTI type within the minimal number of interaction steps."}, {"title": "2.1 The Background of MBTI", "content": "The Myers-Briggs Type Indicator (MBTI) (Coe, 1992) is a psychological metric designed to classify individuals based on their personality traits, resulting in a four-letter typology. Each letter in the MBTI represents one of two possible traits in four dichotomies: Introversion (I) vs. Extraversion (E), Sensing (S) vs. Intuition (N), Thinking (T) vs. Feeling (F), and Judging (J) vs. Perceiving (P). Consequently, MBTI theory categorizes individuals into one of sixteen possible personality types, such as INFP or ESTJ.\nThe unique combination of these four dimensions results in sixteen distinct personality types, each with its own cognitive patterns and behavioral tendencies. This heterogeneity has contributed to the growing popularity of the MBTI in recent years, with over 1.207 billion test administrations recorded by 16Personalities. However, it is imperative to acknowledge that the MBTI is based on Carl Jung's theory of psychological types (Jung, 1923). Jung's theory postulated a quaternary of cognitive functions-thinking, feeling, sensation, and intuition each with an orientation of either extroversion or introversion, resulting in eight dominant functions, Te (Extroverted Thinking), Ti (Introverted Thinking), Fe (Extroverted Feeling), Fi (Introverted Feeling), Se (Extroverted Sensing), Si (Introverted Sensing), Ne (Extroverted Intuition), and Ni (Introverted Intuition). The constitution of an individual's personality is delineated by the hierarchical preference for these dominant functions. According to the theory of Jung, it is improbable for a person to exhibit high predilections for both extraversion and introversion within the same cognitive function, as human cognitive resources are finite. This principle leads to the emergence of sixteen common cognitive function sequences, aligning congruently with the sixteen MBTI types. For example, the cognitive function sequence of INFP is: Fi, Ne, Si, Te, Fe, Ni, Se, Ti. Consequently, the adjudication of MBTI typologies inherently entails the scrutiny of one's cognitive processes.\nMoreover, the evaluation of MBTI is inherently multifaceted and complex due to its dependence on self-reports. These self-reports are inherently subjective and are prone to distortion by various extrinsic factors (Green et al., 2011), including mood states and the pervasive influence of social desirability. Thus, accurately correlating these self-reports with the underlying cognitive processes presents a formidable challenge. To improve this correlation, it is essential to carefully analyze the specific statements within the self-reports. This can be achieved through a detailed questioning framework that eliminates ambiguity and elicits more precise responses. Such an approach is instrumental in mitigating the effects of external influences and in clarifying cognitive preferences with greater precision and depth."}, {"title": "PsyDI Pipeline", "content": "In this section, we present the motivation and detailed design aspects of the PsyDI pipeline. Recognizing the intricate nature of human cognitive functions, the task of collecting quantifiable MBTI labels for machine learning applications presents a significant challenge. Nevertheless, we can draw upon the methodologies employed in classical psychological scales. These scales typically consist of questions meticulously crafted by experts. And they often include specific quantitative metrics to assess the test-taker's during testing. In line with this approach, we have devised an MBTI profile that dynamically summarizes and records the MBTI predilection derived from the test-taker's statements. This profile is continuously updated with new personal descriptions or feedback obtained from the test-taker, thereby refining the MBTI profile in real-time.\nLeveraging this design, the remainder of the PsyDI is structured into two distinct phases: statement selection and multi-turn chat. The former is dedicated to identifying statements with the greatest potential for in-depth questioning, as elaborated in Section 3.2. Then, the multi-turn chat phase is designed to engage users in a series of iterative questions based on the selected statement, fostering an environment that encourages them to provide statements that accurately reflect their cognitive processes while also mitigating the risk of user attrition (Section 3.3). Finally, PsyDI will ascertain the user's MBTI upon achieving a confident estimation."}, {"title": "MBTI Profile", "content": "Similar to the quantitative metrics used in psychological scales, we initially establish a kind of estimation of the user's MBTI type, derived by their statements. In practice, we adopt the psychology profile commonly used in psychological assessments Watson & Clark (1994). This component serves to document the user's MBTI predilections and subsequently directs other elements of PsyDI in determining the most efficacious strategy for conducting multi-turn dialogues. Specifically, we design a MBTI Profile that documents the individual scores for each trait under assessment. It can translate the user's statement into quantifiable indicators that accurately reflect their MBTI predilections, while ensuring uniformity and cross-user comparability. Although the MBTI is composed of four distinct dimensions, it is recognized that these dimensions are not entirely independent. The impact of a single statement on each MBTI type is complex, influenced by both the dimensions and the underlying cognitive functions. Therefore, we assign a predilection to each type in MBTI profile, thereby encapsulating the possibility that the current user aligns with that particular MBTI type. As the profile is iteratively updated with fresh statements, the estimated predilections of all the MBTI types are dynamically recalibrated to reflect the evolving understanding of the user.\nIn the interactive process of PsyDI, the system can only observe the statements provided. Therefore, the likelihood that a user is classified under each MBTI type is determined by how well each statement indicates that the user belongs to a specific MBTI type, which we define as Representativeness. To achieve this, we train a Score Model $F_{mbti}(\\cdot)$ to estimate the representativeness of a statement under each mbti for each dimension, the result of which should be a 4-dimension vector. Then the value of the statement under a MBTI type is defined as the proportion of its representativeness within the distribution of all the statements for the MBTI type:\n$$V(p) = \\frac{|\\{p' \\in P|\\sum_{p \\in s} F(p') \\le \\sum_{p \\in s} F(p)\\}|}{|P|}$$\nwhere $P$ is the comprehensive set of all statements made by users who have been classified with the corresponding MBTI type. $F(p)$ is the representativeness of statement p while $V(p)$ represents the value. This value can be calculated under each MBTI separately. The entire training process of Score Model will be introduced in Section 4.\nInitialization of MBTI Profile: In the initialization phase, we compute the average representativeness of all known statements attributed to the user. This operation is performed for each MBTI type, allowing us to construct the user's initial profile:\n$$V_{init}(s) = \\frac{|\\{p' \\in P|\\sum F(p') \\le \\sum F(s)\\}|}{|P|}$$\nUpdate of MBTI Profile: In the update phase, the incorporation of new statements serves as a means to refine the accuracy of the MBTI profile. Therefore, after obtaining the MBTI representativeness for a new statement, we proceed to recalibrate the MBTI profile according to both the new statement's representativeness and the established MBTI profile:\n$$V_{update}(s \\cup \\{p\\}) = V(s) + f(V(s)) \\cdot V(p)$$\nwhere $p$ is the latest statement, while $f(\\cdot)$ is the non-linear mapping function designed to judiciously regulate the growth weights in accordance based on the current profile."}, {"title": "Statement Selection", "content": "Following the update of the MBTI Profile, another key challenge emerges in eliciting more representative statement from users through subsequent questioning. Given the preliminary acquisition of user portrait statements, the next process can be divided into two distinct stages: statement selection and multi-turn dialogue with the user. The goal of the former lies in discerning which statements are most indicative of representative responses, thereby delineating the areas requiring in-depth exploration and further analysis. Conversely, the objective of multi-turn dialogue is to engage users, encouraging them to provide more details in the extended question-answers and maintain their interest throughout the assessment.\nTo determine the most indicative statements, we should exclude those with minimal informational value and those that explicitly describe a specific MBTI type, as these do not warrant further inquiry. Instead, we should focus on statements that are ripe for exploration, particularly those that exhibit ambiguity across multiple MBTI dimensions. For instance, considering a user whose statements could plausibly align with either the INFP or ENFJ types. This ambiguity suggests difficulty in distinguishing between the Introversion/Extraversion (I/E) and Perceiving/Judging (P/J) dimensions. Thus, the subsequent questioning should be designed to delve into the motivations underlying these dimensions. In this context, we design a strategy to select statements that are ambiguous yet highly representative of both the I/E and P/J dimensions, thereby refining our understanding of the user's MBTI. This process can be formulated as:\n$\\underset{\\substack{p}}{\\text{arg}}  \\underset{\\substack{i}}{\\text{arg min}} \\sum_{i=1}^4 (M_{MBTI_j} \\diamond M_{MBTI_k}) \\cdot (rank_i(F_{MBTI_j}(p)) + rank_i(F_{MBTI_k}(p))$"}, {"title": "Multi-turn Chat", "content": "Since ChatGPT demonstrates proficiency in both MBTI-related knowledge, the multi-turn chat stage is built upon ChatGPT. The key problem PsyDI need to solve in this stage is, how to lead user to reveal underlying motivation while keep user's interesting on our assessment, to maintain completion rate.\nFor the first challenge, which is to lead users to reveal their underlying motivations, we utilize multiple-choice questions where each option corresponds to a specific cognitive preference. By presenting such options, users can select the one that best aligns with their own, thereby avoiding ambiguous expressions and implicitly guiding them to reflect on their cognitive tendencies. For questions requiring confirmation, PsyDI employs forced-choice questions, compelling users to identify their most likely cognitive preferences. Additionally, PsyDI accepts free-form answers, allowing users to provide responses beyond the preset options. The prompt for this stage is list in Appendix C.\nFor the second challenge, which is to keep user's interesting. We have designed a multimodal input system that allows users to input their preferred music and images, which are then converted into text to form a user statement. Additionally, our questioning framework is designed with a three-stage thought chain. First, we analyze the user statement, then we infer the user's underlying thought patterns, and finally, we derive the next question based on these thought patterns. This approach ensures that the entire questioning process revolves around the user's thinking style, providing greater motivation for them to continue answering questions."}, {"title": "Score Model", "content": "To achieve the goal of identifying the primary cognitive function influencing participant behavior, it's vital to pinpoint the statement best differentiates MBTI categories. This statement will be utilized for further qualitative analysis to elucidate MBTI profiles. To address the challenge, we introduce the score model in Figure 3 to estimates MBTI representativenesss for each statement.\nWithin a given state with a set of statements $s = \\{p_1,p_2,...,p_n\\}$, the score model serves the purpose of evaluating the representativeness of a statement under a particular MBTI type $F_{MBTI}(s)."}, {"title": "Ranking Training Paradigm", "content": "However, according to the existing research on MBTI and available datasets, the MBTI representativeness of a self-report statement remains an unmeasurable variable, attributable to the inherent ambiguities in language. For instance, the phrase \"I easily become lost in fantasies\" may align with an XNXP preference if the user emphasizes possibilities, yet shift towards an XNXJ inclination if the user focuses on long-term future considerations. To address this limitation, we propose employing the accuracy of MBTI prediction, that is, the degree to which the Large Language Model's (LLM) predictions for a given statement correlate with the assigned labels. This accuracy serve as a proxy variable, effectively substituting for the unmeasurable statement representativeness."}, {"title": "Loss function", "content": "Therefore, considering any two statements, we can construct a pair sample $\\{p_i, p_j, mbti\\}$, where $p_i$ has greater representativeness of a specific MBTI type than $p_j$. The details of pair-wise dataset constructing process is introduced in Section 4.3. For each statement p, the score model is designed as an LLM with four heads, seperately predicting its score on the four dimension of MBTI (E/I, N/S, F/T, J/P). For example, the higher the score of the first head is, the statement is more likely to be like E, while a lower score represents I. Therefore, the final score of a statement is calculated as $-mbti^- \\cdot \\sum F(p_i)$, where mbti is a four-dimension vector of 1/-1, representing for the direction of true MBTI on four dimension.\nThen, we construct a loss function as the difference under mbti between the predicted scores of the two posts $y_i$ and $y_j$ as shown in the right side in Fig. 3. This ensures that the score for the more accurate statement is higher. To enhance the clarity of score boundaries for dynamics with varying representativeness, we introduce a margin. If the model's score for $p_i$ exceeds that for $p_j$ by an amount less than the margin, a penalty is applied. This margin enhances the model's robustness and generalization, mitigating the risk of overfitting. The resulting loss function is as follows:\n$$\\mathcal{L}(p_i, p_j, mbti) = max(-mbti \\cdot (\\sum F(p_i) - \\sum F(p_j)) + margin)$$\nWith Eq. 6, we can train a score model to rank the representativeness of statements under specific MBTI."}, {"title": "Pair-wise Dataset", "content": "For a psychology dataset composed of statements with self-reported label, it's unreasonable to directly use label as a ground truth, since the self-reported label could be wrong. Therefore, we apply both the accuracy of MBTI prediction and the label to construct the pair-wise dataset.\nSpecifically, as shown in the left side in Fig. 3, for any two different statements with the same mbti label in the labeled dataset, we apply ChatGPT to predict the top-4 likely mbti and their probabilities. Then we can design an statement comparison metric to decide which statement is more likely to be the mbti, implicitly showing its representativeness of the mbti. For example, for two statements under INFP, the post that ChatGPT predicted to be 70% likely to be INFP has more representativeness comparing with the statement that ChatGPT predicted to be 50% likely to be INFP. Similarly, for one statement, we can mask some part of the statement, so that the masked statement is less likely to be the corresponding mbti under ChatGPT's prediction. Finally, we can use the above two methods to construct pair-wise dataset.\nHowever, due to the composition method of post mask, the score model will tend to output a higher score of a longer sentence since this tendency is aligned with the dataset, where the masked statement always has less representative than original statement. To encourage the score model to learn the true representativeness of a sentence, we apply two data augmentation methods:\nMix Datasets. In order to make the score model focus more on the representativeness of the statement than on the length of the sentence, we constructed a series of statement pairs with the same length but different representativeness. specifically, for each post, we intercepted the original statement's 70%, and the remaining 30% is populated by random statements from other mbti to form the mix dataset.\nMeaningless Datasets. To avoid the score model's tendency to award higher scores to longer statements, we construct a dataset that is longer while representativeness remains constant, penalizing the score model's behavior of giving higher scores to longer statements. Specifically, for each statement, we construct a sample such as (p, ppp, mbti) to build a meaningless dataset by constantly repeating the statement itself."}, {"title": "Experiments", "content": "In this section, we will validate both the score model and the pipeline in PsyDI. For the score model validation, we begin in Section 5.2 by assessing the dynamic ranking accuracy of the score model compared to existing open-source and closed-source LLMs. Subsequently, we delve into the detailed evaluation of the score model's scoring trend with specific statements. These two parts demonstrate the effectiveness of the score model from both a holistic perspective and in terms of detailed scoring metrics. In Section 5.3, we conduct an ablation study to explore the necessity of the score model's structure and training configurations.\nFor the overall pipeline validation, we take a two-pronged approach. First, we examine the score variations of individual MBTI bots throughout the pipeline process to illustrate the pipeline's effectiveness in MBTI assessment, as detailed in Section 5.4. Second, we utilize user statistics collected from PsyDI Online to observe observe whether the PsyDI pipeline shows consistent patterns in MBTI classification across different metrics, presented in Section 5.5."}, {"title": "Experimental Setups", "content": "Datasets. We constructed the following MBTI statement datasets with labels in both English and Chinese:\n\u2022 Reddit. The Myers Briggs Personality Tags on Reddit Data (Storey, 2018) is a public dataset consisting of user statements and their self-reported MBTI types. To balance the distribution of MBTI types, we extracted 400 statements for each MBTI type, ensuring that each statement was longer than 100 words. The Reddit dataset is augmented with the data augmentation methods introduced in section 4.3, forming Reddit-mix and Reddit-mearningless.\n\u2022 16Personalities. We obtained all the questions from 16 Personalities, an authoritative MBTI testing site. Subsequently, we used one ChatGPT to simulate specific MBTI types and engaged another ChatGPT in multi-turn QA sessions with the former one. If the predicting ChatGPT correctly predicted the MBTI type of simulating ChatGPT, the QA record was collected along with the MBTI labels. We collect the dataset in both English and Chinese to form 16Personalities-en and 16Personalities-ch.\n\u2022 Diamente. The Diamente Chinese chit-chat dataset comprises high-quality chit-chat conversations collected with the assistance of a pretrained dialogue model that aligns well with human values. Using these chit-chats as a starting point, we asked ChatGPT to generate multi-turn QA sessions. We randomly selected answers and recorded the entire process, labeling the statements based on ChatGPT's MBT\u0406 predictions.\nBaselines. We compared the proposed score model in PsyDI with 7 existing closed-source LLMs and 4 open-source LLMs. The closed-source LLMs include GPT-3.5 Turbo (OpenAI, 2023) and GPT-4 (Achiam et al., 2023a), the acclaimed leader in LLMs, as well as DeepSeek (DeepSeek-AI, 2024), a Mixture-of-Experts (MOE) (Shazeer et al., 2017) Language Model for both English and Chinese. For open-source LLMs, we use Llama2 (Touvron et al., 2023), a commonly used English LLM, and Chatglm3 (Du et al., 2022), an open bilingual dialogue language model.\nTraining Setting We train PsyDI using llama-2-7b-hf as a base model and LoRA (Hu et al., 2021) finetune with LORA (Hu et al., 2021). Since llama-2-7b-hf itself is an English large language model, we first inject English MBTI datasets from Reddit to enhance its MBTI representativeness judgment ability in English text, forming PsyDI-en. Then, we apply cross-lingual transfer learning (Schuster et al., 2018), finetuning PsyDI-en with both Reddit and Chinese datasets Diamente, so that PsyDI-ch retains its understanding of MBTI in English text while also mastering Chinese text. The lora config is setting as r = 32, alpha = 32, dropout = 0.05, while the margin in loss function is set as 0.3.\nEvaluating Method. To evaluate the score model in PsyDI, for each pair-wise data sample (pi, pj, mbti), we asked all baseline LLMs to determine which statement was more likely from a user with the specified MBTI type mbti. The prompt was designed as follows:\nI will give you two statement, Please choose the one you think is more Just Answer (A) or (B).\nAll LLMs had their temperature set to 0.3 to ensure more deterministic outputs. For PsyDI, we calculate the score $-mbti^- \\cdot \\sum F(p)$ for each statement. Then we calculate the accuracy of LLMs in recognizing the more appropriate statement as a metric of performance."}, {"title": "Score Model Evaluation", "content": "Table 1 shows the performance of PsyDI-en and PsyDI-ch on the benchmarks, compared with all the open-source and closed-course LLMs. As shown in the table, both PsyDI score models surpass all close-source models and open-source models on all the English benchmarks.\nSpecifically, on the Reddit and Reddit-mix datasets, the PsyDI models outperformed other models by at least 9.5%. On the Reddit-repeat dataset, many LLMs that had not undergone fine-tuning exhibited the issue of assuming that longer sentences contain more information, resulting in nearly half of the models achieving accuracies below 50%. In contrast, PsyDI was able to accurately identify completely redundant semantics 100% of the time and assign lower scores to repetitive long sentences. For the 16Personalities-EN dataset, due to its typical expressions, open-source models such as GPT-4, Qwen, and Baichuan achieved approximately 82% accuracy. However, PsyDI-en and PsyDI-zh achieved accuracies of 83.4% and 85.7%, respectively, slightly surpassing the best open-source models.\nOn the Chinese Benchmarks, Although PsyDI-en was not trained on Chinese datasets, its performance is still better than most models. After fine-tuning on Chinese datasets, PsyDI-zh has achieved results that surpass those of other LLM 7.5% on Diamonte. On the typical dataset 16Personalities-ZH, PsyDI-ZH is comparable with yi-medium. Moreover, it can be observed that GPT-4 performs worse than GPT-3.5 on some benchmarks. This is because GPT-4 chooses to say \"I don't know\" for questions it is uncertain about, rather than providing an output.\nTo observe the scoring trends of the score model across four dimensions, we selected an original statement and gradually added expressions that are inclined towards the INFP four dimensions to the statement, observing the changes in the score model's scoring. The results can be seen in Figure 4, where we present the score model's scoring with different statements added, and highlight the target dimension. Note that the scores here have been multiplied by the label and normalized, so the closer the scores are to 1, the more likely they are to correspond to the relevant dimension. From the results, we can observe that by adding expressions of certain MBTI traits, the score model's scoring does indeed gradually increase towards the corresponding dimension. At the same time, as more expressions of certain traits are added, the upward trend of the score model's scoring in this dimension will also gradually slow down. This is because the score model is trained to evaluate the representativeness of sentences, so a sentence that is already very \"INFP\" will not have a"}, {"title": "Ablation Study", "content": "In this section, we want to discuss all the effect of all the details in PsyDI. We discuss five five important design in PsyDI base on Reddit dataset:"}, {"title": "Pipeline Evaluation", "content": "To verify the effectiveness of the PsyDI pipeline, we utilized the AI Character's MBTI bot to interact with PsyDI and observe its performance. Specifically, the whole test process of PsyDI involves 4-5 rounds of multi-turn QA, during which the MBTI profile is updated after each round. We monitored the changes in the MBTI profile following each QA session to assess the trend and accuracy of the MBTI profile updates. The result is shown in Figure 6, where each row represents for an MBTI bot, while each column represents for the MBTI score in MBTI profile.\nAs shown in the result, in the initial stage, when only the user's statements are available, there is no significant correlation between PsyDI's predicted MBTI and the actual MBTI. At this point, most of the MBTI scores are relatively low. By the third round of QA (stage 3), a clear correlation begins to emerge between PsyDI's predicted MBTI and the bot's actual MBTI. At this stage, the scores for the true MBTI and several closely related MBTIs are significantly higher than those for other MBTIs. By the final stage (stage 5), after 4-5 rounds of multi-turn dialogue, the scores for the true MBTI and similar MBTIs are much higher than for other MBTIs, indicating that PsyDI can effectively differentiate between different MBTI types. Additionally, since the MBTI bot's expressions do not perfectly align with its actual MBTI, PsyDI also assigns relatively high scores to some similar MBTIs. From these scores, we"}]}