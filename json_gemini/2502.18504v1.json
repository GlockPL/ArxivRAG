{"title": "TURBOFUZZLLM: Turbocharging Mutation-based Fuzzing for Effectively Jailbreaking Large Language Models in Practice", "authors": ["Aman Goel", "Xian Carrie Wu", "Zhe Wang", "Dmitriy Bespalov", "Yanjun Qi"], "abstract": "Jailbreaking large-language models (LLMs) involves testing their robustness against adversarial prompts and evaluating their ability to withstand prompt attacks that could elicit unauthorized or malicious responses. In this paper, we present TURBOFUZZLLM, a mutation-based fuzzing technique for efficiently finding a collection of effective jailbreaking templates that, when combined with harmful questions, can lead a target LLM to produce harmful responses through black-box access via user prompts. We describe the limitations of directly applying existing template-based attacking techniques in practice, and present functional and efficiency-focused upgrades we added to mutation-based fuzzing to generate effective jailbreaking templates automatically. TURBOFUZZLLM achieves \u2265 95% attack success rates (ASR) on public datasets for leading LLMs (including GPT-4o & GPT-4 Turbo), shows impressive generalizability to unseen harmful questions, and helps in improving model defenses to prompt attacks.", "sections": [{"title": "1 Introduction", "content": "With the rapid advances in applications powered by large-language models (LLMs), integrating re- sponsible AI practices into the AI development lifecycle is becoming increasingly critical. Red teaming LLMs using automatic jailbreaking meth- ods has emerged recently, that adaptively generate adversarial prompts to attack a target LLM effec- tively. These jailbreaking methods aim to bypass the target LLM's safeguards and trick the model into generating harmful responses.\nExisting jailbreaking methods can be broadly cat- egorized into a) white-box methods like (Zou et al., 2023; Wang and Qi, 2024; Liao and Sun, 2024; Paulus et al., 2024; Andriushchenko et al., 2024; Zhou et al., 2024), etc., which require full or partial knowledge about the target model, and b) black- box methods like (Mehrotra et al., 2023; Chao et al., 2023; Takemoto, 2024; Sitawarin et al., 2024; Liu et al., 2023; Yu et al., 2023; Samvelyan et al., 2024; Zeng et al., 2024; Gong et al., 2024; Yao et al., 2024), etc., which only need API access to the tar- get model. In particular, GPTFuzzer (Yu et al., 2023) proposed using mutation-based fuzzing to explore the space of possible jailbreaking templates. The generated templates (also referred as mutants) can be combined with any harmful question to cre- ate attack prompts, which are then employed to jailbreak the target model. Figure 2 in the appendix provides a motivating example of this approach.\nOur objective is to produce sets of high quality (attack prompt, harmful response) pairs at scale that can be utilized to identify vulnerabilities to prompt attacks in a target model and help in de- veloping defensive/mitigation techniques, such as improving in-built defenses in the target model or developing effective external guardrails.\nWe found GPTFuzzer as the most fitting to our needs since it enables creating attack prompts at scale by combining arbitrary harmful questions with jailbreaking templates that are automatically learnt with black-box access to the target model. However, when applying GPTFuzzer (or its exten- sions) in practice, we observed several limitations that resulted in sub-optimal attack success rates and incurred high query costs. First, the mutant search space considered is quite limited and lacked even simple refusal suppression techniques that have shown impressive effectiveness (Wei et al., 2024). Second, the learned templates often jailbroke the same questions, leaving more challenging ques- tions unaddressed. Third, GPTFuzzer combines each generated template with each question, often unnecessarily, resulting in inefficient exploration of the mutant search space.\nTo overcome these limitations, we developed TURBOFUZZLLM that (1) expands the mutation li- brary, (2) improves search with new selection poli- cies, and (3) adds efficiency-focussed heuristics. TURBOFUZZLLM achieves a near-perfect attack success rate across a wide range of target LLMs"}, {"title": "2 Method: TURBOFUZZLLM", "content": "Figure 1 presents an overview of TURBOFUZ- ZLLM. Except of a collection of functional (\u00a72.1), efficiency-focused (\u00a72.2), and engineering up- grades (Appendix A.1), the overall workflow of TURBOFUZZLLM is the same as GPTFuzzer.\nGiven a set of original templates \\(O = {o_1, o_2, ..., o_{|O|}}\\), a set of harmful questions \\(Q = {q_1, q_2, ..., q_{|Q|}}\\), and a target model \\(T\\), TURBO- FUZZLLM performs black-box mutation-based fuzzing to iteratively generate new jailbreaking templates \\(G = {g_1, g_2, ..., g_{|G|}}\\). In each fuzzing iteration, TURBOFUZZLLM selects a template \\(t\\) from the current population \\(P = O \\cup G\\) (initially \\(G = \\emptyset\\)) and a mutation \\(m\\) from the set of all mu- tations \\(M\\) to generate a new mutant \\(m(t)\\). Next, the effectiveness of this new template \\(m(t)\\) is eval- uated by attacking the target model \\(T\\) using \\(Q\\), i.e., \\(m(t)\\) is combined with questions \\(q_i \\in Q\\) to formu- late attack prompts \\(A_{m(t)} = {a_{q_1}, a_{q_2}, ..., a_{q_{|Q|}}}\\), which are queried to \\(T\\) to get a set of responses \\(R_{m(t)} = {r_{q_1}, r_{q_2}, ..., r_{q_{|Q|}}}\\). Each response \\(r_{q_i}\\) from \\(T\\) is sent to a judge model to evaluate whether or not \\(r_{q_i}\\) represents a successful jailbreak for ques- tion \\(q_i\\), to get the subset of successful jailbreak responses \\(R_{m(t)}^{success} \\subseteq R_{m(t)}\\). If \\(m(t)\\) jailbreaks at least one question (i.e., \\(R_{m(t)}^{success} \\ne \\emptyset\\)), then \\(m(t)\\) is added to \\(G\\), or else, \\(m(t)\\) is discarded. Fuzzing iterations end when a stopping criteria, such as all questions got jailbroken or the target model query budget, is reached."}, {"title": "2.1 Functional Upgrades", "content": "TURBOFUZZLLM implements two groups of func- tional upgrades over GPTFuzzer: i) new mutations, and ii) new selection policies to improve the mutant space explored during the search."}, {"title": "2.1.1 New Mutations", "content": "In addition to the 5 mutations from GPTFuzzer (Yu et al., 2023), we added 2 syntactic and 3 LLM- based new mutations to TURBOFUZZLLM.\n\u2022 Refusal Suppression. This is a static mutation, inspired from (Wei et al., 2024), that instructs the model to respond under constraints that rule out common refusal responses, thus mak- ing unsafe responses more likely. Figure 3 in Appendix A.5 details the mutant template generated on applying refusal suppression mu- tation to a given template.\n\u2022 Inject Prefix. This is a static mutation, inspired from (Wei et al., 2024; Jiang et al., 2024), that appends the fixed string \"Sure, here is\u201d to a given template. This can make the model to heavily penalize refusing and continue an- swering the unsafe prompt with a jailbreaking response.\n\u2022 Expand After. This is a LLM-based mutation, inspired from the Expand mutation from GPT- Fuzzer (Yu et al., 2023), designed to append the new content at the end of the given tem- plate (instead of adding new content to the beginning as in Expand).\n\u2022 Transfer Mutation. This is a LLM-based mu- tation that transforms a given template \\(y\\) us- ing another template-mutant pair \\((x, m^*(x))\\) as an example, instructing the LLM to in- fer the (compounded) mutation \\(m^*\\) and re- turn \\(m^*(y)\\). The example mutant \\(m^*(x)\\) is selected randomly from among the top 10 jailbreaking mutants generated so far during fuzzing and \\(x\\) is its corresponding root par- ent template, i.e., \\(x \\in O\\) and \\(m^*(x) = m_k(...m_2(m_1(x))...)\\). The key idea here is to apply in-context learning to transfer the series of mutations \\(m_1, m_2, ..., m_k\\) applied to an original template \\(x\\) to derive one of the top ranking mutants \\(m^*(x)\\) identified so far to the given template \\(y\\) in a single fuzzing it- eration. Figure 4 in Appendix A.5 details the prompt used to apply this mutation to a given template.\n\u2022 Few Shots. This is a LLM-based mutation that transforms a given template \\(y\\) using a fixed set of mutants \\([g_1, g_2,..., g_k]\\) as in-context examples. These few-shot examples are se- lected as the top 3 jailbreaking mutants gen- erated so far from the same sub tree as \\(y\\) (i.\u0435., \\(\text{root}(y) = \text{root}(g_i)\\) for \\(1 \\le i \\le k\\)). The key idea here is to apply few-shot in-context learn- ing to transfer to the given template \\(y\\) a hybrid combination of top ranking mutants identified so far and originating from the same original template as \\(y\\). Figure 5 in Appendix A.5 de- tails the prompt used to apply this mutation to a given template."}, {"title": "2.1.2 New Selection Policies", "content": "TURBOFUZZLLM introduces new template and mutation selection policies based on reinforcement learning to learn from previous fuzzing iterations which template or mutation could work better than the others in a given fuzzing iteration.\n\u2022 Mutation selection using Q-learning. TURBO- FuzzLLM utilizes a Q-learning based tech- nique to learn over time which mutation works the best for a given template \\(t\\). TURBOFUZ- ZLLM maintains a Q-table \\(Q : S \\times A \\rightarrow R\\) where \\(S\\) represents the current state of the environment and \\(A\\) represents the possible actions to take at a given state. Given a tem- plate \\(t\\) selected in a fuzzing iteration, TUR- BOFUZZLLM tracks the original root parent \\(\text{root}(t) \\in O\\) corresponding to \\(t\\) and uses it as the state for Q-learning. The set of possible mutations \\(M\\) are used as the actions set \\(A\\) for any given state. The selected mutation \\(m\\) is re- warded based on the attack success rate of the mutant \\(m(t)\\). Algorithm 1 in Appendix A.2 provides the pseudo code of Q-learning based mutation selection.\n\u2022 Template selection using multi-arm bandits. This template selection method is basically the same as Q-learning based mutation selec- tion, except that there is no environment state that is tracked, making it similar to a multi- arm bandits selection (Slivkins et al., 2019). Algorithm 2 in Appendix A.3 provides the pseudo code in detail."}, {"title": "2.2 Efficiency Upgrades", "content": "TURBOFUZZLLM implements two efficiency- focused upgrades with the objective of jailbreaking more harmful questions with fewer queries to the target model."}, {"title": "2.2.1 Early-exit Fruitless Templates", "content": "Given a mutant \\(m(t)\\) generated in a fuzzing itera- tion, TURBOFUZZLLM exits the fuzzing iteration early before all questions \\(Q\\) are combined with \\(m(t)\\) if \\(m(t)\\) is determined as fruitless. To de- termine whether or not \\(m(t)\\) is fruitless without making \\(Q\\) queries to the target model, TURBO- FuzzLLM utilizes a simple heuristic that iterates over \\(Q\\) in a random order and if any 10% of the cor- responding attack prompts serially evaluated do not result in a jailbreak, \\(m(t)\\) is classified as fruitless. In such a scenario, the remaining questions are skipped, i.e., not combined with \\(m(t)\\) into attack prompts, and the fuzzing iteration is terminated prematurely.\nUsing such a heuristic significantly reducing the number of queries sent to the target model that are likely futile. However, this leaves the possibil- ity that a mutant \\(m(t)\\) is never combined with a question \\(q_k \\in Q\\), even though it might result in a jailbreak. To avoid such a case, we added a new identity/noop mutation such that \\(m_{\text{identity}}(t) = t\\). Thus, even if a mutant \\(m(t)\\) is determined as fruit- less in a fuzzing iteration \\(k\\), questions skipped in iteration \\(k\\) can still be combined with \\(m(t)\\) in a pos- sible future iteration \\(l\\) (\\(l > k\\)) that applies identity mutation on \\(m(t)\\)."}, {"title": "2.2.2 Warmup Stage", "content": "TURBOFUZZLLM adds an initial warmup stage that uses original templates \\(O\\) directly to attack the target model, before beginning the fuzzing stage. The benefits of warmup stage are two-fold: i) it identifies questions that can be jailbroken with original templates directly, and ii) it warms up the Q-table for mutation/template selectors (\u00a72.1.2). Note that the early-exit fruitless templates heuris- tic (\u00a72.2.1) ensures that only a limited number of queries are spent in the warmup stage if the original templates as is are ineffective/fruitless."}, {"title": "3 Experiments", "content": "We conducted a detailed experimental evaluation to answer the following research questions:\nRQ1: Does TurboFuzzLLM outperform GPTFuzzer in terms of attack performance?\nRQ2: How does TURBOFUZZLLM compare against other jailbreaking methods in terms of attack success rate?\nRQ3: How generalizable are templates gener- ated with TURBOFUZZLLM when applied to unseen harmful questions?\nRQ4: Which upgrades significantly influence the attack performance of TURBOFUZZLLM?\nAdditionally, \u00a73.4 presents how to improve in-built defenses by performing supervised adversar- ial training using red-teaming data generated with TURBOFUZZLLM."}, {"title": "3.1 Implementation", "content": "We implemented TURBOFUZZLLM in ~3K lines of code in Python. We utilize Mistral Large 2 (24.07) as the mutator model to power LLM-based mutations. For all experiments, we utilize the fine- tuned Llama 2 13B model introduced in Harm-"}, {"title": "3.3 Evaluation", "content": "RQ1: Does TURBOFUZZLLM outperform GPTFuzzer in terms of attack performance?\nTable 1 summarizes the comparison of TURBO- FUZZLLM versus GPTFuzzer on HarmBench text standard dataset, with a target model query budget of 4,000 (4000 queries / 200 questions = 20 queries per question on average). Overall, TURBOFuz- ZLLM shows 2-3x better attack performance on all evaluation metrics. Functional and efficiency upgrades added exclusively to TURBOFUZZLLM (\u00a72.1 & \u00a72.2) results in TURBOFUZZLLM achiev- ing near-perfect attack success rates (98-100%), while requiring fewer queries (average 3.15x bet- ter) and producing more jailbreaking templates (av- erage 2.69x better).\nAdditionally, Table 1 also indicates how different target models compare based on native defenses against jailbreaking attacks. GPT-4o showed the best performance, reaching a relatively lower ASR while consistently requiring many more queries per jailbreak on an average. As shown in (Huang et al., 2024), a larger model does not always mean better defenses against jailbreaking attacks, as evident from comparing Gemma 7B versus Gemma 2B.\nRQ2: How does TURBOFUZZLLM compare against other jailbreaking methods in terms of attack success rate?\nTable 2 summarizes attack success rates of TURBO- FUZZLLM against a variety of white- and black- box jailbreaking methods taken from (Mazeika et al., 2024). TURBOFUZZLLM consistently out- performed these baselines, reaching near-perfect attack success rates for Zephyr 7B, R2D2, and GPT-"}, {"title": "RQ3: How generalizable are templates generated with TURBOFUZZLLM when applied to unseen harmful questions?", "content": "Table 3 summarizes how effective are templates learnt with TurboFuzzLLM in RQ1 (Table 1) when evaluated as is (i.e., without any fuzzing) on all 100 unseen harmful questions from JailBreak- Bench (Chao et al., 2024) dataset. Overall, these templates showed impressive generalizability to unseen questions, reaching \u2265 95% ASR consis- tently for each target model. The top-1 template individually achieved 69 91% ASR, while the top-5 templates collectively were able to jailbreak > 92% unseen harmful questions."}, {"title": "RQ4: Which upgrades significantly influence the attack performance of TURBOFUZZLLM?", "content": "Table 4 summarizes ablation studies we conducted using GPT-4o as the target model to understand the influence of each upgrade we added in TURBO- FUZZLLM (groups G1 to G4) as well as the effect of increasing the target model query budget (G5). Key observations include:\n\u2022 Among new mutations (\u00a72.1.1), refusal sup- pression and transfer mutation significantly impact the attack performance, while expand after and few shots only influence marginally (G1.a-e vs GO).\n\u2022 New selection policies (\u00a72.1.2) show a rela- tively lower influence compared to new mu- tations (G2.c vs G1.f) or efficiency upgrades (G2.c vs G3.c).\n\u2022 The early-exit fruitless templates heuristic (\u00a72.2.1) impacts the attack performance of TURBOFUZZLLM the most (G3.a vs GO). On the other hand, warmup stage (\u00a72.2.2) only marginally impacts the attack performance (G3.b vs G0).\n\u2022 Increasing the query budget helps both TUR- BOFUZZLLM and GPTFuzzer to achieve bet- ter ASR at the cost of increasing the aver- age queries required per jailbreak (G5.a-b vs G0/G4)."}, {"title": "3.4 Improving In-built Defenses with Supervised Adversarial Training", "content": "Jailbreaking artifacts generated by TURBOFUZ- ZLLM represent high-quality data that can be uti- lized to develop effective defensive and mitigation techniques. One defensive technique is to adapt jailbreaking data to perform supervised fine tun- ing with the objective of improving in-built safety mitigation in the fine-tuned model.\nWe performed instruction fine tuning for Gemma 7B using HuggingFace SFTTrainer\u2074 with QLORA (Dettmers et al., 2023) and FlashAtten- tion (Dao et al., 2022). We collected a total of 1171 attack prompts that were successful in jailbreaking Gemma 7B (200 from Table 1 and 971 from Table 3), paired each one of them with sampled safe responses generated by Gemma 7B for the corresponding question, and used these (successful attack prompt, safe response) pairs as the fine-tuning dataset."}, {"title": "4 Conclusions & Future Work", "content": "We presented TURBOFUZZLLM, a significant up- grade over (Yu et al., 2023) for effectively jailbreak- ing LLMs automatically in practice using black- box mutation-based fuzzing. Our experimental evaluation showed TURBOFUZZLLM achieves > 95% ASR consistently while requiring ~3x fewer queries than GPTFuzzer. Templates learnt with TURBOFUZZLLM generalize to unseen harmful questions directly. Supervised adversarial training using jailbreaking artifacts generated with TURBO- FUZZLLM significantly improved in-built model defenses to prompt attacks.\nFuture work includes presenting evaluation over an extended set of leading LLMs, comparison against latest/concurrent jailbreaking methods (Liu et al., 2024a; Pavlova et al., 2024; Lin et al., 2024; Chen et al., 2024; Liu et al., 2024b), conducting ablation studies for additional hyper parameters (Appendix A.4), exploring new upgrades & heuris- tics, and diving deep into devising effective defen- sive/mitigation techniques in practice."}, {"title": "Ethics Statement", "content": "Our research on jailbreaking techniques reveals potential vulnerabilities in LLMs that could be ex- ploited to generate harmful content. While this presents inherent risks, we believe transparency and full disclosure are essential for several reasons:\n\u2022 The methodologies discussed are relatively straightforward and have been previously doc- umented in existing literature. With suffi- cient resources and dedication, malicious ac- tors could independently develop similar tech- niques.\n\u2022 By revealing these vulnerabilities, we provide vital information to model developers to as- sess and enhance the robustness of their sys- tems against adversarial attacks.\nTo minimize potential misuse of our research, we have taken the following precautionary measures:\n\u2022 We included clear content warnings about po- tentially harmful content.\n\u2022 We will limit distribution of specific jailbreak- ing templates to verified researchers.\n\u2022 We included \u00a73.4 that describes details about how to improve in-built defenses using red- teaming data generated with our techniques.\nThe incremental risk posed by our findings is minimal since many effective jailbreaking tech- niques are already public. Our primary goal is to ad- vance the development of more robust and safer AI systems by identifying and addressing their vulner- abilities. We believe this research will ultimately benefit the AI community by enabling the devel- opment of better safety measures and alignment techniques."}, {"title": "A Appendix", "content": "A.1 Engineering Upgrades\nTURBOFUZZLLM adds a collection of engineering upgrades to improve the effectiveness and ease of usage, as follows:\n\u2022 Limit search to unbroken questions. To avoid the same set of questions being jailbroken across multiple fuzzing iterations, TURBOFUZZLLM removes a question \\(q_i\\) from \\(Q\\) as soon as \\(q_i\\) is jailbroken in a fuzzing iteration \\(k\\) (i.e., \\(Q \\leftarrow Q \\setminus \\{q_i\\}\\)). This ensures that future fuzzing it- erations focuses the search to questions that are still unbroken. Note that due to this upgrade, the total number of jailbreaks equals the number of questions jailbroken.\n\u2022 Checking template-mutation compatibility. Given a template \\(t\\), only a subset \\(M_t\\) of all mutations \\(M\\) might make sense as candidates to be applied to \\(t\\). For example, if \\(t\\) already ends with \"Sure, here is\u201d, there isn't much of a point of applying Inject Prefix or Expand After mutations. Similarly, if \\(t\\) already includes instructions for Refusal Suppression, there is no need to repeat these instructions again. Through simple regular expression checks, TURBOFUZZLLM derives a subset of mutations \\(M_t \\subseteq M\\) that are compatible with \\(t\\) and limits mutation selection to only a compatible mutation \\(m \\in M_t\\) when generating the mutant \\(m(t)\\).\n\u2022 Improved prompts for LLM-based mutations. As shown in figures 4 & 5, TURBOFUZZLLM utilizes formatting tags (e.g., \u201c[ANSWER BE- GINS]\u201d and \u201c[ANSWER ENDS]\u201d) to improve LLM-based mutant generation and decrease in- valid mutants.\n\u2022 Multi-threading support. Given a mutant \\(m(t)\\), TURBOFUZZLLM utilizes multi-threading to parallelize discharging attack prompts \\(A_{m(t)}\\) to the target model as well as evaluating correspond- ing responses \\(R_{m(t)}\\) to speed up the most time- critical steps in each fuzzing iteration.\n\u2022 Usability upgrades. TURBOFUZZLLM provides improved command-line interface, logging sup- port, statistics summary, and results reporting to enhance usage experience and results analysis."}, {"title": "A.2 Pseudo code for mutation selection using Q-learning", "content": "Algorithm 1 presents the Q-learning based muta- tion selection algorithm. Given a template \\(t\\), SE- LECTMUTATION selects a compatible mutation \\(m \\in M_t\\) using an epsilon-greedy exploration- exploitation strategy (lines 1-9). If the generated random number \\(\text{random} \\in [0, 1]\\) is less than ex- ploration probability \\(\\epsilon\\), then a uniformly-random selection is made from \\(M_t\\) (lines 3-5). Otherwise, a weighted random selection is done using the Q- table values \\(Q[s_t]\\) as weights, with the state \\(s_t\\) as the root parent of \\(t\\) (lines 6-8). Using the attack suc- cess rate of the generated mutant \\(m(t)\\) as reward"}, {"title": "A.3 Pseudo code for template selection using multi-arm bandits", "content": "Algorithm 2 presents the pseudo code for tem- plate selection using multi-arm bandits. In a given fuzzing iteration, SELECTTEMPLATE selects a tem- plate \\(t\\) from the current population \\(O \\cup G\\) using an epsilon-greedy exploration-exploitation strat- egy (lines 1-7). If the generated random number \\(\text{random} \\in [0, 1]\\) is less than exploration probabil- ity \\(\\epsilon\\), then a uniformly-random selection is made from \\(O \\cup G\\) (lines 2-4). Otherwise, a weighted random selection is done using the Q-table values \\(Q\\) as weights (lines 5-6). Using the attack success rate of the generated mutant \\(m(t)\\) as reward \\(r\\), the REWARD() function is used to update the Q-table value \\(Q[t]\\) for the selected template \\(t\\) (lines 8-10)."}, {"title": "A.4 Additional Implementation Details", "content": "TURBOFUZZLLM provides command-line options to easily change key hyper parameters, including the mutator model used for performing LLM-based mutations as well as the judge model used for eval- uating whether or not a target response represents"}, {"title": "A.5 Additional Details on New Mutations", "content": ""}]}