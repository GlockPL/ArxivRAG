{"title": "Strongly Topology-preserving GNNs for Brain Graph Super-resolution", "authors": ["Pragya Singh", "Islem Rekik"], "abstract": "Brain graph super-resolution is an under-explored yet highly relevant task in network neuroscience. It circumvents the need for costly and time-consuming medical imaging data collection, preparation, and processing. Current super-resolution methods leverage graph neural networks (GNNs) thanks to their ability to natively handle graph-structured datasets. However, most GNNs perform node feature learning, which presents two significant limitations: (1) they require computationally expensive methods to learn complex node features capable of inferring connectivity strength or edge features, which do not scale to larger graphs; and (2) computations in the node space fail to adequately capture higher-order brain topologies such as cliques and hubs. However, numerous studies have shown that brain graph topology is crucial in identifying the onset and presence of various neurodegenerative disorders like Alzheimer's and Parkinson's. Motivated by these challenges and applications, we propose our Strongly Topology-Preserving GNN framework for Brain Graph Super-Resolution (STP-GSR). It is the first graph super-resolution architecture to perform representation learning in higher-order topological space. Specifically, using the primal-dual graph formulation from graph theory, we develop an efficient mapping from the edge space of our low-resolution (LR) brain graphs to the node space of a high-resolution (HR) dual graph. This approach ensures that node-level computations on this dual graph correspond naturally to edge-level learning on our HR brain graphs, thereby enforcing strong topological consistency within our framework. Additionally, our framework is GNN layer agnostic and can easily learn from smaller, scalable GNNs, significantly reducing computational requirements. We comprehensively benchmark our framework across seven key topological measures and observe that it significantly outperforms the previous state-of-the-art methods and baselines. The STP-GSR code is available at https://github.com/basiralab/STP-GSR.", "sections": [{"title": "1 Introduction", "content": "Multi-resolution neuroimaging offers rich and complementary information, playing a crucial role in various neuroscientific studies [1,2]. Different resolutions offer detailed insights into the brain's anatomical and functional properties, which are instrumental for early disease diagnosis [3,4]. However, super-resolution imaging datasets are expensive and time-consuming to acquire and process. To address these challenges, numerous deep learning methods have been developed for cross-resolution image synthesis [5,6,7]. For instance, [6] utilizes an attention-based architecture to super-resolve PD, T1-w, and T2-w MRI, while [7] employs diffusion models [8] for T1-w and DWI. Recently, deep learning methods have also achieved great success in modeling graphs and higher-order relational structures [9], including brain connectomes [10,11,12]. For example, [12] integrates Graph Convolutional Networks (GCNs) [13] with Long Short-Term Memory (LSTM) networks [14] for the simultaneous spatio-temporal modeling of brain networks.\nDespite the parallel advances in multi-resolution image synthesis and deep graph learning, work on super-resolving brain graphs remains scarce. High-resolution brain graphs are necessary for accurate neuroscientific analysis. For example, [15] shows that coarse brain graphs diminish individual variability required for accurate functional connectome fingerprinting. Yet brain graph super-resolution is challenging for several reasons [16]. First, unlike images, low-resolution (LR) and high-resolution (HR) brain graphs lack a hierarchical structure and cannot use simple local transformations. Second, brain graphs are highly dense, leading to higher computational requirements.\nAlthough challenging, there has been some foundational work in tackling brain graph super-resolution using GNNs [17,18,19,20,21] and earlier works leveraging machine learning [22,23]. For example, [17] formulates graph super-resolution as a node feature learning task, using a graph U-Net architecture [24] to introduce hierarchical structure and a graph Laplacian operator to super-resolve LR graphs. Similar to [17], [19] follows the node feature learning formulation but employs more expressive NNConv layers [25] for global graph alignment and then applies a graph-GAN model [26] to generate HR graphs. Another variant of this work [20] presents a multi-resolution GNN model (StairwayGraphNet) for generating brain graphs at increasing scales. [18] uses representation template graphs in low and high-resolution domains as priors to speed up the training of a super-resolution GNN model. Another work [21] leveraged federated learning to super-resolve brain graphs when learning from limited data. Even though they achieve impressive results in predicting Dosenbach parcellated rfMRI [27] from T1-w MRI, we note some major limitations. First, to learn complex node features, these models use computationally intensive GNN layers and are thus not scalable to large brain graphs. Second, by operating predominately in the node space, they offer limited capacity to model higher-order topological structures such as cliques, hubs, etc.\nThe topological learning limitation forms a serious bottleneck that restricts the utility of such models. Numerous studies [28,29,30,31,32] have shown that brain graph topology plays a central role in correctly identifying the onset and"}, {"title": "2 Methodology", "content": "In this section, we describe our Strongly Topology-Preserving GNN framework for Brain Graph Super-Resolution (STP-GSR) (Figure 1). The key component of our model is the dual-graph formulation, which maps the edges of our brain graphs to nodes in a dual graph. This transformation simplifies the more challenging edge regression problem into an easier node regression task. The STP-GSR framework operates in two main stages. In the first stage, the Target-EdgeInitializer encodes information from the LR source graph to initialize edge features of our HR target graph. In the second stage, the DualGraphLearner constructs a dual graph and maps the HR edge features to its node space. It then applies a GNN to update these features, followed by an inverse mapping from node space back to edge space, ultimately predicting the HR target connectivity matrix.\nProblem statement. Let $G(V, E, A)$ denote a brain graph, where the elements of set $V$ represent the nodes or regions of interest (ROI) in the brain, the"}, {"title": "Primal-Dual Formulation", "content": "We now introduce the key contribution of our paper, which enables direct computations and learning in the higher-order edge-space.\nDefinition1. Given a directed graph $G(V, E, A)$, also known as the primal graph, its dual graph $G'(V', E', A')$ is constructed as follows:\n1. Each node of the dual graph $G'$ corresponds to an edge of the primal graph $G$ i.e. $(i, j) \\in V' \\Rightarrow (i, j) \\in E$\n2. Two dual nodes $(i, j), (k, l) \\in V'$ are connected by an edge in $G'$ if they share a common direction and at least one common node in $G$, i.e., the edges $(i, j)$ and $(k, l)$ have a common endpoint in $G$\n3. Let $r$ and $c$ be the indices of the dual node $(i, j)$ and $(k,l)$, respectively. Then, $A'$ is an unweighted adjacency matrix s.t. $A'_{rc} = 1$ if $(i, j)$ and $(k,l)$ are connected; otherwise $A'_{rc} = 0$\nThe dual graph defined above is also known as a line (di)graph or adjoint graph in graph theory [33]. For simple graphs, this primal-to-dual conversion is invertible, allowing us to easily map the dual nodes back to primal edges.\nSince our brain graphs are undirected, their connectivity matrices are symmetric, and it suffices to predict only the upper triangular part of $A$. Therefore, we define a reduced edge-set $\\hat{E} = \\{(i, j)|(i, j) \\in E; i < j\\}$ and simplify our dual graph formulation to:"}, {"title": "Definition 2", "content": "Given an undirected graph $G(V, \\hat{E}, A)$, it's dual graph $G' (V', E', A')$ is constructed as:\n1. Each node of the dual graph $G'$ corresponds to an edge of the primal graph $G$ i.e. $(i, j) \\in V' \\Rightarrow (i, j) \\in \\hat{E}$\n2. Two dual nodes $(i, j), (k, l) \\in V'$ are connected by an edge in $G'$ if they share a common node in $G$ i.e. they satisfy the condition $i = k \\cup i = l \\cup j = k \\cup j = l$\n3. Let $r$ and $c$ be the indices of the dual node $(i, j)$ and $(k, l)$ respectively. Then, $A'$ is an unweighted adjacency matrix s.t. $A'_{rc} = 1$ if $(i, j)$ and $(k,l)$ are connected; otherwise $A'_{rc} = 0$\nComputational Efficiency. The above reformulation allows us to significantly reduce the computational requirements for the dual graph. For a simple primal graph with $n$ nodes, the dual graph from Definition 1 will have $n' = n(n - 1)$ nodes in the worst case. This reduces by half for our simple undirected graphs in Definition 2. Moreover, even though the number of dual nodes increases quadratically, the resulting $A'$ is highly sparse ( more than 97%) even for our fully-connected primal graphs. This allows us to leverage the in-built optimizations in deep learning packages for highly sparse matrices.\nTopology-Preservation. The dual graph formulation offers two key topological advantages. First, existing GNN layers perform node representation learning and indirectly predict edge information, e.g., by taking the dot product of the node representations. This necessitates using computationally expensive GNN architectures to learn complex node representations capable of predicting edge features, which are not scalable to larger graphs. However, by shifting the computation to the edge-space, we learn directly on the edges, allowing the use of simpler GNN models. Second, nodes are considered 0-dimensional topological objects, while edges are 1-dimensional topological objects. Therefore, computing on these higher-order objects better captures higher-order relationships that underlie a diverse set of topological properties."}, {"title": "Graph Transformer Block (GTB)", "content": "This block encapsulates the key graph computational elements and is composed of:\nGraph Transformer Layer. We adopt the implementation in [34] for the graph transformer layer. For an input graph $G_s (V_s, E_s, A_s)$, let the input node feature matrix be $X = A_s$, i.e., the connectivity pattern for each node becomes its initial feature vector ($X = [x_1, x_2, ..., x_n]^T$). Next, for each node $i$, its representation is updated as:\n$x_i = W_0[x_i |||| ... ||*]$\n$x_i^{new} = x_i + \\sum_{j \\in N(i)} \\alpha_{ij}(W x_j + W_e A_{ij})$\n$\\alpha_{ij} = softmax(\\frac{(Wx_i)^T (Wx_j + W_e A_{ij})}{\\sqrt{d}})$"}, {"title": "GraphNorm", "content": "After calculating the updated representations for graph $G_s$, we apply instance based normalization [35], which helps stabilize and accelerate training."}, {"title": "Non-linearity", "content": "Earlier methods used sigmoid to enforce that the predicted connectivity strengths $\\in [0,1]$. However, we observed that this over-saturates the output and leads to vanishing gradients. Therefore, we switched to ReLU."}, {"title": "A-Target EdgeInitializer", "content": "This block distills information from the source LR primal graph $G_s$ to generate initial edge features for the target HR graph. Specifically, given $A_s$ and $X_s$, for a source LR graph, we update the LR node features as $X_s^{'} = GTB(A_s, X_s)$, followed by matrix multiplication to generate scalar edge features as $X^{edge} = X_s^{'} X_s^{'T}$."}, {"title": "B-DualGraphLearner", "content": "This block uplifts the GNN operations to edge space and predicts the final target HR connectivity $A_t$. First, it creates a HR dual graph $A'_t$ and maps the learned $X^{edge}$ to the dual space using the Primal2Dual conversion $(X^{dual} \\Rightarrow X')$. Then, it refines the edge features in the dual space as $X'_t = GTB(X', A'_t)$. Finally, it applies the Dual2Primal conversion to transform $X'_t$ back to the HR primal space and obtain the predicted target adjacency matrix $A_t$."}, {"title": "Primal2Dual", "content": "To map the edge features of our HR brain graphs to the node features of the dual graph, we extract the upper triangular section of $X^{edge}$ and reshape it to get the one-dimensional dual node feature matrix $X'$. However, we still need to define the underlying domain $A'_t$ of the target dual graph. For this, we use a simple fully-connected unweighted graph with $n_t$ nodes and create its dual using the formulation in Definition 2. $A'_t$ defined this way assumes a maximally connected HR domain, while the specific edge features or connectivity strengths are learned by updating $X'$."}, {"title": "Dual2Primal", "content": "To map dual node features back to the edges of our target HR graph, we treat the values in $X'_t$ as the values in the upper triangular part of $A_t$. To get our final predicted target HR matrix $A_t$, we simply pad, reshape, and reflect $X'$ into a square matrix of size $n_t$. It is worth noting that even though we used our dual formulation to learn scalar edge values, it is capable of learning multi-dimensional edge features and could predict multiple connectivity properties at once. Finally, the whole framework was trained end-to-end using L1 loss between predicted $A_t$ and the true target $A_t$."}, {"title": "3 Experimental Results and Discussion", "content": "Evaluation Dataset. We evaluate our model on 167 subjects from the publicly available Southwest University Longitudinal Imaging Multimodal (SLIM) dataset [36]. SLIM provides a set of structural, diffusion, and resting-state fMRI images along with rich behavioral data. We use the rfMRI scans to generate our LR and HR brain graphs. First, we preprocess the scans using the Preprocessed Connectomes Project Quality Assessment Protocol. We then parcellate them into different regions of interests (ROIs) using the Dosenbach [27] and Shen [37] brain atlases to obtain brain graphs of resolution 160 \u00d7 160 (LR) and 268 \u00d7 268 (HR), respectively.\nComparison methods. We use a combination of existing and newly created baselines to benchmark our framework including:\nAdapted IMANGraphnet. IMANGraphNet [19] is the current state-of-the-art GNN model on brain graph super-resolution. It super-resolves a 35 \u00d7 35 morphological connectivity matrix into 160 \u00d7 160 Dosenbach-parcellated rfMRI brain graph matrix. However, it uses the computationally expensive NNConv [25] layers, which cannot be scaled to our larger dataset due to out-of-memory (OOM) errors. Therefore, we evaluate against a modified version of IMAN-GraphNet, which linearly projects the LR node feature matrix $X_s$, to a lower-dimensional space before applying the NNConv layers. To maintain dimensional consistency, we apply another linear projection to map the output back to a higher-dimensional space.\nDirect SR. To isolate the impact of our Primal-Dual formulation, we define a DirectSR model that uses the Graph Transformer Block (GTB) to directly super-resolve the LR matrices into HR matrices. To ensure a fair comparison, we also increase its capacity by adding an additional graph transformer layer.\nLR-HR-LR AutoEncoder. Inspired by the iterative up-and-down sampling methods in image super-resolution [38], we propose an autoencoder model to capture the mutual dependency of LR and HR graphs. This model uses a GTB block to super-resolve a LR matrix to HR followed by another GTB block to down-resolve this HR matrix to LR. The model is trained using both the prediction loss for the HR matrix and the reconstruction loss for the LR matrix.\nParameter Setting. For all the models, we use a batch size of 16 along with the gradient accumulation trick to avoid memory issues. For all the models except Adapted IMANGraphNet, we use a learning rate of 0.005. For Adapted IMANGraphNet, following the original paper [19], we use a learning rate of 0.025. We also apply binary search to select the largest low-dimensional space (dim = 32) that does not cause OOM errors. For the graph transformer layer in the node space, we use 4 attentional heads with a dropout probability of 0.2. For the graph transformer layer in the edge-space, we use a single head as STP-GSR only uses a single graph transformer layer to predict scalar connectivity strengths. Finally, all models are trained for 60 epochs.\nEvaluation measures. We perform three-fold cross-validation and report the average performance across all folds. In addition to the mean absolute error (MAE) between the true and predicted HR matrix, we evaluate our model using"}, {"title": "Relevance of topological measures", "content": "Node degree centrality measures the number of incident connections to a given node and serves as an indirect measure of network resilience [39]. Betweenness centrality measures the fraction of shortest paths between all node pairs that pass through a given node and is useful for detecting bridge nodes between disparate regions [40]. Closeness centrality quantifies the mean distance between a given node and the rest of the network, indicating the speed of communication within the network. Eigenvector centrality assess the number of connections to a given node, weighted by the centrality of its neighbors, and evaluates hierarchical influence [41]. Participation Coefficient and Clustering Coefficient measures modularity in the network. The Participation Coefficient measures the diversity of intermodular interconnections of individual nodes, while the Clustering Coefficient assesses the presence of cliques or clusters. These metrics are important for evaluating brain network segregation and information processing within specialized brain subsystems [42]. Finally, Small-worldness is defined by the ratio between the characteristic path length and mean clustering coefficient (normalized by the corresponding values calculated on random graphs). It supports both segregated/specialized and distributed/integrated information processing [43]."}, {"title": "Performance Analysis", "content": "From Figure 2, we observe that STP-GSR consistently outperforms other methods on all topological measures. This demonstrates the advantage of our primal-dual formulation. Computations in the dual space benefit from propagating and aggregating information through higher-order topological objects (in this case, the edges) and inherently capture a diverse set of topological properties. While mapping to the dual space preserves topology, the absolute error on the predicted HR connectivity strengths is determined by the richness of our TargetEdgeInitializer and subsequent GNN computations in the HR dual space. However, as we are using a very small and shallow GNN"}, {"title": "4 Conclusion", "content": "In this work, we introduced STP-GSR, the first graph super-resolution framework based on direct edge representation learning. Our main contributions include: (1) A computationally efficient approach leveraging graph duality to map edge space computations to node space computations; (2) An end-to-end trainable pipeline integrating duality with brain graph super-resolution. We evaluated our framework against existing and newly created baselines across seven neuro-biologically relevant topological measures, where it significantly outperformed the previous state-of-the-art model and newly created baselines. Even though our model performs exceptionally well in preserving brain graph topology, its capacity to accurately predict the connectivity strength is limited by richness of the learned dual node features. As a future work, we aim to better understand the impact of dual node feature initialization and the possibility to synergetically combine node and edge space computations."}, {"title": "5 Supplementary Material", "content": "We provide below supplementary material for reproducible and open science:\n1. A 5-mn YouTube video explaining how STP-GSR works on BASIRA YouTube channel at https://www.youtube.com/watch?v=s1k-TcjKGFI\n2. Python code on Github at https://github.com/basiralab/STP-GSR"}]}