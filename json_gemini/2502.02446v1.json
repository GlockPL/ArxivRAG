{"title": "Towards graph neural networks for provably solving convex optimization problems", "authors": ["Chendi Qian", "Christopher Morris"], "abstract": "Recently, message-passing graph neural network (MPNNs) have shown potential for solving combinatorial and continuous optimization problems due to their ability to capture variable-constraint interactions. While existing approaches leverage MPNNs to approximate solutions or warm-start traditional solvers, they often lack guarantees for feasibility, particularly in convex optimization settings. Here, we propose an iterative MPNN framework to solve convex optimization problems with provable feasibility guarantees. First, we demonstrate that MPNNs can provably simulate standard interior-point methods for solving quadratic problems with linear constraints, covering relevant problems such as SVMs. Secondly, to ensure feasibility, we introduce a variant that starts from a feasible point and iteratively restricts the search within the feasible region. Experimental results show that our approach outperforms existing neural baselines in solution quality and feasibility, generalizes well to unseen problem sizes, and, in some cases, achieves faster solution times than state-of-the-art solvers such as Gurobi.", "sections": [{"title": "1. Introduction", "content": "Message-passing graph neural networks (MPNNs) have recently been widely applied to optimization problems, including continuous and combinatorial domains (Bengio et al., 2021; Cappart et al., 2023; Scavuzzo et al., 2024). Due to their inherent ability to capture structured data, MPNNs are well-suited as proxies for representing and solving such problems, e.g., in satisfiability problems, literals and clauses can be modeled as different node types within a bipartite graph (Selsam et al., 2018). At the same time, in linear programming (LP), the variable-constraint interaction naturally forms a bipartite graph structure (Gasse et al., 2019). Consequently, MPNNs are used as a lightweight proxy to solve such optimization problems in a data-driven fashion.\nMost combinatorial optimization (CO) problems are NP-hard (Ausiello et al., 1999), making exact solutions computationally intractable for larger instances. To address this, it is often more practical to relax the integrality constraints and solve the corresponding continuous optimization problems instead. This approach involves formulating a continuous relaxation as a proxy for the original problem. After solving the relaxed problem, the resulting continuous solutions guide the search in the discrete solution space (Schrijver, 1986). For example, solving the underlying linear programming relaxation in mixed-integer linear programming (MILP) is a crucial step for scoring candidates in strong branching (Achterberg et al., 2005), also using MPNNs (Gasse et al., 2019; Qian et al., 2024). Recent studies have extended MPNN-based modeling to other continuous optimization problems, especially quadratic programming (QP) (Li et al., 2024a; Gao et al., 2024; Xiong et al., 2024). Some existing methods integrate neural networks with traditional solvers (Fan et al., 2023; Jung et al., 2022; Li et al., 2022b; 2024a; Liu et al., 2024). These approaches either replace components of the solver with neural networks or use neural networks to warm-start the solver. In the former case, the methods remain limited by the solver's framework. In contrast, in the latter, the solver is still required to solve a related problem to produce feasible and optimal solutions.\nHowever, the above works mainly aim to predict a near-optimal solution without ensuring the feasibility of such a solution. For example, Fioretto et al. (2020); Qian et al. (2024) propose penalizing constraint violations by adding an extra loss term during training without offering strict feasibility guarantees. Existing strategies typically fall into two categories: relying on solvers to produce feasible solutions or projecting neural network outputs into the feasible region. The first approach, where the neural network serves primarily as a warm-start for the solver, still relies on the solver for final solutions. The second approach, which involves projecting outputs into the feasible region, often requires solving an additional optimization problem and can be efficient only for specific cases. Moreover, this projection"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "may degrade solution quality (Li et al., 2024b). More recently, approaches leveraging Lagrangian duality theory have emerged, aiming to design neural networks capable of producing dual-feasible solutions (Fioretto et al., 2021; Klamkin et al., 2024; Park & Van Hentenryck, 2023). While promising, these methods often require many iterations and still lack guarantees for strict feasibility.\nPresent work We propose an MPNN architecture that directly outputs high-quality, feasible solutions to convex optimization problems, closely approximating the optimal ones. Building on Qian et al. (2024), which pioneered using MPNNs for simulating polynomial-time interior-point methods (IPM) for LPs, we extend this approach to linearly constrained quadratic programming (LCQP), covering relevant problems such SVMs. Unlike Qian et al. (2024), where each MPNN layer corresponds to an IPM iteration, our fixed-layer MPNN predicts the next interior point from the current one, decoupling the number of MPNN layers from IPM iterations. We further prove that such MPNNs can simulate IPMs for solving LCQPs. In addition, we incorporate a computationally lightweight projection step that restricts the search direction to the feasible region to ensure feasibility, leveraging the constraints' linear algebraic structure. Experiments show our method outperforms neural network baselines, generalizes well to larger, unseen problem instances, and, in some cases, achieves faster solution times than state-of-the-art exact solvers such as Gurobi (Gurobi Optimization, LLC, 2024).\nIn summary, our contributions are as follows.\n1. We propose an MPNN-based approach for predicting solutions of LCQP instances.\n2. We theoretically show that an MPNN with O(1) distinct layers, where each layer has unique weights, and O(m + n) total message-passing steps and each step executes a layer that may be reused across steps, can simulate an IPM for LCQP.\n3. We introduce an efficient and feasibility-guaranteed variant that incorporates a projection step to ensure the predicted solutions strictly satisfy the constraints of the LCQP.\n4. Empirically, we show that both methods achieve high-quality predictions and outperform traditional QP solvers in solving time for certain problems. Furthermore, our approach can generalize to larger, unseen problem instances in specific cases."}, {"title": "1.1. Related work", "content": "Here, we discuss relevant related work."}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "MPNNS MPNNs (Gilmer et al., 2017; Scarselli et al., 2008) have been extensively studied in recent years. Notable architectures can be categorized into spatial models (Duvenaud et al., 2015; Hamilton et al., 2017; Bresson & Laurent, 2017; Veli\u010dkovi\u0107 et al., 2018; Xu et al., 2019) and spectral MPNNs (Bruna et al., 2014; Defferrard et al., 2016; Kipf & Welling, 2017; Levie et al., 2019; Monti et al., 2018; Geisler et al., 2024). The former conforms to the message-passing framework of Gilmer et al. (2017), while the latter leverage the spectral property of the graph.\nMachine learning for convex optimization In this work, we focus on convex optimization and direct readers interested in combinatorial optimization problems to the surveys Bengio et al. (2021); Cappart et al. (2023); Peng et al. (2021); see a more detailed discussion on related work in Appendix A.2.\nA few attempts have been made to apply machine learning to LPs. Li et al. (2022b) learned to reformulate LP instances, and Fan et al. (2023) learned the initial basis for the simplex method, both aimed at accelerating the solver. Liu et al. (2024) imitated simplex pivoting, and Qian et al. (2024) proposed using MPNNs to simulate IPMs for LPs (Nocedal & Wright, 2006). Li et al. (2024a) introduced PDHG-Net to approximate and warm-start the primal-dual hybrid gradient algorithm (PDHG) (Applegate et al., 2021; Lu, 2024). Li et al. (2024b) bounded the depth and width of MPNNS while simulating a specific LP algorithm. Quadratic programming (QP) has seen limited standalone exploration. Notable works include Bonami et al. (2018), who analyzed solver behavior to classify linearization needs, and Getzelman & Balaprakash (2021), who used reinforcement learning for solver selection. Others accelerated solvers by learning step sizes (Ichnowski et al., 2021; Jung et al., 2022) or warm-started them via end-to-end learning (Sambharya et al., 2023). Graph-based representations have been applied to quadratically constrained quadratic programming (QCQP) (Wu et al., 2024; Xiong et al., 2024), while Gao et al. (2024) extended Qian et al. (2024) to general nonlinear programs. On the theoretical side, Chen et al. (2022; 2024); Wu et al. (2024) examined the expressivity of MPNNs in approximating LP and QP solutions, offering insights into their capabilities and limitations.\nSee Appendix A.2 for a discussion on machine learning for constrained optimization."}, {"title": "1.2. Background", "content": "Here, we introduce notation, MPNNs, and convex optimization problems.\nNotation Let N := {0,1,2,... }. For n \u2265 1, let [n] := {1,..., n} \u2282 N. We use {...} to denote multisets, i.e.,"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "the generalization of sets allowing for multiple instances for each of its elements. A graph G is a pair (V(G), E(G)) with finite sets of vertices or nodes V (G) and edges E(G) \u2286 {{u, v} \u2286 V(G) | u \u2260 v}. For ease of notation, we denote the edge {u, v} in E(G) by (u,v) or (v, u). Throughout the paper, we use standard notation, e.g., we denote the neighborhood of a node v by N(v); see Appendix A.1 for details. By default, a vector x \u2208 Rd is a column vector.\nMPNNS Intuitively, MPNNs learn a vectorial representation, i.e., a d-dimensional real-valued vector, representing each vertex in a graph by aggregating information from neighboring vertices. Let G be an n-order attributed graph with node feature matrix X \u2208 Rn\u00d7d, for d > 0, following, Gilmer et al. (2017) and Scarselli et al. (2008), in each layer, t > 0, for vertex v \u2208 V(G), we compute a vertex feature\n$h_v^{(t)} := UPD^{(t)}(h_v^{(t-1)}, AGG^{(t)}(\\{{h_u^{(t-1)} | u \\in N(v)\\}\\})) \\in \\mathbb{R}^d,$\nwhere UPD(t) and AGG(t) may be parameterized functions, e.g., neural networks, and $h_v^{(0)} := X_v$.\nConvex optimization problems In this work, we focus on convex optimization problems, namely LCQPs, of the following form,\n$\\min_x \\frac{1}{2} x^T Q x + c^T x \\text{ such that } Ax = b, x \\geq 0.$\nHere, an LCQP instance I is a tuple (Q, A, b, c), where Q \u2208 Qnxn and c \u2208 Qn are the quadratic and linear coefficients of the objective, A \u2208 Qmxn and b \u2208 Qm form the constraints. We assume that the quadratic matrix Q is positive semi-definite (PSD), i.e., vTQv \u2265 0, for all v \u2208 Rn; otherwise, the problem is non-convex. We assume m \u2264 n and that A has full rank m; otherwise, either the problem is infeasible, or some linear constraints can be eliminated using resolving techniques (Andersen & Andersen, 1995). Furthermore, if constraints are inequalities, we can always transform them into equalities by adding slack variables (Boyd & Vandenberghe,"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "2004). We denote the feasible region of the instance I as F(I) := {x \u2208 Qn | Ax = b; for j \u2208 [m] and xi > 0 for i \u2208 [n]}. The optimal solution x* \u2208 F(I) is defined such as $\\frac{1}{2} x^T Q x + c^T x > \\frac{1}{2} x^{*T} Q x^* + c^T x^*$, for x \u2208 F(I), which we assume to be unique.\n2. Towards MPNNs for solving convex optimization problems\nHere, we provide a detailed overview of our MPNN architectures. We first describe how to represent an LCQP instance as a graph. Next, we present an MPNN architecture that provably simulates IPMs for solving LCQPs. Finally, we introduce a null space projection method to ensure feasibility throughout the search.\nEncoding LCQP instances as graphs Previous works have demonstrated that LP instances can be effectively encoded as a bipartite or tripartite graph (Gasse et al., 2019; Khalil et al., 2022; Qian et al., 2024). In the case of LCQPs, following Chen et al. (2024), we encode a given LCQP instance I into a graph G(I) with constraint node set C(I) and variable node set V(I). We define the constraint-variable node connections via the non-zero entries of the A matrix and define the edge features via ecv := Acv, for v \u2208 V(I), c \u2208 C(I). In addition, the constraint vector b acts as features for the constraint nodes, i.e., we design the constraint node feature matrix as C := reshape(b) \u2208 Qmx1. The feature matrix for the variable nodes is set to the objective vector V := reshape(c) \u2208 Qn\u00d71. To encode the Q matrix, we follow Chen et al. (2024) and encode the non-zero entries Qvu as edges between variable nodes v, u, and use the value Qvu as the edge attribute, evu := Qvu, v, u \u2208 V(I). Moreover, we add a global node {g(I)} to G(I), similar to Qian et al. (2024) for LPs, and connect it to all the variable and constraint nodes with uniform edge features ecg := 1, c \u2208 C(I), and evg := 1, v \u2208 V(I).\nMPNNs for simulating IPMS Here, we derive an MPNN architecture to provably simulate IPMs for solving LCQPs. For more details on IPM for LCQP, we refer to Ap-"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "pendix A.6. Similar to Gao et al. (2024), we decouple the number of layers L of the MPNN and the number of iterations T. Additionally, the learnable parameters of the L-layer MPNN are shared across the iterations. At each iteration t \u2208 [T], the L-layer MPNN takes the graph G(I) together with the current solution x(t-1) as input. The MPNN outputs a scalar per variable node as the prediction for the next interior point x(t), with an arbitrary initial solution x(0) \u2265 0. We denote the node embedding at layer l \u2208 [L] and iteration t \u2208 [T] as $h_o^{(l,t)}, o \\in V(I) \\cup C(I) \\cup \\{g(I)\\}$. At the beginning of each iteration, we initialize the node embeddings as\n$h_c^{(0,t)} := C_c \\in \\mathbb{Q}, c \\in C(I),$\n$h_v^{(0,t)} := CONCAT(V_v, x^{(t-1)}) \\in \\mathbb{Q}^2, v \\in V(I),$\n$h_g^{(0,t)} := 0.$\nEach message passing layer consists of three sequential steps, similar to Qian et al. (2024). First, the embeddings of the constraint nodes are updated, using the embeddings of the variable nodes and the global node $h_g^{(l,t)} :=$\n$h_c^{(l,t)} := UPD^{(\\c)}[h_c^{(l-1,t)},MSG((\\{(h_v^{(l-1,t)}, e_{cv}) | v \\in N(c) \\cap V(I)\\}\\}),MSG(h_g^{(l-1,t)}, e_{cg})] \\in \\mathbb{Q}^d.$\nNext, the global node embeddings are updated based on the embeddings of the variable nodes and the most recently updated constraint node embeddings $h_c^{(l,t)} :=$\n$h_g^{(l,t)} := UPD^{(\\g)}[h_g^{(l-1,t)},MSG((\\{(h_v^{(l-1,t)}, e_{vg}) | v \\in V(I)\\}\\}),MSG((\\{(h_c^{(l,t)}, e_{cg}) | c \\in C(I)\\}\\}))] \\in \\mathbb{Q}^d.$"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "Finally, the embeddings of the variable nodes are updated by aggregating information from their neighboring variable nodes and the updated constraint node and global node embeddings $h_g^{(l,t)} :=\n$h_v^{(l,t)} := UPD^{(\\v)}[h_v^{(l-1,t)},MSG((\\{(h_u^{(l-1,t)}, e_{uv}) | u \\in N(v) \\cap V(I)\\}\\}),MSG((\\{(h_c^{(l,t)}, e_{cv}) | c \\in N(v) \\cap C(I)\\}\\}),MSG(h_g^{(l,t)}, e_{vg})] \\in \\mathbb{Q}^d.$\nFinally, we use a multi-layer perceptron for predicting the current variable assignments,\n$x^{(t)} := MLP(h_v^{(L,t)}) \\in \\mathbb{Q},$\nwhose output vector x(t) \u2208 Qn serves as the prediction of the next interior point.\nFor training, we use the mean-squared error between our intermediate predictions x(t), t \u2208 [T], and the ground truth interior point given by the IPM $x^{*(t)}, t \\in [T]$,\n$L^{(t)}(x^{*(t)}, x^{(t)}) := ||x^{*(t)} - x^{(t)}||_2^2.$\nDuring training, we pre-set the iterations and supervise all predicted interior points. During inference, however, our framework allows for an arbitrary number of iterations and picks the best solution simultaneously. The training and inference processes are summarized in Algorithm 1 and Algorithm 2."}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "Now, the following result shows that there exists an MPNN architecture, fMpnn,ipm, of O(1) layers and O(m) message passing steps in the form of Equations (2) to (5), that is capable of simulating the IPM algorithm for LCQPs. For the detailed proof, please see Appendix A.7.\nTheorem 1. There exists an MPNN fmpnn,ipm composed of O(1) layers and O(m + n) successive message-passing steps that reproduces each iteration of the IPM algorithm for LCQPs, in the sense that for any LCQP instance I = (Q, A, b, c) and any primal-dual point (x(t), x(t), s(t)) with t > 0, fmPNN,IPM maps the graph G(I) carrying [x(t-1), s(t-1)] on the variable nodes, [\u03bb(t-1)] on the constraint nodes, and [\u03bc,\u03c3] on the global node to the same graph G(I) carrying the output [x(t), s(t)] and [\u03bb(t)] of Algorithm 7 on the variable and constraint nodes, respectively.\nEnsuring feasible solutions In supervised learning, ensuring feasibility is challenging due to training and validation errors in Algorithm 1 and Algorithm 2. Correcting infeasible solutions typically involves additional optimization, which adds computational overhead and may degrade solution quality. To address this, we propose an iterative method that maintains strict feasibility throughout optimization. Starting from a feasible point x(0), the search is constrained to the feasible region x(t) \u2208 F(I), for all t \u2208 [T]. We also discard intermediate steps from the expert solver, focusing only on the optimal solution to enhance flexibility. This section details our approach, answering two key questions: (1) How is an initial feasible solution constructed? (2) How can feasibility be preserved during updates? We also describe MPNN modifications and the search algorithm.\nWe can obtain a feasible initial solution by solving a trivial LP with the given constraints and a simple objective, such as c = 0. This incurs moderate overhead, as solving an LP is computationally cheaper than a quadratic problem. Existing methods, like the big-M and two-phase simplex methods (Bertsimas & Tsitsiklis, 1998), efficiently compute feasible basic solutions, while MOSEK's IPM Andersen & Andersen (2000) achieves feasibility within a few updates.\nWe follow the generic framework of iterative optimization methods (Nocedal & Wright, 2006), where, at each iteration, a search direction d(t) \u2208 Qn is determined and corresponding step length \u03b1(t) > 0 is computed. However, our approach differs in that we train an MPNN in a supervised way to predict the displacement d*(t) := x* \u2212 x(t-1) from the current solution x(t-1)."}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "to the optimal solution x*.1\nTo correct the predicted displacement d(t), we compute a feasibility-preserving displacement $ \\bar{d}^{(t)}$ such that $A(x^{(t-1)} +  \\bar{d}^{(t)}) = b$. If $Ax^{(t-1)} = b$, this reduces to $A \\bar{d}^{(t)} = 0$, meaning $ \\bar{d}^{(t)}$ lies in the null space ${v \\in \\mathbb{Q}^n | Av = 0\\}$. For full-rank $A \\in \\mathbb{Q}^{m \\times n}$, the null space has dimension $n - m$, represented by ${v_1,..., v_{n-m}}$. We project $d^{(t)}$ onto this space as $\\bar{d}^{(t)} = \\sum_{i=1}^{n-m} \\alpha_i v_i$ where $\\alpha_i := \\frac{v_i^T d^{(t)}}{v_i^T v_i}$. Thus, $\\bar{d}^{(t)} := \\sum_{i=1}^{n-m} \\frac{v_i^T d^{(t)}}{v_i^T v_i} v_i$, ensuring $A \\bar{d}^{(t)} = 0$. Updating $x^{(t)} = x^{(t-1)} + \\bar{d}^{(t)}$ preserves feasibility, assuming $x^{(0)}$ is feasible. In practice, singular value decomposition (SVD) (Strang, 2000) provides the orthonormal null space of A. The projection operator is expressed as $\\Pi_A := \\sum_{i=1}^{n-m} v_i v_i^T$, satisfying $\\Pi_A = \\Pi_A$ and has no effect on vectors already in the null space.\nIf the prediction of the MPNN is exact, i.e., $\\bar{d}^{(t)} = d^{(t)}$, and we take a step along $\\bar{d}^{(t)}$ with step length \u03b1(t) = 1 and we end up with the optimal solution. Therefore, by default, we set the step length \u03b1(t) = 1. However, if a full step using \u03b1(t) = 1 leads to the violation of the positivity constraint, we take a maximal possible \u03b1(t) < 1 so that all variables would still lie in the positive orthant, specifically\n$\\alpha^{(t)} := min\\{1, sup\\{\\alpha | x_i + \\alpha d_i^{(t)} \\geq 0, i \\in [n]\\}\\}.$\nFormally, the update step is\n$x^{(t)} := x^{(t-1)} + \\alpha^{(t)} \\Pi_A d^{(t)}.$\nThe MPNN architecture is similar to the IPM-guided approach introduced above. We drop the global node to enhance computational efficiency and align with the theorem outlined below. At each iteration t \u2208 [T], the L-layer MPNN takes the graph together with the current solution x(t-1) as input but, unlike above, predicts the displacement $\\bar{d}^{(t)}$ instead of subsequent point. In each iteration, we ini-"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "tialize the node embeddings as\n$h_c^{(0,t)} := C_c \\in \\mathbb{Q},$\n$h_v^{(0,t)} := CONCAT(V_v, x^{(t-1)}) \\in \\mathbb{Q}^2.$\nThe message passing on the heterogeneous graph is defined as\n$h_c^{(l,t)} := UPD^{(\\c)}[h_c^{(l-1,t)},MSG((\\{(h_v^{(l-1,t)}, e_{cv}) | v \\in N(c) \\cap V(I)\\}\\})].$\n$h_v^{(l,t)} := UPD^{(\\v)}[h_v^{(l-1,t)},MSG((\\{(h_u^{(l-1,t)}, e_{uv}) | u \\in N(v) \\cap V(I)\\}\\}),MSG((\\{(h_c^{(l,t)}, e_{cv}) | u \\in N(v) \\cap C(I)\\}\\}]$\nwhere we first update the constraint node embeddings and then the variable ones. In addition, we use a multi-layer"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "perceptron to predict the displacement from the current solution x(t-1) to the optimal solution x*,\n$\\bar{d}^{(t)} := MLP(h_v^{(L,t)}) \\in \\mathbb{Q}.$\nWe denote the exact displacement pointing from the current solution at iteration t to the optimal solution as the oracle displacement, $d^{*(t)} = x^* \u2212 x^{(t\u22121)}$, and define the supervised loss\n$L^{(t)}(d^{*(t)}, \\bar{d}^{(t)}) := ||d^{*(t)} - \\bar{d}^{(t)}||_2^2.$\nIn practice, when the current solution x(t) approaches the boundary of the positive orthant Q and the prediction $\\bar{d}^{(t)}$ is inaccurate, the step length \u03b1(t) can be too small to ensure the non-negativity constraints. Due to the continuous nature of neural networks, the prediction $\\bar{d}^{(t+1)}$ will hardly change since $x^{(t+1)} \u2248 x^{(t)}$ and a small \u03b1(t+1) will be picked. This makes the search process stagnant. To address this vanishing step length issue, we introduce a correction term $\\frac{\\tau}{x^{(t-1)} + \\epsilon}$, where the bias \u03f5 ensures numerical stability and \u03c4 adjusts the correction's magnitude, encouraging the solution x(t) to move away from the orthant boundary. Details of this design are provided in Appendix A.5. Algorithms 3 and 4 show the training and inference using the MPNNs.\nNow, the following result shows that our proposed MPNN architecture is expressive enough to predict the displacement arbitrarily close.\nTheorem 2. Given a LCQP instance I, assume I is feasible with solution x*, x(0) \u2265 0 is an initial feasible point, for any \u03f5, \u03b4 > 0, there exists an MPNN architecture fMPNN,2 such that\n$\\mathbb{P}[|| f_{MPNN,2}(I, x^{(0)}) - (x^* - x^{(0)}) ||_2 > \\delta] < \\epsilon.$\n2.1. Complexity analysis\nIt is straightforward to show that our IPM-guided approach lies within the framework of MPNN. Thus, the runtime is linear to the number of nodes and edges, i.e., O(n + m + |E(G)|), where m, n are the numbers of constraints and variables. In the worst case, where the A and Q matrices are dense, the complexity amounts to O(mn+n\u00b2). However, we need further investigation for the feasibility approach. The two-phase method, for the feasible initial solution, requires solving an extra LP and finding the initial feasible point, which is in O(nm) (Bertsimas & Tsitsiklis, 1998). The null space calculation is based on SVD or QR decomposition and is of complexity O(nm\u00b2) (Strang, 2000). Fortunately, finding a feasible solution and calculating the null space and corresponding projection matrix only need to be done once in the pre-processing phase. The projection of the predicted direction on the null space of A"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "is O(n(n-m)). The message passing scheme between the two node types has the same complexity O(|E(G)|), which depends on the number of edges, i.e., the nonzero entries of the A and Q matrices, also O(mn + n\u00b2) in the worst case. The remaining part of the algorithm, such as the line search and variable update, is in O(n)."}, {"title": "3. Experimental study", "content": "In the following, we investigate to what extent our theoretical results translate into practice. The implementation is open source at https://github.com/chendiqian/FeasMPNN.\nQ1 How good is the solution quality of our MPNN architectures regarding objective value and constraint violation?\nQ2 How well can our (pre-)trained MPNN architectures generalize to larger unseen instances?\nQ3 How fast are our MPNN architectures compared with baselines and traditional solvers?\nWe evaluate three types of synthetic LCQP problems: generic, soft-margin support vector machine (SVM), and Markowitz portfolio optimization problems, following Jung et al. (2022). Details of dataset generation are provided in Appendix A.4. For each problem type, we generate 1000 instances, split into training, validation, and test sets with an 8:1:1 ratio. Hyperparameters for all neural networks are tuned on our feasibility variant and shared across baselines. Specifically, we train an MPNN of 8 layers with hidden dimension 128 using the Adam optimizer (Kingma & Ba, 2015) for up to 1000 epochs with early stopping after 300 epochs. During training, our IPM- and feasibility-based architectures use 8 iterations, which are increased to 32 during inference. For our feasibility approach, the instances are preprocessed using SciPy (Virtanen et al., 2020) for null space computation and an IPM solver (Frenk et al., 2013) to obtain feasible initial solutions from the linear constraints. Training is conducted on four Nvidia L40s GPUs. Timing evaluations for neural network methods in Table 17 are performed on a single Nvidia L40s. In contrast, solver and preprocessing evaluations are carried out on a MacBook Air with an Apple M2 chip.2\nSolution quality (Q1) We benchmark all approaches regarding the relative objective gap and constraint violation metrics. Given the ground truth optimal solution x*, MPNN-predicted solution x of an LCQP instance, and the objective function obj(x) := +xQx + cx the relative objective gap is calculated as\n$\\frac{obj(x) - obj(x^*)}{obj(x^*)} \\times 100\\%$,\nand the constraint violation metric is computed as\n$\\frac{1}{m} \\sum_{i=1}^m \\frac{|A_i x - b_i|}{\\max \\{|b_i|, \\max_j |A_{ij}|\\}},$"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "i.e., for each constraint i, we calculate the absolute violation number |Aix \u2013 bi|, normalized by the scale of Ai, bi, and we calculate the mean value across all the constraints. To show the model-agnostic property of our approaches, we use the GIN (Xu et al., 2019) and GCN (Kipf & Welling, 2017) as our MPNN layers. The selected baselines are: (1) a naive MPNN approach that directly predicts the LCQP solution, following Chen et al. (2024), and (2) a variant of IPM-MPNN for LCQPs (Qian et al., 2024), where the output of each layer represents an intermediate step of the search process.\nOur IPM-guided search theoretically requires a global node in the graph, but our feasibility method does not. To ensure fairness, we conduct experiments with and without the global node; see Table 1 and Table 2. Our feasibility method generally achieves lower relative objective gaps, indicating better approximations of optimal solutions, particularly for generic LCQP and portfolio problems. However, the advantage is less pronounced on SVM tasks, where the quadratic matrix has a diagonal structure. While both IPM approaches exhibit constraint violations, similar to naive MPNN predictions, our feasibility method ensures strict feasibility up to numerical precision (10-7). Differences between global-node and non-global-node settings are typically minor, except for the Chen et al. (2024) approach on portfolio optimization, where problem-specific factors may account for an order-of-magnitude difference.\nFurthermore, to compare against feasibility-related work, we generate another synthetic dataset of 1000 LCQP instances with 200 variables, 50 equality constraints, and 200"}, {"title": "Towards graph neural networks for provably solving convex optimization problems", "content": "trivial inequality constraints (x > 0). The dataset is split into training", "8": 1}]}