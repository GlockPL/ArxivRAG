{"title": "ACTIVE LEARNING FOR CONTINUAL LEARNING:\nKEEPING THE PAST ALIVE IN THE PRESENT", "authors": ["Jaehyun Park", "Dongmin Park", "Jae-Gil Lee"], "abstract": "Continual learning (CL) enables deep neural networks to adapt to ever-changing\ndata distributions. In practice, there may be scenarios where annotation is costly,\nleading to active continual learning (ACL), which performs active learning (AL)\nfor the CL scenarios when reducing the labeling cost by selecting the most infor-\nmative subset is preferable. However, conventional AL strategies are not suitable\nfor ACL, as they focus solely on learning the new knowledge, leading to catas-\ntrophic forgetting of previously learned tasks. Therefore, ACL requires a new AL\nstrategy that can balance the prevention of catastrophic forgetting and the ability\nto quickly learn new tasks. In this paper, we propose AccuACL, Accumulated\ninformativeness-based Active Continual Learning, by the novel use of the Fisher\ninformation matrix as a criterion for sample selection, derived from a theoretical\nanalysis of the Fisher-optimality preservation properties within the framework\nof ACL, while also addressing the scalability issue of Fisher information-based\nAL. Extensive experiments demonstrate that AccuACL significantly outperforms\nAL baselines across various CL algorithms, increasing the average accuracy and\nforgetting by 23.8% and 17.0%, respectively, in average.", "sections": [{"title": "1 INTRODUCTION", "content": "Continual learning (CL), a learning scenario to adapt models continuously on evolving data distribu-\ntions, is essential in our dynamic world (Thrun, 1995). Numerous CL methods have been advanced\nwith the common goal of preserving past knowledge while acquiring new knowledge across the CL\ntasks (Abraham and Robins, 2005; Kim et al., 2023b; Mermillod et al., 2013). While most studies in\nCL assume that the evolving data distributions are fully labeled, this is rarely the case in practice. For\nexample, fraud detection systems in financial services must continuously learn to recognize new fraud\npatterns. However, the process of annotating these unique patterns is expensive, since it requires\nprofessional analysis in the field (Lebichot et al., 2024). As a result, active continual learning (ACL)\nis becoming a key challenge for effectively mitigating the limited labeling budget, by querying the\nmost important examples at each CL task that maximize the model's performance over all observed\ntasks (Cai et al., 2022; Perkonigg et al., 2021; Vu et al., 2023).\nHowever, conventional active learning (AL) strategies are not suitable for ACL scenarios, because\nthey are mainly designed to query the examples relevant to the knowledge about a new task. That\nis, in both uncertainty-based and diversity-based AL strategies, the examples that the model has\nnot encountered are highly prioritized (Ash et al., 2019; Sener and Savarese, 2017; Settles, 1995).\nFigure 1(a) first illustrates the inappropriateness of the conventional AL strategies for ACL scenarios.\nThe unlabeled data with diverse feature importance is continuously received for each task. At\ntask t, these AL strategies typically pay more attention to new features (i.e., Features 3 and 4),\nand accordingly, the examples mainly involved with the new features are selected by the active\nlearner. That is, the AL strategies focus only on quickly learning new tasks and neglect preventing\ncatastrophic forgetting. Thus, the past knowledge involved with Features 1 and 2 can be forgotten\nafter learning task t. Failing to capture the crucial features of the past knowledge causes catastrophic\nforgetting (French, 1999), which results in significant performance degradation even compared to\nrandom querying, as shown in Figure 1(b)."}, {"title": "2 RELATED WORK", "content": "Active Learning (AL). AL is a research field that focuses on the selection of unlabeled data points\nfor labeling by an oracle, which provides supervision, especially in domains where labeling requires\nsignificant costs Ren et al. (2021); Tharwat and Schenck (2023). This process allows us to optimize\nmodel performance under labeling budget constraints. Many strategies exist for selecting informative\nexamples from unlabeled data. Uncertainty-based approaches measure model prediction uncertainty\nand select the most uncertain examples (Roth and Small, 2006; Settles, 1995; Wang and Shang, 2014).\nDiversity-based methods prioritize diverse examples to reduce redundancy between selected examples\nand capture a broader range of patterns and complexities in the data pool (Sener and Savarese, 2017).\nHybrid approaches use gradient space embedding to select diverse and uncertain examples (Ash\net al., 2019). Fisher information-based methods measure the asymptotic value of unlabeled data with"}, {"title": "3 PRELIMINARY", "content": ""}, {"title": "3.1 PROBLEM SETUP: ACTIVE CONTINUAL LEARNING", "content": "Consider a sequence of tasks $T = \\{1, . . ., T\\}$, where the input space $X_t$ and label space $Y_t$ shift as\nthe tasks progress. This study focuses on class-incremental learning, where $Y_t \\cap Y_{t'} = \\emptyset (t' < t)$. In\nthe active continual learning (ACL) framework, at task t, an unlabeled dataset $U_t = \\{x_i\\}_{i=1}^{|U_t|} \\sim D_{X_t}$\nis provided. Within a labeling budget constraint $b_t$, we query the label of the selected subset $S_t \\subset U_t$\nto the oracle labeler $A(\\cdot)$ to obtain $L_t = \\{(x_i, y_i)\\}$, where $y_i \\sim D_{y_i|x_i}(x_i)$. The objective of\nACL is to identify the most informative subset $S$ such that, when the parameter $\\hat{\\theta}_t$ is trained by $S$,\nit minimizes an expected arbitrary error $\\epsilon$ across all encountered data distribution $D_{1:t} = D_{X_{1:t} \\times Y_{1:t}}$.\nFormally, at each task t,\n$\\qquad S^* = \\underset{S_t \\subset U_t, |S_t| \\leq b_t}{\\text{arg min}} \\mathbb{E}_{(x,y) \\sim D_{1:t}} [\\epsilon(x, y; \\hat{\\theta}_t)] \\text{ s.t. } \\hat{\\theta}_t = \\underset{\\theta}{\\text{arg min}} \\mathcal{L}_{CL} (\\theta; \\theta_{t-1}, A(S_t)),$ (1)\nwhere $\\epsilon$ can be the cross-entropy error for classification tasks. Note that AL for each CL task $t \\in T$\nis performed through multiple rounds, as in conventional AL."}, {"title": "3.2 FISHER INFORMATION-BASED ACTIVE LEARNING", "content": "The Fisher information matrix is often used to quantify the information conveyed to the model\nparameters, indicating their significance in modeling a data distribution (Lehmann and Casella, 2006).\nA model parameter $\\theta \\in \\Theta$ with a high Fisher information is essential for modeling the distribution,\nand altering its value hinders the model performance. Fisher information-based AL assumes the true\nmodel parameter $\\theta^*$, in which the underlying conditional distribution $D_{y|x}(x) = p(\\cdot|x, \\theta^*)$. Under\nthis premise, Fisher information-based AL seeks to select an optimal subset $S^* \\subset U$ to label, which\nminimizes the discrepancy between the trained model parameter $\\hat{\\theta}$ and the true model parameter\n$\\theta^*$. In particular, when the discrepancy is formulated as the log-likelihood ratio $\\epsilon(x, y, \\theta, \\theta^*) =$\n$\\log p(y|x; \\hat{\\theta}) - \\log p(y|x; \\theta^*)$, it results in a simpler objective function that leverages the Fisher"}, {"title": "4 ACCUACL: PROPOSED ACL METHOD", "content": "In this section, we develop a novel ACL strategy that queries data, which prevents catastrophic\nforgetting and, at the same time, learns new tasks quickly. First, we establish the accumulated\ninformativeness to formulate an optimal informativeness measure that accounts for both preventing\nforgetting and facilitating rapid learning (in \u00a7 4.1). Second, we show that the Fisher-based ACL\nis a promising approach for integrating accumulated informativeness into the query strategy (in\n\u00a7 4.2). Third, we provide an efficient approach for approximating the Fisher information matrix to\nimprove scalability (in \u00a7 4.3). Finally, we introduce AccuACL, Accumulated informativeness-based\nActive Continual Learning, which is derived from two unique properties that the approximated Fisher-\nbased ACL should satisfy (in \u00a7 4.4). Furthermore, we provide a complexity analysis of AccuACL,\ndemonstrating its practical usability. The overall methodology is provided in Algorithm 1."}, {"title": "4.1 ACCUMULATED INFORMATIVENESS", "content": "We commence by introducing the accumulated informativeness for ACL, which quantifies the amount\nto which a subset (or a sample) $S_t \\subset U_t$ at task t is beneficial for enhancing the performance within"}, {"title": "4.2 ACCUMULATED INFORMATIVENESS AND FISHER-BASED ACL", "content": "From Eq. (1), we can extend the objective in Eq. (4) to the ACL problem. In contrast to conventional\nAL, the objective of CL is to maximize the generalization performance across all encountered tasks.\nThe Fisher-based AL objective for each task t in ACL is formulated as\n$\\qquad S^* = \\underset{S_t \\subset U_t, |S_t| \\leq b_t}{\\text{arg min }} \\text{tr } [I(\\theta; S_t)^{-1}I(\\theta; U_{1:t})] - ACCUINFO(S_t, U_{1:t})$ (8)\nwhere $U_{1:t}$ is the whole collection of unlabeled data from all encountered tasks $\\{1, . . ., t\\}$, and $b_t$\nrefers to the labeling budget for task t. The target Fisher information matrix $I(\\theta_t; U_{1:t})$ represents\nthe importance of parameters for all observed tasks. That is, the trace function in Eq. (8) represents\nthe accumulated informativeness in Eq. (7). As a result, the optimal subset $S_t$ guarantees an accurate\nestimate of essential parameters for all observed tasks.\nIn Theorem 4.1, we show that the target Fisher information matrix in Eq. (8) can be decoupled into two\nmatrices representing past and new information, respectively, with $\\lambda$ balancing the informativeness\nbetween the two. A number close to 1 indicates an AL that prioritizes preventing catastrophic\nforgetting, whereas a value close to 0 indicates an AL that prioritizes quick learning of new tasks.\nThat is, Eq. (9) offers a practical form of the function $f(\\cdot, \\cdot)$ that combines the two informativeness\nmeasures for past and new tasks in Eq. (7).\nTheorem 4.1. Let $U_{1:t}$ be the unlabeled data pool for all seen tasks until task t. Then, the target\nFisher information matrix can be divided into past and new information matrices such that\n$\\qquad I(\\theta_t; U_{1:t}) = \\lambda \\cdot I(\\theta_t; U_{1:t-1}) + (1 - \\lambda) \\cdot I(\\theta_t; U_{t})$ (9)\nwith the optimal value of the balancing parameter $\\lambda = \\frac{|U_{1:t-1}|}{|U_{1:t|}}$\nHowever, it is infeasible to directly apply an existing optimization technique to Fisher-based AL, as\ndeveloped for conventional AL, to select examples based on Eq. (8) (Ash et al., 2021). The reason is\nthat the unlabeled data pool $U_{1:t-1}$ of the past tasks is not available in CL scenarios. Consequently,\nwe leverage a small-sized memory buffer $M_t \\subset L_{1:t-1}$, generally maintained in rehearsal-based\nCL (Aljundi et al., 2019; Buzzega et al., 2020; Rolnick et al., 2019). The estimated target Fisher\ninformation matrix for task t is defined as\n$\\qquad I(\\theta_t; U_{1:t}) \\approx I(\\theta_t; M_t, U_t) = \\lambda \\cdot I(\\theta_t; M_t) + (1 - \\lambda) \\cdot I(\\theta_t; U_+), \\lambda = \\frac{|U_{1:t-1}|}{|U_{1:t|}}$ (10)"}, {"title": "4.3 FISHER INFORMATION EMBEDDING", "content": "For deep neural networks with numerous parameters, directly solving Eq. (8) is infeasible owing to the\ncomputationally expensive and time-consuming calculation of the inverse of the Fisher information\nmatrix, which is cubic in complexity. Recent research, such as BAIT (Ash et al., 2021), reduces\nthe computational cost by using the last linear classification layer to obtain the Fisher information\nmatrix and an online approach to update the inverse matrix via Woodbury matrix identity. However,\nsince matrix inversion is still needed, it is computationally demanding, confining its application to\nsmall-scale datasets such as MNIST (LeCun et al., 1998) and CIFAR-10 (Alex, 2009).\nAccordingly, we propose the Fisher information embedding, which is the diagonal component of the\nFisher information matrix, to reduce spatial and temporal complexity from square to linear. Formally,\nthe Fisher information embedding $f (\\theta_t; x)$ of an example x is expressed as\n$\\qquad f(\\theta_t; x) = \\sum_{y \\in C} p(y|x; \\theta_t) [\\nabla_{\\theta_t} \\log p(y|x; \\theta_t)]^2 \\in \\mathbb{R}^{|\\Theta|},$ (11)\nwhich is equivalent to the diagonal component of Eq. (5). The use of the diagonal elements of the\nFisher information matrix is known to effectively prevent catastrophic forgetting when a model is\nadapted to shifting data distributions (Kirkpatrick et al., 2017; Pennington and Worah, 2018). While\nprevious studies have used the diagonal Fisher information as a regularization method in gradient\ndescent, we use it as a representation for each example.\nMoreover, we consider solely the last linear classification layer to compute the Fisher information\nmatrix, based on the premise that the penultimate layer representation approximates a convex\nmodel (Ash et al., 2021). The computation of the Fisher information embedding necessitates |C|\nbackward propagation since the gradient must be derived throughout the whole class space, which may\nbe impractical for large-scale datasets. In Theorem 4.2, we show that its calculation can be reduced\ninto a single forward operation, thereby avoiding the need for heavy computations proportional to\n|C|. This embedding is used to diagonally approximate the Fisher information matrix of a dataset\n$D$ as $F(\\theta_t; D) = \\mathbb{E}_{x \\in D} f (\\theta_t; x)$. Accordingly, we obtain the embedding version of our target\nFisher information $F(\\theta_t; M_t, U_t) = \\lambda\\cdot F(\\theta_t; M_t) + (1 - \\lambda) \\cdot F(\\theta_t; U_t)$.\nTheorem 4.2. Let $K$ be the number of classes, $d$ be the number of embedding dimensions, $\\theta^{[L]}_t=$\n$(w_{k,1}, ..., w_{k,d}) \\in \\mathbb{R}^{Kd}$ be the parameters of the last linear classification layer, and $h(\\theta_t; x) \\in \\mathbb{R}^{d}$ be\nthe embedding of an example $x$. Then, the $(k, i)$-th component of the Fisher information embedding\nf($\\theta_t; x$) can be formally expressed as\n$\\qquad f(\\theta_t;x)_{k,i} = \\sum_{y=1}^K p(y|x; \\theta_t) [\\nabla_{w_{ki}} \\log p(y|x; \\theta_t)]^2 = p_k (1 - p_k) h(\\theta_t; x)^2,$ (12)\nwhere $k \\in [1, K], i \\in [1, d], p_k = \\frac{\\exp{z_{x,k}}}{\\sum_{j=1}^{K} \\exp{z_{x,j}}}$ the softmax probability of an example x for the class\nk, and $z_{x,k}$ the logit for the class k of the example x."}, {"title": "4.4 FISHER-OPTIMALITY-PRESERVING PROPERTIES", "content": "Since the Fisher-based AL objective in Eq. (8) is not submodular (Ash et al., 2021), greedy op-\ntimization does not guarantee a bounded approximation. Furthermore, understanding Eq. (4) for\nmultivariate models is challenging since it involves the inverse of the Fisher information matrix.\nHence, it is difficult to get a clear intuition of what examples are most beneficial for optimizing\nthe objective function. However, we show that by simplifying the objective function from a Fisher\ninformation matrix to a Fisher information embedding, we can get intuitions about what properties\n$x \\in S$ should possess. The objective function of Eq. (4) can be rewritten as\n$\\qquad S^*= \\underset{S_t \\subset U_t, |S_t| \\leq b_t}{\\text{arg min}} \\sum_{i=1}^{\\Theta_t} \\frac{t_i}{s_i}$ (13)\nwhere the i-th components of the target Fisher information embedding $F(\\theta_t; M_t, U_t)$ and the\ncandidate Fisher information embedding $F(\\theta_t; S_t)$ are $t_i$ and $s_i$, respectively. As the value of $t_i$ does\nnot change, we find two properties that the $s_i$ should have under two different conditions."}, {"title": "4.5 PUTTING THEM ALL TOGETHER: ACCUACL", "content": ""}, {"title": "4.5.1 GREEDY QUERY STRATEGY", "content": "We propose a novel greedy query strategy based on the two properties discussed in Section 4.4.\nAccuACL successfully constructs a batch of examples with the properties at task t.\nMagnitude Score. Based on Property 1, in order to reward the examples with higher Fisher infor-\nmation, we propose the magnitude score $M(\\theta_t, x)$, which is the $l_2$-norm of the Fisher information\nembedding $M(\\theta_t, x) = || f(\\theta_t; X)||_2$.\nDistribution Score. Based on Property 2, in order to reward the examples with similar information\ndistribution to $F(\\theta_t; M_t, U_t)$, we propose the distribution score $D(\\theta_t, x, M_t,U_t)$, which is the\nJensen-Shannon divergence (Lin, 1991) between the distributions of $f (\\theta_t; x)$ and $F(\\theta_t; M_t, U_t)$,\n$\\qquad D(\\theta_t, x, M_t, U_t) = \\exp\\left(-D_{JS}(\\sigma(f(\\theta_t;x))||\\sigma(F(\\theta_t; M_t, U_t)))\\right),$ (14)\nwhere $\\sigma(z) = \\frac{e^z}{\\sum e^z}$ is the softmax function, and $D_{JS}(\\cdot|\\cdot)$ is the Jensen-Shannon divergence.\nMerger of the Two Scores. In order to select the examples that satisfy both properties, we overly-\nsample the subset that ranks highest according to $D(\\cdot)$, and then further narrow it down by selecting its\nsubset that ranks highest according to $M(\\cdot)$. Intuitively, after identifying important parameters for the\npast and the new through the target Fisher information $F(\\theta_t; M_t, U_t)$, AccuACL prioritizes sample\nselection to preserve the stability of past parameters while effectively optimizing those important for\nthe new task."}, {"title": "4.5.2 \u0421\u043eMPLEXITY ANALYSIS", "content": "Space Complexity. Owing to the Fisher information embedding, for each AL round, AccuACL has a\nspace complexity of $O((m + n)dK)$, where m is the memory buffer size, n is the data pool size, d is\nthe embedding dimensionality, and K is the total number of classes, which is significantly less than\nthe space complexity of $O((m + n)d^2K^2)$ required for the query strategy of BAIT (Ash et al., 2021).\nTime Complexity. For each AL round, AccuACL has a runtime complexity of $O(n\\log n +$\n$dK \\log dK)$, where $n\\log n$ is induced by selecting the examples with the highest score, and\n$dK \\log dK$ is induced by selecting the dimensions with the highest Fisher information for measuring\n$D(\\cdot)$. On the other hand, BAIT (Ash et al., 2021) has a time complexity of $O(bndK + n(dK)^2)$,\nwhere b is the labeling budget, which is very expensive compared to AccuACL."}, {"title": "5 EXPERIMENT", "content": ""}, {"title": "5.1 EXPERIMENT SETTING", "content": "Algorithms. We compare AccuACL with six AL algorithms in combination with four rehearsal-based\nCL methods. The implementation details can be found in Appendix G."}]}