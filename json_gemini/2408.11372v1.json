{"title": "Denoising Pre-Training and Customized Prompt Learning for Efficient Multi-Behavior Sequential Recommendation", "authors": ["Hao Wang", "Yongqiang Han", "Kefan Wang", "Kai Cheng", "Zhen Wang", "Wei Guo", "Yong Liu", "Defu Lian", "Enhong Chen"], "abstract": "In the realm of recommendation systems, users exhibit a diverse array of behaviors when interacting with items. This phenomenon has spurred research into learning the implicit semantic relationships between these behaviors to enhance recommendation performance. However, these methods often entail high computational complexity. To address concerns regarding efficiency, pre-training presents a viable solution. Its objective is to extract knowledge from extensive pre-training data and fine-tune the model for downstream tasks. Nevertheless, previous pre-training methods have primarily focused on single-behavior data, while multi-behavior data contains significant noise. Additionally, the fully fine-tuning strategy adopted by these methods still imposes a considerable computational burden. In response to this challenge, we propose DPCPL, the first pre-training and prompt-tuning paradigm tailored for Multi-Behavior Sequential Recommendation. Specifically, in the pre-training stage, we commence by proposing a novel Efficient Behavior Miner (EBM) to filter out the noise at multiple time scales, thereby facilitating the comprehension of the contextual semantics of multi-behavior sequences. Subsequently, we propose to tune the pre-trained model in a highly efficient manner with the proposed Customized Prompt Learning (CPL) module, which generates personalized, progressive, and diverse prompts to fully exploit the potential of the pre-trained model effectively. Extensive experiments on three real-world datasets have unequivocally demonstrated that DPCPL not only exhibits high efficiency and effectiveness, requiring minimal parameter adjustments but also surpasses the state-of-the-art performance across a diverse range of downstream tasks.", "sections": [{"title": "INTRODUCTION", "content": "WITH the rapid evolution of the Internet, recommendation systems have proliferated across online platforms. Among these systems, sequential recommendation (SR) has garnered considerable attention from both academic researchers and industry practitioners. SR involves predicting the next item for users by analyzing their historical interactions as temporally-ordered sequences. This approach has been extensively explored in various studies such as [1], [2], [3], [4], [5], [6], [7], [8], [9], [10].\nIn reality, users exhibit a diverse range of behaviors when interacting with items, reflecting their multifaceted preferences. For instance, on e-commerce platforms, users may engage with items through various behaviors like clicking, tagging as favorites, adding to carts, and making purchases. These diverse behaviors encapsulate users' preferences across multiple dimensions and have been leveraged as supplementary knowledge to enhance recommendation accuracy for the target behavior. This approach has been investigated in studies such as [11], [12], [13], [14].\nDespite the considerable achievements made in recent years, the deployment of these advanced methods is severely constrained by online latency due to their high computational complexity. This limitation forces a compromise on the model input length, leading to suboptimal results. To address this issue, several pre-training methods have been proposed, including PeterRec [15], UPRec [16], and PinnerFormer [17]. These methods leverage large architectures, such as transformers, to learn common knowledge from extensive historical datasets through self-supervised tasks. After pre-training, the model is fine-tuned for different downstream tasks using recent user behavior data, as discussed in studies such as [17], [18], [19]. This approach allows models to effectively utilize vast amounts of historical data while maintaining efficiency and improving performance on specific tasks.\nWith the advent of the pre-training paradigm, the issue of deployment complexity has been alleviated to some extent. This paradigm has enabled models to handle extensive historical data more efficiently, thus improving performance across various downstream tasks. However, despite achieving significant success, as illustrated in Figure 1, these methods still overlook certain problems that need to be addressed, such as noise in historical behaviors and the tuning efficiency and effectiveness in recommendation scenarios.\nNoise in historical behaviors. In multi-behavior sequential recommendation scenarios, the data usually covers a variety of user behaviors such as clicking, browsing, and purchasing, which are interspersed with a large amount of noise information, especially the clicking behavior. These noises can negatively affect the pre-trained model, making it difficult to accurately capture the user's behavioral patterns, or even overfitting to the noisy information, which ultimately results in unsatisfactory downstream performance. Towards this problem, some pre-training methods [20], [21] proposed to enhance the robustness of the model by contrastive learning with different data augmentation strategies. However, these methods will introduce extra noise during the random data augmentation process, and potential misalignment between the self-supervised task and the recommendation task further hinders their application in the high-noise scenarios.\nTuning Efficiency and Effectiveness In recommendation scenarios. Although promising results are achieved in downstream tasks, the comprehensive fine-tuning strategy adopted by previous methods usually requires more time and computational resources. In addition, pre-trained models can learn rich user item representations on large-scale data, but full fine-tuning may cause the catastrophic forgetting issue [22], [23], i.e., some common knowledge acquired from pre-training is forgotten. Therefore, instead of full fine-tuning, we propose to adopt the prompt-tuning technique [24] to utilize the pre-trained model, which is proven to be efficient and effective. However, it is non-trivial to adapt prompt-tuning to the multi-behavior sequential recommendation scenario. Unlike NLP, the tokens of the pre-trained recommendation model lack semantic information, making it challenging to manually design hard prompts. Besides, general prompts fail to fulfill the personalization requirement in recommendation systems.\nTo tackle the two aforementioned challenges, we propose a novel Denoising Pre-training and Customized Prompt Learning paradigm (DPCPL) for the efficient multi-behavior sequential recommendation. Firstly, to alleviate the noise problem in user behavior history, we innovatively propose an Efficient Behavior Miner (EBM) in the pre-training stage, which can decompose the user behavior at different time scales through Fast Fourier Transform [25]. In addition, we adopt learning filter kernel and techniques such as frequency-aware fusion and chunked diagonal mechanism to reduce noise at different scales and minimize the number of parameters in the model. Secondly, for efficient tuning of pre-trained models in multi-behavioral scenarios, we point out the necessity of personalization for prompts in recommendation systems and introduce a new concept, Customized Prompt Learning (CPL), which dynamically sets up the prompts based on a variety of user-specific auxiliary information. Furthermore, we find the pre-training model adopts a bottom-up process to gradually condense user interests from user behaviors, for this reason, we propose the Prompt Factor Gate (PFG) structure to leverage users' personalized information to generate layer-wise prompts, enabling an in-depth impact on the model's learning process. Besides, to avoid homogeneity of prompts, we introduce a compactness regular loss function to better control the diversity of prompts. The contributions of this paper can be summarized as follows:\n(1). We present a comprehensive study on the challenges of pre-training and prompt-tuning in multi-behavior sequential recommendation scenarios. Our study highlights the crucial importance of denoising historical behaviors and implementing personalized prompt learning to enhance the accuracy and efficiency of recommendations.\n(2). We propose an efficient denoising module capable of effectively denoising information across multiple scales of behavior sequences with frequency domain mapping during the pre-training stage.\n(3). We introduce the concept of customized prompt learning, aimed at generating personalized, progressive, and diverse prompts to fully utilize the potential of pre-trained models in multiple behaviors.\n(4). We conducted extensive experiments on three real-world datasets and have demonstrated the effectiveness and efficiency of DPCPL, which consistently achieves superior performance across various downstream tasks with minimal parameter tuning."}, {"title": "2 RELATED WORK", "content": "2.1 Multi-behavior Sequential Recommendation\nRecommendation system recommends personalized content based on individual preferences, sequential recommendation predicts a user's next target item based on their historical behavior, playing a crucial role in enhancing the user experience on online platforms [26], [27], [28], [29], [30], [31]. With the emergence of deep learning, sequential recommendation models such as BERT4Rec [32], DIN [33], SASRec [34], and FEARec [35] were introduced for recommendation tasks. However, they failed to consider the diversity of user interactions in real-world scenarios, such as clicking, liking, and purchasing in e-commerce, which provided valuable insights into user intent. To overcome this limitation, researchers have proposed various methods for handling multi-behavior data.\nPrevious research has explored the use of multi-task frameworks to optimize recommendation systems. One approach is to model the cascade relationship among different user behaviors, as done in NMTR [36]. Another approach is to assign user behaviors to distinct tasks and employ hierarchical attention mechanisms to improve recommendation efficiency, as in DIPN [37]. Other studies have focused on enhancing recommendation by fusing multi-behavior data and using other behaviors as auxiliary signals. This has been achieved through attention mechanisms [38], graph neural networks [39], [40], [41], or other related approaches. For example, MATN [42] used a transformer and gated network to capture behavior relationships, while CML [43] introduced a multi-behavior contrastive learning framework to enhance behavior representations. KMCLR [14] utilized comparative learning tasks and functional modules to improve recommendation performance through the integration of multiple user behavior signals.\nAlthough the fusion of multi-behavior information can further effectively explore user behavior patterns and multi-dimensional user interests, some behavior data will inevitably introduce noise to the modeling of user interests. This noise poses challenges to the judgment of user sequence interests. Moreover, with the diversification of behavior data, user behavior sequences become increasingly lengthy in a short period, which presents challenges to the efficiency of the sequence recommendation model.\n2.2 Pre-trained Recommendation Methods\nNonetheless, existing multi-behavior recommendation methods face significant challenges. Firstly, in-depth exploration of user interests often leads to increased model complexity, which compromises operational efficiency in real-world applications. Secondly, the proliferation of behaviors extends the sequences of user interaction history, complicating effective modeling. A practical solution to these problems is to use pre-trained models, which can avoid heavy computational demands during actual deployment.\nTherefore, some pre-training methods have been proposed to address computational complexity problem [44], [45], [46], which employ large architectures such as transformers to learn common knowledge from large historical data sets through self-supervised tasks, and then fine-tune the model for different downstream tasks to alleviate the issue of deployment complexity. To exemplify, S\u00b3-Rec [20] employs pre-training to bolster data augmentation, with a focus on deciphering correlations across attributes, items, subsequences, and sequences through the lens of mutual information maximization principles. PeterRec [15] starts by pre-training a comprehensive model and then integrates specialized sub-models for downstream tasks, allowing for easy task adaptation. UPRec [16] uses user attributes and social graphs in pre-training to enhance personalization, while CL4SRec [21] employs contrastive learning for sequence modeling. PinnerFormer [17] focuses on long-term action prediction with a dense all-action loss.\nHowever, the self-supervised tasks designed by some methods may introduce additional noise during the random data augmentation process. Additionally, the potential misalignment between self-supervised tasks and recommendation tasks further limits their effectiveness in high-noise scenarios. Moreover, these methods often overlook the need for efficient fine-tuning of the pre-trained models to facilitate the effective transfer to downstream tasks.\n2.3 Prompt Learning in Recommendation\nIn contrast to earlier fine-tuning methods, the success of GPT [24] has highlighted the effectiveness of maintaining a well-trained model's integrity while modifying only the input prompt. This has paved the way for the prompt-tuning paradigm [47], which has gained traction in recent years for sequential recommendation tasks. By leveraging fewer parameters and improving efficiency, prompt-tuning enhances model performance."}, {"title": "3 PROBLEM DEFINITION", "content": "In this section, we will first delve into the task formulation of pre-training and fine-tuning for multi-behavioral sequential recommendation. This process involves a two-step approach where we initially pre-train the model on a large dataset to capture general patterns, followed by fine-tuning it on a specific dataset to tailor it to the user's needs. The goal is to provide a more personalized recommendation system that takes into account various behavioral sequences. Following this, we introduce the innovative concept of Customized Prompt Learning. This novel idea aims to leverage the full potential of pre-trained large-scale models by generating prompts dynamically based on individual user characteristics and preferences. By doing so, we can enhance the model's ability to understand and respond to users' unique behaviors, ultimately improving the overall recommendation system's performance.\nIn traditional sequential recommendation systems, Multi-BehaviorIn traditional sequential recommendation systems, Multi-BehaviorRecommendation (MBSR) utilizes various forms of user interaction data with items, such as clicking, adding to cart, and favoriting, to capture more nuanced patterns of user behavior. Typically, in a multitude of behaviors, there is only one designated target behavior, such as purchasing, and the predictive task involves forecasting items under this particular behavior. However, due to limitations in online latency, it is often essential to pre-train a model on historical data and subsequently fine-tune it using more recent data in real-world scenarios. The primary objective of MBSR is to enhance the precision of recommendations while simultaneously minimizing latency by effectively utilizing information about user interactions with items. This problem can be formally defined as follows:\nDEFINITION 1. (Pre-training and Fine-tuning for Multi-Behavior Sequential Recommendation) Given the sets of users U, items V, and types of behavior B, for a user u (u \u2208 U), his/her behavior-aware interaction sequence Su consists of individual triples (v,t,b) which are ordered by time t. Each triple represents the interacted item v under the behavior type b at time t. Then a Pre-training and Fine-tuning paradigm consists of two steps: Firstly, given the previous part of users' behavior-aware interaction sequences Su = [(v\u2081, t\u2081, b\u2081), (v\u2082, t\u2082, b\u2082),..., (v_{pre}, t_{pre}, b_{pre})], where index pre is the truncated sequence length in pre-training, a model is pre-trained with multiple pretext tasks based on the sequences. Subsequently, the pre-trained model is further fine-tuned on the remaining user sequences Su = [(v_{pre+1}, t_{pre+1},b_{pre+1}),..., (v_{|Su|-1},t_{|su|-1},b_{|su|-1})] with a next-item prediction task, which aims to predict the item with the target behavior type at the next time step (V\\Su, Sul, b_{target}).\nHowever, the comprehensive fine-tuning strategy adopted by previous pre-training methods still poses a considerable computational burden, hindering their application in real-world scenarios. So we intend to follow a pre-training & prompt-tuning paradigm to model user preferences for the sake of efficiency, which is yet non-trivial. On the one hand, the token of the pre-trained recommendation model is the ID of items, which lacks specific semantics, making it challenging to manually design hard prompts based on the grammatical experience as in NLP. On the other hand, personalization plays a crucial role in the field of recommendation systems, which means prompts should vary for each user. To this end, we point out that prompt learning in recommendation scenarios requires personalization and introduce a new concept called Customized Prompt Learning, which involves dynamically setting prompts based on various user-specific auxiliary information. Formally, we define it as:\nDEFINITION 2. (Customized Prompt Learning) Given a user u \u2208 U and his/her information including attribute sets Au and behavior-aware interaction Sequence Su, the output is a set of customized prompts {p\u2081, p\u2082, ..., pm}. pm represents the n-th prompt vector for user u. These prompts are generated by fusing user-specific information to tune the pre-trained model without modifying its parameters.\nBased on the above problem definition, we propose the model DPCPL to address the problem of noise impact and computational burden in the previous method."}, {"title": "4 METHODOLOGY", "content": "In this section, we present our model DPCPL, which mainly consists of a denoised pre-trained module and a prompt learning module with personalization, progressivity, and diversity. Our framework is a pioneering model for solving multi-behavior sequential recommendation problems using customized prompt learning. The overall flow of the model is depicted in Figure 3.\n4.1 Behavior-Aware Sequence Embedding\nThe embedding layer of DPCPL integrates item information (v), position information (p), and behavior information (b). For a triad (v, p, b) within a user behavior sequence (S), the embedding is denoted as follows:\n$e = e_v + e_p + e_b, S = [e_1, e_2, ..., e_{L_{seq}}]\\in R^{L_{seq}\\times d}$, (1)\nwhere Lseq represents the sequence length, and d denotes the embedding size. This embedding combines item information, position information, and behavior information to reflect the user's behavioral sequences more comprehensively, which helps to improve the model's understanding of the user's interests and behaviors, and thus improves the accuracy of personalized recommendations.\n4.2 De-noised Pre-trained Model\nPre-trained models have been devoted to addressing the long-sequence overload issue [17]. They often pre-train using long-term historical behavior data and then fine-tune using recent behavior data. However, in multi-behavior recommendation scenarios, the data typically includes a variety of user behaviors such as clicking, browsing, and purchasing. These behaviors are often interspersed with a significant amount of noise, such as random click activity, which greatly impacts the training of pre-trained models and can further degrade their downstream performance.\nTherefore, our research focuses on the need to purify sequences during the pretraining phase. One of the primary challenges in this task is the lack of explicit labels for noise elements, which makes it an unsupervised task. In real-world scenarios, collecting negative feedback from users to identify data noise is extremely difficult. Although previous pre-training methods [20], [21] based on contrastive learning can improve the robustness of models to some extent, they often introduce additional noise during the random data augmentation process. Moreover, the inherent conflict between self-supervised tasks and recommendation tasks further impedes their effectiveness in high-noise environment.\nRecently, some research work has revealed the possibility of frequency-domain denoising in recommendation scenarios with a learnable filter [51]. Through extensive comparative experiments, it has been conclusively demonstrated that different frequency components of user sequences have varying impacts on recommendation effectiveness. Specifically, low-frequency components tend to contain valuable information, while high-frequency components are often data noise, which is an established conclusion. At the same time, multiplication in the frequency domain can replace convolution in the time domain, fully integrating various feature information while denoising.\nInspired by the above findings, we transform the user behavior sequence S into the frequency domain (X) with the help of Fast Fourier Transform (FFT) [25], [52], and then the filtering operation is implemented through dot product operation. Finally, the fully denoised sequence representation S is obtained by inverse transformation. Due to the O(Nlog N) computational complexity of the FFT, this denoising process is executed with remarkable efficiency. The specific formula is as follows:\n$X = F (S) \\in C^{L_{seq}\\times d}, X = W\u00a9X, \\tilde{S} = F^{-1} (X) \\in R^{L_{seq}Xd}$ (2)\nwhere S represents the user behavior sequence, X represents the frequency domain representation of S, S represents the denoised sequence features, W denotes the dot product matrix and C denotes the complex space.\nHowever, this approach encounters two significant challenges. First, the dot product operation fails to effectively integrate information across various frequency bands of the model. In the time domain, this inadequacy manifests as an inability to comprehensively capture the user's interest information across multiple time scales. Second, the number of parameters in the weight matrix W increases with the length of the input sequences. As a result, the model struggles to adapt flexibly to changes in input length, making it difficult to maintain efficiency and performance with varying sequence sizes.\nTo address these challenges, we propose the Efficient Filter Layer (EFL) and make enhancements to two key aspects of the dot-product operation involving the W matrix. First, we replace the dot product with matrix multiplication to achieve better fusion of information across different frequency bands. This improves the model's ability to capture user interest information at multiple time scales. However, this change further increases the number of model parameters. To mitigate this issue, we introduce the Chunked Diagonal Mechanism, which allows model parameters to be shared among different tokens, enabling the model to handle extremely long sequences without a significant increase in parameters. The specific process is as follows:\nFrequency-Aware Fusion. In the EFL, the first improvement involves utilizing matrix multiplication instead of the traditional dot product operation. Specifically, we redefine the weight matrix W to be in $C^{L\\times d\\times d}$ rather than $C^{L\\times d}$. This modification enables the effective fusion of user behavioral information across different frequency bands. By capturing user interests at multiple time scales, both long-term and short-term, the EFL facilitates a more comprehensive and efficient mining of user behavior patterns. However, while this method significantly improves frequency domain fusion, it also further increases the number of model parameters. To address this, we further introduce the Chunked Diagonal Mechanism.\nChunked Diagonal Mechanism. To address the issue of increasing matrix parameters as user sequences grow, the Efficient Filter Layer (EFL) introduces a Chunked Diagonal Mechanism for complex weight matrices. This mechanism is designed to effectively manage parameter growth while maintaining the ability to fully mine sequences and adapt to different sequence lengths. The weight matrix $W \\in C^{L\\times d\\times d}$ is decomposed into k shared weight matrices $W^n \\in C^{d/k\\times d/k}$ (n = 1,..., k), each with reduced dimensions. This decomposition into k smaller diagonal weight matrices, denoted as Wn, is somewhat interpretable, similar to k-head attention, while enabling computational parallelization. So we get $X^n_i = W^n x_i$, where $x_i$ represents the n-th block of the i-th frequency token (i \u2208 [1, L//(d/k)]). Specifically, we employ a double-layer MLP structure as $W_n$. The formula is as follows:\n$\\hat{x_i} = MLP(x_i) = W_o (W_r\\sigma(x_i) + b_r) + b_2$, (3)\nwhere Wr and Wo are the weights, br and b2 are the biases, and \u03c3 denotes an activation function. Importantly, these weights and biases are shared across all tokens, significantly"}, {"title": "4.3 Customized Prompt Tuning", "content": "After pre-training, we aim to utilize prompt tuning techniques to transfer knowledge to downstream tasks efficiently. It is worth mentioning here that compared to very early user behavior, the data we use for fine-tuning is the user's behavior data in the most recent period. However, unlike in NLP contexts [53], [54], [55], [56], the tokens of a pre-trained recommendation model lack semantic information, making it challenging to manually design effective hard prompts. Specifically, in recommendation models, the tokens are item IDs, which do not carry specific semantics. This absence of inherent meaning makes it difficult to create hard prompts based on grammatical rules as done in NLP. Moreover, personalization is crucial in recommendation systems, requiring prompts to be tailored to individual users. Therefore, we propose that prompt learning in recommendation scenarios must be personalized and introduce a new concept called Customized Prompt Learning. This approach involves dynamically setting prompts based on various user-specific auxiliary information.\nTo leverage the pre-trained model effectively, we use soft prompts. Our goal is to ensure these prompts possess three key properties: Personalization, Progressiveness, and Diversity. By doing so, we aim to maximize the pre-trained model's potential and enhance the efficiency and accuracy of downstream tasks in recommendation systems.\n4.3.1 Prompt Personalization\nTo explore the personalized behavioral patterns in the pre-trained model, we propose the concept of Customized Prompt Learning to personalize prompt learning for each user. Specifically, we dynamically customize the prompts based on the user's personalized information, whereas, in MBSR, we can take into account the user's attributes, statistics, and behaviors.\nFirst, as for attributes and statistics, we embed them directly. It is worth mentioning that in MBSR, we found and firstly pointed out that statistics is a crucial feature. For instance, the number of various behaviors of a user can reflect whether the user is in a cold-start group, and the conversion ratio between behaviors (e.g., the proportion of purchases made by adding to a cart) can reflect the user's behavioral habits. Second, in order to model the variability of different behaviors, we model the different sequences of users' behaviors separately to generate prompts through a simple yet efficient gated recurrent network. Formally, for user u, we get prompts about the user's attributes $q_{u,attr}$ through MultiMLP([$a_1||a_2||\u00b7\u00b7\u00b7||a_n$]), and with the same token we can get prompts about the user's statistics $q_{u,statis}$, where the || symbol represents vector concatenation. In addition, we represent the user's behavioral prompt information $q_{u,b}$ by the hidden state of the last layer of the Gated Recurrent Unit (GRU) at the final time step.\n4.3.2 Prompt Progressiveness\nBeyond personalization, we aim to further exploit the potential of pre-trained models by designing elaborate prompt strategies. To achieve this, we find that the pre-trained model uses a bottom-up learning process, where user interests are learned through a step-by-step hierarchical condensation process of user behaviors. Considering this, we develop an innovative progressive prompt strategy. Specifically, our progressive prompt approach incorporates prompts not only at the input side of the model but also at each layer of the model. This approach enables prompts to steer and enhance the model's comprehension of user preferences as it advances through each layer, enabling more efficient fine-tuning of pre-trained models and improving performance on downstream tasks such as cold-start.\nFurther, we considered that the various layers of the model require distinct prompt factors, which are obtained from the user's personalized information. Extracting the appropriate prompt factors for each layer from the complex user information poses a significant challenge. To this end, we propose a Prompt Factorized Gate Network (PFG) structure for refining the prompt factors from the prompt information and then generating the prompts for each layer of the pre-trained model.\nSpecifically, following the personalized prompt generator, we acquire various aspects of prompt information referred to as Qu for user u. Initially, we consolidate this prompt information into a prompt factor matrix of size L \u00d7 N, where L is the number of network layers and N is the number of prompt factors in each layer through PFG. The specific formula used is as follows:\n$Qu = [q_{u,attr}||q_{u,statis}||...||q_{u,b}]$, (5)\n$\\tilde{A_n} = softmax (W_{i,n}Q_u), E_{u,n} = A_{u,n}Q_u$, (6)\nwhere the || symbol represents vector concatenation.\nIn addition, we believe that some prompts may be shared in different processes of model learning. To this end, we use the same method to generate a set of shared prompt factors En. Therefore, for each layer of the model, we employ the shared and layer-specific factors as input to generate the corresponding layer's prompt through the Prompt Factorized Gate Network structure. The specific formula is as follows:\n$\\Phi_u = [E_{1,1}||E_{1,2}, ..., E_{1, N} ||E_{1,1}||E_{1, 2}, ..., E_{2, N}]$, (7)\n$\\tilde{B_y} = softmax (W_1\\Phi_u), P_{l,c}= \\frac{2N}{\\sum B_{s,N}}$, (8)\n$P^u_{l,c} = W_{i,c} \\tilde{B_y} $, (9)\nFinally, we obtain the prompt pu for user u employed within layer l of the pre-trained model and place the prompt in the first C tokens which are analyzed in the hyperparameter experiment.\n4.3.3 Prompt Diversity\nHowever, the prompts of different layers in Eq. (6) tend to be easily assimilated, because the information sources generating the prompts are consistent. Although we designed the PFG to fully decouple and fuse the prompt information, it is still challenging to guarantee the process of prompt generation is controllable. To further ensure the diversity of prompts, we introduce a regularization loss based on representation compactness [57].\nCompactness is a desired trait of intra-factor representations and its opposite is what we expect for inter-factor representations. ReduNet [58] proposed to measure compactness of representation with rate-distortion R(z, e), which determines the minimal number of bits to encode a random variable z subject to a decoding error upper bounded by \u0454. Inspired by this, we design a compactness regularization loss function to control the diversity of the prompt vector space. Ideally, diversity should be maintained between prompt factors, and between prompts across layers for each user. The specific formula is as follows:\n$R(E, \\epsilon) = \\frac{1}{2} log det (I+ \\frac{1}{Nd \\epsilon^2} EET)$, (10)\n$R(P, \\epsilon) = \\frac{1}{2} log det (I+ \\frac{1}{Ld \\epsilon^2} PPT)$, (11)\nwhere E\u2208 RIN\u00d7(L+1)|\u00d7d is the prompt factors matrix, P\u2208 R|L|\u00d7d is the prompt matrix, and the rest are hyperparameters. logdet(\u00b7) means the logarithm of the determinant of a matrix and I is the identity matrix. Finally, we can obtain our compactness regularization loss as follows:\n$L_{compactness} = \\sum_{u\\epsilon U} [\\lambda_eR(E_i, \\epsilon_e) + \\lambda_pR(P_i, \\epsilon_p)]$. (12)\nThrough the compactness regularization loss, we ensure diversity in prompt factors and the final prompt vector across different layers. This guarantees that prompts from the same personalized information at different layers meet the criteria of progression. This is because it reinforces the understanding that prompts at different layers are distinct, aligning with the assumption of continuous refinement of interests across the model's layers. Consequently, the total loss of the prompt-tuning stage can be derived as follows:\n$L_{total} = L_{pred} + \\lambda L_{compactness}$, (13)\nwhere \u03bb is a hyperparameter used to control the strength of compactness regularization, and Lpred is similar to Lpt in Eq. (4) but only predicts item under a given target behavior.\nBy employing the three properties of prompts-Personalization, Progressiveness, and Diversity, we can obtain a fine-tuned model capable of handling downstream tasks effectively. Due to this paradigm, we can efficiently model long sequences of users' historical behaviors and benefit from a wide range of users' behaviors without significantly increasing the complexity of the model. Subsequent experiments also proved that the effect of fine-tuning is equal to or even exceeds the effect of full-scale fine-tuning of the model."}, {"title": "5 EXPERIMENT", "content": "5.1 Experimental Setting\n5.1.1 Datasets\nTo comprehensively investigate the performance of DPCPL, we conduct experiments on three large-scale real-world recommendation datasets, which are widely utilized in multi-behavior sequential recommendation research and are considered standard benchmarks [40], [59]. These user behavior datasets contain various interactions: click, add-to-cart, add-to-favorite, and purchase.\nCIKM\u00b9. The CIKM dataset is an E-commerce recommendation dataset that was released by Alibaba. It is specifically designed to aid in the development and evaluation of recommendation algorithms within the E-commerce domain.\nIJCAI\u00b2. This dataset is released by IJCAI Contest 2015 for the task of repeat buyers prediction. This dataset provides extensive data on user purchasing behavior, which can be leveraged to develop and test algorithms aimed at identifying customers who are likely to make repeat purchases.\nTaobao\u00b3. This dataset is collected from Taobao, which is one of the largest e-commerce platforms in China. This dataset offers a wealth of information on user interactions and transactions on the platform, making it an excellent resource for developing and testing various E-commerce applications, such as recommendation systems, user behavior analysis, and sales forecasting.\nIn data processing, the experiment aims to maintain the original dataset's distribution to reflect real-world characteristics accurately. We filter out user and item data with fewer than 20 interactions. The first 60% of the data, based on timestamps, is designated as pre-training data, while the remaining 40% is used for fine-tuning and validation tests. For non-pre-trained models, no pre-training data is utilized in the experiments. This is because recommendation algorithms that often input sequence lengths that are limited, and generally only input the user's most recent behavior. The pre-training fine-tuning paradigm can mitigate this issue to some extent. It allows for pre-training with ultra-long historical behaviors and fine-tuning using the most recent behavioral data. Detailed statistical information about these datasets is summarized in Table 2.\n5.1.2 Comparison Baselines\nWe compare DPCPL with various state-of-the-art baseline methods, including general sequential recommendation, multi-behavior sequential recommendation, and pre-training fine-tuning approaches.\nGeneral Sequential Recommendation Methods. In this context, the sequential recommendation algorithm inputs only the items with which the user interacts, without considering the type of behavior.\nGRU4Rec [60]. It utilizes the gated recurrent unit as sequence encoder to learn dynamic preference.\nSASRec [34]. In SASRec, self-attention is employed to encode the sequential patterns of user interaction, without the recurrent operations over input sequences.\nBERT4Rec [32]. It uses a bidirectional encoder for modeling sequential information with transformer, which is optimized with the Cloze objective and has produced state-of-the-art performance among many baselines.\nFEARec [35]. It improves the original time domain self-attention in the frequency domain with a ramp structure, allowing for the explicit learning of both low-frequency and high-frequency information.\nMulti-Behavior Recommendation Methods. In the multi-behavior recommendation algorithm, we take into account the relationships between different behavior types.\n5.1.3 Implementation Details\nTo ensure fair comparisons, we maintain consistent settings across all methods. The embedding size is set to 256, and all methods incorporate the embedding of user attribute information. During the experimentation process, we perform a grid search to identify the optimal hyperparameters. The maximum number of epochs is set to 1000, and training is halted if the NDCG@K_summation on the validation dataset does not improve for 20 consecutive epochs. For our proposed method, the ratio of the compactness loss \u03bb is tuned among {1\u00d710\u22123,1\u00d710\u22122, 1\u00d710-1}, and the value of \u03b1 is tuned among {0.5,1,5}. As for the baselines, we tune their hyperparameters according to the guidelines provided in their original papers and initialize these parameters using Xavier Initialization [64]. By adhering to these consistent settings and carefully tuning the hyperparameters, we aim to ensure that our comparisons are both rigorous and fair, providing reliable insights into the performance of the proposed method relative to established baselines.\n5.1.4 Evaluation Metrics\nIn this study, we assess the performance of comparison methods for the top-K recommendation using two evaluation metrics: Hit Ratio (HR@K) and Normalized Discounted Cumulative Gain (NDCG@K). HR@K measures the average proportion of relevant items in the top-K recommended lists, while NDCG@K evaluates the ranking quality of the top-K lists in a position-wise manner. For fair and efficient"}, {"title": "5.2 Overall Performances", "content": "In Table 3", "follows": "n(1). We observe that more advanced multi-behavioral approaches tend to achieve more promising results. This demonstrates the effectiveness of incorporating multiple types of behavioral data into sequential modeling. By leveraging richer user multi-behavior information, these models can better understand and predict user preferences.\n(2). Compared to end-to-end approaches, pre-trained models consistently outperform, highlighting the potential of the pre-training paradigm to enhance downstream task performance. Pre-training empowers models to learn from extensive datasets, capturing intricate patterns that can be fine-tuned for specific tasks, resulting in superior performance. Moreover, as the number of parameters in a pre-trained model increases, its memory capacity expands, facilitating the absorption of larger historical datasets and mitigating concerns related to excessively lengthy sequences.\n(3). We find that models incorporating denoising techniques during pre-training outperform other methods. This suggests that historical user behavioral noise significantly impacts model performance and needs to be addressed. By removing noise from historical data, these models can learn more accurate representations of user behaviors.\n(4). Our proposed DPCPL consistently"}]}