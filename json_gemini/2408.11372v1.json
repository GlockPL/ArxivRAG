{"title": "Denoising Pre-Training and Customized Prompt Learning for Efficient Multi-Behavior Sequential Recommendation", "authors": ["Hao Wang", "Yongqiang Han", "Kefan Wang", "Kai Cheng", "Zhen Wang", "Wei Guo", "Yong Liu", "Defu Lian", "Enhong Chen"], "abstract": "In the realm of recommendation systems, users exhibit a diverse array of behaviors when interacting with items. This phenomenon has spurred research into learning the implicit semantic relationships between these behaviors to enhance recommendation performance. However, these methods often entail high computational complexity. To address concerns regarding efficiency, pre-training presents a viable solution. Its objective is to extract knowledge from extensive pre-training data and fine-tune the model for downstream tasks. Nevertheless, previous pre-training methods have primarily focused on single-behavior data, while multi-behavior data contains significant noise. Additionally, the fully fine-tuning strategy adopted by these methods still imposes a considerable computational burden. In response to this challenge, we propose DPCPL, the first pre-training and prompt-tuning paradigm tailored for Multi-Behavior Sequential Recommendation. Specifically, in the pre-training stage, we commence by proposing a novel Efficient Behavior Miner (EBM) to filter out the noise at multiple time scales, thereby facilitating the comprehension of the contextual semantics of multi-behavior sequences. Subsequently, we propose to tune the pre-trained model in a highly efficient manner with the proposed Customized Prompt Learning (CPL) module, which generates personalized, progressive, and diverse prompts to fully exploit the potential of the pre-trained model effectively. Extensive experiments on three real-world datasets have unequivocally demonstrated that DPCPL not only exhibits high efficiency and effectiveness, requiring minimal parameter adjustments but also surpasses the state-of-the-art performance across a diverse range of downstream tasks.", "sections": [{"title": "INTRODUCTION", "content": "WITH the rapid evolution of the Internet, recommendation systems have proliferated across online platforms. Among these systems, sequential recommendation (SR) has garnered considerable attention from both academic researchers and industry practitioners. SR involves predicting the next item for users by analyzing their historical interactions as temporally-ordered sequences. This approach has been extensively explored in various studies such as [1], [2], [3], [4], [5], [6], [7], [8], [9], [10].\nIn reality, users exhibit a diverse range of behaviors when interacting with items, reflecting their multifaceted preferences. For instance, on e-commerce platforms, users may engage with items through various behaviors like clicking, tagging as favorites, adding to carts, and making purchases. These diverse behaviors encapsulate users' preferences across multiple dimensions and have been leveraged as supplementary knowledge to enhance recommendation accuracy for the target behavior. This approach has been investigated in studies such as [11], [12], [13], [14].\nDespite the considerable achievements made in recent years, the deployment of these advanced methods is severely constrained by online latency due to their high computational complexity. This limitation forces a compromise on the model input length, leading to suboptimal results. To address this issue, several pre-training methods have been proposed, including PeterRec [15], UPRec [16], and PinnerFormer [17]. These methods leverage large architectures, such as transformers, to learn common knowledge from extensive historical datasets through self-supervised tasks. After pre-training, the model is fine-tuned for different downstream tasks using recent user behavior data, as discussed in studies such as [17], [18], [19]. This approach allows models to effectively utilize vast amounts of historical data while maintaining efficiency and improving performance on specific tasks.\nWith the advent of the pre-training paradigm, the issue"}, {"title": "RELATED WORK", "content": "2.1 Multi-behavior Sequential Recommendation\nRecommendation system recommends personalized content based on individual preferences, sequential recommenda- tion predicts a user's next target item based on their his- torical behavior, playing a crucial role in enhancing the user experience on online platforms [26], [27], [28], [29], [30], [31]. With the emergence of deep learning, sequen- tial recommendation models such as BERT4Rec [32], DIN [33], SASRec [34], and FEARec [35] were introduced for recommendation tasks. However, they failed to consider the diversity of user interactions in real-world scenarios, such as clicking, liking, and purchasing in e-commerce, which provided valuable insights into user intent. To overcome this limitation, researchers have proposed various methods for handling multi-behavior data.\nPrevious research has explored the use of multi-task frameworks to optimize recommendation systems. One ap- proach is to model the cascade relationship among different user behaviors, as done in NMTR [36]. Another approach is to assign user behaviors to distinct tasks and employ hier- archical attention mechanisms to improve recommendation efficiency, as in DIPN [37]. Other studies have focused on enhancing recommendation by fusing multi-behavior data and using other behaviors as auxiliary signals. This has been achieved through attention mechanisms [38], graph neural networks [39], [40], [41], or other related approaches. For ex- ample, MATN [42] used a transformer and gated network to capture behavior relationships, while CML [43] introduced a multi-behavior contrastive learning framework to enhance behavior representations. KMCLR [14] utilized comparative learning tasks and functional modules to improve recom- mendation performance through the integration of multiple user behavior signals.\nAlthough the fusion of multi-behavior information can further effectively explore user behavior patterns and multi- dimensional user interests, some behavior data will in- evitably introduce noise to the modeling of user interests. This noise poses challenges to the judgment of user se- quence interests. Moreover, with the diversification of be- havior data, user behavior sequences become increasingly lengthy in a short period, which presents challenges to the efficiency of the sequence recommendation model."}, {"title": "Pre-trained Recommendation Methods", "content": "Nonetheless, existing multi-behavior recommendation methods face significant challenges. Firstly, in-depth explo- ration of user interests often leads to increased model com- plexity, which compromises operational efficiency in real- world applications. Secondly, the proliferation of behaviors extends the sequences of user interaction history, complicat- ing effective modeling. A practical solution to these prob- lems is to use pre-trained models, which can avoid heavy computational demands during actual deployment.\nTherefore, some pre-training methods have been pro- posed to address computational complexity problem [44], [45], [46], which employ large architectures such as trans- formers to learn common knowledge from large historical data sets through self-supervised tasks, and then fine-tune the model for different downstream tasks to alleviate the issue of deployment complexity. To exemplify, S\u00b3-Rec [20] employs pre-training to bolster data augmentation, with a focus on deciphering correlations across attributes, items, subsequences, and sequences through the lens of mutual information maximization principles. PeterRec [15] starts by pre-training a comprehensive model and then integrates specialized sub-models for downstream tasks, allowing for easy task adaptation. UPRec [16] uses user attributes and social graphs in pre-training to enhance personalization, while CL4SRec [21] employs contrastive learning for sequence modeling. PinnerFormer [17] focuses on long-term action prediction with a dense all-action loss.\nHowever, the self-supervised tasks designed by some methods may introduce additional noise during the random data augmentation process. Additionally, the potential mis- alignment between self-supervised tasks and recommenda- tion tasks further limits their effectiveness in high-noise sce- narios. Moreover, these methods often overlook the need for efficient fine-tuning of the pre-trained models to facilitate the effective transfer to downstream tasks."}, {"title": "Prompt Learning in Recommendation", "content": "In contrast to earlier fine-tuning methods, the success of GPT [24] has highlighted the effectiveness of maintaining a well-trained model's integrity while modifying only the input prompt. This has paved the way for the prompt- tuning paradigm [47], which has gained traction in recent years for sequential recommendation tasks. By leveraging fewer parameters and improving efficiency, prompt-tuning enhances model performance.\nSeveral notable works have applied this paradigm. PPR [48] pre-trains recommendation models and employs sequence prompts to boost performance. UP5 [49] integrates fairness-aware prompt templates to promote recommenda- tion equity. PLCR [18] incorporates domain knowledge into pre-trained models and fine-tunes them with prompts for more effective cross-domain recommendations. DPT [50] utilizes a three-stage denoising and prompt fine-tuning ap- proach to mitigate noise impacts. CPTPP [19] combines user information with graph-based contrastive learning to align pre-trained user vectors with downstream tasks.\nDespite these advancements, these methods often fall short in personalized modeling under complex behavioral scenarios, leading to suboptimal performance in multi- behavior tasks. The lack of nuanced personalization and adaptation to individual user behaviors remains a signifi- cant challenge, suggesting the need for further refinement and innovation in this area."}, {"title": "PROBLEM DEFINITION", "content": "In this section, we will first delve into the task formulation of pre-training and fine-tuning for multi-behavioral sequential recommendation. This process involves a two-step approach where we initially pre-train the model on a large dataset to capture general patterns, followed by fine-tuning it on a specific dataset to tailor it to the user's needs. The goal is to provide a more personalized recommendation system that takes into account various behavioral sequences. Following this, we introduce the innovative concept of Customized Prompt Learning. This novel idea aims to leverage the full potential of pre-trained large-scale models by generating prompts dynamically based on individual user character- istics and preferences. By doing so, we can enhance the model's ability to understand and respond to users' unique behaviors, ultimately improving the overall recommenda- tion system's performance.\nIn traditional sequential recommendation systems, Multi-BehaviorIn traditional sequential recommendation systems, Multi-BehaviorRecommendation (MBSR) utilizes various forms of user interaction data with items, such as clicking, adding to cart, and favoriting, to capture more nuanced patterns of user behavior. Typically, in a multitude of behaviors, there is only one designated target behav- ior, such as purchasing, and the predictive task involves forecasting items under this particular behavior. However, due to limitations in online latency, it is often essential to pre-train a model on historical data and subsequently fine- tune it using more recent data in real-world scenarios. The"}, {"title": "Behavior-Aware Sequence Embedding", "content": "The embedding layer of DPCPL integrates item information (v), position information (p), and behavior information (b). For a triad (v, p, b) within a user behavior sequence (S), the embedding is denoted as follows:\n$e = e_v + e_p + e_b, S = [e_1, e_2, ..., e_{L_{seq}}] \\in \\mathbb{R}^{L_{seq} \\times d},$ (1)\nwhere $L_{seq}$ represents the sequence length, and $d$ denotes the embedding size. This embedding combines item infor- mation, position information, and behavior information to reflect the user's behavioral sequences more comprehen- sively, which helps to improve the model's understanding of the user's interests and behaviors, and thus improves the accuracy of personalized recommendations."}, {"title": "De-noised Pre-trained Model", "content": "Pre-trained models have been devoted to addressing the long-sequence overload issue [17]. They often pre-train us- ing long-term historical behavior data and then fine-tune using recent behavior data. However, in multi-behavior recommendation scenarios, the data typically includes a variety of user behaviors such as clicking, browsing, and purchasing. These behaviors are often interspersed with a significant amount of noise, such as random click activity, which greatly impacts the training of pre-trained models and can further degrade their downstream performance.\nTherefore, our research focuses on the need to purify sequences during the pretraining phase. One of the primary challenges in this task is the lack of explicit labels for noise elements, which makes it an unsupervised task. In real- world scenarios, collecting negative feedback from users to identify data noise is extremely difficult. Although previous pre-training methods [20], [21] based on contrastive learning can improve the robustness of models to some extent, they often introduce additional noise during the random data augmentation process. Moreover, the inherent conflict be- tween self-supervised tasks and recommendation tasks fur- ther impedes their effectiveness in high-noise environment.\nRecently, some research work has revealed the possibil- ity of frequency-domain denoising in recommendation sce- narios with a learnable filter [51]. Through extensive com- parative experiments, it has been conclusively demonstrated that different frequency components of user sequences have varying impacts on recommendation effectiveness. Specif- ically, low-frequency components tend to contain valuable information, while high-frequency components are often data noise, which is an established conclusion. At the same time, multiplication in the frequency domain can replace convolution in the time domain, fully integrating various feature information while denoising.\nInspired by the above findings, we transform the user behavior sequence $S$ into the frequency domain $(X)$ with the help of Fast Fourier Transform (FFT) [25], [52], and then the filtering operation is implemented through dot product operation. Finally, the fully denoised sequence rep- resentation $\\tilde{S}$ is obtained by inverse transformation. Due to the $O(N \\log N)$ computational complexity of the FFT, this denoising process is executed with remarkable efficiency. The specific formula is as follows:"}, {"title": null, "content": "$X = F(S) \\in \\mathbb{C}^{L_{seq} \\times d}, \\tilde{X} = W \\odot X, \\tilde{S} = F^{-1} (\\tilde{X}) \\in \\mathbb{R}^{L_{seq} \\times d},$ (2)\nwhere $S$ represents the user behavior sequence, $X$ repre- sents the frequency domain representation of $S$, $\\tilde{S}$ repre- sents the denoised sequence features, $W$ denotes the dot product matrix and $C$ denotes the complex space.\nHowever, this approach encounters two significant chal- lenges. First, the dot product operation fails to effectively integrate information across various frequency bands of the model. In the time domain, this inadequacy manifests as an inability to comprehensively capture the user's in- terest information across multiple time scales. Second, the number of parameters in the weight matrix $W$ increases with the length of the input sequences. As a result, the model struggles to adapt flexibly to changes in input length, making it difficult to maintain efficiency and performance with varying sequence sizes.\nTo address these challenges, we propose the Efficient Filter Layer (EFL) and make enhancements to two key aspects of the dot-product operation involving the $W$ ma- trix. First, we replace the dot product with matrix mul- tiplication to achieve better fusion of information across different frequency bands. This improves the model's ability to capture user interest information at multiple time scales. However, this change further increases the number of model parameters. To mitigate this issue, we introduce the Chun- ked Diagonal Mechanism, which allows model parameters to be shared among different tokens, enabling the model to handle extremely long sequences without a significant increase in parameters. The specific process is as follows:\nFrequency-Aware Fusion. In the EFL, the first improve-"}, {"title": null, "content": "ment involves utilizing matrix multiplication instead of the traditional dot product operation. Specifically, we redefine the weight matrix $W$ to be in $\\mathbb{C}^{L \\times d \\times d}$ rather than $\\mathbb{C}^{L \\times d}$. This modification enables the effective fusion of user behavioral information across different frequency bands. By capturing user interests at multiple time scales, both long-term and short-term, the EFL facilitates a more comprehensive and efficient mining of user behavior patterns. However, while this method significantly improves frequency domain fu- sion, it also further increases the number of model param- eters. To address this, we further introduce the Chunked Diagonal Mechanism.\nChunked Diagonal Mechanism. To address the issue of increasing matrix parameters as user sequences grow, the Efficient Filter Layer (EFL) introduces a Chunked Diago- nal Mechanism for complex weight matrices. This mecha- nism is designed to effectively manage parameter growth while maintaining the ability to fully mine sequences and adapt to different sequence lengths. The weight matrix $W \\in \\mathbb{C}^{L \\times d \\times d}$ is decomposed into $k$ shared weight ma- trices $W_n \\in \\mathbb{C}^{d/k \\times d/k} (n = 1, ..., k)$, each with reduced dimensions. This decomposition into $k$ smaller diagonal weight matrices, denoted as $W_n$, is somewhat interpretable, similar to $k$-head attention, while enabling computational parallelization. So we get $\\hat{x_i} = W_n x$, where $x$ represents the $n$-th block of the $i$-th frequency token $(i \\in [1, L//(d/k)])$. Specifically, we employ a double-layer MLP structure as $W_n$. The formula is as follows:\n$\\hat{x_i}= MLP(x) = W_o^r (W_r^r x + b_r^r) + b_o^r,$ (3)\nwhere $W_r^r$ and $W_o^r$ are the weights, $b_r^r$ and $b_o^r$ are the biases, and $\\sigma$ denotes an activation function. Importantly, these weights and biases are shared across all tokens, significantly"}, {"title": "Customized Prompt Tuning", "content": "After pre-training, we aim to utilize prompt tuning tech- niques to transfer knowledge to downstream tasks effi- ciently. It is worth mentioning here that compared to very early user behavior, the data we use for fine-tuning is the user's behavior data in the most recent period. However, unlike in NLP contexts [53], [54], [55], [56], the tokens of a pre-trained recommendation model lack semantic infor- mation, making it challenging to manually design effective hard prompts. Specifically, in recommendation models, the tokens are item IDs, which do not carry specific semantics. This absence of inherent meaning makes it difficult to create hard prompts based on grammatical rules as done in NLP. Moreover, personalization is crucial in recommendation sys- tems, requiring prompts to be tailored to individual users. Therefore, we propose that prompt learning in recommen- dation scenarios must be personalized and introduce a new concept called Customized Prompt Learning. This approach involves dynamically setting prompts based on various user-specific auxiliary information.\nTo leverage the pre-trained model effectively, we use soft prompts. Our goal is to ensure these prompts possess three key properties: Personalization, Progressiveness, and Diversity. By doing so, we aim to maximize the pre-trained model's potential and enhance the efficiency and accuracy of downstream tasks in recommendation systems.\n4.3.1 Prompt Personalization\nTo explore the personalized behavioral patterns in the pre- trained model, we propose the concept of Customized Prompt Learning to personalize prompt learning for each user. Specifically, we dynamically customize the prompts based on the user's personalized information, whereas, in MBSR, we can take into account the user's attributes, statis- tics, and behaviors.\nFirst, as for attributes and statistics, we embed them directly. It is worth mentioning that in MBSR, we found and firstly pointed out that statistics is a crucial feature. For in- stance, the number of various behaviors of a user can reflect whether the user is in a cold-start group, and the conversion ratio between behaviors (e.g., the proportion of purchases made by adding to a cart) can reflect the user's behavioral habits. Second, in order to model the variability of differ- ent behaviors, we model the different sequences of users' behaviors separately to generate prompts through a simple yet efficient gated recurrent network. Formally, for user u, we get prompts about the user's attributes $q_{u,attr}$ through MultiMLP([$a_1||a_2||\u00b7\u00b7\u00b7||$]), and with the same token we"}, {"title": "Prompt Progressiveness", "content": "Beyond personalization, we aim to further exploit the po- tential of pre-trained models by designing elaborate prompt strategies. To achieve this, we find that the pre-trained model uses a bottom-up learning process, where user interests are learned through a step-by-step hierarchical condensation process of user behaviors. Considering this, we develop an innovative progressive prompt strategy. Specifically, our progressive prompt approach incorporates prompts not only at the input side of the model but also at each layer of the model. This approach enables prompts to steer and enhance the model's comprehension of user preferences as it advances through each layer, enabling more efficient fine-tuning of pre-trained models and improving performance on downstream tasks such as cold-start.\nFurther, we considered that the various layers of the model require distinct prompt factors, which are obtained from the user's personalized information. Extracting the appropriate prompt factors for each layer from the com- plex user information poses a significant challenge. To this end, we propose a Prompt Factorized Gate Network (PFG) structure for refining the prompt factors from the prompt information and then generating the prompts for each layer of the pre-trained model.\nSpecifically, following the personalized prompt gener- ator, we acquire various aspects of prompt information referred to as $Q_u$ for user u. Initially, we consolidate this prompt information into a prompt factor matrix of size $L \\times N$, where $L$ is the number of network layers and $N$ is the number of prompt factors in each layer through PFG. The specific formula used is as follows:\n$Q_u = [q_{u,attr}||q_{u,statis}||...||q_{u,b}],$ (5)\n$\\Lambda^n = softmax(W_{i,n}Q_u), E_{u,n} = \\Lambda_{u,n}Q_u,$ (6)\nwhere the $||$ symbol represents vector concatenation.\nIn addition, we believe that some prompts may be shared in different processes of model learning. To this end, we use the same method to generate a set of shared prompt factors $E^s$. Therefore, for each layer of the model, we employ the shared and layer-specific factors as input to generate the corresponding layer's prompt through the Prompt Factorized Gate Network structure. The specific formula is as follows:\n$\\Phi_u = [E_{u,1}||E_{u,2}, ..., E_{u,N}^s||E_{u,1}||E_{u,2}, ..., E_{u,N}],$ (7)\n$\\Beta^l_v = softmax(W_l\\Phi_u), p^l_u = \\Sigma_{j=1}^{2N} \\Beta^l E^{\\prime}_{s,N},$ (8)\n$p_{lc} = W_{i,c} \\phi^g,$ (9)\nFinally, we obtain the prompt $p_u^l$ for user u employed within layer l of the pre-trained model and place the prompt in the first C tokens which are analyzed in the hyperparam- eter experiment."}, {"title": "Prompt Diversity", "content": "However, the prompts of different layers in Eq. (6) tend to be easily assimilated, because the information sources gen- erating the prompts are consistent. Although we designed the PFG to fully decouple and fuse the prompt information, it is still challenging to guarantee the process of prompt generation is controllable. To further ensure the diversity of prompts, we introduce a regularization loss based on representation compactness [57].\nCompactness is a desired trait of intra-factor representa- tions and its opposite is what we expect for inter-factor rep- resentations. ReduNet [58] proposed to measure compact- ness of representation with rate-distortion R(z, e), which determines the minimal number of bits to encode a random variable z subject to a decoding error upper bounded by \u0454. Inspired by this, we design a compactness regularization loss function to control the diversity of the prompt vec- tor space. Ideally, diversity should be maintained between prompt factors, and between prompts across layers for each user. The specific formula is as follows:\n$R(E, \\epsilon) = \\frac{1}{2} log det (I+ \\frac{EE^T}{N\\epsilon^2}),$ (10)\n$R(P, \\epsilon) = \\frac{1}{2} log det (I+ \\frac{PPT}{L \\epsilon^2}),$ (11)\nwhere $E \\in \\mathbb{R}^{|N \\times (L+1)| \\times d}$ is the prompt factors matrix, $P \\in \\mathbb{R}^{|L| \\times d}$ is the prompt matrix, and the rest are hyperpa- rameters. $logdet(\\cdot)$ means the logarithm of the determinant of a matrix and $I$ is the identity matrix. Finally, we can obtain our compactness regularization loss as follows:\n$L_{compactness} = \\Sigma_{u \\in U} [\\lambda_e R(E_i, \\epsilon_e) + \\lambda_p R(P_i, \\epsilon_p)].$ (12)\nThrough the compactness regularization loss, we ensure diversity in prompt factors and the final prompt vector across different layers. This guarantees that prompts from the same personalized information at different layers meet the criteria of progression. This is because it reinforces the understanding that prompts at different layers are distinct, aligning with the assumption of continuous refinement of interests across the model's layers. Consequently, the total loss of the prompt-tuning stage can be derived as follows:\n$L_{total} = L_{pred} + \\lambda L_{compactness},$ (13)\nwhere $\\lambda$ is a hyperparameter used to control the strength of compactness regularization, and $L_{pred}$ is similar to $L_{pt}$ in Eq. (4) but only predicts item under a given target behavior.\nBy employing the three properties of prompts-Personalization, Progressiveness, and Diversity, we can obtain a fine-tuned model capable of handling downstream tasks effectively. Due to this paradigm, we can efficiently model long sequences of users' historical behaviors and benefit from a wide range of users' behaviors without significantly increasing the complexity of the model. Subsequent experiments also proved that the effect of fine-tuning is equal to or even exceeds the effect of full-scale fine-tuning of the model."}, {"title": "EXPERIMENTAL SETTING", "content": "5.1.1 Datasets\nTo comprehensively investigate the performance of DPCPL, we conduct experiments on three large-scale real-world rec- ommendation datasets, which are widely utilized in multi- behavior sequential recommendation research and are con- sidered standard benchmarks [40], [59]. These user behavior datasets contain various interactions: click, add-to-cart, add- to-favorite, and purchase.\nCIKM\u00b9. The CIKM dataset is an E-commerce recommen- dation dataset that was released by Alibaba. It is specifically designed to aid in the development and evaluation of rec- ommendation algorithms within the E-commerce domain.\nIJCAI\u00b2. This dataset is released by IJCAI Contest 2015 for the task of repeat buyers prediction. This dataset provides extensive data on user purchasing behavior, which can be leveraged to develop and test algorithms aimed at identify- ing customers who are likely to make repeat purchases.\nTaobao\u00b3. This dataset is collected from Taobao, which is one of the largest e-commerce platforms in China. This dataset offers a wealth of information on user interactions and transactions on the platform, making it an excellent resource for developing and testing various E-commerce ap- plications, such as recommendation systems, user behavior analysis, and sales forecasting.\nIn data processing, the experiment aims to maintain the original dataset's distribution to reflect real-world charac- teristics accurately. We filter out user and item data with fewer than 20 interactions. The first 60% of the data, based on timestamps, is designated as pre-training data, while the remaining 40% is used for fine-tuning and validation tests. For non-pre-trained models, no pre-training data is utilized in the experiments. This is because recommendation algo- rithms that often input sequence lengths that are limited, and generally only input the user's most recent behavior. The pre-training fine-tuning paradigm can mitigate this is- sue to some extent. It allows for pre-training with ultra-long historical behaviors and fine-tuning using the most recent behavioral data. Detailed statistical information about these datasets is summarized in Table 2.\n5.1.2 Comparison Baselines\nWe compare DPCPL with various state-of-the-art base- line methods, including general sequential recommenda- tion, multi-behavior sequential recommendation, and pre- training fine-tuning approaches.\nGeneral Sequential Recommendation Methods. In this context, the sequential recommendation algorithm inputs only the items with which the user interacts, without con- sidering the type of behavior.\nGRU4Rec [60]. It utilizes the gated recurrent unit as sequence encoder to learn dynamic preference.\nSASRec [34]. In SASRec, self-attention is employed to encode the sequential patterns of user interaction, without the recurrent operations over input sequences.\nBERT4Rec [32]. It uses a bidirectional encoder for mod- eling sequential information with transformer, which is optimized with the Cloze objective and has produced state- of-the-art performance among many baselines.\nFEARec [35]. It improves the original time domain self- attention in the frequency domain with a ramp structure, allowing for the explicit learning of both low-frequency and high-frequency information.\nMulti-Behavior Recommendation Methods. In the multi-behavior recommendation algorithm, we take into account the relationships between different behavior types."}, {"title": "Overall Performances", "content": "In Table 3, we present a detailed performance comparison across various datasets. The key observations from this analysis are summarized as follows:\n(1). We observe that more advanced multi-behavioral approaches tend to achieve more promising results. This demonstrates the effectiveness of incorporating multiple types of behavioral data into sequential modeling. By lever- aging richer user multi-behavior information, these models can better understand and predict user preferences.\n(2). Compared to end-to-end approaches, pre-trained models consistently outperform, highlighting the potential of the pre-training paradigm to enhance downstream task performance. Pre-training empowers models to learn from extensive datasets, capturing intricate patterns that can be fine-tuned for specific tasks, resulting in superior perfor- mance. Moreover, as the number of parameters in a pre- trained model increases, its memory capacity expands, facil- itating the absorption of larger historical datasets and miti- gating concerns related to excessively lengthy sequences.\n(3). We find that models incorporating denoising tech- niques during pre-training outperform other methods. This suggests that historical user behavioral noise significantly impacts model performance and needs to be addressed. By removing noise from historical data, these models can learn more accurate representations of user behaviors.\n(4). Our proposed DPCPL consistently outperforms other methods across all datasets. This highlights the effec- tiveness of our customized prompt learning and progressive prompt strategies. By dynamically setting prompts based on user-specific information and progressively refining these prompts, DPCPL can better adapt to individual user behav- iors and improve recommendation accuracy."}, {"title": "Analysis of Efficiency", "content": "To explore the efficiency of customized prompts learning, we compare the time overhead and number of parameters with full parameters fine-tuning. Surprisingly, it even ap- proaches or surpasses the overall fine-tuning effect to some extent. In addition, compared to full fine-tuning, DPCPL requires only a limited number of parameters to be tuned and stored, thus demonstrating parameter efficiency. As indicated in Table 4, the parameter update count in DPCPL amounts to only 1.2%, 1.4%, and 0.8% of that required for full fine-tuning for each dataset. Accordingly, the time required for DPCPL is merely 8.15%, 12.96%, and 7.43% of that needed for full fine-tuning, respectively. It is important to note that since most baselines are based on transformer architectures and typically require full fine-tuning, their per- formance results are similar to the full fine-tuning method. Compared to the prompt-based fine-tuning method, the robust baseline model DPT, our approach achieves sub- stantial reductions in parameter count and fine-tuning time when applied to the CIKM dataset. Specifically, our method decreases the parameter count to 34.6% and reduces the fine-tuning time to 23.5% of DPT's requirements. Moreover, our approach demonstrates improvements of approximately 10% across multiple experimental metrics.\nIn addition to the high efficiency of parameters and time adjusted during the fine-tuning phase, our pre-trained model is also very efficient in the previous complexity analysis in Table 1. It is noteworthy that the EBM module maintains a time complexity of  $Ld\u00b2/k + Ldlog L$ and a parameter count of $(1 + 4/k)d\u00b2 + 4d$, which is substantially lower than that of self-attention mechanisms. This design ensures efficient handling of behavioral sequences, with the added benefit of a parameter size that is agnostic to the length of the sequence.\nIn conclusion, our pre-trained model architecture follows a linear structure, providing a solid foundation in terms of parameter count and time complexity. Additionally, through customized prompt fine-tuning, we significantly reduce the number of parameters involved in fine-tuning, resulting in faster processing. This highlights that our DPCPL not only delivers impressive results but also demonstrates high efficiency in both pre-training and fine-tuning processes."}, {"title": "Ablation Studies", "content": "To investigate the effectiveness of each component, we introduce the following variants of DPCPL:\n(1). Variant without Denoising Block (w/o DS) Instead of the EBM block, we exclusively employ the attention block in the pre-trained model.\n(2). Variant without Personalized Prompts (w/o PS) In this variant, instead of employing personalized prompts, we utilize continuous (soft) prompts, which are randomly initialized and trainable, drawing inspiration from method- ologies in the field of NLP.\n(3). Variant without Progressive Prompts (w/o PG) In- stead of progressive prompts, we only incorporate prompts into the first layer of our model."}, {"title": "Analysis of the Adaptation to downstream tasks", "content": "In this subsection, we aim to verify the efficient adap- tation of our pre-trained model to downstream tasks by conducting experiments on additional tasks.\nThe target behavior pertains to the items that have been interacted with within the behavior we endeavor to forecast.\nAs shown in Table 6 and Table 7, we add shopping cart and clicks to the target behaviors and compare them with other baselines respectively, and find that DPCPL not only achieves efficient adaptation with the pre-trained model, but also achieves good results on various tasks.\nIn addition, we define users with target behaviors less than or equal to 2 as cold-start users and use some of the user data for validation. From table 8, we observe that for cold-start users, we improve 30% over the current state- of-the-art model, which proves the effectiveness of DPCPL in small sample scenarios. Compared to traditional multi- behavioral approaches, DPCPL proves to be better at trans- ferring general knowledge to user representations in the presence of insufficient training data, which underscores the generalization ability of our denoising pre-trained model, as well as the knowledge transfer capabilities of customized prompt learning."}, {"title": "Hyperparameter Analysis", "content": "To examine the impact of various hyperparameters on DPCPL", "below": "n(1). Number of prompt factors of each group (N). We observed that N values between 8 to 12 yielded optimal results. Further increasing the N value seems likely to have a bad effect on the representation possibly due to overfitting, potentially due to the introduction of noise resulting from excessive N values.\n(2). Number of tokens in prompt (C). We observed that auxiliary information can be effectively introduced when the token count ranges between 8 to 12. However, increasing the token count beyond this range resulted in a decrease in performance. This decline is potentially due to a reduction in the influence of user behavior input when the token count becomes excessively large, leading to a dilution of the critical information needed for accurate recommendations.\n(3). Compactness regularity parameter (\u03bb). \u03bb controls the weight of the regularization loss. Observations indicate that \u03bb values between 0.01 and"}]}