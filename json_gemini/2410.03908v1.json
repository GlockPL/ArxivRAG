{"title": "Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis", "authors": ["Amey Hengle", "Atharva Kulkarni", "Shantanu Patankar", "Madhumitha Chandrasekaran", "Sneha D'Silva", "Jemima Jacob", "Rashmi Gupta"], "abstract": "In this study, we introduce ANGST, a novel, first of its kind benchmark for depression-anxiety comorbidity classification from social media posts. Unlike contemporary datasets that often oversimplify the intricate interplay between different mental health disorders by treating them as isolated conditions, ANGST enables multi-label classification, allowing each post to be simultaneously identified as indicating depression and/or anxiety. Comprising 2876 meticulously annotated posts by expert psychologists and an additional 7667 silver-labeled posts, ANGST posits a more representative sample of online mental health discourse. Moreover, we benchmark ANGST using various state-of-the-art language models, ranging from Mental-BERT to GPT-4. Our results provide significant insights into the capabilities and limitations of these models in complex diagnostic scenarios. While GPT-4 generally outperforms other models, none achieve an F1 score exceeding 72% in multi-class comorbid classification, underscoring the ongoing challenges in applying language models to mental health diagnostics.", "sections": [{"title": "1 Introduction", "content": "With the advancement of web technologies, social media platforms such as Reddit (Gkotsis et al., 2016; Gaur et al., 2018), Twitter (De Choudhury et al., 2013a; Coppersmith et al., 2014a), and ReachOut (Shandley et al., 2010; Kahl et al., 2020), become popular hubs for mental health support and information exchange. They offer an anonymous, safe space that fosters a sense of community and empowerment that begets in-depth mental health discussions (De Choudhury and De, 2014; Berry et al., 2017). Consequently, there is a growing body of research on \"digital psychiatry\" (Tsugawa et al., 2015) that analyzes the mental health discourse and language usage on these platforms to enhance the discovery, understanding, and detection of mental health concerns. However, despite significant efforts, there exist numerous concerns regarding the curation of these resources.\nDrawbacks of Existing Data Resources. The prevalent modus operandi for sourcing mental health-related datasets involves crawling social media posts that are either intrinsic to specific online communities pertaining to mental health (Turcan and McKeown, 2019) or those that bear certain attributive words (Mowery et al., 2016), hashtags (Berry et al., 2017), or self-reported diagnoses (Coppersmith et al., 2015; Yates et al., 2017). The binary indicator of the presence or absence of these signals is used to determine the positive class, while the negative class\u00b9 constitutes randomly crawled posts. This strategy engenders highly biased data and skewed annotations incongruous with the real-world distribution. Furthermore, it exacerbates the semantic divergence between the positive and negative classes, simplifying the task and diminishing its utility in real-world settings. We term this issue as the 'Data Source Bottleneck'. Moreover, these 'proxy diagnostic signals' of affiliation behavior (hashtags/community membership) or self-reports of diagnosis provide an easy and inexpensively means of collecting silver-labeled data, obviating the need for hiring professional annotators. However, as elucidated by Ernala et al. (2019), they lack clinical grounding, theoretical contextualization, and psychometric validity. They presents a rather myopic approach"}, {"title": "2 Related Work", "content": "Corpora related to Mental Health Disorders.\nSince the past decade, social media platforms have been actively used for compiling datasets for various mental health issues (De Choudhury et al., 2013a,b; Tsugawa et al., 2015; Pedersen, 2015). For instance, CLPsych15 (Coppersmith et al., 2015), RSDD (Yates et al., 2017), Depression Reddit (Pirina and \u00c7\u00f6ltekin, 2018), and Dreaddit (Turcan and McKeown, 2019) are commonly used corpora for depression analysis. Similarly, DATD (Owen et al., 2020) and the Anxiety on Reddit corpus (Shen and Rudzicz, 2017) are popular benchmarks for anxiety issues. UMD (Shing et al., 2018) and T-SID (Ji et al., 2021) are compiled exclusively for identifying suicide ideation.\nThe CLPsych16 dataset (Milne et al., 2016) supports multi-label classification, covering depression, control, and PTSD categories. Additionally, the CAMS (Garg et al., 2022) and SAD (Mauriello et al., 2021) datasets offer more granular classifications, categorizing the causes of depression into six and nine categories, respectively. On a broader scale, SMHD (Cohan et al., 2018), SWMH (Ji et al., 2022a), and CAMS (Garg et al., 2022) encompass a more comprehensive coverage of several mental health disorders. Yang et al. (2024) aggregated multiple mental health-related datasets into a unified benchmark named IMHI. More recently, Jin et al. (2023) proposed PsyEval, a suite of mental health-related tasks designed to evaluate the performance of large language models.\nComputational Models for Mental Health Disorder Identification. Early approaches for identifying mental health disorders from social media platforms relied heavily on feature engineering and traditional machine learning classifiers (De Choudhury et al., 2013a,b; Coppersmith et al., 2014b; Mitchell et al., 2015; Tsugawa et al., 2015). Subsequent research endeavors aimed to obviate the need for hand-crafted features by employing neural network architectures such as LSTMs and CNNs, enabling more accurate identification of mental health conditions (Sawhney et al., 2018; Tadesse et al., 2020). Borba de Souza et al. (2022) propose a deep learning ensemble method that effectively classifies anxiety, depression, and their comorbidity using Reddit posts. Another line of research explores the use of mental health questionnaires (Nguyen et al., 2022), multi-task learning (Sarkar et al., 2023), and hierarchical attention networks (Han et al., 2022) to augment existing architectures. In recent years, numerous transformer-based models pre-trained on mental health-related data, such as Mental-BERT, Mental-RoBERTa, Mental-XLNet, and Mental-LongFormer (Ji et al., 2022b, 2023), have been developed and released. More recently, several open-source mental health-focused LLMs, including Mental-Flant-T5, Mental-Alpaca (Xu et al., 2024), and Mental-LLama (Yang et al., 2024) have been introduced. Furthermore, endeavors such as that of Chen et al. (2023), Yang et al. (2023a), and Yang et al. (2023b) provide in-depth analyses of proprietary LLMs like chatGPT, GPT-3, and GPT-4, evaluating their performance in identifying various mental health conditions."}, {"title": "3 Curating ANGST", "content": "3.1 Data Collection and Filtering\nANGST is compiled from publicly available Reddit posts. As illustrated in Table 1, each post in ANGST is labeled in a multi-label fashion to indicate depression and/or anxiety. We adhere to established protocols for data collection as described in prior research on constructing mental health datasets (Yates et al., 2017; Cohan et al., 2018). To begin with, we compile a list of relevant mental-health-related Subreddits informed by prior investigations into depression and anxiety on Reddit (Pavalanathan and De Choudhury, 2015; Yates et al., 2017; Cohan et al., 2018). We employ PRAW ( Python Reddit"}, {"title": "3.2 Data Annotation", "content": "We employed two primary and one secondary annotator, each a trained professional psychologist. To preserve objectivity and prevent potential biases, we established a protocol ensuring complete anonymity between the annotators. Specifically, no additional information or context beyond the post's content was shared with them. Moreover, the annotators worked in isolation, ensuring their annotations were performed independently, precluding any collaborative influence. The primary role of the annotators was twofold. First, they discerned and labeled if a post signified depression or anxiety, indicating their decision with a clear \"yes\" or \"no.\" Second, highlight specific statements in the posts to support the validity of their judgment (see Table 1). The secondary annotator is used to resolve conflicting annotations. Additionally, to protect the identity of users, the annotators were asked to flag any posts that might"}, {"title": "4 Yet Another Mental Health Dataset?", "content": "In this section, we conduct a comprehensive cross-sectional analysis of ANGST. We scrutinize it across various facets and juxtapose it with existing mental health corpora, thereby underlining its unique characteristics and distinguishing features. Specifically, we compare ANGST against SDCNL (Haque et al., 2021), Depression Reddit (Pirina and \u00c7\u00f6ltekin, 2018) Dreaddit (Turcan and McKeown, 2019), and DATD (Owen et al., 2020). We employ the corpora comparison strategy as outlined by Kulkarni et al. (2023).\n4.1 Inter-Class Similarity\nHypothesis \u2013 The more similar the inter-class samples, the more difficult it becomes to classify the dataset. We hypothesize that due to its neutral-seeding policy, ANGST would exhibit higher"}, {"title": "4.2 Adversarial Validation", "content": "Hypothesis \u2013 Data drift (Lu et al., 2019) quantifies the change in the feature space between two datasets. All samples in the old (source) dataset are considered the negative class, and all the samples in the new (target) dataset are deemed the positive class. A simple classifier is trained for this binary classification task. A high performance suggests the presence of discriminatory features between the two datasets. We conjecture that due to its"}, {"title": "5 Experimental Setup", "content": "5.1 Models\nWe benchmark ANGST using both discriminative and generative language models. The former include Mental-BERTbase, Mental-BERTlarge, Mental-ROBERTalarge, Mental-XLNetbase, and Mental-LongFormerbase (Ji et al., 2022b, 2023). These models have undergone continued pre-training (Gururangan et al., 2020) on extensive mental health-related data collected from Reddit, demonstrating state-of-the-art performance on various mental health corpora. Amongst generative language models, we report results on Llama-2 chat models (7B and 13B) (Touvron et al., 2023), GPT3.5-turbo (Ouyang et al., 2022), and GPT-4 (Achiam et al., 2023). We report results for both the zero and few-shot settings.\n5.2 Evaluation Criteria\nWe benchmark ANGST on two tasks, providing alternative but complementary viewpoints for our analysis. They are as follows:\n\u2022 Multi-label classification where a post can simultaneously be classified as depression, anxiety, both, or None.\n\u2022 Binary classification for depression vs non-depression and anxiety vs non-anxiety.\nWe report the standard weighted precision, recall, and F1 scores for both multi-label and binary classification tasks. Additionally, we provide macro-F1 scores for both tasks. In the case of multi-label classification, we also report the Hamming loss (Tsoumakas and Katakis, 2007), which measures the fraction of labels for which the predicted and actual labels disagree. It is calculated as the average number of incorrect labels divided by the total number of labels."}, {"title": "6 Results and Discussion", "content": "6.1 Binary Classification.\nThe overall binary classification results for depression and anxiety are presented in Table 3. We observe that discriminative models exhibit consistent performance across both tasks, outperforming much larger models such as LLama-2 and GPT3.5-turbo. Apart from GPT-4, all other generative models show considerable variance in performance in both zero- and few-shot settings. Furthermore, there is a noticeable difference in how models handle depression versus anxiety.\nDepression results The fine-grained results for depression classification presented in Table 4, demonstrate a differential performance across labels. Models consistently exhibit higher recall and F1 scores for the depression label compared to the control group, indicating a stronger ability to identify true cases of depression while accepting lower precision. This trend signifies a model's bias towards minimizing false negatives, thus reducing the risk of missing actual depression cases. The comparison between discriminative models and GPT-4 shows only a slight difference. Both GPT-4 and Mental-XLNet achieve similar F1 scores; however, GPT-4 exhibits superior performance in classifying the control groups. This suggests that while the models are effective in identifying depression, there exists a precision trade-off that prioritizes avoiding missed diagnoses.\nAnxiety results Table 5 shows the fine-grained results for anxiety classification. GPT-4 significantly outperforms all other discriminative"}, {"title": "6.2 Multi-Label Classification.", "content": "Table 6 presents the results for multi-label classification. We observe a consistent trend of high recall and moderate precision. This indicates that while the models excel at identifying relevant labels and minimizing false negatives, they incur high false positives. Notably, the models demonstrate superior performance in predicting depression compared to anxiety, as evidenced by consistently higher F1 scores for depression. This disparity could stem from the more pronounced or readily learnable language features associated with depression in the dataset. GPT-3.5 Turbo with few-shot prompting stands out as the most effective, achieving an overall balanced F1 score of 71%, with noteworthy scores of 53% for depression and 17.9% for anxiety. On the other hand, PLMs that are characterized by lower Hamming Loss, adopt a more conservative prediction approach, likely reducing false positives but potentially missing some true positives. In contrast, GPT-4, with its higher F1 scores and greater Hamming Loss, adopts a more liberal approach, enhancing its ability to"}, {"title": "7 Error Analysis", "content": "7.1 Few shot vs Zero Shot\nFrom our qualitative analysis, we observe that zero-shot prompting outperforms few-shot learning. Out of 334 samples where the predictions of the two approaches differed, the zero-shot prompt correctly classified 241 samples that the few-shot prompt misclassified. Only 4/241 samples were actually labeled as depressed in the ground truth, while the remaining 237 were non-depressed instances. Notably, all 4 of these depressed examples contained self-diagnosis statements, which the few-shot approach failed to identify correctly (see Table 12). For anxiety classification, out of the 468 samples where the predictions differed, the zero-shot approach correctly classified 363 non-anxiety samples that the few-shot approach misclassified. We observe that slight anxious behavior mentioned in the posts is aggressively classified as an anxiety disorder by the few-shot approach, despite the ground truth indicating non-anxiety\nUpon qualitative analysis of these misclassified samples, we hypothesize that the few-shot prompts may be inducing noise and bias by overgeneralizing from the limited examples provided in context. Specifically, many non-depressed posts contain mentions of depressive symptoms, which the few-shot model appears to heavily weight, leading to false positive predictions. This can also be attributed to the fact that the in-context learning examples are silver labeled, the retriever is not potent enough to understand the minutiae in the semantics, or LLM's ability to handle long context.\n7.2 Error-Analysis \u2013 The Battle of the GPTS\nBoth GPT-3.5-turbo and GPT-4 show a limitation in assessing the temporal aspect of depression. Among the 761 samples misclassified by both models, only 42 samples with a true label of \"depressed\" were incorrectly labeled as \"not depressed.\" The models struggled to differentiate between past and present states of depression (Refer Table 13). Focusing on zero-shot depression, a total of 334 samples differed for GPT-3.5-turbo vs GPT-4. Out of these, GPT-4 demonstrated superior performance, with 270 samples correctly classified, while GPT-3.5 provided incorrect classifications. Among the 270 samples where GPT-4 was accurate, 251 instances were correctly identified as non-depressed, contradicting GPT-3.5's classification as depressed. This finding highlights GPT-4's enhanced contextual understanding and ability to differentiate between genuine depressive symptoms and non-depressive states, thus avoiding the over-classification of non-depressive instances as depressed."}, {"title": "8 Conclusion", "content": "In this study, we propose ANGST a novel dataset aimed at bridging critical gaps in the comorbid diagnosis of depression and anxiety from social media posts. By embracing a multi-label classification approach, ANGST promotes research in early detection and understanding of comorbid depression and anxiety conditions, which are often co-occurring yet underserved by existing datasets."}, {"title": "9 Limitations", "content": "This study has several limitations that future research could address. Firstly, our data collection from Reddit was constrained by time limitations and a finite search space, leading to potential blind spots in identifying users' self-disclosure. There may be rare expressions of self-disclosure or posts from non-mental health related subreddits were we missed curating ANGST. Additionally, our dataset only includes text, omitting other potentially informative modalities. For instance, the timing of posts could indicate insomnia or social relationship issues, which are early signs of depression or anxiety. We also limit our study to two disorders - depression and anxiety, and include posts in English only. Moreover, as discussed in section 6, the performance of all baseline models in classification tasks is far from ideal. Both generative and discriminative models, including GPT-4, consistently exhibit low precision, which shows that they are prone to false diagnoses. Therefore, while these models could serve as preliminary tools for individuals unaware of their mental conditions or those unable"}, {"title": "10 Ethical Considerations", "content": "Social media data can be highly sensitive, especially when pertaining to mental health. Thus, it is imperative to prioritize privacy and recognize the potential risks posed to individuals represented within the data (Hovy and Spruit, 2016; \u0160uster et al., 2017; Benton et al., 2017). Given this consideration, we assert that the risks tied to the data used in this study are minimal. Our assessment is corroborated by prior studies which have introduced similar datasets (Coppersmith et al., 2015; Milne et al., 2016; Losada and Crestani, 2016)\nThe ANGST dataset solely consists of publicly accessible Reddit posts. We diligently remove any information that could disclose an author's identity or demographics. We provided annotators only with anonymized posts and ensured their commitment to neither deanonymize nor contact the authors. Moreover, we extensively adhere to the ethical and privacy guidelines set forth by (Benton et al., 2017). We do not collect any identifiable information, and we securely store all data on protected servers, accessible solely through written agreements with the creators. The institutional review board (IRB) at our institution has classified our experiments using these datasets as exempt from additional review."}, {"title": "A Appendix", "content": "A.1 Curating ANGST-SILVER\nSince ANGST serves exclusively as a test benchmark, we compiled ANGST-SILVER as a complementary corpus suitable for few-shot learning or supervised fine-tuning. Given the complexity and length of the posts, which demand considerable human and financial resources, we utilized LLMs for annotation. Recent advancements in GPT-based solutions have shown them to be effective substitutes for human labeling, aligning well with human judgments in both clinical and non-clinical tasks (Wang et al., 2021; Li et al., 2023; Du et al., 2023; He et al., 2024). Furthermore, Li et al. (2023) demonstrated that generating explanations alongside target labels enhances the quality of silver labels, achieving a higher correlation with crowd-sourced annotations. Leveraging this approach, we employed GPT-3.5-turbo (Ouyang et al., 2022) to generate silver labels for the remaining 22, 124 posts in a zero-shot setting. Using an open-ended prompt, as detailed in Table 17, we directed the LLM to identify and rationalize cues related to any mental health disorder that may be attributed with the post. After analyzing GPT-3.5-turbo outputs, we retained 7, 667 posts identified with depression and/or anxiety and discarded the rest, thus forming ANGST-SILVER.\nA.2 Inter-Class Similarity \u2013 Case study of MMD\nWe report the mean MMD over 1000 runs with a random label-wise pair chosen at each run without replacement. In ANGST, we observed that the MMD between the control group and the groups representing anxiety, depression, and comorbidity is notably higher (0.47) than the MMD among the latter groups themselves (0.42). This observation suggests that distinguishing between anxiety, depression, and comorbidity poses a relatively greater challenge compared to distinguishing the control group from the other classes. Furthermore, when we compare the MMD of ANGST to other datasets, we find that our dataset exhibits a significantly lower MMD. This observation corroborates our hypothesis that ANGST presents a higher difficulty level in classification tasks due to the increased proximity between its class distributions.\nA.3 Hyperparameter Tuning\nWw fine-tune the BERT-based models on ANGST-SILVER. We vary the learning rate within the {2 - 5,2e - 6} range and experiment with batch sizes of {4, 8, 16, 32}. We train each model for 30 epochs with early stopping applied after 10 epochs of no improvement in validation F1 score. We use the Adam optimizer with decoupled weight decay regularization of 10-2 (Loshchilov and Hutter, 2017). For generating the outputs from the LLMs, we use top-p decoding with p = 0.95 (Holtzman et al., 2020). For each hyperparameter configuration, we run 3 seeds and report the averaged results. We apply this hyperparameter setup across depression, anxiety, and comorbidity classification tasks.\nWe use a single consistent prompt for zero-shot prompting of all the generative language models in our setup, provided in Appendix A.4. For few-shot prompting, we utilize the silver-labeled data as the retrieval pool. For each example, we retrieve the two most semantically similar posts from the silver-labeled data, irrespective of its label, to serve as in-context learning examples. We employ the all-mpnet-base-v2 model from sentence-transformers (Reimers and Gurevych, 2019) for computing semantic similarity between the test example and the silver-labeled data. The few-shot prompt is also included in Section A.4.\nA.4 Zero and Few-Shot Prompts\nTable 9 illustrates the zero and few shot prompts used for binary (depression vs non-depression and anxiety vs non-anxiety) and multi-label classification on ANGST using LLMs.\nA.5 Other Prompting Techniques\nSelf-evaluation scales are commonly used by clinicians to assess the presence and severity of mental disorders based on responses to structured questions. Each scale comprises specific questions, and responses are quantitatively scored to determine the severity of the corresponding mental disorder.\nA.5.1 Depression\nFor the assessment of depression, two scales were utilized: PHQ-9 (Kroenke et al., 2001) and MADRS(Williams and Kobak, 2008).\n\u2022 PHQ-9: This scale consists of 9 symptoms, each assessed on a scale ranging from \"not at all\" to \"nearly every day,\" scored from 0 to 4. To"}]}