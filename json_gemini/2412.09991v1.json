{"title": "Visual Object Tracking across Diverse Data Modalities: A Review", "authors": ["Mengmeng Wang", "Teli Ma", "Shuo Xin", "Xiaojun Hou", "Jiazheng Xing", "Guang Dai", "Jingdong Wang", "Yong Liu"], "abstract": "Visual Object Tracking (VOT) is an attractive and significant research area in computer vision, which aims to recognize and track specific targets in video sequences where the target objects are arbitrary and class-agnostic. The VOT technology could be applied in various scenarios, processing data of diverse modalities such as RGB, thermal infrared and point cloud. Besides, since no one sensor could handle all the dynamic and varying environments, multi-modal VOT is also investigated. This paper presents a comprehensive survey of the recent progress of both single-modal and multi-modal VOT, especially the deep learning methods. Specifically, we first review three types of mainstream single-modal VOT, including RGB, thermal infrared and point cloud tracking. In particular, we conclude four widely-used single-modal frameworks, abstracting their schemas and categorizing the existing inheritors. Then we summarize four kinds of multi-modal VOT, including RGB-Depth, RGB-Thermal, RGB-LiDAR and RGB-Language. Moreover, the comparison results in plenty of VOT benchmarks of the discussed modalities are presented. Finally, we provide recommendations and insightful observations, inspiring the future development of this fast-growing literature.", "sections": [{"title": "INTRODUCTION", "content": "VISUAL object tracking (VOT) has been a highly active topic in the past decades due to its crucial applications in broad scenarios like video surveillance [1], [2], [3], autonomous vehicles [4], [5], mobile robots [6], [7], human-machine interaction [8], [9], etc. The VOT task is defined as: given a target bounding box location in the first frame, a tracker needs to recognize and locate this target in all the following sequences consistently and robustly, where the targets could be arbitrary instances and class-agnostic. The task is challenging since 1) the target will undergo lots of complex appearance changes like deformation, rotation, scale variation, motion blur, and out of view; 2) the background will raise various uncontrollable influences like illumination change, similar object distractors, occlusions, and clutter and 3) the video capture sensors may be shaking and moving.\nAs an essential task of computer vision, there are various data modalities for VOT. The most common one is RGB videos, which attract lots of researchers to this task due to their popularity and easy accessibility. The RGB-modal VOT provides approximate target locations in the image coordinate with 2D bounding boxes, laying the foundation of many higher-level image analysis tasks like pose estimation, gait/activity recognition, fine-grained classification, and so on. The evolution of RGB-based VOT [2], [10], [11], [12] is enduring and has a long history, which is further accelerated by the advent of deep learning [13], [14], [15], [16], [17] and large-scale datasets [18], [19], [20].\nWe mainly focus on the methods of the past decade, especially the methods based on Deep Neural Network (DNN). According to their pipelines, we classify the mainstream RGB trackers into four categories, namely Discriminative Correlation Filters (DCF) [17], [21], Siamese Trackers [22], [23], [24], Instance"}, {"title": "RELATED WORKS", "content": "VOT is a fundamental and valuable technology for practical applications, and it has been a prevalent research area for many years, with plenty of methods proposed every year. There are many VOT surveys that have been published in the past decades which are devoted to sort out the development of this field from various perspective. We will present these works from the perspective of the modality and illustrate the difference in this paper."}, {"title": "Single-modality VOT Surveys", "content": "The prior art of single-modality reviews are mainly about RGB-based trackers [42], [44], [45], [46], [47], [48], [49], [50], [54], [55], [56], [57], [58], [59], [60]. In 2006, Yilmaz at al. [60] proposed the first survey about generic VOT rather than specialized target tracking like the human-specific ones. This survey categorized the tracking methods based on the object and motion representations, like points, primitive geometric shapes, object silhouette, and contour, etc.\nNumerous VOT surveys were then proposed. For instance, Yang et al. [54] reviewed VOT methods on the basis of the tracking procedure, including feature descriptors, online learning, integration of context information, and Monte Carlo sampling. Li et al. [55] focused on the appearance modeling of VOT, listing several kinds of representations like raw pixel representation, optical flow representation, histogram representation, and so on. In the past decade, we have witnessed the rapid development of deep-learning-based trackers The most famous DCF and siamese pipelines are also demonstrated in recent surveys. Ondra\u0161ovi\u010d et al. [44] summarized the main challenges and the core principles of siamese-based trackers. Zhang et al. [45] reviewed the tracking algorithms from the DCF-based and deep-learning-based viewpoints. Marvasti et al. [47] provided a systematical survey about deep-learning-based trackers from nine key network aspects like network architecture, network exploitation, network training, and so on. More recently, Soleimanitaleb et al. [49] classified the tracking algorithms into four branches, namely feature-based, segmentation-based, estimation-based and learning-based ones. Chen et al. [46] divided the trackers into generative and discriminative trackers, introducing both deep and non-deep methods. As for the VOT methods based on single TIR modality or LiDAR modality, we have found no general object tracking surveys that merely introduce these two kinds of single-modality VOT in literature up to now.\nOur work differs from previous single-modal surveys mainly in three folds: (1) Unlike previous unimodal reviews, our survey is more comprehensive that includes three mainstream single-modal VOT (the RGB modality, the TIR modality, and the LiDAR modality). To the best of our knowledge, we are the first to extensively introduce LiDAR-based trackers, which is a newly emerged direction. (2) For the RGB modality, we divide the existing trackers into four more complete paradigms, namely, discriminative correlation filters, Siamese-like matching, instance classification/detection, and unified transformers, where the last two classes are rarely or even not mentioned in previous surveys. (3) We systematically review existing VOT approaches, including the most state-of-the-art trackers of not only the three kinds of single modalities but also eight multiple modalities."}, {"title": "Multi-modality Surveys", "content": "We have observed very few previous surveys [51], [52], [53], [61], [62] that focus on multi-modal trackers. Walia et al. [52] is the first multi-modality survey, which emphasized two single-modal VOT of RGB and TIR and five kinds of multi-cue trackers including RGB-TIR, RGB-Audio, RGB-Laser, RGB-RF and stereo vision. Zhang et al. [51] reviewed two kinds of multi-modality trackers, namely RGB-Depth and RGB-TIR, based on the auxiliary modality and tracking framework. Kumar et al. [53] also presented multi-modal trackers (RGB-TIR, RGB-Depth, RGB-Audio and stereo vision) along with single-modal ones, and they classified papers into traditional approaches and deep-learning-based approaches. Zhang et al. [62] classified RGB-TIR trackers into pixel-level, feature-level and decision-level fusion ways. Yang et al. [61] focused on RGB-Depth trackers and introduced their fusion strategies, depth usages, and tracking frameworks.\nThe differences between previous surveys and this paper are twofold: (1) We review three types of single modalities as well as four multi-sensor combinations, providing a much more comprehensive overview than prior works and covering the most state-of-the-art methods. (2) To the best of our knowledge, we are the first to summarize both the RGB-language and RGB-LiDAR modalities, which are emerging yet highly promising directions."}, {"title": "SINGLE-MODAL OBJECT TRACKING", "content": "As shown in Fig. 1, different modalities of VOT have different characteristics and applications. In this section, we introduce three mainstream single-modal VOT methods, including RGB, TIR and LiDAR."}, {"title": "RGB-based Trackers", "content": "RGB modality refers to RGB images/videos, which are captured by commonly used vision cameras, i.e., a sensor most similar to human eye perception. The core merits of RGB modality can be attributed to the abundant appearance information contained in the recordings, as well as the relatively easy access to the devices. Hence, trackers based on this modality are widely used in various scenarios, including autonomous driving, security surveillance, robotics, etc. On the other hand, the RGB camera is a 2D sensor, and it is sensitive to illumination variations, weather changes, and background noise, which pose huge challenges for RGB-modal VOT.\nIn the pre-deep learning era, RGB-modal trackers rely on handcraft features like Haar [237], [238], HOG [2] and color name [239], [240]. And traditional classifiers like SVM [11], [195], multiple instance learning [241] and correlation filters [169], [196], [242] are employed. Subsequently, with the great progress of deep learning techniques and the born of large-scale benchmark datasets, including LaSOT [18], GOT-10K [19] and TrackingNet [20], various DNN-based tracking architectures have also been proposed. From the pioneering DLT [243] to the recent transformer-based methods [1], [77], [156], DNN-based trackers have been the research mainstream in the past decade. Consequently, we mainly review the advanced deep learning works for RGB-based VOT, categorizing them into four types and introducing them in the following. Besides, according to the development timeline, we list the RGB-based trackers' performance in several widely used benchmarks in Table 1, Table 2, Table 3 of this main manuscript, including the trackers from 2022 to 2024, 2019 to 2021 and 2015 to 2018. Note that the reason for splitting the two tables is that the popular datasets for the two periods are different."}, {"title": "Discriminative Correlation Filters", "content": "In DCF-based tracking, a correlation filter or a model predictor is trained online with the tracked target regions. The target is then detected in consecutive frames by convolving the trained filter via the fast Fourier transform (FFT) or convolution operations of DNN. We list the milestones and nodes of DCF-based tracking developments in Fig. 2.\nBefore the deep learning era, the correlation filter dominated for a long time due to its effectiveness and efficiency. It approximates dense sampling by circularly shifting operations and allows the FFT to be employed during the learning process. This technique is first proposed in MOSSE [244] and then further explored and improved in following works like CSK [245], STC [246], DSST [12], CN [240], SAMF [247], KCF [2], SRDCF [169], BACF [191] and so on. For instance, CSK proposed a kernel correlation filter to realize dense sampling. KCF is a significant milestone of the DCF-based trackers, which proposed a fast multi-channel extension of linear correlation filters to utilize HOG features for tracking. Then, several DCF trackers employed the HOG features, like RAJSSC [168], LCT [171], MKCF [167], MUSTer [172], RPT [248], CFLB [249], SRDCF [169], CFAT [250], RCF [251], Staple [182], SCF [252], SRDCFde [185], CACF [189], BACF [191], LMCF [195], PTAV [253], STRCF [224], LSART [254], CSR-DCF [218], LDES [101], DSAR-CF [97] and CMKCF [118]. An important direction among these methods involved extending beyond closed-form computations to enable learning from a search region wider than the template, exemplified by SRDCF, CCOT, BACF, and CSRDCF. This advancement was achieved through formulations utilizing conjugate gradient descent (CGD) [169], [255] and alternating direction method of multipliers (ADMM) [191], [218].\nStepping into the early stage of the deep learning era, the convolution neural network (CNN) based features gradually replaced the handcraft features, stimulating many non-end-to-end trainable trackers, including DeepSRDCF [173], DM-SRDCF [184], HCF [170], C-COT [255], HDT [183], ECO [197], DeepLMCF [195], CFWCR [205], Obli-RaF [196], MCPF [193], CFCF [199], IBCCF [204], MCCT [225], LSART [222], TM3 [217], STRCF [224], UPDT [223], DRT [219], LADCF [98], GFS-DCF [114], ASRCF [107], RPCF [103], fDeepSTRCF [119], RRCF [146], CMKCF [118], WSCF [121] and BWRR [68]. Deep-SRDCF [173] investigated the usage of convolutional layer activations in DCF-based tracking frameworks. HCF [170] illustrated the hierarchies of convolutional layers and exploited these multiple levels of abstraction for visual tracking. C-COT [255] employed an implicit interpolation model to enable efficient integration of multi-resolution deep feature maps. ECO [256] improved C-COT by introducing a factorized convolution operator to dramatically reduce the number of parameters and tackle the over-fitting issues. DeepLMCF [195] directly used the CNN features to demonstrate its proposed large margin structured SVM classifier. MCCT [225] explored a way to combine different appearance features with multiple experts. RPCF [103] introduced ROI-based pooling in the correlation filter by enforcing additional constraints on the learned filter weights. These methods mainly regard the DNN as a feature extractor, exploring the better usage of strong representation without training it together with the following classifiers.\nNext, we review the end-to-end trainable DCF-based deep trackers. Unlike traditional correlation filters, here, the trackers employ several convolutional layers of DNN to replace the FFT operation and generate the correlation weights. We abstract a general DNN-based DCF schema as shown in Fig 3(a), where a model predictor is used to generate the model weights like correlation filters and then operated on the search features to obtain the target model for decoding the results. ATOM [110] is a pioneering work in this line, which first used two shared ResNet-18 to extract features for template and search regions and then designed a target state estimation predictor and a target classifier. More importantly, it proposes reusing automatic differentiation to implement an efficient gradient descent method for training a DCF based on CGD and Gauss-Newton. The correlation weights are obtained by fully connected layers and applied channel-wise multiplication. DiMP [17] exploited both target and background appearance information for target model prediction, improving the discrimination of the DCF trackers. It proposed a model predictor to learn the target model, which is updated online. PrDiMP [137] improved DiMP by a probabilistic regression formulation which modeled the uncertainty in the annotations themselves to counter noise in the annotations and ambiguities in the regression task. KYS [129] learned to effectively utilize the scene information by directly maximizing tracking performance on video segments upon DiMP. To realize long-term tracking, LTMU [257] designed a meta-updater to decide the proper time of model update with a cascaded LSTM module. To tackle the problem of distractors, KeepTrack [141] kept track of distractor objects to continue tracking the target. UATracker [165] proposed a sampling method based on uncertainty adjustment to select representative sample frames to feed the discriminative branch of DiMP. Recently, with the success of Transformers, researchers also integrate it into DCF trackers. ToMP [21] employed a Transformer-based model prediction module to predict the target model weights, which is an encoder-decoder structure.\nIn summary, DCF-based methods have a long exploration history from the early handcraft to the current DNN-based end-to-end learnable approaches. The correlation filter demonstrates its vitality in tackling tracking, deriving hundreds of methods. Moreover, most of this pipeline needs to update the learned model/filter online to keep track, regardless of using handcraft features or DNNs. This model update process is beneficial for adapting to the target appearance changes and improving the tracking accuracy, but it will limit the DNN-based methods' tracking speed."}, {"title": "Siamese Trackers", "content": "Siamese paradigm has been the most prevalent pipeline in recent years. It regards the tracking task as a more general similarity learning problem in an initial offline phase, and then this function is evaluated online during tracking without model updating. More specifically, siamese models commonly employ a shared Siamese network as a feature extractor, tasked with encoding inputs from both the template and search regions. The extracted features are then fused using correlation similarity or specific fusion modules, as shown in Fig. 3(b). The target is localized by choosing the most similar candidates or regressing the bounding boxes with various decoders.\nDeep Siamese Network (DSN) was first employed for signature verification task [258] and then applied to many tasks such as face verification [259], [260], self-supervised learning [261], video object segmentation [262], [263] and so on. The researchers of VOT also exploited DSN in this area. There were four earliest methods, GOTURN [180], YCNN [176], SINT [178] and SiamFC [16] born almost simultaneously. Specifically, GOTURN proposed to use DSN to extract features for template and search regions. Then, the template and search representations were simply concatenated together to directly regressed the target location in the search region by fully connected layers. The whole model is trained offline and tracked online without model updating. Similarly, YCNN introduced a DSN as the features extractor and concatenated the obtained template and search features to a response map with fully connected layers. SINT learned a matching function between the features of template and search candidate proposals which were extracted by a DSN. SiamFC proposed a fully convolutional DSN with a cross-correlation layer, which regarded the template features as the convolutional kernel to convolve the search features and computed the similarity map. Based on SiamFC, CFNet [194] designed an asymmetric Siamese network, which applied the correlation filter as a differentiable layer in a deep neural network, learning deep features that are tightly coupled to the Correlation Filter. DSiam [206] proposed a dynamic Siamese network to explore the model update problem of SiamFC with a fast general transformation learning model and elementwise multi-layer fusion.\nOne of the most significant milestones of siamese trackers is SiameseRPN [3], which absorbed the region proposal subnetwork from the object detection [264] area to generate proposals for VOT. SiameseRPN was end-to-end trained offline with large scale image pairs and online tracked as a local one-shot detection problem. It built a bridge between object detection and VOT and obtained a strong performance with a high speed at that time. After that, plenty of Siamese methods were proposed, like DaSiamRPN [229], SiamRPN++ [22], SiamMask [104], C-RPN [106], SiamDW [108], UpdateNet [115], SiamCAR [23], Siam R-CNN [134], SiamFC++ [125], SiamAttn [139], CRACT [265], SiamBAN [24], CGACD [140], Ocean [132], RE-SiamNets [158], SAOT [144], SiamBAN-ACM [159], TransT [156], Stark [145], SiamRN [160], DTT [266], SiamGAT [161], InBN [78], AutoMatch [143], SLTtrack [81], CSWinTT [77], SparseTT [79], HybTransT [80], AiATrack [84], and so on. We present typical Siamese trackers according to their development vein in Fig. 4.\nOne aspect is to exploit deeper and wider networks, like SiamRPN++ [22] and SiamDW [108]. SiamRPN++ proposed a spatial aware sampling strategy to take advantage of features from deeper networks (ResNet-50 or deeper) and the depthwise correlation operation to further improve the accuracy and reduce the model size. SiamDW also investigated how to leverage deeper and wider convolutional neural networks to enhance tracking robustness and accuracy. Although RPN-based trackers [3], [22], [108] have achieved great success, the main drawback is that they are sensitive to hyper-parameters associated with anchors. Then, some works devoted to eliminating the negative effects of anchors with anchor-free trackers such as Ocean [132], SiamFC++ [125], SiamCAR [23], and SiamBAN [24]. For example, SiamCAR [23] designed an anchor-free and proposal-free tracker, which decomposed tracking into two subproblems: one classification problem and one regression task, and learned them simultaneously in an end-to-end manner. Another prevalent research direction is to explore the correlation operation of Siamese frameworks, such as the depthwise correlation of SiamRPN++, and others like SiamGAT [161] and SiamBAN-ACM [159]. SiamGAT introduced the graph attention mechanism to solve the problem of the fixed-scale cropped template region of cross correlation. SiamBAN-ACM proposed a learnable asymmetric convolution module, which learned to capture the semantic correlation information better. Since most of the Siamese trackers are trained offline and tracked online without model updates for efficiency, many works are devoted to exploring this point. MLT [112] incorporated SiamFC with a meta-learner network to provide the matching network with new appearance information of the target objects. DROL [124] equipped offline siamese networks with an online module with an attention mechanism to extract target-specific features under L2 error. UpdateNet [115] proposed to replace the handcrafted linearly combined update function of Siamese trackers with a CNN that learns to update.\nVery recently, with the development of vision Transformer, Siamese trackers also employ it in this task to explore stronger feature representations and template-search relationship modeling. TransT [156] presented a Transformer tracking method that combined the template and the search region features solely using the attention mechanism of Transformer. Stark [145] employed an encoder-decoder Transformer to model the global feature dependencies of both spatial and temporal information, avoiding many postprocessing steps such as cosine window. Then, many recent methods are proposed to improve the Transformer structure to adapt to VOT tasks. For example, CSWinTT [77] designed a new transformer architecture with multi-scale cyclic shifting window attention, replacing the original pixel-to-pixel attention strategy with window-level attention. SparseTT [79] used a sparse attention mechanism to find the most relevant information in the search regions, improving self attentions. AiATrack [84] proposed an attention in attention module to enhance the correlation operations.\nIn a word, the siamese schema greatly improves the efficiency of the DNN-based method while maintaining the performance by the offline-trained process and no-finetune online tracking. This schema transfers the tracking problem into a template-search similarity matching problem, thus settling the possible performance degradation due to no model updates."}, {"title": "Instance Classification/Detection", "content": "One of the most intuitive ways of employing deep learning technology is to use a neural network to memorize the target information and find the target via binary classification. That is to say, this way models the VOT as an instance classification or detection problem that only looks for a particular instance, which may belong to any known or unknown object class. We simplify the ICD pipeline in Fig. 3(c), where only the search region will be processed in one forward propagation. The backbone extracts the search features and the decoder outputs the final classification/detection results. Although the forward pipeline seems easier than other schemas, the model initialization and update are indispensable to encode the template information into the network.\nThere was an early tracking algorithm [267] based on the ICD paradigm, which trained a CNN offline before tracking and fixed it afterward. However, this work can only handle pre-defined target object classes, e.g., humans, but not for general VOT. DLT [243] is the pioneering work of ICD trackers and end-to-end deep trackers for VOT. It first trained a stacked denoising autoencoder offline with extra data to learn generic image features and transferred the learned model to the online tracking process via online finetuning. DeepTrack [268] proposed a target-specific CNN for object tracking without pre-training, where the CNN is trained incrementally during tracking with new examples obtained online. To cater to the date-poor problem, it enhanced the ordinary Stochastic Gradient Descent approach in CNN training with a temporal selection mechanism, generating positive and negative samples within different periods. SO-DLT [269] exploited the power of CNN based on DLT by using CNN as the feature extractor. From then on, CNN became the main choice of the backbone. Hong et al. [174] explored the usage of a pretrained CNN, using an SVM layer as the classifier to end-to-end learn the network by predicting the target saliency maps. STCT [179] transferred rich features of pre-trained deep CNNs for online tracking by casting online training CNN as learning ensembles to remove feature correlation and avoid over-fitting effectively. UCT [26] proposed to treat both the feature extractor and the ridge regression as convolution operations inside a unified convolutional network. MAML [133] was a representative instance detection method, which retrofitted robust detectors like FCOS [270] and RetinaNet [271] to trackers with proper initialization by model-agnostic meta-learning strategy. MDNet [272] is a typical milestone of ICD trackers, which proposed a multi-domain learning framework based on CNNs. The network is pretrained on visual tracking data for obtaining a generic target representation and is updated online for learning target-specific features. Following MDNet, there are many trackers proposed to improve its performance from multiple aspects like the attentions (SANet [187]), prediction head (DRL-IS [230], ADNet [188], BranchOut [27]), class imbalance (DSLT [231], VITAL [210]), acceleration (DeepAttTrack [227], RTMDNet [233], Meta-Tracker [273]), and refinement (ACT [232]).\nWe present the typical ICD trackers with their development process in Fig. 5. Note that trackers in this category usually finetune a pretrained feature extraction network with the ground truth of the target in the first frame and continuously update the network with tracked regions. Therefore, the ICD models are end-to-end trainable, which are first trained offline to ensure a good initialization and updated online to adapt to specific targets. In fact, the ICD-based trackers mainly emerged in a data-insufficient time, where large-scale tracking datasets haven't been proposed. Hence, most of them are dedicated to research on how to learn a CNN under the data-poor condition due to the lack of sufficient training samples."}, {"title": "One-stream Transformers", "content": "Before the vision Transformer appeared, trackers of the last five years were mainly dominated by the DCF and Siamese methods, where the feature extractors are usually shared between the template and search region. Then, a matcher or a model predictor will be employed to embed the template information into the search representations. In these pipelines, the template and search region interaction happens upon their extracted high-level features.\nTransformer has the attractive characteristic of relation modeling and feature extraction, which is demonstrated in vast vision tasks like segmentation [274], [275], detection [276], video classification [277], [278], vision-language learning [279] and so on. In the recent two years (2021-2022), Transformer has also shown its power in VOT, as shown in Fig. 6. Initially, Transformer in VOT is used for either relation modeling (replacing the conventional cross-correlation operation) like TransformerTrack [155], Stark [145], CSWinTT [77], TransT [156], ToMP [21], DTT [266], SparseTT [79], AiATrack [84] or feature representation (substituting the CNN backbones like ResNet) such as InBN [78] and SparseTT [79], both the two ways are demonstrated to be effective with large-margin improvements of performance. Note that although the methods mentioned here introduce Transformer, they are classified into the aforementioned categories based on their pipelines.\nRecently, we have observed another appealing and emerging trend of VOT, where the previous extractor-matcher separated two-stream pipeline gradually becomes a One-Stream Transformer (OST) pipeline as shown in Fig. 3(d). Plenty of emerging trackers follow this OST paradim as shown in Fig 6, including MixFormer [29], MixFormer V2 [87], OSTrack [13], SBT [28], SimTrack [1], DropMAE [89], F-BDMTrack [85], GRM [90], HIPTrack [94], RFGM [88], ROMTrack [86], SeqTrack [92], ARTrack [91], VideoTrack [93], ODTrack [95] and EVPTrack [96]. Specifically, leveraging the attention mechanism of Transformers, MixFormer [29] proposes to extract target-specific features and facilitate interactions between the target and search regions concurrently using a mixed attention module, dispensing with conventional Siamese CNN feature extraction. Similarly, in the same period, SBT [28] proposed a target-specific tracker based on the self-/cross-attention scheme, which deeply incorporated self-image feature extraction and cross-image feature correlation in multiple layers of the feature network. OSTrack [13] unified the feature learning and relation modeling jointly within a Transformer, bridging the template-search image pairs with bidirectional information flows. SimTrack [1] also leveraged a Transformer backbone for joint feature learning and interaction by serializing the input template and search images and concatenating them directly before the one-branch Transformer backbone. DropMAE [89] investigated masked autoencoder video pretraining for VOT with the OST paradigm. F-BDMTrack [85] and GRM [90] focused on solving the problem of insufficient consideration of foreground-background relationships. HIPTrack [94] and RFGM [88] proposed to incorporate historical information into OST-based trackers. SeqTrack [92] and ARTrack [91] converted the four values of a bounding box into a sequence of discrete tokens and used a decoder to generate this sequence token-by-token. VideoTrack [93], ODTrack [95], and EVPTrack [96] exploited the contextual relationships of video frames, i.e., the spatio-temporal information encoding of OST pipelines. These OST-based trackers have achieved state-of-the-art performance, indicating the potential of this paradigm.\nGenerally, the RGB modality is the most commonly used modality for VOT in various real-world applications due to its easy accessibility and rich appearance information. Hence, RGB-based VOT has a long exploration history and has given birth to a large number of methods. Nevertheless, challenges still exist, such as appearance variations and background noise. In addition, the challenges of long-term stability and accuracy-efficiency dilemma remain unresolved. Robust feature representation and strong relational modeling are key to solving these problems, which have been the most popular research topics for a long time. The recently emerged OST paradigm is promising because it leverages Transformer's feature representation and relational modeling capabilities to achieve superior performance while maintaining simplicity. Besides, to ensure efficiency, powerful but lightweight backbone architectures are always needed to accomplish this task. Moreover, specific issues like redetection modules for long-term tracking, model update strategies for different paradigms, and integration with other modalities are open, interesting, and valuable directions to explore for RGB-based VOT."}, {"title": "Thermal infrared-based Trackers", "content": "Thermal infrared (TIR) tracking refers to object tracking based on TIR video sequences, which are the radiated electromagnetic radiations within a specific wavelength spectrum and emitted by objects with temperatures above absolute zero. This modality can effectively handle some harsh situations like the camouflage and the poor illumination situations due to its imaging principle, enabling robust VOT under these conditions. Compared with RGB modality, TIR is helpful in privacy preserving and more robust to illumination changes. The application scenarios of TIR-based VOT include marine rescue, video surveillance, and night driving assistance. Therefore, TIR-based tracking has become a popular research topic considering the above benefits and the development of infrared equipment. However, since the TIR modality has no visible colors and textures, it is hard to provide discriminative feature representations and resist the distractors of similar objects, making TIR-based VOT challenging.\nTraditional TIR-based algorithms often combine handcrafted features with classical machine learning techniques. For instance, MILTracker [280] combined multiple instance learning with an adaptive motion prediction method to boost the tracker's efficiency. RLRST [281] created the multiple feature pseudo-color images with its kernel density estimation mechanism to monitor the characteristics from feature maps. ABCD [282] employed template-based trackers based on distribution fields for TIR tracking, exploiting background information for an online model update. MFPCIS [283] sought to maximize the likelihood estimation for the residuals based on robust low-rank sparse representation. To overcome partial deformations, DSLT [284] used structural SVM with a part-based matching method that integrated the co-difference feature of multiple parts. P-CODIFF [285] also used co-difference matrix and developed a part-based tracker that sampled at salient corner points. MaskSR [286] combined sparse coding together with high-level semantic features extracted by DNNs within a particle filter framework for TIR target tracking.\nIn recent years, TIR-based VOT methods mainly follow two mainstream paradigms: the DCF and Siamese schemas similar to the RGB tracking. We categorize the TIR trackers in Fig. 7 and introduce the corresponding methods in the following. Besides, we report the results of TIR-based methods in Table 4."}, {"title": "Discriminative Correlation Filters", "content": "DCF paradigm has gained tremendous popularity and achieved significant success in VOT, as introduced in Section 3.1.1. Its basic principle is applying a correlation filter between the template and candidate regions, then selecting the maximum value in the response map to locate the target in the current frame. Many researchers have attempted to solve the TIR tracking based on DCF. For instance, WCF [299", "300": "used a continuously switching mechanism to select a set of base trackers constructed from several dynamical MOSSE [244", "301": "integrated the TIR-specific features learned by a CNN architecture into the DCF paradigm. MCFTS [287", "302": "integrated DCF with structured SVM and employed spatial regularization and implicit interpolation to obtain continuous deep feature maps. One of the most significant milestones in DCF-based deep trackers is Efficient Convolution Operators (ECO) [256", "303": "ECO-stir [288", "289": "ECO-MM [30", "32": "were all developed based on ECO. Specifically, RCCF-TIR joint"}]}