{"title": "ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training", "authors": ["JIAYANG WU", "WENSHENG GAN", "JIAHAO ZHANG", "PHILIP S. YU"], "abstract": "In the current development of large language models (LLMs), it is important to ensure the accuracy and reliability of the underlying data sources. LLMs are critical for various applications, but they often suffer from hallucinations and inaccuracies due to knowledge gaps in the training data. Knowledge graphs (KGs), as a powerful structural tool, could serve as a vital external information source to mitigate the aforementioned issues. By providing a structured and comprehensive understanding of real-world data, KGs enhance the performance and reliability of LLMs. However, it is common that errors exist in KGs while extracting triplets from unstructured data to construct KGs. This could lead to degraded performance in downstream tasks such as question-answering and recommender systems. Therefore, anomaly detection in KGs is essential to identify and correct these errors. This paper presents an anomaly detection algorithm in knowledge graphs with dual-channel learning (ADKGD). ADKGD leverages a dual-channel learning approach to enhance representation learning from both the entity-view and triplet-view perspectives. Furthermore, using a cross-layer approach, our framework integrates internal information aggregation and context information aggregation. We introduce a kullback-leibler (KL)-loss component to improve the accuracy of the scoring function between the dual channels. To evaluate ADKGD's performance, we conduct empirical studies on three real-world KGs: WN18RR, FB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms the state-of-the-art anomaly detection algorithms. The source code and datasets are publicly available at https://github.com/ csjywu1/ADKGD.", "sections": [{"title": "1 INTRODUCTION", "content": "Knowledge graphs (KGs) are a data structure that could effectively integrate numerous real-world relations in triplets [32]. They integrate data from diverse sources into a unified structure. Knowledge graphs are advanced data structures that represent entities and their interrelations in a graph format, where nodes denote entities and edges represent relationships. This structured representation allows for effective storage and retrieval. Based on the deeper semantic understanding of the data, they can be extensively performed in many downstream tasks, such as question answering [13, 30] and recommender systems [17]. Question-answering systems could provide a structured way to interpret and answer complex queries. For instance, a system can use a KG to answer a question like \u201cWhat are the main contributions of Albert Einstein?\" by linking directly to relevant data points such as his theories, publications, and awards, thus offering precise and comprehensive answers. In the field of recommendation systems, KG can help identify buying patterns and customer preferences by linking products with customer demographics and purchasing history. Then, this could allow for more effective strategies in marketing and inventory management.\nHowever, extracting triplets from real-world unstructured data in practice could introduce numerous errors. These errors could lead the downstream task to perform worse. Therefore, anomaly detection should be necessarily considered after constructing KGs. Anomaly detection in knowledge graphs is a task to identify unusual or unexpected patterns in the data that deviate from the norm, which may indicate errors [14]. It is closely related to other tasks, such as KG completion and refinement [20]. While completion focuses on filling in gaps and refinement on improving quality, anomaly detection serves as a quality assurance mechanism, ensuring that additions and modifications made through completion and refinement do not introduce errors. In essence, anomaly detection acts as a safeguard, maintaining the integrity and reliability of the knowledge graphs.\nIn recent years, large language models (LLMs) have seen significant development and application [26, 38, 39]. However, these models often suffer from the hallucination phenomenon [12, 41], where they generate text that sounds plausible but is inaccurate or irrelevant. This issue arises mainly due to the knowledge gaps in the training data. Using KGs as an external information source can effectively mitigate this problem [7]. The combination with KGs can effectively reduce hallucinations in LLMs, so the accuracy of the information within the KGs is crucial. Knowledge graph anomaly detection can identify and correct errors within the graph, ensuring that the knowledge base used by LLMs is reliable. If the knowledge graph contains erroneous information, LLMs might generate misleading content, affecting user experience and trust. The accuracy of knowledge graphs not only improves the safety and consistency of the content generated by LLMs but also enhances their reasoning capabilities [16, 18, 19, 37]. For example, as shown in Fig. 1, when asked \"Did Michael Jordan play for the Los Angeles Lakers?\", LLM might generate an incorrect answer that contradicts known facts. The related knowledge retrieved using the KGs is fed into LLM as additional contextual information, enabling LLM to use the retrieved knowledge to generate more accurate responses. Additionally, for complex questions that involve multi-hop relationships and attribute comparisons, precise reasoning is essential. KoPL programming language translates natural language into basic function combinations for complex problem-solving [44]. For instance, to determine who is taller between LeBron James and his father, the process involves querying their heights and comparing them. This method showcases rigorous reasoning, benefiting human-machine interaction and improving response interpretability [28].\nDue to the complex interactions in real-world data, detecting anomalies in knowledge graphs becomes challenging. The methods in KG anomaly detection can be classified into three primary forms: rule-based, path-based, and embedding-based methods. The rule-based methods detect errors by relying on predefined rules [10, 27]. KG errors are defined as statements that violate any of these rules. However, these methods are not generalizable because different KGs require distinct sets of rules based on domain-specific knowledge. This dependence on specific rules restricts their applicability across different KGs, reducing their versatility in addressing the diverse range of errors encountered in real-world scenarios. Path-based methods focus on the paths between entities"}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 Triplets scoring function", "content": "The triplets scoring function can measure the compatibility between entities and their relationships. Several scoring functions have been developed to assess the score of triplets in KGs. Common methods include distance-based scoring functions and semantic matching scoring functions. A prominent example of a distance-based scoring function is TransE [4]. TransE minimizes the distance between the head entity, relation, and tail entity embeddings: $||h + r \u2013 t||$, where h, r, t are the embeddings of the head entity, relation, and tail entity, respectively. DistMult [43] uses a bilinear scoring function, which is given by: $f_r(h, t) = \\langle h, r, t \\rangle$, where $\\langle h, r, t \\rangle$ denotes the trilinear dot product. Complex [36] extends the idea of DistMult to complex numbers. Its scoring function is: $f_r(h, t) = Re(\\langle h, r, \\bar{t} \\rangle)$, where $Re$ denotes the real part and $\\bar{t}$ denotes the complex conjugate of the tail entity vector. Negative samples are crucial for training these models. A common approach is to generate negative samples by randomly replacing the head or tail entities in positive triplets. For instance, given a positive triplet (h, r, t), a negative triplet could be (h', r, t) or (h, r, t'), where h' or t' are randomly selected entities. Therefore, scoring functions can also be used for anomaly detection in KGs. By calculating the score of each triplet, we can identify anomaly triplets with low scores, which often represent unlikely relationships in KGs."}, {"title": "2.2 Anomaly detection methods in KGs", "content": "The traditional KG embedding scoring functions such as TransE [4], DistMult [43], and ComplEx [36] do not consider the errors in KGs and thus cannot learn discriminative representations for anomaly triplets. Therefore, several advanced methods have been proposed to detect anomalies in KGs, including CKRL [31], KGTtm [15], KGIst [3], and CAGED [45]. These methods employ unsupervised learning techniques to improve the detection of anomaly triplets. For simultaneous noise detection, CKRL defines local and global confidence scores based on the internal structure of KGs. It optimizes global consistency with confidence-weighted translations, enhancing KG embedding robustness [31]. Building on confidence and trustworthiness, KGTtm quantifies the semantic correctness and factual accuracy of triplets. It uses a cross-neural network to measure trustworthiness at entity, relation, and KG levels, allowing comprehensive evaluation [15]. KGIst uses unsupervised inductive summarization to represent KGs, focusing on learning \"normal\" patterns. It employs the minimum description length principle to identify anomalies [3]. The CAGED model adds contrastive learning to KG modeling and checks the triplet credibility by using both KG embedding and contrastive learning loss. It leverages multi-view and internal triplet consistency [45].\nCross-layer learning has demonstrated significant advantages in various algorithms. For example, LGLP [5] transforms the original graph into a line graph, allowing the link prediction task to be directly conducted within the line graph. This approach avoids information loss in graph pooling operations and performs well in both sparse and dense graphs. In addition, LGCL [46] enhances model robustness by maximizing the similarity between subgraphs and line graphs through contrastive learning. This cross-layer learning approach uses different levels of graph representations to enhance feature learning, enabling the model to better handle sparse and complex network data. The previous methods are used for link prediction, while the CAGED method utilizes cross-layer learning for anomaly detection [45]. CAGED also integrates graph representations from different views to identify anomalies in KGs."}, {"title": "2.3 Dual-channel training", "content": "Dual-channel training arises from the desire to improve item transition modeling, both within and across sessions [8]. This approach enhances the recommendation systems' ability to capture collaborative information and similar behavior patterns. It is particularly beneficial in the context of session-based recommendations, where the data is often anonymized and only the user's actions within a session are available. Dual-channel training uses two types of information: the intra-session channel, which captures transitions within the current session, and the inter-session channel, which captures transitions from neighboring sessions. This dual approach allows for a more comprehensive understanding of user behavior by integrating signals from both the target session and similar past sessions.\nDual-channel training has been widely used in graph learning algorithms, particularly in the development of graph neural networks (GNNs). DGTN is an innovative method designed to model item transitions across different sessions to enhance the performance of session-based recommendation systems [47]. Traditional methods only consider item transitions within the target session, ignoring the complex transitions in neighboring sessions. DGTN integrates the target session and its similar neighboring sessions into a single graph and explicitly injects transition signals into the embeddings through channel-aware propagation. D2PT is designed to address the issue of graph learning with weak information (GLWI) [23]. D2PT introduces a dual-channel architecture that alleviates isolated node problems through an enhanced global graph, further improving information propagation. DualGCL [24] is a graph contrastive learning method that enhances the performance of graph embeddings through a dual-channel structure. This method achieves superior classification accuracy across multiple benchmark datasets compared to existing contrastive learning models, demonstrating its advantages in capturing graph structure information and node representations."}, {"title": "3 PRELIMINARIES", "content": "In this section, we first provide the formal problem statement for detecting anomalies in a knowledge graph. Then, the definitions and fundamental concepts used in this paper are introduced."}, {"title": "Definition 3.1 (Problem definition).", "content": "A knowledge graph can be formulated as $G = (E, R, T)$, where $E$ denotes the set of entities, $R$ represents the set of relations between these entities, and $T$ comprises all the triplets within the KG, each triplet being a statement of the form $(e_1, r, e_2)$ indicating a relationship $r \\in R$ between $e_1, e_2 \\in E$. The whole KG contains the label triplets as $Y = \\{(t_i, y_i)\\}_{i=1}^N$ where $t_i \\in T$. It consists of two types of data, where $y_i \\in \\{0, 1\\}$ indicates the correctness of the triplet. The total training process is under unsupervised training, and the labels are inaccessible during training. During the training process, we treat all the samples as positive and use them to construct the negative samples. In our model, we use these samples to learn the representations and how to score the anomalies, i.e., establish the scoring function. In the testing step, it directly uses the representations and scoring function to determine the degree of the node's anomalies. This framework, represented as as $F (f (G; \\Theta), Y; \\Phi)$, learns the representations from $f (\\cdot; \\Theta)$ and constructs the anomaly scoring function from $F(\\cdot;\\Phi)$ with learnable parameters $\\Theta$ and $\\Phi$. By optimizing the loss over the training data, we aim to learn the scoring function that most effectively identifies anomaly triplets in $G$. Then, it uses a ranking method to predict the label $\\hat{Y}$ for $G$ and compares these predictions against the actual ground truth labels $Y$."}, {"title": "Definition 3.2 (BI-LSTM).", "content": "Long short-term memory (LSTM) networks have become essential tools for handling sequential data tasks, including natural language processing and time series analysis, due to their ability to manage long-term dependencies. A notable enhancement of LSTM networks is the bidirectional LSTM (BI-LSTM), which enhances context comprehension by processing data sequences in both forward and backward directions. By employing two separate hidden states for these directions, BI-LSTM networks effectively capture contextual information from both past and future states within the data [48]. In our model, we utilize two types of BI-LSTM networks:"}, {"title": "6", "content": "J. WU et al."}, {"title": "Definition 3.3 (Graph encoder layer).", "content": "Unlike BI-LSTM, which learns representations within the intra-view of the triplets, the graph encoder layer focuses on aggregating information from the head neighbor triplet or tail neighbor triplet for each anchor triplet [40]. Given an anchor triplet $q_i$, we update its embedding representation based on the weighted aggregation of its neighbor triplets, e.g., $\\{q_1, q_2, q_3, \\cdot\\cdot\\cdot, q_j\\}$. The neighbor triplets can be divided into two types: head neighbor triplet or tail neighbor triplet. A head neighbor triplet shares the same head entity as the anchor triplet. For example, if the anchor triplet is (h, r, t), then a head neighbor triplet would be (h, r', t'), where the head entity h remains the same while the relations and tail entities differ. Conversely, a tail neighbor triplet shares the same tail entity as the anchor triplet. For example, if the anchor triplet is (h, r, t), then a tail neighbor triplet would be (h', r', t), where the tail entity t remains the same while the head entities and relations differ.\nThe weight between the anchor triplet $q_i$ and its neighbor triplet $q_j$ is calculated as follows:\n$\\hat{a}_{ij} = sim(q_i, q_j)$.\n$\\hat{a}_{ij}$ indicates the importance of triplet j to triplet i. Here $sim$ is the attentional function: $\\mathbb{R}^n\\times\\mathbb{R}^n \\rightarrow \\mathbb{R}$. To make attention scores easily comparable across different triplets, we normalize them by applying a softmax function:\n$a_{ij} = \\frac{exp(\\hat{a}_{ij})}{\\sum_{k=1}^m exp(a_{ik})}$\nwhere m is the number of the neighbors. The head neighbor triplet aggregation can be calculated with a sigmoid function, as depicted:\n$x_i = \\sigma \\left(\\sum_{j=1}^m a_{ij} q_j\\right)$"}, {"title": "Definition 3.4 (Knowledge graph scoring function).", "content": "The knowledge graph scoring function evaluates the score of a given triplet (h, r, t), where h is the head entity, r is the relation, and t is the tail entity. This function calculates a score for each triplet based on the embeddings of the head entity, relation, and tail entity. Higher scores indicate a higher compatibility of the triplet. Given the embeddings of the head entity $e_h \\in \\mathbb{R}^d$, relation $e_r \\in \\mathbb{R}^d$, and tail entity $e_t \\in \\mathbb{R}^d$, the scoring function can be defined as follows:\n$f(h, r, t) = \\phi(e_h, e_r, e_t)$,\nwhere $\\phi(e_h, e_r, e_t)$ is a scoring function that measures the compatibility of the embeddings. One common choice for $\\phi$ is the TransE scoring function [4]:\n$\\phi(e_h, e_r, e_t) = -||e_h + e_r - e_t ||_2,$"}, {"title": "Definition 3.5 (Consistency loss function).", "content": "The consistency loss function is introduced to ensure that the vector representations obtained from two different views are consistent with each other. This is particularly useful when learning from multiple perspectives, as it encourages the model to produce similar embeddings across these views. To achieve this, we can use the kullback-leibler (KL) divergence to measure the similarity between the representations. Given two matrix representations $Q_1$ and $Q_2$, the consistency loss $L_{consistency}$ is defined as follows [11]:\n$L_{consistency} = KL(Q_1||Q_2) = \\sum_i Q^{(i)}_1 log \\frac{Q^{(i)}_1}{Q^{(i)}_2}$\nwhere $Q^{(i)}_1$ and $Q^{(i)}_2$ are the i-th elements of the matrix representations $Q_1$ and $Q_2$, respectively. The KL divergence $KL(Q_1||Q_2)$ quantifies the difference between the two probability distributions represented by $Q_1$ and $Q_2$. The purpose of the consistency loss is to minimize the divergence between these two matrix representations, thereby encouraging the model to produce consistent results with different views. This helps in maintaining coherence and reliability in the learned representations, making them more robust and interpretable."}, {"title": "4 ALGORITHM", "content": "Our framework learns to detect anomalies in KG with dual-channel training. As shown in Figure 2, each channel of ADKGD is mainly composed of two parts. The first part is to learn the representations from the cross-layer. The cross-layer learning can decompose into internal information aggregation and context information aggregation. The internal information aggregation is to use BI-LSTM to learn the internal relationship for each triplet in KG. However, there is a difference between channel I and channel II. Channel I uses the entity-view, while channel II uses the triplet-view. We use consistency loss to ensure the learning is effective between these two channels. The context information aggregation is to aggregate the representations with their neighbor triplets, including head neighbor and tail neighbor triplets. It's also different between the two channels. During the training, it uses methods the same as TransE to construct the negative triplets. It learns to calculate the score for positive samples and negative samples. Its goal is to make the score between the positive samples and negative samples with a margin. Finally, we could use these representations and score functions to identify the anomalies in the unlabeled data."}, {"title": "4.1 Data preparation", "content": "As shown in Figure 3, we start with the original Knowledge Graph (KG) data, which is divided into multiple batches, denoted as $B_1, B_2, . . ., B_n$. This batching process helps manage the computational load and facilitates efficient training of the model. Each batch $B_i$ contains a subset of the triplets from the original KG. These triplets T include both correct triplets ($T^+$) and anomalies ($T^\u2212$). Within each batch, we generate negative samples (N) for each triplet (T). This ensures that both correct triplets and anomalies have their corresponding negative samples. For each triplet T in the batch, we generate corresponding negative samples (N) by randomizing parts of the positive triplets. Specifically, we create negative samples by either replacing the head entity h or the tail entity t with a random entity from the KG. This randomization helps the model learn to identify and distinguish incorrect relationships. The process can be described as follows, where G represents the set of triplets in the knowledge graph:\n$N = \\{(h',r,t) | h' \\neq h and (h', r, t) \\notin G\\} \\cup \\{(h, r, t') | t' \\neq t and (h, r, t') \\notin G\\}.$\nFor each triplet, we obtain head neighbor triplets ($T_h$) and tail neighbor triplets ($T_t$) from the graph. These neighbor triplets provide additional context for the model to learn from the relationships surrounding each entity in the triplet. The definitions are as follows:\n\u2022 Head neighbor triplet ($T_h$): For each triplet (h, r, t), we identify and include triplets that share the same head entity h. $T_h = \\{(h, r', t') | (h, r', t') \\in G\\}$.\n\u2022 Tail neighbor triplet ($T_t$): For each triplet (h, r, t), we identify and include triplets that share the same tail entity t. $T_t = \\{(h',r', t) | (h',r', t) \\in G\\}$.\nThe final dataset structure for each batch includes the samples T and their corresponding negative samples N, along with their head neighbor triplets $T_h$ and tail neighbor triplets $T_t$. This structured data is then fed into the model for training. This process enables the model to learn to distinguish between correct and anomalous triplets by leveraging both the triplets themselves and their neighboring contexts."}, {"title": "4.2 Entity-view for detecting anomalies", "content": "In this part, we utilize the entity-view in CAGED [45] as one learning view for detecting anomalies. The process involves two main stages: internal information aggregation using BI-LSTM and aggregation with neighbor triplets, as shown in Figure 4 (A). First, we use BI-LSTM to capture the relationship of the entities and relations within a triplet. This approach helps in understanding the context by processing the sequences in both forward and backward directions. The dimension can be denoted as: $\\mathbb{R}^n \\times \\mathbb{R}^n \\times \\mathbb{R}^n \\rightarrow \\mathbb{R}^n \\times \\mathbb{R}^n \\times \\mathbb{R}^n$. Formally, given the embeddings of the head entity $e_h$, relation $e_r$, and tail entity $e_t$, the BI-LSTM outputs can be expressed as:\n$\\tilde{e}_h, \\tilde{e}_r, \\tilde{e}_t = BI-LSTM(e_h, e_r, e_t), \\forall (h, r, t) \\in G$,\nwhere G represents the set of triplets in the knowledge graph. We concatenate these outputs to form a single vector representation for each triplet:\n$q_i = [\\tilde{e}_h; \\tilde{e}_r; \\tilde{e}_t]$.\nNext, we aggregate these representations with their neighbor triplets to derive more robust embeddings. There are two types of neighbor triplets considered: head neighbor triplets and tail neighbor triplets. Firstly, for each triplet, we compute the similarity with multiple head neighbor triplets. The similarities are then processed using the softmax function to normalize. The aggregation is performed by weighing the neighbor triplets according to these normalized similarities. This process results in obtaining $z_1$:\n$z_1 = \\sum_j softmax(sim(q_i, q_j)) \\cdot q_j$\nwhere $sim(q_i, q_j)$ denotes the similarity between the anchor triplet $q_i$ and a head neighbor triplet $q_j$. The similarity is calculated by using the dot product. The softmax function is used to normalize these similarities, ensuring they sum to 1 across all neighbor triplets. This weighted aggregation results in the embedding $z_1$, which captures the context from the head neighbors. Similarly, for each triplet, we compute the similarity with multiple tail neighbor triplets. These similarities are also normalized using the softmax function. The aggregation is done by weighing the neighbor triplets according to the normalized similarities. This process results in obtaining $z_2$:\n$z_2 = \\sum_k softmax(sim(q_i, q_k)) \\cdot q_k$"}, {"title": "4.3 Triplet-view for detecting anomalies", "content": "In this part, as shown in Figure 4 (B), we use BI-LSTM-D to capture the relationships between entities and relations while reducing the dimensionality. The dimension can be denoted as: $\\mathbb{R}^n \\times \\mathbb{R}^n\\times\\mathbb{R}^n \\rightarrow \\mathbb{R}^n$. Formally, given the embeddings of the head entity $e_h$, relation $e_r$, and the tail entity $e_t$, the BI-LSTM-D outputs can be expressed as:\n$\\breve{e}_{h,r,t} = BI-LSTM-D(e_h, e_r, e_t), \\forall (h, r, t) \\in G$,\nwhere G represents the set of triplets in the knowledge graph. The BI-LSTM-D integrates the information of the entire sequence into the final hidden state, where $\\breve{e}_{h,r,t}$ is the hidden state of the last time step of output. We use this output as the representation for each triplet:\n$q'_i = [\\breve{e}_{h,r,t}]$.\nNext, we aggregate these representations with their neighbor triplets to derive more robust embeddings. The calculations are similar to the entity-view. The aggregation is performed by weighing the neighbor triplets according to these normalized similarities. This process results in obtaining $z_3$:\n$z_3 = \\sum_j softmax(sim(q'_i, d_j)) \\cdot d_j$,\nSimilarly, for each triplet, we compute the similarity with multiple tail neighbor triplets. These similarities are also normalized by using the softmax function. The aggregation is done by weighing the neighbor triplets according to the normalized similarities to obtain $z_4$:\n$z_4 = \\sum_k softmax(sim(q'_i, d_k)) \\cdot d_k$\nwhere $sim(q'_i, d'_j)$ denotes the similarity between the anchor triplet $q'_i$ and a tail neighbor triplet $q'_j$, also calculated using the dot product."}, {"title": "4.4 Training with consistency loss", "content": "In this section, we introduce the consistency loss to ensure that the representations from the two perspectives (entity-view and triplet-view) are consistent with each other. As shown in Figure 5, the consistency is enforced through the Kullback-Leibler (KL) divergence. First, we calculate the scores for the two BI-LSTM models. The score for the entity-view is calculated by using the norm of the vector difference:\n$f_{entity} = ||h + r - t||_2,$\nwhere h, r, and t are the embeddings of the head entity, relation, and the tail entity, respectively. This score represents the score of the given triplet (h, r, t) in the context of the entity-view. In addition, the score for the triplet-view is calculated using a multi-layer perceptron (MLP\u2081):\n$f_{triplet} = MLP_1(q'_i)$,"}, {"title": "12", "content": "J. WU et al.\nwhere $q'_f$ is the output vector from BI-LSTM-D, which integrates the information of the entire sequence into the final hidden state. MLP\u2081 takes this integrated representation and produces a score indicating the score of the triplet in the context of the triplet-view. To ensure consistency between these scores, we compute the KL divergence between the distributions of $f_{entity}$ and $f_{triplet}$:\n$L_{KL, score} = KL(f_{entity} || f_{triplet}).$\nwhere the KL divergence is calculated by using the following formula, $KL(P || Q) = \\sum_i P^{(i)} log \\frac{P^{(i)}}{Q^{(i)}}$, where $P^{(i)}$ and $Q^{(i)}$ represent the probability distributions of $f_{entity}$ and $f_{triplet}$, respectively. In the context of our model, this can be expressed as:\n$L_{KL, score} = \\sum_i f^{(i)}_{entity} log \\frac{f^{(i)}_{entity}}{f^{(i)}_{triplet}}$\nwhere $f^{(i)}_{entity}$ is the probability distribution of the entity-view scores and $f^{(i)}_{triplet}$ is the probability distribution of the triplet-view scores. This loss term penalizes the model if the scores from the two views are significantly different, encouraging the model to produce similar scores for the same triplet from both perspectives.\nNext, we establish the consistency loss for the aggregation of neighbor triplets. For the head neighbors, the aggregation from the entity-view and triplet-view are scored using different MLP. The head neighbor aggregation for the entity-view is scored using MLP\u2082:\n$S_{head, entity} = MLP_2(z_1)$,\nwhere $z_1$ is the aggregated representation of the head neighbors from the entity-view. MLP\u2082 takes this aggregated representation and produces a score. This is the score of the head neighbor aggregation in the entity-view. In addition, the head neighbor aggregation in the triplet-view is scored using MLP\u2083:\n$S_{head, triplet} = MLP_3(z_3)$,\nwhere $z_3$ is the aggregated representation of the head neighbors from the triplet-view. MLP\u2083 takes this aggregated representation and produces a score. This is a score of the head neighbor aggregation in the triplet-view. To enforce consistency between these two distributions, we use the KL divergence:\n$L_{KL, head} = KL(S_{head, entity} || S_{head, triplet}).$\nThis loss term ensures that the scores from the head neighbor aggregations in both views are aligned. This promotes consistency in the head neighbor context representation.\nSimilarly, the tail neighbors use the same score functions as the head neighbors. The tail neighbor aggregation for the entity-view is scored using MLP\u2082:\n$S_{tail, entity} = MLP_2(z_2)$,\nwhere $z_2$ is the aggregated representation of the tail neighbors from the entity-view. MLP\u2082 produces a score for the tail neighbors' context in the entity-view. In addition, the tail neighbor aggregation in the triplet-view is scored using MLP\u2083:\n$S_{tail, triplet} = MLP_3(z_4)$,\nwhere $z_4$ is the aggregated representation of the tail neighbors from the triplet-view. MLP\u2083 produces a score for the tail neighbors' context in the triplet-view. We also compute the KL divergence between these two distributions to enforce similarity:\n$L_{KL, tail} = KL(S_{tail, entity} || S_{tail, triplet}).$"}, {"title": "13", "content": "This loss term ensures that the scores from the tail neighbor aggregations in both views are aligned, promoting consistency in the tail neighbor context representation.\nThe final consistency loss is the sum of the KL divergence losses, i.e.,\n$L_{consistency} = L_{KL, score} + L_{KL, head} + L_{KL, tail}.$\nThis comprehensive consistency loss ensures that the embeddings and their aggregations from both perspectives are aligned, promoting robustness and coherence in the representations learning."}, {"title": "4.5 Detecting anomalies", "content": "The final training loss for detecting anomalies is composed of two main parts. The first part of the loss function focuses on ensuring that the positive samples have a lower score than the negative samples by a specified margin. This is achieved by the following loss calculation:\n$L_{margin} = margin(loss_p, loss_n) = max(0, loss_n \u2013 loss_p + \\gamma)$,\nwhere $loss_p$ represents the sum of the scores for all positive samples and $loss_n$ represents the sum of the scores for all negative samples, and $\u03b3$ is the margin parameter. This method emphasizes that the scores for positive samples should be at least one margin lower than the scores for negative samples, thus distinguishing correct triplets from anomalies.\nEach sample's $loss_p$ consists of two parts: the score from the BI-LSTM layer and the similarity scores from the aggregation with neighbor triplets. The combined score for each sample can be expressed as:\n$loss_p = \\alpha \\cdot f_{BI} + (1 \u2013 \u03b1) \\cdot \\left[ \\frac{1}{2} (sim(z_1, z_2) + sim(z_3, z_4)) \\right]$\nwhere $f_{BI}$ is the score from the BI-LSTM layer. In entity-view, it is calculated by $||h + r - t||_2$, and in the triplet-view, it is calculated with $MLP_1(\u00b7)$, as followings: $f_{BI} = f_{BI-LSTM} + f_{BI-LSTM-D} = ||\\tilde{e}_h + \\tilde{e}_r \u2013 \\tilde{e}_t||_2 + MLP_1(\\breve{e}_{h,r,t})$. In addition, $sim(z_1, z_2)$ is the similarity between the head neighbor triplets aggregation and tail neighbor triplets aggregation in the entity-view, and $sim(z_3, z_4)$ is the similarity between the head neighbor triplets aggregation and tail neighbor triplets aggregation in the triplet-view. The similarity function $sim$ is calculated by the dot product, which is defined as $sim(a, b) = a \u00b7 b$. The parameter \u03b1 is a weight that balances the contributions between internal information aggregation and neighbor triplets aggregation. The calculation for negative samples is similar to the positive sample.\nThe second part of the training loss is the consistency loss, which ensures that the representations from the two perspectives (entity-view and triplet-view) are similar. This is achieved by calculating"}, {"title": "14", "content": "J. WU et al.\nthe kullback-leibler (KL) divergence between the scores from the two views. The consistency loss is defined as:\n$L_{consistency} = L_{KL, score} + L_{KL, head} + L_{KL, tail},$\nBy combining these two parts, the total training loss can be expressed as:\n$L = (1 \u2013 \u03b2) \u00b7 L_{margin} + \u03b2 \u00b7 L_{consistency}.$\nThis combined loss function ensures that the model effectively distinguishes between correct triplets and anomalies while maintaining consistency between the entity-view and triplet-view representations. Finally, we use the best prediction model to complete the prediction. The combined score for each sample is calculated as follows:\n$score = \u03b1 (f_{BI-LSTM} + f_{BI-LSTM-D}) + (1 \u2013 \u03b1) \u00b7 \\left[ \\frac{1}{2} (sim(z_1, z_2) + sim(z_3, z_4)) \\right]$\nIn the final prediction, it does not need to use the negative samples or KL divergence. As a result, a higher score indicates a higher likelihood of the sample being an anomaly."}, {"title": "4.6 Time complexity", "content": "The time complexity of the ADKGD framework can be divided into three main stages: data preparation, training, and inference. Each stage involves specific computational steps, as detailed below. During data preparation, negative sampling and neighbor extraction are the main operations. Negative sampling involves generating N negative samples for each triplet in the knowledge graph (G). For a total of |T| triplets, the complexity of this step is O(|T|\u00b7 N). Additionally, extracting head"}]}