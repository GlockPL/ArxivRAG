{"title": "Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems", "authors": ["Helen Schneider", "Sebastian Nowak", "Aditya Parikh", "Yannik C. Layer", "Maike Theis", "Wolfgang Block", "Alois M. Sprinkart", "Ulrike Attenberger", "Rafet Sifa"], "abstract": "Image-based diagnostic decision support systems (DDSS) utilizing deep learning have the potential to optimize clinical workflows. However, developing DDSS requires extensive datasets with expert annotations and is therefore costly. Leveraging report contents from radiological data bases with Natural Language Processing to annotate the corresponding image data promises to replace labor-intensive manual annotation. As mining 'real world' databases can introduce label noise, noise-robust training losses are of great interest. However, current noise-robust losses do not consider noise estimations that can for example be derived based on the performance of the automatic label generator used. In this study, we expand the noise-robust Deep Abstaining Classifier (DAC) loss to an Informed Deep Abstaining Classifier (IDAC) loss by incorporating noise level estimations during training. Our findings demonstrate that IDAC enhances the noise robustness compared to DAC and several state-of-the-art loss functions. The results are obtained on various simulated noise levels using a public chest X-ray data set. These findings are reproduced on an in-house noisy data set, where labels were extracted from the clinical systems of the University Hospital Bonn by a text-based transformer. The IDAC can therefore be a valuable tool for researchers, companies or clinics aiming to develop accurate and reliable DDSS from routine clinical data.", "sections": [{"title": "1 Introduction", "content": "Implementing artificial intelligence in medical workflows can enhance reading accuracy and productivity, thereby improving the quality and economic efficiency of patient care [11,17]. Effective and reliable DDSS, that aid physicians in detecting and characterizing pathologies, are therefore of great interest [7]. Image-based deep learning models, e.g. Convolutional Neural Networks (CNNs), have shown high potential for detecting pathological alterations in medical imaging achieving human-level performance or exceeding humans [14, 20, 26, 27, 29]. \u03a4\u03bf develop a model with sufficient performance using supervised learning, a significant number of annotated training images are required. This is a major challenge in the medical field as the annotation of medical images requires considerable expertise from medical annotators and is therefore costly.\nIn in-house clinical data systems of radiology departments, diagnoses and findings are already documented by experts in free-text reports during the patients treatment. This information may be utilized as annotations of the associated medical images, eliminating or a least reducing the need for expensive manual annotation [21]. Consequently, analysing local databases of clinical routines is a promising way to develop models with sufficient data for reliable DDSS that offer real benefits in daily clinical practice. In recent years, this has been the motivation for various studies investigating the use of Natural Language Processing (NLP) to extract free-text report content as image labels. Further information about this specific NLP application and the challenges of medical semantics can be found in [9, 10, 21, 22, 30].\nHowever, such labels can feature discrepancies to the image content due to various reasons, e.g. due to the error rate of the used NLP approach [10, 21]. In the following, labels with imperfections are referred to as noisy labels. It is common practice that the performance of labeling systems, which are either created for a medical-scientific project or implemented in a clinical workflows, are evaluated on independent and manually curated test data [9,21,22]. This evaluation can be used to estimate the noise of the labels generated by the annotation system. A significant proportion of noisy labels can greatly impact the model's performance, posing potential harm to patients when used as DDSS.\nNoise-robust algorithms, which can achieve exceptional performance despite label noise, represent therefore a highly relevant research field in medical image processing. Due to extensive data-protected image data sets and limited access to comprehensive local computing capacity, a desirable algorithm feature is a trivial implementation with no increased training complexity. Among other things, increased numbers of hyper- and network parameters can raise the training complexity. The expected label noise, given in practice due to the performance evaluation of the automatic labeler, can present valuable prior knowledge for these solution approaches."}, {"title": "1.1 Related Work", "content": "When dealing with data sets containing noisy labels, there are generally two non-mutually exclusive approaches: noise-robust training and noise detection. In noise-robust training modules are added that enable effective training of the network even in the presence of label noise. This involves implementing modules in network architectures [4,5,32], developing co-teaching approaches [6] or applying resilient regularization [13, 28], among other strategies. Additionally, noise-robust loss functions [3,15,25,33,36-38] represent established and easy-to-apply solution approaches.\nNoise detection methods aim to identify noisy samples which enables excluding noisy samples in a new training iteration [31], treating them as unlabeled data [35] or efficient targeted relabeling [19]. Noisy samples are detected by conspicuous patterns such as high model and label disagreement [19], gradient direction [23], or disagreement between different models. Note that these approaches require a two-step training scheme, and are therefore increasing the training effort.\nThulasidasan et al. introduced the Deep Abstain Classifier (DAC) that can abstain from noisy labels in the loss function by enabling the network to map potential noisy samples to an extra neuron of the classification head [31]. High performances were achieved without complex hyperparameter searches and increased numbers of network parameters. However, the abstain mechanism does not incorporate prior knowledge of expected noise levels in the dataset, which could be valuable information for enhancing its performance. Furthermore, most methods are not sufficiently tested with realistic noise simulations and real-world noisy data sets for medical imaging.\nIt is, therefore, the aim of this work:\nto propose an extension of the DAC, called Informed Deep Abstaining Classifier (IDAC), that enables the inclusion of prior knowledge on the expected noise inside the abstaining loss function. The IDAC represents an easy-to-apply noise-robust loss, leading to no significant increase in the training complexity.\nto evaluate the noise-robust training of the algorithm compared to state-of-the-art baseline loss functions on a public medical dataset with realistic simulated noise levels. We focus on low noise levels between 1%-15%, which have not been sufficiently researched in the existing literature despite their high practical relevance."}, {"title": "2 Materials and Methods", "content": null}, {"title": "2.1 Data Sets", "content": "Public data set The experiments are based on CheXpert, a chest X-ray data set with automatically generated training labels based on the corresponding text reports [9]. We create two training data sets for binary classification (diseased vs. non-diseased) for chest X-ray images in posterior-anterior projection. We choose pleural effusion (n=37530) and cardiomegaly (n=7637) to investigate manifestations of pulmonary and cardiovascular diseases. Both conditions are well-represented in the CheXpert data set, with low intrinsic noise due to high-quality labeling by the NLP label system [9]. We exclude the uncertainty labels of the training data to further minimize the intrinsic noise. Various noise levels are simulated by swapping correct with incorrect labels (1%, 3%, 5%, 7%, 15%, 30%, 50%). The validation set contains 202 and the testing set contains 500 manually annotated samples.\nClinical Real-World data set We also explore the proposed approach using an in-house data set of chest X-ray images of the intensive care units of the hospital Bonn in anterior-posterior projection annotated by report content extracted in previous studies [21,22]. Here, only pleural effusion is investigated, as no cardiomegaly labels are available. The labels of the training set (n=10000) are based on report content extracted by a BERT transformer [2]. Further information about utilized NLP methods are available in [22]. The labels of the validation set (n=1437) are based on report content extracted by research assistants. The test set (n=187) is labeled based on the image data by a medical expert. Noise levels were estimated in previous studies. There is a 4.3% discrepancy in a subset between the labels based on report content compared to labels based on the images themselves and a 1.2% discrepancy caused by errors by the BERT transformer. Further details on the data set can be found in the previous open-access works [21, 22]."}, {"title": "2.2 Loss Functions", "content": "In this section all relevant loss functions and corresponding classifiers for training k-class classification problems are given. Here $p_w(y = ix)$ is the probability of the i-th class of a model output y for a given input image x dependent on the model weights w. For simplicity $p_i$ is used instead of $p_w(y = ix)$ and $t_i$ stands for the corresponding label, as in a previous work [31]. When representing the loss function for an entire batch, $p_{j,i}$ corresponds to the probability of the i-th class in the model output for the j-th sample within the considered batch."}, {"title": "Cross Entropy Loss", "content": "The standard cross entropy (CE) loss is defined as followed,\n$L_{CE}(x_i) = \\sum_{i=1}^{k} t_i log(p_i)$                                                (1)\nwhere $t_i$ is ground truth of the sample $x_i$ for class $i \\leq k$. Although the CE loss performs exceptionally well in clean label training scenarios, it lacks noise robustness, as noted in [36]."}, {"title": "Symmetric Cross Entropy Loss", "content": "The symmetric cross entropy (SCE) loss was introduced to improve the noise robustness of the CE loss without structural adaption of the classifier itself [36]. The SCE adds a Reverse Cross Entropy (RCE) term with clipping of predictions and true targets [36]. It is defined as followed:\n$L_{SCE}(x_j) = -\\sum_{i=1}^{k} t_i log(p_i) - \\sum_{i=1}^{k} p_i log(t_i) = L_{CE}(x_j) + L_{RCE}(x_j)$"}, {"title": "Deep Abstaining Classifier Loss", "content": "The DAC has an additional k + 1 output neuron $p_{k+1}$, designed to represent the probability of abstention for the data point $x_j$ during training [31]. The DAC loss is defined as followed:\n$L_{DAC}(x_j) = (1 - p_{k+1}) (\\sum_{i=1}^{k} t_i log(\\frac{p_i}{1 - p_{k+1}} ) + \\alpha log(\\frac{1}{p_{k+1}})$\nThe first term defines an adjustment of the CE loss over the k non-abstaining classes. If the abstaining output is absent ($p_{k+1} = 0$), it reverts to the standard CE loss, otherwise, the k class probabilities are normalized based on the output of the abstain neuron $p_{k+1}$. The second term with abstention weight $\\alpha > 0$ is a regularization term to penalize abstention, avoiding the DAC to abstain from all training cases.\n$\\alpha$ is linearly increased during training based on the maximal number of training epochs. This allows fewer and fewer cases to be abstained during training, initially focusing on the supposedly clean labels. However, a complex dependency between the loss function and the maximal number of training epochs is introduced, leading to costly hyperparameter searches and less intuitive training analysis."}, {"title": "Informed Deep Abstaining Classifier Loss", "content": "The IDAC loss represents an enhancement of the DAC loss function by taking into account information about the expected label noise of the data set. The classifier, like the DAC, has an additional neuron $p_{k+1}$, which represents the probability of abstention for a sample $x_j$. While the true label noise percentage $\\eta$ is not known in practice, often an"}, {"title": null, "content": "estimate of the noise is given. In the following the noise estimation is referred to as $\\tilde{\\eta}$. In practical implementation, $\\tilde{\\eta}$ can be based on the performance evaluation of the annotators (both for automatic NLP and human annotators), which are typically performed on subsets of the medical dataset. The noise estimation $\\tilde{\\eta}$ represents a fixed hyperparameter for the loss function and is not adapted during training.\nThe IDAC loss extension aims to take this prior knowledge of the data set into account during the data-driven training. The IDAC and DAC loss are methodically differentiated by the abstain regularization term. The IDAC loss is therefore defined as followed:\n$L_{IDAC}(x_j) = (1 - p_{k+1}) (\\sum_{i=1}^{k} t_i log(\\frac{p_i}{1 - p_{k+1}} )) + \\alpha(\\tilde{\\eta} - \\hat{\\eta})^2$\n$\\hat{\\eta} = \\frac{\\sum_{l=1}^{N} p_{l,k+1}}{N}$\nwhere N represents the batch size and $\\hat{\\eta}$ is the currently applied abstention of the classifier per batch. As the direct computation of the ratio of abstained data points in a batch is not differentiable (due to argmax), $\\hat{\\eta}$ is approximated by summing the softmax outputs of the abstaining neuron with division by N. Note that the noise estimation $\\tilde{\\eta}$ is included in the regularization term.\nIf the model abstains to many samples during training compared to the noise estimation $\\tilde{\\eta}$, the regularization term increases and leads to a stronger penalization for abstaining. This can result in a reduction of abstained samples, ideally excluding correct (but difficult to learn) training samples during the abstention. A too-low abstention rate compared to the noise estimation $\\tilde{\\eta}$ during training also results in a high regularization term. Minimizing the penalty term leads to an increase of abstained samples. The goal is to exclude more noisy label samples during training to minimize the effects of noise overfitting on the training performance.\nCompared to the DAC loss, $\\alpha$ remains constant and is independent of the number of training epochs. This can lead to a more user-friendly training process and a less complex hyperparameter search. Additionally, the utilized model does not have a significant increase of parameters, as only a single additional output neuron is required. The IDAC therefore represents a easy-to-implement and easy-to-apply noise-robust classifier, that does not require a more complex training schedule (e.g. a significantly increased number of training weights, hyperparameters, or training runs).\nNote that due to the inclusion of the expected percentage of noise per batch in the IDAC loss, we recommend implementing high batch sizes during IDAC training to obtain a more realistic representation of the noise distribution per batch."}, {"title": "2.3 Experiments", "content": "We apply DenseNet-121 [8] with ImageNet [1] pretrained weights from PyTorch as an established model for processing lung diseases in chest X-ray images [9,24]. Motivated by the DAC paper [31], the model is trained with the stochastic gradient descent for 300 epochs with a momentum of 0.9, a weight decay of 5e-4 and a batch size of 512. The learning rate of 0.1 is decreased at epoch 100 and 250 by factor of 0.1. For the pleural effusion subset of CheXpert 500 epochs are trained to ensure convergence. All images are ImageNet normalized, reshaped to the size 224 x 224 and augmented by affine transformations during training. As CNNs tend to learn relevant features during the initial training phase, even with noisy labels [39], the IDAC and DAC are first trained by applying the CE loss to all k+1 output neurons (including the abstention neuron) in a warm-up phase. For classifying pleural effusion in the CheXpert data set the warm-up phase is set to 10 epochs. As the in-house pleural effusion and the CheXpert cardiomegaly data sets feature less training samples, we perform a hyperparameter search for DAC and IDAC (warm-up \u2208 {10,30,50} epochs). Additionally, the hyperparameter ($\\alpha$\u2208 {1, 10, 20}) is included in the search to investigate the influence of $\\alpha$ when training IDAC with different noise levels.\nFor all simulated noise experiments, the IDAC loss utilizes the percentage of simulated noise as $\\tilde{\\eta}$. Note that this represents only a noise estimation due to the inherent noise of the CheXpert data set. For the analysis of 0% simulated noise, we use an estimated noise level $\\tilde{\\eta}$ of 0.5% due to the inherited noise of the CheXpert dataset. For training with the clinical in-house data set, we employ an upper estimate of 5% for the expected noise.\nFor both IDAC and DAC the abstain neuron $p_{k+1}$ is excluded from inference on the validation and test set, as we assume that these manually annotated sets do not include noisy labels.\nTo enable a fair comparison, we focus on noise-robust loss functions as baseline functions. Other state-of-the-art methods that lead to an increased number of training parameters [6], several additional hyperparameters [34], or are an aggregation of multiple techniques [12, 18] do not, in our opinion, provide a fair comparison to the easily tuned and trained IDAC loss. We therefore implement the CE and SCE loss, as well as the DAC as baseline. For the less extensive cardiomegaly data set we additionally analyzed the performance of the normalized cross entropy (NCE), the normalized generalized cross entropy (NGCE) and asymmetric generalized cross entropy (AGCE) loss. Although they achieved exceptional performance on commonly used computer vision baseline datasets like CIFAR10 [38], we were unable to achieve comparable performance to the other baseline functions for the more complex medical image use case after a reasonable grid search. The obtained results and implemented hyperparameter searches are included in the appendix 4."}, {"title": "3 Results", "content": "Noise Robustness AUROC scores on the hold-out test sets of the CheXpert data are given for all investigated losses trained on different simulated noise levels for all use cases in Table 1, Table 2, Figure 1 and Figure 2.\nAs expected the performance decreases in general for all loss function with increasing noise levels. This is most effectively mitigated by the proposed IDAC loss. Here, IDAC training achieves the highest performance for classifying pleural effusion and cardiomegaly in six out of seven noise levels.\nFor the two cases where IDAC does not reach the highest score, it still outperforms two of the three baselines, there is only a small discrepancy to the best score. This indicates that the IDAC training has the potential to improve noise robustness, for data sets of both substantial and smaller sizes. The direct comparison to the DAC performance underlines that the abstaining loss functions benefit from the prior knowledge of the expected noise.\nIt can be seen, that low noise levels like 3% reduce the CE performance, stressing the importance of analyzing practically relevant low noise levels below 15% of noise for noise-robust training in medical image analysis. If there is no simulated noise, a very low inherited noise level can be expected. The IDAC loss outperforms the considered baselines by up to 2.4%, stressing its usability to work with low noise levels.\nFor the high noise level 50% a significant improvement can be achieved by the cardiomegaly IDAC approach compared to the commonly used CE and SCE loss functions.\nTable 3 shows detailed performance metrics for all investigated losses on the in-house data set of clinical routine. IDAC training achieves the highest performance for classifying pleural effusion in four out of five performance metrics. Compared to conventional CE training, the AUROC score can be improved by up to 5%. The results underline the strong noise-robustness of the IDAC loss, even for real-life noisy data sets. The IDAC can contribute to more reliable DDSS with datasets from clinical routine without additional implementation effort. The inclusion of further clinical in-house data experiments with various noise levels represent future work, to strengthen the evaluation of the IDAC loss."}, {"title": "4 Conclusion", "content": "Noise-robust training is key for the development of deep learning based DDSS from routine clinical image data. This work therefore introduces the noise-robust IDAC loss that incorporates an estimation of the expected noise during training. The IDAC improves noise robustness when evaluated for both simulated and real-world noisy medical imaging datasets. Compared to conventional CE training, the AUROC score improves by 5% for experiments on in-house clinical data and up to 7% for simulated noise scenarios. Besides higher performance,"}, {"title": null, "content": "the IDAC offers a simple implementation without increasing model complexity and greater usability by lower tendency to overfit. The IDAC can therefore be a valuable tool for researchers, companies or clinics that want to develop accurate and reliable DDSS from routine clinical data.\nThe further development of the IDAC from multi-class classification to the medically highly relevant multi-label classification represents future work. Additionally, we want to investigate the influence of inaccurate noise estimations to further evaluate the robustness of the introduced approach."}, {"title": "Additional Baseline Analysis", "content": "We analyze the potential baselines normalized cross entropy (NCE) [16], normalized generalized cross entropy (NGCE) [16] and asymmetric generalized cross entropy (AGCE) loss [38] for the cardiomegaly data set and a simulated noise level of 15%. For each loss we implemented a reasonable grid search with the following hyperparameters:\nNC: learning rate \u2208 [0.1,0.01]\nNGCE: learning rate \u2208 [0.1, 0.01], q \u2208 [0.25, 0.5, 0.75]\nAGCE: learning rate \u2208 [0.1, 0.01], q \u2208 [0.25, 0.75, 1.25], a \u2208 [0.25, 0.75, 1.25]\nThe implementations are based on the code available in [38]. Due to the low performance for the more complex medical image use cases, the loss functions NC, NGCE, and AGCE are not considered as baselines going forward."}]}