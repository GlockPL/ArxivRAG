{"title": "Multi-layer Sequence Labeling-based Joint Biomedical Event Extraction", "authors": ["Gongchi Chen", "Pengchao Wu", "Jinghang Gu", "Longhua Qian", "Guodong Zhou"], "abstract": "In recent years, biomedical event extraction has been dominated by complicated pipeline and joint methods, which need to be simplified. In addition, existing work has not effectively utilized trigger word information explicitly. Hence, we propose MLSL, a method based on multi-layer sequence labeling for joint biomedical event extraction. MLSL does not introduce prior knowledge and complex structures. Moreover, it explicitly incorporates the information of candidate trigger words into the sequence labeling to learn the interaction relationships between trigger words and argument roles. Based on this, MLSL can learn well with just a simple workflow. Extensive experimentation demonstrates the superiority of MLSL in terms of extraction performance compared to other state-of-the-art methods.", "sections": [{"title": "1 Introduction", "content": "Biomedical event extraction (i.e., BEE) is an essential task for extracting key information from the massive biomedical literature, receiving mounting attention in the NLP community in recent decades [5]. The overall workflow of BEE is shown in Fig. 1. Given an input sentence (e.g., \"... FOXP3 promoting factors, such as dexamethasone, CTLA-4...\"), the entity mentions (e.g., \"FOXP3\" and \"CTLA-4\" with \"GENE\" type), BEE needs to recognize the trigger word (e.g., \"promoting\" with the \"Positive Regulation\" type) and the corresponding arguments (e.g., a theme argument \"FOXP3\" and a cause argument \"CTLA-4\") simultaneously. Afterwards, the final biomedical events (e.g., two \"Positive Regulation\" events <PoRe, promoting, cause, CTLA-4>and <PoRe, promoting, theme, FOXP3>) are obtained by a simple assembling rule: a regulation event may have a theme argument and a single cause argument.\nIn a bid to simplify the workflow, we propose a method based on multi-layer sequence labeling for joint biomedical event extraction, namely MLSL. It's a data-driven method that does not introduce complex prior knowledge such as knowledge graphs or dependency parsing, while it only learns from the input data. Additionally, we designed MLSL as the pipeline paradigm so that it can first recognize trigger words using a trigger layer, and then explicitly merge the information of those candidate trigger words into the hidden representation. Empirical results show that the MLSL without complex structures outperforms other state-of-the-art methods on BEE. In addition, the information of trigger words can be very useful to assist the argument recognition in order to improve the overall performance of BEE."}, {"title": "2 Methods", "content": ""}, {"title": "2.1 Overall workflow of MLSL", "content": "The ultimate goal of joint learning of trigger recognition and argument recognition is to extract biomedical events in the form of a quadruple like <type, trigger word, argument role, argument>. There are usually two types of argument roles [5]: one is the theme role, which refers to arguments whose attributes"}, {"title": "2.2 Labeling schema", "content": "Our proposed MLSL has a multi-layer sequence labeling decoder consisting of the trigger layer, the theme layer and the cause layer, each of which decodes (i.e., predicts) a specific type of labels using the BIO labeling scheme to easily convert the biomedical event into the multi-layer sequence labeling representation.\nAs illustrated in Fig. 3, the BIO scheme is sufficient to label different types of trigger words. For instance, the trigger word \"phosphorylation\" with the type of \"phosphorylation\" is tokenized into the tokens \"phosphory\" and \"##lation\", each of which is assigned to the \"B-Phos\" label and the \"I-Phos\" label respectively. Similarly, the trigger word \"induced\" with the type of \"Positive Regulation\" is assigned to the \"B-PoRe\" label.\nFor argument labeling, we use the four labels of \"Left1\", \"Left2\", \"Right1\", and \"Right2\" to label the position of argument roles relative to a specific trigger word. In detail, \"Left1\", \"Left2\", \"Right1\", and \"Right2\" respectively indicate that the trigger word belonging to the argument is the 1st/2nd trigger word on its left/right. In other words, arguments that have more than 2 other trigger words away will be discarded. That's because those arguments only account for ~ 4%/~ 3% in the GE11 train/dev set and ~ 3%/~ 5% in the GE13 train/dev set according to our statistics. Furthermore, these arguments can be hardly recognized due to their long distance from the trigger words in our preliminary experiment. Consequently, discarding these arguments will not have a major impact on the event extraction performance. Fig. 3 shows an example of the theme/cause later. The token \"@GENE@\" next to the token \"\" is assigned to the \"B-Right1\" label, because \"@GENE@\" is the cause argument of the 1st right trigger word \"induced\". Likewise, the word \"Smad1/5/8\" which"}, {"title": "2.3 Multi-layer sequence labeling", "content": "As shown in Fig. 2, we decode the arguments and trigger words using the multi-layer sequence labeling manner, including the trigger layer, the merging layer, the cause layer and the theme layer.\nTrigger layer The operation of the trigger layer is shown in the Eq. (1) and Eq. (2). The hidden representation h\u1d62 \u2208 \u211d\u1d48 of the i-th token is fed into a full-connected layer and then a softmax operation, to obtain the probabilities Ptr of trigger labels. After that, the trigger label with the largest probability \u0177tr is selected as the result of the i-th token.\nP\u209c\u1d63 = softmax(W\u209c\u1d63h\u1d62 + b\u209c\u1d63) (1)\n\u0177\u209c\u1d63 = argmax(P\u209c\u1d63) (2)\nwhere, W\u209c\u1d63 \u2208 \u211d\u1d48\u00d7|Y\u209c\u1d63| and b\u209c\u1d63 \u2208 \u211d\u1d48 are the weight and bias of the trigger layer respectively. Y\u209c\u1d63 is the label space of the trigger words.\nMerging layer The merging layer is used to merge the information of the trigger word predicted by the trigger layer with the subsequent theme/cause layer. For each token x\u1d62, we collectively refer the trigger words predicted not more than two on its left and those not more than two on its right in the trigger layer as its corresponding candidate trigger words, denoted as C\u1d62. Additionally, we assign label embedding l\u1d62 \u2208 \u211d\u1d48 of the trigger word labels (e.g., \"B-Phos\" label, \"O\" label) or entity labels (\"B-Gene\" label) to each token. It is notable that the label embedding is randomly initialized for each trigger word label and entity label, and it will be updated during the training process. For each token x\u1d62 in the merging layer, we first concatenate its label embedding l\u1d62 and its hidden representation h\u1d62 to get its role representation r\u1d62:\nr\u1d62 = concat(l\u1d62, h\u1d62) (3)\nAfter that, every candidate trigger word in C\u1d62 owns its role representation. To explicitly employ such information, for each token x\u1d62, we merge C\u1d62 with its hidden representation h\u1d62 to get its merging representation m\u1d62 in three ways:\nAverage: As described in Eq. (4) and Eq. (8), we concatenate the average of the role representation of C\u1d62 to its hidden representation h\u1d62, to get the merging representation m\u1d62 of the token x\u1d62."}, {"title": "Theme/Cause layer", "content": "Based on the merging representation output from the merging layer, the theme layer and the cause layer predict theme arguments and cause arguments respectively. We first calculate the probabilities Pt/c of theme/cause argument labels in (9). Then, we obtain the theme/cause argument labels by selecting the largest probability \u0177t/c as the result of the i-th token.\nP\u209c/c = softmax(W\u209c/c m\u1d62 + b\u209c/c) (9)\n\u0177\u209c/c = argmax(P\u209c/c) (10)\nwhere W\u209c \u2208 \u211d\u1d48\u00d7|YT| and Wc \u2208 \u211d\u1d48\u00d7|YC| are the weights of the theme layer and the cause layer respectively. And bt, bc \u2208 \u211d\u1d48 are biases of the theme layer and the cause layer respectively.\nMulti-layer loss The trigger layer, the theme layer and the cause layer each perform a multi classification task separately. Therefore, we utilize cross-entropy to train each of them. The total loss of the MLSL is the sum of the losses of the three layers, i.e., L = L\u209c\u1d63 + L\u209c + Lc, which is a multi-task learning loss."}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Setup", "content": "Datasets We train and evaluate our MLSL on the BioNLP11-GE\u00b3(i.e., GE11) [7] and BioNLP13-GE (i.e., GE13) [8], whose specific statistics are illustrated in Table 1. Both GE11 and GE13 provide entity mentions for each sentence. Hence, we should predict the correct events for each sentence given the entity mentions.\nEvaluation The official BioNLP shared tasks provide online evaluation tools\u2075. Usually, the results of the approximate span matching and approximate recursive matching are used as the final results of the test set. Approximate span is the predicted span that can be different from the gold span within a single token. Approximate recursive is a rule for nested events, under which even if a sub-event is partially correct, it is considered a correct event. Three standard metrics including precision (P), recall (R) and micro-averaging F1-score (F1) are used to evaluate performance. We train and validate the MLSL 5 times using different random seeds, and select the checkpoint with the best results on the dev set for subsequent evaluation, where we get the average scores of 5 runs with different random seeds are adopted as the final results.\nSetting We implement our model using PyTorch\u2077 and transformers\u2078. The Hyper-parameter values and search space are listed in Table 2."}, {"title": "3.2 Comparison of different merging method", "content": "Table 3 shows the micro F1 results of using different merging methods in different tasks of the GE11 and GE13 development sets. Here, the \"None\" method means that there is no merging layer to merge the information of the candidate trigger words. \"Trg\", \"Arg\" and \"Eve\" indicate the trigger extraction task, the argument extraction task and the event extraction task, respectively. \"Avg\", \"Att\" and \"Self-att\" are short for the average merging method, the attention merging method and the self-attention merging method, respectively. It can be found that the self-attention merging method achieves the best performance in all tasks, compared to the other merging methods. This may be due to the use of more trainable parameters (e.g., WQ, WK and Wv) in this method, allowing the role representation of each token to better focus on and integrate information from its candidate trigger words. According to such a result, we choose the self-attention merging layer for our MLSL to compare with other baselines."}, {"title": "3.3 Comparison with other systems", "content": "In order to demonstrate the effectiveness of our proposed MLSL, we select several representative pipeline and joint methods for biomedical event extraction as baselines, which are listed below.\nTEES-CNN [3]: A pipeline system for event extraction that operates by sequentially carrying out the extraction of entities, arguments, and events, with each component utilizing a CNN-driven sentence encoding framework.\nKBTL [11]: The KB-Tree LSTM model (short for KBTL) is a pipeline method that introduces an external knowledge base to the tree structured LSTM to enhance the semantic representation of words.\nWu et al. [24]: A pipeline approach sequentially performing trigger identification, argument roles recognition and final event construction, which employ a n-ary relation extraction method to alleviate errors in event construction.\nDeepEventMine [19]: A joint end-to-end method for nested event extraction, which is capable of extracting multiple, intersecting directed acyclic graph (DAG) structures directly from the raw text.\nCPJE [23]: A joint system for event extraction that uses the Graph Convolutional Neural Networks (i.e., GCN) [9] to model the dependency information.\nZhao et al. [26]: An improved RL-based framework for multiple biomedical event extraction. It employs a self-supervised-based data augmentation method for biomedical entities and event triggers in raw texts."}, {"title": "3.4 Discussion and analysis", "content": "Empirical analysis For the purpose of further analyzing the recognition performance of the MLSL, we record its performance for recognizing different types of trigger words in Table 5. There are 9 types of events in GE11, while GE13 adds an additional 4 types of events (i.e., \"PrMo\", \"Ubiq\", \"Acet\" and \"Deac\") based on this. However, these 4 types of events are too sparse, accounting for less than 1% in the train, dev, and test sets. Therefore, we will not list their recognition performance. In Table 5, we can see that the MLSL cannot effectively identify the \"Tran\" event and the \"Regu\" event, resulting in a decrease in overall performance. For the \"Tran\" event, it accounts for a relatively small proportion compared to other simple events (e.g., \"GeEx\", \"PrCa\", \"Phos\" and \"Loc\"), so that the data-driven MLSL cannot effectively recognize the \"Tran\" type event. In terms of the \"Regu\" event, it is a nested event containing theme and cause (may not) Argument.\nTo analyze the performance of the \"Regu\" event, we record the performance of the MLSL for identifying different argument roles in Table 6. We can observe that the MLSL is better able to recognize the theme arguments compared to the cause arguments. This may be due to the lower proportion of cause arguments in the dataset compared to the theme arguments. Based on this observation, we can infer that the recognition performance of the \"Regu\" event is influenced by the recognition performance of the cause arguments."}, {"title": "Complexity analysis", "content": "To simplify the workflow of biomedical event extraction, we use a data-driven method by introducing the Merging layer. Here, we mathematically prove that the cost of the Merging layer is acceptable from two aspects, time complexity and space complexity.\nTime Complexity: We measure time complexity using Floating-point Operations (FLOPs). Without loss of generality, we only consider General Matrix Multiplications (GEMMs) as they are the main component of floating-point operations. Here, we take the self-attention merging method, which has the highest computational complexity, as an example. It consists of 3 steps. First, the total FLOPs of query/key/value matrix transformation (i.e., Wx term) is 2 \u00d7 (2b \u00d7 d\u2095 \u00d7 |C| + s \u00d7 d\u2095 \u00d7 d). Second, the total FLOPs of self-attention score (i.e., QKT term) is 2\u00d7 (b\u00d7 |C| \u00d7 d\u2095 \u00d7 s). Third, the total FLOPs of self-attention weighted sum of value matrix (i.e., AV term) is 2x (bxsx|C|\u00d7d\u2095). Here, b is the batch size, s is the sequence length of an instance with a maximum of 512, d\u2095 is the hidden size of the query/key/value matrix which is set to 768, d is the hidden size of the model which is also set to 768 and C is the average size (up to the maximum of 4) of the candidate trigger words of each token. Thus, the FLOPs of the Merging layer is about 768.375M FLOPs. When using GPU\u2079, the forward propagation process of the Merging layer consumes much less than 1 second.\nSpace Complexity: We measure space complexity using training parameters. Here, we take the self-attention merging method, which has the most training parameters, as an example. In self-attention merging method, we merely introduce a query matrix W\u0119, key matrix WK and a value matrix Wv. Here,"}, {"title": "4 Related works", "content": "Biochemical event extraction (i.e., BEE) is a long-standing traditional and important task in the NLP domain [18,14,21]. Such a task has been dominated by deep learning methods in recent years because neural networks can automatically capture complex features and eliminate the need for feature engineering [5]. There are two main deep learning paradigms used to solve biochemical event extraction: pipeline and joint.\nThe pipeline method uses an encoder like BiLSTM [12], CNN [3] or a Bert-like model (e.g., SciBERT [2]) to encode the input text. Then it sequentially extracts trigger words, arguments and argument roles, in which errors are accumulated. To better capture the sentence information, dependency parsing tree [3] and abstract meaning representation [17] are introduced to model the semantic or syntactic information. In addition, external knowledge has been proven to be beneficial for improving the performance of BEE [11]. Through analyzing the data distribution, Wu et al. [24] found that the \"Binding\" type events have a significant impact on the results of the GE11 and GE13 corpora.\nThe joint method is proposed to address the issue of error accumulation in pipeline methods [21]. Through parameter sharing, it can also reduce computational costs and enhance information exchange between subtasks (i.e., trigger words recognition and arguments recognition) [19,25]. However, in order to identify nested events, it is still necessary to use complex structures (e.g. graphs [6,23]) or multi-turn reinforced agent [26] to construct the joint method. Ramponi et al. [16] designed sophisticated label schema to cast joint BEE into a sequence labeling problem. Wang et al. [22] transformed BEE into a multi-round question answering task, sequentially identifying the trigger word corresponding to the given entity and other arguments of that predicted trigger word."}, {"title": "5 Conclusion and future works", "content": "In this work, we propose the MLSL, a system based on multi-layer sequence labeling for joint biomedical event extraction. It is a data-driven method, which does not introduce prior knowledge and complex structures, merging explicitly the information of candidate trigger words into the sequence labeling, leading to excellent performance in extensive experiments. However, not all event types and argument types can be effectively identified by the MLSL. Therefore, in the future, we will attempt to use data augmentation methods to address the issue of imbalanced distribution of data class. Based on that, we will also try using models with stronger generalization capabilities to solve BEE tasks."}]}