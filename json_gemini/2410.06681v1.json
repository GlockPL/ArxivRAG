{"title": "AI, Climate, and Regulation: From Data Centers to the AI Act", "authors": ["Kai Ebert", "Nicolas Alder", "Ralf Herbrich", "Philipp Hacker"], "abstract": "We live in a world that is experiencing an unprecedented boom of AI applications that increasingly penetrate and enhance all sectors of private and public life, from education, media, medicine, and mobility to the industrial and professional workspace, and potentially particularly consequentially-robotics. As this world is simultaneously grappling with climate change, the climate and environmental implications of the development and use of AI have become an important subject of public and academic debate. In this paper, we aim to provide guidance on the climate-related regulation for data centers and AI specifically, and discuss how to operationalize these requirements. We also highlight challenges and room for improvement, and make a number of policy proposals to this end. In particular, we propose a specific interpretation of the AI Act to bring reporting on the previously unadressed energy consumption from AI inferences back into the scope. We also find that the AI Act fails to address indirect greenhouse gas emissions from AI applications. Furthermore, for the purpose of energy consumption reporting, we compare levels of measurement within data centers and recommend measurement at the cumulative server level. We also argue for an interpretation of the AI Act that includes environmental concerns in the mandatory risk assessment (sustainability risk assessment, SIA), and provide guidance on its operationalization. The EU data center regulation proves to be a good first step but requires further development by including binding renewable energy and efficiency targets for data centers. Overall, we make twelve concrete policy proposals, in four main areas: Energy and Environmental Reporting Obligations; Legal and Regulatory Clarifications; Transparency and Accountability Mechanisms; and Future Far-Reaching Measures beyond Transparency.", "sections": [{"title": "1 Introduction", "content": "The environmental consequences of artificial intelligence (AI) are becoming ever more apparent as large models are increasingly trained and deployed across society. This inherently intertwines the digital transformation with questions of climate change, particularly concerning the energy and water consumption of AI models. These features are attracting attention from both the public and academia"}, {"title": "2 Technical Background", "content": "To lay the ground for the subsequent legal and technical analysis, we start by introducing some core technical aspects of AI models.\nFrom a technical perspective, it is important to distinguish between training, fine-tuning, and inference. Training, on the one hand, refers to the process of initially adjusting a model's parameters or weights to fit the data. This process is highly compute-intensive and typically requires a significant amount of energy [12, 11, 21, 7]. The terms training and pre-training are used interchangeably. The pre-training step involves training an LLM on large-scale data. LLM performance strongly depends on the model scale (number of parameters), which also requires more training data [9, 17]. Therefore, a continuous scaling of the models and thus also of the energy and resource consumption is to be expected, which can also be observed through the continuous publication of new and ever larger models. It is currently not possible to assess when an actual saturation of model performance will occur [19], as evaluation metrics, available data and tasks are also subject to ongoing adaptation and development.\nFine-tuning aims at adjusting a pretrained model to fit more specific data in order to perform better at specific tasks. It is usually performed by retraining specific parts or even the full model. One can also add layers or model architecture components to better account for the new data or task. Overall, fine-tuning follows pre-training and involves a significantly smaller amount of training data and compute budget. The specific procedure for successful fine-tuning is very model-, data-, and task-specific, and rather empirical. Therefore, the computational and energy-intensity can vary significantly for this step. For example, as highlighted by Luccioni et al. [12], the energy usage for fine-tuning the Bloomz-7B required 7,571 kWh compared to 51,686 kWh for the entire training process, adding another 15% to the inital consumption. Fine-tuning and other related methods enable researchers and companies to make use of large-scale models which would otherwise be prohibitively expensive."}, {"title": "3 Regulation on Data Centers", "content": "Data centers run all kinds of operations, such as cloud computing, crypto currencies and the Internet at large. Recently, AI training and inference have experienced massive growth. Broad data center regulation, therefore, indirectly governs environmental effects of AI and constitutes the backdrop against which specific AI regulation must be viewed. Taking a look at the requirements for data centers can help to find a coherent and effective interpretation of the requirements in the AI Act as it builds on already available data and established methodology.\nEU rules stipulate data collection and reporting obligations for data centers (see subsection 3.1) and mandatory energy audits (subsection 3.2). However, they lack binding efficiency and renewable energy targets. Most of these EU rules need national implementation by Member States. Notably, the German implementation goes much further by broadening the scope and putting in place additional requirements, including energy efficiency and renewable energy targets for data centers (subsection 3.3)."}, {"title": "3.1 EU Data Collection and Reporting Obligations for Data Centers", "content": "In the EU, data collection and reporting obligations for data centers were established by two recent legal acts, Art. 12 of the recast Energy Efficiency Directive EU/2023/1791 of September 13, 2023 (\"EED\"), and the Commission Delegated Regulation EU/2024/1364 of March 14, 2024 (\"Delegated Regulation\"). The new rules apply to all data centers in the EU with a power demand of the installed information technology (IT) of at least 500kW, which includes small-sized data centers. Data center operators are required to collect, make publicly available and report to a EU database information that is deemed relevant for the sustainability assessment of the data centers and the industry as a whole. The reporting is mandated on an annual basis.\nThe required data includes energy consumption, power utilization, temperature set points, waste heat utilisation, water usage and use of renewable energy (EED, Annex VII(c)). Notably, while the EED focuses on energy and power, the reporting of water usage is a significant step forward as both energy and water consumption have raised concerns in AI settings [10, 12]. In addition, the Water Framework Directive can be harnessed to limit the overall amount water a data center may consume, and also control for any potential loss of water quality [4].\nThe Delegated Regulation provides specific key performance indicators and methodology. Most notable is the requirement to measure and report the energy consumption of the installed information technology. Following the standard-methodology for the calculation of PUE, the energy consumption must be measured at the uninterruptible power system (UPS) or, if not existent, at the power distribution unit (PDU) or at another point specified by the data center (see Delegated Regulation, Annex II(1)(e)). These options are depicted in Figure 1 as Categories 1-3.\nPrior to the issuance of the Delegated Regulation, the Commission conducted an expert study on the options for a reporting scheme, which the Commission broadly followed. Even though it might be more accurate to measure the energy consumption closer to the ICT equipment, the study recommends the UPS as a primary measuring point. Measuring directly at the ICT equipment is deemed impractical because colocation data centers have no direct access to the ICT equipment housed for their customers. Measuring at PDU level is also considered impractical because many data centers do not yet have the equipment to measure energy consumption after the UPS. The UPS is also the easiest point to implement measuring for those who have no measurement in place"}, {"title": "3.2 Energy Management Systems and Energy Audits", "content": "The EED also requires that Member States mandate companies with an average annual energy consumption of more than 10 TJ to conduct an energy audit at least every four years and those with a consumption of more than 85 TJ to implement an energy management system including regular energy audits (Art. 11 EED). This would also apply to operators of data centers. The Directive sets up certain minimum criteria for energy audits (Annex VI EED) and refers to the relevant international or European standards (Recital 80 EED). The legal minimum criteria, however, do not dictate methodology on measurement of energy consumption."}, {"title": "3.3 German 2023 Energy Efficiency Act", "content": "In Germany, the Energy Efficiency Act of 8 Nov 2023 implements the EED and establishes a national reporting scheme and additional requirements, including specific efficiency and renewable energy targets for data centers.\nThe Act broadens the scope of the reporting obligation to include even smaller data centers, upwards of 300 kW (Sec. 13). It also expands the duty to set up an energy management system to data centers and operators of ICT-i.e., customers of colocation data centers of more than 50 kW (Sec. 12). Most importantly, it sets targets on energy efficiency and renewable energy use, requiring data centers to reach a PUE factor between 1.5 and 1.2 and an ERF of 10% to 20% depending on their age (Sec. 11) and to run on 50 % renewable energy, increasing that factor to 100% by 1 Jan 2027 (Sec. 11).\nLastly, it requires data center operators to inform their customers on an annual basis on the energy consumption directly attributable to them (Sec. 15).\nWhile this implementation goes much further than the EED, it does not provide more detailed methodology. However, the German law may serve as a blueprint for further European regulation for efficiency and renewable energy targets. Especially the obligation to inform customers of their attributable energy consumption may prove an important prerequisite for AI developing companies to optimise energy consumption."}, {"title": "3.4 Bill in the U.S. Sentate for a 2024 AI Environmental Impacts Act", "content": "On 1 Feb 2024, the bill for an AI Environmental Impacts Act was introduced in the U.S. Senate by Senator Edward J. Markey (D-MA). The bill was referred to the Committee on Commerce, Science and Transportation and there has not yet been a vote. The future of the bill is therefore unclear.\nEven if enacted, it would not contain any significant hard regulation. The bill orders the Environmental Protection Agency (EPA) to conduct a comprehensive study on Al's environmental effects (Sec. 4) and requires the National Institute of Standards and Technology (NIST) to convene a consortium of stakeholders to identify the future measurements, methodologies, standards, and other appropriate needs to measure, report, and mitigate the environmental impacts of artificial intelligence (Sec. 5). It further requires NIST to develop a system for voluntary reporting of environmental impacts of artificial intelligence (Sec. 6). The EPA, NIST and the Department of Energy are to report to Congress on these three measures within four years (Sec. 7)."}, {"title": "3.5 Interim Conclusion on Data Center Regulation", "content": "The regulation of data centers in the context of AI's environmental impact, particularly regarding energy and water consumption, presents both advantages and shortcomings. The increasing growth of AI-related activities, such as training and inference, places significant pressure on the environmental footprint of data centers. While the EU has implemented generic data center regulations, such as those outlined in the Energy Efficiency Directive and the Delegated Regulation, these rules also indirectly govern the environmental impact of AI by imposing reporting and data collection requirements. Notably, these regulations require the reporting of both energy and water consumption, a critical aspect given the rising concerns over resource use in AI applications.\nOne of the key strengths of the EU's approach is the establishment of specific reporting obligations. Data center operators must collect and publicly report energy consumption, power utilization, water usage, waste heat utilization, and the use of renewable energy. These measures help create trans- parency and provide a foundation for future efficiency improvements. Additionally, the German implementation of the EED goes beyond mere reporting by setting specific targets for energy efficiency and renewable energy use in data centers, as well as requiring smaller data centers to comply. Germany's approach might serve as a potential blueprint for broader EU regulation, particularly with its mandates to inform customers about their direct energy consumption, an essential factor for optimizing AI-related energy use.\nHowever, the regulations also present several shortcomings. While data collection and reporting obligations are useful, the absence of binding efficiency and renewable energy targets at the EU level is a major limitation. Although the Commission is expected to propose further legislative measures by 2025, the current lack of enforceable standards means that data centers could continue to consume vast amounts of energy and water without significant reductions in their environmental impact. Moreover, while Germany has introduced stricter targets, these do not extend to all Member States, potentially leading to a fragmented regulatory environment across the EU.\nThe situation in the U.S. contrasts with the EU approach. While a bill for an AI Environmental Impacts Act was introduced in the Senate, it remains unenacted and proposes only voluntary measures, such as studies and recommendations by federal agencies and institutions (EPA, NIST). The lack of binding rules for data centers in the U.S. means that AI's environmental footprint could grow unchecked unless future legislation introduces more concrete regulatory measures."}, {"title": "4 AI Act: Gaps and Interpretation Challenges", "content": "The AI Act applies further down in the value chain, targeting entities that develop and deploy AI systems. After introducing the key terminology used by the Act, we discuss the major climate-related obligations contained in it, with a particular focus on transparency, risk assessment and mitigation. As our analysis shows, the Act makes steps in the right direction, but fall short of a comprehensive regime for tackling climate-related risks of AI models."}, {"title": "4.1 Terminology of the AI Act: AI Models and Systems, Providers and Deployers", "content": "The AI Act only applies if an AI model or AI system is used by a specifically designated entity, such as a provider or deployer. The activity also needs to relate to the EU, typically either because the system is offered to persons in the EU or because its output is used in the EU (Art. 2(1) and Recital 22 AI Act).\nAn AI model, though not explicitly defined in the AI Act, is understood to be a machine learning model that is trained on data and comprised of the parameters and the model architecture (Recital 104). AI models require the addition of further components, such as a user interface, to become AI systems (Recital 97). An AI system, in turn, is defined as a machine-based system 'designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments' (Art. 3(1)).\nKey actors in the AI value chain include providers and deployers. Providers develop or market AI models or systems (Art. 3(3)) while deployers use existing AI systems in a professional capacity (Art. 3(4)). Note that other operationally relevant actors, such as cloud service providers, data providers, data center operators, or other intermediaries are not directly subject to AI Act rules.\nThe Act pays specific attention to general-purpose AI (GPAI) models, e.g., large language models (LLMs) like GPT-4, that are defined by the wide range of possible uses. Those with the most advanced capabilities, and therefore higher risk of negative effects, are labeled GPAI models with systemic risk (Art. 3(63)-(65)). An AI system that integrates a GPAI model is a general-purpose AI system (Art. 3(66)), e.g. ChatGPT. AI systems used in specific settings subject to product safety regulation, e.g., medical devices, and areas particularly sensitive for public safety or fundamental rights, e.g., law enforcement, migration, education, employment, credit scoring, health or life insurance, are called high-risk AI (HRAI) systems. These systems are subject to other rules, concerning training data, documentation, human in the loop and performance, inter alia (Art. 9-16). When GPAI systems are used in high-risk applications, rules may apply cumulatively (Recital 85, 97)."}, {"title": "4.2 Provider or Deployer Status", "content": "The AI Act contains energy- and climate-related transparency and risk management obligations, primarily for providers of AI systems or models. Under certain conditions, however, deployers turn into providers, which triggers much more onerous duties, also with respect to climate impacts. Hence, there is a palpable incentive for companies to avoid provider status.\nConcerning HRAI systems, pursuant to Art. 25(1), deployers can become providers if they market an existing HRAI system under their name or trademark, substantially modify an HRAI system or change the intended purpose of a non-high-risk AI system such that it falls under one of the high-risk sectors (e.g., employment; life- or health insurance; education). Specifically, if a deployer uses a GPAI system, such as ChatGPT, in a high-risk setting, for example by harnessing it for resume screening in hiring, they automatically assume the responsibilities of a provider of a HRAI system (Art. 25(1)(c)).\nAn existing HRAI system can be altered. If the modification is substantial, the modifying entity becomes a new provider (Article 25(1)(b)). It is unclear, however, what precisely constitutes a \"substantial modification\" that would trigger provider status for the modifying entity. A formal interpretation suggests that any change to the model could be deemed substantial, based on Art. 3(23), which defines substantial modification as any unplanned change affecting compliance or intended purpose. On the other hand, a more convincing-material interpretation would claim that provider status should only apply if the modification increases the model's risk in a nonnegligible way. This aligns with the AI Act's focus on risk mitigation, and also the language in Article 3(23) according to which any significant modification must affect compliance with the high-risk rules of the Act (or change the purpose).\nFor GPAI models, Recitals 97, 109, and 111 suggest that any entity performing even minimal fine- tuning of a GPAI model is automatically classified as the provider of a new model, including all associated responsibilities [1]. For minor modifications this is disproportionate, even if Recital 109 states that obligations are limited to the fine-tuning itself [1]. A solution could be an analogy with"}, {"title": "4.3 Transparency", "content": "The first climate-related obligation in the AI Act concerns transparency and reporting, but not with respect to data centers, but concerning providers of high-risk and GPAI models [1].\nHowever, the rules come with significant ambiguities and loopholes. In the following, we detail the six most important ones.\n1) For high-risk AI systems, pursuant to Article 11(1) providers must document the computational resources utilized during the development, training, testing, and validation stages, as outlined in Annex IV(2) which does, however, not inlcude the energy consumption directly [1]. This omission hinders the capacity to evaluate and compare the environmental impact of such systems accurately. As a result, the environmental footprint must be estimated indirectly based on the recorded computational resources.\n2) The AI Act requires providers of general-purpose AI models to meet transparency obligations. Article 53(1)(a) mandates that providers maintain up-to-date technical documentation, including the details outlined in Annex XI. This annex requires the reporting of energy consumption, whether known or estimated, while estimates may be based on the computational resources used. However, this requirement exhibits a significant gap as it only covers the energy used during the model's development phase, but leaves out the inference phase [1]. Recent research has shown that energy consumption during inference often exceeds that of the development phase very significantly over time [12, 21].\nAlthough (pre-)training is the most noticeable driver of power consumption, the total energy usage by inferences becomes more significant in the long run when considering overall energy consumption. Eventually, the training of extensive LLMs will likely reach a point of saturation, though the specific timeline is uncertain and will depend on achieving adequate model performance or other factors like energy costs or data availability. Presently, convergence and subsequent training costs grow significantly with increasing model sizes. Nevertheless, once models are predominantly deployed and utilized in products, the energy consumption from inferences will rapidly surpass that of the initial model training phase. Although we are not aware of official numbers, this effect is likely to be already relevant for heavily utilized models such as those available by OpenAI's ChatGPT.\nIn Luccioni et al. [12], the energy usage for inference in various large language models (Bloom) was assessed. They found that it takes between 200 and 500 million inferences, depending on the model's size, for the total energy consumed by inferences to equate to the energy required for initial training. The necessity of incorporating inference energy consumption into mandatory reporting is underscored by Meta's reported carbon emissions for various deployed AI models [21]. While (most of) these models are not LLMs, they demonstrate that the power consumption and associated carbon emmissions from inferences greatly exceeds that from training in production. There is a significant amount of ongoing research focused on optimizing the efficiency of training and inference for large- scale models. Implementing a reporting for inferences would create an incentive to balance not only performance and cost considerations but also explicitly focus on a reduced power consumption. Furthermore, obtaining information on the energy consumption of the cumulative inferences would additionally require the inclusion of model deployers and actually performed inference computations into the reporting obligations.\nTo bridge this gap, we propose an alternative interpretation, based on the information provided to downstream actors (see also [1]). As a result of the AI Act, providers must supply downstream developers and relevant authorities with technical information on how to incorporate GPAI models into AI systems (Articles 53(1)(a) and (b), together with Annex XI and Annex XII). While energy consumption is not explicitly referenced in these provisions, they could reasonably be understood to include details about the computational resources required for inference. This would enable downstream providers to allocate resources more effectively and indirectly promote transparency around the energy consumption involved in each individual inference. However, to calculate the"}, {"title": "4.4 Environmental Risk Assessment and Mitigation", "content": "In tackling the climate effects of AI and ICT more generally, is arguably crucial to move beyond mere transparency provisions towards more substantive goals and obligations. Indeed, the AI Act does contain some language to this effect. For providers of GPAI models with systemic risk and providers of HRAI systems, the Act mandates risk assessment and mitigation. We argue that these measures should also consider environmental risks.\nPursuant to Art. 55(1)(b), providers of GPAI models with systemic risk must assess and mitigate possible systemic risks at Union level, including their sources, that may stem from the development, the placing on the market, or the use of the model. Systemic risk is defined as a risk that is specific to the high-impact capabilities of GPAI models and includes negative effects on public health, safety, public security and fundamental rights (Art. 3(65)).\nSimilarly, according to Art. 9, providers of HRAI systems have to establish a risk management system that identifies and manages the risks to health, safety or fundamental rights when the HRAI system is used in accordance with its intended purpose. For HRAI systems, the assessment and mitigation is limited to the risks that stem from the use, excluding risks in the development phase.\nCrucially, both provisions relate to risks of the AI model or system to fundamental rights which, within the AI Act, must be interpreted as including environmental risks [5]. In Art. 1(1) and Recital 1, the purpose of the AI Act is defined as protecting health, safety, fundamental rights enshrined in the Charter, including democracy, the rule of law and environmental protection. However, in the doctrine of the Charter of Fundamental Rights of the European Union (the Charter), environmental protection (Art. 37 of the Charta) is merely an objective rule, not a fundamental right [14]. Democracy and the rule of law are not enshrined in a particular Article of the Charta but serve as guiding principles that permeate the Charta and all of the fundamental rights. Accordingly, they (only) find mention in the preamble of the Charta."}, {"title": "4.5 Interim Conclusion on the AI Act", "content": "Overall, while the AI Act introduces valuable steps toward addressing climate-related concerns in AI development and deployment, it falls short of establishing a comprehensive framework for mitigating the environmental risks posed by AI systems. Key provisions on transparency and risk management for high-risk AI and general-purpose AI systems make some progress in requiring documentation of computational resources and energy consumption, but significant gaps remain. For example, the Act does not mandate the disclosure of energy consumption during the inference phase, a crucial omission given the long-term environmental impact of AI applications. Moreover, transparency measures are restricted to authorities, limiting broader accountability and public scrutiny.\nAdditionally, while the Act imposes risk assessment and mitigation obligations on providers of HRAI systems and GPAI models with systemic risk, these provisions lack sufficient emphasis on environmental factors. Although environmental protection is included in the Act's objectives, its practical integration into risk management remains unclear, and no detailed reporting on mitigation efforts concerning environmental risks is currently required. Without stronger enforcement and clearer guidance, particularly on the inclusion of energy consumption and other environmental impacts in risk assessments, the Act's potential to address the growing climate-related risks of AI systems will remain limited."}, {"title": "5 Operationalizing the Requirements", "content": ""}, {"title": "5.1 Model Providers and their Access to Infrastructure", "content": "Leading model providers leverage extensive supercomputer networks equipped with high-performance GPUs for training and inference. This primary group is most impacted by energy consumption reporting. We assume that they possess privileged access or considerable influence over the utilized infrastructure given their financial power or strategic value (e.g., OpenAI, Microsoft, or Nvidia). One can distinguish between companies that develop closed models (e.g., OpenAI) and those that create open-source models (e.g., Meta).\nStartups and smaller companies are expected to either directly deploy such models, use available API services of leading model providers, or fine-tune existing models. Although these companies do not typically pretrain large models themselves, they must report energy consumption for fine- tuning-under our proposed interpretation only if the fine-tuning of a model leads to a substantial modification. While this scenario may not be common, it is crucial to establish a regulatory framework for companies that lack the extensive resources of heavily funded, predominantly US-based firms. These smaller entities are likely to rely on cloud services like Amazon's AWS or Microsoft Azure and have limited control over the available product offerings, making them dependent on whether these services provide energy consumption reporting."}, {"title": "5.2 Levels for Measuring and Estimating Energy Consumption", "content": "There are several levels within a data center based on which energy consumption may be measured or estimated [1]. These include (1) the data center level, (2) the cumulative server level, (3) the GPU-Level and other hardware within a server and (4) various other levels. In this section, we outline these levels along with their benefits, drawbacks, and estimation methods."}, {"title": "5.2.1 Data Center Level", "content": "On the data center level, the power required to operate the entire data center is measured, including both the direct power consumption of computing equipment and the additional overhead for cooling and maintaining the data center.\nThis approach provides the most extensive and complete figures since it represents the actual energy usage, but also assumes that a data center is exclusively utilized for the pre-training by the model provider. It encourages the selection of an efficient data center. Additionally, data centers have average PUE values of 1.58, so this overhead makes up a significant portion of the energy consumption. On the other hand, the power usage resulting solely from the model's architecture, the quantity of training data, the efficiency of the implementation, and experimental settings is very important, but is somewhat skewed by the efficiency of the data center.\nIf data-center level power consumption measurement is not available, using the PUE factor for estimation is deemed appropriate. To calculate total energy usage, the PUE factor is multiplied by the raw computational power consumption measured or estimated at the cumulative server or rack level (see below). This might be reasonable, if only parts of a data center are utilized and only measurements closer to the ICT equipment are available."}, {"title": "5.2.2 Cumulative Server Level", "content": "A large-scale model is trained across many servers in a distributed manner. Each server includes one or more GPUs responsible for the primary computation. To accurately monitor the power consumption over time, a local power distribution unit (PDU), capable of measuring the provided power, is attached to each server. Aggregating these measurements yields a highly precise figure of the total energy consumption attributable to the model's computations. Instead of manually aggregating local PDUs, the usage of primary PDUs or uninterruptible power supply (UPS) systems already measuring at the rack level or even many racks is also suitable (cf. Figure 1, as long as the measurements precisely match fully the utilized hardware resources by the model providers. The goal is to include all ICT-related power consumption but exclude data center specific efficiency properties.\nThe upside of this method is that it is extremely accurate and highly correlates with model size or structure, data quantity, and hardware-aware software implementation. It is also widely recognized in the industry for assessing power consumption in data centers. According to a 2023 Green Grid industry survey, 66% of data centers can track power demand at least on rack-level. Roughly one third of overall data centers (Europe: 29%, Global: 32%) are already able to collect average utilization and power demand data for individual servers and storage equipment and match this data to their IT equipment inventory. We assume that the data centers that are used for training by large model providers are already able to track this information given its high cost relevance.\nHowever, a significant number of overall data centers do not currently track power demand or are able to do so. Surveyed data center professionals (see Green Grid survey) project implementation of a data management system able to collect power demand data for individual servers and storage equipment and matching data to the IT equipment inventory to require between 3-6 months (Europe: 15%, Global: 19%), 1 year (Europe: 29%, Global: 28%), 2 years (Europe: 12%, Global: 10%), 3 years (Europe: 4%, Global: 4%) or more than 4 years (Europe: 11%, Global: 8%). For European data centers these numbers stand in (surprising) contrast to the obligation under the EED and Delegated Regulation to provide energy consumption data by Sep 15, 2024 (Art. 3(1) and Annex II(1)(e) Delegated Regulation). Either a substantial number of the participants was unaware of the obligations;"}, {"title": "5.2.3 GPU-Level and other hardware within a server", "content": "The measurement may also be based on the energy usage of particular components within a server as determined by on-chip sensors. Nvidia GPUs and certain CPUs already provide straightforward and user-friendly power consumption monitoring. However, despite GPU power consumption being a significant factor and its usage likely correlating with the total power usage, it substantially under- represents the actual energy consumption since it measures just a single component. CPU power usage is a relatively minor factor in energy consumption during model training. Most other server components cannot be measured. Therefore, we do not advocate for using GPU-level or other component-based power consumption tracking as a suitable method for measuring overall energy usage.\nEstimations are not necessary since Nvidia offers an interface for power consumption measurements via sensors. Components that lack sensor interfaces, estimations come with significant uncertainties and assumptions. Therefore, we do not advocate for estimations at this level."}, {"title": "5.2.4 Other levels", "content": "Other measurement levels, such as Workload, Cloud Instance, or Virtual Machine, involve high complexity and numerous assumptions, resulting in a lack of standardized measurement or estimation methods with considerable uncertainty. Additionally, these granular levels are unsuitable for power consumption measurements in extensive distributed LLM training. Therefore, we advise against using these levels for power consumption tracking."}, {"title": "5.2.5 Interim Conclusion on the Level of Measurement", "content": "In our analysis, we argue that energy consumption should be measured and reported at the cumulative server level [1]. This approach captures the total computation-related power usage and is better suited to help providers optimize their AI models and algorithms for energy efficiency. Additionally, the PUE factor of each data center, which is reported and published by the data center operator under the Energy Efficiency Directive (EU) 2023/1791 and Delegated Regulation (EU) 2024/1364, provides a useful estimate of overall energy consumption [1]. With these two figures, it is possible to distinguish between model-specific power usage (server-level computation) and the data center's efficiency, offering a clearer picture of the total energy investment [1]. Although the EED mandates that PUE factors must be available for data centers situated within the EU, the responsibility of reporting these factors should also fall on the model provider. Specifically, model providers utilizing data center facilities outside the EU should not be granted an exemption.\nEstimates of server-level power consumption should be based on peak utilization figures provided by the hardware manufacturer (e.g., Nvidia) [1]. Still, it is important to consider advancements in research. Interpretation of the legal requirements could accommodate justifiable alternative assumptions that may not require peak utilization figures. For instance, tracking GPU utilization through interfaces like those provided by Nvidia and referencing hardware benchmarks based on specific GPU utilization rates could serve as a basis for such assumptions."}, {"title": "5.3 Measurement or Estimation", "content": "Although actual measurement is more onerous, it also yields more precise results for energy con- sumption reporting. Major model providers are likely to already measure power consumption as it is a primary cost factor and highly linked to computational power. Despite the availability of power consumption data, companies may be tempted to use estimated values to protect sensitive information."}, {"title": "5.4 Sustainability Impact Assessments", "content": "The operationalization of sustainability impact assessments (SIAs) within the risk assessments required under the AI Act involves integrating environmental considerations into the existing risk management frameworks that high-risk AI model providers and GPAI providers must follow.\nMuch like data protection or algorithmic impact assessments, SIAs would serve as a practical tool for embedding climate considerations into the development and deployment of AI systems. Importantly, these assessments should not be limited to high-risk AI models but should also apply to all AI systems, regardless of the associated risk to health or safety. This is because the carbon footprint of AI models is often unrelated to their classification as high or low risk under the Act. Therefore, an SIA could ensure that environmental impacts are considered across the entire AI landscape.\nThe SIA should involve evaluating various models and design choices during the development process, comparing them not only on their performance but also on their estimated environmental impact. For instance, developers would need to assess whether a simpler model, like linear regression or even a non-AI model, could achieve similar results with a smaller carbon footprint compared to more complex models like deep learning [7]. Similarly, the decision to use large, pre-trained models or training new, narrow models (almost) from scratch should factor in the potential climate benefits. By using existing tools to measure the carbon impact of AI models, developers would be required to opt for the more environmentally sustainable option when performance is comparable. This approach would not only encourage environmental awareness but could also lead to synergies where sustainability and cost effectiveness align.\nTo effectively implement sustainability impact assessments, providers would need to establish standardized methodologies for measuring the environmental effects of AI models, particularly energy and water usage during training and inference phases. These methodologies should be aligned with existing metrics such as Power Usage Effectiveness (PUE), Water Usage Effectiveness (WUE), and Renewable Energy Factor (REF). This would allow for consistent and comparable between providers and reporting across the value chain. Providers must also be required to report on their use of renewable energy and efforts to mitigate the environmental impacts of their operations. The operationalization process would involve both the collection of real-time environmental data and"}, {"title": "6 Policy Proposals", "content": "Although the AI Act attempts to address climate concerns through various reporting obligations, these measures largely lack consistency and clarity. We identify twelve policy recommendations that should be integrated into the evaluation report due in August 2028 (Article 111(6)), as well as any interpretive guidelines from the AI Office and other agencies, and in reviews and potential textual"}]}