{"title": "Richer Output for Richer Countries: Uncovering Geographical Disparities in Generated Stories and Travel Recommendations", "authors": ["Kirti Bhagat", "Kinshuk Vasisht", "Danish Pruthi"], "abstract": "While a large body of work inspects language models for biases concerning gender, race, occupation and religion, biases of geographical nature are relatively less explored. Some recent studies benchmark the degree to which large language models encode geospatial knowledge. However, the impact of the encoded geographical knowledge (or lack thereof) on real-world applications has not been documented. In this work, we examine large language models for two common scenarios that require geographical knowledge: (a) travel recommendations and (b) geo-anchored story generation. Specifically, we study four popular language models, and across about 100K travel requests, and 200K story generations, we observe that travel recommendations corresponding to poorer countries are less unique with fewer location references, and stories from these regions more often convey emotions of hardship and sadness compared to those from wealthier nations.", "sections": [{"title": "1 Introduction", "content": "Given the excitement around large language models, users resort to these models for a diverse range of applications (Brown et al., 2020; Touvron et al., 2023). Based on our analysis of ShareGPT, a collection of user interactions with ChatGPT, 1.7% of queries are about travel recommendations, whereas 1.5% concern story generation. Such use cases make one wonder whether the generated travel itinerary for Mumbai is just as informative compared to New York City? Or is a generated story of a girl growing up in Nairobi just as relatable compared to another story based in Seattle? For these applications to be broadly useful, it is important that there are no (or few) geographical disparities.\nSome recent works aim to benchmark the extent of geographical knowledge encoded in large lan-"}, {"title": "2 Related Work", "content": "Geographical Bias in Language Technologies.\nLanguage models can generate disproportionate and prejudiced representations of marginalized groups (Navigli et al., 2023). Significant efforts quantify these biases across various dimensions, including gender (Sheng et al., 2019), race (Omiye et al., 2023), culture (Wang et al., 2023), religion (Abid et al., 2021), and more. Recent studies also highlight 'geographical biases' in LMs: one such study finds that when models are instructed to rank countries in terms of topics such as work ethic, intelligence and attractiveness, they undervalue areas with lower socio-economic status (Manvi et al., 2024). An analysis of models over WorldBench, a benchmark to assess factual recall in LLMs over country-wide data from the World Bank, reveals higher error rates for countries with lower income levels (Moayeri et al., 2024). Global-Liar, a dataset by Mirza et al. (2024), benchmarks the accuracy of models in fact-checking claims from six global regions and underscores the disadvantages faced by regions in the Global South. Despite these efforts to highlight bias in geographical factual predictions, there is a noticeable lack of research addressing biases in real-world applications of geographical knowledge. Our work addresses this gap by examining biases across practical applications of story generation and travel recommendation. There exists prior work on travel planning (Xie et al., 2024), and a large literature on story generation (Zhao et al., 2023), but to the best of our knowledge, these works do not examine geographical disparities."}, {"title": "3 Approach", "content": "Below, we briefly describe our approach to quantitatively examine the outputs from different language models for two tasks: generating travel recommen-"}, {"title": "3.1 Experimental Setup", "content": "Examined Locations. To capture the global variation in LLM performance, it is crucial to incorporate a diverse array of geographical regions, covering cities, towns, and villages, in our analysis. For this purpose, we use Geonames, a community-driven geographical database, comprising an extensive list of location names. We capture all global locations with inhabitants exceeding 1000, to achieve a finer granularity and a more nuanced understanding of global disparities. This surpasses most prior work that largely study geographical biases with only country-level information (\u00a72). At the time of our study, GeoNames contained about 150K locations. In our experiment, we randomly sample, with replacement, up to 25 locations per country from this larger population totalling about 4,000 locations for 190 countries. For every attribute we quantify, we report averages across 3 random samples (of this data) with different seeds.\nInput Prompts. We manually curate a set of prompt templates with location placeholders, which are later populated with the sampled locations. For example, \"Write a story of a family from [Location]\" is a prompt for story generation. We intentionally keep the prompts simple, avoiding additional variables to ensure a fair comparison and isolate the influence of location on the model's response. For each location, we randomly choose 6 templates (4 for story generation and 2 for travel recommendation) and fill the location slot. Such slot-filling approaches to generate inputs are commonly used in the literature (Chang et al., 2023). While queries related to travel recommendations naturally incorporate a geographical aspect,"}, {"title": "3.2 Evaluation", "content": "For geo-anchored applications, such as travel recommendations and story generation, there is often no definitive right or wrong response. One possible approach is to find local participants from every geographical region, and request them to qualitatively evaluate each response. Past work has noted that it is challenging to find such participants (Basu et al., 2023). Instead, we quantify few attributes that we believe contribute to the quality of the response, such as uniqueness and informativeness. We briefly describe these attributes:\nUniqueness. Every location presents a blend of historical, cultural, geographical, and environmental factors, contributing to its unique identity. To reflect this, models need to be aware of these distinctive aspects for different regions. We use the uniqueness measure to capture how distinct the subjective responses for a given location are compared to others. We make a slight modification to the TF-IDF metric to calculate the average rarity of words generated in the response of a location compared to other locations. Terms which score high as per our metric, anecdotally, reflect regional artifacts (e.g.,"}, {"title": "4 Results", "content": "We aggregate the (estimated) city-level attributes for every country to observe trends across different countries. Interestingly, the uniqueness scores for India, Italy, Japan, and the United States consistently rank among the highest across all models in both applications. Comparing regions, we observe that travel recommendations for the Sub-Saharan African region are considerably less unique than those for the North American region, with alarming differences of 43% for GPT-4, 42% for LLaMa 3\n8B, 39% for LLaMa 3 70B, and 38% for Mixtral.\nA similar trend is observed in the informativeness of generated stories, wherein most models generate a large number of geographical entities for the United States and the United Kingdom. Problematically, the responses for the North American region include at least double the number of location mentions in stories compared to those from the Sub-Saharan African region across all models.\nStudying the emotions presented in the generated stories, we notice that while only 18% of stories generated for the North American region depict hardship, this figure rises to 45% for the Sub-Saharan African region. Interestingly, we find that an overwhelming fraction of stories, about 99%, express some form of joy, suggesting an overall positivity bias in model-generated stories.\nRelationship with GDP per capita. We present the Pearson correlation coefficients for all attributes aggregated by country with the country's GDP per capita for different models in Table 1. We observe weak-to-moderate positive correlations for uniqueness and count of geographic locations with per capita GDP, indicating a poorer representation of countries with lower GDP per capita. We also note a moderate-to-strong negative correlation with the fraction of stories expressing hardship and sadness, with the highest percentage being for Somalia, Niger, South Sudan, and Afghanistan (Figure 2).\nRelation to frequency of country mentions. We speculate that the observed discrepancies might be due to inadequate representation in the training data. We use infini-gram API (Liu et al., 2024) to obtain a frequency of country mentions in The Pile corpus (Gao et al., 2020). We note down its correlations of quantified attributes in Table 1. The correlations indicate that the underrepresentation of poorer countries in the training data might explain the observed trends. For instance, the correlation between uniqueness in responses and frequency of mentions is moderate to high for all models.\nModel Size. We examine two models from the LLaMa 3 family, only differing in size, and inquire whether larger models hold more information about global locations, thus potentially reducing disparities. However, our results suggest otherwise as the larger model results in similar correlations.\nAbsence of Information. Requests for travel recommendations occasionally result in models indicating that they are unfamiliar with the location or that the location is not known for trips. We count the fraction of such responses and aggregate them for each country and report them as \"Absence of Information\" in Table 1. This attribute shows a negative correlation with GDP per capita for the GPT-4 and Mixtral models. (LLaMa 3 models do not systematically decline such requests)."}, {"title": "5 Conclusion", "content": "We evaluate language models on two real-world applications of generating travel recommendations and geo-anchored stories, through a geographical lens. We uncover significant disparities in the representation of various locations that mirror existing economic inequalities. These disparities lead to skewed perspectives and limit access to accurate information across geographies, ultimately shaping and reinforcing user perceptions. This study underscores the importance of developing geographically diverse datasets for AI training, to create more equitable and representative models that better serve a wide range of global needs."}, {"title": "6 Limitations", "content": "There are a few important limitations of our work. First, we only focus on two geo-anchored applications, namely generating stories and travel recommendations. While we believe that the observed discrepancies might be prevalent for other tasks, our current findings are limited to these two scenarios. Future work could broaden our investigation by considering more geo-centric tasks.\nSecond, we do not measure the relevance and validity of the generated geo-locations. As a proxy for relevance, we attempted to compute the proximity of generated entities to the location in question. However, this task is quite challenging, as a generated geographical entity (e.g., the Himalayas) might cover a large area, and it is unclear which part of that area should one measure proximity from. Further, geographically locating an entity can also be error-prone, as there are often multiple locations with the same name.\nThird, this study primarily focuses on attributes amenable to easy quantification, however, a qualitative study to evaluate the cultural appropriateness of the responses could yield further insights, and provide a complementary perspective."}, {"title": "A Appendix", "content": "We share our manually curated prompt templates for the application of story generation in Table 2 and travel recommendation in Table 3. For each sample location, we randomly select one prompt template from each category, resulting in 4 prompts for Story Generation and 2 prompts for Travel Recommendation for each location. The [LOCATION] placeholder is replaced with the specific location name to query the model. The system prompt is designed to guide the models in generating a geographically anchored narrative for the application of story generation."}, {"title": "A.2 Uniqueness Calculation", "content": "The following explains how the uniqueness score is calculated. We denote the collection of all the responses for an application a as $R_a$. Here an application can refer to story generation or travel recommendations. We first calculate the inverse document frequency idf of all words w (excluding stop-words) present in $R_a$. This is an indicator of how rare the word is across all responses.\n$idf(w, R_a) = \\frac{|R_a|}{f_{w, R_a}}$\nwhere $|R_a|$ denotes the cardinality of the collection $R_a$ and $f_{w,R_a}$ equals the number of responses in $R_a$ that contain the word $w$. We further calculate the uniqueness score U for each location I as\n$U(l, R_a) = \\frac{1}{|R_{a,l}|} (\\sum_{r \\in R_{a,l}} \\frac{1}{|r|} (\\sum_{w \\in r} idf(w, R_a)))$ \nwhere $R_{a,l} \\subset R_a$ denotes the collection of responses in $R_a$ for location l, $|R_{a,l}|$ denotes the size of $R_{a,l}$, r denotes the individual responses in $R_{a,l}$ and $|r|$ denotes the total number of words in response r, excluding the stop-words."}, {"title": "A.3 Qualitative results", "content": "Rare words that contribute to high uniqueness scores often highlight the regional artifacts and geographic references specific to the location. We share some qualitative examples by highlighting the rare words that contribute most to the uniqueness scores for the application of Story Generation in Figure 3 and Figure 4."}]}