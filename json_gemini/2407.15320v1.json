{"title": "Edge Graph Intelligence: Reciprocally Empowering Edge Networks with Graph Intelligence", "authors": ["Liekang Zeng", "Shengyuan Ye", "Xu Chen", "Xiaoxi Zhang", "Ju Ren", "Jian Tang", "Yang Yang", "Xuemin (Sherman) Shen"], "abstract": "Recent years have witnessed a thriving growth of computing facilities connected at the network edge, cultivating edge computing networks as a fundamental infrastructure for supporting miscellaneous intelligent services like personal voice assistance, video security surveillance, and autonomous driving vehicles. Meanwhile, Artificial Intelligence (AI) frontiers have extrapolated Machine Learning (ML) to the graph domain and promoted Graph Intelligence (GI), which unlocks unprecedented ability in processing, abstracting, and learning from massive data in graph structures. Given the inherent relation between graphs and networks, the interdiscipline of graph representation learning and edge networks, i.e., Edge GI or EGI, has revealed a novel interplay between them GI models principally open a new door for modeling, understanding, and optimizing edge networks, and conversely, edge networks serve as physical support for training, deploying, and accelerating GI models. Driven by this delicate closed-loop, EGI can be widely recognized as a promising solution to fully unleash the potential of edge computing power and is garnering significant attention. Nevertheless, research on EGI yet remains nascent, and there is a soaring demand within both the communications and AI communities for a dedicated venue to share recent advancements. To this end, this paper promotes the concept of EGI, explores its scope and core principles, and conducts a comprehensive survey concerning recent research efforts on this emerging field and specifically, introduces and discusses: 1) fundamentals of edge computing and graph representation learning, 2) emerging techniques centering on the closed loop between graph intelligence and edge networks, i.e., \"edge for GI\" and \"GI for edge\", and 3) open challenges and research opportunities of future EGI. By bridging the gap across communication, networking, and graph learning areas, we believe that this survey can garner increased attention, foster meaningful discussions, and inspire further research ideas in EGI.", "sections": [{"title": "I. INTRODUCTION", "content": "Edge networks are swiftly proliferating. By assembling progressively spreading computing facilities at the network edge, edge networks have hosted ever-increasing amounts of data, storage, and computing resources. They have become a fundamental infrastructure supporting miscellaneous applications like smart industrial manufacturing [1], [2], streaming video analytics [3], [4], and Internet of Robotics and Vehicles [5], [6], etc. As a complementary symmetry of the centralized core network, edge networks locate at the end of the Internet and encompass users in their physical vicinity, allowing for user-centric services with reduced response latency, improved resource efficiency, and enhanced privacy and security. Benefited from these unique architectural superiorities, edge networks have been a vital experimentation arena for advanced communication techniques. They are practically favorable for emerging intelligence services with delay-sensitive, resource-demanding, and privacy-preserved requirements, and have been widely recognized as a promising prospect for bridging the last mile between Artificial Intelligence (AI) and human beings [7], [8].\nMeanwhile, AI is also rapidly booming. To fully unleash the potential of big data in diverse forms, recent AI advances have extrapolated representation learning over massive data from Euclidean structure to graph topology, pushing Deep Learning (DL) frontiers to a new stream of models named Graph Neural Network (GNN) [9], [10]. Different from traditional DNN (e.g., CNN, RNN) that typically applies 1D/2D convolutions, GNN introduces graph embedding techniques to digest information from graph relations [11], [12]. Specifically, it applies neighbor aggregation on an input graph iteratively and captures hierarchical patterns through neural network operators from subgraphs of varying sizes. This enables GNNs to abstract and learn the properties of specific vertices, links, or the entire graph, and thus generalize to unobserved graphs. Leveraging such powerful expressiveness, learning with GNN, i.e., Graph Learning (GL), has exhibited superior graph analysis performance and empowers various graph-related tasks from node classification and link prediction to graph isomorphism and categorization [13], [14]."}, {"title": "A. Motivation and Benefits of Edge Graph Intelligence", "content": "Given the remarkable success of Graph Intelligence (GI) and edge networks in their respective fields, the inherent connection between graphs and networks impels them to a confluence. As illustrated in Fig. 1, GI provides a vast zoo of empirical learning models (e.g., convolutional and recurrent GNNs, graph autoencoders) as well as various learning paradigms like Transfer Learning (TL) and Reinforcement Learning (RL), allowing advanced learning ability from graph data. Symmetrically, edge networks generally comprise of a rich set of platforms including mobile devices, robots, vehicles, and edge nodes, which host miscellaneous graph-based applications such as traffic forecasting and network resource management. Their bidirectional interaction, where GI enhances and optimizes edge networks and edge networks support and enable GI computation, draws a closed loop with mutual empowerment and nurtures a reciprocal interplay of their integration, namely \"Edge Graph Intelligence\" or \"EGI\" for brevity. More specifically, by fusing GI and edge computing, EGI provides three-fold reciprocal benefits in the following aspects.\n\u2022 Reciprocal performance enhancement: With the rapid proliferation of mobile and IoT devices, data generated at edge networks have skyrocketed in both quantity and modality (e.g., physical signals, digital audio, and visual content). As predicted by IDC [15], the billions of IoT devices in edge networks are expected to generate over 90 Zettabyte of data in 2025. This naturally provides a data nursery for modifying, training, and fine-tuning GI models with real-world data, thus boosting GI models toward higher-degree intelligence. Contrariwise, given the rich relational data collected at edge networks, GI enables modern graph analysis for understanding, diagnosing, and optimizing edge networks, which steers the enhancement of network performance such as robustness and Quality of Service (QoS).\n\u2022 Reciprocal capability expansion: As the last mile of the Internet, edge networks are continuously incubating pioneering user-centric scenarios surrounding terminal users, where many of them can be abstracted in graphs (e.g., wireless sensor networks, Internet of Vehicles). These scenarios act as a burgeoning force from the demand side to drive the development and deployment of GI, augmenting the application scope of GI models. Reversely, applying GI to edge networks thus unlocks their extended capability in securing edge networks from anomalies, developing new graph-based applications, and intelligently serving graph-related tasks. This is attributed to GI models' innovative mechanism that combines graph embedding and convolution, which enables GI to deliver an unprecedented ability to learn and infer from graphs such as high-precision node identification and link pre-diction.\n\u2022 Reciprocal technology democratization: Technology democratization envisions making both GI and edge computing more usable, understandable, and friendly to a broader range of people, and has become a crucial agenda for social good. Towards that, GI and edge networks carry out mutual empowerment to improve each other. On the one hand, edge networks can democratize GI by rendering accessible and affordable intelligent computation closer to end users, allowing GI to be available and personalized in diverse scenarios. On the other hand, GI may popularize edge networks through prevailing GI-enabled applications at the edge. Specifically, given the computation-intensive and data-dependent nature of many GI models, edge computing exhibits its clear advantages against cloud computing by providing computing resources with lower delay and reduced bandwidth budget and is thus aligned well with GI. With the prevalence of GI surrounding end users, edge networks also gather attention and deployment for popularization."}, {"title": "B. Scope and Rating of Edge Graph Intelligence", "content": "While the term EGI is fresh to come, research and practices have begun early. Since the development of GCN in 2015 [16], GI has increasingly gained popularity in the AI community and ignited a wave of building GNNs over various real-world graphs. Meanwhile, edge networks and edge computing are also rapidly evolving and actively embracing AI from 2019, giving rise to the concept of edge AI or edge intelligence [8], [17], [18]. Currently, the interplay of EGI has attracted growing attention from both the industry and academia and propelled a plethora of innovative optimizations, techniques, and applications at the network edge, e.g., traffic flow forecasting [19], [20], location-based recommendation [21], [22], and vehicle trajectory prediction [23], [24]. As a substantial extension of edge AI, EGI sheds light on its fundamental questions - how deeply edge networks and AI techniques can be fused and how much potential their fusion can shine - and demonstrates its powerful capability through plentiful realistic applications.\nNonetheless, discussions on EGI are still narrowly limited to unilateral dimensions. Existing literature has either reviewed the graph learning landscape with limited discussion on their applications in edge networks [9], [10], [13], or focused particularly on applying GI techniques on some specific edge scenarios (e.g., traffic domain [25]\u2013[27], power grids [28]\u2013 [30]), yet ignoring the big picture of general edge networks spectrum. Some recent literature [31]\u2013[33] also reviews the progress of GI in the context of IoT and wireless networks but mainly focuses on GI applications in their discussed scopes and lacks a systematic taxonomy on the \"Edge for GI\" aspect, which is one of the fundamental pillars in EGI's closed loop. Although the edge computing and communications community has extensively investigated edge intelligence systems, a majority of them [8], [34]\u2013[37] center on general AI computation systems or are dedicated to traditional DL workloads such as CNNs or RNNs, where GI models, which possess distinct capabilities and unique characteristics, are much less understood.\nIn this paper, we advocate that EGI should not be restricted to merely applying GI on edge data or running GI on edge platforms. Instead, GI and edge networks are blending a confluence and EGI should be treated as a whole to reflect the inherent interplay between GI and edge networks. This indicates that their bilateral empowerment desires a comprehensive exploration such that the degree of EGI can be identified and measured. Specifically, according to the fusion of GI and edge networks, we may rate EGI into six levels from their respective perspectives, as shown in Fig. 2.\n\u2022 Level 0: Given the graph data implicated in the edge network infrastructure, analytical models in Level 0 are unaware of the graph structures. The edge computing systems also process data in an graph-agnostic way. In other words, neither the model side nor the infrastructure side explicitly tackles \"graphs\", and thus they are categorized to the initial level.\n\u2022 Level 1: Data collected from edge networks are modeled in graphs. Systems at Level 1 push one step further over Level 0 by endowing graph semantic to edge data (with general computing methods).\n\u2022 Level 2: Edge data in graph forms are processed with traditional graph computing algorithms such as PageRank and single-source shortest path algorithms. Systems at Level 2 outperform Level 1 by enabling the graph-oriented computing capability.\n\u2022 Level 3: Edge networks serve GI model inference with graph data, where the models may be trained on the cloud. Compared with lower levels, systems at Level 3 initiate AI to edge networks and embrace GI models.\n\u2022 Level 4: Edge networks perform GI model training with graph data. The key difference between Level 4 and Level 3 lies in the ability of learning edge-native GI models, e.g., fine-tuning model parameters with edge data.\n\u2022 Level 5: Interactional EGI, where GI and edge networks can dynamically adapt their configurations during the runtime for optimal EGI performance. Systems at Level 5 outperform all other levels because they can adjust GI and edge networks on the fly, whereas lower levels are all static settings. Both perspectives of GI and edge networks reach a convergence since they are in complete harmony.\nThe rating of EGI can be mainly divided into three intervals. The first interval covers from Level 0 to Level 2, where EGI is less related to AI and even processes non-graph data. The second interval comprises Level 3 and Level 4, where EGI incorporates GI models by either inference or training on edge networks. The third interval is exactly Level 5, which stands at the highest level because its GI and edge networks have profoundly blended as integration and can adapt to diverse scenarios on the fly. As EGI systems locates at higher levels, their fusions of GI and edge networks go deeper. As a result, the intelligence resources of GI and infrastructural resources of edge networks are progressively exploited for better EGI performance. Nonetheless, this may also come at the cost of additional development effort and system overhead. This conflict implies that there is no \u201csilver bullet\" in all cases. Instead, the panacea of EGI in practice should align with user demand, anticipating a joint consideration of specific application scenarios as well as available resources budgets."}, {"title": "C. Summary and Contribution", "content": "In this paper, we discuss in-depth how GI and edge networks are reciprocal to each other, and conduct a comprehensive and concrete survey of the recent research efforts on EGI. In particular, centering around the inherently interconnected nature of graphs and networks, this paper reveals the bilateral interplay, for the first time, between GI and edge networks, and provides a concise rating in accordance with their mutually beneficial interactions. In light of the rating, our survey identifies the four primary enablers essential for EGI, as illustrated in Fig. 3:\n\u2022 GI applications at Edge (Sec. IV): Typical application scenarios and use cases for applying GI in edge networks;\n\u2022 Edge Networks for GI (Sec. V): Paradigms of GI model computation, including model training and inference, for GI over edge networks;\n\u2022 GI for edge networks (Sec. VI): Practical GI-based methods for optimizing edge networks concerning their specific functionalities;\n\u2022 EGI ecosystems (Sec. VII): full-stack infrastructural support for high-performance EGI computation in terms of hardware, software, and benchmarks.\nIn general, these key enablers can be well accommodated in the closed loop, i.e., \"edge for GI\" and \"GI for edge\" as described in Fig. 1, In the \"edge for GI\" course, edge networks provide physical platforms and software stacks to graph intelligence, serving as infrastructure to support GI models training and inference processes. More specifically, GI models' intensive training workload can be resolved by means of pools of edge resources (e.g., federated edge learning), and edge inference techniques are developed for deploying and accelerating GI models under resource constraints and SLO requirements. Alternatively, in the \u201cGI for edge\" course, GI models with these inference solutions can thereafter be efficiently executed upon edge platforms, which enables miscellaneous graph-based applications and optimizes various aspects of edge networks. Besides reviewing these key enablers, our survey provides fundamental and friendly premiers of GI and edge networks that assume no prior knowledge of GI or edge computing. We also discuss various open challenges and research directions toward future EGI, encouraging both AI and communications communities to advance EGI for a broader range of people.\nThe rest of this paper is organized as follows: First, Sec. II and Sec. III briefly review the primers of graph intelligence and edge computing networks, respectively. Next, the subsequent sections introduce research efforts with respect to the four enablers: GI applications at Edge (Sec. IV), edge networks for GI (Sec. V), GI for edge networks (Sec. VI), and EGI ecosystems (Sec. VII). Finally, Sec. VIII discusses open challenges and future research opportunities of EGI and Sec. IX concludes. Table I lists the main abbreviations used in this survey."}, {"title": "II. PRIMER ON GRAPH INTELLIGENCE", "content": "As one of the key flywheel actuating the loop within EGI, graph representation learning is devoted to the algorithm side and contributes enhanced ability in graph data processing. Before diving into EGI, this section compendiously introduces graph representation learning with respect to its basic concepts, general workflow, and representative models and learning paradigms. For a more comprehensive treatment of GI, concentrated reviews [9], [13], [14], [38] on graph representation learning are highly recommended. Table II lists the main notations used in this section.\nA. Basic Concepts\n1) Graphs: Graphs are a way to organize data, and with graphs, one can succinctly characterize relationships across scattered data points. The input of GI models, i.e., GNNs, are graphs, which typically contain two types of data. One is the adjacency matrix or adjacency list, which interprets the graph topology, and the other is the feature vectors that describe vertices and edges' actual properties. Formally, an input graph is denoted as $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})$, with vertices and links collected in $\\mathcal{V}$ and $\\mathcal{E}$, respectively.\n2) Vertices and Links: Vertices or nodes in a graph can be items, objects, or entities, and are not necessarily homogeneous when constructing a graph. For instance, a location-based knowledge graph can represent its vertices as human users, IoT devices, scenic spots, and any other entities of various types within a specific district. Links are another essential component in graphs that characterizes the relationships between these items, objects, or entities. Note that to avoid misunderstanding, we exclusively use \"links\" to indicate the connection between vertices in an input graph while leaving \"edge\" for edge networks. A link can be defined with respect to the two (not necessarily unique) vertices associated with it. For $\\mathcal{V} \\in \\mathcal{G}$ and $\\mathcal{E} \\in \\mathcal{G}$, we denote their size, i.e., the number of vertices and links, as $|\\mathcal{V}|$ and $|\\mathcal{E}|$, respectively, and use $v$ and $e$ to index arbitrary vertex and link in them.\n3) Neighbors: Neighbors are ego-networks centering on specific vertices within a graph. For a vertex $v$, its neighbors cover the vertices directly connected to $v$ and their adjoining links. Note that a vertex's neighbors can be iteratively expanded by considering the neighbors of its neighbors. Formally, given $\\mathcal{N}^{(k)}_v$ as vertex $v$'s $k$-hop neighbors, we have $\\mathcal{N}^{(k+1)}_v = {\\mathcal{N}^{(1)}_u \\ \\forall u \\in \\mathcal{N}^{(k)}_v}$, where $\\mathcal{N}^{(1)}_v$ indicates $v$'s one-hop direct neighbors.\n4) Representation Vectors, Features, and Embeddings: Representation vectors are the numerical vectors associated with vertices and links, and are also referred to as encodings, representations, latent vectors, or high-level feature vectors depending on the context. In this section, we respectively denoted representation vectors by $\\mathbf{h}^{(l)}_v$ and $\\mathbf{h}^{(l)}_e$ at the $l$-th GNN layer. Upon input to the model, the initial representation vectors $\\mathbf{h}^{(0)}_v$ and $\\mathbf{h}^{(0)}_e$ are exactly the features attached to vertices and links, which quantify physical properties in specific applications. Extending the above knowledge graph example, the features of a vertex may include the users' age and food preferences, and for a scenic spot, it can be location and popularity. After processing through model layers, the exported representation vectors are embeddings, a form of compressed feature representations of vertices, links, neighbors, or graphs. Embeddings can be viewed as the mappings of original data in latent spaces, which effectively reserve the semantics implicated in the input graph while can be used by downstream models for specific tasks (e.g., vertex classification and link prediction).\n5) Model Output: The final output of GI models depends on the way of processing embeddings, i.e., the readout function. In general, the outcome of GI models can be grouped into three types: 1) Vertex-level output, where the result is vertex-wise predictions (e.g., classes, scores) for some dedicated vertices. 2) Link-level output, where the result is link-wise predictions for some dedicated links. 3) Graph-level output, where the results are the prediction of the whole graph (e.g., the operational status of a power grid)."}, {"title": "B. General Workflow", "content": "A GI model is an algorithm that essentially leverages graph topology to abstract and learn the relationships between vertices and links. It takes an attributed graph as input, and output embeddings or predictions in an application-admitted format. Among versatile GI models, the GNN series is the state-of-the-art genre and is prevalent in various types of edge applications, thus we illustrate the general workflow of GI model based on GNN models. Fig. 4 depicts the general workflow of them.\n1) Preprocessing: The first step serves as an initialization to prepare data in a format aligned with the targeted GI model's requirement. This can be, for example, reorganizing the adjacency matrix in a dense format or the compressed sparse row format and dropout some irrelevant elements from the feature vectors. Since the GI model is often known ahead of runtime, graph preprocessing is usually done offline.\n2) Sampling: With the preprocessed input graph, the GI model dives into iterations. The number of iterations required is exactly the number of layers the GI model possesses. Within each iteration, it first applies sampling on the input graph $\\mathcal{G}$ to reduce the computational complexity of subsequent steps. Assuming the sampling function as $\\Theta^{(l)}$, this step can be formally written in:\n$\\mathcal{G}' = \\Theta^{(l)} (\\mathcal{G}).$ (1)\nThe result of sampling is a sampled graph $\\mathcal{G}'$, where $\\mathcal{G}' = (\\mathcal{V}', \\mathcal{E}')$. Note that this is an optional step and inference processes typically deactivate this step for prediction accuracy.\n3) Aggregation: Upon the sampled graph $\\mathcal{G}'$, the GI model performs neighbor aggregation where each vertex/link pulls feature vectors from its neighbors. Taking vertices aggregation as example, let $\\varphi_v^{(l)}$ be the aggregation function of vertices, we have\n$\\mathbf{a}^{(l)}_v = \\varphi_v^{(l)} (\\mathbf{h}^{(l)}_u, \\mathbf{h}^{(l)}_e), \\ \\forall v \\in \\mathcal{V}', \\forall u \\in \\mathcal{N}(v),$ (2)\nwhere {$\\mathbf{h}^{(l)}_u | u \\in \\mathcal{N}(v)$} collects $v$'s neighboring vertices' representation vectors and $\\mathbf{a}^{(l)}_v$ is the aggregation result.\n4) Update: The GI model then passes the aggregation $\\mathbf{a}^{(l)}_v$ through a neural network operator $\\Phi^{(l)}$ to update $v$'s representation vector:\n$\\mathbf{h}^{(l+1)}_v = \\Phi^{(l)} (\\mathbf{a}^{(l)}_v), \\forall v \\in \\mathcal{G}'.$ (3)\nThis operator is usually learnable Multi-Layer Perceptron (MLP) and non-linear activations like the sigmoid function. Note that Eq. (2) and Eq. (3) are merely described for vertices for simplicity. Repeating the same procedure to all vertices and links yields the complete representation vectors for the whole graph.\n5) Pooling: Pooling is also an optional step that aims at reducing the original graph to a smaller graph for lower computational complexity. It directly operates the sampled graph with updated representation vectors, pooling fields of graphs:\n$\\mathcal{G}'' = \\Psi^{(l)} (\\mathcal{G}').$ (4)\n6) Readout: The above sampling, aggregation, update, and pooling steps will iterate until all model layers are processed, and thereafter generate embeddings of all vertices and links. To attain the desired results demanded by applications, these embeddings are obliged to the final readout step, which applies a pre-defined operator or model to transform embeddings to a global output, as explained in Sec. II-A5. Given a readout function $\\psi$, the global output vector can be obtained by:\n$\\mathbf{y} = \\psi (\\mathbf{h}^{(L)}_v, \\mathbf{h}^{(L)}_e | v, e \\in \\mathcal{G}'').$ (5)\nIn summary, executing a GI model can be regarded as processing a collection of operators and neural networks iteratively over a graph, where each iteration, i.e., each model layer, comprises weights that specify the computation of vertices' and links' feature vectors. These weights are learnable via model training, i.e., through the means of backpropagation algorithms such as gradient-based optimization. Specifically, during model training, a GI model with $L$ layers undergoes a forward pass: first transforms input graph through model layers to graph embeddings, and next converts the obtained embeddings into desired results. With the exported result and known labels, the model computes the pre-defined loss function, where the gradient is then backpropagated across the layers, updating the shared weights. This process is carried out iteratively with multiple samples, which are often in batches until an expected accuracy is attained. For model inference, it directly goes through a forward pass and generates the predictions."}, {"title": "C. Graph Learning Models", "content": "There are multifarious GI model variants developed for multifarious applications with multifarious ability requirements. For brevity, here we enumerate several representatives that are commonly adopted in edge scenarios.\n1) Recurrent Graph Neural Network (RecGNN): RecGNNs are a pioneering architecture that builds the conceptual foundation in the field of graph representation learning [9]. They are primely proposed to learn node representations using recurrent neural architectures, integrating a recurrent hidden state and graph signal processing (GSP) to exploit the spatial structural information inherent in graph processes. As a genre of GI models dating back to the \"pre-deep-learning\" era, RecGNNs have inspired numerous subsequent research such as convolutional variants."}, {"title": "III. PRIMER ON EDGE NETWORKS", "content": "A. Edge Networks and Edge Computing\nIn the evolving landscape of distributed computing, the edge network emerges as a pivotal architecture, facilitating the transition from centralized cloud-based core networks to more decentralized edge networks [63]\u2013[65]. Fig. 5 illustrates the edge network as a cohesive architecture that integrates the Edge and End layers, encompassing devices naturally situated closer to end users. Besides traditional network-style topology, edge networks can exhibit versatile organizations such as peer-to-peer connection (e.g., client-server mode) and star-like interactions (e.g., one-to-many subscription). Albeit, all these topologies can be unified by the graph abstraction. On the other hand, core networks and the Internet also comprise many graph structures and have introduced GI over their graphs. However, it should be emphasized that EGI is significantly different from GI on core networks given the unique characteristics of edge networks.\nSpecifically, in contrast to the centralized core networks, several salient features distinguish edge networks: (1) Distributed: Edge networks are characterized by their geographically dispersed resources, such as edge servers and mobile devices, in stark contrast to the centralized nature of cloud-based data centers. (2) Heterogeneity: Edge networks encompass a diverse array of edge devices and servers, each varying in computational capacity, network bandwidth, and hardware architecture, embodying an extremely heterogeneous computing environment. (3) Resource Constraints: Unlike cloud-based data centers equipped with high-performance accelerators and dedicated ultra-speed links, devices within edge networks often operate under resource limitations, facing constraints in aspects like computational throughput, device-to-device communication bandwidth, and memory capacity. (4) Dynamic Resources: The proximity of edge network devices to end users inherently results in greater dynamism in resource availability. Their mobility across various networking domains and multitasking with multiple applications simultaneously contribute to frequent fluctuations in both network and computational resources.\nEmerging from the advanced architecture of edge networks, edge computing stands as a new computing paradigm in contrast to cloud computing [8], [34]. Edge computing represents a shift in computational paradigm that brings data processing exponentially closer to the point of data collection and consumption, enabling low-latency and high-bandwidth communication essential for real-time applications. Edge computing, in comparison to cloud computing, presents numerous advantages, notably in its approach to in-situ data processing: (1) Lower Core Network Reliance: Edge computing lessens the reliance on unstable and delay-prone core networks by localizing data processing within edge networks, ensuring more consistent QoS even when wide-area network (WAN) connections are unpredictable. (2) Alleviated Core Network and Cloud Datacenter Stress: With the sheer volume of edge and end devices, routing all data through the core network to cloud data centers imposes substantial strain in terms of communication, computation, and storage. Edge computing mitigates this by retaining computations within the edge network, effectively utilizing the distributed, idle resources of edge and end devices. (3) Privacy and Security Enhancement: Localizing data within edge networks, minimizes the risk of unauthorized access and privacy breaches. Transferring these data to the cloud-based data centers owned by commercial companies inevitably raises users' privacy concerns."}, {"title": "B. Components of Edge Networks", "content": "Locating at the periphery of the Internet, edge networks cover a wide spectrum of diverse and heterogeneous platforms. From fragmentation to integration, we enumerate example components in edge networks in five levels as in Fig. 6.\n1) Sensors and Micro Control Units: Sensors and Micro Control Units (MCUs) are fundamental components of edge networks. Sensors are devices that capture real-time data from the physical environment, such as temperature, motion, and gas composition. This type of devices are the most scattered IoT devices and thus located at the bottom level in Fig. 6, where several example sensors as shown. The DS18B20 [66], a digital temperature sensor, is known for its precision and ease of integration. The MPU-6050 [67] sensor tracks motion by combining a gyroscope and accelerometer, ideal for 3D movement analysis. Additionally, the MQ-2 [68] sensor detects combustible gases and smoke, illustrating the sensors' diverse applications from home safety to industrial monitoring. MCUs are small computing devices that process data at the network's edge. The Arduino Uno [69], a popular choice for DIY projects, excels in simple automation tasks. In contrast, the STM32F103C8T6 [70] is known for its robust performance in complex industrial applications. The ESP8266 [71], widely used in IoT devices, efficiently handles Wi-Fi connectivity. Positioned at the lowest level of the edge computing network's hierarchy, these sensors and MCUs facilitate in-situ data collection and processing, significantly diminishing the necessity of relaying data to distant servers.\n2) Embedded and Mobile Devices: Embedded and Mobile Devices are advanced systems that integrate multiple sensors and MCUs into a single, often portable, framework. Unlike standalone sensors or MCUs that primarily capture or process data, these devices offer comprehensive functionality, including data processing, analysis, and user interaction. They excel in gathering, interpreting, and interacting with data, while seamlessly integrating with other devices and networks, showcasing advanced complexity and connectivity. Embedded devices are specialized computing units designed for specific functions within larger systems. The Raspberry Pi series [72] is a prime example, widely adopted for its versatility and accessibility in both educational settings and hobbyist projects. Advancing in performance, the NVIDIA Jetson series [73] steps in, equipped with GPUs to handle more resource-demanding tasks like AI and machine learning, making them suitable for complex computational needs. Transitioning to mobile devices, smartphones epitomize versatility and connectivity, with models like the iPhone [74] and Samsung Galaxy [75] offering advanced computing power and a wide array of features. Wearable technology, such as the Apple Watch [76] and Fitbit [77], further extends this mobility, providing health tracking and communication in portable, user-friendly designs.\n3) Robotics and Vehicles: Robotics and vehicles, distinct from embedded and mobile devices, usually excel in functionality, autonomy, and complexity. While embedded devices are integral to these systems, robotics and vehicles incorporate them into more complex frameworks, designed for higher autonomy and minimal human intervention. Robotics, for example, integrates sensors, embedded computers, and complex control algorithms to enable machines to autonomously interact with their environment. This autonomy is showcased in various applications, from industrial robots that perform precise and repetitive tasks, to service robots designed for dynamic environments like healthcare or customer support [78], [79], where they navigate, make decisions, and act with minimal human oversight. Autonomous vehicles, ranging from self-driving cars to unmanned aerial vehicles (UAVs) [80], are equipped with advanced navigation systems, real-time data processing, and sophisticated decision-making algorithms. These systems allow them to interpret and respond to diverse environmental conditions. For instance, autonomous cars [81] use a combination of LIDAR, radar, and cameras to understand their surroundings, while UAVs [82] might employ GPS and inertial navigation systems for precise positioning and path planning.\n4) Edge Servers: Edge servers act as micro-data centers to deliver services in a way that's similar to using cloud servers but with a key difference: they are situated closer to the data source. This proximity not only ensures adherence to data localization laws but also significantly reduces data transfer latency. This is particularly beneficial for edge applications with stringent data privacy and real-time processing requirements. Edge servers, which typically exhibit modest performance in contrast to their cloud counterparts, are distinguished by their reduced power requirements and cost-effectiveness. A notable exemplification of edge servers includes Dell PowerEdge series [83] and Lenovo ThinkSystem series [84], both of which are industry standards for edge computing solutions. While edge servers often look like a typical server, many other form factors exist. Examples include a ruggedized laptop, a purpose-built appliance, or a robust mobile device featuring onboard intelligence, all of which can function as edge servers [85].\n5) Edge Cloud: Edge cloud services extend cloud computing's convenience to the network's edge, with providers like AWS and Google offering solutions such as AWS Edge Service [86] and Google Distributed Cloud Edge [87]. Edge cloud are usually hosted by micro-data centers comprising edge servers that store, analyze, and process data faster than is possible using a connection to a cloud data center. By combining a distributed content delivery network (CDN) [88], the edge cloud significantly enhances services such as streaming for live broadcasting, cloud gaming, and virtual reality (VR) [89] experiences. These applications gain from the edge cloud's reduction of data transmission latency, which concurrently amplifies local device storage and processing capabilities, yielding more efficient and agile digital experiences."}, {"title": "C. Software Frameworks for Edge Networks", "content": "The environments in which edge networks operate are markedly more complex and heterogeneous compared to cloud data centers. This complexity is evident in multiple dimensions: (1) The connectivity landscape is fragmented with a plethora of communication protocols", "90": "and is further complicated by the mobility and intermittence of many edge devices. (2) The diversity in operating systems is considerable", "91": "catering to various operational needs. (3) This heterogeneity is also evident in the platform architectures of edge nodes", "92": "each contributing to the multi-faceted nature of edge computing. (4) The development of IoT applications within this domain is characterized by a varied use of programming languages", "93": ".", "Computing": "Software frameworks for edge computing across edge networks are often cross-platform", "94": "is an open-source edge platform that lets users create IoT gateway functionality from edge devices", "95": "has taken a similar approach to EdgeX Foundry to provide a platform for developing IoT gateways. Apache Edgent [96", "97": "is a purpose-built", "98": "and MNN [99", "Techniques": "The requirements of Virtualizing and resource management technology reflect in the following aspects: (1) The challenge of uniformly managing resources across widely distributed and diverse devices in edge networks. (2) The need for resource isolation on edge nodes running multiple applications to prevent contention. (3) Edge applications' reliance on various software library versions and dependencies, where virtualization aids in efficient management and compatibility. KubeEdge [100", "101": "are open-source container-centric virtualizing and resource management techniques based on Kubernetes [102", "103": "enables developers to package services into modules and run them using the Azure IoT Edge runtime."}]}