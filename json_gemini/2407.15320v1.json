{"title": "Edge Graph Intelligence: Reciprocally Empowering Edge Networks with Graph Intelligence", "authors": ["Liekang Zeng", "Shengyuan Ye", "Xu Chen", "Xiaoxi Zhang", "Ju Ren", "Jian Tang", "Yang Yang", "Xuemin (Sherman) Shen"], "abstract": "Recent years have witnessed a thriving growth of computing facilities connected at the network edge, cultivating edge computing networks as a fundamental infrastructure for supporting miscellaneous intelligent services like personal voice assistance, video security surveillance, and autonomous driving vehicles. Meanwhile, Artificial Intelligence (AI) frontiers have extrapolated Machine Learning (ML) to the graph domain and promoted Graph Intelligence (GI), which unlocks unprecedented ability in processing, abstracting, and learning from massive data in graph structures. Given the inherent relation between graphs and networks, the interdiscipline of graph representation learning and edge networks, i.e., Edge GI or EGI, has revealed a novel interplay between them GI models principally open a new door for modeling, understanding, and optimizing edge networks, and conversely, edge networks serve as physical support for training, deploying, and accelerating GI models. Driven by this delicate closed-loop, EGI can be widely recognized as a promising solution to fully unleash the potential of edge computing power and is garnering significant attention. Nevertheless, research on EGI yet remains nascent, and there is a soaring demand within both the communications and AI communities for a dedicated venue to share recent advancements. To this end, this paper promotes the concept of EGI, explores its scope and core principles, and conducts a comprehensive survey concerning recent research efforts on this emerging field and specifically, introduces and discusses: 1) fundamentals of edge computing and graph representation learning, 2) emerging techniques centering on the closed loop between graph intelligence and edge networks, i.e., \"edge for GI\" and \"GI for edge\", and 3) open challenges and research opportunities of future EGI. By bridging the gap across communication, networking, and graph learning areas, we believe that this survey can garner increased attention, foster meaningful discussions, and inspire further research ideas in EGI.", "sections": [{"title": "I. INTRODUCTION", "content": "EDGE networks are swiftly proliferating. By assem-bling progressively spreading computing facilities at the network edge, edge networks have hosted ever-increasing amounts of data, storage, and computing resources. They have become a fundamental infrastructure supporting mis-cellaneous applications like smart industrial manufacturing [1], [2], streaming video analytics [3], [4], and Internet of Robotics and Vehicles [5], [6], etc. As a complementary symmetry of the centralized core network, edge networks locate at the end of the Internet and encompass users in their physical vicinity, allowing for user-centric services with reduced response latency, improved resource efficiency, and enhanced privacy and security. Benefited from these unique architectural superiorities, edge networks have been a vital ex-perimentation arena for advanced communication techniques. They are practically favorable for emerging intelligence ser-vices with delay-sensitive, resource-demanding, and privacy-preserved requirements, and have been widely recognized as a promising prospect for bridging the last mile between Artificial Intelligence (AI) and human beings [7], [8].\nMeanwhile, AI is also rapidly booming. To fully unleash the potential of big data in diverse forms, recent AI advances have extrapolated representation learning over massive data from Euclidean structure to graph topology, pushing Deep Learning (DL) frontiers to a new stream of models named Graph Neural Network (GNN) [9], [10]. Different from traditional DNN (e.g., CNN, RNN) that typically applies 1D/2D convolutions, GNN introduces graph embedding techniques to digest infor-mation from graph relations [11], [12]. Specifically, it applies neighbor aggregation on an input graph iteratively and captures hierarchical patterns through neural network operators from subgraphs of varying sizes. This enables GNNs to abstract and learn the properties of specific vertices, links, or the entire graph, and thus generalize to unobserved graphs. Leveraging such powerful expressiveness, learning with GNN, i.e., Graph Learning (GL), has exhibited superior graph analysis perfor-mance and empowers various graph-related tasks from node classification and link prediction to graph isomorphism and categorization [13], [14]."}, {"title": "A. Motivation and Benefits of Edge Graph Intelligence", "content": "Given the remarkable success of Graph Intelligence (GI) and edge networks in their respective fields, the inherent connection between graphs and networks impels them to a confluence. As illustrated in Fig. 1, GI provides a vast zoo of empirical learning models (e.g., convolutional and recur-rent GNNs, graph autoencoders) as well as various learning paradigms like Transfer Learning (TL) and Reinforcement Learning (RL), allowing advanced learning ability from graph data. Symmetrically, edge networks generally comprise of a rich set of platforms including mobile devices, robots, vehicles, and edge nodes, which host miscellaneous graph-based applications such as traffic forecasting and network resource management. Their bidirectional interaction, where GI enhances and optimizes edge networks and edge networks support and enable GI computation, draws a closed loop with mutual empowerment and nurtures a reciprocal interplay of their integration, namely \"Edge Graph Intelligence\" or \"EGI\" for brevity. More specifically, by fusing GI and edge computing, EGI provides three-fold reciprocal benefits in the following aspects.\n\u2022 Reciprocal performance enhancement: With the rapid proliferation of mobile and IoT devices, data generated at edge networks have skyrocketed in both quantity and modality (e.g., physical signals, digital audio, and visual content). As predicted by IDC [15], the billions of IoT devices in edge networks are expected to generate over 90 Zettabyte of data in 2025. This naturally provides a data nursery for modifying, training, and fine-tuning GI models with real-world data, thus boosting GI models toward higher-degree intelligence. Contrariwise, given the rich relational data collected at edge networks, GI enables modern graph analysis for understanding, diagnosing, and optimizing edge networks, which steers the enhancement of network performance such as robustness and Quality of Service (QoS).\n\u2022 Reciprocal capability expansion: As the last mile of the Internet, edge networks are continuously incubating pioneering user-centric scenarios surrounding terminal users, where many of them can be abstracted in graphs (e.g., wireless sensor networks, Internet of Vehicles). These scenarios act as a burgeoning force from the demand side to drive the development and deployment of GI, augmenting the application scope of GI models. Reversely, applying GI to edge networks thus unlocks their extended capability in securing edge networks from anomalies, developing new graph-based applications, and intelligently serving graph-related tasks. This is attributed to GI models' innovative mechanism that combines graph embedding and convolution, which enables GI to deliver an unprecedented ability to learn and infer from graphs such as high-precision node identification and link pre-diction.\n\u2022 Reciprocal technology democratization: Technology democratization envisions making both GI and edge computing more usable, understandable, and friendly to a broader range of people, and has become a crucial agenda for social good. Towards that, GI and edge networks carry out mutual empowerment to improve each other. On the one hand, edge networks can democratize GI by rendering accessible and affordable intelligent computation closer to end users, allowing GI to be available and personalized in diverse scenarios. On the other hand, GI may popularize edge networks through prevailing GI-enabled applications at the edge. Specifically, given the computation-intensive and data-dependent nature of many GI models, edge computing exhibits its clear advantages against cloud computing by providing computing resources with lower delay and reduced bandwidth budget and is thus aligned well with GI. With the prevalence of GI surrounding end users, edge networks also gather attention and deploy-ment for popularization."}, {"title": "B. Scope and Rating of Edge Graph Intelligence", "content": "While the term EGI is fresh to come, research and practices have begun early. Since the development of GCN in 2015 [16], GI has increasingly gained popularity in the AI community and ignited a wave of building GNNs over various real-world graphs. Meanwhile, edge networks and edge computing are also rapidly evolving and actively embracing AI from 2019, giving rise to the concept of edge AI or edge intelligence [8], [17], [18]. Currently, the interplay of EGI has attracted growing attention from both the industry and academia and propelled a plethora of innovative optimizations, techniques, and applications at the network edge, e.g., traffic flow fore-casting [19], [20], location-based recommendation [21], [22], and vehicle trajectory prediction [23], [24]. As a substantial extension of edge AI, EGI sheds light on its fundamental questions - how deeply edge networks and AI techniques can be fused and how much potential their fusion can shine - and demonstrates its powerful capability through plentiful realistic applications.\nNonetheless, discussions on EGI are still narrowly limited to unilateral dimensions. Existing literature has either reviewed the graph learning landscape with limited discussion on their applications in edge networks [9], [10], [13], or focused particularly on applying GI techniques on some specific edge scenarios (e.g., traffic domain [25]\u2013[27], power grids [28]\u2013[30]), yet ignoring the big picture of general edge networks spectrum. Some recent literature [31]\u2013[33] also reviews the progress of GI in the context of IoT and wireless networks but mainly focuses on GI applications in their discussed scopes and lacks a systematic taxonomy on the \"Edge for GI\" aspect, which is one of the fundamental pillars in EGI's closed loop. Although the edge computing and communica-tions community has extensively investigated edge intelligence systems, a majority of them [8], [34]\u2013[37] center on general AI computation systems or are dedicated to traditional DL workloads such as CNNs or RNNs, where GI models, which possess distinct capabilities and unique characteristics, are much less understood.\nIn this paper, we advocate that EGI should not be restricted to merely applying GI on edge data or running GI on edge platforms. Instead, GI and edge networks are blending a confluence and EGI should be treated as a whole to reflect the inherent interplay between GI and edge networks. This indi-cates that their bilateral empowerment desires a comprehensive exploration such that the degree of EGI can be identified and measured. Specifically, according to the fusion of GI and edge networks, we may rate EGI into six levels from their respective perspectives, as shown in Fig. 2.\n\u2022 Level 0: Given the graph data implicated in the edge network infrastructure, analytical models in Level 0 are unaware of the graph structures. The edge computing sys-tems also process data in an graph-agnostic way. In other words, neither the model side nor the infrastructure side explicitly tackles \"graphs\", and thus they are categorized to the initial level.\n\u2022 Level 1: Data collected from edge networks are modeled in graphs. Systems at Level 1 push one step further over Level 0 by endowing graph semantic to edge data (with general computing methods).\n\u2022 Level 2: Edge data in graph forms are processed with traditional graph computing algorithms such as PageRank and single-source shortest path algorithms. Systems at Level 2 outperform Level 1 by enabling the graph-oriented computing capability.\n\u2022 Level 3: Edge networks serve GI model inference with graph data, where the models may be trained on the cloud. Compared with lower levels, systems at Level 3 initiate AI to edge networks and embrace GI models.\n\u2022 Level 4: Edge networks perform GI model training with graph data. The key difference between Level 4 and Level 3 lies in the ability of learning edge-native GI models, e.g., fine-tuning model parameters with edge data.\n\u2022 Level 5: Interactional EGI, where GI and edge networks can dynamically adapt their configurations during the runtime for optimal EGI performance. Systems at Level 5 outperform all other levels because they can adjust GI and edge networks on the fly, whereas lower levels are all static settings. Both perspectives of GI and edge networks reach a convergence since they are in complete harmony.\nThe rating of EGI can be mainly divided into three intervals. The first interval covers from Level 0 to Level 2, where EGI is less related to AI and even processes non-graph data. The second interval comprises Level 3 and Level 4, where EGI incorporates GI models by either inference or training on edge networks. The third interval is exactly Level 5, which stands at the highest level because its GI and edge networks have profoundly blended as integration and can adapt to diverse scenarios on the fly. As EGI systems locates at higher levels, their fusions of GI and edge networks go deeper. As a result, the intelligence resources of GI and infrastructural resources of edge networks are progressively exploited for better EGI performance. Nonetheless, this may also come at the cost of additional development effort and system overhead. This conflict implies that there is no \u201csilver bullet\" in all cases. Instead, the panacea of EGI in practice should align with user demand, anticipating a joint consideration of specific application scenarios as well as available resources budgets."}, {"title": "C. Summary and Contribution", "content": "In this paper, we discuss in-depth how GI and edge networks are reciprocal to each other, and conduct a comprehensive and concrete survey of the recent research efforts on EGI. In partic-ular, centering around the inherently interconnected nature of graphs and networks, this paper reveals the bilateral interplay, for the first time, between GI and edge networks, and provides a concise rating in accordance with their mutually beneficial interactions. In light of the rating, our survey identifies the four primary enablers essential for EGI, as illustrated in Fig. 3:\n\u2022 GI applications at Edge (Sec. IV): Typical application scenarios and use cases for applying GI in edge networks;\n\u2022 Edge Networks for GI (Sec. V): Paradigms of GI model computation, including model training and inference, for GI over edge networks;\n\u2022 GI for edge networks (Sec. VI): Practical GI-based methods for optimizing edge networks concerning their specific functionalities;\n\u2022 EGI ecosystems (Sec. VII): full-stack infrastructural sup-port for high-performance EGI computation in terms of hardware, software, and benchmarks.\nIn general, these key enablers can be well accommodated in the closed loop, i.e., \"edge for GI\" and \"GI for edge\" as described in Fig. 1, In the \"edge for GI\" course, edge networks provide physical platforms and software stacks to graph intelligence, serving as infrastructure to support GI models training and inference processes. More specifically, GI models' intensive training workload can be resolved by means of pools of edge resources (e.g., federated edge learning), and edge inference techniques are developed for deploying and accelerating GI models under resource constraints and SLO requirements. Alternatively, in the \u201cGI for edge\" course, GI models with these inference solutions can thereafter be efficiently executed upon edge platforms, which enables mis-cellaneous graph-based applications and optimizes various as-pects of edge networks. Besides reviewing these key enablers, our survey provides fundamental and friendly premiers of GI and edge networks that assume no prior knowledge of GI or edge computing. We also discuss various open challenges and research directions toward future EGI, encouraging both AI and communications communities to advance EGI for a broader range of people.\nThe rest of this paper is organized as follows: First, Sec. II and Sec. III briefly review the primers of graph intelli-gence and edge computing networks, respectively. Next, the subsequent sections introduce research efforts with respect to the four enablers: GI applications at Edge (Sec. IV), edge networks for GI (Sec. V), GI for edge networks (Sec. VI), and EGI ecosystems (Sec. VII). Finally, Sec. VIII discusses open challenges and future research opportunities of EGI and Sec. IX concludes. Table I lists the main abbreviations used in this survey."}, {"title": "II. PRIMER ON GRAPH INTELLIGENCE", "content": "As one of the key flywheel actuating the loop within EGI , graph representation learning is devoted to the algorithm side and contributes enhanced ability in graph data processing. Before diving into EGI, this section compendiously introduces graph representation learning with respect to its basic concepts, general workflow, and representative models and learning paradigms. For a more comprehensive treatment of GI, con-centrated reviews [9], [13], [14], [38] on graph representation learning are highly recommended. Table II lists the main notations used in this section.\nGraphs are a way to organize data, and with graphs, one can succinctly characterize relationships across scattered data points. The input of GI models, i.e., GNNs, are graphs, which typically contain two types of data. One is the adjacency matrix or adjacency list, which interprets the graph topology, and the other is the feature vectors that describe vertices and edges' actual properties. Formally, an input graph is denoted as G = (V,E), with vertices and links collected in V and E, respectively.\nVertices and Links: Vertices or nodes in a graph can be items, objects, or entities, and are not necessarily homo-geneous when constructing a graph. For instance, a location-based knowledge graph can represent its vertices as human users, IoT devices, scenic spots, and any other entities of various types within a specific district. Links are another es-sential component in graphs that characterizes the relationships between these items, objects, or entities. Note that to avoid misunderstanding, we exclusively use \"links\" to indicate the connection between vertices in an input graph while leaving \"edge\" for edge networks. A link can be defined with respect to the two (not necessarily unique) vertices associated with it. For V\u2208 Gand & \u2208 G, we denote their size, i.e., the number of vertices and links, as V and E, respectively, and use v and e to index arbitrary vertex and link in them.\nNeighbors: Neighbors are ego-networks centering on specific vertices within a graph. For a vertex v, its neighbors cover the vertices directly connected to v and their adjoin-ing links. Note that a vertex's neighbors can be iteratively expanded by considering the neighbors of its neighbors. For-mally, given N(k) as vertex v's k-hop neighbors, we have N(k+1) = {N(1) Vu \u2208 N(k)}, where N(1) indicates v's one-hop direct neighbors.\nRepresentation Vectors, Features, and Embeddings: Representation vectors are the numerical vectors associated with vertices and links, and are also referred to as encodings, representations, latent vectors, or high-level feature vectors de-pending on the context. In this section, we respectively denoted representation vectors by h(1) and h(1) at the 1-th GNN layer. Upon input to the model, the initial representation vectors h(0) and h(0) are exactly the features attached to vertices and links, which quantify physical properties in specific applications. Extending the above knowledge graph example, the features of a vertex may include the users' age and food preferences, and for a scenic spot, it can be location and popularity. After processing through model layers, the exported representation vectors are embeddings, a form of compressed feature repre-sentations of vertices, links, neighbors, or graphs. Embeddings can be viewed as the mappings of original data in latent spaces, which effectively reserve the semantics implicated in the input graph while can be used by downstream models for specific tasks (e.g., vertex classification and link prediction).\nModel Output: The final output of GI models depends on the way of processing embeddings, i.e., the readout function. In general, the outcome of GI models can be grouped into three types: 1) Vertex-level output, where the result is vertex-wise predictions (e.g., classes, scores) for some dedicated vertices. 2) Link-level output, where the result is link-wise predictions for some dedicated links. 3) Graph-level output, where the results are the prediction of the whole graph (e.g., the operational status of a power grid)."}, {"title": "B. General Workflow", "content": "A GI model is an algorithm that essentially leverages graph topology to abstract and learn the relationships between vertices and links. It takes an attributed graph as input, and output embeddings or predictions in an application-admitted format. Among versatile GI models, the GNN series is the state-of-the-art genre and is prevalent in various types of edge applications, thus we illustrate the general workflow of GI model based on GNN models. Fig. 4 depicts the general workflow of them.\nPreprocessing: The first step serves as an initialization to prepare data in a format aligned with the targeted GI model's requirement. This can be, for example, reorganizing the adjacency matrix in a dense format or the compressed sparse row format and dropout some irrelevant elements from the feature vectors. Since the GI model is often known ahead of runtime, graph preprocessing is usually done offline.\nSampling: With the preprocessed input graph, the GI model dives into iterations. The number of iterations required is exactly the number of layers the GI model possesses. Within each iteration, it first applies sampling on the input graph G to reduce the computational complexity of subsequent steps. Assuming the sampling function as 0(1), this step can be formally written in:\nG' = 0(1) (G).\n(1)\nThe result of sampling is a sampled graph G', where G' = (V', E'). Note that this is an optional step and inference processes typically deactivate this step for prediction accuracy.\nAggregation: Upon the sampled graph G', the GI model performs neighbor aggregation where each vertex/link pulls feature vectors from its neighbors. Taking vertices aggregation as example, let ov be the aggregation function of vertices, we have\na(l) = ov (h(l), huu ), \u2200v \u2208 V', \u2200u \u2208 N(v),\n(2)\nwhere huu \u2208 N(v)} collects v's neighboring vertices' representation vectors and all is the aggregation result.\nUpdate: The GI model then passes the aggregation h(1) through a neural network operator to update v's representation vector:\nh(l+1) = (h(l)), Vv \u2208 G'.\n(3)\nThis operator is usually learnable Multi-Layer Perceptron (MLP) and non-linear activations like the sigmoid function. Note that Eq. (2) and Eq. (3) are merely described for vertices for simplicity. Repeating the same procedure to all vertices and links yields the complete representation vectors for the whole graph.\nPooling: Pooling is also an optional step that aims at reducing the original graph to a smaller graph for lower computational complexity. It directly operates the sampled graph with updated representation vectors, pooling fields of graphs:\nG' = v(1) (G').\n(4)\nReadout: The above sampling, aggregation, update, and pooling steps will iterate until all model layers are processed, and thereafter generate embeddings of all vertices and links. To attain the desired results demanded by applications, these embeddings are obliged to the final readout step, which applies a pre-defined operator or model to transform embeddings to a global output, as explained in Sec. II-A5. Given a readout function 4, the global output vector can be obtained by:\ny = (h(L), h(L)|v, e \u2208 G).\n(5)\nIn summary, executing a GI model can be regarded as processing a collection of operators and neural networks itera-tively over a graph, where each iteration, i.e., each model layer, comprises weights that specify the computation of vertices' and links' feature vectors. These weights are learnable via model training, i.e., through the means of backpropagation algorithms such as gradient-based optimization. Specifically, during model training, a GI model with L layers undergoes a forward pass: first transforms input graph through model layers to graph embeddings, and next converts the obtained embeddings into desired results. With the exported result and known labels, the model computes the pre-defined loss function, where the gradient is then backpropagated across the layers, updating the shared weights. This process is carried out iteratively with multiple samples, which are often in batches until an expected accuracy is attained. For model inference, it directly goes through a forward pass and generates the predictions."}, {"title": "C. Graph Learning Models", "content": "There are multifarious GI model variants developed for mul-tifarious applications with multifarious ability requirements. For brevity, here we enumerate several representatives that are commonly adopted in edge scenarios.\nRecurrent Graph Neural Network (RecGNN): RecGNNS are a pioneering architecture that builds the conceptual foun-dation in the field of graph representation learning [9]. They are primely proposed to learn node representations using recurrent neural architectures, integrating a recurrent hidden state and graph signal processing (GSP) to exploit the spatial structural information inherent in graph processes. As a genre of GI models dating back to the \"pre-deep-learning\" era, RecGNNs have inspired numerous subsequent research such as convolutional variants.\nConvolutional Graph Neural Network (ConvGNN): ConvGNNs extend convolution operations from grid data to graph data, aggregating the features of vertices and links with their neighbors to generate representations [10], [14]. Contrary to RecGNNs, successive graph convolutional layers are stacked in ConvGNNs to extract hierarchical patterns from subgraphs [16]. Among GNNs, ConvGNNs serve as a foundational component in constructing various advanced GI models [39].\nGraph Attention Network (GAT): GATs inherit spatial ConvGNNs by incorporating the attention mechanism into the aggregation functions, which effectively improves the capacity as well as the expressiveness of GI models [40]. The rationale behind this combination is to differentiate the contribution of vertices' neighbors in a learning manner [41]. Based on this, many types of attention mechanisms are derived such as self-attention, gating attention, and semantic-level attention.\nGraph Autoencoder (GAE): GAEs are unsupervised frameworks that encode vertices, links, or graphs into a latent vector space and reconstruct graph data by decoding their encoded information [13]. GAEs are particularly useful for graph generation tasks, where a GAE model employs graph convolutional layers to compute embeddings for vertices and rebuild the graph adjacency matrix via decoders.\nSpatio-Temporal Graph Neural Network (STGNN): STGNNs analyze dynamic graphs from both the spatial and temporal dimensions [42], [43]. Each vertex and link in these graphs attaches a feature vector that describes their behaviors within a time window, and STGNNs aim to learn their patterns and predict their changes in the incoming time slots. To extract information from spatial-temporal dependencies, many sequential decision-making approaches are applied, e.g., Long Short-Term Memory (LSTM).\nGraph Transformer and Graph Foundation Model: Graph transformers explore embracing transformer architec-ture to the graph domain in pursuit of improved graph model-ing ability [44]\u2013[46]. Typically, graph transformers incorporate GNN with transformers in dual ways: 1) design tailored positional embedding modules and graph-specific attention matrices, and 2) exploit GNNs as an auxiliary module by com-bining GNNs into transformer architectures [47]. Following this line, scaling small transformers to huge foundation models leads to Graph Foundation Models (GFMs) [48], [48] and Large Graph Models (LGMs) [49]. Motivated by the success of Large Language Models (LLMs), many researchers believe that utilizing pretraining techniques to resolve massive graph data can breed a comprehensive GI model, which possesses advanced abilities such as in-context graph understanding and versatile graph reasoning [50]. Nevertheless, GFMs and LGMs are still in a very early stage of their development and demands for further exploration."}, {"title": "D. Learning Paradigms", "content": "Given a rich zoo of GI models, distinct learning paradigms empower them with distinct abilities for edge applications. We provide several example learning paradigms as follows.\nSupervised Learning: Supervised learning is one of the most fundamental training paradigms in ML, which requires labeled data to guide the optimization of models [51], [52]. For GNNs, supervised learning enables to capture both local and global graph structures and the latent information of vertices and links. It iteratively optimizes model parameters by minimizing the difference between the model's predictions and the labels, where the performance of the model is evaluated on a separate test set of labeled objects. Supervised GL have found success in various domains such as social network analysis, intelligent transportation, and recommendation sys-tems. However, in many real-world scenarios where labels are unavailable or expensive, supervised learning is constrained and other semi-supervised or unsupervised learning paradigms are introduced.\nTransfer Learning (TL): TL for GI models builds upon the assumption that the learned representations and knowledge from a source graph can be effectively transferred and applied to a targeted graph [53], [54]. Based on this, it exploits knowledge distillation methods to extract the knowledge from one graph data to improve the learning performance on another different but related graph data. By transferring knowledge across graphs, the target graph benefits from the learned representations, enabling improved prediction performance for the targeted graph, even with limited labeled data.\nContrastive Learning (CL): CL for GI models is a self-supervised learning paradigm that learns meaningful represen-tations by contrasting positive and negative samples, where positive samples are pairs of vertices, links, or subgraphs that are similar or related, and negative ones are the contrary [55]\u2013[57]. With these samples, contrastive learning maximizes the similarity between positive samples and minimizes the similarity between negative samples. Various techniques have been applied to enhance contrastive learning on graphs, such as graph augmentation and sample generation with random walks.\nFederated Graph Learning (FGL): FGL applies Feder-ated Learning (FL) on graphs, which allows multiple clients to collaboratively train a GI model without sharing their local data [58]\u2013[60]. In particular, each client trains the GI model using its local graph data and shares only the model updates, i.e., gradients or weights, with a central coordinator, and the coordinator aggregates the updates and sends a merged model update back to each client. Graph data are typically distributed across clients, with respect to structural segments, i.e., subgraphs, or feature segments. More details on FGL are discussed in Sec. V-A.\nDeep Graph Reinforcement Learning (DGRL): DGRL combines GI models with Deep Reinforcement Learning (DRL) techniques for interacting with graph environments [61], [62]. Typically, in DGRL, the GI model is responsible for processing the graph data, extracting features, and capturing the relationships between vertices and links. The DRL compo-nent then uses the embeddings computed by the GI model to learn a policy and make decisions, often by taking actions like vertex selection, link insertion/removal, or graph modification. Benefiting from the superior capability of representing graphs, DGRL has become a powerful tool for graph-based sequential decision-making tasks."}, {"title": "III. PRIMER ON EDGE NETWORKS", "content": "In the evolving landscape of distributed computing, the edge network emerges as a pivotal architecture, facilitating the transition from centralized cloud-based core networks to more decentralized edge networks [63]\u2013[65]. Fig. 5 illustrates the edge network as a cohesive architecture that integrates the Edge and End layers, encompassing devices naturally situated closer to end users. Besides traditional network-style topology, edge networks can exhibit versatile organizations such as peer-to-peer connection (e.g., client-server mode) and star-like interactions (e.g., one-to-many subscription). Albeit, all these topologies can be unified by the graph abstraction. On the other hand, core networks and the Internet also comprise many graph structures and have introduced GI over their graphs. However, it should be emphasized that EGI is significantly different from GI on core networks given the unique characteristics of edge networks.\nSpecifically, in contrast to the centralized core networks, several salient features distinguish edge networks: (1) Dis-tributed: Edge networks are characterized by their geographi-cally dispersed resources, such as edge servers and mobile de-vices, in stark contrast to the centralized nature of cloud-based data centers. (2) Heterogeneity: Edge networks encompass a diverse array of edge devices and servers, each varying in computational capacity, network bandwidth, and hardware ar-chitecture, embodying an extremely heterogeneous computing environment. (3) Resource Constraints: Unlike cloud-based data centers equipped with high-performance accelerators and dedicated ultra-speed links, devices within edge networks often operate under resource limitations, facing constraints in aspects like computational throughput, device-to-device communication bandwidth, and memory capacity. (4) Dynamic Resources: The proximity of edge network devices to end users inherently results in greater dynamism in resource availability. Their mobility across various networking domains and mul-titasking with multiple applications simultaneously contribute to frequent fluctuations in both network and computational resources.\nEmerging from the advanced architecture of edge networks, edge computing stands as a new computing paradigm in contrast to cloud computing [8], [34]. Edge computing rep-resents a shift in computational paradigm that brings data processing exponentially closer to the point of data collection and consumption, enabling low-latency and high-bandwidth communication essential for real-time applications. Edge com-puting, in comparison to cloud computing, presents numerous advantages, notably in its approach to in-situ data processing: (1) Lower Core Network Reliance: Edge computing lessens the reliance on unstable and delay-prone core networks by localizing data processing within edge networks, ensuring more consistent QoS even when wide-area network (WAN) connections are unpredictable. (2) Alleviated Core Network and Cloud Datacenter Stress: With the sheer volume of edge and end devices, routing all data through the core network to cloud data centers imposes substantial strain in terms of communication, computation, and storage. Edge computing mitigates this by retaining computations within the edge network, effectively utilizing the distributed, idle resources of edge and end devices. (3) Privacy and Security Enhancement: Localizing data within edge networks, minimizes the risk of unauthorized access and privacy breaches. Transferring these data to the cloud-based data centers owned by commercial companies inevitably raises users' privacy concerns."}, {"title": "B. Components of Edge Networks", "content": "Locating at the periphery of the Internet", "Units": "Sensors and Micro Control Units (MCUs) are fundamental components of edge networks. Sensors are devices that capture real-time data from the physical environment", "Devices": "Embedded and Mobile Devices are advanced systems that integrate multiple sensors and MCUs into a single", "Vehicles": "Robotics and vehicles"}, {"title": "Edge Graph Intelligence: Reciprocally Empowering Edge Networks with Graph Intelligence", "authors": ["Liekang Zeng", "Shengyuan Ye", "Xu Chen", "Xiaoxi Zhang", "Ju Ren", "Jian Tang", "Yang Yang", "Xuemin (Sherman) Shen"], "abstract": "Recent years have witnessed a thriving growth of computing facilities connected at the network edge, cultivating edge computing networks as a fundamental infrastructure for supporting miscellaneous intelligent services like personal voice assistance, video security surveillance, and autonomous driving vehicles. Meanwhile, Artificial Intelligence (AI) frontiers have extrapolated Machine Learning (ML) to the graph domain and promoted Graph Intelligence (GI), which unlocks unprecedented ability in processing, abstracting, and learning from massive data in graph structures. Given the inherent relation between graphs and networks, the interdiscipline of graph representation learning and edge networks, i.e., Edge GI or EGI, has revealed a novel interplay between them GI models principally open a new door for modeling, understanding, and optimizing edge networks, and conversely, edge networks serve as physical support for training, deploying, and accelerating GI models. Driven by this delicate closed-loop, EGI can be widely recognized as a promising solution to fully unleash the potential of edge computing power and is garnering significant attention. Nevertheless, research on EGI yet remains nascent, and there is a soaring demand within both the communications and AI communities for a dedicated venue to share recent advancements. To this end, this paper promotes the concept of EGI, explores its scope and core principles, and conducts a comprehensive survey concerning recent research efforts on this emerging field and specifically, introduces and discusses: 1) fundamentals of edge computing and graph representation learning, 2) emerging techniques centering on the closed loop between graph intelligence and edge networks, i.e., \"edge for GI\" and \"GI for edge\", and 3) open challenges and research opportunities of future EGI. By bridging the gap across communication, networking, and graph learning areas, we believe that this survey can garner increased attention, foster meaningful discussions, and inspire further research ideas in EGI.", "sections": [{"title": "I. INTRODUCTION", "content": "EDGE networks are swiftly proliferating. By assem-bling progressively spreading computing facilities at the network edge, edge networks have hosted ever-increasing amounts of data, storage, and computing resources. They have become a fundamental infrastructure supporting mis-cellaneous applications like smart industrial manufacturing [1], [2], streaming video analytics [3], [4], and Internet of Robotics and Vehicles [5], [6], etc. As a complementary symmetry of the centralized core network, edge networks locate at the end of the Internet and encompass users in their physical vicinity, allowing for user-centric services with reduced response latency, improved resource efficiency, and enhanced privacy and security. Benefited from these unique architectural superiorities, edge networks have been a vital ex-perimentation arena for advanced communication techniques. They are practically favorable for emerging intelligence ser-vices with delay-sensitive, resource-demanding, and privacy-preserved requirements, and have been widely recognized as a promising prospect for bridging the last mile between Artificial Intelligence (AI) and human beings [7], [8].\nMeanwhile, AI is also rapidly booming. To fully unleash the potential of big data in diverse forms, recent AI advances have extrapolated representation learning over massive data from Euclidean structure to graph topology, pushing Deep Learning (DL) frontiers to a new stream of models named Graph Neural Network (GNN) [9], [10]. Different from traditional DNN (e.g., CNN, RNN) that typically applies 1D/2D convolutions, GNN introduces graph embedding techniques to digest infor-mation from graph relations [11], [12]. Specifically, it applies neighbor aggregation on an input graph iteratively and captures hierarchical patterns through neural network operators from subgraphs of varying sizes. This enables GNNs to abstract and learn the properties of specific vertices, links, or the entire graph, and thus generalize to unobserved graphs. Leveraging such powerful expressiveness, learning with GNN, i.e., Graph Learning (GL), has exhibited superior graph analysis perfor-mance and empowers various graph-related tasks from node classification and link prediction to graph isomorphism and categorization [13], [14]."}, {"title": "A. Motivation and Benefits of Edge Graph Intelligence", "content": "Given the remarkable success of Graph Intelligence (GI) and edge networks in their respective fields, the inherent connection between graphs and networks impels them to a confluence. As illustrated in Fig. 1, GI provides a vast zoo of empirical learning models (e.g., convolutional and recur-rent GNNs, graph autoencoders) as well as various learning paradigms like Transfer Learning (TL) and Reinforcement Learning (RL), allowing advanced learning ability from graph data. Symmetrically, edge networks generally comprise of a rich set of platforms including mobile devices, robots, vehicles, and edge nodes, which host miscellaneous graph-based applications such as traffic forecasting and network resource management. Their bidirectional interaction, where GI enhances and optimizes edge networks and edge networks support and enable GI computation, draws a closed loop with mutual empowerment and nurtures a reciprocal interplay of their integration, namely \"Edge Graph Intelligence\" or \"EGI\" for brevity. More specifically, by fusing GI and edge computing, EGI provides three-fold reciprocal benefits in the following aspects.\n\u2022 Reciprocal performance enhancement: With the rapid proliferation of mobile and IoT devices, data generated at edge networks have skyrocketed in both quantity and modality (e.g., physical signals, digital audio, and visual content). As predicted by IDC [15], the billions of IoT devices in edge networks are expected to generate over 90 Zettabyte of data in 2025. This naturally provides a data nursery for modifying, training, and fine-tuning GI models with real-world data, thus boosting GI models toward higher-degree intelligence. Contrariwise, given the rich relational data collected at edge networks, GI enables modern graph analysis for understanding, diagnosing, and optimizing edge networks, which steers the enhancement of network performance such as robustness and Quality of Service (QoS).\n\u2022 Reciprocal capability expansion: As the last mile of the Internet, edge networks are continuously incubating pioneering user-centric scenarios surrounding terminal users, where many of them can be abstracted in graphs (e.g., wireless sensor networks, Internet of Vehicles). These scenarios act as a burgeoning force from the demand side to drive the development and deployment of GI, augmenting the application scope of GI models. Reversely, applying GI to edge networks thus unlocks their extended capability in securing edge networks from anomalies, developing new graph-based applications, and intelligently serving graph-related tasks. This is attributed to GI models' innovative mechanism that combines graph embedding and convolution, which enables GI to deliver an unprecedented ability to learn and infer from graphs such as high-precision node identification and link pre-diction.\n\u2022 Reciprocal technology democratization: Technology democratization envisions making both GI and edge computing more usable, understandable, and friendly to a broader range of people, and has become a crucial agenda for social good. Towards that, GI and edge networks carry out mutual empowerment to improve each other. On the one hand, edge networks can democratize GI by rendering accessible and affordable intelligent computation closer to end users, allowing GI to be available and personalized in diverse scenarios. On the other hand, GI may popularize edge networks through prevailing GI-enabled applications at the edge. Specifically, given the computation-intensive and data-dependent nature of many GI models, edge computing exhibits its clear advantages against cloud computing by providing computing resources with lower delay and reduced bandwidth budget and is thus aligned well with GI. With the prevalence of GI surrounding end users, edge networks also gather attention and deploy-ment for popularization."}, {"title": "B. Scope and Rating of Edge Graph Intelligence", "content": "While the term EGI is fresh to come, research and practices have begun early. Since the development of GCN in 2015 [16], GI has increasingly gained popularity in the AI community and ignited a wave of building GNNs over various real-world graphs. Meanwhile, edge networks and edge computing are also rapidly evolving and actively embracing AI from 2019, giving rise to the concept of edge AI or edge intelligence [8], [17], [18]. Currently, the interplay of EGI has attracted growing attention from both the industry and academia and propelled a plethora of innovative optimizations, techniques, and applications at the network edge, e.g., traffic flow fore-casting [19], [20], location-based recommendation [21], [22], and vehicle trajectory prediction [23], [24]. As a substantial extension of edge AI, EGI sheds light on its fundamental questions - how deeply edge networks and AI techniques can be fused and how much potential their fusion can shine - and demonstrates its powerful capability through plentiful realistic applications.\nNonetheless, discussions on EGI are still narrowly limited to unilateral dimensions. Existing literature has either reviewed the graph learning landscape with limited discussion on their applications in edge networks [9], [10], [13], or focused particularly on applying GI techniques on some specific edge scenarios (e.g., traffic domain [25]\u2013[27], power grids [28]\u2013[30]), yet ignoring the big picture of general edge networks spectrum. Some recent literature [31]\u2013[33] also reviews the progress of GI in the context of IoT and wireless networks but mainly focuses on GI applications in their discussed scopes and lacks a systematic taxonomy on the \"Edge for GI\" aspect, which is one of the fundamental pillars in EGI's closed loop. Although the edge computing and communica-tions community has extensively investigated edge intelligence systems, a majority of them [8], [34]\u2013[37] center on general AI computation systems or are dedicated to traditional DL workloads such as CNNs or RNNs, where GI models, which possess distinct capabilities and unique characteristics, are much less understood.\nIn this paper, we advocate that EGI should not be restricted to merely applying GI on edge data or running GI on edge platforms. Instead, GI and edge networks are blending a confluence and EGI should be treated as a whole to reflect the inherent interplay between GI and edge networks. This indi-cates that their bilateral empowerment desires a comprehensive exploration such that the degree of EGI can be identified and measured. Specifically, according to the fusion of GI and edge networks, we may rate EGI into six levels from their respective perspectives, as shown in Fig. 2.\n\u2022 Level 0: Given the graph data implicated in the edge network infrastructure, analytical models in Level 0 are unaware of the graph structures. The edge computing sys-tems also process data in an graph-agnostic way. In other words, neither the model side nor the infrastructure side explicitly tackles \"graphs\", and thus they are categorized to the initial level.\n\u2022 Level 1: Data collected from edge networks are modeled in graphs. Systems at Level 1 push one step further over Level 0 by endowing graph semantic to edge data (with general computing methods).\n\u2022 Level 2: Edge data in graph forms are processed with traditional graph computing algorithms such as PageRank and single-source shortest path algorithms. Systems at Level 2 outperform Level 1 by enabling the graph-oriented computing capability.\n\u2022 Level 3: Edge networks serve GI model inference with graph data, where the models may be trained on the cloud. Compared with lower levels, systems at Level 3 initiate AI to edge networks and embrace GI models.\n\u2022 Level 4: Edge networks perform GI model training with graph data. The key difference between Level 4 and Level 3 lies in the ability of learning edge-native GI models, e.g., fine-tuning model parameters with edge data.\n\u2022 Level 5: Interactional EGI, where GI and edge networks can dynamically adapt their configurations during the runtime for optimal EGI performance. Systems at Level 5 outperform all other levels because they can adjust GI and edge networks on the fly, whereas lower levels are all static settings. Both perspectives of GI and edge networks reach a convergence since they are in complete harmony.\nThe rating of EGI can be mainly divided into three intervals. The first interval covers from Level 0 to Level 2, where EGI is less related to AI and even processes non-graph data. The second interval comprises Level 3 and Level 4, where EGI incorporates GI models by either inference or training on edge networks. The third interval is exactly Level 5, which stands at the highest level because its GI and edge networks have profoundly blended as integration and can adapt to diverse scenarios on the fly. As EGI systems locates at higher levels, their fusions of GI and edge networks go deeper. As a result, the intelligence resources of GI and infrastructural resources of edge networks are progressively exploited for better EGI performance. Nonetheless, this may also come at the cost of additional development effort and system overhead. This conflict implies that there is no \u201csilver bullet\" in all cases. Instead, the panacea of EGI in practice should align with user demand, anticipating a joint consideration of specific application scenarios as well as available resources budgets."}, {"title": "C. Summary and Contribution", "content": "In this paper, we discuss in-depth how GI and edge networks are reciprocal to each other, and conduct a comprehensive and concrete survey of the recent research efforts on EGI. In partic-ular, centering around the inherently interconnected nature of graphs and networks, this paper reveals the bilateral interplay, for the first time, between GI and edge networks, and provides a concise rating in accordance with their mutually beneficial interactions. In light of the rating, our survey identifies the four primary enablers essential for EGI, as illustrated in Fig. 3:\n\u2022 GI applications at Edge (Sec. IV): Typical application scenarios and use cases for applying GI in edge networks;\n\u2022 Edge Networks for GI (Sec. V): Paradigms of GI model computation, including model training and inference, for GI over edge networks;\n\u2022 GI for edge networks (Sec. VI): Practical GI-based methods for optimizing edge networks concerning their specific functionalities;\n\u2022 EGI ecosystems (Sec. VII): full-stack infrastructural sup-port for high-performance EGI computation in terms of hardware, software, and benchmarks.\nIn general, these key enablers can be well accommodated in the closed loop, i.e., \"edge for GI\" and \"GI for edge\" as described in Fig. 1, In the \"edge for GI\" course, edge networks provide physical platforms and software stacks to graph intelligence, serving as infrastructure to support GI models training and inference processes. More specifically, GI models' intensive training workload can be resolved by means of pools of edge resources (e.g., federated edge learning), and edge inference techniques are developed for deploying and accelerating GI models under resource constraints and SLO requirements. Alternatively, in the \u201cGI for edge\" course, GI models with these inference solutions can thereafter be efficiently executed upon edge platforms, which enables mis-cellaneous graph-based applications and optimizes various as-pects of edge networks. Besides reviewing these key enablers, our survey provides fundamental and friendly premiers of GI and edge networks that assume no prior knowledge of GI or edge computing. We also discuss various open challenges and research directions toward future EGI, encouraging both AI and communications communities to advance EGI for a broader range of people.\nThe rest of this paper is organized as follows: First, Sec. II and Sec. III briefly review the primers of graph intelli-gence and edge computing networks, respectively. Next, the subsequent sections introduce research efforts with respect to the four enablers: GI applications at Edge (Sec. IV), edge networks for GI (Sec. V), GI for edge networks (Sec. VI), and EGI ecosystems (Sec. VII). Finally, Sec. VIII discusses open challenges and future research opportunities of EGI and Sec. IX concludes. Table I lists the main abbreviations used in this survey."}, {"title": "II. PRIMER ON GRAPH INTELLIGENCE", "content": "As one of the key flywheel actuating the loop within EGI , graph representation learning is devoted to the algorithm side and contributes enhanced ability in graph data processing. Before diving into EGI, this section compendiously introduces graph representation learning with respect to its basic concepts, general workflow, and representative models and learning paradigms. For a more comprehensive treatment of GI, con-centrated reviews [9], [13], [14], [38] on graph representation learning are highly recommended. Table II lists the main notations used in this section.\nA. Basic Concepts\nGraphs: Graphs are a way to organize data, and with graphs, one can succinctly characterize relationships across scattered data points. The input of GI models, i.e., GNNs, are graphs, which typically contain two types of data. One is the adjacency matrix or adjacency list, which interprets the graph topology, and the other is the feature vectors that describe vertices and edges' actual properties. Formally, an input graph is denoted as \\(G = (V,E)\\), with vertices and links collected in V and E, respectively.\nVertices and Links: Vertices or nodes in a graph can be items, objects, or entities, and are not necessarily homo-geneous when constructing a graph. For instance, a location-based knowledge graph can represent its vertices as human users, IoT devices, scenic spots, and any other entities of various types within a specific district. Links are another es-sential component in graphs that characterizes the relationships between these items, objects, or entities. Note that to avoid misunderstanding, we exclusively use \"links\" to indicate the connection between vertices in an input graph while leaving \"edge\" for edge networks. A link can be defined with respect to the two (not necessarily unique) vertices associated with it. For \\(V\\in G\\) and \\(&\\in G\\), we denote their size, i.e., the number of vertices and links, as \\(|V|\\) and \\(|E|\\), respectively, and use v and e to index arbitrary vertex and link in them.\nNeighbors: Neighbors are ego-networks centering on specific vertices within a graph. For a vertex v, its neighbors cover the vertices directly connected to v and their adjoin-ing links. Note that a vertex's neighbors can be iteratively expanded by considering the neighbors of its neighbors. For-mally, given \\(N^{(k)}\\) as vertex v's k-hop neighbors, we have \\(N^{(k+1)} = {N^{(1)} \\forall u \\in N^{(k)}}\\, where \\(N^{(1)}\\) indicates v's one-hop direct neighbors.\nRepresentation Vectors, Features, and Embeddings: Representation vectors are the numerical vectors associated with vertices and links, and are also referred to as encodings, representations, latent vectors, or high-level feature vectors de-pending on the context. In this section, we respectively denoted representation vectors by \\(h_v^{(l)}\\) and \\(h_e^{(l)}\\) at the l-th GNN layer. Upon input to the model, the initial representation vectors \\(h_v^{(0)}\\) and \\(h_e^{(0)}\\) are exactly the features attached to vertices and links, which quantify physical properties in specific applications. Extending the above knowledge graph example, the features of a vertex may include the users' age and food preferences, and for a scenic spot, it can be location and popularity. After processing through model layers, the exported representation vectors are embeddings, a form of compressed feature repre-sentations of vertices, links, neighbors, or graphs. Embeddings can be viewed as the mappings of original data in latent spaces, which effectively reserve the semantics implicated in the input graph while can be used by downstream models for specific tasks (e.g., vertex classification and link prediction).\nModel Output: The final output of GI models depends on the way of processing embeddings, i.e., the readout function. In general, the outcome of GI models can be grouped into three types: 1) Vertex-level output, where the result is vertex-wise predictions (e.g., classes, scores) for some dedicated vertices. 2) Link-level output, where the result is link-wise predictions for some dedicated links. 3) Graph-level output, where the results are the prediction of the whole graph (e.g., the operational status of a power grid)."}, {"title": "B. General Workflow", "content": "A GI model is an algorithm that essentially leverages graph topology to abstract and learn the relationships between vertices and links. It takes an attributed graph as input, and output embeddings or predictions in an application-admitted format. Among versatile GI models, the GNN series is the state-of-the-art genre and is prevalent in various types of edge applications, thus we illustrate the general workflow of GI model based on GNN models. Fig. 4 depicts the general workflow of them.\nPreprocessing: The first step serves as an initialization to prepare data in a format aligned with the targeted GI model's requirement. This can be, for example, reorganizing the adjacency matrix in a dense format or the compressed sparse row format and dropout some irrelevant elements from the feature vectors. Since the GI model is often known ahead of runtime, graph preprocessing is usually done offline.\nSampling: With the preprocessed input graph, the GI model dives into iterations. The number of iterations required is exactly the number of layers the GI model possesses. Within each iteration, it first applies sampling on the input graph G to reduce the computational complexity of subsequent steps. Assuming the sampling function as \\(\\theta^{(l)}\\), this step can be formally written in:\n\\[G' = \\theta^{(l)} (G).\\]\n(1)\nThe result of sampling is a sampled graph G', where \\(G' = (V', E')\\). Note that this is an optional step and inference processes typically deactivate this step for prediction accuracy.\nAggregation: Upon the sampled graph G', the GI model performs neighbor aggregation where each vertex/link pulls feature vectors from its neighbors. Taking vertices aggregation as example, let \\(\\varphi_v^{(l)}\\) be the aggregation function of vertices, we have\n\\[a_v^{(l)} = \\varphi_v^{(l)}(h_v^{(l)}, h_u^{(l)}), \\forall v \\in V', \\forall u \\in N(v),\\]\n(2)\nwhere \\(h_u^{(l)} | u \\in N(v)\\) collects v's neighboring vertices' representation vectors and \\(a_v^{(l)}\\) is the aggregation result.\nUpdate: The GI model then passes the aggregation \\(a_v^{(l)}\\) through a neural network operator \\(\\phi\\) to update v's representation vector:\n\\[h_v^{(l+1)} = \\phi(a_v^{(l)}), \\forall v \\in G',\\]\n(3)\nThis operator is usually learnable Multi-Layer Perceptron (MLP) and non-linear activations like the sigmoid function. Note that Eq. (2) and Eq. (3) are merely described for vertices for simplicity. Repeating the same procedure to all vertices and links yields the complete representation vectors for the whole graph.\nPooling: Pooling is also an optional step that aims at reducing the original graph to a smaller graph for lower computational complexity. It directly operates the sampled graph with updated representation vectors, pooling fields of graphs:\n\\[G = \\upsilon^{(l)} (G').\\]\n(4)\nReadout: The above sampling, aggregation, update, and pooling steps will iterate until all model layers are processed, and thereafter generate embeddings of all vertices and links. To attain the desired results demanded by applications, these embeddings are obliged to the final readout step, which applies a pre-defined operator or model to transform embeddings to a global output, as explained in Sec. II-A5. Given a readout function \\(\\psi\\), the global output vector can be obtained by:\n\\[y = \\psi (h_v^{(L)}, h_e^{(L)}|\\forall v, e \\in G).\\]\n(5)\nIn summary, executing a GI model can be regarded as processing a collection of operators and neural networks itera-tively over a graph, where each iteration, i.e., each model layer, comprises weights that specify the computation of vertices' and links' feature vectors. These weights are learnable via model training, i.e., through the means of backpropagation algorithms such as gradient-based optimization. Specifically, during model training, a GI model with L layers undergoes a forward pass: first transforms input graph through model layers to graph embeddings, and next converts the obtained embeddings into desired results. With the exported result and known labels, the model computes the pre-defined loss function, where the gradient is then backpropagated across the layers, updating the shared weights. This process is carried out iteratively with multiple samples, which are often in batches until an expected accuracy is attained. For model inference, it directly goes through a forward pass and generates the predictions."}, {"title": "C. Graph Learning Models", "content": "There are multifarious GI model variants developed for mul-tifarious applications with multifarious ability requirements. For brevity, here we enumerate several representatives that are commonly adopted in edge scenarios.\nRecurrent Graph Neural Network (RecGNN): RecGNNS are a pioneering architecture that builds the conceptual foun-dation in the field of graph representation learning [9]. They are primely proposed to learn node representations using recurrent neural architectures, integrating a recurrent hidden state and graph signal processing (GSP) to exploit the spatial structural information inherent in graph processes. As a genre of GI models dating back to the \"pre-deep-learning\" era, RecGNNs have inspired numerous subsequent research such as convolutional variants.\nConvolutional Graph Neural Network (ConvGNN): ConvGNNs extend convolution operations from grid data to graph data, aggregating the features of vertices and links with their neighbors to generate representations [10], [14]. Contrary to RecGNNs, successive graph convolutional layers are stacked in ConvGNNs to extract hierarchical patterns from subgraphs [16]. Among GNNs, ConvGNNs serve as a foundational component in constructing various advanced GI models [39].\nGraph Attention Network (GAT): GATs inherit spatial ConvGNNs by incorporating the attention mechanism into the aggregation functions, which effectively improves the capacity as well as the expressiveness of GI models [40]. The rationale behind this combination is to differentiate the contribution of vertices' neighbors in a learning manner [41]. Based on this, many types of attention mechanisms are derived such as self-attention, gating attention, and semantic-level attention.\nGraph Autoencoder (GAE): GAEs are unsupervised frameworks that encode vertices, links, or graphs into a latent vector space and reconstruct graph data by decoding their encoded information [13]. GAEs are particularly useful for graph generation tasks, where a GAE model employs graph convolutional layers to compute embeddings for vertices and rebuild the graph adjacency matrix via decoders.\nSpatio-Temporal Graph Neural Network (STGNN): STGNNs analyze dynamic graphs from both the spatial and temporal dimensions [42], [43]. Each vertex and link in these graphs attaches a feature vector that describes their behaviors within a time window, and STGNNs aim to learn their patterns and predict their changes in the incoming time slots. To extract information from spatial-temporal dependencies, many sequential decision-making approaches are applied, e.g., Long Short-Term Memory (LSTM).\nGraph Transformer and Graph Foundation Model: Graph transformers explore embracing transformer architec-ture to the graph domain in pursuit of improved graph model-ing ability [44]\u2013[46]. Typically, graph transformers incorporate GNN with transformers in dual ways: 1) design tailored positional embedding modules and graph-specific attention matrices, and 2) exploit GNNs as an auxiliary module by com-bining GNNs into transformer architectures [47]. Following this line, scaling small transformers to huge foundation models leads to Graph Foundation Models (GFMs) [48], [48] and Large Graph Models (LGMs) [49]. Motivated by the success of Large Language Models (LLMs), many researchers believe that utilizing pretraining techniques to resolve massive graph data can breed a comprehensive GI model, which possesses advanced abilities such as in-context graph understanding and versatile graph reasoning [50]. Nevertheless, GFMs and LGMs are still in a very early stage of their development and demands for further exploration."}, {"title": "D. Learning Paradigms", "content": "Given a rich zoo of GI models, distinct learning paradigms empower them with distinct abilities for edge applications. We provide several example learning paradigms as follows.\nSupervised Learning: Supervised learning is one of the most fundamental training paradigms in ML, which requires labeled data to guide the optimization of models [51], [52]. For GNNs, supervised learning enables to capture both local and global graph structures and the latent information of vertices and links. It iteratively optimizes model parameters by minimizing the difference between the model's predictions and the labels, where the performance of the model is evaluated on a separate test set of labeled objects. Supervised GL have found success in various domains such as social network analysis, intelligent transportation, and recommendation sys-tems. However, in many real-world scenarios where labels are unavailable or expensive, supervised learning is constrained and other semi-supervised or unsupervised learning paradigms are introduced.\nTransfer Learning (TL): TL for GI models builds upon the assumption that the learned representations and knowledge from a source graph can be effectively transferred and applied to a targeted graph [53], [54]. Based on this, it exploits knowledge distillation methods to extract the knowledge from one graph data to improve the learning performance on another different but related graph data. By transferring knowledge across graphs, the target graph benefits from the learned representations, enabling improved prediction performance for the targeted graph, even with limited labeled data.\nContrastive Learning (CL): CL for GI models is a self-supervised learning paradigm that learns meaningful represen-tations by contrasting positive and negative samples, where positive samples are pairs of vertices, links, or subgraphs that are similar or related, and negative ones are the contrary [55]\u2013[57]. With these samples, contrastive learning maximizes the similarity between positive samples and minimizes the similarity between negative samples. Various techniques have been applied to enhance contrastive learning on graphs, such as graph augmentation and sample generation with random walks.\nFederated Graph Learning (FGL): FGL applies Feder-ated Learning (FL) on graphs, which allows multiple clients to collaboratively train a GI model without sharing their local data [58]\u2013[60]. In particular, each client trains the GI model using its local graph data and shares only the model updates, i.e., gradients or weights, with a central coordinator, and the coordinator aggregates the updates and sends a merged model update back to each client. Graph data are typically distributed across clients, with respect to structural segments, i.e., subgraphs, or feature segments. More details on FGL are discussed in Sec. V-A.\nDeep Graph Reinforcement Learning (DGRL): DGRL combines GI models with Deep Reinforcement Learning (DRL) techniques for interacting with graph environments [61], [62]. Typically, in DGRL, the GI model is responsible for processing the graph data, extracting features, and capturing the relationships between vertices and links. The DRL compo-nent then uses the embeddings computed by the GI model to learn a policy and make decisions, often by taking actions like vertex selection, link insertion/removal, or graph modification. Benefiting from the superior capability of representing graphs, DGRL has become a powerful tool for graph-based sequential decision-making tasks."}, {"title": "III. PRIMER ON EDGE NETWORKS", "content": "A. Edge Networks and Edge Computing\nIn the evolving landscape of distributed computing, the edge network emerges as a pivotal architecture, facilitating the transition from centralized cloud-based core networks to more decentralized edge networks [63]\u2013[65]. Fig. 5 illustrates the edge network as a cohesive architecture that integrates the Edge and End layers, encompassing devices naturally situated closer to end users. Besides traditional network-style topology, edge networks can exhibit versatile organizations such as peer-to-peer connection (e.g., client-server mode) and star-like interactions (e.g., one-to-many subscription). Albeit, all these topologies can be unified by the graph abstraction. On the other hand, core networks and the Internet also comprise many graph structures and have introduced GI over their graphs. However, it should be emphasized that EGI is significantly different from GI on core networks given the unique characteristics of edge networks.\nSpecifically, in contrast to the centralized core networks, several salient features distinguish edge networks: (1) Dis-tributed: Edge networks are characterized by their geographi-cally dispersed resources, such as edge servers and mobile de-vices, in stark contrast to the centralized nature of cloud-based data centers. (2) Heterogeneity: Edge networks encompass a diverse array of edge devices and servers, each varying in computational capacity, network bandwidth, and hardware ar-chitecture, embodying an extremely heterogeneous computing environment. (3) Resource Constraints: Unlike cloud-based data centers equipped with high-performance accelerators and dedicated ultra-speed links, devices within edge networks often operate under resource limitations, facing constraints in aspects like computational throughput, device-to-device communication bandwidth, and memory capacity. (4) Dynamic Resources: The proximity of edge network devices to end users inherently results in greater dynamism in resource availability. Their mobility across various networking domains and mul-titasking with multiple applications simultaneously contribute to frequent fluctuations in both network and computational resources.\nEmerging from the advanced architecture of edge networks, edge computing stands as a new computing paradigm in contrast to cloud computing [8], [34]. Edge computing rep-resents a shift in computational paradigm that brings data processing exponentially closer to the point of data collection and consumption, enabling low-latency and high-bandwidth communication essential for real-time applications. Edge com-puting, in comparison to cloud computing, presents numerous advantages, notably in its approach to in-situ data processing: (1) Lower Core Network Reliance: Edge computing lessens the reliance on unstable and delay-prone core networks by localizing data processing within edge networks, ensuring more consistent QoS even when wide-area network (WAN) connections are unpredictable. (2) Alleviated Core Network and Cloud Datacenter Stress: With the sheer volume of edge and end devices, routing all data through the core network to cloud data centers imposes substantial strain in terms of communication, computation, and storage. Edge computing mitigates this by retaining computations within the edge network, effectively utilizing the distributed, idle resources of edge and end devices. (3) Privacy and Security Enhancement: Localizing data within edge networks, minimizes the risk of unauthorized access and privacy breaches. Transferring these data to the cloud-based data centers owned by commercial companies inevitably raises users' privacy concerns."}, {"title": "B. Components of Edge Networks", "content": "Locating at the periphery of the Internet", "Units": "Sensors and Micro Control Units (MCUs) are fundamental components of edge networks. Sensors are devices that capture real-time data from the physical environment", "66": "a digital temperature sensor", "67": "sensor tracks motion by combining a gyroscope and accelerometer", "68": "sensor detects combustible gases and smoke", "69": "a popular choice for DIY projects", "70": "is known for its robust performance in complex industrial applications. The ESP8266 [71", "Devices": "Embedded and Mobile Devices are advanced systems that integrate multiple sensors and MCUs into a single", "72": "is a prime example", "73": "steps in", "74": "and Samsung Galaxy [75", "76": "and Fitbit [77", "Vehicles": "Robotics and vehicles, distinct from embedded and mobile devices, usually excel in func-tionality, autonomy, and complexity. While embedded devices are integral to these systems, robotics and vehicles incorporate them into more complex frameworks, designed for higher autonomy and minimal human intervention. Robotics"}]}]}