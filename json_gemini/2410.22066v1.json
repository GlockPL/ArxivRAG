{"title": "Sing it, Narrate it: Quality Musical Lyrics Translation", "authors": ["Zhuorui Ye", "Jinhan Li", "Rongwu Xu"], "abstract": "Translating lyrics for musicals presents unique challenges due to the need to ensure high translation quality while adhering to singability requirements such as length and rhyme. Existing song translation approaches often prioritize these singability constraints at the expense of translation quality, which is crucial for musicals. This paper aims to enhance translation quality while maintaining key singability features. Our method consists of three main components. First, we create a dataset to train reward models for the automatic evaluation of translation quality. Second, to enhance both singability and translation quality, we implement a two-stage training process with filtering techniques. Finally, we introduce an inference-time optimization framework for translating entire songs. Extensive experiments, including both automatic and human evaluations, demonstrate significant improvements over baseline methods and validate the effectiveness of each component in our approach. More results can be found in our website.", "sections": [{"title": "1 Introduction", "content": "Have you ever heard of Hamilton in Chinese, or Mamma Mia in Swedish (\u00c5kerstr\u00f6m, 2010)? Advancements in cultural globalization allow musicals to reach universal audiences, but language barriers still hinder full comprehension. Translating musicals into performing country's language could enhance audience experience (Sorby et al., 2014) and expand commercial outreach (Andersson et al., 2008), as it allows audiences to enjoy theatrical elements without heavily relying on subtitles (Engel and Kissel, 2006; Sorby et al., 2014). However, musical translation is labor-intensive and time-consuming, requiring adjustments for musical framework, stage performance, and cultural references beyond mere verbatim translation (Sorby et al., 2014; Fei, 2014). To alleviate this burden, we aim to automatically translate musical lyrics from English to Chinese.\nSong translation, a closely related field, requires aligning the translated text with the music to ensure the translated lyrics can be sung (Low, 2003; Franzon, 2005). However, musical translation requires an even higher standard of translation quality because lyrics play a crucial role in the story-telling of a musical (Kenrick, 2010; Carpi, 2020; Chan, 2017). To preserve the original narration, the translations must accurately convey the meaning and nuance of the source lyrics. This high fidelity ensures that the translated musical maintains its artistic integrity and allows the story to unfold as intended for the target audience. Thus, musical translation demands a rigorous approach to translation quality, focusing on maintaining the narrative function to create a faithful rendition of the original work.\nTo the best of our knowledge, there is no existing work on automatic musical translation, and existing works on automatic song translation (Guo et al., 2022; Ou et al., 2023; Li et al., 2023a) mainly focus on the alignment of text and music, sacrificing translation quality and often produce unnatural and inaccurate translations unsuitable for musicals, as shown in Figure 1. To distinguish our work from existing art, we focus on improving translation quality, which would contribute to maintaining the narrative function, while reasonably following singability constraints. We define translation quality using the well-established criteria for literature translation: fluency, accuracy, and literacy (Yan, 1898). Additionally, we consider the singability constraints of length and rhyme following previous works (Guo et al., 2022; Ou et al., 2023). Figure 1 shows our considered aspects, with examples demonstrating their significance."}, {"title": "2 Related Work", "content": "Translatology: Song and Musical Translation. In translatology, \u201cPentathlon Principle\u201d (Low, 2003, 2005) is a well-known theory and guidance on general song translation (Franzon, 2008; Cheng, 2013; Stopar, 2016; Si-yang, 2017; Opperman et al., 2018; Sardi\u00f1a, 2021; Pidhrushna, 2021; Ou et al., 2023), which proposes five criteria to consider: singability, rhyme, rhythm, sense, and naturalness, where the first three relates to music-text alignment and the rest refer to translation quality. However, this principle is not developed specifically for songs on the musical stage and is not completely suitable for it (Carpi, 2020).\nThe functional approach (Franzon, 2005) is more suitable for songs in musicals (Carpi, 2020), which emphasizes that the translated lyrics should replicate the function of the source text. In musicals, songs are \u201cstory-telling\u201d elements (Kenrick, 2010), and the translated lyrics must carry out this role (Desblache, 2018; \u00c5kerstr\u00f6m, 2010; Sorby et al., 2014; Franzon, 2005). Thus a basic yet necessary constraint in musical translation is that lyrics must maintain the original narrative function, and thus should have high quality.\nAutomatic Song Translation. To our best knowledge, there are only three previous works on automatic song translation (Guo et al., 2022; Ou et al., 2023; Li et al., 2023a). Guo et al. (2022) mainly addresses the problem of aligning words' tones with the melody in the beam search phase, and Li et al. (2023a) focuses on aligning text to musical notes better. However, they both neglect the important rhyme constraint (Strangways, 1921). Ou et al. (2023) considers length, rhymes, and word boundaries, achieving decent results with prompting and the trick of reverse-order decoding. However, the translation quality is awkward and unsuitable for singing in musicals. To bridge this gap, we focus on generating high-quality translations under the two most important constraints for text-music alignment: length and rhyme.\nLarge Language Model and Machine Translation. Recent years have witnessed the huge success of large language models, including close-sourced GPT-4 (OpenAI, 2023), Kimichat, and open-sourced Llama-2 (Touvron et al., 2023). Re-"}, {"title": "3 Problem Formulation", "content": "We formulate the problem of musical translation as: Given a paragraph of English lyrics from a song, the task is to produce a Chinese translation that has high translation quality while adhering to singability constraints. By treating each paragraph independently, we can process an entire song.\nTo ensure singability constraints, we consider the following aspects. (1) Length: The number of syllables in the English lyrics and the number of characters in the Chinese lyrics should match the number of musical notes to ensure proper alignment. Since we lack direct access to sheet music but can easily obtain the English lyrics, we use the number of syllables in the English lyrics as the reference length for alignment. (2) Rhyme: The translated sentences within each paragraph should maintain the same end rhyme as much as possible, particularly aligning with the end rhyme of the last sentence in each paragraph.\nTo evaluate translation quality, we focus on the following three aspects (Yan, 1898). (1) Fluency: The naturalness and readability of the translated lyrics in Chinese. (2) Accuracy: How well the translation conveys the same meaning as the original English lyrics. (3) Literary quality: The aesthetic appeal and literary merit of the translated lyrics. We further categorize fluency and accuracy as basic translation quality, while considering literary quality as advanced translation quality, to differentiate between mandatory and supplementary aspects. To enable machines to evaluate these aspects of translation quality, we train reward models using human annotations as learning data."}, {"title": "4 Method", "content": "Our method consists of three key components: reward models trained to evaluate the quality of the translated language (Section 4.1), a translation model trained using a two-stage pipeline (Section 4.2), and an inference-time optimization framework that composes sentence-level results into paragraph-level output (Section 4.3). Figure 2 illustrates how these components work together."}, {"title": "4.1 Reward Model Training", "content": "To train reward models for evaluating translations, we collect a dataset called MusicalTransEval, where each entry includes an original English line, a translated Chinese line, a paragraph as context, and three scores ranging from 1 to 4 that measure fluency, accuracy, and literacy of the translation respectively. The detailed scoring rubrics are shown in Appendix A, which are developed in collaboration with an expert in musical translation. The English lines were extracted from musicals of diverse genres, ranging from fantasy, modern society, youth and family, history, and literature adaptation. The corresponding Chinese translations were generated by Kimichat using few-shot prompts. After 50 hours of annotation, we compiled a dataset with 3938 high-quality entries. For both basic and advanced translation quality, we train reward models using the dataset and refer to their evaluations as $R_{bas}$ and $R_{adv}$, respectively.\nTo obtain a more balanced training dataset for $R_{bas}$ and $R_{adv}$, we first apply mappings to handle categories that rarely appear. For $R_{bas}$, we map the score pairs of fluency and accuracy to a single integer score ranging from 1 to 4, resulting in 471, 322, 971, and 2174 entries, respectively. For $R_{adv}$, we map the scores for literacy to 2 or 3, obtaining 3104 and 834 data samples, respectively.\nBy utilizing data upsampling and downsampling techniques to further balance the training data, we obtained $R_{bas}$ and $R_{adv}$ with strong correlations with human judgments on a hidden balanced test set, which includes unseen musicals from the training period. The Pearson correlation (Pearson, 1895) of human scores with $R_{bas}$ and $R_{adv}$ are 0.649 and 0.532, signifying strong and moderate correlation. Besides, the precision and recall of the score 3 class $R_{adv}$ are 0.95 and 0.49. The strong correlation of $R_{bas}$ and high precision of $R_{adv}$ make them quite reliable and valuable in our pipeline. More details of MusicalTransEval can be found in Appendix A and more training details are in Appendix B."}, {"title": "4.2 Two-Stage Translation Model Training", "content": "Large-scale training is essential to ensure the translation model generates results that accurately adhere to length and rhyme constraints, as discussed in Section 5.6. However, the same section also demonstrates that increasing the amount of training data does not always yield improvements in translation quality. This observation raises a pertinent question: how can we achieve high translation quality while maintaining satisfactory accuracy in terms of length and rhyme?\nDue to the difficulty of collecting a large-scale musical dataset, we use the dataset provided by Ou et al. (2023), consisting of approximately 2.8M English-Chinese song lyrics sentence translations. To bridge the gap between normal and musical songs and improve dataset quality, we use our reward models to filter a high-quality subset of 1.75M and a higher-quality subset of 700K entries.\nIn the first training stage, we train the LLM with the large-scale high-quality dataset to primarily learn to follow length and rhyme constraints. In the second stage, we further refine translation quality by fine-tuning with the higher-quality dataset. In both training stages, we use the same prompt with length and rhyme constraints, ensuring that the constraints-following ability learned in the first stage is maintained in the second stage. Additional descriptions of the training dataset can be found in Appendix A and more translation model training details are in Appendix B."}, {"title": "4.3 Inference-Time Optimization Framework", "content": "Due to the inaccuracy of generating the whole paragraph at once, we let the translation model handle each sentence independently and then combine them using a novel optimization framework during inference. In particular, we design a proper paragraph-level loss function and optimize the overall loss by jointly considering all sentences.\nIn our setting, we consider length accuracy, rhyme score, and both basic and advanced translation quality. At the paragraph level, our overall loss $L(.)$ is defined for sentence-level translations $Y_1,..., Y_n$ by incorporating all those aspects. Specifically, we define:\n$L(Y_1,..., Y_n) = \\sum_i (11 [Rhy(y_i) \\neq Rhy(y_n)] +12D(gt_i, Y_i) \u2013 13R_{adv}(y_i) \u2013 14R_{bas}(y_i)),$\nwhere we define\n$D(y, x) =\\begin{cases} \\beta(x - y) & \\text{if } y \\leq x, \\\\-x & \\text{if } y > x. \\end{cases}$\nto measure to which extent the translation length differs from the desired length, with an additional penalty $\\beta$ for translations that exceed the desired length, as this poses a greater challenge for singing."}, {"title": "5 Experiments", "content": "In our experiments, we investigate the following research questions:\nRQ 1 How well does our method perform in generating high-quality musical lyrics translations, as measured by automatic evaluation metrics?\nRQ 2 How well do the generation results of our method align with human preference?\nRQ 3 How does each component contribute to our performance improvements?"}, {"title": "5.1 Experiment Configurations", "content": "Datasets. To evaluate musical translation performance, we additionally collect a dataset of English lyrics and quality Chinese translations from Cloud Music. This dataset includes 409 paragraphs and 1,742 lines from 56 popular songs of diverse musicals. We use this test set to evaluate both sentence-level translation and whole-song translation results. More details can be found in Appendix A.3.\nModels. For both the generation model and the reward model, we choose Chinese-Alpaca-2-13B (Cui et al., 2023) as our base model since it is pre-trained with a large amount of Chinese corpora and has satisfying instruction-following ability.\nBaselines. To the best of our knowledge, there are only three previous works on song translation, GagaST (Guo et al., 2022), Controllable Lyric Translation (Ou et al., 2023), and LTAG (Li et al.,"}, {"title": "5.2 Automatic Evaluations", "content": "The sentence-level performance of our generation models trained with several different recipes is reported in Table 1. In this experiment, we consider sentences in a paragraph as independent ones and set the desired length and rhyme according to our reference translation. We find that our dataset filtering strategy can largely improve translation quality by increasing all of $R_{bas}$, $R_{adv}$, and COMET. Also, after deleting the rhyme constraint in the prompt during inference time, generation results are still satisfactory even with slight improvements of $R_{bas}$ and $R_{adv}$, though COMET slightly drops, partially due to the loss of length accuracy and therefore more misalignment with reference translation.\nIn this work, we focus more on the paragraph-level translation results shown in Table 2, which again indicates that our training strategy is effective and both our two training stages can boost performance. Comparing our final results with the baseline's results, it is evident that we have achieved significant improvements across the majority of metrics. The only metric that ours is not as good as the baseline is the rhyme score since Ou et al. (2023) uses its reversed decoding technique to benefit rhyme following at the cost of language quality, but our rhyme score is already high enough for most applications, especially considering that even English lyrics in a paragraph does not guarantee the same rhyme. We thus answer RQ 1 affirmatively: our method can indeed achieve much better translation quality while maintaining satisfactory singability performance."}, {"title": "5.3 Human Evaluations", "content": "We recruit 4 musical enthusiasts from our university to do the human evaluation. We randomly sample 30 sentences and 12 paragraphs from our test set, let baseline and different versions of our model generate 120 sentences and 48 paragraphs, and ask another musical enthusiast to sing all generated results out. Subsequently, we let the evaluators assign scores on fluency, accuracy, literacy, and music-text alignment for sentence results, and overall translation quality and music-text alignment for paragraph results. We provide detailed scoring rubrics with examples and require the participants to adhere to our rules.\nThe human evaluation results are shown in Table 3. They are generally consistent with our automatic evaluations. The clear improvement of our VER.1 over the baseline and the improvement of our VER.3 over the previous two versions demonstrate the effectiveness of our inference-time op-"}, {"title": "5.4 Qualitative Results", "content": "In this section, we show a few representative qualitative results, with more results in Appendix C. For all Chinese translations, the translation errors and awkward phrases are underlined, and the excellent lyrics are underwaved."}, {"title": "5.5 Understanding the Contribution of Each Component", "content": "To answer RQ 3, we investigate the individual contribution of each component in our pipeline to the overall performance improvement.\nThe necessity of fine-tuning translation models."}, {"title": "5.6 Additional Analyses", "content": "Impact of training data scale. Figure 3 illustrates that increasing the scale of training data can help balance translation performance with length accuracy and rhyme score. Without training, the translation model struggles to adhere to length and rhyme constraints. As we increase the size of the training set, length and rhyme accuracy consistently improve, albeit at the cost of a slight drop in translation performance. This is expected, as our train-"}, {"title": "6 Conclusion", "content": "In conclusion, our work successfully balances translation quality and singability in musical lyrics translation. To solve this task, we leverage trained reward models, a two-stage translation model training approach, and an inference-time optimization framework. Our approach ensures that translated lyrics meet the criteria of fluency, accuracy, and literary quality while adhering to the critical constraints of length and rhyme. The substantial improvements over the baseline, as evidenced by both automatic metrics and human evaluations, demonstrate the efficacy of our method in delivering high-quality translations that retain the essence of musical expression. This work paves the way for future advancements in the field, and advances the cross-cultural appreciation of musicals."}, {"title": "Limitations", "content": "Although the current version of our reward models can already achieve good results, there is room for further improvement by scaling the collected dataset and inviting more annotators to score sentence translations for less noise. We believe the results of the proposed method can be more impressive if we can access more resources to train better reward models.\nBesides, we are translating at the sentence level due to the difficulty of tackling various constraints and composing sentences into a paragraph. Yet in some cases, neighboring sentence translations are not that compatible. Thus to further improve trans-"}, {"title": "Ethics Statement", "content": "This work addresses the task of musical translation, considering both translation quality and singability constraints. Potential risks include inaccurate translation results, which may lead to misunderstandings if used directly in certain scenarios.\nThe lyric data used in this research are sourced from the public Cloud Music platform and are used solely for research purposes. The models are obtained from public GitHub repositories. The dataset provided by Ou et al. (2023) is also used in accordance with its original intended purpose.\nFor human evaluations, we strictly adhere to the ACL Code of Ethics. Comprehensive details, including the recruitment process for evaluators and the instructions provided, are included in Appendix D. We collect evaluation scores without any personal information and ensure that the questionnaires do not contain offensive statements. Although our institute does not have an ethical review board or similar entity from which we can obtain approval, we have made every effort to follow the ethical guidelines set forth by ACL.\nRegarding the use of AI assistants in our research, we primarily employed them for language polishing and refining the clarity of our writing. The main ideas, methodologies, and contributions presented in this paper are the result of our own work and intellectual efforts."}]}