{"title": "XIYAN-SQL: A MULTI-GENERATOR ENSEMBLE FRAMEWORK FOR TEXT-TO-SQL", "authors": ["Yingqi Gao", "Yifu Liu", "Xiaoxia Li", "Xiaorong Shi", "Yin Zhu", "Yiming Wang", "Shiqi Li", "Wei Li", "Yuntao Hong", "Zhiling Luo", "Jinyang Gao", "Liyu Mou", "Yu Li"], "abstract": "To tackle the challenges of large language model performance in natural language to SQL tasks, we introduce XiYan-SQL, an innovative framework that employs a multi-generator ensemble strategy to improve candidate generation. We introduce M-Schema, a semi-structured schema representation method designed to enhance the understanding of database structures. To enhance the quality and diversity of generated candidate SQL queries, XiYan-SQL integrates the significant potential of in-context learning (ICL) with the precise control of supervised fine-tuning. On one hand, we propose a series of training strategies to fine-tune models to generate high-quality candidates with diverse preferences. On the other hand, we implement the ICL approach with an example selection method based on named entity recognition to prevent overemphasis on entities. The refiner optimizes each candidate by correcting logical or syntactical errors. To address the challenge of identifying the best candidate, we fine-tune a selection model to distinguish nuances of candidate SQL queries. The experimental results on multiple dialect datasets demonstrate the robustness of XiYan-SQL in addressing challenges across different scenarios. Overall, our proposed XiYan-SQL achieves the state-of-the-art execution accuracy of 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on NL2GQL, and a competitive score of 72.23% on the Bird development benchmark. The proposed framework not only enhances the quality and diversity of SQL queries but also outperforms previous methods.", "sections": [{"title": "1 Introduction", "content": "The ability to convert natural language queries into structured query language (SQL) through natural language to SQL (NL2SQL) technology represents a significant advancement in making complex datasets more accessible. It greatly facilitates both non-expert and advanced users in extracting valuable insights from extensive data repositories [2, 15, 24, 27, 6, 10, 13, 29, 20, 19, 23, 22]. Recent advancements in large language models (LLMs) have significantly enhanced the efficacy and accuracy of NL2SQL applications.\nThere are generally two approaches for NL2SQL solutions based on LLMs: prompt engineering [3, 5, 17, 18], and supervised fine-tuning (SFT) [9]. Prompt engineering leverages the intrinsic capabilities of the model by optimizing prompts to generate diverse SQL queries. Prompt engineering has demonstrated promising results in NL2SQL using zero-shot [3] or few-shot prompting [28, 5, 18]. This type of approach typically employs closed-source models with enormous parameters, such as GPT-4 [1] and Gemini 1.5 [26], which present significant potential and powerful generalization capability. However, most methods rely on multi-path generation and selecting the best option utilizing self-consistency, resulting in significant inference overheads. Approaches based on SFT seek to fine-tune models with much smaller parameter sizes on the NL2SQL task to produce more controllable SQL queries, such as CodeS [9]. Nevertheless, due to their limited parameters, these methods struggle to perform complex NL2SQL reasoning and transfer to databases within a new domain.\nIn this technical report, we propose XiYan-SQL, a novel NL2SQL framework that employs a multi-generator ensemble strategy to enhance candidate generation. XiYan-SQL combines prompt engineering and the SFT method to generate candidate SQL queries with high quality and diversity. To enhance high quality, we take advantage of the high controllability of SFT and utilize a range of training strategies to specifically fine-tune models to generate candidates with different preferences. We introduce a two-stage multi-task training approach, which first activates the model's fundamental SQL generation capabilities, and subsequently transitions to a model with enhanced semantic understanding and diverse stylistic preferences. To enhance diversity of generated candidates and capability of generating complex SQL queries, we utilize in-context learning to prompt LLMs. We propose to extract the skeleton of the questions by masking the named entities with common special tokens and using skeleton similarity to select and organize useful examples. Then, each generator is followed by a refiner to correct logical or syntactical error based on execution results or error information. Finally, a selection agent is required to select the best option. Most existing works use self-consistency, but the most consistent result is not always the correct case. So we propose to fine-tune a model to understand and identify the subtle differences among candidates and pick the final response.\nAdditionally, to enhance LLMs for better understanding of the database schema, we propose a new schema representation method named M-Schema. Inspired by MAC-SQL Schema [28], M-Schema presents the hierarchical structure between databases, tables, and columns in a semi-structured form. We revised MAC-SQL Schema by adding data types and resulting in a more compact and clear format. We conduct experiments to compare the impact of different schema representations on NL2SQL performance. In comparison to DDL Schema and MAC-SQL Schema, LLMs using M-Schema demonstrate superior performance."}, {"title": "2 Overall Framework", "content": "This section outlines the proposed XiYan-SQL framework, which consists of three primary components: 1) Schema Linking; 2) Candidate Generation; 3) Candidate Selection. Schema Linking is used to select relevant columns and retrieve values from a large database schema, helping to minimize irrelevant information and focus on related data. This contextual information is then organized into M-Schema and fed into Candidate Generation module to generate potential candidate SQL queries. These candidates are refined using a self-refinement process. Ultimately, a Candidate Selection agent compares all the candidates to determine the final SQL query. This pipeline is illustrated in Figure 1."}, {"title": "3 M-Schema", "content": "The database schema needs to be provided in the prompt so that LLM understands the database structure. We propose a novel representation named M-Schema. M-Schema illustrates the hierarchical relationships between the database, tables, and columns in a semi-structured format and employs specifical tokens for identification: \" \u3010DB_ID\u3011\" marks the database, \"# Table\" signifies tables, and \"(Foreign Keys\u3011\" indicates foreign keys. For each table, we present table name and description, where table description can be omitted. The information from a table is converted into a list, where each item is a tuple representing the details of a column. Each column includes the column name, data type, column description, primary key identifier, and example values. Additionally, foreign keys need to be listed due to their importance.\nFigure 2 shows examples of representing a database in DDL Schema, MAC-SQL [28] Schema and M-Schema. The Data Definition Language (DDL) schema is the most commonly used representation. However, it lacks essential table and column descriptions, as well as example values. Consequently, LLMs struggle to differentiate between similar columns. Derived from MAC-SQL Schema, M-Schema is a more compact representation. It differs from MAC-SQL Schema mainly in column representation, detailed as follows:\n\u2022 Data type. Data type ensures that the data is correctly structured and manipulated. MAC-SQL Schema lacks data type specifications, which may result in incorrect outcomes when generated SQL queries are executed.\n\u2022 Primary key marking. We include primary key marking to maintain relationships between tables in a relational database."}, {"title": "4 Schema Linking", "content": "Schema linking connects references in natural language queries to elements within a database schema, including table, columns and values. Our schema linking pipeline consists of a retrieval module and a column selector.\nRetrieval Module In order to search for similar values and columns in the database, similar to the approach in [17], we first prompt the model with few-shot examples to identify keywords and entities in the question. We then use a column retriever to retrieve relevant columns. Based on the semantic similarity between the keywords and the column descriptions, we retrieve the top-k columns for each keyword. To enhance efficiency, value retriever employs a two-phase retrieval strategy based on Locality Sensitive Hashing (LSH) and semantic similarity to identify similar values in the database. The final selected schema is the union set of column retriever and value retriever.\nColumn Selector Column Selector aims to reduce the tables and columns to minimally sufficient schema for SQL generation. The retrieved schema from the previous step is organized as M-Schema and presented with LLMs. We then employ a few-shot manner to prompt the language model to evaluating the relevance of each column to the user's query, selecting only those necessary."}, {"title": "5 Candidate Generation", "content": "For candidate generation, we employ various generators to generate high-quality and diverse SQL candidates. On one hand, we utilize a range of training strategies to specifically fine-tune the generation models, aiming to generate high-precision SQL candidates with diverse syntactic styles. On the other hand, we also incorporate the ICL approach to enhance the diversity of the SQL candidates. Our Refiner further improves the generated SQL queries. In the following sections, we provide a brief overview of each part."}, {"title": "5.1 Fine-tuned SQL Generator", "content": "The core purpose is to generate high-precision and diverse SQL candidates. To this end, we take advantage of the high controllability of fine-tuning models on specific tasks to build a series of high-precision models with different preferences. As shown in Figure 3, we employ a two-stage and multi-task training approach to fine-tune the model, including basic-syntax training and generation-enhance training. Through this training approach, the intermediate and final results of our pipeline are a set of models with distinct advantages.\nBasic-syntax training Basic-syntax training focuses on fine-tuning the pre-trained model with the basic and single SQL patterns and syntax. In this stage, the data used for training is SQL dialect-agnostic, covering basic syntax very comprehensively, with a total of tens of thousands of samples. The training objective is to develop a base model that activates SQL generation capabilities and can serve as a transition to different specialized SQL tasks.\nGeneration-enhance training After the first stage of training, we turn to generation-enhance training, aimed at enhancing the model's semantic understanding and stylistic preference in syntax. In this stage, we can combine various multi-task data and syntactic preference data to obtain an enhanced model. The model can benefit from multi-task data to better understand the mapping relationship between questions and SQL queries. Specifically, in addition to the standard task of converting questions to SQL queries, we further design the task of converting SQL to questions, which aims to infer potential questions based on the provided contextual information and SQL query. We have defined the task from SQL to evidence, which is intended to select the most relevant evidence from a set of candidates based on the context and SQL. Moreover, we also introduce the SQL discrimination and regeneration tasks, aimed at performing SQL optimization based on execution feedback, along with other related tasks. This series of specialized tasks effectively enhances the linking between SQL and contextual information, thereby improving overall generation capabilities. The model can benefit from various styles of patterns and syntactic features to better generate a wider diversity of SQL candidates. We utilize different LLMs to rephrase the original query in multiple ways without altering its original meaning. This approach effectively expands the sample data into different syntactic styles, thereby teaching the model to learn from this data form during the training phase.\nDue to multiple dialects in SQL queries, we can process each dialect separately during this stage, following this defined pipeline. Subsequently, we may opt to either train an individual model for each dialect or jointly train a multi-dialect model. In practical applications, we can fine-tune a target model by selecting subsets of multi-task and preference data according to our needs, enabling the generation of high-quality SQL candidates."}, {"title": "5.2 ICL SQL Generator", "content": "The performance of ICL-based NL2SQL generation depends not only on the inherent abilities of the model but also on the examples provided. Several methods have been proposed to retrieve useful examples, such as masked question similarity and query similarity [5]. Although masked question similarity excludes the influence of table and column names, it is still sensitive to the entities. Query similarity based method requires a preliminary model to generate an approximation SQL, so the capabilities of the preliminary model directly affect the final result.\nXiYan-SQL employs an example selection strategy based on the skeleton similarity between the user question and the question from the training set. All named entities in the question are first identified using NLTK's tool, then the named entities of the same type are replaced with a special token. For example, \"China\" and \"America\" are both identified as countries, so both of them are replaced by \"\". Other entities, such as enumeration values, are replaced by the column names. This approach avoids focusing too much on entities, while the semantics of entities is preserved. Then we compute embedding of modified questions in the training and test sets, and top-K examples from training sets that closely match the target question are selected."}, {"title": "5.3 SQL Refiner", "content": "The generated candidate SQL queries inevitably contain logical or syntactical errors [17, 25]. By utilizing clues from these SQL query deficiencies, we can undertake corrections to some extent. To this end, we employ a SQL Refiner to optimize the generated SQL. In practice, based on schema-related context, the generated SQL queries, and execution results (including potential error information), we enable the model to perform a second round of corrective generation. The original SQL and the regenerated SQL can further be subjected to a selection model (as discussed in Section 6) for optimal choice, and this process can be executed iteratively."}, {"title": "6 Candidate Selection", "content": "Based on the schema linking and various candidate generators, we can generate a set of candidate queries for the given question. The challenge of selecting the correct and reasonable SQL query from the pool of candidates remains to be addressed. Most methods [7, 25] employ self-consistency [30] to select the SQL query that appears most consistently across multiple candidate samples. However, this approach has limitations: it cannot handle situations where none of the queries are consistent, and even the most consistent result is not always the correct case.\nFor this purpose, we employ a selection model to make judgments. We measure the consistency of SQL execution results to group them, allowing us to identify inconsistent samples from each group to form a candidate set. Then, we utilize the selection model to select the most reasonable candidate based on the provided contextual information and the candidate set. Instead of employing a prompt-based approach with LLM, we specifically fine-tune a model as a selection model to better distinguish nuances of candidate SQL queries. To align with the varying syntactic preferences of the SQL candidates, we also deliberately perform paraphrasing on the training data of the selection model."}, {"title": "7 Experiments", "content": "7.1 Experimental Setup\nTo assess the generalizability of the proposed XiYan-SQL framework, we evaluate it in an end-to-end way on both relational and non-relational graph databases. Spider [32] and Bird [10] are widely-recognized cross-domain datasets that use SQLite. Since the test set of the BIRD benchmark is not available, we conduct experiments and performance evaluations on the development set. SQL-Eval 3 is an open-source PostgreSQL evaluation dataset released by Defog, constructed based on Spider. NL2GQL [33] built on graph databases is also involved in our experiments. The detailed information of datasets is shown in Table 1. We use Execution Accuracy (EX) to access the effectiveness of the generated SQL queries. EX compares the results of a predicted SQL query and a reference SQL query executed on a specific database instance."}, {"title": "7.2 Bird Results", "content": "We compare the performance of different NL2SQL methods on Bird development benchmark in Table 2. XiYan-SQL achieves a competitive accuracy of 72.23%, much higher than 57.95% of GPT-40. CHASE-SQL [17] framework employs multiple chain-of-thought prompting techniques to generate candidates, and subsequently implements a binary voting mechanism among 21 candidates, achieving an accuracy of 73.14%. XiYan-SQL yields a competitive performance by voting among only 5 candidates.\nWe also observe that a significant number of the leading methods on the bird learderborad are based on prompt engineering techniques. It suggests the immense potential of large-scale models and the importance of carefully designed prompts in optimizing model performance. The SFT based method, ExSL + Granite-34B-Code, secures the second position with an accuracy of 72.43%. This notable performance indicates that, smaller-sized models are indeed capable of generating complex SQL queries effectively through advanced training techniques. XiYan-SQL integrates the methodologies of SFT and ICL to balance the test time and the overall performance of the system."}, {"title": "7.3 Spider Results", "content": "To demonstrate the generalizability of our approach, we also evaluate XiYan-SQL on the Spider dataset. As demonstrated in Table 3, improvements in the underlying backbone model capabilities have contributed to notable improvements in performance metrics. Specifically, GPT-4o has achieved a remarkable accuracy of 83.54%. Moreover, XiYan-SQL refreshes the state-of-the-art execution accuracy of 89.65%, with a marginal advantage of merely 0.05% over previous leading models."}, {"title": "7.4 SQL-Eval Results", "content": "Table 4 presents the results on SQL-Eval dataset. SQL-Eval provides multiple reference SQL queries and we choose the first option as groundtruth for metric computation. XiYan-SQL reports the highest score of 69.86% on SQL-Eval. We outperform SQL-Coder-8B 4 fine-tuned on LLaMA-3 [4] by a large margin of 8.59% and closed-source backbone models by 2~5 percent. It demonstrates the generalizability of XiYan-SQL on SQL generation for PostgreSQL."}, {"title": "7.5 NL2GQL Results", "content": "To assess the effectiveness of XiYan-SQL on non-relational graph datasets, we sample a total of 288 examples from the NL2GQL [33] dataset, which were previously utilized in MoMQ [12]. As shown in Table 5, GPT-40, DeepSeek, Gemini 1.5 Pro and Claude 3.5 Sonnet show a limited overall execution accuracy on NL2GQL dataset. XiYan-SQL achieves 41.20% execution accuracy, outperforming them by a large margin and demonstrating the best performance overall."}, {"title": "7.6 Ablation Studies", "content": "To further investigate the effectiveness of each component in our framework, we conduct ablation studies on the Bird development benchmark because of its challenging nature and more reflective of the real-world scenarios."}, {"title": "7.6.1 M-Schema", "content": "We conduct ablation study on the Bird development benchmark to present the impact of different schema representations on end-to-end SQL generation performance. To demonstrate the generalization ability of our proposed M-Schema, we use fout powerful LLMs as NL2SQL generators, DeepSeek [14], Claude 3.5 Sonnet 5, Gemini 1.5 Pro and GPT-40 [1]. As shown in Table 6, all four models have performance improvements using M-Schema as the representation of database schema compared to DDL Schema, with an average increase of 2.03%. Although M-schema is similar to MAC-SQL Schema in structure, GPT-40 and Claude 3.5 Sonnet show 0.65% and 0.78% improvements, respectively. While DeepSeek and Gemini 1.5 have slight accuracy decreases of 0.13% and 0.26%. The experimental results indicate that M-Schema is a better representation than DDL Schema and MAC-SQL Schema and demonstrates powerful generalizability."}, {"title": "7.6.2 Schema Linking", "content": "We conduct ablation study to evaluate the effectiveness of schema linking. We utilize recall and precision metrics to evaluate the correctness of the selected columns based on the corrected SQL query, which serves as the ground truth. We use GPT-40 as the NL2SQL generator to analyze the impact of schema linking on end-to-end EX metrics. The results are show in Table 7. Without schema linking, we provide all tables, columns and random sampled example values to LLM. It shows a precision of 10.14% and EX of 57.95%. The schema linking method in this report achieves a high precision of 74.74% while only slightly decreasing the recall. By providing the most relevant information to the model, the execution accuracy is improved by 2.15%, demonstrating the effectiveness of schema linking."}, {"title": "7.6.3 Candidate Generation and Selection", "content": "To evaluate the effectiveness and impact of candidate generation and selection, we conduct various ablation studies on XiYan-SQL. Table 8 presents the performance of XiYan-SQL when certain components are dropped, highlighting their significance in achieving high-quality performance. The \"XiYan-SQL All\" method achieves an accuracy of 71.51% by utilizing three candidates, of which two are generated from two distinct fine-tuned SQL generators (as described in Section 5.1), while one is produced by the ICL SQL generator with GPT-40 (as presented in Section 5.2). For the candidate generator, there is a significant decrease in the performance of XiYan-SQL when the fine-tuned candidate generators are removed, further indicating that our generator is capable of generating high-quality and diverse candidate SQL queries. Similarly, the removal of the ICL generator and Refiner also leads to a decline in performance. Additionally, concerning candidate selection, we observe that when the selection model is not employed, relying solely on self-consistency for candidate selection, XiYan-SQL's performance decreases by approximately three percentage points. This finding underscores the effectiveness of our proposed method. Finally, when the number of SQL candidates is increased to five, the accuracy of XiYan-SQL can further reach 72.23%."}, {"title": "8 Conclusion", "content": "In this technical report, we present a multi-generator ensemble framework for NL2SQL, named XiYan-SQL, which harnesses the benefits of the SFT approach to achieve enhanced controllability while also integrating the ICL approach to maximize the generation of high-quality and diverse SQL candidates. We propose a two-stage and multi-task training method to train a series of models with different preferences, along with a candidate selection strategy to select the most reasonable candidate. Xiyan-SQL demonstrates state-of-the-art performance on publicly available relational databases, including Spider and SQL-Eval, as well as on non-relational database NL2GQL. This highlights the significant potential of XiYan-SQL for high-quality NL2SQL generation on unseen samples coming from different distributions."}]}