{"title": "Towards Trustworthy Machine Learning in Production: An Overview of the Robustness in MLOps Approach", "authors": ["FIRAS BAYRAM", "BESTOUN S. AHMED"], "abstract": "Artificial intelligence (AI), and especially its sub-field of Machine Learning (ML), are impacting the daily lives of everyone with their ubiquitous applications. In recent years, AI researchers and practitioners have introduced principles and guidelines to build systems that make reliable and trustworthy decisions. From a practical perspective, conventional ML systems process historical data to extract the features that are consequently used to train ML models that perform the desired task. However, in practice, a fundamental challenge arises when the system needs to be operationalized and deployed to evolve and operate in real-life environments continuously. To address this challenge, Machine Learning Operations (MLOps) have emerged as a potential recipe for standardizing ML solutions in deployment. Although MLOps demonstrated great success in streamlining ML processes, thoroughly defining the specifications of robust MLOps approaches remains of great interest to researchers and practitioners. In this paper, we provide a comprehensive overview of the trustworthiness property of MLOps systems. Specifically, we highlight technical practices to achieve robust MLOps systems. In addition, we survey the existing research approaches that address the robustness aspects of ML systems in production. We also review the tools and software available to build MLOps systems and summarize their support to handle the robustness aspects. Finally, we present the open challenges and propose possible future directions and opportunities within this emerging field. The aim of this paper is to provide researchers and practitioners working on practical AI applications with a comprehensive view to adopt robust ML solutions in production environments.", "sections": [{"title": "1 INTRODUCTION", "content": "In the current landscape of real-world applications, the exponential generation of data coupled with their inherent complexity and dynamism requires the development of efficient analysis mechanisms. With the increasing difficulty in managing data-driven applications for monitoring and prediction, the deployment of artificial intelligence (AI) systems has played a vital role in real-world applications due to fast-paced advances and innovation in the field [137]. These AI systems, equipped with various toolkits, offer a wide range of solutions that can be adopted to help decision makers take rapid action in various applications [3]. Machine learning (ML), the heart of AI, empowers applications to learn and adapt automatically, paving the way for intelligent and autonomous operation. [78].\nTraditionally, the development pipeline of ML systems involves the processing of historical data, which represents the raw input, to extract the features to train an ML model(s) that would perform the desired task offline to produce the output [45]. The pipeline includes additional sub-tasks like feature engineering, validation, testing, and performance evaluation. However, this static approach, while useful for initial research and experimentation, often proved inadequate in real-world scenarios. The fundamental challenge arises when the ML solution needs to be operationalized and deployed to function in a real-world environment [134]. In such scenarios, additional constraints and limitations should be specified to perform the tasks that characterize the ML solution, as the offline solution may not meet real-world requirements. For that, the transformation from offline to online ML system implementation has recently been of great importance to shift towards systems that perform in real-time and continuously circulate in production.\nMachine Learning Operations (MLOps) have emerged as a potential recipe for designing ML solutions in online deployment scenarios. MLOps is an extension of DevOps, which is a well-known and mature topic in software engineering, to run ML systems in production [135]. MLOps is a set of practices and techniques that aims to automate the delivery of ML models to production [5]. Conceptually, MLOps adopts DevOps principles for building ML systems. In particular, the core principles MLOps uses from DevOps are continuous integration (CI) and continuous delivery (CD). Iteratively and continuously, CI/CD facilitates the automated process of releasing reliable software in short cycles [70]. However, ML systems exhibit different specifications and involve more components than traditional software systems, which require special management and maintenance. MLOps supports the development of ML systems in all phases of the entire ML workflow, from data retrieval to the release and deployment of the solution.\nAs illustrated in Fig. 1, MLOps serves as a vital companion throughout the lifecycle of AI products, ensuring the continuous monitoring and delivery of ML systems. However, there exists a great need to establish and clarify the elements and standards necessary for achieving optimal system performance. During the last decades, ML research has been highly dependent on quantitative metrics such as accuracy and loss measures to identify system performance and guide the selection of the ML approach [76]. However, at the holistic level of AI application systems, such metrics may not fully capture task performance. For example, a technically accurate solution that compromises ethical standards, such as utilizing private information in datasets or deploying an ML system with weak robustness to changes, poses significant concerns for AI systems. To address these issues, researchers and practitioners in the AI community have begun to consider these aspects and introduce more principles while building AI systems [93]. The aspects and principles are known as AI trustworthiness [175].\nRecently, trustworthy AI has made substantial strides in both academia and industry. Many governing bodies, organizations, and companies have formulated requirements and introduced principles to build trustworthy AI systems. The most popular definition of trustworthy AI was established by the European Union\u00b9, which states that trustworthy AI systems have three key components: lawful, ethical, and robust [30]. Naturally, any MLOps framework designed within a trustworthy AI product must inherit the same principles and meet the requirements. In fact, from a technical standpoint, the MLOps pipeline is the most significant part of the AI system in production, and the implementation of such a trustworthy strategy must be thoroughly considered when devising an operationalized solution for an AI application.\nSince MLOps is more concerned with the performance and quality of the system [131] and has less to do with ethical and lawful issues, we will narrow the focus of this paper to the technical robustness aspect of trustworthy AI systems. Robustness, in particular, is of major importance in practical MLOps systems. A robust ML system must be able to retain its effectiveness even when faced with unforeseen or unexpected challenges. The occurrence of system failures or inaccuracies in such settings can potentially cause interruptions or safety risks for users. Therefore, to maintain user trust and confidence in AI solutions, the robustness aspect of MLOps systems must be thoroughly addressed during development and deployment to secure sustained reliability in the long run and ultimately the responsible and effective deployment of ML in the dynamic real world.\nThis paper formalizes the specifications of robust ML systems in production through an in-depth literature search. In particular, we explore the connection between the robustness property, as a principal component of trustworthy AI systems, and the MLOps approach, as a primary methodology to streamline ML solutions. By formalizing this connection, which has not been exhaustively covered in the literature, we aim to provide researchers and practitioners with a consolidated view of the field. We summarize the contribution of this paper as follows:\n\u2022 We organize the robustness aspects of ML solutions in production into three components and provide detailed definitions of the related concepts.\n\u2022 We derive a set of specifications for a robust ML system, which is a seminal part of trustworthy AI systems, and reflect it with the workflow of ML solutions in production.\n\u2022 We give a comprehensive overview of the specifications of robust ML systems and the constituent elements of MLOps systems.\n\u2022 We review the literature on existing approaches that address the robustness aspects of ML systems in production.\n\u2022 We iterate the available tools to build MLOps frameworks and discuss their support to deal with the various robustness aspects.\n\u2022 Based on our broad analysis, we propose future directions and opportunities for researchers to further investigate in the area.\nThe remainder of this paper is organized as follows. In Section 2, we provide a general overview of the field and details of the research methodology followed in this work on surveying trustworthy AI and MLOps. In Section 3, we derive specifications to achieve robust MLOps systems and provide definitions related to the specifications of trustworthy AI systems and the elements of MLOps systems. In Section 4, we survey the approaches of academic research that address the robustness aspect of ML systems in production and summarize their pros and cons. We compare the different"}, {"title": "2 MOTIVATION AND RESEARCH METHOD", "content": "Trustworthy AI and MLOps are relatively new research topics in the maturing field of artificial intelligence (AI) in recent years. When searching for the terms trustworthy AI and MLOps on the Web of Science indexing platform\u00b2, the results reveal that the two topics have begun to attract increasing research attention over the past five years. However, trustworthy AI is a more mature topic than MLOps in the literature. As shown in Fig. 2, trustworthy AI began to emerge in 2018 with 25 publications. The number increased to 238 publications in 2021 and 118 in 2022 (the year of writing this manuscript). Similarly to MLOps, publications have increased in the past two years, from 1 publication in 2019 to 16 in 2021."}, {"title": "2.1 Trustworthy Al", "content": "Trustworthy AI is a framework to verify that the system is operating according to the expectations of stakeholders [83]. With the rapid growth of AI applications, researchers demonstrated the urge to shift the focus to building trustworthy AI systems [177]. Therefore, trustworthy AI has been introduced in numerous application domains, such as self-driving cars [81], dentistry [103], the architecture, engineering and construction (AEC) industry [50], and education [170]. For example, in the context of self-driving cars, trustworthy AI ensures safe and reliable autonomous vehicle operation, promoting passenger and pedestrian safety. Similarly, the healthcare field also benefits from trustworthy AI systems that help in the precise diagnosis of diseases and the planning of treatments, ultimately improving patient care and treatment outcomes.\nGiven this, guidelines and specifications have been proposed to frame the limits and set the requirements for a system to be recognized as a trustworthy AI system. These guidelines establish a systematic framework for verifying and confirming the integrity of AI systems in different fields of application. In this section, we summarize the characteristics of trustworthy AI systems and highlight the robustness property and its significance in maintaining the trustworthiness of AI systems."}, {"title": "2.1.1 Characteristics of Trustworthy Al systems", "content": "The High-Level Expert Group on Artificial Intelligence (AI HLEG) was appointed by the European Commission to develop a guide document that describes the key specifications of trustworthy AI systems [38]. The guidelines aim to provide the principles to which every AI system should adhere. Nevertheless, the guidelines document consists of three layers of abstraction, from the most abstract to the most concrete. At the conceptual level, according to EU guidelines, to make an Al system trustworthy, it should align three main components at the top level throughout its evolution; the components are summarized as follows: [82]:\n(1) Lawful: it ensures that the AI system must comply with all applicable laws and regulations, such as the General Data Protection Regulation (GDPR).\n(2) Ethical: it ensures that the development of AI systems is in accordance with the ethical values of human society.\n(3) Robust: it ensures that the AI system is technically and socially reliable so that it does not generate harmful risks that AI systems can cause.\nThe EU emphasized that the three components should be addressed during the development of AI systems and that the components should interact in deployment to provide a trustworthy service. To follow these guidelines, the document has identified four additional ethical principles for the development, deployment, and use of AI systems, which are: (a) respect for human autonomy, (b) prevention of harm, (c) fairness, and (d) explicability. These four principles are composed of seven fundamental requirements for trustworthy AI systems: (1) human agency and oversight, (2) technical robustness and safety, (3) privacy and data governance, (4) transparency, (5) diversity, non-discrimination, and fairness, (6) environmental and societal well-being, and (7) accountability. The EU requirements for trustworthy AI with different levels of abstraction are summarized in Fig. 3."}, {"title": "2.1.2 Robustness property of Trustworthy Al systems", "content": "Technical robustness is one of the imperative requirements for trustworthy AI systems, as discussed previously. The EU document related this requirement to the prevention of harm; in other words, the system should behave in a way that minimizes the associated risks and ensures the physical and mental integrity of humans. However, the technical details of the implementation of robust AI systems are not extensively discussed in the EU guidance document. Meanwhile, another detailed guide document has recently been published that surveys the topics relevant to building trustworthy AI systems has recently been published by the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) [75]. The technical report stated that the specification of trustworthy Al systems is out of the scope of the document; however, the report discussed related definitions and terminologies, threats and challenges, and mitigation measures for trustworthy AI systems.\nThe ISO/IEC report has provided a general definition of robustness as \u201cthe ability of a system to maintain its level of performance under any condition.\u201d However, this general definition can be more concrete depending on the type of AI system. The robustness property generally ensures that the system can operate continuously according to its design. More specific definitions of robustness have been given in the ISO/IEC technical report depending on the functionality of the AI system, such as interpolation, classification, solving tasks or scoring.\nOn the other hand, while accuracy has traditionally been a key metric for the evaluation of Al systems [133], recent studies in ML [163] and deep learning (DL) [185] have emphasized the importance of robustness as another critical measure that highlighted a significant trade-off with the accuracy. Specifically, robustness encompasses a broader set of properties than accuracy as it pertains to the system's ability to maintain functionality amidst various challenges and disturbances. In contrast, accuracy is primarily focused on the predictive performance of the models and serves as a means to achieve robust AI systems [60].\nRegarding other system performance metrics, robustness can impact latency through additional checks, but optimization techniques such as parallel processing can help mitigate this effect [178]. However, as robust systems become more complex, interpretability may decrease, although explainable AI can serve to bridge this gap. Furthermore, highly robust systems may pose challenges in terms of maintenance, as they often involve complex error-handling mechanisms and configurations. Nevertheless, modular design principles and automation can help streamline maintenance processes and facilitate the management of robust systems over time [151].\nTechnically, robustness can also be recognized at both the data and algorithm levels [93]. Since the quality of ML solutions is highly dependent on input data, it is natural that data plays a major role in building robust AI systems. Therefore, data quality issues must be carefully investigated and formulated before implementing an AI solution. An important root of data quality issues is that, in real-life applications, data corruptions and inconsistencies are usually unanticipated. Another major issue is that the data will most likely follow changes during the evolution of the system [161]. Likewise, the robustness property must be considered at the algorithmic level, especially in high dimensions, where computations are relatively expensive [40]. In most cases, the robustness of the algorithm in ML is coupled with the quality of the data, since it mainly implies the insusceptibility to data disturbances and the ability to generalize training inputs."}, {"title": "2.2 Machine Learning Operations (MLOps)", "content": "The field of MLOps is a relatively nascent topic that studies standardized methodologies and strategies for the deployment of ML solutions in real-world AI applications. In the literature, the term AIOps can also be found to describe ML systems in operations [108]. However, according to Google Trends data\u00b3 and as shown in Fig. 4, MLOps has started to be used more frequently than AIOps after 2021. MLOps is a heterogeneous discipline based on the application of DevOps principles to ML software systems [77]. MLOps provides a comprehensive framework for managing the entire lifecycle of ML models, including data acquisition, data preparation, model training, testing, evaluation, deployment, and continuous monitoring. This approach ensures efficient development and effective maintenance of ML systems in operational environments [63].\nThe MLOps lifecycle involves several key stages. It begins with ensuring high-quality, reliable data through the collection, cleaning, and preprocessing of raw data to make it suitable for model training. Next, machine learning models are developed and trained by selecting appropriate algorithms, tuning hyperparameters, and iterating to improve performance [136]. Rigorous testing evaluates the model's performance on unseen data to ensure generalization and meet accuracy and reliability standards. The trained model is then deployed into a production environment to make predictions on new data without disrupting existing services. Continuous monitoring of the model's performance in production is essential to detect any degradation, requiring updates and retraining with new data to maintain consistent performance. Managing data versions and model artifacts is crucial for reproducibility and compliance, ensuring all steps in the ML pipeline are well-documented.\nIn MLOps, testing goes beyond traditional software approaches to specifically address the unique challenges of ML systems. This includes rigorous validation of data quality during collection and preprocessing to optimize model training [191].Unit testing examines specific components like data pipelines and model algorithms to guarantee consistent performance with different datasets. Integration testing validates the seamless interaction between these components throughout the ML lifecycle, from data ingestion to deployment [112]. Additionally, MLOps emphasizes model explainability and robustness testing to enhance transparency and reliability against varying data conditions [125]. By integrating these specialized testing methodologies, MLOps facilitates the deployment of reliable and scalable ML solutions that meet the complex demands of real-world AI applications."}, {"title": "3 SPECIFICATIONS OF ROBUSTNESS FOR MLOPS SYSTEMS", "content": "Generally speaking, robustness is a broad concept that covers a wide range of aspects and properties [22]. As stated in the ISO document [75], robustness is usually defined for a specific problem in a particular context or domain. In the context of MLOps, robustness and resilience are crucial but distinct concepts [19]. Therefore, researchers from different fields have proposed a set of requirements to provide a robust formulation of their problems [86, 101]. Robustness focuses on the ML system's ability to maintain performance under varying and challenging data conditions, ensuring consistent and accurate predictions even with noisy or adversarial data. Resilience, however, pertains to the ML system's capacity to recover from failures or disruptions, ensuring the entire pipeline can continue operating or quickly resume normal functioning after issues such as hardware failures or software bugs. Our main focus is the robustness property, as it is crucial for guaranteeing the reliability and performance of models in real-world scenarios where data variability is common, ensuring the effectiveness of AI solutions in production environments [152]. In this section, and based on an exhaustive literature search, we dissect the specifications of robust MLOps frameworks, which is a seminal part of building trustworthy AI systems in production environments.\nTo build an overall robust MLOps system, robustness specifications should be addressed in all system processes. Practically speaking, to build a holistic robust ML system in production, we should address the issues and challenges that affect system robustness at both the data levels and the algorithmic levels, in addition to employing a robust automation process that drives the entire system. However, none of the existing frameworks addresses all aspects of building a robust system. Meanwhile, existing frameworks partially handle the robustness of ML systems; examples are: robustness to outliers [56], robustness to drift [117], or robustness to noise [68]. Therefore, we drill down to the level of granularity of the MLOps system ingredients, i.e., automation, DataOps, and ModelOps. The overall components and operations of the MLOps system, together with the corresponding subtasks, are summarized in Fig. 5.\nIllustrating robustness with a concrete example of a traffic prediction system utilized in a navigation application. Robustness in this context refers to the system's ability to adapt to unforeseen situations in road conditions, such as accidents or construction, to deliver accurate and timely route recommendations for users. At the data level, challenges may arise from inconsistencies or inaccuracies in input data, such as missing or incorrect traffic flow information. Employing robust data processing techniques such as data cleansing and anomaly detection can ensure the overall validity of the input data. Furthermore, at the model level, robustness involves developing algorithms that are resistant to variations in traffic patterns and environmental factors. Therefore, robust ML models should generalize well across different road networks and traffic conditions, effectively mitigating the impact of data and algorithmic challenges on the accuracy of prediction. In this way, the system reduces the risk of providing inaccurate navigation guidance, promoting user satisfaction and safety during their journeys."}, {"title": "3.1 Robustness in Automation", "content": "MLOps systems are based on a continuous automated process that validates, monitors, and updates ML artifacts to maintain high performance during the evolution of the system [150]. To obtain elastic and reliable MLOps frameworks in production, a robust automation system should be implemented to allow rapid updates in the pipeline [79]. To achieve that, MLOps leverages the principles of DevOps, CI/CD, which offer practical techniques to manage the service throughout its development stages [171]. These techniques ensure that elements of the ML system are regularly managed and updated to optimize performance [55]. Since automation involves several steps, ranging from system build-up to system monitoring, the robustness aspect should be addressed at every step."}, {"title": "3.1.1 Robust Continuous Validation", "content": "ML validation is a diagnostic step that precedes the deployment of the designed solution; it aims to verify the performance under conditions different from those used when building the solution [166]. During ML validation, the robustness of performance could be tested against bias towards training conditions [130]. Therefore, it governs the process of identifying potential solutions for real deployment environments by estimating performance under a wide range of problem settings [92]. Furthermore, the implementation of a well-defined validation mechanism not only leads to more reproducible solutions [83] but also helps mitigate the risks associated with ML models in general, such as security concerns [111], adversarial attacks [148], and risks related to algorithms and data [158].\nThe ML validation methodology generally uses several configurations, including dataset splits, performance evaluation metrics, and model hyperparameter settings [172]. The hyperparameter settings of the model are considered an aspect of model robustness [46] and will be further investigated in a separate section. For the other configurations, there are several techniques and settings that can be found in the literature to develop a robust model evaluation methodology. In particular, how to select the validation datasets and performance metrics to evaluate the performance of the tested solution.\n\u2022 Selection of Validation Split. The factor that typically drives the choice of (a) suitable validation split (s) is the robustness aspect that is being tested during the validation phase. Therefore, to increase the robustness of the ML solution, the system should be thoroughly tested against various potential challenges, such as anomalies, drift, or adversarial attacks [27]. Following that design, it is necessary to prepare curated validation splits that contain potential production data issues to thoroughly verify the robustness of the solution. Mostly, validation splits should include outliers, missing data, or distribution shifts. Then, the performance of the system is recorded across the validation splits. Traditionally, many techniques divide the dataset and achieve more robust systems [75]. Cross-validation is the most common statistical method to estimate the performance of an ML model under specific conditions. In the literature, many techniques to perform cross-validation exist. Generally, K-fold cross-validation is the standard procedure for splitting the dataset. The procedure splits the dataset into K subsets that are used to train and validate the model [8]. Some other cross-validation methods are single hold-out random subsampling and leave-one-out cross-validation [18]. However, since building robust solutions requires a systematic way of selecting the splits, random subsampling would not necessarily guarantee the creation of robust splits.\n\u2022 Selection of Performance Metric. After selecting the validation split, the performance of the ML model in the validation split is statistically quantified. Typically, the learning task determines which performance metric to choose. For example, the most popular metrics in regression problems are empirically calculated based on the distance between the actual and predicted values [21]. On the contrary, in classification, most performance metrics are empirically calculated based on the fraction of correctly classified predictions [140]. However, in some problems, a single performance metric does not necessarily provide a good indication of the robustness of the solution. For example, in class imbalance problems, the accuracy measure does not provide a reasonable estimate of the quality of the solution, and the F score, which is a combination of precision and recall measures, is a more explanatory indicator of performance [59]. Another example is Cohen's kappa coefficient [37] for multilabel classification problems. However, there are other popular performance metrics, such as the area under the receiver operating characteristic curve (AUC-ROC), the confusion matrix, and the coefficient of determination R\u00b2 [51]. Therefore, it is essential to carefully select several performance metrics in the evaluation phase to capture robustness characteristics from different perspectives."}, {"title": "3.1.2 Robust Continuous Versioning", "content": "Building ML solutions in production is an iterative process that accompanies the development of the system throughout its life cycle [34]. The ML artifacts will follow changes over time, so it is fundamental to record the historical versions to obtain robust and tractable MLOps systems. Therefore, incorporating a centralized version control mechanism, a principle derived from continuous integration, is the first step after finalizing a releasable solution [162]. The main benefits of ML versioning are: reproducibility and traceability [110]. On the one hand, using a unique version number allows us to locate and trace the roots of the fault, and on the other hand, it also allows us to reuse a specific state of the system [182]. Continuous versioning requires an effective control mechanism for the governance of ML artifacts. A robust versioning mechanism must ensure that the different ML artifacts, such as configuration and hyperparameters, data and algorithm, have consistent version numbers for a specific iteration [67]. Moreover, the versioning mechanism should clearly define what is considered an iteration. To determine the variations in the ML artifacts to uniquely identify a distinct iteration in the MLOps life cycle."}, {"title": "3.1.3 Robust Continuous Monitoring", "content": "Lifelong monitoring of MLOps systems is a continuous process to collect feedback on production quality. Monitoring of the post-production model actively checks system performance and diagnoses various elements of the system to alert to abnormal behaviors [23]. Since the construction of MLOps systems involves the integration of several components into the system infrastructure, it is essential to establish a comprehensive monitoring strategy to cover these components. In production, model monitoring includes detecting degradation in both model performance and data quality, such as outliers, distributional shift, or concept drift [87]. Monitoring requires a benchmark to compare the behavior of the current iteration with a pre-defined reference. For example, an evaluation is performed on the basis of the ground-truth labels for the production data to identify the degradation of the ML system's performance [187]. However, the ground-truth might be costly (sometimes impossible) to collect or unavailable immediately [202]. Another example is monitoring the input data drift, which will be examined in more detail later, which involves analyzing the distribution of production data. Thus, a reference distribution should be available for comparison."}, {"title": "3.1.4 Robust Continuous update", "content": "An update signal is triggered to refresh the learning system to maintain the robustness of the ML model's performance and keep them up to date with the newly arriving data. This step is activated mainly by feedback from model monitoring to extend the existing solution [75]. Typically, the learning algorithm continuously uses the new output of the system to produce new versions of the ML model, known as the feedback loop. To update the model, two key considerations are identified in the literature [138]; the first is when to update the model. The second is how to execute the update. The first consideration focuses on deciding whether we need to update our learning pipeline. This is closely interlinked with model evaluation results; specifically, a threshold should be set, such as the level of performance degradation or the magnitude of distributional shifts. If these thresholds are exceeded, an update signal should be activated to update the ML artifact with the current context of the environment [165]. A typical example is to re-train the model after following a change in the system, for instance, concept drift occurrence. The second consideration has to do with the update procedure of the model. There are many alternatives to update the model, such as performing re-training, adaptation, or replacement of the model [127]."}, {"title": "3.2 Robustness in DataOps", "content": "ML solutions are mainly based on data manipulation to infer patterns in the system [105]. Data are pivotal for most of the phases of MLOps pipelines, as they are used to understand the characteristics of our problem and interpret the event episodes of our observations, in addition to practical use to train and validate the ML model. Due to this, robust data operations should be employed in the data artifact to increase the robustness of the overall MLOps system. DataOps is a new term coined collectively by data engineers, data scientists, and data analysts [118]. DataOps refers to end-to-end data processing operations in production and is considered an integral part of the entire MLOps system [10]. The challenges of the DataOps pipeline can be roughly divided into two groups. The first group deals with traditional data quality issues that primarily affect the accuracy of the predictive learning task. The second group deals with data operationalization, which is primarily concerned with data handling [26].\nThe e-commerce industry serves as an example of how robust DataOps practices are implemented in real-world scenarios to maintain operational efficiency and provide customized shopping experiences to customers. For example, within a large online retailer, ML systems analyze customer behavior and preferences to generate personalized product recommendations and targeted marketing strategies. Here, robust DataOps processes are key for managing extensive volumes of transactional data, customer interactions, and inventory records. In such a context, the retailer aggregates and processes data from various sources, including website interactions, purchase histories, and demographic profiles. Robust DataOps practices ensure data quality and reliability by employing data cleansing techniques to eliminate inconsistencies and inaccuracies. Furthermore, ongoing monitoring of data quality helps detect anomalies or discrepancies, facilitating prompt corrective actions."}, {"title": "3.2.1 Robust Data Cleaning", "content": "Data quality is a cornerstone of any data-driven solution since it may increase/decrease the accuracy of the analytic results [119]. Real-life applications, in which MLOps systems are used primarily, suffer from a high rate of erroneous data recorded from sensors that require cleaning and corrections. Therefore, most of the effort to build an ML solution is devoted to data cleaning to improve data quality [43]. Methods for processing data value errors can be roughly divided into two types: discarding erroneous data or cleaning erroneous data [174]. The latter can also be divided into manual and automatic cleaning. Manual cleaning provides more accurate results, but is more expensive to implement [174]. Data cleaning generally involves performing several activities to foster high levels of data reliability. These activities should be designed coherently to properly handle data corruption and imperfections. The main dimensions of data quality can be summarized as follows:\n\u2022 Handling Missing and Duplicate Values. Missing values and duplicates are very common in real-world applications and handling them is the most basic data cleaning task [48]. In real-world scenarios, missing values can appear for many reasons, such as sensor failures in industrial problems or incomplete laboratory test results in clinical problems [29]. From a robustness perspective, missing data is problematic for several ML models and should be resolved. As an example, the classification and regression tree (CART) models handle the issue by using surrogate splits to mitigate the effect of missing values [153]. Traditionally, missing values are handled by discarding the tuple that includes incomplete data or replacing missing values with a statistically inferred value, known as imputation [100]. Another issue of data quality is data duplication, or redundancy, which is a term that refers to the situation where some data records are repeated more than once in the dataset [196]. Similarly to missing values, the duplication of data samples has a negative implication in learning, as it can skew the input distribution [35], resulting in duplicate bias [7]. To detect duplicate values, Euclidean distance algorithms and Dynamic Time Warping (DTW) are the most widely used techniques, with the latter providing more convenient results in the case of big data [199]. Data fusion is the most widely used approach to correct data duplication [114].\n\u2022 Anomaly Detection. In the ML community, there is a large body of literature dedicated to studying the detection of extreme values in the dataset, known as anomaly detection. Anomalies are classified into three types: point, contextual, or collective anomalies [28]. Extensive prior works in anomaly detection have explored various methodologies and applications across different fields, providing a foundational understanding that is directly applicable to MLOps. In addition to the negative effect that anomalies have on the performance of predictive systems [72], anomalies can indicate malicious activities or adversarial attacks [74], which can affect the robustness of the overall system. The integration of these established anomaly detection techniques is crucial in MLOps pipelines, where they serve to identify and mitigate abnormal behavior, thereby maintaining system integrity and performance. Thus, anomaly detection is an essential step in any MLOps pipeline to detect abnormal behavior in the system and alleviate associated problems.\n\u2022 Domain-based Constraints. Another step in the data cleaning phase is to deal with data samples that violate the restrictions on attribute values. In classical database management systems, the domain-based constraint is a type of integrity constraint that specifies the semantic rules of the data values that should follow [122]. In almost every application, there are specific rules for the types and values of the different features of the dataset. Simple examples of domain-based constraints are that ages cannot be negative or names cannot be numerical. Usually, domain experts specify the possible ranges and types of attribute values to accurately design a handling mechanism for inconsistent observations in the system [121]."}, {"title": "3.2.2 Robustness to Distribution Shift", "content": "In production environments, the distribution of input data $P(X)$ often demonstrates distinct differences from that of training data due to the dynamic nature of post-deployment data [201]. For lifelong learning systems, the distribution change is an unresolved problem for predictive ML performance, as it tends to decline after the change [192]. Data distribution is a key foundation for many ML algorithms [176]. In deployment, MLOps systems should exhibit high robustness to distributional shifts; this requires systematic detection and adaptation mechanisms to cope with changes [44]. Theoretically, distributional shifts may not be associated with a change in the target concept, known as virtual drift [64]. However, in practice, the model should always be reviewed when there is a change in the data distribution [164]. The data used to train ML algorithms is assumed to be sampled from a distribution defined by an underlying generating function [66]. As discussed in Section 3.1.3, continuous monitoring strategies are deployed for a constant diagnosis of ML artifacts. Regarding distributional shifts, monitoring is generally performed by determining whether the data distribution of the present interval is significantly different from the past distribution using statistical tests [84]. However, some parameters must be defined to establish a robust monitoring strategy, such as the window size to estimate the probability distribution and the change significance threshold, which are selected primarily manually. For adaptation, there exist different techniques that increase the robustness of ML models to distributional shifts, such as importance weighting and uncertainty estimation [197]."}, {"title": "3.2.3 Robustness to Data Scarcity", "content": "Some real-world applications generate a few data points, especially in the medical sector and many industrial production processes [200]. Other related issues caused by data scarcity are applications with underreported data that cause the problem to be sparse [47], or the problem of class imbalance, which is characterized by data-scarce regions of the underrepresented classes [102]. Therefore, the lack of historical data would hinder the development of a learning solution with good generalization performance. Inadequate training samples used to train the model in the training phase would lead to unexpected production behavior or bias towards the overrepresented population [11]. Therefore, data enrichment techniques, such as data augmentation, have been utilized to enhance data-scarce applications by generating more data samples based on the limited available data, or transfer learning by using pre-learned ML models and employing them in a similar task [142]. Additionally, Generative Adversarial Networks (GANs) offer a promising approach to address data scarcity [12]. GANs are a type of deep learning model that can create entirely synthetic data closely resembling the real data distribution, allowing for significant data expansion. This is especially beneficial for scarce datasets, as demonstrated in applications like diagnosing COVID-19 from lung scans with limited real data [4]. Research has also explored the effectiveness of GANs in the energy sector for power consumption prediction and in defect detection [183]."}, {"title": "3.2.4 Robustness and Data Processing Resources", "content": "In information systems, the resources are not infinite. Any solution developed must be designed within the limits of stringent capacity constraints. In relation to deployment systems, data manifest the bottleneck in the MLOps pipeline [128"}]}