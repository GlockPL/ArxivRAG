{"title": "Fast Inference for Probabilistic Answer Set Programs via the Residual Program", "authors": ["Damiano Azzolini", "Fabrizio Riguzzi"], "abstract": "When we want to compute the probability of a query from a Probabilistic Answer Set Program, some parts of a program may not influence the probability of a query, but they impact on the size of the grounding. Identifying and removing them is crucial to speed up the computation. Algorithms for SLG resolution offer the possibility of returning the residual program which can be used for computing answer sets for normal programs that do have a total well-founded model. The residual program does not contain the parts of the program that do not influence the probability. In this paper, we propose to exploit the residual program for performing inference. Empirical results on graph datasets show that the approach leads to significantly faster inference. The paper has been accepted at the ICLP2024 conference and under consideration in Theory and Practice of Logic Programming (TPLP).", "sections": [{"title": "1 Introduction", "content": "Statistical Relational Artificial Intelligence (Raedt et al. 2016) is a subfield of Artificial Intelligence aiming at representing uncertain domains with interpretable languages. One of these languages is Probabilistic Answer Set Programming (PASP) under the credal semantics, i.e., Answer Set Programming (ASP, and we use the same acronym to denote answer set programs) extended with probabilistic facts. Inference in PASP often requires grounding the whole program, due to the model driven ASP solving approach. However, other formalisms based on query driven languages, such as PITA (Riguzzi and Swift 2011) and ProbLog2 (Dries et al. 2015), only ground the relevant part of the program. For a specific class of ASP, namely normal programs without odd loops over negation, we propose to extract the relevant program using SLG resolution (Chen and Warren 1996), that offers the possibility of returning the residual program, which can then be used to compute the answer sets of the program. At a high level, the process is the following: first, we convert a PASP into a Prolog program that is interpreted under the Well-founded semantics. Then, we leverage SLG resolution via tabling to compute the residual program"}, {"title": "2 Background", "content": "In this paper, we consider normal logic programs, i.e., programs composed of normal rules of the form r = h : - b\u2081, ..., bm, not c1,..., not cm, where h, b\u1d62 for i = 1, . . ., m and c\u2c7c for j = 1,...,n are atoms. Given a rule r, we call H(r) = h, B\u207a(r) = {b\u2081,..., bm}, B\u207b(r) = {c\u2081,...,c\u2099}, B(r) = {b\u2081,...,bm, not c\u2081,...,not c\u2099} the head, positive body, negative body and body of r. A rule with an empty body is called fact. We indicate the Herbrand base of a program P with B\u209a and its grounding with ground(P). We use the standard notation name/arity to denote a predicate with name name and arity, i.e., number of arguments, arity. The call graph of a program P is a directed graph with one node for each predicate in the program. There is an edge between a predicate p/n and a predicate q/m if p/n is the predicate of the head atom of a rule and q/m is the predicate of a literal in the body of that rule. The edge is labeled as positive (+) or negative (-) depending on whether the literal is positive or negative in the body of the considered rule. A program P includes Odd Loops Over Negation (OLON) if its call graph contains a cycle with an odd number of negations. The dependency graph of a program P is a directed graph with one node for each atom in the Herbrand base of the program. There is an edge between an atom a and an atom b if a is the head of a rule in the grounding of P and b is the atom of a literal in the body of that rule. A semantics is relevant (Dix 1995) if the truth value of an atom a depends only from the truth value of the atoms of the relevant sub-graph of the dependency graph, i.e., the sub-graph that contains the nodes that are reachable from a."}, {"title": "2.1 Stable Model Semantics", "content": "The Stable Model Semantics (SMS) (Gelfond and Lifschitz 1988) associates zero or more stable models to logic programs. An interpretation is a subset of B\u209a. The reduct of a ground program P w.r.t. an interpretation I, P\u1d35, also known as Gelfond-Lifschitz reduct, is the set of rules in the grounding of P that have their body true in I, that is P\u1d35 = {r \u2208 ground(P) | B\u207a(r) \u2286 I, B\u207b(r) \u2229 I = \u2205}. A stable model or answer set (AS) of a program P is an interpretation I such that I is a minimal model under set inclusion of P\u1d35. With AS(P) we denote the set of answer sets of a program P. We also consider projected answer sets (Gebser et al. 2009) on a set of ground atoms V, defined as AS\u1d65(P) = {A \u2229 V | A \u2208 AS(P)}. Answer Set Programming (ASP) (Brewka et al. 2011) considers programs under the SMS."}, {"title": "2.2 Well-founded Semantics", "content": "The Well-founded Semantics (WFS) (Van Gelder et al. 1991) assigns a three valued model to a program. A three valued interpretation I is a pair I = (I\u1d1b; I\ua730) where both"}, {"title": "2.3 SLG Resolution and Tabling", "content": "SLG resolution was proposed by Chen and Warren (1996) and was proven sound and complete for the WFS under certain conditions. Its implementation in the most common Prolog systems, such as XSB (Swift and Warren 2012) and SWI (Wielemaker et al. 2012), is based on tabling. In the forest of tree model of SLG resolution (Swift 1999), a tree is generated for each sub-goal encountered during the derivation of a query. Nodes are of the form fail or\nAnswerTemplate :- GoalList|DelayList\nwhere AnswerTemplate is a (partial) instantiation of the sub-goal and GoalList and DelayList are lists of literals. DelayList contains a set of literals that have been delayed, which is needed to allow the evaluation of a query under the WFS (where the computation cannot follow a fixed order for literal selection) with a Prolog engine (where the computation follows a fixed order for selecting literals in a rule). An answer is a leaf"}, {"title": "2.4 Probabilistic Answer Set Programming", "content": "The Credal Semantics (CS) (Cozman and Mau\u00e1 2020) allows the representation of un-certain domains with ASP extended with ProbLog probabilistic facts (De Raedt et al. 2007) of the form p\u1d62 :: a\u1d62 where p\u1d62 \u2208 [0,1] is a probability and a\u1d62 is a ground atom. Such programs are called Probabilistic ASP (PASP, and we use the same acronym to denote Probabilistic Answer Set Programs). A world is obtained by adding to the ASP a subset of the atoms a\u1d62 where p\u1d62 :: a\u1d62 is a probabilistic fact. Every PASP with n probabilistic facts has thus 2\u207f worlds. The probability of a world w is computed as:\nP(w) = \u220f\u2090\u1d62\u2208w p\u1d62 \u22c5 \u220f\u2090\u1d62\u2209w(1 \u2013 p\u1d62). Each world is an ASP and it may have 0 or more answer sets but, for the CS to be defined, it is required that each world has at least one AS. If the ASP is normal without OLON, then the CS exists."}, {"title": "$\\\\P(q) = \\\\sum_{w_i : \\exists m \\in AS(w_i), m \\models q} P(w_i), \\qquad \\underline{P}(q) = \\\\sum_{w_i : m \\in AS(w_i), m \\models q} P(w_i).$", "content": "In other words, the upper probability is the sum of the probabilities of the worlds where the query is present in at least one answer set, while the lower probability is the sum of the probabilities of the worlds where the query is present in every answer set. In the case that every world has exactly one answer set, the lower and upper probability coincide, otherwise \\overline{P}(q) > \\underline{P}(q)."}, {"title": "$\\\\2AMC(T) = \\\\bigoplus_{I_O \\in \\mu(X_O)} w_O(I_O) \\bigodot f \\Biggl(\\bigoplus_{I_I \\in \\varphi(T \\| I_O)} \\bigotimes_{b \\in I_I} w_i(b)\\Biggr)$", "content": "where \u03bc(X\uff61) is the set of assignments to the variables in X\uff61 and \u03c6(T | Io) is the set of assignments to the variables in T that satisfy Io. In other words, the 2AMC task requires solving an Algebraic Model Counting (AMC) (Kimmig et al. 2017) task on the variables"}, {"title": "3 Extracting the Residual Program for PASP", "content": "From Example 4, we can see that the probability of the query path(a,d) is not in-fluenced by the probabilistic fact e(a, c). Let us call P(e(a,b)) = p\u2080, P(e(a,c)) = p\u2081, and P(e(b,d)) = p\u2082, for brevity. The upper probability of path(a,d) is computed as\nP(w\u2085) + P(w\u2087) = p\u2080 \u22c5 (1 \u2212 p\u2081) \u22c5 p\u2082 + p\u2080 \u22c5 p\u2081 \u22c5 p\u2082 = (p\u2080 \u22c5 p\u2082) \u22c5 ((1 \u2212 p\u2081) + p\u2081) = p\u2080 \u22c5 p\u2082, so, the value of p\u2081 is irrelevant, and the probabilistic fact e(a, c) can be removed from the program. However, during the grounding process, the probabilistic fact is still considered, increasing the size of the grounding. The same happens with rules that do not influence the probability of a query. While the programmer should take care of writing a compact program, encoding exactly the minimal information needed to answer a query, this is usu-ally difficult to do. Consider again Example 4: here it is difficult to immediately spot that"}, {"title": "Theorem 1", "content": "Given a normal program P without OLON together with its residual program Pr for a query q, the answer sets projected onto the Herbrand base B\u209a\u1d63 of P\u1d63 coincide with the answer sets of Pr, i.e.,\nAS\u1d2e\u1d3e\u1d40(P) = AS(P)."}, {"title": "Theorem 2", "content": "Given a PASP P together with its residual program P\u1d63 for a query q, let \\overline{P}(q) be the upper probability of q in P and \\overline{P'}(q) be the upper probability of q in P\u1d63. Then\n\\overline{P}(q) = \\overline{P'}(q).\nThe same is true for the lower probability."}, {"title": "4 Experiments", "content": "We ran the experiments on a computer running at 2.40 GHz with 32 GB of RAM with cutoff times of 100, 300, and 500 seconds\u00b9."}, {"title": "4.1 Datasets Description", "content": "We considered two datasets with two variations each and with an increasing number of instances. The reachability (reach) dataset models a reachability problem in a proba-bilistic graph. All the instances have the rules (here we model negation with \\+, since it is the symbol adopted in aspmc):\nedge(X,Y):- e(X,Y), \\+ nedge(X,Y).\nnedge(X,Y):- e(X,Y), \\+ edge(X,Y).\npath(X,Y) :- edge(X,Y).\npath(X,Z) :- edge(X,Y), path(Y,Z).\nwhere the e/2 facts are probabilistic with probability 0.1. We developed two variations for this dataset: reachBA and reachGrid. The difference between the two is in the generation of the e/2 facts: for the former, they are generated by following a Barabasi-Albert model with initial number of nodes equal to the size of the instance and 2 edges to attach from a new node to existing nodes (these two values are respectively the values of the n and m parameters of the method barabasi_albert_graph of the NetworkX Python library (Hagberg et al. 2008) we used to generate them). The query is path(0, n \u2212 1). For the latter, the e/2 facts are such that they form a two-dimensional grid. In this case, the query is path(0, i), where i is a random node (different for every dataset).\nThe smokers dataset contains a set of programs modeling a social network where some people smoke and others are influenced by this behavior. Each person is indexed with a number, starting from 0. The base program is:\ninfluences(X,Y):- e(X,Y), \\+ ninfluences(X,Y).\nninfluences(X,Y):- e(X,Y), \\+ influences(X,Y).\nsmokes (X) :- stress(X).\nsmokes (X) :- smokes(Y), influences(Y,X).\nEach stress/1 atom is probabilistic with probability 0.1 and each influences/2 atom is probabilistic with associated probability 0.2. Also for this dataset we consider two variations, smokersBA and smokersGrid, that are generated with the same structure as for reachBA and reachGrid, respectively. For smokersBA the query is smokes(n - 1) where n is the number of person in the network, while for smokersGrid the query is smokes(i) where i is a random person (different for every dataset). For all the instances, the probability associated with probabilistic facts does not influence the time required to compute the probability of the query."}, {"title": "4.2 Results", "content": "In the following, aspmc denotes the results obtained by applying aspmc directly on the considered instance while aspmc* denotes the results obtained by first computing the residual program and then passing it to aspmc. For all the experiments the extraction of the residual program was done using the predicate call_residual_program/2 available in SWI. The extraction takes less than one second, so we decided to report only the total execution times, without indicating the two components for aspmc*. This is also the motivation behind the decision of testing only one Prolog system, namely SWI. We could have also used XSB but the results would not have been much different given the almost instantaneous extraction of the residual program. Given the probabilistic nature of the generation of Barabasi-Albert graphs and of the query for grid graphs, the results are averaged over 10 runs. For reachBA and smokersBA, the query is the same in every run but the structure of the graph changes in every run (i.e., each instance has a different graph structure). For reachGrid and smokersGrid, the grid graph is the same in each of the 10 runs but the query changes in each attempt."}, {"title": "5 Related Works", "content": "The residual program extraction is at the heart of PITA (Riguzzi and Swift 2011) and ProbLog2 (Dries et al. 2015), the first adopting Prolog SLG resolution to caching the part of the programs that has already been analyzed. There are other semantics to represent uncertainty with an answer set program such as LPMLN (Lee and Yang 2017), P-log (Baral et al. 2009) or smProbLog (Totis et al. 2023). LPMLN allows defin-ing weighted rules and assigns weights to answer sets while P-log adopts probabilistic facts but requires normalization for the computation of the probability. Furthermore, P-log has an interface built on top of XSB (Anh et al. 2008) leveraging its tabling mechanisms to speed up inference. The relation between the two has been studied in detail (Balai and Gelfond 2016; Lee and Yang 2017). Another possibility to associate weights to rules is via weak constraints, available in all ASP solvers, that however cannot be directly interpreted as probabilities. smProbLog is the semantics closest to the CS: both support probabilistic facts added on top of an ASP. The probability of a stable model in smProbLog is the probability of its corresponding world w divided by the number of answer sets of w. The CS has also been extended by Rocha and Gagliardi Cozman (2022) to also handle worlds without answer sets, but it requires three truth values (true, false, and undefined). The residual program extraction may help to speed up inference also in these alternative semantics: exploring this is an interesting future work. We consider the SLG resolution implemented in SWI Prolog. However, as already discussed in Section 2.3, it was initially proposed and implemented in the XSB system (Swift and Warren 2012). Our approach is general and can be built on top of any Prolog system that supports SLG resolution.\nThe problem of grounding in ASP has also been addressed by the s(ASP) (Marple et al. 2017) and s(CASP) Arias et al. (2018) systems, which are top-down goal-driven ASP interpreters (the latter also allowing constraints). The result of a query in these systems is a subset of the stable models of the whole program containing only the atoms needed to prove the query. Furthermore, the evaluation of a query does not need to ground"}, {"title": "6 Conclusions", "content": "In this paper we proposed to speed up inference in PASP via extraction of the residual program. The residual program represents the part of the program that is needed to compute the probability of a query and it is often smaller than the original program. This allows a reasoner to ground a smaller portion of the program to compute the probability of a query, reducing the execution time. We extract the residual program by applying SLG resolution and tabling. Empirical results on graph datasets shows that i) the time spent to extract the residual program is negligible w.r.t. the inference time and ii) querying the residual program is much faster than querying the original program."}]}