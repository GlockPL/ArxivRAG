{"title": "Enhancing Whole Slide Image Classification through Supervised Contrastive Domain Adaptation", "authors": ["Il\u00e1n Carretero", "Pablo Meseguer", "Roc\u00edo del Amor", "Valery Naranjo"], "abstract": "Domain shift in the field of histopathological imaging is a common phenomenon due to the intra- and inter-hospital variability of staining and digitization protocols. The implementation of robust models, capable of creating generalized domains, represents a need to be solved. In this work, a new domain adaptation method to deal with the variability between histopathological images from multiple centers is presented. In particular, our method adds a training constraint to the supervised contrastive learning approach to achieve domain adaptation and improve inter-class separability. Experiments performed on domain adaptation and classification of whole-slide images of six skin cancer subtypes from two centers demonstrate the method's usefulness. The results reflect superior performance compared to not using domain adaptation after feature extraction or staining normalization.", "sections": [{"title": "1. Introduction", "content": "Deep Learning (DL) models developed in the medical field must be robust to changes in the distributions of the input data promoting their generalization. The domain shift is defined as the difference between source and target domain data due to variations in image characteristics [1]. In digital pathology, domain shift is manifested as variability in terms of staining and digitalization protocols, specifically between different hospitals. Training robust DL models that tackle domain shift and generalize well across multiple domains remains crucial to provide accurate patient diagnosis.\nStaining normalization has been the most investigated approach to pursue domain generalization in histopathological images. To this end, methods based on H&E component separation [2] or image-to-image translation with generative adversarial networks [3] have been proposed to create a unified color space. However, these methods usually rely on target images and are not transferable to problems assessing tumors located in different tissue types. Other approaches have employed unsupervised contrastive techniques for histopathological image domain adaptation [4]. Nevertheless, these methods are highly demanding in terms of computational effort and volume of images. These limitations are particularly critical in the field of histopathological imaging since a large sample number to train DL-based models is not always available.\nBased on these observations, in this work, we design an efficient domain adaptation method to handle the variability related to the staining and scanning of the whole-slide images across multiple centers. The proposed framework, termed Supervised Contrastive Domain Adaptation (SCDA), addresses the representational shift of foundation models for the slide-level prediction of multiple skin cancer subtypes in a multi-center dataset. Our domain adaptation technique is based on supervised contrastive learning [5] with an embedded constraint during model training forcing the addition of samples from different centers. The low computational burden of the network coupled with the extensibility to the few-shot learning paradigm promotes efficient adaptation to solve the task at hand.\nThe main contributions are summarized as follows: Development of a methodology based on supervised contrastive learning for cross-center domain generalization, extension of our SCDA method to the few-shot learning paradigm, obtaining efficient domain adaptations with fewer exemplars of a hospital not previously covered in the training phase and evaluation of the quantitative and qualitative classification results compared to non-normalization and stain normalization, demonstrating significant improvement."}, {"title": "2. Methodology", "content": "An overview of the proposed method is illustrated in Fig. 1. The problem formulation and the different components implemented are described in the following."}, {"title": "2.1. Problem formulation", "content": "In the multiple instance learning (MIL) paradigm, an arbitrary number N of instances x are grouped into bags X = {X_n}_{n=1}^N. Each bag is assigned to a class S that is mutually exclusive from all other classes. Thus, in a multi-class environment, the assignment of X to a class is denoted as Y_s \u2208 {0, 1}. In the embedding-MIL approach, the goal is to obtain the WSI-level prediction using a bag-level representation Z of the features extracted at the patch level. Let H\u2081 and H\u2082 be different centers with different datasets but the same S classes. The objective is to find a transformation function T that drives Z_{H_1} and Z_{H_2} to a common feature space C, such that T: Z_{H_1} \u222a Z_{H_2} \u2192 C. Consequently, by finding T, we can define a prediction function F: C \u2192 Y_{H'} for the bag-level multi-class classification problem of H', using only the transformed representations T(Z_H) and labels Y_H."}, {"title": "2.2. Deep slide-level representation", "content": "MIL approaches heavily rely on feature extraction at the patch level to subsequently obtain a global representation of the bag. Let us denote a feature extractor f_\u03b8() : X \u2192 F, which projects the instances x \u2208 X to a lower-dimensional manifold z \u2208 F \u2282 \u211d^d, where d is the embedding dimension. Then, we utilize a non-trainable aggregation to obtain the slide-level representation Z by performing batch global average pooling (BGAP) across all the instances within a slide. Note that both the patch-level feature extraction and the WSI embedding aggregation do not require any parameter update, promoting the efficiency of our proposed method for domain adaptation under a few-shot learning scenario."}, {"title": "2.3. Supervised Contrastive Domain Adaptation", "content": "Contrastive learning is a technique that learns representations by contrasting similar and dissimilar data pairs to improve model discrimination. In this paradigm, supervised contrastive learning is established as a method capable of taking advantage of label information. Mathematically, the supervised contrastive loss for univiewed batch (typically, in contrastive learning one has multiviewed batches where there is more than one view for a single sample) can be defined as:\n\nL = \\sum_{i \\in I} L_i = - \\sum_{i \\in I} log \\frac{exp(z_i z_p / \\tau)}{\\sum_{a \\in A(i)} exp(z_i z_a / \\tau)} \n\nwhere z_i is a representation of sample i, z_p is a representation of a sample j \u2260 i that belongs to the same class, A(i) is the set of all representations of the batch and \u03c4 is a temperature parameter that scales the similarity between the representations. A cross-domain constraint is added to successfully apply supervised contrastive learning to the domain adaptation, such that:\n\u2200S, \u2200B, \u2200i \u2208 I_H \u2229 B, \u2203j \u2208 I_{H'} \u2229 B s.t. class(i) = class(j) = S\nbeing I the set of instances of a center H and B the batch where this restriction applies. Equation (1) encourages sample representations of the same class to cluster together and be further distanced from representations of other classes. Consequently, include the cross-domain constraint forces to consider inter-center variations for the same class. It is worth mentioning that applying (1) with the cross-domain constraint yields new slide-level C representations, which are the transformations of the Z representations."}, {"title": "2.4. MI-SimpleShot", "content": "The classification step in MIL frameworks usually constructs a multilayer perceptron (MLP) and a softmax activation function to obtain bag-level scores from the WSI embedding. However, the MLP optimization through minimization of the cross-entropy loss does not handle class imbalance and could lead to overfitting, hampering model generalization. For that purpose, our framework adapts the prompt-based classification approach named MI-SimpleShot [6]. We utilize the transformed bag-level embeddings C to construct the class prototypes (W) and the prediction of each slide is finally assessed by leveraging the largest similarity to the prototypes of each class, such as:\n\nY = argmax(W^T C)"}, {"title": "3. Experimental setting", "content": ""}, {"title": "3.1. Dataset", "content": "We resort to a multi-center dataset to evaluate the SCDA method for cross-center domain adaptation for slide-level classification [7]. The dataset contains up to 608 skin WSI from two different centers: Hospital Cl\u00ednico of Valencia (HCUV) and the Hospital Universitario San Cecilio (HUSC) of Granada. See Table 1 for a summary of the number of slides available for each neoplasm within each center.\nAs stated before, this work pretends to address the generalization ability of slide-level models through multiple centers that could present domain shifts regarding staining and scanning. In Section 4., we provide more insights into the domain shift at the representation level."}, {"title": "3.2. Implementation details", "content": "To accommodate the MIL paradigm, the WSIs were cropped into 512 squared pixel patches at 10x magnification with a 50% overlap. We utilized the Pathology Language Image Pretraining (PLIP) model for feature extraction at the patch level [8]. PLIP is a foundation model trained with vision"}, {"title": "4. Results", "content": ""}, {"title": "4.1. Quantitative evaluation", "content": "The classification results obtained are shown in Table 2. The balanced accuracies obtained by applying MI-SimpleShot on the PLIP and BGAP clustered representations are reasonably successful when predicting samples from the same dataset as the trained dataset or training both datasets (0.69 for HCUV, 0.80 for HUSC and 0.76 for both centers). However, a considerable drop in performance is observed when we infer the untrained hospital (0.54 for HCUV and 0.51 for HUSC).\nAs seen in the qualitative results (see Fig. 3a), the inter-hospital differentiation in the PLIP representations is very prominent. This means that the generalization capacity of the model in the face of domain shifts is partially limited. To solve the inter-hospital differentiation problem, Macenko [2] stain normalization was applied. Nevertheless, since the color of each WSI has a direct dependence on the cellular response to staining, eliminating this information results in a decrease in the classification performance compared to not applying Macenko normalization for domain generalization. When applying our approach, a considerable increase in all test metrics is observed with respect to the two previous approaches. This is due to the fact that our SCDA method removes inter-hospital variability and clusters the skin cancer subtypes in a more condensed way through supervised contrastive loss (see Fig. 3c).\nIn light of the results obtained in the different test sets of each hospital using SCDA, we propose to evaluate our method in a few-shot learning scenario. The results obtained for different numbers of training samples are illustrated in Fig. 2. When training with the HUSC data, it is seen that for the HUSC test set the performance is maintained regardless of the new knowledge introduced with the HUCV samples. With respect to inference on the HUCV test set, it is found that there is a significant improvement in inference performance as the number of shots is increased. With an increase of ~ 10% in the balanced accuracy from 0-shot to 10-shot, the usefulness of SCDA for cross-hospital slide-level classification based on just a few reference images is evident.\nIf we analyze the few-shot learning scenario by training with the HCUV dataset and adding k-samples from the HUSC training set, a significant improvement in the metrics can be seen. Thus, in the HUCV test set, the performance remains consistent regardless of the number of shots. In contrast, in the HUSC test set, the performance as the number of shots increases considerably improves. In this way, from 4-shots onwards, it can be seen how the application of SCDA improves the metrics obtained in the HUSC test set compared to using the whole set of train without using our SCDA method. Regarding the increase from 2-shot to 10-shot, it can be seen that it is ~ 15%. It should also be mentioned that from 8-shot onwards, comparable metrics are achieved when including the whole HUSC training set (ALL). This proves that the few-shot learning approach with SCDA is really powerful since the generalization capacity obtained with a few samples from a different domain is highly significant."}, {"title": "4.2. Qualitative evaluation", "content": "To appreciate the representation shift between the domain of the two centers, we represent in Fig. 3 the 2D t-SNE representations for the original PLIP embeddings and the two approaches for cross-hospital domain adaptation. The dimensionality reduction of the BGAP embeddings of the PLIP shows a large domain shift between centers. However, it is noteworthy the strong representation learning of the feature extractor as the cluster of each class within a center are quite separated from the others. This visualization helps to understand the poor generalization ability (see Table 2) of the initial model as the latent spaces separated due to bias between centers.\nAfterward, we compare the WSI-level embeddings after applying stain normalization to a target image of the HUSC dataset. Although the stain bias is mitigated for certain classes (lm, df), others (fxa, dfs) remain separated in the deep latent distribution. Moreover, the compactness of the samples within each class has been downgraded, suggesting that the color can provide valuable information to differentiate between tumors with different tissues. Finally, our SCDA approach across different centers not only mitigates the stain bias of the foundation model, but also enhances the similarity between samples of each neoplasm."}, {"title": "5. Conclusion", "content": "The intrinsic staining and digitization variability in the field of histopathological imaging, significantly affects the implementation of robust DL models. Solving domain shifts without loss of performance is essential for DL model generalization and implementation. In this work, we introduce a new domain adaptation method applied to histopathological images of a multicenter dataset. By using the supervised contrastive learning technique together with a cross-domain constraint, it is possible to transform features extracted from a foundational model into a generalized domain. Experiments performed using the HCUV and HUSC dataset demonstrate the power of the implemented method. The metrics obtained considerably outperform cross-domain adaptation without supervised contrative learning or applying a staining normalization prior to feature extraction. The adaptation of SCDA to the few-shot learning paradigm shows a considerable increase in classifier performance, being a promising approach in terms of training efficiency. The main limitations are the requirement of labels, the requirement of having the same classes in all hospitals, and the evaluation in a larger multi-hospital scenario (No. of H > 2). The described limitations open promising avenues of research in terms of adapting the proposed method to cases with no labels and to multi-hospital environments."}]}