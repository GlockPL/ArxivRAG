{"title": "Advance Detection Of Bull And Bear Phases In Cryptocurrency Markets", "authors": ["Rahul Arulkumaran", "Suyash Kumar", "Shikha Tomar", "Manideep Gongalla", "Harshitha"], "abstract": "Cryptocurrencies are highly volatile financial instruments with more and more new retail investors joining the scene with each passing day. Bitcoin has always proved to determine in which way the rest of the cryptocurrency market is headed towards. As of today, Bitcoin has a market dominance of close to 50%.\n\nBull and bear phases in cryptocurrencies are determined based on Bitcoin's performance over the 50-Day and 200-Day Moving Averages.\n\nThe aim of this paper is to foretell the performance of bitcoin in the near future by employing predictive algorithms. This predicted data will then be used to calculate the 50-Day and 200-Day Moving Averages and subsequently plotted to establish the potential bull and bear phases.", "sections": [{"title": "I. INTRODUCTION", "content": "A well known fact about the Cryptocurrency markets is that the markets are extremely volatile. Bitcoin was the first cryptocurrency that was developed by Satoshi Nakamota. Satoshi Nakamota is the pseudo name of the person who developed cryptocurrencies. However, until today nobody knows who is Satoshi Nakamoto.\n\nAlthough the identity of the person who created Bitcoin is unknown, the community did not let that bother them. The aim of Bitcoin was to be truly decentralised as Satoshi Nakamoto mentioned in the whitepaper for Bitcoin and the community embraced this change. Bitcoin was created in 2009 and it has been 11 year since then, but it was only in 2013 that Bitcoin started gaining traction. Retail investors were initially reluctant to invest in Bitcoin but that changed in 2013. Since then, the cryptocurrency markets have seen the advent of many altcoins like Ethereum, Cardano, Ripple, Litecoin, Bitcoin Cash, and many more.\n\nSince then, the price of Bitcoin has skyrocketed and as of writing this paper, Bitcoin's all-time high has been at $69,000. Although Bitcoin has seen exponential gains in the last couple of years, Bitcoin has always had bullish and bearish cycles. Usually, each cycle lasts for about 4 years and this has allowed most retail and institutional investors to perform robust technical analysis to understand potential price targets in each cycle.\n\nAlthough Bitcoin has these 4 year cycles, the price of Bitcoin does not always keep increasing or decreasing in bull and bear cycles respectively. There are corrections in bull cycles which result in major pull back in the price and at the same time there are major price pumps during bearish cycles.\n\nWith more and more institutional investors entering the cryptocurrency markets, it becomes increasingly difficult to predict possible price targets. Institutional investors usually have the financial power and political support to manipulate markets for their gains. In recent times, Bitcoin too has seen major market manipulations. However, an interesting thing to note is that, even during such manipulations, technical analysis targets are usually met.\n\nTechnical Analysis has time and again proven to be a useful method to predict future market scenarios and understand current market trends. Moving Averages are on of the most key technical indicators in the cryptocurrency markets. Moving Averages take into consideration past price context to give traders and investors a sense of expected price at a particular instant.\n\nMoving averages can be calculated over various time instances. The most commonly used Moving Averages are 50-day and 200-day Moving Averages. The 50-day Moving Average is also known as the \"Short Term Moving Average\" whereas the 200-day Moving Average is also known as the \"Long Term Moving Average\"\n\nA general concept of seeing crossovers of these 2 moving average lines gives investors a better understanding of current market scenarios. It is generally believed that if the short-term moving average goes crosses and goes below the long-term moving average, then it is a bearish scenario for the markets. This is also called the \"Death Cross\".\n\nIf the long-term moving average goes crosses and goes below the short-term moving average, then it is a bullish scenario for the markets. This bullish scenario is also called the \"Golden Cross\". That being said, Moving average indicators are generally lagging indicators. It takes a while for this indicator to show the true nature of the market. The current market scenario is usually factored into Moving Averages and reflects only a few days later.\n\nIn this paper, the authors formulate a mechanism to predict in current day the future prices of the market and then detect then phase in which the market is headed towards. This advance prediction and detection mechanism will help retail investors understand how the market could move in the future."}, {"title": "II. PREDICTIVE MODELLING AND ADVANCE PHASE DETECTION", "content": ""}, {"title": "A. Data Collection", "content": "The data collection part was the most important aspect of the project. Data for Bitcoin was gathered from an open API where the Open, High, Low, Close and Volume data were available for each day from 1st January 2012. These features were sufficient to build a robust dataset.\n\nThe dataset did not have all the features required like technical indicators. However, the OHLCV data was sufficient to manually calculate the technical indicators required."}, {"title": "B. Data Generation And Technical Indicators", "content": "After collecting the data, the aim was to generate the technical analysis indicators. There are a plethora of technical indicators available to use. The authors in the paper chose Moving Average, RSI, MACD, Momentum, Bollinger Bands and ROC.\n\nEach indicator has its own purpose. RSI talks about whether a particular asset is either overbought or oversold.\n\nMACD is a trend-following momentum indicator that depicts the relationship between two moving averages of an asset's price.\n\nMomentum indicator depicts the direction in which the price of an assets seems to be moving in.\n\nROC is an oscillator that fluctuates above and below the zero line. When the price rises, the ROC moves up and when the price declines, the ROC falls.\n\nThe closing prices of 21 days in the future were also added to each and as a result 21 new columns were created for this purpose."}, {"title": "C. Data Pre-processing and Exploratory Data Analysis", "content": "After generating all necessary data points, the data was required to be processed. Each of these technical indicators did not have some values in the beginning. This is because, these technical indicators required a minimum number of past closing prices to give accurate results. Rows that had no values in certain columns in the beginning of the dataset were discarded.\n\nOnce the data was processed and had all required features, some basic exploratory data analysis was performed. On performing this, a key aspect to address was the high correlation between the features in the dataset. Although each feature had its own importance, the features were all being derived from the existing columns in the dataset.\n\nHowever, this was not a cause of concern as the aim of our model was to predict the right trends. Finding accuracy of the our final model would not give us an accurate overview of the model and its performance. Instead, the authors decided to plot and check the predicted moving average graphs and see how closely related they are to the actual moving average graphs during that duration and whether they followed trends or not."}, {"title": "D. Model Formulation And Data Splitting", "content": "The authors of this model developed a key method to predict prices of the future. To predict prices, one would require all features for that particular day in the future. However, in current day there is no way to get future input values.\n\nAs a result, the authors added the future 21-day closing prices to each day allowing the model to get future context information in present day so that it becomes possible to accurately predict the bitcoin price upto 21 days in the future. The output variables in this case would be the columns with closing prices of 21 days. The input features consisted of OHLCV points, RSI, MACD, Bollinger Bands and ROC."}, {"title": "E. Formulation and Implementation of Multiple Linear Regression", "content": "Multiple linear regression (MLR) is used to determine a mathematical relationship among several random variables by checking how they are related to the response variable. After the relationship is deployed between the independent and dependent variables, the same relationship was used to accurately predict the level of effect it had on the outcome variable. MLR does this by trying to fit a linear line that best approximates all the data points. Below is the equation for the calculation of MLR:\n\n$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_ix_i + e$  (1)\n\nHere y is the dependent variable, x are the exploratory variable, $B_0$ is the y-intercept, $B_i$ are the slope coefficient for the exploratory variable and e is the model error term. The accuracy of the model is decided by the coefficient of determination R\u00b2 which varies between 0 and 1, 0 indicating independent variables that have no effect on the dependent variable and 1 indicating dependent variable that can be accurately predicted by the independent variables.\n\nBut there can be cases where model is found to be over fitted which can result in high value of R2. One of the reasons this can occur is when high multicollinearity is found between the independent variables.\n\nWhile building the MLR model for this project, the authors faced two major challenges. First one was the high correlation between the independent features since the technical indicators are derived from the same OHLCV data. The second challenge was regarding the output as there were 22 dependent variables and 7 independent variables, which is not possible in MLR. Thus, the authors used the MTR(Multiple Target Regression) model wherein multiple target properties can be used to train the model but while predicting the dependent variables using this model resulted in the average of all the target properties rather than the individual values. To circumvent this, the authors went back to MLR and created 22 individual models for each of the 22 individual dependent variables using the same 7 features.\n\nBefore developing the MLR model, dataset was divided into training and testing data, and as this was time series data, training data couldn't be selected randomly, so the latest of the 25% of data was chosen as testing set while remaining as the training set. The authors trained 22 models on training data for all the 22 closing prices(close, close1..close21) using the 7 features. After the model training was complete, prediction of closing prices was done on testing data and, then, the 50 days and 200 days simple moving averages were calculated.\n\nThe authors plotted the actual 50day SMA, 200day SMA and predicted 50day SMA, 200day SMA to check how was the accuracy of the model and if the predicted values were following the same curve as the actual values. This way of checking the accuracy overcame the over fitting and high R\u00b2 value issue."}, {"title": "F. Formulation and Implementation of LSTM", "content": "The model was formulated and built after splitting the data. Since the data was time-dependent, it was necessary to send context information through to future points. Any pattern does not just appear suddenly. The pattern forms gradually, and as a result, it becomes increasingly essential to pass past context to future inputs. Past context information can be passed through various forms of Recurrent Neural Networks (RNNs) the most prominent among which being, Long Short Term Memory (LSTMs) networks and Gated Recurrent Units (GRUs). We decided to use LSTMs based on past experiences.\n\n$f_t = \\sigma(W_f.[h_{t-1}, X_t] + b_f)$  (2)\n\n$i_t = \\sigma(W_i.[h_{t-1}, X_t] + b_i)$ (3)\n\n$c_t = tanh(W_c.[h_{t-1},x_t] + b_c)$ (4)\n\n$C_t = f_t * C_{t-1} + i_t * C_t$ (5)\n\n$O_t = \\sigma(W_o.[h_{t-1},x_t] + b_o)$ (6)\n\n$h_t = O_t * tanh(C_t)$ (7)\n\nThe LSTM built for the purpose of achieving the goal men-tioned in this paper has two hidden layer, one input layer, and one output layer. The input layer composed of 100 neurons, while each of the 2 hidden layers composed of 15 and 31 neurons respectively. The activation function used in the hidden layers was \u201cReLU.\u201d Finally, the output layer just had 22 neurons, which gave a \"ReLU\u201d output since the activation of the output layer was \"ReLU\".\n\nSince \"ReLU\" is an unbounded function, it aligned with the ideaology mentioned in this paper. Using a sigmoid or a tanh activation function would have been appropriate for a classification model as they are bounded between 0 and 1 and -1 and 1 respectively. \"ReLU\u201d does not have an upper bound and aligns perfectly for regression based predictive models. As the aim of the project was to determine a price according to market conditions, the \"ReLU\" activation function was used."}, {"title": "III. RESULTS AND DISCUSSIONS", "content": "After making the price predictions, the predicted values were then used to compute the Moving Averages. The graph below depicts the actual MA of Bitcoin over the 50-day and 200-day time frames.\n\nThe Multiple Linear Regression Model was the first model tested by the models to establish a baseline model. The results produced by the model were not following similar trend as the actual moving averages.\n\nThe moving averages computed from the prices predicted by the MLR Model are as depicted below. The MLR model involved a lot more work mainly because 22 different models were created to predict 22 days' closing prices. This would not be effective and efficient if the model would have to extended to predict market conditions for longer a time frame into the future.\n\nThe MLR model seemed to be taking into consideration a lot of information from way back in the past rather than giving more emphasis to prices in the recent past. This resulted in prices being slightly more divulged from the actual prices.\n\nThe moving averages computed from the predicted prices of the MLR model are as depicted below.\n\nAn interesting thing to note here is that the results shown above were for the LSTM that was trained over 2000 epochs.\n\nOn training it with 1000 epochs, it was noticed that the results were not as accurate as shown above. Due to the unavailability of time and computations resources, the model could not be trained for beyond 2000 epochs.\n\nThe predicted prices using the LSTM were then used to compute the moving averages and the results achieved are as depicted below.\n\nHowever, if the model is trained further the results that the model produces could be more accurate. Finding the point up to which the model can be trained is a key aspect and acts as a hyper parameter. If the model is trained for more epochs than required, the problem of overfitting could arise.\n\nThe MLR model was slightly inaccurate as compared to the LSTM model to predict prices. This is most likely because of the fact that the LSTM model was able to establish more closely the combinatorial relationship between various features and mapped it accurately to a price. LSTMs are known to perform well over time-series data mainly because of its architecture. Not all information from the past carries forward to the future and only limited information context from past is sent through. Any unimportant information is dropped by the Forget Gate in the LSTM. However, in MLR the model seems to taking into consideration a lot of information from the past.\n\nThis is not necessarily needed as the price of Bitcoin would depend more on traits and characteristics of the market in the recent past rather than the longer past.\n\nThe R2 score, also known as the coefficient of determination is the proportion of variance in the dependent variable that can be predicted from the independent variables. In the project, the authors chose not to use R2 as their accuracy indicator because most of the technical indicators are derived from OHLC price points and, therefore, were highly correlated. Instead, to verify accuracy, the original and predicted Moving Averages graphs were compared."}, {"title": "IV. CONCLUSION", "content": "Advance detection of market phases in continuous-time finan-cial systems, if attained successfully, will be of great value to investors and traders, and in particular to critical financial processes. Machine Learning techniques, more precisely the \"learning-functionality-from-data\" methodology of supervised learning, is the most appropriate mechanisms for attaining the same. Previous works have shown that conventional feed-forward Artificial Neural Networks (ANNs) have been able to achieve a fair degree of success in this direction. However, both these techniques work on taking parameter inputs at a single time step of a running process.\n\nHere, LSTMs have been used to extract functionality from time-sequences, with the hypothesis and expectation that more intricate functional relationships between combinatorial pat-terns can be extracted, leading to achieving greater success in the above objective. This hypothesis has been upheld, as shown in the previous sections."}]}