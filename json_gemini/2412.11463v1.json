{"title": "FedCAR: Cross-client Adaptive Re-weighting for Generative Models in Federated Learning", "authors": ["Minjun Kim", "Minjee Kim", "Jinhoon Jeong"], "abstract": "Generative models trained on multi-institutional datasets can provide an enriched understanding through diverse data distributions. However, training the models on medical images is often challenging due to hospitals' reluctance to share data for privacy reasons. Federated learning (FL) has emerged as a privacy-preserving solution for training distributed datasets across data centers by aggregating model weights from multiple clients instead of sharing raw data. Previous research has explored the adaptation of FL to generative models, yet effective aggregation algorithms specifically tailored for generative models remain unexplored. We hereby propose a novel algorithm aimed at improving the performance of generative models within FL. Our approach adaptively re-weights the contribution of each client, resulting in well-trained shared parameters. In each round, the server side measures the distribution distance between fake images generated by clients instead of directly comparing the Fr\u00e9chet Inception Distance per client, thereby enhancing efficiency of the learning. Experimental results on three public chest X-ray datasets show superior performance in medical image generation, outperforming both centralized learning and conventional FL algorithms.", "sections": [{"title": "1 Introduction", "content": "Federated Learning (FL) is a machine learning framework designed to train models directly on clients' devices without data migration. In FL, a central server aggregates model weights from clients into a single global model, which is then shared back with the clients. This iterative process allows for collaborative model training while ensuring data privacy, as data remains on the local clients. The decentralized nature of FL offers a significant advantage in contexts where data security is crucial, such as in healthcare institutions, leading to its widespread use in medical image analysis [4, 8, 20, 21, 24]. Recently, generative adversarial network (GAN) [5] in FL environment has drawn attention for their ability to handle a wide range of applications such as data anonymization [15],\ncross-domain adaptations [14] and other unsupervised learning tasks [2,10], while preserving privacy.\nHowever, there are several obstacles in adapting FL to GAN. First, the im-plementation process can be tricky since it involves transmitting two distinct networks (the discriminator and generator) between the server and clients. Moreover, there are small reference code to implementation of federated GAN since previous researches about it is fairly limited. Second, previous studies [11,18,23] argued that non-independent and identically distributed data(non-i.i.d.) situations, which are commonly found in medical datasets, can cause instablity in convergence of training GAN as updates from different clients may be inconsistent. Thus, to address these obtacles, it is required to develop an advanced aggregation algorithm to embody federated GAN and train it effectively.\nTo overcome these challenges, we propose a novel algorithm solely designed for generative models within FL frameworks. Our method includes adaptive re-weighting the contributions of client models based on quantitative evaluation of distribution discrepancies across clients. We utilized the Fr\u00e9chet Inception Distance (FID) score to evaluate the distribution distances in feature representations across clients' data, directly addressing the heterogeneity in data distribution. We conducted experiments to show that this approach can significantly improve performance of generative model in non-i.i.d. settings. In addition, while conventional aggregation algorithms may tend to excessively overlook clients with smaller datasets, our approach avoids such issues by solely relying on clients' generative capabilities.\nPrevious efforts to adapt FL to GAN have encountered significant hurdles, including poor performance [6] and limited applications to low-quality datasets [22]. Recent studies have successfully demonstrated that FL-adapted GAN can achieve stable convergence by training the generator and discriminator in syn-chronization [3, 16]. While the FedAvg [12] aggregation method has been popular and effective in FL and chosen in FedGAN [16], there's a gap in exploring alter-native aggregation methods. FedOpt [17], which leverages adaptive optimization, emerges as a potential advanced aggregation method option, but never been in-tensively studied. Building upon this foundation, our study aims to develop an effective aggregation algorithm for FL-adapted GAN by introducing a dynamic re-weighting of client contributions.\nOur study have three contributions through this study. First, we developed a novel aggregation algorithm designed for generative models via cross-client eval-uation and adaptive re-weighting in server-side, showing significant enhancement in chest x-ray image generation. Second, we show that generative models in FL can outperform centralized learning in non-i.i.d. settings. Finally, we release the source code for both the FL-integrated GAN and our adaptive re-weighting al-gorithm for FL (FedCAR), which has not been previously released."}, {"title": "2 Method", "content": "In this study, we consider a real-world FL adaption for generative models, especially GAN, across N clients that have own local dataset \\(D_i\\) where \\(i \\in \\{1, 2, ..., N\\}\\). We designate \\(\\Theta\\) to represent a GAN network that consists of the discriminator \\(\\theta_a\\) and the generator \\(\\theta_g\\). The essence of FL is collaboratively training a global model \\(\\Theta\\) by combining the model weights \\(\\theta_i\\) from N clients, where \\(\\theta_c\\) represents the collective set of client models \\(\\theta_c := \\{\\theta_i\\}_{i=1}^N\\), in every training round r.\nAs the references for our FL-related experiments, we train a centralized learning with whole datasets and three localized learning with individual dataset.\nFedAvg in GAN Although FedAvg was not specifically designed for GAN, its intuitive and straightforward mechanism posed no implementation challenges for federated GAN. We simply followed its general process except aggregate twice for \\(\\theta_a\\) and \\(\\theta_g\\) respectively. Therefore, the global weight can be described as below:\n\\[\\Theta = \\frac{\\sum_{i=1}^N d_i\\theta_i}{\\sum_{j=1}^N d_j}\\tag{1}\\]\nwhere \\(d_i\\) denotes the number of dataset belongs to i-th client.\nFedOpt in GAN FedOpt is a framework designed to improve FL by introducing optimization methodologies. To our knowledge, implementation of FedOpt to the generative model is not explored. Given that FedOpt employs adaptive optimization techniques at both the server and client level, it is anticipated"}, {"title": "2.2 Our Method: FedCAR", "content": "Presumably, during the training, several clients learned better than the others in every round. At the aggregation stage of each round, we intended to give more attention to the clients showed higher performance. In our method, the server is responsible for evaluation of each client model's performance. By utilizing given generators from the clients, the server generates x number of fake images and calculates FID score between them. We defined total FID of n-th client \\(FID_n\\) as,\n\\[FID_n = \\sum_{i=1}^{n-1} FID_{i,n} + \\sum_{j=1}^{N-n} FID_{n,n+j}\\tag{2}\\]\nwhere N is total number of clients and \\(FID_{C1,C2}\\) denotes FID score between fake dataset generated from local generator \\(c_1\\) and \\(c_2\\). Then we calculated parameter\n\\[\\alpha_n = \\frac{1}{FID_n}\\tag{3}\\]\n\\[\\bar{\\alpha_n} = \\frac{\\alpha_n}{\\sum_{i=1}^N \\alpha_i}\\tag{4}\\]\n\\(\\bar{\\alpha}\\) is multiplied to each local weight which leads to pay more attention to better clients.\n\\[\\Theta_{r+1} = \\sum_{i=1}^N \\bar{\\alpha_i}\\theta_{g_i} + F(\\theta_a)\\tag{5}\\]\nWe performed above process at every round for dynamic and adaptive re-weighting. In Algorithm 2, we described the detailed process with pseudo code."}, {"title": "3 Experiments", "content": "Datasets Our study utilizes three public chest X-ray datasets: Chest X-Ray8 (NIH) [19], CheXpert [7], and VinDr-CXR [13]. We exclusively focus on normal images to clarify the comparison between aggregation algorithms in FL scenarios with non-i.i.d. datasets. All images were resized to 512 \u00d7 512 pixels and clipped the top 1% percentile of pixel intensities to effectively reduced artifacts like L/R"}, {"title": "3.2 Result", "content": "Mild Non-i.i.d. Scenario Let us assume that three institutions aim to collaboratively develop a generative model while ensuring no data transfer between them, to keep the data security. Each institution contributes a dataset containing 10,000 normal chest X-ray images, sourced from the NIH, CheXpert, and the VinDr datasets, respectively. Although the datasets are of comparable size, they exhibit unique characteristics attributable to their diverse origins. This scenario does not align precisely with the assumption of i.i.d. data, nor does it present extreme deviations from i.i.d. assumptions. Instead, it represents a scenario of mild non-i.i.d. characteristics, offering a realistic reflection of the complexities encountered in practical applications.\nIn this scenario, since re-weighting is performed cross-client adaptively in each round(fig 2), our method preserved the characteristics of the client. As a result, FedCAR outperformed every other methods including centralized learning. In detail, FedCAR shows lower FID by 0.97, 0.74, 0.55 than the NIH, CheXpert, Vin dataset, respectively. It also show lower FID by 1.01 compare to the cen-tralized learning. Table 1 summarized the detailed result.\nThroughout the training process, \\(\\alpha_n\\) of clients exhibited minor fluctuations but generally remained around 0.33 (See Supplement Table 1). This suggests that our model achieved efficient learning by maintaining a balanced learning across all clients while incorporating slight variations per round.\nSevere Non-i.i.d. Scenario We also explored more severe non-i.i.d. scenario that one of the institution has small amount of data compare to others. In this scenario, the institution would not dare to train generative model on their own since generally generative models consumes large amount of data. With FL, however, the institution may have chance to train generative models by other data-abundant institutions' assistance. Thus, we reduced number of CheXpert client from 10,000 to 1,000 images while other clients remain unchanged. As a result, our method achieved the smallest FID score in average compare to other methods. FedCAR shows lower FID by 0.43, 2.10 than the NIH, CheXpert dataset, respectively. It also recorded lower FID by 0.23 compare to the central-ized learning.\nIn addition, similar to the mild non-i.i.d. scenario, \\(\\alpha_n\\) hold 0.33 during training rounds (See fig 2 and Supplement Table 1). Naturally, there is slight decrease in \\(\\alpha_{CheXpert}\\) compare to previous scenario, due to deteriorated performance of the data-deficient client."}, {"title": "4 Discussion", "content": "Our algorithm, FedCAR, outperforms other aggregation algorithms in chest x-ray image generation regardless of discrepancies of data distributions among clients. While focusing on GAN in this study, the concept that utilization of server-side evaluation of the generator weight at each client can be broadly adapted to any other generative models in FL environments.\nWe observed that the averaged values of \\(\\alpha_n\\) over training rounds is similar to"}, {"title": "5 Conclusion", "content": "In our study, we discuss a novel FL aggregation algorithm designed for generative models, specifically addressing the challenges of training on multi-institutional medical image datasets while preserving privacy. By adaptively re-weighting clients' contributions to global model based on their grade in generating fake images, we enhance model training efficiency, image quality, and diversity. Experimental validation on public chest X-ray datasets confirms our method's su-periority over both centralized learning and traditional FL approaches, show-casing its potential to advance medical image generation in a privacy-conscious manner."}]}