{"title": "From Cognition to Precognition: A Future-Aware Framework for Social Navigation", "authors": ["Zeying Gong", "Tianshuai Hu", "Ronghe Qiu", "Junwei Liang"], "abstract": "To navigate safely and efficiently in crowded\nspaces, robots should not only perceive the current state of the\nenvironment but also anticipate future human movements. In\nthis paper, we propose a reinforcement learning architecture,\nnamely Falcon, to tackle socially-aware navigation by explic-\nitly predicting human trajectories and penalizing actions that\nblock future human paths. To facilitate realistic evaluation,\nwe introduce a novel SocialNav benchmark containing two\nnew datasets, Social-HM3D and Social-MP3D. This benchmark\noffers large-scale photo-realistic indoor scenes populated with\na reasonable amount of human agents based on scene area\nsize, incorporating natural human movements and trajectory\npatterns. We conduct a detailed experimental analysis with\nthe state-of-the-art learning-based method and two classic\nrule-based path-planning algorithms on the new benchmark.\nThe results demonstrate the importance of future prediction\nand our method achieves the best task success rate of 55%\nwhile maintaining about 90% personal space compliance. We\nwill release our code and datasets. Videos of demonstrations\ncan be viewed at https://zeying-gong.github.io/\nprojects/falcon/.", "sections": [{"title": "I. INTRODUCTION", "content": "Social navigation (SocialNav) refers to autonomous robot\nadhereing to social norms and social etiquette while navigat-\ning environments shared with humans [1]. This task poses\nnew challenges to visual navigation, as modular approaches\nrelying on pre-built maps struggle in dynamic, human-\npopulated environments where collision avoidance is crucial.\nPrevious works typically train navigation agents using\nreinforcement learning (RL) [2], [3], [4]. However, RL-based\nSocialNav often suffers from short-sighted obstacle avoid-\nance, limiting efficiency around humans [5], [6]. A common\nsolution to this problem is hierarchical methods, which\ncombine global planners with low-level RL policies [7].\nHowever, these approaches rely on prior knowledge of the\nenvironment for planning [8], making them unsuitable for\nrealistic, dynamic scenarios. Consider the example in Fig. 1,\nwhere a robot navigates to a goal located at the intersection\nof two nearby humans' future paths. In such cases, traditional\nRL approaches may struggle to avoid humans due to limited\nforesight or reliance on global information. In contrast,\nour approach addresses these issues by explicitly predicting\nhuman trajectories that enable social compliance and long-\nterm dynamic collision avoidance.\nHuman trajectory forecasting has been shown to improve\ncollision avoidance and navigation in dynamic environ-"}, {"title": "II. RELATED WORKS", "content": "A. Social Navigation.\nIn this paper, we focus on the SocialNav task [7], [15],\nwhich was first introduced in the iGibson SocialNav Chal-\nlenge [19], building on the PointGoal Navigation (PointNav)\nby adding moving humans. Humans in the challenge are\nstatic figures with unrealistic movements. In contrast, our\nwork utilizes the recent Habitat 3.0 simulator [20] to leverage\nrealistic human movements and animations.\nSocialNav has been widely studied in robotics, computer\nvision, and social behavior analysis [21], [22]. In collision-\nfree multi-agent navigation [23], [24], [25] and dynamic\nenvironments [26], research has advanced to address chal-\nlenges posed by the presence of humans [27], [28], [29],\n[30], [31]. Other approaches [28], [31] model human-agent\ninteractions through spatio-temporal graphs [30] to capture\nagent dynamics over time. Recent studies have also focused\non egocentric SocialNav in photo-realistic or real-world\nscenarios [32], [33], [34]. Differing from these approaches,\nour method introduces explicit trajectory prediction within\nauxiliary tasks to train an RL-based agent for SocialNav.\nB. Auxiliary tasks in Navigation.\nAuxiliary tasks can enhance sample efficiency and\nimprove the performance of primary navigation tasks.\nMirowski [35] introduced self-supervised auxiliary tasks to\nhelp agents navigate mazes more efficiently. Since then,\na wide range of general auxiliary tasks have been de-\nveloped [36], [37], including tasks focused on predicting\nenvironmental properties or forecasting the agent's own\nstates [38], [36], [39]. These tasks enable agents to better\nunderstand and interact within static environment. Recently,\nauxiliary tasks using privileged information, such as dis-\ntances or angles between the agent and humans, have been\nintroduced for SocialNav [8]. Our auxiliary tasks not only\nperceive humans' current positions, but also focus on pre-\ndicting their future trajectories, facilitating efficient learning\nof human movement patterns and reducing collisions risks."}, {"title": "C. Human Trajectory Prediction.", "content": "Human trajectory prediction is vital for enabling safe\nand intelligent behavior in autonomous systems [40], [41].\nTraditional approaches often rely on physical models, such\nas the Social Force model [28], which uses attractive and\nrepulsive forces to simulate social behaviors and collision\navoidance. Broadly, these methods fall into three categories.\nOne approach is based on physics, where explicit dynamical\nmodels are derived from Newton's laws of motion to predict\ntrajectories [42], [43], [44]. Another set of methods focuses\non learning motion patterns from observed historical trajecto-\nries [45], [46], [47]. Moreover, planning-based methods aim\nto reason about the motion intent of rational agents, pre-\ndicting trajectories by understanding agents' goals and their\ndecision-making processes [48], [49], [50]. Our approach\nleverages these insights to develop a method that not only\npredicts human trajectories but also integrates socially-aware\ninformation into the agent's navigation policy, ensuring safe\nand efficient navigation in dynamic scenes."}, {"title": "III. METHODOLOGY", "content": "A. Problem Formulation\nConsider a social navigation task where a robot a navigates\nin an environment populated by N active humans, i \u2208\n{1,..., N}. Starting from an initial configuration $q_a \\in Q$,\nthe robot aims to continuously select actions to generate a\npath $T_a$ toward its goal configuration $q_g \\in Q$ while avoiding\ncollision with static obstacles and dynamic humans. The\noverall objective is formulated as follows:\n$T_a = \\underset{T \\in T}{arg \\underset{}{min}} (c_a (T) + \\alpha c_a(\\tau, \\tau_{1:N}))$\ns.t. $A_a(T_a) & C_{obs}$, $A_a(T_a) \\cap A_i(T_i) = \\emptyset$,\n$T_a(0) = q_a, T_a(T) = q_g$\nwhere, $c_a$ is the path cost guiding the robot to its goal; $c_a$ is\nthe cost term accounts for social norms; $A(\\tau)$ represents the\nvolume occupied along trajectory T; $C_{obs}$ represents static\nobstacles; T is the episode end time; and $A_a$ is a weight\nfactor. The constraints make sure the robot does not collide\nwith static obstacles and humans before reaching its goal.\nFig. 2 is an overview of Falcon. The Main Policy Net-\nwork takes a depth image and a point goal at each timestep\nas inputs and directly outputs the robot's actions for the next\nstep. It is trained using PointNav rewards along with our\nproposed Social Cognition Penalty (SCP). In addition, the\nnetwork is accompanied by the Spatial-Temporal Precog-\nnition Module that facilitates several auxiliary tasks during\ntraining. We detail each module in the subsequent sections.\nB. Main Policy Network\nThe main policy network has two key components: the\nstate encoders that extract visual and temporal features from\nobservations, and a social cognition penalty that encour-\nages social compliance. At each timestep, the point goal is\ntransformed by a linear encoder whereas the depth image\nis processed by a ResNet-50 [51] visual encoder. A 2-layer\nLSTM [52] extracts the temporal features, which are then"}, {"title": "C. Spatial-Temporal Precognition Module", "content": "This module utilizes three socially-aware auxiliary tasks\nto boost the robot's grasp of spatial-temporal dynamics. As\nshown in Fig. 2, similar networks with an LSTM encoder\nand a self-attention block are used for each auxiliary task.\nWe discuss each of these tasks as follows.\nHuman Count Estimation. This task aims to estimate the\noverall number of humans and the output is a discrete value"}, {"title": "IV. EXPERIMENTS", "content": "In this section, we first introduce the proposed benchmark\nand its two datasets, followed by the experiment setup and\nevaluation metrics. Next, we show the results of Falcon\nagainst prior methods. Finally, we conduct ablation analy-\nsis of two key components, Social Cognition Penalty and\nSpatial-Temporal Precognition Module."}]}