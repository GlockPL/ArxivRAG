{"title": "Learning Generalizable Prompt for CLIP with Class Similarity Knowledge", "authors": ["Sehun Jung", "Hyang-won Lee"], "abstract": "In vision-language models (VLMs), prompt tuning has shown its effectiveness in adapting models to downstream tasks. However, learned prompts struggle to generalize to unseen classes, as they tend to overfit to the classes that are targeted during prompt tuning. Examining failure cases, we observed that learned prompts disrupt the semantics of unseen classes, generating text embeddings with incorrect semantic relationships among classes. To address this, we propose Similarity Alignment Regularization (SAR), which regularizes learnable prompts to preserve the semantic relationships among classes captured by hand-crafted prompts. Specifically, we first obtain novel classes related to base classes using ChatGPT-40 and utilize them as potential unseen classes during prompt tuning. Then, by targeting both base and novel classes, SAR aligns the similarity relationships among text embeddings generated by learnable prompts with the similarity relationships from hand-crafted prompts. Extensive experiments applying SAR to existing prompt tuning methods demonstrate its effectiveness in improving generalization to unseen classes.", "sections": [{"title": "1. Introduction", "content": "Recently, pre-trained foundation models that can be utilized for various downstream tasks have emerged across diverse fields. In the vision-language domain, CLIP [30] is recognized as one of the representative models. Trained on 400 million image-text pairs from the web, CLIP is able to capture rich semantic relationships between visual and textual information. This capability enables CLIP to achieve competitive zero-shot evaluation performance across a wide range of downstream tasks. One of the key findings in [30] is that using task-specific prompts can improve zero-shot performance by providing the model with additional context. For example, in EuroSAT dataset, which features satellite images depicting various types of land cover, using the prompt \"a satellite photo of a\" helps the model better understand the task, resulting in a notable enhancement in classification accuracy.\nInstead of manually designing prompts, CoOp [43] proposes a prompt tuning approach that learns task-specific prompts. In this method, learnable vectors in the word embedding space are trained using image-text pairs from target tasks and serve as prompts. This approach achieves significant performance improvements over using hand-crafted prompts, emphasizing the importance of prompt designing. However, learned prompts often fail to generalize to unseen classes that were not targeted during prompt tuning, resulting in substantial performance degradation. Extensive research has focused on learning generalizable prompts by exploring both architectural improvements [18, 23, 41, 42] and regularization methods [7, 10, 39, 44]. A widely adopted regularization method minimizes the distance between the text embeddings generated by learnable prompts and those generated by hand-crafted prompts during prompt tuning [10, 19, 32, 39, 40]. This approach improves the generalization ability of learnable prompts by preserving the general knowledge captured by hand-crafted prompts. However, a significant limitation of this method lies in its focus on individual classes in isolation, without considering the relationships among classes. As a result, inter-class consistency is not explicitly accounted for during prompt tuning, which indicates that there is room for further improvement in generalization.\nIn this work, we first investigate how prompts learned from base classes fail to generalize to unseen classes in terms of semantic disruptions. We observe that when the text embeddings generated by learned prompts form incorrect semantic relationships with other classes, they act as low-quality classifiers, leading to poor generalization. In contrast, hand-crafted prompts capture meaningful semantic relationships among classes due to their strong generalization ability. Motivated by these findings, we propose Similarity Alignment Regularization (SAR), a method for regularizing learnable prompts to preserve the semantic relationships captured by hand-crafted prompts. Specifically, we first obtain novel classes semantically aligned with the base classes by utilizing ChatGPT-40. For both base and novel classes, SAR aligns the similarity relationships among text embeddings generated by learned prompts with"}, {"title": "2. Related Work", "content": "Pre-trained Vision-Language Models. Large-scale pre-training is essential for VLMs to develop a comprehensive understanding of the relationships between images and text. The effectiveness of pre-trained VLMs on downstream tasks largely depends on the design of pre-training tasks, which define what the model learns from the data [12]. Among these tasks, image-text matching (ITM) and masked language modeling (MLM) are widely adopted due to their complementary roles [3, 20, 24, 25]. ITM enables models to focus on the global semantics of images and text, facilitating coarse-grained alignments. In contrast, MLM encourages models to extract information from objects within images to predict masked language tokens, thereby promoting fine-grained alignments. Meanwhile, transformers [36] play a key role in VLMs by serving as powerful contextualizers, enabling VLMs to model complex relationships between modalities. Among VLMs, CLIP [30] employs a dual-encoder architecture trained with contrastive learning.\nDespite being trained on noisy web data, it demonstrates effectiveness on various downstream tasks, including complex tasks such as monocular depth estimation [2], visual question answering [33], and instance segmentation [11].\nFine-tuning VLMs for Downstream Tasks. Fine-tuning all parameters in pre-trained VLMs on limited data of downstream tasks is prone to losing the rich representations learned by the model and overfitting. To address this issue, parameter-efficient fine-tuning methods have emerged as an alternative to conventional fine-tuning approaches. One such method, CLIP-Adapter [15], trains small adapters that transform the output embeddings of CLIP encoder into task-useful features. Another approach is prompt tuning, which focuses on tailoring the model's input. In CoOp [43], a set of learnable vectors is added to the input embeddings to guide the encoder to generate task-useful embeddings. Co-CoOp [42] conditioned the prompts on image features, generating image-adaptive prompts that improve generalization to unseen classes. MaPLe [18] and PromptSRC [19] extend adaptability to downstream tasks by adding prompts to both text and image inputs. In contrast to the above approaches, some fine-tuning methods focus on updating only specific parameters, such as bias and normalization terms [33].\nRegularization for Prompt Tuning. Various regularization techniques have been explored to learn generalizable prompts. ProGrad [44] ensures that the gradient for prompt tuning does not conflict with the gradient used to preserve the general knowledge of CLIP. Specifically, if the angle between the two gradient vectors is obtuse, the gradient for prompt tuning is projected to be orthogonal to the other gradient, and is used for the update. KgCoOp [39] minimizes the distance between text embeddings generated by learnable prompts and those generated by hand-crafted prompts, preserving the general knowledge captured by hand-crafted prompts. LASP [5] introduces a text-to-text cross-entropy loss to ensure that text embeddings generated by learnable prompts are correctly classified as those generated by hand-crafted prompts for the same class. DAPT [7] enforces a uniform distribution of text embeddings on a hypersphere to minimize overlap while encouraging image embeddings of the same class to be positioned closer together, to achieve better alignment. TPR [6] maximize Pearson correlation coefficient computed between the pairwise cosine similarity matrices of the original CLIP text embeddings and the learned text embeddings, to preserve the class topology. In this process, they utilize the textual descriptions of both base and new classes in the dataset. LOBG [10] preserves the structural topology of image embeddings captured by hand-crafted prompts, which is achieved by maintaining local angular relationships among image embeddings. Unlike these methods, our method SAR utilize the similarity distribution among text embeddings, to effectively capture the relational similarities among classes."}, {"title": "3. Prompt Tuning with SAR", "content": "In this section, we present the implementation of SAR and its integration within the prompt tuning framework."}, {"title": "3.1. Preliminaries", "content": "Contrastive Language-Image Pre-training (CLIP) [30]. CLIP is a vision-language model pre-trained on 400 million image-text pairs, designed to align semantic relationships between image and text modalities. It consists of an image encoder $\\theta(\\cdot)$ and a text encoder $\\phi(\\cdot)$ that map their respective inputs into a shared embedding space. CLIP is trained using contrastive learning, where embeddings of matched image-text pairs are pulled closer together, while those of unmatched pairs are pushed apart. We can perform zero-shot image classification using CLIP by comparing the matching score, which is cosine similarity between the image embedding and the text embedding. Using appropriate prompts can significantly enhance CLIP's classification performance. Finding task-optimized prompts is referred to as prompt engineering, which often relies on a trial-and-error process.\nContext Optimization. CoOp [43] proposes a framework that trains prompts via a classification task using image-text pairs of target tasks. In CoOp, P trainable vectors $[V_1, V_2, ..., V_p]$ serve as prompts. These vectors are added to $c_i$, the word embedding(s) of the i-th class name $w_i$, and"}, {"title": "3.2. Semantic Disruption by Learned Prompts", "content": "Now we analyze how the semantically misaligned text embeddings, generated by learned prompts, lead to poor generalization.\nComputing Semantic Similarities among Classes. We begin by describing how to compute a similarity distribution matrix, which shows the semantic relationships among text embeddings. Let {$g_i$}$_{i=1}^{N}$ denote a set of text embeddings"}, {"title": "3.3. Similarity Alignment Regularization", "content": "To prevent semantic disruptions caused by learned prompts and improve generalization, we propose Similarity Alignment Regularization (SAR). Figure 2 illustrates the operation of SAR in prompt learning.\nPrompt Learning with Novel Classes. We use ChatGPT-4o to generate novel classes semantically aligned with the base classes, utilizing them as potential unseen classes during prompt tuning. Specifically, we provide ChatGPT-4o with a list of the base classes and instruct it to generate semantically aligned novel classes. The prompt given to ChatGPT-40 is provided in Supp. Material. A. To obtain more robust and representative embeddings for each class, we use ensembled text embeddings from multiple hand-crafted prompts. Let T be the number of hand-crafted prompts used for prompt ensembling. For j-th class, the ensembled text embedding is computed as $g_j = \\frac{1}{T}\\sum_{i=1}^{T} g^i_j$, where $g^i_j$ is the text embedding of j-th class generated by the i-th prompt. The hand-crafted prompts used for ensembling are listed in Supp. Material. B. Let $G_{hand} = \\{g_j\\}_{j=1}^{M}$ denote the set of text embeddings for both base and novel classes, generated by the hand-crafted prompts. In contrast,"}, {"title": "4. Experiments", "content": "We evaluate the effectiveness of SAR in 1) base-to-new generalization and 2) domain generalization. To demonstrate"}, {"title": "4.1. Ablation Study", "content": "Stepwise Analysis of SAR's Effectiveness. To analyze the contribution of each component in SAR, we conduct a base-to-new generalization experiment in the 16-shot setting, using CoOp as the baseline. The results, averaged across 11 datasets, are presented in Table 1. First, CoOp exhibits a significant gap between base and new accuracies, revealing its limited ability to generalize to unseen classes. By intro-"}, {"title": "4.2. Base-to-New Generalization", "content": "In the Base-to-New generalization task, we evaluate the performance of models with and without SAR in 16-shot setting across 11 datasets. The classes in each dataset are divided into two groups, where prompts trained on one group (base classes) are used to evaluate performance on the other group (new classes). As summarized in Table 3, SAR consistently improves the new class accuracy and the harmonic mean (H) across all baselines. For CoOp and MaPLe, SAR also delivers significant improvements in base class accuracy, while showing no critical base-new accuracy trade-offs for other baselines. Notably, SAR yields the largest improvements for CoOp, while also bringing meaningful"}, {"title": "4.3. Effectiveness with Alternative Word Sources", "content": "We investigate whether SAR remains effective when using novel classes extracted from sources other than LLMs. To this end, we train SAR with novel classes from (1) 200 randomly sampled nouns from WordNet [27], a large lexical database, and (2) new class names from the dataset. The base-to-new generalization results for CoOp and CoPrompt are presented in Figure 5. A key observation is that new accuracy improves significantly even when randomly sampled words are used as novel classes. This suggests that SAR is robust to the choice of novel classes and consistently enhances generalization to unseen classes. Notably, using words generated by ChatGPT-40 as novel classes leads to even greater performance improvements. This can be attributed to the fact that these words are more semantically aligned with the new classes in the dataset than randomly sampled words, making them more effective at capturing the semantics of new classes (Examples of generated words are listed in Supp. Material C). However, using the actual new class names from the dataset as novel classes (SAR w/ 'Oracle') does not yield the highest performance improvements. This is primarily due to the small number of them (on average, less than 100), which reduces the semantic diversity available for SAR and ultimately makes it less effective to capture the fine-grained semantics of them."}, {"title": "4.4. Effectiveness in Few Shot Setting", "content": "To validate the effectiveness of SAR in a few-shot setting, we conduct base-to-new generalization experiments under 4-shot setting for CoOp, TCP, and CoPrompt. In the case of CoOp, the models show a stronger tendency to increase SAR loss during prompt tuning compared to the 16-shot setting. This may be due to the model attempting to capture spurious correlations in the limited training data, leading to overfitting. To address this issue, we set the regularization weight to 1.0 for CoOp across all datasets. For TCP and CoPrompt, the same regularization weights as those used in the 16-shot setting are applied to each dataset. The performance averaged across 11 datasets is summarized in Table 4, demonstrating that SAR remains consistently effective even in the few-shot setting."}, {"title": "4.5. Domain Generalization", "content": "Domain generalization evaluates how well a model can generalize to domains with data distributions that differ from its training domain. Following convention, we use ImageNet as the source domain and evaluate the performance"}, {"title": "5. Conclusion and Limitation", "content": "In this paper, we found that prompts trained for base classes can disrupt the semantics of unseen classes, generating text embeddings with incorrect semantic relationships among classes. To address this issue, we proposed SAR, a method that regularizes learnable prompts to preserve the similarity relationships among classes generated by hand-crafted prompts. Our method utilizes ChatGPT-40 to generate novel classes that are semantically aligned with the base classes and uses them as potential unseen classes during prompt tuning. Extensive experiments across five baselines and 11 datasets demonstrate the effectiveness of SAR in improving generalization to unseen classes. Despite its effectiveness, SAR incurs additional memory and training time to compute text embeddings for novel classes. As future work, we aim to reduce the resource cost of SAR while exploring performance enhancement strategies that do not rely on hand-crafted prompts as supervison."}]}