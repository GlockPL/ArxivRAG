{"title": "What Would Happen Next? Predicting Consequences from An Event Causality Graph", "authors": ["Chuanhong Zhan", "Wei Xiang", "Chao Liang", "Bang Wang"], "abstract": "Existing script event prediction task forcasts\nthe subsequent event based on an event script\nchain. However, the evolution of historical\nevents are more complicated in real world sce-\nnarios and the limited information provided\nby the event script chain also make it diffi-\ncult to accurately predict subsequent events.\nThis paper introduces a Causality Graph Event\nPrediction(CGEP) task that forecasting con-\nsequential event based on an Event Causal-\nity Graph (ECG). We propose a Semantic\nEnhanced Distance-sensitive Graph Prompt\nLearning (SeDGPL) Model for the CGEP\ntask. In SeDGPL, (1) we design a Distance-\nsensitive Graph Linearization (DsGL) module\nto reformulate the ECG into a graph prompt\ntemplate as the input of a PLM; (2) propose\nan Event-Enriched Causality Encoding (EeCE)\nmodule to integrate both event contextual se-\nmantic and graph schema information; (3) pro-\npose a Semantic Contrast Event Prediction\n(ScEP) module to enhance the event represen-\ntation among numerous candidate events and\npredict consequential event following prompt\nlearning paradigm. Experiment results validate\nour argument our proposed SeDGPL model\noutperforms the advanced competitors for the\nCGEP task.", "sections": [{"title": "1 Introduction", "content": "Event prediction aims to forecast the consequential\nevent that are most likely to happen next, based\non historical events and their relationships. It has\nsignificant applications in many scenarios and in-\ndustries, such as dialogue systems (Chen et al.,\n2017), discourse understanding (Lee and Gold-\nwasser, 2019), and story generation (Chaturvedi\net al., 2017). Existing script event prediction\ntask (Wang et al., 2023) predicts the subsequent\nevent given a sequence of events, named event\nscript chain. However, we argue that the evolu-\ntion of historical events are more complicated than\na script event chain in real world scenarios. Be-\nsides, the limited information provided by event\nchains also make it difficult to accurately predict\nsubsequent events.\nMotivated from such considerations, this pa-\nper introduces a Causality Graph Event Predic-\ntion(CGEP) task that forecasting consequential\nevent based on an Event Causality Graph (ECG).\nAs illustrated in Fig. 1, the CGEP task is to select\nthe most likely consequential event from candidate\nset based on an input ECG and an selected anchor\nevent. Instead of using event script chain for sub-\nsequent event prediction, we model the connection\nbetween events by an ECG, which can better reveal\nthe evolution of historical events. Besides, an ECG\nmay have more than one consequential event that\nare likely to happen next. As such, we predict a\nconsequential event for each tail node event (i.e.\nthe anchor event) in an ECG, to achieve a more\ncomprehensive understanding of events' evolution.\nTraditional event prediction methods either en-"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Script Event Prediction", "content": "Script Event Prediction focuses on predicting fu-\nture events based on a narrative event chain with\nshared entities. Previous studies (Zhou et al., 2022;\nWang et al., 2021; Huang et al., 2021) employ\nword2vec to encode the events, and predict sub-\nsequent events based on the similarity between can-\ndidate events and script events. With respect to\ntemporal ordering, Pichotta and Mooney (2016);\nWang et al. (2017) employ Long Short-Term Mem-\nory (LSTM) to model the temporal dependencies\nbetween events. Contemporary event modeling\nmethods utilize the Pre-trained Language Models,\ne.g. BERT (Devlin et al., 2018) and ROBERTa (Liu\net al., 2019). However, these models lack discourse-\nawareness as they are trained using Masked Lan-\nguage Modeling, which does not effectively capture\nthe causal and temporal relations between multi-\nhop events. To address this problem, some re-\nsearch (Li et al., 2018; Zheng et al., 2020) also\nexplore specific event graphs as external knowledge\nbase to assist event prediction. For example, Wang\net al. (2022b) proposes a novel Retrieval-Enhanced\nTemporal Event forecasting framework, which dy-\nnamically retrieves high-quality sub-graphs based\non the corresponding entities."}, {"title": "2.2 Event Graph Reasoning", "content": "Event Graph Reasoning aims to leverage the struc-\nture and connections within the graph to identify\nnew patterns (Roy et al., 2024) that do not explic-\nitly exist in the event graph. Depending on the\ngoal of reasoning, the task can be further catego-\nrized into relational reasoning (Huang et al., 2024)\nand event prediction (Li et al., 2021). For rela-\ntion reasoning, Tang et al. (2023) adopts different\nevent attributes to learn the semantic representa-\ntions of events, and reasons event relation based\non their similarities. Tang et al. (2021) combines\nLSTM and attention mechanisms to dynamically\ngenerate event sequence representations, thereby\npredicting event relationships. For event predic-\ntion, prior studies (Du et al., 2021, 2022b) perform\nsubgraph matching between instance graph and\nschema graph to identify subsequent events. How-\never, such methods predict event types rather than\nthe events themselves. Moreover, Li et al. (2023b);\nIslam et al. (2024) predict potential events for the\nnext timestamp by dividing the event graph into a\nseries of subgraphs based on event timestamps."}, {"title": "3 Causality Graph Event Prediction", "content": ""}, {"title": "3.1 Task Definition", "content": "We define the Causality Graph Event Prediction\n(CGEP) task as predicting the most likely conse-\nquential events that will occur next in an event\ncausality graph (ECG). As illustrated in Figure 1,\nthe ECG is a directed graph consisting of some\npast events as nodes and the causal relations be-\ntween them as directed edges, denoted by G(E,R).\nWhere an event node $e_i \\in E$ contains the event\nmention word(s) $Em_i$ and the raw sentence $S_i$ it\nbelongs to; A causality edge $r_{ij} \\in R$ is a directed\ncausal relation from the event node $e_i$ to the event\nnode $e_j$, indicating that $e_i$ causes $e_j$ (i.e. $e_i \\rightarrow e_j$).\nEach tail node in an ECG, which has no edge start-\ning from to any other event node, is used as the\nanchor event $e_t \\in E$ for next event prediction. The\nobjective of CGEP task is to select the most likely\nconsequential events $e_c$ from the candidate event\nset $E_c$ for an anchor event node $e_t$ in an ECG."}, {"title": "3.2 Datasets Construction", "content": "We construct two CGEP datasets based on\nthe public event causality dataset MAVEN-\nERE (Wang et al., 2022c) and EventStoryLine Cor-\npus (ESC) (Caselli and Vossen, 2017), annotating\nevent mentions and directed causal relations be-\ntween events within documents. Figure 2 illustrates\nthe process of CGEP dataset construction.\nWe first construct ECGs based on the annota-\ntions in each document from ESC and MAVEN-\nERE datasets, using the annotated events as nodes\nand the annotated directed causal relation between\nevents as edges. Note that multiple disconnected\nECGs may be constructed from a single document,\nand only weakly connected graphs\u00b2 with more than\n4 event nodes are retained to ensure a complete\nevent causality graph structure for event prediction.\nWe then mask one of the tail event node in an ECG\nas a CGEP instance, where the masked event is\nthe consequential event $e_c$ to be predicted and its\ncause event is the anchor event $e_t$. In case that\nthe masked event is caused by multiple events or\nan anchor event causes multiple effect events, it is\nfurther divided into multiple CGEP instances to en-\nsure that each instance has an unique anchor event\nand ground truth consequential event.\nFor each CGEP instance, we randomly select\na large number of tail node events from all other\nECGs in the dataset as negative samples to con-\nstruct a candidate set of consequential events $E_c$.\nThe ground truth event $e_c$ is the one that has\nbeen masked aforementioned. Considering that the\nground truth event mention may also appears in the\nsentence of other event nodes, that is the sentence\nit belongs to contains multiple event mentions, we\nreplace them by a PLM-specific token [PAD] to\nprevent answer leakage. Finally, we construct two\nCGEP dataset CGEP-MAVEN and CGEP-ESC3\nfor the CGEP task, in which each instance contains\nan event causality graph G(E, R), an anchor event\n$e_t$, a candidate event set $E_c$, and a ground truth\nconsequential event $e_c$.\nConsidering the varying instance sizes of the\nCGEP-MAVEN and CGEP-ESC datasets, the num-\nber of candidate sets for consequential events is\nrandomly selected to be 512 and 256, respectively."}, {"title": "4 Methodology", "content": "We propose a Semantic Enhanced Distance-\nsensitive Graph Prompt Learning Model\n(SeDGPL) for causality graph event prediction.\nAs illustrated in Figure 3, the SeDGPL contains\nthree modules: (1) Distance-sensitive Graph Lin-\nearization (DsGL); (2) Event-Enriched Causality\nEncoding (EeCE); (3) Semantic Contrast Event\nPrediction (ScEP)."}, {"title": "4.1 Distance-sensitive Graph Linearization", "content": "The DsGL module is to reformulate the Event\nCausality Graph (ECG) of an input CGEP instance\ninto a graph prompt template T(G), as the input\nof a Pre-trained Language Model (PLM). As illus-\ntrated in Figure 3 (a), the graph prompt template\nT(G) is a concatenation of some event causality\ntriple templates $T_n$ and a simple prompt template\n$T_m$, represented as follows:\n$T(G) = [c], T_1, [s], ... T_n, [s], T_m, [s],$\t(1)\nwhere [C] and [s] are the PLM-specific tokens\n[CLS] and [SEP], respectively, indicating the be-\nginning and ending of an input sequence. Addition-\nally, [s] is also used to mark the boundary between\neach triple templates and the prompt template.\nGiven an ECG G with n directed causality edges,\nwe can first obtain n event causality triples $T^{(n)} =$\n(ei, rij, ej), each containing a cause event $e_i$, an\neffect event $e_j$ and a directed causal relation $r_{ij}$\nfrom $e_i$ to $e_j$. The template $T_n$ for each event\ncausality triple is formulated by concatenating of\nboth the cause and the effect event mentions with\nan inserted conjunction word causes:\n$T_n = Em_i causes Em_j,$\t(2)\nwhere $Em_i$ and $Em_j$ are the event mentions of\ncause event $e_i$ and effect event $e_j$, respectively.\nWe argue that the closer an event causality triple\n$T^{(n)}$ is to the anchor event $e_t$, the stronger its con-\nnection to the anchor event, and it can provide\nmore critical information for consequential event\nprediction. To this end, we order the event causal-\nity triples based on their distance to the anchor\nevent. The distance of an event causality triple\n$T^{(n)} = (e_i, r_{ij}, e_j)$ to the anchor event $e_t$ is com-\nputed by the number of edges on the shortest undi-\nrected path from its cause event $e_i$ to the anchor\nevent $e_t$, as follows:\n$d_n(e_i, e_t) = \\min_{p \\in P(e_i,e_t)} |p|,$ (3)\nwhere $P(e_i, e_t)$ is the set of all undirected paths\nfrom the cause event $e_i$ to the anchor event $e_t$, and\n$|p|$ is the number of edges on the path p.\nWe arrange the event causality triple templates\n$T_n$ in decreasing order of their distance to the an-\nchor event $e_t$. As in Equation 1, the distances are\nordered such that $d_1 \\geq d_2 \\geq ... > d_n$, indicating\nthat $T_n$ is closest to the anchor event and $T_1$ is the\nfarthest one. At the end of graph prompt template\nT(G), we design and concatenate a simple prompt\ntemplate $T_m$ for event prediction:\n$T_m = Em_t causes [MASK],$\t(4)\nwhere $Em_t$ is the event mention of anchor event\n$e_t$ and the PLM-specific token [MASK] is used to\npredict consequential event."}, {"title": "4.2 Event-Enriched Causality Encoding", "content": "To enrich the event representation for causality en-\ncoding, we propose an EeCE module that integrates\nboth event contextual semantic and graph schema\ninformation into the ECG representation. After\ngraph linearization, we input each graph prompt\ntemplate T(G) into a Pre-trained Language Model\n(PLM) for ECG encoding, denoted as $P_{ECG}$. As\nillustrated in Figure 3 (b), the input representation\nof PLM is constructed by summing the correspond-\ning token embedding $h^{(t)}$, the segment embedding\n$h^{(s)}$, and the position embedding $h^{(p)}$:\n$h^{(q)} = h^{(t)} + h^{(s)} + h^{(p)}.$\t(5)\nFor contextual semantic encoding, we input the\nraw sentence $S_i$ of each event into another PLM Pc\nto obtain its contextual representation $h^{(c)}$, as illus-\ntrated in Figure 3 (b.1). For schema information\nencoding, we first construct an event schema graph\nby replacing each event node in an ECG with its\ncorresponding annotated event type, like (Zhuang\net al., 2023; Groz et al., 2021), and etc. After the\nsame graph linearization operation, we input each\nschema graph template into another PLM Ps to ob-\ntain the event's schema representation $h^{(s)}$, as illus-\ntrated in Figure 3 (b.3). We note that only the token\nembeddings of event's contextual representation\n$h^{(c)}$ and schema representation $h^{(s)}$ are used for\nnext enrichment fusion. The segment embedding\n$h^{(s)}$ and position embedding $h^{(p)}$ of ECG encod-\ning, which contain graph structure information, are\ndirectly used without fusion.\nTo fuse the features of event's contextual se-\nmantic and schema information into the ECG rep-\nresentation, we use the fusion gate to integrate\ntheir event's representations $h^{(c)}$ and $h^{(s)}$ into the\nevent's representation of ECG $h^{(q)}$. Specifically,\nwe first use a fusion gate to integrate the contextual\nrepresentation $h^{(c)}$, schema representation $h^{(s)}$, and\noutput $h^{(r)} \\in R^{dh}$ as the event enrichment vector.\nThe transition functions are:\n$g_r$ = sigmoid($W_rh^{(c)} + U_rh^{(s)}$),$\t(6)\n$h^{(r)} = g_rh^{(c)} + (1-g_r) \\odot h^{(s)},$\t(7)\nwhere $W_r \\in R^{dh \\times dh}$, $U_r \\in R^{dh \\times dh}$ are learn-\nable parameters and $\\odot$ donates the element-wise\nproduct of vectors.\nWe next use another fusion gate to integrate the\nevent enrichment vector $h^{(r)} \\in R^{dh}$ into the token\nembeddings of event's representation in ECG $h^{(q)}$.\nThe transition functions are:\n$g_e$ = sigmoid($W_eh^{(q)} + U_eh^{(r)}$),$\t(8)\n$\\widehat{h}^{(q)} = g_eh^{(q)} + (1-g_e) \\odot h^{(r)},$\t(9)\nwhere $W_e \\in R^{dh \\times dh}$, $U_e \\in R^{dh \\times dh}$ are learnable\nparameters. With the fusion gate, we enrich the\nevent's representation in ECGs by integrating both\nevent's contextual semantic and schema informa-\ntion features. Note that only the representations of\nevent mention in ECGs are fused, the other tokens\nin graph prompt template T(G), such as causes,\n[CLS],[SEP], [MASK],and etc., are originally\nencoded by the ECG encoding PLM $P_{ECG}$.\nFinally, the PLM $P_{ECG}$ outputs a hidden state\nvector z for each input token in the graph prompt\ntemplate T(G), using the fused event's token em-\nbeddings as input representations."}, {"title": "4.3 Semantic Contrast Event Prediction", "content": "Following the prompt learning paradigm (Xiang\net al., 2023; Li et al., 2023a), we use the hidden\nstate vector of [MASK] token $z_m$ for consequen-\ntial event prediction. To enhance the PLM's ability\nof understanding event semantic among numerous\ncandidate events, we apply a kind of semantic con-\ntrastive learning to improve the [MASK] token pre-\nsentation $z_m$.\nAs illustrated\nin Figure 3 (c.1), we first obtain a representation\nvector $z_c$ for each candidate event $e_c$ using the\nfine-tuned PLM $P_{ECG}$. Then, the hidden state\nof [MASK] token $z_m$ is used as the anchor sam-\nple, and the candidate event representations $z_c$ are\nused as contrastive samples, where the ground truth\nevent is the positive sample $z_c^+$ and the other can-\ndidate events are negative samples $z_c^-$. We employ\nthe Supervised contrastive loss (Khosla et al., 2020)\nto compute the semantic contrast loss, as follows:\n$L_c = - \\log \\frac{\\exp(z_m \\cdot z_c^+ / \\tau)}{\\sum_{c \\in C} \\exp(z_m \\cdot z_c / \\tau)},$\t(10)\nwhere $\\tau$ is a scalar temperature parameter and C\nis the candidate set containing the positive sample\nand negative samples.\nConsequential Event Prediction: As illustrated\nin Figure 3 (c.2), the PLM $P_{ECG}$ estimates the prob-\nability of each word within its vocabulary V for\nthe hidden state of [MASK] token $z_m$. We use the\npredicted probability of the event mention word $e_c$\nin the event candidate set E as the ranking score,\nto form an event prediction list:\nP([MASK] = ec \u2208 Ec | T(G)).\t(11)\nWe employ the cross entropy loss to compute the\nevent prediction loss, as follows:\n$L_p = - \\frac{1}{K} \\sum_{k=1}^{K} y^{(k)} \\log(\\widehat{y}^{(k)}) + \\lambda ||\\Theta||^2,$\t(12)\nwhere $y^{(k)}$ and $\\widehat{y}^{(k)}$ are the gold label and predicted\nlabel of the k-th training instance respectively. A\nand $\\Theta$ are the regularization hyper-parameters. We\nuse the AdamW optimizer (Loshchilov and Hutter,\n2017) with L2 regularization for model training.\nTraining Strategy: The cost function of our\nSeDGPL is optimized as follows:\nL = Lp + \u03b2 * Lc,\t(13)\nwhere \u03b2 is a weight coefficient to balance the im-\nportance of the event prediction loss and semantic\ncontrast loss."}, {"title": "5 Experiment", "content": ""}, {"title": "5.1 Experiment Settings", "content": "Our experiments are conducted using the con-\nstructed CGEP-MAVEN and CGEP-ESC datasets.\nFollowing the standard data splitting of the underly-\ning ESC (Caselli and Vossen, 2017) corpus, we use\nthe last two topics as development set and conduct\n5-fold cross-validation on the remaining 20 topics.\nThe average results of each fold are adopted as per-\nformance metrics. Since the underlying MAVEN-\nERE corpus did not release the test set, following\n(Tao et al., 2023), we use the original development\nset as our test set and sample 20% of the data from\nthe original training set to form the development\nset.\nWe adopt the MRR (Mean Reciprocal Rank) and\nHit@n (Hit Rate at n) as the evaluation metrics.\nDetails about experimental settings and evaluation\nmetrics can be found in Appendix B."}, {"title": "5.2 Competitors", "content": "We replicate some advanced event prediction mod-\nels to conduct causality graph event prediction\nas benchmarks, including methods in knowledge\ngraph completion tasks (CSProm-KG (Chen et al.,\n2023), SimKG (Wang et al., 2022a)) and script\nevent prediction (BARTbase (Zhu et al., 2023),\nMCPredictor (Bai et al., 2021)). Furthermore, we\nvalidate the effectiveness of large language models\non the CGEP task, including Llama3-7B (Touvron\net al., 2023) and GPT-3.5-turbo (Gao et al., 2023).\nFor more details about its specific implementation,\nplease refer to the Appendix A and Appendix C."}, {"title": "5.3 Overall Results", "content": "Table 2 compares the overall performance between\nour SeDGPL and the competitors on both CGEP-\nMAVEN and CGEP-ESC datasets.\nWe can observe that our SeDGPL has achieved\nsignificant performance improvements overall com-\npetitors in terms of much higher MRR and Hit@n.\nWe attribute its outstanding performance to two\nmain factors: 1) The transformation of the event\ncausality graph into an ordered triple sequence\nfor graph prompt learning, which enables our\nSeDGPL to effectively leverage both the struc-\nture information of event causality graph and the\nencyclopedic knowledge in a PLM for event pre-\ndiction; 2) The enrichment of event representation\nthrough contextual semantic and schema informa-\ntion fusion encoding. Besides, We can also observe\nthat the BARTbase outperforms the other com-\npetitors in Table 2. This might be attributed to\nthe fine-tuning of a pre-trained language model\nin advance using an event-centric pre-training ob-\njective, which injects event-level knowledge into\nthe PLM before making predictions. 3) The per-\nformance of the Llama3-7B and GPT-3.5-turbo\nsurpasses some models trained on the entire dataset,\ne.g. the SimKG model, indicating that large lan-\nguage models have great potential in understanding\nevent relationships and reasoning event patterns.\nTo validate our argument that predicting conse-\nquential events based on event causality graph is\nmore effective than predicting based on the event\nscript chain, we also employ our SeDGPL and\nthe competitors to conduct script event prediction\nfor comparison, using the longest event chain in\neach event causality graph from CGEP-MAVEN\ndataset."}, {"title": "5.4 Ablation Study", "content": "Module Ablation To examine the effectiveness\nof different modules, we design the following ab-\nlation study: (1) SeDGPL w/o Dist. randomly\norders the event causality triples without consid-\nering distance sensitivity; (2) SeDGPL w/o Ctxt.\nenriches event representation with only schema in-\nformation, but without its contextual semantic; (3)\nSeDGPL w/o Schm. enriches event representa-\ntion with only contextual semantic, but without\nits schema information; (4) SeDGPL w/o Ctrst.\npredicts consequential events without semantic con-\ntrastive learning."}, {"title": "6 Case study", "content": "Figure 5 illustrates an example of SeDGPL applied\nto the causality graph event prediction (CGEP) task\nand the causality script event prediction (CSEP)\ntask. For the CGEP task, SeDGPL linearizes the\nentire event graph into an event chain, compre-\nhensively considering all the causality triples in\nthe event graph. In contrast, for the CSEP task,\nSeDGPL extracts only a subset of the causality\ntriples from the event graph to form the main event\nchain, disregarding the other nodes in the event\ngraph, which undermines the structural information\nof the event graph. From Figure 5, we observe that\nincorporating information beyond the main event\nchain can effectively aid the model in predicting\nsubsequent events more accurately. For instance, in\nthe CGEP task, given the causality triples (Drove,\ncauses, Heist) and (Heist, causes, Escaping) as\nprior knowledge, our model can readily infer that\nthe subsequent event following \"Escaping\" is \"ar-\nrest\". In contrast, for the CSEP task, the model\nonly relies on the main event chain to judge the\nrelationship between events. Therefore, the model\ncan not effectively capture the causal relationships\nbetween events at different levels and the complex\nstructure information in the event causality graph,\nleading to a decline in performance."}, {"title": "7 Concluding Remarks", "content": "In this paper, we argue that predicting consequen-\ntial events based on the event causality graph is\nmore effective than predicting based on the event\nscript chain. To validate our argument, we propose\nthe SeDGPL Model, a distance-sensitive graph\nprompt model that integrate both event contextual\nsemantic and graph schema information, and con-\nduct abundant experiments on both CGEP and SEP\ntask. Experiment results validate our argument,\nand our proposed SeDGPL model outperforms the\nadvanced competitors for the CGEP task.\nIn our future work, we shall attempt to integrate\nother types of event relationships, e.g. temporal\nrelations, to assist in event prediction."}, {"title": "8 Limitation", "content": "Due to the input length limitations of PLMs, we\nmay have to discard some triplets during the lin-\nearization process, which could result in the loss of\ninformation beneficial for prediction."}, {"title": "9 Acknowledge", "content": "This work is supported in part by National Natural\nScience Foundation of China (Grant No:62172167).\nThe computation is completed in the HPC Platform\nof Huazhong University of Science and Technol-\nogy."}, {"title": "10 Ethics Statement", "content": "This paper has no particular ethic consideration."}]}