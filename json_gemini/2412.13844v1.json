{"title": "CRM: Retrieval Model with Controllable Condition", "authors": ["Chi Liu", "Jiangxia Cao", "Rui Huang", "Kuo Cai", "Weifeng Ding", "Qiang Luo", "Kun Gai", "Guorui Zhou"], "abstract": "Recommendation systems (RecSys) are designed to connect users\nwith relevant items from a vast pool of candidates while aligning\nwith the business goals of the platform. A typical industrial RecSys\nis composed of two main stages, retrieval and ranking: (1) the re-\ntrieval stage aims at searching hundreds of item candidates satisfied\nuser interests; (2) based on the retrieved items, the ranking stage\naims at selecting the best dozen items by multiple targets estima-\ntion for each item candidate, including classification and regression\ntargets. Compared with ranking model, the retrieval model absence\nof item candidate information during inference, therefore retrieval\nmodels are often trained by classification target only (e.g., click-\nthrough rate), but failed to incorporate regression target (e.g., the\nexpected watch-time), which limit the effectiveness of retrieval.\nIn this paper, we propose the Controllable Retrieval Model (CRM),\nwhich integrates regression information as conditional features into\nthe two-tower retrieval paradigm. This modification enables the re-\ntrieval stage could fulfill the target gap with ranking model, enhanc-\ning the retrieval model ability to search item candidates satisfied the\nuser interests and condition effectively. We validate the effective-\nness of CRM through real-world A/B testing and demonstrate its\nsuccessful deployment in Kuaishou's short-video recommendation\nsystem, which serves over 400 million users.", "sections": [{"title": "1 INTRODUCTION", "content": "Recommendation systems play a pivotal role across many platforms,\nincluding short-video sharing platforms such as Kuaishou [11],\nDouyin [21], and Google [13], benefiting billions of users world-\nwide. These systems aim to efficiently match users with the right\nitems while aligning with platform goals, thereby achieving a posi-\ntive environment for users, creators, and the platform. To capture\nuser interests precisely, the industrial RecSys always optimized by\nmultiple targets [15, 16], such as classification target (e.g., click,\ncomment) and regression target (e.g., watch-time). By considering\nthese diverse targets, RecSys could select the most related items\nfrom a pool of tens of millions of item pool for users.\nThe typical recommendation architecture is typically divided\ninto two stages, retrieval [6] and ranking [4]: (1) the retrieval stage,\nwhere hundreds of candidates are selected from a corpus of millions\nof items, (2) the ranking stage, where the retrieved hundreds items\nare multi-target scored one by one to determined the best dozens\nto users (as shown in Figure 1(a) and (b)). Compared with ranking\nmodel, the retrieval stage often uses the two-tower training para-\ndigm [7, 17], where user/item features are independently encoded\nby user/item tower, and next utilizing a classification task to opti-\nmize model. On the one hand, benefit by the two-tower architecture,\nwe could achieve a efficient retrieval in inference since only the user\ntower needed re-computation for each recommendation request.\nOn the other hand, the two-tower architecture also seriously limits\nthe retrieval model's ability to support multi-targets training, espe-\ncially the regression targets. To fulfill the multiple-targets gap in\nclassification targets [5], a common strategies is introducing multi-\nroute models in retrieval stage, where each route model focuses\non a specific target, and then aggregated these results for latter\nranking stage.\nDespite these advances, an important problem still unresolved:\nhow to introduce the regression target into retrieval model? Ac-\ntually, the regression targets (e.g., expected watch time) should\nrequire knowledge of the corresponding item to be determined.\nThis is because the expected watch time lacks a common consen-\nsus of 'good' or 'bad', it depends on the video's quality and the\nuser's watch habits at same time, making it challenging to infer\nsolely from user-side information only. Such phenomenon leading\nto a consistency problem between retrieval and ranking stages and\nconstraining the performance of RecSys chain.\nIn this paper, we propose the Controllable Retrieval Model (CRM),\na novel retrieval paradigm that incorporates regression information\nas an additional condition to guide the model. This approach enables\nthe simultaneous utilization of both classification and regression\nsignals, as illustrated in Figure 1(c). Specifically, during training,\nregression condition is incorporated as features in the user tower\nto generate directional user representations. During online infer-\nence, condition is strategically set to guide the retrieval process to\nalign with our platform goals. In our implementation, we give two\nsimple versions: the first is naive CRM and the second is decision\ntransformer CRM from reinforce learning (RL) perspective [3].\nOur contributions are as follows:\n\u2022 We propose a new paradigm for designing retrieval models by\nincorporating regression information as a condition, enhancing\nthe consistency between the retrieval and ranking stages, and\ninspiring advancements in recommendation systems.\n\u2022 We introduce two simple yet effective methods for implementing\nCRM: one involves improving the two-tower architecture, and\nthe other incorporates sequence modeling, providing a reference\nfor others adopting CRM.\n\u2022 We present a novel and effective strategy for selecting conditions,\nvalidated in Kuaishou's largest short video recommendation sce-\nnario."}, {"title": "2 PRELIMINARY", "content": "This section briefly review the: (1) the two-tower retrieval workflow;\n(2) the RL-based decision transformer for sequence modeling."}, {"title": "2.1 Two-Tower Retrieval Workflow", "content": "Generally, the retrieval task aims utilizing the user/item feature to\nmodel user preference and item attributes to predict the next video\nthat user are likely to interact with. For example, $(x_1, W_1), ..., (x_n, W_n)$\nrepresents the IDs and watch times of videos recently viewed by\na user, passed to the user tower as part of UserFea, while $x_{n+1}$\nrepresents the ID of the next video viewed as part of ItemFea. The\ntwo-tower backbone first employ the user/item side information to\ngenerate their representations:\n$u = User\\_Tower(UserFea)$,\n$v = Item\\_Tower(ItemFea)$,\n(1)"}, {"title": "2.2\nDecision Transformer in RL", "content": "RL aims to control an agent to conduct actions to maximum cu-\nmulative reward in an given state and environment [9]. Actually,\nthe RL idea is closely related with our CRM: based on observed\ninteraction sequence (state), to find next item (action) under\nthe regression condition (reward) for each user (environment).\nIn offline RL filed (does not considering the environment factor),\nthe Decision Transformer (DT [3]) is the pioneer work for sequence\nmodeling, which aims to make action decision based on past re-\nward and state sequence directly. as shown in Figure 2(a), the DT\nconstructs a sequence with three elements: (1) reward-to-go $R_i$, (2)\nstate representation $s_i$, (3) action $a_i$, for sequence modeling:\n$a_{n+1} = DT(R_1, S_1, a_1, R_2, S_2, a_2, ..., R_{n+1}, S_{n+1})$,\n(4)\nwhere the DT is a multi-layer Transformers with casual mask mech-\nanism, the $a_{n+1}$ is the predicted next action, the $R_i = \\sum_{i=n+1}^{n} r_i$ de-\nnotes multi-step cumulative rewards, and the $r_i$ is the single-step\nreward from action $a_i$. It is worth noting that the special reward-\nto-go token $R_i$ is crucial for DT to encourage the model to simulate\na RL Q-learning function [12]."}, {"title": "3 METHODOLOGY", "content": "In this section, we dive into CRM to show that how it works. Specifi-\ncally, for better understanding, we utilize the next video's watch-\ntime as condition information to express our CRM."}, {"title": "3.1 Offline Training Strategy", "content": "We have implemented two approaches for CRM: the first is a naive\nDNN-based two-tower paradigm, which is simple to implement and\ncan be integrated into existing models with minimal modifications;\nthe second is a transformer-based paradigm, which offers stronger\nsequence modeling capabilities."}, {"title": "3.1.1 DNN-based Controllable Model", "content": "Figure 1(c) describes the\nsimple variant, which aims to enable the model to perceive the extra\ncondition information to direct the user representation searching\nrelated short-videos. In the model training, we directly input the\nobserved next video's watch time $W_{n+1}$ as a condition to the\nuser tower, allowing the model to learn the joint distribution of\nwatch time and the target video:\n$u_{Condition} = CRM\\_User\\_Tower(UserFea_u, W_{n+1})$,\n(5)\nwhere the $u_{Condition}$ denotes the user representation enhanced\nwith watch-time condition information, and next, we can optimize\nour CRM model by Eq.(2) in the same manner as the two-tower\nmodel. The model-agnostic modification could equipped to the\ncommon two-tower method seamlessly."}, {"title": "3.1.2 Transformer-based Controllable Model", "content": "In recent years, the\nsequence modeling achieves great success at many research areas [1,\n14], while our retrieval task can be naturally formed as a next-\nitem prediction task that could benefit by the SOTA Transformer\nsequence modeling ability. Inspired by the Decision Transformer [3],\nwe form the user's interaction sequence as RL-based sequence style\nin Figure 2(b). Specifically, in CRM, the interaction sequence\n(state) is consist by a series of item (action), therefore CRM's\ndecision sequence only include with two elements: (1) watch-time-\nto-go $W_i$, (2) items $x_i$:\n$u_{Condition} = CRM\\_User\\_Tower(UserFea_u,\nCRM\\_DT(W_1, x_1, W_2, x_2, ..., W_{n+1})),\n(6)\nwhere the CRM_DT denotes a multi-layer Transformer with casual\nmask mechanism, and the $W_i = \\sum_{i=n+1}^{n} w_i$ denotes multi-step cumu-\nlative watching-time. In our online production environment, we\nopted for the transformer-based CRM due to its superior perfor-\nmance."}, {"title": "3.2 Online Inference Strategy", "content": "During offline training of CRM, the condition is known, such as\nthe actual time a user watched a target video. However, during\ninference, the condition is unknown and must be defined based on\nuser information and business requirements. Below, we outline our\napproach to condition setting during online inference in the short\nvideo recommendation scenario, where the expected video watch\ntime is used as the condition."}, {"title": "3.2.1 Maximum vs. Average Watch Time", "content": "When determining the\ncondition's value, one approach is to calculate the average watch\ntime of the last n videos the user has watched. This average reflects\na user's typical behavior and can approximate the time they gen-\nerally spend watching videos. However, our goal is to maximize\nusers' overall watch time on the platform. Therefore, an alterna-\ntive approach is to select the maximum watch time from the last n\nvideos a user has watched, in order to maximize the total viewing\ntime.\nThe value of n must be carefully chosen. A large n might cause\nthe condition to be overly influenced by an outlier, leading to less dy-\nnamic recommendations. Conversely, a small n may fail to capture\nrepresentative user behavior. In our real-world online deployment,\nWe selected 32 as the value of n. As shown in Figure 3, both the\nmax and avg strategies exhibit similar trends of variation over a\nday, though the max values are significantly higher than the avg\nvalues."}, {"title": "3.2.2 Time-Division Multiplexing Strategy", "content": "In our scenario, using\nthe average watch time does not significantly improve the overall\nuser watch time but can increase the number of videos watched\nand enhance interaction-related metrics, such as comments and\nlikes. On the other hand, using the maximum watch time signifi-\ncantly boosts user watch time, but it tends to recommend longer\nvideos, which may reduce the total number of videos watched and\ninteraction metrics.\nTo leverage the strengths of both strategies, we adopt a time-\ndivision multiplexing approach. For each request, we randomly\nselect the maximum watch time strategy with probability p, and\nwith probability 1 \u2013 p, we select the average watch time strategy.\nThis method allows both strategies to be effective at different times,\nwhile appearing to coexist for individual users, as shown in Algo-\nrithm 1. The parameters n and p are hyperparameters, and their\noptimal values were determined through online experiments."}, {"title": "4 EXPERIMENTS", "content": "We conduct online experiments at our short-video recommendation\nscenario, which is the largest recommendation scenario at Kuaishou\nincluding over 400 Million users and 50 Billion logs daily. In this\nsection, we aim at answering the following research questions:\n\u2022 RQ1: How does CRM bring improvement to the performance of\nonline recommendation tasks?\n\u2022 RQ2: How does CRM perform compared to other retrieval ap-\nproaches?"}, {"title": "4.1 Online A/B Test (RQ1)", "content": "The results, as shown in Table 1, highlight the improvements achieved\nby the CRM model across several key metrics. For instance, Video\nWatch Time increased by 0.372% for the Kuaishou Single Page and\nby 0.457% for the Kuaishou Lite Single Page, suggesting that CRM's\nenhanced recommendation process leads to higher engagement\nwith video content. Similarly, Total App Usage Time and Usage\nTime per User also saw noticeable improvements in both versions,\nwith the Kuaishou Lite Single Page showing a 0.196% increase and\nthe Kuaishou Single Page showing a 0.175% improvement.\nIn terms of user interaction, CRM outperformed the baseline\nmodel in Likes, Follows, and Comments. Notably, the Kuaishou Lite\nSingle Page saw a substantial 0.828% increase in Follows, indicating\nthat CRM may help in fostering long-term user engagement. Fur-\nthermore, Video Views demonstrated an increase in both platforms,\nwith the Kuaishou Lite Single Page observing a 0.324% improve-\nment.\nThese results provide strong evidence that CRM significantly\nenhances user engagement and interaction in the short-video rec-\nommendation task. The improvements across all metrics suggest\nthat the controllable recall mechanism contributes to more person-\nalized and relevant recommendations, thus improving the overall\nuser experience in Kuaishou's short-video services."}, {"title": "4.2 Ablation Study (RQ2)", "content": "In Kuaishou's short video recommendation scenario, multiple re-\ntrieval models are employed simultaneously to maximize the di-\nversity of content supply and meet user needs. We compared CRM\nwith the following representative strong retrieval methods which\nare deployed at Kuaishou: (1) Item2Item based methods: Swing [18];\n(2) Multi-interests based methods: ComiRec [2]; (3) Diffusion based\nmethods: DimeRec [10]; (4) List-wise based methods: LTR [19]. (5)\nRanking model based methods: TDM [20]; (6) Transformer based\nmethods: KuaiFormer [11]."}, {"title": "5 CONCLUSION", "content": "We introduced the Controllable Retrieval Model (CRM), a new ap-\nproach to improving recommendation systems by integrating target\ninformation into the retrieval stage. This method bridges the gap\nbetween retrieval and ranking, enhancing the system's ability to\ndeliver more personalized and relevant recommendations.\nThis work highlights the potential of incorporating target infor-\nmation into retrieval models and sets a foundation for further ad-\nvancements in recommendation systems. Future efforts will explore\nadditional targets that can be used as conditions, more effective\nstrategies for specifying conditions, and extending the approach to\ndomains beyond recommendation systems."}]}