{"title": "REVEALING THE UNSEEN: GUIDING PERSONALIZED\nDIFFUSION MODELS TO EXPOSE TRAINING DATA", "authors": ["Xiaoyu Wu", "Steven Wu", "Jiaru Zhang"], "abstract": "Diffusion Models (DMs) have evolved into advanced image generation tools, es-\npecially for few-shot fine-tuning where a pretrained DM is fine-tuned on a small\nset of images to capture specific styles or objects. Many people upload these per-\nsonalized checkpoints online, fostering communities such as Civitai and Hugging-\nFace. However, model owners may overlook the potential risks of data leakage by\nreleasing their fine-tuned checkpoints. Moreover, concerns regarding copyright\nviolations arise when unauthorized data is used during fine-tuning. In this paper,\nwe ask: \"Can training data be extracted from these fine-tuned DMs shared on-\nline?\" A successful extraction would present not only data leakage threats but\nalso offer tangible evidence of copyright infringement. To answer this, we pro-\npose FineXtract, a framework for extracting fine-tuning data. Our method approx-\nimates fine-tuning as a gradual shift in the model's learned distribution\u2014from the\noriginal pretrained DM toward the fine-tuning data. By extrapolating the models\nbefore and after fine-tuning, we guide the generation toward high-probability re-\ngions within the fine-tuned data distribution. We then apply a clustering algorithm\nto extract the most probable images from those generated using this extrapolated\nguidance. Experiments on DMs fine-tuned with datasets such as WikiArt, Dream-\nBooth, and real-world checkpoints posted online validate the effectiveness of our\nmethod, extracting approximately 20% of fine-tuning data in most cases, signifi-\ncantly surpassing baseline performance.", "sections": [{"title": "1 INTRODUCTION", "content": "Recent years have witnessed the advancement of Diffusion Models (DMs) in computer vision. These\nmodels demonstrate exceptional capabilities across various tasks, including image editing (Kawar\net al., 2022), and video editing (Yang et al., 2022), among others. Particularly noteworthy is the\nadvent of few-shot fine-tuning methods (Hu et al., 2021; Ruiz et al., 2023; Qiu et al., 2023), in which\na pretrained model is fine-tuned to personalize generation based on a small set of training images.\nThese approaches have significantly reduced both memory and time costs in training. Moreover,\nthese techniques offer powerful tools for adaptively generating images based on specific subjects or\nobjects, embodying personalized AI and making AI accessible to everyone.\nBuilding on these innovations, several communities, such as Civitai (civ) and HuggingFace (hug),\nhave emerged, hosting tens of thousands of fine-tuned checkpoints and attracting millions of down-\nloads. Although many users willingly share their fine-tuned models, they may be unaware of the risk\nof data leakage inherent in this process. This is particularly concerning when fine-tuning involves\nsensitive data, such as medical images, human faces, or copyrighted material. Moreover, many of\nthese checkpoints are fine-tuned using unauthorized data, including artists' work. This unauthorized\nfine-tuning process raises significant concerns regarding \u201creputational damage, economic loss, pla-"}, {"title": "2 BACKGROUND AND RELATED WORKS", "content": ""}, {"title": "2.1 DIFFUSION MODELS AND FEW-SHOT FINE-TUNING", "content": "Diffusion Models and Score Matching. Diffusion Models (DMs) (Ho et al., 2020; Sohl-Dickstein\net al., 2015) are generative models that approximate data distributions by gradually denoising a vari-\nable initially sampled from a Gaussian distribution. These models consist of a forward diffusion\nprocess and a backward denoising process. In the forward process, noise \\( \\epsilon \\in N(0, 1) \\) is progres-\nsively added to the input image xo over time t, following the equation \\( x_t = \\sqrt{\\alpha_t}x_0 + \\sqrt{1 - \\alpha_t}\\epsilon \\).\nConversely, in the backward process, DMs aim to estimate and remove the noise using a noise-\nprediction module, \\( \\epsilon_\\theta \\), from the noisy image \\( x_t \\). The difference between the actual and pre-\ndicted noise forms the basis of the training loss, known as the diffusion loss, which is defined as\n\\( L_{DM} = E_{\\epsilon \\sim N(0,1), t} [||\\epsilon_\\theta(x_t, t) - \\epsilon||^2] \\).\nAnother series of works focus on score matching, offering insights into DMs from a different per-\nspective (Vincent, 2011; Song & Ermon, 2019; Song et al., 2020). Score matching aims to learn a\nscore network \\( s_\\theta(x) \\) trained to predict the score (i.e., the gradient of the log probability function)\n\\( \\nabla_x log\\;q(x) \\) of data x within real data distribution q(x) (Vincent, 2011). To improve accuracy and\nstability, subsequent research proposes predicting the score of the Gaussian-perturbed data distribu-\ntion q(xt) (Song & Ermon, 2019; Song et al., 2020): \\( s_\\theta(x_t,t) \\approx \\nabla_{x_t} log\\;q(x_t) = \\frac{\\epsilon_\\theta(x,t)}{\\sqrt{1-\\alpha_t}} \\) where\n\\( \\alpha_t = \\prod_{i=1}^t\\alpha_i \\). These works show a strong alignment between the predicted noise \\( \\epsilon_\\theta(x,t) \\) and the\nscore \\( \\nabla_x log\\;q(x) \\)."}, {"title": "Few-shot Fine-tuning.", "content": "Few-shot fine-tuning in DMs (Gal et al., 2022; Hu et al., 2021; Ruiz et al.,\n2023) aims to personalize these models using a limited set of images, enabling the generation of\ncustomized content. Gal et al. (2022) introduced a technique that incorporates new tokens within the\nembedding space of a frozen text-to-image model to capture the concepts in the provided images.\nHowever, this method has limitations in accurately reproducing the detailed features of the input\nimages (Ruiz et al., 2023). To address this, Ruiz et al. (2023) proposed DreamBooth, which fine-\ntunes most parameters in DMs using a reconstruction loss to capture details and a class-specific\npreservation loss to ensure alignment with textual prompts. Additionally, Hu et al. (2021) introduced\nLORA, a lightweight fine-tuning approach that inserts low-rank layers to be trained while keeping\nother parameters frozen."}, {"title": "2.2 \u039c\u0395\u039cORIZATION AND DATA EXTRACTION IN DIFFUSION MODELS", "content": "Recent studies on DMs have highlighted their tendencies toward data memorization and methods\nhave been proposed to extract training data based on it. Carlini et al. (2023) used a graph algorithm\nto identify the generated data most likely to have been included in the training set, thereby retriev-\ning DM's memorized training data. Further investigations (Somepalli et al., 2023a;b) explore the\nunderlying causes of this memorization, revealing that conditioning plays a significant role, and the\nnature of training prompts notably influences the likelihood of reproducing training samples. How-\never, these studies are primarily empirical with no parametric formulation on learned distribution\nof DMs, and they do not address personalization scenarios. In contrast, our approach introduces a\nparametric approximation of the learned distribution of fine-tuned DMs, enabling the design of a\npipeline that efficiently extracts training samples from fine-tuned checkpoints upload online."}, {"title": "3 THREAT MODEL AND METRICS", "content": ""}, {"title": "3.1 THREAT MODEL", "content": "Our threat model involves extracting training data from a fine-tuned DM alongside its corresponding\npretrained DM, with two key parties: model providers and attackers.\nModel providers. Providers fine-tune a pretrained model \\( \\theta \\) using an image dataset \\( X_0 \\). After fine-\ntuning, they upload the fine-tuned model checkpoint \\( \\theta' \\) to specific websites, including necessary\ndetails such as the name of the pretrained model \\( \\theta \\) to make the fine-tuned model checkpoint usable.\nAdditional training details, such as training captions, are sometimes provided (civ; hug)."}, {"title": "3.2 EVALUATION METRICS", "content": "Attacker produces an extracted dataset \\( \\hat{X} \\), which is evaluated by comparing it with the training\nimage set \\( X_0 \\). Specifically, we consider the following two metrics:\nMetric 1: Average Similarity (AS). Average similarity is computed between images in the ex-\ntracted dataset \\( \\hat{X} \\) and those in the training dataset \\( X_0 \\). The metric is defined as:\n\n\\( AS(X_0, \\hat{X}) = \\frac{1}{|X_0|} \\sum_{i=1}^{|X_0|} max_j sim(X_0^{(i)}, \\hat{X}^{(j)})\\).\n\nHere, sim(,) denotes the similarity function, with output ranging from 0 to 1. Following previous\nworks (Somepalli et al., 2023a;b; Chen et al., 2024), we use the Self-Supervised Descriptor (SSCD)\nscore (Pizzi et al., 2022), designed to detect and quantify copying in DMs, for similarity computation\nin this paper. Intuitively, AS measures how well the extracted dataset \\( \\hat{X} \\) covers the images within\nthe training dataset \\( X_0 \\).\nMetric 2: Average Extraction Success Rate (A-ESR). Following previous work (Carlini et al.,\n2023), when the similarity between an extracted image and a training image exceeds a given thresh-\nold, the extraction of that image is considered as successful. To assess the extraction of an entire\ndataset, we compute the average extraction success rate as follows:\n\n\\( A\\text{-}ESR_\\tau(X_0, \\hat{X}) = \\frac{1}{|X_0|} \\sum_{i=1}^{|X_0|} \\mathbb{1}(max_j sim(X_0^{(i)}, \\hat{X}^{(j)}) > \\tau)\\),\n\nwhere \\( \\mathbb{1} \\) is the indicator function. Following previous work (Somepalli et al., 2023a;b), the threshold\n\\( \\tau \\) is set to 0.7 for a strictly successful extraction. We also present results where the threshold \\( \\tau \\)\nis set to 0.6, which represents a moderate similarity and can be considered a loosely successful\nextraction (Chen et al., 2024)."}, {"title": "4 FINEXTRACT: EXTRACTING FINE-TUNING DATA", "content": "In this section, we introduce FineXtract, a framework designed for robust extraction using DMs\nbefore and after fine-tuning. As shown in Fig. 2, we first address a simplified scenario considering\nunconditional DMs (Sec. 4.1). Next, we explore the case where the training caption c is provided\n(Sec. 4.2). Finally, we apply a clustering algorithm to identify the images with the highest probabil-\nity of matching those in the training dataset (Sec. 4.3) from generated image set \\( \\hat{X} \\). The output of\nthe clustering algorithm serves as the extracted image set \\( \\hat{X} \\), closely resembling the training images\nset \\( X_0 \\)."}, {"title": "4.1 MODEL GUIDANCE", "content": "We denote the the fine-tuned data distribution as q(x) for a fine-tuning dataset \\( X_0 \\). During the\nfine-tuning process, the DMs progressively shift their learned distribution from the pretrained DMs'\ndistribution \\( p_\\theta(x) \\) toward the fine-tuned data distribution q(x). Thus, we parametrically approximate\nthat the learned distribution of the fine-tuned DMs, denoted as \\( p_{\\theta'}(x) \\), satisfies:\n\n\\( p_{\\theta'}(x) \\propto p_\\theta^{(1-\\lambda)}(x)q^{\\lambda}(x) \\),\n\nwhere \\( \\lambda \\) is a coefficient ranging from 0 to 1, relating to the training iterations. More training it-\nerations result in larger \\( \\lambda \\), showing the fine-tuned DMs distribution \\( p_{\\theta'}(x) \\) more closely ensemble\nfine-tuned data distribution q(x).\nIn this case, we can derive the score of the fine-tuned model distribution \\( p_{\\theta'}(x) \\) by:\n\n\\( \\nabla_x log\\;p_{\\theta'}(x) = (1 - \\lambda)\\nabla_x log\\;p_\\theta(x) + \\lambda \\nabla_x log\\;q(x) \\),\n\nThis means that we can derive the guidance towards the fine-tuning dataset \\( X_0 \\) by using the score of\nthe fine-tuned data distribution and pretrained DMs distribution:\n\n\\( \\nabla_x log\\;q(x) = \\frac{1}{\\lambda} \\nabla_x log\\;p_{\\theta'}(x) - \\frac{1-\\lambda}{\\lambda} \\nabla_x log\\;p_\\theta(x) \\).\n\nRecalling the equivalence between denoisers and the score function in DMs (Vincent, 2011), we\nemploy a time-varying noising process and represent each score as a denoising prediction, denoted\nby \\( \\epsilon(x_t, t) \\), similar to previous work (Gandikota et al., 2023):\n\n\\( \\epsilon_q(x_t,t) = \\epsilon_{\\theta'}(x_t, t) + (w - 1)(\\epsilon_\\theta(x_t, t) - \\epsilon_\\theta(x_t,t)) \\),\n\nwhere \\( w = \\frac{1}{\\lambda} \\). Eq. 6 demonstrates that by extrapolating from the pretrained denoising prediction\n\\( \\epsilon_\\theta(x_t,t)) \\) to the fine-tuned denoising prediction \\( \\epsilon_{\\theta'}(x_t, t) \\), we can derive guidance toward the fine-\ntuned data distribution. We call this process \u201cmodel guidance\". The guidance scale w should be\ninversely related to the number of training iterations. With model guidance, we can effectively\nsimulate a \"pseudo-\" denoiser \\( \\epsilon_q \\), which can be used to steer the sampling process toward the high-\nprobability region within fine-tuned data distribution q(x)."}, {"title": "4.2 GUIDANCE WITH TRAINING CAPTION PROVIDED", "content": "We further consider the scenario where DMs are fine-tuned with a given caption c. As discussed\nin previous work on classifier-free guidance (CFG) (Ho & Salimans, 2022), DMs often struggle to\naccurately learn the distribution conditional on a given caption c and therefore require additional\nguidance from unconditional generation. We can adopt a similar approximation to the one presented\nin Sec. 4.1:\n\n\\( p_{\\theta}(x|c) \\propto p_{\\theta'}(x)q^{\\lambda'}(x|c) \\),\n\nwhere \\( q_{\\theta}(x|c) \\) denotes the data distribution conditioned on c. The above formulation indicates that\nconditional DMs learn a mixture of the conditional distribution of real data and the unconditional"}, {"title": "distribution of DMs.", "content": "To capture the score of a denoiser \\( \\epsilon_{q_\\theta}(x, c) \\), which guides sampling toward the\nhigh-probability region of \\( q_{\\theta}(x|c) \\), we follow the transition from Eq. 5 to Eq. 6, using denoising\nprediction to represent the scores:\n\n\\( \\epsilon_{q_\\theta}(x_t, t, c) = \\epsilon_{\\theta'}(x_t, t, c) + (w' - 1)(\\epsilon_{\\theta}(x_t, t, c) - \\epsilon_{\\theta}(x_t,t)) \\),\n\nwhere \\( w' = \\frac{1}{\\lambda'} \\). This results in CFG with guidance scale w' (Ho & Salimans, 2022). Furthermore,\nfor fine-tuned DMs \\( \\theta' \\), we similarly obtain:\n\n\\( p_{\\theta}(x|c) \\propto p_\\theta^{x'}(x)q^{\\lambda'}(x|c) \\),\n\nwhere q(x|c) denotes the fine-tuned data distribution conditioned on c. Combined with Eq. 3:\n\n\\( p_{\\theta}(x|c) \\propto p_{\\theta}^{(1-\\lambda)(1-\\lambda')}(x)q^{(1-\\lambda')}(x)q^{\\lambda'}(x|c) \\).\n\nThis implies that:\n\n\\( \\epsilon_{\\rho_\\theta}(x_t, t, c) = (1 - \\lambda)(1 - \\lambda')\\epsilon_{\\theta}(x_t,t) + (1 - \\lambda')\\epsilon_{q}(x_t, t) + \\lambda' \\epsilon_{q}(x_t, t, c) \\).\n\nSince the real-data distribution involving two modalities is expected to be more peaked than a single-\nmodality distribution, we assume that the conditional fine-tuned data distribution q(x|c) is also much\nmore concentrated than the unconditional one, q(x). This results in a significant difference in the\nmagnitude of their score, i.e., \\( ||\\nabla_x log\\;q(x)|| < ||\\nabla_x log\\;q(x, c) || \\). Consequently, based on the\ntransformation in Eq. 5 and Eq. 6, we have \\( \\epsilon_{q}(x,t) << \\epsilon_{q}(x, t, c) \\), allowing us to approximate Eq.\n11 by omitting by omitting \\( \\epsilon_{q}(x, t) \\):\n\n\\( \\epsilon_{\\theta'}(x_t, t, c) \\approx (1 - \\lambda)(1 - \\lambda')\\epsilon_{\\theta}(x_t, t) + \\lambda' \\epsilon_{q}(x_t, t, c) \\),\n\nwhich indicates:\n\n\\( \\epsilon_{q}(x_t, t, c) \\approx \\epsilon_{\\theta'}(x_t, t, c) + (w' - 1)(\\epsilon_{\\theta'}(x_t, t, c) - \\epsilon_{\\theta}(x_t, t)) + k\\epsilon_\\theta(x_t,t) \\).\n\nHere, \\( w = \\frac{w'-1}{w'}, w' = \\frac{1}{\\lambda'} \\) and \\( k = \\frac{1-w'}{w} \\).\nThis transformation demonstrates that we can guide generation within the conditional fine-tuned data\ndistribution, q(x|c), by extrapolating from the unconditional denoising prediction of the pretrained\nDM, \\( \\epsilon_{\\theta}(x_t, t) \\), to the conditional denoising prediction of the fine-tuned model DM, \\( \\epsilon_{\\rho_\\theta}(x_t, t, c) \\),\nusing the guidance scale w'. This process also involves an additional correction term \\( k\\epsilon_\\theta(x_t,t) \\),\nwhich, intuitively, compensates the mismatch between model guidance and CFG .\nIn practice, the training caption c may not always be available. However, we find that it is possible\nto extract some information about the training caption by analyzing only the first few trainable linear\nprojection layers before and after fine-tuning. Details are provided in Appendix Sec. A."}, {"title": "4.3 CLUSTERING GENERATED IMAGES", "content": "Sections 4.1 and 4.2 explain how to sample images within high probability region of fine-tuned data\ndistribution. However, the randomness in the sampling process affects the images, reducing extrac-\ntion accuracy. To further improve extraction accuracy, we take inspiration from previous work (Car-\nlini et al., 2023), sampling N images and applying a clustering algorithm to identify the images with\nthe highest probability, where \\( N > N_0 \\) and \\( N_0 \\) is the number of training images.\nSpecifically, inspired by Carlini et al. (2023), we compute the similarity between each pair of gen-\nerated images and construct a graph where each image is represented as a vertex. We connect\ntwo vertices when the similarity between the corresponding images exceeds a threshold \\( \\delta \\), i.e., if\nsim(xi, xj) \u2265 \\( \\delta \\), we connect vertices i and j. By default, we use SSCD (Pizzi et al., 2022) to\nmeasure similarity, in line with previous work (Somepalli et al., 2023a;b). Instead of using a fixed\nthreshold (Carlini et al., 2023), we gradually increase the threshold \\( \\delta \\) until the number of cliques,"}, {"title": "5 EXPERIMENTS", "content": "In this section, we apply our proposed method, FineXtract, to extract training data under various\nfew-shot fine-tuning techniques across different types of DMs. We conduct experiments on two\ncommon scenarios for few-shot fine-tuning: style-driven and object-driven generation. For style-\ndriven generation, which focuses on capturing the key style of a set of images, we randomly select\n20 artists, each with 10 images, from the WikiArt dataset (Nichol, 2016). For object-driven gen-\neration, which emphasizes the details of a given object, we experiment on 30 objects from the\nDreambooth dataset (Ruiz et al., 2023), each consisting of 4-6 images. This setup aligns with the\nrecommended number of training samples in the aforementioned fine-tuning methods (Ruiz et al.,\n2023; Hu et al., 2021). We experiment with two most widely-used few-shot fine-tuning techniques:\nDreamBooth (Ruiz et al., 2023), and LoRA (Hu et al., 2021). More details for the fine-tuning setting\nare available in Appendix Sec. E.\nThe default model used for training is Stable Diffusion (SD) V1.41. Additionally, we demonstrate\nthe adaptability of our method to various types and versions of DMs, larger training datasets, and\ndifferent numbers of generated images (refer to Sec. 5.2 for more details).\nBy default, we set the generation count N to 50 \u00d7 \\( N_0 \\), where \\( N_0 \\) represents the number of training\nimages. The number of extracted images is set equal to \\( N_0 \\) to best evaluate our method's ability to\nextract the exact training dataset. For DreamBooth, the guidance scale w' for both FineXtract and\nCFG set to 3.0 by default, with the correction term scale k set to -0.02 in Equations 8 and 13. For\nLORA, w' is set to 5.0 for FineXtract and 3.0 for CFG, respectively. For the clustering algorithm,\nwe by default set the maximum clustering time for each threshold to be 30s. If clustering does\nnot end, we simply move to the next threshold to reduce computation time. We discuss how these\nhyperparameters influence extraction efficiency in Sec. 5.3. FineXtract under potential defenses and\ntoward real-world checkpoints on HuggingFace are discussed in Sec. 5.4 and Sec. 5.5, respectively."}, {"title": "5.1 COMPARISON", "content": "Previous extraction methods primarily focus on the generation capabilities of text-to-image DMs,\nemploying either direct text-to-image generation or classifier-free guidance (CFG) (Carlini et al.,\n2023; Somepalli et al., 2023a;b). To better demonstrate the effectiveness of our framework, we\ncompare FineXtract with Direct Text-to-Image and CFG, both combined with the clustering algo-\nrithm proposed in Section 4.3. For both CFG and FineXtract, we set the guidance scale w' to 3.0\nunder DreamBooth fine-tuning. Under LoRA fine-tuning, w' are set to 3.0 for CFG and 5.0 for\nFineXtract. These hyperparameters are found to perform well (see Sec. 5.3 for details). All methods\nuse the same number of generation iterations, N, set to 50 \u00d7 \\( N_0 \\), and the number of extracted im-\nages set to \\( N_0 \\) to ensure a fair comparison. The results, shown in Table 1, demonstrate a significant\nadvantage of FineXtract over previous methods, with an improvement of approximately 0.02 to 0.05\nin AS and a doubling of the A-ESR in most cases."}, {"title": "5.2 GENERALIZATION", "content": "In this section, we take a step further to test whether our method can be applied to a broader range of\nscenarios, including different DM structures, varying numbers of training images \\( N_0 \\), and different"}, {"title": "5.3 ABLATION STUDY", "content": "In this section, we experiment with\nhyperparameters in Eq. 13, including\nthe guidance scale w' and the correc-\ntion term scale k. We experiment on\n4 classes in WikiArt fine-tuning with\nDreamBooth. Results under LoRA\nare shown in Appendix Sec. D.\nGuidance Scale w'. The guidance\nscale w' is the most critical hyper-\nparameter influencing extraction ef-\nficiency. If w' is too low, the guid-\nance provided by fine-tuning meth-\nods is weakened. Conversely, if w'\nis too high, it often causes generation\nfailures, resulting in unrealistic outputs (see visual examples in Fig. 6). As shown in Fig. 5a,\nw' = 3.0 works well for both CFG and FineXtract when DMs are fine-tuned using DreamBooth."}, {"title": "5.4 FINEXTRACT UNDER DEFENSE", "content": "As highlighted in prior research (Duan et al., 2023; Kong et al., 2023; Pang et al., 2023), it is possible\nto partially defend against privacy-related attacks, such as membership inference attacks (\u039c\u0399\u0391).\nNaturally, this raises the question of whether these\ndefense methods can also protect against extrac-\ntion techniques. To explore this, we conducted\nexperiments on FineXtract under two defenses:\nCutout (DeVries & Taylor, 2017), and RandAug-\nment (Cubuk et al., 2020). Notably, RandAugment\nis recognized as a strong privacy-preserving defense\nat the cost of severe decline in generation qual-\nity (Duan et al., 2023).\nThe results presented in Tab. 3 illus-\ntrate how these methods can partially\ndefend FineXtract, though at the cost\nof generation performance. Cutout\nand RandAugment indeed proves to\nbe quite strong at defense. However,\nas shown in Fig. 7, the added trans-\nformations render the output images\nlargely unusable, making them diffi-\ncult to leverage in practice. Our re-\nsults highlight that while these ap-\nproaches may be partially effective\nin defense, there is a lack of re-\nsearch on how to fine-tune models on\nsuch transformed data while preserv-\ning the defensive effects. This re-\nmains an area for further investiga-\ntion."}, {"title": "5.5 REAL-WORLD RESULTS", "content": "Finally, we test our method on fine-tuned checkpoints available in the real world. We experiment on\n10 checkpoints from HuggingFace where the corresponding training datasets are provided, allowing\nus to evaluate the effectiveness of our extraction method. Due to licensing restrictions, we only\nprovide detailed information about the checkpoints with permissive licenses in Appendix Sec. F.\nQuantitative results are shown in Table 4, where FineXtract consistently outperforms the baseline\nmethods, increasing AS by at least 0.03 and doubling A-ESR in most cases."}, {"title": "6 CONCLUSION", "content": "In conclusion, our proposed framework, FineXtract, effectively addresses the challenge of extract-\ning fine-tuning data from publicly available DM fine-tuned checkpoints. By leveraging the transi-\ntion from pretrained DM distributions to fine-tuning data distributions, FineXtract accurately guides\nthe generation process toward high-probability regions of the fine-tuned data distribution, enabling\nsuccessful data extraction. Our experiments demonstrate the method's robustness across various\ndatasets and real-world checkpoints, highlighting the potential risks of data leakage and providing\nstrong evidence for copyright infringements."}, {"title": "A CAPTION EXTRACTION ALGORITHM", "content": "While it can be argued that training captions may not always be available, we find that they can be\npartially extracted. Our focus is on the first layer that is not frozen during the fine-tuning process.\nWe assume this layer behaves as a linear model without bias, which aligns with the common sce-\nnario when fine-tuning DMs. Specifically, in the case of fine-tuning SD using LoRA, the LoRA is\ntypically applied to the cross-attention layers. As a result, the first layer that is fine-tuned is the linear\nprojection layer in the cross-attention module, which processes the text features from a CLIP model\nbased on the input prompt. This assumption also holds true when fine-tuning using DreamBooth\nwithout adjusting the text encoder, which is one of the most frequently used fine-tuning settings.\nThe weights of this layer before and after fine-tuning are denoted as \\( \\beta \\) and \\( \\beta' \\). The output of\nthe layer for a given input prompt embedding \\( e \\) is \\( \\beta' e^T \\). Unlike prior work (Bertran et al., 2024), we do\nnot have a clear formulation of the training target for this particular linear layer, as the downstream\nsignal can change frequently. Therefore, in this case, we rely on the gradient updating process."}, {"title": "A.1 A BASIC SCENARIO", "content": "To begin with, let's consider a very simple case where the prompt consists of only one word, and\nall the training images share the same training caption. We denote the embedding of this specific\nprompt as \\( e_0 \\). \\( e_0 \\) has the shape [1, N] for SD, where N is the dimension for the embedding (we\nomit the positional embedding here and will discuss it later). The weight \\( \\beta_k \\) for the projection layer\nis with shape [H, N], where H is the hidden dimension. Then the forward loss is L(\\( \\beta'e^T \\)). The\ngradient can be computed with:\n\n\\( \\nabla_{\\beta_k} J = \\frac{\\partial L(\\beta'e^T)}{\\partial \\beta_k} =  \\frac{\\partial L(\\beta'e^T)}{\\partial e_0} e_0. \\)\n\nDuring the jth update, we denote this as \\( \\nabla_{\\beta_k}^j =  \\frac{\\partial L_j(\\beta'e^T)}{\\partial \\beta_k} e_0 \\). Then for a basic optimizer, such\nas SGD, we have:\n\n\\( \\delta \\beta_k^j = - \\alpha  \\nabla_{\\beta_k}^j = - \\alpha   \\frac{\\partial L_j(\\beta'e^T)}{\\partial e_0} e_0 \\),\n\nwhich means the row space for the matrix \\( \\beta' - \\beta \\) is in fact span{\\( e_0 \\)}. With this information, we\ncan simply use a different embedding \\( e' \\) to index this equation:\n\n\\( e'^T (\\beta' - \\beta) = \\frac{\\partial L_j(\\beta'e^T)}{\\partial e_0} e_0 e'^T \\)\n\nNotably, if all \\( e' \\) are normalized, we should have arg max \\( e'e^T \\) = \\( e_0 \\). Therefore, we can find this \\( e_0 \\)\nby simply finding the one that maximizes the norm in Eq. 16:\n\n\\( e_0  \\approx arg max_e ||(e'^T(\\beta' - \\beta) e ||^2 \\)"}, {"title": "A.2 EXTENSION TO MULTIPLE-WORDS PROMPTS", "content": "In general cases, prompts consist of multiple words, making the inversion process tricky. In these\ncases, \\( e_0 \\) may have the shape [W, N] for SD, where W is the length of the prompts. (In fact, due\nto the presence of position embedding, cases with different words actually all have W = 77, where\n77 is the maximum length for input prompts). This results in \\( e'e^T \\) not being a scalar anymore\nin Eq. 16. Its shape is [W, W]. Therefore, we cannot obtain \\( e_0 \\) by simply computing the norm.\nIn fact, Eq. 15 shows that the row space of \\( \\beta' - \\beta \\) is span{\\( e_{0,1}, e_{0,2},\u00b7\u00b7\u00b7, e_{0,77} \\)}. Here, we\ncan use a transformation where we perform Principal Component Analysis (PCA) decomposition\n(Abdi & Williams, 2010) on \\( \\beta' - \\beta \\). In other words, we approximate it using a rank-one matrix:"}, {"title": "A.3 EXTENSION TO MORE OPTIMIZERS AND APPROXIMATION DURING TRAINING WITH"}]}