{"title": "EVALUATING REPRESENTATIONAL SIMILARITY MEASURES FROM THE LENS OF FUNCTIONAL CORRESPONDENCE", "authors": ["Yiqing Bo", "Ansh Soni", "Sudhanshu Srivastava", "Meenakshi Khosla"], "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of interpreting high-dimensional neural data, where the comparative analysis of such data is crucial for revealing shared mechanisms and differences between these complex systems. Despite the widespread use of representational comparisons and the abundance classes of comparison methods, a critical question remains: which metrics are most suitable for these comparisons? While some studies evaluate metrics based on their ability to differentiate models of different origins or constructions (e.g., various architectures), another approach is to assess how well they distinguish models that exhibit distinct behaviors. To investigate this, we examine the degree of alignment between various representational similarity measures and behavioral outcomes, employing group statistics and a comprehensive suite of behavioral metrics for comparison. In our evaluation of eight commonly used representational similarity metrics in the visual domain-spanning alignment-based, Canonical Correlation Analysis (CCA)-based, inner product kernel-based, and nearest-neighbor methods-we found that metrics like linear Centered Kernel Alignment (CKA) and Procrustes distance, which emphasize the overall geometric structure or shape of representations, excelled in differentiating trained from untrained models and aligning with behavioral measures, whereas metrics such as linear predictivity, commonly used in neuroscience, demonstrated only moderate alignment with behavior. These insights are crucial for selecting metrics that emphasize behaviorally meaningful comparisons in NeuroAI research.", "sections": [{"title": "1 INTRODUCTION", "content": "Both neuroscience and artificial intelligence (AI) confront the challenge of high-dimensional neural data, whether from neurobiological firing rates, voxel responses, or hidden layer activations in artificial networks. Comparing such high-dimensional neural data is critical for both fields, as it facilitates understanding of complex systems by revealing their underlying similarities and differences.\nIn neuroscience, one of the main goals is to uncover how neural activity drives behavior and to understand neural computations at an algorithmic level. Comparisons across species and between brain and model representations, particularly those of deep neural networks, have been instrumental in advancing this understanding (Yamins et al. (2014); Eickenberg et al. (2017); G\u00fc\u00e7l\u00fc & Van Gerven (2015); Cichy et al. (2016); Khaligh-Razavi & Kriegeskorte (2014); Schrimpf et al. (2018; 2020); Storrs et al. (2021); Kriegeskorte et al. (2008)). A growing interest lies in systematically altering model parameters\u2014such as architecture, learning objectives, and training data and comparing the resulting internal representations with neural data (Yamins & DiCarlo (2016); Doerig et al. (2023); Schrimpf et al. (2018; 2020)).\nSimilarly, in AI, researchers are increasingly focused on reverse-engineering neural networks by tweaking architectural components, training objectives, and data inputs to examine how these modifications impact the resulting representations. However, studying neural networks in isolation can be limiting, as interactions between the learning algorithms and structured data shape these systems in ways we do not yet fully understand. Comparative analysis of model representations offers"}, {"title": "Related Work", "content": "Although few studies directly compare representational similarity measures based on their discriminative power, most efforts in this area focus on identifying metrics that distinguish between models by their construction. These efforts typically involve assessing measures based on their ability to match corresponding layers across models with varying seeds (Kornblith et al., 2019) or identical architectures with different initializations (Han et al., 2023; Rahamim & Belinkov, 2024). The closest to our work are studies by Ding et al. (Ding et al., 2021) and Cloos et al. (Cloos et al., 2024). Cloos et al. (Cloos et al., 2024) optimized synthetic datasets to resemble brain activity under various measures, demonstrating that metrics like linear predictivity and CKA can yield high scores even when task-relevant variables are not encoded. Ding et al. ((Ding et al., 2021)) examined the sensitivity of representational similarity measures\u2014CCA, CKA, and Procrustes\u2014in BERT models (NLP) and ResNet models (CIFAR-10) to factors that either preserve functional behavior (e.g., random seed variations) or alter it (e.g., principal component deletion). However, these studies examine a limited set of similarity measures and primarily assess functional similarity based on task performance alone, without evaluating the finer-grained alignment of predictions across models."}, {"title": "1.1 METRICS FOR REPRESENTATIONAL COMPARISONS", "content": "Notations and Definitions Let S be a set of M fixed input stimuli. Define the kernel functions f:S\u2192 RNx and g : S \u2192 RNY, where Nx and Ny are the output unit sizes of the first and second encoders, respectively. Here, f(si) and g(si) map each stimulus si \u2208 S to vectors in RNx and RNY.\nLet X \u2208 RM\u00d7Nx and Y \u2208 RM\u00d7Ny be the representation matrices. For each input stimulus si, denote the ith row of X as $i = f(si) and of Y as Vi = g(si), each being the activation in response to the ith stimulus."}, {"title": "Representational Similarity Analysis (RSA)", "content": "(Kriegeskorte et al., 2008) A method that quantifies the distance between M \u00d7 M Representational Dissimilarity Matrices (RDMs) of two models in response to a common set of M stimuli.\nRSA(X, Y) = \u0442(J\u043c \u2013 XTX, J\u043c \u2013 YTY)\nwith JM denoting the M \u00d7 M all-ones matrix, the representational dissimilarity matrices (RDMs) for X and Y are JM \u2013 XTX and JM \u2013 YTY, respectively. XTX and YTY in RM\u00d7M represent the self-correlations of X and Y, with each matrix entry i, j quantifying the correlation between activations for the ith and jth stimuli. The Kendall rank correlation coefficient 7(\u00b7) quantifies the similarity between these RDMs."}, {"title": "Canonical Correlation Analysis (CCA)", "content": "(Hotelling, 1992) A popular linear-invariant similarity measure quantifying the multivariate similarity between two sets of representations X and Y under a shared set of M stimuli by identifying the bases in the unit space of matrix X and Y such that when the two matrices are projected on to these bases, their correlation is maximized.\nHere, the ith canonical correlation coefficient pi (associated with the ith optimized canonical weights w\u2208 RNx and w\u2208 RNY) is being calculated by:\n$\\rho_i = \\max_{w, w'} \\text{corr}(Xw, Yw')$ subject to \u2200j < i, XX and Y 1Y,\nwith the transformed matrices Xw and Yw being called canonical variables.\nTo obtain a measure of similarity between neural network representations, the mean CCA correlation coefficient p over the first N' components is reported, with N' = min(Nx, Ny). Here,\n$\\overline{\\rho}= \\frac{\\sum_{i=1}^{N'} \\rho_i}{N'} = ||Q_Y^T Q_X ||_*$ ,\nwhere || ||* denotes the nuclear norm. Here, Qx = X(XTX)-1/2 and Qy = Y(YTY)-1/2 represent any orthonormal bases for the columns of X and Y."}, {"title": "Linear Centered Kernel Alignment (CKA)", "content": "(Kornblith et al., 2019; Gretton et al., 2005)\nA representation-level comparison that measures how (in)dependent the two models' RDMs are under a shared set of M stimuli. This measure possesses a weaker invariance assumption than CCA, being invariant only to orthogonal transformations, rather than all classes of invertible linear transformations, which implies the preservation of scalar products and Euclidean distances between pairs of stimuli.\nCKA(K, L) = $\\frac{HSIC(K, L)}{\\sqrt{HSIC(K, K)HSIC(L, L)}}$\nwith K and L be kernel matrices where Kij = \u03ba(\u03c6i,j) and Lij = \u03ba(\u03c8i, \u03c8j). These matrices represent the inner products of vectorized features & and \u03c8 from two different models, respectively, computed using the kernel function function K. In the linear case, k is the inner product, implying K = XXT, L = YYT. The Hilbert-Schmidt Independence Criterion HSIC(\u00b7) evaluates the cross-covariance of the models' internal embedding spaces, focusing on the similarity of stimulus pairs."}, {"title": "Mutual k-nearest neighbors", "content": "(Huh et al., 2024) A local-biased representation-level measure that quantifies the similarity between the representations of two models by assessing the average overlap of their nearest neighbor sets for corresponding features.\nMNN(\u03a6\u03af, \u03c8\u03b9) = $\\frac{1}{|S(\\phi_i) \\cap S(\\psi_i)|}$\nwhere $i = f(si) and Vi = g(si) are features derived from model representations f and g given the shared stimulus si. S($i) and S(Vi) are the set of indices of the k-nearest neighbors of di and Vi in their respective feature spaces and |\u00b7 | is the size of the intersection."}, {"title": "Linear predictivity", "content": "An asymmetric measure of alignment between the representations of two systems, obtained using ridge regression. The numerical score is calculated by summing Pearson's correlations between each pair of predicted and actual activations in the held-out set. For reporting, we provide symmetrized scores by averaging the correlation coefficients from both fitting directions."}, {"title": "Procrustes distance", "content": "(Ding et al., 2021; Williams et al., 2021) A rotational-invariant shape align-ment distance between X and Y's representations after removing the components of uniform scaling and translation and applying an optimized mapping, where the mappings from one representation matrix to another is constrained to rotations and reflection. Here, the Procrustes distance is given by:\nd(X,Y) = $\\min_{T \\in O(n)} ||\\phi(X) - \\phi(Y)T||_F$\nwhere (\u00b7) is the function that whitens the covariance of the matrix X and Y, i.e. the columns sum to zero and ||$(X)||_F, ||$(X)||_F = 1. O(n) is the orthogonal group.\nThe similarity scores reported are obtained by 1 d(X, Y), such that the comparison with a repre-sentation itself yields a score of 1, and lower distance yields a higher score."}, {"title": "Semi-matching score", "content": "(Li et al., 2015; Khosla et al., 2024) An asymmetric correlation-based measure obtained using the average correlation after matching every neuron in X to its most similar partner in Y. The scores reported are the average from both fitting directions.\nSsemi (X, Y) = $\\frac{1}{N}\\sum_i \\max_{j\\in\\{1,...,N_y\\}} x_i^Ty_j$"}, {"title": "Soft-matching distance", "content": "(Khosla & Williams, 2024) A generalization of permutation dis-tance (Williams et al., 2021) to representations with different number of neurons. It measures alignment by relaxing the set of permutations to \u201csoft permutations\u201d. Specifically, consider a nonneg-ative matrix P \u2208 R\u00d1\u00a4\u00d7Ny whose rows each sum to 1/N\u2082 and whose columns each sum to 1/Ny. The set of all such matrices defines a transportation polytope (De Loera & Kim, 2013), denoted as T(Nx, Ny). Optimizing over this set of rectangular matrices results in a \u201csoft matching\u201d or \u201csoft permutation\" of neuron labels in the sense that every row and column of P may have more than one non-zero element.\ndr(X,Y) = $\\sqrt{\\min_{P\\in T(N_x,N_y)} \\sum_{i,j} P_{ij} || x_i - y_j ||^2}$"}, {"title": "1.2 DOWNSTREAM BEHAVIORAL MEASURES", "content": "For classification tasks, we incorporate various downstream measurements at different levels of granularity to assess behavioral consistency across systems. For a given pair of neural networks, their activations over a shared set of stimuli are extracted. A linear readout based on a fully connected layer is trained over a training set of activations, where the resulting behavioral classification decisions determined by the linear readouts on a held-out testing set are exploited in the following ways as a comparison between the neural networks:"}, {"title": "Raw Softmax alignments", "content": "emphasize the consistency of numerical class-level activation strength patterns. Compares two models' representations by their linear-readout's softmax layer activation, which is a class-dimensional vector reflecting the model's judgement of the probabilities assigned to each label for a given input, with scores calculated by summing the Pearson correlation coefficient between these softmax vectors over the testing set."}, {"title": "Classification Confusion Matrix alignments", "content": "emphasize the consistency of discrete inter-class (mis) classification patterns. A similarity score is obtained by comparing the two models' confusion matrices in the following ways:\n1 Pearson Correlation Coefficient between the flattened confusion matrices given by two models, each being a vector of dimension C2 over C classes.\n2 Jensen-Shannon (JS) Distance (Lin, 1991) introduced as a behavioral alignment measure by Tuli et al. (2021) is functionally similar to a symmetrized and smoother version of the Kullback-Leibler (KL) divergence. For class-wise JS distance, let p = (P1,P2,...,pc) and q = (91, 92,..., qc) be error probability vectors over C classes, with\n$P_i = \\frac{e_i}{\\sum_{i=1}^C e_i}, \\forall i \\in \\{1, 2, ..., C\\}$\nwhere ei represents error counts per class. The JS divergence is defined as:\nJSD(p,q) = $\\frac{D(p||m) + D(q||m)}{2}$ ,\nwith D (plm) = $\\sum_{i=1}^C p_i \\log (\\frac{p_i}{m_i})$ and m = $\\frac{p_i + q_i}{2}$\nA finer inter-class dissimilarity measure derived from the complete misclassification patterns shown in the non-diagonal elements of the confusion matrix results in two C * (\u0421 \u2013 1) dimensional flattened vectors \u00ee\u00ee and \u011d, where each component is proportional to the counts of misclassifications from class i to class j, is calculated as\n$\\overline{c_{ij}} = \\frac{c_{ij}}{\\sum_{i=1}^C \\sum_{j=1, j\\neq i}^C c_{ij}}$ , \u2200i, j\u2208 {1, 2, ..., C'}\nThe resulting distances from both method range from [0, 1], where we simply report a similarity measure given by 1 JSD(p,q)."}, {"title": "Classification Binary Correctness alignments", "content": "emphasize consistency in per-stimulus prediction correctness. The error patterns for each model are encoded as vectors of binary values, where each entry corresponds to the correctness of a stimulus's prediction. We incorporate the following measures to compare alignment between the binary vectors:\n1 Pearson Correlation Coefficient between the two binary vectors of dimension M over M shared testing stimuli, reflecting the prediction correctness of two models (1 = correct, 0 = incorrect).\n2 Cohen's K Score Consider two systems tested independently on identical trials, each correctly classifying with a probability Pcorrect, leading to i.i.d. samples from a binomial distribution.\n$\\Kappa_{xy} = \\frac{C_{obs,xy} - C_{exp,xy}}{1 - C_{exp,xy}}$ ,\nwith Cexp,xy = PiPj + (1 \u2212 pi)(1 - Pj), Cobs,xy = # of agreements/M\nwhere Cexp,xy represents the expected probability of agreement between model x and y, calculated from the accuracies pr and py of two independent binomial observers, and Cobs,xy denotes the observed probability of agreement. Cohen's \u043a assesses the consistency of error overlap, providing a measure of classification agreement without distinguishing error types.\n3 Jaccard Similarity Coefficient is defined as:\nJ(x,y) = $\\frac{\\sum_{i=1}^n x_iy_i}{\\sum_{i=1}^n (x_i + y_i - x_iy_i)}$\nwhere each Xi, Yi \u2208 {0,1} represents the correctness (1) or incorrectness (0) of the ith sample prediction from the two models, respectively. The numerator \"|Intersections|\" counts samples where both models predict correctly, normalized by \"|Unions|\", which counts samples where either model predicts correctly.\n4 Hamming Distance counts the number of discrepancies in the correctness of predictions:\nd(x, y) = |{i: xi \u2260 Yi, i = 1, ..., n}|.\n5 Agreement Score is the normalized difference between counts of agreement and disagreement in the prediction correctness made by the two models:\ns(x,y) = $\\frac{(\u043f_{11} + \u043f\u043e\u043e) - (\u043f_{10} + \u043f\u043e1)}{\u043f_{11} + \u043f\u043e\u043e + \u043f_{10} + \u043f\u043e1}$\nwith nij, where i, j \u2208 0, 1, counts predictions where model x predicts i (correct/incorrect) and model y predicts j over shared stimuli."}, {"title": "1.3 DOWNSTREAM BEHAVIORAL DATASETS", "content": "We analyze the behavior of all models across a series of downstream tasks, including in-distribution and several out-of-distribution image types, such as silhouettes, stylized images, and natural images distorted by various noise types (see Appendix A.1 for details). In total, these comparisons span 17 behavioral datasets."}, {"title": "1.4 SELECTION OF NEURAL NETWORK ARCHITECTURES AND LAYERS", "content": "We incorporated a comprehensive list of popular deep learning models pretrained over the 1000-class classification tasks over the ImageNet-1k dataset (Deng et al., 2009). The selection spans a diverse set of architectures, including conventional convolutional neural networks (CNNs) and transformers. These models were trained using various objective functions, both supervised and self-supervised. Specifically, our lineup includes AlexNet (Krizhevsky et al., 2012), ResNet (He et al., 2015), VGG16 (Simonyan & Zisserman, 2015), Inception (Szegedy et al., 2014), ResNeXt (Xie et al., 2017), MoCo (He et al., 2020), ResNet Robust (Engstrom et al., 2019), and several variants of Vision Transformers (ViTs) (Dosovitskiy et al., 2020) such as Vit-b16 and ViT-ResNet (vit on ResNet architecture),"}, {"title": "2 RESULTS", "content": "2.1 DIFFERENT REPRESENTATIONAL SIMILARITY MEASURES HAVE DISTINCT CAPACITIES FOR MODEL SEPARATION\nTo characterize how different representational similarity measures discriminate models, we first visualize the model-by-model similarity matrices for each measure. We observed that while some measures like the soft-matching distance were effective at differentiating architectural families (Fig. 2, right), others like the Procrustes distance were more sensitive to the effects of training (Fig. 2, left), clearly separating trained from untrained models. Other measures, like linear predictivity, which allow greater flexibility in aligning the two representations, showed limited ability in distinguishing between models trained with different architectures or trained from untrained models (see Appendix A.4 for additional similarity matrices). To quantify these distinctions, we computed d' scores (Appendix A.2) to assess each measure's ability to differentiate two categories of models: (a) those from different architectural families, and (b) those with varying levels of training (trained vs. untrained). Significant differences in d' scores emerged across measures (Fig. 3). For instance, Procrustes achieved d' scores with a mean of 3.70 when separating trained from untrained models across all datasets, while commonly used measures like CCA and linear predictivity produced much lower scores with means of 0.53 and 0.87, respectively. Similarly, some measures were better at discriminating architectural differences, with the soft-matching distance demonstrating the highest discriminability (mean of d' scores = 1.6). Previous studies have also demonstrated that different measures vary in their effectiveness at establishing layer-wise correspondence across networks with the same architecture (Kornblith et al., 2019; Thobani et al.). Considering these differences in how measures distinguish between models, a key question emerges: Which distinctions should we prioritize?"}, {"title": "2.2 BEHAVIORAL METRICS PRIMARILY REFLECT LEARNING DIFFERENCES OVER ARCHITECTURAL VARIATIONS", "content": "To address the question of which separation should be prioritized, we return to our central premise: measures that emphasize functional distinctions should be favored. Therefore, we next evaluated how different behavioral measures (as previously described) distinguish between models. Our results"}, {"title": "2.3 BEHAVIORAL METRICS SHOW GREATER CONSISTENCY THAN NEURAL REPRESENTATIONAL SIMILARITY MEASURES", "content": "We next examined the consistency across different representational similarity measures and across different behavioral measures by computing correlations between the model-by-model similarity matrices generated by each measure. As shown in Fig. 4 (Top), we find that behavioral metrics (mean r: 0.85 \u00b1 0.01) are more correlated on average than representational metrics (mean r: 0.75 \u00b1 0.007), with a significant difference (z = -7.10, p = 5 \u00d7 10\u22128 < 0.0001).\nTo further understand the relationships between different representational similarity measures, we ana-lyzed the MDS plot (Fig. 4 (Bottom)). This visualization revealed distinct clusters of measures based on their theoretical properties. Measures that rely on inner product kernels (stimulus-by-stimulus dissimilarities) tend to group together, indicating they capture similar aspects of representational structure. On the other hand, measures that use explicit, direct mappings between individual neu-rons\u2014such as Linear Predictivity and Semi-Matching\u2014form a separate cluster. Notably, Procrustes Distance and CCA also involve alignment, similar to Linear Predictivity and Semi-Matching; however, this alignment is achieved collectively across all units or neurons rather than through independently determined mappings for each neuron. Procrustes aligns the entire configuration of points, while CCA projects the two representations onto common subspaces to maximize correlation, further distinguishing them from other representational similarity approaches.\nHow behavioral metrics distinguish models is crucial, as most comparative analyses of representations in neuroscience and AI revolve around understanding computations and how those computations relate to behavior; behaviorally grounded comparisons of model representations are key to this endeavor. We find that behavioral metrics distinguish between models in a consistent manner across different datasets, reinforcing the robustness of the model relationships they uncover (Appendix A.3). The"}, {"title": "2.4 WHICH REPRESENTATIONAL SIMILARITY MEASURES SHOW THE STRONGEST CORRESPONDENCE WITH BEHAVIORAL MEASURES?", "content": "Seeing that we want to prioritize the model relationships uncovered by behavioral metrics, we move on to investigate which \u2013if any\u2013 representational similarity metrics reveal the same underlying relationships between models. To rigorously assess this, we computed correlations between the model-by-model similarity matrices of each representational metric with the model-by-model behavioral similarity matrix averaged across all behavioral metrics, separately for many datasets (Fig 5). We found that three metrics stood out in their alignment with behavioral metrics - RSA (mean r: 0.52), Linear CKA (mean r: 0.64), and Procrustes (mean r: 0.70). Going back to our original analysis, these metrics are also able to more strongly differentiate trained and untrained models (Fig 1 Top d' measures). All these representational metrics emphasize alignment in either the overall geometry or shape of representations. Alternate measures like linear predictivity and CCA, which are commonly employed in representational comparisons in neuroscience and AI, showed significantly weaker alignment with mean correlation scores of 0.26 and 0.19 respectively. Given the opacity of neural representations, selecting appropriate representational similarity metrics can be challenging; these findings offer crucial guidance for metrics that support behaviorally grounded comparisons."}, {"title": "3 DISCUSSION", "content": "In this study, we compared 8 neural representational similarity metrics and 9 behavioral measures across 17 datasets.Based on the premise that behavioral differences should be mirrored in the representational structure of neural networks, we examined practical distinctions in their alignment with behavior. Metrics like RSA, CKA, and Procrustes distance, which preserve the overall geometry of neural representations, tend to align closely with behavioral measures. In contrast, methods like linear predictivity, which align dimensions without preserving global geometry, show weaker alignment. This divergence likely arises because linear predictivity has the capacity of mapping complex, distributed geometric structures to simpler, compressed ones while maintaining prediction accuracy. For instance, trained networks were observed to predict untrained network activation patterns well, yielding high symmetrized scores.\nMoreover, while different behavioral measures generally show consistency, neural representational similarity metrics do not, underscoring the need for a deeper understanding of how these representa-tional metrics discriminate between models in practical applications. Our analysis sets a new standard for representational similarity measures in neuroscience and AI, using downstream behavioral ro-bustness as a guide for selecting the most suitable metric. This framework is especially crucial in model-brain comparisons, where representational analyses are frequently applied to assess if artificial neural networks and biological systems are serving comparable functional roles in terms of perceptual and cognitive processes.\nOur framework for representational metric selection, though robust, makes some key assumptions. It assumes a specific mechanism for how behavior is 'reading out' from neural representations, and different readout mechanisms could reveal qualitatively different relationships between models. For example, applying biologically-inspired constraints, such as sparsity, could reveal divergent relationships, especially if some models encode behaviorally relevant information in a sparse manner that others do not. In such cases, the precise representation structure at the unit-level becomes critical. Additionally, we defined \"behavior\" within the scope of object classification across multiple out-of-distribution (OOD) image datasets. Extending evaluations to include fine-grained visual discrimination or broader tasks beyond categorization would better capture the full range of visual processing. Lastly, a stronger theoretical framework explaining why certain similarity measures align more closely with behavior than others is currently lacking in our work, but this remains an exciting direction for future research."}, {"title": "A APPENDIX", "content": "A.1 DOWNSTREAM BEHAVIORAL DATASETS\nAll datasets, directly drawn from Geirhos et al. (2019); Wang et al. (2019); Geirhos et al. (2021), share the coarser 16 labels from ImageNet. These consist of a subset of the ImageNet1k validation set sampled from the following categories: Airplane, Bear, Bicycle, Bird, Boat, Bottle, Car, Cat, Chair, Clock, Dog, Elephant, Keyboard, Knife, Oven, Truck."}, {"title": "A.2 INTER VS INTRA GROUP STATISTIC MEASURES USING d' SCORES", "content": "To quantify a comparative metric's ability to reflect the expected proximity between similarly trained models, compared to their dissimilarity with the untrained models, involves speculating the group statistics from the resulting similarity matrix. We employ the d' score defined as:\nd' = $\\frac{\\mu(A) \u2013 \\mu(B)}{\\sqrt{\\frac{\\sigma^2}{2} + \\frac{\\sigma^2}{2}}}$\nwhere A represents the set of similarity scores from intra-group comparisons, specifically the similarity scores between every pair of trained models. B represents the set of similarity scores from inter-group comparisons, specifically the similarity scores between each pair of trained and untrained models. Equivalent to the set of entries located at the intersection of trained model rows and untrained model columns in the model-by-model similarity matrix of the metrics.\nA similarity metric with d' \u2265 0 of greater magnitude indicates a greater ability to separate trained models from untrained ones. A metric with d' = 0 or d' <0 indicates that there were no discernible difference in average similarity scores computed in \"trained model pairs\" and \"trained vs. untrained model pairs\", or that trained vs. untrained models exhibit even higher similarity than that among trained models.\nSimilarly, when examining architectural differences, A represents intra-group comparisons within Convolutional models, while B captures inter-group comparisons between Convolutional models and Transformers."}, {"title": "A.3 DATASET CONSISTENCY", "content": "To assess consistency across behavioral datasets, we used an M \u00d7 M correlation matrix, where M is the number of datasets. Each entry i, j represents the correlation between datasets i and j, derived from their downstream similarity matrices. Averaging these scores across all behavioral measures revealed high correlations, indicating consistent uniformity across most datasets."}, {"title": "A.4 REPRESENTATION SIMILARITY MATRICES", "content": "We include the Model-by-Model Similarity Matrix given by the 8 distinct representation measures. The scores provided are averaged across 17 datasets. For mutual k-NN, different neighborhood sizes (k) are included. Note that the \"1 \u2013 Procrustes\" score can range from (-\u221e, 1], whereas all other metrics yield scores within the range [0, 1]."}]}