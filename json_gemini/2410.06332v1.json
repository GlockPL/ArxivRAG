{"title": "Boolean Nearest Neighbor Language\nin the Knowledge Compilation Map", "authors": ["Ond\u0159ej \u010cepek", "Jelena Gli\u0161i\u0107"], "abstract": "The Boolean Nearest Neighbor (BNN) representation of Boolean func-\ntions was recently introduced by Hajnal, Liu and Tur\u00e1n [13]. A BNN\nrepresentation of f is a pair (P, N) of sets of Boolean vectors (called posi-\ntive and negative prototypes) where $f(x) = 1$ for every positive prototype\n$x \\in P$, $f(x) = 0$ for all every negative prototype $x \\in N$, and the value\n$f(x)$ for $x \\notin P \\cup N$ is determined by the type of the closest prototype.\nThe main aim of this paper is to determine the position of the BNN lan-\nguage in the Knowledge Compilation Map (KCM). To this end, we derive\nresults which compare the succinctness of the BNN language to several\nstandard languages from KCM, and determine the complexity status of\nmost standard queries and transformations for BNN inputs.", "sections": [{"title": "Introduction", "content": "Boolean functions constitute a fundamental concept in computer science, which\noften serves as the backbone of computation tasks and decision-making pro-\ncesses. Their significance extends across diverse domains including circuit de-\nsign, artificial intelligence and cryptography. However, as the complexity of sys-\ntems increases, the need for efficient representation and manipulation of Boolean\nfunctions becomes more and more important. There are many different ways\nin which a Boolean function may be represented. Common representations in-\nclude truth tables (TT) (where a function value is explicitly given for every\nbinary vector), list of models (MODS), i.e. a list of binary vectors on which the\nfunction evaluates to 1, various types of Boolean formulas (including CNF and\nDNF representations), various types of binary decision diagrams (BDDs, FB-\nDDs, OBDDs), negational normal forms (NNF, DNNF, d-DNNF), and Boolean\ncircuits."}, {"title": "Definitions and Recent Results", "content": "Throughout this paper, we make use of the following notation and notions:\n\u2022 the symbol B denotes the set {0,1} and $B^n$ denotes the Boolean hypercube;\n\u2022 by $d_H(x,y)$ for $x \\in B^n$ we denote the Hamming distance in the Boolean\nhypercube, i.e. the number of coordinates in which x and y differ;\n\u2022 by $d_H(x, A)$ for $x, y \\in B^n$ and $A \\subseteq B^n$ we denote $\\min\\{d_H(x, y) | y \\in A\\}$;\n\u2022 by $|x|$ for $x \\in B^n$ we denote the weight of x, i.e. the number of coordinates\nof x which are equal to 1;\nDefinition 2.1. A Boolean function in n variables is a function $B^n \\rightarrow B$. We\nsay that $x \\in B^n$ is positive vector or a model of f (resp. negative vector or a\nnon-model of f) if $f(x) = 1$ (resp. $f(x) = 0$).\nDefinition 2.2. We call a Boolean function f in n variables a symmetric func-\ntion if there exists a set $I_f \\subseteq \\{0,1,...,n\\}$ such that $f(x) = 1$ if and only if\n$|x| \\in I_f$.\nDefinition 2.3. The symmetric Boolean function in n variables with $I_f =\n\\{i \\text{ is odd } | 1 < i < n\\}$ is called the parity function and we will denote it by\n$PAR_n$."}, {"title": "Succinctness", "content": "In this section, we establish the position of the BNN language in the succinct-\nness diagram presented in KCM [10]. Let us start with a formal definition of\nthis notion.\nDefinition 3.1. Let $L_1$ and $L_2$ be two knowledge representations languages.\nWe say that $L_1$ is at least as succinct as $L_2$, denoted $L_1 \\leq L_2$, if and only if\nthere exists a polynomial p such that for every sentence $a \\in L_2$, there exists an\nequivalent sentence $\\beta \\in L_1$ where $|\\beta| \\leq p(|\\alpha|)$. Furthermore, $L_1$ is strictly more\nsuccinct than $L_2$, denoted $L_1 < L_2$, if $L_1 \\leq L_2$ but $L_2 \\nleq L_1$.\nWe begin our study\nof the relations concerning the BNN language by showing that BNN is strictly\nless succinct than BDD.\nTheorem 3.2. BDD < BNN.\nProof. For the non-strict relation BDD $\\leq$ BNN it suffices to show that there\nexists a polynomial p such that for every sentence $\\alpha \\in$ BNN, there exists\nan equivalent sentence $\\beta \\in$ BDD where $|\\beta| \\leq p(|\\alpha|)$. For any $\\alpha = (P, N)$,\nwe will construct such a a binary decision diagram $\\beta$. Let us assume that\n$P \\cup N = \\{p^1, ...,p^k\\}$ and let $x \\in B^n$. We build $\\beta$ in two steps:\n1. We construct a gadget which for two fixed prototypes $p^i$ and $p^j$ decides\nwhich one is closer to input x.\n2. We put a number of these gadgets together so that the prototype closest\nto x is found and its value outputted.\nFor a fixed $p^i, p^j \\in P \\cup N$, we\nconstruct a diagram $G_{i,j}$, as shown in Figure 3 for n = 3. The gadget first\ncompares each coordinate of x with the corresponding coordinate of $p^i$. Thus\nthe n + 1 nodes on level n + 1 of the gadget reflect the value $d_H(x,p^i)$ from\n$d_H(x,p^i) = 0$ on the right (in this case x = $p^i$) to $d_H(x,p^i) = n$ on the left\n(both vectors differ in every coordinate).\nConsider for an example the gadget in Figure 3 with x = (1,0,1) and $p^i =$\n(0,0,1). In the first three coordinated comparisons, we take the edges labelled\nN, Y and Y. As only one coordinate differs, on level 4 we know that the value\nof $d_H(x, p^i)$ is 1.\nIn the next n levels (starting at level n+1), the gadget sequentially compares\ncoordinates of x with the corresponding coordinates of $p^j$. The comparisons\nstop as soon as it is decided which of $d_H(x, p^i)$ and $d_H(x,p^j)$ is smaller (e.g.\n$d_H(x, p^i) = n$ and $x_1 = p^i_1$ already implies $d_H(x,p^j) > d_H(x,p^i)$ without testing\nthe remaining coordinates). As soon as the gadget determines which of the two\nprototypes $p^i, p^j$ is closer, it points either to the root node of a next gadget\n$G_{i,k}$ (if $p^i$ is closer to x) or $G_{j,k}$ (if $p^j$ is closer to x) for some k, or to one of\nthe terminals 0, 1 if the closest prototype was already determined. In Figure 3\nthe corresponding directed edges go to the index of the closer prototype. The\ngadgets can break ties $d_H(x,p^i) = d_H(x,p^j)$ arbitrarily (tie is achieved at the\ntwo edges in the center of the bottom level), since the aim is to find one of the\nnearest prototypes, and those must all necessarily belong to the same class, by\nthe definition of BNN.\nContinuing with the example above, consider $p^j = (0,0,0)$. Then the edges\nvisited in the bottom half of the gadget have labels N, Y and N, we have\n$d_H(x, p^j) = 2$, and the gadget outputs the index i of the prototype closer to x.\nSince our aim is to construct a BDD, we must somehow convert the compar-\nison nodes in the gadget to standard decision nodes. However, this is of course\neasy. Each gadget is defined for fixed prototypes, so there is an obvious way\nhow to convert the Y and N labels on the outgoing edges from a $x_k = p^i_k$ node\ninto 0 and 1 labels from a decision node on variable $x_k$, as depicted in Figure 4\nfor k = 2.\nIt now remains to build the output BDD $\\beta$ using the gadgets. We can\nsequentially test pairs of prototypes until the closest one is found. We do so\nby making a triangle shaped acyclic directed graph made of gadgets with k - 1\nlevels. At level i, prototype $p^{i+1}$ is compared with every $p^j$ for $j < i$, and\ndirected edges are pointed to appropriate gadgets on the next level. After level\nk-1, a closest prototype has been determined, and so the directed edges going\nout of these gadgets point to terminal 1 (resp. 0) depending on whether the\nfound closest prototype is positive (resp. negative). The output BDD $\\beta$ for a\nfunction with k prototypes is shown in Figure 5.\nWe now show that the constructed BDD $\\beta$ is of polynomial size with respect\nto $|\\alpha|$ = kn. For vectors of length n, each gadget consists of $(n+1)2^{-1} = O(n^2)$\ndecision nodes. As there are k prototypes in $\\alpha$, BDD $\\beta$ consists of $(k \u2212 1)k =$\n$O(k^2)$ gadgets. Hence the size of the constructed BDD $\\beta$ is $O(n^2k^2) = O(|\\alpha|^2)$,\nas desired.\nThis finishes the proof of BDD < BNN. To show that the inequality is\nstrict, it suffices to consider the parity function f on n variables. It has a\nunique BNN representation with $2^n$ prototypes by Theorem 2.7. On the other\nhand, it is well-known [18] that f admits a BDD representation of size O(n).\nWe now continue with proving the remaining two strict inequalities in Fig-\nure 2 which tie the BNN language to languages MODS and \u00acMODS.\nProposition 3.3. BNN < MODS.\nProof. We first show that BNN < MODS. Consider a Boolean function f with\na set of models $M \\subseteq B^n$ where $|M|$ = m. Define\n$(P, N) = (M, \\delta(M)).$\nWe claim that (P, N) is a BNN representation of f with size polynomial in mn,\nwhich is the number of bits to store M.\nSince all models of f are prototypes in P it suffices to check non-models\nto verify that (P, N) indeed represents f. Let x be an arbitrary vector such\nthat f(x) = 0. If $x \\in N$, then x is surely classified correctly. Consider $x \\notin N$\n(which implies $d_H(x, M) \\geq 2$) and let $z \\in P$ be a positive prototype closest to\nx. Clearly, any shortest path from x to z must pass through some $y \\in \\delta(M)$\nand thus through a negative prototype which is closer to x than z which means\nthat x is classified correctly.\nIn the worst case, all n neighbors of every model need to be picked as negative\nprototypes. Thus the constructed BNN (P, N) has at most m + nm prototypes\n(with n(m + nm) bits) which finishes the proof of BNN < MODS.\nTo see that the inequality is strict it suffices to consider the constant 1\nfunction on n-dimensional vectors which has $2^n$ models but can be represented\nby a single positive prototype (and no negative ones).\nCorollary 3.4. BNN < \u00acMODS.\nProof. The corollary follows by an argument analogous to the one for MODS\nwhere the constants 0 and 1 exchange their roles.\nNow we are ready to show that BNN is incomparable to both CNF and\nDNF.\nLemma 3.5. BNN < CNF.\nProof. It suffices to show that there is a Boolean function with CNF representa-\ntion of size polynomial in the number of variables, which cannot be represented\nby a BNN of polynomial size. We will prove that the family of functions defined\nby\n$f_n = \\bigwedge_{i=1}^{n} (x_i \\oplus y_i)$\n(where each $f_n$ is a function in 2n variables $\\{X_1,...,X_n, Y_1,..., Y_n \\}$ and $\\oplus$ is the\nXOR operator) has the desired property. Clearly, each $f_n$ has a CNF represen-\ntation $F_n$ of size O(n)\n$F_n = \\bigwedge_{i=1}^{n} (x_i \\lor y_i) \\land (\\neg x_i \\lor \\neg y_i).$\nOn the other hand, $f_n$ has $2^n$ models (for each i we can decide whether to\nsatisfy $x_i$ or $y_i$) and every model of $f_n$ is isolated (flipping a single bit falsifies\nthe corresponding XOR). Therefore any BNN representation of $f_n$ has at least\n$2^n$ prototypes by Corollary 2.10. It should be noted that this construction is a\nspecial case of the more general construction in [11] (Theorem 11).\nLemma 3.6. CNF < BNN.\nProof. Consider the majority function $g_n$ on n variables which can be repre-\nsented by a BNN of size O(n) by Theorem 2.7. On the other hand any CNF of\nthis monotone function must contain at least as many clauses as is the number\nof maximal false vectors of $g_n$ [8] which is of course exponential in n, and so the\nclaim follows.\nTheorem 3.7. BNN is incomparable with CNF.\nProof. We combine Lemma 3.5 and Lemma 3.6 and obtain the result.\nCorollary 3.8. BNN is incomparable with DNF.\nProof. To show that BNN < DNF consider the function $\u00acf_n$ where $f_n$ is as\ndefined in the proof of Lemma 3.5. After an application of DeMorgan laws, we\nobtain a DNF formula of linear size representing the function $\u00acf_n$. However,\nwe may repeat the argument from Lemma 3.5 for the negative vectors of $f$\nwhich are all isolated and conclude that an exponential number of negative\nprototypes is required. To show that DNF < BNN it again suffices to consider\nthe majority function. Any DNF of this monotone function must contain at\nleast as many clauses as is the number of minimal true vectors [8] which is of\ncourse again exponential in n.\nThe last two relations for BNN already follow for free.\nCorollary 3.9. BNN is incomparable with both IP and PI.\nProof. Consider the function $f_n$ and its CNF $F_n$ from the proof of Lemma\n3.5. Notice that not two clauses in $F_n$ are resolvable. Hence, $F_n$ is the IP\nrepresentation of $f_n$ (contains exactly all prime implicates of $f_n$), and BNN <\nPI follows. The opposite relation PI < BNN follows from the fact that CNN\n< BNN because the PI language is a subset of the CNF language.\nBy symmetric arguments, incomparability to BNN can be shown also for\nthe IP language.\nWe finish this section by a succinctness relation which does not appear in\nFigure 2 because it is just one half of an incomparability result between BNN\nand the OBDD language.\nProposition 3.10. BNN < OBDD."}, {"title": "Transformations", "content": "In this section we shall show that the BNN language unfortunately does not\nsupport any standard transformation from [10] except of negation, which is a\ntrivial transformation for BNN, and singleton forgetting, for which the com-\nplexity status remains open.\nObservation 4.1. BNN supports -C.\nProof. Since no ties are allowed, i.e. for every $x \\in B^n$ all prototypes nearest to\nx must be of the same type, then it follows that f is represented by BNN (P, N)\nif and only if \u00acf is represented by BNN (N, P). If (P, N) is a well defined BNN\nthen so is (N, P) and it can be of course obtained from (P, N) in polynomial\ntime.\nThe fact that BNN does not support CD and FO can be proved using the\nexponential lower bound for threshold functions from Theorem 2.7.\nTheorem 4.2. BNN does not support CD.\nProof. Let (P, N) be the smallest BNN representing the Boolean majority func-\ntion on n = 4k variables, for some $k \\in N$. That is, (P, N) represents the function\n$TH_{4k}^{2k}$ and $|(P, N)| \\leq \\binom{4k}{2k} + 2 = 2^{O(k)}$ holds by Theorem 2.7. Let $x_1,..., x_n$\ndenote the variables of the threshold function. Notice that by setting some vari-\nable $x_i$ to 1, i.e. conditioning on term T = $x_i$ we obtain a threshold function\nwhich has one variable fewer and threshold smaller by one.\nLet $T_k = x_1 \\land x_2 \\land \\ldots \\land x_k$ be a consistent term. Then $(TH_{4k}^{2k} | T_k) = TH_{3k}^{k}$.\nIt follows from Theorem 2.7 that in order to represent such a function, we need\na BNN of size $2^{\\Omega(3k)} = 2^{\\Omega(n)}$, and thus cannot produce it in polynomial time\nfrom the input (P, N) of size O(n).\nThe following lemma shows that for threshold functions conditioning (by a\npositive term) and forgetting work the same way producing the same result.\nLemma 4.3. For m, n \u2208 N, m \u2264 n consider the threshold function $f = TH_n^m$\nand let $i \\in \\{1,2,..., n\\}$ be arbitrary. Then\n$f|x_i = \\exists x_i.f(x_1,x_2,...,x_n)$.\nProof. From the proof of Theorem 4.2, we have that $f|x_i = TH_{n-1}^{m-1}$. Thus it\nsuffices to show that also $\\exists x_i.f(x_1,x_2,...,x_n) = TH_{n-1}^{m-1}$. By definition:\n$\\exists x_i.f(x_1,x_2,...,x_n) =$\n$f(x_1, x_2,..., x_{i-1}, 0, x_{i+1},...,x_n) \\lor f(x_1, x_2,..., x_{i-1}, 1, x_{i+1},...,x_n) =$\n$TH_{n-1}^{m} \\lor TH_{n-1}^{m-1}$\nNotice now that models of $TH_{n-1}^{m-1}$ form a subset of models of $TH_{n-1}^{m}$. We may\nthen omit $TH_{n-1}^{m}$ and hence $\\exists x_i. f(X_1,X_2,...,x_n) = TH_{n-1}^{m-1}$, as desired.\nTheorem 4.4. BNN does not support FO.\nProof. We combine Theorem 4.2 and Lemma 4.3. Again, $TH^{n/2}$ can be repre-\nsented by a BNN of size O(n), but we need a BNN of size $2^{\\Omega(n)}$ after forgetting\nthe first n/4 variables.\nFinally, we shall show that the BNN language does not support conjunction\nand disjunction even in the bounded case.\nTheorem 4.5. BNN does not support ABC.\nProof. Consider the (non-strict) majority function on 2n variables\n$(f(x_1,...,x_{2n}) = 1) = (\\sum_{i=1}^{2n} x_i \\geq n).$\nThis function has a BNN representation of size O(n) by Theorem 2.7. Further-\nmore consider the (non-strict) minority function on 2n variables\n$(g(x_1,...,x_{2n}) = 1) = (\\sum_{i=1}^{2n} x_i \\leq n).$\nBy a symmetric argument (just exchange 0 and 1 in the statement and proof\nof Theorem 2.7) this function again admits a BNN representation of size O(n).\nNow consider the function $f \\land g$\n$((f\\land g)(x_1,...,x_{2n}) = 1) = (\\sum_{i=1}^{2n} x_i = n).$\nThis function has exactly $\\binom{2n}{n} = 2^{\\Omega(n)}$ isolated models (flipping a single bit in\nany model produces a vector where the sum of coordinates is either n-1 or\nn+1 which is in both cases a non-model). It follows by Corollary 2.10 that any\nBNN representation of f \\and g has size $2^{\\Omega(n)}$.\nCorollary 4.6. BNN does not support VBC.\nProof. Consider the negations of functions f and g from the previous proof\n(those are in fact strict minority and strict majority on 2n variables). Since\nnegation preserves the size of BNN representations by Observation 4.1, both f\nand \u00acg have BNN representation of size O(n). However, $(\\neg f \\lor \\neg g) = \\neg(f \\land g)$\nand any BNN representation of this function has size $2^{\\Omega(n)}$ by the previous proof\nand the fact that negation preserves the size.\nThe above results show, that when it comes to transformations, the BNN\nlanguage is not a very good choice for a target compilation language. What\ndisqualifies BNN the most is (in our opinion) the fact that it does not support\nconditioning unlike all other knowledge representation languages considered in\n[10], [3], and [5]. Conditioning is an essential transformation that is needed in\nmany applications. In particular, if some of the variables are observable (and\nthe others are decision variables) then queries are often asked after some (or all)\nof the observable variables are fixed to the observed values (which amounts to\nconditioning on this set of variables and only then answering the query).\nThe complexity status of all standard transformations for BNN and selected\nstandard languages is summarized in Table 1. The only standard transformation\nfor the BNN language for which the complexity status remains open is singleton\nforgetting."}, {"title": "Queries", "content": "In this section we shall show that the BNN language supports a reasonably\nlarge subset of standard queries from [10]. We begin with a trivial observation\nthat both consistency and validity can be checked in constant time.\nObservation 5.1. BNN supports CO and VA.\nProof. For a BNN representation (P, N) consistency check is equivalent to check-\ning that P is non-empty while validity check is equivalent to checking that N is\nempty. Both of these checks can be done in constant time.\nNext we prove that implicant check is supported by the BNN language.\nTheorem 5.2. BNN supports IM.\nProof. Let f be a Boolean function and (P, N) its BNN representation. Let T =\nl1 \u2227...\u2227lk be a consistent term. Without loss of generality, we may assume that\n\u22001 \u2264 i \u2264 k : li \u2208 {xi, \u00acxi}, since otherwise we may relabel the variables. Our\naim is to design a polynomial time algorithm which checks whether T $\\models$ f.\nLet us denote by y \u2208 Bk the (partial) vector satisfying T, i.e. defined by $y_i$ = 1\nif li = xi and $y_i$ = 0 if $l_i$ = \u00acxi. Furthermore, let S denote the sub-cube of $B^n$\ndetermined by the vector y. That is,\n$S := \\{x \\in B^n | \\forall 1 \\leq i \\leq k: x_i = y_i\\}.$\nClearly, T$\\models$ f if and only if there is no negative vector of f inside S (i.e.\nafter fixing the values in y the resulting function is constant 1). We shall show\nthat this condition can be tested efficiently.\nIf there is a negative prototype in S (which is easy to check), we are done\nand T is not an implicate of f. If all negative prototypes are outside of S, let\nus denote by N' the set of projections of all negative prototypes into S:\n$N' := \\{proj_S(q) = (y_1,..., y_k, q_{k+1},..., q_n) | q \\in N\\},$\ni.e. $proj_S(q)_i = y_i$ for 1 \u2264 i \u2264 k and $proj_S(q)_i = q_i$ otherwise.\nIf there exists a negative prototype q which is at most as far from its pro-\njection projS(q) than any positive prototype, i.e.\n$\\exists q \\in N \\forall p \\in P : d_H(p, proj_S(q)) \\geq d_H(q, proj_S(q))$\nthen either there exists another negative prototype which is strictly closer to\nprojS(q) than q, or q is the closest negative prototype to projS(q) in which case\nthe above inequality must be strict for every positive prototype by the definition\nof BNN representation. In both cases f(projS(q)) = 0 follows, we have found\na negative vector of f in S, and thus we can again conclude that T is not an\nimplicate of f. Note, that this condition can be tested in polynomial time with\nrespect to the size of P for any fixed q and thus in polynomial time with respect\nto the size of (P, N) for all q.\nLet us now assume the opposite, namely that for every projS(q) \u2208 N' there\nexists a positive prototype p\u2208 P which is strictly closer to it than q:\n$\\forall q \\in N \\exists p \\in P : d_H(p, proj_S(q)) < d_H(q, proj_S(q))$\nWe claim that in this case there are no negative vectors of f inside S, and we\ncan conclude that T is an implicate of f. Let us assume for contradiction that\nthere exists such a vector x \u2208 S for which f(x) = 0. Let q be the closest negative\nprototype to x and let q' = projS(q) be its projection on S. Furthermore, let p\nbe the positive prototype closest to q'. Then\n$d_H(q, x) = d_H(q,q') + d_H(q',x) > d_H(p,q') + d_H(q', x) \\geq d_H(p, x),$\nThe first equality holds because $d_H(q, q')$ depends only on the first k coordinates\nwhile $d_H(q',x)$ depends only on the remaining coordinates. The first inequality\nfollows from the assumption and the second from the triangle inequality for\nHamming distance. However, $d_H(q, x) > d_H(p,x)$ implies f(x) = 1 which is a\ncontradiction.\nThe above discussion is summarized in Algorithm 1. The algorithm runs in\ntime O(n|P||N|) (which is polynomial in the size of the input n(|P| + |N|)), as\nits main part consists of two nested for loops. In the worst case, the algorithms\nconsiders all projections of negative prototypes, and calculates their distances\nto each of the positive prototypes.\nSince negation is trivial for the BNN language by Observation 4.1, we im-\nmediately get the following result for clausal entailment.\nCorollary 5.3. BNN supports CE.\nProof. Let f be a Boolean function and (P, N) its BNN representation. Let\nC = l1 \u2228 ... \u2228 lk be a consistent clause. Our aim is to design a polynomial\ntime algorithm which checks whether f $\\models$ C. Clearly (f$\\models$ C) =\n(\u00acC $\\Rightarrow$ \u00acf). Moreover, \u00acf is readily available (recall Observation 4.1), and\nby DeMorgan laws the negation of a clause C is a term T. So let T = \u00acC. Now,\nwe may check whether f entails C by calling Algorithm 1 for inputs \u00acf = (N, P)\nand \u00acC = T, getting the correct answer in polynomial time.\nIt is interesting to note that for most standard languages which support CE\nthis property stems from the fact that such languages support CD and CO.\nThe CE algorithm in these cases first performs the required conditioning, then\ntests consistency, and then outputs yes if and only if the partial function is not\nconsistent (i.e. identically zero). This is not the case for BNN as it supports\nCE despite of not supporting CD which is a rather unique combination of sup-\nported transformations and queries. We are not aware of any other knowledge\nrepresentation language that supports clausal entailment without supporting\nconditioning.\nThe fact that BNN supports clausal entailment also directly implies that\nBNN supports model enumeration.\nCorollary 5.4. BNN supports ME.\nProof. Models can be enumerated using a tree search such as the simple DPLL\nalgorithm where at every step before a value is assigned to a variable and a\nbranch to a node on the next level is build, it is first tested whether the current\npartial assignment of values to variables plus the considered assignment yields\na satisfiable formula (and if not then the branch is not build). This of course\namounts to a clausal entailment test. Therefore all branches of the tree that\nis built have full length (all variables are fixed to constants) and terminate at\nmodels. Thus both the size of the tree and the total work required is upper\nbounded by a polynomial in the number of models.\nA question whether BNN supports any of the other queries remains open.\nWe conjecture the remaining standard queries are hard, i.e. that there are no\npolynomial time algorithms for EQ, SE and CT (unless P=NP). The complex-\nity status of all standard queries for BNN and selected standard languages is\nsummarized in Table 2."}, {"title": "Conclusions", "content": "We have studied the properties of the BNN language introduced in [13] with\nrespect to the Knowledge Compilation Map. We have established succinct-\nness relations of this language to languages BDD, CNF, DNF, PI, IP, and\nMODS. The most interesting question that remains open are the relations of\nBNN to OBDD and FBDD. We conjecture that in both cases the languages\nare incomparable. Another open question is the succinctness relation of BDD\nto the languages added to the Knowledge Compilation Map in subsequent pa-\npers, namely to CARD, PBC, and SL languages.\nNext, we have studied the complexity status of standard transformations and\nqueries for the BNN language. Although it supports a decent subset of queries\nin polynomial time (CO, VA, IM, CE, ME) and hence it passes the necessary\ncondition for a target compilation language formulated in [10]\u00b9, we feel that the\nlack of supported transformations (only negation is supported), and in particular\nthe fact that conditioning is not supported in polynomial time, disqualifies the\nBNN from being a good target language for knowledge compilation. The open\nproblems left for future research is the complexity staus of the EQ, SE, and CT\nqueries and of the SFO transformation."}]}