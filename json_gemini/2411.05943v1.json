{"title": "Quantifying artificial intelligence through algebraic generalization", "authors": ["Takuya Ito", "Murray Campbell", "Lior Horesh", "Tim Klinger", "Parikshit Ram"], "abstract": "The rapid development of modern artificial intelligence (AI) systems has created an urgent need for their scientific quantification. While their fluency across a variety of domains is impressive, modern Al systems fall short on tests requiring symbolic processing and abstraction a glaring limitation given the necessity for interpretable and reliable technology. Despite a surge of reasoning benchmarks emerging from the academic community, no comprehensive and theoretically-motivated framework exists to quantify reasoning (and more generally, symbolic ability) in Al systems. Here, we adopt a framework from computational complexity theory to explicitly quantify symbolic generalization: algebraic circuit complexity. Many symbolic reasoning problems can be recast as algebraic expressions. Thus, algebraic circuit complexity theory \u2013 the study of algebraic expressions as circuit models (i.e., directed acyclic graphs) \u2013 is a natural framework to study the complexity of symbolic computation. The tools of algebraic circuit complexity enable the study of generalization by defining benchmarks in terms of their complexity-theoretic properties (i.e., the difficulty of a problem). Moreover, algebraic circuits are generic mathematical objects; for a given algebraic circuit, an arbitrarily large number of samples can be generated for a specific circuit, making it an optimal testbed for the data-hungry machine learning algorithms that are used today. Here, we adopt tools from algebraic circuit complexity theory, apply it to formalize a science of symbolic generalization, and address key theoretical and empirical challenges for its successful application to Al science and its impact on the broader community.", "sections": [{"title": "Introduction", "content": "The ability to reason algebraically is often considered a hallmark of human intelligence\u00b9. The recent evolution of modern artificial intelligence (AI) systems and large language models (LLMs) has led to the speculation that these systems may also reason algebraically2\u20134. Yet due to challenge of evaluating large models trained on massive pretraining datasets, it is difficult to evaluate whether such models are truly exhibiting algebraic reasoning abilities, or whether they instead regurgitate plausible text from their pretraining data 6,7. This ambiguity has led to a deluge of symbolic reasoning benchmarks 8\u201317. Despite these efforts, objectively quantifying the complexity of reasoning problems is difficult; most of these experiments are ad hoc, and designed without a framework to quantify complexity. However, approaches in computational complexity theory, a field within theoretical computer science, have made it possible to explicitly measure a problem's algorithmic difficulty, enabling the design of generalization tests rooted in quantifiable measures of complexity. Here, we adopt a branch of computational complexity theory - algebraic circuit complexity \u2013 to provide a parsimonious set of problems and approaches to rigorously study symbolic computation in machine learning.\nRecently, there has been increased interest in studying AI models through arithmetic and compositional tasks 9,12,18\u201327. Compositional tasks are problems that are generated by recombining a basis set of atomic elements to form a variety of task combinations. (Arithmetic problems are compositional; they are composed of atomic elements (numbers and operators), and can be recomposed to generate novel expressions and problems.) These tasks are good reasoning benchmarks because they require 1) abstraction, 2) logical application of rules or axioms, and 3) precise problem-solving and rigor. Critically, these paradigms have provided reliable ways to elicit failure modes in transformer-based AI models for specific forms of symbolic generalization. For example, a number of studies have demonstrated the difficulty of \u201clength generalization\" \u2013 generalizing to problems of longer length than seen during training 19,21,26,28. Hupkes et al.9 and Hupkes et al. 29 also introduced various notions (e.g., systematicity and productivity) in an effort to taxonomize different forms of linguistic generalization. While incredibly useful for linguistics, it is unclear how these concepts generically apply beyond natural language processing. By contrast, the formalisms from algebraic circuit complexity theory provide a set of parsimonious mathematical tools that can be applied to quantify symbolic generalization, and are agnostic to specific domains, such as linguistics. Moreover, algebraic circuit complexity theory provides an encompassing theoretical framework for the increasingly popular, yet nascent empirical evaluations in AI systems that use arithmetic tasks 18,19,21\u201324,30\u201335."}, {"title": "", "content": "A large class of symbolic problems can be studied with algebraic expressions 36,37. Algebraic circuit complexity theory formalizes algebraic expressions as circuit models (i.e., directed acyclic graphs; Fig. 1). This formalization is well-established in computational complexity theory, the branch of theoretical computer science concerned with quantifying the difficulty of computational problems and the resources required to solve them38. Importantly, formalizing computational problems in terms of circuits is the leading approach to empirically quantify their complexity. Unlike other notions of complexity, such as Kolmogorov Complexity in algorithmic information theory (which is incomputable), notions developed in complexity theory for circuits are explicitly computable and determined by their shape and structure39. Thus, the tools of algebraic circuit complexity can formalize notions of generalization by defining benchmarks in terms of their circuit properties. Furthermore, algebraic circuits are generic mathematical objects; they can be represented from a variety of mathematical perspectives (geometry, topology, etc.), providing useful interpretations in other domains. Algebraic circuits are therefore well-situated to addressing problems in symbolic machine learning \u2013 the problems are computable, large datasets can be straightforwardly generated from circuit specifications, and new models can be developed that address specific failure modes within this framework. In the ensuing sections, we provide a blueprint for the successful adoption of algebraic circuit complexity for machine learning problems; we introduce the core components of algebraic circuits, address how they can be leveraged to study symbolic generalization, and discuss several key open theoretical and empirical challenges."}, {"title": "Algebraic circuits", "content": "Algebraic circuit complexity studies algebraic expressions as computable circuit models. There has been a significant amount of recent machine learning research studying arithmetic generalization, a key symbolic ability. While important and insightful, most of those studies primarily focus on a restricted set of algebraic problems, which we will illustrate later 18,19,21,24,33. Below, we provide definitions of algebraic circuits that will place prior work within a broader mathematical framework. Our goal is to provide the tools to quantify model generalization through circuit complexity, rather than ad hoc goals such as, for example, \"length generalization\".\nDefinition. (For a more formal definition, see Shpilka and Yehudayoff 36 or B\u00fcrgisser et al. 37.) An algebraic circuit C represents a polynomial expression as a directed acyclic graph, comprised of gates v and edges e. Input gates, vx and VF, are respectively defined as either variables (e.g., X = {x1,...,Xn}) or elements in a field F (e.g., R). Input gates have fan-in (in-degree) of 0. All other gates are operators: a sum gate (v+) or a product gate (vx). Here we restrict the fan-in of operator gates to 2, as is standard36. For our purposes, this ensures that there is the same number of gates in a circuit model with its corresponding representation as a string of tokens, which simplifies downstream analyses (e.g., the analysis in Fig. 6). Operator gates have a fan-out (out-degree) of either 1 or 0. If the fan-out or an operator gate is 0, then it is the output gate of that polynomial.\nProperties. An algebraic circuit C has two main complexity measures: size s and depth d (see Table 1 for a summary of all properties). The size s of a circuit refers to the number of edges e in C. The depth d of a circuit refers to the longest path from an input gate to the output gate. We can denote a sub-circuit C, of C, which computes the polynomial f, rooted at gate v. Another important property of an algebraic circuit is its degree (i.e., the degree of a polynomial). The degree of a circuit (or a sub-circuit) can be computed by measuring the degree of the gate v, denoted deg(v). Elements in a field F are of degree 0, input variables x \u2208 X have degree 1, the degree of an sum gate (+) is determined by the degrees of its inputs u, v such that \n$deg(u+v) = max(deg(u), deg(v))$, and the degree of a product gate (\u00d7) is determined by $deg(u\u00b7v) = deg(u) +deg(v)$."}, {"title": "", "content": "Figure 1 provides a few simple examples of algebraic circuits. A circuit representation of an algebraic expression provides a concrete algorithm for computing a polynomial, with some circuits requiring more computation than others (e.g., determined by size or depth). Furthermore, a circuit description can provide explicit differences in required computation for polynomials that are mathematically equivalent (e.g., see Fig. 1C,D). Such a formalization can be useful to study how different representations of equivalent algebraic expressions can lead to different levels of generalization. The recent studies in arithmetic generalization in AI models focus on the simplest circuit representations of algebraic problems (problems analogous to Fig. 1A, but varying the magnitude of the field elements, e.g., train on small digit numbers, test on large digit numbers). The language of circuit complexity can provide more interesting and flexible ways to investigate generalization across circuit complexity classes."}, {"title": "Towards a science of generalization with algebraic circuits", "content": "A recent study concluded that LLMs' behavior is a function of the problems they are trained to solve25. It is difficult to identify what the \"problems\" are when the pretraining corpus is natural language text derived from the internet. A theoretically coherent alternative to quantify AI systems is to select problems where 1) difficulty is quantifiable, and 2) arbitrarily large datasets can be systematically generated. Algebraic circuits satisfy both of these constraints.\nThough recent papers have demonstrated an increased interest in using arithmetic tasks to quantify generalization, pre-liminary approaches have been theoretically limited. As alluded to above, many of the recent papers evaluating \"length generalization\" in arithmetic tasks train on two variable addition (or multiplication), and test on the same circuit class but sample field elements that are larger in magnitude (Fig. 2A)19\u201321,23,26,33,35. Others focus on a more complex form of generalization, i.e., addition or multiplication on problems with a greater number of variables, which is equivalent to increasing the circuit size and depth (Fig. 2B) (e.g., modular arithmetic task; Deletang et al. 30). While useful and informative, both these tests of generalization scratch the surface of generalization metrics that can be devised with algebraic circuits."}, {"title": "", "content": "Aa\u2081 + a2\nb\u2081+ b2\nBa\u2081+ ... + ak\na; E F\nb; \u2208 F\na << b\na \u2208 F\na\u2081 + ... + ak+l\na \u2208 F"}, {"title": "", "content": "Figure 2. Commonly-used AI evaluations for \u201clength generalization\u201d with arithmetic tasks. A) The predominant form of \u201clength generalization\" in transformers is evaluating performance on addition or multiplication problems with larger integers than seen during training 19\u201321,23,26,33. This would be conceptually equivalent to a situation in which the circuit size and depth are fixed, but the sampling of input gates (i.e., field elements) differs across training and testing sets. The notion of length generalization is specific to the context of transformers, given that larger digits require a larger context window. B) Another form of \"length generalization\u201d studied in the literature is to generalize to arithmetic problems with more operands (variables) than seen in the training set30. From a circuit complexity perspective, these two approaches are distinct problems."}, {"title": "The importance of learning composable functions", "content": "We first define symbolic generalization (Box 1), and consider the importance of learning algebraically (or compositionally). The ability to symbolically generalize is one of the most challenging problems in AI, and is a requirement for robust reasoning and planning. Like algebraic circuits, several prior papers formulated symbolic tasks as computing a path through a directed graph or circuit 11,13,24. Importantly, learning a symbolic task requires 1) decomposing and abstracting the individual functions (e.g., nodes) of a circuit, and understanding how they can be recomposed via edges to produce novel circuits (e.g., function composition). Algebra is a natural language to study symbolic generalization as it can be encoded as a circuit, and requires both abstraction and function composition. Moreover, in contrast to other compositional approaches (e.g., regular or context-free grammars; Deletang et al. 30, Chomsky 40), algebraic problems encompass an infinite vocabulary (e.g., R) with an expressive grammar determined by its axioms, making it well-suited for machine learning algorithms that require many training samples. In the following section, we propose a framework of generalization in terms of algebraic circuits."}, {"title": "Box 1. A formal sketch of symbolic generalization.", "content": "Let B be a basis set of elements. Let U\u2081 = B and Ui+1 = {u | (u1,u2 \u2208 U<i) & (u = u\u2081 0 u2)}, where o stands for any computable composition operator on U; (akin to production rules in context-free grammars or operations in a field). Then, we define some universe set\n$U = \\bigcup_{i \\in \\mathbb{N}} U_i$\nWe define a function (task) T on U such that T : U \u2192 R (see below for tasks T for algebraic circuits). T is a compositional function, where \u2200u1,u2 \u2208 U, T(u\u2081 0u2) = T (u\u2081) *T(u2), and * stands for any computable composition on R.\nLet Dtrain and Dtest be distributions over U, and supp(Dtrain|B) and supp(Dtest|B) to be the support of the basis set elements in Dtrain and Dtest, respectively. We restrict Dtest to be a distribution in which supp(Dtest|B) \u2286 supp(Dtrain|B). Additionally, if a composable function is represented in Dtest (i.e., u \u2208 Dtest and u = b10b2), then we require that is also represented in Dtrain. We include these as requirements for symbolic generalization; it would be challenging, if not impossible, to generalize to samples in Dtest if not all basis elements and composition operators were provided in Dtrain.\nWe define symbolic/compositional generalization as the evaluation of a learned model M (e.g., a neural network) where\n$Pr_{x \\sim D_{test}} [M(x) = T(x)] > 1 - \\varepsilon$\nHere, M is only optimized from samples x ~ Dtrain, and & is the evaluation error of M on x ~ Dtest. A strong form of symbolic generalization over algebraic circuits would be to satisfy Equation 1 for all valid partitions of Dtrain and Dtest (with the requisite support of basis sets and composition functions) in U for uniformly small values of \u025b.\nFor algebraic circuit problems, T : U \u2192 R can be a function that maps a circuit to: 1) a field element, e.g., r\u2208 R (in the case of circuit evaluation; Fig. 1); 2) {0, 1}, in the case of a classification task, such as polynomial identity testing (Fig 3A); 3) another circuit C (i.e, in the case of polynomial expansion or factorization; Fig 3B)."}, {"title": "Circuit divergence as a metric of generalization", "content": "The language of algebraic circuits provides quantitative metrics to formalize generalization. In particular, generalization of AI systems can be quantified in terms of circuit divergence \u2013 the divergence of circuit parameters between algebraic circuits employed during training and testing (Fig. 3). In other words, given a model M, we want to characterize its generalization performance M(Ctest|C), where Ctest is a test circuit, and 6 = {C1, ...,Ck} is a family of training circuits. We define circuit divergence as the difference between quantifiable circuit properties between train and test distributions. Here, we emphasize five important circuit properties to measure divergences: the sampling of a field F, the number of variables |X|, size s, depth d, and the polynomial degree. By quantifying the properties of circuits in both the training and testing sets, circuit divergence can be explicitly measured along these dimensions. In the following sections, we will provide several examples where tests of generalization can be constructed through the manipulation of circuit divergence."}, {"title": "Generalization benchmarks", "content": "In this section, we illustrate the flexibility of algebraic circuits in designing meaningful AI benchmarks. To demonstrate the generality of algebraic circuits, we begin by providing benchmarks that are analogous to popular tests of compositional"}, {"title": "Compositional generalization with algebraic circuits", "content": "There has been recent interest in using compositional paradigms to study the symbolic ability of machine learning mod-els 8,9,12,24,41\u201347. Here we demonstrate direct links to popular forms of compositional generalization using algebraic circuits.\nSystematic compositional generalization and regression. Systematic compositional generalization refers to the ability to recombine known basis elements into novel combinations of fixed sequence size (Fig 4A). This means that test sets of systematicity are limited to novel combinations of the same length as seen during training 8,9. The analog in algebraic circuits is to 1) sample a family of circuits & over a field F of a fixed size and depth, and 2) to generalize to circuits of the same size and depth, but differentially sampling input gates and/or operators. This can be implemented by choosing different samplers \u2013 P\u2081 and P2 - that differentially sample gates (Fig 4A). For example, the training set of circuits could be constructed with input gates a\u00a1 Ep\u2081 F, and the testing set of circuits could be constructed with the input gates bi \u2208p\u2082 F. (Note that when samplers choose bi >> ai, this is analogous to the common test of \"length generalization\u201d; Fig. 2A.)\nInterestingly, we note that successful systematic compositional generalization on input gates in algebraic circuit evaluations amounts to learning a distributionally robust regression model (e.g., Zhang et al. 48, Ghosh et al. 49). This is because a circuit of specific size and depth (e.g., as shown in Fig. 4A) expresses to a specific polynomial equation. Generalization on a"}, {"title": "", "content": "circuit class to a distribution shift of its input gates (e.g., field elements but not operator gates) would demonstrate successful out-of-distribution generalization.\nGeneralization within a circuit of fixed size and depth (systematicity)\na; Ep, F\nb\u2081 Ep, F\na; Ep\u2081 F\nu\u00a1 \u2208\u2081\u2081 {+, x}\nbi Ep\u2082 F\nV; \u2208 { +, x }"}, {"title": "Productive compositional generalization.", "content": "Productive compositional generalization refers to the ability to generalize to sequences of longer length. In the context of algebraic circuits, while systematicity focuses on keeping circuit size and depth fixed while manipulating gates, productive generalization focuses on manipulating circuit size and depth (Fig 4B). Thus, evaluating systematic and productive generalization can be studied together; measures of generalization can be quantified in a continuous manner by varying circuit parameters, such as gate samplers (systematicity), size (productivity), and depth (productivity). Understanding how each of these properties interact across training and testing sets will provide a comprehensive quantification of algebraic generalization.\nSince algebraic circuits are circuit representations of algebraic expressions, one can ask more generic questions about algebraic polynomials. For example: Given a class of polynomials as a training dataset, what other class of polynomials will this model be able to compute? Such a question goes beyond asking whether a model can systematically or productively generalize. Instead, it addresses a basic question that can leverage other rich mathematical subfields (e.g., geometry, topology) to quantify AI generalization. Algebraic circuits provides a flexible framework to formalize problem complexity beyond existing paradigms in compositional generalization."}, {"title": "Classification tasks: Polynomial identity testing", "content": "Prior work studying arithmetic abilities in transformer models have typically focused on computing simple expressions with field elements (a \u2208 F; e.g., 5+7 =?), rather than variables (x \u2208 X; e.g., 2x1 + x2+7). Including variables in an algebraic expression increases the polynomial degree (d > 1), thereby increasing its complexity and the need for abstractions. One"}, {"title": "Sequence-to-sequence tasks: Polynomial expansion or factorization", "content": "A wide application of generative models is in sequence-to-sequence transduction tasks. One particularly impactful use case is the development of AI models for code. AI models for code take in code as inputs (e.g., COBOL), and generate a translation of that code (e.g., Java). Despite its potential importance for modernizing many existing codebases, there is significant skepticism as to whether generative models trained with next-token prediction can reliably generate accurate code translations. This is due to the fact that programming languages are not dictated by autoregressive processes, and instead governed by symbolic rules.\nLearning on algebraic circuits provides a straightforward framework to evaluate the ability of models to learn sequence-to-sequence tasks that are governed by symbolic rules. For example, the problem of expanding or factorizing a polynomial is a problem that is governed by the axiomatic rules of algebra (Fig. 5B). Like code translation, this task requires transforming one sequence into another while maintaining mathematical equivalence (or for code, algorithmic equivalence). Importantly, there"}, {"title": "Mechanistic interpretability with algebraic circuits", "content": "A major issue in assessing symbolic generalization is the difficulty of interpreting what goes awry when they fail to generalize. This is partly due to the lack of interpretability of many benchmarks, which are often presented in natural language, and where the ground truth algorithms (e.g., circuit diagrams or parse trees) are not known 14,51. A more recent set of approaches in characterizing the interpretability of neural network representations rely on the design of carefully constructed tasks that have interpretable task components, such as ground truth parse trees or circuit diagrams 24,30,52. Algebraic circuits similarly provide ground truth interpretability. While the input to an AI model might be a string representation of a polynomial, that polynomial's circuit encoding provides its ground truth encoding. Such an encoding makes it easy to directly compare to the internal representations of a model, such as the attention weights within a transformer (Fig. 6). This makes it possible to ask if the internal representations of a transformer computes the algebraic expression similarly to its computable circuit encoding (the adjacency matrix of the graph) \u2013 the normative approach to computing polynomials. More broadly, the distance metric that computes the distance between attention weights and ground truth circuit edges (as shown in Fig. 6) can be used as a regularization term to encourage transformers to learn normative circuit computations, providing algorithmic and step-by-step information to the model. Overall, evaluating AI models on algebraic problems allows practitioners to adjudicate between theoretical models of circuit computation with modern AI computation."}, {"title": "Evaluating LLMs with algebraic circuits", "content": "We have introduced algebraic circuit tasks within the context of training models from scratch. While it is difficult to evaluate pretrained LLMs with precise levels of certainty due to the obscure nature of the pretraining data and optimization protocols, algebraic tasks can be still repurposed for LLMs. Prior work has demonstrated that LLMs typically fail on mathematical problems which require abstract reasoning on variables 7,25,53. Thus, if an LLM calls specific tools (e.g., calculators) which make computing circuits with only field elements too simple (e.g., those illustrated in Fig. 1 and 2, we can replace these with circuits containing variables x \u2208 X (i.e., those of degree \u2265 1)). For example, such tasks can include the aforementioned polynomial identity testing or polynomial expansion/factorization tasks, both of which can be made arbitrarily difficult and use arbitrary sets of variables/tokens."}, {"title": "Few-shot prompting", "content": "Figure 7. The algebraic generalization capability across circuit divergence metrics can be evaluated through few-shot prompting in LLMs. Given a set of question (left) and answer (right, A\u2081) pairs sampled from a specific circuit class CF1,X1,$1,d1 as prompts, we can ask an LLM to what degree it can generalize to algebraic problems sampled from a different circuit class CFkXk,Sk,dk"}, {"title": "Open theoretical and empirical challenges", "content": "Circuits provide a useful formalism to study generalization in AI systems. They are also a leading approach to quantifying the computational complexity of algorithmic problems. However, exactly how formal models of computation are related to AI generalization is broadly unexplored. Here we highlight three primary challenges associated with linking formal models of computation with AI generalization."}, {"title": "Circuit complexity and Al generalization", "content": "Algebraic circuit complexity studies the computational resources (in terms of circuit properties) required to evaluate polynomials. Though there are other metrics of complexity, such as Kolmogorov Complexity in algorithmic information theory 62,63, this measure of complexity is incomputable, as it requires searching over an infinite number of programs (though there are efforts in approximating Kolmogorov Complexity with alternative methods; Wyeth and Sturtivant 39, Johnston et al. 64, Dingle et al. 65). Thus, while circuits allow for the explicit computation of a problem, it remains unclear as to whether notions from circuit complexity will elegantly map onto notions of AI generalization. Nevertheless, given the lack of any framework to measure complexity in AI for symbolic ability, we believe that providing a general circuit complexity framework from which to design quantitative benchmarks (via circuit divergence measures) will be an important step towards building a science of symbolic generalization (e.g., see also Dziri et al. 24, Ram et al. 66). More broadly, an algebraic circuit approach offers extensive machinery to enable generalization through other algebraic tools, such as minimum spanning/basis sets, their decompositions, and more."}, {"title": "Extending formal models of symbolic computation to natural language and beyond", "content": "The types of algebraic problems we presented here are idealized problems that can be straightforwardly mapped to a circuit encoding. However, many real world problems that require algebraic ability are posed in natural language. Thus, applying a circuit complexity-theoretic approach for natural language problems requires parsing natural language into a circuit encoding, adding difficulty to the already challenging problem of generalizing across circuit complexities. It will be important for future work to design frameworks and benchmarks that require tests of algebraic generalization in terms of circuit divergence in natural language settings."}, {"title": "Algebraic representation learning in Al models", "content": "The standard approach to training AI models to perform algebraic or compositional tasks is to directly train them with input-output pairs. While algebraic circuits encode a specific algorithm by which to compute that polynomial (i.e., follow the edges from the input gates), it is possible that there are other viable algorithms to compute that polynomial. (For example, it could be possible that an algorithm first factorizes a sum of monomial representation prior to computing that simplified circuit.) More generally, it can be difficult to ascertain the conditions by which a learning system learns a correct and reliable algorithm to solve algebraic problems using only input-output pairs. Naturally, neurosymbolic approaches are often well-suited to learning algebraic and symbolic problems that are algorithmically reliable and sample efficient (e.g., Klinger et al. 45, Lake et al. 67, Poesia and Goodman 68, Trinh et al. 69). However, designing general purpose neurosymbolic models can be challenging. By contrast, though statistical machine learning models (e.g., transformers) are \u201cgeneral purpose\", the learning process is often obfuscated by learning dynamics that depend on architecture and complex optimization protocols. This makes it difficult to ascertain what computations and algorithms statistical systems learn. However, recent studies in compositional representation learning have suggested that different factors - such as choice of initialization and/or training curriculum can have a strong influence on whether a model learns compositionally41,70\u201373. In addition, developing techniques from the field of mechanistic interpretability provide new avenues from which to inspect whether the learned representations in an AI model are faithful to the hypothesized underlying algorithm (e.g., Fig. 6; Olsson et al. 56, Friedman et al. 74). Nevertheless, leveraging diverse methods to carefully investigate the algorithms that symbolic and statistical AI models learn will be important for their interpretability, reliability, and overall safety to ensure reliable deployment of AI systems.\""}, {"title": "Conclusion", "content": "Quantifying the algebraic ability of AI systems is difficult due to the lack of a theoretical framework from which to establish meaningful benchmarks. While there has been an increasing number of studies that have employed algebraic and compositional tasks to reliably elicit failure modes of transformers and LLMs, no mathematical framework exists to interpret these findings. Here, we provide a parsimonious framework \u2013 algebraic circuit complexity \u2013 to evaluate the extent of a model's algebraic generalization ability in terms of their circuit divergences. In contrast to other formulations of complexity, such as Kolmogorov Complexity, encoding algebraic problems as circuits provides an explicitly computable formulation. The rich expressivity of algebraic problems, the data-rich nature of producing algebraic datasets, and the close links with algebraic circuits to other mathematical fields, makes algebraic circuit complexity a fruitful approach to quantify symbolic generalization in AI systems. We hope this lays the theoretical groundwork for future studies to quantify algebraic generalization in modern AI systems."}, {"title": "Acknowledgements", "content": "We thank Marco Carmosino for helpful discussions on circuit complexity and symbolic generalization. We acknowledge funding support from the Exploratory Science Councils at IBM Research."}]}