{"title": "Privacy-Preserving Synthetically Augmented Knowledge Graphs with Semantic Utility", "authors": ["Luigi Bellomarini", "Costanza Catalano", "Andrea Coletta", "Michela Iezzi", "Pierangela Samarati"], "abstract": "Knowledge Graphs (KGs) have recently gained relevant attention in many application domains, from healthcare to biotechnology, from logistics to finance. Financial organisations, central banks, economic research entities, and national supervision authorities apply ontological reasoning on KGs to address crucial business tasks, such as economic policymaking, banking supervision, anti-money laundering, and economic research. Reasoning allows for the generation of derived knowledge capturing complex business semantics and the set up of effective business processes. A major obstacle in KGs sharing is represented by privacy considerations since the identity of the data subjects and their sensitive or company-confidential information may be improperly exposed.\nIn this paper, we propose a novel framework to enable KGs sharing while ensuring that information that should remain private is not directly released nor indirectly exposed via derived knowledge, while maintaining the embedded knowledge of the KGs to support business downstream tasks. Our approach produces a privacy-preserving synthetic KG as an augmentation of the input one via the introduction of structural anonymisation. We introduce a novel privacy measure for KGs, which considers derived knowledge and a new utility metric that captures the business semantics we want to preserve, and propose two novel anonymization algorithms. Our extensive experimental evaluation, with both synthetic graphs and real-world datasets, confirms the effectiveness of our approach achieving up to a 70% improvement in the privacy of entities compared to existing methods not specifically designed for KGs.", "sections": [{"title": "1 Introduction", "content": "Knowledge Graphs (KG) adopt a graph-based data model to represent knowledge in a variety of application scenarios characterized by a complex interaction of many entities. Currently, KGs are witnessing a growing industrial uptake,"}, {"title": "Example 1.1.", "content": "\u0441\u043e\u0442\u0440\u0430\u043f\u0443(\u0445) \u2192 control(x,x).\ncontrol(x, y), own(y, z, w), v = sum(w), v > 0.5 \u2192 control(x, z)."}, {"title": "Example 1.2.", "content": "holding(x) \u2190 control(x,y), x + y, count(y) \u2265 K."}, {"title": "Definition 3.1 (Neighborhood Attack Graph).", "content": "Given a KG (G,\u03a3), a Neighborhood Attack Graph (NAG) is the pair (G[X], \u03a3), where X \u2286 V is such that G[X] is weakly connected."}, {"title": "Definition 3.2 (KG-isomorphism).", "content": "Let (G, \u03a3) be a KG and let X,Y \u2286 V such that X \u2229 Y = \u00d8. We say that (G[X], \u03a3) and (G[Y], \u03a3) are isomorphic, denoted by (G[X], \u03a3) = (G[Y], \u03a3), if there exists a bijective function \u03a6 : X \u2192 Y, called KG-isomorphism, such that for all u, v \u2208 X it holds that\n|{\u03b5 \u2208 E(G[X]) : \u03c1(e) = (u, v)}| = |{e \u2208 E(G[Y]) : \u03c1(\u03b5) = (\u03a6(u), \u03a6(\u03c5))}|, (4)\n|{e \u2208 DG[X],\u2211 : p(e) = (u, v)}| = |{e \u2208 DG[Y],\u03b5: \u03c1(\u03b5) = (\u03a6(u), \u03a6(v))}|."}, {"title": "Definition 3.3 (Sensitive Attributes).", "content": "Given a KG (G, \u03a3) and v \u2208 V, we define the sensitive attributes of v as the triple:\n\u00a7 (v) = {l(v), d\u00e2n (v), dout(v)}, (6)\nmade of, respectively, its label, in-degree and out-degree."}, {"title": "Semantic Utility.", "content": "To satisfy R.2, we introduce two semantic utility metrics, which quantify the coincidence of the information in the original KG and in the released anonymised one. This is done on a use-case basis, by focusing the metrics on a set of queries."}, {"title": "Definition 3.4 (KG-Utilities).", "content": "Let (G, \u03a3) and (A, \u03a3) be two KGs on the same intensional component \u2211 and Q = {q1,...,qn} be a set of queries. We define the following utility metrics:\nU(G, \u03a3, \u0391, Q) := \\frac{1}{N} \\sum_{qeQ} \\frac{|q(G)\\cap q(A)|}{|q(G)|}, (7)\nU_{\u25b3}(G, \u03a3, \u0391, Q) := \\frac{1}{N} \\sum_{qeQ} \\frac{|q(G) \u25b3 q(A)|}{|q(G) \\cup q(A)|}, (8)\nwith the convention that if the denominator of a term is equal to zero, then the whole fraction is set to zero."}, {"title": "4 Privacy through (k,x)-Isomorphism", "content": "We now introduce our novel structural anonymisation approach for KGs, which we name (k, x)-isomorphism anonymisation. We require each induced subgraph of x vertices to have at least other (k-1) KG-isomorphic subgraphs with different edge weights and sensitive attributes. This guarantees that the NAG matches at least with k different induced subgraphs, each exhibiting different sensitive attributes, thus protecting the KG from de-anonymisation."}, {"title": "Definition 4.1 ((k,x)-isomorphism anonymisation).", "content": "Let (G,\u2211) be a KG with G = (V, E, L, \u03c1,\u03c9,l) weakly connected, n = |V|, and let k, x \u2208 N such that x \u2264 n and k \u2264 (m). Then a (k, x)-isomorphism anonymisation of (G,\u2211) is a knowledge graph (A, \u03a3) with A = (VA, EA, LA,PA, wala) such that:\n1. V \u2286 VA, E \u2264 E\u2081, Ve\u2208 E,pa (e) = p(e); [augmentation]\n2. LOL = \u00d8; [anonymisation of labels]\n3. w\u2084(e) \u2260 w(e) for all e e E; [anonymisation of weights]\n4. for all X1 < V_such_that |X1| = x_and G[X1] is weakly connected, there exist X2, X3,...,Xk\u2286 Va such that:\n(i) Xin X\u2081 = \u00d8 for all i,j \u2208 [k], i \u2260 j; [vertex-disjointness]\n(ii) (\u0391[\u03a71], \u03a3) = (A[Xi], \u03a3) through the isomorphism \u00dei, for all i \u2208 [k] with P1 = idx\u2081; [k-anonymity]\n(iii) \u03be (\u03a6\u03b9(\u03bd)) \u2260 \u03be\u2084(\u03a6\u2081(v)) for all v \u2208 X1, i,j\u2208 [k] with i \u2260 j. [k-diversity]"}, {"title": "Example 4.1.", "content": "control(x, y) \u2192 controlled(y)\ncontrol(x, y), not controlled(x) \u2192 ultimateC(x, y)."}, {"title": "Proposition 4.1.", "content": "Let (A, \u03a3) be a (k,x)-isomorphism anonymisation of a KG (G,\u2211) and suppose that \u2211(G)[X] = \u2211(G[X]) for all X < V(G). Then (\u0391,\u03a3) is a (k,x')-isomorphism anonymisation of (G,\u2211) for any x' \u2264 x ."}, {"title": "5 KLONE", "content": "Algorithm 1 introduces KLONE, our first method to obtain a (k, x)-isomorphism anonymisation of a KG. In particular, the anonymised graph A in output is a (k, x)-isomorphism anonymisation of the input KG for every x \u2208 [n]; in other words, A is robust to the NAG attack regardless of the NAG size. The anonymised graph is constructed by: (a) noising the edge weights of the original KG while optimizing the utility metric U\u25b3; (b) augmenting the KG to guarantee the k isomorphisms per each induced subgraph; (c) adding synthetic edges to reach diversity of in- and out-degrees; (d) anonymising the vertex labels (e) assign the weights to the synthetic edges while again optimizing U\u25b3.\nMore in details, (a) is performed in line 1, where the weights are chosen in way such that the utility U is minimized. Ideally, we would like the change of weights to completely preserve the output of the queries on the KG. This is done by the WeightNoising function in Algorithm 2, which randomly samples new weights for M times and chooses the ones that reach the smallest value of \u0418\u0434. Phase (b) is in lines 2-3. At this point, the graph A is the disjoint union of k copies of G, which guarantees that each induced subgraph is KG-isomorphic to other k-1 different subgraphs according to Definition 3.2. These copies are linked together in line 4 to guarantee that A is weakly connected. Phase (c) is addressed in lines 5-20. The for loop in line 5 iterates on the vertices of a copy of G while the for loop in line 7 iterates on the copies of G, such that v refers"}, {"title": "Lemma 5.1.", "content": "If the degree distributions pin and pout have support in [n], then the anonymised graph A output of Algorithm 1 is such that kn \u2264 |V(A)| \u2264 2kn+1."}, {"title": "Proposition 5.1.", "content": "Algorithm 1 returns a (k,x)-isomorphism anonymisation of the input Knowledge Graph for every x \u2208 [n]. Moreover, it runs in O(Mk2n2) time, under the hypothesis that the computation of the utility metric U\u25b3 is O(1) and the distributions pin and pout have support in [n]."}, {"title": "6 KGUARD", "content": "Algorithm 3 introduces KGUARD, our second proposed algorithm to obtain a (k, x)-isomorphism anonymisation of a KG. Our aim is to reduce the number of synthetic vertices and edges added by KLONE to reach the (k,x)-isomorphism anonymisation by leveraging the subgraph isomorphisms that already exist in the original KG. The anonymised graph is constructed by: (a) noising the edge weights of the original KG while optimizing the utility metric U\u25b3; (b) finding all the induced subgraphs of size x and bucketing them into KG-isomorphic classes; (c) selecting k subgraphs in each bucket to guarantee the k KG-isomorphisms and/or duplicating some of such subgraphs if the bucket has less than k elements; (d) assigning different in- and out-degrees to the vertices mapped into each other by the KG-isomorphisms to reach diversity; (e) adding the synthetic edges to meet the requested in- and out-degrees; (f) anonymising the vertex labels; (g) assigning the weights to the synthetic edges while optimising U\u25b3. Items (a), (f) and (g) are the same as in KLONE so we refer the reader to the previous section; they are in KGUARD respectively in line 1, line 31 and line 32. We now provide details of all the other items.\n(b) Subgraphs identification and isomorphism bucketing We first find all the weakly connected subgraphs of the KG induced by a set of x vertices (line 2, function ConnectedInducedSubgraphs)\u00b9 and gather them in H. Then,"}, {"title": "Proposition 6.1.", "content": "Algorithm 3 returns a (k,x)-isomorphism anonymisation (A, \u03a3) of the input knowledge graph (G,\u03a3), for chosen k, x \u2208 N with x \u2264 n and k\u2264()."}, {"title": "7 Experiments", "content": "In this section we evaluate KLONE and KGUARD for different KGs and reasoning tasks. We also compare our work against existing privacy preserving techniques for structural and neighborhood attacks, stemming from the classical k-anonymity [54]. To do so, we consider and extend the work of J. Cheng et al. [14] that provides anonymisation by forming k pairwise isomorphic subgraphs in the graph (k-isomorphism). The method guarantees that a subgraph-based attack fails, as the adversary finds k indistinguishable subgraphs. However, our experiments confirm that neglecting derived links still leads to privacy issues and leaks of information.\nDatasets Our first set of experiments considers two well-known random graph models: the Erd\u0151s-R\u00e9nyi and the Scale-Free network. For the Erd\u0151s-R\u00e9nyi graph, we consider the directed model D(n, M), where n is the number of vertices and M is the number of directed edges that are sampled uniformly at random among the n\u00b2 possible ones. We set M = nln(n)/2, which corresponds to the threshold for weakly connectivity in the limit n \u2192 +\u221e.\u00b2 Our algorithms works on weakly connected subgraphs, so if the input graph happens to be not weakly connected, we work on each of its components separately. In this model the in- and out- degree distribution is binomial (Poisson in the limit), thus making vertices with very large out-degree, called hubs, unlikely to appear. For the second model we consider instead a random graph where the out-degree profile of each vertex is randomly sampled from a truncated power-law distribution, i.e., for each vertex v:\nP(dout (v) = d) = \\frac{d^{-\u03b1}}{\\sum_{i=1}^{n-1} i^{-\u03b1}} if 0 \u2264 d < n, = 0 otherwise. (10)\nwhere a > 0 is a parameter. Low values of a correspond to a high probability of having nodes with large out-degree, while for high values of a almost almost all the vertices have small out-degree with high probability. A feature of graphs with such power law distributions (particularly when a is small) is the presence of hubs. These networks are called scale free [26, 8] and have been showed to model economics networks [20]. For both these models, to each edge is assigned a weight in [0,1] uniformly at random.\nLastly, we consider six different real-world graphs from the literature, namely the Company Ownership graph [43], MovieLens small [24], Econ-Mahindas [53], Infect-Dublin [53], Power-1138-Bus [53] and Bitcoin Alpha [38]. The Company Ownership KG focuses on Italian companies and has already been introduced in Section 2 and Figure 1; it plays an extremely important role for central banks and financial authorities to study and guarantee economic stability. The characteristics of the above mentioned graphs, such as the number of vertices and edges, are reported in Table 2.\nReasoning Tasks Differently from existing work, the algorithms KLONE and KGUARD are specifically designed to safeguard sensitive data from attackers who might exploit newly derived edges and embed a known subgraph structure into the KG to de-anonymized it. Consequently, our experiments incorporate three distinct reasoning tasks that generate these new derived edges. We employ"}, {"title": "Example 7.1.", "content": "own(x, y, w), x \u2260 y, w > 0 \u2192 reach(x, y)\nreach(x, z), own(z,y,w), x \u2260 y, z \u2260 y, w > 0 \u2192 reach(x,y). (11)\nwhere own(x, y,w) is an edge from entity x to y of weight w."}, {"title": "Example 7.2.", "content": "owns(x, y, w), x \u2260 y, k = sum(1, (y)), k \u2265 2 \u2192 2-owns(x) (12)\nowns(x, y, w), x \u2260 y, k = sum(1, (y)), w > q, k \u2265 2 \u2192 2q-owns(x) (13)\nwhere (12) selects all the vertices of the KG with at least 2 out-going edges, and (13) selects all the vertices of the KG with at least 2 out-going edges with weight greater than q. We set q = 0 for all the considered networks but the economics networks, for which q = 0.5, as it is the threshold for establishing control."}, {"title": "7.3 State-of-the-Art Comparison", "content": "We investigate the privacy of our approaches compared to existing work, specifically the work of J. Cheng et al. [14] to which we refer as k-Iso. This method anonymizes graphs by forming k pairwise isomorphic subgraphs, making them indistinguishable to an adversary. However, as we qualitatively showed in Figure 2, neglecting derived links in KGs results in severe privacy issues and information leaks. In Table 3, we quantitatively evaluate the impact of derived edges using a d-anonymity metric for x=4 and k=3. We recall that such metric measures the percentage of isomorphic subgraph structures that are not uniquely identifiable. The table confirms our theoretical analysis: our approaches anonymise each individual subgraphs, and consistently achieve 8 \u2013 anonymity = 1.0. Contrarily the state-of-the-art approach k-Iso does not protect the privacy of all entities: in the worst case (Bitcoin-Alpha) only 60% of subgraphs are effectively not uniquely identifiable, leaving 40% of potentially identifiable entities by an attacker. The best case for the state-of-the-art algorithm is the Infect-Dublin network, which is less impacted by privacy leaks from derived edges, due to its simple structure and the absence of edge weights.\nAnalytical comparison. In Table 4 we summarize the performance of our anonymisation algorithms on the knowledge graph G against various levels of the attacker's knowledge and we compare it with the existing work. The attacker"}, {"title": "8 Related Work", "content": "Several definitions of privacy have been proposed over the years, ranging from traditional syntactic privacy definitions [54], to more recent semantic privacy definitions like differential privacy [32, 48, 33, 18]. In the last years, traditional anonymization concepts originally developed for relational databases [11, 31] have been extended to graph data, including models such as t-closeness, k-degree, and k-neighborhood anonymity [47, 52]. These approaches fall under the category of structural anonymization, which involves altering the graph structure to preserve privacy. For example, the k-degree anonymity [36, 12] ensures privacy by selectively adding or removing edges in the graph. However, these methods targets specific graph types like directed [37, 12] or weighted graphs [41], and when applied to KGs they can expose sensitive data as they neglect the implications of newly derived knowledge (see Figure 2). On the other hand, differential privacy faces significant challenges when applied to highly correlated and network data [33]. Adding noise to nodes or edges often fails to conceal the overall structure and relationships within the data. While excessive noise can severely degrade data utility, making the synthetic KG and query results useless for a specific downstream task. These two limitations make differential privacy not directly suitable for our domain.\nSpecifically for KGs, only few anonymisation solutions exist [29, 28, 27], but with specific focus on the privacy of sequential publishing of data and their node attributes. Moreover, as we discussed, a novel challenge in disseminating KG financial data lies in ensuring the privacy of stakeholders while maintaining the utility (i.e. the embedded knowledge) of the graph [47]."}, {"title": "9 Conclusion", "content": "We discussed the application of privacy protecting schemes in the realm of Knowledge Graphs, focusing on scenarios where reasoning rules generate new knowledge in the form of derived edges. Our paper shows that existing work neglects such setting and may result in privacy issues. We propose a set of novel privacy requirements for KGs and we introduce two new anonymisation algorithms, KGUARD and KLONE, that generate synthetic variations of the input graphs, protecting sensitive data while preserving the utility of the graph for downstream tasks. Our experimental evaluation demonstrates the effectiveness of the proposed algorithms across well-known network models and real-world datasets. In particular, we show the superior performance of KGUARD in maintaining low utility loss and high fidelity to the original graph structures, making minimal changes to preserve privacy, while KLONE provides a consistent and reliable anonymization regardless of the subgraph size of the attacker knowledge, at the cost of introducing more redundancy. As future work, we envision to better investigate the split & merge procedure to speed-up computation and extend the diversity requirements beyond vertex labels and relationships."}]}