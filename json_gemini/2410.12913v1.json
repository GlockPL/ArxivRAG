{"title": "FAIR CLUSTERING FOR DATA SUMMARIZATION:\nIMPROVED APPROXIMATION ALGORITHMS AND COMPLEXITY INSIGHTS*", "authors": ["Ameet Gadekar", "Aristides Gionis", "Suhas Thejaswi"], "abstract": "Data summarization tasks are often modeled as k-clustering problems, where the goal is to choose k\ndata points, called cluster centers, that best represent the dataset by minimizing a clustering objective.\nA popular objective is to minimize the maximum distance between any data point and its nearest\ncenter, which is formalized as the k-center problem. While in some applications all data points can\nbe chosen as centers, in the general setting, centers must be chosen from a predefined subset of points,\nreferred as facilities or suppliers; this is known as the k-supplier problem. In this work, we focus\non fair data summarization modeled as the fair k-supplier problem, where data consists of several\ngroups, and a minimum number of centers must be selected from each group while minimizing the\nk-supplier objective. The groups can be disjoint or overlapping, leading to two distinct problem\nvariants each with different computational complexity.\nWe present 3-approximation algorithms for both variants, improving the previously known factor of 5.\nFor disjoint groups, our algorithm runs in polynomial time, while for overlapping groups, we present\na fixed-parameter tractable algorithm, where the exponential runtime depends only on the number of\ngroups and centers. We show that these approximation factors match the theoretical lower bounds,\nassuming standard complexity theory conjectures. Finally, using an open-source implementation,\nwe demonstrate the scalability of our algorithms on large synthetic datasets and assess the price of\nfairness on real-world data, comparing solution quality with and without fairness constraints.", "sections": [{"title": "1 Introduction", "content": "Data summarization is a fundamental problem for extracting insights from web data or other sources. Algorithmic\nfairness in data summarization is essential to ensure that the insights derived from the data are unbiased and accurately\nrepresent diverse groups. Consider, for example, a web image search for the term \u201cCEO.\u201d An algorithmically-fair\nresult should display a small subset of images of CEOs that accurately represent the population demographics. The\nsummarization task can be modeled as an instance of the k-center problem (k-CENTER), where images are data points\nand distances between images represent their dissimilarity. We need to find a subset of k data points-called cluster\ncenters that minimize the maximum distance from the data points to their closest center. These chosen cluster centers\nare then displayed as search results.\nA case of algorithmic bias is well documented when for the search query \u201cCEO\u201d, Google Images returned a much\nhigher proportion of male CEOs compared to the real-world ratio [20]. To address such bias, Kleindessner et al. [21]\nintroduced the fair k-center problem, where constraints are imposed to ensure that a minimum number of cluster centers\nof each demographic group are chosen. For example, if 70% of CEOs in the real-world are male, then for the search\nquery \"CEO\" that returns ten images, about three should feature images of female CEOs. Additionally, it is possible\nthat some images are of poor quality or contain inappropriate content and must be excluded from the search results.\nThis consideration leads to the fair k-supplier problem (FAIR-k-SUP), where the cluster centers must be chosen from\na specific subset of data points\u2014called facilities or suppliers\u2014while ensuring fair representation across groups and\nminimizing the maximum distance from the data points to their closest cluster center [6].\nMuch of the literature on fair clustering considers the demographic groups to be disjoint. However, this assumption\nis not realistic in modeling the real-world, where individuals belong to multiple groups, such as being non-binary,\nfrom minority ethnic groups, and/or economically disadvantaged, thus, forming intersecting demographic groups.\nIgnoring group intersections often overlook crucial nuances introduced by these intricacies and research has shown that\nintersecting groups often face greater algorithmic discrimination; for example, algorithms were less accurate for black\nwomen than for either black people or women individually [19]. To address intersectionality in clustering problems,\nThejaswi et al. [24, 25] introduced fair clustering problems, where demographic groups may overlap, and a minimum\nnumber of cluster centers must be chosen from each group while minimizing a clustering objective, either k-median or\nk-means.\nThejaswi et al. [24, 25] highlight that group intersectionality increases the computational complexity of fair clustering\nsignificantly. They prove that the problem is inapproximable to any multiplicative factor in polynomial time and show\ninapproximability even in special cases, such as when each group has exactly two facilities, when the underlying metric\nis a tree, and even when allowed to select f(k) cluster centers (for any computable function f) when asked for k cluster\ncenters. On a positive note, for intersecting facility groups, they presented fixed parameter tractable algorithms (FPT),\nyielding \u2248 (1 + 2)-approximation for FAIR-k-MEDIAN and \u2248 (1 + 2)-approximation for FAIR-k-MEANS. Although\n[24, 25] focus on complexity and algorithmic results for k-median and k-means objectives, these results can be directly\nextended to the fair k-supplier problem with intersecting groups.\nOur contributions. Our work focuses on the fair k-supplier problem, which is (informally) defined as follows. We are\ngiven a set of data points in a metric space that are grouped into (possibly intersecting) sets of clients and facilities. In\naddition, we are given a collection of groups (possibly intersecting) over the facilities, such as demographic groups\ndefined by a set of protected attributes. Furthermore, we are given a requirement vector specifying minimum number of\nfacilities to be chosen from each group, expressing the notion of fairness in the fair k-supplier problem. Finally, as it is\ncommon in clustering problems, we consider that the desired number of cluster centers, k is given. The objective is to\nselect a k-sized subset of facilities, which satisfies the group requirements while minimizing the maximum distance\nbetween any client to its nearest cluster center. The problem has two variants based on whether the facility groups are\ndisjoint or intersecting."}, {"title": "2 Problem definition", "content": "Before we present our approximation algorithms, let us formally define the fair k-supplier problem.\nDefinition 2.1 (The fair k-supplier problem) An instance of a fair k-supplier is defined on a metric space (U, d) with\ndistance function d : U \u00d7 U \u2192 R>0, a set of clients C \u2286 U, a set of suppliers (or facilities) F \u2286 U, an integer t > 1,\na collection G = {G1,...,Gt} subsets of suppliers Gi \u2286 F satisfying \\bigcup_{i \\in [t]} Gi = F, an integer k > 0, a vectors of\nrequirements \u00e5 = {x1,...,at}, where a\u1d62 \u2265 0 corresponds to group Gi. A subset of suppliers S \u2286 F is a feasible\nsolution for the instance if |S| \u2264 k and a\u1d62 \u2264 |S \u2229 Gi| for all i \u2208 [t], i.e., at least a\u1d62 clients from group Gi should be\npresent in solution S. The clustering cost of solution S is maxc\u2208c d(c, S). The goal of the fair k-supplier problem is to\nfind a feasible solution that minimizes the clustering cost.\nWhen the facility groups in G are disjoint, we denote the problem as FAIR-k-SUP-\u00d8. On the other hand, for the general\ncase, when the groups can intersect, we denote the problem as FAIR-k-SUP.\nRemark 2.2 For FAIR-k-SUP-\u00d8, note that \u2211i\u2208 [t] ai \u2264 k, otherwise the instance is infeasible. In fact, without loss of\ngenerality, we assume that \u2211i\u2208[t] ai = k. This is because if \u2211i\u2208[t] ai <k, then we can create a new (super) group\nGo = F with requirement ao = k \u2212 \u2211i\u2208[t] ai. Note that, we now have \u2211i=0 ai = k, and furthermore, the cost of\nevery solution in the original instance is same as its cost in the new instance and vice-versa.\nWe assume that U = CUF and we use |U| = n in the analysis of time complexity. Note that |C| = nc \u2264 |U| = n and\n|F| = nf < |U| = n, that is, both the number of clients and facilities are upper bounded by n."}, {"title": "3 Approximation algorithms", "content": "In this section, we present a polynomial-time 3-approximation algorithm for Fair-k-SUP-\u00d8 and prove that the\napproximation ratio is tight unless P = NP. Next, we extend our approach to provide a 3-approximation algorithm for\nFAIR-k-SUP in FPT(k + t) time and show that the approximation factor is tight assuming W[2] \u2260 FPT. Due to space\nconstraints, we provide only proof sketches in this section, with detailed proofs deferred to Appendix B.\nTheorem 3.1 There is a 3-approximation algorithm for the problem FAIR-k-SUP-\u00d8 with runtime O((kn +\nk\u00b2\u221ak) log n log k). Furthermore, assuming P \u2260 NP, no polynomial-time algorithm achieves (3 \u2013 \u0454)-approximation\nfor FAIR-k-SUP-\u00d8, for any \u0454 > 0.\nAlgorithm overview and comparison with previous work. Let us recall the 5-approximation algorithm of Chen et al.\n[6], which is based on the techniques introduced by Jones et al. [18]. They first solve k-SUPPLIER without fairness\nconstraints. Towards this objective, they find a subset F' of facilities that is 3-good \u2013 that is, every client is at a distance\n3 times the optimal cost from a facility in F'. They show that selecting the farthest clients iteratively for k steps and\nchoosing the closest facility for each selected client, gives a 3-good facility set F'. This approach is based on the idea\nof Hochbaum and Shmoys [14].\nHowever, the set F' may be an infeasible solution as it may not satisfy the fairness constraints. To satisfy fairness\nconstraints, Chen et al. [6] build \u201ctest-swaps\u201d in order to swap a subset of F', and use a maximal-matching framework\nto identify a \"fair-swap\u201d (a swap, which, if performed, will satisfy the fairness constraints). To accomplish this goal,\nthey identify a subset of suitable facilities from F' to replace. \u201cSuitable\u201d has a twofold interpretation: first it aims to\nminimize the number of facilities to replace, since each substitution may increase the objective function value; second,\nthe cost of each substitution should not be excessively high, so every \"suitable\" facility should be relatively easy to\nsubstitute with a nearby facility while also satisfying fairness constraints. They construct fair-swaps using a matching\nframework that introduces an additional factor 2 in the approximation, leading to a 5-approximation in polynomial time.\nIn contrast, our algorithm adopts a simpler approach (see Algorithm 1). Rather than finding a 3-good facility set in the\nfirst phase, we find a 2-good client set C', that is, every client is within distance twice the optimal cost from C'. This\nhas two advantages - first, instead of losing factor 3 by finding a 3-good facility set, we lose only factor 2. Second, we\ncan find a feasible solution from C' by losing only an additional factor in the approximation, rather than losing factor 2,\nas in [6]. This is obtained in the second phase using a matching argument.\nNow, we present the algorithm and give a sketch of its correctness."}, {"title": "Proof sketch of Theorem 3.1", "content": "Our pseudocode, described in Algorithm 1, takes an instance I = (C, F, G =\n{G1,...,Gt}, k, \u00e5) of problem FAIR-k-SUP-\u00d8. Fix an optimal clustering C* = {C\u2081....,C} for I corresponding\nto the solution F* = {f\u2081,..., fx }, and let OPT denote the optimal cost of F*. On a high level, our algorithm works in\ntwo phases. In the first phase, we find a set C' \u2286 C of k clients, called good client set, such that d(c, C') \u2264 2\u00b7 OPT,\nfor every c\u2208 C. Note that C' is not a feasible solution to our problem as it is a set of clients and not a set of facilities.\nHence, in the second phase, we recover a feasible solution using C', which incurs an additional factor of OPT in the\napproximation, yielding an overall approximation factor of 3.\nIn more detail, we construct the good client set C' by recursively picking a farthest client (breaking ties arbitrary)\nfrom C' and adding it to C' for k iterations (see the for loop at line 3). Let C' = (c1, ..., ck), where ci was picked in\niteration i \u2208 [k], and let C = (C1,\u2026\u2026, ci). We claim that d(c, C') \u2264 2 \u00b7 OPT for c\u2208 C. Towards this, we say that a\ncluster C* \u2208 C* is hit by C' if C \u2229 C' \u2260 (). Let \u0108\u2081, for i \u2208 [k], denote the optimal clusters hit by C = (c1, ..., ci).\nIf every cluster in C* is hit by C', then d(c, C') \u2264 2\u00b7OPT, as desired. Now, assume this is not the case, and hence C'\nhits some optimal cluster at least twice, as |C'] = k. Then, note that as soon as C hits an optimal cluster twice, for\nsome i \u2208 [k], the present set C is a 2-good client set. To see this, let l* \u2208 [k] be the first index such that \u0108e*+1 = \u0108e*,\nand let C \u2208 C* be the cluster hit by C'e* +1 twice \u2014 by ce*+1 and by some cj \u2208 C'e*. Then, for any c \u2208 C, we have\nd(c, C'e*) \u2264 d(ce*+1, C'e*) \u2264 d(ce*+1, cj) \u2264 d(ce*+1, f*) + d(f,cj) \u2264 2\u00b7OPT, since ce*+1 was the farthest client\nfrom C.\nHowever, as mentioned before, C' is not a valid solution. The goal of the algorithm now is to obtain a feasible set S\n(satisfying the group constraints) using C'. For ease of exposition, assume that every group Gj \u2208 G has a requirement\naj = 1. Suppose we know l* (it can be shown that a simple binary search on [k] is sufficient for recovering l*), then\nconsider the good client set C = (C1,..., Ce*). We obtain a feasible solution using C* as follows. Let \\* be the\nmaximum distance d(ci, F*) for ci \u2208 C*. We also assume that \u5165* is known (later, we show this can be obtained using\nbinary search on a set of size kn). Using C and \u5165*, we create a bipartite graph H = (C UG, E) (see Lines 12\u201314\nin Algorithm 1) where we add an edge (ci, Gj), for ci \u2208 C' and Gj \u2208 G, to E if there is a facility f \u2208 G; such\nthat d(ci, f) \u2264 X*. Next, we find a maximum matching M in H on C (Line 15). A key observation is that such a\nmatching exists in H since for every ci \u2208 Ce there is a unique facility in F* in a unique group in G at a distance at\nmost * from cr. This is based on the fact that C hits distinct clusters in C*. Once we have matching M on C, then\nfor every edge (ci, Gj) \u2208 M, we pick an arbitrary facility from Gj at a distance at most A* from ci \u2208 C*. Again, such\na facility exists due to the construction of H. Let S be the set of picked facilities. Then, note that, for any c \u2208 C, we\nhave d(c, S) \u2264 d(c, c\u2081) + d(ci, S) \u2264 2\u00b7OPT + 1* < 3\u00b7OPT, where ci \u2208 C'e is the closest client to c in C, and the\nlast inequality follows since >* < OPT. Finally, note that S may still fail to satisfy the group constraints since (i) M\nmay not match every vertex in G of H, and/or (ii) the requirements are larger than 1. But this can be easily handled by\nadding arbitrary facilities of each unmatched group to S.\nNow, to obtain A*, we can do the following. Let I denote the set of distances from each client in C to F. Note that\n|\u0413| \u2264 |F|l \u2264 nk. Since, A* is defined to be the largest distance of clients in C to F, we have that \u03bb* \u2208 \u0393. Finally,\nwe can do a binary search on the sorted I to find the smallest distance in I that returns a feasible matching on H.\nTime complexity. Naively iterating over all values of l \u2208 [k] and \u03bb \u2208 \u0393\" results in O(k\u00b3n\u00b2 + k\u00b3\u221ak n) time, instead\nwe adopt an efficient approach by employing binary-search over l \u2208 [k] and \u03bb \u2208 \u0393l. Although there are at most l \u00b7 n\ndistinct radii in Fe, it is not necessary to check if a feasible matching exists for each radius in Fl to find the optimal\nsolution *. Instead, binary search on sorted Fl is sufficient and can be done in log ln iterations. If a solution exists\nfor some radius > > >*, then we can reduce the radius to check for smaller feasible radii. Conversely, if no feasible\nsolution exists for a radius \u5165, we can discard all radii smaller than \u5165. Furthermore, by employing binary search on\nl\u2208 {1, ..., k} to find the maximum l* for which a feasible matching on {c1, . . ., ce} exists, reducing the number\nof iterations to log k. If a matching exists for some l and \u5165, a matching also exists for the same A and any smaller l.\nConversely, if no matching exists for a given l and \u5165, then no matching exists for any larger l for the fixed vale of A. The\npseudocode is available in Algorithm 1, where Line 6 is executed for log k iterations, and Line 8 sorts ln elements in\nO(ln log In), resulting in time complexity of O(kn log(kn) log k) for sorting. Further, Line 9 is executed for log(nl)\niterations, with the graph H in Line 14 constructed in O(nl) time, and the maximal matching takes O(k\u00b2\u221ak). Thus,\nthe overall time complexity is O((kn + k\u00b2 \u221ak) log n log k).\nHardness of approximation. It is known that [15] for any \u20ac > 0 there exists no 3 \u20ac approximation algorithm in\npolynomial time for k-SUPPLIER, assuming P \u2260 NP. When the number of groups t is equal to 1, FAIR-k-SUP-\u00d8 is\nequivalent to k-SUPPLIER and hence, the hardness of approximation follows.\""}, {"title": "Theorem 3.2", "content": "There is a 3-approximation for FAIR-k-SUP in time O(2tktn(kn + k\u00b2\u221ak) log n log k). Furthermore,\nassuming W[2] \u2260 FPT, there is no (3 \u2013 \u0454)-approximation for FAIR-k-SUP in FPT(k + t) time, for any \u0454 > 0.\nProof. The high level idea of our algorithm (see Algorithm 2) is to reduce the given instance I of FAIR-k-SUP\nproblem to many instances of the same problem but with disjoint groups such that the at least one instance with disjoint\ngroups has same cost as the optimal cost of I. Then, we apply Algorithm 1 on each of the reduced instances to find a\n3-approximate solution and return the solution T* corresponding to the instance that has smallest cost. By correctness\nof the reduction, T* is a 3-approximate solution to I.\nIn more details, we associate each facility f \u2208 F with a characteristic (bit) vector xf \u2208 {0,1}t, where the i-th index is\n1 if f \u2208 Gi and 0 otherwise. For each unique bit vector 7 \u2208 {0, 1}t, define Q(7) = {f \u2208 F : Xf = 7} as the subset\nof facilities with characteristic vector 7. The set P = {Q(7)}7\u2208{0,1}t forms a partition of F. Let F* be an optimal\nsolution to I, and let {71,\u2026\u2026\u2026,7} \u2286 {7}7\u2208{0,1}t be the k-multiset of bit vectors corresponding to the facilities in\nF*. Since F* is feasible, we have \u2211i\u2208[k] 7 \u2265 \u00e5 (element-wise). Hence, if we could find {71,\u06f0\u06f0\u06f0,7}, then we can\ncreate an instance J of FAIR-k-SUP with disjoint groups {Q(71), ..., Q(7)} and run Algorithm 1 on J (see Line 9)\nto obtain a 3-approximate solution T for J. Note that T is also feasible for I and hence a 3-approximate solution for\nI. However, since we do not know {71,...,7}, we enumerate all feasible k-multisets of P (see Line 6), and run\nAlgorithm 1 on the instances corresponding to the enumerated k-multisets. Finally, by returning the minimum cost\nsolution (see Line 10) over the all the instances, we make sure that the cost of the returned solution is at most the cost\nof T.\nTime complexity. The set P can be constructed in time O(2tn) since |P| \u2264 2t. There are (2*+k\u22121) possible k-multisets\nof P, and enumerating them and verifying that they satisfy the range constraints in \u00e5 takes O(2tktn). For each valid\ninstance, we apply Theorem 3.1 to obtain a 3-approximation, which takes O((kn + k\u00b2\u221ak) log n log k). Thus, the\noverall time complexity is O(2tktn(kn + k\u00b2\u221ak) log k log n).\nHardness of approximation. It is known that [11] there exists no algorithm that approximates k-SUPPLIER to\n3\n\u20ac factor in FPT(k) time, for any \u20ac > 0, assuming W[2] \u2260 FPT. When number of groups t = 1, FAIR-k-SUP\nis equivalent to k-SUPPLIER and the hardness of approximation follows by observing that FPT(k + t) = FPT(k),\nfor t = 1.\nSolving fair range clustering. In the literature, the problem variant with restriction on minimum and maximum number\nof facilities that can be chosen from each group is referred as fair range clustering. Our approach can be extended to\nobtain a 3-approximation for FAIR-k-SUP with both lower and upper bound requirements, where the number of chosen\ncluster centers from each group must be within the range specified by lower and upper bound thresholds. Suppose\n = {\u2081, ..., \u00df} represents the upper bound threshold, then, in Line 6 of Algorithm 2, we take into account both \u00e5\nand for computing the feasibility of the multiset considered in Line 5. Specifically, we change the If condition in\nLine 6 to the following.\nLine 6: If & \u2264 \u2211i\u2208[k] Vi \u2264 \u00df then\nIt is routine to check that the instances corresponding to these feasible multisets are, indeed, instances of FAIR-k-SUP-\u00d8.\nTherefore, we obtain a 3-approximation for this problem with same runtime."}, {"title": "4 Experiments", "content": "In this section, we present our experimental setup and datasets used for evaluation, and discuss our findings. The\nexperiments are designed to evaluate the scalability of the proposed algorithms against the baselines, and study the"}, {"title": "5 Related work", "content": "Our work builds upon the existing work on data clustering and algorithmic fairness.\nThe literature on (fair) clustering is extensive, so we focus on the most relevant research for our work. For a review\nof clustering, see Jain et al. [17], and for fair clustering, see Chhabra et al. [7]. k-CENTER and k-SUPPLIER have\nbeen widely studied and numerous algorithmic results are known [10, 11, 13, 15, 23]. Both problems are known to\nbe NP-hard [26], and polynomial-time approximation algorithms have been developed [10, 13, 23]. For k-CENTER\nand k-SUPPLIER, polynomial-time approximation algorithms with factors 2 and 3 are known [14, Theorem 5] [10,\nTheorem 2.2]. Assuming P \u2260 NP, k-CENTER and k-SUPPLIER cannot be approximated within factors of 2 \u2013 \u0454 and\n3 \u2013 6, respectively, for any \u20ac > 0 [14, Theorem 6] [10, Thoerem 4.3]. In the context of fixed-parameter tractability\n(FPT), k-CENTER and k-SUPPLIER are at least W[2]-hard with respect to k, meaning that no algorithm with running\ntime f(k) poly(n, k) can solve them optimally; this is implicit in a reduction presented by Hochbaum and Shmoys\n[14]. Assuming FPT \u2260 W[2], k-CENTER and k-SUPPLIER cannot be approximated within factors of 2 - \u20ac and 3\nfor any \u20ac > 0, in f(k)\u00b7poly(n, k) time, even when f(k) is an exponential function [11, Theorem 2, Theorem 3].\nFairness in clustering has recently attracted significant attention as a means to reduce algorithmic bias in automated\ndecision-making for unsupervised machine-learning tasks. Various fairness notions have been explored, leading to\nmany algorithmic results [1, 2, 5, 8, 9, 12, 22]. Our focus is on cluster center fairness, where data points are associated\nwith demographic attributes forming groups, and fairness is applied to the selection of cluster centers while optimizing\ndifferent clustering objectives such as k-median, k-means, k-center, and k-supplier. Several problem formulations study\ndifferent types of constraints on the number of cluster centers chosen from each group: exact requirement [18, 21],\nlower bound [24, 25], upper bound [5, 12, 22], and combined upper and lower bound [3, 16].\nIn the context of fair data summarization, much of the existing literature focuses on the case where demographic\ngroups are disjoint. Kleindessner et al. [21] introduced the fair k-center problem with disjoint groups, where a\nspecified (exact) number of cluster centers must be chosen from each group and the groups were explicitly disjoint.\nThey presented a 3.2t-1 approximation algorithm in O(nkt\u00b2 + kt\u2074) time, which was later improved to factor 3 in\ntime O(nk + n\u221ak logk) by Jones et al. [18]. Angelidakis et al. [3] considered a variant of FAIR-k-CENTER-\u00d8 with\nboth lower and upper bounds on number of cluster centers from each group and presented a 15-approximation in time\nO(nk\u00b2 + k5). Chen et al. [5] studied the matroid k-center-\u00d8 problem that generalizes FAIR-k-CENTER-\u00d8, where the"}, {"title": "6 Conclusions, limitations and open problems", "content": "Conclusions. In this paper, we provide a comprehensive analysis of the computational complexity for FAIR-k-SUP\nin terms of its approximability. Specifically, for the case with disjoint groups, we present a near-linear time 3-\napproximation algorithm. For the more general case where the groups may intersect, we present a fixed-parameter\ntractable 3-approximation algorithm with runtime FPT(k + t). We also show that the approximation factors can not be\nimproved for both the problems, assuming standard complexity conjectures. Additionally, we rigorously evaluate the\nperformance of our algorithms through extensive experiments on both real-world and synthetic datasets. Notably, for\nthe intersecting case, our algorithm is the first with theoretical guarantees (on the approximation factor) while scaling\nefficiently to instances of modest size, where the earlier works with theoretical guarantees struggled to scale in practice.\nLimitations. Although our algorithm for intersecting groups scales to modest-sized instances, designing algorithms\nthat can handle web-scale datasets with millions to billions of points remains an open challenge. Limited experiments\non real-world data are insufficient to assess the cost of enforcing fairness constraints on solution quality (i.e., clustering\nobjective), as it depends on the specific instance as well as the use case. Drawing a more informed conclusion would\nrequire a detailed case study with domain-specific insights, which is beyond the scope of this work. Our focus is to\npresent approximation algorithms with theoretical guarantees for FAIR-k-SUP that also scale effectively to real-world\ndata.\nOpen problems. For FAIR-k-CENTER, while the lower-bound of FPT(k, t)-time approximation is 2, but our results\nimply a 3-approximation algorithm in FPT(k, t) time. An interesting open problem is to either improve the approxi-\nmation factor for FAIR-k-CENTER or to prove that no such improvement is possible. Similarly, for FAIR-k-SUP (and\nFAIR-k-SUP-\u00d8), improving the approximation factor for special metric spaces, such as Euclidean spaces, is also a\npromising direction. Finally, it remains an open question whether or not a linear time algorithm can be designed for\nFAIR-k-SUP-\u00d8."}, {"title": "B Proof of Theorem 3.1", "content": "Let OPT be the optimal cost of the input instance I to Algorithm 1. Fix an optimal clustering C* = {C\u2081....,C}\nto I corresponding to the solution F* = {f\u2081*, ..., f}. Consider C' = (c\u2081, ..., c\u2081) constructed at the end of the for\nloop in line line 3. We claim that d(c, C') \u2264 2\u00b7 OPT, for every c\u2208 C. Suppose c\u2208 C for all c\u00f3 \u2208 C'. In this\ncase, consider c \u2208 C such that c\u2208 C, and hence d(c, F*) \u2264 d(c, f*) < OPT. Therefore, d(c, C') \u2264 d(c,c) \u2264\nd(c, f) + d(f, c) \u2264 2\u00b7 OPT, by triangle inequality, and the fact that c\u2081, c\u2208 C. Now, suppose that there is C \u2208 C*\nsuch that CCC' = (), this means there exist C \u2208 C* such that |C \u2229 C'| \u2265 2 since both C' and C* are of size k. Let\nc\u2084, c\u00f3 \u2208 C \u2229 C' such that ca was added to C' before c\u00f3. Furthermore, let C\" = (c\u2081, \u2026\u2026\u2026, c\u00f3\u22121) be the set maintained by\nthe algorithm just before adding c\u00f3 to C'. Then, note that d(c\u00f3, C\") \u2264 d(c\u00f3, c\u2084) \u2264 2\u00b7OPT. Since the algorithm selected\ncf to be the furthest point from C\", it holds that, for any c\u2208 C, we have d(c, C') \u2264 d(c, C\") \u2264 d(c', C'') \u2264 2 \u00b7 OPT,\nas required.\nThe next phase of the algorithm obtains a feasible solution from C'. Towards this, the algorithm identifies (by binary\nsearch) the smallest index l* such that each point in Ce* \u22121 := (c\u2081, ..., c'e\u2217 \u22121) belongs to a unique cluster in C*, but\nCe* := (C1,..., c'e\u2217) does not have this property. Next, the algorithm (again using binary search) finds \u5165*, which is\ndefined as the maximum distance between any point in Ce* \u22121 and F*. With l* and \\* in hand, the algorithm constructs\na bipartite graph H = (V, E) a follows. The left partition of V contains a vertex for every point in C'e* \u22121,\nwhile the right partition contains aj vertices {G},..., Gas } for every Gj \u2208 G. For each c \u2208 C'e* -1 and Gj \u2208 G, add\nedges between the vertex c and all vertices {G},..., G} if there exists a facility in Gj at a distance X* from c (see\nlines 12-14). The following is the key lemma that is crucial for the correctness of our algorithm.\nLemma B.1 There is a matching in H on its left partition.\nProof For ease of presentation, suppose the left partition of H is denoted as C'\u00e9* \u22121 = (c1, ..., ce* \u22121). Then note\nthat |Ce* \u22121| \u2264 k = |G'|, where G' (line 12) is the right partition of H. Let F* = {f},..., f; } be the facilities in\nF* \u2229 Gj, for Gj \u2208 G. Now, consider point c \u2208 Ce* -1 and let f' \u2208 F be the optimal facility in F* that is closest\nto cf. Then, note that d(c, f;') \u2264 x*, by definition of \\*. Hence, there is an edge between vertex c and G in H.\nSince each c\u2208 Cl* \u22121 belongs to different cluster in C* and |C'e* \u22121| < |G'|, we have that there is a matching in H\non Ce*1, as desired.\nLet M be a matching in H* on its left partition. Let T\u2286 F obtained (at the end of the for loop at line 18) by taking\nan arbitrary facility from Gj, for every (c, G) \u2208 M. Then, note that d(c, T) < * < OPT, for every c\u00f3 \u2208 C'\u00e9*-1\nTherefore, d(c, T*) \u2264 3\u00b7 OPT, as required. Finally, we add as many arbitrary facilities from each G; \u2208 G to T\n(line 21) so that |T\u00a3* \u2229G;| = a;. This completes the proof."}]}