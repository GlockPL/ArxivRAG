{"title": "AIDE: Agentically Improve Visual Language Model with Domain Experts", "authors": ["Ming-Chang Chiu", "Fuxiao Liu", "Karan Sapra", "Andrew Tao", "Yaser Yacoob", "Xuezhe Ma", "Zhiding Yu", "Guilin Liu"], "abstract": "The enhancement of Visual Language Models (VLMs) has traditionally relied on knowledge distillation from larger, more capable models. This dependence creates a fundamental bottleneck for improving state-of-the-art systems, particularly when no superior models exist. We introduce AIDE (Agentic Improvement through Domain Experts), a novel framework that enables VLMs to autonomously enhance their capabilities by leveraging specialized domain expert models. AIDE operates through a four-stage process: (1) identifying instances for refinement, (2) engaging domain experts for targeted analysis, (3) synthesizing expert outputs with existing data, and (4) integrating enhanced instances into the training pipeline. Experiments on multiple benchmarks, including MMMU, MME, MMBench, etc., demonstrate AIDE's ability to achieve notable performance gains without relying on larger VLMs nor human supervision. Our framework provides a scalable, resource-efficient approach to continuous VLM improvement, addressing critical limitations in current methodologies, particularly valuable when larger models are unavailable to access.", "sections": [{"title": "1 Introduction", "content": "Visual Language Models (VLMs) have achieved impressive advancements in understanding and reasoning about visual content (Alayrac et al., 2022; Liu et al., 2023c; Fang et al., 2024). However, their continued improvement often hinges on knowledge distillation from larger, more capable models through approaches like instruction tuning (Liu et al., 2023a,c,b). While this approach has proven effective for intermediate-scale models, it introduces a significant limitation for the largest state-of-the-art systems: the absence of a superior model renders further enhancement infeasible. This \"chicken-and-egg\" problem stifles progress and raises a critical question: how can VLMs be improved when no superior models exist? Despite their general capabilities, VLMs often underperform in specialized tasks compared to domain expert models such as object segmentation tools or Optical Character Recognition (OCR) systems. For instance, models like Grounding DINO (Liu et al., 2023d) consistently outperform general-purpose VLMs (Yuan et al., 2021; Huang et al., 2023) in visual recognition tasks (Table 1). This observation suggests an alternative pathway: rather than relying on larger general models, VLMs can leverage the specialized capabilities of expert models for improvement (Shi et al., 2024).\nIn this paper, we introduce AIDE (Agentic Improvement through Domain Experts), a framework that enables VLMs to strategically collaborate with domain expert models to enhance their training data. As shown in Fig. 1. AIDE employs a four-stage workflow: (1) identifying instances requiring refinement, (2) invoking expert models for specialized outputs, (3) synthesizing these outputs with existing data, and (4) systematically integrating improved data points into the training process.\nWe validate AIDE 's effectiveness through extensive experiments on benchmarks such as MMMU (Xiang et al., 2024), MME (Fu et al., 2024), MMBench (Yuan et al., 2024), etc., showing that it achieves notable performance improvements using only off-the-shelf lightweight expert models. Unlike traditional methods, AIDE does not depend on access to larger models nor human supervision, making it a scalable and computationally efficient solution for advancing state-of-the-art VLMs."}, {"title": "2 Related Work", "content": "Knowledge Distillation. Traditional methods for improving VLMs rely on knowledge distillation (Wang et al., 2022), where a larger \"teacher\" model generates training data to enhance a smaller \u201cstudent\" model. While effective for intermediate-scale models (Liu et al., 2023c,a), this paradigm creates a dependency on the availability of superior models, which limits its applicability to state-of-the-art systems.\nSpecialized Models. Recent studies (Fei et al., 2024) highlight the superiority of domain-specific expert models in certain tasks. For example, object detection systems such as Grounding DINO and OCR models like PaddleOCR (pad) significantly outperform general-purpose VLMs in their respective domains (Yuan et al., 2021; Ren et al., 2024; Liu et al., 2023d). These findings underscore the potential of leveraging specialized models to complement the general capabilities of VLMs.\nData Synthesis and Augmentation. Existing methods for augmenting training data often involve the model generating synthetic examples (Liu et al., 2023a; Chen et al., 2023) or applying templates to initial human annotations for more truthful data (Chiu et al., 2024b,a). While this approach can enhance performance on specific benchmarks, it risks perpetuating the biases and limitations of the model, resulting in diminishing returns. In contrast, AIDE integrates external expert knowledge and the original samples into the data generation pipeline, enabling more robust and unbiased improvements."}, {"title": "3 AIDE Framework", "content": "The AIDE framework enables VLMs to autonomously improve by collaborating with domain expert models. It comprises two primary agents-Selector and Synthesizer\u2014and operates through three principal actions: Selection, Execution, and Synthesis. AIDEpresumes an existing base dataset as the environment for agents to interact with. Fig. 1 provides an overview of the AIDE pipeline.\nSelector. The selector serves two objectives, identify improvement candidates and match candidates with expert tools: the selector interacts with the base dataset and is presented with detailed information and functionalities of the expert tools and judge if any of the additional information the experts can provide may be beneficial to improve the quality of the data. If it is, then the selector will exercise the corresponding expert tool.\nSynthesizer. The Synthesizer integrates expert outputs with the original data to generate enhanced training examples. This process involves: (i) Aggregating information from multiple sources, i.e. the original instances and domain expert outputs; (ii) Resolving potential conflicts. E.g. between original instances and expert outputs. (iii) Producing richer and more coherent responses. By these instructions, we expect the new response s would inherently be richer and contain reasoning flavors."}, {"title": "3.1 Integration", "content": "After generating enhanced samples, the integration incorporates them back into the training pipeline. This involves filtering: ensures new formulations maintain sensible information along with the original instances to prevent model collapse."}, {"title": "4 Experiment", "content": "Setup. We evaluate AIDE using the Eagle-8B (Shi et al., 2024) as both Selector and Synthesizer, interacting with the Cambrian1-7M dataset for one iteration. Experiments are conducted on an NVIDIA A100 node with 8 GPUs. Note that the choice of Selector and Synthesizer can be adaptable and need not be the same.\nExpert Tool Choice. Two lightweight domain experts, PaddleOCR (pad) and Grounded-SAM (Ren et al., 2024), are employed. These tools complement the visual data-rich composition of Cambrian1-7M (Tong et al., 2024). AIDE is extensible to incorporate additional expert models for multimodal tasks.\nIntegration. We use simple heuristics like n-gram filtering, etc. because we use small-step prompting that we deem enough to maintain quality of new responses (Fig. 2 & Fig. 4), but AIDE can easily add verifiers to further enhance data generation quality (see Sec. 5 for discussions).\nResults. Table 2 shows that applying AIDE is able to improve on MMMU (Xiang et al., 2024) by 1.2%, MMBench (Liu et al., 2023e) by 0.77%, MME (Fu et al., 2023) by 52, Mathvista (Lu et al., 2024) by 1.1%, ChartQA (Masry et al., 2022) by 1.1% etc. These results (Saikh et al., 2022; Li et al., 2023) highlight AIDE 's effectiveness by using domain expertise for VLM improvement."}, {"title": "4.1 Ablations", "content": "Selector Choice. We evaluated variations in Selector strategies, including text-only LLMs and heuristic methods. Tab. 2 (row 2) shows that heuristic like synthesizing the instances that has \u2264 5 tokens is not comparable to using a VLM-selector, even though the heuristic would select much more instances for synthesis (2.5M vs 950k).\nSmall-step Prompting. In the synthesis step, we tried to directly prompt the VLM to generate more detailed responses and then put final answer at the end, but it often fails to do so (Fig. 2-mid). Fig. 2-last shows that it is effective to simply prompt the VLM with the whole information of the instance and with one task (e.g. just generate the reasoning). Even though the VLM knows the correct answers, slightly more complex prompt cannot achieve the desirable outcome.\nOriginals Retention. Tab. 2 shows that AIDE is able to provide improvements with or without the original turn (question, answer pair), suggesting the effectiveness of AIDE."}, {"title": "4.2 Analysis on AIDE-selected data", "content": "We analyze the VLM selected data points for improvement. Out of the 7M training instance, about 2M are text-only and 5M are multimodal. And of the multimodal training instances, around 950K were selected by VLM-Selector. We provide the breakdown of the 950K in Fig. 3. Detailed analysis of AIDE-selected data reveals interesting patterns in two directions, the proportions chosen among the 950k and proportions among the multimodal samples in Cambrian1. We observe that the majority (over 40%) of the selected are from synthdog, an OCR dataset, suggesting the Selector deems the quality of synthdog need most improvement. On the other hand, we analyze the percentage of the selected candidates compared to the original data by source from Cambrian1. Again, about 80% of the synthdog are chosen by the VLM selector for improvement. Arxivqa llavar, textvqa are also predominately selected. We suspect the Selector deems the quality of these document datasets need improvement and posit AIDE may serve as an alternative way to estimate the quality of a dataset through a VLM-as-a-judge approach."}, {"title": "4.3 Qualitative results", "content": "Figure 4 illustrates the comparisons between the original data instances and the enriched data instances by our AIDE workflow. The new responses provides more details and reasoning-flavored context than the original answers. These contextual enhancements (Chiu et al., 2024b) may explain AIDE's ability to improve the performances on various benchmarks (Tab. 2)."}, {"title": "5 Conclusions", "content": "We presented AIDE, an agentic framework enabling VLM improvement through domain expert models. Unlike traditional methods, AIDE offers a scalable, resource-efficient alternative to reliance on larger models. Our contributions include: (i) A novel approach to VLM enhancement without superior models. (ii) Demonstrated improvements across benchmarks like MMMU, MMBench, and SciQA. (iii) Detailed analysis of data selection strategies and their impacts.\nFuture work may explore adapting AIDE for preference optimization, generating new (question, answer) pairs and incorporating test-time inference techniques to further guarantee the quality of new data. These advancements aim to further refine synthesized data quality and broaden AIDE's applicability, paving the way for continuous VLM training paradigms."}, {"title": "6 Limitations", "content": "Although AIDE avoids the need for larger VLMs, integrating expert models and synthesizing enhanced data require additional computational resources. While we utilized lightweight models in our experiments, applying AIDE to large-scale datasets or in real-time settings may be constrained by computational costs. Optimizing selection heuristics and developing more efficient integration strategies could enhance scalability."}]}