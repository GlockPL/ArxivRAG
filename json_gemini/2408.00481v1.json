{"title": "HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization", "authors": ["Bolin Zhang", "Zhiwei Yi", "Jiahao Wang", "Dianbo Sui", "Zhiying Tu", "Dianhui Chu"], "abstract": "The unique diagnosis and treatment techniques and remarkable clinical efficacy of traditional Chinese medicine (TCM) make it play an important role in the field of elderly care and healthcare, especially in the rehabilitation of some common chronic diseases of the elderly. Therefore, building a TCM chatbot for healthcare application will help users obtain consultation services in a direct and natural way. However, concepts such as acupuncture points (acupoints) and meridians involved in TCM always appear in the consultation, which cannot be displayed intuitively. To this end, we develop a healthcare chatbot (HBot) based on a human body model in 3D and knowledge graph, which provides conversational services such as knowledge Q&A, prescription recommendation, moxibus-tion therapy recommendation, and acupoint search. When specific acupoints are involved in the conversations between user and HBot, the 3D body will jump to the corresponding acupoints and highlight them. Moreover, Hbot can also be used in training scenarios to accelerate the teaching process of TCM by intuitively displaying acupuncture points and knowledge cards. The demonstration video is available at https://www.youtube.com/watch?v=UhQhutSKkTU. Our code and dataset are publicly available at Gitee\u00b9.", "sections": [{"title": "1 INTRODUCTION", "content": "Online medical dialogue systems have been playing an increasingly important role [2] in healthcare and medical care, with increasing adoption of such chatbots by patients, caregivers, and clinicians. Chatbots support a more direct and natural way of human-computer interaction via text-based or voice-based communication methods, which makes them suitable for a variety of target groups from young children to the elderly [13] and is an ideal candidate in the healthcare field for remote interventions on patients after discharge. To this end, the amount of medical dialogue systems is rising, and they cover a wide range of categories include mental health, physical health, health information, patient assistance, physician assistance, cognitive or developmental health[14].\nHowever, the TCM-related dialogue system has received less attention. Existing works mainly focuses on TCM diagnosis of diseases [6], medical record management[12] and knowledge base construction[4], while they do not have the ability to communicate with humans in natural language. Since the acupuncture points and meridians involved in TCM always appear in the consultation, we hope to tell users the clear location of these acupoints in an intuitive way. Therefore, we develop a healthcare chatbot (HBot) based on a human body model in 3D and knowledge graph, which provides conversational services such as knowledge Q&A, prescription recommendation, moxibustion therapy recommendation, and acupoint search.\nThe user interface for this system is shown in Fig 1. The interface is divided into four parts: i)the top area is the navigation bar where users can search an acupoint visually, select registration or login page, and obtain API open capability. ii) the right area is the dashboard of 3D body where users can switch parts of the human body, zoom in&out and rotate the body, and click on specific acupoints iii) the left-top area is the dialogue frame where users can chat with HBot in text form and give instructions to operate the 3D body, and iv) the left-bottom area is the multimedia board where the pictures or videos related to acupuncture points and meridians will be displayed to help users understand the TCM-knowledge.\nThe main contributions are summarized as follows:\n\u2022 For the localization and display of acupoints involved in dialogues, we propose an interactive human body in 3D.\n\u2022 To support the consultation services, we construct a knowledge graph (TCM-KG) and annotate a document-level en-tity&relation extraction dataset in TCM.\n\u2022 Human evaluation results demonstrate the robustness of Hbot. Functions such as intent detection, entity&relation extraction, and knowledge query will be publicly released in our platform as open APIs."}, {"title": "2 SYSTEM ARCHITECTURE", "content": "The architecture of the HBot system is shown in Fig 2, where illus-trates an example of interaction flow. HBot contains 6 key modules, Interactive 3D Body, User Intent Detection, Entity&Relation Ex-traction, LLM Handler, LLM Wrapper, and Knowledge Graph Con-struction. User Intent Detection module first classifies user queries and the slot filling task will be finished by the entity extraction module. To achieve multi-turns of dialogue, the history of men-tioned entities and user intents will be be saved in a list for dialogue state tracking. According to the dialogue tracking history, the LLM Handler decides whether to trigger the module of Interactive 3D Body or retrieves from the knowledge graph (TCM-KG). Then, the execution result of LLM Handler will be fed into the LLM Wrapper to generate the response. Based on Knowledge Graph Construc-tion, the triples obtained from Entity&Relation Extraction will be imported into Neo4j for the knowledge growth of TCM-KG. The module of Interactive 3D Body will be activated when user give an instruction or the acupoints are involved in the conversation. These modules are described in detail in the following sections."}, {"title": "3 INTERACTIVE 3D BODY", "content": "To visually display the meridians and acupoints of the human, we constructed an interactive 3D model of the human body. Consid-ering compatibility of operating systems, simplicity of installation and diversity of interactions, we choose to embed our model into a web page and users can interact with the 3D body only through a web browser. Moreover, we pack the operations of the 3D body into javascript API for the developer to call. The implementation of the 3D body is the following steps:\n1. According to the State Standard of the Location of Acupoints[5], we manually make an adult male body and mark 409 acupoints by using 3D graphics software (blender).\n2.Using the GLTFLoader of three.js, the 3D object files (.glb and .hdr) of the body will be loaded in the web page for real-time ren-dering and displaying.\n3.Use the camera controller (controls.js) of three.js to implement 360-degree rotation of the model, switching, zooming and other operations.\n4.Using the event listener functions (onclick, onchange, onmouseover, etc) of Javascript, the switching of body components and the selec-tion and restoration of acupuncture points can be realized."}, {"title": "4 USER INTENT DETECTION", "content": "User Intent Detection is framed as a sentence classification task that aims to identify intents from human utterances, and plays the key role in dialogue systems[1]. However, training intent detection models relies upon a large set of user utterances paired with intents, which are predefined by the developers. In practice, the user will express new intents that may not be expected by the tested system, referred to as out-of-define (OOD) intents. To alleviate this issue, we propose a configurable intent detection process by applying three-phase: i)rule-based intent matching ii) model-based intent understanding and iii) similarity-based query searching.\nPhase I: an intent-table is maintained in the Redis database, where one predefined intent is mapped to 5 example utterances and the related regular expressions. We defined two types of intents: Body manipulation related (i.e. rotation, zoom in, zoom out) and dialog content related (i.e. asking about treatment, asking about symp-toms). When Hbot is running, the user utterance will be matched to a certain intent based on the regular expressions. If the match fails, Hbot will enter the second phase: model-based intent under-standing.\nPhase II: we applied the complex intent detection model Conco-ERNIE[17], which is effective for both multiple intents and implicit intent detection by exploiting co-occurrence patterns between con-cepts appeared in medical queries and user intents conveyed by these queries. Given a user query, Conco-ERNIE can predict the probability distribution of the utterance on 21 common medical intents. If the probability of each intent is less than the threshold (0.6), Hbot will enter the third phase: similarity-based query searching.\nPhase III: We collected a real question-and-answer corpus between patients and doctors (about 100k Q&A pairs) from medical online forum\u00b2. To ensure the quality of the corpus, we only select the Q&A pairs where the question has a bounty and the answer is adopted by the patient. To find the approximate answers, we trained a sentence embedding model SBERT[11] with siamese network ar-chitecture to calculate the similarity between the input sentence and each query in the corpus. Then, the answer to the query most similar to the input sentence will be returned to the user. Followed by [15], the positive samples of the input question are constructed through word repetition operation. Since entities(i.e. disease, symp-toms) appeared in the medical queries have a great influence on sentence semantics, we construct negative samples by randomly replacing the entities of the same or different types."}, {"title": "5 ENTITY&RELATION EXTRACTION", "content": "The task of entity extraction (similar to slot filling) is to identify entities in text with their corresponding type, which is a critical com-ponent in spoken dialogue systems[7]. BERT[3] with a CRF layer have been widely used in named entity recognition and achieved good performance. So we trained a BERT-CRF model to identify all all TCM-related entities in user utterances.\nThe task of relation extraction is to identify the relationship between entities from text[9], which is essential for the construction of TCM knowledge graph. Under the guidance of medical experts, we finely annotated a small-scale but high-quality document-level entity&relation extraction dataset (contains 270 documents, 5996 entities, 4685 relations) based on TCM books. Followed by [16], we treat relation extraction as a multi-label text classification problem. Given an entity pair (head, tail) and the evidence sentences that used to judge its relation, the spliced text of entity pair will be encoded as $e$ by BERT and the i-th evidence sentence will be encoded as $s_i$ by the same BERT. All the representations of evidence sentences $[S_1, S_2, .., S_k]$ will be fed into a Bi-GRU layer, then the final state vector $h$ of Bi-GRU layer and $e$ will be concatenated together and then use a softmax function to compute the probability for each relation type. The relation extraction model is shown as Fig 3 and the performance is shown in Table 1."}, {"title": "6 LLM HANDLER AND WRAPPER", "content": "Based on the prompt engineering, the LLM Handler utilize the large language model to choose the next action for the given dialogue history. To respond to users' medical questions, the LLM handler retrieves from two types of data sources: documents and knowl-edge graphs, in order to obtain text-based answers and entity-based answers respectively. The dialogue history, current user intent, and these two types of answers are input into the LLM Wrapper to generate a fluent answer that conforms to the user instructions. Essentially, our LLM wrapper is a RAG (Retrieval-Augmented Gen-eration) system that comprehensively utilizes knowledge from mul-tiple sources and of multiple types. The LLM adapted by both of these modules is ChatGLM3-6B 3."}, {"title": "7 KNOWLEDGE GRAPH CONSTRUCTION", "content": "Knowledge graph is a knowledge base that uses a graph-structured model to integrate data, which is the cornerstone of question an-swering system. To implement question answering in the domain of TCM healthcare, we construct a TCM-related knowledge graph through three steps: i) ontology modeling ii) instance injection and iii) knowledge growth.\nStep I: Followed by ontology development 101 [8], we create the ontology model in the domain of TCM. We first enumerated the important terms in TCM-ontology and defined their properties. Then we defined the relations between different terms. After that, TCM-ontology contained 12 types of entities, 8 types of relations and 20 types of properties.\nStep II: Since the entities and relations in the extraction dataset mentioned in Sec. 5 are annotated according to TCM-ontology, it is feasible to restored the knowledge triples aligned with the ontology from the dataset directly, and then injected them into the graph database (Neo4j) after deduplication. Through instance injection, we construct a handcrafted TCM domain KG with 37851 triples. Fig 4 shows a 3-hop subgraph of with facial paralysis (entity type is Disease) as the central node, where gray nodes represent symptoms, orange nodes represent human acupuncture points, purple nodes represent diseases and pink nodes represent moxibustion therapy.\nStep III: To obtain a larger-scale TCM-KG, we crawled more doc-uments from the National service platform for academic experience of famous TCM doctors, and used the entity&relation extraction model mentioned in Sec.5 to find more triples from these docu-ments. After manual proofreading, the correct triples are injected into Neo4j. The size of TCM-KG grows from 37851 triples to 48633 triples."}, {"title": "8 HUMAN EVALUATION", "content": "Followed by the methodologies of software testing [10], we con-ducted a&f testing against user requirements to determine whether HBot satisfies the acceptance criteria. a-testing performed to iden-tify all possible issues and bugs before releasing the final product to the end users. A total of 5 members in the development team conducted a-testing on HBot from three aspects: the feedback on 3D model operation, the accuracy of user instruction understand-ing, and the robustness of system at runtime. During a-testing, we executed 100 test cases and found 21 bugs, including 10 error feedbacks, 8 responses that did not satisfy instructions, and 3 sit-uations where the system could not run stably. After fixing these bugs, we hired 8 members of our lab to conduct \u1e9e-testing on HBot. These people were only informed of the system's features and did not grasp the development details, who can be regarded as end users. During \u1e9e-testing, each member was asked to give 15 differ-ent instructions to HBot in the form of text in the dialog box. Each instruction is recorded along with the corresponding feedback or response from HBot and the evaluation of user satisfaction. User satisfaction measures whether the feedback or response of HBot meets the expectations of users:\n\u2022 Bad: not at all as expected\n\u2022 Fair: as expected, with tolerable errors\n\u2022 Good: exactly as expected\n\u2022 None: no feedback or response was returned\nThe performance of HBot on a and \u1e9e testing is shown in Fig 5. After a round of bug fixes, the responses of HBot are generally more in line with user expectations. However, there are more cases where the user evaluation is none. This is because the testers are developers in a-testing and they know where the capability boundaries of the system are, while the testers in \u1e9e-testing often give instructions that are outside the scope of the domain (e.g. chat with them, amuse them and ask how much is the surgery). To continuously improve system performance, we developed the evaluation interfaces for end-user and the function of record collection. When the scale of the records is large enough, relevant modules in HBot will be updated offline by analyzing these records."}, {"title": "9 CONCLUSIONS", "content": "To provide TCM-related conversational services such as knowl-edge Q&A, prescription recommendation, moxibustion therapy recommendation, and acupoint search, we develop a healthcare chatbot (HBot). Based on an interactive human body in 3D, HBot supports the localization and display of acupoints in conversations. Moreover, we annotate an entity&relation extraction dataset and construct a knowledge graph in TCM to support the slot filling and knowledge retrieval functions of HBot."}]}