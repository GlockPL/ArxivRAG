{"title": "HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization", "authors": ["Bolin Zhang", "Zhiwei Yi", "Jiahao Wang", "Dianbo Sui", "Zhiying Tu", "Dianhui Chu"], "abstract": "The unique diagnosis and treatment techniques and remarkable clinical efficacy of traditional Chinese medicine (TCM) make it play an important role in the field of elderly care and healthcare, especially in the rehabilitation of some common chronic diseases of the elderly. Therefore, building a TCM chatbot for healthcare application will help users obtain consultation services in a direct and natural way. However, concepts such as acupuncture points (acupoints) and meridians involved in TCM always appear in the consultation, which cannot be displayed intuitively. To this end, we develop a healthcare chatbot (HBot) based on a human body model in 3D and knowledge graph, which provides conversational services such as knowledge Q&A, prescription recommendation, moxibustion therapy recommendation, and acupoint search. When specific acupoints are involved in the conversations between user and HBot, the 3D body will jump to the corresponding acupoints and highlight them. Moreover, Hbot can also be used in training scenarios to accelerate the teaching process of TCM by intuitively displaying acupuncture points and knowledge cards. The demonstration video is available at https://www.youtube.com/watch?v=UhQhutSKkTU. Our code and dataset are publicly available at Gitee\u00b9.", "sections": [{"title": "1 INTRODUCTION", "content": "Online medical dialogue systems have been playing an increasingly important role [2] in healthcare and medical care, with increasing adoption of such chatbots by patients, caregivers, and clinicians. Chatbots support a more direct and natural way of human-computer interaction via text-based or voice-based communication methods, which makes them suitable for a variety of target groups from young children to the elderly [13] and is an ideal candidate in the healthcare field for remote interventions on patients after discharge. To this end, the amount of medical dialogue systems is rising, and they cover a wide range of categories include mental health, physical health, health information, patient assistance, physician assistance, cognitive or developmental health[14].\nHowever, the TCM-related dialogue system has received less attention. Existing works mainly focuses on TCM diagnosis of diseases [6], medical record management[12] and knowledge base construction[4], while they do not have the ability to communicate with humans in natural language. Since the acupuncture points and meridians involved in TCM always appear in the consultation, we hope to tell users the clear location of these acupoints in an intuitive way. Therefore, we develop a healthcare chatbot (HBot) based on a human body model in 3D and knowledge graph, which provides conversational services such as knowledge Q&A, prescription recommendation, moxibustion therapy recommendation, and acupoint search.\nThe user interface for this system is shown in Fig 1. The interface is divided into four parts: i)the top area is the navigation bar where users can search an acupoint visually, select registration or login page, and obtain API open capability. ii) the right area is the dashboard of 3D body where users can switch parts of the human body, zoom in&out and rotate the body, and click on specific acupoints iii) the left-top area is the dialogue frame where users can chat with HBot in text form and give instructions to operate the 3D body, and iv) the left-bottom area is the multimedia board where the pictures or videos related to acupuncture points and meridians will be displayed to help users understand the TCM-knowledge.\nThe main contributions are summarized as follows:\n\u2022 For the localization and display of acupoints involved in dialogues, we propose an interactive human body in 3D.\n\u2022 To support the consultation services, we construct a knowledge graph (TCM-KG) and annotate a document-level entity&relation extraction dataset in TCM.\n\u2022 Human evaluation results demonstrate the robustness of Hbot. Functions such as intent detection, entity&relation extraction, and knowledge query will be publicly released in our platform as open APIs."}, {"title": "2 SYSTEM ARCHITECTURE", "content": "The architecture of the HBot system is shown in Fig 2, where illustrates an example of interaction flow. HBot contains 6 key modules,"}, {"title": "3 INTERACTIVE 3D BODY", "content": "To visually display the meridians and acupoints of the human, we constructed an interactive 3D model of the human body. Considering compatibility of operating systems, simplicity of installation and diversity of interactions, we choose to embed our model into a web page and users can interact with the 3D body only through a web browser. Moreover, we pack the operations of the 3D body into javascript API for the developer to call. The implementation of the 3D body is the following steps:\n1. According to the State Standard of the Location of Acupoints[5], we manually make an adult male body and mark 409 acupoints by using 3D graphics software (blender).\n2.Using the GLTFLoader of three.js, the 3D object files (.glb and .hdr) of the body will be loaded in the web page for real-time rendering and displaying.\n3.Use the camera controller (controls.js) of three.js to implement 360-degree rotation of the model, switching, zooming and other operations.\n4.Using the event listener functions (onclick, onchange, onmouseover, etc) of Javascript, the switching of body components and the selection and restoration of acupuncture points can be realized."}, {"title": "4 USER INTENT DETECTION", "content": "User Intent Detection is framed as a sentence classification task that aims to identify intents from human utterances, and plays the key role in dialogue systems[1]. However, training intent detection models relies upon a large set of user utterances paired with intents, which are predefined by the developers. In practice, the user will express new intents that may not be expected by the tested system, referred to as out-of-define (OOD) intents. To alleviate this issue, we propose a configurable intent detection process by applying three-phase: i)rule-based intent matching ii) model-based intent understanding and iii) similarity-based query searching.\nPhase I: an intent-table is maintained in the Redis database, where one predefined intent is mapped to 5 example utterances and the related regular expressions. We defined two types of intents: Body manipulation related (i.e. rotation, zoom in, zoom out) and dialog content related (i.e. asking about treatment, asking about symptoms). When Hbot is running, the user utterance will be matched to a certain intent based on the regular expressions. If the match fails, Hbot will enter the second phase: model-based intent understanding.\nPhase II: we applied the complex intent detection model Conco-ERNIE[17], which is effective for both multiple intents and implicit intent detection by exploiting co-occurrence patterns between concepts appeared in medical queries and user intents conveyed by these queries. Given a user query, Conco-ERNIE can predict the probability distribution of the utterance on 21 common medical intents. If the probability of each intent is less than the threshold (0.6), Hbot will enter the third phase: similarity-based query searching.\nPhase III: We collected a real question-and-answer corpus between patients and doctors (about 100k Q&A pairs) from medical online forum\u00b2. To ensure the quality of the corpus, we only select the Q&A pairs where the question has a bounty and the answer is adopted by the patient. To find the approximate answers, we trained a sentence embedding model SBERT[11] with siamese network architecture to calculate the similarity between the input sentence and each query in the corpus. Then, the answer to the query most similar to the input sentence will be returned to the user. Followed by [15], the positive samples of the input question are constructed through word repetition operation. Since entities(i.e. disease, symptoms) appeared in the medical queries have a great influence on sentence semantics, we construct negative samples by randomly replacing the entities of the same or different types."}, {"title": "5 ENTITY&RELATION EXTRACTION", "content": "The task of entity extraction (similar to slot filling) is to identify entities in text with their corresponding type, which is a critical component in spoken dialogue systems[7]. BERT[3] with a CRF layer have been widely used in named entity recognition and achieved good performance. So we trained a BERT-CRF model to identify all all TCM-related entities in user utterances.\nThe task of relation extraction is to identify the relationship between entities from text[9], which is essential for the construction of TCM knowledge graph. Under the guidance of medical experts, we finely annotated a small-scale but high-quality document-level entity&relation extraction dataset (contains 270 documents, 5996 entities, 4685 relations) based on TCM books. Followed by [16], we treat relation extraction as a multi-label text classification problem. Given an entity pair (head, tail) and the evidence sentences that used to judge its relation, the spliced text of entity pair will be encoded as e by BERT and the i-th evidence sentence will be encoded as si by the same BERT. All the representations of evidence sentences [$S_1, S_2, .., S_k$] will be fed into a Bi-GRU layer, then the final state vector h of Bi-GRU layer and e will be concatenated together and then use a softmax function to compute the probability for each relation type. The relation extraction model is shown as Fig 3 and the performance is shown in Table 1."}, {"title": "6 LLM HANDLER AND WRAPPER", "content": "Based on the prompt engineering, the LLM Handler utilize the large language model to choose the next action for the given dialogue history. To respond to users' medical questions, the LLM handler retrieves from two types of data sources: documents and knowledge graphs, in order to obtain text-based answers and entity-based answers respectively. The dialogue history, current user intent, and these two types of answers are input into the LLM Wrapper to generate a fluent answer that conforms to the user instructions. Essentially, our LLM wrapper is a RAG (Retrieval-Augmented Generation) system that comprehensively utilizes knowledge from multiple sources and of multiple types. The LLM adapted by both of these modules is ChatGLM3-6B 3."}, {"title": "7 KNOWLEDGE GRAPH CONSTRUCTION", "content": "Knowledge graph is a knowledge base that uses a graph-structured model to integrate data, which is the cornerstone of question answering system. To implement question answering in the domain of TCM healthcare, we construct a TCM-related knowledge graph through three steps: i) ontology modeling ii) instance injection and iii) knowledge growth.\nStep I: Followed by ontology development 101 [8], we create the ontology model in the domain of TCM. We first enumerated the important terms in TCM-ontology and defined their properties. Then we defined the relations between different terms. After that,"}, {"title": "8 HUMAN EVALUATION", "content": "Followed by the methodologies of software testing [10], we conducted a&f testing against user requirements to determine whether HBot satisfies the acceptance criteria. a-testing performed to identify all possible issues and bugs before releasing the final product to the end users. A total of 5 members in the development team conducted a-testing on HBot from three aspects: the feedback on 3D model operation, the accuracy of user instruction understanding, and the robustness of system at runtime. During a-testing, we executed 100 test cases and found 21 bugs, including 10 error feedbacks, 8 responses that did not satisfy instructions, and 3 situations where the system could not run stably. After fixing these bugs, we hired 8 members of our lab to conduct \u03b2-testing on HBot. These people were only informed of the system's features and did not grasp the development details, who can be regarded as end users. During \u03b2-testing, each member was asked to give 15 different instructions to HBot in the form of text in the dialog box. Each instruction is recorded along with the corresponding feedback or response from HBot and the evaluation of user satisfaction. User satisfaction measures whether the feedback or response of HBot meets the expectations of users:\n\u2022 Bad: not at all as expected\n\u2022 Fair: as expected, with tolerable errors\n\u2022 Good: exactly as expected\n\u2022 None: no feedback or response was returned\nThe performance of HBot on a and \u03b2 testing is shown in Fig 5. After a round of bug fixes, the responses of HBot are generally more in line with user expectations. However, there are more cases where the user evaluation is none. This is because the testers are developers in a-testing and they know where the capability boundaries of the system are, while the testers in \u03b2-testing often give instructions that are outside the scope of the domain (e.g. chat with them, amuse them and ask how much is the surgery). To continuously improve system performance, we developed the evaluation interfaces for end-user and the function of record collection. When the scale of the records is large enough, relevant modules in HBot will be updated offline by analyzing these records."}]}