{"title": "Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling", "authors": ["Jian Xu", "Zhiqi Lin", "Shigui Li", "Min Chen", "Junmei Yang", "Delu Zeng", "John Paisley"], "abstract": "Bayesian Last Layer (BLL) models focus solely on uncertainty in the output layer of neural networks, demonstrating comparable performance to more complex Bayesian models. However, the use of Gaussian priors for last layer weights in Bayesian Last Layer (BLL) models limits their expressive capacity when faced with non-Gaussian, outlier-rich, or high-dimensional datasets. To address this shortfall, we introduce a novel approach that combines diffusion techniques and implicit priors for variational learning of Bayesian last layer weights. This method leverages implicit distributions for modeling weight priors in BLL, coupled with diffusion samplers for approximating true posterior predictions, thereby establishing a comprehensive Bayesian prior and posterior estimation strategy. By delivering an explicit and computationally efficient variational lower bound, our method aims to augment the expressive abilities of BLL models, enhancing model accuracy, calibration, and out-of-distribution detection proficiency. Through detailed exploration and experimental validation, We showcase the method's potential for improving predictive accuracy and uncertainty quantification while ensuring computational efficiency.", "sections": [{"title": "Introduction", "content": "Bayesian Last Layer (BLL) models (Watson et al. 2021; Harrison, Sharma, and Pavone 2020; Kristiadi, Hein, and Hennig 2020; Harrison, Willes, and Snoek 2023; Fiedler and Lucia 2023) have emerged as a robust framework for uncertainty quantification in neural networks, concentrating on the uncertainty inherent in the final layer weights. However, these models often utilize Gaussian priors for the weight distributions, which may be insufficient for capturing the complexity of non-Gaussian, outlier-prone, or high-dimensional data. This constraint can limit the expressiveness of BLL models and adversely affect their performance in more challenging scenarios.\nPrior research highlights the critical need to enhance model flexibility through more adaptable priors. For instance, (Fortuin et al. 2021) demonstrated that isotropic Gaussian priors may inadequately represent the true distribution of weights in Bayesian neural networks, potentially compromising performance. They observed significant spatial correlations in convolutional neural networks and ResNets, as well as heavy-tailed distributions in fully connected networks, suggesting that priors designed with these observations in mind can improve performance on image classification tasks. (Fortuin 2022) underscore the importance of prior selection in Bayesian deep learning, exploring various priors for deep Gaussian processes (Damianou and Lawrence 2013), variational autoencoders (Doersch 2016), and Bayesian neural networks (Kononenko 1989), while also discussing methods for learning priors from data. Their work encourages practitioners to carefully consider prior specification and provides inspiration for this aspect.\nDriven by the need for enhanced model flexibility and performance, we propose an innovative approach that leverages implicit priors for variational learning of Bayesian last layer weights. Implicit priors are parameterized through a neural network, replacing traditional Gaussian weight distributions to achieve greater flexibility. This method connects to the migration of variational implicit processes (Ma, Li, and Hern\u00e1ndez-Lobato 2019) into the BLL model, offering novel insights and opportunities. By employing implicit distributions for weight priors, our approach aims to establish a robust strategy for Bayesian prior estimation. However, as model complexity increases, inference becomes more challenging, posing new obstacles.\nTo address this, we shift to directly utilizing diffusion models (Ho, Jain, and Abbeel 2020; Rombach et al. 2022; Vargas, Grathwohl, and Doucet 2023) for posterior sampling. This approach enables us to effectively capture complex dependencies and correlations among latent variables. By utilizing diffusion stochastic differential equations (SDEs) and incorporating elements similar to score matching (Song et al. 2020), we formulate a novel variational lower bound for the marginal likelihood function through KL divergence minimization.\nAdditional, we delve into the details of our proposed method and demonstrate its potential through extensive experimental validation. By introducing a computationally efficient variational lower bound and showcasing its efficacy in scenarios with non-Gaussian distributions, outliers, and high-dimensional data, we highlight the significance of our approach in advancing uncertainty quantification in neural networks. Overall, our contributions are as follows:\n\u2022 We proposed an innovative approach that utilizes implicit priors for variational learning of Bayesian last layer weights. This method replaces traditional Gaussian weight parameters with prior distributions parameterized through a neural network to achieve more flexible priors.\n\u2022 We directly employed diffusion models for posterior sampling and then constructed a new objective that accurately captures the complex dependencies and correlations among latent variables. This approach explicitly derives a variational lower bound for the marginal likelihood function through KL divergence minimization.\n\u2022 We conduct extensive experiments to demonstrate the effectiveness of the proposed method in handling regression and image classification datasets. These tests highlight the method's impact on improving uncertainty quantification in neural networks, demonstrating its effectiveness and robustness."}, {"title": "Background", "content": "BLL models\nIn the context of Bayesian Last Layer (BLL) networks, these models can be understood as Bayesian linear regression frameworks applied within a feature space that is adaptively learned through neural network architectures. Another perspective is to view them as neural networks where the parameters of the final layer undergo rigorous Bayesian inference. While BLL networks are capable of handling multivariate regression tasks, this discussion will be confined to the case of univariate targets for the sake of simplicity.\nLet the dataset $\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^N$ consist of observed data, where $x_i \\in \\mathbb{R}^D$ and $y_i \\in \\mathbb{R}$. We denote $X \\in \\mathbb{R}^{N\\times D}$ and $y \\in \\mathbb{R}^N$. We define a parameterized function $\\phi(\\cdot; \\theta) : \\mathbb{R}^D \\rightarrow \\mathbb{R}^M$ for projecting features, with $\\theta$ representing its parameters, and $\\phi_i = \\phi(x_i; \\theta)$ and $\\Phi = [\\phi_1^T, ..., \\phi_N^T]^T \\in \\mathbb{R}^{N\\times M}$, where the latter denotes a matrix of stacked row vectors.\nA latent function $f$ is modeled utilizing Bayesian linear regression (Bishop 2006; Hill 1974; Murphy 2023), incorporating weights $\\beta \\in \\mathbb{R}^M$ and zero-mean Gaussian noise $\\epsilon$ with variance $\\sigma^2$, where\n$y_i = f(x_i; \\theta) = \\phi_i^T\\beta + \\epsilon_i$.\nBy imposing a conjugate Gaussian prior $\\mathcal{N} (\\mu_0, \\Lambda_0^{-1})$ over $\\beta$, a Gaussian posterior $\\mathcal{N} (\\mu_n, \\Lambda_n^{-1})$ is obtained (Watson et al. 2021; Harrison, Willes, and Snoek 2023),\n$\\mu_n = (\\Lambda_0 + \\sigma^{-2}\\Phi^T\\Phi)^{-1}(\\Lambda_0\\mu_0 + \\sigma^{-2}\\Phi^Ty)$\n$\\Lambda_n = \\Lambda_0 + \\sigma^{-2}\\Phi^T\\Phi,$\nyielding an explicit Gaussian predictive distribution for a given query $x$,\n$y | x, \\mathcal{D}, \\theta \\sim \\mathcal{N} (\\cdot | \\phi_x^T\\mu_n, \\sigma^2 + \\phi_x^T\\Lambda_n^{-1}\\phi_x),$\nwhere $\\mu_n$ and $\\Lambda_n$ denote the mean vector and precision matrix of the posterior weight distribution, respectively.\nThe parameters encompassing the observation noise $\\sigma^2$, the prior weight parameters $\\mu_0$ and $\\Lambda_0$, and $\\theta$, can be optimized jointly through the maximization of the log-marginal likelihood. In the scenario where $\\mu_0 = 0$, this model aligns equivalently with a Gaussian process, with a kernel $k(x,x';\\theta) = \\phi(x; \\theta)^T\\Lambda_0^{-1}\\phi (x'; \\theta)$ (Williams and Rasmussen 2006). For a more rigorous Bayesian treatment, an inverse gamma prior can be placed on $\\sigma^2$, eliciting a Student-t weight posterior and predictive density.\nVariational Bayesian Last Layer\nTo leverage exact marginalization while avoiding the computational burden of full marginal likelihood computation, Variational Bayesian Last Layer (VBLL) (Harrison, Willes, and Snoek 2023) employs stochastic variational inference (Hoffman et al. 2013). The objective is to jointly compute an approximate posterior for the last layer parameters and optimize network weights by maximizing lower bounds on the marginal likelihood. Specifically, VBLL aims to find an approximate posterior $q(\\beta|\\eta)$ parameterized by $\\eta$.\nGiven a mini-batch $\\mathcal{D}_I$ with $|\\mathcal{X}_I| = B$, where $I \\subset \\{1,2,..., N\\}$ is the set of indices for any mini-batch, and the log marginal likelihood $\\log p(y|x, \\theta)$ with marginalized parameters $q(\\beta|\\eta) = \\mathcal{N}(w, S)$, they derive bounds of the form:\n$\\frac{N}{B} \\sum_{i \\in I} \\log p(y_i|x_i, \\theta) \\geq \\frac{N}{B} [\\sum_{i \\in I} \\log \\mathcal{N}(y_i| w^T\\phi_i, \\sigma^2I) - \\frac{N}{2B}\\sigma^{-2}\\phi_i^T S \\phi_i] - KL(q(\\beta|\\eta)||p(\\beta)).$\nThis formulation results in a mini-batch algorithm for variational Bayesian inference in neural networks.\nFlexible Priors in Bayesian Neural Networks\nIn prior research, there has been a strong emphasis on the importance of enhancing model flexibility through more flexible priors, particularly in the context of Bayesian neural networks. Previous studies (Fortuin et al. 2021; Fortuin 2022) have highlighted that applying isotropic Gaussian priors to weights may not fully capture true beliefs about weight distributions, thus hindering optimal performance, as described in Section\nThese studies provide valuable insights suggesting that introducing more flexible weight priors in Bayesian linear regression models could enhance model flexibility and performance. This flexibility may involve designing prior distributions based on specific task or data characteristics to better capture the true data distribution features, thereby improving model generalization and performance."}, {"title": "Method", "content": "Implict Prior\nIn continuation of techniques for generating implicit processes from prior research on stochastic processes (Ma, Li, and Hern\u00e1ndez-Lobato 2019; Santana, Zaldivar, and Hernandez-Lobato 2021; Ma and Hern\u00e1ndez-Lobato 2021), we introduce a regression model with an implicit prior over the weights $\\beta$:\n$y_i = f(x_i; \\theta) = \\phi_i^T\\beta + \\epsilon_i,$\n$\\beta = G_{\\psi} (\\omega), \\omega \\sim p (\\omega),$\nwhere $\\omega \\in \\mathbb{R}^K$ serves as an auxiliary variable to generate weights $\\beta$, with $p(\\omega)$ representing its prior distribution, which can be a simple distribution such as a Gaussian distribution. And $G_{\\psi}(\\cdot) : \\mathbb{R}^K \\rightarrow \\mathbb{R}^M$ being a neural network parameterized weight parameter generator. We use this hierarchical model to reframe the BLL model. Given that $G_{\\psi}$ is typically a non-linear function, we anticipate that the weight prior $p(\\beta)$ generated by the auxiliary variable $\\beta$ through $G_{\\psi}$ will exhibit greater expressiveness than the original model, capable of yielding non-Gaussian distributions.\nHowever, dealing with the intractable implicit model $p(y | x,\\theta,\\psi,\\omega)$ defined by Eq. (5) poses significant challenges as model complexity increases, rendering traditional mean-field inference methods like those suggested in VBLL(Hoffman et al. 2013; Harrison, Willes, and Snoek 2023) inadequate for our modified model. As the complexity of the model increases, the posterior distribution becomes more intricate. Consequently, it is natural to design more sophisticated posteriors to model Bayesian networks and improve estimation accuracy. To address this issue, we explore an approach centered on posterior sampling using diffusion models (Song et al. 2020).\nDiffusion Posterior Sampling\nParameterizing Auxiliary Variable Posteriors Using Time-Reversal Representation of Diffusion SDE Our goal is to sample from the posterior distribution of auxiliary variable $q(\\omega)$, defined by Bayes' rule as $q(\\omega) = \\frac{p(y|\\omega)p(\\omega)}{p(y)}$ where $p(\\omega)$ represents the prior and $p(y)$ represents the model marginal likelihood. Following similar setups in prior works (Tzen and Raginsky 2019; Zhang and Chen 2021; Vargas, Grathwohl, and Doucet 2023), we begin by sampling from a Gaussian distribution $\\mathcal{N}(0, \\sigma_0^2I)$, where $\\sigma_0 \\in \\mathbb{R}^+$ is the covariance parameter. We then follow a time-reversal process of the forward diffusion stochastic differential equation (SDE):\n$d \\omega_t = -x(t)\\omega_t dt + g(t)dB_t, \\omega_0 \\sim q, t\\in [0,T],$\nwhere $-x(t) \\in \\mathbb{R}$ is the drift coefficient, $g(t) \\in \\mathbb{R}$ is the diffusion coefficient, and $(B_t)_{t\\in[0,T]}$ is a K-dimensional Brownian motion. This diffusion induces the path measure $\\mathbb{P}$ on the time interval $[0,T]$, and the marginal density of $\\omega_t$ is denoted $p_t$. Note that by definition, we always have $p_0 = q$ when using an SDE to perturb this distribution. According to (Anderson 1982; Haussmann and Pardoux 1986), the time-reversal representation of Eq. (6) is given by $\\omega_t = \\omega_{T-t}$ (where equality is in distribution). This satisfies:\n$d\\omega_t = (-x(T - t)\\omega_t + g(T - t)^2\\nabla \\log p_{T-t} (\\omega_t)) dt + g(T - t)dW_t, \\omega_0\\sim p_T,$\nwhere $(W_t)_{t\\in [0,T]}$ is another K-dimensional Brownian motion. In DDPM (Ho, Jain, and Abbeel 2020; Song et al. 2020), this time-reversal starts from $\\omega_T \\sim p_T \\approx \\mathcal{N}(0, \\sigma_0^2I)$ and ensures that $\\omega_T \\rightarrow q$. Then we can parameterize the transition probability $T(\\omega_{t_{s+1}} | \\omega_{t_s})$ in the Euler discretized form (S\u00e4rkk\u00e4 and Solin 2019) of Eq. (7) for steps $t_s \\in \\{0,..., T - 1\\}$.\nScore Matching and Reference Process Trick If we could approximately simulate the diffusion process described in (7), we would obtain approximate samples from the target distribution $q$. However, implementing this idea requires approximating the intractable scores $(\\nabla \\log p_t(\\omega))_{t\\in [0,1]}$. To achieve this, DDPM (Ho, Jain, and Abbeel 2020; Song et al. 2020) relies on score matching techniques. Specifically, to approximate $\\mathbb{P}$, we consider a path measure $\\mathbb{P}^Y$ whose time-reversal is defined by\n$d \\omega_t = (-x(T - t)\\omega_t + g(T - t)^2s_\\gamma (T - t, \\omega_t)) dt + g(T - t)dW_t, \\omega_0 \\sim \\mathcal{N}(0,\\sigma_0^2I),$\nso that the backward process $\\omega_T \\sim \\mathbb{Q}^\\gamma$. To obtain $s_\\gamma(t,\\omega) \\approx \\nabla \\log p_t(\\omega)$, we parameterize $s(t)$ using a neural network, with the parameters obtained by minimizing $KL(\\mathbb{P}||\\mathbb{P}^Y)$. Unlike traditional score matching techniques, given that we can only obtain samples from $\\mathbb{Q}^\\gamma$, we alternatively minimize $KL(\\mathbb{P}^Y||\\mathbb{P})$, by Girsanov's theorem (Oksendal 2013)\n$KL(\\mathbb{P}^Y||\\mathbb{P}) = KL(\\mathbb{Q}^Y||\\mathbb{Q})$\n$=KL(\\mathcal{N}(0, \\sigma_0^2I)||p_T) + KL(\\mathbb{Q}^Y(\\cdot|\\omega)||\\mathbb{Q}(\\cdot|\\omega))$\n$= \\frac{1}{2}\\int_0^T \\mathbb{E}_{\\mathbb{Q}^\\gamma} [g(T - t)^2 ||\\nabla \\log p_{T-t}(\\omega_t) - s_\\gamma(T - t, \\omega_t)||^2]dt.$\nHowever, although we can obtain samples from $\\mathbb{Q}^\\gamma$ by simulating the SDE (8), dealing with the nonlinear drift function of SDE (8) makes it difficult to obtain $\\nabla \\log p_{T-t}(\\omega_t)$ in Eq. (9).\nWe use an alternative approach by constructing a reference process (Zhang and Chen 2021; Vargas, Grathwohl, and Doucet 2023), denoted as $\\mathbb{P}^{ref}$, to assist in measuring $KL(\\mathbb{P}^Y||\\mathbb{P})$. Firstly, observe the following fact:\n$KL(\\mathbb{P}^Y||\\mathbb{P}) = \\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{d\\mathbb{P}^Y}{d\\mathbb{P}} = \\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{d\\mathbb{P}^Y}{d\\mathbb{P}^{ref}} + \\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{d\\mathbb{P}^{ref}}{d\\mathbb{P}}.$\nwhere the stochastic process KL is represented as the Radon-Nikodym derivative. Given the specific form in Eq. (10), we define the reference process $\\mathbb{P}^{ref}$ to follow the diffusion formula as in Eq. (6), but initialized at $p_0^{ref} (\\omega_0) = \\mathcal{N}(0, \\sigma_0^2I)$ instead of $q$, which aligns with the distribution of $\\omega_0$ in Eq. (8),\n$d \\omega_t^{ref} = -x(t) \\omega_t^{ref}dt + g(t)dB_t, \\omega_0^{ref} \\sim \\mathcal{N}(0,\\sigma_0^2I).$\nThe transition kernel $p_t(\\omega_t^{ref}|\\omega_0^{ref})$ is always a Gaussian distribution $\\mathcal{N}(\\mu_t, \\Sigma_t)$, where the mean $\\mu_t$ and variance $\\Sigma_t$ are often available in closed form (S\u00e4rkk\u00e4 and Solin 2019):\n$\\frac{d\\mu_t}{dt} = -x(t)\\mu_t, \\mu_0 = 0,$\n$\\frac{d\\Sigma_t}{dt} = -2x(t)\\Sigma_t + g(t)^2I, \\Sigma_0 = \\sigma_0^2I.$\nBy solving these ordinary differential equations (Hale and Lunel 2013), we obtain the general solutions as follows:\n$\\mu_t = \\mu_0e^{\\int_0^t x(s)ds},$\n$\\Sigma_t = (\\int_0^t g(r)^2e^{\\int_0^r x(s)ds}drI + \\Sigma_0)e^{-\\int_0^t x(s)ds}.$\nAccording to Eq. (13), we can derive that for any t, the distribution $p_t^{ref}$ of $\\omega_t^{ref}$ is a zero-mean Gaussian distribution:\n$p_t^{ref} (\\omega_t^{ref}) = \\int p_t(\\omega_t^{ref}|\\omega_0^{ref})p_0(\\omega_0^{ref}) d\\omega_0^{ref} = \\mathcal{N}(0, \\kappa_tI),$\nwhere the variance $\\kappa_t$ is given by\n$\\kappa_t = (\\int_0^t g(r)^2e^{\\int_0^r x(s)ds}dr + \\sigma_0^2) e^{-\\int_0^t x(s)ds}.$\nMeanwhile, the SDE equation for the reverse process $\\mathbb{Q}^{ref}$ of $\\mathbb{P}^{ref}$ is\n$d \\omega_t^{ref} = (-x(T - t)\\omega_t^{ref} + g(T - t)^2\\nabla \\log p_{T-t}^{ref} (\\omega_t^{ref})) dt + g(T - t)dW_t, \\omega_0^{ref} \\sim p_0^{ref}.$\nAccording to Eq. (14), we can derive an analytical expression for the derivative of the log-likelihood function with respect to $\\omega_t^{ref}$:\n$\\nabla \\log p_{T-t}^{ref} (\\omega_t^{ref}) = -\\frac{\\omega_t^{ref}}{\\kappa_{T-t}}.$\nTo compute $KL(\\mathbb{P}^Y||\\mathbb{P})$, we calculate the first term of Eq. (10). Using the chain rule for KL divergence and Girsanov's theorem (Oksendal 2013), and incorporating Eqs. (8, 15, 16), we obtain:\n$\\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{d\\mathbb{P}^Y}{d\\mathbb{P}^{ref}} = KL (\\mathbb{Q}^Y|| \\mathbb{Q}^{ref}) = KL (\\mathcal{N}(0, \\sigma_0^2I)||p_T^{ref}) + KL (\\mathbb{Q}^Y(\\cdot|\\omega)||\\mathbb{Q}(.\\omega^{ref})) = KL(\\mathcal{N}(0, \\sigma_0^2I)||p_T^{ref}) + \\frac{1}{2}\\int_0^T \\mathbb{E}_{\\mathbb{Q}^\\gamma} g(T-t)^2[\\frac{\\omega_t^{2}}{\\kappa_{T-t}} + ||s_\\gamma(T - t, \\omega_t)||^2] dt.$\nAt this point, we can simulate the SDE (8) to compute for first term in Eq. (10). the integral term can be computed using either ODE solvers (Chen et al. 2018) or by employing Riemann summation methods. For the second term, $\\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{d\\mathbb{P}^{ref}}{d\\mathbb{P}}$, we can see from Eq. (6) and Eq. (11) that $\\mathbb{P}$ and $\\mathbb{P}^{ref}$ have the same dynamic system $\\gamma$, except for different initial values. Therefore, we have\n$\\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{d\\mathbb{P}^{ref}}{d\\mathbb{P}} = \\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{p_{0}^{ref} (\\omega_0^{ref})}{p_0 (\\cdot)} = \\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{p_{0}^{ref} (\\cdot)}{\\mathbb{Q}} = \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log \\frac{\\mathcal{N}(0, \\sigma_0^2I)}{q} = \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log \\frac{\\mathcal{N}(0, \\sigma_0^2I)}{p(\\omega)} + \\log p(y) + \\log p(\\omega),$\nEvidence Lower Bound Let $1_1(\\gamma) = \\mathbb{E}_{\\mathbb{P}^Y} \\log \\frac{d\\mathbb{P}^{ref}}{d\\mathbb{P}}$. Combining Eq. (5, 10, 17, 18), we obtain a new variational lower bound $1(\\gamma, \\theta, \\psi)$ for the marginal likelihood $\\log p(y)$ in our method,\n$\\log p(y) = KL(\\mathbb{P}^Y||\\mathbb{P}) - 1_1(\\gamma) - \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log \\frac{\\mathcal{N}(0, \\sigma_0^2I)}{p(y)p(\\omega)} = KL(\\mathbb{P}^Y||\\mathbb{P}) - 1_1(\\gamma) - \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log \\mathcal{N}(0, \\sigma_0^2I) + \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log p(\\omega) + \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log p(y | x,\\theta,\\psi,\\cdot) \\geq -1_1(\\gamma) - \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log \\mathcal{N}(0, \\sigma_0^2I) + \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log p(\\omega) + \\mathbb{E}_{\\mathbb{Q}^\\gamma} \\log p(y | x,\\theta,\\psi,\\cdot) = 1(\\gamma, \\theta, \\psi)$\nIn our derivation, $p(\\cdot)$ represents the prior function of $\\omega$. We introduce a new variational lower bound for $\\log p(y)$. Unlike the mean-field variational inference model that approximates q with a Gaussian distribution, our model uses a diffusion process to approximate the posterior distribution. The flexibility of the denoising neural network $\\gamma$ provides our model with a significant advantage in accurately approximating the posterior distribution.\nStochastic Gradient Descent\nFor ease of sampling, we consider a reparameterization version of Eq. (19) based on the approaximate transition probability $T_\\gamma (\\omega_{t_{s+1}} | \\omega_{t_s})$ given by\n$T(\\omega_{t_{s+1}}) = \\omega_{t_s} - x(T - t_s)\\omega_{t_s} + g(T - t_s)^2s_\\gamma (T - t_s, \\omega_{t_s}) + g(T - t_s)\\epsilon_{t_s}.$\nwhere $\\epsilon_{t_s} \\sim \\mathcal{N}(0, I)$. In order to accelerate training and sampling in our inference scheme, we propose a scalable variational bounds that are tractable in the large data regime based on stochastic variational inference (Kingma and Welling 2013; Hoffman and Blei 2015; Salimbeni and Deisenroth 2017; Naesseth, Lindsten, and Blei 2020) and stochastic gradient descent (Welling and Teh 2011; Chen, Fox, and Guestrin 2014; Zou, Xu, and Gu 2019; Alexos, Boyd, and Mandt 2022). Our model is shown in Algorithm 1, referred to as DVI-IBLL.\nPrediction Distribution\nFor making predictions in our model, the prediction under the variational posterior distribution is approximated for a test input/label $(x^*, y^*)$ as:\n$p(y^* | x^*, \\mathcal{X}, y) \\approx \\mathbb{E}_{\\mathbb{Q}^\\gamma} [p(y^* | x^*, \\theta,\\psi,\\omega)].$\nHere, $\\mathbb{Q}^\\gamma$ denotes the output of the diffusion process at time T. The expression $p(y^* | x^*, \\theta, \\psi, \\omega)$ can be obtained by substituting the input/output with the test set input/label from Eq. (5). For classification tasks or other likelihood functions, the substitution can be made accordingly during training."}, {"title": "Experiments", "content": "Metrics and Baselines\nIn our regression experiments, we present the predictive negative log likelihood (NLL) for test data, which can be straightforwardly calculated for point feature estimates. Additionally, we include the root mean squared error (RMSE), a widely used metric in regression analysis. For classification tasks, apart from the negative log likelihood, we also showcase the predictive accuracy (based on the standard argmax of the predictive distribution) and the expected calibration error (ECE), which assesses the alignment between the model's subjective predictive uncertainty and actual predictive error. Furthermore, we delve into evaluating out-of-distribution detection performance, a recognized assessment approach for robust and probabilistic machine learning (Liu et al. 2023). Specifically, we measure the area under the ROC curve (AUC) for datasets near and far from the distribution, which will be elaborated on further in this section.\nIn the realm of regression, we contrast our model with approaches that leverage exact conjugacy, including Bayesian last layer models such as GBLL and LDGBLL (Watson et al. 2021), as well as VBLL (Harrison, Willes, and Snoek 2023) and RBF kernel Gaussian processes. We also juxtapose our model with MAP learning (Snoek et al. 2015), which involves training a complete network using MAP estimation and subsequently fitting a Bayesian last layer to these fixed features.\nIn the domain of classification, our primary point of comparison is standard deep neural networks (DNN), given their ability to output a distribution over labels for direct comparison with our model. Additionally, we compare our model with SNGP (Liu et al. 2023) and last layer Laplace-based methods (Daxberger et al. 2021), which are akin to last layer models aiming to approximate deep kernel GPs (Wilson et al. 2016) and computing an approximate posterior after training, respectively. Note that Laplace methods are not assessed in regression due to their similarity to the MAP model.\nFurthermore, we examine various variational methods such as Bayes-by-Backprop (BBB) (Blundell et al. 2015), Ensembles (Lakshminarayanan, Pritzel, and Blundell 2017), Bayesian Dropout (Gal and Ghahramani 2016), and Stochastic Weight Averaging-Gaussian (SWAG) (Maddox et al. 2019) for a comprehensive evaluation of performance. All our experiments were conducted on an RTX 4090 GPU.\nRegression\nOur UCI experiments closely align with the methods outlined in (Watson et al. 2021; Harrison, Willes, and Snoek 2023), enabling a direct comparison with their baseline models. Consistently, we employed the same MLP architecture as described in (Watson et al. 2021), comprising two layers of 50 hidden units each. Maintaining consistency with (Watson et al. 2021), a batch size of 32 was utilized for all datasets, except for the Power dataset where a batch size of 256 was chosen to expedite training. Standard preprocessing techniques were applied, including normalization of inputs and subtraction of training set means from the outputs. The reported results in our manuscript exhibit the outcomes under leaky ReLU activations, with optimization performed using the AdamW optimizer (Loshchilov and Hutter 2017) across all experiments.\nIn deterministic feature experiments, we conducted 20 runs with varying seeds. Each run involved splitting the data into training, validation, and testing sets with ratios of 0.72, 0.18, and 0.1, respectively. Training was executed on the training set, while performance monitoring on the validation set was carried out to determine the optimal number of epochs for model convergence. Our study delves into the performance analysis of regression VBLL models across 6 UCI regression datasets"}, {"title": "Related Work", "content": "Bayesian Last Layers (BLL) Models\nBayesian Last Layers (BLL) models are a class of methods that enhance neural network performance by incorporating Bayesian principles into the final layers of the network. The primary advantage of BLL models lies in their ability to efficiently balance exploration and exploitation. Early work by (Box and Tiao 2011) integrated Bayesian layers with deep neural networks to improve robustness and generalization. Recent advances have further refined these approaches. For instance, (Weber et al. 2018) explored training neural networks online in a bandit setting to optimize the balance between exploration and exploitation. Additionally, (Harrison, Sharma, and Pavone 2020) introduced a functional prior on the model's derivatives with respect to the inputs, enhancing predictive uncertainty. (Harrison, Willes, and Snoek 2023) applied variational inference to train Bayesian last layer neural networks, improving the estimation of posterior distributions. Moreover, (Fiedler and Lucia 2023) addressed computational challenges in the log marginal likelihood by reintroducing the weights of the last layer, avoiding the need for matrix inversion.\nImplicit Prior Models\nImplicit prior models (Hoffman, Riquelme, and Johnson 2017; Ma, Li, and Hern\u00e1ndez-Lobato 2019) in Bayesian inference refer to models where the prior distribution is not explicitly specified but instead learned through neural networks. These models are gaining traction due to their flexibility and ability to capture complex data distributions. Notably, (Ma, Li, and Hern\u00e1ndez-Lobato 2019) proposed highly flexible implicit priors over functions, exemplified by data simulators, Bayesian neural networks, and non-linear transformations of stochastic processes. (Takahashi et al. 2019) introduced the VAE with implicit optimal priors to address the challenges of hyperparameter tuning for the aggregated posterior model. Recent advancements (Kumar and Poole 2020) have focused on enhancing the efficiency and accuracy of these methods by integrating regularization techniques.\nDiffusion Models\nDiffusion models (Ho, Jain, and Abbeel 2020; Song et al. 2020) have emerged as powerful tools for modeling complex distributions and generating high-quality samples. These models simulate a diffusion process in which a simple distribution is gradually transformed into a more complex target distribution. The incorporation of stochastic differential equations (SDEs) (Song et al. 2020) has further enhanced their capacity to model continuous dynamical systems and capture intricate data patterns. Recent research (Vargas, Grathwohl, and Doucet 2023; Richter and Berner 2023; Piriyakulkij, Wang, and Kuleshov 2024) has explored integrating diffusion models with Bayesian inference, resulting in the generation of unnormalized probability density function (PDF) samples. Our approach bears significant resemblance to (Vargas, Grathwohl, and Doucet 2023), but it is distinct in that it derives a different form of SDE aimed at posterior sampling. Unlike (Piriyakulkij, Wang, and Kuleshov 2024), our method does not require the introduction of additional auxiliary variables or wake-sleep algorithms, enabling end-to-end optimization."}, {"title": "Conclusion", "content": "In summary, our novel approach combining diffusion techniques and implicit priors for variational learning of Bayesian last layer weights enhances the expressive capacity of Bayesian Last Layer (BLL) models. This advancement addresses limitations with Gaussian priors and boosts model accuracy, calibration, and out-of-distribution detection proficiency in scenarios with non-Gaussian"}]}