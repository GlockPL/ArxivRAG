{"title": "Beyond Instructed Tasks: Recognizing In-the-Wild Reading Behaviors in the Classroom Using Eye Tracking", "authors": ["EDUARDO DAVALOS", "JORGE ALBERTO SALAS", "YIKE ZHANG", "NAMRATA SRIVASTAVA", "YASHVITHA THATIGOTLA", "ABBEY GONZALES", "SARA MCFADDEN", "SUN-JOO CHO", "GAUTAM BISWAS", "AMANDA GOODWIN"], "abstract": "Eye-tracking technology has become an invaluable tool for analyzing reading processes and understanding how readers comprehend text [6, 11, 18, 27, 28, 35]. Researchers can collect detailed data on gaze behaviors by tracking eye movements, such as fixation duration, saccade length, and regressions [35]. These accumulative gaze metrics have been used to draw correlations between reading strategies and learning outcomes [32], shedding light on the cognitive processes involved in text comprehension [6, 27, 28, 35]. For example, higher fixation counts and longer fixation durations may indicate deeper cognitive processing [30], while shorter and more scattered fixations could suggest skimming or scanning behaviors [8, 21]. While these quantitative metrics provide a wealth of data on how individuals interact with text, they often lack the interpretive depth to translate findings into practical applications in educational settings.\nDespite the wealth of data provided by eye-tracking studies, a significant limitation of the analyses conducted is that the gaze metrics are challenging to interpret and do not offer actionable insights for educators. While researchers can identify patterns that correlate with comprehension or engagement [1, 23, 29], these findings rarely translate into clear guidelines or strategies for teachers to implement in the classroom. There is often a disconnect between what the data reveals about reading processes and how educators can use that information to support and improve student learning. Without clear feedback mechanisms, teachers may struggle to adjust their instruction based on eye-tracking data, limiting the potential impact of this research on educational practice.\nTo address these limitations, other approaches in eye-tracking research have focused on recognizing specific reader behaviors, such as \u201cskimming\u201d, \u201cdeep reading\u201d, and \u201cscanning\u201d. Identifying these distinct behaviors during reading is a crucial first step in providing meaningful, context-specific feedback to educators, enabling them to understand better and respond to students' reading strategies. Many existing methods have successfully classified behaviors like skimming versus deep reading [3, 8], showing that it is possible to infer reading strategies from gaze data. However, a major limitation of these studies is their reliance on task instructions to induce specific reading behaviors, such as asking participants to skim or read deeply. This approach simplifies the data labeling process by ensuring that each segment of gaze data is associated with a known behavior, minimizing the need for costly human annotation.\nHowever, providing specific instructions to participants on how to read can significantly alter their natural reading behaviors [17], impacting the validity of the findings when applied to real-world, in-the-wild settings. Reading is often more fluid and context-dependent in authentic environments, with readers dynamically switching between behaviors based on their comprehension needs, interest levels, or the task at hand [16]. The prescriptive nature of task-based reading studies can limit the generalizability of these models and frameworks to everyday reading situations, where behavior is not fixed but adaptive. To the best of our knowledge, no studies have specifically analyzed the differences in reading behaviors between instructed and naturalistic settings and their implications, revealing a critical gap in the literature that must be addressed to develop more ecologically valid insights into reading processes.\nTherefore, in this study, we address the limitations of prior research on reading behaviors by performing an exploratory investigation on both instructed and in-the-wild reading conditions. We conducted a classroom-based study that collected eye-tracking data from students engaged in natural and instructed reading tasks. Our findings reveal significant differences between instructed and in-the-wild reading behaviors, particularly in the variability and dynamics of gaze patterns, which are crucial for understanding authentic reading processes. We developed a qualitative theoretical framework and conducted statistical evaluations to classify reading behaviors. Next, we developed a real-time classifier using a lightweight 2D convolutional neural network (CNN) that outperformed traditional models for detecting reading behaviors. These insights provide a deeper understanding of natural reading behaviors and highlight the importance of incorporating in-the-wild data for developing reliable reading behavior recognition systems in educational contexts. Overall, in this paper, we present several key contributions that advance the field of reading behavior research:", "sections": [{"title": "1 INTRODUCTION", "content": "Eye-tracking technology has become an invaluable tool for analyzing reading processes and understanding how readers comprehend text [6, 11, 18, 27, 28, 35]. Researchers can collect detailed data on gaze behaviors by tracking eye movements, such as fixation duration, saccade length, and regressions [35]. These accumulative gaze metrics have been used to draw correlations between reading strategies and learning outcomes [32], shedding light on the cognitive processes involved in text comprehension [6, 27, 28, 35]. For example, higher fixation counts and longer fixation durations may indicate deeper cognitive processing [30], while shorter and more scattered fixations could suggest skimming or scanning behaviors [8, 21]. While these quantitative metrics provide a wealth of data on how individuals interact with text, they often lack the interpretive depth to translate findings into practical applications in educational settings.\nDespite the wealth of data provided by eye-tracking studies, a significant limitation of the analyses conducted is that the gaze metrics are challenging to interpret and do not offer actionable insights for educators. While researchers can identify patterns that correlate with comprehension or engagement [1, 23, 29], these findings rarely translate into clear guidelines or strategies for teachers to implement in the classroom. There is often a disconnect between what the data reveals about reading processes and how educators can use that information to support and improve student learning. Without clear feedback mechanisms, teachers may struggle to adjust their instruction based on eye-tracking data, limiting the potential impact of this research on educational practice.\nTo address these limitations, other approaches in eye-tracking research have focused on recognizing specific reader behaviors, such as \u201cskimming\u201d, \u201cdeep reading\u201d, and \u201cscanning\u201d. Identifying these distinct behaviors during reading is a crucial first step in providing meaningful, context-specific feedback to educators, enabling them to understand better and respond to students' reading strategies. Many existing methods have successfully classified behaviors like skimming versus deep reading [3, 8], showing that it is possible to infer reading strategies from gaze data. However, a major limitation of these studies is their reliance on task instructions to induce specific reading behaviors, such as asking participants to skim or read deeply. This approach simplifies the data labeling process by ensuring that each segment of gaze data is associated with a known behavior, minimizing the need for costly human annotation.\nHowever, providing specific instructions to participants on how to read can significantly alter their natural reading behaviors [17], impacting the validity of the findings when applied to real-world, in-the-wild settings. Reading is often"}, {"title": "2 RELATED WORK", "content": "This related work section reviews the application of eye-tracking in reading comprehension to understand gaze patterns and cognitive processes, highlights approaches to reading behavior detection using both rule-based and machine learning methods, and identifies literature gaps such as inconsistent behavior taxonomies, limited ecological validity in studies, and challenges in recognizing diverse, naturalistic reading behaviors."}, {"title": "2.1 Reading Comprehension and Eye-Tracking", "content": "Applying eye-tracking in reading comprehension and analyzing the reading process has a long and vast tradition for understanding the underlying gaze patterns that partake in reading. Just and Carpenter [18] applied eye-tracking to"}, {"title": "2.2 Reading Behavior Detection", "content": "In terms of activity recognition for reading behaviors, Campbell and Maglio [5] utilized a rule-based algorithm to distinguish between \"reading\" and \"skimming\" by analyzing eye movements such as saccades and fixations. Their approach involved assigning specific point values to different eye movement patterns to detect when users were engaged in reading versus other types of visual scanning. Instead of a rules-based approach, Kelton et al. [21] introduced a method for real-time reading detection using a Region Ranking Support Vector Machine, identifying \"reading\" vs. \"skimming\". Their approach combined both global and local information to accurately classify reading versus skimming behaviors and achieve up to 82.5% accuracy in predicting reading behavior. Other methods [2, 8, 36] employ a time-window approach, where sliding time-window segments the gaze data and accumulative metrics are computed based on the isolated segment. More specifically, Chen et al. [8] employed the time-window technique to classify reading behaviors as \"deep\" or \"skimming\u201d. These time-window methods have achieved good performance across various studies and eye-tracking hardware. However, a time-window approach is sensitive and generally have lower performance when using smaller time windows. To achieve robust behavior classification, time-window approaches require a larger time window (>30 seconds) but this limits the level of granularity in models' behavior recognition. Lastly, it is still uncertain which reading behaviors should be recognized, as previous studies use varying behavior labels and definitions. Moreover, many of these definitions are purpose-driven. For instance, Campbell and Maglio [5] distinguishes \u201cscanning\" from"}, {"title": "2.3 Literature Gaps and Limitations", "content": "Through our review of the relevant literature, we have identified critical gaps regarding readi recognition. These include the following:\n\u2022 Authentic vs. Instructed Behavior: Current reader behavior activity literature instructs students on how to read (e.g., skim, deeply read). However, naturalistic reading might not align with these task-instructed behaviors and limits the applicability of these methods.\n\u2022 Inconsistent taxonomy: The lack of precise definitions of reading behaviors with illustrative examples limits the research community's ability to effectively communicate, discuss, and share resources and datasets to achieve reliable and robust reading behavior detection.\n\u2022 Lack of Ecological Studies: Many gaze-based reading studies are performed in laboratory settings and use unauthentic texts such as homogeneous large spacing single paragraphs instead of typical hierarchical text with titles, headings, captions, and paragraphs. These study constraints can cause to alter the reading behavior exhibited by participants.\n\u2022 Behavior Classification Granularity: Prior time-window approaches limit the resolution of behavior prediction, likely missing brief yet critical reading behaviors like skimming."}, {"title": "2.4 Research Questions", "content": "To address the gaps in the literature, we formulate the following research questions:\n\u2022 RQ1: What are the reading behaviors in naturalistic and instructed reading conditions? Do the behaviors differ and/or do their characteristics differ?\n\u2022 RQ2: How can we develop a theoretical framework for reading behaviors - comprising behavior labels and definitions - based on human observations while ensuring that reading behaviors are measurable and distinguishable using data-driven methods?\n\u2022 RQ3: How can we effectively classify reading behaviors, including high-speed and transitional behaviors?"}, {"title": "3 STUDY DESIGN", "content": "The study involved an ecological setting with 38 sixth-grade students to examine natural reading behaviors using eye-tracking technology. An overview of the study is shown in Fig. 2. Students were asked to perform two tasks: (1) instructed behavior reading, where they followed specific reading strategies like skimming or deep reading, and (2) uninstructed reading of a passage, consisting of a \"coldread\" segment without questions and a \"questions\" segment with text access. Gaze data was collected using Tobii Pro Spark\u00b9 eye-trackers and a custom web application interface, allowing for detailed tracking and analysis of reading patterns. Preprocessing was conducted to align gaze data with"}, {"title": "3.1 Participants", "content": "We conducted a classroom study with 38 sixth-grade students from a private school in the southeastern region of the United States. Based on the demographic data provided by the teacher, 22 students identified as male, and 16 students identified as female. The racial composition was predominately White (N=35), with 2 Black and 1 Asian student. Among the White students, 2 identified as Hispanic or Latino. From the 38 participants' data, we ruled out 11 students based on the following criteria: 2 students did not follow study protocols, 4 students' data was corrupted (impacted by students' covering their faces with their hands), and 5 students' data were too noisy for human labeling (impacted by posture). A total of N=27 participant sessions were used for our analysis."}, {"title": "3.2 Stimulus, Apparatus, and Procedure", "content": "In the study, students performed two tasks: (1) an instructed behavior task, where they read sections of a PDF with specific instructions \u2013 such as \u201cskim\", \"regularly\" read, or \u201cdeeply\" read \u2013 for about 20 seconds to minimize cross-contamination of behaviors [33]; and (2) an in-the-wild task, where they read a PDF passage naturally, as they would in class, followed by a question-answering session with access to the text. The passage was approximately 500 words, aligned with the 6th-grade Common Core Standards, with a Lexile level of 810-1000. Prior to reading, students underwent a 9-point calibration with a Tobii Pro Spark eye-tracker (60 Hz). During the session, gaze data and digital interaction logs were collected via a custom web application and ETProWeb, leveraging the Tobii Pro SDK to integrate gaze data directly within the web interface. The study used HP 15-dy2xxx laptops with a resolution of 1920x1080 pixels for data collection. The complete protocol is shown in Fig. 3.\nFor the analysis presented in this paper, we focused on exploring the reading behaviors in the instructed task and the coldread section of the in-the-wild task. The aim is to understand the reading process and the behaviors exhibited by students. In the in-the-wild subsection where students perform two tasks - coldread and question-answering -, we identified a notable shift in behaviors. By asking students to answer questions with the text accessible, their behaviors and strategies drastically changed from reading-focused to information-retrieval. Given the different task objectives and our focus is on examining reading behaviors between instructed and in-the-wild conditions, we isolated our in-the-wild corpus to the cold reading task to concentrate our analysis on reading-focused behaviors."}, {"title": "3.3 Preprocessing", "content": "With the recorded gaze data, our goal was to analyze the gaze scanpath on the PDF content to understand reading behaviors and how students approached text comprehension. For this, it was essential to have the gaze data in page coordinate space (PCS), ensuring consistent and reliable analysis of gaze patterns on the text's pages. Traditional screen-based eye-tracking methods, however, record gaze data in screen coordinate space (SCS), where the (0,0) origin is positioned at the top-left corner of the screen. This approach does not account for dynamic movements, such as scrolling and zooming, that occur in a web-based PDF viewer.\nTo address this, we performed real-time area-of-interest (AOI) encoding by projecting the gaze onto the text, as shown in Fig. 4. The PDF's pages are tracked by the document object model (DOM) and new incoming Pscs gaze points are transformed to Ppcs using the following equation:\n$P_{pcs}=\\frac{P_{scs}(0)-R_l}{R_w}\\ \\frac{P_{scs}(1) - R_t}{R_h}$"}, {"content": "With the recorded gaze data, our goal was to analyze the gaze scanpath on the PDF content to understand reading behaviors and how students approached text comprehension. For this, it was essential to have the gaze data in page coordinate space (PCS), ensuring consistent and reliable analysis of gaze patterns on the text's pages. Traditional screen-based eye-tracking methods, however, record gaze data in screen coordinate space (SCS), where the (0,0) origin is positioned at the top-left corner of the screen. This approach does not account for dynamic movements, such as scrolling and zooming, that occur in a web-based PDF viewer.\nTo address this, we performed real-time area-of-interest (AOI) encoding by projecting the gaze onto the text, as shown in Fig. 4. The PDF's pages are tracked by the document object model (DOM) and new incoming Pscs gaze points are transformed to Ppcs using the following equation:\n$P_{pcs} = \\begin{pmatrix} \\frac{P_{scs}(0) - R_l}{R_w} \\\\ \\frac{P_{scs}(1) - R_t}{R_h} \\end{pmatrix}$"}, {"title": "4 METHODOLOGY", "content": "We employed a mixed-method approach to analyze and compare instructed versus in-the-wild reading behaviors by using quantitative and qualitative analysis methods on the gaze scanpaths. The analysis begins with a hand-coding"}, {"title": "4.1 Human Annotation", "content": "Observations of the scanplot images and videos revealed a range of behaviors, including conventional \"zigzag\" reading, skimming, and re-reading. To distinguish and analyze these varied behaviors, we conducted a human-driven annotation process to segment and classify the students' coldread gaze scanpaths. Each session was annotated by two of the three trained human reviewers, with the third reviewer available to resolve any labeling disagreements. The reviewers were trained and knowledgeable in eye-tracking data and visualizations."}, {"title": "4.1.1 Annotation Protocol.", "content": "As identified in our literature gap, a consistent taxonomy for reading behaviors (e.g., \"skimming\", \"deep\", \"scanning\") has not been established. Different studies use varying and often overlapping labels, with definitions tied to specific cognitive tasks. To address these challenges, we initiated our annotation process by adopting Campbell and Maglio [5]'s \"regular\u201d and \u201cskimming\" labels and definitions as our starting point. The annotation team agreed that, throughout our review of the data, any encounter with unlabeled or unseen behaviors would necessitate creating a new label, saving an instance of the behavior as a reference example, and revisiting previous sessions to identify and update labels for any occurrences of this new behavior. This iterative process of annotating new samples, identifying novel behaviors, and refining our taxonomy and framework aimed to capture and measure in-the-wild reading behaviors accurately.\nIn our annotation process, we utilized both the accumulative gaze scanpath figures and replay video to identify and recognize reading behaviors. To avoid different start and end times for behavior segments by different reviewers that could complicate the calculation of inter-rater reliability, it was decided that a single reviewer would first segment the video and assign an initial label. The second reviewer would then examine the predefined segment and independently assign their label without knowledge of the first. If the second reviewer considered that the original segmentation encapsulated more than one behavior, the original segmentation was further spliced and annotated during a collaborative session with both reviewers. An example annotation table is presented in Table 1. A final label was determined if both reviewers agreed. Any disagreements were resolved in IRR round sessions, where each reviewer could justify their label, followed by a re-vote to finalize the label. Additional metadata, such as the words covered and the word per minute (WPM), was recorded. This differentiation prevents the overuse of the term WPM which is associated with the reading speed rather than the skimming speed of an individual. Fig. 6 illustrates three examples of human-labeled in-the-wild reader behaviors."}, {"title": "4.1.2 Inter-rater Reliability.", "content": "We began with an initial practice round using the \"regular\" and \"skimming\" labels from Campbell and Maglio [5] to train all reviewers on the annotation process. Behavior archetypes, illustrated in Fig. 10, were documented and utilized as references to help reviewers validate and communicate labels consistently. During the second IRR round, we began identifying unexpected behaviors that did not visually align with the \"regular\" and \"skimming\" descriptions. One such behavior was \"non-sequential\u201d reading, where participants continued through the passage but did not follow the conventional \"zigzag\" pattern. Instead, the gaze scanpath diverged significantly from the passage's order, creating a star-like pattern. This behavior was labeled as \u201cnon-sequential\" reading. To better differentiate \"regular reading\u201d from \u201cnon-sequential\", we renamed \"regular reading\u201d to \u201csequential\u201d. Additionally, two slow-moving behaviors were observed. The first, labeled as \u201cdeep\u201d, represented a much slower version of \u201csequential\" reading, characterized by a \"zigzag\u201d pattern that suggested careful, word-by-word re-reading within lines. We hypothesized that this behavior occurs when students struggle with understanding a word or sentence and engage in deep reading to enhance comprehension. The second slow-paced behavior, labeled as \"static\", was identified when the gaze remained stationary for more than approximately 5 seconds.\nIn the third IRR round, we identified only one new behavior, another fast-paced behavior that appeared different from \"skimming\u201d. This behavior, labeled as \u201cpreviewing/mapping\", was characterized by swift movements with large saccades across the entire text. It appeared that students used this behavior to self-pace and map out the text's layout. \"previewing/mapping\" was most commonly observed at the beginning of pages or paragraphs, with quick glances toward the bottom of the text. This was distinct from \"skimming\", where the gaze scanpath still traversed the text quickly, with fixations across paragraphs to grasp content. In our final round, no new behaviors were identified. Cohen's Kappa [39] is a statistical measure for assessing inter-rater reliability, accounting for chance agreement between annotators. As shown in Table 2, the Cohen's Kappa for our third round-the first large-scale annotation round was 0.57. This was improved to 0.65 by the fourth round. Through our discussions during these sessions, we found that many disagreements arose when annotating transitional or intermediary behaviors. Examples included a rapid \"sequential\" read that shifted into a full skim, or a noisy \"sequential\" read with many interruptions, which could appear similar to \u201cnon-sequential\u201d or \"previewing/mapping\" behaviors but still exhibited a distinct \"zigzag\u201d pattern.\nTo enhance the reliability and validity of our work, we implemented a procedure of double-coding all behaviors, resolving disagreements through discussion. During the annotation process, reviewers collaboratively developed and utilized a shared document containing visual examples and detailed descriptions of reading behaviors. This document aided consensus and a shared understanding of the nuanced behaviors observed, while the iterative IRR process further trained annotators and helped identify additional behaviors, aligning with the study's focus on capturing the complexity of in-the-wild reading behaviors.\""}, {"title": "4.2 Behavior Classifier", "content": "To demonstrate the feasibility of using AI to recognize complex and fast-paced reading behaviors, we trained a model using both accumulative and per-behavior statistics derived from the in-the-wild corpus. Tab. 3 provides a detailed summary of per-behavior statistics, including key metrics that characterize the dataset. Tab. 4 provides an overview of the corpus characteristics, while Fig. 7 illustrates accumulative and per-behavior counts, durations, and fixations. A significant challenge was the class imbalance, with the \"sequential\" class dominating the dataset, which limited the ability to represent other behaviors adequately. Furthermore, the brief duration of many behaviors introduced complexity in the segmentation process. Recognizing these constraints, we focused on the \"sequential\u201d, \u201cnon-sequential\", and \"skimming\" behaviors for training, as the limited number of instances for other behaviors restricted their inclusion."}, {"title": "4.2.1 Bag-of-Classifiers.", "content": "We employed a bag-of-classifiers from the Python scikit-learn package [31] for training ML algorithms with a LOPOCV approach. Within each time window, we computed the following accumulative gaze metrics: (1) fixation count, (2) mean fixation duration, (3) fixation dispersion, (4) mean saccade length, (5) saccade vertical next target, (6) saccade horizontal later, (7) saccade line regression rate, and (8) saccade regression rate. We follow the mathematical definitions introduced in Busjahn et al. [4] to compute our input features to the ML algorithms. We sweep across t = [2, 15] time-window sizes. Overall, the performance of ML classifiers increases with large time-window sizes."}, {"title": "4.2.2 CNN Implementation Details.", "content": "Rather than using an accumulative feature time-window approach, more recent methods in time-series analysis leverage CNNs [24] and long short-term memory (LSTM) networks [12]. Given that gaze scanpath data is not time-independent and that both past and current behaviors can influence future predictions, an LSTM approach could be ideal for capturing these temporal dependencies. However, we opted for a CNN-based approach with a short fixation sequence window. The decision to use a CNN was based on its data efficiency; training an LSTM typically requires a larger corpus, can lead to error accumulation over time, and is prone to significant bias errors when working with smaller datasets [37].\nInspired by Cole et al. [9], we developed two CNN-based approaches: a 1D CNN and a 2D CNN. The 1D CNN model takes as input the raw xy fixation subsequence, while the lightweight 2D CNN employs a pretrained ResNet18 backbone [13] with three fully connected layers. This 2D model processes scanplot images generated from scanpath subsequences, examples are shown in Fig. 8. Both methods utilize fixation windows of length 10, allowing for much finer behavior predictions. To compute the classification loss, a standard cross-entropy loss function was used. The CNN models were trained using the Adam optimizer for 50 epochs, with an early stopping mechanism to prevent overfitting. Gaussian noise was add to the input fixation xy points as a data augmentation technique to improve model performance. We performed an exhaustive grid search to identify the ideal hyperparameters for both 1D and 2D CNN including: learning rate, weight decay rate, model design, batch size, and scanpath plot generation."}, {"title": "5 RESULTS", "content": "We present gaze scanpath examples of both instructed and in-the-wild behaviors to illustrate their distinctions. As our gaze-metric data does not follow a normal distribution and remains robust to variability, we use Mann-Whitney U tests [26], a non-parametric statistical method used to compare differences between two independent groups without assuming a normal distribution. To account for multiple comparisons, we apply Bonferroni corrections to compare instructed and in-the-wild conditions. To analyze the differences between \"sequential\" and \"non-sequential\" reading,"}, {"title": "5.1 Contrast between Instructed and In-the-Wild Behaviors", "content": "Our observations of the instructed behaviors showed that students performed the requested tasks, resulting in clean gaze scanpaths, as illustrated in Fig. 9. However, the \"perfection\" of this gaze data limits our ability to capture the natural noise and variability that our theoretical, statistical, and AI models need to account for. Furthermore, instructing students on how to behave based on our hypothesis, rather than observing authentic reading behaviors, restricted our ability to understand naturally occurring reading behaviors. In contrast, the human-driven annotation process of the in-the-wild task allowed us to identify behavioral archetypes, including newly observed behaviors like \u201cnon-sequential\", \"static\", and \"previewing/mapping\". Examples of these in-the-wild behaviors are shown in Fig. 10.\""}, {"title": "5.2 Theoretical Framework and Taxonomy", "content": "Throughout our human-driven annotation process, the language we used to resolve disagreements and describe reading behaviors was instrumental in developing the framework presented in Fig. 12. Reviewers relied on key variables, such as velocity, density, and sequentiality of the gaze scanpaths, when assigning behavior labels and reaching consensus in cases of disagreement. \u201cstatic\u201d behaviors were characterized by stationary gaze scanpaths (near-zero velocity, high density). \"sequential\" and \"non-sequential\" behaviors shared similarities in text progression velocity and density; however, we differentiated them using the sequentiality continuum, which extends the gaze-based measure of linear order proposed by Busjahn et al. [4]. Behaviors such as \"skimming\" and \"previewing/mapping\u201d were identified by their rapid and extremely quick bidirectional fixation sequences, with a broad distribution across the text, respectively.\nFigure 10 presents the archetype examples used by annotators to help communication and achieve consensus during the labeling process, with refined descriptions for each behavior detailed below.\n\u2022 Static: This behavior occurs when WPM approaches zero, and the scanpath remains confined to a small cluster of words for an extended period (approximately 5-10 seconds). While such patterns have been associated with mind wandering in the literature, our study refrains from making such conclusions based on scanpaths alone.\n\u2022 Deep: Deep reading is characterized by the careful re-reading of specific lines or words. Unlike static reading, WPM is notably greater than zero. A key indicator is the repeated traversal of the same line three or more times, signifying a deliberate attempt to comprehend the content in detail.\n\u2022 Sequential: Sequential reading reflects a traditional, line-by-line reading style, often resembling a (potentially noisy) zig-zag pattern. Minor lookbacks are typical and do not disrupt the overall sequential flow. This behavior aligns with standard WPM ranges reported in the literature, accounting for variations in students' age and reading ability. Its primary objective is thorough comprehension of the text.\n\u2022 Non-sequential: Non-sequential reading deviates from the line-by-line pattern. While it shares a similar speed to skimming, its defining feature is its nonlinear trajectory. Unlike skimming, which involves largely forward or backward monotonic movements, non-sequential reading revisits earlier sections of the text within the same paragraph."}, {"title": "5.3 Velocity, Density, and Sequentiality Continua", "content": "The jointplot in Fig. 13a shows the WPM and inverse fixation dispersion for in-the-wild reading behaviors in the log10-log10 scale. Pairwise Hotelling's T-squared tests [20] revealed all pairwise comparisons are statistically significant, as shown in Fig. 5, with the exception of \"previewing/mapping\u201d - \u201cskimming\" pair with a value of p = 0.194. This is likely attributed to their scanpath similarity and the small sample size of \"previewing/mapping\u201d behaviors. The similarity of the jointplot to the theoretical framework and the results of the significance testing further support our behavior regions shown in Fig. 12a.\nTo analyze sequentiality, the box plot in Fig. 13b shows the forward vs. backward saccade ratio (FBSR), as described by Busjahn et al. [4], of \"sequential\" and \"non-sequential\" in-the-wild behaviors. The \"sequential\" and \"non-sequential\" behavior regions overlap with one another, even though visibly having slightly different distributions in Fig. 12a, leverages from the sequentiality continuum to better disambiguate behavior differences. We performed an Independent Two-Sample t-test using Python's SciPy package [38] and identified statistical significance of p < 0.001; therefore, we can reject the null hypothesis and conclude that the \u201csequential\u201d and \u201cnon-sequential\u201d behaviors are different along the sequentiality continuum, agreeing with our theoretical framework shown in Fig. 12b."}, {"title": "5.4 Classification Performance", "content": "The results presented in Table 14a highlight the performance of the 2D CNN model compared to traditional machine learning methods such as a Support Vector Classifier (SVC), a majority classifier, and a random classifier. Moreover, the confusion matrix of the 2D CNN models is shown in Fig. 14b. The 2D CNN model achieved a Macro F1 score of 0.80, outperforming all other baseline methods. This demonstrates that the 2D CNN model can more accurately detect and classify in-the-wild reading behaviors by leveraging the temporal dependencies within fixation sequences. Unlike traditional ML methods, which rely on aggregated time-window approaches, the 2D CNN takes a shorter fixation window as input, enabling more nuanced detection of complex and diverse reading behaviors. This reinforces"}, {"title": "6 DISCUSSION", "content": "For the field to continue improving reading behavior classification, more ecological and in-the-wild research is required. Prior datasets and methods [5, 8, 21] have not taken into consideration the impacts of classroom settings and the high-paced employment of distinct reading behaviors during authentic settings. We have illustrated how instructed"}, {"title": "6.1 Instructed versus In-the-Wild Reader Behaviors", "content": "Our Mann-Whitney U test results have demonstrated the differences between instructed and in-the-wild behaviors for \"sequential\u201d and \u201cdeep\u201d but not \u201cskimming\u201d. This can be attributed to the inherent volatility of \"skim\" reading and/or how reading instruction can impact different reading behaviors unequally [19]. Lastly, our recognition of new in-the-wild behaviors such as \u201cnon-sequential\u201d highlights the gaps in understanding what other possible reading behaviors exist. Capturing the range of reader behaviors and their transitions during reading comprehension provides insights into how students navigate a text and the techniques they employ. It is these tactical shifts from \"sequential\" to \"deep\" or \"previewing/mapping\" that reveal the broader strategies students use, which would be overlooked if our learning theories and models did not account for these in-the-wild behaviors."}, {"title": "6.2 Reading Behavior Framework and Taxonomy", "content": "Our proposed framework and taxonomy for reading behaviors are based on human-coded observations of gaze scanpath videos, incorporating terms related to velocity, density, and sequentiality to distinguish between various behaviors. This approach is well-aligned with prior research on reading behaviors. For instance, in Carver [7], the concept of reading rate and \"gear-shifting\" is heavily reliant on WPM to differentiate between behaviors. Regarding density, Srivastava et al."}, {"title": "6.3 Real-Time Behavior Recognition", "content": "The proposed 2D CNN model with a lightweight ResNet18 backbone achieved a macro F1 score of 0.8 under a challenging LOPOCV setup, demonstrating its capability for real-time reading behavior inference. Benchmarking experiments further support this, with the model achieving an average inference time of 3 ms on a GPU (RTX 3080) and 14 ms on a CPU (11th Gen Intel Core i7-11700F @ 2.50GHz), while gaze scanpath image generation takes 1.5 ms per frame. Given that the input frequency is based on a fixed 10-fixation window (6 seconds), the processing pipeline operates significantly faster than the temporal resolution required for classification. The high variance in reading techniques during naturalistic reading presents a significant challenge for behavior identification, as readers employ a range of strategies from \u201cdeep\u201d reading to \u201cskimming\u201d, often switching behaviors based on context. This variance is particularly evident in the similarity between \"non-sequential\" and \"sequential\" reading, where subtle differences are harder to distinguish compared to more visually distinct behaviors like \u201cskimming\u201d. The mixed \u201cinstructed\" and \"in-the-wild\u201d methodology used in data collection helps capture this range of behaviors, but a larger and more diverse corpus would likely enhance model performance. Increasing the dataset size would allow the model to better generalize and adapt to the natural variability in reading techniques, ultimately improving its accuracy in real-world applications."}, {"title": "7 IMPLICATIONS ON READING INSTRUCTION", "content": "Real-time reading behavior recognition has the potential to revolutionize reading assessment and instruction by providing detailed, context-specific insights into how students interact with texts. By leveraging a classifier that can detect behaviors like \u201cskimming\u201d, \u201csequential reading"}]}