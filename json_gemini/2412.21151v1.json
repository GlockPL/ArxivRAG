{"title": "PyG-SSL: A Graph Self-Supervised Learning Toolkit", "authors": ["Lecheng Zheng", "Baoyu Jing", "Zihao Li", "Zhichen Zeng", "Tianxin Wei", "Mengting Ai", "Xinrui He", "Lihui Liu", "Dongqi Fu", "Jiaxuan You", "Hanghang Tong", "Jingrui He"], "abstract": "Graph Self-Supervised Learning (SSL) has emerged as a pivotal area of research\nin recent years. By engaging in pretext tasks to learn the intricate topological\nstructures and properties of graphs using unlabeled data, these graph SSL models\nachieve enhanced performance, improved generalization, and heightened robust-\nness. Despite the remarkable achievements of these graph SSL methods, their\ncurrent implementation poses significant challenges for beginners and practition-\ners due to the complex nature of graph structures, inconsistent evaluation metrics,\nand concerns regarding reproducibility hinder further progress in this field. Rec-\nognizing the growing interest within the research community, there is an urgent\nneed for a comprehensive, beginner-friendly, and accessible toolkit consisting\nof the most representative graph SSL algorithms. To address these challenges,\nwe present a Graph SSL toolkit named PyG-SSL, which is built upon PyTorch\nand is compatible with various deep learning and scientific computing backends.\nWithin the toolkit, we offer a unified framework encompassing dataset loading,\nhyper-parameter configuration, model training, and comprehensive performance\nevaluation for diverse downstream tasks. Moreover, we provide beginner-friendly\ntutorials and the best hyper-parameters of each graph SSL algorithm on different\ngraph datasets, facilitating the reproduction of results. The GitHub repository of\nthe library is https://github.com/iDEA-iSAIL-Lab-UIUC/pyg-ssl.", "sections": [{"title": "Introduction and Motivation", "content": "Graph Self-Supervised Learning (SSL) has emerged as a pivotal area of research in recent years.\nBy engaging in pretext tasks to learn the intricate topological structures and properties of graphs\nusing unlabeled data [1], these graph SSL models achieve enhanced performance, improved gener-\nalization, and heightened robustness [2\u201312]. Leveraging the representations learned through SSL,\ngraph downstream tasks like node classification, similarity search, and graph classification benefit\nsignificantly [13-20]. For instance, Deep Graph InfoMax (DGI), proposed by Velickovic et al. [21],\naims to maximize the global-local mutual information and capture the high-level summaries of graph.\nMo et al. [22] propose a multi-loss approach to capitalize on the structural and neighbor information,\nthus enriching interclass variation. GraphCL [15] designs various graph augmentation strategies to\naugment the raw graph and then maximize the mutual information between two augmented graphs via\nInfoNCE-style contrastive loss. Hou et al. [23] introduce a masked graph autoencoder with generative\nself-supervised graph learning, specifically tailored to address issues inherent in graph autoencoder.\nDespite the remarkable achievements of these graph SSL methods, their current implementations pose\nsignificant challenges for beginners and practitioners due to the complex nature of graph structures\nand inconsistent evaluation metrics. Additionally, concerns regarding reproducibility continue to\nhinder progress in this field. Recognizing the growing interest within the research community, there\nis an urgent need for a comprehensive, beginner-friendly, accessible toolkit that includes the most\nrepresentative graph SSL algorithms."}, {"title": "Comparison to Related Libraries", "content": "Table 1 compares the key features of existing graph SSL toolkits, where most of them are open-source\ncode delivered with technical papers. DIG-SSL [24] is a unified and highly customizable framework\nfor implementing graph SSL methods. PyGCL [25] is a graph contrastive learning library. These\ntwo packages bear the following limitations: (i) They only support a few SSL algorithms, i.e., 4 in\nDIG-SSL and 7 in PyGCL, and all these SSL algorithms are designed only for homogeneous graphs.\nDifferent from them, our toolkit supports many more SSL algorithms for various types of graphs,\nincluding homogeneous graphs, heterogeneous graphs, and molecular graphs; (ii) PyGCL does not\nprovide user-friendly tutorials, which poses great challenges to beginners; (iii) Graph augmentation\nis a key feature in graph self-supervised learning [7], which is missing in DIG-SSL; (iv) Our toolkit\naddresses the crucial reproducibility by offering the best hyper-parameters for different datasets in\nconfiguration files, which is absent in both DIG-SSL and PyGCL."}, {"title": "Related Works", "content": "Graphs are ubiquitous and are widely used for ranking [26\u201329], social network analysis [30\u201339],\nrecommendation [40\u201347], question answering [48\u201351], spatial-temporal modeling [52\u201355] and text\nsummarization [56] etc. Graph Representation Learning (GRL) aims to transform graph-structured\ndata into low-dimensional representations, while preserving the graph's structural and semantic\ninformation. DGI [57] maximizes mutual information between subgraph representations and global\ngraph summaries, enabling effective reuse for downstream node-level tasks. BGRL [58] learns node\nrepresentations by encoding two augmented graph views using an online encoder and a target encoder,\nwhere the online encoder predicts the target encoder's representations. InfoGraph [16] maximizes the\nmutual information between the graph-level representation and the representations of substructures\nof different scales. GraphMAE [23] focuses on feature reconstruction with a masking strategy and\nscaled cosine error to enable robust training via generative self-supervised graph pretraining.\nContrastive learning [59\u201367] has garnered significant attention from researchers for its exceptional\nperformance in modeling unlabeled data. Many recent works on graph contrastive learning [7,\n10, 15, 68-73] demonstrate the effectiveness of applying contrastive learning to learn the high\nquality representation in unsupervised, semi-supervised and transfer learning settings. For instance,\nGraphCL [15], JOAO [7] and GCA [74] study the impact of graph augmentations when minimizing\ngraph contrastive learning loss. Graph Contrastive Coding (GCC) [4] uses contrastive learning"}, {"title": "Design of PyG-SSL", "content": "Our PyG-SSL is designed as a user-friendly Python library for general audiences of beginners and\npractitioners who are interested in graph SSL methods and the applications of these methods in\ndownstream tasks. As illustrated in Figure 1, our framework can be divided into four components:\n\u2022 Configuration: Users can specify detailed configurations for GNNs, SSL methods, etc.\n\u2022 Method: A variety of SSL methods, e.g., DGI, can be called to pre-train GNNs.\n\u2022 Trainer: A trainer that automatically trains the graph SSL method based on the provided\nconfigurations.\n\u2022 Evaluator: Multiple downstream evaluators, such as support vector machine (SVM), are readily\navailable for users to assess the performance of pre-trained GNNs.\nIn addition, our library provides various augmentations, similarity functions, and losses used in the\nSSL literature for users to build their own SSL methods. Under the MIT License, our toolkit relies\nsolely on open-source libraries.\nWe will now provide a detailed explanation of each component in the framework.\nConfiguration. PyG-SSL provides an easy-to-use configuration function to load the hyper-parameters\nfor data loader, model, optimizer, and classifier. The configurations of the data loader include the\ndataset name, root path to load the dataset, and batch size. The configurations of the optimizer contain\nthe learning rate, optimizer name, maximal training epoch, patience epoch, and weight decay. Model\nconfigurations mainly consist of default hyperparameters for training. The configurations of the\nclassifier include the hyper-parameters for model evaluation in the downstream task. To facilitate the\nreproduction of results, we provide beginner-friendly tutorials and the optimal hyper-parameters of\neach graph SSL algorithm on different graph datasets.\nMethod. The method module in PyG-SSL aims to integrate the major functions of different graph\nself-supervised techniques. Specifically, the graph self-supervised techniques include augmentation\nmethods for graph contrastive learning (e.g., data augmentation [7, 15] or embedding augmenta-\ntion [75]), graph encoders to learn hidden representation (e.g., GIN [76], GCN [77], GAT [21])\nand various loss functions for model training (e.g., InfoNCE-style loss [15], masked reconstruction\nloss [23], etc.). The implemented graph self-supervised methods include DGI [2], GraphCL [15],\nAFGRL [78], MVGRL [3], GCA [74], BGRL [58], SUGRL [22], ReGCL [79], InfoGraph [16],\nGraphMAE [23], etc.\nTrainer. The trainer module takes the data loader and the graph self-supervised learning as input\nand trains the model until convergence. Additionally, we implement early stopping criteria to reduce"}, {"title": "Documentation and Code Example", "content": "We release our software with publicly available documentation at https://pygssl-tutorial.\nreadthedocs.io/en/latest/. Our documentation covers the four major components of PyG-SSL\nand graph self-supervised methods in various research papers. The documentation also includes an\nin-depth tutorial guide and a tour of external resources. In our GitHub repository, we offer code\nexamples for all papers whose methods have been implemented in our library. The documentation\nalso features examples of configuration, method setup, model training, and evaluation. One such\nexample is visualized in Figure 2."}, {"title": "Experimental Evaluation", "content": "Datasets. PyG-SSL evaultes the performance of graph self-supervised methods on six widely-used\ndatasets, including WikiCS [80], Coauthor [81], Amazon-Photo [82], IMDB-B [83], IMDB-M [84]\nand Mutag [85]. The data statistics of these datasets are summarized in Table 2."}, {"title": "Conclusion", "content": "In this paper, we present the Graph Self-Supervised Learning Toolkit (PyG-SSL), a user-friendly\nlibrary designed to streamline and advance research in graph self-supervised learning. Our toolkit\noffers a comprehensive solution for implementing and experimenting with a wide array of state-of-\nthe-art graph SSL methods. With robust support for various graph types and a unified framework that\nsimplifies tasks such as dataset loading, hyperparameter tuning, model training, and performance\nevaluation, PyG-SSL empowers both beginners and experienced practitioners to efficiently explore\nand apply graph SSL techniques. The evaluations of numerous graph SSL methods included in\nPyG-SSL offer practical insights for selecting the most suitable approaches for different tasks. PyG-\nSSL not only stands as a significant advancement in graph SSL but also complements other related\nlibraries, fostering a collaborative and evolving landscape in graph-based research and applications."}]}