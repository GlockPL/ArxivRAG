{"title": "Finding Optimal Trading History in Reinforcement Learning for Stock Market Trading", "authors": ["Sina Montazeri", "Haseebullah Jumakhant", "Amir Mirzaeinia"], "abstract": "This paper investigates the optimization of temporal windows in Financial Deep Reinforcement Learning (DRL) models using 2D Convolutional Neural Networks (CNNs). We introduce a novel approach to treating the temporal field as a hyperparameter and examine its impact on model performance across various datasets and feature arrangements. We introduce a new hyperparameter for the CNN policy, proposing that this temporal field can and should be treated as a hyperparameter for these models. We examine the significance of this temporal field by iteratively expanding the window of observations presented to the CNN policy during the deep reinforcement learning process. Our iterative process involves progressively increasing the observation period from two weeks to twelve weeks, allowing us to examine the effects of different temporal windows on the model's performance. This window expansion is implemented in two settings. In one setting, we rearrange the features in the dataset to group them by company, allowing the model to have a full view of company data in its observation window and CNN kernel. In the second setting, we do not group the features by company, and features are arranged by category. Our study reveals that shorter temporal windows are most effective when no feature rearrangement to group per company is in effect. However, the model will utilize longer temporal windows and yield better performance once we introduce the feature rearrangement. To examine the consistency of our findings, we repeated our experiment on two datasets containing the same thirty companies from the Dow Jones Index but with different features in each dataset and consistently observed the above-mentioned patterns. The result is a trading model", "sections": [{"title": "1 Introduction", "content": "Integrating Deep Reinforcement Learning (DRL) in financial market analysis significantly evolved investment analysis with Deep Learning. DRL combines deep learning and reinforcement learning to offer a sophisticated framework for adapting strategies in the dynamic financial domain. It allows a deep learning model to effectively decipher complex patterns in historical market data often overlooked by traditional quantitative models. It is no secret that financial markets are inherently complex and influenced by economic trends and geopolitical events. Therefore, traditional financial modeling often struggles to adapt to these ever-changing conditions. However, with its direct learning from data and adaptive strategies, DRL presents a promising solution to these challenges. With its autonomous learning ability and continual adaptation to the financial environment, it leverages historical market data to identify complex relationships and patterns."}, {"title": "1.2 Overview of Our Previous Work", "content": "In recent years, significant progress has been made in applying deep reinforcement learning (DRL) to stock trading strategies. For instance, Wang et al. proposed a parallel multi-module DRL algorithm that effectively captures both current market conditions and long-term dependencies using fully connected and LSTM layers [11]. Zhang et al. introduced an automated stock trading system based on the Proximal Policy Optimization algorithm,"}, {"title": "2 Objectives of the Current Study", "content": "So far, we have presented the literature and the setting in which our study operates. The primary objective of our research is to explore the effects of changing the temporal window of a Convolutional Neural Network (CNN) used as a policy in a FinRL. By progressively expanding the observation period, beginning with a concise two-week window and incrementally enlarging it by two weeks in each iteration and culminating in twelve weeks, we aim to observe and analyze the performance of our model as its temporal window changes in the FinRL platform. This iterative window expansion is designed to examine the impact of different temporal scales on the model's performance. This process enables a comprehensive analysis of how varying lengths of financial data affect the model's predictive capabilities, offering insights and an opportunity to optimize the temporal granularity for financial market analysis. Our study also examines the arrangement of feature vectors within these expanding windows to better understand the model-market dynamics.\nFurthermore, we contrast the model's performance across these different temporal windows to discern patterns in market behavior and model performance. In our study, short-term windows, particularly the initial two-week period, are hypothesized to be critical for understanding the model's ability to capture immediate market changes and short-term trends, which are essential for timely and accurate trading predictions. As the window expands, the model is expected to integrate a broader spectrum of market conditions, capturing longer-term trends and patterns. This bi-weekly expansion strategy is designed to balance the benefits of short-term immediacy and long-term historical perspective, ensuring the model remains adaptable and responsive to transient market fluctuations and enduring trends. We hope to contribute to financial analytics by demonstrating the efficacy of CNNs"}, {"title": "3 Literature Review", "content": ""}, {"title": "3.1 Classic ML approachs", "content": "When studying the progressive advancements in this field, the classical Machine Learning (ML) approach in financial analytics primarily revolves around statistical models that have formed the bedrock of quantitative finance. Linear regression, one of the most fundamental techniques, has been extensively utilized for predicting financial trends and stock prices. Its effectiveness in financial forecasting is documented in \"Analysis of Financial Time Series\" by Tsay [18], offering a comprehensive understanding of linear models in finance. Moreover, decision trees have been widely employed for risk assessment and credit scoring, as demonstrated in the study by Kumar and Ravi [9], showcasing their ability to handle categorical and continuous input variables effectively. However, despite their widespread application, these classical models often struggle with financial data's non-linearity and high dimensionality characteristic. This limitation, as highlighted in the survey by Atsalakis and Valavanis [2], clearly indicates the need for more advanced approaches in capturing the complex dynamics of financial markets, especially in volatile or unpredictable scenarios."}, {"title": "3.2 Neural Networks in DRL", "content": "Integrating Neural Networks and Deep Reinforcement Learning (DRL) into financial market analysis represents a significant leap forward from traditional ML methods. As outlined in the groundbreaking work by Mnih et al. [12], DRL combines the depth and complexity of deep neural networks with the decision-making prowess of reinforcement learning, creating a powerful tool for financial analysis. This approach, which allows for direct learning from vast amounts of unstructured market data, effectively identifying intricate patterns and trends, is a game-changer in the field. Convolutional Neural Networks (CNNs) application within DRL, in particular, has further advanced the field. CNNs, renowned for their ability to process high-dimensional sequential data, are highly effective in capturing temporal and spatial dependencies in financial time series. This is exemplified in the research by Tsantekidis et al. [17]., which utilized CNNs to analyze and predict stock prices from limited order book data, demonstrating the model's proficiency in handling complex financial datasets. The success of DRL in financial applications lies in its ability to continually adapt and learn in an ever-changing environment, a crucial feazture given the dynamic nature of financial markets.\nDespite these advancements, there remains a gap in understanding how the temporal scope of input data affects CNN performance in financial DRL models. Our study addresses this gap by systematically exploring various temporal windows and feature arrangements."}, {"title": "4 Hypothesis", "content": "Convolution operations are fundamental to Convolutional Neural Networks (CNNs), which are particularly effective in processing data with a grid-like topology, such as images and sequential data [4] [6]. The convolution operation can be understood as a mathematical process that combines two sets of information. In the context of CNNs, this involves a convolutional kernel (or filter) moving across an input signal (such as an image or time series data) to produce a feature map.\nMathematically, for continuous signals, the convolution operation is defined as:\n(S* K)(t) = \\int_{-\\infty}^{\\infty} S(\\tau)K(t - \\tau)d\\tau\nHere, S represents the input signal, and K represents the convolutional kernel. This integral computes the area under the product of the two functions as the kernel slides over the input signal. However, in practical applications involving digital data, the signals are discrete, and thus the convolution operation is adapted to:\n(SK)[n] = \\sum_{m=-M}^{M} S[m]K[n-m]\nIn this discrete form, the convolution operation involves summing the element-wise products of the input signal and the kernel as it moves across the input. The result is a new set of values (the feature map) that highlight certain features of the input signal, such as edges in an image or patterns in sequential data [7].\nThe size of the convolutional kernel (or filter) is a critical parameter in this operation. The kernel size determines the local region from which features are extracted. A larger kernel can capture more contextual information by encompassing a wider region of the input signal, while a smaller kernel focuses on finer details. The balance between capturing local and global features is essential for the performance of CNNs [5].\nAdditionally, the padding applied to the input signal before convolution affects the output size and the nature of the features extracted. Padding involves adding extra values (typically zeros) around the input signal, which allows the kernel to process edge regions more effectively. The output size of the convolution operation is given by:\nO = \\frac{N-K+2P}{S}+1\nwhere N is the input size, K is the kernel size, P is the padding, S is the stride (the step size of the kernel), and O is the output size. Properly setting these parameters ensures that the CNN can effectively learn and extract meaningful features from the input data [3]. Understanding these concepts is crucial for optimizing CNN architectures, especially in settings where the observation window size can significantly impact the model's performance.\nThe performance of Convolutional Neural Networks (CNNs) in processing sequential data is significantly influenced by the size of the observation window used in the convolutional layers. The kernel size in a convolution layer determines the local region from which features are extracted. Larger kernels can incorporate more contextual information, but excessively large kernels may dilute distinct features. The optimization of window size can be expressed through the effective window size equation:\nWeff = Wkernel + (Wkernel - 1) \\times (D - 1)\nwhere Weff is the effective window size, Wkernel is the kernel size, and D is the dilation factor.\nFurthermore, the role of padding in convolution processes influences the spatial dimensions of the output feature map, described by:\n\u039f = \\frac{N-K+2P}{S}+1\nwhere N is the input size, K is the kernel size, P is the padding, S is the stride, and O is the output size. Excessive padding can lead to overemphasis on peripheral data and potential overfitting, similar to how an over-expanded window size may cause information overload, making distinct features less discernible:\nInformation Overload \\propto \\frac{Weff}{Distinct Features}\nTherefore, a crucial balance is needed between capturing local and global features. We hypothesize that the optimal selection of a temporal window size in a CNN balances local feature detection and global contextual understanding. An optimally sized window allows the model to effectively capture relevant features without succumbing to information overload or excessive generalization, thereby enhancing accuracy and performance in sequential data processing tasks [7].\nGiven that our CNN acts as a policy for a Deep Reinforcement Learning (DRL) algorithm, the window size as a hyperparameter will be optimized through reinforcement learning. This optimal window size is found at the point where local and global feature detection are balanced:\nOptimal Window Size \\leftrightarrow min (\\Delta_{Local-Global})\nwhere $\\Delta_{Local-Global}$ measures the differential in information capture between local and global features. This hypothesis suggests that through careful tuning and reinforcement learning, the CNN can achieve an optimal window size that maximizes performance in sequential data tasks."}, {"title": "5 Methodology", "content": "In this study, we have integrated Deep Reinforcement Learning (DRL), Proximal Policy Optimization (PPO), and the Markov Decision Process (MDP) framework. The integration method is adopted from FinRL [10], providing a robust and dynamic model capable of navigating the complexities of financial markets. DRL offers the foundational learning mechanism, MDP provides a structured approach to decision-making in uncertain environments, and PPO ensures efficient and stable policy optimization. Together, these methodologies create a sophisticated model capable of learning, adapting, and optimizing trading strategies in real-time financial scenarios. The upcoming sections will describe each component in detail, beginning with an overview of DRL and its significance in our framework."}, {"title": "5.1 Deep Reinforcement Learning (DRL)", "content": "Deep Reinforcement Learning (DRL) integrates the pattern recognition capabilities of Deep Learning with the decision-making framework of Reinforcement Learning. This synergy enables the development of sophisticated models that can autonomously adapt to the complex and dynamic nature of financial markets, learning to optimize strategies based on data-driven insights. By leveraging vast and varied datasets, DRL models can identify latent patterns and trends, dynamically adjusting strategies by continually learning from market data. This ability to process high-dimensional data and make real-time decisions significantly advances over traditional quantitative approaches.\nDRL's ability to respond to market volatility and changes is crucial in financial markets. It addresses the high dimensionality of financial data and the need for timely decision-making. This forms the basis for integrating Proximal Policy Optimization (PPO), which enhances the stability and efficiency of our learning process."}, {"title": "5.2 Markov Decision Process (MDP)", "content": "The Markov Decision Process (MDP) provides a mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision-maker. MDPs are fundamental to understanding reinforcement learning and are particularly relevant in financial applications where decisions must be made under uncertainty.\nIn our study, MDPs model the sequential decision-making process, where each action the agent takes affects future states and rewards. We represent the trading environment as an MDP with states, actions, and rewards meticulously defined to capture the intricacies of financial markets. The state space encapsulates key financial indicators, the action space comprises various trading actions, and the reward function reflects financial gains or losses. This representation allows our DRL model to effectively learn and optimize trading strategies over time, accounting for the probabilistic nature of financial markets and the impact of each decision on future market states. With the MDP framework providing the foundation for decision-making, we now turn to the role of feature extraction in our DRL agent, specifically through Convolutional Neural Networks (CNNs)."}, {"title": "5.2.1 MDP Model for Stock Trading", "content": "The trading market is a stochastic and interactive environment in nature and can be formulated as a Markov Decision Process (MDP) with state, action, and reward.\n\u2022 State s = [b,p, h, f] : a set that consist of balance b, price p \u2208 R, holdings of stock h\u2208 Z, and fundamental indicators f. where D is the number of stocks that we consider in the market. Fundamental indicators covers financial ratios listed in tables 2, 4.\n\u2022 Action a = [sell, buy, hold] : a set of actions for all D stocks, consisting of sell, buy, hold which leads to a reduction, growth, or no alteration in the holdings h, correspondingly.\n\u2022 Reward r(s,a,s'): The adjustment in portfolio value upon executing action \"a\" in state \"s\" and transitioning to the next state \"s\". The portfolio value encompasses the total value of equities in the held stocks, denoted as pth, plus the remaining balance, \"b\".\n\u2022 Policy \u03c0(s): The stock trading approach in state \"s\" entails the probability distribution of \"a\" in the state \"s\".\n\u2022 The action-value function Q\u03c0(s, a) represents the anticipated reward obtained by taking action \"a\" in state \"s\" according to policy \u03c0.\nThe primary objective of this process is to optimize (maximize) the reward. Various published approaches exist for addressing this challenge, each with its own set of advantages and disadvantages [16]. We select PPO which is commonly used and show higher performance than other approaches."}, {"title": "5.2.2 Proximal Policy Optimization (PPO)", "content": "Proximal Policy Optimization (PPO) is a cornerstone of our methodology, providing a robust approach to policy gradient optimization. PPO iteratively updates the policy in a controlled manner, minimizing the cost function while ensuring minimal deviation from the previous policy. This approach is achieved through a clipped objective function, which restricts the extent of policy updates at each iteration. PPO maintains stability during the learning process by comparing the new policy's performance to the old policy and ensuring updates occur only if they improve performance within a specified margin."}, {"title": "5.3 CNN is as a Feature Extraction Network", "content": "The CNN integration into FinRL is facilitated through a specialized gym environment simulating stock trading scenarios. This environment includes quantitative elements of the stock market, such as stock prices, trading volumes, and various financial ratios, which are fed into the CNN for analysis, and the CNN's role within this environment is to extract high-level features from the input data, which are then utilized by the DRL agent to make trading decisions. By transforming raw financial data into meaningful features, the CNN enables the DRL agent to learn and optimize trading strategies effectively.\nWithin this framework, our previous work has demonstrated that using Convolutional Neural Networks (CNNs) in Deep Reinforcement Learning (DRL) for financial applications is notably effective. The CNN model processes input states comprising stock prices and technical indicators, capturing complex patterns and relationships within the data. This enables the model to autonomously learn and adapt strategies, making informed trading decisions based on a deeper understanding of market behavior.\nThe CNN acts as a feature extractor within the DRL framework. It processes the raw financial data, learning to identify relevant patterns and trends. These extracted features are then fed into the DRL agent, which uses them to make trading decisions. This integration allows the model to adapt its feature extraction process based on the rewards received, creating a dynamic learning system that evolves with changing market conditions."}, {"title": "5.3.1 CNN Architecture", "content": "As mentioned before, CNN architecture used in our study is designed to handle the multidimensional nature of financial data and train on extensive datasets. Leveraging convolutional layers, batch normalization, and ReLU activation functions enhances this model's feature extraction and pattern recognition robustness. CNN's ability to capture localized features and temporal dependencies is critical in financial markets rich in temporal dynamics and complex patterns.\nThe feature extraction process involves CNN identifying localized features and temporal dependencies within the financial data. Its ability to capture these dynamics ensures that the DRL agent can adapt its strategies in response to changing market conditions. The effectiveness of CNN as a feature extractor is further enhanced by its capacity to handle large datasets and complex input structures. This capability allows the model to leverage vast historical and real-time market data, improving its predictive accuracy and decision-making performance.\nThe network comprises two primary convolutional layers: the first layer features a kernel size of 8 and a stride of 4, while the second layer has a kernel size of 4 and a stride of 2. Both layers include 2D batch normalization, enhancing the network's efficiency in learning from the data by stabilizing the learning process. The data is then flattened and fed into a fully connected neural network layer with ReLU activation, integrating the extracted features for decision-making. The parameter specifications of our CNN network architecture are listed in Table 1.\nThe choice of this specific architecture was motivated by its ability to capture both short-term price movements and longer-term trends. The kernel sizes (8 and 4) were selected to allow the model to focus on weekly and monthly patterns, respectively, while the stride values (4 and 2) help in reducing computational complexity without significant loss of information."}, {"title": "5.4 Iterative Window Expansion Technique", "content": "We conducted 24 structured experiments across six temporal intervals ranging from 2 to 12 weeks, in 2-week increments. Each interval was chosen in 2-week increments, providing a range of short- to medium-term observations. We utilized two distinct dataset types for each timeframe: the Technical Indicator dataset and the Simple Moving Average (SMA) dataset. While these datasets encompass the same companies and timeframes, they include different features for each company. Each dataset was analyzed under two scenarios: one with rearranged features, grouping all columns associated with a single company, and another without rearrangement. This dual-path strategy, uniformly applied across all intervals, resulted in 24 unique experimental setups, comprehensively evaluating the CNN's performance and robustness under various temporal and data scenarios (Figure 2)."}, {"title": "5.4.1 Initial Two-Week Window", "content": "The study begins with a concise two-week observation window, targeting short-term market trends to establish a baseline for model performance. This initial phase is critical for understanding the model's responsiveness to recent market changes and its ability to capture short-term patterns. The two-week window helps the model make timely and accurate predictions in the fast-paced financial trading environment by focusing on the most recent and relevant data points."}, {"title": "5.4.2 Bi-Weekly Expansion Strategy", "content": "Following the initial phase, we bi-weekly expanded the observation window, incrementally integrating more historical data. This gradual enlargement enables the model to assimilate information from a widening scope of market conditions, capturing more extensive long-term trends and patterns. The bi-weekly increments strike a careful balance, incorporating fresh data while retaining the benefits of an extended historical view. This approach ensures the model remains agile, effectively responding to immediate market changes and more substantial, enduring trends."}, {"title": "5.4.3 Final Twelve-Week Window", "content": "The process culminates with a twelve-week window, providing an exhaustive perspective on market trends and behaviors over an extended duration. This elongated observation period supplies the model with a diverse and comprehensive dataset, reflecting a broad spectrum of market activities. The value of the twelve-week window lies in its ability to reveal longer-term market trends and cyclical patterns, which are pivotal for strategic decision-making in financial trading. This concluding phase is crucial for evaluating the model's capacity to generalize and maintain consistent performance across various market cycles."}, {"title": "5.5 Rearranged Features Approach", "content": "Expanding upon our previous research, this paper also investigates the impact of feature rearrangement within expanded temporal windows. The rearranged features setting entails reorganizing the columns of the input data tensor to keep related features in proximity to each other. This arrangement aims to boost the capability of the CNN in identifying relevant patterns from the data, aligning with the underlying relationships and correlations inherent in financial indicators. Presenting the CNN with inputs specifically structured to reflect the interconnected nature of financial metrics is expected to enhance the model's accuracy and generalization ability. This preprocessing strategy is particularly pertinent in financial data analysis, where the interactions between various data types (such as stock prices, transaction volumes, and technical indicators) are often more critical than the individual data points. This approach is intended to promote more efficient learning, improving the model's robustness and adaptability when deployed on a wide range of financial datasets."}, {"title": "5.6 Our Datasets", "content": "To ensure the robustness of our approach, we utilized two distinct datasets from the FinRL and FinRL Meta projects. This methodology helps confirm that the success of our methods is not merely coincidental."}, {"title": "5.6.1 The SMA Dataset", "content": "The first SMA data dataset is adapted from the FinRL Meta project. This dataset encompasses quantitative financial features, including fundamental market data such as opening, high, low, and closing prices and trading volume. Additionally, it includes a series of engineered features like MACD, Bollinger Bands, RSI, CCI, and DX over 30 days, in addition to the 30-day and 60-day closing simple moving averages (SMAs), the VIX, and a turbulence measure. This rich compilation provides an extensive perspective on market trends and volatility, crucial for the Convolutional Neural Network (CNN) model's analysis across varying timeframes."}, {"title": "5.6.2 Feature Vector: A Trading Day in the Market", "content": "Each trading day in the stock market includes a feature vector comprising the initial monetary amount, stock prices of twenty-nine companies, their corresponding shares held, and a set of eight quantitative features for each company. These indicators include MACD, Bollinger Bands (upper and lower), RSI 30, CCI 30, DX 30, 30-day and 60-day SMAs. The total feature vector comprises 261 elements: one for the initial amount, 29 for stock prices, 29 for shares held, and 232 derived from technical indicators (eight per company). Integrating these technical indicators, which play a critical role in signaling market trends and momentum, equips the dataset as an essential tool for the CNN model. It enables the model to identify and leverage market trends effectively, facilitating precise predictions and informed decision-making in the dynamic financial trading environment."}, {"title": "5.6.3 The Technical Indicator Dataset", "content": "The Technical Indicator Dataset offers an in-depth view of financial performance metrics, distinguishing itself from the SMA dataset with a more extensive set of financial ratios and metrics. While it also includes fundamental trading data such as opening price, highest price, lowest price, closing prices, and trading volume, its uniqueness lies in incorporating a diverse range of financial ratios. These include Operating and Net Profit Margins, Return on Assets, Return on Equity, various liquidity ratios (Current, Quick, Cash), turnover ratios (Inventory, Accounts Receivable, Accounts Payable), Debt Ratio, Debt to Equity Ratio, and market valuation ratios like PE, PB, and Dividend Yield. This dataset is instrumental in offering a detailed assessment of instruments' financial health and market valuation, a critical aspect of the nuanced market analysis conducted by our Convolutional Neural Network (CNN) model."}, {"title": "5.6.4 A Different Feature Vector", "content": "The daily feature vector within this dataset is structured to provide an exhaustive market perspective through a multidimensional data array. This table comprises several components: the initial amount, stock prices of thirty companies, the number of shares currently owned in the simulation, and fifteen distinct financial ratios for each of the thirty companies. These ratios, extracted from each company's financial statements, offer vital insights into their financial performance. The feature vector, encompassing the data for one trading day in the stock market, contains 511 elements: one for the initial amount, 30 for stock prices, 30 for shares held, and 450 derived from the financial ratios (15 per company). This elaborate dataset is essential for the CNN model, enabling the analysis and interpretation of intricate patterns and correlations within the financial markets."}, {"title": "6 Results", "content": ""}, {"title": "6.1 Experimentation on the Technical Indicator Dataset", "content": "The analysis of the Technical Indicator dataset, without any feature rearrangement, as illustrated in the figure below, uncovers a notable pattern in the accumulation of rewards over different time intervals. The most significant gain, observed in the 2-week observation size, reached a cumulative reward of 155.89. This finding highlights the efficacy of this specific observation window. The peak performance noted within this 2-week timeframe may constitute the most advantageous period for analysis in the context of this dataset and its feature composition. This observation window provides the optimal balance mentioned in our hypothesis section, generating the most significant rewards in the given feature arrangement setting and dataset.\nThe extended analysis of the Technical Indicator dataset over periods ranging from 4 to 12 weeks reveals a discernible decline in cumulative rewards, reaching its lowest point at the 10-week interval, where the reward significantly drops to 104.58. This downward trajectory, although slightly mitigated in the 12-week observation window, predominantly suggests diminishing returns as the duration of the observation period increases. This pattern serves as a crucial insight, highlighting the limitations of the convolutional neural network (CNN) in effectively utilizing longer observation windows for this specific dataset and feature configuration. This trend underscores the importance of strategically selecting the observation window to optimize the CNN's predictive performance, and it supports our hypothesis that information overload can diminish the CNN's ability to utilize most important features in the input tensor.\nDuring the analysis of the Technical Indicator dataset with rearranged features, as depicted in the figure below, we found a markedly different trend in cumulative rewards across varying timeframes compared to the dataset with the original feature arrangement. The rearranged dataset demonstrates a similar pattern, where the peak cumulative reward is noted at the 10-week mark, registering at 121.59. This outcome indicates that the rearrangement of features shifts the optimal observation window to bigger sizes. Notably, a prolonged 10-week period emerges as most favorable in the rearranged dataset, in stark contrast to the 2-week window size identified as optimal in the original dataset configuration. This finding suggests that feature rearrangement significantly improves the model's ability to utilize longer observation windows, again underscoring the need for adaptable strategies in financial data analysis with CNNs.\nAs depicted in the figure, rearranging features within the technical indicator dataset markedly improves the model's capacity to capitalize on extended observation windows. Notably, the model's optimal performance, demonstrated at the 10-week interval with a cumulative reward of 121.59, signifies an enhanced ability to utilize more extended periods for analysis. This reorganization of features enables a more efficient interpretation of extended-term trends, optimizing the model's accuracy over such durations. This finding emphasizes the vital importance of feature engineering in amplifying the effectiveness of Convolutional Neural Networks, particularly in intricate and dynamic settings like financial market analysis.\nIn contrast, a different pattern emerges when analyzing the technical indicator dataset without feature rearrangement, as illustrated in the corresponding plot. Here, the 2-week interval emerges as the most productive timeframe, registering the highest cumulative reward of 155.89. This finding indicates that in its original configuration, the dataset is optimally tuned for short-term analysis, showing diminishing performance with lengthening observation periods, except for a slight increase at 12 weeks. However, these extended periods do not outperform the initial 2-week observation window. This trend highlights the model's predisposition towards shorter timeframes when processing the non-rearranged data, underscoring the impact of data structuring on the model's temporal adaptability and predictive power.\nThe contrasting results observed in the rearranged technical indicator data are striking. In this scenario, the model strides in the 10-week observation period, achieving a cumulative reward of 121.59. This shift from the optimal 2-week period in the non-rearranged data to a more extended 10-week period in the rearranged data is significant. The rearranging of features profoundly influences the model's efficiency in capturing and forecasting market trends. Compared to the reduced effectiveness in shorter durations, the enhanced performance at this longer interval underscores the impact of data sequencing on the model's predictive precision. This observation again stresses the criticality of data arrangement and preprocessing in financial time series analysis, as it can substantially alter the model's interpretation and response to market dynamics over different temporal scales."}, {"title": "6.2 Experimentation on the SMA dataset", "content": "The analysis of the SMA dataset without data rearrangement reveals a distinct pattern in cumulative rewards over various timeframes, as shown in Figure 6. The most significant performance is apparent in the 2-week observation window, achieving a peak cumulative reward of 184.05. This high point suggests that a 2-week observation window is particularly effective for this dataset, indicating an optimal short-term period for analysis in this context.\nAs the observation window extends, a decreasing trend in cumulative rewards is evident, particularly at 8 and 12 weeks, with rewards noted at 99.80 and 105.99, respectively. However, an unexpected increase in cumulative reward to 144.22 at the 10-week mark presents an intriguing anomaly. This inconsistency might indicate complex, possibly cyclical patterns in the SMA dataset, which the model discerns differently across various intervals. This behavior further highlights the intricate nature of these quantitative indicators and emphasizes the importance of selecting an appropriate observation window for predictive modeling.\nA different outcome is observed in the analysis of the SMA dataset with feature rearrangement. The 4-week interval emerges as the most favorable, registering a peak cumulative reward of 181.84. This result contrasts the lower performance in the 2-week window, where the cumulative reward is 117.14. This discrepancy suggests that rearranging the data may significantly alter the model's ability to utilize temporal relationships in the data, affecting its effectiveness across different timeframes. The rearranged dataset's peak at a longer interval underlines the same pattern where feature arrangement enhances the model's ability to effectively capture and analyze market trends.\nHowever, an irregular trend emerges as the observation period extends beyond 4 weeks. A marked decrease in cumulative rewards is noted at 6 and 8 weeks, with figures falling to 101.04 and 90.77, respectively. Intriguingly, there is a modest reward recovery at the 10 and 12-week intervals. This pattern suggests that the model may interpret different characteristics of the rearranged SMA dataset over extended timeframes. Such fluctuations in performance underscore the added complexity due to data rearrangement and the importance of carefully choosing the observation window to maximize the model's efficacy."}, {"title": "6.3 Best Performers in the SMA Dataset", "content": "In the next phase of our data analysis, we conducted a comparative study of optimal timeframes in the simple moving average (SMA) dataset, considering its original and rearranged forms, as shown in the plot. This revealed distinctive trends.\nIn the case of the non-rearranged SMA dataset, the most effective timeframe emerges as the 2-week window, registering a peak cumulative reward of 184.05. This notable performance at the shorter interval indicates the model's ability to effectively capture the prevailing trends within the original SMA data structure. As the observation period extends, a gradual decline in cumulative rewards is observed across longer timeframes. Although there is a marginal uplift in performance at the 10-week mark, this is within the benchmark set by the 2-week observation window, which means that the pattern still highlights the dataset's responsiveness to short-term fluctuations.\nThe clear differentiation in performance across various timeframes suggests that the underlying dynamics of the SMA dataset are more readily discernible and exploitable in shorter intervals when the data remains in its original sequence. This insight is pivotal for financial analysts and modelers, emphasizing the need for strategic consideration of time windows in predictive modeling, especially when dealing with complex financial datasets like the SMA.\nIn contrast, after rearranging the features in the SMA dataset, our analysis presents a different optimal timeframe. The 4-week window emerges as the best performer with a cumulative reward of 181.84, indicating a significant shift in the model's ability to utilize longer temporal windows. Our analysis also shows a more pronounced decline in performance for other timeframes, especially at 6 and 8 weeks. We noted that the 2-week observation size was the best performer in the non-rearranged data versus the 4-week peak in the rearranged data. Once again, the sharp contrast between the non-rearranged and rearranged data demonstrates the model's temporal processing ability."}, {"title": "6.4 Best Performers overall", "content": "Several insightful trends emerge in our final analysis of the datasets, encompassing both the SMA and Technical Indicator datasets. In its original feature arrangement, the SMA dataset exhibits strong performance in the 2-week timeframe, reaching a cumulative reward of 184.057, the highest across all datasets and timeframes. This result underscores the effectiveness of short-term observation in capturing market dynamics with this dataset. On the other hand, when the SMA features are rearranged, the 4-week window becomes the most productive, achieving a cumulative reward of 181.84. This shift suggests that market dynamics are captured more effectively over shorter temporal windows, but once features are rearranged, a slightly extended observation size proved more effective.\nThe observed trends in the Technical Indicator dataset echo those seen in the SMA dataset, particularly in the context of the original sequence. A 2-week observation window demonstrates optimal effectiveness, reaching a peak cumulative reward of 155.89. This similarity across the datasets consistently proves our decerned pattern that, without shorter observation periods, can be highly effective for predictive modeling. However, a significant shift occurs when the data sequence in the Technical Indicator dataset is rearranged. This modification leads to the 10-week timeframe becoming the most favorable, as evidenced by a cumulative reward of 121.59.\nThis shift indicates that the Convolutional Neural Network (CNN) becomes more adept at discerning the complex patterns between features and their temporal dynamics when the data is organized to maintain a cohesive structure for each company's features. The rearrangement enhances the model's ability to grasp longer-term trends and relationships, which may be less apparent or accessible in shorter timeframes or with non-rearranged data. This observation is crucial as it suggests that the efficacy of a CNN in financial market analysis can be significantly influenced by how the data is structured. It highlights the importance of considering the arrangement of data to optimize the predictive capabilities of models, especially in financial contexts"}]}