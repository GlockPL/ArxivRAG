{"title": "Log-normal Mutations and their Use in Detecting Surreptitious Fake Images", "authors": ["Ismail Labiad", "Thomas B\u00e4ck", "Pierre Fernandez", "Laurent Najman", "Tom Sanders", "Furong Ye", "Mariia Zameshina", "Olivier Teytaud"], "abstract": "In many cases, adversarial attacks are based on specialized algorithms specifically dedicated to attacking automatic image classifiers. These algorithms perform well, thanks to an excellent ad hoc distribution of initial attacks. However, these attacks are easily detected due to their specific initial distribution. We therefore consider other black-box attacks, inspired from generic black-box optimization tools, and in particular the log-normal algorithm.\nWe apply the log-normal method to the attack of fake detectors, and get successful attacks: importantly, these attacks are not detected by detectors specialized on classical adversarial attacks. Then, combining these attacks and deep detection, we create improved fake detectors.", "sections": [{"title": "1 Introduction and outline", "content": "Adversarial attacks (such as Square Attack, SA (Andriushchenko et al., 2020)) or no-box attacks such as purifiers (Saberi et al., 2024) can successfully imperceptibly modify fake images so that they are not recognized as fake by some fake detectors. Therefore, detecting these attacks is necessary for enhancing our fake detectors. In the present paper, we analyze lesser known attacks inspired by the black-box optimization community: their algorithms perform well, and are sufficiently different for being undetected by detectors trained on classical attacks only. Iterative optimization heuristics such as Evolutionary Algorithms (EAs) have shown their strengths in solving hard optimization problems over the past decades. While various methods have been developed for optimization problems in particular domains, for instance, Genetic Algorithms and Evolution Strategies (ES) have been favored for discrete and continuous optimization, respectively, the variants inheriting their techniques have been proposed and applied across different domains. Regarding the topic of borrowing ideas across different domains, there exists much work in exchanging ideas between discrete and continuous optimization domains. For example, variants of Covariance Matrix Adaptation ES (CMA-ES) and Differential Evolution (DE) have been proposed for specific problems (Hansen & Ostermeier, 2003; Hamano et al., 2022; Das et al., 2016). More recently, a study has investigated the ways of discretizing CMA-ES and its performance on different discrete BBOB problems (Thomaser et al., 2023). In this work, we investigate the advantage of borrowing an idea from a self-adaptive pseudo-Boolean optimization algorithm to the continuous domain. One of EAs' key algorithmic components is the utilization of a probability distribution for generating new search points, including an iterative adaptation of this distribution based on the objective function values of the newly generated solutions (Doerr et al., 2020; Doerr & Neumann, 2020). A wide range of such update strategies has been proposed over the past decades, for example, for multivariate Gaussian distributions in the context of covariance matrix adaptation in evolution strategies for continuous optimization problems (Hansen & Ostermeier, 2003) and for binomial and a variety of other mutation strength distributions in the context of mutation rates in evolutionary algorithms for pseudo-Boolean optimization (Doerr et al., 2020). Among those adaptation methods for the mutation strength in pseudo-Boolean optimization, the so-called log-normal mutation was developed almost thirty years ago as a method for allowing the mutation strength to quickly shift from exploration to exploitation (B\u00e4ck & Sch\u00fctz, 1995; B\u00e4ck & Sch\u00fctz, 1996; Kruisselbrink et al., 2011). As shown in (Doerr et al., 2020), on a set of 23 pseudo-Boolean test functions, log-normal mutation shows an empirical cumulative distribution functions (ECDF) performance across all 23 functions"}, {"title": "2 State of the art", "content": "In this section, we briefly discuss the state-of-the-art in fake detection methods, to set the stage for using those as a specific application domain for black-box-optimization (section 2.1). Then, we introduce the general setup of the black-box optimization problem, and the set of algorithms that are used in the empirical comparison presented in this paper."}, {"title": "2.1 Fake detectors", "content": "Due to the many AI-generated images on internet, it becomes important to be able to detect them. DIRE (Wang et al., 2023) is a method to detect images generated by Latent Diffusion Models (LDM) (Rombach et al., 2022). It focuses on the error between an input image and its reconstruction counterpart using a pre-trained diffusion model. This method is based on the observation that"}, {"title": "2.2 Black-box optimization", "content": "An unconstrained optimization problem can be generally formulated as follows, min $f(x)$, x \u2208 \u03a9. where \u03a9 denotes the search space, f: \u03a9 \u2192 Rm, and m is the number of objectives. Note that we consider m = 1 in this work, and without loss of generality, we assume a minimization problem. According to the domain of 2, we can consider problems as continuous optimization when \u03a9CR"}, {"content": ", as discrete optimization when \u03a9 C Z"}, {"content": ", and pseudo-Boolean optimization (PBO) when \u03a9 = {0,1}n, where n is the dimensionality of the problem. We deal with black-box optimization (BBO), in which algorithms can not obtain the exact definition of the objective function f and constraint definitions regarding the structure of f. Evolutionary computation has been widely applied to solve BBO. For example, Evolution Strategies (ES), Differential Evolution (DE), etc., have achieved success in solving continuous BBO problems (B\u00e4ck et al., 2023). The variants of these methods have also been applied for discrete BBO based on relaxation to a continuous problem (Pan et al., 2008; Hamano et al., 2022). Moreover, EAs have been well-studied for pseudo-Boolean optimization (PBO) (Doerr et al., 2020). Some strategies have been commonly applied with specific adjustments when solving different types of optimization problems. A recent study has investigated the performance of a discretized Covariance Matrix Adaptation Evolution Strategy (CMA-ES), addressing the adaptation of continuous optimization algorithms for the discrete domain (Thomaser et al., 2023).\nIn this work, we work on continuous optimization by utilizing discrete optimization algorithms. Specifically, we investigate utilizing the techniques of the (1 + X) EAs that are designed for PBO for continuous optimization (Doerr et al., 2020). The (1 + \u03bb) EAs flip a number l of variables to generate A new solutions from a single parent solution iteratively, and self-adaptive methods have been proposed to adjust the value of l online, essentially detecting the optimal number of variables to be altered dynamically. We consider various black-box optimization methods, which can all be found in (Rapin & Teytaud, 2018). We include many algorithms, specified in Section D.1. We selected, for readability, a sample of methods covering important baselines (such as random search), one representative method per group of related methods, and the over-all best methods. We refer to (Rapin & Teytaud, 2018) for the details about other algorithms."}, {"title": "3 Methodology", "content": null}, {"title": "3.1 Log-normal mutations", "content": "We introduce in this section the general framework of the (1 + X) EA with log-normal mutation, which was proposed for the pseudo-Boolean optimization task, and illustrate a straightforward generalization of this algorithm to continuous and integer domains.\nThe log-normal mutation was first described in (B\u00e4ck & Sch\u00fctz, 1995; B\u00e4ck"}, {"title": "3.2 Modifications of the original log-normal algorithm", "content": "Note that in Algorithm 1 we do not specify the domain \u03a9 of x. The log-normal mutation has been commonly applied for the pseudo-Boolean optimization, i.e., \u03a9 = {0,1}\", and the MUTATE-operator flips l(i) bits that are selected uniformly at random. In this work, we introduce a generalization of the MUTATE-operator, as presented in Algorithm 2, to extend the log-normal mutation to other domains. This generalized MUTATE is applicable for arbitrary search domains \u03a9 = \u03a7 1 \u03a7\u03b9, where Xi \u2208 {{0,1},Z,R,N}. It samples a new value that is distinct from the current one at random from the respective domain for each of l variables, which are selected (uniformly at random) for mutation. This technique has also been adopted by Nevergrad (Rapin & Teytaud, 2018), which automatically adapts algorithms designed for continuous domains to also work for discrete domains and vice versa.\""}, {"title": "4 Experimental results on the Nevergrad Black- box optimization benchmarks", "content": null}, {"title": "4.1 Parameter settings & Ablation", "content": "While the log-normal mutation can control mutation rates of the (1 + \u03bb) \u0395\u0391 online, Algorithm 1 still comprises three hyperparameters, i.e., the initial value of p, population size \u03bb, and y, that can affect the algorithm's performance. We set y = 0.22 following the suggestion in previous studies (Kruisselbrink et al., 2011; Doerr et al., 2020). For the other two hyperparameters, we test two values 0.2 and 0.8 for p and various population sizes \u03bb. The detailed combinations are presented in Table 1."}, {"title": "4.2 Robust performance of log-normal", "content": "The log-normal algorithm has already shown competitive results in existing benchmark studies (Doerr et al., 2019b), and in the present paper we examine its performance by comparing it on extensive benchmarks provided by Never-grad. Table 10 shows the diversity of the benchmarks in Nevergrad, where each benchmark is accompanied with a list of baselines.\nSince NGOpt is a \u201cwizard\u201d provided by Nevergrad that is tuned for selecting automatically a proper algorithm for each problem, we use it as a baseline for comparison. We run log-normal and NGOpt and proposed default methods.\nTables 2 and 11 list the rank of the log-normal algorithm and of NGOpt: Table 2 lists the problems in which the benchmark outperforms NGOpt, and Table 11 presents the results of the other benchmarks.\nWe observe that the log-normal algorithm can outperform NGOpt on 17 out of 41 benchmarks and perform better than 50% of all algorithms on 29 benchmarks. Recall that Nevergrad contains a diverse set of benchmarks, and it is well-known that we can not expect one algorithm to perform the best for all problems. The lognormal algorithm shows robust and competitive performance for Nevergrad benchmarks.\nSince the log-normal algorithm was originally proposed for discrete opti-mization, we first present the detailed results of log-normal variants for the two discrete benchmarks in Fig. 1. In Fig. 1, the y-axis represents the loss of al-gorithms for tested budgets (presented on the x-axis), and algorithm labels are annotated by their average loss for all the maximum budget between parenthe-ses and (for checking stability) the average loss for the tested budgets excluding the largest one between brackets (if there are at least three budget values). For readability, we present only the 35 best results (and the worst, for scale) for each benchmark. We can observe that the log-normal variants obtain the best performance for the two discrete benchmarks."}, {"title": "4.3 Competitive results for deceptive problems", "content": "Recall that in the ranks in Table 2, the log-normal algorithm performs best for the \"deceptive\u201d and \u201cfishing\u201d benchmarks and outperforms NGOpt on many difficult multimodal benchmarks (marked with **). We plot in Fig. 2 the de-tailed results of the best of 61 algorithms on the deceptive benchmark. The deceptive benchmark combines many random translations of hard problems in many dimensionalities, including (i) a problem with a long path to the optimum, which becomes thinner and thinner close to the optimum, (ii) a problem with infinitely many local minima, (iii) a problem with condition number growing to infinity as we get closer to the optimum. We note that on this hard continuous benchmark, the log-normal algorithm performs well across all the tested bud-gets. Therefore, due to its robust performance across a number of benchmarks and particularly competitive performance for the hardest benchmarks, we utilize the log-normal mutation for the following fake detector scenarios."}, {"title": "5 Stress test for fake detectors", "content": "We consider stress tests for fake detectors. More precisely, we add imperceptible noise e to the image x, with this noise chosen so that fake detectors fail: typically x is a fake image detected as fake by a detector D and we find a small e such that x + e is classified as non-fake by D. Black-box algorithms can be straight-forwardly applied to attacking a fake detector D (which returns the estimated probability D(x) that an image x is fake) by defining loss(e) = D(e + x) and minimizing loss on a domain D (typically [-0.03, 0.03]t, where t is the shape of the image tensor\u00b2) using a black-box algorithm. Our attacks (Section 5.1) consider the fake detector as a black-box, so we do not have gradients. Then"}, {"title": "5.1 Black-box attacking fake detectors", "content": "The fake detector we consider is the universal fake detector (Ojha et al., 2023). Precisely, we consider the datasets as described in Table 3. IN500- and IN500+ refer to real images, Fakel, Fake3, Fake2 and Latent Fake-200 refer to images created by image generators. In the present paper, Clean means unattacked, neither by no-box nor by black-box attacks."}, {"title": "5.2 From attack to defense: detecting attacks", "content": "A recent trend is the denoising of watermarked images for evading the detec-tion: whereas the watermark makes it possible to detect that an image is fake, the denoised version goes undetected. However, a defense is to detect such a denoising (e.g. by DiffPure or ImageRephrase), or other forms of attacks (such as SA). That way, our work both provides (i) new attacks and (ii) detectors for those attacks, to be used as an additional step (detection of evasion) in fake detectors."}, {"title": "5.2.1 No-box attacks (purifiers) and their detection", "content": "While watermarking techniques can be made robust against some image al-terations such as resizing or JPEG compression as shown by Fernandez et al. (2023), they remain vulnerable to no-box purification attacks (Saberi et al., 2023) that destroy the hidden message. Additionally, the distribution change introduced by no-box purification can impact negatively the performance of a fake detector, as shown in Table 5. We will next show that one can easily detect these attacks if we have access to the purification method.\nWe consider two purifiers used by Saberi et al. (2024): DiffPure based on guided diffusion and ImageRephrase based on latent diffusion. We consider the strength/steps parameter in the set {0.1, 0.2, 0.3}. These two purifiers lead to an average PSNR (Peak Signal-to-Noise Ratio) between 20 and 30, which is a noticeable yet acceptable quality loss. As expected, the PSNR of the distortion increases with the strength parameter.\nFor detecting the no-box attacks, we train a classifier, specified in table 13, on Dataset2-DP or Dataset2-IR. We experiement with both ResNet50 and SR-net (Boroumand et al., 2018) and the latter performs better overall. We use Dataset3 as a test set (so that the distributions of images differ) with images attacked by same purifier but with different parameters in {0.1, 0.2, 0.3}. The re-sults of the detection of latent purifiers and guided diffusion purifiers are shown in Table 6 and Table 7. We achieve less than 5% FPR and FNR across the hold-out training dataset and the critical part of testset, although the FPR is relatively higher for the full testset that can be explained by having a sort of transfer from detecting DP or IR to detecting images generated by G.\nIn short, training on a purifier with a specific parameter allows us to detect that same purifier with different parameters and for different image distribu-tions."}, {"title": "5.2.2 The detection of black-box attacks", "content": "For detecting square attacks, we train a deep net using a similar setup, as the SRnet model still performs better than ResNet in this scenario. We also employ data augmentation techniques: horizontal flip, random crop and color jitter which empirically makes the model more robust to different attack parameters, while allowing us to train using only one attack parameter budget=10k and l\u221e = 0.01. The training is done on Dataset2-SA. For testing, we use Dataset3-SA using different parameters than those used during training. We then test the transfer of the SA detector on Dataset4, corresponding to Log-normal attacks.\nTable 8 summarizes the results of the SA detector, for detecting SA and as a detector of log-normal attacks. We observe that the transfer to detecting log-normal attacks is very poor. So, we need to include such attacks in our training for improving the defense.\nA new detector for log-normal attacks. We have seen that detectors of SA do not detect our log-normal attacks. For detecting log-normal attacks, we use the same setup as in section 5.2.2 for creating a new detector. Dataset2-LN is used during training with the attacked images now obtained with GSM-SuperSmoothLognormalDiscreteOnePlusOne budget=10k and l\u221e = 0.01 and again, the dataset is split to 80% train, 10% test, 10% validation. For testing, we use Dataset3 with the images attacked using different variations of log-normal and parameters (Budget and l\u221e). Table 9 presents the results of the log-normal detector: we observe that the learning was made on images attacked by algol only and we get positive results for all log-normal variants."}, {"title": "6 Conclusions", "content": "We tested log-normal mutations on various benchmarks and extended it to con-tinuous benchmarks, including fake detection tasks.Lognormal mutations per-form well in some cases in the Nevergrad benchmark, especially on: (i) P\u0412\u041e, \u0430 classical discrete benchmark, and some other discrete benchmarks. (2) In some continuous context, in particular in the most difficult scenarios such as many-objective, highly multimodal, low budget benchmarks, including e.g. real world benchmarks in photonics. We note that other discrete algorithms adapted to the continuous case do perform well.\nWe note that discrete optimization methods are relevant in continuous opti-mization, when the prior (i.e. the range of reasonable values for each variable) is important and excellent precision is impossible (Sections 4.2 and 4.3). Of course this can not compete with classical local optimization in terms of convergence rates for large budgets, but we show that it can be great for a low ratio bud-get/dimension.Fake detection presents a complex challenge, with the difficulty of identification varying based on factors such as the type of data and the model used (Epstein et al., 2023; Sha et al., 2023). We consider the setting in (Wang et al., 2023). We observe that log-normal mutations in continuous settings, as well as other generic black-box optimization algorithms, are credible attack mechanisms, so that detecting attacks is necessary for a good defense. We ob-serve a very poor transfer between the detectors of different types of attacks and in particular from the detection of classical attacks (such as SquareAttack) to our modified attacks (such as log-normal), so that a good defense mechanism (aimed at improving the detection of manipulated images) must include the learning of diverse attack mechanisms.\nOur most immediate further work is the combination of our fake detectors (no-box, SA, lognormal, and existing detectors such as (Ojha et al., 2023) and (Fernandez et al., 2023), into a single detector. We also add new attacks and defenses based on generic black-box optimization, and a third work is the in-vestigation of log-normal mutations (and other discrete algorithms) for other continuous problems."}, {"title": "A Broader Impact Statement", "content": "Detecting fake images is essential for preserving the quality of internet. Our detectors do not provide certainties, only indications."}]}