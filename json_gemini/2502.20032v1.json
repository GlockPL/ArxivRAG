[{"title": "Order-Robust Class Incremental Learning: Graph-Driven Dynamic Similarity Grouping", "authors": ["Guannan Lai", "Yujie Li", "Xiangkun Wang", "Junbo Zhang", "Tianrui Li", "Xin Yang"], "abstract": "Class Incremental Learning (CIL) requires a model to continuously learn new classes without forgetting previously learned ones. While recent studies have significantly alleviated the problem of catastrophic forgetting (CF), more and more research reveals that the order in which classes appear have significant influences on CIL models. Specifically, prioritizing the learning of classes with lower similarity will enhance the model's generalization performance and its ability to mitigate forgetting. Hence, it is imperative to develop an order-robust class incremental learning model that maintains stable performance even when faced with varying levels of class similarity in different orders. In response, we first provide additional theoretical analysis, which reveals that when the similarity among a group of classes is lower, the model demonstrates increased robustness to the class order. Then, we introduce a novel Graph-Driven Dynamic Similarity Grouping (GDDSG) method, which leverages a graph coloring algorithm for class-based similarity grouping. The proposed approach trains independent CIL models for each group of classes, ultimately combining these models to facilitate joint prediction. Experimental results demonstrate that our method effectively addresses the issue of class order sensitivity while achieving optimal performance in both model accuracy and anti-forgetting capability.", "sections": [{"title": "1. Introduction", "content": "Class Incremental Learning (CIL) necessitates that the model dynamically acquires knowledge of new classes while preserving the knowledge of previously learned classes within an infinite sequence of tasks [12, 15, 41]. CIL is realistic but a great challenge for deep neural networks [32], where existing works devoted to overcoming catastrophic forgetting (CF) and encouraging knowledge transfer across different tasks [26, 46, 54, 57]. With the rapid advancement of CIL, a growing number of methods [19, 34, 55] have been introduced to address the problem of CF from the perspective of the order in which classes appear (or task order). In practice, the arrival order of each class and the tasks to which they belong are random and the order in which tasks arrive is uncontrollable [3], further resulting in Class order sensitivity and Intra-task class conflicts [23]. Therefore, designing an order-robust CIL method is essential for the community.\nClass order sensitivity refers to the model exhibiting significant performance variations depending on the sequence in which classes are introduced [34]. This phenomenon is prevalent in real-world applications (see Figure 1(a)). For instance, in online recommendation systems, the order in which user data classes are received at different time points is difficult to control. If the system initially receives data from relatively few classes, the introduction of subsequent classes may impair the system's adaptability, resulting in unstable model performance on new tasks. Furthermore, the model's parameters may be overfitted to the classes of early tasks, diminishing its ability to generalize to subsequent task with new classes. Although existing research, such as APD [55] and HALRP [19], have attempted to mitigate the class order sensitivity problem by modifying network structures, their effectiveness remains limited and has not fundamentally addressed this challenge. Thus, designing a model capable of maintaining stable performance across varying class orders remains a critical unsolved issue in CIL.\nIntra-task class conflicts refers to the discrepancies in model performance caused by similarity between classes that are trained simultaneously in a specific task (see Figure 1(b)). In real-world applications, where the arrival of classes in the data stream is uncontrollable, significant similarities among classes can severely impact the model's resilience. For example, in a specific task from a sequence of tasks, a model may be trained to recognize different breeds within the same species. Within this task, due to the high similarity of features across categories, the model needs to develop resilience in distinguishing between closely related classes. However, existing CIL methods struggle to address this challenge, primarily due to the inherent limitations of the task setting. As CIL incrementally processes different classes, it cannot globally account for all class information, causing class conflicts to accumulate during training and negatively impact model performance. Thus, alleviating class conflicts and improving the model's generalization ability remains a significant challenge in CIL.\nHence, to tackle the challenges of class order sensitivity and Intra-task class similarity sensitivity, we first conduct an in-depth analysis beyond existing theories. Our theoretical findings suggest that as class similarity decreases in CIL, the model's robustness to class order increases, which, in turn, mitigates knowledge conflicts both across different tasks and within individual tasks. Then, we propose a similarity graph-based dynamic grouping method, called Graph-Driven Dynamic Similarity Grouping (GDDSG), to maintain the centroids of existing classes and dynamically groups tasks based on class similarity, assigning classes with lower similarity to the same group. This approach innovatively organizes class groups in CIL by utilizing a graph-based technique to minimize inter-group similarity. It dynamically assigns classes based on adaptive similarity thresholds and optimal graph coloring, thereby enhancing model robustness and computational efficiency across tasks. In the incremental learning process, GDDSG continuously updates existing groups or creates new ones, training a separate model for each group. Consequently, during the prediction phase, decisions are made by aggregating the outputs of multiple models.\nHence, our contributions can be summarised as follows:\n\u2022 In this paper, we elaborate on existing theories and derive an important Corollary: when the similarity between classes is low, the model's sensitivity to class order is significantly reduced, leading to a decrease in class conflicts.\n\u2022 Then, we provide a detailed introduction to the proposed GDDSG method, including its foundational algorithms and basic processes.\n\u2022 Additionally, we conduct extensive comparative experiments to validate the effectiveness of GDDSG, highlighting its advantages and potential in incremental learning tasks."}, {"title": "2. Related Work", "content": "Class-Incremental Learning (CIL) necessitates a model that can continuously learn new classes while retaining knowledge of previously learned ones [5, 10, 59, 61], which can be roughly divided into several categories. Regularization-based methods incorporate explicit regularization terms into the loss function to balance the weights assigned to new and old tasks [2, 17, 21, 48]. Replay-based methods address the problem of catastrophic forgetting by replaying data from previous classes during the training of new ones. This can be achieved by either directly using complete data from old classes [6, 25, 33, 40] or by generating samples [35, 63], such as employing GANs to synthesize samples from previous classes [8, 24]. Dynamic network methods adapt to new classes by adjusting the network structure, such as adding neurons or layers, to maintain sensitivity to previously learned knowledge while acquiring new tasks. This approach allows the model's capacity to expand based on task requirements, improving its ability to manage knowledge accumulation in CIL [1, 30, 42, 44]. Recently, CIL methods based on pre-trained models (PTMs) [5, 7, 61] have demonstrated promising results. Prompt-based methods utilize prompt tuning [14] to facilitate lightweight updates to PTMs. By keeping the pre-trained weights frozen, these methods preserve the generalizability of PTMs, thereby mitigating the forgetting in CIL [20, 36, 36, 43, 49, 49, 50]. Model mixture-based methods mitigate forgetting by saving models during training and integrating them through model ensemble or model merge techniques [11, 45, 47, 58, 60, 62]. Prototype-based methods draw from the concept of representation learning [53], leveraging the robust representation capabilities of PTMs for classification with NCM classifiers [27, 31, 59].\nThe Order in CIL remains a significant and unresolved challenge [46]. APD [55] effectively addresses the problem of CF by decomposing model parameters into task-shared and sparse task-specific components, thereby enhancing the"}, {"title": "3. Problem Formulation and Theory Analysis", "content": "3.1. Problem Formulation\nDefinition 1. (Class Incremental Learning (CIL)) Given a sequence of tasks denoted as 1, ..., t, ..., each task i is associated with a training set (i.e., ground-truth data) \\(D^{i} = \\{X^{i}, Y^{i}\\}\\), where \\(X^{i}\\) represents the set of training samples and \\(Y^{i}\\) is the set of labels. For task i, the set of classes is denoted as \\(CLS^{i}\\) with the size of \\(|CLS^{i}|\\), representing the number of classes in task i. With new tasks incrementally appearing, the goal of CIL is to learn a unified model \\(\\Phi : D^{i} \\rightarrow \\mathbb{R}^{d}\\) mapping input data to an embedding space equipped with a classifier \\(f(\\cdot)\\) that can perform well on all the tasks it has been learned.\nNote that for any pair of tasks i and j with \\(1 \\leq i, j \\leq n\\) and \\(i \\neq j\\), the sets of classes \\(CLS^{i}\\) and \\(CLS^{j}\\) are disjoint and data from other tasks is unavailable at the current task, ensuring distinctiveness and non-overlapping nature between classes across each task.\n3.2. The Effect of Class Ordering in CIL\nIn [23], the authors theoretically derived the expected forgetting value and expected generalization error for CIL under a linear model, where \\(w_{t}\\) denotes the optimal parameters of the model for the t-th task:\nTheorem 1. When \\(p > n + 2\\), we must have:\n\\[\\begin{array}{l}\nE[F_{T}]=\\sum_{i=1}^{T-1} \\frac{1}{p}\\left[c_{i, T} \\sum_{j>i} C_{i, j}\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2}+\\sum_{j=1}^{T} c_{i, j}\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2}\\right] \\+\\frac{\\rho \\sigma^{2}}{p-n-1}\\left(\\frac{1}{r^{T}}-r^{2}\\right),\\\\\nE[G_{T}]=\\sum_{i=1}^{T}\\left\\|w_{i}^{*}\\right\\|^{2}+\\sum_{i=1}^{T}\\sum_{j>i}^{T} c_{i, j}\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2} \\quad+\\frac{\\rho \\sigma^{2}}{p-n-1}\\left(1-\\frac{1}{r^{T}}\\right).\\end{array}\\]\n\\[\\begin{equation}\n\\begin{array}{l}\nT-1\\\\\n\\sum_{j>i}\\left.c_{i, j}\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2}\\right] \\\\\nE[G_{T}]=\\sum_{i=1}^{T}\\left\\|w_{i}^{*}\\right\\|^{2}+\\sum_{i=1}^{T} \\sum_{j>i}^{T} c_{i, j}\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2} \\quad+\\frac{\\rho \\sigma^{2}}{p-n-1}\\left(1-\\frac{1}{r^{T}}\\right).\\end{array}\n\\end{equation}\\]\nwhere the overparameterization ratio \\(r = \\frac{p}{n}\\) in this context quantifies the degree of overparameterization in a model, where n represents the sample size, and p denotes the number of model parameters [13, 29]. The coefficients \\(c_{i, j}=\\frac{1}{(1-r)}\\left(r^{T-i}-r^{j-i}+\\frac{1}{r^{T-j}}\\right)\\), with \\(1 \\leq i<j \\leq T\\), correspond to the indices of tasks, and \\(\\sigma\\) denotes a coefficient representing the model's noise level.\nTheorem 1 made a significant contribution to the study of class order in CIL, particularly in the two key expressions: \\(\\sum_{j>i} c_{i, j}\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2}\\) in Equation 1 and \\(\\sum_{i=1}^{T} \\sum_{j>i}^{T} c_{i, j}\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2}\\) in Equation 2. These formulas highlight the crucial role that class order plays in CIL. Building on this theory, further in this work, we derive sufficient conditions to ensure order robustness.\nCorollary 1. A sufficient condition for the reduction of \\(Var(E[G_{T}])\\) and \\(Var(E[F_{T}])\\) is that the sum of the squared distances between the optimal parameters of tasks increases, i.e., \\(\\sum_{i, j=1}^{T}\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2}\\) becomes larger.\nCorollary 1 integrates the similarity between tasks with the model's robustness to class order. Through Equation 1 and Equation 2, we observe that both forgetting and generalization errors are influenced by the optimal model gap between any two tasks, represented by \\(\\left\\|w_{i}^{*}-w_{j}^{*}\\right\\|^{2}\\) for tasks i and j. This gap serves as a measure of task similarity: the smaller the gap, the greater the similarity. Corollary 1 demonstrates that a smaller similarity between tasks enhances the model's robustness in terms of generalization and resistance to forgetting across different class orders. This finding offers valuable insights for the design of new methods."}, {"title": "4. The Proposed Method: GDDSG", "content": "Overview. Figure 2 provides an overview of our proposed method. Using task t as an example, we begin by projecting all training samples into an embedding space utilizing a pre-trained backbone. In this space, we compute the centroids for each class. Next, we evaluate whether a new centroid \\(c_{t}\\) should be integrated into an existing class group \\(G_{j}\\). If \\(c_{t}\\) is dissimilar to all classes within \\(G_{j}\\), it is added to the group. If it is similar to any class in an existing group, it remains unassigned. For unassigned centroids, we construct new similarity graphs (SimGraphs) based on their pairwise similarities. We then apply graph coloring theory to these SimGraphs, forming new class groups by clustering dissimilar categories together. Finally, we update the NCM-based classifier with all class groups, facilitating efficient model updates with minimal computational overhead.\n4.1. Class Grouping Based on Similarity\nCorollary 1 provides guidance for constructing a sequence of dissimilar tasks. A key idea is to dynamically assign each new class to a group during CIL, ensuring that the similarity between the new class and other classes within the group is minimized. This approach helps maintain the robustness of each group's incremental learning process to the order of tasks. For each group, a separate adapter can be trained, and the results from different adapters can be merged during prediction to enhance the model's overall performance.\nIn a given CIL task sequence, we organize the classes into several groups. The group list is denoted as \\(G = [G_{1},..., G_{k}]\\), where each \\(G_{i}\\) represents a distinct group of classes. For a specified task t and each class \\(C \\in CLS_{t}\\), our objective is to assign class C to an optimal group \\(G^{*}\\), ensuring that the new class is dissimilar to all existing classes in that group.\nTo achieve this objective, we first define the similarity between classes. The similarity between any two classes, \\(CLS_{i}\\) and \\(CLS_{j}\\), is determined using an adaptive similarity threshold \\(\\eta_{i, j}\\). This threshold is computed based on the mean distance between the training samples of each class and their respective centroids in a learned embedding space, as shown below:\n\\[\\eta_{i, j}=\\max \\left[\\frac{\\sum_{k=1}^{X_{t}} I\\left(y_{k}=i\\right) d\\left(x_{k}, c_{i}\\right)}{\\sum_{k=1}^{X_{t}} I\\left(y_{k}=i\\right)}, \\frac{\\sum_{k=1}^{X_{t}} I\\left(y_{k}=j\\right) d\\left(x_{k}, c_{j}\\right)}{\\sum_{k=1}^{X_{t}} I\\left(y_{k}=j\\right)}\\right],\\]\n\\[\\begin{array}{l}\nI(\\cdot) \\text { is an indicator function, and } c_{i}=\\frac{1}{X_{t}} \\sum_{j=1}^{X_{t}} x_{j} \\text { represents the centroid of class } C_{i} .\\end{array}\\]\nBuilding upon this framework, we define the condition under which two classes, \\(CLS_{i}\\) and \\(CLS_{j}\\), are considered dissimilar. Specifically, they are deemed dissimilar if the following condition holds:\n\\[d\\left(C_{i}, C_{j}\\right)>\\eta_{i, j}.\\]\nThus, class C is assigned to group \\(G^{*}\\) only if it is dissimilar to all classes within \\(G^{*}\\), and \\(G^{*}\\) is the choice with the lowest average similarity:\n\\[G^{*}=\\arg \\min _{G} \\frac{1}{\\left|G^{*}\\right|} \\sum_{C^{\\prime} \\in G^{*}} d\\left(C, C^{\\prime}\\right).\\]\nThis approach is consistent with the principles outlined in Corollary 1 and ensures the robustness of the model across the entire task sequence.\n4.2. Graph-Driven Class Grouping\nGraph algorithms provide an efficient method for dynamically grouping classes while minimizing intra-group similarity. In a graph-theoretic framework, classes are represented as nodes, with edge weights quantifying the similarity between them. The flexibility and analytical power of graph structures allow for dynamic adjustment of class assignments in CIL, facilitating optimal grouping in polynomial time. This approach significantly enhances the model's robustness and adaptability in incremental learning tasks.\nTherefore, we can leverage the similarity between classes to construct a SimGraph, defined as follows:\nDefinition 2. (SimGraph.) A SimGraph can be defined as an undirect graph \\(SimG = (V, E)\\), where V is the set of nodes that represent each class's centroid and E is the set of edges connecting pair of nodes that represent classes that are determined as similar by Equation 4.\nThen, we aim to partition the vertex set of this graph into subsets, with each subset forming a maximal subgraph with no edges between vertices. This problem can be abstracted as the classic NP-hard combinatorial optimization problem of finding a minimum coloring of the graphs. Let \\(G^{-1}(\\cdot)\\) be an assignment of class group identities to each vertex of a graph such that no edge connects two identically labeled vertices (i.e. \\(G^{-1}(i) \\neq G^{-1}(j)\\) for all \\((i, j) \\in E)\\). We can formulate the minimum coloring for graph SimG as follows:\n\\[\\chi(S i m G)=\\min \\left\\{G^{-1}(k) \\mid k \\in V\\right\\},\\\\]\nwhere \\(\\chi(SimG)\\) is called the chromatic number of SimG and \\(|\\cdot|\\) denotes the size of the set.\nBrooks' theorem [4] offers an upper bound for the graph coloring problem. To apply this in our context, we must demonstrate that the similarity graphs constructed in CIL meet the conditions required by Brooks' theorem. By doing so, we can establish that the problem is solvable and that the solution converges, ensuring the effectiveness of our grouping and class coloring process in class incremental learning. Without loss of generality, we can make the following assumptions:\nAssumption 1. In the CIL task, class \\(C_{i}\\) is randomly sampled without replacement from the set \\(U=\\bigcup_{i=1}^{100} C_{i}\\), ensuring that \\(C_{i} \\neq C_{j}\\) for all \\(i \\neq j\\). The probability that any two classes \\(C_{i}\\) and \\(C_{j}\\) within the set U meet the similarity condition (as described in Equation 4) is denoted by p.\nIn the CIL scenario with N classes, the probability of forming an odd cycle is given by \\((p^{2}(1-p)^{(N-2)}) = p^{2N}(1-p)^{N^{2}-2N}\\). Similarly, the probability of forming a complete graph is \\(p^{\\binom{N}{2}} = p^{N(N-1)}\\). Thus, the probability that the CIL scenario satisfies Brooks' theorem can be expressed as:\n\\[P_{\\text {Satisfy Brooks }}=1-p^{2 N}(1-p)^{N^{2}-2 N}-p^{\\binom{N}{2}} .\\]\nOur findings indicate that when \\(N>35\\), the CIL scenario adheres to Brooks' theorem. Furthermore, even with fewer classes, as long as p does not exceed 0.9, the CIL scenario can still ensure that the similarity graph complies with Brooks' theorem at a confidence level of 0.99. We conclude that class grouping based on the similarity graph is convergent and can be solved efficiently in polynomial time.\nFor Equation 6, while no algorithm exists that can compute \\(\\chi(SimG)\\) in polynomial time for all cases, efficient algorithms have been developed that can handle most problems involving small to medium-sized graphs, particularly the similarity graph \\(SimG\\) discussed here. In practical scenarios, such graphs are typically sparse. Notably, in conjunction with the above analysis, the similarity graph \\(SimG\\) in the CIL scenario satisfies the non-odd cycle assumption in Brooks' theorem [4]. For non-complete similarity graphs \\(SimG\\), we have \\(\\chi(SimG) \\leq \\Delta(SimG)\\), where \\(\\Delta(SimG)\\) represents the maximum vertex degree in \\(SimG\\).\nTherefore, we can apply a simple yet effective greedy method, the Welsh-Powell graph coloring algorithm [51]. This algorithm first sorts all nodes in the graph in descending order based on their degree and then assigns a color to each node, prioritizing those with higher degrees. During the coloring process, the algorithm selects the minimum available color for each node that differs from its neighbors, creating new color classes when necessary. The time complexity of this algorithm is \\(O(|V|^{2})\\), primarily due to the color conflict check between each node and its neighbors. In theory, the maximum number of groupings produced by this algorithm is \\(\\max \\left\\{\\min _{i=1}^{n}\\left{\\operatorname{deg}\\left(v_{i}\\right)+1, i\\right\\}\\right\\}\\), with an error margin of no more than 1, where V' is the sequence of nodes sorted by degree, derived from V.\n4.3. Overall Training Process\nIn the previous section, we introduced the motivation and core concepts behind the proposed algorithm. In this section, we will describe the entire training process in detail. Recent years have seen CIL methods based on pre-trained models achieve remarkable results [27, 31, 59, 59], largely due to their robust representation capabilities. Since our proposed class grouping method also relies heavily on the model's representation ability, we utilize a widely-adopted pre-trained model as a feature extractor. For each class group, we train independent classification heads, which enhances the model's adaptability and generalization to different class groups.\nAs outlined above, we utilize a frozen random projection matrix \\(W \\in \\mathbb{R}^{L \\times M}\\) to enhance features across all class groups, where L is the output dimension of the pre-trained model and \\(M \\gg L\\) is the expanded dimensionality. Given a task t and a sample x belonging to a class group s, the feature vector of the sample is denoted as h(x), and its"}, {"title": "5. Experiment", "content": "5.1. Experimental Setup\nDatasets. Since most pre-trained models are currently trained on ImageNet-21K [9], we aim to assess the model's performance on entirely new data. To demonstrate the robustness of our model to task similarity, we conduct experiments using several datasets, including CIFAR100 [18], CUB200 [39], Stanford Dogs [16], and OmniBenchmark (OB) [56]. These datasets are divided into multiple, equally sized tasks, and various class orders are tested to evaluate the model's performance across different orders.\nBaseline. For fairness, we only compare against CL methods that have utilized pre-trained models in recent years. We compare GDDSG with the following six latest and effective CL methods with the PILOT toolbox [37]: L2P [50], Dualprompt [49], CODA-Prompt [36], SimpleCIL [59], ADAM [60], EASE [62], RanPAC [27].\nImplementations. Our code, implemented in PyTorch, has been open-sourced for accessibility. All experiments were conducted on a single Nvidia RTX 3090 GPU, using two random seeds, 2024 and 4202, to compute the average for a more robust model evaluation. We use a ViT-B/16 model, which is self-supervised and pre-trained on ImageNet-21K. Detailed dataset descriptions and experimental implementations are provided in the Supplementary Material.\nMetrics. We employ average final accuracy \\(A_{N}\\) and average forgetting rate \\(F_{N}\\) as metrics [50]. \\(A_{N}\\) is the average final accuracy concerning all past classes over N tasks. \\(F_{N}\\) measures the performance drop across N tasks, offering valuable information about plasticity and stability during CL. Following the protocol in [22], we use the Order-normalized Performance Disparity (OPD) metric to assess the robustness of the class order. OPD is calculated as the performance difference of task t across R random class orders, defined as:\n\\[O P D_{t}=\\max \\left\\{\\bar{A}_{t}^{1}, \\ldots, \\bar{A}_{t}^{R}\\right\\}-\\min \\left\\{\\bar{A}_{t}^{1}, \\ldots, \\bar{A}_{t}^{R}\\right\\}.\\]\nThe Maximum OPD (MOPD) and Average OPD (AOPD) are further defined as:\n\\[M O P D=\\max \\left\\{O P D_{1}, \\ldots, O P D_{T}\\right\\},\\\\]\n\\[A O P D=\\frac{1}{T} \\sum_{t=1}^{T} O P D_{t}.\\]\n5.2. Experimental Results\nMain Results. highlights the strong performance of our proposed GDDSG method in terms of accuracy and resistance to forgetting. The results demonstrate that GDDSG consistently outperforms other techniques, achieving state-of-the-art (SOTA) performance. Notably, GDDSG shows marked improvements in both accuracy and forgetting rate. Compared to the previous SOTA method, RanPAC, our approach achieves significantly higher accuracy while maintaining a low forgetting rate of around 1%, underscoring GDDSG's superior effectiveness in the CIL environment.\nAblation analysis. Our method's two components, SimGraphs and Class Groups, operate as a unified whole. Only after generating the SimGraphs can construct the Class Groups. Therefore, we can only conduct ablation experiments on either individual Class Groups or the SimGraphs"}, {"title": "6. Conclusion & Limitation", "content": "In this study, we aim to design an order-robust CIL model capable of addressing two critical challenges: class order sensitivity and intra-task conflicts. Building on existing theories, we find that as class similarity decreases, the model's sensitivity to class order also lessens, which effectively mitigates knowledge conflicts both across tasks and within individual tasks. To enhance the model's robustness across varying class orders, we propose a dynamic grouping method based on similarity graphs, termed GDDSG. The proposed approach maintains the centroids of learned classes and group classes based on dynamic similarity. In GDDSG, we introduce a novel approach to structuring class groups within class-incremental learning. Our GDDSG can continually update existing groups or form new ones, training distinct models for each group. During inference, predictions are derived through an ensemble of outputs from multiple models, thereby enhancing overall accuracy and robustness in CIL.\nInevitably, our method has certain limitations. First, GDDSG currently relies on NCM classifiers. In future work, we aim to explore order-robust CIL approaches with Softmax strategies. Also, while the memory overhead remains small, it could be further streamlined for efficiency, and we intend to address this limitation with future studies."}, {"title": "Appendix", "content": "A. Notation\nIn Table A.1", "50": ".", "as": "n\\[A_{N"}, "frac{\\sum_{t=1}^{T}\\left(\\sum_{i \\in \\operatorname{CLS}^{t}} \\operatorname{Acc}_{i}^{t}\\right)}{\\sum_{t=1}^{T}\\left|\\operatorname{CLS}^{t}\\right|},\\\\\nF_{N}=\\frac{\\sum_{t=1}^{T} \\sum_{i \\in \\operatorname{CLS}^{t}}\\left(\\operatorname{Acc}_{i}^{\\text {to }}-\\operatorname{Acc}_{i}^{t}\\right)}{\\sum_{t=1}^{T}\\left|\\operatorname{CLS}^{t}\\right|}.\\"], "as": "n\\[O P D_{t"}, {"as": "n\\[M O P D=\\max \\left\\{O P D_{1"}, {"baselines": "n\u2022 Finetune adjusts classifier weights through cross-entropy loss.\n\u2022 L2P selects prompts from the prompt pool using the key query matching strategy.\n\u2022 DualPrompt attach prompts to different layers to decompose prompts into universal and expert prompts.\n\u2022 CODA-Prompt builds attention-based prompts from the prompt pool.\n\u2022 SimpleCIL replace updated model classifier weights with class prototypes.\n\u2022 ADAM fine-tuning based on SimpleCIL.\n\u2022 RanPAC projects the feature space onto a higher dimensional space to approach a Gaussian distribution and eliminates mutual information between classes through the Gram matrix.\nC. Proof of Theorem\nC.1. Proof of Brooks' Theorem\nProof:\nLet \\(|V(G)| = n\\)", "H": "G - v\\). By the inductive hypothesis", "Delta": "Delta(G)\\)", "colors": "c_{1}, c_{2}, \\ldots, c_{\\Delta}\\). The \\(\\Delta\\) neighbors of v are denoted as \\(v_{1}, v_{2}, \\ldots, v_{\\Delta}\\). Without loss of generality, assume that these neighboring colors of v are pairwise distinct; otherwise, the proposition holds.\nNext, let's consider all the vertices colored with either \\(c_{i}\\) or \\(c_{j}\\) in H, and all edges between them, forming a subgraph \\(H_{i,j}\\). Without loss of generality, assume that any two different vertices \\(v_{i}\\) and \\(v_{j}\\) are in the same connected component of \\(H_{i,j}\\). Otherwise, if they were in different connected components, we could exchange the colors of all vertices in one of the connected components, making \\(v_{i}\\) and \\(v_{j}\\) have the same color.\nWe denote the aforementioned connected components as \\(C_{i,j}\\), where \\(C_{i,j}\\) must necessarily be a path from \\(v_{i}\\) to \\(v_{j}\\). Since the degree of \\(v_{i}\\) in H is \\(\\Delta-1\\), the neighboring colors of \\(v_{i}\\) in H must all be pairwise distinct. Otherwise, we could assign \\(v_{i}\\) a different color, leading to a"}]