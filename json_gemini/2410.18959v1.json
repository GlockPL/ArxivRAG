{"title": "CONTEXT IS KEY: A BENCHMARK FOR FORECASTING WITH ESSENTIAL TEXTUAL INFORMATION", "authors": ["Andrew R. Williams", "Arjun Ashok", "\u00c9tienne Marcotte", "Valentina Zantedeschi", "Jithendaraa Subramanian", "Roland Riachi", "James Requeima", "Alexandre Lacoste", "Irina Rish", "Nicolas Chapados", "Alexandre Drouin"], "abstract": "Forecasting is a critical task in decision making across various domains. While numerical data provides a foundation, it often lacks crucial context necessary for accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge or constraints, which can be efficiently communicated through natural language. However, the ability of existing forecasting models to effectively integrate this textual information remains an open question. To address this, we introduce \"Context is Key\" (CiK), a time series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities. We evaluate a range of approaches, including statistical models, time series foundation models, and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. By presenting this benchmark, we aim to advance multimodal forecasting, promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://servicenow.github.io/context-is-key-forecasting/v0/.", "sections": [{"title": "1 INTRODUCTION", "content": "The estimation of future conditions is the foundation of decision making (Hyndman & Athanasopoulos, 2018) and intelligence (Wang, 2019). Articulated as time-series forecasting, this problem pervades many domains of science and commerce. Accurate forecasting relies on several crucial decisions up to the practitioner (Hyndman & Athanasopoulos, 2018), in particular on: 1. Model selection: Choosing the appropriate forecasting model for a given problem, and 2. Incorporating prior information: Determining what relevant information should be included in the model and how to effectively integrate it. This involves decisions about statistical priors, inductive biases in the model architecture, and other forms of domain knowledge integration. Traditionally, these decisions have heavily relied on expert knowledge and manual intervention. However, recent advancements in machine learning have shown particular promise in democratizing time-series forecasting by automating both model selection and the integration of prior information.\nIn the wake of the foundation model paradigm shift (Bommasani et al., 2021), several works (e.g., Liang et al. (2024); Chen et al. (2023); Lim & Zohren (2021)) have addressed automatic model selection by learning flexible, adaptable models that can be applied across various problem scenarios. Unfortunately, when compared to traditional statistical methods, current approaches provide debatable performance improvements while requiring significantly more resources (Garza & Mergenthaler-Canseco, 2024). Moreover, these models typically cast inputs and outputs as purely numerical time series, which leaves no room for the context that human experts typically rely on to focus their modelling efforts.\nAn alternative class of recent approaches (Jin et al., 2024; Liu et al., 2024b; Requeima et al., 2024) adapt large language models (LLMs) for forecasting and leverage natural language as an intuitive"}, {"title": "2 PROBLEM SETTING", "content": "Context-Aided Forecasting This work addresses the problem of context-aided forecasting, where the goal is to produce statistical forecasts by incorporating relevant side information (i.e., context). Let XH = [X1, ..., Xt] represent a series of random variables corresponding to historical observations, where each X \u2208 X \u2286 R, and let XF = [Xt+1,..., XT] represent future observations. In the classical statistical forecasting problem, the objective is to estimate the joint distribution of the future observations given the historical data:\nP(X_F | X_H).\nWe further assume access to context, denoted C \u2208 C, which is additional data of arbitrary nature (C) that contains information relevant for predicting XF and complementary to the history XH. The task then becomes estimating the distribution:\nP(X_F | X_H, C)."}, {"title": "3 CONTEXT IS KEY: A NATURAL LANGUAGE CONTEXT-AIDED FORECASTING BENCHMARK", "content": "We present the Context is Key (CiK) benchmark, a collection of probabilistic forecasting tasks that cannot be solved without integrating natural language contextual information with numerical data. CiK consists of 71 distinct tasks spanning seven application domains (Sec. 3.1) and that can be instantiated in different ways, e.g., by changing target time series or by selecting different time windows. These tasks encompass diverse types of contextual information (e.g., past events and known causal relationships; Sec. 3.2), and are designed such that various capabilities (e.g., causal reasoning; Sec. 3.3) are required to fully leverage the context and unlock accurate forecasts (see Fig. 2 for an overview). An example task is illustrated in Fig. 1 and others are given in Appendix B. The complete set of tasks can be explored at https://servicenow.github.io/context-is-key-forecasting/v0/and the source code is available at https://github.com/ServiceNow/context-is-key-forecasting.", "3.1 DOMAINS AND NUMERICAL DATA SOURCES": "The vast majority (95%) of tasks in CiK draw numerical data from 2,644 real-world time series acquired from public sources. These series cover a range of domains: Climatology (solar irradiance and cloud coverage (Sengupta et al., 2018)); Economics (unemployment rates across states and counties (U.S. Bureau of Labor Statistics, 2024)); Energy (electricity consumption and production (Godahewa et al., 2021)); Mechanics (experimental properties of physical systems (Gamella et al., 2024)); Public Safety (fire department intervention counts (Ville de Montr\u00e9al, 2020)); Transportation (highway segment occupancy rates and average speeds (Chen et al., 2001)); and Retail (cash withdrawals from various ATMs (Godahewa et al., 2021)). The remaining 5% of tasks use simulated data from dynamical systems crafted specifically for the tasks. Overall, the time series in CiK exhibit diverse sampling frequencies, with observations ranging from every 10 minutes to monthly intervals. Additional details on data sources can be found in Appendix A.1.\nMemorization mitigation: Using publicly available real-world data introduces the risk that pretrained LLMs and time-series foundation models may have memorized portions of the data,"}, {"title": "3.2 NATURAL LANGUAGE CONTEXT", "content": "For each task in the benchmark, we jointly sample numerical data from one of the series described in Sec. 3.1 and then carefully craft the natural language context necessary to unlock accurate forecasts. In some cases, this context is purely descriptive, providing information about the general nature of the target variable and its historical behavior, as seen in the task illustrated in Fig. 1. In other cases, the raw numerical data is adjusted to reflect the influence of the context. For example, in one task based on data from Godahewa et al. (2021), an ATM is expected to be inaccessible during a specific period, leading to zero withdrawals (visualized in Appendix B.3). In another task, electricity demand is projected to surge due to an incoming weather event (visualized in Appendix B.2). In such cases, we modify the series to incorporate these patterns and include such information into the corresponding context.\nOverall, we include diverse forms of natural language context, capturing various aspects of the process underlying the time series and revealing complementary knowledge that could be provided by a human expert or an external information source. The types of context are described below and exemplified in the task illustrated in Fig. 3. Several additional examples are given in Appendix B.\nIntemporal information (c\u2081) Information about the process that remains invariant in time. For example, a description of the process and the nature of the target variable, as in Fig. 3 (point 2), patterns that cannot be inferred from the available numerical data (e.g., long-period seasonalities), or constraints on values (e.g., positivity).\nHistorical information (CH) Information about the past behavior of the series that is not reflected in the available numerical history. For example, statistics on past values of the series, as in Fig. 3 (point \u2462), or an explanation for spurious patterns to be disregarded at inference (e.g., periodic anomalies due to sensor maintenance)."}, {"title": "3.3 MODEL CAPABILITIES", "content": "In addition to forecasting and natural language understanding, all tasks are designed such that fully utilizing the contextual information requires a range of capabilities, including instruction following, various forms of reasoning, and retrieval.\nFor example, to solve the task in Fig. 3, the model could retrieve from memory that Montreal experiences snowfall and cold weather during the winter months. It could then infer that trash fires are less likely to occur during this period through deductive reasoning. This chain of thought reveals a seasonal pattern that is not apparent in the short numerical history. Additionally, through causal reasoning, it is apparent that, despite a strong association between field fires and trash fires, the intervention described in \u2464 is unlikely to reduce the frequency of the latter. Failure to recognize this distinction would lead to inaccurate forecasts.\nA list of all capabilities with definitions is available in Appendix A.4 and the capabilities required to solve each task are documented at https://servicenow.github.io/context-is-key-forecasting/v0/. The distributions of tasks per capability and context type are shown in Fig. 2, while the distribution of lengths of the numerical historical data, prediction horizons and natural language context can be found in Appendix A.5. Multiple example tasks from CiK are provided in Appendix B, along with an explanation of their sources of natural language context and the capabilities required to solve them."}, {"title": "4 REGION OF INTEREST CONTINUOUS RANKED PROBABILITY SCORE", "content": "Alongside the tasks, we introduce the Region of Interest CRPS (RCRPS), a novel proper scoring rule designed specifically for context-aided probabilistic forecasting. This new scoring rule is an extension of the Continuous Ranked Probability Score (CRPS; Gneiting & Raftery (2007)), a proper scoring rule that provides a comprehensive assessment of forecast quality by evaluating the entire predictive distribution rather than focusing solely on summary statistics. Importantly, since it is based on the CRPS, the RCRPS can be calculated using only samples from the predictive distribution, and so can be used even in cases where closed-form distributions are unavailable. The RCRPS extends the CRPS via two key components: a region of interest and a measure of constraint satisfaction. This allows assessing both forecast accuracy and the integration of contextual information.\nRegion of interest (RoI): The score reweighs a strict subset of time steps, denoted by IC [t+1,...,T], whose values are heavily informed by the context. For example, in the ATM task described in Sec. 3.2 (visualized in Appendix B.3), this would correspond to the time intervals during which the ATM is expected to be unavailable. In other tasks, such as those in Figs. 1 and 3, where the context informs the value of all future time points, we set the Rol to an empty set, essentially weighting all time steps equally (for readability, we report the definition of RCRPS for this special case in Appendix E).\nConstraint satisfaction: The score penalizes violations of constraints, whether explicitly or implicitly included in the context, by measuring a task-specific function, denoted by vc, whose value is zero for any trajectory that satisfies the constraints and > 0 for any trajectory that violates them. Concrete examples are given in Appendix E.4. For tasks whose context does not imply constraints, we use vc() = 0."}, {"title": "RCRPS(X_F, x_F) := \u03b1", "content": "{ 1 \n2 |\\mathcal{I}| \\sum_{i \\in \\mathcal{I}} CRPS(X_i, x_i) + \\frac{1}{2 |\\mathcal{\\neg I}|} \\sum_{i \\in \\mathcal{\\neg I}} CRPS(X_i, x_i) + \\beta \\cdot CRPS(v_c(X_F), 0) },\nwhere the terms respectively account for CRPS inside the RoI, CRPS outside of the RoI, and constraint satisfaction. We note that the last term is inspired by the threshold-weighted CRPS of Gneiting &\nRanjan (2011) and that it vanishes when all constraints are satisfied. The \u03b1 term is a task-dependent\nscaling factor that is used to ensure that score values for tasks with numerical data of various scales\ncan be aggregated; its calculation is described in Appendix E.1. Finally, \u03b2 is a scaling factor that\ncontrols the impact of constraint violation on the score; we use \u03b2 = 10 in our experiments. For\nadditional details and discussion on the RCRPR properness, we refer the reader to Appendix E."}, {"title": "5 EXPERIMENTS AND RESULTS", "content": "In this section, we define our evaluation protocol (Sec. 5.1) and outline the baseline models evaluated on CiK (Sec. 5.2). We then present results on the benchmark (Sec. 5.3), along with an analysis of factors affecting model performance. Finally, we look at areas for improvement by analyzing forecasting errors (Sec. 5.4) and inference cost (Sec. 5.4)."}, {"title": "5.1 EVALUATION PROTOCOL", "content": "Each task in CiK has many unique specifications, i.e. instances arising from the various time series and windows in the associated numerical data, as well as minor variations in natural language context. In order to make the evaluation reproducible and affordable, we deterministically select 5 instances of each task for evaluation. For each instance, we generate 25 independent samples from each model for evaluation. Since many of the tasks in the benchmark share similarities due to having been created from the same data sources or using variants of the same context, we identify these clusters of similar tasks, and design a weighting scheme such that each cluster has equal total weight in our aggregate score (see Appendix A.2 for more details). Finally, to prevent the aggregate scores from being dominated by rare instances where some models give forecasts which are orders of magnitudes away from the ground truth, we introduce an upper bound of 5 to the RCPRS value for each instance, which intuitively represents the value a forecast would get if the distance between the forecast and the ground-truth was 5 times bigger than the range of the ground-truth of the instance."}, {"title": "5.2 BASELINES", "content": "We evaluate a wide variety of models ranging from methods based on language models to state-of- the-art numerical time series foundation models and classical statistical forecasting methods. Since CiK is meant to be an evaluation benchmark and hence does not have a corresponding training set, we only directly evaluate models that support zero-shot inference (such as LLMs and time series foundation models), and those which can be fit directly to the few historical data points of each task instance evaluated, such as traditional statistical models. We outline these methods below and refer the reader to Appendix D for additional details.\nLLM-based Forecasters: We consider two prompt-based approaches: LLM-processes (LLMP; Requeima et al. (2024)) and a simple approach which we propose, called \u201cDirect Prompt\", where we instruct the model to directly output a forecast as a structured output, rather than prompting it multiple times as in (Requeima et al., 2024) (described in detail in Appendix D.1). For each of these, we evaluate a variety of LLMs with diverse architectures and sizes, such as GPT-40 (Achiam et al., 2023), Mixtral-8x7B (Jiang et al., 2024)), Llama-3-8b (Dubey et al., 2024), and Llama-3.1-405b (Dubey et al., 2024). 2 Next, we evaluate multimodal forecasting models, UniTime (Liu et al., 2024b) and Time-LLM (ETTh1) Jin et al. (2024) each trained according to their respective authors' guidelines (detailed in Appendix D.3). For all of these approaches, inference is performed zero-shot on the benchmark and we compare their performance with and without the natural language context.\nQuantitative Forecasting Models: To contrast the performance of LLM-based forecasters, we also evaluate a number of models that are only capable of processing numerical data (no natural language). This includes exponential smoothing (Gardner Jr., 1985), ETS (Hyndman et al., 2008), and ARIMA (Box et al., 2015), three simple, but time-tested statistical approaches, as well as four\""}, {"title": "5.3 RESULTS ON THE BENCHMARK", "content": "Our main results are shown in Tab. 1. At a high level, we observe that the best-performing baselines combine pretrained LLMs with prompting strategies like Direct Prompt and LLMP, with a bias toward the largest models. In terms of RCRPS, Llama-3.1-405B-Inst (Direct Prompt) significantly outperforms all of its counterparts. As can be seen in Fig. 4, it achieves this only with context. GPT-40 (Direct Prompt) performs worse with respect to RCRPS, but compares favorably in terms of average rank, taking the best average rank by a small margin. This discrepancy is due to strong failures on some of the tasks, which we discuss in Sec. 5.4. Other models like Llama-3-70B (LLMP), Mixtral-8x7B-Inst (LLMP), Mixtral-8x7B (LLMP), and Llama-3-8B (LLMP) are on par with GPT-40 (Direct Prompt) in terms of RCRPS. Interestingly, all of these baselines outperform UniTime and Time-LLM, which also rely on LLMs (GPT-2 & LLaMA-7B). We discuss this gap in Appendix D.3. Finally, as emphasized in Fig. 5, we observe that the best-performing LLM baselines significantly outperform purely quantitative models. In what follows, we examine various aspects of these results."}, {"title": "Explaining the performance of LLM-based approaches", "content": "The stronger performance of LLM baselines could be due to two factors: (i) properly leveraging the natural language context and (ii) being more proficient at numerical forecasting. We thus attempt to disentangle their contributions. On the one hand, Fig. 4 shows clear evidence that most baselines make use of the context to improve their forecasts. For example, Llama- 3.1-405B-Inst (Direct Prompt) improves by 67.1% with context. This is reflected in the quality of the forecasts, where we observe clear improvements especially in regions of interest and improved satisfaction of con-"}, {"title": "Comparing the LLMP and Direct Prompting Strategies", "content": "Clear patterns emerge when comparing these strategies. First, as shown in Fig. 5 (right), LLMP baselines exhibit stronger numerical forecasting performance without context than Direct Prompt baselines. This advantage likely stems from LLMP's closer alignment with the forecasting task: LLMP simply prompts the LLM to autoregressively predict the next value in the time series \u2013 a task well suited for non-instruction tuned LLMs. This contrasts with Direct Prompting which requires output forecasts to be structured, complicating the overall task.\nThis line of reasoning leads us to our second observation; as reflected in Tab. 1 and Fig. 5, instruction tuning appears to degrade LLMP performance, with Llama-3 models showing a twofold decrease in performance after tuning\u2014a behavior previously observed by Gruver et al. (2024). Interestingly, instruction tuning does not degrade Mixtral-8x7B performance. Finally, while instruction tuning generally harms LLMP, it is essential for models used with the Direct Prompt strategy. Again, Direct Prompt requires forecasts to be produced in a specific structure, a skill that base models typically hone during post-training (see Appendix D.1.1 for details)."}, {"title": "No Baseline Excels Across All Capabilities", "content": "Based on the results in Tab. 1, it is evident that some models possess the necessary capabilities to effectively utilize the contextual information provided. However, we observe that no single model is the best across all capabilities. Llama-3.1-405B-Inst (Direct Prompt), our overall top-performing baseline, outperforms its counterparts in only 4 out of 7 capabilities. This finding indicates that the benchmark remains unsolved, leaving significant room for advancements from the research community."}, {"title": "5.4 ERROR ANALYSIS", "content": "We find that models occasionally return forecasts that miss the ground truth by a large margin. A significant failure denotes a forecast that over or undershoots by at least five times the range of the ground truth; at that point, we clip the RCRPS to 5 as explained in Sec. 5.1. Despite this cap, such unpredictable behaviour impacts the results of Tab. 1: GPT-40 with Direct Prompt, while emerging as a top-performer in most tasks (as reflected in its average rank), provides significantly higher aggregate RCRPS than models ranked worse, such as Mixtral-8x7B with LLMP. As an example, Direct Prompt with GPT-40 fails significantly in a task with a context involving scientific notation (see Fig. 16; more examples can be found in Appendix C.5). These findings underscore the need for future work to develop more robust models that can handle context effectively while avoiding significant failures."}, {"title": "5.5 INFERENCE COST", "content": "A key practical aspect for forecasting applications is the inference time of models and their associated cost. Fig. 6 (left) shows that, while Llama-3.1-405B-Instruct has the best RCRPS, it comes at the cost of a significantly higher parameter count than the quantitative forecasters. This emphasizes that, while LLMs can be powerful context-aware forecasters, they come with a steep computational cost, highlighting the need for efficient models that balance both accuracy and resource demands. Of note is also that many LLM baselines are Pareto dominated by quantitative forecasters such as Lag-Llama and Chronos. This suggests that the ability to ingest text is not enough and that a careful choice of LLM and prompting strategy is crucial for Pareto efficiency.\nFig. 6 (right) emphasizes the disparity in inference time between LLMs and quantitative models. LLMs take significantly longer to make predictions, with the most accurate LLMs having inference times that are orders of magnitude higher than their quantitative counterparts. Quantitative models, in contrast, maintain much lower inference times, making them far more efficient for practical use. The high computational demands of context-aware LLMs hinder their practical use in real-world forecasting, especially where speed and cost matter. The clear benefits of incorporating context warrants research into making them more efficient, aiming to match the cost-effectiveness of traditional models and enabling their deployment in large-scale forecasting."}, {"title": "6 RELATED WORK", "content": "We review two streams of related work: (i) work that introduce related benchmarks and datasets, and (ii) work that repurpose LLMs to obtain foundation models for context-aided forecasting."}, {"title": "7 DISCUSSION", "content": "In this work, we propose the Context is Key (CiK) benchmark: a collection of forecasting tasks that require combining historical data with critical natural language context. We evaluate a range of models on CiK, including our proposed LLM prompting method, Direct Prompt, which achieves the best performance. We analyse and discuss the failure modes of these models, and our findings underscore the critical role of contextual information in improving forecasts, while also revealing both the unexpected strengths and notable limitations of the investigated LLM-based forecasters.\nLimitations: While our benchmark provides valuable insights into the integration of contextual information in time series forecasting, it is important to acknowledge its limitations. Our study excludes modalities other than time series data and text, and excludes multivariate time series scenarios. Although we carefully and deliberately designed the tasks to assess how well time series forecasters can integrate contextual information, our focus was on relationships between context and forecasts that are discernible to humans. Hence, our benchmark does not explicitly evaluate a models' capacity to leverage latent relationships that might elude human observation. Moreover, while tasks are designed to require certain capabilities, we do not guarantee that alternative approaches to solving them do not exist. Our collection of capabilities and context types was not intended to be exhaustive but rather to serve as tools for analyzing forecasters' performance on the benchmark. While we have taken steps to mitigate memorization concerns, as discussed in Sec. 3.1, achieving absolute certainty in this regard is challenging without strictly held-out data.\nFuture work: There are several promising avenues for future work in the context-aided forecasting setting. Enhancements to the benchmark could include tasks that require multivariate forecasting or incorporate additional modalities, such as images, structured databases, or spatiotemporal data. Tasks that deliberately challenge context length limitations or probe specific weaknesses of language models would also be valuable additions. Furthermore, this benchmark strongly motivates research into developing more accurate and efficient multimodal forecasting models, which it is well-positioned to support. Lastly, as models become more robust, they could be integrated into agentic systems with conversational interfaces, allowing forecasts to be augmented with human expertise and automatically retrieved facts (e.g., via search engines). Such advancements would represent a significant step toward automating and democratizing access to powerful forecasting tools."}, {"title": "A.2 WEIGHTING SCHEME FOR TASKS", "content": "To take full advantage of the available data, we create multiple tasks using each data source, by varying the specific contextual information we provide to the models. Since we do not want our aggregate results to be dominated by the few datasets for which there are a larger number of tasks, we weight the contribution of each task to the various aggregated results.\nTo define the weight of each task, we first group the tasks in clusters. These clusters are primarily defined based on the original data source used to create the tasks. However, when tasks are fundamentally different, due to not testing the same capabilities, we put them in different clusters despite them using the same data source. For example, for tasks created using the Solar irradiance and cloud cover data, all of which ask models to forecast the irradiance, the tasks form three distinct clusters:\none for tasks asking models to do forecast with very short history (less than a day), one for tasks giving the cloud cover as covariate, and the final one for tasks where the models are given a tight upper bound on the possible irradiance. Once we define these clusters, we simply equal weight to each cluster, and equal weight to each task inside each cluster."}, {"title": "A.3 STANDARD ERRORS AND AVERAGE RANKS", "content": "To get the standard errors shown in Tab. 1, we first compute the standard error for tasks using the method described in Appendix E.5. We then aggregate them according to each task weight, by assuming that errors for each are independent and thus using the formula for the variance of a weighted sum of independent variables.\nTo take into consideration the uncertainty we have for the scores, we compute average ranks through a simple simulation. In this simulation, we replace the RCRPS for each task and model pair by an independent Gaussian variable of mean equals to the one we measured, and of standard deviation equals to the standard error. We then draw from this distribution and compute the weighted average ranks for each model. The results shown in Tab. 1 are the mean and standard deviation measured from 10,000 repetitions of this simulation."}, {"title": "A.4 MODEL CAPABILITIES", "content": "We provide a detailed explanation of each model capability here. Note that tasks in the CiK benchmark need not be mutually exclusive with the model capabilities they require; tasks are tagged with one or more model capabilities.\nInstruction following (24 Tasks): Using direct instructions available in the context. Instructions could express constraints to be satisfied, or the expected effect of an event, for example.\nRetrieval: Retrieving facts from memory or context."}, {"title": "A.5 TASK LENGTHS", "content": "Fig. 7 provides an overview of the distribution of the lengths of the natural language context, numerical history and target (prediction horizon) for a set of five instances for each task in the CiK benchmark."}, {"title": "B.1 TASK: CONSTRAINED PREDICTIONS", "content": "Domain: Traffic\nContext sources: Future information\nCapabilities: Instruction Following\nContext: \"Suppose that in the forecast, the values are bounded above by 11.88, the values are bounded below by 7.06.\"\nThis task, which we refer to as \"Bounded Prediction Constraint Based On Prediction Quantiles\", is a forecasting task where we modify the forecast horizon (in green in the plot) by bounding one or both of its extremes according to its unmodified ground truth's quantile values. We verbalize these bounds in the context, and the model is expected to interpret and respect them.\nSince we draw this series from the PeMS dataset (Chen et al., 2001), we tag its domain as \"Traffic\". The context directly refers to the future, hence the context source is tagged as \"Future information\". Finally, since the model is expected to obey the constraints in the context, we tag the evaluated capability as \"Instruction following\".\nSince the context contains constraints, the Region of Interest CRPS metric that we introduce (Sec. 4) heavily penalizes forecasts that exceed these constraints: models that do not incorporate the information about bounds in the context, such as quantitative forecasting models, would not be able to predict the ground truth (orange line) because its lower bound is much higher than that of the history. In this case, the region of interest for the metric is the entire forecast horizon because the context applies everywhere. Although statistical forecasters may pick up on the seasonality present in the history (black line), they would obtain worse scores than models capable of processing the context and adjusting the lower bound of their predictions."}, {"title": "B.2 TASK: ELECTRICAL CONSUMPTION INCREASE", "content": "Domain: Energy\nContext sources: Future information, Covariate information\nCapabilities: Instruction following, Retrieval from context\nContext: \"This is the electricity consumption recorded in Kilowatt (kW) in city A. A heatwave struck the city, which began on 2012-10-09 18:00:00 and lasted for approximately 3 hours, saw temperatures soar to unprecedented levels. According to the city's electricity provider, power consumption during the peak of the heatwave reached approximately 5 times the typical usage for this time of year.\"\nThe \"Short News Electricity Increase\" task introduces a large shock in the forecast horizon that is only referred to in the context. Hence, the model must interpret the context appropriately to forecast the spike.\nSince this series represents electricity consumption (Sec. 3.1), we tag it a coming from the \u201cEnergy\u201d domain. The context sources for this task are twofold: the first context source is \"Future information\", which represents knowledge of the five-fold increase in typical usage during the shock. The second source of context, \u201cCovariate information\u201d, represents the occurrence of a heatwave, which coincides with the timing and duration of the shock. The model must therefore interpret both the information on the magnitude of the shock from the future information, as well as the timing and duration of the sock from the covariate information. Together, these pieces of information enable an accurate forecast despite the lack of information about the shock in the task's numerical history.\nThe skills for this task are tagged as \"Instruction following\" and \"Retrieval from context\". While instruction following involves interpreting the context to include the shock in the prediction, the model must also retrieve from the context the relevant information, as there is unneeded information in the context as well: an accurate forecast does not require knowing that the temperature has reached unprecedented levels.\nIn this task, we also see a \"Region of Interest\" (RoI), characterized by a darker region of the forecast horizon. This RoI represents the region of the forecast horizon for which the context is relevant, i.e. the period during which the increased power consumption occurred. As detailed in Sec. 4, this region of interest is taking into account in the RCRPS metric."}, {"title": "B.3 TASK: ATM MAINTENANCE", "content": "Domain: Retail\nContext sources: Intemporal information, Covariate information\nCapabilities: Instruction following, Deductive reasoning\nContext: \"This is the number of cash withdrawals from an automated teller machine (ATM) in an arbitrary location in England. The ATM was under maintenance for 7 days, periodically every 14 days, starting from 1996-11-30 00:00:00. Assume that the ATM will not be in maintenance in the future.\"\nThe \"Automated Teller Machine (ATM) Under Period Maintenance\" task represents the history of withdrawals from an ATM that undergoes regular maintenance. This maintenance introduces a periodic, easily forecastable signal into the history. However, the context explicitly states that the forecast should assume the ATM will not be in maintenance during the forecast. Therefore, forecasting models are expected to ignore this signal.\nSince this series represents ATM withdrawals, we tag it as \u201cRetail\u201d. The context includes information such as the location of the ATM, and therefore provides \u201cIntemporal information\". As the maintenance frequency and duration is also described, the context sources include \"Covariate information\".\nThis task is tagged with two capabilities. \u201cInstruction following\u201d is necessary because the model must assume that the ATM will not be in maintenance in the future. However, the model must use \"Deductive reasoning\" to determine what and when the impact of the maintenance was \u2013 reducing the number of withdrawals to 0 every 14 days \u2013, and avoid including that pattern in the forecast. The Rol represents when the maintenance periods would have occurred in the forecast horizon, which is likely where forecasting models that do not leverage the context will forecast 0. While a quantitative forecasting model would find such a signal irresistible, context-aware models should avoid repeating the pattern in the forecast.\nWe also note that the series is not quite 0 during the maintenance periods. This is a consequence of using one of our memorization mitigation schemes (Appendix A.1, paragraph \"Memorization mitigation\")."}, {"title": "B.4 TASK: MONTREAL FIRE HIGH SEASON", "content": "Domain: Public Safety\nContext sources: Intemporal information", "information\nCapabilities": "Deductive reasoning", "memory\nContext": "The Montreal Fire Department is in charge of responding to various kind of public safety incidents. This is the number of field fire incidents responded to by Montreal firefighters in the borough of Rivi\u00e8re-des-Prairies-Pointe-aux-Trembles. In other years", "Montreal Field Fire With Explicit Short History": "ask requires predicting the number of field fire incidents during the summer", "Public Safety\" domain.\nThe context contains information from two different sources": "it contains \u201cIntemporal information\u201d", "Historical information\", which verbalizes statistics about past values of the series, beyond the numerical data. That is, the yearly average number of incidents, along with the knowledge that June is the month with the most incidents.\nThis task is tagged with many skills and involves several steps of interpretation to arrive at a reasonable forecast. We first note that the task requires \u201cRetrieval from memory\"": "an important piece of information for this prediction is that winters in Montreal, a city in the northern hemisphere, are long and harsh, with temperatures reaching -40\u00b0C. Secondly, the task requires the model to use \"Deductive reasoning\" to deduce that, since temperatures are so cold during the winter months, fields are likely covered in snow and are rather unlikely to catch fire. Finally, the model can employ \"Mathematical reasoning\u201d to determine how many field fires are likely to occur"}]}