{"title": "Personalized Federated Continual Learning\nvia Multi-granularity Prompt", "authors": ["Hao Yu", "Xin Yang*", "Xin Gao", "Yan Kang", "Hao Wang", "Junbo Zhang", "Tianrui Li"], "abstract": "Personalized Federated Continual Learning (PFCL) is a new prac-\ntical scenario that poses greater challenges in sharing and per-\nsonalizing knowledge. PFCL not only relies on knowledge fusion\nfor server aggregation at the global spatial-temporal perspective\nbut also needs model improvement for each client according to\nthe local requirements. Existing methods, whether in Personalized\nFederated Learning (PFL) or Federated Continual Learning (FCL),\nhave overlooked the multi-granularity representation of knowl-\nedge, which can be utilized to overcome Spatial-Temporal Cata-\nstrophic Forgetting (STCF) and adopt generalized knowledge to\nitself by coarse-to-fine human cognitive mechanisms. Moreover,\nit allows more effectively to personalized shared knowledge, thus\nserving its own purpose. To this end, we propose a novel concept\ncalled multi-granularity prompt, i.e., coarse-grained global prompt\nacquired through the common model learning process, and fine-\ngrained local prompt used to personalize the generalized represen-\ntation. The former focuses on efficiently transferring shared global\nknowledge without spatial forgetting, and the latter emphasizes\nspecific learning of personalized local knowledge to overcome tem-\nporal forgetting. In addition, we design a selective prompt fusion\nmechanism for aggregating knowledge of global prompts distilled\nfrom different clients. By the exclusive fusion of coarse-grained\nknowledge, we achieve the transmission and refinement of com-\nmon knowledge among clients, further enhancing the performance\nof personalization. Extensive experiments demonstrate the effec-\ntiveness of the proposed method in addressing STCF as well as\nimproving personalized performance.", "sections": [{"title": "1 INTRODUCTION", "content": "Federated Continual Learning (FCL) is a new practical paradigm\naiming at fusing knowledge from different times and spaces without\ncatastrophic forgetting in dynamic Federated Learning (FL) settings\n[47]. Moreover, Personalized Federated Learning (PFL) tries to fuse\nimplicit common knowledge extracted from various clients and\npersonalize the generalized knowledge for better performance on\nthe client side [37]. However, to better accommodate diverse local"}, {"title": "2 RELATED WORK", "content": "2.1 Multi-Granularity Computing\nMulti-granularity computing addresses the challenge of tackling\nthe coexistence of data with different granularities [45, 46]. Ex-\ntracting multi-granularity knowledge benefits our understanding\nof materials and their intrinsic properties.\nVL-PET [13] designs a multi-granularity controlled mechanism\nto impose control on modular modifications of the pre-trained\nlanguage model at coarse and fine granularities. [5] constructs a\nquestion-answering dataset with yearly, monthly, and daily-grained\ndata and proposes MultiQA to address temporally multi-granularity\nquestion-answering. [46] adopts the sequential three-way decision\nmethod to extract knowledge of different granularities in open-\ntopic classification tasks. [42] decouples the objects of group re-\nidentification tasks into individual, subgroup, and entire group\ngranularities to handle the dynamic changes in group layout and\nmember variations. [32] introduces granular computing in FL and\nachieves automatic neural architecture search to adapt the different"}, {"title": "2.2 Prompt-Based Continual Learning", "content": "Continual Learning (CL) aims to overcome catastrophic forget-\nting of the previous knowledge after training on new data in non-\nstationary task streams [6]. Various CL techniques [21, 29, 30]\nhave been proposed to alleviate catastrophic forgetting and achieve\nknowledge transfer across tasks, including regularization, rehearsal,\nparameter isolation, and knowledge distillation.\nRecent works introduce prompt learning to CL to achieve more\nefficient exemplar-free CL [34, 40, 41]. Prompt learning is a novel\ntransfer learning technique applied to adapt general knowledge of\npre-trained large language or vision models to downstream tasks by\noptimizing prompts [14, 15, 20, 49]. CoOp [49] integrates learnable\nprompts in the vision-language model to facilitate end-to-end learn-\ning where the design of task-specific prompts is fully automated.\nL2P [41] applies learnable task-specific prompts to mitigate forget-\nting and even outperforms exemplar-based methods in accuracy\nand efficiency. DualPrompt [40] decouples the learnable prompts\ninto general and expert prompts, encoding task-invariant and task-\nspecific knowledge, respectively. CODA [34] replaces key-value"}, {"title": "2.3 Personalized Federated Learning", "content": "Personalized Federated Learning (PFL) focuses on training cus-\ntomized models to accommodate various preferences and require-\nments of clients in heterogeneous FL. Existing works on PFL can\nbe categorized into data-based and model-based approaches [37].\nPer-FedAvg [9] designs a Model-Agnostic Meta-Learning (MAML)\nframework to find a generalized global model. It trains personalized\nlocal models derived from the shared global model. pFedMe [36]\nintegrates L2-norm regularization in the loss function to adaptively\ncontrol the balance between personalization and generalization\nin federated MAML. Ditto [22] adds a regularization term in the\nlocal objectives as the loss function of the local adaptation process\nbut aggregates the models before the local adaptation to strike a\nbalance of personalization and generalization. FedSteg [44] enables\ndomain adaptation from the shared global model to personalized\nlocal models by adding a correlation alignment layer before the\nsoftmax layer. FedPer [1, 33] decouples the model into base layers\nand personalized layers and aggregates the shallow base layers to\ncapture generic knowledge while retaining the deep personalized\nlayers locally to maintain personalized knowledge. FedMSplit [4]\nadopts multi-task learning to fit related but personalized models for\nclients. FedCE [2] clusters the clients into several groups based on\nthe similarity of local data distributions and trains multiple global\nmodels for each group. FedCP[48] proposes an auxiliary Condi-\ntional Policy Network to achieve more fine-grained personalization\nwith sample-wise feature separation. [38] conducts clustering by\nanalyzing the principal angles of local data in the subspaces and\ndelays the training stage until the clustering is accomplished. These\nworks do not explicitly explore the multi-granular knowledge in\nthe processes of generalization and personalization.\nSome recent works incorporated prompting learning methods\ninto PFL. pFedPG [43] utilizes personalized prompt generation\nglobally and personalized prompt adaptation locally to achieve PFL\nunder heterogeneous data. pFedPrompt [11] extracts user consensus\nfrom linguistic space and adapts to local characteristics in visual\nspace in a non-parametric manner.\nHowever, extracting and fusing spatial-temporal multi-granular\nknowledge via prompting to overcome catastrophic forgetting and\ndata heterogeneity has not yet been implemented in PFCL."}, {"title": "3 PROBLEM DEFINITION", "content": "3.1 Personalized Federated Continual Learning\nThe primary goal of PFCL is to accumulate and fuse knowledge\nfrom different times and spaces. Clients employ suitable personal-"}, {"title": "3.2 Spatial-Temporal Catastrophic Forgetting", "content": "Catastrophic Forgetting is a fundamental challenge in CL, which\nrefers to a phenomenon that a model would forget the knowledge\nlearned on old tasks when training on new tasks [6]. The reason for\ncatastrophic forgetting is that the well-learned network parameters\non the old tasks are overwritten during training on the new tasks\n[47].\nIn the FCL setting, catastrophic forgetting exists as well. In a\nreal-world scenario, data reaches clients consecutively through\ntask streams [24], causing temporal catastrophic forgetting. At the\naggregation stage, the central server collects local models and ag-\ngregates them into one global model. Then, the server distributes\nthe global model back to clients. Local models are trained with dif-\nferent training data. Aggregating them leads to the overwriting of\ncertain task-specific crucial parameters, consequently causing a de-\ncline in the performance of the global model on local-specific tasks.\nAdopting the global model consolidated such conflict knowledge\nexacerbates the temporal catastrophic forgetting of each client's\nprevious tasks.\nThe fundamental reason for STCF is that the knowledge rep-\nresented by the model's parameters is too fine-grained, leading\nto a lack of robustness against minor variations. Therefore, it is\nnecessary to represent knowledge in a multi-granularity way. Split-\nting it into coarse-grained spatial-temporal-invariant knowledge\nand fine-grained spatial-temporal-specific knowledge and handling\nthem separately can effectively overcome STCF.\nWe design Temporal Knowledge Retention to measure the\neffectiveness of temporal knowledge transfer and Spatial Knowl-\nedge Retention to measure the effectiveness of spatial knowledge\ntransfer in PFCL.\nDefinition 1. (Temporal Knowledge Retention) Given a fed-\nerated learning system with a clients, the temporal knowledge\nretention is defined as:\nKR_t = 1/a \u2211_{i=1}^{a} Acc(\u03b8_i^r, T_i^0) / Acc(\u03b8_i^0, T_i^0)  (1)\nwhere  Acc(\u03b8_i^r, T_i^0) denotes the test accuracy of client Ai's local\nmodel at r-th round on the 0-th task and  Acc(\u03b8_i^0, T_i^0)  denotes the\ntest accuracy of client Ai's local model at the initial round on the\n0-th task.\nDefinition 2. (Spatial Knowledge Retention) Given a federated\nlearning system with a clients, the spatial knowledge retention is\ndefined as:\nKR_S = 1/a \u2211_{i=1}^{a} Acc(\u0398_S^r, T_i^r) / Acc(\u03b8_i^r, T_i^r)  (2)\nwhere  Acc(\u0398_S^r, T_i^r)  denotes the accuracy of the global model \u0398_S^r on\nthe current local task T_i^r at client Ai and  Acc(\u03b8_i^r, T_i^r) denotes the\naccuracy of the local model \u03b8_i^r on its current local task T_i^r."}, {"title": "4 MULTI-GRANULARITY PROMPT", "content": "In this section, we elaborate on our proposed Federated Multi-\nGranularity Prompt (FedMGP), which introduces a multi-granularity\nknowledge space into PFCL for the first time to better address per-\nsonalized requirements and spatial-temporal forgetting.\nSpecifically, on the client, we design prompts at two granular-\nity levels for knowledge representation, namely Coarse-grained\nGlobal Prompt (see Sec. 4.1) and Fine-grained Local Prompt (see\nSec. 4.2). Global prompts represent coarse-grained common knowl-\nedge, while local prompts, built upon global prompts, represent\nclass-wise fine-grained knowledge. Only fusing the coarse-grained\ncommon knowledge facilitates the formation of generalized knowl-\nedge and avoids spatial forgetting caused by aggregating fine-\ngrained knowledge. Local prompts based on global prompts aim\nto personalize the generalized knowledge from the server while\npreventing temporal forgetting due to class increments.\nOn the server side, we devise a new approach for fusing global\nprompts called Selective Prompt Fusion (see Sec. 4.3) without spatial\nforgetting. Aggregating only coarse-grained knowledge not only en-\nhances aggregation speed but also provides further improvements\nin privacy protection.\nThe overall framework of the proposed method is shown in Fig. 2,\nand the algorithm is summarized in algorithm 1."}, {"title": "4.1 Coarse-grained Global Prompt", "content": "Due to the heterogeneity of data, significant differences exist among\nlocal models, leading to substantial variations in extracted knowl-\nedge. This also poses significant challenges for the fusion and trans-\nfer of knowledge, as the knowledge learned by each client is overly\nfine-grained. Inspired by the cognitive processes of humans, knowl-\nedge transfer among humans is effective because there is a fun-\ndamental shared cognition, enabling the meaningful exchange of\nknowledge. Therefore, we assign each client with the same pre-\ntrained ViT model as a foundational cognitive system. With ViT's\nparameters frozen, clients learn global prompts that operate at the\ninput level. Consequently, these global prompts represent coarse-\ngrained knowledge acquired through the common model learning\nprocess. Furthermore, as the knowledge is extracted from the same\nmodel, it is more convenient to aggregate knowledge on the server\nside without spatial forgetting.\nThe training of coarse-grained global prompts is based on the\nfrozen ViT model. Moreover, global prompts operate at the input\nlevel, not influencing the model's parameters. The purpose is to\nextract knowledge into a common space through the same model.\n4.1.1 Global Prompt Pool. Taking inspiration from L2P [41], we\ndevise a prompt pool for storing and selecting the global prompts.\nThe prompt pool is defined as:\nP_g = {P_1^g, P_2^g, ..., P_M^g},  (3)\nwhere m is the pool size and  P_i^g  is a single global prompt. Then,\nlet x and  E = f_e(x)  be the input and its corresponding embedding\nfeature, respectively. Denoting {s_i} be the indices of N global"}, {"title": "Algorithm 1: FedMGP Algorithm.", "content": "4.2 Fine-grained Local Prompts\nOnce the training of global prompts is completed, they will be frozen\nand remain unchanged, including both the prompts themselves and\ntheir corresponding keys, until the next task training. Based on the\nfrozen global prompts, we further developed fine-grained class-wise\nlocal prompts. These prompts directly impact the model's multi-\nhead self-attention (MSA) [39] layers, facilitating the extraction\nof local, fine-grained knowledge. Additionally, this fine-grained\nprompting helps overcome temporal forgetting induced by class\nincrements. The hierarchy of prompts, from coarse to fine, simplifies\ngeneralized knowledge extraction, fusion, and personalization.\n4.2.1 From Coarse to Fine. Similarly, a prompt pool is constructed\nfor local prompts. However, since it represents class-specific knowl-\nedge, the size of the pool depends on the number of data classes.\nThe local prompt pool is defined as:\nP_l = {(K_1^l, P_1^l), (K_2^l, P_2^l), ..., (K_C^l, P_C^l)},  (7)\nwhere C represents the number of classes. It is precisely the class-\nwise fine-grained knowledge that imparts significant effectiveness\nto our approach of personalization and addressing temporal forget-\nting induced by class increments. It is proved in Sec. 5.3.\n4.2.2 Local Query Function. Fine-grained prompts are selected\nbased on the global prompt, so we must first obtain frozen global\nprompts by allowing the original input x to undergo the global\nquery function. Subsequently, we concatenate to form an input E'\nwith selected global prompts. Then, similar to obtaining the key\nfor global prompts, we acquire the key for local prompts  K_in^l = V(E') , with the only difference being that the input is now E'.\nThe subsequent steps of calculating similarity and selection are\nanalogous to the corresponding operations for global prompts.\nNote that we do not employ this querying function during the\ntraining phase. Instead, we use mask code to select the local prompt\ncorresponding to the data class for training.\n4.2.3 Optimization for Local Prompt. Local prompts directly op-\nerate on the model's MSA layer, where we represent the input\nquery, key, and values as hq, hk, hv, respectively. MSA layers can\nbe denoted as:\nMSA(h_q, h_k, h_v) = Concat(h_1, \u2026, h_z)W^O,  (8)\nwhere h_i = Attention(h_qW_q, h_kW_k, h_vW_v). W is the project\nmatrix and z is the number of MSA layers. We use the Prefix\nTuning (Pre-T) to tune local prompts. Pre-T splits the local prompt\nP\u2081 into P_K and p_V, and adds them to hk andhv:\nMSA' = MSA(h_q, [p_V; h_k], [p_V; h_v]).  (9)\nOnce global prompts have completed training, they freeze along\nwith their corresponding keys. The input x first goes through the\nglobal query function to find the corresponding global prompts.\nSubsequently, the embedding of x is concatenated with the prompts\nto form E'. Then E' is processed by the local query function to\nfind the corresponding fine-grained prompts {K\u2081, P1}. Thus, ViT\nmodifies its MSA layer based on P\u2081 and loads the local classification\nhead H\u00ec, forming Vi\u00ec. The local prompt training loss function is\nmin_{H, P_l, K_l} L(V_i (E'), y) + \u03bb_2 \u2211_{K} dis(K_in^l, K_i).  (10)"}, {"title": "4.3 Selective Prompt Fusion", "content": "To fuse global prompts precisely, we devise a novel selective prompt\nfusion mechanism that aggregates prompts from different prompt\npools through knowledge distillation, enhancing their generaliza-\ntion. To our knowledge, it is a novel approach to distill prompts\nfrom different clients."}, {"title": "5 EXPERIMENTS", "content": "5.1 Experimental Setup\n5.1.1 Datasets. We conduct extensive experiments on CIFAR-100\n[19] with 5 incremental tasks to evaluate the effectiveness of our\nFedMGP in addressing the challenges of PFCL. CIFAR-100 is a\nwidely used benchmark dataset and consists of 60,000 RGB color\nimages, each of size 32x32 pixels, classified into 100 different classes.\nWe consider two practical scenarios of FCL, namely synchronous\nFCL and asynchronous FCL.\nIn the synchronous FCL settings [47], clients have the same task\nsequences but a varied proportion of samples from each class. It is a\ncommon setting employed in existing FCL works [7]. The degree of\ndata heterogeneity in this scenario is controlled with the Dirichlet\nparameter, which is set to be 1 in our experiments. Specifically, we\nfirst partition the dataset into 5 tasks, each containing 20 classes,\nwith no overlapping class between tasks. Then, within each task, the\nsamples of each class are randomly divided into the same number\nof subsets as the total number of clients, ensuring that the data\namong clients is also non-overlapping.\nIn the asynchronous FCL settings [47], some of the classes are\naccessible to all clients while others are private to certain clients,\nwhich is derived from pathological Non-IID in static FL [31]. In this\nsetting, we consider that there are 15 private classes for each client.\nEach task contains 8 classes. To be specific, each client first selects\n15 classes unique to itself, and only that client has access to the full\ndata of these classes. Therefore, there are 25 classes lefted as public\nclasses shared by all clients. As a result, each client has data for 40\nclasses. The client then randomly divides these 40 classes into 5\ntasks, each containing 8 classes.\n5.1.2 Baselines and Backbones. We compare FedMGP with FedAvg\n[31], FedEWC [18], FedProx [23] and GLFC [7] on ResNet-18 [12].\nSince our method is based on ViT-B/16, we also conduct experi-\nments on ViT-B/16 to compare FedMGP with FedViT. FedViT is\na naive combination of FedAvg and ViT [8], which performs fed-\nerated training by locally updating and globally aggregating the\nparameters of the classifier heads iteratively. FedL2P and FedDualP\nare the adapted versions of two effective prompt-based methods\nin traditional CL, L2P [41] and DualPrompt [40], making them\nmore suitable for use in a federated environment. More detailed\ndescriptions are in Appendix 3."}, {"title": "5.2 Expermental Results", "content": "We use the accuracy of the aggregated global model on local test\nsets as the metric in Table 1. To examine the impact of different\nbackbone networks on the experimental results, we employed base-\nline methods based on two backbones, namely ResNet-18 and the\npre-trained ViT.\nSurprisingly, all methods generally perform better in the asyn-\nchronous setting than in the synchronous setting. This is attributed\nto the fact that in the synchronous setting, each task involves 20\nclasses. GLFC, FedAvg, and FedProx failed in both asynchronous\nand synchronous FCL. As expected, methods based on ViT outper-\nformed those based on ResNet-18 in both scenarios. But FedAvg\nperforms even better than FedViT and FedDual in synchronous\nFCL. This indicates that in scenarios with similar data distributions,\nFedAvg has the ability to challenge large pre-trained models.\nIn all methods using ViT as the backbone, FedL2P with prompts\nperformed better than using ViT alone. Unfortunately, FedDualP\nperformed even worse than the simple FedViT. We believe this is\ndue to the heterogeneity in the learned parameters across clients.\nMoreover, the performance of these methods did not show signifi-\ncant improvement after aggregation. In fact, FedViT experienced a\ndecrease of 3.9% in average accuracy after aggregation in synchro-\nnous FCL and a decrease of 7.27% in asynchronous FCL.\nOur method achieved the best performance in both synchronous\nand asynchronous settings, with accuracies of 90.56% and 83.46%,\nshowing the state-of-the-art performance of fusing heterogeneous\nknowledge. Although our method performs well on this metric\neven without some components, such as Ours-w/oGP achieving\n89.36% and 81.06%, and Ours-w/oLp achieving 87.29% and 77.93%,\nthe ability to retain spatial-temporal knowledge is significantly\naffected. In the following section (Sec. 5.3), we will evaluate each\nmethod using new metrics, i.e., temporal knowledge retention and\nspatial knowledge retention, to evaluate the resistance of spatial-\ntemporal catastrophic forgetting."}, {"title": "5.3 Ablation Studies", "content": "To further validate the effectiveness of the multi-granularity knowl-\nedge space, we conducted three different ablation experiments un-\nder the same experimental setup. These experiments respectively re-\nmoved the global prompts, local prompts, and the selective prompt\nfusion mechanism on the server. Results are shown in Fig. 3.\nIn both asynchronous and synchronous settings, ViT-based meth-\nods have demonstrated exceptional performance in retaining spatial\nknowledge. This result also confirms our hypothesis: having sim-\nilar cognition is the foundation for knowledge sharing. Based on\nthat, the increment of spatial knowledge retention of FedAvg in the\nsynchronous setting is not difficult to understand, as similar data"}, {"title": "5.4 Sensitivity Analysis", "content": "FedMGP involves several hyperparameters, including prompt length,\nprompt pool size and so on. To further investigate the robustness\nof FedMGP, we conduct sensitivity analyses of prompt length and\npool size on CIFAR-100 with 5 incremental tasks and present the\nresults in Fig. 4."}, {"title": "6 DISCUSSION", "content": "This section will provide a preliminary analysis and discussion\nof the computational cost, communication overhead, and privacy\nprotection in federated learning for FedMGP.\nComputational cost. The clients have only two parts to train:\ncoarse-grained global prompts and fine-grained local prompts. The\nsize of the global prompt pool of one client is determined by the\nnumber of prompts, prompt length, and embedding dimension,\nwhich are set to 10, 10, and 768 in the experiments. And the size\nof prompt keys is determined by the pool size and embedding\ndimension. In our experimental setup, the total size of local prompts\nis 4,608,000, and the size of their corresponding keys is also the\nsame as the global prompts' keys, which is 7,680. In summary, each\nclient has a total of 4,700,160 parameters to train.\nMoreover, the server only needs to aggregate the global prompts.\nThis means that the training process of local prompts can proceed\nin parallel with the server's aggregation process.\nCommunication overhead. Our method transmits only coarse-\ngrained global prompts and keys, keeping communication overhead\nlow. The size of the global prompt pool per client is determined by\nthe number of prompts, prompt length, and embedding dimension\n(set to 10, 10, and 768 in experiments). Prompt keys size depends\non pool size and embedding dimension. Thus, the total transmitted\nsize is 76,800 + 7,680 parameters. Although there are fine-grained\nlocal parts that also need to be trained, they remain local, which"}, {"title": "7 CONCLUSION", "content": "Personalized Federated Continual Learning is a novel and practical\nscenario. It not only requires the accumulation of knowledge that\nevolves over time and space but also needs consideration of per-\nsonalized strategies to make generalized knowledge better adapted\nto local requirements. Moreover, spatial-temporal catastrophic for-\ngetting is also a key issue that needs to be addressed.\nIn this paper, we first formulated a formal problem definition\nfor PFCL and shaped the objectives of PFCL as three folds: (1)\nAlleviating spatial knowledge catastrophic forgetting caused by\ndata heterogeneity; (2) Mitigating temporal knowledge catastrophic\nforgetting caused by dynamic task streams; (3) Training customized\nlocal models to achieve personalization.\nTo address these issues, we proposed a multi-granularity knowl-\nedge space for federated continuous learning (termed as FedMGP),\nwhich has efficient fusion and personalization by representing\nknowledge at different granularities. Specifically, the FedMGP uti-\nlizes a shared ViT to construct coarse-grained global prompts and\nmodifies the ViT with local prompts based on these global prompts.\nIn addition, we designed 1) global prompts on the embedding layer\nto learn coarse-grained knowledge continually and 2) local prompts\non the multi-head self-attention layer to learn fine-grained knowl-\nedge as a complementary to achieve personalization. Extensive\nexperiments under synchronous and asynchronous FCL settings\nare conducted to demonstrate the effectiveness of our method.\nThe effectiveness of multi-granularity knowledge representation\nhas been experimentally proven in this work, and their comple-\nmentary nature significantly enhances the model's resistance to\nspatial-temporal catastrophic forgetting. Our future research will\ninvestigate the multi-granularity representation of knowledge in\nvarious federated learning scenarios such as vertical federated learn-\ning [27] and multi-objective federated learning [16]. We will explore\nits implications for privacy preservation, model performance, algo-\nrithm efficiency, and so on, aiming at achieving trustworthy PFCL."}, {"title": "ACKNOWLEDGEMENTS", "content": "This work was supported by the National Natural Science Foun-\ndation of China (Nos. 72242106, 62176221), the Natural Science\nFoundation of Sichuan Province (No. 2022NSFSC0528), Sichuan Sci-\nence and Technology Program (No. 2024YFHZ0024), Jiaozi Institute\nof Fintech Innovation in Southwestern University of Finance and\nEconomics (Nos. kjcgzh20230103, kjcgzh20230201) and the Funda-\nmental Research Funds for the Central Universities (YJ202421)."}, {"title": "1 NOTATION", "content": "In Table 2, we introduce the notations in our paper.\nTable 2: Mathematical notations and descriptions.\nNotation\nAi\n\u03b8\n\u03b8\nPG\npi\nTi\nT\ni\nV\nE\nH\nDescription\nClient i\nThe global model at round r\nThe local model of client i at round r\nGlobal prompt pool\nLocal prompt pool of client i\nTask sequence of client i\nThe task of client i at incremental state n\nThe pre-trained ViT\nEmbedding layer\nThe classification head"}, {"title": "2 SENSITIVITY ANALYSIS", "content": "As illustrated in Fig. 5, the aggregation of global prompts has im-\nproved the performance of both global prompts and local prompts.\nFig. 5(a) shows the performance improvement of coarse-grained\nglobal prompts evaluated with test accuracy (%) after the aggre-\ngation of global prompts. Fig. 5(b) illustrates the performance im-\nprovement of fine-grained local prompts after the aggregation of\nglobal prompts. We can find that both improvements are robust to\ndifferent values of prompt pool size and prompt length."}]}