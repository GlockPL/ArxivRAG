{"title": "Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection", "authors": ["Suhee Yoon", "Sanghyu Yoon", "Hankook Lee", "Ye Seul Sim", "Sungik Choi", "Kyungeun Lee", "Hye-Seung Cho", "Woohyung Lim"], "abstract": "Out-of-distribution (OOD) detection, which determines whether a given sample is part of the in-distribution (ID), has recently shown promising results through training with synthetic OOD datasets. Nonetheless, existing methods often produce outliers that are considerably distant from the ID, showing limited efficacy for capturing subtle distinctions between ID and OOD. To address these issues, we propose a novel framework, Semantic Outlier generation via Nuisance Awareness (SONA), which notably produces challenging outliers by directly leveraging pixel-space ID samples through diffusion models. Our approach incorporates SONA guidance, providing separate control over semantic and nuisance regions of ID samples. Thereby, the generated outliers achieve two crucial properties: (i) they present explicit semantic-discrepant information, while (ii) maintaining various levels of nuisance resemblance with ID. Furthermore, the improved OOD detector training with SONA outliers facilitates learning with a focus on semantic distinctions. Extensive experiments demonstrate the effectiveness of our framework, achieving an impressive AUROC of 88% on near OOD datasets, which surpasses the performance of baseline methods by a significant margin of approximately 6%.", "sections": [{"title": "1 Introduction", "content": "Out-of-distribution (OOD) detection is a fundamental machine learning task which aims to detect whether a given sample is drawn from the in-distribution (ID) or not. Among a number of OOD detection methods (Lee et al. 2018; Liu et al. 2018; Bevandic et al. 2018; Malinin and Gales 2018; Hendrycks and Gimpel 2017), one promising approach is to learn a detector using auxiliary OOD samples, as pioneered by Outlier Exposure (OE; Hendrycks, Mazeika, and Dietterich 2019). This makes learning relatively easier since such outliers can provide practical heuristics for OOD detection. Although this approach has achieved outstanding performance in the recent literature (Ravikumar et al. 2020; S. et al. 2020; Yang et al. 2021; Jinyu and Fan 2022; Zhang et al. 2023a), they suffers from the outlier acquisition problem since determining whether a sample qualifies as an outlier is difficult."}, {"title": "2 Preliminaries", "content": "Out-of-Distribution Detection. The task of OOD detection aims to identify whether a given input x is drawn from the training distribution or not. Let $D_{ID} = \\{x^{(i)}, y^{(i)} \\}$ be a training distribution over $X \\times Y$, where $X$ denotes the input space and $y = \\{1,...,C \\}$ denotes the label space with C classes.\nA feature encoder $f: X \\rightarrow Z$ is trained on this distribution to map inputs to a feature space Z. Subsequently, a classifier g: Z \u2192 Y is trained to predict the class labels. The trained feature encoder and classifier are then used to develop a scalar function $S_{f,g}: X \\rightarrow \\mathbb{R}$, which provides a confidence score to determine if an input x is within the training distribution (i.e., $S_{f,g}(x) \\leq \\kappa$) or not (i.e., $S_{f,g}(x) > \\kappa$), where \u03ba \u0456\u0455 a predefined hyperparameter.\nConditional Diffusion Models (CDMs). CDMs have recently shown promising advances in image generation by incorporating specific conditions c (e.g., class labels or text prompts) into diffusion process. In particular, Classifier-free Diffusion Guidance (CFG; Ho and Salimans 2022) represents a simple yet effective approach of CDM, eliminating the need for a separate classifier. During CFG training, they randomly drop the condition with an unconditional probability, optimizing the reverse process parameter $\\theta$ with the following objective:\n$L(\\theta) = \\mathbb{E}_{(x_0, c) \\sim D, t \\sim \\mathcal{U}\\{1,...,T\\}, \\epsilon \\sim \\mathcal{N}(0,1)} [||\\epsilon_{\\theta} (x_t, c) - \\epsilon||^2]$.\nIn the sampling phase, the noise prediction $\\epsilon_{\\theta}(x_t, c)$ can be expressed as:\n$\\tilde{\\epsilon}_{\\theta}(x_t, c) = \\epsilon_{\\theta}(x_t) + s \\cdot (\\epsilon_{\\theta}(x_t, c) - \\epsilon_{\\theta}(x_t))\n= \\epsilon_{\\theta}(x_t) + s \\cdot \\Delta(\\epsilon_{\\theta}(x_t), c)$,\nwhere s is the guidance scale and $ \\Delta(\\epsilon_{\\theta}(x_t), c)$ denotes the difference between conditional and unconditional predictions. While previous outlier generation methods utilized Stable Diffusion (Rombach et al. 2022) for its strong performance"}, {"title": "3 Method", "content": "We introduce Semantic Outlier generation via Nuisance Awareness (SONA), a novel and effective outlier synthesizing framework covering Near-to-Far OOD detection scenarios. Our key idea is to directly incorporate full pixel-space ID images into CDM by specifying semantic and nuisance regions. This enables our framework to generate semantic-discrepant outliers with resembling the nuisance of ID samples, which has superiority over prior synthetic outlier-based training methods, especially in Near-OOD detection tasks."}, {"title": "3.1 Overview", "content": "Our framework begins by introducing the underlying structure of input deformation and guides it to a new desired direction (Section 3.2). Following this, we specify semantic and nuisance non-overlapping regions for each sample (Section 3.3). Based on these regions, we propose our new region-specific guidance, SONA Guidance, denoted by $\\Delta_{SONA}$ (Section 3.4). $\\Delta_{SONA}$ allows a diffusion model to deform the original semantic more intensively while remaining the nuisances. The modified noise prediction with our SONA guidance can be expressed as follows:\n$\\epsilon_{\\theta}(z_t, c_{ID}, c_{OOD}) := \\epsilon_{\\theta}(z_t) + s \\Delta_{SONA}(z_t, c_{ID}, c_{OOD})$,\nwhere $c_{ID}$ and $c_{OOD}$ are conditions obtained by ID and OOD labels, respectively, and the latter can be sampled from a broad range of text conditions that does not include in ID. Lastly, the advanced OOD detector training method with"}, {"title": "3.2 Input Deformation for Outlier Synthesis", "content": "We here describe our underlying framework for input deformation that transforms the original ID sample $x \\in D_{ID}$ into an outlier. After encoding x into its latent representation $z_0$, the deformation process starts by performing an incomplete diffusion process from the clean latent $z_0$ to a noisy latent $z_\\tau$ where $ \\tau \\sim U(1,T)$ is an early stop timestep. By stopping the process earlier, we obtain the noisy latent $z_\\tau$ with more corruption effects in the semantically important areas. This is because Gaussian noise exhibits a uniform spectral density, which makes semantic components more susceptible to perturbations than nuisance (Leach, M., and G 2022; Y. et al. 2023; Wang Haohan 2020). Hereby, denoising from the obtained $z_\\tau$ with the new conditional guidance is supposed to lead to more deformation effect on the semantic rather than nuisance.\nNevertheless, these denoised samples are not sufficiently qualified as outliers, due to their limited property of varying $ \\tau$. Stopping too early $ \\tau$ fails to initiate semantic changes, leaving the sample almost identical to the ID and potentially confusing the OOD detector. Conversely, a large $ \\tau$ leads to abrupt changes in both semantic and nuisance, resulting in overly distant outliers. We solve this sensitivity issue and improve the quality of the transformation by specifying semantic and nuisance region (Section 3.3) and proposing an effective guidance term $ \\Delta_{SONA}$ (Section 3.4)."}, {"title": "3.3 Semantic and Nuisance Region Masking", "content": "Our key strategy is to robustly control the changes in both semantic and nuisance information for any $ \\tau$. For this, we identify two non-overlapping regions, the semantic region"}, {"title": "3.4 SONA Guidance", "content": "In this section, we introduce SONA guidance, a novel approach that enables fine-grained control on each semantic and nuisance region for outlier generation. Our method draws inspiration from recent advances in image editing, which aims to completely replace target semantics. However, as they are not inherently designed for OOD detection, their application has shown limited impact in this context (see Appendix G). We propose a developed approach adequate for outlier generation, allowing precise control over both $M_s$ and $M_N$ to prioritize semantic differences. The SONA guidance term, $ \\Delta_{SONA}$, is composed of three components as follows, each of which is described in the following paragraphs:\n$ \\Delta_{SONA} := \\Delta_{ID} + \\Delta_{N} + \\Delta_{OOD}$.\nRemoval of ID semantic information. During the denoising process, $ \\Delta_{ID}$ removes the ID semantic, $c_{ID}$, targeting on $M_s$. For this, we change the direction of semantic enhancement in the opposite way as written below. Figure 4 (c) shows that $M_s$ retains a substantial amount of $c_{ID}$ semantics during the initial stages of the denoising process, but by the end of the process, most of the semantic information gradually disappears. This approach effectively mitigates the issue of the original image being restored when the stop timestep $ \\tau$ is chosen too early.\n$\\Delta_{ID}(z_t, c_{ID}) := -M_s(z_t, c_{ID}) \\odot \\psi(z_t, c_{ID})$.\nPreservation of ID nuisance information. To encourage the detector to focus on changes within the semantic regions, $ \\Delta_{N}$ is designed to retain a relative amount of nuisance information (Figure 4 (d)). By guiding $M_N$ in the direction of $ \\psi(z_t, c_{ID})$ as written below, we can maintain varying degrees of nuisance information, depending on $ \\tau$. Therefore, our method gains more advantage over semantic editing methodologies that aim for explicit nuisance preservation, as our method generates a diverse set of outliers with different levels of nuisance retention.\n$\\Delta_{N}(z_t, c_{ID}) := M_N(z_t, c_{ID}) \\odot \\psi(z_t, c_{ID})$.\nAddition of OOD semantic information. $ \\Delta_{OOD}$ serves as another component that induces semantic-discrepant outlier generation by corrupting with new semantic of $c_{OOD}$. However, as shown in Figure 4 (e), $M_s (z_t, c_{OOD})$ slightly extends beyond the original semantic region. To improve the preservation of nuisance and induce the corruption on the semantic region, we further filter out the intersecting parts between OOD semantic region $M_s(z_t, c_{OOD})$ and the nuisance region $M_N(z_t, c_{ID})$ (Figure 4 (f)). By intentionally rectifying the areas where $ \\psi(z_t, c_{OOD})$ has an effect, we ensure that the influence of nuisance attributes remains significant even when $ \\tau$ chosen as later timestep.\n$\\Delta_{OOD}(z_t, c_{ID}, c_{OOD}) := M_s (z_t, c_{OOD}) \\odot (1 - M_N (z_t, c_{ID})) \\odot \\psi(z_t, c_{OOD})$.\nFinally, we obtain the outliers by denoising $z_t$ for every timestep t = $ \\tau$,\u2026\u2026\u2026,1 with our SONA guidance. To generate the pixel-space outlier image $x_{OOD}$, we pass the denoised latent representation $z_0$ through the decoder of the diffusion model. Algorithm 2 in the Appendix provides a detailed pseudo-code implementation of our framework."}, {"title": "3.5 OOD Detection with SONA Outliers", "content": "The generated SONA outliers are used to preciously regularize the classifier, with a focus on semantic aspects. Given (x, y) \u2208 $D_{ID}$ and $x_{OOD} \u2208 D_{OOD}$, our training objective with SONA is formulated as:\n$L = \\mathbb{E}_{(x,y)\\sim D_{ID}} [L_{CE}(g(f(x)), y)]$\n+ $\\beta \\mathbb{E}_{x_{OOD}\\sim D_{OOD}} [L_{OE} (g(f(x_{OOD}))) ]$\n+ $L_{MI} (f(x), f(x_{OOD}))$\nIn the above objective, $L_{CE}$ is a cross-entropy loss that compels ID samples to discriminate classes using labels y. $L_{OE}$ encourages the separation of SONA outliers from ID by inducing their predictions to a uniform distribution, which can be expressed as $-\\sum_{c=1}^{C} softmax(f(x_{OOD}))$. Moreover, we introduce an additional loss term, $L_{MI}$, which minimizes the mutual information between SONA outliers and their source ID samples. This is achieved through the Kullback-Leibler divergence between the joint distribution and the product of marginal distributions:\n$L_{MI} = MI (f(x); f(x_{ood}))$\n$= KL (P(f(x), f(x_{ood}))||P(f(x))P(f(x_{ood}))) $\nSpecifically, we implement this by minimizing the Contrastive Log-ratio Upper Bound (CLUB; Cheng et al. 2020) at the feature extraction layer, where nuisances are significantly reduced. This enables the classifier to directly compare and learn the semantic differences between ID samples and their corresponding SONA outliers.\nDuring the test phase, we utilize the energy score (Liu et al. 2020a), which effectively addresses overconfidence issues in OOD detection by assigning lower energy values to ID samples and higher energy values to OOD samples."}, {"title": "4 Experiments", "content": "In this section, we evaluate the OOD detection performance of our SONA framework. We first describe our experimental setups (Section 4.1), then showcase novel outlier examples and impressive main results (Section 4.2). Finally, we present various analyses proving the robustness of our framework (Section 4.3)."}, {"title": "4.1 Experimental Setup", "content": "Datasets. We mainly evaluate our framework on ImageNet-200 (Zhang et al. 2023b) as ID, a subset of 200 categories from ImageNet-1k (Deng et al. 2009). Our evaluation covers both far-OOD and challenging near-OOD scenarios. For far-OOD detection, we employ widely-used datasets such as iNaturalist (Horn et al. 2018), Texture (Cimpoi et al. 2014a), and OpenImage-O (Wang et al. 2022). For near-OOD detection and SSB-hard (Vaze et al. 2022a) and NINCO (Julian Bitterwolf and Hein 2023) for near-OOD detection., which have no class overlap but show close semantic similarity with ImageNet-1K.\nImplementation details. Our implementation is based on Stable Diffusion v2-base model , with sampling hyperparameters consistent with (Brack et al. 2024). For selecting"}, {"title": "5 Related Work", "content": "5.1 OOD Detection with Auxiliary Outliers\nRecent strategies aim to construct robust OOD detectors by regularizing the classifier with real-world outliers in training OE (Hendrycks, Mazeika, and Dietterich 2019). (Yu and Aizawa 2019) trains two randomly initialized classifiers and minimizes their discrepancy on the outlier. (Yang et al. 2021) collects semantically coherent outliers through clustering. (Zhang et al. 2023a) synthesize fine-grained outlier by applying mixup (Zhang et al. 2018a). However, these methods require explicit outlier gathering, which may be costly.\nAn alternative approach is to synthesize outliers on pixel or latent space. (Du et al. 2022) approximates the ID latent distribution as a mixture of class-conditional Gaussians and sample outliers deviating from this mixture. (Tao et al. 2023) identifies boundary ID samples in the CLIP (Radford et al. 2021a) space and regards distant features as outliers."}, {"title": "5.2 Semantic Guidance for Diffusion Model", "content": "Text-guided diffusion models allow for controlling semantic content through textual prompts. One approach to enhancing fine-grained controllability is inpainting (Nichol et al. 2021; Couairon et al. 2022), which uses pre-defined or learnable masks to modify the semantic regions of an image. Another line of research has focused on developing more semantically grounded approaches, leveraging the semantics encoded in the cross-attention maps (Hertz et al. 2022) of the diffusion model or directly manipulating noise estimates (Brack et al. 2024). Instead of using semantic control for image editing, we aim to leverage it for outlier generation, intentionally inducing imperfect semantic control to produce outlier samples that slightly deviate from the original meaning."}, {"title": "6 Conclusion", "content": "In this paper, we introduce Semantic Outlier generation via Nuisance Awareness (SONA), a novel and effective outlier synthesizing framework for OOD detection. Our key idea is to leverage the informative pixel-space ID images for outlier generation by directly incorporating them into diffusion models. To this end, we propose SONA guidance that enables the generation of diverse outliers that closely resemble the ID in nuisance regions while representing semantically distinct information. By training OOD detectors with SONA samples, we successfully capture subtle distinctions between ID and OOD, leading to improved OOD detection performance.\nLimitation. This paper focuses on extracting and utilizing nuisance information of ID images to generate outliers. However, there exist various types of nuisance information (e.g., drawings styles and textures), and it might require different approaches to extract and utilize them better. We believe our framework can be further specialized to a nuisance type based on additional knowledge (e.g., style representation (Zhang et al. 2023c)) or can be further improved by advanced representation learning (e.g., contrastive learning (Tack et al. 2020))."}, {"title": "H Broader Impact.", "content": "The SONA framework demonstrates significant potential for broad applications, particularly in settings where reliable OOD detection is crucial. In anomaly detection tasks, SONA can enhance the resilience of models when encountering novel or unexpected samples. Additionally, our methodology can contributes as a reliable near-OOD test benchmark, facilitating the advancement and evaluation of future methods focused on semantic distinctions in near-OOD scenarios.\nA Proposal of a SONA Test Dataset. The SONA dataset is designed to maintain the nuisance information of the ID while introducing subtle semantic differences, making it a more refined test dataset compared to existing Near-OOD datasets. To empirically validate the effectiveness of our SONA test dataset, we evaluated the performance of well-known OOD detection methods on this dataset. As the results are presented in Table 10, when ImageNet-200 given as the ID dataset, the SONA test dataset showed significantly lower OOD detection performance compared to the exisiting Near-OOD datasets SSB-hard and NINCO. This performance degradation demonstrates that the SONA test dataset successfully generates more challenging Near-OOD samples. Furthermore, it suggests that the SONA test dataset can serve as a valuable benchmark for developing and evaluating future semantic-focused Near-OOD detection models."}]}