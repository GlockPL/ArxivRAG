{"title": "Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection", "authors": ["Suhee Yoon", "Sanghyu Yoon", "Hankook Lee", "Ye Seul Sim", "Sungik Choi", "Kyungeun Lee", "Hye-Seung Cho", "Woohyung Lim"], "abstract": "Out-of-distribution (OOD) detection, which determines whether a given sample is part of the in-distribution (ID), has recently shown promising results through training with synthetic OOD datasets. Nonetheless, existing methods often produce outliers that are considerably distant from the ID, showing limited efficacy for capturing subtle distinctions between ID and OOD. To address these issues, we propose a novel framework, Semantic Outlier generation via Nuisance Awareness (SONA), which notably produces challenging outliers by directly leveraging pixel-space ID samples through diffusion models. Our approach incorporates SONA guidance, providing separate control over semantic and nuisance regions of ID samples. Thereby, the generated outliers achieve two crucial properties: (i) they present explicit semantic-discrepant information, while (ii) maintaining various levels of nuisance resemblance with ID. Furthermore, the improved OOD detector training with SONA outliers facilitates learning with a focus on semantic distinctions. Extensive experiments demonstrate the effectiveness of our framework, achieving an impressive AUROC of 88% on near-OOD datasets, which surpasses the performance of baseline methods by a significant margin of approximately 6%.", "sections": [{"title": "1 Introduction", "content": "Out-of-distribution (OOD) detection is a fundamental ma-chine learning task which aims to detect whether a given sample is drawn from the in-distribution (ID) or not. Among a number of OOD detection methods (Lee et al. 2018; Liu et al. 2018; Bevandic et al. 2018; Malinin and Gales 2018; Hendrycks and Gimpel 2017), one promising approach is to learn a detector using auxiliary OOD samples, as pio-neered by Outlier Exposure (OE; Hendrycks, Mazeika, and Dietterich 2019). This makes learning relatively easier since such outliers can provide practical heuristics for OOD detec-tion. Although this approach has achieved outstanding per-formance in the recent literature (Ravikumar et al. 2020; S. et al. 2020; Yang et al. 2021; Jinyu and Fan 2022; Zhang et al. 2023a), they suffers from the outlier acquisition prob-lem since determining whether a sample qualifies as an out-lier is difficult.\nTo mitigate the issue, recent research has explored syn-thesizing outliers to help the model to learn a precise de-cision boundary between ID and OOD. For example, VOS (Du et al. 2022) synthesizes outliers from the low-likelihood region within a latent space under a distributional assump-tion (e.g., Gaussian) regarding the ID latent variables. How-ever, this assumption is often inadequate, leading to a fail-ure in capturing the informative features for OOD detec-tion, such as class-specific object details (Bai et al. 2024). Another recently emerging direction is to synthesize out-liers within the pixel-space via diffusion models (Mirzaei et al. 2022; Du et al. 2024), which provides not only high-resolution samples but also visual interpretability. However, the existing works often suffers from volatility in the OOD detection performance as the quality of outliers heavily re-lies on generation targets (e.g., OOD prompts in DreamOOD (Du et al. 2024) or blurry images in Fakeit (Mirzaei et al. 2022)). In particular, DreamOOD intensifies this volatility by entirely depending on OOD (label/text) prompts since it starts from random noises without pixel-space information in ID images. Consequently, these approaches generate less"}, {"title": "2 Preliminaries", "content": "Out-of-Distribution Detection. The task of OOD detec-tion aims to identify whether a given input x is drawn from the training distribution or not. Let $D_{ID} = {(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)})}$ be a training distribution over $\\mathcal{X} \\times \\mathcal{Y}$, where $\\mathcal{X}$ denotes the input space and $\\mathcal{Y} = {1,...,C}$ denotes the label space with $C$ classes.\nA feature encoder $f : \\mathcal{X} \\rightarrow \\mathcal{Z}$ is trained on this distribu-tion to map inputs to a feature space $\\mathcal{Z}$. Subsequently, a clas-sifier $g: \\mathcal{Z} \\rightarrow \\mathcal{Y}$ is trained to predict the class labels. The trained feature encoder and classifier are then used to develop a scalar function $S_{f,g} : \\mathcal{X} \\rightarrow \\mathbb{R}$, which provides a con-fidence score to determine if an input $\\mathbf{x}$ is within the training distribution (i.e., $S_{f,g}(\\mathbf{x}) \\leq \\kappa$) or not (i.e., $S_{f,g}(\\mathbf{x}) > \\kappa$), where $\\kappa$ i\u0455 a predefined hyperparameter.\nConditional Diffusion Models (CDMs). CDMs have re-cently shown promising advances in image generation by incorporating specific conditions $c$ (e.g., class labels or text prompts) into diffusion process. In particular, Classifier-free Diffusion Guidance (CFG; Ho and Salimans 2022) repre-sents a simple yet effective approach of CDM, eliminating the need for a separate classifier. During CFG training, they randomly drop the condition with an unconditional prob-ability, optimizing the reverse process parameter $\\theta$ with the following objective:\n$\\mathcal{L}(\\theta) = \\mathbb{E}_{(\\mathbf{x}_0,c) \\sim D, t \\sim U{1,...,T}, \\epsilon \\sim \\mathcal{N}(0,I)}[ || \\epsilon_{\\theta}(\\mathbf{x}_t, c) - \\epsilon ||^2 ]$.\nIn the sampling phase, the noise prediction $\\epsilon_{\\theta}(\\mathbf{x}_t, c)$ can be expressed as:\n$\\begin{aligned} \\epsilon_{\\theta}(\\mathbf{x}_t, c) &= \\epsilon_{\\theta}(\\mathbf{x}_t) + s \\cdot ( \\epsilon_{\\theta}(\\mathbf{x}_t, c) - \\epsilon_{\\theta}(\\mathbf{x}_t) ) \\\\ &= \\epsilon_{\\theta}(\\mathbf{x}_t) + s \\cdot \\varphi(\\mathbf{x}_t, c),  \\end{aligned}$\nwhere $s$ is the guidance scale and $\\varphi(\\mathbf{x}_t, c)$ denotes the dif-ference between conditional and unconditional predictions. While previous outlier generation methods utilized Stable Diffusion (Rombach et al. 2022) for its strong performance"}, {"title": "3 Method", "content": "We introduce Semantic Outlier generation via Nuisance Awareness (SONA), a novel and effective outlier synthesiz-ing framework covering Near-to-Far OOD detection scenar-ios. Our key idea is to directly incorporate full pixel-space ID images into CDM by specifying semantic and nuisance regions. This enables our framework to generate semantic-discrepant outliers with resembling the nuisance of ID sam-ples, which has superiority over prior synthetic outlier-based training methods, especially in Near-OOD detection tasks.\n3.1 Overview\nOur framework begins by introducing the underlying struc-ture of input deformation and guides it to a new desired direction (Section 3.2). Following this, we specify seman-tic and nuisance non-overlapping regions for each sam-ple (Section 3.3). Based on these regions, we propose our new region-specific guidance, SONA Guidance, denoted by $\\Delta_{SONA}$ (Section 3.4). $\\Delta_{SONA}$ allows a diffusion model to de-form the original semantic more intensively while remain-ing the nuisances. The modified noise prediction with our SONA guidance can be expressed as follows:\n$\\epsilon_{\\theta}(\\mathbf{z}_t, c_{ID}, c_{OOD}) := \\epsilon_{\\theta}(\\mathbf{z}_t) + s \\Delta_{SONA}(\\mathbf{z}_t, c_{ID}, c_{OOD}),$\nwhere $c_{ID}$ and $c_{OOD}$ are conditions obtained by ID and OOD labels, respectively, and the latter can be sampled from a broad range of text conditions that does not include in ID. Lastly, the advanced OOD detector training method with"}, {"title": "3.2 Input Deformation for Outlier Synthesis", "content": "We here describe our underlying framework for input defor-mation that transforms the original ID sample $\\mathbf{x} \\in D_{ID}$ into an outlier. After encoding $\\mathbf{x}$ into its latent representation $\\mathbf{z}_0$, the deformation process starts by performing an incomplete diffusion process from the clean latent $\\mathbf{z}_0$ to a noisy latent $\\mathbf{z}_{\\tilde{T}}$ where $\\tilde{T} \\sim U(1,T)$ is an early stop timestep. By stop-ping the process earlier, we obtain the noisy latent $\\mathbf{z}_{\\tilde{T}}$ with more corruption effects in the semantically important areas. This is because Gaussian noise exhibits a uniform spectral density, which makes semantic components more suscepti-ble to perturbations than nuisance (Leach, M., and G 2022; Y. et al. 2023; Wang Haohan 2020). Hereby, denoising from the obtained $\\mathbf{z}_{\\tilde{T}}$ with the new conditional guidance is sup-posed to lead to more deformation effect on the semantic rather than nuisance.\nNevertheless, these denoised samples are not sufficiently qualified as outliers, due to their limited property of varying $\\tilde{T}$. Stopping too early $\\tilde{T}$ fails to initiate semantic changes, leaving the sample almost identical to the ID and potentially confusing the OOD detector. Conversely, a large $T$ leads to abrupt changes in both semantic and nuisance, resulting in overly distant outliers. We solve this sensitivity issue and improve the quality of the transformation by specifying se-mantic and nuisance region (Section 3.3) and proposing an effective guidance term $\\Delta_{SONA}$ (Section 3.4)."}, {"title": "3.3 Semantic and Nuisance Region Masking", "content": "Our key strategy is to robustly control the changes in both semantic and nuisance information for any $T$. For this, we identify two non-overlapping regions, the semantic region"}, {"title": "3.4 SONA Guidance", "content": "In this section, we introduce SONA guidance, a novel ap-proach that enables fine-grained control on each seman-tic and nuisance region for outlier generation. Our method draws inspiration from recent advances in image editing, which aims to completely replace target semantics. However, as they are not inherently designed for OOD detection, their application has shown limited impact in this context (see Appendix G). We propose a developed approach ade-quate for outlier generation, allowing precise control over both $\\mathcal{M}_s$ and $\\mathcal{M}_N$ to prioritize semantic differences. The SONA guidance term, $\\Delta_{SONA}$, is composed of three compo-nents as follows, each of which is described in the following paragraphs:\n$\\Delta_{SONA} := \\Delta_{ID} + \\Delta_{N} + \\Delta_{OOD}.$\nRemoval of ID semantic information. During the de-noising process, $\\Delta_{ID}$ removes the ID semantic, $c_{ID}$, target-ing on $\\mathcal{M}_s$. For this, we change the direction of semantic en-hancement in the opposite way as written below. Figure 4 (c) shows that $\\mathcal{M}_s$ retains a substantial amount of $c_{ID}$ semantics during the initial stages of the denoising process, but by the end of the process, most of the semantic information gradu-ally disappears. This approach effectively mitigates the issue of the original image being restored when the stop timestep $T$ is chosen too early.\n$\\Delta_{ID}(\\mathbf{z}_t, c_{ID}) := -\\mathcal{M}_s(\\mathbf{z}_t, c_{ID}) \\odot \\varphi(\\mathbf{z}_t, c_{ID}).$\nPreservation of ID nuisance information. To encourage the detector to focus on changes within the semantic regions, $\\Delta_{N}$ is designed to retain a relative amount of nuisance in-formation (Figure 4 (d)). By guiding $\\mathcal{M}_N$ in the direction of $\\varphi(\\mathbf{z}_t, c_{ID})$ as written below, we can maintain varying degrees of nuisance information, depending on $T$. There-fore, our method gains more advantage over semantic edit-ing methodologies that aim for explicit nuisance preserva-tion, as our method generates a diverse set of outliers with different levels of nuisance retention.\n$\\Delta_{N}(\\mathbf{z}_t, c_{ID}) := \\mathcal{M}_N(\\mathbf{z}_t, c_{ID}) \\odot \\varphi(\\mathbf{z}_t, c_{ID}).$\nAddition of OOD semantic information. $\\Delta_{OOD}$ serves as another component that induces semantic-discrepant outlier generation by corrupting with new semantic of $c_{OOD}$. How-ever, as shown in Figure 4 (e), $\\mathcal{M}_s(\\mathbf{z}_t, c_{OOD})$ slightly extends beyond the original semantic region. To improve the preser-vation of nuisance and induce the corruption on the semantic region, we further filter out the intersecting parts between ood semantic region $\\mathcal{M}_s(\\mathbf{z}_t, c_{OOD})$ and the nuisance region $\\mathcal{M}_N(\\mathbf{z}_t, c_{ID})$ (Figure 4 (f)). By intentionally rectifying the areas where $\\varphi(\\mathbf{z}_t, c_{OOD})$ has an effect, we ensure that the in-fluence of nuisance attributes remains significant even when $T$ chosen as later timestep.\n$\\Delta_{OOD}(\\mathbf{z}_t, c_{ID}, c_{OOD}) \\\\ := \\mathcal{M}_s(\\mathbf{z}_t, c_{OOD}) \\odot (1 - \\mathcal{M}_N(\\mathbf{z}_t, c_{ID})) \\odot \\varphi(\\mathbf{z}_t, c_{OOD}).$\nFinally, we obtain the outliers by denoising $\\mathbf{z}_t$ for every timestep $t = T,\u2026\u2026\u2026,1$ with our SONA guidance. To gen-erate the pixel-space outlier image $\\mathbf{x}_{OOD}$, we pass the de-noised latent representation $\\mathbf{z}_0$ through the decoder of the diffusion model. Algorithm 2 in the Appendix provides a detailed pseudo-code implementation of our framework."}, {"title": "3.5 OOD Detection with SONA Outliers", "content": "The generated SONA outliers are used to preciously regu-larize the classifier, with a focus on semantic aspects. Given $(\\mathbf{x}, y) \\in D_{ID}$ and $\\mathbf{x}_{OOD} \\in D_{OOD}$, our training objective with SONA is formulated as:\n$\\begin{aligned} \\mathcal{L} &= \\mathbb{E}_{(\\mathbf{x},y) \\sim D_{ID}} [\\mathcal{L}_{CE}(g(f(\\mathbf{x})), y)]\\\\ &+ \\beta \\mathbb{E}_{\\mathbf{x}_{OOD} \\sim D_{OOD}} [\\mathcal{L}_{OE} (g(f(\\mathbf{x}_{OOD}))) ]\\\\ &+ \\mathcal{L}_{MI} (f(\\mathbf{x}), f(\\mathbf{x}_{OOD}))  \\end{aligned}$\nIn the above objective, $\\mathcal{L}_{CE}$ is a cross-entropy loss that com-pels ID samples to discriminate classes using labels $y$. $\\mathcal{L}_{OE}$ encourages the separation of SONA outliers from ID by in-ducing their predictions to a uniform distribution, which can be expressed as $-\\sum_{c=1}^{C} softmax(f(\\mathbf{x}_{OOD}))$. Moreover, we introduce an additional loss term, $\\mathcal{L}_{MI}$, which minimizes the mutual information between SONA outliers and their source ID samples. This is achieved through the Kullback-Leibler divergence between the joint distribution and the product of marginal distributions:\n$\\begin{aligned}  \\mathcal{L}_{MI} &= MI (f(\\mathbf{x}); f(\\mathbf{x}_{OOD}))\\\\ &= KL (P(f(\\mathbf{x}), f(\\mathbf{x}_{OOD}))||P(f(\\mathbf{x}))P(f(\\mathbf{x}_{OOD})))  \\end{aligned}$\nSpecifically, we implement this by minimizing the Con-trastive Log-ratio Upper Bound (CLUB; Cheng et al. 2020) at the feature extraction layer, where nuisances are signifi-cantly reduced. This enables the classifier to directly com-pare and learn the semantic differences between ID samples and their corresponding SONA outliers.\nDuring the test phase, we utilize the energy score (Liu et al. 2020a), which effectively addresses overconfidence is-sues in OOD detection by assigning lower energy values to ID samples and higher energy values to OOD samples."}, {"title": "4 Experiments", "content": "In this section, we evaluate the OOD detection performance of our SONA framework. We first describe our experimen-tal setups (Section 4.1), then showcase novel outlier ex-amples and impressive main results (Section 4.2). Finally, we present various analyses proving the robustness of our framework (Section 4.3).\n4.1 Experimental Setup\nDatasets. We mainly evaluate our framework on ImageNet-200 (Zhang et al. 2023b) as ID, a subset of 200 categories from ImageNet-1k (Deng et al. 2009). Our evaluation covers both far-OOD and challenging near-OOD scenarios. For far-OOD detection, we employ widely-used datasets such as iNaturalist (Horn et al. 2018), Texture (Cimpoi et al. 2014a), and OpenImage-O (Wang et al. 2022). For near-OOD detection and SSB-hard (Vaze et al. 2022a) and NINCO (Julian Bitterwolf and Hein 2023) for near-OOD detection., which have no class overlap but show close semantic similarity with ImageNet-1K.\nImplementation details. Our implementation is based on Stable Diffusion v2-base model 1, with sampling hyperpa-rameters consistent with (Brack et al. 2024). For selecting"}, {"title": "4.3 Analysis", "content": "SONA remains competitive regardless of T. SONA guidance effectively mitigates the sensitivity of T, as shown in Figure 6. Global guidance, which uniformly applies guid-ance to entire regions, shows performance variations de-pending on the T, with the best results at a fixed T = 25. In contrast, SONA guidance demonstrates robust results across both early and later T values, achieving the best score when randomly choosing $\\tilde{T} \\sim U(1,50)$ for each sample, exhibit-ing an ensemble effect. In addition, we evaluate the simi-larity between the ID and SONA samples at each timestep using the LPIPS (Zhang et al. 2018b) score. As timesteps in-crease, the global guidance's LPIPS score continues to rise, indicating growing dissimilarity. In contrast, SONA demon-strates minimal LPIPS score variations, effectively starting to remove original semantics in early T and preserving nui-sances until in later $\\tilde{T}$. This property eliminates the need for meticulous T tuning, reducing the dependency on T and making our approach more robust compared to methods heavily relying on optimal hyperparameters.\nSONA remains competitive regardless of COOD. SONA presents remarkable consistent results across different COOD selection methods (Table 2), while DreamOOD is highly"}, {"title": "5 Related Work", "content": "5.1 OOD Detection with Auxiliary Outliers\nRecent strategies aim to construct robust OOD detectors by regularizing the classifier with real-world outliers in train-ing OE (Hendrycks, Mazeika, and Dietterich 2019). (Yu and Aizawa 2019) trains two randomly initialized classifiers and minimizes their discrepancy on the outlier. (Yang et al. 2021) collects semantically coherent outliers through clustering. (Zhang et al. 2023a) synthesize fine-grained outlier by ap-plying mixup (Zhang et al. 2018a). However, these meth-ods require explicit outlier gathering, which may be costly. An alternative approach is to synthesize outliers on pixel or latent space. (Du et al. 2022) approximates the ID la-tent distribution as a mixture of class-conditional Gaussians and sample outliers deviating from this mixture. (Tao et al. 2023) identifies boundary ID samples in the CLIP (Radford et al. 2021a) space and regards distant features as outliers.\n5.2 Semantic Guidance for Diffusion Model\nText-guided diffusion models allow for controlling semantic content through textual prompts. One approach to enhanc-ing fine-grained controllability is inpainting (Nichol et al. 2021; Couairon et al. 2022), which uses pre-defined or learn-able masks to modify the semantic regions of an image. An-other line of research has focused on developing more se-mantically grounded approaches, leveraging the semantics encoded in the cross-attention maps (Hertz et al. 2022) of the diffusion model or directly manipulating noise estimates (Brack et al. 2024). Instead of using semantic control for image editing, we aim to leverage it for outlier generation, intentionally inducing imperfect semantic control to produce outlier samples that slightly deviate from the original mean-ing."}, {"title": "6 Conclusion", "content": "In this paper, we introduce Semantic Outlier generation via Nuisance Awareness (SONA), a novel and effective outlier synthesizing framework for OOD detection. Our key idea is to leverage the informative pixel-space ID images for out-lier generation by directly incorporating them into diffusion models. To this end, we propose SONA guidance that en-ables the generation of diverse outliers that closely resem-ble the ID in nuisance regions while representing semanti-cally distinct information. By training OOD detectors with SONA samples, we successfully capture subtle distinctions between ID and OOD, leading to improved OOD detection performance.\nLimitation. This paper focuses on extracting and utiliz-ing nuisance information of ID images to generate outliers. However, there exist various types of nuisance information (e.g., drawings styles and textures), and it might require dif-ferent approaches to extract and utilize them better. We be-lieve our framework can be further specialized to a nuisance type based on additional knowledge (e.g., style representa-tion (Zhang et al. 2023c)) or can be further improved by advanced representation learning (e.g., contrastive learning (Tack et al. 2020))."}, {"title": "A Backgrounds", "content": "A.1 Diffusion Models\nA diffusion model is a generative model that gradually adds noise to an input signal x = x0 until it is fully destroyed into random noise xy, and then denoises it through multiple steps to generate an output signal xo with a probability distribution similar to that of the input. A diffusion process is defined as a Gaussian process with a Markov chain:\n$\\mathbf{x}_t = \\sqrt{1 - \\beta_t}\\mathbf{x}_{t-1} + \\sqrt{ \\beta_t} z_t, t = 1, ..., T$\nwhere $ \\beta_1, ..., \\beta_T$ is a fixed variance scheduler which means the quantity of noise for each step t and $ z_t \\sim \\mathcal{N}(0, I)$. It can be rewritten as,\n$q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t}\\mathbf{x}_{t-1}, \\beta_t I)$\n$q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{a}_t}\\mathbf{x}_0, (1 - \\bar{a}_t)I)$\nwhere $a_t := 1 - \\beta_t$ and $ \\bar{a}_t := \\Pi_{i=1}^{t}a_t$.\nTo recover the input signal, we need to learn reverse process, which requires estimating the noise prediction function $\\epsilon_{\\theta}(\\mathbf{x}_t); t = 1, ..., T$. The parameter $ \\theta$ is optimized by minimizing follows:\n$\\mathcal{L}(\\theta) = \\mathbb{E}_{\\epsilon, \\mathbf{x}, t} [ || \\epsilon_{\\theta}(\\mathbf{x}_t) - \\epsilon ||^2 ]$\nin which $ \\epsilon \\sim \\mathcal{N}(0, I)$. This objective performs denoising score matching over multiple noise scales by t. Leveraging pre-dicted noise $\\epsilon_{\\theta}$, we can sample $\\mathbf{x}_{t-1} \\sim p(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$. The most widely adopted sampling method is Denoising Diffusion Proba-bilistic Models (DDPM) (Ho, Jain, and Abbeel 2020) sampler:\n$\\mathbf{x}_{t-1} =  \\frac{1}{\\sqrt{a_t}} (\\mathbf{x}_t - \\frac{1 - a_t}{\\sqrt{1 - \\bar{a}_t}} \\epsilon_{\\theta}(\\mathbf{x}_t) ) + \\sigma_t z$\nA.2 Classifier-Free Diffusion Guidance\nClassifier-free Diffusion Guidance (CFG) (Ho and Salimans 2022) is a simple yet effective conditional diffusion model that avoids the need for a separate classifier. They obtain a combination of a conditional model parameterized with $\\epsilon_{\\theta}(\\mathbf{x}_t, c)$ and an unconditional model parameterized with $\\epsilon_{\\theta}(\\mathbf{x}_t) = \\epsilon_{\\theta}(\\mathbf{x}_t, c = \\varnothing)$, which gives a null token to guidance c in a single network. During training, it randomly drops the condition with an unconditional probability $P_{uncond}$. The training process is described in Algorithm 1."}, {"title": "B Full Algorithm of SONA", "content": "Algorithm 2: Semantic Outlier generation via Nuisance Awareness (SONA)\nInput: In-distribution training data $\\mathcal{D}_{ID} = {(\\mathbf{x}^{(i)},y^{(i)})}_{i=1}^{n}$\nOutput: SONA $\\mathcal{D}_{OOD} = {\\mathbf{x}_{OOD}^{(i)}}_{i=1}^{n}$\nRequire: Latent Diffusion Model LDM with initial weights $ \\theta$, Diffusion timestep $T$\nRequire: ID prompt embedding $c_{ID}$, OOD prompt embedding $c_{OOD}$, threshold $ \\lambda$\n$ \\tilde{T} \\sim U(0,T)$\n$\\mathbf{z} \\leftarrow LDM.encode(\\mathbf{x})$\n$\\mathbf{z}_{\\tilde{T}} \\leftarrow LDM.add\\_noise(\\mathbf{z},\\tilde{T})$\n\u25b7 Add noise at timestep $\\tilde{T}$\nfor $t \\leftarrow \\tilde{T}, ..., 1$ do\n$c_{ID}, c_{OOD} \\leftarrow LDM.forward(\\mathbf{z}_{\\tilde{T}}, c_{\\varnothing}, c_{ID}, c_{OOD})$\n$\\mathcal{M}_{S\\_ID}, \\mathcal{M}_{S\\_OOD}, \\mathcal{M}_{N\\_ID} \\leftarrow GetMasks (\\mathbf{z}_t, c_{ID}, c_{OOD}, \\eta_{\\lambda})$\n$\\Delta_{ID}  \\leftarrow - \\mathcal{M}_{S\\_ID} \\cdot c_{ID}$\n\u25b7 Remove ID semantic\n$\\Delta_{N}  \\leftarrow \\mathcal{M}_{N\\_ID} \\cdot c_{ID}$\n\u25b7 Preserve ID nuisance\n$\\Delta_{OOD} \\leftarrow \\mathcal{M}_{S\\_OOD} \\cdot (1 - \\mathcal{M}_{N\\_ID}) \\cdot c_{OOD}$\n\u25b7 Add OOD semantic\n$\\Delta \\leftarrow s \\cdot (\\Delta_{ID} + \\Delta_{OOD} + \\Delta_{N})$\n$\\mathbf{z}_{t-1} \\leftarrow LDM.denoise(\\mathbf{z}_t, \\Delta)$\n\u25b7 Denoise with SONA guidance\nend for\n$\\mathbf{x}_{OOD} \\leftarrow LDM.decode(\\mathbf{z}_0)$\nreturn $\\mathbf{x}_{OOD}$"}, {"title": "C Dataset Details", "content": "C.1 Near-OOD Detection\nFor Near-OOD detection, we utilize two specific OOD datasets that have been carefully chosen to challenge the robustness of our model: SSB-hard and NINCO. This setting is adopted directly from the OpenOOD v1.5 (Zhang et al. 2023b) framework, ensuring consistency with established benchmarks.\n\u2022 SSB-hard (Vaze et al. 2022b) (Semantic Shift Benchmark - Hard): SSB-hard is a subset derived from the Semantic Shift Benchmark (SSB), designed to evaluate model performance under subtle semantic shifts. It contains images closely similar to ImageNet-1K, making it particularly challenging. The dataset comprises 980 classes from ImageNet-21K, sharing significant visual and semantic characteristics with ImageNet-1K.\n\u2022 NINCO (Bitterwolf, Mueller, and Hein 2023) (No ImageNet-1K Class Objects): NINCO is a new dataset with 64 unique classes designed for robust OOD detection evaluation. These classes do not overlap with ImageNet-1K but are visually similar, testing the model's ability to generalize beyond training data. It helps assess the model's performance in identifying visually similar OOD samples without relying on class mismatch.\nC.2 Far-OOD Detection\nFor far-OOD detection, we leverage OOD test datasets that are commonly used in prior OOD detection research. These datasets provide a stark contrast to the ID data, thereby testing the model's ability to handle significantly different OOD scenarios.\n\u2022 iNaturalist (Van Horn et al. 2018): iNaturalist is a large-scale, diverse dataset containing images of various species of plants, animals, and other natural entities. It is used to validate the model's performance in detecting OOD samples signifi-cantly different from ImageNet-1K, ensuring the model can handle a wide range of natural variations.\n\u2022 Textures (Cimpoi et al. 2014b): The Textures dataset contains images representing a wide variety of real-world patterns and surface textures, differing from the object-centric images in ImageNet-1K. It tests the model's ability to recognize OOD samples based on textural differences, crucial for robust OOD detection.\n\u2022 OpenImage-O (Wang et al. 2022): OpenImage-O, a subset of the OpenImages dataset curated for OOD detection research, includes diverse images not in ImageNet-1K, offering broad OOD scenarios. It assesses the model's capability to detect OOD instances in an open-world setting with a greater variety of objects and scenes."}, {"title": "D Implementation Details of SONA Framework", "content": "Implementation details. Our implementation is based on Stable Diffusion v2-base model 2 for more information for gener-ating SONA. For our best results", "2": "nFor our main results on ImageNet-200", "categories": "Post-hoc detection methods that do not require further training, training with real-world outlier methods that require explicit outliers, and outlier synthesis-based methods. For the post-hoc baselines, we compare against OpenMax (Bendale and Boult 2016), MSP (Hendrycks and Gimpel 2017), ODIN (Liang, Li, and Srikant 2018), EBO (Liu et al. 2020b), OpenGAN (Kong and Ramanan 2021), ReAct (Sun, Guo, and Li 2021), KNN (Sun et al. 2022), and DICE (Sun and Li 2022). For the methods that require explicit outlier, our comparison includes OE (Hendrycks, Mazeika, and Dietterich 2019), MCD (Yu and Aizawa 2019), UDG (Yang et al. 2021), and MixOE (Zhang et al. 2023a) where all methods use remaining 800 categories of the ImageNet-1k dataset as additional outliers. Finally, we compare against various OOD synthesis methods, including VOS (Du et al. 2022), CIDER (Ming et al. 2023), NPOS (Tao et al. 2023) and DreamOOD (Du et al. 2024).\nE Computational Cost\nWe summarize the computational cost of SONA. For outlier synthesis, generating a total of 200K images takes approximately 8.1 hours. This is significantly less time compared to other outlier-synthesis methods, as our approach does not generate outliers from random noise with full DDIM steps, but rather starts from the original image and stops early. Training a classifier with the generated outliers and an additional OE loss term takes around 5 hours. In comparison, post-hoc methods only require training a multi-class classification model on the ImageNet-200 training dataset, which takes approximately 4 hours. Our experiments"}]}