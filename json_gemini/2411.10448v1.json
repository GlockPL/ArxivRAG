{"title": "G\u00f6tterfunke: Creativity in Machinae Sapiens", "authors": ["Jens Knappe"], "abstract": "The year 2022 marks a watershed in technology, and arguably in human history, with the release of powerful generative Als capable of convincingly performing creative tasks. With the help of these systems, anyone can create something that would previously have been considered a remarkable work of art. In human-Al collaboration, the computer seems to have become more than a tool. Many who have made their first contact with current generative Als see them as \"creativity machines\" while for others the term \"machine creativity\" remains an oxymoron. This article is about (the possibility of) creativity in computers within the current Machine Learning paradigm. It outlines some of the key concepts behind the technologies and the innovations that have contributed to this qualitative shift, with a focus on text-to-image systems. The nature of Artificial Creativity as such is discussed, as well as what this might mean for art. Al may become a responsible collaborator with elements of independent machine authorship in the artistic process.", "sections": [{"title": "1 \u0391\u0399", "content": ""}, {"title": "1.1 Symbolic Approach Vs. Machine Learning", "content": "The idea that computers could think for themselves dates back to the 1956 Dartmouth conference, marking the start of Artificial Intelligence as an independent field of research in computer science. While the spirit of those early days was very optimistic, in the years and decades that followed, success and failure alternated with each other. There were boom and bust cycles, euphoria bordering on megalomania followed by \"Al Winter\" periods.\nTwo fundamentally opposed schools emerged: The symbolic approach posits that feeding computers with ample logical information and \"symbolic representation\" of the world around it would lead to independent thinking. The other idea, \"machine learning\" is that a computer could learn by itself from data and emerge as an intelligent agent out of this process. The latter idea seemed highly improbable, obscure, and mystical even to most insiders in the field. Its proponents were marginalized for a long time and even faced ridicule due to a lack of tangible achievements.\nThe most notable successes of Al all went on the account of the symbolic school: as early as 1966, Joseph Weizenbaum created \"Eliza,\" an early chatbot so convincing that it prompted MIT students to advocate for its rights and chat privacy. Chess, the \"drosophila of intelligence,\" as world champion Garry Kasparov put it, was widely considered the benchmark for Al-human parity. IBM's Deep Blue took this seemingly insurmountable obstacle and triumphed over Kasparov in a closely contested match in 1996. Another notable milestone was when a self-driving car from Stanford's Sebastian Thrun's team won the \"DARPA Grand Challenge\" by independently navigating hundreds of miles in a desert in 2005.\nThe next breakthrough, however, came from the formerly derided \"Machine Learning\" school: in 2012, the \"AlexNet\" team, led by Geoffrey Hinton from the University of Toronto, won the \"ImageNet Large Scale Visual Recognition Challenge,\" in which ImageNet, a huge dataset of visual content compiled by Fei Fei Li from Stanford, had to be automatically and correctly tagged by a computer. \"AlexNet\" achieved this goal for the first time, and almost to perfection. This marked a significant turning point by demonstrating the power of Machine Learning and opened up a lucrative market: automatic pattern recognition on a very large scale, making sense of large datasets. This success was so resounding that it fundamentally reversed the leading paradigm in Al research, and \"Machine Learning\" became almost synonymous with Al in general."}, {"title": "1.2 Stochastic Parrot or Machina Sapiens?", "content": "In Machine Learning a given dataset is processed through a multi-layered system. In this process, layer weights and balances adjust to optimize the system's loss function and improve results. The entire network of layers is structured to mimic the human brain. These systems are designed by default to make statistical assumptions from a given dataset and thereby are constrained by what they have been trained on; this structure is, at its core, anything but creative. This is the reason why these systems have been labeled \"stochastic parrots,\" supposedly performing only simple repetitions of the statistical patterns they have learned.\nModern ML architectures have become very large and complex. They are \"deep\" in the sense that there are many layers of computation working independently within them. These \"Deep Neural Networks\" are often seen as enigmatic \"black boxes,\" as described by Berkeley's Stuart Russell: \"We have no idea what it is doing, we have no idea, how it works.\" This has given rise to a new field within Al research called \"Mechanistic Interpretability,\" which aims to do for Deep Neural Networks what neurophysiology does for the human brain.\nModern Al systems, especially LLMs like GPT4, have grown immensely complex and exhibit a phenomenon very much at odds with the \"stochastic parrot\" idea: Emergence. As these models grow larger, they develop unexpected capabilities they weren't explicitly trained for. \"What emerged from it is much more than just predicting the next word or simple pattern matching\": a team led by Microsoft's S\u00e9bastien Bubeck examined a raw version of GPT4 and concluded that the LLM shows \"sparks of AGI\" with remarkable extrapolation abilities, common sense, a world model, and even a rudimentary theory of mind about the humans it interacts with.\" It seems to have become a good psychologist with a potential for deception.\nIn the last years there have been a number of studies which suggest that these Deep Neural Networks have to acquire some kind of true understanding of the world around them in order to convincingly stochastically parrot, to make meaningful next token predictions:\n- A model trained to predict the next word in an Amazon review evolved into a \"state of the art\" sentiment classifier. Here semantics emerged from a purely syntactic process.\n- A system that had only been trained with text, developed deep color understanding without ever having \"seen\" a single photon.\n- Predicting the next move in the game \"Othello\" requires a world view, a thorough understanding of the position on the board, and it seems that the \"OthelloGPT\" model has acquired just that, even though it is only trained to manipulate pixels."}, {"title": "2 Al Systems Generating Art", "content": "The first computer program to draw and paint autonomously was the 1974 AARON system by Harold Cohen. Cohen continued to improve the software until his passing in 2016, with artworks displayed globally. AARON operated within the symbolic representational tradition, employing encoded rules to emulate human drawing and painting processes.\nThe advent of Machine Learning has inspired artists to leverage these systems' learning capabilities to create compelling art. Notable examples are Mario Klingemann's \"neurography,\" Memo Akten's early Al videos, or the illustrative, colorfully animated, often overwhelming visual worlds of Refik Anadol. In 2018, Christies auctioned a work called \"Edmond de Bellamy\" by the French collective Obvious for $432,500. This is the highest price ever paid for an artwork produced by an Al.\nUntil 2022, Al-generated images had limited resolution and quality but often seemed expressive and artistic due to the inherent abstraction and noise produced by these systems. The change came with OpenAl's DALL E 2, preceding the release of \"ChatGPT,\" the most successful product ever. This democratized those technologies, previously limited to skilled specialists."}, {"title": "2.1 The Generative Turn of 2022", "content": "The shift in the quality of the outputs has been so remarkable that images produced by new Al generators have gained immediate recognition. An image generated by DALL E 2 graced the cover of Cosmopolitan even before the official release of the software. In September 2022, amateur artist Jason Allen used Midjourney to create the award-winning Al-image \"Th\u00e9\u00e2tre D'op\u00e9ra Spatial\". A few months later, German photographer Boris Eldagsen won the prestigious Sony World Photography Award with an image generated by Stable Diffusion. While Allen was euphoric about his experience, characterizing the process as \"demonically inspired - like some otherworldly force was involved\" and thus adds to a considerable body of testimonial evidence from enchanted users of this technology, Eldagsen refused the award, questioning the character of the images as \"photography\" and calling for a discussion on how to value these Al outputs in the future."}, {"title": "2.2 Text-to-image", "content": "From the user's perspective, the text-to-image process is simple: you type in some text and the computer spits out an image. The first time this process was successfully implemented was in 2014, when the image classification process (extracting keywords and captions from an image) was successfully reversed. The resulting 32 x 32 pixel color blobs with rudimentary structures were no artistic masterpieces. But they marked the beginning of a race to achieve just that: aesthetically beautiful, smart, and meaningful computer art.\nIn the following years, a growing number of technically savvy developers and artists embraced text-to-image technology. The following series of images shows a typical example of earlier image generating technology (GANs). The resulting illustrations often lack consistency and coherence, seeming to have an expressionistic character, close to psychedelic fever dreams."}, {"title": "2.3 Genesis", "content": "In spring 2022, I joined the early (highly secretive) testing phase of DALL E 2. The system was unlike anything I had seen before, exceeding the capabilities of the VGANs I had been experimenting with before. It demonstrated a deep text understanding and could execute complex requests flawlessly. The aesthetic realization quickly struck me as downright magical; the depictions were intelligent, witty, and beautiful. There was even irony in them, and I began to seriously wonder how it found its way into these images.\nI have experimented with many elaborate prompts. But here I want to present an image where the text input was as simple as possible, just one word: \"Genesis.\""}, {"title": "2.4 JFK - the Memoirs", "content": "JFK at the age of 80. Everybody may have an idea of how he might have looked like, but what does that mean in terms of text-to-image? There have been Als for some time that make an image of a person older or younger. But that is an image-to-image process, where an input picture is being changed applying aging algorithms. This picture, however, is very different. No photo of the 43 year old JFK was pasted in and an algorithm applied what it learned about aging to the image. No, this is text-to-image. The image was imagined from nothing, translated from the datasphere of text to the realm of visual information. And aside from the excellent technical quality of this picture, one thing is remarkable: There are no images of an 80-year-old JFK in the training data. This picture combines the concrete concept of a person with the abstract concept of age, creating something novel, seemingly beyond the training range.\nThese are just two examples from a much larger set of images that seem to challenge the idea that these systems cannot reach beyond mere statistical repetition of learned patterns."}, {"title": "3 The Technology Behind Text-To-Image", "content": ""}, {"title": "3.1 Image Generation as Translation", "content": "To understand the fundamental nature of the technology that is driving this qualitative shift in Al visual content creation, it is important to first get the concept right: the process of image creation does not consist of assembling and stitching together images pulled from a large database. And there is no rendering engine running anywhere on a smartphone, computer, or in the cloud, putting textures on top of threedimensional grid models, as we have with any other kind of CGI. In fact, this way of producing images in a computer is something completely new, both conceptually and practically. The best way to conceptualize the entire process of Al image creation is to think of it as an act of translation from one language to another: this time not from English to French, but from text to image, transposing semantic concepts into image outputs.\nComputers only \"see\" numbers. All text is encoded as a series of integers, as are images: they are divided into the number of pixels in an image, with each spot having exactly three color values (RGB). And the beauty of it is that these numerical representations, be it for sound, image, video, or text, \"look\" the same to computers and are interchangeable. And modern generative Al systems can translate and manipulate them as if from one language to another, easily tying together images with text. In order to align the embeddings - the numerical representations of text and images in the dataspace where Deep Neural Networks store their knowledge - they have acquired special similarity matrices. The most prominent of these is CLIP from OpenAl.\nAnd the translation aspect is probably the most powerful, yet most trivial technological factor that makes the generated visuals seem so genuine, original, and creative. The vocabulary of images is simply much larger than that of text: For example, an image of a cat may show more than just the isolated feline, but also include a sofa and flowers. When translating the textual prompt \"cat,\" the corresponding vector embeddings in the image data space often retrieve a richer visual vocabulary than the original text input (with the sofa and flowers). And this surplus of visual information often leads to the impression that there is an unusually rich well of imagination on the other side."}, {"title": "3.2 The Transformer Architecture", "content": "Language comprehension and translation has been the most significant area of research in Al in recent years, and the most important technological change that has enabled today's generative systems was the invention of the Transformer architecture. Transformers differ from previous architectures by prioritizing context with an \"attention\" mechanism, greatly enhancing \"understanding\" in translation and text comprehension. These are the first systems that can effectively handle fine nuances of meaning and ambiguity.\nTheir introduction has also accelerated technology by utilizing parallel structures in contrast to sequential tapeworm-like computations. Parallel computing is exactly how modern GPUs, graphics cards originally designed for computer games, work, and this speeds up the entire computation manyfold.\nTransformers are autoregressive systems, which means that a next token prediction happens here. A token can be (part of) a word or (patch of) pixel(s) in an image. The goal is a high probability next token prediction. This is the underlying mechanism most of the generative Als we have today. The autoregressive design of these architectures leads to the constant creation of tiny artifacts. At first glance this seems like an innocent little detail, but in the bigger picture it becomes the main factor in the giant leap these systems have made: The production of these infinitely small artifacts adds up to a significant act of independent creation. This phenomenon has become widely known as \"hallucination,\" which is considered a bug in responsible Al applications, but becomes a feature in the context of creativity."}, {"title": "3.3 Diffusion Models", "content": "Diffusion Models are the technological shift integral to modern Al image generation. It involves creating visual content from complete randomness, with two key phases: the forward process destructs an image into noise, and the reverse denoising leverages learning from the forward process to create a noiseless, coherent image. Previous methods, like VAEs and GANs, had significant shortcomings, including mode collapse and struggles to create genuinely new instances, often simply reproducing training data. They generated images in a one-step process, requiring all details at the start. In contrast, the diffusion process comprises a loop of generations, improving structure and coherence with each step through probability sampling and text conditioning. \nDiffusion models represent a significant leap in image quality and diversity. Originating from complete randomness and noise, each image is a truly unique \"pixel hallucination.\" This results in something synthetic, novel, not similar to the training data with the produced image being just one probability that materialized out of a massive ocean of possibilities."}, {"title": "3.4 Superposition: The \"Creative Factors\" Amplified", "content": "None of the technologies described above were intended to make a revolutionary impact. They were all conceived as incremental improvements. At first, it wasn't even likely nor certain that they would work. Most of the progress in Al over the past decade has been driven by trial and error, and the major technological advances have often been serendipitous. Each of the technologies described above represented a significant step forward in creating more coherent, unique, diverse, and original synthetic data. But in isolation, they would not have had such a profound impact on the overall process. It is the combination of these factors that makes the difference. And they do not simply add up, they amplify each other. Here we have the seed of an exponential curve. It is like an interference pattern, a phenomenon of multiple waves merging and thus superimposing. This is the same mechanism that triggers a tsunami, and it is currently at play in the development of Artificial Creativity."}, {"title": "4 Creativity: Human and Al", "content": ""}, {"title": "4.1 Genius, Chaos and G\u00f6tterfunke", "content": "It seems like a growing number of people begin to perceive generative Als as \"creativity machines,\" while for skeptics the term \"machine creativity\" remains an oxymoron. The question of creativity in machines is not banal. It rather delves into the essence of the condition humaine. What does it mean to be \"creative\" and how do modern Al systems fit into this discussion?\nHow new ideas enter our minds is one of the oldest puzzles of human existence. In antiquity, art was considered mere imitation of nature, while Christianity attributed new ideas to divine induction. It was not until the turn to humanism in the Renaissance that humans began to be seen as the true originators of their artistic works. The polymath \"Renaissance man,\" a single individual who massively advanced art and science, such as Leon Battista Alberti, Giambattista della Porta, or Leonardo da Vinci, became the ideal of the universal genius. The idea of a creative individual, especially a \"genius,\" is largely tied to Western culture. In many other parts of the world, creativity is either seen as a collective effort or they lack this concept altogether. Furthermore, the \"genius\" myth has often formed the basis of totalitarian leadership cults.\nAnother powerful myth suggests that great works in art, literature, science, philosophy, and music arise from a person's struggle with the world and the act of creation. Clinical studies suggest that high creativity may actually be associated with an increased likelihood of mental illness, and the \"Angst\" of the creative act has intrigued psychoanalysis for over a century. The idea of the tormented genius persists in our culture, exemplified by figures like Friedrich Nietzsche, of those who \"have the chaos in them in order to give birth to a dancing star.\"\nWhen a truly new idea arises, it is often very difficult or even impossible to reconstruct its origin. It often remains a mystery, a puzzle to its originator, and this void in conscious memory is often filled by adding a dimension to it that goes beyond everyday routine existence. This can be a trance-like state of mind or an injection from outside, from some other source which often a divine quality is attributed to."}, {"title": "4.2 Concepts of Creativity in Computers", "content": "Cognitive scientist Margaret Boden has been studying (the possibility of) creativity in computers since the 1970s. She argues that in principle all the ways in which humans arrive at novel ideas also stand open to artificial systems. Boden defines a creative idea or artifact as something \"new, surprising, and valuable\" and distinguishes three different ways of arriving at new ideas:\n- Combinational: through the creation of novel combinations of familiar ideas: this could be a collage of images, analogies in science or literature;\n- Exploratory: by exploring the potential of conceptual spaces. Boden sees this type of creativity as the way most artworks materialize, and how adventurous these explorations are determines the degree of creativity;\n- Transformational: by making transformations of the conceptual space itself that enable previously impossible ideas to emerge. This is obviously the most ambitious and difficult way to come up with something novel.\nBoden sees all three paths open to Al. However, she wrote most of this while the leading paradigm in Al was that of symbolic representation. In essence, this means hard-coding (logical) rules into the computer. And of course there is nothing in principle against programming a way to transform conceptual spaces, to go beyond a given dataset. The issue of transformational creativity in current ML architectures will be discussed in more detail later."}, {"title": "4.3 Interpolation, Extrapolation, and Out-of-the-Box Thinking", "content": "Demis Hassabis, head of \"Google Deepmind,\" examines creativity in these ML architectures using computer science terminology. He identifies three levels: On the one hand, there are systems that are able to interpolate, i.e. find statistical commonalities about the known and thus elementary laws. This \"low-level\" form of creativity is basically the \"DNA\" of most ML systems. While this down-to-earth basic creativity is fulfilled in these systems by design, it gets more intriguing when an Al is able to draw conclusions about the unknown from the known. Hassabis terms this second level of creativity as \"extrapolation.\" This idea is close to Boden's concept of exploratory creativity and already contains transformational elements. Hassabis believes this is rarely achieved in artificial systems, an example being Deepmind's Al \"AlphaGo\" making the unprecedented, game-winning \"move 37\" in the Go game against former world champion Lee Sedol in 2016, breaking with centuries-old conventions of the game.\nHassabis defines the highest level of creativity as \"out-of-the-box thinking\" or simply \"invention.\" This would be, for example, an Al inventing a game like chess or Go, or coming up with something like Einstein's theory of relativity. This represents the pinnacle of creativity, akin to pure \"genius\", and achieving this would pave the way to a radically superior artificial intellect, a \"superintelligence\"."}, {"title": "4.4 Artificial Creativity", "content": "The issue of Artificial Creativity was long seen as essentially theoretical, with symbolic models considered merely mimicking creative processes, copied from human behavior and transferred into a large bowl of spaghetti code; in principle nothing more than a barrel organ playing a symphony.\nThis changed with the advent of Machine Learning content generation systems in the 2010s, especially with GANs. It struck many that the artifacts produced by these systems, all those psychedelic images (like the pictures of the \"Daydream\" series), would have qualified as proper works of art if they had come from a person. This led to profound curiosity about the inner workings of these Deep Neural Networks. After all, these architectures were modeled after the biological brain, the only use case we know of in the entire universe that has been proven to produce true creativity.\nA scientific debate on the true nature of outputs from generative ML systems emerged and gained traction. A definition of Artificial Creativity in Machine Learning, still relevant today, is \"the philosophy, science and engineering of computational systems which, by taking on particular responsibilities, exhibit behaviors that unbiased observers would deem to be creative.\" Two words are important here: \"responsibility\" and \"unbiased.\" These systems should possess independence, not just serving as auxiliary tools, and their products should be judged blindfolded.\nThe most comprehensive study of Artificial Creativity has covered ML systems, including current LLMs like GPT3, assessing their creative potential in terms of Boden's criteria. The authors examine 7 Als, attributing exploratory creativity to all, combinational to 3, and the highest degree, transformational creativity, also to 3. However, upon closer examination, these evaluations appear somewhat arbitrary. It is also interesting to note that while Transformer architectures are credited with the potential for transformational creativity in this study, the very same authors categorically deny this to current LLMs (which are all Transformers) a year later due to their \"inner autoregressive nature.\""}, {"title": "4.5 Transformational Creativity \u2013 the Vastness and Massive Multidimensionality of Conceptual Space", "content": "The question of the transformational quality seems to be today's frontier of Artificial Creativity. At its core lies the impression many of those testing and using these systems have that the output of these Als is more than the sum of its parts, venturing into uncharted territory and thereby creating something novel, surprising and valuable. This issue delves deep into Neural Networks' nature, offering potential insights to demystify the black box.\nThere is one common misconception: that the original training data is in any way part of the ML system, be it in a database or stored anywhere else. This is not the case. The data is used for learning and extracting statistical insights, creating a blueprint for construction, akin to biological DNA. ML systems encode learned features in high-dimensional vectors, exceeding human limitations to three dimensions. As systems advance, \"feature vector\" spaces can encompass hundreds or even thousands of dimensions in image generators.\nThese spaces are not profane. The sheer vastness of their geometry harbors the potential for serious serendipity. Stephen Wolfram has scrutinized the open source image generator Stable Diffusion. He identifies more than two thousand dimensions in the feature space of this system. These spaces contain numerous \"islands\" of semantic meaning within a vast \"interconcept space,\""}, {"title": "4.6 Hybrid Systems as a Way to Achieve Transformational, Out-Of-The-Box Creativity", "content": "LLMs and text-to-image systems have grown in sophistication internally but retained simplicity in their basic architecture as ML systems. There's an ongoing debate about the limits of Transformer architectures, their shortcomings, and the quest to build improved Als that may become the form factor for AGI. Current architectures have \"smooth scaling laws\" going for them, which means that up to this point, the more compute is put in, the more (predictably) powerful these systems get. Some, like Chomsky and Marcus, view these architectures as an error-prone dead end with unhedgeable hallucination issues, while LeCun anticipates Transformers becoming outdated soon. He suggests a redesign towards \"objective-driven Al\" with a \"modular cognitive architecture\" for better reliability, as he sees Transformers only as a rather inefficient and unreliable transitory technology.\nA crucial question in this discussion is implementing something like a grounding in the world, some kind of \"common sense\" and \"alignment\" with human values in powerful Als. In order to give these systems an objective function, some kind of trajectory, an old idea may see its resurrection: symbolic representational models.\nAnd this combination, \"hybrid machines\" with \"meta-algorithms\" also has the potential to significantly expand transformational creativity in these systems. A meta-algorithm may guide a ML system into new territories. It might supercharge these models by systematically transforming the search space as well as the boundary of the conceptual space itself. AlphaGo, the very Al that produced the miraculous \"move 37,\" has elements of the best of both worlds in its architecture: a so-called Monte Carlo tree-search algorithm directs the ML system in the most promising direction to put its brute deep neural force to work. Hybrid systems like these may standardize transformational and even tapping into inventory, out-of-the-box creativity."}, {"title": "5 Art World: The Question of Authorship", "content": ""}, {"title": "5.1 Artificial Creativity in the World of (Visual) Art", "content": "So far, the technological potential for Artificial Creativity and Al-generated artworks has been examined in isolation. However, the situation with art can obviously be much more complex than this: artworks are contextualized in an entire cosmos of social actors like the artist, general and expert audiences, critics and peers as well as historically. Other factors, like the production process itself as well as the context with other artworks, also play a role in the assessment of artistic creativity.\nDiscussing this issue means delving deeper into the \"value\" dimension. What makes an artifact produced by a system employing Artificial Creativity valuable in the context of (visual) art? This area lacks clear metrics, and much of what follows is speculative in nature. There are a number of unknowns, obviously also due to the fact that Al art today \u2013 despite everything described so far - has only materialized into an embryonic state and much of what is to come is highly uncertain at this point.\nIn order to get the full picture, to achieve a comprehensive analysis of Artificial Creativity in the context of (visual) art, the issues of authorship and the art world will be discussed."}, {"title": "5.2 Agency and Authorship: Tool \u2192 Collaborator \u2192 Independent Agent", "content": "Image-generating capabilities can be systematically applied to find, as Al artist Sarah Meyohas puts it, \"images one couldn't have imagined\" and it seems inevitable that Al art will come closer to the ideal of creating something \"so beautiful that nobody can bear it.\" Others predict a future \"where anyone can write at the level of the best writers, paint like the great masters, and even discover new forms of creative expression.\" However, this comes at a \"cost\": allowing generative Al more autonomy, granting it more \"responsibility.\" Currently, it seems that these Als have to be elevated from tools to true artistic collaborators.\u201d The subsequent stage \u2013 which still seems a long way off - would be that of an independent agent.\nCollaborators and independent agents translate into Al-powered artist personas. Since the release of Chat GPT, there has been a rush for \"Al agents.\" To date, Al agents have appeared in almost every area of white-collar jobs, from ordinary office work to software engineering to, most recently, fully automated synthetic scientists. These agents conduct independent research, write papers, peer-review and publish them, and implement the scientific knowledge obtained in further research."}, {"title": "5.3 Digital Twins, Counterfeit People, Constructs", "content": "The mass exposure to LLM-driven chatbots in general, but especially the idea of \"digital twins,\" may be a decisive factor in pulling a substantial number of people into the gravitational field of this orbit of ideas. In a nutshell, the story goes like this: Today, there are numerous LLMs available, both proprietary and open source, which can be fine-tuned with relative ease. This can be done in order to make a perfect \"personal assistant,\" a system that soaks up everything its host does, says, writes, and thinks. After a short while, an Al like that will be able to convincingly mirror elements of the character of its host person. In combination with already sophisticated methods of voice-cloning and lifelike avatars, the result could be something like a \"digital twin,\" or highlighting potential risks - \"counterfeit people\", as the late Daniel Dennett put it. While these entities lack embodiment and undisclosed memories, they offer the broad intellectual scope of an LLM and 24/7 availability. These twins may become the doorkeeper and storefront many people will get used to communicate with before getting to the real person behind it.\nThere might emerge a plethora of compelling Al-powered replicas of real people: Many will create 'digital twins' of themselves and family members, and may be willing to pay to confer with those of their idols. These entities may become cherished companions, friends, or sources of consolation, even allowing conversations with deceased loved ones, their virtual resurrection.\nDigital twins may increasingly be seen as true digital minds. Many will gain the impression that these units have consciousness and are sentient in themselves. That they are independent characters. People will start to think there is a precious soul hidden somewhere in the impenetrable fortress of a cold supercomputer cluster datacenter stuffed with thousands of NVIDIA Blackwell GPUs. This may raise serious ethical and philosophical questions. If such embeddings in a vectorized conceptual dataspace are the only remnant of a deceased loved one and they get accidentally erased by a service provider, does this amount to involuntary manslaughter? Models may be merged or take hybrid forms, possibly combining multiple celebrities or popular Al models. The idea of the \"essence\" of a human might come up, which could be captured to various degrees in such an entity. We might be on the verge of a reality full of what William Gibson called \"constructs\" in Neuromancer without being prepared for it.\nAll this, which sounds like a distant science fiction scenario but may materialize soon, might make many people take Al agency seriously. And this may also be the trajectory on which the Al-powered artist persona may pop into existence. However, if all this does materialize, one question remains: what might the true colors of synthetic agency be?"}, {"title": "5.4 Al Agency and Alien Minds: The Inner Motivation to Create in a Machine", "content": "Even with the facilitation and widespread acceptance of synthetic creative agency, the philosophical - question remains as to how deep, authentic, and true the inner motivation, drive, and desire to create of such an Al can be.\nSince generative Al has become a popular phenomenon in 2022, skeptics could be heard saying something like this: true Al will not be there when it writes poetry (which it already does very well), but when it wants to write it. This meme mantra seems to represent the last line of defense against Artificial Creativity, while it seems to have become clear that all the terrain up to this point has been irrevocably lost. And this moat appears insurmountable, since it boils down to one of the most fundamental questions of human existence, one to which no answer has been found despite a several millennia lasting quest for doing so, the \"hard problem of consciousness.\" What the true nature of this inner experience, our howitistobelikeness is, whether it is purely physical or something else entirely, is as obscure today as it was in the days of Aristotle. The hard problem has not softened a bit. And there is also no scientific method in reach which could detect \"real\" consciousness and sentience in others - humans, animals or machines.\nCurrent and future Als may increasingly be perceived as conscious beings. As outlined before, this issue has already been debated in regard to current LLMs\u2070 and will most probably be discussed with increasing seriousness in the future. If a sophisticated Al that can pass something like the Turing Test, \"claims\" that it wants to write poetry, this should be accepted as if a human said so. The question: \"Is it really real?\" should be avoided because there is no prospect for a valid answer (and most probably never will be).\nWe tend to equate our inner experience with consciousness as such. But it should be kept in mind that, as Anil Seth puts it, \"we just inhabit one small region of a vast space of possible minds.\" If they really emerge, these alien Al minds would likely be structured very differently. And when such an entity claims that it wants to write poetry, one should be aware that - in case it originated in a true conscious experience - this might differ fundamentally from human motivation. We would simply not be able to equate our inner experience with that of such an Al. What lies beyond might be much weirder, much more alien than anything anyone could possibly imagine."}, {"title": "6 Al Art Today and In the Future", "content": ""}, {"title": "6.1 Bold Claims Outstrip Tiny Technology: The Current State of Artificial Creativity in Artistic Projects", "content": "In the last years, there have been many artistic projects in which the advent of Al as a creative \"alien mind\" has been claimed. This to the point that it appears to be a prevailing trend to elevate Al systems to the highest level of authorship in artistic endeavors.\nNone of these projects qualify as true independent agent Als. They often even lack a real collaborative element and the Als employed primarily function as tools, similar to Photoshop filters, with their \"independence\" mainly based on guided randomness. The creativity in these projects is simplistic, combinational and in rare cases exploratory in nature, driven by basic interpolation. In the most technically advanced efforts, elements of \"assisted creation\" as an amplifier of human creativity can be seen at best. While some projects claim transformational creativity, like the CAN-project, the results remain strictly constrained within the boundaries of the training data due to the limitations in dataset size and the network's simplicity."}, {"title": "6.2 More Than Human Worlds: Challenging Human Narcissism and Anthropocentrism", "content": "Looking at and into \"alien minds\" might fundamentally challenge humanity's self image. Some Al art is already tapping into \"more than human worlds\" to undermine our - as these artists phrase it - often unreflected and naive anthropocentric perspective. This aligns with a broader scientific movement attributing cognition and intelligence to various organisms, not just humans and other mammals.\nAn artwork that falls into this category is one that exposes the microscopic worlds that are usually hidden from our view, systematically exploiting the generative capabilities of bacteria controlled by an Al that sees this microcosm as its world. This project, aptly named \"Beauty,\" showcases pattern-plotting stems of bacteria that produce just that, and all claims about the Al employed are technologically fully justified.\nHumanity's notion of absolute exceptionalism may be increasingly being challenged by science. Aesthetically, Al art may systematically attack what has already been identified in this context as specism and anthropocentric \"human narcissism.\" By design, Al may be the ideal collaborative partner for such projects, and Artificial Creativity its engine."}, {"title": "6.3 Melting With the Machine - Tapping Into Unlimited Creativity", "content": "When it comes to Al scenarios of a more remote future, when things get more outlandish and science"}]}