{"title": "REPRESENTATIVE ARM IDENTIFICATION: A FIXED CONFIDENCE APPROACH TO IDENTIFY CLUSTER REPRESENTATIVES", "authors": ["Sarvesh Gharat", "Aniket Yadav", "Nikhil Karamchandani", "Jayakrishnan Nair"], "abstract": "We study the representative arm identification (RAI) problem in the multi-armed bandits (MAB) framework, wherein we have a collection of arms, each associated with an unknown reward distribution. An underlying instance is defined by a partitioning of the arms into clusters of predefined sizes, such that for any j > i, all arms in cluster i have a larger mean reward than those in cluster j. The goal in RAI is to reliably identify a certain prespecified number of arms from each cluster, while using as few arm pulls as possible. The RAI problem covers as special cases several well-studied MAB problems such as identifying the best arm or any M out of the top K, as well as both full and coarse ranking. We start by providing an instance-dependent lower bound on the sample complexity of any feasible algorithm for this setting. We then propose two algorithms, based on the idea of confidence intervals, and provide high probability upper bounds on their sample complexity, which orderwise match the lower bound. Finally, we do an empirical comparison of both algorithms along with an LUCB-type alternative on both synthetic and real-world datasets, and demonstrate the superior performance of our proposed schemes in most cases.", "sections": [{"title": "1 Introduction", "content": "The stochastic multi-armed bandit (MAB) problem [1] is a widely studied online decision-making framework, which consists of K arms each associated with an a priori unknown reward distribution. Each pull of an arm results in a random reward, generated i.i.d. from the associated distribution. At each round, the learner can decide which arm to pull based on the entire history of pulls and rewards. The MAB framework has found application in a wide variety of domains ranging from A/B testing [2] and online advertising [3] to network routing [4], clinical testing [5], and hyperparameter optimization [6] in machine learning.\nThere are several objectives that a learner might be interested in while interacting with the MAB. For example, one widely studied goal is to maximize the expected cumulative reward accrued by the learner over a certain time horizon, or equivalently to minimize the regret with respect to an oracle which knows the arm reward distributions beforehand. Several regret minimization algorithms have been proposed in the literature [7, 8], and they are typically based on the idea of balancing exploration (trying different arms to reduce uncertainty about their mean rewards) and exploitation (pulling the arms known to have high rewards).\nAnother popular learning objective is identifying the best arm in terms of the mean reward [9, 10]. The problem has been studied in both the fixed confidence setting [10], where the goal is to find the best arm using the minimum number of pulls while guaranteeing a certain pre-specified error probability d; and the fixed budget setting [11] where the total"}, {"title": "2 Problem Formulation", "content": "We consider a stochastic multi-armed bandit with a collection N of N = |N| arms, each associated with a \u03c3-subGaussian reward distribution\u00b2, which is a priori unknown to the learner.\nTo define the representative arm identification (RAI) problem, we sort the arms in decreasing order of their mean rewards and then partition them into m clusters of predefined sizes given by c = (C1, C2,..., cm), such that for any j > i, all arms in cluster i have a larger mean reward than those in cluster j. Clearly, $\\sum_{i=1}^m C_i = N$.\nWe label the arms as follows: for each $i \\in [m] := \\{1,2,...,m\\}$ and $j \\in [c_i] := \\{1,2,...,c_i\\}$, we have an associated reward distribution $II_{i,j}$ with the j-th arm in cluster i, so that each pull of the arm results in an i.i.d. reward sample from $II_{i,j}$. The corresponding mean reward is denoted by $\\mu_{i,j}$, and we have that $\\mu_{i_1}^{j_1} \\geq \\mu_{i_2}^{j_2}$ for any $i_1 \\neq i_2, j_1 \\neq j_2$ such that $\\mu_{i_1}^{j_1} = \\mu_{i_2}^{j_2}$."}, {"title": "3 Lower Bound", "content": "In this section, we derive a lower bound on the sample complexity of any \u03b4-PC algorithm for the RAI problem. To state the result, we first need a few definitions.\nDefinition 1. (Arm Gap): Consider an instance $I = (c, r, II)$; recall that $\\mu_{i,j}$ denotes the mean reward of the jth arm in cluster i. The arm gap $\u0394_{i,j}$ for that arm is defined as\n$\u0394_{i,j} := min\\{\\mu_{i,j} - \\mu_{i-1,r_{i-1}}, \\mu_{i,j} - \\mu_{i,j+1}\\} \\forall j \\in c_i, i \\in [m].$\nHere, for notational simplicity, we have assumed two dummy clusters, 0 and m + 1, having one arm each, such that $\\mu_{0,1} = \\infty$, $\\mu_{m+1,1} = -\\infty$.\nDefinition 2. (Bottleneck Gap): Consider an instance $I = (c, r, II)$. For each cluster $i \\in [m]$, let $\u0394_i$ denote the ri-th largest arm gap amongst its arms. By convention, $\u0394_i = \\infty$ if $r_i = 0$. The bottleneck gap $\u25b3_I$ associated with the instance I is defined as\n$\u25b3_I := min\\{\u0394_1, \u0394_2,\u2026\u2026, \u0394_m\\}.$\nIntuitively, $\u0394_i$ captures the complexity associated with the sub-task of identifying ri arms from cluster i, while $\u25b3_I$ captures the complexity associated with the complete RAI task; the smaller these gaps, the harder the corresponding task. This is formalized in the following theorem.\nTheorem 1. For a given error threshold $\u03b4 \u2208 (0, 1)$, in the space of \u03c3-Gaussian instances (i.e., each arm has a Gaussian reward distribution with standard deviation \u03c3), any \u03b4-PC algorithm A for the RAI problem satisfies\n$\\underset{\u03b4 \\to 0}{lim inf} \\frac{E[T_I(A)]}{log(1/\u03b4)} > \\frac{1}{2(\u0394_I)^2}.$\nWe conclude this section by specializing the lower bound in Theorem 1 to the task of identifying M out of the top K arms, where 1 < M < K < N (this special case of the RAI problem was analysed in [16]). Without loss of generality, suppose that the arms are also labelled 1,2,..., N such that the corresponding mean rewards satisfy $\\mu_1 \\geq \\mu_2 \\geq\u2026\u2026\\geq \\mu_N$. Then it is easy to show that the bottleneck gap for this task is given by $\u25b3_I = \\mu_M - \\mu_{K+1}$.\nTo the best of our knowledge, such an explicit, interpretable, instance-dependent complexity characterization is not available in the literature for this task."}, {"title": "4 Algorithms", "content": "This section describes the two algorithms we propose to solve the RAI problem and presents upper bounds on their sample complexity. In spirit, these algorithms are similar to the successive elimination style schemes which are widely used for MAB problems [10]. Under both algorithms, active arms are pulled in a round robin fashion, and suitable confidence intervals are maintained for the mean reward of each active arm. From time to time, arms whose membership in a certain cluster can be inferred based on the computed confidence intervals are 'selected' to be part of the algorithm output; these selected arms are then removed from the active set. The two algorithms differ with respect to the scheduling of the membership check-the Vanilla Round Robin Algorithm performs this check after each round robin cycle, whereas the Butterscotch Round Robin Algorithm performs the membership check only on each halving of the confidence interval widths.\nVanilla Round Robin Algorithm for RAI\nThe Vanilla Round Robin Algorithm is stated formally as Algorithm 1. This algorithm proceeds in rounds; each round involves the following steps:\n\u2022 The algorithm samples every arm in its active set A once (line 4); this is the set of arms whose cluster membership is not yet confirmed.\n\u2022 The arms in A are then partitioned into tentative clusters of sizes $\\tilde{c}_1,\\cdots, \\tilde{c}_m$ based on their empirical mean rewards (line 6); here, $\\tilde{c}_i$ is the (estimated) number of active arms from cluster i (more formally, $\\tilde{c}_i = c_i - |O_i|$, where Oi denotes the set of representative arms that have been identified by the algorithm as being from cluster i by that point).\n\u2022 Next, for each arm a in the active set, a check is made to see whether its cluster assignment, say i, can be finalised. This entails checking whether the confidence intervals indicate arm a as being \u2018better' than $\\sum_{j>i} \\tilde{c}_i$ active arms, and \u2018worse' than $\\sum_{j<i} \\tilde{c}_i$ active arms (line 11). If this holds, arm a is assigned to cluster i (if additional representatives are required from cluster i), and it is removed from the active set.\n\u2022 Finally, we merge adjacent clusters whose requirement for representative arms has been met (lines 19-22). Such a merger relaxes the membership check for the merged cluster (note that the algorithm does not need to output any arms from the merged cluster), hastening the removal of its members from the active set. Empirically, we find that this final step results in significantly fewer arm pulls by the algorithm, as we demonstrate in Section 5.\nOf course, the algorithm terminates when the requisite number of representatives have been identified from each cluster. The following result establishes that the Vanilla Round Robin Algorithm is \u03b4-PC, and also provides an instance-dependent high probability upper bound on the sample complexity of the algorithm.\nTheorem 2. The Vanilla Round Robin Algorithm (see Algorithm 1) is \u03b4-PC for the RAI problem. With probability at least 1 \u2212 \u03b4, its sample complexity $T_I$ satisfies\n$T_I \\leq \\sum_{i=1}^m \\sum_{j=1}^{c_i} 1\\{\u0394_{i,j} > \u0394_I\\} \\frac{16\u03c0^2}{\\(\u0394_{i,j}\\)^2} ln\\frac{N^2\u03c0}{3\u03b4}+1\\{\u0394_{i,j} < \u0394_I\\} \\frac{16\u03c0\u03bb}{\\(\u0394_{I}\\)^2} ln\\frac{N\u03c02}{3\u03b4}+1.$\nButterscotch Round Robin Algorithm for RAI\nNext, we discuss the Butterscotch Round Robin Algorithm, stated formally as Algorithm 2. The key difference from the Vanilla Algorithm discussed before is that the arm pulls are conducted in batches (line 5). Specifically, in round R, each arm in the active set A is pulled $t_R - t_{R-1}$ times, where the value of $t_R$ is chosen (line 2) so that the confidence interval for the mean reward of each arm in A is of size x $2^{-R}$. This is reflected in the confidence-interval based cluster membership check conducted in line 10. The rest of Algorithm 2 proceeds in essentially the same way as Algorithm 1.\nTheorem 3. The Butterscotch Round Robin Algorithm (see Algorithm 2) is \u03b4-PC for the RAI problem. With probability at least 1 \u2212 \u03b4, its sample complexity $T_I$ satisfies\n$T_I \\leq \\sum_{i=1}^m \\sum_{j=1}^{c_i} 1\\{\u0394_{i,j} > \u0394_I\\} max\\{\\frac{32}{\\(\u0394_{i,j}\\)^2} ln\\frac{\u039d\u03c02}{3\u03b4}, log_2(\\frac{1}{2\u0394_{i,j}}\\) \\}, + 1\\{\u0394_{i,j} < \u0394_I\\} 128 ln\\frac{\u039d\u03c02}{3\u03b4}.$"}, {"title": "5 Numerical Case Studies", "content": "In this section, we conduct an empirical evaluation of Algorithms 1 and 2 using both synthetic and real-world datasets. In addition, we also consider a suitably tailored version of LUCB-style sampling [12], which has been widely used in the multi-armed bandit literature and offers a sequential sampling strategy as opposed to the parallel nature of the successive elimination style strategies. In each round, the LUCB algorithm considers every empirical cluster for which the arms requirement hasn't yet been fulfilled and then based on the current confidence intervals of the mean estimates, selects from each cluster an arm (together with the 'boundary' arms of the neighboring clusters) whose membership is most likely to be confirmed with the additional pull; further details along with a proof that the proposed variant is \u03b4-PC are provided in Appendix B. For our simulations, we assume the reward distribution to be Bernoulli[0, 1], a member of the 1/2 SubGaussian distribution family. Finally, we set the error probability \u03b4 = .01 and present sample complexity results which are averaged over 100 independent runs of the corresponding algorithms.\nWe first examine an instance with 10 arms divided into clusters of sizes 3,5, and 2, respectively. The true means for this instance are given by: [0.9, 0.85, 0.7, 0.66, 0.65, 0.6, 0.4, 0.35, 0.2, 0.15]. Table 2 presents the average sample complexity of the three algorithms for various special cases of the RAI problem.\nWe observe that in almost all the cases, the Vanilla and Butterscotch schemes perform better than the LUCB-based algorithm. Intuitively, this is because the LUCB algorithm inherently targets sequential membership identification of arms which can lead to many unnecessary pulls for the boundary arms especially when the number of required arms is higher. Secondly, between the Vanilla and Butterscotch algorithms, the former performs better in Problems 1, 3, 5 while the latter is superior for Problems 2, 4. Problems 1, 3, 5 turn out to be simpler problems that require only one round of the Butterscotch scheme (which is why the sample complexity is also the same for all three problems), while the Vanilla algorithm requires even fewer since it can stop at any time and does not have a batch constraint.\nBoth Algorithms 1 and 2 employ adaptive merging of clusters when the representative arm requirement for neighboring clusters is found to be already satisfied. To demonstrate the benefit of this feature, we conduct an empirical comparison of both algorithms with their corresponding non-merging versions"}, {"title": "6 Conclusion", "content": "We have proposed the representative arm identification (RAI) problem which generalizes several well studied problems in multi-armed bandits, including best arm identification, identifying M out of the top K arms, and coarse ranking. We provided a lower bound on the sample complexity of any reliable scheme and also proposed two algorithms based on the idea of confidence intervals. Upper bounds on the sample complexity of these algorithms were presented and their empirical performance was demonstrated over synthetic and real-world datasets.\nSome questions remain open and several directions can be pursued in the future:\n1. While Theorem 1 presents an instance-dependent and interpretable lower bound on the sample complexity of the RAI problem, it is in general loose. On the other hand, [17] provides a lower bound on problems with multiple correct answers (which includes the RAI problem) which can in general be tighter, but the bound is in the form of an optimization problem and is hard to compare against. Deriving a tighter lower bound which is still interpretable in terms of the problem parameters is a key open problem and can provide insights into multiple problems of interest given the many special cases that RAI covers.\n2. Federated RAI: In this version of the problem, we have multiple clients, each having its own mean reward vector corresponding to the arms. Each client aims to solve its own local RAI problem, while a server which can communicate with the clients (at some cost) might be interested in solving a global RAI problem. A preliminary study of the problem indicates that a carefully crafted combination of the two algorithms proposed in this work can be used to solve the federated RAI problem, while ensuring low communication cost."}, {"title": "A Proof of Theorems", "content": "Before proceeding with the proofs, let us state the necessary concentration inequality used in proving Theorem 2 and Theorem 3\nLemma 1. Let $X_1, X_2, \u2026\u2026\u2026, X_R \\in \u03c3$-SubGaussian be independent and identical random variables. Than for the empirical mean $\\bar{\\mu}(R) = \\sum_{i=1}^R X_i /R$ we have\n$P(|\\bar{\\mu}(R) - \\mu| \\geq \\epsilon_R) \\leq 2 exp(-2R\\epsilon_k)$\nProof of Lemma 1. From Hoeffdings inequality for any $\u03c3^2$-SubGaussian random variable, we have\n$P(|\\bar{\\mu}(R) - \\mu| > \\epsilon_R) \\leq 2 exp(-\\frac{R\\epsilon_R^2}{2\u03c3^2}) (1)$\nOn substituting \u03c3 = \u00bd in Equation 1, for any-SubGaussian random variable, we get\n$P(|\\bar{\\mu}(R) - \\mu| \\geq \\epsilon_R) \\leq 2 exp(-2R\\epsilon_k) (2)$\nA.1 Proof of Theorem 1\nThe proof of the lower bound on expected sample complexity starts from recognizing that the RAI problem fits in the 'multiple correct answers' framework of [17] and thus the general lower bound derived there applies to the RAI problem as well. However, that lower bound is in the form of a min min max optimization problem and the rest of the proof involves simplifying it to obtain an interpretable form.\nTo state the lower bound in [17], we have to introduce some additional notation. Consider an RAI problem instance I = (c, r, II), where the arm reward distributions are Gaussian with standard deviation 1/2 and the mean reward vector is given by $\u00b5 := \\{\u00b5_{i,j}\\}$, where $\u00b5_{i,j}$ is the mean reward for arm j from cluster i under the current instance. Let $i^*[\u00b5]$ denote the set of all correct answers when the reward distributions are specified by \u00b5. Note that each such correct answer corresponds to a set of arms such that $r_1$ of them belong to cluster 1, $r_2$ of them belong to cluster 2 and so on. Next, for any correct answer $a \u2208 i^*[\u00b5]$, we need the notion of an alternate mean reward vector \u03bb such that a is not a correct answer when the underlying arm reward distributions are Gaussian with standard deviation 1/2 and the mean reward vector is \u03bb = \\{\u03bb_{i,j}\\}$. We will denote the collection of all such alternate mean reward vectors by \u00aca. Finally, let $A_K$ denote the K-dimensional simplex and $d(a, b)$ denote the Kullback-Leibler (KL) divergence between two Gaussian distributions with means a and b, and variance 1/2 each. Note that $d(a, b) = 2(a - b)^2$.\nNext, from [17, Theorem 1], we have the following lower bound on the expected sample complexity of any \u03b4-\u0420\u0421 algorithm for an RAI problem $I = (c, r, II)$, where the arm reward distributions are Gaussian with variance 1/2 and the mean reward vector is given by $\u00b5 := \\{\u00b5_{i,j}\\}$:\n$ \\underset{\u03b4 \\to 0}{lim inf} \\frac{E[T_I(A)]}{log(1/\u03b4)} > D(I)^{-1} (3)$\nwhere $D(I) = \\underset{\u03b1\u2208i^*[\u00b5]}{max} \\underset{\\omega \u2208 \u0394_N}{max} \\underset{\u03bb\u2208\u00ac\u03b1}{inf} \\sum_{i=1}^m \\sum_{j=1}^{c_i} \u03c9_{i,j}d(\u00b5_{i,j}, \u03bb_{i,j}).$\nNow, we will derive an upper bound on D(I), which will yield the lower bound in the expression of Theorem 1. Consider any given correct answer $a \u2208 i^*[\u00b5]$. Then, a particular alternate mean reward vector \u03bb \u2208 \u00aca, can be constructed by shifting the mean reward for any one arm included in a, say arm k, so that its cluster membership is changed, and keeping all other mean rewards the same; see Figure 3 for an illustration. In particular, the minimum shift needed to do so is given by the arm gap for arm k, as defined in Definition 1. Amongst all the arms included in a, we will choose the one, say $b_\u03b1$, which requires the smallest change in mean reward to result in an alternate mean reward vector, i.e., for which the set of arms a is no longer a correct answer. Denote the corresponding change in the mean reward of arm $b_\u03b1$ by $l_\u03b1$. Then we have\n$D(I) = \\underset{\u03b1\u2208i^*[\u00b5]}{max} \\underset{\\omega \u2208 \u0394_N}{max} \\underset{\u03bb\u2208\u00ac\u03b1}{inf} \\sum_{i=1}^m \\sum_{j=1}^{c_i} \u03c9_{i,j}d(\u00b5_{i,j}, \u03bb_{i,j})$\n$\u2264 \\underset{\u03b1\u2208i^*[\u00b5]}{max} \\underset{\\omega \u2208 \u0394_N}{max} \u03c9_{b_\u03b1}2l_\u03b1^2$\n$= \\underset{\u03b1\u2208i^*[\u00b5]}{max} 2l_\u03b1^2$"}, {"title": "A.2 Proof of Theorem 2", "content": "The proof of this theorem is organized as follows. First, we define a good event \u03c8. Based on this condition, we then demonstrate the correctness of Claims 1 and 2.\n$\u2193 \u2266 \\{\u2200R \u2208 Z, \u2200i \u2208 [m], \u2200j \u2208 [c_i], |\\tilde{\u00b5}_{i,j}(R) - \u00b5_{i,j}| \u2264 \\sqrt{\\frac{1\u03b7 (\u03c0^2 R^2N/3\u03b4)}{2R}}\\} (4)$\nClaim 1. Under A = Alg1, let $\\tilde{\u00b5}_{i,j}^{}(R)$ be the empirical mean of arm j from cluster i at round R. Let \u03c8 be the event defined in 4. Than the $P_I(\u03c8) \u2265 1 \u2212 \u03b4$\nProof of Claim 1. By the union bound, we have\n$P_I(\u03c8^c) \u2264 \\sum_{R=1}^\\infty \\sum_{i=1}^m \\sum_{j=1}^{c_i} P(|\\tilde{\u00b5}_{i,j}(R) - \u00b5_{i,j}| > \\sqrt{\\frac{1\u03b7 (\u03c0^2 R^2N/3\u03b4)}{2R}}) (5)$\nFrom Equation 2 and 5, we have\n$P_I(\u03c8^c) \u2264 \\sum_{R=1}^\\infty \\sum_{i=1}^m \\sum_{j=1}^{c_i} \\frac{6\u03b4}{\\pi^2 R^2N} (6)$\n$< \\sum_{R=1}^\\infty \\frac{6\u03b4}{\\pi^2 R^2} (7)$\n$\u2264 \u03b4 (8)$"}, {"title": "A.3 Proof of Theorem 3:", "content": "The proof of Theorem 3, follows a similar approach to that of Appendix A.2. We start with defining the good event, conditioned on which the rest of the proof follows.\n$\u2193 \u2266 \\{\u2200R \u2208 Z,\u2200i \u2208 [m], \u2200j \u2208 [c_i], |\\tilde{\u00b5}_{i,j}(R) - \u00b5_{i,j}| \u2264 2^{-(R+3)}\\} (15)$\nClaim 3. Under A = Alg2, let $\\tilde{\u00b5}_{i,j}$ be the empirical mean of arm j from cluster i after $t_R$ pulls, where $t_R$ is defined in the line 2 of the Alg2. Given & be the good event defined in 15, we have $P_I(\u03c8) \u2265 1 \u2212 \u0431$\nProof of Claim 3. From union bounding, we have\n$P_I(\u03c8^c) \u2264 \\sum_{R=1}^\\infty \\sum_{i=1}^m \\sum_{j=1}^{c_i} P[|\\tilde{\u00b5}_{i,j}(R) - \u00b5_{i,j}| > \\frac{\u2206}{8}] (16)$\nNow, on using the equations 2 and 16, and from line 2 of the Algorithm 2, we have"}, {"title": "B LUCB", "content": "The LUCB version for the representative identification problem is inspired from [12] and is stated in Algorithm 3. In this algorithm, we have an intelligent sampling rule following a pull strategy based on the LCB and UCB of the arms. We start this section, by defining the upper and lower confidence bounds."}]}