{"title": "Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis", "authors": ["Mary Ogbuka Kenneth", "Foaad Khosmood", "Abbas Edalat"], "abstract": "Humour styles can have either a negative or a positive impact on well-being. Given the importance of these styles to mental health, significant research has been conducted on their automatic identification. However, the automated machine learning models used for this purpose are black boxes, making their prediction decisions opaque. Clarity and transparency are vital in the field of mental health. This paper presents an explainable AI (XAI) framework for understanding humour style classification, building upon previous work in computational humour analysis. Using the best-performing single model (ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to analyse how linguistic, emotional, and semantic features contribute to humour style classification decisions. Our analysis reveals distinct patterns in how different humour styles are characterised and misclassified, with particular emphasis on the challenges in distinguishing affiliative humour from other styles. Through detailed examination of feature importance, error patterns, and misclassification cases, we identify key factors influencing model decisions, including emotional ambiguity, context misinterpretation, and target identification. The framework demonstrates significant utility in understanding model behaviour, achieving interpretable insights into the complex interplay of features that define different humour styles. Our findings contribute to both the theoretical understanding of computational humour analysis and practical applications in mental health, content moderation, and digital humanities research.", "sections": [{"title": "1 Introduction", "content": "Humour is the tendency to experience or provoke laughter or provide amusement through written or spoken words (Sen, 2012). It plays a vital role in interpersonal interactions, emotional expression (Amjad and Dasti, 2022), and psychological well-being (Chen and Martin, 2007; Edalat, 2023; Martin and Ford, 2018; Martin et al., 2003). Different humour styles\u2014self-enhancing, self-deprecating, affiliative, and aggressive\u2014carry distinct emotional undertones and social implications (Kuiper et al., 2016; Martin et al., 2003). While affiliative humour fosters positive social interactions, aggressive humour may strain relationships through its potential to offend or demean (Anderson and Di Tunnariello, 2016). Understanding these styles has significant implications across multiple domains, including mental health (Edalat et al., 2024; Martin and Ford, 2018; Martin et al., 2003), content moderation (Sari, 2016; Zhu et al., 2022), and artificial intelligence (AI) (Kenneth et al., 2024; Kenneth Ogbuka et al., 2024). However, computational humour style recognition presents unique challenges in natural language processing (NLP) due to its subjective nature and complex psychological underpinnings (Amjad and Dasti, 2022; Kazienko et al., 2023; Kenneth et al., 2024). Even though recent developments have been effective in categorising various humour styles, these models' decision-making procedures remain mainly unknown. Understanding how and why machine learning models categorise various humour styles is crucial for advancing both computational linguistics and digital humanities research (Cortinas-Lorenzo and Lacey, 2024).\nRecent work by Kenneth Ogbuka et al. (2024) established baseline performance for humour style classification across four categories: self-enhancing, self-deprecating, affiliative, and aggressive humour. Their two-model approach achieved promising results, particularly with the General Text Embeddings Upgraded (ALI) + XGBoost for the single model configuration and the Multilingual E5 Text Embeddings (MUL) + XGBoost + ALI+XGBoost for the two-model configuration. However, the interpretability of these classifications\u2014understanding which features and patterns drive the model's decisions\u2014remains an open challenge.\nExplainable AI (XAI) has emerged as a solution to address the opacity of traditional ML models by providing insights into their decision-making processes Lyu et al. (2024). Through techniques such as Local Interpretable Model-Agnostic Explanations (LIME) Ribeiro et al. (2016) and Shapley Additive Explanations (SHAP) Lundberg and Lee (2017), XAI enables researchers to identify key features driving predictions. This interpretability is especially crucial for recognising humour styles, as the interaction of linguistic patterns, emotional tones, and semantic nuances necessitates a thorough comprehension. For instance, identifying features such as sarcasm, sentiment contrasts, or emotions can provide more detailed information about why a certain text is categorised as affiliative or self-deprecating.\nThis paper extends the work of Kenneth Ogbuka et al. (2024) by introducing an XAI framework for humour style classification. By applying XAI to the best-performing single model (ALI+XGBoost) reported in their research, we provide detailed interpretability that highlights the influence of linguistic and emotional features on model predictions. This approach not only makes the classification of humour styles more transparent, but it also gives researchers practical insights that allow them to further investigate the role of humour in communication and psychological well-being.\nThe primary contributions of this paper are as follows:\n1. Development of a comprehensive XAI framework tailored to humour style recog-"}, {"title": "2 Related Works", "content": "The development of explainable approaches to computational humour analysis converges three research streams: general XAI methodologies for text classification, interpretable humour analysis models, and explainable style classification approaches. This section examines these areas' contributions to computational humour recognition interpretability, progressing from foundational XAI methods to specific style-based classifications."}, {"title": "2.1 General XAI Methods for Text Classification", "content": "Recent advances in XAI for text classification demonstrate varied approaches to model interpretability. P\u00e9rez-Landa et al. (2021) combined emotional, sentiment, syntactic, and lexical features for xenophobic content detection, achieving F1-scores of 76.8% and 73.4% on different datasets. Although their keyword-based pattern matching may face generalisation challenges, their success with emotion and sentiment features informs our approach to humour style explanation.\nChowdhury et al. (2021) applied LIME to explain black-box sentiment analysis models, achieving 72% accuracy with Long Short-Term Memory (LSTM) networks and FastText embeddings. Their implementation revealed word-level contributions to sentiment predictions through probability scores and contextual relationships, demonstrating LIME's effectiveness for deep learning interpretability.\nAhmed et al. (2022) integrated attention mechanisms with fuzzy logic rules for interpretable sentiment analysis, achieving 89% F1-score. Their dual-layer approach combined local explanations with global interpretability through attention weights and fuzzy rules. While effective for mental health applications, questions remain about adapting such hybrid systems for subjective tasks like humour classification, where decision boundaries may be less clearly defined.\nIn humour-adjacent tasks, Ortega-Bueno et al. (2022) employed attention mechanisms for irony detection in Spanish, demonstrating that different attention types focus on distinct linguistic features. However, their approach prioritised performance over explainability, underscoring the need for XAI methods that consider both linguistic feature utilisation and cross-cultural variations."}, {"title": "2.2 Interpretable Models for Humour Analysis", "content": "Early interpretable humour analysis focused on transparent feature development. Zhang et al. (2017) proposed interpretable features for humour recognition: contextual knowledge (modelling semantic relationships), affective polarity (quantify-"}, {"title": "2.3 Explainable Approaches to Style Classification", "content": "Style classification has evolved from binary to multi-class approaches. Abulaish and Kamal (2018) developed a two-layer system for self-deprecating sarcasm detection (94% F1-score), using explicit linguistic rules and feature-based classification. Despite its success in binary classification, their work underscored the need for more advanced explainability to handle multiple humour styles. Kamal and Abulaish (2020) expanded this work with three explicit feature categories (self-deprecating patterns, exaggeration markers, and word embeddings) for self-deprecating humour detection, achieving F1-scores of 62%-87% across datasets.\nKenneth Ogbuka et al. (2024) introduced a dataset and a two-model approach for humour style classification, targeting four styles (self-deprecating, self-enhancing, affiliative, aggressive) and non-humour. They addressed challenges in distinguishing affiliative and aggressive humour by using a four-class classification followed by binary discrimination, achieving a 78.6% F1-score with improved differentiation. However, their work left unanswered questions about misclassification reasons between styles\u2014a gap our XAI framework seeks to fill.\nWhile significant progress has been made in humour classification and XAI techniques, two significant gaps persist: most interpretable approaches focus on binary rather than style-specific classification, and current style-specific approaches lack comprehensive explanatory frameworks for linguistic and emotional feature interaction."}, {"title": "3 Methodology", "content": "This study develops an XAI framework to analyse humour style classification by examining model predictions, linguistic features, and emotional patterns. Our methodology comprises three main components: dataset and model selection, prediction analysis using LIME, and comprehensive feature analysis across linguistic, affective, and contrast patterns."}, {"title": "3.1 Dataset and Classification Model", "content": "This study utilises the dataset and ALI+XGBoost model from Kenneth Ogbuka et al. (2024), which achieved 77.8% accuracy and 77.3% F1-score. The dataset comprises 1,463 instances gathered from multiple sources:\n\u2022 983 jokes from different websites (Reader's Digest, Parade, Bored Panda, Laugh Factory, Pun Me, Independent, Cracked, Reddit, Tastefully Offensive, and BuzzFeed), labelled based on original website tags and humour theory.\n\u2022 280 non-humorous text instances from the ColBERT dataset (Annamoradnejad and Zoghi, 2020)"}, {"title": "3.2 Model Prediction Analysis", "content": "We employ LIME (Local Interpretable Model-agnostic Explanations) due to its advantages for word embedding-based classification (Ribeiro et al., 2016). LIME provides word-level interpretability through local explanations while maintaining model-agnostic analysis and computational efficiency. Our analysis progresses through:\n1. Individual prediction explanation using LIME\n2. Feature importance extraction from XGBoost\n3. LIME result visualization\n4. Analysis of confidence score across humour styles"}, {"title": "3.3 Feature Analysis", "content": "We categorise the patterns extracted to explain the classification model into three groups: linguistic patterns, affective patterns, and contrast patterns. Our analysis leverages multiple feature detection algorithms, each with different capabilities and limitations."}, {"title": "3.3.1 Linguistic Patterns", "content": "Linguistic patterns capture the language elements that contribute to humour's comedic effect. These patterns manipulate structure, context, and style to create humorous situations (Kenneth et al., 2024). The key linguistic patterns analysed include:\nSound Patterns Sound patterns exploit auditory features of language, such as rhyme, alliteration, and homophony.\n\u2022 Rhyme: The repetition of similar sounds at the ends of words. Examples include sight and flight, sad and mad, cat and hat. In our analysis, we used the \u201cpronouncing\" library with the CMU Pronouncing Dictionary to detect rhymes. Although the dictionary effectively covers standard English pronunciations, it may not capture slang or neologisms present in the dataset. For instance, out of the 4,506 unique words in the dataset, 90.75% (4,089 words) were found in the CMU Pronouncing Dictionary. Unmatched examples include: \u2018launchalot', \u2018aronofskys', \u2018500000', 'ahappy', 'admited', \u2018kanye', 'houseplant', 'idk', \u2018behaviours'"}, {"title": "3.3.2 Affective Patterns", "content": "Affective patterns relate to feelings, moods, and attitudes, as defined by the Collins English Dictionary. In humour style analysis, these patterns help distinguish whether a statement is humorous, sarcastic, or offensive (Kenneth et al., 2024). Key affective patterns analysed include:\nSarcasm : Sarcasm detection was performed using a RoBERTa-based model trained for sarcasm identification, achieving 60.7% accuracy. The model provides binary classification (sarcastic/non-sarcastic) and probability scores, capturing subtle verbal irony often found in specific humour styles.\nSentiment : Sentiment analysis employed a multi-layered approach using RoBERTa (93.2% average accuracy) (Hartmann et al., 2023) and TextBlob models to assess:\n\u2022 Dominant sentiment (positive, negative, neutral) with confidence scores\n\u2022 Sentiment strength measured through positive-negative score differential\n\u2022 Polarity (-1 to 1) indicating sentiment direction and intensity\n\u2022 Subjectivity and objectivity metrics to gauge emotional content\nEmotion : Emotional content was analysed using a DistilBERT-based model that classifies text into six discrete emotion categories (joy, anger, sadness, fear, love, and surprise) with an accuracy of 93.8% and F1-score of 93.79%. This fine-grained emotional analysis reveals distinctive affective patterns across different humour styles."}, {"title": "3.3.3 Contrast Patterns", "content": "Our analysis of contrast patterns focuses on semantic and sentiment-based contradictions that generate humorous effects through the following components:\nSentiment Contrasts : We examined opposing emotional valences at two distinct levels:\n\u2022 Sentence-level contrasts: Sequential sentences were analysed for opposing sentiment polarities, capturing dramatic shifts in emotional tone.\n\u2022 Word-level contrasts: Content words (adjectives, adverbs, verbs, and nouns) were evaluated using SentiWordNet to identify internal sentiment conflicts within sentences.\nSemantic Elements : We investigated semantic relationships and conflicts through:\n\u2022 Exaggeration markers: Systematic identification of absolute terms and extreme descriptors that amplify narrative elements.\n\u2022 Intensification patterns: Analysis of linguistic intensifiers that heighten semantic impact.\n\u2022 Semantic incongruity: Quantification of conceptual contradictions using WordNet similarity metrics to identify semantically distant word pairs.\nHaving established our methodological framework and feature detection capabilities, we now turn to the analysis of our results and their implications for humour style classification."}, {"title": "4 Results and Discussion", "content": "This section presents analysis of the ALI+XGBoost model's performance in humour style classification, followed by detailed examination of linguistic mechanisms and error patterns. We first evaluate the model's classification metrics and confidence scores across different humour styles, then analyse the distinctive linguistic features characterising each style, and finally examine misclassification patterns to understand the model's limitations."}, {"title": "4.1 Model Performance Analysis", "content": "The performance analysis of the ALI+XGBoost model highlights distinct patterns in classification accuracy and confidence across different humour styles. The model achieved an overall accuracy of 78% and a macro-average F1-score of 77%, with style-specific variations:\n\u2022 Self-enhancing humour exhibited the highest precision (0.82) and F1-score (0.83).\n\u2022 Neutral content attained the highest recall (0.93) and a strong F1-score (0.85).\n\u2022 Affiliative humour had the lowest recall (0.58), underscoring challenges in identifying this style."}, {"title": "4.2 Linguistic Mechanism Analysis", "content": "Analysis of linguistic mechanisms revealed distinct patterns across humour styles, as summarised in Table 2. We examined four key dimensions: syllabic complexity, semantic conflicts, homonym usage, and exaggeration patterns."}, {"title": "4.2.1 Syllable Complexity", "content": "Neutral content exhibited significantly higher syllabic complexity (mean: 1.355, SD: 0.245), suggesting more formal or sophisticated language use. In contrast, aggressive humour demonstrated the lowest complexity (mean: 1.148, SD: 0.118), indicating a preference for simpler, more direct language. Other humour styles showed intermediate complexity levels, with self-enhancing (mean: 1.206) and self-deprecating (mean: 1.192) humour showing similar patterns."}, {"title": "4.2.2 Semantic and Structural Elements", "content": "Affiliative humour exhibited the highest frequency of semantic conflicts (mean: 29.755, SD: 114.755), significantly surpassing other styles. This suggests frequent use of wordplay and unexpected combinations. Self-deprecating humour followed with a mean of 18.717 (SD: 47.830). In contrast, neutral and self-enhancing content demonstrated markedly lower frequencies of semantic conflicts (mean: 7.025, SD: 7.347, and mean: 7.557, SD: 7.274, respectively).\nHomonym usage patterns revealed significant differences between humorous and neutral content. Social forms of humour\u2014affiliative and aggressive\u2014showed the highest homonym frequencies (mean = 6.796, SD = 4.743 and mean = 6.667, SD = 3.772, respectively), while neutral content demonstrated significantly lower usage (mean = 2.662, SD = 1.987). This indicates that wordplay involving multiple word meanings is a common feature across humour styles."}, {"title": "4.2.3 Rhetorical Devices", "content": "Exaggeration patterns varied significantly across styles. Self-deprecating humour exhibited the highest frequency of exaggeration (mean = 1.848, SD = 1.738), followed by aggressive humour (mean = 1.456, SD = 1.593). Neutral and self-enhancing content showed significantly lower exaggeration frequencies (mean = 0.738, SD = 0.853 and mean = 0.885, SD = 0.950, respectively)."}, {"title": "4.2.4 Mechanism Correlations and Interactions", "content": "Analysis of correlations between linguistic mechanisms revealed complex interaction patterns in humour construction (Table 3). We observed a hierarchy of associations ranging from strong correlations to weak or negligible relationships.\nPrimary Correlations The strongest association was identified between semantic conflicts and rhyme (r = 0.95), indicating substantial co-occurrence of these mechanisms in humorous content. This relationship suggests that rhyming elements may systematically contribute to the creation of semantic conflicts, potentially enhancing humorous effects through structural-semantic interactions.\nWordplay Networks Homonyms demonstrated significant correlations with multiple linguistic features, forming a network of moderate-strength associations. These included correlations with semantic conflicts (r = 0.66), rhyme (r = 0.61), and exaggeration (r = 0.58). The strength and consistency of these correlations suggest that multiple-meaning words may function as central anchoring elements in humour construction, facilitating the integration of various linguistic devices.\nIndependent Mechanisms Several mechanisms demonstrated operational independence. Self-referential content exhibited consistently weak correlations with other features (0.06 \u2264 r \u2264 0.28), suggesting it functions largely autonomously in humour construction. Similarly, alliteration showed minimal correlation with other mechanisms (r < 0.21 across all comparisons), indicating its role as an independent supplementary device rather than a core component of humour construction.\nPun-Related Patterns Pun usage demonstrated selective associations, showing moderate correlations with sound-based features including rhyme (r = 0.29) and homonyms (r = 0.28). However, correlations with other mechanisms were notably weaker (r < 0.20). This pattern suggests that while puns integrate sound patterns and multiple meanings, they operate through relatively distinct linguistic pathways in humour generation.\nThese correlation patterns reveal a hierarchical structure in humour construction, where certain mechanisms (particularly rhyme and semantic conflicts) demonstrate strong interdependence, while others (such as alliteration and self-reference) function"}, {"title": "4.3 Affective and Emotional Patterns", "content": "Examination of affective patterns revealed distinct emotional signatures and sentiment characteristics across humour styles, providing insights into their underlying psychological mechanisms."}, {"title": "4.3.1 Distribution of Primary Emotions", "content": "Table 4 presents the frequency distribution of primary emotions across different humour styles. Each style demonstrated characteristic patterns in emotional expression."}, {"title": "4.3.2 Style-Specific Emotional Patterns", "content": "Self-Enhancing Humour : Self-enhancing humour demonstrated a clear predominance of joy (n = 30) compared to other emotions, combined with positive sentiment polarity (0.227) and the highest classification confidence (0.889) among all styles.\nAggressive Humour : This showed the highest frequency of anger (n = 28) among all styles, with negative sentiment polarity (-0.039). The presence of joy-related content (n = 13) suggests complex emotional dynamics within this style.\nSelf-Deprecating Humour Analysis revealed that self-deprecating humour maintained the most balanced emotional distribution, with no significant differences between positive and negative emotion frequencies. The distribution showed comparable levels of joy (n = 15, 32.6%), anger (n = 14, 30.4%), and sadness (n = 11, 23.9%), with near-neutral sentiment polarity (mean = -0.002, SD = 0.098).\nAffiliative Humour : Affiliative humour demonstrated a relatively even distribution between anger (18) and joy (16), with positive overall polarity (0.145), suggesting its role in social bonding through shared emotional experiences.\nNeutral Content : Neutral content exhibited high frequencies of both joy (n = 39, 48.8%) and anger (n = 34, 42.5%), while maintaining significantly lower subjectivity scores (mean = 0.273, SD = 0.089) compared to all humour styles."}, {"title": "4.3.3 Sentiment and Confidence Patterns", "content": "Table 5 presents the distribution of confidence scores and affective metrics across humour styles. Analysis revealed systematic variations in sentiment characteristics and classification confidence across different styles.\nSentiment Polarity : Analysis revealed a clear demarcation in sentiment polarity across styles. Self-enhancing and affiliative humour maintained positive polarity (0.227 and 0.145 respectively), while aggressive humour exhibited negative polarity (-0.039). Self-deprecating humour demonstrated near-neutral polarity (-0.002), suggesting balanced emotional content. Neutral content showed mild positive polarity (0.089), positioned between the extremes of other styles.\nSubjectivity Patterns : Subjectivity analysis revealed distinct patterns across styles. Self-deprecating humour exhibited the highest subjectivity (0.474), indicating strong emotional investment in content. Conversely, neutral content showed markedly lower subjectivity (0.273), consistent with its more objective nature. Affiliative and aggressive styles showed comparable subjectivity levels (0.406 and 0.404 respectively).\nClassification Confidence : Model confidence demonstrated systematic variation across styles. Self-enhancing humour and neutral content showed the highest confidence scores (0.889 and 0.887 respectively), suggesting more distinctive linguistic and emotional patterns. Affiliative humour exhibited the lowest confidence (0.748), indicating greater classification uncertainty for this style.\nSarcasm Distribution : Sarcasm presence varied substantially across styles, with neutral content showing the highest frequency (48.8% of instances) and self-deprecating humour the lowest (8.7%). This distribution suggests that sarcasm may serve different functions across humour styles, potentially contributing to style differentiation.\nThese patterns indicate that humour styles employ distinct emotional mechanisms and linguistic strategies. Self-enhancing and affiliative styles maintain predominantly positive emotional valence, while aggressive and self-deprecating styles demonstrate more complex emotional patterns. The variation in subjectivity and sarcasm levels further differentiates these styles, with self-deprecating humour showing heightened emotional investment and neutral content maintaining greater objectivity. While these patterns reveal distinct characteristics of different humour styles, the classification process faces several challenges, which we examine in detail in the following section on error analysis."}, {"title": "4.4 Error Analysis and Misclassification Patterns", "content": "Systematic analysis of classification errors revealed distinct patterns in model behaviour, with a predominant challenge in affiliative humour classification. This finding aligns with previously identified performance limitations in the single-model approach (Kenneth Ogbuka et al., 2024)."}, {"title": "4.4.1 Primary Misclassification Categories", "content": "Analysis of error patterns revealed three dominant misclassification types, each characterised by distinct feature combinations:\nAffiliative-Neutral Confusion (n = 8) These misclassifications demonstrated moderate classification confidence (mean = 0.649) with distinctive sentiment characteristics: elevated polarity (0.197) combined with reduced subjectivity (0.296). Notably, these cases exhibited minimal semantic conflicts (mean = 9.500), suggesting potential oversimplification of humorous content.\nAffiliative-Self-enhancing Confusion (n = 8) Cases in this category showed moderate confidence levels (mean = 0.709) with mild positive sentiment polarity (0.094). A distinguishing feature was the elevated presence of exaggeration (mean = 1.375), indicating potential confusion between social and self-directed humour mechanisms.\nAffiliative-Aggressive Confusion (n = 7) These cases exhibited the lowest confidence scores (M = 0.611) and negative sentiment polarity (-0.037). The high semantic conflict count (M = 29.857) suggests that complex linguistic structures may contribute to classification ambiguity."}, {"title": "4.4.2 Feature-Specific Error Analysis", "content": "Analysis of classification errors revealed systematic patterns across multiple dimensions, as detailed in Table 6.\nConfidence Patterns : Model confidence demonstrated significant variation across error types (p < 0.0001), with distinct patterns emerging:\n\u2022 Affiliative-aggressive misclassifications exhibited the lowest confidence (mean = 0.611, SD = 0.179).\n\u2022 Self-deprecating misclassifications showed unexpectedly high confidence (mean = 0.811, SD = 0.160).\nSentiment Characteristics Sentiment analysis revealed significant associations between misclassification types and polarity patterns (p = 0.0001):\n\u2022 Affiliative humour misclassified as aggressive showed negative polarity (-0.037), deviating from typical affiliative patterns.\n\u2022 Self-deprecating humour misclassified as affiliative exhibited unexpected positive sentiment (0.403).\n\u2022 Subjectivity scores varied systematically with error types, particularly in cases involving self-deprecating humour."}, {"title": "4.4.3 Analysis of Representative Misclassifications", "content": "Detailed examination of misclassified instances revealed systematic patterns in classification errors. We selected eight representative cases (two from each humour style) to illustrate key error patterns, focusing on cases with the most distinctive feature combinations.\nAffiliative Humour Misclassifications\n1. Error Type: Affiliative misclassified as Self-deprecating:\n\u2022 Joke: \"As best man, it is my job to tell you about the groom, and all the embarrassing things that have happened to him in the 28 years leading up to what was the happiest day of his life until I started this speech\"\n\u2022 confidence score: 0.447\n\u2022 Top features: \"embarrassing\": 0.30, \"my\": 0.17, \"groom\": -0.17, \"i\": 0.12, \"28\": -0.10\n\u2022 Linguistic features: High semantic conflict count (40), self-reference count (2 instances)\n\u2022 Affective Profile: Sarcasm probability (false), negative sentiment (0.989 confidence), subjectivity (0.3), emotion (sadness - 0.932 confidence)\n\u2022 Target: self-targeted: true, other-targeted: true, situation-targeted: false\n\u2022 Analysis: The model focusing on the word \"embarrassing\" and personal references \"my\", and the strong negative sentiment and emotion, high semantic conflict in the sentence triggered self-deprecating classification despite the social bonding context typical of wedding speeches.\n2. Error Type: Affiliative misclassified as Aggressive:\n\u2022 Joke: \"What did one DNA say to the other DNA? these genes make me look fat\"\n\u2022 confidence score: 0.781\n\u2022 Top features: \"me\": 0.05, \"say\": -0.03, \"genes\": -0.03, \"one\": -0.02, \"did\": -0.02\n\u2022 Linguistic features: semantic conflicts (19), self-reference count (1)\n\u2022 Affective Profile: Sarcasm probability (0.999), negative sentiment (0.99 confidence), subjectivity (0.375), emotion (joy - 0.865 confidence)\n\u2022 Target: self-targeted: true, other-targeted: false, situation-targeted: false\n\u2022 Analysis: The model's high confidence (0.781) in the aggressive classification appears driven by the sentence's sarcastic nature, negative sentiment, and Wwround \"genes/jeans\" that could be interpreted as mockery.\nAggressive Humour Misclassifications\n1. Error Type: Aggressive misclassified as Affiliative:\n\u2022 Joke: After every sentence I say you say ketchup and rubber buns. what did you eat for breakfast? \"ketchup & rubber buns.\" what did you eat for lunch? \"ketchup & rubber buns.\" what did you eat for dinner? \"ketchup & rubber buns.\" what do you do when you see a hot girl? \"ketchup & rubber buns.\" YOU WHERE RUBBING MY GF'S WHAT?!?!"}, {"title": "5 Conclusion and Future Work", "content": "This study introduces a comprehensive XAI framework for understanding humour style classification, revealing significant patterns in how linguistic mechanisms and emotional features interact across humour styles. Social forms of humour, particularly affiliative and aggressive styles, demonstrate higher rates of wordplay and semantic conflicts. The emotional signatures vary markedly between styles, with self-enhancing humour showing consistently positive polarity (0.227) and high confidence (0.889), while aggressive humour tends toward negative polarity (-0.039). Our correlation analysis reveals strong relationships between linguistic mechanisms, notably between semantic conflicts and rhyme (r = 0.95), indicating how multiple features work together to create humorous effects.\nThe classification challenges highlight important considerations for future development. The model shows varying confidence levels across styles, particularly struggling with affiliative humour (lowest average confidence: 0.748). These challenges often stem from emotional ambiguity and context misinterpretation, especially when multiple humour mechanisms interact. Self-reference and target identification emerged as critical factors in classification decisions, suggesting their importance for future model development.\nThe practical implications of our findings extend beyond theoretical understanding. Our framework provides actionable insights for researchers studying humour's role in psychological well-being and social communication, while offering a valuable template for applying XAI to other subjective classification tasks in digital humanities. The framework's ability to explain model decisions enhances transparency and trust in automated humour analysis, supporting applications in mental health assessment, content moderation, and digital humanities research.\nDespite the valuable insights provided by this study, several important limitations must be acknowledged. Our analysis focuses on a single model configuration (ALI+XGBoost) with a dataset of 1,463 English-language instances, which inherently limits the generalisability of our findings. The feature detection components faced significant technical constraints, particularly in terms of dictionary coverage and algorithmic accuracy. The CMU Pronouncing Dictionary covered 90.75% of unique words in our dataset for rhyme detection, while WordNet synset coverage reached 88.50% of the vocabulary, leaving notable gaps in handling slang and neologisms. The alliteration detector showed particular limitations, such as considering only the first phoneme, leading to false positives like grouping words beginning with different sounds (e.g., \"when\"/\"one\"); counting repeated words as alliteration, and grouping words regardless of their proximity in the text. This contributed to a moderate correlation (r = 0.21) with homonym detection, which is partially due to overlapping feature detection rather than true linguistic relationships.\nA significant methodological constraint lies in our reliance on pre-trained models for sarcasm (60.7% accuracy), sentiment (93.2% accuracy), and emotion detection (93.8% accuracy), not specifically trained on humorous content. Humorous text contains unique linguistic patterns, irony, and complex emotional layers that may not be well-captured by these general-purpose models. The binary classification of features, such as sarcasm detection, oversimplifies complex linguistic phenomena that exist on a spectrum. Additionally, automated sentiment and emotion detection may not fully capture the subtle, often contradictory emotional cues present in different humour styles, like simultaneous positive and negative emotions in self-deprecating humour.\nSeveral analytical constraints affect our findings. The study does not address temporal or contextual variations in humour interpretation, and the analysis of misclassifications may not capture all possible error patterns due to the limited sample size. Future research should expand to multiple models and larger, more diverse datasets, incorporating cross-cultural perspectives and multilingual analysis. Enhanced feature detection algorithms are needed, particularly for complex linguistic features like multi-word puns and contextual wordplay, along with better handling of informal language. The development of specialised models trained specifically on humorous content would improve the accuracy of sentiment and emotion detection in comedic contexts. Additionally, more refined methods for capturing contextual and cultural factors would enhance the framework's applicability across different contexts, while integration of temporal analysis would provide deeper insights into how humour interpretation varies over time and across different social settings. These improvements would strengthen the framework's reliability and broaden its applicability in real-world scenarios."}]}