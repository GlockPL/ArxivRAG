{"title": "Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery", "authors": ["Karl-Philippe Beaudet", "Alexandros Karargyris", "Sidaty El Hadramy", "St\u00e9phane Cotin", "Jean-Paul Mazellier", "Nicolas Padoy", "Juan Verde"], "abstract": "While laparoscopic liver resection is less prone to complications and maintains patient outcomes compared to traditional open surgery, its complexity hinders widespread adoption due to challenges in representing the liver's internal structure. Laparoscopic intraoperative ultrasound offers efficient, cost-effective and radiation-free guidance. Our objective is to aid physicians in identifying internal liver structures using laparoscopic intraoperative ultrasound. We propose a patient-specific approach using preoperative 3D ultrasound liver volume to train a deep learning model for real-time identification of portal tree and branch structures. Our personalized AI model, validated on ex vivo swine livers, achieved superior precision (0.95) and recall (0.93) compared to surgeons, laying groundwork for precise vessel identification in ultrasound-based liver resection. Its adaptability and potential clinical impact promise to advance surgical interventions and improve patient care.", "sections": [{"title": "1 Introduction", "content": "Primary liver cancer ranks seventh globally among all cancer types, representing 8.2% of cancer-related deaths in 2018 [1]. Liver resection remains the primary potentially curative method, with laparoscopic surgery showing promise in reducing postoperative complications [6]. However, challenges persist, including the risk of unintended damage to intrahepatic vascular structures [2]. Intraoperative ultrasound (IOUS) has emerged as a valuable tool for guiding surgery, particularly in assessing tumor margins and avoiding vascular damage [3,8]. However, IOUS faces challenges such as restricted workspace and the need for multiple exchanges between instruments and the ultrasound probe [7]. Laparoscopic IOUS (LIOUS) introduces further complexity as it necessitates a reinterpretation of US images in the longitudinal-like plane, demanding a process of relearning and retraining, as well as a limited range of movement within the abdominal cavity [8]. These limitations underscore the need for innovative solutions. We propose leveraging machine learning to enhance the efficacy and safety of laparoscopic liver resection. However, the scarcity and quality of training datasets pose significant challenges, compounded by the operator-dependent nature of ultrasound (US) imaging. Offline annotation of 2D US video streams is laborious and unreliable, particularly with laparoscopic IOUS.\nImage guidance systems (IGS) are applied to laparoscopic liver resection (LLR) to enhance safety and intraoperative orientation [10,17]. IGS allows surgeons to visualize structures like tumors and blood vessels from preoperative scans that are not visible with a laparoscope [17]. However, laparoscopic ultrasound is limited by its 2D nature and poor tumor contrast [10]. Vessel segmentation in US is explored for 3D B-Mode volumes with adaptive thresholding and Hessian post-processing [16]. However, there are no commercially available 3D laparoscopic US probes. For 2D US in liver imaging, a segmentation method using Hessian-based filters and shape elimination is proposed in [22]. Deep learning with convolutional neural networks is also increasingly used for 2D US hepatic vasculature segmentation. U-Net methods offer high segmentation performance with 2D and 3D US datasets [20]. Other authors propose to use a U-Net for LUS vessel segmentation to support automatic untracked LUS to CT registration [14,19]. However US-to-CT registration faces challenges like slow inference times, demanding faster and more efficient registration algorithms for real-time integration of preoperative imaging data. Finally, some authors advocate using generative adversarial networks (GANs) [25] or physics-inspired methods [23] to construct datasets for training ultrasound segmentation models. However, existing studies primarily address simpler applications like bone surface segmentation, while our research focuses on identifying hepatic vessels.\nThis paper introduces contributions aimed at surmounting the challenges in LLR and improving preoperative-to-intraoperative translation. In the conventional LLR workflow, preoperative CT scans are performed for surgical planning and intraoperative guidance. However, surgeons are often required to mentally translate preoperative 3D data into 2D LIOUS. In order to provide a solution for accurate intrahepatic vascular structure identification in LIOUS, our contributions entail proposing a clinically applicable modified workflow consisting in (1) acquiring a 3D US liver volume from preoperative 2D US liver scan sequences; (2) semi-automatically segmenting the intrahepatic vascular structures in the 3D volume; (3) training a patient-specific deep learning model from the preoperative volume to identify portal branches in intraoperative US in real-time.\nTo train the patient specific model, we propose to use a dataset of synthetic 2D US images along with their corresponding segmentation obtained by reslicing the 3D US volume. The reslicing is combined with data augmentation to enhance the generalization capabilities of the intraoperative artificial intelligence (AI) model.\nBy providing surgeons with real-time guidance and precise vascular identification, our system could potentially improve liver cancer surgery, benefiting both patients and healthcare providers. The paper is organized as follows: Sect."}, {"title": "2 Methods", "content": "In our work, we simplified several problems to deliver a proof of concept while retaining core constraints. Firstly, we assumed the structural integrity of the ex vivo swine liver during imaging, using a rigid gel-based scaffold to prevent deformation. Secondly, we maintained a fixed ultrasound depth of 9cm to encompass the liver model adequately. Lastly, we focused on developing a personalized, patient-specific identification model rather than a generalized one, aligning with practicality and surgical workflow integration. This involved preoperative liver scans to gather patient-specific data for model training, potentially using a 3D ultrasound liver volume for intraoperative inference via a laparoscopic probe.\nThese considerations form the basis of our real-time liver portal branch identification method, detailed in six steps in Fig. 1. Subsequent sections will delve into each step."}, {"title": "1. Tracked US acquisition", "content": "We utilized a US system with a linear transducer to scan the liver (see supplementary materials Sect. 1), mimicking a preoperative US scan. The pose of the transducer was tracked using an EM tracking system, allowing us to record 2D tracked US sequences. Notably, the linear probe, chosen deliberately as a worst-case scenario, required multiple scans, potentially resulting in gaps or overlaps between swipes."}, {"title": "2. 3D US volume reconstruction", "content": "We employed the volume reconstruction algorithm from [11] to generate 3D US volumes from 2D tracked US sequences. This algorithm redistributes tracked US frames into the 3D volume space through linear interpolation, with voxel values determined as weighted averages of overlapping pixels. To prevent gaps, especially in high-resolution"}, {"title": "3. Semantic segmentation", "content": "The reconstructed US volume was annotated by a senior surgeon (see Fig. 2.b), who was asked to segment only \"large\" vessels confidently identifiable, omitting \"small\" vessels (diameter < 2mm) due to clinical irrelevance and visibility/connectivity limitations. The surgeon segmented the key hepatic vessels (adapted to swine anatomy), including the Main Portal Vein (MPV), the Right Lateral Portal Vein (RLPV), the Right Medial Portal Vein (RMPV), the Left Medial Portal Vein (LMPV), and the Left Lateral Portal Vein (LLPV) (see Fig. 2.b)."}, {"title": "4. Data augmentation (Reslicing)", "content": "We employed a semi-supervised data augmentation pipeline to generate labeled synthetic 2D US images from segmented 3D US volumes. The reslicing, based on spline interpolation, incorporated intensity variation for improved generalization across different scanning protocols. Realistic US maneuvers such as tilting, rocking, sliding, transversal sliding, and lifting were applied to adapt to user and scanning protocols. Validation with a clinician ensured the synthetic images closely resembled realistic US scans. Central cropping was performed according to linear dimensions and aspect ratio. This pipeline allowed us to create a personalized dataset of segmented synthetic 2D US images by reslicing each 3D US volume."}, {"title": "5. Personalized model training", "content": "We trained a patient-specific 2D attention U-Net model [18] (model choice justification in Sect. 3.2) on the labeled synthetic 2D US image (containing all the possible US scanning protocols) to learn the hepatic labels in the synthetic 2D US images."}, {"title": "6. AI-enabled intraoperative assistance", "content": "Our personalized 2D segmentation model enabled intraoperative support by identifying intrahepatic vessels. Real-time inference on unseen 2D US sequences or real-time US acquisition was performed using a linear transducer, corresponding to the typical US guidance in LLR. In laparoscopic US, similar signal dimensions to linear transducers were observed despite potential intensity variations from tissue contact. Our data augmentation compensated for contrast and gain differences, ensuring minimal impact on Unet performance and maintaining consistent size and shape of image features across transducers."}, {"title": "3 Results", "content": ""}, {"title": "3.1 Dataset and Implementation Details", "content": "Tracked US sequence and scanning technique: We utilized an ACUSON S3000 HELX Touch US system with a linear probe (9L4) set to a 9 cm depth for a full transversal view of the liver. An EM tracking system (trakSTAR, NDI, Canada) with a 6 DoF sensor attached to the US transducer was employed. US images were captured using a frame grabber (AV.io HD+, Epiphan Video), and tracked sequences were recorded using the PLUS toolkit and 3D Slicer. Calibration for spatial and temporal alignment was achieved using the Freehand tracked US calibration application (fCal) from"}, {"title": "3.2 Model validation", "content": "Metrics and protocol We evaluated our model's intrahepatic structure identification using the DICE score, a standard metric for segmentation tasks [13], emphasizing the importance of segmentation alongside identification accuracy for visual representation. We compared the model's 2D segmentation predictions to the 3D segmentation ground truth projected onto initial 2D US frames. Model validation involved running inference on tracked US sequences and computing the DICE score to assess segmentation accuracy. Additionally, we used a brute force method for comparison, which identified the closest US image from a dataset of 50,000 images using the Structural Similarity Metric [24]. This served as a baseline to justify using a neural network. Real-time capabilities were evaluated by measuring frames per second (fps) processed in the test sequences.\nAblation and sensibility study We evaluated several model architectures: U-Net [4], Attention U-Net [18], SegResNet [15], VNet [12], and UNETR [9]. Using the Validation DICE score as the primary metric, Attention U-Net outperformed all other architectures across various dataset sizes, achieving a score of 0.799 for a dataset size of 50,000 (see Fig. 3). Therefore, we selected Attention U-Net as the optimal architecture for our hepatic vascular structure identification task due to its highest Validation DICE score. To evaluate the impact of clinical data augmentation on model generalization across different US protocols and knobology settings, we examined how training dataset size affects model performance measured by the DICE metric. Modifying the dataset size allowed us to adjust the diversity of parameter variations present within the training data. Results of this sensitivity analysis are shown in Fig. 3.\nResults Our method outperformed the brute force approach in vessel identification and localization accuracy on validation sequences. With an inference time of 0.072 \u00b10.002 s (13.89\u00b10.39 fps) compared to the brute force method's 18.42 \u00b1 0.01 s (0.05429 \u00b1 0.0001 fps) for a 50,000 images dataset, our method enables real-time identification of vascular structures in IOUS. The mean DICE score for our method on the US frames test set was 0.60\u00b10.05, significantly higher than the brute force approach's 0.030 \u00b1 0.088 (see table 1)."}, {"title": "3.3 Pre-clinical validation", "content": "Metrics and protocol To validate our solution in a clinical setting, four surgeons identified 12 targets in the portal branches. Surgeons selected optimal views, communicated identifications, and markers were placed accordingly. Surgeons had unlimited time and were aided by 3D segmentation. The AI model was trained exclusively on portal labels for a fair comparison. Performance assessment compared the model to surgeons by evaluating spatial portal branch identification. Surgeons annotated US frames in real-time, while the model performed inference on those frames. Precision was employed as the metric for both the model and surgeons. Recall was computed for the model, not for surgeons, due to predetermined target identifications. True positives were determined based on the model's predictions and surgeons' annotations within the ground truth volume. The validation tracked US sequence was registered to the 3D volume, allowing projection of segmentation onto 2D frames. A 5 mm error tolerance was allowed for annotation predictions [21]. Performance was compared for two tasks: distinguishing portal and hepatic veins and identifying portal vein branches.\nResults We compared surgeons' performance with the Attention U-Net model in portal branch identification, as summarized in Table 2. Possible sources of bias include differences in orientation between the ground truth and surgeons' perspectives and limited anatomical context in our ex vivo liver models. However, these biases are consistent across our model and experimental conditions. The model generally outperforms surgeons, achieving a mean precision of 0.95 and recall of 0.93, compared to surgeons' mean precision ranging from 0.50 to 0.86 for portal vein tree identification and from 0.05 to 0.54 for portal vein branch identification (see Table 2). Model identification errors primarily consist of false negatives due to recall, but this is not a significant issue for our application, as precision is prioritized to minimize false positives. Surgeons' lower identification scores can be attributed to misidentification of the portal vein leading to complete misidentification of its branches. Surgeons's feedback on our real-time hepatic vascular structures identification tool (see supplementary materials Sect. 2) was generally positive, with mean scores ranging from 3.75 to 4.75 on a scale of 0 (Strongly Disagree) to 5 (Strongly Agree), indicating high satisfaction, confidence in identification, and educational value of the tool (see Table 3)."}, {"title": "4 Conclusion", "content": "In this study, we introduced a novel method for vessel identification in intraoperative ultrasound frames. Our approach combines tracked preoperative ultra- sound acquisition, volume reconstruction, data augmentation, and personalized model training. Validation experiments on humanized swine livers showed that our method accurately identifies vessels, surpassing surgeon performance with high precision and low false discovery rates. Its adaptability to various scanning protocols and knobology enhances clinical applicability, while personalized model training improves accuracy. Additionally, streamlining the training process with advanced 3D segmentation tools could potentially lead to full automation. Future work will focus on enhancing the data augmentation pipeline to handle deformations and incorporating temporal modeling for further improvements."}]}