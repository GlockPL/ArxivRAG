{"title": "Skeleton-Based Action Recognition with Spatial-Structural Graph Convolution", "authors": ["Jingyao WANG", "Issam FALIH", "Emmanuel BERGERET"], "abstract": "Human Activity Recognition (HAR) is a field of study that focuses on identifying and classifying human activities. Skeleton-based Human Activity Recognition has received much attention in recent years, where Graph Convolutional Network (GCN) based method is widely used and has achieved remarkable results. However, the representation of skeleton data and the issue of over-smoothing in GCN still need to be studied. 1). Compared to central nodes, edge nodes can only aggregate limited neighbor information, and different edge nodes of the human body are always structurally related. However, the information from edge nodes is crucial for fine-grained activity recognition. 2). The Graph Convolutional Network suffers from a significant over-smoothing issue, causing nodes to become increasingly similar as the number of network layers increases. Based on these two ideas, we propose a two-stream graph convolution method called Spatial-Structural GCN (SpSt-GCN). Spatial GCN performs information aggregation based on the topological structure of the human body, and structural GCN performs differentiation based on the similarity of edge node sequences. The spatial connection is fixed, and the human skeleton naturally maintains this topology regardless of the actions performed by humans. However, the structural connection is dynamic and depends on the type of movement the human body is performing. Based on this idea, we also propose an entirely data-driven structural connection, which greatly increases flexibility. We evaluate our method on two large-scale datasets, i.e., NTU RGB+D and NTU RGB+D 120. The proposed method achieves good results while being efficient.", "sections": [{"title": "I. INTRODUCTION", "content": "Human activity recognition (HAR) is a research field that spans computer science and electronic engineering. Its goal is to identify and classify human activities using algorithms. Human Activity Recognition (HAR) has received significant attention in recent years and has been applied in various fields such as healthcare, sports, security, smart homes, and wearable devices. The aim is to enhance human well-being, safety, and productivity by offering insights and information for decision-making, monitoring, or feedback purposes [26]. The HAR process involves several steps: data collection, data preprocessing, feature extraction, and activity recognition [26]. Various data modalities are used for different scenarios. They could be divided into two groups: visual modality and non-visual modality. RGB and skeleton data are two common types of visual modalities. RGB data is typically captured with a camera and contains a wealth of color and contour information. This data is widely used in security cameras, intelligent robots, and other applications. Skeleton data is usu-ally extracted from RGB data or collected by depth cameras. Compared to RGB data, 3D skeleton data effectively captures spatial-temporal properties. It contains less data but has higher computational efficiency [16]. At the same time, it protects pri-vacy. Skeleton data is a good choice when computing resources are limited or privacy protection is required. Acceleration data is typically non-visual data. The acceleration sensor is small, lightweight, and designed to protect privacy. It can accurately and comprehensively measure the spatial acceleration of an object without prior knowledge of its direction of motion. This sensor is commonly used in low-cost and low-power-consumption portable devices, such as smartwatches. Each of the various data modalities has its suitable application scenario. In this article, we focused on visual data, specifically on skeleton data.\nCurrently, the predominant approach involves using spatial-temporal convolutional networks to extract features from skeleton data. Researchers utilize GCN to extract spatial fea-tures within frames, and then utilize TCN to extract temporal features between frames. The researcher designs the skeletal connection diagram based on the human skeleton's topology. When performing graph convolution, the adjacency matrix is utilized to depict the connections between nodes and perform message passing between neighboring joints [25], [28]. The issue is that human beings have symmetrical structures, and there should be not only spatial connections but also structural connections between joints.\nThe action of \"clapping hands\" requires both hands to come together. There is a strong connection between the two hands. However, a mere spatial connection would not adequately represent the connection between the hands, and we need to depict this connection with a structural link. We believe that distinguishing fine-grained activities requires a focus on the activities of edge nodes. Taking typing on the keyboard and writing as an example [19], the most critical metric to distinguish between these two actions is the fine-grained movement of the hand. In terms of spatial structure, edge"}, {"title": "II. RELATED WORKS", "content": "HAR is a classic temporal classification problem. In earlier years, traditional CNN and RNN models were dominant. Zhang et al. [32] designed a two-stream CNN-RNN model to overcome view dependency. The main idea of this paper is to use view adaptation modeling to obtain a variable observation coordinate, allowing for the generation of skeleton data from different viewpoints. An RNN-based view adaptation subnet-work is integrated into the VA-RNN stream, while a CNN-based view adaptation subnetwork is integrated into the VA-CNN stream. Then, an LSTM classification network is applied in the VA-RNN stream, while a CNN classification network is applied in the VA-CNN stream. Caetano et al. [2] encoded the magnitude and orientation values of the skeleton joints into the image, and then utilized a CNN network for classification.\nIn recent years, several Transformer-based and GCN-based models have appeared. Plizzari et al. [17] developed a two-stream spatial-temporal transformer network. On the S-TR stream, a Spatial Self-Attention module (SSA) is used to analyze intra-frame interactions between different body parts, followed by a 2D convolution on the time dimension (TCN). On the T-TR stream, a Temporal Self-Attention module (TSA) is used to model inter-frame correlations, while spatial features are extracted by a standard graph convolution (GCN).\nSkeleton data used for human activity recognition (HAR) tasks are sequential data that contain consecutive frames. Skeleton data represents natural topography. In addition to being used as a matrix, skeleton data could also be utilized as a graph by a graph neural network [18]. In addition, the skeleton data used for action recognition is sequential data. GCN and TCN blocks are often used to capture spatial-temporal features, where Graph Convolutional Network (GCN) is used to cap-ture intraframe spatial information by aggregating information from neighboring nodes, and Temporal Convolutional Network (TCN) is used to capture interframe temporal information.\nYan et al. [28] propose the Spatial-Temporal Graph Convo-lutional Networks (ST-GCN) model, which applies alternating convolution of GCN and TCN, and has become the baseline in the field of skeleton-based action recognition. Song et al. [25] developed an efficient graph convolutional network. They extended the convolutional layer in CNN to the GCN network to extract temporal dynamics and compress the model size. They then employed a compound scaling method that adjusts the width (number of channels) and depth (number of layers) factors to make the model flexible and effective. In addition, Spatial Temporal Joint Attention (ST-JointAtt) is incorporated into each block, and three input branches are fused early in the network. The above strategies enable the network to achieve good results at a low computational cost."}, {"title": "A. Skeleton Data Representation", "content": "Skeleton data consists of a set of joint coordinates, usually represented as 3D points or 2D projections, along with addi-tional information like joint velocities or orientations. These joint coordinates are often normalized to a consistent scale or relative to a specific reference point to enhance generalizability across individuals and improve recognition accuracy. Skeleton data removes video backgrounds, people textures and outlines, which reduces lots of calculations. 3D skeleton data has a good view-invariance. It is possible to change the data view by rotating the skeleton in 3D space.\nSome researchers use matrices or images to represent skeleton data. Yang et al. [29] proposed a Tree Structure Skeleton Image (TSSI) which encodes skeleton data by depth-first tree traversal order to image. Banerjee et al. [1] extracted four features from skeleton data (Distance feature, Distance velocity feature, Angle feature, Angle velocity feature). These"}, {"title": "III. PROPOSED APPROACH", "content": "In this work, we utilize the GCN-TCN block to extract spatial-temporal features, where the GCN layer and TCN layer are alternately employed to capture spatial and tempo-ral dependencies. Temporal convolutions are essentially 2D convolutions with a kernel size of 1, designed to capture the temporal dependence of each node. In this section, we introduce our proposed spatial-structural graph convolution and the generation of the structural adjacency matrix."}, {"title": "A. Spatial-Structural Graph Convolution (SpSt-GCN)", "content": "For GCN-based methods, the input skeleton data is represented as (V, E) with N joints and T frames. Here, V represents joint points, and E represents connections between nodes, often represented by an adjacency matrix.\nThe conventional spatial graph convolution is shown below, where $f_{in}$ and $f_{outSpatial}$ represent the input and output features, respectively. $A_j$ represents the adjacency matrix at\n$f_{out Spatial} = \\sum W_j f_{in} (A_jA + A_j^*)$\nTo increase the flexibility of graph convolution, we add a parameterized matrix B as described in [21]. The matrix B is initialized to an all-zero matrix of the same size as adjacency matrix A and optimized together with the other parameters in the training process.\n$f_{out Spatial} = \\sum W_j f_{in} (A_jA + B_j)$\nMany researchers commonly employ the skeletal topology structure for establishing connections among joints, a method-ology known for its efficiency albeit lacking in precision. It is crucial to recognize that the human skeleton, characterized by symmetry, presents a nuanced structure wherein even widely spaced symmetrical joints exhibit robust structural correlations. While prevailing graph convolution techniques generally enable non-edge nodes to efficiently aggregate in-formation from both nearby and distant nodes, limitations arise when considering edge nodes. These edge nodes pos-sess only a singular connection and, as a result, can solely aggregate information from nodes in close proximity to the central point. This asymmetry in information flow becomes particularly evident when comparing edge nodes to central nodes, as the former receives comparatively less neighbor information, thereby impeding the formation of optimal node representations. To address this challenge and enhance the representation of both symmetric and edge nodes, we propose a novel approach named spatial-structural graph convolution. This innovative method involves the integration of two branches: a spatial branch responsible for aggregating infor-mation from spatially adjacent nodes and a structural branch focused on consolidating information between edge nodes. By combining these branches, the spatial-structural graph convo-lution aims to achieve a more comprehensive and accurate representation of the underlying skeletal structure, thereby advancing the state-of-the-art in joint connectivity modeling\n1. The structural graph convolution is formulated as follows:\n$f_{out Structural} = \\sum M_j f_{in} A_{sj}$\nwhere $f_{in}$ and $f_{outStructural}$ represent the input and output features, respectively. $A_{sj}$ represents the structural adjacency matrix for distance j. The parameters $M_j$ can be optimized during the training process. In this work, we set the distance as 1. Then, we use element-wise addition to combine the outputs of these two branches and obtain the final output.\n$f_{out} = f_{outSpatial} + f_{outStructural}$"}, {"title": "B. Structural Adjacency Matrix", "content": "In contrast to the conventional approach of spatial graph convolution, where all samples share a uniform adjacency matrix, we recognize that the structural connection between edge nodes is intricately linked with the specific actions performed. To capture these nuanced relationships, we propose a data-driven structural adjacency matrix, wherein the strength of connections between edge nodes is determined solely by the characteristics of each sample.\nIn the context of the NTU60 dataset's skeleton data, we observe five edge nodes, each corresponding to a distinct time series. In standard graph convolutional networks (GCN), the adjacency matrix is normalized based on the number of adjacent nodes. However, for structural connections, creat-ing a conventional adjacency matrix between edge nodes is impractical as edge joints lack tangible spatial connections. Aggregating them without differentiation would compromise the unique characteristics of each edge node. Based on this idea, we use the similarity of edge node sequences instead of the number of adjacent nodes to represent the strength of the connection.\nEuclidean distance and cosine similarity are widely employed distance calculation methods in deep learning. Euclidean dis-tance quantifies the straight-line separation between two points in Euclidean space, making it well-suited for sequences with consistent lengths and where element order is crucial. Cosine similarity gauges the cosine of the angle between two vectors, treating sequences as vectors in a high-dimensional space. Cosine similarity is suitable for situations involving text data, document comparison, and situations where vector magnitudes are not critical.\nIn the context of skeleton data, the interplay of human muscles and bones results in a strong correlation among joint movements. However, the execution of force progresses incrementally. Consider playing badminton as an example: the upper arm propels the forearm, the forearm propels the wrist, leading to the final stroke of the shuttlecock. The transmission of the movement unfolds from the core to the periphery, with movement speed and amplitude gradually accelerating. Despite the collective coordination of the entire arm for a given motion, the time and range of movement for different joint points vary. In such cases, neither Euclidean distance nor cosine similarity proves suitable.\nTaking inspiration from similarity calculation methods in natu-ral language processing, we turn to the utilization of Dynamic Time Warping (DTW) to compute distances between each pair of edge nodes. DTW is a technique adept at measuring the similarity between two sequences that may exhibit variations in time or speed. It excels in scenarios where sequences share similar patterns but may be temporally misaligned. The DTW algorithm constructs an optimal warping path between the sequences, assessing similarity between corresponding points and allowing for time axis stretching or compressing as needed. The primary objective is to minimize the overall cost of warping while aligning similar features. Notably, DTW accommodates discrepancies in movement time among differ-ent joint points and considers the magnitude of movement, making it highly suitable for assessing movement similarity between edge nodes.\nWe finally use FastDTW for efficiency. We calculate a distance matrix D for each sample. To discern the correlation between different edge nodes, we leverage the inverse of the distance matrix $D^{-1}$ as a representation of the correlation matrix. Larger values in $D^{-1}$ signify greater similarity in actions between the two edge nodes, indicating a stronger correlation. Addressing the over-smoothing issue inherent in GCN, where data from different joints tends to become overly similar with each aggregation step, structural GCN takes a different approach. When employing the $D^{-1}$ approach directly, height-ened similarity among adjacent nodes leads to an aggregation of information, thereby exacerbating the likeness of edge nodes, a condition contrary to the desired outcome. Rather than engaging in information aggregation from neighboring nodes, this method prioritizes the preservation of node-specific information by delineating each edge node from others through the utilization of $-D^{-1}$. Consequently, the application of $-D^{-1}$ fosters greater differentiation among edge nodes, thereby facilitating the capture of nuanced information. To achieve this, an identity matrix (I) is introduced to retain the distinct characteristics of each node. The dynamic structural adjacency matrix, denoted as $I-D^{-1}$, is then calculated for each sample, providing a nuanced representation of the structural connections within the data."}, {"title": "C. Data Preprocessing", "content": "In this work, we adopt the same data preprocessing as de-scribed in [25]. The shape of each action sequence x is ($C_{in}$, $T_{in}$, $V_{in}$), where $C_{in}$ denotes coordinates, $T_{in}$ denotes"}, {"title": "IV. EVALUATION", "content": "1) NTU RGB+D Dataset: \"NTU RGB+D\" dataset [19] con-tains 60 action classes and 56,880 video samples captured from 40 different people using the Microsoft Kinect v2. The 60 action classes can be categorized into three main groups: 40 daily actions, 9 health-related actions, and 11 mutual actions. As mentioned, the NTU RGB+D dataset is a multi-modal dataset that contains RGB videos, depth map sequences, 3D skeletal data, and infrared (IR) videos for each sample. In this work, we only utilize skeleton data. Each frame contains two skeletons, and each skeleton contains 25 joints.\nWe evaluated our method using two benchmarks proposed by the authors of this dataset: cross-subject validation (X-sub) and cross-view validation (X-view). In cross-subject validation, we divided the subjects into two groups: twenty subjects in the training data group and another twenty subjects in the validation group. In cross-view validation, the data collected by cameras 2 and 3 are recognized as training data, while the data collected by camera 1 is used for validation.\n2) NTU RGB+D 120 Dataset: The \"NTU RGB+D 120\" dataset [11] is an extension of the \"NTU RGB+D\" dataset, captured from 106 different individuals, with an additional 60 classes and 57,600 video samples. The 120 action classes can be categorized into three main groups: 82 daily actions, 12 health-related actions, and 26 mutual actions. We evaluate our method using two benchmarks proposed by the authors of this dataset: cross-subject validation (X-sub) and cross-setup (X-set120). In cross-subject validation, 53 subjects are divided into a training data group and another 53 subjects into a validation group. In cross-validation, 16 setups are used for training, and the remaining 16 setups are used for testing."}, {"title": "B. Experimental Setting", "content": "In our experiments, we set the training epoch to 50. We apply the same settings as described in [25]. Our models are trained with gradient descent (SGD) with a Nesterov momentum of 0.9 and a weight decay of 0.0001. The learning rate is set to 0.1 and decays with a cosine schedule after the 10th epoch. The probability in the dropout layer is set to 0.25. We perform a data transformation as described in [21] for the X-view benchmark. The batch size is set to 16 for both the NTU RGB+D dataset and the NTU RGB+D 120 dataset. All our experiments are performed on one NVIDIA GeForce RTX 3090 GPU."}, {"title": "C. Comparisons", "content": "1) Effect of Structural Graph Convolution: In this part, we will discuss the impact of three input modalities and the impact of our structural branch on X-sub benchmark I and on X-view benchmark II. We can see that all three modalities are essential, and that fusing the scores of the three modalities outputs in the highest accuracy for both X-sub and X-view benchmarks. In addition, using the same network structure, there is a significant improvement in accuracy when employing the spatial-structural graph convolution layer instead of the spatial graph convolution layer."}, {"title": "2) NTU RGB+D Dataset:", "content": "We compare our models with the state-of-the-art methods on the NTU RGB+D dataset in III. We classify the commonly used methods for skeleton-based human activity recognition into two categories: CNN-RNN-LSTM-based methods and GCN-based methods. Notably, the GCN-based method exhibits superior performance compared to CNN-RNN-LSTM-based methods. In recent years, there has been a growing preference among researchers for GCN-based approaches in skeleton recognition tasks, showcasing better overall performance than their CNN-RNN-LSTM coun-terparts. ST-GCN is one of the most well-known GCN-based models for skeleton recognition. Our method greatly exceeds it by 10.1% on the X-sub benchmark and 7.5% on the X-view benchmark. EfficientGCN is another popular model for its high efficiency and high accuracy. In this work, we use the same GCN block and the same number of blocks as EfficientGCN-B0. The accuracy of our model exceeds it by 1.4% on the X-sub bencnmark and 0.9% on the X-view benchmark. CTR-GCN learns topologies dynamically, which demonstrates commendable outcomes. However, it overlooks critical considerations such as the symmetry inherent in human body structure and the constraints associated with edge nodes. We posit that integrating the adaptable topology of CTR-GCN with our refined graph representation will likely yield superior results. We consider that the results of StSp-GCN exceed those of most models due to our precise expression of the skeleton"}, {"title": "3) NTU RGB+D 120 Dataset:", "content": "Compared with the NTU RGB+D data set, the NTU RGB+D 120 dataset is larger and has more classes. This means that there are more similar"}, {"title": "4) Model Complexity:", "content": "Considering the importance of efficient resource utilization, we not only assess model accuracy but also consider computational complexity. We compare the model complexity (FLOPs and the number of parameters) with state of art methods on the X-sub benchmark in V. Compared with most models, our model has a higher accuracy while having low computational complexity and parameter quantity. Specifically, our model's FLOPS and parameter"}, {"title": "V. CONCLUSION", "content": "In this article, we propose a Spatial-Structural Graph Con-volutional Network (SpSt-GCN) for skeleton-based action recognition to better represent symmetrical human structures and edge nodes and address the issue of over-smoothing in Graph Convolutional Networks. The spatial branch aggregates information based on the topological structure, while the data-driven structural branch performs differentiation based on the similarity of edge node sequences. Our approach yields favorable results while maintaining efficiency. In the future, we will explore how to improve the flexibility of structural connection and how to extend this method to other graph recognition tasks, e.g. In this article, we have only considered the structural connectivity of edge nodes. The representation of structural connectivity between non-edge nodes is also worth exploring."}]}