{"title": "SCALE-SPECIFIC AUXILIARY MULTI-TASK CONTRASTIVE LEARNING FOR DEEP\nLIVER VESSEL SEGMENTATION", "authors": ["A. Sadikine", "B. Badic", "J.-P. Tasu", "V. Noblet", "P. Ballet", "D. Visvikis", "P.-H. Conze"], "abstract": "Extracting hepatic vessels from abdominal images is of high\ninterest for clinicians since it allows to divide the liver into\nfunctionally-independent Couinaud segments. In this respect,\nan automated liver blood vessel extraction is widely sum-\nmoned. Despite the significant growth in performance of se-\nmantic segmentation methodologies, preserving the complex\nmulti-scale geometry of main vessels and ramifications re-\nmains a major challenge. This paper provides a new deep\nsupervised approach for vessel segmentation, with a strong\nfocus on representations arising from the different scales in-\nherent to the vascular tree geometry. In particular, we propose\na new clustering technique to decompose the tree into various\nscale levels, from tiny to large vessels. Then, we extend stan-\ndard 3D UNet to multi-task learning by incorporating scale-\nspecific auxiliary tasks and contrastive learning to encourage\nthe discrimination between scales in the shared representa-\ntion. Promising results, depicted in several evaluation met-\nrics, are revealed on the public 3D-IRCADb dataset.", "sections": [{"title": "1. INTRODUCTION", "content": "Probing liver vessels from abdominal images is paramount for\ndiagnosis, therapy, and surgery planning intents. Since man-\nually performing dense voxel-level annotations of vascular\nstructures from Computed Tomography (CT) scans is com-\nplex, time-consuming, and prone to expert variability, there\nremains a renowned need for an automated computerized ap-\nproach that could effectively capture tubular structures while\nmanaging low contrast, high signal-to-noise, intensity varia-\ntions, complex bifurcation, and multi-scale geometry. Numer-\nous studies have addressed the challenge of vessel segmenta-\ntion through vesselness enhancement [1], active contours [2],\nor tracking [3] methods. With imaging data and computa-\ntional resources availability, supervised semantic segmenta-\ntion approaches founded on Convolutional Neural Networks\n(CNN) [4, 5] have significantly raised and promoted notable\nperformance for miscellaneous tasks. Despite a good ability\nto extract visceral organ contours [6, 7], their ability to delin-\neate hepatic vascular systems still remains a challenge.\nTypically, blood vessel extraction is tackled without tak-\ning advantage of deep Multi-Task Learning (MTL) [8] whose\naim is to improve generalization, learning efficiency and pre-\ndiction accuracy by leveraging domain-specific information\nfrom related tasks. However, considering blood vessel seg-\nmentation with multiple (sub-)tasks appears promising. Fur-\nther, the network architectures related to MTL are multifari-\nous and adjusted depending on the specific concerns under in-\nvestigation [8]. In the setting of single-input and multi-output\nnetwork, which is a component of encoder-focused architec-\ntures, the encoding stage shares its layers (i.e., hard parameter\nsharing) to learn a generic representation which is then used\nas input of independent task-specific decoder heads."}, {"title": "2. METHODS", "content": "Deep learning-based liver vessel segmentation from medical\nimages is addressed in a multi-task fashion, relying on scale-\nspecific auxiliary sub-tasks. Let us denote D = {(Xi, {Y}s)}\nas the training dataset where s \u2208 {0,..., S} indexes task re-\nferring to different scales, x\u012b a greyscale volume and {y}=0\nthe multiple sets of ground truth vasculature segmentation\nmasks, with voxels coordinates v. In our case, we define s as\na specific vascular scale that belongs to the binary mask y =\nUS1ys where y\u00ba reflects the initial scale (i.e., y = y\u00b0). In\nthis setting, supervised multi-task segmentation with a single\ninput, multiple outputs and S learning tasks {T} consists of\napproximating a mapping function \u03be : x \u2192 \u00a7(x) = {y}=0\nfrom D, through a deep multi-task convolutional network."}, {"title": "2.1. Multi-scale vessel clustering", "content": "Defined as a set of \u0463 branches {B;}1 in the binary seg-\nmentation mask y, vessels are assumed to be tubular, which\ninsinuates that each branch B; C y is regular and has a con-\nstant radius rj. This assumption is denoted as hypothesis\nH. To estimate all the radii {r;}}1 at the scale of the en-\ntire vascular network, both edge surface (noted as \u03a9) detec-\ntion and thinning [15] algorithms were sequentially applied\n(Fig.2a). The latter extracts a voxel level skeleton \u0413\u0421\u0423,\nwith a set of voxels coordinates {k}=1 Cv. Based on\nthis, a local radius \u00f4k estimated in a given orthogonal cross-\nsection of y with centroid Yk is derived from the nearest m-\ntuplet voxel neighbors {wp | wp-1 < wp}=1 with wp =\narg minwen || Yk - w|| \u2208 \u03a9 the distance to the closest ves-\nsel surface voxel, as follows:\n\\\u03c3\u03bfk = \\max_{p<m} || Yk - WP ||                                      (1)\nTo estimate the radii \u00ee; from the set of local radii {k}=1,\nwe cluster in an unsupervised manner the skeleton branches\ninto no classes (i.e., each class in the skeleton \u0393 is assigned\nas a branch of index j). The clusterized skeleton is noted as\n\u0393', beneath the assumption H:\n\\j = \\text{median}{\\\u00f4k | Yk \u2208 Bj}                                                  (2)\n                                                                                                                                       k<q\nTo reconstruct the labeled branches {B;}1, we rely on\nthe Euclidean Distance Transform (EDT), defined for a given\nbranch as in Eq.3. Thus, we look for the voxel v closest to\n(i.e., the voxel of the centerline labeled by the index of the\nbranch j) with v not being part of the centerline. This means\nfinding the voxels orthogonal to v and labeling them as part\nof the branch Bj.\n\\Bj (v) = js.t. \\min_{v\u2208\u0393'} || - || Vk and y(v) = 1                                   (3)\nAs a final step, we define S 1 thresholds based on the\nintrinsic statistics of each volume yi. This choice is related\nto the intra-volume variability in order to generate S ground\ntruth masks {y}, each corresponding to a given scale s. In\nour study, we fixed S = 3, which is equivalent to decompos-\ning the vascular tree into large, medium, and small blood ves-\nsels (Fig.2b). In this context, the first and the second threshold\nwere estimated from {j}701 and the estimators were defined\nas the first quartile Q1 and the third quartile Q3 (Fig.??)."}, {"title": "2.2. Multi-Task Learning (MTL)", "content": "To approximate the mapping function \u00a7, a multi-task con-\nvolutional network with single input and multiple outputs is\nemployed (Fig.1). It comprises a contracting path encoder\nE = E2' fo o... \u25cb Efo dealing with a succession of convo-\nlutions, Batch Normalization (BN), non-linearity, and max-\npooling, which projects to a latent representation denoted\nas z (Fig.3), where l and fo respectively designates the num-\nber of hidden layers and the initial number of features maps.\nThe developed architecture also includes multiple expansive\npathway decoders D$ = D\u2021\u00ba 0...0 D2(1-1) fo composed of a\ncascade of up-sampling, long symmetrical skip-connections,\nconvolutions, BN, and non-linearity, except Dfo which com-\nprises an additional convolution with 1 \u00d7 1 \u00d7 1 kernel as well\nas an activation function (Fig.3). Each decoder projects back\nthe shared representation z to achieve a task-specific segmen-\ntation map y. This conducted us to define in a general way\nthe network (denoted \u00a7 as the mapping function it approxi-\nmates) with numerous tasks {T}, following:\n\\f(x) = {D\u2084(z) = \u0177\u00b0 | z = E(x)}=0                                                       (4)\nwhere Do(z) = Dmt(z) and {Ds(z)}=1 refer respectively\nto the main (mt stands for main task) and the auxiliary tasks\ndecoders. Furthermore, the model parameters are estimated\nby learning both main and auxiliary tasks jointly through the\noptimization of the following loss function:\n\\L = Lmt(Y,Y) + \u03a3 \u22111sLs (y, \u00db\u00b3)                                                           (5)\ns=1\nwhere Lmt and Ls combine Dice and weighted cross-entropy.\nHyper-parameters \u5165 balance the contributions of each scale-\nspecific auxiliary task."}, {"title": "2.3. Contrastive multi-task multi-scale learning", "content": "All tasks shared the same representation z, which may bring\nconfusion to the encoder E. To handle this, in favor of the\nmain task, constraining E to manage inter- and intra-auxiliary\ntask relationships is needed. Therefore, we propose to add an\nadditional loss to Eq.5, allowing to benefit from contrastive\nlearning [13]. Defined as a hardness-aware loss function,\nthe contrastive loss encourages features representation z, be-\nlonging to an anchor set A from the same scale to be aligned\n(i.e., closeness) and separate features from different scales\napart in order to ensure uniformity (i.e., uniform distribution\nin a hypersphere). Since it is difficult to make the distinction\nbetween the latent representation of each auxiliary task at z,\nwe define the compact representation derived from the first\nlayer of the decoder D, for each task Ts, following:\n\\z = \\text{proj} (D2(1-1) fo fo)                                                                    (6)\nwhere proj, applies a sequence of 1 \u00d7 1 \u00d7 1 convolutions, BN\nand non-linearity (Fig.3) to map the dense feature D2(1-1) fo\nto a lower dimensional space. The representations z from the\nsame scale (resp. different scale) belong to the set Pi (resp.\nNi). From this, the contrastive loss can be written as:\n\\Lc = \\frac{1}{|A|} \u03a3_{i\u2208A} [ \u03a3_{j\u2208P_{i}} l_{i,j} ]                                                                     (7)\nwhere:\n\\li,j = - \\text{log} \\frac{\\text{exp}(z_{i}^{T} z_{j}/\u03c4)}{\\text{exp}(z_{i}^{T} z_{j}/\u03c4) + \u03a3_{k\u2208N_{i}} \\text{exp}(z_{i}^{T} z_{k}/\u03c4)}                                            (8)\nzs is a 12-normalized vector and \u03c4 > 0 a scalar tempera-\nture hyper-parameter. Finally, this leads us to propose Eq.9\nas global loss function:\n\\L_{total} = L_{mt} + \u03a3_{s=1}^{S} \u039b_{s} L_{s} + \u039b_{c} L_{c}                                                               (9)\nwhere A depicts a hyper-parameter that regulates the strength\nof contrastive learning."}, {"title": "3. EXPERIMENTS", "content": "We assess the proposed approach on the publicly-available\nabdominal 3D-IRCADb [14] dataset containing CT scans\nwith ground truth masks from 20 patients (10 women, 10\nmen) with liver tumours in 75% of cases. After extracting a\nliver bounding box in each CT scan, we resized all volumes\nto 256 \u00d7 256 \u00d7 128 voxels with isotropic size. Then, we\nperformed the clustering of ground truth masks described in\nSect.2.1 with p = 8 to generate {y}."}, {"title": "3.2. Implementation details", "content": "For all experiments, the number of layers l, the number of\nfeatures maps fo, the learning rate, batch size, and the num-\nber of epochs were respectively set to 5, 8, 3 \u00d7 10-4, 2, and\n2000. After hyper-parameters mining using Optuna [17], op-\ntimal 11, 12, 13, \u03bb\u03b5 and \u03c4 (Eq.9) were empirically set to\n0.78, 0.48, 0.54, 0.53 and 0.94. Random data augmentation\nwas involved on the fly during training: rotation, translation,\nflipping, and gamma correction. 5-fold cross-validation was\nfollowed, and segmentation networks were implemented with\nPyTorch. Seeds were fixed for weight initialization, data aug-\nmentation, and data shuffling to ensure reproducibility."}, {"title": "3.3. Evaluation of predicted segmentation", "content": "To evaluate the performance of our model against existing\napproaches, we compared ground truth GT and predicted\nP masks through the following metrics: Dice coefficient\n\\DSC \\frac{2|GT\u2229P|}{|GT|+|P|}, Jaccard coefficient \\frac{|GT\u2229P|}{|GT\u222aP|} as well\nas c1DSC coefficient [18] for connectivity assessment. The\nHausdorff distance HD(GT, P) = max(h(GT, P), h(P, GT))\nwas also used with h(A, B) = maxa\u2208 A mint\u2208 B ||\u0430 - b||."}, {"title": "4. RESULTS AND DISCUSSION", "content": "Regarding multi-scale vessel clustering, the letter-value plot\nin Fig.?? reveals a substantial heterogeneity in intra-volume\nyi multi-scale geometry (i.e., shape, topology) within the 3D-\nIRCADb dataset. Moreover, this finding explains the intrinsic\nstatistics choice per volume highlighted in Sect.2.1. This con-\ncretely demonstrates the difficulties that a deep network can\nface in such a challenging liver vessel segmentation task.\nConcerning the segmentation, the baseline 3D ResUNet\nmodels (i.e., S = 0 in Eq.4) in binary and multi-class set-\ntings were compared with the proposed method, consisting\nof multi-task learning with contrastive multi-scale auxiliary\nsub-tasks. The quantitative results from Tab.1 demonstrate,\nunder the assumption of reaching the optimal loss function\nhyper-parameters, that our approach outperforms the baseline\nin terms of DSC, Jacc and clDSC with a gain of 0.79%,\n0.85%, and 1, 29% respectively, except for HD where the bi-\nnary segmentation baseline overwhelms our method. On the\nother hand, the model performance drops out in multi-class\nsetting, which can be explained by the inter-scale confu-\nsion faced by the model in its hidden layers. Moreover,\nthe ablation study demonstrates the effectiveness of inte-\ngrating multi-scale contrastive learning into Eq.5, especially\nin clDSC. Further, Fig.5 illustrates the connectivity im-\nprovement reached by our method. Ultimately, it is worth\nmentioning that during the inference stage, only the main\ntask decoder Dmt (Fig.1) was employed, which is desirable\ntowards the deployment of our pipeline into clinical routine."}, {"title": "5. CONCLUSION", "content": "We have unveiled a novel approach for liver vessel segmen-\ntation based on scale-specific auxiliary multi-task contrastive\nlearning. In future works, it would be valuable to evaluate\nthe proposed method with a various number of vascular tree\nscales to more deeply assess its robustness. In addition, incor-\nporating shape and topological priors could allow the model\nto avoid prediction confusion and increase its generalization\nability. Furthermore, a memory bank storing multi-scale la-\ntent representations could be a way to further benefit from\ncontrastive learning while alleviating batch size constraints.\nMore globally, our contributions could be easily extended to\nother types of vasculature including brain and pulmonary ves-\nsels from diverse imaging modalities."}, {"title": "6. COMPLIANCE WITH ETHICAL STANDARDS", "content": "This research study was conducted retrospectively using hu-\nman subject data made available in open access [14]."}]}