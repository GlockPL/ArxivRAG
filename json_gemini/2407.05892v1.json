{"title": "An efficient method to automate tooth identification and 3D bounding box extraction from Cone Beam CT Images", "authors": ["Ignacio Garrido Botella", "Ignacio Arranz \u00c1gueda", "Juan Carlos Armenteros Carmona", "Oleg Vorontsov", "Fernando Bay\u00f3n Robledo", "Adri\u00e1n Alonso Barriuso"], "abstract": "Accurate identification, localization, and segregation of teeth from Cone Beam Computed Tomography (CBCT) images are essential for analyzing dental pathologies. Modeling an individual tooth can be challenging and intricate to accomplish, especially when fillings and other restorations introduce artifacts. This paper proposes a method for automatically detecting, identifying, and extracting teeth from CBCT images. Our approach involves dividing the three-dimensional images into axial slices for image detection. Teeth are pinpointed and labeled using a single-stage object detector. Subsequently, bounding boxes are delineated and identified to create three-dimensional representations of each tooth. The proposed solution has been successfully integrated into the dental analysis tool Dentomo.", "sections": [{"title": "INTRODUCTION", "content": "In the last few years, there has been a significant push towards automating disease diagnosis in clinical settings [12]. Advancements in medical imaging techniques and technologies, along with the integration of Artificial Intelligence (AI) algorithms, have significantly contributed to the growth of this field.\nParticularly, Cone Beam Computed Tomography (CBCT) has become a powerful, cost-effective imaging technology for dental applications. It offers precise and accurate images while exposing patients to relatively low radiation doses [10]. In addition, its detailed three-dimensional reconstructions of the oral and maxillofacial regions can be used to diagnose several dental pathologies and conditions. Moreover, as an imaging technology, CBCT is not an exception when employing AI techniques for automatic diagnosis, and extensive research is being done in this line [8].\nOne common initial step in these algorithms is identifying and segregating teeth for their subsequent analysis. Typically, teeth are first located and identified. Then, a small bounding box containing the tooth and some context is used as input to another pipeline that infers other features [20, 21].\nWe propose a tooth detection, identification, and reconstruction algorithm based on a three-stage pipeline. First, the three-dimensional CBCT image is divided into axial slices where the present teeth are located and identified with a one-stage object detector. Then, the two-dimensional bounding boxes are aligned, matched, and merged to generate three-dimensional tooth models. Ultimately, we would tackle artifacts due to the deficient teeth split. We treat the images as graphs to satisfactorily delineate teeth boundaries, with each voxel connected to its adjacent neighbors within the same sagittal slice. Through a sequence of heuristic-based penalties, we assign weights to each node. These weights help trace the interocclusal space division boundary. As a result, our method yields three-dimensional bounding boxes, each enclosing an individual tooth model along with a small surrounding context area around it.\nThe rest of the paper is organized as follows. Section 2 introduces other detection and segmentation methods, situating our proposal. Section 3 explains the main blocks of our algorithm required to build the three-dimensional tooth models. Section 4 proposes several experiments to test our solution. Finally, Section 5 concludes with future guidelines."}, {"title": "RELATED WORK", "content": "Tooth identification and segregation are well-researched subjects. The latter generally comprises tooth segmentation or bounding box creation. Traditional methods often rely on features and structural extraction using thresholding, contour detection, or any other image transformations [13, 17]. These methods are convenient as they do not require an extensive dataset or expert knowledge for the labeling task. However, deep learning methods consistently outperform them [15].\nDental fillings and other restorations may cause artifacts in CBCT images, leading to incorrect inferences. Deep learning-based methods usually rely on CNN architectures such as U-Net [16], V-Net [14], and 3D U-Net [3], which are more suited to treat these imperfections. Moreover, these studies usually cover a broad range of tasks, from the location of the teeth to the identification of their labels in two-dimensional and three-dimensional slices.\nMost three-dimensional approaches to interpreting CBCT images are based on multi-stage methodologies [2, 5, 20]. Furthermore, some studies segment the teeth from the rest of the CBCT image, extracting other structures such as bone tissue [4]. While deep learning-based segmentation approaches result in valuable features, they tend to need complex and relatively extensive datasets.\nBesides, operating deep learning models directly applied to three-dimensional images tends to be resource-intensive. These techniques may also need more flexibility when adapting to specific hardware configurations.\nConversely, alternative approaches perform inference on two-dimensional projections, such as axial slices or panoramic images. Nevertheless, these algorithms require a volume restoration stage in which the three-dimensional tooth is reconstructed [7, 11]. Our method builds on this idea, including a custom algorithm to remedy artifacts. Overall, our approach offers a resource-efficient, fast, interpretable, and robust method. It significantly mitigates the effort and expert knowledge required for labeling, making it a practical solution in dental imaging applications."}, {"title": "METHOD AND MATERIALS", "content": "The proposed method for solving the tooth detection, identification, and segregation problem consists of three steps:\n1.  In the first stage, the images are divided into equispaced axial\nslices. A deep learning model detects and classifies the teeth in\neach axial slice into eight possible categories. Given the sym-\nmetry of dental structures and the resemblance between the\nmandible and maxilla in the axial dimension, these categories\ndo not differentiate between the top and bottom or the right and\nleft sides of the maxillofacial region. Following the FDI 2-digit\nWorld Dental Federation (ISO) notation [9], each of our eight\nlabels corresponds to the next teeth:\n\u2022 First incisor (1): 11, 21, 31, 41.\n\u2022 Second incisor (2): 12, 22, 32, 42.\n\u2022 Canine (3): 13, 23, 33, 43.\n\u2022 First premolar (4): 14, 24, 34, 44.\n\u2022 Second premolar (5): 15, 25, 35, 45.\n\u2022 First molar (6): 16, 26, 36, 46.\n\u2022 Second molar (7): 17, 27, 37, 47.\n\u2022 Third molar (8): 18, 28, 38, 48.\n2.  Then, individual three-dimensional bounding boxes containing\neach separate tooth are extracted. This step is formulated as an\noptimal assignment problem. Precisely, we use the Hungarian\nalgorithm to match all the bounding boxes that belong to the\nsame tooth. This approach is inspired by a tracking task [1]\nalong the axial slices.\n3.  Finally, some artifacts may emerge when upper and lower teeth\nlack separation, occluding the interdental space. To mitigate this,\npractitioners often employ a silicone bite block. This device is\ninserted into the mouth to stabilize and position the patient's\njaws. However, even with a dental bite block, some instances\nmay still lead to overlapped reconstructions. We have designed\na graph-based approach to calculate the division of these dis-\ntinctive cases.\nThe pipeline inputs a three-dimensional CBCT image and produces a set of three-dimensional bounding boxes containing the identified teeth and some context around them. Eventually, these bounding boxes adapt tightly to circumvent teeth boundaries without sufficient interoclussal space."}, {"title": "Dataset and notation", "content": "Our dataset comprises 250 anonymized CBCT images displaying the maxillofacial region. It encompasses both natural teeth and dental prosthetics, including implants and bridges. For the purpose of our study, these prosthetics have been classified alongside natural teeth and have been assigned one of the eight possible labels.\nAs part of the training process for the detection model, 15 equispaced axial slices have been extracted from each CBCT image. The dataset has been randomly partitioned into training, testing, and validation subsets, adhering to an 80/10/10 distribution."}, {"title": "Tooth detection", "content": "The first step of our algorithm involves detecting and identifying teeth in axial slices. For this purpose, we have trained a single-stage deep learning model based on a fine-tuned version of YOLOv7 [19]. This model localizes the teeth and identifies one of the eight possible labels described in Section 3.1. The detection algorithm consists of two steps:\n1.  In the analysis of CBCT images of the mouth, axial slices are\nfirst extracted at regular, equispaced intervals of 1.4 mm. This\ninterval is chosen based on the minimum expected size of an\nadult tooth, ensuring at least three axial slices per tooth. Further-\nmore, the region from which the teeth are extracted is identified\nas the image section that displays the highest mean axial value\nwhen projected to the vertical axis. More precisely, during our\nexperiments, we have found that it is reasonable to define this\nregion as the window that displays the top 90% range of mean\naxial slice values upon projection to the vertical axis. It is impor-\ntant to note that this interval of 1.4 mm between axial slices is\napplied during inference. The training dataset does not adhere\nto the 1.4 mm interval between consecutive axial slices; instead,\n15 axial slices per image are extracted.\n2.  The model evaluates each axial slice, resulting in a collection of\ntwo-dimensional detections. Each detection is associated with\nits axial slice (enumeration identifier) and a label.\nOne instance of the detections predicted by our model is depicted\nin Figure 2. This image shows an axial slice of the mandible, where\nthe teeth on the right side of the mouth are assigned the same label\nas those mirrored on the left."}, {"title": "Tooth reconstruction", "content": "Building upon the previous detections in axial slices, we construct the candidate volumes that contain each tooth. Essentially, the volumes consist of a collection of two-dimensional bounding boxes.\nThis step involves iteratively aligning and joining the slices corresponding to the same tooth. This process begins by analyzing the top axial slice that contains detections and proceeds downward until all axial slices of the CBCT image have been analyzed. The following metrics are employed to evaluate the quality of a new match:\n\u2022 We contrast between a bounding box in the axial slice under\nstudy and a previously matched bounding box in another ax-\nial slice. The latter corresponds to the last match within the\ntooth volume under construction. The Euclidean distance\nin the vertical plane is used to measure proximity. It facil-\nitates the identification of detections across non-adjacent\naxial slices. Furthermore, a limit can be set on the maximum\nnumber of consecutive axial slices where a tooth is present\nbut not detected (i.e., missed detections). Beyond this limit,\nany new match is deemed invalid, resulting in the tooth\nbeing fully reconstructed.\n\u2022 The Intersection over Union (IoU) measures the overlap\nbetween a bounding box on the current axial slice, and the\nprojection of the last match of the volume under construc-\ntion onto the same axial slice.\n\u2022 A minor penalty is imposed when a bounding box and a\ntooth volume with differing labels are matched. The tooth\nvolumes under construction may potentially belong to mul-\ntiple classes simultaneously. This situation arises because a\nlabel is assigned to a tooth volume based on its bounding\nbox collection. Therefore, the penalty for label mismatch\nvaries in proportion to the uncertainty of the label of the\ntooth volume being constructed. The higher the uncertainty\nof the match, the greater the weight of the penalty. This\napproach allows matching bounding boxes that belong to\nthe same tooth, even when the detection algorithm misla-\nbels them. Although the detection model is proficient at\nlocating teeth, it occasionally mislabels some detections.\nDuring construction, tooth volumes are labeled as \"active\" or \"closed\". \"Active\" indicates tooth volumes that are still under construction and can accept further matches, whereas \"closed\" refers to tooth volumes that have been fully reconstructed. The matching algorithm operates as follows:\n1.  Start with the top axial slice containing detections. Create a\ntooth volume for each detection and mark them as \"active\".\n2.  Continue scrutinizing the successive axial slices until exhausted.\nFor each new axial slice:\n2.1.  Calculate the optimal match between the new detections\nand the \"active\" tooth volumes under construction. This\nprocess involves weighting the metrics described above,\nand utilizing the Hungarian algorithm to infer the optimal\nmatch. Additionally, an upper threshold beyond which a\nmatch between a two-dimensional detection and a tooth\nvolume is not permitted can be imposed. We have achieved\nfavorable results by setting this threshold such that, if there\nis no overlap in the axial dimension, the match is deemed\ninvalid.\n2.2.  Create a new \"active\" tooth volume for those detections in\nthe axial slice under study that have not been matched with\nany existing \"active\" tooth volumes."}, {"title": "Artifacts and correction", "content": "When insufficient interocclusal space exists, sequential volume construction may fail. Even with a bite block, there is a potential risk of joining the occlusal counterparts (Figure 6a). A heuristic-based, graph-oriented strategy ensures accurate separation, even in cases where the division of the mandible and maxilla regions is challenging, primarily due to the limited interocclusal space. Our algorithm effectively separates these fused counterparts into distinct entities (Figures 6b and 6c).\nFirstly, we apply \"if/else\" rules to detect these artifacts automatically. Joined teeth will be significantly larger than any other tooth from the same scan. We compute the size of each tooth and flag volumes that deviate significantly from the expected size distribution for review.\nSubsequently, those volumes containing two teeth are processed using our graph-based division algorithm. In CBCT images, voxel values are directly proportional to their density [18]. Ideally, the projection of the mean value of each axial slice onto the vertical axis will delineate two prominent peaks representing each tooth, with an intervening valley corresponding to the mouth aperture. This statement remains true, provided there is sufficient interocclusal space. In cases where this space is minimal, we computationally infer its expected position, typically at the midpoint of the volume. This estimate supports the search process as an initial condition. Manifold penalties related to the density of the pixels and boundary conditions confine the results in the desired range of values. Finally, all the identified divisions are combined into a lattice that adequately separates the volumes."}, {"title": "EXPERIMENTS", "content": "In this section, we present the experiments conducted to assess each of the three components of our algorithm. First, we evaluate the detection model described in Section 3.2. Subsequently, we examine the accuracy of the reconstruction algorithm explained in Section 3.3. Finally, we test the division algorithm discussed in Section 3.4.\nThe detection model utilized in our study is based on the YOLO architecture. We carried out a series of fine-tuning procedures on various YOLO versions, achieving the most satisfactory results with YOLOv7. Our final model was trained using 3,375 axial images from the training and evaluation sets and tested on a separate set of 375 images. For training, we used the Adam optimizer for 200 epochs. All axial images were resized to 416 \u00d7 416. We set the object confidence threshold and the IoU threshold for non-maximum suppression at 0.4. The resulting model achieved a Mean Average Precision at an IoU threshold of 0.5 (mAP@0.5) of 0.889, and a Mean Average Precision at IoU thresholds ranging from 0.5 to 0.95 (mAP@0.5:0.95) of 0.606.\nIt should be emphasized that the reconstruction algorithm is tolerant to some errors in both the label assigned to the detections and the spurious detections. This tolerance stems from the algorithm's reliance on heuristics that evaluate the label and the detection's position.\nTable 2 displays the mAP@0.5 and mAP@0.5:0.95 results for each tooth class. The molars, especially the third molars, present the most influential challenge for labeling. This is due to their similarity in the axial dimension, the limited number of examples of this class, and the more outstanding variability in their positions compared to the frontal teeth. Nevertheless, given that the reconstruction algorithm tolerates some errors at this stage, the results are considered satisfactory.\nTo assess the performance of the reconstruction and division algorithms, we compiled a dataset consisting of 89 CBCT images. This dataset was divided into two subsets: the first subset comprises 56 CBCT images in which a bite block is used, and there is some interocclusal space. In contrast, the second subset includes 33 CBCT images where the bite block was not utilized, and there is no interocclusal space. The first subset encompasses a total of 1568 teeth, and the second includes 868 teeth.\nThe rationale behind dividing the dataset into two subsets was motivated by the significant influence of interocclusal space on the results. First, the reconstruction algorithm tends to create fewer volumes containing two teeth when there is a slight separation between the mandible and maxilla regions. Moreover, more favorable outcomes are observed in the subset with interocclusal space in cases where the division algorithm separates a volume with two teeth. These better results are achieved because the inferred division is less constrained and can adapt closely to the teeth's geometry.\nOur algorithm successfully detected and reconstructed all but 26 teeth, resulting in a detection rate of 98.93% (this value does not necessarily reflect accurate reconstruction). Most detection errors were attributed to small dental bridges and implants, frequently facing misclassification issues caused by reflections and suboptimal image quality. Additionally, the detection model mistakenly identified some bone structures as tooth roots. Nevertheless, our reconstruction algorithm employs a minimum size criterion of 2.8mm for a volume to be accepted as a tooth. Consequently, there was only one wrong model (false positive) in the dataset of 89 CBCT images, where a small bone structure in the nostril area was incorrectly classified and modeled as a tooth root.\nWe have designed two tests to evaluate the reconstruction and division algorithms independently. First, we classify the results of the reconstruction algorithm (prior to division) into the next categories:\n\u2022 Single tooth: The volume contains a single tooth.\n\u2022 Double tooth: The volume contains two teeth (before the\ndivision algorithm is applied).\n\u2022 Not detected: The tooth is present, but our algorithm does\nnot detect it.\nThis test does not aim to evaluate perfect teeth modeling, where all tooth voxels are accurately captured. Instead, it serves as a foundational metric to estimate the frequency of cases requiring the application of the division algorithm.\nIn addition, we have evaluated the combination of the reconstruction and division algorithms. Specifically, we applied the division algorithm to the reconstructed volumes containing two teeth. Subsequently, we categorized the outcomes into four distinct groups:\n\u2022 Good reconstruction: The volume contains all the voxels\nbelonging to a single tooth, along with some additional\ncontext (a few additional voxels around the tooth).\n\u2022 Bad reconstruction: The volume contains a single tooth.\nHowever, some voxels of the tooth were left outside of the\nvolume.\n\u2022 Double tooth: This volume contains two teeth but was\nidentified as if it contained a single tooth. Consequently,\nthe volume still includes both teeth.\n\u2022 Not detected: The tooth is present, but our algorithm does\nnot detect it."}, {"title": "DISCUSSION AND CONCLUSION", "content": "We have successfully designed and developed an algorithm for detecting and identifying teeth in three-dimensional CBCT images. The initial phase of our algorithm focuses on detecting teeth in two-dimensional axial slices. This approach simplifies the detection and identification process by requiring less complex training data. Furthermore, it makes the annotation process more straightforward and accessible.\nWe have created a fast and reliable automatic process for generating three-dimensional teeth models by integrating this streamlined detection method with a proven reconstruction and division algorithm. These models can be used directly by experts or serve as a foundation for further segmentation techniques. For instance, the segmented three-dimensional teeth can be utilized in various tasks, including pathology detection, demonstrating the algorithm's versatility and effectiveness in dental imaging.\nThe primary challenge lies in detecting and dividing reconstructed tooth volumes containing two teeth, especially in scenarios with minimal interocclusal space. One potential solution to improve the inference in such cases is to employ another deep learning model to detect both the volumes that contain two teeth and the approximate height of the division. In addition, density-based erosion methods could further refine the teeth volumes for precise pixel-wise segmentation.\nMultiple domain experts have confirmed the effectiveness and reliability of our solution. Moreover, our detection and identification algorithm has been integrated into the tooth analysis tool Dentomo [6], improving expert efficiency by simplifying and reducing diagnosis time."}]}