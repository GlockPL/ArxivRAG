{"title": "An efficient method to automate tooth identification and 3D bounding box extraction from Cone Beam CT Images", "authors": ["Ignacio Garrido Botella", "Ignacio Arranz \u00c1gueda", "Juan Carlos Armenteros Carmona", "Oleg Vorontsov", "Fernando Bay\u00f3n Robledo", "Adri\u00e1n Alonso Barriuso"], "abstract": "Accurate identification, localization, and segregation of teeth from\nCone Beam Computed Tomography (CBCT) images are essential\nfor analyzing dental pathologies. Modeling an individual tooth can\nbe challenging and intricate to accomplish, especially when fill-\nings and other restorations introduce artifacts. This paper proposes\na method for automatically detecting, identifying, and extracting\nteeth from CBCT images. Our approach involves dividing the three-\ndimensional images into axial slices for image detection. Teeth are\npinpointed and labeled using a single-stage object detector. Sub-\nsequently, bounding boxes are delineated and identified to create\nthree-dimensional representations of each tooth. The proposed so-\nlution has been successfully integrated into the dental analysis tool\nDentomo.", "sections": [{"title": "1 INTRODUCTION", "content": "In the last few years, there has been a significant push towards au-tomating disease diagnosis in clinical settings [12]. Advancements\nin medical imaging techniques and technologies, along with the\nintegration of Artificial Intelligence (AI) algorithms, have signifi-\ncantly contributed to the growth of this field.\nParticularly, Cone Beam Computed Tomography (CBCT) has\nbecome a powerful, cost-effective imaging technology for dental\napplications. It offers precise and accurate images while expos-\ning patients to relatively low radiation doses [10]. In addition, its\ndetailed three-dimensional reconstructions of the oral and maxillo-\nfacial regions can be used to diagnose several dental pathologies and\nconditions. Moreover, as an imaging technology, CBCT is not an\nexception when employing AI techniques for automatic diagnosis,\nand extensive research is being done in this line [8].\nOne common initial step in these algorithms is identifying and\nsegregating teeth for their subsequent analysis. Typically, teeth are\nfirst located and identified. Then, a small bounding box containing\nthe tooth and some context is used as input to another pipeline that\ninfers other features [20, 21].\nWe propose a tooth detection, identification, and reconstruc-tion algorithm based on a three-stage pipeline. First, the three-dimensional CBCT image is divided into axial slices where the\npresent teeth are located and identified with a one-stage object\ndetector. Then, the two-dimensional bounding boxes are aligned,"}, {"title": "2 RELATED WORK", "content": "Tooth identification and segregation are well-researched subjects.\nThe latter generally comprises tooth segmentation or bounding\nbox creation. Traditional methods often rely on features and struc-tural extraction using thresholding, contour detection, or any other\nimage transformations [13, 17]. These methods are convenient as\nthey do not require an extensive dataset or expert knowledge for\nthe labeling task. However, deep learning methods consistently\noutperform them [15].\nDental fillings and other restorations may cause artifacts in CBCT\nimages, leading to incorrect inferences. Deep learning-based meth-ods usually rely on CNN architectures such as U-Net [16], V-Net\n[14], and 3D U-Net [3], which are more suited to treat these im-perfections. Moreover, these studies usually cover a broad range\nof tasks, from the location of the teeth to the identification of their\nlabels in two-dimensional and three-dimensional slices.\nMost three-dimensional approaches to interpreting CBCT im-ages are based on multi-stage methodologies [2, 5, 20]. Furthermore,\nsome studies segment the teeth from the rest of the CBCT image,\nextracting other structures such as bone tissue [4]. While deep\nlearning-based segmentation approaches result in valuable fea-tures, they tend to need complex and relatively extensive datasets."}, {"title": "3 METHOD AND MATERIALS", "content": "The proposed method for solving the tooth detection, identification,and segregation problem consists of three steps:\n1. In the first stage, the images are divided into equispaced axial\nslices. A deep learning model detects and classifies the teeth in\neach axial slice into eight possible categories. Given the sym-metry of dental structures and the resemblance between the\nmandible and maxilla in the axial dimension, these categories\ndo not differentiate between the top and bottom or the right and\nleft sides of the maxillofacial region. Following the FDI 2-digit\nWorld Dental Federation (ISO) notation [9], each of our eight\nlabels corresponds to the next teeth:\n\u2022 First incisor (1): 11, 21, 31, 41.\n\u2022 Second incisor (2): 12, 22, 32, 42.\n\u2022 Canine (3): 13, 23, 33, 43.\n\u2022 First premolar (4): 14, 24, 34, 44.\n\u2022 Second premolar (5): 15, 25, 35, 45.\n\u2022 First molar (6): 16, 26, 36, 46.\n\u2022 Second molar (7): 17, 27, 37, 47.\n\u2022 Third molar (8): 18, 28, 38, 48.\n2. Then, individual three-dimensional bounding boxes containing\neach separate tooth are extracted. This step is formulated as an\noptimal assignment problem. Precisely, we use the Hungarian\nalgorithm to match all the bounding boxes that belong to the\nsame tooth. This approach is inspired by a tracking task [1]\nalong the axial slices.\n3. Finally, some artifacts may emerge when upper and lower teeth\nlack separation, occluding the interdental space. To mitigate this,\npractitioners often employ a silicone bite block. This device is\ninserted into the mouth to stabilize and position the patient's\njaws. However, even with a dental bite block, some instances\nmay still lead to overlapped reconstructions. We have designed\na graph-based approach to calculate the division of these dis-tinctive cases.\nThe pipeline inputs a three-dimensional CBCT image and pro-duces a set of three-dimensional bounding boxes containing the\nidentified teeth and some context around them. Eventually, these\nbounding boxes adapt tightly to circumvent teeth boundaries with-out sufficient interoclussal space."}, {"title": "3.1 Dataset and notation", "content": "Our dataset comprises 250 anonymized CBCT images displaying the\nmaxillofacial region. It encompasses both natural teeth and dental\nprosthetics, including implants and bridges. For the purpose of our\nstudy, these prosthetics have been classified alongside natural teeth\nand have been assigned one of the eight possible labels.\nAs part of the training process for the detection model, 15 equis-paced axial slices have been extracted from each CBCT image. The\ndataset has been randomly partitioned into training, testing, and\nvalidation subsets, adhering to an 80/10/10 distribution."}, {"title": "3.2 Tooth detection", "content": "The first step of our algorithm involves detecting and identifying\nteeth in axial slices. For this purpose, we have trained a single-stage\ndeep learning model based on a fine-tuned version of YOLOv7 [19].\nThis model localizes the teeth and identifies one of the eight possible\nlabels described in Section 3.1. The detection algorithm consists of\ntwo steps:\n1. In the analysis of CBCT images of the mouth, axial slices are\nfirst extracted at regular, equispaced intervals of 1.4 mm. This\ninterval is chosen based on the minimum expected size of an\nadult tooth, ensuring at least three axial slices per tooth. Further-more, the region from which the teeth are extracted is identified\nas the image section that displays the highest mean axial value\nwhen projected to the vertical axis. More precisely, during our\nexperiments, we have found that it is reasonable to define this\nregion as the window that displays the top 90% range of mean\naxial slice values upon projection to the vertical axis. It is impor-tant to note that this interval of 1.4 mm between axial slices is\napplied during inference. The training dataset does not adhere\nto the 1.4 mm interval between consecutive axial slices; instead,\n15 axial slices per image are extracted.\n2. The model evaluates each axial slice, resulting in a collection of\ntwo-dimensional detections. Each detection is associated with\nits axial slice (enumeration identifier) and a label.\nOne instance of the detections predicted by our model is depicted\nin Figure 2. This image shows an axial slice of the mandible, where\nthe teeth on the right side of the mouth are assigned the same label\nas those mirrored on the left."}, {"title": "3.3 Tooth reconstruction", "content": "Building upon the previous detections in axial slices, we construct\nthe candidate volumes that contain each tooth. Essentially, the vol-umes consist of a collection of two-dimensional bounding boxes.\nThis step involves iteratively aligning and joining the slices cor-responding to the same tooth. This process begins by analyzing\nthe top axial slice that contains detections and proceeds downward\nuntil all axial slices of the CBCT image have been analyzed. The\nfollowing metrics are employed to evaluate the quality of a new\nmatch:\n\u2022 We contrast between a bounding box in the axial slice under\nstudy and a previously matched bounding box in another ax-ial slice. The latter corresponds to the last match within the\ntooth volume under construction. The Euclidean distance\nin the vertical plane is used to measure proximity. It facil-itates the identification of detections across non-adjacent\naxial slices. Furthermore, a limit can be set on the maximum\nnumber of consecutive axial slices where a tooth is present\nbut not detected (i.e., missed detections). Beyond this limit,any new match is deemed invalid, resulting in the toothbeing fully reconstructed.\n\u2022 The Intersection over Union (IoU) measures the overlapbetween a bounding box on the current axial slice, and theprojection of the last match of the volume under construction onto the same axial slice.\n\u2022 A minor penalty is imposed when a bounding box and a\ntooth volume with differing labels are matched. The tooth\nvolumes under construction may potentially belong to mul-tiple classes simultaneously. This situation arises because a\nlabel is assigned to a tooth volume based on its boundingbox collection. Therefore, the penalty for label mismatchvaries in proportion to the uncertainty of the label of thetooth volume being constructed. The higher the uncertaintyof the match, the greater the weight of the penalty. Thisapproach allows matching bounding boxes that belong tothe same tooth, even when the detection algorithm misla-bels them. Although the detection model is proficient atlocating teeth, it occasionally mislabels some detections.\nDuring construction, tooth volumes are labeled as \"active\" or\n\"closed\". \"Active\" indicates tooth volumes that are still under con-struction and can accept further matches, whereas \"closed\" refers\nto tooth volumes that have been fully reconstructed. The matching\nalgorithm operates as follows:\n1. Start with the top axial slice containing detections. Create a\ntooth volume for each detection and mark them as \"active\".\n2. Continue scrutinizing the successive axial slices until exhausted.\nFor each new axial slice:\n2.1. Calculate the optimal match between the new detectionsand the \"active\" tooth volumes under construction. Thisprocess involves weighting the metrics described above,\nand utilizing the Hungarian algorithm to infer the optimalmatch. Additionally, an upper threshold beyond which amatch between a two-dimensional detection and a toothvolume is not permitted can be imposed. We have achievedfavorable results by setting this threshold such that, if thereis no overlap in the axial dimension, the match is deemedinvalid.\n2.2. Create a new \"active\" tooth volume for those detections inthe axial slice under study that have not been matched withany existing \"active\" tooth volumes."}, {"title": "3.4 Artifacts and correction", "content": "When insufficient interocclusal space exists, sequential volumeconstruction may fail. Even with a bite block, there is a potentialrisk of joining the occlusal counterparts (Figure 6a). A heuristic-based, graph-oriented strategy ensures accurate separation, evenin cases where the division of the mandible and maxilla regionsis challenging, primarily due to the limited interocclusal space.Our algorithm effectively separates these fused counterparts intodistinct entities (Figures 6b and 6c).\nFirstly, we apply \"if/else\" rules to detect these artifacts automati-cally. Joined teeth will be significantly larger than any other toothfrom the same scan. We compute the size of each tooth and flag vol-umes that deviate significantly from the expected size distributionfor review.\nSubsequently, those volumes containing two teeth are processedusing our graph-based division algorithm. In CBCT images, voxelvalues are directly proportional to their density [18]. Ideally, theprojection of the mean value of each axial slice onto the vertical axiswill delineate two prominent peaks representing each tooth, withan intervening valley corresponding to the mouth aperture. Thisstatement remains true, provided there is sufficient interocclusalspace. In cases where this space is minimal, we computationallyinfer its expected position, typically at the midpoint of the volume.This estimate supports the search process as an initial condition.Manifold penalties related to the density of the pixels and bound-ary conditions confine the results in the desired range of values.Finally, all the identified divisions are combined into a lattice thatadequately separates the volumes."}, {"title": "4 EXPERIMENTS", "content": "In this section, we present the experiments conducted to assess eachof the three components of our algorithm. First, we evaluate thedetection model described in Section 3.2. Subsequently, we examinethe accuracy of the reconstruction algorithm explained in Section3.3. Finally, we test the division algorithm discussed in Section 3.4.\nThe detection model utilized in our study is based on the YOLOarchitecture. We carried out a series of fine-tuning procedures on"}, {"title": "5 DISCUSSION AND CONCLUSION", "content": "We have successfully designed and developed an algorithm fordetecting and identifying teeth in three-dimensional CBCT images.The initial phase of our algorithm focuses on detecting teeth intwo-dimensional axial slices. This approach simplifies the detectionand identification process by requiring less complex training data.Furthermore, it makes the annotation process more straightforwardand accessible.\nWe have created a fast and reliable automatic process for generat-ing three-dimensional teeth models by integrating this streamlineddetection method with a proven reconstruction and division algo-rithm. These models can be used directly by experts or serve as\na foundation for further segmentation techniques. For instance,the segmented three-dimensional teeth can be utilized in varioustasks, including pathology detection, demonstrating the algorithm'sversatility and effectiveness in dental imaging.\nThe primary challenge lies in detecting and dividing recon-structed tooth volumes containing two teeth, especially in sce-narios with minimal interocclusal space. One potential solutionto improve the inference in such cases is to employ another deeplearning model to detect both the volumes that contain two teethand the approximate height of the division. In addition, density-based erosion methods could further refine the teeth volumes forprecise pixel-wise segmentation.\nMultiple domain experts have confirmed the effectiveness and re-liability of our solution. Moreover, our detection and identificationalgorithm has been integrated into the tooth analysis tool Den-tomo [6], improving expert efficiency by simplifying and reducingdiagnosis time."}]}