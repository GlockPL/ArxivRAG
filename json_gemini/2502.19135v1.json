{"title": "A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided Knowledge Base Management", "authors": ["Enrico Saccon", "Ahmet Tikna", "Davide De Martini", "Edoardo Lamon", "Luigi Palopoli", "Marco Roveri"], "abstract": "This paper presents a novel framework, called PLANTOR (PLanning with Natural language for Task-Oriented Robots), that integrates Large Language Models (LLMs) with Prolog-based knowledge management and planning for multi-robot tasks. The system employs a two-phase generation of a robot-oriented knowledge base, ensuring reusability and compositional reasoning, as well as a three-step planning procedure that handles temporal dependencies, resource constraints, and parallel task execution via mixed-integer linear programming. The final plan is converted into a Behaviour Tree for direct use in ROS2. We tested the framework in multi-robot assembly tasks within a block world and an arch-building scenario. Results demonstrate that LLMs can produce accurate knowledge bases with modest human feedback, while Prolog guarantees formal correctness and explainability. This approach underscores the potential of LLM integration for advanced robotics tasks requiring flexible, scalable, and human-understandable planning.", "sections": [{"title": "1. Introduction", "content": "The introduction of advanced language models (LLMs) represents a paradigm shift for a wide range of AI applications. In robotics, LLMs could drive disruptive advancements in human-robot interaction, adaptive behaviours, and multi-agent collaboration, bringing the widespread integration of robots into everyday life closer to reality in the coming years. To achieve these ambitious goals, robot decision-making processes must go beyond initial user input, continuously incorporating feedback loops for real-time task adaptation [1].\nDespite the remarkable efficiency of LLMs in interpreting natural language and providing semantic information about the real world, this technology lacks a crucial feature for robotic applications: the predictability and explainability of the decision-making process. These qualities are at the heart of more traditional approaches to knowledge representation and management, such as logic or functional languages [2]. For instance, Prolog [3] enables the expression of a Knowledge Base (KB) through facts and rules, linking them to feasible actions. This capability has already been successfully leveraged in robotics to construct knowledge representations [4], address planning and reasoning challenges [5], and, when combined with natural language processing, enhance human-robot interaction [6, 7].\nThe use of Prolog makes the KB inherently compositional and reusable, allowing for the deduction of new concepts and the execution of queries to verify consistency, infer new knowledge, or update existing knowledge. Logical reasoning facilitates the evaluation of these updates, ensuring coherence. For example, a new robotic implementation of the same task can be achieved by refining the relevant predicates and actions. However, populating a KB is not a straightforward task for non-experts, as it requires mastery of a highly specific formalism and its associated rules.\nIn this work, we bridge the gap between these two worlds by harnessing the power of LLMs to generate a human-readable logic KB. This process is carried out using natural language descriptions of the environment, the goals, and the robot's capabilities, which can be easily derived from technical documentation or the verbalised experiences of workers and operators. The KB is then utilised to generate executable plans with a high degree of predictability and robustness.\nSpecifically, this manuscript introduces a novel framework for knowledge generation, management, and planning in multi-agent systems, which: i) employs a semi-automatic procedure that leverages LLMs to populate a Prolog-based KB ; ii) enables the seamless generation of plans incorporating temporal parallelism, thus allowing multiple agents to execute concurrent actions; iii) automatically translates the generated plan into the widely used"}, {"title": "2. Problem Description and Solution Overview", "content": "The initial input of our framework is a text expressed in natural language containing a description of the following: 1. How a task can be accomplished by combining high-level actions. 2. The robotic resources available, along with a description of the low-level actions they are capable of performing. 3. The environment. The final objective is to generate, through an explainable process, an executable specification of the actions assigned to each robotic resource. The key requirements for the framework are as follows:\nR1: The execution of a task must be formally correct, i.e., it must accomplish the goals and adhere to the constraints derived from the natural language text.\nR2: The process must be explainable, ensuring that methods exist for human users to understand and trust the results produced by the system.\nR3: The knowledge obtained from understanding task execution through high-level actions must be reusable across different implementation scenarios (e.g., using one robot or multiple robots).\nR4: The generation of the plan must support and optimise the parallel execution of actions across the available robotic resources.\nR5: The executable specification of the plan must be compatible with ROS2, which serves as a de facto standard for the execution environment of a wide range of robotic devices.\nThe problem outlined above is addressed in this paper through a software framework depicted in Figure 1. The framework comprises the following modules:"}, {"title": "3. Background and Definitions", "content": "Classical Task Planning. A (STRIPS) classical planning problem is defined as a tuple CP = (F, A, I, G), where F is the set of fluents, A is a finite set of actions, I \u2286 F is the initial state, and G C F is the goal condition. Intuitively, a fluent is a predicate expressing a condition (e.g., on the system's state) that can evolve over time as a consequence of actions. For example, a fluent can be a predicate such as at(robot, RoomA), with an obvious interpretation. A literal is defined as a fluent or its negation. In a classical planning problem, each action a \u2208 A consists of preconditions denoted pre(a), and effects denoted eff(a), both of which are sets of literals. An action is executable if all the fluents in pre(a) are present in the current state. Once executed, the state is updated according to eff (a). The effects e f f (a) consist of a set of fluents in the form of add(l) or del(l), where the first adds the fluent I to the current state and the latter removes it. A literal 1(x) may depend on a set of variables x, which are fluents: x \u2208 F. For instance, available(A) indicates whether a generic A is available or not, but the value of A is not grounded to a specific instance. For an action a \u2208 A with preconditions pre(a) and effects eff(a), the action's variables, denoted fl(a), are defined as the set of all variables appearing in the literals of pre(a) Uef f(a). For example, if the preconditions for an action a are pre(a) = [11(A), 12(B), 13], then the set of its variables is fl(a) = {A,B}. This later allows us to identify the resources on which the action a depends. Consider the action move(robot, RoomA, RoomB) as a conclusive example. It requires, as a precondition, that the fluent at(robot, RoomA) be present in the system state. Its effects are given by del(at(robot, RoomA)) and"}, {"title": "3.1. Task Planning", "content": "Following [15, 16, 17], a temporal planning problem is defined as a tuple TP = (F, DA, I, G), with F, I and G as in the classical planning problem and with DA being a set of durative actions. A durative action a \u2208 DA is given by\ni) two classical planning actions af and a\u00ac (i.e., the start actions and the end action);\nii) an overall condition overall(a) that is true for the duration of the action;\niii) and a duration \u03b4(\u03b1) \u2208 R+ in the interval [dmin (a), dmax(a)], dmin(a) \u2264\n\u0431\u0442\u0430\u0445 (\u0430).\nIn the definition of a durable action a, a\u3134 and a\u02e7 are snap actions and are used, respectively, to set the conditions for action a to start and to finalise its effects when the action is completed. We will consistently use Greek letters (e.g., a) with reference to durable actions and latin letters (e.g., a) with reference to snap actions. A temporal plan \u03c0 = {tta\u2081,\u2026\u2026,ttan} is a set of time-triggered temporal actions ttai, where each tta; is a tuple (ti, ai, di) where ti \u2208 R+ is the starting time, a\u017c \u2208 DA is a durable action, and di is its duration. \u03c0is said to be a valid temporal plan if and only if it can be simulated, i.e., it can be executed, meaning that starting from the initial state, we apply each time-triggered action and at the end of the simulation, we obtain a state fulfilling the goal condition [8, 12, 15, 16, 17].\nState-space temporal planning is a specific approach to temporal planning. The intuition behind this approach is to combine i) a classical forward state-space search to generate a candidate plan outline; and ii) a temporal reasoner to check its temporal feasibility [15, 16, 17]. By considering the durative actions a \u2208 DA as the start and end snap actions, one can generate an abstract classical problem, which is then solved using any state-space search. The search extracts a classical plan and then checks if the associated temporal network is consistent; then a time-triggered plan can be computed, and the search stops once a solution has been found. Otherwise, the search continues by computing another classical plan until either the search proves that the problem has no solution or the search bumps into a temporally"}, {"title": "3.2. Temporal task planning.", "content": "Our approach extends the standard temporal task planning problem, introducing a novel formalization that we define as Mapped Temporal Task Planning. This problem is characterized by the tuple TP = (F, DA, I, G, K, M), where:\nF is the set of all fluents;\nDA = DAHU DAL is the set of durative actions, distinguished in high-level (DAH) and low-level temporal actions (DAL), with DAL\u2229DAH =\n\u00d8;\nICF is the initial state;\nGCF is the final state;\nKC F represents the set of grounding predicates;\nM \u2286 U DAH \u00d7 DA with N \u2265 1 denotes the set of mappings.\ni=1..N\nThis formulation differs from standard temporal planning in three key aspects:\n1. We introduce the set K \u2286 F, which encapsulates grounding knowledge, i.e., information assumed to remain invariant during plan execution. For instance, a grounded predicate such as HasManipulator(Agent1) signifies that Agent1 is endowed with a manipulator.\n2. We distinguish between high-level actions (DAH) and low-level actions (DAL). Conceptually, high-level actions represent abstract tasks (e.g., moveBlock(BlockA, LocA, LocB)), whereas low-level actions encode the concrete steps required to execute these tasks (e.g., grasp(Arm1, Block)).\n3. We introduce the mappings M \u2286 U DAH \u00d7 DA\u2081 with N > 1. A\ni=1..N\nhigh-level durative action a is said to be an abstraction of a sequence (\u03b11, ..., \u03b1\u03bd) if the following property holds: If a \u2208 DAH is executable in a states, and results in a state sa, then for any states s' and sa such that sss' and sa \u2286 s'a, the sequence (\u03b1\u2081, ..., \u03b1\u03bd) is executable in s' and leads to s'a.\nThe set of mappings M is defined as the subset of MC Ui=1..N DAH \u00d7\nDA with N > 1 made of the elements (\u03b1, (\u03b11, ..., \u03b1\u03bd)) such that a is an abstraction of (a1, ..., \u03b1\u03bd). In formal terms:\nM = {(\u03b1, (\u03b11, ..., \u03b1\u03bd))|\u03b1 \u2208 DAH,\u2200i, ai \u2208 DAL, N \u2265 1, \u03b1\nis an abstraction for (\u03b11, ..., \u03b1\u03bd}}\u02d9"}, {"title": "3.3. Mapped Temporal Task Planning.", "content": "For any element m = (a, (a1, ..., \u03b1\u03bd)) \u2208 M, we denote by m(a) the sequence (\u03b11, ..., \u03b1\u03bd).\nFor example, consider a high-level action a\u017c mapped to a sequence of low-level actions aj, ak, where i \u2209 {j, k}, with the mapping m(ai) = (\u03b1j, \u03b1\u03ba). This mapping can also be expressed in terms of snap actions: m(air) =\n, indicating that the mapping is applied when a\u017c starts, and that ai should terminate only when all actions in the mapping have completed.\nAs in standard temporal planning, a feasible plan for mapped temporal task planning consists of a set of durative actions such that the goal state is reached from the initial state, through simulation, i.e., by applying the durative actions in the correct order, the system transitions from the initial state to a state that satisfies the goal conditions.\nFinally, as part of the set of fluents (F), we also define a set of resources RCF, which in this work describe the agents that can carry out a task. This will allow us later to set up a MILP problem to parallelize tasks for multiple agents and shrink the makespan of the plan.\nTo simplify notation, we will henceforth use the term \u201caction\u201d to refer to \"durative actions,\u201d unless explicitly stated otherwise."}, {"title": "3.4. Prolog", "content": "Prolog is a logic-based programming language commonly utilized for knowledge representation and symbolic reasoning. In Prolog, a KB can be defined as a collection of facts and rules, which can be queried to evaluate the satisfiability of more complex conditions. Within robotics, Prolog is a useful tool for encoding knowledge about robots, their actions, and the environment in which they operate. This programming language has also shown great potential in task planning [5] and has gained interest when combined with natural language processing, as this integration facilitates human-robot interaction [6, 7].\nIn the following, we provide an overview of Prolog's semantics and its operational principles. For a detailed explanation of Prolog semantics and the specifics of the SWI-Prolog implementation, we refer the reader to [18].\nIn Prolog, the order of predicates within the KB significantly affects execution. When a query is made, the interpreter evaluates the predicates in the sequence in which they appear. To demonstrate this, consider the following example. Suppose the KB includes these facts listed in this order:\navailable(agent2) and available(agent1). If the query available(X)"}, {"title": "3.5. Large Language Models", "content": "LLMs are a class of AI models aimed at natural language processing. They are often built upon transformer networks [19], which utilise self-attention mechanisms to better understand the context of words in a sentence. They are typically trained with enormous amounts of data and have hundreds of billions of parameters, which can also be fine-tuned for the task in which they are employed [20, 21]. Thanks to their ability to generalise and understand the context in which they are used, they have gained increasing relevance in recent years. LLMs have been applied to a growing number of different fields, from healthcare [22] to planning [23], also demonstrating their limitations [24]. In fact, while LLMs excel at learning complex patterns and information from vast training data, they rely primarily on statistical associations. They do not possess genuine inferential reasoning capabilities and, consequently, LLMs struggle when confronted with tasks different from the data they were trained on. Despite this, they can provide acceptable starting points for further refinements. Since they are trained on very general knowledge, it is also important to instruct LLMs on how to provide the output or solve some particular tasks that they are unaware of. Some of the most common techniques are:\nFew-shot learning [25]: A series of examples in the form of QAs is passed to the LLM as input, allowing the LLM to understand how it should answer.\nFine-tuning [26]: a more complex and complete training algorithm, which enables the user to generate a dataset to pass to the LLM in order to re-train the last layers of the neural network, enabling a more accurate output."}, {"title": "3.6. LLMs are a class of AI models", "content": "Chain-of-Thought (CoT) [27]: similar to few-shot learning, it enables the user to pass a series of examples with also an explanation of the solution improving the LLM's \"reasoning\" abilities."}, {"title": "4. Knowledge-base Generation", "content": "The Knowledge Management System module (KMS), is in charge of taking the natural language description of both the environment and the actions that the agents can do, and convert them to a Prolog KB using a LLM. The KB contains all the necessary elements to define the mapped planning problem introduced in the previous section.\nThe framework works by considering a high-level and a low-level knowledge-base. For this reason, the input descriptions are also split into high-level and low-level. The former captures more abstract concepts, e.g., complex actions such as move_block or the objects that are present in the environment. The latter captures more concrete and physical aspects of the problem, e.g., the actions that can be actually carried out by the agents such as move_arm or the positions of the blocks. An example of this division can be seen in Section 4.1.\nThe knowledge-base is divided in the following parts:\nGeneral KB (K): contains the grounding predicates, both for the high-level and low-level. These predicates describe parts of the scenario or of the environment that do not change during execution. For example, the predicate wheeled(a1), which states that robot a1 has wheels, should be part of the general KB and not of the state.\nInitial (I) and final states (G): they contain all the fluents that change during the execution of the plan. This could be, for example, the position of blocks in the environment.\nHigh-level actions (DAH): each high-level action predicate is written as:"}, {"title": "5. Plan Generation", "content": "In this section, we describe how the framework uses the information from the KB to generate a task plan for multiple agents. Generation takes place in three steps: 1. Generation of a total-order (TO) plan, 2. extraction of a partial-order (PO) plan and of the resources, 3. solution of a MILP problem to improve resource allocation and reducing the plan makespan by exploiting the possible parallel executions of actions."}, {"title": "5.1. Knowledge-base Generation", "content": "A total-order plan is a strictly sequential list of actions that drives the system from the initial to the goal state. The algorithm used to extract a total-order plan is shown in Algorithm 1 and consists of two distinct steps:\nidentify a total-order plan for high-level actions, and\nrecursively map each high-level action to a sequence of actions with a lower level until they are mapped to actions corresponding to the APIs of the available robotic resources.\nThis enables the extraction of total-order plans that are consistent with the KB provided, and we reduce the computational cost of checking all the possible actions at each time step. The TO_PLAN function is the main function, which takes the initial and final states, and it inspects which actions can be executed given the current state. The select_action function selects the"}, {"title": "5.2. Total-Order Plan Generation", "content": "The algorithm starts from the initial state and from the first action in the KB, which in this case is the one shown in Section 4.1. The algorithm takes the grounding predicates in this case:\nagent (Agent), pos(X1, Y1), pos(X2,Y2), block(Block)\nand checks whether there is an assignment of predicates from the knowledge-base that satisfies them. For example, the predicate pos(1,1) satisfies pos (X1,Y1). Not only this, but since the predicates in this list are grounded w.r.t. the KB, one can also check some conditions. For example, if we were to assign the values to the previous predicates, it can happen that X1 = X2 and Y1 = Y2, which is useless for an action that moves a block from one position to another. By adding the following predicates, we can ensure that the values are different:"}, {"title": "5.3. Partial-Order Plan Generation", "content": "The next step is to analyse the total-order plan in search of all possible causal relationships. This is done by looking for actions that enable other actions (enablers). In addition, we extract all the resources that can be allocated and used for the execution of the task. This step will be important for the next phase of the planning process, the MILP problem, in which the resources will be re-allocated allowing for shrinking the makespan of the"}, {"title": "5.4. Partial-Order Plan Optimization", "content": "The last part of the planning module, shown in Figure 1, is the optimisation module which allows for shrinking the plan by scheduling the task (temporal plan) and allocating the resources. In order to do this, we instantiate a MILP problem, the solution of which must satisfy constraints ensuring that we are not violating precedence relationships and invalidating the obtained planned.\nWe start by taking the work from [29], in which the authors describe how it is possible to obtain a plan with lower makespan by reordering some tasks. In particular, we adopt the following concepts from [29]:"}, {"title": "5.5. Partial-Order Plan Optimization", "content": "Let f(l) = {a \u2208 DA|l \u2208 eff(a)} be the set of actions that achieve a literal l, and\nlet p(l,a,r) =a <r> \u2227 (ai <aVai > r) be the temporal\nai\u2208f(l)\\{a,r}\nconstraint stating which is the last achiever a of an action r for a literal l.\nThe constraints that must hold are the following:\nV p(l, aj, a).\naj\u2208f(l)\\{a}\nWhich states that at least an action with effect I should occur before a.\n\u039b aj Ef (l)\np(l, aj, a) \u2192\n\u039b\naj\u2208f(-1)^l\u2208pre(a)\nat\u2208f(-1)\\{a}\n(at <aj Vat > a)\n((aj <a) V (aj > a-)).\n))))\nWhich state that between the last achiever a; of a literal I for an action a and the action a there must not be an action at negating said literal. This condition is also enforced by Equation 6 that constrains actions negating the literal to happen before the action a has started or after it has finished.\nNotice though that in this work, the authors have considered achievers and not enablers. The difference is that an action a; is an achiever of ai if a; adds a fluent I that is needed by aj. Enablers instead consider the case in which fluents are also removed. Since these constraints only consider achievers and not enablers, we need to extend them. We redefine the previous as:\nlet f(l) = {a \u2208 DA|add(l) \u2208 ef f(a)} be the set of actions that achieve a literal l, and\nlet f(\u00acl) = {a \u2208 DA|del(l) \u2208 ef f(a)} be the set of actions that delete a literal l, and\nU\nlet F(l) = f(l) \u222a f(\u00acl) be the union set of f(l) and f(\u00acl), and\nlet p(l, a, r) = a<r> \u2227 (ai < avai> r) be the last enabler a\nai\u2208F(l)\\{a,r}\nof an action r for a literal 1.\nConsequently, we need to:"}, {"title": "5.6. Partial-Order Plan Optimization", "content": "revise Equation 4 to include all enablers:\nVp(l, aj, a).\naj\u2208F(l)\\{a}\nadd two constraints similar to Equation 5 and Equation 6 to ensure that a predicate that was removed is not added again before the execution of the action:\np(l, aj, a) \u2192\n\u039b\naj Ef (l)\nat\u2208f(l)\\{a}\n(at <aj Vat > a)\n\u039b\naj Ef (l)^(\u00acl)\u2208pre(a)\n((aj <a+) V (aj > a-)).\nThe second aspect of the MILP problem concerns resource allocation. Indeed, as stated before, there are some predicates that are parameterised on resources, e.g., available(A) states whether an agent A is available or not, but it does not ground the value of A. One possibility would be to allocate the resources using Prolog, as done in [11], but this choice is greedy since Prolog grounds information with the first predicate that satisfy A. To reduce the makespan of the plan and improve the quality of the same, we delay the grounding to an optimisation phase, leaving Prolog to capture the relationships between actions.\nAs a first step, we are also going to assume that all the actions coming from a mapping of a higher-level action and that are not mapped into lower-level actions shall maintain the same parameterised predicates as the higher-level action. So the constraint in Equation 10 must hold.\n\u039b\naj\u2208m(az)/m(aj)\u2260M\n\u039b\np(xi)\u2208pre(ai)^p(xj)\u2208pre(aj)\nXi = X j\nMoreover, for these constraints, we will consider only predicates that are part of the set K, that is predicates that are not resources R\u2229 K = 0.\nThe objective now is three-fold:\nidentify a cost function,\nsummarise the previous constraints, and\nconstruct a MILP problem to be solved."}, {"title": "5.7. Partial-Order Plan Optimization", "content": "In this work, the first point is straightforward: we want to minimise the makespan, i.e., the total duration required to complete all tasks or activities.\nFor the second point, we are trying to find a way to put the previous constraints, Equations (2), (3) and (5) to (10) in a compact formulation or structure. We opted to extract the information regarding the enablers using Prolog and to place it into a N \u00d7 N matrix C, where N is the number of actions and each cell Cij is 1 if az is an enabler of aj (without considering resources), 0 otherwise.\nWe now need to address the resource allocation aspect, specifically, how to distribute the available resources R among the various actions. When performing this task, there are primarily two factors to consider:\nA resource cannot be utilised for multiple actions simultaneously.\nIf two actions share the same resource, they must occur sequentially, meaning one action enables the other.\nFor the first factor, we need to make sure that, for each resource type r\u2208 R, the number of actions using the resource at the same time must not be higher than the number of resources of that type available, as shown in Equation 11.\nVt \u2208 {to, tEND}, |r| \u2265\u2211t\u2208 {air, Ai-}^ (\u2203 l(x) \u2208 pre(ai)|r \u2208x).\n\u03b1 \u0395\u03a4\u039f\nThe second factor must instead be merged with also the precedence constraints embedded in C. In particular, we want to express that actions ai, aj are in a casual relationship if Cij = 1 or if they share the same resource. This can be expressed with the following constraint:\nCij V\u2203r \u2208 R : r \u2208 fl(az) \u2227r \u2208 fl(a;)\nNote that fl(a) was defined in the problem definition paragraph and represents the set of variables and literals used by the predicates in the preconditions of a.\nFinally, we need to set up the MILP problem that consists in finding an assignment of the parameters, of the actions' duration and of the causal relationships, such that the depth of the graph G representing the plan is minimised. This problem can be expressed as shown in Equation 13."}, {"title": "5.8. Plan Optimization", "content": "min\nP.T\nTEND\ns.t.\nCij V\u2203r \u2208 R : r \u2208 fl(az) \u2227r \u2208 fl(aj),\nVt \u2208 {to, tEND},\n\r\\> \u2211 (t\u2208 {ait, ai\u00ac} \u2227\u2203 l(x) \u2208 pre(ai)|r\u2208 x).\n\u03b1\u0395\u03a4\u039f\nAs mentioned before, the MILP part is implemented in Python3 using OR-Tools from Google. The program also checks the consistency of the PO matrix C, by making sure that all the actions must have a path to the final actions. The output of the MILP solution is basically an STN, which describes both the causal relationship between the actions and also the intervals around the duration of the actions. The initial and final nodes of the STN are factitious as they do not correspond to actual actions, but they simply represent the start and the end of the plan. The STN is extracted by considering the causal relationship from the C matrix taken as input, and by adding the causal relationship given by the resource allocation task. Once we have the STN, we can extract a BT, which can then be directly executed by integrating it in ROS2."}, {"title": "5.9. Plan Optimization", "content": "As we said at the end of subsubsection 5.2.1 on the running example, that particular plan is not optimisable as the actions are executed in sequence. Let's then consider a slight modification, which consists in finding a plan to move the two blocks in two new positions instead of stacking them in one position. We also have a new agent that can be used to carry out part of the work. Our new plan and actions' enablers are the following one:\n[0] init()\n[1] move_table_to_table_start(a1, b1, 1, 1, 1,2), [0]\n[2] move_arm_start(a1, 1, 1), [0,1]\n[3] move_arm_end(a1, 1, 1), [0,1,2]\n[4] grip_start(a1), [0,1,2,3]\n[5] grip_end(a1), [0,1,2,3,4]\n[6] move_arm_start(a1, 1, 2), [0,1,2,3,4,5]\n[7] move_arm_end(a1, 1, 2), [0,1,2,3,4,5,6]\n[8] release_start(a1), [0,1,2,3,4,5,6,7]\n[9] release_end(a1), [0,1,2,3,4,5,6,7,8]\n[10] move_table_to_table_end(a1, b1, 1, 1, 1, 2), [0,1,2,3,4,5,6,7,8,9]"}, {"title": "6. Behavior Tree Generation and Execution", "content": "The conversion from STN to BT is taken from [30]. We summarize it here and refer the reader to the main article.\nAn STN is a graph with a source and a sink, which can be artificial nodes in the sense that they represent the start and the end of the plan. Each node can have multiple parent and multiple children. Having multiple parents implies that the node cannot be executed as long as all the parents haven not finished and, whereas, having multiple children implies that they will be executed in parallel.\nWith this knowledge we can extract a behavior tree, which is a structure that, starting from the root, ticks all the nodes in the tree until it finishes the last leaf. Nodes in the tree can be of different types:\naction: they are an action that has to be executed;\ncontrol: they can be either SEQUENCE or PARALLEL and state how the children nodes must be executed;\ncondition: they check whether a condition is correct or not;\nThe ticking of a node means that the node is asked to do its function, e.g., if a SEQUENCE node is ticked, then it will tick the children one at a time, while if a condition node is ticked, it will make sure that the condition is satisfied before continuing with the next tick.\nThe algorithm to convert the STN to a BT starts from the fictitious initial node (init), and for every node it checks:\nThe number of children: if there is only one child, then it is a SEQUENCE node, otherwise it is a PARALLEL node.\nThe number of parents: if there are more than one parents then the node must wait for all the parents to have ticked, before being executed.\nThe type of the action: if it is a low-level action, then it is inserted into the BT for execution, otherwise it will not be included."}, {"title": "7. Experimental Validation", "content": "In this section, we first present the implementation details of the framework, followed by a description of the experiments conducted and the results obtained. We then discuss the scalability of PLANTOR before concluding with a final discussion on the proposed framework.\nThe different parts have been developed and devised to ensure modularity, efficiency, and scalability. The implementation process involved a careful selection of algorithms and data structures to optimize performance. In"}, {"title": "8. Related Work", "content": "In this section, we are going to discuss, to the best of our knowledge, the current state of the art and highlight the gap we are filling.\nKnowledge representation is an essential component that endows robots with the cognitive abilities necessary to autonomously execute tasks and make informed decisions [35, 36]. This capability underpins the development of systems that can simulate common-sense reasoning in robotic applications. Typically, knowledge systems rely on ontologies to formally describe discrete pieces of information and the relationships among them. In this context, the OpenRobots Ontology (ORO) [37] is designed to store symbolic-level knowledge and events by transforming previously acquired symbols into interconnected concepts. Built upon the framework of semantic triples [38], ORO facilitates a server architecture where information can be both pushed and pulled, thereby supporting dynamic knowledge management.\nOntologies are frequently tailored to specific domains. For example, the Ontology for Robotic Orthopedy Surgery (OROSU) [39] is dedicated to the medical domain, integrating healthcare ontologies with robotic systems to represent the critical knowledge required during surgical interventions. Similarly, the Worker-cobot ontology [40] focuses on industrial applications, supporting collaborative tasks in shared, closed environments through a framework that leverages multi-agent systems and business rules.\nIn addition to these domain-specific systems, advanced knowledge processing frameworks such as KnowRob [41], now in its second version [42], demonstrate a more comprehensive approach by incorporating environmental data into the reasoning process. Unlike systems that rely solely on deductive closure computation, such as ORO, KnowRob integrates inferential reasoning via Prolog, thus enabling more dynamic and context-aware knowledge management. Furthermore, KnowRob2 expands its capabilities by integrating semantic web information and utilizing a game engine to facilitate the"}, {"title": "8.1. Related Work", "content": "learning of action-related knowledge. This integration allows the system to \"reason with its eyes and hands,\" meaning that it can construct a realistic representation of its environment. Consequently, KnowRob2 is able to abstract and generalize common knowledge from experiential data, thereby enhancing its adaptability to novel situations. One of the main limitations of systems like KnowRob2 is related to the generation of its knowledge base, which involves complex syntactical structures that complicate the maintenance and scalability of the system, potentially hindering efficient inference and integration of new data. Large Language Models (LLMs) can address this limitation by leveraging their ability to parse and generate natural language, thereby producing more flexible and context-aware representations that reduce the reliance on rigid, manually defined syntactic structures in knowledge base generation.\nVarious approaches leveraging LLMs to construct generalizable planning domains have been proposed, demonstrating"}]}