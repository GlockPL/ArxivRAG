{"title": "Learning Plasma Dynamics and Robust Rampdown\nTrajectories with Predict-First Experiments at TCV", "authors": ["Allen M. Wang", "Alessandro Pau", "Cristina Rea", "Oswin So", "Charles Dawson", "Olivier Sauter", "Mark D. Boyer", "Anna Vu", "Cristian Galperti", "Chuchu Fan", "Antoine Merle", "Yoeri Poels", "Cristina Venturini", "Stefano Marchioni", "the TCV Team"], "abstract": "The rampdown in tokamak operations is a difficult to simulate phase during which the plasma is often pushed towards multiple\ninstability limits. To address this challenge, and reduce the risk of disrupting operations, we leverage recent advances in\nScientific Machine Learning (SciML) to develop a neural state-space model (NSSM) that predicts plasma dynamics during\nTokamak \u00e0 Configuration Variable (TCV) rampdowns. By integrating simple physics structure and data-driven models, the\nNSSM efficiently learns plasma dynamics during the rampdown from a modest dataset of 311 pulses with only five pulses\nin the reactor relevant high performance regime. The NSSM is parallelized across uncertainties, and reinforcement learning\n(RL) is applied to design trajectories that avoid multiple instability limits with high probability. Experiments at TCV ramping\ndown high performance plasmas show statistically significant improvements in current and energy at plasma termination, with\nimprovements in speed through continuous re-training. A predict-first experiment, increasing plasma current by 20% from\nbaseline, demonstrates the NSSM's ability to make small extrapolations with sufficient accuracy to design trajectories that\nsuccessfully terminate the pulse. The developed approach paves the way for designing tokamak controls with robustness to\nconsiderable uncertainty, and demonstrates the relevance of the SciML approach to learning plasma dynamics for rapidly\ndeveloping robust trajectories and controls during the incremental campaigns of upcoming burning plasma tokamaks.", "sections": [{"title": "1 Introduction", "content": "Upcoming burning plasma tokamaks, such as SPARC2 and ITER\u00b3, require reliable plasma control to avoid operational delays\nand machine damage due to plasma disruptions, a challenge that will only increase for tokamak pilot plants like ARC5 and\nDEMO. Given this risk becomes intolerable at high plasma current, Ip, and stored energy, W\u0142ot, a key mitigation strategy is\nto de-energize the plasma by performing a rampdown of the plasma current, but doing so typically pushes the plasma closer\nto multiple instability boundaries7\u20139. Figure 1 depicts the phases of a tokamak pulse, beginning with rampup of the plasma\ncurrent to the steady-state flattop phase, and ending with a rampdown. Notably, Figure 1 also shows an example of a quantity\ncorrelated with plasma instability growing during the rampdown phase, a challenge which motivates the algorithmic design of\nsafe rampdown trajectories. This challenge is especially acute in reactor relevant high performance plasmas, which operate\nclose to instability boundaries to achieve the high normalized plasma density, typically quantified by the Greenwald fraction\nfGw 10, and normalized plasma pressure, \u1e9e11\u06c1, necessary for economical energy production. The importance of designing robust\nrampdowns for reactor relevant fusion plasmas is highlighted by the recent record-breaking high performance campaign at the\nJoint European Torus (JET), for which most disruptions occurred during the termination phase12. For the baseline scenario, a\n\u2248 15% increase of the plasma current, from 3MA to 3.5MA, increased the disruptivity considerably from \u2248 20% to \u2248 50%12.\nThis challenge motivates the development of tools that can rapidly adapt rampdown trajectories to manage disruptivity as fusion\nperformance is increased.\nDue to the stochasticity of plasma dynamics, hardware and control imperfections, and the possibility of off-normal-events\n(ONEs), it is important to design scenarios, trajectories, and controllers with robustness to distributional uncertainty in the\ndynamics of the plasma. The biggest barrier to designing for robustness in this context is the difficulty of simulating plasma\ndynamics during the highly transient rampdown phase, during which multiple physical quantities, many of which are not"}, {"title": null, "content": "well-modeled with a principles-based approach, can change drastically. Due to this challenge, prior rampdown studies using\nexisting simulators7,8,13\u201316 typically make assumptions on important effects like the confinement regime transition which is\nsubject to significant uncertainty. These simulation limitations motivated recent experiments at DIII-D designing rampdown\ntrajectories with black box Bayesian Optimization on three control variables, which achieved improvements in the plasma\ncurrent at time of termination. This experiment showed relatively small adjustments can make an out-sized impact; however,\nreported pulses, also known as shots, were all at low performance, and a predictive model-based approach is desired for\nupcoming tokamaks. These limitations motivate the development of models that efficiently learn difficult to simulate dynamics\nfrom experimental data, and which are massively parallelizable across uncertainties to enable robust model-based design of\ntrajectories.\nTo address these challenges, this work takes a data-driven approach, leveraging recent advances made by the Scientific\nMachine Learning (SciML) community17\u201319 and new machine learning frameworks, namely JAX20, which enable the training\nof dynamics models that combine physics-based equations with data-driven models. A data-driven approach is not without\nprecedent; aircraft flight control and simulation primarily utilize data-driven models of aerodynamics derived from flight test\ndata in lieu of computational fluid dynamics (CFD)21,22, often with classical linear state-space models (SSMs)23. While prior\nworks on learning plasma dynamics using unstructured neural networks required large datasets, often spanning thousands of\nshots24\u201326, we gain sample efficiency by embedding physics structure into a Neural State Space Model (NSSM)27,28. This\nmodel was trained to generate sufficiently accurate predictions using a modest amount of data, with 311 rampdowns at low\nperformance and only five shots with incomplete rampdowns in the relevant high performance regime, with \u1e9eN > 2 and near\nthe density limit. The model is capable of simulating \u2248 104 rampdown trajectories per second on a single A100 GPU, enabling\nthe usage of the NSSM in a reinforcement learning (RL) training environment.\nThe RL environment is massively parallelized to design trajectories with robustness to uncertainties, including the initial\nconditions of the plasma and its time varying dynamics. In contrast with prior works on applying RL approaches to fusion, we\nleverage its capabilities for offline design of robust trajectories, which is more readily applicable to the safety-critical settings\nof upcoming tokamaks than RL for real-time control, as was done in prior works29,30. After a small number of initial trial\nshots, the plasma reliably terminated at low plasma current and stored energy for five consecutive high performance shots,\nwith statistically significant improvements relative to baseline, although we encourage caution in interpreting the statistics\nof the result due to the small sample size. As a test of the viability of this approach for performing small extrapolations in\nan incremental high performance campaign, which upcoming tokamaks like SPARC and ITER will undergo, we design a\nrampdown trajectory and perform a predict-first experiment by increasing the plasma current by 20%, from 140kA to 170kA, for\na high \u1e9en plasma near the density limit, a scenario for which zero shots of rampdown data exists for TCV. In this extrapolation\ntest, we a priori predict the dynamics of key quantities to within sufficient accuracy to successfully terminate the plasma on\nboth attempts.\nThe paper is organized as follows. We begin with an overview of the experiment and report the achieved rampdown\nimprovements, as measured by the key figures of merits of plasma current Ip and stored energy W\u0142ot at time of plasma termination.\nThen, an overview of the NSSM is provided along with medium scale validation metrics demonstrating its predictive power.\nThis is followed by an analysis of two shots in the experiment demonstrating the importance of accounting for control errors in\ntrajectory design for preventing a class of disruptions known as vertical displacement events (VDEs). Then, an analysis of\n140kA shots in the experiment shows how incremental re-training between run days resulted in rampdowns that are both faster\nand less disruptive. Results from the predict-first extrapolation test are reported, demonstrating the ability of the NSSM to make\nsmall extrapolations. Finally, we discuss future work and implications for upcoming tokamaks like SPARC and ITER."}, {"title": "2 Results", "content": "The reported experiment was conducted as a part of the 2024 TCV integrated control, high performance experimental campaign.\nFlattop plasmas operated at a high performance of \u1e9ey > 2.0 and near the density limit with a highly elongated diverted geometry\nwith x \u2248 1.6 and 995 \u2248 4. Initial shots in the experiment operated at Ip = 140 kA, henceforth known as the baseline high\nperformance (HP) scenario, with a final extrapolation test at Ip = 170 kA. Successful rampdowns from these scenarios require\ncareful management of multiple plasma instability limits that can be exacerbated by details of the plasma trajectories. To name\na few considerations, an overly fast reduction in plasma current increases the Greenwald fraction, prompting a density limit\nevent, managing the relatively high elongation diverted geometry introduces risks of a vertical displacement event (VDE),\nand fast reductions in elongation and minor radius can decrease the safety factor 995, exciting magnetohydrodynamic (MHD)\ninstabilities. Managing the density limit in this scenario is a particular challenge for fast terminations, as the relatively long\nparticle confinement time-scale is a major constraint on the speed of the rampdown.\nTo address the problem, a NSSM dynamics model was trained on a modest dataset of past rampdowns, which contains only\n5 incomplete rampdowns in the relevant high performance parameter space, as shown in Figure 2A-B. This NSSM is then used\nin a reinforcement learning (RL) environment to optimize a reward function, designed to minimize time to a goal plasma current\nof 40kA and stored energy of 0.5kJ without disrupting, as shown in Figure 2C. The action space was chosen to be plasma\ncurrent, Ip, shaping parameters and aminor and neutral beam injection (NBI) power PNBI. User-specified constraints were\nset on the Greenwald fraction fGw, safety factor q95, vertical instability growth rate Yvgr, and poloidal beta \u1e9ep. The optimized\naction trajectories were then manually programmed into the TCV plasma control system (PCS). The details of the reward\nfunction, chosen limits, and PCS programming process are further discussed in the Methods.\nEvery shot involved in the experiment is shown in Figure 2D, showing improvements on the normalized Ip and W\u0142ot at time\nof plasma disruption over the course of the experimental runs. The un-optimized baseline rampdown trajectory for this scenario\ndisrupted at relatively high current and stored energy in #81101 and #81102 at Ip \u2248 80kA and Wtot \u2248 4kJ. The experiment\nproceeded iteratively, with re-training of the NSSM on new data and trajectories done after shots #81635, #81745,#81751, and\n#81830. A preliminary optimized trajectory was deployed in TCV #81635, which reached the goal Ip and W\u0142ot before disrupting,\nbut post shot analysis showed poor radial control and tracking of the target shape, which was determined to be due to a legacy\nsoftware issue detailed in Figure 14 in the Supplementary Information. Shots #81741 and #81745 were spent resolving this\nissue, with it properly resolved in #81751, as shown in Figure 14. #81751 still disrupted due to a VDE, which was found to be\ndue to a large sensitivity of Yvgr to small control errors in the inner gap. After #81751, an uncertainty distribution on gap errors\nwas added to the RL training environment to gain robustness to this uncertainty, with subsequent shots experiencing similar\ncontrol errors but without similar increases in Yvgr, demonstrating the importance of designing trajectories with robustness to\nreal-world uncertainties, as further discussed in Section 2.3.\nFor the final run-day, trajectories were re-optimized, and predictions of the plasma dynamics were generated a priori for\nboth two reprisals of the baseline high performance scenario, but also for the extrapolation test. All four shots for both scenarios\nterminated successfully below the goal Ip, with the baseline scenarios realizing both faster and non-disruptive trajectories\nrelative to baseline and successful a priori predictions of plasma dynamics for both scenarios.\nStatistical significance of control results in fusion is typically difficult to establish due to the scarcity of experimental time\nand relevant data-points. This experiment also faces this, given the rampdown experiment involved only nine shots, two of\nwhich were dedicated to debugging a legacy software issue, with only five rampdowns in the database near the relevant high\nperformance regime with \u1e9eN > 2. We use these five shots as our control set and define two test sets: one with the debugging\nshots and one without. As shown in Figure 3, the Mann-Whitney U test33 shows a statistically significant improvement in Wtot,\n(p < 0.05), at time of plasma termination of the experimental rampdowns for both definitions of the test set. Improvements\nin Ip are only statistically significant when we do not include the debugging shots. While the results of this statistical test\nare encouraging, we urge caution in its interpretation given the small sample sizes involved, and the fact that tokamaks are\nhighly drifting distributions in practice, with uncontrolled variables such as wall conditioning making a meaningful impact on\nexperimental outcomes."}, {"title": "2.3 Preventing VDEs by Designing for Robustness to Control Error", "content": "The experiment also clearly highlighted the importance of accounting for control errors when optimizing rampdown trajectories.\nThe rampdowns for the initial shots of the experiment were designed without accounting for the impact of uncertainty in shape\nerrors on the vertical growth rate Yvgr. This uncertainty had a highly sensitive effect in TCV #81751, which ended in a VDE.\nEven though the Yvgr at zero control error was tolerable, a small increase in the deviation of the high-field-side (HFS) gap, 8HFS,\nfrom the planned value caused an order-of-magnitude increase in Yvgr, as shown in Figure 6.\nAfter #81751, an uncertainty distribution on the gap errors was added to the RL training environments to encourage the\noptimization of trajectories that succeed despite this control error. The positive impact of optimizing for robustness to this\nuncertainty was realized with TCV #82875, which experienced similar control errors at similar HFS gap values, but without the\nlarge increase in Yvgr. This increased robustness is likely due to a change in the minor radius trajectory, which decreased the\nlow-field-side (LFS) gap, thus increasing the stabilizing effect of the LFS wall whenever the plasma experiences an unexpected\noutward shift. Prior work at TCV has shown the importance of managing these gaps for vertical stability35. The importance of\naccounting for this uncertainty is further highlighted by the fact that #82875 is more stable in practice than #81751, despite a\nhigher elongation, the quantity most typically associated with vertical instability. In fact, we can see that #81751, with its lower\nelongation, does have a lower Yvgr than #82875 when gap error is near zero, but it is also much more sensitive to control errors.\nThis result demonstrates that the optimal trajectory for minor radius can differ, with significant consequence, once real-world\nerrors and uncertainties are accounted for. Given that existing studies on rampdown design and optimization for ITER36 and\nDEMO13 find solutions involving large reductions in minor radius, these experimental results motivate the further advancement\nof techniques that enable trajectory design with robustness to uncertainty."}, {"title": "2.4 Improving Terminations by Incremental Re-training", "content": "Both the NSSM and trajectories were incrementally re-trained on newly generated data from experimental run-days, which\nresulted in more robust and faster rampdowns for the baseline high performance scenario, as shown in Figure 7. The speed\nof the model enabled re-training of both the model and trajectories in fewer than ten hours total on a single A100 GPU. The\nun-optimized solution in #81101 involved a NBI power rampdown while keeping constant plasma current, to allow for a\ndecrease in density to avoid the Greenwald limit, a solution which the RL approach initially decided on as well, as shown\nwith #81751, with an even more conservative current ramp and introducing a reduction in K. As discussed in 2.3, this shot\nresulted in a VDE, and, with the introduction of an uncertainty distribution on gHFS, the solution in #81830 resulted in less of a\nreduction in the minor radius aminor, which helped eliminate the Yvgr spikes. Subsequent dynamics model training and trajectory\noptimization resulted in a solution in #82876 which allows for an immediate reduction in Ip without running into a density\nlimit, highlighting the ability for the workflow to assist in gradually making improvements. All optimized trajectories involved\na fast initial drop in PNBI, followed by a slower ramp phase, although the rates and critical points for the transition differed from\nshot to shot."}, {"title": "2.5 Predict-First Results for the Extrapolation Test", "content": "Learned dynamics models need not extrapolate far out of distribution to assist with control and trajectory design for net energy\ntokamaks, as their operations will involve incrementally moving towards higher performance. Thus, they simply need to be\nable to make reasonable predictions under small extrapolations, and rapidly learn from experiment with as few shots of data\nas possible. To test the viability of the developed approach in such a setting, we used the learned dynamics model to design\ntrajectories for the extrapolation test scenario, for which zero shots of rampdown data exists in our training dataset for TCV,\nand generated a priori predictions of the distribution of plasma dynamics during rampdown.\nAs shown in Figure 8, experimental results from #82878 largely fell within this distribution, with accurate predictions of\nthe stored energy and density dynamics. Arguably the largest sources of error came from unreliable control of the plasma\nshape, contributing to errors in quantities like the rotational transform 195 = 1, and also leading to an earlier than expected HL\n995' back-transition. #82878 also started near the density limit, a challenging situation which motivated the introduction of a delay\nto the Ip ramp in the baseline scenario, but the RL algorithm was able to determine a trajectory to immediately decrease Ip,\nwhich is desirable, while keeping few roughly constant. #82877 fell further out of distribution due to a loss of NBI power, and\nthe presence of a neo-classical tearing mode (NTM) at the beginning of rampdown that did not exist in TCV #82878, as shown\nby Figure 17 in the Supplementary Information. Fortunately, these un-modeled off-normal events (ONEs) did not take the\nplasma far enough out of distribution to cause a disruption. As discussed earlier, the profile predictor was removed to help\naccelerate trajectory optimization, but post shot evaluation of the profile predictor on the OD scalars generated by the training\nenvironment, shown in Figure 9, shows reasonable agreement against experimental Thomson measurements.\nThe results from this experiment demonstrate the ability for the learned dynamics model to make small extrapolations to\nsufficient accuracy to enable the design of robust disruption-free trajectories via RL, and even the prediction misses in TCV\n#82877 further emphasize the importance of further advancing the developed methodology to design with robustness to as\nmany ONEs as possible."}, {"title": "3 Discussion", "content": "Our results demonstrate that the developed approach to learning plasma dynamics can predict the highly transient rampdown\nphase with a modest dataset and even make small extrapolations to higher performance regimes. The relative sample efficiency\nof the approach, only requiring five shots in the relevant high performance regime, indicates this may be a viable approach for\nupcoming tokamaks like SPARC and ITER, which will initially operate at low performance before incrementally increasing\nperformance. Developing robust terminations during such incremental campaigns is crucial, as highlighted by the 2020 JET\nhigh performance campaign where a 15% increase in plasma current, from 3MA and 3.5MA, raised disruptivity from \u2248 20% to\n\u2248 50%12. Prediction metrics on the validation dataset, as shown in Figure 4, shows this approach yields accurate predictions\nfor the majority of ramp-downs, but the 5% worst cases can involve large prediction errors, meriting further investigation.\nThe developed RL approach for designing robust trajectories yielded promising improvements in the plasma current and\nstored energy at time of termination, with incremental re-training improving the ramp speed. This result represents one of\nthe first successful demonstrations of trajectory design with robustness to real-world uncertainties for tokamaks, which has\nhistorically been infeasible due to the computational cost of simulation. A degree of statistical significance is shown, but\nthe sample size is still relatively small; a larger scale study would more thoroughly determine the efficacy of the approach.\nAlthough a large set of uncertainties was accounted for, detailed further in Table 4, experimental results involved additional\nuncertainties, such as the NBI failure in #82877, that still need to be addressed to further improve the robustness of trajectories.\nRobustness to hardware failure is of particular interest for future work as an exhaustive survey of disruption causes at JET has\nrevealed hardware failure as a significant contributing factor to disruptions37. It is also noteworthy that the RL designed action\ntrajectories tended to be relatively simple, suggesting that the key important ingredient is the fast and parallelized simulation\nmodel, as a human expert may be able to find similar trajectories if given access to the simulation model.\nTo improve the relevance of the developed approach to devices like SPARC and ITER, future work should model additional\nphysics like impurity accumulation and neo-classical tearing mode dynamics, both of which are difficult to simulate, partially\nstochastic, and have been found to be significant contributing factors to disruptions at JET37. Accounting for such effects that\ncan drastically change the plasma dynamics may motivate the employment of real-time adjustments to the rampdown trajectory,\nor the deployment of a library of trajectories as was done in previous simulation studies38. Applying the developed approach to\nlearning JET rampdown dynamics would also further inform the application of this approach to SPARC and ITER.\nThe developed approach also holds promise for full-shot simulation, which ongoing work is investigating39. The ability for\na neural network to predict kinetic profiles using 0D scalars, demonstrated both in this work and in prior work34, suggests a\ndata-driven approach may be sufficient for certain control tasks without principles-based transport simulation, which can be\nextremely computationally expensive and require strong assumptions on edge temperature and density. The ability to deploy\naccurate, fast, and massively parallel simulators of tokamak plasmas would likely unlock new capabilities for tokamak trajectory\nand control design, allowing for more reliable access to higher performance plasmas, and ameliorating the risk posed by plasma\ndisruptions to future tokamaks."}, {"title": "4 Methods", "content": "Learning dynamical systems from data has been a core discipline within control design for decades, including aircraft flight\ncontrol21 and simulation22, and has historically been known as system identification23,40. However, due to computational\nlimitations of the time, classical approaches have typically been restricted to linear models, often in the form of linear state-space\nmodels (SSMs):\n$\\dot{x} = Ax + Ba$ (1a)\no = Cx + Da (1b)\nWhere A, B, C, and D are the matrices to be learned from datasets of observables, o, actions, a, and, possibly, states, x. We note\nthat the controls literature typically uses the notation y in lieu of o and u in lieu of a, reflecting a difference in notation between\nthe controls and RL communities, but here we use RL notation for consistency. In the modern deep-learning learning era, this\nidea of learning dynamical systems from data was re-discovered from a different perspective, with the advent of the neural\ndifferential equation (NDE)19:\n$\\dot{X} = NN_\\Theta(X)$ (2)\nwhere it was discovered that, given datasets of x, a neural network, NNe, can be used as a system of differential equations that\nis integrated forward in time with a differential equations solver, and then adjoint back-propagation methods can be used in\nconjunction with automatic differentiation to determine the gradient of loss with respect to the network parameters (17\u201319. The\nintroduction of flexible machine learning frameworks has enabled the development of the field of Scientific Machine Learning\n(SciML) based around the core idea of extending NDEs to include physics, and other domain-specific, structure17,19. One\nextension that completes the circle with the classical linear SSM is the neural state-space model (NSSM), which re-introduces\nthe concepts of actions and observations:\nx(t) = f(x,a) (3a)\no(t) = O(x,a) (3b)\nThanks to the power of new highly flexible machine learning frameworks such as JAX and the Julia SciML ecosystem, fe and\nO can be programmed to include arbitrary combinations of neural networks, physics formulas, and even classical data-driven\nmodels such as power laws, a capability which we exploit in this work. The training process of a NSSM is shown in Figure 10,\nand involves the simulation of the NSSM forward in time using an initial state x0 and a time series of actions a0:7 from an\nexperimental database. The error of the simulation results against the experimental data is computed, and adjoint methods and\nautomatic differentiation are used to determine the gradient to reduce the loss. In this work, the differential equation solver\npackage diffrax18 is used, which includes the integration of multiple adjoint methods with the JAX automatic differentiation\nsystem, which allows backpropagation through all differential equation solvers in the package."}, {"title": "4.1.1 The Dynamics Function fe (x, a)", "content": "We begin by defining the following confinement laws:\n$\\tau_{n,pred}(x,a) = c_{n,PCP} \\frac{I_p}{|I_p|^{1/2}} c_{ne, 20}^{cnp} input NN_{conf,0}(x, a) e^{(c_{n,h} tanh PCP)h_{mode}(x,a)}$ (4a)\n$\\tau_{E,pred}(x,a) = c_{I,E} \\frac{I_p}{|I_p|^{1/2}} c_{ne, 20}^{cEIp} input \\frac{K^{c_K,E} c_{\\epsilon,E}}{|I_p|^{\\iota_{ip,E}}} NN_{conf,1}(x,a) e^{(c_{E,h} tanh PCP)h_{mode}(x,a)}$ (4b)\n$h_{mode}(x, a) = tanhHeaviside (P_{input} - c_h ne 20 \\alpha_{minor})$ (4c)\n$tanhClip(x) = tanh (\\frac{2\\kappa}{max - min} (x - \\frac{max - min}{2} + center))$ (4d)\n$tanhHeaviside(x) = \\frac{1}{2} (tanh(kx+1))$ (4e)\nwhere the parameters to be learned include all coefficients c* and neural network parameters. The laws are structured to multiply\na portion corresponding to L-mode, a neural network correction factor, and an H-mode correction factor. The L-mode term\nreflects standard confinement scalings, but with the introduction of a \u0130p, which was found to help better capture short-term\neffects of ramping plasma current. The neural network output includes a tanhClip final activation that constrains it's output\nto the range [0.75, 1.25], thus controlling the maximum adjustment the network is allowed to make. The hmode function\nincludes a tanhHeaviside function which provides a smooth transition between one to zero once Pinput falls below the learned\nback-transition threshold, which is structured to reflect the Martin scaling41. Note that the use of the hmode function output\nas a power de-activates the H-mode correction term once hmode transitions from one to zero. While, in principle, the neural\nnetwork should be able to learn the effects of H-mode implicitly, we found that adding an explicit H-mode correction factor\nhelped improve model predictions in our low-data regime. The k factor controls the smoothness of both the tanhClip and\ntanhHeaviside functions.\nThese confinement laws are integrated as a part of the following OD energy and particle balance equations, which is a model\nthat blends simple physics principles, power laws, and neural networks:\n$\\frac{dW_{tot}}{dt} = \\frac{W_{tot}}{TE,pred} +INN_{ohm,rad,0}(x, a) \u2013 \\bar{n}_{e,20}VNN_{ohm,rad,1} (x, a) + P_{NBI} + P_{ECRH}$ (5a)\n$\\frac{d(\\bar{n}_{e,20}V)}{dt} = \\frac{\\bar{n}_{e,20}}{TN,pred} + c_{NBI}P_{NBI} +c_{gas,0}\\sigma (c_{gas,1}V_{gas} +c_{gas,2})+NN_{wall} (x, a) exp (c_{wall}8_{HFS}$ (5b)\nwhere o is the sigmoid function, NNohm,rad is a network that predicts two quantities; the first is multiplied by I to serve as an\nOhmic heating term, and the second is multiplied by density and volume to serve as the radiated power term. NNwall is included\nto account for possible wall fueling effects when in a limited configuration, and is multiplied by an exponential in the HFS gap\nto de-activate it when diverted. Additional simple constants are included to account for fueling from both NBI and gas puffing.\nWe note that, in both cases, the included terms do not capture important state dependencies and time delays, but they proved\nsufficient for this use case. All NNs used in the dynamics function f are simple MLPs with GELU activations on the hidden\nstate and tanhClip functions as final activations to constrain their outputs to reasonable ranges. The dynamics of density times\nvolume are predicted; in cases where density itself is used (e.g. to compute the Greenwald Fraction), the following volume\napproximation is used to recover density:\nV\u2248 2\u03c0\u03bb\u03b5\u03ba (\u03c0- (\u03c0-\u03b5) (6)\nSince time derivatives of quantities, \u0130p, K, \u0227minor, & are used as actions, their integrated values are also added as state variables\nwith trivial dynamics."}, {"title": "4.1.2 The Observation Function O (x, a)", "content": "The observation function consists of several components: a NN predictor for Yvgr, a profile predictor, and simple physics\nformulae to compute derived quantities:\n$\\beta_p = \\frac{8 W_{tot}}{3 \\mu_0 R O I}$ (7a)\n$f_{GW} = \\frac{\\bar{n}_{e, 20} \\alpha_{minor}^{2}}{I_{p,MA}}$ (7b)\n$O_\\Theta(x, a)$ 995 = $\\frac{4.1 a_{minor} B_O}{\\frac{R\\alpha l_{p,MA}}{\\mu_O}} (1 + 1.2(k \u2013 1) + 0.56(x \u2212 1)\u00b2) (1 + 0.098 + 0.168\u03b4\u00b2) - \\frac{1+0.45\u03b4\\epsilon}{1 \u2212 0.74\\epsilon}$ (7c)\nYvgr = NNvgr(x, a) (7d)\nTe(p),Ne(p) = NNprof(x,a) (7e)\nwhere \u1e9ep is computed in accordance to the LIUQE definition42, fGw is the usual Greenwald Fraction10, , 995 is the approximation\ngiven in43 with the squareness factor set to 1, NNvgr is a MLP with GELU activation and a scaled sigmoid output, and NNpro f\nis a neural-operator based profile predictor, discussed further in the next subsection."}, {"title": "4.1.3 Neural Operator Based Profile Predictor", "content": "Prior work at NSTX-U trained a neural network to successfully predict kinetic profile shapes using their averages plus zero\ndimensional control parameters such as plasma current, shaping, and auxiliary heating. Building upon this prior work, we\nshow that, on TCV data, kinetic profiles can be predicted to reasonable accuracy with a neural network using the stored\nenergy Wtot, line-averaged electron density \u00f1e,20, and control parameters. The key implication is that accurate prediction of the\ntime-dependent dynamics of just two scalars, W\u0142ot and ne,20, implies reasonable prediction of the dynamics of kinetic profiles.\nWe leverage methods developed by the neural operator44,45 literature, which has found success for solving machine learning\nproblems in scientific domains involving PDEs. Letting fin denote an input function and fout denote an output function, a neural\noperator F parameterized by @ maps an input function to an output function:\nfout = Fo(fin) (8)\nIn practice, the functions involved are approximated using a set of basis functions, thus the practical implementation results\nin a neural network operating on basis function coefficients. In this work, we make use of cubic B-spline basis functions to\nrepresent the kinetic profiles:\nnbasis\nnbasis\nTe(p) = \u2211 cr,iBi,3(\u03c1) ne,20 (p) = \u2211 Cn,iBi,3(\u03c1) (9)\ni=1\ni=1\nAnd we predict these profiles using a set of OD scalars, where every scalar is a control parameter except stored energy W\u0142ot and\ne,20. The full set of input and output parameters is listed in Table 2. During training, the p grid corresponding to the dataset is\nchosen to evaluate the basis functions, but arbitrary alternative grids can be used during inference time."}, {"title": "4.2 Training Data Distribution", "content": "The dataset used for training models in this work consists of 442 shots with rampdowns that are at least partially complete,\ngathered with DEFUSE (Disruption and Event analysis framework for FUSion Experiments)46. The initial training phase\ninvolved training on 311 shots of data, with the rest of the dataset used for validation. After the initial training phase, the model\nis further trained on a fine-tuning dataset of 44 shots, during this phase all of the model weights except those in the TE and TN\nhybrid confinement laws described in 4.1.1 are frozen. As shown in Figure 12, the dataset consists of only five shots of data\nanywhere near the relevant high-performance region."}, {"title": "4.3 Reward Function", "content": "The reward function is designed to balance the priority of achieving a low plasma current and energy against the risk of\ndisrupting the plasma", "by": "nr(x(t),a(t)) = \u2212ctime \\frac{c_w W_{tot}(t) + C_{1p} I_p(t)}{\\sum_{i=1}^{n_{soft}} C_{soft}S_i(x(t)) - \\sum_{j=1}^{n_{hard}} C_{hard}h_i(x(t)) } (10)\nPenalty for time Penalty for current and energy Soft chance-constraints Hard chance-constraints\nThe reward function is active for every"}]}