{"title": "Algorithmic causal structure emerging through compression", "authors": ["Liang Wendong", "Simon Buchholz", "Bernhard Sch\u00f6lkopf"], "abstract": "We explore the relationship between causality, symmetry, and compression. We build on and generalize the known connection between learning and compression to a setting where causal models are not identifiable. We propose a framework where causality emerges as a consequence of compressing data across multiple environments. We define algorithmic causality as an alternative definition of causality when traditional assumptions for causal identifiability do not hold. We demonstrate how algorithmic causal and symmetric structures can emerge from minimizing upper bounds on Kolmogorov complexity, without knowledge of intervention targets. We hypothesize that these insights may also provide a novel perspective on the emergence of causality in machine learning models, such as large language models, where causal relationships may not be explicitly identifiable.", "sections": [{"title": "1. Introduction", "content": "The case has been made that learning and compression are intimately related (Blumer et al., 1987; MacKay, 2003; Gr\u00fcnwald, 2007; Vapnik, 1999, Sec. 4.6): both are made possible by regularities in datasets. In the present paper, we seek to extend this connection beyond predictive machine learning. Such settings are often studied using causal models such as structural causal models (SCMs) and causal Bayesian networks (CBNs) (Pearl, 2009). We are particularly interested in settings where data is non i.i.d. and originates from multiple environments which share (most of the) mechanisms or causal conditionals. This assumption is termed sparse mechanism shift (SMS) (Sch\u00f6lkopf et al., 2021). Intuitively, SMS helps us when jointly compressing models learned across multiple environments, since shared mechanisms then need only be compressed once. However, it is not trivial to integrate this into the known compression framework. This serves as a motivation for our paper, with the goal of working towards a rigorous framework of compression in which causality emerges as a regularity bias.\nAs a starting point, we observe that most of the previous literature on identifiability in causal discovery and causal representation learning can be rephrased in a classical compression framework: There is (up to tolerable ambiguities) a unique model under which the data has maximal likelihood, equivalently, a unique model whose distribution has minimal cross-entropy with the data distribution. A common criticism of causality research is that identifiability generally requires strong assumptions. We are interested in cases when those assumptions do not hold, and investigate what we can still say about causality. As a motivation we remark that if the only well-defined notion of causality were to build upon identifiability subject to unrealistic assumptions, why could humans and animals possess reliable causal knowledge of aspects of the world, and how should we formalize this knowledge despite the issues of non-identifiability?\nContributions\n\u2022 We discuss the relationship between identifiability (in causal discovery and causal representation learning) and compression (\u00a7 2).\n\u2022 To the best of our knowledge, our work is the first rigorous treatment of principled decisions (rather than only non-identifiability) of causal arrows with no constraints on distribution classes and no knowledge of intervention types or targets in a non-Bayesian perspective, with a weaker definition of causality (\u00a7 3, Definition 3, Definition 11).\n\u2022 Under the settings where minimum cross-entropy cannot identify causal arrows, we use a more general notion of compression, i.e., Kolmogorov complexity, to carry out model selection over the algorithmic causal models. (\u00a7 4) We provide computable upper bounds on Kolmogorov complexity (i.e., finite codebook complexity (Definition 19)) under certain non-universal Turing machines, i.e., universal finite codebook computers (UFCC, Definition 18).\n\u2022 We prove that under some UFCCs, models using causal factorizations and models with the sparsest mechanism shifts are preferred by minimizing the finite codebook complexity. (\u00a7 5, Proposition 23) This means that algorithmic causality emerges as a by-product when minimizing an upper bound of Kolmogorov complexity. We further show that some UFCCs align simplicity (i.e., short coding length) with symmetries such as invariance or equivariance under group actions (Proposition 25)."}, {"title": "2. Identifiability in causality and its relation with compression", "content": "In this section, we review the general relation of compression and identifiability in causality, and the limitations of both two notions. We focus on CBNs since Pearl (2009) shows that identifying CBNs is strictly easier than identifying SCMs, and hence all difficulties regarding identifiability in CBNs also exist in SCMs. An observational CBN model is a tuple (G, P) where G = (V, E) is a directed acyclic graph (DAG), and the distribution P is Markov relative to G, i.e., P(X) = \u03a0P(Xi|Xpa(i)). Dn denotes n iid samples from P. A multi-env CBN model is tuples M = (G\u00b2, P\u00b2) i\u2208 [1] where each tuple is called an environment (env), and each P\u00b2 is Markov relative to Gr. De denotes n iid samples from P\u00b2. Denote M as a (multi-env) CBN model class that contains different (multi-env) CBN models.\nDefinition 1 (Identifiability in causal discovery) Given an observational CBN model class M in which all the joint distributions are absolutely continuous w.r.t. a measure \u00b5, we say Mis identifiable if for any (G,Pe), (G', Po') \u2208 M with Po(x) = Po\u2032(x) \u03bc-almost everywhere, we have G = G'. Given an multi-env CBN model class M, we say M is identifiable if for any (Gi, Po) i\u2208[1], (G'i, P, )i\u2208[1] \u2208 M with P(x) = P(x) \u03bc-almost everywhere for all i \u2208 [I], we have Gi = G'i for all i \u2208 [I].\nFor both observational and multi-env models, we have the following well-known result, similar to that in classical statistics (e.g. Greene, 2003, Thm 17.3). Defining the likelihood function L(0|Dn) = po(Dn), we have:\nLemma 2 (Identifiability implies uniqueness of solution of minimum cross-entropy)\u00b9\nGiven a CBN model class M, if M is identifiable and its distribution class is parametric, then\n(1) For the observational CBN model, the solution of maximum likelihood arg maxM\u2208M limn\u2192\u221elog L(M|Dn) is unique. Equivalently, the minimizer of cross-entropy arg min(G,0) EM Ep\u2020 [\u2013 log Po(X)] is unique.\n(2) For the multi-env CBN model with uniform prior over environments, the solution of maximum likelihood arg maxMem limn\u2192\u221e 1 log L(MD) is unique. Equivalently, the minimizer of the sum of cross-entropies across multi-env\narg min\n((Gi)i\u2208[1],(\u03b8i)i\u2208[1])\u2208M i=1\nI\n\u03a3\u0395\u03a1 [-log Po; (X)]\n(2.1)\nis unique.\nBy Shannon's source coding theorem (Theorem 42) the entropy, (equivalently the minimum cross-entropy) is the shortest (most compressed) average coding length for an iid sequence. Therefore the desideratum of identifiability research is to justify that compression (minimum cross-entropy) is the correct model selection method in causal discovery."}, {"title": "Limitations", "content": "\u2022 Identifiability is deterministic model selection. By Lemma 2, once we have identifiability results in a model class M, we can deterministically select the ground truth model in M using maximum likelihood or minimum cross-entropy. It is known that without constraints of distribution class and without knowledge of the intervention targets, there is no identifiability beyond the Markov equivalence class. There is extensive research on finding model classes that make causal models identifiable. These correspond to hard priors, restricting the model class to a lower dimensional submanifold, resulting in subjective model pre-selection. However, the model selection problem is inescapable \u2014one can either pre-select the model class with constraints and then derive a deterministic model selection result, or perform model selection directly in an unconstrained model class. The success of modern empirical machine learning is based on the latter, while identifiability, based on the former, excludes parts of the model space a priori.\n\u2022 Intervention types and targets. Many papers show identifiability results under no distribution constraints on causal mechanisms but with the knowledge of intervention types or targets. In Definition 1, we can see that intervention types or targets are constraints in G\u00b9, the I-th cartesian product of all graphs of d nodes. For example, the assumption of \u201call interventions are soft\" (Perry et al., 2022; Wildberger et al., 2023) implies that the multi-env graphs (Gi)i\u2208[1] have to be the same graph G across all environments. Under faithfulness assumption, M = (Gi)i\u2208 [1] \u2208GI \u04e8(Gi)i\u2208[1], a disjoint union of model classes, each of which contains I-env systems that are Markov and faithful to I-many graphs. By reducing the possible graphs, they in fact force hard priors over the probabilistic model class on multi-env systems. The more assumptions we have on intervention types or targets, the smaller the distribution class is, and the more chance of model misspecification there is. Without intervention types or targets, multi-env data are in fact correlational data, because every new environment can arise from interventions in each variable respectively, which can be completely unrelated to the mechanisms in the observational environment. In such cases, no identifiability beyond Markov equivalence class is possible.\n\u2022 Entropy is not all the bits needed to encode datasets. The length of the codebook is missing in cross-entropy, which is why identifiability theories cannot distinguish different computational models that compute the same probabilistic model. We discuss this in detail in \u00a7 B.3.\nThe central questions in this paper:\n1. If we observe multi-env data, but have no certain knowledge about intervention types or targets, no hard prior over the model class, and thus no identifiability guarantees, can we decide on the causal relationship between variables, with a weaker definition of causality?\n2. How to learn such a causal relationship? What is its relation with compression?"}, {"title": "3. Algorithmic causality", "content": "We will now present an approach to describe causal models as probabilistic models implemented by Turing machines (TM). While this idea was first proposed by Janzing and Sch\u00f6lkopf (2010)"}, {"title": "4. Learning algorithmic causality by compression", "content": "In \u00a7 3, we introduced a computational model that can compute a wide range of probabilistic models. Recall that in our problem setting, no identifiability beyond the Markov equivalence class is possible"}, {"title": "4.1. Kolmogorov complexity", "content": "We review Kolmogorov complexity, which led to the idea of two-part code (Li et al., 2019). This inspired our idea of finite codebook complexity. We leave some definitions in computation theory in \u00a7 B.1.\nDefinition 13 (Kolmogorov, 1968; Li et al., 2019) (First version) For any x \u2208 N, the Kolmogorov complexity of x w.r.t. the universal Turing machine U is defined as\n$C_U(x) = \\min_{T\\in \\{Turing machines\\}} \\{l_U(T)|U(T) = x\\}$\n(4.1)\nwhere lu is a mapping from the class of all Turing machines to N* such that for each n \u2208 N* there are less than 2n Turing machines T such that lu(T) \u2264 n.\n(Second version) equivalently, the Kolmogorov complexity of x w.r.t. the universal Turing machine U can also be defined as\n$C_U(x) = \\min_{n\\in N} \\{l_U(n)|U(n) = x\\}$\n(4.2)\nwhere lu is a monotonically increasing map from N* \u2192 N* such that for any n \u2208 N*, lu(2n) \u2264 n.\nIn the second version of the definition, the input of lu is not a Turing machine, but an index of a Turing machine. It is important to note that each universal Turing machine (UTM) defines a computable bijective mapping N \u2192 {Turing machines}: U(1) = T\u2081,U(2) = T2,..., which is called an effective enumeration of TMs. A UTM does not have to take the literal description of a Turing machine as input. There exists a UTM U for which a TM T with 5 states has the length lu(T) = 1. In Li et al. (2019) and much of the literature, people use l instead of lu, which can be somewhat confusing because they implicitly assume that readers are aware that each UTM defines a different effective enumeration over all TMs. In this paper, we use l to denote the literal length"}, {"title": "4.2. Finite codebook complexity", "content": "After decomposing the Kolmogorov complexity of a multi-env dataset CU(x1,... In) into a two-part code lu(T) + Cu(x1,...xn|T), there is still an uncomputable part lu(T). We can construct an upper bound of lu(T) by constraining the Turing machine class, without constraining the distribution class or codebook class that our Turing machines can compute.\nDefinition 17 We say that an injective function g: A \u2282 Xd \u2192 B* is a finite codebook if the set g(A) is prefix-free. We say that a Turing machine T is a finite coding mechanism (FCM) if it computes a finite codebook.\nDefinition 18 Given the dimension d and precision m of Xd, we say that a Turing machine V is a universal finite codebook computer (UFCC)10 if\n1. V takes input (k,p), where k is the index of an FCM in a decidable set\u00b9\u00b9 of FCMs; p is a natural number, which is equivalent to a binary string B(p) (see Definition 26); same as Lemma 16, \u3008\u00b7,\u00b7) is the self-delimiting concatenation.\n2. for any finite codebook g : A < Xd \u2192 B*, there exists k such that V((k,\u00b7)) is an FCM computing (g*)\u00af\u00b9, which is a partial (i.e., not everywhere defined) function B* \u2192 A*, and g* is the extension of the codebook g (see Definition 37, (g*)\u2212\u00b9 is well-defined because gis prefix-free);\n3. V((k,p)) is computed by decoding the binary string B(p) using V((k, \u00b7)).\nDefinition 19 Given a UFCC V, for any finite codebook g, the finite codebook (FC) complexity is defined as\n$C^{FC}_V(x_1...x_n):= \\min_{\\substack{(k,p)\\in N^2}} \\{l((k, p)) : V((k, p)) = x_1...x_n\\}$\n(4.6)\nWe now first apply Lemma 14 to upper bound CU (X1... Xn) by CFC (x1... In), and then split CFC (x1...In) into a two-part code using the idea similar to Lemma 16.\nFor any additively optimal (Lemma 14) UTM U and any UFCC V, using the same argument as in the proof of Lemma 14, there exists n such that V = Tn, so we can bound the Kolmogorov complexity Cu by FC complexity CFC:\n$C_U(x_1...x_n) \\leq C_V^{FC} (x_1... x_n) + 0(1)$\n(4.7)"}, {"title": "4.3. Comparisons among UFCCS", "content": "Are some UFCCs better than others? We are not interested in finding the UFCC that achieves the smallest FC complexity for all data, because it is often not computable. Instead, we are interested in finding some UFCCs that are good at model selections, i.e. such a UFCC should not consider all FCMs to be equally preferable to select.\nFor the Kolmogorov complexity, the choice of UTM is not important because all the additively optimal UTMs are equivalent up to O(1) (Lemma 14). For UFCC it is not the case.\nConsider the following extreme example: a UFCC Uunif first takes m, d, n as input where m denotes the precision of X, i.e. |X| = 2m, and d denotes the number of variables, and n denotes the precision of discrete distribution values. Let Uunif encode any distribution by a table, where each row is a distribution value for a point in Xd. Suppose the rows are well ordered so we do not need to encode the points for simplicity. Then Uunif only needs to encode (2m)d numbers, with each number occupying n bits. After coding the distribution values, Uunif uses a Huffman coding program to turn it into a prefix code.12 Therefore, for any codebook g, any binary codeword sequence B(p) is decoded by FCMs with the same model length, i.e. same luunif(T) in eq. (4.9). For any (m, n, d), Uunif gives a uniform prior over all codebooks that are Shannon codes of a distribution on Xd with precision (m, n). Using Uunif as UFCC, the objective eq. (4.9) is equivalent to maximum likelihood. Namely, from the perspective of Uunif, no codebook is simpler or more preferable than another.\nBack to our question: are some UFCCs better than others? We conjecture that a criterion for good UFCC is: for any additively optimal UTM, a good UFCC U should have a similar landscape (i.e. the order) as the UTM in the right figure of Figure 2. Namely, a good UFCC should preserve the order of codebooks in a certain UTM."}, {"title": "5. Case studies", "content": "We study the solutions for eq. (4.9) under some particular UFCCs, showing that compression leads to selecting CFMPs that have algorithmic causal or symmetric structures. In the following, all the UFCCs simulate FCMs by composing a CFMP with a Huffman coding program, and all the CFMPs only involve no-hidden-variable mechanisms."}, {"title": "5.1. Causal factorizations and sparse mechanism shifts", "content": "Consider a UFCC UTabCBN that first takes m, d,n as input where m denotes the precision of X, i.e., |X| = 2m, and d denotes the number of variables, and n denotes the precision of discrete"}, {"title": "5.2. Symmetries", "content": "Consider a UFCC UTabIny that first takes m, d,n as input where m denotes the precision of X, i.e., |X| = 2m, and d denotes the number of variables, and n denotes the precision of discrete distribution values. Let UTabInv only allow the CFMPs in the form of (4) in Example 2 and with further constraint same as the first constraint in the definition of UTabCBN, plus that"}, {"title": "6. Experiments", "content": "We illustrate our theoretical findings through simple experiments with synthetic data.\nWe consider two synthetic settings with sparse mechanism shifts. In both settings, the goal is to show that by minimizing FC complexity, we select a model that trades off the complexity of the model itself and the data-to-model coding length, i.e. negative log-likelihood. Then we say that according to the model selection method of minimizing FC complexity, X algorithmically causes Y. Details of experiments are in \u00a7 F. The code can be found here: https://github.com/WendongL/algorithmic-causality-compression"}, {"title": "6.1. Covariate shifts", "content": "Consider a multi-env system with covariate shift: P(X, Y, E) = P(X|E)P(Y|X)P(E). Suppose many CFMPs (\u03b1\u03b9)\u03b9\u2208[L] generate the same P and I and featurize them in the same way, as described in strategy 2 before Proposition 23. The question is: among these CFMPs, under the UFCC UCompCBN in Proposition 23, given multi-env finite data, if we only consider the case \u201cX causes Y\", which CFMP should we select? In the current experiment, we generate 10 environments for\""}, {"title": "6.2. Causal discovery without identifiability", "content": "Consider a multi-env system with 5 environments generated by linear Gaussian SCMs: X ~ \u039d(0, \u03c3\u2081), Y = aX + \u0454 with \u0454 ~ N(0,02). We generate 10 iid samples for each environment.\nIn total, 8 parameters are needed to fit the data optimally.\nHowever, the causal graph is not identifiable, because we can also find parameters for each env using the linear Gaussian model Y \u2192 X: Y ~ N(0, t\u1ec9), X = bY + \u0454 with e ~ N(0, \u03c4\u2082).\nFor both causal and anti-causal linear Gaussian models, we allow 8 choices for each parameter, which include the optimal parameters, in total 24 parameters for the multi-env system. We constrain the number of mechanisms (in this case, parameters) before training the model, just as Strategy 2 in Proposition 18.\nWe see that FC complexity provides a new criterion of a \"good model\u201d that is applicable when the model is not identifiable from infinite sample and addresses the model selection problem, e.g., here fewer mechanisms than in the ground truth are selected."}, {"title": "7. Related work", "content": "Janzing and Sch\u00f6lkopf (2010) were the first to consider causal mechanisms implemented by Turing machines. They replace statistical (conditional) independence with algorithmic (conditional) independence, conjecturing that if the Kolmogorov complexity of a string or a joint distribution can be decomposed into a sum of conditional Kolmogorov complexities of the causal mechanisms according to a graph, then this graph should be selected. They also extended their model selection principle to probabilistic models (Janzing and Sch\u00f6lkopf, 2010, Postulate 7), which we comment in detail in \u00a7 G and compare with our Principle 12. The incomputable objective in (Janzing and Sch\u00f6lkopf, 2010, Postulate 7) is replaced by entropy (Steudel et al., 2010; Pranay and Nagaraj, 2021) or MDL (Budhathoki and Vreeken, 2016, 2017; Marx and Vreeken, 2019a; Mian et al., 2021, 2023) in all subsequent papers. We discuss in \u00a7 B.3 and \u00a7 H the difference between our approach and them. Marx and Vreeken (2021) discusses the relationship between Postulate 7 and two-part code. We give our comments on their results and on Postulate 7 in \u00a7 G. Some papers (Marx and Vreeken, 2019b,c; Mameche et al., 2022, 2024) claim identifiability (i.e., recovery of the ground-truth graph) by minimizing their proxy of Postulate 7 in Janzing and Sch\u00f6lkopf (2010). We show in Lemma 2 that any identifiability of graphs is reduced to the claim of the uniqueness of the solution of minimum cross-entropy instead of minimizing a bound of Kolmogorov complexity. Our approach focuses on an upper bound of Kolmogorov complexity of a specific class of Turing machines that compute probabilistic models. Our objective is fundamentally different from (Janzing and Sch\u00f6lkopf, 2010, Postulate 7), as we show in \u00a7 G.\nDhir et al. (2024) address bivariate causal discovery without confounding by comparing the posteriors of two graphs, with the correctness (probability of selecting the ground truth graph) depending on the total variation between the ground-truth distribution and marginal likelihood. In \u00a7 H, we discuss the difference between our approach and Bayesian model selection.\nOn the side of computation theory, there is abundant work on constraining the definition of Kolmogorov complexity to make it computable, such as resource-bounded complexity (Barzdin, 1968), logical depth (Chaitin, 1977), automatic complexity (Shallit and Wang, 2001).Those definitions are fit for compressing more general strings without any probabilistic structure, therefore the entropic code (- log P) is not applicable. In the domain of knowledge representation, Shen et al. (2018);"}, {"title": "8. Discussion", "content": "If it is the case that compression in some cases may automatically yield causal structure, then this has significant implications for modern machine learning. For instance, there is an ongoing debate as to whether large language models (LLMs) can understand causality in the sense of correctly applying causal principles across a range of problems (Jin et al., 2023). After all, a large extent of apparent causal knowledge may be explained by simply regurgitating causal knowledge which is abundant in the training set, and one may thus argue that the apparent causal knowledge of LLMs may be entirely superficial. The arguments put forward in the present paper suggest that perhaps these two extremes may not be entirely irreconcilable: training a (large, but finite) model on a significant fraction of the internet necessarily forces a model to compress data, and even though the classical identifiability assumptions do not hold, an algorithmic causal model can still be extracted. In other words, if the empirical scaling laws for LLMs continue to hold, the model may have no choice but to learn (algorithmic) causality. Similar indirect arguments have been made for non-causal learning for the case of grokking (Power et al., 2022) and the emergence of complex skills (Arora and Goyal, 2023). An open question is whether LLMs simulate nontrivial CFMPs, i.e., whether they call and reuse some mechanisms like in CFMP. We know that in principle, they can (P\u00e9rez et al., 2021).\nThe use cases of algorithmic causality and Pearl's causality are disjoint. Algorithmic causality is not a competitor of Pearl's causality, since (i) if we have infinite data and the likelihood converges, compression is trivialized to minimum cross-entropy, which outputs any Turing machine that computes the same probability distribution, so the model selection by any UFCC suffers from the same non-identifiability as Pearl's framework; (ii) algorithmic causality deals with multi-env but correlational data and is a rung 1 model in Pearl's hierarchy; (iii) its advantage lies only in those cases where the intervention targets are not certain, for example in LLM pre-training, there is no prior knowledge about which context token is the environment label or intervention-target variable. In this case, using Pearl's causality might not be as appropriate as using algorithmic causality; on the other hand, if scientists have data generated by some strictly randomized controlled experiments on many variables respectively, then the identifiability results in Pearl's causal models are more convincing than algorithmic causality for the scientific community."}, {"title": "Appendix A. Notations", "content": "Symbol Description\nlog\nSimplified symbol for log2\nQ\nThe set of rational numbers\nG\nA directed acyclic graph with nodes V = [d] and arrows E\n[d]\nThe natural numbers 1,..., d\npa(i)\nParents of i, defined as {j \u2208 V(G) | (j, i) \u2208 E(G)}\nB\nBinary alphabet {0,1}\nX\nThe discrete finite space for one dimension of samples, of cardinal 2m\n\u03a9\nThe discrete finite space for one dimension of the formal variable w, of cardinal 2m\n\u03f5\nEmpty string\n\u03b1\nA conditional feature-mechanism program (CFMP) (Definition 9)\n\u0393\u03b1\nCylinder, defined in Definition 32\nPa\nList of probabilistic mechanisms (Definition 7) generated by CFMP \u03b1\n\u03a6\u03b1\nSet of feature mechanisms (Definition 8) generated by CFMP \u03b1\nf1\nA probabilistic mechanism (Definition 7)\ng.x\nGroup action on x \u2208 Xd, with g \u2208 G for a certain group G\nCU(x)\nKolmogorov complexity of a string x under a universal Turing machine U (Definition 13)\nn\nSelf-delimiting code of a natural number n, see Definition 27\n(x, y)\nSelf-delimiting concatenation of natural numbers x, y, defined in Definition 27\nlu(T)\nLength of the index of Turing machine T in the effective enumeration of\nTuring machines in a universal Turing machine or UFCC U, see Definition 13\nl(n)\nLength of a binary string or equivalently a natural number n in the binary\nrepresentation, defined in eq. (B.3)\nUTabCBN\nA UFCC that is defined and used in \u00a7 5. Same for UCompCBN, UTabInv"}, {"title": "Appendix B. Preliminaries", "content": "B.1. Computation theory\nWe introduce some notions that we mentioned in the paper. We follow Li et al. (2019).\nWe use an alphabet of binary symbols B = {0, 1}. The set of all finite strings over B is denoted by B*, defined as\nB* = {\u03f5, 0,1,00, 01, 10, 11,000,...}\n(B.1)\nwith \u03f5 denoting the empty string, with no letters. Concatenation is a binary operation on the elements of B* that associates xy with each ordered pair of elements (x, y) in the Cartesian product B* \u00d7 B*.\nWe now consider a correspondence of finite binary strings and natural numbers. The standard binary representation has the disadvantage that either some strings do not represent a natural number, or each natural number is represented by more than one string. For example, either 010 does not represent 2, or both 010 and 10 represent 2. We can map B* one-to-one onto the natural numbers by associating each string with its index in the length-increasing lexicographic ordering\n(\u03f5, 0), (0, 1), (1, 2), (00, 3), (01, 4), (10, 5), (11, 6), ...\n(\u0392.2)"}, {"title": "B.2. Discrete probability theory", "content": "Definition 32 (Li et al., 2019) Let B be a finite or countably infinite set of symbols. In this paper, we use B = {0,1}. A cylinder is a set \u0393x \u2208 B\u221e defined by\n$\u0393_x = \\{xw : w \\in B^\\infty\\}$\n(B.6)\nwith x \u2208 B*. Let G = {\u0393x :x \u2208 B*} be the set of all cylinders in B\u221e. A function \u03bc : G \u2192 R defines a probability measure if\n\u03bc(\u0393\u03f5) = 1,\n\u03bc(\u0393x) = \u03a3\u03bc(\u0393xb).\nb\u2208B\nConsider the function \u03bc' : B* \u2192 R defined by \u03bc'(x) = \u03bc(\u0393x). Trivially from \u03bc' we can reconstruct \u03bcand vice versa. From now on we identify \u03bc' with \u03bc. Formally, we use the definition of measure below. One should keep in mind that our notation is shorthand for the original measure.\nDefinition 33 A finite cylinder of depth m is defined by\n$\u0393^m = \\{xw : w \\in B^m\\}$\n(B.7)\nThe probability space X we consider in Definition 5 can be redefined as X := {\u0393\u00a3 : x \u2208 B*}.\nDefinition 34 (Li et al., 2019) A function \u03bc : B* \u2192 R is a probability measure (measure for short) if\n\u03bc(\u03f5) =1 and \u03bc(x) = \u03a3\u03bc(xb),\nb\u2208B\n(B.8)\nfor all x \u2208 B* . A semi-measure is a defective measure. A function \u03bc : B* \u2192 R is a semi-measure if for all x \u2208 B*,\n\u03bc(\u03f5) \u2264 1,\n\u03bc(x) \u2265 \u03a3\u03bc(xb).\nb\u2208B"}, {"title": "B.3. Compression in information theory", "content": "Here we recall some basic results in information theory. We follow Cover (1999).\nDefinition 36 A codebook14 (or source code) c for a random variable X is a mapping X \u2192 B* = {0,1}*. Let c(x) denote the codeword corresponding to x and let l(c(x)) denote the length of c(x). The expected length L(c) of a codebook c for a random variable X with probability mass function p(x) is given by\n$L(c) = E[l(c(x))] = \\sum_{x\\in X} p(x)l(x)$\nExample 5 Let X be a random variable with the following distribution and codeword assignment:\nP(X = 1) = $ \\frac{1}{2}$, codeword c(1) = 0\nP(X = 2) = $ \\frac{1}{4}$, codeword c(2) = 10\nP(X = 3) = $ \\frac{1}{8}$, codeword c(3) = 110\nP(X = 4) = $ \\frac{1}{8}$, codeword c(4) = 111.\nThe entropy H(X) of X is 1.75 bits, and the expected length L(c) = E[l(X)] of this code is also 1.75 bits. Here we have a code that has the same average length as the entropy. We note that any sequence of bits can be uniquely decoded into a sequence of symbols of X. For example, the bit string 0110111100110 is decoded as 134213."}, {"title": "Lemma 35 When the precision of Z is fixed, the conditional independence set", "content": "{X __ Y|Z; X, Y, Z are random variables in P}\nis decreasing as the precisions of X and Y increase.\nProof We will prove that if X \u2aeb Y | Z, then X \u2aeb Y|Z.\nFor all i \u2208 B, for all (x, y, z) in the support of (X, Y, Z), P(xi, y, z)P(z) = P(xi, z)P(y, z). Therefore,\nP(x, y, z)P(z) = [P(x0, y, z) + P(x1, y, z)] P(z)\n(B.9)\n= P(x0, z)P(y, z) + P(x1, z)P(y, z)\n= P(x, z)P(y, z)\n(B.10)\n(B.11)\nwhich implies P(X, Y|Z) = P(X|Z)P(Y|Z)."}, {"title": "Definition 37 The extension c* of a codebook c is the mapping from finite-length strings of X to finite-length strings of B*, defined by", "content": "c*(X1X2\u00b7\u00b7\u00b7Xn) = c(x1)c(x2)\u2026\u2026c(xn),\nwhere c(x1)c(x2)\u00b7\u00b7\u00b7c(xn) indicates concatenation of the corresponding codewords.\nExample 6 If c(x1) = 00 and c(x2) = 11, then c(x1x2)"}]}