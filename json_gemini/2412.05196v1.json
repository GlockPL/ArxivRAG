{"title": "Exponential Speedups by Rerooting Levin Tree Search", "authors": ["Laurent Orseau", "Marcus Hutter", "Levi H. S. Lelis"], "abstract": "Levin Tree Search (LTS) [Orseau et al., 2018] is a search algorithm for deterministic\nenvironments that uses a user-specified policy to guide the search. It comes with a formal\nguarantee on the number of search steps for finding a solution node that depends on the\nquality of the policy. In this paper, we introduce a new algorithm, called \u221a LTS (pronounce\nroot-LTS), which implicitly starts an LTS search rooted at every node of the search tree.\nEach LTS search is assigned a rerooting weight by a (user-defined or learnt) rerooter, and the\nsearch effort is shared between all LTS searches proportionally to their weights. The reroot-\ning mechanism implicitly decomposes the search space into subtasks, leading to significant\nspeedups. We prove that the number of search steps that \u221aLTS takes is competitive with\nthe best decomposition into subtasks, at the price of a factor that relates to the uncertainty\nof the rerooter. If LTS takes time T, in the best case with q rerooting points, \u221aLTS only\ntakes time O(q\u221aT). Like the policy, the rerooter can be learnt from data, and we expect\n\u221aLTS to be applicable to a wide range of domains.", "sections": [{"title": "Introduction", "content": "We are interested in tree search algorithms for deterministic domains. Tree search algorithms\nsuch as all variants of best-first search including A* [Hart et al., 1968], Weighted-A* (WA*),\nand Greedy Best-First Search (GBFS) [Doran et al., 1966] and variants of MCTS such\nas UCT [Kocsis and Szepesv\u00e1ri, 2006], AlphaGo, AlphaZero and other variants [Silver et al.,\n2016, 2017b,a] \u2014 explore the search tree starting at the root and can visit a node only if its\nparent has been visited first. These algorithms are often guided by some side information, such\nas with cost-to-go heuristic function for A*, WA* and GBFS, a reward/value function for UCT\nand AlphaZero, or a policy for AlphaZero, Levin Tree Search (LTS) [Orseau et al., 2018], and\nPolicy-Guided Heuristic Search [Orseau and Lelis, 2021].\nSuch algorithms also sometimes come with different types of guarantees: A* and WA*, with\nan admissible heuristic function i.e., a function that never overestimates the optimal cost-\nto-go are guaranteed to return a solution that is cost-optimal (A*) or bounded-suboptimal\n(WA*), while UCT and AlphaZero are guaranteed to (eventually) have low regret in terms of\ncumulative reward during the search. LTS is guaranteed to return a solution within a number\nof search steps that depends on the quality of its policy. In this paper, we consider the latter\ntype of guarantee, on the efficiency of the search process depending on the quality of the side\ninformation.\nTo explain the main concepts of this paper, let us consider a kind of side information we call\nclues: some nodes are clue nodes, and a node can be known to be a clue node only when reaching\nit. A clue may be helpful if it is on the path toward a solution node, or misleading otherwise.\nThe following example describes a minimalistic clue environment."}, {"title": "Notation and Background", "content": "A table of notation can be found in Appendix I. The set of nodes is N. The set of children of\na node n is C(n). Each node n has either one parent par(n) except for the root node n\u2081 which\nhas no parent. The set of descendants of a node n is desc(n) (the transitive closure of C(\u00b7)), and\nwe define desc+(n) = desc(n) \u222a {n}. Similarly, the set of ancestors of n is anc(n), and we define\nanc+(n) = anc(n) \u222a {n}. For two nodes n and n, we write n\u4eban for n\u2208anc(n) and n \u2264 n for\nn\u2208 anc+(n). The depth of a node n is d(n) = |anc(n)|, hence d(n\u2081) = 0.\nA policy \u03c0: \u039d \u00d7 N \u2192 [0, 1], written \u03c0(\u00b7|\u00b7), is such that for all \u03b7 \u20a4 \u03ae : \u03c0(\u03ae \u03b7) = 0, and\nfor each node n, Enec(n) \u03c0(n/n) \u2264 1; the policy is called proper if this holds with equality."}, {"title": "Lower Bound", "content": "First we prove a general lower bound on the number of node visits that any search algorithm,\nrandomized or deterministic, using any kind of heuristic guide, must perform before visiting a\nsolution node in the presence of clues. We will also use this set of environments as a running\nexample and to show that some improvements to \u221aLTS are impossible in general. In the following\nresult, for simplicity we assume that the algorithm can test whether a node is the solution node\nn* only upon visiting it."}, {"title": "Self-Counting Cost Functions", "content": "In this section, we first define self-counting cost functions and show their relation to the BFS\nsteps at which nodes are visited. Next, as a side contribution, we improve the self-counting cost\nfunction of LTS. Then, we show how to compose self-counting cost functions into a single one.\nDefinition 4 (Self-counting cost function). A cost function c : N \u2192 R is said to be self-counting\nif, for all \u03b8 \u2265 0, the number of nodes of cost at most \u03b8 is itself at most \u03b8:\n\\{n \u2208 N : c(n) \u2264 \u03b8\\} \u2264 \u03b8.\nNote that non-monotone cost functions may still be self-counting.\nOrseau et al. [2018, 2023] use the monotone cost function (n) = d(n)/\u03c0(n) to guide the\nBFS of Levin Tree Search. They prove that |{n: (n) \u2264 \u03b8}| \u2264 1 + \u03b8 for all \u03b8 \u2265 0. But because\nBFS is invariant to cost translation, BFS with the cost function(\u00b7) is equivalent to BFS with\nthe cost function 1 + (\u00b7). Since |{n : 1 + (n) \u2264 1 + \u03b8}| \u2264 1 + \u03b8, which is equivalent to\n|{n: 1+(n) \u2264 \u03b8}| \u2264 \u03b8, the cost function 1 + (.) is a self-counting cost function.\nThe following result strongly links the number of BFS steps with the cost of a monotone\nself-counting cost function. The proof is in Appendix C."}, {"title": "Slenderness Cost Function", "content": "Now we define a variant of the cost function 1 + (\u00b7) with tighter guarantees. Indeed, as a\nself-counting cost function, 1 + (\u00b7) is a little loose, as shown by the following example."}, {"title": "Composing Self-Counting Cost Functions", "content": "We show how self-counting cost functions can be composed, which is a central idea of our al-\ngorithm. But first, suppose that we have N algorithms that all try to solve the same problem\nin different ways, and they all run on the same CPU. We want to share the computation steps\nnon-uniformly between the algorithms, and we have weights w\u2081, W2,...w that sum to 1. After\na total of T computation steps, each algorithm i has been assigned at least [wiT] computation\nsteps. Now, if algorithm i needs Ti steps to find a solution, then this happens when the total T\nis such that wiT] = Ti. This implies T < (Ti + 1)/wi. Since this holds for all i, a solution is\nfound after T steps where\nT < min_{i\u2208[N]} (T_i + 1)/w_i \nWe use a similar idea to compose a set of base self-counting cost functions into a single self-\ncounting cost function to be used within a single instance of BFS."}, {"title": "The LTS Algorithm and its Guarantee", "content": "The idea of \u221aLTS is to start several instances of LTS (using) rooted in different nodes {nt}t,\nand compose them with weights {wt}t as in Lemma 8. Let us make a first attempt: For each\nt\u2208 N1, we define the base cost function c(n) = (n;nt), and these are composed via \u010d(n) =\nmint\u2208N\u2081 \u010ct(n)/wt. Since \u010dt(n) = \u221e for nt \u20a4 n, this can be simplified to\nc(n) = min_{n_t < n} (\\frac{1}{w_t}) (\\hat(c))(n; n_t).\nNote that the index t of the base cost function \u0109t corresponds to the step t at which the node nt\nis visited during the BFS with the cost function \u010d.\nUnfortunately, the base cost function (\u00b7; n\u2081) is monotone only on the descendants of nt, but\nis not monotone in general on the descendants of n\u2081. Hence, while \u010d is self-counting by Lemma 8,\nit is itself not monotone either. This prevents using Eq. (10) to derive a straightforward bound.\nBut this issue is easy to fix by defining cmax(n) = max\u00f1_n \u010d(n) which is monotone by design,\nand preserves the self-counting property. Then, assuming that the weights {wt}t sum to at\nmost 1, from Eq. (10), for the node ny visited at step T of BFS with the cost function cmax,\nT < c^{max}(n_T) = max_{\u03c0 < n_T} c(n) =  max_{\u03c0 < n_T}  min_{ n_t  < \u03c0}  \\frac{1}{w_t} (\\hat(c))(n; n_t) ."}, {"title": "Robustness to Clue Overload", "content": "Recall the clue environments of Section 3. What if the total number of clue nodes q is very large\nor infinite? In this case the bound T < qr2a+1 of Example 12 becomes vacuous, since qr could be\nas large as \u03a9(\u03a4). Similarly, the bound of Eq. (16) compared to LTS alone is also vacuous. This is\nnot an artifact of the proof, and indeed \u221aLTS with uniform weights may never find the solution\nnode n* in this setup. To tackle this issue, we first design non-uniform rerooting weights for clue\nenvironments, and then generalize the approach for general rerooting weights."}, {"title": "Conclusion", "content": "We have proposed a new search algorithm for deterministic domains, called \u221aLTS, which uses a\nrerooter to start the policy-based LTS at various nodes in the search tree, potentially speeding\nup the search significantly. The rerooter can use side information that the policy does not, such\nas 'clues'. \u221aLTS comes with theoretical guarantees on the number of search steps depending on\nthe quality of the policy and of the rerooter.\nClues appear similar in nature to shaping rewards and landmark heuristics, and knowledge\nfrom these fields could be leveraged to design domain-specific rerooters and derive guarantees.\nWhile many search domains are deterministic in nature (e.g., theorem proving, many games,\nprogram synthesis, etc.), it could be valuable to extend \u221aLTS to tackle stochastic domains.\nWe are eager to see how \u221aLTS performs on real-world applications, when both the policy\nand the rerooter are learnt, in particular since LTS already works well [Orseau et al., 2018,\n2023; Orseau and Lelis, 2021]. We hope that the theory we have proposed can provide a solid\nfoundation for designing faster search algorithms and solving challenging search problems."}, {"title": "Clues and Classic Algorithms", "content": "Expanding on the claims made in the introduction, we show that classical algorithms (A*, WA*,\nLTS and MCTS variants) all struggle to make good use of clues."}, {"title": "Admissible A* Cannot Use Clues", "content": "A* [Hart et al., 1968; Dechter and Pearl, 1985] is a best-first search algorithm whose priority\nqueue is sorted according to the function f(n) = g(n) + h(n), for each node n. The g-value of\na node is the depth of the path connecting the root of the tree to n, while h(n) is an estimate\nof the number of actions to go. We denote as h*(n) the minimum number of actions to connect\nn to a goal node. A* is guaranteed to find depth-optimal solutions if h(n) \u2264 h*(n) for all n.\nWeighted A* [Pohl, 1970] is a generalization of A* that uses a weighted version of the heuristic\nh to ensure g-optimality of the return solution within a factor 1 + \u025b for a chosen \u025b \u2265 0.\nRegarding the specific clue environment of Example 1 of the Introduction, it is actually\npossible to design an admissible heuristic function for A* that solves the problem as efficiently\nas \u221aLTS: for every node at depth 50 or depth 100 that is not a clue node, set the heuristic to\ninfinity. This effectively prunes all these nodes. However, this 'rerooting-by-pruning' behaviour\nis not feasible in general while guaranteeing depth-optimality of the solution. For example, if\nthere is even a small chance that the solution node does not descend from a clue node of depth 50,\nthen no single path can be pruned by any admissible heuristic and A* must search everywhere\nto guarantee depth-optimality of the returned solution. The following theorem implies that no\nalgorithm (including A* and Weighted A*) can be claimed to guarantee 1 + \u0454 g-optimality for\nall monotone cost functions g while also making efficient use of clues."}, {"title": "LTS Struggles with Clues", "content": "LTS [Orseau et al., 2018] is a best-first search [Pearl, 1984] that uses the cost function n \u2192\n(n) = d(n)/\u03c0(n) to guide the search, where is a policy (see its definition in Section 2), and\nthe path probability \u03c0(n) is the product of the edge (or 'action') probabilities 6 from the root to\nn. For example, if at each node there are two actions, left and right, with constant respective\nprobabilities p and 1 p, and the solution node n* is found after taking l lefts and r rights,"}, {"title": "MCTS Struggles", "content": "We compare \u2713LTS with MCTS on a couple of illustrative examples. It is important to note\nthat these examples do not mean that \u221aLTS is better suited than MCTS for reward-based\nenvironments in general (in particular for adversarial or stochastic environments), but they show\nat least that the linear scaling of the bounds in Section 5 and Section 6 are a reassuring feature\nof \u221aLTS."}, {"title": "D-chain environment", "content": "Coquelin and Munos [2007]; Orseau and Munos [2024] show that several variants of UCT, in-\ncluding AlphaGo [Silver et al., 2016] and its descendants, can take double-exponential time with\nthe depth of the solution node in the D-chain environment see Figure 4. How does \u221a LTS\nbehave on this environment?\nWe take a uniform policy. We set wt to the the reward observed at this node, and set w\u2081 = 1.\nLike for UCT, all the intermediate rewards/clues are misleading and delay \u2713LTS from finding\nn*. However, in this example at least, the exploration/exploitation ratio struck by \u221aLTS is\nfar more balanced. The analysis is also quite simple. If n* is visited at step T, then we have\nw<T \u2264 W1+\u2211i<p(D\u22121)/D = (D+1)/2. The node n* is at depth D, so (n*; n\u2081) = 2D+1 \u2013 1.\nThen from Eq. (16) we obtain that T < (D+1)2D, which is only a log factor worse than breadth-\nfirst search (which is not misled by the intermediate rewards), and is exponentially faster than\nthe MCTS algorithms mentioned above.\nBut perhaps these MCTS algorithms are significantly faster than \u2713LTS if the solution node is\nplaced elsewhere in the tree? Assume that n* is placed randomly at depth D and is a descendant\nof the node n2, which is the very first reward the algorithms may observe. Since the reward is\nso high in the tree, MCTS still needs to visit at least 2D descendants of n2. As in the previous\nexample, \u221aLTS visits at most (D + 1)2D nodes, which is only a log factor worse."}, {"title": "A measly misleading reward", "content": "It can even be shown that AlphaZero-like MCTS algorithms can take quadratic time compared\nto breadth-first search even with just one misleading reward close to the root. For each child n\nof a node n, define, according to the AlphaZero formula:\nB_t(n) = X_t(n) + Cpuct*\u03c0(n|n)  * sqrt(m_t(n))/(m_t(n)+1)\nwhere Xt(n) is taken to be the average reward observed on the descendants of n (included),\nand mt(n) is the number of times the node n has been traversed before step t. We assume that\nCpuct = 2. At every expansion step, the tree is traversed from the root n\u2081 and, at every parent\nnode, its child with maximum B value is selected for traversal.\nConsider an infinite perfect binary tree where the two children n2 and 13 of the root are such\nthat there is a reward a \u2208 (0,1) at n2. We assume that n\u2082 is visited before n3. For both \u221aLTS\nand AlphaZero we take a uniform policy. Then Cpuct\u3160(n|n) = 1 for all n \u2208 C(n). The node n* has\na reward of 1 and descends from n3. If n* is visited at step T, we must have Br(n3) > \u0412\u0442 (\u043f\u2082)\nwhich implies \u0392r(n3) \u2265 \u03b1. To visit n*, the MCTS algorithm must first visit all descendants of"}, {"title": "Slenderness", "content": "This appendix provides further details and examples regarding the slenderness cost function\nintroduced in Section 4.1, as well as the proof of Eq. (6)."}, {"title": "More Slenderness Examples", "content": "Consider an infinite binary tree where the conditional proba-\nbility of the left child is always p and that of the right child is always 1-p. Then, starting at the\nroot and taking l times the left child and r times the right child, in any order, the corresponding\nnode n satisfies\n(n) \u2264 max_{p, (1-p)}  [\\frac{1}{\u03c0(n)}]\nwith \u03c0(n) = p\u00b2(1 \u2013 p)\". Compare with (n) = (l + r)/\u03c0(n)\nand recall that (n) \u2264 1 + (n).\nAlso note that this means that the slenderness \u03bb(n) \u2264 max{1/p, 1/(1 \u2212 p)}.\""}, {"title": "Proof of the Slenderness Bounds", "content": "Refer to Example 19 for some intuition about why\u2018counts' the number of nodes in a tree.\nBefore proving the bounds of Eq. (6), we build an intermediate concept we call the comple-\nmentary policy with respect to a tree, and we prove that it satisfies some useful properties.\nRecall that a set N' C N of nodes is a tree rooted in some node na if for every node in the\nset, its parent is also in the set, except for the root na: \u2200n \u2208 N' \\ {na}, par(n) \u2208 N'.\nDefinition 20 (Complementary policy). For a given tree N' \u2286 N rooted in n\u2081, the N'-\ncomplementary policy \u03c0' of \u03c0is, for all n \u2208 N,\n\u03c0'(n) = \u03c0(n) - \u03c0(n)* sum (\u03c0(n/n'))/ sum (\u03c0(n)). \n{n\u2019 in C(n) intersection N\u2019}\nThe quantity \u03c0'(n) is the amount of the path probability \u03c0(n) that is not passed down to\nchildren of n within N'. That is, \u03c0'(n) is 'lost' (or 'leaked') by n from N'. This also accounts"}, {"title": "Self-Counting Cost Functions", "content": "Recall Lemma 5: A monotone cost function c is self-counting if and only if t \u2264 c(nt) for all\nt\u2208 N1, where nt is visited at stept of the BFS with the cost function \u0441."}, {"title": "Telescoping Property", "content": "We show that the root-dependent cost function satisfies a form of 'telescoping' property."}, {"title": "Detailed Example: Sokoban", "content": "To make our ideas a little more concrete, we make some back-of-the-envelope calculations to\nanalyse the behaviour of \u221a LTS on a level of Sokoban see Figure 5. The reader must keep in\nmind that this serves only illustrative purposes. In particular, this level of Sokoban has been\ndesigned to demonstrate some interesting features of our results, and most of the numbers we\npresent are likely largely overestimated. Both the rerooter and the policy we design are simplistic\nfor the sake of clarity.\nA state is one configuration of the board. Multiple nodes in the search tree may correspond\nto the same states. There are 89 non-wall cells, 4 boxes, 4 goal spots and 1 player. That is, there\nare 89 possible places for the 5 moving objects and, since the 4 boxes are not distinguishable, the\nnumber of possible states is at most (but close to) 89!/(1!4!(89-4-1)!) = 207538 210. With this"}, {"title": "Table of Notation", "content": null}]}