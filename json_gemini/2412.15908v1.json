{"title": "Speedup Techniques for Switchable Temporal Plan Graph Optimization", "authors": ["He Jiang", "Muhan Lin", "Jiaoyang Li"], "abstract": "Multi-Agent Path Finding (MAPF) focuses on planning collision-free paths for multiple agents. However, during the execution of a MAPF plan, agents may encounter unexpected delays, which can lead to inefficiencies, deadlocks, or even collisions. To address these issues, the Switchable Temporal Plan Graph provides a framework for finding an acyclic Temporal Plan Graph with the minimum execution cost under delays, ensuring deadlock- and collision-free execution. Unfortunately, existing optimal algorithms, such as Mixed Integer Linear Programming and Graph-Based Switchable Edge Search (GSES), are often too slow for practical use. This paper introduces Improved GSES, which significantly accelerates GSES through four speedup techniques: stronger admissible heuristics, edge grouping, prioritized branching, and incremental implementation. Experiments conducted on four different map types with varying numbers of agents demonstrate that Improved GSES consistently achieves over twice the success rate of GSES and delivers up to a 30-fold speedup on instances where both methods successfully find solutions.", "sections": [{"title": "Introduction", "content": "Multi-Agent Path Finding (MAPF) (Stern et al. 2019) focuses on planning collision-free paths for multiple agents to navigate from their starting locations to destinations. However, during execution, unpredictable delays can arise due to mechanical differences, accidental events, or sim-to-real gaps. For instance, in autonomous vehicle systems, a pedestrian crossing might force a vehicle to stop, delaying its movements and potentially causing subsequent vehicles to halt as well. If such delays are not managed properly, they can lead to inefficiencies, deadlocks, or even collisions.\nTo address these issues, the Temporal Plan Graph (TPG) framework was first introduced to ensure deadlock- and collision-free execution (H\u00f6nig et al. 2016; Ma, Kumar, and Koenig 2017). TPG encodes and enforces the order in which agents visit the same location using a directed acyclic graph, where directed edges represent precedence. However, the strict precedence constraints often lead to unnecessary waiting. For example, as shown in Figure 1c, a delay by Agent 1 causes Agent 2 to wait unnecessarily at vertex F2 because TPG enforces the original order of visiting G. In such cases, switching the visiting order of these two agents would allow Agent 2 to proceed first, avoiding unnecessary delays.\nTo capture this idea, Berndt et al. (2024) introduced the notion of a switchable edge that can be settled in one of two directions, each representing one possible visiting order of two agents at a location. Then, they proposed the Switchable Temporal Plan Graph (STPG), a superclass of TPG that contains a set of switchable edges. By gradually settling these switchable edges, STPG allows the search for a Temporal Plan Graph (TPG) that encodes optimal visiting orders to minimize total travel time under delays. However, both Berndt's original solution based on Mixed Integer Linear Programming (MILP) and the subsequent Graph-"}, {"title": "Related Work", "content": "Approaches for handling delays in MAPF execution can be broadly categorized into offline and online methods.\nOffline approaches consider delays during planning. Robust MAPF planning methods (Atzmon et al. 2018, 2020) generate robust plans under bounded or probabilistic delay assumptions. While these methods improve robustness, they tend to produce conservative solutions and require significantly more computation than standard MAPF algorithms.\nOnline approaches, on the other hand, react to delays as they occur. The simplest method is to replan paths for all agents upon a delay, but this is computationally expensive. TPG (H\u00f6nig et al. 2016; Ma, Kumar, and Koenig 2017) avoids heavy replanning by adhering to the original paths and precedence constraints, but it often results in unnecessary waits due to overly strict ordering. To address this problem, Berndt et al. (2024) introduce the STPG framework to optimize the precedence by MILP. Despite its generality, the MILP approach is too slow for large-scale problems. To improve the scalability, Feng et al. (2024) propose a dedicated search algorithm, GSES, to replace the MILP. However, GSES still suffers from inefficiencies due to the large search tree and redundant computation. In contrast, Kottinger et al. (2024) proposed an alternative formulation that solves the same problem as STPG by introducing delays to agents' original plans. It constructs a graph for each agent and then applies standard MAPF algorithms to search for solutions. We refer to the optimal version of their algorithm, which applies Conflict-Based Search (CBS) (Sharon et al. 2015), as CBS with Delays (CBS-D). MILP, GSES, and CBS-D are all optimal algorithms, and we will compare our method against them in terms of planning speed in the experiments.\nDifferent from these optimal methods, Liu et al. (2024) propose a non-optimal heuristic approach called Location Dependency Graph (LDG), which reduces waits online using a formulation similar to STPG. Bidirectional TPG (BTPG) (Su, Veerapaneni, and Li 2024) is another non-optimal approach based on TPG, but it falls into the offline category. BTPG post-processes a MAPF plan and produces an extended TPG with special bidirectional edges. These edges enable agents to switch visiting orders at certain locations in a first-come-first-served manner during execution."}, {"title": "Background", "content": "In this section, we provide the necessary definitions and background for STPG optimization. For more details, please refer to the GSES paper (Feng et al. 2024).\n3.1 Preliminaries: MAPF, TPG, and STPG\nDefinition 1 (MAPF). MAPF problem aims at finding collision-free paths for a team of agents indexed by i \u2208 I on a given graph, where each agent i has a start location s' and a goal location g\u00b2. At each timestep, an agent can move to an adjacent location or wait at its current location. We disallow two types of conflicts like previous works (Feng et al. 2024):\n1. Vertex conflict: two agents take the same location at the same timestep.\n2. Following conflict: one agent enters a location occupied by another agent at the previous timestep.\nDefinition 2 (TPG). A Temporal Plan Graph (TPG) is a directed graph G = (V, E1, E2) that encodes a MAPF plan by recording its precedence of visiting locations.\nThe vertex set V = {v : p \u2208 [0, z\u00b2], i \u2208 I} records all locations that must be visited sequentially by each agent i.\u00b9 Specifically, z' is the number of locations for agent i, and each v is associated with a specific location, loc(v).\nThe edge set E\u2081 contains all Type-1 edges, which encode the precedence between an agent's two consecutive vertices. A Type-1 edge (v, v+1) must be introduced for each pair of v and v+1 to ensure that v must be visited before v+1.\nThe edge set E2 contains all Type-2 edges, which specify the order of two agents visiting the same location. Exactly one Type-2 edge must be introduced for each pair of v and vj \u2260 j, with loc(vi) = loc(v). We can introduce the Type-2 edge (v+1,v) to encode that agent i can only enter v after agent j leaves vi and arrives at v+1, or introduce its reversed edge (v+1, v) to specify that agent j can only enter vi after agent i leaves v and arrives at v+1\u00b7\nFor example, in Figure 1b, the red and blue arrows are Type-1 edges, and the black arrow is a Type-2 edge.\nWhen agent i moves along an edge e from v to v+1 and suffers from a t-timestep delay, we insert t vertices along e to encode this delay (e.g., Figure 1c) so that each edge in the figures always takes 1 timestep for an agent to move.2\nA TPG is executed in the following way. At each timestep, an agent i can move from v to v+1 if for every edge e ="}, {"title": "The Baseline Algorithm: GSES", "content": "We now introduce our baseline algorithm, Graph-based Switchable Edge Search (GSES) (Feng et al. 2024). We start with some useful definitions.\nDefinition 5 (Reduced TPG). The reduced TPG of an STPG GS = (V,E1, (S,N)) is the TPG that omits all switchable edges, denoted as Redu(GS) = (V,E1,N)."}, {"title": "Speedup Techniques", "content": "This section describes our methods to speed up the search in Algorithm 1, including constructing stronger admissible heuristics by estimating the future cost (Section 4.1), finding switchable edges that could be grouped and branched together (Section 4.2), different ways to prioritize switchable edges for branching (Section 4.3), and incremental implementation of computing longest path lengths (Section 4.4).\n4.1 Stronger Admissible Heuristics\nIn the Line 22 of Algorithm 1, we use the execution cost of the current STPG as the admissible h-value in the GSES. However, this cost is an estimation based on the reduced TPG with currently settled edges."}, {"title": "Stronger Admissible Heuristics", "content": "Intuitively, we can obtain extra information from the unsettled switchable edges. For example, in Figure 2a, the execution cost of the STPG is 8. The switchable edge (H\u00b9, G2) is not settled and, thus, ignored in the computation. But we know eventually, this edge will be fixed or reversed. If we fix it (Figure 2b), then the EAT of G\u00b2 will increase from 2 to 5 because now it must be visited after H\u00b9, the EAT of which is 4. In this way, we can infer that the EAT of vertex D2 will be postponed to 7, leading to an increase of 3 in the overall execution cost. If we reverse the edge, we will get a similar estimation of the future cost increase, which is 1 in Figure 2c. Then we know the overall cost will increase by at least min{3, 1} = 1 in the future for the STPG in Figure 2a.\nBefore the formal reasoning, we introduce another useful concept, vertex slack, for easier understanding later.\nDefinition 7 (Vertex Slack). The slack of a vertex $v$ to an agent j's goal location $g^j$ in an STPG is defined as $Sl(v, g^j) = L(g^j) - L(v) - L(v, g^j)$, if $v$ is connected to $g^j$ in the reduced TPG. $L(v)$ is the EAT at vertex $v$, which is also the forward longest path length. $L(v, g^j)$ means the longest path length from v to gi and we call it the backward longest path length (BLPL).\nThis slack term measures the maximum amount that we can increase the EAT at v (i.e., L(v)) without increasing the agent j's EAT at its goal (i.e., L(g)). In other words, $L(v) + Sl(v, g^j)$ is the latest time that agent i can reach v without increasing agent j's execution time. In Figure 2a, the EAT of G\u00b2 is L(G2) = 2, the longest path length from G2 to D2 is L(G2, D\u00b2) = 2 and the EAT of D\u00b2 is L(D2) = 4. Then the slack of G\u00b2 is $Sl(G^2) = 4 - 2 - 2 = 0$. It means that there is no slack, and any increase in the EAT of G2 will be reflected in the EAT of D\u00b2. Therefore, in Figure 2b, where L(G2) increases by 3, L(D2) also increases by 3.\nIt is worth mentioning that L(v, 9) cannot be obtained during the computation of L(v) and should be computed again by topological sort and dynamic programming in the backward direction (Line 20 of Algorithm 1). Unfortunately, in this computation, we need to maintain the backward longest path lengths from v to each goal location gi separately because the increase in a vertex v's EAT may"}, {"title": "Edge Grouping", "content": "In the MILP-based method, Berndt et al. (2024) proposed a speedup method named dependency grouping, explicitly called edge grouping in this work. Edge grouping tries to find switchable edges whose directions can be decided together. If these edges do not follow the same direction, we can easily find a cycle within this group of edges. Berndt et al. (2024) describe two obvious grouping patterns, parallel and crossing (Figure 3a and Figure 3b), which can be easily"}, {"title": "Prioritized Branching", "content": "In Line 26-Line 29 of Algorithm 1, we need to select a conflicting edge to branch. However, different prioritization in conflicting edge selection may influence the search speed. We experiment with the following four strategies:\n1. Random: randomly select a conflicting edge.\n2. Earliest-First: select the first conflicting edge e = (Up, Uq) with the smallest ordered-pair (L(vq), L(vp)).\n3. Agent-First: select the first conflicting edge with the smallest agent index. This is the strategy used by GSES.\n4. Smallest-Edge-Slack-First: select the first conflicting edge with the smallest edge slack Sl(e).\nIn Section 5, we find that Smallest-Edge-Slack-First performs the best empirically. The intuition behind this design is that Sl(e) reflects edge e's degree of conflict with the current STPG, and we want to address the most conflicting one first because it may influence the overall cost the most."}, {"title": "Incremental Implementation", "content": "In GSES, the computation of the longest path lengths (Line 20 of Algorithm 1) takes the most time in a search node construction, as illustrated in Figure 7. But each time we build a child node, we only add one edge (group) to the reduced TPG of the parent node. Therefore, We directly apply an existing algorithm for computing the longest path lengths incrementally in a directed acyclic graph (Katriel, Michel, and Van Hentenryck 2005) to speed up the search."}, {"title": "Experiments", "content": "Following the setting in the baseline GSES paper (Feng et al. 2024), we evaluate algorithms on four maps from the MAPF benchmark (Stern et al. 2019), with 5 different numbers of agents per map. For each map and each number of agents, we generate 25 different instances with start and goal locations evenly distributed. We then run 1-robust PBS on each instance to obtain the initial MAPF plans. We add the 1-robust requirement (Atzmon et al. 2018) to PBS (Ma et al. 2019) because the original PBS does not resolve the following conflicts. Each solved instance is tested with 6 different delay scenarios. We obtain a scenario by simulating the initial MAPF plan until some delays happen. An agent will be independently delayed for 10-20 steps with a constant probability $p\\in \\{0.002, 0.01, 0.03\\}$ at each step. We run 8 times for each scenario and set a time limit of 16 seconds for each run. Notably, since all the algorithms we compare with are optimal, we only compare their search time. Due to the space limit, we only report the results of 0.01 delay probability in the main text with others reported in Appendix A.4. The conclusions are consistent across different probabilities.\nAll the algorithms in the experiments are implemented in C++.6 All the experiments are conducted on a server with an Intel(R) Xeon(R) Platinum 8352V CPU and 120 GB RAM."}, {"title": "Comparison with Other Algorithms", "content": "We compare our method IGSES with the baseline GSES algorithm and other two optimal algorithms, MILP (Berndt et al. 2024) and CBS-D\u00b3 (Kottinger et al. 2024). The success rates on four maps with increasing sizes are shown in Figure 5. Compared to GSES, IGSES at least doubles the success rates in most cases. Due to the inefficiency of a general branch-and-bound solver, MILP can only solve instances on the small Random map. An interesting observation is that CBS-D is worse than GSES on small maps but generally becomes better than GSES as the map size increases. However, directly applying existing MAPF algorithms without tailored adaptations like CBS-D shows much worse performance than our IGSES, which better exploits the problem's structure. In Appendix A.4, we also plot the mean search time for different maps and agent numbers to support our conclusions."}, {"title": "Conclusion and Future Work", "content": "In this paper, we study the STPG optimization problem. We analyze the weakness of the optimal GSES algorithm and propose four speedup techniques. Their effectiveness is validated by both theoretical proof and experimental data. To scale to larger instances, a potential future direction is to devise sub-optimal algorithms for the STPG optimization problem to trade-off between solution quality and speed."}, {"title": "Appendix", "content": "A.1 Computing the Longest Path Lengths\nThis section describes the algorithms for computing the forward longest path lengths (FLPL) and backward longest path lengths (BLPL) on the reduced TPG. They are simple, so we mainly present the pseudocode.\nWe first describe the non-incremental version of these two algorithms in Algorithm 5 and Algorithm 6. The input graph G = (V, E) is the reduced TPG of the current STPG, where E contains both Type-1 edges and non-switchable Type-2 edges. The topological ordering, Ordered(V), obtained in the computation of FLPL will also be input to the calculation of BLPL. The returned L(v) and L(v, g) represent the functions of FLPL and BLPL, respectively.\nWhen computing the FLPL in Algorithm 5, we update L(v) by the predecessors of v (Line 6) in the topological ordering. Similarly, when computing the BLPL in Algorithm 6, we update L(v, g\u00b2) by the successors of v that are connected to g\u00b2 (Line 8) in the reverse topological ordering."}, {"title": "Forward Longest Path Lengths", "content": "When computing the FLPL in Algorithm 7, we update the L'(v) by the predecessors of v (Line 11). If the length changes, we push into the heap all the successors of v that have not been visited for future updating (Line 17). Similarly, when computing the BLPL in Algorithm 8, we update the L'(v, gi) by the successors of v that are connected to g\u00b2 (Line 12). If any length changes, we push into the heap all the predecessors of v that have not been visited for future updating (Line 18).\nSince the incremental implementation only updates the longest path lengths for a small portion of vertices affected by the newly added edge (group) in the reduced TPG, the computational complexity is significantly reduced."}, {"title": "The Termination Condition of GSES", "content": "This section proves the termination condition of GSES.\nProposition 1. If there is no conflicting switchable edge found in Line 8 of Algorithm 1, GSES can be terminated by fixing all the switchable edges. It returns an acyclic TPG with the same execution cost as the current reduced TPG.\nIf all the switchable edges are not conflicting, then their edge slacks $Sl(e) \\geq 0$, $ \\forall e \\in S$, where S is the set of switchable edges in the current STPG $G_S$. To prove that fixing all the switchable edges will not introduce any cycle and extra cost, we prove Lemma 2, which considers the case of adding only one edge to an acyclic TPG.\nLemma 2. Given an acyclic TPG $G = (V,E_1,E_2)$ with the forward longest path lengths as L(v), v \u2208 V. If we add to G a new Type-2 edge $e' = (v_1, v_2)$ with its slack $Sl(e') = L(v_2) - L(v_1) -1 \\geq 0$, then the new graph $G' = (V, E_1, E_2')$ remains acyclic, where $E_2' = E_2 \\cup \\{e'\\}$. Further, it has the same forward longest path lengths as G at each vertex v. Namely, $L' (v) = L(v), \\forall v \\in V$.\nProof. By definition, L(e) \u2265 0 for all e \u2208 E2. Since L(e') > 0 as well, so we can state that L(e) \u2265 0 for all e E E2."}, {"title": "Greedy Matching Algorithm For EWMVC", "content": "This section describes the greedy matching algorithm for the Edge-Weighted Minimum Vertex Cover (EWMVC) problem in Section 4.1. We have a weighted fully-connected undirected graph GD = (VD, ED, WD), where each vertex ui \u2208 VD represents an agent, ED are edges and WD are edges' weights. Specifically, we set the weight of each edge (Ui, uj) \u2208 Ep to be the pairwise cost increase, $\\Delta cost(g^i, g^j)$ obtained from our stronger heuristic reasoning. Our target is to assign a cost increase xi to each vertex ui such that xi + xj > \u2206cost(g\u00b2, g\u00b9) so that the overall cost increase \u2211i xi is minimized.\nThe pseudocode is illustrated in Algorithm 9. Briefly speaking, the algorithm always selects the max-weighted edge at each iteration, whose two endpoints have never been matched. Then, the weight is added to the overall weight, and the two endpoints are marked as matched. Since each iteration checks all the edge weights and we assume it is a fully connected graph, each iteration takes O(|VD|2) time. There could be, at most, VD iterations. The worst-case complexity of this algorithm is O(|VD|\u00b3)."}, {"title": "Experiments", "content": "This section explains more details about our benchmark, code implementation, and how to reproduce the experiments. We also illustrate experiment results with different delay probabilities. To be more self-contained, this section may overlap with the main text.\nBenchmark The benchmark generation process is described in the main text. Notably, our benchmark evaluates with as twice many agents as the benchmark used in the GSES paper (Feng et al. 2024). Therefore, We use k-robust PBS rather than k-robust CBS to obtain the initial MAPF plan since the former is much faster than the latter when solving instances with more agents. We run k-robust PBS on 25 instances with evenly distributed starts and goals from"}]}