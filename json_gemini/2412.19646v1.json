{"title": "CHIMERA: A BLOCK-BASED NEURAL ARCHITECTURE SEARCH FRAMEWORK FOR EVENT-BASED OBJECT DETECTION", "authors": ["Diego A. Silva", "Ahmed Elsheikh", "Mohammed E. Fouda", "Kamilya Smagulova", "Ahmed M. Eltawil"], "abstract": "Event-based cameras are sensors that simulate the human eye, offering advantages such as high-speed robustness and low power consumption. Established Deep Learning techniques have shown effectiveness in processing event data. Chimera is a Block-Based Neural Architecture Search (NAS) framework specifically designed for Event-Based Object Detection, aiming to create a systematic approach for adapting RGB-domain processing methods to the event domain. The Chimera design space is constructed from various macroblocks, including Attention blocks, Convolutions, State Space Models, and MLP-mixer-based architectures, which provide a valuable trade-off between local and global processing capabilities, as well as varying levels of complexity. The results on the PErson Detection in Robotics (PEDRo) dataset demonstrated performance levels comparable to leading state-of-the-art models, alongside an average parameter reduction of 1.6 times.", "sections": [{"title": "Introduction", "content": "Object detection is a critical task in computer vision that involves identifying objects and determining their locations within an image. This capability is essential for various real-world applications, including autonomous driving [1], robotics [2], and surveillance [3]. Traditionally, these applications rely on data from RGB cameras, which provide a continuous stream of high-resolution images [4]. Recently, event-based cameras were introduced a new sensing paradigm, inspired by the human eye's functioning [5]. Unlike traditional cameras, pixels in event-based sensors generate outputs independently only when changes occur in the scene, leading to a spatio-temporal stream of events in response to brightness variations. Event-based sensors offer several advantages over RGB cameras, such as microsecond-range latency, a High Dynamic Range (HDR) exceeding 120 dB, power consumption in the milliwatt range, and potential memory savings by discarding redundant information [6].\nAmong the various techniques developed for object detection using RGB input, deep learning algorithms, particularly the You-Only Look-Once (YOLO) family and transformer-based detectors-have achieved significant success [4]. Various YOLO versions were introduced, enhancing its speed and accuracy while maintaining minimal trainable parameters [7]. There is a notable correlation between the success of deep learning methods in RGB applications and their performance in the event-based domain, as seen with convolutional networks [8], [9], [10], and transformer-based networks [11], [12], [13], [14]. Many of these networks are designed monolithically, meaning they consist of repeated layers of the same blocks.\nAdditionally, in conventional computer vision, integrating different architectural blocks into a single hybrid network has shown benefits. Specifically, using convolutions in the trunk layers and transformers in the later stages has proven effective in balancing local and global contextual processing and managing computational complexity across"}, {"title": "Related Works", "content": "Currently, there are various neural architectures available for vision tasks. Existing event-based object detectors can be divided into two primary categories based on their processing approach: sparse models and dense models. Sparse models process input event streams asynchronously and include techniques like Graph Neural Networks (GNN) [23], [24], [25] and Spiking Neural Networks (SNN) [26], [27], [28], [29], [30], [31], [32], [33]. In contrast, dense models convert event streams into an intermediate format suitable for neural networks that process image-like features. The most common and effective configurations for dense neural networks are built using convolutional layers [8], [9], [34], [35], [10], as well as self-attention blocks and their variants [11], [12], [13], [36], [14]. Additionally, several architectures integrate Recurrent Neural Networks (RNNs) to enhance temporal modeling [8], [11], [9]. Notably, State Space Models (SSM) [14] and Hierarchical Memory Networks (HMNet) [37] are also implemented in this context. Although significant has been done on sparse models, there is still a gap in performance between them and the dense approaches, which motivates adopting the latter in this work."}, {"title": "Hybrid Neural Networks", "content": "Combining diverse blocks into a hybrid architecture and leveraging their complementary features can enhance perfor-mance while achieving a balanced trade-off between computational complexity and global/local modeling [19], [38]. For example, transformer-based models are recognized for their state-of-the-art accuracy in vision applications [39], but their high computational complexity can make processing high-resolution images challenging. To mitigate this issue, it is common practice to employ convolutional layers in the initial stages for input downsampling, followed by transformer-based blocks as the resolution decreases [40]. This approach helps to maintain a balance between local and global feature modeling throughout the network [17], [16], [15], [18].\nSimilarly, convolutional layers have been used with MLP-Mixers to accommodate arbitrary input resolutions while reducing computational complexity [19]. In EfficientVMamba, an integration of convolutional blocks with State Space Models (SSM) was implemented, but unlike previous approaches, the SSM blocks were positioned in the early stages of the network to maximize global feature capture, with convolutional layers placed in the later stages [41]. Conversely, MambaVision [20] employs convolutional layers at higher resolution layers while incorporating a mixer block that alternates between Mamba [38], an SSM block, and self-attention [39]. Other methodologies explore modifications of convolutional blocks with self-attention [42], the reverse [43], [44], [45], [15], and even the creation of novel blocks that combine both paradigms [45], [16], [17], [46]."}, {"title": "Zero-Shot NAS", "content": "Neural Architectural Search (NAS) was developed to automate the process of finding the structure and design of neural networks considering the given constraints to improve performance In this work, the preference is given to the Zero-Shot NAS, which eliminates the need for training neural networks and, therefore, improves cost and time efficiency [47]. Moreover, it offers high scalability and can be optimized for specific metrics using zero-shot proxies. The proxies are developed based on theoretical and empirical analysis of deep neural networks, incorporating factors such as topology, initialization, gradient propagation, etc. Understanding how they impact the overall performance enhances interpretability and predictions.\nThe implementation of Zero-Shot NAS requires identifying a design space of candidates F and selection of proxy metrics. As a result, the framework evaluates the candidate architectures, ranks them according to the estimated proxy scores, and selects the top architectures."}, {"title": "Methodology", "content": "Event-based cameras are 2D sensors that detect brightness fluctuations at the pixel level. This phenomenon can be quantitatively represented as follows:\n$\\AL(Xk, Yk, tk) \u2265 PkC$                                                                        (1)\nIn this equation, $\\AL$ represents the logarithmic change in the current of a photoreceptor (brightness) at the pixel coordinates (xk, Yk) at timestamp tk. The term pk \u2208 {+1,-1} denotes the polarity of the event, indicating that a brightness change that surpasses the threshold (C) in absolute value triggers a positive or negative event [5]. Each event is defined by the tuple ek = (xk, Yk, Pk, tk). To facilitate the processing of event data, it is common to convert it into an intermediate format that Deep Learning algorithms can easily handle.\nChimera has a modular design consisting of fixed and variable computing blocks, also comprising choices of such event conversion. Overall, its structure is inspired by the architecture of Recurrent YOLOv8 (ReYOLOv8) [10] and consists of a recurrent backbone module for feature extraction from the input and the multi-scale feature fusion and detection heads adopted from the original YOLOv8 model [48]. The NAS in Chimera focuses on finding the best-performing combination of heterogeneous variable blocks for composing the architecture of a recurrent backbone.\nThe framework includes multiple steps:\n\u2022 Creation of a design space and benchmarks;\n\u2022 Selection of proxy metrics and evaluation of the candidates from the search space;\n\u2022 Evaluation of the resulting Chimera network on the dataset PEDRO."}, {"title": "Chimera Network Organization", "content": "Figure 1 displays the fundamental architecture of Chimera's recurrent backbone, which consists of seven layers. It begins with a variable Event Encoding block, followed by a 3x3 downsampling convolutional STEM layer. The subsequent four layers are called Chimera layers, each having an identical structure but varying compositions. Each of these four layers comprises three components: downsampling, processing, and a memory cell. The downsampling components resemble the STEM layer, while the memory cell is a fixed structure based on ConvLSTM [49]. The ConvLSTM is modeled after a standard LSTM [50], with the critical distinction that the fully connected layers in the LSTM gates have been replaced by convolutional layers, allowing it to effectively process spatial features, similar to the implementations seen in Recurrent Vision Transformer (RVT) [11] and ReYOLOv8 [10]. The Downsample block diminishes the spatial dimensions before passing the features to the variable processing block, which extracts relevant information from the current features, while the following memory cell performs spatiotemporal modeling between the current and previous feature maps. The processing block can utilize any option available in Chimera's component library, and the choice of block for each Chimera Layer is made independently from the others.\nThe final layer of the recurrent backbone is a fixed Spatial Pyramid Pooling Fast (SPPF) [51] block, stacked to Chimera Layer 4 and is inherited from YOLOv8 [48]. Detection within the Chimera framework is carried out using the multi-scale YOLOv8 detection head, considering the findings reported in [10] as well as the successful application of other YOLO models within the event-based literature [11], [36], [14]."}, {"title": "Library of Components", "content": "The library supporting Chimera is comprised of various building blocks and options for data encodings. This section will provide a brief overview of each component. Further details regarding their implementations are available in the Supplementary Material."}, {"title": "Building Blocks", "content": "\u2022 Convolutional Layers. The well-recognized capability of Convolutional Neural Networks (CNNs) to extract features has significantly transformed a variety of computer vision tasks [52]. For example, YOLOv8, which serves as the foundation of the Chimera framework, is composed of backbone, neck, and head blocks made entirely of convolutions, like the downsampling convolutions and the C2f blocks adopted for finer feature extraction [48]. Then, besides the convolutional layers on the YOLOv8 detection heads and in the downsampling and SPPF operations from the backbone, the C2f was selected as one of the possible processing blocks for the Chimera Layers.\n\u2022 Transformers. Transformers are highly powerful in modeling global context information due to the presence of self-attention operations [39]. However, this operation has quadratic complexity concerning the input size, which incurs computational burdens. In this context, Multi-axis Vision Transformer (MaxViT) [16] is a variation of self-attention with reduced computational complexity. Moreover, it was already successfully adopted in the event domain [11], which motivated us to include it in Chimera's library.\n\u2022 MLP-Mixers. Multilayer Perceptron (MLP)-Mixers model both local and global relationships through channel mixing and token mixing [53]. Token mixing captures spatial information, while channel mixing focuses on feature information. Particularly, WaveMLP is an MLP-Mixer that treats tokens as waves, incorporating amplitude and phase information and introducing a Phase-Aware Token Mixing module (PATM) [54]. Due to its flexibility and reported performance, WaveMLP was included in the Chimera library.\n\u2022 State Space Models. Grounded in continuous-time linear systems, these models have recently gained prominence for their efficiency in parallel processing. A variety of models adhering to this principle have emerged, mainly differing in their matrix representations. The Mamba block, which is included in the library, has attracted significant attention recently, both in the context of Large Language Models (LLMs) [38] and in the vision domain [20]."}, {"title": "Data Encodings", "content": "To allow a dense neural architecture to effectively process input events, these events must be converted into a grid-like format [8]. Various encoding schemes have been proposed, each varying in its capacity to capture events. In our"}, {"title": "Chimera-NAS", "content": "Chimera-NAS is inspired by ZS-NAS, which provides the flexibility to choose proxies for selecting the best candidate neural blocks. In this study, we selected several ZS-NAS proxies from a range of existing options [57], including gradient-based accuracy proxies such as Zen-Score [47] and the Neural Tangent Kernel (NTK) Condition Number [58], along with naive proxies based on the number of parameters, denoted as #Params, and Multiply-Accumulate (MAC) operations. Additionally, a diversity index was introduced to ensure heterogeneity within the architecture. Together, these components address multiple objectives to achieve a balanced structure."}, {"title": "Search Metrics", "content": "\u2022 Zen-Score The expressive capacity of a network refers to its ability to effectively capture complex relationships within the input data.\nFor vanilla CNNs, it can be associated with Gaussian complexity according to\n$\\$(f) = log Ex,0||\u2207xf(x|0)||F                                                                           (2)\nwhere x is the input, @ the network parameters, and f(.) is the network backbone with the last feature before the Global Average Pooling (GAP) operation. The formulation from Equation 2 considers a network without Batch Normalization (BN) layers. However, this leads to problems such as overflow when applied to deep networks. The Zen-score solved this problem by introducing BN layers and considering their variance into the score computation [47]. Furthermore, to avoid adopting the backward propagation from Equation 2, they calculate the score according to the finite differential\n$\\Delta = Ex,e||f(x) f(x + \u03b1\u03b5) || F$                                                                          (3)\nwhere e is a random disturbance and a is an adjust parameter for this noise. Then, the Zen-score is given by:\n$Zen(f) = log(\\Delta) + \\log(\u03c3\u03b5)$                                                                          (4)\nwhere i refers to the index of the BN layers, each with its respective standard deviation \u03c3\u03c4. Originally, both x, 0, and e were taken from a standard Gaussian Distribution [47]. Also, in Chimera, f(.) will consider the whole backbone block, including the SPPF block.\n\u2022 Neural Tangent Kernel (NTK) Condition Number The NTK (Neural Tangent Kernel) of a Neural Network can be expressed as follows:\n$\\Theta(x, x') = J(x)J(x')^T$                                                                           (5)\nwhere J(x) represents the Jacobian evaluated at (x) with respect to the parameters \u03b8. It has been demonstrated that the training dynamics of a neural network under gradient descent can be characterized by the conditioning of its NTK matrix, which is given by:\n$NTKcond = \\frac{\u03bb0}{\u03bbm}$                                                                         (6)\nwhere 10 and Am denote the lowest and highest eigenvalues of \u0398(x, x'), respectively. A well-conditioned NTK matrix is linked to enhanced trainability, and a negative correlation between NTK conditioning and test-set accuracy for image classification tasks has also been reported [58].\n\u2022 Model Parameters and Complexity. The number of parameters in a model and its complexity, measured in terms MACs, have been found to exhibit a certain degree of correlation with the model's test accuracy. These factors will also be included in the analysis of this work [57].\n\u2022 Diversity Index. To assess the distribution of different types of blocks within a given architecture, we introduce an index to measure architectural diversity. Let B(f) \u2208 RN\u00d71 represent a vector where N denotes the number"}, {"title": "Search Space", "content": "The design space F of Chimera includes a variety of modules and parameters, notably event encoding and processing blocks. The encoding blocks convert the input stream of events into formats such as VTEI, SHIST, MDES, or TAF, which are discussed in detail in Section 3.2.2. For this study, the number of temporal bins assigned for the input representation is set to five. Following this, the output channel Ch will be specified at the STEM layer, defined by a 3x3 convolution with a stride of 2.\nFor each Chimera layer, a multiplier Mi, a processing block, and its corresponding parameters Block and BlockParams will be selected. The parameter Repeats is applicable for all blocks, except Mamba. For the C2f, this parameter represents how many bottleneck blocks will be stacked inside its structure, and for the remaining ones, it represents how many of each structure will be stacked together. For Mamba, the number of heads will also be considered a parameter, and a head multiplier will scale the number of heads of a given Mamba block according to its predecessor. Considering all the possible choices, around 20,000 combinations can be generated from this model generator."}, {"title": "Chimera-NAS Algorithm", "content": "The Chimera-NAS Algorithm operates in two stages. In the first stage, it generates and selects architectures using an Evolutionary Algorithm, favored for its simplicity and effectiveness, with prior results in the ZS-NAS domain [47]. The Fitness Score can be calculated based on any of the metrics described in Section 3.3.1, or as a combination of these metrics. For a given design space F, the optimization problem that Chimera-NAS seeks to solve to identify an effective architecture can be expressed as follows:\n$max_{fEF} F = aW \u2022 Z(f) + (1 \u2212 a)D(f)$\ns.t.\nParams(f) < MAXParams.\n(8)\nwhere Z(f) = [Zen(f), MAC's(f), NTKcond(f)] is a vector that includes the ZS-NAS proxies for the architecture f, weighted according to the vector W \u2208 R3\u00d71; D(f) represents the Diversity Index from Equation 7; Params(f) indicates the number of parameters in the architecture f; MAXParams is the upper limit on the number of parameters;"}, {"title": "Dataset", "content": "The PErson Detection in Robotics (PEDRO) dataset, focusing on robotics applications, is the dataset evaluated in this work. Captured in Italy using a handheld camera, PEDRO includes recordings of individuals in various scenes, lighting conditions, and weather scenarios, with 43k labels. The data was obtained using a DAVIS346 camera with a resolution of 346x260 pixels. To date, PEDRO is the only large-scale, real-world event-based dataset specifically tailored for robotics applications [59]. In all instances, the events were aggregated into intermediate representations utilizing constant time windows of 40 ms, as adopted in previous works [59], [10]. Results for another dataset, the Prophesee's Generation 1 Automotive Dataset (GEN1) [60], are included in the Supplementary Material."}, {"title": "Chimera Benchmark", "content": "To evaluate the accuracy of the selected proxies in predicting test set performance, a benchmark was created using a subset of architectures from the Design Space. The PEDRO dataset was chosen for this evaluation due to its relatively small size. Each model was trained for 50 epochs, providing an effective compromise between runtime and convergence, and the mAP for the test set was recorded. Additionally, the Zen Score, MACs, number of parameters, and NTK_cond were documented. This analysis involved running 250 randomly generated heterogeneous models. Initially, each model was trained using VTEI, MDES, TAF, and SHIST representations, with 5 temporal bins each.\nTwo correlation measures assessed how effectively the proxies approximate the mAP ground truth. One of these, Kendall's Tau, compares the ranking of models based on mAP and the proxies. The other metric used is Spearman's correlation, which measures the degree of monotonicity between the two variables, in this case, the proxies and the mAP [57]."}, {"title": "Training Procedure", "content": "For both the benchmark and final performance analysis, the same set of hyperparameters will be applied to each dataset, consistent with the procedures outlined in ReYOLOv8 [10]. An image size of 320x256 was utilized for both datasets to enhance compatibility during the search process across different blocks and datasets. The models were trained using"}, {"title": "Evaluation of the Chimera Benchmark", "content": "For the created benchmarks, the relationship between the ZS-NAS proxies and the event encodings was studied via analyzing the correlation between the rankings generated from these scores using Kendall's correlation and their actual mAP rankings. The results are illustrated in Figure 2a. On average, the Zen Score demonstrated the best performance among other proxies, followed by the number of MACs and the total number of parameters. The NTK exhibited a negative correlation with the actual mAP, not exceeding 0.2 in absolute value. Furthermore, the computation time for NTK was significantly higher than that required for the Zen Score. Consequently, NTK was excluded from further analysis.\nFigure 2b presents box plots of the mAP values for all heterogeneous architectures in the benchmark, grouped by encoding format. The results indicate that SHIST, MDES, and VTEI outperform TAF, whereas in the previous analysis, SHIST and TAF demonstrated a better relationship with the proxies than MDES and VTEI. Since SHIST demonstrated a superior performance in both evaluations, it was decided to use it for the subsequent experiments.\nBased on the results presented in Figure 2, a decision was made to explore further a fitness function that combines only the Zen Score and the number of MACs proxies. The number of parameters was excluded from the main function and instead treated as a constraint during the search process. Table 2 reflects the impact of various weight combinations for the Zen Score and MACs on their corresponding Kendall's and Spearman's correlations relative to the mAP at 50 epochs, derived from the full heterogeneous subset of SHIST in the Chimera benchmark The data reveals that the correlations increase up to a point when 60% of the score is derived from the Zen Score and 40% from MACs. Beyond this combination, the correlations begin to decline. Consequently, these weights were selected for use in the following experiments."}, {"title": "Analysis of ZS-NAS proxies and event encodings", "content": "For the created benchmarks, the relationship between the ZS-NAS proxies and the event encodings was studied via analyzing the correlation between the rankings generated from these scores using Kendall's correlation and their actual mAP rankings. The results are illustrated in Figure 2a. On average, the Zen Score demonstrated the best performance among other proxies, followed by the number of MACs and the total number of parameters. The NTK exhibited a negative correlation with the actual mAP, not exceeding 0.2 in absolute value. Furthermore, the computation time for NTK was significantly higher than that required for the Zen Score. Consequently, NTK was excluded from further analysis.\nFigure 2b presents box plots of the mAP values for all heterogeneous architectures in the benchmark, grouped by encoding format. The results indicate that SHIST, MDES, and VTEI outperform TAF, whereas in the previous analysis, SHIST and TAF demonstrated a better relationship with the proxies than MDES and VTEI. Since SHIST demonstrated a superior performance in both evaluations, it was decided to use it for the subsequent experiments.\nBased on the results presented in Figure 2, a decision was made to explore further a fitness function that combines only the Zen Score and the number of MACs proxies. The number of parameters was excluded from the main function and instead treated as a constraint during the search process. Table 2 reflects the impact of various weight combinations for the Zen Score and MACs on their corresponding Kendall's and Spearman's correlations relative to the mAP at 50 epochs, derived from the full heterogeneous subset of SHIST in the Chimera benchmark The data reveals that the correlations increase up to a point when 60% of the score is derived from the Zen Score and 40% from MACs. Beyond this combination, the correlations begin to decline. Consequently, these weights were selected for use in the following experiments."}, {"title": "Impact of the Diversity Index", "content": "Based on the findings from Section 4.1, SHIST was approved as the reference event encoding for the Chimera-NAS algorithm. Furthermore, as shown in Figure 2a and Table 2, the weights were set to W = [0.6,0.4,0.0], which"}, {"title": "Search Results", "content": "To conduct the search of the architectures, the Algorithm 1 was repeated with the same population and iteration parameters, utilizing the W obtained from Section 4.1 and the a = 0.05 established in Section 4.1.2 for three constraints of MAXParams set to 3M, 5M, and 10M. Generally, after the search, the composition of the population regarding block types remained nearly identical across all individuals, with only minor variations in other parameters such as the number of channels, heads, and multipliers. Table 3 presents the blocks within the Chimera Layers obtained as a result of search for these three cases. After 1,000 iterations for each scenario, the population exhibited the same composition and arrangement of blocks, with differences confined to the number of channels and other parameters specific to the blocks.\nTo optimize the number of trainable parameters, Chimera-NAS recommends positioning the MaxViT block within the earlier layers of Chimera to enhance the capture of global data context. The C2f block is a convolutional component that accelerates processing and enhances model accuracy, primarily concentrating on local feature extraction. In contrast, the SSM module in the Mamba architecture is specifically designed to address both long- and short-term dependencies. Consequently, it can be inferred that the Chimera-3M model places a greater emphasis on spatio-temporal modeling compared to the Chimera-5M. Furthermore, the WaveMLP block in Chimera Layer 4 facilitates the encoding of both local and global features.\nFor the Chimera-10M model, the initial phase focuses on learning short- and long-term dependencies while engaging in local feature extraction. Global feature extraction occurs in Chimera Layers 3 and 4 through the WaveMLP and Max ViT blocks."}, {"title": "Comparison with the state-of-the-art", "content": "Figure 3 presents the architectures generated from the three searches-Chimera-3M, Chimera-5M, and Chimera-10M-alongside comparisons to other works in the literature for PEDRO. The results from ReYOLOv8 only include outcomes before the application of Random Polarity Suppression (RPS) [10], an augmentation technique specific to VTEI that has not yet been investigated alongside other formats, and therefore, were not applied to the Chimeras using SHIST. The MaxViT-Base model adheres to the backbone specifications from RVT [11] but was trained under the same setup as the other models in this work.\nThe Chimera networks demonstrate strong performance, particularly at lower scales. Specifically, Chimera-3M performs similarly to ReYOLOv8n but with 1.5 times fewer parameters. Meanwhile, Chimera-5M shows an improvement in mAP of approximately 9% compared to a similarly scaled ReYOLOv8n, achieving a comparable mAP to ReYOLOv8s, but with a model size that is 1.7 times smaller. However, Chimera-10M does not yield significant improvements over Chimera-5M or other similarly scaled models in the literature. One potential explanation for this is that at the 10M parameter constraint, the search space becomes larger than at lower scales, which may complicate the search process."}, {"title": "Conclusions and Future Work", "content": "This work presents a two-stage NAS approach specifically aimed at Event-Based Object Detection. Instead of exploring variations of particular blocks, the architecture search centered on combining blocks from various paradigms within the literature to create more robust architectures. The resulting framework, named Chimera-NAS, utilizes proxies to assess architecture performance on test sets without requiring extensive training, enabling the examination of over 1,000 structures within a few hours. To manage the diversity of blocks within the architectures, a diversity index was introduced to quantify this aspect. The results obtained on the PEDRO dataset demonstrated significant improvements, achieving performance comparable to state-of-the-art models while maintaining an average parameter reduction of 1.6x. Future work will explore more blocks, alternative types of memory cells, such as State Space Models, and larger datasets, specifically Prophesee's GEN1 and 1MegaPixel."}]}