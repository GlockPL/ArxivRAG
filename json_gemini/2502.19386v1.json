{"title": "EFFICIENT 4D FMRI ASD CLASSIFICATION USING SPATIAL-TEMPORAL-OMICS-BASED\nLEARNING FRAMEWORK", "authors": ["Ziqiao Weng", "Weidong Cai", "Bo Zhou"], "abstract": "Autism Spectrum Disorder (ASD) is a neurodevelop-mental disorder impacting social and behavioral development. Resting-state fMRI, a non-invasive tool for capturingbrain connectivity patterns, aids in early ASD diagnosis anddifferentiation from typical controls (TC). However, previ-ous methods, which rely on either mean time series or full4D data, are limited by a lack of spatial information or byhigh computational costs. This underscores the need for anefficient solution that preserves both spatial and temporalinformation. In this paper, we propose a novel, simple, andefficient spatial-temporal-omics learning framework designedto efficiently extract spatio-temporal features from fMRI forASD classification. Our approach addresses these limita-tions by utilizing 3D time-domain derivatives as the spatial-temporal inter-voxel omics, which preserve full spatial reso-lution while capturing diverse statistical characteristics of thetime series at each voxel. Meanwhile, functional connectivityfeatures serve as the spatial-temporal inter-regional omics,capturing correlations across brain regions. Extensive experi-ments and ablation studies on the ABIDE dataset demonstratethat our framework significantly outperforms previous meth-ods while maintaining computational efficiency. We believeour research offers valuable insights that will inform andadvance future ASD studies, particularly in the realm ofspatial-temporal-omics-based learning.", "sections": [{"title": "1. INTRODUCTION", "content": "Autism Spectrum Disorder (ASD) is a neurodevelopmen-tal disorder that impacts social interaction, communication,learning, and behavior [1]. Early diagnosis is crucial foreffective intervention and treatment but presents significantchallenges. Traditional clinical diagnostic methods primar-ily rely on behavioral and cognitive assessments, which arenot only time-consuming and labor-intensive but also highlysubjective, increasing the risk of misdiagnosis. Therefore,developing fully automated ASD diagnostic technology isessential, as it would alleviate the burden on clinicians andfacilitate early symptom identification, enabling timely inter-vention and treatment [2]. Functional Magnetic ResonanceImaging (fMRI) is widely valued for its non-invasiveness,high spatial-temporal resolution, and ability to provide de-tailed insights into both physiological and pathological brainactivity [3, 2, 4, 2, 5]. Resting-state fMRI (rs-fMRI), whichcaptures brain activity in a resting state, is particularly suit-able for ASD patients and has been widely used to investigatealtered brain connectivity and activity patterns in ASD. In linewith most ASD classification studies, we leverage rs-fMRIdata to distinguish ASD patients from typical controls.\nDeep learning (DL) has been extensively applied to thediagnosis of brain disorders, including ASD. Given that rs-fMRI data capture both spatial and temporal signals, manyDL-based approaches focus on dimensionality reduction tomanage the complex spatio-temporal information effectively.These methods typically employ different brain atlases to par-tition the brain into approximately 100 to 400 distinct func-tional regions. For each region of interest (ROI), the meantime series is extracted and either directly processed by a1D convolutional network [6] or used to compute correlationcoefficients between ROIs, thereby constructing a functionalconnectivity matrix for subsequent classification [7, 3, 8, 9,10, 11, 12, 13]. Since these hand-crafted features can be pre-computed and the classifiers are typically simple, such meth-ods are computationally efficient and less prone to overfitting.However, this aggressive downscaling often fails to fully cap-ture the rich spatio-temporal information inherent in 4D fMRIdata, potentially disrupting essential temporal and spatial cor-relations. Consequently, the ability to detect complex neuralactivity patterns may be compromised, leading to suboptimalperformance. Alternatively, to avoid excessive dimensional-ity reduction and better preserve spatio-temporal information,several studies have proposed learning directly from full 4DfMRI sequences [14, 15, 16, 2, 17]. While this approach retains more information, processing full 4D fMRI data typ-ically requires a significantly larger number of network pa-rameters, resulting in higher computational costs and longerconvergence times. This reduces efficiency and increases therisk of overfitting. Additionally, the varying temporal lengthsof 4D data, due to different scan durations, necessitate crop-ping fixed-length sub-sequences during training. During in-"}, {"title": "2. METHOD", "content": "ference, a temporal sliding window is used to cover the entiretime series, further exacerbating inefficiencies.\nIn this study, we propose a spatial-temporal-omics-basedlearning framework (STO) to overcome the limitations of pre-vious methods and enable efficient and intelligent learning ofspatio-temporal features for ASD classification. Our frame-work integrates two complementary types of spatial-temporalomics: inter-voxel and inter-regional. For spatial-temporalinter-voxel omics (STVOmics), which focuses on voxel-levelanalysis, we extract 3D time-domain derivatives from 4DfMRI, capturing diverse statistical characteristics of the timeseries at each voxel while preserving full spatial resolution[18]. These features are then processed by a 3D CNN togenerate rich voxel-wise representations. In contrast, spatial-temporal inter-regional omics (STROmics), which focuseson regional-level analysis, utilizes functional connectivityfeatures to produce compact region-wise information througha single-layer perceptron (SLP). The voxel-wise and region-wise omics are subsequently fused and passed through anSLP for final ASD classification. Furthermore, our method ishighly scalable, allowing seamless integration with existingfunctional connectivity-based techniques for inter-regionalomics analysis.\nWe evaluated our approach against methods that eitherprocess full 4D fMRI or rely on mean time series acrossvarying dataset sizes using the ABIDE benchmark datasetfor ASD classification. Our results demonstrate that theproposed framework consistently achieves significant per-formance improvements over other methods in all scenarioswhile maintaining simplicity and computational efficiency.We believe our experiments and analyses provide valuableinsights for advancing ASD research."}, {"title": "2.1. Spatial-Temporal-Omics-based Framework", "content": "Previous DL-based methods for ASD classification either ex-tract mean time series using various brain atlases or explore\nspatio-temporal information from full 4D fMRI data. The firstapproach often struggles to capture complex neural activitypatterns due to significant spatial information loss, while thesecond approach increases computational cost and modelcomplexity. To address these issues, our STO frameworkprovides an effective solution by combining two complemen-tary omics. This method preserves spatial resolution whileextracting rich temporal features. As shown in Figure 1, theframework integrates inter-voxel and inter-regional omics,processed in parallel branches.\nSpatial-Temporal Inter-Voxel Omics: We extract 3D time-domain statistical features from 4D fMRI data at each voxel,known as STVOmics. This approach preserves full spatialresolution, effectively capturing the detailed spatio-temporalcharacteristics of fMRI data across voxels. The extracted fea-tures are then processed by a lightweight 3D CNN to generaterich voxel-wise representations.\nSpatial-Temporal Inter-Regional Omics: Following Li etal. [7], we select features from the upper triangle of thefunctional connectivity matrix as STROmics, which cap-ture spatio-temporal characteristics across brain regions andreduce the complexity of 4D data. These 1D features arepassed through a fully connected layer to be mapped into thesame embedding space as the inter-voxel omics features. Todemonstrate the versatility of inter-regional omics in integrat-ing with functional connectivity-based methods, we adopt theDiagNet training paradigm [13]. In this approach, input fea-tures are downsampled, and a decoder is introduced after theencoder to reconstruct the input from intermediate features,as shown in the reconstruction section of Figure 1.\nFinally, the encoded features from both omics are con-catenated and fed into a fully connected layer to generate pre-dictions for ASD classification."}, {"title": "2.2. Dataset and Preprocessing", "content": "This study leveraged the publicly available ABIDE-I datasetprovided [19], which comprises data from 1,112 subjects, in-cluding 539 ASD patients and 573 healthy controls, collectedfrom 17 different sites across North America and Europe. Thedataset includes T1-weighted structural brain images, fMRIscans, and extensive phenotypic information for each sub-ject. After performing rigorous quality control, we finalizedadataset of 871 subjects, consisting of 403 ASD patientsand 468 healthy controls. The dataset was then preprocessedusing the Connectome Computation System (CCS) pipeline,which involved several key steps: slice timing correction, mo-tion correction, and voxel intensity normalization. Subse-quently, nuisance signal removal was performed to mitigateconfounding variations caused by head motion, physiologi-cal processes. After nuisance regression, bandpass filtering(0.01-10 Hz) was applied, without global signal correction.Finally, spatial normalization was conducted to align the brainimages with the Montreal Neurological Institute (MNI) tem-"}, {"title": "2.3. Evaluation Metrics and Baseline", "content": "plate, achieving a uniform resolution of 3 \u00d7 3 \u00d7 3 mm\u00b3. It isnoteworthy that while the 3D spatial dimensions of the fMRIdata are consistent across sites 61 \u00d7 73 \u00d7 61, the temporaldimensions vary from 78 (OHSU) to 316 (CMU).\nIn addition to the 4D fMRI data, the ABIDE initiativeoffers several valuable statistical derivatives and mean timeseries for different brain atlases. For methods based on func-tional connectivity, we utilized the widely adopted AutomatedAnatomical Labeling (AAL) atlases and the Craddock 200(CC200) atlas to compute the average time series across 116and 200 functionally homogeneous ROIs. The resulting meantime series is organized into a 2D matrix, with each row rep-resenting a time point and each column corresponding to anROI. For temporal statistics, we employed four 3D deriva-tives that preserve the full spatial resolution of the original 4DfMRI data. These derivatives include Regional Homogeneity(ReHo), Degree Centrality (DC), Local Functional Connec-tivity Density (LFCD), and Voxel-Mirrored Homotopic Con-nectivity (VMHC). Further details regarding these derivativescan be found in [20].\nFollowing most studies on ASD classification, we performed5-fold cross-validation. We applied data splitting separatelyto the ASD and TC subsets in each fold to ensure that classproportions remained consistent with the original dataset inboth the training and testing folds.\nWe adopt the Area Under the ROC Curve (AUC) met-ric for evaluating classification performance. Unlike accuracyand F1 score, which are highly sensitive to decision boundaryselection, AUC offers a more robust and interpretable assess-ment across varying thresholds. In addition, we report modelparameters, GFLOPs, and memory consumption to compre-hensively evaluate computational efficiency.\nTo ensure a fair comparison, we replicated several rep-resentative methods based on mean time series and 4D data,using the same data and settings. Additionally, to demon-strate the robustness and effectiveness of our proposed frame-work, we evaluated all methods with varying data proportions(100%, 75%, 50%), modifying only the number of trainingsamples while keeping the same test set across experiments.Below, we provide a brief overview of the baseline methodsimplemented for comparison with our proposed method:\nBaselines with Mean Time Series as Input:\n\u2022 1DConv [6]: Utilizes a 1D convolutional layer to processthe mean time series matrix, where each channel corre-sponds to a different ROI, and the signal sequence cap-tures the entire temporal progression.\n\u2022 FC_2DCNN [12]: Takes the functional connectivity ma-trix as input to a 2D CNN. This network consists of 7 par-allel blocks, each containing a convolutional layer and amax-pooling layer. The convolutional kernel sizes rangefrom (1, M) to (7, M), where M is the number of ROIs,operating on rows that represent brain regions."}, {"title": "2.4. Implementation", "content": "Baselines with Full 4D Data as Input: For these methods,we set the cropped time steps during training and the slidingstride during inference to 15, while reducing the spatial reso-lution to 32, consistent with the 3D approaches.\n\u2022 3DCNN-MS [21]: Utilizes a sliding window to computetemporal statistics (mean and standard deviation) as 2-channel inputs to a 3D CNN (ResNet-10).\n\u2022 3DCNN-TC [16]: Treats time points as stacked channelsand processes the 4D data using a 3D CNN (ResNet-10).\n\u2022 ConvGRU-CNN3D [16]: First applies temporal process-ing with a 3D ConvGRU, followed by spatial processingwith a 3D CNN (ResNet-10).\n\u2022 CNN3D-GRU [2]: Combines a 3D CNN with a GRU forspatio-temporal feature extraction.\n\u2022 3DCNN-ConvLSTM [14]: Uses a shallow 3D CNN withfour convolutional layers at each time point, followed bya two-layer bidirectional ConvLSTM to capture both lo-cal spatial and global temporal information. The resulting3D feature maps are processed by a 3D CNN, temporallypooled, and then passed through a fully connected layerfor classification.\nWithout loss of generality, we chose the 3D ResNet-10 to pro-cess the STVOmics. The network starts with an initial convo-lutional layer, omitting max-pooling and using a kernel size of3. It is followed by three Basic-Res-Blocks, each containingtwo 3 \u00d7 3 \u00d7 3 convolutional layers, and ends with a 1 \u00d7 1 \u00d71downsampling layer. Global average pooling is applied afterthe final module to obtain spatial features. The encoded fea-ture dimensionality for both omics is standardized to 512. Thefinal fully connected layer uses a dropout rate of 0.2, followedby a sigmoid activation for ASD classification probabilities.\nTo improve the efficiency and reduce computational cost,we downscaled the spatial dimensions of the 3D temporalstatistics to 32 \u00d7 32 \u00d7 32, aligning with our implementa-tion of full 4D fMRI-based methods. To enhance general-ization, we applied standard spatial augmentations-flipping,rotation, translation, and scaling-to the 3D statistics. Allmodels were trained to convergence with a batch size of 8.We used the Adam optimizer with a learning rate of le-5 tominimize cross-entropy loss. During training, performancewas evaluated on the validation set every 5 epochs, and thebest-performing model was selected for final evaluation."}, {"title": "3. EXPERIMENTS AND RESULTS", "content": "We compared our models to previous deep learning-basedASD classification approaches, each employing distinctstrategies for handling temporal and spatial information."}, {"title": "4. DISCUSSION AND CONCLUSION", "content": "former consistently delivers better performance with signifi-cant computational advantages. This underscores the effec-tiveness of brain functional connectivity and its robustnessagainst overfitting, validating our choice of functional con-nectivity as the STROmics in the STO framework.\nTo identify the optimal STVOmics, we conducted ab-lation experiments using 3D temporal statistics. While theABIDE dataset provides eight types of time-domain deriva-tives, for simplicity, we focused on four key derivatives:ReHo, DC, LFCD, and VMHC. We assessed the performanceof each derivative individually and evaluated the combinedeffect by concatenating them along the channel dimension.As shown in Table 2, the results align with our expecta-tions, demonstrating that the combination of four derivativesyields the best performance. Furthermore, a comparisonof the results in Table 1 with those in Table 2 shows thatour framework-combining both STVOmics and STRO-mics-consistently outperforms the use of either omics alone,emphasizing the complementary nature of these two types.\nWe introduce a spatial-temporal-omics learning frameworkthat addresses the limitations of previous methods relying onmean time series or 4D data. Traditional approaches oftenstruggle with limited spatial information, increased modelcomplexity, and high computational costs. Our frameworkovercomes these challenges by using STVOmics to extract3D time-domain derivatives, preserving inter-voxel informa-tion, and STROmics to leverage 1D functional connectivityfeatures, capturing rich inter-regional temporal dynamicswith low computational cost. The synergy of these two omics\nsignificantly improves classification performance. Results\non the ABIDE dataset demonstrate that our method outper-\nforms existing approaches across all data proportions, whilemaintaining a simple network structure and reducing com-putational overhead. Although this paper presents the initialversion of the STO framework, future work could incorporateadditional 3D temporal statistics into STVOmics and exploremore advanced methods for STROmics. A key future di-rection will be developing better strategies to integrate bothomics and further improve performance."}, {"title": "5. ACKNOWLEDGMENTS", "content": "This research was supported by Australian Government Re-search Training Program (RTP) scholarship."}, {"title": "6. COMPLIANCE WITH ETHICAL STANDARDS", "content": "This research study was conducted retrospectively using hu-man subject data made available in open access by [19]. Eth-ical approval was not required as confirmed by the licenseattached with the open access data."}]}