{"title": "KAN based Autoencoders for Factor Models", "authors": ["Tianqi Wang", "Shubham Singh"], "abstract": "Inspired by recent advances in Kolmogorov-Arnold Networks (KANs), we introduce a novel approach to latent factor conditional asset pricing models. While previous machine learning applications in asset pricing have predominantly used Multilayer Perceptrons with ReLU activation functions to model latent factor exposures, our method introduces a KAN-based autoencoder which surpasses MLP models in both accuracy and interpretability. Our model offers enhanced flexibility in approximating exposures as nonlinear functions of asset characteristics, while simultaneously providing users with an intuitive framework for interpreting latent factors. Empirical backtesting demonstrates our model's superior ability to explain cross-sectional risk exposures. Moreover, long-short portfolios constructed using our model's predictions achieve higher Sharpe ratios, highlighting its practical value in investment management.", "sections": [{"title": "1 INTRODUCTION", "content": "Factor models are fundamental in quantitative finance. It provides a framework to forecast asset returns beyond standard return variation as a compensation for aggregated risk factors. In an economically intuitive way, the practitioners and portfolio managers conduct performance attribution and mean-variance-optimization based on asset's exposures to common risk factors. The most general form of factor model takes the form:\n$r_t = \u03b1_t + \u03b2_t * factor_t + \u03f5_t$\nwhere, $r_t$ is (n x 1) cross sectional asset excess returns vector at time t, $\u03b1_t$ is the (n x 1) intercept term, often interpreted as asset's abnormal returns. $\u03b2$ is the factor exposure matrix, where each row contains the asset's exposures to risk factors. $factor_t$ is the (kxn) risk factor returns. $\u03f5_t$ is the (n x 1) idiosyncratic return vector, representing asset-specific risk that is not captured by the market wide risk factors.\n\nPast trends in academic literature have been focusing on identifying economically important risk factors [1][2][3]. But Traditional models like the CAPM and the Fama-French three-factor model rely on linear relationships between cross sectional asset returns with the returns of a set of predetermined characteristic portfolios. However, there is no intuitive reason for this simplifying assumption: There is no guarantee that our set of risk factors best explains the variation in cross sectional returns. Moreover, the relationship between these risk factors and asset returns may not necessarily be linear.\n\nThis issue is partially resolved with the Statistical Factor Model, which relies on PCA to find a set of latent factors that maximize the explained variance of returns. [5]. But the PCA-based model is well-known for its lack of interpretability and inefficient information use, as it is solely based on returns series and ignores additional asset specific characteristics.\n\nIn light of this limitation, the asset pricing models proposed by KPS incorporate an additional flexibility, which assumes a factor structure of the form:\n$r_t = \u03b2(Z_{t-1}) f_t + \u03f5_t$\nwhere factors $f_t$ are now treated as latent, and factor exposures are modeled as a function of $Z_{t-1} a N * P$ characteristic matrix, where P stands for the number of asset specific characteristics.\n\nThe functional form of $\u03b2$ is a modeling choice. KPS assumes that the mapping from P characteristics to K latent factors is linear, i.e.\n$\u03b2(Z_{t-1}) = Z_{t-1}\u0393$\nFor some matrix \u0393. Although this formulation has a particularly tractable estimation strategy for both latent factors and factor exposures, the level of flexibility brought by the linear model is not always satisfying.\n\nRecent advances in deep learning have paved the way for non-linear models such as autoencoders, which have shown promise in capturing intricate relationships in financial data by removing noise, or modeling functions such that features can be linearly represented in factor models. [6] assumes a more general form of beta functions, and proposes to use neural networks to approximate it.\n\nThis paper builds on this foundation by introducing [7] Kolmogorov-Arnold Networks (KANs) for asset pricing models. KANs are particularly adept at representing nonlinear functions due to their ability to decompose complex functions into simpler ones and then combine these components to approximate the original function through use of learnable activation functions .\n\nTraditional activation functions such as ReLU, GeLU, Sigmoid, Tanh, Maxout, although works well for some problems, can fail to approximate certain functions. For example, because ReLU activation functions introduce piecewise linearity to the model, it leads to inefficiency in approximating smooth functions like sine and cosine. Although switching the type of activation functions may sidestep this problem, for most applications, the optimal choice of activation functions is not immediately clear and can be difficult to decide.\n\nIn this study, we propose an implementation of a latent factor conditional asset pricing model using KANs within an autoencoder architecture. Unlike traditional methods that rely on Multilayer Perceptrons (MLPs) with ReLU activations, our approach harnesses the power of KANs to enhance both the accuracy and interpretability of latent factor exposures. By embedding KANs into the beta network of an autoencoder, we aim to provide a more robust noiseless framework for modeling complex relationships in financial data.\n\nIntegrating KANs into the beta network of an autoencoder for latent factor modeling and demonstrating superior predictive performance and interpretability through extensive empirical analysis.\n\nThe remainder of this paper is organized as follows: Section 2 reviews relevant literature on factor models and deep learning in finance. Section 3 details our methodology, focusing on the integration of KANs into the autoencoder framework. Section 4 presents empirical results, followed by a discussion in Section 5. Finally, Section 6 concludes with implications for future research and applications."}, {"title": "2 LITERATURE REVIEW", "content": "2.1 Kolmogorov-Arnold Networks\n\nKolmogorov-Arnold Networks represent a paradigm shift in neural network architecture, inspired by the Kolmogorov-Arnold representation theorem [8]. This theorem posits that any multivariate continuous function can be decomposed into a finite composition of continuous functions of a single variable, combined with addition operations [2]. KANs diverge from traditional neural networks by embedding learnable activation functions directly on the edges connecting nodes. Parameterized spline functions replace the typical weight matrices found in Multilayer Perceptrons (MLPs), enabling flexible and adaptive nonlinear transformations of input data. This design enhances the model's expressiveness and interpretability while maintaining efficiency [8].\n\nThe efficiency of KANs lies in their ability to represent complex functions using fewer parameters compared to traditional MLPs, crucial for applications involving high-dimensional data such as finance [10]. KANs mitigate the curse of dimensionality often encountered with spline-based models by leveraging the compositional nature of the Kolmogorov-Arnold theorem. The KAN architecture introduces the concept of a \"KAN layer,\" allowing for deeper representations beyond the original two-layer formulation [8]. This ability to handle high-dimensional data efficiently while providing interpretable results makes KANs particularly promising for financial applications where transparency is crucial.\n\n2.2 Autoencoders for Factor Models\n\nAutoencoder models have advanced financial econometrics by improving factor models through noise removal. Recent innovations include the integration of variational autoencoders (VAEs) with dynamic factor models [11], the development of conditional autoencoder (CA) asset pricing models for specific markets [12], and the application of asymmetric autoencoders for covariance matrix estimation [13]. Deep learning methodologies have led to models integrating Beta and Factor networks, surpassing traditional linear frameworks in capturing the complexities of asset returns [14].\n\nThe application of KANs in autoencoder models is an attempt to create factor models that are both highly expressive and interpretable, addressing a key challenge in applying AI to finance. Future research may explore the applicability of these models to a wider range of financial instruments and market conditions, their performance in real-time decision-making scenarios, and methods to ensure their robustness in volatile markets. Addressing interpretability, regulatory compliance, and ethical considerations will be crucial for their widespread adoption in the financial industry."}, {"title": "3 METHODOLOGY", "content": "3.1 Dataset Description\n\nWe utilize the same data as [6] (GU 2020). We analyze the same dataset studied in Gu et al. (2019), which contains monthly individual stock returns from the Center for Research in Securities Prices (CRSP) for all firms listed in the three major exchanges: NYSE, AMEX, and NASDAQ. We use the Treasury bill rate to proxy for the risk-free rate from which we calculate individual excess returns. Our sample begins in March 1957 (the start date of the S&P 500) and ends in December 2016, totaling 60 years.\n\nThe dataset is prepared with a lag. We assume that the monthly stock characteristics are delayed for a month, quarterly stock characteristics are delayed for 4 months, and annual characteristics are delayed for a year. This practice avoids look-ahead bias in our simulation.\n\nNo filters are imposed on the stocks that are included in our simulation. The total number of stocks in our sample is nearly 30,000, with the average number of stocks per month exceeding 6,200.\n\n3.2 Model Design\n\nWe deploy a similar model architecture as Gu et al. At the highest level, we assumes factor structure of the form:\n$r_t = \u03b2(Z_{t-1}) f_t + \u03f5_t$\nwhere the factor exposure $\u03b2$ is a general function of asset specific covariates, and $f_t$ is factor return at time t.\n\nOur main difference from Gu et al is the choice of function approximator for $\u03b2$. Instead of a MLP, we use a KAN network to model the factor exposure. The core operational principle of KANs in our model involves embedding spline functions within the network's architecture. For each edge connecting nodes in the Beta network, a spline function is parameterized to adaptively transform the input data. This operation is mathematically represented as:\n$y_i = \\sum_{j=1}^n \u03c9_{ij} * Spline(x_j)$\nWritten down in matrix notation, this amounts to the following:\n$\u03a6_{i,t-1}(Z_{i,t-1}) := KAN(Z_{i,t-1}) = (\u03a6_L \u00b0 ... \u00b0 \u03a6_1 \u00b0 \u03a6_0) Z_{i, t-1}$\nWhere $\u03a6_i$ is the ith layer of KAN network, defined as a shape $n_{in} X n_{out}$ matrix of 1d spline function $\u03a6_{i,j}$; each with trainable parameters. In practice, it is empirically discovered that the KAN network works best in latent space, so we add embedding layers for both inputs and outputs in the form:\n$\u03b2(Z_{i,t-1}) = \u0393_{out} (\u03a6_{L-1} \u00b0 ... \u00b0 \u03a6_1 \u00b0 \u03a6_0 \u0393_{in}) Z_{i, t-1}$\nwhere $\u0393_{in}$ is the linear embedding layer, and $\u0393_{out}$ is the output linear layer that maps vectors from embedding space to returns space.\n\nFollowing the methodology of Gu et al., we use a standard autoencoder for the factor specification. The mathematical formulation of the factor returns is specified as the following:\n$f_t = wor_t$\nwhich is essentially a one layer neural network without bias term and activation function. The choice of this architecture is based on the economic interpretation of the factor returns: they are themselves the return of a certain characteristic portfolio (and therefore their returns are linear combinations of the returns of the underlying assets)\n\nIn practice, the number of assets (N) could be astronomical, which would significantly increase the size and computational complexity of the factor network, therefore we employ a dimension reduction before feeding it to the neural network:\n$x_t = (Z^T_{t-1} Z_{t-1})^{-1} Z^T_{t-1} r_t$\nthe $x_t$ is the solution to the linear regression equation:\n$r_t = Z_{t-1}x_t + \u03f5_t$. It can be interpreted as the observable characteristic factors return, where the factor exposures are exactly $Z_{t-1}$ This architectural choice greatly reduced the size of the factor network, and connected the factor returns to characteristics based portfolios.\n\nIt is quite common that we would end up with a characteristic matrix that is rank deficient, especially if the characteristics include \"country\" or \"industry\" loadings. To sidestep this issue, we used a linear regression with L2 regularization (Ridge regression):\n$X_t = (Z^T_{t-1} Z_{t-1} + \u03bbI)^{-1} Z^T_{t-1} r_t$\nwhere $\u03bb$ is the regularization strength. The particular choice of $\u03bb$ is decided using the validation period. In principle the observable factor estimates obtained this way are no longer unbiased. However, we believe that this issue is trivial because the flexibility of the neural network can easily accommodate this.\n\nCombining the two networks, the end product of our model is of the form:\n$r_t^0 = KAN(Z_t) Wx_t$\n\nThe mean squared loss is computed using the predicted and actual returns, and then is used to jointly train our 2 networks."}, {"title": "4 Experiment", "content": "4.1 Experimental Setup\n\nWe have the first 30 years of data as training period (1957 - 1987), next 12 years as validation period (1987 - 1999), and all the remaining years as test period (2000 - 2016). The neural network is trained with the first 12 years of training data, and then recursively refitted with the rest of the training data, each time we extend the training sample by one year. In each refitting, the hyperparameters are tuned using the validation period, therefore it indirectly serves as input to our model. We roll it forward by one year in each refitting to maintain the same size (12 years) for the validation period.\n\n4.2 Performance Metrics\n\nThe evaluation framework hinges on a robust selection of performance metrics tailored to assess the model's effectiveness in financial forecasting and risk management.\n\nFollowing the benchmark set by KPS, we use total R2 and predictive R2 to evaluate model performance. In addition, we evaluate its performance in economic terms by calculating the sharpe ratio of long-short portfolios formed using the predictions made by the models.\n\nTotal R2: This metric serves as a benchmark for evaluating the goodness-of-fit of the model to the observed data. Total R2 quantifies the explanatory power of current factor realization, and therefore can be used to assess how accurate the model is to assess an asset's aggregate riskiness.\n\nPredictive R2: This metric serves as a complement to the total R2, in that it assesses the accuracy of the prediction of the cross-sectional asset excess returns made by the model. It quantifies the model's ability to explain variation in risk compensation.\n\nSharpe Ratio: As a measure of risk-adjusted return, the Sharpe ratio evaluates the excess return generated per unit of risk taken by the investment strategy. The shape ratio of the long-short portfolio formed using the model's predictions quantifies the economic utility that the model has in actual applications."}, {"title": "5 Results and Discussion", "content": "The empirical findings demonstrate the KAN-based autoencoder's superior performance in financial forecasting tasks compared to traditional and previous autoencoder models. As shown in Table 1, the KAN-CA (KAN based Conditional Autoencoder) model achieves improved R\u00b2 scores of 11.02%, 11.26%, and 11.32% for 1-, 3-, and 6-factor models respectively, indicating a more precise fit to the underlying data compared to Fama-French (FF) and conditional autoencoder (CA) models. Notably, the KAN-CA model's performance remains consistent across different numbers of factors, suggesting its robustness in handling varying levels of complexity in financial data. The FF model's negative R\u00b2 scores across all factor models highlight the significant improvement offered by both CA and KAN-CA approaches in capturing the underlying patterns in financial markets. The model's enhanced predictive power is further evident in Table 2, where the KAN-CA model exhibits superior predictive R\u00b2 scores of 0.203%, 0.203%, and 0.214% for 1-, 3-, and 6-factor models, outperforming both FF and CA models across all factor scenarios. This consistent outperformance in out-of-sample predictions underscores the KAN-CA model's ability to generalize well to unseen data, a crucial attribute for practical applications in financial forecasting. Interestingly, while the CA model shows a slight decline in performance as the number of factors increases (from 0.202% to 0.168% to 0.188%), the KAN-CA model demonstrates improved performance, particularly in the 6-factor model, suggesting its capability to effectively leverage additional factors for enhanced predictive accuracy.\n\nFurthermore, Table 3 illustrates the model's improved risk-adjusted returns, with the KAN-CA model consistently delivering higher Sharpe ratios (0.86, 0.86, and 0.96 for 1-, 3-, and 6-factor models) compared to the CA model (0.84, 0.87, and 0.91 respectively). This improvement in Sharpe ratios indicates that the KAN-CA model not only enhances returns but does so with a more favorable risk-return tradeoff, a key consideration for practical portfolio management. The notable increase in the Sharpe ratio for the 6-factor KAN-CA model (0.96) compared to its CA counterpart (0.91) further emphasizes the model's ability to effectively utilize multiple factors for improved risk-adjusted performance. The training performance of the KAN model is visualized in Figures 2, 3, and 4, which depict the training versus validation loss for the 1-factor, 3-factor, and 6-factor models respectively. These graphs demonstrate the model's learning progression and its ability to generalize to unseen data. In all three figures, we observe a consistent decrease in both training and validation loss over the epochs, indicating effective learning without overfitting. The close alignment between training and validation curves suggests good generalization capabilities, which is crucial for reliable financial forecasting.\n\nWhen compared to the MLP model results shown in Figures 1, 2, and 3, the KAN-based model exhibits improved learning stability and generalization capabilities. The MLP models, while showing decreasing loss trends, display more volatility in their validation curves, particularly in the 3-factor and 6-factor models (Figures 2 and 3). This contrast highlights the KAN model's superior ability to maintain stable performance across increasing model complexity. The smoother convergence of the KAN model, especially in the later epochs, suggests its potential for more reliable and consistent predictions in real-world financial applications. Overall, the KAN-based model's ability to capture complex, non-linear relationships within financial data is evidenced by its significant improvements in prediction accuracy across different factor models. This capability is crucial for navigating dynamic market conditions and identifying nuanced patterns that drive investment performance. The model's consistent outperformance in R\u00b2 scores, predictive accuracy, and risk-adjusted returns, coupled with its stable learning behavior across various factor models, positions it as a promising advancement in financial modeling. These results suggest that the KAN-based approach not only enhances the accuracy of financial forecasts but also provides a more robust and reliable framework for decision-making in complex financial markets."}, {"title": "6 Conclusion", "content": "This research introduces a KAN-based autoencoder latent factor model that improves upon traditional asset pricing models by capturing non-linear relationships. The empirical analysis demonstrates the model's superior predictive power and economic interpretability.\n\nThe findings have significant implications for financial economics, providing a more accurate and interpretable model for asset pricing. This approach can be extended to other financial applications, such as risk management and portfolio optimization.\n\nThe study is limited by the advancement of KAN model architecture. Unlike MLP, whose training behavior, regularization technique, choice of layers / activation functions are thoroughly studied over the past decades, KAN is still a relatively novel invention whose capacity remains largely unexplored. There may exist better architecture for KAN networks to approximate the beta function. We leave this engineering problem for future research.\n\nAlso, one of the key advantages of KAN over MLP is its interpretability. Through the exploration of spline function in each KAN layer, we can visualize how each covariates of assets interact with their betas to each latent factor. This visualization may provide more information of how the covariates affect the risk aggregation of assets, and may further simplify the model.\n\nFuture research could explore extending the model to other asset classes and incorporating additional covariates. Additionally, further advancements in KANs and other deep learning techniques could provide even greater improvements in model performance."}]}