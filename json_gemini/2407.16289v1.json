{"title": "Federated Learning for Face Recognition via Intra-subject Self-supervised Learning", "authors": ["Hansol Kim", "Hoyeol Choi", "Youngjun Kwak"], "abstract": "Federated Learning (FL) for face recognition aggregates locally optimized models from individual clients to construct a generalized face recognition model. However, previous studies present two major challenges: insufficient incorporation of self-supervised learning and the necessity for clients to accommodate multiple subjects. To tackle these limitations, we propose FedFS (Federated Learning for personalized Face recognition via intra-subject Self-supervised learning framework), a novel federated learning architecture tailored to train personalized face recognition models without imposing subjects. Our proposed FedFS comprises two crucial components that leverage aggregated features of the local and global models to cooperate with representations of an off-the-shelf model. These components are (1) adaptive soft label construction, utilizing dot product operations to reformat labels within intra-instances, and (2) intra-subject self-supervised learning, employing cosine similarity operations to strengthen robust intra-subject representations. Additionally, we introduce a regularization loss to prevent overfitting and ensure the stability of the optimized model. To assess the effectiveness of FedFS, we conduct comprehensive experiments on the DigiFace-1M and VGGFace datasets, demonstrating superior performance compared to previous methods.", "sections": [{"title": "Introduction", "content": "Recent years have witnessed a burgeoning interest in safeguarding personal data, a concern further emphasized by Article 25 of the GDPR [26], which mandates heightened data protection measures throughout system development and prohibits the unauthorized collection of personal information. Consequently, safeguarding personal information during the training of deep-learning networks has emerged as a paramount concern.\nFace recognition has garnered considerable attention due to its efficacy in identifying individuals. This method finds widespread application in user authentication and has even found integration into smartphones to safeguard personal information or financial transactions. However, a significant portion of face recognition models [14, 15, 19] are typically hosted on servers, necessitating the transmission of facial images from smartphones for authentication, which raises privacy concerns. To address this issue, the adoption of lightweight models directly on smartphones has been proposed. Nonetheless, limitations persist in training these models solely using public data. Consequently, there is a growing interest in training models to utilize users' facial data on their own devices while ensuring data privacy, with many studies leveraging federated learning methods garnering attention in this regard.\nFederated learning is a method in which multiple clients join together to train a model with good performance while protecting personal information. FedFace [1] introduced a spread-out regularizer aimed at training a face recognition model within a federated learning framework. However, the process of dispersing the identity proxies received from clients in FedFace raises concerns regarding potential privacy violations. FedFR [20] prevented bias by training personalized models using public data, demonstrating promising performance among federated learning-based face recognition models. However, this approach necessitates clients to continuously receive public data, posing significant resource constraints, especially in on-device environments like mobile platforms where computational resources are severely limited. Additionally, FedFR proposed a new evaluation metric for personalizing performance, but this metric is far from real-world situations because the number of clients is too small and one client holds multiple identities.\nTo address these challenges, we propose FedFS, which trains generalized facial features and personalized face recognition model without leaking personal data outside each user's device in a federated learning environment. FedFS has three models: a pre-trained model trained with public data, a personalized model, and a global model, as well as two components: adaptive soft label construction utilizing dot product and intra-subject self-supervised learning employing cosine similarity, to reduce computational complexity and intra-class variation. Additionally, we introduce regularization loss to prevent bias in personalized models in heterogeneous data situations. We assume an actual authentication environment in which tens of thousands of clients participate in federated learning and evaluate personalizing performance using DigiFace-1M [3] and VGGface [6] benchmark data. Our main contributions are summarized as follows:\n\u2022 We propose FedFS, Federated Learning for personalized Face recognition via intra-subject Self-supervised learning framework. FedFS trains optimized facial features for each client and reduces intra-class variation by leveraging adaptive soft label construction utilizing dot product and intra-subject self-supervised learning employing cosine similarity while protecting users' data privacy.\n\u2022 Regularization loss is proposed to prevent bias in the performance of personalized models. Through this, FedFS solves the problem of easily falling into overfitting when training only with personal data, and trains indirectly generalized facial features.\n\u2022 Experiment results utilizing face recognition benchmarks like DigiFace-1M and VG-GFace demonstrate that our proposed method outperforms previous approaches. Furthermore, we conducted training and evaluation with the assumption of 10,000 clients participating, each with only one identity, mirroring real-world conditions. This assumption is the first attempt in federated learning-based face recognition research."}, {"title": "Related Works", "content": "Face Recognition. Face recognition has seen a remarkable enhancement in performance through the utilization of large-scale data, identities, and models, sparking considerable interest [4, 17, 28]. However, state-of-the-art models require a lot of resources, so the execution environment is often limited to servers with no resource limitations. In this case, personal information is violated because the actual authentication process requires facial data to be transmitted from the client to the server. In contrast to large-scale models, there is a growing body of research focusing on lightweight models [2, 5]. MobileFaceNet [7] exemplifies one such lightweight face recognition model, boasting speeds that are more than twice as fast as MobileNetV2 [23]. However, enhancing the performance of pre-trained models like these, which utilize public data, proves challenging due to constraints imposed by model size and the inability to conduct additional training using user data. FedFS aims to address this limitation by enhancing recognition performance through personalized facial feature training while safeguarding personal information.\nFederated Learning. Federated learning is attracting attention as a way to protect personal information. FedAvg [22] is a method of creating a global model by calculating the average of the parameters of a local model trained using data from each client. Recently, research on personalized federated learning, which improves personalized performance by utilizing models customized to suit individual goals, is increasing. However, most research has only been conducted on small-scale datasets such as MNIST [18] and CIFAR-10 [16]. \u03a4\u03bf solve these problems, research on face recognition has been conducted in federated learning environments such as FedFace [1] and FedFR [20]. FedFR simultaneously trained for generalizing performance and personalizing performance using public data. In contrast, we do not use public data directly, because utilizing the data requires the client's resources, which can be very taxing on the client's devices."}, {"title": "Contrastive Learning", "content": "Contrastive learning researchs achieve state-of-the-art results on learning image features [8, 9, 12]. The main idea of contrastive learning is to diminish the distance between the features of the same identity of the images and increase the distance between the features of different identities of images. In the past, dot products were widely used in contrastive learning, but recently, cosine similarity has been widely used [10, 27]. This shift is attributed to the potential of dot products to yield large values based on the data, resulting in various issues such as inflated weight values [25]. However, geometrically speaking, cosine similarity solely concerns angular, rendering normalized data indistinguishable in magnitude. This means that cosine similarity is effective in maximizing inter-class variation, but shows poor performance in some cases [24]. In contrast, the dot product is influenced not only by the angle but also by the magnitude, enabling differentiation even among data involving the same identifier. From this perspective, we aim to minimize intra-class variation by using dot product and cosine similarity simultaneously.\nContrastive learning is garnering significant attention due to its outstanding performance, and numerous studies applying federated learning and contrastive learning are underway. Unlike traditional contrastive learning approaches, in federated contrastive learning, clients can only have their data, so there are no other identities. To address this challenge, a variety of federated learning-based studies [13, 20] are attracting much attention. In this paper, we focus on effectively learning individual features (positive data) without other identities (negative data) in a federated learning setup and propose regularization loss to prevent overfitting and bias."}, {"title": "Proposed Method", "content": "In this section, we propose a federated learning framework for personalized face recognition with intra-subject self-supervised learning and this flow is summarized in Algorithm 1. We will first describe the training environment and then explain in detail the training process proposed in this environment. Additionally, we demonstrate the convergence analysis for our proposed method in Appendix A."}, {"title": "Problem Formulation", "content": "We define the total number of participating clients in federated learning as C, and the specific client as $c, c \\in \\{1, ...,C\\}$. Clients combine a personalized model, a pre-trained model, and a global model to collectively train their individual facial features. The personalized model has the same architecture as the global model. Each client has a training dataset $D_{C,N} = \\{x_{c,i}, 1 < i \\le N, 1 \\le c < C\\}$, where N is the cardinality of the local data $D_{C,N}$. In a federated learning setup, the parameter server collects and aggregates the parameters of the global model from each client without sharing any private data. We adopt the commonly used FedAvg [22] as our aggregate baseline method. This step is summarized as follows:\n$w_g^{t+1} = \\frac{\\sum_{c=1}^{C} |D_{C,N}|}{\\sum_{c=1}^{C} |D_{C,N}|} w_c^t$\nwhere t means tth communication round, $t \\in \\{0, ..., T\\}$, $w_g$ is the parameters of server-global model, $w_c$ is the parameters of global model trained in personal device of client c and $|D_{C,N}|$ is the number of samples on dataset $D_{C,N}$. After updating the parameters of the server-global model, the parameters are broadcast to all clients. Through this process, we can indirectly train generalized facial features."}, {"title": "Intra-subject self-supervised learning", "content": "Intra-subject representations. In intra-subject self-supervised learning, two major operations are performed simultaneously. 1) Training local information and reducing intra-class variation with intra-subject loss. 2) Preventing overfitting and bias with regularization loss. Considering the client's restriction to utilize only local data for privacy protection, each client trains the model using only positive data, excluding negative data. Under these conditions, the client c performs operations with the global model, personalized model, and pre-trained model on input data $x_{c,i}$ and obtains the following results, respectively:\n$r_{c,i} = \\phi_c(x_{c,i}, w_c), q_{c,i} = \\phi_c(x_{c,i}, \\theta_c), v_{c,i} = \\xi (x_{c,i}, \\Psi), z_{c,i} = r_{c,i} \\cdot q_{c,i}$\nwhere $w_c$ is the global model($\\phi (w)$) parameters of client c, $\\theta_c$ is the personalized model($\\phi(\\theta)$) parameters of client c and $\\Psi$ is the pre-trained model($\\xi$) parameters. Subsequently, we obtain the intra-subject representation using the cosine similarity between the results and calculate the intra-subject loss value within the online-batch. We do not update $\\Psi$ parameters, and share $\\theta$ parameters with the server. The process is as follows:\n$cos_{c,i,j} = \\frac{z_{c,i} \\cdot v_{c,j}}{||z_{c,i}||_2 ||v_{c,j}||_2}$"}, {"title": "Adaptive soft label", "content": "To obtain an adaptive soft label, we calculate the adaptive soft score $ass$ using the dot product. Additionally, we select the K ratio of the batch size in descending order to emphasize the correlation with the specific ratio. Afterward, instead of labels, we use the adaptive soft label. This process is as follows:\n$ass_{c,i,j} = z_{c,i} \\cdot v_{c,j}, ASS_{c,i,j} \\in \\{ass_{c,1,j},..., ass_{c,i,j} \\}$\n$\\beta_{c,i,j} = \\begin{cases} ass_{c,i,j} * \\gamma, & \\text{if } y_{c,j} = 1 \\\\ ass_{c,i,j}, & \\text{else if } * \\\\ 0, & \\text{otherwise} \\end{cases}$\n$\\alpha_{c,i,j} = (\\frac{exp(\\beta_{c,i,j})}{\\sum_{i=1}^{N} exp(\\beta_{c,i,j})})^{\\gamma}$\nwhere * means $y_{c,j} = 0$ and $ass_{c,i,j}$ is Top K in $ASS_{c,i,j}$. $ASS_{c,i,j}$ is adaptive soft score set of client c. The $\\gamma$ is a positive number, and the K value is a value between 0 and 1. The $\\gamma$ is a probability enhancement value for itself. As the value increases, the model focuses more on training the similarity to itself, and as it becomes smaller, the model trains by focusing on the similarity to surrounding vectors. In this paper, the K value is set to 4 and $\\gamma$ is set to 2. Finally, the local facial features are trained by performing a cross-entropy operation using the adaptive soft label $\\alpha$ instead of the previously used label value $y_{c,j}$. The process can be summarized as follows:\n$F_{insub} (\\Psi, w_c, \\theta_c) = - \\sum_{j=1}^{N} \\alpha_{c,i,j} log \\frac{exp(cos_{c,i,j})}{\\sum_{j=1}^{N} exp(cos_{c,i,j})}$"}, {"title": "Regularization loss", "content": "Training only on local data without including negative data can easily lead to overfitting and biased results. To solve this problem, we perform regularizing between the global model that trains generalized facial features through sharing the parameters with the server and the personalized model, as follows:\n$F_{reg} (w_c, \\theta_c) = 1 - \\frac{r_{c,i}^{'} \\cdot q_{c,i}^{'}}{||r_{c,i}^{'}||_2 ||q_{c,i}^{'}||_2}$\nwhere $r_{c,i}^{'}$ and $q_{c,i}^{'}$ are the output vectors that do not pass through the last linear layer of the global model and personalized model, respectively. Finally, the intra-subject self-supervised learning process is summarized as follows.\n$F_{total} (\\Psi, w_c, \\theta_c) = \\lambda * F_{insub} (\\Psi, w_c, \\theta_c) + (1 - \\lambda) * F_{reg} (w_c, \\theta_c)$\nwhere $\\lambda$ is an objective weight value between 0 and 1. In this paper, $\\lambda$ is set to 0.7."}, {"title": "Experiments", "content": "In this section, we demonstrate the performance of our proposed method through experiments. To evaluate the performance of each client's personalized face recognition model, we use an evaluation technique that arranges the evaluation data in a 1:N structure conducted in FedFR [20]. In addition, we check whether our proposed method reduces intra-class variation and ablation study in Appendix B."}, {"title": "Experiment Setting", "content": "We use MS-Celeb-1M [11] to train pre-trained models and share the data publicly in FedFR [20]. And we set MobileFaceNet [7], PocketNet [5], GhostFaceNet [2] and MobileNetV2 [23] as pre-trained models. DigiFace-1M [3] and VGGFace [6] are benchmark datasets for training and evaluation of personalized face recognition models. We use 80% of the images in total for local client training and the remaining 20% of the images for evaluation. Specifically, in each local client, the number of training data and evaluation data are 57/13 for DigiFace-1M and 100/13 for VGGFace, respectively. Also, DigiFace-1M and VGGFace have 10,000 and 8,673 identities, respectively, and each client has only one identity.\nIn this experiment, we employ 64-layer CNN architecture [21] as a global model and personalized model in the same way as FedFR. We add a linear layer to the last layer for intra-subject self-supervised learning. We use the SGD optimizer with a learning rate of 5e-3. Each client trains 2 local epochs and 5 communication rounds, and clients participating in training are selected randomly."}, {"title": "Experiment Results", "content": "We conduct experiments to analyze how much performance is improved compared to the pre-trained model using FedFace [1], FedFR [20], and our proposed method, FedFS. We use four pre-trained models: MobileFaceNet [7], PocketNet [5], GhostFaceNet [2], and MobileNetV2 [23]. The participation rate of all federated learning algorithms is 0.7, and we calculate AUROC and the percentage improvement based on the pre-trained model. These results are summarized in Table 1, and the ROC Curve graph under the same conditions is shown in Figure 3.\nAs a result of Table 1 and Fugure 3, we can see that most models show good performance compared to the pre-trained model, but FedFS has the best performance. Because pre-trained models are trained based on large amounts of public data, they are difficult to retrain, and collecting the user data causes privacy issues. Additionally, in the case of the FedFace and FedFR, the performance improvement is not high because they assume a small number of clients and a 1.0 participation rate rather than a large number of clients. On the other hand, our proposed FedFS effectively trains facial features and reduces intra-class variation through intra-subject self-supervised learning using only local data without violating personal information, and shows that significantly improves personalized face recognition performance."}, {"title": "Performance with various participation rates", "content": "Additionally, we compare the performance of the federated learning method using true positive identification rates (TPIR) at different false positive identification rates (FPIR) for 1:N identification protocol [20]. Specifically, we calculate the average TPIR of all clients based on FPIR 0.1, 0.01, and 0.001. The pre-trained model is MobileFaceNet [7], and we set various participation rates: 0.01, 0.1, 0.3, 0.5, and 0.7. According to the experimental results Table 2, the performance of the proposed FedFS shows the best performance in all fields. Through this, FedFS, training using the intra-subject self-supervised learning method, is less affected by the participation rates compared to the previously federated learning methods FedFace [1] and FedFR [20]."}, {"title": "Conclusion", "content": "We proposed FedFS, a federated learning framework to train optimized facial features for each client by using intra-subject self-supervised learning while protecting personal information. Through intra-subject self-supervised learning, we could effectively learn a user's facial features and reduce intra-class variation by simultaneously leveraging dot product and cosine similarities among personal data, resulting in improved recognition performance compared to previous federated learning methods. We believe that FedFS could be applied to various federated face recognition tasks."}, {"title": "Appendix", "content": "In this section, we analyze the convergence of FedFS. To do the analysis, we first need to make some preliminary definitions. The point where the local model is trained is designated as e. (For example, $w^{e+1}$ means the model parameter that has completed the e + 1th training.) We denote the loss function of FedFS as F. We do not display $\\Psi$ separately, because the parameter is not updated.\nAssumption 1. Lipschitz Smoothness.\nIf the gradient of the local model of any client c is L-Lipschitz smooth, the following formula holds.\n$||\\nabla_w F(w^1, \\theta^1) - \\nabla_w F(w^1, \\theta^2)||_2 <= L||\\theta^1 - \\theta^2||_2$\n$||\\nabla_{\\theta} F(w^1, \\theta) - \\nabla_{\\theta} F(w^2, \\theta)||_2 <= L||w^1 - w^2||_2$\nAssumption 2. Unbiased Gradient and Bounded Variance\nThe w and $\\theta$ parameters each use SGD as an optimization function, so they each have unbiased and bounded variance. The parameter update process using SGD is as follows:\n$w^{e+1} = w^e - \\eta \\nabla_w F(w^e, \\Theta^e)$\n$\\theta^{e+1} = \\theta^e - \\eta \\nabla_{\\theta} F(w^e, \\theta^e)$\nAssuming that the amount of change in the parameter is within a certain range, the conditions are as follows:\n$||w^e - w^*||_2 <= \\epsilon_w$\n$||\\theta^e - \\theta^*||_2 <= \\epsilon_{\\theta}$\nwhere $\\epsilon_w$ and $\\epsilon_{\\theta}$ are positive value. With this assumption, updates to each parameter occur randomly within a certain range.\nTheorem 1. Convergence analysis\nBased on Assumption 1 and Assumption 2, a convergence analysis of FedFS can be performed as follows:\n$||w^{e+1} - w^*||_2 <= \\epsilon_w - \\eta L \\epsilon_{\\theta}$\n$|| \\Theta^{e+1} - \\theta^*||_2 <= \\epsilon_{\\theta} - \\eta L \\epsilon_w$\nBased on the above analysis, we confirm that the parameters of FedFS converge within the real number range."}, {"title": "Ablation Studies", "content": "Intra-subject self-supervised learning learning defined in the Equation 9, improves performance of personalized face recognition compared to previous approaches. We go further and check whether the proposed method reduces intra-class variation and analyze how the method affects performance. We set the participation rate at 0.7, and use PocketNet [5] as the pre-trained model. As shown in Figure B.1 and Table B.1, we can see that the intra-subject self-supervised learning method considering correlation shows superior performance"}]}