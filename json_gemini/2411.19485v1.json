{"title": "Action Engine: An LLM-based Framework for Automatic FaaS Workflow Generation", "authors": ["Akiharu Esashi", "Pawissanutt Lertpongrujikorn", "Mohsen Amini Salehi"], "abstract": "Function as a Service (FaaS) is poised to become the foundation of the next generation of cloud systems due to its inherent advantages in scalability, cost-efficiency, and ease of use. However, challenges such as the need for specialized knowledge and difficulties in building function workflows persist for cloud-native application developers. To overcome these challenges and mitigate the burden of developing FaaS-based applications, in this paper, we propose a mechanism called Action Engine, that makes use of Tool-Augmented Large Language Models (LLMs) at its kernel to interpret human language queries and automates FaaS workflow generation, thereby, reducing the need for specialized expertise and manual design. Action Engine includes modules to identify relevant functions from the FaaS repository and seamlessly manage the data dependency between them, ensuring that the developer's query is processed and resolved. Beyond that, Action Engine can execute the generated workflow by feeding the user-provided parameters. Our evaluations show that Action Engine can generate workflows with up to 20% higher correctness without developer involvement. We notice that Action Engine can unlock FaaS workflow generation for non-cloud-savvy developers and expedite the development cycles of cloud-native applications.", "sections": [{"title": "I. INTRODUCTION", "content": "FaaS is a cloud computing paradigm that allows developers to execute code in response to events without managing the underlying infrastructure, providing scalability and cost efficiency [2]. This model abstracts away the complexities of infrastructure management, thereby enabling developers to concentrate on writing and deploying code triggered by spe- cific events. As a result, FaaS enhances operational efficiency and accelerates cloud-native software development cycles. A key component of FaaS is its workflow orchestration, which enables the developer to orchestrate multiple functions to serve complex tasks by using high-level API. In cloud-native software development and Robotic Process Automation (RPA) [6], FaaS workflows are essential to automate repetitive or complex tasks, hence improving efficiency and accuracy.\nFaaS is expected to be the foundation of the next generation of cloud systems [1] that mitigates the burden of cloud- native application development and enables developers to focus solely on the application and business logic rather than dealing with the resource allocation complexities. Major cloud providers have already adopted the FaaS paradigm, e.g., AWS Lambda, Google Cloud Functions, and Azure Functions. These hyper-scalers also provide various tools for workflow creation and orchestration, e.g., AWS Step Functions, Google Cloud Composer, and Azure Durable Functions."}, {"title": "B. Limitations of FaaS Workflow Tools", "content": "Despite the advancements in FaaS platforms, developers still face several challenges that make developing FaaS workflows knowledge-demanding and time-consuming. We summarize these limitations as follows:\n1) Specialized Knowledge Requirement: Designing and implementing FaaS workflows requires expertise in each platform-specific language and configuration. For in- stance, AWS Step Functions demand familiarity with Amazon States Language (ASL), and Google Cloud Composer necessitates knowledge of Python and Airflow. These steep learning curves are significant barriers for new developers in serverless cloud computing.\n2) Scalability Challenge: Effective scaling of FaaS work- flows demands a comprehensive understanding of ex- isting functions to avoid redundancy and system flaws. As the function repository of an organization grows, the number of functions within it increases, leading to greater complexity that developers must learn to manage. New developers, in particular, must comprehend these intricacies to modify or create new workflows effectively. This complexity hinders the seamless adoption and exten- sion of workflows, impacting the system's flexibility and responsiveness as it grows.\n3) Increasing Development Time: Current FaaS workflow development relies heavily on manual coding, which is inefficient for large FaaS repositories. This reliance significantly increases the development time, making it challenging to adapt and respond quickly to new or changed requirements."}, {"title": "C. FaaS Workflow Generation via LLM", "content": "To address these challenges, we propose leveraging Tool- Augmented Large Language Models (LLMs) [11] to enhance FaaS workflow generation. Tool-augmented LLMs can inter- pret human language and interact with various tools, such as APIs, to automatically create and modify workflows. This approach reduces the need for specialized knowledge and manual workflow design, enabling dynamic and scalable FaaS workflow generation.\nExisting studies on Tool-Augmented LLMs primarily focus on parameter extraction from user queries and the execution of workflows, often overlooking critical aspects such as data flow (aka data dependency management). In the context of FaaS, data flow refers to the seamless transmission and transfor- mation of data between various functions within a workflow."}, {"title": "III. DESIGN AND ARCHITECTURE OF ACTION ENGINE", "content": "This section describes the design of the Action Engine. To address the challenge of language and platform depen- dency in automatic workflow generation, our methodology integrates the Directed Acyclic Graph (DAG) concept with the standard Tool-Augmented LLMs procedure. We begin by defining nodes, where each node represents a sub-task derived from the user query, and identifying suitable APIs for this sub-task. The edges between nodes are managed through a data dependency approach to ensure correct data flow. Finally, we use a platform-specific configuration compiler to adapt the generated DAG into a functional workflow. This method ensures not only the automated generation of workflows for FaaS but also maintains language and platform agnosticism, avoiding common pitfalls associated with language-specific or platform-dependent workflows.\nThe overall architecture of Action Engine is shown in Figure 2. Action Engine consists of the following modules:\n1) Text-to-Workflow: Transforming the user's query into an executable workflow configuration.\n2) Workflow Execution: Executing the workflow that gen- erated by text-to-workflow module. Each workflow has its own API endpoint for the user to call."}, {"title": "A. Text-to-Workflow", "content": "This section explains the design and technique for generat- ing the workflow from the user query in the Text-to-Workflow module. We design this module to have five components:\n\nLLM Engine: The LLM Engine processes internal prompts generated by the Func Selector and Workflow Generator. The architecture is designed to support comparable LLMs. We employ in-context learning [3] over fine-tuning due to the dynamic nature of FaaS, where workflows are often variable and tasks are highly diverse. Fine-tuning models typically require retraining on a fixed dataset, which can be inefficient and inflexible for the continuously changing environment of FaaS.\nFunc Repo: The Function Repository (Func Repo) is the centralized information storage for all available functions used within the system. Functions' information, including input and output parameters and functional descriptions, are stored as vector embeddings to facilitate efficient retrieval and selection during workflow generation. By embedding functions in a vector database, the system enables rapid sim- ilarity searches, significantly improving the efficiency of the function identification process (see more in Section IV-B).\nFunc Identifier: The Function Identifier (Func Identifier) is responsible for finding the functions for each sub-task within the workflow. These functions will be formed as the nodes of the DAG that represent the workflow. This module operates in two key phases: Task Planning (Section IV-A). and Function Selection (Section IV-B).\nWorkflow Generator: The Workflow Generator is designed to create the data dependencies for each sub-task in the workflow, which are then used to construct the edges of the DAG. This module operates through three key processes: Topological Ordering (Section V-A), Parameter Classifi- cation(Section V-B), and Data Dependency Construction (Section V-C).\nPlatform-Specific DAG Compiler: This component takes the generated conceptual DAG from the Workflow Generator and converts it into a specific configuration for the target FaaS platform. This component achieves one of the primary objectives, which is language and platform independence from workflow generation. The conceptual DAG is stored in a language-neutral format, allowing it to be compiled into configurations compatible with different FaaS platforms by different DAG compilers. By enabling this platform- specific compilation, the system provides flexibility and broad applicability, allowing workflows to be executed across various cloud environments without requiring manual reconfiguration. This component ensures that the generated workflows are not tied to a single platform, thus supporting the accessibility of a wide range of cloud-native applica- tions."}, {"title": "B. Workflow Execution", "content": "To execute the generated workflow, we design the workflow execution module with three generic components:"}, {"title": "IV. FUNC IDENTIFIER", "content": "Task Planning involves breaking down user queries into actionable sub-tasks. This is achieved using in-context learning with carefully selected examples to ensure the appropriate granularity of task decomposition relative to the available functions in the repository. A LLM function LLM_plan that maps queries $q \\in Q$ to their corresponding sets of subtasks $S$\n$S = \\text{LLM\\_plan}(q) = \\{s_1, s_2, ..., s_n\\}$\n(1)\nThe function LLM_plan submits a query to the LLM that includes a collection of example queries and their correspond- ing decompositions to create each subtask $s_i$. Therefore, the LLM can apply the same decomposition principles to a new query to convert complex queries into manageable, executable actions, facilitating the efficient execution of tasks."}, {"title": "B. Function Selection", "content": "Following the Task Planning phase, the Function Selection is responsible for pairing each sub-task with the most relevant function from the Func Repo. Function Selection is conducted for each sub-task, where the system retrieves the top-k most relevant functions from the Func Repo based on cosine simi- larity between the sub-task and the function embeddings. This ensures that the functions selected are semantically aligned with the intended task, resulting in accurate and effective function-task pairing.\nFor each subtask $s_i$, the algorithm selects the top-k functions $F_{1..k} = \\{f_1, f_2,..., f_k\\}$ with the highest cosine similarity scores.\nSubsequently, the LLM is utilized to select the most suitable function from the top-k retrieved functions. The LLM eval- uates the semantic alignment and contextual appropriateness of each function relative to the subtask, ensuring the closest match. The final function $f^*$ chosen by the LLM is:\n$f^* = \\text{LLM\\_select}(q, s_i, F_{1..k})$\n(2)\nThe output of this process is a set of pairs representing nodes in the workflow, where each node $(s_i, f^*)$ consists of a subtask $s_i$ and its corresponding selected function $f^*$. This set of pairs $N$ is then used as the nodes to construct the workflow DAG. For simplification, we create node $n_i$ that refers to $(s_i, f^*)$, therefore, $N$ can now be defined as:\n$N = \\{n_i | n_i = (S_i, f_i)\\}$\n(3)"}, {"title": "V. WORKFLOW GENERATOR", "content": "The Workflow Generator module is designed to construct the data dependency between each sub-task of the workflow as edges to build the workflow model in DAG. Once the Function Selection creates the set of nodes $N$, the Workflow Generator performs topological ordering on the set of nodes $N$ to ensure the correct execution sequence. It then classifies each input pa- rameter of sub-tasks within the workflow to determine whether it depends on a direct user input or an output generated by a previously executed node. The classification result is used for constructing the data dependency and combining the data dependency and sub-task information into the workflow model in DAG."}, {"title": "A. Topological Ordering", "content": "Nodes in $N$ are ordered to ensure that sub-tasks are executed only after their dependencies are resolved. This ordering is achieved by passing the list of sub-tasks to a LLM, which semantically arranges the nodes. This ensures that no node $n_i$ is executed before its required preceding nodes are completed."}, {"title": "B. Parameter Classification", "content": "Each node $n_i$ has input parameters $\\{p_{i1}, p_{i2},..., p_{ik}\\}$. Pa- rameter Classification classifies each parameter $p_{ij}$ as either a direct user input or an output from a previous sub-task. Let $O$ denote the set of semantic descriptions of output parameters from the previously executed nodes. The classification of parameter $p_{ij}$ of node $n_i$ considers both $p_{ij}$ and $O$. The result is the type $t_{ij}$:\n$t_{ij} = \\text{LLM\\_classify}(p_{ij}, O)$\n(4)\n$\\begin{cases}\nInput & \\text{if from direct user inputs}\\\\\nOutput(n_k) & \\text{if from } n_k \\text{ with } k < i\n\\end{cases}$\n(5)"}, {"title": "C. Data Dependency Construction", "content": "For each parameter $p_{ij}$ classified as an output of a previous node, Action Engine create an edge $(n_{out}, n_{in})$ as a data dependency in dataflow graph $DF$:\n$DF = \\{(n_s, n_i) | t_{ij} = Input\\}\nU \\cup \\{(n_k, n_i) | t_{ij} = Output(n_k)\\}$\n(6)\nWe create the node $n_s$ to represent the starting node of this workflow to hold the direct user inputs. For the parameter $p_{ij}$ that was classified as an input, Action Engine creates the edge form $n_s$ to $n_i$. Otherwise, the system creates the edge from $n_k$ to $n_i$ where the parameter $p_{ij}$ is classified as an output of $n_k$. This process ensures the data flow reflects correct data dependencies, resulting in a valid workflow structure that is executable without errors. Finally, we create the result DAG by combining both nodes $N$ and data flow $DF$:\n$DAG = \\text{combine}(N, DF)$\n(7)"}, {"title": "VI. EVALUATION", "content": "For system testing and evaluation, we employed OpenAI's GPT-3.5 model, which was selected for its advanced natural language understanding and task decomposition capabilities. Additionally, we utilized the all-MiniLM-L6-v2 model to em- bed function representations, ensuring a high level of semantic relevance in matching functions to tasks.\nThe implementation of the Action Engine was carried out in Python. Argo Workflow [4] was used as the workflow orchestrator, and Knative [5] served as the Function as a Service (FaaS) engine. Consequently, the DAG Compiler was required to compile DAG semantics into an Argo-compatible configuration in YAML format."}, {"title": "B. Dataset", "content": "To thoroughly evaluate the performance of Action Engine, we developed a custom dataset comprising workflows of varying complexity levels. This dataset was manually con- structed to simulate a range of complex scenarios in FaaS environments, ensuring the evaluation covers different aspects of workflow generation.\nThe dataset consists of 30 workflows, each categorized into one of three complexity levels:\n\nEasy: These workflows contain 1-2 nodes, representing straightforward tasks that require minimal orchestration.\nIntermediate: This category includes workflows with 3- 5 nodes, introducing moderate complexity and requiring more intricate function selection and data dependency management.\nHard: The most complex workflows in this set consist of 6-10 nodes, demanding advanced orchestration and data flow management across multiple functions.\nGiven the small size of the dataset, we took additional steps to ensure the robustness of our evaluation. To mitigate the impact of randomness inherent in the generation process, we generated each workflow five times for every configuration of Action Engine. Consequently, for each evaluation, a total of 150 YAML files were generated, which were then compared against the ground truth to assess the accuracy of the workflow generation."}, {"title": "C. Effectiveness of Action Engine", "content": "To assess the effectiveness of our proposed system, we designed a series of experiments under different configura- tions. These experiments aimed to isolate and evaluate the contribution of each component to the system's overall per- formance in generating accurate FaaS workflows. Specifically, we examined the following configurations:\n\nSetting 1 - AE: that is a full-feature Action Engine.\nSetting 2 - AE w/o C: that is an Action Engine without the DAG compiler to remove the language-neutral feature.\nSetting 3 - AE w/o WG&C: that is an Action Engine with- out the DAG compiler and workflow generator to remove language-neutral and data dependency management features.\nTo substitute the removed components, we utilize OpenAI's GPT-40 model to generate Argo-based workflows in YAML format. The generated workflows are evaluated using three key metrics: correctness of function selection, pairwise topological ordering, and data dependency, along with an overall correct- ness metric that averages these three measures. These metrics assess the proportion of correctly predicted components rela- tive to the ground truth, providing a comprehensive evaluation of the workflow YAML generated by all three versions of Action Engine.\nBefore proceeding with the evaluation, it is essential to address the syntactic integrity of the generated workflows. Fur- ther evaluation cannot be conducted if a workflow is produced with syntactic errors. Such errors indicate a fundamental issue in generating executable workflow, rendering the workflow inoperative within a FaaS environment. Therefore, workflows with such errors are assigned an accuracy score of zero."}, {"title": "D. Results and Overall Analysis", "content": "The overall evaluation highlights the significant contribu- tions of both the DAG Compiler and Workflow Generator, improving the correctness of workflows by up to 20%. The DAG Compiler is pivotal in minimizing hallucinations in large language models (LLMs), which can lead to incorrect func- tion selection and task orchestration, especially in complex workflows. Unlike LLMs, the DAG Compiler ensures that the generated workflow YAML is structured and contextually accurate based on the given DAG. This impact is especially pronounced in intermediate and hard workflows, where pre- cise task sequencing and data dependency management are essential.\nSimilarly, the Workflow Generator plays a vital role in improving workflow correctness by enhancing the accuracy of topological ordering and data dependency management. The significant performance improvements from Setting 3 to Setting 2, where only the Workflow Generator is included, underscore its importance in generating correct workflows, particularly in intermediate and hard scenarios. The Workflow Generator effectively mitigates the adverse effects of LLM hallucinations by orchestrating tasks and dependencies with greater precision.\nNotably, while our system utilizes an inferior model (GPT- 3.5) compared to the baseline LLM (GPT-40), it achieves bet- ter accuracy in workflow generation across almost all evaluated metrics. This highlights the effectiveness of incorporating the DAG Compiler, which provides language neutrality, and the Workflow Generator, which manages data dependencies. These elements help to mitigate the limitations of the underlying model and enhance the overall performance of the system. Together, these components ensure robust workflow generation and task orchestration, enabling the system to excel in real- world scenarios with varying workflow complexities."}, {"title": "VII. LIMITATIONS OF ACTION ENGINE", "content": "While the results of this research demonstrate the effective- ness of generating FaaS workflow through the integration of the DAG Compiler and Workflow Generator, we believe that the high range of confidence intervals in our findings is due to the small dataset size and the non-determinism of LLMs. These results underscore the need for a more robust evaluation framework and larger datasets to enhance reliability. As such, our future study will aim at refining the evaluation section with an extensive dataset that can provide us with a more conclusive assessments of the system performance."}, {"title": "VIII. CONCLUSION", "content": "In this paper, we present Action Engine, a system for automatically generating FaaS workflows using LLM and ex- ecuting it. Action Engine tackles the challenges of automated data dependency management across FaaS workflows. It also employs a platform-neutral strategy in generating DAGs that can be later compiled to a specific serverless cloud format. Ad- ditionally, Action Engine includes a data dependency manage- ment module to enhance the workflow generation process. The results show that these features can improve the correctness of generated workflows by 20% compared to plainly using LLMs.\nEven though Action Engine can improve the correctness of the generated workflows, there is still a non-negligible chance of failure (i.e., incorrectness), which underscores the essence of improving its accuracy and reliability. As such, we consider the current version of Action Engine as an \"assistant\" to the cloud developers, reducing the lead time to generate FaaS workflows. However, developer intervention and verification are still required to assure workflow correctness."}]}