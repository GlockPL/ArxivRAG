{"title": "CybORG++: An Enhanced Gym for the Development\nof Autonomous Cyber Agents", "authors": ["Harry Emerson", "Liz Bates", "Chris Hicks", "Vasilios Mavroudis"], "abstract": "CybORG++ is an advanced toolkit for reinforcement learning research focused on\nnetwork defence. Building on the CAGE 2 CybORG environment, it introduces\nkey improvements, including enhanced debugging capabilities, refined agent im-\nplementation support, and a streamlined environment that enables faster training\nand easier customization. Along with addressing several software bugs from its\npredecessor, CybORG++ introduces MiniCAGE, a lightweight version of CAGE\n2, which improves performance dramatically-up to 1000\u00d7 faster execution in\nparallel iterations\u2014without sacrificing accuracy or core functionality. CybORG++\nserves as a robust platform for developing and evaluating defensive agents, making\nit a valuable resource for advancing enterprise network defence research.", "sections": [{"title": "Introduction", "content": "As cyberattacks grow more frequent and sophisticated, the need for advanced, autonomous cyberde-\nfence systems is critical. In this evolving landscape, reinforcement learning (RL) has emerged as a\npowerful tool for developing agents capable of protecting enterprise networks. Among the leading\nplatforms in this domain, the CAGE 2 CybORG simulator [11] stands out as a widely adopted\nenvironment for training and evaluating RL-based defensive agents. By simulating realistic network\nattack scenarios, CybORG has become a standard framework within the cybersecurity research\ncommunity, providing a controlled yet dynamic environment for testing defence strategies.\nHowever, as CybORG has gained traction, significant limitations have surfaced. Despite its robustness,\nthe platform suffers from persistent software bugs and inefficiencies that undermine its reliability\nas a benchmark for RL agents. These issues, including erratic agent behavior caused by flawed\ncode, often lead to inconsistent results, complicating reproducibility. Furthermore, CybORG's\narchitecture-designed with potential future emulation in mind\u2014introduces unnecessary complexity,\nslowing down agent training and making it difficult for developers to debug agent actions. These\nchallenges present barriers to progress in developing more capable autonomous defence agents.\nIn response to these issues, we introduce CybORG++, a comprehensive upgrade to the original\nCybORG platform. CybORG++ improves both the usability and reliability of the environment\nby addressing key bugs and streamlining agent interactions. It includes two major components:\n(1) a debugged version of the original CybORG CAGE 2, and (2) MiniCAGE, a lightweight re-\nimplementation that preserves the core functionality while delivering significantly faster execution.\nMiniCAGE allows researchers to conduct large-scale experiments with up to 1000\u00d7 speed improve-\nments in parallel execution, drastically reducing the time required for training and evaluation. Addi-"}, {"title": "CybORG - CAGE 2 Challenge", "content": "The Cyber Operations Research Gym, or CybORG, is an open-source AI gym environment for devel-\noping blue and red team decision-making agents for cybersecurity tasks [11, 10]. The environment\nis designed to implement a variety of different scenarios, the most notable of which are the CAGE\nchallenges [1, 10, 6, 7]. The CAGE challenges are a series of public challenges designed to foster the\ndevelopment of autonomous defensive agents.\nThe first two CAGE challenges use a version of the CybORG environment which is compatible with\ntraining single defensive agents, whilst the third and fourth challenges focus on training multi-agent\nRL agents. The CAGE 2 Challenge is one of the most widely explored challenges [9, 3, 5, 12, 4, 2]\nand focuses on developing a defensive blue agent able to defend a small enterprise network, seen in"}, {"title": "2.1 Enhancements", "content": "A variety of bugs were identified within the CAGE 2 CybORG environment, many of which affected\ncore components of the environment and liked influenced defensive agent strategy. A detailed\nbreakdown of the bugs can be found in the associated GitHub repository. The most notable are\nsummarised as follows:\n\u2022 Invalid Actions - Several actions of the blue agent do not function as intended. For instance,\nthe decoy for Vsftpd is incorrectly identified as the decoy for Apache, the fermitter decoy"}, {"title": "2.2 Extended Developer Guide", "content": "The CAGE 2 CybORG environment exhibits considerable complexity; consequently, the developer\nguide for the original implementation has been expanded to ensure that all the features of the\nenvironment remain fully transparent to reinforcement learning (RL) developers. This comprehensive\nguide includes an in-depth explanation of the state, action, and reward components, a detailed analysis\nof the pre-programmed behavior of the red agents, and an extensive reference detailing the interactions\namong various decoys, processes, and exploits across different hosts which can also be seen in the\ntables in appendix. There was not much other literature to cross reference our understanding of the\nsystem structure, though our perception of the decoy mappings and user processes and ports aligns\nwith that of [8]."}, {"title": "3 MiniCAGE", "content": "MiniCAGE is a lightweight version of CAGE 2 CybORG environment that enhances speed, trans-\nparency, and ease of use while staying true to the original challenge objectives. The package mimics\nthe basic RL components of the original environment (e.g. state-action space, reward, etc.), but\nabstracts the bulky files and complex processes, resulting in a streamlined and more accessible\nframework that retains core functionalities."}, {"title": "3.1 Optimisations", "content": "The main optimisations introduced by miniCAGE are the following:\n\u2022 Parallel execution - MiniCAGE supports parallel execution allowing agents to be trained\nand evaluated across thousands of different network configurations simultaneously on a\nsingle CPU. This modification accelerates mini-CAGE by almost 1000\u00d7 that of the original\nCybORG environment.\n\u2022 Red Agent Interface - MiniCAGE can now be used to train both red and blue agents,\nenabling the exploration of more advanced offensive strategies compared to the pre-\nprogrammed agents in the original CybORG implementation.\n\u2022 Simplified State-Action Space - Environment inputs and outputs have been vectorised\nto more easily support RL training and evaluation. The default states from the original\nCybORG implementation have been enhanced with additional metrics to track malicious\nscans and decoy placements. The agent action space has been simplified. Decoy actions\nhave been streamlined to a single action per host, automatically deploying the strongest\ndecoy by default."}, {"title": "3.2 Environment Benchmarking", "content": "To explore the speed improvement resulting from MiniCAGE, both environments were run over\na specified number of iterations with random starting initialisations and input actions. The time\nelapsed between initialisation and completion was then used as a metric of environmental execution\nspeed. The results were aggregated over 100 separate instances. MiniCAGE offers significant speed\nimprovements over the original CybORG CAGE 2 environment, as evidenced by Figure 2a. Over the\nfour iteration intervals, MiniCAGE offers speed improvements of approximately 15\u00d7, 65\u00d7, 950\u00d7\nand 800x, respectively."}, {"title": "4 Potential Future Directions", "content": "\u2022 Community Contribution - CybORG++ is the product of an interdisciplinary effort aimed\nat reigniting interest in the application of reinforcement learning to cybersecurity and network\ndefence. We actively encourage community contributions to the repository, particularly\nthose that focus on identifying bugs in the CAGE 2 CybORG environment or enhancing the\nfunctionality of MiniCAGE.\n\u2022 Extension of MiniCAGE - MiniCAGE's streamlined design makes it highly adaptable for\nmodifications and improvements. Future enhancements could include implementing custom\nnetwork scenarios within the simulator, particularly those replicating more realistic network\nconfigurations. Additionally, re-writing the environment in JAX could likely lead to further\nperformance improvements.\n\u2022 Comprehensive Benchmarking - Benchmarking within CybORG++ could be enhanced by\nestablishing a leaderboard that tracks performance across various cyber defence scenarios.\nThis could also involve storing the top-performing models, along with their code and weights,\nwithin the repository."}]}