{"title": "Who should I trust? A Visual Analytics Approach\ntfor Comparing Net Load Forecasting Models", "authors": ["Kaustav Bhattacharjee", "Soumya Kundu", "Indrasis Chakraborty", "Aritra Dasgupta"], "abstract": "Net load forecasting is crucial for energy plan-\nning and facilitating informed decision-making regarding trade\nand load distributions. However, evaluating forecasting models'\nperformance against benchmark models remains challenging,\nthereby impeding experts' trust in the model's performance. In\nthis context, there is a demand for technological interventions that\nallow scientists to compare models across various timeframes and\nsolar penetration levels. This paper introduces a visual analytics-\nbased application designed to compare the performance of deep-\nlearning-based net load forecasting models with other models\nfor probabilistic net load forecasting. This application employs\ncarefully selected visual analytic interventions, enabling users to\ndiscern differences in model performance across different solar\npenetration levels, dataset resolutions, and hours of the day over\nmultiple months. We also present observations made using our\napplication through a case study, demonstrating the effectiveness\nof visualizations in aiding scientists in making informed decisions\nand enhancing trust in net load forecasting models.", "sections": [{"title": "I. INTRODUCTION", "content": "Comparing multiple computational models for their per-\nformance is crucial for enhancing trust in model outcomes\nbecause it provides a basis for evaluating the reliability and\nconsistency of each model [2], [10], [12]. By assessing how\ndifferent models perform under various conditions and scenar-\nios, stakeholders can better understand their strengths, weak-\nnesses, and overall effectiveness. Such comparative analysis\nhelps to identify the most suitable model for specific tasks\nor applications, thereby instilling confidence in the reliability\nof the chosen model. This becomes more important while\npredicting the net load of an electric grid, which is defined as\nthe difference between total electricity demand and generation\nfrom behind-the-meter resources like solar and distributed gen-\nerators, and is influenced by various factors such as weather\nconditions and time of day [3], [15].\nAccurate net load forecasting enables grid operators, poli-\ncymakers, and energy providers to make informed decisions\nregarding energy trade, load distribution, and resource alloca-\ntion. However, the rise of solar energy generation sources in\nresidential settings has significantly impacted the performance\nof traditional net load forecasting models, highlighting the\nneed for robust time-series forecasting techniques [6]. Collab-\norating with scientists, we developed a deep-learning model\nthat integrates variables such as temperature, humidity, appar-\nent power, and solar irradiance to achieve strong predictive\nperformance and resilience in the face of missing data [14].\nHowever, the model's sensitivity to seasonal variations and\nnoisy inputs underscores the need for further exploration with\ndomain experts. Hence, we developed an interactive tool that\nempowers users to investigate the model's performance across\ndiverse time periods and input scenarios [1].\nHowever, while we initially recognized the importance of\ncomparing the model's performance with traditional models,\nfeedback from domain experts further emphasized its signif-\nicance in building trust in model outcomes. Visual analytics\ncan play a pivotal role here, as evidenced by prior research\ndemonstrating its importance in enhancing trust in machine\nlearning models [4]. This is exemplified by the interactive\ntool we developed, which enabled domain experts to extract\nvaluable insights concerning the model's sensitivity toward\ntemperature and humidity. Moreover, recent discourse, as\nhighlighted in [8], emphasizes the critical role of visual\nanalytics in fostering trust-augmented applications of artificial\nintelligence and machine learning (AI/ML) within the energy\nsector. Building upon this, we designed our application, incor-\nporating carefully selected visual analytic interventions. These\ninterventions facilitate the comparison of multiple models\nacross various parameters, including solar penetration levels,\ndataset resolutions, and different hours of the day, enhancing\nstakeholders' confidence in model performance.\nThe aim of our application is to build trust through model\ncomparison, primarily comparing our net load forecasting\nmodel with a reference model. We enhanced our model to\nprocess inputs at varying resolutions and then devised the\nreference model, which generates predictions by averaging net\nload ground truths for the last 30 days at the same time point.\nDespite lacking predictive ML components, this reference\nmodel serves as a benchmark in various net load forecasting\ncompetitions, including the recent Net Load Forecasting Prize\nby the National Renewable Energy Laboratory (NREL) and\nthe U.S. Department of Energy Solar Technologies Office\n(SETO) [13]. Through the web interface of our application,\nwe were able to uncover patterns in the performance that help\nimprove trust in the model outcomes. In this work, we identify\nthe visual analytic tasks that are required to compare these"}, {"title": "II. MODEL DESCRIPTION", "content": "We start with a deep learning-based probabilistic model\ntailored for net load forecasting in high behind-the-meter solar\nscenarios [14]. This model has three key components: a ker-\nnelized probabilistic forecasting (kPF) module, an autoencoder\n(AE), and a long short-term memory (LSTM) network. This\nmodel effectively captured complex temporal dependencies\nand uncertainties inherent in net load data, which is crucial\nfor reliable forecasting in environments with high solar pen-\netration. By incorporating kernel methods into probabilistic\nforecasting, the model handled non-linear relationships and\ncaptured subtle variations in net load influenced by solar\nenergy fluctuations. The autoencoder component enhanced\nfeature extraction and dimensionality reduction, facilitating the\nLSTM network's ability to capture long-term dependencies\nand predict future net load values accurately. Experimental\nresults demonstrated the superior performance of this model\ncompared to traditional forecasting models, showcasing its\nefficacy in addressing the challenges posed by high solar\nscenarios and advancing the state-of-the-art in net-load fore-\ncasting methodologies.\nThis model was used in the Net Load Forecasting Prize\ncompetition hosted by NREL and SETO [13]. However, during\nthis competition, we observed its underperformance on the\ndata provided by the organizers, which had lower resolutions.\nWe discovered that while the autoencoder component excelled\nwith high-resolution datasets (such as 15-minute intervals),\nit struggled to effectively capture temporal dependencies in\nlower-resolution datasets (e.g., 1-hour intervals provided by\nthe organizers). Consequently, this limitation led to subpar\noutcomes generated by the LSTM component. In light of this,\nwe opted to remove the kPF and autoencoder components\nand instead developed a version of the model solely utilizing\nthe LSTM component. Additionally, fine-tuning the number of\nlayers in the LSTM component yielded significantly improved\nresults in the competition.\nThe competition employed a reference model to assess\nmodel performance across various probability levels. As pre-\nviously mentioned, this reference model simply utilizes histor-\nical input data from the past 30 days to generate probabilistic\nforecasts for a specific time point. This model can serve as\nthe initial benchmark for assessing the effectiveness of other\nmodels. Therefore, in this work, we developed a reference\nmodel following the same principles. Since these forecasts are\nprobabilistic in nature, we calculated the Continuous Ranked\nProbability Score (CRPS) for both the reference model and our\nmodel. Subsequently, we computed the Continuous Ranked\nProbability Skill Score (CRPSS) based on these CRPS scores,\nevaluating whether our forecast presents an improvement or\ndeterioration compared to the reference forecast [5], [17]. A\npositive CRPSS indicates that the forecast outperforms the\nreference forecast, whereas a negative value suggests inferior\nperformance. Utilizing these CRPSS values, we compare the\nperformance of our model against the reference model across\nmultiple dates throughout the year, and present these values\nin our application."}, {"title": "III. VISUAL ANALYTICS-BASED DESIGN", "content": "Our application employs a visual analytics-based design\nfeaturing coordinated views enhanced with visual cues to help\nusers compare model performance. It combines interactive\nvisualization with comparison metrics like CRPSS to improve\ntrust in the model outcomes and also allows the users to probe\nthe model and understand its performance across different so-\nlar penetration levels and months. In this section, we highlight\nthe two tasks performed by our application and how its visual\nanalytics-based design aids in executing these tasks:\nT1: Compare model performance across different solar pen-\netration levels and data resolutions: Model performance may\nvary across different solar penetration levels due to the in-\ncreased variability in net load data caused by intermittent solar\ngeneration. LSTM-based models might struggle to capture\nand predict these dynamic behaviors accurately. Furthermore,\ndatasets with higher resolutions, such as sub-hourly intervals,\nenable models to more effectively capture short-term fluctua-\ntions and dependencies. Hence, this task essentially involves\ncomparing model performance at different solar penetration\nlevels and data resolutions.\nT2: Identify patterns across different timeframes: By analyzing\nperformance across multiple timeframes, power scientists can\nassess the net load forecasting models' robustness and consis-\ntency in capturing both short-term fluctuations and long-term\ntrends. This evaluation helps to identify whether a model's\nperformance is consistent across various temporal scales or"}, {"title": "IV. RESULTS FROM A CASE STUDY", "content": "The efficacy of an application can be validated if the\napplication is able to perform the intended tasks effectively.\nIn this section, we show the results through a case study that\ndemonstrates how our application can be used to compare and\nselect net load forecasting models effectively.\nThis case study involved a power scientist with over 10\nyears of experience in power and grid systems. With expertise\nin nonlinear dynamics, large-scale networks, and distributed\ncontrol, he played a crucial role in developing the model.\nHis main objective was to assess the model's performance\nrelative to the reference model across various time points and\nsolar penetration levels, which are critical factors to consider\nbefore deploying it for a project. We informed him that we had\nintegrated CRPSS values for both the model and the reference\nmodel for all dates throughout the year. He then accessed our\napplication through a browser and examined the distribution\nof CRPSS values across different data frequencies at a 20%\nsolar penetration level (Figure 2a). Notably, he discovered\nthat the model performed better with the lower resolution\ndataset (1-hour), contrary to expectations for an LSTM-based\nmodel (T1). Upon further examination, he noted a marginal\ndifference in the median CRPSS between high and low-\nresolution datasets (0.85 and 0.89, respectively). Therefore, he\nenabled the comparison mode through the Sidebar, enabling\nhim to assess the model's performance as solar penetration\nincreased. He noted that the model consistently performed well\nwith the higher resolution dataset (15-min) across all other\nsolar penetration levels, confirming the notion that our model\nexcels with high-resolution datasets in high solar penetration\nscenarios (Figures 2b and 2c). Next, he observed that although\nthe median CRPSS was significantly above zero, the minimum"}, {"title": "V. CONCLUSION", "content": "Efficient model selection for net load forecasting plays a\npivotal role in energy planning and grid operations. In this\nwork, we delve into this process, integrating visual analytics\nwith input from domain experts to identify key tasks for\ncomparative model selection. Subsequently, we translate these\ntasks into an interactive interface, enabling users to assess\nmodel behavior across various factors such as solar penetration\nlevels, data resolution, and time of day.\nThroughout this endeavor, we gained valuable insights into\nthe model behavior and the challenges posed during the multi-\nway comparison of models. This collaborative effort under-\nscored the need for interactive tools that facilitate the seamless\ntranslation of model insights into actionable decisions. We can\nargue that our application is a first step towards this direction.\nAs a next step, our plan is to incorporate multiple net load\nforecasting models into the application and integrate additional\nmetrics for effective comparison of their performance.\nLooking ahead, we aim to enhance our application in several\nways. Incorporating economic planning and analysis options\nwill allow stakeholders to assess the cost-benefit ratio before\nmodel selection, thereby enhancing trust in the outcomes.\nAdditionally, as the energy landscape evolves, our applica-\ntion's flexibility will be pivotal in effectively comparing and\nselecting forecasting models for real-world applications. In\nsummary, our collaborative endeavor has produced a robust\ntool for multi-faceted model comparison and has paved the\nway for informed decision-making through visual analytics in\nenergy planning."}]}