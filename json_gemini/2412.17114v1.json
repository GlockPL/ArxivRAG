{"title": "On the ETHOS of Al Agents: An Ethical Technology and Holistic Oversight System", "authors": ["Tomer Jordi Chaffer", "Justin Goldston", "Bayo Okusanya", "Gemach D.A.T.A.I"], "abstract": "In a world increasingly defined by machine intelligence, the future depends on how we govern Al's development and integration into society. Recent initiatives, such as the EU's Al Act, EDPB opinion, U.S. Bipartisan House Task Force and NIST's AI Risk Management Report, highlight the urgent need for robust governance frameworks to address the challenges posed by advancing Al technologies. However, existing frameworks fail to adequately address the rise of Al agents-autonomous systems capable of complex decision-making, learning, and adaptation-or the ongoing debate between centralized and decentralized governance models. To bridge these gaps, we propose the ETHOS (Ethical Technology and Holistic Oversight System) framework, which leverages Web3 technologies-including blockchain, smart contracts, decentralized autonomous organizations (DAOs), and soulbound tokens (SBTs)-to establish a decentralized global registry for Al agents. ETHOS incorporates the concept of Al-specific legal entities, enabling these systems to assume limited liability and ensuring accountability through mechanisms like insurance and compliance monitoring. Additionally, the framework emphasizes the need for a collaborative, participatory approach to Al governance, engaging diverse stakeholders through public education, transparency, and international coordination. ETHOS balances innovation with ethical accountability, providing a forward-looking strategy for the responsible integration of Al agents into society. Finally, this exploration reflects the emergence of a new interdisciplinary field we define as \u201cSystems Thinking at the Intersection of Al, Web3, and Society\".", "sections": [{"title": "Introduction", "content": "Artificial intelligence (Al) is reaching a defining moment in its integration into our society. This next step in the \u201crace to Al\u201d will be marked by the emergence of Al agents at scale - autonomous Al systems capable of advanced reasoning, iterative planning, and self-directed actions (Xi et al., 2023). Al agents exhibit a high degree of autonomy, both in their ability to perform tasks in pursuit of a goal independently as well as in their ability to learn and adapt over time across a multitude of contexts (Guo et al., 2024). Because of their ability to automate complex tasks and enhance informed decision-making, Al agents are expected to transform various industries, including healthcare, finance, and governance. However, this transformative potential also introduces profound societal and legal implications, particularly as Al agents operate with increasing independence and become undeniably influential in our society. As highlighted in a recent Science publication (Bengio et al., 2024), current governance structures for Al lack appropriate considerations for autonomous Al agents, underscoring the urgent need for a framework that accounts for the latest advancements in Al technology.\nTo address this concern, our conceptual analysis explores a central question that will dictate how we move forward in the age of artificial intelligence: What is the ethos-the character, guiding principles, or moral nature-of Al agents (Hess and Kjeldsen, 2024), and how does it inform their regulation? Defining the ethos of Al agents is an attempt to enter the next stage in the journey of artificial intelligence with a more examined outlook on how Al will influence our lives, and how we should guide Al toward upholding societal values and achieving collective goals. In this spirit, we introduce the ETHOS (Ethical Technology and Holistic Oversight System) model, a novel framework for regulating Al agents. ETHOS is built on foundational concepts from the ongoing literature on Al regulation, ethics, and law, while also seeking to pioneer a multi-dimensional approach to Al governance by leveraging Web3 as the core architecture. We balance innovation with ethical accountability by categorizing Al agents into risk tiers and aligning oversight mechanisms proportionally to their societal impact. The ETHOS model establishes a robust foundation for aligning Al technologies with societal values and ensuring their responsible development and deployment, offering a balanced, forward-looking regulatory strategy for Al agents."}, {"title": "Defining the Ethos of Al Agents", "content": "Our position is that the integration of Al agents into society is inevitable. As such, our interest is in understanding how to set up safeguards so that a collective vision will guide their integration and prioritize responsibility, fairness, and accountability. To do so, we must understand what Al agents are at their core. Al agents are autonomous entities that are fully capable of acting independently, leveraging tools to accomplish goals. Indeed, as Hooker and Kim (2019) emphasize, this independence necessitates the formulation of a well-defined foundation of rationality and ethical grounding (Hooker & Kim, 2019). Without such a foundation, autonomous systems may pursue objectives in ways that lead to unforeseen and potentially harmful consequences.\nRationality in Al agents relates to their ability to make high-level decisions and take actions that maximize performance through logical reasoning, data analysis, and empirical evidence. Within the Al philosophy literature, rational agents are also referred to as BDI-agents as they can be ascribed beliefs, desires, and intentions (Dennis et al., 2016; Cervantes et al., 2019). This rationality is inherently shaped by the agent's vision of the world-the contextual framework and dataset within which it operates. This \"vision\u201d defines the parameters of its understanding, influencing how it interprets data, evaluates options, and prioritizes goals (Vetr\u00f2, 2019). Consequently, the rationality of an Al agent is not an isolated construct but a reflection of the environment it is designed to navigate and the objectives it is programmed to achieve. While a contentious topic within the philosophical literature, it can be argued that a critical aspect of rationality is consistency (i.e., consistent beliefs), as rational decisions must adhere to coherent logic, avoiding contradictions within their reasoning processes (Elster, 1982). This will be especially important for multi-agent systems, known as swarms, working together to achieve a common objective (Jiang et al., 2024). Adaptability can also be indirectly related to rationality, as agents need to modify their decisions and strategies as new information emerges, ensuring their actions remain contextually relevant and effective (Xu et al., 2024).\nEthical grounding is a necessary condition for Al agents to operate in a manner that respects fundamental human values, dignity, and rights (Laitinen & Sahlgren, 2021). This involves embedding robust ethical principles into their architecture and decision-making processes, an approach that is in line with ethical governance. Indeed, Winfield and Jirotka (2018) define ethical governance as a \u201cset of processes, procedures, cultures, and values designed to ensure the highest standards of behavior\u201d (Winfield & Jirotka, 2018). The implication is that in order to achieve ethical governance, ethical behaviors are required by the developers of Al in addition to the end users. A foundational approach is deontological ethics, which establishes rules and duties that bind agents to predefined ethical guidelines (McGraw, 2024), such as the imperative to avoid harm and uphold privacy. Complementing this is consequentialism, which obligates agents to assess the outcomes of their actions (Card & Smith, 2020), striving to maximize benefits while minimizing potential harm. Human-centric design further fortifies ethical grounding by prioritizing human welfare and agency (Balayogi et al., 2024), ensuring that the decisions of Al agents tangibly benefit individuals and communities. Equally critical are transparency and accountability, which demand that agents provide comprehensible explanations for their actions and remain subject to scrutiny (Chaffer et al., 2024). This has the potential to foster trust and mitigate risks, including preserving foundational ethical and legal norms.\nFinally, goal alignment, also referred to as value alignment, enables agents to harmonize short-term actions with long-term objectives, all while maintaining ethical considerations. This alignment ensures that autonomous behavior is purpose-driven and responsive to overarching societal and systemic priorities (Malek Mechergui & Sarath Sreedharan, 2024). This requires a deliberate balance between immediate functionality and broader implications, enabling Al agents to navigate complex environments while remaining purpose-driven and ethically sound. In practice, goal alignment entails a dynamic relationship between the agent's programmed objectives and its adaptability to real-world contexts. Key to achieving goal alignment is the incorporation of multi-layered feedback loops, where Al agents continuously assess the outcomes of their actions against predefined ethical benchmarks and societal objectives. This approach is critical to iterative improvement and responsiveness to evolving human values and systemic changes."}, {"title": "How the Ethos of Al Agents Informs Risk-based Regulation", "content": "The ethos of Al agents, therefore, is the combination of rationality, ethical grounding, and goal alignment that guides their autonomous behavior, ensuring decisions are logical, ethically sound, and aligned with societal and systemic priorities. To bridge the conceptual understanding of the ethos of Al agents with actionable strategies for their integration into society, propose four key attributes-autonomy, decision-making complexity, adaptability, and impact potential-as essential in operationalizing their ethos. These attributes serve as practical proxies for translating the abstract principles of rationality, ethical grounding, and goal alignment into measurable factors that can guide governance and human oversight.\nAutonomy, which measures the degree of independence in decision-making and execution (Beer et al., 2014), reflects the principle of rationality by determining how effectively an Al agent can act on its own while adhering to logical reasoning and ethical constraints. For example, consider a healthcare diagnostic Al system operating autonomously in a remote clinic. Such a system must independently analyze patient data, identify potential health issues, and recommend treatment plans based on logical reasoning and medical guidelines (Ferber et al., 2024). Its ability to act autonomously ensures timely interventions in resource-limited settings while adhering to ethical constraints, such as prioritizing patient safety and privacy, thereby aligning its actions with immediate clinical objectives and broader societal norms of healthcare equity and accessibility.\nDecision-making complexity, which captures the intricacy of tasks and environments the Al operates in (Swanepoel & Corks, 2024), connects to rationality and ethical grounding by addressing how Al agents handle intricate environments and tasks. The more complex the decision-making process, the greater the need for transparency, fairness, and consistency to avoid unintended consequences and ensure decisions align with ethical principles. For example, consider a judicial Al agent used in sentencing recommendations. Such a system must analyze vast amounts of legal precedents, case details, and contextual factors while ensuring that its recommendations are fair and unbiased (Uriel & Remolina, 2024). The complexity of this task necessitates transparency in how decisions are made, such as providing clear explanations for why certain sentences are recommended, and adherence to ethical principles like avoiding racial or socioeconomic bias. Failing to address decision-making complexity in this context could lead to unjust outcomes and erode trust in both the Al system and the legal process it supports.\nAdaptability, reflecting the agent's ability to adjust to new data or evolving circumstances (Xia et al., 2024), is tied to rationality's emphasis on responsiveness and goal alignment. By assessing an agent's capacity to adapt, this attribute ensures that the Al remains effective, contextually relevant, and ethically consistent even in dynamic environments. For example, consider an Al agent managing a smart energy grid (Malik & Lehtonen, 2016). The agent must adapt to fluctuating energy demands, weather conditions, and renewable energy inputs while prioritizing efficiency and minimizing environmental impact. If a sudden heatwave increases energy consumption, the agent must dynamically adjust resource allocation and recommend power-saving measures without compromising critical services. This adaptability ensures its decisions remain effective and ethically consistent, aligning with both immediate needs and long-term sustainability goals.\nImpact potential, which evaluates the scope and scale of consequences resulting from the agent's actions (Zhang et al., 2024), operationalizes the concept of goal alignment by assessing how purpose-driven an agent's behavior is and ensuring that its societal effects are proportionally overseen. This attribute reflects an agent's ability to balance short-term objectives with long-term systemic priorities. Together, these attributes provide a practical framework for translating the abstract principles of rationality, ethical grounding, and goal alignment into actionable, measurable factors that guide governance and human oversight. For instance, an Al agent managing urban traffic flow can significantly reduce congestion and emissions, directly impacting millions of commuters and the environment (Lungu, 2024). However, such an agent must also balance the needs of different stakeholders, such as prioritizing emergency vehicles during peak traffic. This ensures that the agent's decisions align with both short-term objectives, like immediate traffic efficiency, and long-term priorities, such as improving overall urban mobility and air quality.\nNow, consider an Al agent designed to manage disaster response in a smart city (Fan et al., 2019). This agent exemplifies the integration of autonomy, decision-making complexity, adaptability, and impact potential:\n1. Autonomy: The agent operates independently, analyzing real-time data from sensors, social media, and emergency services to deploy resources like ambulances, firefighters, and evacuation plans without requiring constant human input. Its ability to act independently ensures swift responses, aligning with rational decision-making and societal priorities.\n2. Decision-Making Complexity: The agent navigates intricate environments, balancing the needs of affected populations, resource availability, and infrastructure constraints. For example, during a flood, it must prioritize evacuating hospitals, dispatching relief supplies, and rerouting traffic, ensuring decisions are fair, transparent, and ethically sound.\n3. Adaptability: As conditions evolve, such as a sudden surge in floodwaters or an unexpected infrastructure collapse, the agent updates its strategies in real-time. This dynamic responsiveness ensures that it remains contextually relevant, continuously effective, and ethically consistent, even in unpredictable scenarios.\n4. Impact Potential: The agent's decisions have far-reaching consequences, from saving lives to minimizing economic damage and ensuring long-term urban recovery. Its ability to balance immediate rescue efforts with systemic priorities like maintaining public trust and rebuilding infrastructure demonstrates its alignment with both short-term objectives and overarching societal goals.\nWhile this Al agent can save the city, it can also coordinate its destruction. To this point, Al agents can be superheroes, but as the saying goes, \u201cwith great power comes great responsibility\". Such responsibility, however, ultimately lies in the hands of humanity. To this end, we must place great efforts in understanding what Al agents are, what they can become, and what they can ultimately do for humanity. This underlines the motivation for our exploration of the ethos of Al agents. Indeed, the ethos of Al agents-rooted in rationality, ethical grounding, and goal alignment-provides a way in which to conceptualize them as entities as we guide their integration into society. Furthermore, by examining their degrees of autonomy, decision-making complexity, adaptability, and impact potential, we can better anticipate and address the unique challenges and risks they may pose. This philosophical examination can help address the challenges of human oversight in Al regulation.\nTo engage with the issue of human oversight (D\u00edaz-Rodr\u00edguez et al., 2023), we adopt a risk-based regulatory model to categorize Al agents according to their potential risks (EU, 2024; Celso Cancela-Outeda, 2024). Risk management is a trending approach to Al regulation (Barrett et al., 2023), as exemplified by The European Union's Al Act risk-based categories for Al use. Recently, in a study by The National Institute of Standards and Technology (NIST), commissioned by the United States Department of Commerce, risk was referred to as \u201cthe composite measure of an event's probability (or likelihood) of occurring and the magnitude or degree of the consequences of the corresponding event\u201d (NIST, 2024). We adapt the risk-based model to categorize Al agents into four tiers-unacceptable, high, moderate, and minimal-ensuring proportional oversight based on their potential societal impact and associated risks."}, {"title": "The ETHOS Model", "content": "Embedding decentralized governance at the core of Al regulation can help us move toward a future that prioritizes inclusivity, mitigates risks of power concentration, and enables all citizens to shape how Al impacts their lives. This vision aligns with our broader goal of balancing innovation with ethical responsibility while ensuring that no single entity dominates the trajectory of Al development and deployment. The ETHOS framework thus positions blockchain as the foundation for a more equitable, participatory, and resilient Al governance ecosystem.\nTo implement a scalable, decentralized governance model, our proposed framework leverages the following core technologies:\n1. Smart Contracts\nSmart contracts are self-executing agreements stored on the blockchain that automate compliance enforcement, risk monitoring, and decision-making processes. For instance, they trigger actions like adjusting risk tiers, enforcing penalties, or revoking compliance certifications based on predefined benchmarks. By minimizing human intervention, smart contracts ensure transparency, efficiency, and trust in regulatory execution (Buterin, 2014).\n2. Decentralized Autonomous Organizations (DAOs)\nDAOs form the backbone of ETHOS governance, enabling participatory decision-making through consensus mechanisms. Stakeholders-such as developers, regulators, auditors, and ethicists-vote on governance actions, including updates to risk thresholds, ethical guidelines, or approvals for high-risk Al agents. Governance decisions are logged immutably on the blockchain for transparency and accountability (Hassan & De Filippi, 2021).\n3. Oracles\nOracles bridge off-chain and on-chain data by securely gathering, validating, and transmitting real-world information-such as performance logs, user feedback, and societal impact metrics-onto the blockchain (Hamda Al-Breiki et al., 2020). This ensures that ETHOS remains dynamic and responsive to Al agent performance while preventing data manipulation through decentralized verification and redundancy mechanisms.\n4. Self-Sovereign Identity (SSI)\nSSI enables privacy-preserving and verifiable identity management for Al agents (Chaffer & Goldston, 2022). Each agent is assigned a digital identity containing compliance credentials, performance logs, and audit results. SSI ensures that sensitive metadata remains encrypted and accessible only to authorized stakeholders while allowing seamless validation of compliance records.\n5. Soulbound Tokens (SBTs)\nSBTs act as non-transferable compliance certifications issued when Al agents meet predefined ethical benchmarks, such as bias mitigation, privacy safeguards, or transparency audits (Weyl et al., 2022). Breaches of compliance trigger smart contracts to flag or revoke SBTs, ensuring continuous accountability and ethical alignment.\n6. Zero-Knowledge Proofs (ZKPs)\nZKPs are cryptographic techniques that allow compliance verification without revealing sensitive data (Lavin et al., 2024). For example, ZKPs enable auditors to confirm that an Al agent meets ethical standards (e.g., bias mitigation) without accessing underlying datasets or proprietary algorithms. This ensures data confidentiality while maintaining trust in compliance outcomes.\n7. Dynamic Risk Classification System\nETHOS uses a real-time risk classification system powered by blockchain and oracles to assess Al agent risk levels based on their autonomy, decision-making complexity, adaptability, and societal impact. Smart contracts continuously monitor agent performance against global and regional benchmarks, recalibrating risk profiles as new data emerges.\n8. Immutable and Transparent Audit Trails\nBlockchain-based audit trails record every Al agent's decision, input, and outcome in immutable blocks. Each transaction includes: Input Data: Raw data (e.g., medical records, case files) used for decision-making. Decision Pathways: Algorithms, parameters, and logical reasoning employed. Output Results: The final decision, action, or recommendation. Verification Signatures: Cryptographic hashes ensuring data authenticity. This creates a tamper-proof, transparent mechanism for real-time monitoring and accountability.\n9. Reputation-Based Systems\nReputation systems assess the reliability and trustworthiness of validators, auditors, and Al agents within the ETHOS framework. Stakeholders earn reputation scores based on consistent, verified, and ethical participation, while malicious behavior (e.g., false verification or data manipulation) results in penalties or reduced reputation.\n10. Tokenization and Staking Mechanisms\nETHOS uses native tokens to incentivize validators and auditors for accurate compliance verification. Validators stake tokens to participate in risk assessments, creating a financial deterrent against false verification. Successful verification earns rewards, while malicious behavior results in token slashing.\nProblem: Dangers associated with ineffective centralization of Al regulation and governance.\nSolution: A Global Registry framework, which leverages decentralized technologies to address concerns of ineffective centralization (Cihon et al., 2020). This framework establishes a global platform for Al agent registration, risk classification, and compliance monitoring. By utilizing blockchain technology, the ETHOS Global Registry advocates for immutable recordkeeping, automated compliance checks via smart contracts, and real-time updates to Al agent risk profiles based on validated off-chain data collected through oracles."}, {"title": "ETHOS Governance", "content": "To address concerns about centralized control, the ETHOS framework advocates for the use of DAOs to establish a transparent, participatory, and scalable governance structure. This decentralized framework empowers a diverse set of stakeholders, including governments, developers, ethicists, auditors, civil society groups, and end-users, to actively contribute to regulatory decision-making.\nA core feature of DAOs is their reliance on weighted voting mechanisms (Fan et al., 2023). For instance, subject matter experts, such as ethicists in Al bias or medical professionals in healthcare Al, may carry greater weight in decisions relevant to their domain. At the same time, reputation scores, earned through consistent and trustworthy participation in the governance process, could further incentivize accountability and discourage malicious behavior. All governance actions-including the approval of high-risk Al agents, the adjustment of compliance thresholds, or the revocation of non-compliant systems-are permanently recorded on the blockchain, creating an immutable, transparent audit trail that fosters trust and accountability.\nUltimately, DAOs show promise in fostering adaptive oversight by ensuring governance structures remain responsive to the dynamic and evolving nature of Al agents. Smart contracts automate decision enforcement, such as implementing updated compliance standards or triggering escalated oversight for flagged systems. It is important to evalaute whether this automation can reduce delays, minimize human intervention, and set up conditions for seamless execution of regulatory decisions in this context."}, {"title": "Identity Management of Al Agents on ETHOS", "content": "To mitigate risks of data centralization and safeguard privacy, the ETHOS framework advocates for the incorporation of selective transparency mechanisms powered by SSI and SBTs. Indeed, SSI provides a privacy-preserving solution for managing Al agent credentials and compliance records (Haque et al., 2024). For example, each Al agent is assigned a unique SSI, which securely contains its risk-tier classification and compliance credentials, such as risk assessments based on the ETHOS framework's four-tier system (unacceptable, high, moderate, minimal), third-party audits, and ethical compliance approvals. Examples include certifications aligned with regional and global standards, such as GDPR for data privacy (Naik & Jenkins, 2020) and FHIR or HIPAA for healthcare data security (Broshka & Hamid Jahankhani, 2024). SSI ensures verifiable identity management while preventing unauthorized access to sensitive information, empowering stakeholders-such as regulators, developers, and auditors-to validate an Al agent's compliance securely. Each Al agent's SSI includes the following key metadata and compliance details:\n1. Unique Identifier: A global Al agent ID, functioning as a digital passport, uniquely identifies the Al agent across jurisdictions and regulatory bodies, ensuring traceability and accountability throughout its lifecycle.\n2. Developer Information: Includes the name, location, and certification status of the Al agent's creator(s). This ensures transparency about the agent's origin, promoting trust and accountability for developers' adherence to global and regional standards.\n3. Intended Use Case: A clear description of the Al agent's function, sector, and operational scope. For instance, whether the agent is deployed in healthcare diagnostics, judicial decision-making, financial transactions, or industrial automation. This information allows for context-specific compliance verification aligned with the ETHOS risk classification framework.\n4. Technology Stack: A summarized record of the algorithms, datasets, and machine learning models utilized in the Al agent's design and operation. This ensures that stakeholders can evaluate the technical transparency and ethical integrity of the Al agent, while sensitive details remain encrypted and available only to authorized auditors and regulators.\n5. Deployment Details: Information on the countries and regions where the Al agent is deployed, along with its compliance with jurisdiction-specific regulations (e.g., GDPR for European data privacy or HIPAA for U.S. healthcare security). This fosters alignment with regional governance frameworks while enabling seamless cross-border collaboration.\n6. Performance Logs: Immutable, on-chain records of the Al agent's operational performance, including:\nAccuracy Metrics: Data on the agent's task success rates and error margins.\nBias Mitigation: Evidence of the agent's fairness across demographic or contextual variables.\nSocietal Impact: Metrics assessing the agent's broader effects on individuals, communities, and the environment. These logs are cryptographically secured and transparently verifiable, allowing auditors and regulators to validate performance benchmarks dynamically.\n7. Audit Results: Verified outcomes of independent regulatory audits and inspections, including third-party compliance certifications (e.g., GDPR, HIPAA, etc.) and ethical benchmarks (e.g., transparency audits, privacy safeguards, and bias mitigation standards). These results are logged immutably on the blockchain and linked to the SSI, ensuring transparency and trust in the auditing process.\nComplementing SSI, SBTs act as non-transferable, on-chain compliance certifications tied to predefined ethical benchmarks, such as bias mitigation, privacy safeguards, and transparency audits (Weyl et al., 2022). Certifying bodies issue SBTs when Al agents successfully meet compliance milestones, enabling instant verification of adherence to regulatory and ethical guidelines. In the event of a breach-such as the detection of bias or privacy violations-smart contracts automatically trigger actions to flag or revoke SBTs, restricting further deployment until corrective measures are taken. This automated enforcement mechanism ensures continuous accountability while minimizing manual intervention.\nTo further preserve privacy, zero-knowledge proofs (ZKPs) enable compliance verification without exposing sensitive underlying data. ZKPs allow auditors or regulators to confirm that an Al agent meets ethical and regulatory benchmarks without revealing proprietary information, such as technology stacks or operational algorithms. Additionally, metadata-such as details of a developer's proprietary systems or operational performance-remains encrypted and accessible exclusively to authorized stakeholders, ensuring data confidentiality.\nBy combining SSI, SBTs, smart contracts, and ZKPs, the ETHOS framework embeds ethical compliance mechanisms that are both transparent and privacy-preserving. Examples of compliance credentials-such as risk-tier classifications, third-party audits, and certifications like GDPR and HIPAA ensure a jurisdictionally recognized and consistent standard for verification. This approach can empower equitable collaboration across global stakeholders while safeguarding sensitive Al agent data. Selective transparency ensures that compliance verification remains robust, verifiable, and automated, while sensitive operational details are shielded from misuse. As a result, ETHOS creates a resilient, accountable, and privacy-conscious governance system that addresses the challenges of centralization and promotes the responsible integration of Al agents into society."}, {"title": "ETHOS in Practice", "content": "The registry integrates a dynamic risk classification system powered by decentralized oracles and smart contracts, ensuring real-time, transparent, and adaptive Al governance. Blockchain serves as the foundation for securely aggregating and sharing Al agent performance data, enabling continuous updates to risk profiles based on real-world inputs. Oracles play a critical role in bridging off-chain and on-chain data by securely gathering, validating, and transmitting diverse data streams-such as task performance, societal impact metrics, and user feedback-onto the blockchain. These data streams can originate from Internet of Things (IoT) sensors, Application Programming Interfaces (APIs), or manual inputs, ensuring broad, real-time monitoring capabilities.\nTo maintain accuracy and reliability, multiple oracles participate in decentralized verification processes, cross-referencing data sources to ensure consistency before anchoring information to the blockchain. For instance, oracles can validate resource allocation reports generated by Al agents against real-world outcomes, such as healthcare delivery logs or environmental monitoring results. This redundancy and consensus mechanism minimizes the risk of data manipulation or inaccuracies. Once securely recorded, smart contracts automatically compare on-chain data to predefined global and regional compliance benchmarks, facilitating continuous risk assessment and compliance monitoring. This includes recalibrating risk profiles, automating tier adjustments, triggering penalties for ethical or performance deviations, or escalating issues to human oversight when necessary. By continuously feeding and verifying new data, the system ensures proportional oversight that evolves in response to a Al agent's real-world performance and societal impact. The decentralized, automated nature of this framework enhances transparency, accountability, and resilience while mitigating risks associated with centralized control, such as bottlenecks, regulatory capture, or security vulnerabilities.\nIncentive structures are central to enhancing the decentralization, reliability, and scalability of the ETHOS framework, ensuring the integrity of data verification and compliance processes. The system relies on decentralized participants-validators and auditors-who assess the accuracy and integrity of real-time data submitted by oracles. This multi-layered process fosters trust and equitable participation across diverse stakeholders, including data providers (e.g., IoT devices, APIs), validators, and decision-makers such as regulators and Al developers.\nThe incentive mechanism operates through a well-defined workflow: Oracles gather and submit real-world data-such as performance logs, societal impact metrics, and user feedback-to the blockchain, where validators perform decentralized verification (Pasdar et al., 2022). Validators assess data for accuracy using techniques such as timestamp checks, cross-referencing with alternative sources, or consensus mechanisms like Proof of Stake (PoS) and Proof of Authority (PoA) (Bahareh Lashkari & Musilek, 2021; Manolache et al., 2022). By requiring majority consensus to approve submissions (Alhejazi & Mohammad, 2022), the system could minimize the risk of inaccurate or manipulated data entering the registry. A native token system underpins the incentive structure. Validators stake tokens to participate in the verification process, creating a financial deterrent against dishonesty-false verification or inaccurate assessments result in penalties, such as token slashing or temporary bans. Successful verification earns validators tokenized rewards, incentivizing ongoing participation and maintaining system scalability. Additionally, a reputation-based system assigns scores to validators based on their performance, rewarding consistently accurate verification with higher rewards or increased voting power in governance decisions. This approach fosters long-term reliability and trust within the ecosystem. Smart contracts enforce these incentive mechanisms automatically, ensuring transparency and accountability. Non-compliance or unethical behavior-such as approving fraudulent data or breaching ethical standards-triggers pre-programmed penalties, including freezing Al agent deployments or revoking developer credentials. This automated enforcement process minimizes human intervention while maintaining fairness and integrity."}, {"title": "ETHOS and the Evolution of Legal Liability", "content": "A holistic model for Al risk management is not built solely on technical and operational safeguards but must also address how Al agents may pose fundamental risks to questions of justice-an essential pillar of our society. An emerging issue with Al agents is the question of legal liability. Al agents pose distinct liability challenges that necessitate a structured accountability framework to address issues such as information asymmetry, complex value chains, and delegation of discretion (Dunlop et al., 2024; Soder et al, 2024). To address these challenges, we must answer the question of how responsibility is assigned, provide clarity in liability, and propose mechanisms for compensating damages caused by autonomous systems. Lior (2019) argues that Al agents are not entities that are capable of assuming legal responsibility for any wrongdoing as they lack judgement and are merely used as an instrument by the human overseer (Lior, 2019). We acknowledge the merits of his position, and while Al agents may currently lack the human qualities-such as judgment, intent, and moral responsibility-needed to assume legal accountability, it is not difficult to imagine a scenario where Al agents obtain such qualities and, as a result, have complicating effects for traditional conceptions of accountability.\nETHOS anticipates scenarios where legal ambiguities arise and offers mechanisms to ensure adherence to core legal values, such as proportional accountability, ethical transparency, and equity, even in uncharted territories. Indeed, the ETHOS framework addresses the challenges of legal liability by proposing innovative mechanisms that adapt traditional accountability structures to the unique characteristics of Al agents. Central to this is the concept of Al-specific legal entities, granting highly autonomous Al systems a limited form of legal status, akin to corporate entities (Doomen, 2023). This conceptual status envisions scenarios where Al agents could assume liability for damages caused by their actions, effectively shifting the burden of responsibility from developers and operators to the Al system itself. However, this approach is not without its worrisome implications-it raises profound ethical, legal, and societal questions about the nature of responsibility, intent, and the moral agency of Al systems. As creators of Al, we must tread carefully in considering such paths, weighing the long-term impacts of these decisions on societal structures and values. Recognizing these complexities, the ETHOS framework proposes a roadmap for exploring alternative scenarios and carefully guiding discussions about the evolving role of Al agents within the legal system. Rather than endorsing the immediate application of these ideas, this approach encourages thoughtful deliberation, offering a conceptual lens to consider how legal systems might adapt to address novel issues arising from the integration of Al agents into our society.\nOne approach worthy of consideration is the idea of Al-specific legal entities being governed by a decentralized governance body and required to maintain mandatory insurance coverage, ensuring financial compensation for damages and incentivizing risk mitigation through reduced premiums for safer, more ethically aligned systems. For instance, high-risk Al agents, such as those used in healthcare, require stringent measures, including legal entity registration, mandatory insurance, and frequent audits to ensure compliance. Moderate-risk agents, operating in less sensitive environments, would still mandate insurance and operator accountability, with periodic audits to confirm adherence to ethical and safety standards. Minimal-risk agents, by contrast, would have lighter oversight, with general liability remaining with operators and optional insurance coverage. Accountability is ultimately at the hands of developers and operators first, who remain responsible for ensuring ethical design, avoiding biases, and adhering to safety standards. Certification processes and mandatory audits would help enforce compliance while legal mechanisms apportion shared liability in cases of joint fault. To handle disputes arising from Al agent operations, specialized dispute resolution mechanisms such as dedicated tribunals and alternative dispute resolution (ADR) processes can be employed.\nIn addition to developer and operator accountability, we propose extending the concept of Al agent insurance to the consumer level, allowing individual users to insure Al agents operating within their personal or professional domains. This innovation would not only empower users to manage liability risks associated with their Al agents but also foster the emergence of a specialized insurance industry tailored to the unique challenges posed by Al technologies. For example, a consumer's Al agent personal assistant might mistakenly execute a high-value financial transaction outside of preset parameters, resulting in significant financial losses that could be mitigated through consumer-level Al agent insurance. Policies could be customized based on the agent's autonomy and application, opening avenues for dynamic risk assessment and mitigation strategies. Consumer-level insurance offers a dual advantage: it alleviates some of the liability burdens on developers and operators while providing an additional safeguard to encourage public trust and adoption of Al systems.\nThe ETHOS framework has the potential to facilitate the implementation of these accountability mechanisms by providing a structured and adaptive governance model tailored to the unique challenges of Al agents. By leveraging decentralized governance structures, such as DAOs (Decentralized Autonomous Organizations), ETHOS provides transparent oversight and participatory decision-making for Al-specific legal entities. Its dynamic risk classification system enables proportional oversight, aligning mandatory insurance requirements and liability standards with the potential societal impact of Al agents. Furthermore, the framework's use of blockchain-based transparency tools and audit trails ensures that compliance processes remain robust, verifiable, and accountable. By embedding these principles into its design, the ETHOS framework creates the necessary infrastructure to operationalize developer, operator, and consumer-level accountability, fostering trust and ethical alignment in Al systems."}, {"title": "A Collaborative Approach to Regulating Al Agents", "content": "Strategies for Al governance cannot be created in a vacuum. The transformative potential of Al agents will likely affect every facet of society, making it imperative to draw on diverse perspectives and foster collaboration. Ethical governance of Al agents will require a collaborative effort (Gianni et al., 2022), marked by societal engagement, public education, and innovative policy development to ensure inclusivity, adaptability, and global alignment (Celso Cancela-Outeda, 2024). Stakeholder engagement through, for example, public consultations, is critical to this framework's success (Kallina & Singh, 2024), incentivizing active participation from governments, industry leaders, ethicists, and the public to shape regulatory policies that reflect diverse perspectives and societal priorities (Celso Cancela-Outeda, 2024). It will be important to assess if our ETHOS framework has an effect on creating a sense of collective ownership over Al governance, possibly by fostering transparency and building trust. Transparency in policy development through open processes further enhances societal trust and buy-in, resulting in more robust and acceptable policies (Matasick, 2017).\nEducation can empower individuals and communities to engage with Al agents (Kim et al., 2022). Al literacy programs should educate the public about the capabilities, limitations, and ethical considerations of Al, enabling informed decision-making and advocacy. Simplified explanations, ethical awareness, and hands-on interaction with Al agents can foster familiarity and reduce fear of the unknown. We advocate for educators to consider how Al is framed when communicating to students (Kim, 2023). That is, framing of Al agents as collaborators with humans, rather than adversaries or replacements, could, in theory, significantly influence regulatory approaches and societal perceptions. This paradigm, which we have previously described (Chaffer et al., 2024), emphasizes the symbiotic relationship between humans and Al, fostering shared accountability in the human-agent coevolution. We extend our paradigm to explore how collaborative framing-wherein multiple stakeholders share their assumptions, values, and goals-can reduce societal resistance to Al adoption and foster the development of human-centric systems designed to enhance user capabilities rather than operate independently. This approach can inspire policies that balance innovation with"}]}