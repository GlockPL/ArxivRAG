{"title": "Learning Representations for Reasoning : Generalizing Across Diverse Structures", "authors": ["Zhaocheng Zhu"], "abstract": "Reasoning, the ability to logically draw conclusions from existing knowledge, is a hallmark of human. Together with perception, they constitute the two major themes of artificial intelligence. While deep learning has pushed the limit of perception beyond human-level performance in computer vision and natural language processing, the progress in reasoning domains is way behind. One fundamental reason is that reasoning problems usually have flexible structures for both knowledge (e.g. knowledge graphs) and queries (e.g. multi-step queries), and many existing models only perform well on structures seen during training.\nIn this thesis, we aim to push the boundary of reasoning models by devising algorithms that generalize across knowledge and query structures, as well as systems that accelerate development on structured data. This thesis is composed of three parts. In Part I, we study models that can inductively generalize to unseen knowledge graphs, which involve new entity and relation vocabularies. For new entities, we propose a novel framework that learns neural operators in a dynamic programming algorithm computing path representations [275]. This framework can be further scaled to million-scale knowledge graphs by learning a priority function [274]. For relations, we construct a relation graph to capture the interactions between relations, thereby converting new relations into new entities. This enables us to develop a single pre-trained model for arbitrary knowledge graphs [65]. In Part II, we propose two solutions for generalizing across multi-step queries on knowledge graphs and text respectively. For knowledge graphs, we show multi-step queries can be solved by multiple calls of graph neural networks and fuzzy logic operations [270]. This design enables generalization to new entities [62], and can be integrated with our pre-trained model to accommodate arbitrary knowledge graphs [66]. For text, we devise a new algorithm to learn explicit knowledge as textual rules to improve large language models on multi-step queries [273]. In Part III, we propose two systems to facilitate machine learning development on structured data. Our open-source library treats structured data as first-class citizens and removes the barrier for developing machine learning algorithms on structured data, including graphs, molecules and proteins [271]. Our node embedding system solves the GPU memory bottleneck of embedding matrices and scales to graphs with billion nodes [272].", "sections": [{"title": "1. Introduction", "content": "Perception and reasoning are two major themes of artificial intelligence. Perception en-dows an agent with the ability to perceive the environment and process them into knowledge, while reasoning empowers it to use the stored knowledge to answer questions and draw new conclusions. With the rise of deep learning, there have been numerous advanced models in perception domains such as computer vision [82] and natural language processing [210]. These models further reach a zenith when trained on massive data from the Internet, often condensing into a single large model that can serve a wide range of tasks [2, 201, 163, 3]\u2014termed as foundation models nowadays. Nevertheless, breakthroughs of deep learning in reasoning domains are very limited, and consequently many applications are still bottle-necked by the reasoning abilities of current models.\nOne fundamental reason explaining this discrepancy is that reasoning domains require much more complicated generalization than perception domains. Unlike perception domains where unseen problems are mostly interpolation of seen problems, problems in reasoning domains are usually extrapolation of seen problems, e.g. composition, factorization, abstraction or substitution of seen problems. If a model does not possess proper inductive biases to deal with such dimensions of generalization, it will inevitably fail to solve new reasoning problems. highlights the shortcomings of existing model architectures in performing reasoning, which cannot even be amended by training on the whole Internet.\nIn this thesis, we aim to push the boundary of representation learning models in reason-ing domains. We notice that reasoning problems, despite their various surface forms, are underpinned by structures that represent the background knowledge in a reasoning process. Answering a query is thus cast to a series of actions on such structures, often resulting in a sub structure."}, {"title": "1.1. Summary of Contributions", "content": "Here we provide an overview of this thesis and summary of our contributions. In Chap-ter 2, we discuss the definition of problems and the goal of generalization across structures. We summarize related works on representation learning for structures in order to provide readers a better understanding of our contributions. Chapter 3 & 4 study models that gener-alize to structures with unseen entity and relation vocabularies. Chapter 5 & 6 demonstrate models for solving multi-step queries in both graph and text modalities. Chapter 7 & 8 present systems to facilitate development of machine learning on structured data.\n(Chapter 3) Generalization to Knowledge Graphs with Unseen Entities. Knowl-edge graph reasoning is typically solved by embedding methods, which learn an embedding vector for each entity and relation in a knowledge graph. Such embedding vectors restrict the prediction of these methods to entities they are trained on. We proposed NBFNet [275] to learn the representation of every entity pair as a function of the relational paths between them, which eliminates the need for entity embeddings and generalizes to new entities or even new knowledge graphs of the same relation vocabulary. NBFNet achieved state-of-the-art results in both transductive and inductive settings, and can be made more efficient by learning a priority function to select nodes and edges on the fly [274]. NBFNet ranked 12 out of 39 teams in 1st OGB large-scale challenge, being the strongest single model and the most parameter efficient on a knowledge graph with 87 million entities and 504 million facts.\n(Chapter 4) Generalization to Any Knowledge Graph with Arbitrary Entity and Relation Vocabularies. Generalization across knowledge structures plays a key role in the era of foundation models. In order to train a single generic model that performs reasoning on arbitrary input, we need to enable generalization to new relation vocabularies in addition to the entity vocabularies studied in Chapter 3. In our work Ultra [65], we solved this challenge by parameterizing relative relation representations as a function of relation interactions, resulting in two nested NBFNet, one for entities and one for relations. By training on 3 standard knowledge graphs, Ultra shows strong zero-shot generalization performance on 40 knowledge graphs of various domains and sizes, on par or even surpassing state-of-the-art methods on 32 datasets. Ultra eliminated the need of training models separately for each graph and established the first foundation model for knowledge graph reasoning.\n(Chapter 5) Solving Multi-hop Queries on Knowledge Graphs. Many applications of reasoning require to deal with queries that inherently contain multiple steps, e.g. at what universities do Turing Award winners in the field of deep learning work? Common embedding methods modeling such queries simulate logic operations with neural networks, which do not generalize well to different combinations of steps. We proposed GNN-QE [270] to decompose queries into individual steps, and parameterize each step with graph neural networks (GNNs) or fuzzy logic. Such a design aligns with the subgraph matching algorithm that generalizes perfectly when the graph is complete. GNN-QE not only achieves a relative gain of 22.3% on existential positive first-order (EPFO) queries and 95.1% on negation queries, but is also applicable to knowledge graphs with unseen entities [62]. Meanwhile, GNN-QE supports visualization of entity distributions for every intermediate steps, and can be further integrated with Ultra to answer queries on any knowledge graph [66].\n(Chapter 6) Solving Multi-step Queries with Large Language Models. With the popularization of large language models (LLMs), reasoning in natural languages has gradu-ally drawn the attention of the community. Chain-of-Thought (CoT) prompting [225] showed that we can teach LLMs to solve multi-step queries using a small set of in-context examples with intermediate steps. However, CoT relies on implicit knowledge stored in the param-eters of LLMs, of which errors may exacerbate in multi-step reasoning. We rectified this issue with Hypotheses-to-Theories (HtT) prompting [273] that learns explicit knowledge as"}, {"title": "1.2. Other Works", "content": "While this thesis mainly focuses on representation learning techniques for reasoning tasks, some of our works do not directly fall into this range. GraphAny [261] studied generalization across feature and label spaces in the node classification task. BioKGC [92] applied NBFNet to predict new interactions in biomedical networks. We have collaborated in a position paper discussing multi-hop reasoning and neural graph databases [166], and two cross-modal reasoning projects, including KEPLER [218] for enhancing language models with knowledge graph supervision, and GraphText [262] for training-free graph reasoning with LLMs. We have also developed a few works in drug discovery [184, 234] based on our TorchDrug library,"}, {"title": "1.3. Reading Guide", "content": "This thesis is organized in an order from fundamental techniques to application solutions for reasoning and structured data. Readers interested in reasoning domains are encouraged to follow the original order of this thesis. Additionally, this thesis may be interesting to those working on topics related to the techniques we developed. For readers who want to focus on specific machine learning topics, we recommend the following chapters\n\u2022 Graph neural networks: Chapter 3, 4 and 5.\n\u2022 Inductive generalization: Chapter 3, 4 and 5.\n\u2022 Compositional generalization: Chapter 5 and 6.\n\u2022 Zero-shot learning: Chapter 4 and 5.\n\u2022 Large language model reasoning: Chapter 6.\n\u2022 Batching irregular structure: Chapter 3, 5 and 7.\n\u2022 Scalability: Chapter 3 and 8."}, {"title": "2. Background", "content": "In this chapter, we introduce the background knowledge and discuss related work of this thesis. We provide definitions for knowledge graph reasoning, inductive generalization and compositional generalization, as well as discuss challenges for achieving such generalization in representation learning models. We summarize related work in both knowledge graph reasoning and large language model reasoning literature, highlight their drawbacks and refer interested readers to referenced materials."}, {"title": "2.1. Preliminary", "content": "We adopt knowledge graphs as the major testbed for studying generalization, since they are a common discrete format of knowledge and free of confounding factors such as linguistic variations. A knowledge graph is denoted by $G = (V, E, R)$, where $V$ and $E$ represent the set of entities (nodes) and relations (edges) respectively, and $R$ is the set of relation types. Each relation is expressed as a triplet $(h, r, t)$, with $h$ and $t$ being the head and tail entities, and $r$ being the relation type. Due to this formulation, knowledge graphs are often referred to as a collection of triplets, where each triplet is a training or test sample from the perspective of machine learning.\nThe goal of knowledge graph reasoning is to predict all answer entities in a knowledge graph given a query. In its simplest form, the query contains only an entity and a relation, and the goal is to find either head entities or tail entities that form valid triplets with the query. A query example may be Who are Turing Award winners? We denote such queries as $(u, q,?)$ or $(?, q, u)$. Usually, due to the incomplete nature of knowledge graphs, the answer entities cannot be directly retrieved from the knowledge graph, and we need to reason about such missing triplets with representation learning models."}, {"title": "2.1.2. Inductive Generalization", "content": "Traditionally, knowledge graph reasoning methods are evaluated on the knowledge graph they are trained on, with test queries that are not seen during training, which is referred as transductive setting. By contrast, inductive setting uses a test knowledge graph $G_{test} = (V_{test}, E_{test}, R_{test})$ different from the training one $G_{train} = (V_{train}, E_{train}, R_{train})$, and evaluates models with queries on $G_{test}$. Typically, this new graph consists of some entities unseen during training, or a completely new vocabulary of entities, but shares the same relation vocabulary with the training graph, i.e. $R_{train} = R_{test}$. The inductive setting requires models to induce principles that generalize to new entities, rather than memorizing certain properties of entities. In addition to the inductive setting above, we consider a more challenging setting where $G_{test}$ and $G_{train}$ have completely different entity and relation vocabularies, termed as inductive entity and relation setting. The rationale behind this setup is that knowledge graphs may share some reasoning patterns in common (e.g. symmetric rules, composition rules) despite differences in their entity and relation semantics. Since the test graph can be arbitrarily different from the training one, this setting evaluates the ability of generalizing to any knowledge graph."}, {"title": "2.1.3. Compositional Generalization", "content": "Compositional generalization is required for answering multi-step queries, since there are an exponential number of combinations in multi-step queries and most of them cannot be covered in the training set. In other words, models should learn skills for individual steps in the training set, and adaptively re-combine skills for these steps to solve a test query. There are two dimensions of compositional generalization: (1) generalizing to new combinations of steps, which is implicitly covered in the evaluation of multi-step queries; (2) generalizing to longer combinations of steps. We explicitly investigate generalization to longer combinations of steps in Chapter 6."}, {"title": "2.2. Related Work", "content": "In this section, we discuss literature related to reasoning and generalization across struc-tures, grouped by graph representation learning, multi-hop query answering, and reasoning over natural languages. Graph representation learning covers techniques commonly used for learning representations of elements in a graph structure, such as entities, relations, sub-graphs or paths. For multi-hop query answering, we discuss neural and neural-symbolic approaches for solving first-order logic queries on knowledge graphs. For reasoning over natural languages, we summarize the latest techniques in finetuning or prompting LLMs for solving reasoning tasks."}, {"title": "2.2.1. Graph Representation Learning", "content": "Different graph representation learning paradigms developed for knowledge graph reasoning.\nEmbedding Methods. Embedding methods compute the likelihood of a triplet as a func-tion over its entity and relation embeddings. In early methods, the entity embeddings are represented by vectors, while the relations are represented by matrices. For example, SE [24] scores a triplet as the distance between two entities projected by the relation ma-trix. RESCAL [151] scores the triplet as a bilinear model over the entities and the relation, which is generalized to non-linear neural networks by NTN [187]. However, these models lack regularization for relations and tend to overfit the datasets [150].\nLater works reduce the number of parameters in such models by defining relations as vector embeddings with the same dimension as entity embeddings. For example, TransE [23] simplifies the parameterization of SE and interprets relations as a translation in the entity embedding space, and scores triplets based on the distance between translated embeddings and target embeddings. The embeddings are optimized by maximizing the likelihood of observed triplets and minimizing the likelihood of unobserved triplets. Following TransE, a bunch of works improve embedding methods with new score functions that satisfy specific patterns of relations. Here we summarize some prominent works in literature. \nTransE [23] represents relations as a translation in the entity embedding space. For a triplet (h, r,t), the entity embedding $e_h$ after translation should be close to the entity embedding $e_t$ if the triplet is true. Mathematically, the score function can be written as\n$d_r(h,t) = -||e_h + r_r - e_t||$ (2.1)\nwhere $r_r$ is the embedding for relation r. TransE is capable of modeling inversion and composition patterns. For instance, consider a pair of inverse relations $r_1$ and $r_2$ (e.g. husband and wife), we have $d_{r_1}(h, t)$ and $d_{r_2}(t, h)$ hold, which implies $r_{r_1} = -r_{r_2}$, i.e. inverse relations are modeled as opposite translations in TransE. Similarly, if a relation is equivalent to the composition of two relations (e.g. uncle is a composition of father and brother), its embedding can be represented by the sum of the two translations.\nDistMult [236] is simplified parameterization of bilinear score functions [151]. By restricting the relation matrix to be diagonal, DistMult only requires computation linear to the dimension d, achieving the same scalability as TransE. Specifically, DistMult uses the following score function\n$d_r(h,t) = e_h^T diag(r_r) e_t = \\langle e_h, r_r, e_t \\rangle$ (2.2)\nFrom the perspective of relation patterns, DistMult is able to model symmetry patterns (e.g. friend), which is a defect of TransE. However, DistMult is always symmetric and cannot model inversion patterns. DistMult can neither model composition patterns due to its product formulation.\nComplEx [207] is proposed to solve the limitations of DistMult. [207] shows that DistMult is equivalent to an eigen decomposition of the adjacency matrix of each relation. Since DistMult learns real embeddings, which can only model real symmetric matrices, ComplEx learns more general complex embeddings to model asymmetric adjacency matrices. The corresponding score function is\n$d_r(h,t) = Re(e_h^T diag(r_r)\\overline{e_t}) = Re(\\langle e_h, r_r,\\overline{e_t} \\rangle)$ (2.3)\nCompared to DistMult, ComplEx is capable of modeling symmetry, antisymmetry and inversion relation patterns.\nSimplE [108] is another work that tackles the symmetric issue of DistMult. It takes the observation that canonical Polyadic (CP) decomposition [87] can handle asymmetric tensor decomposition, but the subject and object embeddings of each entity is learned indepen-dently. Therefore, SimplE proposes to jointly learn each relation and its inverse relation. The score function of Simple is\n$d_r(h,t) = \\langle e_h, r_r, e'_t \\rangle + \\langle e_t, r_{r^{-1}}, e'_h \\rangle$ (2.4)\nwhere $e$ and $e'$ are two separate embeddings for subjects and objects. If we let $e_h = [e_h, e'_h]$ and $r^*_r = [r_r, r_{r^{-1}}]$, Simple can be rewritten as $ \\langle e^*_h, r^*_r, flip(e^*_t) \\rangle$ where flip(.) flips the first and the second half of the embedding. Same as Complex, Simple can handle symmetry, antisymmetry and inversion relation patterns.\nRotatE [194] is built on the motivation that none of the previous methods can model all common relation patterns. Specifically, it proposes to model symmetry, antisymmetry, inversion and composition relation patterns. This is achieved by defining each relation as a rotation in complex space. Mathematically, RotatE uses the following score function\n$d_r(h,t) = -||e_h r_r - e_t||$ (2.5)\nwhere r, is a vector of unitary complex numbers and is the Hadamard product. $r_r$ can be reparameterized by phase vectors to remove the constraint on unitary norm. RotatE handles symmetry patterns by embedding such relations as phase 0 or \u03c0in each dimension. Inversion patterns are modeled by conjugate rotations. Because any composition of rotations is still a valid rotation, composition patterns are naturally modeled in RotatE.\nQuatE [253] extends RotatE to hypercomplex space, which enjoys two planes of rotations. With Hamilton quaternions, the score function for QuatE is\n$d_r(h,t) = e_h \\frac{r_r}{||r_r||} e_t$ (2.6)\nNode GNN Encoders. Node GNN encoders are the most prevalent framework for ap-plying GNNs to knowledge graphs. GAE [112] and RGCN [176] adopt an auto-encoder formulation, which uses GNNs to encode entity representations, and decodes triplets from entity representations and relation representations with a score function from embedding methods [23, 236, 207, 108, 194]. Some methods adopt a variational auto-encoder [111] for-mulation to regularize the entity representations with a prior distribution, such as a Gaussian distribution [112] or a von Mises-Fisher distribution [49]. Recent works improve node GNN encoders with advanced GNN architectures for knowledge graphs [209, 29]. However, the capacity node GNN encoders is somehow limited, since the two entities in a triplet are en-coded independently by GNN. One remedy is to adopt an expressive pooling layer [117] over the representations learned by node GNN encoders. Note that node GNN encoders are inductive when each entity has its input features, but are not inductive for knowledge graphs without features.\nSubgraph GNN Encoders. Subgraph GNN encoders [250, 202] explicitly encode the subgraph enclosing each query triplet as its representation. Typically, these methods extract a h-hop subgraph around the query entities, label each entity with its distance to the query entities, and learn the representation of the subgraph with a GNN. Subgraph GNN encoders are proved to be more powerful than node GNN encoders [251], and can be naturally applied to the inductive setting [202]. However, subgraph GNN encoders require to materialize a subgraph for each link, which significantly restricts their scalability for large graphs.\nPath-based Methods. Path-based methods have a long history in the literature of rea-soning on graphs. Early methods on homogeneous graphs compute the similarity between two nodes based on the weighted count of paths (Katz index [106]), random walk probability (personalized PageRank [153]) or the length of the shortest path (graph distance [125]). All these methods define some handcrafted metrics over the full set of paths between two nodes, and can be efficiently solved via some polynomial algorithms (e.g. iterative fixed-point algo-rithm for PageRank [153], Bellman-Ford algorithm for graph distance [125]). SimRank [99] uses advanced metrics such as the expected meeting distance on homogeneous graphs, which is extended to heterogeneous graphs by PathSim [193].\nOn knowledge graphs, Path Ranking [122] directly uses relational paths between two entities as symbolic features for prediction. Given a query triplet, Path Ranking gener-ates a feature vector based on the number of each type of path. Such a feature vector can be viewed as a handcrafted representation for this pair of entities, and is fed into an SVM [42] to predict the likelihood of the query relation between the entity pair. Each type of path in Path Ranking can be interpreted as a probabilistic logical rule, weighted by the parameters learned by SVM."}, {"title": "2.2.2. Multi-hop Query Answering", "content": "We divide multi-hop query answering methods into two categories, neural methods and neural-symbolic methods, based on how they represent intermediate variables.\nNeural methods. Neural methods represent operations and intermediate variables in a query with learned embeddings. MPQE [50] learns a representation for the query graph using RGCN [176], and select the closest entity based on the cosine similarity between the query representation and entity embeddings. In [73], the authors proposed compositional training to train cascades of relation projections for answering path queries. Extending the query types to conjunctive queries (\u0245), GQE [76] learns a geometric intersection operator I to model conjunctions\n$I({q_1, ..., q_n}) = \\bigoplus_{i=1}^{n} WMLP(q_i)$ (2.7)\nwhere $q_i$ are the embeddings of partial queries involved in the conjunction, MLP is a multi-layer perceptron and \u2295 is a symmetric vector function (e.g. mean or min over a set of vectors) followed by a learnable transformation matrix W. Such an operator is known as DeepSets and is invariant to the permutation of its input [247]. Following GQE, later works try to inject more geometric inductive bias into logical operators to achieve better performance, such as Query2Box [167] and BetaE [168]. Query2Box [167] represents each intermediate variable as a high-dimensional box with a center embedding and an offset embedding, resulting in the following intersection operator\n$I({q_1, ..., q_n})^{center} = \\frac{\\sum_{i=1}^{n} \u03b1_i q^{center}_i}{\\sum_j \u03b1_j}$ (2.8)\n$I({q_1, ..., q_n})^{offset} = min(q^{offset}_1 ... q^{offset}_n) \\odot DeepSet({q_1, ..., q_n})$ (2.9)\nwhere \u2299 is element-wise multiplication,\u03c3(\u00b7) is the sigmoid function and DeepSet refers to the architecture in Equation 2.7. Query2Box aligns better with the intuition of conjunction, since intersection of boxes is always a box. To solve existential positive first-order (EPFO) queries (\u2203, \u2227, V), the authors rewrite them into disjunctive normal form (DNF), i.e. disjunction of conjunctive queries, where answers can be obtained by solving each conjunctive branch and merging the predictions. BetaE [168] further models negation operators and extends neural methods to first-order logic (FOL) queries (\u2203, \u2227, V, \u00ac) by parameterizing each intermediate variable with a Beta distribution.\nContrary to methods that process multi-hop queries step by step, CQD-CO [9] formulates multi-hop queries as a structure optimization problem and adopts pre-trained knowledge graph embeddings [207] to compute scores for each hop. Specifically, CQD-CO maximizes the following objective for embeddings of each variable $e_i$ in the query\n$argmax_{e_i \\in R^{k}}(\u03c3_{r_1}(h^1, e_1)T... T \u03c3_{r_{n_1}}(e_{n_1 - 1}, e_{n_1})) 1 ... 1 (\u03c3_{p_1}(h^d, e_q) T... T \u03c3_{r_{n_d}}(e_{n_d - 1}, e_{n_d}))$ (2.10)\nwhere $\u03c3_i (\u00b7,\u00b7) \u2208 [0, 1]$ is the score function for entity embeddings based on relation ri, and $h^i$ corresponds to the pre-trained embeddings of the constant entities given in the query. \u22a4 and \u22a5 are a t-norm and a t-conorm respectively, which are continuous generalization of boolean conjunction and disjunction for variables between [0, 1]. The embeddings of variables can be optimized via gradient-based methods, such as Adam [110], and the final answer can be obtained by replacing the target embedding with the pre-trained embeddings of all entities to maximize the objective.\nThere are some other works improving the design of logical operators in neural meth-ods. FuzzQE [35] leverages t-norm fuzzy logic to model FOL queries, which satisfies the axiomatic system of classical logic. Some recent works utilize advanced geometric embed-dings to achieve desired properties for operators, e.g. hyperboloid embeddings in HypE [37] and cone embeddings in ConE [259]. Generally, all these methods compute embeddings for intermediate variables without aligning them with entities in the knowledge graph, which limits their interpretability. Besides, these methods require entity embeddings and do not generalize to new knowledge structures.\nNeural-symbolic methods. Neural-symbolic methods adopt embeddings to model each hop in multi-hop queries, and meanwhile take the symbolic constraint of entity assignment into consideration, providing interpretability for intermediate variables. EmQL [192] simul-taneously maintains an embedding and a count-min sketch, i.e. a hash compression of a set of entities. To decode an intermediate variable or an answer, EmQL first finds the top-k entities with the highest dot product with the embedding, and then filters these entities using the sketch, which helps it to find answers logically entailed by the knowledge graph."}, {"title": "2.2.3. Reasoning over Natural Languages", "content": "Solving reasoning problems in natural language can be traced back to the bAbI bench-mark [226], which consists of many multi-step reasoning tasks that evaluate deduction, in-duction and other reasoning abilities. Early attempts to solve bAbI designed models to read and write a differentiable memory component when processing the input [227, 120]. With the rise of Transformer architecture [210] and later pretrained language models [161, 55, 162],"}, {"title": "3. Representation Learning for Generalizing to Unseen Entities", "content": "Knowledge graph reasoning has long been dominated by embedding methods due to their simplicity. However, embedding methods always have to be re-trained whenever the underlying knowledge graph is updated. While there are a few attempts [250, 202] on encoding local subgraphs for generalization to new entities, they are largely limited by their scalability. Is there an inductive, strong, yet scalable model that can substitute embedding methods in most scenarios?\nIn this chapter, we propose such a solution, NBFNet, by combining representation learn-ing with traditional path-based methods and dynamic programming. We further improve the scalability of NBFNet with a learned priority function in each iteration, resulting in A*Net. NBFNet achieved significantly better performance than embedding methods, and A*Net extended such an advantage to million-scale knowledge graphs. As of the year 2024, NBFNet remains a strong baseline in knowledge graph reasoning, and many of its insights, such as path representations and efficient computation via dynamic programming, continue to benefit various reasoning tasks."}, {"title": "3.2. Method: NBFNet", "content": "In this section, we first define a path formulation for link prediction. Our path formulation generalizes several traditional methods, and can be efficiently solved by the generalized Bellman-Ford algorithm. Then we propose Neural Bellman-Ford Networks to learn the path formulation with neural functions."}, {"title": "3.2.1. Path Formulation for Link Prediction", "content": "We consider the link prediction problem on both knowledge graphs and homogeneous graphs. A knowledge graph is denoted by $G = (V,E,R)$, where $V$ and $E$ represent the set of entities (nodes) and relations (edges) respectively, and $R$ is the set of relation types. We use $N(u)$ to denote the set of nodes connected to $u$, and $E(u)$ to denote the set of edges ending with node $u$. A homogeneous graph $G = (V, E)$ can be viewed as a special case of knowledge graphs, with only one relation type for all edges. Throughout this paper, we use bold terms, $w_q(e)$ or $h_q(u, v)$, to denote vector representations, and italic terms, $w_e$ or $w_{uv}$, to denote scalars like the weight of edge $(u, v)$ in homogeneous graphs or triplet $(u, r, v)$ in knowledge graphs. Without loss of generality, we derive our method based on knowledge graphs, while our method can also be applied to homogeneous graphs.\nPath Formulation. Link prediction is aimed at predicting the existence of a query relation q between a head entity u and a tail entity v. From a representation learning perspective, this requires to learn a pair representation $h_q(u, v)$, which captures the local subgraph structure between u and v w.r.t. the query relation q. In traditional methods, such a local structure is encoded by counting different types of random walks from u to v [122, 69]. Inspired by this construction, we formulate the pair representation as a generalized sum of path representations between u and v with a commutative summation operator. Each path representation $h_q(P)$ is defined as a generalized product of the edge representations in the path with the multiplication operator \u2297.\n$h_q(u, v) = \\bigoplus_{P_i \\in P_{uv}} h_q(P_1) \u2295 h_q(P_2) \u2295 ... h_q(P\\backslash P_{uv})$ (3.1)\n$h_q(P = (e_1, e_2, ..., e_{\\vert P \\vert})) = w_q(e_1) \\otimes w_q(e_2) ... w_q(e_{\\vert P \\vert}) = \\bigotimes_{i=1}^{\\vert P \\vert} w_q(e_i)$  (3.2)\nwhere $P_{uv}$ denotes the set of paths from u to v and $w_q(e_i)$ is the representation of edge $e_i$. Note the multiplication operator \u2297 is not required to be commutative (e.g. matrix multipli-cation), therefore we define \u2297 to compute the product following the exact order. Intuitively, the path formulation can be interpreted as a depth-first-search (DFS) algorithm, where one searches all possible paths from u to v, computes their representations (Equation 3.2) and"}, {"title": "3.4. Theories and Proofs", "content": "Here we demonstrate our path formulation is capable of modeling traditional link predic-tion methods like Katz index [106], personalized PageRank [153] and graph distance [125], as well as graph theory algorithms like widest path [16] and most reliable path [16].\nRecall the path formulation is defined as\n$h_q(u, v) = \\bigoplus_{P_i \\in P_{uv}} h_q(P_1) \u2295 h_q(P_2)\u2295 ...  h_q(P/P_{uv}) $ (3.1)\n$h_q(P = (e_1, c_2, ..., e_{\\vert P \\vert})) = w_q(e_1) \\otimes w_q(e_2) ...  w_q(e_{\\vert P \\vert}) = \\bigotimes_{i=1}^{\\vert P \\vert} w_q(e_i) $ (3.2)\nwhich can be written in the following compact form\n$h_q(u,v) = \\bigoplus_{P \\in P_{uv}} \\bigotimes_{i=1}^{\\vert P \\vert} w_q(e_i)$ (3.10)\nKatz Index. The Katz index for a pair of nodes u, v is defined as a weighted count of paths between u and v, penalized by an attenuation factor \u03b2 \u2208 (0,1). Formally, it can be written as\n$Katz(u, v) = \\sum_{t=1}^{\\infty} \u03b2^t e^T_u A^t e_v $ (3.11)\nwhere A denotes the adjacency matrix and $e_u, e_v$ denote the one-hot vector for nodes u, v respectively. The term $e^T_u A^t e_v$ counts all paths of length t between u, and v and shorter paths are assigned with larger weights.\nTheorem 3.1. Katz index is a path formulation with \u2295 = +, \u2297 = \u00d7 and $w_q(e) = \u03b2w_e$.\nProof. We show that Katz(u, v) can be transformed into a summation over all paths between u and v, where each path is represented by a product of damped edge weights in the"}, {"title": "3.4.2. Generalized Bellman-Ford Algorithm", "content": "First, we prove that the path formulation can be efficiently solved by the generalized Bellman-Ford algorithm when the operators (\u2295, \u2297) satisfy a semiring. Then, we show that traditional methods satisfy the semiring assumption and therefore can be solved by the generalized Bellman-Ford algorithm.\nPreliminaries on Semirings. Semirings are algebraic structures with two operators, sum-mation and multiplication, that share similar properties with the natural summation and the natural multiplication defined on integers. Specifically, \u2295 should be commutative, associative and have an identity element 0. should be associative and have an identity element"}]}