{"title": "Algorithmic Behaviors Across Regions: A Geolocation Audit of YouTube Search\nfor COVID-19 Misinformation between the United States and South Africa", "authors": ["Hayoung Jung", "Prerna Juneja", "Tanushree Mitra"], "abstract": "Despite being an integral tool for finding health-related infor-\nmation online, YouTube has faced criticism for disseminating\nCOVID-19 misinformation globally to its users. Yet, prior au-\ndit studies have predominantly investigated YouTube within\nthe Global North contexts, often overlooking the Global\nSouth. To address this gap, we conducted a comprehensive\n10-day geolocation-based audit on YouTube to compare the\nprevalence of COVID-19 misinformation in search results be-\ntween the United States (US) and South Africa (SA), the\ncountries heavily affected by the pandemic in the Global\nNorth and the Global South, respectively. For each country,\nwe selected 3 geolocations and placed sock-puppets, or bots\nemulating \"real\" users, that collected search results for 48\nsearch queries sorted by 4 search filters for 10 days, yield-\ning a dataset of 915K results. We found that 31.55% of the\ntop-10 search results contained COVID-19 misinformation.\nAmong the top-10 search results, bots in SA faced signifi-\ncantly more misinformative search results than their US coun-\nterparts. Overall, our study highlights the contrasting algo-\nrithmic behaviors of YouTube search between two countries,\nunderscoring the need for the platform to regulate algorithmic\nbehavior consistently across different regions of the Globe.", "sections": [{"title": "Introduction", "content": "\"This virus is here to stay. It is still killing and it is still\nchanging.\" - Ghebreyesus (2023), Director-General of the\nWorld Health Organization\n\nSince March 2020, the World Health Organization\n(WHO) has designated COVID-19 as a global pandemic.\nThe pandemic continues to pose a public health threat, regis-\ntering 206K COVID-19 cases and 3.5K deaths worldwide in\nJuly 2024 alone (WHO 2024). As the largest video search\nengine, YouTube has emerged as a vital tool for finding\nhealth-related information online, particularly during out-\nbreaks and global pandemics (Dubey et al. 2014; Bora et al.\n2018; Khatri et al. 2020). However, YouTube has faced crit-\nicism for disseminating COVID-19 misinformation globally\nto its users, with fact-checkers calling the platform a \"ma-\njor conduit of fake news\" (Milmo 2022). This misinforma-\ntion has undermined public health efforts worldwide, fuel-\ning vaccine hesitancy and eroding trust in health institutions\n(WHO 2022). Thus, there is a pressing need for empirical\ninvestigation into search engine systems to ensure algorith-\nmic accountability, safeguard global health, and promote a\nmore responsible, trustworthy web.\nIn response to public pressure, YouTube collaborated\nwith the WHO to develop a content moderation policy\nfor COVID-19 misinformation for their platform (Google\n2020). However, past reports expressed concerns that\nYouTube's content moderation practices are biased in fa-\nvor of the Global North and neglect the misinformation\nchallenges in the Global South, noting that YouTube does\nnot fact-check or remove videos in non-English languages\n(Nguyen and Scurato 2021; Grant 2022). While multiple\nprevious studies have empirically investigated search en-\ngines for COVID-19 misinformation in the Global North\ncontext (Papadamou et al. 2022; Kravets et al. 2023), the\nGlobal South has received little attention. The global aspect\nof the pandemic presents a unique and crucial opportunity\nto conduct a comparative audit of COVID-19 misinforma-\ntion in two different parts of the world.\nGuided by an overarching research question: What is the\nprevalence of COVID-19 misinformation in YouTube search\nresults between the US and SA?, we conducted a com-\nprehensive 10-day geolocation-based comparative audit of\nYouTube search from January 30th, 2023 to February 9th,\n2023. The goal of the audit was to compare the preva-\nlence of COVID-19 misinformation in Search Engine Result\nPages (SERPs) between the United States (US) and South\nAfrica (SA), the countries heavily affected by the pandemic\nin the Global North and the Global South, respectively. For\neach country, we selected 3 geolocations and placed sock-\npuppets (bots emulating real users) that collected YouTube\nSERPs for 48 search queries belonging to 8 globally persis-\ntent COVID-19 misinformation topics, such as \"Bill Gates\nClaims.\" To gain deeper insights into the platform's sorting\nalgorithm, we sorted the search results across 4 search fil-\nters: the default \u201cRelevance,\u201d \u201cUpload Date,\u201d \u201cView Count,\u201d\nand \"Rating,\" resulting in 915K search results. We scored\nthe videos based on their stance toward COVID-19 misinfor-\nmation and compared the amount of misinformation present\nin search results between the US and SA.\nWe find multiple instances where bots in SA encountered\nstatistically significantly more misinformative SERPs than\nbots in the US. These disparities were observed within the\ntop-10 search results (p<0.001, r=0.49) and search results\nsorted by YouTube's \"Relevance\" filter (p<0.001, r=0.86)\nwith medium to large effect sizes, indicating practical sig-\nnificance. Since 95% of user traffic is directed towards the\nfirst page of the search results (Kaye 2013) and YouTube\nemploys the \"Relevance\u201d filter by default, users in SA may\nlikely encounter significantly more misinformative SERPs\nthan users in the US. Given YouTube's established impor-\ntance for finding health information, this could raise per-\nsonal health risks for users in SA by potentially nega-\ntively influencing their beliefs, health practices, and deci-\nsions. Overall, our work highlights the contrasting algorith-\nmic behaviors of YouTube's search function in two countries\nwithin the context of COVID-19 misinformation, underscor-\ning the need for YouTube to regulate its algorithmic behav-\niors consistently across different regions of the Globe."}, {"title": "Related Work", "content": "Algorithmic Audits of Search Engines\nSearch engines determine what information is relevant and\nshape user behavior, impacting aspects such as political vot-\ning behavior (Diakopoulos et al. 2018), scientific knowledge\n(Papadamou et al. 2022), and beliefs (Knobloch-Westerwick\net al. 2015). Despite their societal importance, search en-\ngines operate without external regulation, leaving the cred-\nibility of the content unverified. Consequently, researchers\nhave investigated search systems by conducting algorithmic\naudits that empirically measure and understand the condi-\ntions in which problematic content arises on the platform.\nSeveral studies have investigated search engines for mis-\ninformation (Hussein et al. 2020; Papadamou et al. 2022;\nTomlein et al. 2021), conspiracy theories (Chen et al. 2023;\nFaddoul et al. 2020), hate speech and extremism (Albadi\net al. 2022; Ribeiro et al. 2020), and partisanship (Robert-\nson et al. 2018). Among the various methods to audit search\nengines, we utilize sock-puppet audits (programming bots\nto emulate real users), a methodology commonly employed\nin prior audits (Hussein et al. 2020; Papadamou et al. 2022;\nKliman-Silver et al. 2015) for its control over experimental\nvariables. Our study adds to the existing sock-puppet audit\nstudies, investigating the prevalence of COVID-19 misinfor-\nmation on YouTube between the US and SA.\n(Lack of) Algorithmic Audits in the Global South\nPrior works have highlighted the growing need to consider\nthe Global South in algorithmic audit research (Costanza-\nChock et al. 2022). In a recent paper, Urman et al. (2024) ar-\ngued that most algorithmic audit research is skewed towards\nthe Western context, noting that \u201ccountries located outside\nof North America and Western Europe are understudied.\"\nA limited number of studies have conducted algorithmic au-\ndits within the Global South context, examining factors such\nas language (Narain et al. 2023) and culture (Dammu et al.\n2024). Among these audits conducted in the Global South\ncontexts, only a few considered geolocation, with a vast ma-\njority focusing on Google Search (Le et al. 2022; Dabran-\nZivan et al. 2023). We contribute to the less-researched con-\ntext of the Global South and extend prior algorithmic audits\non YouTube, the largest video search engine.\nSearch-Enabled COVID-19 Misinformation\nGiven the importance of search engines for finding health-\nrelated information during the COVID-19 pandemic (Kha-\ntri et al. 2020), several scholars have audited search en-\ngines for COVID-19 misinformation (Li et al. 2020; Kravets\net al. 2023; Papadamou et al. 2022) and anti-vaccine con-\ntent (Juneja et al. 2021; Papadamou et al. 2022). In addi-\ntion, researchers have engineered various features and built"}, {"title": "Audit Experiment Setup", "content": "This section presents the methodology for selecting geolo-\ncations for our audit experiments, curating globally persis-\ntent COVID-19 misinformation topics and associated search\nqueries, and designing our experimental setup.\nSelecting the Geolocations for the Audit\nWe considered the US and SA because they were heavily af-\nfected by the pandemic in the Global North and the Global\nSouth, respectively, making them vulnerable to COVID-\n19 misinformation (WHO 2024). Previous work estab-\nlished that Google personalizes search results across differ-\nent states in the US (Kliman-Silver et al. 2015). Therefore,\nwe chose to identify three states in each country to achieve\na more robust analysis of COVID-19 misinformation in\nYouTube search results of the selected countries. We iden-\ntified three states in the US and three provinces in South\nAfrica with the highest total confirmed cases of COVID-\n19 (Adeline et al. 2020; Wits University 2023), which may\nmake them susceptible to COVID-19 misinformation. To\ncapture the highest proportion of the population in these\nstates and provinces, we selected the largest populated city\nas the geolocation. For US, we selected Los Angeles (Cal-\nifornia), Houston (Texas), and Jacksonville (Florida). For\nSouth Africa, we selected Johannesburg (Gauteng), Durban\n(KwaZulu-Natal), and Cape Town (Western Cape). Figure 1\ndepicts the geolocations chosen in the US and SA.\nCurating Topics and Search Queries\nCurating COVID-19 Misinformation Topics. To cu-\nrate globally persistent COVID-19 misinformation topics,\nwe partnered with expert fact-checkers at Pesacheck. As\nAfrica's largest indigenous fact-checking organization, Pe-\nsaCheck is affiliated with the International Fact-Checking\nNetwork (ICFN) and collaborates with expert fact-checkers\nworldwide. Since our audit study investigates both SA and\nthe US, our partnership enabled us to incorporate their ex-\npertise on the COVID-19 misinformation widely circulat-\ning globally into our study. Utilizing editorial coverages\nand frequent fact-checking, the expert fact-checkers iden-\ntified 8 globally persistent COVID-19 misinformation top-\nics, providing a dataset of 362 YouTube videos related to\nthese topics. Please refer to Appendix Table 4 for the sam-\nple YouTube videos provided by PesaCheck. These videos\noriginate from channels associated with 29 countries span-\nning the Global North and the Global South (See Appendix\nTable 3). Table 1 presents the 8 topics and samples of our\ncurated search queries, which we explain next.\nCurating Search Queries. We utilized three methods to\ncurate search queries for each topic. Given that English is the\nonly language spoken commonly in both the US and SA,\nwe focused on queries in English, thus enabling a controlled\ncross-country comparison in the amount of COVID-19 mis-\ninformation returned by YouTube's search algorithm.\nFirst, we utilized YouTube video tags in the videos pro-\nvided by Pesacheck. Video tags are descriptive keywords\nrepresenting how content creators want their videos to be\ndiscovered (Google 2022). Misinformative videos often con-\ntain tags describing misleading narratives, effectively serv-\ning as potential search queries for identifying more misin-\nformative videos (Juneja et al. 2023). We collected 2,911\nvideo tags from the videos and applied systematic filter-\ning criteria employed in prior work (Juneja et al. 2021).\nWe excluded queries mentioning individuals or news orga-\nnizations (e.g., \"Obama\", \"Republic TV\u201d), overly generic\nterms (e.g., \"breaking news\"), excessively specific terms\n(e.g., \"COVID3rdWaveInMyanmar\"), and irrelevant terms"}, {"title": "Audit Experiment Design", "content": "Overview. To host our experiments, we used Amazon\nWeb Services (AWS) to create all the virtual machines\n(VMs). We programmed Selenium bots (Patra 2020) to em-\nulate real-world users and automate browser actions. To ob-\nscure the automated interactions of the bots, we followed the\nsuggestions from Klimek (2021). Each bot utilized IPRoyal\nproxies (IPRoyal 2023) and validated the IP geolocation of\nthe proxy using IP2Location, an IP geolocation lookup ser-\nvice (IP2Location 2023), to obtain personalized search re-\nsults from the desired IP geolocation. For each query, we\ncollected YouTube SERPs sorted by 4 search filters: \"Rele-\nvance,\" \"Upload Date,\u201d \u201cView Count,\u201d and \u201cRating.\" During\nthe data collection, we extracted the top 50 search results\nfrom each SERP. Additionally, we added wait times after\nevery browser action and chose two evenly separate times to\ndistribute our search queries throughout the day to avoid get-\nting rate-limited by YouTube. We ran the audit experiment\nfor 10 consecutive days from January 30th, 2023 to Febru-\nary 9th, 2023, where we simultaneously searched 24 queries\nat 00:00 UTC and the other 24 queries at 12:00 UTC.\nTo control for possible confounding factors that may af-\nfect our audit, we followed standard noise control proce-\ndures based on prior work (Kliman-Silver et al. 2015; Hus-\nsein et al. 2020; Juneja et al. 2021). To differentiate between\nnoise and geolocation-based personalization in SERPs, we\ncreated identical twin bots, consisting of a treatment bot and\nits corresponding control bot that conducted the same ac-\ntions simultaneously at each geolocation. Thus, any differ-\nence in the search results between the twin bots should be\nattributed to noise rather than personalization. If the dif-\nferences in the SERPs between two geolocations exceeded\nthe noise, it can only be attributed to geolocation-based per-\nsonalization. In our experiment, we placed twin bots at each\ngeolocation, resulting in 12 bots.\nValidation Experiments. Changing IP addresses using\nVMs (Hussein et al. 2020) and proxies (Boeker et al. 2022)\nare common methods to conduct geolocation audits, espe-\ncially in the US context. However, obtaining fine-grained\ncoverage of IP addresses through VMs and proxy services\nin South Africa was challenging. The only AWS cover-\nage in South Africa, let alone in Africa, is in Cape Town.\nMeanwhile, nearly all the proxy and VPN providers except\nIPRoyal were unfeasible due to the steep pricing or the lack\nof proxy coverage of our selected geolocations in South\nAfrica (see Appendix Table 6 for further details). Due to\nchallenges associated with IP addresses, we initially turned\nto the \"geospoofing\u201d method used in Kliman-Silver et al.\n(2015), in which they fed precise latitude and longitude co-\nordinate information to automated scripts and obtained per-\nsonalized search results, providing a cost-effective alterna-\ntive. For brevity, we summarized the results from our vali-\ndation experiments and left the details in the Appendix. We\ndefined the metric for geolocation-based personalization in\nAppendix B. In our first validation experiment, we curated\na set of search queries and validated that the queries elicited\ngeolocation-based personalization, resulting in personalized\nSERPs based on geolocation (Appendix C). Using the vali-\ndated search queries, we performed a second validation ex-\nperiment and found that YouTube uses IP geolocation in-\nstead of geospoofed location to personalize search results\n(Appendix D). Thus, we conducted a third validation exper-\niment using IPRoyal proxies, which validated the accuracy\nand consistency of the proxies in giving us the correct IP\ngeolocations for our experiment (Appendix E)."}, {"title": "Developing Data Annotation Scheme", "content": "Our geolocation audit experiment collected 23,020 SERPs\nconsisting of 915,440 search results (10,139 unique videos).\nTo label these videos for COVID-19 misinformation, we un-\nderwent extensive procedures to determine what constitutes\nmisinformation and develop the qualitative coding scheme.\nHow do we know what is misinformation?\nTo determine what constitutes misinformation, we based our\nannotation heuristics on Google's COVID-19 medical mis-\ninformation policy, which has been developed in partnership\nwith the WHO (Google 2020). We also referenced the poli-\ncies of national health authorities in the US and SA, such\nas the Center for Disease Control and Prevention (CDC)\n(CDC 2023) and the South African Government's COVID-\n19 Fake News resources (South African Government 2023).\nGiven the misleading nature of xenophobic terms such as\n\"Kungflu\u201d and \u201cChina Virus,\u201d we also incorporated them in\nour annotation heuristics. Additionally, we took extra pre-\ncautions in annotating videos about the COVID-19 Lab Leak\nTheory by referencing a declassified report from the US\nNational Intelligence Council, which presented the consen-\nsus by various government agencies (ODNI 2023). The re-\nport assessed that both the Natural Origins Theory and the\nLab Leak Theory are plausible until more evidence comes\nto light. However, the report also debunked many mislead-\ning claims, such as COVID-19 being a biological weapon\ndeveloped in a lab. Thus, we did not label videos as misin-\nformative for discussing the origin theories about the virus\n(such videos were labeled as \"On the COVID-19 origins in\nWuhan, China\" see Appendix Table 7); however, we la-\nbeled videos as misinformative if they promoted debunked\nand misleading claims outlined in the report.\nAnnotation Scale and Heuristics\nDeveloping the qualitative coding scheme to label YouTube\nvideos for COVID-19 misinformation was challenging, re-\nquiring multiple iterations and discussions with external re-\nsearchers to refine the heuristics. In the first iteration, the\nfirst author sampled 80 videos from the audit experiment\nand annotated the videos. After multiple iterations analyzing\neach video, the author created an initial 7-point annotation\nscale: \"Opposing COVID-19 Misinformation (-1),\u201d \u201cNeu-\ntral COVID-19 Information (0),", "Supporting COVID-19\nMisinformation (1)\u201d, \u201cOn the COVID-19 origins in Wuhan,\nChina (2),": "Irrelevant (3),\u201d \u201cVideo in a language other than\nEnglish (4),"}, {"title": "Labeling YouTube Videos", "content": "After developing our data annotation scheme, we labeled the\nvideos. Given the large amounts of data (10,139 videos), we\nscaled the labeling process using a machine-learning clas-\nsifier for English videos. We constructed the ground-truth\ndataset, trained and evaluated 62 different classifiers, and\nseparately handled videos in non-English languages.\nCreating the Ground-Truth Dataset\nWe obtained annotations for 3,075 videos, which were an-\nnotated by the first author and Amazon Mechanical Turk\n(AMT). The first author, as the expert, annotated 1,087\nvideos . For 1,988 videos, we obtained three AMT worker\nannotations per video. To assess the AMT workers' agree-\nment, we calculated the Fleiss' Kappa Score and obtained\n\u03ba = 0.62, indicating \u201csubstantial agreement.\" We employed\nthe majority response to assign the final label, arriving at a\nfinal label for 1,899 videos. For the remaining 89 videos, all\nthree AMT worker responses diverged. The first author an-\nnotated the 89 videos to obtain the final annotation values. In\n\u00a711, we address the steps to minimize potential harm asso-\nciated with exposing AMT workers to misinformation. See\nAppendix F for the AMT worker training, screening, com-\npensation, and annotation task. Overall, the ground-truth\ndataset consisted of 3,075 videos, 820 of which were sup-\nporting, 837 opposing, 431 neutral, 409 irrelevant, 317 non-\nEnglish, 228 on COVID-19 origins, and 33 URLs not acces-\nsible. To train our classifier, we excluded videos annotated\nas non-English and URL not accessible.\nTraining and Applying Classifier to English Videos\nUsing the ground-truth dataset, we trained 62 different clas-\nsifiers to find the best-performing model for our task.\nConsolidating from 5-classes to 3-classes. Developing a\nclassifier to detect COVID-19 misinformation in YouTube\nvideos was difficult, requiring experimentation with several\nmodels. Initially, we trained classifiers that predicted five\nclasses: opposing, supporting, neutral, COVID-19 origins,\nand irrelevant. Such a model could only achieve an accu-\nracy of 0.71. We sought to improve our classifier's accu-\nracy by reducing the number of classes, while maintain-\ning our study's objective of measuring the level of COVID-\n19 misinformation in YouTube SERPs. Thus, we merged\nthe classes neutral, irrelevant, and COVID-19 origins into\na single category as these classes neither support nor op-\npose COVID-19 misinformation. This consolidation yielded\na classification task with 3-classes: supporting misinforma-\ntion, opposing misinformation, and neither.\""}, {"title": "Handling Videos in Non-English Languages", "content": "Our classifier, trained exclusively on English videos, was ap-\nplied only to annotate English videos within the remaining\nunlabeled portion of the dataset. Non-English videos were\nmanually annotated separately. To identify non-English\nvideos in the remaining dataset, we employed two tools:\nGoogle Translate's Language Detection API (Google 2023)\nand langdetect library to predict the language of the video\nbased on text-based metadata such as the title. For videos\nflagged as non-English by any of the tools, we manually\nverified to confirm the video's language. After identifying\nnon-English videos in the remaining dataset, we merged\nthem with the 317 non-English videos from the ground-\ntruth dataset, totaling 784 confirmed non-English videos in\nthe entire dataset. We manually annotated each video using\nGoogle Translate and referenced external researchers at our\ninstitution fluent in the respective languages."}, {"title": "Quantifying Misinformation Bias", "content": "To quantify the misinformation present in YouTube SERPs,\nwe adopted the misinformation bias score metric developed\nby Hussein et al. (2020). The score determines the misin-\nformation bias in a ranked list, giving more weight to the\nannotation labels of higher-ranked videos in the calculation:\n$\n\\Sigma_{r=1}^{n}(x*(n-r+1))\n$, where x represents the annotation label\nof the video, r represents the ranking of the video, and n\nrepresents the total number of videos in the SERP. To con-\nform to the video annotation scale in Hussein et al. (2020),\nwe mapped our 3-class labels from \u00a75 to a normalized scale\nof -1, 0, and 1 based on their stance towards COVID-19\nmisinformation. Videos that oppose COVID-19 misinforma-\ntion were assigned scores of -1, while those supporting it re-\nceived a score of 1. However, videos that fell into the merged\ncategory, including irrelevant, neutral, and COVID-19 ori-\ngins labels, do not support nor oppose COVID-19 misinfor-\nmation. Thus, they received a score of 0. Therefore, the\nmisinformation bias score of a SERP is a continuous value\nranging from -1 (all videos oppose misinformation) to +1\n(all videos support misinformation). A positive score indi-\ncates a lean toward misinformation, while a negative score\nindicates a lean toward content opposing misinformation. A\nscore of 0 suggests a set of content that neither supports nor\nopposes misinformation. A higher score suggests a higher\nprevalence of misinformation in the SERP."}, {"title": "Results", "content": "Here, we compare the prevalence of misinformation in\nYouTube SERPs across geolocations, topics, and filters. A\ntest of normality revealed that our data is not normal. Thus,\nwe used the non-parametric Mann-Whitney U Test for pair-\nwise comparisons and Kruskal-Wallis tests, followed by the\npost-hoc Conover-Iman tests with Bonferroni adjustment for\nmultiple comparisons. We provide comprehensive details of"}, {"title": "Misinformation Bias across Geolocations", "content": "Figure 2 displays the distribution of the mean misinforma-\ntion bias scores for the top-10 to top-50 videos in SERPs be-\ntween geolocations in the US and SA. To get the mean mis-\ninformation bias scores, we computed the bias scores con-\nsidering the top-N videos in the SERPs, averaging across all\nqueries, filters, and bots at a particular geolocation.\nAmong the top-N videos, the top-10 videos in the SERPs\nhave the highest misinformation bias scores. We observed\nthat the top-10 videos in the SERPs have the highest misin-\nformation bias scores for both the US and SA (see Figure 2).\nThis suggests that misinformative content is more prevalent\nin top-10 search results than lower-ranked results. Within the\ntop-10 search results, we observed that nearly a third of the\ncontents were misinformative: 31.55% of the search results\nsupported COVID-19 misinformation, 36.03% were oppos-\ning, and 32.42% belonged to the remaining classes.\nBots in SA encountered significantly more misinforma-\ntive SERPs than bots in the US for both the top-10 and\ntop-20 search results. For the top-10 videos, the effect size\nr was 0.49 (see Appendix Table 9), indicating a \"medium\neffect\" (Cohen 1988). This effect size indicates that our ob-\nserved differences moderately carry practical significance,\nsuggesting that geolocation influences the algorithmic be-\nhaviors of YouTube search in our case, resulting in statis-\ntically significantly more misinformative SERPs in SA com-\npared to the US. We discuss the potential implications of the"}, {"title": "Misinformation Bias Within Each Country", "content": "How do the geolocations within each country influence the\nprevalence of misinformation in YouTube SERPs? To an-\nswer, we conducted a Kruskal-Wallis H Test to examine dif-\nferences in misinformation bias scores across geolocations\nwithin each country. The test revealed a significant differ-\nence for US geolocations (KW H(2, N=30)=6.98, p<0.01,\n\u03b7\u00b2=0.18), but no significant difference within SA. The large\neffect size for the US (\u03b7\u00b2=0.18) (Tomczak et al. 2014) sug-\ngests that the observed differences carry practical signifi-\ncance, indicating that geolocation may influence the preva-\nlence of misinformation in YouTube SERPs in the US. We\nconducted a post-hoc Conover-Iman test with Bonferroni\nadjustment, revealing that bots in Houston received a higher\nprevalence of misinformation in their search results than in\nLos Angeles. We discuss the implications in \u00a78."}, {"title": "Misinformation Bias in Topics", "content": "Figure 3 shows the mean misinformation bias scores and the\nMann-Whitney U Test results between the US and SA across"}, {"title": "Misinformation Bias in Search Filters", "content": "Figure 5 depicts the mean misinformation bias scores and\nthe Mann-Whitney U Test results between the US and SA\nacross 4 search filters.\nBoth \"Upload Date\u201d and \u201cRating\u201d filters showed posi-\ntive scores in both countries. This indicates that SERPs\nsorted for highly rated (more likes than dislikes) or newly\nuploaded videos lean towards misinformative content. Our\nfindings suggest that highly rated and newly uploaded videos\ntend to feature misinformation. This observation suggests\nthat YouTube may not prioritize its content moderation ef-\nforts toward recently uploaded or highly rated videos.\nIn contrast, \"Relevance\" and \"View Count\" filters\nshowed negative bias scores in both countries. This sug-\ngests that SERPs sorted by relevant or most-viewed videos\nlean towards opposing misinformation. This may suggest\nthat YouTube's content moderation efforts prioritize relevant\nand highly viewed videos, which are likely to be surfaced by\nthe search engine or have gained viewer attention.\nBots in SA received significantly more misinformative\nSERPs than bots in the US when sorting the result by\n\"Relevance.\" As shown in Figure 5, the effect size of r=0.86\nindicates a large effect, suggesting that users in SA may en-\ncounter more misinformative SERPs than their US counter-\nparts when using the default \"Relevance\u201d filter.\nIn contrast, bots in the US received significantly more\nmisinformative SERPs than those in SA when results\nwere sorted by \"Rating.\" The effect size r=0.48 indicates a\nmedium effect. While this effect size is not as pronounced as\nwhen sorting by \"Relevance\" (r=0.86), it suggests that the\nobserved differences have moderate practical significance.\nIt is important to note that YouTube's default filter is \"Rele-\nvance,\" suggesting that users are more likely to engage with\nSERPs sorted by this criterion. Consequently, the observed\ndifferences with the \u201cRating\u201d filter may have a lesser impact\non users compared to the \u201cRelevance\u201d filter, where bots in\nSA received significantly more misinformative SERPs than\nbots in the US."}, {"title": "Discussion", "content": "COVID-19 Misinformation on YouTube: Auditing\nYouTube's search engine for COVID-19 misinformation\nis urgently needed to ensure algorithmic accountability", "Biological Weapon\" and \"Lab Leak\nTheory\" were consistently contaminated with COVID-19\nmisinformation across all search filters in both countries\n(Figure 4). These results indicate the problematic and global\nnature of these misinformation topics, highlighting the ur-\ngent need for YouTube to enhance its content moderation in\nthese areas. On the other hand, topics \"5G Claims,\" \"Spread\nof Virus,\" and \"Vaccine Content Claims\" contained oppos-\ning search results across all filters in both countries. This\nfinding may be attributed to YouTube's content modera-\ntion policies and its commitment to reducing misinformative\ncontent relating to 5G conspiracy, vaccines, and informa-\ntion that contradicts medical authorities (Hern 2020; Pruitt-\nYoung 2021; Google 2020). Overall, our study suggests that\nwhile YouTube may be successful in moderating content on\nsome topics, it still has considerable work to do in moderat-\ning COVID-19 misinformation in its search engine.\nMisinformation in Emerging and Highly-Rated Content": "nWe observed an alarming trend in both countries for certain\nfilters such as \"Upload Date\" and \"Rating.\" As illustrated\nin Figure 5, the misinformation bias scores were positive\nfor these filters, indicating that emerging and highly rated\nvideos tend to feature misinformation. This is problematic,\nas users may place trust in videos highly rated by others, and\nusers seeking the latest information about the pandemic may\nbe at heightened risk of encountering misinformation. On\nAugust 25th, 2023, the European Union's Digital Services\nAct went into effect, placing responsibility on online search\nengines, including YouTube, for the misinformative content\non the platforms (European Commission 2023). In light of\nthese regulations, our study provides valuable insights for\nYouTube to enhance its content moderation practices, espe-\ncially in addressing emerging or highly rated content that\nmay contribute to the spread of COVID-19 misinformation\nand, consequently, impact public health.\nContrasting Alg"}]}