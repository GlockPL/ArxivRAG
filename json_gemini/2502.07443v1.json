{"title": "Approximating Human Strategic Reasoning with LLM-Enhanced Recursive Reasoners Leveraging Multi-agent Hypergames", "authors": ["Vince Trencsenyi", "Agnieszka Menselt", "Kostas Stathis"], "abstract": "LLM-driven multi-agent-based simulations have been gaining traction with applications in game-theoretic and social simulations. While most implementations seek to exploit or evaluate LLM-agentic reasoning, they often do so with a weak notion of agency and simplified architectures. We implement a role-based multi-agent strategic interaction framework tailored to sophisticated recursive reasoners, providing the means for systematic in-depth development and evaluation of strategic reasoning. Our game environment is governed by the umpire responsible for facilitating games, from matchmaking through move validation to environment management. Players incorporate state-of-the-art LLMs in their decision mechanism, relying on a formal hypergame-based model of hierarchical beliefs. We use one-shot, 2-player beauty contests to evaluate the recursive reasoning capabilities of the latest LLMs, providing a comparison to an established baseline model from economics and data from human experiments. Furthermore, we introduce the foundations of an alternative semantic measure of reasoning to the k-level theory. Our experiments show that artificial reasoners can outperform the baseline model in terms of both approximating human behaviour and reaching the optimal solution.", "sections": [{"title": "1 Introduction", "content": "Multi-agent systems provide environments for individual-based modelling and simulations [28]. Game theory and multi-agent-based simulation (MABS) have established a mutually beneficial relationship: MAS leverages game-theoretic interaction models and strategic tools [31], and game theory relies on multi-agent-based social simulations to investigate strategic decision-making [36]. Large language models (LLMs) have received particular interest in their potential to simulate human-like reasoning and decision-making, and MABS frameworks are used to evaluate LLM capabilities in game-theoretic environments [17]. Traditional approaches often rely on simplified agent frameworks implemented with a weaker concept of agency [45], which may impose limitations on the system's"}, {"title": "2 Background", "content": "adaptability and the agent's reasoning sophistication. In contrast, our approach involves a stronger, modular agent concept enabling a decoupled investigation of reasoning processes. Our agents are hosted in a role-based multi-agent framework governed by an umpire who manages game environments and facilitates agent interactions.\nWe focus on beauty contest games, a well-established concept for studying recursive reasoning [10]. We evaluate the reasoning capabilities of LLM-enhanced agents, integrating recursive reasoning via a formal hypergame representation. Our experiments compare the performance of LLM-enhanced agents against both a baseline economic model and human data, providing insights into the models' ability to approximate human strategic behaviour. Furthermore, we introduce a self-evaluation method \u03ba, a revised measure of reasoning depth that complements traditional k-level theory, offering a more nuanced understanding of reasoning sophistication.\nOur key contributions include:\n-A flexible multi-agent-based simulation platform capable of hosting a wide array of reasoners, offering a detailed view of reasoning processes;\n-LLM-enhanced agents that leverage a hypergame-based model for recursive reasoning;\n-Introduction of k, a complementary measure to k-level reasoning;\n-Experiments comparing our LLM-based reasoners to the baseline model and human data.\nOur results suggest that artificial reasoners can benefit from the expanded architectural complexity and can not only match but potentially outperform baseline models in both approximating human behaviour and achieving optimal solutions in strategic settings."}, {"title": "2.1 Game Theory", "content": "Game theory provides a mathematical framework for analyzing decision-making in multi-agent \u2013 human or artificial \u2013 strategic interactions [30]. A game is formally defined by its players, their available strategies, and utility functions that evaluate the players' outcomes [33]. Beauty contest games (BCGs) provide an experimental testbed for iterative reasoning, where players have to guess a number which they believe will be the closest to the mean of all guesses weighted by a parameter p [10]. BCGs are a popular choice for studies concerning the k-level theory, as optimal play requires thinking about others' thoughts: given the range [0,100] and p =3, 0-level players pick 50 and level-k thinkers choose $50p^k$. Experimental evidence consistently shows that most human players exhibit 1st or 2nd-level reasoning, with few advancing beyond level 3 [29,14,7].\nHypergames extend standard game theory by modelling individual player perspectives, allowing hypergame models to capture misaligned perceptions [4]."}, {"title": "2.2 Language Models", "content": "Large language models (LLMs) are sophisticated neural networks - usually based on the transformers architecture [15] and a pre-trained model on a vast amount of data [32] - that target natural language processing applications [48]. Chain-of-thought (CoT) prompting is a technique that improves LLMs reasoning capabilities by having LLMs decompose complex tasks into smaller problems [42]. Such prompts can be demonstrative examples showcasing what the expected response may pertain to and/or descriptive instructions that guide the model on reaching the expected response [46].\nClaude 3.5 Claude 3.5 is a family of state-of-the-art LLM models from Anthropic, supporting multimodal applications [3]. In this work, we evaluate two Claude models: Sonnet offers large context windows and advanced analytical capabilities, suitable for complex tasks and process automation; Haiku is a smaller, cost-efficient, fast model targeting interactive and sub-agent tasks.\nGPT-4 GPT-4 is OpenAI's SOTA system supporting multimodal input and output and a long context window arming models with a broad general knowledge and advanced problem-solving abilities [1]. We implement two models: GPT-40 possesses a generally high reasoning performance across various benchmarks; 40-mini is a lightweight variant for resource-constrained environments."}, {"title": "2.3 Recursive Reasoning", "content": "We describe recursive reasoning as an agent's ability to reason about each other's physical and cognitive states [44]. The cognitive hierarchy model introduced the concept of k-level thinkers, proposing that players engage in different levels of strategic thinking, where players on level k best respond to k - 1 level strategies, assuming every other player must be at most at level k 1 [10]. Epistemic game theory is a branch of game theory which provides a formal mathematical framework for representing and operating with belief hierarchies [11]. Hypergame theory aims to analyse conflict under asymmetric information and misaligned perceptions [5], providing a game-oriented representation of sequential beliefs."}, {"title": "LLM Reasoners in Multi-level Hypergames", "content": "Multi-level hypergames provide a formalized model of hierarchical games representing nested beliefs [40]. A third-level hypergame between players i, j, is a composite structure of lower-level hypergames representing individual players' perspectives: $H\u00b3 {H2, H3}$, where $H = {H, H}}$ and $H = {Hj, Hji}$. Finally, $Hoji = Giji$ is i's perceptual game defining player i's belief of j's belief of i's perspective of G. This theoretical framework provides the foundation for studying how agents engage in recursive strategic reasoning and form hierarchical beliefs about others' decision-making processes."}, {"title": "3 Multi-agent Simulation via Centralized Hypergames", "content": "Our simulations are materialized in game environments composed of and hosting an umpire, a set of players, and a set of hypergames. We revise hierarchical hypergames from [40] to integrate 2-player BCGs as individual perceptual games capturing the agent's beliefs and reasoning level."}, {"title": "3.1 Perceptual Beauty Contest Games", "content": "In our framework, we define BCGs formally as $G = (N, A, U, \u03a8)$, where $N = i, j$ is the set of two players, $A = A\u00a1 \u00d7 Aj$ is the action space, where $Ai, A; CZ$ represent the available actions for players i and j respectively, $U : A \u2192 R\u00b2$ is the utility function, where for each player: $U\u017c(ai, aj) = \u2212|ai - p\u00b7 \u03bc|$, with $\u03bc = \\frac{ai+aj}{2}$ and p as the BCG's scalar parameter and $I = (\u03c8\u2081 = \u03c3, \u03c82, ..., \u03ba)$ is an ordered sequence of a number of perspectives, where the first component 41 denotes the interpreter (creator) of the game perspective, \u03c3. \u03a4\u03bf help position player beliefs in our BCGs in the context of belief hierarchies, we suggest simplifying assumptions as follows. Given \u0430\u043a = 2 level reasoner i, \u03b2i(\u03b2j(\u03b2k)) [11] corresponds to i's beliefs about player j's beliefs about player k's reasoning. Then we assume \u03b2i(\u03b2j(\u03b2k)) = Gijk, where Gijk is the perceptual game capturing the same beliefs, with subscripts denoting the sequential order of perspectives: i's reconstruction of G based on his beliefs about j's beliefs of k's perspective. However, the rigorous analysis of the proposed relationship is beyond the scope of this work. Finally, the set of individual perceptual games invokes the hypergame H\u043a, capturing both players' beliefs, where at least one of the players exhibits the highest level of reasoning \u03ba."}, {"title": "3.2 Recursive Reasoners", "content": "Agents in our framework are implemented following the standard intelligent agent architecture [34] and inspired by the Observe-Orient-Decide-Act decision-making model [8,38] as shown on Figure 1a. An iteration of the game environment comprises the umpire's matchmaking activities and the players' reasoning processes. Given the space of natural language game descriptions X, the umpire v sends game requests to each pair of players to participate in G* = ({i, j}, {Ai, Aj }, U, (v)). In the facilitated games, the umpire is a passive participant a pseudoplayer [33].\nEach player's reasoning processes are then decoupled and defined as follows:\n-The player's revision module - Figure 1b processes the game description, reasons about what the opponent's move could be, and constructs a perceptual game. These steps are integrated into an interpretation function I : G \u00d7 N \u2192 G', that creates an instance of G reflecting the player's beliefs:\n\u2022 \u03c1 : X \u2192 \u039e, R is the reasoning function: p(x) = \u03be\u2081$, a$j where \u03be\u2081 \u2208 \u039e is i's natural language reasoning based on game description x \u2208 X on what the opponent j's guess \u00e1; is expected to be;"}, {"title": "LLM Reasoners in Multi-level Hypergames", "content": "\u2022 \u03c6: \u039e\u2192 N is the reasoning analysis function: \u03c6(\u03bei) = \u03ba, where is the player's estimated reasoning level based on the number of nested beliefs present in the reasoning \u00a7i;\n\u2022 i's perceptual game is then: Gi...k = (i, {i, j}, A,U,\u03a8 = (\u03c8i,..., \u03c8\u03ba)).\nThe decision module selects an action based on the revised expectation:\n\u2022 \u03b4: R \u2192 A\u00bf is the decision function selecting i's preferred action a based on the expected opponent guess: \u03b4(aj) = a;\nWhile k-levels are derived from players' numerical choices, \u03ba provides an alternative measure based on the explicit reasoning steps we observe in players' natural language explanations. These reasoning steps are represented as perspectives in the perceptual game G, allowing us to analyze the depth of strategic thinking through players' own articulation of their decision process."}, {"title": "3.3 Model Prompting Design", "content": "We integrate CoT prompting into our multi-step reasoning process across the agent's revise and decide phases. During revise, the LLM mind processes information through sequential steps: first reasoning about the situation to predict opponent guesses, then analyzing the reasoning depth to determine \u03ba, resulting in the kth order perceptual game. The mind's decision function then interprets this processed information to derive the final guess, completing the multi-step reasoning process. LLM prompts follow a modular structure: (1) optional agent profile for context-specific reasoning [25], (2) role and task definition, (3) game/task specific request, and (4) implementation-specific requirements (e.g., \u201csurround the chosen number in curly brackets: n\").\""}, {"title": "3.4 Baseline Model", "content": "The self-tuning experience weighted attraction model (EWA) is a benchmark model for reproducing human-like strategic interaction in game-theoretic experiments [18].\n$A(t) = \\frac{\u2022 N(t \u2212 1). A (t \u2212 1) + [8 + (1 \u2212 \u03b4) \u00b7 I(s, S_i(t))]\u00b7 \u03c0_i(s, s_i(t))}{N(t \u2212 1)\u00b7 \u00b7 (1 \u2014 \u03ba)}$\nEquation 1 defines player i's associated attention to strategy j at time (or round) t, where\n$\\pi_i(s^j, s_i(t))$ denotes i's payoff for choosing strategy j against si at time t;\nN is the experience weight $N(t) = (1 \u2212 \u03ba) \u00b7 \u0444\u00b7 N(t \u2212 1) + 1$ [9];\n$ is the change detector function $(t) = 1 \u2212 S_i(t)$;\nthe surprise index is denoted by $S_i(t) = \\sum_{i=1}^t (\\frac{r(t) - \\overline{r(t)}}{N(t)})^2$ with r(t) = I(ski, si(t)) and $\\overline{r(t)} = \\frac{\\sum_{i=1}^t r_i(t)}{N(t)}$;\n$\\d_{ij}$ is the weight to foregone payoffs: $\\delta_{ij} (t) =  { 1 if is, si(t)) \u2265 \u03c0i(t),\n0 otherwise.$;\nand I(x, y) is an index function returning 0 if x = y and 1 otherwise.\nLett 0 denote the agent's initial state. We then define the initial attraction A (0) according to the cognitive hierarchy model and the Poission distribution function $P(k) = \\frac{e^{-TTk}}{k!}$ [10] and set N(0) = 1. The self-tuning EWA model was trained and tested on a 7-player beauty contest with p = 0.7 and p = 0.9 [19], for which Ho et al. determined x = 2.39 for the sensitivity of the response function and T = 1.5 for deriving the first-period plays via the CHM-derived Poisson distribution. We adopt these parameters in our experiments without further tuning. Finally, agents choose an action according to P(t + 1) = $\\frac{\u0395\u03bb.\u0391 (1)}{mix(t)}."}, {"title": "4 Experiments", "content": "We use beauty contest games as the test bench for evaluating our agents' recursive reasoning capabilities, as guessing games are closely associated with k-level reasoning [10]. In this context, k level reasoners best respond to the k 1 level players' choices and at k = 0 players choose randomly. In order to classify players by their reasoning, we adopt the guess-based conversion approach presented in [29]. We assume level 0 reasoners choose 50; then we set each kth reasoning level at 50pk. More specifically, we use 2-player BCGs to conduct our evaluation. In n-player BCGs, reasoners eliminate weakly dominated strategies iteratively which process can be extended to infinity until the theoretical solution of everyone choosing 0 is reached [10]. The two-player game provides a simpler solution concept, where the smaller number wins [16]. Zero is a weakly dominated"}, {"title": "LLM Reasoners in Multi-level Hypergames", "content": "strategy that always wins, which, in theory, significantly simplifies the iterative reasoning process.\nWe evaluate our agents on the experiment from [16], involving 132 student participants, pooled from first-year students with no prior game-theoretic training nor existing familiarity with beauty contests and 130 professionals with extensive game-theoretic domain knowledge.\nIn the first instance, we replayed the 2-player beauty contests using the original experiment design, simulating 25 independent rounds with each LLM. Additionally, we conducted 60 rounds with pairs of agents using the EWA model as the benchmark. Artificial agents were provided with a description worded similarly to what human participants would be given - however, obfuscated to mitigate reliance on game-theoretic analyses in the models' training data -, without any explicit instructions on their reasoning and decision-making. Providing a persona description as context pushes the LLM to behave in the desired way by guiding the reasoning process according to the profile specification [25]. Similarly, in the second set of experiments, we expand our prompting mechanism with an agent profile, allowing us to specify the level of domain knowledge the agent should use for its reasoning. Following the original group descriptions from [16], we ran 15-15 games with the specifications of \"first years students with no game-theoretic knowledge\" and \"professors with expert domain knowledge in game theory\" with Claude 3.5 Haiku and GPT-40 - chosen based on their proximity to the human performance and the optimal strategy, 0."}, {"title": "LLM Reasoners in Multi-level Hypergames", "content": "results of the second experiment, where player profiles are successfully integrated into both agents' reasoning processes. Similar to the human groups with different levels of domain expertise, the models acting as students performed noticeably poorer than the models that were described as professionals. However, while 9.85% of human students and 36.02% of human professionals managed to reach 0, none of the artificial reasoners nor the baseline model - chose the optimal strategy in either experiment. Most studies concentrate on BCGs involving more than 2 players, where 0 is not an obvious solution to the game. This bias is likely inherently present in the LLMs training data, potentially tainting the information used to generate reasoning in the 2-player BCG.\nK-level reasoning provides another metric for comparing human and artificial agents' thought processes. Table 1 reinterprets the mean results through k-level classifications, showing that while humans exhibit 1st-level reasoning, only Claude 3.5 Haiku produced comparable results. Other models performed at the 2nd and 3rd levels, with EWA and GPT-40 approaching level 4 reasoning. Additionally, the \"Mean k\" and \"Median \u03ba\" columns report the LLM agents' reasoning steps involved, corresponding to perspectives in their perceptual games.\nThe second experiment revealed that the estimated k and K levels are aligned with the expectation that reasoners with domain expertise would outperform and exhibit a higher order of reasoning than non-professionals. While \u03ba can provide a semantics-backed estimate of the reasoning steps involved in the process, it does not yet tell us much about the quality of the agent's reasoning. The results suggest that a semantic qualitative reasoning classification may complement the current numerically defined measures."}, {"title": "5 Related Work", "content": "The recent emergence of LLM agents [39] and LLM-MAS [22] has influenced social simulations. Multi-agent strategic interactions are used to evaluate LLM reasoning [27,13], and LLM-based simulations are leveraged for empirical investigations on strategic behaviours [25,26]. Recent work on LLM-driven reasoning in BCGs focuses on studying agent rationality and reasoning levels [47,24,17]. Centralized role-based architectures rely on an umpire [35] or a game manager [21] to coordinate game-based interactions - such as artificial trading [43] or utility markets [23,49]. Hypergame theory, while effective for analyzing complex conflicts post-hoc [5], has seen limited practical application [6] due to challenges in automation. Most agent-based implementations only borrow conceptually [12,2], with few examples of full integration [20,37].\nWhile prior approaches typically implement a looser agentic concept \u2013 a weaker notion of agency [45] \u2013 potentially constraining the system's flexibility and bounding LLMs' reasoning [41], our framework offers enhanced flexibility and depth. Our conceptually elaborate multi-agent architecture enables a more nuanced evaluation process, facilitating a systematic review of LLM reasoning and automating the generation of hypergames. This approach provides valuable insights into LLMs' capabilities for recursive reasoning, particularly their ability to form beliefs about beliefs and develop a theory of mind."}, {"title": "6 Conclusions and Future Work", "content": "We present a MABS framework integrating hypergames for multi-level reasoning in BCGs. Our contributions are threefold. First, we introduce a flexible multi-agent simulation platform capable of hosting both simple models like the self-tuning EWA and sophisticated multi-step reasoners powered by state-of-the-art LLMs. The platform's architecture emphasizes a strong notion of agency,"}]}