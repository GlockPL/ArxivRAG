{"title": "KIPPS: Knowledge infusion in Privacy Preserving Synthetic Data Generation", "authors": ["Anantaa Kotal", "Anupam Joshi"], "abstract": "The rapid evolution of Machine Learning (ML) has led to a large number of applications across diverse domains. The success of ML models lies in the availability of large volumes of data to train on. Since data is siloed in many areas like healthcare and cybersecurity, this requires data to be shared across sites to create a model that is not narrow and brittle. The necessity for sharing data raises significant questions on data privacy and confidentiality. In many domains, data sharing is regulated or outright prohibited, impacting the success of ML models. One approach to this problem is Federated learning, but it has its limitations. An alternate approach is synthetic data generation, which is a scalable and practical solution for privacy-preserving data sharing. It allows organizations to collaborate on research and analysis without compromising sensitive information. Generative Deep Learning models have proven instrumental in addressing privacy concerns by generating synthetic data that retains statistical characteristics while concealing individual details. The integration of privacy measures, including differential privacy techniques, ensures a provable privacy guarantee for the synthetic data. However, challenges arise for Generative Deep Learning models when tasked with generating realistic data, especially in critical domains such as Cybersecurity and Healthcare. Generative Models optimized for continuous data struggle to model discrete and non-Gaussian features that have domain constraints. Challenges increase when the training datasets are limited and not diverse. In such cases, generative models create synthetic data that repeats sensitive features, which is a privacy risk. Moreover, generative models face difficulties comprehending attribute constraints in specialized domains. This leads to the generation of unrealistic data that impacts downstream accuracy. To address these issues, this paper proposes a novel model, KIPPS that infuses Domain and Regulatory Knowledge from Knowledge Graphs into Generative Deep Learning models for enhanced Privacy Preserving Synthetic data generation. The novel framework augments the training of generative models with supplementary context about attribute values and enforces domain constraints during training. This added guidance enhances the model's capacity to generate realistic and domain-compliant synthetic data. The proposed model is evaluated on real-world datasets, specifically in the domains of Cybersecurity and Healthcare, where domain constraints and rules add to the complexity of the data. Our experiments evaluate the privacy resilience and downstream accuracy of the model against benchmark methods, demonstrating its effectiveness in addressing the balance between privacy preservation and data accuracy in complex domains.", "sections": [{"title": "I. INTRODUCTION", "content": "Data is a crucial asset in the information age, profoundly af-fecting many aspects of modern society. As technologies fordata mining and data analytics advance, the potential valueof data become more apparent. Businesses and organizationsrecognized that data, when properly leveraged, could yieldvaluable insights, drive informed decision-making, and offera competitive advantage. The rapid evolution of machinelearning models further intensified the value and demand fordata across diverse domains. Machine learning relies heavilyon large and diverse datasets for training models effectively.More data allows these models to learn intricate patterns,improve accuracy, and generalize well to new situations.As machine learning applications continue to expand acrossvarious industries, the quality and quantity of data play acrucial role in the success of these models.While the availability of data is crucial, particularly in thecontext of machine learning, it also gives rise to potentialrisks to the privacy of individuals. Organizations, driven bythe desire to extract valuable insights from vast datasets,often gather crucial but sensitive information. This practicehas raised concerns on how individual privacy is compro-mised in the process. The recognition of these concernshas prompted a growing emphasis on data privacy, leadingto the establishment of regulations like the General DataProtection Regulation (GDPR). These regulations sets forthguidelines and standards for the protection of personal data,making it a legal necessity for organizations to comply withthe privacy rules. As the need for data privacy becomesmore urgent, there is increasing effort to develop privacy-preserving measures for data sharing. Privacy-preservingtechniques involve the implementation of methods that alloworganizations to extract meaningful information from datawithout compromising the identity or sensitive details ofindividuals. These measures aim to strike a balance betweenretaining data utility and safeguarding privacy.Synthetic data generation stands out as a crucial solutionin the face of growing concerns about privacy. Rather thansharing raw, identifiable data, organizations can generatesynthetic samples that retain the overall structure and pat-terns of the data. This allows collaborative research andanalysis without the need to expose sensitive information.Generative Deep Learning has emerged as a powerful toolfor enhancing privacy in various applications, addressingconcerns related to data security and confidentiality. The ap-plication of Generative models, particularly in the context ofprivacy, revolves around its ability to generate synthetic data.By using generative models, like Generative AdversarialNetworks (GANs), researchers and organizations can createsynthetic datasets that maintain the statistical characteristics of the original data without revealing specific details about individuals. This facilitates the development andtesting of machine learning models without compromisingprivacy. The incorporation of privacy measures, such as theintegration of differential privacy techniques with GenerativeDeep Learning, offers an additional layer of protection andprovides a provable privacy guarantee.While Generative Deep Learning offers promising solu-tions for privacy preservation in the realm of images and text,it encounters challenges when tasked with generating realis-tic tabular data, such as for Cybersecurity, Healthcare etc. Generative Adversarial Networks (GANs) are designedfor continuous Gaussian distributions and encounter diffi-culties when faced with discrete features and non-gaussianfeatures. Most datasets in domains such as Cybersecurityand Healthcare contain a mix of discrete and non-gaussianfeatures, posing difficulties for these models. The challengeis amplified due to the lack of diverse datasets for trainingGenerative Models. Generative models, trained on limiteddata, have visibility of only a subset of the possible featurevalues. Consequently, during synthesis, they can onlyproduce those limited values. As a result, the synthetic data isless diverse and poses a privacy risk as it contains repetitionsof features that may be sensitive. Furthermore, the possiblevalues of discrete features in such datasets is often very high.This increases the complexity of generative models whichis directly proportional to the range size of discrete values.Consider the example of network activity data generation,where one of the significant attributes is IP address. The IPaddress in the training data is limited and the entire actualrange of IP address is enormous. The model training onthe limited data capture has narrow scope of view and thecomplexity of modeling the entire range of values is veryhigh and infeasible.Moreover, the scarcity of data poses a challenge forgenerative models in comprehending attribute constraintsimposed by the domain. Datasets in specialised domainsoften contain specific meanings and relationships betweenattribute values, which are challenging for these models todeduce from limited training data. For instance, in networkactivity data, specific protocols correlate with particular portnumbers, and an incorrect pairing is not just improbable butinaccurate. Generative models may fail to explicitly capturethese constraints, leading to the generation of unrealistic datathat is distinguishable from the original. This discrepancycan misguide downstream tasks, like classifiers distinguish-ing between legitimate and anomalous behavior. Going backto the example of network activity data, IP addresses havespecial meanings and associated constraints. For example,a DNS lookup request can only go from the Home IPto the Gateway Server IP, never the otherway round. Thisinformation is not explicit to the generative model from thetraining data.To address these challenges, it is essential to providethe generative models with added context about the domain. Thedomain knowledge provides additional information attributevalues and ranges, and awareness of domain-specific patternsor constraints. This domain specific context enhances thegenerative models ability to interpret data meaningfully.In this study, we introduce a novel framework, KIPPS,"}, {"title": "II. Background", "content": "In addressing data privacy challenges, strategies like dataanonymization, secure cryptographic methods, and dis-tributed model release have been used, but each has lim-itations. Data anonymization, a common technique, canbe compromised with future information, and secure cryp-tographic methods restrict open access to data [8]-[11].Synthetic data generation emerges as a promising solution,offering a practical way to share data while preservingprivacy. This approach creates entirely new datasets withoutreal individual associations. In critical fields like healthcareand security, where micro-data is essential, synthetic datageneration ensures reliable conclusions. These methods try tomaintain the inherent properties of the original dataset, thusenabling the use of synthetic data as replacement in down-stream tasks with minimal cost to accuracy. This providesa cost-effective, scalable alternative that encourages datasharing, reduces privacy costs, and enables collaboration.Generative Adversarial Networks (GANs) are a powerfulclass of Generative Deep Learning models widely recognizedfor their success in creating synthetic data closely resemblingthe original dataset. GANs excel in generating high-fidelitysynthetic data, particularly in image and text domains [1],[2], [12], [13]. In real-world domains like Cybersecurityand Healthcare, traditional GANs encounter challenges. Thedata in these domains is typically tabular, containing bothdiscrete and continuous values. Generating realistic tabulardata poses difficulties in modeling complex relationshipsand diverse value ranges, rendering GANs less effectivecompared to their success with continuous and image-baseddatasets. In the 2019 paper by Xu et al. [14], the authorproposes a GAN model to address the challenges with tabulardata. Specifically, they address the issues of multi-modalityand non-gaussian nature of continuous variables and classimbalance in tabular data. In the 2021 paper by Kotal etal. [15], further used this model to create a frameworkfor privacy preserving data generation in tabular data. Theauthors enforce t-closeness in the generated data to theoriginal dataset to preserve privacy.However, generative models are not sufficient by itself inguaranteeing privacy. We need strong mathematical foun-dation for the privacy guaranteed through this process.Differential Privacy provides provable privacy guarantee for a randomized algorithm. As a practical and imple-mentable method of differential privacy Dwork et al. [10]propose noise addition to true output. Differential privacyprovides the mathematical foundation for ensuring privacyin any algorithmic setting. Differential Privacy StochasticGradient Descent (DP-SGD), introduced by Abadi et al.[16], is a privacy-preserving deep learning algorithm thatblends stochastic gradient descent (SGD) principles withdifferential privacy. The NIST-winning Probability GraphicalModels framework [17] utilizes a graphical model assump-tion for data distribution, employing parametric and non-parametric techniques to estimate parameters maximizingentropy. PrivBayes [18] is a privacy-preserving data gener-ation method using Bayesian networks with binary nodes.Abay et al. [19] propose an autoencoder-based data syn-thesis method, partitioning a sensitive dataset into label-based groups. Building on Abadi et al.'s work [16], variousGAN models have been proposed that combine DifferentialPrivacy Stochastic Gradient Descent (DP-SGD) with Gener-ative Adversarial Networks (GANs) to generate differentiallyprivate synthetic data [20], [21]. These models introducenoise into the GAN's discriminator during the trainingprocess to enforce differential privacy. The crucial aspectof DP's guarantee of post-processing privacy means that bysafeguarding the GAN's discriminator, it ensures differentialprivacy for the parameters of the GAN's generator.However, GANs continue to face challenges, specificallyin generating synthetic tabular data for domains with limitedtraining data availability leading and strict domain con-straints. Limited view of discrete value attributes, complex-ity of attribute ranges and conditional constraints of theattributes make it harder for the GANs to model the dataaccurately and pose significant privacy risks. We discuss thechallenges with privacy preserving synthetic data generationusing GAN further in Section III. We propose that domainknowledge can provide the added context needed to train thegenerative model for alleviating these challenges."}, {"title": "B. Knowledge Guided Learning", "content": "Generative Adversarial Networks (GANs) trained solely onobserved tabular data encounter limitations in comprehend-ing intricate attribute relationships, such as the interplaybetween categorical variables or the constraints govern-ing certain feature combinations. For instance, in tabulardatasets, specific attributes may adhere to predefined rulesor correlations, such as the acceptable range of values forcategorical variables or the permissible combinations offeatures. Without explicit guidance, GANs lack the inherentability to conform to these rules, potentially leading to thegeneration of synthetic data that deviates from the estab-lished constraints.In domains where data adherence to predefined rulesis paramount, such as Cybersecurity and Healthcare, in-corporating domain knowledge becomes indispensable. Byleveraging knowledge guidance techniques, we can explic-itly convey these constraints to the generative model. Thisprocess equips the model with the necessary contextualunderstanding to generate synthetic data that adheres to theestablished rules and preserves the realism and integrityrequired for accurate analysis within the observed system.Knowledge Graphs (KG) serve as a versatile graph-structured data model designed for knowledge representationand reasoning. Within a KG, information is organized intosemantic triples, consisting of a subject, predicate, andobject. Subjects and objects correspond to nodes or entitiesin the graph, while predicates denote the functional relation-ships between them. The graph-like structure of KGs allowsfor the efficient storage of extensive information, and the net-work can be expanded with new knowledge as required. KGSare equipped with powerful reasoning capabilities, enablingthe imposition of constraints on entities and the deduction ofnew knowledge. For instance, specifying constraints such asthe source IPs must not belong to a subnet or must originatefrom a specific external CIDR range. Leveraging these robustknowledge representation and reasoning abilities, KGs canenhance and enrich the data generation process.Knowledge graphs excel at storing contextual informa-tion crucial for enhancing learning in distributed systems.The Unified Cybersecurity Ontology (UCO) stands out as acomprehensive ontology designed for cyber situationalawareness in cybersecurity systems. Its integration has beendemonstrated to significantly improve contextual awarenessin machine learning (ML) systems, as evidenced by studiessuch as those by Piplai et al. [22] and Narayanan et al. [23].In a related context, Hui et al. [24] have introduceda knowledge-enhanced Generative Adversarial Network(GAN) designed to generate Internet of Things (IoT) trafficdata for devices from various manufacturers. Their approachhowever is specific to IoT traffic and uses knowledge injec-tion to set the conditions for IoT traffic generation. In thispaper, we inject knowledge about network traffic into thetraining of the GAN by adding the Knowledge base as anindependent discriminator."}, {"title": "III. Objective and Proposed Method", "content": "Generative models have shown remarkable success in du-plicating datasets, yet challenges persist when it comes togenerating synthetic tabular data. This discussion exploresthree main problems faced by generative models in thiscontext.1) Limited diversity in training data One significantchallenge is the limited availability of data in thetraining set, offering an incomplete view of attributes.This is particularly problematic for discrete attributeswhere the training data may only cover a subset ofpossible values. Consider a practical scenario in a Net-work activity dataset, where the available IP addressesare both limited and private. This restricted viewexcludes a broader spectrum of valid IPs. Generativedeep learning models, when trained on such data, tendto replicate only the discrete values observed duringtraining. This is a privacy risk as the specific value ofthe IPs are considered sensitive. In spite of the privacypreserving measure, the risk of re-identification is notremoved as the sensitive attribute value is repeated inthe synthetic data. To truly anonymize the dataset, weneed to allow the generative model to consider otherpossible values of the sensitive attribute.2) Complexity of Discrete Attributes Generative modelsfor tabular data categorize attributes as either contin-uous or discrete. The complexity of the generativ"}]}