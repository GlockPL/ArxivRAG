{"title": "Consent in Crisis: The Rapid Decline of the AI Data Commons", "authors": ["Shayne Longpre", "Robert Mahari", "Ariel Lee", "Campbell Lund", "Hamidah Oderinwale", "William Brannon", "Nayan Saxena", "Naana Obeng-Marnu", "Tobin South", "Cole Hunter", "Kevin Klyman", "Christopher Klamm", "Hailey Schoelkopf", "Nikhil Singh", "Manuel Cherep", "Ahmad Mustafa Anis", "An Dinh", "Caroline Chitongo", "Da Yin", "Damien Sileo", "Deividas Mataciunas", "Diganta Misra", "Emad Alghamdi", "Enrico Shippole", "Jianguo Zhang", "Joanna Materzynska", "Kun Qian", "Kush Tiwary", "Lester Miranda", "Manan Dey", "Minnie Liang", "Mohammed Hamdy", "Niklas Muennighoff", "Seonghyeon Ye", "Seungone Kim", "Shrestha Mohanty", "Vipul Gupta", "Vivek Sharma", "Vu Minh Chien", "Xuhui Zhou", "Yizhi Li", "Caiming Xiong", "Luis Villa", "Stella Biderman", "Hanlin Li", "Daphne Ippolito", "Sara Hooker", "Jad Kabbara", "Sandy Pentland"], "abstract": "General-purpose artificial intelligence (AI) systems are built on massive swathes of public web data, assembled into corpora such as C4, RefinedWeb, and Dolma. To our knowledge, we conduct the first, large-scale, longitudinal audit of the consent protocols for the web domains underlying AI training corpora. Our audit of 14,000 web domains provides an expansive view of crawlable web data and how consent preferences to use it are changing over time. We observe a proliferation of AI-specific clauses to limit use, acute differences in restrictions on AI developers, as well as general inconsistencies between websites' expressed intentions in their Terms of Service and their robots.txt. We diagnose these as symptoms of ineffective web protocols, not designed to cope with the widespread re-purposing of the internet for AI. Our longitudinal analyses show that in a single year (2023-2024) there has been a rapid crescendo of data restrictions from web sources, rendering ~5%+ of all tokens in C4, or 28%+ of the most actively maintained, critical sources in C4, fully restricted from use. For Terms of Service crawling restrictions, a full 45% of C4 is now restricted. If respected or enforced, these restrictions are rapidly biasing the diversity, freshness, and scaling laws for general-purpose AI systems. We hope to illustrate the emerging crisis in data consent, foreclosing much of the open web, not only for commercial AI, but non-commercial AI and academic purposes.", "sections": [{"title": "Introduction", "content": "The web has become the primary communal source of data, or \u201cdata commons\u201d, for general-purpose and multi-modal AI systems. The scale and heterogeneity of web-sourced training datasets provide the foundation for both open and closed AI systems, such as OLMo [42], GPT-40 [85], and Gemini [115]. However, the use of web content for AI poses ethical and legal challenges to data consent, attribution, copyright, and the potential impact on creative industries [35, 62, 94, 128]. This has spurred new initiatives to better verify data quality and provenance [34, 32, 55, 66, 11], isolate public domain and permissively licensed data [77], and integrate new infrastructure to signal [31], detect [112], and even evade the use of data for AI training [108].\n\nThe focus of this work is to understand the evolving role of the internet as a primary ingredient to AI, and how AI has collided with the limited protocols that govern data use. Web data is traditionally collected using web crawlers-automatic bots that systematically explore the internet and record what they see. However, the mechanisms for indicating restrictions to web crawlers, such as the Robots Exclusion Protocol (REP), were not designed with AI in mind [92]. As such, we examine their (in)ability to communicate the nuances in how content creators wish their work to be used, if at all, for AI. And more broadly, we analyze how AI is already re-shaping the culture of web consent, and how this is shifting the landscape for AI training data. Our results foretell significant changes not only to AI data collection practices, and data scaling laws, but also the structure of consent on the open web, that will impact more than AI developers.\n\nTo this end, we present a large-scale audit of the web sources underlying three open AI training corpora: C4 [98], RefinedWeb [90], and Dolma [111]. In contrast to prior audits, that assess datasets-curated snapshots of data-this work looks beneath the datasets, at the web domains they were derived from, and traces the temporal evolution of these sources. We are, to our knowledge, the first to systematically measure detailed provenance, crawler consent mechanisms, and content monetization factors, all relevant to the responsible downstream use of this data. These analyses enable us to trace fundamental distribution shifts in how preference signals are expressed and the inadequacy of existing tools. Our work has several key findings:"}, {"title": "Methodology", "content": "AI models that are highly performant on tasks in language [98], images [132, 37, 4], video [7, 76, 79], and even audio [64, 26] increasingly depend on massive web-sourced training datasets. These datasets are collected using web crawlers-agents that navigate the web, accessing and retrieving web pages without human intervention. While these robots are essential for a variety of applications, including search engines, studying the internet (ie archiving), and link verification tools; recently they have also become the backbone of AI training data collection [97, 16].\n\nIn our study, we focus on three popular, open-source, and permissively licensed data sources which are derived from Common Crawl, the largest publicly available crawl of the web, which has collected and stored hundreds of billions of web pages since 2008. For each web-based data source, we sample the web domains from which it was created, and extensively human annotate their properties. Our analysis examines a snapshot of the present, as well as longitudinal changes across time, to understand how ecosystem norms have evolved.\n\nData sources The data sources used for our study are C4 [98], RefinedWeb [90], and Dolma [111]. These data sources each have 100k-1M+ downloads, are the primary component in most modern foundation models [16, 42, 14], as well as being widely used to derive other popular datasets [130, 118, 116]. Common Crawl is released on a monthly basis, and, as see in Table 1, each data source is based on a different set of monthly snapshots. Each of these corpora apply various automatic filtering techniques, including removing duplicative pages, low-quality content, and personal identifiable information such as addresses.\n\nHead sample and random sample For each data source, we identified and selected the top 2k web domains ranked by their number of tokens. We refer to the resulting 3.95k union of these web domains as HEADAll. This sample represents the largest, most actively maintained, and critical domains for AI training. For certain analyses, we consider only the head of C4, which we will refer to as HEADC4.\n\nWe are also interested in how attitudes toward consent have evolved within a wider sample of internet domains. To capture this, we randomly sampled 10K domains (RANDOM10k) from the intersection of the three corpora, totalling 10,136,147 domains. From the 10k sample, we selected a random subset of 2K for human annotation (RANDOM2k). RANDOM10k was sampled from the intersection of domains listed across all three datasets, which means this subset may skew towards more widely-used or high-quality domains.\n\nHuman annotations We trained annotators to manually label the websites for their content modalities (e.g. video, text); website purpose(s) (e.g. news, e-commerce); presence of paywalls and embedded advertisements; the text of the terms of service, if any; and other metadata detailed in Table 2. Annotators received individual instructions, frequent quality calibration, and were compensated well above industry standards at $25-$30 per hour. We collected annotations for the entirety of HEADAll as well as from the random sample RANDOM2k. More details on our annotation process are available in Appendix A, and all annotations will be made publicly available for reproducibility and future research."}, {"title": "Findings", "content": "Web domains are adopting robots.txt and Terms of Service pages to signal preferences.  shows from 2016, the portion of web domains in HEADC4 without a robots.txt and Terms of Service has gone from 20% and 80% respectively, to near zero. This reflects an emerging adoption of these practices to signal and protect data intentions.\n\nRobots.txt crawling restrictions have risen precipitously since mid-2023.  shows the rapid re-distribution of robots.txt restrictions, directly after the introduction of GPTBot and Google-Extended crawler agents. This re-distribution to full restrictions mainly comes from websites with previously moderate restrictions, such as disallowed directories, pattern-based or search page restrictions, and partly from websites with no prior restrictions in their robots.txt.\n\nAcross the entire corpora, ~1% of C4, RefinedWeb, and Dolma tokens were restricted in mid 2023, as compared to 5-7% of tokens in April 2024. Among the most critical domains (HEADAll), 20-33% of all tokens are restricted, as compared to <3% one year prior (Figure 2a). From a relative perspective, from 2023-4 to 2024-4 these restrictions have risen 500%+ for both C4 and RefinedWeb's full corpus,\n\nAI developers are restricted at widely varying degrees.  breaks down the restrictions by AI developers and non-profit organizations. OpenAI crawlers are restricted for 25.9% of tokens in HEADC4, followed by Anthropic and Common Crawl (13.3%), Google's AI crawler (9.8%), and more distantly Cohere (4.9%), Meta (4.1%), the Internet Archive (3.2%), and lastly Google Search's crawler (1.0%). These asymmetries in restrictions have significant differences, and tend to advantage less widely known AI developers. In Subsection 3.2 we discuss these asymmetries and their consequences in more depth.\n\nTerms of Service pages have imposed more anti-crawling and now anti-AI restrictions.  illustrates this gradual re-composition of Terms pages\u2014with web domains shifting from no terms pages, to those with restrictions on crawling, commercial-use, using the data for competing services, or re-distribution. Only in 2024 do we see the wider emergence of Terms which specifically mention and restrict the use of their data for generative AI. In the last year, we've seen a 26-53% relative increase in Terms of Service crawling restrictions across C4, RefinedWeb, and Dolma. Figure 2c shows 45-55% of all tokens in these three corpora have a form of data use restriction in their Terms pages. In practice, most automatic crawlers do not heed these Terms, though they may provide some avenue of legal enforcement\n\nAI restrictions are driven primarily by news, forums, and social media websites. For robots.txt, Figure 2b shows nearly 45% of all News website tokens are fully restricted in HEADAll, as compared to 3% in 2023. For Terms of Service, Figure 2d shows News website tokens have had a 6% rise in the restricted portion since 2023. Paired with the findings in Table 2, this suggests that the composition of tokens in crawls respecting robots.txt may shift away from news, social media, and forums, and towards organization and e-commerce websites.\n\nForecasting trends in the future suggest a continued and significant decline in open and consenting web data sources. SARIMA forecasts suggest that for just the next year (by April 2025) an additional absolute 2-4% of C4, RefinedWeb, and Dolma tokens will be fully restricted by robots.txt."}, {"title": "Inconsistent and Ineffective Communication on AI Consent", "content": "In many cases, data holders fail to effectively communicate their preferences on how their data is used by AI systems. We observe robots.txt instructions which allow some AI organizations to crawl while restricting others, references to non-existent crawlers, and contradictions between the robots.txt and Terms of Service. Together, these issues point to the need for better preference signaling protocols.\n\nSome AI crawlers are allowed, while others are not. We find not all AI agents are disallowed equally. In Table 3 we estimate the conditional probabilities of each organization's crawler being restricted, conditioned on whether any other AI organization is restricted. Whereas OpenAI and Common Crawl agents are frequently disallowed (in 91.5% and 83.4% of cases where any of the organizations are disallowed), the agents of other AI companies, such as Google, Cohere, and Meta are often omitted from robots.txt. The omissions of Cohere, Meta, and other small AI organizations are likely because website administrators are unaware or unable to update their robots.txt to reflect the full list of AI developers. On the other hand, the particularly high omission rates of Internet Archive and Google Search suggest web administrators may be open to more traditional crawler uses like archiving and search engines, even as they seek to restrict AI usage. A full confusion matrix showing the correlation between restrictions for each user agent is provided in Appendix Figure 5.\n\nUnrecognized crawler agents cause incorrect specifications. We find several instances where robots.txt refer to user agents that the companies do not recognize. For instance, 4.5% of websites disallowed the unrecognized user agents ANTHROPIC-AI or CLAUDE-WEB (documented as FALSE ANTHROPIC), but not the documented agent for Anthropic's crawler, CLAUDEBOT. The origin and reason for these unrecognized agents remains unclear\u2014Anthropic reports no ownership of these. These inconsistencies and omissions across AI agents suggest that a significant burden is placed on the domain creator to understand evolving agent specifications across (a growing number of) developers. Al crawler standardization could address these challenges in consent signaling.\n\nContradictions exist between robots.txt and ToS. The Robots Exclusion Protocol (REP) is a guideline for web crawlers, while a website's Terms of Service is a legal agreement between the"}, {"title": "Correlating Features of Web Data", "content": "What does web data actually look like? Prior work has measured the characteristics of web-derived datasets, for the presence of artifacts [34, 66], undesirable text and images [69, 11], demographic biases [32], and quality discrepancies across languages [22]. We expand upon these analyses by measuring what web data sources look like before they have been neatly processed into AI training datasets. We measure the presence of multi-modal content, user-derived content, website monetization schemes, and sensitive content on the most well-represented web domains on the internet (HEADAll) and on a random sample of domains (RANDOM2k). We also annotate the services provided and purpose of each web domain.\n\nMost of the web is comprised of organizational/personal websites, and blogs, however the head distribution is disproportionately news, forums, and encyclopedias. Table 4 shows several notable and statistically significant differences between head distribution (HEADAll) and tail distribution (RANDOM2k) of web domains. HEADAll is comprised mostly of news, and social media/forums, and encyclopedias (72.9%), in contrast to the long tail data in RANDOM2k, which is dominated by personal or organization websites, blogs and E-commerce sites (97%). Academic and government content is also proportionately higher in the head distribution. Note however that though they are all derived from Common Crawl snapshots, C4, RefinedWeb, and Dolma, all show variations in their source compositions\u2014highlighting the importance of curation choices.\n\nThe head distribution of domains is more multimodal, and heavily monetized. We observe that HEADAll web domains are much more heavily monetized through ads (+47.5%) and paywalls (+24.1%). Accordingly, they also have significantly greater restrictions from both robots.txt (+22.5%) and Terms of Service (+35.3%). This monetization and restrictions likely correspond to the higher quality and heterogeneity of content usually produced by news, periodicals, forums, and databases which are more common in HEADAll. This is reflected by the higher proportions of image (+4.4%), video (+39.8%), and audio content (+38.4%) than the rest of the web. Interestingly, the fraction of user-generated content and sensitive content between the head and tail distributions is less pronounced. Crawlers that respect the restrictions that occur far more frequently in HEADAll will increasingly lose access to the most multi-modal, highly curated, and up-to-date content sources."}, {"title": "Misalignment between Real-world AI Usage and Web Data", "content": "In this section, we measure the degree of alignment between real world uses of ChatGPT and the content in the webcrawls that form the bulk of AI training. For each web domain in HEADAll, we had annotators label the services provided by the website, as well as the presence of some monetization, such as a paywall or automatic ads. We compare these services against the services that real-world users solicit in their interactions with conversational AI systems. We use WildChat, a recent set of 1 million user conversations with ChatGPT [131], collected through a HuggingFace Space wrapper around OpenAI services. We randomly sampled 100 conversation logs from WildChat, which the paper authors manually clustered by the type of tasks or goals conveyed by each conversation, with the goal of relating the core function of these conversations with the services provided by the websites crawled in training. Subsequently, we used GPT-40 to label 1k randomly selected conversations from the WildChat dataset; these conversations were labelled using the taxonomy we developed to categorize websites. Further details on the taxonomy and labelling procedure can be found in Appendix B.6.\n\nApparent uses of ChatGPT are misaligned with the popular web domains language models are trained on. Figure 4(a) shows the distribution of services provided by the web domains, broken down by whether those domains are monetized. In contrast, Figure 4(b) shows how ChatGPT is used in the real world. The way that users interact with ChatGPT is different in important ways from the types of content that is most frequently represented in publicly available web-based training datasets. For instance, in over 30% of conversations, users request creative compositions such as fictional story writing or continuation, role-playing, or poetry. However, creative writing is poorly represented among the web data used for model training. These results may provide evidence for where models trained exclusively on unstructured internet data are most \u201cunaligned\u201d with how real users want to use generative AI [87]. Language models trained only on web data are known to struggle to understand the structure of discourse and underperform models trained with instruction finetuning and preference training on highly curated data [124, 6, 27]. The misalignment between real use cases and web crawled data may suggest the key areas of model distributional misalignment, as well as inform future data collection efforts based on real-world uses.\n\nSexual role-play appears to be a prevalent use of ChatGPT, despite being mostly removed from common public datasets. Whereas sensitive (e.g. sexual) content represents < 1% of the web domains in HEADC4 (see Table 4), sexual role-play represents 12% of all recorded user interactions in WildChat. All the public datasets we consider-C4, RefinedWeb, and Dolma\u2014have undergone some form of filtering to remove illegal or sexually explicit content, as training on such content introduces potential liability concerns; the web, in general, is known to have high portions of sexually explicit content [11, 83]. OpenAI states in the GPT-4 technical report that it also filtered its training data for harmful content [84]. In addition to filtering web-derived training data, OpenAI's models are further trained to refuse requests that violate OpenAI's Usage Policies.4. OpenAI's Usage Policies prohibit \"sexually explicit or suggestive content\" with respect to minors, or re-distribution that may harm others; however, there is ambiguity as to whether this would cover all user requests for sexual role-play [52]. For instance, the GPT-4 technical report makes a distinction in model refusal instructions between erotic and non-erotic sexual content, \u201c(e.g. literary or artistic value) and contextualized sexual content (e.g. medical)\" [84].\n\nSexual-related uses of AI are a topic of ongoing debate within the scientific community [53, 82, 119], and rules differ by company, service, and jurisdiction. In a review of 30 generative AI developers' acceptable use policies, Klyman [52] finds that OpenAI's policies are not among the most restrictive with respect to sexual content; while OpenAI has a blanket ban on \u201csexually explicit or suggestive content,\u201d other companies' acceptable use policies also explicitly prohibit \u201cerotic content,\u201d \u201cadult content,\" \"pornography,\u201d \u201cnudity,\u201d and \u201csexual fetishes\u201d [3, 41, 1]. However, harsher restrictions on sexual content come with tradeoffs, as more heavily safety-tuned language models may then be less able to direct users to resources about sex education or generate fictional stories with PG-13 type content.\n\nCommon ChatGPT uses appear distinct from the uses of commercialized web sources. Figure 4 shows that a significant portion of tokens in HEADC4 are from web domains with ads, paywalls, or both-in other words they are the most commercialized. However, while news websites (the mostly highly commercialized category) comprise nearly 40% of all tokens in HEADC4, fewer than 1% of ChatGPT queries appear to be related to news or current affairs. It also shows that news websites have the highest instance of ads, paywalls, or both in other words, they are the most commercialized. Our observations suggest that real-world use cases of ChatGPT are not necessarily directly related to the most prevalent, commercialized content on the web. This finding has interesting implications for the use of AI in industries with web-based services, such as journalism, or for US copyright analysis, which evaluates how the secondary use of a protected work (training AI models) affects the potential market for the original use of the work (see 17 U.S.C \u00a7107).\n\nWe believe our observations provide strong empirical evidence for the (mis)alignment between AI uses and web-derived training data. However, our observations come with significant caveats. The WildChat [131] dataset may not include a representative sample of how people interact with language models. Not only does it solely include conversations with a specific instance ChatGPT, but the WildChat proxy service is hosted on a technical website, HuggingFace Spaces, which could suggest a more technical user base, or one more likely to audit ChatGPT for inappropriate uses. Model uses also change both by time and product; our analysis is specific to the model interactions collected in WildChat between April 9, 2023, at 12 AM to May 1, 2024, using the GPT3.5-Turbo and GPT-4 APIs. Different AI products are likely to have different use distributions, and usage patterns will inevitably change over time. Finally, the use taxonomy, both for web domains and WildChat uses, were developed based on a manual, iterative process that is limited in its granularity. It is possible that data/information from News web domains could be used in responses for non-News classifications in WildChat, e.g. General Information. This would be exceedingly difficult to measure, and merits analysis in future work."}, {"title": "Discussion", "content": "Consent to use the web-sourced AI data commons is rapidly declining. The web has acted as the primary \"data commons\" for general-purpose AI. It's scale and heterogeneity have become fundamental to advances in capabilities. However, our results show web domains are rapidly restricting crawling and use of their content for AI. In less than a year, ~5% of the tokens in C4 and other major corpora have recently become restricted by robots.txt. And nearly 45% of these tokens now carry some form of restrictions from the domain's Terms of Service. If these rising restrictions are respected by model developers (as many claim to) or is legally enforced, the availability of high-quality pretraining sources will rapidly diminish.\n\nDeclining consent will skew data representativity, freshness, and scaling laws. Prior work has forefronted scaling data as essential to frontier model capabilities [46, 120]. While the declining trend in consent would protect content creators' intentions, it would also challenge these data scaling laws [46, 120]. Not only would these restrictions reduce the scale of available data, but also the composition (away from news and forums), diversity, and representativeness of training data-biasing this data toward older content and less fresh content.\n\nRecently, multiple AI developers have been accused of bypassing robots.txt opt-outs to scrape publisher websites [88, 73]. While it is not possible to confirm, in each case it appears AI systems may be distinguishing between crawling data for training, and crawling data to retrieve information for user questions at inference time. One of the few, OpenAI has two crawler agents, GPTBot for training, and ChatGPT-User for live browsing plugins (see Table 5). Other companies may simply not be registering their inference time crawlers for opt-outs. This circumvention may allow developers to directly attribute the retrieved web pages, as well as better achieve data representativity, freshness, and approximate the scaling laws had they trained on it. However, creators may feel this violates the spirit of the opt-outs, especially if the opportunity to attribute sources is not taken.\n\nThe web needs better protocols to communicate intentions and consent. The REP places an immense burden on website owners to correctly anticipate all agents who may crawl their domain for undesired downstream use cases. We consistently find this leads to protocol implementations that don't reflect intended consent. An alternative scheme might give website owners control over how their webpages are used rather than who can use them. This would involve standardizing a taxonomy that better represents downstream use cases, e.g. allowing domain owners to specify that web crawling only be used for search engines, or only for non-commercial AI, or only for AI that attributes outputs to their source data. New commands could also set extended restriction periods given dynamic sites may want to block crawlers for extended periods of time, e.g. for journalists to protect their data freshness. Ultimately, a new protocol should lead to website owners having greater capacity to self-sort consensual from non-consensual uses, implementing machine-readable instructions that approximate the natural language instructions in their Terms of Service.\n\nDecreasing consent affects non-profits, archives, and academic researchers. A new wave of robots.txt and Terms of Service pages have not, or cannot, distinguish the various uses of their data. For instance, having to individually prohibit a plethora of AI crawlers has motivated many domains to simply blanket prohibit any crawling with the wildcard \u201c*\u201d marker. Or domains have also limited crawlers from non-profit archives such as the Common Crawl Foundation or Internet Archive, in order to prevent other organizations from downloaded their data for training. However, these archives are also used for non-commercial uses of AI, as well as academic research, knowledge, and accountability, well beyond the scope of AI. For instance, the Common Crawl is reported to be cited in 10,000+ research articles from varying fields.5 This tension between data creators and, predominantly, commercial AI developers has left academic and non-commercial interests as secondary victims. As web consent continues to evolve, we believe it is essential that these often essential facilities not be marginalized or severely hampered."}, {"title": "Conclusion", "content": "In this work, we presented the first, large-scale audit of the web sources underlying the massive training corpora for modern, general-purpose AI. Our audit of 14,000 web domains provides a view the changing nature of crawlable content, consent norms, and points to daunting trends for the future openness of the highest quality data used to train AI. The inconsistencies and omissions between robots.txt and terms of service pages suggest a data ecosystem ill-equipped to signal or enforce consent. Lastly, we uncover distributional mismatches in the documented real uses of AI systems and their underlying data. We release all our collected annotations and analysis, with the hope that future work will further investigate the provenance, consent, and composition of the fundamental ingredients to AI systems."}, {"title": "Impact & Ethics Statement", "content": "Consent to copy, use and train on data is a complex issue. First, the robots.txt and Terms of Service that communicate these intentions are owned by the web administrators, which are often imperfect proxies for the actual copyright holders. For instance, social media websites or forums often host content that was originally created or belongs to others. This is pervasive across the web. And there are insufficient tools to attribute all content to their copyright holders, or disentangle consenting from non-consenting use content indeed that is partly demonstrated by this work. As such, it is important to recognize that robots.txt and Terms of Service have become the status quo out of practicality, though they suffer from limitations in ownership, and effective communication of intentions.\n\nAdditionally, while many data consent signals exist, which ones should be enforceable and how they should be enforced both remain open questions, legally and ethically. Data crawling restrictions can be motivated by intentions to protect copyright holders, privacy, or a desire to monetize the data themselves. Some of these motivations may not override the competing right for humans to collect public web material, for study, or non-commercial purposes. And, some have argued that humans, and by extension machines, have the \"right to read and learn\" from open web data [48]. The laws, ethics, and best practices that emerge around these conflicting goals will impact the future efficacy of AI technologies, the types of organizations that are able to acquire sufficient data to compete in frontier model development, as well as the economy of creators from which these datasets are sourced. In this work, we do not prescribe legal or ethical answers, but describe the precise and evolving nature of consent signals on the web. While we advocate for more protocols and mechanisms that enable more effective communication of these intentions, we leave the adherence to these intentions as a broader question for readers, developers, and legislators."}]}