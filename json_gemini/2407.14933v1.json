{"title": "Consent in Crisis: The Rapid Decline of the AI Data Commons", "authors": ["Shayne Longpre", "Robert Mahari", "Ariel Lee", "Campbell Lund", "Hamidah Oderinwale", "William Brannon", "Nayan Saxena", "Naana Obeng-Marnu", "Tobin South", "Cole Hunter", "Kevin Klyman", "Christopher Klamm", "Hailey Schoelkopf", "Nikhil Singh", "Manuel Cherep", "Ahmad Mustafa Anis", "An Dinh", "Caroline Chitongo", "Da Yin", "Damien Sileo", "Deividas Mataciunas", "Diganta Misra", "Emad Alghamdi", "Enrico Shippole", "Jianguo Zhang", "Joanna Materzynska", "Kun Qian", "Kush Tiwary", "Lester Miranda", "Manan Dey", "Minnie Liang", "Mohammed Hamdy", "Niklas Muennighoff", "Seonghyeon Ye", "Seungone Kim", "Shrestha Mohanty", "Vipul Gupta", "Vivek Sharma", "Vu Minh Chien", "Xuhui Zhou", "Yizhi Li", "Caiming Xiong", "Luis Villa", "Stella Biderman", "Hanlin Li", "Daphne Ippolito", "Sara Hooker", "Jad Kabbara", "Sandy Pentland"], "abstract": "General-purpose artificial intelligence (AI) systems are built on massive swathes of public web data, assembled into corpora such as C4, RefinedWeb, and Dolma. To our knowledge, we conduct the first, large-scale, longitudinal audit of the consent protocols for the web domains underlying AI training corpora. Our audit of 14,000 web domains provides an expansive view of crawlable web data and how consent preferences to use it are changing over time. We observe a proliferation of AI-specific clauses to limit use, acute differences in restrictions on AI developers, as well as general inconsistencies between websites' expressed intentions in their Terms of Service and their robots.txt. We diagnose these as symptoms of ineffective web protocols, not designed to cope with the widespread re-purposing of the internet for AI. Our longitudinal analyses show that in a single year (2023-2024) there has been a rapid crescendo of data restrictions from web sources, rendering ~5%+ of all tokens in C4, or 28%+ of the most actively maintained, critical sources in C4, fully restricted from use. For Terms of Service crawling restrictions, a full 45% of C4 is now restricted. If respected or enforced, these restrictions are rapidly biasing the diversity, freshness, and scaling laws for general-purpose AI systems. We hope to illustrate the emerging crisis in data consent, foreclosing much of the open web, not only for commercial AI, but non-commercial AI and academic purposes.", "sections": [{"title": "1 Introduction", "content": "The web has become the primary communal source of data, or \u201cdata commons\u201d, for general-purpose and multi-modal AI systems. The scale and heterogeneity of web-sourced training datasets provide the foundation for both open and closed AI systems, such as OLMo [42], GPT-40 [85], and Gemini [115]. However, the use of web content for AI poses ethical and legal challenges to data consent, attribution, copyright, and the potential impact on creative industries [35, 62, 94, 128]. This has spurred new initiatives to better verify data quality and provenance [34, 32, 55, 66, 11], isolate public"}, {"title": "2 Methodology", "content": "AI models that are highly performant on tasks in language [98], images [132, 37, 4], video [7, 76, 79], and even audio [64, 26] increasingly depend on massive web-sourced training datasets. These datasets are collected using web crawlers-agents that navigate the web, accessing and retrieving web pages without human intervention. While these robots are essential for a variety of applications, including search engines, studying the internet (ie archiving), and link verification tools; recently they have also become the backbone of AI training data collection [97, 16].\nIn our study, we focus on three popular, open-source, and permissively licensed data sources which are derived from Common Crawl, the largest publicly available crawl of the web, which has collected and stored hundreds of billions of web pages since 2008. For each web-based data source, we sample the web domains from which it was created, and extensively human annotate their properties. Our"}, {"title": "3 Findings", "content": null}, {"title": "3.1 The Decline of Consent to Open Web Data", "content": "To understand the web sources underlying foundation models, we analyze the longitudinal changes in robots.txt and Terms of Service restrictions between January 2016 and April 2024. In Figure 1 the plots depict the percent of tokens present in each category of restriction over time, for the AI Organizations in $HEADC4$-the largest, most actively maintained, and critical domains for AI training. The fine-grained longitudinal analysis of robots and Terms of Service trends allows us to estimate this time series into the future. We apply Seasonal Autoregressive Integrated Moving Average (SARIMA) models to generate forecasts of future trends for both the head sample and random subset, the details of which can be found in Appendix C along with the coefficients and tests.\nIn Figure 2 we measure the restricted tokens, or how many tokens fall into the most restrictive settings for each of robots.txt and Terms of Service, as a portion of the Full Corpus, or $HEADAll$. The intermittent lack of smoothness for Figures 2c and 2d is mainly due to temporal gaps in the Wayback Machine; however the main trends remain visible. In all analyses we exclude web domains which could not be retrieved from the Wayback Machine, and all proportions are based on the set of web domains which existed in that time period.\nThese analyses show a clear and systematic decline in consent to crawl and train on data, from across the webs. To the degree this consent is respected, it also foretells a decline in open data, which may"}, {"title": "3.2 Inconsistent and Ineffective Communication on AI Consent", "content": "In many cases, data holders fail to effectively communicate their preferences on how their data is used by AI systems. We observe robots.txt instructions which allow some AI organizations to crawl while restricting others, references to non-existent crawlers, and contradictions between the robots.txt and Terms of Service. Together, these issues point to the need for better preference signaling protocols.\nUnrecognized crawler agents cause incorrect specifications. We find several instances where robots.txt refer to user agents that the companies do not recognize. For instance, 4.5% of websites disallowed the unrecognized user agents ANTHROPIC-AI or CLAUDE-WEB (documented as FALSE ANTHROPIC), but not the documented agent for Anthropic's crawler, CLAUDEBOT. The origin and reason for these unrecognized agents remains unclear\u2014Anthropic reports no ownership of these. These inconsistencies and omissions across AI agents suggest that a significant burden is placed on the domain creator to understand evolving agent specifications across (a growing number of) developers. Al crawler standardization could address these challenges in consent signaling.\nContradictions exist between robots.txt and ToS. The Robots Exclusion Protocol (REP) is a guideline for web crawlers, while a website's Terms of Service is a legal agreement between the"}, {"title": "3.3 Correlating Features of Web Data", "content": "What does web data actually look like? Prior work has measured the characteristics of web-derived datasets, for the presence of artifacts [34, 66], undesirable text and images [69, 11], demographic biases [32], and quality discrepancies across languages [22]. We expand upon these analyses by measuring what web data sources look like before they have been neatly processed into AI training"}, {"title": "3.4 Misalignment between Real-world AI Usage and Web Data", "content": "In this section, we measure the degree of alignment between real world uses of ChatGPT and the content in the webcrawls that form the bulk of AI training. For each web domain in $HEADAll$, we had annotators label the services provided by the website, as well as the presence of some monetization, such as a paywall or automatic ads. We compare these services against the services that real-world users solicit in their interactions with conversational AI systems. We use WildChat, a recent set of 1 million user conversations with ChatGPT [131], collected through a HuggingFace Space wrapper around OpenAI services. We randomly sampled 100 conversation logs from WildChat, which the paper authors manually clustered by the type of tasks or goals conveyed by each conversation, with the goal of relating the core function of these conversations with the services provided by the websites crawled in training. Subsequently, we used GPT-40 to label 1k randomly selected conversations from the WildChat dataset; these conversations were labelled using the taxonomy we developed to categorize websites. Further details on the taxonomy and labelling procedure can be found in Appendix B.6.\nApparent uses of ChatGPT are misaligned with the popular web domains language models are trained on. Figure 4(a) shows the distribution of services provided by the web domains, broken down by whether those domains are monetized. In contrast, Figure 4(b) shows how ChatGPT is used in the real world. The way that users interact with ChatGPT is different in important ways from the types of content that is most frequently represented in publicly available web-based training datasets. For instance, in over 30% of conversations, users request creative compositions such as fictional story writing or continuation, role-playing, or poetry. However, creative writing is poorly represented among the web data used for model training. These results may provide evidence for where models trained exclusively on unstructured internet data are most \u201cunaligned\u201d with how real users want to use generative AI [87]. Language models trained only on web data are known to struggle to understand the structure of discourse and underperform models trained with instruction finetuning and preference training on highly curated data [124, 6, 27]. The misalignment between real use cases and web crawled data may suggest the key areas of model distributional misalignment, as well as inform future data collection efforts based on real-world uses.\nSexual role-play appears to be a prevalent use of ChatGPT, despite being mostly removed from common public datasets. Whereas sensitive (e.g. sexual) content represents < 1% of the web domains in $HEADC4$ (see Table 4), sexual role-play represents 12% of all recorded user interactions in WildChat. All the public datasets we consider-C4, RefinedWeb, and Dolma\u2014have undergone some"}, {"title": "4 Discussion", "content": "Consent to use the web-sourced AI data commons is rapidly declining. The web has acted as the primary \"data commons\" for general-purpose AI. It's scale and heterogeneity have become fundamental to advances in capabilities. However, our results show web domains are rapidly restricting crawling and use of their content for AI. In less than a year, ~5% of the tokens in C4 and other major corpora have recently become restricted by robots.txt. And nearly 45% of these tokens now carry some form of restrictions from the domain's Terms of Service. If these rising restrictions are respected by model developers (as many claim to) or is legally enforced, the availability of high-quality pretraining sources will rapidly diminish.\nDeclining consent will skew data representativity, freshness, and scaling laws. Prior work has forefronted scaling data as essential to frontier model capabilities [46, 120]. While the declining trend in consent would protect content creators' intentions, it would also challenge these data scaling laws [46, 120]. Not only would these restrictions reduce the scale of available data, but also the composition (away from news and forums), diversity, and representativeness of training data-biasing this data toward older content and less fresh content.\nRecently, multiple AI developers have been accused of bypassing robots.txt opt-outs to scrape publisher websites [88, 73]. While it is not possible to confirm, in each case it appears AI systems may be distinguishing between crawling data for training, and crawling data to retrieve information for user questions at inference time. One of the few, OpenAI has two crawler agents, GPTBot for training, and ChatGPT-User for live browsing plugins (see Table 5). Other companies may simply not be registering their inference time crawlers for opt-outs. This circumvention may allow developers to directly attribute the retrieved web pages, as well as better achieve data representativity, freshness, and approximate the scaling laws had they trained on it. However, creators may feel this violates the spirit of the opt-outs, especially if the opportunity to attribute sources is not taken.\nThe web needs better protocols to communicate intentions and consent. The REP places an immense burden on website owners to correctly anticipate all agents who may crawl their domain for undesired downstream use cases. We consistently find this leads to protocol implementations that don't reflect intended consent. An alternative scheme might give website owners control over how their webpages are used rather than who can use them. This would involve standardizing a taxonomy that better represents downstream use cases, e.g. allowing domain owners to specify that web crawling only be used for search engines, or only for non-commercial AI, or only for AI that attributes outputs to their source data. New commands could also set extended restriction periods given dynamic sites may want to block crawlers for extended periods of time, e.g. for journalists to protect their data freshness. Ultimately, a new protocol should lead to website owners having greater capacity to self-sort consensual from non-consensual uses, implementing machine-readable instructions that approximate the natural language instructions in their Terms of Service.\nDecreasing consent affects non-profits, archives, and academic researchers. A new wave of robots.txt and Terms of Service pages have not, or cannot, distinguish the various uses of their data. For instance, having to individually prohibit a plethora of AI crawlers has motivated many domains to simply blanket prohibit any crawling with the wildcard \u201c*\u201d marker. Or domains have also limited crawlers from non-profit archives such as the Common Crawl Foundation or Internet Archive, in order to prevent other organizations from downloaded their data for training. However, these archives are also used for non-commercial uses of AI, as well as academic research, knowledge, and accountability, well beyond the scope of AI. For instance, the Common Crawl is reported to be cited in 10,000+ research articles from varying fields. This tension between data creators and, predominantly, commercial AI developers has left academic and non-commercial interests as secondary victims. As web consent continues to evolve, we believe it is essential that these often essential facilities not be marginalized or severely hampered."}, {"title": "5 Related Work", "content": "Prior work has conducted large scale audits of the provenance, quality, biases, and characteristics of AI training data, for pretraining text [32, 55, 34, 57], finetuning text [66], as well as multimodal datasets [11, 13, 12, 109, 30], and challenges in data development [89]. Recent work have looked at collecting non-copyrighted data [77], interpreting the legal implications of fair use for AI data [44, 61], and forecasting future data constraints [120]. However, there is little work inspecting the evolution of consent signals on AI data. Prior research have attempted to understand the link decay on the web [25], the collection process for Common Crawl [5], or evolving behavior and implications of web crawlers [60, 18, 58, 113, 19]. Initial news reports have begun to investigate the rate of blocking AI web crawlers for general websites [86] and news publishers [127], laying the foundation for our more rigorous analysis. The dearth of data documentation on AI datasets [39, 9, 101, 8] has been highlighted as a challenge for understanding AI model behavior [67, 100, 74, 43, 81], reproducibility, consent, and authenticity [68]."}, {"title": "6 Conclusion", "content": "In this work, we presented the first, large-scale audit of the web sources underlying the massive training corpora for modern, general-purpose AI. Our audit of 14,000 web domains provides a view the changing nature of crawlable content, consent norms, and points to daunting trends for the future openness of the highest quality data used to train AI. The inconsistencies and omissions between robots.txt and terms of service pages suggest a data ecosystem ill-equipped to signal or enforce consent. Lastly, we uncover distributional mismatches in the documented real uses of AI systems and their underlying data. We release all our collected annotations and analysis, with the hope that future work will further investigate the provenance, consent, and composition of the fundamental ingredients to AI systems."}]}