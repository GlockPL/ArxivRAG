{"title": "ON THE ROBUSTNESS OF FULLY-SPIKING NEURAL NETWORKS\nIN OPEN-WORLD SCENARIOS USING FORWARD-ONLY\nLEARNING ALGORITHMS", "authors": ["Erik B. Terres-Escudero", "Javier Del Ser", "Aitor Mart\u00ednez-Seras", "Pablo Garcia-Bringas"], "abstract": "In the last decade, Artificial Intelligence (AI) models have rapidly integrated into production pipelines\npropelled by their excellent modeling performance. However, the development of these models has\nnot been matched by advancements in algorithms ensuring their safety, failing to guarantee robust\nbehavior against Out-of-Distribution (OoD) inputs outside their learning domain. Furthermore, there\nis a growing concern with the sustainability of AI models and their required energy consumption\nin both training and inference phases. To mitigate these issues, this work explores the use of the\nForward-Forward Algorithm (FFA), a biologically plausible alternative to the Backpropagation\nalgorithm, adapted to the spiking domain to enhance the overall energy efficiency of the model. By\ncapitalizing on the highly expressive topology emerging from the latent space of models trained\nwith FFA, we develop a novel FF-SCP algorithm for OoD Detection. Our approach measures the\nlikelihood of a sample belonging to the in-distribution (ID) data by using the distance from the latent\nrepresentation of samples to class-representative manifolds. Additionally, to provide deeper insights\ninto our OoD pipeline, we propose a gradient-free attribution technique that highlights the features\nof a sample pushing it away from the distribution of any class. Multiple experiments using our\nspiking FFA adaptation demonstrate that the achieved accuracy levels are comparable to those seen in\nanalog networks trained via back-propagation. Furthermore, OoD detection experiments on multiple\ndatasets (e.g., Omniglot and Not-MNIST) prove that FF-SCP outperforms avant-garde OoD detectors\nwithin the spiking domain in terms of several metrics used in this area, including AUROC, AUPR,\nand FPR-95. We also present a qualitative analysis of our explainability technique, exposing the\nprecision by which the method detects OoD features, such as embedded artifacts or missing regions,\nin multiple instances of MNIST and KMNIST. Our results underscore the enhanced robustness that\ncan be achieved by analyzing the latent spaces produced by already trained models.", "sections": [{"title": "1 Introduction", "content": "The fast development of learning algorithms has drastically impacted our dependency on Artificial Intelligence (AI)\nmodels, as their exceptional capabilities have led to their continual integration into production-ready software. However,\nthis rapid pace has not been accompanied by additional safety guarantees to address well-known issues faced by\nmodern AI systems. Among these shortcomings, the lack of robustness against inputs outside the training distribution\nposes a significant challenge in ensuring functionality in scenarios where generalization capabilities are essential [1].\nConsequently, many people are hesitant to rely on AI for critical decisions in fields such as medicine or law, even if\nthe model's performance surpasses that of human experts on specific tasks [2]. This limitation on the generalization\ncapability arises from the predominant use of gradient Back-Propagation (BP) for training models within the AI field."}, {"title": "2 Related Work and Contributions", "content": "In this section, we present a comprehensive overview of relevant literature for this work, focusing on the following\ncentral topics: Spiking Neural Networks (Subsection 2.1); Forward-only Learning Algorithms (Subsection 2.2); Out-of-\nDistribution Detection (Subsection 2.3); and Explainability and Attribution (Subsection 2.4). Finally, Subsection 2.5\ndetails the contribution that this papers offer with respect to the current literature."}, {"title": "2.1 Spiking Neural Networks", "content": "SNNs constitute a special category of artificial neural networks inspired by biological models, aiming to replicate the\ncommunication patterns found in real neurons within the brain. Unlike traditional approaches, primarily driven by\nAnalog Neural Networks (ANNs) that rely on continuous activation values to forward information, spiking models\noperate by using discrete pulses of information, known as spikes. The internal dynamics of the neuron, determined by\nthe chosen neural model, dictate when spikes occur and are typically presented as a dynamical system that provides a\nmathematical approximation of the behavior observed in real neurons [7]. Consequently, neurons can exhibit highly\ncomplex dynamics depending on the neural model, the degree of biological plausibility and the total computational\ncomplexity desired for the simulation.\nIn this work, we rely on the Leaky Integrate-and-Fire (LIF) neural model, known for preserving the standard action-\npotential dynamic while achieving high computational efficiency [8, 9]. Under this model, the membrane potential U of\nthe neuron is tracked and updated in response to the external stimuli $I_{in}$, which represents the information forwarded to\nthe neuron via the axon. Whenever the membrane potential reaches a threshold $\u03b8_{thr}$, a spike is generated and forwarded"}, {"title": "2.2 Forward-only Learning Algorithms", "content": "BP stands as the most commonly employed algorithm for training artificial neural networks. This method computes\nexact gradient values of the weights with respect to a loss function by back-propagating the error from the output\nthrough the layers using the chain rule. Due to the precision of weight updates, BP has achieved state-of-the-art results\nin terms of accuracy across a multitude of tasks. However, the requirement for differentiability in the functions defining\nthe network poses a clear limitation for non-differentiable neural models, such as those in spiking systems. To address\nthis limitation, the most commonly employed approach involves replacing the neural model with a differentiable\napproximation so that the backward pass can create a faithful approximation of the gradients [14]. Additionally, due\nto the optimization nature of the problem, models trained with BP have been observed to be prone to overfitting [15],\nconsequently failing to generalize beyond the training distribution and resulting in unknown outcomes when presented\nwith new, unseen data.\nTo overcome the present limitations of BP, the NeuroAI field has recently emerged as a strong alternative movement.\nThis field advocates for incorporating and studying learning mechanisms observed in the brain to improve current\nmodels, aiming for fast learning and highly robust learning models [16]. Among these approaches, the branch of\nforward-only algorithms poses a viable method for bridging the gap between neuroscience and AI by focusing on\na reduced set of biological properties while preserving the advantage of being computationally efficient and staying\nclose to traditional AI methods. These algorithms specifically address the weight transport and update lock problems\nby relying solely on forward passes. By avoiding these biological incompatibilities, these algorithms also enhance\nintegrability into neuromorphic systems, which are better suited for spiking models.\nRecently, the Forward-Forward Algorithm was introduced as a novel forward-only alternative to BP, advocating for a\nbiologically motivated heuristic in which the backward pass is replaced by an additional contrastive forward pass [3]. In\nthis secondary pass, the model is presented with an adversarial sample to contrastively learn to distinguish between\nsamples from the training set (referred to as positive or $D\u2295$) and synthetically created data (referred to as negative\nor $D$). As it follows from to its forward-only nature, each layer is trained independently, using a layer-specific loss\nfunction that relies solely on local information. To formulate this loss function, Hinton proposed the use of a goodness\nscore, which measures the likelihood of a latent vector from belonging to the positive data distribution. This goodness\nfunction $G: L \u2192 R$ is defined as the squared Euclidean distance of the latent vector from its original position, where\n$I_L$ denotes the latent space of the given layer. This choice was motivated by the simplicity of its derivative, which\nfacilitates clear and effective weight update expressions. Under this formulation, the goodness score serves as a measure\nof the layer's activity, advocating for achieving highly active layers when presented with positive samples, and nearly\ndormant outputs when encountering a negative instance.\nTo avoid relying on a regression-based task, which could provoke unstable learning dynamics, a probability-based\napproach was taken. By using the Binary Cross-Entropy loss with a probability function defined over the goodness\nscores, the approach ensures a balanced distribution of positive and negative activities. The probability function\n$P: R\u2192 [0, 1]$ is chosen to map the goodness scores to a final probability estimation, indicating the likelihood of a\nlatent vector being obtained from a sample from the positive data distribution. This function is defined by the logistic"}, {"title": "2.3 Out-of-Distribution Detection", "content": "OoD detection is a crucial task for developing production-ready software, as it ensures that models are not presented\nwith inputs outside their training distribution, which could result in unpredictable and potentially dangerous outputs\n[1]. To achieve this, OoD detection algorithms define a scoring function that measures the likelihood of a sample\nfrom belonging to the ID dataset, which is then used to label input data as either ID or OoD depending on the score\nobtained. When studying how OoD samples emerge, it's important to distinguish between two fundamentally different\nscenarios: semantic shifts, which occur when samples that do not belong to any class start to emerge, changing the\noverall distribution of the input space without truly altering the distribution of the previously seen classes; and covariate\nshifts, which occur when the inherent distribution of one or several classes shifts from its original distribution. In\nthis context, OoD detection only covers the detection of semantic shifts in the data, as covariate shifts are covered by\nthe branch of anomaly detection [20]. Based on the review from Yang et al. [1], OoD detection algorithms can be\ncategorized into four distinct heuristics based on the information used to detect OoD samples: classification-based,\ndistance-based, density-based, and reconstruction-based methods. Our paper focuses on distance-based techniques,\nwhich rely on the distances within the latent space to define the desired OoD scoring function. Due to the lack of\nliterature on OoD detection in networks trained using the FFA, we will provide a comparative perspective on methods\nemploying backpropagation BP.\nCurrently, the ODIN algorithm stands as the most widely-used benchmark for OoD detection due to its high accuracy\nand reduced computational costs. This algorithm operates by measuring the effect on the softmax distribution of the\nlast layer when changing the temperature scaling and introducing small perturbations into the inputs, where OoD\nsamples result in the greatest differences [21]. An alternative approach was proposed by Bergman et al., where the deep\nk-nearest neighbor algorithm is employed to measure the distance between input samples and previously computed ID\nrepresentative latent manifolds, thereby using the latent distance to detect anomalies [22]. Building upon this research,\nSun et al. extended the application of the deep k-nearest-neighbor distance for OoD detection [23], highlighting the\nimportance of exploiting the geometric properties in the latent space of trained networks for OoD detection tasks.\nDespite the extensive literature on this task, a noticeable gap exists in the context of techniques designed specifically for\nspiking neural networks. In their recent work, Martinez-Seras et al. introduced a novel method for OoD detection that\nfocuses on spike count patterns in the latent space. By characterizing spike patterns across various layers, they identify\nwhether a given spike pattern aligns with those extracted from in-distribution data [24]."}, {"title": "2.4 Explainability and Interpretability", "content": "Explainable AI, commonly referred to as XAI, is a field focused on developing techniques to offer humanly under-\nstandable explanations for the motivations behind a model's outputs. It is well acknowledged that most modern\nmodels operate as black boxes, achieving high performance across multiple tasks but offering little to no insight into\nthe heuristics they follow to obtain their outputs. To address this shortcoming, the XAI field encompasses multiple\nsubtopics aimed at extracting different types of knowledge of models. Among these subtopics, the most relevant are\ngiven by: understandability, comprehensibility, interpretability, explainability, and transparency. This paper focuses on\nInterpretability, which aims to extract meaningful explanations that can be easily understood by humans agents.\nAs of now, the most prevalent interpretability techniques for computer vision tasks are driven by Class Activation Maps\n(CAMs) [25], which create visual insights highlighting the most significant regions of an input image that impacted\nthe prediction. Among methods providing this type of explanation, Grad-CAM stands as the one with the greatest\nimpact. This method uses the gradient information of the last convolutional layer to detect the areas of the input that\nhad the highest impact on the prediction of a specific class [26]. Although several extensions of the algorithm have been\ndeveloped to enhance the quality of the attribution maps [27, 28], these methods are not applicable to spiking networks\ndue to their reliance on precise gradient information, which cannot be obtained from spiking networks because of the\nnon-differentiability of their neural model. To overcome this issue, Kim et al. introduced a visualization algorithm\nnamed Spike Activity Mapping, which leverages the temporal dynamics of SNNs to compute neuronal contribution\nscores during forward propagation based on the history of spikes [29]. Another approach proposed by Bitar et al.\naddresses the gradient issue in image attribution by employing surrogate gradients, demonstrating their capability to\nmaintain sufficient accuracy for effectively modeling the saliency map [30].\nContrasting with these approach, which rely solely on gradient information, Martinez et al. presented a technique\ninvolving a backward pass of a latent vector through the network to compute the relevance of specific features in the\ninput space [24]. This method operates by reconstructing spike patterns across the layer and enabling the quantification\nof feature activity, thereby identifying regions of significance within the image. By doing so, the authors place\nadditional focus on exploiting the representational capabilities of the latent space of non-convolutional networks to\ncreate interpretable techniques. Our paper follows the same geometrical motivation, leveraging the specific latent\ntopology of FFA to provide enhanced interpretable results."}, {"title": "2.5 Contributions", "content": "This work presents a seamless adaptation of FFA for spiking models, offering an alternative formulation to the one\nproposed by Ororbia in [6]. In our formulation, we introduce two alternative goodness functions: an unbounded\ngoodness function, which follows Ororbia's methodology by treating spikes as a discrete version of ReLU activation;\nand a bounded goodness function, which fully leverages the bounded behavior of spiking models, making it more\nsuitable for neuromorphic computers. Subsequently, we develop FF-SCP, an OoD detection algorithm that capitalizes\non the characteristic latent space observed by the community to enhance the robustness of FFA. The applicability of\nFFA's geometrical properties remains impactful for creating software that meets industry requirements in terms of\nsecurity. However, the current trend in the literature has primarily focused on its predictive capabilities. Thus, this work\noffers an initial step toward providing additional methodologies that bring FFA closer to being a robust alternative\nto BP in terms of functionality. Additionally, to further explore the functional aspects of the latent space of FFA, we\ndevelop an attribution algorithm that provides understandable explanations for the features of an image that push it\noutside the distribution of any given class. This work also contributes to expanding the literature advocating for the\nstudy of the geometrical properties of latent spaces to benefit model reliability, particularly from the explainability field.\nHowever, we acknowledge the intrinsic challenge posed by the lack of better-suited architectures when introducing FFA\ninto production-ready software."}, {"title": "3 Proposed Approach", "content": "This section introduces the methodological aspects of the algorithms proposed in this work, dedicating one subsection\nto each of the contributions. Subsection 3.1 outlines the adaptation of FFA for SNNs. Subsection 3.2 introduces the\nFF-SCP algorithm, which employs the latent state of SNNs trained with FFA to create an OoD detection algorithm.\nLastly, Subsection 3.3 presents an attribution technique aimed at providing visual insights into the information relating\narbitrary samples to the distribution of specific classes."}, {"title": "3.1 Spiking Forward-Forward Algorithm", "content": "Although the original motivation that led to the development of FFA was to propose a biologically plausible alternative\nto BP, the vast majority of research on this method is still obtained using ANNs. In this section, we present a\nstraightforward adaptation of FFA for SNNs, modifying the goodness scoring function to aggregate the temporal\ndimension and employing surrogate gradient techniques to enable training under standard ML pipelines. Additionally,\nto capitalize on the bounded dynamics offered by spiking models, we propose a novel bounded goodness function\nthat operates independently of the total simulation time. For the remainder of this paper, we will denote the spiking\nformulation of FFA as sFFA.\nAs detailed in Section 2, the original goodness function G was formulated using the squared Euclidean distance of the\nlatent vector. This function, combined with the unbounded dynamics of ReLU activations, enabled learning dynamics\nthat could result in positive latent vectors achieving arbitrarily high goodness scores as training progressed. However,\ndue to the discrete event-driven nature of SNNs, where the latent space consists of binary latent vectors, the activation\nvalue of each neuron is bounded by the total number of timesteps in the simulation. Therefore, to replicate behaviors\nsimilar to those observed in ANNs, the goodness function must be adapted to handle these discrete binary states. This\npaper introduces two implementations of the goodness function for spiking models: an unbounded goodness, which\nmimics the behavior of ANNs through the aggregation of the temporal dimension; and a bounded goodness, designed to\ncapitalize on the bounded activation range of SNNs.\nThe first goodness function, namely the unbounded goodness function, referred to as $G_\u221e(\u00b7)$, can be naturally adapted\nfrom the conventional goodness function by considering the sum of spikes as a linear approximation of ReLU-like\nfunctions. In this scenario, the goodness function takes the latent vector l, composed of the spike train of the neurons\nof the layer, and acts as the squared Euclidean norm of the number of spikes. Formally, given the latent vector\n$l\u2208 {0, 1}^{N\u00d7T}$ consisting of N neurons and T timesteps, the function $G_\u221e(l) : {0,1}^{N\u00d7T} \u2192 R_{>0}$ is formulated as:\n$G_\u221e(l) = \\sum_{n=1}^{N} \\sum_{t=1}^{T}l_{n,t}^{2}$,\nwhere $l_{n,t}$ denotes the value of the n-th neuron at timestep t.\nOur second goodness function, namely the bounded goodness, denoted by $G_o(\u00b7)$, offers an alternative formulation in\nwhich the learning process relies solely on bounded states, aligning more closely with biological models compared to\ntheir unbounded counterparts. To achieve this, we replace the squared Euclidean distance with the Manhattan distance\nof the mean number of spikes in the latent spike train, ensuring all neurons contribute equally to the goodness score.\nMoreover, by applying mean aggregation, the obtained goodness scores remain independent of the total number of\ntimesteps. Formally, given the latent vector $l \u2208 {0, 1}^{N\u00d7T}$, the bounded goodness function $G_o(l) : {0, 1}^{N\u00d7T} \u2192 R_{\u22650}$"}, {"title": "3.2 The FF-SCP Algorithm", "content": "This section introduces the FF-SCP algorithm, which leverages the emergent representational properties in the latent\nspace of FFA to detect OoD inputs. As previously mentioned, multiple studies have observed that the latent space of\nnetworks trained using FFA exhibits a distinctive topology, characterized by distinct clusters for each training class\n[5, 4]. Conversely, due to ReLU activations having a minimum value of 0, negative data tends to generate near-zero\nlatent vectors, resulting in all negative data clustering around the origin of the latent space. However, due to the\ninherent noise present in spiking models, negative latents attain higher activity bounds, shifting the single cluster of\nnegative data into multiple different clusters dispersed throughout the space. These clusters retain the representability\nof the space, as each one can be observed to contain samples from the same class and which employed the same\nembedding label. Despite the presence of a high number of clusters, the neural specialization of the neurons contributes\nto creating a highly separated latent space, which is a desirable property for detecting samples not drawn from the\ntraining distribution.\nIn its original formulation, the SCP algorithm proposed using a class-representative latent vector to describe each\nclass, so that the geometric complexity of the latent space could be reduced into a single characteristic vector. To\nachieve this, SCP employed the centroid of the class latent vectors, allowing for straightforward computation of the"}, {"title": "3.3 Interpretation of Latent Vector", "content": "Our FF-SCP algorithm presents a method to provide robustness guarantees for AI products. However, this OoD\ndetection method only offers a quantitative measurement indicating the extent to which a sample does not belong to the\ntraining dataset. To enhance the functionality of this algorithm, this section introduces a novel interpretability algorithm\ndesigned to produce human-understandable explanations of the decisions made by FF-SCP. Given an input sample x,\nthis algorithm generates an attribution map highlighting the features that do not align with those expected from the\ndata distribution of a selected class c. This method leverages the same latent space approximation used by FF-SCP,\nemploying a large sample set of latent vectors to approximate the emerging topology from the network's activity (see\ninitialize_latents in Algorithm 1). By exploring this latent space, our algorithm identifies the closest neighbor\n$x_f$ of the sample x, ensuring that its latent representations closely resemble those expected from the latent data of class\nc while retaining key features that characterize the original input x.\nTo search the latent space for the desired ID sample $x_f$, we employ a decoder network that accurately maps the latent\nspace back to its pre-image space in $D\u2295$. Networks trained using FFA are known to provide accurate projections of the\ninput images, capturing the key distinctive features of this input space, thus allowing for precise reconstruction of the\nlatents [5]. Consequently, we can assert that latent vectors surrounding the latent class manifold will result in plausible\nreconstructions, not distant from those present in the training dataset. We denote the application of this decoder network\nas Decode: $L \u2192 D\u2295$, which is trained using the input-latent pairs from the positive dataset. It's important to note that\nwhile negative samples belong to the latent space of the network and provide accurate representation probabilities, they\ndo not align with the features expected for the ID data. Therefore, to obtain the features that cause an input sample to\ndeviate from the ID of a specific class, it is important to create a decoder that operates exclusively within the positive\ndistribution.\nOur algorithm operates by employing this decoder network to explore the obtained latent space approximation to find\nan alternative sample $x_f$, derived from the input x, so that it better fits the input distribution of a user-selected class\n$c\u2208 C$. This exploration is achieved by using a parameter latent vector $l_w$, whose reconstruction results in our desired\ninput vector $x_f$. This vector is optimized using a gradient descent algorithm to minimize two key distances: first, the"}, {"title": "4 Experimental Setup", "content": "To systematically evaluate the methods presented in this work, we outline 3 Research Questions (RQs) that encapsulate\nthe conditions under which our initial hypothesis would be satisfied, thereby establishing the practical utility of FFA.\nThe chosen research questions are:\n1. RQ1: Can our proposed sFFA achieve competitive accuracy compared to the original FFA?\n2. RQ2: Does the enhanced latent representation of sFFA, utilized by our proposed FF-SCP, improve upon the baseline\nresults of SCP and ODIN?\n3. RQ3: Does the latent space of models trained with sFFA exhibit sufficiently representative properties to develop\ninterpretability mechanisms?\nTo provide insights into the experimental process used to address these questions, we have organized this section as\nfollows: Section 4.1 outlines the configuration employed for the different models and the training process used to\naddress RQ1; Section 4.2 describes the experimental procedure followed to evaluate our FF-SCP algorithm in relation to\nRQ2; Section 4.3 presents the process used to assess the quality of the attribution maps generated by our interpretability\nalgorithm to answer RQ3; and finally, Section 4.4 lists the datasets and data processing employed in this work. All the\ncode for the experiments has been uploaded to https://github.com/AnonymousSquirrel316/FFA_OOD."}, {"title": "4.1 Architecture and Training Process", "content": "To conduct an unbiased experimental analysis across the different network architectures, minimizing potential biases\nbetween analog and spiking networks, all models were designed to achieve equivalent behaviors. Specifically, each\nmodel consisted of two densely connected feed-forward layers, each with 1400 neurons. The analog networks employed\nReLU activation functions, while the spiking networks relied on LIF neural models as a biological counterpart. To\nimplement these spiking dynamics, we utilized the LIF class from the snnTorch [32] library, with the following\nhyperparameters: a fast sigmoid as the surrogate function, 20 timesteps per forward pass; a threshold of 0.4 for the\nfirst layer and 0.3 for the subsequent layer; and $\u03b2_n$ values of 0.4 for the first layer and 0.2 for the subsequent layer. To\nprevent spiking neurons from entering over-excited states, an input downscaling technique was applied. This technique\ninvolved scaling down the input to each neuron by a factor of $0.85^{N_{spikes}}$ at each timestep, where $N_{spikes}$ denotes the total\nnumber of output spikes from the respective neuron. This approach effectively reduces the input activities of highly\nactive neurons over time, thereby moderating their overall activity throughout the timesteps.\nThe training process for all models followed the supervised methodology proposed by Hinton [3], wherein positive and\nnegative samples are generated by embedding an encoded version of the label into the image. In addition to Hinton's\nproposed negative generation process, we also employed a greedy negative generation method. In this approach, the\nnegative label is chosen as the one which maximizes the goodness score, aiming at increasing the distance between the\ngoodness scores of positive and negative labels. Each method was independently used to train each network, and the\none resulting in higher accuracy was selected for further experimentation to ensure optimal predictive capabilities for\nsubsequent tasks, including OoD detection and our attribution method. Additionally, we adopted the label initialization\nand embedding techniques proposed by Lee et al. [17], where embedding vectors of class labels are set as random\nbinary vectors appended at the end of the data. Each binary vector, of dimension 100, was initialized using a Bernoulli\ndistribution with a probability of 0.1 for each element of the vector."}, {"title": "4.2 Out-of-Distribution Evaluation Setup", "content": "As this paper builds upon the groundwork of the original SCP algorithm introduced in [24], and given the absence\nof subsequent spiking-specific OoD detection methods in the literature, the benchmarks used for this work are\nextracted from the aforementioned study. Specifically, the SCP and ODIN algorithms stand as the top-performing\napproaches, serving as the designated benchmarks for comparative analysis in this work. Furthermore, to demonstrate\nthe competitiveness of our algorithm in the spiking domain compared to its analog counterpart, both types of networks\nhave been tested.\nThe models used in these experiments are the best-performing ones from the training experiments of RQ1. We explored\nthe use of Euclidean, Manhattan, and Cosine distances for the distance function d(\u00b7,\u00b7), and chose the Manhattan\ndistance due to its superior performance. We employed 1024 samples to create the latent space, following the process\ndetailed in the initialize_latents function of Algorithm 1. For the filtering step, we removed 20% of the highest\nand lowest latent vectors from their respective latent sets. The hyperparameters \u03b3, \u03b2, and $z_0$ were selected through\nan early hyperparameter selection process for each training and goodness. Their search space was defined as follows:\n$z_0$ was chosen from the set {0.85, 1, 1.15, 1.4}; \u03b3 was either $10^4$ or $10^6$; and \u03b2 was set to either 1 or 2, representing\nManhattan or Euclidean aggregation of distances, respectively.\nTo objectively evaluate the model's OoD detection performance across the experiments, three key evaluation metrics\nhave been measured: AUROC, AUPR, and FPR95. These metrics are widely employed in the OoD detection literature,\nproviding valuable insights into the model's ability to distinguish between in-distribution and out-of-distribution samples.\nTheir definitions are as follows:\n\u2022 AUROC, also known as the Area Under the Receiver Operating Characteristic Curve, is a threshold-independent\nmetric that, when given a set of OoD scores for the data, quantifies the extent of overlap between OoD and ID samples.\nThe AUROC metric ranges from 0 to 1, where 0.5 indicates a random classifier's performance, and 1 signifies a\nperfect classifier that can perfectly separate OoD and ID samples.\n\u2022 AUPR, also known as the Area Under the Precision-Recall Curve, considers the precision and recall trade-off in\nclassifying OoD samples. AUPR values closer to 1 indicate better performance, with high precision and recall in\ndistinguishing OoD samples.\n\u2022 FPR95, also known as the False Positive Rate at a 95% True Positive Rate, provides insights into the model's false\npositive rate when the true positive rate is set at 95%. This metric quantifies the model's ability to maintain a low\nfalse positive rate while correctly identifying 95% of OoD samples. Lower FPR95 values are indicative of better OoD\ndetection performance."}, {"title": "4.3 Evaluation of the Quality of the Attribution Method", "content": "As mentioned in Section 3.3, our proposed interpretability algorithm provides a visual representation of the areas that\ndrive images towards the OoD direction. Given the subjective nature of evaluating the quality of an attribution map, we\nrely on a qualitative analysis of several samples from the training data. We conducted this analysis using instances\nfrom the MNIST and KMNIST datasets, generating altered images through several obstruction methods to measure\nour method's performance when presented with closely resembling images. The artifacts introduced in these images\nserve as primary factors pushing them towards the OoD direction, and thus, should be the most prominent regions\nhighlighted on the attribution maps. The samples chosen for evaluation were randomly selected from both datasets,\nand after comprehensive inspection, those that most clearly embody the characteristics captured by the attribution map\nwere retained for further analysis. This analysis focuses on identifying the attribution capabilities of the approach and\nuncovering potential limitations.\nThe decoder network chosen to reconstruct the latent spaces is a single-layer analog network utilizing Sigmoid\nactivations. To prepare the spike train vectors for the analog decoder, these latent vectors are averaged over the time\ndimension. During training, the decoder minimizes Binary Cross Entropy loss between the input image and the\nreconstructed image generated from the latent vector obtained from the first layer. This loss function was preferred due"}, {"title": "4.4 In-Distribution and Out-of-Distribution Datasets", "content": "To evaluate the training accuracy of our adaptation of FFA to spiking networks, we employed five well-known datasets:\nMNIST [33], consisting on 60,000 images of 10 classes of handwritten digits; Fashion MNIST [34], composed of\n60,000 images representing 10 classes of clothing items; Kuzushiji-MNIST (KMNIST) [35], consisting of 60,000\nimages of Japanese characters divided into 10 different classes; and EMNIST (Letters) [36], composed of 145,000\nimages of the 26 lowercase letters of the Latin alphabet. A uniform normalization pipeline was applied across all\ndatasets. Each of these spike trains was set to last for 20 timesteps.\nSince OoD experiments require a trained model and its corresponding training dataset as the ID baseline, we utilize all\nthe models previously trained in RQ1 for experimentation in RQ2. In these experiments, the OoD dataset is constructed\nby combining all other training datasets on which the models were not trained. To expand the scope of our analysis, we\nintroduce two additional OoD datasets: Not-MNIST (small) [37], which consists of 19,000 font glyphs representing\nletters A to J, and Omniglot [38], containing 1,623 handwritten images spanning 50 different alphabets. These datasets\nunderwent the same data processing pipeline used in the training experiments."}, {"title": "4.5 Limitations", "content": "This work proposes FFA as a candidate alternative to BP, highlighting its functional latent space and representational\ncapabilities, which offer substantial advantages for developing techniques to enhance model robustness for industry-\nready software. However, due to the early stage of research into this algorithm, we observed a clear lack of alternative\narchitectural formulations (e.g., convolutional or transformer layers). To date, only one work has presented a possible\ndesign for a convolutional layer in FFA by relying on pattern-like embeddable patterns [39]. While this method\ndemonstrates accurate precision on small datasets, no proofs have been given of this algoritmh scaling to more complex\ndatasets, such as CIFAR-10, where images contain non-empty backgrounds. Consequently, current models can only\nrely on densely connected layers, which have multiple limitations when learning from highly complex datasets. As a\nresult of this limitation, the latent representations of these models exhibit a clear upper boundary on representational"}, {"title": "5 Results and Discussion", "content": "This section presents the results from various experiments, discussing the findings and highlighting observed limitations.\nInitially, Subsection 5.1 showcases the accuracy results of our proposed spiking adaptations of FFA. Subsection 5.2\npresents the outcomes of the OoD detection task using the FF-SCP algorithm, comparing it against the SCP and ODIN\nalgorithms. Finally, Subsection 5.3 discusses the results obtained from the attribution method proposed in this paper."}, {"title": "5.1 RQ1: Training Results of SFFA", "content": "The accuracies obtained from the training experiments using the different goodness functions are presented in Table 1.\nThese results demonstrate the comparable performance between the analog and the spiking implementations of FFA,\nwhere SNNs only exhibit a slight decrease in accuracy, likely due to the increased noise within latent vectors caused\nby the stochastic input preparation process. Among the two proposed goodness functions, the models employing the\nunbounded version achieved higher accuracy than their bounded counterparts, with an accuracy of 86.16% compared to\n81.20%.\nNevertheless, while the average accuracy shows a noticeable drop, this loss in accuracy is primarily related to the\nsignificant difference in accuracy on the MNIST dataset, where the bounded version reduces accuracy by 14.61 points.\nThis abnormal relationship in the drop in accuracy across different datasets suggests that the bounded and unbounded\nmodels process the data differently, leading to distinct classification heuristics and representation properties. These\nresults align with the observation that networks using bounded goodness functions do not experimentally create sparse\nlatent representations, which can result in reduced feature specificity in the neurons (see Appendix B)."}, {"title": "5.2 RQ2: Out-of-Distribution Detection Results", "content": "The metrics of the OoD detection experiments using our proposed method are presented in Table 2. After thoroughly\nanalyzed the results, we conclude that they have yielded a positive outcome to our initial research question. A detailed\ndiscussion of these results follows in the present subsection.\nSFF-SCP is competitive against SCP and ODIN The main hypothesis guiding the development of the FF-SCP\nalgorithm was that the improved representation capabilities of networks trained with FFA, together with refined\ngeometric methods, would yield higher accuracy in OoD Detection tasks. The results, as presented in Table 2, verifythe hypothesis, with both the bounded and unbounded models consistently outperforming the SCP algorithm across all\ndatasets and metrics, except for one instance. The results are particularly evident when compared against the unbounded\nversions of the FF-SCP, where the average AUROC is 7.95 points higher. Furthermore, the proposed algorithm exhibits\na significant reduction in the FPR95, implying that it is more robust in situations where a high True Positive Rate is\nrequired. Nevertheless, the FF-SCP algorithm appears to follow the same pattern of the best and worse-performing pairs"}, {"title": "5.3 RQ3: Attribution Results", "content": "To address the third research question and verify the quality of the attribution maps generated by our approach, as\ndetailed in Algorithm 2, we have employed a qualitative analysis of several visually modified samples from the MNIST\nand KMNIST datasets. Recalling from the approach detailed in Section 3.3, our method provides an interpretability map"}, {"title": "6 Conclusions and Future Work", "content": "The field of Artificial Intelligence has experienced rapid advancements over the last decade, even surpassing human\nexperts in multiple tasks. However, the development of methods to ensure the robustness of these models has not kept\npace with those driving performance improvements. This imbalance has resulted in the accuracy of models being\novershadowed by their black-box nature when integrated into production-ready software. This issue is particularly\ncritical in neuromorphic computing, where the temporal dynamics of spikes pose a challenge in analyzing model\nbehavior. Nonetheless, the introduction of the Forward-Forward Algorithm (FFA) has offered a promising biologically\nplausible alternative learning mechanism, offering a latent space with highly representative properties This spaces are\ncharacterized by a well-defined distribution of latent vectors that cluster with other samples from the same class while\nremaining distinct from instances of other classes.\nThis work proposes an adaptation of FFA for spiking neural networks by developing two alternative formulations of\nthe goodness functions and utilizing surrogate gradients to circumvent the non-differentiability of the neural models.\nCapitalizing on the representational properties of these networks, we develop a novel Out-of-Distribution (OoD)\ndetection algorithm, denoted as FF-SCP, which uses the distances between latent vectors and the latent manifolds of\nclasses as an effective measure of the likelihood of a sample belonging to the training distribution. To enhance the\nfunctionality of this method, we introduce a novel attribution method that explores the latent space to generate an\nattribution map, highlighting features in the sample that differ from an arbitrary class. To verify the competitiveness\nof our FFA adaptation, we trained the network on multiple well-known datasets (e.g., KMNIST, EMNIST) and\nused these networks to evaluate the performance of our FF-SCP algorithm when presented with OoD samples from\nother conventional baselines (e.g., Omniglot, NotMNIST). Additionally, we performed a qualitative analysis on our\ninterpretability algorithm by manually including artifacts into samples from the training data and then evaluating\nthe quality of the generated attribution maps. Our results provide additional evidence of FFA's capability to deliver\ncompetitive results in spiking neural networks compared to its analog formulation. Furthermore, we demonstrate\nhow FFA can effectively detect OoD instances in spiking neural networks, outperforming SCP and ODIN. Similarly,\na qualitative analysis on the distorted images shows how our method can accurately highlight the regions of the\nartifacts, allowing human evaluators to identify the regions pushing samples outside the image distribution. With\nthese two algorithms, FFA proves to offer highly functional properties, resulting in a more explainable model than\nbackpropagation.\nThe positive outcomes of our work pave the way for multiple future lines of research into the applicability of FFA. One\nclear line of research involves extending the key concepts from this work into the study of concept drift, which is critical\nin highly dynamic scenarios. Similarly, leveraging the findings on OoD detection by incorporating incremental learning\ntechniques is crucial for implementing an Open-World Learning algorithm. It is also important to note that our results\nare limited by the lack of alternative architectures, such as convolutions or transformers, which could vastly improve\naccuracy in complex data domains. Consequently, one of our primary focuses will be adapting FFA to accommodate\nmore complex dynamics, potentially enhancing performance in diverse data regimes."}, {"title": "A Reversal of Order in FF-SCP", "content": "This appendix formalizes the mathematical arguments that drive the reversal of the order in the scoring function. As\npointed out in Subsection 3.2, the main limitation of the initial scoring function depicted in Equation (9) arises when,\ngiven a randomly selected sample from the ID dataset X, the following inequality holds:\n$min_{p \u2208 C} \\sum_{c \u2208 C} d(0, L_{c,c}) <_E min_{p \u2208 C} \\sum_{c \u2208 C} d(N_1 (X, c), L_{c,c})$.\nFor instance, this reversal effect of the order predominantly occurs in OoD samples that were identified as negative\ninputs by the network, resulting in a near-zero latent state. Formally, let N be an accurate enough network, defined as a\nnetwork in which the following expression almost always holds:\n$E[||N_i (X, c)||_2] < \u03f5$,\nwhere X denotes a random negative sample and e represents a sufficiently low value. If this property holds, then we\ncan understand the geometric behavior of $L_{c,p}$, where p and c represent non-equal classes from C.\nLemma A.1. The discrete set $L_{c,p}$, where c and p are distinct elements from C, has a near-zero mean norm after the\ninitial filtering step of the FF-SCP algorithm in accurate enough networks."}, {"title": "B Latent State of FFA", "content": "This appendix offers additional insights into the structure of the latent activity of networks trained using the FFA and the\nenhanced representational capabilities it provides. To analyze this space, we rely on the trained models used for the OoD\ndetection experiments, specifically the analog model using ReLU activation functions and the bounded goodness SNN.\nThese two models have been selected as they encompass both activity regimes observed during the experimentation: the\nsparse latent space and the bounded latent space. To avoid redundancy in the latent space, and given the similar latent\nbehavior arising from the different datasets, we employ random batches of data from the MNIST dataset to extract the\nlatent spaces.\nThe plot showing the latent vectors obtained from the analog ReLU network is depicted in Figure 8. Consistent with\nthe findings of Tosato et al. [4] and Yang [19], the latent vectors emerging from these networks are characterized by\nsparse activity regimes and high neural specialization. As observed in the images, most latent vectors are composed of\nonly a small subset of active neurons, which represent key distinctive features of the different classes. For instance,\ngiven that the latent vectors of the images are ordered by class, it can be observed that the set of neurons that activate\nwhen presented with each input distribution is highly consistent among the batch. Similarly, each neuron is usually only\nactive when presented with a small subset of the available input classes, often being active with only one.\nSimilarly, Figure 9 shows the latent activity from the network trained using FFA with the Go(\u00b7) goodness function. In\ncontrast to the previous network, the representations obtained showcase a denser activity regime, with latent vectors\ncomprising a larger set of active neurons per instance. As in the previous case, the activity of the data follows class-based\nactivation patterns, with each neuron specializing in a specific set of classes. However, in this instance, the set of active\nclasses results in a broader selection, allowing for more classes to activate each neuron. Upon early experimentation,\nthe emergence of these representations appears to be a byproduct of the bounded regimes of the goodness functions.\nDue to the inability to achieve unbounded goodness through a small set of unbound neurons, the network relies on a\nlarger set of neurons for each sample. In contrast with the unbounded models, where the negative samples resulted in"}, {"title": "C OoD Detection Results without Order Reversal Considerations", "content": "This appendix presents the results obtained when employing the FF-SCP algorithm when employing the s(\u00b7) scoring\nfunction. As previously mention in Section 3.2, the function s(\u00b7) does not properly measure the distance in scenarios\nwhere the intra-cluster distance is greater than the distance between the zero vector and each sample of positive latent\nclusters, which is formally proven in Appendix A. As expected, the results from Table 3 evidence the reduced OoD\ndetection accuracy when compared to the ones from Table 2, which relies on the refined scoring function S(.)."}]}