{"title": "GPTKB: Building Very Large Knowledge Bases from Language Models", "authors": ["Yujia Hu", "Shrestha Ghosh", "Tuan-Phong Nguyen", "Simon Razniewski"], "abstract": "General-domain knowledge bases (KB), in particular the \"big three\" -Wikidata, Yago and DBpedia- are the backbone of many intelligent applications. While these three have seen steady development, comprehensive KB construction at large has seen few fresh attempts.\nIn this work, we propose to build a large general-domain KB entirely from a large language model (LLM). We demonstrate the feasibility of large-scale KB construction from LLMs, while highlighting specific challenges arising around entity recognition, entity and property canonicalization, and taxonomy construction. As a prototype, we use GPT-40-mini to construct GPTKB, which contains 105 million triples for more than 2.9 million entities, at a cost 100x less than previous KB construction projects.\nOur work is a landmark for two fields: For NLP, for the first time, it provides constructive insights into the knowledge (or beliefs) of LLMs. For the Semantic Web, it shows novel ways forward for the long-standing challenge of general-domain KB construction. GPTKB is accessible at https://gptkb.mpi-inf.mpg.", "sections": [{"title": "Introduction", "content": "General-world knowledge bases (KB) like Wikidata (Vrandecic and Kr\u00f6tzsch, 2014), Yago (Suchanek et al., 2007) and DBpedia (Auer et al., 2007) are important backbones for intelligent applications. While these projects exist for over a decade, innovation in the field of general-world KB construction is low, with neither fundamental paradigm shifts nor major novel projects emerging (Weikum et al., 2021).\nRecently, large language models (LLMs) stirred up many fields of AI (Bubeck et al., 2023), and also been proposed as sources for structured knowledge (Petroni et al., 2019). More specifically, Cohen et al. (2023) showed how, in principle, one can build a KB from an LLM by simple factual prompts and iterative graph expansion, but have not attempted this at scale.\nThe success of LLMs has also raised important intrinsic questions, in particular, what and how much these models know or believe (Petroni et al., 2019; Jiang et al., 2020; Roberts et al., 2020; Veseli et al., 2023; Sun et al., 2024; Wu et al., 2024b). A large set of benchmarks and studies investigate this via example-based prompting, e.g., to determine, how many answers to common benchmarking question answering (QA) datasets are known by LLMs. However, all these works remain non-exhaustive, investigating samples from specific datasets or domains, without attempting to materialize all knowledge of an LLM.\nIn this paper we propose to comprehensively materialize the knowledge/beliefs\u00b9 of LLMs into a KB."}, {"title": "Related work", "content": "Large-scale KB construction Dominating public large-scale KBs are Wikidata (Vrandecic and Kr\u00f6tzsch, 2014), Yago (Suchanek et al., 2007) and DBpedia (Auer et al., 2007), all started more than 10 years ago. While Wikidata is constructed by volunteers, Yago and DBpedia represent the paradigm of (semi-)structured information harvesting and integration, extracting in particular from Wikipedia infoboxes and Wikidata (Weikum et al., 2021). They all remain incomplete (Razniewski et al., 2024), warranting the search for novel paradigms. Commercial projects like the Google KG (Singhal, 2012) or Amazon's KG (Dong et al., 2020) have usually followed these approaches. By comparison, text-based KB construction, e.g., in NELL (Mitchell et al., 2018) or ReVerb (Fader et al., 2011), has achieved less adoption. Our approach is more related to the latter approaches, as LLMs are distillations of large text corpora."}, {"title": "Methodology", "content": "An overview of our approach is shown in Fig. 1. In the first phase, we iteratively elicit LLM triples for a given subject, and enqueue newly encountered named entities for further triple elicitation. In the second phase, we consolidate the resulting triple set by canonicalizing entities, relations and classes, and by constructing a coherent taxonomy.\nOur paradigm is that as much knowledge as possible should come from the LLM itself, we therefore refrain from imposing any standardized vocabu-"}, {"title": "Knowledge elicitation", "content": "Iterative graph expansion We start the extraction process from a single seed subject, Vannevar Bush, the visionary behind the concept of hyperlink-based knowledge organization (Bush, 1945). From the triples obtained for him, just like in web crawling, we can then identify further entities (e.g., MIT (affiliation) or Everett, MA (birth place)), for which we can then elicit further knowledge, and so on (Cohen et al., 2023).\nKnowledge prompting A major challenge in knowledge elicitation is to elicit as much knowledge as possible, but at the same time, not encouraging hallucinations. We found that without guidelines on the expected number of triples, LLMs systematically returned much fewer triples than they could correctly return. However, a static number would not be suitable either, as e.g., for Albert Einstein, an LLM should return many more triples than for the average person. We solve this via a subtask where the LLM first specifies the number of triples it believes to know for the subject, with two ranges as orientation. In difference to (Cohen et al., 2023), we also streamlined the process by dropping the separate elicitation of relations and relation-specific triples. To structure the knowledge, we also request that at least one instance Of triple should be returned. Output parsing is eased"}, {"title": "Knowledge consolidation", "content": "Because input prompt size directly relates to the complexity and cost of prompting, it is not possible to feed a large amount of existing entity or taxonomy knowledge into the knowledge elicitation phase. Consequently, the output exhibits a huge degree of redundancy and variance, which we consolidate post-hoc.\nRelation clustering The naive process generates 688,855 distinct relation names, with many obvious duplicates, e.g., instanceOf, isA, or InstanceOf. To remove redundancies within this set, we apply greedy clustering, based on embedding similarity computed via SentenceTransformers (Reimers and Gurevych, 2019). Specifically, we compare each relation R with all more frequent ones, starting from the most frequent one, and merge relation R into relation S, if the textual embedding similarity between the names of R and S is greater than:\n$1.2 \\times \\frac{\\text{log (freq(R))}}{\\text{log (freq(most\\_freq\\_relation))}}$\nIn particular, the formula is designed so that the similarity threshold varies with the frequency of the relation, leading to a more aggressive removal of relations that occur with low frequency. This way, we reduce the number of relations to 2,133 (a 323x reduction).\nClass clustering The naive process also generates 83,770 distinct class names (objects for instanceOf), with both obvious duplicates, and many overly specific cases. We employ the same greedy clustering as for relations, with the same multiplier 1.2 in the merging criterion. This way, we reduce the number of classes to 367.\nTaxonomy construction The classes in the KB so far do not form a coherent, or even connected taxonomy, as the knowledge elicitation process only expands named entities. But we also cannot simply prompt for a complete taxonomy to put on top (e.g., following the approach in (Funk et al., 2023)), because we need to include the existing classes. We chose to proceed in three steps: In step 1, we prompt the LLM to generate an initial high-level taxonomy of about 50 classes (see prompt in Fig. 4 (top)). In step 2, we prompt the LLM to assign to each class in the KB a score describing how general it is (see prompt in Fig. 4 (upper middle)), then use that score to rank the classes from most general to most specific. In step 3, we insert classes into the taxonomy, one at a time. We initially tried this with the full taxonomy as input, but found that the LLM struggled. We therefore now proceed recursively. Starting from the nodes below the root, we ask the LLM repeatedly, whether the given class to insert belongs below one of them, in which case we repeat this process recursively with that node's children (see prompt in Fig. 4 (lower middle)). The recursion stops either when the given class is not a subclass of any child anymore (in which case it is inserted as sibling), or when a leaf is reached (in which case it is inserted as new child). Then we prompt LLM to update the (sub)taxonomy from current node with the given class (see prompt in Fig. 4 (bottom)). We feed the final taxonomy back into GPTKB via the rdfs:subClassOf relation. Further LLM-based refinement in the style of (Peng et al., 2024) could be considered."}, {"title": "Implementation", "content": "LLM choice and parallelization We chose GPT-40-mini (OpenAI, 2024) for our experiments, because of its relatively good tradeoff between performance and cost, and its ability to process requests in batches. This means we can send multiple subjects from our queue at the same time, after startup, typically 5,000 entities per batch, and up to 100 batches in parallel. The model's size is not publicly released, but has been estimated to be around 8B.\nSeed entity, result size, runtime and cost We start the process from Vannevar Bush, the visionary of interlinked knowledge management. We require a total of 2,200 batches to prompt GPT for 5.8M entities, obtaining in the answers triples for over 2.9M entities of them, which took us about 27 hours. The subject queue was still not empty at that point, but contained overwhelmingly duplicate or hallucinated subjects (see discussion below). Including trial runs, constructing GPTKB costed us a total of $2,200 for OpenAI API calls.\nGPTKB statistics Our KB contains a total of 105M triples for 2.9M entities, organized into 2,133 relations and 367 classes. This gives an average of 36 triples per subject, with two distinct clusters, in particular, 651K entities with 10 triples and 86K with 50 triples, with most others near these values. Of all triples, more than 37M have an entity as object, and more than 67M have a literal as an object. The average length of entity labels is 24.5 characters. Example output for Vannevar Bush is shown in Table 2.\nDataset provision and license We provide our KB both as a download (3.8 GB in TTL format), via a web browsing interface, and via a SPARQL query endpoint at https://gptkb.mpi-inf.mpg.de."}, {"title": "Analysis", "content": "GPTKB content\nThe most frequent classes generated for entities are shown in Fig. 5, where we find that patent and Person dominate the dataset. Several more classes are actually subclasses of Person, e.g., Noble, Duke, historical figure. Including these, the total number of humans is close to 600K. We also find a largely hallucinated class, US Coast Guard cutters, among the top-3.\nThe most frequent properties in the whole KB are patentCitation (3.15M) and instanceOf (2.96M). with similarly generic properties following at the KB level. At the class level, we find more specific properties, for instance, the most frequent properties in the class Person are instanceOf (251K), hasOccupation (126K), knownFor (119K), nationality (114K).\nWe also analyze the geographic bias of our KB, using the listed nationalities as proxy. The results are shown in Fig. 6. We can observe a clear bias towards English-language nationalities, stronger than, e.g., in Wikidata (Shaik et al., 2021), and a curious lack of others (e.g., Chinese only 2K), likely reflecting the (undisclosed) English-centric training corpus of GPT-40-mini. Further interesting observations concern the LLM's reluctance to express the gender property (only 30K triples, with female at 15K more present than male at 8K), likely reflecting the measures taken towards hiding sensitive attributes, and active debiasing."}, {"title": "Wikidata comparison", "content": "We compare with Wikidata on several aspects: First, we compute the fraction of subjects that exist in Wikidata. For a random sample of 200 subjects from GPTKB, 24% have an entity with exactly matching label in Wikidata. A further 6.5% have a non-empty search result, i.e., an entity of paraphrased or similar label. The remaining 69.5% appear novel. Second, we exemplarily look at the 41 triples for Vannevar Bush, of which we find that more than 10 are not contained in Wikidata, e.g., his affiliation with the US government, his children count (incorrect by 1), or him inventing the concept of hypertext. Third, we identify several properties not modelled at all in Wikidata, for instance, historicalSignificance (270K triples), hobbies (30K triples), or hasArtStyle (11K triples). This indicates that GPTKB potentially contains a significant amount of novel knowledge. A more comprehensive KB comparison in the style of (F\u00e4rber et al., 2018) is planned."}, {"title": "Precision and hallucinated content", "content": "Evaluating the precision of large-scale KBs is not straightforward, because they contain a significant amount of long-tail knowledge, for which finding evidence or counter-evidence is difficult. In line with previous work (Suchanek et al., 2007), we evaluate precision within the context of web-retrievable information.\nIn particular, for a given triple, we retrieve the top-5 web-page snippets for the search term <subject object> from a search engine API, then use another LLM, namely Llama-3.1 (?), to judge whether the given triple appears true/plausible/implausible/false, given the snippets. We adapt the prompt used by Adam and Kliegr (2024), extending it with the \u201cfalse\u201d level. From a random sample of 200 triples, we find that, based on the snippets, 22.5% appear true, 57.5% appear plausible, 1% appear implausible, 19% appear false. We also sample 200 triples from entities that are instances of Person, finding there that 21.5% of their triples appear true, 52.5% appear plausible, 0% appear implausible, 26% appear false. Extrapolating the former results, we can estimate that GPTKB contains approximately 24M triples that can be web-verified as true, 60M that appear plausible according to web context, 1M that appear implausible, and 19M that are contradicted by web context.\nIn terms of subjects, we observed a wide variance. While for some classes, e.g., Person or Company, most entities appeared real, others showed a strong runaway, e.g., patents, where most codes were made up (e.g., US_04,500,002_A1), or United States Coast Guard Cutter (the LLM continuously added varying incorrect type numbers to real names, e.g., USCGC_Biscayne_(WLB-201)). We therefore also evaluate the web verifiability of subjects alone. Similar to the approach used for triples, we employ a search engine to retrieve 5 snippets, now given only the entity's name as query. We then evaluate three levels: (i) The snippets contain an entity of exactly that name, (ii) the snippets make it likely that the entity exists, perhaps under a slightly different label, (iii) the snippets give no support for the existence of that entity. From a random sample of 200 entities, we find that 41.5% fall into the first category, 43.5% into the second, 15% into the third, implying an extrapolated 1.2M verifiable, 1.3M plausible, and 0.4M questionable KB subjects. Among subjects classified as Person, 67%"}, {"title": "Lessons for LLM epistemiology", "content": "LLMs and the way they store, retrieve, and generate knowledge are under intense scrutiny from computational, as well as cognitive and philosophical perspectives (Nosta, 2024). We have shown that one can iteratively materialize internal knowledge of an LLM at an unprecedented scale, but the notion and definition of LLM knowledge itself is controversial (Fierro et al., 2024). We adopt here the term knowledge base because it is common in the field, but would consider the term belief base equally appropriate. In terms of the definitions of knowledge that are introduced by Fierro et al. (2024), our output falls into the minimalistic sui-generis (g-knowledge) category, as our KB may contain false as well as inconsistent triples.\nWe can now, in principle, relate the number of parameters of an LLM to the amount of entity-centric triple knowledge it holds: As discussed in Section 4, GPT-40-mini likely has in the order of 8B parameters. Given the 105M triples that we obtained, that makes 76 parameters per triple. We emphasize that this number captures only encyclopedic knowledge, yet that LLMs also possess other knowledge, e.g., linguistic knowledge, procedural knowledge, etc.\nAs already observed by Petroni et al. (2019), prompt formulations heavily influence LLM re-"}, {"title": "Lessons for KB construction", "content": "The GPTKB prototype reveals several important lessons for LLM-based KB construction. In particular, we find it notable that building such a large KB was possible so quickly, with a relatively small model.\nPrecision-recall trade-off The biggest challenge in our view is precision, both in terms of hallucinated entities, and triples. We do not expect that larger models alone will solve this problem, because the long tail, where hallucinations occur, would likely just be pushed farther, but remain difficult to delineate. Tuning the precision-recall trade-off, for example, via more conservative prompts, or via thresholding based on elicited confidence values (Xiong et al., 2023), might be a way forward.\nConsolidation challenges Our exploration surfaced a potpourri of other challenges, some of them known to KB construction research since years (Weikum et al., 2021), others requiring novel adaptations in the light of LLMs. These concern, in particular, (1) NER for short labels without context, (2) entity deduplication, (3) entity canonicalization, (4) literal typing and canonicalization, (5) relation clustering, (6) relation organization in terms of subrelations, (7) class clustering, (8) taxonomy construction, and (9) triple verification. While we explored simple techniques for 1, 2, 5, 7 and 8, each has room upward, and the other tasks were not treated so far.\nCost-effectiveness The GPTKB approach deviates from traditional Wikimedia- and data-integration focused KB construction, and although its precision still needs improvement, it stands out with its potential for cost efficiency. In a back-of-the-envelope calculation, Paulheim (2018) estimated the cost per triple for existing manual KB construction projects at $2-6, and for existing automated KB construction projects at $0.01-0.15. In contrast, in our prototypical execution, the cost is just $0.00009 per correct triple ($2.2K/24M triples), i.e., over 100x less than with previous methods."}, {"title": "Other LLMs", "content": "We performed a parallel exploration using Llama 3.1 70B on local HPC hardware, but found this not competitive in terms of runtime. We also envisioned a run using the strongest publicly available LLM, GPT-40, however, by its 15x higher API cost, and its estimated 25x larger parameter set, assuming knowledge is roughly proportional to parameters, at about $825K, this is beyond our budget."}, {"title": "Conclusion", "content": "We proposed to build large general-domain KBs entirely from LLMs. We showed that large-scale KB construction from LLMs is feasible, while highlighting specific challenges arising around precision, and KB construction tasks like entity recognition, entity and property canonicalization, and taxonomy construction. As a prototype, we used GPT-40-mini to construct GPTKB, which contains 105 million assertions for over 2.9 million entities, at a cost 100x cheaper than existing projects.\nOur work is a landmark for two fields: For NLP, for the first time, it provides constructive insights into what LLMs know (or believe). For the Semantic Web, it shows novel ways forward for the long stale topic of open-domain KB construction. GPTKB is accessible at https://gptkb.mpi-inf.mpg.de."}, {"title": "Limitations", "content": "GPTKB presents a proof of concept that so far does not satisfy the precision requirements of most downstream use cases, nor is its precision even accurately established, because it contains many long-tail triples without web sources that enable confirming or refuting their truth. The knowledge in our KB can intrinsically not be sourced back to any specific document and contributor. Also, as we do not prescribe any standardized vocabulary, and only apply lightweight consolidation, our KB does"}]}