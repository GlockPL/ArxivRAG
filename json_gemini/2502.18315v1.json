{"title": "GraphRank Pro+: Advancing Talent Analytics Through Knowledge Graphs and Sentiment-Enhanced Skill Profiling", "authors": ["Dr. Sirisha Velampalli", "Chandrashekar Muniyappa"], "abstract": "The extraction of information from semi-structured text, such as resumes, has long been a challenge due to the diverse formatting styles and subjective content organization. Conventional solutions rely on specialized logic tailored for specific use cases. However, we propose a revolutionary approach leveraging structured Graphs, Natural Language Processing (NLP), and Deep Learning. By abstracting intricate logic into Graph structures, we transform raw data into a comprehensive Knowledge Graph. This innovative framework enables precise information extraction and sophisticated querying. We systematically construct dictionaries assigning skill weights, paving the way for nuanced talent analysis. Our system not only benefits job recruiters and curriculum designers but also empowers job seekers with targeted query-based filtering and ranking capabilities.", "sections": [{"title": "1 Introduction", "content": "In the contemporary digital landscape, semi-structured data constitutes a significant portion of textual information, encompassing diverse documents such as invoices, resumes, business documents, and technical reports [9]. Unlike structured data, these documents lack a standardized format, leading to varied and subjective organizational structures. This variability poses a substantial challenge for traditional unstructured language models and logic-based parsing systems, rendering them insufficient in comprehensively addressing the intricate nuances of human-written styles.\nAmidst this complexity, the recruitment landscape has transformed dramatically, with a surge in online resume submissions facilitated by platforms like Info Edge Limited. However, this digital influx has introduced a new challenge: the overwhelming volume of resumes, making it arduous and time-consuming"}, {"title": "2 Related work", "content": "In the dynamic landscape of resume information extraction, diverse methodologies have been explored, each with distinct approaches and advantages. Traditional techniques like keyword search-based methods, rule-based methods, and semantic-based methods have been prominent, yet they often struggle to grasp the intricate nuances of skills and experiences due to the ever-evolving nature of job descriptions and applicant backgrounds [3].\nRecent strides have introduced innovative methods leveraging graph-based structures for skill processing. [2] pioneered a graph-based approach utilizing the MapReduce Programming model, enabling the extraction of common skill-sets from extensive resume datasets. Their foundational work integrated graph theory into talent analytics, offering a promising avenue for nuanced skill assessment.\nThe integration of sentiment analysis into skill evaluation marks a groundbreaking development. [4] introduced a methodology focused on feature selection, enhancing the efficiency of the resume selection process. Their research showcased a substantial reduction (50-94%) in the number of features recruiters needed to review, highlighting the potential of advanced techniques in streamlining hiring.\nAdditionally, [5] proposed a method combining the modified Boyer-Moore Method and Dice metrics-based string similarity verification. This hybrid approach empowers employees to sift through overwhelming resume databases efficiently, ensuring accurate query results.\nThe emergence of video resumes has presented novel challenges and opportunities. [3] introduced a framework for processing video resumes, analyzing the formation of personality traits and hirability impressions. This multimodal approach, integrating visual and verbal cues, provides a holistic understanding of candidates, revolutionizing how recruiters assess potential hires.\nIn recent years, the fusion of natural language processing and deep learning techniques has significantly enhanced resume parsing and skill extraction. [11] proposed methods enhancing resume parsing through natural language processing techniques, offering a more nuanced understanding of applicant qualifications. [17] delved into semantic resume parsing and skill extraction using deep learning, providing a more sophisticated approach to understanding the context and relevance of skills mentioned in resumes.\nFurthermore, [18] introduced a graph-based resume analysis method tailored for job matching. Their approach utilized graph structures to represent both job requirements and applicant skills, enabling a more comprehensive and accurate matching process. This innovative method has opened new horizons in the realm of resume analysis and job matching.\nIn our pioneering work, we have taken a significant leap by attributing weights to sentiment words associated with skills. This innovative step enables us to attach these sentiment weights to edges within the graph structure. This nuanced approach not only refines the ranking method for jobseekers and organizations but also opens avenues for more granular skill evaluation. By integrating these latest advancements with our innovative graph-based methodology, we aim to"}, {"title": "3 Proposed Methodology", "content": "In this section, we explain the methodology that we will follow to extract information from the Resumes which will be useful for better ranking of JobSeekers based on their skills, projects and organizations.\nFirst the resume is parsed using techniques which include conversion of the document to text, identification of specific sections of the document using regular expression parsing for generic heading keywords and whitespace patterns, Part-Of-Speech tagging, regular expression parsing for absolutely identifiable entities, gazetteer matching for well known words and Named Entity Recognition for Person Names, Locations, Skills and Organizations. We then identify the sections of name and address, skillsets, projects and organizations and retrieve those text blobs. Then we build the knowledge graph which will capture the relations of people, skills, organizations and projects. We however do not identify and trying to normalize the projects as we are not interested in unifying the project descriptions which can be different by different jobseekers for the same job including the title of the project. As we are only interested in the signals in the project description we need not unify or normalize the projects.\nBuilding Gazetteers We create a mini-gazetteer of positive keywords with different weights of positivity for different skills which we call skill-sentiment-gazetteer. For example, in the software domain design, scalability, robust, debugging, distributed, client-server etc., are strong keywords which indicate that the project requires greater skill than a project without such keywords. In the management domain team player, lead, cohesive, align, hire etc., are keywords with strong positive influence on the work involved in the project. We employ sentiment analysis and concordance extraction for retrieving such strong keywords."}, {"title": "Building the Knowledge Graph", "content": "The sections identified in the resume are used to build a knowledge graph in the following step-wise method.\n1. The name of the jobseeker and his/her attributes form the identity of the jobseeker which is represented in the node <JobSeeker1> and the skills of the jobseeker are parsed and normalized there by enabling us to build skill nodes in the graph. Eg. <C++> node in Figure 2.//\n2. The details of the project/experience that the jobseeker has put in the resume are parsed for organization/client details thereby making the organization node and the project node.\n3. The parsed project/experience text is searched for mention of skill and keywords are looked up against the aforementioned skill-sentiment-gazetteer to deduce weights of the particular skill which we assign to the edge from the skill to the project.\n4. The edge from the jobseeker to the skill is weighted as the average of the weights of the particular skill in different projects thereby allowing us to calculate overall strength of the skill that the candidate has.\n5. The edge from the Organization to the skill is also deduced as the average of all the skill-project edges of different jobseekers who were in a particular project using the skill.\n6. We also extract duration which is a strong indicator of the development of a skill overtime for a person. The duration is also used to add to the weight of the jobseeker-skill edge."}, {"title": "4 Implementation Details", "content": "Our implementation process begins with the construction of a comprehensive skills dictionary. We aggregate skills from various internet sources, including career sites (accessible through APIs), Wikipedia utilizing wikibots, and datasets"}, {"title": "4.1 Dataset Processing:", "content": "We utilize resumes from the paper [2] as our dataset. Each resume undergoes processing following the methodology outlined in Figure 1. Initially, the document is converted into plain text format using Apache Tika. Standard NLP techniques are applied for minimal stop word removal, skill normalization, and organization normalization. Section identification is performed through pattern recognition techniques and section header matching. We extract project details, skills sections, and names from the resumes. Each jobseeker is assigned a unique identity. POS tagging using SpaCy, regular expression-based entity matching, skill gazetteer matching, and Named Entity Recognition are employed to identify entities. The processed information is then transformed into JSON files containing the relevant keys and values."}, {"title": "4.2 Graph Construction:", "content": "The JSON structure serves as the foundation for building the graph, utilizing Neo4j, a popular graph database. We assess the positivity of keywords and the frequency of positive words, assigning weights to specific <skill, project> edges. The weight assignment is based on initial bootstrap values ranging from 0 to 1, denoting different classes of keywords in the skill-sentiment gazetteer. The overall sentiment for a single project description is calculated as the average sentiment weight value of its constituent words. If multiple skills are described, the same sentiment weight value is assigned to each corresponding <skill, project> edge. The weights on <jobseeker, skill> edges are learned from <skill, project> edges, normalizing as similar resumes are processed, ensuring accurate quantification of <jobseeker, skill> relationships.\nThis JSON structure is used to build the graph using the steps mentioned in the section \"Proposed Methodology\". We use popular graph databse Neo4j to build the graph. We detect the positivity of the keywords and the number of times the positive words have been used to assign weights to particular <skill, project> edge. The weight to positivity is calculated by initial bootstrap values of 0 to 1 assigned to different classes of keywords in the skill-sentiment gazetteer. The overall sentiment from a single project description will be the average over the sentiment weight values of each of its constituent words. If multiple skills are described in the description we assign same sentiment weight value to each <skill, project> edge. Since the weights on <jobseeker, skill> edges are learnt from <skill, project> edges, as more number of similar resumes are parsed these weights normalize resulting in a better quantification of the <jobseeker, skill> edges."}, {"title": "5 Results and Analysis", "content": "In this section, we will present dataset statistics, comparisons with other approaches and analyse the reasons for superiority of our proposed approach."}, {"title": "5.1 Dataset Statistics:", "content": "Before delving into the results and comparisons, it's essential to understand the dataset's key statistics, which provide context for the subsequent analysis.\nNumber of Resumes: 1000 Industries Represented: 15 (including IT, Healthcare, Engineering, Finance, etc.) Experience Levels: Entry-Level (30Skills Categories: Programming Languages, Operating Systems, Database Technologies, Middleware Technologies, Scripting Languages, Web Technologies, Soft Skills, Certifications Average Number of Skills Mentioned per Resume: 12 Average Number of Projects Mentioned per Resume: 2 Geographical Diversity: Resumes sourced from 25 countries Education Levels: Bachelor's (40%), Master's (35%), Ph.D. (15%), Others (10%)"}, {"title": "5.2 Results:", "content": "Table 1 presents the comprehensive evaluation metrics for the developed resume processing system. The system's accuracy in extracting skills, determining sentiment, and ranking resumes based on skills are highlighted.\nSkill Extraction Accuracy:\nPrecision: The system achieves a precision rate of 92\nRecall: With a recall rate of 88\nF1-Score: The Fl-score, calculated at 90\nSentiment Analysis Accuracy (Positive/Negative/Neutral):\nAccuracy: The sentiment analysis accuracy stands at 85\nPrecision and Recall: The precision and recall rates, both around 86% and 84% respectively, highlight the system's ability to accurately classify sentiments associated with skills.\nGraph-based Ranking Performance:\nTop 3 Relevant Resumes: The system achieves an impressive accuracy of 78% in identifying the top 3 most relevant resumes based on skill matching.\nTop 5 Relevant Resumes: Extending the evaluation to the top 5 resumes, the accuracy increases to 85%, indicating the system's effectiveness in broader candidate selection.\nTop 10 Relevant Resumes: With a remarkable accuracy of 90%, the system excels in identifying the top 10 relevant resumes, showcasing its potential for large-scale recruitment processes."}, {"title": "5.3 Comparision with other approaches", "content": "In this section, we compare our graph-based approach with traditional methods such as keyword search, rule-based methods, and semantic-based methods in the context of skill extraction, sentiment analysis, and ranking of relevant resumes. Our innovative methodology outperforms existing techniques in several key aspects:\nSkill Extraction Accuracy: Our graph-based approach achieves a remarkable skill extraction accuracy of 92%, significantly surpassing keyword search (72%), rule-based methods (85%), and even semantic-based methods (88%) can be seen in Table 2. This superior accuracy ensures precise identification of skills from resumes, a crucial factor in talent evaluation.\nSentiment Analysis Accuracy: While traditional methods like keyword search and rule-based approaches struggle with sentiment analysis, our graph-based approach achieves an accuracy of 85%. This capability is essential for understanding the context and tone associated with skills mentioned in resumes, providing deeper insights into candidates' qualifications.\nTop Relevant Resumes Ranking: When it comes to ranking relevant resumes, our graph-based approach outperforms other methods comprehensively. We achieve an accuracy of 78% for the top 3 resumes, 85% for the top 5 resumes, and an impressive 90% for the top 10 resumes can be seen in Table 3. In contrast, keyword search, rule-based, and semantic-based methods lag behind, emphasizing the efficacy of our approach in identifying the most suitable candidates."}, {"title": "6 Conclusion and Future Work", "content": "We presented the first study of a method of adding sentiment signals to skills from resumes. We built a system that effectively extracts information from resumes and using systematically built dictionaries assigns weights to skills at a project level. The graph built from such information enables us to rank and query various combinations of requirements that can be of use for hiring. In the future, we plan to use Graph Neural Networks which enable efficient similarity searching. We also plan to enrich this graph topology to represent stochastic job shifts and then perform DeepWalk to find patterns of job shifts which enable finding patterns of retainable employees and volatile employees in various technology skill sets. It will also help organizations to determine predictable associative times of their workforce and use retention methods or augment with similar or complementing workforce for business continuity."}]}