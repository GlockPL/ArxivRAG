{"title": "HACD: Harnessing Attribute Semantics and Mesoscopic Structure for Community Detection", "authors": ["Anran Zhang", "Xingfen Wang", "Yuhan Zhao"], "abstract": "Community detection plays a pivotal role in uncovering closely connected subgraphs, aiding various real-world applications such as recommendation systems and anomaly detection. With the surge of rich information available for entities in real-world networks, the community detection problem in attributed networks has attracted widespread attention. While previous research has effectively leveraged network topology and attribute information for attributed community detection, these methods overlook two critical issues: (i) the semantic similarity between node attributes within the community, and (ii) the inherent mesoscopic structure, which differs from the pairwise connections of the micro-structure. To address these limitations, we propose HACD, a novel attributed community detection model based on heterogeneous graph attention networks. HACD treats node attributes as another type of node, constructs attributed networks into heterogeneous graph structures and employs attribute-level attention mechanisms to capture semantic similarity. Furthermore, HACD introduces a community membership function to explore mesoscopic community structures, enhancing the robustness of detected communities. Extensive experiments demonstrate the effectiveness and efficiency of HACD, outperforming state-of-the-art methods in attributed community detection tasks. Our code is publicly available at https://github.com/Anniran1/HACD1-wsdm.", "sections": [{"title": "1 INTRODUCTION", "content": "Community detection [29] is a fundamental problem in network analysis, seeking to unveil closely connected subgraphs (i.e., communities) within complex networks. Previous research has adeptly utilized network topology to discern communities [6, 9]. However, nodes in real-world networks typically possess rich attribute information. For example, in citation networks [32], papers are associated with specific keyword domains. Such networks, known as attributed graphs [30], introduce additional complexity for community detection algorithms.\nTo harness the potential of topology and attribute information for attributed community detection (ACD), existing methods, e.g., CommDGI [35] and ACDM [4], map these dual information sources to low-dimensional continuous vector spaces by using embedding techniques. While these methods have demonstrated promising results, we contend that current solutions may not be optimal because they overlook two critical issues:\n\u2022 Semantic similarity. Semantic similarity refers to the degree of semantic resemblance or the extent of correlation between attributes. For instance, as illustrated in Figure 1, the semantic similarity of attributes can reveal latent relationships between nodes and enhance the attribute cohesiveness of detected communities [7]. However, existing methods usually disregard the semantic similarity between node attributes within communities, leading to the omission of crucial nodes in the detected communities."}, {"title": "2 PRELIMINARIES", "content": "2.1 Problem Statement\n2.1.1 Attributed Network. An attributed network [1] is typically denoted by a graph $G = (V, E, A)$, where $V = {v_1, v_2, ..., v_n}$ represents the set of n nodes. $E \\subset {(v_i,v_j) | v_i, v_j \\in V}$ is the edges sets where each edges connect two nodes in the graph. $A = {a_1, a_2,..., a_n }$ is the set of node attributes for all nodes, where $a_i$ is the attributes of node $v_i$. In addition, each node $v_i \\in V$ is associated with some types of d-dimensional attribute feature vectors, the feature matrix can be represented as $X = {x_1, x_2, . . ., x_n}^T \\in \\mathbb{R}^{n \\times d}$\n2.1.2 HACD-Problem. Given an attributed network $G = (V, E, A)$, the problem of attributed community detection based on heterogeneity returns attributed communities $C = {C_1, C_2, ..., C_k}$ from a heterostructure aspect, satisfying the following properties (i) structure cohesiveness, where nodes within each community are tightly connected, while nodes in different communities are sparsely connected, and (ii) attribute cohesiveness, where the attributes of nodes within a community have a semantic similarity."}, {"title": "2.2 Attribute cohesiveness.", "content": "Usually, the attribute score [14] is used to measure the attribute cohesiveness of a community. Given two nodes u, v, the attribute score is denoted as $Ascore(u, v)$. For different types of attributes, we can employ different methods, such as Euclidean distance and Jaccard distance [11], to calculate the attribute score of two nodes. When different types of attributes co-exist, we can employ a unified function to combine different distance functions, e.g., $Ascore(u, v) = \\alpha \\frac{Sdist(u,v)}{Sdist_{max}}+(1-\\alpha )\\frac{Tdist (u,v)}{Tdist_{max}}$, where $Sdist(u, v)$ and $Tdist(u, v)$ compute the numerical distance and textual distance, respectively; $Sdist_{max}$ and $Tdist_{max}$ are the maximum numerical distance and maximum textual distance, respectively, for normalization; the parameter $0 \\leq \\alpha \\leq 1$ is used to balance numerical proximity and textual relevancy."}, {"title": "2.3 Structure cohesiveness.", "content": "Modularity reflects the quality of community structure in a network, which is a commonly used performance metric to measure the structure cohesiveness of communities [21, 34]. The traditional definition of modularity[19] is based on the adjacency matrix of a graph, and the modularity function is defined as follows:\n$Q = \\frac{1}{2M} \\sum_{i,j}(A_{i,j} - \\frac{k_i k_j}{2M} ) \\delta (c_i, c_j)$\nwhere M denotes the number of edges in the graph; $A_{ij}$ can be understood as the observed structural information between two nodes $v_i, v_j$, for example, the edge between nodes $v_i$ and $v_j$; $k_i$ denotes the degree of node $v_i$; as well as $\\delta (c_i, c_j)$ denotes the connectivity between community $c_i$ and community $c_j$, which can be calculated based on the community division. A common way to calculate it is to define a connectivity matrix $\\delta$, where $\\delta_{ij}$ denotes whether node $v_i$ and node $v_j$ are in the same community, i.e., $\\delta(c_i, c_j) = 1$ if $c_i = c_j$, 0 otherwise."}, {"title": "3 METHODOLOGY", "content": "3.1 Overall Framework\nTo address the above challenges, we introduce a novel HACD method, as shown in Figure 2, that comprises three key components: graph constructing and encoding, attribute-level attention mechanism, and community membership function."}, {"title": "3.2 Graph Constructing and Encoding", "content": "Traditional graph construction methods typically rely on homogeneous structures, where attribute information is directly encoded, making it challenging to uncover the semantic nuances therein. To delve deeper into attribute information, departing from conventional homogeneous attribute graph approaches, we introduce heterogeneous graphs, treating node attributes as an additional node type to catch semantic similarity.\nOur approach centers on the construction of a heterogeneous attribute graph, denoted as $G = (V, E, A)$. Initially, we define the node and edge types within the desired heterogeneous graph. Here, the original attribute information $A = {a_1, a_2, ..., a_n}$ is treated as an additional node type, complementing the intrinsic node types $V = {v_1, v_2, ..., v_n}$ within $G$. The resulting set of nodes in the heterogeneous graph is represented as $V$, encompassing various distinct node types. The relationship between the original node entities and attribute node entities is delineated by possession, refining E to $E \\subset {(v_i,v_j), (v_i, a_i) | v_i, v_j \\in V, a_i \\in A}$. Thus, we derive the heterogeneous graph $G = (V, E)$. Notably, $G$ is characterized by a node type mapping function $\\phi(v) : V \\rightarrow A$ and an edge type mapping function $\\varphi(e) : E \\rightarrow R$, where A and R denote the sets of predefined node types and edge types, respectively, with $|A| + |R| > 2$.\nTo address the challenge of heterogeneity, meta-paths have become a staple in various heterogeneous graph embedding methodologies. However, traditional approaches often rely on manually predefined meta-paths, necessitating expert prior knowledge and potentially impacting model efficacy. In this work, we introduce a novel heterogeneous convolution module [2], denoted as $F^{(l)}(\\cdot)$, designed to automatically generate and extract effective meta-path schemes. Mathematically, the module operates as follows:\n$A_{node}^{(l)} = F^{(l)}(A_{ele} | e \\in T^l) = \\sum_{e \\in T^l} \\alpha_e A_e,$\nwhere, $A_{node}^{(l)}$ and $A_{ele} \\in T^l$ represent the set of local bipartite graphs in $G$ and the edge type set of the graph $T^l$, respectively. $\\alpha_e$ denotes a layer-wise independent parameter to be learned, signifying the contribution of the sub-graph of type e to the convolved structures. Recognizing that the neighbors of each node play distinct roles and carry varying degrees of importance in learning node embeddings, we then propose to embed nodes using node-level attention inspired by HAN [28], facilitating the capture of complex structures and rich semantic information. Specifically, we compute the importance between node pairs based on meta-paths and normalize them to obtain the weight coefficient $\\alpha_{ij}^p$ via the softmax function:\n$\\alpha_{ij}^p = \\frac{exp(\\sigma(\\alpha_p \\cdot [h'_i || h'_j]))}{\\sum_{k \\in N_i^p} exp(\\sigma(\\alpha_p \\cdot [h'_i || h'_k]))},$\nwhere $\\sigma$ denotes the activation function, $||$ signifies the concatenation operation, $\\alpha_p$ represents the node-level attention vector for the meta-path, and $h'$ projects the features of different node types into the same feature space.\nSubsequently, the meta-path-based embedding of node i is aggregated by the projected features of its neighbors with the corresponding coefficients as follows [28]:\n$h_i^p = \\sigma(\\sum_{j \\in N_i^p} \\alpha_{ij}^p h'_j),$\nwhere $h_i^p$ represents the learned embedding of node i for meta-path p, and $N_i^p$ denotes the meta-path-based neighbors of node $v_i$. By obtaining the meta-path set ${p_0, p_1, ..., p_m}$ through Formula (3),"}, {"title": "3.3 Attribute-level Attention Mechanism", "content": "Through conventional encoding, the resulting node embeddings learn the significance of different neighbors of nodes in each meta-path for the specific task at hand. However, they may fail to reflect the semantic importance of node attributes. A straightforward approach involves designing an attention mechanism capable of directly performing weighted summation or averaging on node attributes based on attention weights, subsequently aggregating them to the nodes to derive the final node representation:\n$\\beta_{ij} = att(x_i, x_j), \\forall j \\in N_i,$\n$h_i = \\sum_{j \\in N_i} \\beta_{ij} x_j,$\nwhere $x_i$ represents the attributed information of node $v_i$, and $N_i$ denotes the neighbors of node $v_i$. However, this simplistic attention mechanism treats all node types equally, disregarding the intricate relationships between different types of nodes in heterogeneous graphs. To address this, we propose a novel meta-path-based attribute-level attention mechanism to automatically learn the semantic importance of different attributes in meta-paths and fuse them for attributed community detection tasks. Taking m groups of semantic-specific node embeddings learned from node-level attention as input, the learned weights of each meta-path $(\\beta_{p_0},..., \\beta_{p_m})$ are calculated as follows:\n$(\\beta_{p_0},..., \\beta_{p_m}) = att_{sem}(H^{p_0},...,H^{p_m}),$\nwhere $att_{sem}$ denotes the deep neural network performing the attribute-level attention. Initially, we average the importance of all semantic-specific node embeddings to determine the importance of each meta-path. The significance of each meta-path, denoted as $wp_i$, is computed as follows:\n$\\frac{1}{|V|} \\sum_{i \\in V} q^T \\tanh(W\\cdot h_i^p + b),$\nwhere $W \\in \\mathbb{R}^{d' \\times d}$ represents the weight matrix, $b \\in \\mathbb{R}^{d' \\times 1}$ denotes the bias vector, and $q \\in \\mathbb{R}^{d' \\times 1}$ signifies the semantic attention vector [28]. To this extent, we obtain the importance of each meta-path, which can help draw key attributes of communities.\nTo learn the importance of different attributes in each meta-path and fuse the semantic similarity between attributes within the community, we propose to utilize the node similarity metric to update the importance of meta-paths. Recognizing the limitations of Euclidean distance in measuring node similarity in graph data due to the curse of dimensionality and differences in feature weight, we employ an attention-based similarity score [3]:\n$s_{ij} = (x_i^T u) x_j,$\nwhere $x_i$ and $x_j$ denote the attributed feature vectors of node $v_i$ and node $v_j$, respectively, and u represents a non-negative trainable weight vector. Subsequently, we normalize the attention-based similarity scores to obtain the attribute coefficient $\\gamma_{ij}$ as follows:\n$\\gamma_{ij} = \\frac{exp(s_{ij})}{\\sum_{k \\in N_i} exp(s_{ik})}$\nIntuitively, nodes with more similar attributes tend to exert greater influence on nodes within the target community. To adaptively adjust the relative importance of meta-path semantic and attributed semantic similarity, we introduce two learnable parameters $\\ell$ and $\\ell_a$, denoted as $q'$ and $q_a'$, respectively. They are formally expressed as follows:\n$q' = \\frac{exp(\\ell)}{exp(\\ell) + exp(\\ell_a)},$\n$q'_a = \\frac{exp(\\ell_a)}{exp(\\ell) + exp(\\ell_a)},$\nAfter that, we combine the meta-path coefficient $wp_i$ and the attribute coefficient $\\gamma_{ij}$ to compute the attribute-level importance coefficient $\\beta_{p_i}$:\n$\\beta_{p_i} = q'_a \\sum_{i, j \\in p_i} \\gamma_{ij} + q' \\cdot wp_i$\nWith the learned attribute-level importance coefficients, we fuse all semantic-specific embeddings to obtain the final embedding H:\n$H = \\sum_{i=1}^P \\beta_{p_i}\\cdot H^{p_i}$\nThis process further integrates the attribute-based semantic similarity, effectively capturing the nuanced relationships between attributes and nodes within the community.\nHowever, the aforementioned process introduces a large number of trainable parameters to extract semantic information, necessitating the task of uncovering additional supervised signals to ensure training accuracy. To address this challenge, we integrate the concept of contrastive learning. Through self-supervised learning, we aim to unearth latent signals. Intuitively, the embedding of nodes within each community should exhibit similarity, ideally minimizing the distance between nodes within the community:\n$L_{intra} = \\sum_{C \\in C} \\sum_{i, j \\in C} dist (h_i, h_j),$\nwhere C represents the set of all communities. However, if we only consider similarities within communities, all nodes in the network may become similar, leading to the entire network being perceived as a single community. Therefore, it is crucial to ensure that node embeddings between communities are as dissimilar as possible. It can be formally expressed as:\n$L_{inter} = \\sum_{(C_1,C_2) \\in E_c} \\sum_{i \\in c_1, j \\in c_2} dist (h_i, h_j),$\nwhere $E_c$ denotes the set of edges between communities, and $c_1, c_2$ represent different communities. Inspired by recent work of contrastive learning [12, 38], which aims to learn effective representations by minimizing the distance between similar samples and maximizing the distance between dissimilar samples, we construct the objective function for attribute cohesiveness:\n$L_A = r_1L_{intra} - r_2L_{inter},$\nwhere $r_1$ and $r_2$ serve as controlling parameters. This formulation encourages the embeddings of nodes within the same community to be similar while promoting dissimilarity between nodes from different communities."}, {"title": "3.4 Community Membership Function", "content": "A traditional approach to detecting communities relies on modularity optimization, typically employing greedy algorithms or constructing modularity matrices. High-quality communities exhibit high modularity, indicating dense connections within communities and sparse connections to nodes outside the community. However, directly capturing information from connections may lead to suboptimal results, as it overlooks the joint recognition of information from nodes, edges, and neighborhoods with special attention in the deep learning process. Deep neural network-based community detection frameworks embed complex structural relationships and minimize loss, such as cross-entropy, over all possible permutations $S_c$ of community labels:\n$L = \\min_{\\pi \\in S_c} \\sum_{i=1}^n - log \\Theta_{i,\\pi(y_i)}.$\nHere, the softmax function identifies conditional probabilities that a node $v_i$ belongs to the community $C_k (\\Theta_{ik} = p(y_i = c_k))$. Notably, these approaches primarily focus on microscopic pairwise connections, neglecting modularity, which can reveal the inherent community structure during training.\nDrawing on recent research, we propose incorporating modularity into the training process to effectively capture the underlying community structure. However, the classical definition of modularity only emphasizes first-order proximity, which may oversimplify complex structures in real-world scenarios. To extend modularity to higher-order proximity, it requires redefinition:\n$Q = \\sum_{C_k \\in C} \\sum_{i,j} P_{i,c_k} P_{j,c_k} [A_{ij} - \\frac{k_ik_j}{2M}],$\nwhere, $Q_{i,c_k}, Q_{j,c_k} \\in [0, 1]$, and $\\sum_{C_k \\in C} P_{i,c_k} = \\sum_{c_k \\in C} Q_{j,c_k} = 1$. Additionally, we encode node category labels into one-hot vectors, constructing the initial community membership matrix M by integrating these vectors. Then, we concatenate M horizontally with the feature matrix X to form the updated matrix X'. After training, the attributed community detection model saves the learned community membership information as community membership embedding B, corresponding to $q_{i,c_k}P_{j,c_k}$. We can rewrite Q in matrix terms:\n$\\frac{1}{2M} tr(B^TPB),$\nwhere $P = A_{ij} - \\frac{k_ik_j}{2M}$. Based on the above, we design the CMF to guide embedding for preserving the inherent community structure. Modularity quantifies the disparity between the actual number of edges within a community and the anticipated number in a comparable network with randomly distributed edges. A higher modularity value indicates a stronger concentration of structural information within the community compared to random expectations. We formulate the CMF as a modularity optimization problem:\n$L_M = -Q.$"}, {"title": "3.5 Training", "content": "We prioritize the CMF as the main objective to obtain the division of communities on a global scale and further refine community members using the attribute cohesiveness function. The total loss is used for training as follows:\n$L = L_M + \\lambda L_A,$\nwhere $\\lambda$ is a controlling parameter that adjusts the impact of attribute cohesiveness."}, {"title": "4 EXPERIMENTS", "content": "In this section, we evaluate the effectiveness of our proposed HACD model on five real-world datasets by comparing it with seven state-of-the-art baseline methods.\n4.1 Experimental Setup\n4.1.1 Datasets. We use five public benchmark datasets widely employed in community detection [29, 35]: Cora, Citeseer, Amazon, Pubmed, and DBLP, all accessible from the SNAP website\u00b9. The distinct statistical properties of these different datasets make them suitable for reliably validating model performance. The statistics are summarized in Table 1.\n4.1.2 Baseline algorithms. To demonstrate the effectiveness of HACD, we compare it with several state-of-the-art methods:\n\u2022 GCN[10]: A fundamental graph representation learning model that operates directly on graph-structured data.\n\u2022 GAT[26]: A model that leverages masked self-attentional layers to assign different weights to different nodes in a neighborhood.\n\u2022 AnECI [15]: A framework for learning community information-based attributed network embedding by reconstructing higher-order proximity.\n\u2022 CDE[13]: A method that encodes potential community membership information based on nonnegative matrix factorization (NMF) optimization.\n\u2022 DANMF[31]: A deep autoencoder-like nonnegative matrix factorization model for community detection.\n\u2022 DAEGC [27]: A goal-directed graph clustering approach that employs an attention network to encode the importance of neighboring nodes and reconstructs the graph structure by training a decoder.\n\u2022 CommDGI[35]: A community detection-oriented graph neural network that uses a mutual information mechanism to capture neighborhood and community information."}, {"title": "4.1.3 Evaluation Metrics and Parameter Settings.", "content": "We use five widely adopted metrics to measure the performance of the methods: accuracy (ACC), F1-score (F1), normalized mutual information (NMI), adjusted rand index (ARI), and modularity. A better model should exhibit higher values across all metrics."}, {"title": "4.1.4 Parameter Settings.", "content": "We train our model for 400 iterations and maintain a fixed size of 32 for the embeddings. We use Adam to optimize the parameters with a default learning rate of 0.01 and a default weight decay of 0.2. For the baseline algorithms, we meticulously set all hyper-parameters according to the scope outlined in their original papers and tune them on every datasets."}, {"title": "4.2 Experiment Results", "content": "4.2.1 Overall Performance. We compare the performance of our HACD model with seven state-of-the-art community detection methods on five real-world datasets, as shown in Table 2. We can make the following key observations:\n\u2022 Our proposed HACD framework achieves noticeable improvements across nearly all datasets. Among them, compared to the baselines with the best results, HACD respectively achieves the highest improvement of 23.49%, 24.26%, 17.19%, 21.45%, and 4.58% in five evaluation indicators, demonstrating its effectiveness. Notably, HACD achieves significant performance gains on the Pubmed and DBLP datasets. This not only validates our method but also highlights HACD's capability to detect communities in large-scale datasets.\n\u2022 GNN-based methods generally outperform CDE and DANMF, due to the excellent performance of GNN in mining node attribute information. However, since GNN-based baselines only incorporate intuitive attribute information without delving into the semantic similarity between attributes, they cannot fully utilize the information within the attributes.\n\u2022 CDE, CommDGI, and AnECI achieve good results in almost all evaluation metrics. Different from capturing structural performance by encoding the pairwise connections of nodes, they encode latent community membership information, demonstrating the efficiency of leveraging inherent community information. However, while CDE, CommDGI, and AnECI encode membership information, they overlook higher-level mesoscopic structural constraints and global structural patterns, resulting in suboptimal performance."}, {"title": "4.2.2 Attribute Information.", "content": "Instead of using the original attributed graph structure directly, our model pioneers a new approach. We treat node attributes as another type of node, transforming real-world attributed graphs into a heterogeneous graph structure. We then apply this updated graph structure to baseline models such as GAT, DAEGC, and CommDGI, which also consider attribute information. Figure 3 shows the performance comparison between the models using the original graph structure and the corresponding improved models. It is obvious that the improved models universally outperform the original models, demonstrating that using the updated graph structure as input allows each model to encode attribute information at a higher level of granularity, resulting in improved performance. This proves that our enhanced graph structure can unlock the potential of attribute information."}, {"title": "4.2.3 Efficiency.", "content": "We evaluate the efficiency of HACD by directly comparing the total running time with all baselines. In this evaluation, all models run 600 epochs as well as other parameters for baselines are set following their original papers. Table 3 illustrates the performance (F1 score) and running time (seconds). We can observe that the running time of HACD is consistently competitive. HACD is always faster than CommDGI, which also considers dual information of attributes and community. Even on large-scale datasets Pubmed and DBLP, the running time of HACD is still within a reasonable range."}, {"title": "4.2.4 Parameter Discussions.", "content": "We vary the training epoch and the dimension of embedding to explore the parameter settings of our model. It can be observed from Figure 4(a) and 4(b) that: (i) with the increase of parameter values, the trend initially rises and then declines. Because when training for fewer epochs or embedding sizes, HACD fails to sufficiently learn the data features but training for too many epochs or embedding sizes leads to overfitting. (ii) Due to the influence of the training epoch, modularity gradually increases and then maintains a stable level."}, {"title": "4.2.5 Robustness and Scalability.", "content": "We now discuss the robustness and scalability of our proposed model on the DBLP dataset. We add Gaussian noise to the network and verified the robustness of HACD by changing the range of data fluctuations. Figure 5(a) shows the changes in the evaluation metrics. As the range of noise distribution expands, the modularity only decreases by about 5% and then tends to stabilize, with little impact from noise variation. Although other evaluation metrics are more affected by noise, the decrease is still within a controllable range. Because HACD not only considers the information between node attributes at the microscopic level, but also takes into account the structural patterns at the mesoscopic level, exhibiting excellent robustness."}, {"title": "4.2.6 Ablation Study.", "content": "To validate the effectiveness of each part of HACD, we perform ablation experiments. The NMI results are shown in Tables 4. Due to space limitations, we omit the results of ACC, F1 and ARI, which show similar trends to NMI. A2M and CMF denote HACD utilizing only the attribute-level attention module and the community attribution function module, respectively."}, {"title": "5 RELATED WORK", "content": "5.1 Community Detection\nCommunity detection [8, 18, 24] is commonly defined as the process of partitioning graph nodes into multiple groups and widely applied in various real-world applications, such as recommendation system[22] and anomaly detection [33]. In recent years, graph neural networks (GNNs) have proven effective in various graph data mining tasks and exhibit strong capabilities in community detection [16, 23]. CP-GNN [16] uses a context path-based GNN to detect communities in heterogeneous graphs, and KPI-HGNN [23] designs a community detection algorithm based on heterogeneous graph neural network.\nAttributed graphs integrate attributes into the graph structure, resulting in a richer network representation [25]. Attributed community detection [36, 39] aims to find densely connected communities with homogeneous attributes by leveraging both topological and attribute information. Method like CDE [13] formulates the problem as a NMF optimization task, while ACDM [4] constructs an attributed k-NN layer to extract common node representations. Recently, COD[20] devises a local hierarchical reclustering method to identify the largest community, which takes into account the query attribute.\nDespite the widespread use of GNNs in non-attributed community detection [17] and graph clustering [5], their application to attributed community detection remains underdeveloped. Moreover, existing ACD methods often overlook the inherent community structures and encode node attributes directly, neglecting the semantic similarities between attributes within real communities. Our model effectively addresses these two issues by integrating A2M and CMF at the same time."}, {"title": "6 CONCLUSION", "content": "In this paper, we study the problem of attributed community detection from a new heterostructure perspective. We propose HACD, a model that ensures both attribute cohesiveness and structure cohesiveness in detected communities. Specifically, we construct attributed networks into a heterogeneous graph structure. We then use A2M to capture attribute semantic similarity and reveal the latent relationships between nodes in the network. Finally, CMF addresses sensitivity issues and enhances robustness by optimizing the community structure. Extensive experiments on real-world datasets demonstrate that our HACD model effectively discovers communities in attributed networks and significantly outperforms all baseline methods. While our model has demonstrated promising results, there remain opportunities to enhance its interpretability and generalization capabilities. In future work, we will explore alternative graph structure optimization techniques to further strengthen these aspects and investigate the novel insights that may emerge from the interplay between large language models for graphs and community detection."}]}