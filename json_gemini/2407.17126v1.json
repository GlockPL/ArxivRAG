{"title": "SDoH-GPT: Using Large Language Models to Extract Social\nDeterminants of Health (SDoH)", "authors": ["Bernardo Consoli", "Xizhi Wu", "Song Wang", "Xinyu Zhao", "Yanshan Wang", "Justin Rousseau", "Tom\nHartvigsen", "Li Shen", "Huanmei Xu", "Yifan Peng", "Qi Long", "Tianlong Chen", "Ying Ding"], "abstract": "Extracting social determinants of health (SDoH) from unstructured medical notes depends heavily on\nlabor-intensive annotations, which are typically task-specific, hampering reusability and limiting sharing.\nIn this study we introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM)\nmethod leveraging contrastive examples and concise instructions to extract SDoH without relying on\nextensive medical annotations or costly human intervention. It achieved tenfold and twentyfold\nreductions in time and cost respectively, and superior consistency with human annotators measured by\nCohen's kappa of up to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the\nstrengths of both, ensuring high accuracy and computational efficiency while consistently maintaining\n0.90+ AUROC scores. Testing across three distinct datasets has confirmed its robustness and accuracy.\nThis study highlights the potential of leveraging LLMs to revolutionize medical note classification,\ndemonstrating their capability to achieve highly accurate classifications with significantly reduced time\nand cost.", "sections": [{"title": "Introduction", "content": "Social determinants of health (SDoH) [1-9], contributing to an astonishing 80-90% of health outcomes [10-\n12]. The coexistence of multiple SDoH factors within individuals can significantly exacerbate health risks\n[13-16]. Critical SDoHs are locked in unstructured clinical narratives [18 -21]. Methods for SDoH extraction\nusing natural language processing (NLP) encompass rule-based, tool-based, and supervised/unsupervised\nlearning approaches, relying on annotated data and lexicons constructed manually or semi-automatically\n[22]. This manual procedure depends extensively on guidelines that steer the annotation process [21, 23],\ntypically task-specific, resulting in poor reusability. Large Language Models (LLMs) [24], including pre-\ntrained domain specific LLMs [25], have demonstrated promising potential across various healthcare\napplications [26-30]. A primary obstacle in classifying SDoH from medical notes is the challenge of\nobtaining high-quality annotations to train machine learning models. LLMs' potential for data labeling has\nbeen explored across various NLP tasks, showing great potential to lower cost and yield results\ncomparable to human annotations [31-35]. In this paper, we introduced a simple and effective few-shot\nlearning LLM method that leverages contrastive examples and concise instructions to extract SDoH\nwithout relying on extensive medical annotation guidelines or costly human intervention. Furthermore,\nwe trained XGBoost classifiers using LLM annotated SDoH data to achieve optimal performance with\naffordable computational resources. XGBoost was chosen over transformer-based Language Models (LM)\nlike BERT because XGBoost is computationally cheaper to run and can achieve great performance once\nthe training dataset growing up to 500 and above. Most language models must be fine-tuned on large\nrelevant texts to achieve superior results in specialized tasks. Given the heterogeneous nature of\ninterinstitutional medical notes, as well as the challenges of sharing medical data across different\ninstitutions, XGBoost is far more practical and computationally efficient.\nIn this study, we developed SDoH-GPT utilizing GPT-3.5 with few-shot learning to extract SDoH from\nmedical notes and tested SDoH-GPT on three datasets: MIMIC-SBDH [37]; the Suicide Notes Dataset from\nthe National Violent Death Reporting System (NVDRS) [38]; and the Sleep Notes dataset from a private\nmedical center [39] (See Method; Extended Data 1-3). SDoH-GPT has achieved comparable accuracy to\nhuman annotations with a tenfold reduced time and a twentyfold decrease in cost, for 2048 sample\nannotations (Fig. 1d). If more annotations had been performed, using SDoH-GPT would have become even\ncheaper and less time-consuming. When compared to human annotation, SDoH-GPT can become a\nthousandfold cheaper and a hundredfold faster while maintaining comparable accuracy (Extended Data\n4). With different few-shot learning strategies, SDoH-GPT has reached superior consistency with human\nannotators measured by Cohen's kappa: 0.72 to 0.92 in MIMIC-SDBH, 0.71 to 0.88 in Suicide Notes, and\n0.70 to 0.91 in Sleep Notes (Fig.1e). The synergistic integration of SDoH-GPT and XGBoost harnesses the\nstrengths of both sides to ensure high accuracy and computational efficiency."}, {"title": "Results", "content": null}, {"title": "SDOH-GPT: An Effective SDOH Classifier", "content": "Training an XGBoost [40] classifier using SDoH-GPT annotations can yield enhanced accuracy, consuming\nless computational resources (Fig. 1a). The scaling up LLMs can perform agnostic tasks with few-shot or\nzero-shot learning, surpassing state-of-the-art fine-tuning approaches [41,42]. We selected three SDOH\ncategories from MIMIC-SDBH with the highest lexical diversity: Community (i.e., the presence of active\nsocial support), Economics (i.e., current employment status), and Tobacco Use (i.e., current or past\ntobacco consumption) [37]. Fig.1b shows the average performance of XGBoost classifiers for three MIMIC\nSDOH categories trained on 16 to 2048 annotated examples either by human annotators or SDoH-GPT\nwith zero-shot learning (called O-shot SDoH-GPT), indicating that with mere 256 examples, XGBoost\nclassifier trained on SDoH-GPT annotations (called XGBoost-SDoH-GPT) can reach ~0.90 AUROC. The\ndiscrepancy between XGBoost-SDoH-GPT and XGBoost classifier trained with human annotations (called\nXGBoost-Human) with more than 256 annotations was marginal, within a range of 0.014 to 0.022 AUROC\n(Fig.1b). In scenarios with high lexical diversity, such as Economics, XGBoost-Human trained on 256\nannotations achieved 0.95 AUROC, while XGBoost-SDoH-GPT trained on 256 annotations by SDoH-GPT\ntwo-shot learning (called 2-Shot SDoH-GPT), consistently maintained above 0.90 AUROC scores (Extended\nData 5). For Community, XGBoost-Human trained on 512 annotations surpassed 0.95 AUROC, in contrast\nto XGBoost-SDOH-GPT on 1024 2-Shot SDoH-GPT annotations to maintain the same AUROC score.\nHowever, XGBoost-SDoH-GPT with a mere 256 0-Shot SDoH-GPT annotations achieved 0.90 AUROC. The\nAUROC difference was within a range of 0.014 to 0.035 when comparing XGBoost-Human with XGBoost-\nSDOH-GPT trained on 2048 annotations. In Tobacco Use, both XGBoost-Human and XGBoost-SDoH-GPT,\ntrained with 128 annotations, reached above 0.90 AUROC. These results demonstrate the comparable\nperformance of XGBoost-Human and XGBoost-SDoH-GPT (Extended Data 5). Fig.1d illustrates that the\naverage performance of XGBoost-Human and XGBoost-SDoH-GPT, trained on 2048 annotations, shows a\negligible difference of 0.0194 in AUROC. However, SDoH-GPT is nearly 19 times more cost-effective and\n13 times faster when annotating 2048 samples (see Method; Extended Data 5)."}, {"title": "SDOH-GPT: A simple few-shot learner", "content": "Fig.2b illustrates the structured template of a prompt, comprising three sections: Instructions, Examples,\nand Query. The Instructions section includes three components: Roleplaying, which establishes a specific\nrole for GPT-3.5; General Task Instruction, succinctly outlining a goal for GPT-3.5; and SDoH Specific\nInstruction, providing specific instructions for each SDoH category. This section does not require expertise\nfrom domain specialists or intensive details from annotation guidelines. The Examples section includes\ntwo examples. The Query section encompasses a medical note (i.e., the social history) and a question\nregarding the appropriate SDoH category for classification. The combination of examples is thoroughly\nexplained in Fig.2c. First, we deployed O-Shot SDoH-GPT on 100 randomly chosen discharge summaries\nfrom MIMIC-SDBH for each SDoH category. Subsequently, we compared SDoH-GPT annotations with\nhuman annotations to identify True Positives, True Negatives, False Positives, and False Negatives. This\nled to the formulation of four two-example strategies for the Examples section: combining one positive\nexample from True Positives and one negative example from True Negatives to create 2-Shot E, with\nadded explanations forming 2-Shot E+Ex; and selecting one positive example from False Negatives and\none negative example from False Positives to develop 2-Shot H, with explanations yielding 2-Shot H+Ex.\nOur experiment with different numbers of examples in prompts, ranging from zero to eight, revealed that\nprompts with zero and two examples exhibit comparable accuracy to those with eight examples (Fig.3d).\nOur prompt template is simpler than those from [36] which provide an extensive human-generated\nannotation guideline (Extended Data 7-8). [46] used GPT with zero-shot learning to annotate SDoH on\n1,000 medical notes from a University Hospital. Their GPT template is simple, but their F1 scores for\nEmployment status (0.613), Tobacco use (0.652), and Living status (0.608) are much lower than ours\n(Fig.3d).\nFig.2a shows the workflow of SDoH-GPT. In the Data Extraction section, we prepared the Training Set with\n1024 positive and 1024 negative examples; and the Testing Set with 512 positive and 512 negative\nexamples for each MIMIC SDOH category. Then we ran O-Shot SDoH-GPT on 100 randomly selected\nexamples from the Training Set to select two examples for 2-Shot SDoH-GPT. We utilized Regular\nExpressions (RegEX) to extract the Social History subsection from discharge summaries of MIMIC-III,\nexcluding neonates and those with missing values. This process yielded 37,558 social history notes without\nhuman annotations (called Unannotated Social Histories). Then we ran O-Shot SDoH-GPT and 2-Shot\nSDoH-GPT on the Unannotated Social Histories to produce 1024 positive and 1024 negative examples for\neach SDoH category. We have six training sets with 1024 positive and 1024 negative examples for each\nMIMIC SDOH category: Human-Annotated Training Set (same as the Training Set), O-Shot SDoH-GPT\nTraining Set, 2-Shot E SDoH-GPT Training Set, 2-Shot E+Ex SDoH-GPT Training Set, 2-Shot H SDoH-GPT\nTraining Set, and 2-Shot H+Ex SD0H-GPT Training Set. We trained six XGBoost classifiers, one for each\nTraining Set, and evaluated their performance using AUROC based on the Testing Set."}, {"title": "SDOH-GPT: Classifying SDoH for MIMIC Discharge Summaries", "content": "We evaluated SDoH-GPT on MIMIC-III discharge summaries to classify the top three lexically diverse SDoH\ncategories: Community, Economics, and Tobacco Use. It is crucial to consolidate the various SDOH\ncategory values into binary classifications of 'Yes' or 'No' (Fig.3a). For example, MIMIC Tobacco Use was\nsimplified from five to two binary values: 'Yes' encompassing both Past and Present usage, and 'No'\nindicating either No Mention or Never Used, while Unsure was removed. To counteract data imbalance,\na random sampling method was employed to balance the number of positive and negative examples. Next,\nthe balanced annotation set was divided into a Training Set with 1024 positive and 1024 negative\nexamples, and a Testing Set with 512 positive and 512 negative examples (Fig.3a). Fig.3b shows the\ncomparative performance of XGBoost classifiers trained on the annotations of best performing SDoH-GPT\nfor each category (2-Shot H+Ex SDoH-GPT for Community; 0-Shot SDoH-GPT for Economics; 2-Shot E\nSDOH-GPT for Tobacco Use) versus those classifiers trained on human annotations, including the\nassociated time and financial costs. Given the high expense and complexity inherent in human annotation,\nrelated studies typically have a limited number of SDoH annotations: 1,000 [46], 1,576 [47] and 500 [48].\nAssuming only 512 human annotations are available for Community, SDoH-GPT can effortlessly generate\n2048 additional annotations at an additional cost of $1.89 and an extra 8.5 minutes, achieving a 0.01\nhigher AUROC score compared to XGBoost trained on 512 human annotations. Similarly, for Economics,\nSDOH-GPT could produce 2048 additional annotations at an additional $0.93 and 8.5 extra minutes,\nattaining the same AUROC score. Likewise, for Tobacco Use, SDoH-GPT could generate 2048 additional\nannotations with an increase of $1.87 and an additional 8.5 minutes, resulting in a 0.018 higher AUROC\nscore (Fig.3b). Notably, SDoH-GPT requires only 100 human-annotated examples in total to select two\nexamples for 2-Shot SDoH-GPT, demonstrating significant cost-effectiveness and efficiency. Ablation\nstudies revealed minimal variance in AUROC scores between O-Shot SDOH-GPT and various 2-Shot SDOH-\nGPT trained on 2048 annotations, suggesting that additional shots do not necessarily enhance\nperformance (Fig.3c). Employing 2-Shot SDoH-GPT directly for annotating the Testing Set (512 positive\nand 512 negative examples) without XGBoost yielded an F1 score nearly equivalent to that achieved by\nusing XGBoost trained on 2048 human annotations (Fig.3d). This result indicates that SDoH-GPT can\nsignificantly reduce manual annotation efforts, needing twenty times fewer human annotations to\nmaintain comparable F1 scores (Fig.3d). O-Shot SDoH-GPT on the Testing data outperformed XGBoost\nclassifier trained on 2048 human annotations in terms of F1 scores in all categories except Economics,\nwithout necessitating any human annotations (Fig.3d).\nIn this study, we attained a notably higher F1 score using 2-Shot SDoH-GPT: 0.905 in Economics, which is\n0.102 higher than those from GPT-4 in [36]; 0.963 in Tobacco Use, surpassing 0.138 than those in [36];\nand 0.926 in Community, a significant improvement of 0.336 over Living Status in [36]. Several factors\npotentially contribute to the differences: 1) Variance in GPT prompt structure: [36]\u2019s query in GPT prompts\nwas to annotate discharge summaries in the BRAT standoff format, while ours were pure SDOH\ncategorization which are triggers in BRAT; 2) Dataset differences: [36] contains MIMIC III and an additional\ndataset from the University of Washington; while ours are MIMIC III and two other datasets 3) Instruction\nguideline: [36]'s prompt included a lengthy instruction, exceeding 1,000 characters; while our instruction"}, {"title": "Validating SDoH-GPT using Suicide Notes and Sleep Notes", "content": "SDOH-GPT was validated using two distinct datasets: Suicide Notes and Sleep Notes. This validation\nfollowed the methodology delineated in Fig.2a, which guided the creation of both Training and Testing\nSets (Fig.4b). For Sleep Notes, each note was segmented into multiple sentences and each sentence was\nannotated using all five SDoH-GPT prompts to detect sleep apnea. For Suicide Notes, each note comprised\ntwo specific sections, namely the coroner or medical examiner's report and the law enforcement report,\nwhich were considered to comprise one medical note. All O-Shot SDoH-GPT and various 2-Shot SDoH-GPT\nwere employed to ascertain the association between job problems and the victim's suicide ideation\n(Fig.4a). Fig.4c presents the results in AUROC, time and cost. For Suicide Notes, XGBoost-SDoH-GPT\ntrained on annotations from 2-Shot H SDoH-GPT performs comparably to XGBoost-Human with\nsignificantly reduced time and computational cost. If only 256 human annotations are available, XGBoost-\nSDoH-GPT exhibited a substantial increase in AUROC score by 0.036 (Fig.4d). Moreover, with mere 128\nannotations, both XGBoost-Human and XGBoost-SDoH-GPT with O-Shot, 2-Shot E+Ex and 2-Shot H+Ex\nattained 0.90 AUROC score. However, human annotations incurred greater financial and time costs\n(Extended Data 5). In scenarios where only 512 human annotations were feasible, XGBoost trained on\n2048 2-shot H SDoH-GPT annotations exhibited a remarkable enhancement in AUROC scores, escalating\nfrom 0.946 to 0.973. This is particularly noteworthy as the time and cost associated with SDoH-GPT remain\nconstant, whereas those for human demonstrate significant escalations. For Sleep Notes, where only 236\nhuman annotations were available for sleep apnea (74 as Training Set and 162 as Testing Set), the peak\nAUROC achieved by XGBoost-Human is 0.922. By spending an extra $2.68 dollars and 8.5 minutes,\nXGBoost-SDoH-GPT, trained 2048 annotations generated by 2-Shot H SDoH-GPT, can improve AUROC\nfrom 0.922 to 0.964 (Fig.4c, Fig.4d). This demonstrates the substantial utility of SDoH-GPT in areas where\nhuman annotations are scarce and expensive to obtain. SDoH-GPT can markedly enhance performance\nwith minimal additional effort."}, {"title": "Understanding SDoH-GPT Classification Errors", "content": "We employed SDoH-GPT to classify the Testing Set in MIMIC-SDBH (Fig.2a) to conduct a thorough error\nanalysis. Fig.5a and 5b show four categories of errors: Human error (i.e., errors in human annotations);\nSDOH-GPT error (i.e., errors in SDoH-GPT annotations); and Extraction error (i.e., incorrect extractions of\nsocial histories from discharge summaries using Regular Expression algorithms), and Ambiguity (i.e., hard\nto decide). These are several instances of annotation ambiguity (Fig.5c): 1) Contextual Misinterpretations:\nhuman annotators classified Case1 as community absent, whereas SD0H-GPT identified it as community\npresent, misinterpreting the context of \"lost family\u201d. 2) Temporal Conditions: human annotators\nmistakenly treated the subject in Case2 as currently employed, neglecting past tense and context of\nhaving five great-grandchildren. Conversely, SDoH-GPT categorized this as unemployed or retired. 3)\nEvolving Status: SDoH-GPT's annotation in Case3 was limited to the initial part of the sentence, leading to\nthe annotation of community present. However, considering a potential 5-day rehabilitation stay, his\nsituation could shift to community present within five days, indicating a temporary condition. 4) Implicit\nStatements: Case4 suggests daily access to community services for the patient, yet this does not explicitly\nimply anything about community presence, while SDoH-GPT marked it as community present. Daily access\nto healthcare services cannot directly infer community presence [52]. 5) Incomplete Information: It is\nunclear whether the patient in Case5 lives with his children or not. The patient's searching for housing\ncould imply a lack of permanent residence, rendering his community presence ambiguous. Nevertheless,\nSDOH-GPT classified this as community present, which can be questionable. An extreme example\nillustrates the challenges in interpretation of \u201cA patient has never smoked and drinks socially alcohol\" as\ncommunity present by SDoH-GPT, presumably due to the social implication of alcohol consumption. Fig.5d\ndemonstrates the inconsistencies in annotations between human annotators and SDoH-GPT for roughly\nthe same social histories across two visits of the same patient."}, {"title": "Discussion", "content": "SDoH data in medical notes are concise, lacking detailed context. This brevity often results in implicit\nstatements, which introduces ambiguity into SDoH annotations. There are several pivotal issues\nconcerning ambiguity: 1) Overgeneralization: LLMs are predominantly trained on patients in urban areas,\nleading to inaccurate extrapolations for rural patients [53]. 2) Individualization: The living conditions of a\npatient in an elder care facility can lead to diverse SDoH annotations [52]. 3) Incompleteness: The absence\nof comprehensive information further compounds the ambiguity in determining SDoH status [54]. 4)\nMisclassification: LLMs often classify mentions of \"community support\" as references to social activities,\noverlooking contexts where it might pertain to community healthcare services [55]. Ambiguity in SDOH\nstems from its inherently complex and multifaceted nature, requiring a nuanced understanding and\ncontext-specific analysis to ensure precise and meaningful annotation [47, 50, 56]. Effectively addressing\nthese issues requires a comprehensive understanding of the medical domain, as well as the broader\nsocietal context pertinent to healthcare. Our proposed approach, which employs XGBoost trained with\nSDOH-GPT annotations, presents an efficient and straightforward solution. This approach attains accuracy\ncomparable to human-level performance for SDoH annotation while requiring fewer computational\nresources. Nevertheless, our paper has certain limitations. First, our SDoH categorization is binary (Yes or\nNo), which may not adequately capture clinical complexity. Second, our current experiment was limited\nto the categories of Community, Economics, and Tobacco Use, excluding other SDoH categories. Last, our\napproach to SDoH annotation is confined to the categorical level and does not extend to sentence-level\nannotation of triggers and spans."}]}