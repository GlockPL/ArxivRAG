{"title": "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)", "authors": ["Bernardo Consoli", "Xizhi Wu", "Song Wang", "Xinyu Zhao", "Yanshan Wang", "Justin Rousseau", "Tom Hartvigsen", "Li Shen", "Huanmei Xu", "Yifan Peng", "Qi Long", "Tianlong Chen", "Ying Ding"], "abstract": "Extracting social determinants of health (SDoH) from unstructured medical notes depends heavily on labor-intensive annotations, which are typically task-specific, hampering reusability and limiting sharing. In this study we introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM) method leveraging contrastive examples and concise instructions to extract SDoH without relying on extensive medical annotations or costly human intervention. It achieved tenfold and twentyfold reductions in time and cost respectively, and superior consistency with human annotators measured by Cohen's kappa of up to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the strengths of both, ensuring high accuracy and computational efficiency while consistently maintaining 0.90+ AUROC scores. Testing across three distinct datasets has confirmed its robustness and accuracy. This study highlights the potential of leveraging LLMs to revolutionize medical note classification, demonstrating their capability to achieve highly accurate classifications with significantly reduced time and cost.", "sections": [{"title": "Introduction", "content": "Social determinants of health (SDoH) [1-9], contributing to an astonishing 80-90% of health outcomes [10-12]. The coexistence of multiple SDoH factors within individuals can significantly exacerbate health risks [13-16]. Critical SDoHs are locked in unstructured clinical narratives [18 -21]. Methods for SDoH extraction using natural language processing (NLP) encompass rule-based, tool-based, and supervised/unsupervised learning approaches, relying on annotated data and lexicons constructed manually or semi-automatically [22]. This manual procedure depends extensively on guidelines that steer the annotation process [21, 23], typically task-specific, resulting in poor reusability. Large Language Models (LLMs) [24], including pre-trained domain specific LLMs [25], have demonstrated promising potential across various healthcare applications [26-30]. A primary obstacle in classifying SDoH from medical notes is the challenge of obtaining high-quality annotations to train machine learning models. LLMs' potential for data labeling has been explored across various NLP tasks, showing great potential to lower cost and yield results comparable to human annotations [31-35]. In this paper, we introduced a simple and effective few-shot learning LLM method that leverages contrastive examples and concise instructions to extract SDoH without relying on extensive medical annotation guidelines or costly human intervention. Furthermore, we trained XGBoost classifiers using LLM annotated SDoH data to achieve optimal performance with affordable computational resources. XGBoost was chosen over transformer-based Language Models (LM) like BERT because XGBoost is computationally cheaper to run and can achieve great performance once the training dataset growing up to 500 and above. Most language models must be fine-tuned on large relevant texts to achieve superior results in specialized tasks. Given the heterogeneous nature of interinstitutional medical notes, as well as the challenges of sharing medical data across different institutions, XGBoost is far more practical and computationally efficient."}, {"title": "Results", "content": "In this study, we developed SDoH-GPT utilizing GPT-3.5 with few-shot learning to extract SDoH from medical notes and tested SDoH-GPT on three datasets: MIMIC-SBDH [37]; the Suicide Notes Dataset from the National Violent Death Reporting System (NVDRS) [38]; and the Sleep Notes dataset from a private medical center [39] (See Method; Extended Data 1-3). SDoH-GPT has achieved comparable accuracy to human annotations with a tenfold reduced time and a twentyfold decrease in cost, for 2048 sample annotations (Fig. 1d). If more annotations had been performed, using SDoH-GPT would have become even cheaper and less time-consuming. When compared to human annotation, SDoH-GPT can become a thousandfold cheaper and a hundredfold faster while maintaining comparable accuracy (Extended Data 4). With different few-shot learning strategies, SDoH-GPT has reached superior consistency with human annotators measured by Cohen's kappa: 0.72 to 0.92 in MIMIC-SDBH, 0.71 to 0.88 in Suicide Notes, and 0.70 to 0.91 in Sleep Notes (Fig.1e). The synergistic integration of SDoH-GPT and XGBoost harnesses the strengths of both sides to ensure high accuracy and computational efficiency."}, {"title": "SDOH-GPT: An Effective SDOH Classifier", "content": "Training an XGBoost [40] classifier using SDoH-GPT annotations can yield enhanced accuracy, consuming less computational resources (Fig. 1a). The scaling up LLMs can perform agnostic tasks with few-shot or zero-shot learning, surpassing state-of-the-art fine-tuning approaches [41,42]. We selected three SDOH categories from MIMIC-SDBH with the highest lexical diversity: Community (i.e., the presence of active social support), Economics (i.e., current employment status), and Tobacco Use (i.e., current or past tobacco consumption) [37]. Fig.1b shows the average performance of XGBoost classifiers for three MIMIC SDOH categories trained on 16 to 2048 annotated examples either by human annotators or SDoH-GPT with zero-shot learning (called O-shot SDoH-GPT), indicating that with mere 256 examples, XGBoost classifier trained on SDoH-GPT annotations (called XGBoost-SDoH-GPT) can reach ~0.90 AUROC. The discrepancy between XGBoost-SDoH-GPT and XGBoost classifier trained with human annotations (called XGBoost-Human) with more than 256 annotations was marginal, within a range of 0.014 to 0.022 AUROC (Fig.1b). In scenarios with high lexical diversity, such as Economics, XGBoost-Human trained on 256 annotations achieved 0.95 AUROC, while XGBoost-SDoH-GPT trained on 256 annotations by SDoH-GPT two-shot learning (called 2-Shot SDoH-GPT), consistently maintained above 0.90 AUROC scores (Extended Data 5). For Community, XGBoost-Human trained on 512 annotations surpassed 0.95 AUROC, in contrast to XGBoost-SDOH-GPT on 1024 2-Shot SDoH-GPT annotations to maintain the same AUROC score. However, XGBoost-SDoH-GPT with a mere 256 0-Shot SDoH-GPT annotations achieved 0.90 AUROC. The AUROC difference was within a range of 0.014 to 0.035 when comparing XGBoost-Human with XGBoost-SDOH-GPT trained on 2048 annotations. In Tobacco Use, both XGBoost-Human and XGBoost-SDoH-GPT, trained with 128 annotations, reached above 0.90 AUROC. These results demonstrate the comparable performance of XGBoost-Human and XGBoost-SDoH-GPT (Extended Data 5). Fig.1d illustrates that the average performance of XGBoost-Human and XGBoost-SDoH-GPT, trained on 2048 annotations, shows a negligible difference of 0.0194 in AUROC. However, SDoH-GPT is nearly 19 times more cost-effective and 13 times faster when annotating 2048 samples (see Method; Extended Data 5)."}, {"title": "SDOH-GPT: A simple few-shot learner", "content": "Moreover, annotated examples by human annotators and SDoH-GPT shared extremely high agreement measured by Cohen's kappa [43]. Cohen's kappa score as low as 0.41 is deemed acceptable for health-related studies [43]. In our experiments, Cohen's kappa scores demonstrated significant agreement between human annotators and 2-shot SDoH-GPT: 0.87 for Community, 0.82 for Economics, and 0.92 for Tobacco Use, 0.88 for Suicide Notes, across 1024 annotations, and 0.91 for Sleep Notes, across 236 annotations (Fig.1e). These results indicate strong and near-perfect agreement between human annotators and SDoH-GPT. For comparison, Cohen's kappa between two human annotators conducting similar SDoH annotations on clinic notes from Brigham and Women's Hospital/Dana-Farber Cancer Institute was 0.76 for Employment status (akin to MIMIC Economics) and Social Support (akin to MIMIC Community) [45]. Setting the threshold at a 0.8 Cohen's kappa, all SDoH categories, from MIMIC, Suicide Notes, and Sleep Notes, surpassed this benchmark, underscoring a high level of consistency between human annotators and SDoH-GPT (Fig.1c).\n\n\n\nFig.2b illustrates the structured template of a prompt, comprising three sections: Instructions, Examples, and Query. The Instructions section includes three components: Roleplaying, which establishes a specific role for GPT-3.5; General Task Instruction, succinctly outlining a goal for GPT-3.5; and SDoH Specific Instruction, providing specific instructions for each SDoH category. This section does not require expertise from domain specialists or intensive details from annotation guidelines. The Examples section includes two examples. The Query section encompasses a medical note (i.e., the social history) and a question regarding the appropriate SDoH category for classification. The combination of examples is thoroughly explained in Fig.2c. First, we deployed O-Shot SDoH-GPT on 100 randomly chosen discharge summaries from MIMIC-SDBH for each SDoH category. Subsequently, we compared SDoH-GPT annotations with human annotations to identify True Positives, True Negatives, False Positives, and False Negatives. This led to the formulation of four two-example strategies for the Examples section: combining one positive example from True Positives and one negative example from True Negatives to create 2-Shot E, with added explanations forming 2-Shot E+Ex; and selecting one positive example from False Negatives and one negative example from False Positives to develop 2-Shot H, with explanations yielding 2-Shot H+Ex. Our experiment with different numbers of examples in prompts, ranging from zero to eight, revealed that prompts with zero and two examples exhibit comparable accuracy to those with eight examples (Fig.3d). Our prompt template is simpler than those from [36] which provide an extensive human-generated annotation guideline (Extended Data 7-8). [46] used GPT with zero-shot learning to annotate SDoH on 1,000 medical notes from a University Hospital. Their GPT template is simple, but their F1 scores for Employment status (0.613), Tobacco use (0.652), and Living status (0.608) are much lower than ours (Fig.3d).\nFig.2a shows the workflow of SDoH-GPT. In the Data Extraction section, we prepared the Training Set with 1024 positive and 1024 negative examples; and the Testing Set with 512 positive and 512 negative examples for each MIMIC SDOH category. Then we ran O-Shot SDoH-GPT on 100 randomly selected examples from the Training Set to select two examples for 2-Shot SDoH-GPT. We utilized Regular Expressions (RegEX) to extract the Social History subsection from discharge summaries of MIMIC-III, excluding neonates and those with missing values. This process yielded 37,558 social history notes without human annotations (called Unannotated Social Histories). Then we ran O-Shot SDoH-GPT and 2-Shot SDoH-GPT on the Unannotated Social Histories to produce 1024 positive and 1024 negative examples for each SDoH category. We have six training sets with 1024 positive and 1024 negative examples for each MIMIC SDOH category: Human-Annotated Training Set (same as the Training Set), O-Shot SDoH-GPT Training Set, 2-Shot E SDoH-GPT Training Set, 2-Shot E+Ex SDoH-GPT Training Set, 2-Shot H SDoH-GPT Training Set, and 2-Shot H+Ex SD0H-GPT Training Set. We trained six XGBoost classifiers, one for each Training Set, and evaluated their performance using AUROC based on the Testing Set."}, {"title": "SDOH-GPT: Classifying SDoH for MIMIC Discharge Summaries", "content": "We evaluated SDoH-GPT on MIMIC-III discharge summaries to classify the top three lexically diverse SDoH categories: Community, Economics, and Tobacco Use. It is crucial to consolidate the various SDoH category values into binary classifications of 'Yes' or 'No' (Fig.3a). For example, MIMIC Tobacco Use was simplified from five to two binary values: 'Yes' encompassing both Past and Present usage, and 'No' indicating either No Mention or Never Used, while Unsure was removed. To counteract data imbalance, a random sampling method was employed to balance the number of positive and negative examples. Next, the balanced annotation set was divided into a Training Set with 1024 positive and 1024 negative examples, and a Testing Set with 512 positive and 512 negative examples (Fig.3a). Fig.3b shows the comparative performance of XGBoost classifiers trained on the annotations of best performing SDoH-GPT for each category (2-Shot H+Ex SDoH-GPT for Community; 0-Shot SDoH-GPT for Economics; 2-Shot E SDoH-GPT for Tobacco Use) versus those classifiers trained on human annotations, including the associated time and financial costs. Given the high expense and complexity inherent in human annotation, related studies typically have a limited number of SDoH annotations: 1,000 [46], 1,576 [47] and 500 [48]. Assuming only 512 human annotations are available for Community, SDoH-GPT can effortlessly generate 2048 additional annotations at an additional cost of $1.89 and an extra 8.5 minutes, achieving a 0.01 higher AUROC score compared to XGBoost trained on 512 human annotations. Similarly, for Economics, SDoH-GPT could produce 2048 additional annotations at an additional $0.93 and 8.5 extra minutes, attaining the same AUROC score. Likewise, for Tobacco Use, SDoH-GPT could generate 2048 additional annotations with an increase of $1.87 and an additional 8.5 minutes, resulting in a 0.018 higher AUROC score (Fig.3b). Notably, SDoH-GPT requires only 100 human-annotated examples in total to select two examples for 2-Shot SDoH-GPT, demonstrating significant cost-effectiveness and efficiency. Ablation studies revealed minimal variance in AUROC scores between O-Shot SDOH-GPT and various 2-Shot SDOH-GPT trained on 2048 annotations, suggesting that additional shots do not necessarily enhance performance (Fig.3c). Employing 2-Shot SDoH-GPT directly for annotating the Testing Set (512 positive and 512 negative examples) without XGBoost yielded an F1 score nearly equivalent to that achieved by using XGBoost trained on 2048 human annotations (Fig.3d). This result indicates that SDoH-GPT can significantly reduce manual annotation efforts, needing twenty times fewer human annotations to maintain comparable F1 scores (Fig.3d). O-Shot SDoH-GPT on the Testing data outperformed XGBoost classifier trained on 2048 human annotations in terms of F1 scores in all categories except Economics, without necessitating any human annotations (Fig.3d).\nIn this study, we attained a notably higher F1 score using 2-Shot SDoH-GPT: 0.905 in Economics, which is 0.102 higher than those from GPT-4 in [36]; 0.963 in Tobacco Use, surpassing 0.138 than those in [36]; and 0.926 in Community, a significant improvement of 0.336 over Living Status in [36]. Several factors potentially contribute to the differences: 1) Variance in GPT prompt structure: [36]\u2019s query in GPT prompts was to annotate discharge summaries in the BRAT standoff format, while ours were pure SDOH categorization which are triggers in BRAT; 2) Dataset differences: [36] contains MIMIC III and an additional dataset from the University of Washington; while ours are MIMIC III and two other datasets 3) Instruction guideline: [36]'s prompt included a lengthy instruction, exceeding 1,000 characters; while our instruction"}, {"title": "Validating SDoH-GPT using Suicide Notes and Sleep Notes", "content": "prompt template: Instructions, Examples, and Query. (c) Two steps on how to generate examples for 2-Shot SDoH-GPT.\nSDOH-GPT was validated using two distinct datasets: Suicide Notes and Sleep Notes. This validation followed the methodology delineated in Fig.2a, which guided the creation of both Training and Testing Sets (Fig.4b). For Sleep Notes, each note was segmented into multiple sentences and each sentence was annotated using all five SDoH-GPT prompts to detect sleep apnea. For Suicide Notes, each note comprised two specific sections, namely the coroner or medical examiner's report and the law enforcement report, which were considered to comprise one medical note. All O-Shot SDoH-GPT and various 2-Shot SDoH-GPT were employed to ascertain the association between job problems and the victim's suicide ideation (Fig.4a). Fig.4c presents the results in AUROC, time and cost. For Suicide Notes, XGBoost-SDoH-GPT trained on annotations from 2-Shot H SDoH-GPT performs comparably to XGBoost-Human with significantly reduced time and computational cost. If only 256 human annotations are available, XGBoost-SDoH-GPT exhibited a substantial increase in AUROC score by 0.036 (Fig.4d). Moreover, with mere 128 annotations, both XGBoost-Human and XGBoost-SDoH-GPT with O-Shot, 2-Shot E+Ex and 2-Shot H+Ex attained 0.90 AUROC score. However, human annotations incurred greater financial and time costs (Extended Data 5). In scenarios where only 512 human annotations were feasible, XGBoost trained on 2048 2-shot H SDoH-GPT annotations exhibited a remarkable enhancement in AUROC scores, escalating from 0.946 to 0.973. This is particularly noteworthy as the time and cost associated with SDoH-GPT remain constant, whereas those for human demonstrate significant escalations. For Sleep Notes, where only 236 human annotations were available for sleep apnea (74 as Training Set and 162 as Testing Set), the peak AUROC achieved by XGBoost-Human is 0.922. By spending an extra $2.68 dollars and 8.5 minutes, XGBoost-SDoH-GPT, trained 2048 annotations generated by 2-Shot H SDoH-GPT, can improve AUROC from 0.922 to 0.964 (Fig.4c, Fig.4d). This demonstrates the substantial utility of SDoH-GPT in areas where human annotations are scarce and expensive to obtain. SDoH-GPT can markedly enhance performance with minimal additional effort."}, {"title": "Understanding SDoH-GPT Classification Errors", "content": "We employed SDoH-GPT to classify the Testing Set in MIMIC-SDBH (Fig.2a) to conduct a thorough error analysis. Fig.5a and 5b show four categories of errors: Human error (i.e., errors in human annotations); SDOH-GPT error (i.e., errors in SDoH-GPT annotations); and Extraction error (i.e., incorrect extractions of social histories from discharge summaries using Regular Expression algorithms), and Ambiguity (i.e., hard to decide). These are several instances of annotation ambiguity (Fig.5c): 1) Contextual Misinterpretations: human annotators classified Case1 as community absent, whereas SD0H-GPT identified it as community present, misinterpreting the context of \"lost family\u201d. 2) Temporal Conditions: human annotators mistakenly treated the subject in Case2 as currently employed, neglecting past tense and context of having five great-grandchildren. Conversely, SDoH-GPT categorized this as unemployed or retired. 3) Evolving Status: SDoH-GPT's annotation in Case3 was limited to the initial part of the sentence, leading to the annotation of community present. However, considering a potential 5-day rehabilitation stay, his situation could shift to community present within five days, indicating a temporary condition. 4) Implicit Statements: Case4 suggests daily access to community services for the patient, yet this does not explicitly imply anything about community presence, while SDoH-GPT marked it as community present. Daily access to healthcare services cannot directly infer community presence [52]. 5) Incomplete Information: It is unclear whether the patient in Case5 lives with his children or not. The patient's searching for housing could imply a lack of permanent residence, rendering his community presence ambiguous. Nevertheless, SDOH-GPT classified this as community present, which can be questionable. An extreme example illustrates the challenges in interpretation of \u201cA patient has never smoked and drinks socially alcohol\" as community present by SDoH-GPT, presumably due to the social implication of alcohol consumption. Fig.5d demonstrates the inconsistencies in annotations between human annotators and SDoH-GPT for roughly the same social histories across two visits of the same patient."}, {"title": "Discussion", "content": "SDoH data in medical notes are concise, lacking detailed context. This brevity often results in implicit statements, which introduces ambiguity into SDoH annotations. There are several pivotal issues concerning ambiguity: 1) Overgeneralization: LLMs are predominantly trained on patients in urban areas, leading to inaccurate extrapolations for rural patients [53]. 2) Individualization: The living conditions of a patient in an elder care facility can lead to diverse SDoH annotations [52]. 3) Incompleteness: The absence of comprehensive information further compounds the ambiguity in determining SDoH status [54]. 4) Misclassification: LLMs often classify mentions of \"community support\" as references to social activities, overlooking contexts where it might pertain to community healthcare services [55]. Ambiguity in SDOH stems from its inherently complex and multifaceted nature, requiring a nuanced understanding and context-specific analysis to ensure precise and meaningful annotation [47, 50, 56]. Effectively addressing these issues requires a comprehensive understanding of the medical domain, as well as the broader societal context pertinent to healthcare. Our proposed approach, which employs XGBoost trained with SDOH-GPT annotations, presents an efficient and straightforward solution. This approach attains accuracy comparable to human-level performance for SDoH annotation while requiring fewer computational resources. Nevertheless, our paper has certain limitations. First, our SDoH categorization is binary (Yes or No), which may not adequately capture clinical complexity. Second, our current experiment was limited to the categories of Community, Economics, and Tobacco Use, excluding other SDoH categories. Last, our approach to SDoH annotation is confined to the categorical level and does not extend to sentence-level annotation of triggers and spans."}, {"title": "Data Availability", "content": "MIMIC-III (https://physionet.org/content/mimiciii/1.4/) and NVDRS (https://www.cdc.gov/violenceprevention/datasources/nvdrs/dataaccess.html) are third-party datasets available for credentialed use. MIMIC-SBDH is a publicly available third-party dataset (https://github.com/hibaahsan/MIMIC-SBDH). The Sleep Notes dataset is protected by HIPAA law. It is restricted to research and healthcare use. Access can be granted by the University of Pittsburgh's Office of Sponsored Programs (osp@pitt.edu), which has a 2-6-month response timeframe."}, {"title": "Code Availability", "content": "Our codebase is available upon request (corresponding author)."}]}