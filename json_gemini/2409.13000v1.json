{"title": "Introducing the Large Medical Model: State of the art healthcare cost and risk prediction with transformers trained on patient event sequences", "authors": ["Ricky Sahu", "Eric Marriott", "Ethan Siegel", "David Wagner", "Flore Uzan", "Troy Yang", "Asim Javed"], "abstract": "With U.S. healthcare spending approaching $5T (\u201cNHE Fact Sheet\" 2024), and 25% of it estimated to be wasteful (\"Waste in the US the health care system: estimated costs and potential for savings\", n.d.), the need to better predict risk and optimal patient care is evermore important. This paper introduces the Large Medical Model (LMM), a generative pre-trained transformer (GPT) designed to guide and predict the broad facets of patient care and healthcare administration. The model is trained on medical event sequences from over 140M longitudinal patient claims records with a specialized vocabulary built from medical terminology systems and demonstrates a superior capability to forecast healthcare costs and identify potential risk factors. Through experimentation and validation, we showcase the LMM's proficiency in not only in cost and risk predictions, but also in discerning intricate patterns within complex medical conditions and an ability to identify novel relationships in patient care. The LMM is able to improve both cost prediction by 14.1% over the best commercial models and chronic conditions prediction by 1.9% over the best transformer models in research predicting a broad set of conditions. The LMM is a substantial advancement in healthcare analytics, offering the potential to significantly enhance risk assessment, cost management, and personalized medicine.", "sections": [{"title": "1. Introduction", "content": "Healthcare administration involves balancing the cost of care with the need to mitigate risks and ensure positive patient outcomes. The industry, especially in the United States, is largely driven by health plans attempting to reduce healthcare costs while maintaining high margins, and healthcare providers (typically under fee-for-service incentive structures) who benefit from increased services and care resulting in increased revenue. Pharmaceutical companies (pharma) are also deeply invested in this landscape, aiming to develop and commercialize medications to improve patient outcomes while mitigating adverse reactions. New value-based-care incentives propagate the balancing act between cost and risk, but shift the responsibility to single entities like Accountable Care Organizations (ACOs) or Medicare Advantage Plans.\nFor providers, payers, pharma, and patients to better balance risk, cost, and treatment efficacy, they must understand what attributes of an individual's history most impact the future, and the web of interaction effects among those over time. Along with medical outcomes, the financial aspects of care delivery are also important. They are, however, often separately codified in contracts between payers, providers, and pharma, further occluded by negotiations between the parties. Understanding the long term cause and effect of healthcare interventions is an exceptionally difficult problem for humans and machines alike.\nFirst, the science of medicine is continuously developing. Our understanding of how different parts of the body react to various treatments and interventions continues to evolve. As new therapies and medications are developed, the complexity of medical care increases, necessitating ongoing learning and adaptation. Healthcare's dynamic environment makes it challenging to maintain up-to-date knowledge while considering a broad set of possibilities and effective application of treatments across diverse patient populations.\nSecond, the data available in healthcare is vast and varied. Medical records encompass an extensive range of data types, including procedures, medications, costs, locations, provider information, genomics, conditions, laboratory results, textual notes, demographics, images, and more. Furthermore, these data originate from multiple sources such as electronic medical records (EMRs), insurance claims, sensors, and the environment. As longitudinal patient records are often fragmented it is difficult to assemble a comprehensive view of a patient's medical history and predict future healthcare needs accurately.\nFinally, the variation in the population and environment leads to highly individualized medical journeys that even large-scale research studies fail to capture fully.The research that is done is often isolated geographically or to only those patients who will respond most favorably, limiting the generalizability of findings. This individuality necessitates personalized approaches to care that account for the distinct medical and social contexts of each patient.\nTo achieve improved healthcare predictions within the high dimensional nature of healthcare, one approach is to imagine healthcare data as a sequence of events playing out over time. This framing lends itself naturally to sequence to sequence models in order to predict future events. The field of sequence based modeling has recently been taken over by deep learning and is now largely centered upon sequence to sequence neural network architectures, such as transformers."}, {"title": "2. Related Work", "content": "Healthcare plays a massive role in national economies, is a major focus of financial investment globally, and is ever important in our own lives as we age. As healthcare costs continue to mount, so has interest from government agencies, insurance providers, healthcare institutions, medical professionals, the pharmaceutical industry, and patients in understanding how to better manage and control these expenses while achieving better outcomes. This imperative has produced many commercial models designed to accurately forecast healthcare costs and patient risks.\nTraditionally, healthcare analytics are based on purpose-built statistical models specialized for specific problems. These models typically focus on structured data such as diagnostic codes, demographic information and pharmacy records. For example, the Hierarchical Condition Category (HCC) model developed by the Centers for Medicare and Medicaid Services (CMS) is a classical linear model used for risk adjustment to identify patients with chronic health conditions and estimate their healthcare costs. Since 2004, CMS has used the HCC model to calculate payments to healthcare organizations for patients with Medicare Advantage, Accountable Care Organization (ACO), and Affordable Care Act (ACA) plans (\"IMO Health\", n.d.). Similarly, models such as the Chronic Illness & Disability Payment System (CDPS), Milliman's MARA, and Adjusted Clinical Groups (ACG) from Johns Hopkins University assess morbidity burdens by analyzing diagnostic data and a limited set of other events like medications and past cost. These models are often designed for targeted populations such as Medicaid beneficiaries and are effective within their limited scope.\nWhile most commercial offerings are also based on linear models, some employ more advanced statistical methods such as gradient boosted trees (Kumar 2023). However, these models still fall short in capturing the complexity, sequencing, and nuances of medical data as they fail to account for the entirety of a patient's health record. This limitation becomes evident in predicting outcomes for complex diseases such as diabetes where long term progression pattern plays significant role (An Tran-Duy 2020,).\nGiven the billions of dollars to be gained with better cost and risk prediction models and the clear benefits on patient outcomes, the industry has begun to explore the application of generative Al to this domain. Recent works such as BEHRT (BERT for Electronic Health Records) (Li, n.d.,), RETAIN (REverse Time AttentioN) (Choi, n.d.) Foresight (Kraljevic, n.d.) and Deepr (Nguyen, n.d.) have shown promising results in using sequential models and attention mechanisms for healthcare predictions. For instance, BEHRT, adapts the transformer architecture to capture the nuances of patient histories, while RETAIN (REverse Time AttentIoN) employs a reverse time two level attention mechanism to prioritize recent clinical events in its prediction, enhancing the interpretability of the model to understand what influences the predictions.\nDeepr applies deep learning techniques to model patient sequences for predictive analytics. Additionally, the potential of applying Large Language Models (LLMs) to healthcare is gaining traction, with researchers investigating how these models can be fine-tuned to handle patient data.\nThe Foresight v2 model is a LLM fine-tuned on MIMIC-III dataset to predict both disorders and disease risk scores for patient timelines using SNOMED codes. The authors expand the tokenizer to add these codes and report improvements over their Foresight v1 model on a test set of 2101 patients, demonstrating how generative AI can be effective in predicting both specific disorders and overall risk of future medical events. However they also describe challenges due to lack of data and reliance on a small dataset, which may fail to capture the diversity of patient populations.\nDespite the progress in exploring generative Al and transformer-based approaches, a critical gap remains-the lack of a transformer-based model trained on multi-modal attributes from claims and clinical records, tokenized using medical terminology systems, and trained at scale. In this research we present the LMM, which achieves state-of-the-art (SoTA) performance for cost and risk prediction in healthcare."}, {"title": "3. Method", "content": null}, {"title": "3.1 Large Medical Model (LMM)", "content": "To conduct our research, we trained an autoregressive transformer based neural network on patient medical events as a unified sequence of data. Rather than employing language and text in the sequence as is done with LLMs, we compose individual patient timelines by combining structured medical event data as sequences of medical event codes and taxonomies. A text based approach would require much longer sequence lengths to convey the same information presented in medical codable concepts which LLM's have been shown to struggle with (Soroush, n.d.). For example, medical concepts such as ICD-10 CM codes (International Classification of Diseases) convey information about patient diagnoses and conditions. Typically in human language a condition could be referred colloquially as \"breast cancer,\" more specifically for healthcare data standards and billing purposes as a \"Malignant neoplasm of unspecified site of unspecified female breast\" which is also specified as the ICD-10 CM code \"C50.919.\" Using a language based vocabulary, later more specific text requires 13 tokens, whereas in our approach using a medical event based vocabulary we can convey the same information in 1 to 4 tokens.\nAn LLM tokenizer would use 25 tokens to convey this information:\nBy contrast, GenHealth.ai's LMM represents the same information with codable concepts instead of words resulting in a shorter, more information dense sequence:\nAutoregressive models tend to place more importance on recent events and tokens, and by reducing the total number of tokens we are able to drastically reduce compute requirements and capture a more salient signal for each event. Additionally, training on text would necessitate getting data from the entire internet, and might occlude healthcare specific insights. Furthermore, text models struggle with numeric data, while our approach allows for a custom tokenization for better handling of numerical information. Finally, text models do not have a built in way for representing time series events, this makes tracking patient historical timelines difficult."}, {"title": "3.2 Data", "content": "Our patient sequences are produced from healthcare claims data from a number of sources in a variety of formats. The total data set covers 140M patients of which 95% are in the training set and 5% split between the validation and test sets. The patient population spans the entire United States geographically and is composed of approximately equally of commercial, Medicare, and Medicaid members including medical events from 2016 to 2022. Patients aged 0 to over 100 are all included. We do not prune or filter the data when training our model.\nEach patient's data is formatted into a linearized sequence of event tokens representing the medical history of an individual. There are tokens representing place of service, service codes (CPT-4, HCPCS, ICD-10 PCS), diagnosis codes (ICD-10 CM), drugs (NDC), demographic information, claim costs and the timing of events."}, {"title": "3.3 Monte Carlo Simulations", "content": "Subsequent to model training, during inference, the LMM produces multiple sequences of events given a patient's history. Each inference run using a patient's history will produce different future events given the non-deterministic nature of our decoding method. This Monte Carlo simulation of futures allows us to estimate the probabilities of events as we aggregate across them.\nConsider the example as shown in figure 1; 5 different sequence runs with the same patient's history may produce 5 different futures which can then be stacked and aggregated to produce a probability distribution of the patient's future over time. The individual events from each of these predictions or the compiled simulations can be used to interrogate the data at the event or sequence level. For example, if each green event were one dollar, we can interpret the model to say in runs 1, 3, and 4 the patient's future set of medical events cost $1, run 2 cost $2, and run 5 did not incur any medical cost. Moreover, we can associate successive events with conditional probabilities beginning to indicate causal relationships."}, {"title": "3.4 Training and Evaluation Pipeline", "content": "Overall the process consisted of this series of steps:\n1. Build a vocabulary of medical events\n2. Construct sequences of historical patient events\n3. Train a transformer based neural network model on those events to predict the next token\n4. Use the resulting model to run inference multiple times for each patient in a validation set\n5. Calculate the total cost of care by summing the predicted cost events, and compare to the actual"}, {"title": "4 Experiments and Results", "content": "The study is divided into two parts: one focused on forecasting healthcare costs and the other on predicting chronic conditions. Each part uses a distinct cohort, chosen to align with the objectives of the respective analysis and directly compare to prior research."}, {"title": "4.1 Care Cost Prediction", "content": "We benchmarked the LMM against existing predictive risk models as measured by the Society of Actuaries (SoA) in Accuracy of Claims-Based Risk Scoring Models (2016). To the best of our knowledge, no equally comprehensive evaluation of industry standard risk scoring models has been published since the SoA study. Our model outperforms all the models compared in the SoA paper, including thosefrom Milliman, Hopkins, Cotiviti, etc.\nWe conducted additional analysis comparing the public Hierarchical Condition Category (HCC) risk model from the US government, and found that we outperform that as well. Additionally, given the meaningful advancements in Large Language Models (LLMs) we also evaluated various methods of coaxing Open Al's gpt-40 model into predicting next year's cost given last year's data (in both structured and language formats). However, the best response from the LLM was to use last year's total cost to predict next year's total cost, which is a naive approach that performs far worse than all other models in this study."}, {"title": "4.1.1 Data Collection", "content": "To compare to the results from the SoA paper, we produced a cohort of 50,000 patients per the same inclusion and exclusion criteria as specified in the SoA paper, from a similarly broad commercial patient population. While the 2016 SoA study used data from 2012 to predict healthcare costs for 2013, we used the data from 2017 to predict 2018, as our data begins in 2016."}, {"title": "4.1.2 Data Overview", "content": null}, {"title": "4.1.3 Measure of fit", "content": "This section introduces the key metrics used in the SoA's research to evaluate the accuracy and effectiveness of the LMM in estimating healthcare costs.\nR-Squared\nR-Squared (R2, Coefficient of Determination) measures the proportion of the variance in the actual costs that is predictable from the predicted costs. It is calculated as:\n$R^2 = 1 - \\frac{\\Sigma_{i=1}^n (Y_i - \\hat{Y_i})^2}{\\Sigma_{i=1}^n (Y_i - \\bar{y})^2}$\nwhere \u0177; is predicted cost, y; is actual cost, y is the mean of the actual costs, and n is the number of observations.\nA higher R\u00b2 value suggests that the model more effectively captures the underlying patterns in the data, leading to more accurate predictions."}, {"title": "4.1.4 Results", "content": "The LMM reduces the Normalized Mean Absolute Error by approximately 14.1% compared to the best commercial models. The SoA conducted analysis on both a raw uncensored population and a censored population (where patients were removed from the metric calculations if their predicted cost was greater than $250,000). As shown in Table 1, we find that our model outperforms on both uncensored and censored calculations, and for the purposes of this research, we report the data for the raw uncensored comparisons. The LMM achieves a NMAE of 78.3%, which is 14.1% better than the previous best NMAE of 91.2% reported in the 2016 SoA study. The average cost in the GenHealth cohort is $6,097 so on average the LMM would predict $972.closer to actual cost compared to the best model from the SoA paper. To calculate the future year cost, we run the Monte Carlo simulation on 64 generated futures for each patient and sum the dollar amount tokens from each future to create that simulation's predicted cost. Finally, we average the 64 futures' total costs to produce the model's predicted cost for each patient.\nThe model also achieves an R2 (Coefficient of Determination) of 25.3%, which is a 2% improvement over the best model in the SoA study. This suggests that in addition to predicting better cost on average, the model's explanatory power of the variance is also improved. When compared with the HHS-HCC model (\u201cThe HHS-HCC Risk Adjustment Model for Individual and Small Group Markets under the Affordable Care Act - Centers for Medicare & Medicaid Services\u201d, n.d.) a risk adjustment methodology commonly used in the US healthcare industry-on the same cohort, it produced a NMAE of 123% and a negative R\u00b2 of 0.343, indicating a poor fit, whereas our model demonstrates better explanatory power and overall performance. For reference, the square of the Pearson correlation coefficient (r\u00b2) for HHS-HCC is 0.134 vs 0.282 for the GenHelath.ai LMM."}, {"title": "4.2 Chronic Disease Prediction", "content": "Unlike the risk models in the SoA paper, the LMM has the ability to predict any condition, procedure, medication, or episode of care etc. and the time to those events. Chronic condition prediction is often critical in managing care. To assess the LMM's ability to predict diagnoses we utilized definitions of chronic conditions from the Chronic Conditions Data Warehouse (CCW) for evaluating predictions across 30 chronic diseases categories and compared our results to BERHT introduced a novel approach to modeling longitudinal patient data using transformers within electronic health records (EHRs) for predictive healthcare tasks. While the LMM predicts ICD diagnosis codes directly, BERHT predicts a higher level aggregation for 301 conditions. On aggregating across common conditions we are able to directly compare 19 chronic condition categories with BERHT and find that the LMM has marginally better results."}, {"title": "4.2.1 Data Collection", "content": "In this CCW section, we leveraged data from both commercial insurers and the Centers for Medicare & Medicaid Services (CMS), and randomly selected 50,000 records from each source's validation set for evaluating performance. Our focus was on patients who were enrolled in 2017 and continued their enrollment through 2021, allowing us to capture a comprehensive longitudinal view of their health trajectories. To ensure consistency with the BEHRT study, which emphasizes predictions within the first six months of the year, our analysis was concentrated on this same prediction period.\nNote the difference in data selection from the SoA paper. We included the Medicare population (over 65 of age) and we included up to 4 years of history instead of only 1 year."}, {"title": "4.2.2 Data Overview", "content": "The Figure 6 displays demographic distributions for the evaluation cohort including age, gender, and ethnicity. The age distribution covers a range from 0 to over 100 and 7 ethnicities. The lower count in the 60-70 group is due to US patients transitioning to Medicare Advantage resulting in fewer patients whose histories include 4 years which we maintained for consistency to BEHRT."}, {"title": "4.2.3 Measures of fit", "content": "To compare our model with the BEHRT model we will compare AUROC and AUPRC scores.\nAUROC (Area Under the Receiver Operating Characteristic Curve): This metric measures the model's ability to distinguish between classes at all decision thresholds. The area under the curve reflects the probability that the model will rank a randomly chosen positive instance higher than a randomly chosen negative one.\n$AUROC = \\int_0^1 TPR(t) \\ dFPR(t)$\nwhere:\nTrue Positive Rate (TPR) or Sensitivity is defined as:\n$TPR = \\frac{TP}{TP + FN}$\nFalse Positive Rate (FPR) is defined as:\n$FPR = \\frac{FP}{FP + TN}$"}, {"title": "4.2.4 Results", "content": "Across the 19 conditions mapped using CCW and Caliber Codes, the GenHealth LMM achieves an average AUROC of 0.897 which is a 1.9% improvement over the BEHRT score of 0.881. We see close performance between the two models, with minor variations by conditions. The LMM sequences, however, indicate all other events before and after the chronic condition diagnosis; that level of detail in output can make the LMM more actionable.\nSpecifically, in Figure 8, the GenHealth model demonstrates higher AUROC scores for conditions like diabetes (0.95 vs. 0.81), atrial fibrillation and flutter (0.95 vs. 0.90), dyslipidemia (0.87 vs. 0.79), and hypertension (0.90 vs. 0.82)."}, {"title": "5 Discussion and Future Research", "content": "Our research introduces the Large Medical Model (LMM), which, for the first time, combines numerous advancements building over prior models: 1) we sequenced medical event tokens rather than natural language text or one-hot-encoding 2) we employed a transformer based architecture 3) we achieve a large scale by training on 140M patients 4) we simulated multiple futures using a Monte Carlo method to predict any of those events including cost. Our results suggest that the model is capable of understanding and modeling a varied set of patient timelines and is able to outperform top risk scoring models by 14.1% on cost of care and 1.9% on disease risk prediction over a range of conditions.\nThe LMM marks a significant advancement in the application of transformer-based architectures over previous state of the art. In particular, we demonstrate the model's effectiveness in key downstream tasks such as cost and chronic disease prediction, finding it to perform exceptionally well despite only being (pre)-trained on next token prediction. In doing so, we set a new benchmark for the integration of such models in real world health care settings, enabling more precise and personalized healthcare interventions.\nMost notable, however, is the unique method of sequencing medical events over time. By training the model on temporally accurate sequences of actual patient histories, the LMM can generate more types of actionable insights than any existing risk and cost prediction methods. For example, the LMM can not only stratify a population based on cost or risk for some condition, but it can also identify specifically why the most complex and expensive patients in that group will be expensive. The LMM can specify the individual procedure codes and conditions that the patient may have in the future and when they may occur. Additionally, it can also identify the likelihood of a patient to be admitted to an Emergency Department, what that admission is expected to be for, and how much that will cost. This level of detail is unprecedented in the industry today and is crucial for positively impacting patient care and healthcare costs."}, {"title": "5.1 In-Silico Research and Personalized Medicine", "content": "In addition to its ability to predict total cost of care and onset of conditions, the LMM is also able to simulate the clinical effects of an intervention, new diagnosis, and more. This can be achieved by appending an additional event to the end of any patient history used as input into the model. We explored some of these simulated interventions using the LMM and see that it can identify novel clinical relationships unexplored in the current medical literature. For example emerging but inconclusive research exists investigating hearing stroke as a cause of Parkinson's. Using the LMM, we can simulate the effect of stroke on various patients including a 70 year old female and males. The LMM indicates a much higher likelihood of the patient developing Parkinson's and Parkinsonism for males than females. Although our model has never before seen any research papers or text indicating causality (given that it is trained only on medical event codes), our findings are corroborated by published research by the Parkinson's Foundation in which men have 1.5 times higher likelihood of Parkinson's (\"Prevalence of Parkinson's disease across North America\"). That research however does not indicate what triggers the diagnosis. The LMM, however, indicates it is the stroke that leads to Parkinson's. This relationship has been found in mice models (\"Ischemic stroke causes Parkinson's disease-like pathology and symptoms in transgenic mice overexpressing alpha-synuclein\") and in associations without direct casualty ascribed in human data research (\"Associations between cerebrovascular risk factors and parkinson disease\")."}, {"title": "5.2 Use Cases", "content": "Like the above, the LMM's predictions can be leveraged to address a broad set of healthcare challenges beyond the evaluations detailed in this paper. Similar to LLMs which can be used to perform Q&A, run chatbots, write articles, summarize text, etc., the LMM supports a wide range of use cases that are crucial for the healthcare industry. For instance, in Population Health, the LMM can stratify patient populations and identify optimal next-best actions by analyzing care paths derived from over 100 million other patients. For Prior Authorization, the model can simulate patient journeys to better understand outcomes and cost implications, thereby improving decision-making during care determinations. Financial Forecasting is another key application, where the LMM can predict the total cost of care using simulated care pathways for individuals or cohorts, enhancing underwriting, stop-loss insurance, and financial planning. Lastly, in Risk Management, the LMM can forecast patient health trajectories at the ICD level, enabling the identification of high utilizers and improving care paths.\nIn future research, we will explore a broader range of downstream tasks to demonstrate additional domains where this approach can positively impact healthcare.\nThe Large Medical Model represents a leap forward in how we can model and understand healthcare, leveraging the advances in modern Al and a deep understanding of the healthcare domain. We hope the broader use of it in the industry will lead to a more efficient healthcare system which can also significantly improve patient care."}]}