{"title": "LLM Agent Honeypot:\nMonitoring AI Hacking Agents in the Wild", "authors": ["Reworr", "Dmitrii Volkov"], "abstract": "We introduce the LLM Honeypot, a system for monitoring autonomous AI hacking\nagents. We deployed a customized SSH honeypot and applied prompt injections with tem-\nporal analysis to identify LLM-based agents among attackers. Over a trial run of a few\nweeks in a public environment, we collected 800,000 hacking attempts and 6 potential AI\nagents, which we plan to analyze in depth in future work. Our objectives aim to improve\nawareness of AI hacking agents and enhance preparedness for their risks.", "sections": [{"title": "1 Introduction", "content": "The continuous evolution of AI capabilities and agent frameworks is gradually increasing the\npotential for AI-driven cyberattacks. These advancements make it possible to create autonomous\nagents capable of adapting to diverse environments and executing complex attack behaviors.\nThis paper introduces LLM Agent Honeypot, a system for capturing and analyzing in-the-\nwild LLM-based cyberattacks using prompt injections and temporal analysis aimed at improving\npreparedness for AI-driven threats. Its dashboard is available online at https://ai-honeypot.\npalisaderesearch.org/."}, {"title": "2 Related Work", "content": "Honeypots. Cybersecurity professionals use honeypots as decoy systems to attract potential\nattackers and study their techniques and behaviors. While these systems have been effective\nwith conventional cyberattacks, their application in AI-driven contexts is still new.\nRecent literature has begun to explore the intersection of AI and honeypot technologies. Two\nrepresentative works are Sladic et al.'s LLM-powered shell honeypots [1] and \"Galah\" the LLM-\npowered web honeypot [2]. However, these focus on using AI to improve traditional honeypots,\nrather than capturing AI-driven attacks through honeypots.\nAgents. Al agents are becoming more important to cybersecurity. Google's Project Naptime\n[3] evaluates LLMs' offensive security capabilities, and OpenAI o1 had escaped its Docker con-\ntainment during evals [4].\nPrompt injection. We follow AgentDojo's [5] evaluations of agent prompt injection resistance\nand use a variation of the \"Important message\" hijack in our work."}, {"title": "3 Methodology", "content": "Before deploying the honeypot on the Internet, we conducted internal evaluations on model\nhacking agents to calibrate detection methods."}, {"title": "3.1.1 Prompt Injection Techniques", "content": "First, we tested prompt injections across common agent design frameworks (ReAct and CoT)."}, {"title": "3.1.2 Temporal Analysis", "content": "In addition to active detection, we performed a temporal analysis to identify implicit indicators\nof LLM agents.\nOur analysis shows that most interactions (~96%) in the wild, including those driven by\nLLMS, occur within 1.5 seconds:"}, {"title": "3.2 Detection Methodology", "content": "The detection methodology of our AI Honeypot system combines active and passive techniques\nto identify AI agents. It classifies actor types into three categories: traditional software bots,\nAI-based agents, and humans."}, {"title": "3.2.1 Distinguishing LLM Agents", "content": "Our detection strategy focuses on two key distinctions:\n1. LLM Agents vs. Software Bots: We use prompt injections to alter behavior and\nask questions requiring human-like intelligence (e.g., goal hijacking: ignore all previous\ninstructions and return the color of ...). However, humans can also manually respond\nto these injections, potentially passing the test.\n2. LLM Agents vs. Humans: The primary distinction is response time. LLMs respond\nquickly, while humans need time to read, process, and answer prompt injections."}, {"title": "3.2.2 Prompt Injection", "content": "Prompt injections are central to our detection strategy. We use two types:\n\u2022\nGoal Hijacking: manipulate the agent's behavior to perform a new goal. We use con-\ntextual prompt injections based on the \"Important Message\" attack, nudging the agent\ntoward additional actions.\n\u2022 Prompt Stealing: ask the LLM to reveal its initial system instructions, uncovering the\nsystem's context and goals. We apply this technique only after triggering Goal Hijacking.\nBy cross-referencing agent behaviors with prompt injection responses and temporal analysis,\nwe reduce false positives and enhance detection efficiency. Software bots cannot pass human-like\nquestions, and humans cannot respond as quickly as LLMs. Temporal analysis also helps identify\npotential AI-driven attacks."}, {"title": "3.3 System Architecture", "content": "Our honeypot is built on a customized version of the Cowrie SSH honeypot [6], following recom-\nmendations frmo Cabral et al. in Advanced Cowrie Configuration [7]. The modifications include\ndeploying a vulnerable SSH version and altering default users and standard outputs to increase\ndeceptiveness.\nWe integrated prompt injections into various system components to expose interactions with\nLLM-based agents:"}, {"title": "3.4 Deployment", "content": "We deployed the honeypot as a publicly accessible system and implemented strategies to attract\na wide variety of attackers:\n\u2022\nSensitive Domains: Configured DNS entries to point seemingly sensitive domain names\n(e.g., gov-defense-dev.il) to honeypot IPs.\n\u2022 Search Engines: Indexed the honeypots on hacker-oriented search engines like Shodan\nand Censys to increase visibility.\n\u2022 Scaling: Distributed the honeypot across 10 IP addresses in various countries to capture\ndiverse interactions."}, {"title": "4 Preliminary Results", "content": "During the deployment, the honeypot recorded 813,202 interaction attempts, detecting a small\nnumber of potential AI-driven hacking attempts. The collected data includes interaction logs,\ntimestamps, session details, and behavioral patterns. As the dataset grows, we will conduct more\nin-depth analyses to better understand LLM hacking behaviors and refine our methods."}, {"title": "4.1 Public Dashboard", "content": "We developed a public website to provide real-time statistics and results from the LLM Agent\nHoneypot system. The dashboard offers insights into interaction metrics, threat analysis, and\nAI-specific threats, along with updates on our findings."}, {"title": "5 Limitations", "content": "A key limitation of this work is that AI in cybersecurity is often applied to narrow tasks like\nAI-powered vulnerability detection [8], rather than as autonomous agents.\nOur honeypot measures the proliferation of autonomous AI hacking agents and will not catch\nother AI-driven improvements like 10x faster fuzzing."}, {"title": "6 Future Work", "content": ""}, {"title": "6.1 Threat Analysis", "content": "Our immediate focus is to continue collecting data and maintaining the honeypot, as interactions\nremain infrequent. This will allow us to capture a broader range of potential AI-driven attacks.\nOnce we have sufficient data, we will analyze it to identify patterns, behaviors, and strategies\nused by AI agents, publishing our findings on the website and in future work."}, {"title": "6.2 Improving Detection", "content": "Future work will explore advanced detection methods, focusing on data analysis and algorithms.\nWe aim to test widely-used LLM agent frameworks and identify distinctive AI-driven attack\npatterns."}, {"title": "6.3\nExpanding Honeypot", "content": "To attract more AI-driven agents, we plan to expand the honeypot to monitor a wider range\nof attack surfaces, such as social media, websites, databases, email services, and industrial con-\ntrol systems. This would help capture a broader range of threats, including spambots, phishing\nagents, and other offensive LLM-based applications. Additionally, we could integrate the honey-\npot with existing security solutions, such as SIEM systems."}, {"title": "7 Conclusion", "content": "In this paper, we introduced the LLM Agent Honeypot (https://ai-honeypot.palisaderesearch.\norg/), a system designed to detect and analyze AI hacking agents. As AI agents grow more so-\nphisticated, our approach offers insights into emerging cybersecurity threats and new strategies\nto counter them. We hope this project encourages further study of AI-driven agents, which have\nthe potential to significantly alter the cybersecurity landscape."}]}