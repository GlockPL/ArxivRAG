{"title": "Differentially Private Iterative Screening Rules for Linear Regression", "authors": ["Amol Khanna", "Fred Lu", "Edward Raff"], "abstract": "Linear $L_1$-regularized models have remained one of the simplest and most effective tools in data science. Over the past decade, screening rules have risen in popularity as a way to eliminate features when producing the sparse regression weights of $L_1$ models. However, despite the increasing need of privacy-preserving models for data analysis, to the best of our knowledge, no differentially private screening rule exists. In this paper, we develop the first private screening rule for linear regression. We initially find that this screening rule is too strong: it screens too many coefficients as a result of the private screening step. However, a weakened implementation of private screening reduces overscreening and improves performance.", "sections": [{"title": "1 Introduction", "content": "Sparse linear regression is an important statistical technique which can prevent overfitting on high-dimensional datasets. It is typically achieved through LASSO (L1) optimization, which can be represented by\n$w = \\underset{w \\in R^d: ||w||_1 \\leq \\lambda}{\\arg \\min}\\frac{1}{n} \\sum_{i=1}^n (y_i - w \\cdot x_i)^2,$\nwhere \u03bb is the constraint parameter, $x_1, ..., x_n \\in R^d$, and $y_1, ..., y_n \\in R$. The Frank-Wolfe algorithm can be used to directly optimize over this objective [8].\nHowever, the output w of this optimization can reveal information about specific training datapoints. This may be dangerous in fields like medicine, finance, and government, where datapoints consist of sensitive information which should not be revealed when a model is used [1, 14, 16]. To prevent private information differential privacy can be used.\nDifferential privacy is a statistical technique which guarantees that an algorithm's outputs do not reveal whether or not a specific datapoint was used in its training. Specifically, given privacy parameters \u03f5 and \u03b4 and any two datasets D and D' differing on one datapoint, an approximate differentially private algorithm A satisfies $P[A(D) \\in O] \\leq exp{\\{\\epsilon\\}}P[A(D') \\in O] + \u03b4$ for any $O \\subseteq image(A)$ [6].\nMaking an algorithm differentially private requires adding noise to its intermediate steps or outputs. This noise must scale with the algorithm's sensitivity, or how much its outputs can change when one of its input datapoints is added or removed. If this change is measured with an $L_1$ or $L_2$ norm, noise can be added with the Laplacian or Gaussian distributions, respectively. Further introductory details on differential privacy can be found in [19].\nCurrent differentially private high-dimensional regression algorithms modify nonprivate sparse optimization techniques. However, the modifications required to achieve privacy make these algorithms run slowly and produce dense or ineffective solutions [13, 27, 32]. To address these challenges, some works have developed feature selection algorithms to run prior to training [17, 26, 28]. However, these algorithms are computationally inefficient and can assume a final sparsity level before choosing a support set.\nAnother way to achieve sparse weights for high-dimensional algorithm is by using screening rules. Screening rules discard features that do not contribute to a model during training. They are most often used in conjunction with $L_1$-regularized or L1-constrained linear regression. Screening rules have been used to improve the performance of sparse regression optimization on numerous datasets over the past decade and are even included in the popular R package glmnet [9, 10, 20, 24, 29-31]. Unlike the aforementioned approaches adapted for private regression, screening rules do not require a pre-determined support set or level of sparsity. They efficiently check a"}, {"title": "2 Related Work", "content": "Methods to produce private sparse regression weights all suffer in performance due to the addition of noise. Private $L_1$ optimizers must add higher levels of noise when run for more iterations, incentivizing practitioners to run fewer iterations [27, 33]. However, running an optimizer for fewer iterations means that the model will be limited in its learning. On the other hand, private model selection algorithms are computationally inefficient and run prior to training, meaning they are unable to reap the benefit of any information contained within partially trained coefficients of the weight vector [18, 28]. Although noise is necessary for privacy, an effective private screening rule would run with a private optimizer and improve the optimizer's performance by setting the coefficients of irrelevant features to 0. By using the screening rule on the current weight vector, it can adapt to the optimizer's updates and screen features more accurately.\nTo develop a differentially private screening rule, we adapt Theorem 11 of Raj et al.'s rule which is flexible to solving many types of regression problems [24]. While other screening rules exist, they are geometry- and problem-specific [10, 30, 31]. Our goal is to utilize Raj etl al's screening rule for $L_1$-constrained regression to induce sparsity on Talwar et al.'s $L_1$-constrained private Frank-Wolfe algorithm [24, 27].\nSince we use the private Frank-Wolfe algorithm (DP-FW), we also review it here. DP-FW uses the Frank-Wolfe method for L1-constrained convex optimization, which chooses a vertex of the feasible region (scaled $L_1$ ball) which minimizes a linear approximation of the loss function. By doing this for T iterations with appropriate step sizes, the algorithm satisfies $L(w^{(T)}) - \\min_{w^* \\in C}L(w^*) \\leq O(\\frac{1}{T})$ [8, 12]. The progress of the Frank-Wolfe optimizer can be measured with the Wolfe gap function: $G_C(w) = \\max_{z \\in C} (w-z)^T \\nabla f(w)$. It can be shown that $G_C(w) \\geq f(w) - f(w^*)$ for all w. For this reason, the smaller the Wolfe gap function, the closer the optimization is to an optimal solution. To privatize the Frank-Wolfe algorithm, Talwar et al. restrict the $L_\\infty$ norm of datapoints so they can calculate the exact sensitivity of the gradients [27]. They then use the report-noisy-max mechanism to noisily choose which component of the weight vector to update. Unfortunately, due to inexact optimization caused by the noisy selection process, the private Frank-Wolfe algorithm produces dense results, limiting its ability to be used in high-throughput or interpretability-restricted applications of regression. Despite this limitation, the Frank-Wolfe algorithm is ideal for an application of Raj et al.'s screening rule. Of current methods for private high-dimensional regression, recently summarized by [15], the Frank-Wolfe algorithm is unique in that it uses $L_1$-constrained optimization with updates to one component of the weight vector per iteration. Each of these conditions is important. The first is necessary because Raj et al.'s screening rule requires optimization over an $L_1$-constrained set. The second is important because if a private (noisy) optimization algorithm updates all components of a weight vector at each iteration, then any sparsity induced by applying a screening rule would be lost at the next iteration of optimization, since the output of the optimization would be dense.\nTo the best of our knowledge, this is the first work considering a differentially private screening rule. The difficulty of DP screening is counteracted by the reward of obtaining sparse and private regression, as normal DP destroys sparsity via the addition of noise."}, {"title": "3 Privatizing Iterative Screening", "content": "Raj et al. consider the problem $\\min_{w \\in C} f(Xw)$, where C is the feasible set of solutions and f is L-smooth and \u00b5-strongly convex. They also define $x^{(i)} \\in R^n$ to be the ith column of the design matrix\n$X = \\begin{bmatrix}\nX_1^T \\\\\n... \\\\\nX_n^T\n\\end{bmatrix} \\in R^{n \\times d}$ and $G_C(w)$ to be the Wolfe gap function for linear regression, namely $\\max_{z \\in C} (Xw - Xz)^T \\nabla f(Xw)$. Given this information, they prove that if\n$s_i = |x^{(i)T} \\nabla f(Xw)| + (Xw)^T \\nabla f(Xw)$\n$+ L(||x^{(i)}||_2 + ||Xw||_2)\\sqrt{G_C(w)/\\mu} < 0$\n(1)\nat any w \u2208 C, then $w_i^* = 0$, where $w^*$ is the optimal solution to the optimization problem.\nOur goal is to employ this screening rule for linear regression, namely, when $f(Xw) : R^n \\rightarrow R = \\frac{1}{2} (y - Xw)^T (y - Xw)$. Since we want to guarantee privacy, we will determine the sensitivity of this calculation so we can add an appropriate amount of noise and ensure screening is differentially private. Specifically, we want to determine how much the value of f can change between datasets"}, {"title": "4 RNM-Screen", "content": "In this this section, we seek to improve the performance of ADP-Screen by modifying it in two ways:\n(1) We redistribute the total privacy budget to reduce the noisi-ness of private optimization.\n(2) We employ the report-noisy-max mechanism to reduce the screening noise to sub-$O(\\sqrt{d})$ and reduce overscreening."}, {"title": "4.1 Redistributing the Privacy Budget", "content": "Experiments with ADP-Screen indicated that noisy private optimization caused it to lose its ability to screen coefficients effectively. For this reason, we sought to reduce the amount of noise added during private optimization.\nADP-Screen relies on DP-FW for $L_1$-constrained optimization. To the best of our knowledge, this is the only algorithm which performs private $L_1$-constrained optimization, and as such, the only way to reduce the amount of noise added during private optimization is to redistribute the final privacy budget to reduce the noise for private optimization."}, {"title": "4.2 Report-Noisy-Min Mechanism", "content": "Experiments on ADP-Screen demonstrated that it overscreened coefficients, producing solution vectors which were too sparse to output useful predictions. To prevent overscreening, we chose to screen only one coefficient per iteration.\nTo achieve this, we use the report-noisy-max mechanism. The report-noisy-max mechanism is a technique for privately choosing an item with the highest score from a set given a function which computes the score. Specifically, when trying to calculating the arg max of a set of numbers {$U_1, U_2, ..., U_n$} calculated from a dataset X, the report-noisy-max mechanism calculates $\\arg \\max\\{u_1 + Lap(\\frac{s}{\\epsilon}), u_2 + Lap(\\frac{s}{\\epsilon}), ..., u_n + Lap(\\frac{s}{\\epsilon})\\}$, where s is the sensitivity of a single number $u_i$ with respect to a single change in X. This mechanism is (\u03f5, 0)-differentially private.\nBy finding the maximum of the negative values of the scores, the report-noisy-max mechanism can also be used to privately find"}, {"title": "4.3 Analyzing RNM-Screen's Screening Potential", "content": "To observe the behavior of screening only one coefficient per iteration, it is interesting to consider the case where coefficients which"}, {"title": "5 Experiments with RNM-Screen", "content": "To test RNM-Screen, we analyzed its performance on two synthetic datasets and a number of real-world datasets. Results are shown below."}, {"title": "5.1 Synthetic Data", "content": "We began by using the synthetic dataset which Raj et al. used to test their nonprivate screening algorithm. Specifically, we generated 3000 datapoints in $R^{600}$ from the standard normal distribution, and scaled the final dataset so $||x_i||_\\infty \\leq 1$. We set the true weight vector $w^*$ to be sparse with 35 entries of +1 and 35 entries of -1, and set $y = Xw^*$. Raj et al. demonstrated that the nonprivate screening rule listed in Equation 1 performs well on this dataset for linear regression. We verified this result, finding that using the nonprivate Frank-Wolfe optimizer with the nonprivate screening rule at every iteration produced a final weight vector in which nonzero components were only at the locations of nonzero components in the true weight vector and 55% of the true nonzero components were nonzero after training.\nWe also wanted to determine how correlated features affect the performance of the screening rule. To this end, we generated 3000 datapoints in $R^{600}$ from $N(0, \\Sigma)$ where $\\Sigma_{ij} = 0.5^{|i-j|}$. We then scaled the data as above, the true weight vector remained the same, and y was found in the same way.\nWe tested the performance of two settings of RNM-Screen on each of these datasets. We ran RNM-Screen with $\u03f5_1 = 4.9, \u03f5_2 = 0.1, \u03b4_1 = \\frac{1}{4000}, \u03b4_2 = \\frac{1}{12000}, \u03bb = 50$, and T = 1000."}, {"title": "5.2 Real-World Data", "content": "We also explored RNM-Screen's performance on publicly available real-world datasets. We employed the Abalone, Housing, Body Fat, Pyrim, Triazines, Residential Buildings, Normalized Communities and Crime, and BlogFeedback datasets found in the LIBSVM and UCI Dataset Repositories [2, 3, 11, 23, 25]. For the Residential Buildings dataset, our target variable was profit made on the sale of a property. We applied the Yeo-Johnson transform to each dataset and scaled them so $||x_i||_\\infty \\leq 1$ [34]. We also applied a Yeo-Johnson transform to the the target y. The dimensionality of each dataset can be found in Table 2.\nWe chose to apply the Yeo-Johnson transform for a few reasons. First, the synthetic data tested above followed a Gaussian distribution, and to try and replicate its performance on real-world datasets, we transformed our data to have an approximately Gauss-ian distribution. Second, some of the datapoints and features in our real-world dataset contain outliers, and performing a linear scaling transformation to bound the $L_\\infty$ norm of these points without the"}, {"title": "5.2.1 F1 Scores", "content": "To measure how well RNM-Screen performed on these datasets, we compared its solutions to the weight vectors produced by scikit-learn's nonprivate LASSO optimizer [21]. We aimed to find a regularization strength for the nonprivate LASSO algorithm which produced approximately nonzero coefficients on a given dataset. We then used the $L_1$ norm of this output weight as \u03bb for RNM-Screen. For RNM-Screen, we set $\u03f5_1 = 4.9, \u03b4_1 = \\frac{n}{10000}, \u03f5_2 = 0.1, and \u03b4_2 = \\frac{n}{10000} \\times \\frac{1}{n}$. For datasets with fewer datapoints, we ran the algorithm for fewer iterations as more iterations would increase the noise added in both the optimization and screening processes and unnecessarily corrupt the results.\nThe results of this experiment are shown in Table 2. Of note, when computing the $F_1$ score, we defined the true zero and true nonzero coefficients with respect to the output of the nonprivate LASSO optimizer, not with respect to the optimal weight, as the optimal weight vector is unknown. Bolded values in Table 2 are significantly better than those produced by DP-FW, as measured by a nonparametric sign test. Note that we verified that running the Frank-Wolfe algorithm for more iterations on the smaller datasets produced little change in $F_1$ score while increasing the density of the solutions. This is why we chose to run RNM-Screen for fewer iterations on these datasets. For the larger BlogFeedback dataset, additional iterations did increase the density of the result but were accompanied with an increased $F_1$ score. This is why we ran this for more iterations.\nAnalyzing Table 2, it is clear that the results for $F_1$ scores are not ideal. For all datasets, RNM-Screen was unable to produce an F1 score significantly better than the standard private Frank-Wolfe algorithm. Overall, RNM-Screen is significantly better at distinguishing between true nonzero and zero coefficients than ADP-Screen, but the results shown in Table 2 indicate that for real-world datasets, RNM-Screen does not effectively find the same nonzero coefficients as a LASSO solver."}, {"title": "5.2.2 Mean Squared Error", "content": "To determine whether RNM-Screen al-lowed any learning to occur, we tracked the mean squared error at every iteration on the above datasets. Results are shown in Figure 2.\nDespite the disappointing results on $F_1$ scores, the mean squared error plots in Figure 2 indicate that learning still occurs on larger datasets despite the inaccurate choice of nonzero coefficients. We believe this is a valuable result, as it shows that the solutions pro-duced by RNM-Screen may be useful in prediction. Indeed, research"}, {"title": "6 Conclusion", "content": "In this paper, we created ADP-Screen, the first differentially private screening rule. After showing that it overscreens coefficients and is unable to solve a simple regression problem with a synthetic dataset, we developed RNM-Screen. We showed that it performs better than ADP-Screen on synthetic data since it is actually able to distinguish between screening true zero and true nonzero coefficients. After testing on the synthetic datasets, we tested RNM-Screen's per-formance on real-world datasets. We found that it produces good sparsity with decreasing mean-squared error on larger datasets. Additionally, R2 scores indicate that the coefficients it chooses are"}]}