{"title": "XAI-based Feature Selection for Improved Network Intrusion Detection Systems", "authors": ["Osvaldo Arrechea", "Tanish Gunturb", "Mustafa Abdallah"], "abstract": "Explainability and evaluation of AI models are crucial parts of the security of modern intrusion detection systems (IDS) in the network security field, yet they are lacking. Accordingly, feature selection is essential for such parts in IDS because it identifies the most paramount features, enhancing attack detection and its description. In this work, we tackle the feature selection problem for IDS by suggesting new ways of applying eXplainable AI (XAI) methods for this problem. We identify the crucial attributes originated by distinct AI methods in tandem with the novel five attribute selection methods. We then compare many state-of-the-art feature selection strategies with our XAI-based feature selection methods, showing that most AI models perform better when using the XAI-based approach proposed in this work. By providing novel feature selection techniques and establishing the foundation for several XAI-based strategies, this research aids security analysts in the AI decision-making reasoning of IDS by providing them with a better grasp of critical intrusion traits. Furthermore, we make the source codes available so that the community may develop additional models on top of our foundational XAI-based feature selection framework.", "sections": [{"title": "1 Introduction", "content": "An intrusion detection system's (IDS) primary goal is to locate and identify any unauthorized activity, including efforts to misuse or abuse computer networks from the inside as well as the outside [62,85]. Traditional IDS detects the majority of potential threats by assuming that the behavior of attackers differs considerably from that of normal network traffic. Statistical anomaly [65, 10] and rule-based misuse models [34,46] have been the subject of numerous research studies in the literature to detect intrusions for different applications in real-world systems [78,38]. Nevertheless, the spread of diverse computer networks and the growing complexity of assaults provide difficulties for intrusion detection, allowing attackers to carry out increasingly complex attacks without being quickly discovered [59,82].\nDue to these difficulties, automated intrusion detection systems have been developed with the use of artificial intelligence (AI) [15,22]. These artificial intelligence techniques include naive bayes [6,64], random forest [11,88,60], artificial neural networks [42,83], support vector machines [84,20], decision trees [35,26,4], and others. These methods improve the system's capacity to recognize and neutralize harmful activity and allow intrusion detection to be automated.\nThere are several drawbacks to completely automated AI approaches when it comes to real-world IDS. First of all, these models frequently provide incorrect positive and negative predictions, which might have disastrous effects. False forecasts are especially concerning in large-scale businesses and vital infrastructures where a network breach can cause substantial resource and financial loss. The Twitter hack in July 2020 [89] and the May 2021 [69] ransomware attack, for instance, demonstrate the possible repercussions of inaccurate IDS forecasts. Second, the majority of suggested techniques are regarded as black-box prediction models, except decision trees in basic IDS. Put differently, these judgments made by the AI-based IDS are difficult to understand and do not provide an explanation to human security analysts [7,71]. These earlier AI-based works have mostly concentrated on classification accuracy, ignoring the requirement for interpretability and comprehension of the AI's behavior. The aforementioned constraints underscore the necessity of using the nascent domain of explainable AI (XAI) to augment the comprehensibility of AI-generated judgments within IDS [19]. The IDS can explain the decision-making process by utilizing XAI approaches, which help human analysts comprehend and validate the system's outputs.\nThe use of explainable AI (XAI) in IDS has been the subject of several recent studies [51,66,37,70]. A specific study [70] presented an abstract idea for an intelligent IDS method that involves the human in the loop. Furthermore, another study that only looked at the NSL-KDD benchmark dataset [21] extracted decision rules using a straightforward decision tree algorithm [51]. Large-scale datasets may not benefit from this strategy since it can produce enormous trees with more difficult-to-understand properties. Moreover, these studies did not investigate important aspects of how each feature influences the AI's choice, how important characteristics related to an assault are, how to extract important incursion features, or how to investigate a variety of AI models. We attempt to address this gap in the literature on network intrusion detection with our present research project. Our focus is on the feature selection problem, where we employ XAI techniques to determine the primary intrusion attributes that influence AI model decisions. Additionally, we take into account many critical elements that have been overlooked in previous network intrusion detection research.\nThe high-level overview of the extensive XAI-based system that this study presents to improve feature selection in IDS is shown in Figure 1. Our system provides specific global feature selection techniques that reflect the joint effect of the primary characteristics retrieved from network traffic on the output of the AI model. Additionally, it presents five unique XAI-based feature extraction techniques that pinpoint important aspects of network penetration. It isolates the key characteristics of each sort of intrusion that make up that specific incursion. Furthermore, by efficiently utilizing XAI approaches, our framework selects the overall most significant features from various AI models for every database, improving feature selection for such AI models in intrusion detection tasks. As such, it can help security analysts comprehend the characteristics of network traffic records.\nWe perform a thorough analysis of our framework on two different network intrusion datasets. The first dataset (called RoEduNet-SIMARGL2021 [53]) is a recent compilation from the European Union-funded SIMARGL project. Realistic network traffic data, comprising attributes derived from real-time traffic, makes up this dataset. The dataset is invaluable for building deployable network intrusion detection systems because of this feature. The second dataset, CICIDS-2017 [63], was produced in 2017 by the University of Brunswick's Canadian Institute for Cybersecurity and is a well-known benchmark intrusion detection dataset. It has a range of assault profiles. We assess the performance of several black-box AI models for every dataset, evaluating these models sequentially based on their performance on several incursion types and the typical overall criteria. The key characteristics for these various models are then extracted using various XAI-based techniques (described in Section 3.2). Subsequently, we assess our feature selection techniques by presenting the total feature importance, the contribution of each feature to the AI's judgment, and the most important characteristics related to each sort of intrusion.\nWe rate the efficacy of our framework by contrasting its results with those of other feature selection methods used in network intrusion detection systems, such as feature correlation [73], Chi-square [27], feature importance [23], information gain [43], K-best [54], and Xplique [25]. Based on this benchmark comparison, we show that most AI models outperform the baseline methods when they use the most important characteristics chosen by our framework.\nOverview of Contributions: The primary contributions of our study are outlined below.\nWe offer a comprehensive architecture to improve feature selection for network intrusion detection systems.\nWe present four different XAI-based feature extraction techniques to discover important network intrusion traits.\nWe extract significant attributes that are particular to the model and the intrusion for several classes of AI models and various kinds of network intrusions.\nWe present an empirical comparison of seven black-box AI models on one synthetic and one real-world network intrusion dataset.\nWe make our source codes available to the community as an XAI-based framework for feature selection in network intrusion detection tasks so anyone may use them and expand upon them with other datasets and models."}, {"title": "2 The Problem Statement", "content": "This section explains the basic ideas behind network intrusion detection, the problems with black-box AI, and why feature selection must be done using XAI-based techniques."}, {"title": "2.1 Network Intrusion Types", "content": "Many forms of network intrusions are often encountered. In this work [80], we examine the primary network attacks inside the standard MITRE ATT&CK architecture. As a result, the following categories are used to group the network traffic:\nBenign traffic: Benign traffic is the regular data flow that is gathered from the network.\nNetwork Service Discovery / PortScan (PS) [T1046, MITRE ATT&CK ID]: The goal of the intrusion is for the attacker to identify the victim's computer. Finding weak spots and potential entry sites is frequently the initial stage of an attack. Without actually completing the connection, the functionality is to send the victim a connection solicitation. But in this attack, requests are sent to a variety of ports, and the ports that respond with a message are mapped as potential sites of entry [45].\nNetwork Denial of Service [MITRE ATT&CK ID: T1498] / Denial of Service (DoS): The goal of this kind of assault is to make the target inaccessible to the network. A common illustration of this kind of attack is when a hacker persistently sends requests to establish a connection with a server. Nevertheless, the server never hears back from the origin after accepting the solicitation and sending an acknowledgment in the hopes of receiving a response. Consequently, until the server goes down, the memory for these open interactions is kept open and fully utilized. For further information on certain kinds of DoS assaults, see [43,54].\nBrute Force [T1110, MITRE ATT&CK ID]: This type of attack involves the attacker trying every possible password to gain access to the victim's network. Frequently, this technique is combined with the ability to guess the most popular passwords. When a person uses a password that is weak or often guessed, it can become effective [43].\nInitial Access/Web Attack [MITRE ATT&CK ID: TA0001, T16 59, T1189]: This is a kind of online assault where the attacker takes advantage of security holes in websites. An attacker may, for instance, use a software defect, misconfiguration, or malfunction to exploit a public-facing application and obtain access to the program's underlying instance or container. Drive-by Compromise assaults are also included in the category of web attacks [17]; however, web attacks (such as SQL injection and cross-site scripting) usually do not grant initial access to a remote server [80].\nFirst Access/Infiltration [MITRE ATT&CK ID: TA0001]: This attack happens when someone tries to obtain initial access to a system or application. Attacks of this kind can employ a wide range of strategies, including targeted spearfishing and taking advantage of flaws on web servers that are visible to the public. This assault can build its base by anything from a straightforward password reset to ongoing access via legitimate accounts and third-party remote services.\nInfrastructure Compromise/Botnet [MITRE ATT&CK ID: T1 584.005, T1059, T236, T1070]: This type of automated assault is carried out via remotely operated machines that have been taken over by the attacker, where programs, or bots, replicate and imitate human behavior [79]. Its scripting approach makes it possible to scale and deploy it easily, which makes it the perfect tool for hitting several assault locations at once. As a result, it is a popular form of network assault on many computer networks."}, {"title": "2.2 Intrusion Detection Systems", "content": "Critical infrastructure across a range of industries is seriously threatened by the previously described sophisticated network attacks [41,33]. These dangers undermine trust in the security of stored data in addition to jeopardizing service availability [33]. IDS is used in computer network systems to detect and reduce harmful activity carried out by external and internal intruders [56]. Traditional IDS are often designed with the understanding that the behaviors of an intruder differ significantly from those of a legal user and that many unauthorized acts are detectable [49]. Researchers have investigated the application of AI models to automate the detection of network intrusions [15,22], using recent advances in AI."}, {"title": "2.3 The drawbacks of Black-box AI Models", "content": "An important contribution to automating intrusion detection has been made by AI models. Nonetheless, because of the intricate interactions between the features in the models that go into producing their results, they are inherently black-box because of their innate complexity, understanding how and why the AI model produces its outputs is quite difficult. The black-box problem affects many AI models, such as deep neural networks and random forests. Though they have been successfully applied in many areas and have a high prediction accuracy, it is still difficult to understand the reasoning behind the models' actions, especially when there are faults or blunders. Particularly in safety-critical applications such as network security via intrusion detection systems (IDS), these mistakes might have serious repercussions. To overcome these difficulties, it is important to offer justifications for the choices made by AI models in IDS [13]. Extraction and comprehension of the primary features influencing these AI models' actions in IDS constitute a primary step toward meeting this demand."}, {"title": "2.4 Explainable AI", "content": "The area of explainable AI (XAI) has just come into existence as a means of addressing the black-box character of most AI models. With a particular focus on comprehending the elements that go into a model's decision-making process in tasks including classification or regression, XAI seeks to shed light on the interpretability of AI models and it includes several subfields, such as methods that provide explanations for the behavior of AI models at the local level (unique to individual instances) or the global level (across several data instances). These methods can be model-agnostic, which means they can explain any kind of AI model, or model-specific (i.e., they are made to explain particular kinds of AI models). Furthermore, XAI uses explanation techniques such as feature value evaluation to provide a feature priority list for an AI model, or building surrogate models to explain complicated models using simpler ones."}, {"title": "2.5 Benefits of XAI for Network IDS", "content": "The existing AI-based intrusion detection system produces output that is difficult for human analysts to comprehend. Analysts must thus manually review a large number of records in order to spot unusual activity. Furthermore, they encounter difficulties in locating and resolving problems with the AI models themselves. Therefore, in the field of network intrusion detection, obtaining high-accuracy results and also elucidating the behavior and decision-making process of the AI system becomes paramount. Trust in the AI algorithms will be established if security analysts can understand the judgments that the algorithms make. Given this, our XAI-based approach, which selects intrusion features using black-box XAI techniques, represents a significant advancement in the area.\nAfter outlining the essential prerequisites for network intrusion detection and the necessity of improving feature selection via the use of XAI-based methodologies, we go on to describe the key elements of our XAI-based framework for choosing primary intrusion features in network intrusion detection assignments."}, {"title": "3 Framework", "content": "3.1 XAI-based Workflow Sections for Choosing\nFeatures\nThe low-level elements of our XAI-based feature selection process are now explained. The various elements (depicted in Figure 1) are elucidated thereafter.\nIntrusion Dataset Loading: Our framework's first step is to load the data from the database. We start with two well-known network intrusion detection datasets: CICIDS-2017 [63] and RoEduNet-SIMARGL2021 [53].\nExtraction of Features: The next phase in our framework is to choose a basic set of features from the database's log files after the database has been loaded. The AI model's results are significantly influenced by the feature extraction method since some characteristics may represent the nature of network traffic more accurately than others. To extract a basic set of characteristics for each network intrusion dataset, we employed the same methods as in prior works [53,63].\nReduction of Redundancy: After loading the database and finishing the basic feature extraction, the next step is to remove duplicate items from the traffic. Redundancy is frequently present in network traffic [44], and eliminating it is essential to avert the intrusion detection AI model's possible underperformance. We just need to remove every row that is precisely the same to do this. Moreover, we randomize the rows as a preprocessing step before training. This stage is required since attack labels may have been used to arrange the data sequentially. By arranging the rows in a random order, you can make sure that there is no bias introduced into the training data due to entry order.\nData Distribution: We also handle the problem of data imbalance in our architecture. Both of our datasets show an imbalance where the usual traffic greatly surpasses the attack traffic, as seen in Table 3. Remarkably, while developing strong AI models for network security, the issue of imbalanced network traffic types frequently arises [12]. We use the random oversampling technique [57] to balance the dataset to address this problem. By oversampling the cases of the minority class, this strategy makes sure that all classes of network traffic are balanced. Our datasets are huge, and the random oversampling approach is successful in balancing them despite its simplicity [57]. The AI model may learn from a representative collection of data by creating a more balanced distribution of cases across different classes through data balancing.\nNormalization of Features: We use a conventional feature normalization step (min-max feature scaling) to avoid scale differences between distinct traffic features. By bringing all characteristics to a uniform numerical scale, this procedure makes sure that there are no magnitude differences throughout the dataset. We provide a consistent representation that makes training and analyzing the AI model easier by normalizing the characteristics.\nTraining Black-box AI Models: After the database is ready, we begin training the AI model. To do this, we separated the data into a training set, which comprised 70% of the entire set, and a testing set, which included the remaining 30%. Notably, we have included seven popular AI classification models at this stage: k-nearest neighbors (KNN), LightGBM, Adaptive Boosting (AdaBoost), support vector machine (SVM), random forest (RF), deep neural network (DNN), and multi-layer perceptron (MLP). Every model is trained using a unique set of parameters for optimal outcomes. We have carefully adjusted each model's parameters to maximize its effectiveness (see Appendix A for a comprehensive setup).\nEvaluating Black-box AI Models: In our architecture, testing each of the seven AI models with untested data comes after they have been trained. Next, we proceed to use the test data that has not been seen to examine how well these models work. To assess each AI model's efficacy for this performance study, we first construct a confusion matrix for it. From there, we extract several common indicators. Accuracy, precision, recall, F1-score, Matthews correlation coefficient, balanced accuracy, and the area under the ROC curve are some examples of these measurements. To evaluate the computing efficiency of each AI model, we also provide the training and testing run times.\nXAI Global Feature Selection: It is essential to remember that the AI models we have developed and assessed for our framework fall under the category of \"black-box\" models. Therefore, it becomes imperative to explain these models together with their related characteristics (traffic log data) and labels (attack kinds). Consequently, using XAI approaches for feature selection is the next step in our architecture. For every characteristic, we produce global significance values. This is accomplished by creating a variety of graphs that let us infer how each attribute affects the AI model's decision-making process. These realizations help to improve comprehension and expectations regarding the behavior of the AI model in IDS. We use SHAP global graphs, which are based on the theory of Shapley values [50], for this purpose. The Shapley value for a given feature is estimated using coalitions, which are graphs that show the average marginal contribution of each feature value over all conceivable feature combinations.\nAfter outlining the primary elements of our system, we go into further depth about the suggested feature selection techniques and the baseline techniques we employed in our current study."}, {"title": "3.2 IDS Feature Selection Methods", "content": "Starting with an XAI methodology termed SHAP [50], we first describe our suggested feature selection techniques.\nModel Specific Features: The global rankings of features for the examined datasets were acquired using SHAP. For every AI model, the most important features are taken from this rank. Since we employ seven distinct AI models, we extract the top-ranked attributes for each model that influence the algorithm's choice of which incursion class to detect.\nCommon Features by Overall Rank: By ranking each feature independently of other models, this technique produces a single feature rank that applies to all models. To do this, the average rank of every single characteristic across all AI models is determined.\nCommon Features by Overall Weighted Rank: This approach expands on the earlier one. The distinction is that, as opposed to sequential numbering, it considers the correctness of each AI model and the SHAP values for every feature. The product of the SHAP value and the accuracy of the AI model for that feature determines the feature's relevance. Next, a weighted sum that takes into account the accuracy of the AI model as well as the SHAP relevance of each feature is averaged to rank the features.\nCommon Features by Overall Weighted Normalized Rank: With one exception, this approach is identical to the previous one. Every SHAP value is normalized. It was discovered throughout the trials that some models, such as LightGBM, provide SHAP values that are significantly larger than those of other models. To prevent this kind of bias, the normalizing step was included.\nModels + Attacks Ranking Score: This method extracts significant intrusion features via selecting the top-k ranked features across all different AI models and all different intrusion types. Suppose the set of AI intrusion detection models is denoted by $M$ in which each entry $m \\in M$ represents one black-box AI model and that the set of intrusion types be given by $A$ in which $a \\in A$ represents one intrusion class. We calculate the overall ranking score of each feature (given by $r_i$) as follows. $r_i = \\sum_{m \\in M} \\frac{r_{im}}{|M|} + \\sum_{a \\in A} \\frac{r_{ia}}{|A|}$, where $r_{im}$ and $r_{ia}$ are the ranks of feature i for model $m \\in M$ and intrusion $a \\in A$, respectively. The overall ranking score of a feature i ($r_i$) is given by the weighted sum of both the feature rank across all AI models and across all intrusion types. We then chose the k features with the lowest rank value. Note that the lower the $r_i$ value, the higher the feature rank.\nCombined Selection: Using this approach, we assign a weight to each feature based on how frequently it appears in the top-k features across all feature selection techniques that have been suggested. Put differently, the choice of a characteristic in this case is determined by its overall significance when compared to all other suggested approaches."}, {"title": "3.3 Traditional Feature Selection Methods", "content": "Next, we provide popular feature selection techniques that serve as benchmarks for our suggested techniques in this study. Most of these techniques do not require prior model training.\nChi-square [27]: This is a well-known statistical technique that considers two occurrences and calculates their independence. An attribute is more important when its chi-square value is higher.\nFeature Correlation [73]: The correlation between each pair of attributes is measured using this approach. When two traits are closely connected, only one of them may take their position.\nFeature Importance [23]: To assess the significance of features on an artificial classification problem, this approach uses a forest of trees to determine the features' value for a dataset.\nInformation Gain [43]: This approach evaluates a dataset's properties according to information theory's notion of information gain. The entropy of the target variable is measured both before and after the dataset is divided based on a certain characteristic to determine the information gain.\nK-best [14]: The top-K most informative features from a dataset are to be chosen using this feature selection technique. It is a simple method that chooses the K characteristics with the highest scores after ranking the features according to a given criterion."}, {"title": "3.4 Feature Selection Methods from Xplique", "content": "Next, we provide the primary feature selection techniques that we employed in our study using Xplique [25], a recent XAI tool. It can be described as a Python feature selection toolkit package that focuses on explaining complex TensorFlow-based neural network models. Users can choose from a variety of XAI methods in this library to test various approaches or assess how well different methodologies are explained.\nSaliency [75]: Saliency maps draw attention to the key areas in an input image or set of data that affect how the model predicts a certain class. The back-propagation approach is used internally by these maps, and it focuses on determining the class derivatives while taking the input data into account. They aid in visualizing the input components that have an impact on the AI model's conclusion. A saliency map representing the pixels associated with the item or class in the picture or input data, respectively, is the end product.\nIntegrated Gradients [81]: One way to link the model's prediction to its input attributes is to use integrated gradients. The process computes the gradients between the input and the baseline. Afterward, the attributions are obtained by integrating such gradients along this path. It is regarded as one of the deep neural network techniques with the highest degree of reliability [81].\nOcclusion [92]: The Occlusion approach is concealing or deleting portions of the input in a methodical manner and then monitoring the effect on the model's prediction. The procedure checks to see if the model bases its prediction on the context that is, the data around the item. It accomplishes this by methodically applying a gray square or pre-set value to the relevant area of the input data and tracking the correctness. Therefore, it is helpful to know which areas are essential to the model's conclusion.\nSmoothGrad [77]: Deep neural networks can use the SmoothGrad approach to lower noise in their sensitivity maps. To create a smoother representation, it entails creating many sounds, adding them to the relevant pictures, calculating the saliency map for each, and then averaging them. This procedure enhances the coherence and sharpness of sensitivity maps [77] while lowering visual noise.\nVarGrad [2]: Similar to SmoothGrad, VarGrad adds a variation term that is used to produce explanations. The explanation variance that results from introducing noise to the input is called VarGrad. VarGrad captures higher-order partial derivatives, which sets it apart from SmoothGrad [2].\nSquareGrad [32]: An expansion of SmoothGrad, SquareGrad incorporates squared Gaussian gradients into the noise-adding averaging procedure. The primary distinction between the original SmoothGrad approach and SquareGrad is that the former squares each estimate before averaging it. The feature magnitude may matter more than the direction [32].\nDeconvNet [92]: A method for displaying characteristics that convolutional neural networks (CNNs) learn is called DeconvNet, also known as Deconvolutional Network. It maps the activations back to the input space using a technique akin to deconvolution. Rebuilding feature activations using processes including unpooling, rectification, and filtering allows DeconvNet to recreate the activation of the ConvNet layer. The DeconvNet-obtained visualization sheds light on the roles played by intermediate feature layers and the AI classifier [92].\nGradientInput [74]: By multiplying the input to a neuron by the output gradient regarding that neuron, this approach determines the gradient input. In this way, it takes into account both the sign and intensity of the input and gives information about how relevant the input characteristics are to a neural network. It is an effective tool for examining network activity because of its level of detail, which highlights important characteristics and their effects on the network.\nLIME [68]: Through the process of introducing perturbations around the sample of interest and abstracting its behavior, an approach known as Local Interpretable Model-Agnostic Explanations (LIME) with a local scope builds a surrogate model around the region of interest. Because of this, such a model is an easier-to-understand version of the original model while maintaining the same behavior in the relevant domain. This has the benefit of being more explainable than the original model.\nDrawing on Xplique's several feature selection techniques, we provide a straightforward voting procedure that applies to each of these approaches, as elaborated below.\nVoting: Our suggested voting approach is based on a frequency analysis of all the earlier feature selection techniques that Xplique was used to assess. The method uses a point system where the least significant feature is assigned a score of one, and each subsequent characteristic's value is increased by one until it reaches the highest point. Thus, out of 10 attributes, the least significant is assigned a score of one, while the most significant is assigned a value of ten. Because there are nine Xplique approaches, we add up all the points that each feature has received. Next, we arrange the features in descending order to determine which characteristics are the most important using this straightforward voting method."}, {"title": "3.5 Feature Explanation", "content": "Our framework's last part entails taking specific measurements out of the overall feature descriptions. In particular, we concentrate on extracting characteristics that are distinct to the incursion and traits that are specific to the model. The most crucial elements of every AI model are referred to as model-specific characteristics. The relevance of these traits in impacting the model's decision-making process is what led to their identification. We can learn more about the precise traits that influence the AI model's predictions by obtaining model-specific attributes. Conversely, intrusion-specific traits are those that are most closely linked to a given kind or class of network intrusion. These characteristics are essential to comprehending what makes the various forms of intrusions unique. We are able to determine the essential characteristics that aid in distinguishing and identifying particular kinds of network intrusions by extracting information specific to intrusions.\nImportance of Features for Different Attacks: The creation of a list of the best characteristics for every kind of assault is a significant result of our system. Security analysts may use this information to narrow down certain log data aspects that are indicative of various attack types, which is useful when they are looking into suspicious network traffic. This feature importance analysis may also help modify current intrusion detection systems (IDS) by offering user-friendly dashboards that are customized to the unique attack patterns seen in an organization's historical data. Remember that the seven major attack types in the two datasets we analyzed in our work-normal traffic, DoS, PortScanning, Brute Force, Infiltration, Web assault, and Bot-are the subject of our present analysis. Using two datasets, CICIDS-2017 and RoEduNet-SIMARGL2021, we want to have a better knowledge of the feature importance for each sort of assault. It is important to note that the CICIDS-2017 dataset includes information on all attack types, but the RoEduNet-SIMARGL2021 dataset only includes information on DoS and Port Scan attacks combined with regular traffic. The distribution of samples across various attack labels and the number of samples available in each dataset are shown in Table 3.\nComprehensive List of Top Network Intrusion Features: We provide the full list of important network intrusion features for the two datasets this study examines, together with the relevant explanations, to help readers better comprehend these aspects. The rest of the article will make frequent references to these feature lists. In particular, a thorough explanation of every feature in the RoEduNet-SIMARGL2021 network intrusion dataset can be found in Table 1. In a similar vein, each feature in the CICIDS-2017 network intrusion dataset is described in Table 2."}, {"title": "4 Evaluation", "content": "We provide a thorough examination of our evaluation results in this part to answer the following important queries:\nHow well do black-box AI models perform on the two network intrusion datasets that are being examined?\nHow can XAI help identify the key characteristics of various AI models for intrusion detection?\nWhich characteristics are essential for identifying and categorizing every kind of intrusion?\nDo many kinds of AI models share any common, significant intrusive features?\nWhat effect does feature selection have on how well AI models identify network intrusions?"}, {"title": "4.1 Description of Datasets", "content": "RoEduNet-SIMARGL2021 [53]: This dataset comes from the SIMARGL project, which was a joint venture between the Romanian Education Network"}, {"title": "4.2 Design of Experiments", "content": "Coding Resources: For the construction and analysis of our various black-box AI techniques, we employed several open-source toolboxes (including Keras, Scikit-Learn, Pandas, and Matplotlib).\nXAI Methods: The following XAI tools were employed in our assessment:\n(a) SHAP [50]: We employed the widely utilized Shapley Additive explanations (SHAP) XAI toolkit [50]. For our AI models, we generated global features and associated techniques using that SHAP tool.\n(b) Xplique [25]: For feature selection, we additionally utilized the Python toolkit Xplique library [25], emphasizing explainability and comprehension of complex neural network models. This collection of techniques includes descriptions, examples, and links to official publications for a wide range of approaches (e.g., Saliency, Occlusion, Integrated-Gradients, SmoothGrad, VarGrad, SquareGrad, GuidedBackprop, DeconvNet, among others). It enables the user to assess model explanations based just on TensorFlow or try other approaches.\nAI Methods: We assess black-box AI methods and various components of our proposed XAI-based feature selection framework for a better understanding of network intrusion detection tasks by pairing seven popular AI classification algorithms: deep neural network (DNN) [83], random forest (RF) [88], AdaBoost (ADA) [91], k-nearest neighbor (KNN) [47], support vector machine (SVM) [84], multi-layer perceptron (MLP) [52], and light gradient-boosting machine (LightGBM) [39].\nHyper-parameters: We list the primary hyper-parameter selections in Appendix A for each of the many AI models that were employed in this study.\nBlack-box AI Metrics: We use a commonly used set of criteria for assessing intrusion detection and classification issues to evaluate the performance of the black-box AI models. The measures that fall under this category include balanced accuracy (Bacc), Matthews correlation coefficient (MCC), accuracy (Acc), precision (Prec), recall (Rec), and F1-score (F1). The effectiveness of the AI model is also determined by calculating the AucRoc (area under the ROC curve) score.\nSelecting Features for XAI Techniques Evaluation: We produce a variety of feature selection techniques for evaluating XAI approaches to offer performance insights. Global summary charts, which provide a summary of feature rank throughout the dataset, are one of these techniques. Furthermore, we ascertain the significance of each feature for every form of assault, pinpointing the primary attributes that serve as indicators of the existence of particular attack kinds. Additionally, we examine the overall feature rank for each dataset, emphasizing the top characteristics that are shared by several AI models. These techniques offer a thorough assessment of the XAI-based feature selection techniques put forward in this study."}, {"title": "4.3 Findings of the Evaluation Results", "content": "Superiority of our Feature Selection Methods: The comparison results between all feature selection methods (i.e.", "Performance": "The overall effectiveness of our various black-box AI models for IDS is then displayed utilizing various feature selections (all features, top-15, top-10, and top-5). For the RoEduNet-SIMARGL2021 and CICIDS-2017 datasets, respectively, these performances are displayed in Tables 5-6. They display the many metrics that"}]}