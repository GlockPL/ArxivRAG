{"title": "On the Exploration of LM-Based Soft Modular Robot Design", "authors": ["Weicheng Ma", "Luyang Zhao", "Chun-Yi She", "Yitao Jiang", "Alan Sun", "Bo Zhu", "Devin Balkcom", "Soroush Vosoughi"], "abstract": "Recent large language models (LLMs) have demonstrated promising capabilities in modeling real-world knowledge and enhancing knowledge-based generation tasks. In this paper, we further explore the potential of using LLMs to aid in the design of soft modular robots, taking into account both user instructions and physical laws, to reduce the reliance on extensive trial-and-error experiments typically needed to achieve robot designs that meet specific structural or task requirements. Specifically, we formulate the robot design process as a sequence generation task and find that LLMs are able to capture key requirements expressed in natural language and reflect them in the construction sequences of robots. To simplify, rather than conducting real-world experiments to assess design quality, we utilize a simulation tool to provide feedback to the generative model, allowing for iterative improvements without requiring extensive human annotations. Furthermore, we introduce five evaluation metrics to assess the quality of robot designs from multiple angles including task completion and adherence to instructions, supporting an automatic evaluation process. Our model performs well in evaluations for designing soft modular robots with uni- and bi-directional locomotion and stair-descending capabilities, highlighting the potential of using natural language and LLMs for robot design. However, we also observe certain limitations that suggest areas for further improvement.", "sections": [{"title": "I. INTRODUCTION", "content": "Robots constructed from soft, modular components offer the flexibility to be quickly redesigned or reassembled to adapt to new environments [1, 2]. However, designing these robots remains a challenge within the robotics community due to the interleaving complexities involved in the combinatorial exploration of modular compositions and the differentiable optimization of control policies. Adapting these robots to various physical environments, characterized by differing terrain, obstacles, and frictional properties, further exacerbates these challenges. Traditional design pipelines rely heavily on extensive trial-and-error experiments to identify viable designs from a vast pool of possibilities, making the design process particularly tedious when tackling robots consisting of many modules in a complex physical environment [3]. Producing a reasonably optimized design remains impractical, particularly for common users, due to the significant engineering and physics expertise required in the design process.\nWhile a few recent works have begun to explore ML-based models for robot design [4, 5, 6], they often simplify the task by limiting the number of unit robots and predefining the shapes and functionalities of building blocks. These predefined elements rely heavily on expert knowledge in robotics, limiting the flexibility and scalability of these models. To our knowledge, none of the modular robot design frameworks have utilized large language models (LLMs), and we are particularly interested in exploring the potential and capabilities of LLMs for this purpose. In view of recent advances in the field of natural language processing (NLP) where natural language is used to represent task settings and environments in high-dimensional semantic space [7, 8], this paper explores a new direction by exploring the feasibility of using NLP models to generate robot designs in general, unconstrained scenarios. This end-to-end setting adopts natural language as the connecting cord throughout the robot designing pipeline, relieving the requirement of expert-level knowledge and introducing high levels of flexibility to the designs.\nSpecifically, we investigate how the expressive flexibility of natural language can represent robot designs, enabling the training of large language models (LLMs) for the robot design task. To overcome the difficulty of supervising the"}, {"title": "II. RELATED WORK", "content": "Modular Self-reconfigurable Robots (MSRRs): MSRRS present a significant departure from traditional construction methods. These robots are made up of multiple modules, each possessing the ability to move and mechanically connect with one another[9, 10]. This enables them to restructure and adapt to a variety of tasks [11]. Historically, these modules have been rigid. However, the introduction of compliance and flexibility to these modules has expanded the capabilities of soft modular robots. This evolution offers new modes of actuation, mobility, and even safer interactions with humans [1, 3, 12, 13].\nSoft Modular Robots: These robots, with their increased flexibility, can perform a variety of functions by deforming into different shapes from various initial configurations [1, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]. For instance, Zhao et al. [24] developed identical self-reconfigurable blocks called Starblocks, which can achieve diverse forms of locomotion by assembling into configurations such as a self-assembled wheel or a quadruped. Additionally, these blocks can be configured into a robotic arm with a gripper for prehensile manipulation, a lattice for non-prehensile manipulation, or even a tent-like structure for formation tasks. Configurations have spanned from simple chain-like formations to sophisticated designs, all aiming to support activities like locomotion, manipulation, and transformation.\nRobot Design through Manual Assembly and Iterative Testing: In both rigid and soft self-reconfigurable modular robots, the majority of contemporary research still necessitates the manual design of distinct assembled configurations to fulfill various tasks. Though these methodologies prove effective, they often involve significant labor and multiple iterations of trial and error to pinpoint the optimal configuration [25, 24, 17]. Automating the design of these configurations for various environments and tasks is a crucial area for exploration.\nRobot Design Using Learning-Based Techniques: There are several studies that using learning-based methods to design rigid modular robots with different types of components. Whitman et al. [4] apply deep reinforcement learning to design modular serial manipulators for specific tasks. Specifically, the study uses 11 types of modular components, including three base mount orientations, one actuated joint, six different links/brackets, and one end-effector. There are constraints between those modular components, such as the maximum number of modules allowed in a configuration, limited to 16, and the need to ensure physical and functional compatibility between the components, which dictates how they can be arranged to achieve the desired task performance.\nRoboGrammar, done by Zhao et al., introduce an automated framework that generates optimized robot structures by leveraging a recursive graph grammar and various robot components, including body segments, limbs, and joints, to navigate diverse terrains effectively [5]. Hu et al. [6] investigate robot design using a generative adversarial network (GAN) called RoboGAN, which works with modular robots composed of different types of modules: body, legs, wheels. RoboGAN learns a mapping from tasks (e.g., terrain types) to a distribution of modular robot designs. Unlike traditional methods that typically produce a single optimal design, RoboGAN can generate multiple distinct designs that are all viable for the given task.\nHowever, all related works focus on designs composed of rigid, function-specific modules, which offer relatively lower flexibility compared to soft modular robots. To our knowledge, there is no research on designing soft modular robots. Our work addresses this gap by focusing on identical soft modules that can connect freely in any direction, supporting diverse configurations for various tasks. This design space is vastly larger and not predefined, requiring a generative model to manage its complexity. Additionally,"}, {"title": "III. METHODS", "content": "This paper explores the use of LLMs for designing soft modular robots, employing a natural language generation input and output style. The following subsections provide details on the configuration and training/evaluation processes of our proposed model.\n\nA. Robot Designing Model\n\nWe adopt a generative LLM to design robots with pre-specified environments, task objectives, and structural re-quirements. Input and output formats of the model are specified in Sections III-A.1-III-A.2, respectively.\n1) Environment and Task Representation: Leveraging the LLMs' proficiency in understanding natural language, we craft the prompts in natural language, instructing the model to \"Design a soft modular robot for [task-objective] for [distance] in [environment] using [structural-constraints].\" Here, [task objective] and [environment] are essential pa-rameters that link the model to the simulation tool, enabling the model to learn to generate legal and high-quality robot designs. [Distance] and [structural constraints] are optional parameters introducing variability into the prompts and aid in minimizing the risk of overfitting. Below are two example prompts that share the same task objective and environment but vary in their specifications:\n\"Design a soft modular robot for walking from left to right on a flat plane using at most 9 blocks.\"\n\"Design a soft modular robot for walking from left to right for at least 6 body_length on a flat plane.\"\nTo demonstrate the workflow, we design three specific task objectives: unidirectional and back-and-forth locomotion on a horizontal plane, and stair-descending locomotion.\n2) Design Representation: The design representation consists of two parts, i.e., a block-definition section and an ensemble sequence section. Specifically, the block definition section specifies the properties and constraints of the individual blocks that will be used in the robot's construction. The robot ensemble section then provides a step-by-step description of how these blocks are assembled to form the complete robot, detailing the spatial and functional relationships between the blocks to achieve the desired design. Since each robot design could be assembled in arbitrary orders, it could be mapped to multiple language representations, enabling easy data augmentation via breadth-first search (BFS). An example design of a robot and one possible language representation of it is illustrated in Figure 3.\n\nB. Evaluation Metrics and Settings\n\nWe define five reference-less metrics to evaluate soft modular robot designing models from the instruction-following, optimality, and novelty aspects. (1) The instruction-following metric (IF) assesses how closely a model's generated robot designs adhere to the structural requirements specified in the prompts. (2) The promise score (PS) estimates the total locomotion distance that each robot designed by the model can achieve within a long duration. (3) The task optimality metric (OPT) gauges the efficiency of the robot designs by measuring the time needed to complete the tasks specified in the prompts. (4) The generalizability metric (GEN) calculates the percentage of robot designs not previously seen in the model's training data, highlighting the model's ability to improvise instead of memorize. (5) The"}, {"title": "IV. ROBOT DESIGN AND CALIBRATION OF SIMULATION", "content": "This section outlines the design of our two-dimensional (2D) robotic model and the subsequent calibration of its simulation counterparts. The calibration process is driven by the utilization of empirical data from real-world robot operations, ensuring that the simulations accurately reflect the behaviors observed in the actual robots.\n\nA. Robot design\n\nAn individual module (Figure 2(a)) consists of a skeleton, four shape memory alloy (SMA) coils (coil diameter: 3.45 mm; wire diameter: 0.51 mm, Dynalloy), and spherical magnets (diameter: 3/8\u201d). The skeleton has an 'x' shape that matches the shape used in the simulator, with four equal-length bars connected at the center. It is printed from flexible TPU material with an infill density of 100% to provide a stronger adversarial bending force, helping restore the module's original shape after SMA contraction. The SMAS are mounted between the adjacent bars.\nEach SMA spring is crimped with fishing wire and electric wire in a ferrule and attached to grooves in the skeleton. The detwinned Martensite rest length of each SMA is longer than the distance between the grooves, allowing extension when the skeleton deforms due to SMA actuation. The edge length of each module is about 7.2 cm. The Austenitic (actuated) rest length of the actuators is 1.2 cm, while the detwinned Martensite rest lengths are set to 3.7 cm upon installation. These lengths can change with actuation cycles due to variations in antagonistic forces from other SMA actuators and the elastic energy stored in the deformed soft skeleton. When the SMAs are actuated, they deform the skeleton. As they cool, the restoring force of the skeleton stretches the SMAs back to their detwinned Martensite rest length. We control the SMAs in an open-loop manner by actuating them for a specific duration under 5V. Physical experiments were conducted for each application to determine the appropriate actuation duration. Each SMA coil needs 15-20 seconds to cool down and recover."}, {"title": "V. EXPERIMENTS", "content": "We evaluate the performance of our proposed model using the five quantitative metrics outlined in Section III-B, complemented by qualitative analyses of representative generations. We use five prompts for each task objective and generate 10 robot designs per prompt for quantitative evaluation. The model employs a GPT-NEO [29] backbone and is trained using synthetic data across all three task objectives introduced in Section III-A.1. We aggregate the scores for each task objective and present them in Table I.\nIn response to all prompts, our proposed model consistently generates legal robot designs, ensuring that all modules are correctly interconnected without any \"floating\" or detached ones indicated by the relatively high success rate (SR) (over 89%) score. The instruction following (IF) score of over 60% shows the majority of robots designed by our model satisfy the structural and task-oriented requirements in the prompts.\nThe task optimality (OPT) and promise score (PS) metrics further show that the designed robots can complete the tasks within reasonable timeframes and have the capacity to travel longer distances than required within simulation time(on average 14.16 block lengths). For the generalizability (GEN) metric, which evaluates the creativity of robot-designing models, our model scores between 71% and 81%. This range indicates that the model generates robots distinct from the training data most of the time. Such results suggest our model's ability to infer the geometric and structural char-acteristics of superior robots rather than merely memorizing good robot designs in the training data.\nTo verify that the geometric and structural information of robots is captured and utilized by our model when producing robot designs, we use UMAP [30] to visualize the encoding of robot designs in the latent encoding space of our model. Our guiding hypothesis is that the similarity in the encodings of two robots indicates the model's perceived similarity between them. To preclude information leakage stemming from the binary choices training objective, we randomly select 1,000 robots not included in our model's training dataset and generate UMAP visualizations for these sampled robots. The UMAP visualization is displayed in Figure 6, with one representative robot design shown on the side of each cluster to reveal the clustering evidence.\nThe visualization indicates that our model effectively encodes the geometric characteristics of robot designs, e.g., the model distinctly clusters robots with varying aspect ratios within its latent space, suggesting the potential of our model to generate robot designs within complicated environments such as crawling through a small hole. Additionally, our model exhibits understandings of critical design elements such as the presence of legs and the optimal positioning of the robots' centers of mass. For example, designs with no"}, {"title": "VI. DISCUSSION", "content": "Section V has proven the overall strength of our proposed approach, and this section delves deeper into the contributing factors of our model's superior performance via a series of ablation studies.\n\nA. Training Objective Ablation Experiments\n\nAs shown in Table II, ablating the CLM objective (no-CLM) leads to higher failure rates according to the IF and SR metrics and a comparable preference over task optimality, reflected in the PS and OPT scores. This suggests that the ablated model focuses less on representing legal and walk-able robot structures but instead prioritizes characteristics beneficial for accelerating the robots' movement. Conversely, the no-Compare model generally succeeds in designing robots as instructed in the prompts, though it occasionally overlooks the optimality of the designs.\nThis trend is supported by our qualitative assessments illustrated in Figure 7d, where the no-Compare model tends to produce more stable and symmetric designs that are, however, challenging to mobilize. On the other hand, the no-CLM model's creations often demonstrate more effective locomotion despite the high failure rate (Figure 7e). As such, we claim that incorporating both training objectives is crucial to ensure that the model adheres to instructions while also taking care of design quality,\n\nB. Task Ablation Experiments\n\nWe further investigate the importance of task diversity to the generalizability of our model. Specifically, models trained on single tasks (uni, back, and downstairs) often perform well on their specific training objectives while suffer on tasks outside their training data. Introducing a second training objective (uni-back, uni-downstairs, and back-downstairs models) effectively narrows these performance gaps. These observations suggest that incorporating additional task objectives could enhance our models' capacity for solving other untested tasks, helping broaden the scope of robot designs using our model and leading to innovative and effective solutions difficult for experts to design.\nOur manual examinations also reveal that the two-task models display better adaptability to the third task which they are not familiar with. For instance, the uni-downstairs model is prone to generating symmetric configuration to facilitate forward and backward walking (Figure 7i) and the uni-back model tends to increase weight distribution towards the back for enhanced stability when moving down-stairs (Figure 7j). These observations are consistent with our quantitative findings, suggesting that training the models with multiple objectives fosters greater generalizability and encourages the models to generate robust and versatile robot designs for complex tasks.\n\nC. Impacts of Training Data Sizes\n\nWe conduct repeated training and evaluations of our model using three different subsets of the training data, ranging from 40% to 80% in increments of 20%. The models corresponding to these data subsets are denoted as 0.4T, 0.6T, and 0.8T. Our observations indicate that using less training data results in greater variability in the model's performance across different environments and task objectives. For instance, the 0.4T model outperforms the 0.6T and 0.8T models in the stair descending task but significantly underperforms both models in the back-and-forth locomotion"}, {"title": "VII. CONCLUSION", "content": "We introduced a new approach combining pre-trained language models (LLMs) and differentiable physics simulation tools to automate the design of soft modular robots tailored to specific environments and task objectives. To evaluate the approach, we propose five metrics that assess the quality and generalizability of these designs in different physical contexts. We demonstrate the efficacy of our approach by creating appropriate robots following natural language in-structions to accommodate different design tasks."}, {"title": "VIII. LIMITATIONS AND FUTURE WORK", "content": "One limitation of our current system is the slow cooling time of the Shape Memory Alloy (SMA) coils, which re-stricts the locomotion speed of the robot. Although SMAS were chosen for their favorable force-to-mass ratio and high work density-making them effective for quickly and efficiently demonstrating our concept-this slow cooling time is a significant drawback for practical applications. To address this limitation, we are exploring the replacement of SMAs with alternative actuators, such as motors, which could increase actuation speed and allow for untethered operation. This change would enhance the adaptability of the modules to more complex environments, making the system more suitable for practical applications.\nWe used computer vision with color-coded markers to track the (x,y) positions of all robot vertices. However, discrepancies exist between the real and simulated robots: real-world connections have four nodes on the connecting line, while the simulation, limited by DiffTaichi, has only two. Adjusting the simulation would require major changes to DiffTaichi's core. Perfect alignment remains challenging, especially as simulations show more bounce than real tests, which cannot be easily corrected through parameter tuning.\nTo address these challenges, we are developing a special-ized physical engine tailored to our robots' specific physical properties to enhance simulation fidelity. While the primary objective of this paper is to validate the use of learning-based methods for designing soft modular robots, narrowing the gap between simulated and real-world performance remains a key focus for our future work.\nAs this is the first work to use natural language for designing soft modular robots, there is no baseline for direct comparison. The closest research involves rigid modular robots, which have smaller search spaces due to fixed block functionality and limited connection options. Thus, we com-"}]}