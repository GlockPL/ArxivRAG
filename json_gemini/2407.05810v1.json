{"title": "Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT", "authors": ["Xinrui Song", "Jiajin Zhang", "Pingkun Yan", "Juergen Hahn", "Uwe Kruger", "Hisham Mohamed", "Ge Wang"], "abstract": "The integration of artificial intelligence (AI) chatbots into higher education marks a shift towards a new generation of pedagogical tools, mirroring the arrival of milestones like the internet. With the launch of ChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching application (https://chat.openai.com/g/g-limx1py4K-chatge-medical-imaging) and integrated it into our undergraduate medical imaging course in the Spring 2024 semester. This study investigates the use of ChatGPT throughout a semester-long trial, providing insights into students' engagement, perception, and the overall educational effectiveness of the technology. We systematically collected and analyzed data concerning students' interaction with ChatGPT, focusing on their attitudes, concerns, and usage patterns. The findings indicate that ChatGPT offers significant advantages such as improved information access and increased interactivity, but its adoption is accompanied by concerns about the accuracy of the information provided and the necessity for well-defined guidelines to optimize its use.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) represent a significant advancement in artificial intelligence (AI), based on their inherent model capacities and other cutting-edge deep learning technologies, such as self-supervised pre-training. The principle of next token prediction allows the generation of text or more generally a sequence of multimedia tokens that is not only coherent but also contextually relevant. Trained on extensive datasets, these deep models learn complex knowledge without explicit task-specific instructions. The versatility of LLMs and large vision-language models offers opportunities for artificial general intelligence and enables a broad spectrum of applications.\nLaunched on November 6, 2023, ChatGPT-4 Turbo represents a major enhancement of the family of Generative Pre-trained Transformers (GPTs). This advanced AI model builds upon the capabilities of its predecessors by synergizing text, code and image data more broadly and more deeply. The model is optimized for real-time responses that are essential for time-sensitive applications such as interactive learning, produces high-quality and contextually appropriate responses, and in particular creates sophisticated AI-driven interactions in an educational scenario.\nBased on the ChatGPT-4 Turbo platform, we developed a teaching application (https://chat.openai.com/g/g-limx1py4K-chatge-medical-imaging) for our undergraduate medical imaging course in the Spring 2024 semester. We were motivated by both the human-like communication capability of ChatGPT and the observation that the younger generations, especially college students, quickly adapt to new technologies.\nWhile higher education is generally cautious about the influences of IT innovations, our university has a long tradition in pedagogical innovation, allowing us to quickly investigate the use of AI in the classroom.\nWe believe that the potential impact of ChatGPT and other chatbots on education will be comparable to or even greater than the internet technology which has dramatically expanded the information sources available to college students. While higher education showed initial skepticism to this new technology[1], today it is difficult to imagine a university without a Learning Management System (LMS). Furthermore, the reliance on platforms like YouTube exemplifies this shift [2]. The popularity of mobile phones further facilitates access to these resources, a transition embraced by students [3]. The COVID-19 pandemic has underscored the necessity and merits of modern technological infrastructure.\nWhile the internet brought various informational resources to students, ChatGPT-type models make retrieval and extraction of knowledge much more effective and efficient. These AI models have the potential to enable individualized learning when they are used as teaching assistants (TA) or tutors. However, even for ChatGPT-4 Turbo, the state-of-the-art AI-based chatbot, there remain uncertainties about what educational utilities it offers, how much value it adds, and how to address various associated challenges. Recently, commentaries raised concerns about the adverse consequences of ChatGPT's integration into educational settings [4, 5].\nGiven the above considerations, here we evaluate our ChatGPT-4 Turbo software through a semester-long trial. We systematically collected and analyzed data concerning students' interactions with ChatGPT. Also, we compared students' feedback on"}, {"title": "2 Methods", "content": "In the study, three ChatGPT models are utilized with varying capabilities: (1) ChatGPT-3.5 serves as a freely accessible baseline, (2) ChatGPT-4 Turbo represents a significantly enhanced version, and (3) a specialized application we developed, referred to as ChatGe-Medical-Imaging or ChatGe, is tailored for teaching a college-level medical imaging course. To remove any financial barrier, we made a policy that any student can be reimbursed for one-month use of ChatGPT-4 Turbo. In the Spring 2024 semester, two separate sections of the undergraduate medical imaging course were taught by two instructors Drs. Hisham Mohamed and Ge Wang respectively, with enrollments of 36 and 34 students. The two instructors shared the syllabus, the textbook, and exam questions, as well as three MATLAB sessions to provide students with hands-on experience. According to the timeline given in the Supplementary Information (SI), we surveyed our students through three channels: students' questionnaires, course content Q&A evaluations, and students' exam grades, and analyze the data as follows."}, {"title": "3 Results and Discussions", "content": ""}, {"title": "3.1 Students' Survey Results on ChatGPT Usage and Assessment", "content": "Fig. 1 presents students' survey results from both sections on their ChatGPT usage and feedback. As shown in Fig. 1 (a), about 65% of the students from both sections used the ChatGPT models. Moreover, Fig. 1 (b) highlights that nearly all the users were aided by the chatbots for clarification of some course contents, and over half of them received ChatGPT's help for programming and homework. In addition to that, Fig. 1 (c) and (d) give information on how many hours per week the students spent using which chatbots. Next, Fig. 1 (e) confirms that the students are most impressed with the convenience and interactivity of the ChatGPT models. However, few students felt highly confident in chatbots' responses. These data indicate that the students encountered false/untrustworthy answers by ChatGPT and/or they were not able to make good judgments. This is also supported by the students' reasons for not using ChatGPT, as shown in Fig. 1 (a). Finally, Fig. 1 (f) presents the students' answers to the six survey questions listed in the SI, which are related to different aspects of ChatGPT usage. The answers are required to be on a 5-point scale so that the values above 3 are positive while the values below 3 are negative. Evidently, the general attitude towards ChatGPT use in this context is overwhelmingly positive, except for Question #2 which asks if students feel ChatGe-V1 significantly better than ChatGPT-4 Turbo. This negative feedback motivated us to upgrade ChatGe-V1 to ChatGe-V2 with more course-related materials and more specific prompts as further described in the SI."}, {"title": "3.2 Students' Preference over Different Versions of ChatGPT Tools", "content": "As mentioned already, in our course we introduced the customized ChatGPT-4 Turbo app referred to as ChatGe, whose first version is ChatGe-V1, to assist students in understanding the complex theory of medical imaging. After each lecture, the students were asked to submit questions related to the new material. The instructors and TAs selected two most relevant questions (see the SI) and prepared answers using either a human TA, ChatGPT-4, or ChatGe-V1, and then selected two out of the three answers for students to indicate and explain their preference of one over the other.\nSubsequently, we developed the second version of the app called ChatGe-V2, and repeated the comparative study on seven other questions. We asked ChatGPT-4 to summarize students' feedback on (Q1, Q2) to generate a prompt for ChatGe-V2 to enforce more tailored, student-friendly responses. ChatGe-V2 incorporates more course-relevant textbooks and other materials (more details on ChatGe-V1 and ChatGe-V2 can be found in the SI). Again, the students were asked to submit questions related to the new material, seven questions were selected (see the SI), and the answers were similarly generated for students to vote. Our analysis is summarized in Fig.2, showing that while the original ChatGPT-4 performed better than ChatGe-V1, ChatGe-V2 improved the performance, being comparable or better than ChatGPT-4 Turbo, ChatGe-V1 and even human TAs. Interestingly, we found a statistically significant difference in the preference of students who have used ChatGPT for the course and those who have not. The students who used ChatGPT statistically prefer ChatGe-V2 (p-value = 0.091 from Chi-squared test), while no statistically significant preference was found among the rest. This indicates that students accustomed to reading ChatGPT-generated answers might be more capable of extracting information"}, {"title": "3.3 Usage of ChatGPT Influenced by Promotions and Precaution", "content": "Through the questionnaires, we found a significant difference in the students' adoption of ChatGPT, being strongly correlated to the instructor's promotional or pre-cautious emphases in the classroom. In a well-intended contrast, one instructor actively promoted the use of ChatGPT, while the other more often cautioned the students about potential risks with ChatGPT. The impact of this contrast was evident in our post-exam survey: usage of ChatGPT was 87.5% in one section where ChatGPT was encouraged, but only 38.2% in the other section where ChatGPT was offered in a more conservative manner. Among students who chose not to use ChatGPT, our data shows that over half of this population doubted the accuracy of ChatGPT (Fig. 1 (a)). The remainder reported a lack of familiarity with the tools. As students become increasingly accustomed to chatbot assistants, the use of ChatGPT or similar tools is expected to rise. Moreover, advanced ChatGPT-type products now cite sources to support their output, alleviating the unreliability."}, {"title": "3.4 ChatGPT for TA Workload Reduction", "content": "As shown in Fig. 2, ChatGe-V2 generates answers much faster than our TAs (instantly vs. 15-20 minutes). Even when students' questions appear erroneous, ChatGe-V2 can infer the intended meaning of the question. Moreover, the TAs gave three lectures on MATLAB programming tasks. Instead of preparing the lectures directly, the TAs found that ChatGPT generated demonstrations as effectively as they can do. This example suggests that programming projects can also leverage the power of AI."}, {"title": "4 Data and Code Availability Statement", "content": "Data in this paper consists of survey results of each student. Anonymized data is available upon request. Survey questions are included in the supplementary material. All figures in this paper are generated with matplotlib in Python."}, {"title": "5 Competing Interest", "content": "The authors declare no competing interests."}]}