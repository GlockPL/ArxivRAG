{"title": "THE UNKNOTTING NUMBER, HARD UNKNOT DIAGRAMS,\nAND REINFORCEMENT LEARNING", "authors": ["TAYLOR APPLEBAUM", "SAM BLACKWELL", "ALEX DAVIES", "THOMAS EDLICH", "ANDR\u00c1S JUH\u00c1SZ", "MARC LACKENBY", "NENAD TOMA\u0160EV", "DANIEL ZHENG"], "abstract": "We have developed a reinforcement learning agent that often finds\na minimal sequence of unknotting crossing changes for a knot diagram with\nup to 200 crossings, hence giving an upper bound on the unknotting number.\nWe have used this to determine the unknotting number of 57k knots. We took\ndiagrams of connected sums of such knots with oppositely signed signatures,\nwhere the summands were overlaid. The agent has found examples where\nseveral of the crossing changes in an unknotting collection of crossings result\nin hyperbolic knots. Based on this, we have shown that, given knots K and\nK' that satisfy some mild assumptions, there is a diagram of their connected\nsum and u(K) + u(K') unknotting crossings such that changing any one of\nthem results in a prime knot. As a by-product, we have obtained a dataset of\n2.6 million distinct hard unknot diagrams; most of them under 35 crossings.\nAssuming the additivity of the unknotting number, we have determined the\nunknotting number of 43 at most 12-crossing knots for which the unknotting\nnumber is unknown.", "sections": [{"title": "1. INTRODUCTION", "content": "Knot theory plays a fundamental role in low-dimensional topology. A knot is a\nsmooth embedding K : S\u00b9 \u2192 S\u00b3. We say that the knots K and K' are equivalent if\nthere is an orientation-preserving automorphism 4 of S\u00b3 such that 60K = K'. We\ncan represent a knot using a projection onto S2 with only transverse double point\nsingularities, together with information at each double point about which strand is\nhigher. This is called a knot diagram. Two knot diagrams represent the same knot\nif and only if they are related by a sequence of Reidemeister moves R1-R3. For\ntextbooks on knot theory, see Burde-Zieschang [6], Lickorish [23], and Rolfsen [33]."}, {"title": "1.1. The unknotting number", "content": "The unknotting number is one of the oldest and\nmost natural, yet most elusive knot invariants. The unknotting number u(D) of a\nknot diagram D is the minimal number of crossing changes required to obtain a\ndiagram of the unknot U. The unknotting number u(K) of a knot K is defined as\n\n        u(K) := min{u(D) : D is a diagram of K}.\n\nTaniyama [36] has shown that, given any knot Kand n \u2208 N, there is a diagram D\nof K with u(D) \u2265 n.\nA more intrinsic definition of the unknotting number is obtained using crossing\narcs. A crossing arc a for a knot Kis a framed, oriented arc smoothly embedded\nin S\u00b3 such that K \u2229 a = da. A crossing change along a is obtained by performing"}, {"title": "1.2. Additivity of unknotting number", "content": "An old open question is whether the\nunknotting number is additive under connected sum.\nConjecture 1.1. For knots K and K', we have u(K#K') = u(K) + u(K').\nThere is very little theoretical evidence to support this conjecture. Scharle-\nmann [35] has shown that u(K#K') \u2265 2 if K, K' \u2260 U. More recently, Alishahi\nand Eftekhary [1] have proven using knot Floer homology that\n\n        u(K#Tp,q) \u2265 p-1\n\nfor integers 0 < p < q. However, these results leave open the possible existence of\nknots K, K' for which u(K) and u(K') are both large but where u(K#K') = 2.\nWe therefore endeavoured to find counterexamples to Conjecture 1.1. Although\nwe were not successful, we discovered a large amount of new and interesting infor-\nmation about unknotting number and about knot diagrams.\nTo find counterexamples to the conjecture, one needs to start with knots K and\nK' with known unknotting numbers, and then to find efficient ways of unknotting\nK#K'. One significant source of knots K with known unknotting number is those\nfor which u(K) = |\u03c3(K)|/2. Given two such knots K and K', then of course\nu(K#K') = u(K) + u(K') if \u03c3(K) and \u03c3(K') have the same signs. However,\nif they have opposite signs, then there is no obvious reason why K#K' cannot\nbe a counterexample to the conjecture. A further source of knots with known\nunknotting number are torus knots, and again there seems to be no known reason"}, {"title": "1.3. Finding efficient unknotting sequences", "content": "A crucial part of the strategy\nfor disproving Conjecture 1.1 is to be able to find short unknotting sequences. In\nparticular, in the case of K#K', the number of crossing changes needs to be less\nthan u(K) + u(K'). Even when one is presented with a diagram D for a knot K,\nit is not straightforward to compute u(D) when the crossing number of D is large.\nFor a knot diagram D with n crossings, u(D) \u2264 n/2, hence there are at least 2n-1\npossibilities for the subset of crossings that yield a diagram of the unknot. This\nmakes computing u(D) practically impossible when n is large.\nIn order to find out which knot invariants to use for our reinforcement learning\nexperiments, we first trained a supervised learning model on brute-forced unknot-\nting sets that predicts the probability a given crossing lies in a minimal unknotting\nset. This is an instance of behavioural cloning, the simplest form of imitation learn-\ning. This performed well above baseline, and the most useful feature was the Jones\npolynomial.\nWe then trained a reinforcement learning agent that can efficiently find an un-\nknotting sequence of crossing changes in a diagram with as many as 200 crossings.\nGiven the small amount of initial training data, this was initially evaluated on a\nbrute-forced dataset of diagrams. Thereafter, we used unknotting sets provided by\nthe agent to evaluate progress.\nWe have used various features to aid the reinforcement learning agent, and again\nfound the Jones polynomial to be by far the most useful. This suggests that the\nJones polynomial contains yet unobserved information about the unknotting num-\nber.\nBy combining the agent with lower bounds coming from invariants such as the\nsignature, \u03c4, v, and s, we have obtained a dataset of about 57k knot diagrams with\nknown unknotting numbers. We have then taken connected sums of such diagrams,\nwhich were overlaid and, in some cases, then randomly mixed using Reidemeister\nmoves. We have also run it on connected sums of braid closures that were mixed\nby inserting subwords representing the trivial braid. The agent found unknotting\nsequences that involved several crossing changes that resulted in hyperbolic knots,\nand were hence not connected sums. This has led us to diagrams of connected\nsums of knots K and K' that admit an unknotting subset of crossings of size\nu(K) + u(K'), such that any single crossing change from the unknotting subset"}, {"title": "1.4. New unknotting numbers, assuming additivity", "content": "Conjecture 1.1 has in-\nteresting consequences for the unknotting number of some prime knots. Suppose\nthat we have a sequence of unknotting crossing changes of length u(J) for a knot J.\nThen, if we change n of these crossings, the resulting knot must have unknotting\nnumber u(J) \u2013 n. Hence, if we start with a knot K#K' and find a sequence of\nu(K) + u(K') crossing changes that takes it to the unknot, then, assuming Con-\njecture 1.1, we can determine the unknotting number of all the intermediate knots\nin the sequence. Using this approach, we have obtained 43 at most 12-crossing\nprime knots with unknown unknotting numbers. This provides a method for com-\nputing the unknotting numbers of these 43 knots, assuming Conjecture 1.1. These\n43 values all coincide with the largest possible unknotting number given in the\nKnotInfo database. Conversely, if one of these at most 12-crossing prime knots\nhad smaller unknotting number than the KnotInfo upper bound, we would obtain\na counterexample to the additivity of the unknotting number."}, {"title": "1.5. Hard unknot diagrams", "content": "It is a major open problem in knot theory whether\nthere is a polynomial-time unknot detection algorithm. We say that a diagram of\nthe unknot is hard if, in any sequence of Reidemeister moves to the trivial diagram,\nthe crossing number has to first increase before it decreases. They are of particular\ninterest because they might provide counterexamples to potential unknot detec-\ntion algorithms. Hard unknot diagrams are difficult to construct, and previously\nno extensive dataset existed. Burton, Chang, L\u00f6ffler, Mesmay, Maria, Schleimer,\nSedgwick, and Spreer [7] have recently collected 21 hard unknot diagrams and 2\nspecial infinite families from the literature, 10 of which are not actually hard ac-\ncording to our definition, as they can be simplified without increasing the crossing\nnumber (though a monotonically decreasing simplification might not exist).\nInitially, we tried to construct hard unknot diagrams using reinforcement learn-\ning, where a setter performs complicating Reidemeister moves to prevent a solver\nfrom unknotting via simplifying Reidemeister moves, with little success."}, {"title": "2. SOME BACKGROUND ON MACHINE LEARNING", "content": "There are three major Machine Learning paradigms, namely, supervised learning\n(SL), reinforcement learning (RL), and unsupervised learning. In this paper, we\nwill focus on the first two.\nIn SL, we are given a labelled dataset. In other words, we know the values of\na function at certain points. We split our dataset into a training set, which is\ntypically about 80%, and a test set. We would like to learn, or approximate the\nfunction only using the training set such that the error (e.g., L2-norm) is small on\nthe whole dataset.\nThe most classical example is linear regression. More generally, Hornik, Stinch-\ncombe, and White [15] have shown that neural networks (NNs) are universal func-\ntion approximators, if one is allowed to vary the architecture. A neural network\nis a composition of a sequence of affine maps and some simple non-linearities in\nbetween, such as max(0,x) applied coordinate-wise. The network is trained using\nsome variant of stochastic gradient descent. One initialises the affine maps, for ex-\nample, randomly, then computes an approximate of the gradient of the error on\na subset of the training set (whose cardinality is called the batch size), and changes\nthe affine maps in the direction of the gradient according to some step size (or\nlearning rate). This is repeated a number of times, and a pass through the whole\ntraining set is called an epoch.\nThere have been several of applications of SL to knot theory in recent years,\nmostly aimed at finding connections between knot invariants. See, for example,\nHughes [16] and Davies et al. [9].\nRL is a machine learning paradigm where an agent (in our case, a computer\nsoftware) learns to perform actions to maximise a cumulative reward while inter-\nacting with some environment. Typical examples are provided by the games of\nchess and Go, self-driving cars, and humanoid robots that learn to walk. Training\na SL model is often much simpler than RL. There have been only two applications\nof RL to topology so far. Gukov, Halverson, Ruehle, and Su\u0142kowski [13] focused on\nunknot recognition. Furthermore, Gukov, Halverson, Manolescu, and Ruehle [12]\nhave developed RL agents that search for ribbon disks for a knot. In this rest of\nthis section, we give an overview of RL and imitation learning."}, {"title": "2.1. Markov decision processes", "content": "Mathematically, RL can be phrased as a Mar-\nkov decision process, which is a tuple (S, A, Pa, Ra), where\n\u2022 S is a set of states,\n\u2022 As is the set of actions available from state s \u2208 S,\n\u2022 Pa(s, s') is the probability that a \u2208 As leads to state s' \u2208 S, and"}, {"title": "2.2. Q-learning", "content": "A classical approach to solving Markov decision process is Q-\nlearning, where 'Q' stands for 'quality'. Its goal is to learn the state-action value\nQ(s, a), which is the expected discounted total reward if action a \u2208 A, is taken in\nstate s E S. At time t, the agent selects action at, observes a reward rt, and enters\nstate st+1. We initialise Q randomly and updated it via the Bellman equation\n\n        Q^{new}(st, at) := Q(st, at) + \u03b1(rt + \u03b3 \\max_{a \\in A_{st+1}} Q(st+1, a) - Q(st, at))\n\nwhere a \u2208 (0,1] is the learning rate or step size.\nWhen selecting an action, we face the dilemma of exploration versus exploitation;\ni.e., whether we explore the environment to potentially obtain a higher cumulative\nreward, or rely on the Q-values that we have learned so far. The e-greedy policy\nblends the two approaches by performing a random action with probability & and\nan action at \u2208 As, that maximises Q(st, at) with probability 1 \u2013 \u03b5.\nA modern version of Q-learning is deep Q-learning. Here, an artificial neural\nnetwork f: RS \u2192 RA learns the Q-values, where\n\n        f(e_s)_e_a = Q(s,a)\n\nfor the basis vector es of RS corresponding to the state s \u2208 S and the basis vector ea\nof RA corresponding to the action a \u2208 A. The weights of the network are updated\nusing the Bellman equation."}, {"title": "2.3. Importance weighted actor-learner architecture (IMPALA)", "content": "For the\nmajority of our experiments, we used the IMPALA [10] reinforcement learning\narchitecture, which is a distributed agent developed for parallelisation. It learns\nthe policy and the state value function V\u03c0 via stochastic gradient ascent. Acting\nand learning are decoupled. A set of actors repeatedly generate trajectories of\nexperience. One or more synchronous learners use this experience to learn the\npolicy \u03c0. The policy the actors use lags behind the learners', which is corrected\nusing a method called V-trace."}, {"title": "2.4. Imitation learning", "content": "During imitation learning, an agent tries to learn a pol-\nicy that mimics expert behaviour. It does not rely on a reward function. The\nsimplest approach is behavioural cloning, where a supervised learning model, usu-\nally a neural network, learns to map environment observations to (optimal) actions\ntaken by an expert.\nWe mention two other, more sophisticated approaches to Imitation Learning.\nAdversarial imitation, due to Ho and Ermon [14], is a minimax game between two\nAI models (Generative Adversarial Nets): the agent policy model produces actions\nusing RL to attain the highest rewards from a reward model that indicates how\nexpert-like an action is, while the reward model attempts to distinguish the agent\npolicy behaviour from expert behaviour. In the case of inverse Q-learning, due to\nGarg et al. [11], a single Q-function is learned. The policy is obtained by choosing\nthe action with the highest Q value, and one can recover the reward from Q."}, {"title": "3. LEARNING TO UNKNOT", "content": ""}, {"title": "3.1. Imitation learning and unknotting", "content": "We used behavioural cloning based on\na NN to predict for each crossing the probability that it lies in a minimal unknotting\nset. If the predicted probability for a crossing c is larger than 0.5, then we interpret\nthis such that c does lie in a minimal unknotting set. Expert data was obtained\nfrom brute-forced minimal unknotting sets of knots up to 30 crossings.\nThe unknotting numbers of the diagrams ranges between 1 and 8.\nSince knot diagrams are hard to feed into a neural network, the main features\nwe used were invariants of the diagram, together with invariants of all diagrams\nobtained by changing one crossing. We call this one step lookahead, which we also\nused in our RL agent. We computed invariants using SnapPy [8]."}, {"title": "3.2. Reinforcement learning and unknotting", "content": "Our goal was to train an RL\nagent that performs crossing changes in a fixed diagram D to unknot it, giving an\nupper bound on u(D). We used the IMPALA architecture. The resulting trained\nagent can determine u(D) even when c(D) \u2248 200, in which case brute-forcing is not\npossible.\nThe agent architecture is shown in Figure 3. As for imitation learning, the\nfeatures we tried were invariants of the diagram (typically the Alexander and Jones\npolynomial features from (3) of Section 3.1), together with invariants of all diagrams\none can obtain via a single crossing change (one step lookahead). For each invariant,\nan additional boolean feature showed whether the invariant calculation had failed.\nSome invariants had a large range, especially Jones polynomial evaluations, which"}, {"title": "3.3. Braids", "content": "An alternative way to represent knots is as braid closures. This has\na number of advantages. The Jones polynomial computation is exponential time.\nHowever, a polynomial-time algorithm exists for braid closures if we bound the\nbraid index [26]. However, even this gets too slow for RL when the braid index\nis over 6-8. Hence, we considered braids of at most 8 strands. Furthermore, the\nslice-Bennequin inequality, due to Rudolph [34], building on work of Kronheimer\nand Mrowka, provides easy-to-compute bounds on the unknotting number:\n\n        |w(\u03b2)| \u2013 n(\u03b2) + 1 \u2264 2u(\u03b2) \u2264 c(3) + 1 - \u03b7(\u03b2),\n\nwhere w(\u03b2) is the writhe and n(3) is the number of strands of the braid word\n\u03b2, and c(3) is the crossing number of the braid closure \u00df. We verified that our\nRL agent obtained statistically better bounds on the unknotting number than the\nslice-Bennequin bounds.\nWhen considering diagrams of connected sums, one can obtain potentially better\nmixing of the components by inserting up to 7 braid words equivalent to the identity,\nand which mixes strands between the two components, compared to overlaying. See,\nfor example, Figure 6.\nWe furthermore trained an RL agent which operated directly on braid words\nrather than using invariants. In this case, we used a transformer architecture [37],\na ML architecture designed to work on sequences. The input to the model is a\nsequence of integers representing the braid word, and the output is akin to the\ninvariant-based agent a probability distribution over which crossing to switch.\nThis had the big advantage of being invariant-free and hence very fast. It performed\nwell on smaller braids (\u2264 60 crossings, 3\u20138 strands), but struggled to unknot larger\nbraids efficiently. Future work could investigate invariant-free unknotting agents\nfurther.\nA potential direction that we have not explored is to do Imitation Learning on\nthe unknotting trajectories from the braid agent. One would filter trajectories that\nare close to minimal, and augment the dataset by rotating and mirroring the braid\nwords, and by inserting braid identities."}, {"title": "4. ADDITIVITY OF THE UNKNOTTING NUMBER", "content": "We set out to search for a counterexample to the additivity of the unknotting\nnumber using our IMPALA agent. Our strategy was to first find a large dataset\nS of knots with known unknotting numbers. We can assume that \u03c3(K) \u2265 0 for\nevery K\u2208 S by mirroring it if \u03c3(K) < 0. We then construct non-trivial diagrams\nof connected sums K# - K' for K, \u039a' \u2208 S. If the RL agent can unknot K# - \u039a'\nusing u(K) + u(K') \u2013 1 crossing changes, then we are done."}, {"title": "4.1. Strong conjecture", "content": "While we have not found a counterexample to the addi-\ntivity of the unknotting number, we have obtained counterexamples to the stronger\nform, Conjecture 1.2. Recall that this states that, in every collection of unknotting"}]}