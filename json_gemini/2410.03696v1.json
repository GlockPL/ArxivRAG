{"title": "Improving Emotion Recognition Accuracy with Personalized Clustering", "authors": ["Laura Guti\u00e9rrez-Mart\u00edn", "Celia L\u00f3pez Ongil", "Jose M. Lanza-Guti\u00e9rrez", "Jose A. Miranda Calero"], "abstract": "Emotion recognition through artificial intelligence and smart sensing of physical and physiological signals (Affective Computing) is achieving very interesting results in terms of accuracy, inference times, and user-independent models. In this sense, there are applications related to the safety and well-being of people (sexual aggressions, gender-based violence, children and elderly abuse, mental health, etc.) that require even more improvements. Emotion detection should be done with fast, discrete, and non-luxurious systems working in real-time and real life (wearable devices, wireless communications, battery-powered). Furthermore, emotional reactions to violence are not equal in all people. Then, large general models cannot be applied to a multiuser system for people protection, and customized and simple Al models would be welcomed by health and social workers and law enforcement agents. These customized models will be applicable to clusters of subjects sharing similarities in their emotional reactions to external stimuli. This customization requires several steps: creating clusters of subjects with similar behaviors, creating Al models for every cluster, continually updating these models with new data, and enrolling new subjects in clusters when required. A methodology for clustering data compiled (physical and physiological data, together with emotional labels) is presented in this work, as well as the method for including new subjects once the AI model is generated. Experimental results demonstrate an improvement of 4% in accuracy and 3% in fl-score w.r.t. the general model, along with a 14% reduction in variability.", "sections": [{"title": "I. Introduction.", "content": "Recently, Affective Computing (research on people's emotional reactions to certain external stimuli, and how these reactions can be measured and scaled using different types of sensors, [1]) is achieving important results in terms of emotion detection with better accuracy, lower inference times, and user-independent models. The use of huge and powerful processing units (GPUs, multicore servers, etc.) allows the use of deep learning approaches implementing very complex models (Convolutional Neural Networks with several layers and neurons) run in the cloud. Even, some commercial solutions allow local processing with the use of specific microprocessors, instead of cloud computing with remote servers working 24-day/7-hour and consuming very important amounts of energy. However, these solutions are devoted to non-critical applications, and when wearable systems are required with real-time and offline operation at the same time as low power consumption, cybersecurity, and data protection mechanisms, another approach is needed. In this scenario, simple artificial intelligence (AI) models are required to operate on the edge and share as little information as possible out of the edge. This simplification in Al modeling fits very well with the clustering-wise customization of models.\nFurthermore, the research performed on the detection of emotions in people through the analysis of physiological and/or physical data has shown that there are very different emotional reactions in persons, depending on intrinsic and extrinsic factors [2]. Therefore, building a subject- independent model for emotion recognition is not the best solution. However, generating subject- dependent models makes the enrolment process and the application deployment almost unaffordable in most cases. In this dilemma, clustering persons according to similarities in"}, {"title": "II. Background.", "content": "The detection of emotions in humans using technological solutions has interested researchers in the last decades. The range of applications is widening every year. Starting with positive emotions identification, such as in marketing techniques to motivate potential shoppers or in entertainment and leisure activities to improve experiences, and going through negative emotions detection, in cases of mental health, surveillance or violence prevention, there have been several contributions in scientific research and commercial devices, especially in 21st century.\nThere is no global agreement on the range of emotions to be detected, neither their number nor their representation. However, the most accepted classifications are, for discrete emotions that are given by Ekman [3] with 12 main emotions (joy, sadness, surprise, contempt, hope, fear, attraction, disgust, tenderness, anger, calm, tedium), and for dimensional modeling, the Mehrabian proposal [4] of the PAD space (Pleasure, Arousal, Dominance) is frequently used in machine learning algorithms that prefer numerical values. Regarding the number of emotions, typically, a small number is preferred in multiuser applications.\nAutomatic emotion recognition is based on artificial intelligence algorithms that analyze one or multiple measurements from the person under analysis and classify the emotional reaction felt by her/him. This classification is done without the participation of the user, although subsequent confirmation is welcome to readjust the AI model. The key issue in Affective Computing is the type of variables measured from the person to infer the emotional state. Those variables can be physiological signals (Skin Temperature (SKT), Galvanic Skin Response (GSR), Heart Rate (HR), Electromyogram (EMG), Electrocardiogram (ECG), Electroencephalogram (EEG), etc.) caused for the instant reactions in the amygdala and sympathetic nervous system (SNS) and provoking the natural reaction of fight-or-scape. These signals should be captured through specific sensors. On the other hand, emotions can be reflected in human behavior and expressions, in face, voice, walking, etc. These are known as physical variables and can be captured through image or audio devices.\nThere has been intensive research about the best collection of variables to recognize emotional reactions with artificial intelligence. The scientists have finally agreed multimodal systems will always provide better results than unimodal ones. However, the number of sensors or measuring"}, {"title": "III. Tools", "content": "The following section provides detailed information concerning the tools necessary to implement the proposed methodology. The material includes the dataset, the machine learning model to test the clustering strategy influence, and the algorithm for computing the optimal number of clusters.\nThe complete pipeline and model implementation are developed using Python v3.8.10, leveraging its Scikit-learn and SciPy libraries.\nThis research utilized the first release of The Women and Emotion Multi-modal Affective Computing (WEMAC) data [15], a multi-modal dataset integrated within the UC3M4Safety"}, {"title": "IV. Proposed Methodology.", "content": "Two main methods have been designed and implemented to explore the potential of identifying typologies of reaction in volunteers and how these groupings can lead to personalized and improved models. In the first approach, M1, the volunteers are grouped into distinct categories based on statistical variables that correspond to the labeled observations of the two target classes. However, this technique's implementation requires the acquisition of multiple labeled observations from both target classes for the same participant.\nThe second approach, M2, is an extended version that brings the system as close as possible to a real use case. In this scenario, a volunteer with unlabeled observations can be assigned to one specific typology and take advantage of the customized model's benefits."}, {"title": "A. User profile clustering based on labeled data (M1)", "content": "This first technique aims to identify user typologies according to their emotional and physiological reactions.\nThe underlying concept is to detect analogous physiological responses to enhance data similarity, thereby facilitating the model in discerning between different classes. This approach enables a semi-personalized, yet broader model compared to a subject-dependent one.\nFor the initial grouping separation, an initial transformation ($R^{OXF} \u2192 R^{NXM}$) of the feature map Dis required. Where the original dimensions OxF (where O represents the number of observations and F represents the number of features) are converted into a matrix D' of dimensions NxM (where N represents the number of volunteers and M includes the mean and standard deviation of all the features for each of the two target classes: fear and non-fear) with every row a single entry for each volunteer. .\nWith this reshaped feature map and the algorithm previously presented, the optimal number of typologies and emotional similarities Kare found across all the training volunteers. Upon identification of these specific groups, the centroids $C_k \u2208 R^M$ for each cluster $k \u2208 \\{1, ..., K\\}$ are computed.\nFinally, new volunteers are integrated into the existing clusters by employing the minimum distance technique."}, {"title": "B. Unlabeled observation clustering assignment \u2013 online (M2)", "content": "This approach aims to extend the proposed user clustering methodology to enable the assignment of any unlabeled observation to the closest profile, thereby creating a more complex but realistic technique. With this intention, the user typologies are considered the extension's initial starting point.\nTo aid understanding and maintain consistency, clusters found in M1 are referred to as typology clusters (TC), and the new clusters computed in this method are referred to as internal clusters (IC)."}, {"title": "V. Experimental Results.", "content": "This section details the experiments conducted to validate and test the proposed methodology and how it proceeds and influences the performance metrics of the KNN machine learning classifier.\nTwo main set-ups of experiments are shown and referred to: (1) Config.1 is the pipeline validation of the methodologies M1 and its extended version M2; (2) Config.2 presents the baseline, related works, and mean results analysis of the effectiveness of the semi-personalized methodology. Both experiments utilized the first release of the WEMAC dataset presented in Section III.\nConfig.1 evaluates the proposed methods M1 and M2. The experiment is divided into three validation indices: (1) Robustness test, where the model is tested with the volunteers that do not belong to that specific cluster; (2) Performance test, where the clustering model is tested with its assigned and unseen volunteers; (3) Volunteers assignment comparison test between methods.\nIn order to analyze the methodology, a 20-fold strategy is applied to generate a 70%-30% training and testing partition. The training data set generates the four TCs following the M1 approach, and"}, {"title": "Discussion and conclusions.", "content": "This work proposes a novel clustering technique for semi-personalizing a general model and tackling the problem caused by the different physiological reactions to the same target emotion. This approach combines the initial utilization of user clustering based on labeled data to decide the existing typologies within the data, with the possibility of assigning new volunteers to their appropriate model later.\nThe experimental results, including the baseline comparison, robustness numbers, and semi- personalized results, show a slight improvement in the final performance values and a clear reduction of variation.\nAlthough an improvement exists compared to the proposed general model, the performance metric values are not even close to those presented in [19] . This difference of more than 10% in both accuracy and fl-score makes it clear that migration from the KNN to a more complex deep learning model is necessary. With this new variation implemented, the proposed methodology should be retested to see how far it can be achieved and its actual effectiveness.\nFor that reason, future work will explore the use of more complex deep learning models like convolutional neural networks, or LSTMs, which have demonstrated significant effectiveness in recognizing spatial correlation and temporal patterns. But also, some optimizations for the assignment or clustering techniques.\nAnother main limitation of the study is the number of volunteers. There exists a possibility that the lack of data is preventing us from detecting other typologies that are currently agglomerated in the same cluster. For that reason, it would be interesting to perform this same study with a more extended data set, such as the second release of data from the same database used."}]}