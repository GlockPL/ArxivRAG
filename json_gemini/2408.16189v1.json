{"title": "A MORE UNIFIED THEORY OF TRANSFER LEARNING", "authors": ["Steve Hanneke", "Samory Kpotufe"], "abstract": "We show that some basic moduli of continuity d\u2014which measure how fast target risk decreases as source risk decreases-appear to be at the root of many of the classical relatedness measures in transfer learning and related literature. Namely, bounds in terms of d recover many of the existing bounds in terms of other measures of relatedness-both in regression and classification\u2014and can at times be tighter.\nWe are particularly interested in general situations where the learner has access to both source data and some or no target data. The unified perspective allowed by the moduli & allow us to extend many existing notions of relatedness at once to these scenarios involving target data: interestingly, while d itself might not be efficiently estimated, adaptive procedures exist-based on reductions to con-fidence sets-which can get nearly tight rates in terms of 8 with no prior distributional knowledge. Such adaptivity to unknown 8 immediately implies adaptivity to many classical relatedness notions, in terms of combined source and target samples' sizes.", "sections": [{"title": "1 Introduction", "content": "Domain Adaptation or Transfer Learning refer generally to the problem of harnessing data from a source distribution P to improve prediction performance w.r.t. to a target distribution Q for which some or no data is available. This problem has been researched over the last few decades with a recent resurgence in interest driven by modern applications that are often characterized by a scarcity of perfect target data.\nA fundamental question in the theory of domain adaptation (and variant problems on distribution shifts) is how to measure the relatedness between source P and target Q distributions. Importantly, desired measures of relatedness should not only tightly capture the predictive information P has on Q, but have to be practically useful: that is, either the measure can be estimated from data to facilitate algorithmic design, or more generally, it should somehow admit adaptive procedures, i.e., procedures whose performance is adaptive to the a priori unknown level of relatedness between P and Q. Many notions have been proposed over the last few decades, starting with the seminal works of Mansour et al. [2009], Ben-David et al. [2010] on refinements of total-variation for domain adaptation in classification, to more recent proposals for domain adaptation in regression, e.g., Wasserstein distances Redko et al. [2017], Shen et al. [2018], or measures relating covariance structures across P and Q as in Mousavi Kalan et al. [2020], Zhang et al. [2022b], Ge et al. [2023]. These various notions of relatedness appear hard to compare at first glance, leading to a disparate theory of domain adaptation at present with no unified set of principles.\nInterestingly as we show, upon closer look at the existing literature\u2014whether in classification or regression\u2014it turns out that in fact, many seemingly distinct measures of relatedness proposed in domain adaptation actually implicitly bound the same fundamental quantities: we refer to these quantities as weak and strong moduli of transfer, and they roughly measure how fast the Q-risk of predictors decrease as their P-risk decreases. These moduli always yield as tight or tighter rates of transfer than many existing notions, while also admitting adaptive procedures in general settings, as shown via a reduction to the existence of certain confidence sets for the prediction problem at hand. These reductions, while of a theoretical nature, yield insights on general adaptive transfer approaches that are less tied to specific measures of relatedness between source P and target Q."}, {"title": "2 Preliminaries", "content": "We now give a more formal description of results. We consider a general prediction setting with joint distributions P and Q on X \u00d7 Y, and a fixed hypothesis class H of functions h : X \u2192 Y. We consider general risks under a given measure \u03bc (here P or Q) of the form \\(R_\\mu(h) = \\mathbb{E}_\\mu l(h(X), Y)\\) for a generic loss l; of special interest is the excess risk \\(\\mathcal{E}_\\mu(h) = R_\\mu(h) \u2013 \\inf_{h'\\in\\mathcal{H}} R_\\mu(h')\\). Risk minimizers for P and Q need not be the same, and in fact need not exist. We allow a general learning setting with access to labeled samples from P and some or no labeled samples from Q. We remark in particular that many existing results on domain adaptation concern situations with no target data, while here we aim for a general theory.\n\u2022 The weak modulus of transfer is easiest to describe, and happens to be the essential quantity at the root of many existing notions of relatedness. It is given by the following function of \u20ac > 0:\n\\(\\delta(\u20ac) = \\delta_{PQ}(\u20ac) = \\sup \\{\\mathcal{E}_Q(h) : h \\in \\mathcal{H}, \\mathcal{E}_P(h) \\leq \u0454\\} .\\)\nRoughly, \u03b4(\u03b5) captures whether good predictors under P remain good under Q; intuitively, if this is the case, data from the source P should be highly informative for prediction under the target Q, and it is therefore not surprising that it is implicitly tied to many existing notions of relatedness (see Section 3.1 for examples such as Y-discrepancy, transfer-exponent, Wasserstein, covariance ratios, etc.). While \u03b4(\u20ac) is not easy to estimate from data (as it involves the unknown infimum risks), we show that it nevertheless admits adaptive procedures \u0125 which, given data from P and some or no data from Q, and with no knowledge of 8 can achieve transfer rates of the form (Theorem 1)\n\\(\\mathcal{E}_Q(\\hat{h}) \\leq \\min \\{\\epsilon_Q, \\delta(\\epsilon_P)\\},  (1)\nwhere \u03b5\u03bc, for \u03bc denoting Q or P, is roughly the best rate achievable under \u00b5 in vanilla prediction with the n\u00b5 samples from \u00b5 alone; for example in classification, typically \\(\\epsilon_\\mu \\approx n_\\mu^{-1/2}\\), while in linear regression with squared loss, \\(\\epsilon_\\mu \\approx n_\\mu^{-1}\\), ignoring complexity terms such as dimension.\nThus, suppose for instance that the learner only has access to source samples and no target samples, as is commonly studied in the literature. Then the bound of (1) reduces to \\(\\mathcal{E}_Q(\\hat{h}) \\leq \\delta(\\epsilon_P)\\), which is trivially obtained for instance by ERM h on the P sample; upper-bounds on d(\u20ac) then easily recover many existing results in terms of various notions of relatedness. The weak modulus & therefore appears as a good starting point towards a more general theory.\nWe are particularly interested in more general settings allowing some amount of target data. The rate of (1) in this general case may be viewed as interpolating between biasing towards the source data vs biasing towards the target data, whichever is more predictive under Q; this is a priori unknown, since d is unknown. We show that this is achievable by a general adaptive procedure that reduces to the existence of weak confidence sets. These are empirically-induced sets \\(\\mathcal{H} \\subset \\mathcal{H}\\) that contain only predictors with \\(\\mathcal{E}_\\mu(h) \\leq \\epsilon_\\mu\\), while retaining all near-optimal predictors, i.e., those satisfying \\(R_\\mu(h) \\approx \\inf_{h'\\in\\mathcal{H}} R_\\mu(h')\\). By instantiating these rates (and confidence sets) for traditional regression and classification settings (Section 3.3), we obtain unified rates in terms of both source and target samples that automatically extend to many existing relatedness measures simultaneously.\nWe show in Theorem 2 via a classification lower-bound that the adaptive transfer rates of (1) cannot be improved without additional structural assumptions. This confirms that the weak modulus tightly captures, at least in a worst-case sense, the limits of transfer with both source and target data.\n\u2022 The strong modulus of transfer follows as a natural refinement on the weak modulus, and aims to better capture the additional information inherent in having some target data. For intuition, suppose for instance that the source distribution P admits two distinct risk minimizers \\(h_P, h_P'\\), the first with low Q risk, i.e., \\(\\mathcal{E}_Q(h_P) \\approx 0\\), while the second has large \\(\\mathcal{E}_Q(h_P') > 1\\). For example, \\(h_P'\\) might focus on a feature (e.g. background color in object classification) that is predictive for data from P, but is irrelevant for prediction under Q. Then, with enough Q data, the distinction in transferability between hp and hp' becomes apparent, while the weak-modulus is limited by hp'. With this intuition in mind, a simplified version of the strong modulus roughly takes the form\n\\(\\delta(\u20ac_1, \u20ac_2) = \\sup \\{\\mathcal{E}_Q(h) : h \\in \\mathcal{H}, \\mathcal{E}_Q(h) \\leq \u20ac_1 \\text{ and } \\mathcal{E}_P(h) \\leq \u20ac_2\\}, \\)\nfor a range of values of \u20ac1, \u20ac2 (see Section 2.2 for an exact definition). Importantly, the principles underlying in the strong modulus, namely that target data can improve the rate of transfer beyond source alone, are new, and not reflected in the weak modulus nor in any of the existing measures from the transfer learning literature.\nAdaptation to the strong modulus is more tricky and relies on the existence of strong confidence sets (defined in Section 4). This yields adaptive transfer rates of the form d(eQ, ep) always as tight or tighter than the rates of min {eq, d(ep)} achievable under the weak modulus (Corollary 2).\nWhile the analysis presented here remains of a theoretical nature, the resulting design principles have many desirable practical implications: for one, they allow for adaptivity to many measures of relatedness at once, when the source is"}, {"title": "2.1 General Setup", "content": "Basic Definitions. Let X, Y be jointly distributed according to some measure \u03bc (later P or Q), where X is in some domain X and Y \u2208 Y. A hypothesis class is a set H of measurable functions X \u2192 Y. Given a loss function l : Y2 \u2192 R+, we consider risks \\(R_\\mu(h) = \\mathbb{E}_\\mu l(h(X), Y)\\), as measured under a given \u03bc.\nAssumption 1 (Finiteness). We assume throughout that \\(R_\\mu(h) < \\infty, \\forall h \\in \\mathcal{H}\\), and for measures \u03bc considered.\nNote that the above is a mild assumption, as it does not require the loss to be uniformly bounded. For instance this admits the squared loss in linear regression.\nFor example, the case of binary classification corresponds to y = {\u00b11}, where we often choose \\(l(y, y') = 1\\{y \\neq y'\\}\\), and results below will depend on the VC dimension or Rademacher complexity of the class H (see, e.g., Vapnik and Chervonenkis [1971], Koltchinskii [2006]). As another example, the case of regression corresponds to y CR, and we may choose \\(l(y, y') = (y \u2013 y')^2\\), and results below may depend, for instance, on the covering numbers or pseudo-dimension of the class H (see, e.g. Anthony and Bartlett [1999]).\nRemark 1. Our general results will in fact capture quite abstract dependences on H, via an abstractly-defined notion of confidence sets, and any notion of complexity that allows for such confidence sets are therefore admissible.\nDefinition 1. The excess risk w.r.t. a (non-empty) subclass \\(H_0 \\subset \\mathcal{H}\\), and a joint distribution \u00b5, is defined as\n\\(\\mathcal{E}_\\mu(h; H_0) = R_\\mu(h) \u2013 \\inf_{h' \\in H_0} R_\\mu(h').\\)\nI particular, we will just refer to \\(\\mathcal{E}_\\mu(h; \\mathcal{H})\\) as excess risk, and often write \\(\\mathcal{E}_\\mu(h)\\) in this case for simplicity.\nWe will need the following useful definition. Let R+ = (0,\u221e] denote the extended positive reals.\nDefinition 2 (Constraint Set). For any distribution \u00b5, and \u0454 \u2208 R+, define \\(H_\\mu(\u20ac) = \\{h \\in \\mathcal{H} : \\mathcal{E}_\\mu(h) \\leq \u03b5\\}.\\)\nClearly, \\(H_\\mu(\\infty)\\) is just H, so the inclusion of \u221e is just for convenience as we will see later.\nTransfer Setting. We consider source and target distributions P and Q on (X, Y), where we let Ep, EQ denote excess-risks under P and Q. We are interested in excess risk EQ(h) of classifiers trained jointly on np i.i.d samples Sp from P, and no i.i.d. samples SQ from Q. Which EQ is achievable necessarily depends on the discrepancy P\u2192Q appropriately formalized."}, {"title": "2.2 Moduli of Transfer", "content": "As we will argue in Section 3, the above simple definition already captures the bulk of notions of discrepancies proposed in the literature on transfer learning.\nThe first notion considered below serves to capture the reduction in target Q-risk induced by small source P-risk, i.e., by a potentially large amount of P data. In particular, as we will see, e is to stand for the best risk achievable under P given a fixed amount of data from P.\nDefinition 3 (Weak Modulus). Let \u20ac > 0. Define the modulus\n\\(\\delta(e) = \\sup \\{\\mathcal{E}_Q(h) : h \\in H_P(\u20ac)\\}, \\)\nor written as \\(\\delta_{PQ}(\u20ac)\\) when the dependence on distributions is to be made explicit.\nThe next notion aims to refine the above notion: it serves to capture the reduction in Q-risk, induced by the combined effect of target Q and source P data. As such, in our Q risk bounds, \u20ac1 and \u20ac2 will be instantiated as functions of the amount of Q data and P data, respectively."}, {"title": "Definition 4 (Strong Modulus).", "content": "For \u20ac1, \u20ac2 > 0, define the following bivariate modulus:\n\\(\\delta(\u20ac_1, \u20ac_2) = \\sup \\{\\mathcal{E}_Q(h) : h \\in H_Q(\u20ac_1), \\mathcal{E}_P(h; H_Q(\u20ac_1)) \\leq \u20ac_2\\}, \\)\nor written as \\(\\delta_{PQ}(\u20ac_1,62)\\) when the dependence on distributions is to be made explicit.\nWe will aim to understand situations in which the strong modulus is a strict refinement over the weak modulus. The following pivotal quantity will turn out useful to our discussions as the above definition of strong modulus can be simplified for values of \u20ac1 above this pivot.\nDefinition 5 (Pivotal Value). The following quantity captures the infimum excess Q-risk of good classifiers under P:\n\\(\\mathcal{E}_{P,Q} = \\lim_{\u20ac \\to 0} \\inf\\{\\mathcal{E}_Q(h) : h\\in H_P(\u20ac)\\}\\).\nRemark 2 (Intuition). Consider the simplest case of a finite H, and let \\(\\mathcal{H}_1 = \\arg \\min_{h\\in\\mathcal{H}} R_P(h)\\). We easily see that\n\\(\\mathcal{E}_{PQ} = \\min_{h \\in \\mathcal{H}_1} R_Q(h_P) \\text{ while } \\lim_{\u20ac \\to 0} \\delta(\u20ac) = \\max_{h_P \\in H_P} R_Q(h_P)\\).\nWe note that = lim\u300f\u21920 (\u20ac) is an interesting quantity on its own and will be discussed later in Section 3.1. The above general definitions simply allow us to capture a larger variety of situations including generic losses, and in particular, avoid requiring of the existence of risk minimizers.\nNext, we consider an alternative expression of EPQ, which will be useful in the analysis. For intuition, again consider the simplest case of a finite H; we see that \u025brq is the smallest \u20ac1 for which HQ(\u20ac1) contains an hp (whereas EP,Q represents the smallest \u20ac1 for which HQ(\u20ac1) contains every hp). The proposition below generalizes this intuition.\nProposition 1 (Equivalent Form of the Pivotal Value). We have \\(\\varepsilon_{PQ} = \\inf \\{\\epsilon_1 \\in \\mathbb{R}_+:\\forall e > 0, H_Q(\\epsilon_1) \\cap H_P(e) \\neq \\emptyset\\} .\\)\nProof. For ease of notation, let E# denote the set \\(\\epsilon_1 \\in \\mathbb{R}_+ : \\forall e > 0, H_Q(\\epsilon_1) \\cap H_P(e) \\neq \\emptyset\\} .\nFor any \u20ac1 > \u20acPQ, we have that \u20ac1 > inf{\\(\\mathcal{E}_Q(h) : h \\in H_P(\u20ac)\\)} for all \u20ac > 0, since this last infimum only increases as \u20ac \u2192 0; in other words, for all e > 0, \\(H_Q(\\epsilon_1) \\cap H_P(e) \\neq \\emptyset\\), i.e., \u20ac1 \u2208 E#. We therefore have that \u025bpQ > inf E#. Notice that, this last inequality also holds when EPQ = \u221e.\nNow for any \u20ac1 \u2208 E#, by definition, we have that for all e > 0, \\(\\inf_{h \\in H_P(\u20ac)} \\mathcal{E}_Q(h) \\leq 6_1\\), in other words, \u20ac1 > \u00a3p,Q. We therefore also have that \u025bpQ < inf E#.\nRemark 3. We note that we may have \u025bpQ very large, in fact matching supa,bey l(a, b) (admitting \u221e for unbounded losses). This describes P having little information on Q, i.e., where h's with low P-risk have large Q-risk.\nWe have the following useful implications.\nCorollary 1. Let \u20ac1, \u20ac2 > 0.\n\u2022 If \u20ac1 > \u00a3p,q, every h \u2208 H has Ep(h; HQ(\u20ac1)) = Ep(h). It follows that, for \u20ac1 > \u0190P,Q\n\\(\\delta(\u20ac_1, \u20ac_2) = \\sup \\{\\mathcal{E}_Q(h) : h \\in H_Q(\u20ac_1) \\cap H_P(\u20ac_2)\\} .\\)\n\u2022 If \u20ac1 \u2264 EpQ, then \u20ac1 \u2264 \u03b4(62). Equivalently, we always have \u025bpQ \u2264 \u03b4(\u20ac2).\nProof. For the first claim, for \u20ac1 > \u025bpq, we have \u20ac1 \u2208 E# (where E# is defined in the proof of Proposition 1). Now by definition, E# is the set of 61 such that for all e, \u2203h \u2208 HQ(\u20ac1) satisfying Ep(h) \u2264 \u0454. Therefore, \\(\\inf_{h \\in H_Q(6_1)} R_P(h) = \\inf_{h \\in \\mathcal{H}} R_P(h)\\), and the claim follows.\nFor the second claim, we note that 8(\u20ac2) \u2208 E#, since any \u0454 > 0 has \\(H_P(\u20ac) \\cap H_P(\u20ac_2) = H_P(\\min\\{\u20ac,\u20ac_2\\}) \\neq \\emptyset\\), and is a subset of \\(H_P(\u20ac_2) \\subset H_Q(\\delta(\u20ac_2))\\), where the last inclusion is from the definition of 8(\u20ac2). Hence EpQ < \u03b4(\u20ac2).\nWe have the following proposition which simply states that the strong modulus is a refinement of the weak modulus. (Make clear that Prop 1 serves to arrive at Prop2).\nCorollary 2 (Relation Between Strong and Weak Moduli). For \u20ac1, \u20ac2 > 0,\n\\(\\delta(\u20ac_1, \u20ac_2) \\leq \\min \\{\u20ac_1, \\delta(\u20ac_2)\\} .\\)"}, {"title": "3 Weak Modulus of Transfer", "content": "Here we consider a few examples of existing notions of discrepancy between source and target P, Q, and illustrate the types of bounds they imply on \u03b4(\u03b5). These bounds were already implicit in past work, even while the weak modulus \u03b4(\u20ac) was never explicitly defined as the main object of study, or as the implied notion of discrepancy.\nSome Discrepancies in Classification. We first remark that some of the notions below can be stated generally beyond classification, e.g., the V-discrepancy and the transfer-exponent, however they usually appear in works on classification. In what follows assume l(a, b) = 1{a \u2260 b} and for the simplest case suppose Y = {-1,1} (though the claims are valid for any Y).\nExample 1 (V-discrepancy; Mohri and Medina, 2012). Let discy(P,Q) = suph\u2208\u043d |Rp(h) \u2013 RQ(h)|. Similar to [Mohri and Medina, 2012]:\n\\(\\mathcal{E}_Q(h) = R_Q(h) \u2013 \\inf_h' R_Q(h') = R_Q(h) \u2013 \\inf_h' R_P(h') + \\inf_h' R_P(h') \u2013 \\inf_h' R_Q(h')\\)\n\\(\\leq \\mathcal{E}_P(h) + disc_\\mathcal{Y} (P,Q) + \\inf_h' R_P(h') - \\inf_h' R_Q(h').\\)\nIn other words, for any \u0454 \u2208 (0, 1],\n\\(\\delta(\u20ac) \\leq \u20ac + disc_\\mathcal{Y} (P,Q) + (\\inf_h' R_P(h') - \\inf_h' R_Q(h')). (2)\nIn particular, note that the difference in risks above is at most disc(P, Q), i.e. we also have \u03b4(\u20ac) < \u0454 + 2discy(P, Q).\nAs noted by [Mohri and Medina, 2012, Cortes, Mohri, and Medina, 2019], the Y-discrepancy in fact works for essentially any y and loss function l (in particular, they focused on the cases of bounded losses and convex losses)."}, {"title": "Example 2 (A-discrepancy;", "content": "Ben-David et al., 2010, Mansour et al., 2009). Consider discA(P,Q) = suph,h'\u2208H|Px(h \u2260 h') \u2013 Qx(h \u2260 h')|. For simplicity, as in [Mansour et al., 2009], we suppose there exist ho, hp \u2208 H that minimize the respective risks, and also let h* = argmin\u0127en RQ(h) + Rp(h).\nRQ(h) \u2264 Qx(h \u2260 h*) + RQ(h*) \u2264 Px(h \u2260 h*) + disca(P,Q) + RQ(h*)\n<Rp(h) + disca(P,Q) + RQ(h*) + Rp(h*)\nso that\n\\(\\mathcal{E}_Q(h) \\leq \\mathcal{E}_P(h) + disc_\\mathcal{A}(P,Q) + (R_P(h_P) \u2013 R_Q(h_Q)) + R_Q(h^*) + R_P(h^*).\\)\nIn particular, we have for any \u0454 \u2208 (0, 1],\n\\(\\delta(\u20ac) < \u20ac + disc_\\mathcal{A}(P,Q) + (R_P(h_P) \u2013 R_Q(h_Q)) + R_Q(h^*) + R_P(h^*).  (3)\\)"}, {"title": "3.1 Some Existing Discrepancies vs Weak Modulus", "content": "Example 3 (Transfer Exponent; Hanneke and Kpotufe, 2019, Hanneke, Kpotufe, and Mahdaviyeh, 2023). Supposing there exist hp, hp \u2208 H with Eq(hq) = 0 and Ep(hp) = 0, a value p > 0 is called a transfer exponent if there exists\nhp \u2208 argminh Rp(h) such that RQ(h) \u2013 RQ(hp) \u2264 CpE/P (h), for some Cp, and for all h\u2208 H (equivalently\nTh\u2208 HP(60), for some \u20ac0 > 0). It's then immediate that\n\\(\\mathcal{E}_Q(h) = R_Q(h) \u2013 R_Q(h_P) + \\mathcal{E}_Q(h_P) < C_P \\mathcal{E}_P^{1/p}(h) + \\mathcal{E}_Q(h_P), \\)\nimplying that, for all \u0454 \u2208 (0, 1], \u03b4(\u20ac) < Cp \u2022 \u20ac\u00b9/p + EQ(hp).\nA more general definition: we can extend the above definition to the general case with or without P-risk minimizers. Define = lim\u2208\u21920 8(\u20ac). A transfer exponent (Cp, p) is defined as satisfying the condition: \u2200h \u2208 H, Eq(h) \u2264\n#\n#\nEP.Q\n#\nC\\(\\mathcal{E}_P^{1/p}(h) + \\mathcal{E}_Q^{h_P}\\). This immediately implies the following bound:\n\\(\\delta(\u03b5) \\leq \u0393_P. \u03b5^{1/p} + \\varepsilon_{PQ}.\\)\nRemark 5. These various notions appearing in the literature on classification are not directly comparable, but as we see here, many offer upper-bounds on \u03b4(\u20ac) with varying degrees of tightness in various situations. Thus, any transfer rate in terms of 8(e) immediately yields a bound in terms of these existing notions. As it turns out, our bounds in terms of 8(\u20ac) recover many proved so far in terms of these various quantities, and can often be tighter (Theorem 1).\nThe transfer exponent in particular attempts to capture some desired properties of d(\u20ac). For one, it is asymmetric just as d is, and thus does not deteriorate in situations where P has much information on Q, but Q has little information on P-for instance Px covers the decision boundary under Q but not the other way around. Second, the resulting upper-bound yields the same limit \u025b as \u03b4(\u20ac), i.e., it more adequately captures expected performance under large source samples. However, the polynomial form of the transfer-exponent is arbitrary, and simply allows for easier analysis.\nGiven the arbitrariness of the polynomial form, \u03b4(\u03b5) can sometimes be smaller than its upper bound based on the transfer exponent. Similarly, the Y-discrepancy and A-discrepancy can be loose: suppose e.g., that sp = 0 (see e.g., Remark 2 for intuition), while these discrepancies are not 0, implying that the relevant upper-bounds asymptote at non-zero constants and are therefore loose for small \u20ac.\nSome Discrepancies in Regression. We note that, while we now focus on regression, i.e., h has continous output, the discussion below may be extended to classification in the usual way by viewing l(a, b) as a surrogate loss (and the classifier as sign(h) for example)."}, {"title": "3.1 Weak Modulus of Transfer", "content": "Example 4 (Wasserstein 1). Let L denote the set of 1-Lipschitz functions on X w.r.t a metric p. Then consider the integral probability metric W\u2081(P,Q) = supf\u20ac\u00a2 |EPx (f) \u2013 Eqx (f)|.\nSuppose H C\u00c0\u00b7 L, A > 0, and is a set of bounded functions X \u2192 [\u2212M, M], and let l(a, b) = (a - b)\u00b2 be the squared loss. We consider a weak covariate shift scenario, where Ep[Y|X] = EQ[Y|X] = h*(X) for some h* \u2208 H. Notice"}, {"title": "2 Adaptive Transfer Upper-Bounds", "content": "that u \u2192 u\u00b2 is 4M-Lipshitz on [\u22122M, 2M], while for any h, h' \u2208 H, (h \u2013 h') is 21-Lipschitz on X, and has range within [\u22122M, 2M]. Then for any h \u2208 H, we have that x \u2192 (h(x) \u2013 h*(x))\u00b2 is (8MA)-Lipschitz. Hence,\n\\(\\mathcal{E}_Q(h) = \\mathbb{E}_Q(h(X) \u2013 h^*(X))^2 \\leq \\mathbb{E}_P(h(X) \u2013 h^*(X))^2 + 8M\\lambda \\cdot W_1(P,Q) = \\mathcal{E}_P(h) + 8M\\lambda \\cdot W_1(P,Q).\\)\nThus, Ve > 0,\n\\(\\delta(\u03b5) < \u20ac + 8\u039c\u03bb\u00b7 W\u2081(P,Q). (4)\\)\nWe note that Shen et al. [2018] show a similar bound as above\u00b9, but rather than excess risk, are instead interested in relating Q-risk to P-risk (for L\u2081 loss). These can be transformed into excess risk bounds, however with additional terms of the form of (3), which is unsurprising as W\u2081 may be viewed as extending A-discrepancy to any class H of Lipschitz functions). In fact, notice that the derivations above are similar to those for the Y-discrepancy and A-discrepancy.\nSimilarly, certain variants of the MMD distance [Huang et al., 2007], another so-called integral probability metric, may be viewed as special cases of Y-discrepancy or extensions of the A-discrepancy to the regression setting; see e.g., Redko et al. [2017]. The implied bounds on \u03b4(\u03b5) are analogous to those given in Examples 1 and 2 above.\nRemark 6. We emphasize that \u03b4(\u20ac) may be strictly smaller than the above bounds since (4) remains of a worst-case nature over all Lipchitz functions rather than localized to the optimal functions in the class.\nExample 5 (Linear Regression). Consider X C Rd and Y CR, and write Ep = Ep XX\u2122 and EQ = EQ XXT. Assume that Ep is full rank. Consider a weak covariate-shift scenario where Ep[Y|X] = EQ[Y|X] = w+ X (this would be the case under covariate-shift where Py\\x = Qy\\x). Again we consider the squared loss l(a, b) = (a\u2212b)\u00b2. We then have that, for any h(x) = w\u00afx:\n\\(\\frac{\\mathcal{E}_Q(h)}{\\mathcal{E}_P(h)} = \\frac{(w \u2013 w^*)^T\\Sigma_Q(w \u2013 w^*)}{(w - w^*)^T\\Sigma_P(w \u2013 w^*)} \\leq \\sup_{\\textbf{u}} \\frac{\\textbf{u}^T \\Sigma_Q \\textbf{u}}{\\textbf{u}^T \\Sigma_P \\textbf{u}} = \\sup_{\\textbf{u}} \\frac{\\textbf{u}^T \\Sigma_P^{-\\frac{1}{2}} \\Sigma_Q \\Sigma_P^{-\\frac{1}{2}} \\textbf{u}}{\\textbf{u}^T\\textbf{u}} = \\lambda_{max} (\\Sigma_P^{-1}\\Sigma_Q),\\)\nwhere Amax denotes the largest eigenvalue, and the last equality used the fact that the matrices are similar (see Theorem 1.3.20 of Horn and Johnson [1985]). Thus, for any \u20ac > 0,\n\\(\\delta(\u20ac) \\leq \\lambda_{max} (\\Sigma_P^{-1}\\Sigma_Q) \\cdot \u03b5. (5)\\)\nNow, outside of covariate-shift, when w\u2217 = wp \u2260 wo, by the same argument as above, we have that\n\\(\\mathcal{E}_Q(h) \\leq 2 ||w \u2013 w_P||_{\\Sigma}^2 + 2 ||w_P - w_Q||_{\\Sigma}^2 = 2\\lambda_{max} (\\Sigma_P^{-1}\\Sigma_Q) \\cdot ||w \u2013 w_P||_{\\Sigma}^2 + 2\\mathcal{E}_Q(w_P)\\)\n(where \\(\\left\\|z\\right\\|_{\\Sigma}^2 = z^T \\Sigma z\\)) and we therefore have\n\\(\\delta(\u20ac) \\leq 2\\lambda_{max} (\\Sigma_P^{-1}\\Sigma_Q) \\cdot \u20ac + 2\\mathcal{E}_Q(w_P).  (6)\\)\nUpper-bounds similar to the above have been shown in various recent results of Mousavi Kalan et al. [2020], Zhang et al. [2022b], Ge et al. [2023]. We note that Zhang et al. [2022b] consider more general cases with different risk minimizers under P and Q, along with refinements on dmax (2p\u00b9\u2211\u0119) in their upper-bounds."}, {"title": "3.2 Adaptive Transfer Upper-Bounds", "content": "We start with the following short notation for empirical risk minimizers over source or target samples Sp or SQ.\nDefinition 6. Let \u03bc denote either P or Q in what follows, and let \\(\\hat{R}_\\mu(h) = \\frac{1}{\\nu} \\sum_{(x,y)\\in S_\\mu}l(h(x), y)\\) denote empirical risk over S\u00b5. For any H' CH, we let h\u00b5 (H') denote the function returned by an empirical risk minimization function ERM(H'): namely, a function mapping the data set S\u00b5 to an h \u2208 H' satisfying \\(\\hat{R}_\\mu(h) < \\inf_{h'\\in H'} \\hat{R}_\\mu(h') + e^{-\\eta_\\mu}\\). In particular, when H' = H, we simply write ERM\u00b5 = ERM\u00b5(H), and \u0125\u03bc = \u0125\u03bc(H).\nRemark 7. The above definition of ERM\u00b5 is to allow for a generality of losses where the minimizer of Ru may not be achieved in H. However, in commonly discussed settings such as classification with 0-1 loss, or linear regression with squared loss, we can let ERM\u2084(H) denote any h \u2208 H achieving infhen R\u03bc(h'). Furthermore, for 0-1 loss, such a minimizer exists for any H' C H since Ru can only take a finite number of values."}, {"title": "Definition 7. Let \u03bc denote either P or Q.", "content": "Let 0 < r < 1 and \u20ac > 0. We call a random set \\(\\hat{H"}, "mu = \\hat{H}_\\mu(S_\\mu)\\) an (\u20ac, T)-weak confidence set (under \u00b5) if the following conditions are met with probability at least 1 T:\n(i) \\(\\exists \\epsilon_\\mu > \\mathcal{E}_\\mu(\\hat{h}_\\mu) \\text{ such that } H_\\mu(\\epsilon_\\mu) \\subset \\hat{H}_\\mu\\), and"]}