{"title": "DOES GRAPH PROMPT WORK? A DATA OPERATION PERSPECTIVE WITH THEORETICAL ANALYSIS", "authors": ["Qunzhong Wang", "Xiangguo Sun", "Hong Cheng"], "abstract": "In recent years, graph prompting has emerged as a promising research direction, enabling the learning of additional tokens or subgraphs appended to the original graphs without requiring retraining of pre-trained graph models across various applications. This novel paradigm, shifting from the traditional \u201cpre-training and fine-tuning\u201d to \u201cpre-training and prompting\u201d has shown significant empirical success in simulating graph data operations, with applications ranging from recommendation systems to biological networks and graph transferring. However, despite its potential, the theoretical underpinnings of graph prompting remain underexplored, raising critical questions about its fundamental effectiveness. The lack of rigorous theoretical proof of why and how much it works is more like a \"dark cloud\" over the graph prompt area to go further. To fill this gap, this paper introduces a theoretical framework that rigorously analyzes graph prompting from a data operation perspective. Our contributions are threefold: First, we provide a formal guarantee theorem, demonstrating graph prompts' capacity to approximate graph transformation operators, effectively linking upstream and downstream tasks. Second, we derive upper bounds on the error of these data operations by graph prompts for a single graph and extend this discussion to batches of graphs, which are common in graph model training. Third, we analyze the distribution of data operation errors, extending our theoretical findings from linear graph models (e.g., GCN) to non-linear graph models (e.g., GAT). Extensive experiments support our theoretical results and confirm the practical implications of these guarantees.", "sections": [{"title": "1 INTRODUCTION", "content": "Graph Neural Networks (GNNs) have been widely used in analyzing various graph-structured data. A standard workflow using GNNs is the \u201cpre-training and fine-tuning\" paradigm, where a model is first trained on a large-scale, general-purpose dataset and then fine-tuned on a specific downstream task. While this method has been effective in transferring learned representations, it often needs many advanced tricks to retrain the model parameters for each new task, which can be computationally intensive and may not fully capture the unique characteristics of the downstream tasks, potentially limiting the model's generalization.\nInspired by the success of prompting techniques in natural language processing (NLP), there has been a growing interest in adapting similar ideas to graph data through \u201cpre-training and prompting\". Graph prompts (Sun et al., 2023b) modify the input graphs by adding learnable tokens or subgraphs, enabling the pre-trained GNN to better align with the requirements of downstream tasks without tuning the model parameters. Many empirical works (Sun et al., 2022; Liu et al., 2023; Tan et al., 2023; Huang et al., 2023; Ma et al., 2023; Chen et al., 2024) have found that graph prompting can reduce computational overhead, preserve the generality of the pre-trained model, and allow for"}, {"title": "2 BACKGROUND", "content": "Graph Prompt. Compared with \"pre-training and fine-tuning\", which first trains a graph model via some easily accessible task on the graph dataset and then tries to adapt the model to a new task (or even a new graph dataset), \u201cpre-training and prompting\" aims to keep the pre-trained model unchanged but adjust the input data to make the downstream task compatible with the pre-training task. Mathematically, let $F_{\\theta^*}$ be a graph model where its parameters $(\\theta^*)$ have been pre-trained and frozen; $T_{dow}$ be the downstream task, in which the task objective is measured by a loss function $L_{T_{dow}}$. Let $\\mathcal{G}$ be a graph dataset and each graph instance $G\\in \\mathcal{G}$ can be denoted as $G = (V,E,X, A)$ where $V$ denotes the node set with a node feature matrix $X \\in \\mathbb{R}^{|V|\\times F}$; $E$ denotes the edge set and the connection of nodes can be further indicated by the adjacent matrix $A \\in \\{0,1\\}^{|V|\\times|V|}$. Let $\\mathcal{P}_{\\omega}$ denote a parameterized graph prompt function with learnable $\\omega$. In most cases, graph prompts consist of some token vectors or subgraphs which will be integrated into the original graph $G$. $\\mathcal{P}_{\\omega}$ indicates how to define such graph prompts and how to combine them with the original graph to generate a new graph: $G_{\\omega} = \\mathcal{P}_{\\omega}(G)$. Graph prompt learning aims to optimize the following target:\n$$\\omega^* = \\arg \\min_\\omega \\sum_{G\\in\\mathcal{G}} L_{T_{dow}} \\big(F_{\\theta^*} \\big(\\mathcal{P}_{\\omega}(G)\\big)\\big)$$\nWithout loss of generality, we assume all these tasks are graph level (e.g., graph classification). That means $F_{\\theta}(G)$ will output a graph-level embedding for the downstream task. For node-level and edge-level tasks, many studies (Sun et al., 2023a; Liu et al., 2023) have proved that we can always find solutions to translate these tasks to the graph-level task."}, {"title": "GPF and All-in-One.", "content": "Current graph prompt designs, as described in the review by Sun et al. (2023b), can be primarily categorized into two types: prompt as token vectors added to node features, and prompt as additional graph inserted to the original graph. In the rest of this paper, we"}, {"title": "3 WHY GRAPH PROMPT WORKS? A DATA OPERATION PERSPECTIVE", "content": "Let $F_{\\theta^*}$ be any given GNN model that has been pre-trained on a given task $T_{pre}$. Here $\\theta^*$ means the parameters have been determined and frozen. For a given graph instance $G_{ori}$, we can expect the model to output appropriate graph-level embedding on $T_{pre}$ because this model has already been trained on this task. However, when we try to use this model on a new task $T_{dow}$, the output embedding, $F_{\\theta^*}(G_{ori})$, can not guarantee acceptable performance because the pre-training task $T_{pre}$ may be incompatible with downstream tasks $T_{dow}$."}, {"title": "3.1 PERSPECTIVE FROM MODEL TUNING", "content": "To fill this gap, \"pre-training and fine-tuning\" aims to adapt the pre-trained model to a new version and wish it could perform better. Assume there exists an optimal function, say $C$, which can map $G_{ori}$ to the embedding $C(G_{ori})$ to achieve good performance on $T_{dow}$. The nature of \u201cpre-training and fine-tuning\u201d is to hope the fine-tuned graph model could approximate to $C(G_{ori})$:\n$$F_{\\theta^{\\#}}(G_{ori}) \\rightarrow C(G_{ori})$$\nHowever, achieving this goal usually requires fine-tuning the graph model, which is not always efficient and needs many empirical tuning tricks. The tuning course may be even harder if the pre-trained model is ill-designed for the downstream task. In addition, we can not guarantee that fine-tuning the pre-trained model (i.e. $\\theta^* \\rightarrow \\theta^{\\#}$) can always surpass training the model from scratch because the preserved knowledge may contribute negatively to the downstream task."}, {"title": "3.2 PERSPECTIVE FROM DATA OPERATION", "content": "Instead of the above model-level tricks, graph prompts provide a data-level alternative. Some prior works (Fang et al., 2024; Sun et al., 2023a) have initially proved that graph prompts can simulate any graph operations (e.g., deleting/adding nodes/edges/subgraphs, changing node features, etc). However, how effective of graph prompt is and why this works for the new task are still not yet answered. To answer these questions, we first explain our data operation perspective by a theorem as follows:\nTheorem 1. Let $F_{\\theta^*}$ be a GNN model pre-trained on task $T_{pre}$ with frozen parameters $(\\theta^*)$; let $T_{dow}$ be the downstream task and $C$ is an optimal function to $T_{dow}$. Given any graph $G_{ori}$, $C(G_{ori})$ denotes the optimal embedding vector to the downstream task (i.e. can be parsed to yield correct results for $G_{ori}$ in the downstream task), then there always exists a bridge graph $G_{bri}$ such that $F_{\\theta^*}(G_{bri}) = C(G_{ori})$.\nA detailed proof of Theorem 1 can be seen in Appendix A.3.1, from which we can find that for any given graph $G_{ori}$, there always exists a bridge graph, say $G_{bri}$, making the following equation hold:\n$$F_{\\theta^*}(G_{bri}) = C(G_{ori})$$\nThat means, without needing to tune the model, we can try to find a data operation method that translates $G_{ori}$ to $G_{bri}$ with the pre-trained model unchanged. Graph prompts can be treated as a learnable data operation framework to help us manipulate these graph data. In this way, we can significantly reduce the difficulty of traditional fine-tuning work, improve the performance on a new task (or even a new dataset), and further enhance the generalization of graph neural networks. With this perspective, our next question is: How difficult to find such a bridge graph using graph prompts?"}, {"title": "3.3 MEASURING THE DIFFICULTY OF FINDING BRIDGE GRAPHS VIA GRAPH PROMPTS", "content": "Graph prompts can be viewed as a type of graph transformation operator. For example, the simplest graph prompt is just adding a specific prompt token vector $p_{\\omega}$ to each node feature of the graph and then we can transform this graph $G$ into a family of graphs $\\{\\mathcal{P}_{\\omega}(G)|\\omega \\in \\mathbb{R}^F\\}$, where $\\mathcal{P}(G)$ represents the output graph obtained by graph prompt on $G$. Once $\\omega$ is determined, the corresponding data transformation rule and unique output graph data are also defined. This family can be understood as the \"transformation space\" of graph $G$ under prompt $\\mathcal{P}$, denoted as $D_{\\mathcal{P}}(G)$. If the prompt operator maps the original graph $G_{ori}$ to a bridge graph $G_{bri}$ (i.e., $\\mathcal{P}(G_{ori}) = G_{bri}$), then applying the pre-trained model $F_{\\theta^*}$ yields $F_{\\theta^*}(\\mathcal{P}(G_{ori})) = F_{\\theta^*}(G_{bri})$, which conforms to the downstream task. In this process, we achieve seamless alignment of upstream and downstream tasks solely through data transformation operators, without relying on tuning the model's parameters.\nDefinition 1 (Bridge Set and e-extended Bridge Set). The bridge set of a graph $G$ is defined as:\n$$BG = \\{G_p | F_{\\theta^*} (G_p) = C(G)\\}$$\nwhere $F_{\\theta^*}$ is the frozen graph model from the pre-training task, and $C$ is the optimal function for the downstream task. The $e$-extended bridge set of $G$ is a relaxed version of the bridge set, which is defined as:\n$$\\epsilon-BG = \\{G_p | \\epsilon = ||F_{\\theta^*} (G_p) \u2013 C(G)|| \\le \\epsilon^*\\}$$\nAchieving a transformation exactly equivalent to $C(G)$ is highly non-parametric and nonlinear. Finding the corresponding $G_{bri}$ or even the bridge set for any $G_{ori}$ involves solving complex, high-order nonlinear equations. This task becomes virtually impossible manually, especially if the pre-training method integrates multiple tasks or intricate mechanisms. Fortunately, graph prompts $\\mathcal{P}_{\\omega}$"}, {"title": "4 THE UPPER BOUND OF DATA OPERATION ERROR VIA GRAPH PROMPT", "content": "Here we aim to demonstrate that using graph prompts provided by frameworks such as GPF and All-in-One, denoted as parameterized operators $\\mathcal{P}_{\\omega}$ with parameter $\\omega$, can consistently project $G$ into an $e$-extended $BG$, where $e$ has a uniform upper bound. This would initially validate the effectiveness of graph prompting methods in leveraging the potential of pre-trained models without compromising their expressive power. If $G$ can be seamlessly projected into $BG$ or an $e$-extended $BG$ (for small $e$), it would indicate excellent performance and full utilization of the model's capabilities.\nTo this end, we first conduct a quantitative analysis of $\\mathcal{P}$'s graph transformation approximation ability on a single graph. With our proposed data operation perspective, we can reformulate the findings in Fang et al. (2022) as follows:\nTheorem 2. Given a GPF-like prompt vector $p_{\\omega}$, if a GCN model $F_{\\theta}$ does not have any non-linear transformations, then there exists an optimal $\\omega$ for any input graph $G$ such that $\\mathcal{P}_{\\omega}(G) \\in BG$.\nThis theorem is proved by Fang et al. (2022) but it's important to note that all GNN models employ non-linear transformations. According to the function approximation theorem for neural networks (Hornik et al., 1989), the core of improving a model's approximation and simulation ability lies in its non-linear components. Removing these non-linear parts would limit the model to approximating only linear transformations and functions. To demonstrate the effectiveness of graph prompt learning in real downstream tasks, we offer the following theorems further:\nTheorem 3. Given a GPF-like prompt vector $p_{\\omega}$, if a GCN model $F_{\\theta}$ has non-linear function layers but the model's weight matrix is row full-rank, then there exists an optimal $\\omega$ for any input graph $G$ such that $\\mathcal{P}_{\\omega}(G) \\in BG$.\nTheorem 4. Given the All-in-One-like prompt graph $SG_{\\omega}$, if a GCN model $F_{\\theta}$ does not have any non-linear transformations, or has non-linear layers but the model's weight matrix is row full-rank, then there exists an optimal $\\omega$ for any input graph $G$ such that $\\mathcal{P}_{\\omega}(G) \\in BG$.\nTheorems 3 and 4 are proved in Appendix A.3.2. Although we've only added the row full-rank condition, these two theorems significantly expand the applicability of Theorem 2. According to Pennington & Worah (2017), well-trained models mostly contain full-rank matrices, which can be easily guaranteed by some tricks like orthogonal initialization, He initialization, etc. Raghu et al. (2017) also find that a full-rank parameter matrix in the model usually indicates stronger expressiveness. Intuitively, a weight matrix in the graph model usually indicates how to project the input graph into some latent embedding for the downstream task. According to the basic knowledge of linear algebra, when the weight matrix is row full-rank, we can always restore the input from the output. That means we can always find an appropriate input format to meet various downstream requirements. Therefore, from a practical empirical perspective, we can assume that in most cases, both GPF-like and All-in-One-like frameworks can achieve seamless projection of $G$ into $BG$, demonstrating the effectiveness and rationality of graph prompting.\nFor the cases where weight matrices are not full-rank, we have found that the error value ($\u20ac$) of the extended bridge set ($\u20ac \u2013 BG$), into which the prompting framework can map G, is positively correlated with the distance of the graph model parameter matrix from being full-rank. However, a consistent upper bound does exist for the error e of the extended bridge set when the matrix rank is determined. This means that even in some extreme cases, graph prompt learning can still guarantee a certain level of performance without experiencing extremely unexpectedly poor results:\nTheorem 5. For a GCN model $F_{\\theta}$, assume at least one layer's parameter matrix is not full rank, for GPF or All-in-One prompt, there exists an upper bound of e such that for any input graph $G$, there exists an optimal $\\omega$ where $\\mathcal{P}_{\\omega}(G) \\in \\epsilon-BG$, with $\\epsilon \\le \\mu(\\theta^*) \\cdot \\lambda(G)$, where $\\mu(\\theta^*)$ and $\\lambda(G)$ correspond to the model and graph $G$, respectively."}, {"title": "4.1 UPPER BOUND OF THE ERROR ON A SINGLE GRAPH", "content": "Here we aim to demonstrate that using graph prompts provided by frameworks such as GPF and All-in-One, denoted as parameterized operators $\\mathcal{P}_{\\omega}$ with parameter $\\omega$, can consistently project $G$ into an $e$-extended $BG$, where $e$ has a uniform upper bound. This would initially validate the effectiveness of graph prompting methods in leveraging the potential of pre-trained models without compromising their expressive power. If $G$ can be seamlessly projected into $BG$ or an $e$-extended $BG$ (for small $e$), it would indicate excellent performance and full utilization of the model's capabilities.\nTo this end, we first conduct a quantitative analysis of $\\mathcal{P}$'s graph transformation approximation ability on a single graph. With our proposed data operation perspective, we can reformulate the findings in Fang et al. (2022) as follows:\nTheorem 2. Given a GPF-like prompt vector $p_{\\omega}$, if a GCN model $F_{\\theta}$ does not have any non-linear transformations, then there exists an optimal $\\omega$ for any input graph $G$ such that $\\mathcal{P}_{\\omega}(G) \\in BG$.\nThis theorem is proved by Fang et al. (2022) but it's important to note that all GNN models employ non-linear transformations. According to the function approximation theorem for neural networks (Hornik et al., 1989), the core of improving a model's approximation and simulation ability lies in its non-linear components. Removing these non-linear parts would limit the model to approximating only linear transformations and functions. To demonstrate the effectiveness of graph prompt learning in real downstream tasks, we offer the following theorems further:\nTheorem 3. Given a GPF-like prompt vector $p_{\\omega}$, if a GCN model $F_{\\theta}$ has non-linear function layers but the model's weight matrix is row full-rank, then there exists an optimal $\\omega$ for any input graph $G$ such that $\\mathcal{P}_{\\omega}(G) \\in BG$.\nTheorem 4. Given the All-in-One-like prompt graph $SG_{\\omega}$, if a GCN model $F_{\\theta}$ does not have any non-linear transformations, or has non-linear layers but the model's weight matrix is row full-rank, then there exists an optimal $\\omega$ for any input graph $G$ such that $\\mathcal{P}_{\\omega}(G) \\in BG$.\nTheorems 3 and 4 are proved in Appendix A.3.2. Although we've only added the row full-rank condition, these two theorems significantly expand the applicability of Theorem 2. According to Pennington & Worah (2017), well-trained models mostly contain full-rank matrices, which can be easily guaranteed by some tricks like orthogonal initialization, He initialization, etc. Raghu et al. (2017) also find that a full-rank parameter matrix in the model usually indicates stronger expressiveness. Intuitively, a weight matrix in the graph model usually indicates how to project the input graph into some latent embedding for the downstream task. According to the basic knowledge of linear algebra, when the weight matrix is row full-rank, we can always restore the input from the output. That means we can always find an appropriate input format to meet various downstream requirements. Therefore, from a practical empirical perspective, we can assume that in most cases, both GPF-like and All-in-One-like frameworks can achieve seamless projection of $G$ into $BG$, demonstrating the effectiveness and rationality of graph prompting.\nFor the cases where weight matrices are not full-rank, we have found that the error value ($\u20ac$) of the extended bridge set ($\u20ac \u2013 BG$), into which the prompting framework can map G, is positively correlated with the distance of the graph model parameter matrix from being full-rank. However, a consistent upper bound does exist for the error e of the extended bridge set when the matrix rank is determined. This means that even in some extreme cases, graph prompt learning can still guarantee a certain level of performance without experiencing extremely unexpectedly poor results:\nTheorem 5. For a GCN model $F_{\\theta}$, assume at least one layer's parameter matrix is not full rank, for GPF or All-in-One prompt, there exists an upper bound of e such that for any input graph $G$, there exists an optimal $\\omega$ where $\\mathcal{P}_{\\omega}(G) \\in \\epsilon-BG$, with $\\epsilon \\le \\mu(\\theta^*) \\cdot \\lambda(G)$, where $\\mu(\\theta^*)$ and $\\lambda(G)$ correspond to the model and graph $G$, respectively."}, {"title": "4.2 EXTEND THE ERROR BOUND DISCUSSION TO A BATCH OF GRAPHS", "content": "In Sections 3 and 4.1, we have proved that graph prompting frameworks can indeed fit graph transformation operators given a single graph, thereby exploiting model capabilities. However, in other cases, we often train the model via a batch of graphs and seek to find better performance over the whole graph dataset. Correspondingly, we should aspire to transform each graph G in the downstream dataset into its corresponding BG or e-BG (for small \u20ac). If such a uniform upper bound \u20ac* exists, it would theoretically validate the excellent performance of graph prompting in general downstream tasks, confirming the rational utilization of powerful upstream models.\nFor a batch of graphs, the complexity and information contained in the graph prompt become particularly important. For instance, the increased number of prompt vectors in GPF (a.k.a GPF-Plus) and the selection of a larger size of the prompt graph in All-in-One greatly expand the transformation space of graph G under prompt $\\mathcal{P}$ (see $D_{\\mathcal{P}}()$ in section 3.3). A larger transformation space corresponds to a smaller e upper bound. In our theoretical analysis, we found that when the prompt takes an overly simple form, the capability of prompt learning is limited. This manifests as a theoretical lower bound of the bridge set extension as suggested in Theorem 6:\nTheorem 6. For a GCN model $F_{\\theta}$, for GPF with a single prompt vector or All-in-One with a single-token graph prompt, given a batch of graphs $\\mathcal{G} = \\{G_1,\\ldots,G_i,\\ldots,\\ldots, G_n\\}$, the root mean squared error (RMSE) over $\\{\\epsilon_1,..., \\epsilon_n\\}$ has a lower bound $e^\\circ$ such that $RMSE(\\epsilon_1,\\cdots, \\epsilon_n) \\ge \\epsilon^\\circ$.\nTheorem 6 is proved in Appendix A.3.4 and we also give the detailed formulation of $e^\\circ$ in the proof, from which we can find that $e^\\circ$ is related to graph data and the prompt token. This indicates that when the downstream task dataset is relatively large, we must correspondingly increase the transformation space of the prompt to better utilize the model's capabilities, which also aligns with existing empirical observations (Liu et al., 2021). Then our next question is: With the increase of graphs, how does graph prompt complexity increase with their error bound increased?"}, {"title": "4.3 VALUE DISTRIBUTION OF THE DATA OPERATION ERROR WITH GRAPH PROMPT", "content": "In the previous sections, we established a theoretical upper bound of $\\epsilon < \\epsilon^*$, allowing the graph prompt $\\mathcal{P}_{\\omega}$ to map a given graph G into the e-extended BG range. However, the conditions to reach this upper bound are often difficult to meet, making the theoretical upper bound usually correspond to some corner cases which may be not that practical in processing empirical experimental analysis. To offer stronger practical guidance for researchers' general experimental purposes, the value distribution of $\\epsilon$ (a.k.a \u201cerror range\u201d), comes to our next point of interest. The error range analysis indicates a quantitative degree of the bridge set extension, which includes estimating the mean, and variance, and finding the approximate distribution pattern.\nDefinition 2 (Graph Embedding Residual Vector). Consider a graph model with Leaky-Relu as their activation function, we denote the graph embedding residual vector as $\\beta \\in \\mathbb{R}^{1\\times F}$ where $F$ is the graph embedding dimensions. Each entry of $\\beta$ is related to the bridge graph embedding, graph prompt, and the original graph, which is mathematically defined as follows:\n$$[\\beta]_j = \\sum_i -(\\alpha) k W_{i,i,j}$$\nwhere $a$ is the parameter of Leaky-Relu; $V_{i,j}$ is the $j$-th element in the $i$-th node embedding of the bridge graph $G_{bri}$; $W_{i}$ is the weight of the $i$-th node for graph pooling (e.g., summation graph pooling means for any node $i$ in $G_{bri}$, we have $w_{i} = 1$); $k$ can be either 0 or -1 and depends on the original graph, graph prompt, and the bridge graph, the details of which can be seen in Appendix A.3.5. Here, we assume that $\\beta$ should follow an i.i.d. normal distribution with mean 0 and variance c (we carefully discuss the rationality of"}, {"title": "4.4 EXTEND THE DISCUSSION FROM LINEAR MODELS TO NON-LINEAR MODELS", "content": "While our previous analysis focused on GCN or linear aggregation models that can be represented in the form of \"diffusion matrices\", many advanced models utilizing attention mechanisms exhibit distinctly different characteristics. Their aggregation methods involve the computation of attention matrices, which in turn depend on the node feature vectors of G. This can be considered as a non-linear model w.r.t G's feature matrix. In our analysis, we use Graph Attention Networks (GAT) as an exemplar, as the attention mechanism in GAT is a common component in many non-linear models. Fortunately, the guarantees provided by our theorems do not differ significantly for these models. This indicates that even as models become more non-linear and complex, graph prompting can still effectively harness the powerful capabilities of pre-trained models:\nTheorem 9. Let $F_{\\theta}$ be a GAT model. If any layer of the model has a full row rank parameter matrix, then for the All-in-One prompting framework, for any input graph $G$, there exists an optimal $\\omega$ such that $\\mathcal{P}_{\\omega}(G) \\in BG$. When the parameter matrix is not full rank, there is an upper bound $\\mu(\\theta) \\cdot \\lambda(G)$ making $\\mathcal{P}_{\\omega}(G) \\in \\epsilon-BG$, $\\epsilon \\le \\mu(\\theta) \\cdot \\lambda(G)$.\nWe give a detailed proof in Appendix A.3.6. The above theorem demonstrates the robustness of graph prompting methods across different types of GNN architectures, including those with non-linear attention mechanisms. The consistency of these results with our earlier findings for linear models suggests that the fundamental principles of graph prompting remain effective even as we move towards more complex and non-linear model architectures."}, {"title": "5 EXPERIMENTS", "content": null}, {"title": "5.1 EXPERIMENTAL SETTINGS", "content": "Data Preparation: We first confirm our theoretical findings on synthetic datasets because these datasets offer controlled environments, allowing us to isolate specific variables and study their impacts. We generate these datasets by defining the dimension of graph feature vector ($F$), average of graph node numbers ($N_{avg}$), average of graph edge numbers ($E_{avg}$), and number of graphs in the dataset ($M$). These parameters characterize both individual graphs and the entire dataset, facilitating our study of the relationship between these features and e. We further conduct the experiments on the real-world dataset in Appendix B, from which we can find similar observations."}, {"title": "Model Settings:", "content": "We utilize two GNN frameworks: GCN (representing linear models) and GAT (representing non-linear models). We limit our experiments to these two models as other models follow similar patterns. Unless otherwise specified, we use a 3-layer GNN with Leaky-ReLU activation function and feature dimension $F = 25$. For full-rank matrix studies, we ensure each layer's matrix is full-rank (selected after pre-training). For non-full-rank matrix studies, we set the rank loss to 5 by default. The default ReadOut method is mean pooling."}, {"title": "Training:", "content": "In the graph prompting training process, we perform gradient descent on the parameters w of the graph prompt $\\mathcal{P}_{\\omega}$ using the Adam optimizer. We use a learning rate of 1 \u00d7 10-4 and weight decay of 5 \u00d7 10-5. We implement an early stopping mechanism with a maximum of 2,000 epochs by default. Our loss function is defined as $||F_{\\theta^*} (G_p) \u2013 C(G)||$ for single-graph tasks, and $\\sqrt{\\sum_{G\\in\\mathcal{G}} ||F_{\\theta^*} (G_p) \u2013 C(G)||^2/M}$ for multi-graph tasks where $G_p$ is the combined graph with $G$ and graph prompt, and $C(G)$ means an optimal function to the downstream task, which is not accessible without a specific task. Since the ultimate purpose of graph prompting is to approximate graph operation, we here treat C(\u00b7) as various graph data permutations such as adding/deleting nodes, adding/deleting/changing edges, and transforming features of a given graph $G$. Then we wish to see how well the graph prompt reaches C(G) by manipulating graph data with a graph prompt. For more detailed experimental settings, please check in the Appendix C."}, {"title": "5.2 ON MAPPING TO BG WITH SINGLE GRAPH", "content": "According to Theorems 3, 4, and 9, error-free projection can be achieved in full-rank situations. Here we investigate convergence properties with a maximum of 5,000 epochs. From the results we can find that for single-graph, full-rank matrix scenarios, both GPF and All-in-one approaches show loss converging to zero, which is consistent with our theoretical findings."}, {"title": "5.3 ON MAPPING TO E-BG WITH SINGLE GRAPH", "content": "Theorem 5 states that in non-full-rank situations, there exists an upper bound on the error. Here we extensively examine the relationship between various parameters and the error upper bounds in the context of non-full-rank matrices given a single graph. Since showing this upper bound in practice is usually intractable, we fix all other parameters and employ five pre-trained models. For each fixed pre-trained model, we conduct experiments and repeat each experiment 30 times. Then we take the maximum loss from these repetitions as the approximation to the upper bound."}, {"title": "5.4 ON MAPPING TO E-BG WITH MULTIPLE GRAPHS", "content": "Theorem 6 discusses a lower bound on the RMSE over the errors on multiple graphs with a single prompt token. In this section, we conducted experiments on the number of graphs in the dataset w.r.t the empirical minimum error. As shown in , the minimum error shows an upward trend and then tends to saturate, which is highly consistent with the findings in Theorem 6."}, {"title": "6 CONCLUSION", "content": "This paper addresses the theoretical gap in graph prompting by introducing a comprehensive framework from a data operation perspective. We introduced the concepts of \"bridge sets\" and \"e-extended bridge sets\" to formally demonstrate that graph prompts can approximate graph transformation operators, effectively bridging pre-trained models with downstream tasks without retraining. Our contributions are threefold: first, we established guarantee theorems confirming that graph prompts can simulate various graph data operations, explaining their effectiveness in aligning upstream and downstream tasks. Second, we derived upper bounds on the approximation errors introduced by graph prompts for both individual graphs and batches of graphs, highlighting how factors like model rank and prompt complexity influence these errors. Third, we analyzed the distribution of these errors and extended our theoretical findings from linear models like GCNs to non-linear models such as GATs, showcasing the robustness of graph prompting across different architectures. Our extensive experiments validate these theoretical results and confirm their practical implications, demonstrating that graph prompts can effectively leverage pre-trained models in various settings. By providing solid theoretical foundations, our work not only explains why graph prompts work but also guides the design of more effective prompting techniques. This empowers researchers and practitioners to utilize graph prompts with greater confidence, potentially leading to more efficient and generalized graph neural network models across diverse applications."}, {"title": "A THEORETICAL ANALYSIS AND PROOFS", "content": "Reading Guideline: Appendix A \u201cTheoretical Results and Proofs\u201d is divided into four subsections:\n\u2022 A.1 Definitions and Preliminaries: Readers are advised to initially skip this subsection. It serves as a reference for unfamiliar terms encountered later in the text.\n\u2022 A.2 Fundamental Lemmas: These properties are essential components for proving the main theorems. We will clearly express what each lemma demonstrates. Readers are recommended to refer to this subsection when encountering these lemmas while reading the theorem proofs.\n\u2022 A.3 Detailed Proofs of Main Theorems: This subsection is recommended as the primary focus for readers. It contains the core ideas behind why prompts work, even though some lemmas may be required for complete understanding.\n\u2022 A.4 Additional Mathematical Lemmas: This subsection includes purely mathematical lemmas encountered during the proofs in A.2 or A.3. These lemmas are not directly related to GNN models or prompts. Readers are advised to review this subsection after reading the previous content."}, {"title": "A.1 PRELIMINARIES AND DEFINITIONS", "content": null}, {"title": "A.1.1 PRELIMINARIES", "content": "Preliminary 1 (GCN and GAT).\nGraph Convolutional Networks (GCN) Kipf & Welling (2016) perform convolution operations on graph-structured data by aggregating feature information from a node's neighbors. The recursive update rule for a GCN layer is:\n$$H^{(l+1)} = \\sigma (\\tilde{A}H^{(l)}W^{(l)}),$$\nwhere $\\tilde{A} = D^{-1/2}AD^{-1/2}$ is the normalized adjacency matrix, $H^{(l)}$ is the node feature matrix at layer $l$, $W^{(l)}$ is the learnable weight matrix, and $\\sigma$ is a nonlinear activation function.\nGraph Attention Networks (GAT) Veli\u010dkovi\u0107 et al. (2017) enhance GCNs by introducing attention mechanisms to weigh the importance of neighboring nodes during aggregation. In the simplest form of self-attention, the attention coefficient between node $i$ and node $j$ is based on the inner product of their feature vectors:\n$$e_{ij} = \\vec{X}_i^T \\vec{X}_j,$$\n$$\\alpha_{ij} = \\frac{exp(e_{ij})}{\\sum_{k\\in N(i)} exp(e_{ik})},$$\n$$H_i^{(l+1)} = \\sigma \\Big(\\sum_{j\\in N(i)} \\alpha_{ij} H_j^{(l)}W^{(l)}\\Big),$$"}]}