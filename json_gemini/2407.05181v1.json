{"title": "Instructors as Innovators: A future-focused approach to new AI learning opportunities, with prompts", "authors": ["Ethan Mollick", "Lilach Mollick"], "abstract": "This paper explores how instructors can leverage generative AI to create personalized learning experiences for students that transform teaching and learning. We present a range of AI-based exercises that enable novel forms of practice and application including simulations, mentoring, coaching, and co-creation. For each type of exercise, we provide prompts that instructors can customize, along with guidance on classroom implementation, assessment, and risks to consider. We also provide blueprints, prompts that help instructors create their own original prompts. Instructors can leverage their content and pedagogical expertise to design these experiences, putting them in the role of builders and innovators. We argue that this instructor-driven approach has the potential to democratize the development of educational technology by enabling individual instructors to create Al exercises and tools tailored to their students' needs. While the exercises in this paper are a starting point, not a definitive solutions, they demonstrate Al's potential to expand what is possible in teaching and learning.", "sections": [{"title": "Introduction", "content": "Widely accessible Large Language Models show considerable early promise as educational tools (Choi et al, 2023, Henkel et al, 2024). One of the potential benefits generative AI brings to education is the ability to democratize the creation of new tools for learning and teaching. Since they can be \u201cprogrammed\u201d through prompts alone, instructors can more easily become tool creators, enabling transformative uses of technology that are directed by instructors for their specific classroom needs.\nIn this paper we preview a future-focused approach to AI exercises for students that instructors can customize to suit their students, topics, and classrooms. Each of these exercises highlights a personalized learning activity \u2013 simulation, tutoring, mentoring, co-creation, etc. \u2013 that was difficult or expensive to implement prior to the advent of generative AI. Generative AI is unique among educational technologies because classroom applications can be built by individuals without extensive technology or coding experience. Relying on their domain and pedagogical expertise, and their knowledge of their students' specific needs, instructors can create exercises that can help their students learn. Further, instructors are uniquely positioned to assess how and whether these exercises help their students. This is innovation at the teacher and classroom level that does not require systemic action and that puts instructors in the position of builders and creators. And instructors are easily able take a pedagogy-first approach because their focus is not on the technology but on their students, their classroom, and their lessons. Given the varying time commitments and willingness to work with these systems, this approach allows instructors to use Generative AI in a voluntary way and at their discretion; instead of imposing a pre-built technological solution, instructors should be in control of the development of specific technological solutions suited to their classrooms.\nThe exercises we showcase are descriptive and not prescriptive. We attempt to show the capabilities of AI to extend or transform the classroom based on instructor knowledge."}, {"title": "\u201cProgramming\u201d Al Tools", "content": "The skills needed to create AI tools are already in the hands of instructors. Instructors can provide direction, break down tasks into sequential steps, gauge understanding adjust depending on their reading and assessment of student performance. These are the skills needed to instruct an AI Large Language Model and create a prompt for students or other instructors.\nInstructors will need to experiment to ensure that the prompts work for their classes. In doing so, they should be aware of the common mistakes of AI. It can express persistent misconceptions about a topic (based on its training data). AI may have a shallow grasp of a concept and may not easily be able to provide clear explanations, examples, or analogies. Additionally, it can be fickle and refuse to perform actions it is capable of performing and it can get stuck in a loop.\nThere are techniques instructors can use to mitigate these issues and we have used many of these techniques in the prompts. For instance, we include context to provide the AI with specific domain knowledge to draw on, give the AI examples, and we provide the AI with step-by-step directions. Despite these techniques, no prompt is guaranteed to work at any given time. As models change these approaches may change as well. Below is a list of typical errors (although there are many others) and possible approaches to help mitigate those errors."}, {"title": "Ethical and Pedagogical Concerns", "content": "Large Language Models have some advantages in terms of access compared to other technological tools. They can be accessed via phone, and do not generally require high speed internet access. Cost, however, can be an issue. While free access to Large Language Models is broadly available, access to the GPT-4 class models required to use the prompts in this paper is more limited. At the time of writing, Microsoft was the only organization providing access to GPT-4 class models for free (through Microsoft Copilot in Creative Mode). We urge other LLM providers to realize the importance of widespread and free educational access to AI.\nBeyond equity of access, there are other ethical concerns. While this paper focuses on the practical use of AI as a way to expand and transform the classroom, there are also wider implications to using AI that educators may want to consider before deciding whether to use these systems. Large Language Models are trained in ways that may violate copyright, and often rely on the efforts of low-wage workers in precarious conditions for part of their training. Models are trained on biased data and can produce either subtly or overtly biased results. And because these biases seem to come from an objective machine, they can be especially pernicious (Bender et. al, 2021). Using AI systems can mean sharing private data with the for-profit companies developing LLMs, and that data may be used to train further Als.\nInstructors, in consultation with their institutions, will need to reach decisions about the way they will address these risks. They may want to confront the potential biases and harms as part of their instructions, or to teach students to become better consumers of AI content. And, if they choose not to address these issues directly, they should ensure that AI literacy is being taught in other contexts for students to be exposed to this range of issues and risk factors.\nExercises in the paper can be combined with a critical AI discussion. Students may be asked to highlight and explore the AI's deficiencies, including its tendency to hallucinate"}, {"title": "Al Opportunities for Practice and Application", "content": "Learning through Simulations\nFrom pilots to physicians, truck drivers to athletes, those who spend time rehearsing in a simulated environment can identify errors and learn from their mistakes (Edmondson, 2023). Simulations are an effective way for students to rehearse or practice what they have learned in a low-stakes context (Edery & Mollick, 2008). Simulated scenarios create a controlled space for practice; learners can explore, make mistakes, and gain valuable insights without fear of failure (Edmondson, 2023). And simulations can reinforce previously learned knowledge and give students a chance to apply that knowledge, practicing valuable skills rarely encountered in the real world.\nPedagogical approach\nSimulated practice can help students practice skills but traditional educational simulations are hard to build and demand numerous resources (we have been building them ourselves for over a decade!). In contrast, AI-based scenarios are easier to design and deploy and they can be tailored to a specific set of learning goals. Below are simulation exercises that instructors can assign to students: role play, in which the student assumes the identity of someone else in a scenario or goal play in which the student maintains their identity and applies their knowledge and skills in guiding others (a simulated character or set of characters).\nBuilding simulations with Al\nWhen carefully prompted, the AI can quickly create adaptive simulations in which individual students can play a role, interact with character(s) (played by the AI), and practice key skills. AI can quickly and easily develop multiple scenarios in which students can draw on previously learned knowledge to solve or attempt to solve new problems. The AI's ability to set up a compelling scenario, give the student meaningful choices, wrap up the scenario, and summarize what the student did well (and less well) means that each student can practice a key skill at any point. Note that for any of these"}, {"title": "Simulation Type 1: Role Play", "content": "Simulations can be designed so that students take on a role different from who they are in real life (for instance, the student in a negotiation class takes on the role of a seller in a high-stakes negotiation, or the student in an entrepreneurship class takes on the role of startup founder as they pitch their business idea). Students must apply the strategies learned in class to succeed.\nRole playing also has the added advantage of allowing students to move outside their comfort zone and experiment as they play the role \u2013 perhaps they are more assertive than they would be in a real world situation or maybe they take a risk they wouldn't take in real life \u2013 the simulation itself gives them a chance to experiment with different versions of themselves. Stepping into a role also gives students a chance to experience the topic, problem, or framework in a narrative-driven and personally engaging way, and as they role play, they quickly learn their strengths and weaknesses."}, {"title": "Prompting for Role Play", "content": "An AI role-play simulation prompt has several components:\nIntroduction to AI-Mentor. The student is first introduced to an AI Mentor who establishes a supportive context and sets the stage for the experience. The AI Mentor elicits information, asking the student about their experience level to help the AI customize the experience. For instance, in the prompt below, the AI asks about the level of student experience in a negotiation so that it can set up a straightforward or more complex scenario depending on the student's previous experience. Note that this is one question that the AI can ask; depending on the topic and learning goal, individual instructors may customize the initial set of questions. The key: give the AI \u201cinsight\u201d about the student's knowledge and prior experience so that it can effectively tailor the scenario.\nScenario Suggestions. The AI Mentor then offers students a choice among varied scenarios, giving students agency. Note that the more the student shares with the AI the more personalized the scenarios may be. For instance, a student that shares \u201cI have some experience negotiating\u201d will be given a choice of standard scenarios, but a student that shares additional context \u201cI am a medical student and I have some experience negotiating\" will receive scenarios tailored to their interests and background.\nNarrative Set Up and Play. The AI then sets the scene, provides objectives to guide the student's actions, and helps the student navigate the scenario. Every time a student responds during role play their response changes the story. In many cases, the AI gives students hints about what to focus on and what to do next as the scenario progresses. In our scenario prompts, we limit the number of interactions within any scenario so that the AI stays on track, and we prompt the AI to push the student to make a consequential decision to close out the scenario.\nFollow-Up Advice. The AI Mentor then gives the student advice based on their performance in the scenario, helping students reflect on their approach. The AI Mentor will often reiterate the learning goals of the simulation and the strategies the student applied (or didn't apply) effectively.\nThe prompt is structured so that the student understands the goal of the simulation, is then immersed in the simulation, and finally zooms out to consider how well they did. Below you'll find customization suggestions for an example role play prompt focused on negotiations. All prompts can be found in Appendix A."}, {"title": "Simulation Type 2: Goal Play", "content": "Goal play simulations involve students playing themselves, often guiding a character in a scenario, to achieve goals or apply specific frameworks. For instance, the student's goal might be to apply decision-making techniques discussed in class. In one scenario, they might be tasked with helping a fictional character make decisions. The student, playing themselves, would need to interact with that character and help them apply effective decision-making frameworks. The student might help that character assess alternatives, weigh the pros and cons of different actions, and encourage the character to make well-informed decisions. In this case, the student would adapt to the context but \u201cplay\u201d themselves in the scenario, incorporating the framework they learned in class.\nImportantly, in a goal play scenario the AI sets up a scenario in which the student knows something the character in the simulation does not and guides the character using what they know, generally a framework. In one of the examples below students must apply a goal setting framework to help a fictional character set goals and in the other the student must apply self-distancing techniques to help a fictional character problem solve and change how they think about an experience (Kross, 2020)."}, {"title": "Prompting for Goal Play", "content": "A goal-play simulation prompt has several components:\nA Dual Role for the AI. The AI plays the AI Mentor and crafts the scenario and may also give students directions after the scenario or reference an upcoming class discussion. The AI also plays a character within the simulated scenario.\nScenario Choices. The AI Mentor offers students a choice among scenarios (e.g., literary characters or historical figures) to apply the framework. Students can choose a scenario that piques their interest.\nNarrative Set-Up. The AI sets the stage for the scenario and is instructed not to overcomplicate or overwhelm students with too much complexity, prompting students to focus on the topic or framework rather than focusing only on the details of the scenario. This is important because the goal is for students to focus on the lesson and not the concrete details of the scenario alone.\nScenario Initiation. The AI is instructed to clearly mark the beginning of the interactive part of the simulation sending a signal to students \u2013 they are now in a scene and applying what they know to a new situation.\nGuidance on Goal and Techniques. The AI Mentor may step into the scenario and remind students of their goals or give them hints. Note however that the AI Mentor does not interfere during the scenario, giving the student autonomy to apply lessons learned.\nEnd of Scenario and Advice. The AI Mentor steps back onto the scene and can offer students advice. Depending on its instructions, the AI can reinforce key elements of the topic or framework and identify more for the student to consider."}, {"title": "Simulations: Classroom Implementation", "content": "Deployment\nThere are several ways to incorporate AI simulations into a class. Depending on the simulation, you may be fine with students viewing the AI instructions or you might prefer to send students a custom chatbot (a GPT) with so that the AI instructions themselves don't \u201cgive away the game.\"\nTo deploy, you can have students play through the simulation in class and then have a class discussion. Alternatively, you can assign the simulation as homework and have students hand in both the played through conversation (via links) and a reflection paper that asks students to answer a number of questions based on their experience. It's important to note that as AI output is variable, students will have different experiences as they play through their scenarios. 3\nGrading and Assessment\nIdeally, simulated experiences should give students an opportunity to practice skills they are already familiar with. While instructors can experiment with trial-and-error approaches (having students \u201cfail\u201d at the task and then unpack that failure in class as a way to introduce a new topic) there is danger that students will learn the wrong thing or get frustrated. In class, you can explore where the AI was successful and where it failed, using a few examples shared by students, focusing on how the example scenario highlighted (or failed to highlight) class materials. Students should be asked: What happened? What did you do? How did the simulation end? What would you do differently next time and why? And they should also interrogate the AI's output. You can ask: For a role-playing simulation, to what extent was the scenario realistic? Did the simulation play out? Did the AI get stuck in a loop? Did you detect bias in the scenario or interaction? The key is for students to apply ideas or frameworks they"}, {"title": "Risks", "content": "AI simulations present a variety of risks. While they can personalize a simulation and adapt and improvise depending on student responses, they do not always tie the lesson to the scenario or provide solid advice. They also do not always follow directions and instructors should expect that students will have different experiences in interacting with the AI. If the specific lesson or subject calls for tight scripting (if, for instance, a lesson calls for a specific exchange during a team conversation and that dynamic should surface, every time) then the AI approach may not be right for this specific topic. Instructors can however experiment with giving the AI specific instructions about role, character, dialogue, challenges, and scenarios. Our prompts allow the AI to guide the scenario, but it is worth testing to learn how very specific instructions that give the AI less leeway to steer the scenario may work.\nThe strength of AI in crafting simulations, its dynamic ability to adapt and tailor scenarios to individual students, can also be its weakness. While AI often excels at following instructions and adjusting to student choices with the lesson in mind, it can sometimes falter. Its interpretation of instructions and execution of scenarios can also vary significantly between different AI models. For example, Gemini tends to take literary liberties, occasionally overriding instructions to pursue what it considers useful scenarios or inviting students to suggest their own (this may or may not detract from the experience). This capacity to vary output offers a powerful, personalized learning experience, but it comes with risks: each student's experience becomes highly individualized, which may lead to confusion if the AI's narrative strays from the intended lesson or lacks cohesion. Scenes and characters generated by the AI can also vary in difficulty; some students may be presented with challenges that are too difficult and others may encounter a problem that is relatively straightforward, given the same set up. Instructors should experiment with simulation prompts in their subject matter to better understand how the models react to their instructions. As with any AI exercise, instructor involvement, feedback, and oversight are critical."}, {"title": "Learning through Critique", "content": "Pedagogical Approach\nTeaching someone else can help you learn. Students who teach others engage deeply in the material and can gain insights into the gaps in their knowledge, as they monitor their own understanding (Kirschner & Hendrick, 2020). Known as the prot\u00e9g\u00e9 effect\" students who teach others develop higher comprehension and a deeper, more persistent understanding of the material (Fiorella & Mayer, 2013). This is in part because to teach someone else requires that the teacher organize what they know so that they can explain it to someone else, adapt to the student and improvise \u2013 answering questions and making decisions during the lesson (Roscoe & Chi, 2007). The act of structuring their own knowledge ahead of and during teaching is an ongoing and open-ended problem- solving activity (Biswas et al., 2005). Incorporating teaching opportunities for students can be an effective way to promote deeper learning and understanding of specific topics or ideas.\nBuilding Opportunities for Critique\nAI can provide students with multiple \u201cpeers\u201d or \u201cnovice student\u201d teaching opportunities. It can act as scenario creator, quickly generating example scenarios that illustrate an idea or a framework. Students can then be tasked with explaining how (and if) the examples illustrate the idea or framework. The AI can also act as the student for any topic, prompting students to explain ideas to help the \u201cAI student\u201d understand class material. With careful prompting the AI can \u201cact\u201d as a novice about a topic, asking questions that challenge the student-teacher to organize their knowledge. There may be a number of benefits to this approach: students can work with multiple AI \u201cpeers\u201d or \u201cstudents\u201d and unlike in a peer teaching exercise, there is no risk of that AI student learning incorrect information even if the student-teacher makes an error; additionally, instructors can view a comprehensive \"teaching log\" of the conversation, as students can provide a link to the entire AI interaction."}, {"title": "Critiquing Type 1: Critiquing an Al-generated Scenario", "content": "A key aspect of expertise is the ability to abstract out key elements of a concept and recognize those elements in a new situation; experts can recognize the deep structure of a problem rather than focus on its surface elements (Willingham, 2002). In this exercise, we use the AI's strengths (its ability to quickly craft scenarios) and its imperfections (its tendency to hallucinate or make mistakes or anchor on one particular aspect of a concept to the exclusion of others) as a way to challenge student understanding of course concepts. Students who have already learned about a topic, can be prompted to focus on the specific details of an AI-generated scenario and determine how (and if) the scenario demonstrated the underlying elements of a concept. To answer the question: Did the AI apply this concept correctly? the student must draw on deep knowledge of the elements of that concept (Gentner et al., 1993). The exercise can give students the opportunity to practice recognizing the deeper elements of course concepts."}, {"title": "Prompting for Critiquing a Scenario", "content": "In this exercise the AI provides the student with a scenario in which it applies or illustrates a concept. The AI initiates a dialogue with the student and gives the student a choice of topic and a series of scenarios to choose from. The student picks a scenario type, and the AI then illustrates the topic or concept via the scenario the student picked out. The student is then asked to review the scenario explain how (and whether) the AI's output illustrates the concept. Because the AI can make mistakes, provide incomplete illustrations, and miss the mark in exploring the complexity of any concept, students may then ask the AI to rewrite the scenario, giving specific instructions for a revision. In correcting the AI, they get a chance to practice articulating what they know."}, {"title": "Critiquing Type 2: Al as Student", "content": "In the Teach the AI exercise (full prompt in Appendix A) we prompt the AI to take on the role of a novice student and ask questions of the teacher. To give the student a sense of agency and signal early on that the student should take the lead in the scenario, we ask the student choose the AI student persona they will teach. The student then takes on the role of teacher and explains a concept to the AI student who proceeds to follow up and ask questions throughout the conversation.\nWe also specify pedagogical principles we explicitly tell the AI what kinds of questions it might ask and how to \u201ctalk\u201d to the student-teacher in order to draw them out; we instruct the AI to ask open-ended questions to challenge students to reconsider and reorganize what they know through the act of explanation (Coe et al., 2020). At the end of the exercise, the AI (as Mentor) asks students to review the exercise and consider what question they might ask their AI \u201cstudent\u201d to check for understanding challenging the student to reflect on their teaching and on the elements of the topic."}, {"title": "Critique: Classroom implementation & deployment", "content": "Ahead of the exercise, instructors can ask students to prepare to teach \u2013 that is, instructors can direct students in class to spend some time preparing what and how they plan to teach their AI student; preparation alone can help deepen their understanding of the topic (Roscoe & Chi, 2007). Then instructors can send students the exercise (via a"}, {"title": "Grading and Assessment", "content": "Instructors can ask students to report out their interactions: which \u201cstudent\u201d did they choose to teach? What questions did the AI ask? To what extent did students think the AI realistically portrayed a novice? Did the AI ask a question that you weren't sure how to answer? What question did you suggest asking the AI student to check for understanding? Students can also share a link to their interactions so that instructors can take a look at student explanations and note any gaps or sticking points in student understanding. Additionally, students can be asked to note any bias in AI responses and any specific hallucinations they spotted during the interactions.\nStudents should report out the entire interaction and write a paragraph reflecting about the experience. That reflection can also serve as a basis for a class discussion that serves a dual purpose: a discussion about the topic or concept and about how to work with the \u0391\u0399."}, {"title": "Risks", "content": "While the risks of teaching an AI student are low, there are some elements of the exercise to watch out for. The AI may get off track. That is, if a student teaches the AI about a topic and the AI is \u201cinterested\u201d in a particular aspect of the topic, it may keep pushing on this aspect and ignore other aspects of the topic and get off track. It's important to remind students that they are driving this conversation. If the AI asks an irrelevant question or continues to pursue a particular point, they can redirect the AI: \"let's get back on track and consider [the topic].\u201d Similarly, the AI can only roleplay a novice up to a point and the roleplay is not particularly realistic. While it does often ask interesting and challenging questions, the exercise does not mirror an actual teaching exercise in the classroom. As with any AI exercise assigned to students, expect variable responses from the AI. Students will have different experiences to share in class about this interaction."}, {"title": "Learning through Co-Creation", "content": "Pedagogical Approach\nThe act of breaking down your knowledge into sequential step by step instructions to explain something someone else helps you learn, and highlights gaps or inconsistencies in your own knowledge. For students this process may break the illusion of expertise (Glenberg, 1982): can you create something (in this case an explanation) for someone else? (Lombrozo, 2006). This act requires that you step into the shoes of another person and build something that is useful to them giving them examples that highlight aspects of a concept and a process through which they can surface the complexities of the concept.\nCo-Creation with Al\nAI's ability to quickly ask questions and adapt to a given circumstance can make it a partner in a co-creation process. Its capacity to interact and suggest solutions or paths forward can challenge students to both articulate their ideas clearly and consider alternatives. The push and pull of the dynamic can be productive as students apply their own expertise to push the AI to produce something ambitious as they pair their expertise with the AI's capacity to dynamically build and iterate. In addition, co-creating with an AI highlights the role that AI can take beyond the specific exercise a copilot for students in their area of expertise; students can lead and drive the interaction and assess the final output.\nCo-Create a Case\nIn this exercise, students co-create a lightweight case with the help of the AI and their goal is to help create a case that a peer could work through. To begin the exercise, the AI asks the student a series of questions about the topic and asks the student to choose a scenario for the specific topic. The AI then creates the case based on student advice and"}, {"title": "Classroom implementation", "content": "Deployment\nThis exercise is designed for students who have knowledge of a topic. It represents a practice opportunity \u2013 students must articulate ideas, come up with examples, and assess the AI's work. Topics or concepts that work best with this type of exercise are rich in detail and benefit from discussion, analysis, and evaluation. Note: instructors can remind students that they should work with the AI conversationally, asking it to redo work or add to previous work to improve its initial case output, challenging students to add their expertise to the mix.\nGrading and Assessment\nInstructors can highlight that the goal is for the student to co-create a case that explores a major aspect of a topic and that students should actively inform the AI about the topic, giving it step-by-step explanations and clarifying concepts; they should also critique the AI's output and give it input and information to improve its initial case output. The quality of the initial case the AI will output is likely to be fairly surface-level and students need to work with the AI to give it more context and advice to improve the case. Once final cases are developed, instructors can establish a peer review process where students exchange their cases. Peers then analyze and work through the cases, offering solutions or recommendations and assessing the quality of each case.\nRisks\nAs with any AI output, there may be a significant variance in how well the AI leads the student initially (in gathering information for the case). Additionally, the initial case outputs may vary widely, giving some students fairly refined cases as a starting point, and others far less structured versions that require significant work to improve. This type of exercise should be also preceded by instruction about the topic followed up with feedback, otherwise there is a risk of solidifying errors or misunderstandings."}, {"title": "Mentoring, Coaching, and Tutoring", "content": "Pedagogical Approach\nExtensive evidence supports tutoring as an effective intervention (Chi et al., 2001; Dietrichson et al., 2017; VanLehn, 2011). While questions remain about optimal tutoring strategies, evidence suggests that effective tutors are persistent and interactive; they don't dominate the conversation and instead encourage students to generate responses and explain what they know in their own words (VanLehn, 2011). During any lesson or tutoring session, tutors can begin by stating the goal of the session, work to assess the students' prior knowledge, present material in small steps, provide varied examples, offer feedback, and scaffold students with the goal of withdrawing that scaffolding as the student improves (Chi et al., 2001). A tutoring session can provide students with additional instructional time and personalized learning. During one-on-one or small group sessions, tutors can revise their strategies as they react to student responses and students can ask considerably more questions than they do in classroom settings (McArthur et al., 1990). Additionally, tutors can prompt students to reflect or monitor their own knowledge, helping students gain deeper understanding of the material. While tutoring can be immensely effective, it is a complex task that relies on improvisation, adaptivity, interactivity, and pedagogical and domain-specific knowledge. And it is an expensive, time intensive intervention that requires resources and planning; despite evidence of its usefulness, tutoring is available to few students (Chi et al., 2008).\nBuilding Opportunities for Mentoring and Coaching\nGenerative AI models are not built to teach. If asked for an explanation of any topic, the AI will provide one, but that explanation may not be adapted to the specific student and crucially, reading an explanation does not lead to deep understanding. However, if carefully prompted and with instructor oversight Generative AI can play the role of tutor, interacting with the student via open-ended questions, checking on prior"}, {"title": "Mentoring and Coaching Type 1: Reflection Coaching", "content": "Prompting for Reflection\nReflection plays a crucial role in learning by giving students an opportunity to revisit, analyze and make sense of their experiences. Researchers note that reflection, when combined with feedback, can improve student performance. (Anseel et al., 2009) When facilitated through writing (journaling or storytelling) reflection can help students make connections between what they know and new information. Reflection can help students return to the experience and re-evaluate it (Herrington, 2002). Reflection becomes particularly important when students engage with complex bodies of knowledge, as the"}, {"title": "Classroom Implementation", "content": "A reflection GPT can be assigned as homework or in- class work. Students can be told that the AI has general knowledge of their experience, or topic (in its knowledge, if using ChatGPT Plus) and that they can engage in dialogue with the AI, keeping in mind the goal of the exercise (as defined by the instructor) and noting that they can direct the flow of the conversation."}, {"title": "Mentoring and Coaching Type 2: Integration Agent", "content": "Making connections between ideas is key to helping students develop a deep understanding of a subject. When ideas are interconnected, knowledge becomes more durable and accessible over time (Jones, 2023). Studies show that one reason that experts approach problems differently than novices is the way they organize their knowledge. While novices tend to remember facts in isolation, experts structure their understanding around central ideas and core concepts. This allows them to make connections, draw insights, and apply their knowledge more effectively (Bransford et al., 2000).\nFor students to develop expertise in a subject, it is crucial that they learn to organize their knowledge in a similar manner. By taking the time to understand how information within a course connects and relates, students can construct a framework of knowledge, essential for developing expertise (Bransford et al., 2000)."}, {"title": "Al Tutors", "content": "High-dosage tutoring, where students work closely and frequently with tutors, has been shown to improve outcomes (Kraft et al., 2021). Research shows that tutoring that focuses student attention, allows students time to ask and answer questions, and actively work on problems can help students learn (Chi & Roy, 2008). AI Language Models can \"act\u201d as tutors if prompted effectively. Early studies have shown the potential for AI tutors (Kumar et al., 2023; Henkel et al., 2024). The AI can be directed to focus on interactivity and dialogue, adapt to student responses, ask students open- ended questions, assess student prior knowledge, and provide personalized explanations, examples, and feedback."}, {"title": "Classroom Implementation", "content": "Tutoring should be used with caution, but it may be useful to assign students custom- developed tutors to assist with particularly difficult concepts or problems. Only use tutor prompts that you have tested (and iterated on, given subject matter expertise) to assess hallucination risks."}, {"title": "Risks", "content": "A concern with AI tutoring is the potential for the tutor to have only superficial knowledge of a topic, or generate plausible-sounding responses that are incorrect or subtly incorrect. Students may not be aware of this issue, may lack sufficient knowledge about the topic to spot an error, or may not feel confident enough to question the output. Because the AI's knowledge varies across topics, it's important to test the tutor on a specific concept to understand its capabilities and limitations. To mitigate this issue, the AI can be directed to focus on a specific topic area and can be provided with additional context and domain-specific nuance. However, any student interacting with an AI tutor may encounter a misconception. Instructors will need to weigh the benefits and drawbacks of assigning AI tutors for specific topics.\nA note on tutoring behavior across models. Different AI models exhibit varying behaviors when given the same or similar prompts. While there are many similarities, some models appear to have less \u201cagency\u201d compared to others, which can impact the performance of an AI tutor. For instance, OpenAI's ChatGPT 4\u2019s AI tutor can guide the student through a process and ask questions to assess the student's understanding throughout the process. However, when the same prompt is given to different models (Claude, 3 Opus, or Google's Advanced Gemini), these models may let the student take the lead in the conversation, asking for self-assessment during the session (\u201cDo you follow?\u201d, \u201cDo you understand?\u201d, or \u201cDo you need any more help?\u201d) even when explicitly told that students may not be able to self-monitor at this point in the learning process. In such cases, instructors can modify the prompt by adding clear and specific instructions to ensure that the AI tutor takes a more proactive role in guiding the student and evaluating their understanding, rather than seeking confirmation from the student:"}, {"title": "Blueprints: Tools to Build Tools", "content": "The prompts and approaches previously discussed in this paper focused on how prompts could be customized and used by instructors. However, generative AI is a tool that can be used to build other tools. This is particularly useful for cases where instructors want to create a customized tool, but do not have the experience or time to create one based on the templates discussed before.\nWe call these sorts of meta-tools \u201cblueprints\u201d.\nAl Tutor Blueprint\nInstructors can create AI tutors for students and test out those tutor prompts before giving them to students. Using an AI Tutor Blueprint the instructor can work with an AI \u201cinstructional designer\u201d to create AI tutoring prompts specific to the context of their students. The AI will first ask the instructor questions about the topic they would like students to focus on, key elements of the topic or idea, and any sticking points that students generally encounter.\nThe AI will then create a prompt that puts the AI in the role of tutor that helps students learn about their specific topic and gives it directions for how to interact with the student; for instance, ask students questions to pinpoint what they already know about the topic, and step by step instructions for helping students learn about the topic -giving students examples, asking them open ended questions, providing hints, and asking students to explain their thinking. The way this tutor \u201cbehaves\u201d and the context it is given about a topic are specific design choices that can be made by instructors when building their tutor. For any initial blueprint output however, instructors should test out the prompt and adjust it given their students, the specific topic, and the process the tutor undertakes to guide students. For instance, the instructor may need to add additional content knowledge to the prompt, or provide explicit directions about the topic, or add class- specific reminders or directions given what students already```json\nknow. Instructors can start with the blueprint output and tweak the prompt to that it is helpful to their students (see full prompt in Appendix B)"}, {"title": "Al Teaching Assistant Blueprint", "content": "Instructors can also create prompts that help them repeat a process or that help them take on tasks by co-designing an AI teaching assistant for a specific task. In this process, the AI asks the instructor a series of questions about the task they would like help with and outputs a code block for a prompt that creates an AI teaching assistant who specializes in a specific task. The output can be pasted into another chat window, can be made into a separate GPT or custom chatbot that instructors can use repeatedly and share with others. See full prompt in Appendix B."}, {"title": "Conclusions", "content": "This paper has explored the transformative potential of generative AI in education, presenting a framework for instructors to harness these tools to create innovative, personalized learning experiences. By enabling teachers to develop AI exercises tailored to their students' needs, this approach has the potential to democratize the development of educational technology and put instructors in the role of builders and creators. However, realizing the full potential of AI in education will require iteration and rigorous experimentation. The exercises presented here represent a preliminary proof- of-concept, highlighting the need for empirical studies to validate their efficacy and identify best practices for implementation. Future research should employ experimental designs to isolate the effects of specific AI interventions on learning outcomes.\nBeyond the role of instructors and researchers, platform providers need to recognize their impact on education. They should take into account potential transformative uses, and also ensure that low-cost and easy access to their tools are provided to students everywhere. Policymakers should emphasize the ways in which AI can help with the classroom experience but consider necessary regulation to protect against abuse of A\u0399 systems.\nAs the capabilities of generative AI advances, so, too, will the possibilities for pedagogical innovation. The framework and examples presented in this paper serve as a foundation for future exploration and adaptation. By empowering instructors as designers and innovators, we aim to catalyze a bottom-up, teacher-driven approach to educational AI that is responsive to the diverse needs of learners."}]}