{"title": "Instructors as Innovators: A future-focused approach to new AI learning opportunities, with prompts", "authors": ["Ethan Mollick", "Lilach Mollick"], "abstract": "This paper explores how instructors can leverage generative AI to create personalized learning experiences for students that transform teaching and learning. We present a range of AI-based exercises that enable novel forms of practice and application including simulations, mentoring, coaching, and co-creation. For each type of exercise, we provide prompts that instructors can customize, along with guidance on classroom implementation, assessment, and risks to consider. We also provide blueprints, prompts that help instructors create their own original prompts. Instructors can leverage their content and pedagogical expertise to design these experiences, putting them in the role of builders and innovators. We argue that this instructor-driven approach has the potential to democratize the development of educational technology by enabling individual instructors to create Al exercises and tools tailored to their students' needs. While the exercises in this paper are a starting point, not a definitive solutions, they demonstrate Al's potential to expand what is possible in teaching and learning.", "sections": [{"title": "Introduction", "content": "Widely accessible Large Language Models show considerable early promise as educational tools (Choi et al, 2023, Henkel et al, 2024). One of the potential benefits generative AI brings to education is the ability to democratize the creation of new tools for learning and teaching. Since they can be \u201cprogrammed\u201d through prompts alone, instructors can more easily become tool creators, enabling transformative uses of technology that are directed by instructors for their specific classroom needs.\nIn this paper we preview a future-focused approach to AI exercises for students that instructors can customize to suit their students, topics, and classrooms. Each of these exercises highlights a personalized learning activity \u2013 simulation, tutoring, mentoring, co-creation, etc. \u2013 that was difficult or expensive to implement prior to the advent of generative AI. Generative AI is unique among educational technologies because classroom applications can be built by individuals without extensive technology or coding experience. Relying on their domain and pedagogical expertise, and their knowledge of their students' specific needs, instructors can create exercises that can help their students learn. Further, instructors are uniquely positioned to assess how and whether these exercises help their students. This is innovation at the teacher and classroom level that does not require systemic action and that puts instructors in the position of builders and creators. And instructors are easily able take a pedagogy-first approach because their focus is not on the technology but on their students, their classroom, and their lessons. Given the varying time commitments and willingness to work with these systems, this approach allows instructors to use Generative AI in a voluntary way and at their discretion; instead of imposing a pre-built technological solution, instructors should be in control of the development of specific technological solutions suited to their classrooms.\nThe exercises we showcase are descriptive and not prescriptive. We attempt to show the capabilities of AI to extend or transform the classroom based on instructor knowledge."}, {"title": "", "content": "The exercises are demonstrations of what is possible with AI in pedagogy and not a final, tested solution. Extensive testing and customization by individual instructors is necessary for any custom chatbot or prompt given to students. Beyond the classroom, we need rigorous research into what works and when. The paper represents a starting point for exploring transformational use of these tools.\nThe paper is divided into four sections. In the first section we introduce the basics of using these prompts, including risks and approaches to customization. In the second, we highlight novel opportunities for pedagogy enabled by generative AI for students to apply their knowledge. AI can provide students with role-playing scenarios in which they can practice their skills and post-simulation advice on their performance. In the third section we highlight the capacity of the AI to act as a tutor and mentor, helping students connect concepts and gain a deeper understanding of class topics. For each exercise, students are required to engage extensively with the AI and reflect on the process. In the final section we focus on AI blueprint tools that can create tools for instructors to use. We also provide a series of blueprint tools that can help instructors create prompts for their students that instructors can then test and share.\nThe prompts in this paper, along with their variations, generally work for all \u201cGPT-4 class\" models\u00b9. At the time of this writing there are multiple GPT-4 class models available including GPT-4, Google's Gemini 1.5, and Anthropic's Claude 3 Opus. The first open source GPT-4 class models are expected in the summer of 2024. In every exercise, we leverage the core capabilities of these models, capabilities that open up new possibilities for teaching and learning including: interactivity, personalization, and a capacity to adapt and improvise. For every student exercise our goal is to activate hard thinking (Coe et al., 2020). We acknowledge the dual nature of AI in education: it offers students novel opportunities for personalized practice, yet it also poses the risk of dependency, as students might rely on AI to do the work for them, potentially leading to\""}, {"title": "", "content": "learning loss. We suggest methods that may help mitigate this risk, including how AI can be integrated into assignments.\nFor each prompt we share, we provide customization suggestions so that instructors can alter our prompts to suit their class. We also discuss possible classroom implementation and the benefits and risks inherent in deploying each exercise."}, {"title": "On \u201cProgramming\u201d Al Tools", "content": "The skills needed to create AI tools are already in the hands of instructors. Instructors can provide direction, break down tasks into sequential steps, gauge understanding"}, {"title": "Ethical and Pedagogical Concerns", "content": "Large Language Models have some advantages in terms of access compared to other technological tools. They can be accessed via phone, and do not generally require high speed internet access. Cost, however, can be an issue. While free access to Large Language Models is broadly available, access to the GPT-4 class models required to use the prompts in this paper is more limited. At the time of writing, Microsoft was the only organization providing access to GPT-4 class models for free (through Microsoft Copilot in Creative Mode). We urge other LLM providers to realize the importance of widespread and free educational access to AI.\nBeyond equity of access, there are other ethical concerns. While this paper focuses on the practical use of AI as a way to expand and transform the classroom, there are also wider implications to using AI that educators may want to consider before deciding whether to use these systems. Large Language Models are trained in ways that may violate copyright, and often rely on the efforts of low-wage workers in precarious conditions for part of their training. Models are trained on biased data and can produce either subtly or overtly biased results. And because these biases seem to come from an objective machine, they can be especially pernicious (Bender et. al, 2021). Using AI systems can mean sharing private data with the for-profit companies developing LLMs, and that data may be used to train further Als.\nInstructors, in consultation with their institutions, will need to reach decisions about the way they will address these risks. They may want to confront the potential biases and harms as part of their instructions, or to teach students to become better consumers of AI content. And, if they choose not to address these issues directly, they should ensure that AI literacy is being taught in other contexts for students to be exposed to this range of issues and risk factors.\nExercises in the paper can be combined with a critical AI discussion. Students may be asked to highlight and explore the AI's deficiencies, including its tendency to hallucinate"}, {"title": "", "content": "or its lack of depth in specific subject areas or topics. Because the AI provides a response that reasonably follows a given input (prompt) and those responses align with the patterns observed in vast amounts of online content (Wolfram, 2023) there are many misconceptions that the AI has trained on, and it can provide responses that are wrong. For instance, if prompted to describe best practices for learning, it may mention learning styles, an educational myth. The AI may insist on specific misconceptions or argue with the student. Students should be aware of the AI's tendency to hallucinate; they need to know enough about a given topic so that they are equipped to spot and refute hallucinations. The AI may also exhibit bias during the exercise. Additionally, students can be asked to examine when and to what extent they or the AI are steering the conversation. Many of these points \u2013 the AI's biases, hallucinations, and the tendency we have to \u201cfall asleep at the wheel\u201d (Dell'Acqua et al., 2023) while working with AI, extend well beyond these exercises-students should remain the \u201chuman in the loop\" at every point and critically assess AI outputs.\nFor every AI exercise, we outline both the potential benefits and risks for students. We urge instructors to carefully consider the downsides and rewards of using these tools depending on their context and settings."}, {"title": "Al Opportunities for Practice and Application", "content": "Learning through Simulations\nFrom pilots to physicians, truck drivers to athletes, those who spend time rehearsing in a simulated environment can identify errors and learn from their mistakes (Edmondson, 2023). Simulations are an effective way for students to rehearse or practice what they have learned in a low-stakes context (Edery & Mollick, 2008). Simulated scenarios create a controlled space for practice; learners can explore, make mistakes, and gain valuable insights without fear of failure (Edmondson, 2023). And simulations can reinforce previously learned knowledge and give students a chance to apply that knowledge, practicing valuable skills rarely encountered in the real world.\nPedagogical approach\nSimulated practice can help students practice skills but traditional educational simulations are hard to build and demand numerous resources (we have been building them ourselves for over a decade!). In contrast, AI-based scenarios are easier to design and deploy and they can be tailored to a specific set of learning goals. Below are simulation exercises that instructors can assign to students: role play, in which the student assumes the identity of someone else in a scenario or goal play in which the student maintains their identity and applies their knowledge and skills in guiding others (a simulated character or set of characters).\nBuilding simulations with Al\nWhen carefully prompted, the AI can quickly create adaptive simulations in which individual students can play a role, interact with character(s) (played by the AI), and practice key skills. AI can quickly and easily develop multiple scenarios in which students can draw on previously learned knowledge to solve or attempt to solve new problems. The AI's ability to set up a compelling scenario, give the student meaningful choices, wrap up the scenario, and summarize what the student did well (and less well) means that each student can practice a key skill at any point. Note that for any of these"}, {"title": "", "content": "exercises to be effective students must have an understanding of the topic so that they can apply their knowledge; each simulation should also be followed up by an in-class discussion or debrief."}, {"title": "Simulation Type 1: Role Play", "content": "Simulations can be designed so that students take on a role different from who they are in real life (for instance, the student in a negotiation class takes on the role of a seller in a high-stakes negotiation, or the student in an entrepreneurship class takes on the role of startup founder as they pitch their business idea). Students must apply the strategies learned in class to succeed.\nRole playing also has the added advantage of allowing students to move outside their comfort zone and experiment as they play the role \u2013 perhaps they are more assertive than they would be in a real world situation or maybe they take a risk they wouldn't take in real life \u2013 the simulation itself gives them a chance to experiment with different versions of themselves. Stepping into a role also gives students a chance to experience the topic, problem, or framework in a narrative-driven and personally engaging way, and as they role play, they quickly learn their strengths and weaknesses.\nPrompting for Role Play\nAn AI role-play simulation prompt has several components:\nIntroduction to AI-Mentor. The student is first introduced to an AI Mentor who establishes a supportive context and sets the stage for the experience. The AI Mentor elicits information, asking the student about their experience level to help the AI customize the experience. For instance, in the prompt below, the AI asks about the level of student experience in a negotiation so that it can set up a straightforward or more complex scenario depending on the student's previous experience. Note that this is one question that the AI can ask; depending on the topic and learning goal, individual instructors may customize the initial set of questions. The key: give the AI \u201cinsight\u201d"}, {"title": "", "content": "about the student's knowledge and prior experience so that it can effectively tailor the scenario.\nScenario Suggestions. The AI Mentor then offers students a choice among varied scenarios, giving students agency. Note that the more the student shares with the AI the more personalized the scenarios may be. For instance, a student that shares \u201cI have some experience negotiating\u201d will be given a choice of standard scenarios, but a student that shares additional context \u201cI am a medical student and I have some experience negotiating\" will receive scenarios tailored to their interests and background.\nNarrative Set Up and Play. The AI then sets the scene, provides objectives to guide the student's actions, and helps the student navigate the scenario. Every time a student responds during role play their response changes the story. In many cases, the AI gives students hints about what to focus on and what to do next as the scenario progresses. In our scenario prompts, we limit the number of interactions within any scenario so that the AI stays on track, and we prompt the AI to push the student to make a consequential decision to close out the scenario.\nFollow-Up Advice. The AI Mentor then gives the student advice based on their performance in the scenario, helping students reflect on their approach. The AI Mentor will often reiterate the learning goals of the simulation and the strategies the student applied (or didn't apply) effectively.\nThe prompt is structured so that the student understands the goal of the simulation, is then immersed in the simulation, and finally zooms out to consider how well they did. Below you'll find customization suggestions for an example role play prompt focused on negotiations. All prompts can be found in Appendix A."}, {"title": "Simulation Type 2: Goal Play", "content": "Goal play simulations involve students playing themselves, often guiding a character in a scenario, to achieve goals or apply specific frameworks. For instance, the student's goal might be to apply decision-making techniques discussed in class. In one scenario, they might be tasked with helping a fictional character make decisions. The student, playing themselves, would need to interact with that character and help them apply effective decision-making frameworks. The student might help that character assess alternatives, weigh the pros and cons of different actions, and encourage the character to make well-informed decisions. In this case, the student would adapt to the context but \u201cplay\u201d themselves in the scenario, incorporating the framework they learned in class.\nImportantly, in a goal play scenario the AI sets up a scenario in which the student knows something the character in the simulation does not and guides the character using what they know, generally a framework. In one of the examples below students must apply a goal setting framework to help a fictional character set goals and in the other the student must apply self-distancing techniques to help a fictional character problem solve and change how they think about an experience (Kross, 2020).\nPrompting for Goal Play\nA goal-play simulation prompt has several components:\nA Dual Role for the AI. The AI plays the AI Mentor and crafts the scenario and may also give students directions after the scenario or reference an upcoming class discussion. The AI also plays a character within the simulated scenario.\nScenario Choices. The AI Mentor offers students a choice among scenarios (e.g., literary characters or historical figures) to apply the framework. Students can choose a scenario that piques their interest.\nNarrative Set-Up. The AI sets the stage for the scenario and is instructed not to overcomplicate or overwhelm students with too much complexity, prompting students to focus on the topic or framework rather than focusing only on the details of the"}, {"title": "", "content": "scenario. This is important because the goal is for students to focus on the lesson and not the concrete details of the scenario alone.\nScenario Initiation. The AI is instructed to clearly mark the beginning of the interactive part of the simulation sending a signal to students \u2013 they are now in a scene and applying what they know to a new situation.\nGuidance on Goal and Techniques. The AI Mentor may step into the scenario and remind students of their goals or give them hints. Note however that the AI Mentor does not interfere during the scenario, giving the student autonomy to apply lessons learned.\nEnd of Scenario and Advice. The AI Mentor steps back onto the scene and can offer students advice. Depending on its instructions, the AI can reinforce key elements of the topic or framework and identify more for the student to consider.\nExamples of a Goal Play Prompt\nBelow you'll find two examples of goal-play simulation prompts as well as customization tips for each. Depending on the content and specific skill, prompts should be thoroughly tested before assigning them to students. Note that each play-through of any exercise will vary from any other play-through; expect a variety of student experiences in using these exercises \u2013 yet another reason a sound knowledge base pre play and an in-class debrief are important.\nIn the prompts below (full prompts in Appendix A) the student helps a fictional character set goals and gain perspective through self-distancing techniques."}, {"title": "Simulations: Classroom Implementation", "content": "Deployment\nThere are several ways to incorporate AI simulations into a class. Depending on the simulation, you may be fine with students viewing the AI instructions or you might prefer to send students a custom chatbot (a GPT) with so that the AI instructions themselves don't \u201cgive away the game.\"\nTo deploy, you can have students play through the simulation in class and then have a class discussion. Alternatively, you can assign the simulation as homework and have students hand in both the played through conversation (via links) and a reflection paper that asks students to answer a number of questions based on their experience. It's important to note that as AI output is variable, students will have different experiences as they play through their scenarios.\nGrading and Assessment\nIdeally, simulated experiences should give students an opportunity to practice skills they are already familiar with. While instructors can experiment with trial-and-error approaches (having students \u201cfail\u201d at the task and then unpack that failure in class as a way to introduce a new topic) there is danger that students will learn the wrong thing or get frustrated. In class, you can explore where the AI was successful and where it failed, using a few examples shared by students, focusing on how the example scenario highlighted (or failed to highlight) class materials. Students should be asked: What happened? What did you do? How did the simulation end? What would you do differently next time and why? And they should also interrogate the AI's output. You can ask: For a role-playing simulation, to what extent was the scenario realistic? Did the simulation play out? Did the AI get stuck in a loop? Did you detect bias in the scenario or interaction? The key is for students to apply ideas or frameworks they"}, {"title": "Risks", "content": "AI simulations present a variety of risks. While they can personalize a simulation and adapt and improvise depending on student responses, they do not always tie the lesson to the scenario or provide solid advice. They also do not always follow directions and instructors should expect that students will have different experiences in interacting with the AI. If the specific lesson or subject calls for tight scripting (if, for instance, a lesson calls for a specific exchange during a team conversation and that dynamic should surface, every time) then the AI approach may not be right for this specific topic. Instructors can however experiment with giving the AI specific instructions about role, character, dialogue, challenges, and scenarios. Our prompts allow the AI to guide the scenario, but it is worth testing to learn how very specific instructions that give the AI less leeway to steer the scenario may work.\nThe strength of AI in crafting simulations, its dynamic ability to adapt and tailor scenarios to individual students, can also be its weakness. While AI often excels at following instructions and adjusting to student choices with the lesson in mind, it can sometimes falter. Its interpretation of instructions and execution of scenarios can also vary significantly between different AI models. For example, Gemini tends to take literary liberties, occasionally overriding instructions to pursue what it considers useful scenarios or inviting students to suggest their own (this may or may not detract from the experience). This capacity to vary output offers a powerful, personalized learning experience, but it comes with risks: each student's experience becomes highly individualized, which may lead to confusion if the AI's narrative strays from the intended lesson or lacks cohesion. Scenes and characters generated by the AI can also vary in difficulty; some students may be presented with challenges that are too difficult and others may encounter a problem that is relatively straightforward, given the same set up. Instructors should experiment with simulation prompts in their subject matter to better understand how the models react to their instructions. As with any AI exercise, instructor involvement, feedback, and oversight are critical."}, {"title": "Learning through Critique", "content": "Pedagogical Approach\nTeaching someone else can help you learn. Students who teach others engage deeply in the material and can gain insights into the gaps in their knowledge, as they monitor their own understanding (Kirschner & Hendrick, 2020). Known as the prot\u00e9g\u00e9 effect\" students who teach others develop higher comprehension and a deeper, more persistent understanding of the material (Fiorella & Mayer, 2013). This is in part because to teach someone else requires that the teacher organize what they know so that they can explain it to someone else, adapt to the student and improvise \u2013 answering questions and making decisions during the lesson (Roscoe & Chi, 2007). The act of structuring their own knowledge ahead of and during teaching is an ongoing and open-ended problem-solving activity (Biswas et al., 2005). Incorporating teaching opportunities for students can be an effective way to promote deeper learning and understanding of specific topics or ideas.\nBuilding Opportunities for Critique\nAI can provide students with multiple \u201cpeers\u201d or \u201cnovice student\u201d teaching opportunities. It can act as scenario creator, quickly generating example scenarios that illustrate an idea or a framework. Students can then be tasked with explaining how (and if) the examples illustrate the idea or framework. The AI can also act as the student for any topic, prompting students to explain ideas to help the \u201cAI student\u201d understand class material. With careful prompting the AI can \u201cact\u201d as a novice about a topic, asking questions that challenge the student-teacher to organize their knowledge. There may be a number of benefits to this approach: students can work with multiple AI \u201cpeers\u201d or \u201cstudents\u201d and unlike in a peer teaching exercise, there is no risk of that AI student learning incorrect information even if the student-teacher makes an error; additionally, instructors can view a comprehensive \"teaching log\" of the conversation, as students can provide a link to the entire AI interaction."}, {"title": "Critiquing Type 1: Critiquing an Al-generated Scenario", "content": "A key aspect of expertise is the ability to abstract out key elements of a concept and recognize those elements in a new situation; experts can recognize the deep structure of a problem rather than focus on its surface elements (Willingham, 2002). In this exercise, we use the AI's strengths (its ability to quickly craft scenarios) and its imperfections (its tendency to hallucinate or make mistakes or anchor on one particular aspect of a concept to the exclusion of others) as a way to challenge student understanding of course concepts. Students who have already learned about a topic, can be prompted to focus on the specific details of an AI-generated scenario and determine how (and if) the scenario demonstrated the underlying elements of a concept. To answer the question: Did the AI apply this concept correctly? the student must draw on deep knowledge of the elements of that concept (Gentner et al., 1993). The exercise can give students the opportunity to practice recognizing the deeper elements of course concepts.\nPrompting for Critiquing a Scenario\nIn this exercise the AI provides the student with a scenario in which it applies or illustrates a concept. The AI initiates a dialogue with the student and gives the student a choice of topic and a series of scenarios to choose from. The student picks a scenario type, and the AI then illustrates the topic or concept via the scenario the student picked out. The student is then asked to review the scenario explain how (and whether) the AI's output illustrates the concept. Because the AI can make mistakes, provide incomplete illustrations, and miss the mark in exploring the complexity of any concept, students may then ask the AI to rewrite the scenario, giving specific instructions for a revision. In correcting the AI, they get a chance to practice articulating what they know."}, {"title": "Critiquing Type 2: Al as Student", "content": "In the Teach the AI exercise (full prompt in Appendix A) we prompt the AI to take on the role of a novice student and ask questions of the teacher. To give the student a sense of agency and signal early on that the student should take the lead in the scenario, we ask the student choose the AI student persona they will teach. The student then takes on the role of teacher and explains a concept to the AI student who proceeds to follow up and ask questions throughout the conversation.\nWe also specify pedagogical principles we explicitly tell the AI what kinds of questions it might ask and how to \u201ctalk\u201d to the student-teacher in order to draw them out; we instruct the AI to ask open-ended questions to challenge students to reconsider and reorganize what they know through the act of explanation (Coe et al., 2020). At the end of the exercise, the AI (as Mentor) asks students to review the exercise and consider what question they might ask their AI \u201cstudent\u201d to check for understanding \u2013 challenging the student to reflect on their teaching and on the elements of the topic."}, {"title": "Critique: Classroom implementation & deployment", "content": "Ahead of the exercise, instructors can ask students to prepare to teach \u2013 that is, instructors can direct students in class to spend some time preparing what and how they plan to teach their AI student; preparation alone can help deepen their understanding of the topic (Roscoe & Chi, 2007). Then instructors can send students the exercise (via a"}, {"title": "Grading and Assessment", "content": "Instructors can ask students to report out their interactions: which \u201cstudent\u201d did they choose to teach? What questions did the AI ask? To what extent did students think the AI realistically portrayed a novice? Did the AI ask a question that you weren't sure how to answer? What question did you suggest asking the AI student to check for understanding? Students can also share a link to their interactions so that instructors can take a look at student explanations and note any gaps or sticking points in student understanding. Additionally, students can be asked to note any bias in AI responses and any specific hallucinations they spotted during the interactions.\nStudents should report out the entire interaction and write a paragraph reflecting about the experience. That reflection can also serve as a basis for a class discussion that serves a dual purpose: a discussion about the topic or concept and about how to work with the \u0391\u0399."}, {"title": "Risks", "content": "While the risks of teaching an AI student are low, there are some elements of the exercise to watch out for. The AI may get off track. That is, if a student teaches the AI about a topic and the AI is \u201cinterested\u201d in a particular aspect of the topic, it may keep pushing on this aspect and ignore other aspects of the topic and get off track. It's important to remind students that they are driving this conversation. If the AI asks an irrelevant question or continues to pursue a particular point, they can redirect the AI: \"let's get back on track and consider [the topic].\" Similarly, the AI can only roleplay a novice up to a point and the roleplay is not particularly realistic. While it does often ask interesting and challenging questions, the exercise does not mirror an actual teaching exercise in the classroom. As with any AI exercise assigned to students, expect variable responses from the AI. Students will have different experiences to share in class about this interaction."}, {"title": "Learning through Co-Creation", "content": "Pedagogical Approach\nThe act of breaking down your knowledge into sequential step by step instructions to explain something someone else helps you learn, and highlights gaps or inconsistencies in your own knowledge. For students this process may break the illusion of expertise (Glenberg, 1982): can you create something (in this case an explanation) for someone else? (Lombrozo, 2006). This act requires that you step into the shoes of another person and build something that is useful to them giving them examples that highlight aspects of a concept and a process through which they can surface the complexities of the concept.\nCo-Creation with Al\nAI's ability to quickly ask questions and adapt to a given circumstance can make it a partner in a co-creation process. Its capacity to interact and suggest solutions or paths forward can challenge students to both articulate their ideas clearly and consider alternatives. The push and pull of the dynamic can be productive as students apply their own expertise to push the AI to produce something ambitious as they pair their expertise with the AI's capacity to dynamically build and iterate. In addition, co-creating with an AI highlights the role that AI can take beyond the specific exercise a copilot for students in their area of expertise; students can lead and drive the interaction and assess the final output.\nCo-Create a Case\nIn this exercise, students co-create a lightweight case with the help of the AI and their goal is to help create a case that a peer could work through. To begin the exercise, the AI asks the student a series of questions about the topic and asks the student to choose a scenario for the specific topic. The AI then creates the case based on student advice and"}, {"title": "", "content": "input; the student is challenged to think through the elements of the topic because they need to explain those elements to the AI. Once the case is written, the student is then asked to consider the case in terms of the topic \u2013 does the case need to be adjusted? Does it highlight the key aspects of the topic? How might a peer analyze and react to this case? In answering these questions, the student compares the example created by the AI (the case) and their understanding of the topic and should make suggestions for any case adjustments. This exercise draws on student knowledge of a topic, asks the student to reframe the topic so that it can be useful for someone else, and asks the student to critique the work of the AI."}, {"title": "Classroom implementation", "content": "Deployment\nThis exercise is designed for students who have knowledge of a topic. It represents a practice opportunity \u2013 students must articulate ideas, come up with examples, and assess the AI's work. Topics or concepts that work best with this type of exercise are rich in detail and benefit from discussion, analysis, and evaluation. Note: instructors can remind students that they should work with the AI conversationally, asking it to redo work or add to previous work to improve its initial case output, challenging students to add their expertise to the mix.\nGrading and Assessment\nInstructors can highlight that the goal is for the student to co-create a case that explores a major aspect of a topic and that students should actively inform the AI about the topic, giving it step-by-step explanations and clarifying concepts; they should also critique the AI's output and give it input and information to improve its initial case output. The quality of the initial case the AI will output is likely to be fairly surface-level and students need to work with the AI to give it more context and advice to improve the case. Once final cases are developed, instructors can establish a peer review process where students exchange their cases. Peers then analyze and work through the cases, offering solutions or recommendations and assessing the quality of each case.\nRisks\nAs with any AI output, there may be a significant variance in how well the AI leads the student initially (in gathering information for the case). Additionally, the initial case outputs may vary widely, giving some students fairly refined cases as a starting point, and others far less structured versions that require significant work to improve. This type of exercise should be also preceded by instruction about the topic followed up with feedback, otherwise there is a risk of solidifying errors or misunderstandings."}, {"title": "Mentoring, Coaching, and Tutoring", "content": "Pedagogical Approach\nExtensive evidence supports tutoring as an effective intervention (Chi et al., 2001; Dietrichson et al., 2017; VanLehn, 2011). While questions remain about optimal tutoring strategies, evidence suggests that effective tutors are persistent and interactive; they don't dominate the conversation and instead encourage students to generate responses and explain what they know in their own words (VanLehn, 2011). During any lesson or tutoring session, tutors can begin by stating the goal of the session, work to assess the students' prior knowledge, present material in small steps, provide varied examples, offer feedback, and scaffold students with the goal of withdrawing that scaffolding as the student improves (Chi et al., 2001). A tutoring session can provide students with additional instructional time and personalized learning. During one-on-one or small group sessions, tutors can revise their strategies as they react to student responses and students can ask considerably more questions than they do in classroom settings (McArthur et al., 1990). Additionally, tutors can prompt students to reflect or monitor their own knowledge, helping students gain deeper understanding of the material. While tutoring can be immensely effective, it is a complex task that relies on improvisation, adaptivity, interactivity, and pedagogical and domain-specific knowledge. And it is an expensive, time intensive intervention that requires resources and planning; despite evidence of its usefulness, tutoring is available to few students (Chi et al., 2008).\nBuilding Opportunities for Mentoring and Coaching\nGenerative AI models are not built to teach. If asked for an explanation of any topic, the AI will provide one, but that explanation may not be adapted to the specific student and crucially, reading an explanation does not lead to deep understanding. However, if carefully prompted and with instructor oversight Generative AI can play the role of tutor, interacting with the student via open-ended questions, checking on prior"}, {"title": "", "content": "knowledge, providing multiple examples, and challenging students to generate their own knowledge. This type of prompting uses the AI's capacity to role play and adapt to specific instructions.\nBecause the AI it can be prompted to \u201cact\u201d like a tutor, it can be instructed to draw the student out in conversation and focus their attention to specific known sticking points or misconceptions of a topic. Instructors, with expertise in teaching a specific topic can customize tutors for specific use cases or topics and prompt those tutors to guide students. As in all cases of students working with AI, there are inherent risks in the process, and we explore some of these below. One persistent issue has to do with topic specificity and what the AI \u201cknows\u201d. The AI \u201cknows\u201d more about some topics than others and may hold misconceptions which are only uncovered through use. Tutoring prompts must be tested within a specific topic or domain and by an expert (instructor) who can customize the prompt to move the AI away from its standard responses and guide the AI towards a more nuanced approach.\nWhile there are many types of AI tutors that can be implemented, below we'll discuss 3 different types: reflection mentors that ask students to reflect on an experience, integration agents that ask students to connect topics, and general purpose tutors that can be customized for a specific topic."}, {"title": "Mentoring and Coaching Type 1: Reflection Coaching", "content": "Prompting for Reflection\nReflection plays a crucial role in learning by giving students an opportunity to revisit, analyze and make sense of their experiences. Researchers note that reflection, when combined with feedback, can improve student performance. (Anseel et al., 2009) When facilitated through writing (journaling or storytelling) reflection can help students make connections between what they know and new information. Reflection can help students return to the experience and re-evaluate it (Herrington, 2002). Reflection becomes particularly important when students engage with complex bodies of knowledge, as the"}, {"title": "", "content": "process allows them to establish connections as they take time organize information independently (Bangert-Drowns, 2004).\nWhile looking back on past experiences is important, prospective thinking, or drawing on past experiences to simulate potential future scenarios, can help students navigate the future (Seligman et al., 2013). The process can prompt students to extract relevant information from their past experience and reconstruct that information to inform future decision-making (Seligman et al., 2013)."}]}