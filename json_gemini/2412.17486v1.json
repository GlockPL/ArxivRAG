{"title": "Is ChatGPT Massively Used by Students Nowadays? A Survey on the Use of Large Language Models such as ChatGPT in Educational Settings", "authors": ["J\u00e9r\u00e9mie Sublime", "Ilaria Renna"], "abstract": "The rapid adoption of Generative AI (GenAI) based on Large Language Models (LLMs) such as ChatGPT has recently and profoundly impacted education, offering transformative opportunities while raising significant concerns. In this study we present the results of a survey that investigates how 395 students aged 13 to 25 years old in France and Italy integrate LLMs into their educational routines. Key findings include the widespread use of these tools across all age groups and disciplines, with older students and male students demonstrating higher usage frequencies, particularly in scientific contexts. The results also show gender disparities, raising concerns about an emerging AI literacy and technological gender gap. Additionally, while most students utilise LLMs constructively, the lack of systematic proofreading and critical evaluation among younger users suggests potential risks to cognitive skills development, including critical thinking and foundational knowledge. The survey results underscore the need for educational institutions to adapt their curricula to integrate AI tools effectively, promoting ethical use, critical thinking, and awareness of AI limitations and environmental costs. This paper provides actionable recommendations for fostering equitable and effective cohabitation of LLMs and education while addressing emerging challenges.", "sections": [{"title": "1 Introduction", "content": "Few inventions and innovations have genuinely transformed education at large, particularly by enhancing access to knowledge. Notable among these are the advent of writing around 3300 BCE, which facilitated the transmission of knowledge across generations and cultures; the Gutenberg printing press in approximately 1440 CE, which greatly simplified the duplication and dissemination of ideas and knowledge, thereby encouraging wider literacy and education; the large-scale deployment of the World Wide Web in the late 1990s and early 2000s, which allowed for rapid, affordable, and accessible information sharing via the Internet, especially through online encyclopedias such as Wikipedia; and, more recently, the public emergence of Large Language Models (LLMs) [1] in 2022, such as ChatGPT (Chat Generative Pre-Trained Transformer) [2], which have made information access even more straightforward.\nHowever, LLMs differ from previous inventions that facilitated the spread of information and knowledge in several key ways [3, 4]. While writing, the printing press, and the Internet primarily made information more accessible, LLMs provide an array of additional functions, such as multi-language translation, summarisation, simplification of complex information, and advanced writing capabilities to structure and organise content. In other words, LLMS assist people not only with accessing information but also with tasks traditionally considered cognitive. Consequently, these models may also be likened to inventions that support cognitive processes, such as calculators and computers, which are far more efficient than humans in computation and have significantly reduced the need for mental arithmetic resulting, as a side effect, in a decline in our capacity for mental mathematics.\nWhether we welcome them or not, LLMs have arrived and they are here to stay. It is however important to understand how they can be exploited in a positive way while minimizing negative impacts. Their impact on industry, particularly within the research and innovation sectors, is already evident and largely positive. When humans and AI collaborate, the gains in productivity and efficiency are substantial and hard to dispute [5].\nWhile we may marvel at the productive outcomes of human and LLMs collaboration in business, it is perhaps worth questioning its impact on the education sector. Indeed, although delegating cognitive tasks to AI may pose little issue for trained adults in a professional work setting, the reliance of young learners on AI for key tasks\u2014such as critical thinking, summarisation, and even basic logic- should raise some concern. LLMs, and particularly ChatGPT, are widely used by all demographics, including children and young adults, who, according to educational professionals, are substantial users of these tools in schools and universities. On one hand, controlled and guided use of LLMs for educational purposes could significantly enhance learning by enabling customised programs and teaching AI assistants [6\u20138] and could"}, {"title": "2 State of the art", "content": "The 21st century is often regarded as the era of technology, which plays a vital role in economic growth and efficiency. In education, technology has transformed how students learn, making education more interactive, efficient, and accessible. Modern tools like the internet have significantly enhanced learning by providing continuous connectivity, access to tutorials, and interactive visual aids. Students can now easily find educational resources online, which improves their understanding and engagement. The integration of digital media has further revolutionized the education sector,"}, {"title": "2.1 New Technologies and Education", "content": "As underlined by Raja and Nagasubramani [15], Information and communications technologies (ICT) play a vital role in education in four key ways: as an integral part of the curriculum, as a tool for instructional delivery, as a means of supporting teaching, and as a tool to enhance the overall learning experience. Thanks to technological advancements, education has shifted from being passive and reactive to interactive and engaging [16\u201318]. In both corporate and academic environments, education serves different purposes: training employees to improve performance in the workplace, and fostering curiosity and critical thinking in students. In both contexts, technology helps learners grasp and retain concepts more effectively. In this context, teachers face lots of challenges due to the rapid expansion of knowledge and the increasing role of technology in education. In fact, they are required to adapt to new technologies, which intensifies their training needs. Gressard and Loyd [19] emphasize that teachers' attitude toward computers is crucial for successful ICT integration, noting that negative attitudes can hinder the success of computer-based initiatives. Common barriers to technology adoption include lack of time, access, resources, expertise, and support. Additionally, reliability issues such as hardware failures, incompatible software, slow internet connectivity, and outdated software at schools, compared to more up-to-date software at home, also pose challenges, as noted by Butler and Sellbom [20] and Chizmar and Williams [21].\nAccording to Tinio [22], ICT significantly impacts the acquisition and absorption of knowledge for both teachers and students by promoting various learning approaches such as \u201cactive learning\u201d, \u201ccollaborative learning\u201d, \u201ccreative learning\u201d, \u201cintegrative learning\" and \"evaluative learning\". Overall, ICT enhances the learning experience by fostering engagement, collaboration, creativity, and critical thinking. All this led to both positive and negative aspects. On the one hand, technology in education enables a more exciting and engaging learning experience for students; it provides flexibility for those with busy schedules, allowing them to work at their own pace and from home; additionally, it helps students develop valuable technology skills that will benefit them in the workplace and it reduces the need for paper and photocopying, contributing to environmental sustainability. On the other hand, there are also some disadvantages to take into account: for instance, some experts argue that the widespread use of technology in education can hinder students' imagination [23], and reduce their critical thinking abilities [24]. Furthermore, some critics highlight the adverse health effects associated with prolonged screen use. Indeed, various studies have shown that excessive screen time and media multitasking can negatively impact executive functioning, sensorimotor development, and academic performance [25, 26]. Furthermore, from the teacher's perspective, integrating technology can be time consuming and can lead to difficulties in evaluating the actual improvement in students' knowledge."}, {"title": "2.2 Large Language Models", "content": "Language modeling has been a well-established field of research since the 1950s, when C.E. Shannon first applied information theory to human language [30]. Shannon's groundbreaking work introduced the idea of using statistical models to predict and compress natural language text, laying the foundation for the first wave of language modeling with n-gram models. Over the years, the field has progressed through four distinct waves [1], each making significant contributions to the development of modern Natural Language Processing (NLP) systems: Statistical Language Models (SLMs), Neural Language Models (NLMs), Pre-trained Language Models (PLMs) and Large Language Models (LLMs). SLMs [31] modeled text as a sequence of words, predicting each word's probability based on previous ones. N-gram models, using Markov chains, were commonly used in various NLP tasks but faced issues with data sparsity and required smoothing techniques for unseen words or sequences [32]. NLMs addressed the limitations of SLMs by mapping words into low-dimensional continuous vector spaces, known as word embeddings: neural networks were used to predict the next word in a sequence by aggregating the embeddings of preceding words; this innovation alleviated data sparsity issues also allowing for the computation of semantic similarity between different linguistic inputs [33]. However, early NLMs were primarily task-specific, limiting their general applicability. Conversely, PLMs are task-agnostic; they (as BERT [34] and GPT [35]) introduced a paradigm shift through the pre-training and fine-tuning process where language models, based on recurrent neural networks or transformers, are pre-trained on large, unlabeled text corpora for general tasks like word prediction, and then fine-tuned on small, labeled datasets for specific tasks [36]. LLMs, exemplified by models like LLaMA [37], Mixtral [38], Gemma[39], Qwen2 [40], PaLM[41] and GPT-4 [42], are transformer-based models, containing billions of parameters, which are trained on vast text corpora and exhibit advanced language understanding and generation capabilities; LLMs demonstrate emergent abilities such as in-context learning (being capable of any downstream tasks without any gradient update or fine-tuning), instruction following, and multi-step reasoning, which were"}, {"title": "2.3 ChatGPT and Education", "content": "Considering the context outlined in SubSection 2.1 and given the rapid surge of LLMS, as discussed in 2.2, as well as their widespread adoption by the general public, particularly exemplified by ChatGPT, it is natural to ask how these tools might transform the way people learn and what their short- and long-term impacts could be in the learning processes and in education more generally.\nOn one hand, these tools could be seen as helpful [44\u201346], also for supporting students with difficulties [9, 10]. On the other hand, there is a concern that students might rely on them to solve any type of school task, drastically undermining their learning process [47, 48] and the potential of false information as well as compromised academic integrity [49]. These are some concerns [50\u201352] that have been investigated in recent researcher works.\nThe review of [53] on 14 selected empirical studies on ChatGPT from students and teachers points of views underline these two opposite sides: on the positive one, ChatGPT significantly supported the learning process in various ways; learners utilized it as a virtual intelligent assistant, benefiting from immediate feedback, on-demand answers, and easy access to educational resources. It was particularly effective in improving writing and language skills, helping learners generate ideas, compose essays, summarize, translate, paraphrase texts, and check grammar. Additionally, ChatGPT facilitated personalized and directed learning, assisting with understanding concepts, completing homework, creating structured learning plans, and clarifying assignments. Educators also found ChatGPT valuable for boosting productivity and"}, {"title": "3 Material and Methods", "content": "In this section, we begin by describing the main characteristics of our respondents population, the content of our survey. Then, we present the statistical tools that we will use in Section 4 to interpret the survey results and draw our conclusions."}, {"title": "3.1 Survey content", "content": "Our Google Form survey was distributed to professors and heads of institutions to facilitate its administration directly in classrooms via a one page document in which the general aim of the survey was presented. This document featured a QR code link to the survey's form webpage, enabling respondents to complete it using their mobile phones as well as a direct link for those who preferred to respond via a personal computer or laptop. We included a statement about the complete anonymity of the results, and the guaranty of processing the answers in a global way and not individually in accordance with the General Data Protection Regulation\u00b9. For students under the age of 16 and requiring parental authorization before participating, a one-page document was provided to their parents outlining the survey's objectives and including essential legal information, such as the EU GDPR notice. Professors responsible for administering the survey during class time were instructed to read the one-page document aloud and display it (for instance using a projector) to let the students access the questions with the QR code or the link.\nThe survey itself comprised the following question items:\n1. How old are you?\n2. How do you identify yourself? With the possibility of skipping the question, or entering an alternative gender other than male or female.\n3. Have you used ChatGPT (or an equivalent program) at least once during the course of your studies or in an academic context ? [Yes \u2014 No]. In case of a negative answer, the survey skipped to Item 8.\n4. A set of 4 questions detailing their use of ChatGPT for humanity related topics (literature, history, geography, social sciences, foreign languages, law, redaction, etc.):\n\u2022 Have you ever used ChatGPT for a \u201chumanities\u201d topic ? [Never At least once A few times Often].\n\u2022 What did you think of the results? [Does not apply. I did not use it It was very bad It was mediocre It was quite good It was very good].\n\u2022 If you used it, did you rework the answers provided by ChatGPT? [Does not apply. I did not use it No, never Yes, sometimes Yes, always].\n\u2022 For which of the following \u201chumanities\u201d topics or purpose did you use ChatGPT? Check all that apply. For this question, we listed a list of common humanity fields and left the possibility of adding some.\n5. A set of 4 questions detailing their use of ChatGPT for scientific related topics (mathematics, physics, chemistry, biology, computer science etc.):"}, {"title": "3.2 Respondents demographics", "content": "Our survey targeted students aged 13 to 25 years old. It was conducted in France and Italy, where various high schools and higher education institutions agreed to allow some of their classes to participate in our study. Unlike previous surveys conducted online without supervision [59\u201361], ours was administered during class time under the supervision of a professor. Moreover differently from Stojanov et al. [56] and Qu et al. [58] responders were volunteers and they not perceived any kind of financial reward. This approach also enabled us to collect data from younger age groups compared to other studies.\nThe survey was conducted between May 2024 and October 2024, yielding a total of 395 responses. The distribution of respondents by age and gender is presented in Table 1.\nFor presentation purposes, we categorised respondents into age groups corresponding approximately to secondary school (13 to 16 years), high school (17 to 19 years), undergraduate studies (20 to 22 years), and graduate studies (23 years and older).\nGiven the young age of some respondents and the international composition of undergraduate and graduate student populations, different versions of the survey were provided in English, French, and Italian. This approach ensured that all respondents could complete the survey in a language they were proficient in."}, {"title": "3.3 Statistical tools used to interpret the answers", "content": "To analyse and interpret the results of our survey, we will use standard visualisations such as bar plots, histograms and pie charts, as well as statistical tools such as chi-squared test analysis and confidence intervals.\nFor completeness, we remind readers that the chi-squared test is a statistical hypothesis test commonly employed to analyse contingency tables. Its primary objective is to assess whether a significant association exists between categorical variables. Specifically, it evaluates whether a statistically significant difference is present between"}, {"title": "4 Survey answers analysis", "content": "For a better understanding of this section, we first remark that the number of respondents may vary from one table to another depending on the different sub-studies. The reasons are the following:\n\u2022 10 respondents did not specify their gender and have been discarded from the parts focusing on gender differences;"}, {"title": "4.1 Age trends analysis", "content": "In this subsection, we analyse the results of our survey, focusing on potential differences in the academic use of ChatGPT and other LLMs across the age groups of our respondents. As a reminder, the overall age distribution is provided in Table 1.\nThe first notable finding from our study is the widespread use of ChatGPT and LLMs in academia, as reported by students. As illustrated in Figure 1 derived from Table 1, even among the youngest respondents, aged 13 to 16, nearly 70% indicated that they had used such tools at least once in an educational context. Secondary school students stand out in particular, accounting for 71% of the chi-squared value, with a p-value below 10-7.\nAmong other age groups, the use of ChatGPT increases significantly, ranging from 89.7% to 95.4%, with students aged 20 to 22 emerging as the most active users."}, {"title": "4.2 Gender trends analysis", "content": "In this subsection, we analyse the results of our survey, focusing on potential differences in the academic use of ChatGPT and other LLMs by gender. As a reminder, the gender distribution is presented in Table 1. Note that due to the low number of respondents in these categories, we excluded the 10 students who either did not answer the gender question or identified as other than male or female."}, {"title": "4.3 Science topics vs Humanity topics analysis", "content": "In this subsection, we discuss the results of our survey regarding potential differences in the use of ChatGPT in humanities-related fields compared to science-related fields. Using survey questions 4.1 and 5.1, we first assessed differences in the frequency of use between these two domains. The results are illustrated in Figure 12 and summarised in Table 12. It is worth noting that Table 12 columns derive from two different questions, not two modalities of the same question. Consequently, a chi-squared analysis was not deemed appropriate for this sub-study. Furthermore, as discussed in section 3, our sample is biased due to a higher proportion of science students, a disparity evident in Figures 13 and 14.\nTo address these limitations, we used confidence intervals to assess differences in the use of ChatGPT between science and humanities fields. These intervals were computed using a normal approximation of the binomial distribution at a 95% confidence level.\nAs can be seen from Figure 12, the results reveal overlapping confidence intervals for students who have never used ChatGPT or have used it only a few times in both fields. However, the intervals for students who have used it \"At least once\" or \"Often\" are disjoint, with humanities leading in the former category and sciences in the latter. Given that students who never use ChatGPT were excluded from this analysis, we infer that non-users in humanities and sciences are distinct populations.\nThe disjoint intervals suggest a polarisation: humanities students are more likely to be"}, {"title": "4.4 Analysis of device preferences", "content": "Using question item 6, we established Figure 17 and Table 15. We remind that question 6 was multiple choice with no obligation to answer. As such, some user checked several devices, and only 343 of the 346 self-reported users chose to answer this item.\nFirst, we can see that the use of voice recognition is not yet democratized, with only around 4% of our respondents that used it. Then, we can see that both computers (or laptops) and smartphones are frequently used by students to prompt ChatGPT, with a preference for computers (87% vs 65%). However, as we can see from Tables 16 and 17, the situation is not homogeneous between genders and age categories.\nUsing chi-squared analysis, we can see that only stable trend is the use of smartphone accross genders ($\\chi^2$ = 1.22, p-value=0.27). On the other hand, the use of smartphone is tied to the age category ($\\chi^2$ = 60.97, p-value< 10-12) with the two youngest categories being the most frequent users (the 13-16 and 17-19yo age range).\nLikewise, the use of computers and laptops depends on both the age ($\\chi^2$ = 17.29,"}, {"title": "4.5 Analysis of non-chatGPT users", "content": "In this subsection, we analyse the responses of the 51 participants who reported never having used ChatGPT in an academic context, focusing on their answers to question item 9. The results are presented in Table 18. It is important to note that item 9 allowed multiple answers, which explains why the total exceeds 51, and also included a free-text option. In this survey, two respondents indicated they were unaware that ChatGPT offered a freemium model."}, {"title": "4.6 Comments on non-academic ChatGPT uses by student populations", "content": "In question item 8, we asked respondents whether they used ChatGPT or other LLMs for non-academic purposes. This was a multiple-choice question that included several pre-written options, such as \"for personal documents and text writing\", \"to write administrative documents (e.g., CVs, motivation letters)\", and \"for social networks\". Additionally, an open text field allowed respondents to specify other uses. The results are presented in Table 19, where the line \"As a search engine\" includes all uses of ChatGPT related to online research, cultural queries, or daily questions that could otherwise have been addressed through traditional search engines or platforms like Wikipedia.\nWith the unsurprising exception of \"administrative document writing\", which was less commonly reported by younger respondents, no significant (or new) age or gender trends were observed for this question item.\nThe most frequent non-academic use of ChatGPT among respondents was personal document and text writing, with 41.2% of students indicating that they had used LLMs for this purpose. However, overall percentages for non-academic use were surprisingly lower than anticipated. One possible explanation is that academic tasks, such as homework and research for school, are the primary use cases for ChatGPT, as nearly 60% of respondents reported not using it for anything else. Alternatively, the omission of \"as a search engine\" as a pre-written option in the multiple-choice answers may have inadvertently introduced bias, overlooking what could be another major use of LLMs."}, {"title": "5 Conclusions and Future works", "content": "In this paper, we have provided a comprehensive analysis of how students have integrated on their own the use of LLMs such as ChatGPT into their academic routines. This analysis is based on a survey conducted in France and Italy among students aged 13 to 25 years old. The survey had three main objectives:\n\u2022 Assessing the pervasiveness of LLMs across different student populations based on age and gender, with the aim of evaluating how systemic these tools are in academic life.\n\u2022 Analysing potential differences in usage depending on students' age, gender, and the type of academic topic. By differences in usage, we refer to factors such as frequency of use, perceived trustworthiness, proofreading and reformulation habits, as well as device preferences.\n\u2022 Identifying opportunities, threats, and risks related to learning challenges and technological gaps between LLM users and non-users.\nOur findings revealed the widespread use of LLMs across all age groups and topics, with notable trends such as the already frequent use by two-thirds of students aged 13 to 16, and an increase in usage frequency as students progress through their curriculum.\nHowever, significant gender differences have emerged, with male students showing higher usage rates in both humanities and scientific fields. The gap in usage frequencies is particularly pronounced for scientific applications of LLMs. While this may reflect a pre-existing and culturally exacerbated propensity of male students toward scientific topics, it is evident that LLMs could widen the technological gender gap. This raises urgent concerns about widening disparities in AI literacy and gender equality, which could extend beyond STEM and AI-intensive fields to affect nearly all employment sectors impacted by AI. Addressing these disparities should become a priority for educational policymakers. Taking into account the results shown in sections 4.2 and 4.5, we found that these disparities may also be related to a different ethical approach: females could be more concerned about academic integrity. We believe that this issues would deserve deeper investigation to better comprehend whether this disparity is primarily linked to differing ethical attitudes or rather to unequal access, propensity or education regarding computing and AI resources.\nThe widespread popularity of these tools across all student populations highlights a shift in the educational paradigm, with traditional assessment methods such as homework increasingly subject to AI intervention. This calls for a reassessment of pedagogical strategies to incorporate AI tools constructively and ensure cognitive engagement rather than simple delegation to an AI. Our results also demonstrate the need to teach students especially younger generations to critically evaluate and revise outputs from these tools, as this habit is far from systematic at present.\nAlthough it is beyond the scope of this paper, we must note the ethical challenges and risks associated with the over-reliance on AI tools, as well as their potential to erode critical thinking and foundational cognitive skills. Our findings indicate that older students are more likely to critically analyse AI-generated results, likely because they developed these skills during formative years when AI assistance was not yet available, but also because they saw the emergence and evolution of these tools and had time to learn about their strengths and weaknesses. Future students, exposed to AI from a younger age, may struggle to develop the same level of critical assessment and this must be taken into account. Because previous research have shown that typing is less effective than handwriting for words and concept retention [64, 65], it is very likely that copy-pasting LLM-generated answers -and reworking them a bit in best case scenarii- offers even less cognitive benefit. Furthermore, things might get worse if voice recognition takes off, which is not yet the case according to our results.\nIn conclusion, our study raises numerous questions and confirms several concerns that should be addressed by educational systems. On the one hand, AI and LLMS represent a tremendous opportunity, and their mastery will become indispensable in the job market. On the other hand, current educational structures appear ill-equipped to mitigate the potential harms of these tools, including gender gaps, AI illiteracy, and the erosion of critical thinking and foundational cognitive skills.\nGiven that no age group (not even secondary and high-schools) or subject area has remained untouched by LLMs, we strongly recommend that all educational institutions begin integrating these systems into their teaching methods. Key areas of focus should include ethics, critical thinking, the limitations of AI, and the environmental costs associated with these technologies. These topics can be introduced at an early age without overburdening already demanding curricula. Similarly, revising teaching and evaluation methods to account for LLMs is essential to safeguard learning outcomes. By embracing these recommendations, educational systems can harness the potential of LLMs to enhance learning while mitigating risks, ensuring that these powerful tools serve as a bridge rather than a barrier to equitable and effective education.\nBased on our survey results and the statements presented in this section, we have identified 2 distinct, and in some ways opposing, approaches to rethinking homework in light of the existence of LLMs:\n\u2022 The first approach would acknowledge the existence of LLMs and they likelihood that they will be used. It would consist in adding an unassisted restitution part to any homework, thus forcing students to appropriate the answers produced by these tools and in some case mobilize memorization skills.\n\u2022 The second approach embraces the use of ChatGPT, particularly suited to humanities subjects. In this scenario, students would use ChatGPT to complete their assignments and subsequently evaluate their learning process. They would analyze the type of reasoning required, assess the elaboration needed for the task, and compare the time spent utilizing ChatGPT's responses versus solving the task independently.\nThese methodologies could be tested in a research setting, where classes from a specific discipline would engage with homework designed according to these approaches."}]}