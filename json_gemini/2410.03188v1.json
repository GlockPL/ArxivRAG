{"title": "Looking into Concept Explanation Methods for Diabetic Retinopathy Classification", "authors": ["Andrea M. Stor\u00e5s", "Josefine V. Sundgaard"], "abstract": "Diabetic retinopathy is a common complication of diabetes, and monitoring the progression of retinal abnormalities using fundus imaging is crucial. Because the images must be interpreted by a medical expert, it is infeasible to screen all individuals with diabetes for diabetic retinopathy. Deep learning has shown impressive results for automatic analysis and grading of fundus images. One drawback is, however, the lack of interpretability, which hampers the implementation of such systems in the clinic. Explainable artificial intelligence methods can be applied to explain the deep neural networks. Explanations based on concepts have shown to be intuitive for humans to understand, but have not yet been explored in detail for diabetic retinopathy grading. This work investigates and compares two concept-based explanation techniques for explaining deep neural networks developed for automatic diagnosis of diabetic retinopathy: Quantitative Testing with Concept Activation Vectors and Concept Bottleneck Models. We found that both methods have strengths and weaknesses, and choice of method should take the available data and the end user's preferences into account. Our code is available at https://github.com/AndreaStoraas/ConceptExplanations_DR_grading.", "sections": [{"title": "1. Introduction", "content": "Diabetes is a disease with increasing prevalence, and diabetic retinopathy (DR) is one of the most common complications (World Health Organization, 2022). DR is characterized by retinal abnormalities, which damage the eye and can lead to blindness. Its severity depends on the type and amount of retinal abnormalities: Hemorrhages (HE), microaneurysms (MA), hard exudates (EX), soft exudates (SE), intraretinal microvascular abnormalities (IRMA), and neovascularization (NV). DR is graded from 0 to 4 (no DR, mild, moderate, and severe nonproliferative DR, and proliferative DR), as described by Wilkinson et al. (2003). DR grading of fundus images is traditionally a manual process requiring medical expertise. These images underline the challenge of identifying relevant medical abnormalities without specialist training."}, {"title": "2. Data and Method", "content": "Seven open access datasets were used in the current study: APTOS (Karthik and Dane, 2019), DR Detection (Dugas et al., 2015; Cuadros and Bresnick, 2009), Messidor-2 (Decenci\u00e8re et al., 2014; Abramoff et al., 2013), FGADR (Zhou et al., 2021), DDR (Li et al., 2019), DIARETDB1 (Kauppi et al., 2007) and IDRID (Porwal et al., 2018). All datasets including image-level annotations of DR grade were used to train the deep neural networks for DR grading. Several data sources are combined to ensure generalizable models, as the fundus images were captured at different locations, by different healthcare personnel, and using different devices, making the training data diverse. For concept generation, fundus images segmented with medical findings relevant for diagnosis of DR were used. FGADR was applied for both DR grading and concept generation. The distribution of DR levels are highly skewed, with the majority of the images representing eyes with no signs of DR, and annotations of IRMA and NV are only available in FGADR. The four datasets used for developing the DR grading models were split into 80% for training, 10% for validation, and 10% testing. Images from the same patient were placed in the same split of the dataset. Additionally, the black background was removed from all images. Further on, Contrast Limited Adapted Histogram Equalization (CLAHE) was applied to enhance the image quality by making the blood vessels and retinal findings more visible (Zuiderveld, 1994). For the training set, several image augmentation techniques, such as random flipping, blurring, and change of perspective, were also applied. The source code for all the experiments, including concept explanations, is publicly available online\u00b9."}, {"title": "2.1 Testing with Concept Activation Vectors", "content": "Two model architectures, Inception V3 (Szegedy et al., 2016) and Densenet-121 (Huang et al., 2017), were applied due to good performance on analyzing fundus images in previous work (Kora et al., 2022; Tsangalidou et al., 2022; Zhou et al., 2021). Both models were pretrained on ImageNet (Deng et al., 2009), as also used in the previous works, and modified to predict five classes in the final prediction layer. The models were fine-tuned for 100 epochs on the combined training and validation sets for DR grading. The best performing model on the validation set was used for further evaluation. Due to class imbalance, a weighted random sampler was used during training. Moreover, an Adam optimizer with default hyperparameters and cross-entropy loss were applied (Paszke et al., 2019).\nTCAV measures the relative concept importance for a classification result by checking how sensitive the model is to changes in the input image toward the direction of the concept, defined by the concept's corresponding concept activation vector (CAV) (Kim et al., 2018). For estimating the CAV, the user provides a set of positive example images containing the concept of interest and a set of negative example images, where the concept is absent. Next, features are extracted from the positive and negative example sets, respectively, from a specific layer in the model chosen by the user. A linear classifier is trained to separate the features from the two image sets apart, and the resulting CAV lies orthogonal to the classification boundary of the linear model. The process is repeated for each concept. For more details about the mathematics behind the XAI method, the interested reader is referred to the original TCAV paper (Kim et al., 2018). In our work, the concepts were defined as described in the original publication (Kim et al., 2018). First, the full images were used to represent the concepts (Kim et al., 2018), as opposed to cropping out the image regions where the specific medical finding for a given concept were located. However, abnormalities in fundus images can be small, and are typically not evenly distributed in the image. We therefore tested a second way of preprocessing the concept images, masking out the area around the relevant medical findings based on the segmentation masks. This might enhance the quality of the concepts and was inspired by Chen et al. (2020). To avoid extreme variations in image sizes, the masked images were restricted to be at least 520 \u00d7 520 pixels. For both concept generation approaches, CLAHE was applied to enhance the quality of the concept images.\nRegardless of the image preprocessing approach, concepts were generated for all six medical findings used for grading DR in fundus images (MA, HE, EX, SE, IRMA, and NV) based on the segmentation masks. Positive examples containing the concept and negative examples without the concept were employed for generating the concept activation vectors. The presence of other findings in the images were balanced between the positive and negative examples. The positive and negative example sets contained 45 images each, which were randomly selected from the four datasets. To test the significance of the detected concepts, 20 different negative sets were generated for each concept. FGADR was the only dataset annotated with IRMA and NV, and all positive and negative examples for these two concepts thus arrived from the FGADR dataset.\nNext, TCAV scores were calculated for images from the test set. The concepts were extracted from Denseblock4, which is the last block before the prediction layer of the Densenet-121 model. To make sure the concepts were consistent and not only caused by randomness, two-sided paired t-tests were performed on the TCAV scores for a given DR level using the positive example set for a given concept and the 20 negative example sets. Only statistically significant concepts with p-values < 0.05 were considered."}, {"title": "2.2 Concept Bottleneck Models", "content": "CBMs differ from TCAV in that the concepts are learnt together with the target labels during model training. The deep neural network is modified to include a bottleneck layer that predicts the concepts before the final prediction layer (Koh et al., 2020). In other words, the final labels are predicted directly from the concepts. By inspecting the probabilities for the predicted concepts for a given input image, it is possible to observe how much each concept influences the model. A drawback of CBMs is that the dataset must include annotations for both the target labels and the concepts of interest for all images in the dataset. Consequently, getting enough annotated data could be an issue, especially in the medical field, where annotations are typically challenging and expensive to obtain. Moreover, only concepts included during the training phase can be explored. For TCAV, this is less of a concern because the concepts are defined after training the model and the example images are not restricted to images from the training dataset.\nBecause CBMs learn the concepts during model training, the deep neural network used for TCAV could not be used. The original CBM paper (Koh et al., 2020) describes several alternative ways of designing CBMs. In our experiments, we implemented sequential bottleneck models using a modified version of the Densenet-121 and Inception V3 architectures. The bottleneck model was initiated with the weights from the corresponding DR grading model and fine-tuned to predict the presence of six diagnostic concepts. Next, we trained a logistic regression (LR) model to classify DR levels from the concept predictions provided by the bottleneck model. The FGADR dataset, being the only dataset annotated with both DR levels and all six concepts, was applied for training. Due to limited amount of training data, another bottleneck model was also trained to only predict the four most prevalent concepts: MA, HE, EX, and SE. By excluding the IRMA and NV concepts, the DDR, IDRID, and DIARETDB1 datasets can also be used for training. Images of DR level 0 without any of the concepts were also included in the training, validation and test sets, encouraging the models to not always predict the most prevalent concepts to be present. Following Koh et al. (2020), binary cross entropy with logits loss was used for training the bottleneck models. Apart from that, the bottleneck and LR models were trained with the same hyperparameters as the DR grading models.\nThe main advantage with CBMs is the possibility of manually correcting the predicted concepts provided to the LR model at test time. Inspired by the original paper (Koh et al., 2020), we intervened on the concepts by using the 1st and 99th percentiles for the predicted concept values on the training dataset. These percentiles functioned as surrogates for the true concept values for the absence and presence of a given concepts, respectively. Test time intervention was performed on the entire FGADR test set. Additionally, the intervention was performed on the subset of test images classified with incorrect DR levels to make it easier to observe the differences in model performance with and without test time intervention. In both cases, only incorrect concept predictions were corrected using the percentile values. The effect of incrementally correcting more concepts was studied, where the concepts were ordered based on the increase in balanced accuracy when adjusting the concepts independently."}, {"title": "3. Results", "content": "The models based on the Densenet-121 architecture outperformed the Inception V3-based models for both TCAV and CBMs models. The performance metrics on DR grading for the models based on Densenet-121 on the combined and FGADR test sets are presented. Because concepts were not used when training the models explained by TCAV, the performance metrics reported for the 'TCAV models' can be regarded as baseline results for DR level classification. We observe that the model used for TCAV had the highest performance on the combined test set. The CBM trained on six concepts generalized poorly from FGADR to the combined test set, but performed best on the FGADR test set. This is not surprising, as the FGADR training set is much smaller and less diverse than the combined training set. For the model trained on four concepts, the performance was not significantly different between the two test sets because of the mixed training data. Regarding the concept detection task, the CBM trained on six concepts correctly identified 86.2% of the diagnostic concepts, compared to 82.5% for the model based on four concepts. The balanced accuracy also increased from 80.9% to 85.9% when increasing the number of concepts. These results were computed on the FGADR test set. The CBM trained on six concepts was used in further experiments since this model performed best on the FGADR data for both DR grading and concept detection.\nDue to memory limitations, TCAV scores were calculated on a representative subset of the combined test set consisting of 50 randomly picked images from each DR level. The performance for DR prediction on the representative test set did not differ significantly from the full test set. As mentioned in Section 2.1, the TCAV concepts were either based on the full images or only the image area surrounding the medical finding(s) of interest. Masking the concept images did not generate significantly different results, thus the full concept images were used. Increasing DR severity is associated with higher TCAV scores for more concepts and higher concept counts. Note that the TCAV scores and CBM concept counts are not directly comparable. Different datasets were used, and the TCAV scores reflect relative importance between the concepts while the CBM counts are merely the predicted presence of concepts.\nTest time intervention on an increasing number of concepts was performed for the CBM trained on six concepts. The intervention concerned concepts that were wrongly predicted by the CBM. As previously mentioned, the order of which concepts to intervene on was determined by the corresponding balanced accuracy in DR classification following the intervention on a single concept. Consequently, the concept resulting in the best balanced accuracy on the DR grading was included first, while the concept with the worst performance was included last. The left hand side of Figure 4 shows the DR classification performance"}, {"title": "4. Discussion and Conclusion", "content": "According to the diagnostic criteria for DR level 1 (mild DR), MA should be the only abnormality present (Wilkinson et al., 2003). This corresponds well to both TCAV and CBM results in Figure 3, highlighting MA as the most important concept for DR level 1. The IRMA, SE, and MA concepts were ranked highest by TCAV for DR level 2, and all concepts but NV was identified by the CBM. This is consistent with the diagnostic criteria for MA, HE, and SE. Interestingly, the IRMA concept was ranked highest by TCAV, even though this finding is mainly associated with DR level 3. By inspecting the datasets more closely, several DR level 2 images actually contained IRMA. It is therefore reasonable that the model identifies IRMA as important when making predictions on DR level 2 images. Additionally, several DR level 3 images were predicted to belong to DR level 2. This can also partly be explained by the high TCAV scores for the IRMA concept. The TCAV scores for DR level 3 gave high importance to MA, HE, EX, SE, and IRMA, and are coherent with the diagnostic criteria for this DR level, as well as the presence of all concepts except NV for the CBM. The presence of HE, EX, and SE was increased compared to level 2, which is also expected. Finally, for DR level 4, TCAV ranked NV highest, followed by EX and HE, which was expected as this is the only DR level where NV is present. NV was also identified by the CBM. Taken together, the concept-based explanations seem to align with established medical knowledge about DR. This is encouraging in terms of applying TCAV and CBMs in the clinic for explaining deep neural networks for DR grading. The next step would be to validate the usability of these concept-based XAI methods with feedback from ophthalmologists. In this current study, we compare the explanations with widely accepted guidelines for grading of DR, but there might be other clinically relevant aspects that were not considered.\nThe overall ranking of the concepts were not different for the concepts based on full images and concepts based on masked images that focused on the area containing the medical findings of interest. This could mean that even though some findings are small, they are still sufficiently learnt from the full images. On the other hand, similar results could also indicate that the masking technique was not efficient enough. In order to avoid extreme deviations in the image sizes for the masked concept images, a lower limit of 520 \u00d7 520 pixels was applied. For images of low resolutions, this restriction implied that a very small part of the image was removed and that the masked and full image versions were almost the same. However, since the model was trained on images input size 620 \u00d7 620 pixels, input images with few pixels were regarded as less likely to provide useful results. Consequently, the lower pixel limit was considered the best alternative when preparing the masked concept images. The small variations between the results from full concept images and masked concept images indicate that it is sufficient to use the original images for concept generation. Further on, time is saved because we do not have to mask out the relevant findings from the images in order to get meaningful concepts.\nIRMA and NV are typical findings for severe DR. The presence or absence of these findings is therefore expected as useful information when learning to grade DR. As observed, the CBM trained on four concepts (MA, HE, EX and SE) performed worse when grading DR on the FGADR test set. Even though the model trained on four concepts received more training data and was better at predicting these four concepts than the model trained on all six concepts, missing information about IRMA and NV seems to negatively affect the DR grading. This highlights the importance of high quality concept annotations for these XAI methods.\nTest time intervention showed to be a great advantage of the CBM and resulted in more accurate model predictions. When the concepts for incorrect predictions are inspected, the user can get important information about why an image was misclassified. As an example, the DR level 4 image was misclassified as DR level 3, because the bottleneck model missed the NV concept. By correcting this, the image was correctly classified.\nDespite including > 33800 images for training the combined DR classification model, the model did not outperform earlier deep neural networks (Lakshminarayanan et al., 2021). In this work, we combined four different datasets where the fundus images were captured using various devices and arriving from patient populations in different geographical areas. The high image diversity probably makes it challenging for a model to capture representative patterns in the data compared to more homogenous datasets. On the other hand, the diverse collection of training data could make the model robust to variations and noise in data from a real-world setting and increase its ability to generalize to new datasets. We could not identify any previous studies using the same combination of data as us, meaning that our results are not directly comparable to previously reported performance metrics. Because this study focuses on the explanation methods, the performance is regarded as sufficiently high.\nConcept-based explanations are promising for increasing the understanding of DR grading with deep neural networks. While CBMs allow for test time intervention on the concepts, these models are limited by the lack of publicly available medical datasets annotated with both concepts and target labels. For TCAV, concepts can be defined using other data sources, meaning that the training data does not need additional concept annotations. Consequently, the model explained by TCAV outperformed the CBMs for DR grading. Our results highlight a major drawback of the CBMs: Because the development dataset must be annotated with concepts and DR level, the amount of available data is small. The requirement of training a modified CBM also complicates direct comparison and combination with other XAI methods. Before larger medical datasets annotated with concepts and target labels are available, TCAV gives the best trade-off between model performance and explainability for DR grading."}, {"title": "Ethical Standards", "content": "The work follows appropriate ethical standards in conducting research and writing the manuscript, following all applicable laws and regulations regarding treatment of animals or human subjects."}, {"title": "Conflicts of Interest", "content": "The authors declare no conflicts of interest."}, {"title": "Data availability", "content": "The datasets applied in the presented research are publicly available. Details regarding data and code are available on GitHub: https://github.com/AndreaStoraas/ConceptExplanations_DR_grading"}]}