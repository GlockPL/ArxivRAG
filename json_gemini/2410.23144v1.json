{"title": "Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms", "authors": ["Jordan Meyer", "Nick Padgett", "Cullen Miller", "Laura Exline"], "abstract": "We present Public Domain 12M (PD12M), a dataset of 12.4 million high-quality public domain and CC0- licensed images with synthetic captions, designed for training text-to-image models. PD12M is the largest public domain image-text dataset to date, with sufficient size to train foundation models while minimizing copyright concerns. Through the Source. Plus platform, we also introduce novel, community-driven dataset governance mechanisms that reduce harm and support reproducibility over time.", "sections": [{"title": "Introduction", "content": "Advancements in computer vision and natural language processing have fueled demand for ever larger image-text datasets [1-6] to train increasingly sophisticated models [7-9]. To meet this demand, large- scale datasets typically comprise URLs identified by web crawlers and require each model trainer to re- download the images from across the web. This practice has been critiqued for prioritizing scale over re- sponsibility [10] and has prompted a range of con- cerns regarding copyright infringement [11, 12], con- sent [13, 14], inappropriate content [15, 16], person- ally identifiable information (PII) [17], and the per- petuation of harmful biases [18, 19]. Moreover, once released, these datasets degrade over time [20] and are ill-equipped to remediate their contents [21].\nResponding to these concerns, we introduce a new public domain dataset and a novel platform for dataset governance that incorporate current rec- ommendations for responsible dataset creation and maintenance.\nPublic Domain 12M (PD12M) is the largest image- text dataset sourced from only materials labeled with a Public Domain Mark or Creative Commons Zero license (CCO). At 12.4 million image-caption pairs, PD12M and its 3.3 million item subset, Pub- lic Domain 3M (PD3M), match the size of the Con- ceptual Captions datasets (CC12M and CC3M) [1], enabling commercial implementations of AI models trained using those and similarly sized datasets [22- 25]. PD12M and PD3M are released under a Com- munity Data License Agreement (CDLA-Permissive- 2.0).\nIn this paper, we describe our image sourcing and curation process, which was designed to maximize the aesthetic quality of the dataset contents while minimizing copyright concerns. Because the prob- lems of web-scale datasets go well beyond copyright [13, 14, 16, 19], we also outline recommendations for dataset governance and explain how we implement those recommendations with the Source. Plus plat- form."}, {"title": "Background", "content": "Datasets like Common Catalog [27] and Megalith- 10M [26] have attempted to address copyright con- cerns by including only Creative Commons (CC) li- censes. However, the ShareAlike and Attribution re- quirements of many CC licenses raise unresolved legal questions regarding whether model outputs can sat- isfy attribution requirements and whether derivative works created by AI models must carry the same li- cense terms [11, 12].\nBeyond copyright concerns, proponents of respon- sible AI have proposed methods for identifying and mitigating dataset biases [18, 21] and measuring dis- tribution shifts and data quality [28, 29]. Addi-"}, {"title": "Building PD12M", "content": "We include a link to an up-to-date dataset summary in Appendix A.1. We also completed a datasheet [30] and included it alongside the dataset itself on Hugging Face."}, {"title": "Image Collection", "content": "GLAM Metadata: We sourced 23.1M images di- rectly from galleries, libraries, archives, and museums (GLAM), as well as from aggregators of their content. GLAM institutions provide additional layers of qual- ity, safety, and licensing review [37] and more compre- hensive information about an item's origins and au- thenticity [21, 33] when compared to Common Crawl [45]. The OpenGLAM Survey [46], which tracks open access policies across cultural heritage institutions worldwide, provides the most thorough guidance for locating these organizations. A comprehensive list of all contributing institutions and the volume of their contributions, is linked in Appendix A.1.\nWe created custom parsers for each source to ex- tract provenance, metadata, and licensing informa- tion for every image we collected [11, 32, 47, 48] from OpenGLAM sources.\nWe parsed metadata from static files when avail- able, and when traversing APIs, we used self-imposed rate limiting. These measures were taken to minimize the strain on the hosting institutions' servers [49].\nPrior to cloning any images, we filtered the ex- tracted metadata to include only images explicitly marked as public domain or CCO by the source. See Appendix A.2.\nWikimedia Metadata: We sourced 11.3M im- ages from Wikimedia Commons [50], which contains a mix of user uploads and institutional datasets. While the Wikimedia Commons community rigor- ously maintains their media collections, we took ad- ditional steps to pre-filter undesirable content based on the metadata.\nWe first limited our metadata collection to the CC-PD-Mark and CC-Zero categories only. Wiki- media users can tag items with more granular infor- mation. We manually reviewed the user tags within these categories and filtered out any images with tags that implied a license outside of the public domain. Additionally, we filtered out images tagged as AI-"}, {"title": "Image Curation", "content": "We used automated and manual filtering to ensure the overall quality and safety of the dataset. Our curation process was primarily performed through Source.Plus. We filtered the 38M downloaded im- ages described in the previous section down to 12.4M for PD12M and to 3.3M for the PD3M subset.\nSemantic Embeddings: We first used CLIP ViT-L/14 [54] to generate embeddings, which served as inputs for downstream curation tasks, includ- ing document scan identification, NSFW filtering, and aesthetic scoring. We include these embeddings alongside the dataset.\nDocument Scan Identification: After visually inspecting the collected images, we estimated that roughly a quarter were scans of documents, such as books, letters, and newspapers, which pictured only typed or written words. For the first filtering step, we tagged 8.7M images using an internal model trained to identify document scans and removed them from some subsequent tasks in order to reduce compute costs.\nFormat and Resolution Restrictions: We then imposed a minimum resolution threshold of 256x256 pixels to maximize the dataset's suitability for in- creasingly high-resolution training of text-to-image models [55, 56].\nContent Filtering: We used LAION's NSFW classifier [57] to exclude works with a score greater than 0.5. We also manually reviewed the dataset us- ing semantic search tools to remove instances of non-artistic photographic nudity.\nAdditionally, we completed a manual check of known ethnophaulisms listed in Wikipedia [58]. For each term, we searched metadata and conducted a semantic search to remove derogatory metadata and images [16, 45].\nThese steps flagged fewer than 0.05% of the 38M total images collected, demonstrating the value of limiting our initial image collection to trusted and moderated sources.\nDeduplication: We represented the dataset's im- ages as nodes in a sparse graph, with links created between images when the cosine distance of their SSCD embeddings [59] was <0.1 (empirically deter- mined). Each subgraph with more than one member was treated as a group of duplicates. For each dupli- cate group, we selected a canonical image by choos- ing the item having, in order of priority: 1) a GLAM source, if available, 2) the largest image dimensions, 3) the highest aesthetic score, 4) the largest file size, and/or 5) the most complete metadata.\nAesthetic Scoring: We assigned each down- loaded image an aesthetic score using a model trained on an internal dataset of human ratings. For our final curation step, to match the original size of CC12M (12.4M), we excluded images from the bottom 50% of aesthetic scores. To match the original size of CC3M (3.3M), we excluded the bottom 90% of im- ages by aesthetic scores. Randomly sampled images from select percentile ranges are available in Table 2 to demonstrate the model's aesthetic preferences.\nManual Spot-checks: Throughout the curation process, we performed spot-checks on random sam- ples to verify the effectiveness of the automated fil- tering. We reviewed over 0.1% of the dataset, with a focus on edge cases and copyright misclassifications. This process also led us to notice that nearly 2% of Wikimedia Commons photographs had EXIF rota- tions [60], which we corrected for our hosted copies."}, {"title": "Caption Generation", "content": "We generated detailed synthetic captions for each im- age using Florence-2-large [61]. Captioning the ~29M images not identified as document scans required 8 A100 80GB GPUs running for approximately 18 days.\nWe chose to use synthetic captions rather than the associated alt-text or image descriptions to maximize both privacy and quality. Large language models can memorize and reproduce PII from their training data [62, 63], although these cases are necessarily more rare than the rate of PII in the training datasets themselves. Similarly, synthetic captions might in- troduce \"style leakage,\" whereby the captioner leaks details of a living artist's style by associating their name with public domain artwork that shares style characteristics. In cases of style leakage, a model could return consistent results when prompted with a living artist's name, giving the mistaken impression that the artist's work was included in the model's training data. We reduced the risk of style leakage by cross-referencing the synthetic captions against Mid- journey's list of artists [64] to systematically remove any mention of artists still living after 1954."}, {"title": "Data Governance Framework", "content": "In addition to robust curation, dataset revisions are critical to remove problematic content that is discov- ered over time. Here, we outline three key mech- anisms for dataset governance that enable datasets to continually improve: auditability, stabilization, and communication. We implement these mecha- nisms through Source. Plus, which provides technical infrastructure for exploring, reviewing, and refining PD12M while maintaining a detailed history of its changes."}, {"title": "Auditability", "content": "Although PD12M follows strict copyright restric- tions, the \"Creative Commons fallacy\" [13] identifies that copyright status alone does not address privacy and safety issues. These issues are more likely to be discovered as more users explore the dataset, suggest- ing that dataset audits are valuable and most effective when they are public and community-driven [48].\nDataset audits require supporting transparency, in- cluding making it possible to search and view the im- ages used in the dataset regardless of its scale, and defining clear processes for flagging problematic items following a dataset's release.\nSource. Plus provides keyword, semantic, faceted, and reverse image search capabilities to enable dataset exploration. Source.Plus also provides a pub- lic feedback mechanism through its \"flag\" feature. Users can flag items for any reason, including copy- right, bias, and privacy concerns [65, 66], and record their justification in a free-text field. When an item is flagged, it becomes immediately invisible to users pending review. Reviewed items are either restored to the dataset or replaced with a similar image."}, {"title": "Stabilization", "content": "Training dataset stability is crucial for meaning- ful model comparisons [67]. Even small changes in training data can significantly impact model perfor- mance [68], and inconsistent datasets between re- search groups can disrupt reproducibility [69]. Our approach ensures that necessary improvements can be made while preserving the statistical properties needed for reliable benchmarking and comparative analysis [28, 70].\nWhen an image requires replacement, we select an alternative from the ~25 million additional public domain images in Source.Plus (as of October 2024) using quantitative measures, such as similarity be- tween semantic and perceptual embeddings [7, 71], aesthetic scores, image dimensions, file size, meta- data completeness, and other key features."}, {"title": "Image Archiving", "content": "Archiving the images under the control of the dataset maintainers improves stability, and is made possible because the images in PD12M are understood to be in the public domain. Open-web image links are sus- ceptible to changes introduced by others [20, 72] and would have to be regularly monitored to achieve com- parable stability without image archiving.\nPew Research has shown that ~38% of webpages that existed in 2013 were no longer accessible a decade later [73]. Recent changes in API policies, such as Flickr's restrictions on access to CC-licensed images [74], and the growing trend of websites modi- fying their robots.txt files to limit crawling further hinder the consistency of previous datasets. The Data Provenance Initiative underscores this issue, re- porting that between August 2023 and January 2024, data restriction requests increased dramatically, with up to 45% of previously accessible content in major datasets becoming restricted [14].\nAn often overlooked contributor to this trend is the increasing hosting costs associated with web-scraping [49, 75]. Web-scraped datasets externalize egress costs to the original content hosts, often public in- stitutions. Rising costs can discourage institutions from hosting data publicly, further limiting the future availability of resources for AI researchers and the public at large. Image archiving accounts for these costs and reduces the burden on public institutions."}, {"title": "Communication", "content": "Finally, effective use by the research community re- quires monitoring and publicizing changes to datasets over time. Each item in Source. Plus has its own changelog, allowing researchers to track the granu- lar decisions that impact the dataset and allowing dataset maintainers to create digests to accompany new versions."}, {"title": "Limitations and Future Work", "content": "Geographical, Cultural, and Historical Bias: Digitized public domain content over-represents Western geographic regions and cultures [46, 76, 77]. It also over-represents older content, limiting the dataset's applicability to contemporary visual tasks [19].\nDespite careful curation, offensive images reflect- ing these biases are very likely to persist in PD12M. We will use the Source. Plus platform to address prob- lematic contents as they are discovered, and we wel- come feedback. We are also seeking sources of public domain media having a more diverse representation, and we encourage readers to contact us with sugges- tions.\nPD12M Metadata: In the initial release of PD12M, we include images and captions, which are sufficient for training text-to-image models. However, we do not include any of the additional metadata that we collected from the image sources. While that metadata is searchable on Source. Plus, we currently recommend against using it for commercial model training. Some source institutions provide images with a PD or CCO designation alongside metadata elements that carry a more restrictive CC license. Future versions of PD12M will include additional meta- data elements as we determine whether they share a public domain designation.\nSynthetic Captions: We created the captions for PD12M using only images as prompts. As we release additional metadata, providing a captioning model with more context (e.g., artistic medium) will likely improve the specificity and accuracy of the captions. We used Florence-2-large [61], which was trained using copyrighted materials with limited trans- parency about its training data. While we reviewed and edited the captions it produced to eliminate ref- erence to non-public domain artists, we would ul- timately like to replace all captions using a model trained entirely on public domain materials. At the time of writing, no such public domain-exclusive cap- tioning models are known to the authors."}, {"title": "Conclusion", "content": "PD12M is a highly aesthetic, public domain alterna- tive to existing image-text datasets. It addresses crit- ical licensing concerns and demonstrates the feasibil- ity of incorporating responsible AI recommendations at web-scale. Source. Plus supports ongoing dataset governance to address bias, privacy, and safety by allowing responsive data changes that don't compro- mise dataset reproducibility.\nWith Source. Plus, we aim to promote responsible AI development practices across the industry [78]. We hope these efforts offer an opportunity for individ- uals and organizations who are uneasy with current dataset practices to participate in AI development [43, 44]."}, {"title": "Appendices", "sections": [{"title": "Dataset Summary", "content": "We maintain an up-to-date summary of the PD12M dataset contents via a public Google sheet. This sum- mary includes counts by contributing institutions as well as enumerated content filters."}, {"title": "Legal Disclaimer", "content": "To the best of our knowledge and available resources, all works included in PD12M were labeled with a Public Domain mark or CCO license. While we have implemented conservative filtering regarding copy- right status, due to the scale of the dataset (12.4 million items), we cannot guarantee with absolute certainty the licensing status of any individual work. If you identify any work that you believe has been incorrectly included in PD12M due to licensing sta- tus, please notify us through our formal Takedown Policy. Upon review, any erroneously included work will be promptly removed and replaced following our dataset maintenance procedures.\nFor organizations seeking to build upon PD12M, we recommend conducting an independent verifica- tion of licensing status appropriate to use case and jurisdiction.\nThe PD12M dataset is released under the Com- munity Data License Agreement - Permissive 2.0 (CDLA-Permissive-2.0). Under this license, you are free to use, modify, and share this dataset, provided you comply with the terms of the CDLA-Permissive- 2.0 license."}]}]}