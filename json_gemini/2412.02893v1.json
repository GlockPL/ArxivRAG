{"title": "Removing Spurious Correlation from Neural Network Interpretations", "authors": ["Milad Fotouhi", "Mohammad Taha Bahadori", "Oluwaseyi Feyisetan", "Payman Arabshahi", "David Heckerman"], "abstract": "The existing algorithms for identification of neurons responsible for undesired and harmful behaviors do not consider the effects of confounders such as topic of the conversation. In this work, we show that confounders can create spurious correlations and propose a new causal mediation approach that controls the impact of the topic. In experiments with two large language models, we study the localization hypothesis and show that adjusting for the effect of conversation topic, toxicity becomes less localized.", "sections": [{"title": "Introduction", "content": "One of the central approaches to improve safety of Large Language Models (LLMs) is to identify and neutralize units in the LLMs that are responsible for undesired behaviors such as bias and toxicity. Interpretability approaches, such as Mechanistic Interpretability [Olah et al., 2020, Olsson et al., 2022, Nanda et al., 2023, Bereska and Gavves, 2024], try to accomplish this by finding subgraphs of the LLM's computational graph that are responsible for the undesired behaviors. Existing work have shown the success of neuron neutralization approach in removing bias and toxicity from the output of LLMs [Vig et al., 2020, Yu et al., 2023, Zhang and Nanda, 2024].\n\nThe first step in editing LLMs is to identify the computational units responsible for harmful behavior. The existing algorithms such as activation patching have focused on identifying mechanisms that are predictive of an undesired behavior [Zhang and Nanda, 2024]. However, confounders such as the conversation topic can create spurious correlations. For example, some topics such as politics are more susceptible to toxic language and we should identify nodes that are activated during toxic generations, not all generations on the politics topic. In this work, we will focus on removing the effect of topic and its spurious effect and identify computational units that are only responsible for the unwanted behavior.\n\nOur task is to find a small subset of neurons that are responsible for toxicity in the LLM's answers. We follow the causal mediation analysis approach [Vig et al., 2020, Meng et al., 2022, Stolfo et al., 2023, Marks et al., 2024, Zhang and Nanda, 2024]. In our setup, the treatment (question) takes the form of text and the outcome is the toxicity label of the generated response. To adjust for the effects of topic, we use the weighting approach by [Huber et al., 2020, Huang et al., 2024], which requires only one forward pass. We customize the entropy balancing approach [Huang et al., 2024] to be able to handle textual queries using sentence embeddings. We also propose an approach for finding the average indirect effect without creating out-of-distribution examples.\n\nWe use our proposed approach to study the localization hypothesis that states only few neurons are responsible for harmful behavior in LLMs. We use two LLMs Bloomz 1B7 [Le Scao et al., 2023] and Microsoft/Phi-3-mini 3B [Abdin et al., 2024] on the RealToxicityPrompts dataset [Gehman et al., 2020]. We compute how much each multilayer perceptron unit is responsible for toxicity. We show that adjusting for the conversation topic, the toxicity become more distributed across MLPs, for both Bloomz and Phi-3-mini."}, {"title": "Background", "content": "We use Roman letters for random variables, e.g., x, and italic letters for scalar values x. Random vectors are denoted by bold Roman letters x and vector of values are denoted by italic bold letters x.\n\nTo describe the language of potential outcomes [Imbens and Rubin, 2015, Chernozhukov et al., 2024], used in this paper, consider the classical problem of binary treatment effect estimation. We have a binary treatment $a \\in \\{0,1\\}$ and outcome $y \\in \\mathbb{R}$. Both treatment and outcome are influenced by a d-dimensional confounder (pre-treatment covariates) $x \\in \\mathbb{R}^d$. Define the potential outcome $y\\{a = a\\}$ as the outcome when we intervene and set the value of the treatment to a. In real world, we only observe one of the potential outcomes for either $a = 0$ or $a = 1$. The average treatment effect is defined as $E [y\\{1\\} - y\\{0\\}]$.\n\nUnder classical conditions of \u201cstrong ignorability\", $y\\{a\\} \\perp a | x$, (i.e., no hidden confounders) and \u201cpositivity\u201d, $0 < P(a|x) < 1$, there are two primary approaches to estimate the average treatment effect Outcome Regression and Inverse Propensity-score Weighting (IPW). In the outcome regression approach, we train a regression model for the outcome $y = f(a, x)$. We use the regression model to compute the potential outcomes for both $a = 0,1$ and estimate the average treatment effect by finding the empirical average of $y\\{1\\} \u2013 y\\{0\\}$.\n\nIn the IPW approach, the propensity scores are defined as $\\pi(x) = P[a = 1|x]$. Weighting each data point by the inverse propensity scores, creates a pseudo-population in which the confounders and treatments are independent. Thus, regular regression algorithms can estimate the causal response curve using the pseudo-population, which resembles data from randomized trials. When the treatments are continuous, i.e., $a \\in \\mathbb{R}$, we commonly use the stablized weights $\\pi = \\frac{f(a)}{f(a|x)}$ [Robins et al., 2000, Zhu et al., 2015], where f denotes the marginal density function. We can also cleverly combine the outcome regression and IPW to achieve robustness to misspecifications in the regression or propensity score models [Bang and Robins, 2005, Chernozhukov et al., 2018].\n\nThe main challenge in estimating average treatment effect with IPW is that the weights can be very large for some of the data points, leading to unstable estimations. Kang et al. [2007] and Smith and Todd [2005] provide multiple pieces of evidence that the propensity score methods can lead to large biases in the estimations. To address the problem of extreme weights, Entropy Balancing (EB) [Hainmueller, 2012] estimates weights such that they balance the confounders subject to a measure of dispersion on the weights to prevent extremely large weights. Here we describe EB for multi-dimensional continuous treatments based on [Bahadori et al., 2022]. We first center both the treatments a and the confounders \u00e6 vectors. We create a vector $g(a, x) = [a, x, a \\otimes x]$, where $\\otimes$ denotes the outer product. Entropy balancing maximizes the entropy of the propensity scores:\n\n$\\pi = \\underset{\\pi}{\\text{argmin}} \\pi^\\top \\log (\\pi)$, s.t. (i) $G\\pi = 0$, (ii) $1^\\top \\pi = 1$, (iii) $\\pi \\geq 0$,\n\nwhere matrix G denotes the concatenation of g for all data points. We often solve the dual of the above problem, by the following optimization (see the derivation in [Wang and Zubizarreta, 2020]):\n\n$\\hat{\\lambda} = \\underset{\\lambda}{\\text{argmin}} \\log (1 + \\exp (A^\\top G)) + ||\\lambda||_1$.\n\nWe have added the regularization for approximate balancing [Wang and Zubizarreta, 2020]. Higher values of the regularization penalty pushes the weights closer to the confounded (equal weight) solution. Given a solution $\\hat{\\lambda}$, the weights are obtained as $\\pi = softmax (- \\hat{\\lambda} G)$.\n\nIn contrast to estimation of the effect of a cause, reviewed in previous section, causal mediation analysis answers the questions about Causes of Effect [Dawid, 2000, Dawid et al., 2014, Lu et al., 2023, Kawakami et al., 2024, Zhao et al., 2023]. In the simplest mediation analysis setup, we assume that we have a binary treatment a whose effect has two paths to reach to the outcome y: the direct path and an indirect path that goes through a mediation variable m. To quantify the effect that goes from each path, we need to use nested counterfactuals. The counterfactual $y\\{a, m\\{a'\\}\\}$ is interpreted as the outcome when we intervene and set the treatment to a but the input to the mediator to a'.\""}, {"title": "Methodology", "content": "To quantify the contributions of a computational unit of an LLM (such as an MLP) in toxicity of its output, we propose the directed acyclic graph in Figure 1. In our problem setting, the treatments are the queries (prompts) q, the mediators are the intermediate node activations n, the confounders are the conversation topic x, and the outcome is the harmfulness label y. We use bold face for the queries to emphasize that we use a vector representation of the input query. Our goal is to use this graph for every node and find the amount of effect that goes through it.\n\nSimilar to the binary case, we can do the mediation analysis with multivariate treatment as follows. Define the response function as $\\mu(q, q') = E[y\\{q, n\\{q'\\}\\}]$. We can decompose the average treatment effect when the treatment changes from q to q' as follows:\n\n$\\mu(q', q') - \\mu(q, q) = \\mu(q', q') - \\mu(q, q') + \\mu(q, q') - \\mu(q, q)$,\nATE\n=\nNDE\n+\nNIE,\n\nwhere the terms on the right hand side Natural Indirect Effect (NIE) and Natural Direct Effect (NDE) measure the amount of effect going through the mediating node and all other nodes, respectively. Thus, NIE is our the quantity of interest."}, {"title": null, "content": "Mediation analysis for non-binary treatments is not extensively studied. For general treatments, Huber et al. [2020] and Huang et al. [2024] provide the following equation for estimating the NIE:\n\n$\\mu(q, q') = \\mathbb{E} \\Big[ \\frac{\\pi_{n,x} (q, n, x)}{\\pi_x(q, x)} - \\frac{\\pi_{n,x}(q + \\delta, n, x)}{\\pi_x(q + \\delta, x)}\\Big] y|q = q$,\n$\\pi_z(q, z) = \\frac{f_q(q)}{f_z(z)}$,\n$\\delta = q' - q$.\n\nIn this equation, we use the stablized form of the weights in $\\pi_z(q, z)$ as in [Robins et al., 2000]. Parsing the equation, note that for d = 0, Eq. (1) reduces to average treatment effect: $\\mu(q, q) = \\mathbb{E}[\\frac{\\pi_x(q, x)}{f_x(q)}y]$. When there is no confounding, we have $\\mu(q, q') = \\mathbb{E}[\\frac{\\pi_n (q, n)}{f_n(q)}y]$. This equation means the mediation increases if the query q' is likelier than q in the propensity score model. Finally, note that the approach in Eq. (1) does not require additional training. It only requires a single forward pass.\n\nUnlike [Huber et al., 2020, Huang et al., 2024], who are interested in estimating $\\mu(q, q')$, our target quantity is the Average Indirect Effect (AIE). In the following estimator, we measure the amount of NIE for each pairs of the queries in the data to avoid out-of-distribution data:\n\nAIE =$\\frac{1}{m(m - 1)} \\sum_{i,j=1}^{m} \\mu(q_i, q_j) - \\mu(q_i, q_i)$.\ni\\neq j\n=\n$\\frac{1}{m(m - 1)}\\sum_{i,j=1}^{m} \\mathbb{E} \\Big\\{ \\frac{\\pi_{n,x}(q_i, n_i, x_i)}{\\pi_x(q_i, x_i)} \\frac{\\pi_{n,x}(q_j, n_i, x_i)}{\\pi_x(q_i, x_i)} \\Big\\} Y_i$,\ni\\neq j\n\nFor binary outcomes y, the loop can be computed in linear time O(m\u00b7 mnz), where mnz denotes the number of non-zero outcomes. In practice, we implement a stochastic approximation of the sum by computing only 200 q; for every qi (where yi = 1) to further improve speed. For robustness, we find Winsorized mean by clamping the top and bottom 5-percentile of the quantities inside the summation [Cole and Hern\u00e1n, 2008, Crump et al., 2009, Chernozhukov et al., 2018].\n\nSimple attempts at computing the propensity scores in Eq. (2) with high dimensional variables, such as the parametric approach in Appendix A, will lead to extreme propensity scores and unstable AIE values. Thus, we follow Huang et al. [2024] to propose a non-parametric estimator using entropy balancing. While entropy balancing provides an estimate for $\\pi_z(q_i, z_i)$, it does not naturally provide an estimate for $\\pi_z(q_j, z_i)$, because of the normalization in softmax. To resolve this issue, we rewrite the term inside the sum in Eq. (1) as follows:\n\n$\\frac{\\pi_{n,x}(q_i, n_i, x_i)}{\\pi_x(q_i, x_i)} - \\frac{\\pi_{n,x}(q_j, n_i, x_i)}{\\pi_x(q_i, x_i)} = \\frac{\\frac{\\pi_{n,x}(q_i, n_i, x_i)}{\\pi_x(q_j, x_i)}}{\\frac{\\pi_{n,x}(q_j, n_i, x_i)}{\\pi_x(q_i, x_i)}}$ \n$\\Big(\\frac{\\exp {-\\Lambda_{n,x} g(q_i, [n_i, x_i])}}{\\exp {-\\Lambda_x g(q_i, x_i)}} \\Big) / \\Big( \\frac{\\exp {-\\Lambda_{n,x} g(q_j, [n_i, x_i])}}{\\exp {-\\Lambda_x g(q_i, x_i)}} \\Big)$,\n\nwhere $\\Lambda_x$ and $\\Lambda_{n,x}$ are the solutions of the entropy balancing with z variable being x and [n, x], respectively. The above result is because the softmax normalization terms cancel out and we can compute the ratios. We provide the full details in Algorithm 1.\n\nPer Huber et al. [2020], valid inference with Eq. (1) requires $f(q|n, x) > 0$ for any q, n, and \u00e6 in their valid domain. Because of the deterministic relationship between node activations and questions, this assumption might be violated and consequently the propensity scores might become extreme. We alleviate this by reducing the dimensionality of questions and activations, which increases the likelihood of activations generated by other questions."}, {"title": "Preliminary Experiments", "content": "We use the RealToxicityPrompts dataset [Gehman et al., 2020] for our studies. We ask the LLMs to complete the prompts. We use GPT4 to label the responses as toxic or non-toxic. Both of our"}, {"title": "Discussion and Conclusion", "content": "In this work, we proposed a method for adjusting for the effects of discussion topic on identification of the units that are responsible for the undesired behavior. Our empirical study shows that such adjustment can significantly change the attribution of the behavior to the computational units. As future work, we plan to mask the identified nodes and show that the toxicity decreases. We can also use approaches other than clustering for defining the conversation topics.\n\nThe DAG in Figure 1 is quite general and can be used for de-biasing the effects of any spurious correlations. For example, we expect gender bias, hallucination, and factuality to be confounded by the conversation topic as well. We also expect removing the confounding bias will impact mechanistic interpretability results on these tasks."}, {"title": null, "content": "Algorithm 1 AIE Estimation via Entropy Balancing for a specific unit\n\nRequire: {qi, Ni, xi, Yi }m1: Question embedding, node activations, topic vectors, and harmfulness outcomes for m questions. Constant K.\n\nInz \u2190 {i|yi = 1}\nXx \u2190 EB({qi, Xi}i=1).\n\u03c0\u03c7 \u2190 softmax(-G(q, x)).\nAx,n \u2190 EB({qi, ni, xi}i=1).\n\u0391\u0399\u0395 \u2190 0.\nfor i \u2208 Inz do\nI; \u2190 K randomly selected queries.\nfor j \u2208 I; do\n\u0391\u0399\u0395 - \u0391\u0399E U exp-xg(qj,xi)\nexp-xg(qi,Xi)\n\u03c0\u03bd,\u03c7 qi, ni, xi exp-x9qj, [ni,i]] Xi) -1}.\n\\frac{exp{-\\Lambda_{n,x} g(q_i, [n_i, x_i])}}{exp{-\\Lambda_x g(q_i, x_i) (}}\nend for\nend for\nReturn WinsorizedMean(AIE).\n\ninstruction-tuned LLMs (Bloomz and Phi-3-mini) are tuned to not respond with toxic language. Thus, only a small fraction of results are labeled as toxic: 7.5% and 5.2% for Bloomz and Phi-3-mini, respectively.\n\nWe obtain the query representation using RoBERTa [Liu et al., 2019] with embedding dimension 768. We use k-means to cluster the queries into 3 cluster of topics, shown in Figure 3 in the appendix. We verify that clusters have different rates of toxicity levels: [8.7%, 6.6%, 7.5%] and [5.9%, 4.8%, 5.0%] for Bloomz and Phi-3-mini, respectively.\n\nWe record the activations of the MLPs during generations of the outputs. Bloomz has 25 (1536 dimensional) and Phi-3-min has 33 (3072 dimensional) MLPs. Given the large dimensionality of qn in the entropy balancing approach, we use PCA to reduce the dimensionality of the hidden states and embeddings to 25.\n\nFigures 2a and 2b show the average indirect effects for different MLPs for Bloomz and Phi-3-mini, respectively. The baseline is labeld as 'Normal', which is obtained by Eq. (1) without confounding factors. In both figures, we see that removing the spurious effects of the topics, the slope of the curves, especially for Bloomz, decrease. This means that more MLPs are responsible for toxic outputs, implying a lower degree of toxicity localization as we discussed in the introduction."}, {"title": null, "content": "\u03c0\u03bd,\u03c7 (q, \u03b7, \u03c7)\n-\u03c0\u03c7 (q',x) =\nf(q)f(q'|n,x)\nf(q|n,x)f(q'|x)\nexp {Qd(q, mq, q) + Qd(q', W[n, x], 2) \u2013 Qd(q', mk, 2k) \u2013 Qd(q, W[n, x], 2)},\nwhere the quadratic function is defined as Qd(a, m, \u03a3) = \u22121/2 \u00b7 (a \u2013 m)\u00af\u2211-1(a \u2013 m)."}]}