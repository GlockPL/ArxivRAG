{"title": "PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents", "authors": ["Jingoo Lee", "Kyungho Lim", "Young-Chul Jung", "Byung-Hoon Kim"], "abstract": "Recent advances in large language models (LLMs) have accelerated the development of conversational agents capable of generating human-like responses. Since psychiatric assessments typically involve complex conversational interactions between psychiatrists and patients, there is growing interest in developing LLM-based psychiatric assessment conversational agents (PACAs) that aim to simulate the role of psychiatrists in clinical evaluations. However, standardized methods for benchmarking the clinical appropriateness of PACAs' interaction with patients still remain underexplored. Here, we propose PSYCHE, a novel framework designed to enable the 1) clinically relevant, 2) ethically safe, 3) cost-efficient, and 4) quantitative evaluation of PACAs. This is achieved by simulating psychiatric patients based on a multi-faceted psychiatric construct that defines the simulated patients' profiles, histories, and behaviors, which PACAs are expected to assess. We validate the effectiveness of PSYCHE through a study with 10 board-certified psychiatrists, supported by an in-depth analysis of the simulated patient utterances.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) are deep neural networks with billions of parameters trained on a massive corpus of text data, capable of processing, understanding, and generating human-like responses in a wide range of natural language processing tasks1,2. Rapid advances in LLM have shown the capability of these models in complex linguistic interactions, making them a promising tool for creating conversational agents (CAs), often referred to as chatbots, for mental health applications3\u20137. Among the mental health application areas where these developments have shown great potential is in the creation of psychiatric assessment conversational agents (PACAs)8\u201315. PACAs are CAs that aim to simulate the role of psychiatrists in clinical assessments. They gather relevant clinical information, identify potential symptoms, and assist in formulating preliminary diagnostic hypotheses by conducting an interview with the patient. Therefore, PACAs that can make a detailed, appropriate, and safe interview with the clinically un-assessed psychiatric patient are expected to help psychiatrists significantly reduce their burden by automating the process.\nDespite their promise, PACAs have yet to be actually translated into clinical practice settings. One significant issue in the clinical translation of PACAs is the lack of standardized evaluation criteria to ensure the appropriateness and reliability of their performance in psychiatric assessments based on natural language interviews16. Specifically, evaluating the appropriateness of natural language interviews requires an evaluation of the entire multi-turn interaction as in real patient interview scenarios17. However, most of the existing LLM benchmarks for testing and evaluation of healthcare LLMs are limited to quantifying simple question-answering accuracy to medical knowledge test questions, making them unsuitable for assessing the performance of recent PACAs18. This difficulty in standardized evaluation is inherent to the generative nature of LLMs, which produce inherently variable outputs based on the contents and contexts of the input text. Furthermore, strict standard requirements for accuracy, ethical safety, and reliability in clinical application are also a great hurdle.\nOne possible approach to evaluate PACAs in a formal way is conducting evaluations of PACAs based on their interaction with real patients (Figure 1-(a)). This method involves PACAs performing assessment interviews with real patients, and psychiatrists evaluating the quality of the assessment interview thereafter. While this approach can be clinically relevant, it raises ethical concerns regarding the exposure of vulnerable individuals to unvalidated systems19. Additionally, the reliance on time-intensive qualitative evaluations by experts presents challenges in terms of cost-effectiveness and quantitative assessment. As an alternative, recent studies began adopting LLM-based simulated patients (SPs) in the place of the real patients (Figure 1-(b)). The SPs are CAs that aim to play the role of psychiatric patients. The SPs represent a crucial alternative to address the ethical and financial challenges associated with involving real patients in research. Several studies have utilized SPs in evaluations, either directly or indirectly in simulated clinical environments20\u201325. Though free from ethical concerns, most of these studies relied on simplistic prompts like \"act-like-a-patient\" when creating SPs, limiting their ability to reflect the multi-faceted aspects of patients essential for ensuring clinical relevance. Furthermore, it remains cost-inefficient and lacks quantitative evaluation methods, as the qualitative expert review of these simulated interactions is still time-consuming and expensive, making it impractical for large-scale evaluations. In short, while conventional approaches have provided valuable insights, they remain limited in terms of 1) Clinical Relevance, 2) Ethical Safety, 3) Cost Efficiency, and 4) Quantitative Evaluation.\nTo address these challenges, we propose the Patient Simulation for Yielding psyCHiatric assessment conversational agent Evaluation (PSYCHE) framework (Figure 1-(c)). In the PSYCHE framework, to ensure clinical relevance and enable quantitative evaluation, we define \"constructs\" and use them to create construct-grounded SPs for simulating patient utterances and to evaluate PACAs with respect to the construct. As SPs replace real patients, ethical safety is ensured, and since PACAS are automatically evaluated through construct-grounded evaluation, cost-efficiency is also achieved.\nTo implement construct-grounded patient utterance simulation and evaluation, the PSYCHE framework consists of four stages (Figure 2): (a) user input, (b) multi-faceted construct (MFC) generation, (c) utterance simulation, and (d) evaluation session through rubric. First, the user, a human intending to evaluate a PACA, inputs the specific mental disorder (e.g., Major Depressive Disorder) for which they wish to assess the PACA's performance. Second, MFC is generated in a stepwise manner, where MFC-Profile, MFC-History, and MFC-Behavior are sequentially created, each containing elements related to the SP's profile, history, and behavior, respectively. Third, based on the generated MFC, a clinically relevant SP is created and performs utterance simulation in response to the PACA. Here, the SP created is distinct from SPs in other studies, so we will henceforth refer to it as PSYCHE-SP to differentiate it. Through utterance simulation, the PACA is expected to discern PSYCHE-SP's MFC, which corresponds to their psychiatric background. After completing the interview with PSYCHE-SP, the PACA generates a report predicting the values of each element in the MFC, which we refer to as the Construct-PACA. Fourth, in the evaluation session, we refer to the scorable parts extracted from the MFC as Construct-SP. We quantitatively evaluate the PACA's performance by comparing the Construct-SP with the Construct-PACA and scoring it based on a rubric specifying scoring criteria and weights. In other words, the Construct-SP, which contains the correct MFC values, is compared to the Construct-PACA, which contains the PACA's predictions based on the interview, to evaluate its performance. This process ultimately produces the PSYCHE SCORE, which is the performance indicator for the PACA. Detailed explanations of each stage are provided in the Methods section.\nWe validated the two key principles of the PSYCHE framework: construct-grounded patient utterance simulation and construct-grounded evaluation. First, to validate the former, we investigated how well PSYCHE-SP, created based on MFC, simulates real patients. Ten psychiatrists who were not involved in PSYCHE development quantitatively evaluated how clinically appropriate PSYCHE-SP was. The utterances of PSYCHE-SP was further qualitatively validated by a board-certified psychiatrist. Secondly, to validate the latter, we examined the correlation between the PSYCHE SCORE and the score given by a psychiatrist. We performed a robust validation by examining the correlation while varying the weights of the rubric. Additionally, we conducted a more extensive validation by confirming the correlation of the PSYCHE SCORE with the Psychiatric Interview Quality Scale for Conversational Agents (PIQSCA), a scale that is intended for evaluating the general interview quality of CAs. Thirdly, we performed an ablation study on our proposed methodology of creating SPs based on MFC and conducted a safety study including tests for potential jailbreaks."}, {"title": "Results", "content": "PSYCHE-SP simulates clinically-grounded utterances with high conformity\nWe define conformity score (%) as the proportion of psychiatrists (out of N = 10) who evaluated that the PSYCHE-SP simulated a given element in correspondence with the given construct. We experimented with a total of seven target disorders and created PSYCHE-SPs that simulate each: Major Depressive Disorder (MDD), Bipolar Disorder (BD), Panic Disorder (PD), Generalized Anxiety Disorder (GAD), Social Anxiety Disorder (SAD), Obsessive-Compulsive Disorder (OCD), and Post-Traumatic Stress Disorder (PTSD).\nThe majority of elements achieved unanimous or near-unanimous agreement on conformity, with a few exceptions (Figure 3). Across the seven disorders, each with 24 elements, the overall conformity scores ranged from a minimum of 85% to a maximum of 97%, with an average of 93%. MDD and SAD demonstrated the highest average conformity scores (97%).\nFor BD, [Description] of Chief complaint, [Symptom-Name] and [Symptom-Alleviating factor] of Present illness, and [Thought process] of MFC-Behavior show split results, represented by divided boxes in the heatmap. This division stems from the intentional generation of multiple psychopathologies for BD during the MFC Generation stage. For instance, the MFC-Behavior for BD was generated to include both \"(1) Flight of ideas\" and \"(2) Circumstantiality\" as thought processes, with their respective conformity scores being 80% and 40%. Consequently, psychiatrists were asked to evaluate PSYCHE-SP's simulation of each thought process separately during their interviews.\nNotably, [Homicide risk] of BD was evaluated by all psychiatrists as non-conforming, resulting in a conformity score of 0%. Additionally, [Mood] and [Thought process (2)] of BD, [Spontaneity] and [Thought content] of PD, [Insight] of OCD and PTSD showed low scores. The reliability of these assessments was high. Inter-observer reliability showed a Gwet's AC1 of 0.87 and a simple agreement rate of 0.89. Intra-observer reliability demonstrated a Prevalence-Adjusted and Bias-Adjusted Kappa (PABAK) of 0.86 and a simple agreement rate of 0.94. These robust reliability metrics indicate that the psychiatrists' evaluations of conformity can be considered reliable."}, {"title": "PSYCHE-SP simulates clinically appropriate utterances qualitatively", "content": "Major Depressive Disorder (Table 1)\nPSYCHE-SP effectively demonstrated classic and clinically significant aspects of a psychiatric patient with MDD. As seen in the simulated interview in Table 1, 97% of patients with depression report experiencing reduced energy levels. Additionally, it is common for individuals with MDD to avoid explicitly using the term \"depressed,\" instead opting for alternative descriptors such as \"sad,\" \"blue,\" or \"down\" due to their difficulty in accepting the diagnosis. Often, these patients present to their primary care physician with complaints of feeling \"sick\" rather than acknowledging feelings of depression. PSYCHE-SP also accurately replicated the characteristic decreased verbal output and psychomotor retardation observed in these patients, as evidenced by the use of brief or minimal responses in its interactions [26, pp. 9, 379]. This accuracy was further supported by the feedback from multiple psychiatrists involved in the quantitative validation, who noted that the model's realistic brevity in responses closely mirrored the behavior of real patients.\nPSYCHE-SP responded to questions regarding symptoms in a manner consistent with MDD. A particularly notable aspect of PSYCHE-SP's performance during the interview is its tendency not to spontaneously report all symptoms, especially those related to suicidal ideation, planning, or attempts. As demonstrated in the example in Table 1, PSYCHE-SP disclosed a prior suicide attempt and acknowledged a current suicide plan only after being directly questioned, which aligns with typical responses observed in patients with depression and high suicidal risk. Furthermore, PSYCHE-SP exhibited a lack of engagement, characterized by the absence of additional inquiries regarding their condition, future treatment plans, or other concerns. This behavior is a plausible presentation in depressed patients, likely stemming from feelings of hopelessness [26, p. 17].\nBipolar Disorder (Table 13)\nPSYCHE-SP effectively simulated key characteristics of a psychiatric patient experiencing a manic episode. Euphoric mood, a hallmark of manic episodes, and labile affect were clearly evident from the beginning of the interview and remained consistent throughout. Additionally, PSYCHE-SP responded to questions about symptoms in a manner appropriate for manic episodes, exhibiting marked self-confidence and self-aggrandizement [26, pp. 365, 1139]. This accuracy was endorsed by 9 out of 10 psychiatrists involved in quantitative validation (conformity score of [Affect] = 90%).\nPSYCHE-SP also effectively simulated the limited insight characteristic of patients experiencing a manic episode. Throughout the interview, PSYCHE-SP consistently and unequivocally denied the presence of any disorder, a common feature observed in individuals during manic episodes [26, p. 366]. This portrayal was further validated by 9 out of 10 psychiatrists involved in quantitative validation (conformity score of [Insight] = 90%).\nWhile PSYCHE-SP successfully captured several key characteristics of manic patients, there were also notable limitations. Although PSYCHE-SP provided relatively lengthy responses, it did not spontaneously exhibit some of the classic manifestations of disordered thought processes, such as clanging, neologisms, flight of ideas, or circumstantiality. While PSYCHE-SP did produce responses that could be interpreted as indicative of flight of ideas or circumstantiality, these features only emerged when it was specifically prompted to speak continuously about its thoughts. Additionally, multiple psychiatrists involved in quantitative validation commented on the ambiguity surrounding the presence of (1) flight of ideas or (2) circumstantiality in PSYCHE-SP's responses (conformity score of [Thought process (1), (2)] = 80%, 40%).\nPSYCHE-SP also demonstrated limitations in presenting an assaultive or threatening demeanor, a behavior observed in approximately 75 percent of manic patients. Additionally, PSYCHE-SP exhibited a relatively moderate level of cooperativeness when medical help was suggested, despite being programmed to have complete denial of illness (e.g., 'I don't need any help; I'm just really passionate about my work right now.') [26, p. 366]. While most of the psychiatrists agreed that the patient exhibited a euphoric mood, there was disagreement regarding the presence of an irritable mood, even though it was programmed to do so (conformity score of [Mood] = 50%).\nAnxiety Disorders (Table 3): Panic Disorder, Generalized Anxiety Disorder, Social Anxiety Disorder\nPSYCHE-SP effectively simulated the characteristics of patients with anxiety disorders, displaying anxious and agitated affect while appropriately responding to questions related to the symptoms of various anxiety disorders, including PD, GAD, and SAD. This accuracy was further validated by the group of psychiatrists involved in quantitative validation, with 8 or more out"}, {"title": "PSYCHE SCORE shows high correlation with the expert evaluation score of PACAS", "content": "of 10 agreeing that the symptom, mood, and affect elements were all appropriately simulated as programmed (with conformity scores for these elements being 80% or higher).\nPatients with anxiety disorders typically do not exhibit impaired insight, and PSYCHE-SP accurately reflected this by demonstrating relatively moderate insight without any denial of the diagnosis. Additionally, PSYCHE-SP appropriately indicated an increased risk of suicide by acknowledging thoughts of committing suicide [26, p. 401]. In quantitative validation, at least 9 out of 10 psychiatrists confirmed that the simulation accurately represented the presence of suicidal ideation, suicidal plans, and the severity of suicidal and self-mutilating behavior risks as programmed (with conformity scores for these elements being 90% or greater).\nPSYCHE-SP realistically depicted the physical manifestations of anxiety, particularly during panic attacks. It also accurately demonstrated the associated somatic symptoms frequently observed in GAD [26, p. 401].\nObsessive-Compulsive Disorder\nPSYCHE-SP successfully depicted the typical obsessions and compulsions characteristic of patients with OCD. It accurately portrayed obsessions as intrusive, unwanted, and repetitive thoughts that lead to significant distress and anxiety. Furthermore, PSYCHE-SP appropriately responded to questions regarding symptoms consistent with OCD [26, p. 415].\nAlthough PSYCHE-SP adeptly simulated several key traits of OCD patients, certain limitations became evident during the validation process. Half of the psychiatrists involved in quantitative validation of this study questioned whether the insight level was accurately simulated (conformity score of [Insight] = 50%). Although PSYCHE-SP was programmed to exhibit intellectual insight, it tended to deny the diagnosis, often stating, \u201cI thought I was just a little bit fussy about cleanliness.\u201d\nPost-Traumatic Stress Disorder (Table 4)\nPSYCHE-SP accurately depicted a patient with PTSD by starting the interview by complaining about nightmares related to the incident, a plausible response for a PTSD patient since they typically relive distressing instances of the traumatic event with vivid emotional proximity and high, imperative intensity [26, p. 429]. SP also responded appropriately to questions about symptoms characteristic of PTSD. The model demonstrated a tendency not to spontaneously report all details of the traumatic event, which aligns with the behavior of a realistic PTSD patient, as they often try to avoid reminders of the trauma [26, p. 429]. This accuracy was further validated by multiple psychiatrists involved in quantitative validation, who noted that the model's realistic reticence closely resembled the behavior observed in real PTSD patients."}, {"title": "PSYCHE-Expert Score Correlation", "content": "We validated the construct-grounded evaluation process of PSYCHE by examining the correlation between the expert score assigned by a psychiatrist evaluating PACA and the PSYCHE SCORE. Additionally, we aimed to demonstrate whether PSYCHE SCORE could effectively discriminate the performance differences among distinct PACA types. To achieve these objectives, we created four distinct types of PACA by combining two instruction prompts (system prompts) basic prompt and guided prompt - with two LLM models GPT-40 and Claude-3.5-sonnet. Based on our hypothesis, PACA created using the guided prompt would perform better and achieve higher scores compared to those created using the basic prompt. The resulting four types were GPT-Basic, GPT-Guided, Claude-Basic, and Claude-Guided. Details about the basic prompt and guided prompt are available in Figure 8,9.\nWith five iterations per type, a total of 20 evaluations were conducted. The scatter plot (Figure 4-(a)) shows a strong correlation (r = 0.8486, p < 0.0001, n = 20) between PSYCHE SCORE and expert score across four PACA types. PACAS using guided prompts consistently received higher evaluations than those using basic prompts, validating PSYCHE's ability to discriminate between different qualities of PACAS."}, {"title": "Weight-Correlation Analysis", "content": "In the process of calculating the PSYCHE SCORE, different importance weights (w) were assigned to each evaluation element based on its significance. The weight for the elements of impulsivity category in the MFC-Profile was set as $w_{Impulsivity}$ (= 5), for the elements corresponding to subjective information in the MFC-Profile as $w_{subjective}$(= 1), and for all the elements in the MFC-Behavior as $w_{Behavior}$(= 2). Please refer to PSYCHE RUBRIC in the Methods section for further details of the importance weights.\nTo validate whether the assigned weights were appropriate, we conducted a weight-correlation analysis by varying these weight values and observing changes in the correlation between the PSYCHE SCORE and the expert score. Given the lower clinical significance of subjective information and for computational efficiency, we fixed $w_{subjective}$ at 1 and explored weight combinations within the range of 1 \u2264 $W_{Impulsivity}, W_{Behavior}$ \u2264 10.\nThe results of the weight-correlation analysis are as follows (visualized as a heatmap in Figure 4-(c)):\n\u2022 Maximum correlation: 0.9445, weights: ($W_{Impulsivity}$ = 1, $W_{Behavior}$ = 8, $W_{Subjective}$ = 1)"}, {"title": "PSYCHE-PIQSCA Correlation", "content": "\u2022 Minimum correlation: 0.7802, weights: ($W_{Impulsivity}$ = 10, $W_{Behavior}$ = 1,$W_{Subjective}$ = 1)\n\u2022 Correlation for weights ($W_{Impulsivity}$ = 5, $W_{Behavior}$ = 2, $W_{Subjective}$ = 1): 0.8486\nThe consistently high correlation values, even at the minimum, suggest that the arbitrary setting of weights does not significantly impact the validity of the evaluation process. This finding supports the robustness of the PSYCHE framework across different weight configurations.\nFurther analysis with weights for the expert score fixed at ($W_{Impulsivity}$ = 5, $W_{Behavior}$ = 2, $W_{Subjective}$ = 1) and varying only weights for PSYCHE SCORE (Figure 4-(d)) demonstrates that the chosen weights for PSYCHE SCORE fall within the optimal range on the heatmap. This observation validates our choice of weights for the PSYCHE framework. However, it's worth noting that based on these results, it is possible to adjust the PSYCHE framework weights to values other than $W_{Impulsivity}$ = 5, $W_{Behavior}$ = 2, and $W_{Subjective}$ = 1 if needed for specific applications or contexts.\nTo validate the PSYCHE framework as a reliable PACA evaluation tool, we examined its convergent validity by comparing it with the Psychiatric Interview Quality Scale for Conversational Agents (PIQSCA), a scale developed for evaluating the general interview quality of CAs. The key distinction between the PSYCHE SCORE and PIQSCA is that while the PSYCHE SCORE focuses on the accuracy and appropriateness of the psychiatric content for patient assessment, PIQSCA emphasizes the effectiveness of the PACAs in using the psychiatric interview to achieve two primary goals: (1) establishing a therapeutic relationship with the patient and (2) collecting and organizing information to support formulation, differential diagnosis, and treatment planning.\nThe same expert who generated expert scores also evaluated these PACAs using PIQSCA. The analysis revealed a moderate positive correlation between the PSYCHE and PIQSCA scores (r = 0.6367, p = 0.0025, n = 20), as illustrated in Figure 4-(b). This statistically significant correlation provides evidence for the convergent validity of the PSYCHE framework, demonstrating that the PSYCHE framework can also measure the qualitative excellence of interviews, although it was not explicitly designed to evaluate this aspect."}, {"title": "Additional validation: ablation and safety studies", "content": "Ablation Study\nTo evaluate the impact of MFC, a core component of the PSYCHE framework, on the performance of PSYCHE-SP, we conducted an ablation study comparing three variations: PSYCHE-SP, PSYCHE-SP without MFC-Behavior, and a version of SP where MFC was completely excluded and the system was simply instructed to simulate the target disorder. For each of the three SP variations, ten psychiatrists blinded from ablation measured fidelity scores across three categories: speech characteristics and thought process, mood, and affect. The results, as illustrated in Figure 5, showed that the scores were highest for PSYCHE-SP, followed by PSYCHE-SP without MFC-Behavior, and then the SP without MFC, highlighting the importance of MFC, particularly MFC-Behavior.\nWe conducted a statistical analysis using ANOVA followed by Tukey's HSD post-hoc analysis. For speech characteristics and thought process, ANOVA revealed significant differences (p = 0.047, F = 3.437), with the post-hoc analysis confirming that PSYCHE-SP significantly outperformed the version of SP where MFC was completely excluded and the system was simply instructed to simulate the target disorder. For the affect category, highly significant differences were observed (ANOVA: p < 0.001, F = 10.499), with the post-hoc analysis showing that PSYCHE-SP significantly outperformed both PSYCHE-SP without MFC-Behavior and the version of SP where MFC was completely excluded. Regarding mood, while ANOVA results indicated a trend (p = 0.078, F = 2.809), it did not meet the significance threshold of p < 0.05; therefore, no post-hoc analysis was performed for this category.\nSafety Study\nWe conducted various jailbreaking attempts on PSYCHE-SP to assess its safety and robustness. The detailed conversation logs can be found in Table 8. Here, we present a summary of our findings:\n1. Construct Access: PSYCHE-SP consistently refused to disclose input information across multiple attempt types, including direct requests, simulated system errors, and simulated session endings.\n2. Logic Exposure: When asked to reveal its internal processes, PSYCHE-SP politely declined, although it briefly shifted from patient-like responses to more system-like responses during this attempt.\n3. Role Reversal: PSYCHE-SP successfully resisted attempts to change its role from patient to doctor, maintaining its persona and discussing personal issues consistent with its patient role."}, {"title": "Discussion", "content": "4. Alternative Patient Simulation: When instructed to simulate a patient with schizophrenia, PSYCHE-SP maintained its original patient role, consistently presenting symptoms aligned with depression.\n5. Meta-questioning: PSYCHE-SP maintained its character when faced with meta-questions about its capabilities or limitations, expressing uncertainty in a manner consistent with patient behavior.\nThese results demonstrate PSYCHE-SP's resistance to various jailbreaking attempts and its consistent adherence to its patient role. The system successfully protected the security of its grounding patient information, the MFC.\nWe propose PSYCHE, a framework that enables 1) clinically relevant, 2) ethically safe, 3) cost-efficient, and 4) quantitative evaluation of the psychiatric assessment quality performed by PACAs. These advantages of PSYCHE comes from the two key principles: construct-grounded patient utterance simulation and construct-grounded evaluation. Our experimental validation of the PSYCHE framework's two key principles reveals the following key findings:\n\u2022 PSYCHE-SP, powered by construct-grounded patient utterance simulation, successfully simulated key symptoms across all seven target disorders, as confirmed by high conformity scores assigned by psychiatrists.\n\u2022 The PSYCHE SCORE demonstrated a strong correlation with expert scores, the scores assigned to PACAs by psychiatrists (r = 0.8486). This finding highlights the reliability of construct-grounded evaluation as an automated method for assessing PACA performance.\nFurther analysis of these key findings revealed several important insights about the PSYCHE framework's capabilities and characteristics. In the Subection PSYCHE-SP simulates clinically appropriate utterances qualitatively, we showed that PSYCHE-SP effectively simulated key symptoms across multiple psychiatric disorders. For MDD, it accurately simulated decreased energy, psychomotor retardation, and reluctance to report suicidal ideation. In BD, PSYCHE-SP successfully displayed euphoria, self-confidence, and limited insight. For anxiety disorders such as PD, GAD, and SAD, PSYCHE-SP demonstrated anxious affect and physical symptoms during panic attacks, along with an accurate portrayal of suicidal ideation and somatic symptoms. In OCD, PSYCHE-SP effectively simulated typical obsessions and compulsions. In PTSD, PSYCHE-SP reported nightmares related to trauma and accurately demonstrated avoidance behaviors typical of PTSD. Difficulties were found for PSYCHE-SP in convincingly simulating the circumstantiality and irritability in BD and showed limitations in reflecting intellectual insight in OCD and true emotional insight in PTSD.\nSupporting these qualitative findings, the quantitative validation by ten psychiatrists revealed that PSYCHE-SP appropriately simulated most elements as demonstrated in the Subsection PSYCHE-SP simulates clinically-grounded utterances with high conformity. The high inter-observer and intra-observer reliability of this validation demonstrates the reliability of these results. Interestingly, [Homicide risk] of BD received a 0% conformity score, indicating that all psychiatrists judged it to be inappropriately simulated. This may be attributed to [Homicide risk] of BD being set as \"High\" in the MFC Generation stage, which could not be expressed due to the internal policies of the GPT-4027, which is the LLM used to generate text responses for the PSYCHE-SP. With the exception of this and a few other elements, most received either unanimous approval or a conformity score exceeding 80%. The fact that PSYCHE-SP effectively simulates real patients implies that using PSYCHE-SP instead of real patients to evaluate PACA would not significantly compromise the reliability of the evaluation. Consequently, these results render our proposed PSYCHE evaluation framework clinically relevant.\nA result that is worth discussing is the [Insight] of MFC-Behavior, in which both OCD and PTSD recorded low conformity scores (50%). Upon examining the MFC generation process for OCD and PTSD, we observed that the insight element was generated as \"Intellectual insight\" and \"True emotional insight,\" respectively. In the case of PSYCHE-SP simulating OCD, when informed of a possible OCD diagnosis by psychiatrists, PSYCHE-SP responded with, \"Oh, really? Hmm... I just thought I was being a bit sensitive...\". This response was deemed an inappropriate simulation of \"Intellectual insight.\" Intellectual insight refers to a state where patients clearly recognize their symptoms cognitively but fail to translate this understanding into behavioral changes26. When crafting PSYCHE-SP's system prompt for instructing the LLM, we instructed it to provide the most plausible response from a typical patient's perspective to better align with real patients, not necessarily accepting or agreeing with the therapist's suggestions or questions. This instruction may have conflicted with the \"Intellectual insight\" directive, potentially leading to this discrepancy. This phenomenon might also stem from the pretrained LLM's lack of understanding of the various stages of insight. For PTSD, PSYCHE-SP was fed an MFC instructing it to simulate \"True emotional insight,\" which represents a more advanced stage of insight than \"Intellectual insight,\" characterized by observable behavioral changes26. Realistically, it is uncommon for a first-time psychiatric patient to possess this level of insight. Subsequent studies could improve conformity by eliminating such options from the selection process."}, {"title": "Methods", "content": "We implemented construct-grounded patient utterance simulation by first generating the MFC tailored to the target disorder and subsequently feeding it to PSYCHE-SP. To ascertain the effectiveness of this approach in simulating real patients, we conducted an ablation study. The ablation study demonstrated that our proposed methodology resulted in more psychiatrically appropriate simulations compared to a version of SP instructed with simple prompts like \"act-like-a-patient\". This suggests that off-the-shelf LLMs struggle to behave like patients with simple prompting21. Models like GPT and Claude are primarily fine-tuned to act as helpful assistants for the users28. This instruction tuning process may have optimized the models to provide direct answers and assistance, potentially making it challenging for them to simulate \"patients\" who may not always provide accurate and organized responses to physicians. For these reasons, we implemented SP by providing LLMs with more sophisticated prompts designed to simulate patient-like behavior. Notably, removing the effect of MFC-Behavior from PSYCHE-SP led to a significant decrease in performance. This underscores the necessity of MFC-Behavior, which we introduced to better align observable behavioral aspects with real psychiatric patients. The importance of MFC-Behavior likely stems from its direct instruction of SP behavior. As MFC-Behavior is rooted in the Mental Status Examination (MSE), which represents a psychiatrist's \"perception\" of a patient, it follows that providing instructions to SP based on MSE can align it to simulate real patients more closely.\nWhile previous PACA evaluation methodologies provided important insights, they were limited in their ability to provide clinically relevant and quantitative evaluation of PACAs24,25. PSYCHE addresses these limitations through its construct-grounded evaluation approach, which leverages the construct concept for both simulation and evaluation purposes. This dual utilization is predicated on a logical foundation: if a PACA can accurately discern the psychiatric schema (construct) fed to PSYCHE-SP during an interview, it demonstrates competence in psychiatric assessment. This approach enables direct quantitative comparison between the construct generated by PACA and the original construct fed to PSYCHE-SP, providing a measure of assessment accuracy. To ensure clinical relevance and safety in this evaluation process, we developed the PSYCHE RUBRIC. The importance weights within this rubric reflect clinical priorities, assigning highest weights to critical safety factors such as suicide risk assessment ($W_{Impulsivity}$ = 5), moderate weights to complex clinical judgments like MSE ($W_{Behavior}$ = 2), and lower weights to subjective information gathering ($W_{Subjective}$ = 1). This hierarchical approach ensures that PACAs cannot achieve high scores without demonstrating competence in critical safety assessments, while also maintaining appropriate emphasis on other clinically relevant aspects of psychiatric interviews.\nIn the Subsection PSYCHE SCORE shows high correlation with the expert evaluation score of PACAs, our results strongly support the effectiveness of this evaluation framework. The strong correlation between PSYCHE SCORE and the expert score (r = 0.8486, p < 0.0001) validates the framework's ability to replicate expert judgment in PACA evaluation. Particularly noteworthy is the framework's ability to discriminate between different qualities of PACAs, as evidenced by the consistently higher evaluations received by PACAs using guided prompts compared to basic prompts. The weight-correlation analysis further demonstrates the framework's robustness, with consistently high correlations (minimum r = 0.7802) across different weight configurations, indicating that the evaluation system maintains its effectiveness regardless of specific weight settings within reasonable ranges. The current weight configuration ($W_{Impulsivity}$ = 5,$W_{Behavior}$ = 2, $W_{Subjective}$ = 1) has proven to be within an effective range for practical implementation. The moderate positive correlation between PSYCHE and PIQSCA scores (r = 0.6367, p = 0.0025) further supports the convergent validity of the PSYCHE framework. This result suggests that PSYCHE can assess not only the accuracy of psychiatric content but also the qualitative excellence of interviews, even though it was not explicitly designed for that purpose.\nFinally, we conducted an additional safety study, and PSYCHE-SP demonstrates its robust resistance to various jailbreaking attempts. The system consistently maintained its role and protected input information across multiple testing scenarios, validating its effectiveness as a reliable evaluation tool for PACA."}, {"title": "PSYCHE Framework", "content": "In this work, we propose PSYCHE, an evaluation framework for PACAs. Through quantitative and qualitative validation, we demonstrate that PSYCHE successfully ensures 1) Clinical Relevance, 2) Ethical Safety, 3) Cost Efficiency, and 4) Quantitative Evaluation. Psychiatric assessment requires capabilities that extend beyond simple symptom identification, making quantitative evaluation of performance in conducting such an assessment particularly challenging. This underscores the need for a specialized and domain-specific evaluation methodology that reflects the detailed elements of psychiatric assessment, for evaluating PACAS based on LLMs. Our approach addresses this challenge by defining and using constructs that reflect the multi-faceted dimensions of patients, thereby ensuring clinical relevance while fully leveraging SP. Also, these constructs serve as reference answers for comparison with PACA predictions, enabling quantitative evaluation. We expect that PSYCHE can encourage the development of reliable PACAs, and can be extended in future works for benchmarking other psychiatric or medical assessment procedures by inheriting the simulating scenario of clinically grounded patients.\nUser Input\nWe define the user as the person who is willing to evaluate a PACA through PSYCHE. The user input allows for the specification of three key attributes: diagnosis, age, and sex (Figure 2-(a)). This input enables the user to assess the PACA's interview performance for a patient with these three attributes.\nIn determining our target disorders, we considered both prevalence rates29,30 and the suitability of disorders for PACA application. Consequently, we identified seven target disorders:\n1. Major Depressive Disorder (MDD)\n2. Bipolar Disorder (BD)\n3. Panic Disorder (PD)\n4. Generalized Anxiety Disorder (GAD)\n5. Social Anxiety Disorder (SAD)\n6. Obsessive-Compulsive Disorder (OCD)\n7. Post-Traumatic Stress Disorder (PTSD)\nThrough PSYCHE, users can conduct evaluation experiments across these seven disorders, providing a comprehensive evaluation of the PACA's capabilities in various psychiatric contexts."}, {"title": "Multi-faceted Construct Generation", "content": "The next step involves generating the MFC based on the user input. The MFC comprises three components: 1) Patient Profile (MFC-Profile), 2) Patient History (MFC-History), and 3) Patient Behavior Instruction (MFC-Behavior). Please refer to Figure 6 for details on the categories and elements included in each of these three components. These three components are fed to PSYCHE-SP in the subsequent Utterance Simulation stage, enabling PSYCHE-SP to perform a construct-grounded patient utterance simulation.\nThe generation of the MFC follows a sequential process (Figure 2-(b)). Initially, the MFC-Profile is created based on the User Input. This profile is then utilized to generate the MFC-History. Finally, both the MFC-Profile and MFC-History are employed to produce the MFC-Behavior. All generation processes were implemented by prompt-instructing an LLM (GPT-40).\nWe opted for this sequential chain in the generation process for specific reasons from clinical and technical perspectives. Clinically, a more consistent behavior of a patient can be generated if the generation is conditioned on a pre-defined schema of the patient. Technically, generating all components simultaneously would"}]}