{"title": "A Short-Term Predict-Then-Cluster Framework for Meal Delivery Services", "authors": ["Jingyi Cheng", "Shadi Sharif Azadeh"], "abstract": "Micro-delivery services offer promising solutions for on-demand city logistics, but their success relies on efficient real-time delivery operations and fleet management. On-demand meal delivery platforms seek to optimize real-time operations based on anticipatory insights into citywide demand distributions. To address these needs, this study proposes a short-term predict-then-cluster framework for on-demand meal delivery services. The framework utilizes ensemble-learning methods for point and distributional forecasting with multivariate features, including lagged-dependent inputs to capture demand dynamics. We introduce Constrained K-Means Clustering (CKMC) and Contiguity Constrained Hierarchical Clustering with Iterative Constraint Enforcement (CCHC-ICE) to generate dynamic clusters based on predicted demand and geographical proximity, tailored to user-defined operational constraints. Evaluations of European and Taiwanese case studies demonstrate that the proposed methods outperform traditional time series approaches in both accuracy and computational efficiency. Clustering results demonstrate that the incorporation of distributional predictions effectively addresses demand uncertainties, improving the quality of operational insights. Additionally, a simulation study demonstrates the practical value of short-term demand predictions for proactive strategies, such as idle fleet rebalancing, significantly enhancing delivery efficiency. By addressing demand uncertainties and operational constraints, our predict-then-cluster framework provides actionable insights for optimizing real-time operations. The approach is adaptable to other on-demand platform-based city logistics and passenger mobility services, promoting sustainable and efficient urban operations.", "sections": [{"title": "1. Introduction", "content": "\"Click and pay, soon food is at the doorway\" has become an urban lifestyle nowadays, driving the growth of the meal delivery industry into a global market exceeding 150 billion dollars [1]. The COVID-19 pandemic further accelerated demand due to restaurant closures and government-imposed restrictions. In response, more restaurants joined delivery platforms [1]. However, competition remains fierce among on-demand meal delivery (ODMD) platforms such as DoorDash, Uber Eats, JustEat, and Grubhub, making it crucial for these platforms to deliver exceptional customer experiences. Speed and reliability, particularly in meeting promised delivery times, are critical factors for maintaining customer satisfaction and loyalty [2, 3].\nThe operational flow of ODMD platforms involves multiple interdependent steps. In practice, once an order is placed on the platform, its details are sent to the restaurant for preparation. Meanwhile, a nearby courier receives the task and travels to the restaurant for pick-up. Once the order is ready, the assigned courier will have it delivered to the customer. Key metrics for success in this process are speed, availability, and punctuality. The customer desires less waiting time between the order placement and food arrival. The restaurant expects the meal to remain fresh when"}, {"title": "2. Literature Review", "content": "Demand forecasting has been an important area of interest in both fields of forecasting and operation research for various applications [15, 16, 17, 18]. In subsection 2.1, we highlight the benefits of high-resolution demand forecasting for the operations of on-demand delivery platforms and the challenges associated with high spatial and temporal forecasting granularity. Furthermore, we motivate how clustering can serve as an intermediary step to connect demand forecasts with real-time operations. In subsection 2.2, we discuss key studies on short-term demand forecasting, focusing on methods for handling complex seasonality and their applications, with a particular emphasis on recent advancements in forecasting for on-demand meal delivery (ODMD) services. Next, in subsection 2.3, we review previous literature that presents a spatio-temporal predictive framework for on-demand services by integrating demand forecasting and clustering. Lastly, in subsection 2.4, we address the research gaps in the field and discuss how our study contributes to closing these gaps."}, {"title": "2.1. Challenges in operating on-demand meal delivery services with demand predictions", "content": "Real-time operations, such as fleet rebalancing and order-matching, are central to the efficiency of on-demand meal delivery services. These operations are highly time-sensitive due to the limited lead time inherent in last-mile delivery. If the prediction horizon exceeds the operational completion time and is updated infrequently, the resulting demand forecasts may become outdated and unreliable, compromising optimization outcomes. Additionally, real-time rebalancing and order matching strategies that rely on specific locations may not fully leverage forecasted demand information for a larger service area. This indicates that demand forecasts should process a comparable temporal and spatial granularity to the target operations. Effective and forward-looking decision-making for these real-time operations requires location-specific, up-to-date demand predictions alongside accurate fleet information. Compared to forecasts over broader areas or longer horizons, fine-grained temporal and spatial demand forecasting provides"}, {"title": "2.2. Methods and applications of short-term demand forecasting for on-demand services", "content": "Dynamic demand predictions usually involve time-series data, comprising a sequence of data points measured at regular intervals over a period. Unlike cross-sectional data, time series observations typically vary with recent observations in sequence. Depending on the product, demand data may exhibit trends and seasonality patterns. Recent time-series applications on supply chain demand forecasting are reviewed by Seyedan et al. [19]. Generally, there are two types of forecasting models based on predictive features, the univariate model with only the historical demand as input, and the multivariate model where external information (e.g., weather) is jointly used for prediction [20].\nTraditional univariate time series models, such as exponential smoothing and its variants like Holt-Winter and SARIMA, have been successfully applied to short-term forecasting tasks, particularly when dealing with data exhibiting single seasonality. SARIMAX, an extension of SARIMA that incorporates external features, has further improved forecasting performance in applications like short-term load demand prediction [21]. However, traditional models face significant challenges with data that exhibit complex or lengthy seasonal patterns. These limitations stem from the increasing parameter space required for longer seasonal periods, leading to higher computational costs, and the subjective nature of parameter selection. To address these challenges, De Livera et al. introduce a trigonometric exponential smoothing state-space model named TBATS [22]. TBATS is specifically designed to address multiple seasonality while automatically optimizing model parameters. It has been effectively applied to forecasting tasks such as daily gas consumption [23] and demand at electric vehicle charging stations [24].\nWith advancements in machine learning, non-linear multivariate methods such as random regression forest (RF), gradient boosting machines (GBM), and neural networks (NNs) have gained traction in short-term demand forecasting due to their ability to handle non-linear relationships and multivariate inputs [25]. Studies demonstrate their superior performance in tasks with complex seasonality. For instance, Dudek [26] applied random forests to forecast short-term load demand with multiple seasonal cycles. Albrecht et al. [27] compared RF, SVM, KNN, and GBM in real-time call-center arrival forecasting, finding ensemble models consistently outperformed traditional time-series methods. These"}, {"title": "2.3. Combined prediction and clustering framework for on-demand services", "content": "Integrating clustering with demand time series and geographical information across multiple service areas has received significant attention in recent literature. Many studies explore the advantages of cluster-then-predict framework to improve demand forecasting performance for on-demand mobility services[11, 33, 34, 35]. This hierarchical approach reduces the randomness in demand observations by aggregating demand from similar areas at a cluster level. Consequently, the demand predicted by a cluster-based forecasting model tends to be more robust than modeling individual areas with sparse demand. Chen et al. [11] propose a dynamic cluster-based forecasting approach to predict the over-demand probability for clustered areas in the city. They introduce a clustering method that considers geographical proximity, historical demand patterns of service areas, as well as the ongoing special events at the predicted time step. Kim [35] introduces a spatial continuity-constrained hierarchical clustering method to generate clusters for bike-sharing traffic prediction. This study defines two grids to be spatially contiguous if the shortest path between them does not pass through any other grids with bike-sharing stations.\nOn the other hand, the outcomes from clustering can be used to generate insights into the demand landscape within the service network over time [36, 10]. Liu et al. [36] use K-Means clustering with historical demand patterns and location data to identify which districts were historically more likely to have supply surplus and deficits at different periods for a ride-hailing service. To minimize the duration of time when vehicles are unavailable, Caggiani et al. [10] propose a dynamic clustering method to assist relocations of vehicles. Their approach jointly considers the geographical proximity, availability of vehicles, and received demand of service areas as clustering inputs. They show that the efficiency of fleet relocation is enhanced by utilizing dynamic zoning instead of static zoning."}, {"title": "2.4. Research Gaps", "content": "Upon reviewing the existing literature, we have identified several research gaps in demand forecasting for on-demand meal delivery. Firstly, the current literature on short-term demand forecasting is limited, particularly for prediction horizons and update frequencies of less than an hour. To the best of our knowledge, most studies focus on the hourly demand forecasting problem for ODMD [7, 6, 8, 9]. Demand forecasting for intervals shorter than an hour remains largely unexplored. Secondly, few efforts have been made to estimate the uncertainty of demand. The quantification of demand uncertainty has been proven to be the key to the success of operation policies by recent literature on on-demand mobility services [37, 38, 39]. Liang et al. [8] introduce a probabilistic prediction approach based on the Poisson assumption for the arrival of orders. However, this assumption might not fully capture real-life"}, {"title": "3. Problem Description", "content": "In this section, we outline the research questions explored in this paper and introduce the datasets used for our empirical case studies. In Section 3.1, we provide the formulation of our research problems, followed by the definitions of key terminologies in Section 3.2. Finally, Section 3.3 provides an overview of our empirical case studies: a European case study and a Taiwanese case study."}, {"title": "3.1. Research problem formulation", "content": "In this study, we aim to introduce a predict-then-cluster framework to accurately forecast demand across multiple service zones in the city and subsequently cluster similar zones to identify future demand coldspots and hotspots within the service network of a meal delivery platform. Figure 1 provides an overview of the workflow for the proposed framework. The framework utilizes real-time multivariate inputs, such as date-time, weather, and order information, to identify recent demand patterns. Data from multiple sources is processed into zone-wise data arrays, which are fed into pretrained zone-specific predictive models for short-term demand forecasting. The predicted short-term demand for each zone, combined with its location information, serves as input for dynamic clustering. The resulting clusters highlight areas with similar future demand, offering actionable insights to support real-time operational decisions, such as reallocating delivery couriers to zones with high anticipated demand.\nTo summarize, the proposed framework comprises two components: short-term demand forecasting and dynamic clustering. The forecasting step aims to efficiently generate accurate short-term demand predictions using the latest demand and contextual information, leveraging a computationally efficient predictor to make optimal use of limited data. These demand predictions then serve as inputs for the clustering step, where service zones with similar predicted demands are grouped based on operational requirements such as geographical contiguity or proximity. The resulting clusters are designed to enhance delivery efficiency by meeting these practical constraints. Additionally, the dynamic clusters generated from predicted demand should closely resemble those formed using actual demand, thereby validating the robustness and accuracy of the predictive model."}, {"title": "3.2. Definitions", "content": "We consider a platform's service region to be divided into local service zones. In practice, these service zones are typically represented as equal-shaped grids within a city. Based on functionality, a service zone $z_i$ is called a pick-up"}, {"title": "4. The Short-Term Predict-then-Cluster Framework", "content": "This section outlines the design of the proposed short-term demand predict-then-cluster framework for on-demand meal delivery services. Section 4.1 introduces the models selected for short-term demand forecasting within this framework. For the dynamic generation of clusters based on predicted demand, two clustering approaches, Constrained K-Means Clustering (CKMC) and Contiguity Constrained Hierarchical Clustering with Iterative Constrained Enforcement (CCHC-ICE), are introduced in Section 4.2."}, {"title": "4.1. Short-term demand forecasting for on-demand meal delivery services", "content": "In this subsection, we introduce the selected tree-based ensemble learning models and benchmark regressors for deterministic and distributional demand forecasting of meal delivery services in Sections 4.1.1 and 4.1.2, respectively. Next, we describe the proposed lagged-dependent extension for ensemble learning predictors in Section 4.1.3."}, {"title": "4.1.1. Deterministic short-term demand forecasting models", "content": "Tree-based ensemble-learning methods, such as random forest regression (RF) and XGBoost regression, have shown promising performance in deterministic hourly demand forecasting for meal delivery services[9] and other short-term demand forecasting applications [46, 27, 28]. These methods are recognized for their robustness, interpretability, and efficiency, outperforming neural networks in various forecasting tasks [47, 48]. Ensemble methods like RF and XGBoost handle challenging datasets, such as intermittent time series with frequent zeros, common in short-term meal delivery demand. By using decision trees as base learners, they partition data into scenario-specific subsets based on input features, effectively capturing complex patterns. This capability enables them to deliver robust and accurate predictions, even for irregular or extreme demand patterns where conventional regression methods often struggle. Therefore, this study focuses on RF and XGBoost for deterministic forecasting. Detailed formulations and pseudocode for RF and XGBoost are provided in Appendix B.1 and Appendix B.2, respectively.\nTo benchmark the performance of the ensemble methods, we include widely used time series models such as SARIMA, SARIMAX, and TBATS, which have demonstrated state-of-the-art performance in demand forecasting tasks across various domains [49, 50, 51, 52, 53]. Detailed descriptions of these benchmarks are presented in Appendix B.4. In practice, many meal delivery platforms do not yet implement demand forecasting. A simple yet naive alternative is to use the most recent observation as the prediction for the next time interval. This approach, referred to as the myopic predictor, is also included as a benchmark for deterministic demand forecasting."}, {"title": "4.1.2. Distributional short-term demand forecasting models", "content": "Distributional demand predictions offer two key advantages. First, they allow the use of the median of the predicted distribution as a point estimate. Unlike traditional regression methods that default to predicting the mean, median-based predictions are less influenced by extreme values or outliers, resulting in more robust performance. Second, distributional predictions quantify demand uncertainty, providing critical insights that enable platforms to optimize operational policies more effectively. To leverage these benefits, we apply quantile regression forest (QRF), a distributional forecasting variant of RF introduced by Meinshausen [54]. QRF generates robust point predictions while also capturing uncertainty through demand quantiles. It has demonstrated strong performance in various applications, including short-term electricity demand forecasting [55] and online grocery retailing demand [56]. Detailed pseudocode and explanations for QRF are provided in Appendix B.3.\nAs a benchmark, we include the Seasonal Quantile (Seasonal) predictor to evaluate the distributional forecasting performance of QRF methods. The Seasonal predictor segments historical demand data by hour and day of the week to create time-dependent empirical distributions for each pick-up zone. Quantile predictions are then generated based on these seasonally conditioned distributions, providing a baseline for evaluating the effectiveness of the proposed methods."}, {"title": "4.1.3. Lagged-dependent ensemble-learning models for short-term demand forecasting", "content": "Although seasonal variables can be selected from past data observations, there may be uncovered factors that can significantly impact demand levels. For instance, demand could rise because of restaurant promotions or during the break of a popular football game. The demand may also decrease temporally due to platform or restaurant decisions to limit demand because of insufficient staff. To address this issue, we propose to include the lagged-dependent (LD) features, which are the recent demand observations, in the decision-tree-based ensemble-learning models.\nThe inclusion of past observations has shown potential in traditional time series and machine learning methods. The autoregressive (AR) model identifies a linear relation between the target variable y, and its recent observations. The regression function of AR only includes the previous observations, a constant, and the error term. Subsequence time series clustering aims to detect reoccurring patterns of time series subsequence and utilize these patterns for prediction. The approach uses a sliding window to divide a long time series into subsequences, which are then clustered based on similarity measurements [57]. Both models leverage groups of neighboring observations as proxies for predicting the target variable.\nInspired by AR and time series subsequence clustering models, we propose incorporating four lagged-dependent terms $y_t, y_{t-1}, y_{t-2}, y_{t-3}$ as additional temporal features to capture the demand fluctuations. Trained with these additional lagged-dependent features, extended ensemble-learning models LD-RF, LD-XGBoost, and LD-QRF, are introduced in our study. The advantage of LD extension is that the model can leverage insights summarized from recent demand observations to enhance forecasting performance, without requiring extensive efforts in model training and data collection. Compared to subsequence time series clustering, LD extension does not need to train a separate clustering method for time series subsequences. Additionally, it offers a preferable solution over SARIMA models by retaining fast computing, non-linearity, and robustness properties of decision-tree-based ensemble-learning methods."}, {"title": "4.2. Dynamic predict-then-cluster framework for demand cold- and hotspots forecasting", "content": "In this study, we introduce a predict-then-cluster framework to generate dynamic clusters for identifying predicted demand cold- and hotspots within the service network of a meal delivery platform. These outcomes offer a dynamic spatial overview of short-term demand across the city, adapting to fluctuations in demand. Firstly, short-term demand predictions for the next 15 minutes are generated according to one of the forecasting models discussed in the previous subsection 4.1. Next, the predicted demand and the geographical information for all zones are jointly taken as input to the clustering process. This dynamic predict-then-cluster approach groups similar pick-up zones together, providing predictive insights into demand clusters for the upcoming 15 minutes.\nIn this research, we introduce two types of clustering approaches to apply in the predict-then-clustering framework: Constrained K-Means Clustering (CKMC) and Contiguity Constrained Hierarchical Clustering with Iterative Constraint Enforcement (CCHC-ICE). These approaches are particularly useful for generating dynamic, map-based insights to support managerial decision-making. CKMC groups similar zones into larger, cohesive units for managerial operations by enforcing a minimal cluster size constraint. This allows operators to dynamically define operational"}, {"title": "4.2.1. Constrained K-Means Clustering", "content": "By measuring the similarities among clusters with both location and predicted demand information as inputs, CKMC helps monitor the spatial distribution of over-demand/under-supplied areas. CKMC utilizes K-Means clustering to group zones into clusters. This approach partitions a high-dimensional space spanned by data points into clusters by identifying representative centroids for each cluster. The algorithm assigns each data point to the nearest centroid, aiming to minimize the within-cluster variance. K-Means assumes the clusters to be approximately spherical and evenly sized. It is suitable for scenarios where managerial clusters are created to direct the platform on resource allocation and improve operational efficiency, such as fleet rebalancing and demand management.\nIn CKMC, the geographical proximity between two pick-up zones is measured by the distance between their grid centers. For each zone, the latitude and longitude of its grid center are included as static geographical features. The predicted demand features for clustering are dynamic, which are provided from the previous prediction step within the predict-then-cluster framework for the target 15-minute time window t for each pick-up zone. Depending on the forecasting approach in the prediction part of the predict-then-cluster framework, the type of predicted demand features may vary. Particularly, demand uncertainty can be taken into account at the clustering phase by using multiple quantile predictions from QRF and LD-QRF. The distance measure for CKMC is defined as,\n$d(x_i, x_j) = \\sqrt{\\sum_{k=1}^{K} w_k(x_{i,k} - x_{j,k})^2}$,\ngiven input feature vectors of any two pick-up zones i and j. Predefined weight parameter $w_k$ is allocated to each feature k to control its relative importance in the distance measure.\nDistance measures are utilized in the clustering process to assess the similarity between elements. The smaller the distance between two elements, the more similar they are. For the predict-then-cluster experiment with QRF and LD-QRF, we consider applying 0.25, 0.50, and 0.75 quantile predictions of each pick-up zone to measure the predicted demand similarity. Equal weights are allocated to each geographical and predicted demand feature. The distance measure can be further simplified as\n$d(x_i, x_j) = \\sqrt{(lat_i - lat_j)^2 + (lng_i - lng_j)^2 + \\sum_{q = 0.25, 0.50, 0.75} (\u0177_i^q - \u0177_j^q)^2}$.\nOperator users of the predict-then-cluster framework can also finetune the hyperparameters, including the number of quantile predictions and the corresponding weights allocated to these features, based on the optimization performance in specific use cases. For the other experiment with point predictions as input to clustering, the weight for the predicted demand feature is tripled to keep the relative importance of location input the same as before. In this case, the distance measure follows,\n$d(x_i, x_j) = \\sqrt{(lat_i - lat_j)^2 + (lng_i - lng_j)^2 + 3 \\times (\u0177_i - \u0177_j)^2}$.\nBefore clustering, all features are normalized to the same scale. Silhouette coefficient is a clustering performance metric, calculated based on the distance measure $d(x_i, x_j)$. It is applied to compare the similarity of a sample within its current cluster to other clusters [58]."}, {"title": "4.2.2. Contiguity Constrained Hierarchical Clustering with Iterative Constraint Enforcement", "content": "Along with cluster-specific conditions such as the number of clusters and cluster sizes, geographical contiguity is often a critical requirement for supporting operations. This condition ensures connectivity within each cluster, guaranteeing that all zones from the same cluster are directly accessible to one another. However, while methods like CKMC"}, {"title": "5. Experiments and Results", "content": "This section presents the design and computational results of the short-term predict-then-cluster experiments for on-demand meal delivery case studies. Subsection 5.1 details the experiment design, including the model training and prediction generation process, input features, and evaluation scheme of the experiments. Section 5.2 compares and analyzes the computational efficiency of our selected forecasting and clustering algorithms. Subsection 5.3 presents the performance of deterministic and distributional demand forecasting for the European and Taiwanese use cases. Lastly, Subsection 5.4 presents the results of dynamic clustering using demand predictions."}, {"title": "5.1. Design of Case Studies", "content": "This subsection begins by detailing the input features selected for demand forecasting. It then provides an overview of the model training and prediction generation processes, followed by an explanation of the evaluation schemes used for both demand forecasting and clustering experiments."}, {"title": "5.1.1. Features for short-term demand forecasting", "content": "Based on the analysis from Section 3, we propose to utilize three types of input features for the short-term demand forecasting of on-demand meal delivery services. These are the temporal features, weather features, and lagged-dependent features which are the previous observations of demand."}, {"title": "5.1.2. Model training and prediction generation", "content": "For the European case, the original dataset contains orders gathered over 22 weeks. The testing set is derived from the demand series of the final week in the dataset, containing 308 data points to be predicted for each pick-up zone. In reality, platforms often have a limited amount of historical data available for training in some cases, particularly for a fast-expanding platform with new pick-up zones established over time. This challenge can hinder the quality of both univariate time series predictors and ensemble learning-based predictors. To explore the impact of training data size, we prepare two training datasets of different lengths to fit the demand forecasting models and compare their performance for the European case study. The larger training set contains the first 21 weeks' demand data (6468 data points) for each pick-up zone, while the other training set includes only the demand series from the four weeks (1232 data points) preceding the testing period. Utilizing the date-time details of order transaction data, we can retrieve the historical hourly weather features and generate temporal features. These features are then matched to each data point in the training and testing sets.\nFor the Taiwanese use case, the original dataset pre-defines that historical orders from the first 76 days are included in the training set, while orders from the final 14 days are part of the testing set. It results in 7296 and 1344 data points in the training and testing sets respectively. As in the European case study, we pre-process these orders to create the target demand variable and lagged-dependent input features, along with the hour and day-of-the-week features based on the order placement time.\nIn the experiments, zone-specific demand forecasting predictors learn the unique demand pattern processed by each pick-up zone. These models are fitted to the training set of each pick-up zone. The parameter selection for TBATS is done automatically by the algorithm. To prevent overfitting of ensemble-learning models, hyperparameters are fine-tuned during the model training phase following a 10-fold cross-validation process. The list of hyperparameters considered for tuning and their candidate values are detailed in Table C.8 in Appendix C. For SARIMA and SARIMAX modeling, only one seasonal periodicity can be selected due to algorithmic limitations. For computational complexity concerns, we use a daily seasonal periodicity with 44 and 95 observations for the European and Taiwanese use cases, respectively The optimal orders and parameters for SARIMA and SARIMAX are selected via a grid-search process.\nDemand predictions in our experiments are generated for each time interval from the testing set without model retraining for the ensemble learning approaches. For the point forecasting experiments in the European case study, we include benchmark models, baseline ensemble-learning models RF, XGBoost, QRF, and their lagged-dependent"}, {"title": "5.1.3. Evaluation Scheme", "content": "To evaluate point demand forecasting performance, we use common metrics including Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) to assess the magnitude of errors, and Root Mean Squared Logarithmic Error (RMSLE) to measure relative errors. Temporal stability of predictions is analyzed using the standard deviation of residuals (Resid. std.), calculated as the difference between actual and predicted values. For distributional demand forecasting, we report the mean Continuous Ranked Probability Score (MCRPS) across instances. The formulations of MAE, RMSE, RMSLE, and MCRPS are provided in Appendix F.\nFor each metric, the summarized evaluation metric V is computed as the average value of metric V across all pick-up zones, defined as $V = \\frac{1}{N} \\sum V_i$. The computation of selected metric $V_i$ follows the descriptions in Appendix F. To assess spatial stability, we also report the standard deviation of metric values across pick-up zones. Additionally, to evaluate overfitting, we provide in-sample forecast performance of ensemble learning models using the average MAE.\nThe predictive cluster insight generated from the short-term predict-then-cluster framework can inform key strategic decisions, such as determining the required fleet size for each cluster or prioritizing fleet relocation to high-demand areas, thereby reducing the need for micro-level management of individual zones. More importantly, these forecasted clusters should reflect the shifting spatial demand dynamics across the city to improve the efficiency of real-time operations. Therefore, in this study, we focus on evaluating how well the forward-looking clusters, generated using predicted demand, align with the ideal scenario where clusters are generated based on actual demand. For each pick-up zone, we analyze the extent to which the anticipated demand level with its cluster may differ due to demand forecasting errors introduced to the framework. Instead of evaluating the quality of clustering outcomes based on downstream operational performance, we measure the perceived estimated demand deviations between the predicted and actual clusters to assess the framework's predictive accuracy.\nTo perform this evaluation, we first generate the 'actual' clusters using the actual demand and geographic information of pick-up zones. Next, to identify the actual cluster-level demands, we compute the 'actual within-cluster median demand' as the median demand of the cluster it belongs to in the current time window. Similarly, we compute the 'predicted within-cluster median demand' using the predicted clusters formed with forecasted demand. The differences between actual and predicted within-cluster median demand are evaluated using metrics such as MAE, RMSE, RMSLE, and Resid. std. By comparing these metrics, we can evaluate how closely the predicted clustering outcomes approximate the ideal clustering based on actual demand, providing insights into the predictive clustering framework's effectiveness in real-world applications."}, {"title": "5.2. Numerical implementation", "content": "Computational efficiency is a key consideration in model selection. On-demand service providers need scalable models to support their extensive service network and favor models that can quickly generate predictive insights within real-time operations. To analyze the computational efficiency of our proposed algorithms, in the section, we"}, {"title": "5.3. Results of short-term point and distributional demand forecasting", "content": "This subsection presents the point forecasting performance for selected short-term demand forecasting models."}, {"title": "5.3.1. Point forecasting in the European case study", "content": "The predictive performance of selected models for the European case study is summarized in Table 3, evaluated using the metrics MAE, RMSE, RMSLE, and Residual standard deviation (Resid. std.).\nAmong the benchmark predictors, SARIMA and SARIMAX models trained with the 4-week demand series have obtained the highest prediction accuracy and best performance stability. Notably, the performance of SARIMAX is similar to that of SARIMA, with a slightly higher MAE. This suggests that the additional contextual information in SARIMAX may not have been effectively leveraged to enhance the quality of forecasting. Among the ensemble-learning (EL) models trained with 4-week data, LD-QRF and QRF achieved the lowest MAE and RMSLE respectively using median predictions. LD-QRF also had the smallest average in-sample MAE. Notably, LD-RF excelled with the lowest RMSE and residual variance.\nFor models trained with 21-week data, lagged-dependent models performed best in all metrics, with LD-QRF achieving the lowest in-sample MAE, MAE, and RMSLE. While LD-RF had the lowest RMSE, its MAE was higher, suggesting fewer large errors but more small deviations, as supported by the standard deviations. Nevertheless, we"}, {"title": "5.3.2. Point forecasting in Taiwanese case study", "content": "The short-term demand point forecasting results for the Taiwanese use case are presented in Table 4. Given historical date information is unavailable for the Taiwanese use case, only hour and day-of-the-week features are available, along with the lagged-dependent information extracted from the demand series. Therefore, we include only lagged-dependent ensemble-learning approaches for comparison against the benchmarks.\nThe values of MAE, RMSE, and Residual Standard Deviation are higher in the Taiwanese use case compared to the European case, primarily due to higher average demand per 15-minute interval and the limited availability of contextual information for the ensemble learning models. Among the benchmarks, the TBATS and Seasonal Average models exhibit similar forecasting accuracy, both outperforming the Myopic predictor. Notably, all lagged-dependent ensemble learning models outperform the benchmarks in terms of MAE, RMSE, and Resid. std., with LD-XGBoost and LD-QRF achieving the highest overall prediction accuracy."}, {"title": "5.3.3. Distributional forecasting performance", "content": "To investigate the distributional forecasting capability of the proposed short-term distributional demand predictors QRF and its lagged-dependent extension LD-QRF, we estimate their MCRPS values and compare them with the Seasonal distributional forecasting benchmark. If QRF and LD-QRF models more accurately capture the underlying demand distribution, utilizing weather conditions and sequential fluctuations in demand, they will exhibit lower MCRPS values compared to the Seasonal benchmark."}, {"title": "5.4. Performance of short-term predict-then-cluster in the European case study", "content": "From the previous experiment, we have found that the lagged-dependent ensemble-learning models are able to generate accurate point predictions. In the dynamic predict-then-cluster framework, we combine the geographical information and the predicted demand information of pick-up zones as inputs to the proposed Constrained K-Means Clustering (CKMC) and Contiguity Constrained Hierarchical Clustering with Iterative Constraint Enforcement (CCHC-ICE) approaches to generated predicted demand hot- and coldspot insights of the service network. To evaluate how the quality of demand predictions influences the outcomes of each clustering approach, we measure the difference between predicted and actual within-cluster median demand value for each pick-up zone, as detailed in Subsection 5.1. In our experiments for the predict-then-cluster framework, we use point demand predictions from forecasting algorithms SARIMA, SARIMAX, QRF, LD-RF, LD-XGBoost, and LD-QRF. These predictive models have shown competitive short-term forecasting performance. Additionally, we use quantile predictions from QRF and LD-QRF to provide insights on demand uncertainties for the clustering approaches."}, {"title": "5.4.1. Short-term predict-then-cluster with CKMC", "content": "Table 6 presents the dynamic clustering performance using CKMC, evaluated by the differences between actual and predicted within-cluster median demands, using metrics such as MAE, RMSE, RMSLE, and the standard deviation of residuals. Among the benchmark methods, SARIMA achieves the highest hotspot forecasting accuracy based on point predictions. For ensemble-learning models trained on 4-week data, QRF using median predictions attains the lowest average MAE, RMSE, and RMSLE. In the demand point forecasting experiments, QRF has obtained the"}, {"title": "5.4.2. Short-term predict-then-cluster with CCHC-ICE", "content": "Table 7 presents the evaluation of clustering performance using CCHC-ICE approach. Compared to CKMC, the application of CCHC-ICE results in higher metric values due to the additional constraints imposed by contiguity and operational requirements during cluster formation. Variations in actual versus predicted demand data can significantly influence the formation of clusters throughout the hierarchical process. The CCHC-ICE outcomes show improved performance when using EL demand predictors within the predict-then-cluster framework, yielding lower metric values compared to SARIMA or SARIMAX predictors. This improvement is more pronounced when EL models are trained on 21-week data, as extended training data enhances the clustering accuracy. Overall, clustering outcomes generated using distributional predictions align more closely with clusters formed using actual demand. Among the tested approaches, quantile predictions from QRF and LD-QRF trained on 21-week data achieve the best results: QRF delivers the lowest average MAE, while LD-QRF achieves the lowest RMSLE. However, with limited training data (4 weeks), the less precise quantile predictions from QRF and LD-QRF may lead to reduced clustering performance, as demand uncertainty is not fully captured. Interestingly, the lowest RMSE and Resid. std. are obtained using LD-XGBoost as the point demand predictor. However, its slightly higher MAE and RMSLE suggest that LD-XGBoost"}, {"title": "5.4.3. Example visualization of the short-term predict-then-cluster outcomes", "content": ""}]}