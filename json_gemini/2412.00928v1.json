{"title": "A Deep Generative Model for the Design of Synthesizable Ionizable Lipids", "authors": ["Yuxuan Ou", "Jingyi Zhao", "Austin Tripp", "Morteza Rasoulianboroujeni", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"], "abstract": "Lipid nanoparticles (LNPs) are vital in modern biomedicine, enabling the effec-\ntive delivery of mRNA for vaccines and therapies by protecting it from rapid\ndegradation. Among the components of LNPs, ionizable lipids play a key role in\nRNA protection and facilitate its delivery into the cytoplasm. However, designing\nionizable lipids is complex. Deep generative models can accelerate this process\nand explore a larger candidate space compared to traditional methods. Due to\nthe structural differences between lipids and small molecules, existing generative\nmodels used for small molecule generation are unsuitable for lipid generation. To\naddress this, we developed a deep generative model specifically tailored for the dis-\ncovery of ionizable lipids. Our model generates novel ionizable lipid structures and\nprovides synthesis paths using synthetically accessible building blocks, addressing\nsynthesizability. This advancement holds promise for streamlining the development\nof lipid-based delivery systems, potentially accelerating the deployment of new\ntherapeutic agents, including mRNA vaccines and gene therapies.", "sections": [{"title": "1 Introduction", "content": "The successful development of COVID vaccine paved the way for the clinical application of lipid\nnanoparticles (LNPs) to deliver different kinds of messenger RNA(mRNA) [Wilson and Geetha, 2022;\nHou et al., 2021]. The standard structure of LNPs includes four main components: ionizable lipids,\ncholesterol, helper lipids, and PEGylated lipids [Biochempeg, 2024]. Ionizable lipids are critical\nas they condense the negatively charged mRNA during LNP formulation and help it escape from\nendosomes and enter the cytoplasm of target cells to express the protein of interest [Xu et al., 2024;\nCarrasco et al., 2021]. An ionizable lipid is an amphiphillic molecule with an ionizable, hydrophilic\nhead and several hydrophobic tails [Chaudhary et al., 2021].\nDesigning ionizable lipids is time-consuming and labor-intensive. Combinatorial chemistry provides\na fast and cost-effective method to produce these lipids in large quantities, which allows researchers\nperform high-throughput screenings of ionizable lipids [Li et al., 2023]. For example, by using a\nUgi-based three-component reaction (3-CR), researchers can rapidly generate a library of 1,080\nionizable lipids [Xu et al., 2023]. This collection can assist in identifying an ionizable lipid for\nthe application of interest such as activation of stimulator of interferon genes (STING), which is\nuseful for delivering mRNA vaccines. However, despite these advances, the method has limitations.\nThe diversity of ionizable lipids generated remains constrained due to the restricted range of lipid\nheads and tails available. Therefore, designing and testing a broader and more diverse range of lipids\nremains challenging.\nMachine learning methods, particularly generative models, provide a solution for efficiently exploring\nvast molecular search spaces [G\u00f3mez-Bombarelli et al., 2018; Kusner et al., 2017; Bradshaw et al.,\n2019; Qiang et al., 2023; Bradshaw et al., 2020b]. These models capture the distributions of existing\nmolecules, learn how molecular structures correlate with their physical properties, and use this\nknowledge to predict new molecules. Various generative models have been proposed for molecule\ndesign, capable of generating new molecules through either molecular graphs or string representations\n[Bilodeau et al., 2022]. Despite significant advances in machine learning for drug discovery, previous\nworks have shown that generative models are prone to producing molecules which chemists find very\ndifficult to synthesize [Bradshaw et al., 2020b].\nExisting research in machine learning for LNP design primarily focuses on predicting LNP trans-\nfection efficiency [Li et al., 2023; Xu et al., 2023; Ding et al., 2023; Moayedpour et al., 2024]. In\ncontrast, our work addresses the generation of ionizable lipids. Specifically, we adapt an existing\napproach, Synthesis-DAGs [Bradshaw et al., 2020b], which simultaneously generates molecules and\ntheir synthesis routes, to the task of generating synthesizable ionizable lipids [Gao and Coley, 2020].\nOur main constributions are as follows:\n\u2022 Extract a broad range of synthetically accessible building blocks for ionizable lipid and\nconstruct an ionizable lipid synthesis dataset for training the generator.\n\u2022 Develop a generator capable of producing ionizable lipids along with their synthesis path-\nways from the building blocks.\n\u2022 Iteratively fine-tune the generator to identify optimal ionizable lipid structures with synthesis\npathways for high mRNA transfection efficiency in HeLa cells."}, {"title": "2 Background", "content": "In this section, we first introduce the generator on which our work is based, Synthesis-DAGs, then\nwe introduce the mRNA transfection efficiency prediction model used in the optimization process."}, {"title": "2.1 Synthesis-DAGS", "content": "Synthesis-DAGs is a general molecule generator that our method builds upon [Bradshaw et al., 2020a].\nIt can generate molecules along with their synthesis pathways. Below, we briefly introduce how\nSynthesis-DAGs work.\nRepresenting Synthesis Paths as DAGs Synthesis routes are represented as directed acyclic\ngraphs (DAGs). Examples are shown in Figure 3. Building blocks are displayed in blue boxes. These\nbuilding blocks undergo chemical reactions to form intermediate products, shown in light purple\nboxes. Finally, the final product is generated, shown in dark purple boxes."}, {"title": "Serializing the Construction of DAGs as Action Sequences", "content": "The DAGs are serialized into action\nsequences by defining three classes of actions: Node-addition, Building block molecular identity, and\nConnectivity choice. Every molecule in the DAG is considered a node and is classified as either a\nbuilding block node or a product node. The Node-addition action determines which type of node\nto add. Building block molecular identity specifies which molecule to choose from the building\nblock pool. Connectivity choice decides which nodes to connect to the next product and whether that\nproduct is an intermediate product or final product."}, {"title": "Modeling the Probability Distribution of the Action Sequence", "content": "A shared RNN models the\ndistribution of the action sequence. At each step, the RNN computes a context vector, which is passed\ninto a feedforward action network to predict the next action. There are three action networks in total,\none for each action class. In order to feed the action sequence into the RNN model, the actions are\nconverted into action embeddings. The detailed action types, action choices and action embeddings\nare listed in Table 1."}, {"title": "Reaction Predictor", "content": "During sampling, a reaction predictor is used to perform reaction prediction at\nthe product nodes. In Synthesis-DAGs, Molecular Transformer is used for this task [Schwaller et al.,\n2019].\nIn this work, we focus on adapting Bradshaw's Synthesis-DAGs model for use as an ionizable lipid\nDAG generator. The limitations of directly applying the original method to lipid generation and the\ndetailed adaptations we made are discussed in Section 5."}, {"title": "2.2 AGILE framework", "content": "When optimizing ionizable lipids for high mRNA transfection efficiency, we use the AGILE model\n[Xu et al., 2024] to predict the mRNA transfection efficiency of our generated ionizable lipids. The\nAGILE model is a deep learning framework designed to predict the transfection efficiency of ionizable\nlipids in specific cells. It is part of the AI-Guided Ionizable Lipid Engineering (AGILE) platform.\nThe training process of the prediction model occurs in two stages. First, a graph encoder is pre-trained\non a virtual library of 60,000 chemically diverse lipids using contrastive learning. In the second stage,\nthe model is fine-tuned with wet-lab mRNA transfection efficiency data. We use the model fine-tuned\non data with mRNA transfection efficiency in HeLa cells as labels to make predictions."}, {"title": "3 Lipid Property Predictors", "content": "Our method relies on both a lipid classifier and an ionizable lipid classifier to determine whether the\ngenerated product is a lipid or an ionizable lipid. In this section, we introduce the lipid classifier, a\nbinary classification model that determines whether a molecule is lipid-like. We then explain how\nionizable lipids are identified by examining their net charge at physiological and acidic pH."}, {"title": "Lipid Classifier", "content": "The architecture of our lipid classifier is based on the message passing neural\nnetworks framework, Chemprop [Yang et al., 2019]. It consists of three message passing layers\nto integrate molecular features, followed by two feedforward layers for property prediction. The\ntraining dataset includes 180,000 lipids and 180,000 non-lipid molecules. Lipid data are sourced from\npublic datasets LIPID MAPS and SwissLipids, as well as synthetic data generated using graph-based\nstructural motifs [Sud et al., 2006; Aimo et al., 2015; Jin et al., 2020]. Non-lipid molecules are\nobtained from the PubChem database [Kim et al., 2015]. Our classifier demonstrates excellent\nperformance, achieving both a Receiver Operating Characteristic Area Under the Curve (ROC-AUC)\nscore and a Precision-Recall Area Under the Curve (PR-AUC) score above 0.9999."}, {"title": "Ionizable Lipid Classifier", "content": "Ionizable lipids carry a positive charge at acidic pH, enabling them to\ncondense RNAs into LNPs, but are neutral at physiological pH to minimize toxicity [Han et al., 2021].\nTo filter based on this criterion, we consider the net charge at pH 5 (acidic) and pH 7.4 (physiological).\nThe net charge is calculated by first estimating the pKa values of the lipid's acidic and basic groups\nusing MolGpka [Pan et al., 2021], followed by applying the Henderson-Hasselbalch equation to\ndetermine the lipid's net charge at both pH values."}, {"title": "Property Predictors Validation", "content": "To further validate our lipid property predictors, we curated a\ndataset of over 2,500 ionizable lipids sourced from previously published studies [Li et al., 2023; He\net al., 2023; Liu et al., 2021; Abd Elwakil et al., 2023; Yu et al., 2020; Wei et al., 2023]. Importantly,\nthis dataset is entirely independent of the training data used for our lipid classifier. Using this dataset,\nwe evaluated the predictors' performance, with the lipid classifier achieving a high accuracy of\n98.32%. Additionally, the ionizability predictor demonstrated exceptional performance, accurately\nclassifying all ionizable lipids in the dataset."}, {"title": "4 Dataset Construction", "content": "In this section, we first explain how we select synthetically accessible ionizable lipid building blocks\nby detailing the filtering criteria used to choose lipid heads and tails from the ZINC20 dataset of\nsynthetically accessible components. After forming a building block pool, we demonstrate how we\nsynthesize ionizable lipids based on these building blocks and construct the ionizable lipid synthesis\ndataset."}, {"title": "4.1 Building Block Extraction", "content": "We begin the construction of an ionizable lipid synthesis dataset by creating a building block set of\nionizable lipid heads and tails. To ensure that all building blocks are synthetically accessible, we\nselect them from the ZINC20 dataset [Irwin et al., 2020], a publicly available database that includes\ncommercially available compounds. We apply three filtering criteria to identify the ionizable lipid\nheads. The first criterion is molecular weight; since most lipids, including heads and tails, have a\nmolecular weight of no more than 1000 g/mol. We set our limit at no more than 500 g/mol. The\nsecond criterion is about solubility preference, selecting compounds with a LogP value less than zero,\nwhere LogP represents the log of the partition coefficient between octanol, a hydrophobic oil, and\nwater. The third criterion focus on charge characteristics; we seek ionizable heads that maintain a near-\nzero charge at physiological pH and become positively charged in acidic environments. Compounds\ncontaining a nitrogen atom in their structure are likely to meet this ionization requirement. Thus, the\nthird criterion involves selecting molecules that contain amine groups. By applying these criteria, we\nidentify a set of 2.7 million ionizable head molecules.\nAs for selecting lipid tails, we aim to ensure that the molecule structurally resembles a lipid tail, and\nthe tail set is diverse. We initially use LipidAnalyzer (a toolbox already implemented) to extract tails\nfrom the LIPID MAPS[Sud et al., 2006]. LIPID MAPS contains 48,548 unique lipid structures. From\nthese, we extract a total of 8,176 unique lipid tails. To ensure that all the lipid tails are synthetically\naccessible, we find similar lipid tail molecules in the ZINC dataset based on these extracted tails. The\nsearch tool we use called \u2018cartblanche' [CartBlanche22, 2024]. We measure similarity by calculating\nthe graph edit distance (GED) between two molecules, which involves finding the minimum number\nof graph operations needed to transform one graph into another. The second search criterion is\nthat at least one of the molecule's Tanimoto similarity coefficients must be greater than 0.5, using\neither Daylight fingerprints or ECFP4 fingerprints. After identifying all synthetically accessible"}, {"title": "4.2 Lipid Synthesis Dataset Construction", "content": "After obtaining the synthetically accessible lipid heads and tails, our next step is to generate ionizable\nlipids with multiple tails. In this study, we focus on lipids with 1-3 tails. We start by identifying\nlipid heads that are most likely to react with the selected lipid tails. An analysis of the lipid tails\nrevealed the functional groups with high occurrences, among which the top three functional groups\nthat can react with those in the tails are the carboxylic acid group, amine group, and hydroxyl group.\nConsequently, we further refine our selection of ionizable heads based on a combination of these\nthree functional groups. Specifically, we require the lipid head to contain 1-3 functional groups to\nfacilitate chemical reactions that attach the tails. This count of 1-3 functional groups excludes the\namine group used to ensure ionizability.\nWe synthesize ionizable lipids by sequentially adding lipid tails to lipid heads. The chemical reactions\nthat combine a lipid tail with a lipid head or an intermediate product are simulated using Chemformer\n[Irwin et al., 2022], a reaction prediction model. After the final tail addition, the product is formed.\nWe first apply the lipid classifier to determine if it is a lipid. If classified as a lipid, we then apply the\nionizable lipid classifier to assess its ionizability."}, {"title": "5 Synthesizable Ionizable Lipid Generator", "content": "In this section, we explain why the original Synthesis-DAGs method cannot be directly applied to\nlipid generation and describe the adjustments we made to address these limitations."}, {"title": "Limitations of the Synthesis-DAGs Method in Generating Ionizable Lipids", "content": "We sampled 1,000\nmolecules using the original Synthesis-DAGs model trained on the USPTO reaction dataset [Schneider\net al., 2016]. Of these, only 53 were classified as lipids, and 13 as ionizable lipids. This low efficiency\nindicates that the original model cannot be directly applied to ionizable lipid generation. One clear\nreason is that the USPTO reaction dataset is not lipid-specific. Additionally, the reaction predictor in\nSynthesis-DAGs fails to accurately predict reactions between lipid tails and heads [Schwaller et al.,\n2019]. Example predictions from the Molecular Transformer are shown in Figure 2. As seen, the\nMolecular Transformer tends to make copy-paste errors when predicting reactions between large\nmolecules, highlighted in the blue boxes. It incorrectly alters structures that are not involved in the\nchemical reaction. For instance, in the first reaction, the location of the carboxylic acid and the ring\nstructure consisting of five carbons and one nitrogen are both altered on the lipid head (shown in the\nbottom blue box), while a ring structure is incorrectly added to the lipid tail (shown in the top blue\nbox)."}, {"title": "5.1 Ionizable Lipid Synthesis Dataset", "content": "Using the method outlined in Section 4, we generated an ionizable lipid synthesis dataset to ensure the\nmodel is trained specifically in the domain of ionizable lipids. The dataset contains 70,536 synthesis\npaths and includes 43,741 building blocks, comprising 38,431 unique lipid heads and 5,310 unique\nlipid tails. We randomly split the dataset into training, validation, and test sets, with 63,480, 3,582,\nand 3,582 data points, respectively. The training set includes 5,905 one-tail, 21,301 two-tail, and\n36,274 three-tail ionizable lipids."}, {"title": "5.2 A Better Reaction Predictor", "content": "To address the limitations of Molecular Transformer, we adopted Chemformer, a more advanced\nTransformer-based sequence-to-sequence model [Irwin et al., 2022]. Chemformer takes reactant\nSMILES strings as input and outputs the predicted SMILES string of the product. It is initially\npre-trained on approximately 100 million SMILES strings from the ZINC15 dataset [Sterling and\nIrwin, 2015], followed by fine-tuning on the USPTO-MIT dataset [Jin et al., 2017], which includes\naround 470,000 reactions.\nWe selected Chemformer for several key reasons. First, Chemformer is state-of-the-art for reaction\nprediction on the USPTO Mixed and USPTO Separated benchmarks [Manohar Koki and Kancharla,\n2023]. Second, Chemformer significantly reduces copy-paste errors, examples are shown in Figure\n2. For example, in these two examples, Chemformer makes accurate predictions without altering\nstructures not involved in the reaction.\nApart from these two adjustments, the generator's structure, training, and sampling methods remain\nthe same as in Synthesis-DAGs [Bradshaw et al., 2020b]."}, {"title": "6 Experiments", "content": "In this section, we present the experimental results. First, we introduce the baseline methods used for\ncomparison. Next, we describe the experiment implementation. Finally we show results and analysis."}, {"title": "6.1 Baselines", "content": "Random Generation Random generation involves selecting a lipid head and one to three lipid\ntails at random, followed by sequential chemical reactions using Chemformer to combine them. This\nmethod generates raw training data without filtering for lipid property predictors, as described in\nSection 4. The key difference between this approach and ours lies in how the building blocks are\nselected. We refer to this baseline as 'Random + Chem'\nOriginal Synthesis-DAGs Trained on Our Ionizable Lipid Synthesis Dataset We mentioned in\nSection 5 that one of the reasons the original Synthesis-DAGs cannot be used to generate ionizable\nlipids is due to the training data. Now, we compare our method (refered as DAG + Chem), which is\ntrained on the ionizable lipid dataset and using Chemformer as reaction prediction, to the original\nSynthesis-DAGs model, which was trained on our generated ionizable lipid dataset. Because this\nmodel uses DAGs to represent synthesis paths and employs the Molecular Transformer in the sampling\nprocess to predict reactions, we refer to this baseline as 'DAG+MT'. The only difference between our\nmethod and this baseline is the reaction predictor used.\nSynthesis List Generation: A Linear Structure to Represent the Synthesis Path Analyzing the\nsynthesis paths in our training dataset reveals a linear process, characterized by the following steps:\n\u2022 Adding a lipid head.\n\u2022 Sequentially adding lipid tails that react to generate intermediate or final products."}, {"title": "Based on this linear progression, we developed a linear synthesis pathway generator.", "content": "This approach\nsimplifies the representation of the synthesis process as a linear list, compared to DAG-based methods.\nThe structure of the list is as follows:\n[building block node, building block node, product node, building block node, product node, ...]\nEach item in the action sequence represents a molecule's index, with action embeddings corresponding\nto the molecule embeddings. At each product node, the context vector is input into a binary\nclassification network to determine whether to stop the list generation. This baseline investigates the\nimpact of different synthesis pathway representations. All other model components, including the\nreaction predictor (Chemformer), remain the same as in our approach. We refer to this baseline as\n'List + Chem'."}, {"title": "6.2 Experiment Implementations", "content": "The ionizable lipid generator operates in two stages: training and sampling. During training, a\nreaction predictor is not required, but it is used in the sampling stage. The reaction predictor is hosted\non a Flask server running the Chemformer model. The generator sends requests to the server, which\nperforms inference and returns the results. Each model is trained for 10 epochs using the Adam\noptimizer with a learning rate of 0.0001. During sampling, we draw 100 batches from the trained\nmodel, with each batch requesting 200 samples. However, the actual number of generated products is\nlower due to failures in the reaction prediction model. The experiments were conducted on a Tesla\nP100 GPU with 16GB of memory."}, {"title": "6.3 Experiment Results", "content": "We analyze the ability to generate ionizable lipids in terms of generation efficiency and quality, as\nshown in Table 2 and Table 3, respectively. Table 2 presents the ionizable lipid generation rate and\nlipid generation rate for different methods. In Table 3, we evaluate the validity (whether the generated\nSMILES can be parsed by RDKit [RDKit, 2024]), uniqueness (whether the generated molecules\nare different from one another), novelty (whether the generated molecules different from training\ndata), FCD (Fr\u00e9chet ChemNet Distance, whether the generated samples have similar chemical and\nbiological properties to those of the training data) [Preuer et al., 2018], Synthetic Accessibility score\n(SA score) [Ertl and Schuffenhauer, 2009]. In Figure 3, we present four examples of the generated\nionizable lipids along with their synthesis paths."}, {"title": "6.3.1 Method Performance", "content": "As illustrated in Table 2 and Table 3, our ionizable lipid generator performs well in terms of both\nthe ionizable lipid generation rate and the lipid quality. The ionizable lipid rate among all generated\nsamples reaches 83.4%, significantly surpassing that achieved through random generation ('Random +\nChem'). Regarding quality analysis, validity, uniqueness, and novelty are notably high. Furthermore,\nthe relatively low Fr\u00e9chet ChemNet Distance compared to other methods indicates that, although\nthe ionizable lipids generated by our method differ from those in the training set, their chemical and\nbiological properties remain within the same distribution, demonstrating successful generalization."}, {"title": "6.3.2 The Impact of Reaction Predictor Performance", "content": "This comparison focuses on using Chemformer as the reaction predictor versus using Molecular\nTransformer ('DAG + Chem' vs. 'DAG + MT'). Our method significantly outperforms 'DAG + MT'\nin both lipid rate and ionizable lipid rate. The lower efficiency of Molecular Transformer as a reaction\npredictor has a substantial impact on the generation of ionizable lipids [Manohar Koki and Kancharla,\n2023]. Chemformer possesses approximately 45 million trainable parameters, which is substantially\nmore than the 12 million parameters in Molecular Transformer. Generally, a larger number of param-\neters can enhance model performance due to increased learning capacity. Moreover, Chemformer\nundergoes a two-stage training process. It is initially pre-trained in a self-supervised manner on 100\nmillion SMILES strings from the ZINC15 database before being fine-tuned on downstream tasks. In\ncontrast, Molecular Transformer is trained directly on a downstream dataset without the intermediary\nstep of pre-training. This direct approach may limit its ability to thoroughly learn the SMILES syntax,\nwhich is essential for predicting correct chemical structures [Duan et al., 2020]. Thus, the use of\npre-trained models, which have already developed a foundational understanding of SMILES syntax,\nis critical for accurate prediction of chemical products."}, {"title": "6.3.3 The Impact of Data Structure Representing Synthesis Pathway", "content": "In Table 2, the third comparison between 'DAG + Chem' and 'List + Chem' shows that the DAG\ngenerator outperforms the linear method in generating both lipids and ionizable lipids. While the\nuniqueness and novelty metrics are nearly identical for both methods, the DAG generator achieves a\nlower FCD score, indicating that the lipids produced more closely match the training distribution.\nThe primary reason for this is that DAG representations include diverse action embeddings, providing\nricher information to the RNN, which helps generate more accurate hidden states for decision-making.\nAdditionally, DAGs can model more complex synthesis routes, particularly those involving reactions\nof intermediate products."}, {"title": "6.4 Optimization Towards Ionizable Lipids With High Transfection Efficiency", "content": "We have developed an ionizable lipid version of Synthesis-DAGs. Our next goal is to optimize these\nlipids to enhance mRNA transfection efficiency in specific target cells. In Bradshaw's approach\n[Bradshaw et al., 2020b], the Synthesis-DAGs model is capable of iterative optimization to generate\noptimal novel molecules along their synthesis pathways. For this experiment, we utilized the AGILE\nprediction model, which estimates mRNA transfection efficiency in HeLa cells [Xu et al., 2023].\nTo ensure compatibility with AGILE, we constrained our generator to produce only two-tail lipids,\nconsistent with the lipids studied in AGILE's research. Additionally, to improve lipid stability, we\nrestricted lipid tail lengths to 10 carbons or longer. In each iteration, we sampled 5,000 new DAGs\nfrom the model and selected the top 1,000 DAGs based on predicted transfection efficiency. The\nmodel was then fine-tuned for two rounds using these selected DAGs. Figure 4 shows the distribution\nof the top 1000 transfection efficiency scores for ionizable lipids sampled from the model before and\nafter 1-6 fine-tuning iterations. Before iteration 4, we observe an increasing trend in transfection\nefficiency as fine-tuning progresses. This shift demonstrates the ability of our method to identify\noptimal lipid structures for mRNA delivery to HeLa cells while maintaining synthesizability. However,\ncontinuing the iterative fine-tuning process does not guarantee a consistently increasing transfection\nefficiency, as a decline is observed between iteration 4 and iteration 3. Figure 4 also includes 8\nexamples of ionizable lipids with the highest transfection efficiency sampled during iteration 3."}, {"title": "7 Conclusion", "content": "In this work, we constructed a comprehensive ionizable lipid synthesis dataset from ZINC's syn-\nthetically accessible compounds, consisting of over 70,000 synthesis paths. Using this dataset, we\ndeveloped a deep generative model that achieved an 83.4% success rate in generating structurally\ndiverse and synthesizable ionizable lipids, complete with synthesis paths. We also demonstrated the\npotential to identify ionizable lipids with high mRNA transfection efficiency in target cells.\nThis study highlights the application of deep generative models in ionizable lipid synthesis, combining\nadvanced computational techniques with specific chemical synthesis challenges. Our approach\nefficiently generates synthesizable ionizable lipids, showing promise for advancing lipid-based RNA\ndelivery systems.\nHowever, it is crucial to recognize the limitations of this study. First, the validity of the predictors,\nincluding the property predictors and the reaction predictor, directly impacts the reliability of the\ngenerated synthesis DAGs. Second, the validity of the proposed synthesis pathways has not been\nevaluated in this work. We aim to address these issues in future research.\nIn future work, we will collaborate with organic chemists to synthesize the most promising ionizable\nlipids identified by our model and validate their mRNA transfection efficiency in wet lab experiments.\nThis will contribute to building a more comprehensive ionizable lipid library to support the design of\nmRNA delivery systems."}]}