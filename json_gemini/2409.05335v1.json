{"title": "A Multi-Modal Deep Learning Based Approach\nfor House Price Prediction", "authors": ["Md Hasebul Hasan", "Md Abid Jahan", "Mohammed Eunus Ali", "Yuan-Fang Li", "Timos Sellis"], "abstract": "Accurate prediction of house price, a vital aspect of the residential real estate\nsector, is of substantial interest for a wide range of stakeholders. However, pre-\ndicting house prices is a complex task due to the significant variability influenced\nby factors such as house features, location, neighborhood, and many others.\nDespite numerous attempts utilizing a wide array of algorithms, including recent\ndeep learning techniques, to predict house prices accurately, existing approaches\nhave fallen short of considering a wide range of factors such as textual and\nvisual features. This paper addresses this gap by comprehensively incorporating\nattributes, such as features, textual descriptions, geo-spatial neighborhood, and\nhouse images, typically showcased in real estate listings in a house price prediction\nsystem. Specifically, we propose a multi-modal deep learning approach that lever-\nages different types of data to learn more accurate representation of the house.\nIn particular, we learn a joint embedding of raw house attributes, geo-spatial\nneighborhood, and most importantly from textual description and images repre-\nsenting the house; and finally use a downstream regression model to predict the\nhouse price from this jointly learned embedding vector. Our experimental results\nwith a real-world dataset show that the text embedding of the house advertise-\nment description and image embedding of the house pictures in addition to raw\nattributes and geo-spatial embedding, can significantly improve the house price", "sections": [{"title": "1 Introduction", "content": "The global economy is significantly influenced by the real estate market. The global\nreal estate market is projected to attain an impressive value of US$637.80 trillion by\nthe year 2024. Across many countries, owning a home is consid-\nered a major life milestone and represents the most valuable asset in an individual's\nlife. Consequently, the evaluation of house prices, a vital aspect of the residential real\nestate sector, holds substantial interest for a wide range of stakeholders, including\nprospective buyers, sellers, real estate professionals and financiers. However, predict-\ning house prices is a complex task due to the significant variability influenced by\nfactors such as property characteristics, location, neighborhood attributes and many\nothers. In this paper, we introduce an innovative approach based on multi-modal deep\nlearning, which effectively utilizes available data from typical real estate company web-\nsites, encompassing details such as house attributes, descriptions, images and more,\nto achieve highly accurate house price predictions.\nConsidering the huge impact of this problem domain in real life, many house\nprice prediction methods have been proposed over the years, e.g.,[1]. Earlier methods\nsuch as the Hedonic Price models [2] used different house features such as the num-\nber of bedrooms, kitchens, balconies, washrooms, etc. to predict house prices. Later\nmodels incorporate spatial features along with house features to predict prices [3-5].\nHowever, these approaches suffer from the limitations of explicit feature engineering\nthat require the direct involvement of domain experts. To alleviate this limitation,\nseveral machine learning and deep learning model techniques have been proposed [6-\n9]. Among these techniques, the recently proposed Geo-Spatial Network Embedding\n(GSNE) method [10] shows that by incorporating key spatial and neighborhood fea-\ntures such as schools and train stations, it can significantly improve the house price\nprediction accuracy.\nThe recent successes of multi-modal deep learning techniques in the fields of com-\nputer vision and natural language processing (NLP) [11-14] have inspired us to explore\nthe utilization of additional house-related features to further enhance the accuracy of\nhouse price predictions. We have observed that typical real estate websites provide\ninformation including house features, the surrounding neighborhood (including loca-\ntion and points of interest), a concise textual description and a collection of images\nshowcasing the property. These elements collectively assist users in making informed\ndecisions when selecting a suitable house. Figure 1 illustrates a typical real estate\nagent's flyer for a house, featuring four key components: (1) house features (e.g., num-\nber of bedrooms, bathrooms, area), (2) spatial neighborhood features (e.g., location,"}, {"title": "2 Related Work", "content": "House price prediction has garnered substantial attention within the research com-\nmunity, prompting a thorough exploration of diverse methodologies. This inves-\ntigation has primarily unfolded across three principal categories: location-centric\nmethodologies, machine learning-based strategies and conventional methodologies that\nemphasize dwelling attributes.\nTraditional Approaches: Early endeavors in predicting house prices were rooted\nin the principles of hedonic regression [2]. Subsequent research endeavors expanded\nupon this foundational model to forecast prices across distinct markets and scruti-\nnize the impacts of various variables [15-18]. The hedonic price model conceptualizes\nhouses as amalgams of multiple attributes, with consumers purchasing bundles of these\nattributes. However, while this method simplifies the prediction process, it exhibits\ncertain limitations. Notably, hedonic pricing coefficients for specific features display\ninstability across diverse locations, property types and ages [19]. Furthermore, issues\npertaining to model specification, interactions among independent variables, non-\nlinearity and the presence of outlier data points curtail the efficacy of hedonic price\nmodels [20]. Genetic algorithms have also been explored in the context of predict-\ning home prices, where a hybrid approach combining genetic algorithms and Support\nVector Machines (SVM) has been deployed [21], alongside another study investigating\nthe potential of genetic algorithms in this domain [22]. Furthermore, genetic algo-\nrithms have been harnessed to examine the influence of geographic location on various\noutcomes, with evolutionary polynomial regression recently applied to housing price\nmodeling [23].\nMachine Learning Approaches: Acknowledging the achievements of machine\nlearning models across diverse prediction tasks, researchers have embraced a spectrum\nof machine learning approaches for home price prediction. Support Vector Machine\n(SVM) regression was employed to compute house prices in [24] and [25], while\nLasso and Ridge Regression were enlisted for price prediction in [26]. Artificial Neu-\nral Network (ANN)-based models have exhibited superior performance compared to\nhedonic price models in out-of-sample predictions [20]. A comprehensive study eval-\nuated multiple machine learning methods, encompassing ANN, AdaBoost, Random\nForest, Gradient Boosted Trees, Multi-Layer Perceptron and ensemble learning algo-\nrithms, determining Gradient Boosted Trees as the most effective in predicting home\nprices [27]. Deep learning techniques, such as Convolutional Neural Networks (CNN),"}, {"title": "3 Methodology", "content": "In this section, we provide a comprehensive description of our methodology MHPP.\nOur MHPP model is designed to forecast house prices by leveraging a rich set of\nfeatures, including raw house feature, geospatial context, textual descriptions and\nimages of the house. The raw features encompass factors like room count, bathrooms,\nbalconies, gardens and more. The geospatial context accounts for the impact of location\nand nearby points of interest (POIs) such as schools, train stations, colleges, shopping\nmalls and more on house prices.\nOur prediction system begins by extracting feature information from the geospatial\ncontext, textual description and images of houses. We refer to this extracted feature\ninformation as \"embedding\". Subsequently, we concatenate this embedding with the"}, {"title": "3.1 Geo-spatial Context Embedding", "content": "The location of a house, along with proximity to key points of interest such as train\nstations, bus stops and schools, plays a crucial role in determining the house price.\nA recent study, Geo-Spatial Network Embedding(GSNE) method introduced in [10],\nrecognized this significance and developed an embedding technique that incorporates\nthe geographical context of houses with the raw house features. In our research,\nwe employed the GSNE to extract geo-spatial neighborhood features embedding for\npredicting house prices.\nThe nodes within this geo-spatial graph represent houses and a\nspecific subset of POIs, encompassing entities like schools, bus stations, or shops. The\nedges within this graph are forged based on spatial characteristics, connecting pairs\nof nodes if their distance falls below a user-defined threshold, denoted as dmax. For\neach edge $e_{ij} \\in E$, its weight is computed as $w_{ij} = \\delta(\\frac{d_{max}}{d(i,j)})$, where d(i, j) quantifies the\nEuclidean distance between nodes i and j.\nThe GSNE leverages both the first and second-order proximity. The first-order\nproximity ($f_k$) captures information from direct connections between node pairs across"}, {"title": "3.2 Text Embedding", "content": "The detailed descriptions of houses, presented in plain text in an advertisement, offer\nan abundance of intricate information that are absent in the listed house raw features.\nFigure 4(d) shows some red-colored texts that cannot be captured by the raw features\nof the houses. These features that include some intricate details of some attribute, aes-\nthetic features, etc., play a significant role in influencing the prices of various houses."}, {"title": "3.3 Image Embedding", "content": "In this section, we explain how the available images can be used as a potential house\nfeatures for house price prediction. House images provide clear visual evidence of a\nproperty's condition, layout and surroundings. They also evoke emotion and aspiration\nin potential buyers or renters, making the decision-making process more informed. As\nan illustration, in Figure 4(e), we can see that combining house images with textual\ndescriptions provides a clearer understanding of the house's interior.\nWe use a multimodal language model known as Contrastive Learning Image Pre-\ntraining (CLIP) [13] to extract image embeddings from the pictures of houses. CLIP\nutilizes a joint training strategy to simultaneously train both image and text encoders.\nThe objective of this integrated training is to guide the image encoder towards\ngenerating embeddings that closely align with the text embeddings.\nTo train the image encoder $I_{enc}$, we employ the self-supervision technique [14]\nwithin the CLIP framework, which involves training a batch of b (image, text) pairs,\nwith CLIP determining which of the $b \\times b$ possible pairs correspond to each other. To\nachieve this, the text and image encoders are jointly trained to maximize the cosine\nsimilarity of embeddings for the b real pairs in the batch, while minimizing the cosine\nsimilarity of embeddings for the $b^2 - b$ incorrect pairs. To supervise the image encoder,\nwe utilize a text encoder $T_{enc}$ based on the distilBert model [37], while the image\nencoder is based on the Resnet50 model [38]. We optimize a symmetric cross-entropy\nloss function based on these similarity scores.\nThe image encoder $I_{enc}$ generates an encoded representation $I_f$ for each batch of\naligned images I, while the text encoder $T_{enc}$ creates an encoded representation $T_f$\nfor each batch of aligned textual descriptions T of the houses.\n$I_f = I_{enc}(I)$\n$T_f = T_{enc}(T)$\nAfter finding the encoded image feature $I_f$ and text feature $T_f$, the image projector\n$I_{proj}$ and the text projector $T_{proj}$ are used to embed them into the same dimension.\nThis involves employing the image projector $I_{proj}$ to generate an image embedding\n$I_E$ from the encoded image feature $I_f$ and the text projector $T_{proj}$ to produce a text\nembedding $T_e$ from the encoded text feature $T_f$."}, {"title": "3.4 Fusing Diverse Embeddings and Raw Features", "content": "In the preceding subsections, we obtain geospatial network embedding (GE), text\nembedding ($T_E$) and image embedding ($I_E$). Additionally, we have the raw features\nof houses, identified as $F_{raw}$."}, {"title": "4 Experiments", "content": "We present an extensive experimental evaluation of our proposed MHPP methodology\nusing real estate dataset from Melbourne, Australia.\nTo assess the effectiveness of our method, we compare the performance of MHPP\nagainst the state-of-the-art GSNE based approach [10]. Our selection of downstream\nregression models includes some of the top performers in Kaggle's house price predic-\ntion competitions [39], recent models for house price prediction [26, 27, 40], as well as\nrenowned regression models like LightGBM [41], XGBoost [42] and Gradient Boosting\n[27].\nOur approach achieves state-of-the-art performance, significantly reducing both\nmean absolute error and root mean squared error. An ablation study underscores the\ncritical role of text and image embeddings in improving the accuracy of house price\npredictions."}, {"title": "4.1 Dataset Description", "content": "Our experimentation was conducted using a dataset comprising records of house trans-\nactions sourced from a prominent real estate website\u00b2. The dataset encompasses real\nestate transactions in Melbourne, Australia's second-largest city in terms of popula-\ntion. It encompasses a total of 52,851 house transaction records from year 2013 to 2015.\nFurthermore, the dataset includes valuable details about nearby Points of Interest\n(POIs), encompassing regions, schools and train stations. This dataset comprehen-\nsively covers information related to 13,340 regions, 709 schools and 218 train stations.\nAdditionally, each record within the dataset includes a concise textual description and\nimages of the houses."}, {"title": "4.1.1 House and POI Features", "content": "Our dataset encompasses an extensive array of house attributes for each property,\ntotaling 43 distinct features as outlined in Table 1. These features span a spectrum\nfrom fundamental characteristics such as the number of bedrooms and bathrooms\nto intricate facility-related attributes like the presence of air-conditioning and tennis"}, {"title": "4.1.2 House Descriptions", "content": "The dataset also provides textual descriptions for each of the houses, capturing various\naesthetics and features that may not be readily quantified. These descriptions exhibit\nvarying lengths, with some extending up to a maximum of 280 words. An illustrative\nexample of a textual description from the dataset is shown in Figure 4(d)."}, {"title": "4.1.3 House Images", "content": "Each property in the dataset typically features an average of five distinct images.\nThese images collectively portray both the interior and exterior aspects of the houses,\nas exemplified in Figure 4(e). It is worth noting that while some houses may have been\nmissing one image within this five-image set, we mitigated this by duplicating one of\nthe four available images to maintain consistency. In our setting, we used the collage of\nfive distinctive images to learn the correlation between house images and descriptions."}, {"title": "4.2 Performance Metrics", "content": "We adopt the mean absolute error (MAE) and root mean squared error (RMSE) as\nthe evaluation metrics for assessing the performance of our model. MAE measures the\naverage absolute difference between the predicted and ground truth values, providing\ninsights into the overall accuracy of the model. On the other hand, RMSE gives more\nweight to larger errors by calculating the square root of the average squared differences.\nBy utilizing these established metrics, we can effectively evaluate the efficacy of our\nproposed model in predicting house prices.\nThe formula for MAE is as follows:\n$MAE = \\frac{1}{N} \\sum_{i=1}^{N} |z_i - \\hat{z}_i|$\nHere, N represents the number of samples, zi is the ground truth price and $\\hat{z}_i$ is\nthe predicted house price.\nThe formula for RMSE is given by:\n$RMSE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (z_i - \\hat{z}_i)^2}$\nHere, N represents the number of samples, zi is the ground truth price and $\\hat{z}_i$ is\nthe predicted house price."}, {"title": "4.3 Experimental Setup and Model Building", "content": "In our research, a 12GB NVIDIA Tesla P100 GPU machine equipped with 16GB of\nmemory and a Google Colab machine featuring 16 NVIDIA Tesla T4 GPUs were\nemployed for model training. Dataset partitioning was conducted utilizing stratified\nrandom sampling, allocating 80% for unsupervised training across three embedding\nmodels (namely, GSNE, text, and image), and reserving 20% for subsequent model\nevaluation. Given that the test set remains unseen during training, favorable perfor-\nmance therein implies robust generalization of the embedding models to previously\nunobserved data, thereby highlighting the model's inductive capacity."}, {"title": "4.4 House Price Prediction Results", "content": "We evaluate the effectiveness of our proposed MHPP approach, where we use house\nraw features, GSNE features, textual description and image features. As GSNE +raw\nfeatures show the state-of-the-art of performance, we consider this as our baseline.\nNote that, GSNE uses raw features and apply first & second order GNN embedding\nto form the final feature space to predict the house price.\nTo test the effectiveness of our MHPP approach, we progressively add different\ntext and image features in our house price prediction task. Note that, Specifically,\nwe compare the performance of the regression models trained using (1) raw features,\n(2) raw + GSNE (first order), (3) raw + GSNE (second order), (4) raw + GSNE"}, {"title": "4.4.1 Result Summary", "content": "Table 2 compares the performance of different prediction models, including Lasso,\nENET, KRR, GBOOST, XGB and LGBM, using metrics such as MAE (Mean\nAbsolute Error) and RMSE (Root Mean Square Error). The table showcases the per-\nformance of each model under different feature combinations, ranging from raw data to\nthe inclusion of text and image features. The best-performing method for each metric\nis bolded.\nThe results reveal that our MHPP method, i.e.,\n\"Raw+first+Second+text+image\", consistently outperforms other models, achieving\nthe lowest MAE (0.159) and RMSE (0.223) values. It demonstrates the importance"}, {"title": "4.4.2 Impact of Text Embedding", "content": "The impact of text embedding on housing price prediction is evident when considering\nthe data provided. The results clearly demonstrate that text embedding plays a cru-\ncial role in improving the accuracy and performance of the prediction task. Without\ntext embedding, the models show suboptimal performance, as observed in Table 2.\nHowever, when text embedding is incorporated into the models, there is a significant\nimprovement in predictive capability, as shown in Table 4.\nAnalyzing the results from 3, we observe that the inclusion of text embedding,\nalong with various combinations of raw data, GSNE (1st order / 2nd order / both)\nand image data, leads to substantial enhancements in the predictive accuracy. The\nMAE and RMSE values consistently decrease after the addition of text embedding,\nindicating a higher level of precision in the housing price predictions."}, {"title": "4.4.3 Impact of Image Embedding", "content": "The incorporation of image embedding brings about a significant improvement in the\nhousing price prediction task. The data provided clearly demonstrates the impact\nof image embedding on enhancing the performance and accuracy of the prediction\nmodels. When image embedding is not utilized, the predictive capability of the models\nis observed to be limited, as evident from the results presented in Table 2. However,\nupon integrating image embedding into the models, there is a drastic improvement in\ntheir performance, as highlighted in Table 5."}, {"title": "4.4.4 Effect of Embedding Dimension", "content": "Choosing the appropriate embedding dimension is an important task. It is essential\nto strike a balance between the embedding size and the model's runtime and memory"}, {"title": "4.4.5 Selection of Text Embedding Dimension", "content": "We utilized Principal Component Analysis (PCA), a dimensionality reduction tech-\nnique [43] to compute text embedding of various dimensions from default length of 768.\nOur experiment shows that downsampling too much can cause information loss, hence\nthe apparent increase in MAE and RMSE as shown in Table 6. Thus, we determined\nthat an embedding size of 128 gives the most promising result, while maintaining\nperformance comparable to the original dimension."}, {"title": "4.4.6 Selection of Image Embedding Dimension", "content": "Through experimentation with different embedding dimensions for image data, it was\nfound that utilizing an embedding dimension of 256 produced the highest level of\nperformance for the model. The results presented in Table 7 further support this\nfinding, as they demonstrate that the 256-dimensional embedding outperformed other\ndimensions in terms of accuracy and other evaluation metrics."}, {"title": "5 Conclusion", "content": "In this paper, we have proposed a MHPP model that incorporates a wide range of data\ntypes, which include house raw features, geo-spatial neighborhood, house description"}, {"title": "Declarations", "content": "Funding:\nThe authors did not receive support from any organization for the submitted work.\nNo funding was received to assist with the preparation of this manuscript.\nNo funding was received for conducting this study.\nNo funds, grants, or other support was received.\nConflict of interest/Competing interests:\nThe authors have no relevant financial or non-financial interests to disclose.\nThe authors have no conflicts of interest to declare that are relevant to the content\nof this article.\nAll authors certify that they have no affiliations with or involvement in any orga-\nnization or entity with any financial interest or non-financial interest in the subject\nmatter or materials discussed in this manuscript.\nThe authors have no financial or proprietary interests in any material discussed in\nthis article."}]}