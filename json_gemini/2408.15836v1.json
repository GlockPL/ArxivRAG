{"title": "Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature", "authors": ["Uri Katz", "Mosh Levy", "Yoav Goldberg"], "abstract": "The exponential growth of scientific literature necessitates advanced tools for effective knowledge exploration. We present Knowledge Navigator, a system designed to enhance exploratory search abilities by organizing and structuring the retrieved documents from broad topical queries into a navigable, two-level hierarchy of named and descriptive scientific topics and subtopics. This structured organization provides an overall view of the research themes in a domain, while also enabling iterative search and deeper knowledge discovery within specific subtopics by allowing users to refine their focus and retrieve additional relevant documents. Knowledge Navigator combines LLM capabilities with cluster-based methods to enable an effective browsing method. We demonstrate our approach's effectiveness through automatic and manual evaluations on two novel benchmarks, CLUSTREC-COVID and SCITOC. Our code, prompts, and benchmarks are made publicly available.", "sections": [{"title": "1 Introduction", "content": "Traditional search engines, while adept at retrieving relevant documents for specific queries, are sub-optimal when dealing with broad, topical queries. Such queries typically return lengthy ranked lists of potentially relevant papers, which, while comprehensive, overwhelms researchers with an information overload, obscuring the underlying structure of the topic and hindering the discovery of relevant subtopics and novel connections. Simply put, researchers are presented with an extensive inventory of documents without a clear map to guide their exploration, while they are interested in understanding broader topical trends.\nThe limitations of ranked list search results have driven a longstanding interest in methods for grouping and categorizing retrieved documents (K\u00e4ki, 2005; Hearst, 2006). Over the years, a vast amount of research was devoted to designing different methods to support the paradigm of grouping and categorizing retrieved documents to organize them into a meaningful structure of knowledge, in many cases taking the form of hierarchical, cluster-based navigation based on automatically induced topical clusters (See \u00a72). However, these browsing methods ultimately did not achieve widespread use and were not adopted by modern search engines, largely due to the insufficient quality of the automatically derived structures for practical application.\nIn this work, we demonstrate that importing the cluster-based navigation paradigm to the era of large language models (LLMs), combined with modern NLP and IR methods, can overcome many of the obstacles faced by previous approaches. Our research shows that the components required to support this paradigm perform well as stand-alone tasks, and the entire framework functions effectively end-to-end.\nWe propose Knowledge Navigator\u00b9, an LLM-based framework that transforms a large corpus of retrieved scientific literature into multi-level, organized themes of subtopics. Given a broad query, Knowledge Navigator generates a list of high-quality subtopics, each accompanied by a readable and interpretable summary grounded in the documents within the corpus. Each subtopic of interest can be expanded through ad-hoc secondary retrieval of fine-grained documents within that specific area. See Figure 1 for a graphical illustration of the system's real-world outputs. These subtopics represent meaningful research clusters, enabling searchers to identify areas of interest, uncover novel connections, and explore specific domains within the broader topic.\nBy shifting the focus from individual documents to organized subtopic clusters, Knowledge Navigator offers a potential solution to the challenges inherent in traditional ranked list presentations for scientific literature search.\nWe evaluate the Knowledge Navigator framework components on various LLMs and representation models, demonstrating its viability with both proprietary models (GPT-4o) and open-source models (Mixtral-8x7B). To evaluate the system's components and overall performance, we use (a) CLUSTREC-COVID, a modified novel form of the TREC-COVID benchmark (Voorhees et al., 2021), which we adapted for subtopic clustering, cluster-based aspect generation, and query generation tasks; and (b) SCITOC, a new dataset of scientific review table of contents, constructed from \"Annual Reviews\" open-access journals in a variety of scientific fields. We publish those datasets for future work in NLP research.\nUsing these benchmarks in both automatic and domain expert evaluation, we demonstrate that Knowledge Navigator performs efficiently in each of its component tasks, as well as in its overall function of organizing and outlining scientific knowledge. To our knowledge, this work is the first to showcase the feasibility of modern LLMs for"}, {"title": "2 Exploratory Information Seeking through Knowledge Navigation", "content": "When scientists explore a new topic and review the literature, their information-seeking behavior is an instance of \"exploratory search\" (Meho and Tibbo, 2003; Soufan et al., 2022). That is when a searcher does not have a particular document or topic in mind but rather is interested in finding out the different aspects reflected in the document collection, to both gain an understanding of the overall structure of the domain, as well as to look for subtopics that may interest them and/or fit their expertise and interests (Marchionini, 2006; White and Roth, 2009).\nCurrently, this process is not well supported by modern search systems, although it has been found to be a common search behavior among scientists (Nedumov and Kuznetsov, 2019; Tahri et al., 2023). A major obstacle is the inability of searchers to effectively consume hundreds to thousands of documents and distill topics from them. Rather, they browse tens of document titles at a time, revise their mental model of the domain based on this subset, maybe take notes, adapt their query to reflect their new mental image and interests, and navigate into a specific aspect or subtopic of interest.\nKnowledge Navigator enhances this exploration process by consuming hundreds of results, finding common themes, and organizing them into a two-level hierarchy of subtopics, allowing users to systematically explore different facets of a broad topic, thereby addressing the complex and multifaceted nature of their information needs. By transforming search results into organized subtopic clusters, Knowledge Navigator supports a holistic way of absorbing new information, helping them to identify areas of interest and discover novel connections even when their queries are initially vague or evolving.\nCluster-based browsing has been extensively studied in the past (Cutting et al., 1992; Hearst, 1999; Zamir and Etzioni, 1999; Osinski and Weiss, 2005), but despite this, these methods were not widely adopted. Approaches like Scatter/Gather (Cutting et al., 1992), which aimed to organize documents into coherent clusters for easier navigation, failed to produce good representations of documents in practice, leading to clusters that did not accurately differentiate between subtopics (Hearst, 1999). Additionally, these methods struggled to generate clusters that were easily interpretable by users due to reliance on keyword extraction techniques that were difficult for searchers to understand (Zhang et al., 2014). This was largely due to the immature state of Information Retrieval (IR) and Natural Language Processing (NLP) methodologies at the time.\nThe introduction of instruction-tuned LLMs, with their advanced world knowledge and text understanding abilities (Ouyang et al., 2022; Achiam et al., 2023), has recently led to renewed research utilizing LLMs for information organization across various tasks (Pham et al., 2023; Viswanathan et al., 2023; Zhang et al., 2023). We demonstrate that LLMs can be effectively used in assisting scientific literature consumption, by organizing document collections that result from a query into a digestible \"table-of-content\" of the topic, where each subtopic is grounded in concrete research works. This builds on the parametric knowledge of the LLM about scientific concepts, their categorization, the relations between them and many other facets of scientific knowledge gained in training, but relying on this knowledge in a fully grounded way, using it solely for the purpose of cataloging and organizing a given set of human authored documents, which result from a provided query."}, {"title": "3 Knowledge Navigator", "content": "Knowledge Navigator system takes a corpus of retrieved scientific documents for a given query and outputs an organized two-level thematic structure of subtopics spanning that topical query. The system's functionality is supported by the following conceptual steps: corpus construction, embedding and clustering of documents, describing and naming clusters, filtering irrelevant clusters, grouping the clusters into a thematic hierarchy, and subtopic query generation. This is implemented in a five-component architecture that largely follows the conceptual steps.\nThis architecture enables LLMs to generate grounded outputs based on a large number of source documents, a crucial requirement for organizing and structuring large corpora.\nSystem Design LLMs are incredibly effective at consuming information but are expensive to run and bottlenecked by the amount of information they can effectively process in their prompts. Thus, we design the system around these constraints, attempting to minimize the number of LLM calls and aiming to make the most effective use of each one. Each step is designed to reduce the information size and transform it into a suitable form to be fed as input to the next LLM step. The system is thus designed to work bottom-up, progressively abstracting information at each stage.\nStarting from hundreds of search-query results, represented as titles, abstracts and snippets, we employ a relatively cheap operation of contextual embeddings followed by clustering, to organize them into smaller\u2014but cohesive-groups. Each group is then fed, as a whole but separately from other groups, into the Cluster Reader, an LLM-based component that is in charge of analyzing it, describing its common themes, naming it, and scoring its relevance to the query. Then, the names and descriptions of all the relevant clusters are fed (together with the initial query) into a subsequent LLM-based component, which organizes them into thematic groups, and names these groups. The result is a corpus-level hierarchical organization of the search results, which can serve as a map to the scientific topic, and whose construction relied on the entire corpus: the clustering is a global operation; the naming is separate per cluster but takes the query into account and considers many documents in assigning the description and name; and the second-stage thematic organization again provides a global view based on all the clusters who passed the relevance filter.\nThe searcher can then browse the generated topical outline, identify a sub-topic of interest, and initiate the Subtopic Expander to automatically generate a query to retrieve additional documents on the fine-grained sub-topic.\nWe now describe each component."}, {"title": "3.1 Topical Corpus construction", "content": "The initial step starts with a search query reflecting a relatively broad scientific topic T (e.g. \"Tool use in animals\"), and results in a topical corpus C comprising the top K documents ranked by a search engine for this query. We select a large K (up to 1000) to ensure a diverse set of research papers that represent the full spectrum of the topic."}, {"title": "3.2 Subtopic Clustering", "content": "Next, we aim to divide the corpus C into subtopic groups, each reflecting a sub-topic $t_i$ of the broad topic T. This is done via clustering of contextual embedding vectors. We represent each retrieved document as a single embedding vector derived from the paper's title and its snippet and abstract (section 5.1 compares various embedders).\nFor clustering, we use Gaussian Mixture Model (GMM), a probabilistic soft-clustering algorithm that can assign each sample to one or more clusters. The optimal number of clusters is determined using the Silhouette score (Rousseeuw, 1987), balancing cohesiveness and separation without penalizing the complexity of the GMM. Given the high-dimensional nature of modern text embeddings, and relatively low sample count, clustering methods face challenges in accurately assessing sample proximity, often resulting in poor quality clusters (Aggarwal et al., 2001). To address this, prior to clustering, we reduce the dimensionality of the vectors using UMAP (Uniform Manifold Approximation and Projection) (McInnes et al., 2018)."}, {"title": "3.3 Cluster Reader", "content": "The Cluster Reader is an LLM-based component that operates independently on each subtopic cluster, receiving as input the titles and abstracts of all documents within that specific cluster, along with the initial topical query. This component serves two functions, \u2013naming and filtering-, which are achieved in a single prompt (See C.1 for the exact prompt). Its output is a subset of the clusters, each with an associated name and description.\nDescribing and Naming Subtopics The Cluster Reader first reads the initial query, paper titles, and abstracts within each cluster to identify and articulate the specific subtopic they address. It generates a detailed description that encapsulates the thematic essence of the cluster in relation to the broader topic (T). Based on this description, it then generates a meaningful title for the subtopic. The output of this process is a detailed description of the subtopic, along with a subtopic title. The performance of the subtopic naming function is evaluated by a domain expert in \u00a75.1.\nSubtopic Filtering In the same LLM call, after the Cluster Reader generates a description and title for each subtopic cluster, it then scores the subtopic's relevance to the original topic T on a scale of 1 to 5. Based on this score, it determines whether to filter out the subtopic cluster. This filtering process eliminates clusters deemed explicitly unrelated to topic T, addressing the noise often present in large retrieved document collections on broad topics. The performance of this filtering function is evaluated by a domain expert in \u00a75.2.\nWe chose to implement the three steps (naming, describing, and filtering) of the Cluster Reader as a single LLM call to induce a scratchpad reasoning process (Nye et al., 2021), where each step builds upon the previous stages. This also motivated the ordering of the generated content, from a detailed description to a concise name, to relevance scoring, and finally to relevance judgment."}, {"title": "3.4 Thematic Organization", "content": "The set of subtopics resulting from the cluster reader are diverse and fine-grained. The Thematic Organizer component takes all of the subtopic names and descriptions as inputs and groups them into meaningful thematic groups. For example, \"Dinosaur Thermoregulation and Metabolism\" and \"Dinosaur Musculature and Biomechanics\" would be grouped under \"Physiology and Functional Morphology\", while \"Evolutionary Transition from Dinosaurs to Birds\" and \"Origins and Ascent of Dinosaurs\" grouped under \"Evolution and Phylogeny\". Such an organization greatly helps in browsing the list of results.\nThe cluster names and descriptions are sufficiently short for their entire set to fit in a single prompt, which is how the thematic organizer is implemented. The prompt contains the full set of topics and an instruction to organize them into higher level groups.\nFrom a technical standpoint, we found it essential to associate each input topic with an explicit numeric ID and task the LLM with listing the IDs for each of its generated high-level themes, rather than to replicate the cluster names in its output. Using the IDs greatly reduced hallucinations, ensured consistent output, and increased coverage of the input topics. See C.2 for the exact prompt."}, {"title": "3.5 Subtopic Expander", "content": "The Subtopic Expander is an LLM-based component designed to enable searchers to automatically retrieve additional scientific documents relevant to fine-grained subtopics, allowing for deeper exploration of a specific subtopic without the need for manual query curation. Given the content of a subtopic cluster (i.e., its title, description, and assigned papers), the Subtopic Expander generates a list of terms directly related to the subtopic and specifically extracted from the scientific terminology present in the cluster's papers. These extracted terms are then concatenated into a single query, which is used to retrieve additional results that will populate the subtopic cluster. The expanded subtopic cluster can subsequently serve as an initial topical corpus for a secondary organization into a two-level thematic structure of subtopics.\nWe conduct an isolated evaluation of the Subtopic Expander on CLUSTREC-COVID in 5.1, and an end-to-end system evaluation on SCITOC in 5.3. See C.3 for the exact prompt."}, {"title": "4 Structured Scientific Literature Benchmarks", "content": "An ideal dataset for evaluating the system end-to-end would necessitate exhaustive annotation of thousands of scientific documents, classifying each for relevancy, subtopics, and thematic groups. Unfortunately, no existing dataset supports this task comprehensively. To this end, we introduce two novel benchmarks, CLUSTREC-COVID and SCITOC, that facilitate a robust evaluation of Knowledge Navigator, both on an individual component level and end-to-end.\nCLUSTREC-COVID To assess the construction and naming of subtopic clusters, we modified TREC-COVID, which was initially designed as an information retrieval (IR) benchmark for evaluating search performance on scientific literature related to COVID-19 (Voorhees et al., 2021). It includes 50 expert-curated queries, each representing a subtopic of COVID-19 research across multiple fields, with each query serving as a concise subtopic title, such as 'coronavirus heart impacts'. For each query, medical experts judged hundreds of documents, annotating each for relevance to the topic, resulting in an average of 300 highly relevant documents per query. These characteristics-expert curation, diverse subtopics, and detailed relevance annotations\u2014make the TREC-COVID benchmark particularly suitable for evaluating the Knowledge Navigator system's components. We transformed the TREC-COVID benchmark into a clustering benchmark by forming clusters from documents annotated as \"highly relevant\" to specific topics. We randomly sampled up to 50 documents from each topic, ensuring documents appear in only one cluster. This resulted in a dataset with 2,284 documents assigned to 50 subtopic clusters labeled with expert-curated titles.\nSCITOC To assess the system's ability to handle complex scientific topics and produce well-organized outputs, we constructed a novel benchmark of 50 tables of contents (TOC) of scientific reviews sourced from 15 diverse peer-reviewed journals published by Annual Reviews\u2074. These reviews span a wide array of scientific fields, including biology, medicine, food industry, environmental studies, and more. Reviews were selected based on predefined criteria: explicit and scientifically described tables of contents and subtopics, excluding metaphorical or abstract language. For instance, the review paper The Effects of Psychedelics on Neuronal Physiology (Hatzipantelis and Olson, 2024) included headers such as \"Effects of"}, {"title": "5 Experiment", "content": "The Knowledge Navigator system comprises several components that have not been extensively explored, particularly within the domain of scientific literature. We present an evaluation of these components, both individually and as part of the integrated system, specifically focusing on the organization of topical scientific corpora."}, {"title": "5.1 CLUSTREC-COVID Experiments", "content": "Does clustering effectively discover subtopics in an already topical corpora? Clustering algorithms aim to group similar instances, but their success in accurately clustering scientific documents into coherent subtopics is uncertain due to the complex nature of scientific concepts, which may not align with the algorithms' similarity measures. Our goal is to assess whether the clustering component effectively organizes CLUSTREC-COVID documents into subtopic clusters that align with human annotations..\nFor the evaluation of the subtopic clustering component, we experiment with GMM clustering using various text representation methods. Following literature on document clustering in information retrieval (Yuan et al., 2022), we report relevance-based measures. We use \"Clusters per topic by relevance\" ($R_c@p$) metric which indicates the number of clusters needed to observe p% of relevant documents, while \"coverage per topic by relevance\" ($R_a@p$) shows the % of minimum number of documents needed to cover p% of relevant documents."}, {"title": "5.2 SCITOC Experiments", "content": "We now present our evaluation based on the Scientific Reviews Table-of-Contents benchmark. Unless otherwise specified, the evaluations are based on a complete human annotation of 20 reviews, annotated by a hired academic researcher with a PhD in Biology. The annotator evaluated each generated subtopic in these 20 scientific review papers, resulting in a total of 1,471 relevant subtopics and 261 filtered subtopics. Each subtopic was assessed through multiple questions, which will be detailed in the following subsections. We performed an inter-annotator agreement assessment on a subset of reviews to evaluate the reliability of the annotation process. The results indicated a high level of agreement for the tasks evaluated. Further details are provided in B.1."}, {"title": "5.3 End-to-End Subtopic Coverage Evaluation", "content": "We evaluate the Knowledge Navigator's overall performance to identify meaningful subtopics within diverse scientific domains by comparing its gener"}, {"title": "5.4 Expanding Subtopics by Retrieving Additional Relevant Papers", "content": "We evaluated the Subtopic Expander as part of the entire Knowledge Navigator on the expert"}, {"title": "6 Related Works", "content": "Cluster-based Browsing notably the Scatter/-Gather paradigm (Cutting et al., 1992; Pirolli et al., 1996), was proposed to enhance exploratory search (Gong et al., 2012) by grouping retrieved documents into clusters and allowing iterative refinement. However, limitations in representing cluster content with extracted keywords hindered its adoption (Zhang et al., 2014). Since then, other notable methods have proposed different cluster-based approaches aimed at improving the computational efficiency of clustering algorithms or the selection of representative keywords (Zamir and Etzioni, 1999; Osinski and Weiss, 2005). Our work draws inspiration from this approach but leverages advancements in LLMs to structure and interpret documents, enhancing interpretability. Additionally, our focus on enabling exploration through multi-level subtopic hierarchies differentiates our system from Scatter/-Gather's document retrieval focus."}, {"title": "Information Organization with LLMs", "content": "It was shown that LLMs are capable of clustering items (Viswanathan et al., 2023; Zhang et al., 2023; Wang et al., 2023) and uncovering latent topics in text collections (Pham et al., 2023). However, these methodologies do not integrate those capabilities within practical applications, focusing instead on evaluating the capabilities of LLMs in isolation. In our work, we showed how using LLMs as a component within a framework can transform large corpora of scientific literature into a thematic organization of subtopics. Each subtopic can then be expanded by using an automatically constructed query to retrieve additional relevant documents."}, {"title": "7 Discussion", "content": "We demonstrate how the challenge of navigating the scientific literature when embarking on a new field can be facilitated by an LLM-aided process, which we call Knowledge Navigator.\nThe Knowledge Navigator operates on a corpus of documents which enables a more holistic understanding and organization of knowledge within the domain. The effectiveness of our framework demonstrates the potential of the bottom-up approach in other settings where LLMs are tasked with extracting insight from a collection of items.\nIn addition, we believe that future work could use outputs from frameworks like Knowledge Navigator in prompts for other systems or in planning tasks for agents. For example in the retrieval-augmented generation (RAG) settings, where structured data boosts the performance and utility of LLMs in various applications."}, {"title": "Limitations", "content": "Knowledge Navigator demonstrates promising results in organizing and structuring scientific knowledge, offering a potential solution to the challenges of information overload in exploratory search. However, like any system, it has limitations that can be addressed in future work:\nCorpus Quality and Recall. The system's performance is inherently dependent on the quality of the retrieved corpus. Suboptimal retrieval can still impact the system's output, even with the subtopic filtering mechanism in place. This limitation highlights the importance of further refining the retrieval process to improve recall and ensure the inclusion of all relevant documents.\nDocument Assignment. Although Knowledge Navigator utilizes soft clustering to potentially assign documents to multiple subtopics, this approach is not exhaustive due to the limitations of clustering algorithms and the representation space. Exploring alternative assignment strategies could enhance the system's ability to represent complex relationships between documents and subtopics.\nUser Interface and Experience. Our work primarily focuses on the technological and system design aspects of information organization. The development of a user interface (UI) that leverages Knowledge Navigator's capabilities and optimizes the user experience is crucial for its practical application."}]}