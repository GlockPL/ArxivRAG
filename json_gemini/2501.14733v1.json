{"title": "LLM as HPC Expert: Extending RAG Architecture for HPC Data", "authors": ["Yusuke Miyashita", "Patrick Kin Man Tung", "Johan Barthelemy"], "abstract": "High-Performance Computing (HPC) is crucial for performing advanced computational tasks, yet their complexity often challenges users, particularly those unfamiliar with HPC-specific commands and workflows. This paper introduces Hypothetical Command Embeddings (HyCE), a novel method that extends Retrieval-Augmented Generation (RAG) by integrating real-time, user-specific HPC data, enhancing accessibility to these systems. HyCE enriches large language models (LLM) with real-time, user-specific HPC information, addressing the limitations of fine-tuned models on such data. We evaluate HyCE using an automated RAG evaluation framework, where the LLM itself creates synthetic questions from the HPC data and serves as a judge, assessing the efficacy of the extended RAG with the evaluation metrics relevant for HPC tasks. Additionally, we tackle essential security concerns, including data privacy and command execution risks, associated with deploying LLMs in HPC environments. This solution provides a scalable and adaptable approach for HPC clusters to leverage LLMs as HPC expert, bridging the gap between users and the complex systems of HPC.", "sections": [{"title": "1 Introduction", "content": "HPC is powerful but often inaccessible to a broad range of users due to their inherent complexity. While graphical user interfaces (GUIs) such as Open OnDemand [12] have made HPC resources more accessible, users still need to interact with the system through command-line interfaces (CLIs) for resource availability, monitoring queue and software availabilities. This requirement places a steep learning curve on users unfamiliar with shell commands and the intricacies of the HPC environment. Furthermore, relying on HPC experts to answer user queries is not an efficient use of time, as their expertise is a valuable and limited resource.\nRecent advances in large language models (LLMs) [9, 15] have opened new possibilities for simplifying user interactions with HPC systems. Tools such as ShellGPT[20] and AI-Shell[3] have demonstrated the potential for LLMs to translate human-readable queries into executable shell commands, simplifying the interaction with complex systems. However, these systems lack the capability to integrate cluster-specific documentation or addressing the real-time user information, which is often essential for users to efficiently navigate HPC environments. LLMs directly putting commands in the terminal also poses some security risks.\nRetrieval-Augmented Generation (RAG) [16] offers a solution by extending LLMs with domain-specific knowledge, dynamically incorporating specific HPC cluster information corresponding to specific HPC organization into the model's context.\nFine-tuned LLMs[4, 7, 17] have shown potential in aiding parallel programming and detecting race conditions, demonstrating their strength in coding parallel programs. However, this paper focuses on extending RAG to flexibly integrate additional cluster documentation and real-time user information.\nWe introduce HyCE, an extension of RAG that enriches LLMs with HPC-specific data, allowing them to serve as HPC experts HPC users. To evaluate this approach, we propose a novel framework where the LLM generates synthetic HPC-specific datasets, evaluates itself using defined metrics for HPC workflows, and acts as its own judge to assess performance. Additionally, we address critical security concerns, including safeguarding data privacy and ensuring command execution integrity, to facilitate safe deployment in HPC environments.\nThis approach not only simplifies access to HPC resources but also lays the foundation for a more interactive and intelligent interface that adapts to the specific needs of each HPC organization. To facilitate this, we open-source the code 1 of our extended RAG, enabling straightforward and secure deployment of LLMs with HPC context in any organization."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 LLMs in HPC Environments", "content": "As HPC applications grow in scale and complexity, there are examples of LLMs being adapted to address HPC-specific requirements in programming, code generation[4, 5, 9, 13, 14, 17], and translation from natural language to commands[3, 20].\nHPC-GPT[7], a fine-tuned version of LLaMA[9] on HPC-specific datasets, optimizes tasks like data race detection in OpenMP parallel code, thereby enhancing productivity and accuracy in specialized coding. Similarly, HPC-Coder [17] pushes the boundaries of LLM utility in HPC by generating parallel, performance-optimized code. It assists in annotating code with OpenMP pragmas and forecasting the performance impacts of code modifications, providing expert-level support for complex, high-performance programming.\nTo enhance user accessibility to HPC systems, tools like Shell-GPT [20] and AI-shell [3] have been developed to translate natural language queries into executable bash commands. While these tools demonstrate significant potential, academic research on leveraging LLMs to improve user interaction with HPC resources remains limited. This paper addresses this gap by introducing HyCE, a method that integrates HPC commands into a standard RAG architecture.\nGiven the critical importance of secure command execution in HPC environments, this paper also explores the security implications of the proposed approach in a dedicated section."}, {"title": "2.2 Retrieval-Augmented Generation (RAG)", "content": "RAG[16] offers another method for incorporating supplementary information into pre-trained LLMs, presenting a flexible alternative to fine-tuning. Unlike fine-tuning, which modifies the model itself, which often is more expensive, RAG dynamically accesses up-to-date or domain-specific information. This dynamic nature makes RAG particularly suited for HPC environments where real-time data, such as user and system information, is essential. For instance, queries like \"What GPUs are available to me?\" or \"What is the status of my program?\" necessitate executing HPC commands and interpreting their output within the user's specific environment. By leveraging RAG, LLMs can respond more accurately, providing context-aware support in HPC contexts.\nAmong various RAG techniques, including query translation, indexing, and retrieval [2, 18, 21], our HyCE approach took inspiration from Hypothetical Document Embedding (HyDE) [10]. HyDE generates a hypothetical answer based on a query, using it to retrieve relevant contexts more accurately. In a similar way, HyCE utilizes hypothetical commands that are embedded into a vector space, which helps in retrieving similar real commands more effectively to enhance the semantic context retrieval.\nMoreover, an automated and continuous evaluation workflow is essential for RAG applications in HPC settings. Recent research has introduced LLMs as evaluators [1, 8, 24], enabling a self-sustaining process in which the LLM generates synthetic data for evaluation and serves as a \"judge\u201d to assess RAG performance. Custom evaluation metrics tailored to specific RAG tasks allow LLM evaluators to effectively assess various RAG implementations, including those involving HPC data."}, {"title": "3 RAG with HPC Data", "content": ""}, {"title": "3.1 Approach", "content": "In our approach expressed in Figure 1, we extend the standard RAG framework to perform HPC-specific question-answering by integrating data such as cluster documentation and command outputs. In a typical RAG workflow, chunks [11, 15] are created from these data, embedded with a text embedding model, and used as context. Top K relevant chunks are retrieved with a bi-encoder[6] and ranked with a cross-encoder[19], then prompt is constructed for LLM to answer. Additionally, we incorporate HyCE into this standard RAG pipeline to accurately include command outputs in the LLM's context."}, {"title": "3.2 HPC data", "content": "In this paper, HPC data encompasses to cluster documentations and shell commands.\nCluster documentation serves as a comprehensive guide to navigating an HPC environment. Typically available online, it provides essential details such as the cluster's purpose, account setup procedures, and access methods. It also includes overviews of hardware, software, and storage resources, along with specific instructions for job submission using schedulers like SLURM or PBS. Furthermore, it outlines best practices for data management and performance optimization while addressing security policies, data protection guidelines, and compliance requirements. Additional resources, such as training materials, support contacts, sample job scripts, tutorials, and FAQs, help users effectively utilize HPC clusters for various tasks.\nShell commands, on the other hand, allow users to retrieve dynamic, real-time information specific to their needs. These commands provide insights into resource availability (e.g., GPUs or CPUs available), job queue status (e.g., running, queued, or held jobs), and software availabilities. Integrating these commands into the RAG framework enables the generation of tailored, context-aware responses, ensuring users receive precise and actionable information for their specific HPC workflows."}, {"title": "3.3 Hypothetical Command Embeddings (HyCE)", "content": "For handling terminal commands, we employ Hypothetical Command Embeddings (HyCE), an adaptation of the \"HyDE\" (Hypothetical Document Embeddings) approach. In HyDE, a hypothetical answer to the query is generated to match relevant contexts for retrieval. Similarly, HyCE leverages command descriptions to identify the most appropriate command to execute in response to a query.\nIn this context, a \"hypothetical command\" refers to a descriptive explanation of what the command does. For example, for the command \"nvidia-smi,\" the description might be \"This command checks the GPU model, memory usage, and utilization rate in real time\".\nAfter retrieving the relevant command, it is executed to generate output, which is then used as context for the LLM to formulate an answer to the query.\nTo measure the effectiveness of the HyCE method in retrieving HPC data, we compared the average text similarity between two setups, a cross-encoder which matches the query directly with command and a cross-encoder with HyCE which matches the query with a command description instead. The results indicate the similarity score is consistently higher between the user query and the HyCE-augmented description than between the query and the raw command.\nMatching the query to a command description proves more accurate than direct matching for several reasons. First, commands are often abbreviated, like \"ls\" for \"list files,\" which lacks semantic meaning on its own, making direct semantic matching ineffective. Second, commands are syntactically structured and thus incompatible with the semantic search methods typically used in bi-encoder and cross-encoder models. By using descriptive explanations instead, HyCE makes the command more semantically aligned with the user's natural language query."}, {"title": "4 Automatic RAG evaluation with HPC data", "content": "Using the generated chunks and the extended RAG architecture, we expand the evaluation process to assess RAG's performance with HPC data automatically as described in table 1"}, {"title": "4.1 Question & Answer Generation and Filtering", "content": "To comprehensively evaluate the RAG system, we utilize chunks of HPC-specific information to generate hypothetical question-answer (Q&A) pairs. These pairs simulate potential user queries and their corresponding answers based on the provided context, creating a benchmark for testing the system's performance.\nThe HPC data chunks comprise two key sources: online documentation and shell commands. For Q&A generation based on command chunks, the commands are executed, and both the command description and output are used in LLM to create the Q&A pairs. This ensures the generated pairs accurately reflect the practical use cases and specific details of the HPC environment.\nIn this study, a total of 100 Q&A pairs were generated: 90 derived from cluster documentation and 10 from shell commands. To ensure the quality and relevance of these pairs, the LLM evaluates them using three criteria aligned with typical HPC usage:\n\u2022 Groundedness: Ensuring the question can be answered unambiguously using the available context.\n\u2022 Relevance: Verifying the question addresses practical and commonly encountered issues in HPC environments.\n\u2022 Standalone: Confirming the question is understandable without requiring additional background information.\nEach response is evaluated using a binary scoring system (1 for success, 0 for failure), and only Q&A pairs scoring 1 on all criteria are included in the evaluation set. This rigorous filtering process ensures the Q&A pairs are both realistic and applicable, providing a robust foundation for assessing the RAG system. Detailed prompts and output formats for this process are provided in the Appendix."}, {"title": "4.2 Evaluation of RAG via LLM as a Judge", "content": "Following the generation of hypothetical Q&A pairs, the RAG system generates responses for each question. These responses are evaluated by comparing them to reference answers using defined scoring criteria:\n\u2022 Correctness: Ensuring that the response accurately matches the reference answer.\n\u2022 Faithfulness: Verifying that the response is free from errors, does not hallucinate, and aligns closely with the given context.\nThis evaluation framework assesses both the factual accuracy and the overall reliability of the RAG system's responses, emphasizing their applicability to HPC users. Unlike the direct scoring approach used for filtering synthetic Q&A pairs, this stage employs a reference-based evaluation approach [1]. Each generated answer is scored against the reference answer using binary metrics, assigning a score of 1 for success and 0 for failure for each criterion.\nThis process provides a structured and rigorous means of evaluating the RAG system, ensuring its responses meet the practical needs of HPC environments. The full prompt can be found in the Appendix."}, {"title": "5 Experiment and Discussion", "content": "While the extended RAG system is designed for deployment as a chatbot integrated into HPC GUIs like Open OnDemand to enable seamless and intuitive user interactions, this experiment evaluates its functionality in a command-line environment. Specifically, the RAG evaluation was conducted on the terminal of Katana [22], an on-premises HPC cluster managed by Research Technology Services at UNSW Sydney. For LLM inference in the RAG, Nvidia NIM microservices and OpenAI were utilized. Details of the RAG hyperparameters and models used in the experiment are provided in the Appendix."}, {"title": "5.1 Qualitative Analysis of RAG with HPC Data", "content": "We conducted a qualitative analysis to evaluate the impact of incorporating shell command data via HyCE. For instance, when asked, \"What GPUs do I have access to?\", an LLM relying solely on cluster documentation provided only generic information about GPU types. In contrast, our RAG setup with HyCE dynamically retrieved user-specific context by executing relevant commands, accurately identifying the user's available GPUs, such as Nvidia V100 and A100.\nThis demonstrates how the integration of shell commands enables RAG to generate precise, tailored responses, enhancing the relevance and utility of its outputs for HPC users. Additional examples are shown in Figure 2."}, {"title": "5.2 Orthogonality of HyCE to Other RAG Improvement Methods", "content": "Our approach to extending RAG with HPC-specific data complements other RAG improvement methods such as prompt engineering using Chain of Thought(CoT) [23] and better models. The results of automatic evaluation in table 2 demonstrate that the incorporation of these components into the pipeline proportionally enhances the performance of our HPC-augmented RAG system. For instance, while HyCE alone improved the baseline RAG by 4.66%, the combination of CoT and better models effectively leveraged the shell commands' output provided by HyCE, resulting in incremental performance gains.\nIn addition, our framework is designed for adaptability, enabling users to integrate fine-tuned models optimized for generating parallel code in HPC environments or to adopt open-source models for enhanced security. This flexibility underscores the robustness of our approach across diverse HPC scenarios, allowing users to tailor the system to their unique needs and security requirements.\nFurthermore, the RAG architecture can be seamlessly integrated with analytics tools to enhance user support. For example, analyzing user interactions can help identify frequently asked questions, driving iterative improvements to user documentation. These enhancements, in turn, enrich the RAG's generative capabilities, creating a \"spiral of improvement\" where both user document and RAG evolve to better serve users."}, {"title": "5.3 Limitations of the Automatic RAG Evaluation", "content": "Despite its utility, our automatic RAG evaluation method has some limitations. This approach relies on data chunks to create hypothetical questions and answers, which means that it cannot effectively measure performance outside of the provided documentation chunks or commands. Consequently, the system may exhibit hallucinations when responding to queries that fall outside the scope of the user documentation or command output in the real world. Future work could explore evaluation methods that assess RAG's ability to generalize beyond specific chunks to further enhance robustness of the RAG system."}, {"title": "5.4 Other Context Retrieval Metrics", "content": "While context retrieval quality could also be evaluated through metrics such as accuracy, precision, F1 score and AUC, this aspect remains consistent with conventional RAG implementations and thus is not a primary focus in our project. While these metrics may provide additional insights, they fall outside the scope of the HyCE-specific extensions in our RAG approach."}, {"title": "6 Security Considerations", "content": ""}, {"title": "6.1 Data Privacy", "content": "Protecting sensitive HPC information is paramount, especially when interacting with external servers (e.g., OpenAI). Solutions include using enterprise and local models. For enterprise deployments, privacy can be maintained if the provider does not record input-output data and does not train their LLMs with user data, thereby ensuring secure usage. Additionally, future encryption technologies may allow data to be encrypted before being sent externally and processed by the LLM. Alternatively, hosting local models entirely within the HPC environment enhances security by eliminating the need to transmit data externally. However, this approach has challenges, as local model hosting requires substantial compute resources and can reduce available HPC resources for other tasks. Thus, finding a balance between privacy and efficient HPC utilization remains essential."}, {"title": "6.2 Command Execution Security", "content": "To maintain security in HPC environments, we implement several layers of safeguards to prevent direct command execution by the LLM:\n\u2022 LLM Safety against Prompt Injection: LLMs are usually pre-trained to counter prompt injection attacks, ensuring that queries with harmful prompts and outputs are detected, keeping the LLM's responses within safe operational bounds. From the perspective of building RAG, developers can ensure this safety aspect when choosing the LLM model.\n\u2022 Predefined Command Retrieval: In HyCE, RAG is restricted to retrieving only predefined, validated commands, preventing it from executing arbitrary commands autonomously. This reduces the risk of unintended or unsafe system actions.\n\u2022 Restricted User Privileges: The LLM operates under user-level privileges, limiting access to sensitive system functions. This minimizes the potential impact of any unintended commands, restricting the LLM to non-administrative interactions.\n\u2022 Containerization: Deploying the RAG application in a container isolates LLM processes from the core HPC environment, ensuring that any unexpected behavior remains contained and does not impact overall system stability.\nThese layers of security collectively create a secure framework, allowing safe LLM-assisted interactions within HPC environments."}, {"title": "7 Conclusion", "content": "In this paper, we introduced HyCE, a novel approach to extending RAG with HPC-specific data, transforming LLMs into effective HPC expert assistants. By incorporating cluster-specific documentation and command outputs, our method enables LLMs to provide contextually accurate, user-tailored responses that address the unique needs of HPC users. Our evaluation framework further strengthens this system, utilizing the LLM as a judge to automate performance assessments and support continuous improvement. This setup, while robust and adaptable, includes layered security"}]}