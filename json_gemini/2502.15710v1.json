{"title": "The Process of Categorical Clipping at the Core\nof the Genesis of Concepts in Synthetic Neural\nCognition", "authors": ["Michael Pichat", "William Pogrund", "Armanush Gasparian", "Paloma Pichat", "Samuel Demarchi", "Michael Veillet-Guillem", "Martin Corbet", "Th\u00e9o Dasilva"], "abstract": "This article investigates, within the field of neuropsychology of artificial intelligence, the process of categorical segmentation performed by language models. This process involves, across different neural layers, the creation of new functional categorical dimensions to analyze the input textual data and perform the required tasks. Each neuron in a multilayer perceptron (MLP) network is associated with a specific category, generated by three factors carried by the neural aggregation function: categorical priming, categorical attention, and categorical phasing. At each new layer, these factors govern the formation of new categories derived from the categories of precursor neurons. Through a process of categorical clipping, these new categories are created by selectively extracting specific subdimensions from the preceding categories, constructing a distinction between a form and a categorical background. We explore several cognitive characteristics of this synthetic clipping in an exploratory manner: categorical reduction, categorical selectivity, separation of initial embedding dimensions, and segmentation of categorical zones.", "sections": [{"title": "1 Introduction", "content": "Synthetic categorical segmentation is the activity of formal neurons consisting of \"cutting,\" within the token world to which a language model is exposed, a dimension of features used to analyze and categorize these tokens\u2014a concept-in-act deemed relevant given the nature of the task to be performed by this model, as Vergnaud would argue [133, 134] in the field of cognitive psychology of human development. The result of this categorical segmentation is reflected in the creation, by each neuron, of a synthetic category of thought, a concept, or, to put it differently, a categorical dimension carried by this neuron [101, 102]. This synthetic conceptual category is, among other things, defined by its extension, that is, the set of tokens for which the neuron associated with this category is (sufficiently) activated.\nIn a previous work [105], we investigated the mathematical-cognitive factors of categorical segmentation performed by the synthetic neurons of language models. In this preliminary exploratory study, we examined, both quantitatively and qualitatively, the genetic elements influencing this categorical segmentation. Based on the aggregation function 1 \u2211(Wi,jxi,j) + b, which partly governs this cognitive process, we identified three key causal elements of a mathematical and cognitive nature involved in this conceptual partitioning process.\nFirst, the \"x effect\" or synthetic categorical priming, which refers to the fact that the activation of the categories carried by precursor neurons in layer n affects the activation of the categories specific to their associated target neurons in layer n + 1, thereby directly impacting their categorical extension. In other words, the more a token belongs to the extension of a precursor category in layer n (i.e., the more this token is activated in the involved neuron), the greater its potential to belong to the extension of its superordinate category (i.e., its potential activation in the neuron of layer n+1). This phenomenon of categorical priming thus partly governs the categorical segmentation performed in layer n+1, that is, the determination of the subset of tokens constituting the categorical extension of the concepts carried by the neurons in layer n + 1.\nSecond, the \"w effect\" or synthetic categorical attention, which relates to the fact that the weights of the connections between a target neuron (layer n + 1) and its precursor neurons (layer n) govern the degree of relevance attributed to the precursor categories in constructing the categorical segment of their corresponding target neurons. This manifests qualitatively as a process of categorical complementation, genetically consisting of \"contributing\" to the constitution of the extension (of tokens) of a target category a specific categorical subdimension"}, {"title": "2 Categorical Extraction, Conceptualization, and\nAbstraction", "content": "The capacities for abstraction and conceptualization constitute a fundamen-tal categorical extraction ability of human cognition. They play a central role in intelligence [67] and make reasoning, generalization, and problem-solving possible [34]. They also provide a key skill for learning, robust adaptation of knowledge to a new domain, and analogy [82, 59].\nWhile human beings demonstrate a strong aptitude for abstraction and conceptualization, composing new concepts from prior ones, the execution of these cognitive processes is more challenging for artificial intelligence systems [125]. Indeed, whereas humans excel at extracting abstract patterns from different sequences, filtering out irrelevant details, and transferring these generalized concepts to other sequences, artificial neural networks are known to encounter greater difficulties in this area [145, 146].\nWithin the classical theory of concepts [80], philosophy defined abstraction as the extraction of definitions (i.e., defining traits) constituting necessary and sufficient conditions for an element\u2019s membership in the extension of a concept. Empiricist philosophers later conceived abstraction as the result of extracting common traits from various sensory experiences or their mnemonic storage, with these abstractions arising from a \u201cdistillation\u201d process applied to concrete impressions embedded in perception.\nThe question of abstraction is, de facto, epistemologically closely linked to that of categorization [103, 104]. In the field of cognitive and developmental psychology, various approaches to the nature of the content and organization of concepts are explored, each focusing on specific (complementary or divergent) aspects of conceptual entities : core knowledge [21, 121], exemplars and prototypes as nodal entities calibrating concepts [92, 115, 123, 138, 90], semantic networks defining the structuring of concepts among themselves [25, 26, 60], the finalization of categories from a situated cognition perspective [10, 48, 73], the metaphorized dimension of concepts [68], concepts as mental models rooted in perceptual activity [69], and the relationship of concepts to a language of thought within a probabilistic stochastic approach [52]. These various approaches each highlight different modalities, functionalities, or purposes of abstraction in its relationship to categorization, but it is arguably Vergnaud [133, 134] who connects them most directly by emphasizing that conceptual categorization is fundamentally an activity of abstraction and extraction of characteristics deemed relevant"}, {"title": "3 The Nature of Contents Extracted by Abstrac-tion and Conceptualization", "content": "But what does the categorical extraction constitutive of abstraction and conceptualization translate to? In other words, what is the cognitive or catego-rical nature of what is extracted in the process of abstraction or conceptualiza-tion?\nIn an empiricist-inspired epistemology, the process of abstraction is often positioned within a concrete/abstract dichotomy, with categorical abstraction considered in terms of extracting more ethereal elements from tangible ones. For instance, Cuccio [28], in the field of neuroscience, suggest that abstract categories are generated based on concrete concepts that constitute previously constructed abstractions. In this vein, Pulvermuller [110], while highlighting the limitations of amodal approaches purely related to definitional traits and disconnected from the context of objects and actions, sheds light on neurobiological mechanisms for extracting common semantic traits, emphasizing the anchoring of the symbolic in entities of the \u201creal\u201d world. This is achieved through a model identifying the processes underlying the rooting of symbols, categories, and concepts in real-world entities, in terms of associations between signs and material reference elements, resulting in the formation of abstract representations through the extraction of semantic traits. The author then points to non-symbolic representations in the form of emerging semantic circuits dispersed across various specific cortical regions, depending on the semantic nature of the sign involved (e.g., action words => motor areas; sensory words => sensory areas). In the specific context of machine learning, studies related to vision and image processing are a rich source of investigations into the nature of categorical extraction. These studies demonstrate the extraction of basic traits (color, texture), complemented by more complex extracted features [126, 17, 75, 71, 54]; the combination of simple categories (with a simple and identifiable reference, perceived by the senses), when sufficiently numerous, into more abstract, extracted categories [146]; or the construction and generalization of abstract representations from concrete sequences by extracting and segmenting shared traits of items appearing in the same context [145].\nVarious studies, particularly in the field of neurobiology, describe the process of abstraction as the extraction of cognitive maps of mental spaces related to a given domain of knowledge [122, 93, 41, 72, 94, 86]; these maps being, for instance, generated by biological neurons (place and grid cells) that enable the representation of experiences and memories. Different techniques for simulating the emergence of these cognitive maps extracted from data can be implemented using formal neural networks that learn based on statistical units whose characteristics are encoded by feature vectors. Among these techniques, dimensionality reduction and clustering methodologies applied to these vectors are particularly"}, {"title": "4 Problematic", "content": "In the field of image or video editing and graphic design, the term outlining refers to the process of separating an element of a visual scene (static or dynamic) from its background. This is done to highlight the isolated element or to manipulate it subsequently, for example, by integrating it into another visual field, emphasizing certain details, altering specific color nuances, or im-proving its focus. Outlining fundamentally involves an operation of delimiting the contour of what is instantiated as the relevant object to dissociate it from what is defined as background or noise, deemed non-relevant, to use terminology from signal processing.\nBy analogy, we define, in the domain of synthetic cognition, categorical outlining as the creation, instantiation, and enaction (in Varela\u2019s sense) [130] of a singular (sub-)dimension within the infinite-dimensional vector space of charac-teristics that can be attributed to a given entity. Here, we are indeed referring to original creation and not the identification of a pre-existing (sub-)dimension al-ready available within a pre-given world of characteristics endowed with ontolo-gical existence [131]. Furthermore, it should be noted that this (sub-)dimension may or may not be analogous to a category of thought currently existing in"}, {"title": "4.2 Categorical Outlining and the Construction of theForm/ Background Separation", "content": "The previously mentioned studies in the fields of human psychology, neu-roscience, and neural networks explore with interest the nature of the contents and the organization of elements extracted through abstraction and concep-tualization in terms of exemplars and prototypes, mental models, basic traits derived from concrete elements, emergent semantic circuits, cognitive maps of mental spaces, ontologies, representational clusters, and more. These various approaches showcase diverse and fascinating models of the results of these extracted contents. But through what processes are these contents extracted by the formal neurons themselves? How does the process of categorical outlining manifest cognitively or categorically with respect to these contents? Through what phenomenology does synthetic cognition\u2019s \u201cdecision\u201d of what constitutes the conceptual form to be retained and dissociated from a background manifest within the framework of its abstraction and conceptualization activity?\nIn the field of human neuroscience, Savioz et al. [117] describe aspects of the effect of the activation function on the construction of the dissociation bet-ween background and form, specifying how neuromodulators influence synaptic plasticity [77]. Indeed, dopamine and noradrenaline induce a strengthening of activated synapses and, conversely, a weakening of non-activated synapses, thereby generating a contrast between the signal and the background noise. This process can be modeled by a sigmoidal transfer function [119], equipped with a gain parameter G. An increase in G leads to stronger neuronal activations in response to positive inputs and stronger inactivations in response to inhibitory inputs. As a result, inputs are better discriminated, and relevant stimuli are more effectively detected against a background noise [61, 51]. This results in more distinct cortical representations and better inhibition of irrelevant informa-tion. Zeki [149], for instance, demonstrates the effect of this figure-background"}, {"title": "4.3 Reflective Abstraction and the Cognitive-MathematicalOperative Mode of Categorical Outlining", "content": "Jean Piaget is certainly one of the researchers in the field of human psy-chology who has most profoundly investigated the concept of abstraction. The theoretical framework he proposes provides a valuable heuristic basis for reflec-ting on the operative mode of the categorical outlining process in its activity of differentiating a form (categorical dimension) from a background within the domain of synthetic cognition. Piaget [19] distinguishes two types of abstraction (we do not address here the case of reflective abstraction nor the sub-case of pseudo-empirical abstraction).\nSimple abstraction (also called empirical abstraction) operates on the \u201cma-terial\u201d and \u201cimmediately observable\u201d dimensions of a set of objects (or actions). It focuses on physical dimensions \u201cimposed\u201d by perception and \u201cinherent\u201d to the object (such as its weight, texture, or color) or to the action (such as its direction or force). This type of abstraction is partly related to that postulated by philosophical empiricism. However, only partly, because Piaget\u2019s construc-tivism specifies that it nonetheless requires knowledge frameworks that were previously generated by reflective abstraction. For example, color is not a fully immediate datum but presupposes a categorization and serialization of impres-sions derived from perceived varied wavelengths-a categorization not directly extracted from reality by empirical abstraction [85]. Similarly, even in physics, measured quantities (mass, force, acceleration, etc.) are themselves constructed and, therefore, the result of inferences derived from prior reflective abstractions [98].\nReflective abstraction, on the other hand, is the activity of identifying a dimension associated with an object and then utilizing this dimension as an ele-"}, {"title": "4.4 Categorical Outlining and Synthetic Reflective Abs-traction", "content": "The three stages of reflective abstraction, as defined by Piaget, shed light on the qualitative modalities by which the aggregation function \u2211(Wi,jxi,j) + b in artificial neural networks \u201cseparates\u201d a form from a background\u2014a singular subdimension from an infinite range of possible subdimensions of categorical segmentation of the world (tokens). Indeed, the activity of this aggregation function can be interpreted as operating these three stages as follows. First, through an initial stage of abstraction (\u201cproper abstraction\u201d), the aggregation function extracts a dimension not inherently present in the tokens themselves but re-sulting from the activity of the neural network itself\u2014a categorical dimension Xi,j constructed within the activation space of each neuron in a layer n. Then, in a second stage, the aggregation function, through a process of reflection, projects this extracted categorical dimension onto a new (representational) vec-torial plane, more abstract\u2014the superordinate neurons of layer n + 1. Finally, in a third and final stage of reasoning, and within this new vectorial plane,"}, {"title": "5 Methodology", "content": "To methodologically situate our present exploratory study, we provide here a concise overview of various explainability methods aimed, with different levels of cognitive detail, at extracting the content or informational processes of for-mal neural networks, whether they are structured by layers, in groups, or as a complete network.\nBroad-spectrum cognitive research focuses on analyzing the gaps between inputs and outputs, seeking to elucidate the connection between initial data and outcomes in a language model. Among these approaches, gradient-based methods assess the role of each input datum by leveraging derivatives for each input dimension [40]. The characteristics of the inputs can be evaluated through elements such as features [32], token importance scores [40], or attention weights"}, {"title": "5.2 Methodological Option", "content": "In our exploratory research, we chose to investigate the GPT model deve-loped by OpenAI, focusing specifically on the GPT-2XL version. This choice is justified by the fact that GPT-2XL offers sufficient complexity to analyze advan-ced synthetic cognitive phenomena while remaining less complex than GPT-4 or its current multimodal version, GPT-40. A practical aspect also influenced our decision: in 2023, OpenAI made detailed information available, as highlighted in the work of Bills et al. [12], regarding the parameters and activation values of the model\u2019s neurons, which are essential data for our study.\nTo simplify our exploration, we focused on examining the first two layers of GPT-2XL, each containing 6400 neurons, for a total of 12800 artificial neurons. Regarding the tokens and their activation values among these neurons, we chose to analyze, for each neuron, the 100 tokens with the highest average activation values, which we referred to as \u201ccore-tokens.\u201d\nTo study the semantic proximity between tokens in the context of the prelimi-nary static results we will present below, we made the central choice to measure the cosine similarity within the GPT-2XL embedding base, rather than in the base of GPT-4, which is more powerful, in order to avoid falling into the metho-dological limitation mentioned by Bills et al. [12] and Bricken [16], which involves matching synthetic cognitive systems that do not rely on the same embedding system, that is, not on the same categorical segmentation system. However, for comparison and verification of the plausibility of our data, we also used two other classic, freely available embedding bases : Alibaba-NLP/gte-large-en-v1.5 and the BERT base model."}, {"title": "5.3 Statistical Choices", "content": "For our statistical analyses, we used Python libraries from the SciPy suite, following the recommendations of Howell [63] and Beaufils [11].\nTo assess the normality of our data, a prerequisite for conducting parame-tric tests, we adopted a two-pronged approach. First, we conducted inferential tests: the Shapiro-Wilk test, suitable for small samples ; the Lilliefors test, use-ful when the parameters of the normal distribution are unknown and estimated from the data; the Kolmogorov-Smirnov test, ideal for large samples; and the Jarque-Bera test, which assesses the symmetry and kurtosis of the data for large samples. Second, we supplemented this analysis with descriptive indicators such as skewness and kurtosis, and graphical methods like the QQ-plot to compare the observed distributions to a theoretical normal distribution. Regarding the evaluation of homoscedasticity (equality of variances between groups), we used Bartlett\u2019s test (sensitive to deviations from normality) complemented by Leve-ne\u2019s test (less sensitive to non-normality).\nThe results, partially indicated in the following sections of this article, reveal a partial normality of our data. As a result, we primarily employed the following for our group comparisons and distribution studies :\nThe Kruskal-Wallis test, which examines the relationship between a no-minal variable defining k independent groups and a ranking variable.\nThis was applied by ranking our numerical activation data for the to-kens, while ensuring the condition of group sizes strictly greater than 5.\nThe univariate x2 goodness-of-fit test, applied while respecting its condi-tions regarding theoretical and observed frequencies, thus not requiring adjustments for small sample sizes (Fisher\u2019s or Monte Carlo statistics).\nRegarding our statistical study of the preferential orientation of the em-bedding dimension vectors of the tokens based on their characteristic of being \u201ctaken-tokens\u201d or \u201cleft-tokens,\u201d we employed a dimensionality reduction ap-proach using principal component analysis (PCA). A PCA was performed for pairs (precursor neuron - target neuron); the precursor neurons here are neurons from the layer, and the target neurons are the 10 neurons from layer 1 with which each precursor neuron has the highest connection weight. For each PCA, the sta-tistical units involved are the 100 core-tokens of the precursor neuron, i.e., the 100 tokens with the highest average activation within this neuron. The variables used here are the 1600 embedding dimensions of GPT-2XL, supplemented by two antagonistic dichotomous variables (0/1) : \u201ctaken-token\u201d and \u201cleft-token.\u201d A core-token of a precursor neuron is a taken-token if it is also a core-token of its associated target neuron, or a left-token if it is not. The usual conditions for applying PCA are : (i) a number of statistical units greater than 100, (ii) a num-ber of statistical units greater than 10 times the number of variables involved, (iii) sphericity confirmed by the significance (a = 5%) of Bartlett\u2019s test, and (iv) a global adequacy validated by a Kaiser-Meyer-Olkin (KMO) coefficient greater than .5 or even 7. These conditions were only partially met in the context of our current study, so the results should be considered with caution and viewed"}, {"title": "5.4 Objective and Implementation of the Study in Terms\nof Statistical Observables", "content": "A categorical dimension (in the sense of Varela), from which a singular cate-gorical subdimension will be outlined, can be minimally defined by three types of elements :\nIts membership function in the sense of fuzzy logic [148, 144], defi-ned as follows. Let X be a set, and A a fuzzy subset of X charac-terized by a membership function \u00b5A : X \u2192 [0,1], determining the partial membership level (as opposed to classical set theory) of an ele-ment x in X to the set A. This fuzzy set is endowed with a height h(A) = max{\u03bc\u03b1(x) | x \u2208 X} and a kernel noy(A) = {x \u2208 X | \u03bc\u03b1(x) = 1} (if A is normalized, i.e., h(A) = 1), containing the elements x fully belon-ging to A. This membership function, in the context of synthetic catego-rical cognition, is vectorized by the aggregation function (composed with the activation function) associated with the neuron carrying the involved categorical dimension."}, {"title": "6 Results", "content": "In relation to our first batch of statistical studies presented below, concerning categorical reduction operationalized in terms of semantic distances measured from cosine similarity, we performed normality and homogeneity of variance checks on our data. For each target neuron in layer 1, the tests were initiated among its 10 precursor neurons (from layer 0) with high connection weights, considering only the precursors for which both the number of taken-tokens and left-tokens is greater than or equal to 6; this was done to ensure a minimum number of tokens for each category. This results in a theoretical maximum of 6,400 target neurons (in layer 1) x 10 precursor neurons (in layer 0) = 64,000 studies of taken-token clusters (referred to as \u201ctaken-clusters\u201d); and an actual number of 9,007 taken-clusters studied (as well as left-clusters for the homos-cedasticity case). For each study, the variable involved is the cosine similarity between all the (distinct) tokens within the cluster in question. Table 1 shows a contrasted normality of cosine similarity between the tokens of different taken-clusters, with compatibility percentages of inferential tests with a normality hypothesis ranging from 52% to 93% using the GPT-2XL embeddings, which were the most reliable, and lower results (from 21% to 73%) for the other em-beddings. Table 2 similarly presents a mixed homogeneity of variances of the tokens between the taken and left-clusters, with 58% of inferential tests compa-tible with this hypothesis for GPT embeddings, and lower values for the others (ranging from 29% to 43%). These results suggest that we should not rely on parametric tests (except as an indication), as their application conditions are only partially validated."}, {"title": "6.2 Outlining and Categorical Reduction", "content": "Within the artificial neurons of language models, as we have indicated pre-viously, the abstraction process generated, among other factors, by the aggre-gation function \u2211(Wi,jxi,j) + b, \u201cdetaches\u201d a constructed categorical form from a background, a singular categorical subdimension from an infinite range of possible categorical segmentation subdimensions of the world (tokens). This process is generated by the three mechanisms of synthetic cognition, mathema-tically supported by this aggregation function: priming, attention, and catego-rical phasing. More specifically, we postulate that the ultimate reflection step of Piagetian reflective abstraction, performed by the aggregation function of a neuron in layer n + 1, will cause the extraction, the outlining of a particular subdimension from each of its contributing precursor neurons (i.e., sources of taken-tokens) in layer n. The successive application, at the level of the target neuron, of these different categorical subsegments thus forms \u201cpart by part\u201d the extension of the new category specific to this target neuron, i.e., the set of its specific core-tokens.\nThis extraction, by a target neuron, of specific categorical subdimensions from the relative categorical diversity of the core-tokens of each of its precursor neurons, should result in the segmentation of taken-clusters that are categori-cally more homogeneous; at least, more homogeneous in terms of a categorical segment, the specific subdimension extracted from the categorical dimension of each precursor. In other words, we postulate a first characteristic of categorical outlining: categorical reduction, which manifests as the partitioning, within the extension (of tokens) of the category associated with each precursor neuron, of a token cluster (i.e., a taken-cluster) that exhibits less categorical variability com-pared to the initial dispersion, with this latter being conceptually \u201cnarrowed\u201d around the subdimension thus extracted.\nWe operationalize this postulate through two methodologically similar hy-potheses, each providing its own added value. First, for each precursor neuron (contributing) of each target neuron, the involved taken-cluster should present a higher average cosine similarity (measuring the average proximity between all the tokens constituting this cluster) compared to the average cosine similarity of the core-tokens associated with this precursor neuron. Second, for each pre-cursor neuron (contributing) of each target neuron, the involved taken-cluster should present a higher average cosine similarity (measuring the average proxi-mity between all the tokens constituting this cluster) compared to the average cosine similarity of the left-tokens associated with this precursor neuron. We"}, {"title": "6.3 Outlining and Categorical Selectivity", "content": "The characteristic of categorical reduction pointed out in the previous sec-tion leads us to formulate another postulate regarding the property of categorical outlining carried out by the aggregation function and its abstraction activity, namely, that of categorical selectivity. This categorical selectivity manifests as the extraction, from the category specific to a given precursor neuron, of a subdi-mension that is very restricted in terms of its own extension, since this precursor category already inherently exhibits a significant categorical convergence that constitutes the categorical dimension it vectorizes.\nWe operationalize this postulate through the following hypothesis: the car-dinality of the token subsets that constitute the taken-clusters tends to be very small compared to the number (100) of core-tokens of each precursor neuron. To test this hypothesis, we set a very low threshold, equal to 6 tokens, which is the reference number against which we will compare the size of each possible taken-cluster associated with layer 1. The total number of taken-clusters invol-ved here is 64,000 (6,400 target neurons in layer 1 x 10 precursor neurons in layer 0).\nThe table n\u00b07 shows a strong over-representation (86%) of taken-clusters composed of fewer than 6 taken-tokens, a trend that is highly significant (p(x\u00b2) < .0001). It should be noted that the very large size of the statistical units invol-ved (64,000) is likely to produce an increased biased significance. However, this bias is not significant as the large effect size at play here can a priori only be associated with high significance. This result is consistent with our hypothesis of categorical selectivity associated with the outlining process."}, {"title": "6.4 Outlining and Separation of Initial Embedding Di-mensions", "content": "Let us continue our exploration of the properties of categorical outlining generated by the factors of priming, attention, and categorical phasing carried"}, {"title": "8 Conclusion", "content": "We have conducted an exploratory investigation in the field of neuropsy-chology of artificial intelligence, focusing on the modalities of categorical seg-mentation performed by a language model, specifically GPT-2XL. This process involves, through different neural layers, the creation of new categorical dimen-sions to analyze textual data and accomplish the tasks required by the model. In a multilayer perceptron (MLP) network, each neuron is associated with a specific category, determined by three factors derived from the neural aggrega-tion function: priming, attention, and categorical phasing. At each new layer, these factors drive the emergence of new categories derived from the catego-ries of the previous neurons. Through a process of categorical clipping, these new categories are formed by a selective abstraction of specific subdimensions of their antecedent categories, distinguishing a form from a categorical back-ground. Several synthetic cognitive characteristics of this clipping have been identified here: categorical reduction, categorical selectivity, separation of ini-tial embedding dimensions, and segmentation of categorical zones.\nThese properties of categorical clipping have been interpreted as manifesta-tions of synthetic theorems-in-action, associated with neuronal aggregation func-tions, which, during a paroxysmal phase corresponding to the maxima of these functions, generate a reflective abstraction of singular synthetic sub-concepts-in-action. The recombination of these sub-concepts shapes the creation of new synthetic categories that are even more functional in relation to the activity objectives of the neural network involved.\nIn the context of a new study, currently underway, we continue our explora-tion of synthetic categorical segmentation by attempting to better understand how categorical restructuring occurs from one neural categorical layer n to its subsequent layer n + 1. This is done by investigating the synthetic cognitive phenomenology through which sub-concepts-in-act (i.e., categorical subdimen-sions), clipped from different precursor neurons, are either semantically and activationally convergent with one another, thus generating, in their associa-ted target neurons, new original and singular categorical structures of synthetic cognition."}, {"title": "7 Discussion", "content": "We have explored, in an exploratory manner, the process of categorical segmentation performed by the synthetic cognition of language models, consisting of cutting and creating new categorical dimensions within the world of tokens. Each formal MLP neuron can be associated with a specific categorical dimension, traceable through its own extension of afferent tokens that particularly activate for this category (its core-tokens).\nFrom a causal structural perspective, this segmentation is, among other things, driven by the aggregation function inherent to each neuron [105], a func-tion embodying three factors that govern the genesis and activation of categories carried by neurons in layer n+1 from the categories of precursor neurons in layer n: (i) the \"x-effect\" or synthetic categorical priming (the activation of precur-sor categories propagates and influences the creation of target categories), (ii) the \"w-effect\" or synthetic categorical attention (the connection weights bet-ween target and precursor neurons control the degree of relevance assigned to precursor categories in the construction of new target categories), and (iii) the \"E-effect\" or synthetic categorical phasing (subgroups of identical core-tokens from different precursors, simultaneously activated, reinforce each other catego-rically in the genesis of new target categories).\nFrom a functional perspective, these three mathematical-cognitive factors of categorical segmentation govern, at the level of a target neuron (layer n), a mechanism for extracting a specific categorical subdimension from the cate-gory carried by each of its precursor neurons (layer n 1); the union of these subdimensions generates the new categorical dimension vectorized by this target neuron. This abstraction translates into a synthetic categorical clipping process, consisting of creating and distinguishing a form from a categorical background. The goal is to understand the properties of this categorical clipping, performed on the relative categorical variability of the tokens constituting the extension of each precursor neuron's category, in order to extract a subset of tokens that are"}, {"title": "7.2 What Epistemological Status to Attribute to the Sub-dimensions Extracted by Categorical Clipping?", "content": "As we have already addressed in previous works [102, 106], it is crucial not to fall into the epistemological trap of anthropomorphism, which involves attempting to analyze synthetic cognition solely through the filter of our own human cognitive and categorical concepts. It is important to understand that the categorical subdimensions extracted through categorical clipping are not necessarily aligned with conventional human categories of thought [43, 12, 96, 95, 16].\nSimilarly, we must move beyond a form of epistemological naivety, both rea-listic and empiricist, that tends to \u201cnaturalize\u201d the subdimensions instantiated by the categorical clipping process, believing that they represent subcategories that already exist in the material world and are corollaries of a form of intrinsic, pre-given, and ontological reality. As von Glaserfeld beautifully tells us [49] : \"In order to judge the goodness of a representation that is supposed to depict something else, one would have to compare it to what it is supposed to represent. In"}, {"title": "7.3 What Cognitive Status to Attribute to the Subdimen-sions Extracted by Categorical Clipping?", "content": "The theory of conceptualization developed by Vergnaud [135] in the field of human cognitive development seems particularly fruitful for providing us with a framework for thinking about the synthetic phenomena of categorical segmentation and categorical clipping construction.\nWithin Vergnaud\u2019s theory, conceptualization is a representational activity whose goal is the cognitive construction of operational characteristics; this is done in order to ground action on these characteristics and thus make it effective [136]. In other words, the function of conceptualization is to establish homomorphisms between the realm of the objects in the world on which action is to be taken and the realm of operations and contents of thought. Thus, for Vergnaud [137], the process of conceptualization is fundamentally a pragmatic, economic cognitive activity: \u201cone conceptualizes in order to act effectively.\u201d Moreover, to a large extent, for the author, conceptualization is not cognitively positioned within the realm of explicit, conscious, and verbalized theorization, but rather within the realm of action. This operational finality is at the root of the characteristic of conceptualization being \u201cin act,\u201d meaning that it is encapsulated in action. Thus, the concepts and theorems mobilized by the individual are called \u201cconcepts-in-act\u201d and \u201ctheorems-in-act\u201d as they are only activated in action and serve no purpose other than to make the action effective.\nVergnaud [133] defines a concept-in-act as a category of thought deemed relevant by the individual in relation to a class of action situations. Concept-in-acts are categories of thought through which the subject creates and inte-grates information related to the type of situations they face. In other words, concept-in-acts are cognitive filters through which a given situation is \u201cread\u201d or constructed cognitively. From an epistemological perspective, there is potentially an infinite number of formal types of categories of thought; the most frequently encountered types are as follows: object, property, relation, transformation, condition, process. Again, concept-in-acts are pragmatic vectors of thought that organize information processing by segmenting objects in the world according to the contingent goals of the finalized activity [99]. Indeed, the functionality of concept-in-acts lies in the fact that they allow the subject to focus attention on"}]}