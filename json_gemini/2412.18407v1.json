{"title": "A Statistical Framework for Ranking LLM-Based Chatbots", "authors": ["Siavash Ameli", "Siyuan Zhuang", "Ion Stoica", "Michael W. Mahoney"], "abstract": "Large language models (LLMs) have transformed natural language processing, with frame-works like Chatbot Arena providing pioneering platforms for evaluating these models. By facilitating millions of pairwise comparisons based on human judgments, Chatbot Arena has become a cornerstone in LLM evaluation, offering rich datasets for ranking models in open-ended conversational tasks. Building upon this foundation, we propose a statistical framework that incorporates key advancements to address specific challenges in pairwise comparison analysis. First, we introduce a factored tie model that enhances the ability to handle ties\u2014an integral aspect of human-judged comparisons\u2014significantly improving the model's fit to observed data. Second, we extend the framework to model covariance between competitors, enabling deeper insights into performance relationships and facilitating intuitive groupings into performance tiers. Third, we resolve optimization challenges arising from parameter non-uniqueness by introducing novel constraints, ensuring stable and interpretable parameter estimation. Through rigorous evaluation and extensive experimentation, our framework demonstrates substantial improve-ments over existing methods in modeling pairwise comparison data. To support reproducibility and practical adoption, we release leaderbot, an open-source Python package implementing our models and analyses.", "sections": [{"title": "Introduction", "content": "The rapid advancement of large language models (LLMs) has transformed natural language pro-cessing, enabling breakthroughs across diverse tasks. As these models evolve, the need for effective evaluation methods becomes crucial for fostering innovation and ensuring that LLMs align with hu-man preferences. Traditional benchmarks, such as MMLU (Hendrycks et al., 2021) and HumanEval (Chen et al., 2021), play an important role in assessing specific capabilities of LLMs. However, they often fall short in capturing the nuanced, real-world interactions characteristic of open-ended conversational tasks, particularly those seen in chatbot applications.\nTo address this gap, crowdsourced evaluation platforms have emerged, with Chatbot Arena(Chiang et al., 2024; Zheng et al., 2023) standing out as a pioneering framework. By facilitating millions of pairwise comparisons between LLMs based on human judgments, Chatbot Arena has become one of the largest and most credible datasets (Zheng et al., 2024) for chatbot evaluation. Its design more closely reflects the open-ended nature of chatbot usage, providing unparalleled diversity and robustness in assessing model performance. In its first year, the platform amassed over two million votes across more than 150 state-of-the-art models, gaining adoption by leading institutions"}, {"title": "Statistical Model", "content": "Consider a paired-comparison experiment involving $m \\geq 2$ competitors (here, LLM chatbots), indexed by the set $V := \\{1, . . ., m\\}$. Let $E \\subseteq \\{\\{i, j\\} | i, j \\in V\\}$ denote the set of unordered pairs of competitors that have been compared in the experiment. We assume the graph $G(V, E)$ is connected.\nWe define the $m\\times m$ matrix $W = [W_{ij}]$, where $w_{ij}$ represents the frequency with which competitor $i$ wins against competitor $j$, and $w_{ji}$ represents the frequency with which $i$ loses to $j$. Similarly, we define the symmetric $m\\times m$ matrix $T = [t_{ij}]$, where $t_{ij}$ denotes the frequency of ties between competitors $i$ and $j$, with $t_{ij} = t_{ji}$. We set $w_{ij} = w_{ji} = t_{ij} = 0$ whenever $\\{i, j\\} \\notin E$ to reflect the absence of comparisons between competitors $i$ and $j$. The total number of comparisons between competitors $i$ and $j$ is denoted by $n_{ij}$, where $n_{ij} = w_{ij} + w_{ji} + t_{ij}$. The triple $(G, W, T)$ constitutes the input data for our problem.\nOur objective is to rank the competitors based on their performance in the overall comparisons. To formalize this in a probabilistic framework, we define $P(i > j|\\{i,j\\})$ as the probability that competitor $i$ wins against competitor $j$, and $P(i \\sim j |\\{i, j\\})$ as the probability that $i$ and $j$ tie. For notational simplicity, we often denote these probabilities by $P_{i>j}$ and $P_{i\\sim j}$, respectively.\nA broad class of parametric models (which we will discuss in detail later) assumes the existence of a score array $x = (x_1,...,x_m) \\in \\mathbb{R}$, which defines the ranking. Specifically, the ranking is inferred by a bijection from $V$ to itself that orders the scores $x_i$, such that $x_i > x_j$ implies $i$ is ranked higher than $j$, denoted by the binary relation $i>j$.\nThe score vector $x$ forms part of the model's parameters, denoted by $\\theta$, which also includes other parameters governing the probability of each outcome. A common approach for estimating these parameters is the maximum likelihood method. The likelihood function $L(\\theta|G,W,T)$ is defined as the product of multinomial distributions for each compared pair $\\{i, j\\} \\in E$, given by\n$L(\\theta|G, W, T) = \\prod_{\\{\\textit{i,j}\\}\\in E} \\frac{N_{ij}!}{w_{ij}!w_{ji}!t_{ij}!}P_{i>j}^{w_{ij}}(\\theta) P_{i<j}^{w_{ji}}(\\theta) P_{i\\sim j}^{t_{ij}}(\\theta).$ \nThe parameter estimate $\\theta^*$ is then obtained by maximizing the log-likelihood function $l(\\theta) := \\log L(\\theta)$, i.e., $\\theta^* = \\arg\\max_{\\theta} l(\\theta)."}, {"title": "Probabilistic Models", "content": "A parametric model for the above probabilities must satisfy two fundamental axioms. First, by the law of total probability, we have $P_{i>j} + P_{i<j} + P_{i\\sim j} = 1$. Second, the model should respect the concept of transitivity in ranking, though in a probabilistic setting. Rather than standard transitivity, where $i > j$ and $j > k$ imply $i > k$, we adopt the principle of stochastic transitivity (see, e.g., Shah et al. (2017); Shah & Wainwright (2018)).\nIn particular, we are interested in strong stochastic transitivity, which states that if $P_{i>j} \\geq \\frac{1}{2}$ and $P_{j>k} \\geq \\frac{1}{2}$, then $P_{i>k} \\geq \\max\\{P_{i>j}, P_{j>k}\\}$. A key sub-class of strong stochastic transitivity, and the focus of this work, is linear stochastic transitivity. This property is characterized by the existence of an increasing comparison function $F : \\mathbb{R} \\rightarrow [0,1]$ and a merit function $\\zeta : \\mathbb{R} \\rightarrow \\mathbb{R}$, such that $P_{i>j} = F(\\zeta(x_i) - \\zeta(x_j))$.\nIn the following subsections, we describe several common models of paired comparison that satisfy these properties."}, {"title": "Bradley-Terry Model", "content": "One of the most widely used models for paired comparison was first introduced by Zermelo (1929) and later rediscovered by Bradley & Terry (1952), leading to the model being named after them. The Bradley-Terry model forms the basis of the well-known Elo rating system, which is extensively"}, {"title": "Models with Ties", "content": "The Bradley-Terry (BT) model does not account for ties (i.e., $P_{i\\sim j} = 0$), making it more suited for balanced paired comparisons, such as zero-sum games. However, in our application of ranking LLM chatbot agents, ties frequently occur, which poses challenges for applying the BT model directly. Previous work, such as Chiang et al. (2024), addressed this by treating a tie as halfway between a win and a loss, modifying the outcome matrix as $W \\leftarrow W + \\frac{1}{2}T$. While this approach provides a straightforward way to handle ties, other extensions of the BT model incorporate ties through axiomatic frameworks, which we explore in the following sections.\nOne such generalization is the model of Rao & Kupper (1967), which modifies the logistic distribution to account for ties. The resulting probabilities for win, loss, and tie are given by\n$P(i > j | \\{i, j\\}) = P(x_i - x_j > \\eta) := \\frac{\\pi_i}{\\pi_i + \\nu\\pi_j},$ \n$P(i < j | \\{i, j\\}) = P(x_i - x_j < -\\eta) := \\frac{\\pi_j}{\\nu\\pi_i + \\pi_j},$ \n$P(i \\sim j | \\{i, j\\}) = P(|x_i - x_j| < \\eta) := \\frac{\\pi_i\\pi_j(\\nu^2 - 1)}{(\\pi_i + \\nu\\pi_j)(\\nu\\pi_i + \\pi_j)},$\nwhere $\\nu := e^{\\eta} > 1$ and $\\eta \\geq 0$ is a threshold parameter to be optimized. In this model, if the difference between competitors' scores is less than the threshold $\\eta$, the judge is unable to distinguish between competitors $i$ and $j$, resulting in a tie. Setting $\\eta = 0$ reduces this model to the standard BT model.\nAnother extension of the BT model, introduced by Davidson (1970) and based on the axiom of choice of Luce (1959), models ties differently:\n$P(i > j | \\{i, j\\}) := \\frac{\\pi_i}{\\pi_i + \\pi_j + \\nu\\sqrt{\\pi_i\\pi_j}},$\n$P(i < j | \\{i, j\\}) := \\frac{\\pi_j}{\\pi_i + \\pi_j + \\nu\\sqrt{\\pi_i\\pi_j}},$\n$P(i \\sim j | \\{i, j\\}) := \\frac{\\nu\\sqrt{\\pi_i\\pi_j}}{\\pi_i + \\pi_j + \\nu\\sqrt{\\pi_i\\pi_j}},$\nwhere $\\nu := e^{\\eta}$ and $\\eta \\in \\mathbb{R}$ is a threshold parameter for tie to be optimized. Here, setting $\\eta = -\\infty$ reduces this model to the BT model. Note that in both the Rao-Kupper and Davidson models, the probability of a tie increases as the difference in scores decreases."}, {"title": "A Generalization for Models with Ties", "content": "The original Rao-Kupper and Davidson models each employ a single parameter for ties, $\\nu$. However, as our numerical results will demonstrate, one tie parameter is insufficient to capture the complexity"}, {"title": "Incorporating Covariance Using Thurstonian Representations", "content": "A fundamental approach to modeling paired comparisons was introduced by Thurstone (1927) through the laws of comparative judgment, laying the foundation for psychometric choice modeling from a statistical perspective. In this section, we build on Thurstone's multivariate discriminal process to incorporate covariance structures into the paired comparison models discussed earlier, enriching the modeling framework with covariance as an additional parameter.\nThurstonian models assume that the score variables $x$ are stochastic processes defined by $x = \\mu+\\epsilon$, where $\\mu\\in\\mathbb{R}^{m}$ is the deterministic component representing the mean of the process, and $\\epsilon$ is a zero-mean random component with covariance $\\Sigma = [\\sigma_{ij}]$, where $\\sigma_{ij} := \\text{cov}(\\epsilon_i, \\epsilon_j)$, often referred to as the comparative dispersion. In this model, $\\mu$ and $\\Sigma$ serve as the parameters, with $\\mu$ determining rankings by reflecting the expected performance of competitors."}, {"title": "Imposing Constraints to Resolve Symmetries", "content": "When estimating the parameters of the models (such as $\\theta = (x, G)$ in the generalized tie models, or $\\theta = (\\mu, G, D, \\Lambda)$ in their Thurstonian representation) through the maximum likelihood method described in (1), we encounter computational issues due to the non-uniqueness of the solution. This arises from the fact that the likelihood function remains invariant under certain transformations of the parameters, known as symmetries. These symmetries can result in poor optimization behavior, such as large or small parameter values, causing instability in the estimation process. To address these issues, we propose constraints on the log-likelihood function to eliminate the problematic symmetries. While one of these symmetries has been addressed in prior work, the other two have not, to the best of our knowledge.\nThe first symmetry arises from the model's invariance under the transformation $x_i \\rightarrow x_i + c$, where $c\\in \\mathbb{R}$ is a constant. This invariance implies that the values of $x_i$ (or $\\mu_i$ in the Thurstonian representation) are not identifiable\u2014only their differences are meaningful (see Appendix B for a detailed discussion on parameter identifiability). Consequently, the parameters can shift uniformly without affecting the model's predictions. To address this symmetry, common approaches include fixing one of the score parameters, as demonstrated by Chiang et al. (2024), or imposing other constraints on the parameter values. For example, the original Bradley-Terry model (Bradley & Terry, 1952) enforces the constraint $\\sum_{i=1}^{m} \\pi_i = 1$. In our work, we adopt a similar approach by setting the mean of the scores: $\\sum_{i=1}^{m} x_i = 0$, which corresponds to $\\sum_{i=1}^{m} \\mu_i = 0$ in the Thurstonian representation. This constraint effectively eliminates the shift invariance, ensuring stable optimization of the score parameters $x$ (or $\\mu$).\nThe second symmetry, which has not been addressed in previous studies, involves scaling both the score and covariance parameters. Specifically, the Thurstonian models remain invariant under the transformation $(\\mu_i, \\sigma_{ij}) \\rightarrow (t\\mu_i, t\\sigma_{ij})$ for any positive constant $t$, because the ratio $z_{ij}$ in (9) remains unchanged. This symmetry can lead to parameters collapsing to very small values, causing numerical instability or underflow during optimization. To resolve this, we introduce the following constraint\n$\\text{trace}(\\Sigma) = 1,$ \nwhere $\\Sigma := P\\Sigma P$, and $P := I - \\frac{1}{m} 11^\\top$ is the centering operator with $I$ as the identity matrix and $1 := (1, ..., 1)$ is a column vector of ones. This constraint ensures proper scaling of the covariance parameters and avoids collapse during optimization. A detailed explanation of this constraint is provided in Appendix C.4.\nThe third symmetry pertains to the factor model parameters $\\Lambda_{ij}$. Using the factor model for covariance in (13), we can express the elements of the matrix $S$ as\n$s_{ii} = 0, \\text{ and } s_{ij} = d_{ii} + d_{jj} + ||\\lambda_i - \\lambda_j||_2^2, i \\neq j,$\nwhere $\\lambda_i := (\\lambda_{i1},..., \\lambda_{ik_{cov}})$ is the $i$-th row of the matrix $\\Lambda$, and $|| . ||_2$ denotes the Euclidean norm. This expression reveals an invariance under translation $\\Lambda_{ij} \\rightarrow \\Lambda_{ij} + c$, which has not been addressed in the literature. To eliminate this translation symmetry, we impose the constraint\n$|| \\bar{\\Lambda} 1 ||_2 = 0.$\nThis constraint fixes the column-wise mean of $\\Lambda$ to zero, preventing the factor parameters from arbitrarily shifting."}, {"title": "Empirical Evaluation of Statistical Models", "content": "In this section, we evaluate the statistical models introduced earlier using the Chatbot Arena dataset. As of September 2024, the dataset comprises $m = 129$ competitors, with $|E| = 3455$ unique pairs. The total number of comparisons across all pairs is $\\sum_{\\{\\textit{i,j}\\}\\in E} N_{ij} = 1,374, 996$, distributed as follows: 43.3% wins, 36.2% losses, and 20.4% ties.\nWe analyzed 30 configurations of the Bradley-Terry, Rao-Kupper, and Davidson models, detailed in Table D.1 in Appendix D.1. These configurations include both the original forms of the models"}, {"title": "Evaluating the Prediction of Win/Loss and Tie Matrices", "content": "Figure 1 visualizes a subset of the win/loss matrix $W$ and tie matrix $T$ for the top 25 competitors predicted by four models. The first row of the figure shows win probabilities, while the second row shows tie probabilities. The leftmost column contains the observed matrices, while the subsequent columns represent predictions from: the generalized Rao-Kupper model with factored ties (second column, corresponding to Model 18), the original Rao-Kupper (RK) model with a single tie parameter (third column, corresponding to Model 7), the Bradley-Terry model with ties treated as half win and half loss (Chiang et al., 2024) (fourth column, corresponding to Model 1), and the original Bradley-Terry model without ties (fifth column, corresponding to Model 4). Note that the Bradley-Terry models do not account for ties, so their tie probability matrices are absent. For consistency, the 25 competitors are ordered identically across all panels based on the ranking from Model 18.\nThe generalized Rao-Kupper model with factored ties (second column) exhibits fine-grained accuracy, closely matching the observed matrices for both win/loss and tie outcomes. In contrast, the original Rao-Kupper model (third column) predicts the win matrix reasonably well but shows reduced accuracy for ties. The Bradley-Terry models (fourth and fifth columns, with ties treated as half win/loss and without ties, respectively) differ significantly in their win/loss matrices, as they do not account for ties, resulting in noticeable discrepancies compared to the observed data.\nTo complement the pairwise probability comparisons presented here, Appendix D.5 evaluates the models using marginal probabilities of win, loss, and tie aggregated across all competitors."}, {"title": "Ranking", "content": "In pairwise comparison methods, the score parameters $x$ (or $\\mu$ in the Thurstonian representation) rank competitors, offering a straightforward interpretation of performance, with higher scores indicating stronger competitors. For example, Figure E.1 in Appendix E.1 shows the scores of the top 50 chatbots, ranked by Model 18 in Table D.1 (generalized Rao-Kupper model with $k_{cov} = 3$ and $k_{tie} = 20$).\nA key question is how different statistical models influence these rankings. To address this, we analyzed rankings produced by 12 selected models from Table D.1. Figure E.2 in Appendix E.2 visualizes the bump chart of these rankings across models of varying complexity. Each column represents a model, ordered from simpler models on the right to more complex ones on the left, and each row tracks a chatbot's rank across models.\nNotably, top-ranked chatbots exhibit stable rankings across all models, indicating reliability regardless of model complexity. In contrast, lower-ranked chatbots display greater variation, reflecting their sensitivity to model selection.\nTo systematically analyze these differences, we computed the Kendall rank correlation ($\\tau$) between all 30 models in Table D.1, as shown in Figure E.3 in Appendix E.3. Kendall's $\\tau$ measures the agreement between two rankings by evaluating the relative ordering of pairs, making it particularly well-suited for ordinal data. This analysis revealed that rankings across models are highly correlated, but notable differences emerge based on model parameterizations.\nTo better interpret these differences, we applied hierarchical clustering to the Kendall correlation matrix, as detailed in Appendix E.4. The resulting ordering of models, displayed in Figure E.3, is determined directly by the optimal ordering suggested by the clustering algorithm, reflecting the structure it uncovered.\nInterestingly, the inclusion or exclusion of the Thurstonian covariance factor emerges as the primary driver of these clusters: models without covariance (indicated by X) form a distinct cluster, separate from those with covariance. Furthermore, within the covariance group, models are divided into two subgroups based on the complexity of their covariance structures: $k_{cov} = 0$ and $k_{cov} = 3$. This highlights the strong influence of covariance parameters on ranking similarities.\nWhile covariance prominently drives ranking\u2014more so than other model features\u2014earlier results (see Section 3 and Appendix D) showed that generalized tie modeling significantly enhances model fit and predictive accuracy. These findings highlight complementary strengths: tie modeling improves fit, while covariance modeling shapes ranking patterns and distinguishes competitors based on shared performance characteristics."}, {"title": "Exploring Competitor Correlations", "content": "Incorporating covariance into Thurstonian models allows for exploring relationships between competi-tors beyond simple rankings. While rankings provide ordinal insights, covariance structures quantify uncertainties and correlations, uncovering patterns that rankings alone cannot capture.\nAs detailed in Appendix C.1, the covariance matrix $\\Sigma$ is not unique, but its associated matrix $S = [s_{ij}]$, representing the variance of score differences, is unique and interpretable. This matrix serves as a dissimilarity measure, capturing the relative uncertainty in performance comparisons. By normalizing score differences with $S_{ij}$, we construct the matrix $Z = [z_{ij}]$ as given in (9), which forms the basis for analyzing relationships among competitors.\nTo visualize these relationships, we apply kernel PCA to $Z$ and project the data into three dimensions, as shown in Figure 2. Each point represents a competitor, with distances reflecting their dissimilarities. We use a squared exponential kernel, $p_{ij} = \\exp(-\\gamma z_{ij}^2)$, with $\\gamma = 10^{-4}$, to improve"}, {"title": "Conclusion", "content": "Evaluating large language models (LLMs) through pairwise comparisons is essential for assessing their capabilities and limitations in practical applications. This paper presents a statistical frame-work that extends traditional methods by incorporating tie modeling, covariance structures, and constraints to address optimization challenges, enhancing interpretability, stability, and accuracy in LLM evaluations.\nOur generalized tie model addresses long-standing limitations of Rao-Kupper and Davidson methods, reducing prediction errors by two orders of magnitude and improving fit across win, loss, and tie outcomes. By introducing covariance structures, our framework uncovers latent relationships"}, {"title": "Broader Implications of Paired Comparison Methods", "content": "Paired comparison frameworks are foundational in many fields and have been widely applied in classical and modern domains. In sports analytics, they are used to predict match outcomes and assess player performance in games such as chess (Elo, 1978), tennis (Glickman, 1995), and soccer. Marketing applications include optimizing product offerings, advertisement placements, and analyzing consumer preferences. In psychometrics and behavioral studies, paired comparisons assess perception and attitudes in response to visual or auditory stimuli. Similarly, in election studies and political science, they are employed to rank candidates, analyze voting behavior, test referendum arguments (Loewen et al., 2012), and measure perceived political ideologies (Hopkins & Noel, 2022). Clinical research also uses paired comparisons to evaluate treatments and interventions in clinical trials and epidemiological studies. These diverse applications illustrate the versatility of paired comparison frameworks in extracting meaningful inferences from comparative data.\nRecent advancements have extended paired comparison methods to machine learning, where they play a pivotal role in preference modeling and optimization. For instance, Reinforcement Learning"}, {"title": "Unidentifiability of Parameters in Paired Comparison Models", "content": "In this section, we discuss the challenge of estimating the uncertainties of scores $x_i$ in paired comparison models. Previous works, such as Chiang et al. (2024), have introduced methods for computing confidence intervals for scores using empirical approaches like bootstrapping. While these methods can be valuable in practice, we demonstrate that this problem is intrinsically ill-posed due to the unidentifiability of the score parameters. Specifically, the likelihood function depends only on score differences $x_i - x_j$, rendering individual score estimates invariant under shift transformation. This invariance introduces non-uniqueness in the quantification of confidence intervals.\nThis issue arises not from specific modeling choices but from a structural characteristic of models based on linear stochastic transitivity, where probabilities take the form $F(x_i - x_j)$ (see Section 2.2). To analyze this limitation rigorously, we examine the Fisher Information Matrix (FIM) of the likelihood function. In Appendix B.1, we provide a background on the FIM and its role in parameter identifiability. In Appendix B.2, we show that the score parameters are unidentifiable due to the singularity of the FIM. Finally, in Appendix B.3, we propose reparameterizations that result in identifiable quantities."}, {"title": "Fisher Information and Identifiability: Background", "content": "The Fisher Information Matrix (FIM) quantifies the amount of information that the likelihood function carries about the parameters of interest. It can be derived from the gradient of the log-likelihood function, known as the informant vector, or equivalently, from the negative Hessian matrix of the log-likelihood under mild regularity conditions:\n$F(\\theta) := E [\\nabla_{\\theta}l(\\theta) \\otimes \\nabla_{\\theta}l(\\theta) | \\theta] = -E [\\nabla_{\\theta}\\nabla l(\\theta) | \\Theta] .$\nThe FIM measures the curvature of the likelihood function around the estimated parameters, reflecting the precision of the parameter estimates. A sharper likelihood function implies higher confidence in the parameter estimates. Formally, the Cram\u00e9r-Rao bound establishes a theoretical lower bound for the covariance of the parameter estimates (see e.g., S\u00f6derstr\u00f6m & Stoica (1989)):\n$\\text{cov}(\\theta) \\geq F^{-1}(\\theta).$\nThis lower bound is often used to derive estimates of parameter uncertainty. For example, assuming the approximation $\\text{var}(\\theta_i) \\approx [F^{-1}]_{ii}$, the confidence interval for $\\theta_i$ can be estimated as\n$\\Delta_i = t_{\\alpha,n-m}\\sqrt{\\text{var}(\\theta_i)},$\nwhere $t_{\\alpha,n-m}$ is the critical value from the Student's t-distribution for a confidence level $\\alpha \\in [0, 1]$ with $n - m$ degrees of freedom, $n$ being the number of data points and $m$ the number of parameters. This approach yields a conservative estimate of the variance of $\\theta_i$, reflecting the Cram\u00e9r-Rao bound."}, {"title": "Unidentifiability of Score Parameters", "content": "We now focus on the identifiability of the score parameters, $x$, in paired comparison models. For simplicity, we limit the analysis to $x$, though the results extend naturally to other parameters. We prove that the FIM for $x$ is singular for likelihood functions satisfying the shift invariance property. While the invariance property trivially implies unidentifiability by definition, analyzing the FIM reveals deeper insights into the parameter space. Specifically, it identifies the null space causing unidentifiability and highlights subspaces suitable for well-defined reparametrizations, as explored in the next subsection.\nProposition B.1. Let the log-likelihood function $l \\in C^2(\\mathbb{R}^M, \\mathbb{R})$ satisfy the shift invariance property\n$l(x + c1) = l(x), c\\in \\mathbb{R}.$\nThen, the corresponding Fisher Information Matrix $F(x)$ is singular where $\\text{rank}(F(x)) \\leq m-1$, with $1$ (the vector of ones) in its null space.\nProof. From (B.4) we have\n$\\frac{\\partial l(x + c1)}{\\partial c} = \\sum_{j=1}^{m} \\frac{\\partial l(x)}{\\partial x_j} = 0.$\nOn the other hand, summing over all columns of the Hessian, $H := \\nabla\\nabla l(x)$, and using (B.5) yields\n$\\sum_{j=1}^{m} H_{ij} = \\sum_{j=1}^{m} \\frac{\\partial^2 l(x)}{\\partial x_i \\partial x_j} = \\frac{\\partial}{\\partial x_i} (\\sum_{j=1}^{m} \\frac{\\partial l(x)}{\\partial x_j}) = 0, \\forall i=1,..., m.$\nHence, $H$ has a zero row sum, implying $H1 = 0$. Therefore, $1$ lies in the null space of $H$, and by extension, $F(x)$ is singular with a rank of at most $m - 1$.\nThe singularity of $F(x)$ confirms the unidentifiability of the score parameters $x$, rendering the quantification of their uncertainties fundamentally ill-posed. As a result, the lower bounds from the Cram\u00e9r-Rao inequality in (B.2) become unbounded, making the confidence interval such as in (B.3) undefined. In the next section, we analyze the structure of $F(x)$ to identify subspaces where meaningful parameter estimation is possible."}, {"title": "Identifiable Parametrization", "content": "We now address which quantities are identifiable through the FIM. Specifically, any reparameter-ization within the range of the FIM is identifiable. Let $\\mathcal{N}_0$ denote the null space of the FIM and $\\mathcal{N}_0^\\perp$ its orthogonal complement. Suppose $\\theta = \\theta^*$ is a local minima of the likelihood function. The FIM, when restricted to $\\mathcal{N}_0^\\perp$, is positive definite, and any parameterization within this subspace is identifiable.\nIn the case of pairwise comparison with the optimal solution $x = x^*$, assuming $\\text{rank}(F(x^*)) = m - 1$, we have $\\mathcal{N}_0^* := \\text{span}(1)$. The projection operator onto $\\mathcal{N}_0$ is given by\n$P = I-\\frac{1}{m}11^\\top,$\nwhich is the centering matrix that converts $x^*$ to the mean-zero vector $x^* := Px^* \\in \\mathcal{N}_0^\\perp$. A representation of this reparameterization is provided by the $(m - 1) \\times m$ forward differencing matrix $A: \\mathbb{R}^m\\rightarrow \\mathcal{N}_0^\\perp$, with entries $A_{ii} = 1, A_{i,i+1} = -1$, and zero otherwise. Using $A$, $x^*$ can be transformed into $y^* := Ax^*$, where each component $y_i^* = x_i - x_{i+1}$ represents the difference between adjacent elements of $x^*$. This reparameterization lies entirely in $\\mathcal{N}_0^\\perp$, making $y^*$ identifiable and enabling meaningful quantification of its uncertainty.\nThus, in paired comparison models we consider, only differences in scores provide meaningful inference. In the next section, we explore this in the context of Thurstonian covariance parameters."}, {"title": "Covariance Model", "content": "In Section 2.4 we expand the inclusion of covariance via Thurstonian model. We recall that, in Thurstonian model, the score parameters are assumed to be stochastic with $x_i = \\mu_i + \\epsilon_i$ where $\\epsilon_i$ is the stochastic component with the covariance $\\Sigma = [\\sigma_{ij}]$ where $\\sigma_{ij} := \\text{cov}(\\epsilon_i, \\epsilon_j)$. Furthermore, we defined the matrix $S = [s_{ij}]$ where $s_{ij} = \\sigma_{ii} + \\sigma_{jj} - 2\\sigma_{ij}$ representing the variance of $x_i - x_j$.\nIn this section, we provide a detailed analysis of the covariance matrix $\\Sigma$ and its associated matrix $S$. In particular, in Appendix C.1, we explore the identifiability, particularly how $\\Sigma$ is inherently non-unique while $S$ remains unique and identifiable. In Appendix C.2 we present how to interpret and visualize these matrices. In Appendix C.3, we examine hierarchical clustering of competitors based on the dissimilarity matrix, uncovering performance tiers and relationships. Finally, in Appendix C.4 we discuss constraints that allow stable identification of covariance during optimization of likelihood."}, {"title": "Non-Uniqueness and Equivalence Class of Covariance", "content": "We begin by noting that the likelihood function in the Thurstonian models we presented depends on the function of $z_{ij}$ defined in (9), which itself depends on $s_{ij}$. That is, $S$ is an observable quantity, while $\\Sigma$ is a latent variable. Below, we formalize the relationship between these two matrices and the equivalence class of covariance matrices that share the same $S$.\nLet $\\mathbb{S}^m$ denote the space of symmetric $m \\times m$ matrices and $\\mathbb{S}_0^m$ be the the space of hollow symmetric matrices where all diagonal elements are zero. Define the map $\\mathcal{S}: \\mathbb{S}^m \\rightarrow \\mathbb{S}_0^m$ that associates a covariance matrix $\\Sigma$ with the matrix $S$, given by\n$S = \\mathcal{S}(\\Sigma) = \\text{diag}(\\Sigma)1 + 1\\text{diag}(\\Sigma)^\\top - 2\\Sigma,$\nwhere $\\text{diag}(\\Sigma)$ is a vector containing the diagonal elements of $\\Sigma$. This relation corresponds to $s_{ij} = \\sigma_{ii} + \\sigma_{jj} - 2\\sigma_{ij}$ in matrix form.\nAs we will show momentarily, the map $\\mathcal{S}$ is non-injective, as for each $S$, there exist non-unique covariance matrices $\\Sigma$ differing by elements in the kernel of $\\mathcal{S}$, all of which map to the same $S$. Consequently, the preimage of $S$ defines the equivalence class of covariance matrices producing the same $S$, given by\n$[\\Sigma] = \\mathcal{S}^{-1}(S) = \\{\\Sigma' \\in \\mathbb{S}^m | \\mathcal{S}(\\Sigma') = S\\} .$\nThis equivalence class partitions $\\mathbb{S}^m$ modulo the kernel of $\\mathcal{S}$, denoted as $\\mathbb{S}^m / \\text{ker}(\\mathcal{S})$. We now formalize this structure."}, {"title": "Interpretation and Visualization of Covariance", "content": "While the covariance matrix $\\Sigma$ is not unique, the matrix $S$ is unique and identifiable. This makes $S$ the preferred object for interpreting relationships between competitors. Unlike $\\Sigma$, which represents similarity, $S$ plays the role of a dissimilarity matrix, as commonly explored in paired comparison literature (Maydeu-Olivares & B\u00f6ckenholt, 2005; B\u00f6ckenholt, 2006). In fact, under suitable conditions, $S$ can be interpreted as a distance"}]}