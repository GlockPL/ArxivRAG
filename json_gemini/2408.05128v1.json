{"title": "Is ChatGPT a Good Software Librarian? An Exploratory Study on the Use of ChatGPT for Software Library Recommendations", "authors": ["Jasmine Latendresse", "SayedHassan Khatoonabadi", "Ahmad Abdellatif", "Emad Shihab"], "abstract": "Software libraries play a critical role in the functionality, efficiency, and maintainability of software systems. As developers increasingly rely on Large Language Models (LLMs) to streamline their coding processes, the effectiveness of these models in recommending appropriate libraries becomes crucial yet remains largely unexplored. In this paper, we assess the effectiveness of ChatGPT as a software librarian and identify areas for improvement. We conducted an empirical study using GPT-3.5 Turbo to generate Python code for 10,000 Stack Overflow questions. Our findings show that ChatGPT uses third-party libraries nearly 10% more often than human developers, favoring widely adopted and well-established options. However, 14.2% of the recommended libraries had restrictive copyleft licenses, which were not explicitly communicated by ChatGPT. Additionally, 6.5% of the libraries did not work out of the box, leading to potential developer confusion and wasted time. While ChatGPT can be an effective software librarian, it should be improved by providing more explicit information on maintainability metrics and licensing. We recommend that developers implement rigorous dependency management practices and double-check library licenses before integrating LLM-generated code into their projects.", "sections": [{"title": "1 INTRODUCTION", "content": "Modern software development thrives on code reuse. Open source libraries provide pre-written code blocks, significantly reducing development time and effort [1-3]. While libraries enhance functionality, they also introduce dependencies \u2013 interconnections between code components \u2013 that can lead to increased complexity and dependency management challenges [4-6].\nOne critical aspect of dependency management is library selection [7]. Choosing the right library impacts factors like code maintainability, performance, and security. Previous studies have explored how developers select libraries, and highlighted primarily ad-hod processes based on past experiences, expert advice, and online resources [8, 9]."}, {"title": "2 STUDY DESIGN", "content": "Figure 1 presents an overview of our approach to curate the dataset used in this study. In order to conduct our qualitative and quantitative analysis, we focus on the Python programming language for its popularity, extensive library ecosystem, as well as the demonstrated capabilities of LLMs in generating and understanding Python code [15\u201318]. Below we describe the steps to curate the dataset used in our study and the experimental setup.\n2.1 Dataset\nWe prepared our dataset using the dataset of Stack Overflow question-code pairs curated by Yao et al. [19]. Their set contained 147,546 Python question-code pairs automatically mined from Stack Overflow using a bi-view hierarchical neural network. We selected this dataset because it provides human-written code, which is necessary for our comparative analysis with ChatGPT-generated code. Also, the dataset is comprised of \"how-to-do-it\" Stack Overflow questions (e.g., how to grab from JSON in selenium python\u00b2), which facilitates prompt crafting for our experiment. Finally, the dataset is labeled, allowing us to filter for specific types of answers, such as multi-code versus single-code answer. Thus, to facilitate code extraction, we select questions annotated single-code answer posts, which are accepted answers that contain only one code snippet.\u00b3 Finally, to ensure that the selected questions are specifically about library usage, we only keep the ones where the code snippet of the corresponding accepted answer includes at least one import statement. This process yields a total of 31,928 question-code pairs. Then, to ensure that our analysis is manageable, we select a random sample of 10,000 question-code pairs (confidence level of 99% with a ~1% confidence interval).\n2.2 Experiment Setup\nTo create model-generated code for each Stack Overflow accepted answer, we take a two-step approach. The first step is to construct the prompts to specify the type of tasks we expect the model to complete. In our case, the model will be generating code to answer programming questions in Python. Therefore, the prompts are structured with the base prompt \"Generate Python code for"}, {"title": "3 RESULTS", "content": "In this section, we present the results of our three research questions. For each research question, we present our motivation, the approach to answer the question, and key findings.\nRQ1: What are the characteristics of the software libraries recommended by ChatGPT?\nMotivation. As developers increasingly turn to tools like ChatGPT and other similar tools for coding assistance [21], the libraries included in the recommended code become more important as the code's performance, security, and functionality are directly impacted by these libraries [4, 22, 23]. Thus, in this RQ, we aim to understand the characteristics of libraries used in model-generated code to understand how software development is changing with the inclusion of LLMs. This knowledge will help us gain insights into the model's underlying knowledge base and its alignment with current software development practices. This is particularly relevant for developers relying on ChatGPT's suggestions to expedite their coding process. For that purpose, we will investigate the types of libraries recommended by ChatGPT, their popularity and maintenance characteristics, as well as their licenses.\nApproach. To answer this RQ, our approach involves a three-step analysis. First, we classify libraries into three categories: standard (included in the standard Python package), third-party (available on the PyPi repository), and other (neither standard nor third-party). Subsequently, we examine the characteristics of libraries in ChatGPT-generated code. Finally, we analyze the licenses of third-party libraries. We outline each step below."}, {"title": "RQ2: What are the challenges encountered by developers when using ChatGPT for library recommendations?", "content": "Motivation. In RQ1, we find that certain libraries recommended by ChatGPT are neither part of the standard Python libraries, nor published on the PyPi repository. Such libraries are potentially problematic because it means that they do not work out of the box, which can confuse developers and hinder their workflow. Thus, identifying and understanding challenges such as this is crucial for improving the practical utility of LLMs in real-world settings. When ChatGPT uses libraries that do not work out of the box (i.e., they do not exist on the current PyPi repository and are not part of the default Python installation), it not only impacts the productivity of developers but also raises concerns about the trustworthiness and validity of the generated code [17]. By studying the challenges developers encounter in the context of LLMs as software librarians, we can develop actionable strategies to mitigate them. Thus, this RQ aims to pinpoint the specific difficulties developers face when using ChatGPT for library recommendations.\nApproach. To understand the underlying causes behind the presence of problematic libraries in ChatGPT-generated code, we first determine whether these libraries were explicitly mentioned in the question. If so, we categorize the library as hard-coded, indicating that ChatGPT was directed to use a library not found in standard Python libraries or the PyPi [26] repository.\nIn cases where the unclassified library is not hard-coded, we verify whether it is deprecated (as of March 2024). We devised a two-step approach to determine the deprecation status of a library. The first step targets libraries that while not found on the PyPi registry, might have been previously part of the standard Python installation, and involves querying the Python documentation website [27] for Python 3 and Python 2 versions. In this case, we consider a library deprecated if the request for Python 3 is successful (i.e., status code is 200) but with a changed library name in the response URL (e.g., urllib2 becomes urllib.request). Alternatively, if the request for Python 3.x fails (e.g., status code is 404), we request the documentation website for Python 2.x; a successful request leads to the library being labeled as deprecated.\nThe second step covers the libraries that might have been on the PyPi registry, but have been removed since then. This step involves using virtual environments and the subprocess module to automate the process. For each library, we create a unique virtual environment and install the library. During both the installation and import stages, we check for deprecation warnings. This is done by capturing and analyzing the output from the pip install command and a Python script that imports the library.\nNext, once we have ruled out the possibility of a problematic library being deprecated or hard-coded, we look at other possibilities. For this, we take the remaining set of recommended libraries and perform open coding. This process involves analyzing the Stack Overflow question used to generate the prompt, including the question body, any provided code snippets, and the accepted answer's body. Through this analysis, we developed a set of nine mutually exclusive labels to categorize the libraries. The open coding was performed by one author, with the labeling scheme"}, {"title": "4 DISCUSSION", "content": "In this section, we discuss the implications of our work and propose recommendations for practitioners and researchers in the context of LLMs as software librarians.\n4.1 Are LLMs Good Software Librarians After All?\nOur results indicate that ChatGPT generated only five hallucinations out of 10,000 questions, and only 6.5% of the libraries were potentially problematic. Based on these findings, we argue that LLMs like ChatGPT have the potential to be good software librarians, though several important considerations must be addressed, which we discuss below.\nLicensing Awareness. One significant area of improvement for ChatGPT as a software librarian is its lack of communication of software licenses. While most of the recommended libraries had permissive licenses, 14.2% were copyleft licensed- a more restrictive type of license- and 10.4% had no license specified. This was not explicitly communicated by the model, which can lead to potential legal and compliance issues for developers. Permissive licenses, such as the MIT or Apache licenses, allow developers to use, modify, and distribute the software with minimal restrictions, providing flexibility and reducing legal risks. On the other hand, copyleft licenses, such as the GNU General Public License (GPL), require that any derivative works also be distributed under the same license. This implies that if developers use a GPL-licenses library in their project, they may be obligated to release their own code under the GPL as well. This can be problematic for proprietary software developers who do not wish to open-source their code. To better understand this, we can consider a scenario where a developer is working on a proprietary project and uses ChatGPT to generate code. The model recommends a library without specifying its license, for example PyQT 12, one of the most popular cross-platform GUI libraries for Python. The developer, assuming it is safe to use, integrates the library into their codebase, but later discovers that it is GPL-licensed. This forces the developer to either comply with GPL requirements, which may not be feasible or desirable, or replace the library, which involves additional effort to refactor the code and ensure compatibility.\nTo avoid such problematic scenarios, developers can enhance the model's responses by including safeguards such as explicit license information for each recommended library. For example, when suggesting a library, the model should include a note such as \"This library is licensed under the GNU GPL v3.0\". Moreover, if the generated output contains a library, the response should clearly state the license type and restrictions, e.g., \"The library PyQt5 is licensed under the GNU GPL v3.0, a copyleft license that may require your code to also be open-sourced under the same license.\"\nAlso, LLM (including GPT) developers should train models to detect and flag libraries with restrictive licenses, and provide alternatives with permissive licenses where possible. For instance, if the model detects a GPL-licensed library, it should offer an alternative like: \"While PyQt5 is suitable, it is GPL-licensed. You might consider Tkinter, which has a more permissive license (PSF License Agreement).\"\nChatGPT Unconditionally Recommends Libraries. One notable finding from RQ2 is that 33% of the libraries that did not work out of the box in ChatGPT code were actually explicitly mentioned in the user question. This highlights a critical issue: if a user explicitly instructs the model to use libraries that are not standard, recognized, or even existent, ChatGPT will still attempt to generate code utilizing that library without any warning. This can lead to several significant problems.\nFirst, ChatGPT may generate code for libraries that are non-existent or no longer supported. This can lead to confusion and wasted time as developers attempt to install and use a library that simply isn't there. For example, a user asked \"how to post data and binary data using urllib2 in Python?\".13 In this case, urllib2 is a library that is no longer supported and no longer available on PyPi. Despite this, ChatGPT generated code using urllib2 as shown in Listing 1. While the code itself is correct, installing urllib2 is not possible with Python 3. Although the Stack Overflow question from which the prompt was generated is eight years old, tools like ChatGPT should have up-to-date knowledge of libraries to ensure that developers use current and supported libraries in their code. From the developer's side, fixing such issues requires the developer to recognize that the library does not exist or is deprecated, which may not be immediately obvious, especially to less experienced developers. Thus, the reliance on user knowledge to identify and correct library recommendations undermines the efficacy and reliability of LLMs as software librarians. As such, we propose that LLM developers enhance models to include warnings when a user requests a non-existent or deprecated library along with the generated code. For example, if a user asks for a deprecated library like urllib2, the model should respond with, \"The library urllib2 is no longer supported. Consider using requests instead.\" This will help developers avoid wasting time on outdated libraries and ensure they use current, supported ones.\nFurthermore, there is a critical security implication arises when ChatGPT unconditionally generates code for libraries that are explicit in the request. For example, if a user mistakenly asks for padnas instead of pandas, ChatGPT might generate code for the misspelled library name. If the user attempts to install padnas, they might inadvertently install a malicious library that takes advantage of typosquatting- a common tactic where attackers upload malicious packages with names similar to popular libraries to exploit such mistakes. In this specific example, padnas 14 is a harmless library designed to resemble pandas to prevent such attacks, which highlights that these scenarios are not uncommon.\nTo mitigate these security risks, we recommend that both LLM developers and practitioners take proactive measures. For example, LLM developers should enhance models to verify and correct library names before generating code. If the model detects a likely typo, it should suggest the correct library name, such as, \"It looks like you meant pandas. Generating code for pandas instead of padnas\". Practitioners should also adopt best practices when using LLMs such as ChatGPT to assist in programming tasks [30]. Notably, they should cross-check library names and ensure they are correctly spelled and widely recognized before attempting to install them. It is critical that practitioners do not blindly adopt generated code without first verifying the overall health of the libraries, as the health of libraries is constantly evolving, and new vulnerabilities may have emerged since ChatGPT was last trained. For this, practitioners can use tools such as the sourceRank provided by libraries.io, or Snyk,15 a security platform for securing code, open source dependencies, and cloud platforms.\nWe conclude that while LLMs like ChatGPT can be good software librarians, they can be improved to better assist developers in streamlining their work. This can be achieved by implementing warning mechanisms to alert users when they request libraries that are deprecated or potentially non-existent, integrating verification tools that cross-reference libraries against known repositories like PyPi, and incorporating alerts for potential security risks like typosquatting. Additionally, providing more explicit information and context for recommended libraries, such as licensing, will help users mitigate potential conflicts and ensure easier integration into their codebase."}, {"title": "4.2 The Impact on Dependency Management", "content": "Our study highlights several implications for practitioners who are increasingly relying on LLMs as programming assistants. Here, we discuss the potential impact on dependency management and development workflow.\nIncreased Use of Third-Party Libraries. Our results show that ChatGPT tends to use third-party libraries more frequently than human developers, favoring well-established and widely adopted libraries. The use of third-party libraries can significantly impact dependency management as it introduces additional complexity and risks into software projects [6, 31]. Each new library brings its own set of dependencies, the majority of which are transitive (dependencies induced by other dependencies) [4]. This can lead to dependency hell, a term used to describe when there are so many dependencies and potential version conflicts that resolving them becomes a significant challenge and developers spend more time managing dependencies than writing actual code [5, 32].\nTo address these challenges, LLM developers should enhance models to provide not only code with appropriate libraries but also information on the dependency footprint of each library. For example, when suggesting a library, the model could include a note such as \"This library has 5 direct dependencies and 20 transitive dependencies.\" Moreover, LLMs could be trained to recommend libraries with fewer dependencies when multiple options are available to minimize the risk of dependency hell. LLM developers should also incorporate security and stability checks into the models by leveraging databases like the National Vulnerability Database 16 (NVD) or GitHub Security Advisories 17 (GSA).\nIn addition to the steps for LLM developers, we recommend that practitioners thoroughly evaluate the maintenance metrics of libraries recommended by ChatGPT before integrating them into their codebase. Firstly, practitioners should consider the number of dependencies associated with each library. A high number of dependencies increases the risk of conflicts and broadens the attack surface of the codebase [4, 6]. For instance, using tools like npm 1s for JavaScript or pipdeptree for Python can help visualize and asses the dependency tree of a library. Practitioners should also consider the version frequency of a library; while frequent updates may indicate active maintenance, they can also be a sign of instability, and managing constant updates can be challenging [22]. Tools such as Dependabot 18 or Renovate19 can automate the process of dependency updates and help keep track of changes without overwhelming the development process.\nLibraries Recommended by ChatGPT are Frozen in Time. The knowledge of an LLM is essentially \"frozen in time\" at the point when it was last trained. This arises from the nature of training LLMs, which is an expensive and infrequent process coupled with the dynamic nature of libraries, which continually evolve with updates with add new features, fix bugs, and address security vulnerabilities. As a result, the libraries recommended by ChatGPT may not reflect the most current versions. Thus, practitioners might find that the functions or methods found in ChatGPT-generated code are deprecated or have been replaced by more efficient alternatives in the latest library versions. New versions of libraries can include breaking changes that are not compatible with previous versions, which can cause runtime errors and necessitate additional effort to refactor the code with work with the updated version. Moreover, libraries are frequently updated to address security vulnerabilities [4, 22], and using an outdated snapshot of a library version as recommended by ChatGPT to avoid compatibility issues can expose projects to security risks.\nTo mitigate these issues, we recommend that practitioners integrate Continuous Integration (CI) tools into their workflow to automate the testing of code against the latest versions of dependencies. CI tools can help identify compatibility issues early, allowing developers to address them before they become problematic [33]. Furthermore, LLM developers should enhance models by incorporating mechanisms to check the currency of recommended libraries. For instance, the LLM could provide a disclaimer such as, \"This library is based on a version as of [last training date]. Please verify with the latest documentation.\" This would prompt practitioners to validate the suggested library version. LLM developers can also train models to prioritize stable libraries that have low frequency of breaking changes. For example, if multiple libraries provide similar functionalities, the model should recommend the one with a proven long-term stability, not necessarily the most popular one as our results of RQ1 indicate. This could be done by integrating data from sources like GitHub releases or library changelogs.\nMind Your Prompts. In light of the above-mentioned implications, one might consider asking ChatGPT for alternative standard libraries equivalent to third-party libraries. Standard libraries are generally more stable, better documented, and maintained as part of the core language distribution, which reduces the dependency management burden and minimizes the risks as mentioned above [34]. However, when asking ChatGPT for alternative libraries, practitioners should be mindful of the potential for the model to \"hallucinate\". An article by Vulcan Cyber states that between 25% and 40% of the libraries generated by ChatGPT are hallucinations [35]. In this article, the author asked ChatGPT to generate code to integrate a library in Node . js and then repeatedly requested alternative methods. As a result, ChatGPT began hallucinating and producing non-existent libraries. While this has significant security implications, it does not reflect a typical user interaction with ChatGPT, which we aimed to reflect in this study.\nTo mitigate these risks, we recommend that practitioners craft solid prompts from the start, providing enough context surrounding the type of library they are seeking so that the model understands what is expected early on. For example, instead of asking, \"Canyou suggest a library for HTTP requests in Python?\", a more detailed prompt would be, \"Can you suggest a standard Python library or widely-used third-party library for making HTTP requests, and provide a brief explanation of its advantages?\" LLM developers can also help in addressing these issues by enabling the models to recognize when it is best to use a standard library versus a third-party library. Implementing a confidence scoring system for library recommendations, where the model indicates the certainty of its suggestions, can guide LLM users in evaluating the reliability of the recommendations. This can be integrated in the models' responses such as, \"This library has a high confidence level based on currenty training data.\"\nUsers as Active Evaluators. The results of RQ2 suggest that the context in which a library is recommended is crucial in determining its relevance and utility. Thus, problematic library usage is not inherently tied to ChatGPT making mistakes, but to the very context-dependent nature of the PyPi ecosystem. This means that developers using LLMs as programming assistants are not just consumers of the library recommendations but should be active evaluators to ensure that the libraries they integrate into their own code are compatible with their own context. For the LLM development community, this means improving the models' ability to recognized, understand, and prioritize context-specific information when generating code with software libraries. For instance, the model should consider a project's framework, the programming language version, and the specific functionality required."}, {"title": "5 RELATED WORKS", "content": "In this section, we discuss the related literature divided into two aspects. First, we discuss the works that have focused on dependency management and related challenges. Second, we discuss the works that report on the use of large language models as programming assistants.\n5.1 Dependency Management Challenges\nWhile open source software libraries significantly reduce development time and costs [1-3], depending on numerous libraries introduces complexity and potential dependency management challenges [4-6]. One such challenge is highlighted by Mujahid et al. [7] who identify library selection as a critical aspect of dependency management. In their work, they surveyed developers from the npm ecosystem to qualitatively understand the characteristics of highly-selected libraries. Their results show that JavaScript developers believe that such libraries are well-documented, popular, and free of vulnerabilities. Building upon this work, our study leverages those same characteristics to categorize libraries used by ChatGPT.Hauge et al. [8] show that organizational library selection is an ad-hoc process that often relies on a combination of past experiences, expert advice, and online resources. This is further discussed in the work of Haenni et al. [9] where the authors surveyed developers about their decision-making when selecting a library to integrate into their application. Their findings show that, in general, developers do not apply rationale when selecting libraries. Alternatively, developers opted for libraries that fulfilled the immediate task requirements. Given this lack of formal selection processes and the increasing popularity of LLMs as programming assistants, this motivated us to investigate the role of LLMs as software librarians.\nDependency hell is a concept discussed in several studies [36-38] and refers to when a project has an excessive number of dependencies, and managing these dependencies becomes difficult and error-prone. Chen et al. [32] discuss the impact of \"trivial packages,\" referring to libraries implementing simple functionalities, on the npm ecosystem. Their survey highlights that developers struggle with the multiple dependencies introduced by these libraries, contributing to dependency hell. For instance, a developer reported the cascading effect of patching a deeply nested dependency, requiring updates throughout the dependency tree. Jafari et al. [22] investigate the relationship between npm library characteristics and the dependency update strategy opted by its dependents. The authors report that the release status, the number of dependents, and the age of a library are the most important indicators of the dependency update strategy. Raemaekers et al. [31] discuss the risks associated with the usage of third-party libraries. They identify key library attributes that could serve as risk indicators. Notably, they report that more popular libraries may be updated more frequently, which increases the chance for new bugs to get introduced into the codebase.\nThese findings support our claim that LLMs can be improved software librarians by providing critical information about recommended libraries, such as maintenance metrics (e.g., number of dependencies, version update frequency, age). Such transparency can help developers anticipate and manage potential maintenance challenges associated with the increased complexity of dependencies.\n5.2 LLMs in Software Development Workflows\nLLMs are increasingly used by software engineering practitioners to perform various tasks, such as code generation, and have shown the potential to improve developer productivity [11, 12, 39]. However, some studies have raised concerns about the reliability of LLM-generated code. For instance, Zhong et al. [40] report common API misuse patterns found in popular LLMs. The study reveals that in the case of GPT-4, 62% of the generated code contained API misuses. The authors argue that this is particularly problematic given that users of LLM code generation are generally not familiar with the APIs that LLMs generate code for, and cannot tell whether the provided code"}, {"title": "6 THREATS TO VALIDITY", "content": "Internal validity considers the experimenter's bias and errors. Thus, a potential threat to the validity of our study is the manual categorization process of instances where a library import or installation resulted in a failure. To mitigate this, each case was discussed and reviewed by other authors and any inconsistencies were carefully addressed. Additionally, the parameters used when prompting the model can impact the generated responses. We addressed this by using ChatGPT's default parameters, mimicking a typical user interaction. Also, a time gap between the Stack Overflow questions and the generated code could introduce inconsistencies due to library changes over time. To mitigate this, we used the latest version of the libraries (as of February 2024) as a baseline for our analysis. Moreover, while the open coding process for categorizing the libraries was conducted by a single author, the labeling scheme was developed collaboratively and the results were validated through discussions with other authors. We opted not to use multiple coders or statistical measures like Cohen's kappa due to the objective nature of the labeling, which focused on factual classifications (library characteristics and usage) rather than subjective interpretations. Nevertheless, this decision may introduce a potential bias, although it was minimized through careful validation and clear, objective criteria. Finally, the stochastic nature of LLMs might lead"}, {"title": "7 CONCLUSION AND FUTURE WORK", "content": "This study investigated the effectiveness of LLMs as \"software librarians\" by analyzing libraries suggested by ChatGPT (specifically GPT-3.5 Turbo) for real-world coding problems derived from Stack Overflow questions. Our findings shed light on several key aspects of LLM library recommendations. First, ChatGPT uses third-party libraries 10% more often than human developers, and prioritized stable and well-established options. Additionally, ChatGPT tends to recommend libraries with few dependencies, which suggests a focus on more self-contained solutions. Interestingly, the libraries used by ChatGPT have a majority of permissive licenses, but a concerning amount of copyleft licenses, indicating that developers need to exercise extra caution in the way they use and distribute the generated code. As such, we recommend that tools like ChatGPT provide explicit information about licensing, providing alternatives to libraries with more restritrive usage.\nOur analysis also revealed areas for improvement. We found that 6.5% of the libraries in ChatGPT-generated code led to import or installation failures and stemmed from aliases and implicit imports of modules. Moreover, two thirds of the problematic libraries were explicitly mentioned in the user question, indicating that ChatGPT generates code for libraries that may not be recognized or even existent. These issues can lead to developer confusion and frustration when encountering import or installation failures. We recommend that developers practice caution before integrating libraries recommended by ChatGPT into their codebase by cross-referencing the libraries with up-to-date resources such as official documentation. We also recommend that LLM programming assistants provide explicit information maintainability metrics of recommended libraries to guide developers in selecting and integrating appropriate libraries into their codebase. In the future, we plan to implement a tool that integrates with LLMs to perform checks on libraries and provide essential metadata (e.g., the number of dependencies and the version frequency) and license information. Additionally, we plan to replicate our study to include more models such as CodeT5 and Llama3.\nWe conclude this work by answering the question: Is ChatGPT a good software librarian? Our answer is a cautious yes."}]}