{"title": "Task-oriented Time Series Imputation Evaluation via Generalized Representers", "authors": ["Zhixian Wang", "Linxiao Yang", "Liang Sun", "Qingsong Wen", "Yi Wang"], "abstract": "Time series analysis is widely used in many fields such as power energy, economics, and transportation, including different tasks such as forecasting, anomaly detection, classification, etc. Missing values are widely observed in these tasks, and often leading to unpredictable negative effects on existing methods, hindering their further application. In response to this situation, existing time series imputation methods mainly focus on restoring sequences based on their data characteristics, while ignoring the performance of the restored sequences in downstream tasks. Considering different requirements of downstream tasks (e.g., forecasting), this paper proposes an efficient downstream task-oriented time series imputation evaluation approach. By combining time series imputation with neural network models used for downstream tasks, the gain of different imputation strategies on downstream tasks is estimated without retraining, and the most favorable imputation value for downstream tasks is given by combining different imputation strategies according to the estimated gain. The corresponding code can be found in the repository https://github.com/hkuedl/Task-Oriented-Imputation.", "sections": [{"title": "Introduction", "content": "Time series analysis plays a crucial role in many real-world applications, such as energy, finance, healthcare, and other fields [1, 2, 3]. For example, forecasting load series forms the basis for further decision-making in power dispatch in the power grid system, thereby generating a significant amount of economic benefits [4, 5, 6]. However, collecting time series data, especially high-quality ones, is challenging. Due to the instability of the external environment, sensor failures, and even ethical and legal privacy issues, missing values are prevalent in time series data [7]. For instance, in the BDG2 load series dataset [8], widely used in building energy analysis, the ratio of complete time series data is less than 10%.\nTo handle missing values in time series data, numerous methods have been proposed for time series imputation in the literature. Based on the features of the imputation methods, these approaches can be divided into statistical and machine learning methods, such as ARIMA and KNN [9, 10], as well as deep learning-based methods [11, 12, 13, 14]. Both types of methods generally use reconstruction errors of missing values to guide learning and perform evaluation. Recently, some researchers have turned their attention to evaluation strategies based on downstream task performance [15]. However, in most cases, downstream tasks are classification tasks [13], while forecasting tasks, as another important branch of time series-related tasks, have not been fully considered. The main challenge for time series forecasting is that the time series serves as both input and label (output) for the model during training, whereas in classification tasks, it only serves as input for the model."}, {"title": "Related Work", "content": "Time Series Imputation Time series imputation can be primarily classified into two categories: traditional techniques and neural network-based techniques. Traditional methods replace missing values with statistics, such as the mean value or the last observed value [17]. They include simple statistical models like ARIMA [18], ARFIMA, SARIMA [19], and machine learning techniques such as KNNI [20], TIDER [21], MICE [22], BayOTIDE [23]. In recent years, deep learning imputation methods have demonstrated remarkable capabilities in capturing intricate temporal relationships and complex variation patterns inherent in time series data. These methods employ deep learning models like Transformers [24, 13], generative neural networks such as VAEs [12, 25], GANs [26, 27], and diffusion models [28] to capture complex dynamic relationships within time series data. Although different methods exhibit various advantages, no universal method currently outperforms others in all scenarios and datasets. This observation inspires us to consider combining existing advanced methods in this work to achieve better time series imputation strategies.\nSample-based Explaination Sample-based explainable methods can be divided into two categories [29]. One is based on retraining, which evaluates the importance of corresponding data by comparing the impact of removing data points on the model and even the final test results [30, 31, 32]."}, {"title": "Methodology", "content": "Consider a multivariate time series dataset represented by {$(X_i, Y_i)_{i=1}^n$}, incorporating $n$ samples. In this dataset, $X_i \\in \\mathbb{R}^{D \\times L_1}$ corresponds to a feature matrix containing $D$ distinctive features over $L_1$ temporal intervals, whereas $y_i \\in \\mathbb{R}^{L_2}$ signifies the target time series, which spans $L_2$ temporal intervals. It is crucial to recognize that $y_i$ may include several missing entries, a common complication within real-world datasets. For example, in the context of electrical load forecasting, $X_i$ encompasses daily weather-related time series data, comprising variables such as temperature, humidity, and wind speed, while $y_i$ represents the electrical load time series of a given day, possibly containing missing entries due to issues in data collection or transmission.\nAddressing missing values in {$y_i$} through imputation is a fundamental preprocessing step for machine learning tasks involving this data, underscoring the necessity to assess the effectiveness of various imputation methods. Consider {$y^{(1)}_i$} and {$y^{(2)}_i$} as two time series resulting from the imputation of {$y_i$} via two different methods. The goal is to ascertain whether the imputation performed on {$y^{(2)}_i$} is superior to that on {$y^{(1)}_i$}. Moreover, we seek to evaluate the quality of imputation at each temporal interval, determining if the imputation of the $l$-th interval in $y^{(2)}_i$ is more accurate than that in $y^{(1)}_i$.\nConventionally, the quality of imputation is quantified by measuring the discrepancy between the imputed values and the actual data, favoring methods that minimize this deviation. In this study, however, we propose to assess imputation quality based on the performance of subsequent tasks.\nOne step further, we evaluate the quality of imputation on a timestep basis, examining if the imputation for the $l$-th interval in $y^{(2)}_i$ exhibits improved efficacy over $y^{(1)}_i$, thereby offering a more nuanced and comprehensive evaluation of imputation methodologies.\nLet us define the loss function for the downstream task as $\\mathcal{L}(f(X, \\theta), y)$, where $f(\\cdot, \\theta)$ denotes the model used in the downstream task parametered by $\\theta$. And let {$(x_i, y_i)_{i=1}^m$} constitute a test dataset that will be used to gauge model performance. We denote $y^{(1)}_{i,l}$ and $y^{(2)}_{i,l}$ as the $l$-th entries of $y^{(1)}$ and $y^{(2)}$, swapping $y^{(1)}_{i,l}$ and $y^{(2)}_{i,l}$ respectively. According to our intuition, if $y^{(2)}_{i,l}$ is superior to $y^{(1)}_{i,l}$, swapping $y^{(2)}_{i,l}$ for $y^{(1)}_{i,l}$ should result in a decrease in the test set's loss. Guided by this rationale, we define the indicator function $\\mathcal{I}(i, l)$, which discerns whether $y^{(2)}_{i,l}$ is preferable over $y^{(1)}_{i,l}$ as follows:\n$\\mathcal{I}(i, l) = \\sum_{k=1}^m \\mathcal{I}(i,l,X_k) = \\sum_{k=1}^m (\\mathcal{L}(f(X_k, \\theta_1), y_k) - \\mathcal{L}(f(X_k, \\theta_2), y_k))$\ns.t. $\\theta_1 = arg \\min_\\theta \\sum_{k=1}^n \\mathcal{L}(f(X_k, \\theta), y^{(1)}_k)$\n$\\theta_2 = arg \\min_\\theta \\sum_{k \\neq i}^n \\mathcal{L}(f(X_k, \\theta), y^{(1)}_k) + \\mathcal{L}(f(X_i, \\theta), y^{(2,l)}_i)$                                                       (1)"}, {"title": "Approximation Model Construction", "content": "To compute $\\mathcal{I}(i, l)$ efficiently, we propose a retrain-free method in this subsection. As both $y^{(1)}_{i,l}$ and $y^{(2)}_{i,l}$ are imputation of $y$, then we assume that $y^{(2)}_{i,l}$ is close to $y^{(1)}_{i,l}$, with which we approximate $\\mathcal{I}(i, l)$ using the first order Tolyer expansion as\n$\\mathcal{I}(i, l) \\approx \\sum_{k=1}^m \\mathcal{L}(f(X_k, \\theta), y_k) = \\sum_{k=1}^m (\\mathcal{L}(f(X_k, \\theta), y^{(1)}_k) + \\frac{\\partial \\mathcal{L}(f(X_k, \\theta), y)}{\\partial y_{i,l}}|_{y_{i,l} = y^{(1)}_{i,l}} \\frac{\\partial f(X, \\theta)}{\\partial y_{i,l}}|_{y_{i,l} = y^{(1)}_{i,l}} (y^{(1)}_{i,l} - y^{(2)}_{i,l}))                              (2)$\nEquation (2) provides an approximation for computing $\\mathcal{I}(i, l)$, where $\\frac{\\partial f(X_k, \\theta)}{\\partial y_{i,l}}$ measures how the training target $y_{i,l}$ affect the prediction of the test data, and $\\frac{\\partial \\mathcal{L}(f(X_k, \\theta), y)}{\\partial f(X, \\theta)}$ computes how the changing of the prediction of $X_k$ affect the final loss. Note that the symbolic expression $\\frac{\\partial f(X, \\theta)}{\\partial y_{i,l}}$ can be conceptually broken down into $\\frac{\\partial f(X, \\theta)}{\\partial y_{i,l}} = \\frac{\\partial f(X, \\theta)}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial y_{i,l}}$, elucidating the role of the label $y_{i,l}$ in shaping the model parameters $\\theta$ throughout the training process. This, in turn, has repercussions on the model's prediction when evaluated on unseen data from the test set, i.e. $f (X^\\prime, \\theta)$. By focusing on the derivative $\\frac{\\partial f(X, \\theta)}{\\partial y_{i,l}}$, our goal is to assess the extent to which changes in label values $y_{i,l}$ influence the model's predictions on the test set, thereby affecting overall model efficacy.\nWhen it comes back to the estimation, dispite $\\frac{\\partial \\mathcal{L}(f(X_k, \\theta), y)}{\\partial f(X, \\theta)}$ and $(y^{(1)}_{i,l} - y^{(2)}_{i,l})$ are easy to compute, estimating $\\frac{\\partial f(X, \\theta)}{\\partial y_{i,l}}$ is difficult. The difficulty comes from two aspects. Firstly, for the complex $f(\\cdot, \\theta)$, the final parameter is not only affected by the training data, some other factors, such as the structure of the network and learning rate during the learning process. Secondly, all of the $n$ training samples affect the parameters of the model, leading to the mixture of the effect of data points on the final model. Thus isolating the effect of a single data point is difficult.\nTo overcome these two difficulties, we propose to approximate $\\frac{\\partial f(X, \\theta)}{\\partial y_{i,l}}$ using a white-box model, where how each training datapoint affects the final prediction is clear from the design of the model. To this end, we propose to approximate $\\frac{\\partial f(X, \\theta)}{\\partial y_{i,l}}$ using a kernel machine, i.e. $\\sum_{i=1}^n \\alpha_{i,l}K(X_i, X)$, where $K (X_i,)$ is a kenerl between the training sample $X_i$ and test samples measuring the similarity between the $X_i$ and $X$, and $\\alpha$ is a learnerable hyperparameter. It can be proven that the indicator function based on this definition satisfies many desirable properties (please see Appendix for details) to construct an axiomatic attribution. Formally, the coefficient $\\alpha_{i,l} \\in \\mathbb{R}^{L_2}$ can be computed by solving the following optimization problem:\n$\\hat{\\alpha} = argmin_{\\alpha \\in \\mathbb{R}^{n \\times \\mathbb{R}^{L_2} \\times \\mathbb{R}^{L_2}}} \\sum_{i=1}^n \\sum_{l=1}^{L_2} \\sum_{j=1}^{n} K(X_i, X_j), \\frac{\\partial f(X_i, \\theta)}{\\partial y_{i,l}}                                                                                                                          (3)$\nTo solve this problem, $\\frac{f(X_j, \\theta_1)-f(X_j, \\theta_2)}{y^{(1)}_{i,l} - y^{(2)}_{i,l}}$ can act as a substitute of $\\frac{\\partial f(X, \\theta)}{\\partial y_{i,l}}$ since there is no ground truth. However, the problem is still not practical to solve because we can not obtain $f(X_j, \\theta_2)$ without retraining the model. Even though it isn't necessary to traverse all $i$, $j$, and $l$ to obtain the"}, {"title": "Similarity Calculation Acceleration", "content": "In the previous section, to gauge the effects of substituting $y^{(1)}_{i,l}$ with $y^{(2)}_{i,l}$ on the downstream task, we utilized the Neural Tangent Kernel to assess the similarity between the model outputs for inputs $X_i$ and $X_j$. Given that the model's output length is $L_2$, the computational complexity of calculating $\\mathcal{I}(i, l)$ for all time steps in $y$ scales as $\\mathcal{O}(mL_2P)$, where $P$ denotes the total number of parameters in the model $f(\\cdot, \\theta)$, i.e., $|\\theta|$. In numerous time series applications, such as forecasting, $L_2$ can be substantially large (e.g., 128), rendering the evaluation process for all imputations time-consuming. To mitigate this challenge, we propose a method to compress the size of $\\frac{\\partial f(X_i, \\theta)}{\\partial \\theta}$. Our approach is inspired by the observation that in time series forecasting, the output of $f(\\cdot, \\theta)$ typically exhibits smooth variability across different $l$ values. Therefore, we posit that the model output $f(X_i, \\theta)$ resides in a low-dimensional space spanned by a limited number of smooth basis functions. In mathematical terms, $f(X_i, \\theta) \\approx A^{+}Af(X_i, \\theta)$ where $A \\in \\mathbb{R}^{r \\times L_2}$ consists of rows each representing a predefined smooth vector, $A^{+} \\in \\mathbb{R}^{L_2 \\times r}$ is the pseudo-inverse of $A$, and $r$, which is significantly smaller than $L_2$, denotes the number of basis functions employed to approximate $f(X_i, \\theta)$. Consequently, we can approximate $\\frac{\\partial f(X_i, \\theta)}{\\partial \\theta}$ as:\n$\\frac{\\partial f(X_i, \\theta)}{\\partial \\theta} \\approx A^{+}\\frac{\\partial Af(X_i, \\theta)}{\\partial \\theta}                                                              (9)$\nThis approximation allows for the compression of the model output, thereby reducing the number of gradients that require computation. Through this simplification, the computational complexity for calculating $\\mathcal{I}(i, l)$ decreases to $\\mathcal{O}(mrP)$, substantially less than the original complexity.\nIn our experiments, we further simplify by assuming $A$ to be a block diagonal matrix, defined as $blkdiag(1_{1}, 1_{2}, ..., 1_{c})$, where $1_{1} = ... = 1_{c-1}$ are vectors of length $\\lceil L_2/c \\rceil$ with all elements equal to 1, and $1_{c} \\in \\mathbb{R}^{L_2-(c-1)\\lceil L_2/c \\rceil}$ is a vector with all elements equal to 1."}, {"title": "Task-oriented Imputation Evaluation", "content": "We have introduced a method for computing the indicator $\\mathcal{I}(i,l)$, which assesses if replacing $y^{(1)}_{i,l}$ with $y^{(2)}_{i,l}$ results in a reduced loss for the downstream task. Given two sets of imputation results, {$y^{(1)}_i$ and {$y^{(2)}_i$}, derived from distinct imputation techniques, we can evaluate $\\mathcal{I}(i, l)$ across all samples and time steps, and identify that $y^{(2)}_{i,l}$ outperforms $y^{(1)}_{i,l}$ at time step $l$ if $\\mathcal{I}(i,l)$ greater than zero and vice versa if the value is lesser. In contrast to conventional evaluation strategies, our proposed method does not necessitate the availability of the ground truth $y$, thereby enhancing its practical utility in myriad real-world scenarios where actual values remain unobtainable. This feature renders our approach significantly more adaptable to situations where empirical truths are elusive."}, {"title": "Task-oriented Imputation Emsemble", "content": "Given that our proposed method can evaluate the quality of two imputations at the time step level, a natural extension is to combine these two sets of imputations to derive an improved result. Specifically, we can generate a new set of imputations $y$ for the $i$-th sample, where the $l$-th entry is $Y_{i,l}$ if $\\mathcal{I}(i,l) > 0$, and $y^{(1)}_{i,l}$ otherwise. Based on the definition of $\\mathcal{I}(i,l)$, we anticipate that a model trained using $y$ will incur a lower loss compared to one trained with $y^{(1)}$, thereby yielding better imputation results. It is important to note, however, that the calculation of $\\mathcal{I}(i, l)$ is predicated"}, {"title": "Experiment", "content": "To validate our method, we conduct experiments on six datasets: the GEF load forecasting competition dataset with the corresponding temperature [39], the UCI dataset (electricity load and air quality) [40], the Traffic dataset containing road occupancy rates\u00b2, and two transformer datasets, ETTH1 and ETTH2 [41]. Note that we use the hourly resolution version of the UCI electricity dataset from [42] in the main experiment. In our main experiment, we set the downstream task as univariate time series forecasting, with both input sequence and prediction lengths set to 24. In addition to the GEF dataset, we implement our method on the 'OT' time series in ETH1 and ETH2, the mean value of the road occupancy rate in Traffic, the temperature in the UCI air quality dataset, and the total electricity consumption of 321 users in the UCI electricity dataset. It is important to note that there are no original missing values in these datasets. To simulate the missing values situation, we randomly set masks with lengths in [2, 4, 6, 12, 24, 48, 96, 120], and replace the original values with the average value at the corresponding positions as the baseline. For the missing rate setting, if the missing rate is too low, the difference between different imputation methods may be small, while if the missing rate is too high, the even best imputation method will also be difficult to obtain reasonable results. Based on the above considerations, we mainly consider 40% missing rates as our main experimental setup. Meanwhile, we will provide experimental results under other missing rate settings in [30%, 50%, 60%] in the Appendix."}, {"title": "Time Series Imputation Methods", "content": "To verify the performance of our strategy in evaluating different time imputation methods, we introduce multiple advanced time imputation methods. Firstly, as mentioned in the last subsection, we use the basic mean value imputation as the baseline. Secondly, we consider several time series imputation methods based on deep neural networks. They are GPVAE [25] and USGAN [27] based on generative neural network, mRNN [43] and BRITS [11] based on RNN structure, SAITS [13], and ImputeFormer [44] based on attention mechanism. All the implementations of the above models are with the help of the toolkit called PyPOTS [45]. In addition, we also implement the network structure of a spatiotemporal graphs-assisted method called SPIN [46] for time series imputation. All the details of the neural network setting will be described in the Appendix."}, {"title": "Experimental Results", "content": "Application 1: Estimate the Gain\nIn this section, we examine the estimated gains of imputation for each time step. We divide the GEF dataset into a training set and a test set, where the training set includes load data from 2011 and the test set includes load data from 2012. We replace 40% of the load data in the training set with the average value at the corresponding position as the baseline, apply the linear interpolation method to replace the corresponding baseline, and use them as training labels separately. In the training set, we have obtained a total of 8760 training samples. Therefore, we replace the labels of each sample one by one to construct new 8760 sets of samples, retrain 8760 forecasting models, test their performance on the test set, and compare the performance of the new model with the model trained on the mean value-based samples. Note that although our estimation is done at each time step of each sample, the time consumption of replacing each time step and retraining is too high. Therefore, we replace all the time steps in each sample and sum up the benefit estimates for each time step as the benefit estimate for the entire sample after replacement. We adopt the 3-layer MLP structure used in [35] and extend it to be used for time series. In addition, we have also added a simple and widely used forecasting model, DLinear [47], as our forecasting backbone model."}, {"title": "Application 2: Combine Different Time Series Imputation", "content": "Similar to the previous section, we use mean value as a baseline to estimate the benefits on the validation set (not test set) obtained by imputation at each time step and replace the 10% time step with the highest benefits to train the forecasting model. In addition, the missing values in the time series damage the original characteristic of the time series. Although imputation values can repair it to some extent, they may still have adverse effects on downstream tasks. Therefore, we also introduce the Influence Function as a comparison, using it to estimate the 10% points with the worst impact on the forecasting results after imputation and remove them, which is often the case in the application of Influence Function [34].\nTable 2 reports the comparison of MSE for downstream forecasting tasks (here we use the DLinear as the backbone model), and we will analyze from two aspects.\nI. Comparison between Original and Gain Estimation. Part I and II in Table 2 demonstrate that combining different imputations can enhance the performance of downstream tasks on all datasets. The improvements in the GEF dataset, Electricity dataset, and Traffic dataset are significant, while the enhancement in others is relatively less noticeable. The primary reason is that, in those datasets, the performance of other imputation methods considerably lags behind the original one, making the replacement of the original label with a newly imputed label seem less impactful. However, after incorporating our estimation, there is still a slight improvement in forecasting performance. On the other hand, when considering combining two imputation methods with similar original performance, incorporating our method will bring significant gains (as seen in the GEF datasets). It's worth noting that the mean value used as a baseline outperforms other imputation methods in most cases, primarily because the training data input is also based on mean value imputation, facilitating unified and convenient comparisons. In practical applications, we can also apply other advanced imputation methods to the input data and modify the labels based on the estimated benefits.\nII. Comparison between Gain Estimation and Influence Function. Part I, II, and III Table 2 indicate that discarding a certain number of samples according to the Influence Function can indeed improve the performance of forecasting; however, such improvement is not universal. In the AIR dataset, discarding some data can negatively impact the performance of most methods. This may be due to the small amount of data contained in the AIR dataset, resulting in a greater adverse effect when discarding data. The operation of discarding data can only consider one imputation method, while our method can combine any two imputation methods to achieve better results. Furthermore, the results of repeated experiments show that the strategy of modifying values at specific time steps can make performance more stable, as its variance is significantly smaller than that of discarding data.\nIn addition to the univariate input results displayed in Table 2, we also include the results of multivariate inputs, which are common in practical applications. For instance, when predicting power loads, temperature is a crucial external variable. A large amount of research has focused on studying the relationship between load and temperature [48, 49]. In this experimental setting, unlike multivariate forecasting, temperature plays an auxiliary role in load forecasting while there is no need to forecast temperature itself. Consequently, we conduct experiments on the GEF dataset, inputting temperature as an external variable into the model to forecast loads. Table 3 presents the performance of our model under multivariate input, which is consistent with the univariate input scenario, and incorporating our method proves to be beneficial."}, {"title": "Conclusion and Future Work", "content": "In this work, we propose to evaluate the imputation values at each time step for the impact on downstream forecasting tasks. On the one hand, our method can accurately estimate the gain of each imputation value without retraining. On the other hand, our method can also combine different time series imputation strategies based on the estimation of gain to obtain better imputation for downstream tasks. To ensure the applicability of this method in practical scenarios, we also provide an accelerated calculation method. In the future, we will focus on further downstream tasks, such as optimization tasks based on prediction values, and build an end-to-end evaluation strategy."}, {"title": "Why We Need Task-oriented Imputation", "content": "Here we use a toy example to illustrate that, in some cases, we can not directly use the accuracy of imputation instead of downstream tasks to evaluate the imputation method. We want to point out that better imputation accuracy does not always mean better forecasting performance, and we simulate a dataset based on the GEF dataset to illustrate this viewpoint, experimenting with a predicted length of 24. Suppose that we only observed the value at the time step $n_k$ ($k\\geq0$) and $n_{k+1}$ ($k\\geq1$), just for the convenience of linear interpolation. In the first case(represented by I), we set n = 4, fill the missing value with linear interpolation, and uniformly add Gaussian noise $N(0.05,0.3)$. In the second case(represented by II), we set n = 6 and only do the linear interpolation (shown in Figure 2). We put two data sets into MLP and calculated the forecasting error as shown in the following Table 4."}, {"title": "Axioms", "content": "In [36], there are several axioms desirable for a fair attribution. In this section, we modify them to a version suitable for our task and demonstrate that our method satisfies such properties. Here we use $\\mathcal{I}(i, l, X_k)$ to represent the impact of the perturbation of the $l$-th step of the $i$-th sample on sample $X_k$.\nDefinition 1 (Efficiency Axiom). For any model $f(\\cdot, \\theta)$, and test point $X_k$, an indication function $\\mathcal{I}(\\cdot, \\cdot, \\cdot)$ satisfies the efficiency axiom iff:\n$\\sum_{i=1}^n \\sum_{l=1}^{L_2} \\mathcal{I}(i, l) = \\sum_{k=1}^m (\\mathcal{L} (f (X_k, \\theta_1), y) - \\mathcal{L} (f (X_k, \\theta_2), y))$\ns.t. $\\theta_1 = arg \\min_\\theta \\sum_{k=1}^n \\mathcal{L} (f (X_k, \\theta), y^{(1)}_k)$\n$\\theta_2 = arg \\min_\\theta \\sum_{k=1}^n \\mathcal{L} (f (X_k, \\theta), y^{(2)}_k)$"}, {"title": "Discussion on Remark 1", "content": "Remark 1. Given two infinitely differentiable functions $f(x)$ and $g(x)$ in a bounded domain $D \\in \\mathbb{R}^n$, $|f(x) - g(x)|$ is always less than $\\epsilon$. For any given $\\delta$ and $\\epsilon_2$, there exists an $\\epsilon$ such that, in the domain $D$, the measure of the region $I$ that satisfying $|\\frac{\\partial f(x)}{\\partial x} - \\frac{\\partial g(x)}{\\partial x}| > \\delta$ is not greater than $\\epsilon_2$, i.e, $m(I) \\leq \\epsilon_2$.\nCorrectness. Firstly, we can relax the restrictions on the function by requiring that each dimension of the function on $\\mathbb{R}^n$ be continuous. Then, we can simplify the problem into a one-dimensional case on $\\mathbb{R}$. Secondly, we can let $h(x) = f(x) - g(x)$ (note that $|h(x)| < \\epsilon$), and then our problem can be transformed into proving that for any given $\\delta$ and $\\epsilon_2$, there exists an $\\epsilon$ such that, in the interval [a, b], the measure of the region satisfying $|h'(x)| > \\delta$ is less than $\\epsilon_2$.\nLet the domain $I$ represent the set of all x that satisfy $|h'(x)| > \\delta$. We first need to prove that $I$ can be rewritten as the union of several disjoint intervals $I_i$ that satisfy"}, {"title": "Implementation Details", "content": "Table 5 summarizes the dataset partitioning we used. Except for the GEF data, the rest are multivariate datasets. We forecast the 'OT' sequences in ETH1 and ETH2, as well as the combined electricity"}, {"title": "Datasets for forecasting", "content": ""}, {"title": "Implementation of time series forecasting model", "content": "We include two models in our experiment. The first one is a 3-layer MLP in which the input size and output size are both 24 while the hidden size is 128. In addition, we mainly apply the simple and high-performance DLiner with default setting in [47] as our forecasting model backbone. In addition, to adapt to situations where the input and output dimensions are different, we constructed an output layer at the end of the DLiner model, mapping the output of multiple variables to the output of a specified dimension. We use the torch.SGD optimizer [53] to optimize the parameters of the model, where the learning rate is set to 0.1. The maximum epochs for each training are 300, and the patience is set to 10."}, {"title": "Implementation of time series imputation model", "content": "We have introduced a total of five imputation methods for comparison, and all experiments were based on pyPOTS [45] except for SPIN. The hyperparameters for each method are set as shown in Table 6. In addition, referring to [13], we set the total training epoch to 100 and the patience to 10, while other hyperparameters are the default setting."}, {"title": "Implementation of our estimation", "content": "In section 2.2, we gives the estimation of $\\mathcal{I}(i, l)$ as follows,\n$\\frac{1}{n} \\sum_{t \\in [T]: i \\in B(t)} \\frac{\\eta^{(t)}}{B(t)} \\frac{\\partial^2 \\mathcal{L} (f(\\tilde{X}_{i}^{(t-1)}, \\theta), y_i)}{\\partial f(\\tilde{X}_{i}^{(t-1)}, \\theta) \\partial y_{i,l}} \\frac{\\partial f(\\tilde{X}_i, \\theta)}{\\partial \\theta} \\frac{\\partial f(X, \\theta)^T}{\\partial \\theta}|_{\\theta = \\theta^{(t)}}$        (15)\nHowever, depending on the solution to the optimization problem (7), we may have different forms of estimation for $\\mathcal{I}(i, l)$. Referring to [36, 35], when we no longer only consider the downstream model parameters at the moment of training convergence but also consider the entire training process, we can obtain another form of solution to the optimization problem that"}, {"title": "Hareware usage", "content": "We use 1 NVIDIA GTX 4090 GPU with 24GB of memory for all our experiments."}, {"title": "Potential Social Impact", "content": "Our estimation may not be 100% accurate compared to the actual situation, so it is possible to introduce bias in the evaluation among different imputation strategies, which may further have adverse effects on downstream tasks."}, {"title": "Supplementary Experimental Results", "content": "Acceleration method"}, {"title": "Performance of the acceleration method", "content": "In our practice, we mainly examine the benefits of modifying each time step on downstream tasks. Therefore, we mainly focus on whether the gain estimation is positive or negative without providing precise values. Based on this idea, we provide methods for accelerating calculations in Section 2.3. Here, we present a comparison between the accelerated estimate and the original estimate. Note that we conduct this experiment on three datasets and they are GEF, ELECTRICITY, and a generated time series, denoted by Brown, based on the following Python code."}, {"title": "A larger dataset", "content": "For large-scale data, we applied our method to a 15-minute resolution UCI electricity dataset (with approximately 100000 training points) and we adjusted our experimental setup to input 96 points and output 96 points, and here is the result."}, {"title": "Additional missing rate", "content": "In addition to the 40% missing rate in the main experiment, we also conduct several experiments in the ELECTRICITY dataset with missing rates in [30%, 50%, 60%]."}, {"title": "Combination with robust time series forecasting", "content": "In addition to our solution, some kinds of methods, such as robust time series forecasting, to deal with missing (anomaly) values have been proposed these days. Here we combine our method with [16], which is one of the SOTA of such kind of method to illustrate that this kind of method is not contradictory to our approach but can be combined. Note that the hyperparameters are the same as the original paper in [16] and we replace the dataset with ours."}]}