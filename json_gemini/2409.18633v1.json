{"title": "Reducing Diversity to Generate Hierarchical Archetypes", "authors": ["Alfredo Ibias", "Hector Antona", "Guillem Ramirez-Miranda", "Enric Guinovart", "Eduard Alarcon"], "abstract": "The Artificial Intelligence field seldom address the development of a fundamental building piece: a framework, methodology or algorithm to automatically build hierarchies of abstractions. This is a key requirement in order to build intelligent behaviour, as recent neuroscience studies clearly expose. In this paper we present a primitive-based framework to automatically generate hierarchies of constructive archetypes, as a theory of how to generate hierarchies of abstractions. We assume the existence of a primitive with very specific characteristics, and we develop our framework over it. We prove the effectiveness of our framework through mathematical definitions and proofs. Finally, we give a few insights about potential uses of our framework and the expected results.", "sections": [{"title": "1. Introduction", "content": "Novel theories of the brain claim that our brains predict the world [1]. They do it by modelling the world in some form of abstraction, and then simulating what would happen. However, to model the world, first they need to extract, from a myriad of real world perceptions of, for example, an object (that is, a set of expressions of that object), the essence of such object in the form of a model or representation. These representations are what in the Artificial Intelligence field has been termed an abstraction, and what in this paper we aim to capture in the form of archetypes. An archetype would be an object able to express the same behaviour than the abstraction it represents when manipulated, and it can be simple (with just one component) or composed (being the product of multiple individual components).\nComing back to how our brain works, it is important to know that we not only build standalone abstractions of objects, but instead we generate abstractions in a constructive and hierarchical way [2]. For instance, four wooden sticks and a wooden board make a wooden table, and the union of tables, chairs and other objects makes the concept of furniture. This kind of hierarchical thinking is known to be a major player in how cognition and intelligent behaviour develops [3]. Moreover, our own brain is known to be divided into a processing hierarchy, where higher levels of the cortex deal with more abstract concepts. For instance, a monkey's brain has less cortex levels and thus has more difficulties developing intelligent behaviours [2].\nThis functioning arises a fundamental task: to develop frameworks to automatically build hierarchies of constructive abstractions. However, since the beginning of the Artificial Intelligence field, very few proposals have been focused on developing such frameworks. That has not impeded the development of a plethora of methods and algorithms that can simulate to work with such hierarchies, although none of them has been proven to actually build them. The most successful proposal, Deep Neural Networks [4], is able to recognise thousands of different objects if trained properly [5], and even clusters them together in a latent space [6]. However, no hierarchy of constructive abstractions is built and no cognition arises from such clustering.\nUp to date, most of the developed algorithms have a huge dependency on a very basic assumption: they are optimising. This implies that the input and output spaces are assumed to be infinite mathematical spaces and the task becomes mapping from one to the other. However, as novel theories of the brain [1] (based on neuroscience research results) clearly expose, that is not how our brains work. In fact, our brain works in a constructive way, were abstractions are built based on the observed world. And then the brain organises such abstractions in a hierarchy, building higher level abstractions the higher in the hierarchy a concept is dealt with [3]. Thus, any proposal of artificial general intelligence algorithm should include a framework to automatically build such hierarchies of abstractions."}, {"title": "2. Related Work", "content": "The use of archetypes is not something new in the Artificial Intelligence field. Even less in science in general. In fact, automatic tools to generate archetypes have been used in fields as diverse as environmental simulations [7], energy modelling [8] and video-game modelling [9]. But what all these fields have in common is that they fail to build hierarchies of those archetypes.\nThe use of hierarchies is nothing new neither. In fact, there is a huge field for generating hierarchies of neural networks [10, 11, 12], and another huge field that tries to find hierarchies of representations in neural networks [13, 14]. Also, there are some works in the reinforcement learning field that use hierarchies, with approaches like using a hierarchy for temporal abstractions [15, 16, 17]. However, none of these proposals build constructive abstractions, and in the best cases the abstractions are pre-defined by the user.\nFinally, the closest to a proposal of hierarchies of abstractions that we are aware of is the Rasmussen Hierarchy abstraction [18], more recently called abstraction-decomposition space [19]. It is a method to perform work domain analysis, a task focused on analysing and modelling process control systems. However, this is not general and thus is not close to what we aim to achieve in this paper.\nThus, to the best of our knowledge, there are no other proposals of a framework, methodology or algorithm to build hierarchies of constructive abstractions through archetypes."}, {"title": "3. The Diversity Reduction Framework", "content": "Our proposal is a framework we called Diversity Reduction Framework (DRF) that is based on a primitive. Thus, such primitive has a huge impact on the performance and capabilities of our algorithm. However, in this paper we do not present an example of such a primitive, but instead a series of characteristics that such a primitive has to have for the framework to work as intended. To be precise, we assume that the primitive over which the framework is built has the following characteristics:\n\u2022 Constructive approach: the primitive should not assume the existence of an input space, but instead take an input set and construct archetypes that will conform its output set.\n\u2022 Same input shape than output shape: as the output set of the primitive will become the input set of another instance of the primitive, it is mandatory that their input and output sets are of the same shape.\n\u2022 Reduction of diversity: the primitive should be able to produce a smaller output set than its input set. This way the primitive will be reducing the diversity present in the input set.\n\u2022 Projections: the primitive should be able to generate projections of its archetypes, in order to transform any archetype into an input value.\nAn example of primitive is displayed in Figure 1, that receives an input and produces an output and a projection. We define a primitive $P$ as a process able to receive a finite input set $I$ and produce an output set $O$ with less elements than $I$. However, $O$ can not be any output set, it has to be an output set for which it exists a \u201creverse\u201d function $f$ that, given an element $o \\in O$, it produces an element $i \\in I$ such that it is one of the elements that $P$ maps to $o$. That is, in a more formal way, if $f(o) = i$ then $P(i) = o$, thus $P(f(o)) = o$. However, it is not always true that $f(P(i)) = i$, as it is not mandatory that the recovered input is the same, but only that it is one of the inputs mapped to $o$. This output set $O$ is what we called a latent set of $I$, because it contains enough information to represent the input set $I$ with less elements, and thus we consider its elements to be archetypes of the elements of $I$. Additionally, $f$ will be the projection function of the primitive. A more formal definition of these components is presented in the next section.\nReducing diversity is the fundamental task of the primitive, as it is the base assumption over which most of the framework is built (as will be made clear in Theorem 2). We define diversity as the number of different elements in a set, in a similar fashion than previous work [20]. This property ensures that we apply the principle of \u201cto comprehension through compression", "element": "the method by which the framework composes signals from the lower levels. We propose two options for such composition: averaging the lower level outputs, or concatenating them.\nWith the first option we will be building compositions of archetypes that would improve the discriminability of the primitive. This type of composition is more suited for identifying samples, like an image of a table versus an image of a chair. A structure that uses the averaging composition is what we call a discriminatory pyramid, and an example of it is displayed in Figure 2. A fundamental property of any discriminatory pyramid is that it builds a latent set of its unique input set as long as the primitive does so, thus the final output set is a smaller latent set of the global input set. A more formal definition of this structure is presented in the next section.\nIf we choose the second option we will be building compositions of archetypes that would focus on the association between them. This type of composition is more suited for associating patterns, like an image of a table and its sound when moved. A structure that uses the concatenation composition is what we call an associative layer, and an example of it is displayed in Figure 3. A fundamental property of any associative layer is that it builds a latent set of the associations between its different input sets, and if its input sets are latent sets then the final output set is a latent set of the associations between those input latent sets, and thus between the global input sets. A more formal definition of this structure is presented in the next section.\nOne extra requirement of our proposal is that any archetype can be materialised into an actual value of the input set, as we need to be able to materialise the archetypes in order to interpret them. Thus, a kind of double way should be built, where in one pass the inputs are being archetyped and in another pass the archetypes are being materialised into input values. To that end, the requirement of our primitive that the input and output shapes should be the same is primordial, as that allows for working with the same shape in any direction. It is also fundamental the requirement that the primitive can build projections, as those will be the materialisation of the archetypes that will be used in the downward pass.\nAn illustrative example of the intuition behind how this framework would work will be the furniture example: let us start by creating a different primitive for each possible material of table, one for wooden tables, other for metal tables, another more for plastic tables, etc... These primitives will take in all the diversity of possible tables of their material and archetype them in few archetypes, simplifying in that sense all the possible tables of one material into an archetype of table of that material. We can make a similar deployment for chairs, sofas, etc... Now, going one level up, we will deploy a primitive that receives as input all the outputs of the material table primitives. Thus, this table primitive will compose all the archetypes of the different table materials, and build few archetypes of tables. For example, it can build the archetypes of circular tables, square tables, etc... independently of their material. Then, we have an archetype of tables. Similar deployment can be done for chairs, sofas, etc... Finally, in the final level, we can deploy a primitive for furniture, that will take as input the different furniture archetypes generated in the previous level and build archetypes of furniture as a concept.\nThis example gives the basic intuition about how a discriminatory pyramid work, building archetypes of each time more complex concepts. To give the intuition of how an associative layer works we need a more complex example, were we have inputs with different typology that have an association between them. A basic example of this will be the pattern matching example. Let us have a dataset with samples and associated labels, then we will build an associative layer that receives as inputs in one side the sample and in the other side the label. It will then build archetypes of their relationships. This way, the primitive will detect patterns via building associative archetypes of pairs of sample and label.\nIn this last example, the requirement of our proposal of being able to materialise any archetype into an actual value is very useful. It allows us to provide the associative layer with one sample, and use the archetypes generated by the primitive of the associative layer to find the label associated with such sample. This would allow to classify previously unseen samples using our learned archetypes and their association with labels.\nFinally, a mixed structure, with lower level primitives that use the average composition and higher level primitives that use the concatenation composition, could potentially develop higher level archetypes of very good quality. In that sense, for each input type, we would have a discriminatory pyramid taking such input, transforming it into an archetype, and averaging their archetypes in a pyramidal structure until the highest level primitive has the most defined archetype able to identify the sample. Then, once we have one of these structures for each input type, we can start associating those archetypal inputs using associative layers that receive as input the outputs of the discriminatory pyramids. The discriminatory pyramids have properly identified the input and the associative layers only find the relationships between different inputs, until the highest level primitive finds the total relationship between all the inputs.\nA good example for this last case would be the association between the sounds of tables and images of tables. Having a discriminatory pyramid identifying the sounds and splitting between the sounds of metal tables and those of wooden tables or plastic tables, and then having another discriminatory pyramid identifying the images of tables and splitting between the images of metal tables and those of wooden tables or plastic tables, allows us to have an associative layer generating archetypes of the association between the sound and image of different tables based on their material. As the inputs would always come synchronised (an image of a wooden table will always come with a sound of a wooden table), then the resulting structure is able to identify the material of a table based on either its sound or its image. Moreover, it is able to recover, from an image of a table, a sample of the sound it could produce. Note here that, for this example, there would be a need for the transformation of both sound and image to a same datatype (like an Sparse Distributed Representation) in order to be able to process them with the same kind of primitive. However, as that is an implementation concern, in the rest of the paper we will assume that those details are being taken care of."}, {"title": "4. Proofs", "content": "In this section we will present some definitions, theorems and proofs that will prove that our framework does what we claim. First, we will delve into the properties and efectiveness of the primitive. Later, we will focus on the scalability component of our framework in two steps: first focusing on the discriminatory pyramids, and later in the associative layers."}, {"title": "4.1. The primitive and its properties", "content": "Let us start by proving some theorems about the primitive that are derived from its properties. First, we need to define a preliminary building block: a process.\nDefinition 1. A process $P$ is any collection of transformations and operations that transform elements from an input set $I$ to elements of an output set $O$.\nA process $P$ can be parameterised, and thus generate different instances of it with different values of its parameters.\nThis definition of process is the building block over which we will build our definition of primitive.\nNow, we need to prove that any process is equivalent to a mathematical surjective function as long as its output set is equal or smaller than its input set.\nTheorem 1. Given a process $P$, and given an input set $I$, if $P(I)$ produces an output set $O$, with $|O| < |I|$, then $P$ is equivalent to a surjective function mapping $I \\rightarrow O$.\nProof. If the input set $I$ has size $|I| = n$, and the process $P$ processes $I$ and produces an output set $O$ with size $|O| \\leq n$, then there is an association between the sets $I$ and $O$ in the form of pairs composed of an input $i \\in I$ and an output $o \\in O$.\nThere will be as many pairs as inputs, and if $|O| = n$ no output will appear in more than one pair. Otherwise, by the pigeonhole principle, there will be at least one output $o$ appearing in more than one pair.\nIf we take these pairs, we can build a surjective function that maps, for each pair, its input to its output. Thus, there exists a surjective function that maps $I \\rightarrow O$ in the same fashion than $P$. And $P$ will be equivalent to such function.\nThis result allows us to reason about processes as mathematical functions, what will be necessary in future proofs.\nWe also need to prove that any process that produces an smaller output set is reducing the diversity that comes from its input set.\nTheorem 2. Given a process $P$, and given an input set $I$, if $P(I)$ produces an output set $O$, with $|O| < |I|$, then $P$ is a function that reduces diversity."}, {"title": "4.2. Discriminatory Pyramids", "content": "Let us now analyse the discrimination power of the discriminatory pyramids. First, we need to define what is a discriminatory pyramid.\nDefinition 4. Given a primitive $P$, a discriminatory pyramid $DP$ is a hierarchical structure composed of multiple instances of the primitive $P$. A pyramid has $n$ levels, and in each level it has $2^l$ primitives, with $l$ being the level number starting from the top with the level 0.\nThe $2^n$ primitives of level $n$ receive all of them the same input, an element $i \\in I$, and the final output of the pyramid is the output of the primitive of the level 0, that is an element $o \\in O$. Thus, $I$ is the input set of the pyramid and $O$ is its output set.\nFinally, between each level there is an average of the lower level outputs. These averaged values will be the inputs of the higher level.\nAn example of discriminatory pyramid is displayed in Figure 2 (left). With this definition, we can start analysing its properties. First, let us show that the averaging of two latent sets is still a latent set.\nTheorem 4. Given a primitive $P$, an input set $I$, two latent sets of that input set $O_1$ and $O_2$ produced by two different instances of $P$, and a function $f : (O_1 \\times O_2) \\rightarrow O$ that computes the average of the inputs, then $O$ is a latent set of $I$.\nProof. Let us assume $O$ is not a latent set of $I$. Then, by Definition 2, there will be no injective function $f : O \\rightarrow I$ such that $f$ maps each element $o \\in O$ to an unique element of $i \\in I$ and such element $i$ is one of the elements that are mapped to $o$ via $P$.\nNow, each element $o\\in O$ is an average of other two elements $o_1 \\in O_1$ and $o_2 \\in O_2$. Thus $o = \\frac{o_1+o_2}{2}$.\nWe also have that both $o_1$ and $o_2$ have been produced from the same input $i\\in I$ through two instances $P_1$ and $P_2$ of the primitive $P$. Thus $o=\\frac{P_1(i)+P_2(i)}{2}$.\nIf we assume, without loss of generality, that $|O_1| > |O_2|$, then we have that $|O| = |O_1|$. Thus $|O| < |I|$.\nNow, we know of the existence of two injective functions $P_1^{-1}$ and $P_2^{-1}$ such that $P_1^{-1}(o_1) = i$ and $P_2^{-1}(o_2) = i$ respectively. Thus, we can build a function $f$ such that:\n$f_{o_2}(o) = P_1^{-1}(2o - o_2)$\n$= P_1^{-1}(2 \\cdot o \u2013 P_2(i))$\n$= P_1^{-1}(2 \\cdot \\frac{P_1(i) + P_2(i)}{2} \u2013 P_2(i))$\n$= P_1^{-1}(P_1(i))$\n$= i$\nfor all $o \\in O$.\nFinally, $f$ is an injective function because $|O| = |O_1|$ and $P_1^{-1}$ is already an injective function.\nThus, there exists an injective function $f : O \\rightarrow I$ such that $f$ maps each element $o \\in O$ to an unique element of $i \\in I$ and such element $i$ is one of the elements that are mapped to $o$ via $P$.\nWith this result we can claim that averaging latent sets still produces a latent set. However, unlike other proofs that will come later, this proof does not provide us with an useful projection function for implementation, as it will depend on the specifics of the implemented primitive. This will make the implementation of the discriminatory pyramids harder, but not impossible.\nNow, let us prove that the latent set of a latent set is still a latent set of the original set.\nTheorem 5. Given a primitive $P$, an input set $I$, a latent set of that input set $O_1$ produced by $P$, and a latent set $O_2$ of the latent set $O_1$ produced by $P$, then $O_2$ is a latent set of the input set $I$.\nProof. Let us assume $O_2$ is not a latent set of $I$. Then, by Definition 2, there will be no injective function $f : O_2 \\rightarrow I$ such that $f$ maps each element $o \\in O_2$ to an unique element of $i \\in I$ and such element $i$ is one of the elements that are mapped to $o$ via $P$.\nNow, we have that, by Definition 2, there exists functions $f_1$ and $f_2$ such that $f_1$ maps each element $o_1 \\in O_1$ to an unique element $i \\in I$ with $P(i) = o_1$, and $f_2$ maps each element $o_2 \\in O_2$ to an unique element $o_1 \\in O_1$ with $P(o_1) = o_2$. Then, the composition of $f_2 \\circ f_1$ is a function that maps each element $o_2 \\in O_2$ to an unique element of $i \\in I$.\nNow, such element $i$ is mapped to $o_1 \\in O_1$ via $P$, that is, $P(i) = o_1$. And this element $o_1$ is mapped to $o_2 \\in O_2$ via $P$, that is $P(o_1) = o_2$. Thus, $i$ is one of the elements that are mapped to $o_2$ via $P$. Thus, $O_2$ is a latent set of $I$.\nThis result proves the transitivity property of latent sets, what will be useful in following proofs.\nFinally, let us show how the output set $O$ of a discriminatory pyramid is still a latent set of its input set $I$.\nTheorem 6. Given a primitive $P$ and given a discriminatory pyramid $DP$ composed of $n$ levels of instances of the primitive $P$, with an input set $I$ and an output set $O$, then $O$ is a latent set of $I$.\nProof. Let us assume $O$ is not a latent set of the input set $I$. Then, by Definition 2, there will be no injective function $f : O \\rightarrow I$ such that $f$ maps each element $o \\in O$ to an unique element of $i \\in I$, and such element $i$ is one of the elements that are mapped to $o$ via $P$.\nNow, by Definition 3, each instance of the primitive $P$ takes its input set and transforms it into a latent set of it. Thus, any primitive in the $n$th level will transform the input set $I$ into a latent set of it $O_{n-1}$.\nTo conform the input set of the primitives of level $n-1$, an average of the outputs of each pair of primitives of level $n$ is computed. This process transforms two output sets that are latent sets of $I$ into an unique output set $O_{n-1}$ that is a latent set of the input set $I$ due to Theorem 4.\nAt level $0 < m < n$, the primitives receive a latent set $O_m$ of the input set $I$ and transform them into a latent set $O_{m-1}$ of the set $O_m$, but by Theorem 5 these new latent sets are latent sets of $I$. And the average function transform those latent sets $O_{m-1_i}$ into latent sets $O_{m-1}$ of the latent sets $O_{m-1_i}$, that by Theorem 5 are latent sets of $I$.\nFinally, at level $m = 0$, the last primitive receives a latent set $O_1$ of the input set $I$ and transform it into a latent set $O$ of the set $O_1$, that by Theorem 5 is a latent set of $I$. Thus, $O$ is a latent set of $I$.\nThis result proves that our discriminatory pyramids are still producing archetypes.\nNow, let us prove that the archetypes produced by a discriminatory pyramid are more refined than the archetypes of a single primitive.\nTheorem 7. Given a primitive $P$ and given a discriminatory pyramid $DP$ composed of $n > 1$ levels of instances of the primitive $P$, both with an input set $I$, and $P$ producing an output set $O_P$ and $DP$ producing an output set $O_{DP}$, then $|I| > |O_P| > |O_{DP}|$\nProof. Let us start by considering an individual primitive $P$ with input set $I$, then $P$ produces an output set $O_P$ such that $|O_P| < |I|$.\nNow, let us consider level $n$ of $DP$. In this level, the inputs of each group of two primitives are the same, and both of them transform the input set $I$ into two output sets $O_{n-1_1}$ and $O_{n-1_2}$ with $|I| > |O_{n-1_1}|$ and $|I| > |O_{n-1_2}|$.\nNow, the input set of the average function is not all the possible combinations of values of $O_{n-1_1}$ and $O_{n-1_2}$, but instead the set of pairs $\\{(o_1, o_2) | o_1 \\in O_{n-1_1}, o_2 \\in O_{n-1_2}, o_1 = P_{n_1}(i), o_2 = P_{n_2}(i)\\}$. Having in account that the output set $O_{n-1}$ of the average function has as many values as its input set, we have that $|O_{n-1}| = max(|O_{n-1_1}|, |O_{n-1_2}|)$, and thus $|I| > |O_{n-1}| \\approx |O_P|$.\nNow, for any level $0 < m < n$, we have that each group of two primitives have two different input sets $O_{m_1}$ and $O_{m_2}$, with $|I| > |O_{m_1}|$ and $|I| > |O_{m_2}|$. The two involved primitives transform them into two output sets $O_{m-1_1}$ and $O_{m-1_2}$ with $|O_{m_1}| > |O_{m-1_1}|$ and $|O_{m_2}| > |O_{m-1_2}|$. Now, the input set of the average function will be the set of pairs $\\{(o_1, o_2) | o_1 \\in O_{m-1_1}, o_2 \\in O_{m-1_2}, o_1 = P_{m_1}(o_{m_1}), o_2 = P_{m_2}(o_{m_2})\\}$. Having in account that the output set $O_{m-1}$ of the average function has as many values as its input set, we have that, as both input sets have a cardinality lower than $O_{m_{max}} = max(|O_{m_1}|, |O_{m_2}|)$, then $|I| > O_{m_{max}} > |O_{m-1}|$.\nFinally, at level $m = 0$, the last primitive receives an input set $O_1$ with $|I| > |O_1|$ and produces an output set $O_{DP}$ with $|O_{DP}| < |O_1| < |I|$. Thus, $|I| > |O_P| > |O_{DP}|$.\nThis is a fundamental result that proves that using discriminatory pyramids improves results over using a single primitive.\nAn interesting corollary of previous results is that, if the primitive is the same in each instance of it inside the discriminatory pyramid, then the pyramid is equivalent to a column. For that, first we need to define what is a discriminatory column.\nDefinition 5. Given a primitive $P$, a discriminatory column $DC$ is a hierarchical structure composed of multiple instances of the primitive $P$. A pyramid has $n$ levels, and in each level it has 1 primitive.\nThe primitive of level $n$ receives as input an element $i \\in I$, and the final output of the pyramid is the output of the primitive of the level 0, that is an element $o \\in O$. Thus, $I$ is the input set of the pyramid and $O$ is its output set.\nFinally, each level receives as inputs the lower level outputs.\nNow, we can formulate the following corollary.\nCorollary 1. Given a primitive $P$ and given a discriminatory pyramid $DP$ composed of $n$ levels of instances of the primitive $P$, if all the instances of $P$ produce the same output set $O$ given the same input set $I$, then $DP$ is equivalent to a discriminatory column $DC$ composed of $n$ levels of instances of the primitive $P$.\nProof. Let us start considering level $n$. In this level, all primitives receive the same input. Thus, their input set for all is $I$, and thus their output set is the same set $O_{n-1}$ for all of them. Then, the average function will have as input set the set $\\{(o, o) | o \\in O_{n-1}\\}$, and as $\\frac{o+o}{2} = o \\forall o \\in O_{n-1}$, then the output set of the average function is still $O_{n-1}$. Thus, all the primitives of this level are equivalent to having a unique primitive in this level.\nNow, at levels $0 < m < n$ we have a similar situation. All primitives have the same input set $O_m$ and will produce the same output set $O_{m-1}$. The average function will be equivalent to the identity function again then. Thus, all the primitives of these levels will be equivalent to having a unique primitive at each level again.\nFinally, at level 0, we already have a single primitive, so it is equivalent to having a single primitive in this level. Thus, $DP$ is equivalent to $DC$.\nThis corollary is useful to save resources when the used primitive is not parameterised neither have any associated randomness in its process, and thus it always generates the same archetypes. It will also allow us to implement a discriminatory pyramid easier, as here the proof gives us a viable way to generate the global projection function."}, {"title": "4.3. Associative Layers", "content": "Finally, let us analyse the associative power of the associative layers. First, we need to define what is an associative layer.\nDefinition 6. Given a primitive $P$, an associative layer $AL$ is a structure composed of a concatenation function and an instance of the primitive $P$.\nThe concatenation function receives multiple inputs $i_1,\\ldots,i_n$ from different input sets $I_1,\\ldots, I_n$ and concatenate them into a single input $i \\in I$, and $P$ process $i$ to produce an element $o \\in O$. Thus, $I_1,\\ldots, I_n$ is the input set of the associative layer and $O$ is its output set.\nNow, let us prove that a concatenation function generates a composition of input sets that keeps the association between correlated inputs.\nTheorem 8. Given correlated input sets $I_1,\\cdots, I_n$ and a concatenation function such that it generates an output set $I$ that is a composition of the input sets. If there is no correlation between the inputs $i_1,\\ldots, i_n$, then the output $i_1\\ldots i_n$ is not present in $I$.\nProof. Let us start by assuming that there is a value $i_1\\ldots i_n \\in I$ such that there is no correlation between at least two elements of $\\{i_1,\\ldots,i_n\\}$. For example, without loss of generality, let us assume such two inputs are $i_j \\in I_j$ and $i_k \\in I_k$. Then, as there is no correlation between $i_j$ and $i_k$ but there is correlation between $I_j$ and $I_k$, then the inputs will not appear at the same time as inputs of the system. That implies that the concatenation layer will never receive an input such that $i_j$ and $i_k$ are part of such input. Thus, the concatenation layer will never produce the output $i_1\\ldots i_j\\ldots i_k\\ldots i_n$, and thus such output will never be part of the output set $I$.\nIt is also important to prove that, if there is no correlation between the inputs, then the concatenation function will produce all possible combinations of its inputs.\nTheorem 9. Given independent input sets $I_1,\\ldots,I_n$ and a concatenation function such that it generates an output set $I$ that is a composition of the input sets. Then the output set $I$ is $\\{i_1\\cdots i_n| i_1 \\in I_1,\\ldots, i_n \\in I_n\\}$.\nProof. Let us start by assuming that there is a value $i_1\\ldots i_n \\notin I$ with $\\{i_1 \\in I_1,\\ldots, i_n \\in I_n\\}$. This implies that there is at least two elements of $\\{i_1,..., i_n\\}$ that will never appear together as inputs of the concatenation function. For example, without loss of generality, let us assume such two inputs are $i_j \\in I_j$ and $i_k \\in I_k$. Then, as there is no correlation between $I_j$ and $I_k$, there should be no correlation between $i_j$ and $i_k$. Thus, the inputs will eventually appear at the same time as inputs of the system. That implies that the concatenation layer will eventually receive an input such that $i_j$ and $i_k$ are part of it. Thus, the concatenation layer will eventually produce the output $i_1\\ldots i_j \\cdots i_k \\ldots i_n$, and thus such output is part of the output set $I$.\nThese two results are the cornerstone over which the associative power"}]}