{"title": "AEPL: AUTOMATED AND EDITABLE PROMPT LEARNING FOR BRAIN TUMOR SEGMENTATION", "authors": ["Yongheng Sun", "Mingxia Liu", "Chunfeng Lian"], "abstract": "Brain tumor segmentation is crucial for accurate diagnosis and treatment planning, but the small size and irregular shape of tumors pose significant challenges. Existing methods often fail to effectively incorporate medical domain knowledge such as tumor grade, which correlates with tumor aggressiveness and morphology, providing critical insights for more accurate detection of tumor subregions during segmentation. We propose an Automated and Editable Prompt Learning (AEPL) framework that integrates tumor grade into the segmentation process by combining multi-task learning and prompt learning with automatic and editable prompt generation. Specifically, AEPL employs an encoder to extract image features for both tumor-grade prediction and segmentation mask generation. The predicted tumor grades serve as auto-generated prompts, guiding the decoder to produce precise segmentation masks. This eliminates the need for manual prompts while allowing clinicians to manually edit the auto-generated prompts to fine-tune the segmentation, enhancing both flexibility and precision. The proposed AEPL achieves state-of-the-art performance on the BraTS 2018 dataset, demonstrating its effectiveness and clinical potential. The source code can be accessed online.", "sections": [{"title": "1. INTRODUCTION", "content": "Brain tumor segmentation plays a pivotal role in medical image analysis, serving as a cornerstone for accurate diagnosis and treatment planning. Precise delineation of tumor boundaries is critical for clinicians to assess tumor progression and design appropriate interventions. However, the inherent characteristics of brain tumors, such as their small sizes, irregular shapes, and often indistinct boundaries, pose significant challenges to automated tumor segmentation. Traditional segmentation methods [1] frequently struggle to handle these complexities, leading to suboptimal performance.\nDeep learning methods have recently shown great potential in automated medical image segmentation [2-4]. These approaches often fail to integrate medical domain expertise into the segmentation process. The absence of domain-specific knowledge can lead to less accurate tumor delineation, especially in challenging cases, where critical factors such as tumor grade\u2014indicative of tumor aggressiveness and biological behavior\u2014are essential for precise segmentation. Prompt learning [5] has been used to guide the segmentation process by using specific input cues. However, existing techniques often require manual intervention, limiting their practical application in clinical environments where time and expertise may be constrained. To address these challenges, we propose Automated and Editable Prompt Learning (AEPL), a novel framework that introduces multi-task learning in conjunction with prompt learning. AEPL utilizes predicted tumor grades as automatically generated prompts, leveraging an encoder to extract image features for both segmentation and tumor grade prediction. These generated prompts are fed into a prompt encoder, guiding a U-Net decoder to produce segmentation masks, eliminating the need for manual prompt inputs. Importantly, our approach offers the flexibility of manual editing, allowing clinicians to refine the automatically generated prompts, thereby improving the precision of segmentation outcomes.\nOur contributions are threefold. (1) An automated prompt learning strategy is introduced by seamlessly incorporating tumor-grade prediction into the segmentation process. This helps eliminate the need for manual prompts. (2) A novel editable prompt paradigm is designed, enabling clinicians to interactively modify the generated prompts. (3) Extensive experiments performed on a benchmark dataset suggest the superiority of AEPL over several state-of-the-art (SOTA) methods, demonstrating its effectiveness and clinical utility."}, {"title": "2. METHODOLOGY", "content": "Our proposed AEPL is built upon a 3D U-Net backbone and consists of four key components: (1) a U-Net encoder, (2) tumor grade classifier, (3) a prompt encoder, and (4) a U-Net"}, {"title": "2.1. Feature Extraction and Multi-Task Learning", "content": "The AEPL processes multi-modality MRI inputs to simultaneously predict tumor grades and generate segmentation masks. Four modalities T1-weighted (T1w) MRI, T2w MRI, contrast-enhanced T1w (T1CE) MRI, and Flair MRI, are concatenated and fed into the U-Net encoder to extract high-dimensional representations. The extracted features are fed to the classifier to predict tumor grade and to the decoder to generate segmentation masks in a multi-task learning manner.\nTo integrate the segmentation task with tumor-grade prediction, the extracted features undergo global average pooling and are passed to a classifier, which predicts the tumor grade. The predicted grade and the ground truth are used to calculate a cross-entropy loss $L_{cls}$. The integration of classification and segmentation tasks enables the model to learn shared representations to boost the overall performance. This multi-task learning strategy ensures that the segmentation process benefits from tumor-grade information, enhancing the model's ability to differentiate between tumor types and shapes."}, {"title": "2.2. Prompt Learning for Segmentation", "content": "In AEPL, the tumor grades predicted by the classifier are used as automatically generated prompts to guide the segmentation process. Specifically, the prompt encoder inputs the tumor grade and outputs multi-scale weights $w = \\{\\omega_1,...,\\omega_N\\}$ and bias $\\beta = \\{\\beta_1,..., \\beta_N\\}$, where N is the number of up-sampling in U-Net decoder. In each stage of the decoder, the output features are adjusted by multiplying the weight $w_i$ and adding the bias $B_i$. By incorporating tumor-grade information directly into the tumor segmentation task, AEPL leverages clinically relevant cues, allowing the model to produce more precise segmentation results.\nNotably, the proposed AEPL also supports manual editing of automatically generated prompts, providing clinicians with the flexibility to fine-tune segmentation results by editing the predicted tumor grades. This editable prompt system provides a unique balance of automation and expert input, ensuring that the model's outputs can be adjusted based on clinical needs. This two-tier prompt learning mechanism not only reduces the need for manual input but also enhances the model's flexibility, ensuring that it performs well across varying tumor shapes and sizes. The final loss function of the proposed AEPL consists of the segmentation loss and the classification loss, which is defined as:\n$L = L_{seg} + \\alpha * L_{cls}$,\nwhere $L_{seg}$ incorporates both the binary cross-entropy (BCE) loss and the Dice loss to optimize for both accuracy and overlap with ground-truth tumor masks, $L_{cls}$ represents the cross-entropy (CE) loss for tumor-grade classification (i.e., high-grade glioma vs. low-grade glioma), and $\\alpha$ is a trade-off parameter. In our experiments, we empirically set the weighting factor $\\alpha$ to 0.1 to balance the contributions of the segmentation and classification losses effectively. This hybrid loss ensures that the model learns to perform well on both tasks, enhancing overall performance in brain tumor segmentation."}, {"title": "3. EXPERIMENTS", "content": "The BraTS 2018 dataset, a widely used benchmark for brain tumor segmentation, is employed in this work. This dataset presents challenges due to variability in tumor size, shape, and location, making it ideal for developing robust segmentation models. It contains multi-modality MRI scans from 285 glioma patients. Each patient has four modalities: T1w, T2w, T1CE, and Flair MRI. Expert annotations are provided for three tumor regions: enhancing tumor (ET), tumor core (TC), and whole tumor (WT). The dataset includes high-grade gliomas (HGG) and low-grade gliomas (LGG), with ground truth available for the training set. In the proposed AEPL, the prompt is generated through the task of tumor-grade prediction (i.e., LGG vs. HGG classification).\nFor a fair comparison, our method and the competing methods use the nnU-Net [6] preprocessing pipeline, including cropping, resampling, normalization, and data augmentations. Our classifier and prompt encoder use a three-layer multi-layer perceptron (MLP), while the U-Net backbone consists of five downsampling and upsampling stages, each with two convolutional blocks. Deep supervision is applied with segmentation loss at five scales, weighted 0.0625, 0.125, 0.25, 0.5, and 1. SGD (momentum=0.99, weight decay=3e-5) is used for optimization, with an initial learning rate of 0.01 decayed to 1e-6 by polynomial learning rate decay schedule, batch size of 2, and patch size of (96, 160, 160). The dataset is split into training, validation, and test sets with a ratio of 6:2:2. The model is trained for 1,000 epochs, and the best-performing model on the validation set is selected for testing. We evaluate performance using volume Dice and 95th percentile Hausdorff distance (HD95). When one of the ground truth and prediction has no foreground, the conventional HD95 calculation fails. We set the HD95 value in this case to the diagonal length of 373 pixels."}, {"title": "3.2. Results and Analysis", "content": "We evaluate the performance of our AEPL against several SOTA 2D and 3D segmentation methods. The 2D methods include U-Net [2], TransFuse [7], and TransUNet [8], while the 3D methods comprise CoTr [4], nnFormer [9], UNETR [3]. To simulate clinical interaction, we replace the automatically generated prompts (through the classification task) with ground-truth tumor-grade labels, and denote this variant as AEPL-E. Table 1 presents a comparative analysis of segmentation performance across three tumor regions:"}, {"title": "3.3. Parameter Analysis", "content": "We further study the influence of $\\alpha$ in Eq. (1) by varying its values within the range of {0, 0.01, 0.1, 1, 10} and report the results of AEPL in Table 2. The results demonstrate that our method with $\\alpha$ = 0.1 yields the overall best performance, implying that segmentation loss contributes more to the fi-"}, {"title": "4. CONCLUSION", "content": "This paper presents a brain tumor segmentation framework, called AEPL, with multi-task learning and prompt learning. AEPL utilizes predicted tumor grades as automatically generated prompts, guiding the segmentation process without the need for manual intervention. It also offers the flexibility to edit prompts for enhanced segmentation performance. Extensive evaluations on a public dataset suggests the superiority of AEPL over state-of-the-art methods. Our method not only provides a robust, adaptable tool for accurate brain tumor segmentation with enhanced clinical applicability."}, {"title": "5. COMPLIANCE WITH ETHICAL STANDARDS", "content": "This research study was conducted retrospectively using human subject data made available in open access by the BraTS 2018 Challenge. Ethical approval was not required as confirmed by the license attached with the open access data."}]}