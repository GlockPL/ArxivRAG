{"title": "Exploring 3D Face Reconstruction and Fusion Methods for Face Verification: A Case-Study in Video Surveillance", "authors": ["Simone Maurizio La Cava", "Sara Concas", "Ruben Tolosana", "Roberto Casula", "Giulia Orr\u00f9", "Martin Drahansky", "Julian Fierrez", "Gian Luca Marcialis"], "abstract": "3D face reconstruction (3DFR) algorithms are based on specific assumptions tailored to distinct application scenarios. These assumptions limit their use when acquisition conditions, such as the subject's distance from the camera or the camera's characteristics, are different than expected, as typically happens in video surveillance. Additionally, 3DFR algorithms follow various strategies to address the reconstruction of a 3D shape from 2D data, such as statistical model fitting, photometric stereo, or deep learning. In the present study, we explore the application of three 3DFR algorithms representative of the SOTA, employing each one as the template set generator for a face verification system. The scores provided by each system are combined by score-level fusion. We show that the complementarity induced by different 3DFR algorithms improves performance when tests are conducted at never-seen-before distances from the camera and camera characteristics (cross-distance and cross-camera settings), thus encouraging further investigations on multiple 3DFR-based approaches.", "sections": [{"title": "1 Introduction", "content": "In the last few years, much attention has been paid to the generation of face synthetic images [10, 29, 37], in particular, 3D data [35,40]. The acquisition of 3D data has been proven to be robust to adverse factors of uncontrolled environments, such as unfavorable illumination conditions and non-frontal poses of the face [1, 8, 39]. Moreover, high accuracy and efficiency can be achieved when comparing faces due to the complementary information of shape and texture [2, 19]. However, in comparison to standard 2D images, the acquisition of such 3D data requires a much more complex enrolment process and expensive"}, {"title": "2 Related Works", "content": null}, {"title": "2.1 Exploiting 3DFR for Face Recognition", "content": "3DFR has been mainly proposed to increase the robustness of face recognition to faces acquired with various view angles, as this is the typical acquisition observed in unconstrained scenarios, with non-frontal and looking-down probe faces due to the non-cooperation of the subjects [20, 25]. However, the performance improvement between 2D and 3DFR strongly depends on the approaches chosen for its application to the face recognition task. These are usually divided into two main categories, namely, model- and view-based approaches [25].\nThe first one synthesizes frontal faces from the 2D images containing non-frontal views. The normalized (or \"frontalized\") faces are then compared to the frontal ones to determine the subjects' identity [17]. This category is prone to produce textural artifacts in the synthesized frontal images [4, 18,45]; thus, it is usually considered in the so-called face identification task rather than for highly accurate authentication [17].\nThe second one adapts the 2D images containing frontal faces to non-frontal ones; in other words, lateral views derive from the 3D template (or model) [17]. Additionally, the 3D facial model can be projected to various poses in the 2D domain to enhance the representation capability of each subject, considering them as synthesized templates [27,44]. In general, view-based approaches are more expensive than model-based ones in terms of computational and storage costs. Thus, they are usually used in the verification task when high reliability is required [17]."}, {"title": "2.2 3DFR in Video Surveillance Scenarios", "content": "Video surveillance scenarios are characterized by faces captured at an extensive range of lighting, pose, and scale due to environmental conditions and the subject's cooperation level. In other words, we must rely on uncalibrated images.\nThe 3D reconstruction from uncalibrated images is an inherently ill-posed problem: the facial geometry, the pose of the head, and its texture must be recovered from a single picture, leading to an undetermined problem, while different"}, {"title": "2.3 Ensemble and Fusion Methods for Face Recognition", "content": "Ensemble methods and multi-modal or uni-modal fusion approaches are constantly being exploited in many fields of pattern recognition to improve the ability to generalize and deal with intra-class variations and inter-class similarity [42]. In biometrics, fusion can be performed at various levels, including sensor, feature, score, and decision levels [31-33,36].\nAmong others, score-level fusion allows the exploitation of several sources of information without increasing the system's complexity (as in the case of sensor-level and feature-level fusion) and without relying only on the binary outcome, as in the case of decision-level fusion. A comprehensive set of previous studies supports this since the earlier attempts at face recognition [9,28,34,36]."}, {"title": "3 Proposed Method", "content": "Figure 2 provides a graphical representation of the proposed method to improve the performance of face verification in video surveillance scenarios, i.e., determine whether the identity in a surveillance image (i.e., probe) matches that represented in the reference data (i.e., mugshot or template). In the following, we summarize the main modules.\n3DFR methods: We have chosen three types of state-of-the-art 3DFR algorithms, each representative of one or a combination of the previously described approaches for reconstructing the 3D templates from high-quality reference data (i.e., frontal mugshot images):\nEOS [22]: based on 3DMM and proposed for reconstructing 3D faces from videos and images in time-critical applications (Figure 3, b)4.\n3DDFA v2 [15]: based on a lightweight network for regressing the 3DMM parameters and proposed for 3D dense face alignment (Figure 3, c)5.\nNextFace [11]: based on the combination of a statistical 3DMM and a photometric approach for making 3D reconstruction robust to light conditions (Figure 3, d)6.\n3DFR-based enhancement strategy: We focus on view-based approaches for enhancing face verification through 3DFR. In particular, we train multiple\nface recognition systems by considering a gallery enlargement strategy through a single 3DFR method for each neural network to make the system robust to pose variations (Algorithm 1). Specifically, we use it on each 3D template generated from training mugshots to project the face in multiple view angles (Figure 4). Then, we train each neural network with all view representations to aid the task of learning how to extract useful information for face verification from non-frontal poses. Concerning the evaluation of each face recognition system at the inference stage, we only compare the frontal face of each subject with the corresponding set of probe images. The computational cost introduced by the gallery enlargement strategy is mainly offline, thus representing a minor issue in many of the application scenarios to which this contribution is intended [24].\nFace recognition methods: We consider two state-of-the-art deep learning networks, XceptionNet [6] and VGG19 [38], with different computational complexities to simulate various application scenarios. In particular, we selected a Siamese architecture [41], which has demonstrated accurate results in face recognition using low-resolution images [26].\nIn order to determine the a posteriori probability $P(match|X, Y)$ between the representation obtained from the reconstructed 3D reference model X and the probe image Y match, we calculate the similarity between such a pair of images using the Euclidean distance value d between their feature embeddings (i.e., the output of the Siamese Network) as follows:"}, {"title": null, "content": "$P(match|X, Y) = \\frac{1}{\\frac{d}{4}+1}$                                                 (1)"}, {"title": null, "content": "In particular, we estimate the a posteriori probability through the previous formula to limit the range to [0, 1].\nFusion methods: To the best of our knowledge, the score-level fusion between face recognition systems enhanced through various 3DFR algorithms is still missing in the literature. Accordingly, we explore different non-parametric fusion methods [36] by applying a set of rules to the a posteriori probability values, namely the scores predicted by the single Siamese Neural Networks. Hence, the final a posteriori probability obtained from the comparison between a reference and a probe represents a combination of such scores.\nHere, we introduce a common notation to ease the understanding of such fusion rules. Let us consider the fusion of N classifier scores, where $P_i (match|X, Y)$ represents the score of the i-th classifier when comparing X and Y. According to this notation, it is possible to compute the fusion scores through the following formulas that represent, in order, the simple average between the scores obtained from the single recognition systems, their maximum, and their minimum:"}, {"title": null, "content": "$avg\\_score = \\frac{1}{N}\\sum_{i=1}^{N}{P_i (match|X, Y)}$ (2)\n$max\\_score = max_i (P_i (match|X, Y))$                                               (3)\n$min\\_score = mini (P_i (match|X, Y))$                                               (4)"}, {"title": "4 Experimental Framework", "content": "The description of the experimental framework is divided into three parts. Section 4.1 describes the database used in our experimental framework. Section 4.2 explains the experimental protocol considered for the configurations regarding the face recognition systems. It is important to highlight that, as indicated in Section 3, no additional data was used to re-train the 3DFR modules' parameters, nor the one described in Section 4.1. We consider the original versions of the 3DFR algorithms available in the corresponding GitHub repositories. Finally, Section 4.3 discusses the analyzed performance metrics."}, {"title": "4.1 Database", "content": "State-of-the-art face recognition systems, even the ones in the 2D domain, achieve nearly perfect performance on traditional benchmark databases [12, 29]. However, the most significant advantage of 3DFR algorithms in recognition tasks is in more challenging scenarios, such as surveillance [25].\nHence, we use the SCface database [14], containing both high-quality mugshot-like images and lower-quality RGB and grayscale surveillance images of 130 subjects. The surveillance images were acquired through five different camera models at three varying distances from the subject, ranging from 1 to 4.2 meters. Each subject was captured once for every possible camera-distance combination. The observed head poses are typically found in surveillance footage, with the camera slightly above the subject's head [5]. Therefore, SCface is considered to analyze the effect of different quality and resolution cameras on face recognition performance and the robustness to different distances [24], thus making this database suitable for evaluating interoperability across settings using data from specific cameras or at certain distances. We refer to these evaluations as \"cross-settings\" experiments, while experiments involving training and testing data from the same camera and distance are referred to as \"intra-settings\".\nConcretely, for both experimental protocols, we use RGB samples related to 25 identities (i.e., about 20% of the subjects) as the test set, while the samples associated with the remaining 105 subjects are further divided, using 90% as training samples and 10% as validation ones. In any experiment concerning the single camera-distance settings for training and test sets, we perform such divisions randomly to limit the possible bias on performance and introduce a face detection stage following the setting used in the same database in [43]."}, {"title": "4.2 Face Recognition Systems: Setup", "content": "All Siamese networks are pre-trained on the LFW database [21]. Then, a fine-tuning through the training set of the SCFace is done, using a validation set for early stopping, according to partitions described in Section 4.1. As shown in Figure 5, the inputs to the networks are the probe image and the representations obtained from a 3D template of the face related to the claimed identity. For comparability reasons, all the models have been trained on the images resampled at a resolution of 128 \u00d7 128, on up to 256 epochs with the patience of 5 epochs, batches of 128 triplets, and the Adam optimizer with a learning rate equal to 0.001. Note that this configuration does not necessarily represent the best parameters and preprocessing stages; rather, it is a general configuration that might be further improved in future work."}, {"title": "4.3 Performance Evaluation", "content": "After training the individual face recognition systems using information from the different 3DFR algorithms, we investigate the potential of combining them through a correlation analysis between the sets of scores obtained using the test"}, {"title": "5 Results", "content": "This section reports the results obtained through the previously described experimental setup. Section 5.1 provides an analysis of the correlation between the single classification models enhanced through different 3DFR methods. Section 5.2 describes the outcome of the intra-setting analysis. Finally, Section 5.3 shows the performance obtained through the cross-setting analysis."}, {"title": "5.1 Correlation Analysis", "content": "Figure 6 shows that recognition systems based on the VGG19 backbone are mainly poorly correlated, with the highest correlation obtained from the systems enhanced through 3DDFA v2 and EOS (0.27). Despite the higher values observed, a similar trend is visible in systems based on XceptionNet. This was expected due to the highest quality of the 3D templates generated by 3DDFA v2 and EOS algorithms, as can be seen in Figure 3. Hence, the general weak correlation highlighted by this analysis enforces the hypothesis of potential complementary information provided by different 3DFR algorithms. However, despite providing clues on the linear correlation between the scores of pairs of systems, the PCC needs to be paired with an analysis of the effectiveness of the individual models to observe if a low correlation could be related to a relevant difference in the overall performance or mostly to differences in single types of errors, which could therefore be exploited through a combination between them."}, {"title": "5.2 Intra-Setting Analysis", "content": "Table 1 reports the average performance values in the intra-setting scenario (i.e., fixed camera-distance settings) for the individual 3DFR algorithms (3DDFA v2, EOS, and NextFace) and their fusion (Avg, Min, and Max). The best values for"}, {"title": "5.3 Cross-Setting Analysis", "content": "Table 2 shows the results achieved when considering different acquisition distances (cross-distance setting) and surveillance cameras (cross-camera setting) between training and test sets. As expected, both single 3DFR-enhanced and fused systems suffer from a significant decay in performance compared to the intra-setting scenario, remarking how challenging the task is. For example, for the VGG19 backbone and Avg score-level fusion, the AUC decreases from 86.94% in the intra-setting scenario to 74.55% in the cross-setting scenario. Still, the Avg fusion rule is confirmed to be able to improve the overall performance, out-performing the single systems and the Baseline one from both a global and a local perspective. A notable finding is that, unlike the intra-setting scenario, the"}, {"title": "6 Conclusions", "content": "In this paper, we investigate the complementary information provided by three state-of-the-art 3D face reconstruction (3DFR) algorithms and the effectiveness of score-level fusion in leveraging this information to improve face recognition in"}, {"title": null, "content": "a video surveillance scenario. We first assess this complementarity by analyzing the linear correlation between the scores produced by different face verification systems, each utilizing the same Siamese Neural Network, using one between the two examined backbones, but enhanced by a different 3DFR algorithm. Then, we also employ three non-parametric fusion methods to combine the individual systems based on the same backbone.\nTherefore, we evaluate the robustness of the proposed approach using a common experimental setup when dealing with data acquired in intra- and cross-setting, involving variations in acquisition distance and surveillance camera. This allows us to explore different application contexts: the intra-setting experiments simulate a context in which the designer knows the data characteristics and has access to representative data for training the recognition system; the cross-setting experiments simulate a more unfavorable application context in which data characteristics are unknown or representative data cannot be obtained.\nThe results obtained from our experiments confirm the initial hypothesis that deep-learning face recognition systems can extract distinct information from different state-of-the-art 3DFR algorithms, and the score-level fusion methods effectively leverage this information to enhance inference robustness. This improvement can be observed even on probe images obtained from surveillance cameras and at distances different from the ones related to training data. Therefore, this approach could represent a valid tool for improving facial recognition in challenging surveillance scenarios like the one considered in this work.\nFuture studies should explore other fusion approaches, such as parametric rules and those based on machine-learning models, which may better exploit the observed complementarity. Similarly, more 3DFR algorithms, enhancement approaches, and deep neural networks could be included in the study, and the impact of the proposed approach on different pre-processing settings should be investigated. Finally, the effects of the differences in terms of acquisition distance and surveillance camera between training and test data should be further investigated.\nThis preliminary study provides valuable insights into the effectiveness of fusion methods in exploiting the complementarity among 3D face reconstruction algorithms within video surveillance contexts. We believe this initial exploration holds promise and could pave the way for developing robust multi-modal face recognition systems capable of recognizing never-seen-before subjects, thereby aiding forensic practitioners and security personnel in identifying criminals and finding missing persons."}, {"title": "Acknowledgment", "content": "Funding from C\u00e1tedra ENIA UAM-VERIDAS en IA Responsable (NextGenerationEU PRTR TSI-100927-2023-2) and project BBforTAI (PID2021-127641OB-100 MICINN/FEDER). The work has been conducted within the sAIfer Lab and the ELLIS Unit Madrid."}]}