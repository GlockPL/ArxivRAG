{"title": "Constrained Identifiability of Causal Effects", "authors": ["Yizuo Chen", "Adnan Darwiche"], "abstract": "We study the identification of causal effects in the presence\nof different types of constraints (e.g., logical constraints) in\naddition to the causal graph. These constraints impose restric-\ntions on the models (parameterizations) induced by the causal\ngraph, reducing the set of models considered by the identifia-\nbility problem. We formalize the notion of constrained iden-\ntifiability, which takes a set of constraints as another input to\nthe classical definition of identifiability. We then introduce a\nframework for testing constrained identifiability by employ-\ning tractable Arithmetic Circuits (ACs), which enables us to\naccommodate constraints systematically. We show that this\nAC-based approach is at least as complete as existing algo-\nrithms (e.g., do-calculus) for testing classical identifiability,\nwhich only assumes the constraint of strict positivity. We use\nexamples to demonstrate the effectiveness of this AC-based\napproach by showing that unidentifiable causal effects may\nbecome identifiable under different types of constraints.", "sections": [{"title": "Introduction", "content": "A causal effect measures the impact of an intervention on an\noutcome of interest. For example, one may ask the question\n\"how likely would an employee resign if the company re-\nduced the bonus?\" More generally, given a set of treatment\nvariables X and another set of outcome variables Y, the\ncausal effect is defined as the probability of y under a treat-\nment do(x) and is commonly denoted by Pr(y|do(x)) or\nPrx(y). These queries belong to the second rung of Pearl's\ncausal hierarchy and cannot be answered in general without\nconducting experiments (Pearl and Mackenzie 2018). When\na causal graph is available, however, some of these causal\neffects may be answered from observational studies. This\nleads to the problem of causal-effect identifiability that stud-\nies whether a causal effect can be uniquely determined from\nobservational distributions when a causal graph is given; see,\ne.g., (Pearl 2009; Imbens and Rubin 2015; Peters, Janzing,\nand Sch\u00f6lkopf 2017; Spirtes, Glymour, and Scheines 2000).\nA recent line of research went beyond classical identifia-\nbility to show that more causal effects may become identi-\nfiable when additional information besides a causal graph\nis available. Works that fall into this line include the ex-\nploitation of the knowledge of context-specific indepen-\ndence (Boutilier et al. 1996; Tikka, Hyttinen, and Karvanen\n2019) and more recently, functional dependencies (Chen and"}, {"title": "Technical Preliminaries", "content": "We consider discrete variables in this work. Single variables\nare denoted by uppercase letters (e.g., X) and their states are\ndenoted by lowercase letters (e.g., x). Sets of variables are\ndenoted by bold uppercase letters (e.g., X) and their instan-\ntiations are denoted by bold lowercase letters (e.g., x).\nThe problem of causal-effect identifiability studies\nwhether a causal effect can be uniquely computed from a\ngiven causal graph G and a subset of observed variables V.\nThat is, to show that a causal effect Prx(y) is identifiable,\nwe need to prove that all parameterizations for G that induce\nthe same observational distribution Pr(V) also yield the\nsame value for Prx(y). While the general definition of iden-\ntifiability (not necessarily for causal effects) in (Pearl 2009)\ndoes not restrict the observational distribution Pr(V), posi-\ntivity assumptions (constraints) are often assumed to prevent\nzeros in Pr(V); see (Chen and Darwiche 2024; Kivva et al.\n2022; Hwang et al. 2024) for recent discussions on positiv-\nity. The most common form of positivity constraints in the\nexisting literature is strict positivity, i.e., Pr(V) > 0, which\nis a sufficient condition for complete causal-effect identifi-\ncation algorithms including the ID algorithm (Shpitser and\nPearl 2006) and the do-calculus (Pearl 2009). We will refer\nto identifiability with strict positivity as \u201cclassical identifia-\nbility,\" which is defined next.\nDefinition 1 (Causal-Effect Identifiability). Let G be a ca-\nsual graph and V be its observed variables. A causal effect"}, {"title": "Constrained Identifiability", "content": "We next generalize this setup by considering more informa-\ntion, in addition to the causal graph and observed variables,\nas inputs to the identifiability problem. Past works that fit in\nthis direction include the exploitation of context-specific in-\ndependences in (Tikka, Hyttinen, and Karvanen 2019) and\nfunctional dependencies in (Chen and Darwiche 2024) to\nimprove the identifiability of causal effects. The general\nsetup we formulate in this work will allow us to also con-\nsider further information types such as fully-known observa-\ntional distributions Pr(V), which can be readily available\nin practice when data on V allows us to estimate Pr(V).\nOur setup is based on the notion of constrained identi-\nfiability, which was recently introduced in (Chen and Dar-\nwiche 2024) to systematically treat a variety of positivity\nconstraints (assumptions). We will extend this notion next\nto incorporate arbitrary types of constraints.\nWe first define the (constrained) identifiability tuple.\nHere, we use \"model\" to mean a full parametrization of the\ncausal graph (a model induces a distribution).\nDefinition 2. We call (G,V, M) an identifiability tuple\nwhen G is a causal graph (DAG), V is its set of observed\nvariables, and M is a set of models induced by G.\nThe notion of constrained-identifiability can now be de-\nfined as follows. For simplicity, we will say \"identifiability\"\nto mean \u201cconstrained-identifiability\u201d in the rest of paper.\nDefinition 3. Let (G,V,M) be an identifiability tuple. A\ncausal effect Prx(y) is said to be identifiable wrt (G, V, M)\nif Pr1x(y) = Pr2x(y) for any pair of models M\u00b9, M\u00b2 \u2208 M\nthat induce Pr\u00b9, Pr\u00b2 where Pr\u00b9(V) = Pr\u00b2(V).\nPositivity constraints, context-specific independencies\n(CSI), and functional independencies restrict the set of mod-\nels M in the definition of constrained-identifiability. That is,\nwe only consider models that induce a distribution Pr that\nsatisfies all the constraints above when testing for identifia-\nbility. To illustrate, consider the causal graph in Figure 3b\nwhere all variables are binary and X, Y are observed. If\nwe impose the positivity constraint Pr(X, Y) > 0, CSI\nconstraint (Y || U|x), and functional variable Y, then a\nmodel will be excluded from M if it assigns Y \u2190 X or\nY \u2190 X \u2295 U as a structural equation for Y.\nIf C is a set of constraints, we will use M(C) to denote the\nset of models that satisfy C. In the example above, we write\nthe set of models as M[Pr(X, Y) > 0, (Y || U|x), (W ="}, {"title": "Testing Constrained-Identifiability Using\nArithmetic Circuits", "content": "We next introduce a general method for testing constrained-\nidentifiability based on Arithmetic Circuits (ACs) as defined"}, {"title": "AC Construction", "content": "We start by constructing an AC for the causal effect Prx(y)\nbased on the approach in (Darwiche 2021a). First, compile\nthe original BN into an AC (in a standard way) that contains\nindicators Av for each variable state v and parameters \u03b8v|p\nfor each instantiation over V and its parents P. Second,\nreplace every parameter \u03b8x|p with 1 for each treatment X \u2208\nX. Finally, for each V\u2208 XUY, assign \u03bb = 1 if v is\ncompatible with x, y and X = 0 otherwise; assign 1 to all\nother indicators.\nTo evaluate an AC under a model M, we simply plugin\neach (non-constant) parameter \u03b8v|p with the value from M\nand compute the output of the AC in a standard way. One\nkey observation is that the ACs constructed from the above\nprocedure are guaranteed to compute Prx(y) correctly un-\nder all parameterizations of G. As we will see later, when\nadditional constraints are available, the ACs may be further"}, {"title": "Invariance Testing", "content": "The AC constructed from the previous step is guaranteed to\ncompute the causal effect under all models in M. We next\ndevelop a method for testing identifiability based on the fol-\nlowing observation: a causal effect Prx(y) is identifiable wrt\n(G, V, M) if the output of the ACs for Prx(y) is invariant\nunder all models (in M) that induce a same Pr(V).\nIn this work, an expression is defined as a composi-\ntion of constants (e.g., 0.8), parameters (\u03b8v|p), and condi-\ntional probabilities (e.g., Pr(a|b)). Note that each parameter\n\u03b8v|p is equal to the conditional probability Pr(v|p) when\nPr(p) > 0. For example, Pr(y|x), 0.65, 0.2 Pr(a|x) +\n0.6 Pr(\u0101|x), \u03a3u Pr(a|x) Pr(u), \u03b8(a|x) Pr(x)+0.3 Pr(\u0101) are\nall valid expressions. An AC specifies an expression con-\nsisting of x's and +'s, which can be obtained by evaluat-\ning the output of the AC in a standard (bottom-up) way.\nFor example, the AC in Figure 4b specifies the expres-\nsion \u03a3a \u03a3\u03b9 \u03b8y|a,b,x \u03a3\u03c5\u03c2 \u03b8u2\u03b8b|u2 \u03a3\u03ba\u03b9 \u03b8u1\u03b8\u03b1|u1, u2. More-\nover, every node in an AC corresponds to an expression so\nwe will use \u201cAC node\u201d and \u201cexpression\u201d interchangeably.\nOur next goal is to propose a method for testing identifi-\nability that operates on ACs. We start by defining some key\nnotions that are required to achieve this goal."}, {"title": "Finding Invariant-Cuts For ACs", "content": "Developing a complete method for finding invariant-cuts, if\nthey exist, is beyond the scope of this paper as it represents a\nfirst step in the proposed direction. However, we will provide\na complete method in this section assuming we only have the\nclassical positivity constraint, Pr(V) > 0. This case has al-\nready been solved in the literature using methods such as the\nID algorithm and the do-calculus, so the results in this sec-\ntion provide another way of solving this case. These results\nalso show that the proposed framework in this paper is at\nleast as powerful as these classical methods. Moreover, we\nwill use these results in the next section where we show how\nto handle other types of constraints but in a less complete\nfashion as far as identifying invariant-cuts.\nOur method for finding projections for ACs is based on\nthe notion of c-components, which has been studied exten-\nsively in (Tian and Pearl 2002, 2003; Shpitser and Pearl\n2006; Huang and Valtorta 2006). Given a causal graph G,\na (maximal) c-component is a (maximal) subgraph of G\nin which all variables are connected by bidirected paths, and each c-component S is associated with a c-factor de-\nfined as Q[S](V) = \u03a3\u03c5 \u03a0\u03c5\u2208V \u03b8v \u03a0v\u2208V \u03b8v|Pv where\nU, V, Pv denote the hidden variables, observed variables,\nand parents of V. Moreover, the causal graph G can be de-\ncomposed into c-components S = {S1,..., Sk} such that\nPr(V) = \u03a0s\u2208S Q[S] when Pr(V) > 0. Existing methods\nin (Tian and Pearl 2003; Shpitser and Pearl 2006; Huang and\nValtorta 2006) identify causal effects by decomposing the\nmutilated graph G' (under do(x)) into c-components S and\nthen checking whether each Q[S] (for S \u2208 S) has a projec-\ntion which only involves V. We next present a notion that\nsummarizes such c-components, which follows from the key\nresults in (Tian and Pearl 2003; Huang and Valtorta 2006;\nShpitser and Pearl 2006) and is defined in an inductive way.\nDefinition 6. Let G be a causal graph with observed vari-\nables V. A subgraph S of G is V-computable if one of the\nfollowing holds: (1) S = G; (2) S is a maximal c-component\nof a V-computable subgraph; or (3) S is the result of prun-\ning a leaf node from a V-computable subgraph.\nWe can always find a projection for each Q[S] as stated\nby the following corollary.\nCorollary 1. Let G be a causal graph with observed vari-\nables V. If S is a V-computable subgraph of G, then Q[S]\nhas a (G, V, M[Pr(V) > 0])-projection."}, {"title": "Exploiting Constraints In Causal-Effect\nIdentifiability: Examples", "content": "We next use examples to demonstrate how our AC-based\nmethod can be applied to improve causal-effect identifia-\nbility under different types of constraints, some of which"}, {"title": "Context-Specific Independence", "content": "We first illustrate that the AC-based method can improve\nidentifiability given knowledge of context-specific indepen-\ndence (CSIs) (Boutilier et al. 1996; Tikka, Hyttinen, and\nKarvanen 2019; Shen, Choi, and Darwiche 2020). CSI has\nthe form (Y || X|p) where X, P are the parents of Y. That\nis, Y is independent of X when the values of other parents\nP are set to p. For simplicity, we write (Y || X|P) if CSI\nholds under all instantiations of P.\nCSI constraints can be incorporated into the construction\nof ACs as follows. For each CSI relation (Y || X|p), we\nmerge all the parameters \u03b8y|x,p (which are leaves) in the AC\ninto a single node \u03b8y|p. This is valid since \u03b8y|x,p = Pr(y|p)\nfor all x and y (Darwiche 2002). We can then apply sim-\nplification rules, such as those provided in Appendix A, to\nfacilitate the discovery of invariant-cuts.\nConsider again the causal graph in Figure 3a where the\ncausal effect Prx(y) is not identifiable under the positivity\nconstraint Pr(V) > 0. Assume now the following CSI con-\nstraints Ccsi: (Y || C|a, B) and (Y || B|\u0101, C). We can\nconstruct the simplified AC in Figure 7 using the procedure\nabove. We can then find an invariant-cut for the AC using\nthe c-component method; see Appendix C.1 for the deriva-\ntion. Hence, we conclude that the causal effect is identifi-\nable wrt (G, V, M[Ccsi, Pr(V) > 0]). We show another\nexample from (Tikka, Hyttinen, and Karvanen 2019) in Ap-"}, {"title": "Functional Dependencies", "content": "In a causal graph, a variable W with parents P is said to\nbe functional, or exhibit a functional dependency, if \u03b8w|p \u2208\n{0, 1} for all instantiations w, p \u2013 we assume that we do not\nknow the specific values for these \u03b8w|p. Functional depen-\ndencies have been recently exploited to improve the identi-\nfiability of causal effects (Chen and Darwiche 2024) and the\ncomputation of causal queries (Darwiche 2020; Chen and\nDarwiche 2022; Han, Chen, and Darwiche 2023).\nLet W be a subset of variables that exhibit functional\ndependencies. (Chen and Darwiche 2024) showed that an\nunidentifiable causal effect may become identifiable given\nthe functional variables W, without the need of knowing\nthe specific functions (\u03b8w|p's) for W. In addition, the work\nintroduced a reduction-based method for testing identifia-\nbility under functional dependencies by eliminating (remov-\ning) a subset of functional variables Q \u2286 W from the\ncausal graph. That is, a causal effect Prx(y) is identifi-\nable wrt (G, V, M) iff it is identifiable wrt (G', V', M'),\nwhere V' = V \\ Q, G' is the result of eliminating Q from\nG, and M' is obtained from M by changing functional vari-\nables W to (W \\ Q). Hence, we can use the elimination of\nfunctional variables as a preprocessing mechanism to reduce\nthe identifiability problem with functional dependencies into\nclassical identifiability (without functional dependencies).\nWhen the states of variables are known, the if-direction of\nthe result still holds. If we can show that Prx(y) is identifi-\nable wrt (G', V', M') using the AC-based method, the same\ncausal effect is guaranteed to be identifiable wrt the original\n(G, V, M) with functional dependencies. We next illustrate\nthis with an example. Consider the causal graph G in Fig-\nure 8a with observed variables V = {A, C, D, X, Y} and\nthe causal effect Prx(y) wrt (G, V, M[Pr(A, C, X, Y) >\n0, (C\u315b U1|x,U2),W = {B, D}]). We first apply the\npreprocessing mechanism to eliminate the functional vari-\nables, which yields the causal graph G' in Figure 8b. Since"}, {"title": "Fully-Known Pr(V)", "content": "When an observational distribution Pr*(V) is given in addi-\ntion to the causal graph G, we have an identifiability prob-\nlem (wrt (G, V,M[Pr(V) = Pr*(V)])) as defined previ-\nously. This is quite common in practice when data over ob-\nserved variables V allows us to estimate Pr*(V) accurately.\nKnowing Pr*(V) leads to several advantages. First, the\npositivity constraint over Pr*(V) becomes immediate since\nall the zero entries are determined by Pr*(V). Second, all\nthe (well-defined) parameters \u03b8v|p over observed variables\nV, P can be fixed to constant values in the AC. This allows\nus to exploit more parameter-specific knowledge such as 0/1\nparameters and equal parameters (subsumes CSI) as exhib-\nited by Pr*(V). One key observation is that a causal effect\nPrx(y) is identifiable under a known Pr*(V) iff Prx(y)\nalways evaluates to a fixed constant under all models that\ninduce Pr*(V). This result follows directly from Proposi-\ntion 3. In fact, the constant can always be evaluated by com-\nputing Prx(y) under any single model that induces Pr*(V).\nConsider the causal graph in Figure 9a where variable\nB has states b1, b2, 63, 64 and all other variables are binary.\nSuppose Pr*(V) > 0 satisfies the conditional probabilities\nin Figure 9b. We show that the causal effect Prx(y) is iden-\ntifiable under the fixed Pr*(V) > 0 (this causal effect is not\nidentifiable if Pr(V) is not fixed to Pr*(V)). Figure 10 de-\npicts the AC for the causal effect after plugging in the known\nconstant values for parameters. If we further apply simplifi-\ncation rules on the AC, we obtain an AC which contains a"}, {"title": "Conclusion", "content": "We formalized the notion of constrained identifiability\nwhich targets causal-effect identifiability in the presence of\nvarious types of constraints. We also proposed an approach\nfor testing constrained identifiability based on constructing\nan Arithmetic Circuit (AC) for computing the causal ef-\nfect using the causal graph and available constraints, and\nthen finding invariant-cuts. We showed that this method is\nat least as complete as classical methods such as the ID al-\ngorithm and the do-calculus (which handle strict positivity\nconstraints). We further demonstrated with examples how\nthis approach can be used for testing causal-effect identifia-\nbility under various types of constraints, including context-\nspecific independencies, functional dependencies, and fully-\nknown observational distributions, therefore improving the\ncompleteness of classical methods when going beyond strict\npositivity constraints."}, {"title": "Simplifying Arithmetic Circuits", "content": "The constructed AC can be simplified (reduced) by exploit-\ning parameter-specific information such as 0/1 entries and\nequal parameters. While most of the simplifications can be\nhandled by the ACE package, we introduce three more\nrules that may lead to additional simplifications:\n1. (sum-out) For a +-node in the AC, if it computes\n\u03a3\u2082 Pr(zw), replace the +-node with constant 1.\n2. (merge) If two nodes in the AC are same and have a same\nset of children, merge them into a single node.\n3. (distributivity) For a +-node in the AC, if it computes\n\u03a3\u2081(c.si), simplify it to c. Ei si\nThese rules can be applied recursively to simplify the AC\nto the maximum extent. Note that we can always omit AC\nnodes that evaluate to zero and nodes that evaluate to one\nif their parent is a \u00d7-node. Please check out examples and\ntheir derivations in Appendix C for more details."}, {"title": "C-component Method For Finding\nProjections", "content": "The c-component method finds projections by decomposing\na causal graph into (maximal) c-components (Tian and Pearl\n2002, 2003; Shpitser and Pearl 2006). As shown in the\nmain paper, a causal graph induces a set of V-computable\nsubgraphs. Moreover, each V-computable subgraph S in-\nduces a c-factor (Tian and Pearl 2002, 2003; Huang and\nValtorta 2006) which we denote as Q[S]. For example, the\nV-computable subgraphs in Figure 5b correspond to the fol-\nlowing formulas:\n\u2022 Q[S1] = \u2211U1,U3 \u03b8U1\u03b8U3\u03b8V1|U1,U3\u03b8V3|U1,V2\u03b8V5|U3, V4\n\u2022 Q[S2] = \u2211U1,U3 \u03b8U1\u03b8U3\u03b8V1|U1,U3\u03b8V3|U1,V2\n\u2022 Q[S3] = \u2211U1 \u03b8U1\u03b8V3|U1,V2\n\u2022 Q[S4] = \u2211U2 \u03b8U2\u03b8V2|U2, V1\u03b8V4|U2, V3\n\u2022 Q[S5] = \u2211U2 \u03b8U2\u03b8V4|U2, V3\nTo see why the c-factors for V-computable subgraphs can\nbe computed from Pr(V), consider the following inductive\nargument. For the original causal graph G, Q[G] = Pr(V)\nwhich is a projection. Whenever we prune a leaf node W\nfrom a V-computable graph G to obtain a new graph G'\n(case (3) in Definition 6), the c-factor for G' is equal to\nQ[G'] = \u2211W Q[G], which has a projection since Q[G]\nhas a projection. Whenever we decompose a V-computable\nsubgraph G into c-components S = {S1, ..., Sk} (case (2)\nin Definition 6), we can compute each Q[S] for each S \u2208\nS from Q[G] using the \u201cGeneralized Q-decomposition\"\nin (Tian and Pearl 2003). Hence, each Q[S] has a projection\nsince Q[G] has a projection.\nThe projections for the c-factors of V-computable sub-\ngraphs in Figure 5b are shown below, where = denotes the\nequivalence between the c-factor and projection."}, {"title": "Examples and Derivations", "content": "C.1 Derivation For Figure 7\nFigure 11 depicts the original AC for Prx(y) under the CSI\nconstraints after merging \u03b8y|a,b,c and \u03b8y|a,b,c into \u03b8y|a,b, and\nmerging \u03b8y|a,b,c and \u03b8y|a,b,c into \u03b8y|a,c (merged nodes are\ncolor-coded in blue). We can further simplify the AC by\npushing the +-nodes downwards (distributivity rule) and\nsumming-out the leaf nodes (sum-out rule). We color-coded\nthe removed +-nodes and leaf nodes in red in Figure 11. Fi-\nnally, we apply the distributivity rule on +(U3)-node on the\nright branch, which yields the simplified AC in Figure 7.\nWe can now apply the c-component method to derive pro-\njections for the AC nodes. In particular, The causal graph in\nFigure 3a induces the following c-factors:\nQ[S1] = \u03a3U1,U2,U3 \u03b8U1\u03b8U2\u03b8U3\u03b8A|U1,U2\u03b8B|U2,U3 = Pr(A, B)\nQ[S2] = \u03a3U1,U2 \u03b8U1\u03b8U2\u03b8A|U1,U2 = Pr(A)\nQ[S3] = \u2211U3 \u03b8U3\u03b8C|U3,X = Pr(C|X)\nEach of the above c-factors matches some node in the\nAC. Moreover, after plugging in the projections for the AC\nnodes, we find an invariant-cut as shown in Figure 7. We\nthus conclude that the causal effect is identifiable."}, {"title": "Additional Example on CSI", "content": "C.2 Additional Example on CSI\nThe following example is from (Tikka, Hyttinen, and Karva-\nnen 2019). Consider the causal graph G in Figure 13a with\nV = {A, X, Y}. The causal effect Prx(y) is not identifi-\nable under positivity constraint Pr(V) > 0. However, the"}, {"title": "Derivation For Figure 8", "content": "C.3 Derivation For Figure 8\nWe show that the causal effect Prx(y) is identifiable wrt\nthe causal graph G in Figure 8b under the CSI constraint\n(C\u315b U1|x, U2). We first construct the AC for Prx(y) in\nFigure 14a, which incorporates the CSI constraint with the\nmethod in Section 6.1. We then simplify the AC using the\nsimplification rules in Appendix A, which yields Figure 14b.\nTo find an invariant-cut, we need to find a projection for\nthe following expression:\n\u2211U2 \u03b8U2\u03b8C|U2,X\u03b8Y|U2, A, C\nwhich does not correspond to any c-factors directly. We now\nconsider the c-factor of the V-computable subgraph S in\nFigure 14c\nQ[S] = \u2211U1,U2 \u03b8U1\u03b8U2\u03b8X|U1,A\u03b8C|U1,U2,X\u03b8Y|U2,A,C\n= Pr(X, C, Y|A)\nIf we fix X = x, we can leverage the CSI constraint and\nreplace \u03b8C|U1,U2,x with \u03b8C|U2,x, which yields\n\u2211U1,U2 \u03b8U1\u03b8U2\u03b8X|U1,A\u03b8C|U1,U2,x\u03b8Y|U2,A,C\n= \u2211U1,U2 \u03b8U1\u03b8U2\u03b8X|U1,A\u03b8C|U2,x\u03b8Y|U2,A,C\n= Pr(x, C, Y|A)\nHence, the subgraph S' in Figure 13d is also V-computable\nunder X = x. We can further decompose S' into c-\ncomponents and obtain the following c-factor:\n\u2211U2 \u03b8U2\u03b8C|U2,x\u03b8Y|U2,A,C = Pr(C, Y|A, x)\nThis c-factor can now be used as a projection for the +(U2)-\nnode in the AC in Figure 8b. We can now find an invariant-\ncut (marked in red) and get an identifying formula Prx(y) =\n\u2211a Pr(a) \u03a3\u03b5 Pr(c, y|a, x)."}, {"title": "Derivation For Figure 9b", "content": "C.4 Derivation For Figure 9b\nWe show that the AC in Figure 10 constructed for Prx(y) un-\nder Pr*(V) in Figure 9b can be simplified to an AC with a"}, {"title": "Derivation For Figure 9c", "content": "C.5 Derivation For Figure 9c\nGiven the AC in Figure 10b, we still need to find the\nprojection for the +-nodes with the following expression:\n\u03a3U2 \u03b8U2\u03b8B|U2,\u0101,x, which does not match any c-factors\nfor V-computable subgraphs. However, by exploiting the\nCSI relation, we can set A = \u0101, X = x in the following\nc-factor \u2211U1,U2 \u03b8U1\u03b8U2\u03b8X|U1\u03b8A|U2\u03b8B|U1,U2,X, A and get\n\u2211U1,U2 \u03b8U1\u03b8U2\u03b8X|U1\u03b8\u0101|U2\u03b8B|U1,U2,x,\u0101\n= \u2211U1,U2 \u03b8U1\u03b8U2\u03b8X|U1\u03b8\u0101|U2\u03b8B|U2,x,\u0101 = Pr(x, \u0101, B)\nThat is, once we fixed the values of X and A, the c-\ncomponent S in Figure 16. We can now further decompose\nS into two c-component, one of which is exactly the expres-\nsion for the +-node in the AC:\n\u2211U2 \u03b8U2\u03b8B|U2,\u0101,x = Pr(\u0101, B|x)\nHence, we conclude the projection fro the +-node is\nPr(\u0101, b|x)."}, {"title": "Proofs", "content": "D Proofs\nProof of Proposition 1\nProof. The causal effect is unidentifiable under some\nPr*(V) > 0 since the ID algorithm returns \u201cunidentifiable\"\n(i.e., the graph contains a hedge). We next show that the\ncausal effect Prx(y) is identifiable whenever Pr*(V) satis-\nfies the CSI constraints (Y || C|a, B) and (Y || B|\u0101, C).\nWe show that the Prx(y) can be identified as\nPrx(y) = Prx(a, y) + Prx(y|\u0101, c) Pr(c|x) Pr(a)"}, {"title": "Proof of Proposition 2", "content": "Proof of Proposition 2\nWLG, to show that the causal effect Prx(y) is unidentifiable\nunder any Pr*(X, Y) > 0, we construct two parameteriza-\ntions 1 and 2 that agree on any Pr*(X, Y) but disagrees\non Prx1 (Y1), where {x1,...,Xn} are the states of X and\n{Y1,..., Ym} are the states of Y. Moreover, we assume that\nthe hidden variables U is binary and has two states 41, 42.\nWe start by constructing a parameterization for G that sat-\nisfy certain conditions.\nLemma 1. There exists a parameterization for G that\ninduces Pr*(X,Y) and in which (i) all CPTs are strictly\npositive; and (ii) \u03b8x|41 \u2260 \u03b8x|42 for all states x of X."}, {"title": "Proof of Proposition 3", "content": "Proof of Proposition 3\nThe result follows from Definition 3 and Definition 4."}, {"title": "Proof of Proposition 4", "content": "Proof of Proposition 4\nProof. By Proposition 3, it suffices to show that the out-\nput of the AC is (G, V, M)-invariant. If we replace all the\nexpressions of nodes on the invariant-cut with their projec-\ntions, it is guaranteed that the output expression of the AC\n(with projections) only involves variables V, which is deter-\nmined by Pr(V)."}, {"title": "Proof of Theorem 1", "content": "Proof of Theorem 1\nProof. First note that the completeness proof of the ID al-\ngorithm (Shpitser and Pearl 2006; Huang and Valtorta 2006)\nassumes all variables are binary. Hence, the if direction of\nthe theorem must hold.\nBefore proving the only-if direction, we briefly review the\ncomplete causal-effect identifiability algorithm in (Huang\nand Valtorta 200"}]}