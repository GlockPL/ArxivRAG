{"title": "GraphSparseNet: a Novel Method for Large Scale Trafffic Flow Prediction", "authors": ["Weiyang Kong", "Kaiqi Wu", "Sen Zhang", "Yubao Liu"], "abstract": "Traffic flow forecasting is a critical spatio-temporal data mining task with wide-ranging applications in intelligent route planning and dynamic traffic management. Recent advancements in deep learning, particularly through Graph Neural Networks (GNNs), have significantly enhanced the accuracy of these forecasts by capturing complex spatio-temporal dynamics. However, the scalability of GNNs remains a challenge due to their exponential growth in model complexity with increasing nodes in the graph. Existing methods to address this issue, including sparsification, decomposition, and kernel-based approaches, either do not fully resolve the complexity issue or risk compromising predictive accuracy. This paper introduces GraphSparseNet (GSNet), a novel framework designed to improve both the scalability and accuracy of GNN-based traffic forecasting models. GraphSparseNet is comprised of two core modules: the Feature Extractor and the Relational Compressor. These modules operate with linear time and space complexity, thereby reducing the overall computational complexity of the model to a linear scale. Our extensive experiments on multiple real-world datasets demonstrate that GraphSparseNet not only significantly reduces training time by 3.51x compared to state-of-the-art linear models but also maintains high predictive performance.", "sections": [{"title": "INTRODUCTION", "content": "Traffic flow forecasting represents a quintessential spatio-temporal data mining challenge, with profound utility in a spectrum of real-world applications, including intelligent route planning, dynamic traffic management, and smart location-based services [33]. The objective of this endeavor is to prognosticate future traffic patterns by leveraging historical traffic data, typically gleaned from the sensors embedded within transportation networks. The advent of deep learning has revolutionized this domain, with deep learning-based techniques, particularly those grounded in graph neural networks (GNNs), emerging as a dominant force. GNNs excel in capturing the intricate nonlinear dynamics inherent in spatio-temporal datasets, with their efficacy underpinned by the natural alignment between traffic data structures and graph-theoretic principles [14, 31]. In these models, graph nodes correspond to traffic sensors, while edges delineate the interconnections among these sensors.\nDespite the predictive prowess of GNN-based methodologies, they are not without their drawbacks, most notably the exponential growth in model complexity. The number of edges in a graph tends to increase exponentially with the number of nodes, posing a significant challenge for the scalability of GNNs to larger datasets. This challenge is exacerbated by the proliferation of sensors within traffic networks, driven by urban development and the pervasive integration of Internet of Things (IoT) technologies. The vast amounts of spatio-temporal data generated by these sensors pose a challenge in applying higher-accuracy GNN methods to larger-scale datasets.\nSeveral strategies have been proposed to expedite the computational efficiency of GNNs. For instance, the AGS method [5] introduces a sparsification technique that prunes a trained model, thereby reducing its complexity during the inference phase. However, this approach still incurs substantial computational overhead during the training phase. Other methods, such as GWNet and AGCRN [1, 35], employ Tucker decomposition to construct graph adjacency matrices with a reduced parameter count. Yet, these techniques merely curtail the number of trainable parameters in the adjacency matrix, without alleviating the computational burden associated with graph operations. The computational complexity of adjacency matrix multiplication, for example, remains O(N2),"}, {"title": null, "content": "where N denotes the number of nodes. While some methods have successfully simplified GNNs to enhance scalability, they are not without their limitations. The BigST method [9], which employs a kernel-based approach to simplify GNNs, is susceptible to aberrant gradient values during backpropagation, potentially leading to suboptimal training outcomes and diminished predictive accuracy.\nThis paper aims to improve the scalability of GNNs for large-scale traffic spatio-temporal data by designing a high-precision, scalable model. This is a non-trivial problem because simplifying GNN models faces two challenges: First, most approaches treat accuracy and scalability in traffic prediction models as two orthogonal issues. Accurately capturing all node relationships leads to an exponential rise in computational demands. As the number of graph nodes increases, generating the adjacency matrix and performing related operations result in a sharp increase in computational complexity. Second, existing methods for simplifying GNNs have significant limitations. Decomposition techniques fail to reduce overall model complexity, sparsification methods cannot be applied during training, and kernel-based approaches risk compromising accuracy. This highlights the need for new strategies to simplify GNNs effectively.\nUpon reviewing and observing existing studies, we find that in well-trained adjacency matrices, the relationships between nodes tend to be sparse, with only a small subset of nodes being connected. To support this claim, we visualized a trained adaptive adjacency matrix [1] and computed the weighted degree of each node, as shown in Figures 1 (a) and 1 (b). This trend is consistent across several models based on adaptive matrices [10, 34, 35]. In Figure 1 (a), higher values in the matrix indicate stronger associations between the corresponding node pairs. It is evident that only a small fraction of the matrix entries have significant values, suggesting that the relationships between nodes are highly sparse. In Figure 1 (b), we compute the weighted degree of each node, which reflects both the number and strength of connections for each node in the graph. As observed, with the exception of a few nodes with higher weighted degrees, most nodes maintain relatively low weighted degrees, indicating that the graph has a low connection density, with the majority of nodes having small numbers and weights of adjacent edges. Existing graph methods learn one entire adjacency matrix to express relationships between nodes, leading to the use of a large number of parameters and computations to learn a highly sparse matrix. We believe that the generation of graphs and related operations can be compressed onto a much smaller space, thereby \"circumventing\" the computation of all node relationships in the complete graph. We theoretically prove the rationality of this motivation, providing a theoretical derivation to show that learning one entire adjacency matrix can be replaced by learning two very small-scale matrices.\nDrawing on our comprehensive analysis and key insights, we introduce a groundbreaking model, GraphSparseNet (GSNet), designed to deliver high predictive accuracy concurrently with scalability to handle large-scale datasets. This innovative model is comprised of two synergistic modules: the Feature Extractor, which is tasked with capturing and encoding the characteristics of graph nodes, and the Relational Compressor, which is responsible for modeling the sparse relationships between nodes. Both modules are engineered to operate with linear time and space complexity, scaling efficiently with an increase in the number of graph nodes. This"}, {"title": null, "content": "design enables the model to effectively manage and analyze large-scale data without compromising performance. GraphSparseNet has reduced the complexity from O(N2) in most existing methods to O(N). Even compared to the state of the art linear models, our method has improved training time by 3.51\u00d7. We evaluated the effectiveness and scalability of our proposed framework on multiple real-world datasets from different regions. The results of these experiments consistently demonstrate the superior performance of GraphSparseNet, achieving commendable results across all datasets evaluated. The principal contributions of our work are encapsulated in the following points:\n\u2022 By conducting a thorough theoretical analysis, we have identified key factors that restrict existing methods and propose innovative solutions to address these limitations. Our approach not only refines the predictive capabilities of GNNs but also significantly enhances their ability to scale with the increasing nodes of traffic data.\n\u2022 We present GraphSparseNet, a novel framework specifically tailored to address the scalability challenges of large-scale traffic spatio-temporal data. This framework is underpinned by two core modules: the Feature Extractor and the Relational Compressor. The Feature Extractor capture and represent the features of each node within the graph, while the Relational Compressor innovatively models the sparse relationships between nodes. Both modules are designed to operate with linear time and space complexity.\n\u2022 We conducted experiments on four real-world datasets from different regions, and the results demonstrate the effectiveness and efficiency of our approach."}, {"title": "PRELIMINARY", "content": null}, {"title": "Traffic Network", "content": "Traffic network is represented by a undirected graph G = (V, E), where V is the set of nodes (sensors), N = |V| denotes the number of nodes, and E is the set of edges between two nodes. In our problem, we assume that each node records its traffic flow data as graph signal. A graph signal is Xt \u2208 RN, where t denotes the t-th time step. The graph signal represents the traffic flow values at the t-th time step."}, {"title": "Problem Definition", "content": "Given a traffic network G and its historical S step graph signal matrix X1:S = (X1, X2, ..., XS) \u2208 RN\u00d7S, our problem is to predict its next T step graph signals, namely XS+1:S+T = (XS+1, XS+2, ..., XS+T) \u2208 RN\u00d7T. We equationte the problem as finding a function F to forecast the next T steps data based on the past S steps historical data:\n(XS+1, XS+2, ..., XS+T) = F ((X1, X2, ..., XS)).  (1)"}, {"title": "ANALYSIS", "content": "In this section, we discuss the constraints that hinder the scalability of graph neural network methods. We also explain our motivations for simplifying models, supported by theoretical evidence and empirical findings."}, {"title": null, "content": "Graph neural network methodologies are highly effective in traffic prediction, as they adeptly capture node features while facilitating the integration of features across different nodes in accordance with the graph's topology. The most prevalent graph neural networks can be represented in the following form:\nH = Agg(\u0391, \u03a7, \u0398) (2)\nHere, H represents the hidden state of the model, A denotes the adjacency matrix, X represents the input data, and refers to the trainable parameters. The function Agg() is a specific method for aggregating elements in X based on the relationships defined in A. A commonly employed approach for this aggregation function is the use of spatial domain graph convolution operations in the following form:\nH = \u03c3(AXW) (3)\nHere, \u03c3(\u00b7) represents arbitrary activation function, and W denotes the trainable parameters. It leverage matrix multiplication to integrate input data X in accordance with the relationships specified by the adjacency matrix A. In the majority of current research [1, 35], to achieve superior predictive performance, matrix A is often composed of trainable parameters, a practice referred to as the adaptive adjacency matrix. This approach allows the model to reduce its reliance on prior knowledge while enhancing its representational capacity for potential node associations. To prevent over-fitting due to the extensive use of parameters, this adaptive matrix is typically factorized into the product of two smaller matrices:\nA = SoftMax(E1E2) (4)\nHere, E1 \u2208 RN\u00d7C and E2 \u2208 RC\u00d7N are both trainable parameters, C is a hyperparameter. This technique reduces the number of parameters required to construct the adjacency matrix from N\u00b2 to 2CN Employing this technique, a series of methods have empirically demonstrated that the effectiveness of the adaptive adjacency matrix can be maintained even when the parameter C is set to a value significantly smaller than N. When N is sufficiently large,"}, {"title": null, "content": "employing a decomposition approach can significantly reduce the number of training parameters needed to construct the adjacency matrix A. However, the complexity of the matrix multiplication for AX in graph convolution is still O(N2), which greatly limits the scalability of this operation on large-scale data.\nAGS [5] proposed the use of a mask matrix to simplify the adjacency matrix A. This approach introduces a Boolean mask matrix \u03b2, which has the same dimensions as the adjacency matrix A, after A has been trained. By performing the Hadamard product of A and B, the final adjacency matrix is determined based on the binary gating within \u00df, deciding whether to retain the connections. However, this method can only theoretically reduce the operational speed during the model's inference phase, as it requires the retraining of \u03b2 to achieve a sparse adjacency matrix after A has been trained. Simultaneously training A and \u03b2 can lead to difficulties in model convergence, thereby diminishing the model's predictive accuracy.\nBigST [9] designed a graph convolutional model with linear complexity. However, BigST can lead to the generation of anomalous gradient values during the model's training process, which affects the training effectiveness and the ultimate predictive accuracy. For graph convolution operations under normal circumstances, The Equation 4 can be rewritten as\nAij = \\frac{f(S_{ij})}{\\sum_{k=1}^{N} f(S_{ik})} (5)\nSij = E1iE2j, f(x) = exp(x) (6)\nThe gradients of the matrix A is derived as [26]:\n\\frac{\\partial A_{ij}}{\\partial S_{ik}} =  \\frac{f'(S_{ik})}{f(S_{ik})} (\\delta_{1j=k}A_{ij} \u2013 A_{ij}A_{ik}) (7)\nIf Equation (6) is substituted into Equation (7), we can deduce that:\n|\\frac{\\partial A_{ii}}{\\partial S_{ik}}| \u2264 \\frac{1}{4} (8)\nIt is evident that the gradients of the parameters do not exhibit any significant anomalies. BigST employs a kernel function mapping approach to simplify the graph convolution operation into a linear product of multiple matrices, as follows:\nSij = \u03c6(E1i)(E2j), f(x) = x (9)\nHere \u03c6(\u00b7) is the kernel function. If Equation 9 is substituted into Equation 7, we can deduce that:\n|\\frac{\\partial A_{ii}}{\\partial S_{ik}}| \u2264 \\frac{1}{4|S_{ik}|} (10)\nThere is always a probability that the gradients during back propagation will produce anomalous values since sij is set from 0 to positive infinity in the BigST.\nOur goal is to approximate the graph convolution operation in Equation 3 with a computational complexity of O(N), while maintaining the model's accuracy. This is feasible because, as shown in Figure 1, well-trained adaptive matrices tend to be highly sparse. For the factorized adjacency matrix A = SoftMax(E1E2), we consider the properties of matrices E\u2081 and E2 that:\nRank(E1) \u2264 C (11)\nRank(E2) \u2264 C (12)"}, {"title": null, "content": "Rank(E1E2) \u2264 Min(Rank (E1), Rank(E2)) \u2264 C (13)\nThis implies that the column (and row) space of the matrix E1 E2 can both be spanned by a set of C linearly independent vectors. In other words, we have the following theorem:\nTHEOREM 3.1. Let M \u2208 RN\u00d7N be a matrix with rank C. There always exists a non-unique matrix K \u2208 RC\u00d7C such that matrix M can be constructed via some matrix multiplication transformations involving K.\nProof:\nFor a matrix M of rank C, it is known from matrix theory that we can factorize A as a product of three matrices:\n\u039c = \u03bb \u03a7 \u039a \u03a7 \u03bc (14)\nHere, the matrix \u03bb \u2208 RN\u00d7C consists of a set of linearly independent column vectors from the column space of M. The matrix \u03bc\u03b5 RC\u00d7N consists of a set of linearly independent row vectors from the row space of M. Matrix K captures the transformation between these basis vectors. In this factorization, \u03bb and u are matrices formed from linearly independent column and row vectors (basis vectors) from the column space and row space of M, respectively. The matrix K represents the transformation between these basis vectors.\nTo find the matrices \u03bb, \u03bc and K, the following steps are taken: Perform column operations on matrix M (e.g., using Gaussian elimination) to identify a set of linearly independent column vectors that span the column space of M. These basis vectors form the columns of matrix \u03bb. Similarly, perform row operations on matrix M to form the rows of matrix \u03bc.\nMatrix K is determined by the linear combination relationships between the basis vectors in A and \u03bc. According to the factorization, matrix M can be written as M = \u03bb \u03a7 \u039a \u00d7 \u03bc. In other words, every element of matrix M is obtained by a linear combination of the column basis vectors in A and the row basis vectors in u, with the coefficients coming from matrix K. Write each column of matrix M as a linear combination of the column basis vectors in \u03bb, with the coefficients being the elements of matrix K. Similarly, write each row of matrix M as a linear combination of the row basis vectors in u, with the coefficients being the elements of matrix K. By comparing each element of matrix M with the corresponding linear combinations of basis vectors, a system of linear equations can be formed. Solving this system gives the elements of matrix K. Specifically, for each element Mij of matrix M, we can write the following equation:\nMij = \\sum_{k=1}^{C}\\sum_{l=1}^{C}  \u03bb_{ik} \u00b7 K_{kl} \u00b7 \u03bc_{lj} (15)\nSolving these equations yields the elements of matrix K.\nNext, we will prove that K is not unique. The matrices A and \u00b5 are not uniquely determined because there are multiple ways to choose the basis vectors for the column space and row space of M. Consequently, there may be different choices of K. The matrix A is formed by selecting a basis for the column space of M, but there can be multiple different sets of linearly independent column vectors that span the same column space. Thus, A is not unique. Similarly, \u03bc is not unique. Since both \u03bb and u can vary, matrix K is not uniquely"}, {"title": null, "content": "determined. We shall further elucidate the aforementioned properties through the construction of an illustrative example. Suppose we have a factorization M = \u03bb \u03a7 \u039a \u00d7 \u03bc. Now, consider applying an invertible linear transformation to the basis vectors. Specifically, let D be an arbitrary invertible C X C matrix. Define new matrices \u012b and \u016d as:\n\u00c3 = \u03bb\u00d7 D and \u0169 = D\u22121 \u00d7 \u03bc (16)\nThen, we can construct a new factorization:\nM = 2 \u00d7 (D-1 \u00d7 K \u00d7 D) \u00d7 \u0171 (17)\nIn this new factorization, the matrix K = D-1 \u00d7 K \u00d7 D differs from the original matrix K. Hence, by applying different invertible transformations, we can generate different matrices K that still satisfy the equation M = \u03bb \u00d7 K \u00d7 \u00b5. This demonstrates that matrix K is not unique, as different transformations of the basis vectors lead to different but valid choices for K. \u03a0\nFor the sake of convenience in subsequent descriptions, we assume, based on the aforementioned theorem, that:\nE1 = \\sum_{i=1}^{C}\\sum_{j=1}^{C} K_{ij}M_{ij} (18)\nHere U represents the coefficient of the linear combination, and Kmn denotes the elements of matrix K with rank C. Thus, we can consider that matrix E1E2 can be derived from matrix K and coefficient matrix U through a series of linear transformations. In other words, the process of the model learning matrix E1 E2 is equivalent to learning matrix K and the coefficient matrix U.\nSince the well-trained adjacency matrix A is sparse, we propose that a significant number of values in U can be replaced with a fixed number, meaning that the number of trainable parameters used to express the combination coefficients in matrix U can be much smaller than its shape. The adjacency matrix A used in existing model is obtained by applying the activation function to E1E2. Taking the most commonly used form, SoftMax(), as an example, we have:\nSoftMax(E1E) = SoftMax(\\sum_{i=1}^{C}\\sum_{j=1}^{C}  K_{ij}M_{ij}) (19)\nIf Aij in the adjacency matrix is zero, we only need to set the corresponding coefficient in U to a fixed negative value (for example, negative 3) to ensure that the calculated Aij is close to zero. For a sparse adjacency matrix A, most elements in U would be set to negative 3, with only a small portion of elements needing to be determined through training. The proportion of trainable parameters in matrix U is positively correlated with the sparsity of matrix A. Similarly, if other activation functions are chosen, we simply need to set the corresponding elements in U to other fixed values since the computation of the activation function is fixed.\nBased on the aforementioned analysis, we can consider that in the adaptive matrix based methods, the technique of setting A as a trainable parameter can be replaced by allowing the model to learn matrix K and the linear combination coefficient matrix U. Intuitively, the information contained in matrix A is equivalent to the information contained in K and U.\nFurthermore, in the graph convolution operation of equation 3, the intention of the matrix multiplication for AX is to perform"}, {"title": null, "content": "feature fusion of the input data X according to the adjacency relationship A through linear transformation. The complexity of this operation is O(N2), which limits the scalability of the graph convolution operation. Since we can learn matrix K and the combination coefficients U separately, in this paper, we propose a new framework to replace the graph convolution operation in equation 3. The following sections will introduce the specific details of our newly proposed method."}, {"title": "PROPOSED MODEL", "content": "we commence by elucidating the overarching framework of the model. Subsequently, we introduce the specific module designs within the model."}, {"title": "Framework of the model", "content": "As depicted in Figure 2, our model comprises two distinct modules: Feature Extractor and Relational Compressor. The Feature Extractor compresses the input data into an low-dimensional space and subsequently reconstructs it, while simultaneously updating an embedding that represents the node features. The Relational Compressor transforms the input data into an low-dimensional space, models the implicit adjacency relationships between different nodes in the low-dimensional space, and ultimately reconstructs the data back into its original space. The low-dimensional spaces involved in the two modules are mutually aligned. Both the Feature Extractor and Relational Compressor are stacked in a serial manner, and the outputs from each layer are concatenated with skip connections, which are then transformed into prediction through an output layer.\nIn our model, there are two types of embedding matrices. One is the input embedding P \u2208 RN\u00d7d, and the other is the node embedding Q\u2208 RN\u00d7d. d denotes the number of channel in the embedding. The node embedding is composed of trainable parameters, the elements of which are updated exclusively during the training process of the model and do not vary with the input data. In contrast, the input embedding is generated from the model's input data and automatically adjusts according to different inputs. The purpose of the node embedding is to model the characteristics of each node in the transportation network during the training process of the model. The input embedding encompasses not only the node feature information but also the spatial information (such as the relationship between nodes) and temporal information present in the input data. The objectives of transforming the input data into input embeddings are twofold: first, to obtain a dense representation for spatio-temporal features, and second, to enable the model to automatically learn the most salient features of the data."}, {"title": "Feature Extractor", "content": "The advantages of Graph Neural Networks stem from two aspects: one is their powerful feature learning capability, which can accurately capture the features of each node, and the other is their ability to handle graph-structured data, allowing node features to be integrated based on adjacency relationships. By aggregating information from neighboring nodes to update the representation of a node, it can capture complex relationships between nodes, thereby better understanding graph-structured data. In the Feature Extractor module, our primary goal is to enable the model to learn the features of different nodes.\nIn the design of the Feature Extractor, we have two objectives: one is to update the node embeddings through this module to model the characteristics of each node in the traffic data, and the other is to attempt to compress the input embeddings, which contain spatio-temporal information, to a low-dimensional space, thereby preparing for subsequent feature fusion in low-dimensional space within the model.\nTo achieve both of these objectives, we have designed a module that compresses and then decompresses the input information based on node features. The input embeddings encompass only the local spatio-temporal characteristics of the input time series, as the data presented to the model at each instance constitutes a small slice of the entire dataset. Concurrently, the node embeddings remain invariant over time, thereby capturing and representing global information. Therefore, we concatenate the two types of embeddings as the input to the module.\nXFE = P||Q (20)\nHere, XFE represents the input of Feature Extractor. The concatenated input XFE contains both the local spatio-temporal information of the input data and the global features of each node. A reasonable approach to compressing data from an N-dimensional space to a low-dimensional space is to cluster based on node features. To this end, we use a matrix generated from the node features to compress the module input, as follows:\nHFE = V1XFE (21)\nV\u2081 = W1Q + B1 (22)\nHere, HFE represents the hidden state, V\u2081 is the compressing matrix. W\u2081 and B\u2081 are trainable parameter matrices. Subsequently, we designed the decompression process, which is similar to the compression. To introduce non-linear characteristics and control in the Feature Extractor, we added an activation function between the compression and decompression processes. We utilize the SoftMax function to present the hidden layer in the form of a probability distribution, thereby enhancing the training effectiveness of this module during the decompression process.\nOFE = V2SoftMax(HFE) (23)\nV2 = W2Q + B2 (24)\nOn one hand, the process of compression and decompression can update the a node embedding Q to learn the features of different nodes. The information contained within this embedding will be shared with Relational Compressor. On the other hand, the model is designed to learn a method of compressing the input to a size of C dimensions, which serves as an auxiliary function for Relational Compressor to map the input into a low-dimensional space. This alignment of the compression ratio in this module with that in Relational Compressor is crucial for the seamless integration and effective operation of the overall model."}, {"title": "Relational Compressor", "content": "As we discussed in the previous analysis, learning the adjacency matrix A can be equivalent to learning matrices K and U. In the design of the Relational Compressor, our objective is to learn the"}, {"title": null, "content": "embeddings and input embeddings as input:\nHRC = V3(P||Q) (25)\nHere HRC is the hidden state in Relational Compressor. Unlike the Feature Extractor, in the compression process, to enable the compression to consider the local spatio-temporal features in the input embedding P, rather than compressing solely based on global node features, we consider using two embeddings to generate the compression matrix:\nV3 = W3 (P||Q) + B3 (26)\nAfter compressing the input into the low-dimensional space, we let the model learn the coefficient matrix U in the hidden state through concatenation.\nHRC = HRC||U (27)\nAs shown in Figure 3, the shape of the coefficient matrix U can be controlled by C'. Subsequently, we fuse features according to the low-dimensional adaptive adjacency matrix K through matrix multiplication in the hidden state, as follows:\nHRC = KHRC (28)\nK is the adaptive adjacency matrix in the C + C'-dimensional space. Both K and U are composed of trainable parameters, and in Section 2, we discussed the feasibility of using K and U to replace the adaptive matrix A. Through concatenation and matrix multiplication, Relational Compressor can achieve the purpose of learning adjacency relationships and feature fusion in the low-dimensional space. The number of trainable parameters contained in matrices"}, {"title": null, "content": "K and U is far less than that in A. Moreover, the computational complexity of the module is also far less than that of spatial GCN and its existing improved schemes, which we will analyze in detail later. Subsequently, we architected the decompression process to be analogous to the compression process, ensuring a symmetrical approach to feature representation.\nORC = V4SoftMax(HRC) (29)\nV4 = W4(P||Q) + B4 (30)\nThe outputs of the two modules are summarized through a skip-connection approach and the final prediction result is obtained through the output layer. The final output is:\nO = OFE || ORC (31)\nThe output layer consists of an activation function and a fully connected layer.\nThe overall training process of our model is outlined in Algorithm 1."}, {"title": "Complexity Analysis", "content": "In this section, we analyze the complexity of various modules within the proposed model. For the sake of simplicity, we assume that C = C' = d in the subsequent discussions.\nRegarding time complexity: The complexity of converting the input graph signal to input embeddings in the input layer is O(NSC), where N is the number of nodes, S is the number of historical time steps, and C is the dimensionality of the low-dimensional space. In the Feature Extractor, the complexity of compression and decompression is O(C2N + C2N). In the Relational Compressor, the complexity of compression and decompression is O(C2N + C2N), and the complexity of feature fusion in the low-dimensional space is O(C\u00b3). The complexity of the output layer is O(NTC), where T is the time step of the output graph signal. Since C, S, and T are constants, the overall time complexity of the model is O(N).\nRegarding space complexity: The space complexity for input embeddings and node embeddings is O(SN + CN). The space complexity for generating the compression and decompression transformation matrices is O(CN). The space complexity for generating K and U is O(CN + C\u00b2). The overall space complexity of the model is O(N).\nIt can be observed that our approach exhibits a space complexity and time complexity of O(N), which endows our method with superior scalability."}, {"title": "EXPERMENTS", "content": "In this section, we evaluated our proposed model by empirically examining on four real-world datasets with the state-of-the-art models for traffic forecasting. To support the reproducibility of the results in this paper, we have released our code on website. 1"}, {"title": "Datasets and Pre-processing", "content": "We conduct experiments on four widely used real-world public traffic datasets from: (1)PEMS\u00b2(PEMS07 and PEMS08), (2)England\u00b3,\nand (3)CA[22]. The biggest dataset is California (CA), including a total number of 8,600 sensors. To the best of our knowledge, CA is"}, {"title": null, "content": "currently the publicly available dataset with the highest number of nodes recorded by loop detectors. It contain three representative areas: Greater Los Angeles, Greater Bay Area, and San Diego. A brief description are given in Table 2.\nZ-score normalization is applied to inputs as follows.\nXinput = \\frac{X - mean(X)}{std(X)} (32)\nHere mean(X) and std(X) denote the mean and the standard deviation of the historical time series, respectively."}, {"title": "Baselines", "content": "We compare the proposed method in this paper with current state-of-the-art approaches in the field. The selected baselines are categorized into five groups based on their model frameworks. The first category includes classical statistical methods, specifically ARIMA [32].\nThe second category consists of CNN-based approaches, such as STResNet [40], ACFM [21] and STGCN [38]. The third category focuses on GNN-based methods, with some incorporating RNN structures, represented by DCRNN [18], GWNet [35], AGCRN [1], AGS [5] and BigST [9]. The fourth category includes transformer-based methods, denoted by PDFormer [13] and Bi-STAT [3]. Lastly, the fifth category includes large model (pretrained neural networks) approaches, denoted as GPT-ST [20] and UniST [39]. :\n\u2022 ARIMA: Historical Average, which models the traffic as a seasonal process and uses the average of previous seasons (e.g., the same time slot of previous days) as the prediction;\n\u2022 STResNet: Spatio-Temporal Residual Network, which combines both spatial and temporal dependencies to forecast crowd movement patterns in urban environments based on residual learning;\n\u2022 ACFM: Attention-based Contextual Feature Mapping, which leverages both spatial and temporal information to predict traffic patterns;\n\u2022 STGCN: Spatio-Temporal Graph Convolutional Networks, which equationte the problem on graphs and build the model with complete convolutional structures;\n\u2022 DCRNN: Diffusion Convolution Recurrent Neural Network, which combines graph convolution with recurrent neural networks in an encoder-decoder manner;\n\u2022 GWNet: Graph WaveNet is a framework that incorporates adaptive adjacency matrix into graph convolution with 1D dilated convolution;\n\u2022 AGCRN: Adaptive Graph Convolutional Recurrent Network which capture fine-grained spatial and temporal correlations in traffic series automatically based on graph neural networks and recurrent networks;\n\u2022 AGS: Adaptive Graph Sparsification, which propose a graph sparsification algorithm in inference process;\n\u2022 BigST: A linear complexity spatio-temporal graph neural network to efficiently exploit long-range spatio-temporal dependencies for large-scale traffic forecasting;\n\u2022 PDFormer: The proposed PDFormer model introduces a new approach for traffic flow prediction using a transformer model that explicitly accounts for propagation delays in traffic data;"}, {"title": null, "content": "\u2022 Bi-STAT: Bidirectional Spatial-Temporal Adaptive Transformer, which introduces an innovative architecture that captures both spatial and temporal dependencies in traffic data, while also adapting dynamically to varying traffic conditions;\n\u2022 GPT-ST: A novel approach for improving spatio-temporal graph neural networks through generative pre-training, which uses a generative pre-training strategy to learn effective representations of spatio-temporal data before fine-tuning the model for specific prediction tasks;\n\u2022 UniST: An universal architecture utilizes prompt-based learning to guide the model's attention to relevant spatial and temporal features, allowing it to adapt efficiently to various urban prediction scenarios."}, {"title": "Experimental Setup", "content": "Our implementation is based on python 3.12.1", "CPU": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "GPU": "GeForce RTX 3080 10GB). Tests on PEMS07", "7": 1, "6": 2, "models": "Mean Absolute Errors (MAE) represents the average absolute value of prediction errors. For each data point, the absolute error between the actual and predicted values is calculated, and then the average is taken across all data points.\nMAE = \\frac{1}{TN} \\sum_{i=1}^{T}\\sum_{j=1}^{N} | x_{j}^{(t"}]}