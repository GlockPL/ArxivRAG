{"title": "Enhancing Machine Learning Performance through Intelligent Data Quality Assessment: An Unsupervised Data-centric Framework", "authors": ["Manal Rahala", "Bestoun S. Ahmed", "Gergely Szabados", "Torgny Fornstedt", "J\u00f6rgen Samuelsson"], "abstract": "Poor data quality limits the advantageous power of Machine Learning (ML) and weakens high-performing ML software systems. Nowadays, data are more prone to the risk of poor quality due to their increasing volume and complexity. Therefore, tedious and time-consuming work goes into data preparation and improvement before moving further in the ML pipeline. To address this challenge, we propose an intelligent data-centric evaluation framework that can identify high-quality data and improve the performance of an ML system. The proposed framework combines the curation of quality measurements and unsupervised learning to distinguish high- and low-quality data. The framework is designed to integrate flexible and general-purpose methods so that it is deployed in various domains and applications. To validate the outcomes of the designed framework, we implemented it in a real-world use case from the field of analytical chemistry, where it is tested on three datasets of anti-sense oligonucleotides. A domain expert is consulted to identify the relevant quality measurements and evaluate the outcomes of the framework. The results show that the quality-centric data evaluation framework identifies the characteristics of high-quality data that guide the conduct of efficient laboratory experiments and consequently improve the performance of the ML system.", "sections": [{"title": "1. Introduction", "content": "Machine learning (ML) as a growing innovative field has proven successful in numerous domains [1]. In recent years, ML programs have evolved into data-driven software systems with a complex yet defined pipeline of operations. Given that an ML software system is based on learning patterns from training data, the first operation in the pipeline typically includes data preparation [2]. Once the data are clean and of high quality, the training and evaluation operations of the ML model are carried out with confidence. Although research shows that data quality (DQ) has a direct impact on the outcomes of an ML software system, the evaluation of DQ has been identified as the greatest challenge for ML practitioners ([3, 4]).\nPoor DQ leads to weak learning from the training data and threatens the generalization power of the model. Therefore, optimizing the performance of the ML software systems could not be achieved without optimizing both the ML model and the DQ [5]. In the literature, DQ evaluation refers to the identification of data dimensions and metrics to measure the importance of data. However, the assessment of DQ is not straightforward, as it is highly dependent on the nature of the application [6]. Therefore, DQ has been addressed from different perspectives in different applications and domains.\nIn the field of analytical chemistry, data-driven research, including the application of ML, has a long history [1]. One of the most popular applications of predictive ML models in this field is the prediction of retention time (tr) in chromatography experiments. During a chromatography experiment, the constituting compounds of a complex mixture undergo separation. The time a compound spends in a chromatography column is called tr. Chromatography-generated raw data could include inconsistent recordings. The source of DQ inconsistency can be attributed to the performance of the chromatographic equipment, experimental conditions, and other external factors. Given that ML operates under the assumption of clean data, DQ should be addressed before it is fed into the ML model in the larger ML software system [7]. In many cases, the evaluation of DQ requires manual intervention from chemical scientists, which is often difficult to implement and time-consuming.\nTo address this gap, this paper proposes a quality-centric data evaluation framework for a fast and simple multi-stage approach to DQ evaluation."}, {"title": "2. Background and Related Work", "content": "This section gives an overview of common data issues in ML software systems and discusses the work related to developing DQ frameworks in the literature. Given that the case study is applied to an application in the field"}, {"title": "2.1. Data Issues in ML Software Systems", "content": "Data understanding and preparation are often the least interesting stages in the ML software pipeline. However, to ensure proper learning, DQ must be handled [8]. During this phase, the features are encoded, the data are checked for null values, outliers, and statistical correlation among the independent variables, and the distribution of the feature values is visualized. The importance of data pre-processing comes from the critical impact of the data on the performance of the ML software system.\nThe literature studying this topic separates the data issues observed in information systems from big data issues. In [9], the authors identified the data problems observed in information systems, such as information loss, ambiguity, meaningless, or incorrect data. The categorization is based on the true representation of an information system in the real world and the fact that data issues arise due to representation deficiencies [9]. With the evolution of big data and AI, researchers have begun to investigate DQ issues beyond classical database operations and have begun to look at big data challenges [6].\nDespite data issues dating back to the early days of computing, DQ is still considered an interesting research topic [6]. In particular, the challenges emerging from big data. Although big data has great potential for the advancement of technologies, at the same time, it presents many challenges that arise from its properties [10]. Most research extracts data issues from the characteristics of the big data itself. For example, Fan et al. identifies the challenges of big data in complex heterogeneity, high dimensionality, noise accumulation, spurious correlation, incidental endogeneity, and measurement errors [11]. Another research considered heterogeneity and incompleteness, scale, and timeliness as data-related issues to be addressed [12]. In another study, the authors present a comprehensive mapping of data issues into three main categories [13]. The first category includes data issues related to the characteristics of big data, such as volume, variety, velocity, veracity, volatility, and variability. The second group is related to the challenges of data processing from collection to the application of ML. The third category pertains to data management issues, including data security, privacy, and ethical concepts."}, {"title": "2.2. Systemic Approaches to DQ Evaluation in the Literature", "content": "The concept of DQ greatly depends on the nature of the application under study. Therefore, the definition and assessment of DQ is a complex concept [6]. As such, there are different definitions of DQ in the literature. For example, DQ could refer to the measurement of incorrect or missing data [14], or represent the suitability of a given dataset, including the features, for a specific use case ([15], [16]). In this paper, we define the DQ as the characteristics of the data that fit the purpose of building high-performing ML systems.\nDQ validation is an influential requirement for a reliable ML system [17]. Given its dependence on the use case, researchers from different perspectives have handled the concept of DQ. However, many of the DQ frameworks in the literature are based on database management concepts that aim to solve generic DQ problems [18]. One of the first DQ frameworks proposed testing whether the data are complete, unambiguous, meaningful, and correct [9]. While in [19], authors go beyond precision and present a hierarchical framework that categorizes the attributes of DQ into four groups: intrinsic, contextual, representational, and accessible. According to [19], high-quality data are defined as intrinsically good, contextually suitable for the task, clearly represented, and accessible. In [20], the authors address the quality of raw data in the pre-processing stage and apply it to a conceptualized weather monitoring and forecasting application as a case study. The idea is to fix as many data issues as possible before training and evaluating ML models [20]. [17] presented a risk-based data validation approach in ML systems inspired by the famous risk-based approach in SE testing. In the risk-based approach, features are presented as risk items where the risk of poor DQ for each feature is estimated. Two important factors are calculated under this approach, the probability that a feature is of low quality and the impact of this feature on the performance of the ML system."}, {"title": "2.3. DQ in Ion-pair Liquid Chromatography", "content": "Chromatography, in general, is an efficient method used in the separation of a range of samples, including drugs, food, air and water samples, and much more. Ion-pair Liquid Chromatography (IPLC) is a chromatography technique that allows one to separate complex molecular mixtures in particular charged molecules [31]. The method includes injecting the sample, including a mixture of compounds, into the column where the separation occurs, as shown in Figure 1. As the separated compounds exit the column, they are detected by the detector as signals. The information collected on the detected signals provides insight into the success of the separation. In our case study, a mixture is a group of ASO compounds separated from the impurities by the IPLC method. An ASO compound is a combination of the nucleotides adenine (A), thymine (T), cytosine (C), and guanine (G). An ASO sequence could be modified by other atoms, such as sulfur, known as phosphorothioation. The importance of ASO sequences comes from their interesting potential in the treatment of diseases that are not targeted by classical medicine [32, 33].\nWhile the compounds are eluting from the IPLC system, the data describing the detected signals are recorded. A sample of the collected data is shown in Table 1, where each row refers to an ASO compound and its peak characteristics. The characteristics of a peak include the signal-to-noise ratio (SNR), Atr, which calculates the difference in tr between two experiments, and the area under the peak. The resulting peaks are typically visualized in a chromatogram, which is later inspected and analyzed by analytical chemists.\nA chromatogram is a graphical representation of the detected signals over the separation time. Analytical chemists spend a substantial amount of time controlling the quality of the data visualized data in a chromatogram [34]. Data pre-processing in this context includes removing the undesired experiments from the obtained signals [35]. A typical pre-processing procedure includes noise removal and baseline correction [35]. Furthermore, inspecting the properties of the peaks, focusing mainly on the tr, shape, and resolution peaks [34]. In particular, inspecting the cases of overlapped peaks, shifted tr, and peaks with low SNR [36]. Chromatogram inspection and analysis are crucial since accurate peaks lead to sound quantitative and qualitative analysis.\nChromatogram analysis is a critical step in correcting the data problems faced during the data acquisition phase. A chemist generally looks for significant peaks and observes failed experiments. The analysis of the data is mostly conducted manually with the assistance of statistical and mathematical tools. Still, it is often complex and time-consuming, as all resulting peaks must be checked. Therefore, the interest in using ML methods to facilitate data analysis is increasing.\nIn the literature, ML has been used for various peak quality control ap-"}, {"title": "3. The proposed Quality-Centric Data Evaluation Framework", "content": "This section presents the methodology for implementing the quality-centric data evaluation framework. The output of the framework is a classification of the input data according to the designed quality measurements. The framework is built on general-purpose ML methods, which allows it to be applied in different domains. The resulting understanding of the quality of the input data can be used in various tasks depending on the nature of the business. For example, from a modeling perspective, high-quality data is fed to the ML software system, and lower-quality data could be rechecked by scientists for further analysis. In addition, low-quality data could be further analyzed to understand why certain chemical modifications can degrade or boost the performance of an ML software system. In this paper, the implementation of this framework reduces the time it takes scientists to check poor input data, as it reduces search space. The overall phases of the framework are shown in Figure 2. Once the raw data are received, the domain experts, along with the ML practitioners, decide on the quality measurements that best fit the nature of the application. The quality measurements are then represented in a dataset where they serve as independent variables for the later application of the unsupervised learning method. The resulting dataset is then sufficiently pre-processed and fed to an unsupervised ML model to generate k quality-sensitive clusters, where k represents the number of clusters. k can be identified through multiple methods such as the elbow method. After the clusters are generated and plotted, a hyper-tuned ML model, using the grid search method, is applied to each of the k clusters' data, where the target variable is predicted. This stage is critical, as it allows one to understand the performance of the ML model on the different clusters. Per cluster, ML performance metrics on the train and test sets are recorded and analyzed. During the analysis stage, insights on the level of quality of the data are learned and fed back to data source controllers. The continuous"}, {"title": "4. Implementation and Evaluation", "content": "In this section, we adopt the quality-centric data evaluation framework for the case study of predicting tr of ASO compounds including defining the relevant DQ measurements. The proposed framework is applied to three ASO datasets collected through IPLC experiments, described in Section 4.2. Based on the experimental setup, we focus on answering three RQs:\n\u2022 (RQ1) How can unsupervised learning be effective in classifying data records into different quality levels?\n\u2022 (RQ2) How do we transform the results of the application of an unsupervised DQ evaluation framework into explainable insights that improve the performance of the ML software system?\n\u2022 (RQ3) How can we validate the results of a DQ evaluation framework built on unsupervised learning?"}, {"title": "4.1. Defining DQ Measurements", "content": "Quality can be defined as a set of multiple dimensions in a specific context, where each dimension represents an aspect of the DQ and can be inherited from one or more measurements [15]. The task of defining quality measurements is critical to the successful implementation of the framework. In principle, it is considered good practice to re-engineer the raw data before incorporating them into an ML software system [40]. Otherwise, important patterns and information may be missed. At the same time, data representation is strongly associated with the goal of unsupervised learning [41]. In clustering, even without natural clusters, data objects could be assigned to the same group [41]. Therefore, the curation and design of quality measurements is a critical task. With the support of domain experts and analytical chemistry theory, relevant DQ measurements are selected, that describe the characteristics of the signal detected by the detector. As a result of rigorous data analysis, four crucial quality measurements were defined. Since data quantification is needed for data analysis, the derived measurements are quantified before application. The derived measurements represent the quality of the ASO data in the three datasets, which serve as input to the"}, {"title": "4.1.1. SNR", "content": "A chromatographic signal is obtained after an ASO sample passes through the column and is detected by the detector. The magnitude of the intensity of the signal at a specific time is a combination of the baseline signal of the chromatogram B(t), the peak signal P(t), and the noise signal N(t), where noise commonly refers to unwanted fluctuations in the experimental system [42]. An SNR is generally defined as the amount of noise relative to the main signal, as illustrated in Figure 3. Hence, the chromatographic signal Y(t) can be expressed as:\n$Y(t) = B(t) + P(t) + N(t)  (1)$\nIn chromatography, measurements depend on the baseline identified when the chromatogram is idle [43]. The higher the SNR, the better the quality of the signal. Assuming its definition, SNR is the first quality measurement to be considered in this paper."}, {"title": "4.1.2. Delta tr (ATR)", "content": "For a given sample where two replicates were conducted, the tr,1 is obtained from the first chromatography experiment run. The tr,2 is obtained"}, {"title": "4.1.3. Peak skewness", "content": "The symmetry of a signal peak in chromatography is an extremely important factor [44]. In reality, the experimentally obtained peaks are asymmetric and commonly tailing [45]. In the literature, there are many methods to determine the skewness [44]. A typical representation of skewness is the ratio WR / WL at a selected peak height [46]. In the context of chromatography data, skewness, whether in the form of tailing or fronting peaks, is usually undesirable. Rather, the more symmetrical a peak is, the higher the quality of the data. In this case study, we calculate the skewness of a peak as in Eq.2:\n$Qs,0(x) =  WR(X)/ WL(x)  where x \u2208 (0,1)   (2)$\nWR(x) and W\u2081(x) represent the horizontal distance to the line through the peak, at x=0.5 of the peak height as shown in Figure 4. At qs,0 =1, the peak is symmetrical. If qs,o \u2208]0, 1[, the peak is a fronting peak skewed to the left. Otherwise its is a tailing peak and qs,0 \u20ac]1,\u221e[."}, {"title": "4.1.4. Peak area", "content": "Another important factor in the chromatographic signal data is the peak area. In other words, it refers to the area under the curve. The area of the peak for a certain eluting compound is proportional to the amount of the compound reaching the detector."}, {"title": "4.2. Description of ASO Datasets", "content": "Three datasets were obtained by performing IPLC experiments on ASO samples to separate the full-length ASO compound from its impurities. Data were collected under three different chemical conditions, which resulted in three different datasets as shown in Table 2. The change in the composition of the mobile phase, typically the organic solvent, is known as the gradient. The gradient allows for different levels of variability and noise in each dataset. The appropriate amount of mobile phase is critical to achieve an acceptable separation in a given experiment [45]. The three datasets have the same number of features but differ in the distribution of the independent variables and the target variable. Independent variables include the defined quality measurements, in addition to the ASO length and the amount of sulfur. In this case, the target variable is tr. The train set and the test set were collected from the same set of experiments, with all conditions unchanged, so we assume that both sets exhibit similar DQ characteristics. Since the data are collected from chromatography experiments, errors could occur during the experiment run-time, either during data collection or data storage.\nBy applying the data quality measurements defined in Section 4.1 to the three datasets in our use case, we analyze the variation in data distribution across these datasets. The results are presented using boxplots, showcasing the independent variables SNR, skewness, and Atr. As shown in Figures 5, 6, and 7, the highest variation in At\u20a8 between the two experiments is found in the G3 dataset, while the lowest is found in the G1 dataset. The same"}, {"title": "4.3. Motivation and Implementation of Selected Methods", "content": "Learning in the context of ML refers to finding patterns in the data [47]. The grouping or clustering of objects based on similarity is considered a fundamental exploratory method of learning [41]. Clustering has been used mainly to detect anomalies and identify important features, perform natural classification of organisms, and compress the data into cluster prototypes. In the context of data science, clustering is simply the meaningful grouping of data objects [48]. Unsupervised clustering is a form of clustering that is applied to unlabeled data [48]. The clustering method is powerful by itself, but the results of the clustering task are often combined with a subsequent prediction task for higher explainability, as in our case study.\nThere are various clustering algorithms to analyze big data. Such as density-based clustering used in real-time data analysis and hierarchical clus-tering and incremental clustering for other applications [49]. This study implements k-means clustering, a hierarchical method, to group the ASO compounds into clusters according to pre-defined quality measurements. Two main advantages contribute to the selection of k-means; it is straightforward and characterized by low computational complexity [48]. K-means aims to find k clusters in a dataset such that the intra-cluster similarity is high and the inter-cluster similarity is low [48]. A cluster is expected to include a set of isolated points [41]. The k-means achieve this by computing the Euclidean distance between the data points and the cluster centers, thus forming the spherical partitioning of the data [48]. In other words, k-means start with an initial cluster and then assign the clusters minimizing the squared error until the clusters are stable [41]. It should be noted that high dimensionality challenges the performance of k-means. Therefore, principal component analysis (PCA) is used to transform the data into a lower dimensional space which facilitates the detection of coherent patterns more clearly in the data [50]. PCA is a feature reduction statistical technique used to extract important information from high-dimensional data and project it into lower-dimensional"}, {"title": "5. Results", "content": ""}, {"title": "5.1. G1 Dataset", "content": "The quality-centric data evaluation framework is tested on the G1 dataset resulting in the grouping of the data into three clusters as shown in Figure 8(a). The results of applying the hypertuned Gradient Boost model to each"}, {"title": "5.2. G2 Dataset", "content": "The result of the application of the hypertuned support vector regression (SVR) model to the three identified clusters in G2 is summarised in Table 8 and Figure 9. The clustering results visualized in Figure 9(a) show the distribution of data points in the reduced dimensional space, with clear separation between quality-based groups. Table 8 shows the RMSE and R2 values in G2 test sets for each of the three clusters. According to the results, the performance of the SVR model varies across the three clusters, as demonstrated in Figures 9(b-d). Cluster 0 has the highest RMSE and the lowest R2 in the test set, with scattered predictions shown in Figure 9(b), indicating poor performance in this cluster compared to the other clusters. Cluster 1 and cluster 2 have lower RMSE and higher R\u00b2 values for both train and test sets, as evidenced by the tighter grouping of predictions around the ideal line in Figures 9(c,d), with SVR recording the lowest RMSE in cluster 1. With respect to RMSE, the performance of the SVR shows to be better in cluster 1 compared to the other clusters.\nThe first cluster in the G2 dataset has 331 ASO compounds. In cluster 0, the Atr is of mean equals 0.18 minutes and standard deviation of 1.78 minutes. The minimum and maximum values are -9.75 and 11.17 minutes respectively, which shows high variation among the two runs. The minimum and maximum values in the SNR column are 2.04 and 3004.23, respectively, where half of the data having SNR equal 44.04. As for skewness, which measures the asymmetry of the peak shape, minimum and maximum values"}, {"title": "5.3. G3 Dataset", "content": "G3 is the most sensitive dataset among all datasets, with the highest noise. Similar to the G1 and G2 datasets, the quality-centric data evaluation framework was applied to the G3 dataset, resulting in the clustering of the data into three groups as shown in Figure 10(a), where the PCA-transformed data points show distinct quality-based groupings. The statistical characteristics of each cluster are presented in Tables 13, 14, and 15. In the next step, the hypertuned SVR model was applied to the three identified clusters, with the prediction results visualized in Figures 10(b-d). The results of the evaluation of the SVR model on the G3 test set are shown in Table 12. The SVR model performed poorly on cluster 0, as evidenced by the scattered predictions in Figure 10(b), unlike clusters 1 and 2, where the rmse recorded 0.92 and 0.49, respectively, showing tighter prediction patterns in Figures 10(c,d). The SVR model performed best in cluster 2, which is reflected in the close alignment of predictions with the ideal line in Figure 10(d).\nThe variation in the Atr feature in the first cluster in G3 is high, as shown in Table 13. The minimum and maximum values for AtR are -18.67 and 16.17, respectively. The average SNR value in cluster 0 is 145.72. The minimum and maximum values for SNR are 1.54 and 3460.76, respectively, suggesting the detection of weak and stronger signals. The degree of skewness varies in this cluster, where the 25th percentile records 0.21. This suggests that the data are skewed in general. On average, ASOs have a length of 15.71 and are at least 12 nucleotides long. All sequences in this cluster are phosphorothioated with a minimum of 8 sulfur atoms.\nThe variation in Atr is the highest cluster 1 with a standard deviation of 3.38 minutes. The average SNR is 147.97, with a standard deviation of 216.63, indicating that the ASOs in this cluster have slightly higher SNR than those in cluster 0. The standard deviation is 7240.84 indicating a high variation in the area recordings. The average length of the ASO in this cluster"}, {"title": "6. Discussion", "content": "The analysis of the obtained results is organized to answer the 1-3 RQS presented in Section 4."}, {"title": "6.1. RQ1: How can unsupervised learning be effective in classifying data records into different quality levels?", "content": "The successful performance of unsupervised learning depends on the careful selection of the quality measurements that are chosen in the second stage of the DQ evaluation framework. The choice of interesting quality measurements is application-specific and depends on the successful collaboration between data scientists and domain experts. Once the clusters are generated, the dominating characteristics of the data points in each cluster can be analyzed in depth, where high- and low-quality data can be deduced. In this case study, the selection of quality measurements proved to play an important role in the clustering of ASO compounds into high- and low-quality groups. Given that the definition of the quality measurements depends on the application being studied, it is recommended that domain experts and ML practitioners work together to identify a representative set of measurements."}, {"title": "6.2. RQ2: How do we transform the results of the application of an unsupervised DQ evaluation framework into explainable insights that improve the performance of the ML software system?", "content": "The application of unsupervised methods alone is often recognized under the exploratory data analysis tools, which can score low on the explainability spectrum. However, when combined with predictive ML unsupervised learning can offer valuable insights. In this case study, unsupervised learning is used to group the data into quality-sensitive clusters. Thus, generating insights on the quality characteristics of the input data in each cluster. Explainability comes one step later, more specifically after predictive ML is applied. One of the approaches to achieve explainable results is by analyzing the statistical characteristics of the data present in each cluster, similar to what is done in this paper.\nFor instance, in the G1 dataset, the ML model performed best in cluster 0. The ASO compounds in this group are characterized by high SNR, low skewness, and relatively low standard deviation in \u2206 tr. The ASOs in this cluster are long, consisting of a minimum of 12 nucleotides. Phosphorothioation in this dataset has negatively affected the performance of the gradient boost model, so the cluster with the majority of sulfur-modified sequences was the hardest to learn. We also note that most of the sequences in this cluster have lost a sulfur atom. Therefore, the modification by sulfur, either adding or losing a sulfur atom shows to degrade the performance of the ML model. At a higher gradient, the ML model performed best in G2 in the cluster where the ASOs are relatively long and are mostly not phosphoroth-ioated. The distinguishing characteristic in this cluster refers to the high average SNR, which therefore contributes to a higher performance of the ML model. At the highest gradient, G3, the SVR model performed best in the cluster consisting of the least modified compounds. Similar to the G1 dataset, phosphorothioation negatively impacted the performance of the model. In summary, the results of the experiments show that high-quality ASO data are characterized by lack of or low modification, relatively long, express low values of skewness, and high values of SNR during a chromatography experiment. Through multiple discussions, the domain expert confirmed that the identified characteristics align with their understanding of the domain. This iterative validation process ensured the findings were consistent with domain knowledge, which helps ensure the framework's outputs are meaningful and can drive real-world improvements in data collection and conducting chromatography experiments.\nTo effectively utilize the insights learned from the analysis stage, the in-sights must be transformed into actionable feedback to the data source con-trollers. This happens by integrating a feedback mechanism between data scientists and business teams. A continuous two-way feedback mechanism improves the quality of the input data and consequently the predictive capa-bilities of the deployed ML model."}, {"title": "6.3. RQ3: How can we validate the results of a DQ evaluation framework built on unsupervised clustering?", "content": "The quality-centric data evaluation framework integrates an essential stage that requires applying predictive ML to the generated quality-sensitive clusters. This step is key to validating and transforming the results of unsupervised learning into quantitative metrics often selected depending on the application. The variant performance of the ML model in each of the clusters represented by quantitative statistical metrics, such as the rmse and R2 in this case study, offers a quantitative representation of the quality of the data records belonging to each cluster. For example, in the G1 dataset, the ML model performed best in cluster 0, where the performance was significantly poor in cluster 2, as shown in Table 4. The difference in the performance of the predictive ML model among clusters shows that high-quality data patterns have been learned from the different groups of input data. Another key step is validating the framework output with domain experts to ensure consistency of conclusions with domain knowledge, or reason about borderline cases."}, {"title": "7. Threats to validity", "content": "The generalization of conceptual frameworks applied to specific real-world applications is often associated with threats to external validity. Such frameworks can be designed for use cases in specific domains that do not apply to others. However, the data evaluation framework presented in Figure 2 could be customized at every stage of the pipeline to fit the application at hand, including the type of unsupervised and supervised learning. The framework does not offer tailored solutions to the case study but is designed to be flexible and reproducible. Furthermore, quality measurements are selected by domain experts and ML practitioners working on a specific application. The customization of the tools and methods at every stage in the framework supports the generalization intent. This applies to ML-related tasks such as the choice of models and non-ML decisions such as the choice of quality measurements. In addition, sending feedback to data source controllers for improving data acquisition and production applies to various business domains. Based on the above, the framework is a general-purpose framework that can be customized and used in different applications. An important aspect of the generalization framework is the identification of quality measurements that"}, {"title": "8. Conclusion", "content": "In this paper, we introduce the quality-centric data evaluation framework, which aims to group the data into high- and low-quality clusters. It is required to define the suitable application DQ measurements before implementing the unsupervised learning method. The framework integrates unsupervised learning to generate quality-sensitive clusters and predictive ML to validate and analyze the results. Predictive ML is applied to each resulting cluster to predict the target variable. Based on the accuracy and the performance of the ML, characteristics of high- and low-quality data are learned. High-quality ASO data are observed to have a lack of or low modification, relatively long sequence, low levels of skewness, and high SNR values. Then the deduced insights are fed back to data source controllers to quality control the operations. The framework is simple and useful in improving the outcome of the ML software system. The framework is deployed and evaluated in an analytical chemistry case study, where it proved its efficiency. In each of the three datasets, the performance of the ML model showed distinguished results among the different generated clusters. In some clusters, ML performed poorly, while in others, the performance was significantly better, which enabled learning of high-quality characteristics of an ASO compound.\nThe quality-centric data evaluation framework integrates general qualitative and ML methods, which facilitate the application in other domains. The user-defined measurements are application-specific, and the user can select the unsupervised or supervised ML method that best serves the application data. Therefore, this framework is presented as a general approach to selecting high-quality data that improves the performance of an ML system.\nBuilding on these findings, several promising directions for future research emerge. Scaling the proposed framework to larger datasets across diverse do-"}, {"title": "9. Data and Code Availability", "content": "The data used to support the findings of this study will be made available from the corresponding author upon reasonable request."}]}