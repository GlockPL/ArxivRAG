{"title": "TriQXNet: Forecasting Dst Index from Solar Wind\nData Using an Interpretable Parallel\nClassical-Quantum Framework with Uncertainty\nQuantification", "authors": ["Md Abrar Jahin", "M. F. Mridha", "Zeyar Aung", "Nilanjan Dey", "R. Simon Sherratt"], "abstract": "Geomagnetic storms, which are brought on by the transmission of solar wind energy to the Earth's magnetic field, have the\npotential to substantially damage a number of critical infrastructure systems, including GPS, satellite communications, and\nelectrical power grids. The disturbance storm-time (Dst) index is used to determine how strong these storms are. Using\nreal-time solar wind data, a variety of models-empirical, physics-based, and machine-learning-have improved Dst forecasting\nduring the last thirty years. However, forecasting extreme geomagnetic events is still difficult, requiring reliable ways to\nmanage unprocessed, real-time data streams in the face of noise and sensor failures. This research aims to create a Dst\nforecasting model that employs specific real-time solar wind data feeds, functions under realistic restrictions, and outperforms\nstate-of-the-art models in terms of prediction. Innovative methods are needed to solve this complex challenge, as it is not\nimmediately evident what the optimal solution is. This study introduces a groundbreaking application of quantum computing in\nspace weather forecasting. Our novel framework represents a pioneering integration of classical and quantum computing,\nconformal prediction, and explainable AI (XAI) within a hybrid neural network architecture. To ensure high-quality input data,\nwe developed a comprehensive data preprocessing pipeline that includes feature selection, normalization, aggregation, and\nimputation. The hybrid classical-quantum neural network, TriQXNet, leverages three parallel channels to process preprocessed\nsolar wind data, significantly enhancing the robustness and accuracy of Dst index predictions. Our model predicts the Dst index\nusing solar wind measurements from NASA's ACE and NOAA's DSCOVR satellites for the hour that is currently underway (to)\nas well as the hour that will follow (t+1), providing vital advance notice to lessen the negative consequences of geomagnetic\nstorms. TriQXNet outperforms 13 state-of-the-art hybrid deep-learning models, achieving a root mean squared error of 9.27\nnanoteslas (nT). Rigorous evaluation through 10-fold cross-validated paired t-tests confirmed TriQXNet's superior performance\nwith 95% confidence. By implementing conformal prediction techniques, we provide quantifiable uncertainty in our forecasts,\nwhich is essential for operational decision-making. Additionally, incorporating XAI methods such as ShapTime and permutation\nfeature importance enhances the interpretability of the model, fostering greater trust in its predictions. Comparative analysis\nrevealed that TriQXNet outperforms existing models in the literature and the model deployed by the CIRES/NCEI geomagnetism\nteam. Our model demonstrated exceptional forecasting accuracy for dual hours in a specific case study involving rapid Dst\nvalue decline. This research sets a new level of expectations for geomagnetic storm forecasting, showing the potential of\nclassical-quantum hybrid models to improve space weather prediction capabilities.", "sections": [{"title": "Introduction", "content": "Geomagnetic storms, principally induced by coronal mass ejections and co-rotating interaction areas, represent an imminent\nthreat to modern technological systems as they may cause catastrophic disruptions of power grids, GPS navigation, and satellite\ncommunications\u00b9. The Earth's magnetic field, due to the effective coupling of amplified solar wind with the ground magnetic\nfield, leads to significant errors in systems using it as a pointing reference. These fluctuations can disrupt the accuracy of\ncompasses, magnetometers, and other devices that rely on magnetic field measurements for navigation or orientation. It is\nimportant for users of these systems to be aware of potential errors during periods of heightened solar activity. An essential\nindicator in this regard is the disturbance storm time (Dst)\u00b2 index, which gauges the intensity of geomagnetic storms. The\nDst index is a standardized indicator of geomagnetic disturbances and is computed using data from four near-equatorial\nobservatories (San Juan, Honolulu, Kakioka, and Hermanus)3. Its values, which come from the magnetic field's horizontal\ncomponent, are vital for powering geomagnetic models such as the NOAA/NCEI High Definition Geomagnetic Model-Real\nTime (HDGM-RT)4\u20138. This model provides high-resolution geomagnetic field predictions that are essential for a variety of\napplications, such as directional drilling and satellite operations. Based on measurements from four geomagnetic observatories,\nthe intensity of these geomagnetic storms is determined by Dst, which is represented in nanoseconds. Lower Dst readings\nindicate a weakening of the Earth's magnetic field, a phenomenon associated with geomagnetic storms. Storms are classified\nas moderate when the Dst reading falls > -50 nanoteslas (nT). Readings between -50 < Dst < -250 nT signify an intense\nstorm. If the Dst value plunges below < -250 nT, the storm is considered a super-storm.\nMany techniques have emerged to model and forecast the Dst index. One such approach, proposed by Burton et al.10,\nutilizes differential equations to create a Dst index model. This model incorporates solar wind parameters as the driving force\nwithin the equations. Using a time-delayed artificial neural network (ANN), Gleisner et al.11 led the way in developing Dst\nprediction models. Their model, which is based on solar wind data, anticipates the Dst index 1\u20136 hours in advance. Another\nmethod that combines ANNs and physical models was introduced by Bala and Reiff12. This combination method makes use of\nvariables such as the solar wind speed, the interplanetary magnetic field (IMF) total strength, and the IMF's orientation. Lazzus\net al.13 optimized the connection weights within an ANN using a particle swarm optimization technique to improve the accuracy\nof Dst predictions. While the aforementioned techniques primarily focus on single-point predictions, Chandorkar et al.14\nproposed an extension by incorporating probabilistic forecasting into the Dst index. Their method builds autoregressive models\nusing Gaussian processes (GPs). These models use the B\u2082 component of the IMF, solar wind velocity, and historical Dst values\nto estimate the Dst index one hour ahead of time. This method produces a probability distribution of possible results instead of a\nsingle forecast. Moreover, these projections' average values might not be as precise as those generated by ANNs. To overcome\nthis constraint, Gruet et al.9 created a Dst prediction model that enhances the point prediction performance of GP by fusing GP\nwith an LSTM network. By combining ANNs, support vector regression, and LSTM networks in a bagging framework, Xu\net al.15 routinely achieved a correlation coefficient (R) > 0.86 and a root mean squared error (RMSE) < 8.09 nT. Nuraeni et\nal.16 studied a technique for Dst index forecasting 24 hours in advance. Using a nonlinear autoregressive exogenous (NARX)\nmodel trained on data from 39 geomagnetic storms between 1997 and 2000, they employed this methodology. Between August\n1st and October 31st, 2021, the model was examined for operational Dst index prediction. The RMSE ranged approximately\n5\u201320 nT on quiet days and 18\u201345 nT on disturbed days. For real-time Dst index forecasting, Nilam and Ram\u00b97 presented a\nnovel ensemble Kalman filter (EnKF) approach that makes use of ring current dynamics, such as injection and decay rates.\nThe real-time Dst values or measurements of the horizontal magnetic field from a single ground-based magnetometer were\nadded to this forecast to improve it. The outcomes show that the EnKF approach produced an RMSE of 4.3 nT and R =\n0.99. To create operationally useful Dst projections, NASA's CoECI, the University of Colorado's CIRES, and NOAA's NCEI\nhosted the \"MagNet: Model the Geomagnetic Field\"18 challenge in 2021. Managed by DrivenData and HeroX, the challenge\nattracted submissions of 1,197 models that used various CML strategies, which were validated using solar wind and Dst data in\na containerized computing environment that simulated real conditions. Nair et al.19 conducted additional analysis on the top\nfour models, which were developed by Ali, Trotta, Medina and Medina, and Eissa and Amer18, based on their lowest RMSE\nerrors. The ensemble averages of these models outperformed those of the individual models despite their different architectures.\nDespite significant advancements, predicting the Dst index is still difficult because of the unpredictability of solar wind\nconditions and the constraints of current models. Over time, physics- and empirical-based models have been created to\nforecast Dst from solar wind data. However, they frequently have trouble making precise real-time forecasts, particularly\nduring the peaks of geomagnetic storms and quiet times10, 20\u201323. Conventional prediction models, mostly grounded in classical\nmachine learning (CML) approaches, have been widely employed for geomagnetic storm forecasting. However, these models\nface severe limitations when attempting to handle the enormous dimensionality and inherent complexity of the datasets in\nquestion. Although intricate patterns and connections in the data are difficult for classical models to capture, they are essential\nfor producing reliable predictions. This limitation leads to suboptimal performance and challenges in scaling these models\neffectively. One of the critical drawbacks of CML models, such as deep neural networks (DNNs), is their requirement for\ntuning millions of hyperparameters. This process is computationally intensive and demands substantial computing power. In\naddition, the amount of data required to train these models continues to increase, which increases the computing load in the\npost-Moore's Law age, when semiconductor technology developments have slowed. The progress and effectiveness of classical\nmodels in processing large-scale, real-time data streams utilized in geomagnetic storm prediction are severely hampered by\nthis bottleneck. On the other hand, issues such as factoring large numbers and performing unstructured database searches are\namong the difficult challenges that quantum computing (QC) offers potential answers for24.\nQuantum machine learning (QML)25\u201330, which leverages the principles of QC31\u201334, has shown superior performance in\nvarious domains compared to its classical counterparts35. One of the primary advantages of QML is its use of variational\nquantum circuits, which require significantly fewer model parameters than classical models36. This reduction in parameters\nhelps mitigate the overfitting issues commonly associated with CML models. Moreover, variational quantum models can\nlearn more efficiently and achieve higher test accuracy under certain conditions37. These methods excel in capturing complex\npatterns and dependencies in data, which are essential for accurate Dst predictions. Killoran et al.38 developed quantum\nversions of specialized models such as residual, recurrent, and convolutional networks and showed how to integrate them into\nquantum formalism. Integrating quantum elements into a QML architecture, in which a classical computer updates the circuit\nparameters, improves the model's overall robustness and predictive power30,39. Larocca et al.40 investigated the phenomena of\nover-parametrization in quantum neural networks (QNNs), characterizing it as a condition where a QNN has more parameters\nthan a critical number, enabling it to explore all pertinent paths in state space. Efficient characterization of quantum states is\nessential to quantum computing, but conventional approaches become computationally costly. Certain quantum states may\nbe identified using QNNs, which integrate feedforward, measurements, and unitary operations. Herrmann et al. utilized a\n7-qubit superconducting quantum processor to find the topological phases of a spin model protected by symmetry41. Direct\nmeasurements of the string order parameter were not as good as the quantum convolutional neural network. For universal\nquantum computation, Beer et al.42 suggested integrating a natural quantum perceptron into a QNN. Positive layer transition\nmaps are utilized by the QNN design to provide a quantum analog of classical backpropagation. For noisy intermediate-scale\nquantum (NISQ) devices, the conventional simulation results of the QNN are encouraging. Wan et al.26 proposed reversible\nand unitary quantum generalizations of classical neural networks. Gradient descent enables the QNN to carry out quantum\ngeneralizations of classical tasks efficiently. It can be applied photonically, compress quantum states, and find quantum\ncommunication protocols. Using QML, it is possible to overcome some of the fundamental issues raised by NISQ devices\nby creating noise-resistant quantum algorithms with controllable circuit depths43. This hybrid classical\u2013quantum approach\nimproves the performance and accuracy of Dst forecasting models and ensures that they are scalable and operationally feasible\nin real-time environments.\nThe motivation behind this research is driven by the urgent need to enhance the accuracy and reliability of Dst forecasting\nmodels, which are crucial for mitigating the impacts of geomagnetic storms on modern technological systems. Vital systems\nlike GPS, satellite communication, and electric power transmission are interfered with by geomagnetic storms, which are\ngenerated by an efficient transfer of energy from the solar wind to the Earth's magnetic field. By enabling scientists and\nengineers to more accurately forecast the timing and severity of geomagnetic storm occurrences, improving these models\ncontributes to protecting critical assets. This makes it possible to take preventative action to reduce damage and downtime.\nDespite advancements in empirical, physics-based, and machine learning (ML) models over the past three decades,\nsignificant limitations persist. First, many existing models rely heavily on prior Dst values as input, but these values are often\nunavailable in real-time or contaminated with noise and baseline shifts, undermining their operational reliability. Second,\nreal-time solar wind data, such as those from the NASA OMNI and RTSW data streams, frequently contain noise, gaps,\nand unprocessed information, complicating the accurate prediction of Dst. Finally, models must operate efficiently within\nthe constraints of real-time computational environments, limiting the complexity and resource usage of potential forecasting\nsolutions. Addressing these challenges is critical for improving the predictive performance and operational feasibility of Dst\nforecasting models, making them more robust and reliable for real-time use.\nResearchers have been creating empirical models to predict Dst based on solar wind observations since the mid-1970s.\nThese initiatives have relied heavily on satellite data such as NASA's Advanced Composition Explorer (ACE) and NOAA's Deep\nSpace Climate Observatory (DSCOVR). However, forecasting extreme geomagnetic occurrences continues to be extremely\ndifficult. Robust methods that can operate with unprocessed, real-time data streams under practical circumstances, such as\nnoise and malfunctioning sensors, are needed.\nBy addressing these key areas, TriQXNet represents a significant advancement in Dst index forecasting, offering a robust,\nreliable, and interpretable solution for real-time applications. The model's nomenclature, TriQXNet, reflects its hybrid nature\nand the innovative approach it embodies. The \"Tri\" signifies the three parallel channels used in the architecture, each designed\nto handle different aspects of the data preprocessing and forecasting process. \"Q\" highlights the integration of QC with classical\nmethods, an approach that is cutting-edge in the realm of geomagnetic storm forecasting. The \"X\" in TriQXNet stands for\nexplainable AI (XAI) and uncertainty quantification (UQ), which are integral to our model's design. The inclusion of \"Net\"\ndenotes the neural network foundation that underpins the model's predictive capabilities.\nThis research represents the pioneering application of interpretable and uncertainty quantifiable QC in space weather\nforecasting, a significant leap forward in leveraging QC for astronomical phenomena. The contributions of this research are as\nfollows:\n1.  We introduce an innovative theoretical framework for forecasting geomagnetic storms using classical and QC techniques.\nThis is the pioneering approach to combine conformal prediction and XAI with hybrid classical-quantum neural networks,\nsetting a new standard in space weather prediction.\n2.  A sophisticated data preprocessing pipeline has been developed, incorporating feature selection, normalization, aggrega-\ntion of hourly features, imputation using the forward-fill method, and the most frequent strategy for dealing with noisy\nsolar wind data from satellites.\n3.  We propose a hybrid classical-quantum neural network-based architecture with three parallel channels. Each channel\nprocesses preprocessed solar wind data to forecast the Dst index, enhancing robustness and accuracy. It is ready for\noperational deployment and can handle real-time data streams with inherent noise and gaps.\n4.  The model is designed to forecast the Dst index for both the current hour (to) and the subsequent hour (t+1), providing\nvaluable lead time for mitigating the effects of geomagnetic storms.\n5.  The model's improved accuracy is demonstrated by carefully evaluating its performance using RMSE and comparing it\nwith that of 13 state-of-the-art hybrid models.\n6.  Through 10-fold cross-validated paired t-tests, we establish the statistical significance of TriQXNet's performance\nimprovements.\n7.  By implementing conformal prediction techniques, we quantify the uncertainty in TriQXNet forecasts, providing\nconfidence intervals that are crucial for operational decision-making.\n8.  By incorporating XAI concepts such as ShapTime and permutation feature importance, we enhance the interpretability of\nthe model, making it easier to understand and trust its predictions.\nThe remainder of this article is organized as follows: In the \"Methods\" section, the architecture of all the developed\nmodels for benchmarking-which includes both classical and quantum components is presented, along with information\non the dataset description, experimental setup, and data preprocessing. The \"Results\" section covers the evaluation metric,\nour experimental findings, a comparison of TriQXNet's performance against the most advanced models, statistical validation,\nconformal prediction analysis, and XAI interpretation of TriQXNet. The probable advantages, practical ramifications, and\nreal-world astronomical applications of the proposed method are discussed in the \"Discussion\" section. The paper's conclusions\nare detailed in the \"Conclusions\" section, offering a synopsis of the results and suggestions for future research."}, {"title": "Methods", "content": "The solar wind measurements collected from NASA's ACE and NOAA's DSCOVR satellites constitute the input data for\nthis research, as shown in Fig. 1. The datasets included solar wind data, sunspot numbers, satellite coordinate data, and hourly Dst\nvalues. Table 1 provides detailed information on the solar wind dataset, satellite positions, and monthly smoothed sunspot\nnumbers (Jan 1998 - Dec 2021), sourced from the SWPC, used in our research. Overall, 11,943,360 records are included in our\ndataset. Table 3 illustrates the six time periods for which we used Dst index data. The dataset's maximum and minimum Dst\nvalues are 77 nT and -422 nT, respectively.\nWe used solar wind data from NOAA's DSCOVR satellite (launched in 2015) and NASA's ACE satellite (in service since 1997)\nfor our modeling work. The Lagrangian (L1) point is where both spacecraft are located, approximately 1.6 million kilometers\nfrom Earth. The fact that solar wind particles arrive at L1 approximately one hour before they strike Earth makes this position\nideal for tracking solar activity. We used the 1-minute averaged data from 1998 to 2020 from NOAA's Space Weather Prediction\nCenter (SWPC) in the \"Real-Time Solar Wind\" (RTSW) dataset. This collection contains important observations that were\ntaken in almost real-time from the L1 site, including the IMF, density, temperature, and solar wind speed. The RTSW is not\ntime-shifted to consider the transit time to Earth's magnetosphere, in contrast to other datasets. SWPC uses ACE data, which\nindicates when there are data outages or problems with DSCOVR.\nThe ACE and DSCOVR satellites circle around the L1 point, keeping their relative positions to Earth constant. The positions of\nthese satellites, which are stored in geocentric solar ecliptic (GSE) coordinates, can improve the prediction accuracy of the Dst\nindex.\nSunspot numbers, which follow an approximately 11-year solar cycle, influence geomagnetic activity. Our dataset spans solar\ncycles 23 and 24, covering periods when geomagnetic storms are most frequent. Using sunspot data helps calibrate our model\nto predict geomagnetic activity throughout different solar cycle phases.\nThe World Data Center for Geomagnetism in Kyoto provides the Dst index, which is used to quantify the strength of geomagnetic\nstorms\u00b3. We used hourly Dst data from 1998 to 2020, including final, provisional, and real-time values. The Dst index represents\nthe average geomagnetic activity over each hour. When TriQXNet forecasts the Dst index, it uses solar wind data up to that\nhour to predict the average Dst for the following hour. This methodology ensures that our forecasts are forward-looking and\naccurate. Our focus is on predicting extreme geomagnetic events, defined as periods when the Dst index is -80 nT or lower, due\nto their significant impact on technology and infrastructure (see Fig. 2). The dataset includes events with Dst values as low as\n-422 nT, highlighting the severity of these disturbances. A crucial step in developing TriQXNet and ensuring its interpretability\ninvolves exploring feature correlations. As depicted in Fig. 3, there is a significant correlation between |Dst| and bulk speed of\nthe solar wind (0.46), magnitude of the IMF component bt (0.31), ion temperature of the solar wind (0.25), and bzgsm (0.20).\nConversely, there is little correlation between |Dst and the positions of the ACE and DSCOVR satellites. Understanding\nthese correlations helps refine TriQXNet's architecture and sensitivity to various input parameters. Further details on model\nperformance and XAI techniques are discussed in the \"Results\" section.\nThe hardware and software configurations used in our studies are shown in Table 2. The Python version, CPU, GPU, RAM, and\nimportant libraries used in our study are detailed.\nWe begin our data preprocessing by exploring the input (feature) and output (label) data to understand their architecture,\nstatistical properties, and basic input-output relationships. Given the vast amount of solar wind data (8,392,320 rows across 15\nfeatures), we performed a similar analysis for sunspots. These initial steps provided insights into each feature's range, central\ntendency, and variability, which is fundamental for effective preprocessing. One major challenge in working with real-time\nsolar wind data is the presence of gaps. To address this, we calculated the percentage of missing data for each feature, finding\ngaps ranging from approximately 3.8% to 9.7%. This highlights the need for robust imputation techniques to maintain data\nintegrity. We used imputation techniques such as forward-filling for sunspot data and the most frequent value imputation for\nsolar wind observations to fill these gaps, ensuring that no missing values remained after postprocessing.\nWe generated features by aggregating the solar wind data to the floor of each hour, computing statistics such as the hourly\nmean and standard deviation. This aggregation step reduces noise and variability, making the data more suitable for modeling.\nThe aggregated data are then combined with sunspot observations to enrich our feature set. Using the conventional scaling\nnormalization procedure, which centers the data around zero with unit variance, we subtracted the mean and divided the result\nby the standard deviation. These steps are essential for ensuring that our model can effectively learn from the data without\nbeing biased by variations in scale or magnitude among the features. This step used 'StandardScaler' from the 'sklearn' library.\nScaling maintains characteristics with wider ranges, from controlling the model training process to aiding in the acceleration of\ngradient-based optimization techniques convergence. To forecast the present (to) and next hour (t+1) values, we constructed a\ntime-shifted version of the Dst index for the output labels. This formulation aligns with our goal of forecasting immediate and\nnear-future geomagnetic disturbances, which is critical for timely space weather alerts. Finally, we combined the processed\nfeatures and labels into a single data frame. This merged dataset is then split into training, validation, and test sets, ensuring\nthat all splits adequately represent each period (train_a, train_b, train_c), as illustrated in Table 3."}, {"title": "", "content": "To ensure that the model performs effectively when applied to new data", "parts": 70, "follows": "the last piece is assigned to the test set"}, {"follows": "n$\\text{Attention"}, 28, 4, 56, 0.1, 25, 0.1, 4, {"overleftarrow{h_t}": "n(6)\nThe architecture is inspired by the work on BiLSTMs by Schuster and Paliwal and is known for its effectiveness in various\nsequence modeling tasks 45", "forget gates\" in LSTM and GRU cells eliminate unnecessary old data while keeping what is essential. Long\nsequences can be handled with this method without the risk of error gradients being too big, which is a common problem with\nprevious RNNs. Mathematically, the forward and backward passes of the GRU layers can be represented by equation (7).\n$h_{t}^{GRU} = \\text{GRU}(x_t, h_{t}^{GRU})$\n(7)\nBoth the LSTM and GRU layers are configured to return sequences. The outputs from the GRU layer are flattened and then\npassed through a series of dense layers with decreasing neuron counts (96, 128, and 64) to extract and consolidate the features\nlearned from the sequential data. The model's mathematical expressiveness remains unchanged with the addition of these dense\nlayers. Net linear functions can always be used in place of linear functions when they are composable. On the other hand, these\nmodifications could affect the initial state or the convergence behavior. To generate the final predictions, a dense output layer\nconsisting of two neurons is added at the end.\nThe ensemble of 21 convolutional neural network (CNN) models, each composed of four blocks, is known as the DepSeqCon-\nvNet architecture19. Within each block, two consecutive convolutional layers are connected. The forward pass through the\nconvolutional layers can be mathematically represented by equation (8).\n$z_i^{(l)} = \\text{Conv}(x_i^{(l-1)})$ for i = 1,2,...,n\n(8)\nFor the ith input, $x_i^{(l-1)}$ is the input to layer 1, and $z_i^{(l)}$ is the output of the convolutional layer I for the ith input.\nFollowing these convolutions, leaky rectified linear unit (ReLU) activation and subsequent max pooling operations are\napplied, reducing the sequence length by half. Additionally, the network incorporates a skip connection, concatenating the\ninput's last timestep with the convolutional segment's output before reaching the final output layers. This model employs a\ncustom loss function, characterized by its formulation in equation (9).\n$\\text{Loss} = \\log((y - s)^2) + |y - s|$\n(9)\nHere, the power s controls the loss function's behavior, allowing for adjustments in both under and overestimation. This\nloss function approximates the RMSE by averaging the logarithm of the squared error. The parameter s plays a crucial role in\nfine-tuning the loss function's response to the RMSE. Specifically, when s = 2, the second component of the loss resembles\nthe mean squared error. Stronger penalties are applied to outliers with higher s values, which indicate heightened sensitivity\nto severe mistakes. This phenomenon stems from formulating the loss function's second term, accentuating the impact of\nsignificant deviations. Large error minimization is prioritized by higher s values, which improve the model's performance on\nextreme data points. With seven random seeds for every variant and the designated loss function with s values of 1.5, 2.4, and\n2.5, the DeepSeqConvNet ensemble consists of 21 trained models.\nTemporalFusionCNN is a robust CNN architecture with several sequential convolutional layers that detect increasing patterns\nover different time frames. After data processing, each convolutional layer output's last data point is concatenated and routed\nthrough a thick layer. Information spanning several periods in history prior to the forecast time is gathered using the last data\npoint in a convolution. For example, information from the past hour may be included in the final feature in the first layer, and\ninformation from the preceding six hours may be included in the features in the next layer.\nThe design of TemporalFusionCNN is similar to that of the U-Net, consisting of a \"contracting path\" with a few convolutional\nlayers that compress the picture and a \"expansive path\" with upconvolution layers that restore the image to its initial size.47.\nLocal predictions consider global aspects. In contrast, the temporal convolutional network uses residual connections, where\nlow- and high-level features are combined by addition rather than concatenation48.\nThe TemporalFusionCNN ensemble consists of five identical models trained on different data parts. Two predictions, t and\nt + 1, are made with separate models, resulting in 10 models. Here, ensemble averaging is used because it might be problematic\nfor individual models to accurately represent the true connection between input and output variables, frequently resulting in\nfitting noise in the training set. Averaging the predictions of multiple models cancels out random noise, providing a smoother\nand more accurate estimate of the underlying relationship.\nWe developed a multi-pathway neural network called CNN+BiLSTM+Multihead Attention, which consists of three main\npathways": "an LSTM network, a CNN, and a multi-head attention mechanism.\nInput, convolutional, and batch normalization layers are the first layers in the CNN pathway. More precisely, batch\nnormalization happens after the first convolutional layer\u2014a kernel size of three-which consists of sixteen filters. After the\nReLU activation and batch normalization, three convolutional layers with 32 filters, a kernel size of 4, and 'same' padding are\nused. Max-pooling processes are interspersed to downsample the feature maps without losing important features. The flattened\nfeatures are then put into a thick layer of sixty neurons.\nConcurrently, BiLSTM layers with 512, 256, and 128 units are used by the LSTM route to process the input sequence. The\noutputs of these LSTM layers are concatenated and then routed through thicker layers. A second dense layer with a single\nneuron is used to generate the final output after the first layer with 128 units and a SELU activation function. The output is then\nflattened for integration with the remainder of the model architecture.\nTo capture self-attention inside the input sequence, a multihead attention layer with three heads and a head size of three is\nused. A 1D vector is created by flattening the output of the multihead attention layer.\nThe CNN, LSTM, and multihead attention pathways' combined outputs are concatenated in the model's output layer, which\nis a dense layer composed of two neurons.\nThe CNN+BiLSTM+Multihead Attention model and this model's architecture are quite similar, except that this model has\nadditional Time-Distributed layers and different parameters. Following a TimeDistributed layer, a dense layer of 32 neurons\nand a ReLU activation function is distributed using the input data.\nWe use the output of the layer before it to start a convolutional operation for the convolutional layers. To be more precise"}]}