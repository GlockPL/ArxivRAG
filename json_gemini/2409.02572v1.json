{"title": "Advancing Cyber Incident Timeline Analysis\nThrough Rule-Based AI and Large Language\nModels", "authors": ["Fatma Yasmine LOUMACHI", "Mohamed Chahine GHANEM"], "abstract": "Abstract-Timeline Analysis (TA) is a key part of Timeline\nForensics (TF) in Digital Forensics (DF), focusing primarily\non examining and analysing temporal digital artefacts such as\ntimestamps, derived from event logs, file metadata, and other\nrelated data to correlate events resulting from cyber incidents and\nreconstruct their chronological timeline. Traditional tools often\nstruggle to efficiently process the vast volume and variety of data\nacquired during DF investigations and Incident Response (IR)\nprocesses. This paper presents a novel framework, GenDFIR, that\ncombines Rule-Based Artificial Intelligence (R-BAI) algorithms\nwith Large Language Models (LLMs) to advance and automate\nthe TA process. Our approach consists of two main stages: (1)\nWe use R-BAI to identify and select anomalous digital artefacts\nbased on predefined rules. (2) The selected artefacts are then\nconverted into embeddings for processing by an LLM with\nthe help of a Retrieval-Augmented Generation (RAG) agent.\nThe LLM consequently leverages its capabilities to perform\nautomated TA on the artefacts and predict potential incident\nscenarios. To validate our framework, we evaluate GenDFIR's\nperformance, efficiency, and reliability using various metrics\nacross synthetic cyber incident simulation scenarios. This paper\npresents a proof of concept, where the findings demonstrate the\nsignificant potential of integrating R-BAI and LLMs for TA. This\nnovel approach highlights the power of Generative AI (GenAI),\nspecifically LLMs, and opens new avenues for advanced threat\ndetection and incident reconstruction, representing a significant\nstep forward in the field.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, cyber incidents have massively increased\ndue to exposed vulnerabilities, affecting a wide range of digital\ndevices, including computers, IoT devices, network hardware\n(routers, switches, IDS, etc.), and embedded systems. Data and\nartefacts resulting from these incidents are always regarded\nand identified as evidence at the end of the Digital Forensics\n(DF) investigation process [1].\nDF, which includes TF, is essential for uncovering evidence\nand reconstructing the sequence of events [2]. Additionally,\nDF, works hand-in-hand with the Incident Response (IR)\nprocess, acting as a primary defence mechanism. After a\ncyber incident, IR teams are the immediate actors, operating\nto identify, detect, and contain the threat. In the aftermath,\nDF analysts and experts are called upon to collect data and\ndigital artefacts resulting from the incident for extensive inves-\ntigations [3]. However, the volume and variety of these data\npose a significant challenge during Timeline Analysis (TA),\ncalling for a rapid automated solution [4]. Unfortunately, few\ntools have the ability to accurately, promptly, and effectively\ndo the job.\nDriven by this demand, the integration of Artificial Intelli-\ngence (AI) into the DF process, and specifically into TA, has\nbecome non-negotiable and represents a significant advance-\nment in the field, offering new tools and methodologies for\ninvestigation and analysis [5] [6] [7].\nThe AI taxonomy is vast and diverse. Each branch is\ndedicated to and useful for specific tasks. However, for greater\nprecision in the DFIR field and within the scope of this\nresearch, Generative AI (GenAI) Large Language Models\n(LLMs) and Rule-Based AI (R-BAI) algorithms are considered\noptimal choices due to their characteristics and functionalities.\nLLMs have abilities that extend beyond mimicking human\ncreativity. They play a transformative role across various do-\nmains, enhancing productivity and automating complex tasks\nthat traditionally required human ingenuity [8] .\nWorthy of special mention are Multimodal LLMs, which are\ncapable of processing diverse data types, such as images, audio\nfiles, and documents [9]. Both multimodal and signle-modal\nLLMs can be applied to tasks like sentiment analysis, predic-\ntive text generation, pattern recognition, and natural language\nunderstanding and generation. While LLMs excel in semantic\nunderstanding, they lack true memory and genuine compre-\nhension [10]. To mitigate some limitations, techniques like\nRetrieval-Augmented Generation (RAG) are often employed\nto enhance context and performance by indexing external\nknowledge [11].\nOn the other hand, R-BAI algorithms are straightforward\nand built with simple if-then statements, making them suitable\nfor setting rules [12]. Given the large volume of data generated\nduring DF data acquisition, R-BAI algorithms are adequate\nfor filtering and reducing the amount of data to process. By\nimplementing predefined rules set by field professionals, we\ncan focus on collecting only relevant digital artefacts and data\nresulting in more manageable forms.\nOverall, combining two AI technologies and techniques to\nimplement them for TF analysis offers promising opportunities\nto enhance the efficiency, accuracy, depth and speed of digital\ninvestigations. However, it's crucial to ensure responsible"}, {"title": "A. Contribution and Novelty", "content": "This research introduces an innovative approach to the DFIR\nprocess by integrating R-BAI and LLMs directly for TA. The\naim is to bridge the gap between theoretical approaches and\npractical applications.\nOur main contributions are:\nUtilising R-BAI to filter and minimise the volume of\ncollected data.\nEmploying pre-trained LLMs with a RAG agent for\ncontext-based query handling and question answering; it's\nimportant to note that RAG agents with LLMs are an\nexisting technical solution. Our novelty lies in tailoring\nthis solution to advance TA.\nDirect the LLM to perform automated TA, correlate\nevents, and generate a narrative forensic TA report to\nprovide insights into the incident, including additional\ninformation and details such as mitigation solutions.\nThis practical approach can be adopted and further developed\nby forensic professionals, facilitating quicker and more ac-\ncurate responses to cyber incidents. Moreover, its potential\nimpact extends beyond academia, with the capacity to influ-\nence digital security practices and benefit various stakeholders,\nincluding law enforcement agencies, cybersecurity firms, and\nother organisations involved in DFIR. Ultimately, it aims to\ncontribute to a more secure digital sector."}, {"title": "B. Research Question", "content": "This paper introduces the use of two AI solutions to advance\nTA. Our study is based on answering the following main\nquestion:\nHow can we build a system that is both performant and\nrelevant, where R-BAI and LLM are integrated to work\ntogether?\nHowever, sub-questions can stem from this main question:\nFor what will R-BAI be useful, and what are its limita-\ntions?\nHow will LLMs collaborate with R-BAI?\nWhat are the limitations of LLMs, and how can they be\naddressed?\nHow can we effectively evaluate GenDFIR?\nThe paper is structured to answer the previous questions as\nfollows: The first Section I is an introduction to the field\nof DFIR to understand its key details found in Section II\nand gain insights about it. Subsequently in Section III, we\ndelve into related works and literature review to strengthen\nour foundation and gather more ideas. Section IV, we present\nhow we built the framework, including its main algorithms.\nWe then in Section V experiment with our system on some\nsynthetic scenarios to observe its effectiveness. Afterwards, in\nSection VII we evaluate to what extent our system is reliable,\nworkable and effective, and examine the limitations of this\nresearch. Finally, in Section VIII we conclude the paper with\nsome suggestions for refinement and future work that can be\nundertaken."}, {"title": "II. BACKGROUND", "content": "TA within DFIR, and Rule-Based (R-B) and LLMs within\nAI, represent two distinct areas of research. It is essential\nto remember that this approach aims to automate a task, or\nprocess using AI. Therefore, understanding and defining key\nconcepts is crucial. Below are definitions aligned with the\nscope of this research:\nDigital Artefact: There is no formal and precise definition\nof this term in the literature [2]. However, within the field of\nDF, artefacts are refered to as the processed and relevant data\nretrieved from digital devices. For example, in OS forensics,\nthese artefacts includes File System, OS Executables, Network\nActivity, Internet History and Cache, etc.\nDigital Data: Data is a raw and unprocessed fact that could\npotentially become information after processing, analysis, and\nexamination. For instance, raw text files, log entries, network\npacket captures, etc., can be analysed and processed to trans-\nform into information that serves as evidence [14].\nChronological or Temporal Digital Artefact: Are sec-\nondary artefacts derived from primary artefacts (source). For\ninstance, a log file is a primary artefact that contains timeline\ndata (date, time, sequential order, etc) which are considered\ntemporal artefacts. In DF, these temporal artefacts, once pro-\ncessed and analysed, provide valuable information for recon-\nstructing and correlating events [14].\nTimeline Analysis: LLMs can reconstruct a timeline of\nevents. By identifying temporal patterns and correlations\nwithin the data. They can automatically generate a detailed\ntimeline that chronicles the sequence of actions performed on\nthe device.\nAnomaly Detection: R-BAI algorithms can be effectively\nemployed for anomaly detection in DF and cybersecurity\ncontexts. These algorithms operate on a set of predefined rules\nthat are manually designed by domain experts. By comparing\nobserved behavior against expected norms or baselines estab-\nlished through these rules, R-BAI can flag unusual events or\ndeviations [15]. This capability allows for the identification\nof potential unauthorised access, data tampering, or other\nmalicious activities.\nLarge Language Models (LLMs): Powered by Natural\nLanguage Processing (NLP), are computational models of\nGenAI that possess the ability to understand and generate\nhuman language. They have the capability to predict the\nprobability of word sequences or produce new text based on\nprovided inputs. LLMs are distinguished by their vast training\ndatasets and sophisticated architectures [8].\nMultimodal Data Fusion: With Multimodal LLMs\n(MLLMs) that are capable of processing diverse data types,\nincluding text, images, and audio [9]. We can integrate various\ndigital artefacts into the investigation process, contextually\nenriching the representation of events to help reconstruct a\ncomprehensive timeline.\nNatural Language Processing (NLP): An Al-powered\ntechnique that can analyse textual data extracted from digital"}, {"title": "A. Timeline Analysis", "content": "TA process is both thorough and sensitive in DFIR. Un-\nfortunately, due to this complexity, there is limited detailed\nresearch, in-depth work, analysis, and interest in this field.\nDuring a cyber incident, massive amounts of data are\ngenerated. Some of them can be considered potential evidence\nat an early stage of the DF collection phase. However, to\ndetermine if the collected artefacts will be considered evi-\ndence, support the investigation, maintain the chain of custody,\nand be admissible in court, they need to undergo meticulous\nexamination and analysis. This is where FT analysis plays a\ncrucial role in enhancing evidence identification and detection\nrelated to the incident.\nTA is also resource-intensive, consuming time, money, and\nrequiring expertise. Many DF analysts, in an effort to speed\nup the process, rely on existing tools namely Exterro Forensic\nToolkit (FTK) [18], Autopsy [19], EnCase [20], and Magnet\nAXIOM [21]. Whilst these tools are robust for analysis, they\noften struggle with timeline reconstruction and event corre-\nlation. These tools typically offer analysis on an artefact-by-\nartefact basis, meaning they do not consider all artefacts and\ndata simultaneously and do not fully automate the process. As\na result, numerous researchers have developed and established\nmore automated tools and frameworks to advance this process."}, {"title": "B. Large Language Models for Cybersecurity and Digital Forensics tasks", "content": "LLMs, which are GenAI models, have been a leading trend\nin recent years. In the early stages, the emergence of language\nmodels like ChatGPT [34], Claude [35], and Llama [36],\npowered by LLMs such as LLaMA [37] by Meta [38], the GPT\n[39] family by OpenAI [40], and Claude by Anthropic [41],\namong others, were initially used primarily for conversation\nand generating text due to their strong NLP capabilities.\nHowever, recent technological advancements have introduced\nmultimodality capabilities, enabling LLM-powered solutions\nto process diverse modalities including text, audio, images,"}, {"title": "C. The use of Retrieval-Augmented Generation", "content": "Understanding RAG, how it works, and the process of its\nintegration can be somewhat confusing and complex. This\ncomplexity largely depends on the scope and objectives of\nits application. In our approach, we narrow its use down to\nthe contexts of TA, DF, and IR.\nRAG primarily aim to optimise and enhance the perfor-\nmance of LLMs. They utilise an external knowledge base be-\nyond the LLM's pre-existing knowledge and training datasets\nto provide additional information during inference. This pro-\ncess is not exactly like fine-tuning or training an LLM but\nrather involves dynamically retrieving, generating, and inte-\ngrating relevant external textual information from databases\n(external storage), local files (as a vault file), or through cloud\npipelines [43]. It is crucial to acknowledge that while an LLM\nalone is very powerful, its knowledge may not encompass\nspecific contexts [11]. For instance, organisations may possess\nsensitive and confidential data, as well as their contextual\ninterpretations of rules, concepts, or topic-related information,\nwhich they wish to keep private [15]. Data for training LLMs\nare typically gathered from various sources such as cookies,\nthird-party datasets, publicly available online content, and\nother means. An LLM cannot access or recognise information\nthat was not included in its training data. This is where\nRAG is particularly useful as it addresses these limitations by\nintegrating relevant external information. Due to privacy and\nsecurity concerns, this process is generally conducted within\nsecure, context-specific, and private task environments.\nTo maintain good cybersecurity practices in TA, it is essen-\ntial to consider the level of risk, privacy, and confidentiality of\ndata, as well as compliance with rules, guidelines, and policies\nduring data and digital artefacts collection phase [15].\nAdditionally, a RAG agent, which is an essential component\nin certain Al systems powered by an LLM [44], serves as\nan intermediary between the LLM and the user. The agent\nis responsible for conducting the search when a user sends a\nquery or input, retrieving all context-based information, and\nproviding it to the LLM, which then generates a context-based\nanswer for the user. Complementing with this, RAG agents\nhave the capability of refining and modifying prompts crafted\nby the human. During inference, the RAG agent receives the\ninput, processes it, and modifies it according to the role it is\ntasked with and designed to do [45]. A core aspect to consider\nis that the role of a RAG agent is assigned by a human.\nFor instance, in an LLM-powered system with a RAG agent, the agent can take on the role of a cybersecurity\nassistant. In TA, the agent could be a \"Digital Forensics\nand Cybersecurity AI Analyst tasked with performing timeline\nanalysis, correlating events, and reconstructing timelines\"."}, {"title": "IV. GENDFIR METHODOLOGY", "content": "This section details the methodology and approach used to\nbuild the GenDFIR framework, including algorithms alongside\ntheir interpretation:\nLLM Model: Llama-3.1 [36], a powerful model by\nMeta [38], evaluated on over 150 standard benchmarks\nand human evaluations. The rationale behind selecting"}, {"title": "A. Forensics Data Pre-processing", "content": "1) Data Collection: First step where data and digital artefacts\nare collected using forensic tools. All data and artefacts will\nbe stored in datasets or normal files (e.g., txt format) whilst\npreserving their integrity.\n2) Multi-modal Processing: As this research aims to make\nRAG work with multi-modal concepts and interpret figures,\ntables, and other illustrations in documents, we have chosen\nan alternative technique:\nWe employ LlaVa as MLLM.\nLLaVA answers forensic questions and queries about im-\nages related to the incident, and provides textual output.\nIn this research, as a proof of concept and for novelty purposes,\nwe focus solely on multimodal processing of images and texts.\n3) Single Modality Preprocessing: Due to the NLP back-\nground of our main LLM model, we extract all relevant\ntextual data from digital artefacts and store them in a textual\ndocument.\n4) Modality Fusion: We merge the textual outputs generated\nby the MLLM with those extracted from single-modality doc-\numents to create an initial forensic report containing incident\nevents. Algorithm 1 summarises the process.\n5) Manual Verification: Manually verify and, if needed,\nrestructure the data within the document. This ensures that:\nData is relevant and structured in an understandable way.\nDocument is prepared for easier processing in the follow-\ning steps."}, {"title": "Algorithm 1 Images Forensic Processing", "content": "Require: Images images\nEnsure: Contexts and Metadata stored in a textual file File\n1: function PROCESSIMAGE()\n2:\tfor image img in images do\n3:\t\tMLLM = load(model='llava-llama3', messages=[{\n4:\t\t\trole: user\n5:\t\t\tcontent: \"Conduct a forensic analysis of the image\nand summarise the results in one sentence.\"\n6:\t\t\timage: img[i]\n7:\t\t}])\n8:\t\tcontext = MLLM [message] [content]\n9:\t\tmetadata = metaminer(img[i])\n10:\t\tFile.append(Context: + context + Metadata: +\nmetadata)\n11:\tend for\n12:\treturn File\n13: end function"}, {"title": "B. Rule-Based AI for Anomaly Detection", "content": "Algorithm 2 Rule-Based Al\nRequire: Dataset of events to select DataSet, and a Set of\nPredefine Rules rules\nEnsure: All infected events (with anomalies) are selected and\nput in one document D\n1: function ANOMALYDETECTION()\n2:\tFile = Convert DataSetT oFile(DataSet)\n3:\tD[]\n4:\tanomalies [ ]\n5:\tanomaly == False\n6:\trules = [ \"type\": \"Set\", \"field\": \"Set\", \"value\": \"Set\",\n\"type\": \"Set\", \"field\": \"Set\", \"value\": \"Set\", ]\n7:\tfor event in file do\n8:\t\tfor rule in rules do\n9:\t\t\tif rule[attribute] == event[attribute] then\n10:\t\t\t\tanomaly == True\n11:\t\t\t\tanomalies.append(event)\n12:\t\t\tend if\n13:\t\tend for\n14:\tend for\n15:\tfor anomaly in anomalies do\n16:\t\tD.append(anomaly)\n17:\tend for\n18:\treturn D\n19: end function"}, {"title": "C. Data Chunking", "content": "Chunking is the process of segmenting large texts into\nsmaller, manageable parts. When using RAG in conjunction\nwith LLMs, chunking is crucial for effective information\nretrieval from an external knowledge base. The precision and\neffectiveness of this process largely depend on the chosen\nsegmentation method [50].\nSeveral approaches have proven reliable for chunking:\nToken-Based: Divides text based on a fixed number of\ntokens.\nParagraph-Based Chunking: Segments text by para-\ngraphs to maintain context.\nSemantic: Groups text based on meaning or topics.\nSentence-Based: Segments text into sentences, where\neach sentence may have a unique semantic.\nFor our framework and within the scope of DFIR, we em-\nploy multiple approaches to attain high precision and accuracy:\nWe structure the text by splitting it into sentences.\nSentences are dynamically grouped into chunks without\nexceeding the maximum allowed chunk length.\nEach sentence represents a unique event or meaning.\nWe define the \"Maximum Length of a Chunk\" as the\nmaximum number of characters, words, or tokens allowed\nper chunk.\nAn approximate calculation of chunks can be presented as\nfollows:\n$CTM \\approx 512 TM \\times 4 C \\approx 2000$ (1)\nAssuming that each English word is approximately 4 to 6\ncharacters C long. By taking 4 C characters as an average\nfor each word, and considering the model maximum tokens\nTM (512), the maximum number of characters the model\ncan accurately embed per chunk is about 2000 characters\nCT M (1). Additionally, in the context of TA, since it requires\nthe embedding of every single character for more precise\nsemantic, we adopt the following chunking method:\nEach sentence is treated as a chunk, with a maximum\ndefined length of characters M. A sentence represents\nan event and includes all its attributes, such as Event\nID, Description, Level, Time, Date, etc. The maximum"}, {"title": "D. Data Embedding", "content": "The purpose of processing text in chunks is to embed it\nusing the mxbai-embed-large embedding model.\nThe embedding operation is as follow:\nTokenisation: Words within a chunk of PT are first\ntokenised. Meaning each word or character, is converted\ninto a token (unit).\nMapping to Numerical Representations: These tokens\nare then mapped to numerical representations.\nFurther Processing: Additional layer transformations\nand processing are then applied to the previous vectors.\nThis allows capturing the semantic of the tokens.\nOutput: A dense vector ED consisting of a list of\nnumbers, where each number represents a feature of the\nchunked text PT."}, {"title": "Algorithm 3 Embed Preprocessed Text", "content": "Require: Preprocessed Text PT Embedding Model EmbedModel\nEnsure: Embed Preprocessed Text ED\n1: function EMBED( PT, EmbedModel)\n2:\tLoad Preprocessed Text PT\n3:\tEmbedModel = 'mxbai-embed-large'\n4:\tfor content in PT do\n5:\t\tED = embeddings (EmbedModel, content)\n6:\tend for\n7:\treturn ED\n8: end function"}, {"title": "E. Retrieval Augmented Generation (RAG) Agent", "content": "This phase operates in two subphases, Retrieval and Genera-\ntion:\nOur DFIR RAG agent is powered by the Llama-3.1 LLM,\nidentified with a prompt that specifies its task, role, and\ncontent.\nGeneration: In Algorithm 4, refining the query UI, or mod-\nifying it into a more context-based RI, is done by the Agent\naccording to the crafted prompt AgentProm pt. The generation\nprocess in GenDFIR occurs twice. First, in this Algorithm\n4, before the retrieval process, the Agent (or the DFIR AI\nassistant) takes the UI and modifies it to generate a new\ncontextualised query RI. The second generation, which is a\ntypical augmented generation, occurs in Algorithm 6.\nRetrieval: Algorithm 5, the retrieval process works with\nvectors only. It considers ED and the vectorised initial input\nV RI. The cosine similarity (3) between E D and UI is then\ncalculated as follows:\n$cosine\\_similarity(q, t) = \\frac{q.t}{\\parallel q \\parallel \\parallel t \\parallel}$ (3)\n$\\theta = arccos \\frac{q.t}{\\parallel q \\parallel \\parallel t \\parallel}$ (4)\n$\\\\ q.t = \\sum_{i=1}^{n} q_i t_i$ (5)\n$\\parallel q \\parallel = \\sqrt{\\sum_{i=1}^{n} q_i^2}$ (6)\n$\\parallel t \\parallel = \\sqrt{\\sum_{i=1}^{n} t_i^2}$ (7)\nqi is the i-th component of vector q.\nti is the i-th component of vector t.\nq is the new query vector V RI, and t is the ED vector. Within\nan axis of x and y, q and t are represented as in Figure 6.\nThe agent will be looking for a high rate of similarities\n(Similarit yScores) within ED for the VRI. The higher\nthe score, the more concise and accurate the answers we\nget. Due to the possibility of having many relevant pieces\nof information, we select only the top to pk (value to be\ndefined manually) and take the most accurate by calculating\nthe minimum distance between topk set and the length of\nSimilarit yScor es. I is the final retrieved textual information.\nRegarding topk information in TA, the following aspects\nare taken into account:"}, {"title": "Algorithm 5 Information Retrieval", "content": "Require: RAG Agent Rewritten Input (Query) RI, Prepro-\ncessed Text PT, Top K contexts topk, Preprocessed Text\nPT and Embedded Data ED and Embedding Model\nEmbedModel\nEnsure: Retrieve Relevant Information |\n1: function RETRIEVE( RI, PT, ED, topk)\n2:\tLoad Embedded Data Vector ED\n3:\tLoad Embedding Model EmbedModel\n4:\tEmbedModel='mxbai-embed-large'\n5:\tV RI=embedding(EmbedModel, Agent prom pt=RI)\n6:\tSimilarityScores = cosine_similarity(VRI, ED)\n7:\ttopk = min(topk, Len(Similarit yScores))\n8:\tTopIndices = getT o pK Indice(Similarit yScores,\nto pk)\n9:\tfor indice in TopIndices do\n10:\t\t1.append(PT[indice])\n11:\tend for\n12:\treturn I\n13: end function"}, {"title": "F. LLMs for an efficient Timeline Analysis (TA)", "content": "Algorithm 6 GenDFIR\nRequire: User Query or Input for the main UI\nEnsure: LLM accurate answer and relevant to the context\n(Timeline Analysis, Event timeline reconstruction and\ncorrelation) answer\n1: Load Text T\n2: Set a message for the Al agent to stay on context SysMsg\n3: Load LLM Model Llama-3.1 llama \u2013 3.1\n4: Load LLM Embedding Model 'mxbai-embed-large'\n5: SysM sg = \"You are an expert Cybersecurity and Digital\nForensics assistant, specialising in timeline analysis. You\nperform timeline analysis by analysing digital artefacts\nand temporal artefacts, reconstructing timelines, and cor-\nrelating events\"\n6: EmbedModel = 'mxbai-embed-large'\n7: LLM Model = llama - 3.1\n8: PT[] = Process (T, Max)\n9: ED[ ]=Embed(PT, EmbedModel)\n10: I[ ] = Retrieve(RI, PT, topk, ED)\n11: load(llama \u2013 3.1)\n12: UI = input(\"Welcome to GenDFIR, your advanced AI-\npowered Timeline Analysis assistant. How can I assist you\ntoday?\")\n13: answer =\nLLMChat(UI, SysMsg, ED, PT, I,\nLLM Model)\n14: print(answer)\nIn Algorithm 6, after successfully generating a new query\nRI and retrieving the context-based information I, the agent\nsends this information to the LLM. GenDFIR functions as\nillustrated in the following Figure 9:\nA document (External Knowledge Base K) containing\nall filtered anomalous events A related to the incident,\nformatted textually, is uploaded to the AI system."}, {"title": "V. GENDFIR IMPLEMENTATION AND TESTING", "content": "To provide a valid proof of concept, we conducted a prelimi-\nnary experiment on different scenarios while incorporating the\nconcept of multimodality. However, due to the large volume\nof data involved, the broad scope of DFIR covered by the\nresearch, and the novelty of our approach, we limited the\nexperiment to the following minimal trials and settings to\nensure accurate results at this initial stage:\nWe deployed Llama3.1-8B as a single-modal large lan-\nguage model (LLM) and Llava-Llama3 as a multimodal\nLLM (MLLM), along with the embedding model mxbai-\nembed-large:335m, all locally.\nWe stored our knowledge base locally in vault files for\nease of access and management.\nTo guarantee a high level of precision, we limited our\nknowledge base to 200 characters per chunk, with a\nmaximum of 900 characters, representing approximately\n40 to 200 tokens per chunk, depending on the incident\ndescription."}, {"title": "VI. EVALUATION AND DISCUSSION", "content": "GenDFIR evaluation considers only the outputs from the\nLLM and RAG modules. The R-BAI algorithms produced\n100% accurate results, with all data correctly preprocessed\nand filtered, making additional evaluation or validation un-\nnecessary.\nTo further validate the framework, specifically the LLM\nand RAG modules, we assessed their performance, relevance,\naccuracy, and reliability using several context-specific metrics.\nThese metrics were developed explicitly for GenDFIR and\ninvolved generating 120 context-based forensic prompts (in the\nform of questions) that were refined and validated with human\nassistance. These prompts evaluate and test crucial aspects\nof our framework, including sentiment analysis, predictions,\nintentions, and retrieval precision. However, all outputs are\nthe results of LLMs in a zero-shot setting."}, {"title": "A. Accuracy", "content": "To calculate accuracy, we evaluated the correctness of the\ngenerated forensic reports for the three scenarios as follows:\nScenario 1: The graph in Figure 10 shows the number of\nfacts generated in the TA output report. This report consists\nof two parts. The first part covers Artefact Analysis, Timeline\nAnalysis, Event Correlation, and Timeline Reconstruction of\nevents, all based on facts from our knowledge base. The\nsecond part includes additional knowledge, such as mitigation\nsolutions, generated by the LLM. Our analysis found that the\nreport contained only one fact that was incorrectly retrieved\nfrom the knowledge base."}, {"title": "B. Exact Match (EM)", "content": "For this metric, we dedicated 20 out of the 120 prompts to\neach scenario. These prompts include tasks such as retrieving\nprecise timestamps (e.g., What was the exact time when\nMichael Davis responded to the first email from the Global-\nBank Security Team?), obtaining exact descriptions (e.g., For\nEvent 5, what was the description of the alligator?), and other\nrelevant questions.\nTable IX illustrates the checks and success of the results\nthat perfectly align with the ground truth answers. Table VIII\npresents the total EM rate:"}, {"title": "C. Relevance", "content": "Of the total 120 prompts, 20 are dedicated to the relevance\nmetric in each scenario and are characterised by their focus\non various aspects, including sentiment (e.g., What is the\noverall sentiment of the image described in Event 2 (Image\nb)?), intention (e.g., What specific action is requested by\nGlobalBank in the initial email?), deep analysis (e.g., Analyze\nthe severity levels associated with the events involving SYN\nflood attacks. List the events and their corresponding severity\nlevels.), as well as retrieval, prediction, and insights. The\ngraph in Figure 13 clearly shows that in Scenario 1, GenDFIR"}, {"title": "D. Time", "content": "A major challenge in TA of an incident's events is the time\nrequired to accurately analyse and examine each artefact. In\nour experiment, we compared the time taken by a Human\nCertified DFIR Expert to that taken by the GenDFIR frame-\nwork. Table XI presents the results for each scenario. The time\nrecorded for GenDFIR includes the overall time for generating\nthe TA report along with additional details, whereas the time\nrecorded for the Human Certified DFIR Expert is specific to\nthe examination of artefacts:"}, {"title": "E. Discussion", "content": "As previously mentioned in V", "GenDFIR\". The evaluation\nresults have indicated a high success rate, ranging from 90%\nto 100%, depending on the metrics applied. Nevertheless,\nwe believe these findings are pertinent and relevant only to\nsimplified scenarios with minimal configurations and settings.\nIn real-world situations, forensic reports generally focus on\ncore findings such as the incident description, evidence analy-\nsis, and the timeline of events. In our experiment, we tailored\nour prompts to generate additional details, including mitigation\nsolutions, as shown in the Appendix Section A. Additionally,\nGenDFIR output reports were automatically condensed due to\nthe token limit of the single-modal LLM.\nRegarding TA timing results, the time taken by GenDFIR\nto produce the outputs can be minimised, as the results are\nprimarily influenced by hardware settings. Be that as it may,\nwe assume that in a highly optimised environment with ideal\nconditions, the results would improve positively.\nWhen combining LLMs with RAG and an external knowl-\nedge base, the common aim is to enrich the LLM's outputs\nwith supplementary information from the knowledge base. In\nour approach, we eradicated this by crafting the agent prompt\nas follows": "n\"AgentPrompt: You are a Cybersecurity and Digital Foren-\nsics and Incident Response (DFIR) expert. Identify events\nand information related to the cyber incident", "process": "RAG\nagent was tasked to retrieve facts and events attributes, while\nthe LLM was employed to generate additional information\nrelevant to the incident. The graphs in Figures 10, 11, and\n12, along with the outputs found in"}]}