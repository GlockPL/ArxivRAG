{"title": "UNSUPERVISED POINT CLOUD COMPLETION THROUGH\nUNBALANCED OPTIMAL TRANSPORT", "authors": ["Taekyung Lee", "Jaemoo Choi", "Jaewoong Choi"], "abstract": "Unpaired point cloud completion explores methods for learning a completion map\nfrom unpaired incomplete and complete point cloud data. In this paper, we propose\na novel approach for unpaired point cloud completion using the unbalanced optimal\ntransport map, called Unbalanced Optimal Transport Map for Unpaired Point\nCloud Completion (UOT-UPC). We demonstrate that the unpaired point cloud\ncompletion can be naturally interpreted as the Optimal Transport (OT) problem and\nintroduce the Unbalanced Optimal Transport (UOT) approach to address the class\nimbalance problem, which is prevalent in unpaired point cloud completion datasets.\nMoreover, we analyze the appropriate cost function for unpaired completion tasks.\nThis analysis shows that the InfoCD cost function is particularly well-suited for\nthis task. Our model is the first attempt to leverage UOT for unpaired point cloud\ncompletion, achieving competitive or superior results on both single-category and\nmulti-category datasets. In particular, our model is especially effective in scenarios\nwith class imbalance, where the proportions of categories are different between the\nincomplete and complete point cloud datasets.", "sections": [{"title": "1 INTRODUCTION", "content": "The three-dimensional (3D) point cloud is a fundamental representation of 3D geometry processing\n(Guo et al., 2020). However, obtaining complete point cloud data is challenging because of the\nlimitations of the scanning process (Yuan et al., 2018). In this respect, many methods have been\nproposed for point cloud completion, which aims to recover a complete point cloud from incomplete\n(partial) data (Yu et al., 2021; Wang et al., 2022; Tchapmi et al., 2019; Ma et al., 2023; Chen et al.,\n2020; Wen et al., 2021). These previous approaches can be categorized into paired (supervised) and\nunpaired (unsupervised) methods. In the paired approach, the completion model is trained using\npaired data, which consists of incomplete point clouds and their corresponding completions (Yu et al.,\n2021; Wang et al., 2022; Tchapmi et al., 2019). However, acquiring this paired training data is often\ndifficult in practice. Therefore, the unpaired point cloud completion aims to train a completion model\nfrom the independently sampled incomplete and complete point clouds, leveraging shared semantic\ninformation, such as object class (Ma et al., 2023; Chen et al., 2020; Wen et al., 2021). In this regard,\nthe unpaired point cloud completion is a challenging task of significant practical importance.\nOptimal Transport problem (OT) problem (Villani et al., 2009; Peyr\u00e9 et al., 2017) investigates the\ncost-minimizing transport map that bridges two probability distributions. Since the introduction of\nWGAN (Arjovsky et al., 2017), the OT-based Wasserstein distance has been widely adopted as a loss\nfunction in various machine learning tasks, including unpaired point cloud completion (Chen et al.,\n2020; Wu et al., 2020). Recently, several works introduced alternative approaches based on OT (Rout\net al., 2022; Fan et al., 2022). Instead of estimating the Wasserstein distance, these works focus on\nlearning the optimal transport map (OT Map) from the source distribution to the target distribution\nusing neural networks. Intuitively, the optimal transport map T serves as a generator of the target"}, {"title": "2 BACKGROUND", "content": "Optimal Transport The Optimal Transport (OT) problem investigates the task of transporting\nthe source distribution \u03bc \u2208 P(X) to the target distribution v \u2208 P(Y). This problem was initially\nformulated by Monge (1781) using a deterministic transport map T : X \u2192 Y such that T#\u00b5 = \u03bd:\n$\\Cot (\\mu,\\nu) := \\inf_{\\substack{T : \\mathcal{X} \\rightarrow \\mathcal{Y} \\\\ T_{\\sharp} \\mu = \\nu}} \\int_{\\mathcal{X}} c(x,T(x))d\\mu(x)$.\nIntuitively, Monge's OT problem explores the optimal transport map T* that connects two distribu-\ntions while minimizing the given cost function c(x, T(x)). Although Monge's OT problem offers\nan intuitive understanding, it has theoretical limitations: this formulation is non-convex and the\noptimal transport map T* may not exist depending on the conditions on \u00b5 and v (Villani et al.,\n2009). To overcome these issues, Kantorovich introduced a relaxed formulation of the OT problem\n(Kantorovich, 1948). Formally, this Kantorovich formulation is expressed in terms of a coupling \u03c0\nrather than a transport map T, as follows:\n$\\Cot(\\mu,\\nu) := \\inf_{\\pi \\in \\Pi(\\mu,\\nu)} \\left[\\int_{\\mathcal{X} \\times \\mathcal{Y}} c(x,y)d\\pi(x,y)\\right]$\nwhere c is a cost function and \u03c0\u2208 \u03a0(\u03bc,\u03bd) is a coupling of \u03bc and v. In contrast to the Monge\nproblem, the minimizer \u03c0* of Eq 2 always exists under some mild assumptions on (\u03a7, \u03bc), (V, v) and\nthe cost function c (Villani et al., 2009). Note that under our assumptions that \u00b5 and v are absolutely", "latex": ["\\Cot (\\mu,\\nu) := \\inf_{\\substack{T : \\mathcal{X} \\rightarrow \\mathcal{Y} \\\\ T_{\\sharp} \\mu = \\nu}} \\int_{\\mathcal{X}} c(x,T(x))d\\mu(x)", "\\Cot(\\mu,\\nu) := \\inf_{\\pi \\in \\Pi(\\mu,\\nu)} \\left[\\int_{\\mathcal{X} \\times \\mathcal{Y}} c(x,y)d\\pi(x,y)\\right]"]}, {"title": "3 UNPAIRED POINT COMPLETION THROUGH UNBALANCED OPTIMAL\nTRANSPORT MAP", "content": "In this paper, our key idea is to train our model to learn the unbalanced optimal transport map\nfrom the incomplete point cloud distribution \u03bc to the complete point cloud distribution v. In Sec\n3.1, we demonstrate that this optimal transport approach is appropriate for the unpaired point cloud\ncompletion task. In particular, we investigate the most appropriate cost function for this application.\nIn Sec 3.2, we present our max-min learning objective. In Sec 3.3, we provide implementation details,\nsuch as neural network parametrization and training algorithm.", "latex": []}, {"title": "3.1 MOTIVATION", "content": "Task Formulation as Optimal Transport Map We begin by formulating our target task: Unpaired\npoint cloud completion. Assume that we are given two sets of point cloud data: the incomplete point\ncloud X = {xi | Xi \u2208 X, i = 1,\u2026\u2026,N} and the complete point cloud Y = {yj | Yj \u2208 V,j =\n1,..., M}. Note that X and Y are not paired, i.e., X and Y are independently sampled from the\nincomplete point cloud distribution \u00b5 and the complete point cloud distribution v, respectively. In", "latex": []}, {"title": "5.3 ABLATION STUDY", "content": "Effect of Appropriate Cost Functional In this paragraph, we validate our motivation experiments\n(Table 1) for selecting InfoCD (Lin et al., 2024) as the cost functional. In the (unbalanced) optimal\ntransport map approach, the cost function c(\u00b7, \u00b7) in Eq. 8 determines how each input x is transported\nto the y = T*(x) by the optimal transport map T*. Thus, setting an appropriate cost function is\ncrucial. In this regard, as a reminder, we assessed various cost function options to determine whether\ntheir cost-minimizing pairs are suitable for the point cloud completion in Sec 3.1. Here, we conduct\nan ablation study by modifying the cost function c(\u00b7, \u00b7) in our model (Eq. 8). Each model is evaluated\non the multi-category setting and the single-category settings for the 'trash bin' and 'TV' classes.\nRobustness For the last ablation study, we evaluate the robustness of our model with respect\nto the cost-intensity hyperparameter \u03c4, defined as c(x, y) = \u03c4 \u00d7 InfoCD(x, y). Specifically, we\ntested our model on the multi-category setting and the single-category settings of the 'bookshelf' and\n'lamp' classes, while changing \u03c4\u2208 {0.02, 0.025, 0.05, 0.1, 0.25}. Note that we impose challenging\nconditions by setting the maximum \u03c4 to \u03c4max = 0.25 and the minimum \u03c4 to \u03c4min = 0.02, resulting\nin a ratio of \u03c4max/min > 10. As depicted in Fig. 3, our model shows moderate performance\nacross various \u03c4 values. In particular, the sweet spot of t lies roughly between 0.05 and 0.1. The\nperformance deteriorates by approximately 10% when \u03c4 is either too large (\u03c4max) or too small (\u03c4min).", "latex": []}, {"title": "6 CONCLUSION", "content": "In this paper, we introduce UOT-UPC, an unpaired point cloud completion model based on the UOT\nmap. To the best of our knowledge, our work is the first attempt to introduce the unbalanced optimal\ntransport map to the point cloud completion task. We formulated the unpaired point cloud completion\ntask as an (unbalanced) optimal transport problem and investigated the optimal cost function for\nthis task. Our experiments demonstrated a strong correlation between cost function selection and\nthe model's point cloud completion performance. When combined with the InfoCD cost function,\nour UOT-UPC attains competitive performance compared to both unpaired and paired point cloud\ncompletion models. Moreover, our experiments showed that UOT-UPC presents robustness to the\nclass imbalance problem, which is prevalent in the unpaired point cloud completion tasks."}, {"title": "ETHICS STATEMENT", "content": "The point cloud completion research contributes positively to various fields, including autonomous\ndriving, robotics and virtual/augmented reality. Also, it is applicable to urban planning and cultural\nheritage preservation. Our research does not involve personal data or human subjects, and we have\ncarefully addressed potential data bias issues. We also ensure that there are no risks related to illegal\nsurveillance or privacy violations. As a result, we believe that this research is conducted ethically and\nposes no social or ethical concerns."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "To ensure the reproducibility of our work, we submitted the anonymized source in the supplementary\nmaterial and included the implementation and experiment details in Appendix A."}, {"title": "A IMPLEMENTATION DETAILS", "content": "Unless otherwise stated, our implementation follows the experimental settings and hyperparameters\nof USSPA Ma et al. (2023).\nWe adopt the generator and discriminator architectures from the USSPA framework as completion\nmodel To and potential v. For the potential v4, the final sigmoid layer of the discriminator is omitted\nto allow for the parameterization of the potential function, enabling outputs to assume any real values.\nAdditionally, we remove the feature discriminator to streamline the architecture. In the potential\nUp, we implement the encoder proposed by Yuan et al. (2018) in their Point Cloud Networks (PCN).\nFollowing the encoder, we employ an MLPConv layer specified as MLPConv(Cin, [C1,..., Cn]) =\nMLPConv(1024, [256, 256, 128, 128, 1]), which indicates that the output y is computed as follows:\ny = Conv1DC4=128,C5=1(ReLU(... ReLU(Conv1DCin=1024,C1=256(x))...))\nHere, Conv1DCin, Cout represents a 1D convolutional layer with Cin input channels and Cout output\nchannels.\nThe completion model To receives as input a concatenation of the incomplete point cloud\nand a complete point cloud. These inputs are processed independently to generate distinct complete\npoint cloud samples. The completion model To follows an Encoder-Decoder architecture, augmented\nby an upsampling refinement module (upsampling module) in sequence. The upsampling module is\nimplemented using a 4-layer MLPConv network, where the final MLPConv layer is responsible for\nrefining and adding detailed structures to the output (Ma et al., 2023). Specifically, the inputs to the\nlast MLPConv layer are composed of the skeleton point cloud produced by the Encoder-Decoder\nstructure and the features extracted from the third MLPConv layer.", "latex": ["y = Conv1DC4=128,C5=1(ReLU(... ReLU(Conv1DCin=1024,C1=256(x))...))"]}, {"title": "A.2 IMPLEMENTATION DETAIL", "content": "Motivation - Optimal Cost Function The incomplete and complete point clouds utilized in the\noptimal cost function outlined in Sec 3.1 are sourced from the dataset proposed by Ma et al. (2023).\nThis dataset consists of paired incomplete and complete point clouds. For a fair comparison, we\nshuffle the complete point clouds to create an unpaired setting. We then use these shuffled point\nclouds as artificial complete data to train the USSPA model.\nTraining Concerning the loss function Lv,T. We employ Infocd as the cost function c with a\ncoordinate value of t = 0.05. For the hyperparameters of InfoCD, we set Tinfocd to 2 and InfoCD\nto 1.0 \u00d7 10-7. The functions and I are defined using the Softplus activation, SP(x) =\n2 log(1+e) - 2 log 2.2 As a regularization term, we incorporate the density loss dl proposed by Ma\net al. (2023), and we designate a coordinate value of 10.5 for dl. The objective of Potential vf is to\nassign high value to target sample y while assigning lower values to generated sample \u0177. We utilize\nthe Adam optimizer with \u03b2\u2081 = 0.95, \u03b22 = 0.999 and learning rates of 2.0 \u00d7 10\u22125, 1.0 \u00d7 10-5 for\nthe potential v and completion model T\u0259, respectively. The training is conducted with a batch size 4.\nThe maximum epoch of training is 480. We report the final results based on the epoch that yields the\nbest performance.\nAblation study - Effect of Appropriate Cost Functional We set cost function coordinate value\nT = 100 for cost function cdl2 fwd, cdl2 and 12. All other parameters and settings, unless otherwise\nspecified, are consistent with those used in our UOT-UPC model.", "latex": []}, {"title": "Evaluation Metrics", "content": "\u2022 L1-Chamfer Distance cd\u00b9\u00b9 (Fan et al., 2017)\n$\\cd^{l_1}(x_i, Y_j) = \\frac{1}{2}\\left(\\frac{1}{|X_i|}\\sum_{x_{im}}\\min_{y_n \\in Y_j} ||x_{im} - y_{jn}||_2 + \\frac{1}{|Y_j|}\\sum_{y_{jn}}\\min_{x_m \\in X_i} ||x_{im} - y_{jn}||_2\\right)$$\nwhere each of xi, Yj is point cloud\n\u2022 F score Fa Fscore (Tatarchenko et al., 2019)\n$\\Fscore = \\frac{2 \\times P(\\alpha) \\times R(\\alpha)}{P(\\alpha) + R(\\alpha)}$\nwhere $P(\\alpha) = \\frac{\\sum_{x_{im} \\in X_i} |\\{x_{im} \\in X_i |\\min_n (||x_{im} - Y_{jn}||_2) < \\alpha\\}|}{X_i}$ measures the accuracy of xi,\nand $R(\\alpha) = \\frac{\\sum_{Y_{jn} \\in Y_j} |\\{Y_{jn} \\in Y_j |\\min_m (||x_{im} - Y_{jn}||_2) < \\alpha\\}|}{Y_j}$ measures the completeness of xi.", "latex": ["\\cd^{l_1}(x_i, Y_j) = \\frac{1}{2}\\left(\\frac{1}{|X_i|}\\sum_{x_{im}}\\min_{y_n \\in Y_j} ||x_{im} - y_{jn}||_2 + \\frac{1}{|Y_j|}\\sum_{y_{jn}}\\min_{x_m \\in X_i} ||x_{im} - y_{jn}||_2\\right)", "\\Fscore = \\frac{2 \\times P(\\alpha) \\times R(\\alpha)}{P(\\alpha) + R(\\alpha)}", "P(\\alpha) = \\frac{\\sum_{x_{im} \\in X_i} |\\{x_{im} \\in X_i |\\min_n (||x_{im} - Y_{jn}||_2) < \\alpha\\}|}{X_i}", "R(\\alpha) = \\frac{\\sum_{Y_{jn} \\in Y_j} |\\{Y_{jn} \\in Y_j |\\min_m (||x_{im} - Y_{jn}||_2) < \\alpha\\}|}{Y_j}"]}, {"title": "A.3 OT-UPC", "content": "For the completion model To, we implement MLPConv(512, [128, 128, 1]) following the PCN en-\ncoder (Yuan et al., 2018). We incorporate R1 regularization (Roth et al., 2017) and R2 regularization\n(Mescheder et al., 2018) to the loss function Lv,T. Both regularization terms are assigned coordinate\nvalues r1 = r2 = 0.2. The density loss dl is excluded from the Lv,T. A gradient clipping value of 1.0\nis applied. We use Adam optimizer with \u03b2\u2081 = 0.9, \u03b22 = 0.999 and a learning rate lrt\u3002 = 5.0 \u00d7 10-5\nfor the completion model To. In addition, we use Adam optimizer with \u03b2\u2081 = 0.9, \u03b22 = 0.999 and\nlearning rate lrvo = 1.0 \u00d7 10\u22127 for the potential v\u1ee3. All other settings not explicitly mentioned\nfollow those of our model, UOT-UPC."}, {"title": "B ADDITIONAL RESULTS", "content": "B.1 ADDITIONAL VISUALIZATION OF THE THREE-NEAREST NEIGHBOR OF VARIOUS COST\nFUNCTIONS FROM SEC. 3.1"}]}