{"title": "RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models", "authors": ["Peizhuo Lv", "Mengjie Sun", "Hao Wang", "Xiaofeng Wang", "Shengzhi Zhang", "Yuxuan Chen", "Kai Chen", "Limin Sun"], "abstract": "In recent years, tremendous success has been witnessed in Retrieval-Augmented Generation (RAG), widely used to enhance Large Language Models (LLMs) in domain-specific, knowledge-intensive, and privacy-sensitive tasks. However, attackers may steal those valuable RAGs and deploy or commercialize them, making it essential to detect Intellectual Property (IP) infringement. Most existing ownership protection solutions, such as watermarks, are designed for relational databases and texts. They cannot be directly applied to RAGs because relational database watermarks require white-box access to detect IP infringement, which is unrealistic for the knowledge base in RAGs. Meanwhile, post-processing by the adversary's deployed LLMs typically destructs text watermark information. To address those problems, we propose a novel black-box \"knowledge watermark\" approach, named RAG-WM, to detect IP infringement of RAGs. RAG-WM uses a multi-LLM interaction framework, comprising a Watermark Generator, Shadow LLM & RAG, and Watermark Discriminator, to create watermark texts based on watermark entity-relationship tuples and inject them into the target RAG. We evaluate RAG-WM across three domain-specific and two privacy-sensitive tasks on four benchmark LLMs. Experimental results show that RAG-WM effectively detects the stolen RAGs in various deployed LLMs. Furthermore, RAG-WM is robust against paraphrasing, unrelated content removal, knowledge insertion, and knowledge expansion attacks. Lastly, RAG-WM can also evade watermark detection approaches, highlighting its promising application in detecting IP infringement of RAG systems.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs), such as GPT [47] and Llama [43], have gained significant attention and are applied across diverse fields, including healthcare [35, 59], content generation [73], finance [72], etc. However, they face considerable challenges, especially with tasks that are domain-specific or knowledge-intensive. They are particularly prone to generating \u201challucinations\" [70] when responding to queries outside their training data. Additionally, many users are unwilling to upload their sensitive data to third-party platforms for LLM training due to data privacy concerns. To address these problems, Retrieval-Augmented Generation (RAG), consisting of a retriever model and a knowledge base, is proposed to improve LLMs by retrieving relevant information from the knowledge bases according to semantic similarity. For example, Microsoft has incorporated RAG into its Azure OpenAI service [45], and the Llama models developed by Meta support RAG integration in certain applications [44]. Additionally, users can implement a team-specific RAG knowledge base on a preferred model (e.g., Llama) using the AnythingLLM AI application [23].\nBuilding an RAG system, particularly its knowledge bases, requires significant investment in resources such as data collection, cleaning, organization, updates, and maintenance by skilled personnel. For example, as noted in [48], CyC [36] costs about $120M; DBpedia [20] is developed at the cost of $5.1M; YAGO [64] costs $10M. Therefore, Intellectual Property (IP) protection of the RAG system is essential to protect the investment of the original RAG developers. Digital watermarking is a content-based, information-hiding technique for embedding/detecting digital information (usually related to the owner's identifier) into/from carrier data and has been demonstrated successful in relational databases [4, 30, 38], texts [31, 46, 50], DNN models [3], etc. However, those watermarking approaches cannot be directly used to protect the IP of RAG systems. On the one hand, when the owner utilizes the model watermarking approach like [3] to embed a watermark into the retriever model to protect the IP of the RAG system, attackers can easily"}, {"title": "2 Background and Related Work", "content": "2.1 Retrieval-Augmented Generation (RAG)\nNaive RAGs. Retrieval-augmented generation (RAG) enhances large language models by integrating external knowledge databases, which improves accuracy and credibility in knowledge-intensive tasks like question-answering [7, 53], medical applications [37], dialogue systems [60], etc. An RAG system comprises three components: a knowledge database, a retriever, and a large language model (LLM). The RAG process involves two main steps: relevant knowledge retrieval and answer generation.\nRelevant Knowledge Retrieval. When presented with a question Q, RAG retrieves the k text records most relevant to Q from the knowledge database KD. The retriever first encodes the question using the text encoder e to produce the embedding vector e(Q). It then applies a similarity metric sim (e.g., Cosine Similarity, Euclidean Distance) to assess the similarity between e(Q) and each text record e(ri) in KD, where ri \u2208 KD. Finally, RAG selects k text records {r1,..., rk} that are most relevant to question Q as below:\n{r1, 2, ..., rk} = top-k (sim(e(Q), e(ri))), ri \u2208 KD\nAnswer Generation. Give the question Q, the k most relevant text records {r1, ..., rk}, and an LLM LLM(), the output answer is obtained by inputting the question and texts into the LLM:\nanswer = LLM(Q, {r1,..., rk})\nThe knowledge database of RAG is accessible to users in a black-box manner. As a result, the owner can only detect IP infringement in a black-box manner. In addition, the adversary may deploy a variety of LLMs, which are unknown to the owner.\nAdvanced RAGs. However, the naive RAG techniques face some challenges in complex deployed scenarios. To solve this problem, some advanced RAG techniques are proposed to improve the performance of the RAG schedule. Self-RAG [11] trains an LLM that adaptively retrieves contexts on-demand and reflects on both retrieved contexts and their generations to improve the quality of generated answers. The core idea of these advanced RAG techniques is to enhance the relevance of retrieved texts, thereby improving the accuracy of LLM-generated answers. For example, CRAG [65] introduces a lightweight retrieval evaluator that assesses the quality of retrieved contexts and provides a confidence score to determine when knowledge retrieval actions should be triggered, thereby enhancing the robustness and accuracy of RAG. FLARE [28] predicts the upcoming sentence to anticipate future content that is then used as the query to retrieve the related documents. IRCOT [56] integrates chain-of-thought (CoT) with the retrieval process, using CoT to guide retrieval and leveraging the results to enhance CoT."}, {"title": "3.1 Threat Model", "content": "The developer or the owner of an RAG system can embed a watermark to detect IP infringement, ensuring it does not compromise its availability. If an LLM exhibits exceptional performance in a domain where the owner's RAG holds specialized knowledge, the owner may suspect it is using a stolen version of their RAG. To confirm this, the owner can query the LLM and obtain the corresponding outputs (through black-box access to the RAG) to extract the watermark from the RAG's knowledge base for IP infringement detection. An attacker might steal the RAG through an insider attack (e.g., colluding administrators) or an intrusion (e.g., malware infection) and integrate the stolen RAG with their LLM for commercial purposes. We assume that the attacker lacks both the expertise to build an RAG system independently, including the specialized knowledge in the target RAG's knowledge base, and the financial resources to do so. Otherwise, they would create their own RAG instead of stealing. However, the attacker may attempt to detect and remove watermarks from the RAG's knowledge base to avoid potential lawsuits. Following prior studies, we consider that the adversaries can apply the following techniques to attack the watermarked RAG:\nParaphrasing Attack. Paraphrasing [33, 40, 49, 68] indicates that the adversary can paraphrase the retrieved texts from RAG to perturb the watermark information to evade the verification. This technique has been applied in defending against RAG poisoning, prompt injection, jailbreaking attacks, etc. We extend it as an attack method against RAG-WM, treating it as a technique to modify the database contents without degrading system performance.\nUnrelated Content Removal. Considering that the watermark content is extra information related to the ownership verification, which may not be related to the core subject matter of the main content. The adversary can also manipulate the retrieved text by analyzing the text and removing any incoherent or unrelated sentences for watermark information removal.\nKnowledge Insertion Attack. Knowledge Insertion Attack involves the adversary inserting additional knowledge or misleading information directly into the RAG's knowledge base. This added knowledge can mislead the RAG's retrieval process against the watermark queries, leading to outputs that either obscure the watermark or introduce noise, thereby undermining the reliability of ownership verification in RAG-based systems. Such an attack is similar to the traditional database insertion attack [30].\nKnowledge Expansion Attack. The adversary can effectively dilute the presence of the watermark by increasing the volume of non-watermarked information in the retrieved texts. Specifically, RAG-WM injects at most Nwm watermark texts into a knowledge database for each watermark question. If the adversary retrieves k texts, with k > Nwm, then it is very likely that at least k - Nwm texts would be clean ones. As a result, the watermark's effectiveness may be significantly reduced.\nDetection by Perplexity. The embedding of watermark information may degrade the text quality of the RAG, thus the adversary can detect the low-quality text contents as the the suspicious watermark content. Particularly, perplexity is used to measure the text's quality, and a large perplexity of a text means it is of low quality."}, {"title": "3.2 Requirements of RAG Watermarks", "content": "An ideal RAG watermarking solution should achieve the following properties: (i) effectiveness: watermark information should be successfully retrieved and remain intact, even after being processed by LLMs deployed by adversaries. (ii) robustness: watermarks should still be detected by owners from stolen RAG systems even if the RAGs are manipulated in various ways, e.g, paraphrasing, knowledge insertion, and other attacks; (iii) security: it should be difficult for attackers to forge a new watermark for the stolen RAG; (iv) integrity: it should be highly unlikely for owners to detect IP infringement over innocent RAGs; (v) stealthiness: it should be difficult for attackers to learn the existence of watermark from the stolen RAG; and (vi) fidelity: watermark-embedding should introduce little impact on the performance of the original RAGs."}, {"title": "4 Watermarking Approach", "content": "Figure 1 illustrates the workflow of our \"knowledge watermark\" approach (RAG-WM). First, based on a well-constructed RAG system, the owner extracts entities and relations from the knowledge database, generating a list of entities and relations {E, R} as candidates for watermarking. To create the watermark entities and relations {Ewm, Rwm} (i.e., the watermark-related knowledge), we apply an HMAC function to {E, R} using the owner's signature as the secret key. For each tuple of watermark entities and their corresponding relations (ewm, rwm, e'wm) in {Ewm, Rwm}, we employ a multi-LLM interaction technique to generate watermark texts. This technique consists of three components: WM-Gen (Watermark Generator), Shadow-LLM&RAG, and WM-Disc (Watermark Discriminator). Through their interaction, we produce high-quality watermark texts embedded with the watermark knowledge (ewm, rwm, e'wm). These generated watermark texts are then integrated into the RAG system to create a watermarked version."}, {"title": "4.1 Watermark Information Generation", "content": "To inject watermarks into an RAG system, the owner can manipulate its key components: the knowledge base, retriever, and LLM. Injecting watermarks into the LLM or retriever is not ideal, as attackers can easily replace these models with clean, unwatermarked models. However, the knowledge base, which contains crucial document chunks, is the most valuable part of the RAG. An adversary cannot remove the watermark without damaging the knowledge base and rendering the system unusable. Therefore, we inject a \"knowledge watermark\" into the knowledge base.\nThe watermark knowledge is injected into the knowledge base as texts, which can be abstracted into entities and relations. That is, we first represent the watermark as a set of tuples in the form (ewm, rwm, e'wm), where e'wm and ewm are entities, and rwm denotes the relation between them. This structured form will simplify both watermark generation and IP infringement detection. Important, the watermark injection process must preserve the RAG's availability and the effectiveness of the watermarks. Moreover, since the adversary lacks expertise in the target RAG's knowledge base (as outlined in Section 3.1), we should inject watermark information that includes entities or relations originally part of the knowledge base, enhancing the watermark's stealthiness. Additionally, to verify the watermark, the injected entities and their relations must be authentic but include deliberate inaccuracies known only to the owner. These \"intentional inaccuracies\" can then be extracted from the LLM's outputs to detect IP infringement.\nEntities and Relations Extraction. We begin by extracting entities and relations from the original knowledge base KD, which will serve as candidates for constructing the watermark's entities and relations. Specifically, we employ a large language model (LLM) (e.g., LLM Graph Transformer) to parse and categorize entities and their relations from the text documents within KD. However, extracting all entities and relations from the extensive text documents in KD would be costly due to their sheer volume. Therefore, we can randomly select a subset of text documents to create the entity list E and relations list R as follows:\n{E, R} = ParseER(Sample (KD, d))\nwhere Sample(KD, d) represents a random sample of d documents from the knowledge base KD, and ParseER(.) denotes the process of parsing entities and relations from the sampled documents using the LLM. Since the raw entity list E and relations list R may include rare types of entities and relations, we reduce the lists by focusing on high-frequency entities and relationships to avoid outliers, enhancing the watermark's stealthiness. Thus, we generate the final entity list E and relations list R, with the size as E and |R|.\nWatermark Entities and Relations Generation. To construct the watermark texts, we generate a set of tuples in the format (ewm, rwm, e'wm) based on the entity list E and relations list R. For IP infringement detection, the owner's signature or identifier (ID) must be embedded within these watermark tuples. However, embedding the signature or ID directly into the entities or relations would compromise stealthiness and reduce the quality of the watermark. To address this, we use the signature as a secret key key in an HMAC (keyed cryptographic hash function) to generate the"}, {"title": "4.3 IP Infringement Detection", "content": "If a suspicious LLM demonstrates exceptional performance in a domain where the owner's RAG contains specialized knowledge, the owner may suspect the LLM is using a stolen version of RAGwm. IP infringement detection can be conducted using the WM-Disc component. Specifically, we randomly select n tuples of (em, rwm, ewm) from {Ewm, Rwm}, generate the corresponding watermark queries WQ, and execute the watermark discrimination operation (as Equation (6) and Equation (7)). This process calculates how many watermark entity pairs (i.e., ewm, e'wm) successfully retrieve their correct relation rwm, resulting in a count cwm. We can verify the watermark by Binomial Test.\nNull Hypothesis H0: The suspicious LLM is not equipped with our watermarked RAG, so the probability of outputting relation rwm is p0 (p0 = 1/nr, where nr is the total number of relations in the RAG);\nAlternative Hypothesis H1: The suspicious LLM is equipped with our watermarked RAG, and the probability of outputting relation rwm is significantly greater than p0. This is a one-tailed test, as we are interested in whether the probability of outputting relation rwm is greater than that of a random LLM (i.e., p0). The calculated p-value from the binomial test is:\nP(X = cwm) = \\binom{n}{cwm} p_0^{cwm} (1-p_0)^{n-cwm}\nwhere n represents the number of queries, and cwm represents the count of successfully retrieved watermark relations. If the p-value is significantly lower than the common significance level \u03b1 = 0.05, we reject the null hypothesis. This suggests that the probability of the suspicious model outputting relation rwm is significantly greater"}, {"title": "5 Evaluation", "content": "Based on the watermark destruction approaches discussed in Threat Model (Section 3.1), we evaluate RAG-WM in the following aspects.\n(i) Effectiveness (Section 5.2). Watermarks should be embedded into RAG and detected by the owners from the stolen RAG in a black-box manner (i.e., the owner queries the adversary's deployed LLM and RAG systems), and the watermark task should have little impact on the original task's performance of watermarked RAGs. (ii) Impact of Parameters (Section 5.3). We evaluate how the parameters of RAG and RAG-WM influence the performance of RAG-WM. (iii) Robustness (Section 5.4). The watermark should still be detected even if the encoders suffer from watermark attacks, e.g., paraphrasing, unrelated content removal, knowledge insertion, and knowledge expansion. (iv) Stealthiness (Section 5.5). The watermark should be stealthy against detection methods (e.g., detection by perplexity, and duplicate text filtering). (v) Advanced RAG Systems (Section 5.6). In addition to the naive RAG, our watermark should effectively protect the IP of the state-of-the-art advanced RAG systems, e.g., Self-RAG, CRAG."}, {"title": "5.1 Experimental Setup", "content": "Datasets & LLMs. We use five benchmark datasets commonly employed in RAG for question-answering tasks. NQ [34], HotpotQA [67], and MS-MARCO [13] are widely used datasets, and watermarks help protect the significant effort invested in their creation. TREC-COVID [58] and NFCorpus [16] are privacy-sensitive datasets, and watermarks support IP infringement detection. A detailed introduction to these datasets is provided in Appendix A. We utilize four mainstream and representative large language models, including the black-box LLMs (GPT-3.5-Turbo [17] and PaLM 2 [10]) by calling their APIs and the white-box LLMs (Llama-2-7B [55] and Vicuna-13B [18]) to evaluate the effectiveness of our RAG-WM.\nRAG Systems. We evaluate RAG systems by configuring various types of retrievers and incorporating diverse expertise into the knowledge database.\nRetriever. We deploy three commonly used retriever models, including Contriever [24], Contriever-ms [24], and ANCE [63] to generate the sentence embeddings. To measure the distance between the query and the retrieved documents, we apply three distance metrics: Euclidean distance, Inner Product, and Cosine similarity.\nKnowledge Database. We store the text content of each of the five dataset into the knowledge dataset for RAG. Specifically, we"}, {"title": "5.2 Effectiveness", "content": "In this subsection, we evaluate the effectiveness of RAG-WM in terms of watermark verification, main-task performance, integrity, time consumption, and human evaluation."}, {"title": "5.3 Impact of Parameters", "content": "The performance of our watermark approach is related to several factors, including the parameters of the RAGs (retriever models, similarity metrics, and the k value for retrieval top k related texts, as defined in equation (1)), as well as the parameters of RAG-WM (e.g., the number of injected watermark tuples, the number of watermark texts per tuple, and the watermark queries). We evaluate the impact of these factors using three datasets: REC-COVID, NFCorpus, and MS-MARCO, which differ in scale and knowledge domain. LLaMA-2-7B is used as the adversary's LLM for the RAG system. Due to space limitations, we present the results of impact of watermark queries in Appendix E."}, {"title": "5.4 Robustness", "content": "After stealing RAGs, attackers may attempt to remove the watermark. The adversary can utilize paraphrasing, removing unrelated content, inserting knowledge, and expanding knowledge attacks."}, {"title": "5.5 Stealthiness", "content": "Adversaries might use perplexity analysis or duplicate text filtering techniques to detect the watermark. We evaluate our watermark agasint them in this subsection."}, {"title": "5.6 Effectiveness in Advanced RAGS", "content": "The above experiments are evaluated against naive RAG systems. Recently, some advanced RAG techniques [11, 65] have been proposed, to solve the naive RAGs' disadvantages, e.g., retrieval challenges, generation difficulties, and augmentation hurdles. Referring to [74], we evaluate our RAG-WM in two commonly used advanced RAG systems, i.e., Self-RAG [11] and CRAG [65]. Table 7 shows that RAG-WM achieves high WSNs (average 22 WSN, well above the threshold of 2), demonstrating its ability to protect the IP of advanced RAGs. This effectiveness is due to the core idea behind these advanced RAG techniques: enhancing the relevance of retrieved texts to improve the accuracy of LLM-generated answers. Meanwhile, the crafted watermark texts are designed to be relevant to watermark queries, allowing the LLM to generate correct watermark relationships based on the retrieved watermark contexts."}, {"title": "6 Discussion", "content": "6.1 Watermark Injection Approach\nWe propose a watermark injection method based on relevant-text concatenation. Alternatively, a direct insertion approach can be considered, where the owner embeds the watermark text WT as a separate record in RAGwm. This method has the advantage of introducing minimal disruption to the structure and content of the original RAG. However, it does not fully confirm that the watermark texts can be retrieved and detected during verification. In contrast, relevant-text concatenation injects WT into the most relevant text TEXT of the RAG through pre-retrieval, improving detectability and extraction. To evaluate direct insertion, we generate the same number of watermark texts as in Section 5.2 using the multi-LLM interaction watermarking technique and directly insert them into RAGwm. The results in Table 8 indicate that the WSN and WIRR values for direct insertion are lower than those for relevant-text concatenation. This is because the pre-retrieval step in the latter improves watermark retrieval performance and increases WSN values. Notably, the performance of direct insertion is poor in large-scale knowledge bases (e.g., NQ, HotpotQA, MSMARCO), and it worsens as the size of the base increases. This is because the vast amount of text in the knowledge base introduces more noise, while direct insertion lacks retrieval guarantees, making the watermark susceptible to interference from other texts."}]}