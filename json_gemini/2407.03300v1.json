{"title": "DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents", "authors": ["Yilun Xu", "Gabriele Corso", "Tommi Jaakkola", "Arash Vahdat", "Karsten Kreis"], "abstract": "Diffusion models (DMs) have revolutionized gen-erative learning. They utilize a diffusion process to encode data into a simple Gaussian distribu-tion. However, encoding a complex, potentially multimodal data distribution into a single contin-uous Gaussian distribution arguably represents an unnecessarily challenging learning problem. We propose Discrete-Continuous Latent Variable Diffusion Models (DisCo-Diff) to simplify this task by introducing complementary discrete la-tent variables. We augment DMs with learnable discrete latents, inferred with an encoder, and train DM and encoder end-to-end. DisCo-Diff does not rely on pre-trained networks, making the framework universally applicable. The discrete latents significantly simplify learning the DM's complex noise-to-data mapping by reducing the curvature of the DM's generative ODE. An addi-tional autoregressive transformer models the dis-tribution of the discrete latents, a simple step be-cause DisCo-Diff requires only few discrete vari-ables with small codebooks. We validate DisCo-Diff on toy data, several image synthesis tasks as well as molecular docking, and find that introduc-ing discrete latents consistently improves model performance. For example, DisCo-Diff achieves state-of-the-art FID scores on class-conditioned ImageNet-64/128 datasets with ODE sampler.", "sections": [{"title": "1. Introduction", "content": "Diffusion models (DMs) (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2021) have recently led to breakthroughs for generative modeling in diverse domains. For instance, they can synthesize expressive high-resolution imagery (Saharia et al., 2022; Ramesh et al., 2022; Rombach et al., 2022; Balaji et al., 2022) or they can generate accurate molecular structures (Corso et al., 2023; Yim et al., 2023; Ingraham et al., 2023; Watson et al., 2023). DMs leverage a forward diffusion process that effectively encodes the training data in a simple, unimodal Gaussian prior distribution. Generation can be formulated either as a stochastic or, more conveniently, as a deterministic process that takes as input random noise from the Gaussian prior and transforms it into data through a generative ordinary differential equation (ODE) (Song et al., 2021). The Gaussian prior corresponds to the DM's continuous latent variables, where the data is uniquely encoded through the ODE-defined mapping.\nHowever, realistic data distributions are typically high-dimensional, complex and often multimodal. Directly encoding such data into a single unimodal Gaussian distribution and learning a corresponding reverse noise-to-data mapping is challenging. The mapping, or generative ODE, necessarily needs to be highly complex, with strong curvature, and one may consider it unnatural to map an entire data distribution to a single Gaussian distribution. In practice, conditioning information, such as class labels or text prompts, often helps to simplify the complex mapping by offering the DM's denoiser additional cues for more accurate denoising. However, such conditioning information is typically of a semantic nature and, even given a class or text prompt, the mapping remains highly complex. For instance, in the case of images, even within a class we find images with vastly different styles and color patterns, which corresponds to large distances in pixel space.\nHere, we propose Discrete-Continuous Latent Variable Diffusion Models (DisCo-Diff), DMs augmented with additional discrete latent variables that encode additional high-level information about the data and can be used by the main DM to simplify its denoising task (Fig. 1). These discrete latents are inferred through an encoder network and learnt end-to-end together with the DM. Thereby, the discrete latents directly learn to encode information that is beneficial for reducing the DM's score matching objective and making the DM's hard task of mapping simple noise to complex data easier. Indeed, in practice, we find that they significantly reduce the curvature of the DM's generative ODE and reduce the DM training loss in particular for large diffusion times, where denoising is most ambiguous and challenging. In contrast to previous work (Bao et al., 2022; Hu et al., 2023; Harvey & Wood, 2023), we do not rely on domain-specific pretrained encoder networks, making our framework general and universally applicable. To facilitate sampling of discrete latent variables during inference, we learn an autoregressive model over the discrete latents in a second step. We only use a small set of discrete latents with relatively small codebooks, which makes the additional training of the autoregressive model easy. We specifically advocate for the use of auxiliary discrete instead of continuous latents; see Sec. 3.2.\nWhile previous works (Esser et al., 2021; Ramesh et al., 2021; Chang et al., 2022; Yu et al., 2022; Pernias et al., 2023; Chang et al., 2023) use fully discrete latent variable-based approaches to model images, this typically requires large sets of spatially arranged latents with large codebooks, which makes learning their distribution challenging. DisCo-Diff, in contrast, carefully combines its discrete latents with the continuous latents (Gaussian prior) of the DM and effectively separates the modeling of discrete and continuous variations within the data. It requires only a few discrete latents.\nTo demonstrate its universality, we validate the DisCo-Diff framework on several different tasks. As a motivating example, we study 2D toy distributions, where the discrete latents learn to capture different modes with smaller curvature during sampling. We then tackle image synthesis, where the discrete latents learn large-scale appearance, often associated with global style and color patterns. Thereby, they offer complementary benefits to semantic conditioning information. Quantitatively, DisCo-Diff universally boosts output quality and achieves state-of-the-art performance on several ImageNet generation benchmarks. In addition, we experimentally validate that auxiliary discrete latents are superior to continuous latents in our setup, and study different network architectures for injecting the discrete latents into the DM network. A careful hierarchical design can encourage different discrete latents to encode different image characteristics, such as shape vs. color, reminiscent of observations from the literature on generative adversarial networks (Karras et al., 2019; 2020). We also apply DisCo-Diff to molecular docking, a critical task in drug discovery, where the discrete la-"}, {"title": "2. Background", "content": "DisCo-Diff builds on (continuous-time) DMs (Song et al., 2021), and we follow the EDM framework (Karras et al., 2022). DMs perturb the clean data $y \\sim P_{\\text{data}}(x)$ in a fixed forward process using $\\sigma^2(t)$-variance Gaussian noise, where $y \\in \\mathbb{R}^d$ and $t$ denotes the time along the diffusion process. The resulting distribution is denoted as $p(x; \\sigma(t))$ with $x \\in \\mathbb{R}^d$. For sufficiently large $\\sigma_{\\text{max}}$, this distribution is almost identical to pure random Gaussian noise. DMs leverage this observation to sample $x_0 \\sim \\mathcal{N}(x_0; 0, \\sigma_{\\text{max}} I)$ and then iteratively denoise the sample through a sequence of $M + 1$ gradually decreasing noise levels $\\sigma_{i+1} < \\sigma_{i}$ ($\\sigma_0 = \\sigma_{\\text{max}}$), where $i \\in [0, ..., M]$ and $x_i \\sim p(x; \\sigma_i)$. The $\\sigma_i$ correspond"}, {"title": "3. DisCo-Diff", "content": "In Sec. 3.1, we first formally define DisCo-Diff's generative model and training framework, before discussing and carefully motivating our approach in detail in Sec. 3.2. In Sec. 3.3, we highlight critical architecture considerations."}, {"title": "3.1. Generative Model and Training Objective", "content": "In our DisCo-Diff framework (Fig. 1), we augment a DM's learning process with an $m$-dimensional discrete latent $z \\in \\Omega^m$, where each dimension is a random variable from"}, {"title": "3.2. Motivation and Related Work", "content": "We will now critically discuss and motivate our design choices and also discuss the most relevant related works. For an extended discussion of related work see App. A.\nThe curvature of diffusion models. DMs, in their simpler ODE-based formulation ($\\beta(t) = 0$ in Eq. (1)), learn a com-"}, {"title": "5. Conclusions", "content": "We have proposed Discrete-Continuous Latent Variable Diffusion Models (DisCo-Diff), a novel and universal framework for combining discrete latent variables with continuous DMs. The approach significantly boosts performance by simplifying the DM's denoising task through the help of auxiliary discrete latent variables, while introducing negligible overhead. Extensive experiments and analyses demonstrate the unique benefits of global discrete latent variables that are learnt end-to-end with the denoiser. DisCo-Diff does not rely on any pre-trained encoder networks. As such, we validated our method not only on image synthesis, but also for molecular docking, demonstrating its universality.\nLimitations and Future Work. There are several potential future directions and limitations in both the experiments and design of DisCo-Diff. First, our experiments have been primarily focused on standard benchmarks such as ImageNet. With more compute resources, DisCo-Diff could be further validated on tasks such as text-to-image generation, where we would expect discrete latent variables to offer complementary benefits to the text conditioning, similar to how discrete latents boost performance in our class-conditional experiments. Secondly, the Group Hierarchical model relies on inductive biases in its architecture, such as the different image characteristics captured at different resolutions in the U-Net. It would be interesting to explore how such architectures could be constructed and similar hierarchical effects could be achieved when working with different data modalities (molecules, etc.). Thirdly, one could apply the idea of DisCo-Diff to other continuous flow models, such as flow-matching (Lipman et al., 2022) or rectified flow (Liu et al., 2022), to further boost their performance. Conceptually, due to the close relation between diffusion models and flow matching, we expect discrete latents to behave similarly there and improve performance. Finally, the current DisCo-Diff framework leverages a two-stage training process. Initially, we jointly train the denoiser and the encoder, followed by the post-hoc auto-regressive model in the second stage. Future work could investigate combining the two-stage training into a seamless end-to-end fashion."}]}