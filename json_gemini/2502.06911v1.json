{"title": "Foundation Models for Anomaly Detection: Vision and Challenges", "authors": ["Jing Ren", "Tao Tang", "Hong Jia", "Haytham Fayek", "Xiaodong Li", "Suyu Ma", "Xiwei Xu", "Feng Xia"], "abstract": "As data continues to grow in volume and complexity across domains such as finance, manufacturing, and healthcare, effective anomaly detection is essential for identifying irregular patterns that may signal critical issues. Recently, foundation models (FMs) have emerged as a powerful tool for advancing anomaly detection. They have demonstrated unprecedented capabilities in enhancing anomaly identification, generating detailed data descriptions, and providing visual explanations. This survey presents the first comprehensive review of recent advancements in FM-based anomaly detection. We propose a novel taxonomy that classifies FMs into three categories based on their roles in anomaly detection tasks, i.e., as encoders, detectors, or interpreters. We provide a systematic analysis of state-of-the-art methods and discuss key challenges in leveraging FMs for improved anomaly detection. We also outline future research directions in this rapidly evolving field.", "sections": [{"title": "1 Introduction", "content": "Anomaly detection, also known as outlier detection, is the process of identifying patterns or events in data that significantly deviate from expected behavior [Chandola et al., 2009]. This process is vital across various fields, including finance [Park, 2024], manufacturing [Gu et al., 2024], and healthcare [Moor et al., 2023]. Traditionally, classical methods like k-nearest neighbors and clustering algorithms have been employed for this purpose. However, recent advancements in machine learning, such as deep learning, one-class classification, self-supervised learning, and generative adversarial networks, have revolutionized this field. These modern techniques have proved extremely successful in detecting or even predicting anomalies from normal data, making them the primary approaches of anomaly analysis in a wide range of applications.\nFoundation models (FMs) are a class of large-scale, pre-trained machine learning models that are trained on massive, diverse datasets using self-supervised or unsupervised learning [Bommasani et al., 2021]. In recent years, they have shown impressive performance in learning a wide range of representations and tasks, such as translation, summarization, and question answering, with notable examples including include GPT-4 [Achiam et al., 2023], Gemini [Team et al., 2023] and CLIP [Radford et al., 2021]. Trained on extensive and diverse datasets, FMs comprise a large number of parameters that enable them to capture intricate patterns and subtle nuances within data. This ability to model such complexity makes them particularly well-suited for anomaly detection, where identifying deviations from normal behavior is essential.\nFMs offer several advantages for anomaly detection, driven by advancements in computational hardware, model architectures, and access to large-scale training data. A key advantage is their capacity for in-context learning, which enables seamless adaptation to entirely new anomaly detection tasks using only natural language instructions [Bakumenko et al., 2024]. This eliminates the need for extensive task-specific training for real-world applications, enabling a more flexible and efficient approach. Additionally, many modern FMs integrate multiple data modalities [Lu et al., 2022], such as text, images, and time-series data, which is crucial for detecting anomalies in complex scenarios involving diverse data types. For instance, multimodal models such as Gato [Reed et al., 2022], can perform tasks ranging from image captioning to robotic control, exemplifying the potential of such models as generalist agents. Furthermore, the application of FMs in anomaly detection can enhance explainability, a critical requirement in high-stakes domains such as healthcare, finance, and cybersecurity, where understanding the rationale behind detected anomalies is critical.\nFMs are increasingly being applied to anomaly detection tasks. However, systematic reviews that thoroughly examine and depict this field are still limited. While some works have explored the use of LLMs for anomaly detection and have made initial attempts to formalize the research landscape, few provide a comprehensive summary of current progress or address the key challenges in this area. For instance, [Su et al., 2024] reviews the application of LLMs in forecasting and anomaly detection but does not provide a taxonomy specifically tailored to show how FMs are applied to anomaly detection tasks. Similarly, [Xu and Ding, 2024] focuses on anomaly and out-of-distribution detection"}, {"title": "with LLMs but overlooks other FMs capable of processing diverse data modalities. This highlights the need for a more systematic and inclusive review. In this survey, we focus on methodologies that leverage FMs for anomaly detection to provide a clearer and more structured perspective by categorizing the models based on the roles FMs play in the detection process-specifically as encoders, detectors, or interpreters. This framework offers a comprehensive overview of the field, presents key insights and advancements in the field, and identifies potential directions for future research.\nOur main contributions include:", "content": null}, {"title": "A novel taxonomy.", "content": "We propose a structured taxonomy that categorizes the role of FMs in anomaly detection into three primary functions: encoder, detector, and interpreter. This classification provides a clear framework for understanding how FMs contribute to different stages of anomaly detection."}, {"title": "A systematic review.", "content": "We conduct an extensive review of state-of-the-art methods that leverage FMs for anomaly detection, organizing them according to our proposed taxonomy. This review highlights the latest trends, methodologies, and applications across various domains."}, {"title": "Future directions.", "content": "We identify key challenges in FM-based anomaly detection, including efficiency, bias, explainability, and multimodality. Furthermore, we outline promising future research directions to address these challenges and advance the field."}, {"title": "2 Preliminaries", "content": "We first introduce the basic concepts of FMs, then, give a clear problem statement of anomaly detection using FMs, and finally, present our proposed taxonomy."}, {"title": "2.1 Foundation Models", "content": "Definition. FMs are a class of large, pre-trained models that serve as the common basis for a wide range of downstream tasks across various domains. First introduced by [Bommasani et al., 2021], FMs build on concepts from deep neural networks and self-supervised learning. A prominent subset of FMs, LLMs, are trained on extensive text datasets and are able to perform tasks like language generation, comprehension, and translation. Unlike LLMs, which are limited to written language, FMs have a broader scope, capable of processing diverse data types such as text, images, and audio. They undergo large-scale pre-training on vast datasets and can be fine-tuned with task-specific data, making them highly versatile for numerous applications.\nComposition. FMs are built on the basis of large data, self-supervised pretraining, and transformer-based architecture [Zhou et al., 2024a]. Pretraining focuses on training a general model to learn generic representations using large amounts of diverse, unlabelled data. This general model, inspired by transfer learning [Niu et al., 2020], could then be used to perform different downstream tasks and enhance model performance in other fields through fine-tuning. In the pretraining stage, self-supervised learning [Liu et al., 2022] is applied across a wide range of domains and areas where unlabeled data is naturally available. As for the model structure, the transformer architecture is the most popular for FMs in different areas, like natural language processing (NLP) and computer vision (CV). These pretrained models may be adapted to specific tasks using a number of methods, such as transfer learning to fine-tune some or all of the parameters of FMs with a much smaller task-specific dataset [Zhang and Gao, 2022], few-shot learning with only a few samples, or zero-shot learning without any task-specific examples"}, {"title": "2.2 Proposed Taxonomy", "content": "As shown in Figure 1, the taxonomy of this survey classifies current anomaly detection models into three main categories: 1) FM as Encoder, where FMs are incorporated into the process of computing embeddings for high-level representations; 2) FM as Detector, where FMs are directly used as anomaly detectors to identify and localize specific anomalies; 3) FM as Interpreter, where FMs are assisted in providing explanations on the causes of anomalies. Examples of downstream tasks include fake news detection in social networks, driver fatigue detection in autonomous robotic systems, and plant/human disease detection in agricultural systems, to name a few.\nIt should be noted that in some works, due to the diversity of FMs, more than one kind of FMs are used, and sometimes they serve different roles in different stages of anomaly detection. Therefore, it is inappropriate to categorize them exclusively into one of these three main classes. For example, LogiCode [Zhang et al., 2024b] transforms structured request prompts and logical rules into executable Python codes by harnessing the power of the LLM to transform structured request prompts and logical rules into Python codes, which regards the foundation model as a code generator. AnomalyRuler [Yang et al., 2025] employs two different FMs, a Vision-Language Model (VLM) to generate descriptions for input video frames and a LLM to derive rules for anomaly detection by contrasting the rules for normality. Audit-LLM [Song et al., 2024] regards a FM as an assistant by serving as task decomposer, tool builder, and executor in every stage during the whole process of insider threat detection."}, {"title": "3 FM as Encoder", "content": "In an anomaly detection model, the encoder module plays a critical role in transforming input data (e.g., text, time series, images, etc.) into a latent feature embeddings. This representation captures essential characteristics of the data samples that can later be analyzed to detect deviations or anomalies. FM as encoder approaches focus on enhancing the quality of data embeddings with the help of powerful FMs. The derived embeddings are directly inputted into downstream classifiers for anomaly detection. Referring to Figure 2, we naturally categorize these approaches into two branches: LLM-based and hybrid embedding, depending on whether or not the latent embeddings are only generated by foundation model.\nThere is a special case where FM is not the encoder of data samples. We classify this kind of models in this section be-"}, {"title": "Embedding:", "content": "zi = $FM(Xi),", "latex": "zi = $FM(Xi),"}, {"title": "Anomaly Detection:", "content": "Y = (zi).", "latex": "Y = (zi)."}, {"title": "In these equations, the text information $x_i$ is encoded by a foundation model $\\phi_{FM}(\\cdot)$ into $z_i$. The embeddings generated by this kind of approach are directly fed into the classifier $\\tau(\\cdot)$ for classification label $\\hat{Y}$, typically without the need for any other encoders. Generally, most of these works use a Large Vision-Language Model (LVLM) to generate both textual and visual embeddings for image/video anomaly detection.", "content": null, "latex": "In these equations, the text information $x_i$ is encoded by a foundation model $\\phi_{FM}(\\cdot)$ into $z_i$. The embeddings generated by this kind of approach are directly fed into the classifier $\\tau(\\cdot)$ for classification label $\\hat{Y}$, typically without the need for any other encoders. Generally, most of these works use a Large Vision-Language Model (LVLM) to generate both textual and visual embeddings for image/video anomaly detection."}, {"title": "3.1 LLM-based Embedding", "content": "With reference to Figure 2(a), FMs are directly utilized as the unique encoder to output embeddings into the classifier for anomaly detection:"}, {"title": "3.2 Hybrid Embedding", "content": "Approaches using hybrid embeddings focus on utilizing the capability of FMs to capture additional information as shown in Figure 2(b). Taking graph anomaly detection as an example, the embeddings are generated by combining the output of both foundation model $\\phi_{FM}(\\cdot)$ and GNNS $\\O_{GNNs}(\\cdot)$:"}, {"title": "Embedding:", "content": "z\u2081 = F($FM(xi),\u00d3GNN(xi)),", "latex": "z\u2081 = F($FM(xi),\u00d3GNN(xi)),"}, {"title": "Anomaly Detection:", "content": "\u0176 = r(zi).", "latex": "\u0176 = r(zi)."}, {"title": "4 FM as Detector", "content": "The core idea behind this category is to utilize FMs as anomaly detectors to detect anomalies for a wide range of tasks, including classifications and localization. However, applying FMs directly as detectors presents unique challenges, primarily because FMs are often prompt-based, while the source data in most cases present different modalities, such as time-series, image, and video. In this section, we classify the models broadly into serialization-based and encoding-based detection, depending on how data are preprocessed before input to FMs."}, {"title": "4.1 Serialization-based Detection", "content": "Most of the existing attempts to employ the question-answering capability of the FM to directly detect anomalies, which omits the representation learning process of data embeddings. As shown in Figure 3(a), serialization-based detection typically involves two steps: (1) transforming source data into a sequence of text with a serialization function $SRL()$, and (2) extracting the detected anomalies from the FM output with a parsing function $Parse()$, as illustrated below:"}, {"title": "Data Serialization:", "content": "Xtxt = SRL(X),", "latex": "Xtxt = SRL(X),"}, {"title": "Prediction:", "content": "Y = Parse($FM(Xtxt,p)),", "latex": "Y = Parse($FM(Xtxt,p)),"}, {"title": "5 FM as Interpreter", "content": "In the last stage of anomaly detection, the FMs could be used as an interpreter to provide explanations on the detection results. We classify the models into detection-based and verification-based models based on whether FM serves as an anomaly detector as well."}, {"title": "5.1 Detection-based Explanation", "content": "This classification is based on the primary focus of interpreting anomalous samples, including the reasoning behind anomalies and the additional context they provide. As illustrated in Figures 4(a) and 4(b), these approaches can be"}, {"title": "Explanation:", "content": "Exp = fFM(Pt, Yi, Ci)", "latex": "Exp = fFM(Pt, Yi, Ci)"}, {"title": "Instruction Dataset Construction:", "content": "I\u2081 = {\"user\" : \" : Pa, \u201cFM\u201d : Exp},", "latex": "I\u2081 = {\"user\" : \" : Pa, \u201cFM\u201d : Exp},"}, {"title": "5.2 Verification-based Explanation", "content": "Verification-based FMs aim to further verify the detection results by providing some textual explanations about the detected anomalies (figure 4(c)). To ensure the effectiveness of FMs, specific prompts are designed to consistently generate identical output for the same queries.\nTo further validate the authenticity of detected anomalies, [Park, 2024] proposes an LLM-based multi-agent framework to analyze the detailed anomaly information, which serves as a critical interface between the AI-driven analysis process and human decision-making. With the aim of assisting end-users in coping with configuration errors in software system through log analysis, [Shan et al., 2024] proposes a two-stage strategy to localize the root-cause configuration logs. The first stage is to identify anomalous logs through obtaining key log messages, and the second stage is to use an LLM for further verification with the help of their strong power in"}, {"title": "6 Open Challenges and Way Forward", "content": "Based on the above review and analysis, we believe that there are still many challenges and potentials for further enhancement in this field. In this section, we list some future research directions for further exploration."}, {"title": "6.1 Efficiency", "content": "Notwithstanding the stellar progress and accomplishments of FMs, the improvements of performance in these models come at the expense of the model's efficiency. However, anomaly detection models need to be particularly efficient because they are often applied in real-time, high-stakes environments where timely detection and response to anomalies are critical. Common application scenarios include fraud detection and healthcare, where even small delays of identification may lead to significant financial loss or even safety risks. While some lightweight adaptation techniques have been proposed to improve the parameter efficiency, [Lester et al., 2021] gives an example that, as the model size increases, the performance gap between full fine-tuning and lightweight adaptation is diminishing rapidly. Therefore, exploring mechanisms to balance the trade-off between efficiency and expressivity of FMs still remains a notable challenge."}, {"title": "6.2 Bias", "content": "In recent years, FMs have led to an extraordinary level of homogenization, which refers to the consolidation of methodologies for building machine learning systems across a wide range of applications [Bommasani et al., 2021]: current NLP models are often adapted from one of popular FMs like BERT. Despite that any improvements of FMs can help produce immediate benefits, such kind of extension might also have the potential to inherit or even amplify the problematic biases of these models. A biased anomaly detection model may potentially lead to incorrect or unfair outcomes. For example, a biased model may disproportionately flag specific data points or groups (e.g., gender and racial bias) as anomalous even when they are normal, limiting their capability of detecting genuine anomalies. Such kind of false positives or false negatives can lead to unfair treatment of certain individuals or groups, missed critical alerts, or a lack of trust in the system, ultimately compromising its effectiveness and fairness. Therefore, it is critical to eliminate the intrinsic bias present within FMs, thereby further avoiding extrinsic harms in downstream anomaly detection systems."}, {"title": "6.3 Explainability", "content": "Despite that FMs are currently used as interpreters, in many works, to illustrate why anomalies are detected by providing textual explanations in a human-understandable manner, the models themselves are not transparent and interpretable enough to give explanations of the internal model structures and behaviors. However, providing evidence and logical steps for decision-making is a critical issue in anomaly detection especially in applications like healthcare and finance, where understanding the reasoning behind an anomaly is as important as detecting it [Chandola et al., 2009]. Therefore, how to improve the interpretability of FMs remains an open research question, and it is absolutely important for researchers to enhance the trust, usability, and decision-making of anomaly detection."}, {"title": "6.4 Multimodality", "content": "While multimodality is considered a critical element of intelligence, and serves as a crucial component for the development of both thorough and broad comprehension of the world, models that go beyond simple alignment of vision and language are yet to emerge [Radford et al., 2021; Lu et al., 2019]. In real-world application scenarios, taking healthcare as an example, medical data are highly multimodal, with various data types, scales, and styles. Multimodal models generally have better performance on anomaly detection by integrating and analyzing data from different sources than models with a single modality. However, current anomaly detection models are mainly developed for single modality (e.g., text, image, and gene), and do not learn from various modalities. By harnessing information across different data types, multimodal data can provide richer and more robust anomaly detection, thereby improving the accuracy of detection results across various applications. Future studies should further examine the design of FMs that integrate various modalities and domains."}, {"title": "7 Conclusion", "content": "The application of FMs to anomaly detection has emerged as a prominent area of research in recent years. In this survey, we provided an in-depth review of the use of FMs in anomaly detection tasks. We introduced a novel taxonomy classifying the methods into three approaches based on the role of FMs played in different stages of anomaly detection, namely encoder, detector, and interpreter. This taxonomy clarifies how FMs can empower the process of data representations, anomaly detection, and explainable result analysis of detection. We also discussed challenges and highlighted several future research directions, aiming to shed light on the advances and challenges in the field of anomaly detection with FMs, thereby encouraging further progress in this domain. As FMS continue to evolve, their role in anomaly detection is expected to expand, unlocking new possibilities for more accurate, interpretable, and scalable anomaly detection systems."}]}