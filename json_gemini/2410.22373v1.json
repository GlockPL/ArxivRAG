{"title": "ANALYTIC CONTINUAL TEST-TIME ADAPTATION FOR\nMULTI-MODALITY CORRUPTION", "authors": ["Yufei Zhang", "Yicheng Xu", "Hongxin Wei", "Zhiping Lin", "Huiping Zhuang"], "abstract": "Test-Time Adaptation (TTA) aims to help pre-trained model bridge the gap be-\ntween source and target datasets using only the pre-trained model and unlabelled\ntest data. A key objective of TTA is to address domain shifts in test data caused by\ncorruption, such as weather changes, noise, or sensor malfunctions. Multi-Modal\nContinual Test-Time Adaptation (MM-CTTA), an extension of TTA with better\nreal-world applications, further allows pre-trained models to handle multi-modal\ninputs and adapt to continuously-changing target domains. MM-CTTA typically\nfaces challenges including error accumulation, catastrophic forgetting, and re-\nliability bias, with few existing approaches effectively addressing these issues in\nmulti-modal corruption scenarios. In this paper, we propose a novel approach,\nMulti-modality Dynamic Analytic Adapter (MDAA), for MM-CTTA tasks. We\ninnovatively introduce analytic learning into TTA, using the Analytic Classifiers\n(ACs) to prevent model forgetting. Additionally, we develop Dynamic Selection\nMechanism (DSM) and Soft Pseudo-label Strategy (SPS), which enable MDAA\nto dynamically filter reliable samples and integrate information from different\nmodalities. Extensive experiments demonstrate that MDAA achieves state-of-the-\nart performance on MM-CTTA tasks while ensuring reliable model adaptation.", "sections": [{"title": "INTRODUCTION", "content": "Test-Time Adaptation (TTA) aims to help the pre-trained model bridge the gap between the source\ndomain and the target domain (Wang et al., 2021; Liang et al., 2024). Unlike Unsupervised Domain\nAdaptation (UDA) (Zhang et al., 2015; Liang et al., 2024), TTA performs adaptation without the\nneed for any source data (i.e., pre-trained dataset), which not only saves computational resources by\navoiding retraining but also preserves the privacy of the source data. One key TTA application is\naddressing the problem of domain shift from source data to corrupted test data, where the corruption\nis often caused by external factors (e.g., weather changes, ambient noise) or sensor malfunctions. As\nan extension of TTA, Continual Test-Time Adaptation (CTTA) has been proposed to align with real-\nworld scenarios where domain shifts usually are dynamic (Wang et al., 2022). Challenges in CTTA\nmainly consist of error accumulation and catastrophic forgetting. Error accumulation, stem-\nming from incorrect pseudo-labels, can mislead models' adaptation and potentially lead to collapse\n(Chen et al., 2019). Catastrophic forgetting refers to the loss of knowledge from the source data\nduring continuous adaptation, reducing the model's generalization ability (McCloskey & Cohen,\n1989). To address these challenges, various CTTA methods have been proposed, yielding promising\nresults in corruption-related tasks (Wang et al., 2022; Gao et al., 2023; Niu et al., 2022).\nMost existing CTTA approaches focus solely on single-modal scenarios, paying less attention to\nmulti-modal applications. Compared with TTA and CTTA, Multi-Modal Continual Test-Time Adap-\ntation (MM-CTTA) (Cao et al., 2023) shows greater potential for real-world applications, as multi-\nmodal data integrates a broader range of information than single-modality adaptation, resulting in\nmore robust networks (Radford et al., 2021). However, applying existing CTTA methods to MM-\nTTA by simply replacing the backbone with muiti-modal encoders is less optimal. MM-CTTA\nperformance can easily suffer from reliability bias, where intra-modality domain shifts increase\ninformation discrepancies in downstream fusion networks (Yang et al., 2024). Such effect becomes"}, {"title": "RELATED WORKS", "content": ""}, {"title": "TEST-TIME ADAPTATION", "content": "Test-Time Adaptation (TTA) focuses on enabling a pre-trained model to adapt to a new target\ndomain without requiring access to the source domain data used to initially train the model. A\nmajor challenge in TTA is error accumulation, which affects methods that rely on pseudo-labeling;\nincorrect predictions can mislead the adaptation process, potentially causing the model to collapse\n(Chen et al., 2019). One of the early solutions, TENT, addresses this by only updating the model's\nbatch normalization (BN) layers through entropy minimization (Wang et al., 2021). Subsequent\nresearch (Niu et al., 2023; Gong et al., 2022a; Zhou et al., 2023) has further mitigated this issue by\nfiltering out low-confidence predictions using carefully designed thresholds and updating the layer\nnormalization (LN) layers for more robust performance."}, {"title": "CONTINUAL TEST-TIME ADAPTATION", "content": "Continual Test-Time Adaptation (CTTA) extends TTA to scenarios where the target domain\nchanges continuously in an online manner without access to source data. The additional challenge\nCTTA faces is known as catastrophic forgetting, which occurs when a model adapts to the target\ndomain, leading to the loss of knowledge acquired from the source domain and dimension of gener-\nalization ability. To solve this problem, some studies turn to Continual Learning (CL) and achieve\ngreat success (Niu et al., 2022; Cao et al., 2023). We follow this trend and introduce a novel CL\napproach called Analytic Continual Learning (ACL) in MDAA.\nACL provides a global optimal solution through matrix inverse operations (Guo & Lyu, 2004). To\naddress the out-of-memory issue caused by large inverse matrices, Zhuang et al. (2021a) demon-\nstrated that iterative computation using block-wise data achieves results equivalent to joint com-\nputation, making analytic learning highly effective in continual learning. By treating data from\ndifferent time periods as blocks, ACL allows for recursive computation, with the final result being\nas accurate as if all data were processed simultaneously. Thanks to its non-forgetting properties,\nACL has shown strong performance across various CL tasks in recent years (Zhuang et al., 2022;\n2023). Inspired by ACL's success in CL tasks, we apply ACL to TTA for the first time in this work,\nimplementing several enhancements to address the issue of catastrophic forgetting."}, {"title": "MULTI-MODALITY TEST-TIME ADAPTATION", "content": "Multi-modality Test-Time Adaptation (MM-TTA) seeks to enhance model reliability by incorpo-\nrating multi-modal data into the TTA task. However, imbalances in inter-modal reliability can result\nin significant performance degradation, known as reliability bias (Wang et al., 2020). Most existing\nMM-TTA models address this issue by independently updating BN or LN layers of each feature\nencoder, followed by a weighted fusion mechanisms (Shin et al., 2022; Cao et al., 2023; Xiong\net al., 2024). Although this allows more reliable modalities to carry more weight during fusion, the\napproach remains relatively shallow in terms of information integration.\nA recent model called READ (Yang et al., 2024) introduced a more advanced approach by fusing\nfeatures through a Vision Transformer (ViT) (Dosovitskiy et al., 2020) block, which allows for\nthe preservation of parameters inherited from source data while effectively integrating inter-modal\ninformation (Vaswani, 2017; Gong et al., 2022b). READ achieves reliable adaptation by modulating\nonly the fusion layer within the attention module of the ViT block. Follow-up work (Lei & Pernkopf,\n2024) aimed to improve performance by updating both the feature encoders and the fusion layer.\nHowever, this approach requires prior knowledge about which modalities are corrupted, making it\nless capable for real-world scenario.\nIn this paper, our MDAA approach introduces classifiers for each feature encoder and the fusion\nnetwork. By adjusting the parameters of each classifier individually, MDAA maximizes the use\nof information from each modality, thus mitigating the effects of reliability bias. Crucially, these\nclassifier updates for upstream and downstream blocks do not cause conflicts, as the entire pre-\ntrained model remains frozen throughout the process. This property enables MDAA to adapt to\nchanging modality corruption without extra prior knowledge, distinguishing it from existing MM-\nTTA approaches."}, {"title": "METHOD", "content": "In this section, we first define the challenging MM-CTTA setting and introduce notations for key\nconcepts in Sec. 3.1. We then introduce the proposed Multi-modality Dynamic Analytic Adapter\n(MDAA) approach, which includes Analytic Classifiers (ACs) integrated with pre-trained multi-\nmodal encoders (Sec. 3.2), the Dynamic Selection Mechanism (DSM) (Sec. 3.3), and the Soft\nPseudo-label Strategy (SPS) (Sec. 3.4). An overview of MDAA is illustrated in Fig. 2, and the\npseudo-code for MDAA is provided in Appendix B."}, {"title": "AC Configuration", "content": ""}, {"title": "PROBLEM DEFINITION AND NOTATIONS", "content": "In this paper, we focus on an audio-video classification task as an example, using two modalities\nfor illustration without loss of generality. In MM-CTTA, the pre-trained model Is (\u00b7) is trained\non a labeled source dataset Ds ~ {X, X, Ys} in source domain S, where X and X represent\nthe audio and video training data matrices respectively. Ys represents the corresponding one-hot\nlabel set. During the adaptation phase, for each timestamp t in the target domain T, the model must\nperform inference and update its parameters based on the unlabeled test dataset Dr,t ~ {X+,t, X,t}.\nThe suffix T, t indicates the current target domain, as it shifts continually. Note that only the test\ndataset at timestamp t is available for updating the parameters \u0424\u0442, \u2192 \u0424\u0442,t+1."}, {"title": "SOURCE MODEL AND ANALYTIC CLASSIFIER CONFIGURATION", "content": "In the context of multi-modality classification task, we propose to integrate the ACs as classifiers\ninto a typical extraction-fusion approach. The standard structure can be represented as follows:\n\u03a6\u03c2 (\u03a7\u03b1, \u03a7\u00b0) = \u03b7s (fm (fs (X\u00ba) & f (X\"))), (1)\nwhere f () and f (\u00b7) represent upstream feature encoders for audio and video modalities, respec-\ntively, indicates the fusion operation implemented as concatenation in this paper, fm (.) denotes\nthe downstream fusion network and ns (\u00b7) indicates the classifier.\nSpecifically, we leverage multiple ACs as classifiers for extracted features of each modality and the\nfused features, with each classifier making an independent prediction. Each AC is of the same struc-\nture as a two-layer fully connected network, denoted by \u03da (FE (\u00b7)). Features are first non-linearly\nprojected into a higher dimensional space 4 by the feature expansion layer FE (\u00b7), enhancing their\nexpressiveness (Zhuang et al., 2022; 2021b). The projected features are then passed through the lin-\near layer (.) for classification. The feature expansion layer remains frozen, while the linear layer\nrequires updates during the adaptation process. For simplicity, we combine the feature encoder\nfs (\u00b7) and the feature expansion layer FE (\u00b7) into a single function, denoted as f\u015b (\u00b7), and refer to\nthe projected features as Xexf. Consequently, MDAA yields three classifiers as follows:\n\u03a6\n(X\u00b2) = (f(x)) = (Xext), i \u2208 {a, v}, (2)\n(\u03a7\u03b1, \u03a7\u00b2) = m (fm' (fs (X\u00ba) & f (x))) = \u00a2\u00ba (Xmf). (3)\nSince all ACs can be represented by the same equation, we will not distinguish between them except\nfor special needs in the following discussion. Following previous ACL works Zhuang et al. (2022),\nthe classifier (s are updated by solving the ridge regression to optimize on the source data Ds. To\nfurther solve the class imbalance problem within the source data, inspired by Fang et al. (2024), we\nformulate the optimization problem as follows:\nargmin\nWs\nNs\n2\n1 || Sk - Xexf,kWs || + ||Ws||, (4)\nwhere ||||F indicates the Frobenius norm, y is the regularization parameter and Ns is the samples\nsize of Ds. wk, Xexf,k and ys,k represents the weight, expanded feature vector and one-hot label of\nsample k in Ds, while the weight is further defined as\nWk =\nNs\nNc \u00d7 Nck (5)\nwhere Nc is the number of classes in Ds and Nc|k is the number of samples in Ds from category\nc to which sample k belongs. Following the ridge regression solution, the solution to optimization\nproblem is given in Theorem 1.\nTheorem 1. The optimal solution to Formula 4 is given as\nWs = (1xx,xext 1x exf, kxexf,k + I)-11 k=1Xexf,k\u0405,k\nT\n=\n(Xexf,SXexf,S+I)-1Xexf, (6)\nwhere xexf,k = \u221aWkXexf,k and \u1ef9s,k = \u221aWkys,k\u00b7 The proof of Theorem 1 is provided in Appendix\nA. In addition to the classifier weights Ws, a memory bank Bs needs to be constructed during the\ntraining phase. Unlike other methods (Cao et al., 2023; Zhang et al., 2023; Xiong et al., 2024), our\nmemory bank contains only two types of matrices, which can be represented as Bs ~ {Ps,Ps},\nwhere\nQs = Xexf,SXexf,S + I, (7)\nT\nQs = Xexf.SYS. (8)\nBoth Ps and Qs are used to extract and preserve the learned knowledge from the source dataset,\nwhich cannot be accessed during adaptation. Therefore weight Ws can be further rewritten as\nWs = PQs. (9)\""}, {"title": "DYNAMIC SELECTION MECHANISM", "content": "When adapting to sequentially incoming multi-modal data in MM-CTTA, some modality may be\nunreliable due to corruption. Such corrupted data can mislead the model to learn incorrect informa-\ntion. To address the reliability bias, we propose Dynamic Selection Mechanism (DSM) to determine\nwhether each AC should be updated in a dynamic way. M first identifies the most reliable classi-\nfier among the three (i.e., a, v, m) as the leader, while the other classifiers are treated as follower.\nSpecifically, the leader is determined by comparing the maximum\nprobability from each classifier's distribution. For each sample, the\nmodel prediction corresponds to the leader's prediction, and the\nleader will not be updated to maintain class balance. Whether to\nupdate each follower in the model depends on the comparison be-\ntween its maximum probability distribution maxP(Follower) and\nthe leader's maximum probability distribution maxP(Leader).\nWe consider four possible scenarios, as illustrated in Fig.3:\n(i). Close Distributions: maxP(Leader) and maxP(Follower)\nare quite close and refer to the same label. In this case, the follower\nis not updated, as this would only reinforce what it has already\nlearned, potentially leading to an imbalanced class distribution.\n(ii). Different Labels with Close Probabilities: maxP(Leader)\nand maxP(Follower) are quite close while they refer to different\nlabels. The follower is also not updated in this scenario because\nthere is no certainty that the leader's result is correct, and updating\nmay introduce errors.\n(iii). Evenly Distributed Probabilities: Both the leader and fol-\nlower have evenly distributed probabilities with no significant dif-\nference between labels. Again, no update occurs.\n(iv). Significant Difference: The leader has a higher probability\nlabel, while the follower has a more even probability distribution.\nIn this scenario, the follower should be updated.\nIn general, cases (i), (ii) and (iii) all belong to a small gap between\nmaxP(Follower) and maxP(Leader), while case (iv) belongs to\na larger gap. Therefore, given a pre-defined threshold 0, DSM can\nbe noted as:\n{Accept, maxP(Leader) \u2013 maxP(Follower) \u2265 0\nReject, otherwise (10)"}, {"title": "SOFT PSEUDO-LABEL STRATEGY", "content": "Using soft labels in self-supervised learning is quite popular as it preserves a broader range of\npossible outcomes compared to hard (one-hot) label learning (M\u00fcller et al., 2019; Hinton et al.,\n2015). Inspired by such trend, we use soft pseudo-labels to update the ACs during MM-CTTA, as\nillustrated in Fig.2(C). For each test sample k, we choose the top n classes of leader's distribution\nset C = {C1,k, C2,k,...,Cn,k} and assign them with weights X1,k, A2,k... An,k, (\u2211i=1&i,k = 1)\nrespectively. The reconstructed label y for sample k through SPS can be represented as\nJk =\n{ai,k,i\u2208 C\n0, otherwise (11)\nSince ACL considers global optimization, which means it accounts not only for the input data XT, t\nat timestamp t, but also all previous data processed by the model, including Xs,k and XT,1:t-1. With\nthe reconstructed label YT,1:t throughout t, the optimization problem for weight matrix Wr,t can be\nrepresented as:\n2\n2\nargmin Sk1Wk ||JS,k - Xexf,kWT, || + ||\u012aT,1:t - Xexf,1: WT, || + ||WT,t||\nWT,t (12)\nIt is important to note that while we treat source data and target data separately, we adjust the cate-\ngory balance for the source dataset by assigning weights to each class. In contrast, it is challenging"}, {"title": "EXPERIMENTS", "content": "In this section, we evaluate the proposed MDAA approach under the challenging MM-CTTA setting.\nThe MM-CTTA setting is detailed in Sec. 4.1. Sec. 4.2 compares MDAA with SOTA methods\nthrough extensive experiments to demonstrate its superior performance. Additionally, the ablation\nstudies on each component of MDAA are presented in Sec. 4.3, which illustrate the effectiveness\nof MDAA in addressing different challenges within the MM-CTTA setting. The implementation\ndetails are provided in Appendix C."}, {"title": "BENCHMARKS AND SETTINGS", "content": "In this section, we introduce the datasets and task settings used for MM-CTTA. The M\u041c-\u0421\u0422\u0422\u0410\nsetting requires the model to initially train on uncorrupted source datasets. Subsequently, the model\nperforms TTA on each corrupted target domain in sequence. We utilize two datasets for this setting:\nKinetics50 (Kay et al., 2017) and VGGSound (Chen et al., 2020). While the original uncorrupted\ndatasets serve as source, the corrupted target datasets, Kinetics50-C and VGGSound-C, are con-\nstructed following Yang et al. (2024), which introduces 15 types of video corruptions and 6 audio\ncorruptions at severity level 5.\nTo evaluate the model performance, we designed two classification tasks specifically for M\u041c-\u0421\u0422\u0422\u0410\nfollowing previous research on corruption-related TTA (Wang et al., 2022; 2021; Yang et al., 2024;\nLei & Pernkopf, 2024). The first task, named progressive single-modality corruption, sequen-\ntially introduces different types of corruption to one modality while keeping the other modality\nuncorrupted. Focusing on evaluating the model's resistance to catastrophic forgetting, this task is\nset in an online manner, where the model processes only one sample at a time. The second task,\ncalled interleaved modality corruption, continually alternates corruption between the two modali-\nties. While most methods perform poorly in the online setting due to severe catastrophic forgetting,\nthis task uses a batch size of 64 during test time to emphasize assessing the model's ability to adapt\nto dynamic reliability biases."}, {"title": "PERFORMANCE COMPARISON", "content": "To provide a comprehensive comparison, we reproduce different types of TTA methods under the\nMM-CTTA setting. Typical TTA methods of TENT (Wang et al., 2021) and SAR (Niu et al., 2023);"}, {"title": "ABLATION STUDY", "content": "In this section, we conduct three ablation studies on both video-corrupted Kinetics50-C dataset and\naudio-corrupted VGGSound-C dataset in severity level 5, with the batch size of 64. For simplicity,\nin the following section we use KS-video and VGG-audio to represent these two tasks.\nComponent analysis. To verify the effectiveness of each MDAA component, we adopt an ablation\nstudy w.r.t three components as shown in Table 6. As observed, the model using only AC under-\nperforms, with an average accuracy 0.5%-0.57% lower than READ on KS-video, and the model"}, {"title": "CONCLUSION", "content": "In this paper, we analysed the factors that affect the model in the MM-CTTA task (i.e., error ac-\ncumulation, catastrophic forgetting and reliability bias) and demonstrate that typical TTA methods\nare not suitable for the MM-CTTA task. To address the impact of these factors, we propose a new\nparadigm MDAA that introduce analytic learning to TTA for the first time. Instead of just adapting\nthe model to the target domain, MDAA integrates the target domain into source domain, and thus\nprevent network from forgetting. With the help of DSM and SPS, model is able to dynamically and\ncomprehensively process the information provided by each modality and use reliable samples to up-\ndate. In the future, we will try to adapt this paradigm to more modalities to solve more challenging\nproblems in real scenarios."}, {"title": "DYNAMIC THRESHOLD UPDATE", "content": "The threshold @ we used in DSM is a fixed number. In this section we attempt to update @ in a\ndynamic way during the adaptation. We define the threshold i for classifier i in time t as\n\u03b8=\n[0\u22121 + 1 (di - di\u22121),ift > 1\nOini , if t = 1 , i = {a, v, m} (16)\n\u03a3k=11 (max (Pleader) \u2013 max(P)), i = {a,v,m},\nNk (17)\nwhere X is the learning rate, dini is the initial threshold and Nk is the batch size. di is calculated to\nreflect the gap between leader and follower i. The original intention of this design is to adjust the\nsize of the threshold according to the change of dt, so as to eliminate the statistical bias of different\ndomains. However, as shown in Table 13, such attempt is not only achieve lower performance while\nneeds more variables to be memorized. So only the fixed threshold is used in the formal method."}, {"title": "LABEL WEIGHT DISTRIBUTION", "content": "The weight assignment in SPS follows the formula ai = round((n+1 \u2013 i)/2=1i). In this\nsection we make a toy experiment to explore whether such assignment is reasonable. We take KS-\nvideo as example which use top 2 classes for reconstruction. Table 14 show the results on different\nweight assignment. It can be seen that the performance peaks at 0.7, corresponding to the assignment\nin main text. Therefore the assignment of weights in the main text is justified."}]}