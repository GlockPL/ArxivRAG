{"title": "Federated Deep Reinforcement Learning for Energy Efficient Multi-Functional RIS-Assisted Low-Earth Orbit Networks", "authors": ["Li-Hsiang Shen", "Jyun-Jhe Huang", "Kai-Ten Feng\u2020", "Lie-Liang Yang*", "Jen-Ming Wu+"], "abstract": "In this paper, a novel network architecture that deploys the multi-functional reconfigurable intelligent surface (MF-RIS) in low-Earth orbit (LEO) is proposed. Unlike traditional RIS with only signal reflection capability, the MF-RIS can reflect, refract, and amplify signals, as well as harvest energy from wireless signals. Given the high energy demands in shadow regions where solar energy is unavailable, MF-RIS is deployed in LEO to enhance signal coverage and improve energy efficiency (EE). To address this, we formulate a long-term EE optimization problem by determining the optimal parameters for MF-RIS configurations, including amplification and phase-shifts, energy harvesting ratios, and LEO transmit beamforming. To address the complex non-convex and non-linear problem, a federated learning enhanced multi-agent deep deterministic policy gradient (FEMAD) scheme is designed. Multi-agent DDPG of each agent can provide the optimal action policy from its interaction to environments, whereas federated learning enables the hidden information exchange among multi-agents. In numerical results, we can observe significant EE improvements compared to the other benchmarks, including centralized deep reinforcement learning as well as distributed multi-agent deep deterministic policy gradient (DDPG). Additionally, the proposed LEO-MF-RIS architecture has demonstrated its effectiveness, achieving the highest EE performance compared to the scenarios of fixed/no energy harvesting in MF-RIS, traditional reflection-only RIS, and deployment without RISs/MF-RISS.", "sections": [{"title": "I. INTRODUCTION", "content": "In revolutionary era of information explosion, global commu-nication technology is rapidly advancing from fifth-generation (5G) to six-generation (6G), driving increasing demands for high-coverage and high-performance networks [1]. To meet these growing requirements, reconfigurable intelligent surface (RIS) technology has emerged as a promising solution [2]. By adjusting the configuration of RIS elements, a virtual line-of-sight (LoS) link can be established to bypass obstacles between the transmitter and receiver [3]. Due to these advantages, RIS technology can enable precise signal distribution, significantly improving communication performance [4].\nDespite its potential, RIS technology still faces challenges, such as half-space coverage limitations and reliance on external power sources, which restrict its full capabilities. To address these issues, the concept of multi-functional RIS (MF-RIS) has been introduced [5]. Unlike traditional RIS, which depends on external power to reflect and manipulate signals, MF-RIS can harvest energy from radio-frequency (RF) signals, enabling self-sufficient operation with fewer needs of batteries or grid power. This energy harvesting capability improves the energy efficiency (EE) and sustainability of MF-RIS. Additionally, MF-RIS extends beyond basic signal reflection by supporting signal amplification, allowing it to enhance both coverage and signal strength when necessary.\nWith advancements in aerospace technology, satellite commu-nication has demonstrated great potential for achieving global coverage [6]. However, the rapid increase in the number of connected ground users presents significant challenges, par-ticularly in terms of limited bandwidth and energy allocation [7]. Low-Earth orbit (LEO) satellite communication systems have emerged as a key focus due to their advantages of global connectivity and high throughput [8]. LEO systems offer com-paratively lower latency than other satellite systems, enabling more efficient real-time communications. However, the long distance involved in LEO satellite communication still results in significant pathloss. Recently, numerous studies have focused on integrating RIS into satellite systems to enhance signal transmission range [9], [10]. Additionally, LEO satellites rely on solar panels to harvest energy in sunlit regions. By contrast, in shadow regions they must depend on battery storage for op-eration. However, most of existing studies have not considered the practical power consumption as well as battery storage of LEO satellites and RIS. To address the issue of insufficient energy, this work proposes the deployment of MF-RIS on LEO satellites, coordinating with solar panels to optimize system energy efficiency.\nIn this work, we focus on the maximization of EE of the conceived LEO-MF-RIS architecture. However, the rapid variation in channel conditions due to the movement of LEO satellites along their orbits creates a highly complex, chal-lenging problem. To address this, deep reinforcement learning (DRL) is employed to adaptively adjust the network policies in response to the dynamic environment. Moreover, we utilize multi-agent deep deterministic policy gradient (MADDPG) to handle the high-dimensional state space and complex action scenarios. MADDPG adopts an actor-critic (AC) framework, enabling each agent to determine the optimal action policy through interaction with the environment [11]. To further en-hance cooperative policy decision-making, federated learning (FL) is incorporated to facilitate exchange and aggregation of model parameters among LEO agents for improved information sharing and coordination. The main contributions of this paper are elaborated as follows:"}, {"title": "II. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "Fig. 1 illustrates an MF-RIS assisted downlink LEO satellite communication network. We consider L LEO satellites denoted by the set $\\mathcal{L} = \\{1, 2, ..., L\\}$, with each equipped with N transmit antennas, serving K users indexed by the set of $\\mathcal{K} = \\{1, 2, ..., K\\}$. We assume a single receiving antenna for each user. An MF-RIS with M elements indexed by the set of $\\mathcal{M} = \\{1, 2, ..., M\\}$ is equipped on each LEO. Note that MF-RIS is in a two-dimensional array with $M = M_h \\cdot M_v$ elements, where $M_h$ and $M_v$ indicate the respective numbers of elements in horizontal and vertical directions. The MF-RIS configuration on the l-th LEO can be defined as\n$\\mathbf{\\Theta}_l = \\text{diag}\\left(\\left[\\sqrt{1 - \\alpha_{l,1}^2} e^{j\\theta_{l,1}}, ..., \\alpha_{l,m} \\beta_{l,m} e^{j\\theta_{l,m}}, ..., \\alpha_{l,M} \\beta_{l,M} e^{j\\theta_{l,M}}\\right]\\right),$ (1)\nwhere $\\theta_{l,m} \\in [0, 2\\pi)$ and $\\beta_{l,m} \\in [0, \\beta_{max}]$ denote the phase-shift and amplitude coefficients of MF-RIS, respectively. Note that $\\beta_{max} > 1$ denotes the signal amplification, whereas $\\beta_{max} \\le 1$ indicates conventional RIS without amplification capability. Each element of the MF-RIS can operate in energy harvesting (EH) mode (H mode) and signal mode (S mode) by adjusting the EH coefficient $\\alpha_{l,m} \\in [0, 1]$. Note that $\\alpha_{l,m} = 1$ implies that MF-RIS operates in S mode, whilst $\\alpha_{l,m} = 0$ indicates that it functions in only H mode. MF-RIS can operate in a hybrid mode when $0 < \\alpha_{l,m} < 1$, which is different from the existing work of [5]. We define $s_{l,m}$ as the incident signal received by the m-th element of the MF-RIS on the l-th LEO satellite. Therefore, the signals harvested and reflected by the m-th MF-RIS element on the l-th LEO are modeled as $y_{l,m}^H = (1 - \\alpha_{l,m}) s_{l,m}$ and $y_{l,m}^S = \\alpha_{l,m} \\beta_{l,m} e^{j\\theta_{l,m}} s_{l,m}$, respectively.\nA. Channel Model\nWe consider the Rician fading channel model [12] between the the l-th LEO and MF-RIS as $\\mathbf{H}_l \\in \\mathbb{C}^{M \\times N}$, i.e.,\n$\\mathbf{H}_l = \\sqrt{\\frac{h_0 d_{sr}^{-\\kappa_0}}{\\beta_0 + 1}} \\left( \\sqrt{\\beta_0} \\mathbf{H}_{LOS} + \\sqrt{\\beta_0} \\mathbf{H}_{NLOS} \\right),$ (2)\nwhere $h_0$ is the pathloss at the reference distance of 1 meter, $d_{sr}$ is the distance, and $\\kappa_0$ is the corresponding pathloss exponent. $\\beta_0$ is the Rician factor, adjusting the portion of LoS path $\\mathbf{H}_{LOS}$ and non-LoS (NLOS) component $\\mathbf{H}_{NLOS}$. The LoS component $\\mathbf{H}_{LOS}$ is expressed as [13]\n$\\mathbf{H}_{LOS} = \\left[1, e^{-j d \\sin{\\phi_r} \\sin{\\vartheta_r}}, ..., e^{-j (M-1) d \\sin{\\phi_r} \\sin{\\vartheta_r}}\\right]^T \\\\otimes \\left[1, e^{-j d \\sin{\\phi_t} \\cos{\\vartheta_t}}, ..., e^{-j (N-1) d \\sin{\\phi_t} \\cos{\\vartheta_t}}\\right]^T,$ (3)\nwhere $\\otimes$ denotes the Kronecker product and T is transpose op-eration. Notation of $\\lambda$ indicates the wavelength of the operating frequency, and d denotes the element separation of MF-RIS. In (3), $\\phi_r, \\vartheta_r, \\phi_t$, and $\\vartheta_t$ represent the vertical/horizontal angle-of-arrivals, and the vertical/horizontal angle-of-departures, re-spectively. Note that $\\mathbf{H}_{NLOS}$ follows independent and identically distributed Rayleigh fading. The channel vectors from LEO $l$ to user $k$ and from the MF-RIS $l$ to user $k$, denoted by $\\mathbf{h}_{l,k} \\in \\mathbb{C}^{N \\times 1}$ and $\\mathbf{r}_{l,k} \\in \\mathbb{C}^{M \\times 1}$, are defined by following $\\mathbf{H}$, but in a vector form, where the LoS components $\\mathbf{h}_{LOS}$ and $\\mathbf{r}_{LOS}$ are expressed as\n$\\mathbf{h}_{LOS} = \\left[1, e^{-j d \\sin{\\phi_t} \\sin{\\vartheta_t}}, ..., e^{-j (N-1) d \\sin{\\phi_t} \\sin{\\vartheta_t}}\\right]^T,$ (4)\n$\\mathbf{r}_{LOS} = \\left[1, e^{-j d \\sin{\\phi_t} \\sin{\\vartheta_t}}, ..., e^{-j (M-1) d \\sin{\\phi_t} \\sin{\\vartheta_t}}\\right]^T,$ (5)\nFor simplicity, we neglect the remaining parameters of $\\mathbf{h}_{l,k}$ and $\\mathbf{r}_{l,k}$ due to similar definitions in (2) and (3). Accordingly, the combined channel between LEO-MF-RIS $l$ and user $k$ can be expressed as $g_{l,k} \\in \\mathbb{C}^{1 \\times N}$\n$g_{l,k} = \\mathbf{h}_{l,k}^H + \\mathbf{r}_{l,k}^H \\mathbf{\\Theta}_l \\mathbf{H}_l,$ (6)\nwhere H indicate Hermitian operation. The transmitted signal and the active beamforming vector of the k-th user served by"}, {"title": "B. Power Dissipation Model", "content": "the l-th LEO are defined as $x_{l,k}$ and $\\mathbf{w}_{l,k} \\in \\mathbb{C}^{N \\times 1}$, respectively. Consequently, the received signal of the k-th user served by the l-th LEO is given by\n$y_{l,k} = g_{l,k} \\mathbf{w}_{l,k} x_{l,k} + g_{l,k} \\sum_{k' \\in \\mathcal{K} \\backslash k} \\mathbf{w}_{l,k'} x_{l,k'} + \\sum_{l' \\in \\mathcal{L} \\backslash l} \\sum_{k' \\in \\mathcal{K} \\backslash k} g_{l',k} \\mathbf{w}_{l',k'} x_{l',k'} + n_{l,k},$ (7)\nwhere $n_{l,k} \\sim \\mathcal{CN}(0, \\sigma_{l,k}^2)$ denotes complex additive white Gaussian noise (AWGN) with power $\\sigma_{l,k}^2$. In (7), the first term represents the desired signal for user k from the l-th LEO. The second term denotes the intra-LEO interference, whilst the third term represents inter-LEO interference. According to (7), the corresponding signal-to-interference-plus-noise ratio (SINR) is given by\n$\\gamma_{l,k} = \\frac{|g_{l,k} \\mathbf{w}_{l,k}|^2}{\\sum_{k' \\in \\mathcal{K} \\backslash k} |g_{l,k} \\mathbf{w}_{l,k'}]^2 + \\sum_{l' \\in \\mathcal{L} \\backslash l} \\sum_{k' \\in \\mathcal{K} \\backslash k} |g_{l',k} \\mathbf{w}_{l',k'}]^2 + \\sigma_{l,k}^2}.$ (8)\nBased on (8), the ergodic rate of LEO l and user k can be obtained as\n$R_{l,k} = \\log_2(1 + \\gamma_{l,k}).$ (9)\nWe also note that time step t is omitted in some content of this article for simplicity, i.e., $R_{l,k}(t)$ is written as $R_{l,k}$, as the movement of LEO satellites is predetermined by their orbital paths.\nWe define the EH coefficient matrix for the m-th element of the l-th MF-RIS on LEO satellite as\n$\\mathbf{\\Upsilon}_{l,m} = \\text{diag}\\left([0, ..., 0, 1 - \\alpha_{l,m}, 0, ..., 0]\\right).$ (10)\nAccordingly, the RF power received at the m-th element of the l-th MF-RIS is acquired as\n$\\mathbf{P}_{l,m}^{RE} = \\left|\\left(\\sum_{l' \\in \\mathcal{L}} \\sum_{k \\in \\mathcal{K}} \\mathbf{w}_{l,k} + n_m\\right) \\right|^2,$ (11)\nwhere $n_m \\sim \\mathcal{CN}(0, \\sigma_m^2 I_M)$ denotes the amplified noise intro-duced by the MF-RIS with its power $\\sigma_m^2$. In order to capture the dynamics of the RF energy conversion efficiency for different input power levels, a non-linear energy harvesting model is adopted [14]. Accordingly, the total power harvested from the m-th element of the l-th MF-RIS on LEO is given by\n$P_{l,m} = \\frac{\\Upsilon_{l,m} - Z \\Omega}{1 - \\Omega} Z,$ (12)\nwhere $\\Upsilon_{l,m} = \\frac{1}{1 + e^{-a (P_{l,m}^{RE} - q)}}$ is a logistic function with respect to the received RF power $P_{l,m}^{RE}$, and $Z \\ge 0$ is a constant determining the maximum harvested power. The constant $\\Omega = \\frac{1}{1 + e^{a q}}$ is introduced to ensure a zero-input/zero-output response for H mode, with constants a > 0 and q > 0 capturing the joint effects of circuit sensitivity limitations and current leakage. Moreover, the power for controlling MF-RIS mainly comes from the total number of PIN diodes required [15]. The total number of required PIN diodes can be obtained as"}, {"title": "C. Problem Formulation", "content": "$\\log_2 L_a + \\log_2 L_\\beta + 2 \\log_2 L_\\theta$, where $L_a, L_\\beta$, and $L_\\theta$ indicate the quantization levels controlled by PIN diodes for the EH coefficient, amplitude, and phase-shifts, respectively. Then, the power consumption of the MF-RIS can be obtained as\n$\\mathbf{P}_{l,m}^{IRD} = \\frac{1}{2} [\\log_2 L_a + \\log_2 L_\\beta + 2 \\log_2 L_\\theta] M P_{pin} + P_c + \\xi P_{l,o},$ (13)\nwhere $P_c$ is the power consumed by the RF-to-DC power conversion circuit, $P_{l,o}$ is the output power of the MF-RIS, and $\\xi$ is the inverse of the amplifier efficiency. In (13), the output power of the MF-RIS can be expressed as\n$P_{l,o} = \\sum_{k \\in \\mathcal{K}} ||\\mathbf{\\Theta}_l \\mathbf{H}_l \\mathbf{r}_{l,k}||^2 + \\sum_{m \\in \\mathcal{M}} \\sigma_m ||\\mathbf{\\Theta}_l||^2,$ (14)\nwhere $|| \\cdot ||_F$ is the Frobenius norm.\nWe partition it into multiple time slots, with the interval of each time slot defined as $\\Delta$. In time t, the energy harvested by satellite solar panels can be expressed as [16]\n$E_{sol}^l(t) = \\eta_s \\psi B \\int_{t}^{t + \\Delta} \\cos^2 \\phi \\cos^2 \\theta_{rot}^l(t) dt,$ (15)\nwhere $\\eta_s$ is the efficiency of energy conversion, $\\psi$ is the light intensity, and B is the size of the solar panels. The notation of $\\phi$ indicates the angle between the satellite orbital plane and the sunlight, and $\\theta_{rot}^l(t)$ defines the satellite rotation angle from the midpoint of the shaded orbit V at time t. Fig. 1 illustrates an example of the LEO satellite\u2019s energy consumption when moving over sunlight and shadow areas. In sunlight area, the battery is charged by harvesting the solar energy from both solar panels and signal energy from the MF-RIS. However, in the shadow region where solar energy is unavailable, the LEO relies primarily on the remained battery capacity and additional energy harvested from the MF-RIS. We define the half-angle of the shadow area that the LEO satellite travels as [16]\n$\\Theta_{rot}^{l,s}(t) = \\left\\{\\begin{array}{ll} 0, & \\text{if } \\phi > \\sin^{-1} \\left(\\frac{R_e}{R_e + h_{l,s}}\\right), \\\\ \\sin^{-1}\\left(\\frac{\\sqrt{R_e^2 \\cos^2 \\phi - (2 R_e h_{l,s} + h_{l,s}^2) \\sin^2 \\phi}}{(R_e + h_{l,s}) \\cos \\phi}\\right), & \\text{otherwise}, \\end{array}\\right.$ (16)\nwhere $R_e$ is the radius of the Earth and $h_{l,s}$ is the height of the l-th LEO satellite. Note that the range of $\\phi$ is $(-\\pi, \\pi)$. When the satellite is in the sunlight area, i.e., $|\\Theta_{rot}^{l,s}(t)| \\ge 0$, the remaining time it takes to move from its current position $\\Theta_{rot}^l(t)$ to the shadow area can be expressed as\n$\\tau_{sun}^l(t) = \\left\\{\\begin{array}{ll} \\frac{2 \\pi - \\Theta - \\Theta_{rot}^l(t)}{\\Omega}, & \\text{if } \\Theta_{rot}^l(t) \\in [0, \\pi), \\\\ \\frac{-\\pi - \\Theta_{rot}^l(t)}{\\Omega}, & \\text{if } \\Theta_{rot}^l(t) \\in [-\\pi, 0), \\end{array}\\right.$ (17)\nwhere $\\Omega$ is the Earth rotation rate. Moreover, the duration of LEO l moving from the current location in shadow area to the sunlight area can be expressed as\n$\\tau_{shd}^l(t) = \\frac{\\Theta_{rot}^l - \\Theta_{rot}^{l,s}(t)}{\\Omega}.$ (18)\nAccording to [16], [17], the charging solar power of the LEO"}, {"title": "III. PROPOSED FEDERATED LEARNING MULTI-AGENT DEEP DETERMINISTIC POLICY GRADIENT (FEMAD) SCHEME", "content": "satellite battery at time t can be expressed as\n$P_{in}^l(t) = \\frac{E_{sun}^l(t)}{\\tau_{sun}^l(t)}.$ (19)\nWhen the LEO satellite is in the sunlight area, the remaining battery energy on LEO l at time t can be expressed as\n$E_l(t) = \\min \\left( E_b, E_l(t - 1) + \\left[ P_{in}^l(t) \\cdot 1_{\\{A = sun\\}} - \\sum_{m \\in \\mathcal{M}} \\Upsilon_{l,m} \\left( P_{l,m}^{IRD} + P_{l,m}^{cons} \\right) - P_l^T - P_{cons}^l \\right] \\cdot \\Delta \\right),$ (20)\nwhere $A \\in \\{sun, shd\\}$ indicates whether the current LEO location is in sunlight or shadow area, and $1_{\\{\\cdot\\}}$ indicates the event occurrence. In (20), $E_b$ denotes the LEO satellite battery capacity, $P_l^T = \\sum_{k \\in \\mathcal{K}} ||\\mathbf{w}_{l,k}||^2$ indicates the transmit power of LEO l, and $P_{cons}^l$ represents the regular operational circuit power. The total energy consumption can be expressed as\n$\\mathcal{E}_{tot}^l(t) = \\left(\\sum_{m \\in \\mathcal{M}} \\left( P_{l,m}^{IRD} + P_{l,m}^{cons} \\right) + P_l^T + P_{cons}^l \\right) \\cdot \\Upsilon_l(t),$ (21)\nwhere $\\Upsilon_l(t) = \\tau_{sun}^l(t) + \\tau_{shd}^l(t)$ denotes the total time it takes for the LEO satellite to complete one full orbit.\nC. Problem Formulation\nThe objective is to maximize the long-term EE while guar-anteeing the constraints of user rate requirement, MF-RIS configuration and LEO power limitation, which is formulated as follows:\n$\\max_{\\Theta_{l,m}, \\alpha_{l,m}, \\beta_{l,m}, \\mathbf{W}_{l,k}} \\lim_{T \\to \\infty} \\frac{1}{T} \\sum_{t=0}^{T} \\sum_{l \\in \\mathcal{L}} \\sum_{k \\in \\mathcal{K}} \\frac{R_{l,k}(t)}{\\mathcal{E}_{tot}^l(t)},$ (22a)\ns.t. $\\mathbf{\\Theta}_l \\in \\mathcal{R}_\\Theta, \\quad \\forall l \\in \\mathcal{L},$ (22b)\n$R_{l,k} \\ge R^{min}, \\quad \\forall l \\in \\mathcal{L}, \\forall k \\in \\mathcal{K},$ (22c)\n$P_l^{IRS} \\ge \\sum_{m \\in \\mathcal{M}} P_{l,m}^h, \\quad \\forall l \\in \\mathcal{L},$ (22d)\n$P_l^T + P_{cons} \\le P_{max}, \\quad \\forall l \\in \\mathcal{L},$ (22e)\n$E_l(t) \\ge 0, \\quad \\forall l \\in \\mathcal{L}.$ (22f)\nConstraints (22b) defines the constraint set of MF-RIS coef-ficients as $\\mathcal{R}_\\Theta$, including $\\alpha_{l,m} \\in [0,1]$, $\\beta_{l,m} \\in [0, \\beta_{max}]$, and $\\theta_{l,m} \\in [0,2\\pi)$. Constraint (22b) guarantees the minimum rate requirement of each serving users as $R^{min}$. Constraint (22c) ensures the self-sustainability of MF-RIS, i.e., power consumption of the MF-RIS cannot exceed its harvested power. Constraint (22d) guarantees that the total LEO transmit power and circuit operational power should be smaller than $P^{max}$. Constraint (22e) ensures that the remaining battery energy must be greater than 0. Due to the inherent non-convexity and non-linearity of problem (22a), as well as the complexity of long-term EE optimization, it presents a significant challenge to solve this problem. To address these difficulties, we propose a DRL-based scheme, which is detailed in the following section."}, {"title": "A. Multi-Agent DDPG Algorithm", "content": "We have conceived a FEMAD scheme for solving problem (22), as depicted in Fig. 2. FEMAD consists of multi-agent DDPG architecture by allowing each LEO as an agent deter-mining its own policy with a plethora of continuous variables. Furthermore, federated learning is leveraged in the multi-agent system for cooperative hidden information exchange.\nWe consider a typical DRL framework consisting of a state set S, an action set A, and a reward set R. In this framework, an agent representing one LEO-MF-RIS will iteratively perform its action in a dynamic environment to receive the corresponding reward while updating its current state. Since optimizing MF-RIS in LEO networks involves multiple observation and config-uration parameters, the state-action space becomes compellingly large. Traditional DRL methods would likely be inefficient, facing issues such as learning instability and slow convergence. Additionally, traditional deep Q networks (DQN) are unsuitable for this problem, as they could result in prohibitively high complexity due to the high-dimensional discrete variables when quantizing continuous parameters. For these reasons, we adopt the MADDPG architecture utilizing a two-layered actor-critic network to effectively address these issues. Accordingly, we define the state, action, and the corresponding reward as follows:\nState: The total state space is defined as a set of individual agent state $\\mathcal{S}(t) = \\{S_1(t), S_2(t), ..., S_L(t)\\}$. Each agent state $S_l(t)$ is composed of a sequence of states over time, denoted as $S_l(t) = \\{s_l(1), s_l(2), ..., s_l(T)\\}$, where $s_l(t) = \\{g_{l,k}(t) | \\forall t, \\forall k \\in \\mathcal{K}\\}$, with $g_{l,k}(t)$ defined as the combined MF-RIS channel in (6) at time t.\nAction: The action space $\\mathcal{A}(t)$ is defined as a set of individual agent action $\\mathcal{A}(t) = \\{A_1(t), A_2(t), ..., A_L(t)\\}$. Each agent action set $A_l(t)$ consists of a sequence of actions over time, denoted as $A_l(t) = \\{a_l(1), a_l(2), ..., a_l(T)\\}$. Note that action $a_l(t)$ includes all parameters to be determined in problem (22a) as $a_l(t) = \\{\\theta_{l,m}(t), \\alpha_{l,m}(t), \\beta_{l,m}(t), \\mathbf{w}_{l,k}(t) | \\forall t, \\forall m \\in \\mathcal{M}, \\forall k \\in \\mathcal{K}\\}$.\nReward: The reward space set is defined as $\\mathcal{R}(t) = \\{R_1(t), R_2(t), ..., R_L(t)\\}$, with each agent reward set as $R_l(t) = \\{r_l(1), r_l(2), ..., r_l(T)\\}$. The obtained reward of each agent is designed as the penalized EE as\n$r_l(t) = \\frac{\\frac{1}{\\left|\\mathcal{K}\\right|} \\sum_{k \\in \\mathcal{K}} R_{l,k}(t)}{\\mathcal{E}_{tot}^l(t)} - \\sum_{i=1}^4 \\rho_{l,i} C_{l,i},$ (23)\nwhere $\\rho_{l,i}, \\forall i \\in \\{1,2,3,4\\}, \\forall l \\in \\mathcal{L}$ indicates the weights of each penalty $C_{l,i}$. The penalty terms $C_{l,i}$ correspond-ing to constraints of (22c)-(22f) are defined as $C_{l,1} = \\sum_{k \\in \\mathcal{K}} \\text{P}_{min} R_{l,k}$, $C_{l,2} = P_l^{IRS} - \\sum_{m \\in \\mathcal{M}} P_{l,m}^h$, $C_{l,3} = P_l^T + P_{cons} - P_l^b$, and $C_{l,4} = -E_l(t)$.\nAs shown in Fig. 2, MADDPG includes both the current network and the target network, with each consisting of an actor and a critic sub-network. Note that network here indicates the deep neural network of DDPG. Here, $\\mathbf{w}_l^{\\mu}$ and $\\mathbf{w}_l^Q$"}, {"title": "B. Enhancing MADDPG with Federated Learning", "content": "are the actor/critic model weights of the current network, whilst $\\mathbf{w}_l^{\\mu'}$ and $\\mathbf{w}_l^{Q'}$ represent the actor/critic model weights of the target network. The current network determines the action of the l-th LEO-MF-RIS as $a_l(t) = \\mu_l(s_l(t) | \\mathbf{w}_l^{\\mu}) + \\mathcal{N}_G$, where $\\mu_l(s_l(t) | \\mathbf{w}_l^{\\mu})$ is the output of the actor network given the input state $s_l(t)$. Notation of $\\mathcal{N}_G$ is defined as Gaussian noise, which enables exploration for potential new actions in the environment. Moreover, the critic network evaluates the Q-value by taking the state and action as inputs, providing an assessment of the expected return as\n$Q_l \\left(s_l(t), a_l(t) | \\mathbf{w}_l^Q\\right) = r_l(t) + \\gamma \\cdot Q_l \\left(s_l(t+1), a_1(t + 1), ..., a_L(t + 1) | \\mathbf{w}_l^{Q'}\\right),$ (24)\nwhere the discount factor $\\gamma \\in [0, 1]$ indicates the importance of future rewards. Note that $a_l(t \\neq l)$ means the actions taken by other LEO agents contributing to the common environment. We define the memory replay buffer $\\mathcal{D}$ with a size of $|\\mathcal{D}|$. The tuple of $(s_l(t), a_l(t), r_l(t), s_l(t + 1))$ will be stored into the memory for further learning. During training of MADDPG, we randomly select X samples from $\\mathcal{D}$ for training, with the loss function given by\n$\\mathcal{L}(\\mathbf{w}_l^Q) = \\frac{1}{X} \\sum_{t=1}^X \\left( Y_{tar} - Q_l \\left(s_l(t), a_1(t), ..., a_L(t) | \\mathbf{w}_l^Q\\right) \\right)^2,$ (25)\nwhere $Y_{tar} = r_l(t) + \\gamma \\cdot Q'_l \\left(s_l(t+1), a_1, ..., a_L | \\mathbf{w}_l^{Q'}\\right)$. Note that $X \\le |\\mathcal{D}|$. The stochastic gradient descent is employed to update the model weights of the current network, with the gradient computed as $\\nabla_{\\mathbf{w}_l^{\\mu}} \\mathcal{L}(\\mathbf{w}_l^Q) \\approx \\mathbb{E}_{a_l(t)} \\nabla_{a_l(t)} Q_l \\left(s_l(t), a_1(t), ..., a_L(t) | \\mathbf{w}_l^Q\\right) \\nabla_{\\mathbf{w}_l^{\\mu}} \\mu_l \\left(s_l(t) | \\mathbf{w}_l^{\\mu}\\right)$. Furthermore, the target network will periodically update the model weights from the current network based on the soft update [17] for both actor-critic sub-networks, which is represented by $\\mathbf{w}_l^{\\mu'} \\leftarrow \\tau_{\\mu} \\mathbf{w}_l^{\\mu} + (1 - \\tau_{\\mu}) \\mathbf{w}_l^{\\mu'}$ and $\\mathbf{w}_l^{Q'} \\leftarrow \\tau_Q \\mathbf{w}_l^Q + (1 - \\tau_Q) \\mathbf{w}_l^{Q'}$, where $0 \\le \\tau_{\\mu}, \\tau_Q \\le 1$ are positive constants indicating the significance of actor parameters of the target and current networks, respectively.\nIn the traditional MADDPG framework, the lack of infor-mation exchange between agents might result in suboptimal solution, especially in highly complex multi-agent environments that require collaborative decision-making. To address this limitation, we propose an enhanced approach by incorporating federated learning (FL) into the MADDPG architecture as the proposed FEMAD scheme. In FEMAD, the model weight of the target critic network from the local LEO-MF-RIS agent are exchanged. We consider the model exchange is performed by the selected LEO edge with the best channel quality. Furthermore, we conduct communication-efficient FL, i.e,, partial nodes of the model are exchanged for preventing high-latency under distant LEO communications [17], [18]. The LEO edge server will aggregate these local models to exchange the implicit information of other LEOs\u2019 policies and potential environmental"}, {"title": "IV. SIMULATION RESULT", "content": "interference, which can be expressed as\n$\\mathbf{w}_{global} = \\sum_{l \\in \\mathcal{L}} \\xi_l \\mathbf{w}_l^{local},$ (26)\nwhere $\\xi_l \\in [0, 1"}]}