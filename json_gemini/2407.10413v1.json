{"title": "Melon Fruit Detection and Quality Assessment Using Generative AI-Based Image Data Augmentation", "authors": ["Seungri Yoon", "Yunseong Cho", "Tae In Ahn"], "abstract": "Monitoring and managing the growth and quality of fruits are very important tasks. To effectively train deep learning models like YOLO for real-time fruit detection, high-quality image datasets are essential. However, such datasets are often lacking in agriculture. Generative AI models can help create high-quality images. In this study, we used MidJourney and Firefly tools to generate images of melon greenhouses and post-harvest fruits through text-to-image, pre-harvest image-to-image, and post-harvest image-to-image methods. We evaluated these AI-generated images using PSNR and SSIM metrics and tested the detection performance of the YOLOv9 model. We also assessed the net quality of real and generated fruits. Our results showed that generative AI could produce images very similar to real ones, especially for post-harvest fruits. The YOLOv9 model detected the generated images well, and the net quality was also measurable. This shows that generative AI can create realistic images useful for fruit detection and quality assessment, indicating its great potential in agriculture. This study highlights the potential of AI-generated images for data augmentation in melon fruit detection and quality assessment and envisions a positive future for generative AI applications in agriculture.", "sections": [{"title": "1 Introduction", "content": "In recent years, rapid advances in artificial intelligence (AI) and deep learning technologies have significantly improved the precision and efficiency of fruit detection and quality assessment [17, 2]. Specifically, the deep learning-based object detection algorithm YOLO (You Only Look Once) has demonstrated high performance in real-time detection, attracting significant attention from researchers [26, 25]. Training these deep learning models effectively requires large-scale, high-quality image datasets [39]. However, in agriculture, there is a serious lack of such large-scale image datasets. This shortage is due to the significant time and resources needed to create datasets that cover crops under various conditions and environments [20]. To address this issue, AI-generated images have recently gained attention [23]. Generative AI models can produce high-quality images through text-to-image, image-to-image, and image-to-video transformations [15]. This technology has great potential to address the problem of limited large-scale image datasets through data augmentation [29].\nSynthetic images created by computer algorithms have been widely used in various fields, including healthcare, fashion, architecture, geospatial studies, and agriculture [5, 3, 8, 22, 27]. Traditional image generation methods, such as parametric techniques [6], ray tracing [24], and physics-based rendering [13], have advanced synthetic image technology. However, each of these methods has limitations: they struggle to adapt to complex shapes [31], have high computational demands and time issues, and lack flexibility [11, 10, 28]. In contrast, generative AI offers substantial benefits for research and development by allowing extensive variations and information to be added to datasets with significantly less time and cost compared to traditional data augmentation techniques [36, 29, 16]. Previous studies on synthetic data enhancement for tasks such as tomato leaf disease classification, pest synthetic image generation, and weed classification [21, 1, 7] show that generative AI is a valuable tool for improving the quality of agricultural data sets.\nMuskmelon, prized for its attractive appearance and flavor, has a high market value. Throughout its growth from fruit set stage to harvest, the fruit undergoes sig-"}, {"title": "2 Materials and Methods", "content": "nificant physiological and morphological changes [14, 12]. During the fruit enlargement stage, rapid growth causes the skin to harden and crack, forming the net pattern, a crucial factor in the commercial value of the melon. To enhance the external quality of muskmelons, it is necessary to analyze the fruit development stages, monitor growth, and manage quality, although this is a challenging task. In this context, fruit detection and quality assessment are crucial research topics in agriculture, significantly impacting crop monitoring, harvesting, quality control, and sorting automation [33].\nThis study aims to explore the potential of generative images for data augmentation by applying and evaluating methodologies for fruit detection and quality assessment. To achieve this, the quality of the generative images was evaluated, melons were detected in the generative images using YOLOv9 fine-tuned with the melon fruit images, and the net evaluation method [37] was applied to assess the external quality of the fruit. Through this, our objective is to confirm the potential of generative images as high-quality data in agriculture and to investigate their practical use."}, {"title": "2.1 Cultivation and data collection", "content": "The cultivation experiment was conducted in a Venlo-type glass greenhouse at the Protected Horticulture Research Institute (NIHHS, Haman, Korea). The muskmelon vari-"}, {"title": "2.2 Generative A\u0399", "content": "To create melon fruit images, we used two popular generative AI tools (Fig.1B): MidJourney (MidJourney Basic Plan, MidJourney, San Francisco, CA, US) and Firefly (Fi"}, {"title": "2.2.1 Text-to-image generation", "content": "Text-to-image generation involves carefully capturing the variations in the image through the topic, style, and parameters of the prompt. In this study, we used the 'describe' command in MidJourney to generate prompts from images and then created images based on these prompts. The images used for the prompts included greenhouse images of melon cultivation and individual fruit images after harvest."}, {"title": "2.2.2 Image-to-image generation (Pre-harvest)", "content": "Compared to text-to-image generation, the image-to-image generation technique references the structure and style of the original image while enhancing clarity and quality, producing accurate and realistic images [28]. Greenhouse images of melon cultivation were used, encompassing various stages of fruit growth, camera angles, lighting, and focus. These diverse images were used as reference images to generate similar structured images."}, {"title": "2.2.3 Image-to-image generation (Post-harvest)", "content": "Melon fruit images focused on individual fruits after harvest were generated for the purpose of evaluating the external quality of the melons."}, {"title": "2.3 YOLOv9", "content": "YOLOv9 is the latest version of real-time object detection technology, achieving significant advancements. Released in February 2024, this version introduces innovative technologies such as PGI (Programmable Gradient Information) and GELAN (Generalized Efficient Layer Aggregation Network). PGI addresses the problem of information being diluted or lost during the forward pass of the neural network, while GELAN emphasizes lightweight design, fast inference, and accuracy, directly addressing information bottlenecks [32]. YOLOv9 outperforms current state-of-the-art models in various metrics, maintaining equal or higher accuracy with fewer parameters. In this study, we trained YOLOv9 using a dataset of 700 real melon images and tested its detection performance on AI-generated images representing various environmental conditions (Fig.1D)."}, {"title": "2.4 Evaluation methods", "content": "Peak Signal to Noise Ratio (PSNR): PSNR is a metric used to evaluate image quality by measuring the ratio of the maximum potential power of the signal (represented by the original image) to the power of disruptive noise (represented by disparities between original and generated images). This ratio is calculated according to Equation 1,\nand the mean squared error (MSE) is estimated according to Equation 2. Higher PSNR values indicate that the generated image is closer to the original image with minimal distortion [28]. Here, $MAX_I$ represents the maximum pixel value, and MSE indicates the pixel-level difference between the generated image (A) and the original image (O), with lower MSE values implying smaller differences between the images."}, {"title": "2.4.1 Evaluation of AI-generated images", "content": "PSNR = 10 log_{10} {\\frac{(MAX_I)^2}{MSE}}\n(1)\nMSE = \\frac{1}{N} \\sum_{i=1}^{N} (O_i - A_i)^2\n(2)\nStructural Similarity Index Measure (SSIM): SSIM is a metric for evaluating the quality of modified or generated images, similar to PSNR. It assesses the correlation between two images (x, y) based on three aspects: Luminance, Contrast, and Structure [35]. Luminance measures the brightness of light, contrast measures the difference in brightness, and structure measures the correlation. These values are calculated using the mean, standard deviation, and covariance of the pixels in the images."}, {"title": "", "content": "SSIM(x, y) = [l(x, y)]^{\\alpha} \\cdot [c(x, y)]^{\\beta} \\cdot [s(x, y)]^{\\gamma}\n(3)"}, {"title": "2.4.2 Accuracy of YOLOv9 for fruit detection", "content": "Intersection over Union (IoU): IoU is a metric that is used to evaluate the accuracy of object detection, to determine whether the detection of individual objects is successful. It has a value between 0 and 1. In computer vision and object detection, bounding boxes are typically represented as rectangles in 2D images. Based on this representation, the IoU between the actual bounding box (Bg, Ground truth) and the predicted bounding box (Ba) is calculated as follows [40]:"}, {"title": "", "content": "IoU = \\frac{Area of overlap between B_g and B_d}{Area of union between B_g and B_a}\n(4)"}, {"title": "2.4.3 Evaluation of net quality in generated images", "content": "Net quality is a major evaluation metric in human visual inspection, evaluated based on the density and uniformity of the net pattern (Fig.1E). To visualize the differences in net quality, 20 fruits with high net quality were selected, and 20 generated images were classified. In this study, to distinguish it from the net, the non-netted exocarp region is referred to as skin. The masks containing only the fruit were then extracted from each dataset. Using a computer vision algorithm, the color of the skin and net were distinguished, and the average area (net density) and standard deviation (net uniformity) of the skin fragments in pixels were calculated [37]."}, {"title": "3 Results and Discussion", "content": "datasets and the original images (Fig.5). The evaluation results showed that the average and standard deviation of PSNR values for text-to-image, image-to-image (pre-harvest), and image-to-image (post-harvest) dataset groups were 27.4\u00b10.6, 27.9\u00b10.05, and 28.8\u00b10.3, respectively (Table 1). The SSIM values, which indicate a higher similarity to the original image when closer to 1, were 0.06\u00b10.02, 0.12\u00b10.03, and 0.42\u00b10.1. These results suggest that images generated through text and pre-harvest references showed a high similarity to the original images, but also had significant changes in brightness, contrast, and structure. In contrast, data augmentation using post-harvest individual fruit images resulted in high similarity to the original images, while also capturing structural features accurately due to the limited background and focused fruit content."}, {"title": "3.1 Evaluation of AI-generated images", "content": "The results of generating net melon images through text prompts are shown in Fig.2A. The two generative AI tools, Midjourney and Firefly, created images focusing on melons grown in greenhouses. However, when attempting to generate net melons (muskmelon variety) using only prompts without reference images, some images of cantaloupe with distinct green lines on the skin were generated. To produce high-quality images, prompt engineering with various word and parameter combinations, along with trial and error, is necessary. In this study, to reduce image variation from prompts, we used Midjourney's prompt generation command (Fig.2B). This command allows the AI to analyze the original image and output semantic features as prompts. As a result, we obtained various prompts, including objects, backgrounds, camera angles and compositions, and styles, which helped us to create a new image set.\nImage-to-image generation refers to a method that enhances the clarity and realism of the original image by referencing the structure and style of a source image. The results generated by referencing pre-harvest fruit images are very realistic, including images from various angles and lighting conditions (Fig.3). This method accurately reflected the detailed characteristics of hydroponic melon cultivation, including planting and training methods and the features of lateral branches, effectively recreating the actual greenhouse environment. Meanwhile, the post-harvest fruit image results detailed the external features of the melon, indicating that generative AI can be useful for evaluating the external quality of fruits (Fig.4).\nIn this study, we augmented data using the three-step image generation methods described earlier, and we evaluated the quantitative similarity between the generated"}, {"title": "3.2 Fruit detection using AI-generated images", "content": "The results of detecting melons at various growth stages using the proposed YOLOv9 image processing algorithm are shown in Fig.6. YOLOv9 achieved a very high performance with an IoU of 0.95 for melon fruit detection using 40 real bounding boxes (Ground truth). This high performance was consistent across various growth stages in the greenhouse, including fruit enlargement, net formation, and maturation, effectively detecting objects even when they were obscured by leaves. Additionally, YOLOv9 effectively detected melons in images generated by the generative AI tools Midjourney and Firefly, just as it did with real images. The generated images included a va-"}, {"title": "", "content": "riety of colors, camera angles, and environmental conditions (e.g., sunny days, cloudy days). The key factors influencing the detection and classification performance of deep learning models include the quality of image data, the image capture conditions, and the hyperparameter settings of each model [33]. However, agricultural environments pose challenges for collecting high-quality data due to dense planting, mutual shading by leaves and crops, intense lighting from sunlight, or shading by greenhouse structures. Therefore, overcoming false positives caused by these structural features of agricultural settings is a critical task for researchers. Large datasets that include a wide range of object classes, lighting conditions, and backgrounds help the model learn extensive features [38]. For example, common datasets like COCO, ImageNet, and Pascal VOC contain millions of annotated images, covering various categories and conditions [34]. In this context, generative AI offers the advantage of recreating diverse cultivation environments without the constraints of time and place, maximizing the quantity and diversity of data available for model development."}, {"title": "3.3 Quality assessment of fruits using AI-generated images", "content": "In this study, we applied a methodology to analyze the pores of muskmelons using computer vision technology and quantified net density and uniformity to assess quality [37]. Fig. 7AB shows representative original images with valid masks and overlapping Regions of Interest (ROI), comparing the nets of high-quality real fruits with those of generated images. Through binarization techniques, we were able to highlight areas of the skin that contrasted with the net as white, although complete separation was challenging (Fig.7C). Using the depth estimation technique, we detected shallow and deep areas in 2D images, allowing us to distinguish between the net and the skin (Fig.7D). Small red-pixel patches of skin were considered individual islands, with lower individual area values indicating higher net density, and lower standard deviation of the area values indicating higher net uniformity (Fig. 7E). This allowed us to quantify the net quality of both real and generated fruits (Fig. 7F). The nets in the AI-generated images detailed specific features of real fruit, such as bumps, cracks, and colors. Since the fruits used in the experiment were selected for their high net quality, both net density and uniformity were high (Fig.7F). The generated fruits showed lower net density and greater uniformity variation, resulting in lower quality evaluations compared to real fruits. However, it is encouraging that the AI-generated images were realistic enough to be used in actual net quality assessment methods."}, {"title": "3.4 Limitations and implications", "content": "The net of a melon is a result of precise irrigation strategies during the growing period and is closely related to sweetness, making it a key indicator of market value [18, 19]. Obtaining a variety of net images through generated images is expected to be effectively used in the development of fruit quality and grading models [4].\nIn this study, we used text-to-image generation, pre-harvest image-to-image generation, and post-harvest image-to-image generation to obtain melon images simulating various environments. Text-to-image generation allows users to intuitively request desired images and easily express creative ideas [9]. However, it may be challenging to generate the desired images due to semantic ambiguity, text dependency, and limited interpretability. However, image-to-image generation produces new images based on reference images, providing specific and consistent results. Nevertheless, it has limitations in terms of transformation and creativity, is highly dependent on the quality of the original image, and the adjustment of detailed features can be more complex.\nDespite these limitations, AI-generated images have shown great potential for research and development by\ndetailing the melon hydroponic cultivation system and the external quality of post-harvest fruits. Beyond melon fruits, generative AI can be used to collect images of various crops at different stages of vegetative and reproductive growth, accurately depict surface conditions to capture physiological disorder images, and obtain images of fruits segmented by quality grades based on marketability. This means that high-quality AI-generated data can improve the performance of automated models related to growth monitoring, pest diagnosis, shipment, and distribution management, in addition to fruit detection and classification.\nWith the rapid advancement of AI generation tools, the results of this study are expected to contribute to the application of generative AI in the fields of agriculture and plant science."}, {"title": "4 Conclusion", "content": "In this study, we used the tools Midjourney and Firefly to generate images of melon cultivation in greenhouses and post-harvest fruit through text-to-image, image-to-image (pre-harvest), and image-to-image (post-harvest) methods. The generated images were evaluated using metrics"}]}