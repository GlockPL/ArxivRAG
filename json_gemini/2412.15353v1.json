{"title": "GeoPro-Net: Learning Interpretable Spatiotemporal Prediction Models through Statistically-Guided Geo-Prototyping", "authors": ["Bang An", "Xun Zhou", "Zirui Zhou", "Ronilo Ragodos", "Zenglin Xu", "Jun Luo"], "abstract": "The problem of forecasting spatiotemporal events such as crimes and accidents is crucial to public safety and city management. Besides accuracy, interpretability is also a key requirement for spatiotemporal forecasting models to justify the decisions. Interpretation of the spatiotemporal forecasting mechanism is, however, challenging due to the complexity of multi-source spatiotemporal features, the non-intuitive nature of spatiotemporal patterns for non-expert users, and the presence of spatial heterogeneity in the data. Currently, no existing deep learning model intrinsically interprets the complex predictive process learned from multi-source spatiotemporal features. To bridge the gap, we propose GeoPro-Net, an intrinsically interpretable spatiotemporal model for spatiotemporal event forecasting problems. GeoPro-Net introduces a novel Geo-concept convolution operation, which employs statistical tests to extract predictive patterns in the input as \"Geo-concepts\", and condenses the \"Geo-concept-encoded\" input through interpretable channel fusion and geographic-based pooling. In addition, GeoPro-Net learns different sets of prototypes of concepts inherently, and projects them to real-world cases for interpretation. Comprehensive experiments and case studies on four real-world datasets demonstrate that GeoPro-Net provides better interpretability while still achieving competitive prediction performance compared with state-of-the-art baselines.", "sections": [{"title": "Introduction", "content": "The spatiotemporal event forecasting problem aims at predicting where and when certain features or events will occur in the geographic space and time. The applications of spatiotemporal event forecasting such as crime prediction and traffic accident forecasting hold significant importance in various domains, including public safety(CPD 2020) and traffic management(Gov 2017). While it is important to make accurate predictions, understanding the predictive process of models in spatiotemporal event forecasting is, if not more, equally important to a wide range of urban stakeholders. This approach assists in justifying government expenditure on unforeseen risks, thereby contributing to more informed decision-making in urban contexts.\nInterpreting spatiotemporal event prediction models is a challenging task. Firstly, spatiotemporal event prediction often involves multi-source input, such as traffic volume, precipitation, and point-of-interests, with complex dependencies and semantics. Interpreting their interplay over space and time is a non-trivial task. Secondly, unlike other problems such as image classification, where a picture can be naturally understood by humans, visualizing high-dimensional spatiotemporal features with post-hoc analysis on a map (e.g., saliency map) is not readily understandable by most individuals without domain knowledge. Thirdly, spatial heterogeneity (Atluri, Karpatne, and Kumar 2018) commonly exists in spatiotemporal event datasets, which implies that the rationale behind the event occurrences might vary significantly from place to place. It poses difficulty in interpreting the modeling process within a heterogeneous space. These challenges call for an intrinsically interpretable model specifically designed for spatiotemporal event forecasting problems.\nHowever, to the best of our knowledge, there has not been any intrinsically interpretable deep learning model for the spatiotemporal event forecasting problem. On the spatiotemporal event model side, early machine learning methods (Drukker, Prucha, and Raciborski 2013; Brunsdon, Fotheringham, and Charlton 1996; Jiang 2015) leveraged regression-based or tree-based models for interpretability but rely on manual feature augmentation, therefore, struggle to capture complex spatiotemporal dependencies in the data. Attention-based spatiotemporal event forecasting methods (Liu et al. 2020; Guo et al. 2019) generate visualizations of scores indicating relevance between input and target locations but fall short of offering insights into the underlying reasons for events at the feature level. On the interpretable machine learning side prototype-based explainers (Chen et al. 2019) are both intrinsically interpretable and naturally understandable by humans when used for image classification. However, visualizing multi-source spatiotemporal features in the same way makes it difficult to be understood. To strengthen the interpretability for abstract and complex features, concept-based models (Koh et al. 2020a) have been introduced to extract high-level information from inputs, making it easier to understand. However, training data must be manually annotated with predefined but interpretable concepts.\nIn this paper, we bridge the research gap by proposing the first intrinsically interpretable deep learning model for spatiotemporal event prediction, named GeoPro-Net. As a classifier, GeoPro-Net predicts if an event will occur at a given geo-location and time based on the spatiotemporal features observed around the location. To unravel the complexity of multi-source spatiotemporal features and transform them into comprehensible insights, we introduce a statistically guided retrieval process to identify multi-scale patterns such as local and global anomalies, thereby filtering noisy spatiotemporal information and alleviating the interpretation difficulty. Furthermore, we incorporate the idea of concepts (Koh et al. 2020a) and structuralize the captured spatiotemporal event patterns into geographic-based concepts (Geo-concepts) via a novel multi-scale hierarchical pooling mechanism. This enables non-expert users to easily understand the extracted and detailed spatial information. Lastly, we learn a set of prototypes, which are representative and predictive combinations of Geo-concepts associated with the two output classes. These prototypes generate predictions through a linear layer and can be projected onto cases in the training set, making predictions interpretable with real-world examples. Comprehensive experiments and case studies on four real-world event datasets in Chicago and New York City demonstrate the faithful interpretability and better prediction accuracy of GeoPro-Net in comparison with other baselines. The code is available at https://github.com/BANG23333/GeoProNet\nOur main contributions are summarized below:\n\u2022 To the best of our knowledge, this is the first prototype-based interpretable framework to learn from spatiotemporal event datasets and explain its reasoning process intrinsically.\n\u2022 We propose a novel spatial conceptualization process to extract Geo-concepts, which are statistically interpretable multi-scale input feature patterns, followed by condensing concepts through channel fusion and geographic-based multi-scale hierarchical pooling.\n\u2022 We propose to use a prototype learning framework to obtain a set of Geo-concepts associated with the occurrence or absence of events. By projecting these prototypes into training cases, we interpret predictions in the context of real-world scenarios."}, {"title": "Related Work", "content": "Interpretable Spatiotemporal Event Forecasting Models traditionally rely on regression based methods (ex. Spatial Autoregressive Model(Brunsdon, Fotheringham, and Charlton 1996) and Geographically Weighted Regression (Drukker, Prucha, and Raciborski 2013)) and tree-based methods (ex. Spatial Decision Tree (Jiang 2015)) on small-scale datasets with limited features. Those methods are inherently explainable via their learned coefficients or tree structures. However, their accuracy is largely limited when complicated spatiotemporal dependencies are involved. Deep learning approaches with enormous parameters (Lv et al. 2019; Yao et al. 2018; Zheyi Pan 2019; An et al. 2023; Meng et al. 2019; Zuo et al. 2021) has been proven effective with superior performance. However, most of the existing spatiotemporal event forecasting deep learning approaches are either black-box models or only partially interpretable. For example, xGAIL (Pan et al. 2020) was proposed to use GAIL-based methods (Ho and Ermon 2016) to draw insights into the decision-making process of taxi drivers. Furthermore, attention-based methods (Guo et al. 2019; Liu et al. 2020; Tang, Xia, and Huang 2023; Ding et al. 2020) are used to interpret the predictive process of forecasting urban events using spatial attention matrix and saliency maps.\nPrototype-based Interpretable Models (Snell, Swersky, and Zemel 2017; Chen et al. 2019) have brought more attention in recent years. Most existing prototype-based interpretable models (Chen et al. 2019; Nauta, van Bree, and Seifert 2021) are limited to image problems, where prototypes are projected as image tensors with RGB channels. Such prototypes are naturally human-understandable. For example, in a bird classification problem, people can easily distinguish different species parts by comparing birds' color, fur, paws, etc. However, such multi-dimensional prototype representations in urban incident problems are not directly interpretable from a human's perspective because a set of traffic speed, volume, and occupancy changing over time and space is not intuitive and self-explainable.\nConcept-Based Interpretable Models label their inputs with high-level concepts. Koh et al. (Koh et al. 2020b) applied this approach by using bone spurs to predict arthritis in X-ray images. These concepts can either be predefined before training or learned during the training process. Essentially, concepts serve as extracted summaries of complex information. The systematic definition of necessary concepts is crucial, as having too few concepts may limit model performance, while an excessive number of concepts can compromise model interpretability."}, {"title": "Preliminaries", "content": "A spatial-temporal field $S \\times T$ is a three-dimensional matrix, where $T = \\{t_1, t_2,..., t_i\\}$ is a study period divided into equal length intervals (e.g., hours, days) and $S = \\{(0,0), s_{(0,1)}, \u2026\u2026\u2026, s_{(m,n)}\\}$ is a $m \\times n$ two-dimension spatial grid partitioned from the study area. Temporal features $F_T \\in \\mathbb{R}^{T \\times f_t}$ (e.g., average temperature, day of week), spatial features $F_s \\in \\mathbb{R}^{m \\times n \\times f_s}$ (e.g., number of POIs), and spatio-temporal features $F_{ST} \\in \\mathbb{R}^{T \\times m \\times n \\times f_{st}}$ (e.g., traffic volume) are mapped to $S \\times T$ field. We denote the total number of features as $f = f_s + f_t + f_{st}$. The detailed list of features, processing steps, and symbol table in this work can be found in Appendix A.\nProblem Definition: Given the socio-environmental features $F_T, F_s, F_{ST}$ of a location $l_m$ and its neighboring locations (e.g., within the distance of r grid cells) in time window $t\\in T$, our problem is to Predict whether an event will occur in the future one-step interval $t_{i+1}$ for location $l_m$. The Objective is to interpret the predictive process while minimizing prediction errors. In this spatiotemporal event"}, {"title": "Methodology", "content": "In this section, we present our GeoPro-Net model to intrinsically interpret the predictive process on the defined spatiotemporal event forecasting problems. Figure 2 demonstrates the proposed model architecture."}, {"title": "Statistically-guided Geo-Concept Encoding", "content": "In cognitive science, the simplicity principle states that the mind tends to seek the simplest available interpretation of observations over complex ones (Feldman 2016). It becomes crucial to extract the most representative information from extensive feature values and consolidate them into basic concepts to facilitate the interpretation of the modeling process. To address such challenges, we design a novel Statistically-guided Spatial Concept Encoding layer (SSCE) as demonstrated in the black dashed box of Figure 2.\nDefinition 1. Local Significance Test $\u03a8_L$. Given a training sample $X \u2208 \\mathbb{R}^{m \\times n \\times t \\times f}$, and a test window $\u039b \u2208 \\mathbb{R}^{d \\times d}$, which is a spatial, temporal, or spatiotemporal sub-region of X, $\u03a8_L(\u039b, F_i) \u2192 \\{True, False\\}$ is a local statistical test function for feature $F_i$ on whether the distribution in $\u039b$ is different from the distribution of $F_i$ in the entire $X$ with \u03b1-level statistical significance with a higher or lower expected value, where \u03b1 is a hyperparameter.\nFor example, a local significance test $\u03a8_L$ can be defined as a Poisson likelihood ratio test (Jung, Kulldorff, and Klassen 2007) on the number of POIs in a $d \u00d7 d$ region of an input sample against the distribution of the number of POIs in all the $d \u00d7 d$ sub-regions in the entire sample. An output of \"True\" for the test suggests that this $d \u00d7 d$ region might be a local hotspot of POIs near the location to be classified. Similarly, we can define a Global Significance Test as follows.\nDefinition 2. Global Significance Test $\u03a8_G$. Given a training sample $X \u2208 \\mathbb{R}^{m \\times n \\times t \\times f}$, and a test window $\u039b$, which is a spatial, temporal, or spatiotemporal sub-region of X, $\u03a8_G(\u039b, F_i) \u2192 \\{True, False\\}$ is a global statistical test function for feature $F_i$ on whether the distribution in $\u039b$ is statistically different from the global distribution of $F_i$ in the entire training set with a higher or lower expected value, with \u03b1-level significance.\n$E_N = \\frac{n(i)}{N}$ (1)\nwhere $n(i)$ is the number of points less than $Y_i$. The value of $Y$ increases with higher $i$. The Kolmogorov-Smirnov test statistic is defined as,\n$\\max_{1 \\leq i \\leq N} (F(Y_i) - \\frac{i-1}{N}, \\frac{i}{N} - F(Y_i)),$ (2)\nwhere $Y$ is the value and $F$ is the theoretical cumulative distribution of the distribution being tested. By performing two-tail tests we can test whether a feature value in a sample is significantly higher or significantly lower than the specified baseline distribution. Note the distribution assumptions vary over different problems, and they are user-defined choices that are replaceable in our solution framework.\nNow we are ready to define Geo-concepts and the concept convolution operation in GeoPro-Net.\nDefinition 3. Geo-concept $\u0398$. Given an input sample $X \u2208 \\mathbb{R}^{m \\times n \\times t \\times f}$, a Geo-concept $\u0398$ of $X$ is a tuple $<\u039b_\u0398, \u03a8, F_i>$, where $\u039b$ is a sub-region of the spatiotemporal area of $X$, $\u03a8$ is a global or local test on feature $F_i$ in $\u039b$, which has an output of \u201cTrue\u201d. Geo-concept is designed to focus on spatiotemporal interoperability, thus the temporal dimension will be flattened by the mean to reduce the total number of generated concepts.\nGeo-concepts encode statistically significant patterns of input features at both local and global scales in each input sample. We design a Statistically guided Spatial Concept Encoding (SSCE) to extract these concepts and convert the input sample into a multi-channel map tensor that records the positions in the input where these Geo-concepts are valid. The process of transforming input features into Geo-concept encoding is done through a set of \u201cConcept Convolution\u201d operations. From the left part of the black dashed box in Figure 2, the Statistically-guided Spatial Concept Encoding (SSCE) starts with scanning the samples from the training set across the study area using multiple user-defined"}, {"title": "Geo-Concept Aggregation", "content": "Geo-concept Channel Fusion In GeoPro-Net, multiple sets of concepts are generated on each input sample by corresponding scanning windows, which increases the amount of extracted concepts and poses challenges for interpretation. To address these issues, we design a Channel Fusion Operation on the different channels of the concept encoding $C$ to consolidate and refine the concept encoding into more concise but still interpretable representations. Especially, for each window size of the same test (i.e., channels), we learn a weight matrix $w_i$ with the same dimensions as each raw concept encoding channel and combine the channels as a weighted some of the features. Formally,\n$CF_O = \\sum_{\u039b_i=1}^k CF,\u0398,\u039b_i * w_i$, where $\u2211_{i=1}W_i = 1^{m\u00d7n}$ (4)\nHere $CF,\u0398,\u039b_i$ represents the encoded input channel for feature $F$ convoluted by concept $\u0398$ with a scanning window of $\u039b_i$, which is combined into a single channel for feature $F$ and $\u0398$, denoted as $CF,\u0398$, and \u2217 is the Hadamard product. Eventually, we obtain a fused concept tensor $C' \u2208 \\mathbb{R}^{(f_s+f_{st}) \\times m \\times n \\times 4}$\nGeo-concept Pooling. To further enhance the semantic"}, {"title": "Concept Prototype Layer", "content": "In GeoPro-Net, the prototype layer is illustrated on the right part of Figure 2. The prototype layer is a learnable parameter $P' \u2208 [\\mathbb{R}^{K \\times f' \\times q \\times 4}$, where each prototype is a vector and $K$ is the number of prototypes in our model. K is a hyperparameter and can be adjusted. The concept prototypes share the same dimension as pooled Geo-concept encoding and will be learned to be close to a subset of pooled concepts during training. The prototype learning is related to case-based classifications (Priebe 2003)(Chen et al. 2019)(Bien and Tibshirani 2011), and K representative prototypes are learned to be compared with unseen testing samples. Given a Geo-concept encoded testing sample $C \u2208 \\mathbb{R}^{f' \\times q \\times 4}$, the squared $L_2$ distances to a set of prototypes $P' \u2208 \\mathbb{R}^{K \\times f' \\times q \\times 4}$ are inverted into K similarity scores,\n$Sim(C, P_k) = \\frac{1}{\\|C - P_k \\|^2}$ (5)\nwhere $p$ is the kth learned prototype vector. Lastly, all similarity scores are connected to classifications, distinguishing the occurrence of an event versus no event, through a fully connected layer. The coefficients of connections indicate the linear correlation between prototypes and their corresponding class."}, {"title": "Optimization", "content": "The training of GeoPro-Net requires diversifying and disambiguating the learned prototypes to ensure representability and interpretability. This section outlines three regularization terms and a prototype projection process to achieve this goal. Related prototype-based models (Chen et al. 2019)(Yao et al. 2019) demonstrate the effectiveness of diversifying and disambiguating prototypes by using such regularization. Specifically, the $Dlv$ (Diversity) term encourages model learning different prototypes, $Sep$ (Separation) term pushes encoded concepts vector to stay away from the prototypes not of its class, and $Clst$ (Cluster) encourages encoded concepts vector to be close to the prototype of its class.\n$Dilv = \\min_{P_i \\in P, P_j \\in P \\atop i \\neq j} \\frac{1}{||P_i - P_j||^2},$\n(6)\n$Sep = \\frac{1}{n}\\sum_{i=1}^{n} \\min_{P_j \\in P \\atop y_i \\neq j} \\min_{z \u2208 (f(x_i))} ||z - P_j ||^2,$ (7)\n$Clst = \\frac{1}{n}\\sum_{i=1}^{n} \\min_{P_j \\in P \\atop y_i} \\min_{z \u2208 (f(x_i))} ||z - P_j ||^2.$ (8)\nThis approach simplifies interpretation by presenting only an appropriate number of significant concepts for each prototype, making the information more comprehensible and interpretable. The overall loss function for training our model is defined as minimizing\n$L = \\frac{1}{n}\\sum_{i=1}^{n}CrsEnt(g(x_i), Y_i) + \u03bb_1Dlv + \u03bb_2Sep + \u03bb_3Clst$ (9)\nwhere the $g()$ is the learned model, and $CrsEnt$ represents the cross-entropy loss,\nComplexity Analysis GeoPro-Net achieves practical scalability with highly efficient inference. The initial preprocessing involves calculating local and global feature distributions via Local Significance Test $\u03a8_L$ and Global Significance Test $\u03a8_G$ across multiple window sizes w over a spatial grid of size m \u00d7 n, with complexity $O(w \u00d7 m \u00d7 n \u00d7 t \u00d7 f)$ per feature $F_i$. Though computationally costly during training, the historical baseline only needs to be calculated once and can be reused during inference, making Concept Convolution more efficient. Once training data is encoded, geo-concepts achieve through Channel Fusion and Geo-concept Pooling, which refines the concept map C by consolidating channels $\u03b8' = \u2211\u03c9 \u00d7 C(F, \u03b8, \u039b)$ and aggregating pooled sub-regions, resulting in complexity of $O(f' \u00d7 m \u00d7 n)$. The resulting Geo-concept tensor, a list of vectors, enables efficient prototype matching. Geo-concept encodings are matched with learned prototypes P, yielding in an efficient complexity of $O(K \u00d7 f' \u00d7 q)$.\nConcept Prototype Projection is a post-training process. To interpret the learned concept prototypes, they are projected back into encoded Geo-concepts from the training set. Each prototype represents a real scenario by demonstrating a sample of encoded concepts. Specifically, we find the sample of encoded concepts with maximum similarity score to every prototype. This set of extracted concepts can be visualized in an easily digestible manner by listing only the most significant ones"}, {"title": "Experiments", "content": "We perform comprehensive experiments using four real-world traffic accident and crime datasets from Chicago and"}]}