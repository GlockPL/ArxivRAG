{"title": "Utilizing RNN for Real-time Cryptocurrency Price Prediction and Trading Strategy Optimization", "authors": ["Shamima Nasrin Tumpa", "Kehelwala Dewage Gayan Maduranga"], "abstract": "This research embarks on the exploration of leveraging Recurrent Neural Network (RNN) for real-time cryptocurrency price prediction and the optimization of trading strategies. Despite the notorious volatility and unpredictability of the cryptocurrency market, traditional forecasting methods and trading strategies often fail to deliver desired results. This study aims to bridge this gap by harnessing the power of RNN, renowned for their proficiency in capturing long-term dependencies and trends in time-series data. Over a concentrated period of ten weeks, the project unfolds through a series of meticulously planned phases, starting with a comprehensive review of the existing literature and the collection of extensive datasets encompassing historical price data, trading volumes and sentiment analysis derived from social networks and news sources. The subsequent weeks are dedicated to data preprocessing, feature engineering, and the iterative development and refinement of the RNN model to accurately predict cryptocurrency prices. This foundation paves the way for the formulation of dynamic trading strategies that are rigorously backtested to assess profitability and risk, culminating in an evaluation phase in which the efficacy of the model and the performance of the trading strategies are thoroughly analyzed. The anticipated outcome of this research is a robust RNN-based predictive model that not only surpasses traditional forecasting methods in accuracy but also empowers traders with optimized strategies tailored for the fast-paced cryptocurrency market. This study not only contributes to the academic discourse on financial market predictions using deep learning techniques, but also offers practical insights and tools for investors navigating the complexities of cryptocurrency trading. Through this endeavor, our goal is to set a precedent for future research to integrate advanced machine learning models with financial trading systems to navigate and profit from the digital currency ecosystem.", "sections": [{"title": "1. Introduction", "content": "The foundation of modern financial systems is predominantly based on fiat currency, which has notable benefits such as divisibility, durability, and ease of transferability. However, fiat currency, being unbacked by a tangible asset, can lead to inflationary pressures and manipulation by centralized authorities, like governments. The centralized control of the monetary supply has historically caused issues like hyperinflation and rising income inequality [6]. Additionally, the financial system's dependence on intermediaries like banks and credit card companies introduces higher costs, delays, and the risk of security breaches [7]. This reliance results in the loss of individuals' control over personal data.\nDespite the limitations, trust in the current financial system is supported by government regulations and legal contracts. However, trust has been breached in the past due to events such as the dot-com bubble in the late 1990s and the 2008 real estate crisis, which led to significant financial losses [8]. These events highlight the need for a more secure, transparent financial system. In 2008, an anonymous entity known as Satoshi Nakamoto introduced blockchain technology, along with the first decentralized cryptocurrency, Bitcoin (BTC), which enabled peer-to-peer (P2P) transactions without the need for third-party intermediaries [9]. Blockchain technology has since gained traction across various industries and has become a subject of extensive research [10].\nCryptocurrencies, powered by blockchain technology, have emerged as a new form of digital currency that employs cryptography to secure and verify transactions [6]. Unlike fiat currencies, cryptocurrencies operate on decentralized networks without the oversight of a central authority. Bitcoin, the first"}, {"title": "2. Literature Review", "content": "Machine learning (ML) has emerged as a key area of artificial intelligence that involves predicting future events based on historical data. Specifically, in the domain of cryptocurrency price prediction, ML models have been applied to forecast market movements, showing enhanced accuracy over traditional financial prediction methods [11]. Numerous techniques like decision trees, support vector machines (SVM), and neural networks (NN) have proven effective for time-series forecasting, especially when predicting the price of digital currencies such as Bitcoin (BTC), Ethereum (ETH), and Litecoin (LTC).\nSeveral studies have demonstrated the efficacy of ML algorithms in cryptocurrency prediction. For instance, one study compared multiple ML models like SVM, Artificial Neural Networks (ANN), and deep learning (DL) for predicting prices of cryptocurrencies including BTC and ETH, concluding that SVM was the most accurate approach [12]. In another study, Long Short-Term Memory (LSTM) models, which are a specialized form of recurrent neural networks (RNNs), were found to produce the lowest prediction error for BTC prices [12].\nBeyond individual models, ensemble methods have also been explored in recent research. One such study combined ANN, K-nearest neighbors (KNN), and gradient-boosted trees to predict the prices of nine cryptocurrencies, showing that ensemble models outperformed standalone models in minimizing prediction errors [1]. In a different study, an ensemble of random forests (RF) and Gradient Boosting Machine (GBM) was used to predict the prices of BTC, ETH, and Ripple (XRP), achieving mean absolute percentage error (MAPE) values between 0.92% and 2.61% [5].\nIn recent years, deep learning models have garnered significant attention due to their ability to process large datasets and discover hidden patterns. In particular, LSTM[13] and Gated Recurrent Units (GRU)[14], which are types of RNNs, have proven particularly adept at financial time-series prediction [11]. A two-stage approach was proposed in one study where ANN and RF models were used to identify relevant features for BTC price prediction before employing LSTM for final forecasts. This method was shown to outperform classical models like ARIMA and SVM [11].\nAdditionally, hybrid models have also been investigated. For instance, a model combining LSTM and GRU for predicting LTC and Monero (XMR) prices achieved higher accuracy compared to single-model approaches like LSTM [5]. Furthermore, recent studies have proposed using convolutional neural networks (CNN) alongside LSTM to improve the accuracy of cryptocurrency price predictions. One study introduced a novel ensemble of LSTM, Bi-LSTM [15], and CNN for predicting hourly BTC, ETH, and XRP prices, achieving highly accurate results [1].\nThese findings indicate the growing efficacy of deep learning models, especially when hybrid approaches are used to improve prediction accuracy. Overall, research continues to explore novel architectures and models to better capture the complexities of cryptocurrency markets."}, {"title": "3. Materials and Method", "content": "In this section, we describe the process followed for data preprocessing and the development of deep learning models aimed at predicting the prices of three major cryptocurrencies: Bitcoin (BTC), Ethereum (ETH), and Litecoin (LTC). The methodology includes six key steps: (1) collection of historical data, (2) exploratory data analysis and visualization, (3) splitting the dataset into training and testing sets, (4) model training, (5) model testing, and (6) performance comparison across models."}, {"title": "3.1. Data Collection and Preprocessing", "content": "The historical price data for BTC, ETH, and LTC were collected from Yahoo Finance, spanning the period from January 1, 2019, to January 1, 2024 [16]. Missing data were addressed using imputation, where the most recent available value was used to fill any gaps, following best practices in time series forecasting [17]. To prepare the data for deep learning models, we"}, {"title": "3.2. Exploratory Data Analysis", "content": "The preprocessed data were visualized to identify potential trends, patterns, and anomalies. Exploratory data analysis helped in understanding the underlying distribution of prices and highlighted significant volatility in the cryptocurrency market [19]. This analysis was crucial for identifying key features that could affect the model's predictions."}, {"title": "3.3. Dataset Splitting", "content": "The dataset was divided into two parts: 80% of the data was allocated for training, and the remaining 20% was set aside for testing. The training set spans from January 1, 2019, to January 1, 2023, while the testing period covers January 1, 2023, to January 1, 2024. This splitting technique follows the common practice for time series forecasting in machine learning, ensuring that models are tested on unseen data [20]."}, {"title": "3.4. Model Development", "content": "Three deep learning models were developed: Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Bidirectional Long Short-Term Memory (Bi-LSTM). These models are well-suited for time series prediction due to their ability to capture temporal dependencies [13, 14, 15]. Each model was implemented using Keras with TensorFlow as the backend [21]. The architecture for each model consisted of two recurrent layers with 100 units each, followed by a dense layer with one unit for output, as proposed by related works in cryptocurrency forecasting [22]."}, {"title": "3.5. Model Training and Testing", "content": "The models were trained using the historical price data, with a batch size of 32 and a varying number of epochs to ensure optimal performance. These hyperparameters were selected based on previous studies that have demonstrated their effectiveness in similar tasks [23]. After training, the models were tested on the unseen 20% test dataset, following the recommended practice for robust model evaluation in financial forecasting [24]."}, {"title": "3.6. Performance Evaluation", "content": "To compare the models' performance, we used the following metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE) [25]. These metrics were used to quantify the difference between the predicted and actual prices, providing a clear picture of each model's accuracy. The model with the smallest error values across these metrics was considered the most accurate."}, {"title": "4. Dataset", "content": "In this study, we implemented a straightforward three-layer network architecture for each of the deep learning models: LSTM, Bi-LSTM, and GRU. Each model's architecture comprised 100 neurons in the deep learning layers, consistent with previous research in time series forecasting [13, 15, 14]. The dataset preparation and preprocessing methods applied in this study are illustrated in Figure 1."}, {"title": "4.1. Data Imputation and Reshaping", "content": "To address missing values, we applied data imputation techniques, where missing data points were replaced with the last available observation. This method of imputation is commonly employed in time series data processing to maintain temporal continuity [17]. Afterward, the dataset was reshaped to accommodate the input requirements of the LSTM, Bi-LSTM, and GRU models, ensuring compatibility for sequential data modeling."}, {"title": "4.2. Normalization", "content": "Normalization was a critical step to ensure that the input features were appropriately scaled for model training, as features with different scales can negatively impact the model's performance. We utilized MinMax scaling, a well-established method for scaling numerical data between a specified range, often [0, 1] [18]. Previous studies have demonstrated that MinMax scaling enhances deep learning model performance, especially in financial and time series data applications [24]."}, {"title": "4.3. Data Splitting", "content": "The data used in this study spans from January 1, 2019, to January 1, 2024, and was divided into training and testing sets in an 80:20 ratio. The training set, comprising 80% of the total data, covers the period from January 1, 2019, to January 1, 2023, while the remaining 20% was reserved for testing, spanning from January 1, 2023, to January 1, 2024. This split ensures that the models are trained on a comprehensive set of data while being evaluated on unseen data to assess generalization performance [20]. All data were obtained from Yahoo Finance and accessed in February 2024 [16]."}, {"title": "4.4. Experimental Setup", "content": "The experiments were conducted using Python 3, along with key libraries for numerical computation, data processing, and deep learning. We utilized NumPy for numerical operations, Pandas for data manipulation, and Matplotlib for visualizing the data. For model development, Keras and scikit-learn (sklearn) were employed as the primary deep learning frameworks [21]."}, {"title": "5. Recurrent Neural Network (RNN) Models", "content": ""}, {"title": "5.1. Long Short-Term Memory (LSTM)", "content": "Long Short-Term Memory (LSTM) networks, originally introduced to tackle the challenges of traditional Recurrent Neural Networks (RNNs), are specifically designed to handle long-term dependencies in sequential data [13]. One of the key benefits of LSTMs is their ability to mitigate the vanishing gradient problem, which typically hinders the performance of standard RNNs when dealing with long sequences. LSTMs achieve this by employing a sophisticated memory structure that selectively retains or forgets information as required.\nThe core building block of the LSTM architecture is the memory cell, which is equipped with three gates: the input gate, forget gate, and output gate. These gates control the flow of information throughout the network. The input gate determines how much of the new input should be stored in the cell, the forget gate decides which information should be discarded, and the output gate manages the information to be passed to the next layer. This selective gating mechanism allows LSTMs to store relevant information over extended time periods, making them highly effective for time-series predictions and other sequential tasks.\nThe forward pass through an LSTM at each time step t can be mathematically expressed through the following equations:\n$i_{t} = \\sigma(W_{i}[h_{t-1}, x_{t}] + b_{i})$ (1)\n$f_{t} = \\sigma(W_{f}[h_{t-1}, x_{t}] + b_{f})$ (2)\n$\\tilde{C}_{t} = f_{t}. C_{t-1} + i_{t} \\cdot tanh(W_{c}[h_{t-1}, x_{t}] + b_{c})$ (3)\n$O_{t} = \\sigma(W_{o}[h_{t-1}, x_{t}] + b_{o})$ (4)\n$h_{t} = O_{t}tanh(c_{t})$ (5)\nWhere:\n- $x_{t}$ is the input at time step t,\n- $h_{t}$ is the hidden state at time step t,\n- $c_{t}$ is the cell state at time step t,\n- $i_{t}, f_{t},$ and $o_{t}$ represent the input, forget, and output gates respectively,\n- W and b are the weight matrices and bias vectors.\nThe gates utilize the sigmoid activation function ($\\sigma$) to regulate the amount of information passing through, while the cell state is updated using the hyperbolic tangent function (tanh) to control the output values between -1 and 1, ensuring stability during training. This architectural design allows LSTMs to maintain a strong capability for learning long-term dependencies without suffering from gradient-related issues."}, {"title": "5.2. Gated Recurrent Unit (GRU)", "content": "Gated Recurrent Units (GRUs) were introduced in 2014 as a simplified variant of Long Short-Term Memory (LSTM) networks [14]. While both GRUs and LSTMs are designed to process sequential data and maintain long-term dependencies, GRUs streamline the architecture by reducing the number of gates. Specifically, GRUs utilize only two gates: the update gate, which determines how much of the past information should be retained, and the reset gate, which controls the amount of previous information to forget. This reduction in complexity allows GRUs to be computationally more efficient and easier to train compared to LSTMs, while still delivering comparable performance in many tasks.\nOne of the key advantages of GRUs is their ability to selectively update the hidden state without needing a separate memory cell, as found in LSTMs. This results in a more straightforward and lightweight architecture, particularly beneficial for applications requiring real-time processing. GRUs have demonstrated strong performance in a variety of tasks, including natural language processing (NLP), speech recognition, and financial time-series predictions. Their ability to capture long-range dependencies in sequential data makes them suitable for tasks where memory retention over extended time-frames is critical.\nThe forward pass of the GRU is described by the following equations:\n$u_{t} = \\sigma(W_{u}[h_{t-1}, x_{t}])$ (6)\n$r_{t} = \\sigma(W_{r}[h_{t-1}, x_{t}])$ (7)\n$h_{t} = (1 - u_{t}) h_{t-1} + u_{t} tanh(W[r_{t}.h_{t-1}, u_{t}])$ (8)\nWhere:\n- $u_{t}$ is the update gate, which determines how much of the previous hidden state ($h_{t-1}$) should be retained,\n- $r_{t}$ is the reset gate, controlling how much of the previous hidden state should be forgotten,\n- $h_{t}$ is the updated hidden state,\n- W represents the weight matrices.\nThe update gate, governed by the sigmoid function ($\\sigma$), regulates how much information from the previous hidden state should be incorporated into the current state. The reset gate allows the GRU to forget parts of the previous hidden state, making it easier to focus on new information. This enables GRUs to adapt to both short-term and long-term dependencies without the computational overhead of LSTMs."}, {"title": "5.3. Bidirectional Long Short-Term Memory (Bi-LSTM)", "content": "Bidirectional Long Short-Term Memory (Bi-LSTM) networks are an extension of standard LSTMs designed to capture patterns in sequential data from both forward and backward directions [15]. This bidirectional approach enables the network to consider both past and future information when making predictions or classifications, which is particularly useful for tasks where the context of an event is influenced by surrounding events.\nIn a Bi-LSTM network, two separate layers of LSTM units are used-one that processes the input sequence in the forward direction and another that processes it in the reverse direction. The outputs from both layers are then combined, allowing the model to have a more comprehensive understanding of the data. This structure is particularly advantageous in tasks like natural language processing (NLP), where understanding the relationship between words in both directions can enhance the performance of tasks such as machine translation, sentiment analysis, and text classification.\nThe concept of bidirectional processing was first introduced in the 1997 work on bidirectional recurrent neural networks, applied to speech signal processing [15]. Since then, Bi-LSTMs have gained widespread adoption in a variety of tasks that benefit from understanding both previous and future contexts. This bidirectional framework has been shown to enhance model performance in various fields, including natural language processing, time series prediction, and speech recognition.\nIn this study, we implemented Bi-LSTM models to better capture long-term dependencies in time series data. By processing information in both directions, Bi-LSTM models offer an advantage over unidirectional LSTM models in identifying complex patterns, making them highly suitable for tasks where relationships between past and future events play a crucial role."}, {"title": "5.4. Hyperparameter Tuning", "content": "Hyperparameter optimization is a critical process in machine learning that directly influences the performance of an algorithm. By carefully adjusting key hyperparameters, the accuracy and efficiency of the model can be significantly improved. In this study, tuning the hyperparameters before training the deep learning models was vital for achieving the best possible performance. The primary hyperparameters optimized in our work were the number of neurons per layer, the number of epochs, and the batch size.\nAn epoch represents one complete forward and backward pass through the entire dataset during training, while the batch size refers to the number of data samples processed in each iteration before the model's weights are updated. The batch size plays a crucial role in determining both the model's performance and the duration of training. Smaller batch sizes tend to provide more frequent updates, which can sometimes slow convergence but lead to more precise adjustments of weights. Conversely, larger batch sizes can speed up convergence by processing more data per iteration, though this comes at the cost of increased computational demands.\nIn our experiments, we used batch size 32 to evaluate the impact on the performance of our models. We found that the batch size of 32 yielded good results, offering a balance between training speed and prediction accuracy across all models used in this study."}, {"title": "5.5. Performance Metrics", "content": "To assess the effectiveness of the deep learning models used in this study, we employed four common performance metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). These metrics allow us to quantify the accuracy of the models by comparing predicted values to actual observations. In all cases, smaller metric values indicate better model performance, as they reflect smaller deviations between the predicted and actual values.\nThe performance metrics are defined by the following equations:\n$MSE = \\frac{\\sum(A_{t} - P_{t})^{2}}{n}$ (9)\n$MAE = \\frac{\\sum|A_{t} - P_{t}|}{n}$ (10)\n$RMSE = \\sqrt{\\frac{\\sum(A_{t} - P_{t})^{2}}{n}}$ (11)\n$MAPE = \\frac{100}{n} \\times \\sum \\frac{|A_{t} - P_{t}|}{A_{t}}$ (12)\nWhere $P_{t}$ represents the predicted value at time step t, $A_{t}$ denotes the actual observed value, and n is the total number of time steps considered.\n\\begin{itemize}\n    \\item MSE: calculates the average of the squared differences between predicted and actual values, giving more weight to larger errors.\n    \\item MAE: computes the mean of the absolute differences, providing a straightforward measure of average error.\n    \\item RMSE: is the square root of the MSE, making it easier to interpret in the same units as the original data.\n    \\item MAPE: expresses the error as a percentage, which allows for a more intuitive understanding of model performance across different scales.\n\\end{itemize}\nThese metrics collectively provide a comprehensive evaluation of the models' accuracy in predicting time-series data."}, {"title": "6. Results and Discussion", "content": "The deep learning models-LSTM, GRU, and Bi-LSTM-were implemented using Python libraries such as Scikit-learn, Keras, and TensorFlow. These models were trained on historical data for Bitcoin (BTC), Ethereum (ETH), and Litecoin (LTC) to predict future price movements. The performance of each model was evaluated by comparing the predicted values to the actual values, using performance metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). Lower values across these metrics indicate a closer alignment between predictions and actual prices, suggesting a more accurate model. The code supporting this research is available on GitHub: https://github.com/shamima08/ Cryptocurrency-Price-Prediction-using-RNN."}, {"title": "6.1. Performance Comparison Across Models", "content": "Table 1 summarizes the results of the models across BTC, ETH, and LTC. For BTC, the Bi-LSTM model achieved the best result, demonstrating its capability to capture complex patterns in the price data with an MSE of 0.0001237, MAE of 0.007581, and RMSE of 0.011. On the other hand, the GRU model outperformed the other models for both ETH and LTC, achieving the smallest errors. For ETH, GRU recorded an MSE of 0.0000905, MAE of 0.006697, and RMSE of 0.010, while for LTC, it achieved an MSE of 0.0000730, MAE of 0.006096, and RMSE of 0.009.\nThese results suggest that while Bi-LSTM excelled in predicting BTC, the GRU model provided superior performance for both ETH and LTC. The simpler architecture of GRU, with fewer gates compared to Bi-LSTM, might have allowed for faster and more efficient learning in the cases of ETH and LTC. Meanwhile, the bidirectional nature of Bi-LSTM proved advantageous for capturing patterns in BTC, likely due to its higher volatility and the need to consider both past and future dependencies."}, {"title": "6.2. Model Convergence Analysis", "content": "Figures 5, 6, and 7 illustrate the training and validation loss curves for each of the models applied to BTC, ETH, and LTC, respectively. These plots show the progression of model training across 100 epochs, where a rapid decrease in loss indicates effective learning."}, {"title": "6.3. Comparative Results Across Models", "content": "To further illustrate model performance, Figures 8 to 16 present the comparative results of actual vs. predicted values for each model across BTC, ETH, and LTC.\nFigures 8, 9, and 10 illustrate the comparison between actual and predicted Bitcoin (BTC) prices using the LSTM, GRU, and Bi-LSTM models, respectively. Each figure plots the actual BTC prices (in blue) against the predicted prices (in red) over the time period from 2019 to 2024."}, {"title": "6.4. Summary", "content": "The error values (MSE, MAE, RMSE, and MAPE) and comparative plots provide a comprehensive understanding of model performance across different cryptocurrencies. GRU consistently performed well, especially for ETH and LTC, showing stable convergence and accurate predictions. Bi-LSTM was highly effective for BTC due to its ability to capture bidirectional dependencies, despite slight overfitting tendencies. In general, these models demonstrated strong capabilities in predicting complex time-series data, confirming their suitability for cryptocurrency price forecasting."}, {"title": "7. Conclusion and Future Work", "content": "This study has explored the effectiveness of deep learning models, specifically LSTM, GRU, and Bi-LSTM, for predicting the prices of cryptocurrencies such as Bitcoin (BTC), Ethereum (ETH), and Litecoin (LTC). The results demonstrated that while each model has its strengths, the GRU and Bi-LSTM models provided superior performance for different cryptocurrencies. GRU was particularly effective for ETH and LTC, whereas Bi-LSTM excelled in predicting BTC prices due to its bidirectional processing capability. These findings highlight the importance of selecting appropriate models based on the characteristics of the target data.\nA key challenge for future research is to develop a versatile model capable of predicting the prices of a wide range of cryptocurrencies with high accuracy. Due to the inherent volatility and unique characteristics of each cryptocurrency, creating a universal prediction model remains a complex task. Optimizing such a model to consistently deliver the best performance metrics, such as RMSE and MAPE, across various cryptocurrencies will require further investigation.\nAdditionally, future work could explore the development of hybrid models, such as LSTM-GRU, GRU-BiLSTM, and LSTM-BILSTM, by combining the strengths of multiple deep learning layers. These hybrid architectures have the potential to enhance predictive accuracy by leveraging the complementary features of each model. Further experimentation could determine which combinations offer the best performance across different market conditions and cryptocurrencies. Exploring advanced optimization techniques and incorporating external factors, such as trading volume and market sentiment, could also contribute to the refinement of cryptocurrency price prediction models' best accuracy."}]}