{"title": "LLM Honeypot: Leveraging Large Language Models as Advanced Interactive Honeypot Systems", "authors": ["Hakan T. Otal", "M. Abdullah Canbaz"], "abstract": "The rapid evolution of cyber threats necessitates innovative solutions for detecting and analyzing malicious activity. Honeypots, which are decoy systems designed to lure and interact with attackers, have emerged as a critical component in cybersecurity. In this paper, we present a novel approach to creating realistic and interactive honey-pot systems using Large Language Models (LLMs). By fine-tuning a pre-trained open-source language model on a diverse dataset of attacker-generated commands and responses, we developed a honeypot capable of sophisticated engagement with attackers. Our methodology involved several key steps: data collection and processing, prompt engineering, model selection, and supervised fine-tuning to optimize the model's performance. Evaluation through similarity metrics and live deployment demonstrated that our approach effectively generates accurate and informative responses. The results highlight the potential of LLMs to revolutionize honeypot technology, providing cybersecurity professionals with a powerful tool to detect and analyze malicious activity, thereby enhancing overall security infrastructure.", "sections": [{"title": "I. INTRODUCTION", "content": "In the realm of cybersecurity, honeypots have proven to be a valuable tool for detecting and analyzing malicious activity by serving as decoy systems that attract potential attackers, allowing organizations to study their tactics and enhance their overall security infrastructure [1]. Honeypots come in various forms, including low-interaction honeypots that simulate services with minimal functionality to gather information about general attack patterns [2], and high-interaction honeypots that provide a more complex and realistic environment to engage attackers more thoroughly. These can range from simple emulations of specific services to full-fledged systems that mimic entire networks. Examples include server honeypots [2], which expose network services to attract attackers, and client honeypots, which are designed to be attacked by malicious servers. Additionally, there are specialized honeypots such as malware honey-pots that capture and analyze malicious software, and database honeypots that protect sensitive data repositories. Each type of honeypot serves a unique purpose in a cybersecurity strategy, providing in-sights into different aspects of attacker behavior and tactics, including reducing the costs associated with maintaining security [3]. Deploying honeypots on cloud platforms like Amazon Web Services, Google Cloud, and Microsoft Azure allows for the monitoring and analysis of adversarial activities in a scalable and dynamic environment [4].\nHowever, despite their advantages, honeypots come with certain limitations that must be carefully considered. For instance, low-interaction honey-pots, often favored for their resource efficiency and minimal engagement with attackers, have constrained emulation capabilities. This limitation makes them vulnerable to honeypot fingerprinting, which can potentially reduce their effectiveness [5]. Moreover, these honeypots are easier for attackers to detect and can only gather limited information about the nature of attacks, resulting in restricted responses to threats [6]. Additionally, the use of fixed rate-limiting thresholds in experiments to pre-vent damage may inadvertently reveal their pres-ence to scanners, thus compromising their covert nature [7]. These factors highlight the necessity for a balanced approach in the deployment and config-uration of honeypots to optimize their effectiveness while mitigating inherent limitations.\nIn parallel, recent advances in artificial intelli-gence and natural language processing have given rise to Large Language Models (LLMs) capable of generating human-like text responses [8]. With ap-propriate fine-tuning and prompt engineering, these"}, {"title": "II. METHODOLOGY", "content": "This study develops an LLM-based honeypot to interact with attackers and gather insights into their tactics. As shown in Figure 1, a multi-stage pipeline was created. It starts with collecting and preprocessing a dataset of attacker commands and responses. This data is used for Supervised Fine-Tuning (SFT) on a pre-trained language model, enhancing its ability to mimic a Linux server.\nThe fine-tuned model is then rigorously evalu-ated to ensure it effectively engages with attackers and provides valuable security insights. Finally, the optimized honeypot is deployed to a public IP address for real-world interaction with potential threats.\nOverall, the combination of real-world attacker data, common Linux commands, and detailed com-mand explanations formed a robust training dataset. This combined dataset played a crucial role in fine-tuning the language model to function effectively as a honeypot, capable of providing realistic and intelligent interactions with attackers:\n\u2022 Dataset #1: consisting of 174 commands parsed from the cloud-deployed Cowrie hon-eypot logs [10]."}, {"title": "A. Data Collection and Processing", "content": "To develop the honeypot, we used log records from a Cowrie honeypot on a public cloud endpoint [12]. Cowrie, a medium-interaction honeypot, logs brute-force attacks and shell commands via SSH and Telnet [13], simulating system compromises and subsequent interactions [14].\nWe parsed terminal commands from a public honeypot dataset [10], providing real-world at-tacker data. To enhance the dataset, we included commonly used Linux commands [15], ensuring the model could respond accurately to various scenarios. Additionally, we added 293 command-explanation pairs [16], providing context to im-prove the model's ability to generate accurate re-sponses. This comprehensive approach improved the model's performance and engagement with attackers.\n\u2022 Dataset #2: comprising the top 100 Linux commands [15] with manually populated vari-ations, totaling 160 commands.\n\u2022 Dataset #3: Summaries of 283 Linux com-mands' man pages [16].\nWe processed the collected data to prepare it for language model training, essential for developing our fine-tuned LLM to mimic a honeypot. This involved transforming raw data into a format suit-able for effective training. Initially, we combined multiple datasets to create a collection of 617 Linux commands, covering various range of scenarios to ensure model robustness. Using a local Cowrie honeypot system, we simulated command execu-tion via SSH, capturing responses in a controlled environment and saving these interactions as logs. This resulted in a substantial dataset of command-response pairs.\nNext, we performed text preprocessing on the dataset, including tokenizing the text data and converting tokens into a standardized format for training. These preprocessing steps were crucial for maintaining dataset quality and consistency. By transforming raw data into a structured format, we laid a foundation for training our LLM, contribut-ing to the development of a realistic and interactive honeypot."}, {"title": "B. Prompt Engineering", "content": "By analyzing the prompts utilized in prior re-search [9]-[11], we rigorously tested and refined our prompts to ensure they aligned with our objec-tives. This iterative process of prompt engineering was essential to optimizing the model's interaction with the dataset, ultimately contributing to the development of a highly effective honeypot system."}, {"title": "C. Model Selection", "content": "The rapid development of Large Language Mod-els (LLMs) has provided powerful tools for various applications, including honeypot mimicry. Select-ing the correct model is critical for accurately sim-ulating interactions and balancing computational efficiency with performance for real-time deploy-ment.\nWe tested several recent models, including Llama3 [17], Phi 3 [18], CodeLlama [19], and Codestral [20]. Llama3, with its 8B and 70B vari-ants, offers scalable language processing, while Phi 3, CodeLlama, and Codestral are notable for their focus on code-development tasks. However, our experiments showed that code-centric models like Phi 3, CodeLlama, and Codestral were less effec-tive for honeypot simulation. Larger models (8B and 70B) were too slow, emphasizing the need for computational speed. Smaller models demonstrated sufficient capability, suggesting the importance of balancing model size and efficiency.\nThese findings highlight the need for a model that excels in linguistic proficiency and meets prac-tical demands for speed and resource management. Therefore, we chose the Llama3 8B model for our honeypot LLM."}, {"title": "D. Supervised Fine-Tuning (SFT)", "content": "Supervised Fine-Tuning (SFT) is essential for adapting large pre-trained models to specific tasks. We fine-tuned the foundation models using Llama-Factory [21] with our curated dataset. To enhance training efficiency, we employed Low-Rank Adap-tation (LoRA) [22], which reduces the number of trainable parameters by decomposing the weight matrices into lower-rank representations, allowing for efficient training without sacrificing perfor-mance.\nQuantized Low-Rank Adapters (QLoRA) fur-ther optimized the model by quantizing it to 8-bit precision, reducing its size and computational load while maintaining accuracy. To prevent over-fitting and improve generalization, we incorporated NEFTune noise [23], a regularization technique that introduces noise during training. Additionally, Flash Attention 2 [24] was integrated to enhance attention mechanism efficiency, critical for process-ing long sequences.\nThe final model, fine-tuned to respond like a honeypot server, achieves a balance between ef-ficiency and accuracy using these advanced tech-niques. The model is publicly accessible on Hug-gingface 1 and our GitHub page 2."}, {"title": "III. EXPERIMENTAL RESULTS", "content": "The experimental results of our proposed ap-proach include an analysis of training losses, eval-uation metrics, and a comparative performance as-sessment of different models. We begin by detailing the experimental setup, which involved significant computational resources, utilizing 2 x NVIDIA RTX A6000 (40GB VRAM) GPUs for training the models. Following this, we provide a com-prehensive analysis of the results, highlighting the effectiveness and efficiency of our fine-tuned model in mimicking honeypot behavior."}, {"title": "A. Interactive LLM-Honeypot Framework", "content": "Large Language Models (LLMs) are primarily designed to process and generate natural language text, and as such, they do not natively under-stand network traffic data. To bridge this gap and leverage LLMs' capabilities for cybersecurity ap-plications, we developed a wrapper that interfaces the LLM with network traffic at the IP (Layer 3) level. This wrapper enables the system to act as a vulnerable server, capable of engaging with attackers through realistic interactions.\nIn figure 2, we illustrate the architecture of our LLM-based honeypot system, which integrates an SSH server with a Large Language Model (LLM) to simulate realistic interactions with potential at-tackers. The setup involves the following compo-nents:\n1) Attacker Interface: Represented by the icon on the left, this interface depicts the external entity attempting to interact with the honey-pot system via SSH (Secure Shell) protocol. Attackers use this interface to execute com-mands and probe the system.\n2) SSH Server: The central component of the system, highlighted in purple, is the SSH server. This server acts as the entry point for all incoming SSH connections from attack-ers. It is configured to handle authentication, manage sessions, and relay commands to the integrated LLM.\n3) Large Language Model (LLM): Embedded within the SSH server and shown in green, the LLM is fine-tuned to mimic the behavior of a typical Linux server. Upon receiving commands from the SSH server, the LLM processes these commands and generates ap-propriate responses. This model leverages pre-trained data and fine-tuning techniques to provide realistic and contextually relevant replies.\n4) Interaction Flow: The arrows indicate the flow of interactions. The attacker initiates a connection and sends commands to the SSH server, which then forwards these commands to the LLM. The LLM processes the com-mands and generates responses, which are sent back to the SSH server and subsequently relayed to the attacker.\nBy combining the SSH server with a sophis-ticated LLM, our system can engage attackers in a realistic manner, capturing valuable data on their tactics and techniques. This architecture not only enhances the honeypot's ability to simulate genuine server interactions but also provides a robust framework for analyzing attacker behavior and improving overall cybersecurity defenses."}, {"title": "B. Custom SSH Server Wrapper", "content": "To deploy the final model as a functional honey-pot server, we crafted a custom SSH server using Python's Paramiko library [25]. This server inte-grates our fine-tuned language model to generate realistic responses.\nThe custom SSH server operates as follows:\n1) SSH Connection: User connects to the honeypot server using ssh -T -p 2222 \"root@localhost\", simulating an attack.\n2) Authentication: Server prompts for a pass-word; upon success, user accesses the hon-eypot's command-line interface.\n3) Command Execution: User runs Linux com-mands (e.g., ls -al, echo 'hello world', ifcon-fig), which the SSH server forwards to the integrated LLM.\n4) LLM Response Generation: LLM generates responses mimicking a real Linux server (e.g., listing directory contents, outputting text, displaying network configuration).\n5) Interaction Logging: Honeypot logs all com-mands and responses, capturing data on at-tacker behavior for cybersecurity analysis.\nFor generating inferences, we utilized the Hug-gingface Transformers [26]. Our Custom-SSH server is capable of collecting the IP addresses of incoming SSH connections, username-password pairs (for authentication), and logs of every com-mand along with the generated responses by the model. By incorporating a LLM, our custom SSH server can engage attackers in a realistic manner, providing insights into their actions and enhancing the honeypot's overall functionality."}, {"title": "C. Training Loss Analysis", "content": "As illustrated in Figure 4, the training losses of our fine-tuned model exhibit a steady decline over the training steps. This trend indicates that the model effectively learned from our dataset and adapted well to the task of mimicking a Linux server. During the fine-tuning phase, we employed a learning rate of 5\u00d710\u22124 and conducted a total of 36 training steps. The entire training process was completed in 14 minutes. The consistent decrease in training loss demonstrates the model's capability to improve its performance progressively, thereby enhancing its ability to generate realistic and con-textually appropriate responses."}, {"title": "D. Similarity Analysis with Cowrie Outputs", "content": "To evaluate the performance of our fine-tuned language model, Llama3-8B, we employed multi-ple metrics to measure the similarity between the expected (Cowrie) and generated terminal outputs. We used cosine similarity to quantify the cosine of the angle between two vectors in high-dimensional space, with higher scores indicating better per-formance. Additionally, we used the Jaro-Winkler similarity, which measures the similarity based on matching characters and necessary transpositions, with higher scores indicating closer matches. Fi-nally, we utilized the Levenshtein distance, which calculates the minimum number of single-character edits needed to transform one string into another, with lower scores indicating closer matches. These diverse metrics provided a comprehensive evalua-tion of our model's performance.\nThe results of our evaluation, summarized in Table I, demonstrate the performance of our fine-tuned language model, Llama3-8B, using different similarity and distance metrics over 140 random samples. The fine-tuned model achieved a cosine similarity score of 0.695 (higher is better), indicat-ing a strong match between the expected and gener-ated terminal outputs. The Jaro-Winkler similarity score was 0.599 (higher is better), also reflecting a reasonable level of similarity. The Levenshtein distance was 0.332 (lower is better), suggesting a relatively low number of edits needed to align the generated output with the expected one.\nIn addition, fine-tuned LLM showed improve-ments across all metrics compared to the base model. These results show the effectiveness of our model in generating outputs that closely match the expected responses from a Cowrie honeypot server.\nAs shown in Figure 5, the cosine similarity scores of the outputs generated by LLM exhibit a distribution with most scores concentrated towards higher values, indicating that the model's responses are mostly similar to the expected outputs.\nIt is also worth noting that while some generated outputs may differ but they remain contextually accurate and true for the given commands."}, {"title": "IV. CONCLUSION", "content": "This study introduces an innovative approach to developing interactive and realistic honeypot systems using Large Language Models (LLMs). By fine-tuning a pre-trained open-source language model on attacker-generated commands and re-sponses, we created a sophisticated honeypot that enhances realism and deployment effectiveness.\nOur LLM-based honeypot system improves re-sponse quality and the ability to detect and ana-lyze malicious activities. The integration of LLMs with honeypot technology creates a dynamic, adap-tive system that evolves with emerging threats. Leveraging LLMs' reinforcement learning and at-tention mechanisms, our system refines responses and maintains high contextual relevance, providing deeper insights into attacker behavior and strength-ening security infrastructures.\nFuture work includes expanding training datasets, exploring alternative fine-tuning, and incorporating behavioral analysis. We plan to deploy the system to a public IP for real-world interaction, collecting logs on attack vectors for analysis. This will involve creating knowledge graphs to map attack techniques and provide insights into attacker strategies. Performance analysis can focus on response realism, engagement effectiveness, and robustness using metrics like accuracy and interaction quality, aiming to refine our model and enhance honeypots for better cyber-threat detection and analysis."}]}