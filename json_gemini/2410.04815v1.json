{"title": "A Review of Artificial Intelligence based Biological-Tree Construction: Priorities, Methods, Applications and Trends", "authors": ["Zelin Zang", "Yongjie Xu", "Chenrui Duan", "Jinlin Wu", "Stan Z. Li", "Zhen Lei"], "abstract": "Biological tree analysis serves as a pivotal tool in uncovering the evolutionary and differentiation relationships among organisms, genes, and cells. Its applications span diverse fields including phylogenetics, developmental biology, ecology, and medicine. Traditional tree inference methods, while foundational in early studies, face increasing limitations in processing the large-scale, complex datasets generated by modern high-throughput technologies. Recent advances in deep learning offer promising solutions, providing enhanced data processing and pattern recognition capabilities. However, challenges remain, particularly in accurately representing the inherently discrete and non-Euclidean nature of biological trees. In this review, we first outline the key biological priors fundamental to phylogenetic and differentiation tree analyses, facilitating a deeper interdisciplinary understanding between deep learning researchers and biologists. We then systematically examine the commonly used data formats and databases, serving as a comprehensive resource for model testing and development. We provide a critical analysis of traditional tree generation methods, exploring their underlying biological assumptions, technical characteristics, and limitations. Current developments in deep learning-based tree generation are reviewed, highlighting both recent advancements and existing challenges. Furthermore, we discuss the diverse applications of biological trees across various biological domains. Finally, we propose potential future directions and trends in leveraging deep learning for biological tree research, aiming to guide further exploration and innovation in this field.", "sections": [{"title": "Backgrounds", "content": "Biological tree analysis methods are fundamental tools in biological research, playing a crucial role in revealing evolutionary and differentiation relationships among organisms, genes, and cells. These methods are widely used in phylogenetics, developmental biology, ecology, and medical research, helping scientists gain a deeper understanding of the origins and maintenance mechanisms of biodiversity. In phylogenetics, biological tree analysis involves constructing phylogenetic trees to uncover evolutionary relationships between organisms, providing a basis for taxonomists to classify and name species. In developmental biology and stem cell research, differentiation tree analysis helps researchers trace cell differentiation processes, elucidating how stem cells generate various specialized cell types. In the medical field, biological tree analysis plays a key role in tracking the evolution of pathogens and studying the evolution and differentiation of tumor cells. Although traditional tree inference methods have played an important role in early research, their limitations have become increasingly apparent. In phylogenetic inference, as the scale and complexity of modern biological data continue to grow, these traditional methods face significant challenges. They typically rely on heuristic algorithms and predefined model assumptions, performing well on small-scale datasets. However, when confronted with large-scale, multi-dimensional data generated by high-throughput sequencing technologies, these methods encounter difficulties in terms of computational complexity and scalability. Moreover, traditional methods struggle to effectively incorporate rich biological prior knowledge, particularly when dealing with complex semantics in multi-omics data, making fast and accurate tree construction a challenging task. For differentiation tree analysis in cell differentiation processes, current methods primarily rely on data representation and use visualization for lineage inference. While these visualization-based methods have shown some success, they still face difficulties in generating accurate tree structures, especially when handling dynamic and complex single-cell transcriptomics and multi-omics data. In response to these challenges, deep learning has emerged as a powerful approach to overcome the limitations of traditional methods due to its strong data processing and pattern recognition capabilities. Deep learning models, particularly Transformer models and large-scale language models, have not only achieved remarkable success in natural language processing but have also demonstrated outstanding performance in phylogenetic analysis. Additionally, the powerful transfer learning capability of large-scale language models offers enhanced predictive and inferential power in genomics and protein analysis. Furthermore, multimodal generative models, by integrating various data types (e.g., gene sequences, protein structures, epigenomic data), provide unprecedented analytical capabilities for gene and protein phylogenetic analysis. It is worth emphasizing that deep learning enables the abstraction of phylogenetic and differentiation tree problems into a unified scientific framework. Although these problems focus on different levels (macro-level evolutionary relationships in phylogenetic trees versus micro-level differentiation pathways in differentiation trees), they can be addressed using similar models and methodologies. However, using deep learning to generate tree structures remains a challenging task. While deep learning excels at representing data in Euclidean space, biological trees are inherently discrete and exhibit non-Euclidean logical structures. Developing deep learning models capable of capturing these complex structures is still an ongoing research problem. Current deep learning models have limitations in capturing the nonlinearity and discrete logic of biological trees, presenting a bottleneck for further advancements in this research area. To address these issues and promote the application of deep learning in biological tree research..."}, {"title": "Definition of the Notions and Data", "content": "Different types of biological data play a crucial role in the construction and analysis of biological trees. The following data types are frequently utilized in phylogenetic studies, each providing unique insights into the evolutionary processes and relationships being investigated.\nGene Sequences: Gene sequences are the order of nucleotides in DNA or RNA that encode genetic information. They are one of the most commonly used data types in phylogenetic analysis.\nProtein Sequences: Protein sequences are chains of amino acids that build and regulate physiological processes in organisms. They are critical for studying the evolution of protein functions.\nRNA Sequences: RNA sequences are the nucleotide sequences in RNA molecules that convey and regulate genetic information, particularly significant in studying gene expression regulation and non-coding RNA.\nMorphological Characteristics: Morphological characteristics refer to the physical or structural traits of organisms, often used in phenotypic studies and classification within phylogenetic analysis\nSingle-Cell Data: Single-cell data are sequencing or analytical data obtained from individual cells, typically used to study cell differentiation, development processes, and the cellular basis of diseases.\nThe construction and analysis of biological trees require the use of various algorithms and models. Below are some of the key algorithms and models used in phylogenetic studies, each contributing to the accuracy and efficiency of tree inference.\nHeuristic Algorithms: Heuristic algorithms are optimization methods based on empirical rules, often used to quickly generate approximate solutions but may be limited when applied to large-scale datasets.\nMaximum Likelihood: Maximum likelihood is a statistical method that estimates model parameters by maximizing the likelihood function given observed data, commonly used in constructing phylogenetic trees.\nBayesian Inference: Bayesian inference is a statistical method that updates the posterior distribution of parameters based on prior distribution and observed data, used for parameter estimation and model selection\nDeep Learning Models: Deep learning models are machine learning models composed of multiple layers of neural networks, excelling at handling complex pattern recognition tasks and widely applied in biological tree inference.\nClustering Algorithms: Clustering algorithms partition a dataset into multiple groups or clusters, making data points within the same cluster more similar. They have important applications in biological data classification and phylogenetic tree construction.\nSeveral key concepts are fundamental to understanding phylogenetic trees and the evolutionary relationships they represent. The following concepts are crucial for interpreting the structure and meaning of biological trees.\nCommon Ancestor: A common ancestor is the earliest shared ancestor of multiple descendant species in an evolutionary tree, representing a key node in phylogenetic analysis.\nNode: A node is a point in a phylogenetic tree representing a species or evolutionary event, often used to denote the starting or ending point of divergence or evolutionary pathways.\nBranch: A branch is a line in a phylogenetic tree that represents the relationship between an ancestor and its descendants in the evolutionary process.\nResolution: Resolution is the ability to distinguish between different organisms in a phylogenetic tree. High resolution means a finer distinction of evolutionary relationships.\nLineage: A lineage is a continuous pathway of evolutionary events from an ancestor to its descendants, commonly used to study the evolutionary history of species or cells.\nTree Balance: Tree balance describes the symmetry of branch lengths or structures in a phylogenetic tree, where a balanced tree often indicates a more uniform evolutionary process.\nUnderstanding the mathematical and statistical underpinnings of phylogenetic analysis is critical for interpreting results accurately. The following terms are commonly used in the quantitative aspects of biological tree inference.\nEvolutionary Distance: Evolutionary distance is a measure of the difference between two species or genes on an evolutionary tree, typically calculated based on gene sequence differences.\nSupport Values: Support values are a measure of the reliability of branches in a phylogenetic tree, often obtained through bootstrap resampling.\nTopology: Topology is the arrangement of branches and nodes in a phylogenetic tree, determining how evolutionary relationships are presented\nELBO (Evidence Lower Bound): ELBO is a key metric in variational Bayesian inference, used to approximate the lower bound of the model's log-likelihood\nKL Divergence (Kullback-Leibler Divergence): KL divergence is an asymmetric measure of the difference between two probability distributions, often used in the design of loss functions in deep learning models."}, {"title": "Data Description", "content": "This section provides a comprehensive overview of the biological datasets used in this study, including gene data, RNA data, protein data, and single-cell data. Each subsection details the data collection process, the technologies employed, and the format of the final datasets.\nGene data, comprising DNA or RNA sequences, are essential for understanding the genetic basis of life and the evolutionary relationships between organisms. These data are typically obtained through sequencing technologies.\nThe Gene data collection begins with the extraction of DNA or RNA from biological samples, which could include tissues, blood, or cell cultures. The extraction process typically involves lysing the cells to release nucleic acids, followed by purification steps using methods such as phenol-chloroform extraction or column-based kits like those provided by Qiagen. Once extracted, DNA sequencing preparation involves fragmenting the DNA into smaller pieces using sonication or enzymatic digestion. Adapters, which are short DNA sequences, are then ligated to both ends of each DNA fragment, serving as primers for subsequent amplification and sequencing steps. For RNA sequencing, the process begins with the isolation of mRNA using oligo(dT) beads that bind to the poly-A tails of eukaryotic mRNA, followed by reverse transcription into complementary DNA (cDNA) using reverse transcriptase. The prepared library is then loaded onto a sequencing platform, with the choice of platform depending on the desired read length, throughput, and the complexity of the genome or transcriptome being studied.\nThree mainstream sequencing technologies are commonly used today. Sanger sequencing, developed in the late 1970s, uses chain-termination methods to read nucleotide sequences. Although largely replaced by high-throughput methods, it remains valuable for small-scale projects, validation, and sequencing of short DNA fragments. Next-generation sequencing (NGS) technologies, such as those offered by Illumina, use massively parallel sequencing to generate large volumes of data, making them suitable for large-scale genomic studies, including whole-genome sequencing, transcriptome analysis, and targeted sequencing. Third-generation sequencing (TGS) technologies, like Oxford Nanopore and PacBio, offer longer read lengths, which are particularly useful for resolving complex genomic regions, such as repetitive sequences and structural variants. These platforms also allow for direct RNA sequencing without the need for reverse transcription.\nThe final output from sequencing platforms is typically raw sequence data. A DNA sequence is mathematically represented as a string $xgene$ or $xs$ over the alphabet $ \\sum = \\{A, C, G, T\\} $, where each symbol corresponds to one of the four nucleotides: Adenine (A), Cytosine (C), Guanine (G), and Thymine (T). For instance, a DNA sequence could be represented as x.\nProtein data, including amino acid sequences and three-dimensional structures, are critical for understanding the functional roles of proteins in biological systems.\nProtein data can be represented in two primary ways: sequence data and structural data. Sequence data includes the amino acid sequences of proteins, which determine the primary structure of a protein. Proteins, as chains of amino acids, perform a wide array of functions within living organisms, including catalyzing metabolic reactions, replicating DNA, responding to stimuli, and transporting molecules. On the other hand, structural data refers to the three-dimensional structures of proteins, which are crucial for understanding how proteins function and interact with other molecules.\nThe collection of protein data involves several steps. First, proteins are extracted from cells or tissues using cell lysis, followed by purification methods such as centrifugation, affinity chromatography, or ultrafiltration. Once extracted, the proteins undergo enzymatic digestion into smaller peptides using proteolytic enzymes like trypsin, a crucial step for subsequent mass spectrometry analysis\nStructural analysis is then conducted using techniques such as X-ray crystallography, cryo-electron microscopy (Cryo-EM), or nuclear magnetic resonance (NMR) spectroscopy, which provide detailed insights into the protein's function and interactions.\nMainstream technologies for protein analysis include mass spectrometry (MS), X-ray crystallography, and Cryo-EM. Mass spectrometry is the primary technology for identifying and quantifying proteins by analyzing peptides based on their mass-to-charge ratio, offering detailed information on protein composition and post-translational modifications. X-ray crystallography is the gold standard for determining the high-resolution three-dimensional structures of crystallized proteins, allowing atomic-level visualization. Cryo-EM, an advanced technique for studying large protein complexes and membrane proteins that are difficult to crystallize, offers near-atomic resolution without the need for crystallization.\nProtein data is typically stored in specific formats depending on whether it is sequence or structural data. Sequence data is stored in FASTA format, similar to DNA and RNA sequences. Each protein sequence can be represented as a string $xprotein$ or $xP$, where $xprotein = \\{s_1, s_2 ... s_n\\}$, and $s_i \\in \\sum $ for $ i = \\{1, 2, ..., n\\}$, with $ \\sum = \\{A, C, D, E, . . . , Y\\}$ representing the set of 20 standard amino acids. The sequence is prefixed by a header line beginning with a \u2018>\u02bb symbol, followed by a description. Structural data, on the other hand, is stored in Protein Data Bank (PDB) format. A protein structure is represented by a set of atomic coordinates $C = \\{(x_i, y_i, z_i) \\}$, where $(x_i, y_i, z_i) \\in R^3$ denotes the 3D coordinates of the i-th atom in the protein. These coordinates are essential for studying protein function and interactions.\nSingle-cell data allow researchers to explore cellular heterogeneity and study processes like differentiation and development at the single-cell level.\nSingle-cell data refers to the information obtained from analyzing individual cells, as opposed to bulk cell populations. This approach allows for the investigation of cellular heterogeneity, gene expression dynamics, and the identification of rare cell populations. Single-cell data can include a variety of omics layers, such as transcriptomics (RNA), genomics (DNA), epigenomics (e.g., chromatin accessibility), and proteomics (protein expression). The collection of single-cell data involves isolating individual cells and then performing various omics analyses at the single-cell level. Cell isolation is typically achieved using techniques such as fluorescence-activated cell sorting (FACS), microfluidics (e.g., 10x Genomics Chromium), or droplet-based methods. After isolation, RNA is extracted from each cell and reverse-transcribed into cDNA, which is then amplified and sequenced to provide a transcriptomic profile for each individual cell. For chromatin accessibility analysis, Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) is adapted to single-cell analysis to identify regulatory elements within the genome. Additionally, single-cell multi-omics techniques such as CITE-seq and ASAP-seq integrate multiple omics layers, combining scRNA-seq with surface protein expression (proteomics) or chromatin accessibility (epigenomics), enabling a more comprehensive view of cellular states and functions.\nMainstream technologies for single-cell analysis include scRNA-seq, CITE-seq, and ASAP-seq. Technologies like 10x Genomics Chromium enable the capture and sequencing of RNA from individual cells, providing a high-resolution view of gene expression at the single-cell level, which is particularly valuable for studying cellular heterogeneity, developmental processes, and the cellular basis of diseases. CITE-seq combines scRNA-seq with surface protein profiling using oligonucleotide-tagged antibodies, allowing simultaneous measurement of transcriptomes and protein expression. ASAP-seq integrates chromatin accessibility profiling with protein expression data, offering insights into the regulatory landscape of individual cells.\nSingle-cell data is typically stored in formats that accommodate the complex and high-dimensional nature of the data. As with other sequencing data, raw single-cell RNA sequencing reads are stored in FASTQ format, containing nucleotide sequences and associated quality scores. Formally, a read can be represented as a tuple (s, q), where $s \\in \\sum^n$ is the nucleotide sequence (with $ \\sum = \\{A, C, G,T, N\\}$) and $q \\in Z^n$ represents the quality scores for each base. After alignment to a reference genome or transcriptome, reads are stored in BAM or SAM formats. In these formats, each aligned read can be represented as a tuple (s, a), where a represents the alignment information, including the reference position and mapping quality. For ATAC-seq data, BAM files also store information on chromatin accessibility\nIn multi-omics single-cell data, each individual data point can be represented as $x^i_j$, where $x \\in R^O$ captures the measured values across the different omics layers for a specific gene i in a specific cell j. Here, $x^i_j = \\{x_1,x_2,...,x_O\\}$ corresponds to the measurements for the same gene-cell pair across the O omics layers, such as transcriptomics, proteomics, and epigenomics. This compact representation allows for the integration and analysis of multiple biological dimensions within a single framework."}, {"title": "Commonly Used Data Set", "content": "The advancement of biological research has been greatly facilitated by the development of comprehensive datasets, which are indispensable for understanding complex biological systems. These datasets can be classified into four primary categories: gene-related, protein-related, single-cell, and image-based datasets. Each category contributes uniquely to various fields, offering resources that enable deeper insights into genetic variation, protein structure and function, cellular heterogeneity, and biodiversity.\nGene-related datasets are foundational for exploring genetic variation, gene expression, and genomic annotations. The dbSNP database provides an extensive collection of over 150 million single nucleotide polymorphisms (SNPs) and is integral to studies of genetic variation and genome-wide association studies. Similarly, the Gene Expression Omnibus (GEO) offers a vast repository of gene expression datasets, allowing researchers to explore gene regulation and expression patterns across different species and conditions.\nThe Human Microbiome Project (HMP) is another crucial resource, advancing our understanding of the microbial communities associated with human health and disease. Meanwhile, the Genotype-Tissue Expression (GTEx) Project provides gene expression data across various human tissues, helping to uncover the relationship between genetic variation and gene expression. Furthermore, large-scale efforts like The Cancer Genome Atlas (TCGA) have significantly contributed to cancer research by offering comprehensive genomic profiles of multiple cancer types, aiding in the identification of molecular alterations. In population genetics, the 1000 Genomes Project has been instrumental in providing whole-genome sequencing data from diverse populations, essential for understanding global genetic diversity.\nOther key datasets include Ensembl Genomes, which offers genome annotations across multiple species, and the Genome Aggregation Database (gnomAD), which aggregates exome and genome data, providing crucial allele frequency information for variant interpretation in both research and clinical contexts.\nUnderstanding protein structure, function, and interactions is central to many biological processes, and protein-related datasets are critical in this context. The Protein Data Bank (PDB) is a fundamental resource containing a vast collection of 3D structures of proteins and nucleic acids, making it indispensable for structural biology and drug discovery efforts. Additionally, PeptideAtlas curates peptides identified through mass spectrometry, supporting large-scale proteomics research and protein expression studies.\nFor the study of protein-protein interactions, the STRING database provides essential data on known and predicted interactions, facilitating the construction of protein interaction networks. UniProt, the most comprehensive protein sequence and functional information repository, is critical for protein annotation and functional studies, offering insights into the biological roles of proteins across species.\nThe emergence of single-cell datasets has revolutionized the understanding of cellular heterogeneity and dynamic processes at the single-cell level. Single-cell transcriptomics, particularly from 10x Genomics, provides high-resolution gene expression data, enabling in-depth analyses of individual cell populations and their roles in tissue development and disease. The Human Cell Atlas (HCA), aiming to create comprehensive reference maps of all human cells, serves as a vital resource for exploring cellular states and types, contributing to our understanding of human biology at an unprecedented scale.\nImage-based datasets are pivotal for integrating computational methods with biological research, particularly in biodiversity and taxonomy studies. For example, the iNaturalist 2021 Dataset (iNat21) leverages citizen science by compiling millions of organism images, making it an invaluable tool for biodiversity monitoring and species identification. DNA barcoding entries from BIOSCAN-1M further enhance biodiversity research by enabling the mapping of global species diversity, supporting ecological studies and species discovery.\nThe Encyclopedia of Life (EOL) aggregates taxonomic data, including images, to aid in biodiversity conservation efforts, while the TREEOFLIFE-10M dataset integrates image data with phylogenetic information, fostering advancements in computational biology and evolutionary studies.\nThe collection and integration of these diverse datasets have dramatically accelerated advancements in biological research. Gene-related datasets have facilitated the exploration of genetic variation and gene expression, while protein-related datasets provide critical insights into protein function and structure. Single-cell datasets have uncovered the complexity of cellular heterogeneity, and image-based datasets are instrumental in biodiversity monitoring and species identification. Together, these resources continue to drive discoveries in genomics, proteomics, and evolutionary biology, offering unprecedented opportunities for future research across multiple disciplines."}, {"title": "Definition and Prior Knowledge of the Tree Construction Problem", "content": "Given a set $S = \\{S_1, S_2, ..., S_n\\}$ of biological entities and a corresponding set $A = \\{a_1, a_2,..., a_n\\}$ of attribute data, the objective is to construct a tree structure $T = (V, E, L)$ that satisfies the following conditions, :\n$V = \\{V_1, V_2, . . ., V_m\\}$,\n$E = \\{C_1, C_2, . . .,C_{m-1}\\}$,\n$L : E \\rightarrow R^+$.\nwhere V is the set of nodes, E is the set of edges, and L is a function mapping edges to positive real numbers, where V includes both the entities in S and their inferred common ancestors or differentiated states, E connects the nodes in V, with each edge $e_k = (v_i, v_j)$ linking two nodes $v_i$ and $v_j$, and L assigns a positive real number $l(e_k)$ to each edge, representing the evolutionary distance, time, or differentiation progression between the connected nodes. The tree T must be acyclic, connected, and optimize an objective function F(T). In this definition, The tree structure is a connected, acyclic graph, and the objective function F(T) can be likelihood, parsimony, or total branch length, depending on the specific application.\nIn the context of evolutionary trees, S represents species, genes, or proteins, and L(ek) typically represents evolutionary distance or time. The objective function F(T) focuses on likelihood under a specific evolutionary model, parsimony, or total branch length.\nFor differentiation trees, S represents cells or developmental states, and L(ek) represents differentiation progression. The objective function F(T) aims to describe differentiation pathways or capture the most parsimonious progression.\nThe objective function F(T) and the constraints for tree construction are determined by prior knowledge. For evolutionary trees, prior knowledge may include evolutionary models, fossil records, or molecular data. For differentiation trees, prior knowledge may include developmental biology insights, gene expression data, or known cell lineage relationships. These prior knowledge sources guide the formulation of the objective function and constraints to ensure that the resulting tree accurately reflects the underlying biological processes."}, {"title": "Prior Knowledge", "content": "When constructing phylogenetic trees using gene sequence data, it is essential to leverage various forms of prior knowledge to enhance the accuracy and reliability of the inferred trees. This section discusses seven key types of prior knowledge, providing both a biological basis and formal mathematical descriptions, along with relevant references.\nConserved regions within gene sequences are sequences that have remained relatively unchanged across different species over evolutionary time. These regions are typically under strong selective pressure, meaning that mutations in these regions are often deleterious and thus purged by natural selection. Such conserved regions can serve as reliable indicators of evolutionary relationships. Mathematically, conserved regions can be represented using an indicator function $I(x^i, x^j)$, where\n$I(x^i,x^j) = \\{\n1, if sequences x^i and x^j share conserved regions\n0, otherwise\n$\nThe similarity between these conserved regions can be quantified by the following equation:\n$d_{conserved}(x^i, x^j) = \\sum_{k=1}^{L} I(x^i_k, x^j_k) \\cdot d(x^i_k, x^j_k)$,\nwhere L represents the length of the sequences, and $d(x^i_k, x^j_k)$ is a distance metric, such as Hamming distance or Jukes-Cantor distance. This approach allows for a focused analysis on regions critical to evolutionary divergence, enhancing the accuracy of tree construction."}, {"title": "Prior Knowledge for Phylogenetic Tree Construction using Protein Structure and Sequence", "content": "When constructing phylogenetic trees using protein sequences and structures, leveraging prior knowledge can significantly enhance the accuracy of the resulting trees. This section discusses key types of prior knowledge, providing both biological context and formal mathematical descriptions, along with relevant references.\nConserved protein domains are specific regions within protein sequences that are preserved across different species due to their critical functional roles. These domains are often associated with essential biological functions and tend to be less variable over evolutionary time. The conservation of these domains can be mathematically represented using an indicator function I(di, dj), where I(di, dj) = 1 if domains di and dj are conserved across sequences, and I(di, dj) = 0 otherwise. The similarity between conserved domains can be expressed as:\n$d^{protein}_{domain} (x^i, x^j) = \\sum_{k=1}^{M} I(d^i_k, d^j_k) \\cdot d(d^i_k, d^j_k)$,\nwhere M is the number of domains, and d(dik, di,k) is the distance metric between corresponding domains dik and dj,k. This metric allows for the focused analysis of regions that are crucial for the protein's function and evolutionary history Evolutionary models are used to describe the probabilistic changes in protein sequences over time. These models account for the biochemical properties of amino acids and the likelihood of certain substitutions occurring more frequently than others. For instance, the JTT model (Jones-Taylor-Thornton model) provides a substitution matrix Q that specifies the rate at which one amino acid is substituted for another over evolutionary time. The probability of substitution can be modeled as:\n$P(t) = e^{Qt}$,\nwhere t represents the evolutionary time, and Q is the rate matrix. This model is critical for estimating the evolutionary distances between protein sequences and constructing accurate phylogenetic trees.\nProtein secondary structures, such as alpha-helices and beta-sheets, are conserved across species when they are essential to the protein's function. These structural elements can be encoded in a matrix S, where each element $S^i_j$ represents the similarity between the secondary structures of sequences $x^i$ and $x^j$. The similarity can be assessed using measures such as the percentage of identical residues in aligned helices or sheets:\n$d_{secondary}(x^i, x^j) = \\sum_{k=1}^{L} S(x^i_k, x^j_k)$,\nwhere L is the length of the aligned sequences. This structural information enhances the accuracy of phylogenetic trees by incorporating the functional and structural constraints that shape protein evolution.\nThe three-dimensional (tertiary) structure of a protein often provides more evolutionary information than its primary sequence alone, as structural features tend to be more conserved. The conservation of tertiary structure can be quantified by superimposing the 3D structures of two proteins and measuring the root-mean-square deviation (RMSD) between corresponding atoms:\n$d_{tertiary}(x^i, x^j) = RMSD(x^i, x^j)$,\nwhere a lower RMSD indicates greater structural similarity. This metric is especially useful for inferring evolutionary relationships when sequence similarity is low but structural features are preserved\nFunctional sites, such as active sites in enzymes or ligand-binding sites, are critical for the protein's function and are often conserved across species. These sites can be identified and compared across sequences, with a focus on residues involved in the active or binding site. The conservation of these sites can be encoded in a function F, where $F(x^i, x^j)$ represents the similarity between the functional sites of sequences $x^i$ and $x^j$:\n$d_{functional}(x^i, x^j) = \\sum_{k=1}^{N} F(x^i_k, x^j_k)$,\nwhere N is the number of residues in the functional site. This prior knowledge helps in accurately reconstructing phylogenetic trees that reflect the conservation of protein function across evolutionary time.\nProtein family classification groups proteins based on sequence and structural similarity, often reflecting common evolutionary origins. These classifications can be used as prior knowledge to constrain the topology of phylogenetic trees. Let C represent the classification, and incorporate it into the tree construction as follows:\n$P(Tree | C) = \\prod_{family \\in C} P(Tree | i)$,\nwhere each family i imposes constraints on the possible tree topologies. This ensures that the resulting phylogenetic tree is consistent with known protein family groupings.\nProteins often co-evolve with other proteins or molecules within the same biological pathway. These co-evolutionary relationships can be inferred from correlated mutations between interacting proteins or domains. The co-evolution can be captured in a matrix C, where $C^{ij}_{ij}$ indicates the strength of the co-evolutionary signal between sequences $x^i$ and $x^j$. This can be incorporated into the tree construction as:\n$d_{co-evolution}(x^i, x^j) = -log(C^{ij}_{ij})$,\nwhere higher values of $C^{ij}_{ij}$ indicate stronger co-evolutionary signals. Incorporating co-evolutionary information helps in reconstructing trees that better reflect the functional interdependencies of proteins."}, {"title": "Prior Knowledge for Constructing Cell Differentiation Trees using Single-Cell Multimodal Data", "content": "When constructing cell differentiation trees using single-cell multimodal data, leveraging prior knowledge is crucial for accurately modeling the complex processes of cellular differentiation. This section discusses key types of prior knowledge, providing both biological context and formal mathematical descriptions, along with relevant references.\nGene expression profiles, which measure the abundance of mRNA transcripts in single cells, provide essential insights into the functional state of a cell. Highly expressed genes often indicate active biological processes and can be used to infer cellular identity and differentiation status. The expression levels of genes can be represented in a matrix E, where $E^j_i$ denotes the expression level of gene j in cell i. The similarity between cells based on their gene expression profiles can be quantified by:\n$d_{expression} (C_i, C_j) = \\sum_{k=1}^{G} (E^k_i - E^k_j)^2$,\nwhere G is the total number of genes. This metric captures the overall difference in gene expression patterns between cells, aiding in the construction of differentiation trees\nRNA velocity is a computational method that estimates the future state of individual cells based on the ratio of spliced and unspliced mRNA transcripts. This provides dynamic information about the direction of cell differentiation at the single-cell level. RNA velocity can be represented as a vector $v_i$ for each cell i, indicating the predicted transcriptional change over time. The distance between cells based on RNA velocity can be defined as:\n$d_{velocity} (C_i, C_j) = ||v_i - v_j||$,\nwhere || || denotes the Euclidean norm. This approach helps in predicting the future states of cells and their differentiation trajectories\nCell type-specific marker genes are genes that are uniquely or highly expressed in particular cell types and are used to identify cell identities during differentiation. The presence or absence of these markers can be encoded in a binary matrix B, where $B_{ij} = 1$ if marker gene j is expressed in cell i, and $B_{ij} = 0$ otherwise. The similarity between cells based on marker gene expression can be calculated as:\n$d_{markers} (C_i, C_j) = \\sum_{k=1}^{M} |B^k_{ik} - B^k_{jk}|$,\nwhere M is the number of marker genes. This information is critical for accurately identifying cell types and understanding the progression of differentiation\nPseudotime analysis orders cells along a continuous trajectory that represents the progression of differentiation. This method infers the relative differentiation time of each cell, allowing the construction of differentiation pathways. Pseudotime can be represented as a scalar T for each cell i, indicating its position along the differentiation trajectory. The distance between cells based on pseudotime can be calculated as:\n$d_{pseudotime} (C_i, C_j) = |\\tau_i - \\tau_j|$\nwhich reflects the temporal distance between cells in their differentiation process. This prior knowledge is instrumental in visualizing and understanding cell differentiation pathways"}, {"title": "Classical Biological Tree Construction Methods", "content": "Distance-based methods are some of the earliest and most computationally efficient techniques for constructing phylogenetic trees, as illustrated in the top section of the diagram. These methods start by calculating genetic or evolutionary distances between sequences to create a distance matrix, which is then used to build an initial tree. Techniques such as UPGMA (Unweighted Pair Group Method with Arithmetic Mean) assume a constant rate of evolution, using the molecular clock to produce a rooted tree. However, this assumption often does not hold in real-world scenarios, leading to potential biases. Neighbor-Joining (NJ) addresses this limitation by constructing an unrooted tree without assuming a constant rate of evolution, instead minimizing the total branch length. More advanced methods like Minimum Evolution (ME) and Balanced Minimum Evolution (BME) further optimize tree topology to minimize overall branch lengths while balancing computational efficiency. While the steps in the diagram show that distance-based methods involve iterative merging of nodes to generate the final tree, they inherently reduce the complexity of the original data into pairwise distances, potentially leading to information loss. Additionally, reliance on assumptions such as the molecular clock in UPGMA can introduce biases. Therefore, these methods are best suited for preliminary analyses or scenarios with limited computational resources.\nMaximum Likelihood (ML) methods, as depicted in the middle section of the diagram, offer a more statistically rigorous approach. They involve selecting an evolutionary substitution model and then searching for tree topologies and branch lengths that maximize the likelihood of the observed sequence data. The diagram illustrates a model selection phase, followed by a tree search and evaluation process, where likelihood values are computed for different tree topologies. Tools like RAxML (Randomized Axelerated Maximum Likelihood) efficiently handle large datasets, offering various evolutionary models. PhyML (Phylogenetic Maximum Likelihood) balances speed and accuracy, while IQ-TREE introduces automated model selection and ultrafast bootstrap methods. However, ML methods are computationally intensive, especially when processing large datasets. Moreover, as shown in the diagram, the maximization process requires careful model selection, as incorrect choices can introduce biases. Thus, while ML methods are powerful and flexible, they require adequate computational resources and evolutionary biology expertise to ensure robust results.\nBayesian Inference (BI) methods, represented in the bottom section of the diagram, offer a comprehensive probabilistic framework for tree estimation. They integrate prior information with observed data to calculate posterior probabilities for various tree topologies. The diagram outlines key steps: model selection, topology exploration, and parameter estimation. Unlike ML methods, BI methods explore the posterior distribution of trees using techniques like Markov Chain Monte Carlo (MCMC). Tools like MrBayes incorporate a wide range of evolutionary models, while BEAST (Bayesian Evolutionary Analysis by Sampling Trees) focuses on divergence time estimation. RevBayes provides flexibility for modeling complex evolutionary processes. The diagram indicates that BI methods use prior distributions for topological structures and branch lengths to guide the exploration process. While Bayesian methods provide probabilistic support and incorporate prior knowledge, they are computationally demanding due to the extensive MCMC sampling required. Furthermore, choosing appropriate priors and models is crucial to avoid biases. Despite these complexities, their ability to offer rigorous probabilistic estimates makes Bayesian methods invaluable for comprehensive phylogenetic studies."}, {"title": "Classical Gene-Based Phylogenetic Tree Methods", "content": "In recent years", "categories": "Bayesian inference methods and alignment-free methods. Bayesian inference has evolved from the early Markov Chain Monte Carlo (MCMC) approach, which samples within tree space to estimate the posterior distribution of evolutionary trees. While MCMC is capable of handling complex evolutionary models and is well-suited for small datasets, it suffers from high computational complexity, particularly with large datasets. MCMC relies on prior knowledge such as Evolutionary Substitution Models (e.g., the Jukes-Cantor model) to describe evolutionary relationships between sequences. Additionally, it incorporates Ancestral Relationship Information to accurately infer species' evolutionary paths\nOne of the early advancements addressing the limitations of MCMC is the coalescent-based approach, represented by ASTRAL. This method leverages multiple gene trees to infer species trees, addressing the issue of incomplete lineage sorting (ILS) by"}]}