{"title": "Exact characterization of \u025b-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation", "authors": ["Alberto Carlevaro", "Teodoro Alamo", "Fabrizio Dabbene", "Maurizio Mongelli"], "abstract": "Probabilistic guarantees on the prediction of data-driven classifiers are necessary to define models that can be considered reliable. This is a key requirement for modern machine learning in which the goodness of a system is measured in terms of trustworthiness, clearly dividing what is safe from what is unsafe. The spirit of this paper is exactly in this direction. First, we introduce a formal definition of e-Safe Decision Region, a subset of the input space in which the prediction of a target (safe) class is probabilistically guaranteed. Second, we prove that, when data come from exponential family distributions, the form of such a region is analytically determined and controllable by design parameters, i.e. the probability of sampling the target class and the confidence on the prediction. However, the request of having exponential data is not always possible. Inspired by this limitation, we developed Multi Cost SVM, an SVM based algorithm that approximates the safe region and is also able to handle unbalanced data. The research is complemented by experiments and code available for reproducibility.", "sections": [{"title": "1 Introduction and Problem Formulation", "content": "Modern machine learning (ML) algorithms face significant uncertainty due to the inherent variability of data, the complexity of model architectures, and challenges in controlling predictions. Developing models that provide consistent and trustworthy results, regardless of data or algorithm variations, is essential Kaur et al. (2022); Li et al. (2023); Liu et al. (2022) and indeed, to prevent undesirable behavior, the artificial intelligence (AI) community has been working on the idea of mitigating this uncertainty by controlling the training sets and parameters of ML models a priori Damiani and Ardagna (2020); Maleki et al. (2020); Menzies and Pecheur (2005); Myllyaho et al. (2021); Tao et al. (2019). In this paper, we take a different a posteriori approach to verify ML models by providing probabilistic certifications of the outcomes to ensure the reliability and robustness of these algorithms. Our research contributes to this by developing a (binary) support vector machine (SVM, Cortes and Vapnik (1995)) based classifier, the Multi Cost SVM algorithm, that offers probabilistic guarantees on its output and is robust to changes in the a priori probability of the events it predicts. The idea comes from the observation that for the special class of data coming from exponential family distributions (e.g., Gaussian, gamma, Chi-squared, etc.) it is possible to draw a \u201cdecision region\u201d of the input parameters (a true classifier) in which the probability of observing a desired event is controlled by the confidence requested on the prediction regardless of the a priori probability of the training data. This idea bridges robust classification and guaranteed predictions, offering a reliable tool for data classification. Therefore, this approach contributes to the development of knowledge in many areas of machine learning classification. Quantile regression, for example, is the statistical reference to which this research belongs Koenker (2005). In fact, the idea of probabilistic certification is the motivation for other theories derived from quantile regression, such as probabilistic scaling (PS) Carlevaro et al. (2023, 2024b) and conformal prediction (CP) Angelopoulos and Bates (2023). From PS this research retrieves the idea of having a scalar parameter (sometimes referred to as \u201cradius\", although this term is somewhat inaccurate since it can also take negative values) to control the output of the classifier that has a confidence in the prediction in the spirit of CP. In this context, previous work, such as Pietraszek and Tanner (2005), attempted to control false positives using alert-management systems without probabilistic guarantees. Others, like Singh et al. (2019), focus on robustness against uncertainty by abstracting possible outputs. Conformity and error control are not however the unique contributions to the reliability of the model. For example, the robustness with respect to the a priori probability of the training data also puts this theory in line with unbalanced classification Wang et al. (2021). In fact, always inspired by the observation that exponential family distribution define classification regions where the effect of the prior probability is concentrated in a bias term, MC SVM is designed such that it profiles a classification function that generalizes to the a priori probability of the data source. The idea at the basis of the algorithm is inbetween ensemble learning Dong et al. (2020) and federated learning Zhang et al. (2021). Specifically, the classifier is simultaneously trained with multiple weighted SVMs to optimize the same vector of learnable parameters, making the algorithm more robust and capable of dealing with data coming from different balanced source probabilities. Thanks to all these factors, this theory is prone to be used in many and various applications. Examples can be numerous too, from healthcare (e.g. detection"}, {"title": "1.1 Contribution", "content": "We consider situations in which an external probabilistic parameter $p_s \\in (0,1)$, that we name safety probability, is known to influence the outcome of our experiments. In words, this parameter can be interpreted as the probability that a given instance of our observed point $x \\in X$ in the parameter space belongs to a given set $S C X$. The parameter $p_s$ is somewhat related to the notion of unbalanced datasets. Indeed, it is very frequent to encounter practical situations in which one observes a possibly large unbalance in binary datasets. For instance, in a production line (imagine, for instance, a line producing electronic circuits) one usually encounters a large number of good situations (i.e. \u201csafe\u201d production) and hopefully a few cases of defective productions (i.e. bad chips). Moreover, the ratio between safe and total number of products (which indeed is governed by $p_s$, at least in expectation) may vary among different production lines, due to different external factors (e.g. quality of the prime materials, workforce). In such cases, it is natural to assume that the safe and unsafe products obey the same distribution, and the changes/unbalances are modeled by the safety probability level. Formally, we may assume that the density of $x \\in X$ is governed by the (Bernoulli) parameter $p_s$ as follows:\n\n$f(x) = f(x|S)p_s + f(x|U)(1 \u2212 p_s),$\n\nwhere $U$ is the complementary event of $S$ and $f(x|S)$, $f(x|U)$ are the densities of the safe and unsafe points.\nMotivated by the above considerations about the importance of obtaining classifiers able to provide provable safety guarantees, in this work we introduce a novel definition of e-Safe Decision Region (\u025b-SDR) as follows:\n\n$\\Phi_\\epsilon = {x : p(S|x) \\geq 1 \u2212 \\epsilon},$\n\nwhere $p(S|x) \\in [0,1]$ denotes the conditional probability (function) that calculates the probability that a certain event $S$ occurs given the observation of an instance $x$. It outlines the set of samples $x$ such that the probability of observing the event $S$ given $x$ is greater or equal than $1 \u2212 \\epsilon$, where $1 \u2013 \\epsilon$ denotes the confidence (and thus \u025b the error, or risk level). In words, a point in \u025b-SDR has a high probability (at least $1 \u2212 \\epsilon$) of being safe. Clearly,"}, {"title": "2 Safety Regions for Exponential Families", "content": "We consider two complementary events S and U, with probabilities $p_s$ and $p_u = 1 - p_s$. To give them a representative meaning, we can consider them respectively as \"Safe\" and \"Unsafe\" configurations, respectively. We consider then a sample space X with probability density function f(x). We assume that the events S and U have a probabilistic effect on x, that is, we consider the density functions f(x|S) and f(x|U) that serve to characterize f(x) in terms of S and U to be expressed as\n\n$f(x) = f(x|S)p_s + f(x|U)p_u \u00b7$"}, {"title": "3 SVM based approximations of the safety region", "content": "Suppose that we have a collection of labelled data points\n\n$Z = {(x_i, y_i)}_{i=1}^n,$\n\nwhere\n\n$y_i =  \\begin{cases}\n +1 & \\text{if } x_i \\text{ has label } S, \\\\\n-1 & \\text{if } x_i \\text{ has label } U.\n\\end{cases}$\n\nSometimes in the text, we will use the notation \u201ci \u2208 [n]\u201d to indicate that the index i varies along all the integers from 1 to n, i.e. i = 1,...,n. We assume that the data in Z has been generated from the distribution in (3). Also, we define the two subsets $Z^+ \\subseteq Z$ and $Z^- \\subseteq Z$ respectively as the subset of data with positive labels (safe data) and the subset of data with negative labels.\n\nRemark 4 (On ps and data unbalance) We note that there exists a probabilistic corre- lation between the safety probability ps underlying the data-generation mechanism (according to the data distribution (3)) and the observed data unbalance between the two classes. In- deed, it is easy to see that the expected cardinality of the set $Z^+$ is just $n\u00b7p_s$. In other words,"}, {"title": "3.1 Multi Cost SVM", "content": "We now present a first (naive) approach for the computation of w and b, based on classical SVM. We would like $yw^T\\varphi(x_i) \u2013 b$ to be negative if $x_i$ is labelled as S (i.e. $y_i = +1$), and positive otherwise. That is, we would like the quantity $y_i (w^T\\varphi(x_i) \u2013 b)$ to be negative with high probability in every situation. Based on this, we now recall the classic SVM opti- mization problem Cortes and Vapnik (1995), leading to a classifier distinguishing between classes S and U:\n\n$\\min_ {\u03c9,b,\u03be_1,...,\u03be_n} \\frac{1}{2}\u03c9^T\u03c9 + \\frac{1}{\u03b7}\\sum_{i=1}^n \u03be_i$\n\ns.t. $y_i(\u03c9^T\\varphi(x_i) \u2013 b) \u2264 \u03be_i \u2212 1, i \u2208 [n]$,\n\n$ \u03be_i \u2265 0, i \u2208 [n].$\n\nThe hyper-parameter \u03b7 > 0 serves to make a trade-off between regularization and misclassi- fication error. Once the value of w and b have been obtained, we could provide the following classifier:\n\n$ y(x) = \\begin{cases}\n +1 & \\text{if } \u03c9^T\\varphi(x) \u2013 b < 0 \\\\\n-1 & \\text{otherwise}.\n\\end{cases}$"}, {"title": "3.2 On the choice of b", "content": "Once the form of the MC-SVM (i.e. the weight vector w) has been determined by solving (17), we can exploit the degree of freedom provided by the bias parameter b to \u201cadapt\u201d the classifier to the specific observed data.\nFormally, we assume to have a calibration set of size \u043f\u0441\n\n$Z_c = {(x_i, y_i)}_{i=1}^{nc} \\subseteq X$\n\nof new labelled data. Again, we define by $Z^S_c$ (resp. $Z^U_c$) the set of positive (resp. negative) data. Note that this data will be associated to a particular safety probability ps, and consequently, a different level of \"unbalance\".\nThe design of b is essential and it can be made in different ways. We revise some of the most suitable ones, at the best of our knowledge, before introducing a new method that takes into account both the confidence and the probability of observing the safe class."}, {"title": "3.2.1 BIAS ADJUSTMENT", "content": "In the literature on unbalanced classification, it has been observed that the low presence of data in one class produces a shift of the separating hyperplane between the two classes towards the minority class, due to the request of reducing the total number of misclassi- fications. In extreme-cases of class imbalance, this would even lead to models labeling all the examples to the majority class He and Ma (2013). In this case, solutions have been proposed to modify the hyperplane bias b to adapt to this unbalance.\nFor instance, N\u00fa\u00f1ez et al. (2017) proposes to recompute the bias b as\n\n$b= \\frac{b^U+b^S}{2}$\n\nwhere\n\n$b^U = \\max_{x \\in Z^U_c} w^T x,  b^S = \\min_{x \\in Z^S_c} w^T x$,\n\nrepresent, respectively, the maximum value of the hyperplane without bias applied to the dataset of unsafe instances $Z^U_c$, and the minimum value of the hyperplane without bias applied to the entries in the safe set $Z^S_c$.\nThe definition of b in (20) has also been extended to take into account the proportion of classes in the dataset, see again N\u00fa\u00f1ez et al. (2017); Shanahan and Roma (2003). More advanced techniques, based on the same idea of shifting the SVM hyperplane, have been proposed in the literature. For instance, in the z-SVM approach Imam et al. (2006), the hyperplane is moved to a position such that the geometric mean of the accuracy of positive and negative samples is maximized for the training data. Clearly, the exact same approach can be translated into our setup."}, {"title": "3.2.2 ADJUSTABLE CLASSIFIER APPROACH", "content": "A second way to design the parameter b stems from the realization that the MC-SVM is a adjustable classifier according to the definition given in Carlevaro et al. (2023) (see in particular Assumption 1). Hence, we can exploit the solution proposed in that work."}, {"title": "4 Conclusions", "content": "Defining safety for data driven systems is an open problem in machine learning and this re- search investigates the question from a modeling perspective. First, the definition of \u03b5-SDR (Definition 2) is given to define formally what safety means in a classification problem (i.\u0435."}]}