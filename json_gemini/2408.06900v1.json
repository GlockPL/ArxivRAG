{"title": "ENTENDRE, A SOCIAL BOT DETECTION TOOL FOR NICHE, FRINGE, AND EXTREME SOCIAL MEDIA", "authors": ["Pranav Venkatesh", "Kami Vinton", "Dhiraj Murthy", "Kellen Sharp", "Akaash Kolluri"], "abstract": "Social bots-automated accounts that generate and spread content on social media-are exploiting\nvulnerabilities in these platforms to manipulate public perception and disseminate disinformation.\nThis has prompted the development of public bot detection services; however, most of these services\nfocus primarily on Twitter, leaving niche platforms vulnerable. Fringe social media platforms such as\nParler, Gab, and Gettr often have minimal moderation, which facilitates the spread of hate speech\nand misinformation. To address this gap, we introduce Entendre, an open-access, scalable, and\nplatform-agnostic bot detection framework. Entendre can process a labeled dataset from any social\nplatform to produce a tailored bot detection model using a random forest classification approach,\nensuring robust social bot detection. We exploit the idea that most social platforms share a generic\ntemplate, where users can post content, approve content, and provide a bio (common data features).\nBy emphasizing general data features over platform-specific ones, Entendre offers rapid extensibility\nat the expense of some accuracy. To demonstrate Entendre's effectiveness, we used it to explore the\npresence of bots among accounts posting racist content on the now-defunct right-wing platform Parler.\nWe examined 233,000 posts from 38,379 unique users and found that 1,916 unique users (4.99%)\nexhibited bot-like behavior. Visualization techniques further revealed that these bots significantly\nimpacted the network, amplifying influential rhetoric and hashtags (e.g., #qanon, #trump, #antilgbt).\nThese preliminary findings underscore the need for tools like Entendre to monitor and assess bot\nactivity across diverse platforms.", "sections": [{"title": "1 Introduction", "content": "A social bot is a computer algorithm designed to automatically generate and share content on social media platforms,\nengaging with human users and mimicking their behavior with the potential to modify it [1]. Social bots cause a\nwide array of adverse effects on social media platforms. Specifically, they exploit platform vulnerabilities, which\ncan include stealing user data, large-scale surveillance, and spreading malware and misinformation [2]. Additionally,\nsocial bots can spread disinformation (e.g., to further the agendas of partisan agendas) [3]. These bots can influence\npublic perceptions and falsely inflate perceived support for radical, fringe agendas that drown out mainstream voices\nin political debates and increase the marginalization of non-dominant groups [3], introduce variability to algorithmic\ntrading [4], and control botnets. When leveraged, these bots can influence public perception and artificially inflate\nperceived support for radical, fringe agendas, which in turn drown out mainstream voices in political debates and\nincrease the marginalization of non-dominant groups [3]. Governments and political actors have previously used social\nbots to successfully manipulate public opinion [5]. Malicious social bots have been responsible for amplifying and\nstrengthening campaigns that disseminate hateful content, manipulate users, and instigate real-world violence [6, 7].\nUnfortunately, social bots can be difficult to detect, and often outmaneuver mitigation algorithms [5]. Likewise, there\nare few, if any, open-source bot detection tools available for fringe social media platforms. Despite the documented,\noutsized societal harms these \u201cniche\u201d platforms facilitate, there remains a paucity of computational tools designed\nspecifically to identify, intercept, and remove or mitigate known causes, such as social bots [3, 6, 8]. As mainstream\nplatforms become more proficient at identifying and removing malicious social bots, they will undoubtedly become\neven more prolific on fringe social media platforms.\nThe malicious use of social bots prompted the creation of public bot detection services. However, their overwhelming\nfocus has been on Twitter [8]. We help address this imbalance and broaden bot detection approaches by employing\nour tool on Parler, a US right wing social media platform. In this paper, we demonstrate its efficacy, while providing\nflexibility and extensibility for it to be quickly adapted to other platforms. Public bot detection services democratize the\ndetection, monitoring, and analysis of bot activity, and help to intercept and mitigate some of their harmful effects. In\naddition to an abundant focus on Twitter, bot-detection tools tend to be platform-specific (e.g., Botometor), and lack\nflexibility to easily adapt them for use on other programs. Likewise, academic and industry developers have neglected\ncreating these tools for use on smaller, niche, and extreme social media platforms (e.g., Parler, Gab, and Gettr). The\nstory of Parler's sudden rise in popularity and subsequent involvement in offline violence is a salient example of the\nurgent need to address this gap. In 2020, Parler's user base grew exponentially over a short period of time once Twitter\nbegan actively enforcing its terms of service (e.g., deleted or labeled misleading posts by Donald Trump and many\nother conservatives [9]). Parler was billed as a Twitter alternative [10]. With no meaningful moderation, the platform\nsoon became a hate-filled, misinformative, echo chamber fomenting further division in the American electorate and\neventually led to coordinated, offline violence [11, 12]. Parler was eventually de-platformed by Amazon for its role in\ncoordinating and fomenting violent acts during the January 6th, U.S. Capitol Insurrection [11]. The platform eventually\nresurfaced under new registration and, after being subjected to stricter content moderation, was relaunched in the\nApple App Store on May 17, 2021 [13] and soon afterward on Google Play on September 2, 2022 [14]. On April 14,\n2023, the media conglomerate Starboard acquired Parler and promptly shut it down the same day. This shut down,\nhowever, may be temporary as the new owners optimistically hint at a 2024 relaunch, citing the precedent set by Apple\nand Google's hosting of X (formerly Twitter), despite the platform's increasingly \"lenient\" speech policies [15]. This\nsituation underscores the necessity of continuous development of tools.\nTo help address the dearth of bot detection tools for extreme, fringe social media platforms, we developed Entendre,\nan open-access bot detection framework for Parler. Entendre checks the activity of requested accounts on Parler and\nutilizes feature-based machine learning to predict the percentage likelihood of the account being a bot via a public\nfacing web application and API. Entendre can also be easily extended to other niche social media platforms such as\nGab and Gettr. Our framework aims to: 1) Provide a scalable, adaptable social bot detection tool optimized for Parler\nand 2) Highlight the urgent need for bot detection on more extreme platforms to better generalize whether humans or\nautomated actors are responsible for particular types of content dissemination. Given the complexities surrounding\ndisinformation and their sources, Entendre extends and develops previous work [1] by specifically focusing on Parler."}, {"title": "2 Previous Work", "content": "Botometer, is an example of a successful, publicly-available service that classifies the extent to which accounts on\nTwitter exhibit bot-like behavior [1]. [7] employed Botometer to determine the concentration of automated accounts\nbehind the #FilmYourHospital COVID-19 misinformation campaign on Twitter. Likewise, Botometer was used to\nidentify the 2016 Russian interference campaign, finding that 4.9% of liberals and 6.2% of conservatives were social\nbots, and they significantly amplified Russian trolls' content. Indeed, a web application using Botometer to visualize"}, {"title": "3 Methods", "content": "To train our machine learning model, we used an open dataset scraped from Parler, containing 183 million posts made\nby 4 million users between August 2018 and January 2021 [11]. We constructed a data subset of verified social bot\nand human accounts. Each post and account contained relevant metadata (followers, hashtags, links, etc). To build\nthe subset, human annotation and automated techniques (flagging suspicious accounts for human review) labeled a\nsignificant amount of social bot and human accounts, yielding 50,000 posts for model training. For the pre-processing\nstep, we normalized features to reduce the training time and ensure data consistency. For missing features, we imputed\nthe missing information through a manual scrape of Parler. For model feature selection, we followed the methodology\noutlined by [18] that focuses on choosing basic account attributes that delineate account usage and deriving nuanced\nattributes of the account."}, {"title": "3.1 Dataset", "content": "To train our machine learning model, we used an open dataset scraped from Parler, containing 183 million posts made\nby 4 million users between August 2018 and January 2021 [11]. We constructed a data subset of verified social bot\nand human accounts. Each post and account contained relevant metadata (followers, hashtags, links, etc). To build\nthe subset, human annotation and automated techniques (flagging suspicious accounts for human review) labeled a\nsignificant amount of social bot and human accounts, yielding 50,000 posts for model training. For the pre-processing\nstep, we normalized features to reduce the training time and ensure data consistency. For missing features, we imputed\nthe missing information through a manual scrape of Parler. For model feature selection, we followed the methodology\noutlined by [18] that focuses on choosing basic account attributes that delineate account usage and deriving nuanced\nattributes of the account."}, {"title": "3.2 Machine Learning Model", "content": "In general, there are three approaches for social bot detection: 1) graph-based, 2) crowdsourcing, and 3) feature-based\nmachine learning [1]. We opted for a feature-based machine learning approach due to its rapid classification when given\nnew data points. Our machine learning algorithm classifies social bot and human accounts based on recent posts and\nmetadata. Extensive literature has pointed to the use of the random forest classification model for robust social bot\ndetection over other models due to its effective classification of numerical inputs [18], performance accuracy, and wide\npopularity for social bot detection [19]. For hyperparameter tuning of the random forest model (node size, number of\ntrees, etc), we followed [20] detailed strategy of sequential model-based optimization to improve the total performance\nof our model."}, {"title": "3.3 Backend API", "content": "Entendre's backend API was written with Express.js. The API, after being provided with a Parler account, will return\nthe percentage likelihood of that account being a bot. While Parler does not have an official API, the platform had"}, {"title": "3.4 Frontend Website", "content": "Entendre is additionally available through a public-facing web application created in React.js (see Figure 1). Like\nBotometer [1], a request initiated from the web application similarly returns the percentage likelihood of an account\nbeing a bot and generates relevant visuals for further analysis, specifically time-based graphs of account activity and\ncharts of most frequently used terms/hashtags."}, {"title": "4 Preliminary Findings", "content": "We employed a prototype version of Entendre over a sample of the open Parler dataset [11] to understand the nature\nof bot interactions and presence on the Parler platform. The prototype version of Entendre exists as a local Python\ntoolchain, allowing for a direct interface with our core bot prediction software to enable for rapid classification large-\nscale classification. The prototype version of Entendre was built prior to obtaining a labeled dataset of bot posts to train\nthe machine learning model. For preliminary testing, the prototype version of Entendre utilizes a mix of fuzzy matching\n(to identify spam content across account posts) and basic heuristics reflective of social bot posts (high volume of posts:\n> 100 posts/day, follower to following ratio: suspiciously close to 1, indicating a network of bots, etc) to predict the\nbot likelihood of a given user. Given the breadth and impact of hateful content on Parler [11], we utilized Entendre to\nexplore the presence of bots among accounts that post racist content. We derived a set of racist users by using a seed set\nof racist posts and expanding the set by adding content connected to it, yielding a working dataset of 233K posts from\n38379 unique users. By feeding the metadata attached with each individual user paired along with their respective posts\nin the sample of Parler into Entendre, we were able to classify 1916 unique users as displaying bot-like activity (4.99%\nof unique users in the dataset)."}, {"title": "5 Conclusion", "content": "In this paper, we introduced Entendre, a robust framework for the detection of bots on niche, fringe, and extreme\nsocial media platforms. Utilizing a prototype version of Entendre, we have shown the nature and presence of bots in\ninstigating and propagating harmful content on alternative platforms, demonstrating the urgent need for accurate and\nscalable bot detection."}]}