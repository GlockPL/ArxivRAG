{"title": "Large Language Models for Autonomous Driving (LLM4AD): Concept, Benchmark, Simulation, and Real-Vehicle Experiment", "authors": ["Can Cui", "Yunsheng Ma", "Zichong Yang", "Yupeng Zhou", "Peiran Liu", "Juanwu Lu", "Lingxi Li", "Yaobin Chen", "Jitesh H. Panchal", "Amr Abdelraouf", "Rohit Gupta", "Kyungtae Han", "Ziran Wang"], "abstract": "With the broader usage and highly successful development of Large Language Models (LLMs), there has been a growth of interest and demand for applying LLMs to autonomous driving technology. Driven by their natural language understanding and reasoning ability, LLMs have the potential to enhance various aspects of autonomous driving systems, from perception and scene understanding to language interaction and decision-making. In this paper, we first introduce novel concepts and approaches to designing LLMs for autonomous driving (LLM4AD). Then, we propose a comprehensive benchmark for evaluating the instruction-following abilities of LLMs within the autonomous driving domain. Furthermore, we conduct a series of experiments on both simulation and real-world vehicle platforms, thoroughly evaluating the performance and potential of our LLM4AD systems. Our research highlights the significant potential of LLMs to enhance various aspects of autonomous vehicle technology, from perception and scene understanding to language interaction and decision-making.", "sections": [{"title": "I. INTRODUCTION", "content": "The recent development of Large Language Models (LLMs) has enhanced numerous cutting-edge technologies, introducing significant advancements across a broad spectrum of applications [1], [2]. Their applications span from the classic nature language process (NLP) tasks like document modification and information extraction to the new emerging scenarios such as LLM-based agents and LLMs for evaluation [1]. One particular application that our study focuses on, among many other domains, is adopting LLMs for autonomous driving (LLM4AD). In this area, various advanced emerging LLM-based algorithms and technologies are continually enhancing the capabilities of autonomous driving technology, leveraging the potential of LLMs to drive innovation and efficiency forward. LLMs can contribute to autonomous systems from high-level decision-making processes to meticulous low-level control. On the high-level side, LLMs can actively engage in adjusting driving mode or decision-making process [3]. Imagine the scenario in which you are seated in an autonomous vehicle, where all you need to do is abstractly express your feelings like \"I do not want my friends to wait for me.\" The LLM4AD system then interprets your emotions and adjusts the vehicle's control strategies accordingly, aligning with your current driving mood or preferences. By contrast, non-LLM-based systems lack the ability to accurately comprehend or interpret humans' intentions only from some vague expressions [4]. Besides, LLMs-based systems have significant potential for achieving personalization in autonomous driving due to their continuous learning capacity. This capability enables it to continuously adapt to individuals' preferences and desires, improving the driving experience according to different users. In addition, LLMs also hold the potential to develop a knowledge-driven system capable of driving like an expert, which can accumulate experience through continuous driving [5].\nOn the other hand, on the low-level side, LLMs can also play a crucial role in the tuning and control process. LLMS have demonstrated the ability to analyze specific scenarios and convert gathered information into mathematical representations to guide low-level controllers [6]. Additionally, LLMS can receive input data from the controller and provide performance updates to aid humans in analyzing the control loop's effectiveness [7]. They can potentially suggest improvements or detect issues to enhance overall performance.\nThe emerging developments of LLM4AD systems raise a crucial question for all related researchers: Why have LLMs become incredibly popular in autonomous driving? What are the advantages of LLM4AD systems over those without LLM integration? Based on current research and developments, we summarize several compelling advantages of integrating LLMs as follows:\n\u2022 Intuitive Language Interaction: LLMs enable intuitive communication between humans and vehicles. Humans can express abstract commands and feelings, while the LLMs can accurately capture the intentions behind human expressions.\n\u2022 Contextual Understanding and Reasoning: LLMs provide contextual understanding from diverse sources such as traffic laws and accident reports, allowing generated decisions to guarantee safety and follow local regulations.\n\u2022 Zero-Shot and Few-Shot Planning: The zero-shot generalization ability enables LLMs to perform tasks they have not been trained on before [8]. This means LLM-based autonomous systems can handle uncommon situations with minimal or no prior experience, enabling them to confidently navigate through 'corner cases.'\n\u2022 Continuous Learning and Personalization: LLMs learn and adapt continuously, providing the ability to follow individual user preferences and improve the driving experience over time.\n\u2022 Interpretability and Trust: LLMs can explain their decisions in natural language, improving trust and understanding between autonomous systems and their users.\nDespite the numerous advantages above, LLMs still have some limitations and potential issues. The most obvious one is sometimes they are inapplicable to real-time tasks in autonomous driving. Specifically, LLMs typically require seconds to process textual information. This delay can pose significant safety concerns and risks in situations requiring immediate, real-time decision-making. Additionally, addressing hallucinations is also a main challenge in LLM4AD systems. \"Hallucination\" refers to instances where LLMs generate output that is factually incorrect, nonsensical, or unrelated to the input prompt. As autonomous driving is a safety-critical task, hallucinations can introduce significant safety and reliability concerns and potentially undermine trust in LLM4AD systems.\nFurthermore, data privacy and security are other potential issues since LLMs collect and process vast amounts of textual data, including potentially sensitive information about their surroundings, passengers, and driving preferences."}, {"title": "B. Overview of This Article", "content": "Our paper presents a comprehensive study on integrating LLMs into autonomous driving systems, from the proposed concept and the creation of an open dataset to the implementation in simulations and real-vehicle experiments. Sec. II introduces the concept and key elements of our proposed LLM4AD framework. Sec. III develops an open benchmark designed to evaluate the performance of LLMs in various autonomous driving tasks, including dataset, evaluation metrics, and baseline model. Sec. IV validates the proposed concepts through extensive simulations, exploring a key perspective: learning from human feedback. Sec. V presents the implementation of our framework on a real-vehicle platform and discusses the results of a series of experiments conducted to validate the system's driving and personalization performance. Sec. VI analyzes the current limitations and outlines promising future research directions for leveraging LLMs in autonomous driving applications. Finally, Sec. VII summarizes the key contributions and findings of this work."}, {"title": "II. CONCEPT OF LLM4AD", "content": "In this section, we introduce a perspective where LLMs play the role of the decision-making \u201cbrain\" within the autonomous driving system. Within our framework, LLMs do not directly affect perception or localization modules, which serve as the vehicle's \"eyes;\" instead, they utilize outputs from these modules as references to guide the high-level decision-making process. By receiving processed data from them, LLMs can enhance informed decision-making, leading to significant improvements in the performance of autonomous vehicles. At the downstream, the vehicle's control module serves as its \u201chands,\u201d executing the driving policy obtained from the LLM-based decision-making process. The symbols we used in the rest of the paper are listed in Tab. I.\nThe overall LLM4AD framework is shown in Fig. 1. In our framework, humans provide instructions and evaluations, where the instructions $I$ and evaluations $F$ along with historical memories $H$, system messages $S$, and context information $C$ serve as inputs to LLMs. The memory module stores corresponding historical interactions between humans and vehicles $H$ for different users. Upon receiving these inputs, LLMs engage in reasoning and produce outputs, including generated Language Model Programs (LMPs) $P$ and reasoning thoughts $R$. The generated LMP is sent to the executor for execution in the environment, while the reasoning thoughts help LLMs generate more reasonable driving policies. It is important to note that this is a general concept, where specific implementations may vary across different applications. However, all applications follow the principles and framework of this concept."}, {"title": "A. Human Instruction and Evaluation", "content": "Human instructions $I$ and evaluations $F$ are directly inputted to LLMs by humans in natural language. $I$ includes the humans' desired needs for the autonomous agent, while human evaluations $F$ are the feedback on the effectiveness of these driving policies."}, {"title": "B. System Message", "content": "The system message $S$ is a way to provide instructions or context to the LLM4AD system at the start of a conversation or task. System messages $S$ allow developers to clearly define the role, constraints, and objectives that LLM4AD systems should follow when engaging with users or working on particular types of tasks.\nSystem messages $S$ in autonomous driving tasks act like a set of high-level guidelines or rules that frame how LLMS should operate and make decisions. These high-level system messages are crucial in defining the basic driving logic, including tasks such as task definition, adherence to traffic rules, description of decision states, and overall goals or metrics to optimize for. They serve as a foundational framework guiding the behavior and decision-making processes of autonomous vehicles on the road. Without a well-crafted system message, LLMs could make incorrect assumptions or unintended strategies."}, {"title": "C. Situation Descriptor", "content": "A situation descriptor transfers the current driving context $C$ into textual descriptions. The situation descriptor follows a predefined structure and employs natural language to provide a detailed textual description of the current driving scenario. It aims to provide LLMs with situational awareness and a comprehensive representation of the current driving scenario, allowing them to make appropriate decisions in the current traffic situation. This could include descriptive statements like \u201cYou are positioned in the leftmost lane of a two-way highway\u201d or \u201cA vehicle is located 50 meters ahead of your current position.\u201d The descriptor translates complex spatial and temporal relationships between different road users and ego vehicles intuitively into the natural language format, allowing context information to be reasoned by LLMs."}, {"title": "D. History Memory and Memory Module", "content": "The memory module stores profiles from various users to enhance driving experiences for all users. Whenever a human user utilizes the LLM4AD system, the system logs the relevant historical interactions $H$ associated with that user. Subsequently, the historical data for the current human user is transmitted to LLMs as input. This particular history interaction $H$ serves as a reference point for the preferences of the current users, therefore guiding the system to improve user experience. After each trip, the interaction data will be updated in the corresponding profile in the memory module. The specifics of the interaction data vary for each system and will be elaborated in their respective sections."}, {"title": "E. Large Language Models", "content": "LLMs serve as the core module in our framework, which will receive all the inputs (history memories (interactions) $H$, system message $S$, situation description $C$, human instruction $I$, and human evaluation $F$) and generate the textual outputs (LMPs $P$ and reasoning thoughts $R$). One important note is that we employ the chain-of-thought prompting [9] technique, which serves as a guiding signal to ensure alignment with human-like reasoning and practical driving considerations. Chain-of-thought presents a structured sequence of reasoning examples to LLMs, bridging existing knowledge gaps. By offering a series of logical and connected steps, LLMs can perform well in complex driving scenarios more effectively."}, {"title": "F. Generated Program", "content": "Inspired by the concept of \"Code as Policy [10],\u201d one of the key outputs from LLMs is the generated LMPs $P$ consisting of executable codes. These codes are used to affect the driving behavior of the ego agent within the environment, and they not only have the ability to generalize to new natural language commands but can also provide precise numerical values such as velocities based on vague linguistic descriptions (e.g., \u201churry,\u201d \u201cturn left\u201d) depending on the driving context."}, {"title": "G. Output Thought", "content": "By employing chain-of-thought prompting [9], LLMs not only generate the program code but also provide a step-by-step explanation of the thought process used to reach that solution. These chains of thoughts represent LLMs' reasoning behind each decision, such as \u201cSince the command is 'hurry,' I will increase the target velocity"}, {"title": "H. Executor", "content": "The executor acts as the bridge between LLMs' textual outputs and the current autonomous driving policy. It takes the generated LMPs $P$ from LLMs and executes it in the corresponding environment. This allows the codes to interact with the current status of the ego vehicle and enables the generated programs to deploy their intended driving behaviors in the real or simulated environment. In our scope, different autonomous driving systems will have some differences in how those codes are executed by their respective executors."}, {"title": "III. AN BENCHMARK DATASET OF LLM4AD", "content": "In this section, we introduce LaMPilot-Bench, the first benchmark of its kind for evaluating the instruction-following capabilities of LLM-based agents in autonomous driving. LaMPilot-Bench consists of three key components: a simulator, a dataset, and an evaluator."}, {"title": "A. Simulator", "content": "The LaMPilot-Bench simulator is built upon HighwayEnv [11], a widely used platform for autonomous driving research and tactical decision-making. HighwayEnv offers various driving models and simulates realistic multi-vehicle interactions. We extend HighwayEnv with interfaces suitable for LLM-based agents and implement custom intersections to diversify the driving scenarios."}, {"title": "B. Dataset", "content": "The LaMPilot dataset consists of 4,900 semi-human-annotated traffic scenes, with a subset of 500 samples split as the test set. Each data sample includes:\n\u2022 An instruction $I$: a high-level task description.\n\u2022 An initial state: used to initialize the simulator.\n\u2022 Goal state criteria: aligned with the instruction $I$.\nThe dataset covers diverse driving scenarios, as shown in Tab. II. For each driving scenario, LaMPilot includes various situations. Taking turning scenarios as an example, the diversity is reflected in several variables, such as the ego vehicle's initial position and state, the specific task (turning left/right or going straight), the number of other vehicles, and their positions and states. The driving model parameters for other vehicles are randomly initialized, and each scenario is assigned a random seed. The dataset also contains a variety of instructions reflecting realistic in-cabin human commands categorized by maneuver types (e.g., routing, lane changing, overtaking) and scenario types (highway and intersection)."}, {"title": "C. Evaluator", "content": "The LaMPilot-Bench evaluator incorporates metrics to assess the safety and efficiency of the agent driving policies. Time-to-collision (TTC) is used to measure the vehicle's ability to maintain safe distances and avoid collisions. In a scenario with n + 1 vehicles (ego vehicle labeled as 0), the TTC ($T_i$) with vehicle i is calculated using the ego vehicle's longitudinal velocity $v_0$ and position $p_0$, and vehicle i's longitudinal velocity $v_i$ and position $p_i$ ($1 \\leq i \\leq n$):\n$T_i = \\frac{(p_0 - p_i) \\cdot (v_0 - v_i)}{||v_0 - v_i||^2}$ (1)\nThe minimum positive TTC value $T_{min}$ among all n vehicles over all time steps t (up to task completion time T) represents the nearest potential collision:\n$T_{min} = \\min_{1<i<n,,1<t<T} T_i$ (2)\nTTC scores are empirically assigned based on a 2-second safety margin, with values above 2 seconds considered safe and given a score of 100:"}, {"title": "D. Experiment Setup", "content": "The experiments are designed to establish baselines for the LaMPilot-Bench. The main objectives are to assess the performance of LLM-based agents in interpreting human instructions within driving contexts and to evaluate the capability of LLMs to generate code for motion planning using provided functional primitives.\nWe conduct benchmarking using various state-of-the-art large language models, including both open-source and proprietary solutions\u00b9:\n\u2022 Llama 2 [13] (llama-2-70b-chat)\n\u2022 PaLM 2 [14] (code-bison)\n\u2022 ChatGPT [15](gpt-3.5-turbo)\n\u2022 GPT-4 [16] (gpt-4)\n\u2022 GPT-4-Turbo [17] (gpt-4-1106-preview)\nWe set a 60-second time limit for each scenario. If a task is not completed within this time frame, the test case is considered a failure, and the simulation is terminated, resulting"}, {"title": "E. Baselines", "content": "1) Heuristic Baselines: In our experiments, we employ two rule-based baseline policies: the Intelligent Driver Model (IDM)[18] and the Minimizing Overall Braking Induced by Lane Changes (MOBIL) principle[19]. IDM describes a rule for updating the acceleration of a vehicle to avoid collisions based on the proximity and relative velocity of the vehicle to the object directly in front. MOBIL is an extension of IDM where a lane change is executed if the prospective new lane offers a more favorable driving scenario and the maneuver can be conducted safely. These baselines can be considered as operating on random chance, as the policy is independent of user instructions but follows predefined rules. Additionally, we include a human performance baseline, where a licensed human driver controls the vehicle in the simulation using arrow keys on the keyboard, following the commands and visuals displayed. This baseline provides a reference for human-level performance on LaMPilot-Bench.\n2) Zero-Shot and Few-Shot Baselines: We also include the zero-shot and few-shot CoT prompting [9] as baseline methods. The zero-shot CoT baseline leverages the prompt \"How to complete the task step by step.\u201d In the few-shot setting, we follow the standard practice [20] by including 3 human-written code exemplars before the test instance. These in-context examples help the model adapt to the tasks in LaMPilot-Bench. The in-context examples are created by a programmer proficient in Python. They are provided with API descriptions and are allowed to write and test their code using the non-test scenarios. The same set of three examples are used for all test cases. The API Docs are also the same across all test cases for both zero-shot and few-shot settings.\n3) Human Feedback Baselines: LLMs have demonstrated proficiency in generating coherent solutions across various tasks without requiring additional fine-tuning. However, when it comes to code generation, especially for complex scenarios, they can produce suboptimal results. The autoregressive nature of these models poses a significant challenge, as tokens generated early in a sequence cannot be modified in the same iteration. This constraint limits the models' ability to refine initial responses, potentially impacting the effectiveness of the generated code [21].\nTo address these challenges and enhance the performance of LLMs on tasks in LaMPilot-Bench, we include the human-in-the-loop baseline introduced in Sec. IV-B, where the LLMs"}, {"title": "G. Conclusion", "content": "In this section, we introduced LaMPilot-Bench, a benchmark for evaluating the instruction-following capabilities of LLM-based agents in AD. Our experiments demonstrated that off-the-shelf LLMs can generate code policies for driving tasks based on human instructions. However, the notable collision rate indicates the need for further research to fully capture the complexities and safety requirements of real-world driving scenarios. As LLMs continue to evolve and integrate"}, {"title": "IV. SIMULATION STUDIES OF LLM4AD", "content": "Simulation is a critical tool in developing and evaluating autonomous driving systems, enabling researchers to safely and efficiently explore diverse driving scenarios and collect training data. In this work, we leverage the CARLA simulator [24] to develop and assess our proposed framework for integrating LLMs into autonomous driving. CARLA provides a realistic and customizable environment well-suited for autonomous driving research.\nOur experiments utilize the official routes from the CARLA Leaderboard 1.0 [25], which consists of 76 routes (50 training routes and 26 testing routes) totaling over 170 km across six towns. The Leaderboard also includes a set of predefined scenarios that the autonomous agent must navigate, covering ten different types of challenging traffic situations, such as control loss and traffic negotiation. The demo for our simulation experiment is publicly available\u00b2.\nIn the Leaderboard 1.0 setup, agents are typically provided with a series of GPS coordinates and route instructions to reach a destination. However, to test the instruction following capabilities of the system powered by LLMs, we modify the setup to provide only natural language navigation instructions based on the agent's current position (e.g., \u201cturn left at the next intersection\u201d). To eliminate the influence of perception on our results, we craft the driving context information using a language generator [26] that leverages CARLA's privileged information.\nThe Leaderboard evaluates agent performance using three key metrics:\n\u2022 Route Completion (RC): measures the percentage of the route distance completed by the agent\n\u2022 Infraction Penalty (IP): tracks various infractions (e.g., collisions, running red lights) committed by the agent, aggregated as a geometric series starting from an ideal base score of 1.0 that is reduced with each infraction\n\u2022 Driving Score (DS): the product of RC and IP, serving as the principal evaluation metric"}, {"title": "B. Human-in-the-Loop Learning", "content": "The main research objective in this section is to develop a human-guided learning pipeline that enables the autonomous agent to continuously learn and improve from human feedback in natural language. While our experiments are conducted in CARLA [27] using Python for code generation, the core approach is not limited to this specific setup and can be adapted to other environments and programming languages.\nTab. IV provides an illustrative example of the LMP generation process. LLMs excel at understanding complex contexts and devising high-level plans for autonomous vehicles by leveraging their inherent common-sense knowledge. However, they also have limitations, such as difficulties in precisely interpreting spatial coordinates and generating detailed motion control commands [28]. Moreover, the large size and autoregressive nature of these models often result in noticeable latency during output generation, posing challenges for real-time objectives like obstacle avoidance.\nTo address these limitations, our framework is designed as a plug-and-play module that complements existing autonomous driving systems rather than serving as a standalone solution. It combines the emerging capabilities of LLMs with the efficiency of classical autonomous driving algorithms. The LLM-based planner generates code snippets at lower frequencies, which act as temporary policies to guide the strategic navigation of the ego vehicle based on user instructions. These policy codes are structured as Python generator functions that unfold until the policy is completed, at which point the system returns to its default mode awaiting further human input.\nThe generated code snippets utilize a suite of functional primitives specialized driving APIs built upon classical planning and control algorithms. These APIs cover a wide range of driving functions, including navigation (e.g., turning, lane changing), control (e.g., waiting, proceeding), perception (e.g., monitoring nearby vehicles, pedestrians, traffic signals), and utility functions (e.g., checking current speed, providing user feedback). The API documentation is also included in the system message (S) for the LLM.\nThis API suite offers flexibility in formulating driving policies. For instance, Navigation APIs can specify the vehicle's future trajectory by dynamically creating waypoints based on map data and classical planning algorithms. Control APIs enable precise vehicle control through momentary control signals. Perception APIs, such as the check_red_light function in Tab. IV, allow identifying and tracking nearby traffic objects, which is crucial for actions that react to the immediate driving context and enable closed-loop control policies.\nHowever, LLMs may hallucinate non-existent API functions when generating policy code [29]. Additionally, the autoregressive generation process of LLMs prevents early tokens from being revised within the same generation cycle, potentially leading to suboptimal solutions [30]. To mitigate these issues, we introduce a human-in-the-loop learning approach based on Retrieval-Augmented Generation (RAG) [22]. This approach grounds the LLM to generate responses to input queries using custom knowledge databases.\nThe key process is as follows: After executing a generated policy code (P), the human passenger provides natural language feedback (F), which is fed back into the LLM along with P. This feedback loop enables continuous learning. If the feedback is positive (i.e., the human is satisfied with the execution), the code (P) is committed to the database for future retrieval and reuse. Otherwise, the feedback serves as guidance for iterative improvement. The new generation process can be formulated as:\n$[R, P'] = l([S, I, C, P, F])$, (10)"}, {"title": "V. REAL-VEHICLE EXPERIMENTS OF LLM4D", "content": "To further assess the effectiveness of the LLM4AD system and validate its applicability in real-world scenarios, we integrate LLMs into practical autonomous driving systems, introducing a framework called Talk2Drive. Similar to the concept in Sec. II, our system has outstanding command understanding and reasoning performance. It also can provide a personalized driving experience by leveraging records of previous interactions.\nThis section proposes Talk2Drive (see Fig. 3), an innovative approach to leveraging LLMs to enhance command interpretation and enable personalized decision-making in autonomous vehicles. It integrates cloud-based LLMs to enable personalized understanding and translation of human commands into"}, {"title": "A. Talk2Drive Framework", "content": "1) Problem Statement: In Talk2Drive, we follow the concept we proposed in Sec. II. The model aims to translate verbal commands into executable control sequences for the vehicle. Without losing generality, denote the verbal commands by $I$, a string sequence. The cloud-based LLM acts as a translating function $f : I \\rightarrow P$ that generates corresponding LMPs as the policy ($P$) for maneuvers.\nFor personalization, we need human feedback on execution $F(I, P)$ to evaluate if the generated policy addresses the preferences of the driver or the passengers. The extra memory module (see V-A5) includes instructions, LMPs, and their evaluation will allow to guide the LLM to learn preferences. Therefore, there are two stages in the Talk2Drive workflow:\nExecution: $P \\leftarrow f(I, S, C, H)$; (11)\nEvaluation : $H \\leftarrow [I, P, F(I, P)]$.\n2) Command Translation and Contextual Data Integration:\nThe initial step in the Talk2Drive framework involves directly receiving arbitrary verbal commands from humans. Utilizing cutting-edge voice recognition technology, specifically the open-source API Whisper [35], these verbal commands are accurately captured and then translated into textual instructions ($I$). An instance for $I$ is:\n$I \\rightarrow$ Could you drive more conservatively? (12)\nSimultaneously, LLMs access additional cloud-based real-time environment data, including weather updates, traffic conditions, and local traffic rules. In our product, LLMs can be informed by the weather information through Openweather API [36], the map information (such as road type and speed limits) through OpenStreetMap API [37], and traffic information through TomTom API [38]. WSame as in Sec. IVe use a predefined structured language generator for both $C$ and $S$, and our system will supply the appropriate values (the red contents) to the generator based on the context information, as shown below:\n$C \\rightarrow$ (13)\nA vehicle in front of you is running at 38.0 km/h.\nYour current speed is 40.0 km/h.\nThe speed limit is 60.0 km/h.\nThe weather is sunny.\n3) Processing and Reasoning with LLMs: The LLMS are trained using in-context learning coupled with chain-of-thought prompting. Specifically, the chain of thought's prompt in Talk2Drive consists of triples: {query, thought, output}. An example can be found in Eq. 14.\nOnce a command is translated into texts, it is uploaded to LLMs hosted on the cloud. In our experiments, we utilize GPT-4 [16] as our LLM and access it through ChatGPT API. The"}, {"title": "4) Actionable Code Generation", "content": "4) Actionable Code Generation: Same as in Sec. II, the LLM is utilized to generate corresponding LMPs (P) based on this interpretation. These LMPs include complex driving behaviors and parameters that need to be adjusted in the vehicle's high-level controllers. Specifically, the LMPs adjust control parameters like the look-ahead distance and look-ahead ratio to optimize pure pursuit [39] performance in Talk2Drive. Additionally, LMPs also modify the target velocity of the vehicle to meet humans' commands. These LMPs take the form of ROS topic commands, directing the autonomous driving system based on Autoware [40] to modify its trajectory following configuration.\nOne simple example codes are shown as follows:\n$P \\rightarrow$ (15)\n$ timeout 1s rostopic pub /vehicle/engage $\n$std_msgs/Bool \"data: true\"$\n$ rostopic pub /autoware_config_msgs $\n$/ConfigWaypointFollower $\n$\"{\\\"param_flag\\\": 1, \\\"velocity\\\": 40,$\n$\"lookahead_distance\\\": 12,$\n$\"lookahead_ratio\\\": 2.0}\"$\nIn the meantime, LLMs also generate thoughts R to explain why they make a particular decision. According to [9], even though the thoughts R are not executed in our systems, they help LLMs make more reasonable and feasible decisions. An example of the thought R is shown below:"}, {"title": "VI. DISCUSSIONS", "content": "The latency of LLMs is a critical factor in determining their suitability for various applications, particularly in the context of autonomous driving. Traditionally, onboard LLM latency primarily depends on model complexity, hardware, and input/output length. Our explorations primarily focused on using the LLM API on the cloud side, where network conditions play a significant role in influencing latency. Our real-world experiments demonstrated a relatively consistent communication latency of around 300ms under stable 4G-LTE network conditions.\nThe empirical results from our tests reveal that the GPT-4 [16] shows an end-to-end latency between 1.2 and 1.8 seconds (under 300 ms network latency). This finding suggests that LLMs can be suitable for making high-level decisions"}, {"title": "B. Safety", "content": "When integrating LLMs into autonomous driving systems, safety is a prior concern. In our proposed LLM4AD concept, the LLMs themselves do not directly handle safety requirements because of the potential for hallucinations in LLM outputs and the reaction time required. Hallucinations could be dangerous in safety-critical situations, and LLMs may not react quickly enough to sudden events. Therefore, instead, the responsibility for ensuring safety depends on"}, {"title": "D. Trust and Transparency", "content": "Another important aspect of integrating LLMs into autonomous driving systems is fostering trust and transparency between human users and the autonomous vehicle. Trust is essential for the widespread adoption and acceptance of autonomous vehicles. One way LLMs can enhance trust is by providing clear and understandable explanations for the vehicle's decision-making process [46].\nIn the Talk2Drive framework, the LLMs generate not only the executable code for vehicle control but also the reasoning behind each decision in natural language. This allows the human user to comprehend why the vehicle is taking certain actions, enhancing the transparency of the system. For instance, if the vehicle decides to change lanes, it can explain that it is doing so because the front vehicle is moving too slowly, and there is a safe gap in the adjacent lane. Such explanations help the user understand the rationale behind the vehicle's behavior, building trust in its decision-making capabilities.\nFurthermore, the memory module in Talk2Drive enables the vehicle to adapt to individual user preferences over time. As the vehicle learns and personalizes its behavior based on the user's past commands and feedback, it demonstrates that it is actively listening to and accommodating the user's needs. This personalization helps strengthen the bond of trust between the user and the vehicle, as the user feels that the vehicle truly understands and cares about their preferences."}, {"title": "VII. CONCLUSIONS", "content": "In this paper, we presented a comprehensive exploration of LLM4AD, the application of Large Language Models (LLMs) for autonomous driving. Our research highlighted the significant potential of LLMs to enhance various aspects of autonomous vehicle technology, from perception and scene understanding to language interaction and decision-making. By leveraging the natural language understanding and reasoning abilities of LLMs, we demonstrated their capacity to enhance the safety, efficiency, and user experience of autonomous vehicles. Moreover, we introduced a comprehensive benchmark specifically designed to evaluate the instruction-following abilities of LLMs within the autonomous driving domain. Our experiments, conducted on both simulation and real-world vehicle platforms, showed promising results, validating the effectiveness of our proposed LLM-based approaches. These findings underscored the significant impact that LLMs can have on the future of autonomous driving technology, making it safer, smarter, and more accessible for all."}]}