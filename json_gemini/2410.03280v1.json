{"title": "Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope", "authors": ["Yasaman Torabi", "Shahram Shirani", "James P. Reilly"], "abstract": "Heart and lung sounds are crucial for healthcare monitoring. Recent improvements in stethoscope\ntechnology have made it possible to capture patient sounds with enhanced precision. In this dataset, we used a\ndigital stethoscope to capture both heart and lung sounds, including individual and mixed recordings. To our\nknowledge, this is the first dataset to offer both separate and mixed cardiorespiratory sounds. The recordings\nwere collected from a clinical manikin, a patient simulator designed to replicate human physiological conditions,\ngenerating clean heart and lung sounds at different body locations. This dataset includes both normal sounds and\nvarious abnormalities (i.e., murmur, atrial fibrillation, tachycardia, atrioventricular block, third and fourth heart\nsound, wheezing, crackles, rhonchi, pleural rub, and gurgling sounds). The dataset includes audio recordings of\nchest examinations performed at different anatomical locations, as determined by specialist nurses. Each\nrecording has been enhanced using frequency filters to highlight specific sound types. This dataset is useful for\napplications in artificial intelligence, such as automated cardiopulmonary disease detection, sound classification,\nunsupervised separation techniques, and deep learning algorithms related to audio signal processing.", "sections": [{"title": "I. BACKGROUND", "content": "Cardiopulmonary diseases are significant contributors to\nglobal mortality rates. Chronic respiratory diseases, such as\nasthma, were responsible for over 147,000 deaths in 2022\nalone [1]. Meanwhile, cardiovascular diseases remain the\nleading cause of death worldwide, accounting for\napproximately 18.6 million deaths annually [2]. Therefore, it\nis crucial to accurately analyze both heart and lung functions.\nAuscultation of heart and lung sounds plays a vital role in\ndiagnosing a variety of cardiopulmonary conditions [3].\nAlthough these acoustic signals are weak, they hold essential\nmedical information [4]. In 1816, Ren\u00e9 Laennec invented the\nfirst stethoscope to listen to body sounds, which has evolved\nover the years from a simple acoustic device to more\nsophisticated digital versions [5].\nTechnological advancements have led to the development\nof electronic stethoscopes that convert sound waves into\nelectrical signals, allowing for sound processing and recording\n[6, 7]. Digital stethoscopes are the latest generation of these\nauscultation devices. They not only have the features of\nelectronic stethoscopes, but also offer enhanced analysis\ncapabilities, including integration with smartphones and\ncloud-based platforms for real-time analysis and sharing [8].\nArtificial intelligence (AI) and machine learning\nalgorithms have made significant improvements in real-time\nanalysis and clinical decision-making [9, 10]. However, the\neffectiveness of these models heavily depends on the\navailability of high-quality datasets that contain diverse\nexamples and enough dataset size. Such datasets are essential\nfor training and validating AI models that perform sound\nclassification, anomaly detection, and signal separation.\nCurrently, there are few available datasets containing heart and\nlung sounds. The invention of patient simulators has become\na critical point in clinical training and data collection, offering\na risk-free and realistic environment for recording heart and\nlung sounds. For example, the manikin used in this work is\nwidely used for its realistic articulation and ability to simulate\na broad range of clinical scenarios [11].\nIn this work, we collected a total of 210 audio recordings\n(101 female and 109 male) from a clinical skills manikin in a\ncontrolled, noise-free environment. We recorded from 12\ndistinct chest locations, including standard heart and lung\nauscultation landmarks. Our dataset includes 50 heart sound\nrecordings, 50 lung sound recordings, and 110 mixed\nrecordings with ten heart sound types and six lung sound types.\nWe controlled the manikin using an instructor tablet connected\nvia Wi-Fi, allowing real-time adjustments. We recorded the\nsounds using a digital stethoscope, connected via Bluetooth to\na cellphone application, which enabled real-time visualization,\nrecording, and storage. Each 15-second recording was saved\nin .wav format and uploaded to a cloud-based platform for"}, {"title": "II. COLLECTION METHODS AND DESIGN", "content": "We performed auscultation in a controlled, quiet, and noise-\nfree environment (Fig. 1A). We positioned the patient\nsimulator in a sitting position to simulate realistic conditions\nfor lung and heart sound recordings (Fig. 1B).\nWe recorded sounds from various chest locations\ndepending on whether we were capturing heart or lung sounds\n(Fig. 2). For the mixed recordings, we selected the location\nfrom either heart or lung zones. We performed lung recordings\nfrom both the right and left sides of the chest, with each side\ndivided into three zones: upper, middle, and lower. We\nfocused on the anterior regions of the chest to ensure high-\nquality recordings, as the manikin's speakers are positioned at\nthe front.\nWe used standard lung auscultation landmarks [17]: Upper\nAnterior (UA), which is on ribs 2-4; Middle Anterior (MA),\nlocated at the anterior surface of ribs 4-6; and Lower Anterior\n(LA), placed over ribs 6-8, 45\u00b0 down from nipple. For heart\nauscultation, we performed auscultation over the classic sites\nof auscultation [28] as follows:\n- Apex (A): Mitral area\nRight Upper Sternal Border (RUSB): Aortic area\nLeft Upper Sternal Border (LUSB): Pulmonary area\n- Left Lower Sternal Border (LLSB): Tricuspid area\nRight Costal Margin (RC)\n- Left Costal Margin (LC)\nWe utilized the CAE Juno\u2122 nursing skills manikin, a mid-\nfidelity patient simulator designed to enhance clinical nursing\nskills. This manikin features interchangeable male and female\nchest skins, allowing gender switching to simulate male and\nfemale patients [19, 20].\nWe employed the CAE Maestro software, installed on a\ntablet, to control and monitor the manikin in real time. We\nconnected the tablet to the manikin via a secure Wi-Fi\nconnection, to remotely manage and customize a variety of\npatient sounds [21]. Fig. 3 shows the manikin and the tablet\nrunning the controlling software.\nThe Manikin offers a range of pre-recorded heart and lung\nsounds, which are synchronized with the cardiac cycle and\nventilation of the left and right lungs, respectively [22]. Using\nthe Maestro software, we adjusted the simulation parameters\nto suit the specific requirements of our study, simulating real-\nlife auscultation scenarios at various chest locations.\nWe used the 3M\u2122 Littmann\u00ae CORE Digital Stethoscope,\n3M's most advanced model, to record lung and heart sounds\n(Fig. 4). Each recording lasted 15 seconds, which was\nsufficient to capture at least one complete respiratory or\ncardiac cycle. The stethoscope has built-in frequency filters,\nallowing us to selectively capture heart sounds, lung sounds,\nor both, thereby enhancing precision during the recording\nprocess. We applied three different filter modes based on the\ntype of sound being captured: Bell mode for recording low-\nfrequency heart sounds, Diaphragm mode for capturing high-\nfrequency lung sounds, and Midrange mode for recording both\nheart and lung sounds simultaneously. The amplification\nfeature provided up to 40x sound enhancement, and the active\nnoise cancellation effectively reduced ambient noise [23, 24].\nWe connected the stethoscope to the Eko software via\nBluetooth, which enabled us to store the recordings directly on\na mobile device. This mobile application pairs with the digital\nstethoscope, to record, visualize, and analyze cardiorespiratory\nsounds. It allows real-time monitoring, playback, and cloud-\nbased storage of the recorded sounds. These recordings were\nsubsequently uploaded to the cloud-based platform, making\nthem accessible for download and further analysis in .wav\nformat on a personal computer (PC) or laptop.\nAfter transferring the recordings to a laptop, we visualized the\ntime-domain signals which provides a clear view of the signal\nvariations over time. We also generated time-frequency\nspectrograms to visualize the frequency content and signal\nenergy over time. The resulting waveforms and spectrograms\nare essential for further analysis of the characteristics of the\ndataset and serve as a basis for future work in analyzing and\ninterpreting the recorded data. Fig. 5 and Fig. 6 show three\nsample waveforms and spectrograms from the dataset,\nrespectively."}, {"title": "III. VALIDATION AND QUALITY", "content": "To ensure the accuracy and reliability of the collected data,\nwe performed several validation measures across all stages of\nthe data acquisition and processing. The nursing team assisted\nus in accurately identifying auscultation landmarks and\nensured that clinical aspects of the data collection process were\nproperly followed. We made recordings in a controlled, noise-\nfree environment with the manikin in a sitting position to\neliminate external noise interference. Before recording the\nsounds, we precisely placed the stethoscope's diaphragm at\nstandard auscultation points to minimize artifacts. After the\nrecording session, we performed a qualitative analysis by\nlistening to the audio files, ensuring they aligned with the\nexpected patterns of heart and lung sounds.\nWe selected a digital stethoscope with high amplification\ngain, active noise cancellation, and built-in frequency filters,\nwhich allowed us to capture sounds with minimal distortion.\nBluetooth data transmission ensures error-free transfer to a\nsecure database without data loss or corruption [25, 26]."}, {"title": "IV. RECORDS AND STORAGE", "content": "The dataset consists of 210 audio recordings (101 Female, 109\nMale) in .wav format, categorized into three primary groups:\n50 heart sound recordings (HS.zip), 50 lung sound recordings\n(LS.zip), and 110 recordings of mixed heart and lung sounds\n(Mix.zip).\nEach category is accompanied by a corresponding CSV\nfile that provides metadata for the respective audio files. The\nCSV files (HS.csv, LS.csv, and Mix.csv) contain metadata\nabout the corresponding audio files, including the file name,\ngender, heart and lung sound type, and the anatomical location\nwhere we recorded the sound.\nThe naming convention of the audio files of single\nrecordings follows the structured format:\nGender_Sound Type_Location.wav\nWe denote the gender of the subject by F for female or M\nfor male, followed by the sound type, and the location on the\nchest where we recorded the sound. For the mixture dataset,\nthe sound type of both heart and lung is mentioned in the\nnaming, separated by an underscore. For example,\nF_LSM_R_LUSB.wav refers to a recording of a female subject\nwith a late systolic murmur and rhonchi, taken from the left\nupper sternal border.\nThere are ten heart sound types and six lung sound types\nin the dataset.\nWe recorded\nsounds from twelve distinct anatomical locations. Detailed\ndemographic information of each recording location is\ndescribed in Table 3."}, {"title": "V. SOURCE CODE AND SCRIPTS", "content": "The Python scripts are publicly available on GitHub at the\nfollowing repository: https://github.com/Torabiy/HLS-CMDS"}]}