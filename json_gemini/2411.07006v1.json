{"title": "Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs", "authors": ["Malte Luttermann", "Tanya Braun", "Ralf M\u00f6ller", "Marcel Gehrke"], "abstract": "Lifting uses a representative of indistinguishable individuals to exploit symmetries in probabilistic relational models, denoted as parametric factor graphs, to speed up inference while maintaining exact answers. In this paper, we show how lifting can be applied to causal inference in partially directed graphs, i.e., graphs that contain both directed and undirected edges to represent causal relationships between random variables. We present partially directed parametric causal factor graphs (PPCFGs) as a generalisation of previously introduced parametric causal factor graphs, which require a fully directed graph. We further show how causal inference can be performed on a lifted level in PPCFGs, thereby extending the applicability of lifted causal inference to a broader range of models requiring less prior knowledge about causal relationships.", "sections": [{"title": "1 Introduction", "content": "A fundamental problem for an intelligent agent performing reasoning under uncertainty is to compute the effect of an action on a certain random variable (randvar) on other randvars. When computing the effect of an action on a specific randvar, it is crucial to deploy the semantics of an intervention instead of performing a classical conditioning on that randvar [22, Chapter 4]. An intervention acting on a randvar R can be thought of as setting R to a fixed value and removing all incoming influences on the value of R. In practice, generally not all causal relationships in a given model are known and thus, only a partially directed graphical model is available. In such a partially directed graph, directed edges represent cause-effect relationships and undirected edges represent causal relationships whose direction is unknown. In this paper, we solve the problem of efficiently estimating causal effects of actions in partially directed lifted probabilistic models, denoted as parametric factor graphs. Lifted representations are not only more expressive than propositional models such as factor graphs, but also allow for tractable probabilistic inference with respect to domain sizes of logical variables (logvars) by exploiting symmetries."}, {"title": "2 Preliminaries", "content": "We begin to introduce parameterised randvars (PRVs), which use logvars as parameters to represent sets of indistinguishable randvars.\nDefinition 1 (Parameterised Random Variable). Let R be a set of randvar names, L a set of logvar names, and D a set of constants. All sets are finite. Each logvar L has a domain $dom(L) \\subseteq D$. A constraint is a tuple (X,Cx) of a sequence of logvars $X = (X_1,...,X_n)$ and a set $Cx \\subseteq \\times_{i=1}^{n}dom(X_i)$. The symbol T for C marks that no restrictions apply, i.e., $Cx = \\times_{i=1}^{n}dom(X_i)$. A PRV R(L1,..., Ln), n \u2265 0, is a syntactical construct of a randvar R \u2208 R possibly combined with logvars L1, . . ., Ln \u2208 L to represent a set of randvars. If n = 0, the PRV is parameterless and forms a propositional randvar. A PRV A (or logvar L) under constraint C is given by AT (L|C), respectively. We may omit |T in AT or LIT. The term range(A) denotes the possible values of a PRV A. An event A = a denotes the occurrence of PRV A with range value a \u2208 range(A).\nExample 1. Consider R = {Comp, Sal, Rev} for competence, salary, and rev- enue, respectively, and L = {E} with dom(E) = {alice, bob, charlie} (employ- ees), combined into PRVs Comp(E), Sal(E), and Rev with range(Comp(E)) = range(Sal(E)) = range(Rev) = {low, medium, high}.\nA parametric factor (parfactor) describes a function, mapping argument values to positive real numbers, of which at least one is non-zero.\nDefinition 2 (Parfactor). Let \u03a6 denote a set of factor names. We denote a parfactor g by \u03c6(A)\\c with A = (A1,..., An) being a sequence of PRVs, \u03c6: $\\times_{i=1}^{n} range(A_i) \\rightarrow \\mathbb{R}^+$ being a function with name \u03c6 \u2208 \u03a6 mapping argument values to a positive real number called potential, and C being a constraint on the logvars of A. We may omit |T in \u03c6(A)|\u315c. The term lv(Y) refers to the logvars in some element Y, a PRV, a parfactor, or sets thereof. The term gr(Y|c) denotes the set of all instances (groundings) of Y with respect to constraint C.\nExample 2. Take a look at the parfactor $g_1 = \\phi_1(Comp(E), Rev)|_\\tau$. Assuming the same ranges of the PRVs and the same domains of the logvars as in Ex. 1, g1 specifies |range(Comp(E))|\u00b7 |range(Rev)| = 9 input-output map- pings $\u03c6_1$(low, low) = $\u03c6_1$, $\u03c6_1$(low, medium) = $\u03c6_2$, $\u03c6_1$(low, high) = $\u03c6_3$, and so on with $\u03c6_i \\in \\mathbb{R}^+$ for all i = 1,...,9. Further, lv(91) = {E} and gr($g_1|\\tau$) = {$\u03c6_1$(Comp(alice), Rev), $\u03c6_1$(Comp(bob), Rev), $\u03c6_1$(Comp(charlie), Rev)}.\nA PCFG is then built from a set of parfactors {91,...,gm} and the causal relationships between the PRVs, which are encoded by the direction of the edges in the graph structure of the PCFG [12]. In its original form, a PCFG is a fully directed graph, but we extend this definition to allow for both directed and undirected edges in the following section."}, {"title": "3 Partially Directed Parametric Causal Factor Graphs", "content": "We now move on to define PPCFGs as lifted models that are able to incorporate partial causal knowledge, thereby allowing to exploit symmetries (in form of indistinguishable individuals) to speed up both probabilistic and causal inference by performing lifted inference.\nDefinition 3 (Partially Directed Parametric Causal Factor Graph). A PPCFG is a graph M = (AUG, E) that consists of variable nodes A, factor nodes G (ANG = \u00d8), and a set of edges E. Each variable node A \u2208 A represents a PRV A and every factor node g\u2208 G represents a parfactor g = \u03c6(A)\\c, where A = (A1,..., Ak) with $A_i \u2208 A,..., A_k \u2208 A$ is a sequence of PRVs, \u03c6: $\\times_{i=1}^{k} range(A_i) \\rightarrow \\mathbb{R}^+$ is a function, and C is a constraint on the logvars of A. We again may omit |T in \u03c6(A)|\u315c. For a variable node A \u2208 A and a factor node g \u2208 G, there is an undirected edge g - A \u2208 E if A appears in the argument list of g = \u03c6(A) and no information about the causal relationships between the PRVs in A is available. If it is known that all A' \u2208 A\\{A} are causes of A \u2208 A (or if A \\ {A} = \u00d8), the edge g A can be replaced by a directed edge g\u2192 \u0410.\nThe semantics of M is given by grounding and building a full joint distribu- tion. With Z as the normalisation constant and Ak denoting the PRVs appearing in the argument list of $\u03c6_k(A_k)$, M represents the full joint distribution\n$P_M = \\frac{1}{Z} \\prod_{g \\in G} \\prod_{\\phi_k \\in gr(g)} \\phi_k(A_k)$.\nExample 3. Following Exs. 1 and 2, Fig. 1 depicts a PPCFG M modelling the interplay of a company's revenue and its employees' competences and salaries. Each parfactor represents a group of ground factors and thus, grounding M results in a partially directed factor graph (see Fig. 2). In this particular example, the causal relationships encoded by M tell us that the revenue of the company influences the salary of each individual employee and the competence of a specific employee influences their salary. Moreover, there is a dependency between the competence of each individual employee and the revenue of the company, but the causal direction is not encoded in M. We humans expect that the competence of the employees influences the revenue of the company, but an autonomous agent might not have this information available, resulting in a partially directed graph."}, {"title": "4 Conditional Independence in PPCFGs", "content": "The notion of d-separation [21] provides a graphical criterion to test for condi- tional independence in directed acyclic graphs and is essential to compute the effect of an intervention in the sense that all non-causal paths, so-called backdoor paths, need to be blocked to remove spurious effects. Frey [6] extends the notion of d-separation to partially directed factor graphs and we build on this definition to define d-separation in PPCFGs (analogously to d-separation in PCFGs [12]). Note that the semantics of d-separation in PPCFGs is defined on a ground level.\nDefinition 5 (d-separation). Let M = (AUG, E) be a PPCFG. Given three disjoint sets of randvars X, Y, and Z (subsets of gr(A)), we say that X and Y are conditionally independent given Z, written as X || Y | Z, if the nodes in Z block all paths between the nodes in X and the nodes in Y in gr(M). A path is a connected sequence of edges (independent of their directions) and it is therefore also possible for a path to pass from a parent of a factor to another parent of that factor. A path is blocked by the nodes in Z if\n1. the path contains the pattern $\u03c6_1 \\rightarrow A\\leftarrow \u03c6_2$ such that neither A nor any of its descendants are in Z, or\n2. the path passes from $\u03c6_1$ through A to $\u03c6_2$ such that it does not contain the pattern $\u03c6_1 \\rightarrow A \\leftarrow \u03c6_2$ and A is in Z, or\n3. the path passes from a parent of a factor \u03c6 to another parent of \u03c6, and neither the child of \u03c6 nor any of its descendants are in Z.\nExample 6. Consider the grounded PPCFG M depicted in Fig. 2. M encodes, for example, that the competence of alice is independent of bob's salary given the revenue of the company, written as {Comp(alice)} || {Sal(bob)} | {Rev}, because all paths from Comp(alice) to Sal(bob) pass through Rev."}, {"title": "5 Efficient Estimation of Causal Effects in PPCFGS", "content": "To compute the effect of actions carried out on randvars on other randvars, we have to answer interventional queries [22]. An intervention on a grounded or parameterless PRV R, denoted as do(R = r) where r \u2208 range(R), changes the structure of the underlying model by setting the value of R tor and removing all incoming influences on R. An intervention is defined on a fully directed graph.\nDefinition 6 (Intervention). Let M = (AUG, E) be a fully directed PPCFG and let gr(A) = {R1,...,Rn} denote the set of randvars obtained by ground- ing the PRVs in A. Any probability distribution entailing the conditional in- dependence statements encoded by M can be factorised as $P(R_1,...,R_n) =$"}, {"title": "6 Conclusion", "content": "We introduce PPCFGs as probabilistic relational models that allow to incorpo- rate partial causal knowledge, thereby enabling lifted causal inference without the need for a fully specified causal model. A lifted representation such as a PPCFG is more expressive than a propositional model and allows for tractable inference with respect to domain sizes of logvars. We further present an algo- rithm to efficiently compute the effect of joint interventions in PPCFGs (i.e., on a lifted level). Our proposed algorithm is also able to efficiently deal with interventions on PRVs representing sets of indistinguishable randvars.\nIn future work, we aim to investigate the effect of interventions in a rela- tional model with mutual interdependencies in form of bidirectional edges. We conjecture that randvars with mutual interdependencies can be collapsed into a single node in the graph such that our proposed algorithm can still be applied. Another interesting direction for future work is to allow for hidden confounders."}]}