{"title": "METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring", "authors": ["Ollie Liu", "Sami Jaghouar", "Johannes Hagemann", "Shangshang Wang", "Jason Wiemels", "Jeff Kaufman", "Willie Neiswanger"], "abstract": "We pretrain METAGENE-1, a 7-billion-parameter autoregressive transformer model, which we refer to as a metagenomic foundation model, on a novel corpus of diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base pairs. This dataset is sourced from a large collection of human wastewater samples, processed and sequenced using deep metagenomic (next-generation) sequencing methods. Unlike genomic models that focus on individual genomes or curated sets of specific species, the aim of METAGENE-1 is to capture the full distribution of genomic information present within this wastewater, to aid in tasks relevant to pandemic monitoring and pathogen detection. We carry out byte-pair encoding (BPE) tokenization on our dataset, tailored for metagenomic sequences, and then pretrain our model. In this paper, we first detail the pretraining dataset, tokenization strategy, and model architecture, highlighting the considerations and design choices that enable the effective modeling of metagenomic data. We then show results of pretraining this model on our metagenomic dataset, providing details about our losses, system metrics, and training stability over the course of pretraining. Finally, we demonstrate the performance of METAGENE-1, which achieves state-of-the-art results on a set of genomic benchmarks and new evaluations focused on human-pathogen detection and genomic sequence embedding, showcasing its potential for public health applications in pandemic monitoring, biosurveillance, and early detection of emerging health threats.", "sections": [{"title": "Introduction", "content": "The development of large language models trained on internet-scale text datasets has revolutionized natural language processing, finding increasingly broad applications across numerous domains. In recent years, this modeling technology has been adapted to genomic sequences\u2014e.g., DNA or RNA strands that carry genetic information\u2014leveraging the wealth of data generated by advances in genome sequencing over the past few decades (Ji et al., 2021, Nguyen et al., 2024b, Dalla-Torre et al., 2023, Zhou et al., 2023, Fishman et al., 2023). These large genomic models aim to harness modeling power for tasks such as genome classification, phenotype prediction, gene network inference, human genome analysis, and biological design for medical and therapeutic applications. To date, most of these models have been trained on human genomes or on curated collections of genomes from selected species (Consens et al., 2023, Benegas et al., 2024).\nParallel to these developments, there has been significant work on large-scale health monitoring driven largely by widespread public health crises, such as the COVID-19 pandemic (Salomon et al., 2021, Reinhart et al., 2021). One notable example of this is the genomic monitoring of wastewater, which involves sequencing material from samples of municipal sewage (Farkas et al., 2020, Consortium, 2021). Wastewater contains a complex mix of organic materials generated from human activities and, when collected across multiple time points and locations, can reveal valuable information about the microbiome at a societal scale (Bogler et al.,"}, {"title": "3. METAGENE-1: Metagenomic Foundation Model", "content": "We pretrain a 7-billion-parameter autoregressive transformer language model, referred to as METAGENE-1, on a novel corpus of diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base pairs. This dataset is sourced from a diverse set of human wastewater samples, which were processed and sequenced using deep metagenomic (next-generation) sequencing methods. Before training, we carry out byte-pair encoding (BPE) tokenization on our dataset, tailored for these nucleic acid sequences. The following sections provide detailed descriptions of the pretraining dataset, tokenization strategy, and model architecture, highlighting the considerations and design choices that enable the effective modeling of metagenomic data."}, {"title": "3.1. Metagenomic Dataset", "content": "One of the goals of our metagenomic foundation model is to train on a genomic dataset that captures the immense diversity of the microbiome surrounding humans. To achieve this, we leverage a newly collected metagenomic dataset\u2014never before used in model training\u2014comprising material from a broad range of organisms, including bacteria, viruses, cells from human and other eukaryotes, and a diverse array of other species, which was collected via metagenomic sequencing of human wastewater (i.e., municipal influent). This approach contrasts with prior genomic sequence models, which often focus on curated collections of specific (known) species or genomic types. By incorporating DNA and RNA sequences collected from wastewater, we aim to model the complexity of microbial and viral interactions in human-associated environments.\nThe dataset was generated using deep metagenomic sequencing, specifically leveraging Illumina sequencing technology, commonly referred to as next-generation sequencing (NGS) or high-throughput sequencing, in which billions of nucleic acid fragments are simultaneously sequenced in a massively parallel manner. This method produces paired-end reads, where each read consists of two contiguous sequences of base pairs from opposite ends of a DNA or RNA fragment\u00b9. Paired-end reads can offer advantages in accuracy and alignment over single-end reads, particularly for complex metagenomic samples. Notably, the nature of metagenomic NGS results in much shorter reads compared to datasets used in many previous large genomic models. In our dataset, most reads range from 100 to 300 base pairs in length (after adapter removal and quality trimming), which introduces unique challenges for modeling, but also provides a rich diversity and large set of biological information. We illustrate this metagenomic data collection and sequencing pipeline in Figure 2.\n3\nThis metagenomic sequence corpus was collected over a six-month period by the Nucleic Acid Observatory (NAO) (Consortium, 2021) in collaboration with partners (Marc Johnson and Clayton Rushford at the University of Missouri\u00b2 and Jason Rothman in Katrine Whiteson's lab\u00b3 at the University of California, Irvine). Samples of wastewater were sourced from multiple locations across the United States, in particular from cities in California and Missouri. After wastewater samples were collected, the material was filtered and nucleic acids extracted (Rothman et al., 2021, Robinson et al., 2022) before undergoing metagenomic sequencing. In full, the metagenomic dataset for pretraining comprises over 1.5 trillion base pairs. Our hope is that this careful sampling and processing approach yields a clean dataset for sequence modeling, which captures a wide array of genomic content, offering a strong foundation for the training of METAGENE-1."}, {"title": "3.2. Tokenization", "content": "In developing our metagenomic foundation model, we sought a tokenization strategy that would enable high-accuracy sequence modeling, accommodate novel nucleic acid sequences, and align with best practices in modern large language models. We opted for byte-pair encoding (BPE) as our tokenization method, as it satisfies these criteria, and drawing inspiration from its successful application in recent genomic models.\nBPE offers several advantages for our model. Unlike fixed-length k-mer tokenization, it allows for flexible token sizes, which is beneficial for capturing varying levels of genomic information, and can allow the model to adapt to different sequence patterns and structures. Moreover, BPE's ability to tokenize novel sequences is particularly valuable for modeling diverse metagenomic sequences containing unknown, varied, and possibly"}, {"title": "3.3. METAGENE-1 Architecture", "content": "For our metagenomic foundation model, we pretrain a 7-billion-parameter autoregressive language model, using a standard dense transformer architecture, similar to the architecture used in popular language models such as the GPT and Llama model families (Radford et al., 2019, Touvron et al., 2023). Specifically, we implement a decoder-only style transformer with a causal language modeling objective, where the model aims to predict the next token in a sequence based on the previous tokens.\nThis architecture choice for METAGENE-1 stands in contrast to some of the alternative approaches explored in recent genomic models, which include BERT-style bidirectional encoders (Ji et al., 2021, Zhou et al., 2023, 2024) or non-attention based architectures (Nguyen et al., 2024b,a). Our decision to use this particular model architecture was driven by the following motivations:\n1. Ecosystem: By aligning with this widely-adopted architecture, we can take advantage of the growing ecosystem of techniques and associated implementations developed for autoregressive decoder-only transformer models. This extends to both pretraining optimizations and downstream applications in fine-tuning and inference.\n2. Infrastructure: Given our large dataset size, this architecture allows us to leverage scalable pretraining infrastructure specifically designed for distributed training of this model type. This infrastructure has demonstrated success in recent language models, enabling efficient training on massive datasets.\n3. Data characteristics: The nature of our metagenomic sequence data, which primarily consists of short sequences, does not necessitate architectures designed for extremely long context lengths. This makes the transformer a suitable and efficient choice for our use case.\nWe next describe some of the specific configuration details of METAGENE-1. First, the model operates with a context length of 512 tokens, which is sufficient for all of the metagenomic sequences in our pretraining dataset. For efficiency, we pack shorter sequences within this context window, a process detailed in Section 4.3"}, {"title": "4. Pretraining METAGENE-1", "content": ""}, {"title": "4.1. Training Infrastructure", "content": "Our model is trained on four nodes, each equipped with 8 H100 SXM5 GPUs interconnected via Ethernet with 40 GB/s bandwidth. This interconnect bandwidth poses a significant performance bottleneck, as it is an order of magnitude slower than NVIDIA's InfiniBand and faster Ethernet interconnects. Despite this limitation, we were able to achieve 40% model FLOPS utilization (MFU) (Chowdhery et al., 2022) by employing a hybrid sharding strategy. Specifically, we use PyTorch's HYBRID_SHARD_ZERO2 strategy implemented in its Fully Sharded Data Parallel (FSDP) utilities. This design choice provides the benefit of model and optimizer state sharding within each node, while practicing standard data parallelism across nodes to reduce the inter-node communication overhead. In practice, it only requires an all-reduce operation on the gradient buckets during the optimizer step.\nFor training, we use a global batch size of 30,720, a sequence length of 512, and a micro-batch size of 48. We observe this combination to offer the best trade-off between high MFU and reduced memory usage; it also allows us to shard the optimizer state and gradients within a single node. Further tests on fewer nodes yield MFU values of 0.51 and 0.47 for 1-node and 2-node setups, respectively. These results suggest that interconnect bandwidth was the main bottleneck in our training environment.\nNode failure. During training, we experienced three node failures, one GPU failure, one network failure, and one disk failure. All failures required us to restart the training from the latest checkpoint."}, {"title": "4.2. Stability", "content": "Foundation model pretraining is prone to suffer from training instability, which can be more pronounced when scaling models to billions of parameters (Wortsman et al., 2023). Such instabilities often arise during the middle or late stages of training, and are often characterized by a sudden spike in loss and/or other divergent behaviors. Failure to identify these problems can result in considerable wasted compute resources. Additionally, the characteristics of the input data have been shown to influence training stability, as highlighted by recent work in large multimodal language models (Team, 2024).\nGiven that we scaled directly from sub-billion parameters to a 7 billion parameter model, and that training"}, {"title": "4.3. Context Stuffing", "content": "A significant portion of our dataset contains sequences with fewer tokens than our model's context length. To optimize compute efficiency and avoid wasting resources on padding tokens, we pack the sequence dimension with multiple samples, where applicable. We modify the attention mask to ensure that tokens from different samples cannot attend to one another. This is implemented using the variable length function in FlashAttention-2 (Dao, 2023) which avoids materializing the full mask, which would have been inefficient."}, {"title": "4.4. Continual Pretraining", "content": "After the initial stage of pretraining is complete, we carry out a second stage of pretraining which constitutes about 9% of our total number of pretraining tokens. In this second stage of training, we extend our dataset to a broader distribution of genomic sequences relative to our original metagenomic distribution, and we follow practices for continual learning, such as annealing the learning rate both to enact a warmup period (i.e., a linear ramp up to account for the shifted data distribution), and a cooldown period (i.e., a ramp down of the learning rate at the end of training for improved performance (H\u00e4gele et al., 2024)).\nThe modified training distribution aims to allow for us to maintain performance on metagenomic tasks, such as metagenomic embedding and classification, while also achieving improved performance on a broader set of genomic tasks (i.e., tasks involving non-metagenomic data). For this, we sample sequences from the dataset provided by Zhou et al. (2023), which includes genomic sequences from known organisms\u2014both from human genomes and a curated selection of genomes from multiple species (e.g., fungi, mammalian, invertebrate, bacteria)\u2014and shuffle it into our metagenomic reads at a 1:8 ratio."}, {"title": "5. Empirical Results", "content": ""}, {"title": "5.1. Pretraining Performance", "content": "As an initial analysis of METAGENE-1, in Figure 5, we show two loss curves generated over the course of pretraining. On the left, we show the training loss over one epoch of our 1.5-trillion-base-pair pretraining dataset. On the right, we show the validation loss, computed on a held-out portion of our metagenomic dataset. In the training curve we note that there are slight systematic oscillations over the course of training, which occur due to pseudo-random data shuffling (implemented for efficiency reasons); however, these do not appear in our validation loss curve."}, {"title": "5.2. Pathogen Detection Benchmark", "content": "Our initial experiments evaluate METAGENE-1's reliability in detecting human pathogens. To this end, we construct four datasets with binary labels, aiming to classify human pathogens versus non-pathogens. These datasets are constructed from four distinct sequencing deliveries, which are excluded from our pretraining data. For each delivery, we extract two sets of sequencing reads: pathogen and non-pathogen. Pathogen reads are defined as a subset of sequencing reads meeting two criteria: (1) Kraken 2 (Wood et al., 2019) identifies at least one hit on a k-mer associated with a human-infecting virus, and (2) the read aligns with a human-infecting virus genome in GenBank. The sub-tasks in this pathogen detection benchmark represent different deliveries, which vary by collection location, sequencing pipeline, date, or a combination of these factors. Each dataset contains 1,600 training samples and 2,000 test samples. We intentionally use a small training set to mimic real-world scenarios where rare human pathogens are expensive to identify."}, {"title": "5.3. Genomic Embedding Benchmark", "content": "Next, we assess METAGENE-1's ability to generate high-quality representations in a zero-shot manner. These representations are crucial for lightweight development of predictive models using a frozen foundation model (Devlin, 2018, Karpukhin et al., 2020, inter alia). They enhance interpretability by enabling sparse autoencoders to produce semantically meaningful encodings (Bricken et al., 2023, Gao et al., 2024). Additionally, they are vital for anomaly detection methods that rely on them for effective modeling (Yang et al., 2024). Drawing inspiration from MTEB (Muennighoff et al., 2022), we introduce a large-scale genomics embedding benchmark, termed Gene-MTEB, to advance the development of robust genomics representations.\nFor this benchmark, we curate eight classification tasks (Human-Virus-1-4, MHPD-single, HMPD-disease, HMPD-source, HMPD-sex), and eight clustering tasks (HVR-p2p, HVR-s2s-align, HVR-s2s-small, HVR-s2s-tiny, HMPR-p2p,HMPR-s2s-align, HMPR-s2s-small, HMPR-s2s-tiny). Datasets for these tasks are sourced from the Human Microbiome Project (Peterson et al., 2009), and held-out portions of our metagenomic dataset. Details and access to all benchmark datasets are provided on the project HuggingFace page. All classification tasks carry out logistic regression on top of embeddings and all clustering tasks carry out mini-batch k-means. Embeddings for all models are accessed via mean pooling on the last hidden state.\nResults on Gene-MTEB are shown in Table 3. Here, accuracy is shown for classification and V-measure for clustering tasks. We find that METAGENE-1 shows strong embedding performance across the board, and in particular for Human-Virus datasets, scoring over 6 points above all other models. Continual training with representation learning objectives, such as contrastive losses, could further enhance its embedding quality beyond its current LM-based pretraining."}, {"title": "5.4. Genome Understanding Evaluation Benchmark", "content": "We now investigate the viability of METAGENE-1 as a general-purpose foundation model. Importantly, we aim to assess its performance on nucleotide sequences sampled from a diverse array of species. One such example is long-sequence full-animal-genome datasets. In many prior genomic sequence models' pretraining datasets, this type of genomic data is found in abundance (Dalla-Torre et al., 2023, Ji et al., 2021, Nguyen et al., 2024b,"}, {"title": "5.5. Anomaly Detection from Wastewater", "content": "Our final experiment aims to show the feasibility of METAGENE-1 to detect out-of-distribution (OOD) data at scale, as it serves as a primer for reliable anomaly detection from wastewater samples. In this early study,"}, {"title": "6. Safety Considerations", "content": "Metagenomic foundation models like METAGENE-1 demonstrate improved capabilities on tasks that can aid in biosurveillance, genomic anomaly detection, and pandemic monitoring. While still relatively small in scale compared with many modern language models, METAGENE-1 shows state-of-the-art results on benchmarks and enables potential downstream uses. However, these capabilities merit careful consideration of safety and must be balanced against potential risks. This category of genomic model\u2014and especially, future larger variants of it\u2014could pose risks to human health and safety by enabling harmful applications, such as the design of novel pathogenic DNA sequences or synthetic genetic materials. These potential abuses were considered when deciding to open source METAGENE-1. The final decision was based on weighing the beneficial applications, such as pandemic preparedness, against the potential for misuse. Based on our safety considerations, which we outline below, we believe that the current iteration of METAGENE-1 poses minimal risk, and its release is justified by its significant positive potential. However, we also recognize and discuss the need for careful safety considerations before open sourcing increasingly capable models of this type.\nRelation to other open source genomic models. METAGENE-1 is a genomic foundation model that builds upon a lineage of similar open-source efforts, such as NucleotideTransformer (Dalla-Torre et al., 2023), DNABERT (Ji et al., 2021), HyenaDNA (Nguyen et al., 2024b), Evo (Nguyen et al., 2024a), and more. At 7 billion parameters, METAGENE-1 matches the largest of these existing models. The key distinction of METAGENE-1 lies in the model's training data: a highly diverse set of metagenomic sequences derived from wastewater, with a focus on the human microbiome. This dataset, comprising short uncurated sequences from tens of thousands of species, allows METAGENE-1 to excel at representing the complexities of microbial and viral diversity in metagenomic samples, providing unique advantages in biosurveillance applications. Similar to other genomic foundation models, and unlike large language models, these models alone do not possess significant reasoning or control capabilities (given that complex control instructions cannot easily be provided via input context, which is restricted to genomic sequences).\nTailored for detection, not design. METAGENE-1 was specifically designed for anomaly detection in metagenomic data, not for complex genomic design tasks. The training data, model architecture, and task design are geared toward detecting and classifying anomalies in short sequences of a few hundred base pairs. Notably, all metagenomic data used in pretraining METAGENE-1 consist exclusively of sequences ranging from 100 to 300 base pairs. Unlike large genomic models focused on longer sequence generation, METAGENE-1's capabilities are tailored to analyzing these short metagenomic reads. Its architectural constraints, including a"}, {"title": "7. Discussion, Limitations, Conclusion", "content": "We have reported our current progress on pretraining and evaluating METAGENE-1, the first large-scale foundation model pretrained on metagenomic sequences. We detail our dataset construction, model training, and fine-tuning procedure to facilitate open-science research. Additionally, we open-source our training code and model checkpoints.\nOur downstream performance on genomic benchmarks indicates the potential of METAGENE-1 as a general-purpose foundation model. Our results also indicate that METAGENE-1 benefits from continual pretraining on a diverse mixture of data sources in addition to metagenomic data (at least for tasks similar to these genomic benchmarks). We are continuing to actively explore this direction, through incorporating additional human reference genomes and multi-species genomic datasets in our metagenomic pretraining data.\nLimitations. METAGENE-1 is pretrained on a dataset consisting primarily of wastewater metagenomics and multi-species genomic sequences, making it well-suited for downstream tasks within this distribution. However, like many foundation models, it requires additional fine-tuning to achieve optimal performance for specific applications. Additionally, the pretraining data predominantly consist of short metagenomic sequencing reads, limiting the model's performance to contexts involving shorter metagenomics inputs. This may restrict its effectiveness for tasks involving long-read or full-genome data, where long-sequence models may be necessary (Nguyen et al., 2024a,b).\nFuture directions. There are many potential avenues for future research. An area that we are particularly excited about concerns the understanding of genomic foundation models. While a great deal of prior work has studied the mechanistic interpretability of language models (Wang et al., 2022, Hanna et al., 2024, Conmy et al., 2023, Syed et al., 2023), their extensions beyond language and vision have been limited. Future work could systematize approaches to mechanistic interpretability in genomics by leveraging sparse autoencoders (SAEs) (Bricken et al., 2023, Gao et al., 2024, Lieberum et al., 2024) to identify biologically meaningful features, employing attribution methods to trace model predictions to genomic regions (Koo and Ploenzke, 2020, Tseng et al., 2020, Majdandzic et al., 2022), and developing new tools for probing model representations using task-specific datasets (Conneau et al., 2018, Hewitt and Liang, 2019). A better understanding of these models would not only advance their reliability but also help mitigate risks, such as inadvertently generating or propagating harmful genomic sequences."}]}