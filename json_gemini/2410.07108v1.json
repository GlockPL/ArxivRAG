{"title": "FAIR GPT: A VIRTUAL CONSULTANT FOR RESEARCH DATA MANAGEMENT IN CHATGPT", "authors": ["Renat Shigapov", "Irene Schumm"], "abstract": "FAIR GPT is a first virtual consultant in ChatGPT designed to help researchers and organizations make their data and metadata compliant with the FAIR (Findable, Accessible, Interoperable, Reusable) principles. It provides guidance on metadata improvement, dataset organization, and repository selection. To ensure accuracy, FAIR GPT uses external APIs to assess dataset FAIRness, retrieve controlled vocabularies, and recommend repositories, minimizing hallucination and improving precision. It also assists in creating documentation (data and software management plans, README files, and codebooks), and selecting proper licenses. This paper describes its features, applications, and limitations.", "sections": [{"title": "Introduction", "content": "The FAIR (Findable, Accessible, Interoperable, Reusable) principles are now a widely accepted framework for scientific data management and stewardship [1]. However, despite their importance, many researchers and organizations struggle to implement these principles effectively due to a range of cultural, technical, and organizational barriers [2, 3, 4].\nFAIR GPT, a customized virtual consultant in ChatGPT, addresses some of these challenges by providing automated support for making data and metadata FAIR-compliant. This paper presents its features, applications by researchers and data stewards, and limitations of the tool."}, {"title": "1 Features", "content": "FAIR GPT offers features that assist researchers and data stewards in various aspects of research data management (RDM). These features help users ensure their data complies with the FAIR principles, and meet the needs of their institutions and funders.\n\u2022 RDM consultancy. FAIR GPT acts as a virtual consultant, providing guidance on best practices in research data management. It assists researchers and organizations in structuring their data workflows, ensuring compliance with FAIR principles, and addressing challenges related to data stewardship.\n\u2022 Metadata review. It reviews uploaded or copy-pasted metadata, assessing it against international standards. The tool provides suggestions for improving metadata, ensuring compliance with FAIR principles. Additionally, FAIR GPT connects to external resources such as the TIB Terminology Service API to suggest terms from controlled vocabularies and ontologies, and to the Wikidata API to ensure the correct use of Wikidata identifiers.\nWithout querying external terminology services, ChatGPT may generate inaccurate or fictitious identifiers for terms from controlled vocabularies, leading to potential errors in metadata and vocabulary alignment [5, 6].\"\n\u2022 Data organization. Organizing datasets properly is critical for their reusability. FAIR GPT recommends best practices for dataset organization, offering guidance on optimal folder structures, file naming conventions, and data hierarchies.\n\u2022 Documentation creation. FAIR GPT assists users in generating key documentation necessary for proper data stewardship. These include Data Management Plans (DMPs), Software Management Plans (SMPs), README files, and codebooks. Based on the provided dataset and code, FAIR GPT tailors the documentation to the specific needs of the project, ensuring that the data can be easily understood, reused, and cited.\n\u2022 FAIR assessment. It supports two open APIs for FAIR data assessment: FAIR-Checker [7] and FAIR-Enough [8]. By analyzing how well a dataset adheres to FAIR principles, FAIR GPT provides actionable recommendations for improving findability, accessibility, interoperability, and reusability. This helps users enhance the overall quality of their data and metadata.\n\u2022 Data Licensing Recommendation. FAIR GPT provides guidance on selecting appropriate data licenses based on the type of dataset, its intended use, and the relevant legal and institutional frameworks. This ensures that data sharing is legally compliant while promoting reuse.\n\u2022 Data repository selection. Selecting an appropriate repository is crucial for ensuring long-term data archiving and compliance with FAIR principles. FAIR GPT leverages the re3data API to recommend suitable repositories.\n\u2022 Data paper publication. FAIR GPT also assists researchers in identifying suitable data journals for publishing data papers, which increases the visibility of their datasets and enhances their citation potential. It provides recommendations for journals such as Scientific Data, Data in Brief, and other relevant outlets based on the research domain and our instructions2.\nFAIR GPT also utilizes the uploaded research data management resources, including the \"Guidelines on FAIR Data Management in Horizon 2020\" [9], \"Turning FAIR into reality \u2013 Final report and action plan from the European Commission expert group on FAIR data\" [10], and \"A curated GitHub-list of awesome RDM resources for researchers and organizations\" [11]. These resources help FAIR GPT to provide well-informed recommendations for RDM best practices."}, {"title": "2 Applications", "content": "FAIR GPT supports both researchers and data stewards by automating key aspects of research data management, thus reducing manual effort and improving the overall quality and FAIRness of datasets.\nFor researchers. FAIR GPT simplifies the process of preparing data and metadata for sharing and publication. Researchers can use the tool to draft rich metadata, generate essential documentation (e.g., README files, codebooks, DMPs, and SMPs), and select suitable data repositories for long-term archiving. By automating these tasks, FAIR GPT allows researchers to focus on their core scientific activities while ensuring their datasets meet the FAIR principles. Once a dataset is published, researchers can also ask FAIR GPT to assess its FAIRness by providing the dataset's DOI, as illustrated in Figure 1a. This feature helps researchers check whether the data is FAIR after publication.\nFor data stewards. FAIR GPT can assist data stewards with reviewing and improving datasets submitted to data repositories. The tool evaluates the quality of metadata, assesses the organization of datasets, and reviews accompanying"}, {"title": "3 Limitations", "content": "While FAIR GPT offers useful features, it also has several limitations that affect its applicability in real-world practice:\n\u2022 Hallucinations. Despite using external APIs to minimize hallucinations, FAIR GPT may still generate incorrect or misleading recommendations, especially in novel or ambiguous cases. These hallucinations can introduce errors into metadata recommendations, reducing the overall reliability of the tool's outputs.\n\u2022 Lack of provenance for generated data. FAIR GPT does not provide clear sources for recommendations it generates. This lack of transparency makes it difficult for users to trace the origins of suggested improvements, reducing the trust in the generated answers.\n\u2022 Evolving data management practices. The field of research data management is continually evolving, and FAIR GPT requires continuous updates to stay relevant. Without frequent updates, the tool risks becoming outdated and ineffective.\n\u2022 Privacy concerns for sensitive data. FAIR GPT is not specifically designed to handle sensitive or restricted data, and it may not adequately account for legal or institutional protocols related to personal data, such as anonymization and compliance with data protection regulations (e.g., GDPR). Users dealing with sensitive datasets should refrain from uploading or copy-pasting such data into FAIR GPT, as it may introduce privacy risks.\n\u2022 There is no API. FAIR GPT does not offer an API for external integration, which limits its ability to be embedded into automated workflows or custom research data management systems. As a result, users must rely on manual interaction through the graphical interface, which can be time-consuming and less efficient."}, {"title": "Conclusions", "content": "FAIR GPT is the first virtual consultant designed to assist with research data management in compliance with the FAIR principles. It automates tasks such as metadata enhancement, dataset organization, and documentation creation, reducing the manual effort required for FAIR compliance. By integrating external APIs, FAIR GPT improves the precision of its recommendations. However, the tool has limitations, including potential hallucinations, lack of provenance for generated data, and no API for external integration, which limits scalability. Privacy concerns restrict its use with sensitive datasets. Despite these limitations, FAIR GPT offers valuable support by streamlining data management tasks and improving metadata quality. Addressing challenges such as hallucinations and lack of provenance could further enhance its applicability."}]}