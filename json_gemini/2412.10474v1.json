{"title": "CROSSVIT-AUGMENTED GEOSPATIAL-INTELLIGENCE\nVISUALIZATION SYSTEM FOR TRACKING ECONOMIC\nDEVELOPMENT DYNAMICS", "authors": ["Yanbing Bai", "Jinhua Su", "Bin Qiao", "Xiaoran Ma"], "abstract": "Timely and accurate economic data is crucial for effective policymaking. Current challenges in\ndata timeliness and spatial resolution can be addressed with advancements in multimodal sensing\nand distributed computing. We introduce Senseconomic, a scalable system for tracking economic\ndynamics via multimodal imagery and deep learning. Built on the Transformer framework, it\nintegrates remote sensing and street view images using cross-attention, with nighttime light data\nas weak supervision. The system achieved an R-squared value of 0.8363 in county-level economic\npredictions and halved processing time to 23 minutes using distributed computing. Its user-friendly\ndesign includes a Vue3-based front end with Baidu maps for visualization and a Python-based\nback end automating tasks like image downloads and preprocessing. Senseconomic empowers\npolicymakers and researchers with efficient tools for resource allocation and economic planning. The\ncode used in this paper can be found in Github.", "sections": [{"title": "1 Introduction", "content": "Different levels of sensing imagery has been widely used in various human activities including agriculture [Yang et al.,\n2013, Nguyen et al., 2020], environmental study [Chen et al., 1997, Albert et al., 2017, Bochenek et al., 2018, Suel et al.,\n2021], transportation [Kiwon Lee et al., 2003, Shaker et al., 2010, Abdelraouf et al., 2022], etc. The imagery contains\nboth spatial and temporal information, providing scientists with enormous information unavailable in traditional census\nand economics data. Traditional approaches to tracking economic development have relied on statistical data, which\noften lacks spatial and temporal resolution [Fobi et al., 2022, Suel et al., 2021]. However, the rapid development\nof Earth observation technology has enabled the acquisition of high-resolution and timely satellite remote sensing\ndata and street view data, providing an alternative and complementary source of geospatial data for tracking regional\ndevelopment patterns [Yeh et al., 2020, Rolf et al., 2021]. In recent years, advances in artificial intelligence (AI),\nremote sensing technologies, and computer vision have shown great potential in transforming the analysis of economic\ndevelopment using satellite imagery [Han et al., 2020, Hall et al., 2022], highlighting the need for continued exploration\nand development of novel methodologies and techniques including integrating different sources of imagery.\nRecent studies have demonstrated the utilization of satellite imagery for scoring economic development and socioe-\nconomic status [Khachiyan et al., 2022, Abitbol and Karsai, 2020, Han et al., 2020], market returns [Yu et al., 2023],\npredicting household electricity consumption [Fobi et al., 2022], understanding economic well-being in Africa [Yeh\net al., 2020], and mapping poverty [Ayush et al., 2021, Geng et al., 2023]. These works have proposed deep learning-\nbased frameworks for learning to score economic development from satellite imagery, leveraging imagery and statistical\ndata [Akbari et al., 2021, Suel et al., 2021], and incorporating macroscopic social network mining [Geng et al., 2023].\nFurthermore, research has shown the potential for extracting socioeconomic indicators from high-resolution satellite\nimages, such as urban patterns [Abitbol and Karsai, 2020], livelihood impact of electricity access [Ratledge et al.,\n2022], and aggregating multi-level geospatial information [Park et al., 2022]. Apart from solid AI models, an integrated\nquery-extraction-visualization system is needed for better visual interpretations. A comprehensive online system opens\nopportunities for more users and researchers to ease their understanding and needs for scientific research.\nDrawing inspiration from these studies, we integrate the latest advancements in multi-source imagery economic\nmonitoring, supervised image processing techniques, and big data processing and visualization systems to develop a\ncomprehensive framework for extracting and analyzing socioeconomic indicators from high-resolution satellite images.\nThis research mainly involves the following two issues: (1) Currently, research using a single modal imagery source\nis prevalent [Han et al., 2020, Yeh et al., 2020, Engstrom et al., 2021, Doll et al., 2006, Sutton and Costanza, 2002],\nmainly focused on satellite imagery, with less use of cost-effective data sources such as street view images. There are\nfew studies that utilize multimodal imagery sources to assess regional socio-economic indicators. Researching regional\nsocio-economic indicators with multimodal imagery sources requires addressing the statistical consistency between\nstreet view images and satellite imagery, as well as the fusion of different modal data. (2) Concerning model-predicted\neconomic indicators, the challenge is how to visualize them efficiently, quickly, and at low cost at the county level to\naid in analysis, decision-making, and research.\nBased on these two issues, considering the close relationship between nighttime light data and regional socio-economic\nindicators [P\u00e9rez-Sind\u00edn et al., 2021, Liu et al., 2021, Proville et al., 2017, Gibson et al., 2021, Hassan et al., 2011],\nthis study plans to use nighttime light data as a proxy variable for local economic indicators. Using China's satellite\nimagery and street view images as multimodal data sources, the study aims to build a multimodal deep learning model\nfor economic indicators and visualize the predicted results.\nIn this paper, we introduce Senseconomic, an online satellite imagery-driven geospatial intelligence system for tracking\neconomic dynamics. The system includes a systematic process to acquire, process, and analyze high-resolution satellite\nand street view imagery, employing a rigorous methodology for data acquisition, processing, and cropping [Rolf et al.,\n2021, Ayush et al., 2021]. In addition, we incorporate advancements in big data processing and visualization systems to\nenable the efficient analysis and presentation of results [Park et al., 2022, Geng et al., 2023]. Considering the correlation\nbetween nighttime light data and socioeconomic indicators [Hassan et al., 2011, Proville et al., 2017, P\u00e9rez-Sind\u00edn et al.,\n2021, Liu et al., 2021, Gibson et al., 2021], we use nighttime light data as a proxy for economic metrics. Using China's\nsatellite and street view imagery, this study develops a multimodal deep learning model to predict and visualize regional\neconomic indicators effectively."}, {"title": "2 Prediction Model", "content": "In this section, we provide the architecture of the prediction model used for analyzing multi-source imagery. The\nmodel integrates techniques from both computer vision and deep learning, leveraging the Vision Transformer (ViT) and\nCross-Attention mechanisms."}, {"title": "2.1 Vision Transformer", "content": "In this paper, we use Vision Transformer (ViT) to extract information from images. ViT splits an image into fixed-size\npatch"}]}