{"title": "A Simple and Provable Scaling Law for the Test-Time Compute of Large Language Models", "authors": ["Yanxi Chen", "Xuchen Pan", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "abstract": "We propose a general two-stage algorithm that enjoys a provable scaling law for the test-time compute\nof large language models (LLMs). Given an input problem, the proposed algorithm first generates $N$\ncandidate solutions, and then chooses the best one via a multiple-round knockout tournament where\neach pair of candidates are compared for $K$ times and only the winners move on to the next round. In a\nminimalistic implementation, both stages can be executed with a black-box LLM alone and nothing else\n(e.g., no external verifier or reward model), and a total of $N \\times (K + 1)$ highly parallelizable LLM calls\nare needed for solving an input problem.\nFor an input problem, assuming that a generated candidate solution is correct with probability\n$P_{\\text{gen}} > 0$ and a comparison between a pair of correct and incorrect solutions identifies the right win-\nner with probability $P_{\\text{comp}} > 0.5$ (i.e., better than a random guess), we prove theoretically that the\nfailure probability of the proposed algorithm decays to zero exponentially with respect to $N$ and $K$:\n$P(\\text{final output is incorrect}) \\leq (1 \u2013 P_{\\text{gen}})^N + [\\log_2 N]e^{-2K (P_{\\text{comp}}-0.5)^2}$\nOur empirical results with the challenging MMLU-Pro benchmark validate the technical assumptions,\nas well as the efficacy of the proposed algorithm and the gains from scaling up its test-time compute.", "sections": [{"title": "Introduction", "content": "Despite the astonishing advancements of large language models (LLMs) in the past few years, they still\nface challenges with reliability and stability. This hinders their applications in high-stakes scenarios where\na problem need to be solved with success probability 99.9% rather than 90%. Similarly, in an LLM-based\nagentic workflow that involves solving many sub-problems, each of them need to be solved with a high success\nprobability in order to ensure the success of the complete workflow, since a single error in the process can lead\nto an incorrect final output. In these and many other similar scenarios, one is willing to boost the success\nprobability by spending more test-time computation on LLM inference. Common approaches include letting\nthe LLM generate a long chain-of-thought trajectory [27, 13, 19], or asking the LLM to iteratively self-verify\nor self-refine the solutions that it has generated [5, 17, 6, 32, 33]. Another category of approaches is about\nsampling multiple candidate solutions and then choosing the best one via majority voting [3, 25, 2, 14],\nranking with pairwise comparisons [9], or using an external verifier [31, 11] or trained reward model [15, 35].\nThe primary goal of this work is to provide some theoretical insights into the full potential of scaling up\nthe test-time compute for LLM inference [22, 29]. Our main contributions are summarized as follows:\n\u2022 We propose a two-stage algorithm that enjoys a provable scaling law for the test-time compute of\nLLM inference, while requiring only a black-box LLM and nothing else (e.g., no external verifier or\nreward model) for a minimalistic implementation. Given an input problem, the proposed algorithm\nfirst generates multiple candidate solutions, and then choose a single one among them as the final\noutput, via a knockout tournament where pairwise comparisons among the candidates are conducted.\n\u2022 We prove theoretically that, as the test-time compute of this algorithm scales up, its failure probability\nin solving a specific problem (i.e., the probability that the final output is incorrect) decays to zero\nexponentially with respect to the total number of LLM calls. This guarantee relies on two natural\n(and arguably minimal) assumptions: (1) the LLM can generate a correct solution with a non-zero\nprobability, and (2) the LLM can do better than a random guess in choosing the right winner between\na pair of correct and incorrect solutions.\n\u2022 Our practical implementation of the proposed algorithm is efficient and scalable, with support for\nparallel and distributed computation. Empirical results with the MMLU-Pro benchmark [26] validate\nthe aforementioned assumptions, and confirm the gains from scaling up the test-time compute of the\nproposed algorithm."}, {"title": "A two-stage algorithm", "content": "Problem formulation. We consider a generic problem formulation where an LLM-based algorithm is\ngiven an input problem and asked to output a solution. For conceptual simplicity, we evaluate any solution\nwith a binary metric indicating whether it is correct or incorrect\u00b9. Our goal is to design a general LLM-based\nalgorithm whose success probability, i.e., the probability of returning a correct solution to the input problem,\ncan be boosted monotonely up to 1 by scaling up its test-time compute.\nThe proposed algorithm. We consider the following two-stage algorithm for solving an input problem:\n1. Generation. We first generate $N$ candidate solutions, which can run in parallel. In situations where\nthe final answer to the problem contains only a few tokens (e.g., for multiple-choice problems or math\ncalculation), we require that each solution contains a reasoning process or explanation of the rationale\nthat leads to its final answer, which can be elicited by chain-of-thought prompting [27, 13] for example;\nsuch information can be useful for enhancing pairwise comparisons in the next stage.\n2. Knockout. We aggregate the candidate solutions via a knockout tournament. At each round of the\ntournament, the candidates are grouped into pairs randomly, and each pair of candidates are compared"}, {"title": "Analysis of success probability: a provable scaling law", "content": "Our theoretical guarantee for the proposed algorithm critically relies on the following assumption about the\ninput problem under consideration and the LLM(s) being used.\nAssumption 1. For the input problem $x$, there exists $P_{\\text{gen}} > 0$ such that\n$P_{y\\sim M_{\\text{gen}}(x)}(y \\text{ is a correct solution}) \\geq P_{\\text{gen}} > 0$.\nIn addition, there exists $P_{\\text{comp}} > 0.5$ such that, for an arbitrary pair of candidate solutions $(y, y')$ where one\nof them is correct and the other is incorrect, it holds that\n$P_{r \\sim M_{\\text{comp}}(x,y,y')} (r \\text{ identifies the right winner}) \\geq P_{\\text{comp}} > 0.5$."}, {"title": "Analysis of efficiency", "content": "The minimalistic implementation of the proposed algorithm starts by generating $N$ candidate solutions with\n$N$ LLM calls that can run in parallel. Since the number of candidates is reduced by half at each round of the\nknockout tournament, there is at most $\\lceil \\log_2 N \\rceil$ rounds in total. For notational convenience, let us assume\nthat $N$ is a power of 2 for the rest of this analysis. At the $i$-th round, there are $N/2^i$ pairs of candidates,\nand each pair need $K$ comparisons; thus a total of $K \\times N/2^i$ LLM calls are needed, which again can be\nparallelized.\nIn sum, the total number of LLM calls required by the two-stage algorithm is\n$N + K \\times (\\frac{N}{2} + \\frac{N}{2^2} + \\frac{N}{2^3} + \u2026 + \\frac{N}{2^{\\lceil \\log_2 N\\rceil-1}} + 1) \\leq N + K \\times N = (K + 1) \\times N,$\nwhereas the end-to-end latency, if sufficiently many machines are available, is merely\n$T_{\\text{gen}} + \\log_2(N) \\times T_{\\text{comp}},$\nwhere $T_{\\text{gen}}$ and $T_{\\text{comp}}$ represent the latency of one LLM call for generating a candidate solution and for\ncomparing a pair of solutions, respectively."}, {"title": "Experiments", "content": "Setup. We validate the efficacy of the proposed two-stage algorithm and the above analysis with the\nchallenging MMLU-Pro benchmark [26]. It contains 14 categories of multiple-choice questions, some of which\nrequire advanced reasoning for obtaining the correct answers. Due to limited computational resources, we\nuse a randomly sampled subset of 100 questions for each category in our experiments, which leads to a total\nof 1400 questions.\nOur implementation of the proposed algorithm, which is built upon the AgentScope framework [7], is\nefficient and scalable, with support for parallel and distributed computation. We use two open LLMs in\nour experiments, namely Llama3.1-70B-Instruct [16] and Qwen2.5-72B-Instruct [30]. The temperature\nfor LLM decoding is set to 0.8 for both models. We use zero-shot chain-of-thought prompting for both\ngenerating a candidate solution and comparing a pair of solutions; the complete prompts can be found in\nTables 1 and 2 in Appendix C."}, {"title": "Discussions", "content": "This is still work in progress, with various limitations and remaining work that need to be done. We provide\ndetailed discussions of some aspects in this section."}, {"title": "The rationales behind Assumption 1", "content": "The proposed two-stage algorithm by itself is aimed at problems that a single LLM call can possibly solve\nbut without absolute certainty, e.g., with a non-zero success probability $p_{\\text{gen}}$ that can be 90% or merely 5%.\nIn such scenarios, Assumption 1 is arguably the minimal assumption that one can hope for, as $p_{\\text{comp}} > 0.5$\nmeans the LLM can do better than a random guess in distinguishing a correct solution from an incorrect\none\u00b3. We make a few comments about the assumption of $p_{\\text{comp}} > 0.5$:"}, {"title": "Solving complex tasks with the proposed method", "content": "The theoretical guarantee in Theorem 1 is not directly applicable to challenging problems that do not\nsatisfy Assumption 1. The common practice of solving a challenging problem with LLM-based algorithms or\nagentic workflows [4, 34] is to leverage task decomposition, i.e., decomposing it into multiple sub-problems\nand solving each one by one. As long as the sub-problems satisfy Assumption 1 after task decomposition,\nwe can apply the proposed method to each of them. This approach offers not only guarantees for the success\nprobability of solving the original problem, but also higher efficiency compared to solving it directly.\nTo see this, consider a scenario where solving the original problem requires solving all $S \\geq 1$ sub-problems\ncorrectly, and each sub-problem satisfies Assumption 1 with parameters $p_{\\text{gen}}$ and $p_{\\text{comp}}$. Directly solving all\n$S$ sub-problems has a exponentially small success probability $p_{\\text{gen}}^S$, and thus generating a correct candidate\nsolution alone already requires $\\Omega((1/p_{\\text{gen}})^S)$ computation, not to mention identifying which generated can-\ndidate is correct. In contrast, by conducting task decomposition and applying our proposed method to each\nsub-problem, it suffices to guarantee a failure probability of $\\delta/S$ in solving each sub-problem, which implies\nan overall success probability of $1 - \\delta$ for solving the original problem, thanks to the union bound. According\nto Eq. (1), this is guaranteed with\n$N \\geq \\frac{1}{p_{\\text{gen}}} \\log (\\frac{2S}{\\delta}) \\text{ and } K \\geq \\frac{1}{2(p_{\\text{comp}} - 0.5)^2} \\log (2 \\log_2 N \\frac{S}{\\delta}).$\nNote that $N$ and $K$ only have logarithmic dependence on the number of sub-problems $S$. The total number\nof LLM calls with this approach is $(K + 1) \\times N \\times S$ (cf. Section 2.2), which grows with $S$ linearly, up to\nlogarithmic factors."}, {"title": "Towards better algorithms with provable scaling laws", "content": "The proposed two-stage algorithm in this work shall be regarded as a prototype or a general principle for\nalgorithm design, which can be further enriched in various ways.\nSimple and practical improvements. There can be numerous ways of improving the practical perfor-\nmance, such as increasing the diversity of initial candidate solutions (e.g., by using different prompts or\nLLMs [24]), conducting pairwise comparison with a specifically fine-tuned LLM [18] / an ensemble of mul-\ntiple LLMs / a non-LLM method [9], reducing the number of unnecessary pairwise comparisons via early\nstopping, tuning the prompts or decoding temperatures (e.g., using a higher temperature in the generation\nstage for diversity and lower temperature in the knockout stage for preciseness), among others.\nAn anytime algorithm. The proposed algorithm can be easily converted to an \u201canytime\" variant [28]\nthat does not require pre-specifying $N$, i.e., the number of initial candidates. This can be useful in practice,\nwhen the amount of test-time compute is adaptive. For example, the algorithm might start with 4 candidate\nsolutions and choose the winner via a knockout tournament. If more test-time compute is allowed (e.g.,\nthe user is not eagerly requesting the solution, or more computational resources become available), then\nthe algorithm can launch another tournament with 4 freshly sampled candidates, the winner of which will\ncompete with the winner of the previous tournament. This complete process is indeed equivalent to a single\ntournament with $N = 4 + 4 = 8$. Such a process can continue until the user finally requests the solution;\nthe eventual value of $N$ is determined online and automatically achieves the maximum value allowed by the\navailable test-time compute.\nDropping the hyperparameter $K$. The theory in Section 2.1 suggests that, in order to achieve a targeted\nsuccess probability $1 \u2013 \\delta$, each pair of solutions in the tournament need to be compared for $K$ times before\nthe winner is chosen, where $K$ need to be pre-specified and depends on $p_{\\text{comp}}$ according to Eq. (1). In\nreality, $p_{\\text{comp}}$ is often unknown a priori. To address this, we provide an alternative analysis in Appendix B,\nwhich suggests that, perhaps surprisingly, the algorithm still works even if $K$ is set to 1 or any other value.\nIn other words, the success probability of the algorithm is boosted monotonely up to 1 while the single\nhyperparameter $N$ scales up. This alternative analysis is still preliminary though; we leave the complete\nanalysis to future work.\nPushing the Pareto front of accuracy versus efficiency. It is not yet clear whether the proposed\nalgorithm is theoretically optimal under Assumption 1. The amount of test-time compute needed to achieve\na success probability $1 \u2013 \\delta$ can be derived from Eq. (1). But is there a different algorithm that can achieve\na better computational complexity, under either Assumption 1 or other plausible assumptions? What is the\ntheoretical lower bound for the computational or sample complexity? It would be exciting to see further\nprogress in resolving these questions."}, {"title": "Proof of Theorem 1", "content": "To begin with, we have a straightforward analysis for the failure probability of the generation stage of the\nalgorithm, where $N$ candidate solutions are sampled independently:\n$P(\\text{no candidate solution is correct}) \\leq (1 \u2013 P_{\\text{gen}})^N$.\nAs for the knockout stage, let us first consider a single pair of correct and incorrect candidate solutions.\nRecall that they are compared for $K$ times with $K$ LLM calls, and each LLM call identifies the correct\ncandidate solution as the winner with probability $\\mu > P_{\\text{comp}} > 0.5$ by assumption. Therefore, the failure\nprobability of comparing this pair of candidates can be bounded as follows, where $X_i$ denotes an independent\nBernoulli random variable with mean $\\mu$:\n$P(\\text{failure of comparison}) \\leq P(\\sum_{i \\in [K]} X_i \\leq \\frac{K}{2}) = P(\\sum_{i \\in [K]} X_i \\leq 0.5).$"}, {"title": "An alternative analysis", "content": "We provide an alternative analysis for the proposed algorithm, to show that it still enjoys a provable scaling\nlaw when the hyperparameter $K$ is fixed at an arbitrary value. For concreteness, let us consider the extreme\ncase of $K = 1$, i.e., each pair of candidate solutions in the tournament are compared only once, with success\nprobability $p_{\\text{comp}} > 0.5$. We will demonstrate that the success probability of the overall algorithm still grows\nto 1 monotonely with $N$ in this case.\nFor simplicity, let us assume that $N$ is a power of 2. Let $p_i$ be the probability that a candidate solution\nat the $i$-th level of the knockout tournament is correct, where $i = 0, 1, \u2026, \\log_2 N$. This is feasible since\nall candidates within the same level of the tournament have symmetric roles. Initially, $p_0 = P_{\\text{gen}}$. Next,\nif $p_i$ is given, we can derive $p_{i+1}$ inductively as follows. A candidate at the $(i + 1)$-th level is the winner\nof pairwise comparison between a pair of statistically independent candidates at the $i$-th level. Thus, the\nwinner is correct if both candidates of the pair are correct, or only one of them is correct and happens (with\nprobability $p_{\\text{comp}}$) to be chosen as the winner. Therefore,\n$p_{i+1} = p_i^2 + 2p_i(1 \u2013 p_i)p_{\\text{comp}} = p_i^2 + 2p_{\\text{comp}}(p_i - p_i^2) = p_i - p_i + p_i^2 + 2p_{\\text{comp}}(p_i - p_i^2)$\n$= p_i + (2p_{\\text{comp}} - 1)(p_i \u2013 p_i^2)$.\nThis implies $p_{i+1} > p_i$, as long as $p_{\\text{comp}} > 0.5$ and $p_i < 1$. More concretely, there are two cases:"}, {"title": "Additional empirical results", "content": "This appendix includes empirical results for the categories of MMLU-Pro that are complementary to those\nin Figure 3, the prompts used in our experiments, and concrete case studies that demonstrate how our\nalgorithm works when solving specific questions."}]}