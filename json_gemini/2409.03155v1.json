{"title": "Debate on Graph:\na Flexible and Reliable Reasoning Framework for Large Language Models", "authors": ["Jie Ma", "Zhitao Gao", "Qi Chai", "Wangchun Sun", "Pinghui Wang", "Hongbin Pei", "Jing Tao", "Lingyun Song", "Jun Liu", "Chen Zhang", "Lizhen Cui"], "abstract": "Large Language Models (LLMs) may suffer from hallucina-tions in real-world applications due to the lack of relevantknowledge. In contrast, knowledge graphs encompass exten-sive, multi-relational structures that store a vast array of sym-bolic facts. Consequently, integrating LLMs with knowledgegraphs has been extensively explored, with Knowledge GraphQuestion Answering (KGQA) serving as a critical touchstonefor the integration. This task requires LLMs to answer nat-ural language questions by retrieving relevant triples fromknowledge graphs. However, existing methods face two sig-nificant challenges: excessively long reasoning paths distract-ing from the answer generation, and false-positive relationshindering the path refinement. In this paper, we propose aniterative interactive KGQA framework that leverages the in-teractive learning capabilities of LLMs to perform reason-ing and Debating over Graphs (DoG). Specifically, DoG em-ploys a subgraph-focusing mechanism, allowing LLMs toperform answer trying after each reasoning step, thereby mit-igating the impact of lengthy reasoning paths. On the otherhand, DoG utilizes a multi-role debate team to graduallysimplify complex questions, reducing the influence of false-positive relations. This debate mechanism ensures the relia-bility of the reasoning process. Experimental results on fivepublic datasets demonstrate the effectiveness and superiorityof our architecture. Notably, DoG outperforms the state-of-the-art method ToG by 23.7% and 9.1% in accuracyon WebQuestions and GrailQA, respectively. Furthermore, the integration experiments with various LLMs on the mentioneddatasets highlight the flexibility of DoG.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs), characterized by their substantial parameter amount (Zhang et al. 2023) and trainingon extensive, diverse, and unlabeled data (Rawte, Sheth, andDas 2023), exhibit remarkable proficiency in a wide rangeof natural language understanding and generation tasks (Linet al. 2023; Liu et al. 2024). For example, GPT-4 (Achiamet al. 2023) demonstrates human-level performance acrossa majority of professional and academic exams originallyintended for humans. However, recent studies (Guan et al.2024; Waldendorf, Haddow, and Birch 2024; Gunjal, Yin,and Bas 2024) have revealed that they may suffer from hal-lucinations in real-world applications due to a deficiency inrelevant knowledge.\nKnowledge graphs (Wang et al. 2024) are large-scale,multi-relational structures housing a plethora of sym-bolic facts, such as the triple <The Eiffel Tower,\nlocatedIn, Paris>. The incorporation of these structured facts may tackle the aforementioned issue of hallu-cinations in LLMs (Guan et al. 2024; Quintero-Narvaezand Monroy 2024; Shi et al. 2023). One approach to eval-uating the integration of knowledge graphs with LLMs isthrough Knowledge Graph Question Answering (KGQA)(Ji et al. 2022), which requires machines to answer naturallanguage questions by retrieving relevant facts from knowl-edge graphs. Recent works (Li et al. 2024; Toroghi et al.2024; Nie et al. 2024) primarily follow an iterative inferenceparadigm, consisting of two steps: (1) identifying the ini-tial entity in the question, and (2) retrieving and refining theinference path iteratively until reaching the answer or obtaining sufficient evidence to answer the question. Althoughthey have achieved significant success, they still suffer fromexcessively long paths and false-positive relations.\nChallenge 1: excessively long paths distracting fromthe answer generation. Existing methods (Ye et al.2022; Guo et al. 2023a; Kim et al. 2023) usuallyfeed a lengthy evidence path like {<Albert Nobbs,starred_by, Glenn Close>,\nAir ForceOne, starred_by, Gray Oldman>,.} at the topof Fig. 1 into LLMs to perform answer generation in a singlestep, which may make it challenging for LLMs to discern thekey points in the path. For instance, LLMs may focus on thetail entity Glenn Close and employ their internal priorknowledge to generate answers. This will result in answersthat appear reasonable but are incorrect.\nChallenge 2: false-positive relations hindering the pathrefinement. Current methods (Bai et al. 2023; Hu et al.2024; Li et al. 2024) typically focus on identifying relationswithin graphs that closely match or have the same meaningas those in the questions, even if the relations have already"}, {"title": "Method", "content": "Given a knowledge graph G consisting of N triples, represented as {(e\u1d62, r\u1d62, e\u1d62\u208a\u2081) | e\u1d62 \u2208 E, r\u1d62 \u2208 R, i \u2208 [1, I], l \u2208[1, L]}, where e\u1d62 and e\u1d62\u208a\u2081 denote the head and tail entity, respectively, I is the number of entities, L denotes the numberof relations, and r\u1d62 is the relation between entities, KGQArequires machines to answer natural language questions qbased on retrieved evidence paths P = {p\u2c7c}\u2c7c\u208c\u2081 with p\u2c7c representing a triple and m denoting the number of triples. Inthis paper, we leverage LLMs to reason over P and generateanswers a word by word."}, {"title": "Overview", "content": "As depicted in Fig. 2, given a K-hop question q and theinitial topic entity e within q, our framework first invokesknowledge graphs to retrieve the set of candidate relationsR linked to e. Then, it enables LLMs to filter out the mostrelevant relation \u00ee\u2081 from R based on in-context learning.Subsequently, the knowledge graph is invoked again to complete the triple information from (e, \u03b9, ?) to (e, r\u2081, e\u1d62\u208a\u2081).Fourthly, DoG focuses on the current reasoning state andemploys LLMs to decide on the subsequent action basedon the completed triple: providing a direct answer to thequestion or performing deep thinking with further iterations.In the latter scenario, a multi-role LLM team leverages thementioned triple to transform the K-hop question to a K-1hop (slightly easier) one through debate, with the tail entity e\u1d62\u208a\u2081 being the subsequent topic entity for the simplifiedquestion in the next iteration. All of these debate steps areautonomously executed by the LLM team. The iteration willbe ended until LLMs generate answers in the fourth step."}, {"title": "Knowledge Graph Invoking", "content": "Reasoning on graphs requires LLMs first to identify relevantknowledge triples. To facilitate this, we have designed twointeractive interfaces specifically tailored to retrieve thesetriples from knowledge graphs. The interfaces are invokedas needed, depending on the requirements.\n\u2022 get_relations(e): This interface is designed to retrievethe candidate relation set R associated with the entity e.For example, in Fig. 2, it is invoked to retrieve the candi-date relation set of Joe Anderson.\n\u2022 triple_filling(e', \u03b9): This interface is responsible for ob-taining the tail entity <e, \u03b9, ?> given the head entityand the filtered relation. We will introduce relation filter-ing in the next subsection.\nThe underlying mechanisms of these interfaces are imple-mented through either SPARQL (for Freebase queries) orspecific matching (for questions in MetaQA). To facilitatecomprehension and generation by LLMs, all entities and re-lationships above the interfaces are expressed in natural lan-guage, with the conversion between a Machine ID (MID)and a corresponding friendly name carried out exclusivelywithin the interfaces. The MID facilitates efficient accessto comprehensive details related to the entity. More specifi-cally, in Freebase, the MID is a unique identifier assigned toeach entity, allowing for straightforward retrieval of entity-specific information. The friendly name of the MID is anatural language descriptor. For example, the MID of thefriendly name Jamaican is m.03_r3."}, {"title": "Relation Filtering", "content": "Through get_relations(e), we obtain a candidate relation setR associated with the initial entity in the question. Subsequently, DoG selects the optimal relation \u00ee\u2081 from this setthrough in-context learning. The prompt and in-context ex-amples are detailed in the In-context Learning subsection ofthe appendix. Specifically, DoG first utilizes LLMs to iden-tify the first-hop problem to be solved in the given ques-tion q. Then, it allows LLMs to choose the optimal relationaccording to the mentioned sub-question. This serves as aguiding principle for relation selection, avoiding the con-stant reliance on the complete multi-hop question through-out the entire reasoning stage, as seen in previous stud-ies (Jiang et al. 2023a; Sun et al. 2024). We believe this"}, {"title": "Answer Trying", "content": "After obtaining the optimal relation, our architecture in-vokes the triple-filling interface triple_filling(e, \u00ee\u2081) toacquire a complete triple, such as <Joe Anderson,~starred_actors, High Life> in Fig. 2. Then,DoG utilizes LLMs to determine whether the retrieved triplecan sufficiently support answering the question. If the tripleis insufficient, DoG prompts LLMs to deeply contemplatethe current question based on the provided triple. This allows DoG to generate answers based on a single triple, thusavoiding excessively long and potentially confusing pathscomposed of multiple triples. The prompt and in-context ex-amples are detailed in the In-context Learning subsectionof the appendix. Notably, if the maximum iteration limit isreached without successfully generating an answer, the pa-rameterized knowledge of LLMs is utilized to respond."}, {"title": "Question Simplifying", "content": "Once LLMs determine that a question is unanswerable withthe current retrieved triple, it represents that further explo-ration is required. Inspired by how humans tackle complexquestions, our architecture employs a question-simplifyingstrategy to transform questions from K hop to K-1 hopbased on the retrieved triple. Specifically, DoG utilizes ateam of agents with distinct roles to engage in debate, en-suring the reliability of the reasoning process. The debateteam consists of three roles.\n\u2022 Question simplifying expert (R1). This expert providesinitial simplifications for questions, which may containapparent errors. For example, the original question in Fig.2 is initially simplified as \"What are some notable filmsin which Joe Anderson has acted?\". This is far from theintention of the original question.\n\u2022 Critic (R2). The critic examines the simplification effortsof the above expert and offers suggestions for modifica-tions. For instance, the above question is modified into\"When did High Life which was starred by Joe Ander-son release?\".\n\u2022 Linguist (R3). This role ensures that the simplifiedquestion is not only semantically correct but also freefrom redundant information of previously resolved sub-questions. For example, the mentioned question is furtherrefined to \"When did [High Life] release?\".\nDue to the interdependency and progressive nature of theroles played by the three agents, DoG employs a one-by-onediscussion strategy (Chan et al. 2023). Each agent, imple-mented by ChatGPT, takes turns contributing to the ongoingoptimization of the simplified question, with the statementsmade by other agents serving as references for guiding sub-sequent remarks generation. After simplification, we obtaina slightly easier K-1 hop question, prompting LLMs to un-dergo iteration once again. In this way, the relation in the"}, {"title": "Experiments", "content": "We select five public datasets to evaluate the reasoning ability over knowledge graphs: MetaQA (Zhang et al. 2018),WebQSP (Yih et al. 2016), CWQ (Talmor and Berant 2018),WebQuestions (Berant et al. 2013), and GrailQA (Gu et al.2021). MetaQA comprises a movie ontology derived fromthe WikiMovies dataset (Miller et al. 2016) and containsthree sets of natural language question-answer pairs: 1-hop,2-hop, and 3-hop. WebQSP contains questions sourced fromthe WebQuestions dataset, which are answerable using Free-base. CWQ is designed for answering complex questionsthat require reasoning over multiple web snippets. GraiQA,which tests three-level generalizations including i.i.d., com-positional, and zero-shot, covers 3,720 relations and 86 do-mains from Freebase. Following (Xiong, Bao, and Zhao2024; Sun et al. 2024), we uniformly sample 500 instancesper type for the mentioned five datasets to reduce computa-tional cost. We use exact match accuracy (Hits@1)to evaluate the reasoning performance of our frameworkand baselines following previous works (Jiang et al. 2023a;Xiong, Bao, and Zhao 2024; Sun et al. 2024; Baek, Aji, andSaffari 2023). For the experiment of integrating DoG withGPT-4, we uniformly sample only 100 instances per typefrom the mentioned datasets to reduce costs."}, {"title": "Implementation Settings", "content": "We preprocess the MetaQA dataset to construct a structuredknowledge graph, facilitating subsequent query and retrievaloperations. A local Virtuoso server is deployed for datasetsderived from the Freebase. We utilize the OpenAI API tocall ChatGPT (gpt-3.5-turbo-0125) and GPT-4 (gpt-4-0613).Additionally, we employ Qwen-14B and Llama-3-8B, run-ning on 8 V100 GPUs, to verify the flexibility of DoG. Themaximum number of debate rounds for the multi-agent teamis limited to three, with only the best unique relation beingrecalled. We implement in-context learning across multiplemodules: specifically, 10 exemplars for Relation Filteringand Answer Trying, and one exemplar for Question Simpli-fying."}, {"title": "Baselines", "content": "Inspired by (Jiang et al. 2023a), we compare DoG withprevious state-of-the-art supervised learning and in-contextlearning-based methods, to verify its effectiveness and supe-riority. Supervised learning: KV-Mem (Miller et al. 2016),GraftNet (Sun et al. 2018), PullNet (Sun, Bedrax-Weiss, andCohen 2019), EmbedKGQA (Saxena, Tripathi, and Taluk-dar 2020), NSM (He et al. 2021), TransferNet (Shi et al.2021), UniKGQA (Jiang et al. 2023b). In-context learning:StructGPT (Jiang et al. 2023a), KG-GPT (Kim et al. 2023),KB-BINDER (Li et al. 2023b), ToG (Sun et al. 2024). Thebaselines are detailed in the Baseline Introduction subsec-tion of the appendix."}, {"title": "Reasoning on Knowledge Graphs", "content": "Main Result Table 1 presents a comparison across fivepublic datasets. Taking GPT-3.5 as an example, we ob-serve that DoG enables it to achieve competitive results"}, {"title": "Flexibility Verification", "content": "We conduct experiments on theaforementioned datasets to explore whether DoG enablesother LLMs, including QWen, Llama, and GPT-4, to achievecomplex reasoning on knowledge graphs. Experimental re-sults in Table 1 show that DoG facilitates improvements in some cases compared to GPT-3.5. Specifically, DoG withLlama achieves a 1.6% improvement on WebQSP. It alsoallows GPT-4 to achieve the most significant improvementon the mentioned datasets. These results clearly demonstratethe flexibility and effectiveness of our architecture. We ob-serve that the performance of DoG with Qwen is slightlylower than with other LLMs. This could be attributed toits marginally weaker complex reasoning capabilities com-pared to other LLMs."}, {"title": "Ablation Studies", "content": "We conduct ablation experiments on the aforementioneddatasets to analyze the contribution of each component ofDoG. The ablation results for DoG with GPT-3.5 are pre-"}, {"title": "Analyses for Debate Rounds", "content": "We conduct experiments to explore how the number of de-bate rounds affects LLM reasoning on knowledge graphs.Fig. 3 shows the performance trend of DoG with GPT-3.5as the number of debate rounds increases across the fivedatasets mentioned. We observe that DoG achieves the bestresults on the majority of datasets with just a single roundof debates. Additionally, increasing the number of debaterounds leads to a performance decrease in some datasets.DoG utilizes a one-by-one discussion strategy, which makeseach agent aware of the historical debate record. This makesthe agents more susceptible to being influenced by the viewsof others, potentially leading to inaccurate decisions forquestion simplifications. We may also conclude that theagent is sufficiently strong to achieve the goal of instructionswithout needing iterative debates."}, {"title": "Exemplar Impacts", "content": "DoG leverages in-context learning to guide LLMs in per-forming relation filtering, question simplification, and an-swer trying during iterative reasoning. Specifically, DoGprovides instructions and exemplars to help LLMs achievethese objectives. We conduct experiments on five publicdatasets to explore the impact of the number of exemplars on"}, {"title": "Error Analyses", "content": "To analyze the deficiency of DoG, we randomly select 50failure cases from each dataset, including MetaQA, We-bQSP, and GrailQA, for manual inspection. Fig. 5 showsthe proportion of factors contributing to these errors. We ob-serve that relation filtering errors are quite common. Thismay be caused by too many relations linked to the entitiesin questions, making it difficult for LLMs to accurately filterthe most relevant relation. Iteration stopping errors denoteLLMs make inaccurate decisions in the answer-trying mod-ule, either terminating the iterative reasoning too early or toolate. This type of error is particularly prevalent in GrailQAcases. Answer aliasing errors mean the generated answers donot have the same description or wording as the annotations,even though they are semantically consistent. This error canbe mitigated by introducing a rich collection of aliases. Answer generation errors refer to that LLMs provide incorrectanswers based on accurately retrieved triples and simplifiedquestions. Question simplifying errors represent that LLMsfail to transform questions from complex to easy. Addition-ally, other errors account for 4% of the failure cases in eachdataset. This type of error often occurs due to API accessissues, an excessively long context, or exceeding the tokenlimit per minute. More details can be found in the FailureCases subsection of the appendix."}, {"title": "Conclusion and Future Work", "content": "This paper proposes an iterative interactive framework,DoG, for knowledge graph question answering. It lever-ages the interactive learning and reasoning capabilities ofLLMs to perform debating on knowledge graphs. Specifi-cally, it employs a team of multi-role agents to transformquestions from complex to simple, enabling LLMs to perform reliable step-by-step reasoning based on the retrieved"}, {"title": "Appendix", "content": "Table 3 shows the prompt, instruction, and exemplar utilizedin the module within DoG.\nBaseline Introduction\nThe brief introduction of supervised-based baselines is asfollows.\n\u2022 KV-Mem (Miller et al. 2016) is a key-value memory net-work that enhances the viability of reading knowledge sources, such as documents or knowledge bases, by uti-lizing different encodings during the addressing and out-put stages of the memory read operation.\n\u2022 GraftNet (Sun et al. 2018) aims to provide answers basedon a question-specific subgraph that includes text, enti-ties, and relations. It employs heterogeneous update rulesto handle knowledge base nodes differently from text nodes and utilizes a directed propagation method to con-strain the propagation of embeddings within the graphs.\n\u2022 PullNet (Sun, Bedrax-Weiss, and Cohen 2019) builds onthe early GraftNet system but focuses on learning how toconstruct the subgraph. Unlike GraftNet, PullNet lever-ages a limited set of retrieval operations, with each oper-ation expanding a graph node by acquiring new informa-tion from knowledge bases or corpora.\n\u2022 EmbedKGQA (Saxena, Tripathi, and Talukdar 2020) isthe first work that utilizes knowledge graph embeddingsto perform multi-hop question answering over sparseknowledge graphs.\n\u2022 NSM (He et al. 2021) is a teacher-student network inwhich the student network aims to retrieve the correctanswer to a question, while the teacher network learnsin"}]}