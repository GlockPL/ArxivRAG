{"title": "AutoML for Multi-Class Anomaly Compensation of Sensor Drift", "authors": ["Melanie Schaller", "Mathis Kruse", "Antonio Ortega", "Marius Lindauer", "Bodo Rosenhahn"], "abstract": "Addressing sensor drift is essential in industrial measurement systems, where precise data output is necessary for maintaining accuracy and reliability in monitoring processes, as it progressively degrades the performance of machine learning models over time. Our findings indicate that the standard cross-validation method used in existing model training overestimates performance by inadequately accounting for drift. This is primarily because typical cross-validation techniques allow data instances to appear in both training and testing sets, thereby distorting the accuracy of the predictive evaluation. As a result, these models are unable to precisely predict future drift effects, compromising their ability to generalize and adapt to evolving data conditions. This paper presents two solutions: (1) a novel sensor drift compensation learning paradigm for validating models, and (2) automated machine learning (AutoML) techniques to enhance classification performance and compensate sensor drift. By employing strategies such as data balancing, meta-learning, automated ensemble learning, hyperparameter optimization, feature selection, and boosting, our AutoML-DC (Drift Compensation) model significantly improves classification performance against sensor drift. AutoML-DC further adapts effectively to varying drift severities.", "sections": [{"title": "1. Introduction", "content": "Sensor drift is prevalent in industry [1], autonomous driving [2], and intelligent systems with integrated sensors [3]. In these use cases, where decision making is based on the real-time accuracy of measurement systems, sensor drift poses significant practical challenges. This phenomenon occurs due to factors such as poisoning or environmental changes [4], sensor aging [5], and mechanical wear [6], leading to progressively inaccurate sensor readings. These inaccuracies impact machine learning (ML) models by introducing variability in input data, which compromises the accuracy and reliability of the model [7]. While, in general, drift is characterized by observations inconsistent with data used for training, we note that there are scenarios where the patterns of temporal change that produce sensor drift are predictable. For example, sensor aging may lead to decreased sensitivity, that is, the same ambient conditions lead to smaller sensor readings. This paper uses automated machine learning (AutoML) techniques to develop a new training paradigm and a sensor drift compensation [8] solution for this type of scenario, where the patterns of identifiable temporal drift are predictable to some extent. Specifically, we assume that the relationship between time and changing sensor behavior can be learned in major parts as a function. This function is intended to capture the drift dynamics with linear and non-linear parts (see Section 3 and Section 9.4) and extrapolate to future unseen data."}, {"title": "", "content": "This allows our method to learn from the drift observed in the training data and enhance the capability of models to adapt and maintain accuracy despite sensor drift, and it could also be used for drift self-calibration in sensor measurements [9]. Although conventional techniques use random subsets of data for training/validation, we propose two training strategies to evaluate different aspects of sensor drift compensation. The first training strategy involves a novel sensor drift compensation framework and handles drift in an anomaly detection setting. The second strategy utilizes an incremental batch learning approach to validate the integration performance of new drift patterns.\nOur research focuses on the following two key aspects:"}, {"title": "(1) Novel sensor drift compensation learning paradigm", "content": "As the first part of the novel learning paradigm, we introduce a sensor drift compensation learning strategy. For this strategy, our work closely relates to anomaly, or out-of-distribution, detection, where models are typically trained on normal data and evaluated on faulty data [10]. We propose a novel training setting for sensor drift compensation that can replace widely utilized 10-fold cross-validation or random sampling strategies for model training and evaluation [11]. Instead, we assume an increasingly severe temporal drift will occur in the training data. Thus, the training data represents initial drift states, and the trained model is expected to learn to compensate for observed (more severe) drift present at later stages in the test data, which can be seen as a variant of the drift adaptation task [12]. Most importantly, we assume that the sensor drift is separable from the data, making it possible to compensate for and reconstruct the original data from noisy measurements. However, we will show that the complex drift dynamics will make explicit drift modeling difficult, leading us to propose our model, which implicitly compensates for the sensor drift effects.\nMotivated by Su\u00e1rez-Cetrulo et al. [13], we introduce an incremental batch learning strategy as the second part of our novel training paradigm. This approach is particularly well-suited for environments where sensor data are received in a streaming fashion, and a continuous adaptation to new information is of interest. In this second learning setup, the model continuously ingests batch data, adjusting its parameters to account for drift and other variables in the environment. This ongoing learning process improves the model's ability to adapt to new patterns and anomalies, resulting in a more robust model performance even as the underlying data distribution evolves. Our framework assumes an iterative learning process. The model updates"}, {"title": "", "content": "its understanding of the data distribution in batches, ensuring that newly observed drift patterns are promptly integrated into the predictive framework. This method minimizes the need for large-scale retraining episodes, making it suitable for contexts that demand low-latency responses. The combination of anomaly detection and batch learning techniques (see Figure 3) in one novel learning paradigm ensures the model remains vigilant to out-of-distribution events while continually refining its predictions based on the batch data.\nWithin different experiments, we demonstrate that several existing methods for sensor drift compensation are ineffective in learning the drift and, therefore, fail when the conventional validation setting is slightly modified. We demonstrate that previously published approaches cannot adequately compensate for the drift effect because of their unrealistic training setups. Existing methods typically learn average models that assume a uniform distribution across all data, making them less effective in the presence of drift. In contrast, our approach learns a static model from the initial batches and explicitly captures the drift dynamics by analyzing the differences between consecutive batches. This enables us to extrapolate the drift behavior to unseen data, providing a more accurate solution to sensor drift."}, {"title": "(2) AutoML Drift Compensation", "content": "We show that AutoML techniques"}, {"title": "", "content": "can improve the results on the drift compensation task in our proposed setting by about 16% compared to all other benchmarking models. In our context, drift compensation means that inherent sensor drift is present in the data, which can be compensated for using AutoML techniques. This ensures that the model's predictions remain accurate to a higher degree despite changes in the data distributions. This is achieved by combining various models and different preprocessing and hyperparameter settings that can learn different aspects of the drift. We showcase experimentally that employing AutoML techniques, such as automated ensemble learning with varying model weights, automated feature preprocessing, optimization of hyperparameters, boosting and imputation strategies, as well as others visualized in Figure 2, allows for the learning of anomaly patterns within the training data. This enables the model to extrapolate from smaller drift effects to increasingly pronounced anomalous effects, thus compensating for sensor drift.\nWe summarize our contributions as follows:"}, {"title": "", "content": "1. We demonstrate that the commonly used training settings are flawed\nin learning and compensating for sensor drift"}, {"title": "", "content": "2. We propose a novel sensor drift compensation learning training paradigm\nthat closely matches real-world scenarios."}, {"title": "", "content": "3. Our findings indicate that AutoML techniques\u00b9, along with the pro-\nposed training setting, enable effective drift adaptation to evolving lev-\nels of drift severity and complex drift dynamics."}, {"title": "2. Related Work", "content": "Automated Machine Learning (AutoML). Machine Learning has succeeded in countless applications [14, 15, 16, 17], raising the demand for automated and streamlined solutions. The field of AutoML, which aims to find well-performing models automatically, has been receiving increased attention [18]. To ensure the flexibility and robustness needed for our sensor drift task, different AutoML techniques are applied, such as dynamic feature selection, model tuning, and adaptation to new drift patterns without extensive manual intervention, addressing the limitations of prior approaches that require fixed models and extensive domain knowledge."}, {"title": "", "content": "Several frameworks, such as SMAC3 or auto-sklearn implement these techniques and are used in many different use cases [19, 18, 20]. Many AutoML frameworks resort to approaches such as Bayesian optimization to guide the non-trivial search for strong hyperparameters given a specific model [18, 19]. The problem of algorithm selection (AS) aims to find the most suitable algorithm for a given task. Other fields, such as Neural Architecture Search (NAS) aim to find new neural network architecture and topologies, to solve new tasks [21].\nDrift Compensation. Prior drift compensation methods can be categorized into five types: component correction, adaptive methods, sensor signal pre-processing, attuning methods, and machine learning approaches."}, {"title": "Component correction methods", "content": "use methods such as Principal Component Analysis (PCA) or Independent Component Analysis (ICA) to identify and eliminate drift components [22, 23]. For dynamically evolving data sets, which regularly change due to drift, these component correction methods would need continual retraining to consider current statistics\u2014making them labor-intensive and inefficient in comparison to systems designed to compensate dynamically without regular re-training. Furthermore methods like PCA, primarily a linear dimensionality reduction method, assumes that the main variability in the data can be captured in a reduced orthogonal space. This works well for stable datasets but can underperform if variability is erratic, time-dependent, or non-linear. ICA finds components that are statistically independent, which might not align with how drift manifests over time. Drift often appears as correlated sequential data changes not fully captured by static independence assumptions. In comparison our AutoML Drift Compensation framework allows a flexible adaptation by learning patterns, updating as the data evolves without the need for constant retraining from scratch, unlike static PCA/ICA frameworks."}, {"title": "Adaptive methods", "content": "include evolutionary algorithms that optimize a multiplicative correction factor for incoming samples. These algorithms, like the one proposed by Di Carlo et al. [24], continuously adapt the correction factor through linear transformations within a restricted time window. Although Evolutionary algorithms can find optimal solutions within complex, high-dimensional spaces, the multiplicative correction factor assumes drift can be corrected through simple linear scaling, which might not suffice for nonlinear drift patterns. The focus on short-term optimization can also lead to overfitting to noise or transient anomalies in the data hindering adaptation"}, {"title": "", "content": "to sustained nonlinear drift dynamics. In comparison our AutoML ensemble methods might capture multi-faceted drift patterns by combining models that individually address different components of the drift. AutoML-DC can also include model evaluation strategies that balance fitting the data while avoiding over-adjustment to noise.\nPreprocessing methods involve baseline manipulation and filtering strategies. Baseline manipulation transforms sensor signals based on initial values using differential, relative, or fractional transformations. Filtering strategies, such as the Discrete Wavelet Transform (DWT), mitigate drift by discarding low-frequency components associated with drift and reconstructing the signal from the remaining components [25]. Nevertheless, preprocessing techniques generally assume that drift patterns, such as baselines or low-frequency components, remain constant over time. This constancy allows them to calibrate and correct the data based on fixed parameters. Thus it is not useful for dynamically adjusting to new drift patterns or evolving drift like in our use-case, as it is used in a rather static manner. With the Auto-ML DC model, we instead combine and learn different preprocessing parameters dynamically according to the temporal drift patterns, that are learnable. Choosing and combining preprocessing strategies alongside model configurations also allows more immediate responses to evolving drifts.\nAttuning methods aim to correct drift components without relying on calibration samples, instead deducing drift directly from training data. Orthogonal Signal Correction (OSC) is one such method, which removes non-correlated variance in sensor-array data [26].Methods like Orthogonal Signal Correction (OSC) remove components orthogonal to the drift, thus eliminating the non-correlated variance in the data set. Thus, They rely on previously seen drift effects being representative for current and future drift compensation. Attuning methods often rely on the assumption that drift manifests in identifiable components (e.g., orthogonality) that are separated and compensated. Unlike attuning methods that are preset to correct only previously identified drift components, AutoML-DC can learn from broader, potentially evolving drift patterns within and beyond initial training data, which is shown in the extensive experiments with different training strategies. In cases where drift doesn't appear as (e.g. orthogonal) component, AutoML-DC might also recognize shifts in sensor behavior dynamically across the operational data range.\nMachine learning approaches initially focused on adaptive drift correction using neural networks [27]. These methods, however, demand a sub-"}, {"title": "3. Formalisation of the Drift Compensation Problem", "content": "In real-world applications, sensors often operate over extended periods, leading to aging and degradation. This degradation is commonly referred to as sensor drift, induced by elusive dynamic processes such as poisoning, aging, or environmental variations [28, 29] and has to be compensated by machine learning models, that are employed to monitor sensory systems. The drift compensation problem can be formulated as follows. Let \\(T_1, T_2, ...,T_K\\) denote time-series data across K batches, organized chronologically. Each time series \\(T_i\\) is defined as \\(T_i = \\{x_{ij}\\}_{j=1}^{N_i}\\), where \\(x_{ij}\\) represents the feature vector of the j-th sample in Batch i, and \\(N_i\\) is the number of samples in Batch i. The sensor drift issue arises when the feature distributions of \\(T_2, ..., T_K\\) deviate from that of \\(T_1\\). Consequently, a classifier trained on labeled data from \\(T_1\\) exhibits degraded performance when tested on \\(T_2, ..., T_K\\) due to diminished generalization caused by drift, which needs to be compensated. The mismatch in distribution between \\(T_1\\) and \\(T_i\\) becomes irregularly more pronounced with increasing batch index i (i > 1) and aging."}, {"title": "4. Formalisation of the Anomaly Compensation Task within AutoML", "content": "The goal is to train a classifier f using the labeled data from the first \\(k_{train} < K\\) batches, with \\(D_{train} = \\{1, ..., k_{train}\\}\\), in a supervised manner."}, {"title": "", "content": "The classifier is trained to predict class labels \\(C_{ij}\\) based on the feature vectors \\(x_{ij}\\). The classifier has to learn both the normal data as well as initial drift patterns from the first few batches and generalize them to later batches where increased drift severity is observed. We argue that generalizing from the initial drift effects to the more pronounced drifts in later batches is a more realistic and more challenging setting. The trained classifier f is then tested on the last \\(k_{test} = K - k_{train}\\) batches, i.e. \\(D_{test} = \\{k_{train} + 1, ..., K\\}\\).\nTo gain enough flexibility to compensate for all drift effects, we model our classifier f as an ensemble of known models, such as MLPs or Random Forests, and optimize it as an algorithm selection and hyperparameter optimization problem (CASH) [20]. We determine the set of algorithms for the ensemble out of a pool of algorithms A, with each \\(a_i \\in A\\) having its own hyperparameter space \\(\\Lambda_i \\in A\\). Searching for the best-performing model becomes the optimization problem\n\\((a^*, \\lambda^*) \\in \\arg \\max_{a_i \\in \\mathcal{A}, \\lambda \\in \\Lambda_i} c(a_i, \\lambda), \tag{1}\\)\nwhere a* denotes the optimal choice of model and \\(\\lambda^*\\) the respective choice of hyperparameters. The cost function c(a_i, \\lambda) quantifies the performance of the current model \\(a_i\\) with some hyperparameter choice \\(\\lambda\\). In our case, c is modeled using the F1-score, while we also track metrics such as precision and recall. Using the k best-performing models determined by the optimization problem above, an ensemble is built to make predictions more robust against sensor drift.\nIn our paper, we optimize this problem using the auto-sklearn framework [19], which also optimizes the choice of feature pre-processing, such as different embeddings, PCA or other encodings. To navigate the search space more efficiently, trading off exploration and exploitation, Bayesian optimization methods are used to guide the search. Utilizing results from meta-learning, the models are instantiated using initial instantiations pre-computed by auto-sklearn, which are determined using carefully selected and empirically found meta-features. The final ensemble is built with ensemble selection techniques and validated on a hold-out set [30, 19]."}, {"title": "5. Dataset Description", "content": "To the best of our knowledge, the dataset by Vergara et al. [11] is the only dataset that fully represents the sensor drift problem in a practical setting."}, {"title": "", "content": "This dataset is particularly valuable for our research because it captures the complexities of sensor drift in a real-world industrial environment, where such issues frequently occur. Other sensor drift datasets, such as those from IntelLab [31], Santander [31], and SensorScope [31], primarily involve synthetic drift, which does not fully capture the nuanced challenges presented by natural sensor drift. Specifically, Vergara et al. curated a dataset featuring responses from a sixteen-element array of metal-oxide semiconductor gas sensors in a 60 ml test chamber. Various odorants, including ammonia, acetaldehyde, acetone, ethylene, ethanol, and toluene, that represent the multi-classes, were injected into the chamber and measured at a constant flow rate of 200 ml/min. The sensors operated at 400 \u00b0C, heated by an external DC voltage source. Resistance time series with a 100 Hz sampling rate, were collected over 36 months, with a deliberate 5-month gap to induce contamination. The dataset contains a total of 13,910 recordings and is introduced as sensor drift dataset with increasing drift severity over time."}, {"title": "5.1. Batch distributions and dataset structure", "content": "According to the setting's definition above, we divide the used data set into K = 10 batches, subdivided into \\(k_{train} = 5\\) training and \\(k_{test} = 5\\) test batches. All runs in the code have been repeated ten times to see the robustness and significance of the results and the standard deviation has been calculated. In order to conduct a fair comparison of all models the hyperparameters of all models have been optimized due to their specific conditions. As all implemented benchmarking models have different specifications, we track the full set of tuned hyperparameters in the appendix due to capacity reasons.\nSince most samples are recorded in later batches, up to the 16th month or Batch 5, we extended the data inclusion up to the fifth batch for training. Thus, the training dataset contains 3633 samples out of 10277. This decision was driven by the already substantial imbalance in the dataset [32]. Further data set descriptions are found in Appendix A.1 and Appendix A.2."}, {"title": "6. Novel Sensor Drift Training Paradigm", "content": "As part of our novel learning paradigm, we address the sensor drift compensation challenge using a two-fold strategy that combines anomaly detection principles with an incremental batch learning approach. This paradigm"}, {"title": "", "content": "is designed to validate the model's robustness and adaptability in the face of dynamic sensor drift.\nFirst, we utilize a learning approach inspired by anomaly detection, training models on initial, drift-free data. This data serves as a baseline for adapting to intensified drift conditions, allowing the model to implicitly manage the complex, non-linear dynamics of sensor drift without explicit modeling.\nSecond, we implement an incremental batch learning strategy for real-time data environments. This approach enables the model to continuously adjust parameters in response to new data, ensuring robust performance against evolving drift characteristics. This method minimizes the need for comprehensive retraining, allowing the model to integrate new drift patterns and maintain accuracy. The incremental addition of batches simulated a real-world scenario where a model is periodically retrained with new data and was motivated from [33]."}, {"title": "7. Evaluation Metrics", "content": "To evaluate the performance of our models in compensating for sensor drift, we employ several key metrics: Precision, Recall, F1-Score, Accuracy, and the Area Under the Receiver Operating Characteristic Curve (AUC-ROC). Precision is defined as the ratio of true positive predictions to the sum of true positive and false positive predictions. It measures the accuracy of the positive predictions made by the model [34]. Recall, also known as sensitivity, measures the ratio of true positive predictions to the sum of true positives and false negatives [34]. The F1-Score is the harmonic mean of Precision and Recall, especially useful for imbalanced datasets [34].Accuracy is defined as the ratio of correctly predicted instances to the total instances in the dataset [35].The AUC-ROC metric evaluates the model's ability to distinguish between classes across various thresholds, offering a comprehensive measure of classification performance [36].\nThe choice of these metrics is motivated by their relevance to the task of sensor drift compensation. Precision and recall provide insights into the correctness and completeness of positive predictions, respectively. The F1-score balances these two metrics, accounting for class imbalances. Accuracy is used for its general assessment capability and is supplemented by AUC-ROC to ensure robust evaluation across various thresholds. These metrics should collectively enable a multifaceted performance evaluation. In our study, machine learning models are specifically designed to recognize and"}, {"title": "", "content": "compensate for sensor drift over time, emphasizing accuracy and robustness across drift levels rather than immediate detection and response. Thus, we employ metrics that effectively assess how well the models manage changing data distributions due to drift. Metrics such as drift detection delay and adaptation time are more pertinent to system-level responses, where operational adjustments are critical. However, our approach focuses on optimizing model parameters for predictive accuracy amidst drift within controlled training paradigms. Thus, speed-focused metrics have been excluded."}, {"title": "8. Hyperparameters of baseline models", "content": "In our study, we tuned the hyperparameters across a range of machine learning models to ensure fair benchmarking. For the XGBoost model, we optimized the learningrate, max-depth, and n-estimators hyperparameters. The Support Vector Machine (SVM) model required tuning of C (regularization parameter), gamma (kernel coefficient), and kernel type. For the Random Forest classifier, we adjusted the max-depth, min-samples-split, and n-estimators. For Logistic Regression, the hyperparameters C (inverse regularization strength), solver (optimization algorithm), and max-iter (maximum iterations) were optimized. The Gradient Boosting model required tuning of the learningrate, max-depth, and n-estimators. For Gaussian Na\u00efve Bayes (GaussianNB), we focused on optimizing var-smoothing.\nThe Decision Tree classifier's hyperparameters criterion (splitting function), max-depth, and min-samples-split were modified. The performance of the k-Nearest Neighbors (kNN) model was enhanced by selecting the optimal num-clusters. For ARIMA, we used the autoarima function. The Autoencoder required adjustments of the input-dim, encoding-dim, num-layers, and learningrate. Hyperparameters for Auto-Sklearn included per-run-time-limit, ensemble-size, and metalearning components.\nFor GRU (Gated Recurrent Unit) and LSTM (Long Short-Term Memory) networks, we tuned hidden-size, num-layers, and learningrate. The Convolutional Neural Network (CNN) was optimized with filter-size, kernel-size, pool-size, and dense-units. The Drift-Ensemble, using a \"hard\" voting strategy, was optimized with the Kruskal-Wallis, Shapiro-Wilk, and Mann-Whitney U tests. In order to tune other hyperparameters the \"hard\u201d voting strategy would have to be changed to a \"soft\" voting strategy, which was not the intention of the paper. Therefore, we left the model like it was supposed to be from the authors. For Anomaly-GAN, we fine-tuned hidden-dim and"}, {"title": "", "content": "learningrate. These hyperparameter optimizations have been used to ensure a fair comparison. The ranges of the optimized hyperparameters can be looked up in the repository. The libraries are listed in the \u2018requirements.txt\u2018 file of the provided repository. All experiments were conducted on CPUs, specifically Intel Xeon Processor with 128GB RAM, running Ubuntu 18.04. However, the code is compatible with GPU execution as well, which can be utilized depending on availability."}, {"title": "9. Experimental Results", "content": "As discussed before, we use the well-studied sensor drift dataset proposed by Vergara et al. [11], which contains real-world sensor-drift data. In this dataset, a certain baseline drift can be observed, but also additional short-term as well as long-term drift effects [32]. Therefore, the machine learning models employed for classifying multiple classes must be able to learn the basic patterns of a hybrid form of sensor drift (see Figure A1) at early stages and accurately learn and predict the subsequent higher levels. Rather than relying on random sampling or ten-fold cross-validation [11], we aim to train the model on our proposed training paradigm. In the first benchmarking results section, we use the Anomaly detection strategy for training. Subsequently, the model should demonstrate proficiency in predicting the accurate classes for the ensuing five batches, characterized by distinct distributions from the initial batches due to high drift severity. Consequently, the models are tasked with learning the distinctive sensor drift patterns present in the initial batches, enabling them to forecast the correct classes for the subsequent unseen batches. As comparison we also showcase the results on the originally proposed training setup for selected models to proove our claim. To further evaluate the classification performance, we also document the AUC-ROC Scores for all benchmarking models. We also conducted a drift linearity test to distinguish between drift effects. Afterwards we also compare the decision boundaries of Random Forest as most frequently used model in the AutoML-DC ensemble against Support Vector Machine (SVM) boundaries with RBF-Kernel. To further investigate the robustnes of the models we also compare the standard deviation and mean accuracy values for all benchmarking models. Afterwards we use the second learning strategy of our learning paradigm to show the capability of the models to adapt to temporal changes of drift effects. Lastly we conduct extensive experiments on the effects of AutoML techniques within the AutoML-DC model to showcase"}, {"title": "", "content": "the single effects within an ablation study. To ensure comparable results, the number of epochs and batch sizes were kept constant across all experiments, while all hyperparameters were specifically tuned according to the specific model conditions."}, {"title": "9.1. Benchmarking results for sensor drift with the anomaly detection training setup", "content": "Based on prior work, as discussed in Section 2, we choose the most frequently used models that have been implemented on the dataset. Since Random Forest [37] showed good results in other studies, we explore other decision tree-based models [38] and Gradient Boosting [39], to assess their impact in comparison. Next, we compare these results against Kernel methods like SVM [40] with RBF Kernel and a Gaussian Naive Bayes Model [41].\nThe third group of models we choose for comparison are temporal baseline models like LSTM [40], GRU [42] and a temporal CNN [43]. As a fourth group, we also investigate the performance of CatBoost [44] against AdaBoost [45], XGBoost [46] and Bagging [47]. The fifth group of models is the instance-based learning model KNN (k nearest neighbours) [48] with an optimized number of neighbours. As one of the review papers on this dataset [49] stated, that spiking neural networks (SNN) could be useful to solve tasks on drift data, we included these models as the sixth group of models.\nThe ensemble drift compensation, that was introduced by Vergara et al. [11] especially on this dataset is also used as benchmarking model. The last group is formed by a generative adversarial network (GAN) to solve the anomaly classification or anomaly detection [50, 51, 52]. For an overview of GANs used in anomaly detection tasks see [53]. Here, the discriminator score is taken to set the threshold for each class.\nTable 1 summarizes the performance metrics of the selected machine learning models. Precision, recall, and F1-score [54] are utilized to evaluate the models, providing a comprehensive assessment of their ability to learn patterns of sensor drift.\nAs the table shows, none of the benchmarking models achieved an F1 score exceeding 60% for our proposed drift compensation setting. Conversely, the ensemble drift compensation of Vergara et al. [11] displays lower scores across all metrics, suggesting a diminished ability to accurately detect sensor drift anomalies despite the promising results of the ensemble model for the whole dataset with random sampling. The Spiking Neural Network (SNN) also exhibits relatively low precision, recall, and F1-score, indicating limited"}, {"title": "", "content": "effectiveness in this context, although it was shown to work well for the random sampling strategy. The AutoML-DC framework leverages meta-learning strategies, streamlining the hyperparameter tuning process and reducing the computational burden compared to traditional methods. This strategic approach, in combination with the other AutoML techniques, improves model configuration, leading to a consistent outperformance with an F1 score of 76%. We note that integrating a rigorous comparison with state-of-the-art drift compensation methods, such as adaptive and component-correction approaches, into this multi-class classification setting presents significant challenges. These methods are not specifically designed for simpler binary classification or regression tasks, which makes direct comparisons in a multi-class context complex. Specifically, each class in the dataset may experience drift at different rates and in different manners, requiring a model that can simultaneously handle complex interdependencies across multiple classes. While a"}, {"title": "", "content": "binary classification approach could isolate these class-specific drift patterns, it might not capture interactions between classes. Thus, methods other than machine learning models have been excluded from the benchmarking results to guarantee a fair comparison, given that a simple adaptation of binary classification methods in terms of One-vs-Rest or One-vs-One might not be sufficient."}, {"title": "9.2. Results on original training scenario as comparison", "content": "In order to be able to compare the results of the benchmarking study on the proposed drift compensation setting with the original training strategy, we present the results for some major models trained with 10 fold cross validation on the same dataset as follows in Table 2:"}, {"title": "9.3. AUC-ROC Scores for benchmarking models", "content": "When trained in the proposed sensor drift compensation task, the AUC-ROC scores for the benchmarking models have been calculated for all classes"}, {"title": "", "content": "(see Figure 4). AutoML-DC performs exceptionally well, as indicated by its ROC curve near the top left corner. This positioning suggests that AutoML-DC achieves a high True Positive Rate with a low False Positive Rate, reflecting the best classification performance in comparison to the other models. Gradient Boost, XGBoost, Bagging, and Adaboost demonstrate strong ability to distinguish between classes, with ROC curves that approach the ideal top-left corner, indicating higher accuracy in these in comparison to the other models. Our approach prioritizes methods that align closely with the evaluation of how models adapt and maintain performance in dynamic environments. Using AUC-ROC scores, we provide a statistically robust framework to evaluate and validate the effectiveness of the model at different classification thresholds."}, {"title": "9.4. Drift Linearity Test", "content": "We employed a support vector regression test to analyze the drift effect in the context of linearity. The primary objective of this test is to provide an initial qualitative assessment of the balance between linear and non-linear drift components using kernel function comparisons. We conducted the originally proposed ten-fold cross-validation for training and testing on the whole dataset (that is, on all batches) and compared the results of the support vector machine (SVM) with a linear kernel against the results of the SVM with an RBF kernel.\nThe choice of kernel (linear or RBF) impacts the decision boundary of the SVM [55]. A linear kernel corresponds to a linear decision boundary in the input space. It assumes that the underlying relationship between the features and the target variable is linear. The linear kernel is effective when the data can be adequately separated by a hyperplane. The Radial Basis Function (RBF) kernel, also known as the Gaussian kernel, introduces nonlinearity by transforming the input space into a higher-dimensional space. It allows the SVM to capture more intricate relationships in the data. The RBF kernel is particularly useful when the decision boundary is complex and nonlinear, see Figure 5. The effectiveness of the linear kernel with an Accuracy of 0.97 implies that a significant portion of the sensor drift can be explained by linear relationships between features and classes. On the other hand, the slightly better performance of the RBF kernel with an Accuracy of 0.98 indicates that there are also additional non-linearities in the data."}, {"title": "9.5. Decision boundaries", "content": "As Random Forest was investigated to be a good sensor drift compensator in the drift compensation setting, we further compare the decision boundaries learned by a Random Forest to those of a Support Vector Machine with RBF-Kernel.\nFor this plot, 50% of the datapoints of each batch have been taken to train the classifiers. While the Random Forest model shows quite complex decision boundaries but with almost all samples being correctly classified for the first two learned features, the SVM model with RBF kernel does not seem to learn decision boundaries, that are capable of distinguishing between the features correctly. It is even worse for the linear SVM."}, {"title": "9.6. Standard Deviation and Mean Accuracy over repeated runs", "content": "The results of the reliability test are displayed in Figure 6.\nAutoML-DC achieves the highest mean accuracy with a very small standard deviation of less than 0.3%. Through the incorporation of robust model architectures such as Random Forests with varying regularization strengths, AutoML-DC captures the diverse patterns inherent in sensor drift data. This prevents overfitting and boosts overall model reliability, as demonstrated by consistently high accuracy and low standard deviation across multiple runs. Other top-performing models include Logistic Regression, GRU (Gated Recurrent Unit), CNN (Convolutional Neural Network), and XGBoost, each showing high accuracy but with slightly higher standard deviations than AutoML-DC. In contrast, Adaboost and ARIMA have the lowest mean accuracy values, along with significant variation, which indicates lower and less stable performance. Models such as Gradient Boost, Drift-Ensemble, and Decision Tree fall in the middle range of accuracy, with moderate variation in performance."}, {"title": "9.7. Results Online Learning Test", "content": "The following Figure 7 illustrates model accuracy progression through the incremental batch learning strategy, emphasizing each model's capacity to seamlessly integrate new data batches over time:\nThe line chart illustrates the performance of different models during the Batch Online Learning Test across varying numbers of batches. The y-axis represents accuracy, while the x-axis represents the batch number. Each line corresponds to a specific model, with the legend on the right identifying the models by color."}, {"title": "9.8. AutoML results on the anomaly compensation task", "content": "The performance metrics of our proposed AutoML-Drift Compensation (AutoML-DC) model for the proposed drift compensation setting in terms of accuracy, precision, recall, and F1-score are referred to in Table 1. Each model contributes a certain weight to the learned ensemble. We use meta-learning techniques, automated feature preprocessing techniques, and early-stopping and automated ensemble-learning methods. To see the impact of the techniques, we conduct the ablation study in the following subsection.\nThe simultaneous usage of all AutoML techniques in the AutoML-CD model delivers a 76% score, which is a performance improvement of 16% compared to the other benchmarking models.\nThe AutoML-DC model for the drift compensation setting consists of eight models composed through automated ensemble learning. These eight"}, {"title": "", "content": "models comprise five variations of Random Forest models, constituting 8"}]}