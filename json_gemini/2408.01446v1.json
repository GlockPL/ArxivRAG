{"title": "Estimating Environmental Cost Throughout Model's Adaptive Life Cycle", "authors": ["Vishwesh Sangarya", "Richard Bradford", "Jung-Eun Kim"], "abstract": "With the rapid increase in the research, development, and application of neural networks in the current era, there is a proportional increase in the energy needed to train and use models. Crucially, this is accompanied by the increase in carbon emissions into the environment. A sustainable and socially beneficial approach to reducing the carbon footprint and rising energy demands associated with the modern age of AI/deep learning is the adaptive and continuous reuse of models with regard to changes in the environment of model deployment or variations/changes in the input data. In this paper, we propose PreIndex, a predictive index to estimate the environmental and compute resources associated with model retraining to distributional shifts in data. PreIndex can be used to estimate environmental costs such as carbon emissions and energy usage when retraining from current data distribution to new data distribution. It also correlates with and can be used to estimate other resource indicators associated with deep learning, such as epochs, gradient norm, and magnitude of model parameter change. PreIndex requires only one forward pass of the data, following which it provides a single concise value to estimate resources associated with retraining to the new distribution shifted data. We show that PreIndex can be reliably used across various datasets, model architectures, different types, and intensities of distribution shifts. Thus, PreIndex enables users to make informed decisions for retraining to different distribution shifts and determine the most cost-effective and sustainable option, allowing for the reuse of a model with a much smaller footprint in the environment.", "sections": [{"title": "Introduction", "content": "Considering the entire development life-cycle of a neural network model, the impact of the training procedure on the environment is substantial, especially with respect to carbon emissions and energy consumption. It would be preferable for a model to be used frequently for a long time \"as is\". However, this is not always feasible. Models must sometimes adapt to a new distribution, environment, or situation - for example, some ground truths might be changed, some data samples might become stale, or some new data samples might need to come into play. A sustainable solution to such situations, ultimately with regard to energy, carbon emissions, and resource consumption, is reusing an existing model to adapt to such changes. That is, models can be retrained and adapted to new distributions with minimal retraining instead of training from scratch. Retraining can achieve satisfactory accuracy on the new distribution while exhibiting lower computation costs, thus reducing the carbon footprint and energy consumption during the model's development and deployment. The primary objective of this paper is the introduction of a novel metric designed to predict and estimate the environmental resource costs associated with reusing a model for distributional shifts. We provide empirical evidence to show that model retraining significantly lowers compute costs compared to training a new model from scratch.\nAs deep learning models become more prevalent in everyday applications, the associated compute demand increases significantly, leading to substantial electricity consumption for model training and inference. This trend has significant social implications, primarily involving the increased release of carbon compounds into the atmosphere. Various works have highlighted the importance of considering sustainable and socially conscious practices in AI research and application.  detail the growing carbon footprint of recent deep learning models for vision and language tasks. Recent research works have shifted towards a sustainability-focused approach to model development by being sustainability-oriented instead of performance-oriented. These research works call attention to the ongoing need for deep learning progress to balance energy demands and carbon emissions with societal concerns. Moreover, there is a requirement for reducing carbon emissions, which in turn contributes to lower climate change, thus protecting areas and populations at risk from the impacts of climate change and scarcity of energy.\nHence, we propose a predictive index (PreIndex) to estimate the environmental cost of retraining a model to new changes in the data. PreIndex can be used to estimate the resources that would be expended if a model is retrained to a new distribution. PreIndex quantifies the change and collapse of the class decision boundaries due to the shift in distribution, and also quantifies the shift in the representation as a result of the changing distribution. PreIndex requires only a single forward pass of the model, following which it provides a single concise quantitative estimate to compare and predict a model's retraining cost. A lower value of PreIndex indicates that fewer resources would be expended when retrained, and vice versa.\nWe conduct experiments to validate that PreIndex is an effective estimator of environmental costs such as carbon emissions and energy usage, as well as several other retraining indicators such as epochs, gradient norm, and change in parameter magnitudes. Through extensive experiments over convolutional architectures and also Vision Transformers (ViT), we show that PreIndex is model agnostic and can be used with different architectures without requiring any modifications to the model structure. By leveraging PreIndex, deep learning practitioners and organizations can make informed decisions on deploying models that meet sustainability and resource usage goals."}, {"title": "Related work", "content": "Distribution shifts can occur due to several factors and can be of different types and intensities as seen in . Augmentation techniques have shown to provide robustness to certain types of distribution shifts, but are computationally heavy and require training a model from scratch. These methods produce robust models for certain distribution shifts, but have marginal improvements on other distribution shifts. Several studies have shown that there is a non-uniform improvement in robustness to the different distribution shifts; in some cases, improvement on one type of noise or corruption results in decreased performance on other distributional shifts. Methods using test time adaptation exhibit only minimal improvements in model robustness, rely on batch data, and fail to provide substantial benefits in scenarios with elevated noise levels. If the test time information is insufficient for adapting the model's prediction, these methods fail to provide accurate and confident outputs during inference.\noriginally coined the concept of Green AI and Red AI, emphasizing how the substantial growth in computational complexity and resource usage of models led to only marginal enhancements in accuracy. They highlight the need for sustainable practices to go hand in hand with performance improvements when developing models. conducted a systematic survey of recent works in sustainable deep learning and showed that energy consumption and carbon footprint are the two most predominant measures to quantify sustainability. Related works tackle the issue of energy consumption of neural networks. demonstrate the significant environmental impact of modern deep learning methods due to the carbon footprint associated with training vision and language models. shows that training ViTs (transformer-based architectures) emits a considerably greater amount of carbon compared to convolutional networks. Similarly, evaluates the high energy consumption of transformer-based models, thereby leading to higher carbon emissions. draw attention to the lack of carbon emission reporting in deep learning research. They provide frameworks for carbon emission measurement and documentation with an emphasis on quantifying the sustainability aspects of training models. provide tools and frameworks to estimate carbon emissions based on energy usage while training models and emissions from energy generation. explore the impact of individual noise types on model adaptation by using original-noise image pairs.\n show how gradients are an important tool in measuring the difficulty of samples and identifying samples that belong to new distributions. They show how the gradients are steeper and have larger values for difficult data and for out-of-distribution data. Studies such as  use the change in layer representation to study pathology data and focus their work to individual layers of a model to show it correlates to accuracy loss on domain shifts.\nVarious research studies demonstrate that commonly used distance measures are not sufficient to be an effective distance metric. study the drawbacks of prevalent divergence metrics for specific use cases. introduced the Adjusted Rand Index for comparing clustering labels, and illustrate the use of Adjusted Rand Index to evaluate supervised classification and feature selection. compares the performance benefits of retraining the entire pre-trained model versus retraining only the feature extractor for classification tasks."}, {"title": "PreIndex", "content": "In this section, we provide a detailed overview regarding PreIndex, which consists of three components \u2013 inverse adjusted rand index, averaged sample representation distance, and noise variance scaling. We introduce each component individually and provide the final formulation of PreIndex at the end of the section.\nAdjusted Rand Index for distribution shift We examine the collapse of decision boundaries between classes' data in the representation space as a result of noise. We quantify this change and shift in the decision boundaries by perform-\ning clustering on the data representation of the distribution-shifted data. The shift and collapse of the decision bound-aries is quantified by obtaining representation data of the entire distributional shift data, followed by clustering on the representation data to generate cluster labels. The cluster labels and the true labels are evaluated to quantify the change in the decision space. Adjusted Rand Index is useful to assess a clustering algorithm. Adjusted Rand Index (ari) is defined as,\n$ari=\\frac{{\\sum\\limits_{i,j} \\binom{n_{i,j}}{2} - \\frac{1}{\\binom{n_s}{2}} [(\\sum_i \\binom{t_i}{2})(\\sum_j \\binom{r_j}{2})]} {(1/2)[\\sum_i \\binom{t_i}{2} + \\sum_j \\binom{r_j}{2}]} - \\frac{1}{\\binom{n_s}{2}} [(\\sum_i \\binom{t_i}{2})(\\sum_j \\binom{r_j}{2})]}$,\nwhere t represents the total count of true labels for each label in the contingency table of true labels vs. representation labels via clustering. r represents the summed values of representation cluster labels in the contingency table. A contingency table in this scenario is a matrix that summarizes the number of samples belonging to the same cluster or having the same label in both clustering scenarios. Here, by 'both clustering scenarios,' we refer to the representation-based clustering labels and the true labels. $n_c$ is the number of cluster labels, which is equal to the number of class labels. $n_{i,j}$ represents the value in each entry of the contingency table, which is common to both cluster labels for a given label i and j. $n_s$ is the total number of samples.\nari takes the value 0 for purely random clustering, and 1 for identical clustering. For our estimator, it is required to have a low value for decision boundaries which are well separated and high value for boundaries which overlap and result in incorrect representation cluster labels. Hence, for our estimator, PreIndex, we take the complement of ari and define it as\n$inv_ari=\\frac{{\\frac{1}{2} [\\sum_i \\binom{t_i}{2} + \\sum_j \\binom{r_j}{2}]} -{\\sum\\limits_{i,j} \\binom{n_{i,j}}{2}} }{(1/2) [\\sum_i \\binom{t_i}{2} + \\sum_j \\binom{r_j}{2}] - [\\sum_i \\binom{t_i}{2}\\sum_j \\binom{r_j}{2})/\\binom{n_s}{2}]}$,\nThe data representation is obtained from the final convolution layer for a convolutional network' case while from the final dense layer in the last transformer encoder block for a vision transformer's case. To obtain the representation labels by clustering, we use KMeans with 3 different centroid initialization techniques as follows:\n1. Using the original data to obtain centroids as detailed in Algorithm 1,\n2. Initializing by Kmeans++ , and\n3. Initializing by random cluster assignment, and selecting the cluster with least entropy among 20 random initialization seeds.\nThe above three initialization schemes result in similar clustering labels. We use Algorithm 1 due to its computational efficiency as it does not requiring random re-initialization or iterative assignment of centroids, unlike methods such as repeated random cluster initialization and KMeans++. Algorithm 1 has quadratic runtime with respect to dataset size and number of class labels. However, it is computed only once to initialize the cluster centroids. This is an efficient approach compared to KMeans++, which has been shown to have a super-polynomial run-time starting from initialization to converge in the worst case. In Algorithm 1, we begin by creating an empty vector that has a size equal to the number of class labels, as depicted in line 1. CentM is a vector of size c when initialized, but as the classes' centroids are obtained, each entry in CentM is a vector itself. In the end, CentM is a matrix of size c x Size of flattened representation.\nAverage sample representation distance In this subsection, we introduce the average sample distance between representations obtained from the original and distribution-shifted sample. The average sample distance is calculated per layer of the model for each data point and then aggregated to provide a single concise scalar value. Wasserstein distance is used to find the distance between probability distributions obtained from the representation of the original sample and the distribution-shifted sample. The two data distributions are used to perform a forward pass and obtain the probability distribution from the activations of each layer.\nAlgorithm 2 provides the detailed procedure to obtain the layer distance per sample for a given layer l of a model. In Algorithm 2, functions P and WD represent the functions to compute probability density and the Wasserstein distance function, respectively. $l_{clean}$ and $l_{noisy}$ are the activation output of all filters in layer l for clean and noisy images, respectively. $I_{clean}$ and $I_{noisy}$ are vectors of size f \u2013 number of filters in the layer l. The activation output of each filter is averaged as depicted in lines 5\u20137 in the algorithm, using $h_{rep}$ and $W_{rep}$, which are the height and width of each filter representation output, respectively. $P_{clean}$ and $P_{noisy}$ are the probability distributions for the clean and noisy samples, respectively.\nAs a reference, Wasserstein distance is preferred over KL-Divergence, Bhattacharya distance, Jensen-Shannon divergence, and Hellinger distance. Wassertein distance, unlike KL-divergence, is a true distance metric that exhibits symmetry , and in contrast to Bhattacharya distance, Wasserstein distance satisfies the triangle inequality . Studies such as  highlight why Wasserstein distance is preferred over KL-divergence and its variants, Jensen-Shannon distance, for scenarios where quantifying the exact difference between the distributions has greater importance than measuring the likelihood between distributions. Additionally, demonstrates that Wasserstein distance is effective in capturing the horizontal distances between distributions within the metric space, unlike Hellinger distance.\nThe process of obtaining the representation distance per sample and per layer is repeated for all samples, and for all layers of the model. The distances for all samples and across all layers are then averaged to obtain the final average sample distance p as follows:\n$p=\\frac{1}{n_s n_l}\\sum_{i=1}^{n_s}\\sum_{k=1}^{n_l}(d_k)_i$,\nwhere $(d_k)_i$ is the distance between distributions at a given layer k for the ith sample, $n_s$ is the total number of samples used, and $n_l$ is the number of layers in the given model.\nNoise variance scaling show that neural networks make incorrect predictions even with small levels of noise in an input image. In particular, illustrates the cascading impact of a single pixel change with large magnitude and its effect on neighboring values of the image representation in the deeper layers of a model.\nDifferent noise types have different traits. In salt-pepper and impulse noises, certain individual pixels (either few or many) are associated with the noise. Hence, the noises affect a specific subset of pixels in an image with a larger magnitude of change per pixel value (that is noised). We refer to this type of noise as pixel-specific noise. Conversely, Gaussian, Blur, Frost, and Poisson noises affect (almost) all pixels in an image with a smaller change per pixel value. We refer to this as global image noise.\nPixel-specific noises, are easier to adapt to since they only affect a subset of pixels as compared to the global image noises. However, the impact of a large magnitude change of a subset of pixels can propagate to the surrounding values in the deeper layer representations. As a result the model may overestimate the raw perturbations caused by pixel-specific noises. To mitigate the overestimation of pixel-specific noises, we introduce an inverse scaling factor. The scaling factor helps reduce the value of PreIndex by utilizing the standard deviation of raw pixel intensities between a clean and a noisy image. We obtain the standard deviation for a specific noise type and intensity as follows:\n$s = \\sqrt{Var ([X_{clean}(i,j) - X_{noisy}(i,j)]_{(i,j)\u2208(h_{img},W_{img})})/\\lambda}$,\nHere, clean image and noisy image are denoted as $X_{clean}$ and $X_{noisy}$, respectively. $h_{img}$ and $W_{img}$ are the height and width of the image, respectively. The resultant standard deviation is then scaled down by a fixed constant factor \u03bb. Var represents the variance of a given vector.\nFinally, PreIndex for quantifying distribution shifts is formulated as,\n$PreIndex = (p + inv\\_ari) - \\frac{s}{(1 + (p + (1 \u2212 ari)) \u2217 3)) }$,\nFor pixel-specific noises, PreIndex is scaled down using the scaling factor and average deviation, s. Average deviation 3 is the average of standard deviations across all intensities for the specific noise type. It is used as an offset when scaling down PreIndex for pixel-specific noise. For global image noises, PreIndex is utilized without the scaling factor or average deviation. In PreIndex, p, ari, and s are obtained for each noise type with a specific intensity. Hence, the noise intensity index is omitted for the sake of simplicity. The values for average sample distance p and ari for each noise type and intensity in Eq. are from Eq. and Eq., respectively."}, {"title": "Resource Indicators", "content": "Resource indicators represent the resources/cost that would have been required if a model were trained or retrained to a new target task or to a new distribution. We show that PreIndex has a strong correlation with, and is an effective estimator of, the various indicators listed in this section. Using PreIndex and based on an indicator of interest, a user can gain knowledge regarding the resource expenditure they are likely to expend if they retrain the model to a new task or distribution. We evaluate several indicators epochs, gradient norm, change in parameter magnitude, energy, and carbon emissions. In particular, energy and carbon emissions represent immediate sustainability costs that are likely to embody an ultimate goal to potential users.\nWhen a model is retrained and adapted to a new target task or distribution, one might count the training cost/effort by looking at how many epochs are expended. For empirical evidence, we show how consistently PreIndex aligns with the number of epochs, which validates that PreIndex is an effective retraining predictive quantifier. The epochs that are reported in this paper are obtained when a model reaches a certain cutoff test accuracy for each dataset. Utilizing additional cutoff conditions, training is terminated after either 25 or 50 epochs if the accuracy gap from the designated cutoff accuracy is within 0.5% or 1%, respectively.\nGradient norm represents the difficulty of learning a new distribution and provides information regarding the likely steepness to reach convergence. For instance, several studies  use gradient norm as a proxy for sample difficulty. They compute gradients using a uniform distribution and do not make use of ground truth label information. For our objective, we report the gradient norm by utilizing the ground truth label. During retraining, we obtain the overall gradient norm for each instance by aggregating the gradient norm at each time step. The final gradient norm value represents the total magnitude of gradients the model encountered throughout the retraining process.\nChange in parameter value for the entire retraining process represents the magnitude of updates a parameter undergoes. That is, during the retraining process, if the model goes through consistently high parameter changes, it indicates that the model requires further updates and to learn the new distribution.\nHence, it is useful to use PreIndex to estimate a model's parameter change when a model is reused for a new distribution.\nWe obtain the change in parameter magnitudes similar to what was done in . However, unlike that calculate changes between parameters' current and initial values (before model updates), we aggregate the change in parameter values between two consecutive time steps. For layer l's parameters, at time step t, Normalized Euclidean distance $E_{l,t}$ between present parameter values and parameter values in the previous time step is represented as\n$E_{l,t} = \\frac{||W_{i,t} - W_{i,t-1}||_2}{\\sqrt{||W_{i,t}||}}$,\nwhere t (\u2265 1) is the current retraining time step and t - 1 is the previous retraining time step. Distance between current parameter values $W_{i,t}$ and previous parameter values $W_{i,t-1}$ is calculated for each layer l, which are then summed and averaged by the number of layers. The normalized Euclidean distance of parameter changes is aggregated throughout the entire retraining process to obtain the final cumulative parameter changes the model undergoes.\nEnergy and carbon emissions provide direct real-world sustainability costs associated with training and/or retraining a model. In accordance with , reporting carbon emissions is an important sustainability factor when developing models. We use CodeCarbon , a Python package, to track the energy consumption and estimate the carbon emissions of a model during retraining. The library uses geographic location information of the energy generated to calculate the estimated weight of carbon emissions. The package not only tracks energy consumption from the GPU while training models, but also tracks the energy consumption of the CPU and RAM that is expended by neural network training. The carbon emissions are calculated based on the energy generation technique of the region, such as coal, petroleum, solar, wind etc."}, {"title": "Experiments", "content": "In this section, we evaluate PreIndex on three datasets CIFAR10 , CIFAR100 , and TinyImageNet . We employ 6 noise types - Gaussian, Poisson/Shot, Blur, Frost, Salt-Pepper, and Impulse. Gaussian and Poisson/Shot are statistical noises that may arise due to errors during data capture. Blur and Frost are real-world noises due to environmental factors. Salt-Pepper and Impulse noise might occur due to artifacts or hardware issues while capturing an image. For each noise type, 9 noise intensities are generated, where the lowest level 1 is comparable to the least amount of noise and the highest level 9 is comparable to severity 4 in .\nTo reuse a pre-existing model, we train a randomly initialized model on the original data distribution until it reaches the minimum required accuracy for each dataset. All experiment results are an average of three runs. When training (or retraining) to higher noise levels, specific hyper-parameter tuning for each individual experiment may result in relatively fewer epochs to converge. However, this approach can impede comparison with other noise types and noise levels. For uniformity and fair comparison among all noise types and intensities, identical hyper-parameters are used.\n displays the various resource indicators for ResNet18 trained from scratch and retrained on CIFAR10 with different intensities of Poisson noise. It is evident that retraining a model requires considerably fewer resources compared to training a new model from scratch. All the retraining indicator values for retraining are significantly lower than training from scratch.\nTo evaluate PreIndex for distribution shifts, we use Convolutional neural networks and Vision Transformers. For CNNs, we explore different model architectures ResNets, VGG, GoogLeNet, and MobileNetv2. For Vision Transformer, we utilize a ViT model with a patch size of 4, 8 transformer blocks, a latent vector size of 512, 8 attention heads, and MLP with a hidden layer size of 1024.\n illustrates the correlation between PreIndex and all the resource indicators. In the figure, ViT and ResNet34 are retrained with distribution shifts to CIFAR10 and TinyImageNet, respectively. It is evident that across the heterogeneous architectures, on various datasets, PreIndex has a strong correlation and aligns with all resource indicators for various types of distribution shifts.\n displays the correlation between PreIndex and all resource indicators when retraining convolutional networks to various distribution shifts on CIFAR10 dataset. provides the Pearson correlation coefficients and Spearman correlation coefficients, with the associated p-values, between PreIndex and the resource indicators when retraining to CIFAR10 datasets with distribution shift. The figures and the correlation table validate that PreIndex has a strong correlation with the resource indicators, and that it is an effective estimator of retraining resources across various model architectures and types of distribution shifts with multiple intensities.\n and provides the trend and correlation metrics between PreIndex and the resource indicators, respectively. With regard to all resource indicators, PreIndex has an increasing monotonic relation noticeable from the graphs and displays a strong positive correlation evident from the correlation coefficients. Additionally, with ResNet18, GoogleNet is evaluated on the TinyImageNet.  and illustrate the relation between PreIndex and the resource indicators for GoogleNet retrained on distribution shifted TinyImageNet."}, {"title": "Conclusion", "content": "We introduced a novel metric to estimate the various resources that would be expended when reusing a model by adapting to distributional shifts. We validate the effectiveness of PreIndex on Convolutional and Transformer based networks. We show that reusing a model by retraining requires significantly fewer resources than training a new model. The effectiveness of PreIndex for estimating environmental costs such as energy consumption and carbon emissions, as well as other resource indicators such as epochs, gradient norm, and model parameter change is empirically validated. All the results consistently verify that PreIndex is an effective estimator and has strong correlation metrics with all resource indicators. PreIndex is shown to be model agnostic, applicable to various datasets and effective for various types and levels of distribution shift, thus enabling sustainable decision making with regard to model reusability."}]}