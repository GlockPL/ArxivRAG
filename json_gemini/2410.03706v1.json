{"title": "Topological Foundations of Reinforcement Learning", "authors": ["Krame Kadurha David"], "abstract": "The goal of this work is to serve as a foundation for deep studies of the topology of state, action, and\npolicy spaces in reinforcement learning. By studying these spaces from a mathematical perspective, we\nexpect to gain more insight into how to build better algorithms to solve decision problems. Therefore,\nwe focus on presenting the connection between the Banach fixed point theorem and the convergence of\nreinforcement learning algorithms, and we illustrate how the insights gained from this can practically help\nin designing more efficient algorithms. Before doing so, however, we first introduce relevant concepts\nsuch as metric spaces, normed spaces and Banach spaces for better understanding, before expressing\nthe entire reinforcement learning problem in terms of Markov decision processes. This allows us to\nproperly introduce the Banach contraction principle in a language suitable for reinforcement learning,\nand to write the Bellman equations in terms of operators on Banach spaces to show why reinforcement\nlearning algorithms converge. Finally, we show how the insights gained from the mathematical study\nof convergence are helpful in reasoning about the best ways to make reinforcement learning algorithms\nmore efficient.", "sections": [{"title": "1. Introduction", "content": "There is not much work on the foundations of Reinforcement Learning (RL). Especially from a topological\npoint of view. This work is, to the best of our knowledge, the first attempt to unify the basic concepts of\nReinforcement Learning in a coherent and well-ordered way, specifying all the underlying mathematical\nconcepts.\nSome researchers have instead been interested in related questions, trying to explore RL concepts from a\nmathematical point of view, with the aim of improving the effectiveness of RL algorithms. For example:\nIn the paper [12], the authors studied the geometric and topological properties of the value functions in\nMarkov decision processes with finite number of states and actions. Their characterization of the value\nfunction space as a general polytope provides an understanding of the relationships between policies and\nvalue functions. This perspective enhances the theoretical understanding of RL dynamics. The authors\nof [5] also explored the concept of Lipschitz continuity in model-based RL, emphasizing the importance\nof learning Lipschitz continuous models for efficient value function estimation. This establishes some\nerror bounds and demonstrates the benefits of controlling the Lipschitz constant in RL setting. The work\ndone in [34] extends model-free RL algorithms to continuous state-action spaces using a Q-learning-\nbased approach, and that advancement opens avenues for applying RL techniques to a broader range of\nreal-world applications with continuous state spaces. A very deep study is then done in [21], introducing\na unified formalism for defining state similarity metrics in RL. The authors claim to address the challenge\nof generalization in continuous-state systems by establishing hierarchies among metrics and examining\ntheir implications on RL algorithms.\nThe aforementioned works can be difficult to understand or even less precise if the foundations are not\nwell clarified. Therefore, the main goal of our work is to serve as a first stone in studying and organising\nthe basic concepts, while presenting Reinforcement Learning in a simple and concise way, to help future\nresearchers to quickly dive into the foundations of RL and to study more deeply, in particular the\ntopology of state, action, and policy spaces. By studying these spaces from a mathematical perspective,\nwe expect to gain more insight into how to build better algorithms to solve decision problems.\nAt the end of this work, we even illustrate the latter assumption by showing that, with the mathematical\ninvestigation we have done, we are able to make very strong and general conjectures which merit to be\ntaken seriously into account. This work is organized then as follows :\nAfter this introduction, in chapter 2, we discuss metric spaces and their completeness, as well as the\nBanach Fixed Point Theorem. We end the chapter giving an application of the Banach Fixed Point\nTheorem to a concrete example.\nIn chapter 3, we formally present the Markov Decision Process framework and directly after that, we\npresent the concept of optimality in Reinforcement Learning. At the end, we then discuss some methods\nwhich are at the core of how optimality is attained in Reinforcement Learning.\nIn chapter 4, we express reinforcement in term of Operators to have a simple way of proving why\nReinforcement Learning Algorithms work, using the Banach Contraction Principle. In fact, this chapter\ndiscusses about Bellman Operators and shows how the optimality can be reached using operators'\nlanguage.\nFinally, before the final conclusion, in chapter 5 we present some limitations of the classical Bellman\noperator and, using some insights gained from the mathematical investigation done before, we propose\nan alternative to the classical Bellman operator which shows good behaviour in terms of optimality and\nefficiency."}, {"title": "2. Metric spaces and the Banach fixed point", "content": "In this chapter, we present the fundamental concepts of metric spaces and explore their completeness,\na crucial property in understanding the behavior of sequences within these spaces. We also study the\nBanach fixed point theorem, a result which establishes the existence and uniqueness of fixed points\nfor mappings in complete metric spaces. We elucidate the significance of this theorem in providing\na theoretical foundation for iterative algorithms and solution techniques in various mathematical and\ncomputational contexts. Furthermore, we culminate our discussion by illustrating the practical relevance\nof the Banach Fixed Point Theorem through a concrete example, demonstrating its applicability in solving\nreal-world problems and providing insight into its computational implications."}, {"title": "2.1 Complete metric spaces", "content": "Metrics and metric spaces provide a structured framework for precisely measuring the relationship be-\ntween elements within a set. This facilitates deeper insights into their interconnections and dependencies,\nenabling pattern recognition, association identification, and informed decision-making across diverse do-\nmains. In this section, we delve into complete metric spaces, which offer a comprehensive framework\nfor understanding the entirety of a set's elements and their interrelations."}, {"title": "2.1.1 Definition (Metric and metric space).", "content": "A metric on a set M is a function $d : M \\times M \\rightarrow \\mathbb{R}$, such\nthat for $x, y, z \\in M$:\n(i) [Non-negativity] $d(x, y) > 0$ and $d(x, x) = 0$\n(ii) [Identity of indiscernibles] $d(x, y) = 0 \\iff x = y$\n(iii) [Symmetry] $d(x,y) = d(y, x)$\n(iv) [Triangle Inequality] $d(x, y) \\leq d(x, z) + d(z, y)$\nThe pair $(M, d)$ is called a metric space.\nLet's now give some interesting examples of metric spaces."}, {"title": "2.1.2 Example.", "content": "1) Let $M = \\mathbb{R}^n$ be the set of real n-uplets. For $x = (x_1,x_2,\\ldots,x_n)$, $y = (y_1, y_2,\\ldots, y_n)$ and\n$z = (z_1, z_2, ..., z_n)$ in $\\mathbb{R}^n$ let's define :\n$d_p(x, y) = (\\sum_{i=1}^{n} |x_i - y_i|^p)^{1/p}$ with $p\\geq 1$\nThe conditions (i), (ii) and (iii) hold due to the properties of the absolute value and the triangle\ninequality also holds because it is the result of the Minkowsky's inequality [19, 20]. Indeed\nassuming that $a_j = x_i - z_i$ and $b_i = z_i - y_i$. We can write the triangle inequality as follows :\n$(\\sum_{i=1}^{n} |a_i + b_i|^p)^{1/p} \\leq (\\sum_{i=1}^{n} |a_i|^p)^{1/p} + (\\sum_{i=1}^{n} |b_i|^p)^{1/p}$"}, {"title": "2.1.3 Definition (Sequences).", "content": "A sequence in a metric space $(X, d)$ is a function $u : \\mathbb{N} \\rightarrow X$. It can be\nwritten $\\{u_n\\}_{n\\in\\mathbb{N}}$ or just $\\{u_n\\}$."}, {"title": "2.1.4 Definition (Convergence).", "content": "A sequence $\\{x_n\\}$ of points in $(X, d)$ is said to be convergent if there\nis a point $x^* \\in X$ such that, for any $\\varepsilon > 0$, there exists a positive integer $N_0$ such that $d(x_n, x^*) < \\varepsilon$\nwhenever $n > N_0$. The point $x^*$ is termed the limit of the sequence and we write $x_n \\rightarrow x^*$."}, {"title": "2.1.5 Proposition.", "content": "The limit of a sequence in a metric space is unique.\nProof. The proof of that can be seen in [31]. It leverages the property that metric spaces belong to the\nfamily of $T_2$ (or Hausdorff) topological spaces"}, {"title": "2.1.6 Definition (Cauchy sequences).", "content": "A sequence $\\{x_n\\}$ in a metric space $(X, d)$ is called a Cauchy\nsequence if for any given $\\varepsilon > 0$, we can find $N_0 \\in \\mathbb{N}$ such that whenever $\\min\\{m, n\\} > N_0$ we have\n$d(x_m, x_n) < \\varepsilon$.\nWhile every convergent sequence is a Cauchy sequence, the reverse of this is only true in 'complete\nmetric spaces'."}, {"title": "2.1.7 Definition (Completeness).", "content": "The metric space $(X, d)$ is said complete if every Cauchy sequence\nconverges in $X$."}, {"title": "2.1.8 Example.", "content": "Using the standard metric (absolute value), $\\mathbb{R}$ is complete. Using also the associated\nstandard metric, $\\mathbb{R}^n$ is complete [20]."}, {"title": "2.1.9 Definition (Uniformly Cauchy sequence of functions).", "content": "We say that a sequence $f_n : X \\rightarrow \\mathbb{R}$ is\nuniformly Cauchy if for a given $\\varepsilon > 0$, there exists $N \\in \\mathbb{N}$ with the following property:\n$|f_n(x) - f_m(x)|<\\varepsilon$ for all $x \\in X$ and for all $m, n \\geq N$.\nNormed spaces are a subset of metric spaces, where vectors have associated norms. They are useful\nbecause they provide a framework for measuring distances and magnitudes in vector spaces, aiding in\nthe analysis of mathematical structures."}, {"title": "2.1.10 Definition (Norms and normed spaces).", "content": "Let's $V$ be a linear space over a field $K$. A norm on\n$V$ is a map $|\\cdot | : V \\times V \\rightarrow \\mathbb{R}^+$ such that for any $x, y \\in V$ and $a \\in K$ :\n(i) [Positivity] $\\|x\\| > 0$ for every $x \\neq 0$\n(ii) [Homogeneity] $\\|\\alpha x\\| = |\\alpha|\\|x\\|$\n(iii) [Triangle inequality] $\\|x + y\\| < \\|x\\| + \\|y\\|$\nThe pair $(V, ||\\cdot||)$ is called a normed space."}, {"title": "2.1.11 Remark.", "content": "While normed spaces focus on vector spaces and their associated norms, metric spaces\nprovide a broader context for studying distances and relationships between points in arbitrary sets. If\n$\\| \\|$ is a norm, we can get a metric $d$ from it by doing $d(x, y) = \\|x - y\\|$. This is called an induced\nmetric."}, {"title": "2.1.12 Example.", "content": "Let X be any nonempty set. Let us consider the linear space $B(X)$ of all bounded\nreal valued functions on X under the sup norm $|\\cdot |_{\\infty}$. In $B(X)$, a sequence $\\{f_n\\}$ is Cauchy if and only\nif it is uniformly Cauchy.\nProof. Detailed proof in [38]."}, {"title": "2.1.13 Definition.", "content": "A Banach space is a complete normed space."}, {"title": "2.1.14 Example.", "content": "The normed space $(B(X), |\\cdot |_{\\infty})$ as defined in the Example 2.1.12 is a Banach\nspace.\nProof. The proof can be found in [20]. We here just sketch it.\nLet $\\{f_n\\} \\in B(X)$ be a Cauchy sequence. By Example 2.1.12, the sequence $\\{f_n\\}$ is uniformly Cauchy.\nLet's fix $x \\in X$ and consider the sequence of scalars $\\{f_n(x)\\}$. Since $\\mathbb{R}$ is complete, the sequence\nconverges to a real number $f(x) \\in \\mathbb{R}$.\nFirst, we have to show that $f$ is bounded on $X$ and,\nSecondly we have to show that $\\{f_n\\}$ converges uniformly to $f$ on $X$. That will complete the proof."}, {"title": "2.1.15 Completion of Metric Spaces [20, 31].", "content": "Let $(X, d)$ be a non-complete metric space. It is\nalways possible to complete the space into a larger space in such a way that every Cauchy sequence in X\nhas a limit in the completion. To do this, we should add new points to $(X, d)$ and extend d to all these\nnew points so that each non-convergent Cauchy sequences in X find limits among these new points."}, {"title": "2.1.16 Definition (Completion).", "content": "Let $(X, d)$ be a metric space. A complete metric space $(X^*, d^*)$ is\nconsidered as a completion of the metric space $(X, d)$ if :\n(i) $X$ is a subspace of $X^*$\n(ii) Every point of $X^*$ is the limit of some sequence in $X$"}, {"title": "2.1.17 Theorem.", "content": "Let $(X, d)$ be a metric space. Then there exists a completion of $(X, d)$.\nProof. For the proof, see [20]."}, {"title": "2.2 Contraction mapping and fixed-point", "content": "Let us now present the contraction mapping and the Banach Contraction Principle. Those are the core\nconcepts that we will use throughout the work."}, {"title": "2.2.1 Definition.", "content": "Let $X$ be an nonempty set and $f : X \\rightarrow X$ be a mapping on that set :\nA point x is said to be a fixed point of f if $f(x) = x$.\nWe will write $Fix(f) = \\{x \\in X : f(x) = x\\}$ the set of fixed points of f on $X$."}, {"title": "2.2.2 Proposition.", "content": "Let $X$ be a nonempty set and $f : X \\rightarrow X$ a mapping defined on it. If $x \\in X$ is a\nunique fixed point of $f^n$ with $f^n = f \\circ f \\circ \\ldots \\circ f$ for any $n > 1$, then it is the unique fixed point of $f$\nand reversely :\n$Fix(f^n) = \\{x\\} \\iff Fix(f) = \\{x\\}$\nProof. Let $x$ be a fixed point for $f^n$ in $X$. Then we can write :\n$f(x) = f (f^n(x)) = f^{n+1}(x) = f^n (f(x)) \\Rightarrow$\n$\\Rightarrow f(x)$ is a fixed point of $f^n$\nSince $x$ is the only one fixed point for $f^n$, then $f(x) = x$, i.e. x is also a fixed point for $f$. Let's now\nshow that the aforementioned fixed point is unique also for $f$ :\nLet's take $y \\neq x$ another fixed point of $f$, and compute $y = f(y) = f^2(y) = \\ldots = f^n(y)$ or\n$y = f^n(y)$. Then, we've clearly seen that x is the unique fixed point for $f$."}, {"title": "2.2.3 Definition.", "content": "[$13, 14, 26, 29$] Let $(X, d)$ be a metric space and $f : X \\rightarrow X$ a mapping on $X$. f is\nsaid to be Lipschitz continuous if there exist $a > 0$ such that :\n$d (f(x), f(y)) \\leq a\\cdot d(x,y) \\quad \\forall x,y \\in X$"}, {"title": "2.2.4 Proposition.", "content": "Let $(X, d)$ be a metric space and $f : X \\rightarrow X$ a contraction mapping with $a \\in (0, 1)$.\nIf f has a fixed point, that point is unique.\nProof. Suppose we have two fixed points $x$ and $y$ for $f$ with always $x \\neq y$. Because f is a contraction,\nwith $a \\in (0,1)$ we can write :\n$0 \\neq d(x, y) = d(f(x), f(y)) \\leq a\\cdot d(x,y)$,\nwhich is impossible (contradictory). So, the fixed point is unique."}, {"title": "2.2.5 Theorem (Banach Contraction Principle: BCP [37]).", "content": "Let $(X, d)$ be a complete metric space,\n$f : X \\rightarrow X$ a contraction. Then f has a unique fixed point $x^*$ and for each $x \\in X, \\lim_{n\\rightarrow\\infty} f^n(x) = x^*$.\nMoreover,\n$d(f^n(x),x^*) \\leq \\frac{a^n}{1-a} \\cdot d (x, f(x))$.\nProof. Let us construct a sequence $\\{x_n\\}$, starting on $x_0$ and using the following recurrence :\n$x_n = f(x_{n-1}) \\forall n \\in \\mathbb{N} \\quad i.e. \\quad x_n = f^n(x_0)$\nWe show that $\\{x_n\\}$ is a Cauchy-Sequence. In fact, since f is a contraction, we should have :\n$d(x_{m+1},x_m) = d(f(x_m), f(x_{m-1})) \\leq a\\cdot d(x_m, x_{m-1})$\n$=\n=\na\\cdot d (f(x_{m-1}), f(x_{m-2})) \\leq a^2 \\cdot d(x_{m-1},x_{m-2})$\n$\\vdots$\n$= a^{m-1}. d (f(x_1), f(x_0)) \\leq a^m \\cdot d(x_1,x_0)$\nNow, for any given m and n, positive and with $n < m$, the triangle inequality applied recursively gives :\n$d(x_m,x_n) \\leq d(x_m, x_{m-1})+d(x_{m-1}, x_{m-2}) + \\cdots + d(x_{n-1},x_n)$\n$< (a^{m-1} + a^{m-2} +\\ldots+a^n) \\cdot d(x_1,x_0) \\quad from \\quad 2.2.2$\n$\\leq a^n (a^{m-n-1} + a^{m-n-2} + \\cdots +1)d(x_1,x_0)$\n$<\\frac{a^n}{1-a} d(x_1,x_0)$\nAs we can now see from $\\lim_{n\\rightarrow\\infty} a^n = 0$ and $d(x_1,x_0)$ is fixed, we can say $d(x_m, x_n) \\rightarrow 0$ as $m, n \\rightarrow \\infty$.\nSo, $\\{x_n\\}$ is a Cauchy sequence and since $X$ is complete, there exits only one $x^* \\in X$ such that $x_n \\rightarrow x^*$.\nSo, by continuity of contractions, we can write :\n$x^* = \\lim_{n\\rightarrow\\infty} x_{n+1} = \\lim_{n\\rightarrow\\infty} f(x_n) = f (\\lim_{n\\rightarrow\\infty} x_n) = f (\\lim_{n\\rightarrow\\infty} f^n (x_0)) = f(x^*)$"}, {"title": "2.3 Application of the Banach Contraction Principle - An example", "content": "And the proposition above (Proposition 2.2.2), we have a way to find this unique fixed point indepen-\ndently on the starting point.\nAnd to show a good estimate of how we are approaching the limit we can rewrite the Expression 2.2.3\nlike this:\n$d (f^n(x), x^*) \\leq \\frac{a^n}{1- a} d (x, f(x)) = \\frac{a^n}{1- a}d(x_n, x^*) \\leq \\frac{a^n}{1- a} d (x_0,x_1)$\nThe beauty of the Banach Contraction Principle is that it only require completeness\nfor the metric space and contraction property on the mapping. Also, we can get closer and closer to\nthe fixed point, starting from any point $x = x_0 \\in X$ by just applying recursively the mapping on that\nspecific point."}, {"title": "2.3 Application of the Banach Contraction Principle - An example", "content": "The Banach Fixed Point principle or Banach Contraction Principle (BCP) is very important in many\nfields, in mathematics as well as in its applications [3, 24, 38, 43]. We here introduce a problem whose\nsolution is guaranteed by the Picard-Lindelof Theorem, the uniqueness of solutions of a first order\nOrdinary Differential Equation (ODE). We show that its solution can be obtained using the BCP.\nLet's say we have the following initial value problem (which is here an ODE with initial conditions) :\n$y' = F(x,y); \\quad y(x_0) = y_0 \\quad with \\quad y' = \\frac{dy}{dx}$\nThis problem is in fact equivalent to the following :\n$y(x) - y(x_0) = \\int_{x_0}^{x} F(t,y(t))dt \\quad as \\quad we \\quad have \\quad y(x_0) = y_0$\n$\\Rightarrow y(x) = y_0 + \\int_{x_0}^{x} F(t,y(t)) dt$\nSo, the two problems 2.3.1 and 2.3.2 are exactly the same. And from this last Expression 2.3.2 we can\ndefine a sequence given by :\n$y_{n+1}(x) = y_0 + \\int_{x_0}^{x} F(t, y_n(t)) dt \\quad with \\quad y_0 = y_n(x_0) \\quad \\forall n$\nThe problem can be seen as demonstrating the Picard-Lindelof Theorem which states the following :\nLet $D \\subset \\mathbb{R} \\times \\mathbb{R}^n$ be an open set, $F:D \\rightarrow \\mathbb{R}^n$ a\ncontinuous function and $(x_0, y_0) \\in D$. Then the initial value problem\n$\\frac{dy}{dx} = f(x,y), \\quad y(x_0) = y_0$\nhas a unique solution $y(x)$ on closed intervals $I = [x_0 - \\epsilon, x_0 + \\epsilon]$ with $\\epsilon > 0$.\nTo easily show the usefulness of the BCP for the problem 2.3.1, we can enunciate the Picard-Lindelof\nTheorem in especially the context of that problem as follows and then prove the existence and uniqueness\nof the solution :"}, {"title": "2.3.2 Proposition. [43] Assume that :", "content": "1. With S a rectangle domain defined as follows\n$S = \\{(x, w) \\in \\mathbb{R}^2 : |x - x_0| \\leq a \\quad and \\quad |w - y_0| \\leq b\\}$ with $a, b \\in \\mathbb{R}$ and $w = y(x)$\nThe function $F : S \\rightarrow \\mathbb{R}$, given in the ODE 2.3.1 above, is continuous, and there exists $c\\in\\mathbb{R}^+$\nsuch that $|F(x, y)| \\leq c$.\n2. F(x, y) satisfies the Lipschitz condition with respect to y on S, i.e. there exists $L \\geq 0$ such\nthat :\n$|F(x, y_1(x)) - F(x, y_2(x))| \\leq L\\cdot |y_1(x) - y_2(x)|, \\quad for \\quad all \\quad (x, y_1), (x, y_2) \\in S$\n3. The real number h satisfies : $0 < h < a, \\quad hc \\leq b, \\quad hL \\leq 1$\nThe following holds :\n(i) The sequence $\\{y_n\\}$ constructed in Relation 2.3.3 converges to a certain function $y^*$.\n(ii) The initial value problem stated in 2.3.1 and equivalently in its integrale form given by the Ex-\npression 2.3.2 has a unique solution which is exactly $y^*$.\n(iii) For $n \\in \\mathbb{N}$ and $k := hL$ we have the following estimates :\n* $\\|y_n - y^*\\|_{\\infty} \\leq \\frac{k^n}{1-k} \\cdot \\|y_1 - y_0\\|_{\\infty} \\quad see the last Expression 2.2.3.$\n* $\\|y_{n+1} - y^*\\|_{\\infty} \\leq \\frac{k}{1-k} \\cdot \\|y_{n+1} - y_n\\|_{\\infty}$\nWe will not prove this proposition explicitly. We will follow a process, inspired with the assumptions\nmade in the Proposition 2.3.2 and that will help us to demonstrate immediately (i) and (ii). The point\n(iii) about the estimates will follow immediately, due to the Expression 2.2.3.\nProof. Let R be the rectangular domain :\n$R = \\{(x, w) \\in \\mathbb{R}^2 : |x - x_0| \\leq h \\quad and \\quad |w - y_0| \\leq h.c\\}$ with $h, c\\in \\mathbb{R}$ and $w = y(x)$\nFollowing the assumptions made for this Proposition, we know that $0 <h<a, hc \\leq b, i.e. $R \\subset S$.\nLet X be the set of all real-valued continuous functions $y = y(x)$ on $[x_0 - h, x_0 + h]$. Then X is a\nclosed subset of the normed space $C ([x_0 - h, x_0 + h])$ with the sup norm $|\\cdot |_{\\infty}$.\nLet's now define an operator (a functional) like this (inspired by the second formulation of our problem,\ngiven in 2.3.2):\n$T:X\\rightarrow X$\n$g(x) \\mapsto h(x) = Tg = y_0 + \\int_{x_0}^{x} F (t, g(t)) dt$\nSince\n$\\|h(x), y_0\\| = sup |\\int_{x_0}^{x} F (t,g(t)) dt| = |\\int_{x_0}^{x} F (t,g(t)) dt| \\leq c (x-x_0) \\leq c.h\\leq b,$"}, {"title": "2.3.3 Example.", "content": "Consider the following first order initial value problem\n$x'(t) = \\frac{1}{2}x(t) - t, \\quad x(0) = 0$.\nFrom the Picard-Lindelof Theorem above, we are sure that we'll get a solution, and to converge to it, we\nstarted with a random function and used an iterative approach, as suggested by the Banach contraction\nprinciple that we used to prove the theorem (through the Proposition 2.3.2). We obtained the following\nresults:"}, {"title": "3. Overview on Reinforcement Learning", "content": "In this chapter, we will first formally present the Markov Decision Process framework and how it relates\nto Reinforcement Learning. Second, we will talk about optimality in Reinforcement Learning, and finally\nwe will discuss some methods that are at the core of how optimality is realised in Reinforcement Learning."}, {"title": "3.1 Markov Decision Processes in the Reinforcement Learning setting", "content": "We here present a formal definition of the Markov Decision Process. But before that, we discuss about\nMarkov Chain because it allows us to present the fact that, there are situations in which the previous\nobservation contains all the information about the past, in such a way that we don't need to look at\nthe whole history."}, {"title": "3.1.1 Definition (Markov chain [22]).", "content": "Let S (a subset of $\\mathbb{R}^n$ for example) represent the state space.\nThe discrete-time dynamic system $\\{S_t\\}_{t\\in\\mathbb{N}} \\in S$ is a Markov chain if :\n$P(S_{t+1} = s|S_t, S_{t-1},\\cdots, S_0) = P(S_{t+1} = s|S_t)$,\ni.e. everything we need to predict (in probability) the future is contained in the current state (this\nis what we call Markov property). Given an initial state $S_0 \\in S$, a Markov chain is defined by the\nfollowing transition probability :\n$p(s'|s) = Pr(S_{t+1} = s'|S_t = s)$.\nWe can now clearly define the Markov Decision Process and related concepts, important for Reinforce-\nment Learning."}, {"title": "3.1.2 Definition (Markov Decision Process [22, 32]).", "content": "Formally, an Markov Decision Process (MDP) is\na 5-uplet $M = \\langle S, A, p, r, \\gamma\\rangle$ where :\n* S represents the state space. It can be finite, countable infinite or continuous.\n* A represents the action space which could also be finite, countable infinite or continuous.\n* p(s, a, s') is the transition probability (called environment dynamics) defined by :\n$p(s, a, s') = p(s'|s,a) = Pr(S_{t+1} = s'|S_t = s, A_t = a)$,\nwith $s, s' \\in S$ and $a \\in A$. This represents the probability of observing a next state s' when the\naction a is taken in the state s.\n* r(s, a, s') is the reward function called also a reinforcement obtained when taking the action\na, in the state s and the next state observed is s'. So :\n$r:S\\times A\\times S \\rightarrow \\mathbb{R}$\n* The transition probability p and the reward function r defines the environment model."}, {"title": "3.1.3 Definition (Policy or decision rule).", "content": "Policy is a mapping of states to actions", "be": "n* Deterministic: in the same conditions", "Stochastic": "at each time", "setting": "n1. The agent-environment interface\nMarkov Decision Processes (MDPs) are indeed a simple way to frame the problem of learning\nfrom interaction to achieve a goal. We are here define some important terms in the field of\nReinforcement Learning :\n* The element that has to learn and make decisions is called agent.\n* Everything with which the agent interacts", "sequences": "n$S_0, A_0, R_1 \\quad,\\quad S_1, A_1, R_2 \\quad,\\quad S"}]}