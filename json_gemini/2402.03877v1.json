{"title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models", "authors": ["Spyridon Mouselinos", "Henryk Michalewski", "Mateusz Malinowski"], "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs' abilities in constructive geometric problem-solving \u2013 one of the most fundamental steps in the development of human mathematical reasoning. Our work reveals notable challenges that the state-of-the-art LLMs face in this domain despite many successes in similar areas. LLMs exhibit biases in target variable selection and struggle with 2D spatial relationships, often misrepresenting and hallucinating objects and their placements. To this end, we introduce a framework that formulates an LLMs-based multi-agents system that enhances their existing reasoning potential by conducting an internal dialogue. This work underscores LLMs' current limitations in geometric reasoning and improves geometric reasoning capabilities through self-correction, collaboration, and diverse role specializations.", "sections": [{"title": "1. Introduction", "content": "Recent advancements in Large Language Models (LLMs) are groundbreaking. Models' capacity to handle complex mathematical and algorithmic tasks, interpreting data from graphs and tables, shows an ever-increasing proficiency in various forms of reasoning. Despite this, constructive geometry is one domain where LLMs still face significant challenges. This area of study, fundamental to human mathematical reasoning, lies at the intersection of tool usage, planning, and spatial reasoning.\nOur investigation into LLMs' capabilities in this domain reveals several intriguing aspects. We find that in instruction following, LLMs often exhibit a bias towards the style of the examples rather than focusing on the reasoning and proper abstraction necessary for solving these geometrical problems. Furthermore, LLMs that are specialized in mathematical domains do not necessarily show proficiency in constructive geometry. This suggests that the skills required for numerical or algebraic reasoning do not directly translate to the spatial and tool-based problem-solving required in this domain. Another interesting observation is the impact of variable naming on problem-solving. Our findings show that the choice of names for variables in geometric constructions can significantly affect both the length and quality of the solutions, pointing to a potential bias in LLMs where variable names carry unintended semantic weight. Moreover, despite being provided with visual aids, multimodal LLMs such as GPT4-V demonstrate difficulties in interpreting 2D spatial relationships. They can identify objects in a scene but struggle to integrate them into a coherent plan involving tools or steps. There's also a tendency to 'hallucinate' objects or points, which complicates their spatial reasoning process.\nWe propose a framework that aims to overcome these challenges. Our solution includes renaming variables to more context-appropriate names, aiming to mitigate the influence of naming conventions on the LLMs' problem-solving process. We also introduce an adaptive selection mechanism on the prompt examples, focusing the LLM on relevant information and avoiding information overload. The model uses previous instances of geometric tasks as a basis for subsequent ones, allowing it to build on past experiences and enhance its adaptability and context awareness. A key factor in our approach is the use of simulacra-based conversational agents (Park et al., 2023). In this setup, agents take on specialized roles, some acting as reasoners while others acting as solvers or tool users. This cross-domain dialogue leverages the strengths of each agent type and fosters a more effective problem-solving approach than traditional role-playing methods. Here, we aim to bridge the gap in geometric reasoning for LLMs, enhancing their capabilities in this complex and fundamental domain."}, {"title": "Contributions", "content": "The main contributions of our work can be summarized in three points:\nFirst, we are the first to provide an extensive analysis of the state-of-the-art leading LLMs' surprising difficulties in solving fundamental constructive geometric problems, highlighting a critical gap in their reasoning capabilities.\nSecond, we introduce three methods that assist LLMs in overcoming current limitations in the domain of constructive geometry. Our dynamic prompting mechanism enables LLMs to build upon their previous interactions instead of uninformative static prompts, our variable renaming technique neutralizes biases from variable name conventions that complicate reasoning, and our scene description prompt enhances LLMs' abilities to understand and manipulate spatial relationships in a geometric context.\nThird, we present a novel simulacra-based system that effectively combines tool usage, instruction following, and geometric problem-solving. Our suggestions show a substantial improvement over non-collaborative methods, leading to effective solutions in geometric reasoning."}, {"title": "2. Related Work", "content": "Our approach is inspired by works of various research directions, which we briefly describe here.\nPrompt Engineering The emergent reasoning and in-context abilities of multi-billion-parameter LLMs (OpenAI, 2023; Brown et al., 2020; Google, 2023; Mitchell et al., 2022; Chowdhery et al., 2022) transformed prompt engineering from simple commands to sophisticated interactions for eliciting detailed responses. Works like (Wei et al., 2022; Kojima et al., 2022; Zhang et al., 2023b) use intermediate reasoning steps in prompts, significantly improving performance in arithmetic and symbolic reasoning tasks. As an alternative to hand-crafted prompts, a series of techniques (Reynolds & McDonell, 2021; Zhou et al., 2023d; Shin et al., 2020) are proposed for automated prompt generation, exhibiting better results in reasoning tasks. In multi-agent scenarios, (Li et al., 2023) introduce Inception Prompting, a method that enables LLM-based agents to prompt each other in collaborative environments under the assignment of roles. Recently, (Hao et al., 2023; Xie et al., 2023; Yao et al., 2023a) use tree-search and self-evaluation for tasks requiring exploration and strategic lookahead. (Yao et al., 2023b) unifies planning and acting in LLMs, prompting the models to generate both reasoning traces and task-specific actions. As a direct expansion, (Zhou et al., 2023b) advances these concepts with a Monte Carlo tree search over possible reasoning steps and actions, achieving state-of-the-art results in coding tasks.\nSimulacra Conversational Agents The concept of 'Agents' as entities exhibiting emergent intelligence through collective interaction was introduced by (Minsky, 1986)."}, {"title": "3. Preliminaries", "content": "In this section, we present the datasets, models, metrics, and definitions central to our experimental framework.\nEuclidea Our primary benchmark is the geometry game Euclidea, an online construction challenge with a range of geometric problems. The game offers eight geometric tools, the availability of which varies by level, to solve progressively complex challenges. While initial levels are straightforward, their difficulty quickly escalates, presenting significant challenges. In our experiments, we use the Python version of Euclidea (PyEuclidea), designed for academic use, encompassing ninety-eight challenges across ten difficulty levels. A custom API for programmatic construction and verification of solutions is also available. We also compile a natural language version of the Euclidea dataset, including challenge definitions, solutions, and explanations from https://euclidea.fandom.com/wiki/Euclidea_Wiki, which we will make accessible for future research.\nEuclid's Elements We explore the efficacy of training open-source LLMs on Euclid's Elements, the seminal work on constructive geometry. In Elements, a set of fundamental axioms and tools - the ruler and compass - are initially presented. Then, progressively more complex tools are synthesized through the solution of constructions using knowledge acquired exclusively from previous chapters. Similarly, various corollaries are suggested during the Elements, offering reasoning shortcuts for more advanced problems in forthcoming chapters. We posit that exposure to Elements would better align LLMs with constructive geometry tasks, as this work theoretically contains the required knowledge to solve the challenges. We utilize the publicly available English translation of Euclid's Elements (Fitzpatrick, 2007-2008) found here.\nModels In our experimental setup, we examine the performance of seven LLMs (five open-source and two closed-source). LLamaV2 (Touvron et al., 2023) is one the most popular instruction-following LLMs, exhibiting impressive performance across various tasks involving commonsense reasoning, natural language understanding, dialogue, maths, and coding. We test two available checkpoints, namely its 7B and 13B variants. We also choose to include the recently introduced Mistral (Jiang et al., 2023) and its fine-tuned variant named Zephyr (Tunstall et al., 2023), two 7B LLMs that, at their scale exhibit performance comparative to larger checkpoints of other open-source LLMs. Meta-"}, {"title": "4. Method", "content": "This section introduces the various components of our proposed framework, each specifically designed to address the limitations of LLMs in solving constructive geometrical problems."}, {"title": "4.1. Prompt Engineering for Geometric Reasoning", "content": "For each tested geometric challenge, we prompt our LLMs with a description outlining the available geometric tools, their expected operation, and the task requirements. We employ a few-shot learning setup to enhance our models' accuracy and reduce erroneous interpretations of tool functionalities. Specifically, we maintain a memory bank of all previously encountered problems. For each new problem, we select a subset of these problems that are most relevant to the current task. This approach ensures that our model is consistently exposed to more intricate problems and diverse tools, cultivating a more nuanced and context-aware reasoning process. We refer to this mechanism as Adaptive-Shot.\nOur proposed Adaptive-Shot mechanism employs a Sentence Transformer to compare the similarity between the current level's description and available tools and those of all other levels. After this initial filtering stage, the remaining examples are presented back to the model. Subsequently, the model is tasked to identify the top five most useful examples for the current challenge, integrating them into the final few-shot prompt. This method not only refines the model's understanding of geometric concepts but also enhances its ability to apply this knowledge effectively to new and more complex problems. An illustrated schematic of our mechanism can be found in the Appendix, Section D."}, {"title": "4.2. From Single Models To Simulacra", "content": "In the following stage, inspired by multi-agent collaborative environments of LLM-powered agents - simulacra (Li et al., 2023; Park et al., 2022), we utilize role-assigning prompts and employ two sets of agents. In the first agent set, which we will refer to as solvers, the natural language solver \\(S_{NL}\\) is tasked to generate rationales for approaching the problem in natural language, and the geometric tool solver \\(S_{GT}\\) interprets these rationales and converts them to a series of steps using exclusively the available geometric tools. Note here that \\(S_{GT}\\) can also be used directly without the existence of \\(S_{NL}\\), which is the default approach of a single LLM, prompted with the available geometric tool examples of the Euclidea dataset. The second set of agents, which we call validators, is responsible for assessing the proposed rationales and geometric tool steps, thus introducing a new layer of roles. Like solvers, validators receive domain-specific prompts, distinguishing them as natural language or geometric tool agents. However, unlike solvers who use the adaptive-shot mechanism for their few-shot examples, validators are prompted with propositions from Euclid's Elements and a static collection of incorrect examples alongside their rectifications. Depending on their domain, these are expressed in natural language or geometric tool steps. Each validator is tasked to provide feedback to its assigned solver through rounds of dialogue. We limit the number of interactions to up to five rounds for our experiments. During each round, the validator either accepts the solver's steps or suggests changes, prompting the solver to incorporate them into their solution."}, {"title": "4.3. Enhancing Spatial Awareness with the Visual Relations Prompt", "content": "Building upon the collaborative dynamic between solvers and validators, we recognize a critical limitation in their capability to conceptualize spatial relationships in geometric problems. This limitation manifests in several ways, notably through geometrically implausible actions such as attempting to connect non-aligned points with a straight line or assuming unproven relationships between objects.\nTo address this, we introduce a method incorporating an auxiliary Vision-Language Large Model (VLLM) to augment scene comprehension while operating within the language domain. Our approach uses the VLLM not as the primary reasoning tool but as a scene analysis instrument. We opt for GPT4-V, given its superior performance and ease of use. The process begins by feeding the VLLM with an image-problem pair, prompting it to comprehensively describe the scene's geometric elements, their interrelations, and spatial orientations. This description, which we will refer to as the Visual Relations Prompt (VRP), is added to each agent's prompt. Through this integration, we disentangle the process of spatial recognition from the challenging geometric problem-solving that the agents must perform concurrently. The proposed VRP is also cost-efficient, as the extraction is required only once per problem and can be shared across all agents concurrently, significantly reducing the need for recurrent interactions with visual extractors. Furthermore, it is also quite flexible, enabling models that lack innate visual capabilities to utilize the VRP, enhancing their decision-making abilities. For a comprehensive visual representation of how the VRP functions within our framework, please refer to the Appendix, Section G."}, {"title": "4.4. Mitigating Naming Biases", "content": "LLMs have been studied for adopting social biases found among humans (Wallace et al., 2019; Liang et al., 2021), or being negatively affected by language bias in their reasoning process (Lin et al., 2020; Mouselinos et al., 2023). We observe a similar bias arising from the terminology used for geometric entities. For instance, when tasked with constructing a target named 'E' in contexts with existing objects' A,' 'B,' and 'C,' models will create an intermediate object 'D' before proceeding to 'E.' This tendency extends to choosing longer reasoning paths based on the alphabetical position of the target variable, leading to unnecessary complexity and incorrect solutions. Likewise, choosing a target variable earlier in the alphabetical sequence than the required minimum steps to solve the problem can introduce faulty rationales (e.g., choosing 'C' as the target of a five-step solution can lead to early stopping on an intermediate generated 'C' point, abruptly ending the construction).\nThus, we propose a straightforward yet effective strategy to address this issue: substituting the target variable with 'X,' a universal symbol for unknowns in mathematics. This change encourages models to seek the most direct solutions, reducing the influence of alphabetical ordering. Our method proves particularly beneficial in the validation stage of our multi-agent system, where it effectively minimizes the misjudgment of correct solutions and the consequent propagation of errors. An example of such behavior can be seen in the dialogue presented in Appendix Section H."}, {"title": "5. Experiments", "content": "We present a comprehensive summary of our tested models' performance on the Euclidea dataset in Table 1. Our results are composed of three different testing setups:\nIn Few-shot, apart from the task, the description of the available tools and their intended use, models are also prompted with five solved examples using geometric tools in their solutions.\nIn Finetuned, we first fine-tune all open-source models using Euclid's book \"Elements.\" In this way, we aim to provide models with the foundational knowledge and principles essential for addressing the challenges within the Euclidea dataset. It is crucial to highlight that, aside from the tutorial levels, there is no direct overlap between Euclidea challenges and the problems included in \"Elements.\" During testing, models use the same setup as in Few-shot.\nSimulacra refers to our proposed multi-agent framework, equipped with adaptive few-shot mechanism, visual relations prompting, and variable renaming. In our few-shot experimental setup, all models exhibit underwhelming performance, which improves modestly after fine-tuning. This aligns with our expectation that familiarity with standard mathematical and reasoning scenarios does not ensure proficiency in constructive geometry tasks. We posit that the increased performance from fine-tuning with Euclid's \"Elements\" represents an upper limit of improvement achievable by open-source models, constrained by the dataset's size. MetaMath-Mistral 7B is the most promising among the open-source options, which we further examine with our multi-agent setup. Our results reveal a significant performance boost in larger models (ChatGPT / GPT4) and, notably, in MetaMath-Mistral 7B, under our proposed framework, surpassing the few-shot ChatGPT in performance. This finding underscores the adaptability and effectiveness of our approach across a spectrum of model sizes.\nMoreover, we compare against two prior studies on the Euclidea Dataset. The model proposed by (Macke et al., 2021) combines a Masked-RCNN detector with an iterative deep search algorithm. It used the Euclidea API to verify each proposed step, continuing until a solution is found within a pre-defined depth limit."}, {"title": "6. Ablation Studies", "content": "6.1. Overcoming hallucinations and context overdependence\nIn our exploration of LLMs' proficiency in geometric problem-solving, we initially used models in a zero-shot setup, with the only context being the tool definitions. This yielded subpar results, with models hallucinating the functionalities of the tools. Consequently, we shifted to a few-shot approach, integrating examples of solved problems into our prompts. This noticeably reduced hallucinations, but models seemed to over-rely on the provided examples, often replicating sequences of steps in their solutions.\nWe hypothesized that this behavior stems from the instruction-tuning training process: Many LLMs are fine-tuned to follow instructions closely, primarily replicating styles and patterns. In our case, models were not merely mimicking styles but inadvertently replicating entire reasoning processes. Instruction-following proved counterproductive here, especially since many geometric problems share common preliminary steps (e.g., constructing bisectors or circles of equal radius). Models frequently repeated specific groups of steps, irrespective of their relevance to the problem, leading to redundant and incorrect constructions. This is further illustrated in Table 2, where we evaluated the model's performance in solving geometric problems from three distinct difficulty levels: Tutorial, Alpha, and Beta. Interestingly, unlike the simpler Alpha and Tutorial levels, the model exhibited improved performance when prompted with higher difficulty (Beta) examples. This observation contradicts typical few-shot prompts in algorithmic or mathematical problem-solving, which include straightforward, demonstrative examples mirroring the dataset's style and expected logic.\nRecognizing these limitations, we repeated our experiments using our proposed adaptive few-shot approach. Apart from Adaptive-Shot (Self), we also tested with a simpler variant, Adaptive-Shot (ST), where the Sentence Transformer, rather than the model, determined the selection of few-shot examples after the filtering stage. Our findings demonstrate that adaptive variations outperform the static approach, corroborating our hypothesis. The Adaptive-Shot (Self) method proved slightly more effective, albeit with the trade-off of necessitating more API calls than the Adaptive-Shot (ST), particularly in closed-source models. The method is also limited by the capacity of the model to identify what prompts would be more useful for the task, which we hypothesized to surpass the contextual abilities of an auxiliary sentence transformer."}, {"title": "6.2. Effectiveness of domain and role division", "content": "Interestingly, LLMs proved quite successful when prompted to merely generate ideas - and not specific steps using geometric tools. Although they made convenient assumptions, their overall reasoning was still accurate. This led us to question the root cause of the discrepancy between knowing the solution in the form of a plan expressed in natural language and failing to execute it accurately using strict and abstract geometric tools.\nWe decided to test whether we can instead benefit from the synergy of those worlds: an LLM instance could focus on generating ideas in the natural language domain, and another could specialize in transforming these ideas into a series of geometric tool steps. By employing such a multi-agent setup, as seen in Table 3, we observed a significant performance gain - 13.6 \u2192 21.5 pass@1 - when comparing a single agent (SGT) operating directly with geometric tools against a duo of collaborative agents with differentiated domains (SNL - SGT). However, we noticed that the chaining of agents could sometimes result in the propagation of errors. For instance, a natural language solver producing a flawed rationale would inevitably pass these inaccuracies on to the geometric tool solver. To counter this, we experimented with the introduction of a set of validators. These agents, prompted under a different role and context, helped to minimize errors both during the transition between domains and by preventing the improper application of tools, leading to a further performance boost of 22.2 \u2192 28.1 pass@1 in our proposed multi-agent configuration."}, {"title": "6.3. Visual Aids in Spatial Reasoning", "content": "Another noteworthy finding was that LLMs would often create new geometric objects without acknowledging their overlap with existing ones. Moreover, they occasionally suggested steps that violated geometric rules or led to repetitive movements. We hypothesized that LLMs' difficulty with geometric reasoning in 2D spaces stems from a lack of exposure to such setups, typically operating in a unidimensional, left-to-right manner. This raised the question: Could introducing a visual signal bridge this reasoning gap?\nTo test this, we used GPT4-V, a multimodal variant of GPT4 known for its proficiency in visual question answering. We began with simple tests, prompting GPT4-V to identify free-hand sketches of geometric objects. The model identified these features successfully, including subtle aspects like right angles indicated by small corner squares. We then proceeded to a more complex scenario: We presented GPT4-V with an image/problem pair and asked for the first solution step. We deliberately performed an incorrect step and found that GPT4-V often validated these errors, suggesting a disconnect between scene understanding and geometric reasoning. We present these findings in Table 4. Comparing GPT4 with its multimodal variant, GPT4-V + Image revealed a marginal improvement, suggesting that a visual signal could only assist the initial scene understanding without significantly improving spatial arrangement in later stages. Building on these insights, we compare our proposed VRP method (VRP-GPT4) to the multimodal approach (GPT4-V + Image). Results demonstrated a slight performance boost with VRP, with its real advantage lying, however, in enhancing the capabilities of non-visually capable models like the tested ChatGPT and multi-agent configurations, which benefited greatly."}, {"title": "6.4. Impact of Geometry Nomenclature on LLMs", "content": "LLMs mirror the human convention of alphabetical naming in mathematical contexts. The choice of target variables later in the alphabetical order leads to longer and more inaccurate solutions. This is a byproduct of their training on"}, {"title": "6.5. Generalisation to different datasets", "content": "To expand the scope of our research and examine the potential generalizability of our multi-agent framework, we tested its performance against three datasets involving mathematical reasoning: GSM8K, SVAMP, and the Geometry split from the MATH dataset. We were inspired by the findings of (Zhao et al., 2023), who identified diverse reasoning patterns when LLMs are engaged in problem-solving using Chain of Thought (COT) (Wei et al., 2022) versus Program-Aid (PAL) (Gao et al., 2023) methodologies. While COT is recognized for its creativity and flexibility in devising solutions, PAL is noted for its enhanced accuracy in numerical computations. This differentiation of roles was an ideal fit for our framework: A pair of Solver-Validator agents (SVCOT) could initially converse about solving a math problem using a chain of thoughts approach. Then, the produced rationale would be passed down to another pair of agents (SVPAL),"}, {"title": "7. Conclusions", "content": "Our study highlights the intrinsic challenges that LLMs face in constructive geometry. We observe a limited skill transfer from other mathematical domains, insufficiencies of typical prompting techniques, and a lack of 2D spatial reasoning. We thus identify that the existing LLMs are inferior in achieving very competitive performance on geometric tasks unless we reinforce the system with strong inductive biases such as a theorem prover (Trinh et al., 2024). On the other hand, we also show that our multi-agent system with role specializations and interactions can substantially boost the performance of the whole system, and tackle geometric problems more effectively. That system has some properties of the conceptual integration networks (Fauconnier & Turner, 1998) where the \u201cblending\" happens if the system is considered as a whole.\nWe hope that our work provides a starting point for a longer-term view where the system is explicitly trained to interact in a multi-agent setting. Though challenging, this paradigm shift from merely enhancing existing models to creating a new generation of LLMs will eventually be required for significant breakthroughs in domains where deep, specific, and accurate cognitive processing is crucial."}, {"title": "8. Limitations", "content": "In our study, we specifically focus on constructive geometry, a distinct subset within the broader field of geometry. While numerous datasets address geometric problems, they predominantly focus on Vision-Language Models (VLMs) and employ a question-answering (QA) format, which differs fundamentally from the nature of constructive geometry. To the best of our knowledge, the dataset used is unique in this area, and we hope to attract more attention to the domain. We also recognize that our multi-agent setup might not be universally applicable, particularly for general-purpose datasets and solutions. Our approach could be less effective and slower than few-shot methods in scenarios where distinct modalities or roles are unnecessary.\nFurthermore, it is crucial to consider the significant costs associated with experiments involving closed-source LLMs behind APIs. The extensive communication rounds and large context sizes required by our method can lead to substantial expenses. In cases where cost is a concern, a more straightforward, single-agent approach may be more viable and cost-effective."}, {"title": "9. Risks and Ethical Considerations", "content": "We do not identify any risks or ethical considerations associated with our proposed ideas and suggested methods."}, {"title": "A. Information on Models and Datasets", "content": "Table 7. URL and Licenses of used Large Language Models / APIs.\nTable 8. URL and Licenses of used Datasets."}, {"title": "B. Information on Experimental Setup", "content": "Our experimental setup consisted of 1x NVIDIA A100 GPU. Regarding the fine-tuning results on Euclid's Elements of Table 1, we trained all LLMs using the bitsandbytes library (https://github.com/TimDettmers/bitsandbytes) and 4-bit quantization with the QLoRA technique (Dettmers et al., 2023). Below, the reader can find the full hyperparameter list:\nTable 9. Hyperparameters and their values\nRegarding the training objective, we used the typical causal language modeling loss. Moreover, we used a validation split of 10% sampled uniformly across different chapters of the book. We monitored the validation loss every 500 steps as our metric for early stopping.\nRegarding the API calls to OpenAI models, gpt3.5-turbo-16k was used for the ChatGPT experiments, gpt4-32k was used for the GPT4 experiments, and for the extraction of Visual Relation Prompts, The endpoint called gpt4-vision-preview was used. All of our API calls were subject to throttling limits, and waiting loops were introduced to avoid interruptions of service. We conducted most of our ablation studies and early experiments with ChatGPT to avoid massive waiting times and reduce the high experimental cost. The total experiment time was approximately 500 hours, and our total costs were around 2000 USD."}, {"title": "C. Tools and problems from Euclidea dataset", "content": "There are 10 tools available in Euclidea", "tools": "n1. Move Tool: Moves a geometric object.\n2. Point Tool: Marks a point and labels it.\n3. Line Tool: Draws a line between two points or a ray from a starting point.\n4. Circle Tool: Constructs a circle using a specific point as the center.\n5. Perpendicular Bisector Tool: Creates the perpendicular bisector of a segment between two points.\n6. Perpendicular Tool: Draws a line perpendicular to a given one at a specific point.\n7. Angle Bisector Tool: Creates a line that bisects a given angle. The line originates at the vertex of the angle.\n8. Parallel Tool: Draws a line parallel to a given line or segment.\n9. Compass Tool: Uses a compass to construct a circle with a radius equal to a given segment.\n10. Intersect Tool: Marks the intersection between two geometric objects.\nHere are some sample problems from different difficulty levels:\nGiven the rectangle ABCD with \\(AB > AD\\). Inscribe a rhombus in the rectangle so that they share a diagonal.\nAvailable Tools: [Line Tool", "Tool]\nSolution": "nPerpendicular Bisector Tool: Construct the perpendicular bisector of AC", "Tool": "Construct line AF.\nLine Tool: Construct line CE.\nGiven the side AB. Construct a rhombus with the given side and an angle of 45\u00b0 in a vertex.\nAvailable Tools: [Line Tool"}, {"Tool]\nSolution": "nPerpendicular Tool: Construct the perpendicular to AB from A; let C be a distinct arbitrary point on that perpendicular.\nAngle Bisector Tool: Construct the angle bisector of BAC.\nCircle Tool: Construct the circle with center A and radius AB", "Tool": "Construct the perpendicular to AC through D.\nLine Tool: Construct line BE.\nLet A be the vertex. Construct two rays that divide the given angle of 54 degrees into three equal parts.\nAvailable Tools: [Line Tool", "title": "D. Static Versus Adaptive Few-Shot", "content": "In this section, we will provide an analytical overview of our adaptive few-shot mechanism.\nAs seen in Figure 2, we begin by collecting a set of previously solved problems alongside their solutions, which call our knowledge base. This set can be acquired in multiple ways: In the case of our GSM8K / SVAMP / Geometry-Math experiments of Table 6, we use all problems belonging to the provided training split. In the case of Euclidea experiments of Table 1, we begin with a small set of five handcrafted geometric challenges. Euclidea's problems vary in difficulty and are grouped into increasingly difficult level-packs. Since we are not provided with a training split, we add all problems belonging to previously seen packs to our knowledge base during the solution of a level. In this way, we continuously increase the size of our base as well as the availability of more diverse and complex techniques that our agents can utilize. The second stage involves the use of a Sentence Transformer to reduce the size of our knowledge base. For this, we compare the cosine similarity scores of our current problem and the problems in our knowledge base and keep entries with scores over 0.5 or the top fifteen, whichever leads to less amount of examples.\nThe third and final stage involves the use of the Sentence Transformer again, which chooses the top five most similar examples to build the final few-shot prompt. This procedure is referred to as Adaptive-Shot (ST) in our experiments. An alternative to this is to use the examples from the second step and prompt our solver-LLM to filter the top five most relevant examples by itself. We call this alternative Adaptive-Shot (Self). Note here that the second step of the procedure can be skipped during Adaptive-Shot (ST) since instead of filtering, we can directly return the top five results. However, it is necessary in the Adaptive-Shot (Self) method, where we need to respect the context size limits of the tested LLMs.\nThe following example presents three different few-shot prompts: A static-handcrafted version, an adaptive prompt compiled by a Sentence Transformer (Adaptive ST), and finally, an adaptive prompt filtered by the model itself (Adaptive Self). Here, our model is ChatGPT, and the problem at hand is:"}, {"title": "E. Target Variable Name Bias", "content": "Below, we present a qualitative example of the effect of the target variable name on GPT4. The problem we present is: \"Find a point that is equidistant from given points A and B.\". We present three illustrations, each signifying a different reasoning path to its solution, according to the name given to the target variable.\nThe model is prompted to solve the problem of finding a point that is equidistant from given points A and B. By altering the variable name of the target point, we observe different reasoning paths (Figure 3): Naming the target C leads to 3 steps with the point C being marked at the intersection of two circles. Naming the target D leads to the same solution, with D being identified as the second point of the intersection between the circles. Using E as the target urges the model to first involve the generation of the variables C and D in its solution (since they precede E in terms of alphabetical ordering). This leads to a different reasoning path: The model comes up with a 4-step solution, where E lies on line CD, the perpendicular bisector of line AB. However, an interesting case can be observed with the letter X, usually associated with a missing variable. Here, the model returns to the shorter 3-step reasoning and gives X multiple possible solutions. X is assigned to points rather than being explicitly constructed as the result of a tool."}, {"title": "F. Baselines", "content": "We introduce two baselines to analyze the complexity of the geometric construction problem. In the first baseline, which we will call \"Longest Common Solution\u201d (LCS), we identify the top five longest common sequences of steps between ground truth solutions. Then, for each given problem, we uniformly sample from these sequences, adjusting the variables of each step and the tool usage to the current task. If a sampled step does not apply to the current state of the problem, the sampled sequence is discarded, and a new one is sampled instead. This baseline corresponds to the success rate of an agent who memorized a set of fixed solution steps and applied them to each given problem.\nAdditionally, we propose a second baseline named 'N-Gram Rollouts' (N-Gram), which begins by creating a database of uni-, bi-, and tri-grams derived from the tools used in ground-truth answers. For each problem, our method involves a two-phase iterative process. Initially, we choose either a single tool (n = 1) or a sequence of tools (n > 1) from our database. Following this, we select the geometric variables upon which these tools will be applied. To facilitate this, we maintain a memory initially populated with variables given in the problem statement. It's important to note that tool application varies in complexity, with some tools requiring a single variable (e.g., constructing a ray from point A) and others necessitating two (e.g., drawing a line between points A and B). For each tool or sequence of tools selected, we sample the required number of variables from memory, with recent variables weighted more heavily than older ones, following an exponential decay schema. Any new variables a tool generates (such as a new point) are added to this memory. This process is repeated until a predefined number of steps is reached."}, {"title": "G. Visual Relations Prompt", "content": "In Figure 4, we provide a visualization of our proposed visual relations prompt:\nWe begin by employing an auxiliary prompt that contains the problem question and an image depicting the initial state of the problem. This is presented to GPT4-V, where a list of Points, Lines, Objects, and their Relations is returned in the form of bullet points. This information, which we refer to as VRP, is then added to the overall agent prompt between the few-shot examples and the current problem and available tool description."}, {"title": "H. Multi-Agent Dialogue Examples", "content": "Illustration of our proposed SVNL \u2013 SVGT multi-agent setup. We present the agent dialogue leading to a successful solution. The use of a single ChatGPT instance is not sufficient to solve this particular problem. However, the combined power of multiple agents can.\nAccording to our proposed method, we employ 4 agents:"}]}