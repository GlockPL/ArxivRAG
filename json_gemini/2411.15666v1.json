{"title": "Ontology-Constrained Generation of Domain-Specific Clinical Summaries", "authors": ["Gaya Mehenni", "Amal Zouaq"], "abstract": "Large Language Models (LLMs) offer promising solutions for text summarization. However, some domains require specific information to be available in the summaries. Generating these domain-adapted summaries is still an open challenge. Similarly, hallucinations in generated content is a major drawback of current approaches, preventing their deployment. This study proposes a novel approach that leverages ontologies to create domain-adapted summaries both structured and unstructured. We employ an ontology-guided constrained decoding process to reduce hallucinations while improving relevance. When applied to the medical domain, our method shows potential in summarizing Electronic Health Records (EHRs) across different specialties, allowing doctors to focus on the most relevant information to their domain. Evaluation on the MIMIC-III dataset demonstrates improvements in generating domain-adapted summaries of clinical notes and hallucination reduction.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) have shown major improvements in their extraction and summarization capabilities. In the medical field, these models offer the potential to automate the summarization process of complex medical data, such as Electronic Health Records (EHRs) and clinical notes [22]. These documents, which contain an overwhelming amount of information, are a significant contributor to clinician burnout [27]. Thus, the generation of more focused and domain-specific summaries would help alleviate this task. Multiple challenges arise when LLMs are applied to the medical domain. Not only is the information condensed in a domain-specific terminology, but clinical notes are unstructured and do not follow specific formats. Additionally, these models are prone to hallucinations which can have serious consequences in healthcare settings. These issues become even more complex when the generated content must be adapted to different medical contexts. For example, the critical information required for cancer treatments differs significantly from that needed for diagnosis imaging analysis. Thus, ideally, different summaries should be generated for different areas of focus. To address these challenges, medical ontologies can be utilized to extract and prioritize information relevant to certain domains, specialties or fields. These ontologies provide a structured representation of medical knowledge, allowing for the identification of key concepts and relationships within a particular field aka domain. This information can be used to extract relevant information from clinical notes and leverage it to produce"}, {"title": "Related work", "content": "Summarization. Summarization is the process of generating a smaller text from a larger input text. The main objective of that process is to grasp the information of the input"}, {"title": "Methodology", "content": "Our research explores the potential of using ontologies to guide a language model towards relevant information using prompting and constrained generation. By constraining the generation using ontological structures, we aim to improve the summarization capabilities of language models and to reduce their hallucinations. To do this, we propose to utilize the ontology in conjunction with the beam search algorithm to assess the relevance and factual accuracy of potential beam candidates in relation to the input. By implementing this ontology-guided beam search, we expect to enhance the overall coherence and reliability of the generated text, ensuring that it aligns more closely with the knowledge represented in the ontology. To reduce hallucinations, we propose to also evaluate the beam paths based on the clinical note to favor those that resemble it the most. As a proof of concept, we develop a new method which divides the summarization task into multiple simple inference passes guided by an ontology-based prompting approach. Figure 2 shows how, given multiple clinical notes about the same patient, our method outputs a text summary and a structured summary whose structure is defined by ontology concepts. This structured representation of the clinical notes can be leveraged afterwards to adapt the final summary to various domains (medical fields such as cardiology, oncology, etc.). Finally, our approach can be applied to any model since it only requires token probabilities."}, {"title": "Domain adaptation analysis", "content": "We define a domain to be a set of ontology classes of interest related to a specific medical field. To adapt the generation to multiple domains, an initial analysis is performed"}, {"title": "Information Extraction using Ontology-based Prompting", "content": "Our next step is to extract medical concepts, properties and their values from clinical notes about a patient using a large language model (LLM), an ontology-based prompting process and a constrained decoding strategy. The overall process of the extraction phase is shown in Figure 3. The main goal of this step is to generate a structured version of clinical notes allowing doctors to easily query information based on concepts. This structured version will also be used in conjunction with the DCF dictionary (see section 3.1) in latter steps to specialize the summary to a given domain.\nTo improve the information extraction capabilities of the LLM, we adapted [32]'s summarization technique to the medical domain by incorporating an ontology-guided prompting process. Given multiple clinical notes of a patient during an admission and a medical ontology, we start by annotating each clinical note to retrieve all the medical"}, {"title": "Constrained Decoding", "content": "The decoding strategy during the extraction step is designed to guide the model's answer towards responses that are more relevant to the prompt. This strategy serves two primary purposes: leveraging the knowledge embedded within the ontology to steer the model towards a more relevant answer to the prompt (relevance), and reducing the occurrence of hallucinations (groundedness) during the generation process to ensure that the model's responses align with both the prompt and the provided notes. The overall constrained decoding process is shown in Fig. 4. This process is used in conjunction with the ontology-based prompting (see section 3.2) to obtain a final class-structured representation (CSR) for each clinical note.\nWe propose an algorithm based on diverse beam search [31], wherein grouped beam search is employed to diversify the results. In a nutshell, our algorithm favors beams that textually resemble the input and that contain concepts that are related in the ontology through hierarchical relations(subclasses and superclasses) and restriction properties. Since extracting information from generated beam candidates is not an operation that can be done trivially token by token, our algorithm computes the beam scores after a certain number of tokens, defined as the generation window. After this threshold, the newly generated tokens are analyzed using the same annotator used to tag the clinical notes. Once the beam is tagged, a score is calculated, as detailed below, to favor beam paths that are aligned with the internal structure of the ontology and with the note content.\nTo calculate the score of a beam, we compute three sub-scores : the hierarchy score $H$, the property score $P$ and the similarity score $S$. For all scores, we define $b$ to be the base class corresponding to the ontology class used in the prompt shown in section 3.2. This corresponds to the ontology class replacing the \"[concept]\" tag. We also define $T$ to be the newly generated tokens in the beam, $C$ the set of classes retrieved from $T$ and $A(c)$ the set of ancestors of a class $c$ in $C$.\nHierarchy Score. The hierarchy score $H$ computes a score based on the number of descendants of the base class that are present in the generated beam :\n$H = \\frac{1}{H_{bf}|C|} \\Sigma_{c \\in C} 1\\{b \\in A(c)\\}$\nwhere $H_{bf}$ is the hierarchy boost factor, a hyperparameter controlling how relevant we want the hierarchy score to have an impact on the final beam score. The primary goal of the hierarchy score is to guide beams towards the ontology's hierarchy to make sure that the generation is relevant to what is expected. For instance, when asked to summarize the patient's diseases, we would expect the model's answer to contain ontology classes that inherit the disease class.\nProperty Score. The property score $P$ evaluates how relevant a beam is to the base class, based on restriction properties associated to the base class. While this can be generalized to any class property, we only consider restriction properties as they are the most frequent in the ontology used in our case. This score allows the decoding process"}, {"title": "Pruning and Verbalization", "content": "Pruning. Once a class-structured representation of each clinical note is obtained using the extraction process, we prune each representation to adapt the summary to a given domain (or specialty) by keeping only the domain-relevant ontological classes. This pruning step aims to adapt the summaries to a given domain by focusing only on the extracted information that is relevant to the domain. This is done using the DCF dictionary computed initially (see section 3.1). In practice, for computational reasons, we retrieve the top-k most frequent classes in the DCF dictionary. However, upper-level classes tend to be more frequent. To account for this problem, we also retrieve all classes that are within a nodes from a frequent class in the ontology using hierarchical relationships from superclasses to subclasses. In this case, k is a hyperparameter controlling the length of generated summaries in terms of the number of concepts covered and a is a hyperparameter controlling the preciseness of the generated summary.\nVerbalization. We also use a final forward pass using the same LLM that transforms the structured output into an unstructured format. This process ensures that the output aligns with the requirements of the task and allows us to compare the efficiency of the method in terms of summarization."}, {"title": "Experiments", "content": null}, {"title": "Dataset & Ontology", "content": "The Medical Information Mart for Intensive Care (MIMIC-III) database [14] was used to retrieve clinical notes. This database regroups over 45,000 de-identified patient admissions to critical care in the Beth Israel Deaconess Medical Center between 2001 and 2012. Each admission contains multiple clinical notes associated to the same patient and is linked to a Brief Hospital Course (BHC) section of the patient's discharge summary. Overall, the dataset contains over 1.4 million single clinical notes. For computational reasons, we only use a test set called $ \\Omega $ of 400 randomly chosen admissions, regrouping over 3000 clinical notes, to perform our evaluations.\nClinical notes are associated to several categories ranging from electrocardiogram (ECG) reports to nursing notes and discharge summaries. Each note category serves a specific purpose and is associated to its own set of medical terms. For instance, ECG reports offer detailed insights about the patient's cardiovascular functions and structures, and nursing notes provide a continuous narrative of the patient's day-to-day care. These categories (ECG, Nursing, ...) are used to define our domains. For the domain adaptation of summaries, we employed the SNOMED-CT ontology [25], given its comprehensive representation of diverse medical fields. To analyze the occurrence of the SNOMED concepts in the MIMIC dataset, we computed the most frequent concepts in each domain (category) of MIMIC's notes. Note that to perform this analysis, we pruned some branches of the SNOMED-CT ontology as they do not correspond to medical concepts (Linkage concepts, Qualifier values, ...)."}, {"title": "Models", "content": "To generate our tailored summaries, we used the Phi-3 model, a 3.5 billion parameter model matching GPT3.5's performance [1] as well as Zephyr-7b-beta [28]. Both models were used for the extraction phase and as verbalizers. As for the annotator linking text sequences and SNOMED-CT classes, we utilized the MedCAT annotator [15]. This annotator was used during the decoding process and during evaluation to tag concepts (see Section 5.3).\nGeneration window. We evaluate empirically that a generation window of 5 to 15 tokens is a good trade-off between extraction capabilities and performance. We use a generation window of 10 tokens."}, {"title": "Evaluation", "content": null}, {"title": "Domain adaptation", "content": "Evaluator. Since no ground truth exists for this task, we needed to train an evaluator to compute a domain adaptation score. For this purpose, we fine-tuned a BERT classifier trained on the medical domain [4] to predict the domain of a clinical note. We denote this model as the evaluator model. To do so, we utilized the CATEGORY column of MIMIC-III which indicates the medical field of a clinical note. In practice, since not all domains are equally present, we focus on the Nursing, ECG, Radiology and Physician domains as they are the most frequent. To train the model, we use 400k individual clinical notes with their respective categories. For validation, 40k clinical notes were randomly selected. These training and validation sets are disjoints from the test set used to evaluate the summaries in other experiments. After training, the model achieved a 99% accuracy on the validation set. However, we found that the model tended to rely on each domain's note format instead of relying entirely on the underlying concepts to predict the domain. Thus, we further fine-tuned the model on a custom-made dataset generated by passing 4k clinical notes not seen during the initial training through a BART paraphraser.\nDomain Score. We compute the domain score $D$ as the average logit score of the expected domain :\n$D = \\frac{1}{N} \\Sigma_{i=0}^{N} EVALUATOR(d(x_i))[d_i]$\\nwhere $d(x_i)$ is the domain adapted summary of the admission $x_i$, $d_i$ is the expected domain and $N$ is the number of samples. This metric is used to evaluate how tailored the generated summary is based on the domain.\nBaselines. To assess the effectiveness of domain adaptation, we evaluated three distinct approaches: (1) greedy search, (2) diverse beam search and (3) our method. For the greedy and diverse beam search methods, we augment the prompt with a prefix specifying the desired domain, instructing the model to tailor the summary accordingly4. For our method, we simply pass the result of the pruning phase to the verbalizer without specifying the desired domain. We then pass each of the summaries (greedy, beam search, our method) through our BERT Evaluator. By comparing these three methods, we aim to demonstrate the relative efficiency of our proposed technique in producing domain-tailored summaries without the need for explicit prompt engineering. We evaluate these methods on the $ \\Omega $ test set. Since each admission can be used to generate 4 domain-adapted summaries (Nursing, ECG, Radiology and Physician), the final test set, in this experiment, contains 1600 pairs (admission, domain-adapted summary)."}, {"title": "Hallucination Reduction", "content": "Evaluator. We also focus on evaluating the impact of our proposed constrained decoding process on reducing hallucinations. More precisely, we aim to evaluate how the constrained decoding process improves the extraction capabilities of the model. We evaluate two aspects: the groundedness and the relevance of the answers. We formulate this problem as an entailment task where we leverage Natural Language Inference"}, {"title": "Summarization", "content": "To compare our approach to state-of-the-art techniques, we evaluate its performance on generating the BHC section of the discharge summary of a MIMIC-III's patient admission, a well known task in the literature of clinical summarization [22,2]. We will define this task as the BHC task. We evaluate it on the $ \\Omega $ test set. As our method only requires a set of ontology classes to define a domain, we extended our approach to consider the BHC section as a domain. Just as presented in section 3.1, we performed a domain adaptation analysis on the BHC section of 1000 admissions to build our DCF dictionary.\nBaselines. We compare our method against a standard single-pass generation using a predefined prompt and other state-of-the-art techniques that underwent fine-tuning such as SPEER [3] and [22]'s dual Transformer. Following the literature, we compute the ROUGE score as it is the most used for this task.\nMetrics. Similarly to [2], we also compute an hallucination score which measures how much the generated summary tends to mention concepts that are not mentioned in the original notes. Given the set $N$ of concepts in the clinical notes and the set $S$ of concepts in the generated summary, this score is defined as :\n$HS = \\frac{|S - N|}{|S|}$\nHowever, this score is not entirely perfect since it does not take into account the uncertainty of the annotator used to tag the concepts. We thus compute the adjusted hallucination score (AHS) which incorporates the concepts from the reference summary into the metric. Given the set $R$ of concepts in the reference summary, this metrics is defined as:\n$AHS = \\frac{|S - (N \\cup R)|}{|S|}$\nThe AHS will give room for concepts that can be inferred from the notes."}, {"title": "Discussion and Limitations", "content": null}, {"title": "Domain adaptation", "content": "The results in Table 1 suggest that our approach is really effective on its intended application. It is more efficient at producing more domain-adapted summaries than simply prompting the model to do so. These findings underscore the significance of the pruning step as it is the main step performing the domain adaptation. This also shows that the set of relevant concepts for a domain can be inferred from the data, as the pruning step is completely based on the initial domain adaptation analysis. These findings also implicitly confirm that our ontology-based decoding process improves model performance. Indeed, the effectiveness of the pruning step heavily relies on the values in the CSR which are determined using our custom decoding process. Furthermore, our method significantly enhances the summarization process interpretability by separating the extraction and adaptation phases, allowing for a more modular, interpretable process. This transparency allows for easier verification and validation of the generated content. Once the extraction phase is performed, the pruning phase can be used to adapt to any domain without the need to repeat the extraction."}, {"title": "Reduction of Hallucinations", "content": "As shown in Table 3 by the hallucination score (HS) and adjusted hallucination score (AHS), our methodhandles hallucinations better in the generated summaries compared to the baselines, especially with Phi-3. While the extraction phase seems to have a large impact on the performance of Phi-3, in the case of Zephyr, it is the pruning phase that creates a bigger jump in performance. The improvements of our method shown in Table 2 also suggest that summaries generated using our custom ontology-guided decoding process are more likely to be factually consistent. This improvement in factuality and relevance is especially pronounced in the case of the Phi-3 model. Grounding each beam with the input and restraining the decoding process using an ontology contributes to hallucination reduction especially for a smaller model."}, {"title": "Summarization Performance", "content": "As Table 3 suggests, our technique demonstrates slight improvements in the summarization performance for clinical notes while providing a structured version of the same summary. This format is easier to query for clinicians. While this is not the best task to evaluate our method as it requires formulations specific to BHC summaries, it allows us to compare our results to state-of-the-art methods. Additionally, we also show that our definition of domains can be generalized since it is applicable to other tasks such as the BHC task. Finally, is is not surprising that our results did not outperform fine-tuned models since we used a prompting-based approach on models that were not specifically pre-trained to handle medical data."}, {"title": "Limitations", "content": "Since our approach relies on summarizing the notes around multiple concepts, the primary challenge is the computational overhead associated with the inference passes required by this method. While, they can easily be parallelized across all clinical notes and ontology classes, the overhead associated to beam search on all these passes poses challenges for scalability and deployment. Plus, our method is highly sensible to hyperparameters (prompt format, k, a, ...) which makes it hard to optimize. Additionally, it heavily relies on a good annotator. While such an annotator exists for SNOMED-CT, it might not be available for other ontologies. Finally, a significant limitation of our work is the absence of human assessment and gold standards with domain-related summaries.\nDue to time constraints in accessing medical experts, our evaluation only relies on automated evaluation methods which may not be always reliable. For instance, the NLI model employed to detect hallucinations in our generated content may not be optimal, as it lacks specific training on medical data. Consequently, the scores about hallucinated content may not be always trustworthy. Our future work will provide a qualitative evaluation of our results."}, {"title": "Conclusion", "content": "In this paper, we introduced a novel approach capable of generating domain-adapted summaries. We leveraged an ontology-guided decoding process to improve the factuality and relevance of the summarization process. We showed that guiding the model towards ontological concepts creates better domain-adapted summaries. Furthermore, our method improves performance in summarization, domain-adaptation, and groundedness on text input while providing a structured version of the summary. This structured version can easily be queried to extract relevant information in any use cases.\nApplied to the medical domain, our approach highlights the potential for generating tailored summaries across various medical fields. While computational overhead remains a challenge, this work represents a step towards reducing clinician burnout and improving patient care through more efficient information synthesis."}]}