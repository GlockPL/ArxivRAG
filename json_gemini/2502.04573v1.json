{"title": "Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer", "authors": ["Yulun Wu", "Doron L. Bergman"], "abstract": "We present an Adversarially Pre-trained Transformer (APT) that is able to perform zero-shot meta-learning on tabular prediction tasks without pre-training on any real-world dataset, extending on the recent development of Prior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trained with adversarial synthetic data agents, who continue to shift their underlying data generating distribution and deliberately challenge the model with different synthetic datasets. In addition, we propose a mixture block architecture that is able to handle classification tasks with arbitrary number of classes, addressing the class size limitation a crucial weakness of prior deep tabular zero-shot learners. In experiments, we show that our framework matches state-of-the-art performance on small classification tasks without filtering on dataset characteristics such as number of classes and number of missing values, while maintaining an average runtime under one second. On common benchmark dataset suites in both classification and regression, we show that adversarial pre-training was able to enhance TabPFN's performance. In our analysis, we demonstrate that the adversarial synthetic data agents were able to generate a more diverse collection of data compared to the ordinary random generator in TabPFN. In addition, we demonstrate that our mixture block neural design has improved generalizability and greatly accelerated pre-training.", "sections": [{"title": "1. Introduction", "content": "In standard deep learning workflows, models are trained per dataset, and expect data in a form compatible with, and drawn from, the same distribution as the dataset it was trained on during inference time. Even in transfer learning, where the output of the model is changed, the input is at most expanded, but at least overlaps heavily with the data distribution the model was trained on. This is in contrast with meta learning, where a model is trained to be adaptive to new datasets such that few gradient updates or fine-tuning are needed, instead of training a new model specialized to every distinct dataset from scratch. In meta learning, rather than modeling a specific dataset, the model is trained to learn how to learn. This has multiple advantages. First, meta learning is highly adaptable \u2013 it learns more generalized models, since it is not specialized to modeling only one dataset. Due to this flexibility, meta learning systems can quickly adapt to new tasks and different domains. Second, meta learning makes efficient use of data it supports learning from just a few samples. Third, as a consequence of its efficient use of (small) data, it can learn and reach a point where it can make meaningful predictions very quickly.\nIn prior work, Verma et al. (2020) discussed the notion of zero-shot meta-learning. They train a generative adversarial network conditioned on class attributes, that can generate novel (previously unseen) class samples. This relies on the inputs present in the training data (class attributes) to be indicative of the new unseen classes. While they do not use gradient updates on the unseen data for prediction, they rely on the input data coming at the very least from a very similar distribution to that of the training data. The scope of problems this work aims to address is pristine zero-shot meta learning: given an unseen dataset from an unseen task after the model is pre-trained and deployed, can we do prediction on this dataset without training the model on it? Specifically, with zero gradient update on the model, and with no reliance on the similarity between this dataset and the datasets that the model was pre-trained on. Note that this concept of zero-shot is slightly different from that in large vision and language models \u2013 the unseen datasets can entail heterogeneous fields or class labels that were never observed during pre-training, and zero-shot in this context refers to the amount of model optimization conducted being zero given the unseen dataset rather than the amount of empirical examples seen being zero. The advantage of successfully establishing such a model is the exceptional generalizability and runtime.\nA few recent breakthroughs have demonstrated that achieving this aspiration is possible: M\u00fcller et al. (2021) introduced Prior-Data Fitted Networks (PFNs). These are transformers pre-trained on synthetic data generated from a prior distribution, to perform approximate Bayesian inference in a single forward pass using in-context learning. PFNs do not fit a model on downstream training data, instead feeding training data into the context and conditioning on the context. Hollmann et al. (2022) introduced a PFN specifically aimed at tabular datasets \u2013 TabPFN. A detailed background review on PFNs and specifically TabPFN can be found in Appendix A. Tabular data \u2013 data organized in rows and columns, and characterized by an unlimited heterogeneity of data fields, remains an area of machine learning where deep neural networks (DNNs) still struggle to push the boundaries of the state-of-the-art gradient boosted decision trees (GBDTs), despite numerous approaches. Yet, tabular data is one of the most common data types in real-world machine learning (ML) applications.\nAlthough TabPFN has demonstrated exceptional zero-shot meta-learning capability on certain small tabular prediction tasks, we show that the distribution of synthetic data used in its pre-training is actually quite limited. Besides, the class size constraints of TabPFN poses a significant limitation on its generalizability \u2013 this might not be an important concern for the traditional one-model-for-one-domain pipeline, but is a crucial weakness for a zero-shot meta-learner (ZSML) since an unprecedented number of class labels could be present in inference time. Note that zero-shot meta-learning is largely similar to foundation modeling but slightly different in its scale and objective \u2013 it does not necessarily involve billions of parameters to learn the distribution of data in a broad domain such as language or health records and acquire token representations, but to model the general prediction logic and learn how to acquire data representations in unseen domains during inference time.\nSimilar to Hollmann et al. (2022), we investigate the capability of zero-shot meta-learning under the scope of tabular data prediction problems. Our contributions are listed as follow:"}, {"title": "2. Proposed Method", "content": "Our Adversarially Pre-trained Transformer (APT) model is pre-trained once offline using a mix of random synthetic data generators and adversarial synthetic data agents. In this phase, the goal of the model is not to learn the specific pattern or probability distribution of any given dataset, but to learn the general prediction logic and means to represent various data, i.e. learning to learn. Once pre-trained and deployed, the model makes predictions on the testing set of any real-world dataset of interest in one forward pass, without performing any back-propagation or gradient updates of its weights. A demonstration of the workflow is shown in Figure 1. In Section 2.1, we describe the adversarial data agents in detail, whose goal is to continuously produce diverse and more challenging datasets for the meta-learning model during pre-training; in Section 2.2, we elaborate on the architecture of our transformer model, which has no restrictions on the class size of any real-world datasets practitioners provide."}, {"title": "2.1. Adversarial Data Agents", "content": "In the pre-training phase, we compose a batch of m datasets ${X^{(k)},y^{(k)}}_{1\\leq k\\leq m}$ in each iteration using m different data generators ${g_1,..., g_m}$ that each independently generate n number of data points, where $X^{(k)} = [{x^{(k)}_{i}}]^{(k)T}_{1\\leq i \\leq n} = [{X^{(k)}_{i,j}}]_{i \\leq n, j \\leq d_k}$ and $y^{(k)} = [y^{(k)}_{i}]_{i \\leq n}$ are the predictor matrix and response vector (denoted as X and y when no index is specified) with feature size $d_k$. We adopted the multi-layer perceptron (MLP) construction introduced in Hollmann et al. (2022) for each generator instance, where predictors $x^{(k)}$ and response $y^{(k)}$ are values of randomly selected neurons in sparsified noisy MLPs with some additional pre-processing. More details regarding this approach can be found in Appendix A.1.\nDifferent from Hollmann et al. (2022), instead of generating datasets solely from randomly initialized sparse MLPs, a subset of the m generators in our framework are adversarial agents that learn from the model's performance on the generated data, and perform gradient ascent on the model's prediction loss. In other words, these adversarial agents challenge the model by constantly shifting the synthetic data generating distributions to deliberately produce datasets that are more difficult for the model to handle. The loss for an adversarial agent $g_n$ with respect to prediction model $q_{\\theta}$ can be written as\n$\\mathcal{L}(g_n) = \\mathbb{E}_{x,y \\sim g_n} \\log q_{\\theta}(Y_{(l+1):n}|X_{(l+1):n}, \\{X_{1:l}, Y_{1:l}\\})$\nwhere $\\{X_{1:l}, Y_{1:l}\\}$ and $\\{X_{(l+1):n}, Y_{(l+1):n}\\}$ are the training and testing set split from generated dataset $\\{X, y\\}$ at position l. In the following sections, we refer to the former (generators based on randomly initialized MLPs) as ordinary data generator, and the latter (generators based on adversarially updated MLPs) as adversarial data agents."}, {"title": "Relation to Classic Adversarial Training", "content": "In relation to GANs, the data agents here are the generators, and the meta-learner is the discriminator. Contrary to classic adversarial training, there is no real versus fake samples for the discriminator to distinguish in this context. The generator (data agent) and the discriminator (meta-learner) have one coherent competing objective: the meta-learner seeks to minimize the prediction loss on data generated by the data agents, while the data agent seeks to generate data that maximize the prediction loss by the meta-learner. As a result, the desired gradients for updating the discriminator is but a flip of sign to its gradients calculated through back propagation on the generator's objective. Hence, both the meta-learner and the data agents can be updated in one single iteration after loss calculation in this scenario. This results in a more efficient adversarial training, and we further reduce its potential of mode collapse with data agent reset described in the last paragraph of this section. Note that contrary to classic GANs, the discriminator is the final product in this context rather than the generator."}, {"title": "Discretization of Variables", "content": "A key challenge in establishing adversarial data agents is the gradient flow under discretization: how do we generate synthetic data with categorical features while being able to perform end-to-end loss back-propagation? Inspired by the Gumbel-Softmax trick and the Concrete distribution , we propose a continuous relaxation of discretization that naturally extends on the ranking discretization approach introduced in Hollmann et al. (2022), controlled by a user-specified temperature hyperparameter $\\tau$. For the j-th feature column $x_{.,j}$ of a predictor matrix X and the corresponding $N_j - 1$ randomly sampled Gaussian quantiles $Q^{(1)}_j < Q^{(2)}_j < ... < Q^{(N_j - 1)}_j$ at the initialization of the corresponding data agent, the soft-discretization that converts the i-th value of the j-th feature $x_{i,j}$ to a soft-categorical value with cardinality $N_j$ is given by\n$x^{cat}_{i,j} = \\pi\\left( \\left[\\{ x_{i,j} \\geq Q^{(l)}_j \\} \\right]^{N_j - 1}_{l=1} \\right) +$\n$\\tau \\cdot log \\left( 1 + \\frac{\\mathbb{I} (\\{ i,j \\}) } { \\sum_{l=1}^{N_j - 1} \\mathbb{I} (\\{ \\frac{x_{i,j} - Q^{(l)}_j}{Q^{(l)}_j - Q^{(l-1)}_j} \\}) } \\right)$\nwhere $\\pi$ is a permutation function on integer domain $\\{1,2,..., N_j - 1\\}$, $Q = min(x_{.,j}) + \\frac{l}{N_j}(max(x_{.,j}) - min(x_{.,j}))$ for $1 < l < N_j$ are the unnormalized quantiles with boundaries $Q^{(0)}_j = min(x_{.,j})$ and $Q^{(N_j)}_j = max(x_{.,j})$, and $|\\{v \\geq Q^{(l)}_j\\}_{l=1}^{N_j}| = \\sum_{l} \\mathbb{I}(v \\geq Q^{(l)}_j)$ is the position of a value v in the ordered sequence $\\{Q^{(l)}_j\\}_{1<l<N_j}$. A visual demonstration of this conversion can be found on the right side of Figure 6 in the Appendix. Same as Hollmann et al. (2022), the extended ranking discretization approach decides the value of a categorical variable using only the continuous scalar $X_{i,j}$, i.e. the value of one neuron in the sparsified noisy MLP, as opposed to the Gumbel-Softmax or Concrete distribution approach which would require selecting $N_j$ neurons as logits of the $N_j$ classes. In our early experiments, we found that sampling multiple neurons to decide the value of one categorical feature achieved significantly worse performance than ranking discretization. Furthermore, since we do not desire to learn the explicit form of these distributions, explicitly generating class logits is not a necessity, and hence we prefer a more efficient differentiable discretization technique that does not involve reparameterization tricks, softmax operations or excessive samplings."}, {"title": "Data Agent Reset", "content": "In terms of the diversity of generated data, there is a balance between adversarially updating the neurons in the MLPs and re-initializing the MLPs all together. Although in the short run, re-initializing the MLPs and the corresponding random factors (number of features, number of classes, etc.) instantaneously yield new datasets with a high chance of possessing much different fields and distributions from the previous, such generation is constrained by the domain of distribution defined by the preset range of hyperparameters in the long run (we show some evidence on this in Section 3.2). On the other hand, although adversarial data agents are performance-driven and could explore out-of-distribution regions better than random initialization, it also has the potential to converge to the Nash equilibrium and reach a stalemate with the meta-learner \u2013 for example, converging to a state where generated predictors x and response y have no correlation. Hence, we combine the two approaches and reset the adversarial data agents every $N_e$ epochs to avoid such convergence. To speak from the GANs angle, we are letting the discriminator, i.e. the meta-learner, to periodically gain an advantage and slightly beat the generator. Different from classic GANs, the discriminator is the desired model here while the generator is the supporting entity, hence exploration is more important than optimization for the generator in this context."}, {"title": "2.2. Mixture Block Architecture", "content": "Contrary to modern deep neural networks, traditional ML algorithms such as K-nearest neighbors and tree-based methods are more flexible in terms of their ability to handle varying cardinality of classification labels, in the sense that they do not entail fixed-size MLP parameters that cannot generalize to a different classification task with different label cardinality. This is not much of an issue for the traditional one-model-for-one-dataset ML pipeline, but is of significant importance for zero-shot meta-learners, yet unaddressed in prior works. Inspired by how tree-based methods solve classification tasks in a manner that is compliant to the empirical values and cardinality of training labels, we propose a scatter-sum mixture block as the output prediction head for classification tasks that significantly departs from the ordinary MLP final layer approach. A visual demonstration can be found on the right of Figure 2. For each data point in the testing set, we use its embedding after the transformer blocks to query the embeddings of training data, and yield two sets of logits via two separate feedforwards: one set of logits is used to calculate softmax probability weights of keys and the other set is used to sample soft-discrete gates via Concrete distribution to sparsify these weights. In essence, these gates govern the splits of training data in relation to the testing query, such that the final prediction only pays attention to a subset of relevant training data representations. In our preliminary experiments, we discovered that sparsifying attention through these gates are crucial to performance, and the mixture block works poorly without this component.\nThe output class probabilities are then acquired by a scatter summation of non-gated values using their original labels as index. Relating to tree-based methods, the gates here are used to determine the subset of training data that are in the same split of leaf nodes as a given testing data point, and the weights are used to determine the relative importance of each label in that split. Contrary to tree-based methods, the splits are point-specific, i.e. there is a different split decided for each testing data point, and the decision within the split is weighted rather than via majority voting. Note that this approach does not change the order of computation complexity in terms of data size and data dimensions \u2013 it simply removes the final MLP layer and adds two more multi-head attentions and feedforwards to the transformer architecture in a non-sequential manner."}, {"title": "3. Experiment", "content": "We evaluated our model and competing algorithms on common ML benchmarking dataset suites for tabular classification and tabular regression problems. In Section 3.1, we show that APT achieves state-of-the-art performance on small tabular classification tasks with a runtime comparable to that of TabPFN. In Section 3.2, we present qualitative analysis on the impact and characteristics of the adversarial data agents. In Section 3.3, we demonstrate the generalizability of the mixture block and its effect on pre-training. In Section 3.4, we provide ablation study and show that adversarial pre-training was able to enhance the performance of TabPFN on both classification and regression tasks.\nDatasets For classification, we used the curated open-source OpenML-CC18 dataset suite containing 68 popular tabular benchmark datasets (4 vision datasets mnist_784, CIFAR_10, Devnagari-Script, and Fashion-MNIST are not treated as tabular and removed from the total 72 datasets), and our main results are presented on all small datasets (number of samples no larger than 2,000) in OpenML-CC18 similar to Hollmann et al. (2022), except that 1) there is no additional filtering, i.e. all datasets regardless of number of classes, number of features, number of categorical features, and number of missing values are kept in our evaluation pool, composing a more general collection of datasets. This brings the number of datasets in the evaluation pool from 18 to 35; 2) The train-test split is set to 80-20 instead of the unconventional 50-50. For regression benchmarking, we used the curated open-source OpenML-CTR23 dataset suite.\nAlgorithms We compared APT to the top 3 GBDT algorithms and the top 3 DNN methods in the main experiments of TabZilla, as well as 5 standard machine learning algorithms.\nHyperparameters The hyperparameter search space of benchmark models is directly inherited from Hollmann et al. (2022), and directly inherited from McElfresh et al. (2024) if the benchmark model is not in Hollmann et al. (2022)."}, {"title": "3.1. APT Achieves State-of-the-art Performance on Small Tabular Classification Tasks", "content": "We evaluated APT and benchmark models on small datasets in OpenML-CC18 using area under the receiver operating characteristic curve (ROC-AUC) with the one-vs-one (OVO) multi-class evaluation configuration, similar to Hollmann et al. (2022). Previously, Hollmann et al. (2022) has shown that TabPFN matches the performance of state-of-the-art GBDT algorithms and outperforms them on small datasets that have less than 100 features, less than 10 classes, no categorical features, and no missing values in their main results. In this work, we do not impose any of these restrictions to further examine APT's and TabPFN's zero-shot meta-learning capability. The results are presented in Table 1. For datasets with number of features larger than 100, we subsample 100 features similar to (McElfresh et al., 2024).\nIn these experiments, APT achieved state-of-the-art performances with a runtime similar to that of TabPFN. The average runtime of APT increased by 4.6% compared to TabPFN and remained within a second on GPU (NVIDIA H100), showing that neural modifications from the mixture block have not made APT significantly heavier. Note that there is no cherry-picking being performed on model checkpoints for APT \u2013 the APT model that we released and used for evaluations is the last model after the final iteration of pre-training. Realistically, PFN-based models are pre-trained on synthetic data, and picking checkpoints for evaluations ad hoc is not ideal unless using a whole different collection of real-world datasets for validation. But even in that case, it would still raise the concern of data leakage.\nIn these experiments, the deep learning algorithms under the standard supervised learning pipeline, ResNet and SAINT, yielded subpar performances. Note that the computing budget in Hollmann et al. (2022) and ours is set to 1 hour per dataset per split contrary to the 10 hours in McElfresh et al. (2024). The deep learning algorithms under the zero-shot meta-learning pipeline, APT and TabPFN, yielded ideal performances, but it has been previously shown that TabPFN sees a significant drop in performance on datasets with categorical features or missing values. In Figure 4, we further break down the results on datasets with and without these characteristics.\nFrom Figure 4, it can be observed that APT has fairly dealt with TabPFN's weakness in handling datasets with missing values, and has closened the gap between performance on datasets with and without categorical features compared to TabPFN, although GBDTs such as CatBoost still shows the greatest capability in handling datasets with categorical features. We further break down the performance contributions from each proposed component of the APT framework in Section 3.4."}, {"title": "3.2. Qualitative Analysis of the Adversarial Data Agents", "content": "Even though arbitrary MLPs have the potential to serve as universal function approximators given certain regularity constraints, the pre-set hyperparameters (e.g. sampling distribution of neurons, sampling distribution of the number of layers, choices of activations, etc.) as well as the lack of gradient updates restrict the family of data distributions that randomly initialized sparse neural networks can put forward in practice. As shown in Figure 3, the distribution of two-dimensional data generated by two whole different sets of random sparse neural networks align fairly precisely with merely 2,000 independent initializations. On the contrary, even without resetting neural architecture and neural parameters, the adversarial data agents still managed to generate a more diverse collection of data and diffuse the concentrated peaks presented in the density distribution of data generated by ordinary data generators. To be exact, for a collection of 2, 000 datasets generated by ordinary data generators, we evaluated a KL-divergence of 0.134\u00b10.141 between it and a collection of 2, 000 datasets generated by another set of ordinary data generators, and a KL-divergence of 0.813\u00b10.072 between it and a collection of 2, 000 datasets generated by adversarial data agents.\nAs a motivation of imposing data agent reset, we were wary that the data agents after many adversarial updates could yield synthetic datasets whose features have little to no signal on the response variable. With our hyperparameter settings, we have not observed such behavior and to our surprise, the synthetic datasets generated by adversarial agents exhibit slightly stronger signal with a Pearson correlation of 0.311 \u00b1 0.026 between predictors and responses on datasets with two-dimensional features as oppose to the 0.268\u00b10.013 of ordinary data generators. We postulate that this is partially in consequence of the high reset frequency and high generator learning rate."}, {"title": "3.3. Generalizability of the Mixture Block", "content": "After a ZSML is deployed, one should not be required to re-do its pre-training given certain characteristics of the datasets in evaluation pool that the model cannot handle, and this is why the mixture block architecture is important. For TabPFN, we have to look at the evaluation dataset pool first, calculate the largest class size, before using it as a hyperparameter for pre-training. This is not a procedure that fits well into the zero-shot learning concept. Our proposed mixture block architecture does not have such class size limitation, and we show the performance of APT on datasets with more than 10 classes in OpenML-CC18 in Table 2.\nInterestingly, the mixture block's generalizability significantly accelerated pre-training in our experiments. The ROC-AUC evaluated after each iteration of pre-training with and without the mixture block is presented in Figure 5. Note that ensembling over permutations is not performed in this experiment as it would dramatically increase runtime given that evaluation is performed following every gradient step."}, {"title": "3.4. Ablation Study", "content": "Classification Although we discovered that the mixture block gives the model a nice performance acceleration in the previous section, the original purpose of designing such architecture was not performance-driven, and we still expect that the final performance improvement was largely contributed by the adversarial pre-training. We present ablation study in Table 3 to verify this expectation."}, {"title": "Regression", "content": "Although ZSMLs are gradually catching up with GBDTs on classification problems and likely reached a performance mark close to saturation on small classification problems, tabular regression remains an area where ZSMLs have not yet shown exceptional performance. We additionally report a study on the 35 datasets in OpenML-CTR23 regression suite in Table 4, and show the progress APT has made on regression tasks over TabPFN.\nFrom Table 4, it can be observed that incorporating adversarial pre-training has boosted the performance of TabPFN, yielding a larger number of wins with a significant margin."}, {"title": "4. Related Work", "content": "4.1. Tabular Learning\nGBDTs such as XGBoost and others are commonly used for tabular data problems, in the traditional one-model-for-one-dataset approach. At this point, numerous deep learning approaches have been developed for tabular data, mostly taking the one-model-for-one-dataset approach, but some also venturing into transfer learning, many but not all leveraging large language models to find relevant information for the tabular data problem at hand."}, {"title": "Tabular Meta-Learning", "content": "Auto-Sklearn introduced in Feurer et al. (2015) and improved upon in Feurer et al. (2022) use Bayesian optimization to determine the best algorithm and feature pre-processing steps for modeling a given dataset. Meta learning is used for initializing the Bayesian optimization. In contrast to the approaches of transfer learning in deep tabular data, and of Auto-Sklearn, TabPFN is trained solely on synthetic data to learn how to acquire meaningful data representations and to learn the general prediction logic of tabular classification tasks. A more detailed background review on TabPFN can be found in Appendix A. Extensions to TabPFN include Feuer et al. (2024), where fine tuning was leveraged on top of TabPFN's basic function, to compress incoming data to fit into TabPFN's limitations. Helli et al. (2024) introduced a variant of TabPFN that was trained on a drifting synthetic data distribution, but the drift is independent of the performance of the model being optimized."}, {"title": "4.2. Zero-shot Learning", "content": "Recent work such as Xian et al. (2018; 2017); Chang et al. (2008); Larochelle et al. (2008); Palatucci et al. (2009) have shown impressive capability of zero-shot learning in the space of language and vision problems. Recent approaches to zero-shot or few-shot learning for tabular data problems mostly encode tabular data as language, and then leverage large language models (LLMs) for their zero- or few-shot capabilities. These approaches rely on relevant information about the tabular data existing in LLMs \u2013 this is most obviously the case when column names are meaningful \u2013 but it is not guaranteed for all tabular data problems."}, {"title": "4.3. Adversarial Training", "content": "Upon generative adversarial networks (GANs), recent work such as Shafahi et al. (2019) improved on the efficiency by combining the back-propagation steps of the generator and discriminator. However, this method has been shown to suffer from catastrophic overfitting without further modifications. Other works focusing on improving the efficiency of GAN training include Wong et al. (2020) and Zhang et al. (2019) where they restrict most of the forward and back propagation within the first layer of the network during adversarial updates. Zhang et al. (2021) in particular noted that weights updates frequently going back and forth in opposite directions in one training epoch, suggest those updates are redundant. Many other variations have been introduced to mitigate vanishing gradient and additional challenges of GAN training (see Jabbar et al. (2021) and references therein): failing at finding a Nash-equilibrium and internal covariate shift."}, {"title": "5. Conclusion", "content": "In this work, we gave the first effort in using adversarial synthetic data generators for the pre-training of deep zero-shot meta-learning algorithms. We proposed APT, a zero-shot meta-learner that improves the performance of TabPFN on tabular prediction tasks and matches state-of-the-art GBDTs on small tabular classification tasks. In addition, we proposed a mixture block neural design within the transformer architecture to eliminate the class size restriction of PFNs, addressing a crucial problem on zero-shot classifications.\nAs for limitations, APT does not outperform GBDTs on large tabular datasets, and shared the quadratic runtime and memory scaling of TabPFN. Hence, extensions of this work could explore means of acquiring data representations in a more inexpensive manner. Besides, future research in this field could shift the attention slightly more to zero-shot regressions, where there is a lot room for improvement. The final prediction layer of most neural architecture has reduced dimensions for regression compared to classification, while continuous variables generally have higher empirical cardinality than class labels \u2013 such dissonance could drive more creative solutions that benefit both zero-shot and traditional DL pipelines in solving tabular regression problems."}, {"title": "A. Background", "content": "In this section, we give a brief introduction to PFNs, and specifically the synthetic data generating mechanism of TabPFN. For a more complete description, see M\u00fcller et al. (2021); Hollmann et al. (2022); Nagler (2023). Given training dataset $D_{\\text{train}} = (X_{\\text{train}}, y_{\\text{train}})$ and testing dataset $D_{\\text{test}} = (X_{\\text{test}}, y_{\\text{test}})$, the goal is to approximate the posterior predictive distribution (PPD) $y_{\\text{test}} \\sim p(\\cdot|X_{\\text{test}}, D_{\\text{train}})$. In the Bayesian framework for supervised learning, the prior of the dataset is a hypothesis of the data generating mechanism $\\phi$ drawn from hypothesis space $\\Phi$, and the PPD can be factorized as\n$p(\\cdot|X_{\\text{test}}, D_{\\text{train}}) = \\int_{\\Phi} p(\\cdot, X_{\\text{test}}, \\phi) d\\phi = \\int_{\\Phi} p(\\cdot| X_{\\text{test}}, \\phi) p(\\phi|X_{\\text{test}}, D_{\\text{train}}) d\\phi$ \n$= \\alpha \\int_{\\Phi} p(\\cdot| X_{\\text{test}}, \\phi) \\frac{p(\\phi)p(D_{\\text{train}}|\\phi)p(X_{\\text{test}}|\\phi)}{p(X_{\\text{test}}, D_{\\text{train}})} d\\phi$\n$= \\alpha \\int_{\\Phi} p(\\cdot| X_{\\text{test}}, \\phi) p(D_{\\text{train}}|\\phi) \\frac{p(\\phi)p(X_{\\text{test}}|\\phi)}{p(X_{\\text{test}}, D_{\\text{train}})} d\\phi,$\nPFNs conduct synthetic prior fitting by defining a family of data generating mechanisms $\\Phi$ to draw synthetic datasets $D = D_{\\text{train}}\\cup D_{\\text{test}} \\sim p(D) = E_{p(\\phi)} [p(D|\\phi)]$, and use a transformer model $q_{\\theta}(\\cdot|X_{\\text{test}}, D_{\\text{train}})$ to approximate $p(\\cdot|X_{\\text{test}}, D_{\\text{train}})$.\nThe loss is given by\n$\\mathcal{L}(q_{\\theta}) = E_{p(D)}[-\\log q_{\\theta}(y_{\\text{test}}|X_{\\text{test}}, D_{\\text{train}})]$\nTabPFN in particular, conducts synthetic prior fitting by defining a family of sparsified-random-MLP-based data generating mechanisms $\\Phi$, which we call ordinary data generators in the context of this paper. The following section gives a detailed description of the workflow of these generators."}, {"title": "A.1. Ordinary Data Generator", "content": "To sample data generating mechanism $\\phi \\sim \\Phi$, TabPFN first initializes a random MLP by sampling a collection of hyperparameters from a pre-defined hyperparameter space, including number of layers, hidden size, activation function, dropout probability, noise scales, etc. Specifically, dropout probability is used to sparsify neural connections between neurons, and noise scales dictate the amount of random noise injected into neurons at each layer. After the sparsified noisy random MLP is initialized, TabPFN randomly selects a subset of neurons in this MLP to be predictors $x_i$, and randomly select one neuron to be response $y_i$. With n different random inputs to the MLP, a dataset with n instances of (x, y) is thus generated.\nDiscretization Since generated data are selected neurons from MLPs, their values are naturally continuous. To mimic real-world datasets that possess categorical features and to generate discrete class labels for classification tasks, TabPFN uses a ranking discretization approach that converts a subset of continuous values to discrete by designating certain quantile ranges of the continuous value v to certain categories. A visual demonstration of this conversion can be found on the left side of Figure 6.\nNormalization The generated synthetic data (as well as real-world datasets during inference time) are normalized across samples within each dataset, with the range of the values clipped to four standard deviations. Although the meta-learner might see datasets with unseen fields and out-of-distribution predictor-response relations during inference time, this ensures that at least the range of values will not be out-of-distribution as well."}, {"title": "A.2. Limitations", "content": "Although there is no theoretical limitation on the number of data PFNs can handle, the transformer architecture does entail significant computation complexity and memory usage for large datasets. Besides, given the nature of MLP input embedding layer and MLP final prediction layer, there is a theoretical limitation on the number of features and the number of classes that PFNs can handle. The former is less of an issue since feature selections or simply random sampling of features can be performed, and PFNs would still yield ideal performance as shown in McElfresh et al. 2024. The latter is a rather big problem for classification tasks because there is hardly any direct and effective work-around."}, {"title": "B. Hyperparameter Settings", "content": "All common hyperparameters of APT are directly inherited from TabPFN and not tuned, including learning rate $10^{-4}$, number of blocks 12, hidden dimensions 512, hidden feedforward dimensions 1024, number of heads 4, effective"}]}