{"title": "MAKE INTERVAL BOUND PROPAGATION GREAT AGAIN", "authors": ["Patryk Krukowski", "Daniel Wilczak", "Jacek Tabor", "Anna Bielawska", "Przemys\u0142aw Spurek"], "abstract": "In various scenarios motivated by real life, such as medical data analysis, autonomous driving, and adversarial training, we are interested in robust deep networks. A network is robust when a relatively small perturbation of the input cannot lead to drastic changes in output (like change of class, etc.). This falls under the broader scope field of Neural Network Certification (NNC). Two crucial problems in NNC are of profound interest to the scientific community: how to calculate the robustness of a given pre-trained network and how to construct robust networks. The common approach to constructing robust networks is Interval Bound Propagation (IBP). This paper demonstrates that IBP is sub-optimal in the first case due to its susceptibility to the wrapping effect. Even for linear activation, IBP gives strongly sub-optimal bounds. Consequently, one should use strategies immune to the wrapping effect to obtain bounds close to optimal ones. We adapt two classical approaches dedicated to strict computations \u2013 Dubleton Arithmetic and Affine Arithmetic - to mitigate the wrapping effect in neural networks. These techniques yield precise results for networks with linear activation functions, thus resisting the wrapping effect. As a result, we achieve bounds significantly closer to the optimal level than IBPS.", "sections": [{"title": "1 INTRODUCTION", "content": "Deep neural networks find application in medical data analysis, autonomous driving, and adversarial training (Zhang et al., 2023) where safety-critical and robustness guarantees against adversarial examples (Biggio et al., 2013; Szegedy et al., 2014) are extremely important. The rapid development of artificial intelligence models does not correspond to their robustness (Luo et al., 2024). Therefore, certifiable robustness (Zhang et al., 2022; Ferrari et al., 2022) becomes an important task in deep learning. The aim of Neural Network Certification lies in rigorous validation of a classifier's robustness within a specified input region.\nMost commonly applied certification method is interval bound propagation (IBP) (Gowal et al., 2018; Mirman et al., 2018). It is based on application of interval arithmetic, which allows to propagate the input intervals through a neural network. If in the case of classification tasks such propagation gives an unambiguous output then all elements of the interval inputs are guaranteed to have identical prediction. Therefore, we can control the behavior of predictions of a neural network in an explicit neighborhood of the input data. Among the approaches studied most extensively in robustness of neural networks is Certified Training (Singh et al., 2018; Mao et al., 2024). These certified training methods try to estimate and optimize the worst-case loss approximations of a network across an input domain defined by adversary specifications. They achieve this by computing an over approximation of the network reachable set through symbolic bound propagation techniques (Singh et al., 2019; Gowal et al., 2018). Interestingly, training techniques based on the least accurate bounds derived from interval-bound propagation (IBP) have delivered the best empirical performance (Shi et al., 2021; Mao et al., 2024).\nThe certification process uses the network's upper bound of the propagated input interval. Although classical IBP gives reasonable estimations in robust training, it ultimately fails in the certification of classically trained neural networks. In practice, for a given pre-trained networks, intervals that store intermediate values in a neural network evaluation increase exponentially with respect to number of layers, see Theorem 2.1. This phenomena is known as the wrapping effect (Neumaier, 1993), which"}, {"title": "2 IBP AND WRAPPING EFFECT", "content": "In this section, we examine how interval bounds propagate through a linear layer. We show that the appearance of wrapping effect, even in the case of isometric transformations, leads to an exponential growth of interval bounds. Wrapping effect is typically studied in the context of strict estimations for solutions of dynamical systems, where the propagated set is at each iteration \u201cwrapped\u201d in the minimal interval bound (Neumaier, 1993). Therefore, applying the standard interval bound propagation layer after layer leads to an exponential increase of bounds.\nGiven a bounded set $X \\subset \\mathbb{R}^n$, by $IB(X)$ (interval bounds) we denote the smallest interval bounding box for $X$. The aim of IBP (Interval Bound Propagation) lies in obtaining the IB for the processing of $X$ through a network, i.e. a series of possibly nonlinear maps. In the case of linear map $A = [a_{ij}]$, the optimal bounds are given by\n$IB(A(x + [-r,r])) = Ax + [-|A|r, |A|r]$,\nwhere $x + [-r,r] = \\prod_i[x_i - r_i, x_i + r_i]$ and $|A| = [|a_{ij}|]$. To propagate an interval through the ReLU activation, we propagate the lower and upper bound separately: $ReLU([x, y]) = [ReLU(x), ReLU(y)]$. We can propagate intervals through the standard network $\\Phi$, which is represented as a sequence of mappings corresponding to the successive layers $y = \\Phi(x) = \\phi_k \\circ ... \\circ \\phi_1(x)$. The aim of IBP is to obtain the estimate of $IB(\\Phi(x + [-r, r]))$, where commonly we restrict to the case when $r = \\epsilon \\mathbf{1}$:\n$IB(\\Phi(x + \\epsilon[-1,1]^n)), \\text{ where } \\mathbf{1} = (1, ..., 1) \\in \\mathbb{R}^n$.\nThe standard classical approach used for IBP in the networks uses the naive iterative approach, where we process through each layer the interval bounds obtained from the previous one:\n$[I = x + [-r,r]] \\rightarrow [I^1 = IB(\\phi_1(I))] \\rightarrow [I^2 = IB(\\phi_2(I^1))] \\rightarrow ... \\rightarrow [y = IB(\\phi_k(I^k))]$.\nSince we compute interval bound in each stage, the estimations are far from optimal; see Fig. 1. In practice, wrapping effects appear in neural networks. We will show that intervals grow exponentially, even for linear networks. We consider linear orthogonal ones, as they can be seen as the natural initialization of the deep network (Nowak et al.).\nWe will need the following lemma which proof is given in the Appendix.\nLemma 2.1. Let $V = (V_1, ..., V_n)$ be a random vector uniformly chosen from the unit sphere in $\\mathbb{R}^n$. Let $R$ be a random variable given by $R = |V_1| + ... + |V_n|$. Then\n$E(R) = \\frac{2\\sqrt{n}}{\\sqrt{\\pi}} + O(1/n), V(R) = 1 - \\frac{2}{\\pi} + O(1/n)$.\nNow we will show how a uniform interval bound is processed through an orthogonal map (isometry).\nProposition 2.1. Let $U$ be a randomly chosen orthogonal map in $\\mathbb{R}^n$. Then\n$IB(U([-1,1]^n)) \\approx \\frac{\\sqrt{2}}{\\sqrt{\\pi}}\\sqrt{n} \\cdot ([-1,1]^n + O(1/\\sqrt{n}))."}, {"title": "3 DOUBLETON AND AFFINE ARITHMETICS", "content": "As shown in the previous section, classical interval bound propagation leads to an exponential increase in the bounds, even for the case of most superficial linear networks, which implies that it is suboptimal for pre-trained networks. Consequently, we postulate that we should develop methods that obtain strict estimation in the case of linear networks. In this paper, we propose adapting two Doubleton and Affine Arithmetics models for deep neural networks.\nDoubleton Arithmetics Doubleton is a class of subsets of $X \\subset \\mathbb{R}^n$ that are represented in the following form\n$X = \\{x + Cr + Qq : r \\in \\mathbf{r}, q \\in \\mathbf{q}\\}$,\nfor some $x \\in \\mathbb{R}^n, C \\in \\mathbb{R}^{n \\times m}, Q \\in \\mathbb{R}^{n \\times k}$ and $\\mathbf{r} \\subset \\mathbb{R}^m, \\mathbf{q} \\subset \\mathbb{R}^k$ are interval vectors (product of intervals) containing zero. For a possibly nonlinear function $f : \\mathbb{R}^m \\rightarrow \\mathbb{R}^n$ and a compact set $W \\subset \\mathbb{R}^m$ we use doubletons to enclose range $f(W)$. The component $x + Cr$ is supposed to store linear approximation to $f$, while $Qq$ stores accumulated errors (usually bounds on nonlinear terms) in certain (often orthogonal) coordinate system."}, {"title": "C EXPERIMENTAL SETTING", "content": "Datasets We use the following publicly available datasets: 1) MNIST dataset, consisting of 60,000 training and 10,000 testing $28 \\times 28$ pixel gray-scale images of 10 classes of digits; 2) CIFAR-10 dataset, consisting of 50,000 training and 10,000 testing $32 \\times 32$ colour images in 10 classes; 3) SVHN dataset, consisting of 600,000 $32 \\times 32$ pixel colour images of 10 classes of digits; 4) Digits dataset, consisting of 1797 $8 \\times 8$ pixel gray-scale images of 10 classes of digits.\nArchitectures We use three CNN architectures (small, medium and large) as defined in Table 1 in Gowal et al. (2018). Additionally, we consider an MLP architecture consisting of four hidden layers with 100 neurons per layer. A classification head is added on top of these layers.\nTraining parameters During training, we use the Adam optimizer Kingma & Ba (2017) with the default configuration of $\\beta_1 = 0.9$ and $\\beta_2 = 0.999$, but with different learning rates (lr) across all datasets. We consistently use the ReLU activation function. Whenever a scheduler is mentioned, we apply the MultiStepLR scheduler with a default multiplicative learning rate decay factor set to 0.1. The scheduler steps are applied twice: once after $\\frac{2}{3}$ of the total number of iterations and once after $\\frac{5}{6}$ of the total number of iterations. Additionally, there is a parameter $\\kappa$ scheduled over the entire training process as $\\kappa_i = max\\{1 - 0.00005 \\cdot i, \\kappa_{max}\\}$, where i denotes the current training iteration and $\\kappa_{max}$ is set to 0.5. A perturbation value $\\epsilon$ grows linearly from 0 at the beginning of training to the $\\epsilon_{max}$ hyperparameter value at the midpoint of the total number of iterations. The considered $\\epsilon_{max}$ values are from the set $\\{0.0001, 0.001, 0.01, 0.05, 0.1\\}$ and remain the same regardless of the architecture used. We use 10% of the training samples as the validation set."}]}