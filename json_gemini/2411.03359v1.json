{"title": "Self-Calibrated Tuning of Vision-Language Models for\nOut-of-Distribution Detection", "authors": ["Geng Yu", "Jianing Zhu", "Jiangchao Yao", "Bo Han"], "abstract": "Out-of-distribution (OOD) detection is crucial for deploying reliable machine\nlearning models in open-world applications. Recent advances in CLIP-based OOD\ndetection have shown promising results via regularizing prompt tuning with OOD\nfeatures extracted from ID data. However, the irrelevant context mined from ID\ndata can be spurious due to the inaccurate foreground-background decomposition,\nthus limiting the OOD detection performance. In this work, we propose a novel\nframework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem for\neffective OOD detection with only the given few-shot ID data. Specifically, SCT\nintroduces modulating factors respectively on the two components of the original\nlearning objective. It adaptively directs the optimization process between the two\ntasks during training on data with different prediction uncertainty to calibrate the\ninfluence of OOD regularization, which is compatible with many prompt tuning\nbased OOD detection methods. Extensive experiments and analyses have been\nconducted to characterize and demonstrate the effectiveness of the proposed SCT.\nThe code is publicly available at: https://github.com/tmlr-group/SCT.", "sections": [{"title": "1 Introduction", "content": "The deep neural networks (DNNs) are demonstrated to be overconfident on the OOD data out of\nthe pre-defined label space [Hendrycks and Gimpel, 2017], which can induce severe problems in\nthose safety-critical applications like autonomous driving or medical intelligence. Various explo-\nrations [Liang et al., 2018, Djurisic et al., 2022, Du et al., 2022, Zhu et al., 2023b] thus have been\nconducted in designing scoring functions or fine-tuning methods with auxiliary outliers to improve\nthe OOD distinguishability. Specially, with the emergence of the powerful pretrained vision-language\nmodels (VLMs) [Radford et al., 2021], a series of prompt tuning based methods [Miyai et al., 2024b,\nTao et al., 2023, Bai et al., 2023, Ming et al., 2022c] show impressive performance in current OOD\ndetection benchmarks, with the regularization given only few-shot in-distribution (ID) data.\nGenerally, these regularizations [Wang et al., 2023, Miyai et al., 2024b] are built upon the ID-irrelevant\nlocal context as the surrogate OOD source, which is extracted by VLMs (refer to Figure 1) based on\nits alignment with ID-class text features. Although this saves the costly collection of auxiliary outliers\nfrom the open world, the quality of the ID-irrelevant local context also becomes the bottleneck, which\ncan be greatly affected by the foreground-background decomposition with VLMs. Specifically, as\nrevealed in previous studies [Oh et al., 2023, Tu et al., 2024, Wang et al., 2024], the prevalent VLMs\nstruggle with poor calibration, which means that the decomposition performance on downstream data\nmight not be well guaranteed. Thus, it naturally motivates the following question:\nCan we flexibly leverage the imperfect OOD features extracted by the VLM itself,\nto facilitate the few-shot prompt tuning for effective OOD detection?"}, {"title": "2 Related works", "content": "Prompt tuning for VLMs. The concept of prompt tuning was originally applied in the field\nof natural language processing [Radford et al., 2018]. To eliminate the need for manual prompt\ncrafting, prompt tuning exploits supervision signals from downstream tasks to automate the process\nof prompt generation. Autoprompt [Shin et al., 2020] searches for tokens that cause the greatest\nchanges in gradients based on the label likelihood. Prefix-Tuning [Li and Liang, 2021] introduces\na sequence of continuous vectors that can be end-to-end optimized in the token embedding space.\nIncorporating prompt tuning into computer vision. CoOp [Zhou et al., 2022a] adapts pretrained\nvision-language models by optimizing a set of learnable continuous prompt vectors. Various prompt\ntuning methods [Zhou et al., 2022b, Khattak et al., 2023, Sun et al., 2022] have been subsequently\nproposed to address different vision tasks. However, since these methods are not developed for OOD\ndetection, they face challenges in identifying unknown OOD samples encountered at inference stages.\nOut-of-distribution detection with VLMs. Large pretrained vision-language models have enriched\nthe landscape of OOD detection through their remarkable generalization capability in both visual\nand textual domains. MCM [Ming et al., 2022a] employs the concept of maximum softmax proba-\nbility [Hendrycks and Gimpel, 2017] into the inference process of CLIP for OOD detection, while\nCLIPN [Wang et al., 2023] trains an additional text encoder using and set of prompts with a large\nexternal dataset to improve its negative semantic understanding. Compared with zero-shot methods,\nprompt tuning based approaches achieve better OOD detection with access to few-shot ID training\ndata. LoCoOp [Miyai et al., 2024b] adopts prompt tuning and extracts ID-irrelevant background\nfrom CLIP's local features as surrogate OOD data to regularize the learned prompts. [Bai et al.,\n2023] discovers ID-like outliers from ID samples via random cropping to learn a set of negative\nprompts. However, these two representative prompt learning-based methods suffer from spurious\nOOD features extracted from ID data due to the imperfect foreground-background decomposition of\nVLMs. In addition, LSN [Nie et al., 2023] introduce negative prompts to empower VLMs to learn\nnegative semantics from ID samples while NegPrompt [Li et al., 2024] leverages negative prompts to\ninvestigate the novel setting of open-vocabulary OOD detection."}, {"title": "3 Method", "content": "In this section, we introduce our new framework, i.e., Self-Calibrated Tuning (SCT), which conducts\nadaptive redirection of model learning far away from OOD data region during prompt tuning with only\nthe few-shot ID data. Firstly, we provide preliminaries and notations about prompt tuning based OOD\ndetection (Section 3.1). Secondly, we present and discuss the critical motivation that inspires our\nmethod (Section 3.2). Thirdly, we introduce its newly derived learning objective with the explanation\nand analysis of the underlying intuition and present its algorithmic realization (Section 3.3)."}, {"title": "3.1 Preliminaries", "content": "VLM-based OOD detection aims to identify test samples that do not belong to any ID class designated\nby the downstream tasks [Miyai et al., 2024a]. Therefore, the ID distribution is defined by the ID\nclasses from the downstream tasks, which are different from those of the upstream pretraining.\nFormally, we consider multi-class classification as the original training task [Nguyen et al., 2015],\nwhere X \\subset \\mathbb{R}^d denotes the input space and \\mathcal{Y} = \\{1, ..., M\\} denotes the label space. A reliable\nclassifier should be able to detect the OOD input, which can be considered a binary classification\nproblem. We consider \\mathcal{D}_{in} as the distribution of ID data over pairs of examples x \\in \\mathbb{R}^d and\ncorresponding labels y \\in \\mathcal{Y}. At test time, the environment can present a distribution \\mathcal{D}_{out} over X of\nOOD data. In general, the OOD distribution \\mathcal{D}_{out} is defined as an irrelevant distribution of which the\nlabel set has no intersection with \\mathcal{Y} [Zhu et al., 2023a] and thus should not be predicted by the model\nparameterized by \\theta. A decision model \\Gamma(\\cdot) can be made with the threshold \\mu:\n\\Gamma_\\mu(x; \\theta) = \\begin{cases}\nID & S(x; \\theta) \\geq \\mu\\\\\nOOD & S(x; \\theta) < \\mu\n\\end{cases}"}, {"title": "3.2 Motivation", "content": "Given the only ID data, previous studies propose to extract the ID-irrelevant local context as the\nsurrogate OOD source, which depends on the foreground-background decomposition using CLIP.\nHowever, since the model itself has uncertainty on the prediction results, the correctness of the\ndecomposition cannot always be guaranteed. Thus, as illustrated in Figure 1, the extracted local\nregions based on the prediction of CLIP may result in spurious OOD features, which then limits the\nOOD detection performance. Thus, it naturally motivates the following critical research question:\nHow could we better utilize the surrogate OOD features extracted by imperfect\nforeground-background decomposition of CLIP for effective OOD regularization?"}, {"title": "3.3 Self-calibrated tuning", "content": "As aforementioned, the LoCoOp-based OOD detection paradigm relies on the extracted ID-\nbackground local features for OOD regularization. Given the imperfect foreground-background\ndecomposition, the model is expected to effectively learn from the inaccurate OOD features for better\nOOD detection. Inspired by the previous observation as shown in Section 3.2, one conceptual idea to\nmitigate this problem is to adaptively adjust the importance of OOD regularization generated from\ndifferent ID samples based on uncertainty estimation to alleviate the wrong guidance of invalid OOD\nfeatures. Under this learning paradigm, the model can be regularized by more valid OOD features\nand simultaneously prevent itself from overconfidence to improve OOD detection. To this intuition,\nwe consider reformulating the learning objective under the framework of prompt tuning as follows,\n\\mathcal{L}_{SCT} = \\mathbb{E}_{(x,y)\\sim \\mathcal{D}_{in}} [l_{CE}(p(y|x; \\omega), y) * \\varphi(p(y|x; \\omega)) + \\lambda l_{OOD}(p(X); \\omega) * \\psi(p(y|x;\\omega))],\\newline\nwhere \\varphi : \\mathbb{R}^M \\rightarrow \\mathbb{R} and \\psi : \\mathbb{R}^M \\rightarrow \\mathbb{R} indicate the newly-introduced modulating functions that\ncalculate adaptive factors for the two components of the original loss function (i.e., Eq (3)) of LoCoOp\nbased on the uncertainty estimation. In this loss function, the left part is for the ID classification task,\nand the right part is for the OOD regularization. Specifically, \\varphi should be monotonically decreasing\nand \\psi should be monotonically increasing with respect to p(y|x; \\omega) so that the modulating factors\nshift the focus of prompt learning between the two tasks during the training process.\nIn detail, when the model outputs low-confidence prediction for the ground-truth label, the importance\nof the ID classification task is highlighted in order to better generalize to the downstream task and\nsimultaneously reduce the effect of regularization from invalid OOD features extracted from ID data.\nWhen the model can accurately and confidently classify the ID samples, its attention is redirected\ntowards OOD regularization to strengthen the positive effect of useful ID-irrelevant features for better\nOOD detection. In the meantime, the loss contribution of the classification task is reduced to avoid\nthe model overfitting to the downstream dataset, which benefits the calibration of the model [Mukhoti\net al., 2020] and further enhances the validity of extracted OOD features.\nUnder this learning framework, the goal of confidence calibration and OOD detection can benefit\nfrom each other. This method calibrates the influence of OOD features mined from different ID data\nbased on model prediction confidence during the training process to facilitate capturing more reliable\nOOD features from ID data. Among a wide range of functions that satisfy the simple requirements as\ndiscussed above, we choose the linear function due to its simple design. Concretely, we formulate the\nloss function of SCT as follows,\n\\mathcal{L}_{SCT} = \\mathbb{E}_{(x,y)\\sim \\mathcal{D}_{in}} [l_{CE}(p(y|x; \\omega), y) * (1 - p(y|x; \\omega)) + \\lambda l_{OOD}(p(X); \\omega) * p(y|x;\\omega)],\nThis implementation of \\mathcal{L}_{SCT} introduces no extra hyperparameters and we empirically demonstrate\nits effectiveness in the following experiment section 4. In the Appendix A.3.2, we consider other\ninstantiations of the modulating function and demonstrate that these can be comparably effective.\nExtraction of OOD local features. We adopt the ranking-based method as suggested by Lo-\nCoOp [Miyai et al., 2024b] to extract OOD local features from ID samples for OOD regularization."}, {"title": "4 Experiment", "content": "In this section, we present the comprehensive verification of the proposed SCT in the CLIP-based\nOOD detection scenario. First, we provide the experimental setups in detail (in Section 4.1). Secondly,\nwe provide the performance comparison of our approach with a series of CLIP-based post-hoc\nmethods and prompt tuning based methods (in Section 4.2). Thirdly, we conduct various ablation\nstudies and further discussions to understand our method (in Section 4.3)."}, {"title": "4.1 Experimental setup", "content": "Datasets. Following the common benchmarks used in previous works, we adopt the ImageNet-1K\ndataset [Deng et al., 2009] as the ID data. For OOD datasets, we adopt the same ones as in [Huang"}, {"title": "4.2 Main results", "content": "In this part, we present the major performance comparison with some representative baseline methods\nfor OOD detection to demonstrate the effectiveness of the proposed SCT. Specifically, we consider\nseveral zero-shot methods as the performance reference based on the pretrained CLIP and some\nprompt tuning based methods for specific comparison on fine-tuning with few-shot ID data. Note that\nwe leave the experiment results on 2-shot and 4-shot settings in Appendix A.3.2.\nComparisons on conventional OOD detection In Table 1, we present the overall results of the\ncomparison between different baseline methods and SCT for OOD detection. Since the prompt\ntuning based methods engage the ID data during training, the model will generally gain better\nempirical performance on OOD detection, reflected by evaluation metrics like FPR95 and AUROC.\nIDLike, NegPrompt, and LSN all introduce a set of negative prompts for each ID class to learn\nnegative semantics of ID objects using different strategies, which obtain different levels of detection\nperformance gains. Without sacrificing much classification performance (i.e., ID classification\naccuracy) on ID data, as shown in Table 6, our SCT can consistently achieve better OOD detection\nperformance on the large-scale ImageNet-1k benchmark, which verifies the effectiveness of our\nmethods with the newly proposed modulation factors.\nCompatibility with other baselines. In Table 2, we report the results of compatibility experiments,\nin which we compare those prompt tuning based methods with their variants, incorporating our\nSCT to dynamically adjust the importance of OOD regularization from ID samples with different\nuncertainty levels. We can find that our SCT can consistently help them gain better or comparable\nOOD detection performance across two evaluation metrics while keeping the classification accuracy\ncomparable with the vanilla prompt-tuned model, as shown in Appendix A.3.2.\nComparisons on hard OOD detection. Following the setup in MCM [Ming et al., 2022a], we\nalso explore the performance of SCT on hard OOD detection tasks, as shown in Table 3. SCT\nsignificantly outperforms LoCoOp in all four experimental settings, demonstrating that SCT has\nstrong discriminative power for semantically hard OOD data."}, {"title": "4.3 Ablation study", "content": "In this part, we conduct various ablation experiments and further explorations to provide a thorough\nunderstanding of the characteristics of our proposed SCT. For the extra results and discussions (e.g.,\ncomputational cost and social impact), we leave more details in Appendix A.3.2."}, {"title": "5 Discussions and limitations", "content": "Comparisons with advanced post-hoc methods. Recently, advanced post-hoc ap-\nproaches [Djurisic et al., 2022, Xu et al., 2024] exhibit comparable OOD detection performance to\ntuning based methods, despite the lack of training data. However, prompt tuning based methods can\nleverage the generalization ability of VLMs to better fit the domains of the downstream tasks given\nonly few-shot ID training data. What's more, post-hoc methods and prompt tuning based methods\nare compatible with each other, further boosting the OOD detection performance. We provide more\ndetailed discussions, including empirical experiments, on the compatibility of SCT with advanced\npost-hoc methods in Appendix A.3.2. Furthermore, future research efforts into post-hoc calibration\nmethods for prompt tuning based OOD detection could also contribute to the community."}, {"title": "6 Conclusion", "content": "In this paper, we propose a novel learning framework, i.e., Self-Calibrated Tuning (SCT), that\nimproves the OOD detection capability of VLMs with only the given ID training data. To mitigate\nthe problem caused by invalid OOD features mined from ID data, SCT introduces two modulating\nfactors to the original learning objective to conduct adaptive redirection of prompt tuning process\nbetween the tasks of ID classification and OOD regularization. Through the redirection effect, our\nmethod calibrates the impact of OOD features extracted from different ID samples based on the\nsample uncertainty estimation during the training process, which facilitates the model learning from\nimperfect surrogate OOD features for OOD regularization. We have conducted extensive experiments\nto demonstrate the effectiveness of SCT and its compatibility with a range of prompt tuning based\nmethods, along with various ablation studies and further explorations to characterize the framework."}, {"title": "A Appendix / Supplemental Material", "content": "The whole Appendix is organized as follows. In Appendix A.1, we present the detailed definitions\nand implementation of zero-shot, post-hoc methods and several prompt tuning based methods that\nare considered in our experiments. In Appendix A.3, we provide our extra experimental details\nand more comprehensive results with further discussion on the underlying implications. Finally, in\nAppendix A.4, we discuss the potential broader impact and limitations of our work."}, {"title": "Reproducibility statement", "content": "To ensure reproducibility, we outline several key aspects about the experiments below:\n\u2022 Datasets. The datasets we used are all publicly accessible, which are introduced in Sec-\ntion 4.1.\n\u2022 Open source. The source code is publicly available at https://github.com/\ntmlr-group/SCT. We provide a backbone for our experiments as well as several aux-\niliary components, such as OOD detection performance evaluation.\n\u2022 Environment. All experiments are conducted with multiple runs on NVIDIA GeForce RTX\n3090 GPUs with Python 3.8 and PyTorch 1.12."}, {"title": "A.1 Details about considered baselines", "content": "In this section, we present the details about the baselines, including zero-shot, post-hoc methods, and\nseveral prompt tuning based methods, as well as related hyper-parameters that are considered in our\nwork.\nMSP. Hendrycks and Gimpel [2017] proposes to utilize maximum softmax probability(MSP) as the\nscoring function to differentiate between ID and OOD samples, of which the definition is as follows,\nS_{MSP}(x; f) = \\max_m P(y = m|x; f) = \\max_m \\text{softmax}(f(x))\\newline\nwhere f represents a given well-trained model and m is one of the classes y = \\{1, . . ., M\\}. A higher\nMSP score signifies a greater probability that a sample belongs to the in-distribution distribution,\nindicating the model's confidence on the sample.\nODIN. Liang et al. [2018] designs the ODIN score function, utilizing the temperature scaling and\nminor perturbations to test samples to widen the gap between the distributions of ID and OOD data.\nThe ODIN score is defined as follows,\nS_{ODIN}(x; f) = \\max_m P(y = m|x; f) = \\max_m \\text{softmax}(\\frac{f(\\tilde{x})}{T})\\newline\nwhere \\tilde{x} denotes the perturbed samples (controled by \\epsilon) and T denotes the temperature.\nEnergy. Liu et al. [2020] proposes to use the Energy of the prediction logits to discriminate between\nthe ID and OOD samples. The Energy score is formulated as follows,\nS_{Energy}(x; f) = -T\\log \\sum_{m=1}^M e^{f(x)_m/T}\\newline\nwhere T denotes the temperature parameter. As theoretically proved in Liu et al. [2020], a lower\nEnergy score represents a higher probability for a sample to belong to ID.\nReAct. Sun et al. [2021] designs a simple and effective approaches, named Rectified Activations\n(ReAct), to alleviate model overconfidence on out-of-distribution data. This work observes that\nOOD samples can induce unusually high unit activation in the deep layer of neural networks. ReAct\nimproves OOD detection by simply rectifying the activations at an upper limit c > 0, which can be\nperformed on a pretrained model without any modification to training."}, {"title": "A.2 In-depth comparison between SCT and hard example mining.", "content": "The part of ID classification in the learning framework of SCT bears a strong resemblance to hard\nexample mining methods, such as focal loss [Lin, 2017]. In this section, we clarify the novelty and\ninsights of our SCT by analyzing the difference between SCT and hard example mining as follows.\nConceptually, the motivation of SCT is to mitigate the problem of unreliable OOD features in prompt\ntuning based OOD detection methods. Generally, these methods rely on the ID-irrelevant local\ncontext extracted by VLMs as the surrogate OOD features to perform regularization, the quality of\nwhich is greatly affected by the inaccurate foreground-background decomposition of VLMs. As\nshown in Figure 1 and Figure 5, although VLMs can mask out some ID-related regions (shown as the\ngrey patches of images), large portions of the extracted OOD features (shown as the colored patches\nof images) obviously belongs to ID features.\nEmpirically, we find that the quality of extracted OOD features significantly correlated with the\nuncertainty level of ID data. As illustrated in the left panel of Figure 2, the extracted OOD features\nbecome more inaccurate as the uncertainty increases. In the right panel of Figure 2, we train LoCoOp\non multiple data groups with different uncertainty levels. The results demonstrate that the OOD\ndetection performance of LoCoOp can be significantly impacted by the uncertainty level of ID data.\nTherefore, to mitigate the issue of unreliable OOD features, we propose SCT to calibrate the influence\nof OOD regularization from different ID samples based on their uncertainty level.\nTechnically, despite the simple design, SCT is significantly different from hard sample mining. The\nlatter conducts reweighting directly on the samples based on the classification difficulty during\ntraining. The former adaptively adjusts the importance between the two components of the original\nlearning objectives for every single sample. Data with high uncertainty are directly down-weighted\nin hard sample mining while they are utilized more for OOD regularization in SCT. As shown in\nTable 4, under 16-shot ID data, the OOD detection performance of simply assigning 1-p(y|x) to Lce\n(denoted as \\checkmark and \\psi \\times) are significantly inferior to SCT (denoted as \\checkmark and \\psi \\checkmark), demonstrating\nthe difference of SCT and hard sample mining."}, {"title": "A.3 Additional experimental results and further discussion", "content": "In this section, we provide more experiment results from various perspectives to characterize our\nproposed SCT. First, we introduce the additional experimental setups for the empirical verification in\nprevious figures and our learning framework. Second, we offer more detailed results and analyses\nof our method in comparison to other advanced baselines. Finally, more demonstrations of the\nmotivation of our method are provided."}, {"title": "A.3.1 Additional experimental setups", "content": "Figure 2. In the right panel of Figure 2, we conduct experiments to investigate the relationship\nbetween sample uncertainty and OOD detection performance of prompt tuning based methods. We\nfirst calculate the prediction probability for ground-truth labels of all the training samples in a 64-shot\ntraining set using a prompt-tuned CLIP model. This model is prompt-tuned with LoCoOp on a\n4-shot training set which contains no overlapping samples with the 64-shot set. We use the prediction\nprobability for ground-truth labels to represent uncertainty. High-uncertainty samples are assigned\nlow prediction probability for their ground-truth labels and vice versa. We choose the data with the\nlowest and highest uncertainty for every ID class to generate two data groups of specific shots with\ndifferent uncertainty levels respectively, and train the model with LoCoOp on these two data groups.\nFigure 3. In Figure 3(b), we explore different regularization functions to perform OOD regular-\nization, including entropy maximization [Miyai et al., 2024b], cross-entropy loss to the uniform\ndistribution [Hendrycks et al., 2019, Ming et al., 2022b] and the energy-based function [Liu et al.,\n2020], under the 16-shot setting. In Figure 3(a), Figure 3(c) and Figure 3(d), we train the models\nof all the architectures with 16-shot training datasets. In Figure 3(d), we evaluate the performance\nof SCT with various methods for ID-irrelevant region extraction. To be specific, we consider three\ndifferent methods, including the ranking-based method, probability-based method, and entropy-based\nmethod. Following the setups in [Miyai et al., 2024b], for the entropy-based method, we extract local\nregions where the entropy of p_i(x) is lower than -log M since it is the half value of the maximum\nentropy of M-dimensional probabilities, as done in previous studies [Saito et al., 2020]. For the"}, {"title": "A.3.2 Additional experimental results and illustrations", "content": "Experiments on multiple few-shot settings. In order to further understand the effectiveness of\nour SCT on different few-shot settings, we report the evaluation results of our SCT with 2-shot and\n4-shot training datasets, which are summarized in Table 5. The results demonstrate that SCT can gain\nsignificant improvement on OOD detection under all the few-shot settings.\nID classification performance of baselines and SCT in Table 1 and Table 2. To evaluate the\nperformance of all the considered baselines and SCT on the original classification task, we report\nthe classification accuracy on the ID test set in Table 6. Since NegPrompt and LSN learn positive\nprompts and negative prompts separately, they have the same ID classification performance as vanilla\nCoOp. The results show that SCT maintains comparable ID classification performance compared\nwith vanilla prompt tuning CoOp and other advanced prompt tuning based OOD detection methods\nwhile achieving more effective OOD detection.\nFine-grained results of OOD test dataset for experiments in Table 4. To further evaluate the\ninfluence of both modulating factors introduced in Eq (4) on the performance on every OOD test"}, {"title": "A.3.3 More empirical demonstrations and illustrations of our research problem.", "content": "In this section, we present more empirical evidence and illustrations of the research problem that\ninspires our SCT in Fig 5. As illustrated, portions of the extracted local features from ID data are\ninvalid OOD features, thus degrading the performance of OOD detection."}, {"title": "A.4 Broader impact", "content": "OOD detection is crucial for deploying reliable deep learning systems in real-world scenarios\n[Nguyen et al., 2015, Hendrycks et al., 2022]. This significance is particularly evident in safety-\ncritical domains such as finance or medical intelligence, where a trustworthy model must accurately\ndistinguish between samples belonging to distinct label spaces (e.g., animals) rather than simply\nproviding predictions based on known classes (e.g., financial products or medical conditions). Our\nresearch focuses on a general and practical challenge concerning prompt tuning methods for improving\nOOD detection efficacy. We specifically focus on the issue of spurious OOD features extracted from\nID samples. It is important for effective OOD detection to gain better empirical performance through\nregularizing prompt tuning."}, {"title": "Claims", "content": "Question: Do the main claims made in the abstract and introduction accurately reflect the\npaper's contributions and scope?\nAnswer: [Yes]\nJustification: The main claims made in the abstract and the introduction accurately reflect\nthe paper's contributions and the scope."}, {"title": "Limitations", "content": "Question: Does the paper discuss the limitations of the work performed by the authors?\nAnswer: [Yes]\nJustification: We have discussed the limitations of the work in Section 5."}, {"title": "Theory Assumptions and Proofs", "content": "Question: For each theoretical result, does the paper provide the full set of assumptions and\na complete (and correct) proof?\nAnswer: [NA]"}, {"title": "Experimental Result Reproducibility", "content": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-\nperimental results of the paper to the extent that it affects the main claims and/or conclusions\nof the paper (regardless of whether the code and data are provided or not)?\nAnswer: [Yes]\nJustification: The experimental setups are provided in Section 4.1 to ensure the result\nreproducibility."}, {"title": "Open access to data and code", "content": "Question: Does the paper provide open access to the data and code, with sufficient instruc-\ntions to faithfully reproduce the main experimental results, as described in supplemental\nmaterial?"}, {"title": "Experimental Setting/Details", "content": "Question: Does the paper specify all the training and test details (e.g., data splits, hyper-\nparameters, how they were chosen, type of optimizer, etc.) necessary to understand the\nresults?\nAnswer: [Yes]\nJustification: We provide the detailed experimental setups in Section 4.1 and more discussion\nin Appendix A.1."}, {"title": "Experiment Statistical Significance", "content": "Question: Does the paper report error bars suitably and correctly defined or other appropriate\ninformation about the statistical significance of the experiments?\nAnswer: [Yes]\nJustification: We demonstrate the experimental statistical significance by reporting the mean\nand std value based on multiple trials of the experiments in Tables 1, 2, and other results."}, {"title": "Experiments Compute Resources", "content": "Question: For each experiment, does the paper provide sufficient information on the com-\nputer resources (type of compute workers, memory, time of execution) needed to reproduce\nthe experiments?\nAnswer: [Yes]\nJustification: We provide the details of the used experiment compute resources in the\nreproducibility statement in Appendix."}, {"title": "Code Of Ethics", "content": "Question: Does the research conducted in the paper conform, in every respect, with the\nNeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?\nAnswer: [Yes]\nJustification: The research conducted in the paper conforms, in every respect, with the\nNeurIPS Code of Ethics."}, {"title": "Broader Impacts", "content": "Question: Does the paper discuss both potential positive societal impacts and negative\nsocietal impacts of the work performed?\nAnswer: [Yes]\nJustification: We discuss the potential positive and negative societal impacts of the work in\nAppendix A.4."}, {"title": "Safeguards", "content": "Question: Does the paper describe safeguards that have been put in place for responsible\nrelease of data or models that have a high risk for misuse (e.g., pretrained language models,\nimage generators, or scraped datasets)?\nAnswer: [NA]\nJustification: This paper poses no such risks."}, {"title": "Licenses for existing assets", "content": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in\nthe paper, properly credited and are the license and terms of use explicitly mentioned and\nproperly respected?\nAnswer: [Yes]\nJustification: The creators or original owners of the datasets and referred codes are properly\nmentioned in the references and their credits are properly respected."}, {"title": "New Assets", "content": "Question: Are new assets introduced in the paper well documented and is the documentation\nprovided alongside the assets?\nAnswer: [NA]\nJustification: This paper does not release new assets."}, {"title": "Crowdsourcing and Research with Human Subjects", "content": "Question: For crowdsourcing experiments and research with human subjects, does the paper\ninclude the full text of instructions given to participants and screenshots, if applicable, as\nwell as details about compensation (if any)?\nAnswer: [NA]\nJustification: This paper does not involve crowdsourcing nor research with human subjects."}, {"title": "Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects", "content": "Question: Does the paper describe potential risks incurred by study participants, whether\nsuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)\napprovals (or an equivalent approval/review based on the requirements of your country or\ninstitution) were obtained?\nAnswer: [NA]\nJustification: This paper does not involve crowdsourcing nor research with human subjects."}]}