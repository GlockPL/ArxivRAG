{"title": "Revisiting Essential and Nonessential Settings of Evidential Deep Learning", "authors": ["Mengyuan Chen", "Junyu Gao", "Changsheng Xu"], "abstract": "Evidential Deep Learning (EDL) is an emerging method for uncertainty estimation that provides reliable predictive uncertainty in a single forward pass, attracting significant attention. Grounded in subjective logic, EDL derives Dirichlet concentration parameters from neural networks to construct a Dirichlet probability density function (PDF), modeling the distribution of class probabilities. Despite its success, EDL incorporates several nonessential settings: In model construction, (1) a commonly ignored prior weight parameter is fixed to the number of classes, while its value actually impacts the balance between the proportion of evidence and its magnitude in deriving predictive scores. In model optimization, (2) the empirical risk features a variance-minimizing optimization term that biases the PDF towards a Dirac delta function, potentially exacerbating overconfidence. (3) Additionally, the structural risk typically includes a KL-divergence-minimizing regularization, whose optimization direction extends beyond the intended purpose and contradicts common sense, diminishing the information carried by the evidence magnitude. Therefore, we propose Re-EDL, a simplified yet more effective variant of EDL, by relaxing the nonessential settings and retaining the essential one, namely, the adoption of projected probability from subjective logic. Specifically, Re-EDL treats the prior weight as an adjustable hyperparameter rather than a fixed scalar, and directly optimizes the expectation of the Dirichlet PDF provided by deprecating both the variance-minimizing optimization term and the divergence regularization term. Extensive experiments and state-of-the-art performance validate the effectiveness of our method. The source code is available at https://github.com/MengyuanChen21/Re-EDL.", "sections": [{"title": "INTRODUCTION", "content": "In high-risk domains such as autonomous driving and medical analysis, it is imperative for models to reliably convey the confidence or uncertainty level of their predictions [1], [2]. Despite effective uncertainty quantification methods based on Bayesian theory and ensemble techniques have been developed, these mainstream methods necessitate multiple forward passes in the inference phase [3]\u2013[8], imposing substantial computational burdens that hamper their widespread industrial adoption. This limitation drives the interest of researchers in exploring how to achieve high-quality uncertainty estimation with minimal additional cost.\nEvidential deep learning (EDL) [9] is such a newly arising single-forward-pass uncertainty estimation method, which has attracted increasing attention for its success in various pattern recognition tasks [10]\u2013[18]. Drawing upon the subjective logic theory [19], [20], EDL employs deep neural networks to derive Dirichlet concentration parameters, constructing a Dirichlet distribution that models the distribution of class probabilities and enables high-quality uncertainty estimation. Specifically, in C-class classification, EDL models the distribution of class probability px with a constructed Dirichlet distribution $Dir(p_x, \\alpha_x)$, whose concentration parameter vector $\\alpha_x(x)$ is given by\n$\\alpha_x(x) = e_x(x)+C\\frac{\\alpha}{C}, \\forall x \\in X = \\{1, 2, ..., C\\}$,                                                                                                                                                   (1)\nwhere the base rate \u03b1 is typically set as a uniform distribution over X, and its scalar coefficient C serves as a parameter termed as a prior weight. Note that to keep the notation uncluttered, we use $\\alpha_x(x)$ as a simplified expression of $\\alpha_x(X = x)$, and similarly for $e_x(x)$ and $\\alpha_x (x)$. The random variable X denotes the class index of the input sample, and $e_x(x)$ signifies the amassed evidence for the sample's association with class x. Thereafter, for model optimization, the traditional EDL method integrates the mean square error (MSE) loss over the class probability $p_x$, which is assumed to follow the above Dirichlet distribution, thus deriving the empirical risk (average loss over training samples) as\n$L_{edl-emp} = \\frac{1}{D} E_{p_x\\sim Dir(p_x,\\alpha_x)}[||Y - Px ||^2] = \\frac{1}{D}\\sum_{(z,y) \\in D}\\sum_{x\\in X} (Y_x - E_{p_x\\sim Dir(p_x,\\alpha_x)}[p_x(x)])^2 + Var_{p_x\\sim Dir(p_x,\\alpha_x)}[p_x(x)]$,                                          (2)\nwhere the training set D consists of sample features and their one-hot labels denoted $(z, y)$, and $y_x$ refers to the x-th element of y. In addition, the structural risk (loss with extra regularization to mitigate over-fitting) of EDL-related methods typically include an additional regularization $L_{kl}$,\n$L_{kl} = \\frac{1}{D}\\sum_{(z,y) \\in D} D_{KL} (Dir(p_x, \\alpha_x), Dir(p_x, 1))$,                                                                                     (3)\nwhere 1 denotes a C-dimensional ones vector, and $\\tilde{\\alpha_x} = y + (1 - y) \\odot \\alpha_x$ represents a modified Dirichlet parameter"}, {"title": "RELATED WORK", "content": "Theoretical Extensions of EDL. A comprehensive introduction to EDL [9] is provided in Section 3.2. Here, we offer a brief overview of the subsequent developments of EDL. Early research primarily focuses on enhancing the model's uncertainty estimation capabilities by incorporating additional OOD samples. For instance, [22] employs generative models to obtain proximal OOD samples, using"}, {"title": "PRELIMINARY: FROM SUBJECTIVE LOGIC TO EVIDENTIAL DEEP LEARNING", "content": "The essence of Evidential Deep Learning (EDL) lies in employing DNNs as analysts within the framework of subjective logic. In this section, we briefly introduce core concepts of subjective logic theory (Section 3.1), and outline the primary steps involved in developing EDL (Section 3.2). This introduction aims to differentiate between the fundamental theoretical requirements and the optional practical implementations, facilitating the subsequent discussion on the essential and nonessential settings of EDL (Section 4)."}, {"title": "Subjective Logic Theory", "content": "Just as the names of binary logic and probabilistic logic imply, an argument in binary logic must be either true or false, and while probabilistic logic allows for probabilities within the range [0, 1] to express partial true. However, both binary logic and probabilistic logic deal with definite arguments and do not provide a mechanism to express uncertainty or indifference, such as saying \u201cI don't know\u201d. To address this limitation, subjective logic [19], [20] extends probabilistic logic by explicitly including uncertainty about probabilities in the formalism. Specifically, an argument in subjective logic, also called a subjective opinion, is formalized as follows:\nDefinition 1 (Subjective opinion). Given a categorical random variable X on the domain X, a subjective opinion over X is defined as the ordered triplet $w_x = (b_x, u_x, a_x)$, where $b_x$ is a belief mass distribution over X, $u_x$ is a uncertainty mass, $a_x$ is a base rate, aka a prior probability distribution over X, and the additivity requirements $\\sum_{x\\in X}b_x(x) + u_x = 1$ and $\\sum_{x\\in X} a_x (x) = 1$ are satisfied.\nBelief mass $b_x(x)$ assigned to a singleton value $x \\in X$ expresses support for the statement $X = x$ being TRUE, and uncertainty mass can be interpreted as belief mass assigned to the entire domain. Therefore, subjective logic also provides a well-defined projected probability, which follows the additivity requirement of traditional probability theory, by reassigning the uncertainty mass into each singleton of domain X according to the base rate $a_x$ as follows:\nDefinition 2 (Projected probability). The projected probability $P_x$ of the subjective opinion $w_x = (b_x, u_x, a_x)$ is defined by $P_x (x) = b_x(x) + a_x(x)u_x, \\forall x \\in X$. Note that the additivity requirement $\\sum_{x\\in X}P_x(x) = 1$ is satisfied.\nFurthermore, the subjective logic theory points out that, if the base rate $a_x$ and a parameter termed prior weight, denoted as W, is given, there exists a bijection between a"}, {"title": "Evidential Deep Learning", "content": "Based on subjective logic, [9] proposes a single-forward-pass uncertainty estimation method named Evidential Deep Learning (EDL), which lets deep neural networks play the role of analysts to give belief mass and uncertainty mass of samples. For example, in C-class classification, the belief mass $b_x$ and uncertainty mass $u_x$ of the input sample, whose category index is a random variable X taking values x from the domain $X = [1, ..., C]$, are given by\n$b_x (x) = \\frac{e_x (x)}{S_x},  u_x = \\frac{C}{S_x} = \\frac{C}{\\sum_{x\\in X}e_x(x) + C}$.                                                                                                                                                                                                                                                                                                                                                                                                                      (6)\nSpecifically, $e_x(x)$, which denotes the evidence of the random variable X taking the value x, is the x-th element of the evidence vector $e_x = f(g(z)) \\in \\mathbb{R}^C$, where z is the feature of the input sample, g is a deep neural network, \u0192 is a non-negative output activation function (e.g., softplus), sometimes also called evidence function, and the scalar C in this equation serves as the prior weight.\nAccording to Theorem 1, there exists a bijection between the Dirichlet PDF denoted $Dir_x(p_x, \\alpha_x)$ and the opinion $w_x = (b_x, u_x, a_x)$ if the requirement in Eqn. 5 is satisfied. Substituting Eqn. 6 into Eqn. 5 and setting the prior weight W in Eqn. 5 as C, we obtain the relationship between the parameter vector of the Dirichlet PDF and the collected evidence in EDL, as expressed by Eqn. 1. Moreover, since EDL sets the base rate $a_x (x)$ as a uniform distribution, the relationship given by Eqn. 1 can be further simplified into $\\alpha_x(x) = e_x(x) + 1, \\forall x \\in X$.\nTo perform model optimization, EDL integrates the MSE loss function over the class probability $p_x$ which is assumed to follow the Dirichlet PDF specified in the bijection, thus derives the empirical risk given by Eqn. 2. Moreover, the structural risk of EDL-related methods typically includes"}, {"title": "RE-EDL: REVISIT ESSENTIAL AND NONESSENTIAL SETTINGS OF EDL", "content": "Despite the significant success of EDL, we argue that the existing EDL-based methodologies (Section 3.2) retain several rigid settings, which, while widely accepted, are not intrinsically mandated within subjective logic (Section 3.1) and typically offer minimal benefit to uncertainty quantification. Specifically, in this section, we identify the following nonessential EDL settings: In model construction, (1) a prior weight parameter is fixed to the number of classes, suppressing the model's ability to adjust the impact of evidence magnitude and its proportion on predictions (Section 4.1);\nIn model optimization, (2) for the empirical risk (average loss over training samples), traditional EDL adopts the expected value of the MSE loss over the constructed Dirichlet distribution rather than directly applying MSE to the expected value of the Dirichlet distribution. This results in an additional variance-minimizing term, which exacerbates overconfidence. (Section 4.2); (3) For the structural risk (loss with extra regularization terms), a commonly adopted KL-Div-minimizing regularization on non-target evidence limits model's complexity but hampers uncertainty estimation in most situations (Section 4.3). After relaxing the above nonessential EDL settings while strictly adhering to subjective logic, we further provide an in-depth discussion about the truly essential EDL settings which contribute to the superior uncertainty estimation capability (Section 4.4)."}, {"title": "Relaxing the Rigid Setting of Fixing Prior Weight in Model Construction", "content": "In this subsection, we elucidate how the prior weight W balances between leveraging the proportion and magnitude of evidence to compute predictive scores. Conclusively, we argue against the rigidity of fixing W to the class number and propose viewing it as an adjustable hyperparameter.\nThe nomenclature of prior weight comes from the expression of Eqn. 1. The scalar coefficient C, functioning as the prior weight W, denotes the weight of the base rate $a_x$, which is alternatively termed the prior distribution. In Theorem 1, it should be noted that the bijection between subjective opinions and Dirichlet PDFs is only specified when the base rate $a_x$ and the prior weight W are given. Typically, in the absence of prior information, we default to setting the base rate as a uniform distribution over the domain X, i.e., $a_x(x) = 1/|X| = 1/C, \\forall x \\in X$. However, the setting of the prior weight W is worth further discussion.\nWe argue that fixing the prior weight to the cardinality of the domain, which is widely adopted by EDL researchers, is not intrinsically mandated by subjective logic and may result in counter-intuitive results. For example, a"}, {"title": "Deprecating the Variance-minimizing Optimization Term in Empirical Risk", "content": "With the above generalized form of the concentration parameter, this subsection elaborates on our simplified EDL empirical risk, which directly optimizes the expectation of the constructed Dirichlet distribution, i.e., the projected probability $P_x$. In contrast, traditional EDL uses the MSE loss's expectation over the Dirichlet distribution as empirical risk, resulting in an additional variance-minimizing optimization term that potentially exacerbates overconfidence. With the generalized setting of $\\alpha_x$ in Eqn. 10, the projected probability $P_x$ has the following variant:\n$P_x (x) = \\frac{\\alpha_x (x)}{S_x} = \\frac{e_x(x) + \\lambda}{\\sum_{x'}e_x(x') + C\\lambda}, \\forall x \\in X$.                                                                                                                                                                                                                                                        (11)\nConsequently, by substituting the class probability in traditional MSE loss with the projected probability $P_x$ in Eqn. 11, we seamlessly derive our empirical risk denoted $L_{re-edl-emp}$:\n$L_{re-edl-emp} = \\frac{1}{D}\\sum_{(z,y) \\in D}\\sum_{x\\in X} (y_z \u2013 P_x(x))^2$.                                                                                                                                                                                                                                                                                                                                                                                                                                                      (12)\nRegarding the reason for adopting this formulation, we contend that the projected probability $P_x$ has the unique property of alleviating the overconfidence typically arising from optimization toward the hard one-hot labels y. As previously noted, the projected probability $P_x$ harnesses both the magnitude and proportion of collected evidence to more accurately represent the actual likelihood of a given output. From an optimization perspective, compared to the proportion of evidence among classes, i.e., $e_x(x)/\\sum_xe_x(x)$, or the belief mass $b_x$, the projected probability $P_x$ has more tolerance towards the existence of the uncertainty mass $u_x$, since $u_x$ also contributes to the projected probability $P_x$ according to the base rate $a_x$. In other words, the item $a_xu_x$ alleviates the urgency of the projected probability $P_x$ tending to the one-hot label y when the model has not collected enough evidence, since the uncertainty mass $u_x$ is inversely proportional to the total amount of evidence, thus mitigating the over-confidence issue to some extent.\nMeanwhile, Eqn. 12 can be interpreted as encouraging the expectation of the Dirichlet distribution to converge to the provided label, since the bijection introduced in Theorem 1 has been established on the following identity:\n$P_x(x) = E_{p_x\\sim Dir(p,a)} [P_x(x)]$,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (13)"}, {"title": "Delving into KL-divergence-minimizing Regularization on Non-target Evidence in Structural Risk", "content": "Originating from the pioneer work [9], a Kullback-Leibler (KL) divergence-minimizing regularization is commonly incorporated into the structural risk of EDL-related methods [12], [29], [44], [46], [53]\u2013[55], [77]\u2013[80], suppressing the evidence for non-target classes. While this regularization can marginally improve classification accuracy with a carefully tuned coefficient and enhance generalization on noisy data, we regard it as nonessential, since it is not mandated by subjective logic and typically brings minimal benefit on uncertainty estimation. In this subsection, we initially present the vanilla form of this regularization and its variant with our relaxation proposed in Section 4.1, and then offer an analysis of both the optimization direction and practical impact, supported by experimental results.\nIn the traditional EDL method, after the target class value of the Dirichlet parameter vector being set to 1, the KL divergence between the modified Dirichlet distribution and a uniform distribution is expected to be minimized by an auxiliary regularization, which has the following form:\n$L_{kl} = \\frac{1}{D}\\sum_{(z,y) \\in D}KL (Dir(p_x, \\alpha_x), Dir(p_x,1))$,                                                                                                                                                                                                                                                                                                                                                                                                                                                                    (15)\nwhere 1 denotes a C-dimensional ones vector, and $\\tilde{\\alpha_x} = y + (1 - y) \\odot a_x$ represents the modified Dirichlet parameter"}, {"title": "What are the Essential Settings of EDL?", "content": "In Section 4.1, we challenge the rigidity of fixing the prior weight to the class number, advocating instead for treating it as an adjustable hyperparameter. In Section 4.2, we propose a simplified empirical risk by deprecating a variance-minimizing optimization term in the traditional EDL loss. In Section 4.3, we analyze the disadvantages of the commonly used KL-Div-minimizing regularization on non-target evidence. With these relaxations, our EDL variant, Re-EDL, simply optimizes the expectation of the constructed Dirichlet distribution, also known as the projected probability, using the given one-hot labels, without any additional regularization. The impressive simplicity of the Re-EDL formulation naturally leads to a fundamental question: What is the essential EDL setting that contributes to its uncertainty estimation capability?\nOur experiments shows that, simply replacing the traditional softmax probability with the projected probability in traditional CE and MSE loss functions results in obvious improvements (> 4%) in OOD detection performances (refer to Table 11). Therefore, in this subsection, we argue that the adoption of the projected probability is the essential setting of EDL, and delve into its differences with the traditional softmax probability. For the convenience of following discussion, we first present their formulations here:\n$Softmax Probability_x = \\frac{exp(l_x)}{\\sum_{x'\\in X}exp(l_{x'})}$.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (17)"}, {"title": "EXPERIMENTS", "content": "5.1 Experimental Setup\nBaselines. Following [29], we focus on comparing with other Dirichlet-based uncertainty methods, including the traditional EDL [9], 1-EDL [29], RED [28], R-EDL [21], PostN [75], and NatPN [76]. Additionally, we present the results of the representative single-forward-pass method\nDUQ [71], the popular Bayesian uncertainty method MC Dropout [5], and the Deep Ensemble [6] method using\n5 and 25 model instances for reference. For experiments concerning video-modality data, following [11], we compare our methods with: OpenMax [82], MC Dropout, BNN\nSVI [83], RPL [84], and DEAR [11].\nDatasets. Refer to Appendix B.2 for a detailed introduction.\n5.2 Implementation Details\nClassical setting. Six datasets (i.e., SVHN [85], CIFAR-100 [86], GTSRB [87], LFWPeople [88], Places365 [89], Food-101 [90]) are utilized as OOD data for CIFAR-10, while FMNIST [91] and KMNIST [92] are used for MNIST. In alignment with [29], [75], VGG16 serves as the backbone network for CIFAR-10, and a ConvNet with three convolutional and three dense layers is employed for MNIST. Softplus is adopted as the evidence function. The Adam optimizer is employed with a learning rate of $1 \\times 10^{-4}$ for CIFAR-10, and a learning rate of $1 \\times 10^{-3}$, decaying by 0.1 every 15 epochs for MNIST. The hyperparameter $\\lambda$ is set to 0.8 and 0.1 for CIFAR-10 and MNIST, which is selected from the range [0.1:0.1:1.0] on the validation set. The batch size is set to 64, and the training epoch is set to 200 and 60 for CIFAR-10 and MNIST. Reported results are averaged over 5 runs.\nFew-shot setting. Following [29], we adopt a pre-trained WideResNet-28-10 network from [93] to extract features and"}, {"title": "Few-shot Setting", "content": "Next, we conduct more challenging few-shot experiments on mini-ImageNet to further demonstrate the effectiveness of our method. As shown in Table 5, we report the averaged top-1 accuracy of classification and the AUPR scores of confidence estimation and OOD detection over 10,000 few-shot episodes. As depicted in Table 5, R-EDL and Re-EDL achieve satisfactory performances on most N-way K-shot settings. Specifically, comparing with the EDL and I-EDL methods, R-EDL obtains absolute gains of 9.19% and 1.61% when evaluated by MP on OOD detection of the 5-way 5-shot task. However, in this setting, Re-EDL fail to achieve further improvements over R-EDL as it does in the classical setting and subsequent video-modality setting. We speculate that this may be because few-shot tasks demand stronger generalization capabilities due to the limited amount of training data. Consequently, the improvement in generalization brought about by the KL-Divergence-minimizing regularization compensates for the performance loss it otherwise causes. However, after deprecating this regularization, our simpler Re-EDL still achieves performances comparable to those of R-EDL in the few-shot setting, which also suggests that the regularization is not an essential EDL setting."}, {"title": "Video-modality Setting", "content": "We also assess our approach using video-modality samples [11], [99], specifically on the open-set action recognition task. Following [11], we train models on UCF-101 training split and use the testing splits of HMDB-51 and MiT-v2 datasets as unknown sources. Given that the SOTA method DEAR is predicated on EDL, we substitute its EDL implementation with our R-EDL and Re-EDL version. As evidenced by Table 7, this modification yields enhanced performance, substantiating the efficacy of our methods."}, {"title": "Noisy Setting", "content": "In Section 4.3, we argue that the regularization Lkl constrains the magnitude of model outputs within a narrower range, thereby reducing complexity and mitigating overfitting to some extent. Although Lkl typically has a negative effect in experiments across the classical and video-modality settings, it exhibits strong generalization capabilities when tested on noisy data. Specifically, we introduce zero-mean isotropic Gaussian noise into the test split of the ID dataset to generate noisy samples. Table 6 presents the classification accuracy and the AUPR scores for noisy detection across varying levels of Gaussian noise on CIFAR-10. As indicated in Table 6, R-EDL significantly outperforms both EDL and I-EDL across nearly all noise levels, with its advantages becoming more pronounced as the noise intensity increases. However, the performance of Re-EDL, which omits the KL-Div-minimizing regularization, generally falls below that of R-EDL. This observation suggests that Lkl equips R-EDL with superior generalization abilities, enabling it to collect reliable evidence from noisy data, thereby leading to enhanced performances. Nonetheless, Re-EDL still maintains superior performances compared to both EDL and I-EDL."}, {"title": "Parameter Analysis", "content": "Hyperparameter \u5165 in projected probability. We further investigate the effect of the hyperparameter \u5165. Fig. 3 presents the trend of variation in the average AUPR score for OOD detection on six OOD datasets as the hyperparameter \u5165 varies from 0.02 to 1.3. The observations reveal findings"}, {"title": "Ablation Study", "content": "Nonessential EDL settings. As summarized in Table 9, we evaluate the performance impact of relaxing individual or combined instances of the three nonessential EDL settings. These settings are denoted as follows: (1) \u5165 = 1: the rigid setting of fixing prior weight to the number of classes, as"}, {"title": "CONCLUSION", "content": "Summary. We propose Re-EDL, a simplified yet more effective version of EDL, achieved by revisiting the essential and nonessential settings of the traditional method. Our analysis yields insights in two key aspects. On one hand, we identify the nonessential settings in traditional EDL, which include: (1) Fixing the prior weight parameter, which governs the balance between leveraging the proportion of evidence and its magnitude in deriving predictive scores, to the number of classes; (2) The empirical risk of EDL includes a variance-minimizing optimization term which encourages the Dirichlet PDF to approach a Dirac delta function, thereby heightening the risk of model overconfidence; (3) EDL's structural risk adopts a KL-Div-minimizing regularization on non-target evidence, which extends its effect beyond the intended purpose and contradicts common sense, hindering uncertainty estimation in most cases.\nOn the other hand, we identify the essential setting of EDL as the adoption of projected probability, which more effectively preserves the magnitude information of logits than the traditional softmax probability, thereby enhancing uncertainty estimation. Building on these insights, Re-EDL treats the prior weight as an adjustable hyperparameter instead of fixing it to the class number, and directly optimizes the expectation of the Dirichlet PDF, phasing out both the variance-minimizing optimization term and the regularization on non-target evidence. Comprehensive experimental evaluations underscore the efficacy of our method.\nDeficiencies and Future directions. This paper can be extended along several directions below. (1) While the crucial role of the prior weight in balancing the trade-off between leveraging the evidence proportion and the magnitude has been elucidated, the underlying mechanism dictating its optimal value warrants further investigation. (2) The optimization objective of Re-EDL can be interpreted as optimizing the expected value of the constructed Dirichlet PDF. While principled and effective, it is somewhat coarse. Future work could explore optimization goals considering other statistical properties of Dirichlet PDFs. (3) Although Re-EDL deprecates the traditional KL-Div-minimizing regularization, experiments still validate its benefits in certain aspects. Exploring regularization that simultaneously enhances generalization and uncertainty estimation is worthwhile. In brief, we anticipate that Re-EDL, with its impressive simplicity, can establish a new baseline facilitating the single-forward-pass uncertainty quantification research."}, {"title": "APPENDIX A", "content": "PROOF AND DERIVATION\nThis section provides the proof of Theorem 1 and the derivation of optimization objectives of EDL."}, {"title": "Proof of Theorem 1", "content": "Theorem 1 (Bijection between subjective opinions and Dirichlet PDFs). Let X be a random variable defined in domain X", "ax)": "n$F : w_x = (b_x", "1": "To prove the mapping F\u2081 : ax \u2192 Dir(px", "2": "To prove the bijection between $w_x$ and $\\alpha_x$", "F_2": "w_x \\rightarrow \\alpha_x$ is both injective and surjective. Since the base rate ax and the non-informative prior weight W in Eqn. 20 are given", "formulation": "n$\\alpha_x(x) = \\frac{b_x(x)"}, {"formulation": "n$\\sum_{x\\in X}\\alpha_x(x) = \\frac{1-u_x}{u_x}$,                                                                                                                                                                                                    (28)\nwhere $S_x = \\sum_{x\\in X} \\alpha_x(x)$. By reorganization and substituting ux into Eqn. 25, we"}]}