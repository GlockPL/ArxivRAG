{"title": "A Spatio-temporal Graph Network Allowing Incomplete Trajectory Input for Pedestrian Trajectory Prediction", "authors": ["Juncen Long", "Gianluca Bardaro", "Simone Mentasti", "Matteo Matteucci"], "abstract": "Pedestrian trajectory prediction is important in the research of mobile robot navigation in environments with pedestrians. Most pedestrian trajectory prediction algorithms require the input historical trajectories to be complete. If a pedestrian is unobservable in any frame in the past, then its historical trajectory become incomplete, the algorithm will not predict its future trajectory. To address this limitation, we propose the STGN-IT, a spatio-temporal graph network allowing incomplete trajectory input, which can predict the future trajectories of pedestrians with incomplete historical trajectories. STGN-IT uses the spatio-temporal graph with an additional encoding method to represent the historical trajectories and observation states of pedestrians. Moreover, STGN-IT introduces static obstacles in the environment that may affect the future trajectories as nodes to further improve the prediction accuracy. A clustering algorithm is also applied in the construction of spatio-temporal graphs. Experiments on public datasets show that STGN-IT outperforms state of the art algorithms on these metrics.", "sections": [{"title": "I. INTRODUCTION", "content": "Many pedestrian trajectory prediction algorithms tried to help robots navigate in human-robot coexistence environments, from the early algorithms based on Bayesian filtering to the later algorithms based on recurrent neural networks (RNNs) and spatio-temporal graphs [1]\u2013[5]. Almost all existing algorithms use average displacement error (ADE) and final displacement error (FDE) as metrics. Furthermore, when a pedestrian is unobservable in any frame in the past, its historical trajectory is called as an incomplete trajectory, and these algorithms will not predict the future trajectory of this pedestrian.\nAlthough many pedestrian trajectory prediction algorithms have achieved excellent ADE and FDE, most of them are trained and evaluated on datasets with top-down views such as ETH [6], UCY [7], and SDD [8]. However, the mobile robot usually obtains egocentric vision and local LIDAR maps, rather than a top-down view image. As shown in Fig. 1, pedestrians are unlikely to be obscured in the top-down view, but it is very common in the egocentric view, which means that incomplete trajectories have a greater impact on algorithms in egocentric view datasets than in top-down view datasets.\nAs shown in Fig. 2a, the historical trajectory of pedestrian 1 is incomplete, and the historical trajectory of pedestrian 2 is complete, while a robot may collide with pedestrian 1. The prediction mode of almost all existing algorithms, the filtration mode (Fig. 2b), only predicts the trajectory of pedestrian 2. And the pad mode represents the pedestrian's position as (0,0) when it is obscured and then predicts its trajectory (Fig. 2c). In this case, the FDE in filtration mode is less than that in pad mode, as it avoids the difficult prediction of incomplete trajectories. However, the pad mode is safer than the filtration mode as its prediction can indicate a possible collision for the robot. Therefore, it is more ideal to use pad mode and evaluate the performance of algorithms in pad mode.\nFor pad mode in Fig. 2, it can be misinterpreted by algorithms that the pedestrian has moved from its original position to the position (0,0). Through experiments, we find that this misinterpretation can reduce the performance of algorithms.\nTo address the limitations of existing algorithms in dealing with incomplete historical trajectories, we designed a spatio-temporal graph network allowing incomplete trajectory input (STGN-IT) to predict the future trajectories of pedestrians. As shown in Fig. 3, STGN-IT obtains static obstacle information from the occupancy grid map, which can be automatically generated by the point cloud data. Thus, STGN-IT is more flexible than algorithms using semantic maps, which need to be manually labeled. In addition, STGN-IT uses spatio-temporal graphs to represent pedestrian and obstacle information and uses an encoding method to cope with the incomplete parts of historical trajectories. We evaluate our algorithm and compare it with state of the art algorithms on the public dataset STCrowd (STC) [9].\nThe main contributions of this article are as follows.\n1) We designed STGN-IT, combining with a special encoding method, graph convolutional networks, and GRU networks. STGN-IT can predict the future trajectory of pedestrians with incomplete historical trajectories and occupancy grid maps, which makes it more suitable for robot navigation.\n2) We verify that the incomplete trajectories can seriously affect the performance of the existing algorithms by experiments, and propose an encoding method to reduce the performance degradation.\nThe paper is structured as follows; in Section 2, we present an overview of pedestrian trajectory prediction algorithms and datasets, focusing on available datasets and algorithms used for this task. In Section 3.A, we formulate the problem. From Section 3.B, we present the STGN-IT algorithm with its pipeline for prediction in detail. In Section 4, we compare quantitatively and qualitatively the performance of different algorithms in different prediction modes with the ablation study."}, {"title": "II. RELATED WORKS", "content": "Datasets for pedestrian trajectory prediction have different perspectives. In top-down view datasets, ETH [6] and UCY [7] are used most frequently, and in recent years, SDD [8] has become popular, which has more data and complex environments. In egocentric view datasets, KITTI [10] and BDD100K use [11] sensors carried on vehicles, while FPL [12], SiT [13], and STC [9] use sensors carried by small robots or pedestrians. In the STC dataset, the sensors are carried on a static bracket, which makes it easier to model the impact on pedestrian trajectories.\nThere are many existing algorithms based on long short-term memory (LSTM) networks [14] for trajectory prediction [15]\u2013[17]. Given that the gated recurrent unit (GRU) [18] has fewer parameters and similar performance to LSTM, some algorithms utilize GRU to predict trajectories [19], [20]. Some algorithms also use encoder-decoder structures to improve the performance [21]. Social-VRNN [22] and Social-BiGAT [23] use the encoder-decoder model and encode social interaction condition about pedestrians. A distribution discrimination method based on the encoder-decoder model, DisDis [24], was proposed to learn the behavior pattern of each person.\nConsidering that interactions between pedestrians may occur at the end of the trajectories, some algorithms started to use the bidirectional LSTM and bidirectional GRU to extract trajectory features [25]\u2013[27]. To better model interactions between pedestrians, some algorithms construct matrices using information of other pedestrians around a pedestrian, and extract features from matrices by neural network. The Social-LSTM [28] is the most representative one, where the velocities and positions of the surrounding pedestrians are embedded within a 3D matrix by square segmentation. Except for that, SS-LSTM constructs the matrix using ring segmentation, and FSP constructs the matrix using relative positions [29]."}, {"title": "III. METHODOLOGY", "content": "The position information of pedestrian $i$ at time $t$ are represented as $X_t^i = [x_t^i, y_t^i]$. Further, $X_t^i = [x_t^i, y_t^i]$ when the pedestrian is observable with position $[x_t^i, y_t^i]$, and $X_t^i = [Nan, Nan]$ when the pedestrian is not observable. Suppose there are $m$ pedestrians in the scene at time $t_0$, then their historical position information $H_{1:m}^{t_0}$ and ground-truth future position information $F_{1:m}^{t_0}$ can be represented as follows:\n$H_i^{t_0} = \\{X_{t_0}^i, X_{t_0-1}^i,..., X_{t_0-T_{obs}+1}^i\\}$\n$H_{1:m}^{t_0} = \\{H_1^{t_0}, H_2^{t_0},...,H_m^{t_0}\\}$\n$F_i^{t_0} = \\{X_{t_0+1}^i, X_{t_0+2}^i,..., X_{t_0+T_{pred}}^i\\}$\n$F_{1:m}^{t_0} = \\{F_1^{t_0}, F_2^{t_0},..., F_m^{t_0}\\}$\nwhere $T_{obs}$ and $T_{pred}$ are the time step length of the historical and predicted trajectories, respectively. The algorithm will output future trajectory predictions $F_{1:m}^{t_0}$ for $m$ pedestrians based on their historical trajectory information and environmental information. The loss function of STGN-IT tries to minimize the ADE between the prediction $F_{1:m}^{t_0}$ and the ground-truth trajectory $F_{1:m}^{t_0}$.\nThe STGN-IT algorithm makes 2 times of predictions and contains 4 modules. Its structure and prediction process are shown in Fig. 4. In the first prediction, the network directly predicts the future trajectories of pedestrians without using environmental information. Then obstacles near the predicted trajectory are added to the spatio-temporal graph as nodes, and the new spatio-temporal graph is used as input for the second prediction to increase the accuracy of the prediction.\nDuring the prediction, the spatio-temporal graph construction module generates the spatio-temporal graph and the corresponding matrices with the DBSCAN clustering algorithm [37], then the observation state encoding module encodes the matrices based on the pedestrian observation states, and finally the trajectory prediction module predicts the trajectories based on the encoded features. Between two times of predictions, the obstacle addition module adds obstacles near the predicted trajectories to the graph as nodes."}, {"title": "C. Spatio-temporal Graph Construction Module", "content": "When constructing the spatio-temporal graph, we consider both position and velocity information. In the spatio-temporal graph, node $N_t^i$ represents the information of a pedestrian or an obstacle at time $t$, and edge $E_t^{ij}$ represents the correlation between $N_t^i$ and $N_{t-1}^j$ at time $t$. Suppose $\\Delta X_t^i = X_t^i \u2013 X_{t-1}^i$ is the velocity of $N_t^i$ at time $t$, then $N_t^i$ and $E_t^{ij}$ can be represented as follows:\n$N_t^i = [X_t^i, \\Delta X_t^i]$\n$E_t^{ij} = [X_t^i \u2013 X_{t-1}^j, \\Delta X_t^i \u2013 \\Delta X_{t-1}^j]$\nThen, we use the DBSCAN clustering algorithm to adjust the order of the nodes in the matrix, making the interactions between the nodes easier to detect. As shown in Fig. 4, the node order in the matrix is (1, 4, 2, 5, 6, 3) instead of (1, 2, 3, 4, 5, 6), because the obstacle $N_t^5$ and $N_t^6$ have an impact on the trajectories of the pedestrian $N_t^3$ and $N_t^2$, and making them neighboring in the matrix is beneficial for the graph convolutional network to extract the features."}, {"title": "D. Observation State Encoding Module", "content": "When node $N_t^i$ is not observable, we let $X_t^i = [0,0]$ and $\\Delta X_t^i = \\Delta X_{t+1}^i = [0,0]$. To allow the network to distinguish whether a node is not observable or truly in position (0,0), we design an encoding rule to describe the observation state. Specifically, we add two vectors, $N_{ot}^i$ and $E_{ot}^{ij}$, to describe the availability of the data. Define $ON_t^i$ as the observation state of $N_t^i$, the specific rules are shown in Table I and Table II. Then, for the nodes, we use the fully connected layers to combine the information from $N_t^i$ and $N_{ot}^i$ to obtain the feature $N_{fi}^t$:\n$N_{e}^i = \\phi_{ne} (N_t^i; W_{ne})$\n$N_{oe}^i = \\phi_{noe} (N_{ot}^i; W_{noe})$\n$N_{fi}^t = N_{e}^i \\odot N_{oe}^i$"}, {"title": "E. Trajectory Prediction Module", "content": "In order to reduce the influence of missing positions on the trajectory feature extraction, two GRU networks are first used to compensate for the missing position information by utilizing the features from previous frames. The compensation node matrix $V_{fc}$ can be constructed as follows:\n$H_{vfc} = GRU^{v_f} (H_{vf}, V_f; W_{vf})$\n$V_{fc} = \\phi_{vfc} (H_{vfc}; W_{vfc})$\nwhere $GRU^{v_f}$ is a GRU network with an input layer dimension of $n_{en}$ and hidden state dimension of $n_{gru}$, and $\\phi_{vfc}$ is the fully connected layer with an input dimension of $N_{gru}$ and an output dimension of $n_{en}$. $H_{uf}$ is the initial hidden state of $BiGRU^{uf}$, and $H_{ufc}$ is the stack of hidden states at each step of $BiGRU^{uf}$. Similarly, we construct the compensation adjacency matrix $A_{fc}$ by another two networks $BiGRU^{af}$ and $\\phi_{afc}$, and a similar process to (10)-(11). $V_{fc}$ has the same dimension as $V_f$, and $A_{fc}$ has the same dimension as $A_f$.\nInspired by [31], we use the Spatio-Temporal Graph Convolution Network (STGCN) and the Time-Extrapolator Convolution Network (TECN) to extract features from the $V_{fc}$ and $A_{fc}$ matrices. The process is shown as follows:\n$V_{stg} = STGCN(V_{fc}, A_{fc}; W_{stgcn})$\n$V_{p} = TECN(V_{stg}; W_{tecn})$\nwhere STGCN is a STGCN network that kernel size is $n_{stg}$, and TECN is a three-layer TECN Network that kernel size is $n_{te}$. The node prediction matrix $V_p$ has a dimension of $[T_{pred}, m, n_{de}]$.\nFinally, a Bi-GRU network is utilized to extract the features in $V_p$ to obtain the matrix $GV_p$, and then a multi-layer perception (MLP) network is utilized to decode $GV_p$ and output the final prediction velocity. The process is shown as follows:\n$SP_{1:T_{pred}} = BiGRU^{uup} (H_{gvp}, GV_p; W_{pv})$\n$\\Delta x_t = MLP_{SP}(S_{pt}; W_{sp}) (t = 1,2,...,T_{pred})$\n$X_t = X_{t-1} + \\Delta x_t (t = 1,2,...,T_{pred})$\nwhere $BiGRU^{uup}$ is a Bi-GRU network with an input layer dimension of $n_{de}$ and hidden state dimension of $n_{gru}$, and $MLP_{SP}$ is a three-layer MLP network with an input dimension of $2 * n_{gru}$ and an output dimension of 2. $H_{gvp}$ is the initial hidden state of $BiGRU^{uup}$, and $SP_{1:T_{pred}}$ is the stack of hidden states at each step of $BiGRU^{uup}$. $\\Delta x_t$ and $X_t$ are the displacement and position of pedestrians predicted by the network at time $t$, respectively."}, {"title": "F. Obstacle Addition Module", "content": "As shown in Fig. 4, after the first prediction, the obstacle addition module will add obstacle nodes to the spatio-temporal graph based on the occupancy grid map and the predicted trajectories. Suppose the set of predicted trajectories in the first prediction is $X$. The obstacle position in the occupancy grid map can be represented as $(x_{obs}, y_{obs})$, and the set of obstacles added to the spatio-temporal graph is $Obs$, defined as follows:\n$Obs = \\{(x_{obs}, y_{obs}) | f_{mindis} ((x_{obs}, y_{obs}), X) < o_d\\}$\nwhere the function $f_{mindis} (p, S)$ is defined as the minimum distance from the point $p$ to all points in the set $S$, and $o_d$ is the minimum distance to add an obstacle as a node.\nSince the obstacles in $Obs$ are close to the pedestrian's predicted trajectories, they will affect the future trajectories of pedestrians. After adding them to the spatio-temporal graph as nodes, STGN-IT will make the second prediction, which considers the influence of the environment and has a higher accuracy."}, {"title": "IV. EXPERIMENTS AND ANALYSIS", "content": "We use average displacement error (ADE) and final displacement error (FDE) to evaluate the performance of algorithms, which are defined as follows:\n$ADE = \\frac{\\sum_{i=1}^{m}\\sum_{t=1}^{T_{pred}}||\\hat{X}_t^i - X_t^i||_2}{m * T_{pred}}$\n$FDE = \\frac{\\sum_{i=1}^{m}||\\hat{X}_{T_{pred}}^i - X_{T_{pred}}^i||_2}{m}$\nwhere $|| \\cdot ||_2$ denotes the Euclidean norm. ADE and FDE are measured in meters.\nThe STC dataset annotated over 5,000 trajectories in over 10 scenes with the raw data of 3D LIDAR for each scene. We use the raw LIDAR data to create point cloud maps and further generate occupancy grid maps. We use trajectories in the STC dataset to train and evaluate the performance of STGN-IT and state of the art algorithms. To further evaluate the influence of missing trajectories on the algorithm performance, we randomly removed about 10% of the samples from the original dataset and generated a new dataset, STC-c. Samples are kept when they are used as labels and only removed when they are input as observation sequences, so STC and STC-c datasets have the same training and validation labels.\nThe STC dataset has a frame rate of 2.5 Hz. Same as the settings of state of the art algorithms, we set the observation time as 3.2 seconds and the prediction time as 4.8 seconds, so $T_{obs} = 8$ and $T_{pred} = 12$. As defined in (20), the conditions for STGN-IT to perform trajectory prediction for pedestrian $i$ are that it is observable in the latest frame and is observable for over 2 of the past 8 frames. Notice that under this rule, STGN-IT predicts the trajectory of a pedestrian 1.2 seconds after observing it, rather than the 3.2 seconds required by most existing algorithms. The shorter response time makes STGN-IT more suitable for mobile robot navigation than other existing algorithms.\n$X_t^i \\neq [Nan, Nan] \\& \\sum_{t=-T_{obs}+1}^{t_0} f_{exist}(X_t^i) > 2$\n$f_{exist}(X_t^i) = \\begin{cases} 1 & \\text{if } X_t^i \\neq [Nan, Nan] \\\\ 0 & \\text{if } X_t^i = [Nan, Nan] \\end{cases}$\nThe structural parameters of the network are set as $n_{en} = 9$, $n_{de} = 7$, $n_{gru} = 64$, $n_{stg} = 7$, $n_{te} = 3$. The distance parameters are set as $o_d = 0.8$, $a_d = 1$, $f_d = 1$. The learning rate is set to 0.001, the batch size is set to 16, and the number of epochs is set to 200.\nWe compare STGN-IT with the following state of the art algorithms: STIGCN [38] (2024), SSAGCN [39] (2023), MSRL [40] (2023), GraphTERN [41] (2023), Social-Implicit [42] (2022), SGCN [43] (2021), Social-STGCNN [31] (2020). Referring to [44], for the state of the art algorithms, we randomly sample 3 times and select the samples with the best metrics, that is, minADE3 and minFDE3. For STGN-IT, we output three candidate trajectories based on the possible directions of pedestrians. To better evaluate the performance of the algorithms, we train and evaluate them with two modes, the filtration mode and the pad mode:\n*   Filtration mode: the algorithms only predict pedestrians with complete historical trajectories.\n*   Pad mode: the algorithms predict pedestrians that satisfy (20) during training and testing. When pedestrians are not observable, their positions are replaced by (0,0).\nIn the following, we refer to the condition \"p-p\" as the algorithm trained and tested with filtration mode, and refer to the condition \"p-f\" as the algorithm trained with pad mode and tested with filtration mode."}, {"title": "D. Quantitative Experiments and Analysis", "content": "Table III shows the ADE and FDE of algorithms evaluated in three prediction conditions. The performance of all algorithms decreases from \u201cSTC,f-f\u201d to \u201cSTC,p-p\u201d to \u201cSTCc,p-p\u201d, due to the increasing incomplete parts of the trajectories between these three conditions. However, the performance degradation rate differs greatly among different algorithms. GraphTERN cannot be trained successfully in condition \u201cp-p\", SSAGCN and Social-Implici have almost twice the metrics in \u201cSTCc,p-p\u201d as \u2018STC,f-f\u2019\u201d, and even metrics for algorithms that are less affected, such as STIGCN and MSRL, also increase by over 25%. This situation leads to the second best algorithm being different in three prediction conditions. STGN-IT, on the other hand, has a performance degradation rate of about 15%, which is the smallest among all the algorithms. Also, STGN-IT has the best ADE and FDE in all three conditions, which means that the predictions of STGN-IT are closest to the true trajectories of pedestrians, making potential collisions the most likely to be detected.\nNote that the ADE and FDE in condition \u201cf-f\u201d are the metrics used in most publications, however, as demonstrated in Fig. 1 and Fig. 2, condition \u201cp-p\u201d is safer for robot navigation rather than condition \u201cf-f\u201d. And in Table III, an algorithm has a low ADE in condition \u201cf-f\u201d does not mean a low ADE in condition \u201cp-p\u201d, as Social-Implicit has lower ADE than STIGCN in condition \u201cf-f\u201d but higher ADE than STIGCN in condition \u201cp-p\u201d. Therefore, when evaluating the performance of algorithms, it is more appropriate to compute the ADE in condition \u201cp-p\u201d rather than in condition \u201cf-f\u201d."}, {"title": "E. Ablation Study", "content": "We explore the influence of different modules on the performance of STGN-IT through an ablation experiment with the following algorithms:\n1) STGN-IT without adding obstacle nodes. (w/o obs)\n2) STGN-IT without observation state. (w/o code)\n3) STGN-IT without clustering process. (w/o clu)\nTable IV shows the ADE and FDE of algorithms evaluated in different prediction conditions. The least affected algorithm is STGN-IT w/o code in condition \"f-f\", which makes sense because in condition \"f-f\" all input trajectories are complete and the observation state encoding is redundant. In addition to this case, the deletion of any module reduces the performance metrics of the algorithm by at least 20%.\nWithout the clustering process, the feature vectors of nodes with interactions cannot be neighboring in the matrices, making the network hard to extract features. Without the observation state encoding, the algorithm cannot recognize invisible trajectories properly, thus reducing performance. Without adding obstacle information, the algorithm cannot predict the trajectories of pedestrians to avoid obstacles, resulting in lower performance."}, {"title": "F. Qualitative Analysis", "content": "The prediction results of some scenes are shown in Fig. 5. In scenes B, F, and G, GraphTERN does not predict the future trajectories of some pedestrians due to their incomplete historical trajectories, which can increase the risk of pedestrians during robot navigation. In scenes A, B, and C, the trajectories predicted by some state of the art algorithms clash with static obstacles, while the predictions of STGN-IT do not. This is because STGN-IT uses the occupancy grid map as the input, reducing the probability of predicting collision trajectories.\nSTGN-IT also successfully predicts the interactions between pedestrians. In scene D, pedestrians 2, 3, and 4 stop on the road, and pedestrian 1 bypasses them, and STGN-IT successfully predicts the bypass trajectory. In scene E, four pedestrians meet at an intersection, and the STGN-IT successfully predicts their turns, while the trajectories predicted by the SGCN collide. The same situation occurs in scene F, where only the trajectories predicted by STGN-IT avoid collisions, GraphTERN does not predict trajectories, and the trajectories predicted by SGCN and STIGCN collide.\nIn scene G, when the trajectory of pedestrian 1 is partially missing due to column occlusion, the trajectories predicted by STGN-IT are smooth and roughly correct, while the trajectories predicted by STIGCN and SGCN are very unstable. The trajectory predictions for Pedestrian 2 demonstrate that all algorithms have good predictions for stationary pedestrians.\nQualitative analysis demonstrates that STGN-IT has good trajectory prediction performance and can predict trajectories that are smooth and close to the ground-truth labels."}, {"title": "V. CONCLUSION", "content": "In this paper, we present a spatio-temporal graph network allowing incomplete trajectory input (STGN-IT) for pedestrian trajectory prediction. By using occupancy grid maps, observation state encoding, and clustering processes, STGN-IT achieves better trajectory prediction accuracy than the other algorithms in experiments. In addition, we propose the prediction condition of the pad mode, which is more ideal for applying the algorithm to mobile robot navigation than the filtration mode. For incomplete trajectory inputs in the pad mode, STGN-IT can output predictions more consistently than other state of the art algorithms.\nBased on STGN-IT, we will further study algorithms to improve the prediction accuracy of pedestrian trajectory prediction with incomplete historical trajectories."}]}