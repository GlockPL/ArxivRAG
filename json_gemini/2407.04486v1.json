{"title": "Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses", "authors": ["Tianshu Feng", "Rohan Gnanaolivu", "Abolfazl Safikhani", "Yuanhang Liu", "Jun Jiang", "Nicholas Chia", "Alexander Partin", "Priyanka Vasanthakumari", "Yitan Zhu", "Chen Wang"], "abstract": "Human cancers present a significant public health challenge and require the discovery of novel drugs through translational research. Transcriptomics profiling data that describes molecular activities in tumors and cancer cell lines are widely utilized for predicting anti-cancer drug responses. However, existing AI models face challenges due to noise in transcriptomics data and lack of biological interpretability. To overcome these limitations, we introduce VETE (Variational and Explanatory Transcriptomics Encoder), a novel neural network framework that incorporates a variational component to mitigate noise effects and integrates traceable gene ontology into the neural network architecture for encoding cancer transcriptomics data. Key innovations include a local interpretability-guided method for identifying ontology paths, a visualization tool to elucidate biological mechanisms of drug responses, and the application of centralized large scale hyperparameter optimization. VETE demonstrated robust accuracy in cancer cell line classification and drug response prediction. Additionally, it provided traceable biological explanations for both tasks and offers insights into the mechanisms underlying its predictions. VETE bridges the gap between AI-driven predictions and biologically meaningful insights in cancer research, which represents a promising advancement in the field.", "sections": [{"title": "1. Introduction", "content": "Cancer is a significant global health issue that requires a comprehensive spectrum of anti-cancer drug research, including the discovery of novel compounds, biochemical optimizations, preclinical evaluations, and the final translational stages of rigorous clinical trials (Gutierrez et al., 2009; Cui et al., 2020; Honkala et al., 2022). In recent years, integrating AI approaches into molecular data and anti-cancer drug response studies has revolutionized our understanding and capabilities in the field of cancer research (Albaradei et al., 2021; Franco et al., 2021; Leng et al., 2022; Partin et al., 2023). These advanced computational methods allow researchers to unravel complex biological networks and pathways with unprecedented precision and depth. In data-driven omics characterization of molecular and biology profiles, deep learning algorithms have been instrumental in decoding large and intricate datasets, ranging from genomics to proteomics, thus enhancing our understanding of cellular mechanisms and disease pathogenesis (Zou et al., 2019; Aliper et al., 2016; Bulik-Sullivan et al., 2019). In drug response studies, deep learning has shown promise in predicting drug efficacy and toxicity, personalizing oncology approaches, and accelerating drug discovery processes (Chang et al., 2018; Kuenzi et al., 2020). The ongoing advancements in AI algorithms, neural network architecture, and computational power continue to open new frontiers in cancer research, promising transformative impacts on therapeutic development and precision oncology.\nDespite the advancements brought by deep learning in cancer omics and drug response research, these multilayered neural models are limited by their lack of transparency in understanding biological mechanisms. Often operating as \u201cblack boxes,\u201d deep learning models provide limited insight into how they derive their conclusions. This opacity is a critical drawback in biomedical research, where understanding the biological underpinnings is as crucial as predictive accuracy for formulating testable hypothesis and determining follow-up biological experiments. For instance, in omics studies, while deep learning models can efficiently predict cell types based on gene expression patterns or genetic variants (Dong et al., 2022), they often fail to offer clear explanations for these predictions, which is vital for clinical decision-making and therapeutic development (Haywood et al., 2022; Kircher et al., 2023; Pleasance et al., 2022). Similarly, in drug response prediction, although these models can identify potential responders and non-responders to a treatment, their inability to explain the basis of these predictions limits their clinical applicability and translational research aimed at overcoming drug resistance (Adam et al., 2020; Baptista et al., 2021). These challenges highlight the need for more interpretable and explainable AI models in biomedical research, where the understanding of 'why' and 'how' a model makes a prediction is just as important as the prediction itself (Rudin, 2019).\nIn this paper, we propose the Variational and Explanatory Transcriptomics Encoder (VETE), based on variational information bottleneck principle (Alemi et al., 2016). VETE can be configured with various deep learning components (hereby referred as submodel), including a submodel for encoding cancer transcriptomics data, and can incorperate additional submodels for extracting embeddings from other omics data and/or drug data (Figure 1a). The transcriptomics submodel's neural network structure is designed according to the Gene Ontology, a literature-curated knowledge database encompassing various aspects of biology subsystems (intracellular components, processes or functions) (Gene Ontology Consortium, 2017). Each parent-child relationship between these subsystems is represented as a connection in the network, forming a hierarchical model structure that explicitly models the biological process at different scales and links gene expression to molecular and functional relevance. The drug embedding submodel, on the other hand, is based on multi-layer perceptron (MLP) with drug fingerprint as input and drug molecular structure embedding as output (Kuenzi et al., 2020).The outputs of these submodels are concatenated to generate latent random variables, from which latent realizations are drawn for downstream tasks, such as cancer type classification and drug response prediction. Previous studies have used the Gene Ontology to predict phenotypes with disrupted genes in a eukaryotic cell, albeit using binary genetic mutation states as features (Kuenzi et al., 2020; Ma et al., 2018). Despite the hierarchical structure, understanding the model decision process for individual predictions remains challenging. In this paper, we propose a graph-based model explanation technique to reveal the influence of subsystems on final model predictions, leading to a more transparent approach.\nThe model is validated with two datasets: Genomics of Drug Sensitivity in Cancer (GDSC) (Yang et al., 2012) and The Cancer Genome Atlas Program (TCGA) (Weinstein et al., 2013) (detailed in the appendix). We evaluated the model performance in cancer type classification detailed the transcriptomics submodel on both datasets and further study the drug response prediction using GDSC. The results demonstrate that VETE efficiently identifies key drug-cell interaction factors consistent with existing literature, even without explicitly incorporating prior biological knowledge during model training. These findings suggest VETE's substantial potential to advance drug-cell interaction studies and enhance our understanding of biological mechanisms."}, {"title": "2. Methodology", "content": ""}, {"title": "2.1. Data Preparation", "content": "For model training and analysis, we selected the top 15% most frequently mutated genes in human cancers, as identified in the Cancer Cell Line Encyclopedia (CCLE) (Barretina et al., 2012). We focused on genes annotated with Gene Ontology (GO) terms (Ashburner et al., 2000), resulting in a set of 3,008 genes. GO terms were retained only if they included at least 10 of these selected genes and were distinct from all their child terms. To reduce model complexity, we further limited the hierarchy to a maximum depth of five. The final hierarchy consists of 2,086 GO terms and defines the structure of the VETE submodel for encoding cancer transcriptomics data.\nMultiple datasets were utilized for model training and validation. Multi-omics data of cell lines, including gene expressions and cancer types, were extracted from the Dependency Map (DepMap) portal of CCLE. Drug information was retrieved from PubChem (Kim et al., 2016). Using the SMILES (Simplified Molecular Input Line Entry Specification) nomenclature for drugs (Weininger, 1988), we calculated molecular fingerprints and descriptors to embed drugs' molecular structures using the Mordred (Moriwaki et al., 2018) and RDKit (Landrum & others, 2006) Python packages. Cell line response data were extracted from GDSC version 2 (Yang et al., 2012). In total, we included 66,353 unique drug-cell line pairs with 1,007 cell line samples and 1,565 drugs."}, {"title": "2.2. Variational and Explanatory Transcriptomics Encoder for Biological Graphs", "content": "The proposed Variational and Explanatory Transcriptomics Encoder (VETE) consists of expandable submodels for learning the latent embeddings of gene expressions and drug molecular structures (Figure 1b). The submodel for transcriptomics encoding is based on a hierarchical neural network (HNN) (Ma et al., 2018) (Figure 1c). This HNN architecture mirrors the hierarchical structure of an ontology of cellular subsystems, where each subsystem's parent-child relation is modeled with an MLP. The drug embedding submodel encodes the drug structure using a fully connected feed-forward neural network. VETE follows the variational information bottleneck (VIB) framework (Alemi et al., 2016), where the drug-cell pair embedding is represented as a latent distribution rather than a deterministic vector. Compared with classic autoencoder structure, theoretical and practical studies suggest that VIB framework is more robust against data perturbations and noises (Kingma & Welling, 2014; Alemi et al., 2016; Camuto et al., 2021; Korshunova et al., 2021). This robustness is beneficial given the relatively large number of parameters (over 180 million) and the pre-specified sparse model structure in VETE, as well as the noisy gene expression data with a limited sample size (114,000 drug-cell pairs from GDSC version 2).\nWe consider a general directed acyclic biological graph \\(G = (V, E)\\) with \\(M_V\\) biological terms as nodes \\(V = \\{1,..., M_V\\}\\) (e.g., genes, pathways, or biological processes) and their directed association as edges \\(E = \\{i \\rightarrow j | i, j \\in V\\}\\) (e.g., gene \\(i\\) directly influences a biological process \\(j\\)). The graph can be curated and constructed based on existing literature and findings, including the Gene Ontology (GO) (Gene Ontology Consortium, 2017), Clique-eXtracted Ontology (CliXO) (Dutkowski et al., 2013), and kyoto encyclopedia of genes and genomes (KEGG) (Kanehisa & Goto, 2000; Chanumolu et al., 2021).\nLet the samples be \\((x^{g,1}, x^{d,1}, y_1), ..., (x^{g,N}, x^{d,N}, y_N)\\), where gene feature vector \\(x^{g,n}\\) represents the vector of gene expression values, drug feature vector \\(x^{d,n}\\) denotes the structure embedding of a drug, and \\(y_n\\) is the response variable of the \\(n\\)-th drug-cell pair. For the gene expression embedding submodel, we consider a general model framework for directed biological graph. First, each node \\(i\\) is represented with an embedding vector \\(v_i\\). Then, for a given node \\(j\\) and and its parents \\(E.j = \\{i \\in E | i \\rightarrow j\\}\\), the relationship of \\(E_j\\) and \\(j\\) can be estimated with an almost everywhere differentiable function \\(f_j\\); using the training set such that \\(v_j \\approx f_j(v_i, i \\in E_j)\\). In this paper, we model the relationship of \\(\\{i | i \\in E.j\\}\\) and \\(j\\) using an MLP, where the \\(M_j\\)-dimensional embedding of the subsystem, \\(L_j \\in \\mathbb{R}^{M_j}\\), is defined as:\n\\(L_j = \\text{BatchNorm}(\\text{tanh}(\\text{MLP}(I_j))),\\)   (1)\nwhere \\(I_j = (L_i, i \\in E_j; x^g)\\) is the concatenation of \\(L_i\\) for \\(i \\in E.j\\) and gene expression features \\(x^g\\) directly related to node \\(j\\). Here, tanh represents the nonlinear hyperbolic tangent transformation, and BatchNorm regularizes the model weights to mitigate internal covariate shift and smooth the objective function (Santurkar et al., 2018). The gene expression embedding from the last layer of the submodel is denoted as \\(L^g\\). The drug embedding submodel follows a classic feed-forward neural network structure with three layers, where the input is the 512-bit ECFP4 fingerprints of drugs (Rogers & Hahn, 2010). The output of the final layer, \\(L^d\\), represents the drug embedding learned by the model.\nThe combined layers \\(L^g\\) and \\(L^d\\) are input into an additional fully connected layer. This layer outputs two parameter vectors: \\(\\mu\\) and \\(\\sigma\\), both in \\(\\mathbb{R}^M\\), where \\(M\\) is the dimension of the latent space. These vectors represent the mean and standard deviation of the latent random variable distribution \\(Z = (Z_1, ..., Z_M) \\in \\mathbb{R}^M\\) for the drug-cell pairs, which can be considered as the encoded latent representation. For downstream applications such as classification or regression, we employ decoder models \\(D\\), where \\(D\\) can be a classifier, regressor, or a neural network designed to reconstruct the input from low-dimensional embeddings. These models are tailored to the specific response variable \\(y\\), using realizations \\(z \\sim Z\\) as their input. Notably, \\(y\\) can represent various biological responses, such as the Area Under the dose-response Curve (AUC) for drug response or different cell types. Since the decoder \\(D\\) is jointly trained with the encoder, it can serve both as an auxiliary model during the training stage and as a predictive model during the inference stage.\nWe consider the mean-field assumption such that elements in \\(Z\\) are independent of each other and follows a normal distribution. Then the objective function of the proposed model is:\n\\(\\frac{1}{N} \\sum_{n=1}^N E_{z \\sim Z} \\text{Loss}(D(z_n), y_n) - \\beta \\text{KL}(q(z_n | x^{d,n}, x^{g,n}) || p(z_n)) + \\lambda \\sum_{j} \\text{Loss}(\\text{MLP}(L_j), y_n).\\)  (2)\nHere, \\(\\text{Loss}\\) is the loss function comparing the output of the model and the response variable, \\(\\text{KL}(q(.) || p(.))\\) is the KL divergence between two distributions with probability density functions \\(q\\) and \\(p\\), \\(q(z|x^d, x^g)\\) is the posterior distribution of \\(Z\\) given input pair \\((x^d, x^g)\\), \\(p(z)\\) is the pre-specified prior of \\(Z\\), and \\(\\beta\\) and \\(\\lambda\\) are regularization parameters balancing the influence of KL divergence and prediction performance of subsystems. Considering the relatively large scale of the network, following the idea of GoogLeNet (Szegedy et al., 2015), we include auxiliary classifiers connected to the individual GO terms in the objective function with a discount weight \\(\\lambda\\). In this way, individual GO terms are encouraged to contribute to the overall model performance, and gradients can be propagated back through layers more effectively."}, {"title": "2.3. Identifying Critical Hierarchical Paths with Local Model Explanation Techniques", "content": "While HNN is considered due to its architecture reflecting the hierarchical organization of cellular subsystem's GO terms, the contribution of each subsystem to the model's output for a specific sample through the ontology graph is not immediately clear. In this paper, we propose graph integrated gradients (GIG), a local post-hoc model explanation method designed to assign importance scores to the parent-child relationship of subsystems within a biological graph, following the idea of integrated gradients (Sundararajan et al., 2017). As a local explanation method, instead of explaining the overall estimated model, GIG focuses on explaining how model makes decisions for individual samples. This local focus is particularly advantageous for drug responses prediction tasks, given the diverse origins of cells from various tumor and organ types. Local explanations enable the identification of specific GO terms contributing to the drug responses of drug-cell pairs pertinent to particular cell or drug types.\nSpecifically, for a model \\(f\\), a point of interest \\(X\\), and a baseline point \\(X'\\), the proposed IGNIM for an edge \\(i \\rightarrow j\\) within a directed biological graph is defined as\n\\(GIG_{i \\rightarrow j} (v_j; V_j, A, Q) = (v'_j - v_j) \\sum_{k=1}^m \\int_0^1 \\frac{\\partial f_j(v'_j + \\alpha (v_j - v'_j))}{\\partial \\alpha} d\\alpha,\\frac{\\partial v_i}\\) (3)\nwhere \\(v_j\\) is the vector of all \\(v_i\\)s for \\(i \\in E_j\\). In VETE, we let \\(v_j = L_j\\), \\(V_i = L_i\\), and \\(f\\) as defined in (1).\nThe point of interest in our GIG explanation method refers to the specific sample or group of samples for which we aim to explain the model's prediction mechanism. This could be a particular drug-cell pair or a set of pairs from the same tumor type. For groups, we average the GIG scores across all points to derive a collective explanation.\nThe baseline represents the reference point or population against which comparisons are made, and the choice of which significantly affects the explanation's outcome. The selection of an appropriate baseline can be based on the fitted model and dataset, such as the model's decision boundary or the dataset's expectation (Nair et al., 2022). To enhance interpretability, context-specific baselines can be employed. For instance, to understand why a model predicts drug DTX to be more effective for BRCA than LUAD, DTX-BRCA pairs can serve as the point of interest, with DTX-LUAD pairs as the baseline. Through GIG, we can then uncover the features most influential in the sensitivity prediction difference between BRCA and LUAD. For simplification and demonstration purpose, in this paper, unless specified otherwise, we use zero values as the baseline, representing scenarios where gene expression is unobserved."}, {"title": "2.4. Visualization with Sankey Plot", "content": "Algorithm 1 Searching and Pruning Algorithm\nInput: \\(G\\) (\\(V\\), \\(E\\)), \\(GIG_{i \\rightarrow j}\\) for \\(i j \\in E\\), \\(p\\) the number of nodes to be kept.\nInitialize \\(S \\leftarrow \\{S_0\\}\\).\nwhile \\(\\{i \\in G_s | i \\rightarrow j, j \\in G_T\\} \\neq \\Phi\\) do\nfor \\(j\\) in \\(G_T\\) do\nSelect nodes \\(i\\) from \\(G_s\\) with the highest |\\(GIG_{i \\rightarrow j}\\)|\nAdd selected nodes and associated edges to \\(G_T\\)\nend for\nend while\nWe visualize GIG scores using a Sankey plot to aid in interpretation, where nodes represent the subsystems, and edges represent the flows of importance scores from the subsystems to the final model output through the hierarchical oncology graph.\nHowever, The complexity of Sankey plots, often containing hundreds to thousands of GO terms and parent-child pairs, raises a challenge for effective visualization and interpretation. We develop a searching and pruning algorithm to identify and highlight the most important paths. With an empty graph \\(G_T\\), the process begins by adding the sink node \\(M_V\\) from the original Sankey plot \\(G_S\\) to \\(G_T\\). Subsequently, we consider a recursive process starting from the second-highest level of \\(G_S\\). In each iteration, we identify and add to \\(G_T\\) the nodes in \\(\\{i \\in G_S | i \\rightarrow j, j \\in G_T\\}\\) with the highest absolute GIG scores. This searching procedure is repeated until \\(\\{i \\in G_S | i \\rightarrow j, j \\in G_T\\}\\) is empty. The pseudo code of the process can be found in Algorithm 1."}, {"title": "2.5. Large Scale Hyper Parameter Optimization", "content": "Model explanation results are influenced by both data and the fitted model (Chen et al., 2020). Although VETE combines interpretable model structures and explanation methods to uncover drug-cell interaction mechanisms in the proposed framework, the explanations can still be inaccurate if model fitness is suboptimal (Molnar et al., 2020). Issues, such as overfitting, underfitting, and poor convergence can lead to less valuable explanations as they reflect faulty model behaviors. Therefore, gaining accurate insights into drug-cell interactions and drug response predictions require well-fitted models.\nGiven the numerous hyperparameters involved in VETE, hyperparameter optimization (HPO) is critical for improving the model prediction and explanation. In this study, we utilize DeepHyper (Balaprakash et al., 2018), an asynchronous hyperparameter search package, which offers parallel implementations of the SMAC (Sequential Model-Based Algorithm Configuration) algorithm (Hutter et al., 2011), enabling HPO on large scale high-performance computers.\nWe specifically used Bayesian optimization (BO) (Jones et al., 1998), known for its efficiency in global optimization through minimizing the number of direct queries to the real \"expensive\" black-box function by iteratively updating an internal surrogate model. Unlike grid search and random search, BO effectively explores the high-dimensional hyperparameter space by balancing exploration and exploitation (Wu et al., 2019). To fully utilize the parallel capacity of HPC, DeepHyper parallelizes BO through a centralized architecture, where a central coordinator assigns hyperparameter evaluations to remote workers. We use Extremely Randomized Trees (Geurts et al., 2006) as the surrogate model for its improved epistemic uncertainty estimates from a ran-dom-split strategy in tree construction. By leveraging HPO on large-scale HPC, we aim for the VETE model to accurately learn intrinsic drug-cell interactions and provide reliable drug response predictions and explanations."}, {"title": "3. Experiments", "content": ""}, {"title": "3.1. Model Training Tasks", "content": "Top-5 cancer type classification (cell line tumors from GDSC). To assess the transcriptomics submodel's effectiveness for gene expression embedding in cancer cell lines, we conducted a classification task. The dataset comprised transcriptomics data from cancer cells, divided into 806 training and 201 testing samples. Given the dataset's imbalanced observations across 138 cancer types, we reframed the problem as a binary classification task. The objective was to identify whether a sample belonged to one of the five most common cancer types (LUAD (lung adenocarcinoma), COAD (colon adenocarcinoma), SCLC (small cell lung cancer), GB (gallbladder cancer), PAAD (pancreatic adenocarcinoma)). For this task, we implemented an MLP with one hidden layer and a singular output neuron as the decoder. This design choice was intended to improve the encoder's learning of sample embeddings. Notably, the drug embedding submodel was excluded from this task. We used binary cross-entropy as the loss function for evaluating model performance.\nDrug response prediction (GDSC). We applied VETE to predict drug response. Our dataset includes drug-cell pairs from GDSC 2, split into 95,373 training samples and 19,271 testing samples. We ensured no overlap of cell lines between the training and testing sets. The inputs are drug-cell pairs, and the response variable is the Area Under the dose-response Curve (AUC) for drug responses. Similar to the classification task, we used an MLP with one hidden layer as the decoder to promote effective learning of sample embeddings by the encoder. The loss function for this task is mean squared error, aligning with the regression nature of the task."}, {"title": "3.2. VETE for Cell Line Classification", "content": "We trained the VETE model to differentiate between the five most common cancer types (LUAD, COAD, SCLC, GB, PAAD) and other types, using gene expression data as input. The optimization was performed using stochastic gradient descent. Evaluation on the testing set focused on the Receiver Operating Characteristic (ROC) curve and the Area Under the Receiver Operating Characteristic Curve (AUC-ROC). Hyperparameters related to network structure and optimization were crucial for VETE's performance. We searched for the optimal set of hyperparameters, which are listed in Table 1. Model initialization followed the methods introduced in (He et al., 2015), and optimization was carried out using Adam. The model is implemented in PyTorch 1.13.1 on Tesla V100 GPUs. For each sample, we took 20 realizations and used the average logits as the final output.\nAs shown in Figure 2, VETE demonstrates a notable advantage in identifying the top five cancers compared to MLP, XGBoost, and Random Forest. The ROC and AUC-ROC metrics indicate that while MLP, XGBoost, and Random Forest perform comparably, VETE outperforms them. The advantage in performance implies the effectiveness of VETE in learning the gene embedding of cell line samples, which suggests the usefulness of the transcriptomics submodel for the subsequent task of drug response prediction."}, {"title": "3.3. VETE for Drug Response Prediction", "content": "Given the efficiency of VETE in encoding cell line transcriptomics data, we further incorporated drug embedding and trained VETE as a regression model to predict drug responses for drug-cell pairs, where the response is the Area Under the dose-response Curve (AUC). The model was trained with Adam. We employed Spearman's rank correlation coefficient as the performance metrics and compared the model performance with MLP, XGBoost, and Random Forest. For MLP, XGBoost, and Random Forest, gene expression and drug molecular structure embeddings are concatenated together as the model input.\nExperiment results are shown in Figure 3. VETE achieves an overall correlation coefficient of 0.725 on the testing set. We analyzed the prediction accuracy across different actual AUC intervals (Figure 3a), revealing that VETE performs well across varying treatment sensitivities. However, it slightly overestimates low sensitivity samples due to lack of data points. Samples with AUC less than 0.2 account for only 0.14% of the total samples (157 out of 114,644 drug-cell pairs) and are omitted in evaluation. Comparatively, VETE, XGBoost and Random Forest outperform MLP in this study, with VETE having the highest performance among the four models (Figure 3b). Additionally, we investigate the prediction performance for individual drugs and identify 10 drugs associated with the highest prediction performance, where model performance varies across different types of drugs (Figure 4). Interestingly, the model performs the best for vinca alkaloids drugs (vinblastine, vincristine, and vinorelbine) and YK-4-279, which have been shown to exhibit synergy with vinca alkaloids in a previous study (Z\u00f6llner et al., 2017).\nWe used ovarian cancer (OV) and breast cancer (BRCA) samples treated with Docetaxel as the examples to demonstrate VETE's interpretability in providing insights into drug-cell interactions. Docetaxel, a type of taxane drugs that interferes with microtubules, is commonly used to treat breast cancer, ovarian cancer, non-small cell lung cancer, etc. (Lyseng-Williamson & Fenton, 2005). We selected 56 Docetaxel-OV samples and 155 Docetaxel-BRCA samples for the analysis.\nSeveral GO terms are shared across the two cancer types (highlighted with blue squares in Figure 5). For instance, Docetaxel is known to interfere with microtubules to suppress cell proliferation by decreasing phosphorylation (Lyseng-Williamson & Fenton, 2005), where protein phosphorylation (GO:0001933 and GO:0006468) are identified in both plots. Similarly, ERK1/2 (GO:0070371/70373) can also be influenced by microtubule-targeting agents and are shared in the plots (Stone & Chambers, 2000). We observed that GO terms and paths related to heart development (GO:0007507) are considered to influence the sensitivity of OV and BRCA cells to Docetaxel. Docetaxel is known for its cardiotoxicity (Shimoya et al., 2001), and several studies and cases have reported the potential heart failure issues associated with treating BRCA with Docetaxel that requires additional care in the treatment (Mackey et al., 2013; Mase et al., 2023). Studies suggest that ubiquitination is involved in the regulation of metabolic reprogramming in cancer cells (Shi & Grossman, 2010; Deng et al., 2020; Han et al., 2023). For example, a recent study in prostate cancer report that the deubiquitinating enzyme ubiquitin-specific protease 33 inhibits Docetaxel-induced apoptosis of prostate cancer cells (Guo et al., 2020). The results in Figure 5 imply that enzyme deubiquitylation may play a similar role in breast cancer and ovarian cancer (GO:0006511/0031397).\nBesides the shared GO terms, unique GO terms exist that are specific to each cancer type (highlighted with red squares in Figure 5). Figure 5a the Sankey plot for Docetaxel-OV samples, where several GO terms align with existing literature findings. For example, previous studies suggest the association of tyrosine phosphorylation (GO:0018108) and ovarian cancer (Song et al., 2019) and that Docetaxel administration can reduce certain types of phosphorylation in castrate-resistant prostate cancer (Lee et al., 2014). However, the association of Docetaxel and ovarian cancer through phosphorylation is rarely studied and require further investigation. Numerous apoptotic signaling pathways (e.g., GO:0042771, GO:0070059, GO:0097192, GO:0008625) identified in VETE have been carefully studied in relation to Docetaxel sensitivity (Liu et al., 2013; Lee et al., 2023) and ovarian cancer (Zhao et al., 2017; Nie et al., 2022). Fatty acid transport (GO:0015908) is also associated with the increased incidence and aggressiveness of ovarian cancer (Yoon & Lee, 2022), and previous studies have shown that Docetaxel and fatty acid binding protein produce synergistic inhibition of prostate cancer (Carbonetti et al., 2020).\nSimilar consistency is observed in Figure 5b. Cyclin-dependent protein serine/threonine kinase activity (CDK)(GO:0045736) is identified as related to the drug response of breast cancer samples, where the use of CDK4/6 inhibitors for breast cancer treatment has drawn significant attention in recent years (Shah et al., 2018; Sofi et al., 2022; Wang et al., 2024). Although Docetaxel has not been directly linked to CDK4/6, studies have found that pharmacological inhibition of CDK4/6 yields a cooperative cytostatic effect when combined with Docetaxel (Kumarasamy et al., 2020; De Kouchkovsky et al., 2022). Previous studies also revealed that inhibition of ERK1/2 can reverse Docetaxel resistance in MCF-7 spheroid culture, a human breast adenocarcinoma cell, which is also depicted in the Sankey plot (GO:0070373) (Jeong et al., 2010). Atypically acetylated proteins (GO:0006476) have been shown to promote breast cancer metastasis and proliferation (Riolo et al., 2012; Chang et al., 2014), which may also cause Docetaxel resistance (Li et al., 2020).\nA summary of the selected shared and unique GO terms in the two Sankey plots are summarized in Figure 6. Although transcriptomics submodel relies solely on gene expression and biological processes, and the gene embedding is concatenated with drug embedding in the final layers of VETE's encoder, several drug-related GO terms are identified in the pruned Sankey plots. This finding highlights VETE's potential in effectively interpreting drug response predictions."}, {"title": "4. Discussion", "content": "In this work, we propose VETE, an interpretable variational neural network designed to mirror biological processes for encoding cancer profiles and predicting drug responses. To further enhance the explainability of the fitted model, we developed a graph-based post-hoc explanation method that assists in searching and pruning the biological graph from VETE. As the quality of explanations is sensitive to the model's fit, we employ large-scale hyperparameter optimization using a centralized Bayesian optimization framework. Our final results show consistency with existing biological findings. We anticipate that these proposed methodologies will advance precision oncology by uncovering novel molecular mechanisms of drug responses and inspiring new treatment strategies.\nDespite its strengths, the proposed method has limitations. For example, while VETE can effectively identify important GO terms and paths, the results can be dominated by the most influential GO terms, which are already well-studied and well-analyzed in the literature. Alternative searching and pruning algorithms may be needed to discover previously unknown and relatively less influential GO terms."}]}