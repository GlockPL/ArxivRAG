{"title": "Harnessing AI data-driven global weather models for climate attribution: An analysis of the 2017 Oroville Dam extreme atmospheric river", "authors": ["Jorge Ba\u00f1o-Medina", "Agniv Sengupta", "Allison Michaelis", "Luca Delle Monache", "Julie Kalansky", "Duncan Watson-Parris"], "abstract": "AI data-driven models (Graphcast, Pangu Weather, Fourcastnet, and SFNO) are explored for storyline-based climate attribution due to their short inference times, which can accelerate the number of events studied, and provide real time attributions when public attention is heightened. The analysis is framed on the extreme atmospheric river episode of February 2017 that contributed to the Oroville dam spillway incident in Northern California. \u201cPast\" and \u201cfuture\u201d simulations are generated by perturbing the initial conditions with the pre-industrial and the late-21st century temperature climate change signals, respectively. The simulations are compared to results from a dynamical model which represents plausible \u201cpseudo-realities\u201d under both climate environments. Overall, the AI models show promising results, projecting a 5-6 % increase in the integrated water vapor over the Oroville dam in the present day compared to the pre-industrial, in agreement with the dynamical model. Different geopotential-moisture-temperature dependencies are unveiled for each of the AI-models tested, providing valuable information for understanding the physicality of the attribution response. However, the AI models tend to simulate weaker attribution values than the \"pseudo-reality\u201d imagined by the dynamical model, suggesting some reduced extrapolation skill, especially for the late-21st century regime. Large ensembles generated with an AI model (>500 members) produced statistically significant present-day to pre-industrial attribution results, unlike the >20-member ensemble from the dynamical model. This analysis highlights the potential of AI models to conduct attribution analysis, while emphasizing future lines of work on explainable artificial intelligence to gain confidence in these tools, which can enable reliable attribution studies in real-time.", "sections": [{"title": "1. Introduction", "content": "Large volumes of greenhouse gasses (GHG) are continuously emitted into the air, warming the Earth's atmosphere (IPCC, 2022), and increasing the frequency and intensity of extreme events, such as heat waves (Russo et al., 2014, Guo et al., 2017, Dosio, 2017, Molina et al., 2020), droughts (Cook et al., 2020, Vicente-Serrano et al., 2022), and heavy-rains (Trenberth, 2005; Frei et al., 2006, John et al., 2022). The field of climate attribution aims to quantify the human fingerprint on climate, and looks for establishing connections between the weather we experience and climate change.\nDifferent climate attribution methodologies exist in the literature (see e.g., Hulme, 2014, and Shepherd 2016, for a review). In this study we focus on the storyline approach (Hoerling et al., 2013). This approach compares sets of simulations, which are framed in different emission scenarios of GHG (e.g., the \"present\" and the \u201cpast\"). For the former, the model is initialized using reanalysis data, whereas the latter translates the initial condition field to the \"past\" climate by removing the climate change signal, or \u201cdelta\", of the temperature variables. Several studies have adopted this methodology to quantify the human fingerprint on the intensity of an observed extreme event (e.g., Rasmussen et al., 2011; Mallard et al., 2013; Hoerling et al., 2013; Hazeleger et al., 2015; Lackmann, 2015; Trapp & Hoogewind, 2016; Shepherd, 2016). Similarly, analysis for plausible future climates can be undertaken to evaluate how certain extreme events may intensify in the future (e.g., Michaelis et al., 2022). Storyline approach simulations are currently run with either Global (GCMs) or Regional Climate Models (RCMs; Hegerl & Zwiers, 2011), which are the main tools used to study the evolution of climate. However, their huge computational costs and long simulation times limit the number of events that are currently analyzed, and prevent these experiments from being applied in near-real time, where public attention is peaked. Furthermore, forecast uncertainty, which can arise from imperfections in both the model and/or in the initial conditions, is usually under-sampled due to the small number of members in the ensemble forecasts. This undersampling is extremely relevant since climate attribution studies usually deal with extreme events where the characterization of uncertainty is of utmost importance.\nIn this study, AI data-driven models that have generated substantial research interest in the past couple of years, especially in the domain of weather forecasting, are examined for\""}, {"title": "2. Data", "content": "The European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis version 5 (ERA5, Hersbach et al., 2020) currently provides the most accurate representation of the recent historical atmosphere. This dataset assimilates observational measurements of weather with \u201cfirst-guess\u201d forecasts to produce global atmospheric fields for a large number of variables at 0.25\u00b0 of spatial resolution. The AI-models of this study were trained on ERA5 using values at 6-hour intervals (0, 6, 12, 18 UTC) for the 1979\u20132015 period, and are publicly available at the ECMWF Github repository (see Data availability section). The Integrated Water Vapor (IWV) from ERA5 is downloaded from the ECMWF portal and used as \"groundtruth\u201d to evaluate the AI-models in the present climate. This variable, representing the total amount of water vapor (precipitable water) within a square meter column of air, is an important descriptor of ARs (Reid et al., 2020).\nTemperature climate change signals, or \u201cdeltas\u201d, were derived from a subset of 20 GCMs from the Coupled Model Intercomparison Project Phase 5 (CMIP5; see Table 2 in Michaelis et al. (2019) for the complete list of GCMs). GCMs simulate the global climate based on different emission scenarios called Representative Concentration Pathways (RCP, Meinshausen et al., 2011), including historical, pre-industrial, and future periods. The future \"deltas\u201d were computed by taking the difference between the February climatological mean temperatures during the late 21st century (2080\u20132099) following the high-emissions RCP8.5 and the historical (1980\u20131999) period. Similarly, the \u201cpast\u201d deltas were computed considering the pre-industrial mean temperatures (1880\u20131899) in comparison to the historical period. While the RCP8.5 simulation presents the strongest climate change signal, and therefore allows us to evaluate the extrapolation ability of the AI models, the pre-industrial scenario represents a case of moderate extrapolation, and exemplifies the"}, {"title": "3. Methods", "content": "The Model Prediction Across Scales-Atmosphere (MPAS-A; Skamarock et al., 2012) is a global, atmosphere-only, nonhydrostatic numerical model. MPAS-A integrates the atmospheric differential equations over a variable-resolution latitude-longitude grid that builds on unstructured Voroni meshes (Du et al., 1999), where spatial resolution gradually coarsens proportionally to the distance to a centroid. These types of models are well-versed in simulating regional climates and provide a more complete description of the global atmospheric state than limited-area RCMs (Park et al., 2014). In particular, Michaelis et al. (2022) ran their MPAS-A simulations using a 3\u201360 km variable resolution mesh with the 3-km centroid on 37\u00b0N, 126\u00b0W at 3-hourly temporal resolution. This mesh orientation produced 3-km fields over California, and extended about 15-km offshore into the Pacific Ocean, where the AR originated.\nMPAS-A contains an initialization module that adjusts the geopotential, winds, pressure variables, and specific humidity to the thermodynamic state, in case this one is modified. This component of the model is key, since for the storyline approach the temperature variables are added to the initial condition.\nThe Adaptive Fourier Neural Operator (AFNO, Guibas et al., 2021; Pathak et al., 2022), is a neural network that performs self-attention in the space of frequencies by means of the Fast Fourier Transform (FFT) and a Vision Transformer backbone (ViT, Dosovitskiy et al., 2020). The latter combination was found capable of dealing with high-dimensional input spaces, where the large number of parameters in the network made self-attention simply intractable. This topology was tested for weather forecasting in Pathak et al. (2022), being the first AI model to ever achieve comparable results to NWP systems. Given a set of input features the model was tasked with learning the atmospheric state 6-hours ahead, using 8 AFNO blocks, thus repeatedly transforming and de-transforming from the Fourier space to"}, {"title": "c. Ensemble of Adaptive Fourier Neural Operators (EnAFNO)", "content": "The Ensemble of Adaptive Fourier Neural Operators (EnAFNO) is a strategy to produce ensemble forecasts by means of six bred vectors and 90 AFNO models, resulting in a 540-member ensemble (Ba\u00f1o-Medina et al., 2024). This ensemble achieved probabilistic skill on par with state-of-the-art NWP systems for the IWV, and showed an impressive skill to reproduce the main features of an extreme AR over California. While bred vectors are estimations of initial condition uncertainty (Toth and Kalnay, 1997), the 90 AFNOs represent the uncertainty in the model parameters. Models are retrieved during the training phase by sampling the coefficients at the different epochs with a modified learning rate schedule. Bred vectors are computed by generating 6 different breeding cycles-starting January 26th at 12 UTC-by adding gaussian noise to ERA5 (perturbed forecast). A control forecast, fed with non-perturbed ERA5 data, is removed from the perturbed one, and the differences, i.e., the bred vector at time t+6 hours, are scaled to match the norm of the gaussian noise. The bred vector is then added to the ERA5 data at time t+6, and the process is repeated. Each breeding cycle requires about 8-12 iterations \u20131-2 days of lead time- until it converges to estimations of initial condition uncertainty. Then, these pre-computed bred vectors are used to perturb the initial condition of the forecast. The reader is referred to Ba\u00f1o-Medina et al., 2024 for more details on the ensemble generation strategy, and the breeding cycle. EnAFNO uses the same set of 20 input variables as AFNO of Pathak et al., 2022."}, {"title": "d. Spherical Fourier Neural Operator (SFNO)", "content": "The Spherical Fourier Neural Operator (SFNO; Bonev et al., 2023) is an updated version of AFNO, also tasked to forecast the next 6 hours of weather. This model uses spherical harmonics instead of the FFT, therefore providing a better representation of the Earth's sphere. It uses the following set of 73 input variables: surface air temperature; mean sea level"}, {"title": "e. Pangu-Weather", "content": "Pangu-Weather (hereafter just Pangu), builds on 3D Earth-specific transformer (3DEST) blocks to model the Earth's geometry (Bi et al., 2023). First, a patch embedding layer maps the input fields to a smaller dimension. Second, the resulting (reduced) 3D (for pressure variables) and 2D (for surface variables) fields feed an encoder-decoder Swin transformer (Liu et al., 2021), with 8 layers each, where each layer is a 3DEST block. The positional bias of the transformer is set to consider the fact that distances between adjacent grid-points vary with latitude. Finally, a patch recovery layer maps the decoder outputs to the global 3D and 2D dimensions representing the weather state forecast 6-hours ahead.n Bi et al. (2023), different versions of Pangu were trained to forecast the next weather states at different lead times (i.e., 1-hour, 3-hours, 6-hours, 24-hours), however for consistency with the other AI models, only Pangu-6 is utilized here. Pangu uses the same set of variables as SFNO only without the integrated water vapor."}, {"title": "f. Graphcast", "content": "Graphcast is a Graph Neural Network (GNN) tasked to forecast the next 6 hours of weather (Lam et al., 2023). GNNs are generalizations of the rigid Convolutional Neural Networks (CNN; LeCun et al., 1995) to heterogeneous gridded data (e.g., Scarselli et al., 2008), where a set of learnable weights are only allowed to convolute over a 2-D equally-spaced gridded data. Differently, GNNs build on graphical structures, which are defined by a set of nodes and edges. Each node is a representation of the features, e.g., atmospheric variables at a certain gridpoint, and the edges establish connections between them, making possible the design of complex topological structures. GNNs are trained to learn a set of weights that transforms the input graph into another representation with the same graphical structure by leveraging the features at each node with information from its neighboring ones (and itself). This is called message-passing. By performing message passing multiple times, the information of one node can flow through the graph exchanging information to those located further. In particular, Graphcast consists of three modules: an"}, {"title": "g. NN-INIT", "content": "The NN-INIT network is an AFNO topology trained with 6-hourly data for the period 1979\u20132015 from ERA5, to emulate the MPAS-A initialization module. This network uses as input the temperature and relative humidity fields at every available pressure level at time t and is tasked to minimize the mean squared error of the IWV, geopotential, surface pressure and mean sea level pressure at the same time t. The set of input and output variables was decided based on the MPAS-A initialization module configuration, where relative humidity was held constant at initial time. The model was trained on a cluster of 64 P100 GPUs using an Adam optimizer with a learning rate of 5E-4 and a cosine annealing scheduler for 100 epochs."}, {"title": "4. Model simulations", "content": "Following Michaelis et al. (2022), the goal is to simulate the Oroville AR (from February 5th, 2017 at 12 UTC to February 11th, 2017 at 12 UTC) based on different climate scenarios: the \"present\", the \u201cpast\u201d, and the \u201cfuture\u201d. For the \u201cpresent\u201d simulation, the models are initialized on February 5th, 2017 at 12 UTC using data from ERA5. For the \u201cpast\u201d and \u201cfuture\u201d scenarios the initial condition is modified following two steps (see Figure 1 for the Al-models). First, the temperature climate change signals for the month of February at all pressure-, sea-, and deep soil-levels available in each model are added to the initial conditions. Second, the modified initial condition feeds the initialization module, whose goal is to adjust the atmosphere to the new thermodynamic state. For this, the network NN-INIT estimates the IWV, mean sea level pressure, surface pressure, and geopotential at 50, 500, 850, and 1000 hPa. In parallel, the geopotential fields are adjusted to be in hydrostatic balance with the modified temperature fields at initial time (Jim\u00e9nez-Esteve et al., 2024), using the temperature and relative humidity fields at each pressure level (see Appendix A). This is usually a good assumption of the Earth's atmosphere for hourly time scales and longer (Merriam, 1992). Finally, the remainder of the variables are concatenated, and the resulting initial condition is fed to the model.\nThe impact of the initialization module is analyzed in Section 5.d, and simulations for the Al-models without this component are also run. This allows us to explore whether or not they are able to physically adjust the other variables under a warmer/cooler atmosphere, i.e., respect the temperature-moisture link. This aspect is directly linked to their intrinsic ability to learn inter-variable dependencies in the atmosphere, which has not been deeply explored, and is key to climate attribution studies.\nFor the probabilistic forecasts, MPAS-A breeds from the 21 initial conditions from the Global Ensemble Forecast System (GEFS), while 6 breeding cycles per AFNO within the EnAFNO system are generated, starting January 26th, 2017 at UTC from a gaussian noise with a scale factor of 0.15. By starting the breeding cycle a few time steps earlier than the initial condition, the bred vectors are allowed to shift from the original gaussian noise (spin-up)."}, {"title": "5. Results", "content": null}, {"title": "a. Forecasting the Oroville AR", "content": "Simulations of the four aforementioned AI data-driven models (third to sixth rows) and MPAS-A (second row) are compared to ERA5 (\u201cgroundtruth\"; first row), and displayed in Figure 2. Columns show the evolution of the IWV over the North Central and North Eastern Pacific Ocean and Western coast of the United States (US) for four different dates: February 5th at 12 UTC, February 6th at 12 UTC (lead time of 24 hours), February 7th at 12 UTC (lead time of 48 hours), and February 9th at 00 UTC (lead time of 84 hours). These dates represent important episodes of the event: the initial condition, the end of MPAS-A spin up in Michalis et al. (2022), the first peak, and the second peak of the AR. The Oroville AR moved eastward from the Central Pacific to the US transporting more than 40 kg/m\u00b2 of moisture per"}, {"title": "b. On the extrapolation of AI data-driven models", "content": "AI data-driven models are trained on historical records and they lack explicit physics in the formulation, therefore their extrapolation abilities are not yet clear. Towards addressing this gap, two different cases of extrapolation are analyzed: a strong and a moderate one, building on the \u201cfuture\u201d and \u201cpre-industrial/past\u201d scenarios, respectively. Figure 3 displays the differences between the \u201cfuture\u201d and \u201cpresent\u201d simulations, and between the \u201cpresent\u201d and \u201cpast\u201d ones, for the air temperature at 850 hPa. For the strong extrapolation case, results are shown for the same dates considered in Figure 2; for simplicity, for the moderate case, we show only the second peak (last column). The \u201cdelta\u201d fields for both cases are located in the top-left panelside. Here, the dynamical simulations with MPAS-A are used as a reference (or \"pseudo-reality\u201d) to measure the extrapolation skill of the AI models, following a well-established evaluation practice in climate change studies (e.g., Vrac et al., 2007). Therefore, the closer the AI data-driven models are to the MPAS-A results the better the extrapolation skill. The temperature \u201cdelta\u201d fields added to the initial condition of MPAS-A, evolve with time preserving the signal over most of the spatial domain, with only very small areas showing no signal or even negative values. The latter might be caused by differences in"}, {"title": "c. On the moisture response to \u201cclimate-change\u201d perturbations", "content": "AI data-driven models are not explicitly tasked to learn the interactions between atmospheric variables. Instead, these interactions are assumed to be indirectly learned during model training. Therefore, how perturbations in an atmospheric field modifies other variables in AI data-driven models is not yet clear. For this case of the Oroville AR, the moisture-temperature link is explored to investigate the realism of other atmospheric variables with perturbations in the initial condition temperature fields. Again, for the moderate extrapolation case, only the second peak is shown. MPAS-A shows increased moisture, consistent with a warmer atmosphere. The highest increments are located in the tropics and in the AR at every time step, surpassing the values of 10 kg/m\u00b2 at every gridpoint. Pangu and Graphcast also project increased values of moisture from the very beginning of the AR through the very end of the episode, with magnitudes comparable to MPAS-A for most of the domain. The spatial patterns of the moisture differences are also similar between MPAS-A and select AI models. For example, the arrow-shape negative values (in blue) located southeast of Alaska, in the MPAS-A during the second peak are also observed for Pangu, Graphcast, and AFNO, albeit with different intensities. These properties might be indicative of the physically consistent response in the IWV field to temperature changes in the initial condition. Finally, SFNO projects virtually unaltered values of moisture, consistent with the loss of temperature signal . AFNO also shows increases in moisture, with remarkable similarities with the spatial pattern of the Graphcast simulation, e.g., the negative values observed just north of the Oroville dam.\nFor the moderate extrapolation case, the AI-models show consistent results with MPAS-A, showing increases of the filament of the AR over the ocean and also in the tropics (most southern part in the panels). However, some lack of extrapolation is still diagnosed for this case, especially over land for Graphcast and Pangu. A detailed analysis over the Oroville dam domain is shown in Figure 6."}, {"title": "d. On the initialization module", "content": "Model simulations run with the initialization module (see Section 4) for the different AI-models are shown in Figure 5 at a lead time of 84 hours for the \u201cfuture\u201d scenario. Values for simulations without the initialization module are also included in the Figure for comparison purposes, together with the MPAS-A ones, which are used as reference. Therefore, the goal is to measure the impact of the"}, {"title": "e. On the attribution skill at the Oroville dam", "content": "IWV differences over the Oroville dam domain (yellow box in Figure 2) between the \"future\" and the \u201cpresent\u201d (strong extrapolation case, first row), and the \u201cpresent\u201d and the"}, {"title": "f. On the potential of large ensembles for extreme events and climate attribution", "content": "Figure 7 shows the time series of the Oroville AR as described by the EnAFNO (540-members) and MPAS-A (21-members) probabilistic systems for the (from top to bottom) \u201cpresent\u201d, \u201cfuture\u201d, and \u201cpast\u201d simulations. Following ERA5, the characteristic two peaks of the Oroville AR are clearly evident, with the second one showing higher values and a longer duration. There is also a minimum between the peaks, coinciding with the time when the two ARs merge into a single, and stronger, AR over the Pacific Ocean. Both MPAS-A and EnAFNO are able to reproduce these main characteristics of the event under \"present\" conditions, with some differences. For example, the ensemble mean of EnAFNO fails to capture the intensity of the second peak while MPAS-A overestimates IWV during the gap in AR conditions between the two peaks. The difference of ensemble sizes and thus, the IWV range covered at each time-step, is notable between MPAS-A, and EnAFNO. EnAFNO spread clearly increases as a function of lead time, in line with the non-linear and chaotic nature of the atmosphere. The large number of members within EnAFNO allows the ensemble system to assign probabilities to values that are in alignment with the ERA5 ground-truth over the valley and the second peak, whereas the MPAS-A ensemble spread is not enough to capture the ERA5 values between IWV peaks. For the \u201cfuture\u201d simulations both MPAS-A and EnAFNO project increased values of IWV over the peaks, in line with Figure 6. The time series nicely illustrates the spin-up of IWV as a function of lead time, shifting from the \u201cpresent\u201d IWV values at initial time to higher values surpassing the ERA5 reference and its own forecast in the \u201cpresent\u201d scenario. This exemplifies the temperature-moisture link shown in Figure 4, and the physical consistent response of this network. However, as mentioned before, the IWV increments are not as large as those produced by MPAS-A, which is consistently greater than the ERA5 reference throughout the entire AR episode. For the \u201cpast\u201d simulations both models show slightly similar results to their \"present\" ones. Notably, the large number of members within EnAFNO provides a considerably wider range of IWV values for both the \u201cfuture\u201d and \u201cpast\u201d simulations, and thus larger uncertainties, or possibilities, for the attribution of the event.\""}, {"title": "6. Discussion", "content": "The analysis presented provides an examination of the key properties required to conduct attribution studies with AI-models: ability to forecast an extreme event, the extrapolation ability, the relationship between temperature and moisture (related to energy conservation), the initialization module, and the potential of large ensembles. The conclusions derived from this study are exclusively for the Oroville AR; future work, including other types of extreme events such as heat waves or cyclones, will allow broader conclusions about the suitability of the current generation of AI data-driven models for climate attribution. A few examples can be found in a concurrent analysis to this work with the SFNO model for the moderate extrapolation case (Jim\u00e9nez-Esteve et al., 2024).\nTwo extrapolation cases are presented-strong and moderate-building on the temperature \u201cdelta\u201d fields from a CMIP5 GCM ensemble under RCP8.5 and pre-industrial scenarios relative to a historical period, respectively. The resulting simulations, three for each model, are compared to measure the human fingerprint on the magnitude of the Oroville AR (moderate extrapolation case) and to elucidate its potential magnitude in the \u201cfuture\u201d (strong extrapolation case). To evaluate the extrapolation ability of AI data-driven models, MPAS-A simulations are used as a \u201cpseudo-reality\u201d, following well-established practices in the climate change literature (e.g., Vrac et al., 2017). Note that conclusions drawn from this evaluation procedure entails risks, since dynamical models also present uncertainties in their climate change simulations (e.g., Bo\u00e9 et al., 2020), although MPAS-A was specifically designed to model such events in detail. The AI-models are able to preserve a large fraction of the temperature signal throughout the entire AR episode. Pangu and Graphcast are able to do this without adjusting the geopotential \u2013based on the hydrostatic balance in the initial condition field- while AFNO and SFNO extrapolation skill clearly depends on this component of the initialization module due to the strong influence of the geopotential in these models (Ba\u00f1o-Medina et al., 2024c), which prevents them to extrapolate to the new thermodynamic atmospheric state. Nevertheless, the evolved temperature signal for all AI models during the second peak present smaller changes than MPAS-A, and thus suggests poor extrapolation skill, especially for the strong extrapolation case. Pre-training the models with climate simulations has been a successful practice to improve the extrapolation ability of certain statistical downscaling (Doury et al., 2023; Bo\u00e9 et al., 2023; Ba\u00f1o-Medina et al., 2024b), and seasonal forecasting (Gibson et al., 2021) models, by providing them with samples from different scenarios during training. A similar practice could help this generation of AI data-driven models to better extrapolate to climate change regimes.\nModeling the interactions between atmospheric variables is not explicitly tasked in the neural network. Therefore, the AI models might not necessarily produce a physically consistent response to perturbations in an atmospheric variable. However, some cases of study have shown how these models might actually be producing forecasts based on physical mechanisms (Hakim &, Ba\u00f1o-Medina et al., 2024c). This is key in climate attribution, since links between the temperature fields and other variables (e.g., circulation, winds, moisture) must be properly captured. Here, the moisture-temperature link was examined due to its relevance to the Oroville AR and resultant precipitation. Graphcast, Pangu, and, to a lesser degree, AFNO, produced increased levels of moisture in line with the temperature increments given by the \"delta\u201d fields, demonstrating the ability to rapidly shift the IWV values towards magnitudes consistent with the temperature fields, similar to the spin-up of dynamical models. Again, SFNO required the initialization module to adjust the geopotential, so it is in hydrostatic balance, to produce consistent increments of IWV with the temperature \u201cdeltas\u201d. Moreover, important similarities in the spatial patterns between the MPAS-A and the AI data-driven models response were also identified, highlighting that the moisture-temperature link learned is to some degree built on physics, and thus demonstrating their ability to produce physically consistent responses to \u201cclimate-change\u201d perturbations. However, the strong dependence of SFNO on the geopotential suggests potential covariability with the temperature variables, which can hinder reliability. Also, adjusting the hydrostatic balance and consequently modifying the geopotential fields in Pangu and Graphcast seem to worsen their extrapolation skill, which could be also an indicator of potential improvements on the geopotential-temperature-moisture inter-variable links. To properly capture these atmospheric links in the neural network coefficients is key to gain confidence on these tools for attribution analysis. Loss functions including expressions describing the interactions between atmospheric variables could help to better model this aspect. A few physics-informed neural networks have been developed for atmospheric studies (e.g., Gonz\u00e1lez-Abad et al., 2023), but are yet to be explored for AI data-driven weather models. Other alternatives are to train additional networks emulating the initialization modules of dynamical models, such as the NN-INIT model developed here. Moreover, this type of networks can even avoid assumptions in the modeling of the atmosphere, such as the hydrostatic balance assumption, that might not be entirely accurate and could lead to errors in the simulations. However, NN-INIT comes with its own sources of error, since this network is tasked to complete the remaining atmospheric fields of the initial condition given a limited number of variables at the same time."}], "Appendix A": {"title": "Appendix A", "content": "Hydrostatic balance component of the initialization module\nThe following integration scheme (from bottom to top) is used to adjust the geopotential fields (z) to be in hydrostatic balance with the modified virtual temperature fields (Tv) at initial time, which are functions of the temperature and relative humidity fields at each pressure level (l). R is the ideal gas constant, for air R=287 J/kg.K.\nz", "equation": "Z1+1 = 21 - In(P1+1 - P\u2081) \u00d7 R \u00d7 (TV1+1 + Tv) \u00d7 0.5"}, "Appendix B": {"title": "Appendix B", "content": "Integration of IWV for Pangu and Graphcast\nThe following integration scheme (from bottom to top) is used to compute the Integrated Water Vapor (IWV) for Pangu and Graphcast, given this variable is not included in their model formulation. Both models contain values for the specific humidity (q) at 13 pressure levels (p): 1000, 925, 850, 700, 600, 500, 400, 300, 250, 200, 150, 100, and 50 hPa.", "equation": "IWV = 0.5 \u00d7 (q\u2081 + 91+1) \u00d7 (P\u2081 - P1+1)"}}