{"title": "Modeling Nonlinear Oscillator Networks Using\nPhysics-Informed Hybrid Reservoir Computing", "authors": ["Andrew Shannon", "Conor Houghton", "David Barton", "Martin Homer"], "abstract": "Surrogate modeling of non-linear oscillator networks remains challenging due to discrepancies between simplified analytical\nmodels and real-world complexity. To bridge this gap, we investigate hybrid reservoir computing, combining reservoir computing\nwith \"expert\" analytical models. Simulating the absence of an exact model, we first test the surrogate models with parameter\nerrors in their expert model. Second, we assess their performance when their expert model lacks key non-linear coupling terms\npresent in an extended ground-truth model. We focus on short-term forecasting across diverse dynamical regimes, evaluating\nthe use of these surrogates for control applications. We show that hybrid reservoir computers generally outperform standard\nreservoir computers and exhibit greater robustness to parameter tuning. Notably, unlike standard reservoir computers, the\nperformance of the hybrid does not degrade when crossing an observed spectral radius threshold. Furthermore, there is good\nperformance for dynamical regimes not accessible to the expert model, demonstrating the contribution of the reservoir.", "sections": [{"title": "Introduction", "content": "Networks of oscillators appear widely across engineering, and in both the physical and biological sciences. When the networks\nare non-linear their dynamical behavior can be complex, displaying synchronization, chaos, and traveling waves1\u20133. Creating\nanalytical or data-driven models that can predict their dynamics is important in applications, for example in producing surrogate\nmodels. Downstream applications for a surrogate model of non-linear oscillator networks (NLONs) include smart electrical\ngrid optimization4\u20136, biological computing7, synthetic biology8,9 and the diagnosis and treatment of neurological disorders\nsuch as epilepsy10 and Parkinson's disease11\u201314. These surrogate models have two broad applications: parameter inference\nand control. Parameter inference can help identify critical states and associated parameter values within a system, ideally also\nexposing underlying mechanistic processes. Control using surrogate models aims to exploit system knowledge to improve\ncontrol performance. Methods such as model predictive control15 and model-based reinforcement learning16 are examples.\nIn this paper, we focus on hybrid reservoir computing (RC), a specific form of physics-informed machine learning (PIML).\nIn particular, with a view to probing its viability for control applications, we investigate how well hybrid RC performs surrogate\nmodeling of NLONS.\nReal NLONs are often high dimensional, partially observable, noisy, and involve complex intra-network interactions. As\nsuch, it can be extremely difficult to create accurate surrogate models. This challenging task may be approached in several\nways. The classical approach is direct physics-based modeling, where mechanisms are pre-ordained and parameters fit to data.\nMachine learning (ML), or data-driven modeling, is an alternative approach which uses fully parameterized models and with\nparameters updated using learning algorithms. These two contrasting methods confer distinct benefits and drawbacks.\nPhysics-based models are physically accurate within the bounds of the assumptions made in their construction. Similarly,\nwithin the domain of their training data, data-driven models perform well, however physical accuracy is not enforced. Failure\nwhen predicting out-of-domain is therefore common to the two approaches. Out-of-domain failure is guaranteed for physics-\nbased models as there is no scope for adapting their structure or parameters. ML models however, can be updated online using\nnew data to adapt to new situations, although this is in itself a challenging problem\u00b97. Physics-based models are inherently\ninterpretable: each term generally has some understood physical meaning, or represents some physical laws or constraints. On\nthe other hand, ML discards this prior knowledge in favor of complete parameterisation from observed data. The correspondence\nbetween the parameters and the physical system can be difficult to discern. When data-driven models have many parameters,\nthey require large amounts of data. Physics-based models tend to have few parameters that need fitting to data, and therefore\ngenerally require less. Both methods can be computationally expensive as physics-based models rely on complex numerical\nschemes, and data-driven models often need to use extensive training algorithms for parameter updates.\nPIML is a recently-formulated approach for surrogate modeling and prediction applications18. It combines both physics-\nbased and data-driven methods, in an attempt to make use of the best features of each approach. Its goal is to obtain physically\nconstrained, robust, and interpretable models that capture both expert knowledge of dynamical processes, and the information\nthat can be extracted from data obtained from sensing and recording devices. PIML models promise to be more data efficient as\nthey do not require all of the dynamics to be learned from scratch, and they may also facilitate adaptivity through the use of\nmachine learning. PIML-based control for NLONs may thus result in more robust, efficient and accurate controllers that are\nadaptable and generalisable.\nFor PIML-based modeling of dynamical systems, it is natural to consider ML components with a time component or\nsequential nature. For instance, recurrent neural networks (RNNs) and their variants (LSTMs19, GRUs20) are a common\nchoice21\u201323. However, RC24,25 is a particularly promising alternative, due to its small size and simple training procedure. The\nsimplicity of an RC may also offer a unique benefit for PIML parameter inference; while a large RNN can learn, or over learn,\na complete model of the data without any input from the physics-based component, an RC has a limited capacity which may\nforce the model to use the physics-based component, making it more interpretable. The small number of parameters used by an\nRC may also further enhance the low-data requirement conferred by the use of system knowledge. RCs are a restricted form of\nrecurrent neural network (RNN), where learning only takes place in an external readout layer. Sequential data is passed into the\nreservoir via a fixed, random input weight matrix. An update rule then acts as a discrete non-linear map upon the internal state\nstored within the activations of the reservoir nodes. The result is a high-dimensional non-linear filter of the incoming data with\na fading memory of past states. Scaling the weights of the input matrix and internal connectivity controls the extent to which\npast-state information is maintained in the hidden state and how much influence is exerted by the input data. To compute an\noutput from the reservoir's internal state, an output weight matrix is trained, often using regularized linear regression. The\nreadout can be trained to perform classification of the reservoir state, and thus the input sequence, or regression to predict\nnumerical features. The readout layer may also be trained to perform n-step-ahead prediction. When configured to predict the\nnext step in a sequence, the reservoir may be run autoregressively with its output fed back in as the next input instance and thus\nused for time-series forecasting. This is the format we are considering here: using RCs for the prediction of dynamical system\ntrajectories.\nThe main advantage of RCs over more complex RNNs is their ease of initialization and simplicity of training. Good\ntime-series forecasting performance can be achieved using only linear regression, even when chaotic dynamics are present26,\nand issues such as the vanishing gradient problem are avoided. Since they require only general non-linear high-dimensional\nfiltering of inputs and a fading memory of past inputs, RCs can also be constructed in a wide range of physical substrates27,28.\nRecently, a PIML variant of an echo state network RC was proposed29. In hybrid RC (Fig. 1), the prediction from a standard\nRC is augmented by a single-step integration of an expert ordinary differential equation (ODE) model of the system being\npredicted. The next step prediction of the ODE model is passed into the reservoir alongside the current state. It is also passed\naround the reservoir to be considered by the output weight matrix on its own merit, during training and inference. The output\nweight matrix, still the only trained component, thus aims to combine the augmented reservoir state with the ODE model\nprediction to most accurately predict the next state. This approach allows the reservoir to compensate for errors in the expert\nODE model, and has been shown to result in superior performance when compared to models that use only one of the two\ncomponents, that is, a standard RC or an expert ODE model. In particular, the hybrid RC was used to predict the dynamics of\nthe Lorenz and Kuramoto-Sivashinsky systems when incorporating a model of each system with parameter error. With the"}, {"title": "Methods", "content": "We present first an overview of the standard and hybrid RCs used in this study, followed by a shared procedure for ground truth\ndata generation and testing in each task. We then describe the specific initialization and training methods, followed by details of\nthe parameter error and residual physics tasks."}, {"title": "Reservoir Computing", "content": "We use the echo state network (ESN)24 formulation of RC throughout this work (Fig. 2). An ESN comprises D, nodes with\ninternal states at time t denoted $r_t \\in \\mathbb{R}^{D_r \\times 1}$. The nodes are coupled together via a weight matrix $A \\in \\mathbb{R}^{D_r \\times D_r}$. Two weight\nmatrices, $B \\in \\mathbb{R}^{D_r \\times D_u}$ and $C \\in \\mathbb{R}^{D_u \\times D_r}$, corresponding to the input weights and the output weights respectively complete the\narchitecture. Input data, $u_t \\in \\mathbb{R}^{D_u \\times 1}$, is fed into the network via the input weight matrix, B. An update rule operates upon the\nhidden state and input data to produce the next internal state. For an ESN without a leak term, as used here, the update rule is\n$r_{t+1} = \\text{tanh} (Ar_t + Bu_t).$ \nOnly the output weight matrix, C, is trained, generally via regularized linear regression to produce an output that can\ntake many forms depending on the task. Here, we are focused on next-step prediction for dynamical-systems forecasting,\nso the output matrix is trained to estimate the next state of the ground truth trajectory. An internal state history matrix\n$R = [r_0, r_1,...,r_{\\bar{r}}] \\in \\mathbb{R}^{D_r \\times n_r}$ is formed by passing a training trajectory, $u_\\Upsilon \\in \\mathbb{R}^{D_u \\times n_t}$, into the reservoir in a feed-forward\nfashion (Fig. 2 training mode). The linear-regression step optimizes the weights in C to best form a map between R and the\ncorresponding next step states of $u_\\Upsilon$.\nTo produce a forecast from a given initial condition, an ESN must be run autoregressively, using its output as the next input\n(Fig 2 prediction mode). This requires first that the internal reservoir state is synchronized to the start of the trajectory it is\nforecasting. This warm-up phase, with the RC run in feed-forward mode, tends to be quite short, and requires that the reservoir\nsatisfies the echo state property33.\nA non-linear transformation of the reservoir internal states, $r_t$, may be applied before the output computation to enrich the\nrepresentations or break symmetries in the input data34."}, {"title": "Hybrid Reservoir Computing", "content": "A hybrid RC29 (Fig. 3) is constructed out of a standard echo state network with the addition of an ODE model of the target\nsystem (the 'expert ODE model', Fig. 3, blue triangle). An auxiliary next-step prediction $\\bar{u}_{t+1}$ is computed from the present\nstate $u_t$ by a numerical integrator. The integrator's prediction is then concatenated with the present state, $[\\u_t+1;u_t]$, before\nbeing passed into the reservoir as usual via the input weight matrix. The integrator's prediction, $\\bar{u}_{t+1}$, is also passed around the\nreservoir and concatenated with the reservoir internal states after the internal update, $[\\u_t+1;r_t+1]$. Because of the concatenation\nof the usual data instances with the predictions of the ODE model, the size of the input and output weight matrices must change\naccordingly: $B \\in \\mathbb{R}^{D_r \\times 2D_u}$, and $C \\in \\mathbb{R}^{D_u \\times (D_r+D_u)}$. If a non-linear transformation is applied, it is applied to the reservoir internal\nstates, $r_{t+1}$, only, not the augmented state vector as a whole.\nThe training procedure is the same as for the standard reservoir, except that the internal-state history matrix includes the\nauxiliary next-state predictions, $\\bar{u}_{t+1}$, and therefore C is being optimized to map from the augmented state, $[\\u_{t+1};r_{t+1}]$, to the\nnext state, $u_{t+1}$. Trajectory forecasting again requires a warm-up phase, and proceeds in the same fashion as the standard ESN\nmethod with the addition of the computation of the expert ODE model's auxiliary next state predictions."}, {"title": "Shared Test Procedure", "content": "We used a shared method across each task in this study. In each task, there is a distinct ground truth dynamical system that we\nare trying to predict. To produce the training, warm-up, and test data for each task, we evolved the ground truth system for a\nlong time and segmented the resulting trajectory. The training, warm-up and test trajectory lengths were chosen according to\nprevious work presenting the hybrid RC architecture29 to enable comparison with the performance achieved there. Figure 4\ndetails the lengths of each stage, and shows schematically the organization of the stages. The long trajectory was divided such\nthat the start is the training span. After a gap, 20 disjoint warm-up/test spans follow. In every test, regardless of the performance\nevaluation metric, we initialized 40 instantiations of the reservoir (standard or hybrid) and trained them on the appropriate\ntraining span. Each test then consisted of synchronizing the reservoirs to the initial condition of the test span by feeding in\nthe corresponding warm-up span, and then running the reservoirs autoregressively to produce forecasts of the same length as\nthe test span. As a control, 40 instantiations of the hybrid RC's expert ODE model (each with sampled parameter error) were\nproduced and integrated with initial conditions matching the test trajectories."}, {"title": "Model Initialization and Training", "content": "To initialize the standard and hybrid RCs we used the same method as in previous work29. In particular, the internal connectivity\nmatrix of each reservoir, A, was constructed as an Erd\u0151s-R\u00e9nyi random graph with mean degree (d), corresponding to an edge\nprobability of $(d)/D_r$. The weights were initialized uniformly randomly between \u20131 and 1, and then scaled such that the"}, {"title": "Standard Reservoirs", "content": "spectral radius was set to a desired value. The spectral radius of a matrix is the magnitude of its largest eigenvalue. The input\nweight matrix, B, was initialized with a single non-zero element per row, corresponding to one connection per reservoir node.\nEach of these connections was assigned uniformly randomly to one of the input dimensions. The weight of each connection\nwas drawn from a uniform distribution on a range set by the input scaling hyper-parameter: for all $i \\in \\{1, ..., D_r\\}$,\n$j \\sim$\n$\\begin{cases}\n\\text{Uniform } \\{1,..., D_u\\}, \\text{ with probability KR},\n\\text{Uniform } \\{D_u +1,...,2 \\times D_u\\}, \\text{ with probability 1-KR}.\n\\end{cases}$\n$b_{ij} \\sim \\text{ Uniform(-input scaling, input scaling)},$\n$b_{ik} = 0 \\text{ for } k \\neq j.$\n(2)\nThe spectral radius and input scaling were set to 0.4 and 0.15 respectively as baseline values as in previous work29.\nWe used the non-linear transformation g, applied to the reservoir internal states, $r_t$, that was used previously29. The output\nof the reservoir, $u_{t+1}$, was thus computed as\n$u_{t+1} = Cg (r_{t+1}),$\nwith the non-linear transformation $g : \\mathbb{R}^{D_r} \\rightarrow \\mathbb{R}^{D_r}$ defined such that its i-component, $g_i$, is given for all $i \\in \\{1, ..., D_r\\}$ by\n$\n g_i(r) = \\begin{cases}\nr_i, & i = \\text{odd,}\n\\text{?}, & i = \\text{even}.\n\\end{cases}\n$"}, {"title": "Hybrid Reservoirs", "content": "For the hybrid RC, the internal reservoir weight matrix, A, was constructed in the same way as for the standard reservoir.\nThe initialization of the input weight matrix, B, differed from the standard reservoir implementation. A hyper-parameter, the\nKnowledge Ratio, was used to determine the fraction of connections to the expert ODE model output states. For instance,\nwith a knowledge ratio of 0.3, 30% of the connections are from states within the expert ODE model output, and 70% are\nfrom the incoming data. This was achieved by connecting each reservoir node to either the expert model or the input data,\nwith probability KR \u2208 [0, 1] of connection to the expert model. Again, only one connection per reservoir node to the input\nstates/ODE output was formed and the weights were drawn from a uniform distribution on a range set by the input scaling\nparameter, so, for all $i \\in \\{1, ..., D_r\\}$ we set\n$j\\sim \n\\begin{cases}\n\\text{Uniform } \\{1,..., D_u\\}, \\text{ with probability KR,}\n\\text{Uniform } \\{D_u +1,...,2 \\times D_u\\}, \\text{ with probability 1-KR}.\n\\end{cases}$\n$b_{ij} \\sim \\text{ Uniform(-input scaling, input scaling)},$\n$b_{ik} = 0 \\text{ for } k \\neq j.$\n(6)\nA knowledge ratio of 0.5 was used as a baseline. A sweep from 0.1 to 0.9 knowledge ratio on the parameter error task is\npresented in the supplementary information (Supplementary Fig. S6).\nThe output weight matrix, C, was again trained using regularized linear regression. However, in the hybrid case, the\naugmented state history matrix $\\tilde{R} \\in \\mathbb{R}^{(D_u+D_r)\\times n_t}$ is formed by concatenation of the auxiliary next step predictions with the\nreservoir node activations, $\\tilde{R} = [\\tilde{U};R]$. $\\tilde{U} \\in \\mathbb{R}^{D_u\\times n_t}$ contains the auxiliary next step predictions of the expert ODE model\ncorresponding to each instance of the training data. Each column of R is thus $[\\u_{t+1};r_{t+1}]$. The activations $r_{t+1}$ are, in turn,\nproduced by processing the training data state, $u_t$, and the corresponding auxiliary next step prediction, $\\bar{u}_{t+1}$. Only the reservoir\ninternal states, $r_{t+1}$, within $\\tilde{R}$ were transformed by g prior to computation of the output matrix, C, or any output states during\nprediction."}, {"title": "Phase Component Transformation", "content": "Dynamical systems models of NLONs are often composed of phase variables, one for each oscillator in the network. As phase\nis bounded within [-\u03c0, \u03c0], representing the angle around the unit circle, a phase variable trajectory can contain discontinuous\njumps. To avoid this, we project the phase variables onto the x and y axes, forming continuous x and y phase components,\nwhich are then processed by the reservoir. To conserve the magnitude of the phase variables upon each iteration of the reservoir\n(standard or hybrid), we projected the phase components to phases, and back to components again after every step (Fig. 2 and\nFig. 3, phase component magnitude normalization)."}, {"title": "Parameter Error Task", "content": "In the parameter error task, we were aiming to evaluate the performance of the hybrid RC when its expert model differs from\nthe ground truth only through errors in its parameters. This was the case considered previously29. We conducted this test to find\nout if the hybrid RC could provide a forecasting performance improvement when predicting NLONs, as it did for the Lorenz\nand Kuramoto-Sivashinsky systems. We carried out a parameter sweep over a range of hyperparameter settings to test the\nrobustness of any improvement over the standard RC."}, {"title": "Ground Truth", "content": "The Kuramoto model is a canonical model of a system of coupled non-linear oscillators35. We use it as the ground truth in the\nparameter error task, and as the expert ODE model of the hybrid RC throughout this study. In particular, we used an all-to-all\ncoupled network of Kuramoto oscillators. This model can demonstrate synchronous, asynchronous, and chaotic behavior. The\nfixed reference frame form of the model is\n$\\frac{d \\theta_i}{dt} = \\omega_i + \\frac{K}{N} \\sum_{j=1}^N sin (\\theta_j - \\theta_i),$\nwhere 0(t) are the individual oscillator phases, w\u00a1 are the oscillator natural frequencies, K is the coupling strength, and N is the\nnumber of oscillators.\nThe different dynamical states of equation (7) are achieved by varying the global coupling strength K and the natural\nfrequencies w\u2081. For large enough K, and a tight enough distribution of w\u2081, the oscillators will synchronize, or demonstrate phase\nlocking. When the coupling strength is low, or the frequencies far apart, the model will display asynchronous behavior35.\nWe explored three qualitatively distinct dynamical regimes of the Kuramoto model in the parameter error task. They were:\na fully synchronized regime, an asynchronous regime, and a multi-frequency regime that has timescale separation between the\noscillators but otherwise demonstrates phase locking (Fig. 5).\nAs the Kuramoto model was also being used within the hybrid RC, and therefore needed to be integrated upon every\niteration, we used a transformed version of the system of equations to coincide with the x, y phase component projection that\nthe reservoirs were using. Each of the oscillator phase variables \u03b8; was transformed into phase components, $x_i = cos (\\theta_i)$ and\n$y_i = sin (\\theta_i)$. Under this transformation, the Kuramoto model is described by a pair of ODEs for each oscillator, one for each"}, {"title": "Models", "content": "The standard and hybrid RC's were initialized with a set of baseline parameters and whichever parameter was being varied was\nset according to the parameter sweep being conducted (Table 2). For the parameter error task, the hybrid RC's expert ODE\nmodel, and therefore the control ODE model, was the same as the ground truth Kuramoto model. To introduce the parameter\nerror, we added multiplicative error to the coupling strength and to each of the natural frequencies:\np \u2190 (1 + 5)p,\nwith p standing in for the parameters and \u00a7 sampled independently for each parameter from a normal distribution, N(0, \u03c3\u3121) for\ncoupling strengths and N(0, \u03c3) for natural frequencies. The standard deviations \u03c3\u03ba,\u03c3\u03c9 were set according to the relevant\nparameter sweep (baseline 0.05, other settings are explored in the supplementary information, Supplementary Fig. S1 to S4).\nThe errors were sampled independently for each instantiation."}, {"title": "Evaluation Metric", "content": "To evaluate the quality of the trajectory predictions in the parameter error task, we used the normalized mean square error\n(NMSE)\n$\\text{NMSE} (t) = \\frac{||u (t) \u2013 u^* (t) ||}{\\langle ||u (t) ||^2 \\rangle},$\nwhere u*(t) is the prediction and u(t) the ground truth. This metric was used in previous work29 to evaluate the valid time\nmetric. For each test, the mean NMSE across the entire trajectory was computed, capturing the overall agreement between the\nforecast and the ground truth."}, {"title": "Parameter Sweep", "content": "A range of hyper parameters were investigated in the parameter error task (Table 2). Only the effect of the input scaling and\nspectral radius parameters are shown here; other results are presented in the supplementary information (Supplementary Fig S1\nto S7). To ensure that a wide range of model instantiations were tested, a random seed dependent on the parameter sweep index\nwas used in the initialization."}, {"title": "Residual Physics Task", "content": "In the residual physics task, we evaluated the ability of the hybrid RC to forecast trajectories of a ground truth whose dynamical\nequations are different from the expert ODE model. To do this we kept the expert ODE model the same as in the parameter error\ntask, i.e., the standard Kuramoto oscillator network model, and used an extension with additional coupling terms to produce a\nground truth with new dynamical regimes not accessible to the standard Kuramoto model. In this task, we again evaluated the\nperformance of the standard and hybrid RCs with parameter sweeps, and compared the performance of both RCs to the hybrid\nRC's expert ODE model alone. Subsequently, we conducted a grid search to investigate the potential of an optimized hybrid\nRC in comparison to an optimized standard RC."}, {"title": "Ground Truth", "content": "We used an extended, bi-harmonic version of the Kuramoto oscillator network model that includes an extra harmonic in the\nnonlinear coupling term30, given by\n$\\frac{d \\theta_i}{dt} = \\frac{K}{N} \\sum_{j=1}^N [sin(\\theta_j - \\theta_i + \\gamma_1) + \\alpha sin (2(\\theta_j \u2013 \\theta_i) + \\gamma_2)].$\nThis introduces a structural difference between the ground truth and the hybrid reservoir's model; the extra harmonic allows for\nmore complex dynamical regimes, including heteroclinic cycles and self-consistent partial synchrony30. The regimes can be\nelicited by appropriate choice of the coupling phase shifts 1 and 2 and the scaling of the second harmonic a. As with the"}, {"title": "Models", "content": "The standard and hybrid RC's were again initialized using the baseline parameters, and whichever parameters were being varied\nwere set appropriately depending on the parameter sweep or grid search parameter set (Table 4, Fig. 7). For the residual physics\ntask the standard Kuramoto model is used as the hybrid RC's expert ODE model, and therefore the control ODE model. As\nsuch, neither model was the same as the ground truth system. We included parameter error to the coupling strength and to each\nof the natural frequencies in the same fashion as in the parameter error task."}, {"title": "Evaluation Metric", "content": "For the residual physics task, we focus on the application of hybrid RCs to control, and therefore used the valid-time metric to\nassess short-term prediction quality in both the parameter sweep and the grid search. The valid time t* is the time during which\nthe predicted trajectory has a NMSE less than some threshold \u03b5 in NMSE\n$t^* \\text{ max } {t : \\text{NMSE}(\\tau) \\le \\epsilon,\\forall \\tau \\le t} .$\nThroughout this task, we used \u025b = 0.4."}, {"title": "Parameter Sweep", "content": "We used the same method for the residual physics task that we did previously, for the parameter error task. However, here\nwe varied a different set of parameters. Specifically, we varied the spectral radius, input scaling, regularization strength, and\nreservoir size (Table 4)."}, {"title": "Grid Search", "content": "To explore the potential of \u2018optimally' tuned standard and hybrid RCs, a grid search was conducted in the residual physics\ntask. High and low parameter settings for the input scaling, spectral radius, and regularization strength were chosen from\nthe results of the parameter sweeps. In particular, these were selected to approximately range the optimum region identified\nfor each parameter, across both the standard and hybrid RC results. A set of all of the combinations of these parameters was\nproduced, labeled from A to H, at each vertex of a cube in parameter space (Fig. 7). For each parameter combination, we\nfollowed the shared evaluation method as for both of the parameter sweeps. 40 instantiations of standard and hybrid reservoirs\nwere produced and then trained and tested on ground truth data from three of the four regimes in the residual physics task.\nThese were the synchronous, heteroclinic cycles, and partial synchrony regimes. We excluded the asynchronous regime as both\nthe standard and hybrid RC failed to predict the dynamics in this regime."}, {"title": "Results", "content": "In this section we demonstrate the capability of the hybrid RC to predict NLONs in a range of different circumstances. We\nfirst present results from the parameter error task. Across three qualitatively different dynamical regimes, we compare the\nmean performance of multiple standard and hybrid RCs. As a control, we test the hybrid RC's expert model, the base ODE\nmodel, which is also subject to parameter error. We show two parameter sweeps: the spectral radius and the input scaling.\nSecond, we give the results of the residual physics task, where the hybrid RC is given a reduced form of the ground truth\nbi-harmonic Kuramoto model. Parameter sweeps are presented for four dynamical regimes. First, we test synchronous and\nasynchronous regimes. These were present in the standard Kuramoto model, however the bi-harmonic synchronous regime\ncan support multiple clusters. The other two regimes are heteroclinic cycles, and partial synchrony; both are inaccessible to\nthe standard Kuramoto model. We test the effects of spectral radius, input scaling, regularization strength and reservoir size.\nShort-term prediction quality is evaluated to investigate viability for control applications. Finally, the results of a grid search\noptimization process across three parameters are presented, illustrating the potential of a tuned hybrid RC."}, {"title": "Parameter Error", "content": "Our initial aim was to assess whether hybrid RCs are a viable architecture for surrogate modeling of NLONs by testing the\nquality of their long-term prediction across a range of parameters. We find that the performance of the hybrid RC is consistently\nbetter than the base ODE model or the standard RC. The hybrid RC also achieves low error even when both of its constituent\nparts, the base ODE model and the standard RC, do not. This matches what was previously reported for the Lorenz system29.\nDespite some variation due to parameter tuning, the hybrid RC often achieves near zero mean NMSE, particularly for the\nsynchronous and multi-frequency regimes (Fig. 8 a, d, c, f).\nIn the synchronous regime (a) there is an immediate departure from zero mean NMSE as the spectral radius crosses 1.0\nfor the standard RC. Notably, the performance of the hybrid RC also suffers here, becoming more variable; however, perhaps\nsurprisingly, it recovers as the spectral radius is increased further. For the asynchronous (b) and multi-frequency regimes (c),"}, {"title": "Residual Physics", "content": "As in the parameter-error task we find that the hybrid RC generally performs better than either the base ODE model or the\nstandard RC (Fig. 9), although this is more variable than in the parameter-error task. This is true even on the out of domain\nheteroclinic cycles and partial synchrony regimes not accessible by the expert model alone. Both the standard and hybrid RC\nfailed to learn the asynchronous regime, achieving 0.0 s valid time across nearly all parameter settings (Fig. 9 b, f, j, n). The\nbase ODE model achieves higher valid times on the asynchronous regime, however it is clear that it is also not accurate as it\npredicts slow, synchronous trajectories; it fails to capture the qualitative character of the regime (Supplementary Fig. S11).\nThe spectral radius again has a strong effect on the performance of the standard and hybrid RC; furthermore, the effect is\ndifferent for the two (Fig. 9 a, b, c, d). Most notable is the divergence in behavior at and above a spectral radius of 1.0. There is\na sharp decline in performance for the standard RC on the synchronous regime that is similar to that observed in the parameter\nerror task (Fig. 8 a). The standard RC achieves the maximum 250 s valid time with a spectral radius below 1.0 but this falls\nto 75 s for a spectral radius of 2.0. As in the parameter error task, the hybrid RC begins to fail at a spectral radius of 1.0 but\nthen appears to recover as the spectral radius is increased further (a). On the heteroclinic cycles and partial synchrony regimes\n(c, d), where the behavior is not seen in the expert model, the hybrid RC shows the same recovery, this time after a steady\ndecrease in valid time as the spectral radius increases to 1.0, followed by an increase back to near its maximum valid time. The\ninput scaling parameter (Fig. 9 e, f, g, h) only affects the more complex dynamical regimes (g - heteroclinic cycles, h - partial\nsynchrony), with maximum valid time for both the standard and hybrid RC being reached with minimum input scaling.\nThe regularization parameter (Fig. 9: i, j, k, l) has a strong effect on the valid time of both the standard and hybrid RC. High\nregularization in the synchronous regime greatly reduces the performance of the standard RC. In the heteroclinic cycles and\npartial synchrony dynamical regimes, sufficiently low regularization appears to cause complete failure of both the standard and\nhybrid RC. In all cases, the optimal regularization strength range is much broader for the hybrid RC than the standard RC.\nBeyond requiring at least 100 nodes, the reservoir size (Fig 9 m, n, o, p) has little effect on the valid time on any of the\ndynamical regimes. The hybrid RC benefits slightly from a larger reservoir (350 nodes) when predicting the heteroclinic\ncycles regime but it still outperforms the standard RC across the full range of reservoir sizes explored."}, {"title": "Grid Search", "content": "In the final part of this study we investigate how easy it is to optimize hybrid RCs. We do this with control applications in\nmind, as optimization is an important step in the development of controllers, and short-term prediction horizons are well suited\nto them. We evaluated the performance of hybrid and standard RCs using the valid time metric in a grid search of the hyper\nparameters that were shown to most strongly affect performance (Fig. 9). We ran tests on three of the dynamical regimes\n(synchronous, heteroclinic cycles and partial synchrony). On each regime, we evaluated the hybrid RC and standard RC with\nparameter settings defined by the corners of a cube in parameter space, labeled A to G (Fig. 7).\nAs identified in the parameter sweep tests, the synchronous regime is the easiest to predict (Fig. 10, top row). The hybrid\nRC achieves near perfect valid times (250 s) across all parameter settings in the grid search. A high spectral"}]}