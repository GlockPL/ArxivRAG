{"title": "OptiMUS-0.3: Using large language models to model and solve optimization problems at scale", "authors": ["Ali AhmadiTeshnizi", "Wenzhi Gao", "Herman Brunborg", "Shayan Talaei", "Madeleine Udell"], "abstract": "Optimization problems are pervasive in sectors from manufacturing and distribution to healthcare. However, most such problems are still solved heuristically by hand rather than optimally by state-of-the-art solvers because the expertise required to formulate and solve these problems limits the widespread adoption of optimization tools and techniques. We introduce a Large Language Model (LLM)-based system designed to formulate and solve (mixed integer) linear programming problems from their natural language descriptions. Our system is capable of developing mathematical models, writing and debugging solver code, evaluating the generated solutions, and improving efficiency and correctness of its model and code based on these evaluations. OptiMUS-0.3 utilizes a modular structure to process problems, allowing it to handle problems with long descriptions and complex data without long prompts. Experiments demonstrate that OptiMUS-0.3 outperforms existing state-of-the-art methods on easy datasets by more than 12% and on hard datasets (including a new dataset, NLP4LP, released with this paper that features long and complex problems) by more than 8%.", "sections": [{"title": "1. Introduction", "content": "Optimization problems are common in domains from operations and economics to engineering and computer science. Major advances in optimization algorithms over the last several decades have led to reliable and efficient optimization methods for a wide variety of structured optimization problems, including linear programming (LP) and mixed-integer linear programming (MILP), among many others. Unfortunately, optimization modeling \u2014 transforming a domain problem into a mathematical optimization problem \u2014 still requires expert knowledge. According to a recent survey, 81% of Gurobi's commercial solver users have advanced degrees, with 49% of them holding a degree in operations research (Gurobi Optimization 2023). This expertise gap prevents many organizations from using optimization, even when it could significantly improve their operations. Examples include inventory management in supermarkets, patient operations in hospitals, transportation policies in small municipalities, energy management in local solar farms, and operations in small businesses or NGOs (Saghafian et al. 2015, Aastrup and Kotzab 2010, Yao et al. 2020, Shakoor et al. 2016). Automating optimization modeling would allow enterprises to improve efficiency using optimization techniques, even when they cannot afford to access optimization experts.\nLarge language models (LLMs) offer a promising way to automate optimization modeling, and increase the reach of the powerful algorithms developed by the operations research community. However, these LLM models are still in their infancy and suffer from major flaws that prevent deployment in important"}, {"title": null, "content": "applications. Most problematically, it is difficult to ensure correctness and completeness of the LLM output. We highlight four challenges:\n\u2022 Long problem descriptions. Realistic optimization problems can be exceedingly long and complex: for example, the documentation for the energy system problem described in Liu et al. (2023b) is 60 pages long. Unfortunately, LLMs have a limited context size, and even long-context models perform less well as the input context grows Liu et al. (2023b), Levy et al. (2024). Consequently, LLMs tend to make more mistakes as the length of the problem description increases and perform poorly on complex problems. How can we design an LLM-based optimization modeling system that keeps track of each individual constraint and term in the objective and ensures the model is complete and correct?\n\u2022 Large problem data. The specification of an optimization problem often involves large amounts of data, such as customer attributes or sales of goods. Efficient formulations that ensure fast solve times are essential to handle large problem data and competing with expert-level solutions. Previous approaches to optimization modeling using LLMs, which pass numerical data to the LLM directly and use simple formulations, are thus restricted to the simplest of toy problems.\n\u2022 Hallucination. LLMs are known to hallucinate: they may produce answers that sound reasonable, but are incorrect. In the context of optimization, the generated solver code may hallucinate constraints that incorrectly model the problem, or it may hallucinate API calls that do not exist, resulting in code that cannot run. It is especially challenging to verify whether the solution is correct, supposing the code runs without error. For instance, if the solver claims the solution is unbounded, perhaps a constraint has been accidentally omitted from the formulation.\n\u2022 Bad models. The solve time for an optimization problem can depend on the particular modeling formulation chosen, and on how the structure of the problem is communicated to the solver. Optimization experts spend much of their effort modeling the problem to enhance the efficiency of the solution method. A challenge for LLMs is to produce not just an accurate model, but good code that solves the problem quickly.\nThis paper studies the feasibility of using LLMs to expand the reach of operations research techniques and analytic methods for decisionmaking by studying the performance of OptiMUS, an automated system we have developed that uses LLMs combined with traditional solvers to model and solve (mixed integer) linear programs (MILPs). OptiMUS advances the agenda of operations research when viewed as a meta-analytic tool to improve decisionmaking. We have chosen to begin with MILP modeling as MILP is one of the more classic, important, and widely used tools in the operations research toolbox. Moreover, examples of MILP problems, models, and solutions are plentiful and readily available. Our hope is that by making powerful solvers easily accessible to domain experts, OptiMUS can empower better, faster decisions that reduce costs and improve outcomes. Our studies of OptiMUS demonstrate both the promise and pitfalls of the LLM approach to quantitative decisionmaking. More broadly, through ablation studies, this paper clarifies the"}, {"title": null, "content": "information flow needed to perform optimization modeling: in other words, it provides empirical evidence for what kind of education is effective to teach (LLMs) optimization modeling.\nWe call the version of OptiMUS studied in this paper OptiMUS-0.3 to distinguish it from previous versions that have been described in the arXiv draft AhmadiTeshnizi et al. (2023) and the conference publication Ahmaditeshnizi et al. (2024). Compared to these previous versions, OptiMUS-0.3 uses an LLM-based pipeline instead of the more flexible but error-prone agent-based system of OptiMUS-0.2. Our findings indicate that the increased flexibility in OptiMUS-0.2 led to more errors, outweighing the benefits at the current LLM capabilities. Additionally, nondeterministic errors made maintaining and improving the system challenging. Unlike OptiMUS-0.1, OptiMUS-0.3 uses a modular approach, using only relevant information for each constraint. OptiMUS-0.3 also incorporates Retrieval-Augmented Generation (RAG) and error correction, which were absent in both previous versions.\nOur contributions in this paper are as follows:\n\u2022 We identify 18 important (non-exclusive) types of MILP problems, including scheduling, routing, production planning, and inventory management, which we use as labels for optimization problems. We curate a new dataset, NLP4LP, a comprehensive open-source dataset of 252 optimization problems that ensures adequate coverage of all these problem types, by combining problems from existing datasets with new problems. This dataset also includes problems that range in difficulty and description length, including real-world problems that are an order of magnitude longer that the problem instances in other MILP modeling datasets. Table 1 compares NLP4LP to existing datasets and Section 3 describes NLP4LP.\n\u2022 We develop a modular, LLM-based agent to model and solve optimization problems, which we call OptiMUS-0.3. OptiMUS-0.3 employs a connection graph that allows it to process each constraint and objective independently, which allows the system to solve problems with long descriptions and large data files without excessively long prompts.\n\u2022 We develop several new modules designed to improve the performance of OptiMUS-0.3 and study their impact, including:\n1. Self-reflective error correction. We ask OptiMUS to assess its own confidence in its output, and fall back to a more powerful LLM or to user feedback when OptiMUS is unsure its answer is correct.\n2. Retrieval-augmented generation. We search through a database of constraints and their formulations to find ones similar to the task at hand. We include a few of these as examples in the prompt which OptiMUS passes to the LLM.\n3. Advanced optimization modeling techniques. We teach OptiMUS advanced optimization modeling techniques by prompting it to identify important structures in the problem, including structure of problems and solver features such as special ordered sets, and to use those structures to model and solve the problem more efficiently. We observe consistent improvement in terms of scalability and solution time after proper structure is identified."}, {"title": "2. Related Work", "content": "Optimization problems are mathematically defined by an objective function and a set of constraints. For example, an MILP can be written mathematically as\nminimize \\(\\sum_{j=1}^{n} c_j x_j\\)\nsubject to \\(\\sum_{j=1}^{n} a_{ij} x_j \\ (<, =, >) \\ b_i, i = 1,...m\\)\n\\(l_j \\leq x_j \\leq u_j, j = 1, ..., n\\)\n\\(x_j \\in Z, j \\in I\\)\nAn optimization workflow consists of 1) formulating an optimization problem in mathematical form by identifying its objective and constraints, and then 2) solving the realization of problem from real data, generally using code that calls an optimization solver.\nFormulation is often a challenging task even for experts in optimization. Different formulations can lead to significantly different solving times and enable the use of different solvers or solution techniques (Boyd and Vandenberghe 2004). One important skill for an optimization expert is to identify assumptions or relaxations that allow for casting the problem as a well-studied problem type, such as MILP, which enables the use of well-developed optimization solvers. Crafting such an efficient formulation often requires specialized knowledge (Zohrizadeh et al. 2020, Low 2013, Roub\u00ed\u010dek 2020, Luo et al. 2010, Krarup and Pruzan 1983).\nGiven the formulation, an optimization expert must choose a solver. Each solver has its own interface and functionalities (Achterberg 2019, Diamond and Boyd 2016, CPLEX User's Manual 1987). However, the user manuals for these solvers are often hundreds of pages, making them difficult to fully understand and use."}, {"title": "3. Dataset", "content": "We introduce NLP4LP, a comprehensive open-source dataset of 344 optimization problems. Our goal in creating NLP4LP is to provide the community with examples they can use to design optimization modeling"}, {"title": "4. Methodology", "content": "This section details the design of OptiMUS-0.3. The workflow of OptiMUS-0.3 is outlined in Algorithm 1. For brevity, the term clause refers to a constraint or objective within the problem.\nOptiMUS-0.3 begins by extracting parameters from the problem description (line 2). It then extracts (line 4), and formulates (line 7) the clauses. During clause formulation, the variables, their auxiliary constraints,"}, {"title": "4.1. State", "content": "OptiMUS-0.3 manages and modifies the solution using states saved in JSON format. The state consists of the following components:\n\u2022 Parameters: OptiMUS-0.3 can choose a symbol for each parameter, infer its shape, and define the parameter if it is not explicitly included in the problem statement. Numerical data from the problem statement is omitted from the parameter list and stored separately for later use, ensuring that the parameter list remains concise and easy to include in future prompts.\n\u2022 Clauses: Each clause (objective or constraint) contains a natural language description, a TEX formulation, and a definition code."}, {"title": "4.2. Error Correction", "content": "To build a trustworthy and reliable system using LLMs, it is important to mitigate the impact of LLM hallucinations. In the context of optimization modeling, an LLM might confidently generate incorrect parameters, redundant mathematical constraints, or erroneous code. To address this issue, OptiMUS-0.3 uses two main error correction techniques: reflective prompts and confidence-based user feedback."}, {"title": "4.2.1. Reflective prompts", "content": "LLMs can often identify and fix their mistakes by using reflective prompts Shinn et al. (2023). We analyzed the most common types of mistakes made by LLMs at each step of the process and designed reflective prompts to address each one. Using these prompts significantly reduces the modeling error rate. The resulting substantial improvement to OptiMUS substantiates the claim that domain-specific knowledge can be used to develop LLM applications that outperform general-purpose LLMs (see Section 5.3). The reflective prompts used by OptiMUS-0.3 are as follows:\nParameter Extraction. The model often confuses parameters with variables, misidentifies parameter shapes or misses some parameters. We use the following reflective prompt to correct these errors:\n\u2022 \u201cIs the value of P known or not? Based on that, is it a parameter or a variable?\u201d (see Fig. 7)"}, {"title": "4.2.2. Confidence-based user/LLM feedback", "content": "In the context of real-world optimization modeling, it is exceeding rare for a natural-language problem description to correspond to an unambiguous MILP formulation. Rather, the process of optimization modeling generally involves many cycles of formulation"}, {"title": "5. Experiments", "content": "In this section, we conduct a comprehensive evaluation of OptiMUS-0.3. We begin by detailing the datasets used in our experiments and showcase the superior performance of OptiMUS-0.3 across these datasets, highlighting its strengths. An ablation study demonstrates the impact of different system components on our results, and a sensitivity analysis probes the internal dynamics of OptiMUS-0.3. We conclude this section by identifying failure cases and potential areas for further improvement."}, {"title": "5.1. Overall Performance", "content": "To evaluate the overall performance of OptiMUS, we compare it with standard prompting, Reflexion, and Chain-of-Experts (CoE) Shinn et al. (2023), Xiao et al. (2023). Reflexion is the highest-performing general-purpose framework and CoE is the state-of-the-art method for natural-language optimization modeling. Three main metrics have been used in the literature: accuracy, compilation error (CE) rate, and runtime error (RE) rate. However, a method can generate a totally irrelevant short code that runs, or fix runtime and complication errors by completely removing relevant sections of the code. Hence, we only compare the models' accuracy. Accuracy is defined as the number of instances correctly solved (An instance is considered as correctly solved only if the code runs successfully and the optimal value is correct. Optimal values are obtained from the dataset or by solving the problems manually). Results are presented in Section 5.3. OptiMUS-0.3 outperforms all other methods in all datasets by a large margin. This remarkable performance improvement highlights the importance of modularity and structure compared to a single prompt to solve complex problems using LLMs."}, {"title": "5.2. Ablation Study", "content": "Table 5.3 shows the impact of different components, as well as choice of LLM on the performance of OptiMUS. One interesting observation is the performance drop that occurs when less capable LLMs are used instead of GPT-4-0. Optimization tasks need complicated reasoning, and we believe that smaller models are mostly optimized on simpler tasks. Nonetheless, OptiMUS-0.3 can achieve an acceptable performance using the open-source LLaMa3-70B.\nWe can observe that the constraint extraction error correction step is cruicial to OptiMUS-0.3's performance. The modeling EC, however, is not as important, mainly because most of the modeling errors can later be fixed in the debugging step (while constraints can only be added in the extraction step).\nThe LLM feedback step marginally improves the performance of the system. The debugging step, is particularly important for harder problems, given LLMs often make a few small mistakes when they generate code.\nFig. 12 left shows the relation between the performance and the number of debugging steps for different models. In all models, the first few debugging steps increase the performance, but the gain plateaus afterwards. Fig. 12 shows the composition of different failure reasons for easy and hard problems. Clause extraction and clause modeling are the most common reason of failure."}, {"title": "5.3. Failure Cases", "content": "To understand its strengths and weaknesses, we analyze the most common reasons why OptiMUS fails. We categorize failure cases into the following groups (Fig. 12):\n\u2022 Missing or wrong clauses: OptiMUS generates wrong constraints or objective (e.g., price \u2265 0 where price is a parameter), or fails to extract all of the constraints from the description."}, {"title": "5.4. RAG", "content": "Retrieval Augmented Generation (RAG) enhances the performance of the LLMs by augmenting the prompt with specialized data relevant to the task. It has shown success in Q&A systems that require domain-specific"}, {"title": "6. Optimization Techniques in OptiMUS", "content": "Many of the advances in optimization solvers in the last several decades rely on the fact that solvers are faster when they can exploit particular structures within the optimization problem. One of the main tasks of an optimization expert is to identify these structures so as to choose an appropriate solver or parameter settings. However, detecting useful structures in a given optimization problem can be very challenging,"}, {"title": "6.1. Design of Structure Detector and Advanced Optimization Coding", "content": "OptiMUS maintains a pool of optimization structures which are commonly exploited in optimization software. To detect structure in an optimization problem, OptiMUS iterates through these structures and format them into a structure detection prompt. Within each prompt, the LLM is provided with the description of the structure, explained by an example illustrating how the structure should be exploited. The LLM is asked to decide whether the structure can be applied to the existing formulation. Upon identifying the appropriate structure, the formulation is adjusted to high-light the problem structure.\nCurrently, OptiMUS considers the following three types of structures."}, {"title": null, "content": "Problem structure These structures apply when MILP formulation is applied to solve problems that boil down to some more specific type. Customized solvers often exist for these problems and can dramatically improve solution speed. SAT, traveling salesman (TSP), vehicle routing (VRP) knapsack, network flow, constraint programming fall into this category.\nConstraint (variable) structure These structures are considered within an MILP model and are defined on a subset of variables or constraints. Optimization solvers can exploit these structures to improve performance Gamrath et al. (2016), and customized interface are often available. Using the interface not only reduces the complexity of (and potential for errors in) using auxiliary variables or constraints, but also informs the solver of the existence of structure that can be exploited to solve the problem faster. Typical examples of structure include Special Ordered Set (SOS) Beale and Forrest (1976), indicator variables, semi-continuous variables, and general constraints Bertsimas and Tsitsiklis (1997a).\nLarge-scale optimization technique and advanced optimization coding The aforementioned structures are generally straight-forward to exploit: either changing the optimization solver or modifying a few lines of modeling code suffices. However, in large scale optimization, it is common that exploiting structure becomes highly nontrivial: in these applications, optimization solvers are often embedded into some high-level optimization framework and called as a subroutine. Typical examples including decomposition structure, column generation, and cutting plane methods. To leverage these structures, optimization coding needs to invoke advanced solver interface (for example, call-back, model attribute query and analysis), which goes far beyond modeling itself. OptiMUS implements a dedicated coding agent that adapts available modeling code to some user-specified framework.\nTo illustrate the performance of OptiMUS, we provide showcase examples to demonstrate the efficiency of OptiMUS in optimization structure detection."}, {"title": "6.1.1. Large-scale column/constraint generation", "content": "Consider a general optimization problem\nminimize c(x)\nsubject to x \u2208 Xk, k = 1,...,m (P)"}, {"title": "7. Conclusion", "content": "How can we leverage LLMs to achieve complex goals? This paper interrogates this question in the domain of optimization and showcases the importance of modular structure. We develop OptiMUS-0.3, a modular LLM-based agent designed to formulate and solve optimization problems from natural language descriptions. Our research serves as a proof-of-concept, illustrating the potential for automating various stages of the optimization process by combining LLMs with traditional solvers. To showcase the performance"}, {"title": "Appendix: SCUC problem", "content": "Description. The Security Constrained Unit Commitment (SCUC) is a critical optimization problem in the operation of electrical power systems. Its goal is to schedule generation units in a cost-effective manner while ensuring reliable operation over a specified time period (typically 24 hours), considering the system's physical and operational constraints. This appendix presents a detailed description of the SCUC problem, including its objectives and constraints:"}, {"title": null, "content": "\u2022 Objective. The objective of the SCUC problem is to minimize the total operational cost of the power system. This cost generally includes:\n\u2022 Fuel Cost: The cost associated with consuming fuel to generate electricity.\n\u2022 Start-up and Shut-down Cost: Cost incurred from starting up or shutting down generation units.\n\u2022 Emission Cost: Cost related to the emissions produced by the generating units, if applicable.\nConstraints. The SCUC must satisfy several constraints to ensure the safe and reliable operation of the power system:\n\u2022 Power Balance Constraint: Ensures that the total power generation meets the total demand plus system losses at every interval. Mathematically, this is expressed as the sum of the outputs of all online generators being equal to the sum of the demand and the transmission losses.\n\u2022 Minimum and Maximum Output Limits: Each generator has a minimum and maximum generation capacity when it is online. The SCUC ensures that the output of each unit stays within these bounds.\nRamp-up and Ramp-down Limits: These limits specify the maximum rate at which a generator can increase or decrease its output. They are critical for handling load changes throughout the day.\n\u2022 Unit Start-up and Shut-down Constraints: These constraints handle the logistics of turning units on or off. Start-up constraints may include minimum down times (the minimum time a unit must remain off before it can be restarted) and minimum up times (the minimum time a unit must remain on once started).\n\u2022 Minimum Up and Down Time Constraints: Ensures that once a generator is turned on, it stays on for at least its minimum up time, and similarly, once turned off, it remains off for at least its minimum down time. These constraints are crucial for the mechanical integrity of the generation units.\n\u2022 Reserve Requirements: The system operator must ensure that sufficient spinning and non-spinning reserves are available. These reserves are needed to handle sudden increases in demand or unexpected generator failures."}, {"title": "Appendix: Checking formulation equivalence", "content": "To evaluate the correctness of the formulation of a given optimization problem, OptiMUS evaluates the formulation on a numerical example and checks that the optimal value matches the ground truth and that all constraints are satisfied. This approach runs the risk that an incorrect formulation might return the correct solution on the particular problem data chosen, but not for different problem data. An alternative approach would be to compare the formulation against a reference ground-truth mathematical formulation, and evaluate whether the formulations are the same. This alternative approach has the benefit that it is independent of numerical data, and indeed would not require the availability of any problem data. This benefit is important for complex and realistic industrial problems, for which true problem data may be proprietary and feasible problem data may be difficult to generate.\nUnfortunately, there are several serious obstacles to comparing the formulation of a problem against a reference formulation. First, for most reasonable notions of equivalence, two formulations can both be"}]}