{"title": "ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model", "authors": ["Qiguang Chen", "Libo Qin", "Jinhao Liu", "Dengyun Peng", "Jiaqi Wang", "Mengkang Hu", "Zhi Chen", "Wanxiang Che", "Ting Liu"], "abstract": "Recent advancements in large language models (LLMs) have led to significant successes across various applications, where the most noticeable is to a series of emerging capabilities, particularly in the areas of In-Context Learning (ICL) and Chain-of-Thought (CoT). To better understand and control model performance, many studies have begun investigating the underlying causes of these phenomena and their impact on task outcomes. However, existing explanatory frameworks predominantly focus on isolating and explaining ICL and CoT independently, leading to an incomplete understanding of their combined influence on model performance. To address this gap, we propose the Electronic Circuit Model (ECM), which provides a foundation for developing scalable, learnable policies and improving the management of AI-generated content. Specifically, ECM conceptualizes model behavior as an electronic circuit: ICL is represented as semantic magnetic field to providing an additional voltage following Faraday's Law, while CoT is modeled as series resistors to constrain the model output performance following Ohm's Law. Experimental results demonstrate that the ECM effectively predicts and explains LLM performance across a variety of prompting strategies. Furthermore, we apply ECM to advanced reasoning strategy optimization on a series of tasks, such as the International Olympiad in Informatics (IOI) and the International Mathematical Olympiad (IMO), achieving competitive performance that surpasses nearly 80% of top human competitors.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have made significant strides across various tasks, including code generation, knowledge-based question answering, and complex reasoning [46, 3, 29, 32]. Unlike earlier models that showed incremental improvements, LLMs exhibit emergent capabilities that fundamentally reshape problem-solving. At the core of these capabilities are two critical mechanisms: In-Context Learning (ICL) [2, 11, 31] and chain-of-Thought (CoT) reasoning [26, 41, 5],\nenabling LLMs to adapt dynamically to new challenges and achieve human-comparable learning and reasoning [2, 27, 1]. Specifically, ICL triggers LLMs to generalize information based on task-specific context provided in the input, without requiring parameter updates. In parallel, CoT reasoning allows LLMs to approach complex problems stepwise, enhancing both performance and interpretability. Together, these mechanisms empower LLMs to serve as versatile problem solvers in critical fields such as healthcare and education [14, 25, 16, 18].\nDespite their transformative potential, the mechanism of LLMs' emergent capabilities remains poorly understood. Current research on ICL has uncovered preliminary evidence of how models encode and process contextual information, with studies suggesting latent representations that approximate forms of task-specific meta-learning [38, 36] or topic models [39]. Similarly, CoT research has begun to map the reasoning pathways LLMs employ, providing insights into their demonstration alignment with human cognitive heuristics [24, 37]. Others seek to interpret emergent behaviors using macroscopic mathematical models based on experimental analysis [13, 5]. In practice, ICL and CoT are often integrated, allowing models to adapt to context and solve problems step-by-step [17, 15, 30, 47, 6]. To put it figuratively, combining ICL and CoT is like planting a tree: ICL provides the rich \"soil\" in which the model can absorb and integrate contextual knowledge, while CoT guides its \u201cbranches\" to grow step by step in a clear, structured direction. Together, they create a natural, human-like reasoning process that's both flexible and transparent, enabling models to tackle complex tasks with greater depth and precision. Unfortunately, in the current literature, a unified understanding of the combined effect of ICL and CoT remains limited, which seriously affects correct performance interpretation and controllable result prediction and further constrains the development of principled methodologies for LLM design and deployment.\nTo bridge this gap, we introduce the Electronic Circuit model (ECM), a unified theoretical paradigm that reimagines model performance through the lens of physical circuit systems. Specifically, as shown in Figure 1, we try to conceptualize ICL capabilities as semantic magnetic fields, driving additional voltage gains that correspond to enhanced information absorption, while CoT challenges are modeled as series resistors, introducing predictable constraints akin to circuit losses. Based on these hypotheses, we discover Faraday's Law of ICL and Ohm's Law of CoT in LLMs' reasoning process. By rigorously aligning theoretical circuit power predictions with empirical accuracy results across 3 prompting strategies, 4 task categories, and 13 different LLMs. The ECM successfully establishes a unified quantitative paradigm for predicting and optimizing the behavior of LLMs.\nMoreover, based on the introduction of ECM, we further explain over 10 existing prompt optimization strategies from the perspective of optimizing the magnetic field and optimizing the resistors. And given these perspectives, some phenomena that have not been successfully explained by previous works and more excellent prompt strategies are discovered based on ECM. Notably, our results show that combined with these approaches has achieved breakthroughs in complex domains: LLMs guided by ECM-optimized strategies have outperformed over 80% of human competitors in the International Olympiad in Informatics and the International Mathematical Olympiad. Furthermore, in subjective and exploratory contexts such as academic research development, ECM-optimized strategies have driven significant gains, achieving a minimum 10% improvement in overall human scores.\nIn summary, our contributions are as follows:\n\u2022 To the best of our knowledge, we are taking the first meaningful step to introduce the Electronic Circuit Model (ECM), effectively offering a unified theoretical paradigm to reformulate model performance through the lens of circuit systems.\n\u2022 In this framework, we discover Faraday's Law of ICL and Ohm's Law of CoT in LLMs' reasoning, and further utilize ECM to effectively predict the empirical accuracy and explain the effectiveness of 10 existing strategies from the view of optimizing the magnetic field and optimizing the resistor.\n\u2022 We utilize ECM to explain some open phenomena and to propose more excellent prompt strategies based on ECM. Combined with these approaches, we have achieved breakthroughs in mathematical and code competition and academic research development scenarios. Further, we empirically demonstrate that applying ECM-driven optimizations to LLMs leads to substantial performance gains."}, {"title": "2 Theoretical Model", "content": "This theoretical model shows that model performance (Pout) relies not only on basic voltage from model inherent capabilities (Emodel) but also on external factors like reasoning difficulty (RCOT) and additional voltage from extra demonstrations in ICL (EICL), which are described as follows in detail:\n2.1 Model Inherent Capabilities as Power Supply\nIn our model, we draw an analogy by conceptualizing LLM's inherent capabilities as a power supply that drives computational processes and reasoning tasks (Figure 1). The voltage value Emodel represents the strength of the inherent capability, governing the LLM's capacity to execute a range of tasks. Just as the voltage in an electrical circuit determines the power available to drive various components, the internal capabilities govern its ability to manage increasingly complex inputs.\n2.2 Faraday's Law of In-Context Learning\nInspired by Wang et al. [38], the process of ICL can be conceptualized as the interaction of LLM with contextual data, where it absorbs, retains, and eventually releases semantic information flow."}, {"title": "2.3 Ohm's Law of Chain-of-Thought", "content": "In a parallel vein, Chen et al. [5] have discovered a combination law for LLM reasoning, which aligns with the series formula of electrical resistors after transformation (See in Appendix A). Inspired by this, we conceptualize the difficulty of CoT reasoning as analogous to series circuits. In this framework, each reasoning process introduces a distinct resistor $(R_{cot} = \\sum_{i} R_{i})$, compounding the task's overall difficulty (R\u2081). As illustrated in the right panel of Figure 1, Ohm's law for CoT can be expressed as:\n$I_{model} = \\frac{E_{model} + E_{ICL}}{R_{COT} + R_{o}}$,\nwhere Ro represents the resistance of an output resistor with static resistance value in the circuit, which reflects the difficulty of reasoning conclusion. This formulation quantifies the cumulative effect of reasoning resistors, providing a modular quantitative perspective on cognitive task complexity."}, {"title": "2.4 Model Performance as Output Power of Bulb", "content": "Extending the conceptual model, we equate model performance to the power output of a light bulb in an electronic circuit. Task execution efficiency depends on a nonlinear interaction of internal and external factors, rather than solely on the model's intrinsic capabilities. The output power, Pout, is expressed as:\n$P_{out} = I_{model}^{2} R_{0} = \\frac{(E_{model} + E_{ICL})^{2} R_{0}}{(R_{COT} + R_{o})^{2}}$\nHere, output power represents the model's effective performance, with higher power indicating better task execution, akin to a brighter bulb. The equation highlights that maximizing performance requires enhancing the basic voltage of power supply (Emodel) of LLM, minimizing reasoning resistor (RcoT) in CoT, and optimizing the extra voltage (EICL) provided by ICL. This synergy explains and predicts the model's performance on complex tasks quantitatively."}, {"title": "3 Theoretical Model Verification", "content": "3.1 CoT Meets Ohm's Law\nFirst, we verify whether CoT adheres to Ohm's law. Since the electric current Imodel in Eq. 2 is not directly observable, we instead examine whether Pout is linearly related to true accuracy, thereby indirectly validating CoT Ohm's law. Specifically, to control variables, we remove the ICL and let the model perform zero-shot reasoning step-by-step following the instructions, which satisfies:\n$P_{out} = \\frac{E_{model}^{2} R_{0}}{(R_{COT} + R_{O})^{2}}$ The strong Spearman correlation coefficient between theoretical power (Pout) and observed accuracy (Acc), shown in Figure 2a, is 0.8843, with a p-value below 0.01. This strong correlation suggests difficulty of CoT reasoning actually exhibits resistor-like behavior, making it a reliable predictor of model performance.\n3.2 ICL Meets Faraday's Law\nWe conceptualize contextual demonstrations in ICL as a semantic magnetic field governed by Faraday's Law during reasoning. Under this framework, semantic influence and proximity are quantified by projection length, as illustrated in the lower right of Figure 2b. To validate this hypothesis, we evaluate various metrics for contextual proximity between demonstrations and user"}, {"title": "3.3 ICL and CoT Satisfy a Unified ECM", "content": "In an unprecedented integration, we unify ICL and CoT within a single ECM, offering a comprehensive framework to explain their interaction and collective impact on model performance. We rigorously test this unified model using three distinct retrieval strategies for ICL demonstrations, all of which yields a consistent linear distribution, as illustrated in Figure 2c. This consistent alignment, with a Spearman correlation coefficient of 0.8979 and a p-value approaching zero between calculated power in Eq. 3 and practical accuracy, provides strong empirical evidence for the robustness of our theoretical model. These results confirm that both ICL and CoT not only can be calculated independently but are inherently compatible within the same theoretical structure, offering a powerful new way to describe and predict the behavior of LLM systems.\n3.4 Extension Experiments on Various LLMs and Tasks.\nTo demonstrate the generality of our theoretical ECM, we conduct extension experiments across LLMs configured with varying power supply voltages to represent different capacities. Figure 2d reveals a consistent linear correlation over 0.8348 between theoretical output power estimates and empirical accuracy, confirming the ECM's robustness in predicting performance. Beyond traditional"}, {"title": "4 Explanation based on ECM", "content": "In this section, we mainly pay attention to how to use ECM to explain the effectiveness of existing prompting methods.\n4.1 Explanation for ICL Strategies\nEnhanced embeddings facilitate accurate semantic magnetic field strength estimation and retrieval. Recent advancements in embedding models have shown that improved text represen- tations directly enhance LLM's efficacy in the retrieval process [21]. This improvement is tied to the precise estimation of semantic magnetic field strength. As shown in Figure 3a, we employ three models\u2014BERT [9], RoBERTa [22], and BGE [4]\u2014to represent and retrieve demonstrations in ICL. Among these, BGE achieves the highest degree of alignment, with a Spearman correlation coefficient of 0.9106 between theoretical power and empirical accuracy, significantly surpassing the other models. This result highlights superior embedding ability attributed to the accurate semantic magnetic field estimation.\nMeta Recognition Enhance Magnetic Field Strength Estimation Modeling. The study of Di- dolkar et al. [10] introduces Meta-Recognition, a method leveraging GPT-4 [1] to decompose complex problems into modular sub-capabilities for ICL representation, improving LLMs' performance. We at-"}, {"title": "4.2 Explanation for CoT Strategies", "content": "Direct Answering Introduces Greater Logical Resistor Compared to CoT Recent studies suggest that generating direct answers without intermediary reasoning steps increases cognitive load on the model [13, 17]. We hypothesize that the absence of explicit reasoning pathways introduces significant resistance of \u201clogical resistor,\u201d leading to weaker performance compared to Zero-shot CoT. To test this, we analyzed performance and power correlations for direct answering and Zero-shot CoT on a power-accuracy graph, finding a strong linear correlation of 0.9131 (p-value < 0.01). The average resistance for direct answering is calculated as 10.93, substantially higher than the 1.50 observed for Zero-shot CoT. This discrepancy corresponds to a performance reduction of over 30% for direct answering. These findings indicate that the lack of a CoT framework imposes additional greater logical resistor, hindering the model's reasoning capabilities and resulting in diminished performance.\nTool Usage optimizes computational resistor, and PoT further reduces planning resistor, im- proving model performance. Chen et al. [5] propose that Program of Thought (PoT) and Tool Usage (TU) enhance computational reasoning capabilities to a theoretical maximum, effectively minimizing reasoning complexity to zero, akin to eliminating the resistance to zero. Inspired by this, we investigate the correlation between CoT and TU models under this \"zero-resistance\" assumption. Our analysis revealed that modeling TU as a circuit with zero resistance of computational resistor increased the Power-accuracy Spearman correlation by over 10% compared to the original model, as illustrated in Figure 4b, which validates our hypothesis.\nFurthermore, we hypothesize that PoT, leveraging programming languages, reduces planning resis- tance. As shown in Figure 4b, modeling PoT as a circuit with lower planning resistance achieved a correlation score exceeding 0.9423 between theoretical power and accuracy-significantly higher than TU. This finding highlights the superior effectiveness of PoT in improving model performance.\nSelf-consistency and Inference Scaling Law via Parallel Resistor in Circuits Self-consistency, as demonstrated by Wang et al. [40], utilizes multiple reasoning paths simultaneously, and determines final decision through majority voting, enhancing performance robustness and accuracy. Here, we interpret its effectiveness using a circuit model, which introduce parallelization of original resistors (Rcot), significantly reducing the total system resistance. As shown in Figure 4c, the practical accuracy of the self-consistency strategy aligns closely with the theoretical output power curve, validating the correctness of our proposed model. Recent findings on the Inference Scaling Law [43, 28] further demonstrate that increasing the number of parallel samples, n, substantially improves accuracy. As n grows, the resistance value of CoT resistor approaches zero, optimizing the reasoning process. Further, when coverage introduces an absolutely correct answer verification process with zero resistance of verification resistor, exceeding the gains achieved by self-consistency alone. The alignment between theoretical predictions and empirical results, also evident in Figure 4c, reinforces the validity of this model. These results highlight the central role of self-consistency and inference scaling in enhancing the performance of circuits."}, {"title": "5 Exploration based on ECM", "content": "In this section, we primarily focus on how to use ECM to explore phenomena that have never been well explained and more novel prompting methods.\n5.1 ICL Exploration\nWhen Few-shot CoT Performs Worse than Zero-shot CoT? Despite the growing importance of ICL and CoT, a critical question remains: under what conditions is ICL essential, and when does zero-shot CoT suffice? To investigate this, we systematically examine the interaction between these two strategies. As shown in Figure 5a, our findings reveal a phenomenon we term \u201creverse ICL,\" where demonstrations associated with a negative semantic magnetic field significantly impair the output power of circuits, thereby decreasing the model's reasoning ability and resulting in worse performance compared to zero-shot CoT. This suggests that not all demonstrations contribute positively to the learning process. In contrast, demonstrations with a positive semantic magnetic field lead to an enhancement in performance. These results highlight the critical importance of\""}, {"title": "5.2 CoT Exploration", "content": "Optimize the same proportion of capabilities. The greater the original difficulty of the task corresponding to the capability, the greater the impact on the final performance. We can prove that optimizing a resistor with higher resistance to its original value results in a greater reduction in overall resistance of reasoning resistor Rcot, yielding a more significant performance improvement compared to optimizing a lower resistance (See in Theoretical Proof). As shown in the meta-analysis in Appendix A, when solving questions that demand advanced planning, 01 [28]'s reasoning method, which emphasizes extensive exploration, significantly enhances the most challenging reasoning components. This improvement ultimately boosts overall performance on complex reasoning tasks. However, for tasks where the hardest component requires extensive domain-specific knowledge, insufficient optimization of such knowledge limits performance gains in those domains.\nFine-grained Self-consistency achieves better performance Easily, we can prove that, with a stable supply voltage, we can split a self-consistency ensemble into more fine-grained step-by-step self-consistency by conducting majority voting verification for each step, so that each resistance value of verification resistor can be smaller, and we can obtain larger output power (see Theoretical Proof). Indeed, as the number of self-consistency steps increases, the theoretical power value gradually increases. As shown in Figure 6a, the corresponding performance also gradually increases. At the same time, the corresponding upper bound and lower bound also satisfy the original self-consistency"}, {"title": "6 Best Practice", "content": "To evaluate the impact of sufficient power on LLM performance, we analyzed its effects across three domains: the International Olympiad in Informatics (IOI), the International Mathematical Olympiad (IMO), and Natural Language Processing (NLP) idea generation using the AI-Scientist framework [23], by ensembling strategies outlined in Exploration Section. Our findings, shown in Figure 6c, demonstrate that augmenting the o1-preview model with enhanced power results in significant improvements. The power-enhanced o1-preview outperformed AlphaCode [20] and other state-of-the-art models on the IOI-level test set (code_contests [20]). Crucially, this boost consistently surpassed configurations lacking sufficient power, underscoring its pivotal role in model efficacy. In competitive contexts, such as IOI 2024 and IMO 2024, the powered ol-preview outperformed nearly 80% of global participants, earning silver and bronze medals. This highlights power as a decisive factor in high-stakes scenarios where traditional optimizations often fall short. Beyond correctness-focused tasks, as shown in Figure 6d, sufficient power also enhanced performance in creative challenges. For instance, in NLP-related idea-generation, it facilitates the better generation of novel and impactful research ideas (over 1 point of overall score improvement on average), expanding the potential of LLMs in both objective and subjective tasks."}, {"title": "7 Conclusion & Discussion", "content": "The Electronic Circuit Model (ECM) offers a unified framework for understanding and optimizing the ICL and CoT mechanisms, marking a significant advancement in LLM research. This framework elucidates model behavior while providing a quantifiable approach to enhance LLM performance. Our experiments demonstrate that ECM effectively captures model intricacies, serving as a reliable tool for analyzing and improving AI capabilities. Moreover, applying power-based optimization derived from ECM to advanced reasoning challenges, such as the International Olympiad in Informatics and the International Mathematical Olympiad, yielded superior results compared to leading competitors. These outcomes validate the theoretical foundation of ECM and highlight its transformative potential in improving Al reasoning and learning efficiency, with broad implications for next-generation intelligent systems."}, {"title": "8 Code Availability", "content": "The code and relevant data are available at https://github.com/LightChen233/ECM."}, {"title": "A.1 Theoretical Model", "content": "Faraday's Law of In-Context Learning In-context learning (ICL) can be likened to the behavior of a semantic magnetic field generated by a sub-power source, as described by Faraday's Law. The positive direction of the semantic magnetic field is defined by the query semantic vector Sq. Given N context samples represented by semantic vectors S\u2081, the total semantic magnetic field strength B experienced by the model is the projection of these vectors onto Sq. Mathematically:\n$\\overrightarrow{B_{q}^{0}} = \\sum_{i=1}^{N} \\frac{cos \\Theta_{qi} \\overrightarrow{S_{i}}}{|\\overrightarrow{S_{i}}|}  =\\sum_{i=1}^{N} cos \\Theta_{qi} \\frac{\\overrightarrow{S_{i}}}{|\\overrightarrow{S_{i}}|}$  \nwhere cos Oqi represents the angle between S and S.\nAs new context samples are processed, the semantic field strength f is hypothesized to decay linearly over time:\n$\\Phi_{B}^{0}(t) = - \\lambda \\Phi_{B}^{0}$,\nwhere X is the decay constant representing the rate at which the model forgets or absorbs information. According to Faraday's Law of electromagnetic induction, the rate of change in the semantic magnetic field induces an electromotive force, which drives effective ICL. With a time step At for each reasoning step, the induced EMF, EICL, is:\n$E_{ICL} =  \\frac{ \\Delta \\Phi_{B}^{0}(t) }{\\Delta t} = \\lambda \\Phi_{B}^{0}$.\nSubstituting f into this equation yields:\n$E_{ICL} =  \\lambda \\sum_{i=1}^{N} \\frac{ \\overrightarrow{S_{q}} \\overrightarrow{S_{i}} }{ | \\overrightarrow{S_{i}} |}$ \nIn conclusion, this analogy offers a structured framework to analyze how information flows during ICL. By extending the dynamics of ICL through the principles of electromagnetic induction, we provide a mathematical model to explain how models incorporate and gradually forget information as they process contextual examples."}, {"title": "Ohm's Law of Chain-of-Thought", "content": "In this framework, each sub-difficulty of a model introduces a distinct level of difficulty, analogous to resistors in series. Formally, following Chen et al. [5], the ease with which a model can solve a particular task is represented by its reasoning boundary. Let BCOT denote the overall reasoning boundary of a Chain-of-Thought process, and Bi denote the reasoning boundary of the i-th sub-capability. The overall reasoning boundary can be expressed by the harmonic sum:\n$\\frac{1}{B_{COT}} = \\sum_{i=1}^{K} \\frac{1}{B_{i}}$\nwhere K denotes the number of sub-capabilities. Reasoning resistor, R, quantifies the difficulty of a reasoning process and is mathematically defined as the reciprocal of the reasoning boundary. A higher boundary corresponds to an easier problem and lower resistor. Specifically, we define the sub-difficulty of the i-th sub-task as:\n$R_{i} = \\frac{1}{B_{i}}$"}, {"title": "Substituting", "content": "Substituting this into Equation 8, the total reasoning resistor for the CoT process is expressed as:\n$R_{COT} = \\sum_{i=1}^{K} R_{i}$,\nwhere Rcot represents the combined difficulty, analogous to total resistor in a series circuit. Overall, the CoT reasoning framework is further formalized by the Ohm's law analogy:\n$I_{model} = \\frac{E_{model} + E_{ICL}}{R_{COT} + R_{o}}$\nwhere Ro denotes a output resistor with static resistance value. This modular formulation effectively quantifies cognitive task complexity through combined reasoning resistor."}, {"title": "A.3 Model Verification Experiment Details", "content": "To validate the Ohm's Law assumption in the CoT approach, we conduct the following experiment. To eliminate potential interference from ICL and ensure effective stimulation of CoT capabilities, we append the phrase \u201cLet's think step-by-step!\" to the user query. This adjustment aims to stimulate and isolate the CoT mechanism and prevent ICL-related influences. We then perform sampling based on power levels from the BIGGSM dataset, using 30-unit intervals to map calculated power to accuracy\u00b2. To reduce random errors and ensure sufficient sampling points, we retain data points with at least 10 samples. Accuracy is calculated for each sampling interval to analyze the relationship between power levels and model performance, enabling an effective evaluation of the correlation between sampling power and accuracy.\""}, {"title": "2The", "content": "The absolute power values are meaningless due to inconsistencies in semantic space scaling across encoding methods. However, their relative values within a method correlate positively with real accuracy."}, {"title": "A.4 Model Explanation Experiments", "content": "4We remove those generated samples are totally the same to keep the independent sampling."}, {"title": "Substituting", "content": "Substituting this into Equation 8, the total reasoning resistor for the CoT process is expressed as:\n$R_{COT} = \\sum_{j}^{k} R_{i}$,\nwhere i denotes the sampling size, $R^f_{i}$ represents the small and fine-grained verification resistance for j-th step, and $R_{i}^r$ corresponds to smaller reasoning resistance for j-th step for i-th sampling. The total resistance can be broken down into resistance of sub-step resistor as $R_{COT} = \\sum_j R_{i}^r$.\nWe aim to demonstrate that our approach indeed optimizes the total resistance, i.e., $R_{all}^{fine} < R_{all}$. To prove this, we need to show that $R_{all}^{fine} - R_{all} < 0$. The proof is as follows:\n$R_{all}^{fine} - R_{all} = \\sum_{j}^{k} R_{i} - R_{S} + \\sum_{j}^{k} \\sum_{i}^{k} \\frac{1}{R_{i}} - R^r -\\sum R_{S}$.\nIt is evident that verifying correctness at the individual step level is simpler than verifying the correctness of the entire chain, so $\\sum \\frac{1}{R_{i}} < R_{S}$. Therefore, $R_{all}^{fine} - R_{all} < 0$, indicating that the total resistance of the circuit has been optimized."}, {"title": "CProof", "content": "To compute the derivatives of $P_{model}$ with respect to $R_{COT}$, we start with the given expression:\n$P_{model} = \\frac{(E_{model} + E_{ICL})^2 R_{o}}{(R_{COT} + R_{o})^2}$,\nAccording to Eq. 10, let $R_{COT} = \\frac{R_1}{k} + R_2$, where $R_1 \\gg R_2$, if R\u2081 is improved to $\\frac{R_1}{k'}$, the power can be calculated as:\n$P'_{model} = \\frac{(E_{model} + E_{ICL})^2 R_{o}}{(\\frac{R_1}{k'} + R_2 + R_{o})^2}$"}, {"title": "The", "content": "The corresponding power improvement is:\n$\\Delta \\P_{model}^1 = \\P_{model} - P_{model} = \\frac{(E_{model} + E_{ICL})^2 R_{o}}{(\\frac{R_1}{k'} + R_2 + R_{o})^2}$\n$= \\frac{(E_{model} + E_{ICL})^2 R_{o}}{(\\frac{R_1}{k'} + R_2 + R_{o})^2} = \\frac{1}{(\\frac{R_1}{k'} + R_2 + R_{o})^2} = \\frac{1}{\\frac{R_1}{k'} + R_2 + R_{o})^2} = (E_{model} + E_{ICL})^2 R_{o} (- \\frac{1}{(\\frac{R_1}{k'} + R_2 + R_{o})^2})$\nSimilarly, if R2 is improved to the original $\\frac{R_1}{k'}$, the power improvement can be calculated as:\n$\\Delta \\P_{model}^2 = (E_{model} + E_{ICL})^2 R_{o} (\\frac{1}{(R_1 + R_2 + R_{o})^2} \\frac{1}{(\\frac{R_1}{k'} + R_2 + R_{o})^2})$\nTo determine which improvement has a greater effect, consider:\n$\\Delta \\P_{model}^1 = \\Delta \\P_{model} = (E_{model} + E_{ICL})^2 R_{o} (\\frac{1}{(\\frac{R_1}{k'} + R_2 + R_{o})^2} \\frac{1}{(\\frac{R_1}{k'} + R_2 + R_{o})^2})$\nDefine:\n$A = \\frac{R_1}{k'}$, B = R_1 + \\frac{R_1}{k'} + R_{o}$,\nThe fractional difference simplifies as:\n$\\frac{1}{A}$ - $\\frac{1}{B} = \\frac{B^2-A^2}{A^2-B^2}$ - \\frac{1}{B^2}$\nWe need to prove that for R1 \u226b R2 whether B2 \u2013 A2 larger or smaller than zero. Now, let's calculate B2 \u2013 A2:\n$\\B^2 - A^2 = (B - A)(B + A)$\nwhere:\n$B-A=(R_1+\\frac{R_1}{k}+R_{o})-(\\frac{R_1}{k}+R_2+R_{o})$\n$\\= R_1+\\frac{R_1}{k}+\\frac{R_1}{k} - R_1(1-1)+\\frac{R_1}{k}$\nand:\nB+A=$(R_1+\\frac{R_1}{k}+R_{o})+(\\frac{R_1}{k}+R_2+R_{o})$\n$\\= R_1+\\frac{R_1}{k}+R_2+R_{k}+2+R_{o}$\nAnalysis of the Sign of B2 \u2013 A2:\n$B^2 - A^2 = (B - A)(B + A)$\nWe only need to examine the sign of B - A, since B + A > 0 holds true at all times.since R1 \u226b R2, and 1 1 > 0 for n > 1, we have:\n$\\R_1 (1-1)-R_2(1-1)>0$\n$(R_1-R_2)(1->0$\nso \\P_\\\n$\\triangle - \\frac{\\Delta \\P_{model}^1}{\\Delta \\P_{model}^2} > 0$\nTherefore, The greater the original difficulty of the task corresponding to the capability, the greater the impact on the final performance."}]}