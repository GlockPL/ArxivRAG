{"title": "Demystifying Issues, Causes and Solutions in LLM Open-Source Projects", "authors": ["Yangxiao Cai", "Peng Liang", "Yifei Wang", "Zengyang Li", "Mojtaba Shahin"], "abstract": "With the advancements of Large Language Models (LLMs), an increasing number of open-source software projects are using LLMs as their core functional component. Although research and practice on LLMs are capturing considerable interest, no dedicated studies explored the challenges faced by practitioners of LLM open-source projects, the causes of these challenges, and potential solutions. To fill this research gap, we conducted an empirical study to understand the issues that practitioners encounter when developing and using LLM open-source software, the possible causes of these issues, and potential solutions. We collected all closed issues from 15 LLM open-source projects and labelled issues that met our requirements. We then randomly selected 994 issues from the labelled issues as the sample for data extraction and analysis to understand the prevalent issues, their underlying causes, and potential solutions. Our study results show that (1) Model Issue is the most common issue faced by practitioners, (2) Model Problem, Configuration and Connection Problem, and Feature and Method Problem are identified as the most frequent causes of the issues, and (3) Optimize Model is the predominant solution to the issues. Based on the study results, we provide implications for practitioners and researchers of LLM open-source projects.", "sections": [{"title": "1. Introduction", "content": "With the advancements of Pre-trained Language Models (PLMs) in recent years, there has been a significant breakthrough in the capacity of Language Models (LMs) to handle very large-scale data, which has led to the emergence of Large Language Models (LLMs) (Hou et al., 2024; Zhao et al., 2023a). LLMs refer to neural network language models trained on massive text datasets with billions of parameters. The most advanced LLMs to date have demonstrated remarkable language comprehension and generation capabilities (Zheng et al., 2023).\nSince the release of ChatGPT in 2022 (OpenAI, 2022), there has been a noticeable increase in research related to LLM (Zhao et al., 2023a). The Software Engineering (SE) research community has also extensively used LLMs as tools to solve SE tasks. This is evident in recent review papers on LLM in SE. For example, Zheng et al. collected relevant literature on LLMs from seven literature databases, categorizing these papers according to the SE tasks involved, then reviewed the current research status of LLMs from the perspective of the seven major tasks in software development (Zheng et al., 2023). In addition, Hou et al. conducted a systematic literature review on the application of LLMs in SE (Hou et al., 2024). They investigated which LLMs were utilized for SE tasks, and the collection and preprocessing of SE-related datasets for these models. They also investigated strategies for optimizing and evaluating LLM performance in SE, and the SE tasks LLMs successfully addressed.\nConversely, software practitioners are increasingly integrating LLMs as components within their software systems (Weber, 2024; Liu et al., 2023). These systems, known as \"LLM-based Systems\", utilize the capabilities of LLMs to perform tasks that typically require substantial coding effort (Weber, 2024). This trend is also evident in open-source software (OSS) projects, primarily due to the emergence of open-source LLMs and frameworks. For example, LangChain, an open-source software framework for building applications based on LLMs, is currently receiving significant attention from practitioners (Chase, 2024). In addition, Microsoft's semantic-kernel, an SDK that integrates LLMs into popular programming languages such as C#, Python, and Java, has also received widespread attention (Microsoft, 2024). In this paper, we refer to OSS projects that leverage LLMs as LLM open-source projects.\nDespite the increasing number of LLM open-source projects, there is no systematic research on the issues experienced in LLM open-source project development, the causes of the issues, and potential solutions from the perspective of practitioners. This study aims to address this gap by studying approximately 1000 GitHub closed issue discussions from LLM open-source projects. Considering that GitHub is presently the largest hosting platform for open-source projects in the world, and numerous related studies have utilized community data from open-source software for empirical software engineering work, we have decided to select LLM open-source projects from GitHub.\nOur findings show that: (1) Model Issue is the most common issue faced by practitioners, (2) Model Problem, Configuration and Connection Problem, and Feature and"}, {"title": "2. Methodology", "content": "Our study aims to identify the issues in developing and using LLM open-source software and to determine the causes of these issues as well as possible solutions. With this aim in mind, we formulate three RQs to guide the subsequent phases of the methodology, as shown in Fig. 1. The RQs and their rationales are detailed in Section 2.1."}, {"title": "2.1. Research Questions", "content": "RQ1: What issues do OSS practitioners encounter when developing and using LLM open-source software?\nRationale: As mentioned in Section 1, remarkable advances in LLMs (Zhao et al., 2023a) have led to a growing number of open-source projects leveraging LLMs as one of their core functional components (i.e., LLM open-source projects). The answer of this RQ can provide an overall picture of the issues that OSS developers experience when developing LLM open-source projects. It also opens new directions for subsequent research on how these issues can be resolved.\nRQ2: What are the underlying causes of these issues?\nRationale: After collecting the issues currently faced by practitioners as identified in RQ1, it is important to further identify the causes of these issues. By identifying the causes, the study can provide insights for finding solutions and inspire subsequent refinement and optimization of both LLM open-source software and the LLMs.\nRQ3: What are the current and potential solutions to address these issues?\nRationale: This RQ aims to understand how practitioners address the issues they encounter. The answer to this RQ can identify the most commonly used solutions, and provide various potential solutions from practitioners to the issues collected in RQ1. Ultimately, by exploring existing solutions to these issues, the study can provide guidance for the optimization of the software, thereby enhancing its performance."}, {"title": "2.2. Data Collection", "content": "We collected the data for our study from GitHub, which is currently the largest platform for hosting open-source software projects. In addition, every project on GitHub has an \"Issues\" page, which provides a platform for developers and users of the project to raise issues encountered while developing and using the software, and to discuss the identification, tracing, and resolution of these issues with other developers and users.\nTo collect data as comprehensively as possible, we did not set a start date for the source of the data. The date we conducted the data search is December 11, 2023, and we collected the data that were created before this date. The first author utilized a keyword search approach, connecting the search terms \u201cLLM\u201d and \"Large Language Model\" with an \"OR\" logic, and then searched for projects on the entire GitHub. Any project that contains the search terms (e.g., project description, tags) was retrieved.\nAfter obtaining the search results, we found that although many projects include \u201cLLM\u201d or \u201cLarge Language Model\" terms, they do not use LLMs as components to implement their functionality. For example, some project are to teach LLMs without using LLMs in the projects."}, {"title": "2.3. Data Labelling and Sampling", "content": "After collecting closed issues from the 15 LLM open-source projects, we conducted data labelling to identify issues suitable for our study. The closed issues we expected should contain specific information related to the issues that practitioners encountered while developing or using LLM open-source software. Then, on the basis of the labelling results (as detailed in Section 2.3.1 and Section 2.3.2), we selected a representative data sample (as detailed in Section 2.3.3) to construct the dataset for data extraction."}, {"title": "2.3.1. Pilot Data Labelling", "content": "To minimize potential personal biases, the first and third authors independently conducted a pilot data labelling. We randomly selected 50 closed issues from all closed issues, and then the first and third authors independently labelled them. The two authors labelled the data that contain information related to issues arising during the development or use of LLM open-source software. The inter-rater consistency on data labelling results between the two authors was measured using the Cohen's Kappa coefficient (Cohen, 1960), yielding a value of 0.838, which indicates a reasonable level of data labelling consistency between the two authors. For any disagreements or conflicts in the pilot data labelling results, the two authors discussed together with the second author to reach a consensus. Finally, wo got 32 issues out of 50 issues are considered relevant. The results of pilot data labelling were compiled and recorded in MS Excel files (Cai et al., 2024)."}, {"title": "2.3.2. Formal Data Labelling", "content": "The first author then conducted the formal data labelling. In this process, we excluded the issues not related to our study. The projects we selected utilized LLMs to achieve the main functions of the software. However, some issues raised by practitioners may not be related to the problems with the projects. For example, some practitioners only raised an issue to chat with others or to learn how the features of GitHub, like a practitioner simply submitted an issue titled \"hi\" as a greeting, without any content related to the software. We only kept those issues related to the problems that practitioners encountered during the development and use of LLM open-source software. Ultimately, the first author collected a total of 14,476 closed issues. The results of formal data labelling were compiled and recorded in MS Excel files (Cai et al., 2024)."}, {"title": "2.3.3. Data Sampling", "content": "We found that the dataset comprising a total of 14,476 closed issues was too large for manual data extraction. Therefore, we decided to select a suitable number of closed issues. We randomly selected 994 closed issues to form a representative set as our dataset for data extraction with a 95% confidence level and a 3% margin of error (Israel, 1992)."}, {"title": "2.4. Data Extraction", "content": "To answer the three RQs presented in Section 2.1, we defined a set of data items for data extraction, as shown"}, {"title": "2.4.1. Pilot Data Extraction", "content": "We randomly selected 50 closed issues from our dataset. Next, the first author independently conducted the pilot data extraction on the 50 issues. The results of pilot data extraction indicated that all three data items (see Table 2) could be extracted from our dataset. Based on the pilot data extraction results, we reached a consensus and defined the following rules for formal data extraction: (1) In principle, only one issue can be extracted from each closed issue. If there are multiple issues that can be extracted, we record the first issue discussed. (2) If there are multiple causes mentioned in a closed issue, we record all the causes identified by the reporter and the development team. (3) If there are multiple solutions mentioned in a closed issue, we record all the solutions identified by the reporter and the development team."}, {"title": "2.4.2. Formal Data Extraction", "content": "After completing the pilot data extraction, the first author independently conducted the formal data extraction on the dataset to extract the data based on the data items defined in Table 2. If there were any questions during the data extraction process, the first author discussed these questions with the second author to resolve the doubts. After the first author completed the formal data extraction, the second author reviewed the extraction results and then discussed the results with the first author to reach a consensus on the inconsistencies. The first and second authors conducted multiple rounds of reviews and revisions on the data extraction results to obtain the final results. The data extraction results were compiled and recorded in an MS Excel file (Cai et al., 2024).\nNot all closed issues had a corresponding cause and solution which could be extracted. For some closed issues, the discussion content of the issues was too vague to discern specific information (i.e., cause or solution) that could be extracted. Moreover, if an issue of a project is not discussed or updated for a long period, it will be automatically closed and turn into a closed issue, making it impossible to extract valid cause and solution. An issue may also be temporarily closed due to its low priority for resolution. Similarly, an issue might be too complex to identify its causes and solutions."}, {"title": "2.5. Data Analysis", "content": "After completing the data extraction, we conducted data analysis to answer the three RQs formulated in Section 2.1. We employed Open Coding and Constant Comparison methodologies for data analysis, which are commonly used methodologies within Grounded Theory for qualitative data analysis in software engineering research Stol et al. (2016). In Grounded Theory, Open Coding refers to the initial process of data analysis. In this process, researchers meticulously"}, {"title": "3. Results and Interpretation", "content": "In this section, we report the study results of the three RQs and provide their interpretation.\nFor the Issue, Cause and Solution taxonomies, we provide a two-tier classification, i.e., categories and types. We also provide brief descriptions of the types under each category. To show the relationship between issues and their causes and solutions, we present the mapping relationships between the Issue categories and the Cause categories, as well as between the Issue categories and the Solution categories. It should be noted that only closed issues from which a cause has been extracted are represented in the issue-cause mapping. Similarly, only closed issues from which"}, {"title": "3.1. Category of Issues (RQ1)", "content": "Fig. 2 presents the taxonomy of the issues extracted from the dataset. It can be observed that Model Issue (24.55%) accounts for the majority of issues encountered by practitioners of LLM open-source projects. In addition, a substantial number of practitioners have raised Component Issue (9.26%) and Parameter Issue (9.26%). There is also a portion of practitioners who have encountered Answer Issue (8.25%), which indicates that they did not get answers they want from LLM open-source software, while smaller percentages (less than 8%) were identified for Performance Issue (7.14%), Code Issue (6.74%), Installation Issue (4.93%), Documentation Issue (4.73%), Configuration Issue (4.53%), Network Issue (4.43%), Memory Issue (3.92%), Prompt Issue (3.62%), Security Issue (3.52%), GUI Issue (2.72%), and Database Issue (2.41%)."}, {"title": "3.1.1. Model Issue (24.55%)", "content": "Model Issue refers to issues related to the models that practitioners encounter while developing and using LLM open-source software. This category encompasses the following ten types.\n\u2022 MODEL RUNTIME ISSUE refers to the issues that arise during the runtime of LLMs. The core functions of LLM open-source software are performed by the integrated models. Therefore, anomalies or crashes in the models during runtime have a significant impact on the operation of LLM open-source software. For example, a user found that \u201cthe model is loaded into memory without any errors, but crashes on generation of text\" (text-generation-webui #2926).\n\u2022 MODEL ARCHITECTURE ISSUE refers to issues related to the design and implementation of LLM architecture. Issues in this type are primarily manifested in unreasonable architectural design (e.g., layers) and unsuitable implementation of mechanisms (e.g., model training), leading to anomalies or failures in the training and use of LLMs. For example, a user received a message that \u201cInstructorEmbedding is not found\u201d, which is a component used to form the embedding layer of the model (langchain #867).\n\u2022 MODEL LOADING ISSUE refers to the issues that arise during the loading of LLMs, such as loading failures, incomplete loading, loading the wrong model. Once the model fails to load, the subsequent functions of LLM open-source software cannot proceed normally. For example, a user reported that \"an error was thrown when loading with Exllama or Exllamav2 even though pip indicates they are installed\" (text-generation-webui #4293).\n\u2022 MODEL TRAINING ISSUE refers to the issues that arise during the training of LLMs. These issues include inefficient training algorithms, the need for optimization of model training algorithms, sudden interruptions or crashes during training. For example, a user asked \u201cis DEiT-3 trained from scratch only based on the BEIT initialization algorithm or using the similar stagewise pre-training strategy introduced in VLMo\", which"}, {"title": "3.1.2. Component Issue (9.26%)", "content": "Component Issue refers to the issues that arise within or between the components of LLM open-source software. These issues may affect user experience and stability of LLM open-source software. This category encompasses the following four types.\n\u2022 COMPONENT INCOMPATIBILITY refers to incompatibility issues between components of LLM open-source software, such as version incompatibility, incompatibility in data types, or even functional incompatibility. For example, a user reported that \"function calls do not work with Azure OpenAI currently due to differences between the OpenAI API and AzureOpenAI\" (autogen #78).\n\u2022 COMPONENT MISSING ISSUE refers to the need for additional or extended components of LLM open-source software. The emergence of new requirements that necessitate a new component, or the realization that an essential function lacks a component for implementation. For example, to \u201cimplement real-world, persistent Document Store for v2\", a user suggested that the haystack team integrate a component called \"ElasticSearch 8\", which is an open-source search engine (haystack #5326).\n\u2022 COMPONENT FAILURE refers to the malfunctiones and crashes of components. Such failures constitute a significant issue affecting the functionality and the user experience of LLM open-source software. For example, a user reported that the API \"crashed on the second response\" when using a model named ggml-vicuna-7b (text-generation-webui #816).\n\u2022 COMPONENT SELECTION ISSUE refers to the issues of choosing the right components in the development of LLM open-source software. When implementing the specific features, the selection of components is crucial. For example, a user requested the langchain team to support a \u201cmulti-core loader\", because the loader called DirectoryLoader was \u201cusing a single\""}, {"title": "3.1.3. Parameter Issue (9.26%)", "content": "Parameter Issue refers to issues concerning the parameters of LLM open-source software. The definition, input, passing, and output of parameters are critical steps in the process of the development and use of LLM open-source software. The fact that Parameter Issue ranks third among all categories of issues emphasizes its importance. This category encompasses the following three types.\n\u2022 PARAMETER SETTING ISSUE refers to the issues with the settings of parameters within LLM open-source software. Improper parameter settings may result in poor performance or even anomalies. The settings of parameters include not only the values of the parameters but also their formats, names, length constraints, and the definitions of their data structures. Ensuring reasonableness and consistency of parameter settings is crucial for facilitating subsequent passing and calculation. For example, a user suggested the langchain team that parameters, such as \"OPENAI_BASE_URL, OPENAI_API_KEY, CLAUDE2_BASE_URL, and CLAUDE2_API_KEY\", can be replaced to increase flexibility in handling the integration and use of other APIs (ChatDev #6).\n\u2022 MISSING KEY PARAMETER refers to the issues arising from the absence of certain parameters. There is complex logic for parameter passing and calculation within LLMs. The lack of key parameters can significantly impact the training and effectiveness of the model. For example, a user reported that \"the parameter 'sources' is empty but it should be included in a list called 'result' as a string\" (langchain #5536).\n\u2022 PARAMETER PASSING ISSUE refers to the issues that occur during the process of parameter passing in LLM open-source software. These issues manifest in aspects such as type conversion of parameters, the composition of parameter sets, and data formatting during the passing process. For example, a user was \u201cunable to provide 'llm_chain' to initialize_agent() while initializing the agent\" (langchain #4437).\nInterpretation: Parameter Issue is a critical concern in the development and use of LLM open-source software.\""}, {"title": "3.1.4. Answer Issue (8.25%)", "content": "Answer Issue refers to issues concerning the responses provided by LLM open-source software to the questions given by users. The effectiveness of the responses of LLM open-source software is a crucial characteristic that reflects the user experience of the software. This category encompasses the following four types.\n\u2022 POOR-QUALITY ANSWER refers to responses produced by LLM open-source software that are correct but low quality, such as being overly verbose with excessive repetition, failing to generate responses according to the specified formats provided by users, and providing responses that are too brief and lack details. For example, when a user asked \"a few questions in a conversation, there is no context between questions\", which indicates that the memory of the models is too short to give satisfactory answers (ollama #8).\n\u2022 INCORRECT ANSWER refers to responses where wrong answers are provided by LLM open-source software, such as responses that are not pertinent to the question asked, factually inaccurate, or illogical. For example, a user reported that \u201cthe results both from Azure OpenAI and from OpenAI are really random and have nothing to do with prompts\", which indicates that answers are given randomly (semantic-kernel #1337).\n\u2022 BLANK OUTPUT refers to issues that LLM open-source software fails to provide a response, resulting in an empty answer, or is unable to successfully deliver a response. For example, a use reported that the answers given by the model \"are all blank\u201d (FastChat #2319).\n\u2022 ANSWER LANGUAGE ISSUE refers to the inadequacy in the variety of human natural languages supported by the LLM open-source software. If the software could support a broader range of human languages, it would significantly enhance user experience. For example, a user asked the gpt4all team to \"support Chinese model\" (gpt4all #1199).\nInterpretation: Answer Issue is a kind of quality issue related to answers generated by LLM open-source software. It is evident that the most prominent concerns in this category are POOR-QUALITY ANSWERS (35) and INCORRECT ANSWERS (28). Answer Issue arises due to the limitations"}, {"title": "3.1.5. Performance Issue (7.14%)", "content": "Performance Issue refers to issues concerning the performance of LLM open-source software. This category encompasses the following four types.\n\u2022 SLOW RESPONSE refers to the issues in which LLM open-source software shows a delayed response to requests. The response time significantly impacts the user experience. Sometimes, practitioners even encounter timeouts when waiting for answers. For example, a user reported that the application, which enables users to run and manage LLMs on their local machines, \"got stuck\u201d when running it and had to \"quit manually\" (ollama #1382).\n\u2022 PERFORMANCE OPTIMIZATION ISSUE refers to the discussions on how to enhance the performance of LLM open-source software. Performance optimization of LLM open-source software has been a concern of practitioners. For example, one user reported that \u201cour deployment gives only 50 English words in 6 seconds\", and the user inquired with the development team about how to optimize the output token per second (FastChat #1041).\n\u2022 UNSTABLE PERFORMANCE refers to the instability of the performance of LLM open-source software under varying conditions. The performance of LLM open-source software may deteriorate due to longer execution time, or significant performance discrepancies may arise when execute on different devices or software environments. For example, a user reported that the software \"started lagging when it got past 3 lines and can take up to a minute to complete\", which indicates that the response time of the software decreased over time (text-generation-webui #1542).\n\u2022 PERFORMANCE EVALUATION ISSUE refers to the discussions on how to evaluate the performance of LLM open-source software. Practitioners attempt to discuss and establish a unified set of evaluation criteria to measure the performance of LLM open-source software. For example, a user wanted to know the performance of the model \u201ccompared to vicuna-13b-v1.3 model\" and the ranking of this model in the Hugging Face (HF) community, which reflects concerns of users about the performance evaluation of the model (FastChat #2152).\nInterpretation: Performance Issue mainly stems from the inadequacies and instability of the model performance. Due to SLOW RESPONSE (27) and UNSTABLE PERFORMANCE (14) of LLM open-source software, PERFORMANCE\""}, {"title": "3.1.6. Code Issue (6.74%)", "content": "Code Issue refers to the programming issues of LLM open-source software. This category encompasses the following five types.\n\u2022 FUNCTION ISSUE refers to issues concerning the implementation of functions of LLM open-source software, such as the definition of the parameter list of the function, the naming of the function, issues within the code logic of the function, code syntax errors. For example, a user reported that the method \u201c\u201cmax_marginal_relevance_search()' was not implemented", "IKernel\", in order to improve the data extraction abilities of models (semantic-kernel #3195).\n\u2022 OBJECT ISSUE refers to the issues with the instantiation and management of objects within LLM open-source software, which includes issues related to the manipulation of existing objects, management of object life cycles. For example, a user reported that \\\"property 'id_hash_keys' of the 'Document' objects cannot be set\", which led to the failure of metadata comparison (haystack #1920).\n\u2022 CODE LANGUAGE SUPPORTING ISSUE refers to requirements to support more programming languages in LLM open-source software. For example, a user asked the langchain team \\\"to support the kotlin language\" in order to ensure \u201cthe safety and reliability of the software\", which is an open-source framework for building LLM applications (langchain #4963).\n\u2022 CODE STYLE STANDARDIZATION refers to the discussion of normalizing coding styles. For example, a user suggested to \\\"standardize our code\" of the software, which is used for building end-to-end question-answering systems and retrieval-augmented generation models (haystack #2022).\nInterpretation: Code Issue highlights the programming problems within LLM open-source projects. These concerns range from the definition and implementation of functions\"\n    },\n    {\n      \"title\": \"3.1.7. Installation Issue (4.93%)\",\n      \"content\": \"Installation Issue refers to the issues that arise during the installation of LLM open-source software. This category encompasses the following two types.\n\u2022 SETUP ERROR refers to the issues encountered by practitioners during the installation or initialization process of LLM open-source software. For example, a user reported that the software, which is a localized open-source LLM, was \u201cnot working on Windows after fresh installation\" (gpt4all #400).\n\u2022 DOWNLOAD ERROR refers to the issues that arises during the process of downloading LLM open-source software. For example, a user reported that \\\"the download speed falls to 100 KB or something\" after 5% when downloading the localized LLM (gpt4all #734).\nInterpretation: Installation Issue reflects the errors and anomalies that occur during the download and initialization of LLM open-source software. LLM open-source projects require compatibility with specific hardware, operating systems, and machine learning libraries. SETUP ERROR (38) as the dominant type of Installation Issue highlights the demands that LLM open-source software places on the deployment environment.\"\n    },\n    {\n      \"title\": \"3.1.8. Documentation Issue (4.73%)\",\n      \"content\": \"Documentation Issue refers to issues with the writing and management of documentation related to LLM open-source projects. This category encompasses the following five types.\n\u2022 MISSING DOCUMENTATION reflects a lack of relevant documentation in LLM open-source projects, which leads to barriers for practitioners in developing and using the software. For example, a user suggested the FastChat team \\\"adding tutorials to increase token limits for self-deployment\\\" in order to let the model be able to generate longer answers (FastChat #638).\n\u2022 DOCUMENTATION CONTENT ERROR reflects that some parts of the documentation of LLM open-source projects contain inaccuracies or errors. Documentation content does not align with reality or there are inconsistencies among different parts of the documentation. For example, a user posted the screenshots of two documents that introduce the evaluation results of the models and asked \\\"which one is correct\\\", showing inconsistency between the two documents (FastChat #1782).\n\u2022 OUT OF DATE DOCUMENTATION reflects that certain portions of the documentation of LLM open-source projects are outdated. It shows that during the\"\n    },\n    {\n      \"title\": \"3.1.9. Configuration Issue (4.53%)\",\n      \"content\": \"Configuration Issue refers to issues concerning the configuration of LLM open-source software. This category encompasses the following two types.\n\u2022 CONFIGURATION SETTING ERROR refers to the issues arising from setup settings of LLM open-source projects, including environmental variables, system configurations, component configurations, and machine learning library configurations. For example, a user received a message that \"Ray Dependency Conflict\" while configuring a distributed computing framework named Ray (haystack #1657).\n\u2022 CONFIGURATION FILE ERROR refers to issues concerning configuration files of LLM open-source projects, including missing configuration files, reading and loading errors of configuration files. For example, a user was \u201cunable to gather the deployment name from the .env file\", which led to the failure of deploying the localized model (semantic-kernel #1474).\nInterpretation: Configuration Issue covers issues related to\"\n    },\n    {\n      \"title\": \"3.1.10. Network Issue (4.43%)\",\n      \"content\": \"Network Issue refers to network environment issues concerning LLM open-source software, including issues with network connections and servers. This category encompasses the following two types.\n\u2022 NETWORK CONNECTION ISSUE refers to the errors concerning network connections when using LLM open-source software, including network connection interruptions, connection timeouts, connection errors, and configuration issues related to network connection. For example, a user \u201ccannot connect to remote host\" of an open-source search engine, when performing word embeddings (langchain #7995).\n\u2022 SERVER ISSUE refers to the issues in the servers of LLM open-source software, including server connection anomalies, server out of service, and server optimization problems. For example, a user reported a \u201clangchain-server error": "hen preprocessing dataset of the model (langchain #822).\nInterpretation: Network Issue covers the network-related"}, {"title": "3.1.11. Memory Issue (3.92%)", "content": "Memory Issue refers to issues concerning memory management and the data storage in memory when using LLM open-source software. This category encompasses the following two types.\n\u2022 OUT OF MEMORY refers to the situation where available memory is exhausted and no additional memory can be allocated for LLM open-source software, which indicates that the computational and storage resources required to run LLM open-source software are substantial. For example, a user received an error message that \"OutOfMemoryError: CUDA out of memory. \u2013 train dolly v2\" (dolly #100).\n\u2022 STORAGE ISSUE reflects the data storage issues in memory encountered by practitioners of LLM open-source software, which primarily involve issues related to memory allocation strategies, anomalies or failures in data storage. For example, a user reported that \"memory allocation error occurred\u201d when trying to \"inference on the given model\" (unilm #729).\nInterpretation: Memory Issue covers anomalies in the al-"}, {"title": "3.1.12. Prompt Issue (3.62%)", "content": "Prompt Issue refers to issues concerning the prompts input into LLM open-source software and the process of inputting prompts. This category encompasses the following two types.\n\u2022 PROMPT FAILURE refers to issues encountered when inputting prompts into LLM open-source software, including exceeding the length limit of prompts, using an invalid prompt data type, containing invalid characters in prompts, or errors when uploading prompts. For example, a user reported that \"the error of 'valid_languages' occurred\" when uploading a PDF document as a prompt (haystack #874).\n\u2022 PROMPT PARSING ISSUE refers to abnormalities and errors encountered by practitioners of LLM open-source software when parsing prompt content. For example, a user reported that the software \"only recognized the first four rows of a CSV file\u201d when chatting with the model (langchain #3621).\nInterpretation: Prompt Issue covers issues that arise when"}, {"title": "3.1.13. Security Issue (3.52%)", "content": "Security Issue refers to security problems or vulnerabilities in LLM open-source software, including flaws, weaknesses, or errors within the system that could be exploited by malicious users to compromise its security. This category encompasses the following five types.\n\u2022 USER PERMISSION ISSUE refers to issues regarding user permissions of LLM open-source software. Many users have expressed concerns regarding user permissions, questioning whether user permissions are either insufficient or excessive. For example, a user had \u201cno right to download checkpoint", "it seems that GPT4ALL disallows\\\" the interaction between the local webpage and the model, \\\"and the access is blocked by CORS\" (gpt4all #941).\n\u2022 ILLEGAL INSTRUCTION refers to the utilization of unauthorized instructions during the operation of LLM open-source software, which may potentially lead to security issues. For example, a user received a message that \u201cthread 5 \u2018llm thread' received signal SIGILL, Illegal instruction\", which shows that an illegal instruction made the core dump (gpt4all #378).\n\u2022 PRIVACY ISSUE refers to the risk of privacy breaches encountered by users when using LLM open-source software. For example, a user complained that \\\"different users share the same chat history\\\" when chatting with the model, which shows the concern of users about their privacy (text-generation-webui #2950).\n\u2022 MALWARE ISSUE refers to the potential presence of malicious software attacks in LLM open-source software, which adversely affects the security of LLM open-source software. For example, a user reported that \\\"Windows defender claims to have found a backdoor in pytorch_model.bin\\\" (text-generation-webui #456).\nInterpretation": "Security Issue covers various security-"}, {"title": "3.1.14. Graphical User Interface (GUI) Issue (2.72%)", "content": "GUI Issue refers to issues concerning the user interface of LLM open-source software. GUI serves as the channel through which users interact with the software and significantly impacts the user experience. This category encompasses the following two types.\n\u2022 GUI DESIGN ISSUE refers to issues concerning the GUI design of LLM open-source software. A well-designed GUI enhances user experience, making optimization of GUI design an aspect worthy of attention."}]}