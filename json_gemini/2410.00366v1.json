{"title": "EASYDIAGNOS: A FRAMEWORK FOR ACCURATE FEATURE\nSELECTION FOR AUTOMATIC DIAGNOSIS IN SMART\nHEALTHCARE", "authors": ["Prasenjit Maji", "Amit Kumar Mondal", "Hemanta Kumar Mondal", "Saraju P. Mahanty"], "abstract": "The rapid advancements in artificial intelligence (AI) have revolutionized smart healthcare, driving\ninnovations in wearable technologies, continuous monitoring devices, and intelligent diagnostic\nsystems. However, security, explainability, robustness, and performance optimization challenges\nremain critical barriers to widespread adoption in clinical environments. This research presents an\ninnovative algorithmic method using the Adaptive Feature Evaluator (AFE) algorithm to improve\nfeature selection in healthcare datasets and overcome problems. AFE integrating Genetic Algorithms\n(GA), Explainable Artificial Intelligence (XAI), and Permutation and Combination Techniques (PCT),\nthe algorithm optimizes Clinical Decision Support Systems (CDSS), thereby enhancing predictive\naccuracy and interpretability. The proposed method is validated across three diverse healthcare\ndatasets using six distinct machine learning algorithms, demonstrating its robustness and superiority\nover conventional feature selection techniques. The results underscore the transformative potential\nof AFE in smart healthcare, enabling personalized and transparent patient care. Notably, the AFE\nalgorithm, when combined with a Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%,\nhighlighting its capability to improve clinical decision-making processes in real-world healthcare\napplications.", "sections": [{"title": "Introduction", "content": "The world has made medical illness analysis more and more critical [1], leading to increased research and development\nefforts in this area. Advances in technology, such as deep learning and machine learning [2], have enabled researchers\nto leverage the potential of healthcare data to create novel approaches that enhance human health outcomes. These\nalgorithms can anticipate outcomes reasonably. However, those algorithms frequently need to explain their forecasts\nclearly, which reduces their effectiveness and reliability [3]. \"Black Box\" is the term or issue discussed about the\nreliability problem in [4]. Furthermore, these algorithms' lack of interpretability presents severe difficulties in clinical\ncontexts where medical personnel need lucid explanations to comprehend and rely on the advice these models provide"}, {"title": "Related Prior Research", "content": "The increasing demand for personalized healthcare solutions has driven significant advancements in smart healthcare\ndevices, offering continuous and automatic monitoring capabilities. Recent developments, such as MyWear, a novel\nsmart garment that enables continuous vital monitoring, demonstrate the potential of wearable technology in healthcare,\nproviding real-time health data with minimal patient intervention [12]. The study employed post-hoc and agnostic\nmodels, namely Local Interpretable Model-Agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP),\nto determine the most significant genes for classifying lung cancer types and subtypes [13], as well as the most crucial\nfeatures for predicting lung cancer survival [14]. Intelligent devices like iKardo, an advanced ECG monitoring system,\nenhance competent healthcare by automatically identifying critical heartbeats, thereby aiding in timely interventions\nfor cardiovascular conditions [15]. Additionally, continuous glucose monitoring technologies have evolved to provide\npatients and healthcare providers with comprehensive and actionable insights into glucose levels, supporting diabetes\nmanagement with a high degree of accuracy and convenience [16]. These innovations underscore the importance of\nintegrating advanced algorithms and smart devices in developing personalized and efficient healthcare solutions.\nIn recent times, the researchers discussed, for instance, and suggested utilizing SHAP and LIME in conjunction with\niAFPs-EnC-GA (GA (Fuzzy K-nearest neighbor (FKNN), Random Forest (RF), k-nearest neighbor (KNN), and Support\nVector Machine (SVM)) for fungal infection [17]. The paper introduces a deep ensemble method that uses uncertainty\nin relevance scores to improve the reliability and trustworthiness of predictions for clinical time series data with\nexplainable AI [18].\nMediastinal Cysts and Tumors have also been detected using the Ensemble of Extreme Gradient Boosting (XGBoost)\nand SHAP [19]. Recently, bloodstream infections with SHAP(XAI) have been found in [20] using XGBoost, RF, SVM,\nand MLP. An SVM-based model for predicting lung cancer from an image dataset is proposed in [21]. Using a dataset\nfrom the University of California's online repository, they performed preprocessing operations, such as eliminating\nvalues that are not relevant. The work separated the dataset into training and testing sets and used the SVM model to\nforecast using the features retrieved. With an accuracy of almost 98.8%, the model outperformed KNN, Naive Bayes,\nand J48 models. The study introduces a scalable ML model using minimal cognitive tests for accurate and explainable\ndementia risk prediction in aging populations. [22].\nThe study employs DNN and XAI (SHAP) to predict postprandial glucose levels in Type 1 diabetes, enhancing artificial\npancreas systems and decision-making tools. [23]. The researchers propose a histopathology image gathered from\nthe LC25000 dataset to construct a CAD system for lung and colon cancer analysis [24]. Hu invariant moments and\nthe GLCM method extract features from the pictures. The authors have classified lung and colon cancer using MLP,\nXGBoost, RF, SVM, and LDA models. Furthermore, the expected results of the ML models are explained using the\nSHAP technique. With 98.8% and 99% accuracy, respectively, XGBoost has the highest F1 score and accuracy out\nof the five models. The author on the domain in recent times [25] suggested a technique for early-stage lung cancer\ndiagnosis that uses three picture datasets and machine learning models. Using CNN for classification and U-Net CNN\nfor lung nodule segmentation, they obtained an AUC of 0.6459.\nGenerative AI has been explored as a means to enhance data quality, demonstrating its effectiveness as a complementary\ntool to traditional methods. It has been shown to improve accuracy and streamline workflows. Integrating Generative\nAI into data quality processes can yield substantial long-term organizational benefits, including increased efficiency and\nenhanced decision-making capabilities [26]. Feature selection is essential for removing irrelevant features, enhancing\nmodel accuracy, and reducing costs, as reviewed in key literature [27]. The Integrate-RF approach, a hybrid feature\nselection method combining multiple models with random forests, addresses dimensionality reduction and overfitting\nby selecting optimal features based on Out-of-Bag (OOB) classification error rates [28]. A novel neural network-based\nfeature selection method employing a weighting approach is proposed to highlight critical features, significantly\nenhancing algorithm speed and accuracy [29]. Another study presents a correction method for feature importance bias\nin RandomForest models using permutation-based p-values, which improves interpretability and prediction accuracy by\nidentifying significant variables in simulated and real-world datasets [30]. Using data from 5,601 COVID-19 patients\nin South Korea, an AI model is developed to predict clinical severity levels-categorized as low or high-based on\n20 critical features identified through feature importance analysis. The model, constructed with a 5-layer deep neural\nnetwork, was evaluated using metrics such as accuracy, specificity, and AUC [31]. A two-stage surrogate-assisted"}, {"title": "Challenges in Deploying XAI for Healthcare Applications", "content": "The development of AI systems that can provide clear, understandable justifications for their choices and actions is\nknown as Explainable Artificial Intelligence (XAI). Incorporating XAI in the healthcare setting presents many obstacles\n[43", "44": ".", "45": ".", "black boxes.\" One major challenge is explaining these models' decision-making procedures in a\nway that medical professionals can comprehend [46": ".", "47": ".", "48": "."}]}