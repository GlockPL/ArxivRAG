{"title": "LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner", "authors": ["Xiaopan Zhang", "Hao Qin", "Fuquan Wang", "Yue Dong", "Jiachen Li"], "abstract": "Language models (LMs) possess a strong capabil- ity to comprehend natural language, making them effective in translating human instructions into detailed plans for simple robot tasks. Nevertheless, it remains a significant challenge to handle long-horizon tasks, especially in subtask identification and allocation for cooperative heterogeneous robot teams. To address this issue, we propose a Language Model-Driven Multi- Agent PDDL Planner (LaMMA-P), a novel multi-agent task planning framework that achieves state-of-the-art performance on long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning capability and the traditional heuristic search planner to achieve a high success rate and efficiency while demonstrating strong generalization across tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that fea- tures household tasks with two different levels of complexity based on the AI2-THOR environment. The experimental results demonstrate that LaMMA-P achieves a 105% higher success rate and 36% higher efficiency than existing LM-based multi- agent planners. The experimental videos, code, and datasets of this work as well as the detailed prompts used in each module are available at https://lamma-p.github.io.", "sections": [{"title": "I. INTRODUCTION", "content": "Multi-robot systems have been widely applied to various real-world tasks, such as search and rescue [1], [2], ware- house automation, and agricultural processes [3]-[5]. These systems enable multiple robots to collaborate autonomously, which often have well-defined objectives and require efficient coordination between robots. Recently, language models (LMs) have been applied to complex, long-horizon house- hold tasks, allowing robots to understand semantics and execute natural language commands [6], [7]. Fig. 1 illustrates multi-robot cooperation in a household setting that exem- plifies the complexity of long-horizon task planning, where robots need to perform a sequence of interconnected tasks that may require coordinated actions. Thus, different robots need to be assigned specific tasks based on their capabilities. For instance, Robot 1 is responsible for moving a laptop, while Robot 2 is tasked with switching off the lights. Such scenarios highlight the challenges of long-horizon planning for heterogeneous robot teams, including task generalization, efficient sub-task allocation, and ensuring optimal coordi- nation. Managing these tasks over a long horizon requires both effectively leveraging each robot's skills and accurately identifying parallelizable tasks to maximize performance."}, {"title": "II. RELATED WORK", "content": "Long-horizon planning involves solving complex tasks that require a series of decisions over an extended period. Traditional methods such as hierarchical task networks [17], general-purpose planning systems based on PDDL [18], and Monte Carlo tree search [19] have been employed to address long-horizon problems by decomposing tasks into subtasks or sampling possible future outcomes. However, these meth- ods often struggle to scale to larger problem spaces, and they encounter difficulties in generalization and efficiency. Reinforcement learning [20] also faces similar challenges when learning transferable and generalizable policies.\nRecent studies integrate LLMs into long-horizon planning to tackle these challenges [6], [7], [12]. LLMs can process natural language tasks and translate them into structured formats, which enables more adaptable and context-aware planning. For example, recent LLM-enhanced planning ap- proaches rely on translating natural language tasks into Plan- ning Domain Definition Language (PDDL) patterns [21]- [28], a framework used to represent and solve complex planning problems. Silver et al. [22] and Zhou et al. [24] combine classic PDDL validators with LLM-based chain-of- thought planning to create an automatic loop that enables iterative correction of planning mistakes by LLMs. Singh et al. [13] propose a teacher-student pipeline where two agents guide the planner. However, existing approaches are only restricted to single-agent or two-agent systems. In contrast, our work advances the field by applying PDDL to LM-driven task planning with an arbitrary number of agents."}, {"title": "III. PROBLEM FORMULATION", "content": "We consider a scenario where multiple robots collabora- tively complete everyday activities in a household environ- ment, such as preparing meals or rearranging objects. A hu- man provides high-level natural language instructions, which may lack detailed specifications of required actions. This requires task parsing and reasoning, long-horizon planning, and task allocation among robots, which involves identifying necessary sub-tasks from the instructions and determining whether certain sub-tasks can be executed in parallel.\nWe formalize this problem as a cooperative Multi-Agent Planning (MAP) task [29] where multiple agents collab- oratively generate a joint task plan to achieve a shared goal. Formally, the MAP task is represented as a tuple $(AG, D, \\{A^i\\}_{i=1}^n, P, I, G)$, where AG is a set of n agents. Each agent i operates within a domain $d_i \\in D$ with its own set of actions $A^i$. P is the set of atoms representing the world state, $I \\subset P$ is the initial state, and $G \\subset P$ defines the goal state. A solution plan is an ordered sequence of actions $\\Pi_g = \\{\\Delta, <\\}$, where $\\Delta \\subset A$ are actions and < defines their order. The generated plan starts from the initial state I and leads to the goal state G."}, {"title": "IV. METHOD", "content": "Our framework, LaMMA-P, is designed to address long- horizon tasks for heterogeneous multi-agent systems. Fig. 2 provides a detailed overview of the modular structure of our framework, which employs language models (LMs) and PDDL planners within six key modules: Precondition Identifier (P), Task Allocator, Problem Generator (G), PDDL Validator (V), Fast Downward/LLM Planner, and Sub-Plan Combiner. For detailed prompts for each module, refer to our project website or the supplemental video. Each module serves a specific role in the planning and execution of long- horizon tasks across multiple robots with different skill sets.\nWe focus on deterministic, fully observable planning tasks. A PDDL domain consists of a name, types, predicates, and operators. Each robot type has a pre-defined domain for its available actions. The domain defines two types: robot and object. One predicate is (at ?o ?l) , where ?o is a placeholder for an object. Operators in the domain represent specific robot skills, and all the elements (types, predicates, operators, and objects) have human-readable names. For example, the \"pick up\" operator is represented as:"}, {"title": "A. Task Decomposition and Precondition Identifier", "content": "The first step in our framework involves decomposing the task into sub-tasks [11] and introducing a Precondition Identifier for each one. Classical planner computes a heuristic h(I, G) by ignoring delete effects [16], whereas LLMs tackle tasks through probabilistic reasoning over action sequences"}, {"title": "B. Task Allocation", "content": "Once the task is decomposed into smaller, manageable sub-tasks for a single robot, the sub-tasks are then allocated to heterogeneous multi-agent systems. The Task Allocator module parses the task description, identifying the necessary actions and matching them with the appropriate robots based on their skills and capacities. This allocation process ensures that resources are used efficiently, with the option to execute tasks in parallel when feasible to reduce the time for task completion. Due to the length and inherent randomness of the previous result, LLM fails to generate in the correct format [30], [31]. Therefore, weddesign this module to conclude the identified preconditions and the task allocation into a structured summary. The Task Decomposition Analysis, as shown in Fig. 2, is generated by the LLM within this module."}, {"title": "C. PDDL Problem Generation and Validation", "content": "With the sub-tasks allocated, the next phase involves generating PDDL problems. Each sub-task is translated into a PDDL problem, considering the current state of the envi- ronment and the specific goals that need to be achieved.\nThe Problem Generator module constructs the PDDL problems by specifying the relevant objects, actions, initial conditions, and goals. These problems are then passed to the PDDL Validator module, which verifies the correctness of the problem files by checking their format and structure to ensure they are ready for the planning phase. A PDDL problem is characterized by a domain, a set of objects, an initial state, and a goal. An object is identified by a name and a type, e.g., Egg object. A ground atom is a predicate and a tuple of objects of the appropriate types, e.g., (cooked Egg). A state consists of a conjunction of true ground atoms, assuming all other ground atoms are false. A goal is a conjunction of ground atoms that must be true in any goal state. For example, in \u201cPrepare plate with egg\", the goal is (at-location Egg Plate). The full PDDL Problem 1, as illustrated in Fig. 2, is written as"}, {"title": "D. Planning and Validation", "content": "Once the PDDL problems are generated, they are passed to the Fast Downward/LLM Planner module for plan gen- eration. The Fast Downward planner [16], operating within the types, constraints, and operators defined in the PDDL domain, produces a sequence of actions that achieve the spec- ified sub-task goals. A validator verifies the plan against the robot domain's constraints by analyzing the logs generated by the Fast Downward planner. If the plan is invalid, the system falls back to the LLMs for potential re-planning or refinement, ensuring that a viable solution is available."}, {"title": "E. Sub-Plan Combination and Task Execution", "content": "After individual sub-plans are generated and validated, the Sub-Plan Combiner merges them into a final plan that addresses the entire high-level long-horizon task, as shown in Fig. 2. The combiner accounts for task parallelizability, scheduling simultaneous execution where possible, while ensuring sequential execution for tasks with dependencies. This synchronization ensures smooth transitions between sub-tasks and maintains inter-task dependencies, particularly in multi-robot scenarios. By balancing parallel and sequential execution, the system maximizes efficiency throughout task execution. Once the final plan is combined, the Plan-to-Code Converter transforms it into executable code, which runs in the simulated environment using the Scenario Simulator. The simulator visualizes the robots performing their assigned sub- tasks, completing the task execution process."}, {"title": "V. EXPERIMENTS", "content": "We present MAT-THOR, a multi-agent long-horizon task dataset expanded from the SMART-LLM benchmark [11], to evaluate LaMMA-P and baseline methods based on the AI2-THOR simulator [32]. The MAT-THOR dataset includes 70 tasks across five floor plans, with increasing complexity and vague commands for a more challenging evaluation. It supports testing on task allocation and execution efficiency with two to four robots of varying skills, and provides detailed task information, including initial states, robot skills, and final conditions for success.\nThe tasks are categorized into three levels of complexity:\n1) Compound Tasks: These tasks allow for flexible exe- cution strategies (e.g., sequential, parallel, or hybrid). Each robot possesses the necessary specialized skills to handle its assigned sub-tasks independently, with the number of sub-tasks ranging from two to four.\n2) Complex Tasks: These tasks are specifically designed for heterogeneous robot teams, where individual robots may not process all skills to complete their sub-tasks independently. The number of sub-tasks is six or more.\n3) Vague Command Tasks: These tasks present additional challenges with ambiguous natural language instruc- tions, which require the robots to infer missing details.\nOur MAT-THOR dataset includes 30 compound tasks, 20 complex tasks, and 20 vague command tasks to evaluate task decomposition, allocation, and execution efficiency."}, {"title": "B. Evaluation Metrics and Baselines", "content": "We adopt five evaluation metrics [11]: Success Rate (SR), Goal Condition Recall (GCR), Robot Utilization (RU), Ex- ecutability (Exe), and Efficiency (Eff). For a certain task, successful execution occurs when all task-specific goals are achieved. SR represents the ratio between successful execu- tions and the total number of tasks. GCR is the set difference between the ground truth final state and the achieved final state, normalized by the number of task-specific goals. RU calculates the ratio between the total transition count of all successful executions and the total ground truth, measuring how effectively the action sequence is planned. Exe measures the fraction of actions that can be executed, regardless of task relevance. Eff captures system efficiency as the ratio between the total action time steps and the ground truth time steps. Both RU and Eff are assessed only on successful executions. We evaluate LaMMA-P across diverse tasks with different language models, including GPT-40 [33], Llama-3.1-8B, and Llama-2-13B [34]. We adopt SMART-LLM [11] as the state- of-the-art baseline, with GPT-4 replaced by GPT-40 for a fair comparison. Also, we introduce a second baseline using only Chain-of-Thought (CoT) prompting with GPT-40. For the CoT baseline, we manually translate the generated plans into code and evaluate performance metrics accordingly."}, {"title": "C. Results and Discussion", "content": "We evaluate LaMMA-P and baseline methods on the MAT-THOR dataset across three distinct task categories: Compound, Complex, and Vague Command. LaMMA-P consistently achieves superior performance compared to the baseline methods across all task categories.\nFig. 3 visualizes task executions in the AI2-THOR simulator (task descriptions are detailed in the caption). Each row presents key execution frames for a task. In the first Compound task, Robots 1 and 2 work simultaneously, while Robot 3 starts only after Robot 2 leaves the desk, optimizing parallelism. In the second Complex task, only Robot 1 possesses the ability to open and close objects, creating a dependency between the sub-tasks. Robot 2 waits by the drawer for Robot 1 to arrive and open it. These demonstrate our method's ability to effectively manage complex dependencies while ensuring smooth coordination among the robots for efficient task completion.\nOurs (GPT-40) improves the av- erage SR and Eff by 105% and 36%, respectively, compared to the strongest baseline SMART-LLM (GPT-40), which indicates a substantial improvement in task completion, efficiency and generalizability. These improvements result from LaMMA-P's integration of LMs' advanced reasoning abilities with traditional heuristic search. By accurately de- composing tasks, efficiently assigning sub-tasks, and lever- aging heuristic search for planning, our method consistently outperforms the baselines across all metrics. The quantitative results of our experiments are summarized in Table I."}, {"title": "Ablation Study", "content": "We conduct an ablation study to evaluate the impact of various components of LaMMA-P on its overall performance. The results, shown in Table II, indicate that the addition of key elements, such as the pre-defined domains (D), Problem Generator (G), Precondition Identifier (P), and PDDL Validator (V), leads to a significant increase in task performance on both compound and complex tasks. The first variation excludes all major components: P, V, G, and D. As a result, performance is significantly lower. The absence of pre-defined robot domains significantly decreases the LLM's ability to identify appropriate sub-tasks for each robot, resulting in incorrect task allocation and sub-optimal performance. After adding D, the SR increases substantially for all categories of tasks. This improvement highlights the importance of domain knowledge in guiding the LLM to assign tasks more appropriately to robots. Next, the addition of G further improves performance by providing a structured approach to describe sub-tasks, making them easier to assign. Eff for compound tasks and RU for complex and vague command tasks show an increase, indicating more effective task decomposition and improved robot utilization. V brings notable improvements in task performance. It ensures that all generated plans are executable before task execution, which reduces task failures and optimizes the overall workflow. When all components are included, Ours (GPT-40) achieves the best performance. The addition of P simplifies complex preconditions, enabling the LLM to generate action se- quences with fewer constraints to guide further task planning."}, {"title": "VI. CONCLUSION", "content": "We introduce LaMMA-P, a Language Model-Driven Multi-Agent PDDL Planner that addresses long-horizon task allocation and planning for heterogeneous multi-robot sys- tems. By unifying the strong reasoning ability of LLMs with heuristic search planning based on PDDL, LaMMA-P significantly improves task success rates and robot utilization efficiency over existing methods, while exhibiting generaliza- tion across a wide range of tasks. LaMMA-P outperforms the strongest baseline SMART-LLM on the MAT-THOR benchmark with a 105% higher success rate and 36% higher efficiency in long-horizon tasks. The integration of LLMS enables flexible task translation and assignments, enhancing the system's generalizability across various tasks. While LaMMA-P shows promising results, it assumes fully observ- able, static environments, which may not always satisfy real- world conditions. Future work may focus on incorporating vision-language models for improved perception and devel- oping adaptive re-planning for dynamic scenarios."}]}