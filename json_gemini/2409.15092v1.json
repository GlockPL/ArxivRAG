{"title": "M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics from Digital Pathology Images", "authors": ["Hongyi Wang", "Xiuju Du", "Jing Liu", "Shuyi Ouyang", "Yen-Wei Chen", "Lanfen Lin"], "abstract": "The advancement of Spatial Transcriptomics (ST) has facilitated the spatially-aware profiling of gene expressions based on histopathology images. Although ST data offers valuable insights into the micro-environment of tumors, its acquisition cost remains expensive. Therefore, directly predicting the ST expressions from digital pathology images is desired. Current methods usually adopt existing regression backbones along with patch-sampling for this task, which ignores the inherent multi-scale information embedded in the pyramidal data structure of digital pathology images, and wastes the inter-spot visual information crucial for accurate gene expression prediction. To address these limitations, we propose M2OST, a many-to-one regression Transformer that can accommodate the hierarchical structure of the pathology images via a decoupled multi-scale feature extractor. Unlike traditional models that are trained with one-to-one image-label pairs, M2OST uses multiple images from different levels of the digital pathology image to jointly predict the gene expressions in their common corresponding spot. Built upon our many-to-one scheme, M2OST can be easily scaled to fit different numbers of inputs, and its network structure inherently incorporates nearby inter-spot features, enhancing regression performance. We have tested M2OST on three public ST datasets and the experimental results show that M2OST can achieve state-of-the-art performance with fewer parameters and floating-point operations (FLOPs). The code will be released upon acceptance.", "sections": [{"title": "Introduction", "content": "Digital pathology images, as a kind of Whole Slide Images (WSIs), have witnessed widespread utilization in research nowadays, as they can be more easily stored and analyzed compared to traditional glass slides (Niazi, Parwani, and Gurcan 2019). However, besides the spatial organization of cells presented in these pathology images, the spatial variance of gene expressions is also very important for unraveling the intricate transcriptional architecture of multi-cellular organisms (Rao et al. 2021; Tian, Chen, and Macosko 2023; Cang et al. 2023). As the extended technologies of single-cell RNA sequencing (Kolodziejczyk et al. 2015; Mrabah et al. 2023), ST technologies have been developed recently, facilitating such spatially-aware profiling of gene expressions within tissues (Rodriques et al. 2019; Lee et al. 2021; Bressan, Battistoni, and Hannon 2023).\nA detailed illustration of the acquisition process of WSIs and ST maps is presented in Figure 1. As shown, WSIs are obtained by scanning the glass slide tissues at various magnification factors, resulting in a multi-scale hierarchical data structure (Ryu et al. 2023). Correspondingly, ST maps are obtained by firstly sampling spots with a fixed interval on the glass slide tissues. Each spot contains two to dozens of cells depending on different ST technologies (Song and Su 2021). Subsequently, the accumulated gene expressions of the cells within the spots are profiled, forming a spatial gene expression map. Such gene expression maps can be used along with their corresponding WSIs for multi-modal computational pathology analysis, leading to higher performance in tasks such as cancer sub-typing and prognosis prediction (Hoang et al. 2022). However, despite their rapid evolution, ST technologies have yet to find widespread application in pathological analysis, primarily due to the expensive costs (Pang, Su, and Li 2021). In contrast, WSIs are more economical and accessible as they are routinely generated in clinics (Pang, Su, and Li 2021). Consequently, there is a growing imperative to directly generate ST maps from WSIs at a low cost through deep learning methods (Levy-Jurgenson et al. 2020; Weitz et al. 2021).\nCurrent approaches typically treat the ST prediction problem as a conventional regression problem (He et al. 2020; Monjo et al. 2022), where the network is fed with a WSI patch as input and produces the cumulative gene expression intensities of the cells within the corresponding patch area. In this paradigm, the methods are trained with single-level image-label pairs just like standard regression tasks. This makes them only able to model the relationship between the gene expressions and the images of the maximum magnification, wasting the multi-scale information inherent in WSIs. From a bionic perspective, pathologists often zoom in and zoom out frequently when analyzing WSIs, as each level of WSIs encapsulates distinct morphological information that can be useful for ST predictions (Chen et al. 2022; Yarlagadda, Massagu\u00e9, and Leslie 2023). For instance, cell-level images can facilitate the evaluation of gene expressions based on cell types, while higher-level images can offer regional morphologies that help determine overall gene intensities. Hence, we propose to conceptualize the ST prediction as a many-to-one modeling problem, in which case multiple images from different levels of WSI are leveraged to jointly predict the gene expressions within the spots. As we notice that the absolute field of view of the microscope will not change during the zooming operations performed by pathologists, we also biomimetically employ a fixed patch size for the pathology patches from different WSI levels in our regression model. In this case, higher-level image patches naturally have a larger receptive field, and thus is able to include more supporting features around the ST spot, compensating for the destroyed cell features on the patch edges during the patch cropping procedure (Chung et al. 2024).\nMany-to-one-based modeling aims to learn a mapping function from a variable number of inputs to one single output. These multiple inputs can have different shapes or lack semantic alignment, with the goal being to find their common mapping target. It can be used for many tasks, such as multi-phase radiology image analysis (Hu et al. 2023) and label assignment problem (Wei et al. 2023). Our many-to-one scheme differs from conventional multi-scale methods by offering a structure that can easily scale to accommodate different numbers and different shapes of inputs. For instance, while we primarily present our model in a three-to-one structure, it can be easily adjusted to two-to-one or four-to-one scenarios by removing or adding streams in the pipeline, making it suitable for different WSI scanning technologies. Additionally, during training, model parameters can be partially updated when some levels of inputs are missing, as the model parameters are highly decoupled across the multiple inputs.\nBased on this idea, we propose M2OST, a many-to-one-based regression Transformer designed to leverage pathology images at various levels to jointly predict the gene expressions. By incorporating the inter-spot visual information and the multi-scale features within the WSIS, M2OST exhibits the capability to generate more accurate ST maps. Moreover, to optimize the computational efficiency, we further introduce Intra-Level Token Mixing Module (ITMM), Cross-Level Token Mixing Module (CTMM), and Cross-Level Channel Mixing Module (CCMM) to decouple the many-to-one multi-scale feature extraction process into intra-scale representation learning and cross-scale feature interaction processes, which greatly reduces the computational cost without compromising model performance. In summary, our contributions are:\n1. We propose to conceptualize the ST prediction problem as a many-to-one modeling problem, leveraging the multi-scale information and inter-spot features embedded in the hierarchically structured WSIs for joint prediction of the ST maps.\n2. We propose M2OST, a flexible regression Transformer crafted to model many-to-one relationships for ST prediction. Its unique design makes M2OST suitable for different many-to-one scenarios, and is robust to input sets with various sequence lengths.\n3. In M2OST, we propose to decouple the multi-scale feature extraction process into intra-scale feature extraction and cross-scale feature extraction, which significantly improves the computational efficiency without compromising model performance.\n4. We have conducted thorough experiments on the proposed M2OST method, and have proved its effectiveness with three public ST datasets."}, {"title": "Related Works", "content": "The prediction of ST maps from WSIs has garnered sustained attention since the inception of ST technologies. ST-Net (He et al. 2020) is the first work that attempts to tackle this problem. ST-Net employs a convolutional neural network (CNN) with dense residual connections (He et al. 2016; Huang et al. 2017) to predict patch-wise gene expressions. By sequentially processing the patches in a WSI, ST-Net can eventually generate a complete ST map. Similarly, DeepSpaCE (Monjo et al. 2022) adopts a VGG-16 (Simonyan and Zisserman 2015) based CNN for such patch-level ST prediction, and it introduces semi-supervised learning techniques to augment the training sample pool. More recently, BLEEP (Xie et al. 2024) introduced a contrastive learning approach to align WSI patch features with ST spot embeddings, using K-Nearest Neighbors during the inference stage to mitigate the batch effect in biomedical datasets. Although these classic CNN backbones have demonstrated considerable success in various vision tasks, their performance has been eclipsed by the advancements achieved with Transformer-based models (Ding et al. 2023). HisToGene (Pang, Su, and Li 2021) was the first method proposed to leverage vision Transformers (Dosovitskiy et al. 2020) for predicting ST maps. Diverging from the approach of ST-Net and DeepSpaCE, which predict one spot at a time, HisToGene proposes to predict the entire ST map at a time."}, {"title": "Methodology", "content": "In M2OST, we use $I_0$, $I_1$, and $I_2 \\in \\mathbb{R}^{3\\times H\\times W}$ to represent the three input images of different levels, where $I_i$ denotes the pathology image patch from level $i$, and $H$, $W$ represents the image height and width, respectively. The observed gene expressions in each spot are denoted as $G = \\{g_1, g_2, ..., g_k\\}$, where $k$ is the total number of genes. The goal is to minimize the mean squared error (MSE) between $G = \\text{M2OST}(\\{I_o, I_1, I_2\\}|\\theta_o, \\theta_1, \\theta_2)$ and $G$ by optimizing the network parameters $\\theta_0, \\theta_1$, and $\\theta_2$ of each stream.\nA schematic view of the proposed M2OST is presented in Figure 2. Upon receiving the multi-scale pathology image patches from three different levels, M2OST initially sends them into our proposed Deformable Patch Embedding (DPE) layers to realize adaptive token generation. After appending [cls] token to each sequence, intra-scale representation learning within each sequence is first performed using ITMM. Then, CTMM is introduced to facilitate cross-scale information exchange between the different inputs, followed by CCMM mixing the channels in a squeeze-and-excitation way. This multi-scale feature extraction module is termed the M2OST Encoder and is iterated N times within M2OST. Finally, the three [cls] tokens are concatenated to be fed into the linear regression head for the ST spot prediction."}, {"title": "Deformable Patch Embedding", "content": "Although high-level pathology patches provide more nearby visual information of the target ST spot, the central image area that directly maps to the target spot should still be primarily focused on. To emphasize the in-spot features during many-to-one modeling, we introduce DPE to generate fine-grained in-spot tokens and coarse-grained surrounding tokens. As shown in Fig 3, apart from using patch size $p$ on $I_0$, $I_1$, and $I_2$ to generate the basic tokens in a weight-sharing manner, DPE also adopts $\\frac{p}{2}$ and $\\frac{p}{4}$ patch sizes on the higher-level pathology images to ensure the central area of the patches receives the most attention. Eventually, DPE converts the three input images into $L \\times C$, $2L \\times C$, and $3L \\times C$ sequences $S_0$, $S_1$, $S_2$, where $L = p^2$ represents the sequence length and $C$ denotes the number of channels after embedding."}, {"title": "Intra-Level Token Mixing", "content": "After patch embedding, a [cls] token is appended to the beginning of each sequence. Then, a fully learnable positional embedding is added to each sequence to encode the positional information for the multi-scale tokens generated by DPE. After that, each level's sequence data undergoes processing through ITMM to extract the intra-level features, whose structure is mainly based on ViT (Dosovitskiy et al. 2020), as depicted in Figure 4. ITMM uses the Random Mask Self-Attention trick (Zehui et al. 2019) to enhance its generalization ability."}, {"title": "Cross-Level Token Mixing", "content": "After the intra-level feature extraction, the acquired representations are amalgamated into CTMM for cross-level information exchange. Given that the sequence lengths of $S_0$, $S_1$, and $S_2$ are different, these data can not be directly fused together for simple information exchange. In the meantime, to most possibly retain the independence of the network parameters $\\theta_0$, $\\theta_1$, and $\\theta_2$, CTMM introduces fully-connected cross-level attention to realize the goal, as illustrated in Fig 5(a).\nLet M represents the total number of input sequences, and $K_i, Q_i, V_i$ denotes the hidden representation extracted from $S_i$, CTMM can be mathematically defined as:\n$\\text{CTMM}(S_i) = \\Sigma_{0<j<M \\atop j\\neq i} w \\sigma (\\frac{Q_iK_j^T}{\\sqrt{d_K}})V_j,$\n(1)\nwhere $\\sigma$ represents the Softmax operation, and $w$ is the learnable weights indicating how much the j-th level information contributes to the i-th level CTMM output. Finally, M sequences are obtained with their shape unchanged, and subsequently sent into CCMM for further channel mixing."}, {"title": "Cross-Level Channel Mixing", "content": "CCMM is used to explicitly facilitate the channel interaction between multi-level sequences. Since the input sequences are still of different lengths, we design a length-insensitive channel mixing method for CCMM to address this issue, which is presented in Fig 5(b). Inspired by the squeeze-and-excitation operation in (Fu et al. 2019), we first use global average pooling for each sequence to compress their sequential information into one token. Then, we combine these tokens from different levels together and use a squeeze-and-excitation operation to obtain the cross-level channel attention scores. After that, the scores are split and multiplied back to their respective input sequences, leading to channel-level cross-scale information exchange.\nIn summary, as afore-presented, every module of M2OST is insensitive to sequence length, and can be easily scaled to handle different numbers of input by removing or adding streams to the pipeline."}, {"title": "Experiments", "content": "In our experiments, we utilized three public datasets to evaluate the performance of the proposed M2OST model.\nThe first one is the human breast cancer (HBC) dataset (Stenbeck et al. 2021). This dataset contains 30,612 spots in 68 WSIs, and each spot has up to 26,949 distinct genes. The spots in this dataset exhibit a diameter of 100 \u00b5m, arranged in a grid with a center-to-center distance of 200 \u00b5m.\nThe second dataset is the human HER2-positive breast tumor dataset (Andersson et al. 2021). This dataset consists of 36 pathology images and 13,594 spots, and each spot contains 15,045 recorded gene expressions. Similar to the previous dataset, the ST data in this dataset also features a 200\u00b5m center-to-center distance between each captured spot with the diameter of each spot also being 100\u00b5m.\nThe third dataset is the human cutaneous squamous cell carcinoma (cSCC) dataset (Ji et al. 2020), which includes 12 WSIs and 8,671 spots. Each spots in this dataset have 16,959 genes profiled. All the spots have a diameter of 110\u00b5m and are arranged in a centered rectangular lattice pattern with a center-to-center distance of 150\u00b5m.\nWe employ the mean values of Pearson Correlation Coefficients (PCC) and Root Mean Squared Error (RMSE) of the spots to evaluate the regression accuracy. Mathematically, PCC can be described as:\n$\\text{PCC} = \\frac{\\text{Cov}(G, \\hat{G})}{\\sqrt{\\text{Var}(G) \\cdot \\text{Var}(\\hat{G})}},$\n(2)\nwhere Cov(\u00b7) is the covariance, Var(\u00b7) is the variance, G is the ground truth gene expressions of a spot, $\\hat{G}$ is the corresponding predicted result."}, {"title": "Implementation Details", "content": "Due to the inherently sparse nature of the ST map, we need to filter out less-variable genes in each dataset before initiating the training process. Following previous works (He et al. 2020), we select 250 spatially variable genes for the regression task, which will be released with the code.\nUsing the same pre-processing procedures in (Zeng et al. 2022), we normalize the gene expression counts for each spot by dividing them by their total counts and multiplying the result by the scale factor 1,000,000. Then, the values are natural-log transformed by log(1 + x) where x is the normalized count. Given the high sparsity of ST maps, we select 250 spatially variable genes for regression on each dataset. For all datasets, we use a patch size of 224\u00d7224 (which covers around 110\u00b5m\u00d7110\u00b5m in the pathology image) for each spot on level 0 pathology image, and the patch size p is set to 16 accordingly. In each dataset, 60% of the WSIs and their corresponding ST maps are used for training, 10% for validation, and the remaining 30% for testing. All the methods are trained with Adam (Kingma and Ba 2015) optimizer with a learning rate of 1e-4 for 100 epochs. Batch size is 96 for patch-level methods and 1 for slide-level methods. The hyper-parameters of M2OST are the model width, model depth, and the number of heads in self-attention. The three hyper-parameters were tuned following the goal of surpassing other methods with minimal model size. Specifically, the M2OST Encoder is repeated 4 times (i.e, model depth), the embedding channel is 192 (i.e., model width), and the number of head for the self-attention operation in ITMM is set to be 3. A larger model size can lead to even better ST regression performance but the computational cost will also be higher. All the methods are trained on two Nvidia RTX A6000 (48G) GPUs."}, {"title": "Ablation Study", "content": "To verify the effectiveness and efficiency of M2OST, we have conducted a thorough ablation study on its network structure. We begin by replacing DPE with ordinary patch embedding layers, which leads to a notable decrease in PCC of all three datasets. Although the FLOPs dropped due to the reduced input sequence length, the parameter counts increased because of the absence of the weight-sharing mechanism used in DPE. Such experimental results prove the effectiveness of the adaptive patch embedding in DPE.\nThen, we substitute the three ITMMs into one unified Self-Attention to directly process the concatenated sequences (the three sequences are of the same length without DPE, so they can be directly concatenated), destroying the decoupled design in M2OST. It is observed that the parameter count dramatically increased, but the model performance did not benefit from it, which validates the efficiency of using ITMM to decouple the multi-scale feature extraction process in M2OST. We further remove CTMM from M2OST, using simple concatenation for cross-level feature fusion. This time, the parameter count did not drop much, while the performance suffered a further decline. This indicates that CTMM is necessary for processing such many-to-one modeling problems, where each sequence may contain different semantic information that cannot be fused by simple concatenation. We have also tried using summation to replace CTMM, but it fails to outperform the concatenation scheme.\nFinally, we replaced CCMM with ordinary fully connected layers, and the FLOPs increased while the performance did not change much. This illustrates the effectiveness of CCMM in performing channel mixing for sequences of different lengths in M2OST."}, {"title": "Study on the Input Combinations for M2OST", "content": "Using M2OST as the backbone, various input combinations were fed into the model to verify the effectiveness of our many-to-one design. We kept the network width and depth identical for different combinations of inputs to ensure fairness during comparison, which also leads to similar parameter counts and FLOPs of the compared methods.\nAnalysis of the table reveals that when employing M2OST as a one-to-one-based method, using level 0 pathology images yields optimal results across all three datasets. This is attributed to the comprehensive high-frequency information present in the level 0 pathology images, validating that the gene expression in a spot is primarily related to its corresponding tissue area. In this case, M2OST also did not surpass other one-to-one-based methods such as ResNet-50 and ST-Net when referring to the results in Table 3, which is mainly due to its smaller model size. Nonetheless, after introducing level 1 and level 2 image patches as additional inputs, the PCC of M2OST increases to 48.07%, 44.17%, and 50.50% on the three datasets, achieving state-of-the-art performance. This illustrates the effectiveness of the many-to-one scheme in M2OST, proving that introducing the multi-scale and surround-spot visual information for ST prediction can improve the model accuracy."}, {"title": "Experimental Results", "content": "The experimental results of the comparison between M2OST and other methods are presented in Table 3. This table provides detailed insights into the PCC and RMSE on various datasets of different methods, along with their parameter count and FLOPs. Analysis of the experimental results reveals that M2OST achieves superior performance with fewer FLOPs and a reduced parameter count. In comparison to ST-Net, which features 0.38 million more parameters and 1.43G more FLOPS, M2OST surpasses its performance on HER2+ and CSCC datasets by 0.97% and 1.23% PCC, respectively."}, {"title": "Comparison between M2OST and One-to-one Multi-Scale Methods", "content": "In Table 3, we also have some comparisons with ordinary one-to-one multi-scale methods, such as CrossViT and HIPT/iStar. Compared with the vanilla ViT, CrossViT significant improvement in ST regression performance, confirming the value of incorporating multi-scale information for this task. However, since CrossViT is limited in its ability to fully utilize inter-spot information, it falls short of surpassing the performance of our proposed M2OST model.\nIn the case of iStar, the model achieved an even higher prediction accuracy for ST, underscoring the effectiveness of HIPT in extracting multi-scale features from WSIs. However, due to HIPT's hierarchical ViT architecture, training the model end-to-end is computationally expensive. As a result, iStar employs frozen HIPT weights to generate WSI features for ST prediction, which might compromise feature extraction performance. Furthermore, our observations (based on the official code release) indicate that iStar requires significantly more processing time during inference. This increased time is primarily attributed to its multi-scale feature extraction process, which operates patch by patch and scale by scale. When we limited M2OST's batch size to match iStar's GPU memory consumption, M2OST demonstrated an inference speed that was 100\u00d7 faster than iStar's for ST regression. Despite this remarkable efficiency, M2OST still outperformed iStar, highlighting the superiority of end-to-end training in ST prediction and validating the effectiveness of our model design."}, {"title": "Comparison between Patch-Level and Slide-Level ST Methods", "content": "From Table 3, it is also observed that the slide-level ST methods fail to outperform patch-level methods on all three datasets. Among the slide-level methods, Hist2ST does surpass HisToGene due to its larger model size, but the extra FLOPs and the dramatic parameter count diminish the significance of this performance improvement. When compared to baseline patch-level methods such as ST-Net, the PCC of Hist2ST is 2.78%, 2.99%, and 2.66% lower on the three datasets respectively. This suggests that the gene expressions of a spot are primarily related to its corresponding tissue area, and introducing inter-spot correlations does little to enhance prediction accuracy. Nevertheless, slide-level methods still possess the advantage of being more efficient in generating entire ST maps. With a refined network design, they still have the potential of achieving a competitive regression accuracy."}, {"title": "Statistical Significance and Deviation Analysis", "content": "A paired T-test for M2OST predictions has been conducted to ensure the statistical significance of the experimental results, and it is observed that p-value<0.05 holds for all other methods. We have also presented a boxplot in Fig 6, and it is shown that M2OST demonstrated the most stable predictions across all considered methods, validating the effectiveness of its network design."}, {"title": "Visualization Analysis", "content": "Finally, we present some visualization results in Figure 7 to make an intuitive comparison of the methods. In Figure 7(a), Principal Component Analysis (PCA) is used to compress the 250-dimension gene expressions into one dimension for better color mapping and visualization. As it is shown, slide-level methods such as HisToGene and Hist2ST tend to generate smoother ST maps, owing to the holistic processing of entire slides. In contrast, patch-level methods typically yield sharper predictions due to the independent processing of each spot in the ST map. Notably, M2OST consistently produces more accurate ST maps with distributions closely resembling the ground truth. This observation underscores the effectiveness of M2OST. Additionally, we augment our findings with individual gene visualizations in Figure 7(b) to further elucidate the efficacy of M2OST. The gene we selected for visualization is DDX5, which plays a pivotal role in the proliferation and tumorigenesis of non-small-cell cancer cells by activating the beta-catenin signaling pathway (Wang et al. 2015). Our results indicate that M2OST achieves the highest accuracy in gene expression prediction for the selected gene, surpassing the performance of other patch-level and slide-level methods."}, {"title": "Conclusion", "content": "In this study, we tackle the challenging task of predicting ST gene expressions from WSIs by proposing a novel many-to-one-based regression Transformer, M2OST. M2OST leverages pathology images from several distinct levels to collectively predict gene expressions within their common central tissue area. The model incorporates M2OST Encoder for decoupled multi-scale feature extraction, which comprises ITMM for intra-scale representation learning, CTMM for cross-scale feature extraction, and CCMM for multi-scale channel mixing. The experimental results on three public ST datasets show that M2OST can achieve state-of-the-art performance with minimal parameters and FLOPs."}, {"title": "Additional Experimental Results", "content": "External validation is crucial for the practical application of M2OST. Without employing any domain generalization or domain adaptation techniques, we have performed a thorough external validation for M2OST and other methods.\nIn the experiment, one entire ST dataset is used for training, while the rest two datasets are used for validation.\nIn practical applications, doctors have the flexibility to manually specify the target genes before the training process."}, {"title": "Limitations", "content": "As a spot-level method, M2OST has a lower efficiency compared to the slide-level methods, as it can only generate gene predictions of one spot at a time. Additionally, since M2OST is an end-to-end spot-level method, it can only perceive limited nearby non-local information in a WSI during training, which may leave space for future improvements."}]}