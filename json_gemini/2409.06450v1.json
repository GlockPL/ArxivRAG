{"title": "Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles", "authors": ["Qiujing Lu", "Xuanhan Wang", "Yiwei Jiang", "Guangming Zhao", "Mingyue Ma", "Shuo Feng"], "abstract": "The generation of corner cases has become increasingly crucial for efficiently testing autonomous vehicles prior to road deployment. However, existing methods struggle to accommodate diverse testing requirements and often lack the ability to generalize to unseen situations, thereby reducing the convenience and usability of the generated scenarios. A method that facilitates easily controllable scenario generation for efficient autonomous vehicles (AV) testing with realistic and challenging situations is greatly needed. To address this, we proposed OmniTester: a multimodal Large Language Model (LLM) based framework that fully leverages the extensive world knowledge and reasoning capabilities of LLMs. OmniTester is designed to generate realistic and diverse scenarios within a simulation environment, offering a robust solution for testing and evaluating AVs. In addition to prompt engineering, we employ tools from Simulation of Urban Mobility to simplify the complexity of codes generated by LLMs. Furthermore, we incorporate Retrieval-Augmented Generation and a self-improvement mechanism to enhance the LLM's understanding of scenarios, thereby increasing its ability to produce more realistic scenes. In the experiments, we demonstrated the controllability and realism of our approaches in generating three types of challenging and complex scenarios. Additionally, we showcased its effectiveness in reconstructing new scenarios described in crash report, driven by the generalization capability of LLMs.", "sections": [{"title": "I. INTRODUCTION", "content": "Scenario-based testing is vital in the development of autonomous driving, as it allows AVs to be tested in specially crafted scenarios inside simulation. This method is essential for evaluating performance, identifying weaknesses, and ensuring safety- key factors in assessing AVs before road testing. However, the scenario libraries currently in use, primarily sourced from real-world data, fall short due to the scarcity of corner cases. To make things worse, as the intelligence level of autonomous driving improves, the rarity of critical events becomes increasingly problematic, exacerbating what is referred to as the \"curse of rarity\" [1]. The insufficient testing coverage and inefficiencies throughout the testing process is hindering enhancements in AV safety. As such, the efficient generation of testing scenarios is of critical importance. Various techniques has been explored, such as dense deep reinforcement learning [2] and adversarial framework [3]. Yet, considering the diverse testing requirements and different development stages in AV development, effectively designing and generating suitable scenarios to meet the testing needs remains an unresolved challenge.\nMany efforts have been made in this area, primarily focusing on generating challenging scenarios based on predefined functions or well-defined search algorithms. However, there has been limited exploration into developing an effective control mechanism that allows flexible management of scenario generation based on requirement descriptions. This is particularly important because developers often conceptualize scenarios in abstract terms while simulations require precise configurations for execution. For instance, developers might envision turning scenarios, while simulation requires detailed road geometry, precise initial vehicle placements and behaviors for each turn. Enhancing the controllability of the scenario generation system based on abstract descriptions can bridge the gap between developers and scenario-based testing, making it a more viable tool and expediting the path to efficient performance evaluation for AV systems.\nHowever, building such text-conditioned generation mechanism is challenging as it demands modeling capacity ranging from static elements in road structures to agent behaviors and map between narrative language to detailed configurations. Additionally, it must ensure the conformity to user requests, maintain he diversity of the road network, and preserve the fidelity of the generated scenarios. Such generation process requires a high level of intelligence, as it involves not only understanding the control signal but also reasoning from the request to design then generate the desired testing scenarios. The emergence of LLMs and Vision-Language Models (VLM), trained with vast amounts of data from the internet, has demonstrated remarkable intelligence, encompassing learning, reasoning, linguistic capabilities, human-like communication, and complex thinking abilities. There have been extensive explorations into their applications in fields such as medicine, education, finance, and engineering. Notably, OpenAI's CodeX [4] and DeepMind's AlphaCode [5] has demonstrated promising coding capabilities, MathPrompter [6] has shown advancements in mathematical reasoning, and SceneCraft [7] has excelled in creating narrative experiences.\nMotivated by these impressive advancements in large language models (LLMs), this paper aims to explore how the coding, narrative, and reasoning capacities of LLMs, along with the extensive knowledge acquired from the internet, can be harnessed to bridge the gap between developers and the simulation systems. Building such a simulation tool with a ro-"}, {"title": "II. RELATED WORKS", "content": "A. Scenario-based testing\nSafety is the major factor holding back the widespread deployment of AVs, extensive efforts have been made to identify and address unsafe components through rigorous testing [13]-[15]. Compared to road testing, scenario-based testing aims to offer more efficient, targeted assessments with"}, {"title": "III. METHOD", "content": "In this section, we delineate the OmniTester system, the multimodal LLM-driven tool designed for text-conditioned scenario generation. Within this system, we introduce several techniques to enhance LLM's understanding and generation capabilities for scenarios. We begin by introducing the overall generation framework, followed by an explanation of the prompt engineering techniques utilized for scenario generation. Subsequently, we provide an in-depth explanation of the Net Generator and Vehicle Generator components. Finally, we introduce the RAG mechanism.\nA. Pipeline\nThe generation framework is illustrated in Fig. 2. The process of creating a set of scenarios starts when the user"}, {"title": "B. Scenario Prompt Engineering", "content": "The LLM's ability to comprehend the scenarios both geometrically and programmatically, will greatly impact the controllability and realism of the generated scenarios. We utilized various prompt techniques to integrate domain knowledge, generate more structured outputs, and maximize the reasoning capabilities of LLMs, while minimizing the hallucination. Chain-of-Thought (CoT) prompting [35] motivates the LLM to articulate its reasoning process before providing the final answer. We designed specific prompts to break down the generation task into a series of subproblems, leading the model to tackle these sequentially to achieve the ultimate solution. For example, in network generation, we utilize a multi-step process to aid the model in understanding user requests. Initially, we direct the model to summarize the task in the \"Description\" section and then guide it to \"step by step explain your reasoning process\u201d in the \u201cReasoning\" section. Refer to the prompt example in Appendix 1. This method not only helps the LLM to better comprehend and analyze the testing requirements but also encourages rational thought with minimal hallucination. For further evidence of the importance of this component, see the ablation study in section IV-E.\nSecondly, we specify the output requirements for the LLM. We instruct the LLM to generate the correct format of node and edge files by providing detailed formatting guidelines. Additionally, we impose additional constraints on road length and design rules to enhance the realism of the output network.\nConsidering the complexity of output, the varying number of vehicles, and the heterogeneous information (such as edge and time information), we use the few-shot prompting technique [36] to help the model understand the context and generate the desired format of the response with a higher success rate. Please refer to the Appendix A for detailed prompt samples."}, {"title": "C. LLM-driven Scenario Generation", "content": "We decompose scenario generation into two stages: road network generation and agents' routes generation. Road structure is important since testing on accurate and varied road structures ensures that AVs comply with road safety regulations and can respond appropriately to diverse road conditions. In our implementation for road generation, a properly prompted LLM-based Interpreter is employed to generate a detailed description for the whole scenario, then SUMO compatible Node and Edge file defined in XML format is generated based on the description.. Lastly, SUMO tool is utilized to convert them into single net file defined in XML format, representing the entire road network. See Fig. 3 for an illustration and more detailed examples in Section IV. This design is not confined to SUMO or its XML formats. Since road network naturally represents a graph structure, it can be represented by other structured languages [37] and processed by graph tools [38], compatible to other simulators such as MATSim [39].\nConsidering close interactions with other vehicles are among the most challenging scenarios for AVs [40], we utilize"}, {"title": "D. RAG for scenarios", "content": "The process begins with the extraction of road geometry from OpenStreetMap [43], a collaborative project that provides freely accessible, editable geographic data globally. This platform is utilized to obtain detailed and up-to-date road geometries of specified regions of interest, serving as the foundational dataset for providing open-world knowledge about road structures. The extracted road geometries are then converted into a network model using netconvert. This model is represented in the net.xml format, which is compatible with SUMO.\nFollowing the network model creation, a bird's-eye view (BEV) image of the traffic scenario is generated using the graphical user interface of SUMO (sumo-gui). This image captures the layout and other relevant road network attributes. The BEV image serves as an input to an LLM, which processes the visual information and generates descriptive text detailing the road geometry and network characteristics. This step is critical as it bridges the gap between visual data and textual representation, facilitating easier interpretation and further processing of network characteristics in textual form. Once each textual description generated by the LLM, it is transformed into vector embeddings using OpenAI's embedding tools, text-embedding-ada-002 [44]. It converts the text into a high-dimensional space that captures the semantic features of the text numerically. These embeddings are then stored in a database, based on Chroma DB [45], enabling efficient retrieval and comparison based on semantic similarity.\nDuring the retrieval phase, the description of the target scenario is converted into an embedding using the same embedding tool. This embedding serves as the basis for identifying the most semantically similar road geometry stored in the database, achieved through comparison of embeddings. This method of similarity assessment ensures that the selected"}, {"title": "IV. EXPERIMENTS", "content": "In this section, we demonstrate the effectiveness of our Multimodal LLM framework for scenario generation. Firstly, we show that the system can generate diverse scenarios to cover various situations while maintaining high realism, based on user's testing requests. Secondly, we highlight the difficulty of these scenarios by testing an LLM-driven AV within them. Thirdly, we showcase the effectiveness of RAG module. To demonstrate our system's controllability and generalization capabilities in generating scenarios with more detailed descriptions, we introduce a case study where our OmniTester generates similar risky situations purely based on text descriptions from crash reports. Lastly, we validate the importance of the key design elements in this framework through a thorough ablation study."}, {"title": "A. Controllable realistic scenarios", "content": "Controllable scenario generation requires high conformality to user requests and realistic outputs. In our experiments, we observed that with proper prompting, the LLM demonstrates strong intelligence and high performance in this task. One detailed example of a generated road network, along with comprehensive descriptions provided by the interpreter, can be"}, {"title": "B. Controllable challenging scenarios", "content": "RandomTrip [47] from the SUMO tool generates a set of random trips for a given network by randomly selecting source"}, {"title": "C. Effectiveness of RAG Module", "content": "To generate diverse freeway ramp scenario, we pulled several on/off ramp map from OpenStreetMap and added into the database. Upon user request, it can generate realistic ramp scenarios with assistance from the data retrieved from this database. Instead of using code, text, or picture formats of the road network on the fly for assisting generation, a detailed description of the road structure is prepared to provide distilled information. The generated description ensures that the Net Generator receives sufficient information to construct a similar new road structure that matches the layout, segment details, and directional flow of the original.\nAs illustrated in Fig.2, the text description is generated using a VLM-based summarizer. Powered by VLM's vision and spatial reasoning capabilities, layout information can be extracted from the picture. The node and edge files offer detailed information about the road structure, including length, number of lanes, and the shape of each curved edge. With this abundant information, the summarizer intelligently selects key features based on knowledge from the open world and hints injected from the prompt. It then summarizes all the important information into the final description, which contains the general layout, main segment locations, moving directions, connectivity, and even detailed descriptions of curve shapes. Fig.7 contains an example illustrating how the retrieved example's description guided the generation of freeway off-ramp road structures. As shown, it describes a freeway off-ramp comprising three segments, covering the main freeway road and the trunk for exiting the freeway. Besides detailing the layout, segments, and number of lanes for each edge, it provides a thorough description of the curve shape. Using this example in the prompt, the Interpreter can generate a similar"}, {"title": "D. Effectiveness of OmniTester with crash report", "content": "A direct application of our OmniTester framework is reconstructing scenarios similar to those described in text. This allows for the generation of multiple challenging testing scenarios that can be used for stress testing AV systems. For example, by varying the departure time for each vehicle or changing the driving strategies, a wide range of testing scenarios near risky situations can be generated.\nAs an example, we use one case from crash reports [49] to demonstrate how to reconstruct similar dangerous situations for testing a vehicle's reaction. Specifically, instead of using the Interpreter, we directly use the scenario description from crash report for Net Generator as well as the Vehicle Generator. As shown in Fig.8, the text is extracted directly from a crash report, describing a crash event that occurred near an intersection. It includes the moving direction for the roads and their speed limits in km/h. The Net Generator not only generates the exact geometry as described in the report but also automatically converts the speed unit in SUMO's default speed unit of m/s without error. For the Vehicle Generator, according to the reasoning process present, it can extract each vehicle's property (such as brand and color) and infer their relative positions based only on crash evolution process: \"As Vehicle 1 approached the intersection, it slowed for Vehicle 3, which was attempting to make a right-hand turn. Vehicle 2 braked, but was unable to stop, causing the frontal plane of Vehicle 2 to strike the rear plane of Vehicle 1. After the rear impact from Vehicle 2, Vehicle 1 then continued forward and struck the rear plane of Vehicle 3 with its front plane.\u201d. Eventually, the system can reconstruct the routes with corresponding departing time to ensure the relative positions match and similar scenario can be reconstructed."}, {"title": "E. Ablation Study", "content": "As shown in Table IV, the success rate of the generation process (with a maximum of 3 attempts per scene) drops from"}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "We present a scenario generation framework based on LLM and VLM models. This is the first system to generate road structures and vehicles based on user requests with high controllability and flexibility, powered by RAG and self-improvement techniques. We demonstrate that a traffic flow simulator can serve as an efficient tool for LLM to generate complex and diverse testing scenarios with properly designed prompts. A structured definition written in XML, combined with image-based representation and narrative description, effectively represents a scenario. Lastly, self-improvement through effective feedback can enhance scenario generation.\nCurrent endeavors are still in their early stages, and utilizing multimodal large language models and the vast array of knowledge learned within these models to create more complex scenarios remains an open question. One direction for future work is to generate more realistic BV behaviors which could be controlled by deep neural networks (DNNs) or another LLM model. Another direction is to model more elements within the scenario based on detailed descriptions. By pursuing this path, we aim to generate controllable world models that enhance the realism and complexity of simulated environments, making testing more targeted and efficient."}, {"title": "APPENDIX A", "content": "PROMPT EXAMPLES\nPrompts are crucial in enhancing the reasoning and generation capabilities of LLMs. Fig.10 demonstrate the prompts used in the Net Generator and Vehicle Generator of OmniTester. Each prompt includes several parts: a summary of the generation task, the steps guiding the generation process, and the desired format of the output. For the Net generator, the prompt additionally includes several road constraints to ensure the generated node and edge files are well-defined XML format. For Vehicle Generator, the prompt includes explanations for challenging situations."}]}