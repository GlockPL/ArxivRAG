{"title": "Shiksha: A Technical Domain focused Translation Dataset and Model for\nIndian Languages", "authors": ["Advait Joglekar", "S. Umesh"], "abstract": "Neural Machine Translation (NMT) models\nare typically trained on datasets with limited\nexposure to Scientific, Technical and Educa-\ntional domains. Translation models thus, in\ngeneral, struggle with tasks that involve scien-\ntific understanding or technical jargon. Their\nperformance is found to be even worse for low-\nresource Indian languages. Finding a trans-\nlation dataset that tends to these domains in\nparticular, poses a difficult challenge. In this\npaper, we address this by creating a multilin-\ngual parallel corpus containing more than 2.8\nmillion rows of English-to-Indic and Indic-\nto-Indic high-quality translation pairs across\n8 Indian languages. We achieve this by bitext\nmining human-translated transcriptions of\nNPTEL\u00b9 video lectures. We also finetune and\nevaluate NMT models using this corpus and\nsurpass all other publicly available models at\nin-domain tasks. We also demonstrate the po-\ntential for generalizing to out-of-domain trans-\nlation tasks by improving the baseline by over\n2 BLEU on average for these Indian languages\non the Flores+ benchmark. We are pleased\nto release our model and dataset via this link:\nhttps://huggingface.co/SPRINGLab.", "sections": [{"title": "Introduction", "content": "NPTEL (National Programme on Technology En-\nhanced Learning) has long been a valuable re-\nsource for free on-demand higher-educational con-\ntent across a diverse range of specialized disci-\nplines. Over the past two decades since its incep-\ntion, NPTEL has curated an extensive library of\nover 56,000 hours of video lectures, all made pub-\nlicly available along with their audio transcriptions\nin an easily accessible manner. In response to the\ngrowing number of Indian students, NPTEL has\ntaken steps to support Indian language transcrip-\ntions for more than 12,000 hours of video content.\nThese captions are primarily translations of the"}, {"title": "Where does Present-day MT fail?", "content": "Let's quickly look at how Machine Translation\nmodels in use widely today perform on Technical-\ndomain tasks and instances in which they fail."}, {"title": "Related Work", "content": "In related work like Samanantar (Ramesh et al.,\n2022) and IndicTrans2 (Gala et al., 2023), NPTEL\nhas been identified as a useful resource for Machine\nTranslation (MT). These two studies in particular\nattempt at mining for parallel sentence pairs by uti-\nlizing various sources on the internet, including this\none. Due to the lack of precise information given\nin these papers, we are unable to know the exact\nquantity of sentence-pairs mined from NPTEL with\ncertainty. Regardless of this, we have found some\nkey issues with their data. A significant quantity of\nextracted sentence-pairs was found to be composed\nof unfiltered artifacts like timestamps. Several in-"}, {"title": "The Dataset", "content": "The initial step in creating any dataset involves ob-\ntaining the raw data. Instead of scraping subtitles\nfrom YouTube videos, we obtained the raw data\nfrom NPTEL. We were provided a list of 10,669\nvideos and their corresponding transcriptions and\nrelated metadata. These transcriptions were bilin-\ngual documents spanning 8 languages 3, featuring\nalternating English and Indic text, interspersed with\nreference timestamps and video snapshots. Refer\nto Appendix A for a sample page."}, {"title": "Data Cleaning and Extraction", "content": "Given the unusual format of these documents, we\nwrote a Python script to extract the meaningful\ntext data from it while avoiding any timestamp ref-\nerences. In this script, we first pull out the text\nfrom these documents and then use regex patterns\nto filter out the timestamps. We then used simple"}, {"title": "Bitext Mining", "content": "With this parallel corpora in place, we begin the\nmost crucial part: Bitext mining. Our objective is\nto find as many sentence-pairs as we can from the\nsource data while still maintaining high confidence\nin their translation accuracy. Luckily, Sentence-\nAlignment is a well studied problem dating as far\nback as 1991 (Brown et al.).\nRecent work like Vecalign (Thompson and\nKoehn, 2019) has focused on using multi-lingual\nembedding models to find pairs based on vector\nsimilarity of sentence embeddings. These have\nbeen shown to achieve state-of-the-art performance,\nsignificantly surpassing previous approaches. In\nour work, we use SentAlign (Steingrimsson et al.,\n2023) which employs LABSE (Feng et al., 2022)\nalong with optimized alignment algorithms to mine\nparallel documents with high accuracy and effi-\nciency. With this we are also able to find 1-n and\nn-1 sentence matches."}, {"title": "Data Collation", "content": "Each lecture now has its own documents with all\nits sentences aligned into bilingual sentence-pairs.\nWe collect these pairs and combine them, along\nwith their lecture metadata, into a massive transla-\ntion dataset. After post-processing with deduplica-\ntion, we arrive at a corpus of roughly 2.8 million\nsentence-pairs."}, {"title": "Data Analysis", "content": "To understand the quality and quantity of this data,\nwe must first thoroughly analyse it. Our dataset has\n8 English-Indic and 28 Indic-Indic language pairs.\nThis means that there exists at least one common\nset of lectures among each language-pair, provid-\ning us with inter-Indic alignments for all languages\ncovered in this dataset. We find 48.6% of these to be\nEnglish-to-Indic language pairs. This is the direct\nresult of English lectures having been translated\ninto multiple languages, albeit with arbitrary com-\nbinations, giving us a robust Indic-to-Indic data\nsubset.\nFor assessing the alignment quality of our trans-\nlation pairs, we look at the average LABSE similar-\nity scores as the primary measure. The plot of this\nmetric (Figure 2) demonstrates a strong consistency\nin scores across all languages despite differences\nin the quantity of the mined sentence-pairs. These\ndata points are also seen to be tending towards 0.8\nand are never below 0.75, validating our confidence\nin the quality of the source data and the accuracy\nof our alignments."}, {"title": "The Model", "content": "The value of a dataset can only be best quantified\nwhen a model has been trained with it, evaluated\nagainst others and the results analyzed. We wish to\nfine-tune and evaluate a powerful MT base model\nto test the hypothesis that our dataset can help im-\nprove the performance of translation tasks in the\nTechnical domain. We will test if existing models\ncan be improved meaningfully by being fine-tuned\non our dataset."}, {"title": "Baseline Model selection", "content": "When it comes to choosing a strong multi-lingual\nmodel that is, or at least close to, the state-of-"}, {"title": "Training", "content": "NLLB-200 models are available in a wide vari-\nety of sizes ranging from a 600M parameter dis-\ntilled model to a massive 54B parameter Mixture-\nof-Experts model. For our experiments, we decide\nto choose the 3.3B parameter version as a sweet\nspot between performance quality and compute\nrequirements.\nStill, even with this relatively smaller NLLB\n3.3B model, running a Full Fine-Tuning (FFT)\nsetup can turn out to be a very compute intensive en-\ndeavour. The amount of time required to effectively\ntrain our model will also be significant. In our case\nwe wish to execute a number of experiments with\ndifferent approaches in hopes to achieve the best\nresults. FFT thus would not be a feasible approach.\nInstead, we decide to utilize a Parameter-Efficient\nFine Tuning (PEFT) method known as Low-Rank\nAdaptation (LoRA) (Hu et al., 2022) to train our\nmodel.\nWe primarily trained three models using three\ndifferent approaches. All of them were done us-\ning LoRA with NLLB 3.3B. These approaches in-"}, {"title": "Evaluation", "content": "For evaluation we compare our third model, trained\non 12 million rows, with the baseline NLLB model\nand the 1B parameter IndicTrans2 model. For an\nin-domain test, we used the top one thousand rows\n(by LABSE score) of our held-out test set for each\nlanguage. Our model outperforms the rest on our\ntest set and demonstrates the efficacy of our model\nat translations involving the technical domain. We\nfurther test our models on the Flores+ 4 (Previously\nFlores-200) devtest set. We find that our model\nis also able to generalize well, as seen from the\nimprovements on the baseline scores. Our results\nmanage to come closer to IndicTrans2, which was\ntrained on a corpus far larger than ours. These\nscores are depicted in Table 2 above. Language-\nwise comparison of evaluation scores are also avail-"}, {"title": "Translingua", "content": "This research goes beyond just experiments. Our\nmodels are now built into a tool called Translin-\ngua, that is being widely used by human annotators\nacross India to translate NPTEL lecture transcripts"}, {"title": "Conclusion", "content": "In this paper, we introduced Shiksha, a novel trans-\nlation dataset and model tailored for Indian lan-\nguages, with a particular focus on the Scientific,\nTechnical, and Educational domains. We created\na robust multilingual parallel corpus consisting\nof over 2.8 million high-quality translation pairs\nacross 8 Indian languages. Our approach involved\nmeticulous data extraction, cleaning, and bitext\nmining to ensure the accuracy and relevance of the\ndataset. We also fine-tuned state-of-the-art base-\nline NMT models using this dataset and demon-\nstrated significant performance improvements in\nnot only in-domain, but also out-of-domain transla-\ntion tasks.\nWith this paper, we wish to encourage the im-\nportance of domain-specific datasets in advancing\nNMT capabilities. We believe that our dataset and\nmodels will serve as valuable resources for the com-\nmunity and foster further research in multilingual\nNMT."}, {"title": "Limitations", "content": "Despite the promising results of our dataset and\nmodel, there are some limitations that need to be\nacknowledged:\n\u2022 The dataset is heavily skewed towards sci-\nentific, technical, and educational domains,\nsourced primarily from NPTEL video lectures.\nThis can lead to degradation in translation\nquality for general tasks in unexpected ways\nthat standard benchmarks may not catch. We\nrecommend supplementing our dataset with\nadditional diverse and balanced sources cov-\nering a wide range of domains, including ev-\neryday conversational language, literature, so-\ncial media, and news articles. This will help\nensure a more stable training and evaluation\nprocess, ultimately enhancing the translation\nsystem's robustness and accuracy across dif-\nferent contexts.\n\u2022 We have not meaningfully tested our model's\nperformance on Indic-English or Indic-Indic\ndirections as our research was focused primar-\nily on translating out of English. Our models"}]}