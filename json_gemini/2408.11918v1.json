{"title": "NEURAL SYMBOLIC LOGICAL RULE LEARNER FOR\nINTERPRETABLE LEARNING", "authors": ["Bowen Wei", "Ziwei Zhu"], "abstract": "Rule-based neural networks stand out for enabling interpretable classification by learning logical rules\nfor both prediction and interpretation. However, existing models often lack flexibility due to the fixed\nmodel structure. Addressing this, we introduce the Normal Form Rule Learner (NFRL) algorithm,\nleveraging a selective discrete neural network, that treat weight parameters as hard selectors, to learn\nrules in both Conjunctive Normal Form (CNF) and Disjunctive Normal Form (DNF) for enhanced\naccuracy and interpretability. Instead of adopting a deep, complex structure, the NFRL incorporates\ntwo specialized Normal Form Layers (NFLs) with adaptable AND/OR neurons, a Negation Layer\nfor input negations, and a Normal Form Constraint (NFC) to streamline neuron connections. We\nalso show the novel network architecture can be optimized using adaptive gradient update together\nwith Straight-Through Estimator to overcome the gradient vanishing challenge. Through extensive\nexperiments on 11 datasets, NFRL demonstrates superior classification performance, quality of\nlearned rules, efficiency and interpretability compared to 12 state-of-the-art alternatives. Code and\ndata are available at https://anonymous.4open.science/r/NFRL-27B4/.", "sections": [{"title": "1 Introduction", "content": "In contrast to explainable models Angelov et al. [2021], Rudin [2019], Setzu et al. [2021], Lundberg et al. [2020], which\nprimarily focus on elucidating the contributions of individual input features towards the predictions made by black-box\nmodels, interpretable models Molnar [2020] are inherently \"white-box\" in nature, offering full transparency in their\ninference process. This means that the pathway by which these models arrive at a specific prediction, based on input\nfeatures, is fully accessible and comprehensible to humans (such as decision trees). Such transparency of the model's\ninner workings is vital for affirming the model's reliability, promoting fairness, and building trust. This is particularly\ncritical in high-stakes areas such as healthcare, finance, and legal applications, where the justification for a model's\npredictions is as crucial as the outcomes themselves.\nAddressing this need, rule-based models Yin and Han [2003], Frank and Witten [1998], Cohen [1995], Wang et al.\n[2020, 2021], Quinlan [2014], Yang et al. [2017], Angelino et al. [2018], Breiman [2017], Mooney [1995], Dries\net al. [2009], Jain et al. [2021], Beck et al. [2023], Sverdlik [1992], Hong and Tsang [1997], S. [1969], Michalski\n[1973], Pagallo and Haussler [1990], Clark and Niblett [1989], Quinlan [1990] have garnered attention for their inherent\ninterpretability. Initially, example-based rule learning algorithms S. [1969], Michalski [1973], Pagallo and Haussler\n[1990] were proposed. Building on these, a system for learning first-order Horn clauses Quinlan [1990] was developed,\ninspiring a line of DNF Cohen [1995], Frank and Witten [1998], Yin and Han [2003], S. [1969], Michalski [1973],\nPagallo and Haussler [1990], Clark and Niblett [1989] and CNF learners Mooney [1995], Dries et al. [2009], Jain et al.\n[2021], Beck et al. [2023], Sverdlik [1992], Hong and Tsang [1997]. Extensive exploration of heuristic methods Quinlan\n[2014], Loh [2011], Cohen [1995] has often failed to produce optimal solutions. Recent innovations such as ensemble\nmethods and soft or fuzzy rules have improved rule-based models, achieving state-of-the-art prediction accuracy at\ntimes at the cost of interpretability Ke et al. [2017], Breiman [2001], Irsoy et al. [2012]. Bayesian approaches have\nfurther refined these models' architectures, though their reliance on computationally intensive methods like MCMC or\nSimulated Annealing limits scalability Letham et al. [2015], Wang et al. [2017], Yang et al. [2017]."}, {"title": "2 Related Work", "content": "Thanks to the potent expressiveness and generalization ability, robustness and data-driven nature, the use of neural\nnetworks to represent and learn interpretable logical rules presents an exciting development Wang et al. [2020, 2021],\nYu et al. [2023]. This approach facilitates the automatic and efficient learning of complex rules on a large scale, merging\nthe strengths of neural computation with the clarity of rule-based reasoning.\nHowever, a notable drawback in the existing literature on rule-based neural networks is the lack of flexibility due\nto the fixed structure of the model. These models strictly specify each layer to be either CNF or DNF, stacking\nthese layers alternately Wang et al. [2020], Beck et al. [2023]. During the learning process, these methods are either\nheuristic-based Beck et al. [2023] or involve multiple forward and backward passes Wang et al. [2020, 2021], these\nrestrictions significantly impair the models' ability to effectively and efficiently produce precise and sophisticated\nlogical rules for accurate predictions and insightful interpretations.\nHence, we propose a Normal Form Rule Learner (NFRL) algorithm, which designs a selective discrete neural network\ntreating weight parameters as hard selectors to learn logical rules strictly in CNF and DNF for delivering precise\nclassifications and interpretable insights. To realize this ambition, we confront four pivotal challenges: (1) Neural\nArchitecture Design: How can neurons be architected to adaptively select appropriate logical operations and ensure\ntheir connections allow the neural network to flexibly represent rules? (2) Negation Operation: how to effectively\nimplement the negation operation on input features to achieve functional completeness of logic? (3) Rule Learning\nEfficiency: how to efficiently learn optimal rules (represented by connections between neurons) given a vast search\nspace of neuron connections? and (4) Discrete Network Optimization: how to optimize such a discrete neural network\ncontaining numerous non-differentiable components, while circumventing the gradient vanishing issue common in\nrule-based neural networks?\nTo address these challenges, we propose using two Normal Form Layers (NFLs) with flexible selective neurons. These\nneurons treat the corresponding weight parameter as a hard selector that can adaptively choose whether an AND or OR\noperation should be applied, allowing their logical connections to effectively represent CNF and DNF rules. We also\nintroduce a Negation Layer with negation gate neurons to implement the negation operation on inputs. Additionally,\nwe devise a Normal Form Constraint (NFC) to efficiently learn the connections between neurons in the two NFLs.\nWith the novel network architecture designed in NFRL, we apply the adaptive gradient update with a Straight-Through\nEstimator to effectively optimize the discrete neural network. Extensive experiments across 11 datasets and 12 baselines\ndemonstrate the superiority of NFRL compared to both traditional and cutting-edge rule-based models in terms of\nprediction performance, quality of learned rules, training efficiency, and interpretability. NFRL can deliver effective\nclassification and learn accurate and diverse rule sets with lower complexity and reduced computational time. Data and\ncode are available at https://anonymous.4open.science/r/NFRL-27B4/."}, {"title": "2.1 Traditional Rule Learning Methods", "content": "Historically, example-based rule learning algorithms S. [1969], Michalski [1973], Pagallo and Haussler [1990] were\nfirst proposed, selecting a random example and finding the best rule to cover it. However, due to their computational\ninefficiency, CN2 Clark and Niblett [1989] explicitly changed the strategy to finding the best rule that explains as many\nexamples as possible. Building on these heuristic algorithms, FOIL Quinlan [1990], a system for learning first-order\nHorn clauses, was subsequently developed. Some algorithms learn rule sets directly, such as RIPPER Cohen [1995],\nPART Frank and Witten [1998], and CPAR Yin and Han [2003], while others postprocess a decision tree Quinlan\n[2014] or construct sets of rules by postprocessing association rules, like CBA Liu et al. [1998] and CMAR Li et al.\n[2001]. All these algorithms use different strategies to find and use sets of rules for classification.\nMost of these systems are based on disjunctive normal form (DNF) S. [1969], Michalski [1973], Pagallo and Haussler\n[1990], Clark and Niblett [1989], Liu et al. [1998], Li et al. [2001], Frank and Witten [1998], Yin and Han [2003],\nCohen [1995] expressions. CNF learners have been shown to perform competitive with DNF learners Mooney [1995],\ninspiring a line of CNF learning algorithms Dries et al. [2009], Jain et al. [2021], Beck et al. [2023], Sverdlik [1992],\nHong and Tsang [1997]. Traditional rule-based models are valued for their interpretability but struggle to find the\nglobal optimum due to their discrete, non-differentiable nature. Extensive exploration of heuristic methods Quinlan\n[2014], Loh [2011], Cohen [1995] has not consistently yielded optimal solutions.\nIn response, recent research has turned to Bayesian frameworks to enhance model structure Letham et al. [2015],\nWang et al. [2017], Yang et al. [2017], employing strategies such as if-then rules Lakkaraju et al. [2016] and advanced\ndata structures for quicker training Angelino et al. [2018]. Despite these advancements, the extended search times,\nscalability, and performance issues of rule-based models limit their practicality compared to ensemble methods like"}, {"title": "2.2 Rule Learning Neural Networks", "content": "Neural rule learning-based methods integrate rule learning with advanced optimization techniques, enabling the\ndiscovery of more complex and nuanced rules. While tree-based models precisely follow rules represented by feature\ncondition connections, neural rule methods rely on weight parameters to control the rule learning process. These\nmethods combine the interpretability of rule-based models with the high performance of neural models, offering\nimproved generalization and robustness due to their data-driven nature. Approaches like neural decision trees or rule\nextraction from neural networks Frosst and Hinton [2017], Ribeiro et al. [2016], Wang et al. [2020, 2021], Zhang et al.\n[2023] face challenges in fidelity and scalability. For example, RRL Wang et al. [2021], the SOTA rule-based neural\nnetwork, requires a predefined structure of CNF and DNF layers, leading to inefficient and ineffective rule-learning\nprocesses and results. Additionally, the network architectures and optimization algorithms of existing works Wang\net al. [2020, 2021] suffer from the gradient vanishing problem. Our proposed NFRL aims to effectively address these\nchallenges through its unique and novel designs introduced in Section 4."}, {"title": "2.3 Binarized Neural Network", "content": "A related topic to this work is Binarized Neural Networks (BNNs), which optimize deep neural networks by employing\nbinary weights. Deploying deep neural networks typically requires substantial memory storage and computing resources.\nTo achieve significant memory savings and energy efficiency during inference, recent efforts have focused on learning\nbinary model weights while maintaining the performance levels of their floating-point counterparts Courbariaux et al.\n[2015, 2016], Rastegari et al. [2016], Bulat and Tzimiropoulos [2019], Liu et al. [2018]. Innovations such as bit\nlogical operations Kim and Smaragdis [2016] and novel training strategies for self-binarizing networks Lahoud et al.\n[2019], along with integrating scaling factors for weights and activations Sakr et al. [2018], have advanced BNNs.\nHowever, due to their discrete nature, BNNs face optimization challenges. The Straight-Through Estimator (STE)\nmethod Courbariaux et al. [2015, 2016], Cheng et al. [2019] allows gradients to \"pass through\" non-differentiable\nfunctions, making it effective for discrete optimization.\nDespite both using binarized model weights and employing STE for optimization, our work diverges significantly from\nBNNs. First, NFRL adopts special logical activation functions for performing logical operations on features, whereas\nBNNs typically use the Sign function to produce binary outputs. Second, BNNs are fully connected neural networks,\nwhile NFRL features a learning mechanism for its connections. Most importantly, these distinctions enable NFRL to\nlearn logical rules for both prediction and interpretability, setting it apart from BNNs, which are primarily designed to\nenhance model efficiency."}, {"title": "3 Preliminaries", "content": ""}, {"title": "3.1 Problem Formulation", "content": "A set of instances is denoted as X, where each instance $x \\in X$ is characterized by feature vector $x = [x_1, x_2, \u00b7 \u00b7 \u00b7, x_n]$.\nThese features can be either continuous or categorical. Each instance is associated with a discrete class label $y$. The\nobjective of classification is to learn a function $f : x \\rightarrow y$. In this work, we design a rule-based model as $f$, which can\nautomatically learn rules of features for prediction, and the learned rules are innate interpretations of the model."}, {"title": "3.2 Feature Binarization", "content": "Due to the discrete nature of logical rules, we need to convert all features into binary format. For a categorical feature $b_i$,\nwe apply one-hot encoding to get the corresponding binary vector $\\tilde{b_i}$. For continuous features, we employ the feature\nbinning method introduced by Wang et al. [2021]. In particular, for binarizing the j-th continuous feature $c_j$, a set of $k$\nupper bounds $[H_{j,1}, ..., H_{j,k}]$ and $k$ lower bounds $[L_{j,1},..., L_{j,k}]$ will be randomly sampled in the value range of $c_j$.\nThen, we can derive a binary representation of $c_j$ as $\\tilde{c} = [q(c_j - L_{j,1}), ..., q(c_j - L_{j,k}), q(H_{j,1} - c_j), . . ., q(H_{j,k} -c_j)]$,\nwhere $q(x) = 1$ if $x > 0$, $q(x) = -1$ otherwise. Therefore, the binarized input feature vector is represented as\n$\\tilde{x} = [\\tilde{b_1},..., \\tilde{b_p}, \\tilde{c_1}, ..., \\tilde{c_t}]$.\nBesides, there are other heuristic-based or learning-based methods, such as: AutoInt Zhang et al. [2023], a learning-\nbased binning method that learns the optimized bins along with model training; KInt Dougherty et al. [1995], a K-means\nclustering-based method that divides the feature value range based on clusters; and EntInt Wang et al. [2020], which\npartitions the feature value range to reduce uncertainty (entropy) about the class label within each bin. In Section 5.5,\nwe empirically compare the effectiveness of these methods integrated in our proposed framework."}, {"title": "3.3 Normal Form Rules as Model Interpretation", "content": "Propositional logic is the foundational component of mathematical logic, which focuses on propositions \u2013 statements\nwith definitive true or false values \u2013 and employing logical connectives (such as $\\land$ for \"and\", $\\lor$ for \"or\", and $\\neg$ for\n\"not\") to construct expressions. The truth values of expressions are determined by the truth values of their components,\nanalyzed using truth tables. Within propositional logic, normal forms, specifically Conjunctive Normal Form (CNF)\nand Disjunctive Normal Form (DNF), play a pivotal role.\nConjunction Normal Form (CNF). A propositional formula $z$ is in conjunctive normal form iff $z = \\bigwedge_i \\bigvee_j l_{ij}$, where\na literal $l_{ij}$ indicates an atom or the negation of an atom.\nDisjunction Normal Form (DNF). A propositional formula $z$ is in disjunction normal form iff $z = \\bigvee_i \\bigwedge_j l_{ij}$.\nThese standardized formats are crucial for simplifying the process of logical deduction, optimization, and analysis.\nThey allow for the efficient conversion of arbitrary logical expressions into a form that is easier to handle for both\ntheoretical investigations and practical applications.\nInterpretation via normal form rules. In this work, our goal is to learn a logical rule-based classification model that\npredicts based on automatically learned CNF and DNF logical expressions (rule). Concretely, we aim to learn a set\nof logical rules $R = {z_1,..., z_m}$. Each rule $z$ is either in CNF or DNF with binary features and their negations as\nliterals. For a rule $z$, we also learn a set of contribution scores {$s_{z,1},..., s_{z,Y}$} indicating the contribution of the rule\nfor each class $y \\in {1, . . ., Y}$. For a given input $x$, we first determine the true/false value of each rule in $R$, and then\ncalculate the logit for one class $k$ as $\\hat{y_k} = \\sum_{i=1}^{m} z_i \\times s_{z_i,k}$. The learned logical expressions $R$ allow us to express the\ncomplete inference process in a structured and mathematically rigorous manner. By this, we not only provide accurate\npredictions but also make the model transparent and interpretable."}, {"title": "4 Method", "content": ""}, {"title": "4.1 Overall Structure", "content": "To achieve the goal in Section 3.3, we propose a neural network that can be optimized end to end. Specifically, we\nidentify four key challenges: (1) How can neurons be designed to dynamically select suitable logical operations to\nflexibly represent CNF and DNF? (2) How to support the negation operation? (3) How to efficiently learn logical"}, {"title": "4.2 Normal Form Layer (NFL)", "content": "Neuron Operator Selection. Motivated by the nested structure of CNF and DNF, we propose to stack two Normal Form\nLayers (NFLs) to effectively express CNF and DNF rules. Each NFL contains K logical neurons {$u_1,u_2,...,u_K$}\nwhere each neuron represents a logical operator selected from either AND ($\\land$) or OR ($\\lor$). We use $w^{op} \\in R^K$ to\nparameterize the logical operator selection process of all K neurons. Given the weight $w^{op}_{ui}$ for a neuron $u_i$, we further\nget the binary version by taking the sign of it: $\\tilde{w}^{op}_{ui} = sign(w^{op}_{ui}) \\in {+1, -1}$. Then, the operator selection mechanism\nis defined as:\n$u_i =\n\\begin{cases}\n\\land, &\\text{if } \\tilde{w}^{op}_{ui} = 1\\\\\n\\lor, &\\text{otherwise}\n\\end{cases}$\n\nNeuron Connection. Similar to multi-layer perceptron, we learn a weight matrix $W^{conn}$ recording weights for\npairs of neurons from two consecutive layers, e.g., $W^{conn}_{u_i, u_j} \\in R$ is the weight for neurons $u_i$ and $u_j$ from two\nconsecutive layers. In NFRL, we only need to learn two weight matrices, one for (input layer, 1st NFL), the other\nfor (1st NFL, 2nd NFL). Given the learned $W^{conn}$, we further turn it into a binary version by taking the sign:\n$\\tilde{W}^{conn}_{u_i, u_j} = sign(W^{conn}_{u_i, u_j}) \\in {+1, -1}$, representing the connection between the involving two layers \u2013 neurons $u_i$ and\n$u_j$ are connected if $\\tilde{W}^{conn}_{u_i, u_j} = 1$, neurons are not connected otherwise. Given this, we define the output $v_i$ of a neuron\n$u_i$ in NFL as:\n$v_i =\n\\begin{cases}\n\\bigwedge_{W^{conn}_{u_i, j} = 1} v_j, &\\text{if } u_i = \\land\\\\\n\\bigvee_{W^{conn}_{u_i, j} = 1} v_j, &\\text{if } u_i = \\lor\n\\end{cases}$\nwhere $v_j$ are neurons from the previous layer that are connected to $u_i$, i.e., $\\tilde{W}^{conn}_{u_i, j} = 1$.\nLogical Activation Functions. In propositional logic, for a scenario involving m inputs: for the AND operation, the\noutput will be +1 if and only if all the connected neurons are +1; for the OR operation, the output will be +1 as long as at\nleast one connected neuron is +1. Based on these principles, we propose to adopt max and min functions to implement\nthe logical operations as logical activation functions in NFRL. The AND ($\\land$) operation can be defined as the minimum\nof its connected inputs, and the OR operation is defined as the maximum of its connected inputs:\n$v_i = \\begin{cases}\nmin_{W^{conn}_{u_i, j} = 1} v_j, &\\text{if } u_i = \\land\\\\\nmax_{W^{conn}_{u_i, j} = 1} v_j, &\\text{if } u_i = \\lor\n\\end{cases}$"}, {"title": "4.3 Negation Layer", "content": "Most existing works Wang et al. [2020, 2021] only support {AND, OR}, which is not functional complete Mendelson\n[1997], Enderton [2001] for propositional logic. We aim to enable NFRL to theoretically express any form of rule by\nsupporting a functionally complete set of logical operators {AND, OR, NEGATION}. To achieve this, we introduce the\nnegation layer to achieve the negation operation on features.\nBecause the negation is exerted on input features, we apply the negation layer after the input layer. Specifically, for\neach connection between a neuron $v_j$ from the input layer $x$ and a neuron $u_i$ from the 1st NFL, we further design a\nnegation gate to determine if we input the original input $v_j$ or the negation $\\neg v_j$ to $u_i$. For such a gate, we learn a weight\n$W^{neg}_{i,j} \\in R$ and take the sign of the learned weight to get the binary version: $\\tilde{W}^{neg}_{i,j} = sign(W^{neg}_{i,j}) \\in {+1, -1}$, with\nwhich we define the negation operation as: $Neg(v_j, \\tilde{W}^{neg}_{i,j}) = v_j \\times \\tilde{W}^{neg}_{i,j}$"}, {"title": "4.4 Optimization", "content": "Learning such a binary neural network is challenging. The core challenge lies in calculating gradients for the discrete\nfunctions in the model \u2013 the $sign(\\cdot)$, $max(\\cdot)$ and $min(\\cdot)$ \u2013 all of which are non-differentiable.\nGradient of the Sign Function. Motivated by the idea of searching discrete solutions in continuous space Courbariaux\net al. [2015]. We adopt the Straight-Through Estimator (STE) algorithm that allows for the propagation of gradients\nthrough a non-differentiable operation during backpropagation. In practice, the STE assumes the derivative of the\nsign function w.r.t. its input is 1, effectively allowing the gradient to \"pass through\" the non-differentiable operation\nunchanged:\n$\\frac{d sign(x)}{dx} = 1$.\nGradient of Logical Activation Functions. The max and min operations, when applied to input neurons, identify\nthe maximum or minimum value across inputs. Previous work Lowe et al. [2022] primarily applies these activation\nfunctions in continuous scenarios with paired inputs. We extend this approach to handle discrete and multiple inputs.\nIn pairwise situations, a logical operator selects one or two inputs, making it straightforward to assign a gradient of\n1 to the selected input and update the parameters equally. However, extending this to multiple inputs allows several\nneurons to be satisfied simultaneously for some rules, while others involve a relatively small number of satisfied neurons.\nThis discrepancy within the rule sets makes it inappropriate to expect equalized gradient updates across all neurons.\nComplex rules should be updated smoothly due to the large number of involved features, while specific rules require\nmore rapid updates. During the backward pass of gradient computation, if multiple neurons share the same maximum\nor minimum value, the gradient will be evenly distributed among all selected neurons. Formally, given an input vector x\nwith elements {$x_1, x_2, . . .$}, the gradient of an input element $x_i$ is:\n$\\frac{d max(x)}{dx_i} = \\frac{1}{\\sum_j I(x_j = max(x))}$;\n$\\frac{d min(x)}{dx_i} = \\frac{1}{\\sum_j I(x_j = min(x))}$.\nGradient Vanishing. Our innovative design circumvents the gradient vanishing problem that plagues existing meth-\nods Wang et al. [2020, 2021]. There are two primary causes of the gradient vanishing in these prior works. First, they\ndesign the binary states of their models with values 0 and 1, leading to numerous neurons producing an output of 0.\nThese 0 values in the forward pass can nullify the gradients in the backward pass. Second, these prior methods rely\non accumulative multiplications to implement AND and OR for logical activation functions. For example, the AND\noperation can be implemented as AND(x) = $\\prod_{i=1}^{m} x_i$ when $x_i \\in {0,1}$. This results in the situation where the gradient\nof an input depends on the product of others: $dAND(x)/dx_j = \\prod_{i\\ne j}x_i$. As the input dimension increases, this\ngradient as a product is likely to approach 0. A detailed discussion is included in Appendix F.\nIn contrast, we adopt +/-1 for defining the binary states in the neural network to prevent generating 0 outputs and 0\ngradients. Furthermore, our simple yet powerful logical activation functions do not rely on a product. The straightforward\ngradient calculation introduced in Equation 5 alleviate the gradient vanishing problem."}, {"title": "4.5 Normal Form Constraint (NFC)", "content": "Next, we turn our attention to one critical challenge of NFRL \u2013 learning the connections between the two NFLs is\ncomputationally intensive. Assuming we have K neurons in each NFL, we need to learn and determine $K^2$ potential\nconnections, significantly weakening the efficiency and efficacy of the model. Hence, we design a normal form\nconstraint to keep the learned rules in CNF and DNF, and at the same time, reduce the search space for learning the\nconnections between two NFLs. Specifically, since CNF and DNF are in a nested structure, where the operations in\nthe two levels have to be different (CNF is the conjunction of disjunction rules, DNF is the opposite), we have the\nconstraint that only different types of neurons from the two NFLs can be connected. For neurons $u_i$ and $u_j$ from two\nNFLs, we define a mask parameter $M_{i,j}$ as:\n$M_{i,j} = \\tilde{w^{op}_{u_i}} \\oplus \\tilde{w^{op}_{u_j}} = -\\tilde{w^{op}_{u_i}} \\tilde{w^{op}_{u_j}}$\nwhere $\\oplus$ denoted the XOR operation. Then, there is a connection between $u_i$ and $u_j$ if $M_{i,j} \\times W^{conn}_{i,j} = 1$, otherwise\nno connection. And during optimization, we only update $W^{conn}$ when $M_{i,j} = 1$.\nAssuming there are $C_1$ and $C_2$ conjunction neurons in two NFLs respectively, and $D_1$ and $D_2$ disjunction neurons\nrespectively ($C_1+ D_1 = C_2+ D_2 = K$), then potential connections under NFC is $C_1D_2+C_2D_1 < K^2$. The empirical\nstudy in Section 5.5 demonstrates that NFC benefits both the efficiency and efficacy of the model while guaranteeing\nthe learned rules are in CNF and DNF."}, {"title": "5 Experiment", "content": "In this section", "questions": "RQ1: How does NFRL perform w.r.t. classification accuracy compared to SOTA baselines? RQ2:\nWhat is the quality of the rules learned by NFRL? RQ3: How efficient NFRL is in terms of model complexity and\ntraining time? RQ4: What are the effects of the proposed Negation Layer", "RQ5": "What are the impacts of different hyperparameters in NFRL?\n5.1 Experimental Settings\nDatasets. We conduct extensive experiments on seven small datasets (adult Becker and Kohavi [1996", "2012": "chess Bain and Hoff [1994", "1995": "letRecog Slate [1991", "2007": "wine Aeberhard and Forina [1991"}, {"2012": "ndota2 Tridgell [2016", "2020": "fashion-mnist Xiao et al. [2017", "2015": "Wang et al. [2017", "2017": ".", "Discrete": "r 'Continuous'\ndepending on whether their features are exclusively of one type. A dataset incorporating both types is categorized as\n'Mixed'. We employ 5-fold cross-validation for evaluation. We report the average performance over five iterations in\nthis paper.\nPerformance Evaluation. We use the F1 score (Macro-average for multi-class cases) for assessing classification\nperformance. Additionally", "2006": "as a\ncomprehensive evaluation (the lower the better).\nReproducibility. In NFRL", "2014": "with a batch size of 32. For small datasets", "2021": ".", "2019": "."}, {"2021": ".", "https": ""}, {"2021": "Concept Rule Sets (CRS) Wang et al.\n[2020", "2014": "CART Breiman [2017", "2017": "and\nCertifiably Optimal Rule Lists (CORELS) Angelino et al. [2018", "2008": ".", "2018": "Support Vector\nMachines (SVM) Sch\u00f6lkopf and Smola [2002", "2001": "LightGBM Ke et al. [2017", "2016": "."}]}