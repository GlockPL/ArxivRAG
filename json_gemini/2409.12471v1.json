{"title": "Arena 4.0: A Comprehensive ROS2 Development and Benchmarking Platform for Human-centric Navigation Using Generative-Model-based Environment Generation", "authors": ["Volodymyr Shcherbyna", "Linh K\u00e4stner", "Diego Diaz", "Huu Giang Nguyen", "Maximilian Ho-Kyoung Schreff", "Tim Seeger", "Jonas Kreutz", "Ahmed Martban", "Huajian Zeng", "Harold Soh"], "abstract": "Building upon the foundations laid by our previous work, this paper introduces Arena 4.0, a significant advancement of Arena 3.0 [1], Arena-Bench [2], Arena 1.0 [3], and Arena 2.0 [4]. Arena 4.0 provides three main novel contributions: 1) a generative-model-based world and scenario generation approach using large language models (LLMs) and diffusion models, to dynamically generate complex, human-centric environments from text prompts or 2D floorplans that can be used for development and benchmarking of social navigation strategies. 2) A comprehensive 3D model database which can be extended with 3D assets and semantically linked and annotated using a variety of metrics for dynamic spawning and arrangements inside 3D worlds. 3) The complete migration towards ROS 2, which ensures operation with state-of-the-art hardware and functionalities for improved navigation, usability, and simplified transfer towards real robots. We evaluated the platforms performance through a comprehensive user study and its world generation capabilities for benchmarking demonstrating significant improvements in usability and efficiency compared to previous versions. Arena 4.0 is openly available at https://github.com/Arena-Rosnav.", "sections": [{"title": "I. INTRODUCTION", "content": "As the field of autonomous robots evolves, the demand for robots capable of navigating and interacting within human-centric environments continues to grow, particularly in areas such as healthcare, logistics, and assistive robotics [5]. To develop and test social navigation approaches that operate these robots, realistic and comprehensive simulation platforms are essential. However, the transition from simulation to real-world applications (sim2real) still remains a substantial bottleneck, with many existing platforms still reliant on outdated software such as ROS1, making the transition difficult and exacerbating the sim2real gap [6].\nFurthermore, despite recent advancements and the growing demand for social robotics, many existing works remain limited by overly specific implementations, lack of reproducibility, and fragmentation across different simulation platforms, which hinders broader adoption and industrial deployment [6], [5], [7]. As an effort to address these existing issues, in our previous work, Arena 3.0, we provided a unified platform to develop and test social navigation approaches in realistic social settings by incorporating sophisticated human behavior models and social interaction patterns, focusing on the complexities of social navigation [1].\nBuilding on these foundations, Arena 4 introduces a fully ROS2-based development and benchmarking platform to not only facilitate unified benchmarking and testing of social navigation approaches but also to improve the ease of transitioning from simulation to real-world robotic systems. The adoption of ROS2 is an important step towards closing the sim2real gap. The platform also integrates state-of-the-art generative AI techniques such as large language models (LLMs) and diffusion models to dynamically generate complex environments for development and benchmarking. The main contributions of this work are as follows:\n\u2022 The full transition of the platform to ROS2 with a number of new functionalities to ease production level development;\n\u2022 A world and scenario generation pipeline using generative models;\n\u2022 A 3D models database with semantically linked assets for dynamic and customizable world and scenario generation\n\u2022 Additional improvements such extended human behavior simulation with HuNavSim extension with social states for scenario generation, and enhanced usability features such as one click installer, user interfaces for creation and execution of processes, documentation, and tutorials;."}, {"title": "II. RELATED WORKS", "content": "This work builds on our previous platforms Arena-Bench [2], Arena 1.0 [3], Arena 2.0 [8], and Arena 3.0 [1] extended them with extended world and scenario generation, benchmarking, and usability functionalities. Furthermore it is fully migrated to ROS2 providing all its functions. This latest version emphasizes dynamic generation of social environments as well as addressing the needs for production level and operating with the latest industrial available robots. Furthermore, the platform employs a more stable version and adds capabilities for benchmarking and competitions due to the new dynamic world and scenario generation aiming for the platform to serve as a host platform for international competitions.\nRobot navigation and obstacle avoidance in dynamic environments have been a well studied problem in robotics with a diverse range of research works employing both classic control theory as well as learning based approaches using reinforcement or imitation learning [9], [10], [11], [12]. More recently, a number of approaches utilized large language or diffusion models to incorporate socially aware navigation into the system [13], [14], [15], [16], [17], [18]. However, a recent study by Francis et al. [7] on principles and guidelines for social navigation research found out that comprehensive simulation platforms for navigation benchmarking were still lacking or limited in functionality. Similar conclusions were drawn by a recent studies by Singamaneni et al. [6] and Mirsky et al. [5]\nSocial navigation platforms such as SEAN 1.0 and 2.0 by Tsoi et al. [19], [20] provided valuable insights but were limited in terms of environment variety and simulation capabilities. For instance, Habitat 3.0 [21] focuses solely on home environments whereas other platforms such as HuNavSim [22] or SocialGym 2.0 [23] are limited to specific simulators such as Gazebo or customized 2D simulators. Other benchmarking platforms such as Bench-MR by Heiden et al. [24], Robobench by Weisz et al. [25], CommonRoad by Althoff et al. [26], and the Benchmarking suite by Moll et al. [27] contributed significantly to static environment navigation but did not address dynamic human-robot interaction complexities. Benchmarks that include dynamic pedestrian movements such as MRPB 1.0 by Wen et al. [28], DynaBARN by Nair et al. [29] or CoNav by Li et al. [30] made strides in social navigation but faced limitations in scenarios, robot variety, or simulation environments.\nOur proposed platform addresses aforementioned gaps and aspire to provide a platform with comprehensive and dynamic world and scenario generation capabilities, a full transition to ROS2, as well as complete abstraction making it executable on multiple ubiquitous simulators, thus making it an ideal platform for de bencvelopment and benchmarking purposes."}, {"title": "III. OVERVIEW OF ARENA 4.0", "content": "Similar to our previous works, Arena 4.0 is designed as a platform software stack of modules to facilitate the development and benchmarking of social navigation methods. Figure 2 outlines the current version's modules. Arena 4.0 introduces several new key features:\nArena-gen. One of the main novel contributions is an improved world generation module Arena-gen, which employs generative models and a language-based interface, accompanied by a web-based interface, to allow users to customize world generation processes for an array of diverse applications.\nArena-Models. Closely related is another essential contribution, the Arena-Models database that allows users to add and semantically link 3D models and assets for the system to plan for and spawn them in a dynamic manner. For creating and editing semantic annotations, we also provide an intuitive database explorer GUI. The Task generator and Simulation-Setup have been adapted and extended to receive those input and generate dynamic worlds and scenarios from the additional scene graph and room segmentation annotations. In the same manner, the respective simulators Gazebo and Unity have been adapted to reflect that information where applicable.\nROS2 migration. Another significant contribution is the complete migration to ROS2 to facilitate and simplify deployment in industrial production setups and robots, making newer functions accessible that are critical for production site robots, such as security, communication protocols, and improved navigation functionalities. This migration to ROS2 includes the navigation stack, which now operates on the Nav2 package, making it more accessible for newer robots that run exclusively on ROS2, such as Unitree's quadrupeds. It is important to note that the ROS1 version is still supported, and the possibility to run both in parallel is maintained until the end of the ROS1 lifecycle next year.\nHuman Behavior Models. Finally, human behaviors have been optimized, extended, and refined. Specifically, we incorporated the open-source framework HuNavSim and extended it with more human-human and human-object interactions. In addition to these three core contributions, Arena 4.0 also adds a number of other miscellaneous functions such as new robots, planners, an improved training pipeline, a web application, or a comprehensive installer. In the following, each module will be described in more detail."}, {"title": "A. Arena-gen: Generating Distinct Environments using Generative Models", "content": "The system design of the Arena-gen submodule is illustrated in Figure 2. It includes the pipeline for generating environments. Whereas in Arena 3, only three distinct randomized environment types could be generated, Arena Gen allows for the generation of a wide variety of indoor environments using language descriptions and diffusion models.\nFigure 3 illustrates the system design. Our generation process consists of a 2-stage pipeline, consisting of a Generation and a Population stage. The Generation stage uses an LLM that transforms natural language prompts into a a machine-readable graph. This graph is used in GNN inference to produce (1) an annotated floor plan image, and (2) asset regions placed within the rooms.\nDuring the Population Stage, the space of the assets is filled with models from a semantic model database. The floor plan, together with all placed models, is transformed into a final 3D environment that can be loaded by a simulator. Subdividing the process in this manner allows us to exploit the full extent of the expressiveness of the generative model during generation and then solving the model-populating sub-problem using more modular semi-classical approaches.\n1) 3D Scene Graph: We introduce a variant of the 3DSG [31] as an intermediate format between the LLM and GNN components. The 3DSG format is a 2-level hierarchical graph that contains the room layout with room-room connections (upper half), and room-asset relationships (lower half) with asset descriptions. Assets are defined by a natural language description of the object, size, and color \u2013 which the LLM extracts and supplements from user input. Preserving natural language descriptions throughout the pipeline allows us to decouple the embedding and thus semantics of each stage, making feature extraction fit each purpose instead of the data.\n2) Dataset: Our dataset consists of (3DSG, floor plan image) pairs that are used to train our GNN. The samples are based on the CubiCasa5K [32] dataset, which contains almost 5000 suitable real-world floor plan scans. The provided CubiCasa5K data processing detects the room and object segmentations using pre-trained CNNs, which we use as a base for our own data processing. We extract the 3DSG by (1) filtering and re-categorizing assets, (2) classifying doorways as either inter-room or external, (3) building a room connectivity matrix from inter-room doorways, (4) assigning the remaining assets to the sub-graph of the containing room. The result is a hierarchical graph in our 3DSG format paired with a cleaned floor plan image for direct insertion of our dataset."}, {"title": "B. Model Database", "content": "Another contribution of our work is the provision of a model database Arena-Models, which is a semantic database of obstacle and human 3D models that can be spawned in the simulation. We provide a workflow and builder scripts to process a directory containing models and annotations into 1) a prompt-queriable vector database of model IDs, 2) a simulator-specific Asset Bundle that stores the 3D models in a single compressed file. End users can use our Python API to query the database and retrieve models, both as Unity prefabs and as exported COLLADA files for use in other simulators. Compared to the classic solution of loading a directory of models at run-time, we propose several key differences for more efficient processing of the input data: 1) we pre-compute additional annotations, e.g. 2D convex hulls, during the build process, 2) natural language queries provide a layer of abstraction that is convenient to interface with neural network outputs, in particular LLMs, 3) all semantic annotations are directly available from one query, 4) the indexing overhead is shifted from the end user's runtime to our build time, 5) models are released in a semi-obfuscated format, compatible with more licenses than raw files."}, {"title": "C. ROS2 migration", "content": "Arena 4.0 is fully operational under ROS2. To achieve this, we developed a number of components specifically for ROS2, including a dynamic map generator and a universal metrics recorder and evaluator. Additionally, we migrated to the Nav2 framework, which provides enhanced navigational functionalities such as recovery behavior, dynamic switching between planners, or enhanced SLAM cababilities out of the box. This migration also simplifies the deployment of the navigation stack on robots, such as quadrupeds, that operate exclusively under ROS2. Furthermore, functionalities such as real-time support, security, and communication protocols are now accessible using ROS2. A table listing all the modules that were migrated from ROS1 to ROS2 is provided in Table I."}, {"title": "D. Scenario Generation and Human Behavior Simulation", "content": "To extend the human simulations of our previous works, we integrated HuNavSim [22] into our platform and leveraged our new semantic annotations of existing and generated worlds to provide a more complete and realistic simulation of pedestrian behavior. Points are sampled from semantic world regions (zones) to produce endless pedestrian behavior scenarios, which are further enhanced by the use of human-human/robot interactions to create a nuanced social environment. Our extensions to HuNavSim allow for more semantic depth, which finds applications in professional environments with distinct pedestrian roles, e.g., hospitals and offices."}, {"title": "E. Improvement of Usability Features", "content": "Several user studies and surveys conducted during our previous works [1] provided valuable feedback on the necessity for improvement in usability features such as easy installation and comprehensive documentation. Thus, we have incorporated the responses and feedback to enhance the user experience and development cycle such as the provision of multiple graphical user interfaces for improved user understanding and control customization, as well as editors for annotating training data that directly match the format required to execute functions, e.g., creating new rooms and scenarios. Furthermore, the installation process has been simplified through the use of an installer that guides the user through the installation."}, {"title": "F. Platform for competition and benchmarking", "content": "Arena 4.0 extends evaluation capabilities by providing a number of functions to enable the platform's use for unified benchmarking. With the provided APIs, we facilitate the integration of methods and new planners. The introduced world generation pipeline is capable of generating a unified set of specialized environments of varying difficulty levels, which is crucial for providing consistent and standardized worlds for testing and benchmarking (examples illustrated in Figure 5). This allows users to test their approaches in specific situations and scenarios, based on individual circumstances and needs. As such, Arena 4.0 is has been selected as the hosting platform for the competition as part of the SocialNav2025 workshop."}, {"title": "IV. VALIDATION AND EVALUATION", "content": "Similar to all our previous works, we conducted a study asking participants to install and test out specific modules of the platform. Subsequently, we evaluated the capabilities of the o module ur proposed world generation module to generate levels of increasing difficulty and variety from text prompts."}, {"title": "A. User Study", "content": "We evaluated our platform through a user study with 20 participants from universities in Germany, Switzerland, the US, Singapore, Vietnam, Japan, and Korea, all with varying levels of robotics expertise. Participants were selected from diverse groups, including students and researchers familiar with previous versions of Arena, social navigation researchers who had never used Arena, new users from our lab, and students from various international universities without prior experience with Arena. Participants were instructed to install and interact with the platform by completing a specific set of tasks and subsequently completed a questionnaire covering the questions about the platform. All questions and responses are publicly available online.\nThe study results were mostly positive, with participants highlighting the platform's diverse functionalities in world generation and customizable scenario creation as key enhancements. Both new and experienced users emphasized that the simplified installation process greatly improved usability. Most participants expressed interest in using the platform for benchmarking and integrating their own planning algorithms. Some industry and academic participants also suggested that incorporating a more realistic simulator, like Isaac Gym and Habitat, could further enhance the platform. Furthermore, a number of participants found the evaluation and plotting pipeline counterintuitive, preferring the previous version's customizable iPython notebooks over the current web-based interface. We are currently using this feedback to further improve Arena."}, {"title": "B. World Generation Evaluation", "content": "Figure 5 illustrates examples of worlds generated using Arena-gen at different difficulty levels, based on the prompt: \"Generate 50 indoor worlds with 8 difficulty levels.\", repeated for 100 batches with different contexts, ranging from residential homes to hospitals. Figure 7 outlines the average computational cost across all worlds. To evaluate the difficulty of the generated levels, we plotted various factors that could potentially contribute to increased difficulty, such as the number of rooms, assets, links to other entities, and the number of pedestrians. Figure 6 illustrates these plots. We show (1) the asset and doorway count, and (2) the leaf/non-leaf room count, plotted against world difficulty. Thereby, the difficulty is estimated by the LLM using the number of rooms and obstacles. A linear growth of all metrics can be observed with increasing world difficulty. This indicates that real complexity scales well with input difficulty and does not saturate even up to 25-room worlds, covering most practical use cases. The doorway count shows lower variance compared to the other metrics, suggesting a strong correlation between room count and non-leaf room count. (4) and (5) display the absolute frequency of (non-leaf) nodes, leaf nodes, and assets per scene graph in the dataset. The wide distributions demonstrate the diversity of generated environments. (3) shows the mean and variance of the number of rooms and leaf rooms against the number of doorways. A continuous growth of the mean with bounded variance is clearly visible. (6) shows the increase in the graph edges count with an increase in the number of rooms, while the graph diameter (minimum longest distance between any two nodes) is kept low. In practice, our generated worlds offer a desirably high graph connectivity, providing robots with several pathways to reach the same goal."}, {"title": "V. CONCLUSION", "content": "In this paper, we introduced Arena 4.0, an enhanced version of our previous platforms emphasizing the dynamic generation of 3D environments for training, testing, and benchmarking. Using the Arena models database, users can integrate their own 3D assets and link them semantically to be placed, spawned, and interact with each other. We have fully migrated the platform to operate entirely under ROS2 to ensure compatibility with recent robotics hardware and ease the transition to industry production levels. Furthermore, we improved usability features such as a fast installation process, substantially faster processing times, and simplified usage through the GUIs. Our evaluations and user studies demonstrated substantial improvements in processing efficiency and enhanced user experience. Future work includes the addition of simulators such as Isaac Gym and Habitat, the employment of multi-agent reinforcement learning approaches, as well as automated pipelines for deployment on real robots. Additionally, we aspire to release the second version of Arena-web [33], which will offer the majority of the current platform's functionalities within a web application."}]}