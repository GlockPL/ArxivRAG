{"title": "AnyGraph: Graph Foundation Model in the Wild", "authors": ["Lianghao Xia", "Chao Huang"], "abstract": "The growing ubiquity of relational data structured as graphs has un-derscored the need for graph learning models with exceptional gen-eralization capabilities. However, current approaches often struggleto effectively extract generalizable insights, frequently requiring ex-tensive fine-tuning and limiting their versatility. Graph foundationmodels offer a transformative solution, with the potential to learnrobust, generalizable representations from graph data. This enablesmore effective and adaptable applications across a wide spectrumof tasks and domains. In this work, we investigate a unified graphmodel, AnyGraph, designed to handle key challenges: i) StructureHeterogenity. Addressing distribution shift in graph structuralinformation; ii) Feature Heterogenity. Handling diverse featurerepresentation spaces across graph datasets; iii) Fast Adaptation.Efficiently adapting the model to new graph domains; iv) ScalingLaw Emergence. Enabling the model to exhibit scaling law be-havior, where its performance scales favorably with the amountof data and parameter sizes. To tackle these critical challenges, webuild the AnyGraph upon a Graph Mixture-of-Experts (MoE) archi-tecture. This approach empowers the model to effectively manageboth the in-domain and cross-domain distribution shift concern-ing structure-level and feature-level heterogeneity. Furthermore, alightweight graph expert routing mechanism is proposed to facili-tate AnyGraph's fast adaptability to new data and domains. Ourextensive experiments on diverse 38 graph datasets have demon-strated the strong zero-shot learning performance of AnyGraphacross diverse graph domains with significant distribution shift.Furthermore, we have validated the model's fast adaptation abilityand scaling law emergence, showcasing its versatility.", "sections": [{"title": "1 Introduction", "content": "The growing ubiquity of relational data in the form of graphs hasunderscored the pressing need for advanced graph learning modelsthat excel at generalization [7, 13]. As real-world applications ofgraph-structured data continue to proliferate across diverse do-mains, including social networks, academic networks, transporta-tion systems, and biological networks, the ability of graph learningmodels to effectively handle distribution shifts and adapt to newgraph domains has become increasingly crucial [20, 29, 37, 38]. De-veloping models with robust zero-shot learning performance andfast adaptation capabilities can unlock transformative opportunitiesfor leveraging the rich insights encoded within graph data.\nThe field of graph learning has seen significant advancements inrecent years, largely driven by the power of Graph Neural Networks(GNNs) [15, 18, 31]. However, the current state-of-the-art modelsoften fall short when it comes to truly generalizable performance.Existing approaches tend to be heavily reliant on arduous fine-tuning processes, making them ill-equipped to handle the diversearray of graph structures and distributions encountered in real-world applications. This inability to adapt swiftly and seamlesslyto novel graph domains poses a critical barrier to the widespreadadoption of graph learning technologies. Therefore, addressing thischallenge is of paramount importance if we are to fully harness thetransformative potential of graph-based insights.\nInspired by the principles that have driven the development ofsuccessful foundation models in understanding vision and languagedata [26, 27], the concept of a versatile graph foundation modelholds immense potential to unlock new frontiers in graph learning.By learning rich, transferable representations from diverse graph-structured data, such a model can be efficiently adapted to a widearray of graph domains and tasks. However, building an effectiveand adaptive graph foundation model is not a trivial endeavor.Several key challenges must be overcome, including:\n(i) Structure Heterogeneity. The development of versatile graphmodels faces the challenge of accommodating diverse structuralproperties and data distributions in various graph datasets. Forinstance, graphs can exhibit substantial heterogeneity in node degree distributions, ranging from homogeneous to highly skewedpatterns. Similarly, graph structures can vary greatly in complexity, from simple topologies to intricate, hierarchical arrangements.These structural variations can significantly impact the performance and generalization of graph learning algorithms. Effectivelyaddressing this diversity is critical for developing unified modelsthat can thrive across a wide range of graph-structured data.\n(ii) Feature Heterogeneity. Graphs exhibit substantial heterogeneity in their node and edge features, which can span categoricalattributes, continuous numerical data, and multi-modal content.Furthermore, the dimensionality and semantics of these features often vary dramatically across different graph domains. For instance,a social interaction graph may include textual content and demographic information associated with its nodes, while a moleculargraph may feature atomic compositions and bond types. Effectivelyhandling this feature heterogeneity is crucial for building a versatilegraph model capable of generalizing across diverse graph domains.\n(iii) Fast Adaptation for Broad Applicability. A key capabilityfor effective graph foundation models is the ability to efficientlyadapt to new graph dataset and domains. Rather than requiringextensive retraining or fine-tuning, the ideal model should be able to"}, {"title": "2 Preliminaries", "content": "Graph-Structured Data. A graph \\(G\\) consists of a set of nodes\\(V = \\{v_i\\}\\) and a set of edges \\(& = \\{(v_i, v_j)\\} \\). In many cases, eachnode \\(v_i\\) is associated with a feature vector \\(f_i \\in \\mathbb{R}^{d_o}\\). To efficientlyutilize such graph-structured data, the link information is typicallyrecorded using an adjacency matrix \\(A \\in \\mathbb{R}^{|V|\\times|V|}\\). Each element\\(a_{i,j}\\) of \\(A\\) is either 1 or 0, inddicating whether there is an edge fromnode \\(v_i\\) to \\(v_j\\). Additionally, the feature vectors of the nodes areusually represented by a feature matrix \\(F\\in \\mathbb{R}^{|V|\\times d_o}\\), where eachrow corresponds to a node's feature vector. The primary goal oflearning from such graph-structured data is to generate embeddingsfor the graph elements, typically nodes, that effectively capture boththe structural and feature-based information of the graph.\nGraph Foundation Models (GFMs). The essence of GFMs lies intheir strong generalization capabilities. Specifically, a graph foundation model should be able to handle unseen graph data that exhibit significant discrepancies from its training graph datasets. Thesediscrepancies may include differences in feature spaces, as well asvariations in node and edge semantics across datasets. Formally,let's denote the training graphs as \\(S = \\{G_s\\}\\), where each graph \\(G_s\\)is associated with a label set \\(Y_s\\). Similarly, the set of test graphs isdenoted as \\(T = \\{G_t\\}\\), with labels \\(Y_t\\). With a differentiable training"}, {"title": "3 Methodology", "content": "The proposed AnyGraph framework aims to address both cross-domain and in-domain heterogeneity in graph structures and nodefeatures, while enabling fast adaptation to new data. The overallframework of AnyGraph is depicted in Fig. 2."}, {"title": "3.1 MoE Architecture of AnyGraph", "content": "3.1.1 Addressing Cross-domain Graph Heterogeneity. To model heterogeneous graph patterns across different domains, Any-Graph employs a MoE architecture that consists of multiple graphexpert models, each responsible for handling graphs with specificcharacteristics. An automated routing algorithm is designed toassign input graph data to the most competent expert model fortraining and prediction. Specifically, the AnyGraph framework canbe denoted as \\(M = (f_{\\theta_1}, f_{\\theta_2},\u00b7\u00b7\u00b7, f_{\\theta_K}, \\psi)\\), where \\(K\\) denotes thenumber of experts. For an input graph \\(G\\), the routing algorithm \\(\\psi\\)firstly identifies the most competent expert model, and the corresponding model is then used for predicting the graph data, as:\n\\[\\hat{y}_{i,j} = \\hat{e}_i^T \\hat{e}_j, \\quad \\hat{e}_i = f_{\\theta_r}(G), \\quad k = \\psi(G)\\]\nwhere each expert model \\(f_{\\theta_r}\\) can be viewed as a projection fromthe graph space to a node embedding space with uniquely trainedparameters \\(\\theta_k\\). And \\(\\hat{y}_{i, j}\\) represents the dot-product-based prediction of whether the entity \\(v_i\\) should be related to the entity \\(v_j\\). Here,\\(v_i\\) and \\(v_j\\) could be vanilla graph nodes, class labels, or graph labels.\n3.1.2 Graph Expert Routing Mechanism. Inspired by the effectiveness of graph self-supervised learning tasks [12], we propose measuring the competence of expert models on specific graphdatasets using the models' self-supervised learning loss values.Specifically, for an input graph \\(G = (V,\\&)\\), the routing mechanism \\(\\psi\\) calculates the dot-product-based relatedness scores forsome positive edges \\((v_{c_1}, v_{p_1}),\u00b7\u00b7\u00b7, (v_{c_S}, v_{p_S}) \\in \\&\\) and analogouslycalculates the relatedness scores for some sampled negative nodepairs \\((v_{c_1}, v_{n_1}),\u00b7\u00b7\u00b7, (v_{c_S}, v_{n_S}) \\notin \\&\\). The following score differenceis then calculated as the competence indicator \\(\\phi_k\\) for the \\(k\\)-th expert"}, {"title": "3.1.3 Fast Adaptation Capabilities of AnyGraph", "content": "With theaforementioned MoE architecture and routing mechanism, the training and inference process of AnyGraph is conducted by only one expert model. This approach consumes only 1/K of the computationaland memory resources required for predictions and optimization,compared to other non-MoE graph foundation models based oncomplex networks like transformers. This endows AnyGraph withthe advantage of fast adaptation when dealing with new datasets."}, {"title": "3.2 Adaptive and Efficient Graph Experts", "content": "3.2.1 Addressing In-domain Graph Heterogeneity. To handlegraph data with different adjacency and feature dimensionalities,the expert models of our AnyGraph employ a structure and featureunification process. Adjacency matrices and node features of vary-ing sizes are both mapped into initial node embeddings of fixeddimensionality using a unified mapping function. Inspired by theeffectiveness of singular value decomposition (SVD) in extractingimportant latent features, we utilize SVD for this unified mapping"}, {"title": "3.2.2 Efficient and Strong Feature Encoder", "content": "To achieve efficiency while retaining the capacity to encode graph features, ourgraph experts are configured by deep multi-layer perceptron (MLP)networks. Specifically, the final node embeddings given by an expertmodel is calculated iteratively as follows:\n\\[\\bar{E}^{(l+1)} = LayerNorm \\Big(Dropout \\Big(ReLU\\big(\\bar{E}^{(l)}W+b\\big)\\Big) + \\bar{E}^{(l)}\\Big)\\]\nThe final embeddings are denoted as \\(\\hat{E} = \\bar{E}^{(L')}\\in \\mathbb{R}^{|V|\\times d}\\), where\\(L'\\) represents the number of fully-connected layers. And \\(\\bar{E}^{(0)}\\) isinitialized by the aforementioned embeddings \\(E_1\\). Each layer of our"}, {"title": "3.3 Efficient Cross-domain Model Training", "content": "To maximize the cross-graph generalizability of AnyGraph, thetraining samples from different datasets are mixed together andrandomly shuffled for model training. Each batch of training samples contains the following information:\n\\[S = \\{\\Big((v_{c_s}, v_{p_s}) \\in B\\Big)\\}\\subset \\&_{G_s},\\quad \\&_i = InitialEmbed(G_s),\\quad for \\quad where \\quad k = \\psi(G_s)\\]\nInspired by the effectiveness of link-wise graph pre-training tasks [12],we utilize link prediction as the training task. Here, \\((v_{c_s}, v_{p_s})\\) denotes the positive edges for link prediction, and B denotes the batchsize. To facilitate batch training, each training batch involves onlyone training graph \\(G_s\\). The initial node embeddings \\(&_1\\) and themost competent expert model for are preprocessed in advance toaccelerate the training. Specifically, the loss function used by ourAnyGraph training is as follows:\n\\[L=\\sum_{s\\in S} -log\\frac{exp(\\hat{y}_{c_s,p_s} - \\hat{y}_{max})}{\\sum_{v_n\\in V} exp(\\hat{y}_{c_s,n} - \\hat{y}_{max})}\\]\nThis training objective maximizes the prediction scores for positivesamples \\((v_{c_s}, v_{p_s})\\) and minimizes the predictions for all possiblenode pairs between \\(v_{c_h}\\) and all nodes \\(v_n\\). To avoid numerical instability, we employ a technique where the maximum prediction scoreof the batch, \\(\\hat{y}_{max}\\), is subtracted from all prediction scores."}, {"title": "3.3.1 Feature and Structure Augmentation", "content": "To further enrichthe training data, the training of AnyGraph undergoes periodicreprocessing of, firstly, the initial graph embeddings \\(E_1\\), and sec-ondly, the graph routing results. We demonstrate that such reprocessing augments the features and structures of the original graphdata, thereby training AnyGraph using more diversified input data.\nFor the initial graph embeddings, we periodically reconductthe SVD and simplified GCN processes after a certain number oftraining steps. This helps generate different embedding spaces forthe same data, thereby greatly improving the generalizability ofAnyGraph regarding representation heterogeneity [16]. To preventthis process from consuming excessive computational time, wepropose adopting different augmentation frequencies adaptive tothe size of different datasets. Specifically, each dataset undergoesthis representation augmentation after \\(|E|/(10B)\\) training steps.\nFor the graph routing results, we also periodically recalculate therecalibrated competence scores. Specifically, the positive samplepairs \\((v_{c_s}, v_{p_s})\\) for \\(s = 1,..., S\\), as well as the negative samples \\(v_{ns}\\),are randomly sampled. This essentially performs structure augmentation by using a random subset to evaluate the performance ofgraph experts on the input graph, thereby enhancing the model'srobustness against structural noise."}, {"title": "3.3.2 Complexity Analysis", "content": "The training and inference processof AnyGraph is conducted by only one expert model, which has acomplexity of \\(O(B\\times d^2\\times L')\\) for each batch. Since we preprocess theinitial embeddings and the expert routing, these two processes donot increase the batch-wise computational complexity. As a result,the complexity of the forward and backward steps for AnyGraph ismuch lower than that of other graph foundation models that involvecomplex GNNs and graph transformers. Additionally, the expertrouting performs \\(O\\big(\\sum_{G_s} |\\&_s| \\times d \\times K + \\sum_{G_s} |V_s| \\times d^2 \\times L' \\times K\\big)\\)computations, where the latter term empirically has a larger scalecompared to the former term. This dominant term is similar to asimple GCN network of a comparable model size. Overall, Any-Graph is more efficient than existing methods in both trainingand inference, and the additional computations for routing have acomplexity comparable to simple GCNs."}, {"title": "4 Evaluation", "content": "Our experiments aim to answer the following Research Questions:\n\\begin{itemize}\n    \\item RQ1: How does the zero-shot prediction performance of Any-Graph compare to different baseline methods?\n    \\item RQ2: How do AnyGraph's various modules impact its overall performance with the contribution of each component?\n    \\item RQ3: How does the model size and the amount of training data influence the performance of AnyGraph?\n    \\item RQ4: How interpretable is the expert routing mechanism within AnyGraph's graph Mixture-of-Experts (MoE) architecture?\n    \\item RQ5: How is the scalability and efficiency of AnyGraph compare to fine-tuning methods when adapting to new datasets?\n\\end{itemize}"}, {"title": "4.1 Experimental Settings", "content": "4.1.1 Experimental Datasets. To conduct a comprehensive eval-uation of the cross-domain generalizability of graph models, weemploy a total of 38 graph datasets. These datasets span a widerange of domains, including e-commerce (e.g. user interactions andproduct-wise relations), academic graphs (e.g. citation and collab-oration networks), biological information networks (e.g. relationsamong drugs and proteins), and other domains like email networks,website networks, trust networks, and road networks.\nWe set up different dataset groups and conduct cross-datasetevaluations on these groups. Specifically, all datasets are dividedinto two cross-domain groups, Link1 and Link2, which have asimilar number of total edges and a similar number of domain-specific edges. Specifically, the Link1 and Link2 groups contain15 and 18 datasets, respectively. For the node classification task,we use 5 datasets gathered from e-commerce and academic information scenarios. Additionally, we have three domain-specificgroups: Ecommerce, Academic, and Others. The Others groupis primarily composed of biological networks, combined with othersmall domains that have fewer datasets. See Appendix A.1 for moreinformation of our experimental datasets.\n4.1.2 Experimental Settings. We follow previous works [9, 14]for dataset splitting and evaluation metrics. Our AnyGraph modeland the graph foundation models are evaluated on a cross-graphzero-shot prediction task. For baselines that cannot handle cross-dataset transfer, we evaluate their few-shot performance. Details ofthe evaluation protocols are provided in Appendix A.2. The Hyper-parameter Settings of AnyGraph are provided in Appendix A.3.The compared Baseline Methods are introduced in Appendix A.4."}, {"title": "4.2 AnyGraph's Zero-Shot Prediction (RQ1)", "content": "To assess the zero-shot prediction capabilities of the AnyGraphmodel, we conducted an extensive evaluation across 38 graphdatasets from various domains. We independently trained two versions of the AnyGraph model - one on the Link1 dataset and theother on the Link2 dataset. Each trained model was then used tomake zero-shot predictions on datasets it was not originally trainedwith. It is important to note that the Link1 and Link2 datasets donot share the same feature spaces or sources of data collection, whichadds to the complexity and challenges of the zero-shot evaluation.We also compare our AnyGraph with existing graph foundationmodels. And in this comparison we add another AnyGraph-F ver-sion, which removes the utilization of node features. The outcomesof this evaluation are detailed in Table 1 and Table 2, and our keyobservations are listed as follows:\ni) Superior Generalizability across Diverse Datasets. Supe-rior Prediction Accuracy. Compared to the few-shot capabilitiesof existing GNN models, pre-training techniques, and foundationmodels, AnyGraph demonstrates exceptional zero-shot predictionaccuracy across various domains. This superior performance spansboth link prediction and node classification tasks. EffectivelyHandling Heterogeneity. The enhanced generalizability can beat-tributed to the effective handling of structure-level and feature-leveldata heterogeneity through unified structure and feature representations in the expert models. This approach enables AnyGraph todevelop comprehensive modeling functions that are universallyapplicable across different graph data scenarios. Comprehen-sive Training. Additionally, the extensive training regimen, whichincorporates a variety of large-scale datasets, equips AnyGraphwith a deep and broad expertise in graph modeling and prediction."}, {"title": "4.3 Scaling Law of AnyGraph Framework (RQ2)", "content": "In this section, we explore the applicability of the scaling law toAnyGraph. We conduct experiments using 18 different versionsof AnyGraph, each differing in model size and quantity of training data. Specific configurations of these variants are discussedin Appendix A.5. The evaluation results are depicted in Figure 3,which includes overall and domain-specific performance, as well aszero-shot and full-shot outcomes. Our key findings are as follows:\ni) Generalizability of AnyGraph Follows the Scaling Law.As the model size and the volume of training data increase, wenotice a saturation point in AnyGraph's full-shot performance. Incontrast, the zero-shot prediction accuracy continues to improve.This pattern supports the scaling law of graph foundation models,illustrating that scaling up can significantly enhance the capabilitiesof graph models. Two key factors contribute to this phenomenon:\n\\begin{itemize}\n    \\item Task Difficulty. The saturation in full-shot performance is partly because the evaluation tasks might not be challenging enough.\n\\end{itemize}"}, {"title": "4.4 Ablation Study (RQ3)", "content": "This section evaluates the effectiveness of AnyGraph's sub-modulesby comparing ablated variants in terms of their zero-shot and full-shot performance across both cross-domain datasets and domain-specific datasets (specifically Academic data). The results are inFigure 4. We make the following observations:\n\\begin{itemize}\n    \\item MoE Significantly Enhances Zero-Shot Performance. The -MoE variant, which employs a single expert model without the MoE architecture, demonstrates decent performance on datasets on which it was trained, as shown in parts (b) and (c). However, this variant exhibits a substantial decline in zero-shot prediction capabilities. This underscores the critical role of the MoE architecture in enhancing AnyGraph's generalization abilities. The use of multiple expert models significantly expands AnyGraph's modeling capacity, effectively managing the large disparities between various domains using multiple seperated models.\n    \\item Feature Modeling is Crucial in AnyGraph. In the -Feat variant, node features are omitted, leading to the most significant degradation in both zero-shot and full-shot performance. This underscores the effectiveness of AnyGraph's unified structure\n\\end{itemize}"}, {"title": "4.5 Investigation on Expert Routing (RQ4)", "content": "This section delves into the expert routing mechanism of AnyGraph.Figure 5 displays the competence scores of various expert models forthe input datasets, as determined by AnyGraph's routing algorithmbased on the self-supervised loss. The figure illustrates that datasetssharing common characteristics-such as source of collection orfeature construction method are often routed to the same expertmodels by AnyGraph. For instance, datasets like arxiv-ta, Photo,GoodReads, and Fitness, which utilize a common text-embedding-based feature space, are assigned to highly similar experts (expert0, 2, 4, 5). Additionally, ML1M and ML-10M, both sourced from themovie-rating platform Movielens, are predominantly associatedwith expert 1. It is also notable that this routing pattern extends\nto zero-shot datasets, as shown on the right part of Figure 5. Here,YelpT, SteamT, and AmazonT, which share the same feature space,are assigned to very similar expert models. This outcome underscores the efficacy of AnyGraph's routing mechanism in identifyingthe appropriate expert models for various datasets, and also showcases its explainability in revealing graph-wise relatedness."}, {"title": "4.6 Efficiency Study (RQ5)", "content": "Tuning Curve Comparison. To evaluate the efficiency of Any-Graph, we compare its fine-tuning process with that of GraphCLand the training from scratch process of a GCN model. As depictedin Figure 6, when fine-tuned on a new dataset, the pre-trained Any-Graph rapidly achieves a high performance saturation point. In"}, {"title": "5 Related Works", "content": "Graph Neural Models. Graph learning has garnered significantinterest for its broad applicability across various fields such asuser behavior modeling, social analysis, and studies in biology andchemistry [2, 8]. Graph neural networks (GNNs) learn node representation vectors for downstream tasks like node classification andlink prediction. The core mechanism involves iterative messagepassing, refining node embeddings to capture both node-specificinformation and higher-order topological structures. This processensures that the final node embeddings effectively encapsulateboth node-specific information and higher-order topological structures. Notable techniques include Graph Convolutional Networks(GCNs) [11], Graph Attention Networks (GATs) [1], Graph Isomor-phism Network (GIN) [33], and Graph Transformer [10], whichimproves the encoding function for better graph modeling. Despitethese advancements, these methods still require high-quality training data and often struggle with generalization capabilities.\nSelf-Supervised Graph Learning. Given the challenges with thegeneralizability of GNNs, considerable research efforts [32] havefocused on enhancing GNNs through self-supervised learning objectives, aiming to capture invariant graph features. Specifically,GraphCL [36] introduced a contrastive pre-training approach forgraph data, designed to learn authentic graph characteristics thatare robust to structural and feature perturbations. Building on this,JOAO [35] and GCA [39] have developed adaptive augmentationstrategies for self-supervised tasks, effectively mitigating the adverse effects of random augmentations. Subsequent works havesought to quickly adapt these pre-trained models to downstreamtasks and evolving graph data, as demonstrated by GPF [6] andGraphPrompt [19]. Despite these advancements, the generalizability of these methods remains confined to graph data with similarstructural patterns and feature spaces, thus not addressing the cross-domain generalization challenges highlighted in this paper.\nLarge-scale Graph Pre-training. Recent advances in graph mod-eling have seen efforts to pre-train large-scale graph models acrossmultiple datasets to improve their generalization abilities, drawinginspiration from the strong generalization capabilities of large language models (LLMs) [30]. For instance, OFA [17] and ZeroG [16]utilize text embeddings to standardize the feature spaces acrossvarious graph datasets and tasks, facilitating cross-dataset trainingof graph models. Models like InstructGLM [34] GraphGPT [23] andLLaGA [4] synchronize graph representation spaces with the hidden spaces of LLMs, thus enabling the application of general LLMsfor graph prediction tasks. Furthermore, HiGPT [24] expands thecapabilities of LLMs to accommodate heterogeneous graph data.\nDespite these advancements, most generalized graph modelsrequire substantial access to and integration of text features, whichconfines their use primarily to text-abundant environments suchas academic networks. Additionally, these methods are typicallytrained within specific application realms, failing to address thesignificant variances between datasets from diverse domains."}, {"title": "6 Conclusion", "content": "In this work, the presented AnyGraph framework, an effective andefficient graph foundation model designed to address the multifaceted challenges of structure and feature heterogeneity acrossdiverse graph datasets. AnyGraph's innovative Mixture-of-Experts(MoE) architecture, coupled with its dynamic expert routing mechanism, positions it at the state-of-the-art of cross-domain generalization capabilities. Extensive experiments on 38 varied graphdatasets have not only underscored AnyGraph's superior zero-shotlearning performance but also its robustness to distribution shiftsand its adherence to scaling laws, thereby enhancing its predictiveaccuracy with increased model size and data volume. The model'sefficiency in training and inference, validated through comparisonwith existing methods, further cements its practical applicability."}, {"title": "A Appendix", "content": "A.1 Experimental Datasets\nWe utilize a total of 38 graph datasets across various domains. Theentire dataset contains 14,437,372 nodes, and 199,265,688 edges. Thedataset specifics are detailed below:\nE-commerce Datasets. This category includes 15 datasets fromvarious e-commerce contexts such as user rating platforms and on-line retail services. These datasets vary in terms of the presence andtype of node features. For instance, datasets such as Amazon-book,Yelp2018, Gowalla, Yelp-text, Amazon-text, Steam-text, Goodreads,Amazon-Fitness, Amazon-Photo, Movielens-1M, Movielens-10M,Products-home, Products-tech, Home-node, Tech-node are included.Notably, Amazon-text, Steam-text, and Yelp-text utilize the samemethod for feature generation, while Fitness, Photo, and Goodreadsemploy a different consistent method.\nAcademic Network Datasets. We use 13 datasets focused onacademic networks, which include citation and collaboration relations among scholars and papers. These datasets represent variousresearch fields and employ diverse feature generation methods,such as NLP embeddings, bag-of-words, and different versions oflarge language models. The specific datasets are Cora, Pubmed,Arxiv, Cora-link, Pubmed-link, Citeseer, CS, Arxiv-link, Arxiv-t(with features derived using an alternative method), Citation-2019,Citation-20Century, OGB-Collab.\nBiological Information Networks. Our collection includes 6datasets related to biological entities like proteins, drugs, and dis-eases. This category features networks such as OGB-DDI, OGB-PPAand four protein relation networks for different species, denoted asProteins-0, Proteins-1, Proteins-2, Proteins-3.\nOther Datasets. In addition to the categories mentioned above,we include 5 datasets from various other fields: an email networkEmail-Enron, a website network Web-Stanford, a road networkdataset RoadNet-PA, a P2P web network dataset P2P-Gnutella06,and a trust network dataset Soc-Epinions1.\nDataset Groups. For conveinience of performance evaluation, wespilt the many datasets using different grouping methods. Firstly,two big data groups Link1 and Link2 are made using all the linkprediction datasets. Notably, datasets from the same source of col-lection, such as Movielens-1M and Movielens-10M, or uses the samemethod to generate features, such as Fitness, and Photo, are putinto the same group, to avoid information leakage when evaluatingzero-shot performance on the other group. Apart from these twodatasets, we also conduct evaluations on domain-specific groups,including E-commerce, Acadmic, and Others. Specifically, thesedata groups contain the following datasets, respectively:\n\\begin{itemize}\n    \\item Link1: Products-tech, Yelp2018, Yelp-textfeat, Products-home, Steam-text, Amazon-text, Amazon-book, Citation-2019, Citation-20Century, Pubmed-link, Citeseer, OGB-PPA, P2P-Gnutella06, Soc-Epinions1, Email-Enron.\n    \\item Link2: Photo, Goodreads, Fitness, Movielens-1M, Movielens10M, Gowalla, Arxiv, Arxiv-t, Cora, CS, OGB-Collab, Proteins-0, Proteins-1, Proteins-2, Proteins-3, OGB-DDI, Web-Stanford, RoadNet-PA.\n    \\item Ecommerce and Academic: These two datasets contain all the domain-specific datasets as mentioned above.\n\\end{itemize}"}, {"title": "A.2 Evaluation Protocols", "content": "All datasets used in this study are sourced from previous research asreferenced [16, 23]. We adhere to the original data splits from thesesources to delineate our training and testing sets. Given that manybaseline methods are not equipped to manage zero-shot predictionacross datasets, we instead assess their few-shot capabilities. Thisallows for a comparative analysis against the zero-shot performanceof AnyGraph. We employ specific evaluation settings tailored toeach method, detailed as follows:\n\\begin{itemize}\n    \\item Zero-shot Setting for AnyGraph, GraphGPT, and Open-Graph. In our study, AnyGraph and two comparative graph foundation models, GraphGPT and OpenGraph, undergo evaluations for zero-shot prediction capabilities. We pre-train two instances of AnyGraph using Link1 and Link2 datasets. The model pre-trained on Link1 is then tested for zero-shot performance on the Link2 group datasets, and vice versa. Results labeled as \"zero-shot\" for AnyGraph are derived using this cross-evaluation method. Conversely, results marked as \"full-shot\" pertain to supervised learning outcomes, where, for example, the model trained on Link1 is tested on the test sets of Link1 group datasets. For GraphGPT and OpenGraph, we utilize the models as released in their respective original studies, which were pre-trained on specified datasets.\n    \\item Zero-shot Node Classification for AnyGraph. Drawing from insights in prior research [22], our approach to zero-shot node classification involves a novel method where label classes are represented as distinct nodes. We then connect existing nodes that have training labels directly to these new class nodes. This technique eliminates the need for learning specific parameters for each class within the zero-shot learning framework, streamlining the process. We have integrated this innovative approach into baseline methods as well, enhancing their capability to handle unseen node labels effectively.\n    \\item Few-shot Training for GIN and GAT. The GIN and GAT models, employed as end-to-end training baselines, undergo training from scratch on few-shot subsets of the evaluation datasets. This approach is necessary because these models are not well-suited for cross-dataset transfer, particularly when dealing with datasets that have varying feature dimensionalities.\n    \\item Pre-training and Few-shot Tuning for GraphCL, GPF and GraphPrompt. These category of baselien methods follow the pre-training-and-fine-tuning mode. In our evaluations, they are firstly pre-trained using the same pre-training datasets as our AnyGraph. Then, they experience an additional fine-tuning process using the few-shot subsets of the evaluation datasets.\n\\end{itemize}"}, {"title": "A.3 Hyperparameter Settings", "content": "Optimization. Our model, AnyGraph, is implemented using Py-Torch. The optimization process employs the Adam optimizer witha learning rate of \\(1 \\times 10^{-4}\\) and a training batch size of 4096. We usecross-entropy loss with a sampled negative set [29]. The learnableparameters of AnyGraph are initialized using the Xavier uniforminitializer. Network Configurations. The standard configurationof our AnyGraph includes 512 hidden units and 8 graph expert models. Each expert model comprises 8 fully-connected layers. Theselayers utilize a ReLU activation function and incorporate a dropoutlayer with a dropout probability of 0.1. Algorithm Hyperparameters. The frequency regularization of our routing mechanism isset with an adjustment range of \\(\\rho = 0.2\\). The SVD decomposition isperformed using 2 iterations. For structural and feature augmentation, each dataset is reprojected after using 1/10 of its samples foroptimization. A minimum of 100 training steps should be executedfor each dataset before its initial representations are reprojected.The reassignment of experts occurs after all training datasets haveundergone one cycle of re-projection.\nThe baseline methods are evaluated using theeir original codeor released model. We closely follow the original code to adapt toour experiments. Grid search is conducted to search for the besthyperparameter settings for each baseline method."}, {"title": "A.4 Baseline Methods", "content": "This section provides detailed descriptions of the baseline methodsused in our analysis. We employ seven different baseline modelsacross four distinct categories.\n\\begin{itemize}\n    \\item GAT [25]. Graph Attention Networks (GAT) leverage an attention mechanism to dynamically weight node-to-node connections, enhancing the model's ability to adaptively propagate and aggregate information across the graph.\n    \\item GIN [33]. The Graph Isomorphism Network (GIN) significantly boosts the expressive power of Graph Neural Networks by introducing a unique graph encoding technique aimed at effectively\n\\end{itemize}"}, {"title": "A.5 Details of the Scaling Law Experiment", "content": "For the scaling law experiment (RQ2), we elaborate the configurations of the developed instances of AnyGraph. For AnyGraph withdifferent model sizes, we begin with the smallest model which has64 hidden units, 1 fully-connected layer, and 1 expert model. Thesubsequent 3 model instances increases in their hidden dimensionality, from 64 to 12"}]}