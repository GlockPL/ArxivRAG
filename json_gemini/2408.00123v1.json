{"title": "Semantic Codebook Learning for Dynamic Recommendation Models", "authors": ["Zheqi Lv", "Shaoxuan He", "Tianyu Zhan", "Shengyu Zhang", "Wenqiao Zhang", "Jingyuan Chen", "Zhou Zhao", "Fei Wu"], "abstract": "Dynamic sequential recommendation (DSR) can generate model pa-rameters based on user behavior to improve the personalization ofsequential recommendation under various user preferences. How-ever, it faces the challenges of large parameter search space andsparse and noisy user-item interactions, which reduces the applica-bility of the generated model parameters. The Semantic CodebookLearning for Dynamic Recommendation Models (SOLID) frame-work presents a significant advancement in DSR by effectivelytackling these challenges. By transforming item sequences intosemantic sequences and employing a dual parameter model, SOLIDcompresses the parameter generation search space and leverageshomogeneity within the recommendation system. The introductionof the semantic metacode and semantic codebook, which storesdisentangled item representations, ensures robust and accurateparameter generation. Extensive experiments demonstrates thatSOLID consistently outperforms existing DSR, delivering moreaccurate, stable, and robust recommendations.", "sections": [{"title": "1 INTRODUCTION", "content": "Nowadays, as an important branch of recommendation systems,sequential recommendation has emerged, including DIN [60],GRU4Rec [12], SASRec [17], BERT4Rec [34] and other models thatare crucial in the field of recommendation systems. However, thebehavior logic of most users is not universally applicable, and asinterests can change, it necessitates that sequence recommenda-tion models be able to adjust their parameters in real-time accord-ing to the user's current interest preferences. Consequently, dy-namic sequential recommendation models (DSR) like DUET [29]and APG [48] have been developed.\nThe DSR paradigm consists of two parts: (1) The primary model.This model has a structure similar to conventional sequential rec-ommendation models like SASRec, but it is divided into a staticlayer and a dynamic layer. The parameters of the static layer re-main unchanged after pre-training, whereas the parameters of thedynamic layer change with the user's behavior. (2) The parame-ter generation model. This is mainly used to sparse user behaviorand generate the parameters for the dynamic layer of the primarymodel based on this behavior. The DSR paradigm enables tradi-tional static sequential recommendation models to quickly adjusttheir parameters according to the potential shift of interests andintentions reflected in user behaviors, thus dynamically obtainingmore interest-aligned models in real time.\nDespite the promising potential of Dynamic Sequential Recom-mendation (DSR) systems, they face significant challenges, primar-ily stemming from the item-to-parameter modeling scheme: (1) A\nlarge number of items result in a vast search space for the parametergeneration model. Slight variations in user behavior sequences, suchas \"shirt, tie, suit\" versus \"tie, shirt, suit,\" which suggest similar pref-erences, can unpredictably alter the item-to-parameter modeling,introducing complexity and potential instability. (2) The interactionbetween users and items is generally sparse and potentially noisy(e.g., the notorious implicit feedback issue), leading to heteroge-neous behavior sequences that complicate the learning of accurateitem representations. This results in inaccurate item representationlearning, weakening the precision of model parameter customiza-tion based on item sequence features, and further exacerbating theinaccuracy of generated parameters.\nTo address these issues, we propose the Semantic CodebookLearning for Dynamic Recommendation Models (SOLID). The coreobjective of SOLID is to compress the search space of the parame-ter generation model, promoting homogeneity signals utilizationwithin the recommendation system. We construct a semantic code-book that better utilizes these homogeneity signals. In the code-book, item representations are disentangled into semantics thatare learned to be absorbed in the codebook elements, such thatthe homogeneity between items in the disentangled latent spacecan be established. The user-item interactions are transformed intodensity-enriched user-semantic interactions in the latent space. Theenriched density reduces the heterogeneity and complexity of userbehavior space modeling in the parameter generator. Moreover,SOLID shifts from a traditional item sequence-based parametergeneration mode to a dual (item sequence + semantic sequence)\u2192 model parameter generation mode, effectively merging bothuniform and diverse information in a structured manner. Uniforminformation derived from the semantic-to-parameter part is utilizedto develop parameters that generalize across certain user behaviors,while diverse information allows for the crafting of specific parame-ters tailored to individual behavioral nuances. Crucially, by aligningthe dimensions of the codebook with those of the semantic encoder,we transform the semantic encoder into a meta-code that servesas an initial state for the codebook, further easing the modeling ofparameter generation.\nSpecifically, to reduce the search space of the parameter gen-eration model through the semantic codebook, SOLID involvesthree main modules. Initially, SOLID employs a pretrained modelto extract semantic components from item, image, and text features.This disentanglement transitions the focus from item sequencesto semantic sequences, shifting the modeling approach from item-based to semantics-based parameter generation. This design resultsin trunk parameters that generalize behaviors from the entire userbase to specific groups, and branch parameters that cater to individ-ual user behaviors, both derived from semantic and item sequencesrespectively. Parameters derived from items are tightly controlled(e.g., \u00b10.01) before their integration into the dynamic layer of theprimary model, ensuring a responsive and adaptive system basedon real-time user activity. Despite this, branch parameters stilladhere to an item-centric approach, necessitating the use of a Se-mantic Codebook (SC) to maintain personalization and stability inrepresentation. This codebook stores semantic vectors of behavior,"}, {"title": "2 RELATED WORK", "content": "2.1 Sequential Recommendation\nRecommendation system predicts user preferences based on user be-havior history [7, 19, 20, 22\u201325, 32, 33, 47, 51, 52, 56, 57]. Sequentialrecommendation, as an important branch of the recommendationsystem, arranges users' recent historical behaviors in chronologicalorder to more accurately capture users' recent preferences. Recentadvancements [4, 12, 17, 26, 27, 29, 34, 45, 48, 60] have shifted to-wards deep learning-based sequential recommendation systems.For instance, GRU4Rec [12] employs Gated Recurrent Units toeffectively model sequential behavior, demonstrating impressiveresults. Additionally, DIN [60] and SASRec [17] incorporate atten-tion mechanisms and transformers, respectively. BERT4Rec [34]further applies BERT for superior outcomes in recommendationtask. The models have significantly impacted academic research andindustry practices. However, these SR Models struggle to achieveoptimal performance across every data distribution when dealingwith users' real-time changing behaviors and interest preferences.\n2.2 Disentangled Representation Learning\nThe goal of disentangled representation learning is to parse the datainto distinct, interpretable components by identifying different un-derlying latent factors [2, 3]. Variational autoencoders (VAE) [5] and\u03b2-VAE [13] provide more possibilities for disentangled learning byadjusting the balance between the model's disentanglement abilityand its ability to represent information. By incorporating multi-interest methods [18, 30] along with disentangled representationlearning, several studies [41\u201344, 58] have demonstrated significantadvancements in recommendation tasks. We draw on the idea of dis-entangling and apply it to dynamic model parameter generation toreduce the parameter search space and leverage the homogeneousinformation of user behavior.\n2.3 Dynamic Neural Network\nResearch in dynamic neural networks focuses on HyperNet-works [11] and Dynamic Filter Networks [16], which have betterability to adapt to distribution deviations than traditional static"}, {"title": "3 METHODOLOGY", "content": "3.1 Notations and Problem Formulation\nFirst, we introduce the notation in sequential recommendations.\n3.1.1 Data. We use Xori = {u, v, sv} to represent a piece of data,\nXdec = {u, c, sc} to represent a piece of disentangled data, Xmm =\n{i, t} to represent multimodal information, and Y = {y} to repre-sent the label indicating whether the user will interact with theitem. In brief, X = Xori \u222a Xdec \u222a Xmm = {u, v, sv, c, sc, i, t}, where\nu, v, c, sv, sc, i, t represent user ID, item ID, category ID, user's clicksequence consists of item ID, user's click sequence consists of cate-gory ID, the image of the item, and the title of the item respectively.\nWe represent the dataset as D, where D = {X, Y}. More specif-ically, we use DTrain to represent the training set and DTest torepresent the test set. Roughly speaking, let L be the loss obtainedfrom training on dataset DTrain. For simplicity, we simplify thesymbol DTrain to D. Then, the model parameters \u0398 can be ob-tained through the optimization function argmin \u0398 L. The sequencelength inputted into the model is set to Ls, so the lengths of bothsu and sc in a sample are Ls.\n3.1.2 Model. The recommendation model is represented by M\nand the parameters of the M is \u0398, where \u0398 = \u0398s, \u0398d. The model\nM is utilized to generate the \u0398d according to the item id sequence\nsu, Mc is utilized to generate the \u0398d according to the category id\nsequence sc, M(\u00b7) and Mc(\u00b7) represent the forward propagationprocesses of two models, where denotes the input.\n3.1.3 Feature. We use Ev and Ec to represent the item feature\nset and semantic feature set extracted from sv and sc respectively.\nSpecifically, Ev = {ev1, ev2, ..., evLse }, Ec = {ec1, ec2, ..., ecLsc }. ev and ec are\nthe sequence features obtained through sequence feature extractionmodels such as Transformer or GRU, via Ev and Ec, respectively.\nThe length of an item representation or a semantic representationis set to Lr.\n3.1.4 Formula. Sequential Recommendation Models (SR), DynamicSequential Recommendation Models (DSR), and Disentangled Mul-timodal Dynamic Sequential Recommendation Models (SOLID) canbe formalized as follows:\nSR : M(Xori; \u0398) \u2192 (\u0177, y) Loss Calculation (1)\nRecommendation Procedure\nDSR : M(Xori; \u0398s, \u0398d = Mv (Xori)) \u2192 (\u0177, y) Loss Calculation (2)\nRecommendation Procedure\nSOLID :\n (Xori, Xmm \u2192 c = f(v, i, t) \u2192 Xdec, \n \u0398d = Mv(Ev(sv))+ Mc(Ec(sc)), \nM(Xori; \u0398s, \u0398d) \u2192 (\u0177, y) Loss Calculation (3)\nRecommendation Procedure\nIn the aforementioned formula, a \u2192 b indicates indicates informa-tion transfer from a to b, with the text next to it representing thecontent of the transfer. a \u2192 b signifies that b is derived from a.\n3.2 Preliminary\n3.2.1 Sequential Recommendation Models. Here we first retrospectthe paradigm of sequential recommendation.\nIn the training stage, the loss can be calculated to optimize thesequential recommendation models as follows,\nmin L = \u2211u,v,sv,y\u2208D \u2113CE (y, \u0177 = M(u, v, sv; \u0398)). (4)\nThe loss function can set to CE (Cross Entropy) loss and MSE (MeanSquared Error) loss, etc. However, since sequential recommendationoften focuses more on CTR (Click-Through Rate) prediction tasks,and this paper is also focused on CTR prediction, the recommenda-tion loss in this paper is CE loss and represented by \u2113CE.\n3.2.2 Dynamic Sequential Recommendation Models. DSR generatemodel parameters based on users' real-time user behaviors. Then,the updated model is used for current recommendations. In thispaper, the network layer that can adjust model parameters as thedata distribution changes is called an adaptive layer.\nDSR treat the parameters of one of the adaptive layers as amatrix K \u2208 \u211dN in\u00d7N out, where Nin and Nout represent the numberof input neurons and output neurons of a fully connected layer(FCL), respectively. DSR utilize a encoder Eu to extract the sequencefeature e from the user's behavior sequence su to generate theparameters of the model's adaptive layers.\n\u0398d = Mv(Eu(su)), (5)\nAfter parameter generation, the parameters of the model will bereshaped into the shape of K."}, {"title": "3.3 SOLID Framework", "content": "The architecture of our proposed SOLID is shown in the Figure 2.\n3.3.1 Semantic Parameter Generation. Transforming the Item-basedDynamic Recommendation Model into a Semantic-based DynamicRecommendation Model is an important step in disentangling per-sonalized model parameters. First, items need to be transformedinto semantics. For data without category labels, clustering can bedirectly applied to obtain semantics, i.e.,\nCluster({ei}N i=1) \u2192 {ci}N i=1, ci \u2208 {1, 2, ..., k}. (7)\nFor data with category labels, since the same item often belongsto multiple categories, we select a primary category as semantic\ncp for item v. First, we define the centroid mc of each category c, which isthe average of embeddings e for all items belonging to category c.Assuming nc is the number of items belonging to category c, thecentroid mc for category c can be represented as:\n1\nmc =\n\u2211(ev or ei or et), (8)\nnc i=1\nwhere ev, ei, et are the representation of item ID v, item image i,item title t, respectively. Next, we compute its distance to eachcategory center mc. Assuming we use the Euclidean distance, it canbe represented as,\nd(v, c) = ||(ev or ei or et) \u2212 mc||, (9)\nwhere || \u00b7 || denotes the norm of the vector, typically the Euclidean\nnorm. Finally, we select the closest category as the semantic foritem v. That is, the semantic cp for item v can be represented as:\ncp = argmin d((v or i or t), c). (10)\nc\nAfter converting items into semantics, a semantic-to-parametermodel can be trained. The training process is similar to that of theitem-to-parameter model. The only differences are that the input forthe item-to-parameter model is an item sequence, whereas for thesemantic-to-parameter model, it is a semantic sequence; similarly,the outputs are the target item and target semantic, respectively.\nmin L =\n\u03a3u,v,sc,y\u2208D \u2113CE(y, \u0177),\n\u0398s, \u0398c\n\u0177 = M(u, v, sc; \u0398s, \u0398d),\n\u0398d = Mc(Ec(sc)).\n(11)\nIn the above equation, Ec represents the semantic encoder, whichis similar to the item encoder Ev.\n3.3.2 Semantic Metacode Learning. To balance the use of person-alized user behavior information and homogeneous informationfrom similar user behaviors, we combine the item-to-parameter andsemantic-to-parameter models for the parameter generation pro-cess. The former's advantage lies in providing personalized informa-tion, but its disadvantage is the inaccuracy in parameter generationdue to strong data heterogeneity and sparse user-item interactions.The latter's advantage is providing homogeneous information fromsimilar user behaviors, and dense user-item interactions make theparameter generation process more robust. However, its disadvan-tage is that the semantic sequence is less personalized compared tothe item sequence.\nTherefore, our approach primarily uses the semantic-to-parametermethod to generate the main part of the model parameters. Sincethe following optimization problem,\nmin L =\n\u03a3u,v,sc,y\u2208D \u2113CE(y, \u0177),\n\u0398s, \u0398c, \u0398v\n\u0177 = M(u, v, sv; \u0398s, \u0398d),\n\u0398d = Mc(Ec(sc)) + Clip(Mv(Ev(sv))); \u0393),\n(12)\nwhere \u0393 is a hyperparameter used to control the threshold forparameter deviation, thereby also controlling the impact of per-sonalized information on the model parameters. Semantic Encodercan be transformed into a Semantic Metacode(SM), which can beused to further enhance the initialization of the Semantic Codebookfor the item-to-parameter process. The Semantic Metacode can beeffectively learned through the above process.\n3.3.3 Semantic Codebook Learning. Even if the model parametergeneration process is disentangled, the item-to-parameter mode isstill needed because it is the source of personalized information.Therefore, to further improve the accuracy of the item-to-parametermapping, we design a Semantic Codebook (SC). Upon obtainingsemantic sequences are easier to obtain than similar itemsequences, the parameters derived from the semantic sequencecan be viewed as a user group model. Then, the item-to-parametermethod is used as a branch, with parameters generated from itemsequences being constrained within a smaller threshold and mergedwith the parameters obtained from the semantic sequence. Thismerging process is seen as a transition from a user group model toan individual user model, thus balancing homogeneous informationand personalized information. Therefore, the training process canthe semantic metacode, we initialize the semantic codebook withit. Subsequently, we continue using the trunk and branch methodof parameter generation, specifically semantic-to-parameter anditem-to-parameter, to derive the parameters for the adaptive layerof the model. In the branch branch, the item representations arereplaced with semantic codes from the codebook, which are thenused to further predict model parameters. The generated modelparameters are used for click prediction on item sequences, just asbefore, ultimately allowing for the training of the semantic code-book. The specific method for computing the loss is described below.SC is denoted as D, and D \u2208 \u211dNc\u00d7Lr. Specifically, we first usethe weights of the semantic encoder in the semantic-to-parametermethod to initialize the item representation, as their dimensions are the same."}, {"title": "4 EXPERIMENTS", "content": "4.1 Experimental Setup\n4.1.1 Datasets and Preprocessing. We evaluate SOLID andbaselines on eight datasets. Amazon Arts (Arts), AmazonInstruments (Instruments), Amazon Office (Office), AmazonScientific (Scientific), which are four benchmarks that wasrecently released but has been widely used in the multimodal rec-ommendation tasks [40]. Amazon CDs (CDs), Amazon Electronic(Electronic), Douban Book (Book), and Douban Music (Music),which are four widely used public benchmarks in the recommen-dation tasks. We choose the leave-one-out approach to processthe dataset, taking the last action of each user for testing and allprevious actions for training and validation. Our task is CTR (Click-through Rate) prediction, so we process these datasets into CTRprediction datasets. These datasets consist of user rating datasetswith complete reviews. We treat all user-item interactions in thedataset as positive samples because having a rating implies thatthe user clicked on the item. Further, to ensure the training processgoes smoothly with both positive and negative samples, we sample4 negative samples for each positive sample in the training set and99 negative samples for each positive sample in the test set.\n4.1.2 Baselines. The baselines we select are as follows:\n\u2022 Static Recommendation Models. DIN [60], GRU4Rec [12],SASRec [17], and BERT4Rec [34] are all highly prevalent se-quential recommendation methods in both academic researchand the industry. They each incorporate different techniques,such as Attention, GRU (Gated Recurrent Unit), and Self-Attention, to enhance the recommendation process.\n\u2022 Dynamic Recommendation Models. DUET [29] andAPG [48] consists of two parts: a parameter generation modeland a primary model. The primary model refers to the afore-mentioned models like DIN, GRU4Rec, SASRec, BERT4Rec,etc. After pre-training, the parameter generation model cangenerate model parameters for the primary model duringinference based on the samples.\n4.1.3 Evaluation Metrics. We use the widely adopted AUC, UAUC,NDCG, and Recall as the metrics to evaluate model performance."}, {"title": "4.2 Overall Results", "content": "As shown in Table 1, we evaluate the overall performance acrossfour multimodal datasets: Arts, Instruments, Office, and Scientific.\nFor each dataset, we test the performance of four SR Models: DIN,GRU4Rec, SASRec, and BERT4Rec. We evaluate performance viaAUC, UAUC, NDCG@10, Recall@10, NDCG@20, and Recall@20.\nFor each SR Model, there are five options for DSR Models: None(\"-\"), APG, Ours (APG), DUET, and Ours (DUET), where \"-\" indi-cates no DSR Model usage, i.e., the inherent performance of theSR Model itself. Since the \"-\" option consistently performs worsethan using a DSR Model, our comparison primarily focuses on theperformance of APG vs. Ours (APG) and DUET vs. Ours (DUET)"}, {"title": "4.3 Ablation Study", "content": "We conduct ablation studies on each dataset, each SR and eachDSR to further analyze the impact of modules and modalities. Theablation results on each dataset, DR, and DSR combinations aresimilar, so we only show the results under the condition {Dataset=Arts,SR=SASRec, DSR=DUET}. Each row's \u2713 and \u2717 respectively indicatewith and without the module/modality.\n4.3.1 Ablation Study on Modules. As shown in Table 2, we conductan ablation study on each module proposed in our method, SPGstands for Semantic Parameter Generation, SML stands for Seman-tic Metacode Learning, and SCL stands for Semancic CodebookLearning. Since SPG is a prerequisite for SML, SML cannot existindependently of SPG; therefore, there is no separate performancedata for SML alone in the table. The first line represents the tradi-tional DSR model where parameters are generated using an itemsequence. The second line represents generating parameters usinga semantic sequence. The third line represents the joint generationof parameters using both item sequence and semantic sequence,with joint training. The fourth line represents using semantic code-book learning without using semantic information. The fifth linerepresents our complete method. The experiments show that themodel performs best when all three modules are used. In terms ofindividual modules, SCL has the greatest impact on performance.\n4.3.2 Ablation Study on Modalities. As shown in Table 3, we con-duct ablation study on each modality. The experimental results show that the fusion of three modalities - ID, Image, and Text - isnot necessarily the best option. In terms of the impact on perfor-mance for individual modalities, Text > Image > ID. For the fusionof two modalities, in terms of impact on performance, ID + Text >Image + Text > ID + Image."}, {"title": "4.4 Depth Analysis", "content": "We further conduct depth analysis to demonstrate the effectiveness.Unless otherwise specified, the dataset, SR, and DSR default to Arts,SASRec, and DUET, respectively. Note that we get similar resultsfor all settings, but only a subset of them are shown here.\n4.4.1 Stability and Robustness. We tested the variance of the UAUCfor SOLID and DUET on each user in the Arts dataset when facedwith similar user behaviors. Specifically, we added one user behav-ior at a time for each user behavior and calculated the performancevariance. We then aggregated the variances for all users to obtain"}]}