{"title": "Spb3DTracker: A Robust LiDAR-Based Person Tracker for Noisy Environment", "authors": ["Eunsoo Im", "Changhyun Jee", "Jung Kwon Lee"], "abstract": "Person detection and tracking (PDT) has seen significant advancements with 2D camera-based systems in the autonomous vehicle field, leading to widespread adoption of these algorithms. However, growing privacy concerns have recently emerged as a major issue, prompting a shift towards LiDAR-based PDT as a viable alternative. Within this domain, \"Tracking-by-Detection\" (TBD) has become a prominent methodology. Despite its effectiveness, LiDAR-based PDT has not yet achieved the same level of performance as camera-based PDT. This paper examines key components of the LiDAR-based PDT framework, including detection post-processing, data association, motion modeling, and lifecycle management. Building upon these insights, we introduce SpbTrack, a robust person tracker designed for diverse environments. Our method achieves superior performance on noisy datasets and state-of-the-art results on KITTI Dataset benchmarks and custom office indoor dataset among LiDAR-based trackers. Project page at anonymous.", "sections": [{"title": "1 Introduction", "content": "Lidar-based person detection and tracking (PDT) is crucial for ensuring safety and reliability in various domains, including autonomous driving, industrial safety, and crowd management [35]. While image-based trackers have been widely used, recent concerns about personal information protection have highlighted their limitations [14]. As a result, LiDAR technology has emerged as a promising alternative, as LiDAR data does not contain personally identifiable information, making it impossible to distinguish specific individuals solely from this data [15]. However, LiDAR-based person tracking presents its own set of challenges. To address these, we delve into the tracking module and propose improved algorithms. LiDAR-based PDT generally fall into two categories: neural network-based approaches and tracking-by-detection (TBD) methods. Neural network-based approaches, such as those utilizing Graph Neural Networks (GNNs), offer attractive end-to-end solutions [23]. However, they often require ground truth (GT) labels for object IDs, which are scarce in real-world datasets and challenging to obtain [18]. TBD has emerged as the predominant and most effective paradigm for LiDAR-based tracking in recent years [4]. This paper focuses on enhancing the TBD mechanism due to its practicality and widespread applicability. Traditional TBD tracking systems comprise several modules, including detection, association, motion modeling, and object management [5]. Each module requires careful analysis to adapt to person tracking scenarios. To address these challenges, we propose a comprehensive analysis of these modules, considering various conditions and scenarios. Our research aims to improve the overall performance and reliability of LiDAR-based person tracking systems by optimizing each component of the TBD framework. This work contributes to the advancement of person tracking technology, which has significant implications for safety and efficiency in autonomous driving, industrial environments, and crowded public spaces [36].\nIn this paper, we propose several enhancements to the LiDAR-based PDT framework to improve trajectory robustness and continuity. Our approach addresses key limitations in current tracking-by-detection (TBD) methods for LiDAR data. Firstly, we argue that relying solely on distance-based Intersection over Union (IoU) for association is insufficient [3]. We introduce a more robust approach that incorporates object similarity metrics and object dimensions [26]. This enhancement improves the accuracy of object association across frames. Secondly, we address the limitations of standard Kalman filters in handling non-linear motion and poor observation scenarios. person motion is often non-linear,"}, {"title": "2 Related Works", "content": "Many recent person trackers are designed based on end-to-end deep learning networks. A common approach involves integrating recurrent layers with detector modules. For instance, ROLO combines the convolutional layers of YOLO with LSTM recurrent units [16], while TrackR-CNN extends multi-object tracking to include instance segmentation [20]. Tractor++ offers an efficient tracking solution by utilizing bounding box regression to predict object positions in subsequent frames without requiring training on tracking data [2]. Other approaches focus on enhancing tracking performance through various techniques. Deep SORT integrates appearance information with the Simple Online and Realtime Tracking (SORT) technique, employing a recursive Kalman filter and frame-by-frame data association [25] [28]. This method incorporates an offline pre-training stage to learn a deep association metric using large-scale person re-identification datasets [12]. Similarly, some trackers adopt a single-stage approach, learning target detection and appearance embedding in a shared manner, often complemented by Kalman filters for location prediction [22]. While 2D trackers can leverage rich RGB information for appearance models, a resource not typically available in LiDAR-based 3D tracking, they often struggle with accurately representing 3D scene dynamics [3]. Conversely, 3D tracking methods can better handle scale variations and provide more accurate spatial information [9]. Ultimately, the design of person tracking methods should align with the specific characteristics of each modality to achieve optimal results, whether utilizing 2D image data, 3D LiDAR point clouds, or a fusion of multiple sensor inputs [24]."}, {"title": "2.2 Lidar-based Tracking", "content": "Recent developments in Lidar-Based Tracking (LBT) have explored diverse strategies to enhance tracking performance in dynamic environments [32]. Some approaches focus solely on 3D bounding boxes detected from point clouds, offering rapid processing and comprehensive scene dynamics capture, albeit potentially underutilizing point cloud appearance features [32]. Alternative methods have incorporated custom point cloud features or employed deep networks to estimate 3D bounding boxes from single-view images [32][17]. More recent approaches have shown promising results by combining features extracted from both RGB images and point clouds [34]. Many LBT techniques rely on rule-based components. For instance, AB3DMOT, a widely-used baseline, employs Intersection over Union (IoU) for association and a Kalman filter for motion modeling [32]. Subsequent enhancements have focused on improving the association step, such as substituting IoU with Mahalanobis or L2 distance metrics [34]. Researchers have also recognized the significance of lifecycle management in tracking systems [34]. Additionally, recent studies have investigated the application of graph neural networks (GNN) to address LBT in an end-to-end manner, with a focus on data association and active tracklet classification [27][11]. As the field progresses, there is an increasing need for comprehensive studies on 3D Multi-Object Tracking (MOT) methods to identify areas for improvement and guide future research directions [34]. This systematic approach will help in addressing the challenges unique to LBT and advancing the state-of-the-art in this domain [32][34]."}, {"title": "2.3 Kalman Filter", "content": "Kalman filters (KF) are widely used in tracking-by-detection methods for object tracking in autonomous driving due to their effectiveness in filtering noise from state estimations while handling noisy measurements [33]. However, standard KFs have limitations in real-world scenarios. They assume linear system models and Gaussian noise distribution, which may not hold in complex environments [33][29]. They struggle with non-linear motion and poor observation conditions due to fixed system covariance, leading to error accumulation in state predictions, especially during periodic occlusions of objects [29]. Additionally, spatial distortions in 3D sensor detections can result in imprecise motion parameter estimations [33]. To address these issues, advanced filtering techniques such as the Unscented Kalman Filter (UKF) and Cubature Kalman Filter (CKF) have been proposed [29][30]. These filters are designed to better handle non-linearities and approximate state distributions more accurately than standard KFs [30]. Furthermore, adaptive filters can adjust system covariance dynamically to better respond to changing environments, improving tracking performance in complex, real-world autonomous driving scenarios [30][31][13]."}, {"title": "3 SpbTracker", "content": "Our approach diverges from conventional algorithms that typically retain only high-confidence 3D detection boxes. Instead, we implement a more inclusive strategy that avoids strict confidence thresholds [33]. This method aims to preserve potential tracklets and enhance recall performance. In our pipeline, we employ the DSVT (Dynamic Sparse Voxel Transformer) detection model[21] and apply Non-Maximum Suppression (NMS) to refine the detection results. Unlike image-based approaches, our LiDAR-based method focuses on 3D space, simplifying the post-processing steps. By eschewing a fixed confidence threshold, our approach seeks to strike a balance between retaining potentially valid detections and mitigating false positives. This strategy is particularly effective in challenging scenarios where low-confidence detections may still represent genuine objects. As illustrated in Fig. 3, our experiments reveal an inverse relationship between the confidence threshold and tracking performance metrics (A\u041c\u041e\u0422\u0420 and AMOTA). Lower thresholds correspond to improved metric scores, underscoring the importance of managing \"ghost\" objects (false positives) in enhancing recall.\nGiven the limited availability of person data in the KITTI dataset[8], we adopted a strategy to enhance our model's performance through transfer learn"}, {"title": "3.2 Motion Model", "content": "Most previous methods apply simplistic motion models that fail to adequately account for the complexity of a person's movement. persons can move freely along the X and Y axes and rotate around the Z-axis (yaw direction) according to the right-hand rule. Furthermore, analysis of person detection results reveals the difficulty in distinguishing between front and back views of individuals. Consequently, prediction models relying solely on heading angle may be inaccurate. To address these limitations, we propose formulating the state of an object trajectory as an 11-dimensional vector:\n\n[x, y, z, \u03b8, \u03a7\u03c5, Yv, Xa, Ya, w, l, h]\n\n(x, y, z) represents the 3D location of the object's geometric center. (0) represents the object's orientation around the Z-axis. (Vx, Vy) represents the object's velocity components in the X and Y directions. (ax, ay) represents the object's acceleration components in the X and Y directions.(w, l, h) represents the object's 3D dimensions (width, length, height)"}, {"title": "3.3 Dynamic Unscented Kalman Filter", "content": "The standard Kalman Filter is widely used in Track-By-Detection (TBD) tracking modules for associating motion model systems with measurement systems (detection systems). Most previous methods assume linear object motion and Gaussian distribution. However, person motion is inherently non-linear, and the typical LiDAR sensor frame rate of 10Hz, coupled with TBD detection module latency of 0.3-0.7 seconds, often violates the Gaussian distribution assumption in the tracking module. To address these issues, we propose a Dynamic Unscented Kalman Filter (D-UKF). We leverage the D-UKF to estimate the trajectory state. The prediction process can be described by:\n\n(Xt-1, Wt) = (Tt\u22121, Pt-1, \u043a)\n\n(Tt, Pt) = UT(f(xt\u22121), Wt, Q)\n\n(Dt, Pz,t) = UT(h(Xt\u22121), Wt, R)\n\nwhere T denotes the prediction model, D means the detection model, P is the covariance matrix of the previous frame, Q is the prediction model system's"}, {"title": "3.4 Association", "content": "The Generalized 3D Generalized IoU (GIoU) is a widely adopted association metric in object tracking. This metric enhances the traditional IoU (Intersection over Union) by accounting for the spatial relationship between non-overlapping bounding boxes, thereby providing a more comprehensive measure of object overlap. However, GIoU solely reflects the proportion of overlap, neglecting crucial factors such as volume size and object viewpoint. To address these limitations, we incorporate the concept of Complete-IoU (CIoU) into our association framework. CIoU extends the capabilities of GIoU by considering additional geometric properties, thus offering a more nuanced approach to object association. We suggest new metric by modifying CIoU metric as Modified Complete-IoU(MCIOU). MCIOU is specifically designed to reflect the unique characteristics of person tracking, particularly taking into account the ratio of person height:\n\n\u03c5 = \\frac{4.0}{\u03c0}(arctan(\\frac{hs}{Areas}) - arctan (\\frac{ht}{Areat}))\n\n\u03c5 = v(1-GIOU + 1)\n\nMCIOU = GIOU + \u03b1\n\nNevertheless, IoU-based association methods inherently face challenges in Re-Identification (Re-ID) tasks, particularly when dealing with objects that have been absent from the scene for extended periods. This limitation arises from the reliance on threshold distances for matching, which can fail to associate objects that have undergone significant spatial displacement over time. To mitigate this issue, we augment our association strategy by incorporating feature similarity measures. This additional dimension allows for more robust matching, especially in scenarios where spatial proximity alone is insufficient. we utilize bird's eye view(BEV) features sampled via region of interest (ROI) as feature similarity. Considering that the matched object ROI features of the two branches, we design the feature similarity (FS) as:\n\nFS = exp(\\frac{fs(ft)}{fs2ft2}^T )"}, {"title": "3.5 Life Cycle Management", "content": "While previous approaches often rely exclusively on high-confidence 3D bounding boxes, our method incorporates all predicted 3D boxes to enhance recall metrics. To address the challenges associated with this comprehensive approach, we adopt a holistic strategy as follows: Firstly, we utilize the F1 score as the classification criterion. We associate the track pool with all detection results using our previously described association method. This approach, however, can potentially lead to decreased precision due to the inclusion of low-confidence detections and increased computational complexity in the association step, which employs the Hungarian algorithm. In contrast to conventional algorithms that use distance-based thresholds for association, we employ a Feature Similarity (FS) metric. Among pairs exceeding a distance threshold, we compare their FS values. Pairs with FS values above a predetermined threshold are retained in the pair memory pool. Matched pairs undergo processing through a Dynamic Unscented Kalman Filter (UKF) and a Low-Pass Filter (LPF) for confidence score smoothing. The LPF mitigates rapid fluctuations in confidence scores, applying to both matched trajectory scores and detection result scores. If the LPF result"}, {"title": "4 Experiments", "content": "We implemented our proposed methodology using Python and C++, and conducted experiments on an Intel Xeon Gold 5218R CPU (2.10GHz) with 125GB RAM. All reported results reflect online performance.\nDatasets We evaluated our method on two datasets: the KITTI tracking dataset, and a our own dataset. The KITTI tracking dataset was recorded in Karlsruhe, Germany, using a 64-beam LiDAR sensor at a 10Hz frame rate. Following the convention in, we used sequences 1, 6, 8, 10, 12, 13, 14, 15, 16, 18, and 19 as the validation set. Our custom Office dataset was captured using a Hesai QT128 LiDAR sensor. This sensor features a vertical Field of View (FOV) of 105.2\u00b0 [-52.6\u00b0, +52.6\u00b0], a horizontal FOV of 360\u00b0, a range of 0.05 to 50 meters, and operates at a frame rate of 10Hz. We collected person tracking data in an indoor environment using this LiDAR sensor.\nEvaluation Metrics and Criteria For the KITTI dataset, we conducted 3D MOT evaluation on the validation set, as the test set only supports 2D MOT evaluation and its ground truth is not publicly available. We followed the KITTI convention, presenting results for Pedestrian. Regarding matching criteria, we adopted the convention from the KITTI 3D object detection benchmark, using 3D IoU to determine successful matches. Specifically, we employed 3D IoU thresholds (IoU thres) of 0.25 for pedestrian.\nOn KITTI, we also report SAMOTA [56] and HOTA [31] metrics, which allows us to analyze detection and association errors separately. We also report the number of identity switches (IDs) at the best performing recall."}, {"title": "4.2 Benchmark results", "content": "KITTI 3D Pedestrian validation set benchmark In Table 5, we present a summary of the pedestrian tracking results. Our proposed system demonstrates superior performance compared to other modern tracking algorithms. Across all metrics, with the exception of ID switches (IDs), our method achieves the best results. It's worth noting that AB3DMOT shows the lowest number of ID switches. However, this is primarily due to its significantly lower detection capability. To provide a fair comparison, we modified AB3DMOT to use the same detector as our SpbTracker, denoted as AB3DMOT*. With this modification, AB3DMOT* exhibits the highest number of ID switches.\nOffice 3D person tracking In Table 6, AB3DMOT* denotes the AB3DMOT algorithm using our detector instead of its original one. The office dataset presents a more challenging environment compared to KITTI due to the presence of crowded objects. Additionally, the LiDAR sensor used in our office dataset has a low range than KITTI's sensor and the frame rate is lower. These factors contribute to the overall lower performance results compared to those obtained on the KITTI dataset. It's important to note that all tracking algorithm parameters, including those for our method and the other algorithms evaluated, remain consistent with the settings used in the KITTI experiments. This comparison highlights the robustness of our tracking system across different environmental conditions and sensor configurations, while also demonstrating the challenges posed by more complex scenarios such as crowded indoor environments."}, {"title": "KITTI 2D Pedestrian Tracking", "content": "In Table 4, we present the 2D Pedestrian tracking results obtained on the KITTI test set. Although our tracking is performed in 3D space, we can report 2D tracking results by projecting the 3D bounding boxes onto the image plane using camera intrinsic and extrinsic parameters. We then report the minimal axis-aligned 2D bounding boxes that fully enclose these projections as the tracks' 2D positions. Despite focusing on 3D tracking and using 2D detections only as a secondary cue, our method achieves state-of-the-art results in terms of SMOT\u0391, \u039c\u039f\u03a4\u0391, \u039c\u039fTP, and IDSW metrics for the 3D modality(except for models considering only 2D image space). Notably, our SMOTA and IDSW metrics are state-of-the-art even when compared to 2D+3D multi-modal models. This performance demonstrates the effectiveness of our 3D tracking approach, which can compete with and even surpass methods that directly operate in 2D or use both 2D and 3D information. Our results highlight the potential of 3D-focused tracking methods in achieving high performance across both 3D and 2D evaluation metrics."}, {"title": "5 Conclusion", "content": "In this paper, we analyzed the \"TBD\" 3D tracking algorithm and proposed several enhancements for improved person tracking. Our contributions include a person-biased detector, MCIOU, feature similarity measures, a specific person motion model, a robust filter, and long-term life-cycle memory, all of which lead to significant performance improvements. However, the use of large-scale memory in the life-cycle model results in increased matching time. To address this, we optimized the code using C++, but further research is needed to develop a more compact algorithm. Future work will explore learning-based methods for end-to-end tracking with multi-modal, moving away from the rule-based TBD approach."}]}