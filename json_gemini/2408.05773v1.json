{"title": "Neurosymbolic Methods for Rule Mining", "authors": ["Agnieszka \u0141AWRYNOWICZ", "Luis GAL\u00c1RRAGA", "Mehwish ALAM", "B\u00e9r\u00e9nice JAULMES", "V\u00e1clav ZEMAN", "Tom\u00e1\u0161 KLIEGR"], "abstract": "In this chapter, we address the problem of rule mining, beginning with essential background information, including measures of rule quality. We then explore various rule mining methodologies, categorized into three groups: inductive logic programming, path sampling and generalization, and linear programming. Following this, we delve into neurosymbolic methods, covering topics such as the integration of deep learning with rules, the use of embeddings for rule learning, and the application of large language models in rule learning.", "sections": [{"title": "1. Introduction", "content": "The schema of knowledge graphs (KGs) can be represented using ontological axioms and/or rules. Rules can be used for explainable inference for tasks such as link prediction or fact checking [1].\nHovewer, formulating rules manually is demanding in practice. For that reason, automatic rule learning approaches have attracted attention.\nWu et al. in their survey [2] distinguish three major groups of rule learning methods: Inductive Logic Programming-based, statistical path generalisation and neuro-symbolic. In this chapter, to introduce the topic of rule mining and provide necessary backround, we discuss each of these groups and give a more detailed example of algorithms within each group paying most attention to neuro-symbolic ones. We also discuss the topic of using Large Language Models (LLMs) for rule mining."}, {"title": "2. Background", "content": "Rules A (Horn) rule is an expression of the form\nCorresponding Author: Author Name, contact details."}, {"title": "Rules", "content": "A (Horn) rule is an expression of the form\n\\(q_1(x, z_1) \\land q_2(z_1, z_2) ... q_n(z_{n-1}, z_n) \\Rightarrow p(x,y)\\)\nwhere \\(p(x, y)\\) and each term \\(q_i(z_{i-1}, z_i)\\) is an atom, that is, a KG fact such that at least one of its terms is a variable \\(v \\in V\\). In the remainder of this chapter we denote variables \\(v \\in V\\) by lowercase letters, and constants by capitalized names, e.g., Germany \\(\\in \\mathcal{E}\\), where \\(\\mathcal{E}\\) is a set of entities. The left-hand side part of the rule is a logical conjunction of atoms that we call the body or antecedent of the rule, denoted by \\(B\\), whereas the right-hand side atom is called the head or the succedent of the rule, denoted by \\(H\\). We say two atoms are connected if they share at least one argument. A conjunction of atoms or a rule is connected if every atom is transitively connected to every other atom. For instance the rule nationality(x,z1) \\land officialLang(z\u0131,y) \\Rightarrow nationality(x, y) is connected, whereas the rule speaks(x, z1) \\land officialLang(z2,z3) \\Rightarrow speaks(x, y) is not because the second atom is not reachable from any other atom. Applications on KGs usually require connected rules.\nWe say a rule is safe if the head variables are present in the rule's body. For exam-ple, the rule birthCountry(x, z1) \\land nationality(x,z2) \\land officialLang(22,23) \\Rightarrow speaks(x, y) is not safe because variable y is absent in the antecedent, which actually means that y is existentially quantified. In other words, this rule could be interpreted as \\(\\forall x \\exists y, Z_1, Z_2, Z_3\\): birthCountry(x,z1)^nationality(x,z2)\\land officialLang(22,23) \\Rightarrow speaks(x, y). Safeness ensures that the rule makes concrete predictions. In our example, the rule states that if someone, with known birth country is citizen of a country with an official language, that person speaks some language we still do not know which. If we instead consider a safe version of this rule, i.e., \\(\\forall x, y \\exists y, z_1, z_2\\): birthCountry(x,z\u2081) \\land nationality(x, z2) A officialLang (z2, y) \\Rightarrow speaks(x,y), we can now predict the person speaks the official language of their country of citizenship. If no variable is existentially quantified, i.e., each variable appears in at least two different atoms, we say the rule is closed. Most applications relying on rules resort to safe rules, or more frequently to closed rules such as \\(\\forall x,y,z_2\\): birthCountry(x,z2) \\land nationality(x,z2) \\land officialLang(z2,y) \\Rightarrow speaks(x,y)."}, {"title": "Before", "content": "As mentioned before, safe rules can be used to draw specific conclusions, e.g., deduce the nationality of a person from known information in a KG \\(\\mathcal{K}\\). To do so we need to introduce the notion of substitution. A substitution \\(\\sigma: V \\rightarrow \\mathcal{E}\\) is partial mapping from variables to constants. Applying a substitution to an atom replaces the variables of the rule by the constants associated to those variables in the substitution. We call the result of this operation an instantiation. This operation can be naturally ported to conjunctions of atoms, which returns a set of instantiations. If we apply the substitution \\(\\sigma = \\{x \\rightarrow E.Macron, z_1 \\rightarrow France, y \\rightarrow French\\}\\) to the conjunction B : birthCountry(x,z1)\\land officialLang (z\u0131,y), we obtain instantiations that are actual facts (no variables left) \\(\\sigma(B) = \\{birthCountry(E.Macron, France), officialLang(France,French)\\}\\). Let R be a rule of the form B \\Rightarrow H and \\(\\sigma\\)an instantiation. We say R and \\(\\sigma\\) fire in KG \\(\\mathcal{K}\\), if \\(\\sigma(B) \\subseteq \\mathcal{K}\\), denoted by \\(\\sigma(B) \\vdash \\mathcal{K}\\). Put differently an instantiated rule fires in a KG if all the instantiated body atoms are facts from the KG. If additionally \\(\\sigma(H) \\in \\mathcal{K}\\), we say the rule predicts the fact obtained by instantiating H, which we denote by \\(\\sigma(R) \\vdash \\mathcal{K}\\). That is the case for our example rule and the KG in Figure 1 since both \\(\\sigma(B)\\) and \\(\\sigma(H) = speaks(E. Macron, French)\\) are in the KG.\nLogical rules in KGs are unlikely to make correct predictions every time they fire. That is why we usually talk about soft rules, that is, rules with exceptions. Take as an example the rule birthCountry(x, z1)^officialLang(z\u0131,y) \\Rightarrow speaks(x, y). It is easy to see that such a rule is overall accurate but may have an exceptions, e.g., people born in a country but raised elsewhere. In a related note we should be skeptical about rules that fire or hold in very few cases. It follows from these observations that we need metrics to quantify the predictive power of rules before using them in applications. A popular score to quantify the significance of a rule B \\rightarrow H in a KG \\(\\mathcal{K}\\) is the support, defined as:"}, {"title": "significance", "content": "\\(\\text{supp}_\\mathcal{K}(B \\Rightarrow H) = \\#\\sigma_H: \\sigma_H(B \\Rightarrow H) \\vdash \\mathcal{K}.\\)  (2)\nIn this equation \\(\\#\\sigma_H\\) is the number of unique instantiations \\(\\sigma_H: \\text{vars}(H) \\rightarrow \\mathcal{E}\\), that is, instantiations that map the rule head variables to constants in the KG. Intuitively the support is the number of observed predictions of the rule in the KG. Those predictions are the positive examples of the rule. The higher the support, the more evidence about the soundness of the rule we have. If we take as eample the rule\nR: birthCountry(x,z1) \\land officialLang(z\u0131,y) \\Rightarrow speaks(x,y),\nwe can see that its support is\nsupp.x (R) = #(x,y) : \\exists z\u2081 : birthCountry(x,z1) \\land officialLang(z\u0131,y) / speaks(x,y).   (3)\nIn our example graph of Figure 1, this value is 2 because of the substitutions {x \\rightarrow E.Macron,y \\rightarrow French} and {x \\rightarrow U.v.d.Leyen,y \\rightarrow German}. A popular variant of the support normalizes Equation 2 by the number of facts in the head relation. This is called the head coverage:"}, {"title": "head coverage", "content": "hcx (BH) = \\(\\frac{\\text{supp}(B \\Rightarrow H)}{\\#r(x,y) : r(x,y) \\in \\mathcal{K}}\\)   (4)"}, {"title": "confidence score", "content": "Our example rule has a head coverage of in Figure 1 since it predicts 2 out of the 3 facts of the relation speaks. The support and head coverage are anti-monotonic scores. This means that adding atoms to an existing rule cannot increase its support. This property is crucial when designing efficient algorithms that learn those rules automatically.\nBut even if a rule has many supporting positive examples, it may also have many counter-examples, to put it another way, instantiations for which the rule fires but its predictions are false. If those false predictions outnumber the correct predictions, then we should take the rule's predictions with a grain of salt. This illustrates the risk of learning only from positive examples. The confidence score solves this issue by normalizing the support by the total number of examples of the rule, both positive and negative:\nconf x (BH) =  \\(\\frac{\\text{supp}(B \\Rightarrow H)}{\\text{supp}(B \\Rightarrow H) + (\\#\\sigma_H : \\sigma_H(B) \\vdash \\mathcal{K} \\land \\sigma_H(H)\\nvDash \\mathcal{K})}\\)    (5)\nThe expression on the right-hand side of the denominator describes the number of ex-amples that make the rule fire but whose predictions, represented by \\(\\sigma_H(H)\\), are not entailed by the KG. By \"not entailed\" we mean they contradict what is stated in the data. Bear in mind, however, that KGs do not store negative information. They cannot state things like \"Emanuel Macron does not speak English\". One could argue that the absence of such fact in our example graph (Figure 1) entails that Macron does not speak English. Unfortunately most KGs, and most particularly Web-based KGs, are in-herently incomplete: the absence of evidence is not evidence of absence. This means that if the KG does not say anything about Macron speaking English, we cannot conclude he does not speak English. This information is unknown. Take as an example the rule worksFor(x, EU) \\Rightarrow speaks(x,English). Since E. Macron works for the EU, this rule predicts he speaks English. We therefore have a problem when computing the confidence of this rule because we do not have a way to say whether this prediction is an example or a counter-example. As we will see in the next paragraph, one needs to make some assumptions about the completeness of KGs in order to evaluate the accuracy of logical rules and their inferences."}, {"title": "Closed World vs Open World Assumption", "content": "The Closed World Assumption (CWA), com-monly applied in database systems and logic programming, is the assumption that KGs are complete. This means that any statement not explicitly present in the KG is as-sumed false. This applies for speaks(E. Macron, English) in our example graph from Figure 1. It follows that this fact would be considered as a counter-example for the rule worksFor(x, EU) \\Rightarrow speaks(x,English). The CWA allow us to devise a confidence metric for rules, hence Equation 5 becomes:\nstd-conf x (B\\Rightarrow H) = \\(\\frac{\\text{supp}(B \\Rightarrow H)}{\\#\\sigma_H : \\sigma_H (B) \\vdash \\mathcal{K}}\\)    (6)\nThe CWA confidence, also called standard confidence normalizes the support of the rule by the number of examples that make the rule fire. This denominator term includes both the positive examples and the predictions that are not present in the KG now assumed as negative examples. In our example KG of Figure 1, the rule birthCountry(x,EU) \\Rightarrow speaks(x,English) has a confidence of because Angela Merkel satisfies the conditions"}, {"title": "partial completeness assumption", "content": "In contrast, the OWA does not offer a solution to the problem of determining whether a prediction should be counted as a counter-example or not (see Figure 2). A way to deal with this issue is the partial completeness assumption [3], also called the local closed world assumption [4]. The PCA assumes that information in KGs is added in \u201cbatches\". If the KG constructor included one language for let us say, U.v.d. Leyen, then it included all her languages in the KG. This assumption allows us to devise a new criterion to de-fine counter-examples for rules: if a rule such as worksFor(x, EU) \\Rightarrow speaks(x, English) predicts a new language for a person and that language is different from the languages stated in the KG, then that prediction must be a counter-example. An important corollary of this assumption is that if the KG does not know any language for that person, then the OWA applies and that example is labeled unknown and therefore excluded both as positive example or as counter-example. This assumption can be therefore used to devise a new confidence score, the PCA confidence [3]:\npca-conf x (B\\Rightarrow H) =  \\(\\frac{\\text{supp}(B \\Rightarrow H)}{\\#\\sigma_H: \\sigma_H (B\\land H') \\vdash \\mathcal{K}}\\)   H' = r(x,y') or H' = r(x',y).   (7)\nEquation 7 normalizes the support by the number of head substitutions that make the rule fire and for which there is a known head fact. This fact can be the rule's prediction but can be a different since the new variables x', y' in the formula are existentially quantified. In our example from Figure 1, the PCA confidence of the rule speaks(E. Macron, English) is. Differently from the standard confidence, Angela Merkel is not used as a counter-example because the KG does not know anything about the languages she speaks, i.e.,"}, {"title": "3. Rule Mining", "content": "Rule mining is the task of learning logical rules from a knowledge graph fully automat-ically. This problem is challenging for two main reasons. First, it is computationally ex-pensive, specially for large KGs, because it incurs the exploration of a very large search space. Second, it requires to make assumptions about what constitutes a counter-example in order to evaluate the quality of the rules. Since those rules are usually used for in-ference tasks, it is common to focus on closed rules, which as a side effect also reduce the space of rules to explore. There are different approaches to rule mining that we will describe in the following."}, {"title": "3.1. Inductive Logic Programming", "content": "The study of learning Horn clauses has been a significant focus in the inductive logic programming (ILP) field [6,7,8]. ILP methods are based on search of the space of possi-ble patterns or rules. To systematically explore the space during the learning process, ILP methods usually use refinement operators. A refinement operator defines a way to move from one candidate rule to another, more specific or more general. In rule mining, partic-ularly within ILP, refinement operators help navigate the pattern or rule space in a struc-tured manner. Refinement operators usually add/remove atoms or specialize/generalize predicates. We will see example refinement operator in Section 3.1.1 where the algorithm AMIE is discussed."}, {"title": "3.1.1. AMIE", "content": "AMIE [3] is a top-down closed rule mining algorithm designed for large KGs under the OWA. AMIE constructs new rules by adding atoms to already discovered rules. This process is called refinement. Some of those rules will be intermediate non-closed rules that AMIE refines but does not output. By default, the algorithm starts with all the rules of the form 0 \\Rightarrow r(x,y) that are iteratively refined via three mining operators:\nAdd dangling atom refines a rule with a new atom containing a fresh variable. For rule 0\\Rightarrow speaks(x, y), this operator could produce rules such as hasOfficialLang(z\u0131,y) \\Rightarrow speaks(x, y) or nationality(x,z1) \\Rightarrow speaks(x,y)."}, {"title": "add closing atom", "content": "Add closing atom adds a new atom without fresh variables. In our previous exam-ple, this operator could lead to the rule likes(x,y) \\Rightarrow speaks(x,y). Similarly, the rule hasOfficialLang(z\u0131,y) \\Rightarrow speaks(x,y) could be closed by adding the atom nationality(x, z1) to the body."}, {"title": "Add instantiated atom", "content": "Add instantiated atom refines the rule with an instantiated atom, that is, an atom where one of the arguments is a constant, e.g., the rule likes(x,y) \\Rightarrow speaks(x, y) could become is(x, Linguist)\\likes(x,y) \\Rightarrow speaks(x,y). By default, this operator is dis-abled, but can be turned on by the user. This also allows the system to start with rules of the form 0 \\Rightarrow r(x, C) or 0 \\Rightarrow r(C,y) for constants C from the KG.\nThese mining operators allow AMIE to explore the space of closed Horn rules. AMIE imposes a user-defined minimum threshold on support and a maximum rule length (also configurable by the user) to keep the search space under control. By default, AMIE finds rules up to 3 atoms and stops the refinement as soon as head coverage drops below 1%. This policy, based on the anti-monotonicity of the head coverage, speeds up the mining by avoiding noisy rules that cover too few positive examples. AMIE can also enforce user-defined thresholds on standard and PCA confidence (set by default to 10%).\nAll these considerations made AMIE the fastest rule mining algorithm on KGs at its time of publication, achieving a speed up of at least 3 orders of magnitude w.r.t. classical inductive logic programming approaches such as WARMR [9] and ALEPH [10] on modern KGs such as YAGO2 [11] (approx. 1M facts) previous approaches could not handle larger datasets such as DBpedia. Moreover, and in contrast to its competitors, its reliance on the PCA confidence to quantify the quality of rules made it produce more and more precise predictions than its competitors. On YAGO2, for instance, the rules had a precision in the range of 30%-40% and the PCA confidence proved more suitable than the standard confidence at ranking best the rules that inferred good new predictions predictions beyond the KG.\nAMIE+ [5] improves over AMIE with the help of various algorithmic optimizations to speed up rule mining. This included changes in the rule refinement procedure as well as some heuristics to discard potentially noisy rules. AMIE+ avoids refining rules when the resulting refinement cannot lead to a closed rule given the maximal length constraint. It also implements some query simplification for recursive rules, i.e., rules where a pred-icate appears more than once. It also implements a skyline technique that stops refin-ing closed rules that have already attained 100% confidence and propose lower bounds and confidence estimations that prune noisy rules, i.e., rules of very low confidence, be-fore computing their actual confidence scores a computationally expensive task. All these optimizations allowed AMIE+ to run on larger datasets such as DBpedia 3.8 and Wikidata 2014 and achieve a speed up of at least one order of magnitude w.r.t. AMIE.\nAMIE 3 Lajus et al. [12] introduced the latest version of AMIE, called as AMIE3, that features several query processing and data representation improvements. For example, the existential variable detection heuristic optimizes the queries required to compute the rule confidence scores by properly identifying variables with existential semantics whose instantiations do not need to be fully enumerated. AMIE3 also proposes a lazy evaluation criterion for the confidence scores. This strategy stops the enumeration of the solutions of the normalization term (denominator) of the confidence scores as soon as it is clear that the resulting confidence will be below the minimum confidence threshold. Other optimizations include the parallelization of the construction of some indexes and"}, {"title": "3.2. Path Sampling and Generalization", "content": "RuDiK [13] is an algorithm that discovers both positive and negative rules. Mining negative rules helps to detect erroneous facts, which can be common in knowledge bases, due to errors being propagated. RuDiK consists of three modules: the first module gener-ates negative examples, the second one is an incremental rule miner and the last module executes rules, to generate new facts and find inconsistencies.\nNegative example generator creates negative examples, given a knowledge base and a target predicate. It does this by leveraging the Local Closed-World Assumption (LCWA) [15]. Under this assumption, if a triple q(s, o) does not occur in a knowl-edge base, but q(s,x) is present, then q(s,o) is false. Similarly, if q(s, o) is present but q'(s, o) is not, then q'(s, o) is false. RuDiK finds entities whose information is more likely to be complete, to generate good negative examples.\nIncremental rule miner discovers Horn Rules. Here, the atoms are of the form q(s, 0). The algorithm uses a set of positive examples G and a set of negative examples V. The ideal solution is the minimal set of rules for which all the examples in G are valid and none of those in V are. The goal of this rule miner is to find the optimal set of weighted rules. The weight of a rule has two components. The first is the ratio between the coverage of this rule over G and G itself. The second component measures the same thing over V. Parameter a is set to define the weight of the first component. There is also \u1e9e, defined as 1-\u03b1. \u03b2 defines the importance of the second component. This definition of weight is extended to define a marginal weight as follows. If R is a set of rules and r is a rule:\nwm(r) = w(RUr) \u2013 w(R)   (8)\nA rule will not be added to the solution if its marginal weight is at or below 0. A valid rule r(x,y) can be represented as a path between x and y in the knowledge base, which is represented as a directed graph. Another type of atoms can be in-cluded in the rules: literal comparison. For example, the rule\nbornIn(a,x) \\land x \u2260 U.S.A. \\Rightarrow \u00ac president(a,U.S.A.).\nThe algorithm starts with an entity x and keeps a set of candidate paths. At each step, the path with the smallest marginal weight is expended. Once a path is con-sidered valid, it is added to the solution, and it stops being expended.\nRule execution Once a rule has been discovered, RuDiK can run it in the knowledge base, as a SPARQL query. This enables it to deduce new facts, or to detect erro-neous ones that are in the knowledge base. The accuracy for new facts is 85%, and 97% for inconsistencies. When running RuDiK over Wikidata, DBpedia and YAGO 3, the proportion of erroneous triples was respectively 0.23%, 0.26% and 0.6%."}, {"title": "Different", "content": "Different parameters impact on the performance of RuDiK. Turning off literal com-parison visibly degrades accuracy for both positive and negative rules. The level of noise in the database also affects the performance, though RuDiK is rather robust in this regard. Another important parameter is the maximum path length. When it is set at 2, precision for positive rules drops to 49%. When it is set at 4, RuDiK does not finish after 24 hours, and the precision is not notably better than when it is set at 3. Therefore, 3 is used as the maximum path length. The last parameter is a and \u1e9e, the weight parameters. There are different optimal values for positive and negative rules, however the algorithm is robust and the variation in performance are limited as long as a (and \u1e9e) is in the [0.1,0.9] range.\nAnyBURL [16] is a bottom-up algorithm inspired by Golem [17] and Aleph [10]. The algorithm chooses random paths of a set path profile, and generalizes them to rules. A path profile \"describes path length and whether the path is cyclic or acyclic\". The support and confidence of these rules are then computed, and the rules that fulfil a given criteria, usually minimum support or confidence, are stored. Given a completion task, the candidates are ranked by the maximum confidence of the rules that have generated them, then by the second best one, and so on, until one rule stands out. There is more than one round of mining and selection of rules. Each round lasts a set amount of time. At the end, the length of possible paths can be increased if the set of results reaches saturation, i.e. if the number of new rules being discovered is too low.\nAnyBURL also uses reinforcement learning to determine how much effort should be dedicated for each path profile. It also uses Object Identity, which assumes that when two variables appear in a rule, they designate different entities. This is made to avoid redundant rules. There is a new version of AnyBURL [18], which introduces four ma-jor modifications. The first modification is object identity as described in [19], to avoid learning redundant rules, which would skew the confidence score. The second modifica-tion is confidence sampling, which serves to avoid a depth-first search when computing the confidence of a rule in a very large dataset. The third modification is reinforcement learning-based sampling which makes the path sampling more robust, and especially less sensitive to change in parameter settings. The fourth modification is multi-threading which enhances the performance of AnyBURL on very large graphs and makes it 20 times faster than SOTA.\nRARL [20] uses rule relatedness (or TBox relatedness) to rank candidate rules. The authors define two boxes. The ABox contains the facts, while the TBox contains the underlying schema of the knowledge base. Rules are considered related when they often link the same subjects and objects in the ABox. The confidence of these rules is computed under the Partial Completeness Assumption [5], which allows the creation of negative examples."}, {"title": "3.3. Linear programming", "content": "A recent paper [21] presents LPRules, an algorithm for rule mining that uses linear pro-gramming to mine rules inside a knowledge graph. It creates a weighted linear combina-tion of FOL rules that are then used as a scoring function for knowledge graph comple-tion. It also limits the size of the rules, to increase human interpretability."}, {"title": "4. Neurosymbolic Methods", "content": "4.1. Deep learning and Rules\nWe now introduce end-to-end approaches that utilize deep neural networks (DNNs) to learn rules by optimizing objective functions approximating path patterns."}, {"title": "4.1.1. Neural Logic Programming", "content": "Neural LP [22] is one of the pioneering efforts to integrate rule structure learning with parameter learning in an end-to-end differentiable model. It draws inspiration from the TensorLog [23] differentiable probabilistic logic framework. The TensorLog framework compiles rule inference into a series of differentiable operations by linking rule applica-tion to sparse matrix multiplications. The method thus simplifies the rule learning prob-lem to algebraic operations on neural embedding-based representations of a given knowl-edge graph.\nThe reasoning task the NeuralLP addresses involves three components: query, an entity tail about which the query is made, and an entity head that serves as the query's answer. The objective is to generate a ranked list of entities in response to the query, aiming to position the correct answer (i.e., the head) as high as possible on this list. We can formalize the query as a rule\n91 (x, z1) ...qn(x,zn) \u21d2 p(x,y)   (9)\nwith associated confidence a \u2208 [0,1], where p(x,y) is the query, and q1,\u2026\u2026\u2026,qn are rela-tions in the knowledge base. During inference, given an entity x, the score for each entity y is calculated as the sum of the confidence scores of rules that imply p(x,y). A ranked list of entities is then returned, where a higher score corresponds to a higher ranking.\nTensorLog TensorLog maps each entity e\u00a1 \u2208 & to a one-hot vector v; \u2208 {0,1}|| where only the i-th entry is 1, and it defines an operator Mq for each relation q by mapping each relation q \u2208 R to a matrix Mq \u2208 {0,1}|8|\u00d7|| such that its (i, j) entry is 1 iff q(ei,ej) is a fact in the KG, where ei, ej \u2208 E. So Mq is essentially an adjacency matrix.\nFor instance, considering a subgraph of the KG presented in Figure 1 consisting of 5 entities, every entity is encoded as a one-hot vector of length 5, corresponding to the number of the entities in the subgraph, so, for relations q1 = birthCountry, q2 = officialLang we have the following adjacency matrices:"}, {"title": "4.1.2. Decoupling Models", "content": "To address challenges of optimization in joint learning of rule structures and confidence, several methods have been proposed that separate these two tasks.\nRNNLogic [26] addresses the challenges in existing methods that struggle with navi-gating a large search space (as in neural logic programming). RNNLogic is composed of a rule generator and a reasoning predictor. The rule generator is responsible for structure learning and a reasoning predictor for confidence learning. The rule generator produces logic rules for the reasoning predictor, for a given query. The reasoning predictor uses the generated rules as input to reason over a knowledge graph and predict the answer. In each iteration, the rule generator produces a set of logic rules. Moreover, in each iteration, the reasoning predictor is updated to explore these rules for reasoning. In the next step, a set of high-quality rules is identified from the generated rules via posterior inference. In the final step, the rule generator is updated to align with the high-quality rules identified in the previous step.\nRNNLogic is optimized using an Expectation-Maximization (EM) algorithm.\nRLogic [27] is a method for mining chain-like rules. The authors highlight two lim-itations of other algorithms: their dependence on observed rule instances to define the score function for rule evaluation, and their inability to mine rules that lack support from rule instances. To address these challenges, RLogic operates by sampling closed paths within a knowledge graph and proposes a sequential rule learning algorithm that decom-poses a sequential model into smaller atomic models in a recursive manner. For example, the relation path [birthCountry, o f ficialLang] existing in our sample KG (Figure 1) can be replaced by a single relation nativeLang. To address cases when the relation to replace with might not be present in the knowledge graph, a \"null\" predicate is also introduced into the relations set.\nThe authors introduce a relation path encoder and a close ratio predictor. The goal of the relation path encoder is to find a head relation ph to replace an entire relation path. The relation path encoder reduces the rule body [91,..., qn] to a head ph by recursively merging relation pairs using a greedy algorithm. The close ratio predictor is based on the observation that, even after logically deducing a reduction of the relation path to a single relation head, this head relation may not always be present in the knowledge graph. Therefore, the task of close ratio predictor is to estimate the ratio that a path will close and the probability of replacing a relation pair with a single relation. A two-layer, fully connected neural network (MLP) is used for this purpose."}, {"title": "4.2. Embeddings and rule learning", "content": "Among other things, the previously mentioned algorithms have been designed to provide a rule-based approach for solving predictive tasks, e.g. the KG completion, with a set of mined rules. The main feature of rule-based systems is the need to first obtain rules whose relevance is then computed based on the coverage of a given rule by some exam-ples occurring in the input KG. Hence, the rules searching process and their relevance determination often require storing the entire KG in the memory to allow for fast explo-ration of the search space or walking through the graph. This may be a problem for large KGs since they have high resource requirements, and the existing systems are not able to effectively scale input data and the mining process."}, {"title": "pure", "content": "Graph embeddings are often regarded as an alternative to rule-based approaches for solving specific prediction tasks over graph data, e.g. for link prediction. The graph-embeddings prediction model is composed of a nodes/relations representation (e.g. vec-tors, matrices) and a scoring function (to calculate the reliability of a predicted entity). The popularity of these kinds of models is given by a simple vector or matrix representa-tion of the entire graph where fast and scalable vector operations can be performed, e.g., to determine similarities among nodes within Euclidean space. Recent studies have also shown that some techniques using graph embeddings outperform convenient rule-based approaches, like AnyBURL [28,29", "30": "HolE [31", "32": ".", "33": ".", "34": "uses low-dimension embeddings of RDF KG resources and predicates for fast search of Horn rules. This algorithm, which accord-ing to the authors' benchmark, outperforms EmbedRULES, focuses on a specific predi-cate p at the head position. For each p it creates a sample of an input KG with such facts that are connected to p up to the maximum length of the rule. This operation is required for a large KG since RLVLR uses the RESCAL factorization to create embeddings by default, which can be slow for large data sets. Most of the mining sub-processes, such as paths finding, support and confidence computations, are performed by matrix operations from embeddings and adjacency matrices. Although this method can be faster than state-of-the-art approaches, such as AMIE, it is limited only to learning rules for a specific predicate and is not designed to discover rules with constants. The main use case of this algorithm is traceable KG completion with a given predicate.\nAnother rule mining system using embeddings is RuLES2 [35", "36": "for computing measures of significance.\nWhile learning rules from embeddings has certain advantages, it is also known to have multiple weaknesses.\nDifferences in predictive performance between rule-based, rule embedding and pure embedding models There is a"}]}