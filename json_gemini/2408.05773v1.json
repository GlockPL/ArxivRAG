{"title": "Neurosymbolic Methods for Rule Mining", "authors": ["Agnieszka \u0141AWRYNOWICZ", "Luis GAL\u00c1RRAGA", "Mehwish ALAM", "B\u00e9r\u00e9nice JAULMES", "V\u00e1clav ZEMAN", "Tom\u00e1\u0161 KLIEGR"], "abstract": "In this chapter, we address the problem of rule mining, beginning with essential background information, including measures of rule quality. We then explore various rule mining methodologies, categorized into three groups: inductive logic programming, path sampling and generalization, and linear programming. Following this, we delve into neurosymbolic methods, covering topics such as the integration of deep learning with rules, the use of embeddings for rule learning, and the application of large language models in rule learning.", "sections": [{"title": "1. Introduction", "content": "The schema of knowledge graphs (KGs) can be represented using ontological axioms and/or rules. Rules can be used for explainable inference for tasks such as link prediction or fact checking [1].\nHovewer, formulating rules manually is demanding in practice. For that reason, automatic rule learning approaches have attracted attention.\nWu et al. in their survey [2] distinguish three major groups of rule learning methods: Inductive Logic Programming-based, statistical path generalisation and neuro-symbolic. In this chapter, to introduce the topic of rule mining and provide necessary backround, we discuss each of these groups and give a more detailed example of algorithms within each group paying most attention to neuro-symbolic ones. We also discuss the topic of using Large Language Models (LLMs) for rule mining."}, {"title": "2. Background", "content": "Rules A (Horn) rule is an expression of the form"}, {"title": "3. Rule Mining", "content": "Rule mining is the task of learning logical rules from a knowledge graph fully automatically. This problem is challenging for two main reasons. First, it is computationally expensive, specially for large KGs, because it incurs the exploration of a very large search space. Second, it requires to make assumptions about what constitutes a counter-example in order to evaluate the quality of the rules. Since those rules are usually used for inference tasks, it is common to focus on closed rules, which as a side effect also reduce the space of rules to explore. There are different approaches to rule mining that we will describe in the following."}, {"title": "3.1. Inductive Logic Programming", "content": "The study of learning Horn clauses has been a significant focus in the inductive logic programming (ILP) field [6,7,8]. ILP methods are based on search of the space of possible patterns or rules. To systematically explore the space during the learning process, ILP methods usually use refinement operators. A refinement operator defines a way to move from one candidate rule to another, more specific or more general. In rule mining, particularly within ILP, refinement operators help navigate the pattern or rule space in a structured manner. Refinement operators usually add/remove atoms or specialize/generalize predicates. We will see example refinement operator in Section 3.1.1 where the algorithm AMIE is discussed."}, {"title": "3.1.1. AMIE", "content": "AMIE [3] is a top-down closed rule mining algorithm designed for large KGs under the OWA. AMIE constructs new rules by adding atoms to already discovered rules. This process is called refinement. Some of those rules will be intermediate non-closed rules that AMIE refines but does not output. By default, the algorithm starts with all the rules of the form 0 \u21d2 r(x,y) that are iteratively refined via three mining operators:\nAdd dangling atom refines a rule with a new atom containing a fresh variable. For rule 0\u21d2 speaks(x, y), this operator could produce rules such as hasOfficialLang(z\u0131,y) \u21d2 speaks(x, y) or nationality(x,z1) \u21d2 speaks(x,y)."}, {"title": "", "content": "Add closing atom adds a new atom without fresh variables. In our previous example, this operator could lead to the rule likes(x,y) \u21d2 speaks(x,y). Similarly, the rule hasOfficialLang(z\u0131,y) \u21d2 speaks(x,y) could be closed by adding the atom nationality(x, z1) to the body.\nAdd instantiated atom refines the rule with an instantiated atom, that is, an atom where one of the arguments is a constant, e.g., the rule likes(x,y) \u21d2 speaks(x, y) could become is(x, Linguist)\\likes(x,y) \u21d2 speaks(x,y). By default, this operator is disabled, but can be turned on by the user. This also allows the system to start with rules of the form 0 \u21d2 r(x, C) or 0 \u21d2 r(C,y) for constants C from the KG.\nThese mining operators allow AMIE to explore the space of closed Horn rules. AMIE imposes a user-defined minimum threshold on support and a maximum rule length (also configurable by the user) to keep the search space under control. By default, AMIE finds rules up to 3 atoms and stops the refinement as soon as head coverage drops below 1%. This policy, based on the anti-monotonicity of the head coverage, speeds up the mining by avoiding noisy rules that cover too few positive examples. AMIE can also enforce user-defined thresholds on standard and PCA confidence (set by default to 10%).\nAll these considerations made AMIE the fastest rule mining algorithm on KGs at its time of publication, achieving a speed up of at least 3 orders of magnitude w.r.t. classical inductive logic programming approaches such as WARMR [9] and ALEPH [10] on modern KGs such as YAGO2 [11] (approx. 1M facts) \u2013 previous approaches could not handle larger datasets such as DBpedia. Moreover, and in contrast to its competitors, its reliance on the PCA confidence to quantify the quality of rules made it produce more and more precise predictions than its competitors. On YAGO2, for instance, the rules had a precision in the range of 30%-40% and the PCA confidence proved more suitable than the standard confidence at ranking best the rules that inferred good new predictions predictions beyond the KG.\nAMIE+ [5] improves over AMIE with the help of various algorithmic optimizations to speed up rule mining. This included changes in the rule refinement procedure as well as some heuristics to discard potentially noisy rules. AMIE+ avoids refining rules when the resulting refinement cannot lead to a closed rule given the maximal length constraint. It also implements some query simplification for recursive rules, i.e., rules where a predicate appears more than once. It also implements a skyline technique that stops refining closed rules that have already attained 100% confidence and propose lower bounds and confidence estimations that prune noisy rules, i.e., rules of very low confidence, before computing their actual confidence scores \u2013 a computationally expensive task. All these optimizations allowed AMIE+ to run on larger datasets such as DBpedia 3.8 and Wikidata 2014 and achieve a speed up of at least one order of magnitude w.r.t. AMIE.\nAMIE 3 Lajus et al. [12] introduced the latest version of AMIE, called as AMIE3, that features several query processing and data representation improvements. For example, the existential variable detection heuristic optimizes the queries required to compute the rule confidence scores by properly identifying variables with existential semantics whose instantiations do not need to be fully enumerated. AMIE3 also proposes a lazy evaluation criterion for the confidence scores. This strategy stops the enumeration of the solutions of the normalization term (denominator) of the confidence scores as soon as it is clear that the resulting confidence will be below the minimum confidence threshold. Other optimizations include the parallelization of the construction of some indexes and"}, {"title": "3.2. Path Sampling and Generalization", "content": "RuDiK [13] is an algorithm that discovers both positive and negative rules. Mining negative rules helps to detect erroneous facts, which can be common in knowledge bases, due to errors being propagated. RuDiK consists of three modules: the first module generates negative examples, the second one is an incremental rule miner and the last module executes rules, to generate new facts and find inconsistencies.\nNegative example generator creates negative examples, given a knowledge base and a target predicate. It does this by leveraging the Local Closed-World Assumption (LCWA) [15]. Under this assumption, if a triple q(s, o) does not occur in a knowledge base, but q(s,x) is present, then q(s,o) is false. Similarly, if q(s, o) is present but q'(s, o) is not, then q'(s, o) is false. RuDiK finds entities whose information is more likely to be complete, to generate good negative examples.\nIncremental rule miner discovers Horn Rules. Here, the atoms are of the form q(s, 0). The algorithm uses a set of positive examples G and a set of negative examples V. The ideal solution is the minimal set of rules for which all the examples in G are valid and none of those in V are. The goal of this rule miner is to find the optimal set of weighted rules. The weight of a rule has two components. The first is the ratio between the coverage of this rule over G and G itself. The second component measures the same thing over V. Parameter a is set to define the weight of the first component. There is also \u1e9e, defined as 1-\u03b1. \u03b2 defines the importance of the second component. This definition of weight is extended to define a marginal weight as follows. If R is a set of rules and r is a rule:\n$wm(r) = w(RUr) \u2013 w(R)$"}, {"title": "", "content": "A rule will not be added to the solution if its marginal weight is at or below 0. A valid rule r(x,y) can be represented as a path between x and y in the knowledge base, which is represented as a directed graph. Another type of atoms can be included in the rules: literal comparison. For example, the rule\nbornIn(a,x) ^x \u2260 U.S.A. \u21d2 \u00ac president(a,U.S.A.).\nThe algorithm starts with an entity x and keeps a set of candidate paths. At each step, the path with the smallest marginal weight is expended. Once a path is considered valid, it is added to the solution, and it stops being expended.\nRule execution Once a rule has been discovered, RuDiK can run it in the knowledge base, as a SPARQL query. This enables it to deduce new facts, or to detect erroneous ones that are in the knowledge base. The accuracy for new facts is 85%, and 97% for inconsistencies. When running RuDiK over Wikidata, DBpedia and YAGO 3, the proportion of erroneous triples was respectively 0.23%, 0.26% and 0.6%."}, {"title": "", "content": "Different parameters impact on the performance of RuDiK. Turning off literal comparison visibly degrades accuracy for both positive and negative rules. The level of noise in the database also affects the performance, though RuDiK is rather robust in this regard. Another important parameter is the maximum path length. When it is set at 2, precision for positive rules drops to 49%. When it is set at 4, RuDiK does not finish after 24 hours, and the precision is not notably better than when it is set at 3. Therefore, 3 is used as the maximum path length. The last parameter is a and \u1e9e, the weight parameters. There are different optimal values for positive and negative rules, however the algorithm is robust and the variation in performance are limited as long as a (and \u1e9e) is in the [0.1,0.9] range.\nAnyBURL [16] is a bottom-up algorithm inspired by Golem [17] and Aleph [10]. The algorithm chooses random paths of a set path profile, and generalizes them to rules. A path profile \"describes path length and whether the path is cyclic or acyclic\". The support and confidence of these rules are then computed, and the rules that fulfil a given criteria, usually minimum support or confidence, are stored. Given a completion task, the candidates are ranked by the maximum confidence of the rules that have generated them, then by the second best one, and so on, until one rule stands out. There is more than one round of mining and selection of rules. Each round lasts a set amount of time. At the end, the length of possible paths can be increased if the set of results reaches saturation, i.e. if the number of new rules being discovered is too low.\nAnyBURL also uses reinforcement learning to determine how much effort should be dedicated for each path profile. It also uses Object Identity, which assumes that when two variables appear in a rule, they designate different entities. This is made to avoid redundant rules. There is a new version of AnyBURL [18], which introduces four major modifications. The first modification is object identity as described in [19], to avoid learning redundant rules, which would skew the confidence score. The second modification is confidence sampling, which serves to avoid a depth-first search when computing the confidence of a rule in a very large dataset. The third modification is reinforcement learning-based sampling which makes the path sampling more robust, and especially less sensitive to change in parameter settings. The fourth modification is multi-threading which enhances the performance of AnyBURL on very large graphs and makes it 20 times faster than SOTA.\nRARL [20] uses rule relatedness (or TBox relatedness) to rank candidate rules. The authors define two boxes. The ABox contains the facts, while the TBox contains the underlying schema of the knowledge base. Rules are considered related when they often link the same subjects and objects in the ABox. The confidence of these rules is computed under the Partial Completeness Assumption [5], which allows the creation of negative examples."}, {"title": "3.3. Linear programming", "content": "A recent paper [21] presents LPRules, an algorithm for rule mining that uses linear programming to mine rules inside a knowledge graph. It creates a weighted linear combination of FOL rules that are then used as a scoring function for knowledge graph completion. It also limits the size of the rules, to increase human interpretability."}, {"title": "4. Neurosymbolic Methods", "content": "4.1. Deep learning and Rules\nWe now introduce end-to-end approaches that utilize deep neural networks (DNNs) to learn rules by optimizing objective functions approximating path patterns."}, {"title": "4.1.1. Neural Logic Programming", "content": "Neural LP [22] is one of the pioneering efforts to integrate rule structure learning with parameter learning in an end-to-end differentiable model. It draws inspiration from the TensorLog [23] differentiable probabilistic logic framework. The TensorLog framework compiles rule inference into a series of differentiable operations by linking rule application to sparse matrix multiplications. The method thus simplifies the rule learning problem to algebraic operations on neural embedding-based representations of a given knowledge graph.\nThe reasoning task the NeuralLP addresses involves three components: query, an entity tail about which the query is made, and an entity head that serves as the query's answer. The objective is to generate a ranked list of entities in response to the query, aiming to position the correct answer (i.e., the head) as high as possible on this list. We can formalize the query as a rule\n$q1 (x, z1) ...qn(x,zn) \u21d2 p(x,y)$"}, {"title": "", "content": "with associated confidence a \u2208 [0,1], where p(x,y) is the query, and q1,\u2026\u2026\u2026,qn are relations in the knowledge base. During inference, given an entity x, the score for each entity y is calculated as the sum of the confidence scores of rules that imply p(x,y). A ranked list of entities is then returned, where a higher score corresponds to a higher ranking.\nTensorLog TensorLog maps each entity e\u00a1 \u2208 & to a one-hot vector v; \u2208 {0,1}|| where only the i-th entry is 1, and it defines an operator Mq for each relation q by mapping each relation q \u2208 R to a matrix Mq \u2208 {0,1}|8|\u00d7|| such that its (i, j) entry is 1 iff q(ei,ej) is a fact in the KG, where ei, ej \u2208 E. So Mq is essentially an adjacency matrix.\nFor instance, considering a subgraph of the KG presented in Figure 1 consisting of 5 entities, every entity is encoded as a one-hot vector of length 5, corresponding to the number of the entities in the subgraph, so, for relations q1 = birthCountry, q2 = officialLang we have the following adjacency matrices:"}, {"title": "", "content": "We now establish the connection between TensorLog operations and logical rule inference, where the goal is to imitate logical rule inference for some entity ei. The application of the rule on an entity e\u00a1 can be represented by performing matrix multiplications\n$Mq1Mq2... Mqn \u00b7 Vi = s$\nFor example, consider the rule\nbirthCountry(x,z), of ficialLang(z,y) \u21d2 speaks(x,y)\nwhich we can translate, for the sake of inference, to:\nMbirthCountry MofficialLang Vy = S\nThe non-zero entries in the vector s point to the entities for which p(x,y) (in this case speaks(x,y)) is derived. These non-zero entries of the vector s equals the set of y such that there exists z that birthCountry(x,z) and of ficialLang(z,y) are in the KG.\nBy assigning vx = [1,0,0,0,0]T to point to E. Macron and performing the matrix multiplications, as the result we have s = [0,0,0,1,0], which points to French.\nLet \u1e9ei denote an ordered list of all relations appearing in the rules. Following [22], the inference for each query is defined, more generally, as:\n$\\sum {a_i \\prod M_{q_k}}$\nke\u03b2\u03b9\ns =$\\sum (a_\u03b9 (\\prod M_{q_k}Vy)), score(x_\u03b9, y) = v_x^Ts^\u03c4$\nke\u03b2\u03b9\nIn summary, the learning problem for each query becomes:"}, {"title": "", "content": "$\\max {\\sum score(xy)}$\n{\u03b1\u03b9,\u03b2\u03b9} {x,y} =$\\max {\\sum v_x^T (\\sum (a_\u03b9 (\\prod M_{q_k}V_y))}$"}, {"title": "", "content": "The goal is to extract the rules from the solution of the above optimization problem, by using the defined operators.\nLearning rules The set of rules that imply each query and the confidences associated with these rules need to be learnt, that is {\u03b1\u03b9, \u03b2\u2081} are to be learnt. To facilitate this by addressing the problem of enumerating rules, Yang et al. [22] proposes to rewrite Equation 13 in the following way:\n$\\prod\\sum M_{a_k}$"}, {"title": "", "content": "where T denotes the maximum length of rules and R the number of relations in the knowledge graph. In order to combine the enumeration of the rules and confidence assignment, the key difference in this new formulation is that each relation in the rules is associated with a weight.\nSince rules may be of different length Yang et al [22] introduced a recurrent formulation that resembles this in Equation 14. This version uses auxiliary memory vectors ut, which are at the beginning set to the given entity vy:\n$u_0= V_y$\nThen, at each step, the model first computes a weighted average of the previous memory vectors using the memory attention vector b\u2081, and secondly, it applies the TensorLog operators using the operator attention vector at:\nR\n$U_t = (\u2211Ma_k) b_t for 1\u2264 t \u2264T$\nket=\nIn the last step, the model computes a weighted average of the memory vectors. In order to choose a proper rule length, attention is used in this step:\n$VT+1 =\u2211b^\u03c4+1U_t$\nThe learnable parameters are the memory and operator attention vectors. Recurrent neural networks can now be used that fit this recurrent formulation, and the authors of [22] used LSTM for this purpose.\nNeural-Num-LP [24] enhances Neural-LP by incorporating the ability to learn rules with negations and numeric values. Additionally, it improves on Neural-LP through implicit representation of essential matrix operations. These improvements include the use of dynamic programming, cumulative sums for numerical comparison features, and low-rank factorisations for negated atoms.\nDRUM [25] was introduced to mitigate a tendency of Neural-LP to learn meaningless rules with high confidence that share atoms with valid rules. To mitigate this issue, DRUM employs bidirectional RNNs to prune potentially incorrect rules as well as low-rank decompositions of matrix Mp."}, {"title": "4.1.2. Decoupling Models", "content": "To address challenges of optimization in joint learning of rule structures and confidence, several methods have been proposed that separate these two tasks.\nRNNLogic [26] addresses the challenges in existing methods that struggle with navigating a large search space (as in neural logic programming). RNNLogic is composed of a rule generator and a reasoning predictor. The rule generator is responsible for structure learning and a reasoning predictor for confidence learning. The rule generator produces logic rules for the reasoning predictor, for a given query. The reasoning predictor uses the generated rules as input to reason over a knowledge graph and predict the answer. In each iteration, the rule generator produces a set of logic rules. Moreover, in each iteration, the reasoning predictor is updated to explore these rules for reasoning. In the next step, a set of high-quality rules is identified from the generated rules via posterior inference. In the final step, the rule generator is updated to align with the high-quality rules identified in the previous step.\nRNNLogic is optimized using an Expectation-Maximization (EM) algorithm.\nRLogic [27] is a method for mining chain-like rules. The authors highlight two limitations of other algorithms: their dependence on observed rule instances to define the score function for rule evaluation, and their inability to mine rules that lack support from rule instances. To address these challenges, RLogic operates by sampling closed paths within a knowledge graph and proposes a sequential rule learning algorithm that decomposes a sequential model into smaller atomic models in a recursive manner. For example, the relation path [birthCountry, o f ficialLang] existing in our sample KG (Figure 1) can be replaced by a single relation nativeLang. To address cases when the relation to replace with might not be present in the knowledge graph, a \"null\" predicate is also introduced into the relations set.\nThe authors introduce a relation path encoder and a close ratio predictor. The goal of the relation path encoder is to find a head relation ph to replace an entire relation path. The relation path encoder reduces the rule body [91,..., qn] to a head ph by recursively merging relation pairs using a greedy algorithm. The close ratio predictor is based on the observation that, even after logically deducing a reduction of the relation path to a single relation head, this head relation may not always be present in the knowledge graph. Therefore, the task of close ratio predictor is to estimate the ratio that a path will close and the probability of replacing a relation pair with a single relation. A two-layer, fully connected neural network (MLP) is used for this purpose."}, {"title": "4.2. Embeddings and rule learning", "content": "Among other things, the previously mentioned algorithms have been designed to provide a rule-based approach for solving predictive tasks, e.g. the KG completion, with a set of mined rules. The main feature of rule-based systems is the need to first obtain rules whose relevance is then computed based on the coverage of a given rule by some examples occurring in the input KG. Hence, the rules searching process and their relevance determination often require storing the entire KG in the memory to allow for fast exploration of the search space or walking through the graph. This may be a problem for large KGs since they have high resource requirements, and the existing systems are not able to effectively scale input data and the mining process."}, {"title": "", "content": "Graph embeddings are often regarded as an alternative to rule-based approaches for solving specific prediction tasks over graph data, e.g. for link prediction. The graphembeddings prediction model is composed of a nodes/relations representation (e.g. vectors, matrices) and a scoring function (to calculate the reliability of a predicted entity). The popularity of these kinds of models is given by a simple vector or matrix representation of the entire graph where fast and scalable vector operations can be performed, e.g., to determine similarities among nodes within Euclidean space. Recent studies have also shown that some techniques using graph embeddings outperform convenient rule-based approaches, like AnyBURL [28,29]. Some well-known methods to transform a KG or its individual components (nodes and edges) into vectors are, e.g. RESCAL [30], HolE [31] and TransE [32]. Besides pure graph embedding models, some algorithms even combine the rule-based with the graph embedding approach.\nAn early approach combining embeddings and rule-based systems was called EmbedRULES [33]. The RLvLR algorithm [34] uses low-dimension embeddings of RDF KG resources and predicates for fast search of Horn rules. This algorithm, which according to the authors' benchmark, outperforms EmbedRULES, focuses on a specific predicate p at the head position. For each p it creates a sample of an input KG with such facts that are connected to p up to the maximum length of the rule. This operation is required for a large KG since RLVLR uses the RESCAL factorization to create embeddings by default, which can be slow for large data sets. Most of the mining sub-processes, such as paths finding, support and confidence computations, are performed by matrix operations from embeddings and adjacency matrices. Although this method can be faster than state-of-the-art approaches, such as AMIE, it is limited only to learning rules for a specific predicate and is not designed to discover rules with constants. The main use case of this algorithm is traceable KG completion with a given predicate.\nAnother rule mining system using embeddings is RuLES2 [35]. It uses the AMIE approach to generate rules (with or without constants) and an embedding pre-trained model by TransE, HolE, or SSP [36] for computing measures of significance.\nWhile learning rules from embeddings has certain advantages, it is also known to have multiple weaknesses."}, {"title": "", "content": "Differences in predictive performance between rule-based, rule embedding and pure embedding models There is a paucity of research showing better performance of embeddings-based rule approaches over pure rule learning approaches. Compared with the state-of-the-art RLVLR algorithm, the pure rule-learning approaches AnyBURL and its enhanced version SAFRAN [37] are reported to perform better [37]. However, this benchmark is based only on one dataset (FB15K-237). The same paper [37] also shows that SAFRAN generally performs on part with the best embedding-based (latent) approaches, but unlike them, it is rule-based and thus inherently interpretable. It should be noted the evaluation in [37] is limited by possibly different evaluation conditions between RLVLR and SAFRAN and may not be free of bias, as the evaluation was done by the author of some of the compared methods.\nExplainability With the growing emphasis on explainability in machine learning, a major limitation is that the predictions generated by graph embedding models are not traceable. Thus, the reliability of the prediction is given by the scoring function, which, however, does not explain to us what parameters lead to a given score. This is in contrast to rule-based models, where a specific score (confidence) value can be traced back to individual paths in the training data. For example, the RDFRules system offers a graphical interface to easily trace predictions based on AMIE-like rule-based models [38]."}, {"title": "4.3. RLvLR: Rule Learning via Learning Representations", "content": "The Rule Learning via Learning Representations (RLvLR) algorithm is inspired by NeuralLP. It mines closed rules introduced in section 2, that have the form shown in Eq. 1.\nP1(x,z1)P2(Z1, Z2)... Pn (Zn \u2013 1,y) \u21d2 p(x,y).\nRLVLR uses the Standard confidence (Eq. 6) and Head Coverage (Eq. 4) to evaluate the quality of rules. RLvLR authors state three main improvements compared to previous approaches such as NeuralLP described earlier:\n\u2022 removing data not relevant for computation,\n\u2022 argument embeddings: new rule quality measure through,\n\u2022 rule quality computed through matrix operations.\nRemoving data not relevant for computation This operation takes advantage of the problem formulation, where for a given head predicate p and maximum rule length 1, only entities that are directly or indirectly related to p are relevant for the mining.\nFor each head predicate p, this procedure creates a subset of the input KG containing facts that are connected to p up to the maximum length of the rule 1(1 > 2). The fact and entity selection is done so that the subset contains all information relevant for learning rules of length I with a given head predicate p. The algorithm first identifies the sets eo...ei...el-2, which contain entities in facts directly (for i = 0) or indirectly (for i > 0) related to p. Consequently a subset of the original KG is generated, referred to as KG'. KG' contains only those facts from the original KG, where both entities in the fact (subject and object) are present among the previously identified entities (those in E' = U-2 ei).\nReferring to the sample knowledge graph in Figure 1, consider this procedure for speaks as the head predicate p and 1 = 2. The algorithm first identifies the set eo, which contains entities in facts directly related to p. In this case, the directly related facts are {speaks(UvdLeyen,English),speaks(Macron,French)}, hence the set eo = {Macron,French,UvdLeyen,English}. Since l = 2, the set e1=2 = e0 and KG2 = speaks(EMacron,French), speaks(U.v.d.Leyen,English). However, there is no non-trivial rule of length 2 that can be extracted from KG1_2. We need to, therefore, increase the value of I to l = 3. Now, we additionally need to compute the set e\u2081, which will contain those entities that are linked to any of the entities in eo by any predicate. We get e1 = {English, German, Germany, EU, female,France,male}. Consequently, e1=3 will contain all entities from the original KG except A. Merkel. Based on el=3, we will get KG_3, which will contain all statements in the original KG in Figure 1 except for nationality(A. Merkel, Germany) and birthCountry(A. Merkel, Germany). From this KG, the algorithm can extract rules such as the one in Eq. 3 and the absence of some facts (in this case, two facts with A Merkel), will make this process faster."}, {"title": "", "content": "Note that while this step was originally called 'sampling' by RLvLR authors, it does not, in our opinion, correspond to the probabilistic implementation of sampling, which is typically understood as a random process affecting a user-set percentage of data samples. As the example shows, in RlvLR, this step can be variously effective based on the rule's length (l parameter) and the graph's overall characteristics.\nArgument embedding KG embeddings, as implemented by, e.g., the RESCAL algorithm, apply to entities and relations. With argument embeddings\nRLVLR uses both synonymy and the newly introduced co-occurrence scoring functions. We will first introduce the synonymy scoring function, including with an example, and then we will briefly cover the more complex co-occurrence scoring function, details of which can be found in the article describing RLvLR [39].\nUsing the notation we introduced in section 4.1.1, predicates in a body of a RLVLR rule are represented using adjacency matrices P1,..., Pn and the head predicate using embedding matrix P, the product P1 P2..... Pn should, according to the authors, capture pairs of entities connected by the body of the rule. As the body should be predictive of the head, the more this product is similar to the matrix P, the better. To measure matrix similarity, the RLvLR algorithm uses the exponentiated result of a Frobenius norm of the difference between the two matrices. Unfortunately, the authors do not provide source code or additional details on how the embeddings are computed, besides a generic reference to predicate embeddings from [40].\nIn addition to the synonymy scoring function, the RLvLR algorithm uses the co-occurrence scoring function. To compute this, the authors introduced the concept of argument embeddings, which are averages of the \"embedding vectors\" in the subject and object positions of the given predicate.\nMatrix computation of rule evaluation measures The RLVLR algorithm uses adjacency matrices to compute the rules' standard confidence and head coverage. We will illustrate how head coverage is computed.\nLet us use the sample knowledge graph in Figure 1, and rule 3 as an example.\nIn the following, there are adjacency matrices for the two predicates in the body of the rule."}, {"title": "4.4. Large Language Models for Learning Rules", "content": "This section discusses some of the recent studies using Large Language Models for learning rules."}, {"title": "4.4.1. Hypotheses-to-Theories", "content": "One of the recent framework, Hypotheses-to-Theories (HtT) [41] is designed to learn a set of rules from training examples, which is then used for reasoning over test samples using Large Language Models (LLMs). The framework is designed with the objective to target the issue of incorrect rule generation by LLMs which is often the case when LLMs rely on their implicit knowledge for rule creation instead of taking into account the problem at hand or the data provided. The framework employs both inductive and deductive reasoning through few-shot prompting. Inductive reasoning involves deriving general rules from specific observations, while deductive reasoning involves deriving new facts based on the existing ones.\nInduction Stage: Learning a Rule Library. The induction stage aims to learn rules from training examples without explicit rule annotations. For each training example (a question-answer pair), HtT prompts an LLM to generate rules for answering the question. Regular expressions are then used to extract rules from the LLM's output. Given the noisy nature of LLM reasoning, rules and accuracy metrics are collected from a sufficient number of training examples. The rules are filtered based on criteria from [3], considering both coverage and confidence. Coverage indicates how likely a rule is to be reused, while confidence indicates how likely it is to be correct.\nDeduction Stage: Reasoning using the Rule Library. The rule library generated in the induction phase is used for deductive reasoning prompt based on Chain-of-Thought prompting. The examples are modified to teach the LLM to retrieve rules from the library whenever it needs to generate a rule. If all the rules required by a question are present in"}, {"title": "4.4.2. ChatRule", "content": "ChatRule [42", "as": "n$P := Alice \\xrightarrow{Mother} Bob  \\xrightarrow{Father} Charlie,$\nwhich completes the triple (Alice, GrandMother, Charlie) in K"}]}