{"title": "SELF-CONTROLLER: CONTROLLING LLMs wiTH MULTI-ROUND STEP-BY-STEP SELF-AWARENESS", "authors": ["Xiao Peng", "Xufan Geng"], "abstract": "The applications of large language models (LLMs) have been widely spread across all domains. However, the basic abilities such as the controllability of LLMs are still limited. To address this, we propose \"Self-controller\u201d, a novel agentic framework bringing self-awareness into LLMs' reasoning logic. The core idea of this work is to maintain states based on the LLM's response, letting the LLM become self-aware of current status and think step by step in a multi-round chain-of-thought paradigm. Our experiment on the state of textual length has shown the controllability and effectiveness of the Self-controller. We further implement a binary search algorithm to accelerate the generation process based on the linearity and monotonicity of the textual length state. Another advantage of the Self-controller comes with DeepSeek's Context Caching technology, which significantly saves computational token consumption when a cluster of conversations shares the same prefix of context. Theoretically, we prove that in this scenario the extra time complexity is O(clogn). Results of the back-of-the-envelope estimation suggest that the token consumption of our method is no more than twice as much as that of the trivial single-round generation. Furthermore, our ablation study on word constraints demonstrates the Self-controller's consistent controllability across all foundation models.", "sections": [{"title": "INTRODUCTION", "content": "Humans are constantly troubled with self-control issues. Naturally, we ponder the question: do LLMs learning from humans inherit the same characteristics? The willpower of self-control was first discussed in psychology. The study called \"the marshmallow test\u201d (Mischel, 2015), was originally developed in the 1960s. The test's goal is to observe how children make decisions between waiting 15 minutes longer for two marshmallows they eagerly wanted or settling for just one right away. The experimental results imply that without accurate reward assessment, the actions of human beings might converge to a local optimum.\n\nThe self-awareness mechanism is embedded in the mind. In real practice, to reach a specified goal such as finishing an article with a fixed page size, humans often verify their current progress repetitively. As a result, self-awareness promotes self-control. Adam and Eve \"realizes they are naked\" in the garden and feels ashamed, starting to wear clothes ever after (Bratcher, 1979). In the meantime, the advancement of LLMs shows new emergent abilities, demonstrating great potential for mimicking such primary intelligent behaviors. However, building self-awareness upon LLMs to ensure controllability is still underexplored.\n\nLength control is a classical task that reflects controllability in LLMs. Traditional length control approaches highly rely on trivial instructions, post-hoc verification, and supervised fine-tuning (SFT). These approaches"}, {"title": "RELATED WORKS", "content": "Large Language Models In recent years, LLMs' abilities continually grow. Raffel et al. (2020) revealed the broad application potential of large-scale pre-trained models in natural language processing (NLP) tasks through fine-tuning techniques. Brown (2020) demonstrated that even with limited sample sizes, LLMs can still exhibit excellent performance through autoregressive mechanisms. Chowdhery et al. (2023) further explored the relationship between model size and performance, confirming the advantage of larger models in capturing linguistic complexity. With the advent of models such as ChatGPT and GPT-4 (Liu et al., 2023;\n\nSelf-awareness There are attempts to assess self-awareness in LLMs. Li et al. (2024) propose a unified taxonomy for awareness in LLMs, including capability, mission, emotion, culture, and perspective. Wang et al. (2024) introduces the knowledge quadrant for multimodal LLMs, knowing knowns and unknowns. To enhance trustworthiness and self-awareness in LLMs, various approaches have been proposed, such as Chain-of-thought (Wei et al., 2022; Kojima et al., 2022), Self-consistency (Wang et al., 2023), ReAct (Yao et al., 2023), Tree-of-thought (ToT) (Muralidharan & Thomas, 2024) and Think-Solve-Verify (Liu et al., 2024). LLMs' hallucination problems have been alleviated with these fine-grained stepwise generation frameworks, while the accurate output manipulation remains underexplored.\n\nControllability The trivial method to improve controllability is to include extra zero-shot instructions (such as \"Output in a sonnet style.\") to the prompt (Kojima et al., 2022). Post-hoc verification utilizes additional check programs evaluating LLMs' responses. Chain-of-Verification (CoVe) designs a planning module to raise a set of verification questions and self-corrects them to get the final response afterward (Dhuliawala et al., 2023). Zhang & Gao (2023) applies a similar idea for news claim verification along with the help of the web search. Recently, generating longer text has drawn attention. Bai et al. (2024) proposes AgentWrite, leveraging \"divide-and-conquer\" agents to generate 10,000+ words, while the length control for each paragraph remains trivial. On the other hand, supervised fine-tuning has been the most prevailing way of ensuring controllability. Juseon-Do et al. (2024) realizes sentence compression with a prompt and improves its performance through instruction-based fine-tuning. Yuan et al. (2024) adds length constraints to the prompt and designs a contrastive proxy task to fine-tune via Reinforcement Learning from Human Feedback (RLHF). Jie et al. (2024) uses reinforcement learning and beam sampling for length control, on GPT-2 models with less than 0.8 billion parameters. Anonymous (2024) embeds length constraints into positional encodings to execute fine-tuning achieving precise length control. The major problems with SFT methods are that they are resource-consuming and lack generalizability."}, {"title": "METHODOLOGY", "content": "3.1 OVERVIEW OF THE SELF-CONTROLLER\n\nThe abstract workflow of the Self-controller, shown in Figure 2, contains a state reflector submodule. Given a specified task, the Self-controller will maintain relevant state variables in the state reflector. In length control, the state variable is the textual length, making transitions from 0 to the requested word constraint Lrequest. The state reflector parses the new LLM response at each round and updates state variables accordingly. The state is then passed as natural words to the LLM generating the next-step response. The reflection procedure will be recycled indefinitely until the framework gets satisfactory results. In practice, JSON output is necessary"}, {"title": "BINARY SEARCH ON THE TEXTUAL LENGTH STATE", "content": "Based on the linearity and monotonicity of the textual length state, we design the binary-search algorithm for the length control, demonstrated in Algorithm 1. The major difference between the trivial and the binary-search state reflector is the initiative of the state reflector. The trivial state reflector only provides textual length states for the LLM to be self-awareness, including the requesting textual length Lrequest and the current number of words len(Soutput). In binary-search state reflector, the reflector not only provides basic statistics but also actively asks the LLM to output [Lrequest - len(Soutput)] words in the next round, thus executing a binary search on the linear space of [0, Lrequest]. In practice, we set the algorithm to go back to the trivial mode when the surplus textual length is no longer valid for constructing a complete sentence.\n\nAlgorithm 1 Binary Search for Length Control\nRequire: Initial input I, textual length constraint Lrequest, deviation constraint \u03b4.\nRequire: A LLM LLM taking a message list M as input.\nRequire: A state reflector R taking a length parameter L to guide the LLM to output.\nRequire: An empty string to store output Soutput.\n1: M = {I}\n2: while len (Soutput) \u2264 Lrequest + d do\n3: r1 - R\n4:  \n5: M + M + {r1}\n6: r2 \u2190 LLM(M)\n7: if \"Summary complete\" \u2208 r2 then\n8: return Soutput\n9: end if\n10: MM+r2\n11: Soutput Soutput + 12\n12: end while\n\n3.3 CONTEXT CACHING IN MULTI-ROUND SESSIONS\n\nCompared with trivial single-round prompts, the cost of the Self-controller is proportional to the total rounds in the muli-round dialogue. An optimization to this is to build contextual caches, thanks to DeepSeek's Context Caching technique, which is made possible by the MLA architecture in DeepSeek-V2 (DeepSeek-AI et al., 2024). Context caching builds textual blocks on disks and saves token consumption by an order of magnitude. When duplicate inputs (only prefixes) are detected, the repeated parts will be retrieved from disks, thus bypassing redundant recomputation.\n\nThe theoretical token consumption of 3 different methods analysis is shown in Figure 3. The single-round generation is the trivial prompting method. The multi-round generation is the plain implementation of the Self-controller. The binary search multi-round generation is an optimized version with both Context Caching and binary search on top of the plain Self-controller.\n\nAssume the input length is Linput, and the requested textual length constraint is Lrequest. The cost of output tokens is k times as much as input tokens. For simplicity, we ignore the difference in token consumption"}, {"title": "", "content": "For the trivial single-round generation, the overall cost is:\ncostsingle-round = Linput+k. Lrequest (1)\nFor the multi-round generation, we generate one sentence at a time. The generated textual length in each round is Lsentence on average. We denote the number of total rounds as n = kLrequest/Lsentence. The overall cost is:\ncostmulti-round = n. Linput + k. Lsentence n. (Lsentence + Lrequest) =  n. Linput + k/2(Lsentence + Lrequest) (2) =  n. Linput + 1/2(Lsentence + Lrequest) (3)\nFor the binary search multi-round generation, the expected generated textual length is proportional to the rest of Lrequest at each round. c is the cost scaling coefficient due to context caching, meaning the cost of"}, {"title": "", "content": "cache-hitting tokens is c times as much as cache-free input tokens (c < 1). The number of total rounds is log n = log(Lrequest/Lsentence) The overall cost is:\ncostbinary-search = [1 + c(log n \u2212 1)]. Linput+k. Lrequest + c . Lrequestlog(n-1)\u03a3(1-1/2i) = [1 + c(log n \u2212 1)] . Linput + k\u00b7 Lrequest . (1 + c log(n - 1) - log(n-1)\u03a31/2i)] = [1 + c(log n \u2212 1)] \u00b7 (Linput + k \u00b7 Lrequest) - k. Lrequest.c.log(n-1)\u03a31/2i = [1 + c(log n \u2212 1)] . costsingle-round - k. Lrequest.c.log(n-1)\u03a31/2i <(1+clog n) . costsingle-round (4) (5) (6) (7) (8)\n\nThe result shows that the extra time complexity is O(clogn) compared with the trivial method. Let's have a back-of-the-envelope estimation. In practice, long output length such as Bai et al. (2024) can generate Lrequest ~ 10,000 words. On average, the textual length of natural sentences has Lsentence < 20. For DeepSeek, c = 0.1. Therefore, we have\nclogn = clog(Lrequest/Lsentence) \u2248 0.1 \u00d7 log(10,000/20) \u2248 0.1 x 8.96 < 1 (9)\nwhich indicates\ncostbinary-search < (1 + clog n) . costsingle-round < 2. costsingle-round (10)\nThis proves the efficiency of the binary search multi-round approach."}, {"title": "EXPERIMENTS", "content": "4.1 LENGTH CONTROL\n\nIn this experiment, 3 datasets are selected from HuggingFace: webis/tldr-17 (short as \"tldr\"), argilla/news-summary (short as \"news\"), and ccdv/arxiv-summarization (short as \"arxiv\"). For each dataset, we sample 128 instances with textual lengths ranging in [800, 1200] words. For foundation models, we choose the following models: GLM series (GLM-4-air, GLM-4-flash), GPT series(GPT-40, GPT-4o-mini, GPT-3.5-turbo), and Deepseek-V2. The word constraint Lrequest is 250 words. Results are within Table 1.\n\nTo ensure the textual generation quality, we evaluate the former results on BERTSCORE proposed by Zhang et al. (2020). We introduce a hypothesis here that the ground-truth reference is the generated text by GPT-40 in single-round respectively. Therefore, the BERTSCOREs of GPT-40 in single-round equals 1 on all datasets. The evaluation results are illustrated in Figure 4, which shows no significant textual quality loss on most models. The degradation and low performance in Table 1 on GLM-4-flash may indicate the inner inability of weaker models. The gap between GPT-40 and all other models may be caused by fine-grained writing styles."}, {"title": "BINARY SEARCH ON LENGTH CONTROL", "content": "To study the effectiveness of the binary-search method, we select 128 samples with longer textual lengths from the tldr and the arxiv dataset, ranging in [2000, 2500] words. The news dataset doesn't contain enough satisfiable samples thus being excluded in this section. The word constraint is set to 500 words. The results"}, {"title": "ABLATION STUDY", "content": "Efficiency We examine the efficiency between the multi-round generation and binary search multi-round generation. We choose 64 samples from the tldr dataset ranging in [2000, 2500] words, along with the representative word constraints as [200, 400, 600, 800, 1000]. Results are illustrated in Figure 5. For weaker LLMs (GPT-3.5-turbo and GLM-4-flash), the efficiency is insignificant in terms of dialogue rounds. For stronger LLMs with moderate instruction following ability, the number of rounds for multi-round generation grows rapidly with the growth of word constraints, while the binary-search version grows slowly at a near log scale. This empirical finding aligns with the theoretical results.\n\nWord Constraint As observed in former experiments, the overall performance of the Self-controller varies according to different word constraint parameters. In this part, we carefully investigate the influence of word constraints. we set the word constraint within a dynamic range of [50, 1300]. All other settings are equivalent to the ablation study on efficiency. The results are shown on scatter plots in Figure 6. This clearly shows that GPT-series are gaining immanent controllability with OpenAI's pretraining advancement on foundation models, which counteracts the Self-controller's controlling effect on small constraints (Lrequest < 500). However, the results imply that the Self-controller takes effect on all word constraints and all models, demonstrating its substantial generalizability."}, {"title": "DISCUSSION", "content": "Exploring Automatic State Management Although the states are not confined to any specific task, the self-controller's prompts still require revision for each new scenario to manage novel states effectively. For future work, we can develop real-time state management based on user intentions, utilizing a society of"}, {"title": "", "content": "agents. Inspired by the binary-search optimization, more heuristic reflections may accelerate the convergence of state transitions.\n\nEnhancing Prompt Engineering Techniques Improving output quality is a key area for further development. An additional refinement process for the self-controller's final output can enhance textual quality and detail expression. For shorter constraints Lrequest < 500, advanced foundation models like GPT-40 already perform well. However, longer outputs may benefit from planning techniques such as the divide-and-conquer approach proposed by Bai et al. (2024). In the future, exploring the integration of planning within the multi-round paradigm of the self-controller could provide global controllability on a book-scale."}, {"title": "New Paradigm of Thoughts", "content": "Towards the dawn of reasoning, ReAct and ToT represent two paths for future directions on CoT. The major difference between these two paths is the way in which the message is passed. ReAct can reason within a single session, while ToT requires assembly in different sessions. Recently, Diagram-of-thought (DoT) (Zhang et al., 2024) proposes a similar idea to our Self-controller, executing reasoning in multi-round sessions. With the development of near-infinite input and output length of LLMs, the multi-round sessions can be more informative than a cluster of generated responses in the future."}, {"title": "CONCLUSION", "content": "In this paper, we introduced the Self-controller, a novel framework designed to enhance the controllability of LLMs by incorporating self-awareness into their reasoning processes. By maintaining state variables and enabling multi-round dialogue sessions, the Self-controller allows LLMs to refine their outputs iteratively, achieving more precise control over tasks such as length control. Our experiments demonstrated that the Self-controller significantly improves the controllability of LLMs across various datasets and models, without compromising the quality of the generated text. Implementing binary search optimization further enhances the efficiency of the multi-round generation process, reducing the computational overhead. The results also suggest that the Self-controller is adaptable to different foundation models and various word constraints, showcasing its generalizability and robustness. Additionally, we explored the potential of the Self-controller in other tasks, such as keyword extraction, indicating its broader applicability beyond length control. Future work will focus on automating state management and exploring more advanced prompt engineering techniques to enhance output quality. Integrating planning techniques within the multi-round paradigm could also provide global controllability for more complex tasks. In conclusion, the Self-controller represents a significant step towards building more controllable and self-aware LLMs, paving the way for more reliable and versatile applications in natural language processing."}]}