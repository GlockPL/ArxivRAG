{"title": "Label Dropout: Improved Deep Learning Echocardiography Segmentation Using Multiple Datasets With Domain Shift and Partial Labelling", "authors": ["Iman Islam", "Esther Puyol-Ant\u00f3n", "Bram Ruijsink", "Andrew J. Reader", "Andrew P. King"], "abstract": "Echocardiography (echo) is the first imaging modality used when assessing cardiac function. The measurement of functional biomarkers from echo relies upon the segmentation of cardiac structures and deep learning models have been proposed to automate the segmentation process. However, in order to translate these tools to widespread clinical use it is important that the segmentation models are robust to a wide variety of images (e.g. acquired from different scanners, by operators with different levels of expertise etc.). To achieve this level of robustness it is necessary that the models are trained with multiple diverse datasets. A significant challenge faced when training with multiple diverse datasets is the variation in label presence, i.e. the combined data are often partially-labelled. Adaptations of the cross entropy loss function have been proposed to deal with partially labelled data. In this paper we show that training naively with such a loss function and multiple diverse datasets can lead to a form of shortcut learning, where the model associates label presence with domain characteristics, leading to a drop in performance. To address this problem, we propose a novel label dropout scheme to break the link between domain characteristics and the presence or absence of labels. We demonstrate that label dropout improves echo segmentation Dice score by 62% and 25% on two cardiac structures when training using multiple diverse partially labelled datasets.", "sections": [{"title": "1 Introduction", "content": "Echocardiography (echo) is the first imaging examination carried out when assessing cardiac function. Based on segmentations of the cardiac structures from echo images, useful biomarkers can be extracted to measure the function of the heart for diagnosis and treatment management. Deep learning models have been proposed to automate this segmentation process [2,5,7,8,10,13], but for clinical translation it is important that such models are robust to the wide variation in image characteristics that will be encountered in the real world (e.g. different"}, {"title": "2 Materials and Methods", "content": "Datasets: Three publicly available 2D echo datasets were exploited in this work (see Table 1). CAMUS and EchoNet Dynamic contain images at end diastole (ED) and end systole (ES) for each subject. Unity Imaging does not provide information at the subject level. Upon manual review, several of the Unity Imaging segmentations were discarded due to the left ventricular myocardium (LVM) being overlabelled into the right ventricular myocardium. Therefore, we utilised 400 mostly apical 2-chamber images out of the 1504 available. The extraneous"}, {"title": "Baseline segmentation models:", "content": "A U-Net [11] was used as the baseline segmentation model. All models were trained using a stochastic gradient descent optimizer with a variable learning rate and a Nestorov momentum of 0.9 for 500 epochs. The initial learning rate and batch size was selected using a grid search and the model with the best foreground Dice score on the validation set was used for evaluation on the test set. Models were trained using two different loss functions. First, standard loss models were trained using a standard CCE loss function calculated over all classes including the background. Second, we trained adaptive loss models using the adaptive cross entropy loss proposed in [6]. This loss was implemented by removing the labels which are missing from the ground truth from the predicted segmentation, eliminating their contribution to the loss. Data augmentation was applied on the fly when training some models as specified in Section 3. The following augmentations were applied: scaling, rotation, Gaussian blur, brightness and contrast adjustment. The data were randomly split into 80%/10%/10% for the training, validation and test sets."}, {"title": "Label dropout:", "content": "As we will show in Section 3, a significant drop in performance of the adaptive loss model was observed when training with partially labelled datasets which have a domain shift between them. It was hypothesised that this was due to the model learning to associate domain specific characteristics with the presence of labels. Therefore, we propose the label dropout scheme, which aims to break the link between domain characteristics and the presence or absence of certain labels. In label dropout, we introduce a random probability of a label being removed (i.e. set to background) from the ground truth mask of each sample during training."}, {"title": "3 Experiments and Results", "content": "This section will detail a series of experiments which aim to illustrate the problem when training with multiple diverse partially labelled datasets, as well as the effectiveness of our proposed label dropout scheme in overcoming this problem."}, {"title": "Experiment 1 - The need for multiple diverse training datasets:", "content": "We first illustrate the need to train echo segmentation models using multiple diverse datasets. In this experiment we trained left ventricle (LV) segmentation models with data augmentation using each of the datasets previously described in Section 2. Each model was evaluated on each of the three datasets. Fig. 1 shows the test set Dice scores achieved for each evaluation. As can be seen, the models perform worse when tested on datasets they were not trained on. Therefore, training models using multiple diverse datasets is necessary to improve the generalisability of echo segmentation models."}, {"title": "Experiment 2 - Training using a combination of three diverse partially labelled echo datasets:", "content": "The purpose of this experiment was to illustrate the problem of using the standard loss model when training with diverse partially labelled datasets and explore if using the adaptive loss model would lead to satisfactory results. We again used all three datasets in this experiment but this time combined them into a single training dataset. Therefore, the training dataset was partially labelled and highly diverse including various cone shapes and sizes, intensity inhomogeneities within the cones and differing contrasts. Using these data, we trained three different models to segment the LV, LVM and LA: a standard loss model with augmentation and adaptive loss models with and without augmentation. Fig. 2 shows a representative sample of the"}, {"title": "Experiment 3 - Investigating the adaptive loss in a controlled experiment:", "content": "The purpose of this experiment was to further investigate our hypothesis that domain shift has led to shortcut learning in the adaptive loss model. Here, we investigate the viability of the adaptive loss model in a controlled environment, with no domain shift between the differently labelled samples. To achieve this, ground truth labels were artificially removed from a subset of samples from the CAMUS dataset. Three models were trained and evaluated. The first was a benchmark model viewed as the best achievable performance with no partial labelling, using a standard loss. Then, a standard loss model and an adaptive loss"}, {"title": "Experiment 4 - Label dropout:", "content": "Experiment 3 showed that the adaptive loss has the potential to deal with partially labelled training data, but it did not produce clinically acceptable segmentations in Experiment 2 when there were domain shifts between the differently labelled datasets. In this experiment, the utility of our proposed label dropout scheme in addressing this problem is explored. Two datasets were used in the first part of this experiment: CAMUS and Unity Imaging. The LA was artificially removed in all Unity Imaging ground truth masks in the training set to produce a combined training set with partial labels and a domain shift. Two types of model were trained: adaptive loss models with label dropout using the partially labelled data, and a benchmark model with a standard loss and fully labelled data, which represents the best achievable performance. For the label dropout model, different probabilities for label dropout ranging from 0.0 to 1.0 in steps of 0.1 were tested. This is the probability of the LA being dropped out from the ground-truth segmentation for each training pair during training. Augmentation was used for training all models in this experiment."}, {"title": "4 Discussion and Conclusion", "content": "This paper has made two significant contributions: (i) we have highlighted for the first time that state-of-the-art approaches for dealing with partially labelled segmentation data can be negatively affected by a form of shortcut learning when trained with datasets featuring domain shift, (ii) we have proposed a new label dropout technique for dealing with this problem. For contribution (i), we note that the adaptive loss that we employed to deal with the partially labelled data was shown to work effectively in an experimental environment with no domain shift (Experiment 3) and has previously been shown to be effective when there was domain shift but no relationship between domain characteristics and label presence (e.g. occasionally missing LVM at ES in cine cardiac magnetic resonance [6]). Thus, we conclude that its poorer performance in Experiment 2 was due to the presence of such a relationship. For contribution (ii), label dropout was shown to improve model performance in Experiment 4. It is noticeable that the Dice score for the label dropout scheme plateaus when the label dropout is introduced. We speculate that this could be because, after a certain number of epochs, the model eventually sees all images with all labels.\nWe believe that this work is important for training robust segmentation models. When combining multiple diverse echocardiography segmentation datasets, the resulting training datasets are typically partially labelled and therefore this technique could allow the training of more generalisable models.\nFurther work will include investigating the impact of label dropout on different network architectures, such as transformers [1], as well as alternative strategies for dealing with partial labels, such as the marginal loss [12]. Furthermore,"}]}