{"title": "Sybil Detection using Graph Neural Networks*", "authors": ["Stuart Heeb", "Andreas Plesner", "Roger Wattenhofer"], "abstract": "This paper presents SYBILGAT, a novel approach to Sybil detection in social networks using Graph Attention Networks (GATs). Traditional methods for Sybil detection primarily leverage structural properties of networks; however, they tend to struggle with a large number of attack edges and are often unable to simultaneously utilize both known Sybil and honest nodes. Our proposed method addresses these limitations by dynamically assigning attention weights to different nodes during aggregations, enhancing detection performance. We conducted extensive experiments in various scenarios, including pretraining in sampled subgraphs, synthetic networks, and networks under targeted attacks. The results show that SYBILGAT significantly outperforms the state-of-the-art algorithms, particularly in scenarios with high attack complexity and when the number of attack edges increases. Our approach shows robust performance across different network models and sizes, even as the detection task becomes more challenging. We successfully applied the model to a real-world Twitter graph with more than 269k nodes and 6.8M edges. The flexibility and generalizability of SYBILGAT make it a promising tool to defend against Sybil attacks in online social networks with only structural information.", "sections": [{"title": "1 Introduction", "content": "Online social networks have become a central part of modern digital life, connecting billions of users worldwide. However, their open nature and vast scale make them vulnerable to various security threats, with Sybil attacks being a prevalent and challenging attack to detect. In Sybil attacks, malicious entities create fake accounts to manipulate the network, spread misinformation, or gain undue influence. Thus, detecting Sybil accounts is crucial for maintaining the integrity and trustworthiness of social networks. Effective Sybil detection can prevent the spread of fake news, protect users from scams, and ensure a fair distribution of resources and influence within the network. However, as attackers become more sophisticated, traditional detection methods increasingly fail to perform their task.\nThe rise of modern generative AI has allowed the creation of user features, images, and texts that closely mimic genuine human activity, leaving the structural features of networks as the most reliable indicators for Sybil detection. Although current approaches, such as random walks and loopy belief propagation, have demonstrated effectiveness, they also exhibit significant drawbacks. These techniques often suffer from issues like label noise, inability to concurrently leverage information from both known Sybil and honest nodes, and vulnerability to sophisticated attack strategies.\nIn recent years, Graph Neural Networks (GNNs) have emerged as a powerful tool for learning on graph-structured data. GNNs can capture complex patterns and relationships within networks, making them a promising approach to Sybil detection. However, their application to this specific security challenge remains underexplored. In this work, we introduce SYBILGAT, a novel approach to Sybil detection that leverages Graph Attention Networks (GATs), a specific type of GNN. SYBILGAT addresses the limitations of existing methods by dynamically assigning attention weights to different nodes during the aggregation process, allowing it to focus on the most relevant information for detection. We have conducted extensive experiments to evaluate the performance of SYBILGAT in various scenarios. These include pre-training on sampled subgraphs, testing on synthetic networks of different sizes and structures, and assessing robustness against targeted attacks. Our experiments use real-world datasets, such as Twitter and Facebook networks, and synthetically generated graphs based on well-known models such as Barab\u00e1si-Albert and Power law graphs.\nThe results show that SYBILGAT significantly outperforms the state-of-the-art algorithms, particularly in scenarios with high attack complexity and many attack edges. Our approach shows robust performance across different network models and sizes, even as the detection task becomes more challenging."}, {"title": "2 Related Work", "content": "Structure-based methods The majority of previous work considered for this research were structure-based methods, meaning that the only features available for Sybil detection are the graph structure and a set of known (honest and Sybil) nodes. Many methods heavily use the homophily assumption, which states that nodes connected by an edge tend to share the same label. Based on this assumption, the labels of a few known nodes are propagated through the social network. This is generally done using random walks (RW) or loopy belief propagation (LBP).\nSYBILGUARD and SYBILLIMIT assume that it is more likely for a random walk starting from a known honest node to reach other honest nodes than Sybil nodes, and vice versa. They use the same length of random walks for all nodes. While SYBILGUARD accepts $O(n\\log n)$ Sybils per attack edge, it suffers from a high false-negative rate (FNR). The improved algorithm SYBILLIMIT reduces the number of accepted Sybils per attack edge to $O(\\log n)$ while allowing more attack edges.\nSYBILINFER is a centralized random walk procedure that uses a probabilistic model via Bayesian inference. This allows the algorithm to assign a degree of certainty besides just classifying the nodes.\nSYBILRANK uses early-stopping random walks to propagate trust scores rooting from a set of known honest nodes based on the assumption that the honest region of the network is fast-mixing. The trust scores are degree-normalized and ranked, allowing classification with a threshold value. All security guarantees outlined in the paper are based on the assumption that the attack edges are randomly established between honest and Sybil nodes.\nExisting random walk methods have the disadvantage that they can only leverage known honest nodes or known Sybil nodes, but not both simultaneously. They also tend to lack robustness to label noise in the set of known nodes.\nSYBILBELIEF utilizes a set of known honest nodes and, optionally, a set of known Sybil nodes to perform classification. Accounting for prior probabilities, the algorithm uses LBP to infer the posterior probabilities of nodes being Sybil.\nSYBILSCAR aims to combine the approaches of random walks and LBP by introducing a novel local update rule which is applied iteratively for a given number of iterations or until convergence. The algorithm has two variants: SYBILSCAR-C assumes constant homophily between any two nodes, and takes a parameter specifying this. Setting this parameter, however, usually requires some analysis of the full graph. The other variant is SYBILSCAR-D which computes homophily for each edge individually.\nSYBILHP was developed for directed social networks and uses LBP combined with a homophily estimator to classify the nodes. It is designed to overcome the limitation many algorithms have of implicitly assuming constant homophily, which doesn't account for the directional nature of some social trust relationships.\nApproaches based on LBP can incorporate knowledge about both known honest and known Sybil nodes simultaneously and tend to be more robust to label noise.\nFeature-augmented methods Increasingly, there has been research that uses features in addition to the graph structure to perform a more accurate classification.\nTRUSTGCN leverages graph convolutional networks (GCNs) to classify nodes using a two-stage process: trust propagation (via random walks) and trust-guided graph convolution. BOTRGCN is a Twitter bot detection algorithm that leverages different possible kinds of edges in a social network by applying a relational graph convolutional network (RGCN).\nSATAR is a self-supervised representation learning framework for Twitter bot detection. It aims to adapt better to different types of social media bots and is proven to generalize in real-world scenarios.\nEarly Sybil detection Some methods specialize in early Sybil detection, using additional information about friend request targets and responses, along with the network topology. The motivation for these methods is the prevention of Sybils in the network, not just their detection after they have established themselves, aiming to avoid the negative effects they have on the network. SYBILEDGE aggregates over these features, giving more weight to the request targets that are preferred by other Sybil nodes (in contrast to honest nodes) while considering how these friend request targets respond. PREATTACK uses initial friend request behaviors to perform classification by approximating the posterior probability that a new node is Sybil or not under their proposed multi-class Perferential Attachment model for unanswered friend requests. PREATTACK can successfully (AUC \u2248 0.9) detect Sybil nodes before any edges have been actualized (that is, friend requests have been accepted)."}, {"title": "3 Methodology", "content": "3.1 Problem Definition\nGiven a social network $G = (V, E)$, which consists of honest (negative) nodes $H$ and Sybil\u00b9 (positive) nodes $S$, and small subsets of known nodes $(H_{train}, S_{train})$, we want to perform the Sybil classification. The size of the training (known) nodes is assumed, unless otherwise mentioned, to be 5% of the respective original node set size.\nThe edges of these social networks are assumed to be some kind of trust relationship and can be directed or undirected. Since, due to the nature of the available underlying data or for other reasons, much of the previous work focuses on the evaluation of undirected graphs. We will follow suit in this. Note that a directed network can be transformed into an undirected one by either keeping all edges or only the bidirectional ones while losing the information that the directedness might have implied. Although the edges represent trust relationships, the edges between the honest and"}, {"title": "3.2 Social Network Synthetization", "content": "Due to limited access to labeled social network datasets, previous research resorted to evaluating (and developing) their algorithm on synthesized social networks. We will adopt the methods and parameters from related research.\nThe general approach assumes that social networks consist of honest and Sybil regions. Following previous research, and to allow proper comparison, we will assume that there is one of each region, but this approach can be generalized to allow multiple regions.\nWe construct a synthetic social network as follows: We take as honest and Sybil regions real-world social network graphs or synthesized graphs (Section 3.2). These regions are assumed to be tightly connected within and are connected by a certain number of attack edges. We measure the number of attack edges in the unit of attack edges per Sybil, that is, the average number of edges that cross over the regions per Sybil. Of course, the more attack edges there are, the harder the problem becomes, since then the regions no longer present themselves as tightly connected as they initially were and start to \"blend\" with one another (e.g., the Sybils can \"convince\" many honest nodes to engage in trust relationships with them, making themselves appear more honest according to the homophily assumption). Increasing the number of attack edges is a common way to make the problem harder and can show distinguishable performance differences between algorithms.\nThis methodology for social network synthetization is prevalent in most previous research in structure-based Sybil detection.\nSynthetic Regions The following synthetic models were chosen for our evaluation. These models are used in related works, and the parameters were inspired by previous research in conjunction with the analysis of real social networks.\nBarab\u00e1si-Albert (BA) Model Barab\u00e1si-Albert (BA) model generator creates a graph of n nodes by attaching new nodes (with $m \\in \\{1, ..., n\\}$ edges each) that are preferentially attached to existing nodes with high degree (Barab\u00e1si and Albert 1999). Our standard parameter configuration is $(n, m) = (., 6)$.\nPower law (PL) Model The Power law (PL) graph generator is an algorithm for generating graphs with power law distributed degrees, and approximate average clustering (Holme and Kim 2002). The parameters of this random graph generator are n (the number of nodes), $m \\in \\{1,..., n\\}$ (the number of random edges to add for each node), and $p\\in [0,1]$ (probability of adding a triangle after adding a random edge). Unless otherwise mentioned, these parameters are set to $(n, m,p) = (\\cdot, 6, 0.8)$. This is equivalent to the BA model, but with the added chance (controlled by p) that a newly added random edge is closed to form a triangle (Barab\u00e1si and Albert 1999). A graph generated with the PL model may be disconnected (but this did not happen in our experiments).\nAttack Edge Placement The placement of these synthesized attack edges can be performed with two general strategies: random or targeted. The attack edges $E_T$ are placed between honest and Sybil (sub)sets, $T_H \\subseteq H$ and $T_S \\subseteq S$.\nRandom attack edges These edges are placed uniformly at random between nodes of the honest and Sybil target sets, which are set to $T_H = H$ and $T_S = S."}, {"title": "3.3 Graph Neural Network Model", "content": "Our evaluation of the feasibility of using Graph Neural Networks (GNNs) to detect Sybils in online social networks involved different GNN architectures.\nGraph Convolutional Networks (GCNs) aggregate node neighbors, and feed the aggregated features through a traditional neural network, which are then taken as the features in the next layer (Kipf and Welling 2016). The parameters of this neural network make up the parameters of the GNN, where each edge is treated equally. The values are propagated through the layers of the network. Using GCNs to perform Sybil detection can keep up with many of the compared baselines, but does not consistently outperform them.\nRelational Graph Convolutional Networks (RGCNs) are potentially interesting for Sybil detection, as they allow the specification of different types of edges, and learn parameters according to this distinction (Schlichtkrull et al. 2017). This could be beneficial for targeted attacks, where the different types of edges could play a more significant role. When choosing the types of edges to be the different possible combinations between known honest and Sybil nodes, and unknown nodes, the RGCN performs well in a targeted attack setting. However, when the attack edges are predominantly random, the RGCN's performance is much worse.\nGraph Attention Networks (GATs) introduce an attention mechanism to assign different weights to different nodes in the neighborhood (Veli\u010dkovi\u0107 et al. 2018). This can allow the model to focus on certain nodes during aggregations. The attention mechanism operates over neighborhoods, and unlike in \"vanilla\u201d GNNs which have globally learned weights, GATs assign different, learnable weights to neighbors dynamically, which might be interesting to Sybil detection where some nodes (Sybils) disrupt the network by infiltrating it with attack edges. This approach works well and is the basis of our algorithm, presented in Section 3.4.\nWhy GNNs for Sybil Detection? Among previous work on structure-based Sybil detection, there is a common trend of using approaches based on random walks (RW) and loopy belief propagation (LBP). These methods constitute the current state-of-the-art for this problem. Due to the nature of GNNs, they should - at least in theory - be just as powerful as LBP or RWs. The motivation for using GNNs for Sybil detection is not only this potential theoretical superiority, but it also presents the opportunity to no longer have to rigorously analyze different graphs to arrive at an algorithm design that might apply to only certain scenarios but to design and test different GNN architectures that can self-adapt taking out the guesswork while generalizing well.\nPre-training on Smaller Graphs The main mechanism used in this work to perform Sybil detection with GNNs is to run the algorithm on a known small network graph (e.g., a sampled subgraph of the social network graph of interest), and then apply the model to a larger network graph, where only a small number of nodes are known (e.g., the remaining network graph after said subsampling). The performance is then evaluated solely on the evaluation network graph. We will consider the evaluation network to be disjunct from the initial pre-training network, to make for a more realistic setting and more fair evaluation.\nTransductive Learning Another way Sybil detection can be performed on social network graphs using GNNs is through transductive learning. In this setting, the GNN algorithm does not perform separate pre-training, but runs on the social network graph of interest directly, with a small set of known (train) nodes, and concludes by predicting labels for all nodes of the graph. The prediction is then evaluated on the set of unknown (test) nodes. We will focus on the aforementioned pretraining approach, and only use transductive learning in Section 4.5."}, {"title": "3.4 SYBILGAT: Detecting Sybils with GATs", "content": "In this work, we present SYBILGAT, a GNN algorithm for Sybil detection based on the GATConv layer (Veli\u010dkovi\u0107 et al. 2018).\nModel Parameters The model itself consists of the following hyperparameters: input width, hidden width, output width (number of classes), number of attention heads, and number of layers (the depth). The input width can be either 1 (representing \u201cSybil-ness\") or 2 (a channel for honest and one for Sybil), where we found the former to be conceptually simpler and at least as effective. The hidden width and number of heads are hyperparameters that can be heavily experimented with. We ended up with a robust evaluation by taking both the hidden width and the number of heads as 4. Like the input, the output width can be 1 or 2. The output is then used for prediction depending on some threshold. The number of layers dictates how far into the network layers are aggregated, and an optimal value depends on the structure of the network.\nModel Architecture Suppose the model has parameters $I$ for input width, $H$ for hidden width, $O$ for output width, $N$ for number of heads, and $L$ layers. The first layer is a GATConv layer with $I$ input units and $H$ output units, with $N$ heads. The intermediate layers have $H \\cdot N$ input units, $H$ output units, and $N$ heads. The last layer has $H \\cdot N$ input units, $O$ output units, and 1 head. Before each layer, there is a dropout layer with a probability of 0.5. After each layer, there is a tanh activation layer. After the last layer, there is a sigmoid ($O = 1$) or softmax ($O = 2$) activation function.\nTraining Procedure with Early Stopping Initially, the training set of known nodes is split into an actual training set and a validation set used for early stopping with a specifiable patience parameter. By default, the train/validation split is 0.8/0.2 for the training phase and 0.9/0.1 for the inference (prediction) phase. A set of known labels are used as inputs (depending on the input width) and fed through the network. The predictions made by the model are compared with the ground-truth label output of the known nodes. To this, a loss function is applied, and an optimizer performs the backward step. In our experiments, we used the binary cross entropy loss for ($O = 1$), the cross entropy loss ($O = 2$), and the Adam optimizer. If there has been no improvement in validation loss for the last epochs (specified by the patience parameter), the training process is stopped and the best model (according to validation loss) is retrieved for prediction. The predictions are then evaluated in terms of some metric on the test set (the remaining nodes).\nPrediction Threshold Estimation During inference and before prediction, a threshold value is computed. This is done using the 10% of known nodes in the validation set, as mentioned above. The optimal threshold is computed for the validation set and this estimate is used for prediction."}, {"title": "3.5 Sampling Subgraphs of Social Networks", "content": "The sampling method used in the evaluation is the Forest Fire sampling method (Leskovec, Kleinberg, and Falout-sos 2005; Leskovec and Faloutsos 2006). It implements a stochastic snowball sampling method with a specifiable burning probability that is proportional to the expansion (Rozemberczki, Kiss, and Sarkar 2020)."}, {"title": "4 Experimental Results", "content": "4.1 Setup\nDatasets The Twitter dataset is a real-world social network graph consisting of 269'640 nodes and 6'818'501 edges. The nodes represent users, and the directed edges represent the \"following\u201d relationship. Before evaluation, this graph is transformed into an undirected graph. This dataset was sampled and processed (Lu et al. 2023) from a previously much larger crawled graph (Kwak et al. 2010). Initially, the Twitter API was used to crawl the graph and then, retroactively and repeatedly over the past few years, determine which accounts were honest or Sybil accounts by querying their account status.\nThe Facebook graph (Leskovec and Mcauley 2012; Leskovec and Krevl 2014) from SNAP10 is an undirected, unlabeled social network graph with 4'039 nodes and 88'234 edges. The dataset is a friendship network from Facebook, where the nodes are users and the edges are friendships between the users. Following previous research , we will be using this graph as regions of a synthesized social network. Since this graph is very highly connected, the synthesized network is created with a high number of attack edges (in our evaluation, 20 attack edges per Sybil).\nIn the following experiments, we will use both these two real-world data sets (either directly or as real regions), as well as fully synthesized social networks (cf. Section 3.2).\nBaseline Algorithms From the list of previous research that study Sybil detection using only the network structure (Cf. problem definition in Section 3.1) we narrowed our baselines to three algorithms which have consistently been used as baselines: SYBILRANK, SYBILBELIEF and SYBILSCAR. The latter is used in its D variant due to its flexibility and the lack of need for analysis of the full graph, as described in Section 2. SYBILSCAR, the most recent of them, consistently outperforms the other baseline algorithms and is more robust in different evaluation scenarios. For this reason, it is our main baseline and is used for the first three experiments. A comparison between all baseline algorithms with varying numbers of attack edges can be found in Experiment 4 in Section 4.5. Full tables for all experiments with results for all algorithms can be found in the appendix. For the implementation of SYBILSCAR, we used the matrix-form algorithm described by the authors and optimized its runtime by using sparse matrix operations (allowing it to run in matrix form when evaluating large graphs such as the Twitter network). We tested against the public C++ code by the authors, and our implementation performed equally (up to numerical differences, and sometimes better) to the comparison. Due to this, we used our implementation."}, {"title": "Experiments", "content": "In the following four sections, we will present the results of our experiments:\n1. Pre-training on Sampled Subgraph (Section 4.2)\n2. Pre-training on Small Synthetic Network (Section 4.3)\n3. Attacking after Pre-training (Section 4.4)\n4. General Robustness Baseline Comparison (Section 4.5)\nEach experiment is performed five times, and the mean is calculated. The performance metric we will focus on is the AUC (Area under the ROC curve) score. For most experiments, we will evaluate three instances of SYBILGAT: a shallow, intermediate, and deep model with 2, 4, and 8 layers, respectively."}, {"title": "4.2 Experiment 1: Pre-training on Sampled Subgraph", "content": "Using the sampling method described above, we will produce a subgraph of a social network, which will be used by SYBILGAT for pretraining. The evaluation (prediction) will then be performed exclusively on the remaining graph.\nFor all experiments, the size of the subgraph is 10% of the initial graph, except for the Twitter graph, where it is 5%. The training set for the Twitter graph is 11.2% (honest) and 10.9% (Sybil) of the respective total sizes.\nReal Twitter Dataset Using the Twitter dataset introduced above, we evaluated the performance of SYBILGAT by training on a subset of the graph using the forest fire sampling method. The results seen in Table 2 show that the best SYBILGAT instance performs up to 5%-points better than SYBILSCAR.\nSynthesized Social Network with Real Honest and Sybil Regions Here, we used the Facebook graph as the honest and Sybil regions of the graph and added 20 (random) attack edges per Sybil to create the network. The two strategies used are random placement, and targeted placement with attack probability $p_T = 0.1$ and discrete target hit distance PDF $p = \\frac{1}{4}$.\nThe results in Table 2 show superior results for the shallow version SYBILGAT-L2. The deep model of SYBILGAT performs very poorly, most likely due to the high average degree of the Facebook graph, omitting the need for propagating values very far through the network, essentially rendering the deep model too complex.\nFully Synthesized Network For the fully synthesized network we evaluate two sizes of networks: 10'000 nodes and 50'000 nodes. Both networks are created with the power law model with parameters m = 5 and p = 0.8, and 8 (random) attack edges are added per Sybil.\nThe results in Table 3 indicate that SYBILGAT-L4 achieves the highest score in both inspected networks. Also, given that both networks produce almost identical scores for each algorithm, the network size is not a relevant factor given a certain synthetization scheme."}, {"title": "4.3 Experiment 2: Pre-training on a Smaller Synthetic Social Network", "content": "In this experiment, instead of pre-training on an actual subgraph of a large network, SYBILGAT is pre-trained on a smaller version of the synthesized network before being applied to a larger network with the same underlying model (exception is the last case, where we apply it to a network synthesized using the Facebook graph-a scenario we consider useful and close to the real world).\nThree cases were evaluated: the synthetic models Barab\u00e1si-Albert (BA) and power law (PL), and pre-training on a small synthesized power law network before applying to a synthesized network with the Facebook graph as real regions (PL-FB). In each experiment, the small network consists of 2000 nodes, and the large network consists of 20'000 nodes (except the Facebook network, where the size is given by the underlying real graph-namely 8'078 nodes). The network is filled with 8 attack edges per Sybil (20 for the Facebook evaluation), either randomly or targeted ($p_T = 0.1$, $p = \\frac{1}{4}$.\nThe results in Table 4 show that for the Barab\u00e1si-Albert model, SYBILGAT-L8 outperforms the other algorithms notably. In the power law model, all SYBILGAT instances are very similar in performance while significantly outperforming SYBILSCAR. In the last experiment, which evaluates the synthesized Facebook network, SYBILGAT-L2 achieves the highest, while the deep model performs very poorly for the same reason as mentioned above."}, {"title": "4.4 Experiment 3: Attacking the Social Network after Pre-training", "content": "In this experiment, SYBILGAT is pre-trained on a social network that was attacked with 8 random attack edges per Sybil (20 for the Facebook evaluation). It is then evaluated on a social network consisting of identical honest and Sybil regions, but attacked with 8 attack edges per Sybil (20 for the Facebook evaluation) following the targeted attack parameters $p_T = 0.2$ (20% of attack edges will be targeted, the rest will be random) and the discrete target hit distance PDF $p = [\\frac{1}{2}, \\frac{1}{2}]$ (half of all targeted edges will hit a known node directly, the other half will hit a neighbor). The sizes of the social networks (except for the one involving the Facebook graph) are 2000 nodes.\nSynthesized Network with Real Honest and Sybil Regions In this experiment, the Facebook graph was used as the honest and Sybil region. Table 5 shows, similarly to Table 2 (which also inspected the Facebook network), that SYBILGAT-L2 outperforms the other algorithms. As described previously, SYBILGAT-L8 performs very poorly.\nFully Synthesized Network In this part, the two random graph models Barab\u00e1si-Albert (BA) and power law (PL) were used to generate synthetic social networks. The scores in Table 6 show that in the BA model, SYBILGAT-L8 significantly outperforms SYBILSCAR. Using the PL model SYBILGAT-L4 has the best score."}, {"title": "4.5 Experiment 4: General Robustness Evaluation", "content": "We evaluate the general robustness of the algorithms, including SYBILRANK and SYBILBELIEF. The experiment is set up as follows: Synthetic social networks are created using the Barab\u00e1si\u2013Albert (BA) and power law (PL) models to have a size of 2000 nodes. The number of attack edges per Sybil ranges from 1 to 12, which represents an increasing difficulty of the problem given random attack edges.\nFigure 1 shows the AUC score of the inspected algorithms while increasing the attack edges per Sybil. The plots show clearly that, with increasing attack edges per Sybil, the SYBILGAT algorithms outperform the baselines, especially when the problem gets very hard."}, {"title": "5 Conclusion", "content": "This paper introduced SYBILGAT, a novel approach for Sybil detection using Graph Attention Networks. Our experiments demonstrated that SYBILGAT consistently outperforms the state-of-the-art algorithms in various types of networks and attack scenarios. Key findings include superior performance on both real-world and synthetic datasets, effective pre-training on smaller networks for application to larger ones, and maintained performance under targeted attacks. We show that the method can be applied to a real-world graph from Twitter with 269k nodes and 6.8M edges.\nThe robust performance of SYBILGAT, especially as the complexity of the attacks increases, represents a significant advancement in the security of social networks. However, limitations exist: The depth of the optimal model varies with network structures, and its scalability to larger networks and robustness against adversarial attacks remains to be fully explored. These challenges indicate the need for adaptive architectures and further investigation of the performance of SYBILGAT on dynamic networks.\nSYBILGAT's success opens new avenues for applying graph learning techniques to network security challenges. Future work could address the identified limitations, explore larger-scale networks, focus on gathering more real-world data for testing, and investigate why different network structures result in different optimal numbers of layers. Overall, SYBILGAT offers a promising tool for maintaining the integrity of social networks in the face of evolving Sybil threats that depend solely on the network structure."}]}