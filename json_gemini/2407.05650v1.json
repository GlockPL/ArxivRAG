{"title": "Weight Initialization", "authors": ["Pascal J. Sager", "Jan M. Deriu", "Benjamin F. Grewe", "Thilo Stadelmann", "Christoph von der Malsburg"], "abstract": "We present a novel intelligent-system architecture called \"Dynamic Net Architecture\" (DNA) that\nrelies on recurrence-stabilized networks and discuss it in application to vision. Our architecture models\na (cerebral cortical) area wherein elementary feature neurons encode details of visual structures, and\ncoherent nets of such neurons model holistic object structures. By interpreting smaller or larger\ncoherent pieces of an area network as complex features, our model encodes hierarchical feature\nrepresentations essentially different than artificial neural networks (ANNs).\nDNA models operate on a dynamic connectionism principle, wherein neural activations stemming\nfrom initial afferent signals undergo stabilization through a self-organizing mechanism facilitated\nby Hebbian plasticity alongside periodically tightening inhibition. In contrast to ANNs, which rely\non feed-forward connections and backpropagation of error, we posit that this processing paradigm\nleads to highly robust representations, as by employing dynamic lateral connections, irrelevant details\nin neural activations are filtered out, freeing further processing steps from distracting noise and\npremature decisions.\nWe empirically demonstrate the viability of the DNA by composing line fragments into longer lines\nand show that the construction of nets representing lines remains robust even with the introduction\nof up to 59% noise at each spatial location. Furthermore, we demonstrate the model's capability to\nreconstruct anticipated features from partially obscured inputs and that it can generalize to patterns\nnot observed during training. In this work, we limit the DNA to one cortical area and focus on its\ninternals while providing insights into a standalone area's strengths and shortcomings. Additionally,\nwe provide an outlook on how future work can implement invariant object recognition by combining\nmultiple areas.", "sections": [{"title": "Introduction", "content": "We present the first implementation of a novel intelligent-system architecture called \u201cDynamic Net Architecture\u201d (DNA).\nWe motivate it here by contrasting it to the architectures of artificial neural networks (ANNs) that play an essential\nrole in analyzing high-dimensional data (LeCun et al., 2015; Schmidhuber, 2015; Stadelmann et al., 2018). An ANN\nis a static, deeply nested function optimized with respect to a static cost function. An input to an ANN is mapped to\nan output by a succession of nested functions arranged in layers. Consequently, representations have the form of a\nhierarchy that integrates simpler low-level features (outputs of inner functions) to more complex high-level features\n(outputs of outer functions). The representations computed by the inner functions are independent of the outputs of\nouter functions. We posit that this is one of the leading causes of the lack of robustness witnessed in ANNs (Windrim\net al., 2016; Li et al., 2019; Wang et al., 2019; Rusak et al., 2020; Drenkow et al., 2022) since the decisions of inner\nfunctions cannot be adjusted by plausibility checks based on outer functions. This assertion finds support in the formal\nexplanation provided by Goodfellow et al. (2015), who argue that adversarial attacks rely on perturbations below the\nthreshold of visibility when these are summed over a sufficiently high input dimensionality (cf. Ilyas et al. 2019).\nFollowing Marr (2010), we call this phenomenon of lacking robustness due to sequential information processing \u201cthe\nfallacy of early commitment,\u201d i.e., the inability to factor the outputs of the outer functions (high-level features) into\nthe computation of the inner functions (low-level features), so that low-level decisions are in danger of misleading\nhigh-level decisions.\nWith the proposed DNA, we overcome this limitation by dynamically integrating local and global features. The DNA is\nformulated in terms of cortical areas (two-dimensional sheets of neurons) and projections between them. Connectivity\nwithin areas is dominated by short-range lateral (\u201crecurrent\u201d) connections, different areas are connected bidirectionally.\nThe neurons of a given area are elementary feature detectors. Afferent connections from a given input pattern activate a\nfraction of all neurons in the area. Cyclically rising inhibition then silences the majority of the initially activated neurons,\nleaving only those active that are supporting each other with sufficient strength through excitatory lateral connections.\nThis mutual support can only be realized within specifically structured consistent networks, \u201cnets\u201d (von der Malsburg,\n2018) and have to be generated by statistical learning. Nets can span the entire visual field and connect feature neurons\nthat are spatially distant through chains of locally connected intermediary neurons. Nets are flexibly composed of \"net\nfragments\" that correspond to often-occurring feature constellations. Each position of an area contains many fragments\n(analogous to the code-book of image compression schemes, Taubman and Marcellin (2002)) from which the input can\nchoose. Unlike the pieces of a jigsaw puzzle, each net fragment fits to a choice of possible neighboring fragments (and\neach neuron can be part of several net fragments), so that a virtually infinite number of nets can be formed from a finite\nset of neurons and net fragments.\nAccording to this principle, a two-phase process admits first a transient initial volley of activity, while in a second\nphase, most of this activity is silenced so that only mutually supporting neurons stay active. What is responding to the\ninput of a cortical area are thus not individual neurons but rather organized nets. From Gestalt psychology (Wertheimer\net al., 1938; K\u00f6hler, 1992), we know the visual system can rapidly discern holistic structures, that is, recognize global\npatterns as arrays of local features that conform consistently to certain \"local Gestalt rules\u201d K\u00f6hler (1992): from all\nthe local features present in the input, only those are selected by the visual system that fit consistently into a coherent\nglobal pattern (coherent in the sense of being composed throughout of overlapping fragments). Thus, local decisions are\nconditioned on global patterns, whereas global patterns need for their constitution local features. We offer our nets of\nlateral connections as the mechanism that mediates between local and global levels: local Gestalt rules are implemented\nby net fragments, and as long as an input pattern can be covered throughout by fragments, the response it elicits is a\ncoherent net.\nThe two-phase process described is able to remove noise and filter out irrelevant details. It thus avoids the fallacy\nof early commitment by conditioning neuron activation on integrability into a globally consistent net. An additional\neffect is that neurons that aren't receiving afferent input but have sufficient lateral support might get activated, thus\ncomplementing figures or textures and allowing the interpretation of occluded objects.\nThe connectivity necessary for stable second-phase activity is very specific and needs to be generated by learning. The\ngoal is to find and stabilize those patterns of afferent activation that stand out statistically. This is possible with the\nhelp of Hebbian plasticity (Hebb, 1949) that strengthens short-range excitatory connections between neurons often\nco-activated by the input. In the initial stages of learning, before the establishment of supporting connections, learning\nhas to rely on phase one activity, that is, on the actual statistics of input activation. In the course of learning, however,\nplasticity has to be biased more and more in favor of those neurons that stand out by lateral support, neurons whose\nactivity survives into phase two.\nHow do our cortical areas compare to the layers of ANNs? Whereas the latter are mainly there to accommodate a\nhierarchy of feature detectors of higher and higher complexity, already a single cortical area provides for such hierarchy"}, {"title": "Related Work", "content": "As outlined above, deep neural networks exhibit a deficiency in robustness. In the scientific literature, robustness is\ntypically defined as immunity to noise (additive noise, or subtractive noise in the form of missing information; see Cao\net al. (2021); Neururer et al. (2024)) and adversarial attacks (Drenkow et al., 2022), as well as the capability of dealing\nwith ambiguous inputs (Simmler et al., 2021) and generalization within/across domains (e.g., over image translation,\nrotation, changing lighting, etc.).\nThis work focuses on analyzing net fragments that are formed in each DNA-based area concerning their robustness\nto small perturbations. Related work pertaining to this aspect is summarized in Section 2.1, followed by a review\nof representation learning. The subsequent Section 2.3 examines systems utilizing correspondence-based mapping,\nwhich can cope well with ambiguous inputs and exhibit good generalization capabilities. These systems closely align\nconceptually with the DNA proposed in this work, making them highly relevant for future research, especially for\nscaling to a multi-area DNA."}, {"title": "Robustness to Noise", "content": "Adversarial attacks exploit deep networks' vulnerability to noise by calculating slight perturbations capable of altering\nthe model's predictions for specific samples (Szegedy et al., 2014; Goodfellow et al., 2015; Papernot et al., 2016a;\nCarlini and Wagner; Deriu et al., 2022) or perturbations applicable across the entire dataset (Moosavi-Dezfooli et al.,\n2017). Adversarial attacks can also be devised without direct access to the model and its parameters, for example, by\nanalyzing a model's decision boundary (Brendel et al., 2018; Engstrom et al., 2019) or training an auxiliary model\n(Chen et al., 2017; Cisse et al., 2017; Sarkar et al., 2017).\nCurrent approaches aim to counter these attacks by modifying the network's architecture to increase robustness\n(Papernot et al., 2016b; Gao et al., 2017; Ros and Doshi-Velez, 2018), including adversarial examples to the training"}, {"title": "Representation Learning", "content": "Other research relevant to this work employs other design principles to enhance robustness. A crucial principle involves\nsparse neural activation, which enhances robustness relative to dense representations, as shown for deep neural networks\n(Guo et al., 2018; Liao et al., 2022; Timpl et al., 2022; Prince, 2023). This is particularly true for binary sparse\ndistributions (Ahmad and Scheinkman, 2019). Element-wise comparison of two vectors, each with only a few activated\nneurons, proves to be highly robust. Given sufficiently large vector dimensionality, accidental similarity across different\nbinary sparse representations is highly improbable (Ahmad and Hawkins, 2015).\nAlso in this work, we exploit binary sparse representations to bolster model robustness. In our system, sparsity is not\nimposed by specific constraints but by design along established principles, including lateral connections (Kothari and\nAgyepong, 1996; Corchado et al., 2003) and self-organization through local Hebbian updates (Hebb, 1949), coupled\nwith inhibitory mechanisms for activity regulation (Abbott and Nelson, 2000; Luz and Shamir, 2012)."}, {"title": "Correspondence-Based Mapping", "content": "A highly robust vision framework for object detection is based on correspondence mapping between pixel patterns\nwithin an image and a corresponding prototype (Wolfrum et al., 2008). Here, \u201ccorresponding\" refers to neurons\nrelating to the same point on the object's surface. A pivotal concept in this framework are maps implemented as sets of\nprojection fibers (connections that dynamically turn on and off) known as shifter circuits (Anderson and van Essen,\n1987; Olshausen et al., 1993) that are composed of maplets (Zhu and von der Malsburg, 2004). These maps are activated\nwhen point-to-point correlations are detected between coherent nets in two cortical areas. The composite nets in the two\ncortical areas explicitly represent spatial relations, and a map between them can only be formed if they agree on this\nspatial structure. Once a forward mapping to a coherent model of a visual pattern is established, backward mapping to\nthe primary visual domain can stabilize the modeled structure there by complementing missing elements or by lacking\nto support visual noise elements.\nSo far, correspondence-based mapping has been applied only to human face detection and identification (Lades et al.,\n1993; Wolfrum et al., 2008; Fernandes and von der Malsburg, 2015), in which image and object model match with little\ndeformation. For general classes of visual structure, mapping has to tolerate deformation and must be based on the\nmatching of robust feature constellations (Biederman and Kalocsai, 1997). Net fragments can be seen as an attempt to\nmodel these (von der Malsburg, 2014, 2018; von der Malsburg et al., 2022a). So far, however, net fragments have only\nbeen proposed as a theoretical concept and have not been modeled in any concrete fashion.\nIn this work our focus is, however, not on correspondence-based mapping, but on the learning of fragment-based net\nformation, hoping to thereby contribute to the establishment of this neural code as a sound conceptual framework\ntranslating concepts of biological vision to applications in next-generation machine learning systems."}, {"title": "Net Fragments for Visual Perception", "content": "In the following, we restrict the discussion of DNA to the visual system. Light fields captured by the human eyes are\ntranslated to retinal images that appear as two-dimensional arrays of activated neurons in the primary visual cortex\n(Grill-Spector and Malach, 2004). There, neurons are sensitive to local texture elements within their receptive fields\n(Grill-Spector and Malach, 2004) and interact through short-range lateral connections (Gilbert et al., 1990). Visual\npatterns that appear with significant frequency within an image patch lead, through Hebbian plasticity, to the formation\nof net fragments, as visualized in Figure 1."}, {"title": "Computational Framework", "content": "We here restrict ourselves to modeling this functionality within a single cortical area, although the significance of\ncoherent nets in primary sensory areas can be fully appreciated only in the context of different interacting areas.\nA single area of a DNA model comprising net fragments is shown in Figure 2(A). Our system is based on an input\nlayer representing observed images by simple feature detectors (which are perhaps to be localized within layer IV of\nthe primary visual cortex, see, for instance, Usrey et al. (2003)) and two layers, Stage 1 (denoted as S1) and Stage 2\n(denoted as S2) whose neurons are thought to be also localized in the same primary visual cortex area, presumably\nwithin layers II and III.\nFeature Extraction. The system's input is a retinal 2D image represented by variables \u00e6k,i (gray box in Figure 2),\nwhere k \u2208 (1, ..., C') denotes the channel index of the image (C = 1 for grayscale, C = 3 for RGB), and the composite\nindex i = (h, w) \u2208 (H \u00d7 W) stands for vertical and horizontal position of pixels within the input image.\nSuch an image is used as afferent input to the feature extraction neurons in S1 and first increases their \u201cmembrane\npotential\u201d $a^{(S1)} \\in \\mathbb{R}^{C^{(S1)} \\times H \\times W}$ and potentially triggers their binary activation state $y^{(S1)} \\in {0,1}^{C^{(S1)} \\times H \\times W}$ (green\nbox in Figure 2). The membrane potential $a^{(S1)}$ is calculated by applying a convolutional operation (LeCun et al.,\n1989) (yellow box S1 in Figure 2):\n$a^{(S1)}_{c,j} = \\sum_{k \\in C} \\sum_{i \\in l_j} W^{(S1)}_{c,k,j-i} x_{k,i}$\nHere, c \u2208 C'(S1) denotes the feature channel, the compound index j, expanded as j = {h, w}, designates again spatial\nposition h\u2208 \u0397, w \u2208 W, and the compound index i = {h, w} is running through all (h, w)-pairs in the two-dimensional\nrange $l_1 = (h, ...., h + h^{(W1)}; w, ...., w + w^{(W1)})$ where $h^{(W1)}, w^{(W1)}$ denote the size of the convolutional filter. The\nsize of the convolutional kernel used for feature extraction is $W^{(S1)} \\in \\mathbb{R}^{C^{(S1)} \\times C \\times h^{(W1)} x w^{(W1)}}$\nFeature Binarization. The membrane potential $a^{(S1)}$, together with a bias parameter $b^{(S1)}$, determines the binary\noutput of the neurons in S1, denoted as variable $y^{(S1)} \\in {0,1}^{C^{(S1)}, C^{(S1)} \\times H \\times W}$, where 1 stands for firing, 0 for silence.\nThe binary neuron model with the input-output function B : a, b \u2192 y is defined as\n$y^{(S1)}_{c,j} = B(a^{(S1)} -b^{(S1)}) = \\begin{cases} 1, & \\text{if } a^{(S1)} -b^{(S1)} > 0 \\\\ 0, & \\text{otherwise} \\end{cases}$\nwith the same bias parameter $b^{(S1)}$ for all neurons acting as a firing threshold (cells fire if the membrane potential is\nabove this threshold).\nDynamics. Stage S2 builds net fragments by allowing active neurons to support laterally connected neurons over T\ntime steps (depicted as recurrent connection in Figure 2). A sample image is introduced into the system at time step\nt = 0 to activate neurons and remains unchanged until time step t = T. Throughout this period, neuronal activity\nundergoes sparsification due to growing inhibition. Through the sparsification process, the system forms an object\nrepresentation by leaving active a set of neurons each of which is supported by active neighbors, that is, a net.\nShort-Range Lateral Connections. Although typical convolutional neural networks (Fukushima, 1980; Waibel et al.,\n1987; LeCun et al., 1989) apply convolution operations to establish feed-forward connections between different layers,\nwe employ them here to implement short-range lateral connections within the same layer, their symmetry permitting\na pattern to manifest itself at any spatial location based on corresponding net fragments. Given lateral connections,\nthe neural activity of the previous time step t - 1 is accessed to calculate a neuron's activity at time t. In contrast to\nrecurrent networks like LSTMs (Hochreiter and Schmidhuber, 1997), where a new token is input at each time step, we\niterate over the same input while updating the internal state.\nThe membrane potentials $a^{(S2)}_{c,j}$ of the second stage neurons get excited by the (constant) signals of the previous stage S1\nand iteratively by lateral excitation from within S2. Before digitization, they are modified by saturation, normalization,\nand inhibition (yellow box S2 in Figure 2). Before those modifications, its raw form is computed as:\n$a^{\\prime(S2)}_{c,j}[t] = \\sum_{k \\in C^{(S1)}} \\sum_{i \\in l_j} W^{(F)}_{c,k,j-i} y^{(S1)}_{k,i} + \\sum_{k \\in C^{(S2)}} \\sum_{i \\in l_j} W^{(L)}_{c,k,j-i} y^{(S2)}_{k,i}[t-1]$\nSimilar to S1, c \u2208 C(S2) denotes the feature channel of S2, the compound index j expands to j = {w, h}, w \u2208 W,\nh\u2208 H, and the compound index i is running in the range $l_j = (h, ...., h + h^{(W2)}; w, ...., w + w^{(W2)})$, with $h^{(W2)}$ and\n$w^{(W2)}$ being the size of the convolution kernel.\nThe forward connections are denoted as $W^{(F)} \\in \\mathbb{R}^{C^{(S2)} \\times C^{(S1)} x h^{(W2)} x w^{(W2)}$ and the lateral connections as $W^{(L)} \\in\\mathbb{R}^{ C^{(S2)} x C^{(S2)} x h^{(W2)} x w^{(W2)}$, where C(S2) is the number of channels in S2, including the set of all feature channels and\nits alternative channels, i.e. $C^{(S2)} = n_a \\cdot C^{\\prime(S1)}$ where $n_a$ denotes the number of alternative channels per feature type\n(the alternative channels handle the alternative neurons that are required to prevent cross-talk between fragments, see\nApendix A). In the case of the forward connections, the kernel size determines which of the neurons $y^{(S1)}$ in stage 1\ncan be connected to a neuron $y^{(S2)}$ in stage 2 (red box in Figure 2), while the kernel size of the lateral connections"}, {"title": "Experiments", "content": "We evaluate our framework by assessing the efficacy of net fragments to filter out random Gaussian noise, the capacity\nto reconstruct occluded objects, i.e., the efficacy of dealing with subtractive noise, and its generalization capacity by\ncomposing small net fragments into object structures not observed during training."}, {"title": "Dataset", "content": "The dataset comprises binary images measuring (32 \u00d7 32) pixels, each sample depicting a straight line going through\nthe image center, starting and ending 2 pixels from the image boundary (leading to 59 distinct lines of different angles)."}, {"title": "Results", "content": "In the following, we show that the proposed net fragments can suppress Gaussian noise in Section 6.1 and can reconstruct\nremoved pixels, see Section 6.2. A description of the feature extraction mechanism to obtain $y^{(S1)}$ is in Appendix\nF, and details about the used parameters are in Appendix G. Additionally, Appendix H contains visualizations of the\naverage support strength received by cells, and Appendix I a quantitative evaluation of suppressed noise."}, {"title": "Filtering Gaussian Noise", "content": "The illustration in Figure 3 visually demonstrates the system's effective capability of filtering out isolated noise or\nsmall clusters thereof. Noise of varying degrees (from 0% to 59% noise probability at each spatial location - see\nAppendix 5.1) is introduced in an area's afferent input, from which a significant portion is removed when constructing\nnet fragments. While introducing up to 47.8% noise, remarkably consistent outputs $y^{(S2)}$ are generated. As additional\nnoise is introduced, more undesired neurons receive support and persist in their activity. However, the overarching\npattern remains distinguishable even when subjected to noise levels of up to 59%. In Appendix I, we quantitatively\nconfirm the efficacy of noise filtering by measuring precision, recall, and noise filtration rate for various parameter\nsettings, showing that lines remain well distinguishable for up to 59% added noise."}, {"title": "Reconstructing Subtractive Noise", "content": "If a substantial number of neurons activate and support other neurons within a net fragment, inactive neurons can receive\nsignificant support, leading them to switch on and encouraging figure reconstruction. Figure 5 shows how inactive\nneurons activate and thus demonstrates that net fragments can deal with subtractive noise (occluded patterns). This\nreconstruction works only reliably for up to 3 missing pixels (see Appendix I). In some cases, as in this Figure, the line\nis fully reconstructed for up to 6 removed pixels and partly reconstructed for 7 pixels."}, {"title": "Compositionality", "content": "A single DNA area models a feature hierarchy through nested net fragments of increasing size (von der Malsburg\net al., 2022b). In this study, we demonstrate that these higher-level nets can be composed of local features (small net\nfragments), even though the underlying patterns had never been observed during training. We show this on the example\nof curved lines, which share only local features with the straight lines of the training set.\nFigure 8 depicts four samples of curved lines with the corresponding neuronal activation within an area, once without\nnoise and once with 18.5% noise added to its afferent input. The cortical area is able to represent the curved lines as\ncomposite of net fragments learned from straight lines. Added unstructured clutter is efficiently removed, leading to\nrobust input representation."}, {"title": "Discussion and Conclusions", "content": "The concepts proposed here may be compared to established neural theory. Nets are based on associative learning but\ndiffer fundamentally from Hebbian assemblies (see Appendix A) as described in (Hopfield, 1982; Cohen and Grossberg,\n1983; Papadimitriou et al., 2020), which are monolithic and without inner structure, whereas nets can represent an\ninfinity of patterns based on shared fragments and can deal with new entities based on homeomorphy between common\ncompositional structure, thus enabling the systematicity and productivity characterizing cognitive operations (Fodor\nand Pylyshyn, 1988; von der Malsburg, 2023). In comparison to multi-layered perceptrons, coherent nets replace\nhierarchies of independent feature neurons by net fragments, share with them the potential for equivariance (shift\nsymmetry), but in distinction to them support the construction of an invariant representation that doesn't need to be\nlearned object-by-object (see next section). With the transformer architecture (Vaswani et al., 2017), nets share the\nprovision for finding non-local patterns through on-the-fly computation of lateral links.\nA decisive difference between DNA and all deep-learning systems (LeCun et al., 2015; Schmidhuber, 2015; Stadelmann\net al., 2019) is the mode of learning. ANNs typically rely on backpropagation of error where the goal is reaching\nconsistency (minimal error) between system output and teaching signals. With DNA models, the goal is mutual\nconsistency at each neuron, between the excitatory connections converging there, this consistency being measured\nby the probability for each connection to reach a highly active neuron when carrying a signal itself. Of all possible\nconnectivity patterns, only a minute fraction has this property of self-consistency. This condition of self-consistency\nacts as a selection criterion for eligible networks and thus powerfully reduces the search space of learning.\nNet fragments and the structured nets they build form a basis for the representation of hierarchical structures. They\nare effective for feature filtering and for preventing early commitment, which may be of fundamental importance for\nimproving the robustness of current machine learning systems. So far, a neural code based on net fragments has merely\nbeen proposed as a theoretical concept (von der Malsburg et al., 2022b), while this study pioneers the implementation\nof net fragments in a concrete simulation.\nOur experiments demonstrate that the proposed DNA architecture builds net fragments that effectively stabilize patterns,\nenhance robustness by eliminating visual clutter, and can reconstruct removed parts of known patterns. The DNA model\ncan handle additive noise exceptionally well and eliminates up to 96% of it while preserving the initial pattern, even in\nscenarios where up to 59% of all locations are affected. Figure completion works well for line interrupts for segments\nof up to 3 pixels, while for larger interruptions, the reconstruction rate decreases considerably. One reason for this is\ncertainly due to the nature of the used 1D pattern: as it involves straight lines with a width of one pixel, typically, only a\nfraction of the neurons within the local 2D neighborhood of size $h^{(W2)} \\times w^{(W2)}$ are active. With a larger line interrupt,\nthe proportion of active neurons compared to neighboring neurons is vanishingly small, which makes reconstruction\nmore difficult. It is expected that reconstruction will be much more robust with two-dimensional patterns.\nWe posit that this work, which focuses on the internals of a single cortical area, allows for scaling to multiple areas that\nwill allow the implementation of more complex tasks (see next section). Nevertheless, although this work is intended\nto be a step towards implementing a robust learning framework and the proposed neural code exhibits promising\ncharacteristics, it still has weaknesses that should be addressed in future work. One such weakness is dependence on\nmanual adjustment of the parameters b and \u03b3. The mechanism of signal control is biologically implausible. It should be\nreplaced by a more elegant, theoretically justified, and self-adjusting mechanism."}, {"title": "Future Work", "content": "One important purpose of handing structure from one area to another is generalization, a prime example for which in\nvision is object recognition invariant to translation (and wider transformation groups). While our system only includes\none \"cortical\" area, another area (that would correspond to the cortical inferotemporal cortex (Ito et al., 1995)) could\ncontain invariant object models. In the context of DNA, we see invariant recognition as realized by a process in which\nan object-representing net in a primary sensory area A forms and activates a homeomorphic net in a secondary area\nB. Two nets are homeomorphic if they contain the same feature types in the same spatial arrangement. Invariance is\nachieved if differently transformed mutually homeomorphic nets in A activate the same net in B under a homeomorphic\nmapping. Inter-areal homeomorphic maps are based on feature type-preserving connections, which in the brain are\nrealized by axonal fibers\u00b2. In fact, connections should not only be feature type-preserving but also restricted to pairs of\ncorresponding alternative neurons in A and B, such that they carry not only feature information but also information\non connectedness\u00b3. The generation of the net in B is again the result of a two-phase process, the afferent connections\nfrom A to B transiently activating many neurons in B, most of which getting silenced in phase two, leaving only those\nneurons active that not only got afferent input but are also supported by lateral excitation within B. The net thus formed\nin B is invariant to homeomorphic transformations in A. Object classification, the identification of the net in B as a\nparticular object type or recognition of individual objects needs a further area C containing a fixed net that is activated\nbased on approximate homeomorphy with the invariant net in B.\nThe result of the recognition process is the formation of a larger net composed of a net in A, a net in B, and one-to-one\nconnections between corresponding neurons in A and B. The self-consistency of this larger net is the basis for learning\nall participating connections, as all connections are stabilized (or generated) by their success in predicting activity in\ntheir target neuron.\nThrough inverse mapping, these stabilizing interactions can be re-imported to the previous area and thus help to\ndiscriminate the corresponding nets there from noise and clutter and bridge larger partial occlusions, which would\nrealize the idea of predictive coding Keller and Mrsic-Flogel (2018).\nAn obvious first step in preparation for a larger-scale system of interacting areas is, however, the training of a single\nprimary-sensory area with natural images to capture as net fragments all textures that occur in them with significant\nfrequency. This project should include the extraction of such different sensory qualities as stereo depth, local motion or\nsurface discontinuities. Net fragments and nets based on these would then have a chance to relate to intrinsic surface\nproperties such as form."}, {"title": "Appendix", "content": ""}, {"title": "Net Fragments vs. Associative Memory, Alternative Neurons", "content": "Learning of lateral connections to form net fragments shares aspects with associative memory (Hopfield, 1982; Cohen\nand Grossberg, 1983). There are, however, important differences. In an associative memory system, neural patterns\nare stored at once in their entirety with the help of synaptic plasticity, any pair of active neurons within a pattern\nstrengthening their mutual excitatory connections. The resulting connectivity turns each stored pattern into an attractor\nstate that can be recalled (dynamically activated) starting from initial states that come near to it. Such stored and\ndynamically stabilized neural patterns are often called \"assemblies\" (Hebb, 1949), and are discussed to this day as\nfundamental to the function of the brain, see for instance (Papadimitriou et al., 2020).\nThere are two problems with the concept of associative memory. One is rather fundamental in that a pattern is\nmonolithic and can be recalled only as a rigid whole. This is due to the indiscriminate stickiness with which any pair\nof simultaneously active neurons is tied together by synaptic plasticity in the one-time storage process. Fragments,\nin distinction, are formed in a protracted statistical process in which connections are gradually established between\nneurons that are co-active with statistical significance. Due to the spatial deformation of visual patterns, this can only\nbe the case for neurons relating to neighboring visual points. DNA models distinguish insignificant from significant\nconnections, only the latter being permitted to grow, which they do under competition until reaching equilibrium. As a\nresult, the system doesn't store rigid global patterns but is able to dynamically stabilize an unlimited number of global\nstates that are composed combinatorially out of overlapping fragments.\nThe other, more technical, problem of associative memory is that stored states have to be statistically independent\n(\"orthogonal\") to avoid cross-talk between them. (In a simple example of cross-talk, a neuron c\u2081 gets connected at\ndifferent times with neurons C2, C3, C4, although the pattern {C1, C2, C3, C4} doesn't occur with statistical significance\nduring learning. As a result, c\u2081 may be activated erroneously if {C2, C3, C4} is active as part of a larger pattern.) Sparsity\n(according to which a very small fraction of all neurons are active within any given pattern) has been proposed as a\ngeneral means to avoid cross-talk and to ensure statistical independence of stored patterns (French, 1999).\nDNA models are freed from this constraint by the introduction of \u201calternative neurons,\u201d neurons that are activated by\nthe same input feature but are free to learn different lateral connections to other neurons. (In our example, neuron C1\nwould be replaced by a set {C1, C1, C1"}, "of alternative neurons, which could then independently learn the connections\nC3 and C11/", "C4, thus avoiding the above cross-talk.) In the biological case, there is ample room for\nalternative neurons. There are, for instance, a hundred times more neurons in the primary visual cortex compared to the\nnumber of fibers coming out of the retina (Leuba and Kraftsik, 1994)."], "content": "The forward connections W(F) are initialized so that the activations of the S1 neurons are copied into the S2 neurons in\nthe same position. This is done by setting the connections at the center of the kernel (at position $(h^{(W2)}/2, w^{(W2)}/2)$)\nto 1 if Cin = [Cout/na], where Cin denotes the index of the input channel, Cout the index of the output channel, and na\nthe number"}