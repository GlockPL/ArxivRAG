{"title": "THE DYNAMIC NET ARCHITECTURE: LEARNING ROBUST AND\nHOLISTIC VISUAL REPRESENTATIONS THROUGH\nSELF-ORGANIZING NETWORKS", "authors": ["Pascal J. Sager", "Jan M. Deriu", "Benjamin F. Grewe", "Thilo Stadelmann", "Christoph von der Malsburg"], "abstract": "We present a novel intelligent-system architecture called \"Dynamic Net Architecture\" (DNA) that\nrelies on recurrence-stabilized networks and discuss it in application to vision. Our architecture models\na (cerebral cortical) area wherein elementary feature neurons encode details of visual structures, and\ncoherent nets of such neurons model holistic object structures. By interpreting smaller or larger\ncoherent pieces of an area network as complex features, our model encodes hierarchical feature\nrepresentations essentially different than artificial neural networks (ANNs).\nDNA models operate on a dynamic connectionism principle, wherein neural activations stemming\nfrom initial afferent signals undergo stabilization through a self-organizing mechanism facilitated\nby Hebbian plasticity alongside periodically tightening inhibition. In contrast to ANNs, which rely\non feed-forward connections and backpropagation of error, we posit that this processing paradigm\nleads to highly robust representations, as by employing dynamic lateral connections, irrelevant details\nin neural activations are filtered out, freeing further processing steps from distracting noise and\npremature decisions.\nWe empirically demonstrate the viability of the DNA by composing line fragments into longer lines\nand show that the construction of nets representing lines remains robust even with the introduction\nof up to 59% noise at each spatial location. Furthermore, we demonstrate the model's capability to\nreconstruct anticipated features from partially obscured inputs and that it can generalize to patterns\nnot observed during training. In this work, we limit the DNA to one cortical area and focus on its\ninternals while providing insights into a standalone area's strengths and shortcomings. Additionally,\nwe provide an outlook on how future work can implement invariant object recognition by combining\nmultiple areas.", "sections": [{"title": "1 Introduction", "content": "We present the first implementation of a novel intelligent-system architecture called \u201cDynamic Net Architecture\u201d (DNA).\nWe motivate it here by contrasting it to the architectures of artificial neural networks (ANNs) that play an essential\nrole in analyzing high-dimensional data (LeCun et al., 2015; Schmidhuber, 2015; Stadelmann et al., 2018). An ANN\nis a static, deeply nested function optimized with respect to a static cost function. An input to an ANN is mapped to\nan output by a succession of nested functions arranged in layers. Consequently, representations have the form of a\nhierarchy that integrates simpler low-level features (outputs of inner functions) to more complex high-level features\n(outputs of outer functions). The representations computed by the inner functions are independent of the outputs of\nouter functions. We posit that this is one of the leading causes of the lack of robustness witnessed in ANNs (Windrim\net al., 2016; Li et al., 2019; Wang et al., 2019; Rusak et al., 2020; Drenkow et al., 2022) since the decisions of inner\nfunctions cannot be adjusted by plausibility checks based on outer functions. This assertion finds support in the formal\nexplanation provided by Goodfellow et al. (2015), who argue that adversarial attacks rely on perturbations below the\nthreshold of visibility when these are summed over a sufficiently high input dimensionality (cf. Ilyas et al. 2019).\nFollowing Marr (2010), we call this phenomenon of lacking robustness due to sequential information processing \u201cthe\nfallacy of early commitment,\u201d i.e., the inability to factor the outputs of the outer functions (high-level features) into\nthe computation of the inner functions (low-level features), so that low-level decisions are in danger of misleading\nhigh-level decisions.\nWith the proposed DNA, we overcome this limitation by dynamically integrating local and global features. The DNA is\nformulated in terms of cortical areas (two-dimensional sheets of neurons) and projections between them. Connectivity\nwithin areas is dominated by short-range lateral (\u201crecurrent\u201d) connections, different areas are connected bidirectionally.\nThe neurons of a given area are elementary feature detectors. Afferent connections from a given input pattern activate a\nfraction of all neurons in the area. Cyclically rising inhibition then silences the majority of the initially activated neurons,\nleaving only those active that are supporting each other with sufficient strength through excitatory lateral connections.\nThis mutual support can only be realized within specifically structured consistent networks, \u201cnets\u201d (von der Malsburg,\n2018) and have to be generated by statistical learning. Nets can span the entire visual field and connect feature neurons\nthat are spatially distant through chains of locally connected intermediary neurons. Nets are flexibly composed of \"net\nfragments\" that correspond to often-occurring feature constellations. Each position of an area contains many fragments\n(analogous to the code-book of image compression schemes, Taubman and Marcellin (2002)) from which the input can\nchoose. Unlike the pieces of a jigsaw puzzle, each net fragment fits to a choice of possible neighboring fragments (and\neach neuron can be part of several net fragments), so that a virtually infinite number of nets can be formed from a finite\nset of neurons and net fragments.\nAccording to this principle, a two-phase process admits first a transient initial volley of activity, while in a second\nphase, most of this activity is silenced so that only mutually supporting neurons stay active. What is responding to the\ninput of a cortical area are thus not individual neurons but rather organized nets. From Gestalt psychology (Wertheimer\net al., 1938; K\u00f6hler, 1992), we know the visual system can rapidly discern holistic structures, that is, recognize global\npatterns as arrays of local features that conform consistently to certain \"local Gestalt rules\u201d K\u00f6hler (1992): from all\nthe local features present in the input, only those are selected by the visual system that fit consistently into a coherent\nglobal pattern (coherent in the sense of being composed throughout of overlapping fragments). Thus, local decisions are\nconditioned on global patterns, whereas global patterns need for their constitution local features. We offer our nets of\nlateral connections as the mechanism that mediates between local and global levels: local Gestalt rules are implemented\nby net fragments, and as long as an input pattern can be covered throughout by fragments, the response it elicits is a\ncoherent net.\nThe two-phase process described is able to remove noise and filter out irrelevant details. It thus avoids the fallacy\nof early commitment by conditioning neuron activation on integrability into a globally consistent net. An additional\neffect is that neurons that aren't receiving afferent input but have sufficient lateral support might get activated, thus\ncomplementing figures or textures and allowing the interpretation of occluded objects.\nThe connectivity necessary for stable second-phase activity is very specific and needs to be generated by learning. The\ngoal is to find and stabilize those patterns of afferent activation that stand out statistically. This is possible with the\nhelp of Hebbian plasticity (Hebb, 1949) that strengthens short-range excitatory connections between neurons often\nco-activated by the input. In the initial stages of learning, before the establishment of supporting connections, learning\nhas to rely on phase one activity, that is, on the actual statistics of input activation. In the course of learning, however,\nplasticity has to be biased more and more in favor of those neurons that stand out by lateral support, neurons whose\nactivity survives into phase two.\nHow do our cortical areas compare to the layers of ANNs? Whereas the latter are mainly there to accommodate a\nhierarchy of feature detectors of higher and higher complexity, already a single cortical area provides for such hierarchy"}, {"title": "", "content": "in the form of nested net fragments of growing size (von der Malsburg et al., 2022b), a hierarchy that extends up\nto input-activated nets representing entire objects. One role of higher cortical areas is to permit the construction\nof representations invariant to transformations affecting lower areas (translation, rotation, scaling, etc.), while the\nconnection between variant and invariant representations is established by structured dynamic sets of connections (see\nbelow).\nAreas are dominated by short-range lateral connections, which abound in the cortex Stettler et al. (2002); Suzuki et al.\n(2023) but are ignored in multi-layer perceptrons (MLPs) (Prince, 2023) and transformer architectures (Vaswani et al.,\n2017). Lateral, recurrent connections play important roles both for function and for learning. As for function, they are\nthe basis for the establishment of nets as high-level (e.g., object-global) representations by a collective computational\nmechanism Forrest (1990), conditioning global and local decisions on each other, as noted above. Such mediation\nbetween levels is not possible in ANNs with their purely feed-forward flow of information (which is unavoidable due to\ntheir learning principle of backpropagation of error (Rosenblatt, 1962; Linnainmaa, 1970; Rumelhart and McClelland,\n1987)). Regarding learning, the restriction to connectivity patterns that are self-consistent (connectivity structure\nsupporting activity states that stabilize this same connectivity structure) reduces the search space of learning by many\norders of magnitude and has the potential to produce connectivity patterns representing novel structures never seen as\nexamples. Moreover, the stabilization of connection weights based on local rules (rather than backpropagation through\nmany layers) decisively relaxes precision requirements put on them.\nIn this work, we present the first implementation of a cortical area structured by fragments and apply it to a simple\nvision task, showcasing its ability to be robust against noise and perform figure completion. We believe that this\nconceptual work lays the foundation for a novel learning system that can fulfill complex tasks such as invariant object\nrecognition when scaled up to multiple areas in subsequent research (see Section 2.3). Specifically, we make the\nfollowing contributions:\n\u2022 We demonstrate the viability of net fragments as neural code, highlighting their role in enhancing the robustness\nof computational frameworks.\n\u2022 We provide a summary of the relevant neuroscientific hypotheses of net fragments and dynamic linking.\n\u2022 We translate these hypotheses into a computational framework compatible with recent machine learning\nadvances.\n\u2022 We discuss the introduced concepts and describe how extending it with multiple areas can foster invariant\nobject detection."}, {"title": "2 Related Work", "content": "As outlined above, deep neural networks exhibit a deficiency in robustness. In the scientific literature, robustness is\ntypically defined as immunity to noise (additive noise, or subtractive noise in the form of missing information; see Cao\net al. (2021); Neururer et al. (2024)) and adversarial attacks (Drenkow et al., 2022), as well as the capability of dealing\nwith ambiguous inputs (Simmler et al., 2021) and generalization within/across domains (e.g., over image translation,\nrotation, changing lighting, etc.).\nThis work focuses on analyzing net fragments that are formed in each DNA-based area concerning their robustness\nto small perturbations. Related work pertaining to this aspect is summarized in Section 2.1, followed by a review\nof representation learning. The subsequent Section 2.3 examines systems utilizing correspondence-based mapping,\nwhich can cope well with ambiguous inputs and exhibit good generalization capabilities. These systems closely align\nconceptually with the DNA proposed in this work, making them highly relevant for future research, especially for\nscaling to a multi-area DNA."}, {"title": "2.1 Robustness to Noise", "content": "Adversarial attacks exploit deep networks' vulnerability to noise by calculating slight perturbations capable of altering\nthe model's predictions for specific samples (Szegedy et al., 2014; Goodfellow et al., 2015; Papernot et al., 2016a;\nCarlini and Wagner; Deriu et al., 2022) or perturbations applicable across the entire dataset (Moosavi-Dezfooli et al.,\n2017). Adversarial attacks can also be devised without direct access to the model and its parameters, for example, by\nanalyzing a model's decision boundary (Brendel et al., 2018; Engstrom et al., 2019) or training an auxiliary model\n(Chen et al., 2017; Cisse et al., 2017; Sarkar et al., 2017).\nCurrent approaches aim to counter these attacks by modifying the network's architecture to increase robustness\n(Papernot et al., 2016b; Gao et al., 2017; Ros and Doshi-Velez, 2018), including adversarial examples to the training"}, {"title": "", "content": "data (Moosavi-Dezfooli et al., 2016; Goodfellow et al., 2015), transform the inputs before being processed (Dziugaite\net al., 2016; Bhagoji et al., 2018), or adding external models (Meng and Chen, 2017; Xu et al., 2018) or attack detectors\n(Amirian et al., 2018).\nThe lack of robustness also manifests itself in poor generalization between domains, where a change in the statistical\ndistribution of data prevents the applicability of a model trained on a source domain to a slightly different target domain\n(Tuggener et al., 2022; Yan et al., 2024). Addressing such domain shifts typically involves domain alignment (Erfani\net al., 2016; Ghifary et al., 2017; Rahman et al., 2020; Sager et al., 2022), meta-learning (Dou et al., 2019; Zhou et al.,\n2020; Du et al., 2020), or data augmentation (Carlucci et al., 2019; Zhang et al., 2020; Tuggener et al., 2024).\nDespite notable advances in improving robustness and preventing adversarial attacks, existing methods primarily\naddress symptoms by reducing the number of parameters (Papernot et al., 2016b), removing specific features (Gao et al.,\n2017), regularizing gradients (Ros and Doshi-Velez, 2018), augment or extend the training data (Moosavi-Dezfooli\net al., 2016; Dziugaite et al., 2016; Tuggener et al., 2024), align domains (Erfani et al., 2016), or meta-learn features\n(Dou et al., 2019). In contrast, we here attempt to fundamentally rethink the principles underlying learning, network\narchitecture, and information flow, potentially leading to more robust representations. In our experiments (see Section\n6), we substantiate the efficacy of the proposed net fragments in effectively mitigating random Gaussian noise and\ndealing with occluded objects (a type of subtractive noise)."}, {"title": "2.2 Representation Learning", "content": "Other research relevant to this work employs other design principles to enhance robustness. A crucial principle involves\nsparse neural activation, which enhances robustness relative to dense representations, as shown for deep neural networks\n(Guo et al., 2018; Liao et al., 2022; Timpl et al., 2022; Prince, 2023). This is particularly true for binary sparse\ndistributions (Ahmad and Scheinkman, 2019). Element-wise comparison of two vectors, each with only a few activated\nneurons, proves to be highly robust. Given sufficiently large vector dimensionality, accidental similarity across different\nbinary sparse representations is highly improbable (Ahmad and Hawkins, 2015).\nAlso in this work, we exploit binary sparse representations to bolster model robustness. In our system, sparsity is not\nimposed by specific constraints but by design along established principles, including lateral connections (Kothari and\nAgyepong, 1996; Corchado et al., 2003) and self-organization through local Hebbian updates (Hebb, 1949), coupled\nwith inhibitory mechanisms for activity regulation (Abbott and Nelson, 2000; Luz and Shamir, 2012)."}, {"title": "2.3 Correspondence-Based Mapping", "content": "A highly robust vision framework for object detection is based on correspondence mapping between pixel patterns\nwithin an image and a corresponding prototype (Wolfrum et al., 2008). Here, \u201ccorresponding\" refers to neurons\nrelating to the same point on the object's surface. A pivotal concept in this framework are maps implemented as sets of\nprojection fibers (connections that dynamically turn on and off) known as shifter circuits (Anderson and van Essen,\n1987; Olshausen et al., 1993) that are composed of maplets (Zhu and von der Malsburg, 2004). These maps are activated\nwhen point-to-point correlations are detected between coherent nets in two cortical areas. The composite nets in the two\ncortical areas explicitly represent spatial relations, and a map between them can only be formed if they agree on this\nspatial structure. Once a forward mapping to a coherent model of a visual pattern is established, backward mapping to\nthe primary visual domain can stabilize the modeled structure there by complementing missing elements or by lacking\nto support visual noise elements.\nSo far, correspondence-based mapping has been applied only to human face detection and identification (Lades et al.,\n1993; Wolfrum et al., 2008; Fernandes and von der Malsburg, 2015), in which image and object model match with little\ndeformation. For general classes of visual structure, mapping has to tolerate deformation and must be based on the\nmatching of robust feature constellations (Biederman and Kalocsai, 1997). Net fragments can be seen as an attempt to\nmodel these (von der Malsburg, 2014, 2018; von der Malsburg et al., 2022a). So far, however, net fragments have only\nbeen proposed as a theoretical concept and have not been modeled in any concrete fashion.\nIn this work our focus is, however, not on correspondence-based mapping, but on the learning of fragment-based net\nformation, hoping to thereby contribute to the establishment of this neural code as a sound conceptual framework\ntranslating concepts of biological vision to applications in next-generation machine learning systems."}, {"title": "3 Net Fragments for Visual Perception", "content": "In the following, we restrict the discussion of DNA to the visual system. Light fields captured by the human eyes are\ntranslated to retinal images that appear as two-dimensional arrays of activated neurons in the primary visual cortex"}, {"title": "", "content": "(Grill-Spector and Malach, 2004). There, neurons are sensitive to local texture elements within their receptive fields\n(Grill-Spector and Malach, 2004) and interact through short-range lateral connections (Gilbert et al., 1990). Visual\npatterns that appear with significant frequency within an image patch lead, through Hebbian plasticity, to the formation\nof net fragments, as visualized in Figure 1."}, {"title": "", "content": "Among afferent input-activated neurons, only a few are part of net fragments so as to support each other's activity\nby exchanging spikes along excitatory lateral connections (Stettler et al., 2002). Within milliseconds, neurons that\nhave sufficient lateral support are singled out by neural inhibition (Vogels et al., 2011) from all others that also receive\nafferent input but lack lateral support.\nAll statistically significant visual textures within image patches with the radius of the range of lateral connections are\nrepresented by local connectivity patterns (such as in image compression algorithms (Wallace, 1991) by codebook\nvectors). To account for the homogeneity of image structure, it can be assumed that the connectivity has translational\nsymmetry (\u201cconvolutional\u201d structure) supporting equivariance, that is, the property that image shift gets reflected in\nactivity shift.\nA given feature can be part of a large number of patterns. To avoid interference between these patterns, each feature\n(defined in the primary visual area by a particular receptive field shape in a particular position) is represented by a\nnumber of \"alternative neurons,\u201d which are free to carry different connections 1. In this way, features can vary their\nconnections to other features by activating different alternative neurons: they are connected by \"dynamic links.\" For\nmore details on alternative neurons, please refer to Appendix A.\nTo project net fragments and coherent nets out from the mass of all neurons that are individually activated by the sensory\ninput needs dynamic processing: After neurons are activated by afferent input, they are subjected to progressively\nincreasing inhibition, which eventually silences all those of them that don't have sufficient lateral support. As many\nfragments can survive inhibition only if supported by overlapping other fragments, inhibition-resistant responses\nconstitute nets that are coherently composed of overlapping fragments.\nThese fragment-composed nets differ fundamentally from associative memories as formalized, for instance, by Hopfield\n(1982); Cohen and Grossberg (1983). In these, entire neural patterns, \u201cassemblies,\u201d are stored (in a single step) and"}, {"title": "4 Computational Framework", "content": "We here restrict ourselves to modeling this functionality within a single cortical area, although the significance of\ncoherent nets in primary sensory areas can be fully appreciated only in the context of different interacting areas.\nA single area of a DNA model comprising net fragments is shown in Figure 2(A). Our system is based on an input\nlayer representing observed images by simple feature detectors (which are perhaps to be localized within layer IV of\nthe primary visual cortex, see, for instance, Usrey et al. (2003)) and two layers, Stage 1 (denoted as S1) and Stage 2\n(denoted as S2) whose neurons are thought to be also localized in the same primary visual cortex area, presumably\nwithin layers II and III.\nFeature Extraction. The system's input is a retinal 2D image represented by variables \u00e6k,i (gray box in Figure 2),\nwhere k \u2208 (1, ..., C') denotes the channel index of the image (C = 1 for grayscale, C = 3 for RGB), and the composite\nindex i = (h, w) \u2208 (H \u00d7 W) stands for vertical and horizontal position of pixels within the input image.\nSuch an image is used as afferent input to the feature extraction neurons in S1 and first increases their \u201cmembrane\npotential\u201d $a_{c,j}^{(S1)} \\in R^{C^{(S1)} \\times H \\times W}$ and potentially triggers their binary activation state $y_{c,j}^{(S1)} \\in \\{0,1\\}^{C^{(S1)} \\times H \\times W}$ (green"}, {"title": "", "content": "box in Figure 2). The membrane potential $a_{c,j}^{(S1)}$ is calculated by applying a convolutional operation (LeCun et al.,\n1989) (yellow box S1 in Figure 2):\n$a_{c,j}^{(S1)} = \\sum_{k \\in C} \\sum_{i \\in l_j} W_{c,k,j-i} x_{k,i}$\nHere, c \u2208 C'(S1) denotes the feature channel, the compound index j, expanded as j = {h, w}, designates again spatial\nposition h\u2208 \u0397, w \u2208 W, and the compound index i = {h, w} is running through all (h, w)-pairs in the two-dimensional\nrange l\u2081 = (h, ...., h + h(W1); w, ...., w + w(W1)) where h(W1), w(W1) denote the size of the convolutional filter. The\nsize of the convolutional kernel used for feature extraction is $W^{(S1)} \\in R^{C'(S1) \\times C \\times h(W1) \\times w(W1)}$\nFeature Binarization. The membrane potential $a_{c,j}^{(S1)}$, together with a bias parameter $b^{(S1)}$, determines the binary\noutput of the neurons in S1, denoted as variable $y^{(S1)} \\in \\{0,1\\}^{C(S1), C(S1) \\times H \\times W}$, where 1 stands for firing, 0 for silence.\nThe binary neuron model with the input-output function B : a, b \u2192 y is defined as\n$y_{c,j}^{(S1)} = B(a_{c,j}^{(S1)} - b^{(S1)}) = \\begin{cases}\n1, & \\text{if } a_{c,j}^{(S1)} - b^{(S1)} > 0\\\\\n0, & \\text{otherwise}\n\\end{cases}$\nwith the same bias parameter $b^{(S1)}$ for all neurons acting as a firing threshold (cells fire if the membrane potential is\nabove this threshold).\nDynamics. Stage S2 builds net fragments by allowing active neurons to support laterally connected neurons over T\ntime steps (depicted as recurrent connection in Figure 2). A sample image is introduced into the system at time step\nt = 0 to activate neurons and remains unchanged until time step t = T. Throughout this period, neuronal activity\nundergoes sparsification due to growing inhibition. Through the sparsification process, the system forms an object\nrepresentation by leaving active a set of neurons each of which is supported by active neighbors, that is, a net.\nShort-Range Lateral Connections. Although typical convolutional neural networks (Fukushima, 1980; Waibel et al.,\n1987; LeCun et al., 1989) apply convolution operations to establish feed-forward connections between different layers,\nwe employ them here to implement short-range lateral connections within the same layer, their symmetry permitting\na pattern to manifest itself at any spatial location based on corresponding net fragments. Given lateral connections,\nthe neural activity of the previous time step t - 1 is accessed to calculate a neuron's activity at time t. In contrast to\nrecurrent networks like LSTMs (Hochreiter and Schmidhuber, 1997), where a new token is input at each time step, we\niterate over the same input while updating the internal state.\nThe membrane potentials $a_{c,j}^{(S2)}$ of the second stage neurons get excited by the (constant) signals of the previous stage S1\nand iteratively by lateral excitation from within S2. Before digitization, they are modified by saturation, normalization,\nand inhibition (yellow box S2 in Figure 2). Before those modifications, its raw form is computed as:\n$a_{c,j}^{'(S2)}[t] = \\sum_{k \\in C^{(S1)}} \\sum_{i \\in l_j} W_{c,k,j-i}^{(F)} y_{k,i}^{(S1)} + \\sum_{k \\in C^{(S2)}} \\sum_{i \\in l_j} W_{c,k,j-i}^{(L)} y_{k,i}^{(S2)}[t-1]$\nSimilar to S1, c \u2208 C(S2) denotes the feature channel of S2, the compound index j expands to j = {w, h}, w \u2208 W,\nh\u2208 H, and the compound index i is running in the range lj = (h, ...., h + h(W2); w, ...., w + w(W2)), with h(W2) and\nw(W2) being the size of the convolution kernel.\nThe forward connections are denoted as $W^{(F)} \\in R^{C(S2) \\times C(S1) \\times h(W2) \\times w(W2)}$ and the lateral connections as $W^{(L)} \\in\nR^{C(S2) \\times C(S2) \\times h(W2) \\times w(W2)}$, where C(S2) is the number of channels in S2, including the set of all feature channels and\nits alternative channels, i.e. C(S2) = na \u00b7 C'(S1) where na denotes the number of alternative channels per feature type\n(the alternative channels handle the alternative neurons that are required to prevent cross-talk between fragments, see\nApendix A). In the case of the forward connections, the kernel size determines which of the neurons $y^{(S1)}$ in stage 1\ncan be connected to a neuron $y^{(S2)}$ in stage 2 (red box in Figure 2), while the kernel size of the lateral connections"}, {"title": "", "content": "determines which neurons can be connected within stage 2. The kernel W(F) is initialized such that the sets of\nequivalent neurons in S2 copy the activity (and with that the feature type) of the corresponding neuron in S1, and\nW(L) is initialized with zeros except for self-coupling of neurons, with value 1 (details in Appendix B). The weights\nare updated using Hebbian Learning (details in Appendix C).\nFor the first time step t = 0, when $y_{c,j}^{(S2)}$ is undefined, we initialize the S2 neurons with zeros, i.e., the neurons are\nsilent and do not provide lateral support:\n$y_{c,j}^{(S2)} [t = 0] = 0$\nSingle Weight-Kernel Implementation. This entire process is visually depicted in the upper part (A) of Figure 2.\nFor simplicity in our algorithm, and since we use the same kernel size for the forward and lateral connections, we stack\nthe two kernels W(F) and W(L) as $W^{(S2)} = (W^{(F)}; W^{(L)})$ as well as the inputs $y_{k,i}^{(S1)}$ and $y_{k,i}^{(S2)}[t-1]$ as shown in\nFigure 2(B), leading to the equivalent formulation:\n$a_{c,j}^{'(S2)} [t] = \\sum_{k \\in C^{(S1)}} \\sum_{i \\in l_j} W_{c,k,j-i}^{(S2)} \\begin{bmatrix} y_{k,i}^{(S1)} \\\\ y_{k,i}^{(S2)} [t-1] \\end{bmatrix}$\nThe net fragments are implicitly contained in this processing as the active neurons whose activity state is stored in $y^{(S1)}$\nand their connection to other neurons.\nInhibition. The raw neural excitation a' computed in eq. 3 (or eq. 5) is to be subjected to saturation, inhibition,\nand normalization so it can be binarized using a pre-defined threshold. These steps of processing the raw membrane\npotential a' of neurons proved necessary in our simulation experiments to achieve the qualitative function we aimed for.\nThe details to obtain the normalized activations anorm in the range (0, 1) are described in Appendix D. The differences\nbetween activation levels of neurons are accentuated by setting\n$a_{c,j}^{(S2)} = max((a_{norm}^{'(S2)} - \\gamma \\cdot a_{norm}^{'(S2)}[t]),0)$,\nThe coefficient \u03b3 regulates the inhibition strength and increases with the time-steps of the inner loop according to\n\u03b3 = 1.2 + 0.2t, making it harder for neurons to fire (as $a_{norm}^{'(S2)} < 1$). The membrane potential is higher for neurons\nthat are part of coherent fragments (valid patterns) as they receive lateral support, while invalid activations are less\nsupported. While the inhibition coefficient increases over time, many neurons eventually get suppressed, leaving only\nthose active that support each other and form a consistent net. Finally, the membrane potential is converted to a binary\nactivation, neurons becoming active when their inhibited membrane potential is above the activation bias $b^{(S2)}$, which\nserves to control the firing rate of neurons:\n$y_{c,j}^{(S2)} [t] = B (a_{c,j}^{(S2)} - b^{(S2)})$\nThe final output $y^{(S2)} [t = T]$ is the lateral connection-supported neuronal activation in which, in contrast to the initial\nactivation, unsupported activations are suppressed. To allow features to be part of multiple net fragments and represent\nvarious patterns, they are represented by a set of alternative neurons (details in Appendix A). All neurons within such\nsets are free to learn different lateral connections to other neurons. They are connected by distinct channels within the\nconvolutional matrix and engage in competition, with only one alternative channel gaining activation at each spatial\nlocation while the remaining neurons are suppressed (set to zero). This selection process process is described in the\nAppendix E."}, {"title": "5 Experiments", "content": "We evaluate our framework by assessing the efficacy of net fragments to filter out random Gaussian noise, the capacity\nto reconstruct occluded objects, i.e., the efficacy of dealing with subtractive noise, and its generalization capacity by\ncomposing small net fragments into object structures not observed during training."}, {"title": "5.1 Dataset", "content": "The dataset comprises binary images measuring (32 \u00d7 32) pixels, each sample depicting a straight line going through\nthe image center, starting and ending 2 pixels from the image boundary (leading to 59 distinct lines of different angles)."}, {"title": "", "content": "The images are generated when required and their set may vary from one epoch to another. During each training cycle,\nwe randomly generate 300 image instances (each line about 5 times). During evaluation, we sample each of the 59\ndistinct lines exactly once. In contrast to training, the samples used for evaluation comprise local distortions in the form\nof additive Gaussian nose and missing line segments (subtractive noise), and we evaluate the net fragments' capability\nto remove these.\nWe introduce additive Gaussian noise to the afferent input in stage S2, thereby simulating an image structure that\nhas already survived the filtering of feature kernels in S1. To that end, we probabilistically flip neurons within each\nchannel with a probability of up to 20%. Since we use four feature channels in our experiments, this corresponds to a\nprobability of $1 \u2013 (1 \u2013 0.2)^4 = 59$% that a neuron is flipped at any spatial location. To evaluate subtractive noise, we\ncreate discontinuous lines by deleting a line segment in the middle.\nTo demonstrate the generalization capability of DNA areas, we generate validation samples that differ from the ones\nused during training. Specifically, we produce kinked lines by generating four random points within the image and draw\nstraight lines between these points."}, {"title": "6 Results", "content": "In the following, we show that the proposed net fragments can suppress Gaussian noise in Section 6.1 and can reconstruct\nremoved pixels, see Section 6.2. A description of the feature extraction mechanism to obtain $y^{(S1)}$ is in Appendix\nF, and details about the used parameters are in Appendix G. Additionally, Appendix H contains visualizations of the\naverage support strength received by cells, and Appendix I a quantitative evaluation of suppressed noise."}, {"title": "6.1 Filtering Gaussian Noise", "content": "The illustration in Figure 3 visually demonstrates the system's effective capability of filtering out isolated noise or\nsmall clusters thereof. Noise of varying degrees (from 0% to 59% noiseprobability at each spatial location see\nAppendix 5.1) is introduced in an area's afferent input, from which a significant portion is removed when constructing\nnet fragments. While introducing up to 47.8% noise, remarkably consistent outputs $y^{(S2)}$ are generated. As additional\nnoise is introduced, more undesired neurons receive support and persist in their activity. However, the overarching\npattern remains distinguishable even when subjected to noise levels of up to 59%. In Appendix I, we quantitatively\nconfirm the efficacy of noise filtering by measuring precision, recall, and noise filtration rate for various parameter\nsettings, showing that lines remain well distinguishable for up to 59% added noise."}, {"title": "", "content": "Figure 3 visualizes that neural activity simulating visual clutter without coherent structure is removed after processing\nfor 5 time-steps. Figure 4 depicts this systematic filtering over time. The additionally introduced clutter doesn't activate\noverlapping net fragments and cannot withstand increasing inhibition. The figure illustrates a substantial noise reduction\nalready at time step t = 0 due to the filtering by matrix $W^{(F)}$ and initial inhibition. In each subsequent time step,\nadditional clutter is removed. This reduction is due to increased inhibition and falling support as a consequence of the\ndrop-out of supporting neurons. We thus observe a chain reaction of gradual suppression of incoherent structure as well\nas the preservation of net structure on the basis of internal support."}, {"title": "6.2 Reconstructing Subtractive Noise", "content": "If a substantial number of neurons activate and support other neurons within a net fragment, inactive neurons can receive\nsignificant support, leading them to switch on and encouraging figure reconstruction. Figure 5 shows how inactive\nneurons activate and thus demonstrates that net fragments can deal with subtractive noise (occluded patterns). This\nreconstruction works only reliably for up to 3 missing pixels (see Appendix I). In some cases, as in this Figure, the line\nis fully reconstructed for up to 6 removed pixels and partly reconstructed for 7 pixels."}, {"title": "", "content": "When dealing with missing pattern elements, the\nmembrane potential map $a_{c,j}^{(S2)}$ plays a crucial role. The potential is higher at spatial locations where line features are\nobserved and lower where they are not observed but expected. Consequently, the network can, to some extent, handle\nthis ambiguity and model it based on the activation map, as shown in Figure 6. Modeling this ambiguity enables having\ndifferent internal interpretations, such as whether \u201cit is an interrupted line that should be reconstructed\" or \"there are\ntwo co-linear line segments.\u201d We find that the activation map is especially reliable during the first time step, where it is\ncalculated based on the observed input and the network's expectation about local patterns. Since local interactions can\ntrigger or deactivate neurons, the activation map changes over time, reducing its interpretability."}, {"title": "", "content": "Figure 7: Reconstruction of a horizontal line interrupted by 7 pixels: The feature activation and the initial output activity\nat t = 0 are interrupted but reconstructed within the two subsequent time steps (t = 1, 2). Afterward, some artifacts\ntriggered at line ends are reduced due to increasing inhibition. Activation bias $b^{(S2)}$ = 0.5, inhibition coefficient\n\u03b3 = 1.8 + 0.1t.\nIncreasing Inhibition Over Time Stabilizes Patterns. The reconstruction process unfolds across multiple sequential\nsteps, as illustrated in Figure 7. Initially, at time step t = 0, the net fragments represent the interrupted line. Subsequently,\nduring the second time step (t = 1), some of the removed pixels are reconstructed, and shortly after, at t = 2, the entire\nline is represented by the net fragments. Thus, reconstruction can persist even amid increasing inhibition, given that\ninactive neurons receive adequate support. This example underscores the necessity for multiple time steps, essential not\nonly for noise removal but also for the reconstruction of features, as neurons can undergo flipping in each time step,\nfostering a dynamic interplay where the flipping of certain neurons encourages others to follow."}, {"title": "6.3 Compositionality", "content": "A single DNA area models a feature hierarchy through nested net fragments of increasing size (von der Malsburg\net al., 2022b). In this study, we demonstrate that these higher-level nets can be composed of local features (small net\nfragments), even though the underlying patterns had never been observed during training. We show this on the example\nof curved lines, which share only local features with the straight lines of the training set.\nFigure 8 depicts four samples of curved lines with the corresponding neuronal activation within an area, once without\nnoise and once with 18.5% noise added to its afferent input. The cortical area is able to represent the curved lines as\ncomposite of net fragments learned from straight lines. Added unstructured clutter is efficiently removed, leading to\nrobust input representation."}, {"title": "7 Discussion and Conclusions", "content": "The concepts proposed here may be compared to established neural theory. Nets are based on associative learning but\ndiffer fundamentally from Hebbian assemblies (see Appendix A) as described in (Hopfield, 1982; Cohen and Grossberg,\n1983; Papadimitriou et al., 2020), which are monolithic and without inner structure, whereas nets can represent an\ninfinity of patterns based on shared fragments and can deal with new entities based on homeomorphy between common\ncompositional structure, thus enabling the systematicity and productivity characterizing cognitive operations (Fodor\nand Pylyshyn, 1988; von der Malsburg, 2023). In comparison to multi-layered perceptrons, coherent nets replace\nhierarchies of independent feature neurons by net fragments, share with them the potential for equivariance (shift\nsymmetry), but in distinction to them support the construction of an invariant representation that doesn't need to be\nlearned object-by-object (see next section). With the transformer architecture (Vaswani et al., 2017), nets share the\nprovision for finding non-local patterns through on-the-fly computation of lateral links.\nA decisive difference between DNA and all deep-learning systems (LeCun et al., 2015; Schmidhuber, 2015; Stadelmann\net al., 2019) is the mode of learning. ANNs typically rely on backpropagation of error where the goal is reaching\nconsistency (minimal error) between system output and teaching signals. With DNA models, the goal is mutual\nconsistency at each neuron, between the excitatory connections converging there, this consistency being measured\nby the probability for each connection to reach a highly active neuron when carrying a signal itself. Of all possible\nconnectivity patterns, only a minute fraction has this property of self-consistency. This condition of self-consistency\nacts as a selection criterion for eligible networks and thus powerfully reduces the search space of learning."}, {"title": "", "content": "Net fragments and the structured nets they build form a basis for the representation of hierarchical structures. They\nare effective for feature filtering and for preventing early commitment, which may be of fundamental importance for\nimproving the robustness of current machine learning systems. So far, a neural code based on net fragments has merely\nbeen proposed as a theoretical concept (von der Malsburg et al., 2022b), while this study pioneers the implementation\nof net fragments in a concrete simulation.\nOur experiments demonstrate that the proposed DNA architecture builds net fragments that effectively stabilize patterns,\nenhance robustness by eliminating visual clutter, and can reconstruct removed parts of known patterns. The DNA model\ncan handle additive noise exceptionally well and eliminates up to 96% of it while preserving the initial pattern, even in\nscenarios where up to 59% of all locations are affected. Figure completion works well for line interrupts for segments\nof up to 3 pixels, while for larger interruptions, the reconstruction rate decreases considerably. One reason for this is\ncertainly due to the nature of the used 1D pattern: as it involves straight lines with a width of one pixel, typically, only a\nfraction of the neurons within the local 2D neighborhood of size $h(W^2) \\times w(W^2)$ are active. With a larger line interrupt,\nthe proportion of active neurons compared to neighboring neurons is vanishingly small, which makes reconstruction\nmore difficult. It is expected that reconstruction will be much more robust with two-dimensional patterns.\nWe posit that this work, which focuses on the internals of a single cortical area, allows for scaling to multiple areas that\nwill allow the implementation of more complex tasks (see next section). Nevertheless, although this work is intended\nto be a step towards implementing a robust learning framework and the proposed neural code exhibits promising\ncharacteristics, it still has weaknesses that should be addressed in future work. One such weakness is dependence on\nmanual adjustment of the parameters b and \u03b3. The mechanism of signal control is biologically implausible. It should be\nreplaced by a more elegant, theoretically justified, and self-adjusting mechanism."}, {"title": "8 Future Work", "content": "One important purpose of handing structure from one area to another is generalization, a prime example for which in\nvision is object recognition invariant to translation (and wider transformation groups). While our system only includes\none \"cortical\" area, another area (that would correspond to the cortical inferotemporal cortex (Ito et al., 1995)) could\ncontain invariant object models. In the context of DNA, we see invariant recognition as realized by a process in which\nan object-representing net in a primary sensory area A forms and activates a homeomorphic net in a secondary area\nB. Two nets are homeomorphic if they contain the same feature types in the same spatial arrangement. Invariance is\nachieved if differently transformed mutually homeomorphic nets in A activate the same net in B under a homeomorphic\nmapping. Inter-areal homeomorphic maps are based on feature type-preserving connections, which in the brain are\nrealized by axonal fibers\u00b2. In fact, connections should not only be feature type-preserving but also restricted to pairs of\ncorresponding alternative neurons in A and B, such that they carry not only feature information but also information\non connectedness\u00b3. The generation of the net in B is again the result of a two-phase process, the afferent connections\nfrom A to B transiently activating many neurons in B, most of which getting silenced in phase two, leaving only those\nneurons active that not only got afferent input but are also supported by lateral excitation within B. The net thus formed\nin B is invariant to homeomorphic transformations in A. Object classification, the identification of the net in B as a\nparticular object type or recognition of individual objects needs a further area C containing a fixed net that is activated\nbased on approximate homeomorphy with the invariant net in B.\nThe result of the recognition process is the formation of a larger net composed of a net in A, a net in B, and one-to-one\nconnections between corresponding neurons in A and B. The self-consistency of this larger net is the basis for learning\nall participating connections, as all connections are stabilized (or generated) by their success in predicting activity in\ntheir target neuron.\nThrough inverse mapping, these stabilizing interactions can be re-imported to the previous area and thus help to\ndiscriminate the corresponding nets there from noise and clutter and bridge larger partial occlusions, which would\nrealize the idea of predictive coding Keller and Mrsic-Flogel (2018).\nAn obvious first step in preparation for a larger-scale system of interacting areas is, however, the training of a single\nprimary-sensory area with natural images to capture as net fragments all textures that occur in them with significant\nfrequency. This project should include the extraction of such different sensory qualities as stereo depth, local motion or\nsurface discontinuities. Net fragments and nets based on these would then have a chance to relate to intrinsic surface\nproperties such as form."}, {"title": "Funding", "content": "This research has been funded by the Canton of Zurich, Switzerland, through the Digitalization Initiative of the Canton\nof Zurich (DIZH) Fellowship project \"Stability of self-organizing net fragments as inductive bias for next-generation\ndeep learning.\u201d"}, {"title": "Data Availability Statement", "content": "The code to generate the data as well as to reproduce the results can be found after the publication of this work on\nGithub at https://github.com/sagerpascal/dynamic-link-architecture."}, {"title": "Appendix", "content": ""}, {"title": "A Net Fragments vs. Associative Memory, Alternative Neurons", "content": "Learning of lateral connections to form net fragments shares aspects with associative memory (Hopfield, 1982; Cohen\nand Grossberg, 1983). There are, however, important differences. In an associative memory system, neural patterns\nare stored at once in their entirety with the help of synaptic plasticity, any pair of active neurons within a pattern\nstrengthening their mutual excitatory connections. The resulting connectivity turns each stored pattern into an attractor\nstate that can be recalled (dynamically activated) starting from initial states that come near to it. Such stored and\ndynamically stabilized neural patterns are often called \"assemblies\" (Hebb, 1949), and are discussed to this day as\nfundamental to the function of the brain, see for instance (Papadimitriou et al., 2020).\nThere are two problems with the concept of associative memory. One is rather fundamental in that a pattern is\nmonolithic and can be recalled only as a rigid whole. This is due to the indiscriminate stickiness with which any pair\nof simultaneously active neurons is tied together by synaptic plasticity in the one-time storage process. Fragments,\nin distinction, are formed in a protracted statistical process in which connections are gradually established between\nneurons that are co-active with statistical significance. Due to the spatial deformation of visual patterns, this can only\nbe the case for neurons relating to neighboring visual points. DNA models distinguish insignificant from significant\nconnections, only the latter being permitted to grow, which they do under competition until reaching equilibrium. As a\nresult, the system doesn't store rigid global patterns but is able to dynamically stabilize an unlimited number of global\nstates that are composed combinatorially out of overlapping fragments.\nThe other, more technical, problem of associative memory is that stored states have to be statistically independent\n(\"orthogonal\") to avoid cross-talk between them. (In a simple example of cross-talk, a neuron c\u2081 gets connected at\ndifferent times with neurons C2, C3, C4, although the pattern {C1, C2, C3, C4} doesn't occur with statistical significance\nduring learning. As a result, c\u2081 may be activated erroneously if {C2, C3, C4} is active as part of a larger pattern.) Sparsity\n(according to which a very small fraction of all neurons are active within any given pattern) has been proposed as a\ngeneral means to avoid cross-talk and to ensure statistical independence of stored patterns (French, 1999).\nDNA models are freed from this constraint by the introduction of \u201calternative neurons,\u201d neurons that are activated by\nthe same input feature but are free to learn different lateral connections to other neurons. (In our example, neuron C1\nwould be replaced by a set {C1, C1', C1\" } of alternative neurons, which could then independently learn the connections\nto C1', and C1'/\" C4, thus avoiding the above cross-talk.) In the biological case, there is ample room for\nalternative neurons. There are, for instance, a hundred times more neurons in the primary visual cortex compared to the\nnumber of fibers coming out of the retina (Leuba and Kraftsik, 1994)."}, {"title": "B Weight Initialization", "content": "The forward connections W(F) are initialized so that the activations of the S1 neurons are copied into the S2 neurons in\nthe same position. This is done by setting the connections at the center of the kernel (at position (h(W2)/2, w(W2)/2))\nto 1 if Cin = [Cout/na], where Cin denotes the index of the input channel, Cout the index of the output channel, and na\nthe number of alternative cells.\nThe lateral connections W(L) are initialized with zeros except for the self-coupling of neurons, which is set to 1. When\nHebbian plasticity is employed on the weight matrix W(L), these connections ought to grow (as neurons tend to keep\ntheir activation state between time steps), but due to the constraint of keeping all connection weights within the range\n(0, 1) (refer to equation 8), they stay put at 1."}, {"title": "C Hebbian Plasticity", "content": "After processing for T time steps both matrices W(F) and W(L) undergo Hebbian updates (Hebb, 1949):\n$W^{(S2)} := min (max (W^{(S2)} + \\alpha \\cdot p_{avg}, 0),1)$\nwhere \u03b1 represents the learning rate, and pavg denotes the average correlation between input and output. This average\nis determined for a given activation over all instances of a given pair of neurons c, c' in different positions of the image\ndomain. To compute pavg, we count the number of instances in which both neurons are on, subtract from it the number\nof instances where one neuron is on, and the other is off, and divide that sum by the number of all positive and negative\ninstances. The actual modification eq. (8) is applied once after the last iteration over T timesteps to increase stability\nagainst fluctuation of the activities $y^{(S2)} [t]$ in the course of iterations.\nThe network employs shared connections, formulated as convolutional kernels, between input patches and output\nneurons, making the building of fragments translation equivariant. Consequently, the same lateral connection is applied\nacross multiple output and input neurons. The decision to update this connection is based on the average correlation\npaug between all input and output neurons it connects. If the resulting average is positive, the corresponding connection\nincreases by \u03b1 as it connects more simultaneously active neurons than neurons that fire disjointly. Conversely, if the\naverage correlation is negative, indicating more disjoint firing, the connection strength is reduced by \u03b1."}, {"title": "D Normalization", "content": "We use two normalization steps to confine the neuronal activations $a^{'(S2)}$ to the interval (0, 1). These steps are\nfunctionally motivated and not by reference to biology.\nWe first apply a size limit:\n$a_{c,i}^{' (S2)} [t] = \\begin{cases}\na_{c,i}^{' (S2)} [t], & \\text{if } a_{c,i}^{' (S2)} [t] \\leq \\lambda\\\\\n\\frac{2 \\lambda - a_{c,i}^{' (S2)} [t]}{2}, & \\text{otherwise.}\n\\end{cases}$\nAccording to this formula, a\" grows undiminished with a' until it reaches the value \u03bb, and thereafter actually diminishes\nwith slope -1/2. (In our experiments we found the value ) = 1.3. $to work well). This saturation helps\nto mitigate imbalances between network fragments with differing numbers of participating neurons (as with our stimuli,\nline segments, where many more feature neurons activate around the end-points than in the middle of segments).\nIn the next step, we introduce the normalization\n$a_{c,i}^{norm (S2)} [t] = \\frac{a_{c,i}^{' (S2)} [t]}{max \\; a_{c,i'}^{'' (S2)} [t]}$\nThis normalization confines activations to the interval (0, 1), where neurons receiving maximal support are mapped to\n1, while those with lesser support are mapped to correspondingly smaller values. This normalization relative to the\nmaximal value that itself is growing during learning instead of relative to a constant parameter like \u03bb is important to\ngive neurons initially (when lateral connections are still small) a chance to fire and later, when lateral links of often\nco-active neurons have grown, to suppress those neurons that are part of accidental or noise patterns."}, {"title": "E Alternative Neuron Selection", "content": "Only one of a set of alternative neurons is allowed to be active. The selection process is determined by evaluating the\ncorrelation between feature patches and alternative kernel filters. Initially, patches matching the size of the feature\nkernel are extracted from every position in the input ($y^{(S1)}; y^{(S2)} [t \u2013 1]$). Subsequently, the correlation of these patches\nwith the feature kernels is computed, and at each location, the alternative kernel exhibiting the highest correlation is\nchosen. Consequently, multiple features may be active at each location, but only one of the competing feature channels\nthe one best matching a given input patch achieves activation. At initialization (see Appendix B), where all\nalternative channels fit equally well to a given local pattern, the first channel is selected. However, after applying a\nHebbian update, this channel starts specializing in recognizing a specific local pattern. Consequently, the activation of\nsubsequent local patterns may either trigger the same channel if they have a high correlation or activate another channel\nbetter suited to recognizing the new pattern."}, {"title": "F Feature Extraction", "content": "The input images have C = 1 channel and C(S1) = 4 features are extracted at each spatial location. We utilize\nhand-crafted filters with a size of 5 \u00d7 5 as displayed in Figure 9, each of the four filters corresponding to a particular\nline orientation (vertical, positive diagonal, horizontal, and negative diagonal). This approach is motivated by the\nobservation that, given our specific elementary feature types (cf. Fig. 9), straight lines, when viewed locally, can be\nexpressed as combinations of these fundamental line types (e.g., a line with a 20\u00b0 angle activates the horizontal and the\n+45\u00b0 diagonal feature neurons). The use of such manually designed filters allows a more straightforward interpretation\nof the results. While more complex datasets necessitate learned filters, our primary focus in this work is on constructing\nnet fragments, and thus, we favor the simplicity of hand-crafted filters.\nThese filters move across the image with a step size (\"stride\") of 1 (assuming 0 as input signal beyond the image border:\n\"zero padding\") so that the input image and output image are of the same size. Thus, the input \u00e6x in the feature extraction\nstage are images of size (1 \u00d7 32 \u00d7 32) and the output y(S1) feature activation maps of size (4 \u00d7 32 \u00d7 32). The dataset's\nlines activate multiple filters at different positions, facilitating the construction of net fragments across these feature\nchannels. We convert the floating-point output of the convolutional weights to binary activations using binary neurons\nB() with a bias of b(S1) = 0.5, i.e. neurons fire a binary spike if aj > 0.5 (see eq. 2)."}, {"title": "G Parameters", "content": "We train the model with a learning rate of \u03b1 = 0.2 for 100 training cycles (epochs). The model uses na = 10 alternative\nneurons with lateral connections spanning a kernel of 11 \u00d7 11 neurons. Since we use C'(S1) = 4 filters for feature\nextraction in S1 (see Appendix F), the number of alternative channels in S2 corresponds to C(S2) = 4. na = 40.\nThe resulting weight matrices have dimensions $W^{(F)} \\in R^{40 \\times 4 \\times 11 \\times 11}$ and $W^{(L)} \\in R^{40 \\times 40 \\times 11 \\times 11}$, respectively\n$W^{(S2)} \\in R^{40 \\times 44 \\times 11 \\times 11}$"}, {"title": "H Learned Support Strength", "content": "A crucial parameter for gauging the efficacy of net fragments involves quantifying the difference in support received by\nactive and inactive neurons. During the initial stages of training, active neurons receive a support of 1, and inactive\nneurons receive a support of 0. The support increases during training as net fragments are formed. Figure 10 visually\nrepresents the average support for active and inactive neurons, captured by a'; (see eqs. 3, 5). Notably, the graph\ndemonstrates a widening gap between the support for active and inactive neurons. This discrepancy suggests an\nenhancement in the robustness of statistically relevant patterns over time as active neurons receive increased support\nand the support of inactive neurons remains close to 0."}, {"title": "I Quantifying Noise Filtration", "content": "Our evaluations focus on the efficacy of net fragments in suppressing added Gaussian noise and complementing missing\nor occluded patterns. For both evaluation experiments, we report recall and precision: Recall is defined as the proportion\nof neurons that maintain activity (on) when noise is added, and precision quantifies the extent to which neurons activated\nin the presence of noise were also active without noise. To assess the system's noise reduction capability in the case\nof Gaussian noise, we additionally measure the percentage of flipped neurons that revert to their original activation\nstate, referring to this measurement as the noise reduction rate. To assess subtractive noise, we measure the similarity"}]}