{"title": "Path-Guided Particle-based Sampling", "authors": ["Mingzhou Fan", "Ruida Zhou", "Chao Tian", "Xiaoning Qian"], "abstract": "Particle-based Bayesian inference methods by sampling from a partition-free target (posterior) distribution, e.g., Stein variational gradient descent (SVGD), have attracted significant attention. We propose a path-guided particle-based sampling (PGPS) method based on a novel Log-weighted Shrinkage (LwS) density path linking an initial distribution to the target distribution. We propose to utilize a Neural network to learn a vector field motivated by the Fokker-Planck equation of the designed density path. Particles, initiated from the initial distribution, evolve according to the ordinary differential equation defined by the vector field. The distribution of these particles is guided along a density path from the initial distribution to the target distribution. The proposed LwS density path allows for an efficient search of modes of the target distribution while canonical methods fail. We theoretically analyze the Wasserstein distance of the distribution of the PGPS-generated samples and the target distribution due to approximation and discretization errors. Practically, the proposed PGPS-LwS method demonstrates higher Bayesian inference accuracy and better calibration ability in experiments conducted on both synthetic and real-world Bayesian learning tasks, compared to baselines, such as SVGD and Langevin dynamics, etc.", "sections": [{"title": "1. Introduction", "content": "Bayesian learning is a powerful approach for distribution-based model predictions, naturally equipped with uncertainty quantification and calibration powers (Murphy, 2022). The key of Bayesian learning \u2013 computing the posterior by Bayes' rule, however, is well-known to be challenging due to the intractable partition function (a.k.a. the normalizing constant) (Andrieu et al., 2003).\nTo circumvent this difficulty, approaches based on sampling according to the (target) posterior distribution without computing the partition function have been considered; e.g., Markov Chain Monte-Carlo (MCMC) sampling (Andrieu et al., 2003) and its gradient-based variants (e.g., Langevin dynamics) generate samples (or particles) that follow the target distribution asymptotically using a partition-free function. Such particle-based Bayesian inference methods, which essentially transform a set of initial samples/particles along certain dynamics (e.g., an ordinary differential equation (ODE) or a stochastic differential equation (SDE)) governed by a vector field, have witnessed great successes (Liu, 2017). Most of these methods, e.g. Stein variational gradient descent (SVGD) (Liu & Wang, 2016) and preconditioned functional gradient flow (PFG) (Dong et al., 2022), fall into the category of gradient-flow particle-based sampling, where the vector field is a gradient function of the Kullback-Leibler (KL) divergence of the current distribution to the target distribution, such that the dynamics would drive the particles to the minimum of KL-divergence solution, i.e., the target distribution.\nAlthough gradient-flow particle-based sampling methods are shown to be flexible and efficient in some applications (Dong et al., 2022), they may not achieve the ideal Bayesian inference performance due to not effectively capturing the posterior distribution. Specifically, as a realization of the KL-Wasserstein gradient-flow method, Langevin Dynamic (LD) is known to suffer from slow mixing, and in turn tends to result in mode missing or misplaced mode weights (Song & Ermon, 2019). It is believed that the posterior for complicated models, especially Bayesian Neural Networks (BNNs) (Goan & Fookes, 2020), contain multiple modes of different weights, and mode missing would impact its generalization, uncertainty quantification, and calibration abilities. More detailed discussions can be found"}, {"title": "2. Background", "content": "Given an inference model parameterized by parameters x, e.g., a neural network with parameters x, Bayesian inference updates the distribution of the parameters by Bayes' theorem, and performs statistical inference according to the posterior distribution. Specifically, suppose parameters $x \\in \\mathbb{R}^d$ has prior density po(x), and given a data set D, the posterior $p^*(x)$ is updated by $p^*(x) = \\frac{p(x)}{Z}$ with $p(x) = p_0(x)L(D|x)$, where L(D|x) is the likelihood function of the data D and $Z = \\int p_0(x)L(D|x) dx$ is the partition function. The partition function Z is usually computationally intractable. Many inference methods, including broadly applied Monte Carlo methods (Liu & Liu, 2001), have been proposed to (approximately) draw samples from the posterior/target distribution $p^*(x)$ using the more tractable partition-free function p(x).\nParticle-based (particularly flow-based) Bayesian inference methods direct a set of random samples/particles $\\{x^{(i)}\\}_{i=1}^n \\subset \\mathbb{R}^d$ drawn i.i.d. from an initial distribution $p_0$ (e.g., the prior or other distributions from which samples can be drawn directly) along certain ODE dynamics\n$\\frac{dx_t}{dt} = \\phi_t(x_t), \\quad X_0 \\sim p_0,$\ndefined by a vector field $\\phi_t : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$. The corresponding evolution of the density functions is characterized by the continuity equation (Jordan et al., 1998):\n$\\frac{\\partial}{\\partial t} p_t(x) = -\\nabla \\cdot (p_t(x)\\phi_t(x)),$\nwhere pt (x) denotes the density of xt, \u2207 is the vector differential operator w.r.t. x (we omit x for simplicity throughout the paper), and \u2207 \u00b7 f denotes the divergence of the vector function f.\nThe critical point of the particle-flow-based methods is the design of the vector field $\\phi_t$. A typical choice is the gradient of some objective function under a certain metric, and the dynamic is thus a gradient flow. An example of the gradient-flow particle-based method is the Wasserstein gradient flow (Ambrosio et al., 2005), which has drawn considerable interest. It is motivated by minimizing a functional $\\mathcal{L}(p_t) \\in \\mathbb{R}$ in the Wasserstein space, which is a space of distributions equipped with the Wasserstein metric\n$W_q(p_1, p_2) = \\bigg( \\inf_{\\gamma \\in \\Gamma(p_1, p_2)} \\int_{\\mathbb{R}^d \\times \\mathbb{R}^d} ||x_1 - x_2||^q d\\gamma(x_1, x_2) \\bigg)^{1/q},$\nwhere \u0393(p1,p2) is the set of all the coupling of p1 and p2. When the functional is the KL divergence $KL(p_t||p^*) = \\mathbb{E}_{x_t \\sim p_t} [-\\ln p^*(x_t) + \\ln p_t(x_t)]$ and under the 2-Wasserstein metric, i.e. q = 2, the resulting gradient has a closed form\n$\\phi(x) = \\nabla \\ln p^*(x) - \\nabla \\ln p_t(x).$\nUnder mild assumptions, the gradient flow converges to the optimal solution, i.e., $\\lim_{t \\rightarrow \\infty} p_t = p^*$, which implies that with sufficiently large t, xt approximately follows the target distribution $p^*$. Computing \u2207 ln pt (x) in Equation (2) is however not feasible in most practical cases. Methods such as learning the current density pt(x) (Wang et al., 2022), or transforming the problem of finding $\\phi_t(x)$ to a tractable learning/optimization problem (Dong et al., 2022; di Langosco et al., 2021) by a swarm of particles at step t, have been developed to implement the gradient flow. The vector field learning in our work is also based on a swarm of particles in the same manner, though the training loss function and the desired vector field are significantly different."}, {"title": "2.1. Motivation of the Proposed PGPS Method", "content": "We first pinpoint the cause of the slow convergence of KL Wasserstein gradient flow (e.g., LD), and provide the intuition for the proposed method as a remedy. Consider the experiment setup with a target distribution being a mixture of two Gaussian distributions, as shown in Figure 1 (a). Taking a zero mean isometric Gaussian as initial distribution, the convergence of LD to the target distribution is extremely slow as shown in Figure 1 (b-c), where the particles \"stuck\" at the left-hand-side mode of the Gaussian mixture and it takes many iterations to reach the right-hand-side mode. The reason for this behavior is that LD and similar gradient-flow-based methods rely heavily on the target distribution, which is an asymptotic target. Such an asymptotic target does not reflect the short-term need to escape from the current mode; i.e., the convergence to the target distribution can be extremely slow. To solve this issue, we propose PGPS which specifies a density evolution path directly connecting the initial and target distribution, and let the distribution of the particles evolve along such a path. At each time step, a short-term intermediate target on the path is set for the particles; more details are given in Section 3. As shown in Figure 1 (d), PGPS indeed finds both modes and converges to the target distribution with considerably fewer iterations.\nIn the following, we denote the unnormalized density function with a hat as $(\\hat{\\cdot})$, i.e. $p_t(x) \\propto \\hat{p}_t(x)$ with $\\int p_t(x) dx = 1$ but $\\int \\hat{p}_t (x) dx$ being an unknown positive number."}, {"title": "2.2. Related Works", "content": "Gradient-flow particle-based sampling usually aims at finding tractable estimations for the KL-gradient flows in the Wasserstein space. One track of works relies on the universal approximation theorem of neural networks (Hornik et al., 1989) to approximate the gradient-flow and maximize certain discrepancies (di Langosco et al., 2021; Grathwohl et al., 2020; Hu et al., 2018; Dong et al., 2022), among which preconditioned functional gradient flow (PFG) (Dong"}, {"title": "3. Path-Guided Particle-based Sampling", "content": "We propose Path-Guided Particle-based Sampling (PGPS) methods based on a continuous density path linking initial distribution po to target distribution $p_1 = p^*$, while only accessing the partition-free version of the target distribution $\\hat{p}_1 = \\hat{p}$. Compared to the annealing methods that also utilize intermediate distributions (path), PGPS learns a vector field that would drive the particles to the next intermediate distribution based on a predefined path in each step, which has not been studied previously to the best of our knowledge. In this section, we first derive a condition for viable guiding paths and present a novel class of log-weighted shrinkage paths. We then propose a learning algorithm to effectively approximate the path-guided flow.\nGiven a partition-free density process $\\{p_t\\}_{t \\in [0,1]}$ and its normalized densities $\\{p_t\\}_{t \\in [0,1]}$, with $p_0 = p_0$ being the initial distribution and $p_1$ being the target, assume that $\\frac{\\partial}{\\partial t}\\hat{p}_t$ and $\\nabla_x\\hat{p}_t(x)$ exist for any $t \\in [0, 1]$ and x on the support. We wish to construct a vector field $\\phi_t : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ such that the process\n$\\frac{dx_t}{dt} = \\phi_t(x_t), \\quad X_0 \\sim P_0$\nsatisfies $x_t \\sim p_t$ for any $t \\in [0, 1]$. The following proposition establishes that determining $\\phi_t(x)$ does not require the partition function.\nProposition 3.1. For a given partition-free density path $\\{\\hat{p}_t\\}$, the gradient flow guided by the vector field $\\phi_t(x)$ following the continuity equation (1) satisfies:\nr(x, t) - \\mathbb{E}_{x \\sim p_t} [\\frac{\\partial}{\\partial t} \\ln \\hat{p}_t(x)] = 0,\nwhere $r(x, t) = \\frac{\\partial}{\\partial t} \\ln \\hat{p}_t (x) + (\\nabla \\ln \\hat{p}_t(x) + \\nabla) \\cdot \\phi_t(x).$"}, {"title": "3.1. Selection of Path", "content": "One of the most important components of the proposed approach is the selection of partition-free guiding path $\\{p_t\\}_{t \\in [0,1]}$. Although any reasonable path linking the initial and target distributions is valid to direct particles according to Equation (3) as long as the corresponding vector field follows the condition in Proposition 3.1, certain paths that are more robust against democratization and more tractable for training are preferred and may have better performance in practice.\nWe propose a class of Log-weighted Shrinkage paths $\\{\\hat{p}^{lws}\\}$ as follows\n$\\ln \\hat{p}^{lws}(x) := (1 - t) \\ln p_0 \\big((1 - \\alpha t) x\\big) + t \\ln \\hat{p}_1 \\big( \\frac{x}{\\beta + (1 - \\beta) t} \\big),$\nwhere $\\alpha \\in [0, 1]$ and $\\beta \\in (0, 1]$ are controlling parameters.\nIt is straightforward to check that LwS paths are valid with $\\ln \\hat{p}^{lws}(x) = \\ln p_0(x)$ and $\\ln \\hat{p}^{lws}(x) = \\ln \\hat{p}_1(x)$. Moreover, $\\ln \\hat{p}^{lws}$ and $\\nabla \\ln \\hat{p}^{lws}$ both exist, when $\\nabla \\ln \\hat{p}_1$ and $\\ln p_0$ exist; see Appendix B.\nAs its name suggested, LwS paths (5) have two components - Log-weights and Shrinkage. The log-weights enable representing the log-distribution on the path by a linear mixture of the log-initial-distribution and log-target-distribution terms in Equation (5) weighted by (1 \u2013 t) and t. The linear mixture allows efficient computation of r(x, t) in Proposition 3.1 when training $\\phi_t$ by a neural network. The Shrinkage operates on the initial-distribution term by \u03b1 and the target-distribution term by \u03b2 in Equation (5). The first term spreads the initial distribution by a factor $1/(1 - \\alpha t)$ to cover larger ranges as the factor increases along t; and the second term shrinks the target distribution $\\hat{p}_1$ towards zero (i.e., the distribution $\\frac{x}{\\beta + (1 - \\beta) t}$ is thinner than $p_1(x)$) by a factor $\\beta + (1 - \\beta)t$. Since a typical choice of po is zero-mean Gaussian, the shrinkage allows better coverage of the target distribution, and the coverage enables better mode seeking. It is illustrated in Figure 2 for different choices of the hyperparameters \u03b1, \u03b2. We can observe that with appropriate choices of hyperparameters (e.g., (B) and (C)), the right mode of the target distribution is detected at an early stage"}, {"title": "3.2. Learning Vector Field $\\phi_{\\theta}(x)$", "content": "Given a viable path $\\{p_t\\}$, we aim to find a corresponding vector field $\\phi_t(x)$ as in Proposition 3.1 to direct the particles as in Equation (3). However, solving Equation (4) for $\\phi_t(x)$ in closed form is intractable. We use a parameterized vector field model $\\phi_{\\theta}^t(x) \\in \\mathbb{R}^d$ \u2013 a neural network parameterized by \u03b8 \u2013 to approximately solve for Equation (4).\nSpecifically, at each time step t starting with t = 0, we have N particles $\\{x_{t,(i)}\\}_{i=1,...,N}$ and minimize the training loss\n$L_t(\\theta) = \\frac{1}{N} \\sum_{i=1...N} r(x_{t,(i)}) - \\frac{1}{N} \\sum_{j=1...N} \\frac{\\partial \\ln \\hat{p}_t(x_{t, (j)})}{\\partial t}^2,$\nresembling the squared value of the LHS of Equation (4). When particles $\\{x_{t,(i)}\\}$ following distribution pt, $\\frac{1}{N} \\sum_{i=1...N} \\frac{\\partial \\ln \\hat{p}_t(x_{t,(j)})}{\\partial t}$ is an unbiased estimate of $\\mathbb{E}_{x_t \\sim p_t}: [\\frac{\\partial}{\\partial t} \\ln \\hat{p}_t(x)]$.\nThe training algorithm is presented in Algorithm 3, where the loss (6) is minimized by gradient descent. It is an iterative algorithm starting from time step t = 0 and is increased by \u2206t after the training for time t. The time step increment \u2206t is adaptively determined by Algorithm 1, which leads to a smaller increment for larger vector field $\\phi_{\\theta}^t$ to control the movement of the particles. Since we have an intermediate target distribution $\\hat{p}_t$ on the path to follow, an optional Langevin adjustment (Langevin dynamics w.r.t. the intermediate target $\\hat{p}_t$) in Algorithm 2 can be applied to adjust the particles' distribution closer to pt to reduce the biasedness in the loss function (6). We further discuss the Langevin Adjustment in the experiment section.\nTraining-free deployment of PGPS Many efficient algorithms such as LD or SVGD, are training-free, i.e., learning is not required during the evolution of the particles. We can also implement PGPS in a training-free manner, where at each time step t without training a neural network we update the particles by Langevin adjustment solely. In other words, we iteratively apply Langevin dynamics for sampling from an intermediate target distribution $\\hat{p}_t$. A similar approach"}, {"title": "4. Theoretical Analysis", "content": "In this section, we study the distribution of the PGPS-generated particles compared to the target distribution. Note that the target distribution $p^* \\propto \\hat{p} $ equals to $\\hat{p}_{x_1}$, where $x_1 = x_0 + \\int_0^1 \\phi_t(x_t) dt$ with $x_0 \\sim p_0$ by Proposition 3.1. The PGPS method without Langevin adjustment simulates the integration by\n$\\hat{x}_{(n+1)h} = \\hat{x}_{nh} + h \\phi_{\\theta_h}(\\hat{x}_{nh}), \\quad h = \\frac{1}{n}, t= 0, ..., n - 1,$\nwhere $h = 1/n$ is the step size for some $n \\in \\mathbb{N}$ capturing the discretization error, and $\\hat{x} \\sim p_0$.\nWe analyze the performance of PGPS using the 2-Wasserstein distance between the generated distribution $\\hat{P}_{x_1}$ and the target distribution $P_{x_1}$ under the approximation error $\\delta^2 := \\int_0^1 \\mathbb{E}_{x \\sim p_t} [||\\phi_{\\theta}^t(x) - \\phi_t(x)||^2]dt$ and discretization error due to step size h in Theorem 4.2. The following assumptions are taken in the analysis.\nAssumption 4.1.\n(1) Lipschitzness of $\\phi_t$ and $\\phi_{\\theta}^t$ on x space: There exists $K_1 < \\infty$, such that $|\\phi_t(x_1) - \\phi_t(x_2)|| \\leq K_1||x_1 - x_2||$ and $||\\phi_{\\theta}^t(x_1) - \\phi_{\\theta}^t(x_2)|| \\leq K_1||x_1 - x_2||$ for any $x_1, x_2 \\in \\mathbb{R}^d, t \\in [0, 1]$;\n(2) Lipschitzness of $\\phi_{\\theta}^t$ on t space: There exists $K_2 < \\infty$, such that $||\\phi_{\\theta}^{t_1}(x) - \\phi_{\\theta}^{t_2}(x)|| \\leq K_2|t_2 - t_1|$ for any $x \\in \\mathbb{R}^d, t_1, t_2 \\in [0, 1]$;\n(3) Finite vector field: There exists $K_3 < \\infty$, such that $|\\phi_t(x)|| \\leq K_3$ for any $x \\in \\mathbb{R}^d, t \\in [0, 1]$\nTheorem 4.2. For two flows $\\phi_{\\theta}^t(x)$ and $\\phi_t(x)$ under Assumption 4.1, the Wasserstein distance between the distribution $\\hat{P}_{x_1}$ of PGPS generated samples according to dynamics"}, {"title": "5. Experiments", "content": "We demonstrate the effectiveness of the proposed PGPS methods compared to LD, SVGD (Liu & Wang, 2016), PFG (Dong et al., 2022) baselines. The number of iterations for each method is the same, where the Langevin Adjustment steps in PGPS are counted. The code to reproduce the"}, {"title": "5.1. Gaussian Mixture Target Distribution", "content": "We study the mode-seeking and weight-estimation capabilities of the proposed PGPS for Gaussian mixture target distributions, compared to LD, SVGD, and PFG gradient-flow particle-based benchmarks."}, {"title": "5.1.1. MODE DISCOVERY MISSING", "content": "Given initial distribution $\\mathcal{N}(0, 3^2)$ and target distribution of a mixture of two Gaussian distributions $\\mathcal{N}(0, 1)$ and $\\mathcal{N}(8, 1)$ with equal weights, we investigate whether the methods can effectively discover both modes.\nNote that the left mode $\\mathcal{N}(0,1)$ of the target mixture is automatically discovered by the initial distribution $\\mathcal{N}(0, 3^2)$. Define score\u2081 = $\\frac{1}{N}\\sum_{i=1}^N 1(x_{t,(i)} > 5)$ to capture the rates of the samples discovering the right mode $\\mathcal{N}(8,1)$ by moving across threshold 5. The score1 is shown in Figure 3a, where the dashed true score is $\\mathbb{P}_{target}(x > 0.5) \\approx 0.499$. Note that the performances of PGPS methods are scattered because the method may require different adaptive iterations for"}, {"title": "5.1.2. FALSE MODE DISCOVERY - SENSITIVITY", "content": "The benchmarks not only fail to effectively discover modes but are also sensitive to the target distribution and may lead to false discovery, i.e., they may focus on some negligible mode.\nGiven initial distribution $\\mathcal{N}(0, 2^2)$ and target distribution of a mixture of two Gaussian distributions $\\mathcal{N}(-5, 1)$ and $\\mathcal{N}(5, 1)$, where the left mode has an extremely small weight 0.001 and the right mode has weight 0.999. As shown in Figure 3d, the left mode is negligible and the target distribution is visually indistinguishable from a Gaussian distribution.\nDefine score2 = $\\frac{\\sum_{i=1}^N 1(x_{t,(i)} < 0)}{N}$ to capture the rates of the samples focusing on the negligible left mode $\\mathcal{N} (-5, 1)$. The score2 is shown in Figure 3c, where the dashed true score is $\\mathbb{P}_{target}(x < 0) \\approx 0.001$. We observe that the benchmarks have a relatively large score2, which indicates they are very sensitive w.r.t. the target distribution. A negligible perturbation from the Gaussian target may lead to these methods focusing on a negligible mode. In contrast, the proposed PGPS is less sensitive with score2 close to the desired value 0.001. Figure 3d corroborates the finding by visualizing the output distribution of the methods.\nCompared to the gradient-flow-based benchmarks solely relying on the target distribution and its gradient, the proposed PGPS method follows a smooth LwS path instead, and is indeed less sensitive with better sampling quality."}, {"title": "5.1.3. WEIGHT RECOVERY", "content": "We investigate the capability of the proposed PGPS method in estimating the corresponding weights besides detecting modes. The target distribution is a mixture of four 8-dimensional isometric Gaussian distributions $\\{\\mathcal{N}(\\mu_j, 0.15^2I_8)\\}$ and randomly generated weights; and the initial distribution is $\\mathcal{N}(0, I_8)$.\nFor generated samples $\\{x_i\\}_{i=1}^N$, define the estimated weight $\\hat{w}_j := \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}(\\mid\\mid x_i - \\mu_j \\mid\\mid_2 < 1)$. We evaluate the weight mismatch by $\\epsilon := \\sqrt{\\sum_{j=1}^4 (\\hat{w}_j - w_j)^2}$, where $w_j = \\mathbb{P}_{target} (\\mid\\mid x - \\mu_j \\mid\\mid < 1)$ is the ground truth. Smaller error \u03f5 indicates more accurate weight estimation."}, {"title": "5.2. Bayesian Neural Network Inference", "content": "We further test PGPS methods for the Bayesian Neural Network (BNN) inference tasks. BNNs, which model the parameters of NNs as random variables to derive predictive posteriors for prediction, are usually considered to be difficult inference targets because of their non-concave likelihoods (Li et al., 2018). The proposed PGPS methods, with a stronger ability to discover the modes and recover their weights, achieve better inference performance."}, {"title": "5.2.1. UCI DATASET", "content": "We conduct BNN inference for UCI datasets (Dua & Graff, 2017), where the neural network (NN) has one hidden layer with 32 hidden neurons and Sigmoid activation. More details of the experimental setup can be found in the Appendix E.4.\nWe report the averaged testing Expected Calibration Error (ECE) and testing accuracy (ACC) in Table 1, where ECE represents the calibration ability of the uncertain prediction by comparing the difference in prediction accuracy and prediction uncertainty for the test samples. The proposed PGPS methods achieve the best performance across most of the benchmark datasets with lower ECE and higher ACC, compared with SVGD, SGLD, and PFG baselines."}, {"title": "5.2.2. NOISY MNIST DATASET", "content": "Robustness is another desired property of learning Bayesian models. It is expected that Bayesian models would give more reasonable predictions with uncertainty quantification (UQ) when facing out-of-distribution data. We benchmark the prediction and UQ performance of the proposed PGPS methods for learning BNNs on the MNIST dataset (Deng, 2012).\nTo test the robustness of inferred models, we create perturbation by injecting additive Gaussian noise into the test MNIST images. Ensembles of 10 learned BNNs (i.e., 10 particles) are considered for evaluating competing inference methods. The performances are evaluated by negative log-likelihood (NLL), ACC, and ECE in Table 2. We can observe that the proposed PGPS method is again the best-performing inference method on all the metrics with the perturbed test data. SGLD is slightly better in NLL by 0.02 but with a large standard deviation of 0.127."}, {"title": "5.2.3. TRAINING-FREE PSPG", "content": "We compare the standard PGPS and the training-free PGPS as discussed in Section 3.2 using the same Log-weighted"}, {"title": "6. Conclusion", "content": "In this paper, we proposed a novel path-guided particle-based sampling (PGPS) method and a Log-weighted Shrinkage path as a partition-function-free path that guides the particles moving from an initial distribution to the target distribution. We theoretically analyzed the performance of PGPS under the Wasserstein distance and characterized the impact of approximation error and discretization error on the quality of the generated samples. We conduct extensive experiments to test the PGPS methods in seeking the modes of the target distribution in sampling tasks, and the inference performance in terms of testing accuracy and calibration/uncertainty quantification in Bayesian learning tasks. The proposed PGPS methods perform consistently and considerably better than LD, SVGD, and PFG benchmarks in the experiments.\nA limitation of the standard PGPS method is the requirement of training neural networks, similar to the PFG and other learning-required benchmarks. We propose training-free PGPS as an immediate solution, which is slightly worse than the training-based PGPS but more efficient.\nA better density path design in PGPS that leverages the structure of the target distribution and analysis of training-free PGPS of its convergence to the target distribution are interesting future directions with both theoretical and practical importance."}, {"title": "Impact Statement", "content": "This paper presents a new Bayesian inference algorithm for efficient Bayesian learning, which would be critical in small-data scenarios that require uncertainty quantification. It can motivate advances in science, engineering, and biomedicine, for example in bioinformatics, materials science, and high-energy physics."}, {"title": "A. Related Works", "content": "Wasserstein gradient flow aims at building gradient flow where the density follows the steepest descent path of some objective functional of density function under the Wasserstein metric. Sampling is fulfilled once the descent path converges to the target distribution, which is the minimizer of the objective function. A popular objective function of density is the KL-divergence between the density and the target distribution, and the flow is thus called KL Wasserstein gradient flow. While it is intractable in general to derive the KL Wasserstein gradient flow, i.e., the flow does not have a closed-form, Wang et al. (2022) resorted to Kernel Density Estimation (KDE) to estimate the gradient flow and uses Euler discretization to update the samples. However, it suffers from the curse of dimensionality, i.e. the kernel matrix would tend to be diagonal as dimensionality increases, due to the nature of kernels, which leads to inaccurate density estimation.\nAside from Euler discretization, the Jordan, Kinderlehrer, and Otto (JKO) scheme, aiming at finding a JKO operator that minimizes the target functional as well as the movement of the particles in each step, has been broadly applied to discretize the Wasserstein gradient flow. Alvarez-Melis et al. (2021) and Mokrov et al. (2021) applied a series of Input Convex Neural Networks (ICNN, Amos et al. (2017)) to model the gradient flow to ensure the convexity of the potential function in JKO scheme.\nWhile the popularity of Stein Variational Gradient Descent (SVGD) (Liu & Wang, 2016) arises as a particle-based VI method, it can also be viewed as a specific type of gradient flow w.r.t. KL-divergence by determining the gradient \u03c6t(x) that is the steepest descent direction under the kernelized Stein's Discrepancy (Chwialkowski et al., 2016) by the reproducing kernel Hilbert space (RKHS) (Liu, 2017). However, the curse of dimensionality for the kernel-based methods leads to the particle collapse in SVGD (Ba et al., 2021), i.e., variance collapse. Currently, there are two major methods to tackle the curse of dimensionality. Projecting the inference space to a lower dimension can naturally avoid high-dimensional VI. While Chen & Ghattas (2020) projected the dynamics into a lower dimensional subspace and theoretically proved the asymptotically converging performance of the projected SVGD, Gong et al. (2020) proposed sliced kernel Stein discrepancy that projects the particle dynamics into a single dimensional subspace. More recently, Liu et al. (2022) proposed Grassmann SVGD that also considers a low-dimensional projection and is claimed to be more efficient than projected SVGD (Chen & Ghattas, 2020) without the need for costly eigenvector decomposition. Another type of popular method leverages the Universal Approximation Theorem of Neural Networks (NNs) (Hornik et al., 1989) and defines more general discrepancy. di Langosco et al. (2021) proposed to minimize Stein's discrepancy based on the NNs, instead of functions drawn from RKHS like SVGD. Grathwohl et al. (2020) proposed to learn a single energy function based on Stein's Discrepancy for energy-based models, while Hu et al. (2018) tried to learn a transport plan based on Stein's Discrepancy or more general f-divergence. Dong et al. (2022) modified the regularization term of the loss function to a preconditioned version but it needs to calculate the Jacobian of the target density and in turn time-consuming."}, {"title": "B. Implementation of LwS Path", "content": "Though it is possible to fully depend on the AutoGrad functionality of the machine learning packages, a relatively closed form of the gradient and derivatives of our Log-Shrinkage Path, $\\ln \\hat{p}^{lws}(x) = (1 - t) \\ln p_0 \\big((1 - \\alpha t) x\\big) + t \\ln \\hat{p}_1 \\big( \\frac{x}{\\beta + (1 - \\beta) t} \\big)$, would lead to better calculation quality and faster computational speed.\nDenote $x_{\\alpha} = (1 - \\alpha t)x$, $x_{\\beta} = \\frac{x}{\\beta + (1 - \\beta) t}$. The gradient of our paths $\\nabla \\hat{p}^{lws}(x)$ at time t would be\n$\\nabla \\ln \\hat{p}^{lws}(x) = (1 \u2013 t)(1 \u2013 \u03b1t)\u2207 ln p_0(x_\u03b1) + \\frac{t}{\\beta + (1 \u2212 \u03b2)t} \u2207 ln \\hat{p}_1(x_\u03b2),$\nand the derivative would be\n$\\frac{d}{dt} \\ln \\hat{p}^{lws}(x) = - \\ln p_0(x_{\\alpha}) + \\ln \\hat{p}_1(x_{\\beta}) - \\alpha (1 \u2013 t)x \u00b7 \u2207 ln p_0(x_{\\alpha}) - \\frac{(1 \u2212 \u03b2)tx \u00b7 \u2207 ln \\hat"}]}