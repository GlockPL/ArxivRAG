{"title": "A Scalable Quantum Non-local Neural Network for Image Classification", "authors": ["Sparsh Gupta", "Debanjan Konar", "Vaneet Aggarwal"], "abstract": "Non-local operations play a crucial role in computer vision enabling the capture of long-range dependencies through weighted sums of features across the input, surpassing the constraints of traditional convolution operations that focus solely on local neighborhoods. Non-local operations typically require computing pairwise relationships between all elements in a set, leading to quadratic complexity in terms of time and memory. Due to the high computational and memory demands, scaling non-local neural networks to large-scale problems can be challenging. This article introduces a hybrid quantum-classical scalable non-local neural network, referred to as Quantum Non-Local Neural Network (QNL-Net), to enhance pattern recognition. The proposed QNL-Net relies on inherent quantum parallelism to allow the simultaneous processing of a large number of input features enabling more efficient computations in quantum-enhanced feature space and involving pairwise relationships through quantum entanglement. We benchmark our proposed QNL-Net with other quantum counterparts to binary classification with datasets MNIST and CIFAR-10. The simulation findings showcase our QNL-Net achieves cutting-edge accuracy levels in binary image classification among quantum classifiers while utilizing fewer qubits.", "sections": [{"title": "Introduction", "content": "Computer vision has become a cornerstone of artificial intel-ligence, consisting of a wide array of applications such as au-tonomous driving (Bao et al. 2023), medical imaging (Li et al.2023), healthcare (Zhou et al. 2022), etc. An essential task in this domain is image classification, where the goal is to assign a label to an image based on its visual significance. This task also builds upon more complex applications such as image segmentation (Minaee et al. 2021), object detection (Amjoud and Amrouch 2023; Fu et al. 2023), and scene understand-ing (Naseer, Khan, and Porikli 2018). Image classification approaches have been significantly advanced by Convolu-tional Neural Networks (CNNs) (O'shea and Nash 2015), which achieve state-of-the-art performance on datasets like ImageNet (Krizhevsky, Sutskever, and Hinton 2012). However, CNNs are limited by their local receptive fields, which restricts them from capturing broader contextual information and long-range dependencies within an image. To overcome these limitations, non-local neural networks were introduced to capture long-range dependencies in data, an extension of the self-attention mechanism used in Transformer architec-tures (Vaswani et al. 2017). Initially proposed for computer vision applications by (Wang et al. 2018), non-local neural networks capture global context effectively and have shown significant improvements in computer vision tasks that bene-fit from modeling long-range dependencies.\nParallel to these advancements, quantum machine learning (QML) (Biamonte et al. 2017) has emerged as a revolutionary technology built upon the principles of quantum mechanics, which describes the behavior and nature of atoms at the small-est fundamental level and applies them to machine learning. In classical computing, information only exists in bits, which are 0 or 1. In contrast, quantum computing introduces the concept of qubits that can have quantum states |0\\rangle and |1\\rangle simultaneously, taking advantage of the concept of superpo-sition and introducing features such as quantum parallelism (Nielsen and Chuang 2001). Theoretically, this allows for speeding up computations and devising algorithms that can solve complex challenges more efficiently compared to clas-sical computing where computation might be expensive and inefficient, and potentially revolutionize fields like pattern recognition and image classification, optimization (Abbas et al. 2023), cryptography (Bernstein and Lange 2017), etc. QML also introduces algorithms for classification problems such as QSVM, Quantum Kernel methods, Variational Quan-tum Classifiers (VQC), etc. VQC is a particularly interesting approach within QML because it lets us combine classical and quantum computing to use a quantum circuit as the core algorithm consisting of quantum gates that can be parameter-ized (Benedetti et al. 2019; Peddireddy, Bansal, and Aggar-wal 2023). These parameters can be optimized using classi-cal methods, enabling the model to be trained with a hybrid quantum-classical approach, which we utilize in our work. Researchers have still been trying to understand whether QML offers a significant advantage to classical machine learning theoretically and practically, and it has been an active field of research for long (Biamonte et al. 2017). A sub-domain in this field, Quantum Neural Networks (QNNs), has been developed intensively to determine whether these are capable of outperforming classical neural networks. It was also recently explored in (Abbas et al. 2021) by perform-ing simulations on actual quantum hardware and proving"}, {"title": "Related Work", "content": "Image classification using quantum machine learning (QML) became an area of significant interest due to its potential ad-vantages over classical methods. One notable approach was Quantum Convolutional Neural Networks (QCNNs), which utilized quantum circuits to implement convolutional opera-tions, focusing on quantum phase recognition and quantum error correction optimization techniques (Cong, Choi, and Lukin 2019). Another significant development was the Quan-volutional Neural Network, introduced by (Henderson et al.2020) in 2019, which employed quantum convolution (quan-volutional) layers. These layers transformed classical data using random quantum circuits to extract features, akin to the feature extraction process in classical CNNs. Their results demonstrated superior accuracy and training performance compared to classical CNNs. QML models have also shown efficacy in binary classification tasks for noisy datasets and images (Schetakis et al. 2022). Additionally, recent work by (Cherrat et al. 2024) developed an approach for loading ma-trices as quantum states and introducing trainable quantum orthogonal layers adaptable to different quantum computer capabilities. This method yielded promising results on super-conducting quantum computers.\nSeveral works also explored the application of quantum neu-ral networks for binary classification tasks in computer vision, providing benchmarks for our results. QTN-VQC (Qi, Yang, and Chen 2023) built a framework with quantum circuits for tensor-train networks integrated with variational quantum circuits for an efficient training pipeline. Another work in-troduced hierarchical quantum classifiers (Grant et al. 2018), which utilized several expressive circuits to classify highly entangled quantum states and demonstrated robustness to noise. A scalable approach for quantum neural networks (SQNNs) for classification was discussed in (Wu, Tao, and Li 2022), where authors proposed a strategy to use multiple small-scale quantum devices to extract local features and per-form prediction over these collected features. (Jiang, Xiong, and Shi 2021) presented the QuantumFlow model, which represented data as unitary matrices to achieve quantum ad-vantage, reducing the cost complexity of unitary matrices-based neural computation. These recent advancements in QML models demonstrated robustness in image classifica-tion, making them suitable for handling higher-dimensional data more effectively than their classical counterparts."}, {"title": "Non-local Neural Networks", "content": "Traditional convolution operations in convolutional neural networks (CNNs), a popular choice for computer vision mod-els, process a local neighborhood, and applying these opera-tions repeatedly to capture long-range dependencies causes incremental growth in the receptive field. This has several drawbacks associated with computational inefficiency and difficulties in optimization. Non-local neural networks ad-dress these limitations by introducing non-local operations that compute the response at a position as a weighted sum of the features at all positions in the input. These are simple operations that are highly efficient and generic in capturing long-range dependencies, which is of utmost importance in computer vision (Wang et al. 2018).\nA generic non-local operation for an input signal's (image, sequence, video) feature map $x \\in \\mathbb{R}^{N\\times C}$, where $N$ is the number of positions (i.e. pixels) and $C$ is the number of channels, can be defined as:\n$\\displaystyle Y_i = \\frac{1}{C(x)}\\sum_{\\forall j} f(x_i, x_j)g(x_j),$ (1)\nwhere i is the index of an output position (in space/time/s-pacetime) whose response is to be computed, j enumerates"}, {"title": "Quantum Non-local Neural Network", "content": "In this work, we introduce the Quantum Non-Local Neural Network (QNL-Net), which utilizes trainable quantum cir-cuits to implement non-local operations, effectively capturing and processing long-range dependencies in input data. The QNL-Net module integrates with classical dimensionality re-duction techniques to function as a hybrid quantum-classical classifier. In this section, we first delve into the design and im-plementation of the QNL-Net module. Next, we discuss the integration of classical dimensionality reduction techniques with the QNL-Net to create a hybrid classifier, highlighting the CNN-QNL-Net and PCA-QNL-Net models. Finally, we cover the post-QNL-Net classical computation.\nThe QNL-Net mechanism translates classical non-local oper-ations into quantum circuits, enabling the network to exploit the parallelism and entanglement properties of quantum com-puting. This translation involves designing quantum gates"}, {"title": "Simulation Results", "content": "The experiments were conducted using different combina-tions of feature map repetitions r = 1, 2, or 3 and the number of ansatz repetitions D = 1, 2 or 3. The accuracies reported are averaged for all runs for each specific ansatz and model configuration, as shown in Appendix Table 1.\nThe results on the MNIST dataset for classes 0 and 1 indi-cate that the CNN-QNL-Net model performs slightly bet-ter than the PCA-QNL-Net model, achieving a near-perfect average classification test accuracy of 99.96% whereas the PCA-QNL-Net achieved a test accuracy of 99.59%. Ansatz-0 and Ansatz-2 generally yield better results compared to Ansatz-1 for this dataset, as evident in Appendix Table 1. For the CIFAR-10 dataset, the hybrid-QNL-Net models perform comparatively worse than the MNIST due to the introduction of three color channels (i.e., RGB) compared to MNIST's grayscale images. However, the CNN-QNL-Net was still able to obtain an average test accuracy of 93.98%. Ansatz-1 per-forms better on the testing dataset for CIFAR-10 compared to the other ansatzes. On both datasets, the CNN-QNL-Net significantly outperforms the PCA-QNL-Net due to its ability to efficiently extract features from the dataset before feeding them to the QNL-Net module.\nIncreasing the depth of both the feature map and the ansatzes (i.e., r and D, respectively) generally improved classification accuracies due to the increased expressiveness of the circuit. However, it also resulted in longer training times compared to using fewer repetitions, which still obtained reasonably good results within the bounds reported in Appendix Table 1. Fur-thermore, PCA-QNL-Net models required higher learning rates to obtain convergence than the CNN-QNL-Net models. The PCA-QNL-Net demonstrated faster training compared to the CNN-QNL-Net, as CNNs add an overhead for training parameters, utilizing a total of 34,282 classical parameters on MNIST and 41,314 classical parameters on CIFAR-10. The PCA-QNL-Net, however, optimizes only 22 classical parameters from the linear layers, offering an advantage in terms of classical training efficiency."}, {"title": "Discussion", "content": "The novelty of the QNL-Net architecture lies in its efficient utilization of fewer qubits, a critical consideration in the NISQ era. However, its significance extends beyond that to take into account the fundamental principles of quantum me-chanics, particularly in its treatment of rotations around axes and entanglement. TThe choice of rotation gates in the QNL-Net ansatzes is tied to the fundamental idea behind non-local neural networks, which aim to capture intricate spatial depen-dencies within the data. In the quantum paradigm, rotation gates achieve this by translating quantum states around dif-ferent axes, thereby implementing spatial transformations. Now, for simplification, consider the raw data x and the three embeddings ($\\theta, \\phi, \\rho$) in the non-local neural net architecture as akin to the four features passed on to the QNL-Net circuit. In non-local neural nets, raw data is not embedded, but in this work, we utilize rotation around the z-axis primarily because it allows us to maintain a trainable parameter on qubit 0 af-ter the feature map encoding which ensures the consistency and completeness of quantum theory while not affecting the"}, {"title": "Conclusion", "content": "This paper introduced the Quantum Non-local Neural Net-works (QNL-Net) mechanism as a novel hybrid classical-quantum approach for image classification. Through experi-ments on MNIST and CIFAR-10 datasets, QNL-Net models demonstrated competitive performance in binary classifica-tion tasks, using fewer qubits compared to traditional quan-tum classifiers. The use of fundamental quantum techniques like entanglement and rotation gates proved effective in cap-turing intricate spatial dependencies critical for image analy-sis.\nHowever, QNL-Net exhibits limitations in multi-class classi-fication and efficiency with larger, complex datasets due to re-liance on classical preprocessing methods. These challenges underscore the need to explore future work on innovative QNL-Net variants and optimization techniques. Additionally, exploring the integration of more efficient quantum encoding strategies might also enhance performance.\nIn conclusion, QNL-Net promises advancements in accu-racy and efficiency for image classification tasks, with poten-tial transformative impacts in fields requiring robust pattern recognition, such as medical imaging and real-time video analysis. Its ability to operate with reduced computational resources compared to classical and existing quantum meth-ods positions QNL-Net as a scalable solution for quantum-enhanced machine learning applications, laying the ground-work for broader use in practical applications."}, {"title": "Supplementary Material: Technical Appendix", "content": "Quantum computing leverages the fundamentals of quantum mechanics, such as superposition and entanglement, to in-troduce new properties to computing. It uses the concept of qubits that have the computational basis states |0\\rangle and |1\\rangle, which can also be represented as\n|0\\rangle = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} , |1\\rangle = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}. (17)\nA qubit is a linear combination of these basis states, which is the general principle of superposition, and can be represented as a vector in a two-dimensional complex Hilbert space, such that,\n|\\psi\\rangle = \\alpha |0\\rangle + \\beta |1\\rangle, (18)\nwhere $\\alpha, \\beta \\in \\mathbb{C}$ are the complex coefficients of the quantum states |0\\rangle and |1\\rangle respectively. The probabilities of the qubit being in state |0\\rangle or |1\\rangle are given by the magnitude squared of these coefficients $|\\alpha|^2$ and $|\\beta|^2$. These probability amplitudes satisfy the normalization condition $|\\alpha|^2 + |\\beta|^2 = 1$.\nEntanglement is another quantum phenomenon where the states of two or more qubits become interconnected, and the state of one qubit affects the other entangled qubits. This also demonstrates that the states cannot be factored into a product of individual qubit states as they are strongly correlated (i.e., $|\\Psi_{AB}\\rangle \\neq |\\Psi_{A}\\rangle |\\psi_{B}\\rangle$ for states A and B).\nThe first step to any quantum computation is encoding clas-sical data into quantum states. To achieve this, several fun-damental encoding techniques are used: (i) Basis encoding maps classical bits 0 and 1 to states |0\\rangle and |1\\rangle directly, and therefore each classical bit string is encoded as the corre-sponding quantum state; (ii) Amplitude encoding uses the amplitudes of a quantum state to represent classical data such that the sum of the squared amplitudes of the quantum state is normalized to 1 for the classical data; (iii) Phase encoding maps classical information to the phases of a quantum state and is used in the proposed QNL-Net mechanism.\nQuantum computations are performed primarily by ma-nipulating quantum states through unitary transformations, achieved using quantum gates. Hadamard (H) gate is used to attain an equal superposition of the two basis states. The H gate maps the basis state |0\\rangle to $\\frac{|0\\rangle+|1\\rangle}{\\sqrt{2}}$ and the basis state |1\\rangle to $\\frac{|0\\rangle-|1\\rangle}{\\sqrt{2}}$. Rotation gates ($R_x, R_y, R_z$) rotate the state of a qubit around a specified axis on the Bloch sphere. A Phase (P) gate shifts the phase of a qubit by a specified an-gle $\\phi$ such that applying P($\\phi$) to $|\\psi\\rangle$ in eq.(18) results in $P(\\phi) |\\psi\\rangle = \\alpha |0\\rangle + \\beta e^{i\\Phi} |1\\rangle$. A CNOT (CX gate) is a two-qubit gate that flips the state of the second qubit (target) only if the first qubit (control) is |1\\rangle. The following are the matrix representations of the relevant gates utilized in this work:\n$H = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}, P(\\phi) = \\begin{bmatrix} 1 & 0 \\\\ 0 & e^{i\\phi} \\end{bmatrix}$ (19)\n$R_x(\\theta) = \\begin{bmatrix} \\cos(\\frac{\\theta}{2}) & -i \\sin(\\frac{\\theta}{2}) \\\\ -i \\sin(\\frac{\\theta}{2}) & \\cos(\\frac{\\theta}{2}) \\end{bmatrix}$ (20)\n$R_y(\\theta) = \\begin{bmatrix} \\cos(\\frac{\\theta}{2}) & - \\sin(\\frac{\\theta}{2}) \\\\ \\sin(\\frac{\\theta}{2}) & \\cos(\\frac{\\theta}{2}) \\end{bmatrix}$ (21)\n$R_z(\\theta) = \\begin{bmatrix} e^{-i\\frac{\\theta}{2}} & 0 \\\\ 0 & e^{i\\frac{\\theta}{2}} \\end{bmatrix}, CX = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\end{bmatrix}$ (22)\nWe use the Convolutional Neural Network (CNN) architec-ture in combination with our QNL-Net Module because CNN is adept at capturing spatial dependencies and identifying lo-cal patterns within complex image data through convolutional and pooling layers, which reduce the input dimensionality while retaining essential features (O'shea and Nash 2015). In the proposed CNN-QNL-Net architecture, we start with two convolutional layers, each with an activation function and max pooling, for an input image tensor $X \\in \\mathbb{R}^{W\\times H\\times C}$, where $W$ is the width, $H$ is the height, and $C$ is the number of channels (i.e. 1 for grayscale images and 3 for RGB images) of the input image. In general, mathematically, a convolution operation '*' for an input image I and a filter K to output a feature map F looks like,\n$F[i, j] = (I * K)[i,j];$ (23)\n$F[i, j] = \\sum_{m=0}^{M-1}\\sum_{n=0}^{N-1}\\sum_{c=0}^{C-1} I[i+m,j+n,c]\\cdot K[m,n,c],$ (24)\nwhere i, j are positions in the output feature map F, m, n are positions in the filter K for channel c, and M, N, and $C$ are the width, height, and number of channels of the filter respec-tively. The first convolutional layer applies a 2D convolution operation with $K_1$ filters (or kernels) of size 5 $\\times$ 5 resulting in $K_1$ output channels, and is defined as,\n$\\displaystyle Y[k] = \\sum_{c=1}^{C} X[c] * W[k] + b[k], k = 1, ..., K_1,$ (25)\nwhere $W[k]$ is the k-th filter weight and $b[k]$ is the bias term. We apply the activation function ReLU, which simply elim-inates the negative values in an input vector and is defined as ReLU(x) = max(0, x), on each filter element-wise such that,\n$A[k] = ReLU(Y[k]), A\\in \\mathbb{R}^{W_1\\times H_1\\times K_1},$ (26)\nwhere $W_1$ and $H_1$ are the width and height after convolution. Then, we apply a max pooling operation with a pool size of 2 x 2 on the Convolution + ReLU layer to obtain the pooled tensor P, which reduces the spatial dimensions of"}, {"title": "PCA-QNL-Net", "content": "Principal Component Analysis is another linear dimensional-ity reduction technique that is suitable for linearly separable datasets used in this study. It uses Singular Value Decompo-sition (SVD) of the data to project it to a lower dimensional space. PCA proves to be computationally efficient and easy to compute compared to a technique like CNN. It does provide some disadvantages by losing some patterns and informa-tion in the data when reducing its dimensionality (Jolliffe and Cadima 2016). In the PCA-QNL-Net architecture, our input data matrix is $X \\in \\mathbb{R}^{N\\times P}$, where N is the number of samples in the dataset and P is the total number of pixels per image. Before applying the SVD, the input data is centered for each feature, such that,\n$\\mu = \\frac{1}{N}\\sum_{i=1}^{N} X_i$ (34)\n$\\widetilde{X} = X - 1\\mu^T$ (35)\nwhere $\\mu$ is the calculated mean vector of the data, 1 is an N-dimensional vector of ones, and $\\widetilde{X}$ is the centered input data matrix. We perform SVD on this centered matrix to decompose it into several component matrices with various interesting properties (Brunton and Kutz 2022),\n$X = U \\Sigma W^T$ (36)\nwhere $U \\in \\mathbb{R}^{N\\times N}$ is a matrix with each of its columns being a length-N orthogonal unit vector or the left singular vector of X, $\\Sigma \\in \\mathbb{R}^{N\\times P}$ is a diagonal matrix composed of singular values of X, and $W \\in \\mathbb{R}^{P\\times P}$ is a matrix with each of its columns being a length-P orthogonal unit vector or the right singular vector of X. We project the centered data matrix onto the principal components by selecting the desired L number of columns (or principal components, i.e., 4 in this case) of W, such that,\n$Z = XW_L$ (37)\nwhere $Z \\in \\mathbb{R}^{N\\times L}$ is the desired reduced form of the data. This matrix is standardized to have zero mean and unit variance,\n$\\hat{Z} = \\frac{Z - \\mu_z}{\\sigma_z}$ (38)\nwhere $\\mu_z$ and $\\sigma_z$ are the mean and standard deviation of Z respectively. $\\hat{Z}$ is a reduced vector of size L x 1 (i.e. 4 x 1) and is then passed to a fully connected layer, such that,\n$H_3 = W_3 Z + b_3$ (39)\nwhere $W_3$ is the weight matrix and $b_3$ is the bias vector. Finally, $H_3 \\in \\mathbb{R}^{4\\times 1}$ can be fed directly to the QNL-Net for further processing."}, {"title": "Loss Convergence Analysis", "content": "In the QNL-Net framework, a hybrid gradient backpropa-gation approach is used to train our model effectively. This approach comprises optimizing both the classical parameters in neural nets and the set of trainable parameters, which are the angles of quantum gates in VQCs. This hybrid training approach first applies a forward pass to optimize parameters and converge the loss function. Our model uses the negative log-likelihood (NLL) loss function for the binary classifica-tion problem. The NLL loss measures the variation between the true labels y and the classical predicted probabilities $\\hat{y} = [\\hat{y_0}, \\hat{y_1}] = p(y|x; \\theta)$ obtained from the measurement of the hybrid classical-QNL-Net model, and is defined for binary classification as:\n$\\mathcal{L}(\\theta, \\phi) = - \\sum_{i=1}^{n} (y_i log \\hat{y}_{i1} + (1 - y_i) log \\hat{y}_{i0})$ (40)"}, {"title": "Datasets", "content": "MNIST (Deng 2012) is a handwritten digit recognition dataset used for many machine learning and computer vi-sion tasks. Each image in MNIST is a grayscale 28 x 28-pixel representation of handwritten digits ranging from 0 to 9. The MNIST dataset contains 60,000 training samples used to train models and 10,000 testing samples used to evaluate model performance. These samples are handwritten by various in-dividuals, covering a lot of variations and styles, ideal for machine learning.\nCIFAR-10 (Krizhevsky, Hinton et al. 2009) is another widely-used benchmark dataset in the field of computer vision. It presents a collection of 32 x 32 size RGB images distributed across ten classes, including images of objects such as air-planes, cars, birds, cats, etc. The dataset contains a total of 50,000 training samples (5000 training samples per class) and 10,000 testing samples (1000 testing samples per class). Its diverse set of classes, coupled with variations in lighting, angle, and pose within images, makes it a suitable dataset for evaluating the robustness and generalization capability of image classification models."}]}