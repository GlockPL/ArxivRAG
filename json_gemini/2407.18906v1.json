{"title": "A Scalable Quantum Non-local Neural Network for Image Classification", "authors": ["Sparsh Gupta", "Debanjan Konar", "Vaneet Aggarwal"], "abstract": "Non-local operations play a crucial role in computer vision enabling the capture of long-range dependencies through weighted sums of features across the input, surpassing the constraints of traditional convolution operations that focus solely on local neighborhoods. Non-local operations typically require computing pairwise relationships between all elements in a set, leading to quadratic complexity in terms of time and memory. Due to the high computational and memory demands, scaling non-local neural networks to large-scale problems can be challenging. This article introduces a hybrid quantum-classical scalable non-local neural network, referred to as Quantum Non-Local Neural Network (QNL-Net), to enhance pattern recognition. The proposed QNL-Net relies on inherent quantum parallelism to allow the simultaneous processing of a large number of input features enabling more efficient computations in quantum-enhanced feature space and involving pairwise relationships through quantum entanglement. We benchmark our proposed QNL-Net with other quantum counterparts to binary classification with datasets MNIST and CIFAR-10. The simulation findings showcase our QNL-Net achieves cutting-edge accuracy levels in binary image classification among quantum classifiers while utilizing fewer qubits.", "sections": [{"title": "Introduction", "content": "Computer vision has become a cornerstone of artificial intelligence, consisting of a wide array of applications such as autonomous driving (Bao et al. 2023), medical imaging (Li et al. 2023), healthcare (Zhou et al. 2022), etc. An essential task in this domain is image classification, where the goal is to assign a label to an image based on its visual significance. This task also builds upon more complex applications such as image segmentation (Minaee et al. 2021), object detection (Amjoud and Amrouch 2023; Fu et al. 2023), and scene understanding (Naseer, Khan, and Porikli 2018). Image classification approaches have been significantly advanced by Convolutional Neural Networks (CNNs) (O'shea and Nash 2015), which achieve state-of-the-art performance on datasets like ImageNet (Krizhevsky, Sutskever, and Hinton 2012). However, CNNs are limited by their local receptive fields, which restricts them from capturing broader contextual information and long-range dependencies within an image. To overcome these limitations, non-local neural networks were introduced to capture long-range dependencies in data, an extension of the self-attention mechanism used in Transformer architectures (Vaswani et al. 2017). Initially proposed for computer vision applications by (Wang et al. 2018), non-local neural networks capture global context effectively and have shown significant improvements in computer vision tasks that benefit from modeling long-range dependencies.\nParallel to these advancements, quantum machine learning (QML) (Biamonte et al. 2017) has emerged as a revolutionary technology built upon the principles of quantum mechanics, which describes the behavior and nature of atoms at the smallest fundamental level and applies them to machine learning. In classical computing, information only exists in bits, which are 0 or 1. In contrast, quantum computing introduces the concept of qubits that can have quantum states |0\\rangle and |1\\rangle simultaneously, taking advantage of the concept of superposition and introducing features such as quantum parallelism (Nielsen and Chuang 2001). Theoretically, this allows for speeding up computations and devising algorithms that can solve complex challenges more efficiently compared to classical computing where computation might be expensive and inefficient, and potentially revolutionize fields like pattern recognition and image classification, optimization (Abbas et al. 2023), cryptography (Bernstein and Lange 2017), etc. QML also introduces algorithms for classification problems such as QSVM, Quantum Kernel methods, Variational Quantum Classifiers (VQC), etc. VQC is a particularly interesting approach within QML because it lets us combine classical and quantum computing to use a quantum circuit as the core algorithm consisting of quantum gates that can be parameterized (Benedetti et al. 2019; Peddireddy, Bansal, and Aggarwal 2023). These parameters can be optimized using classical methods, enabling the model to be trained with a hybrid quantum-classical approach, which we utilize in our work. Researchers have still been trying to understand whether QML offers a significant advantage to classical machine learning theoretically and practically, and it has been an active field of research for long (Biamonte et al. 2017). A sub-domain in this field, Quantum Neural Networks (QNNs), has been developed intensively to determine whether these are capable of outperforming classical neural networks. It was also recently explored in (Abbas et al. 2021) by performing simulations on actual quantum hardware and proving that QML does, in fact, offer several advantages. However, a few challenges exist due to insufficient capabilities for faulttolerance, still-evolving quantum error correction techniques, and quantum scalability, which presents an avenue for revolutionary research in this field and transitioning to a new era of quantum computing from the present noisy intermediate-scale quantum (NISQ) era (Preskill 2018; Gujju, Matsuo, and Raymond 2024). The present challenges limit the practical applications of QML algorithms. Still, despite that, developing QML research and devising new quantum algorithms offers an outlet to test methodologies as a proof-of-concept on a smaller scale and deploy applications in the future while we approach scalable quantum processors.\nIn this context, our paper proposes a Quantum Non-local Neural Network (QNL-Net), which combines the principles of quantum computing with the non-local neural network mechanism. By leveraging quantum entanglement, the QNL-Net can establish non-local correlations between qubits, mimicking the behavior of classical non-local operations while exploiting the advantages of quantum mechanics to enhance machine learning performance and capabilities. This paper aims to improve pattern recognition and binary classification tasks in computer vision by capturing long-range dependencies more effectively. The main contributions of this paper are:"}, {"title": "Related Work", "content": "Image classification using quantum machine learning (QML) became an area of significant interest due to its potential advantages over classical methods. One notable approach was Quantum Convolutional Neural Networks (QCNNs), which utilized quantum circuits to implement convolutional operations, focusing on quantum phase recognition and quantum error correction optimization techniques (Cong, Choi, and Lukin 2019). Another significant development was the Quanvolutional Neural Network, introduced by (Henderson et al. 2020) in 2019, which employed quantum convolution (quanvolutional) layers. These layers transformed classical data using random quantum circuits to extract features, akin to the feature extraction process in classical CNNs. Their results demonstrated superior accuracy and training performance compared to classical CNNs. QML models have also shown efficacy in binary classification tasks for noisy datasets and images (Schetakis et al. 2022). Additionally, recent work by (Cherrat et al. 2024) developed an approach for loading matrices as quantum states and introducing trainable quantum orthogonal layers adaptable to different quantum computer capabilities. This method yielded promising results on superconducting quantum computers.\nSeveral works also explored the application of quantum neural networks for binary classification tasks in computer vision, providing benchmarks for our results. QTN-VQC (Qi, Yang, and Chen 2023) built a framework with quantum circuits for tensor-train networks integrated with variational quantum circuits for an efficient training pipeline. Another work introduced hierarchical quantum classifiers (Grant et al. 2018), which utilized several expressive circuits to classify highly entangled quantum states and demonstrated robustness to noise. A scalable approach for quantum neural networks (SQNNs) for classification was discussed in (Wu, Tao, and Li 2022), where authors proposed a strategy to use multiple small-scale quantum devices to extract local features and perform prediction over these collected features. (Jiang, Xiong, and Shi 2021) presented the QuantumFlow model, which represented data as unitary matrices to achieve quantum advantage, reducing the cost complexity of unitary matricesbased neural computation. These recent advancements in QML models demonstrated robustness in image classification, making them suitable for handling higher-dimensional data more effectively than their classical counterparts."}, {"title": "Non-local Neural Networks", "content": "Traditional convolution operations in convolutional neural networks (CNNs), a popular choice for computer vision models, process a local neighborhood, and applying these operations repeatedly to capture long-range dependencies causes incremental growth in the receptive field. This has several drawbacks associated with computational inefficiency and difficulties in optimization. Non-local neural networks address these limitations by introducing non-local operations that compute the response at a position as a weighted sum of the features at all positions in the input. These are simple operations that are highly efficient and generic in capturing long-range dependencies, which is of utmost importance in computer vision (Wang et al. 2018).\nA generic non-local operation for an input signal's (image, sequence, video) feature map $x \\in \\mathbb{R}^{N \\times C}$, where N is the number of positions (i.e. pixels) and C is the number of channels, can be defined as:\n$\\displaystyle Y_i = \\frac{1}{C(x)} \\sum_{\\forall j} f(x_i, x_j)g(x_j), \\qquad (1)$\nwhere i is the index of an output position (in space/time/spacetime) whose response is to be computed, j enumerates over all possible positions, and y is the output signal. f is a pairwise function that computes a scalar representing the relationship (such as similarity) between i and all j. g is a unary function that computes a representation of the input signal at j and normalizes it by a factor $C(x)$.\nIn terms of the functions, g is simply considered as a linear embedding such that $g(x_i) = W_g x_j$, where $W_g$ is a learned weight matrix. There are several choices for the pairwise function f such as:\n1. Gaussian:\n$\\displaystyle f(x_i, x_j) = e^{x_i^T x_j}, \\quad C(x) = \\sum_{\\forall j} f(x_i, x_j);$\n2. Embedded Gaussian:\n$\\displaystyle f(x_i, x_j) = e^{\\theta(x_i)^T \\phi(x_j)}, \\quad C(x) = \\sum_{\\forall j} f(x_i, x_j);$\nwhere $\\theta(x_i) = W_\\theta x_i$ and $\\phi(x_j) = W_\\phi x_j$ are linear embeddings. This also relates to self-attention (as explored in (Vaswani et al. 2017)), which non-local networks are just an extension of in the computer vision domain, or more specifically, a generic space or spacetime domain. This is due to the fact that for any i, $\\frac{1}{C(x)} f (x_i, x_j)$ becomes the softmax computation along the dimension j.\n3. Dot Product:\n$\\displaystyle f(x_i, x_j) = \\theta(x_i)^T \\phi(x_j), \\quad C(x) = N;$\nwhere N is the number of positions in x.\n4. Concatenation:\n$\\displaystyle f(x_i, x_j) = \\text{ReLU}(w^T [\\theta(x_i), \\phi(x_j)]), \\quad C(x) = N;$\nA non-local block in spacetime encapsulates the non-local operation in eq.(1) elegantly and can be defined as:\n$\\displaystyle Z_i = W_y y_i + x_i \\qquad (2)$\nwhere $y_i$ is the non-local operation and residual connection '+ $x_i$' allows integrating the non-local block into any pre-trained model without disruptions in their initial behavior (He et al. 2016)."}, {"title": "Quantum Non-local Neural Network", "content": "In this work, we introduce the Quantum Non-Local Neural Network (QNL-Net), which utilizes trainable quantum circuits to implement non-local operations, effectively capturing and processing long-range dependencies in input data. The QNL-Net module integrates with classical dimensionality reduction techniques to function as a hybrid quantum-classical classifier. In this section, we first delve into the design and implementation of the QNL-Net module. Next, we discuss the integration of classical dimensionality reduction techniques with the QNL-Net to create a hybrid classifier, highlighting the CNN-QNL-Net and PCA-QNL-Net models. Finally, we cover the post-QNL-Net classical computation.\nThe QNL-Net mechanism translates classical non-local operations into quantum circuits, enabling the network to exploit the parallelism and entanglement properties of quantum computing. This translation involves designing quantum gates and circuits that can replicate the functionality of classical non-local layers, allowing the network to analyze complex data structures more efficiently. To encode the classical data $X \\in \\mathbb{R}^d$ into the quantum space where $X = [y_0, y_1,\\dots, y_k]$, we utilize Qiskit's ZFeatureMap (Kanazawa et al. 2023) (as one can see in Fig. 1) which takes advantage of the quantumenhanced feature space, providing a quantum advantage to classification problems (Havl\u00ed\u010dek et al. 2019). The feature map $\\Phi$ acts as $\\Phi : X \\rightarrow |\\psi_\\Phi \\rangle$, where the feature space $|\\psi_\\Phi \\rangle$ is an n-qubit Hilbert space, such that\n$\\displaystyle |\\psi_\\Phi \\rangle = (U_\\Phi^+(y_k) H^{\\otimes n})^r |0^n \\rangle, \\quad 0 \\le k \\le N - 1, \\qquad (3)$\nwhere r is the depth or the number of repetitions of the feature map, $H^{\\otimes n}$ is a layer of Hadamard gates acting on all n qubits, and N denotes the number of input vectors in a data sample. $U_\\Phi$ is the encoding ansatz used in the feature map composed of single-qubit phase-shift ($P_x$) gates for rotation about the Z-axis,\n$\\displaystyle U_\\Phi(X) = \\prod_{k=1}^n P_{2*y_k} \\qquad (4)$\nWe utilize variational quantum circuits in this mechanism, which can be trained classically to optimize trainable parameters using a predefined cost function (Benedetti et al. 2019). This hybrid quantum-classical approach leverages the expressive power of quantum circuits while making use of classical optimization techniques for efficient parameter tuning. We implement three different ansatzes with five parameterized rotation gates in each, enabling fine-grained control over the quantum state. These three ansatz each have three CX gates with distinct configurations, introducing entanglementinduced correlations between the qubits and ensuring that the quantum state captures the non-local dependencies in the data. The quantum circuits for the ansatzes are presented in Fig. 2."}, {"title": "Quantum Simulation", "content": "In our experiments, we utilize two widely used image processing datasets for image classification: MNIST (Deng 2012) and CIFAR-10 (Krizhevsky, Hinton et al. 2009) (sample images are shown in the Appendix in Fig. 5). For MNIST, we focus on binary classification using the digits 0 and 1, comprising 12,665 training samples and 2,115 testing samples. For CIFAR-10, we perform binary classification using classes 2 (birds) and 8 (ships). Before feeding the images into the models, we normalize them using the global mean and standard deviation of each dataset, scaling pixel values from [0, 255] to [0, 1]."}, {"title": "Simulation Settings", "content": "The experiments are conducted on a MacBook Pro with an M2 Max chip and 64GB RAM. The QNL-Net network is implemented by utilizing the EstimatorQNN module of Qiskit Machine Learning 0.7.2 and Qiskit 1.1.0, which facilitates the encoding of classical data into quantum data and enables the training of the ansatz. The classical node is constructed, and gradient optimization is performed using PyTorch 2.3.0, which connects seamlessly with the EstimatorQNN module. The models are trained for 100 epochs with a batch size of 1 using the negative log-likelihood (NLL) loss function for convergence. The Adam optimizer (Kingma and Ba 2014) is configured with different learning rates, which vary between 0.0001 to 0.0004 depending upon the model and the ansatz used as listed in Appendix Table 1. The ExponentialLR scheduler (Li and Arora 2019) uses a $\\gamma$ decay rate of 0.9. The rest of the parameters are set to default."}, {"title": "Simulation Results", "content": "The experiments were conducted using different combinations of feature map repetitions r = 1, 2, or 3 and the number of ansatz repetitions D = 1, 2 or 3. The accuracies reported are averaged for all runs for each specific ansatz and model configuration, as shown in Appendix Table 1.\nThe results on the MNIST dataset for classes 0 and 1 indicate that the CNN-QNL-Net model performs slightly better than the PCA-QNL-Net model, achieving a near-perfect average classification test accuracy of 99.96% whereas the PCA-QNL-Net achieved a test accuracy of 99.59%. Ansatz0 and Ansatz-2 generally yield better results compared to Ansatz-1 for this dataset, as evident in Appendix Table 1. For the CIFAR-10 dataset, the hybrid-QNL-Net models perform comparatively worse than the MNIST due to the introduction of three color channels (i.e., RGB) compared to MNIST's grayscale images. However, the CNN-QNL-Net was still able to obtain an average test accuracy of 93.98%. Ansatz-1 performs better on the testing dataset for CIFAR-10 compared to the other ansatzes. On both datasets, the CNN-QNL-Net significantly outperforms the PCA-QNL-Net due to its ability to efficiently extract features from the dataset before feeding them to the QNL-Net module.\nIncreasing the depth of both the feature map and the ansatzes (i.e., r and D, respectively) generally improved classification accuracies due to the increased expressiveness of the circuit. However, it also resulted in longer training times compared to using fewer repetitions, which still obtained reasonably good results within the bounds reported in Appendix Table 1. Furthermore, PCA-QNL-Net models required higher learning rates to obtain convergence than the CNN-QNL-Net models. The PCA-QNL-Net demonstrated faster training compared to the CNN-QNL-Net, as CNNs add an overhead for training parameters, utilizing a total of 34,282 classical parameters on MNIST and 41,314 classical parameters on CIFAR-10. The PCA-QNL-Net, however, optimizes only 22 classical parameters from the linear layers, offering an advantage in terms of classical training efficiency."}, {"title": "Discussion", "content": "The novelty of the QNL-Net architecture lies in its efficient utilization of fewer qubits, a critical consideration in the NISQ era. However, its significance extends beyond that to take into account the fundamental principles of quantum mechanics, particularly in its treatment of rotations around axes and entanglement. TThe choice of rotation gates in the QNLNet ansatzes is tied to the fundamental idea behind non-local neural networks, which aim to capture intricate spatial dependencies within the data. In the quantum paradigm, rotation gates achieve this by translating quantum states around different axes, thereby implementing spatial transformations.\nNow, for simplification, consider the raw data x and the three embeddings ($\\theta$, $\\phi$, g) in the non-local neural net architecture as akin to the four features passed on to the QNL-Net circuit. In non-local neural nets, raw data is not embedded, but in this work, we utilize rotation around the z-axis primarily because it allows us to maintain a trainable parameter on qubit 0 after the feature map encoding which ensures the consistency and completeness of quantum theory while not affecting the measurement initially. The $R_y$ gates around qubits 1 and 2 for embeddings $\\theta$ and $\\phi$, respectively, is crucial. These gates induce phase shifts in the states of the corresponding qubits, playing a vital role in generating interference effects and complex quantum states. Additionally, they facilitate capturing relative phase information, which is pivotal in discerning subtle patterns within the data. The linear embedding g translates to qubit 3, where an $R_x$ gate modifies the probability amplitudes of states |0\\rangle and |1\\rangle, fine-tuning the data representation within the quantum circuit.\nA key advantage of QNL-Net is leveraging quantum entanglement. While classical non-local blocks typically involve matrix multiplications within the embeddings and elementwise summation with the raw data, the QNL-Net utilizes the intrinsic significance of CNOT entanglements to replicate variable dependencies present in classical non-local mechanisms. This creates a highly interconnected system between all qubits, effectively extracting intricate probabilities and facilitating the exploration of complex data structures in a quantum framework. As we can infer from the results, it does not matter significantly what the specific pattern for entanglement is in different ansatz, rather the idea that all qubits encompassing different rotations are entangled together. Then, further applying another $R_z$ gate on qubit 0, which is already in a highly entangled state, introduces additional phase modulation within the entangled system. This modulation is crucial for fine-tuning the quantum state before measurement, thereby influencing the outcome probabilities."}, {"title": "Conclusion", "content": "This paper introduced the Quantum Non-local Neural Networks (QNL-Net) mechanism as a novel hybrid classicalquantum approach for image classification. Through experiments on MNIST and CIFAR-10 datasets, QNL-Net models demonstrated competitive performance in binary classification tasks, using fewer qubits compared to traditional quantum classifiers. The use of fundamental quantum techniques like entanglement and rotation gates proved effective in capturing intricate spatial dependencies critical for image analysis.\nHowever, QNL-Net exhibits limitations in multi-class classification and efficiency with larger, complex datasets due to reliance on classical preprocessing methods. These challenges underscore the need to explore future work on innovative QNL-Net variants and optimization techniques. Additionally, exploring the integration of more efficient quantum encoding strategies might also enhance performance."}, {"title": "Datasets", "content": "MNIST (Deng 2012) is a handwritten digit recognition dataset used for many machine learning and computer vision tasks. Each image in MNIST is a grayscale 28 x 28-pixel representation of handwritten digits ranging from 0 to 9. The MNIST dataset contains 60,000 training samples used to train models and 10,000 testing samples used to evaluate model performance. These samples are handwritten by various individuals, covering a lot of variations and styles, ideal for machine learning.\nCIFAR-10 (Krizhevsky, Hinton et al. 2009) is another widelyused benchmark dataset in the field of computer vision. Itpresents a collection of 32 x 32 size RGB images distributedacross ten classes, including images of objects such as airplanes, cars, birds, cats, etc. The dataset contains a total of50,000 training samples (5000 training samples per class)and 10,000 testing samples (1000 testing samples per class).Its diverse set of classes, coupled with variations in lighting,angle, and pose within images, makes it a suitable datasetfor evaluating the robustness and generalization capability ofimage classification models."}, {"title": "Supplementary Material: Technical Appendix", "content": "Quantum computing leverages the fundamentals of quantummechanics, such as superposition and entanglement, to in-troduce new properties to computing. It uses the concept ofqubits that have the computational basis states |0\\rangle and |1\\rangle,which can also be represented as\n|0\\rangle = \\begin{bmatrix} 1\\\\ 0 \\end{bmatrix}, |1\\rangle = \\begin{bmatrix} 0\\\\ 1 \\end{bmatrix}. \\qquad (17)\nA qubit is a linear combination of these basis states, which isthe general principle of superposition, and can be representedas a vector in a two-dimensional complex Hilbert space, suchthat,\n|\\psi\\rangle = \\alpha |0\\rangle + \\beta |1\\rangle, \\qquad (18)\nwhere $\\alpha, \\beta \\in \\mathbb{C}$ are the complex coefficients of the quantumstates |0\\rangle and |1\\rangle respectively. The probabilities of the qubitbeing in state |0\\rangle or |1\\rangle are given by the magnitude squared ofthese coefficients $|\\alpha|^2$ and $|\\beta|^2$. These probability amplitudesatisfy the normalization condition $|\\alpha|^2 + |\\beta|^2 = 1$.\nEntanglement is another quantum phenomenon where thestates of two or more qubits become interconnected, and thestate of one qubit affects the other entangled qubits. This alsodemonstrates that the states cannot be factored into a productof individual qubit states as they are strongly correlated (i.e.,$\\psi_{AB}\\rangle \\neq |\\psi_{A}\\rangle |\\psi_{B}\\rangle$ for states A and B).\nThe first step to any quantum computation is encoding clas-sical data into quantum states. To achieve this, several fun-damental encoding techniques are used: (i) Basis encodingmaps classical bits 0 and 1 to states |0\\rangle and |1\\rangle directly, andtherefore each classical bit string is encoded as the corre-sponding quantum state; (ii) Amplitude encoding uses theamplitudes of a quantum state to represent classical data suchthat the sum of the squared amplitudes of the quantum stateis normalized to 1 for the classical data; (iii) Phase encodingmaps classical information to the phases of a quantum stateand is used in the proposed QNL-Net mechanism.\nQuantum computations are performed primarily by ma-nipulating quantum states through unitary transformations,achieved using quantum gates. Hadamard (H) gate is usedto attain an equal superposition of the two basis states. TheH gate maps the basis state |0\\rangle to $\\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}}$ and the basis state|1\\rangle to $\\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}}$. Rotation gates ($R_x, R_y, R_z$) rotate the stateof a qubit around a specified axis on the Bloch sphere. APhase (P) gate shifts the phase of a qubit by a specified angle $\\phi$ such that applying P($\\phi$) to |$\\psi\\rangle$ in eq.(18) results inP($\\phi$) $|\\psi\\rangle = \\alpha |0\\rangle + Be^{i\\Phi} |1\\rangle$. A CNOT (CX gate) is a twoqubit gate that flips the state of the second qubit (target) onlyif the first qubit (control) is |1\\rangle. The following are the matrixrepresentations of the relevant gates utilized in this work:\nH = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1&1\\\\ 1&-1 \\end{bmatrix}, P(\\phi) = \\begin{bmatrix} 1&0\\\\ 0&e^{i\\phi} \\end{bmatrix}  \\qquad (19)\n\\begin{aligned} & R_{x}(\\vartheta)=\\begin{bmatrix} \\cos(\\frac{\\vartheta}{2}) & -isin(\\frac{\\vartheta}{2})\\\\ -isin(\\frac{\\vartheta}{2}) & \\cos(\\frac{\\vartheta}{2}) \\end{bmatrix} & \\qquad (20)\\\\ & R_{y}(\\vartheta)=\\begin{bmatrix} \\cos(\\frac{\\vartheta}{2}) & -sin(\\frac{\\vartheta}{2})\\\\ -sin(\\frac{\\vartheta}{2}) & \\cos(\\frac{\\vartheta}{2}) \\end{bmatrix} & \\qquad (21)\\\\ & R_{z}(\\vartheta)=\\begin{bmatrix} e^{-i \\frac{\\vartheta}{2}} & 0\\\\ 0 & e^{i \\frac{\\vartheta}{2}} \\end{bmatrix} & \\end{aligned}\nCX = \\begin{bmatrix} 1 & 0 & 0 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 0 & 1\\\\ 0 & 0 & 1 & 0 \\end{bmatrix}  \\qquad (22)"}, {"title": "CNN-QNL-Net", "content": "We use the Convolutional Neural Network (CNN) architecture in combination with our QNL-Net Module because CNNis adept at capturing spatial dependencies and identifying local patterns within complex image data through convolutionaland pooling layers, which reduce the input dimensionalitywhile retaining essential features (O'shea and Nash 2015).\nIn the proposed CNN-QNL-Net architecture, we start withtwo convolutional layers, each with an activation functionand max pooling, for an input image tensor $X \\in \\mathbb{R}^{W\\times H\\times C}$,where W is the width, H is the height, and C is the number ofchannels (i.e. 1 for grayscale images and 3 for RGB images)of the input image. In general, mathematically, a convolutionoperation '*' for an input image I and a filter K to output afeature map F looks like,\nF[i, j] = (I * K)[i,j]; \\qquad (23)\n$\\displaystyle F[i, j] = \\sum_{m=0}^{M-1}\\sum_{n=0}^{N-1}\\sum_{c=0}^{C-1} I[i+m,j+n,c] \\cdot K[m,n,c],  \\qquad (24)\nwhere i, j are positions in the output feature map F, m, n arepositions in the filter K for channel c, and M, N, and Carethe width, height, and number of channels of the filter respectively. The first convolutional layer applies a 2D convolutionoperation with $K_1$ filters (or kernels) of size 5 \u00d7 5 resultingin $K_1$ output channels, and is defined as,\n$Y[k] = \\sum_{c=1}^{C}X[c] * W[k] + b[k],  k = 1, ..., K_1, \\qquad (25)$\nwhere W[k] is the k-th filter weight and b[k] is the bias term.We apply the activation function ReLU, which simply eliminates the negative values in an input vector and is definedas ReLU(x) = max(0, x), on each filter element-wise suchthat,\n$A[k] = \\text{ReLU}(Y[k]),   A \\in \\mathbb{R}^{W_1\\times H_1\\times K_1}, \\qquad (26)$\nwhere $W_1$ and $H_1$ are the width and height after convolution.Then, we apply a max pooling operation with a pool sizeof 2 x 2 on the Convolution + ReLU layer to obtain thepooled tensor P, which reduces the spatial dimensions of each channel by selecting the maximum value within eachpool, such that,\nP[k] = \\text{MaxPool}(A[k]),  P \\in \\mathbb{R}^{W_2\\times H_2\\times K_1}, \\qquad (27)\nwhere $W_2 = \\frac{W_1}{2}$ and $H_2 = \\frac{H_1}{2}$. This Convolution + ReLU +MaxPool layer combination is repeated again on P for furtherfeature reduction with $K_2$ filters of size 5 \u00d7 5, and we obtain,\n$Z[k] = \\sum_{c=1}^{K_1}P[c] * W[k]+b[k],  k = 1, ..., K_2;  \\qquad (28)$\n$B[k] = \\text{ReLU}(Z[k]),   B \\in \\mathbb{R}^{W_3\\times H_3\\times K_2}, \\qquad (29)$\nwhere $W_3$ and $H_3$ are the width and height after the secondconvolution. Again, we apply the max pooling operation witha pool size of 2 \u00d7 2 on the previous layer,\nQ[k] = \\text{MaxPool}(B[k]),   Q \\in \\mathbb{R}^{W_4\\times H_4\\times K_2}, \\qquad (30)$\nwhere $W_4 = \\frac{W_3}{2}$ and $H_4 = \\frac{H_3}{2}$. We apply a Dropout layer(Srivastava et al. 2014) to the resultant pooled tensor Q toprevent overfitting which sets any element of the input to 0during training with probability p, such that,\nD = \\text{Dropout}(Q,p),  p = 0.5. \\qquad (31)\nThen, we flatten the output D to obtain a 1-dimensionalvector F of size ($W_4\\cdot H_4\\cdot K_2$)\\times 1. We apply a fully-connected(FC) layer to this flattened vector F with ReLU activation,which results in,\n$H_1 = \\text{ReLU}(W_1F + b_1),   H_1 \\in \\mathbb{R}^{128\\times 1}, \\qquad (32)$\nwhere $W_1$ is the weight matrix and $b_1$ is the bias vector. FC layers simply apply a linear transformation to an input vector,essential for dimensionality reduction, aggregating scattered patterns across the features, and optimizing parameters (Kocsis et al. 2022). Further, applying a non-linear activationfunction (e.g., ReLU) to a linear transformation enables representing non-linear relationships within the data. Finally, toobtain an output vector $H_2$ with size 4 \u00d7 1, which can bepassed to the QNL-Net module, we apply our last FC layerto the output of $H_1$ such that,\n$H_2 = W_2H_1 + b_2,   H_2 \\in \\mathbb{R}^{4\\times 1}, \\qquad (33)$\nwhere $W_2$ is the weight matrix and $b_2$ is the bias vector."}, {"title": "PCA-QNL-Net", "content": "Principal Component Analysis is another linear dimensionality reduction technique that is suitable for linearly separabledatasets used in this study. It uses Singular Value Decomposition (SVD) of the data to project it to a lower dimensionalspace. PCA proves to be computationally efficient and easy tocompute compared to a technique like CNN. It does providesome disadvantages by losing some patterns and information in the data when reducing its dimensionality (Jolliffeand Cadima 2016). In the PCA-QNL-Net architecture, ourinput data matrix is $X \\in \\mathbb{R}^{N\\times P}$, where N is the number ofsamples in the dataset and P is the total number of pixels perimage. Before applying the SVD, the input data is centeredfor each feature, such that,\n$\\mu = \\frac{1}{N}\\sum_{i=1}^{N}X_i   \\qquad (34)$\n$X = X - 1\\mu^T. \\qquad (35)$\nwhere u is the calculated mean vector of the data, 1 is anN-dimensional vector of ones, and X is the centered inputdata matrix. We perform SVD on this centered matrix todecompose it into several component matrices with variousinteresting properties (Brunton and Kutz 2022),\n$X = USW^T, \\qquad (36)$\nwhere $U \\in \\mathbb{R}^{N\\times N}$ is a matrix with each of its columns beinga length-N orthogonal unit vector or the left singular vectorof X, $\\Sigma \\in \\mathbb{R}^{N\\times P}$ is a diagonal matrix composed of singularvalues of X, and $W \\in \\mathbb{R}^{P\\times P}$ is a matrix with each of itscolumns being a length-P orthogonal unit vector or the rightsingular vector of X. We project the centered data matrixonto the principal components by selecting the desired Lnumber of columns (or principal components, i.e., 4 in thiscase) of W, such that,\n$Z = XW"}]}