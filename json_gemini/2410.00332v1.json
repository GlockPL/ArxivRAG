{"title": "Vision Language Models Know Law of Conservation without Understanding More-or-Less", "authors": ["Dezhi Luo", "Haiyun Lyu", "Qingying Gao", "Haoran Sun", "Yijiang Li", "Hokin Deng"], "abstract": "Conservation is a critical milestone of cognitive development considered to be supported by both the understanding of quantitative concepts and the reversibility of mental operations. To assess whether this critical component of human intelligence has emerged in Vision Language Models, we leverage the ConserveBench from CogDevelop2K, a data-intensive cognitive experiment benchmark for assaying the developmental trajectory of machine intelligence developed by [Li et al., 2024]. The battery includes over 350 questions across four dimensions of physical quantities: volume, solid quantity, length, and number. The former two involve only transformational tasks, whereas the latter two also involve non-transformational tasks assessing the understanding of quantitative concepts alone. Surprisingly, we find that while VLMs are generally capable of conserving, they tend to fail at non-transformational tasks which success is typically considered to be entailed by the ability to conserve. This implies that the law of conservation, at least in concrete domains, may exist without corresponding conceptual understanding of quantity.", "sections": [{"title": "Introduction", "content": "Conservation is the ability required for understanding that physical quantities do not change in amount when they undergo spatial transformations [Piaget, 1965, Halford, 2011, Piaget and Inhelder, 1974, McGarrigle and Donaldson, 1974, Church and Goldin-Meadow, 1986, Goldin-Meadow and Beilock, 2010, Houd\u00e9 et al., 2011]. First studied by Jean Piaget, it is considered a landmark ability during children's cognitive development for it not only signifies the understanding of quantitative concepts in rudimentary, concrete domains, but also lays the foundation for formal, abstract thinking required in advanced cognitive abilities such as mathematical reasoning [Piaget, 1965, 1971, McGarrigle and Donaldson, 1974]. In Piaget's theory of cognitive development, the acquisition of conservation marks children's transition from the pre-operational to the concrete operational stage [Piaget, 1965, Miller, 2016]. The pre-operational stage is characterized by children's reliance on a single attribute of an object while ignoring others when reasoning about the physical world. Piaget posits that this is because their mental representations supporting physical attributes are still isolated and juxtaposed [Piaget, 1952, 1971, Houd\u00e9, 1997]. As these representations stabilized into organized concepts of numerosity, volume, length, and so on, they became supportive of mental operations, which are internalized actions supported by organized logic structures that can be manipulated in systematic ways [Piaget, 1950, Miller, 2016]. Children by then enter what is characterized as the concrete operational stage, when children are able to perform reversible mental operations that allow them to simulate physical transformations, namely conservation."}, {"title": "Methods", "content": ""}, {"title": "Dataset", "content": "We leverage ConserveBench from the CogDevelop2K to build our assay of cognitive experiments to investigate the law of conservation in Vision Language Models. ConserveBench contains 39 multi-image and 326 single-image cognitive experiments."}, {"title": "Cognitive Experiments", "content": "Following classic Piagetian design [Piaget, 1965, Halford, 2011, McGarrigle and Donaldson, 1974, Church and Goldin-Meadow, 1986, Lozada and Carro, 2016], cognitive experiments are separated into four groups, each probing one dimension of physical quantity: number, length, solid quantity, and liquid volume, as shown in Figure 2. In real-life, the conservation tasks consist of the experimenter showing the child the process of physical transformation by hands-on manipulating the objects in front of them. Given that VLMs process visual information on a discrete, frame-by-frame basis, such demonstration of physical transformation is operationalized into three phase: the Initial Phase, the Manipulation Phase, and the End Phase, represented by three images that are consecutively fed to the models. The prompt of the question provides the information that the series of images depicts a continued process, which is mandatory in order to prevent VLMs to directly cross-compare the quantity across images without acknowledging the transformation. Below introduced the tasks for different dimensions separately in details.\n1. Number: Initial Phase depicts two parallel lines of objects aligned perfectly by their\npositions on the lines; Manipulation Phase depicts the experimenter's fingers moving one\nline of objects; End Phase depicts the line of the objects moved being more spread out than\nthe other, whilst the number of coins remains the same. Experiments in virtual setting are\nalso tested.\n2. Length: Initial Phase depicts two linear objects placed parallel to each other and aligned\nperfectly; Manipulation Phase depicts the experimenter's fingers moving one of the linear\nobjects; End Phase depicts the linear object moved misaligned with the other straw. Both\nvirtual and reality settings are tested.\n3. Solid Quantity: Initial Phase depicts a round-shaped piece of play dough; Manipulation\nPhase depicts the experimenter's hand rubbing the play dough; End Phase depicts the play\ndough appearing notably extended.\n4. Liquid Volume: Initial Phase depicts a tall glass partially filled with colored liquid placed\nnext to an empty, shorter glass. Manipulation Phase depicts the experimenter's hand holding\nthe tall glass, pouring the colored water into the short glass. End Phase depicts the short\nglass now partially filled with colored water, while the tall glass next to it is now empty.\nNotably, the prompts (as shown in Figure 2) for Solid Quantity and Liquid Volume are different from that for Number and Length in that the formers ask the quantity to be compared between the"}, {"title": "Model Selection and Experiment", "content": "We evaluate the presence of conservation and rudimentary quantitative understanding in three cate-gories of Visual Language Models (VLMs):\n1. Open-source VLMs with Multi-Image Reasoning: Includes models with different sizes\nand other variants such as CogVLM Series [Hong et al., 2024], Qwen series(Qwen-VL [Bai\net al., 2023], Qwen-2 [Wang et al., 2024]), and Blip2 [Li et al., 2023], LLaVA-Next [Liu\net al., 2024], which are capable of reasoning over interleaved multiple images and texts.\n2. Closed-source VLMs with Multi-Image Reasoning: Includes proprietary models such as\nGPT series [OpenAI] (GPT-4v, GPT-4-turbo, GPT-40-mini), Gemini Series [Gemini],\nand Claude Series [claude]. These models also support reasoning across interleaved images\nand texts,\n3. Open-source VLMs with single-Image Reasoning: Includes models designed to process a\nsingle image alongside continuous text. InstructBlip Series [Dai et al., 2023], LLaVA Series\n[Liu et al., 2023a] [Liu et al., 2023b]\nIn total, we have aligned 60 models. For a fair comparison, all VLMs were tested on our dataset\nusing the same prompt under a zero-shot, open-ended generation task. Detailed documentation of\ninference methodology can be seen in the paper reporting the CogDevelop2K benchmark [Li et al.,\n2024]. We have selected 5 typical models for demonstration here. In order to analyze the reasoning\nabilities of VLMs, we ask the models to explain their answers after they have given the answers."}, {"title": "Results", "content": "On full conservation tasks, VLMs achieve perfect performances across all four types of tasks, each\ntesting one of the four dimensions: number, length, solid quantity, and liquid volume, matching the\nperformances of chilren characterized as Total Conserver. This indicates that VLMs consistently\nrecognize the law of conservation, matching the performance of children classified as Total Conservers\nin the developmental literature. Notably, for the conservation of volume quantity, VLMs produce\nresults that feature the wrong answer choices, but the corresponding reasoning turns out to indicate\na solid understanding of conservation. For example, in the case (Figure 2), GPT-40 answers with\nthe wrong choice (the water in the short glass is not the same as that in the tall glass). However,\nits reasoning clearly shows that it can not only understand the transformation process of pouring\nwater and that the process does not change the quantity of the liquid, but also the fact that there could\nbe \"potential spillage or absorption\" throughout the process, causing the quantity to change, hence\nthe \"wrong\" answer. This ability to not only understand the law of conservation but also being able\nto apply it flexibly in complex, real-life scenarios has rarely, if not never, been documented in the\ndevelopmental literature for tests of conservation. This may be explained by the notion that being able\nto form hypotheses based on highly detailed and rigorous knowledge and apply them in reasoning\n(i.e., the fact that there might be spillage or absorption when moving liquids across containers and\nthat it affects the overall quantity) requires both sophisticated quantitative understanding and the use\nof abstract mental operations, which are beyond the reach of children at the concrete operational\nstage [Piaget, 1971].\nIn contrast, in quantity understanding tasks for number and length dimensions, VLMs perform\nsignificantly poorer in general, exhibiting consistent errors comparable to pre-operational children\nwith extremely limited understanding of quantity. This indicates that VLMs have difficulties in what\nrequires a rudimentary conceptual understanding of quantity, at least in these dimensions, which\nconverges with recent studies reporting that major language models and as well as their corresponding\nvision models fail at simple counting tasks [Rane et al., 2024, Rahmanzadehgervi et al., 2024].\nNotably, however, a particularly surprising finding of the present study is that among the tasks that\nask more-or-less questions (as seen in Figure 3, 5, and 6), VLMs consistently give answers that are\nnot just incorrect but opposite to the typical human fallacy. There are 95 tasks from ConserveBench\nthat specifically probe what is known as the length-equals-number fallacy, which is understood to be\nproduced by the heuristics that longer lines tend to have more objects among them [Houd\u00e9, 1997,\nViarouge et al., 2019]. Said heuristics remain presented in older children and adults as a common\nSystem-1 strategy used in daily life but can be suppressed with a reasonable amount of effort when\nthe task at hand requires [Harnishfeger and Bjorklund, 1990, Poirel et al., 2012]. Children during the\npre-operational stage who fail the number conservation tasks are shown to exhibit significantly low\nactivation in neural pathways associated with the suppression of said fallacy as compared to adults,\nwhich corresponds to the observation that they nearly always tend to demonstrate the length-equals-\nnumber fallacy (as through declaring that a longer, more loosely-spread line of coins contains more\ncoins than a shorter, more densely-spread line) [Houd\u00e9 et al., 2011, Poirel et al., 2012, Viarouge et al.,\n2019]. Here, we show that this is not the case for VLMs. Notably, every quantity understanding task\namong the said 95 tasks that GPT-40 fails is by choosing the choice opposite to what demonstrates the\nlength-equals-number fallacy. The consistency of this phenomenon reveals a significant divergence\nbetween human and VLM reasoning with respect to quantity understanding."}, {"title": "Discussions", "content": "This study aims to provide the first assessment of VLMs' ability to understand the law of conserva-tion and pre-operational concepts of quantity. Our preliminary results show that VLMs appear tobe proficient in conservation across all four dimensions of physical quantity assessed, matching theperformance of children at the concrete operational stage and beyond. Notably, they are further ableto draw abstract concepts and propositions when reasoning about conservation, which demonstratesformal operational skills that are typically associated with older children and adults. This capabilityto solve full conservation tasks likely indicates that the law of conservation has already emerged inVLMs.\nIn stark contrast, VLMs consistently fail at tasks assessing quantity understanding on the numberand length dimensions using scenarios taken directly from full conservation tasks. This is perplexingnot only in the sense that rudimentary concepts of quantity are typically understood as prerequisites ofconservation at respective dimensions but also with respect to the phenomenon that providing VLMs\nwith the scenario of a transformational process overrides their fallacy in quantity understanding, given\nby direct comparison between full conservation tasks and quantity understanding tasks extracted\nfrom the corresponding scenarios. Such dissociation has rarely, if never, been demonstrated in\ndevelopmental literature among experiments carried out in real life with children determined as\nNon-Conserver, who tend to exhibit a rudimentary understanding of quantity that can be disturbed by\ntheir failure to conserve. For VLMs, it thus appears to be the exact opposite.\nGiven the critical status of conservation and quantity understanding for assessing cognitive abilities\nand their developmental trajectory among intelligent agents, it is important to interpret the underlying\nmechanism of this staggering contrast between the performance of humans and VLMs described here.\nRecent neuroimaging evidence probing the neural mechanisms underlying number conservation and\nthe length-equals-number fallacy may offer a prima facie explanation for this dissociation. It has\nbeen shown that successful performance of number conservation requires not only activation among\nnetworks supporting the reversibility of cognitive operations centered around the intraparietal sulcus\nbut also executive functional pathways underlying the inhibition of the length-equals-number strategy.\n[Houd\u00e9 et al., 2011, Poirel et al., 2012, Viarouge et al., 2019]. The present dissociation found in VLMs,\ntherefore, seems to indicate that upon being offered a task scenario involving physical transformation,\nthey can successfully infer the concept of reversibility from the transformation process depicted in the\nscenario while simultaneously inhibiting misleading strategies of quantity understanding. Notably,\nsuch inhibitions are contingent on processing the transformation process, provided by the robust\nobservation that VLMs consistently employ these strategies for solving non-transformational quantity"}]}