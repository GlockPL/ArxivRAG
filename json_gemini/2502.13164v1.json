{"title": "Multi-Agent Actor-Critic Generative AI for Query Resolution and Analysis", "authors": ["Mohammad Wali Ur Rahman", "Ric Nevarez", "Lamia Tasnim Mim", "Salim Hariri"], "abstract": "In this paper, we introduce MASQRAD (Multi-Agent Strategic Query Resolution and Diagnostic tool), a transformative framework for query resolution based on the actor-critic model, which utilizes multiple generative AI agents. MASQRAD is excellent at translating imprecise or ambiguous user inquiries into precise and actionable requests. This framework generates pertinent visualizations and responses to these focused queries, as well as thorough analyses and insightful interpretations for users. MASQRAD addresses the common shortcomings of existing solutions in domains that demand fast and precise data interpretation, such as their incapacity to successfully apply AI for generating actionable insights and their challenges with the inherent ambiguity of user queries. MASQRAD functions as a sophisticated multi-agent system but \"masquerades\" to users as a single AI entity, which lowers errors and enhances data interaction. This approach makes use of three primary AI agents: Actor Generative AI, Critic Generative AI, and Expert Analysis Generative AI. Each is crucial for creating, enhancing, and evaluating data interactions. The Actor AI generates Python scripts to generate data visualizations from large datasets within operational constraints, and the Critic Al rigorously refines these scripts through multi-agent debate. Finally, the Expert Analysis AI contextualizes the outcomes to aid in decision-making. With an accuracy rate of 87% when handling tasks related to natural language visualization, MASQRAD establishes new benchmarks for automated data interpretation and showcases a noteworthy advancement that has the potential to revolutionize AI-driven applications.\n\nImpact Statement-By converting imprecise user queries into precise, actionable insights, MASQRAD transforms data analysis and improves the efficiency and accuracy of data interpretation in a variety of industries. With the integration of a multi-agent actor-critic model, MASQRAD achieves an 87% accuracy rate in converting natural language to visualizations while also significantly minimizing errors and optimizing data utility. This development is especially significant for industries like healthcare, finance, and public policy where quick and accurate data analysis is essential. The framework enables smooth user interaction and strong analytical performance by \"masquerading\" as a single AI entity and operating with complex inter-agent dynamics. In addition to enhancing decision-making, MASQRAD's creative use of generative AI agents for data creation, refinement, and analysis also establishes new benchmarks for automated data interpretation, exemplifying a transformative approach in AI applications and generating new paradigms for smart, multi-agent technology integration.", "sections": [{"title": "I. INTRODUCTION", "content": "WITH applications ranging from image synthesis to natural language processing and beyond, generative AI has made tremendous strides in recent years. Still, there are several obstacles that need to be overcome before generative AI can be effectively used for data analysis and complex query resolution. A significant challenge is the propensity of generative models to generate \u201challucinations,\" or results that appear credible but are factually false or unrelated to the user's query [1, 2]. When dealing with ambiguous or poorly defined user inputs, this problem is especially noticeable and can produce results that are unreliable or deceptive. In applications where accuracy and precision are crucial, hallucinations not only compromise the reliability of AI systems but also present serious difficulties.\n\nThe scalability of generative Al systems when handling big datasets presents another difficulty. The constraints imposed by API query limits and computational resources frequently cause traditional generative AI models to falter [3]. This limits their capacity to effectively manage large amounts of data, which lowers the caliber and comprehensiveness of the pro-duced outputs. Longer processing times, higher computational costs, and the inability to handle real-time or nearly real-time data processing all of which are crucial in many industrial applications are all consequences of scalability problems.\n\nFurthermore, a useful mechanism for creating and validating intricate analytical workflows is frequently absent from current systems. While code snippets and simple visualizations can be produced by generative AI, significant human intervention is usually necessary to ensure these outputs' accuracy, effective-ness, and utility [4, 5]. This restricts the use of generative AI in fields where accuracy and in-depth research are essential. The time-consuming and error-prone nature of the manual review and correction process further reduces the effectiveness of generative AI applications.\n\nFurther complexity is added when multi-agent systems are integrated into generative AI frameworks. Conventional single-agent systems are frequently constrained by their incapacity to oversee and optimize several tasks at once. Comparatively, multi-agent systems are able to divide up the work and work together to produce more accurate and efficient outcomes. Coordinating several agents, ensuring smooth communication, and keeping the system cohesive are still difficult tasks."}, {"title": "II. RELATED WORKS", "content": "Over the past few decades, natural language processing (NLP) has undergone significant evolution, with notable break-throughs in data-driven and symbolic approaches to query resolution systems. The groundwork for early NLP research was established by symbolic approaches, which depend on rule-based systems and organized knowledge. Conversely, the introduction of deep learning and massive data processing has caused a shift in emphasis towards data-driven approaches that utilize machine learning and statistical models. The main advancements in data-driven and symbolic natural language processing (NLP) approaches are reviewed in this section, along with their advantages and disadvantages. The transition towards combining both paradigms for more reliable and effective query resolution systems is also discussed."}, {"title": "A. Symbolic NLP Approaches", "content": "Rule-based systems and symbolic reasoning are used in symbolic approaches to natural language processing (NLP) in order to generate and interpret human language. These approaches, which are distinguished by their reliance on predetermined rules and organized knowledge bases, have long been a mainstay of NLP research.\n\nELIZA, created by Joseph Weizenbaum in the 1960s, is one of the most renowned early systems in symbolic NLP. By employing pattern matching and substitution techniques, ELIZA was able to replicate human communication, show-casing the potential of rule-based systems to imitate social interaction [11]. ELIZA established the foundation for more complex symbolic systems despite being simple by today's standards.\n\nSymbolic natural language processing (NLP) was further enhanced in the 1970s and 1980s by systems such as SHRDLU and LUNAR. The potential of combining language under-standing with a well-defined domain was demonstrated by Terry Winograd's SHRDLU, which could comprehend and carry out commands in a block world [12]. William A. Woods showed how to use a structured database and natural language interface to provide answers to inquiries regarding the geological examination of moon rocks [16]."}, {"title": "B. Data-Driven NLP Approaches", "content": "Deep learning has completely changed natural language processing (NLP) by making it possible to create models that can learn from massive datasets directly. Because of these data-driven approaches' superior performance on various tasks, symbolic methods have been largely replaced.\n\nAmong the most important models in this paradigm change is the Transformer architecture, which Vaswani et al. intro-duced. [3]. Unlike earlier architectures, the Transformer model processes input sequences using self-attention mechanisms, enabling it to capture contextual information and long-range dependencies better. The Transformer is now the foundation of many modern NLP models, such as GPT and BERT.\n\nDeveloped by Devlin et al., BERT (Bidirectional Encoder Representations from Transformers) is a noteworthy develop-ment in pre-trained language models [14]. BERT is incredibly useful for a range of natural language processing (NLP) tasks, including text classification [17] and question answering [18] because it is built to comprehend a word's context in both directions. Its broad adoption in academia and industry can be attributed to its ability to be tailored for particular tasks.\n\nLikewise, OpenAI's GPT (Generative Pre-trained Trans-former) series has proven to be exceptionally proficient in language modeling and text generation [2]. With only a small amount of task-specific training, GPT-3, with its 175 billion parameters, is capable of executing tasks like creative writing and code generation. Its outstanding performance highlights how large-scale pre-trained models can be generalized across a variety of NLP applications.\n\nOther noteworthy contributions, besides BERT and GPT, are T5 (Text-To-Text Transfer Transformer) and ELMO (Em-beddings from Language Models). Peters et al. developed ELMo, by taking into account the complete sentence context, developed deep contextualized word representations that dra-matically enhanced performance on a variety of NLP tasks [19]. Raffel et al. introduced T5 and showed that a single strategy can produce state-of-the-art results across multiple benchmarks by framing all NLP tasks as text-to-text problems [20].\n\nEven with these models' success, there are still problems. There is still a lot of research and discussion going on re-garding topics like model interpretability, data privacy, and the possibility of producing biased or harmful content. The pursuit of more resilient and moral AI systems has led to continuous endeavors to enhance the accountability and transparency of data-driven natural language processing models [21, 22].\n\nFurthermore, there's a growing interest in combining data-driven and symbolic approaches to take advantage of both paradigms' advantages. The goal of hybrid systems is to bring together the data-driven models' learning capabilities with the rule-based accuracy of symbolic methods. Hybrid techniques, for instance, have been applied to enhance neural networks' interpretability and reasoning powers, allowing them to func-tion better on tasks requiring structured knowledge and logical inference [23, 24].\n\nNovel approaches for transforming natural language into data visualizations have been investigated in the context of recent developments in the NL2VIS field. To produce vi-sualizations from natural language queries, Maddigan and Susnjak's Chat2VIS system makes use of large language models (LLMs) such as ChatGPT, Codex, and GPT-3 [15]. This method addresses the inherent ambiguities and under-specifications of natural language by uniquely using prompt engineering, providing a dependable end-to-end solution for creating visualizations. Traditional NL2VIS systems, which frequently rely on specially designed models and manually crafted grammar rules, are much more expensive and complex than Chat2VIS.\n\nChat2VIS can interpret user queries and produce visualiza-tions with high accuracy and efficiency thanks to the use of pre-trained LLMs. The system does have certain drawbacks, though. The non-deterministic nature of LLMs leads to vari-ability in plot generation, and there is room for improvement in the consistency of plot aesthetics, such as background colors and grid lines."}, {"title": "III. METHODOLOGY", "content": "The Multi-Agent Strategic Query Resolution and Analytical Diagnostic (MASQRAD) System was developed and imple-mented using several different processes and techniques, all of which are detailed in the methodology section. To provide reliable query resolution, generate Python scripts for data visualization, validate and improve these scripts, and generate thorough analytical reports, the system uses sophisticated transformer-based models and a multi-agent framework. Four important subsections comprise the methodology:"}, {"title": "A. Query Interpretation with RoBERTa and LLaMA", "content": "1) Overview of RoBERTa: RoBERTa (\"Robustly Optimized BERT Approach\") modifies the original BERT architecture by enhancing training efficiency and removing the next-sentence prediction task. This model, specifically the RoBERTa large, employs 24 layers, each with 1024 hidden units and 16 self-attention heads, totaling about 355 million parameters. [33]. In our system, RoBERTa excels at transform-ing ambiguous user queries into structured, actionable clues through a multilabel classification framework, enabling precise guidance for subsequent AI operations."}, {"title": "2) Application of RoBERTa in Our System", "content": "As a key component of our system, ROBERTa translates intricate queries into targeted clues that direct the Actor Al's response tactics. RoBERTa is used to predict multiple relevant clues from each query by utilizing its refined capabilities. These clues or indicators correlate to various aspects of the query, giving the Actor AI a complete set of guidelines for proceeding efficiently.\n\nThe model processes input queries and predicts the likeli-hood of each metric being relevant, which is formulated as follows:\n\n$P_{labels} = \\sigma(W \\cdot \\text{ROBERTa}(x) + b)$\n\nwhere x is the tokenized input query, W is a weight matrix that maps ROBERTa's output embeddings to the label space, b is a bias vector, and o is the sigmoid activation function applied element-wise. This function outputs probabilities between 0 and 1, representing the likelihood of each metric's relevance to the query.\n\nUsing this method, ROBERTa can provide the Actor Al with accurate, probabilistically weighted insights that facilitate sophisticated decision-making and customized responses based on the unique requirements of the user."}, {"title": "3) Overview of LLaMA", "content": "Equipped with 13 billion param-eters, LLaMA-2-13b presents novel processing improvements such as the Grouped Query Attention (GQA) method. The goal of this model (Figure 2(b)) is to optimize computational resources and contextual responsiveness by grouping and selectively attending to the most relevant portions of the input. The GQA mechanism is formulated as follows:\n\n$\\text{GQA} = \\text{softmax}\\left(\\frac{QW_Q \\cdot (KW_K)^T}{\\sqrt{d_k}}\\right)(VW_V)$\n\nIn this equation:\n\n*   Q, K, V represent the query, key, and value matrices, respectively, which are standard components in attention mechanisms.\n*   $W_Q, W_K, W_V$ are the parameter matrices that transform the input query, key, and value data into higher-dimensional spaces for better feature extraction.\n*   The element-wise multiplication \u2022 between $QW_Q$ and $(KW_K)^T$ allows the model to focus on how closely each element of the query aligns with elements of the key, enhancing the specificity of the attention mechanism.\n*   $\\sqrt{d_k}$ is a scaling factor used to avoid overly large values during matrix multiplication that can lead to gradient vanishing problems.\n*   The softmax function is applied to normalize the atten-tion scores, ensuring they sum to one, thus representing probabilities.\n*   The final element-wise multiplication between the normalized attention scores and $VW_V$ weights the value matrix, emphasizing the parts of the data that are most relevant to answering the query.\n\nBy concentrating computational efforts on the most notable elements of the input data, this sophisticated attention mech-anism enables LLaMA to process multiple queries at once, improving efficiency in handling complex information scenar-ios. Additionally, Llama encodes the positional information of tokens using Rotary Positional Embeddings (RoPE).\n\n$\\text{RoPE}_{pos} = \\text{pos} \\cdot \\cos(\\omega_{pos}) + \\text{pos} \\cdot \\sin(\\omega_{pos})$\n\nwhere $\\omega_{pos}$ represents the frequency of the positional en-codings, enabling the model to preserve the relational context across different parts of the sequence."}, {"title": "4) Application of LLaMA in Our System", "content": "By provid-ing imaginative, contextually rich interpretations of the same questions, LLaMA complements RoBERTa. It func-tions autonomously, generating creative recommendations that broaden and deepen the Actor AI's analytical capabilities and improve the system's capacity to create thorough and varied responses."}, {"title": "B. Actor Agent-Driven Python Script Generation", "content": "The GPT family of advanced Generative AI models, namely GPT-3.5 Turbo and Codex, are employed by the Actor Agent in our system. These models, based on OpenAI's transformer architecture, are essential for producing Python scripts that dynamically react to user queries.\n\n1) GPT-3.5 Turbo and Codex as Actor AI: With a so-phisticated multi-head self-attention mechanism that helps them manage complex data dependencies, GPT-3.5 Turbo and Codex both build on the capabilities of GPT-3. Because our system requires dynamic responses, this architecture makes it easier to generate contextually rich text based on input prompts [1, 3].\n\n*   Multi-Head Attention (MHA): Central to their func-tionality, MHA allows these models to assess and synthe-size different aspects of the input data through multiple \"heads\" of attention.\n\n$\\text{MHA}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O$\n\n$\\text{head}_i = \\text{softmax}\\left(\\frac{(QW_i^Q)(KW_i^K)^T}{\\sqrt{d_k}}\\right)VW_i^V$\n\nWhere $W_i^Q, W_i^K, W_i^V$ are the parameter matrices for the query, key, and value in each head, and $W^O$ is the output transformation matrix.\n*   Positional Encoding: Positional encodings are integrated into input embeddings to maintain the sequence order, enhancing the model's ability to process language [3].\n\n2) Mitigating Hallucination Error: Hallucination errors, where models generate non-factual or irrelevant content, are a significant concern with language generation models. To mitigate such errors, the Actor Agent leverages contextual cues and structured inputs from RoBERTa and LLaMA, ensuring that the generated Python scripts remain accurate and relevant to the provided data [34].\n\n3) Functionality of the Actor Agent: The primary role of the Actor Agent is to generate Python scripts that:\n\n*   Produce data visualizations to answer user queries through intuitive graphs and charts.\n*   Perform numerical analysis and store results in dataframes for subsequent examination by the Expert Analysis Agent.\n\nThese scripts are tailored based on insights from ROBERTa and LLaMA, guided by the robust AI capabilities of GPT-based models, ensuring precise and actionable outputs.\n\nThe incorporation of these models improves the system's capacity to provide intelligent and tailored answers efficiently, enabling an advanced analytical procedure to handle intricate inquiries."}, {"title": "C. MAD Critic Agent's Script Validation and Refinement", "content": "The Critic AI, a pivotal component of our system, employs the GPT-4-turbo model to review and refine the Python scripts generated by the Actor AI. This step is crucial to ensure the scripts not only execute without errors but also accurately ad-dress the user's queries through appropriate data visualizations and analytics.\n\n1) Functionality of the Critic AI: The primary role of the Critic Al is to meticulously review the Python scripts produced by the Actor AI. This involves several checks and enhancements:\n\n*   Validation of Script Execution: The Critic AI first verifies that the script can execute successfully and is capable of generating the required graphs and dataframes relevant to the original user query. This step ensures that the output precisely aligns with what is necessary to answer the user's query effectively.\n*   Storage and Accessibility: It ensures that all outputs, including charts and dataframes, are stored in appropriate cloud locations, accessible to the Expert Analysis Agent for further processing and analysis.\n*   Enhancement of Outputs: Beyond functional validation, the Critic AI enhances the aesthetic aspects of the graphs and optimizes the performance of the script, improving execution efficiency and visual appeal.\n\n2) Critic Al Powered by Multi Agent Debate: Once vali-dation has been completed successfully, the script is run to produce the required results. Execution errors, on the other hand, send the script to a different instance of Critic AI along with the error message, dataset URL, and user query. In response, several instances of Critic AIs begin an iterative process of refining the script in a Multi Agent Debate (MAD):\n\n*   Iterative Refinement: Each Critic AI attempts to correct any errors identified by its predecessors, rewriting the script if necessary to ensure error-free execution.\n*   Multi Agent Debate: This process embodies a robust debate among several AI agents, each critiquing and enhancing the script to not only resolve errors but also to optimize the script's overall effectiveness and accuracy.\n\nIn order to improve accuracy and reliability in automated systems, this iterative debate process leverages collective AI capabilities to gradually refine responses, which is advanta-geous for complex query resolution.\n\nThe Critic Al's capacity to produce flawless and highly refined outputs is greatly improved by the integration of Multi Agent Debate into its workflow, guaranteeing that the end-user gets the most accurate and perceptive data possible [35]."}, {"title": "D. Expert Analysis and Report Generation", "content": "As a key component of our artificial intelligence system, the Expert Analysis Agent generates comprehensive analysis reports and analyzes dataframes after the python script is executed. Claude-3.5 Sonnet [36, 37] and GPT-4-omni [38] models have been tested in our system. Even though both models have demonstrated efficacy, the Claude-3.5 Sonnet is usually chosen because of its superior analytical capabilities and graduate-level reasoning, which enable it to handle highly complex analytical tasks with exceptional skill [39].\n\n1) Functionality of the Expert Analysis Agent: The Expert Analysis Agent's primary function is to process the numerical results stored in dataframes, which represent the outcomes of Python scripts executed by the Actor Agent. The responsibil-ities of the Expert Analysis Agent include:\n\n*   Analyzing dataframes to extract meaningful insights and patterns that directly respond to the user's queries.\n*   Generating comprehensive reports that not only detail the findings from the data but also provide contextually rele-vant insights derived from the latest information available to GPT-4-omni and Claude 3.5 Sonnet.\n*   Enhancing the understanding of the visual representa-tions, such as graphs and charts, by correlating them with numerical analyses to provide a thorough interpretation of the results.\n\n2) Insight Generation Powered by Advanced AI: Utilizing the advanced capabilities of Claude-3.5 Sonnet and GPT-4-omni, the Expert Analysis Agent synthesizes the insights from the data with contemporary knowledge extracted from the internet. This integration allows the Agent to:\n\n*   Deliver insights that are not only based on the raw data but are also enhanced by the most recent and relevant information, making the analyses more valuable and actionable for the user.\n*   Provide recommendations and strategic advice that are informed by the latest trends and data, ensuring that the analysis is not only accurate but also aligned with current real-world applications.\n\nThe use of sophisticated AI models ensures that the Expert Analysis Agent is equipped to handle complex analytical tasks and generate reports that are both informative and practically useful for decision-making processes."}, {"title": "IV. EXPERIMENT SETTINGS AND RESULTS", "content": "The experimental setup that was utilized to set up and train our system's interpreter models, RoBERTa and Llama, is described in this section. Understanding how these models are ready to handle and interpret complex queries requires an understanding of these settings. In order to maximize the performance of all generative AI models, this section will also introduce the Prompt Engineering strategies. Using our MASQRAD system, we have validated its performance at the end of this section by testing it on a subset of the NL4DV and nvBench datasets."}, {"title": "A. Experiment Settings for Interpreter Models", "content": "1) Experiment Settings for RoBERTa: The main objective of training the RoBERTa models was to improve their Query Interpreter skills so that they could offer helpful suggestions for efficiently responding to user inquiries. To do this, we optimized pre-trained RoBERTa models by fine-tuning the model on a multilabel classification task, in which the model predicts particular clues or indicators on which to build its responses to questions pertaining to a given dataset. Because of this, every dataset required a different RoBERTa model to be trained, so every model became an expert in its own domain. The following training methods and configurations were used for ROBERTa:\n\nDataset Preparation: In order to effectively train our RoBERTa interpreter models to handle imprecise queries and translate them into clear, concise queries, we created several customized query datasets that were specific to each dataset we used for our analyses. This was imperative to make sure the models were ready to handle and interpret queries unique to various contexts. To test our MASQRAD system, for example, we created a special query dataset for the Movies category, which we then used to analyze the \"movie_1\" and \"cinema\" databases from the nvBench dataset and the \"Movies\" dataset from NL4DV. The utilization of Generative Language Models guided the creation of these query datasets, guaranteeing that any data present in the corresponding datasets might be applied to address the queries. 1000 queries were included in each query dataset to train the multilabel classification models. The quantity of ground truth labels differed based on the particular dataset under consideration. It is significant to highlight that the unbalanced nature of these datasets created extra difficul-ties for the training process. This dataset goes through a number of preprocessing stages:\n\n*   Tokenization using RobertaTokenizer, configured for a maximum length of 64 tokens.\n*   Shuffling and resetting the index to ensure an unbiased order of input data.\n\nModel Configuration:\n\n*   Model: Roberta Large Model from the transformers li-brary.\n*   The model employs the pooled embedding from the first token tensor of the last hidden state for classification, effectively capturing the contextual essence of each query.\n\nTraining Process:\n\n*   The dataset was divided into training, validation, and testing segments in the ratios of 50%, 20%, and 30% respectively, to monitor learning progress and prevent overfitting.\n*   The model was trained on a batch size of 16, and for 40 epochs, using the Adam optimizer with a learning rate"}, {"title": "2) Experiment Settings for Llama", "content": "Because of its text gener-ation capabilities, the Llama model\u2014in particular, the Llama-2-13b-hf version-has been used. This model is a component of the larger architecture of our system that helps it understand and react to complex queries.\n\n*   Model Configuration:\n    *   Model Setup: LlamaForCausalLM, a model opti-mized for text generation, was loaded from a pre-trained configuration specifically designed for high-fidelity and contextually aware text outputs.\n    *   Tokenizer: LlamaTokenizer was used to ensure that text inputs are appropriately converted into token for-mats that are compatible with the model, supporting a maximum new token generation of 64 tokens per query.\n*   Query Handling:\n    *   A pipeline for text generation was established using the Llama model and tokenizer, configured to handle various data types and computational optimizations such as setting the torch data type to float16 for efficiency.\n    *   The device map was automatically set to optimize resource allocation during model operation."}, {"title": "B. Prompt Engineering for Generative LLMS", "content": "In order to ensure that the responses from generative lan-guage models are accurate and specifically tailored to the operational requirements at various stages of query resolu-tion, prompt engineering is a fundamental technique in our system [40, 41, 42]. Every prompt is designed with care to correspond with the desired results, regardless of whether that means following strict dataset limitations or utilizing more comprehensive sources of data.\n\n1) Focused Prompts for Actor and Critic Stages: In the Actor and Critic phases, the prompts are formulated to guar-antee that the generative models generate outputs that strictly adhere to the dataset's context. All outputs are guaranteed to be directly applicable to the dataset at hand thanks to this targeted prompting strategy, which reduces the possibility of producing irrelevant or out-of-scope content.\n\n*   Dataset-Specific Prompts: For these stages, prompts specifically instruct the models to generate Python scripts or validate outputs based solely on the dataset provided. A generalized example might be, \"Using only the data provided in dataset_url, generate a Python script to analyze column_names and produce visualizations that answer the user's query.\"\n*   Containment Strategies: These prompts ensure that the model doesn't hallucinate or incorporate irrelevant data by restricting the Al's response scope to the dataset, protecting the accuracy and significance of the outputs that are produced.\n*   Conflict Resolution: In the rare instances where conflicts arise, especially during the Critic AI phase, a multi-agent debate mechanism ensures resolution through consecutive agreement between Critic AIs, effectively preventing any single error or discrepancy from compromising the sys-tem's outputs.\n\n2) Expansive Prompts for Llama and Expert Analysis Stages: On the other hand, prompts in the Llama and GPT for Expert Analysis stages are designed to take advantage of the models' ability to incorporate broader contextual informa-tion. By incorporating insights that go beyond the immediate dataset, this approach improves the analyses' depth and use-fulness.\n\n*   Incorporating External Knowledge: Prompts in these stages encourage models to draw on external sources and their pre-trained knowledge. For example, an Ex-pert Analysis prompt might be, \"Based on the data in dataset_url and your broader knowledge, provide insights and potential action points that could benefit the user's understanding of the analyzed trends.\"\n*   Utilizing Model Capabilities: This strategy utilizes the full capabilities of the AI to enrich the analysis with internet-sourced information, offering more comprehen-sive insights and recommendations based on up-to-date trends and data.\n\n3) Ensuring Alignment with System Goals: In order to match the responses of AI models with the strategic objectives of the system, such as raising decision-making efficiency by drawing insights from the generated results, prompt engineer-ing is essential at every step. The generative AI agents, pro-duce outputs that are both practically and technically valuable thanks to strategic prompt design.\n\n*   Strategic Alignment: Each prompt is not only a directive for generating specific types of outputs but also a tool for ensuring that these outputs serve the broader objectives of the system effectively.\n*   Agent Interaction: Agents within the system share com-putational resources and storage, operating in a sequential process where the output of one agent serves as the input for another. This tightly integrated workflow minimizes the potential for conflicts, as each agent is designed to build upon the previous agent's results, ensuring coherent and unified progress towards the final output.\n\nThis sophisticated use of prompt engineering across dif-ferent stages of our Al-driven query resolution system en-sures that generative models produce high-quality, relevant, and actionable outputs, adhering closely to user needs and operational demands.  illustrates an example of query resolution using the MASQRAD system, showcasing the comprehensive process from script generation, through script validation powered by multi-agent debate, to code execution, detailed analysis of generated visualizations, and the offering of insightful conclusions.\n\n4) Parameter Settings: In our system, the generative AI agents are fine-tuned with specific parameter settings to opti-mize their performance for different tasks:\n\nInterpreter Models: For the LLaMA model, which focuses on query interpretation, we use a conservative temperature setting of 0.3 to prioritize precision and a top_p value of 0.7 to balance diversity with relevance. The maximum number of"}, {"title": "E. Implementation in Domain-Agnostic Setting", "content": "The team of experts in online brand marketing also col-laborated on a Search Engine Optimization (SEO) project where they integrated MASQRAD framework in their system. The project involved analyzing query datasets spanning di-verse domains such as Web3, Metaverse, Vitality & Health, Restoration, and Capital Investment. With 40 queries per domain, the MASQRAD framework was used to process 200 queries in total. The system's domain-agnostic capabilities were demonstrated by using the same fine-tuned ROBERTa model, which was trained on a multi-label classification task with 6800 queries and 52 labels, as the query interpreter across"}, {"title": "V. CONCLUSION", "content": "This paper introduced MASQRAD, a Multi-Agent Strategic Query Resolution And Diagnostic tool that enhances query resolution and data analysis through the synergistic interplay of multiple generative AI agents. MASQRAD translates vague user inputs into precise queries, generates tailored Python scripts, and provides detailed insights explaining the visual-ization results, distinguishing it from most NL2VIS systems which only generate visualizations.\n\nMASQRAD demonstrated superior performance on subsets of the nvBench and NL4DV benchmarks, achieving an 87% accuracy rate, significantly outperforming existing systems like Chat2Vis and RGVisNet. This success is attributed to the iterative refinement from our multi-agent debate methodology, which rigorously ensures clarity and correctness in each script and visualization.\n\nNonetheless, our assessments also brought to light certain shortcomings in benchmarks such as nvBench and NL4DV, like unclear query guidelines and uneven data preparation. Developing AI-driven visualization tools requires more robust datasets, as these challenges highlight."}, {"title": "A. Limitations", "content": "1) Scope of Generalization: Due to its dependence on domain-specific RoBERTa models, which necessitate unique"}, {"title": "B. Future Directions", "content": "1) Expanding System Capabilities: The modularity of MASQRAD will be improved by future research, allowing for integration of reinforcement learning and APIs for more complex analysis. Because of the system's plug-and-play de-sign, agents (like Actor AI and Critic AI) can be enhanced or swapped out for more advanced LLMs, keeping it at the forefront of technology. Healthcare, finance, and marketing are just a few of the industries that MASQRAD can adapt to by changing domain-specific models like RoBERTa or cus-tomizing prompts. Its generalization will be further evaluated through testing on various benchmarks and tasks, which will lessen the need for task-specific training.\n\n2) Developing Adaptive Templates: MASQRAD will incor-porate adaptive learning to refine templates dynamically based on user feedback, improving usability and precision. Schema adaptation techniques and feedback loops will help handle evolving data structures or schema-less systems. By combining continual learning with reinforcement strategies, MASQRAD will iteratively generalize across diverse query resolution tasks and industries.\n\n3) Overcoming Domain Dependencies: MASQRAD's domain-specific, fine-tuned ROBERTa models, which necessitate extensive training tailored to particular datasets, are the reason for its effectiveness in NL2VIS tasks. Although accuracy is guaranteed by this specialization, the system's initial applicability to more general query resolution tasks is limited. In order to lessen these dependencies, future improvements will concentrate on combining zero-shot and few-shot learning strategies. With the help of these techniques, MASQRAD will be able to adjust more easily to a variety of tasks, such as NL2SQL or intricate decision making, requiring less retraining. This will increase its usefulness while upholding its dedication to addressing the difficulties of translating natural language into accurate visualizations, a goal shared among systems in similar area of research."}]}