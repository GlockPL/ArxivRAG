{"title": "Leonardo vindicated: Pythagorean trees for minimal reconstruction of the natural branching structures", "authors": ["Dymitr Ruta", "Corrado Mio", "Ernesto Damiani"], "abstract": "Trees continue to fascinate with their natural beauty and as engineering masterpieces optimal with respect to several independent criteria. Pythagorean tree is a well-known fractal design that realistically mimics the natural tree branching structures. We study various types of Pythagorean-like fractal trees with different shapes of the base, branching angles and relaxed scales in an attempt to identify and explain which variants are the closest match to the branching structures commonly observed in the natural world. Pursuing simultaneously the realism and minimalism of the fractal tree model, we have developed a flexibly parameterised and fast algorithm to grow and visually examine deep Pythagorean-inspired fractal trees with the capability to orderly over- or underestimate the Leonardo da Vinci's tree branching rule as well as control various imbalances and branching angles. We tested the realism of the generated fractal tree images by means of the classification accuracy of detecting natural tree with the transfer-trained deep Convolutional Neural Networks (CNNs). Having empirically established the parameters of the fractal trees that maximize the CNN's natural tree class classification accuracy we have translated them back to the scales and angles of branches and", "sections": [{"title": "1 Introduction", "content": "There is no doubt natural trees are as beautiful and inspiring as they are ingeniously optimal from the engineering point of view [1]-[6], [13]-[20]. Ensuring the most efficient water and nutrients transport from roots to leaves up to a 100m, optimally resisting fractures from gusty winds, efficiently balancing photosynthesis with transpiration while successfully branching out to maximize the access to the space and light are just some of the tree's ingenious mechanisms that make it survive and thrive for up to thousands of years despite nature or human inflicted troubles.\nMany algorithmic generative tree models have been proposed [5]-[9], some of which successfully approached photo-realism quality required for the fast expanding computer graphics and animation industry. An emerging observation from these attempts is that while being so complex, the tree appears to be also beautifully simple, with its branching structure following similar recursive generative patterns that inspired attempts to model them by fractals [2]-[4], [11]-[20]. From the minimalist point of view, reconstructing the trees by fractals is the most appealing, since it offers the shortest and most essential description of how to generate the naturally looking tree structure and for that reason it is also more likely to offer explanations for the fundamental engineering principles guiding the natural tree creation, which we are keen to explore.\nWhat gives the natural tree its signature look is the branching structure eventually leading to the green leaves. Although in general we observe examples of trees with junctions splitting out into more than two branches, the dominant observation is, also reinforced by human imposed selective breeding, that of the apical dominance of the strongest stem (trunk), which typically leads to binary branch attachments or forking that leaves a pair of branches after the junction [1].\nThere have been many attempts to describe and explain the branching structure of the natural tree [13]-[20]. The first dating back over 500 years ago is attributed to the Renaissance painter and polymath Leonardo da Vinci, who proposed the rule of intersection area preservation when passing through any junction of the tree. In the original Italian, the eighth rule Leonardo wrote in his notebook on drawing trees reads \"Ogni biforcazione di rami insieme giunta ricompone la grossezza del ramo che con essa si congiunge\", i.e. \u201call the branches of a tree at every stage of its height when put together are equal in thickness to the trunk they branch from\u201d. This da Vinci rule implies that the total sum of intersections of all the branches at the terminal level is equal to the intersection of the main trunk. In other words, if a tree's branches were folded upward and squeezed together, the tree would look like one big trunk with the same thickness from top to bottom. Such model gained the support of the pipe model [15], that considers the tree a collection of vascular vessels connecting roots to the leaves, as well elastic similarity model [16],[17], which assumes fixed rate of branches weight-imposed deflection per unit of their length, later proven to result with the optimal (even) distribution of fracture risk implying globally minimized probability of fracture if the da Vinci rule truly holds [14]. However simple and beautiful the da Vinci rule may seem, recent reviews analyzing experimental work conclude that it does not hold in general"}, {"title": "2 Pythagorean tree", "content": "Pythagorean tree is a plane fractal design constructed from squares resting on the sides of the right triangle. It was first described in 1942 by Albert E. Bosman who coined the name to highlight the link to the famous ancient Greek mathematician. The base fractal configuration of squares enclosing the right triangle is also traditionally used to illustrate the Pythagorean Theorem [11]. It is perhaps worth noting that Elisha Scott Loomis' classic \u201cThe Pythagorean Proposition\" [30], which contains 371 proofs of the Pythagorean Theorem, includes one by Leonardo da Vinci. In its simplest form with isosceles right triangle, construction of symmetrical Pythagorean tree recursively takes the base square and puts its $\\sqrt(1/2)$-scaled down and \u00b1\u03c0/4-rotated versions around the parent upper corners as shown in an instructive illustration of 5-levels deep Pythagorean tree in Figure 1(a), followed with deep expanded tree up to 25 recursive steps in Figure 1(b).\nFor clarity, we assume the root at depth 0 and introduce a simple tree-mimicking color map linearly scaling the colors from full black to full green along the recursion depth. An immediate observation is"}, {"title": "3 Generalised fractal trees", "content": "In an attempt to further encourage the more realistic appearance of the Pythagorean trees we have decided to allow for deviation from the Pythagoras rule of the branching triangle that would allow any triangle shape, while maintaining random flip in the recursive growth. To orderly parameterize the freed shape of the branching triangle we kept the branch imbalance parameter b unchanged from the Pythagorean trees but added the variable $a$ of the triangle's angle opposite its resting base a. Moreover, we also decided to put the da Vinci's rule to test by actively controlling the fraction by which the total intersection of the branches reduces or exceeds the intersection of the parent. To achieve this we simply multiply the scales derived from the sides of the branching triangle by a fixed scalar computed to achieve desired ratio $v$ of the branches to parent intersection. For notation simplicity we will consider a fractal tree defined by the 4 parameters as: T(e,b, a,v) in the subsequent analysis.\nGiven the tree input parameters (e,b, a, v) and the unconstrained shape of the triangle resting on a rectangular parent with sides (1,e) we can apply the cosine rule to the branching triangle to derive the scales for the sides of the branching triangle. Book II of Euclid's Elements, compiled c. 300 BC from material up to two centuries older, contains a geometric theorem corresponding to the law of cosines but expressed in terms of rectangle areas. Euclid proved the result by using the Pythagorean Theorem. Using modern notation, the rule can be written as follows:\n$s_r = 1/\\sqrt{1+b^2 - 2bcos(a)}, s_l = bs_r$ (3.1)\nNow given all the sides of the triangle and the same cosine rule we can find the rotation angles required to construct the child branches:\n$y = arccos \\frac{s_r^2 - s_l^2 + 1}{2s_l}, \u03b2 = \u03c0- \u03b1 - \u03b3;$(3.2)\nThe parameters and their use to derive key fractal transformation constants required by the main recursive tree generator function are depicted in Figure 3.\nWith the computed scales and rotation angles both child branches can be instantly computed from the parent simply by scaling the parent down with respect to its bottom vertices, translate (shift) them"}, {"title": "3.1 Fast recursive software implementation", "content": "The coding strategy for fractal implementation is simple: take the object, compute its perturbed, smaller, connected version(s) and recursively repeat the same upon the reduced versions until the depth limit is reached. In our case there is no difference, the recursive function tree() will be launched with the initial rectangular base and the pre-computed scaling and rotation constants for left and right child and the depth limit d:\nt=tree([0 1 1 0;0 0 e e]',sl,rotl,sr,rotr,d);\nTo further simplify and speed up the rotation process inside the function we have pre-computed rotations in a matrix form:\n$rot_l =  \\begin{bmatrix}  cos(\u03b3) & -sin(\u03b3) \\  sin(\u03b3) & cos(\u03b3) \\end{bmatrix},rotr =  \\begin{bmatrix} cos(\u03b2) & sin(\u03b2) \\ -sin(\u03b2) & cos(\u03b2) \\end{bmatrix}$(3.4)\nand they are passed as constant matrix parameters to the recursive function such that internal computations are simplified to the optimally vectorized computation of the rotated branches. Overall, given the parent trunk t and the parameters, the whole process of scaling, translating and rotating that produces the children branches can be simplified to the following:\nfunction t=tree(t,sl,rotl,sr,rotr,d)\ndx=t(end,:) \u2212 t ( 1 ,:);\ntl=t(1,:)+s1*(t-t(1, :))+dx;\ntr=t(2,:)+sr*(t-t(2,:))+dx;\ntl=tl (1,:)+( tl \u2013 tl (1,:))*rotl;\ntr=tr(2,:)+(tr-tr(2,:))*rotr';\nnoting the transposed rotr since rotation of the right branch happens clockwise. Once the child branches are computed what remains to be done is to recursively call the same tree() function upon freshly generated children branches and/or organize the output depending on the depth we are in:\nif d==1\nt=[t;tl;tr];\nelse\nt=[t;tree(tl,sl,rotl,sr,rotr,d-1)];\nt=[t;tree(tr,sl,rotl ,sr,rotr,d\u22121)];\nend\nTo implement the random flip of the branching triangle we need to make provision to run the transformations on the swapped scales and rotations if a random flip turns opposite:\nif rand >.5\ntl=t(1,:)+sr*(t-t(1,:))+dx;\ntr=t(2,:)+s1*(t-t(2,:))+dx;\ntl=tl (1,:)+( tl \u2013 tl (1,:))*rotr;\ntr=tr(2,:)+(tr-tr(2,:))*rotl';\nend"}, {"title": "3.2 Visual review of the generalized fractal trees", "content": "The optimized recursive code described above allowed to generate fractal trees in a fraction of a second up to the depth of 18. Deeper trees required essentially doubled processing time for each next depth such that 25-deep tree took around 2 minutes to generate. At depth=25 displaying the tree takes almost double the generation time since it requires plotting about 64 million coloured rectangles with 256m edges and vertices. At this depth we have generated 64 generalized fractal trees for all combinations of the four critical parameter values split into a grid of 4 values: b = {1,1.25,1.5,2}, \u03b1 = {60\u00b0,90\u00b0,120\u00b0,150\u00b0}, v = {0.9,1,1.1,1.25}, except of elongation that we kept fixed at e = 5 for which we received the most realistic results with the Pythagorean trees. For simpler visual association we replace a with the corresponding angle between branches that is always exactly \u03c0 \u2013 \u03b1."}, {"title": "4 Deep learning for fractal trees classification", "content": "Overall 99 fractal trees (35 of which are Pythagorean) have been generated and visually assessed for subjective resemblance to the real trees. While the most realistic trees appear to be T (5,1.25 : 1.5, 60\u00b0 :\n90\u00b0, 1: 1.1), we set off to evaluate the realism of the fractal trees by means of supervised Machine Learning (ML). Specifically, we chose the state-of-the-art deep convolutional neural networks (CNN)\nre-trained (transfer-trained) on real tree images along with hundreds of other objects observed in everyday life and deployed to classify the images of our fractal trees. To build the CNN we initially used the established Googlenet [22] design originally pre-trained on ImageNet [21] dataset and attempted to transfer-train it on the real part of the DomainNet [23] dataset pooling together over 170k images of various objects grouped in the 345 class-categories, one of which was obviously the natural tree. Given the tree class was rather small compared to other classes we have complemented it by a number of real tree images extracted from Google image search. The tree class is representatively illustrated in Figure 8.\nThe default Googlenet architecture was updated to accommodate DomainNet's 345 classes. All\nimages were reduced to the Googlenet accepted image input size of 224 \u00d7 224 and the network re-trained\nfor up to 100 epochs with batch size of 128 images and the fixed learning rate of 0.0001, using 10% of the\ndata for validation and applying every-epoch-shuffling. After about 50 epochs the validation classification\naccuracy saturated at around 80%, even though the training accuracy kept rising up above 90% by the\nend of 100 epochs, at which stage the network was clearly over-fitted with validation accuracy falling\nback below 75%. We have therefore collected the most robust network re-trained after 50 epochs and\napplied to classification of our fractal images, also reduced to the same compliant size of 224 \u00d7 224. The"}, {"title": "5 Conclusion", "content": "We have set off on a journey to try to reconstruct the natural tree side look, with the simplest possible fractal model that could be literally written in a few lines of a recursively coded algorithm. To achieve this goal we have modified the Pythagorean tree fractal algorithm and paired it with a flexible parameterization structure that takes rectangular trunk and appends it recursively with pairs of similar down-scaled branches at fully controlled parameters: branch elongation (e), branch imbalance (b), branching angle (a) and the da Vinci factor accounting for thinner or thicker intersection of the children branches compared to the parent branch. These parameters were mapped into fixed pre-computed constants used throughout the efficient matrix-represented recursive operations of scaling, translation and rotation to rapidly generate population of deep fractal trees with flip-randomised forking and branches colored with a linear black-to-green color-map. We have explored the parametric space of such remarkably short recipe and identified a parametric plateau that tends to produce very naturally-looking trees. We have quantitatively evaluated the realism or the natural look of generated fractal trees by the tree class classification score of the convolutional neural network (CNN) predictors competitively cross-trained on the hundreds of natural tree images along with hundreds of thousands of other images from 345 classes. Interestingly, the most naturally looking fractal tree family identified as T(2g, g, 67\u00b0, 1) is composed of rectangles elongated by twice the golden ratio (2g), branches imbalanced by exactly the g and spread by about 67\u00b0 apart, while obeying both the da Vinci and Grigoriev's intersection or surface area preservation rules (v = 1). The trees generated from the T(2g,g,67\u00b0,1) family are consistently classified by the CNN predictor with natural tree label and its support to the tree class exceeding 0.95. Despite very simplistic representation and rather neglected concept of leaves, the generated fractal trees look very natural to the human eye.\nFurther work in this space will concentrate on improvements in weight-aware spatial balancing of the trees, especially relevant when attempting to build stable tree models in 3D. We also aim to build upon this work to develop the capability to fractal-reconstruction of the specific tree species aimed at generating artificial training examples to build a powerful ML image-based tree species predictor and compare it against much more computationally expensive generative AI models. The authors are also enthusiastic to explore a logarithmic fractal tree representation paired with Fourier transformation analysis that can complement the research of Grigoriev et al. [20] and perhaps extend it beyond the deciduous trees."}]}