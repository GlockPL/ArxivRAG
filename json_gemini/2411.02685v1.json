{"title": "Geometry of naturalistic object representations in recurrent neural network models of working memory", "authors": ["Xiaoxuan Lei", "Takuya Ito", "Pouya Bashivan"], "abstract": "Working memory is a central cognitive ability crucial for intelligent decision- making. Recent experimental and computational work studying working mem- ory has primarily used categorical (i.e., one-hot) inputs, rather than ecologically- relevant, multidimensional naturalistic ones. Moreover, studies have primarily investigated working memory during single or few number of cognitive tasks. As a result, an understanding of how naturalistic object information is maintained in working memory in neural networks is still lacking. To bridge this gap, we developed sensory-cognitive models, comprising of a convolutional neural net- work (CNN) coupled with a recurrent neural network (RNN), and trained them on nine distinct N-back tasks using naturalistic stimuli. By examining the RNN's latent space, we found that: 1) Multi-task RNNs represent both task-relevant and irrelevant information simultaneously while performing tasks; 2) While the latent subspaces used to maintain specific object properties in vanilla RNNs are largely shared across tasks, they are highly task-specific in gated RNNs such as GRU and LSTM; 3) Surprisingly, RNNs embed objects in new representational spaces in which individual object features are less orthogonalized relative to the perceptual space; 4) Interestingly, the transformation of WM encodings (i.e., embedding of visual inputs in the RNN latent space) into memory was shared across stimuli, yet the transformations governing the retention of a memory in the face of incoming distractor stimuli were distinct across time. Our findings indicate that goal-driven RNNs employ chronological memory subspaces to track information over short time spans, enabling testable predictions with neural data.", "sections": [{"title": "1 Introduction", "content": "Working memory (WM) \u2013 the ability to store and manipulate information over short periods \u2013 is a central cognitive capability that enables a wide spectrum of behaviors [Baddeley, 1992]. Over the past few decades, various experimental, computational, and theoretical techniques have been adopted to study WM from both cognitive and neural perspectives. However, several fundamental issues remain unresolved, including the key question of how high-dimensional sensory information is encoded, maintained, and modulated according to specific task demands.\n\nA significant body of work has been dedicated to modelling the computations underlying WM. These include many classic models from cognitive science [Meyer and Kieras, 1997a, Ritter et al., 2019,"}, {"title": "2 Related Works", "content": "Models of working memory. Originally rooted in cognitive science, the notion of WM was first formally defined and popularized by Baddeley [1992] who proposed a cognitive system consisting of modality-specific buffers and a shared executive module to control the information flow in and out of the memory buffers. This initial work, along with most early models, portrayed WM as a memory system with three key features: flexibility of information representation, limited capacity, and limited temporal span.\n\nSubsequent models based on this perspective were largely akin to the architecture of the Von-Neumann computers, comprising of input and output channels, volatile memory components, and a central processing system that continuously executed pre-specified computer code according to task goals [Cowan, 1988, Meyer and Kieras, 1997b, Anderson, 2013]. However, experimental work in"}, {"title": "3 Methods", "content": "Tasks. We considered N-back tasks (N \u2208 {1,2,3}) based on one of three distinct object properties (i.e. feature; F \u2208 {Location, Identity, Category} (denoted as L, I, C'), resulting in a total of 9 N-back task variants (Figure 1b). Naturalistic stimuli were generated using 3D object models from the ShapeNet dataset (rendered examples in Figure Ala) [Chang et al., 2015], comprising 4 object categories, each with 2 unique identities rendered from various view angles, and presented at 1 of 4 possible locations. We consider two validation approaches: validating on novel view angles, and validating on novel identities. The training and validation novel angle datasets differed in their viewing angles, necessitating view-invariant processing by the model. In contrast, the validation novel identity includes unseen identity sampled from categories same as the training dataset.\n\nModel Architecture. We considered a two-stage model that delineates perceptual and cognitive processes (Figure 1c). At the first stage, the model processes sequences of images, utilizing an ImageNet [Deng et al., 2009] pre-trained ResNet50 [He et al., 2016] model to derive visual embeddings from each image input. All object features including category, identity, and location were highly decodable from these activations (category: 100.00%, identity: 99.57%, location: 100.00%; 2-fold cross-validation). A point-wise convolutional layer reduces the dimensionality of the 2048-channel feature map from ResNet's penultimate layer (layer 4.2 ReLU) to match the RNN's hidden size. Next, the vectorized embeddings are concatenated with a task index vector and processed by a fully connected layer (matching the RNN's latent size) with layer normalization [Ba, 2016], serving as input to the RNN. The RNN's output is then fed through another fully connected layer and projected to one of three possible responses: match, non-match, or no action.\n\nEach network is trained to perform one (single-task-single-feature) or multiple tasks (multi-feature or multi-task or both). After training, we analyzed activations from the penultimate layer of ResNet50 (i.e. the perceptual space), as well as the RNN activations during the stimulus presentation and subsequent timesteps (i.e. encoding and memory space respectively, denoted as E and M as shown"}, {"title": "4 Experiments", "content": "All models reached > 95% accuracy on train and > 90% on validation set with novel object angles. Generalization to novel object instances was substantially weaker (Figure Alb, c). Model"}, {"title": "4.1 Encoding of task-relevant and -irrelevant object properties in task-optimized RNNS", "content": "We first examined how RNN modules represent various object properties such as location, identity and category in their latent space. In particular, we investigated the following two questions:\n\n1) Do recurrent networks preserve object properties that are not necessary for the task? In order to perform a task, recurrent networks must maintain information about the task-relevant object properties. However, maintaining information about the task-irrelevant factors is not necessary from the perspective of the task objective. Therefore, RNNs may either selectively maintain task- relevant information or maintain full object representations, recalling task-relevant information when prompted.\n\nWe trained decoders (i.e. classifiers) to predict each object property from the RNN hidden state activity from the first timestep of each trial (e.g. F = Li vs. F = Lj\u2260i decoders, total 4 location decoders). Cross-validated decoding accuracies are shown in Figure 2b for STSF, STMF, and MTMF GRU models. Unsurprisingly, the task-relevant object properties are fully retrievable in all models. Further tests revealed a causal relationship between the subspaces encoding task-relevant information and the network's generated response (Fig. A7; see section .1 for details.) However, while task-irrelevant object features are not generally well-preserved in STSF models (Figure 2b, left), they are much better preserved in STMF and MTMF models (i.e. decoding accuracy > 85%; Figure 2b middle and right). This finding was consistent across all three RNN architectures (Figure A2a) and across time points (Fig. A5). These results suggested that all RNNs maintained a full representation of objects in their latent spaces regardless of which object properties were required for performing the task.\n\n2) Are object properties encoded within a subspace that is shared across different tasks or distinct ones within each task? Having observed that both task-relevant and -irrelevant information are retained by multi-feature RNNs, we next asked whether RNN encoding of object properties is task-dependent or -independent. To probe this, we trained decoders to predict object properties from the RNNs' activations during one task, and tested the decoder on RNN activations when performing another task (i.e., cross-task decoding). We quantified the generalization performance of MTMF models across all three architectures (Figure 2a). We found that gated RNNS (GRU and LSTM, Figure A2b) utilized highly task-specific subspaces for encoding object properties, while vanilla RNN encoded object properties within a subspace that was shared across all task-variations (Figure 2c). This suggests that gated RNNs tend to learn task-specific representations that do not generalize across tasks, potentially impacting their ability to generalize to new tasks."}, {"title": "4.2 Representational orthogonalization in task-optimized RNNs.", "content": "To improve their performance, RNN weights might form structured and separable representations for each task-relevant feature. For this to be true, the RNN latent space may orthogonalize feature representations beyond their perceptual representation (see schematics in Figure 3a). To quantify orthogonalization, we calculated the angles between all pairs of decision hyperplanes using cosine similarity (bootstrapped 10 times). We then summarized these angles into a single orthogonality mea- sure by computing the Frobenius norm of the difference between this matrix and the identity matrix (which represents complete orthogonalization). We defined this measure as the orthogonalization index (O):\n\n$W_{ij} = 1 - abs (cos(W_i, W_j))$\n\n$O = E(triu(W))$\n\nwhere $W_i$ is the normal vector of the decision hyperplane that separates points assigned with feature value i from the rest, $cos(W_i, W_j)$ is the cosine similarity between the two normal vectors. We take the absolute value since the relative direction does not matter. triu(.) is the upper triangle operator."}, {"title": "4.3 Neural mechanisms of concurrent encoding, maintenance, and retrieval in RNN models of WM", "content": "Having examined the encoding of objects in the RNN's latent space, we next investigated how RNN dynamics enable simultaneous encoding, maintenance, and retrieval of information. Performing our N-back task suite required the RNN to keep track of prior objects' properties while simultaneously encoding incoming stimuli with minimal interference."}, {"title": "5 Discussion and Conclusions", "content": "We investigated how naturalistic objects are represented in recurrent models during a dynamic and difficult WM task. In contrast to most prior work that build computational models of WM using abstract categorical stimuli, which typically study WM during a stable fixation/delay period, we trained a range of sensory-cognitive models to perform N-back tasks using naturalistic stimuli. We found that models trained on multiple features and multiple tasks retained object information regardless of their task-relevance. While prior studies investigating WM tasks using RNNs have identified shared representations and dynamical motifs across related tasks [Yang et al., 2019, Driscoll"}, {"title": "6 Limitations", "content": "Our study has several limitations:\n\n1. Task-Specific Findings: Our results are specific to the N-back task structure, and it remains uncertain whether similar computational strategies would emerge in other working memory tasks.\n\n2. Analysis for Novel Objects: While we observed reduced performance with novel objects, we did not analyze the representational geometry associated with these stimuli or investigate the reasons for diminished performance. Our use of naturalistic stimuli was intended to avoid imposing the representational geometry typical of abstract inputs, as seen in previous studies (e.g., Piwek et al. [2023], Yang et al. [2019]).\n\n3. Architectural Constraints: Our findings are restricted to commonly used RNN architec- tures, such as vanilla RNNs and LSTMs. Therefore, we cannot make definitive claims about how different neural network architectures might affect representational geometry. Further research could explore whether other architectures yield similar or distinct patterns.\n\n4. Impact of Network Scaling: We did not explore how scaling the network size might influence the results. It is possible that increasing the network size could alter the strategies employed by models to perform dynamic WM tasks."}, {"title": ".1 Methods", "content": "Model training We used cross-entropy loss for training, and the identity of the task was encoded in a 6-digit binary format: the first 3 digits represented the one-hot encoding of the feature (e.g., stimulus location, category, or identity), and the second 3 digits represented the one-hot encoding of the n-back choice of n. For the single-task single-feature model, we used the same task identity vector as in the multi-task models. The multi-task multi-feature model typically takes around 4-8k iterations with a batch size of 256, and we cut off training at 14k iterations. The sequence length is fixed at 6 for both the training and validation sets.\n\nCausal test To establish the causal relevance between the decoder-defined subspace and the network's behavioral performance, we perturbed the network's representations by shifting them along the direction of the normal vector to a given decision hyperplane. By passing the resulting hidden states through consecutive timesteps, we computed the probabilities of the three possible actions. We subsampled matched trials and perturbed the hidden states at various magnitudes in the direction of the corresponding decision hyperplane. As shown in Figure A7, the probability of obtaining a match action dropped significantly as the hidden states traversed the hyperplane, while the probability of no action increased. The probability of a non-match action remained largely unaffected, except for an increase in variance as the hidden states crossed the boundary. These results support the causal relationship, indicating that the subspace defined by the decoding analysis is actively utilized by the network in solving the task.\n\nDecoding analyses We consider the latent space of the RNN as a D-dimensional space RD where D is the number of units in the RNN model. We used support vector classifiers (SVC) to perform all the decoding analysis. The decoder should be able to classify one feature value from the rest, for example, location bottom left to all the other locations. Each decoder was fitted with activations from either perceptual, encoding, or memory spaces and labels from one of the three possible features (L, I, C') of the stimuli from current or previous time steps. We adopted 10-fold cross-validation as well as grid search to find the best regularization values from {0.001, 0.01, 1, 10}. All the classifiers reached cross-validated accuracy of \u2265 85%.\n\nEach classifier is then described by its normal vector w to its decision hyperplane dand a bias term b."}]}