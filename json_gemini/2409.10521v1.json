{"title": "LSTM Recurrent Neural Networks\nfor Cybersecurity Named Entity Recognition", "authors": ["Houssem Gasmi", "Abdelaziz Bouras", "Jannik Laval"], "abstract": "The automated and timely conversion of\ncybersecurity information from unstructured online sources,\nsuch as blogs and articles to more formal representations has\nbecome a necessity for many applications in the domain\nnowadays. Named Entity Recognition (NER) is one of the early\nphases towards this goal. It involves the detection of the relevant\ndomain entities, such as product, version, attack name, etc. in\ntechnical documents. Although generally considered a simple\ntask in the information extraction field, it is quite challenging in\nsome domains like cybersecurity because of the complex\nstructure of its entities. The state of the art methods require\ntime-consuming and labor intensive feature engineering that\ndescribes the properties of the entities, their context, domain\nknowledge, and linguistic characteristics. The model\ndemonstrated in this paper is domain independent and does not\nrely on any features specific to the entities in the cybersecurity\ndomain, hence does not require expert knowledge to perform\nfeature engineering. The method used relies on a type of\nrecurrent neural networks called Long Short-Term Memory\n(LSTM) and the Conditional Random Fields (CRFs) method.\nThe results we obtained showed that this method outperforms\nthe state of the art methods given an annotated corpus of a\ndecent size.", "sections": [{"title": "INTRODUCTION", "content": "Timely extraction of cybersecurity information from\ndiverse online web sources, such as news, vendor bulletins,\nblogs, forums, and online databases is vital for many types of\napplications. One important application is the conversion of\nunstructured cybersecurity information to a more structured\nform like ontologies. Knowledge modeling of cyber-attacks\nfor instance simplifies the work of auditors and analysts [1].\nAt the heart of the information extraction tasks is the\nrecognition of named entities of the domain, such as vendors,\nproducts, versions, or programming languages. The current\nNER tools that give the best performance in the field are\nbased on feature engineering. These tools rely on the specific\ncharacterizing features of the entities in the field, for\nexample, a decimal number that follows a product is very\nlikely to be the version of that product and not quantities of\nit. A sequence of words starting with capital letters is likely\nto be a product name rather than a company name and so on.\nFeature engineering has many issues and limitations.\nFirstly, it relies heavily on the experience of the person and\nthe lengthy trial and error process that accompanies that.\nSecondly, feature engineering relies on look-ups or\ndictionaries to identify known entities [2]. These dictionaries\nare hard to build and harder to maintain especially with\nhighly dynamic fields, such as cybersecurity. These activities\nconstitute the majority of the time needed to construct these\nNER tools. The results could be satisfactory despite requiring\nconsiderable maintenance efforts to keep them up to date as\nmore products are released and written about online.\nHowever, these tools are domain specific and do not achieve\ngood accuracy when applied to other domains. For instance,\na tool that is designed to recognize entities in the\nbiochemistry field will perform very poorly in the domain of\ncybersecurity [3].\nCRFs emerged in recent years as the most successful and\nde facto standard method for entity extraction. In this paper,\nwe show that a domain agnostic method that is based on the\nrecent advances in the deep learning field and word\nembeddings outperforms traditional methods, such as the\nCRFs. The first advancement, which is the word2vec word\nembedding method was introduced by Mikolov et al. [4]. It\nrepresents each word in the corpora by a low dimensional\nvector. Besides the gain in space, one of the main advantages\nof this representation compared to the traditional one-hot\nvectors [5] is the ability of these vectors to reflect the\nsemantic relationship between the words. For instance, the\ndifference between the vectors representing the words 'king'\nand 'queen' is similar to the difference between the vectors\nrepresenting the words 'man' and 'woman'. These\nrelationships result in the clustering of semantically similar\nwords in the vector space. For instance, the words 'IBM' and\n'Microsoft' will be in the same cluster, while words of\nproducts like 'Ubuntu' and 'Web Sphere Server' appear\ntogether in a different cluster.\nThe second advancement is the recent breakthroughs in\nthe deep learning field. It became feasible and practical\nbecause of the increase in the hardware processing power"}, {"title": "RELATED WORK", "content": "Approaches to NER are mainly either rule-based or\nmachine learning/statistical-based [11], although quite often\nthe two techniques are mixed [12]. Rule-based methods\ntypically are a combination of Gazette-based lookups and\npattern matching rules that are hand-coded by a domain\nexpert. These rules use the contextual information of the\nentity to determine whether candidate entities from the\nGazette are valid or not. Statistical based NER approaches\nuse a variety of models, such as Maximum Entropy Models\n[13], Hidden Markov Models (HMMs) [14], Support Vector\nMachines (SVMs) [15], Perceptrons [16], Conditional\nRandom Fields (CRFs) [17], or neural networks [18]. The\nmost successful NER approaches include those based on\nCRFs. CRFs address the NER problem using a sequence-\nlabeling model. In this model, the label of an entity is\nmodeled as dependent on the labels of the preceding and\nfollowing entities in a specified window. Examples of\nframeworks that are available for CRF-based NER are\nStanford NER and CRFSuite.\nMore recently, deep neural networks have been considered\nas a potential alternative to the traditional statistical methods\nas they address many of their shortcomings [19]. One of the\nmain obstacles that prevent the adoption of the methods\nmentioned above is feature engineering. Neural networks\nessentially allow the features to be learned automatically. In\npractice, this can significantly decrease the amount of human\neffort required in various applications. More importantly,\nempirical results across a broad set of domains have shown\nthat the learned features in neural networks can give very\nsignificant improvements in accuracy over hand-engineered\nfeatures. RNNs, a class of neural networks have been studied\nand proved that they can process input with variable lengths\nas they have a long time memory. This property resulted in\nnotable successes with several NLP tasks like speech\nrecognition and machine translation [20]. LSTM further\nimproved the performance of RNNs and allowed the learning\nbetween arbitrary long-distance dependencies [21].\nVarious methods have been applied to extract entities and\ntheir relations in the cybersecurity domain. Jones et al. [22]\nimplemented a bootstrapping algorithm that requires little\ninput data to extract security entities and the relationship\nbetween them from the text. An SVM classifier has been\nused by Mulwad et al. [23] to separate cybersecurity\nvulnerability descriptions from non-relevant ones. The\nclassifier uses Wikitology and a computer security taxonomy\nto identify and classify domain entities. The two previously\nmentioned works relied on standard NER tools to recognize\nthe domain concepts. While these NER tools obtained\nsatisfactory results in general texts, such as news, they\nperformed poorly when applied to more technical domains,\nsuch as cybersecurity because these tools are not trained on\ndomain-specific concept identification. For instance, the\nStanford NER tool is trained using a training corpus\nconsisting mainly of news documents that are largely\nannotated with general entity types, such as names of people,\nlocations, organizations, etc.\nTo overcome the limitations of NER tools in technical\ndomains and identify mentions of domain-specific entities,\nGoldberg [5] adopted an approach that trains the CRF\nclassifier of the Stanford NER framework on a hand-labeled\ntraining data. He achieved acceptable results that are much\nbetter than the two previous efforts. Although they produced\ngood results, the effort involved in painstakingly annotating\neven a small corpus prohibits the practical implementation of\nthis approach. To address this problem, Joshi et al. [3]\ndeveloped a method to automate the labeling of training data\nwhen there is no domain-specific training data available. The\nlabeling process leverages several data sources by combining\nseveral related domain-specific structured data to infer\nentities in the text. Next, a Maximum Entropy Markov\nModel has been trained on a corpus of nearly 750,000 words\nand achieved precisions above 90%. This type of training\nrelies on external sources for corpus annotation. These\nresources need to be regularly maintained and updated to\nmaintain the quality and precision of the text labeling.\nGiven the benefits of neural networks, this paper aims to\napply the LSTM method on the problem of NER in the\ncybersecurity domain using the corpora made available by"}, {"title": "LSTM-CRF MODEL", "content": "In this Section, we will provide an overview of the LSTM-\nCRF architecture as presented by Lample et al. [8].\nRNNs are neural networks that have the capability to\ndetect and learn patterns in data sequences. These sequences\ncould be natural language text, spoken words, genomes, stock\nmarket time series, etc. Recurrent networks combine the\ncurrent input (e.g., current word) with the previous perceived\ninput (earlier words in the text). However, RNNs are not good\nat handling long-term dependencies. When the previous input\nbecomes large, RNNs suffer from the vanishing or exploding\ngradient problems. They can also be challenging to training\nand very unlikely to converge when the number of parameters\nbecomes large.\nLSTMs were first introduced by Hochreiter et al. [7] They\nare an improvement on RNNs and can learn arbitrary long-\nterm dependencies, hence can be used for a variety of\napplications such as natural language processing and stock\nmarket analysis. LSTMs have a similar chain structure as\nRNNs, but the structure of the repeating nodes is different.\nLSTMs have multiple layers that communicate with each\nother in a particular way. A typical LSTM consists of an input\ngate, an output gate, a memory cell, and a forget gate. Briefly,\nthese gates control which input to pass to the memory cell to\nremember it in the future and which earlier state to forget.\nThe implementation used is as follows [8]:\n$i_t = \\sigma (W_{xi}x_t + W_{hi}h_{t-1} + W_{ci}c_{t-1} + b_i)$\n$c_t = (1 - i_t) \\odot c_{t-1} + i_t \\tanh(W_{xc}x_t + W_{hc}h_{t-1}+b_c)$\n$o_t = \\sigma (W_{xo}x_t + W_{ho}h_{t-1} + W_{co}c_t + b_o)$\n$h_t = o_t \\odot \\tanh(c_t)$\nThe sigma sign $\\sigma$ is the elementwise sigmoid function and\n$\\odot$ is the elementwise product.\nAssuming we have a sequence of n words X = (x1, x2,...,\nxn) and each word is represented by a vector of dimension d.\nLSTM computes the left context $lh_t$ which represents all the\nwords that precede the word t. A right context $rh_t$ is also\ncomputed using another LSTM that reads the same text\nsequence in reverse order by starting from the end and go\nbackward. This technique proved very useful and the\nresulting architecture, which consists of a forward LSTM and\na backward LSTM, is called a Bidirectional LSTM. The\nresulting representation of a word is obtained by\nconcatenating the left and right contexts to get the\nrepresentation $h_t = [lh_t;rh_t]$. This representation is useful for\nvarious tagging applications, such as the NER problem at\nhand in this paper.\nFigure 1 shows the architecture of the Bidirectional\nLSTM-CRF model. It consists of three layers."}, {"title": "EVALUATION", "content": "In this section, we will introduce the benchmark tool, the\npreprocessing performed on the gold standard corpora, and\nthe metrics we used for evaluation.\nWe compare the performance of the LSTM-CRF\narchitecture against a CRF tool that uses a generic feature set\nfor NER with word embeddings. These features were\ndesigned for domain-independent NER and defined by the\ntool writer. Using word embeddings in both systems will help\nus compare only the CRF method with the suggested LSTM-\nCRF architecture and negate the effect of word embeddings.\nWe used the CRFSuite to train a CRF model using the default\nsettings of the tool.\nWe performed our evaluation on around 40 entity types\ndefined in three corpora and also analyzed the performance\nof the model on a subset of the seven most significant entities\nof the domain. Each word in these corpora is auto-annotated\nwith an entity type. The corpus is an auto-labeled cyber\nsecurity domain text that was generated for use in the Stucco\nproject. It includes all descriptions from CVE/NVD entries\nstarting in 2010, in addition to entries from MS Bulletins and\nMetasploit. As stated in [1]: \"While labelling these\ndescriptions may be useful in itself, the intended purpose of\nthis corpus is to serve as training data for a supervised\nlearning algorithm that accurately labels other text"}, {"title": "Text Preprocessing", "content": "In its original form as provided by Bridges et al [1], all\nthe corpora were stored in a single JSON file with each\ncorpus represented by a high-level JSON element. To\nfacilitate further processing, we converted the file to the\nCONLL2000 format as the input for the LSTM-CRF model.\nIn the newly single annotated corpus, we removed the\nseparation between each of the three corpora and annotated\nevery word in a separate line. Each line contains the word\nmentioned in the text and its entity type as show in the\nfollowing example:\nApple B-vendor\nQuickTime B-application\nbefore B-version\n7.7 I-version\nallows B-relevant term\nremote B-relevant term\nattackers I-relevant term\nto O\nAs for the CRF model, the CRFSuite requires the training\ndata to be in the CoNLL2003 format that includes the Part of\nSpeech (POS) and chunking information with the NER tag\nappearing first as shown below:\nB-vendor Apple NNP O\nB-application QuickTime NNP O\nB-version before IN O\nI-version 7.7 CD O\nB-relevant term allows NNS O\nB-relevant term remote VBP O\nI-relevant term attackers NNS O\nO to TO O\nAs the original corpus did not contain the POS and\nchunking information, the training corpus had to be\nreprocessed. We started by converting it to its original form\n(i.e., a set of paragraphs). Then, we used the python NLTK\nlibrary to extract the necessary information for each word in\nthe corpus. Finally, we converted the text back to the\nexpected format shown above."}, {"title": "Evaluation Metrics", "content": "We divided the annotated corpus into 3 disjoint subsets.\n70% was allocated for the training of the model, 10% for the\nholdout cross-validation set (or development), and 20% for\nthe evaluation of the model. We compared the two models\n(LSTM-CRF and CRF) in terms of accuracy, precision,\nrecall, and F1-score for the full set of tags and for a subset of\nthe most relevant tags of the domain. In our experiments, the\nhyperparameters of the LSTM-CRF model were set to the\ndefault values used by Lample et al. [8]."}, {"title": "RESULTS AND DISCUSSION", "content": "We evaluated the performance of the NER method that is\nbased on the LSTM-CRF architecture against a traditional\nstate of the art CRF tool that uses standard NER features. The\nevaluation was performed on three different sets covering\nover 40 entity types from the cybersecurity domain. For\nevaluation purposes, we will analyze the average\nperformance of models across all the entity types, then we\nwill consider the most popular entities that appear frequently\nin the cybersecurity vulnerability descriptions and evaluate\nthe performance on these entities only. The entities\nconsidered are vendor, application, version, file, operating\nsystem (os), hardware, and edition. The reason for this is that\nwe are usually not interested in extracting all entity types but\nonly a subset of them that are most relevant to the application\nat hand.\nStarting with the global item accuracy of both models,\nFigure 2 shows the accuracy values measured on the test set\nat each iteration of the training stage for 100 iterations.\nLSTM-CRF achieved an accuracy of 95.8% after the first\niteration and increased gradually to reach values between\n98.2% and 98.3% starting from iteration 23 until the end of\nthe training. On the other hand, the CRF method started\nslowly at accuracies of 65% and increased rapidly to reach\naccuracies of 96% where it leveled off to reach eventually\n96.35%\nat the end of the\ntraining."}, {"title": "Performance of LSTM-CRF and CRF", "content": "We then compared the performance of LSTM-CRF and\nCRF on the most popular seven entity types in the domain.\nThe results for each method for the different entities in terms\nof F1-score, precision, and recall are shown in Tables II, III,\nand IV. LSTM-CRF achieved the best performance for all the\nentities types with the exception of the hardware, and edition\ntags, which affected the average considerably. On average\n(macro average), F1-scores are 82.8% for the generic LSTM-\nCRF method and 84.4% for the generic CRF method. In\nterms of precision, the results are close at 87.2% and 89%\nrespectively. As for the recall, it is 80.1% and 81.8%\nrespectively.\nWe can see that the overall item accuracy of the resulting\nLSTM-CRF model is higher by 2% than the CRF model.\nLikewise, the average precision, recall, and F1-score across\nall entity types are better by an average of 6.5%. As for the\nperformance metrics per entity type, the LSTM-CRF model\nperformed better on five entity types and poorly on the\nhardware and edition tags. The reason for this poor\nperformance is related to the size of the training data. Deep\nlearning algorithms such as LSTM, needs lots of data for\nbetter predictions. The more data we have, the better the\nprediction model can get. Upon analyzing the data set, it\nturned out that very few entities are tagged with these two\ntags compared to the other entities. There are 549 entities\ntagged as hardware and 565 tagged as edition. These\nnumbers are relatively low compared to other tags, such as\napplication (19093 tags) and vendor (10518 tags). Therefore,\nthe first five tags overwhelmed the other poorly performing\ntwo tags. Increasing the size of the training data that contains\nmore examples of these tags will improve the prediction of\nthe model."}, {"title": "CONCLUSION AND FUTURE WORK", "content": "As this paper showed, the results demonstrate that\nLSTM-CRF improved the accuracy of NER extraction over\nthe state-of-art traditional pure statistical CRF method. What\nis impressive about the LSTM-CRF method is that it does not\nrequire any feature engineering and is entirely entity type\nagnostic. Even the format of the training corpus is much\nsimpler, thus requiring less text pre-processing. This\nalleviates the need to develop domain-specific tools and\ndictionaries for NER. In the future, our research will\nconcentrate on applying the LSTM-CRF method on entity\nRelations Extraction (RE). RE is concerned with attempting\nto find occurrences of relations among domain entities in text.\nThis would provide a better understanding of product\nvulnerability descriptions. For example, RE could extract\ninformation from a vulnerability description that would help\nus distinguish between the product or tool that is the mean of\nan attack and the product being attacked. With information\nextraction becoming more accurate, more automated, and\neasier to achieve using recent neural networks advancements,\nthere is a pressing need to turn this advancement into\napplications in the domain of cybersecurity. One such\napplication is the conversion of the textual descriptions of\ncybersecurity vulnerabilities that are available in the web into\na more formal representation like ontologies. This gives\ncybersecurity professionals the necessary tools that grant\nthem rapid access to the information needed for decision-\nmaking."}]}