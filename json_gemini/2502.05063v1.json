{"title": "COMPUTING AND LEARNING ON COMBINATORIAL DATA", "authors": ["Simon Zhang"], "abstract": "The twenty-first century is a data-driven era where human activities and behavior, phys- ical phenomena, scientific discoveries, technology advancements, and almost everything that happens in the world resulting in massive generation, collection, and utilization of data. Connectivity in data is a crucial property. A straightforward example is the World Wide Web, where every webpage is connected to other web pages through hyperlinks, providing a form of directed connectivity. Combinatorial data refers to combinations of data items based on certain connectivity rules. Other forms of combinatorial data include social networks as simplicial complexes, molecules as graphs, sets of binary classifiers as hypergraphs, and ra- dius graphs from a metric space, which realizes connectivity for topological data analysis. This Ph.D. dissertation focuses on computation and learning on combinatorial data. Persistence theory asks the question of: \"What are the future dependencies of a vector in a time-indexed representation space?\". A canonical example is given by persistent ho- mology, which asks this question for a sequence of homology vector spaces. Homology is a measurement of \"partial disconnectedness.\" For example, it can measure an obstruction to traveling through a 2d surface from one point to another. Since persistence is computed over a causal ordering, computing persistent homology appears as an inherently sequential process which would make computation on GPU difficult. We find that much of the alge- braic computation only depends on the neighboring connectivity of the data and not on any algebraic operations, allowing for a CPU-GPU hybrid approach. When given samples from a metric space, higher order connectivity can be realized on samples through a Vietoris-Rips complex. The persistence can be computed efficiently by exploiting the heavy hitter case of \"generalized nearest neighbors.\" This can be computed massively in parallel on GPU with an efficient transfer of data structures between GPU and CPU. We have successfully designed and implemented algorithms and their implementations on GPU in the domain of persistent homology, achieving high performance by two open- source software, namely HYPHA and Ripser++. The multiset of pairs of time end points when a homology generator belongs to a homology vector space is called a persistence diagram. Since any pair of times which are equal belong to", "sections": [{"title": "1. INTRODUCTION", "content": "This Ph.D. dissertation focuses on learning and computing with combinatorial data, studying and examining topological and connectivity features within and across connected data to improve the performance of learning and achieve high algorithmic efficiency. The dissertation is structured into eight Chapters.\n\u2022 Chapter 1. The Introduction\n\u2022 Chapter 2. The background introducing all relevant notation and math. We begin with first order logic followed by set theory. We then introduce category theory which gives a general language for spaces and transformations between them. We then go through algebra, geometry and topology, which describe spaces with specific physical meaning. Finally, we review statistics and the relevant data that concerns this dissertation.\n\u2022 Chapter 3. We introduce what it means to compute persistence from an algebraic perspective. In persistence theory, we are given a functor F : D \u2192 Vec from the category D to the category of vector spaces over the reals and an acyclic subcategory Q(D) of D. We ask the question of: \"In what objects in im(F|Q(D)) does a vector in \u03bf \u2208 im(F|Q(D)) stay independent?\" We go over persistence theory in this context.\n\u2022 Chapter 4. ([1]) Persistence is often viewed through the homology functor with the category D provided as data. This is called persistent homology. The data is given as a sequence of simplicial complexes, which are in analogy to discrete manifolds. We ask the question of persistence for the homology vector spaces over the reals. This is an entirely linear algebraic question but much of the algebra is not needed, allowing us to devise a hybrid CPU/GPU approach, termed HYPHA, to compute persistent homology as a sparse matrix problem.\n\u2022 Chapter 5. ([2, 3]) This chapter is about computing persistence with GPU for con- nectivity that can be realized by a metric space. Ripser++ is a method to compute persistent homology induced by a metric. In Ripser++ we are in the same framework of persistent homology, but where the combinatorial data or Vietoris-Rips simplicial"}, {"title": "2. BACKGROUND", "content": "We go over all of the necessary mathematical notations and definitions to understand this thesis.\n2.1 First Order Logic\nIn order to have a language with which we can do reasoning, we must define a logic. We go over first order logic (FOL) [8] here in order to be able to define the later mathematical background.\nIn FOL, we define truth and false as two separate values that can be assigned to logical statements. These values are denoted by T and F, respectively. When expressing logic, we would like to connect true logical statements instead of false logical statements.\nIn FOL, we start with a domain of objects. These are in analogy to entities either physical or non-physical.\nDefinition 2.1.1. Objects can be one of either constant or variable. Variables are change- able but constants cannot change.\nIn FOL, in order to express objects in a language we define terms. These are in analogy to nouns in natural language. The objects \"pear\" and \"banana\" are examples of terms over the domain of tangible entitites.\nWhen there are multiple terms together, let:\nDefinition 2.1.2. An ordered list of terms be called a tuple.\nWe can also define a way to convert a tuple of terms into exactly one term. For example, \"the country of origin of (...)\" is a function on the term (...) that returns a single country.\nDefinition 2.1.3. A function in FOL is defined as taking a tuple of terms and returning a single term.\nWe can now formally define terms:\nDefinition 2.1.4. A term is a variable object, a constant object or a function of a tuple of terms.\nIn order to assign truth or falsity value to a tuple of terms, we define a predicate.\nDefinition 2.1.5. A predicate takes a tuple of terms and returns a single value of T or F\nPredicates are also known as atomic logical statements.\nIn FOL, we can build up atomic logical statements to form logical statements. We can do this by connecting logical statements to form more logical statements. These come about through logical connectives. We can also negate a logical statement to flip its True/False value. Quantifiers are used to assign truth value to a logical statement in terms of variables. Since logical statements are built from atomic logical statements, they must have one of either True or False value.\nDefinition 2.1.6. The connectives between two logical statements P,Q allow for the for- mation of another logical statement. These include:\n\u2022 (conjunction) P AND Q means \"both P and Q are True\"\n\u2022 (disjunction) P OR Q means \"one of P or Q are True\"\n\u2022 (implication) P \u21d2 Q means \"if P is True, then Q is True.\"\nDefinition 2.1.7. We can also take a logical statement P and flip its truth value through negation. We denote this by \u00acP.\nWe can also apply Quantifiers on variables.\nDefinition 2.1.8. A quantifier can be a \"for all\", denoted \u2200. This quantifier means that every possible object that the variable could instantiate, or be, is involved in the logical state- ment.\nDefinition 2.1.9. A quantifier can be an \"exists\", denoted \u2203. This quantifier means that some object that the variable could instantiate, or be, is involved in the logical statement.\nDefinition 2.1.10. A logical statement is defined as an atomic statement, logical state- ments with connectives in between them, logical statements with quantifiers on their variables, or a negated logical statement.\nWe can summarize the language of FOL in the following grammar: Under finiteness assumptions this grammar becomes a context free grammar [8]."}, {"title": "2.2 Set Theory", "content": "Foundational to the language of math is the concept of a set. Sets provide the building blocks of definitions that are usable in math. They are intimately tied to first order logic, providing a formalization to groupings of objects.\nDefinition 2.2.1. A set is an unordered collection of objects called elements.\nA set can be denoted by enumerating its elements via the following notation:\n$A = \\{ c_1, ..., c_n\\}$  (2.2)\nTo denote that an element e belongs to a set A, we use the notation e \u2208 A.\nSimilarly, to denote that an element e does not belong to a set A, we use the notation e \u2209 A.\nDefinition 2.2.2. The cardinality or size of a set is the number of elements in it. This number can be either finite or infinite. For a set A, let |A| denote its cardinality.\nA set can also be denoted by set-builder notation, this is a first order logical statement that determines the set in terms of another set.\n(2.4) For example, letting X denote the set of all \"fruits\".\n$A = \\{ x \u2208 X : x \\text{ is a red apple} \\}$ (2.5)\nis a set determined by the truthness of the logical statement \"x is a red apple\" where x is viewed as a variable.\nSome simple examples of sets include number systems, which are necessary for measurement:\n(2.6)\n\u2022 The natural numbers: N = {0, 1, 2, ...}\n\u2022 The integers: Z = {..., -2, -1, 0, 1, 2, ...}\n\u2022 The rational numbers: Q = {$\\frac{p}{q} : p, q \u2208 Z, q \\neq 0\\}$ \n\u2022 The real numbers: R\n\u2022 The closed intervals: [a,b] = {x \u2208 R : a \u2264 x \u2264 b}.\n\u2022 The closed-open intervals: [a,b) = {x \u2208 R : a \u2264 x < b}\n\u2022 The complex numbers: C\n\u2022 The integers from 1 to n: [n] = {1, ..., n}, n \u2208 N\n\u2022 The integer interval: {i, ...,j}, i, j \u2208 N, i \u2264 j\nThe natural numbers N can be bootstrapped from:\n1. The empty set, which represents 0 \u2208 N\n2. The singleton of an emptyset: {\u2205}, which represents 1 \u2208 N\n3. And the successor operation, which takes a natural number and increments it by 1. This is done by taking a set-theoretically constructed natural number and its union with {0}.\nThe other number systems are derivable from N, see [9, 10]."}, {"title": "2.3 Category Theory", "content": "We will briefly review category theory [12]. The definition of a category is motivated by classes of sets and the functions between these sets.\nIn order to define a category, we must define a generalization of a set called a class:\nDefinition 2.3.1. A class C is defined by its members, which are sets. A member c belonging to C is denoted c\u2208 C\nA subclass S \u2286 C of a class C has every member of S belonging to C.\nIn terms of observables in the real world, which is of more concern in computer science, we can assume that classes are just sets.\nWe define a category by classes of objects and morphisms, also called arrows, in analogy to sets and functions. Formally, we define a category Cas:\nDefinition 2.3.2. A category C = (ob(C), mor(C), dom : mor(C) \u2192 ob(C), codom : mor(C) \u2192 ob(C),\u25e6) where ob(C) is a class of objects, mor(C) are a class of morphisms, or arrows, and:\n\u2022 \u2200a,b,c\u2208 ob(C),\u25e6 : hom(a,b) \u00d7 hom(b,c) \u2192 hom(a,c) where hom(b,c) \u2286 mor(C) is a subclass of mor(C) where all f \u2208 mor(C) have dom(f) = b, codom(f) = c, denoted f:b\u2192c\n\u2022 The composition operation \u2022 is associative: \u2200a,b,c \u2208 ob(C), \u2200 f : a \u2192 b, g : b \u2192 c, h : c \u2192 d, h\u25e6 g\u25e6 f = (h\u25e6 g) \u25e6 f = h \u25e6 (g\u25e6 f)\n\u2022 \u2200a \u2208 ob(C), ida : a \u2192 a, \u2200 f \u2208 mor(C), id\u0105 o f = f \u00a9 ida = f\nWe can view categories as sets with the following definitions:\nDefinition 2.3.3. A category C where the class of objects ob(C) is a set is called a small category.\nFurthermore, if the category where the class of morphisms is also a set then C is called a locally small category.\nWe will attempt to make all categories locally small categories.\nWe will often denote locally small categories C by a pair (V, E) where V is a set of objects and E is a set of morphisms between objects. We can also recover the objects and morphisms of C with the notation: V(C) and E(C). These are the sets of objects and morphisms of C.\nDefinition 2.3.4. A category C is finite if its class of objects is a finite set and the class of morphisms is also a finite set.\nA finite category C is a locally small category and a locally small category is a small category. The converses to any of these statements are not true, however.\nA subcategory S of a category C is a category derived from the same objects and mor- phisms of category C while preserving the same properties of C using S. This is formally defined below:\nDefinition 2.3.5. For category\nC = (ob(C), mor(C), dom : mor(C) \u2192 ob(C), codom : mor(C) \u2192 ob(C),\u0970)\na subcategory S \u2286 C has:\nob(S) \u2286 ob(C) as a subclass and mor(S) \u2286 mor(C) as a subclass and:"}, {"title": "2.4 Algebra", "content": "Algebra is a branch of math that involves sets with binary operations defined on them, called algebraic structures. These algebraic structures generalize arithmetic over number systems.\n2.4.1 Monoids\nOne of the simplest algebraic structures are monoids. These are simply sets with a binary operation along with a designated identity element.\nDefinition 2.4.2. A monoid (M,\u00b7) has that M is a set and \u00b7 is a binary operation that takes two element a,b \u2208 M to form an element a\u00b7be M has two properties:\n1. (Associativity) a\u00b7 (b\u00b7 c) = (ab).c\n2. (Identity Element) \u2203\u0435\u0454 \u041c with e\u00b7 a = a, \u2200a \u2208 M\nDue to a monoid's simplicity, most other algebraic structures inherit it's structure. Monoids generalize the natural numbers N with addition.\n2.4.3 Groups\nA slightly more structured algebraic structure is a group. These are generalizations of the integers.\nDefinition 2.4.4. A group (G,\u00b7) consists of a non-empty set G together with a binary operation on G, here denoted \u00b7, that combines any two elements a,b e G to form an element of G. This binary operation satisfies the following axioms:\n\u2022 Associativity: Va,b,c\u2208G, one has (a\u00b7b) \u00b7 c = a \u00b7 (b. c).\n\u2022 Identity element: There exists a unique element e e G such that, for every a \u2208 G, one has e \u00b7 a = a and a\u00b7e = a. It is called the identity element.\n\u2022 Inverse element: For each a \u2208 G, there exists an element b \u2208 G such that a\u00b7b = e and b\u00b7a = e, where e is the identity element. For each a, the element b is unique and denoted a-1.\nThe category Grp has objects as groups and morphisms called homomorphisms.\nA group is called abelian if its binary operation has the commuting property:\n\u2200a, b \u2208G : a\u00b7b = b \u00b7 a (2.48)\nThese are special objects in the category Grp.\nDefinition 2.4.5. For two groups (G1,1), (G2,\u00b72), a group homomorphism \u00a2 : (G1,\u00b71) \u2192 (G2,2) is a map that satisfies the following commuting diagram:\nThis can be equivalently written as:\n\u03c6(\u03b1\u00b71 b) = \u03c6(\u03b1) \u00b72 $(b), \u2200a, b \u2208 G1 (2.50)\nAs in category theory, the group isomorphism and group automorphism are defined based on the group homomorphism.\nDefinition 2.4.6. A subgroup (H,\u00b7) of a group (G,\u00b7), denoted H \u2264 G has H \u2286 G as a subset where (H,\u00b7) is a group with the same binary operation of (G,\u00b7).\nA special subgroup that has a partial commuting property can be defined. This is helpful for defining an equivalence relation on a group that respects its binary operation:"}, {"title": "2.5 Euclidean Geometry", "content": "Euclidean geometry in damb-dimensions is a space that models the physical world. It can be defined as an affine space. As an affine space it is defined by the pair (E, E) where E is a set of points determined by a tuple of damb real numbers and Eis represented as a real vector space Rdamb of damb dimensions. The space of points E has an origin point, denoted 0, which is the all O's tuple. The vectors in Eare called Euclidean vectors.\nThe vectors ve\u1eba act on E via the following map:\n$(v, p) \u2192 p + v \u2208 \u0395$\n(2.156)\nwhere the addition between p and v is an entry-wise addition of the two damb lengthed tuples.\nFor any p\u2208 E this map is a free and transitive group action [16], meaning it satisfies the following properties:\n1. (Right identity) p + O = p, \u2200 p \u2208 E, O\u2208\u1eba\n2. (Associativity) p + (v + w) = (p + v) + w, \u2200v, w \u2208 \u0395\n3. (Free and transitive action) v \u2194 p + v, \u2200pe E is a bijection\nAccording to property (3) of the group action, for any two points p, q \u2208 E, there is a unique displacement vector qp = p -q \u2208 E determined by the points p and q.\nE forms a vector space: Viewing points as vectors displaced from the origin, E can form a vector space with the addition between two points p, q \u2208 E defined as\n$p + q = (p - 0) + (q \u2212 0) + 0 \u2208 E$ (2.157)\nand scalar multiplication by ce Ron a point pe Eas:\n$cp = c(p \u2013 \u2642) + \u2208 E$ (2.158)\nThe physical meaning of the Euclidean vector is as a direction. This means for a Euclidean vector v \u2208 that for any point pe E, the points q(t) = p + t \u00b7 v, \u2200t \u2208 [0, \u221e) are all displaced away from p in the direction v.\nDefinition 2.5.1. An affine subspace of Euclidean space (E,E) is defined by the pair ({a + v :v \u2208 E'}, \u0395') where a \u2208 E is a single point and E\u2286 \u00c8 is a linear subspace of E. We say that a point q \u2208 E belongs to a p-dimensional affine subspace if there exists a \u2208 E and \u1eba \u2286 \u00c8 so that q \u2208 {a + v : v \u2208 F} and dim(E') = p\nThe space \u1eba is equipped with the Euclidean inner product, called the dot product, between Euclidean vectors. The dot product between two Euclidean vectors is defined by:\n$u. v = \\sum_{i=1}^{d_{amb}}u_i v_i, \u2200 u, v \u2208 E$\n(2.159)\nThe norm of a vector in Euclidean space \u1eba is defined through the dot product:\n$||v||_2 = \\sqrt{v \\cdot v}$ (2.160)\nAny vector ve \u1eba with norm 1 is called a unit vector."}, {"title": "3 COMPUTING PERSISTENCE", "content": "This Ph.D. dissertation focuses on learning and computing with combinatorial data, studying and examining topological and connectivity features within and across connected data to improve the performance of learning and achieve high algorithmic efficiency. The dissertation is structured into eight Chapters.\n\u2022 Chapter 1. The Introduction\n\u2022 Chapter 2. The background introducing all relevant notation and math. We begin with first order logic followed by set theory. We then introduce category theory which gives a general language for spaces and transformations between them. We then go through algebra, geometry and topology, which describe spaces with specific physical meaning. Finally, we review statistics and the relevant data that concerns this dissertation.\n\u2022 Chapter 3. We introduce what it means to compute persistence from an algebraic perspective. In persistence theory, we are given a functor F : D \u2192 Vec from the category D to the category of vector spaces over the reals and an acyclic subcategory Q(D) of D. We ask the question of: \"In what objects in im(F|Q(D)) does a vector in \u03bf \u2208 im(F|Q(D)) stay independent?\" We go over persistence theory in this context.\n\u2022 Chapter 4. ([1]) Persistence is often viewed through the homology functor with the category D provided as data. This is called persistent homology. The data is given as a sequence of simplicial complexes, which are in analogy to discrete manifolds. We ask the question of persistence for the homology vector spaces over the reals. This is an entirely linear algebraic question but much of the algebra is not needed, allowing us to devise a hybrid CPU/GPU approach, termed HYPHA, to compute persistent homology as a sparse matrix problem."}, {"title": "3.1 Persistence", "content": "The above question motivated by Gaussian elimination hints at a generalization.\nFor the Gaussian elimination case we had a composable sequence of maps on subspaces of Rn. On the ith space Vi \u2286 Rn, the next space Vi+1 \u2286 Rn can be viewed as adding more generators and relations to the Vi. For a vector us \u2208 F(vs) we would also like to track the merging of generators from the past j that \"happened before\" index i + 1 into the i + 1-th space due to a composition of maps from space j to space i + 1.\nWe can then generalize the above to the following definition:\nDefinition 3.1.1. A data representation functor on a finite simple acyclic sub- category is defined by the pair:\n(F : D \u2192 Span Vec, Q(D) = (V, E)) (3.8)\nwhere the image of the restricted functor must satisfy:\nim(F|Q(D))) = Subspan Vec(W) (3.9)\nThis is the category of subobjects of a common object W = (Forget(W), W) \u2208 ob(Span Vec) where W is a vector space. The object W is called an embedding space.\nThe functor F : D \u2192 SpanVec is a functor from some data category D to the category of vector spaces with spanning sets, SpanVec.\nThe category SpanVec is defined in Definition 2.4.35.\nAs in the case of Gaussian elimination, each new column vector provides new information to a sequence of linear maps. In analogy, for an object (S, V) \u2208 ob(SpanVec), S provides a set of free generators to the presentation of a vector space from a vector representation of ob(D). If these free generators can be determined without ambiguity, then the target category of the functor F can be replaced with Vec.\nThe finite simple acyclic subcategory Q(D) represents some relevant observable portion of the data which can be measured by the functor F. Due to acyclicity of Q(D), finite paths"}, {"title": "3.2 Persistent Homology", "content": "Persistence theory was originally formulated in terms of the homology functor over a finite filtered simplicial complex. This can be denoted by:\n(3.63) The functor (H. : Simp \u2192 Vec, Q(Simp)) from Section 2.6.8 where the finite simple acyclic subcategory Q(Simp) = (V, E) has:\n$V = \\{K_i\\}_{i=0}^{n}, E = \\{inc_{i,j} : K_i \\rightarrow K_j\\}_{i,j\\in\\{0,...,n\\}:i\\leq j}$ (3.64)\nThis is called a filtration on simplicial complexes and denoted $K_0 \\subseteq K_1 \\subseteq ... \\subseteq K_n$.\nIf $K_0 = \\emptyset$ and $K_{i+1} = K_i\\cup \\{\u03c3_{i+1}\\} ,\u03c3_{i+1}$ a new simplex so that $K_{i+1}$ is still an abstract simplicial complex. We then call this finite simple acyclic subcategory as a simplex-wise filtration. For a simplex-wise filtration, for any two simplices \u03c3j, \u03c3\u2081 \u2208 Kn we can define the total order:\n$\u03c3_j < \u03c3_i \\text{ iff } j < i$ (3.65)\nThese two vector subspaces of  < S > satisfy:\n$Syzygy_1(<S_i>, V_i) \\subseteq Syzygy_1(<S_{i+1}>, V_{i+1})$ (3.6)\nup to isomorphism. If the two vector spaces are isomorphic, then (1) occurs, otherwise (2) occurs.\nPersistence theory on the tuple\n(F: Tot OrderedSet \u2192 SubspanVec((Forget(Rr), Rr)), Q(TotOrderedSet)\n= (V = {S}, E = {inc : Si \u2192 Sj}i,je{0,...,m}:i\u2264j)\nasks the question:\nQuestion 3.0.1. For any $v_s \\in R^n$, 1 \u2264 s \u2264 m, for which i which \"happening after\" s, s < i < m, do we have that:\n1. (New Independence) $v_i \\perp im(\\phi_{i-1,i})$ or\n2. (New Dependencies) $\u2203c_s \\neq 0$ with $v_i = c_s v_s + \u2211_{j < i} c_j v_j$"}, {"title": "3.2.11 Matrix Reduction for Computation", "content": "Given $Q(Simp) = (V = \\{K_i\\}_{i=0}^{n}, E = \\{inc_{ij}: K_i \\rightarrow K_j\\}_{i,j\\in\\{0,...,n\\};i<j})$, as a simplex-wise filtration of simplicial complexes $\\emptyset = K_0 \\subseteq K_1 \\subseteq ... \\subseteq K_n$. In order to compute the interval modules for the induced persistence module for the simplex-wise filtration, we can devise the following \"standard algorithm\" for persistent homology.\nIn the order of the filtration $\u2205 \\subseteq K_1 \\subseteq ... \\subseteq K_n$, for each dimension p > 0 and for each simplex $\u03c3_i \u2208 K_i \u2216 K_{i\u22121}$, $ K_i \u2216 K_{i\u22121} \u2286 C_{p+1}(K_n)$, we compute the boundary of $\u03c3_i$ as defined in Equation 2.6.7 viewed as a column vector in $R^n$: $[\u2202_{p+1}(\u03c3_i)] \u2208 R^n$.\nThen, while respecting the causality of the filtration, we check for the independence of $\u2202_{p+1}(\u03c3_i)$ from the subspace $span(\\{\u2202_{p+1}(\u03c3_j)\\} = 1)^i$. The intention is to compute the intervals as determined by Gabriel's theorem. According to Theorem 3.2.9, we know that these intervals are an answer to \"The Question of Persistence across Vector Spaces\" in the general framework of Question 3.1.1.\nThe independence check can easily be accomplished by vector addition from left to right onto column $[\u2202_{p+1}(\u03c3_i)]$ over the partial boundary matrix $[[\u2202_{p+1}(\u03c3_1)]||\u2026||[\u2202_{p+1}(\u03c3_i)]]$ (the con- catenation of the first i vectors: $\\{[\u2202_{p+1}(\u03c3_j)]\\}_{j=1}^{i}$), viewed as column vectors in $R^n$, where n is the number of simplicial complexes in the filtration.\nThe independence test of left to right column addition must respect the arrows pro- vided by the filtration. In matrix terms, for any matrix M these columns are defined as causal past columns for column M[i] of M that respect the nonzeros of column M[i]:\nDefinition 3.2.12. A column j of matrix M is a causal past column for column M[i] if j < i and all nonzero entries of column j have index less than or equal to the largest index of a nonzero of column M[i].\nSimilarly, a column k of matrix M is a causal future column for column M[i] if k > i and all nonzero entries of column k have row index greater than or equal to the smallest index of a nonzero of column M[i].\n(3.84) In terms of the $[\u2202_{p+1}]$ boundary matrix, this means for column $[\u2202_{p+1}(\u03c3_i)]$ we only add the causal past columns $ [\u2202_{p+1}(\u03c3_j)] = [\u2202_{p+1} \u2211(-1)^k [(\u03c3_j)_{-k}]|$ for j < i that have all summands $ [\u03c3_i] = [(\u03c3_j)_{-k}]| having the property that i \u2264 max\u03bf\u03c4 \u2208 \u03b8p+1(\u03c3i ) M.\nWe can then form a submatrix of M involving all of the causal past columns of a column M[i]. We call this concatenation of columns the causal past submatrix."}, {"title": "3.2.25 Time Reversal and Duality", "content": "In persistence theory, when given a pair of a functor and a finite simple acyclic subcat- egory (F : D \u2192 Vec, Q(D)), if the functor F is covariant, then the directions of the arrows in the upstairs Q(D) category are preserved in the downstairs category im(F|Q(D)). On the other hand, if the functor F is contravariant, then the arrows in the downstairs im(F|Q(D)) are all reversed. We call the use of a contravariant functor Fon an acyclic subcategory Q(D) as introducing time reversal through contravariance.\nAccording to Section 2.4.20, we have the duality functor between finite dimensional vector spaces and finite dimensional dual vector spaces:\n\u2022 \u22a5 : Vec \u2192 Vec\u22a5\nFor the case of covariant functors F : D \u2192 Vec, we can then define the dual functor F\u22a5 : D \u2192 Vec\u22a5 as the functor F\u22a5 \u2245 \u2022\u22a5 \u25e6F. The functor F\u22a5 is a contravariant functor due to the following non-commuting diagram on vector spaces V, W:\nWe define a dual persistence module in terms of dual vector spaces:\nDefinition 3.2.26. For a pair of a functor with finite simple acyclic subcategory (F : D \u2192 E, Q(D) \u2286 D),\nIf V = im(F |Q(D)) is a persistence module.\nA dual persistence module V\u22a5 of the persistence module V is the persistence module:\nV\u22a5 \u2245 (im(F |Q(D))\u22a5) (3.110)\nThis means the concept of time is reversed in a dual persistence module for vector spaces. We call this the time reversal through duality principle."}, {"title": "5 GPU-ACCELERATED COMPUTATION OF VIETORIS-RIPS PERSISTENCE BARCODES", "content": "HYPHA is an approach to solve the matrix reduction problem for persistent homology using the GPU in a CPU/GPU hybrid framework. The matrix reduction problem is concerned with computing an interval composition of Gabriel's theorem [29] for a sequence of vector spaces, namely homology vector spaces. We ask the question of how to compute persistent homology when more assumptions on the data are available. In particular, given a finite metric space, it is possible to construct a filtration of simplicial complexes from this finite metric space called the Vietoris-Rips filtration. This introduces a boundary map between adjacent dimensions of connectivity. Applying the H. functor to this filtration allows us to compute persistence across the downstairs persistence module of homology vector spaces.\nWe then ask the following question:\nQuestion 5.0.1. In the context of the Vietoris-Rips filtration, what are the parallelization opportunities for GPU when computing persistent homology?\nThe computation of Vietoris-Rips persistence barcodes is both execution-intensive and memory-intensive. In this paper, we study the computational structure of Vietoris-Rips persistence barcodes, and identify several unique mathematical properties and algorithmic opportunities with connections to the GPU. Mathematically and empirically, we look into the properties of apparent pairs, which are independently identifiable persistence pairs com- prising up to 99% of persistence pairs. We give theoretical upper and lower bounds of the apparent pair rate and model the average case. We also design massively parallel algorithms to take advantage of the very large number of simplices that can be processed independently of each other. Having identified these opportunities, we develop a GPU-accelerated software for computing Vietoris-Rips persistence barcodes, called Ripser++. The software achieves up to 30x speedup over the total execution time of the original Ripser and also reduces CPU-memory usage by up to 2.0x. We believe our GPU-acceleration based efforts open a new chapter for the advancement of topological data analysis in the post-Moores Law era."}, {"title": "5.1 Vietoris-Rips Filtrations", "content": "When computing persistent homology, data is usually represented by a finite metric space X, a finite set of points with real-valued distances determined by an underlying metric d between each pair of points. A metric is defined formally below:\nDefinition 5.1.1. A metric d : X \u00d7 X \u2192 R+ on a point set X is a real-valued function on pairs of points so that:\n\u2022 d(x,x) = 0, \u2200x \u2208 X (identity distance is zero)\n\u2022 d(x,y) > 0 if x + y \u2208 X (distance between differing point is positive)\n\u2022 d(x,y) = d(y,x), \u2200x,y \u2208 X (symmetry)\n\u2022 d(x,z) \u2264 d(x,y) + d(y, z), \u2200x,y,z\u2208 X (triangle inequality)\nWe say a metric d has no equidistant points if\n$d(x,y) = d(z,w), \u2200x,y,z,w\u2208 X \\text{ and } (x,y) \\neq (z, w)$ (5.1)\nThe metric space X is defined by its distance matrix D, which is defined as D[i,j]=\nd(point i, point j) with D[i, i] = 0. This finite metric space X can be considered as a set of\nsamples from a distribution P(x) supported on a i.i.d. set of points X \u2287 X with a global\nmetric dglobal on X. With dglobal, we can define the aspect ratio of X as\n$\u03b1(X)_{dglobal} = \\frac{max_{x,y\u2208X} d_{global}(x, y)}{min_{x,y\u2208X} d_{global}(x, y)}$ (5.2)\nThere does not have to exist a global metric, however. The finite metric space can be defined on the samples alone.\nDefine an (abstract) simplicial complex K as a collection of simplices closed under the subset relation, where a simplex s is defined as a subset of X. This means that any simplex s' : s' \u2286 s must also belong to K. We call a \"filtration\" as a totally ordered sequence of growing simplicial complexes. A particularly popular and useful [97] filtration is a Vietoris- Rips filtration. On the metric space, we hallucinate simplices over an adjustable threshold"}, {"title": ""}]}