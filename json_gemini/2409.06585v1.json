{"title": "Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records", "authors": ["Zoe Hancox", "Andrew Clegg", "Sarah R. Kingsbury", "Philip G. Conaghan", "Samuel D. Relton"], "abstract": "Background: Hip replacement procedures improve patient lives by relieving pain and restoring mobility. Predicting hip replacement in advance could reduce pain by enabling timely interventions, prioritising individuals for surgery or rehabilitation, and utilising physiotherapy to potentially delay the need for joint replacement. This study predicts hip replacement a year in advance to enhance quality of life and health service efficiency. Methods: Adapting previous work using Temporal Graph Convolutional Neural Network (TG-CNN) models, we construct temporal graphs from primary care medical event codes, sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip replacement risk. We match hip replacement cases to controls by age, sex, and Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187 controls, predicts hip replacement one year in advance. We validate the model on two unseen datasets, recalibrating for class imbalance. Additionally, we conduct an ablation study and compare against four baseline models. Results: Our best model predicts hip replacement risk one year in advance with an AUROC of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209), achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after recalibration. Conclusions: The TG-CNN model effectively predicts hip replacement risk by identifying patterns in patient trajectories, potentially improving understanding and management of hip-related conditions.", "sections": [{"title": "I. INTRODUCTION", "content": "The ageing population, coupled with increasing obesity rates, contributes to a rising prevalence of Osteoarthitis (OA) and hip replacements, causing pain and diminished quality of life [1]\u2013[5]. OA presents a significant challenge for UK healthcare, with musculoskeletal (MSK) issues accounting for 1 in 5 to 1 in 7 GP consultations [6], [7]. The burden is exacerbated by a growing number of joint replacements, particularly for knee and hip OA [8], placing strain on both the National Health Service (NHS) and affected individuals [9]. For patients with advanced OA, total joint replacement may be recommended if conservative treatments fail.\nMSK conditions impose not only financial burdens but also significant well-being impacts, potentially leading to conditions like depression or obesity [6]. Previous analysis of CPRD data revealed that 32.5% of individuals with hip OA underwent total joint replacement [5]. Between 2003 to 2014, there were 708,311 primary total hip replacements in the UK [8]. Recognising alternative diagnoses associated with hip replacement surgeries may help delay or reduce the need for these invasive procedures.\nElectronic Health Record (EHR) data, commonly collected during primary and secondary healthcare visits, provides structured and temporal information. However, the irregular time intervals within EHRs present a challenge for designing predictive algorithms in healthcare. Predicting post-surgery intensive care unit admission or hip replacement in advance using preoperative data supports efficient resource allocation and improves patient outcomes. Using temporal EHRs could assist in accurately forecasting health-related outcomes [10], [11], thereby aiding clinical decision-making and patient care. Additionally, machine learning models extract valuable in-sights, such as disease progression, from EHRs [12].\nThis paper presents a model combining temporal graphs, 3D convolutional neural networks (CNNs), and Long Short-term Memorys (LSTMs) to process Read Codes and time intervals from EHRs. Read Codes are clinical terms used in the UK to electronically record patient symptoms, results and treatments in health and social care. The 3D CNN captures short-term temporal patterns, while the LSTM han-dles longer-term associations. The project aims to explore variations of the Temporal Graph Convolutional Neural Network (TG-CNN) model for predicting hip re-placements in individuals [13]. The long-term goal is to develop a clinical decision support tool promoting trust, aiding patient-clinician discussions, offering personalised medicine, and enhancing patient safety.\nThis paper makes the following contributions:\n\u2022 Representing individual patient EHRs as temporal graphs and adapting the TG-CNN model to the clinical domain.\n\u2022 Improving the efficiency of the 3D CNN layer using sparse linear algebra.\n\u2022 Conducting an ablation study to evaluate model layers, regularisation techniques, and inclusion of demographic and prescription data.\n\u2022 Developing a prognostic model for predicting hip replace-ment risk one year in advance."}, {"title": "II. RELATED WORK", "content": "[14] investigated predicting the risk of hip replacement among patients with osteoarthritis or hip pain in the UK using CPRD data. They developed cumulative incidence equations to forecast the 10-year probability of hip replacement, nar-rowing down the model to 20 predictors for hip replacement. They achieved an Area under the Receiver Operator Curve (AUROC) of 0.72 and a C-slope of 1.00. This study marked the first clinical risk prediction model for hip replacement in patients newly presenting with hip pain/osteoarthritis in primary care. To the best of our knowledge this is the only existing work to predict hip replacement risk without using radiographic images.\nHip injury strongly indicated future hip replacement risk [14]. Other models, such as those by [15] and [16], employ ra-diographic images for prediction. Utilising TG-CNN and EHR data from primary care services to predict hip replacement risk could reveal novel patterns associated with the procedure, thus enhancing predictive accuracy. This approach might facilitate early intervention or triage for individuals showing potential hip replacement indicators.\nIn a study on deep learning methods for handling irreg-ularly sampled medical time series data [17], linear regres-sion, Random Forests (RFs), and Support Vector Machines (SVMs) showed predictive capabilities for health outcomes but struggled to integrate irregular time data effectively. Con-versely, T-LSTM and DATA-Gated Recurrent Unit (GRU) models were suitable for accommodating irregularly sampled data, with DATA-GRU featuring implicit attention mechanisms that enhance interpretability. Our model generates informative features, evaluates events within their clinical context to reduce reporting bias, and incorporates elapsed time between events.\nThe TG-CNN model, originally demonstrated on an online course clickstream dataset to predict student dropout [13], faces a key distinction in the medical domain when using EHRs: EHRs can record multiple Read Codes per visit, leading to parallelism within graph networks, whilst click actions can only occur sequentially."}, {"title": "III. METHODS", "content": "The methodology proposed in this paper incorporates the elapsed time between EHR events (CTV3 Read Codes), alongside automatically capturing informative features within the data. In this work, we build on the TG-CNN model which combines temporal graph theory and CNNs to analyse structural, temporal data [13].\nA. Cohort Analysis\nWe utilise NHS data from ResearchOne, managed by The Phoenix Partnership (TPP), comprising clinical and admin-istrative data from 151,565 patients aged 40-75, attending healthcare practices in England that use SystmOne. Patients had their first record of joint pain clinically coded between April 1st, 1999, and March 31st, 2014 [18]. This age range was chosen as these patients are likely to present with MSK symptoms. Descriptive cohort characteristics are detailed in Table I, prior to removing ineligible records.\nIn this paper, an EHR refers to a patient's record, consisting of reported primary care CTV3 Read Codes with timestamps. Each record also includes age, sex, and Index of Multiple Deprivation (IMD) score, a measure of location-based depri-vation based on postcodes [19]. Including IMD in our model is crucial, as research indicates that individuals with higher IMD scores (indicating lower deprivation) are less likely to have hip replacements [5].\nB. Data Extraction\nTime windowing: To forecast hip replacements occurring one year in advance, we identify the specific time of the replacement and gather all available patient records from 1999 up to one year prior to the replacement date (see Figure 1). Patient inclusion criteria: Patients needed a minimum of two primary care provider visits before the one year prior to a hip replacement (partial or full). Clinician-selected CTV3 Read Codes (n=45) for primary hip replacement were utilised for the outcome, with the incident date defined as the first occurrence of one of these codes. The codes can be found in supplementary materials\u00b9 Table S1. The initial recorded hip replacement instance served as the label. To mitigate the influence of age, sex, and IMD on joint replacement, one-to-one matching was performed for these variables in the training dataset of each hip replacement patient. This ensures prediction performance is unaffected by differences in these variables. A small fraction (0.007%, n=1,039) of patients in this dataset deceased, with 7 of them having undergone hip replacement.\nC. Feature Choices\nDemographic characteristics, including sex, age, and IMD, were collected alongside all events and medical history within specified time periods. The most commonly used 512 Read Codes, covering 99.71% of the data, were selected to construct temporal graph-based EHR representations for each patient, ensuring detailed representation while avoiding overfitting. Additionally, body mass index (BMI) was included as a predictor among the Read Codes. The first recorded IMD value for each patient was used for consistency, given its stability over time. Predictors synonymous with hip replacement, such as Read Codes for hospital referral, were excluded from the model. For the ablation study, medications were appended as 6 predictors using British National Formulary (BNF) codes, grouping drugs into opioids (04.07.02), non-opioid analgesics (04.07.01), and non-steroid anti-inflammatory drug (NSAIDs) (10.01.01), further subgrouped into acute and repeat prescrip-tion types. This addition brings the total number of predictors in the model to 521 when we include age, sex and IMD score.\nD. Temporal Graph Representation of EHRS\nIn discrete mathematics, a graph $G = (V, E)$ comprises nodes $V$ linked by edges $E$ [20], [21]. Our method involves transforming sequences of Read Codes from EHRs into tem-poral multigraphs, framing hip replacement risk prognosis as a graph classification problem. Each temporal graph represents an individual and is classified to provide risk probabilities. We utilise Read Codes as graph nodes $V$, while temporal edges $E$ capture time intervals between code occurrences, measured in months, represented in a 3D tensor $G(i, j, k) = t_k$, where $i,j \\in {1,...,n}$ indicate graph nodes, and $t_k$ is the time elapsed for the $k$th edge. Each of the 512 most frequently used CTV3 codes maps to one node $V_1, V_2,..., V_{512}$. Figure 2 demonstrates how we convert a snippet of an EHR into 3-tensors. We set $k = 100$ as the maximum number of time steps, resulting in a 3-tensor input size of $512 \\times 512 \\times 100$. By representing Read Codes as graphs rather than linear sequences, we accommodate multiple code recordings per patient visit, forming temporal graphs. These graphs are then fed into a TG-CNN deep learning algorithm, enabling pattern detection within Read Code graph structures and temporal features. An overview of using EHR data for joint replacement prediction is provided in Figure 2, and the model architecture is detailed in Section III-E.\nE. Model Architecture\nTensorFlow was employed to craft a custom 3D CNN Keras layer using sparse linear algebra. The temporal graph representation, sized at 512x512 \u00d7 100, undergoes processing through this layer to extract Read Code sequence and elapsed time patterns (see Figure 2). The output of the CNN is a sequence of feature vectors capturing short patterns (account-ing for elapsed time). The CNN output is flattened, followed by batch normalisation for faster convergence, and subsequent layers include a Leaky Rectified Linear Unit (ReLU), LSTM (captures longer temporal patterns), dropout, dense layers, and concatenation with demographic features (if included). Finally, the model employs categorical cross-entropy loss with sigmoid for the categorical target. Tensorflow 2.8.0, NumPy 1.19.2, Pandas 1.2.4, Scikit-Learn 0.23.1, and CUDA 10.2.89 were used on a desktop with a NVIDIA RTX 3090. Interested readers can access our Git repository\u00b9 for code exploration.\nEvents occurring further in the past may have a diminishing impact on recent events. Therefore, clinicians typically focus on recent health records rather than trawling through years' worth of data. Similarly, models predicting patient outcomes prioritise recent events. In this task, we limit our analysis to the 100 most recent primary care visits per patient to manage computational load. We front-pad any 3-tensors representing fewer than 100 visits, ensuring the most recent visits are always at the end of the 3-tensor. Multi-stream networks are also explored to search over different granularities in time, in our two stream model we use a stride of 1 in the coarse stream and 2 in the fine stream.\nEvents occurring closely together may indicate a worse health condition compared to those with wider time intervals between them. To capture this, a modified version of elapsed time is stored, measuring the proximity of two events occur-ring. The graph is transformed using $G(i, j, k) = exp(-\\gamma t)$, where $\\gamma$ is a trainable model parameter. This transformation assigns a score of 1 to simultaneous events and close to 0 for events with a large time gap. Elements indicating no interaction between node pairs at a set time are set to 0.\nWe employ an l\u2081 (LASSO) regularisation penalty on each filter to prevent overfitting and promote sparsity. This reg-ularisation is applied by adding the l\u2081 norm to the loss: $loss + \\sum_{i=0}^{n}|w_i|$, where $n$ is the number of features in the dataset, $w_i$ represents the weight for the $i$th feature, and $\\lambda$ is the regularisation strength. Filters help approximate a subgraph, implying that if an individual's EHR is close to a given filter, their disease outcome will match. We incorporate a graph regularisation function, denoted as $l_G$, which penalises the model with a graph regularisation strength $\u03bb_G$ if the filter deviates from a typical graph structure, such as when a node lacks incoming or outgoing connections to other nodes.\nF. Comparison Models\nAn ablation study is carried out using 10 variations of the models to assess component benefit as shown in Table II, we also evaluate a model variation which includes prescriptions. When evaluating TG-CNN performance in modelling tem-poral dependencies within sequential graph data, robust base-line references are crucial. We compare RF and Logistic Regression (LR) with Recurrent Neural Network (RNN) and LSTM networks. RNNs specialise in processing sequential data by maintaining internal states over time, effectively capturing long-term dependencies within EHR data. However, their performance must be compared against simpler models like RF and LR, which lack explicit mechanisms for modelling such dependencies but offer simplicity and interpretability.\nG. Evaluation Approach\nWe follow the Transparent Reporting of a Multivari-ate Prediction Model for Individual Prognosis or Diagnosis (TRIPOD)-AI statement for both the reporting of model de-velopment and the prediction models (see the Supplementary material for the completed checklist).\nWe took a random 10% sample of the patients that met the inclusion criteria to test the trained model on, where this group represents the same proportion of the population that has a hip replacement as the full dataset. From the other 90% we match every hip replacement patient to a control patient based on sex, IMD, and age at replacement. Note we do not oversample, each match is a new addition. Within the balanced training dataset, we perform 5-fold cross-validation when choosing hyperparameters (detailed in the supplied repository). We optimise the model based the on cross-validation mean validation accuracy value, we conducted a random hyperparameter search on the Full TG-CNN model 20 times. We take the model with the best AUROC score from the cross-validation and use the same hyperparameters across the ablation study models, running each model for a maximum of 12 hours. For the 10% test dataset, we use half to recalibrate the model (we denote this as Test 1) and the other half (denoted as Test 2) to test the recalibrated model. Calibration is undertaken to assess how close the predicted probabilities reflect the true risk of needing a hip replacement. Calibration is vital to ensure that the predicted probabilities are accurate for different subgroups based on their risk levels [22]. We also assess discrimination (AUROC and Area under the Precision Recall Curve (AUPRC)) of the models. After testing on the balanced data, we proceed to recalibrate the model. Since the model was trained on a balanced dataset, we adjust the model predictions to enhance alignment with the true incidence rates of the outcomes in the test set. For recalibration, we create a LR model that takes the linear predictors of the original model. The LR model improves calibration by estimating new coefficients. We can assess the calibration slope before and after recalibration to determine efficiency. Once the model is recalibrated on the Test 1 data, we validate the recalibrated model's performance on a second unseen test set (Test 2). We resample the Test 2 data to assess model stability, bias, and variability using bootstrapping. We also perform patient stratification on the best recalibrated TG-CNN model, assessing the model calibration on different demographic sub-groups separately. We create sub-groups based on sex (female and male), age at prediction (40-60, 60-70 and 70+ year olds) and IMD (quintiles)."}, {"title": "IV. RESULTS", "content": "Table III displays the characteristics of the cohort included in model training and testing. We conduct a Chi-squared analysis to compare the population of Test 2 to the National Joint Registry 12th Annual Report 2015, ensuring similar demographic distributions [8]. Results in Table S2 in the supplementary materials show no significant difference in age, sex, and IMD between our Test 2 set and the NJR. However, there is a significant difference observed in weight category distribution between the datasets.\nTable IV displays the distribution of hip replacements per deprivation quintile, indicating slightly higher rates in more deprived areas (IMD 1-3) compared to less deprived regions. No data are missing for age, sex, or IMD.\nUpon running the trained model on the test data, an in-verted calibration curve was observed (Figure 3), with all probabilities below 0.5, indicating predictions skewed towards the positive group, despite around only 7% of the population belonging to this group. However, recalibrating the model resulted in a closer fit to the optimal line and more accu-rate probability distribution. To understand this phenomenon, several evaluations were conducted. We tried training the model on an imbalanced dataset, where each case patient was matched with two control patients, yet the probability distribution remained skewed towards case patients. Further testing involved reserving 20% of unmatched control patients for testing, resulting in similar probability skewing. This phenomenon persisted during training of baseline models, indicating it is data-based rather than model-based. Holding back a portion of matched training data as test data yielded good results even prior to calibration. These tests suggest that the occurrence is due to the model being well-trained on matched patients, resulting in different trajectories for unseen test patients.\nTable V displays AUROC and calibration slope results from 5-fold cross-validation on the TG-CNN model. We select the w/o l\u2081 model with the validation C-slope value closest to 1 to illustrate before and after recalibration calibration curves (Figure 3), as this model demonstrates the best calibration. The TG-CNN w/o exponential model outperformed others in terms of AUROC on the balanced dataset but showed poor recalibration, suggesting overfitting. Table VI and Table VII present AUROC and AUPRC results using the Test 2 (unseen) data on the TG-CNN and baseline models, respectively.\nThe most important features, according to the best RF model are provided in the supplementary materials Figure S1. Additionally, Figure S2 in the supplementary materials displays the top 10 largest odds ratios from the LR model, indicating variables that act as risk multipliers. As anticipated, both models seem to recognise that Read Codes associated to hip pain and OA are crucial for predicting hip replacement. We conduct subgroup analysis (patient stratification) on the recalibrated TG-CNN w/o l\u2081 model. See the supplementary materials for calibration curves (Figures S3 - S12) which demonstrate fair equity across demographic subgroups. There seems to be slightly more underprediction in the female population compared to males, but overall, predicted risks are reasonable in a large proportion of the population. Younger populations tend to experience more overprediction, while individuals aged 60-70 exhibit the best calibration; how-ever, those over 70 are notably underpredicted. Regarding deprivation levels, IMD 1, 2, and 4 demonstrate the best calibration, while IMD 5 overpredicts hip replacement and IMD underpredicts, indicating no bias based on IMD."}, {"title": "V. DISCUSSION", "content": "The RF and LR models, though interpretable with top predictors like hip pain, hip OA, OA, and tobacco smoking, showed poor AUROC and AUPRC. The RF model empha-sised OA, smoking, and weight. Using demographics alone improved performance slightly compared to using Read Codes in the recalibrated RF and LR models. While these models performed competitively on the balanced training set, their recalibrated application to Test 2 data led to poorer AUPRC re-sults. Excluding demographics in the TG-CNN model resulted in overfitting, indicating that including predictors beyond basic demographic information may be beneficial.\nThe LSTM and RNN baseline models might perform poorly due to time decay on events occurring further in the past, weakening relationships with longer time intervals. Reversing the input vector prevented convergence, indicating that the model may learn best from a mix of recent and historical events. With simple RNNs, we cannot include elapsed time, so we only feed the events into the model as a sequence, losing some temporal features. Including an LSTM in the TG-CNN model could be beneficial for retaining distant Read Codes in memory rather than focusing solely on recent ones.\nUsing an exponential function for elapsed time allows rescaling to avoid extreme values in neural networks and mitigate potential under/overflow issues with half-precision arithmetic. The negative exponential ensures that actions taken quickly in succession have values close to 1, while those with greater temporal gaps are closer to 0. The model without the exponential component achieved the highest validation AUROC with minimal difference from the training set, sug-gesting no overfitting occurred. However, despite its success on balanced data during training, it performed poorly during recalibration, leading to significant underprediction for some patients. This suggests that the exponential component im-proves generalisability to unbalanced datasets. It also implies that the time step (axis z of the 3D tensor representing the temporal graph) requires the exponential component to recognise past events compared to recent ones.\nIncorporating prescriptions tripled the number of eligible records for our model. Including prescriptions in the model may result in poor validation AUROC outcomes because the graphs become inundated with prescriptions rather than diagnostic Read Codes. Moreover, additional features could in-crease model complexity, potentially prolonging convergence time and yielding poorer results.\nElastic Net might not perform as effectively as 12 regu-larisation alone, especially when handling highly correlated features, as indicated by the good performance of our TG-CNN model without l\u2081 regularisation. l\u2081 regularisation tends to select only one feature from a group of correlated features, effectively disregarding the rest. In contrast, l2 regularisation penalises all feature coefficients, distributing the weight more evenly among correlated features. Our custom graph regular-isation function le seems to effectively prevent overfitting. The model without a second stream would not converge, this shows that having a long and a short stream is useful for seeing both large and small features. Having two different kernel sizes (in this paper we refer to them as 'streams') capture features at different scales. A fine branch with smaller kernel sizes might capture finer details and textures, while a coarse branch with larger kernel sizes captures broader patterns and structures. Combining these branches allows the model to learn features at multiple scales simultaneously, enhancing its ability to understand complex patterns in the data.\nThe TG-CNN model without elapsed time overfitted and exhibited a poor C-slope value, highlighting the significance of incorporating irregular elapsed time between Read Code recordings to enhance predictive performance.\nThe TG-CNN model utilises EHR data from primary care, allowing for the identification of individuals at higher risk of future hip replacement. With this model, targeted preventative care could be applied to slow progression, severity, or pain. Future research should investigate clinical outcomes and po-tential interventions in primary care based on this model.\nThe TG-CNN model serves as an alternative to the current EHR-based hip prediction model [14], enabling the infusion of temporality and trajectory. In future work, we aim to incorporate explainability into this approach using the filters from the CNN layer, to enable further trust in the model and explain why certain predictions may have occurred [23]. We also aim to reconfigure this model to determine the risk of needing a hip replacement 5-years in advance, allowing clinicians more time to apply interventions and planning. Limitations arise from GPs potentially lacking time to code diagnoses accurately during consultations, leading to misclassification. Although multi-modal models, such as those incorporating imaging, could be beneficial, time and cost con-straints in healthcare favour models quicker to train, especially when recalibration is necessary to prevent temporal drift. Util-ising readily available EHRs data facilitates implementation in routine primary care.\nThe absence of limb sidedness/laterality data prevents spec-ifying which leg has undergone replacement, potentially re-sulting in misinterpretation, although using the first record of primary replacement attempts to mitigate this. The primary care data used in the study may lack the depth found in secondary care records, which could provide more compre-hensive replacement details and reasons for the replacements, such as trauma or elective surgeries. Left censoring issues, stemming from having Read Codes only from a specific date onwards, might overlook joint replacements conducted before the analysis period."}, {"title": "VI. CONCLUSION", "content": "The TG-CNN model can aid in clinical decision-making by targeting individuals with an elevated risk of future hip replacement for intensive non-surgical management or active monitoring, enabling the application of preventive treatments and care. Implementing this model clinically may potentially reduce patients' time in pain, enhance quality of life, and improve healthcare efficiency and resource allocation."}, {"title": "ETHICAL APPROVAL", "content": "The study was approved by the University of Leeds School of Medicine Research Ethics Committee (SOMREC/13/079) and the ResearchOne Project Committee (201428378A)."}]}