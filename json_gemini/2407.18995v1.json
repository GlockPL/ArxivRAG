{"title": "SWIFT: Semantic Watermarking for Image Forgery Thwarting", "authors": ["Gautier Evennou", "Vivien Chappelier", "Ewa Kijak", "Teddy Furon"], "abstract": "This paper proposes a novel approach towards image authentication and tampering detection by using water-marking as a communication channel for semantic information. We modify the HiDDeN deep-learning watermarking architecture to embed and extract high-dimensional real vectors representing image captions. Our method improves significantly robustness on both malign and benign edits. We also introduce a local confidence metric correlated with Message Recovery Rate, enhancing the method's practical applicability. This approach bridges the gap between traditional watermarking and passive forensic methods, offering a robust solution for image integrity verification.", "sections": [{"title": "I. INTRODUCTION", "content": "Many technical means can verify the authenticity of multi-media content. This ranges from a digital signature stored in the metadata like in the recent C2PA (Coalition for Content Provenance and Authenticity) and IPTC (International Press Telecommunications Council) initiatives, to passive forensics [1], [2] and active fragile watermarking [3], [4]. The main difficulty resides in making a clear cut between benign processing which are common editing in the entertainment indus-try and malicious transformations which modify on purpose the content. Semi-fragile watermarking faces this challenge: it should be robust to benign processing but fragile to deeper transformations. At the decoding side, its absence reveals that the piece of content has been modified beyond the accepted limit. This limit between benign and malicious editing is not easy to be defined in mathematical terms, although in real life the difference is straightforward: Any modification of the semantics is malicious.\nThis paper investigates the idea of hiding semantics infor-mation within the cover work in an imperceptible and robust manner. The verification amounts to compare the semantics of the content with the decoded information. To the best of our knowledge, embedding its own semantic into the content itself to ensure integrity is an unexplored research path. A first challenge lies in the poor capacity of robust image watermarking. Multi-bit watermarking embeds messages into images but typically only supports up to 64 bits of data transmission. Higher capacity schemes exist but with a much lower robustness. The second challenge is the representation of the semantic of an image whose definition is still a matter of debate. We chose the textual description of the image given by an automatic captioning as the message to be hidden.\nThe scenario establishes a covert channel between two entities: Alice, the sender who authenticates the original work, and Bob, the recipient tasked with verifying its authenticity. The cover work may undergo modifications by a third party, referred to as Eve, acting as an intermediary. Eve's alterations may be intentional, involving semantic edits, or unintentional, comprising benign changes. The crux of our method lies in Bob's ability to recover the message embedded by Alice. This recovery enables Bob to assess whether Eve's modifications have introduced semantically misleading alterations to the original content. By comparing the recovered message with the received work, Bob makes informed decisions about the nature and extent of any change. The robustness of the communication channel despite potential interferences is key.\nTo this end, we propose to increase the utility, re-usability and flexibility by disentangling the watermarking layer from the encoding layer. The watermarking layer is responsible for hiding a high-dimensional real-valued unit-norm vector in the cover while optimizing robustness to various transforms and the watermark imperceptibility. The encoding layer is respon-sible for encoding a message as a signal to be transmitted on this noisy communication channel. The decoding layer then retrieves the message with some confidence level.\nThis framework provides a robust mechanism for authenti-cation and content verification in scenarios where the integrity of digital media may be compromised between creation and reception. This paper introduces three contributions:\n\u2022 Hide-R: Inspired by HiDDeN [5], we propose an encoder-decoder network architecture jointly trained to embed and extract high-dimensional unit-norm vectors in images.\n\u2022 Encoding layer: It encodes a variable-length binary mes-sage into a vector to be hidden in images.\n\u2022 Caption Compression: We finetune a large language model for captioning and combine it with an arithmetic codec to compress the payload as in LLMZip [6].\nThree major features stem from the combination of these contributions into the SWIFT scheme:\n\u2022 Reliability: A confidence metric on the decoded caption gives an informed decision-making about authenticity.\n\u2022 Security: The design guarantees security via a secret key.\n\u2022 Performance: SWIFT achieves state-of-the-art results across various benign and malicious transforms, demonstrating its robustness in challenging scenarios."}, {"title": "II. RELATED WORK", "content": "a) Image forensics: Passive methods detect alterations of a piece of content, possibly malicious ones. They utilize noise residuals or high-frequency features as input to highlight manipulation traces. These methods are limited to providing localized insights into specific alterations. For instance, copy-move forgery detection uses Siamese networks [7] while splicing detection leverages two-stream architectures [8], [9]. Inpainting detection methods have focused on traces left by some deep inpainting models [10], [11]. Forensics methods lack the capacity to offer a global perspective due to the absence of contextual information from the original image.\nb) Image watermarking: Traditional watermarking schemes embeds invisible marks within multimedia content to assert copyright ownership (robust watermarking) or authenticate content (fragile watermarking). Classic techniques involve manipulating spatial or frequency domains representation of the media [12], [13]. Recently, deep-learning enabled more robustness as first shown with the encoder-decoder HiDDeN architecture [5] and followed with [14], [15]. SSL [16] embeds a binary message in the latent space of a foundation model learned with supervised learning with low perceptibility but high inference cost due to its iterative nature. TrustMark [17] leverages a more classic encoder-decoder architecture and a GAN loss to learn how to embed binary messages. Note that the payload of a watermarking scheme is always fixed in the literature. One of our contributions is to tackle variable-length messages.\nWatermarking can be used for authenticity verification, but it usually uses a fragile or semi-fragile signal whose absence reveals tampering [3], [4]. One exception is the idea of embedding a compressed representation of the image in itself with robust watermarking [18]. At the detection stage, the verifier finds back a copy of the original image to be compared with the image. Our work is similar in spirit except that we embed the semantic textual description of the original image."}, {"title": "III. METHOD", "content": "This section presents the design of the encoding and water-marking layers. We break down the encoding layer into two primary components: the message layer and the modulation layer. \n\nA. The message layer\nAlice wants to transmit a message M to Bob so that he can assess the integrity of the cover image. Alice uses an image captioning model like BLIP2 [19] to generate the caption m of the cover.\nAlice uses arithmetic coding [20] for losslessly compressing m into M to reduce the number of bits.\nAs in LLMZip [6], Alice takes advantage of a LLM to model the distribution of the messages and improve the compression. She uses OPT-125m [21] finetuned on BLIP2 captions from 2,000 MSCOCO validation set images. This acts as oracle and gives the probability of each caption symbol used by the arithmetic coding [22].\nB. The watermarking layer\nModern watermarking leverages deep-learning to learn end to end how to embed a message into a cover image. It enables robustness against benign edits by performing augmentations between the watermark embedding and watermark extraction stages [23]. The most famous example is HiDDeN [5] based on two convolutional neural networks (CNN) jointly trained to embed and extract a fixed-length binary message.\n\nSpecifically, we draw random samples X uniformly distributed on the surface of the unit hypersphere in $\\mathbb{R}^D$ with D = 256 :\n$X = \\frac{Z}{||Z||}$ with $Z \\sim N(0, I_D)$.\nWe extend the number of channels in the convolutional layers to 1.5D instead of the fixed 64 to account for higher dimension D than the message length L = 30 proposed in the original paper. Signal X is concatenated with the cover image $I_{co}$ along the channel dimension before the first convolutional layer. Instead of using a discriminator, we opt for a fixed PSNR budget which both enforce imperceptibility in a flexible way and speed up the learning process. The training minimizes the reconstruction loss $||X \u2013 Y||$ between X and the reconstructed unit vector Y.\nThis framework gives a zero-bit watermarking system. Assume $X_0$ is drawn according to (1) from a pseudo-random generator seeded by the secret key K associated with a fixed index M = 0. A watermarking signal is deemed present if the cosine similarity $C_0 = Y^T X_0$ is above a threshold c. Under the hypothesis $H_0$, the cover is not watermarked or watermarked with another secret key K'. Then, the p-value is defined as the probability of having higher cosine similarity $C_0$ than the threshold c and given by:\n$p_0(c) = P(C_0 \\geq c) = \\begin{cases} I(\\frac{1-c}{2}, \\frac{D-1}{2}, \\frac{1}{2}), & \\text{if } c > 0 \\\\ 1, & \\text{otherwise,} \\end{cases}$\nwhere I is the regularized incomplete beta function. This illustrates how a confidence value is available to Bob at the watermark extractor.\nC. The modulation layer\n1) Multi-bit watermarking with confidence: One way to use zero-bit watermarking to send a N-bit message M is to share $2^N$ different secret keys, each associated with one possible message. Then Alice selects the key K corresponding to the message to send, and Bob runs the watermark extractor with all the $2^N$ possible keys. Bob selects the decoded message as:\n$\\hat{M} = \\underset{m \\in [0..2^N-1]}{argmax} (C_m)$"}, {"title": "IV. EXPERIMENTS & RESULTS", "content": "This section introduces evaluation of SWIFT and recent watermarking methods for the task of message recovery.\nA. Evaluation\nMetrics. The benchmark compares watermarking methods by their Message Recovery Rate (MRR), which is defined as the rate of messages being perfectly transmitted without any modifications, over a test set of watermarked images $I_t$. Let $m_i$ be the original caption and $\\hat{m_i}$ the corresponding recovered caption for an image $I_i \\in I_t$. The MRR is defined as follows:\n$MRR = \\frac{1}{|I_t|} \\sum_{i=1}^{|I_t|} \\mathbb{1}(m_i, \\hat{m_i})$\nWe chose this metric to ensure practicability and accurately assess the robustness of a system. A watermarking system designed for our task should strive to reach 100% MRR, especially when no confidence metric is available at the decoding step, which is the case of all systems but SWIFT.\nTest set. Our test set $I_t$ is composed of 20,220 images. We use the Emu Edit test set [27] which comprises 2,022 images from MSCOCO [28] and editing instructions for Image Editing models from 8 classes (local, add, remove, global, text, background, style, color). For each image, we perform 6 benign and 1 malign transformation with four variations in classifier-free guidance. Benign ones are chosen to be realistic in a web setting, or quite important distortion-wise but without semantic alterations: crop 40% of image surface, random noise, grayscale conversion, resize to 128 \u00d7 128, jpeg compression with quality coefficient at 50. Malign ones are images edited by a diffusion model according to Emu Edit instructions, supposed to change the meaning of the cover work.\nB. Comparison with state of the art\nTable I shows the results of state-of-the-art methods SSL and TrustMark against SWIFT: we observe superior resilience to malign transforms while maintaining state-of-the-art perfor-mance on benign modifications with significant improvement on resize and grayscale transforms due to our training. We provide another version of SWIFT to watermark at 42db which performs better than TrustMark(Base) on almost all settings.\nC. Confidence metric\nAfter the TCCSK modulation, a message M is encoded into a vector X on the 256-d hypersphere. Given an encoded mes-sage X, due to transforms during transmission, Y is the noisy extracted vector. At inference, Y is decoded by the TCCSK demodulation into $\\hat{M}$. X is unknown, but let $\\hat{X}$ be the perfect encoding of $\\hat{M}$ and C the cosine similarity computed between X and Y . We define our pratical confidence metric as $p \\ (7)$. We assume that Y close to the perfect representation $\\hat{X}$ of the decoded message M means that Y is also close to"}, {"title": "E. Limitations", "content": "We believe this work introduces to a new way of assert-ing integrity of images. By disentangling watermarking and encoding layers, we expose two research directions: better modulation and better representation of the message to trans-mit. Further research on carrier modulation techniques could potentially enhance performance by reducing inter-carrier in-terference. On the latter, our choice of a text description may be considered simplistic compared to a specifically learnt representation. Moreover, we limit the granularity of captions to reduce the length of the message to encode. This hampers fine-grained comparison but we believe it will be further optimized. We leave to future work the task of designing a system taking advantage of our pipeline output: Alice could be considered as the source of the original media while Bob would be a moderation system on a social media platform."}, {"title": "V. CONCLUSION", "content": "In this work, we present a novel way to assert the integrity of an image by the relevant use of watermarking as a covert communication channel. Moreover we provide a definition of the image semantics, through its caption, to the recipient of the message. By using an LLM combined with an arithmetic encoder to compress the caption, the limited capacity of Hide-R to convey information is optimized.\nFinally, our local confidence metric improves the applica-bility of our method as any trusted operator may check if the received image is consistent with the descriptive decoded caption of the original content in a trustworthy manner."}]}