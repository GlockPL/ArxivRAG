{"title": "LAPIS: Language Model-Augmented Police Investigation System", "authors": ["Heedou Kim", "Dain Kim", "Jiwoo Lee", "Chanwoong Yoon", "Donghee Choi", "Mogan Gim", "Jaewoo Kang"], "abstract": "Crime situations are race against time. An AI-assisted criminal investigation system, providing prompt but precise legal counsel is in need for police officers. We introduce LAPIS (Language Model Augmented Police Investigation System), an automated system that assists police officers to perform rational and legal investigative actions. We constructed a finetuning dataset and retrieval knowl-edgebase specialized in crime investigation legal reasoning task. We extended the dataset's quality by incorporating manual curation efforts done by a group of domain experts. We then finetuned the pretrained weights of a smaller Korean language model to the newly constructed dataset and integrated it with the crime inves-tigation knowledgebase retrieval approach. Experimental results show LAPIS' potential in providing reliable legal guidance for po-lice officers, even better than the proprietary GPT-4 model. Qualitative analysis on the rationales generated by LAPIS demonstrate the model's reasoning ability to leverage the premises and derive legally correct conclusions.", "sections": [{"title": "1 INTRODUCTION", "content": "Police officers are gradually overburdened with increasing num-bers of diversified crimes which may lead to shorthanded crime investigation. Particularly in South Korea, the incidence of cyber crimes has more than doubled over the eight-year period from 2014 to 2022, increasing from 110,109 cases to 230,355 cases [1]. At the same time, the average number of days required to process a re-ported crime per police officer has steadily increased from 50.4 days in 2019 to 67.7 days in 2022 [1]. Moreover, considering increasingly complex nature of recent crimes in our evolving society, the most intellectually challenging and time-consuming aspect for police officers is determining whether their actions are procedurally and legally justifiable [3]. This leads to the necessity of using and devel-oping automated approaches in AI-assisted law enforcement such as crime prediction and investigation [19].\nCrime investigation is the process within the criminal justice system of proving the occurrence of a criminal act when there is a possibility that certain behavior or its outcomes may constitute a crime [36]. Given the current context of crime investigation such as collected evidence or analysis results, police officers perform investigative actions based on their legal reasoning skills [11]. Legal reasoning commonly involves legal assessment of hypotheses based on its supportive premises [47]. These premises formulated based on crime investigation knowledge constitute a logical rationale that explains the hypothesis assessment. This concept is crucial as it guides crime investigators within the legal boundaries stated by the criminal law system.\nHowever, one of the challenges in developing AI-assisted law enforcement applications is the difficulty of incorporating the in-tangible concept of legal reasoning [7, 9]. Moreover, the important traits in crime investigation are swift and accurate decision-making and responsive action [34]. To address, we propose to borrow the foundational ideas and methods from pre-existing domain-specific application systems of other tasks such as clinical event predic-tion and decision-making [25, 40, 41, 45]. The key pillars of these systems involve the use of large language models (LLM) and their injection of expert-level knowledge.\nLocally trained small language models (SLM) have gained at-traction in developing domain-specific application systems [18, 31]. While utilizing proprietary LLMs via its API (e.g GPT-4) could po-tentially benefit the development of a crime investigation system, there are several weaknesses in terms of their practicability. First, such LLMs cannot be further trained with continuously updated laws and confidential police investigation data. Also, there is a security risk where sensitive information such as ongoing crime cases could potentially be exposed through police officers' API usage [29, 46, 48]. Lastly, public LLMs are susceptible to ethical complications such as privacy leakage or the misuse of criminal records used for training [16, 27, 30]. This further justifies the need of employing locally trained SLMs when developing an AI-assisted police investigation system.\nSuch local SLMs can be obtained by fine-tuning their pretrained weights utilizing a well-designed instruction dataset [23, 45]. Our work emphasizes addressing the critical elements of legal reasoning through the injection of crime investigation knowledge. A fine-tuned SLM lacking these elements, when embedded in a crime investigation system, can generate incorrect legal assessments, po-tentially leading police officers to perform misguided investigative actions [12, 43]. To address this, we propose to employ retrieval-augmented generation (RAG) from a domain-specific knowledgbase in both finetuning dataset construction and the SLM's functionality. Moreover, we incorporated manual curation efforts performed by a group of domain experts to further the quality of our dataset.\nAs illustrated in Figure 1, suppose a police officer received an emergency call where the suspect was witnessed driving under the influence. Having encountered the suspect after 40 minutes passed, the police officer felt a strong scent of alcohol from them. Due to these circumstances, a hypothesis rises whether the police officer can arrest the suspect, who has allegedly committed a crime of driving under the influence, or not. Given this hypothesis as input prompt, an LLM-based agent would respond that the suspect should be indeed arrested for their alleged crime as there are substantial evidence. However, the criminal law states that the officer cannot exercise their lawful rights to arrest the suspect, as arresting a driver who has been at the roadside for more than 40 minutes after the initial report cannot be deemed a lawful execution of official duty. This highlights the importance of equipping LLMs with expert-level CI knowledge in order to elude wrongful lawful executions such as misarrests.\nIn this work, we present a Language Model-Augmented Police Investigation System (LAPIS). LAPIS guides the police officer's decision-making on investigative actions through generation of accurate assessments and their rationale given hypothesis questions, empowered by legal reasoning. The building blocks that address the design principles of developing a crime investigation system are our novel task formulation of Crime Investigation, and our newly constructed Crime Investigation Legal Reasoning (CIRL) dataset and Crime Investigation KnowledgeBase (CIKB) which are for SLM finetuning and RAG purposes respectively. To the best of our knowledge, our work firstly attempts to develop a system specialized in crime investigation task.\nOur experiment design explores the effects of finetuning various pretrained SLMs, providing each training instance with different types of supportive rationales (i.e expert-curated, GPT-generated) and utilizing domain-specific RAG module. Furthermore, we de-ployed LAPIS in a crime investigation scenario and evaluated not only its hypothesis assessment but also generated supportive ratio-nales. Both the experimental and simulation results conclude that LAPIS can potentially benefit crime investigation in police agencies. Code and data is available in our github repository 1.\nThe main contributions of our work are the following,\n\u2022 We formulated a downstream task for LAPIS called crime investigation which involves legal reasoning and knowledge retrieval.\n\u2022 We constructed an expert-curated finetuning dataset and knowledgebase to effectively inject crime investigation knowl-edge in LAPIS' SLM.\n\u2022 Both quantitative and qualitative results demonstrate LAPIS' potential in benefiting police officers and law enforcement agencies."}, {"title": "2 RELATED WORK", "content": "2.1 AI in Law Enforcement\nThe applicability of AI in law enforcement has recently gained recognition especially by fields of forensic science and criminal investigation [2, 32, 35]. Moreover, law enforcement agencies have recently started to incorporate AI-driven automated systems for aiding police officers, crime investigators and forensics experts [20]. Particularly, researchers have explored various ways to utilize AI-related methodologies in crime investigation (CI) domain. Johnsen and Franke emphasized the importance of following text prepro-cessing requirements when utilizing Open-source Intelligence (OS-INT) to preemptively deal with cyber threats [22]. Schiliro et al. devised a novel cognitive computing approach using convolutional neural networks to develop a cognitive assistant for police inves-tigators while Bunnin and Smith introduced a novel archetype of Bayesian hierarchical models for inferring progression of criminal attacks [5, 37]. Hepenstal et al. proposed a novel design approach for developing conversational agents and Kim and Lim implemented a deep learning-based named recognition model, both specialized in CI [17, 26]. Motivated by these works, our work employs expert-curated dataset construction techniques and conventional LLM-related methodologies to build a system that provides precisive legal guidance for police investigators."}, {"title": "2.2 LLMs and Legal Reasoning", "content": "Legal practice is one of the fundamental aspects of crime investi-gation. Recently, LLMs have been trained with massive parameter size, enabling them to exhibit impressive capabilities in numerous NLP tasks through zero-shot or few-shot prompting learning [4, 10]. Advancements in LLMs also have a significant impact on the uti-lization of AI in the legal field [33]. Chalkidis evaluated LLMs on LexGLUE benchmark dataset [8] in a zero-shot manner, and Katz et al. evaluated GPT-4 on bar exams by using instruction-following formats. Additionally, there are on-going studies that verify the ef-fectiveness of legal prompting by inducing legal reasoning skills to LLMs [42]. Jiang and Yang introduced legal syllogism prompting to teach the general legal thought process to LLM for legal judgment prediction. Yu et al. added an IRAC explanation to instructions, which provides a skill for thinking like a lawyer, and guided the process of legal reasoning through a few-shot demonstration on COLIEE's legal entailment task. While these studies explore LLM's general legal reasoning capabilities mostly tailored for law prac-titioners, our work focuses on developing a LLM-powered crime investigation system which requires reasoning skills specialized in criminal law and investigation principles."}, {"title": "3 METHODS", "content": "3.1 Task Formulation\nPROBLEM 1 (CRIME INVESTIGATION TASK). We define the objective of Crime Investigation Task as finite steps of performing Legal Reasoning and Investigative Action with the objective of proving or disapproving a criminal allegation or suspicion. Each step involves LAPIS' legal reasoning task which guides the police officer's decision making on the appropriate investigative action to take.\nTo solve the above problem, we formulate the following two tasks performed by the components of LAPIS, evaluator (f) and retriever (g).\nTASK 1 (LEGAL REASONING). Given an input prompt X question-ing whether the hypothesis h formulated under the current crime investigation context C is true or false, LAPIS evaluator f generates a response y consisting a pair of True-False assessment $y_a \\in [0, 1]$ and its corresponding rationale yr. As a result, this task is modeled by y = f(X) where X = {h, C} and y = {$y_a$, yr}.\nTASK 2 (KNOWLEDGE RETRIEVAL). Given an input prompt X, LAPIS retriever g retrieves the most relevant premises P from crime investigation knowledgebase K and exploits them in generating its response y. The enhanced version of LAPIS' legal reasoning task is thus modeled by y = f(X, P) where P = g(X).\nFigure 2 shows the development process of LAPIS starting from task formulation to deployment. We elaborate the following details of developing LAPIS in this section which mainly involve dataset construction, knowledgbase creation, domain expert curation and SLM finetuning."}, {"title": "3.2 Dataset Construction", "content": "3.2.1 Criminal Law Proficiency Exam.\nThe annual Criminal Law Proficiency Exam organized by the Ko-rean National Police Agency evaluates the qualifications of police officers' lawful duty to conduct crime investigations. As this process requires swift and precise decision-making skills, examinees are required to read long texts implicating crime investigation context and assess each of its possible legal hypotheses in a limited amount of time. The examination consists of three subject areas which are Criminal Law, Criminal Procedure law and Crime Investigation. The first two subjects mostly comprise questions testing the exami-nee's knowledge in criminal law related to investigative procedures while the last subject covers questions related to the theoretical concepts and real-world protocols of crime investigation itself.\nWe collected the Korean-written exam questions from the three subjects ranging an yearly period from 2013 to 2023, with the total number being 1,760. Each subject contains multiple-choice ques-tions where most of them explicitly state crime investigation con-text. To strictly evaluate LAPIS' hypothesis assessment ability, we partitioned the dataset on an annual basis into train (Dt, 2013-2020), development (Dd, 2020) and test (Ds, 2021-2023). Inspired by the COLIEE dataset [47], we first converted all the given multiple-choice options in the exam questions into hypotheses answerable as true or false (h, ya). As a result, our initial Crime Investigation Legal Reasoning dataset contains 4,895 data instances (Di (C, h, Ya)).\n3.2.2 Crime Investigation Knowledgebase.\nAccurately answering hypothesis-based questions of crime inves-tigation area with simple True or False responses does not fully suffice the qualifications of being a police investigator. Each inves-tigative action performed by the police officer should adhere to the investigative protocols and requires concretely supportive rationale based on officially documented criminal law articles and previous court rulings [6, 15, 39].\nBased on this motivation, we created a Crime Investigation Knowledgebase (CIKB) containing documents from multiple data sources which are Criminal Investigation textbooks, up-to-date Criminal Law Articles and Criminal Court Rulings. The Criminal Investigation textbooks cover theories and practical methodologies, such as behavioral analysis and interrogation [38]. The Criminal Law Articles collected from the Korean Law Information Center provide the fundamental legal guidelines for specifying criminal acts along with each of its degrees and forms of punishment [28]. The Criminal Court Rulings also collected from the Korean Law Information Center, are actual judgements issued by the Supreme Court of Korea which contain comprehensive information on actual criminal cases [28].\nAs a result, our newly created CIKB K contains 19,388 dense embeddings of 687 paragraphs (223,224 tokens) extracted from Criminal Investigation textbooks, 3,304 paragraphs (1,442,869 to-kens) from Criminal Law Articles and 15,397 paragraphs (3,232,570 tokens) from Criminal Court Rulings. We generated these dense embeddings using a pretrained GPT3.52.\n3.2.3 GPT-4-Generated Rationales.\nGiven the data instances (C, h, ya) in the training and development parition of our initial dataset Di, we prompted the GPT-4 to gen-erate responses consisting its predicted true-false assessment and rationale. These GPT-generated rationales yr are included in the output part of each data instance which guides the SLM not only make correct true-false hypothesis assessment but also provide better explainability to police officers.\nWhen prompting the GPT-4, we employed two approaches which are utilizing our devised Crime Investigation Legal Reasoning (CILR) prompting method and a RAG method that exploits our created CIKB denoted as Crime Investigation Knowledge Retrieval (CIKB). The CILR prompting method is a modified version of the Issue-Rule-Application-Conclusion (IRAC) prompting method, previously used in legal entailment tasks which are distant from actual crime investigation scenarios [47]. The CIKR method performs a vec-tor similarity search on the CIKB given the crime investigation context (C) and hypothesis (h) as input and retrieves the most rele-vant premises from the knowledgebase (P CK) [14]. The relevant premises are then augmented to the original input prompt and are used to generate rationales via the GPT-4.\nCILR prompting employs a structured approach to guide a LLM's question answering through provision of foundational con-text based on the premises retrieved from CIKB. The instructions to guide GPT-4's generative process included in the input prompt are as follows, \"You are an expert in judging a legal hypothesis on the criminal investigation domain. Given the hypothesis and premise, your task is to judge whether the legal hypothesis is True or False through the following process.\"\n\u2022 First, you should analyze the given hypothesis based on the premise considering both the overall context and specific de-tails.\n\u2022 Subsequently, if the premise provides sufficient information to judge the hypothesis, state your judgement based on the premise. If not, make a judgement of the legal hypothesis to the best of your legal expertise and reasoning abilities.\n\u2022 Use pertinent legal principles, precedents, and logical argu-ments to answer.\"\nTo ensure that the SLM is trained on various legal reasoning approaches, we utilized six different prompting strategies for each data instance as follows,\n\u2022 GPT4-VP-ZS: Zero-shot vanilla prompting method.\n\u2022 GPT4-IRAC-ZS: Zero-shot IRAC prompting method.\n\u2022 GPT4-IRAC-1S: One-shot IRAC prompting method.\n\u2022 GPT4-CILR-ZS-CIKR: Zero-shot CILR prompting for meth-od with CI Knowledge Retrieval.\n\u2022 GPT4-CILR-1S-CIKR: One-shot CILR prompting for meth-od with CI Knowledge Retrieval.\n\u2022 GPT4-CILR-3S-CIKR: Three-shot CILR prompting for meth-od with CI Knowledge Retrieval.\nWe used the GPT-4 to generate various responses for each data instance contained in our initial dataset Di. We then eliminated those that have incorrect assessment (i.e wrongly predicted true-false labels) of the given hypothesis. We then augmented our dataset"}, {"title": "3.3 Finetuning Small Language Model", "content": "We finetuned the SLM's Criminal Investigation Legal Reasoning task on the training set $D_t^+$ while using the development set $D_d^+$ for validation purposes. Given a data instance containing a pair of input prompt X (crime investigation context C, hypothesis h) and output response y (ground truth True-False assessment ya, supportive rationale yr), the model parameters of the SLM f optimized under loss objective $L(\\theta)$ so that it generates the desired response \u0177 that closely matches y.\nThe model parameters ($\\theta$) of the SLM optimized under loss ob-jective $L(\\theta)$ are mathematically expressed as follows,\n$L(\\theta) = - \\sum_{t=1}^T y_t \\log(\\hat{y}_t)$ (1)\n$ = - \\sum_{t=1}^T y_t \\log(f_\\theta(X))$ (2)\n$ = - \\sum_{t=1}^T y_t \\log(f_\\theta(C, h))$ (3)\nThe SLM candidates whose model architecture and pretrained weights are imported from HuggingFace are the following [44],\n\u2022 yanolja/EEVE-Korean-Instruct-10.8B-v1.0\n\u2022 yanolja/EEVE-Korean-10.8B-v1.0\n\u2022 yanolja/KoSOLAR-10.7B-v0.2\n\u2022 beomi/Yi-Ko-6B\n\u2022 beomi/llama-ko-7b\n\u2022 beomi/OPEN-SOLAR-Ko-10.1\nAll SLM candidates were trained for 5 epochs using the same Paged AdamW optimizer with its learning rate set to 0.0001. We em-ployed the Quantized version of Low Rank Adaptation (QLORA) [13] for training efficiency. The hardware used for finetuning the SLMs is two NVIDIA A100 80GB Tensor Core GPU devices while the elapsed training time was approximately 30 hours."}, {"title": "4 EXPERIMENTS AND ANALYSIS", "content": "4.1 LAPIS Deployment\nLAPIS is a crime investigation system built based on two major components which are the evaluator and retriever. The evaluator f is an SLM finetuned on our constructed dataset, is prompted with a question asking whether the user's formulated hypothesis h based on current crime investigation context C is true or false and generates a response consisting of the true-false assessment ya and its supportive rationale yr. Previously utilized during the rationale generation process, the retriever g augments the input prompt with the top 5 relevant premises retrieved from the CIKB via vector similarity search PC K. In sum, LAPIS' overall generative process is mathematically expressed as y = f(h, C, P) where P = g(h, C).\n4.2 Experimental Settings\nUpon selecting the most suitable SLM to be used as LAPIS' evaluator, we first performed experiments with different SLM candidates and also included GPT-4 (gpt-4-1106-preview) as our baseline. We finetuned all pretrained SLMs with the same optimization setting and prompting method (CILR-FT). We then ran LAPIS' model inference on the test partition of the dataset (Ds).\nDue to the difficulty of finetuning GPT-4, we instead used its API to generate the responses for the same test set, using the same CILR prompting and CIKR method. The GPT-4 baseline experiments were conducted with zero-shot and 3-shot learning settings (CILR-ZS and CILR-3S).\nAll model setting's performance were evaluated using the classif-ication-related metrics, accuracy (ACC), F1-score (F1) based on their generated binary-labeled assessments (True or False) com-pared with ground truths (ya) per data instance. Table 2 shows each setting's performance on legal hypothesis assessment.\nAccording to the first eight rows in Table 2, finetuning the pre-trained weights of EEVE-Korean-Instruct model showed the best hypothesis assessment performance in terms of accuracy and F1-score (0.74, 0.79). Interestingly, EEVE-Korean-Instruct demon-strated its legal reasoning ability quantitatively sub-par with GPT4 (0.73, 0.79), despite having approximately 1/157 the number of model parameters. This suggests that not only choosing the most adequate SLM but also incorporation of domain-specific approaches such as retrieving the relevant premises and finetuning with expert-curated rationales could potentially enhance LAPIS' ability to guide police's investigative decisions. Also, we emphasize that our system design approach minimizes reliance on proprietary LLMs such as GPT-4.\nWe performed ablation studies by removing LAPIS' Crime Inves-tigation Knowledge Retrieval capability (CILR-FT without CIKR), eliminating data instances containing expert-annotated rationales (CILR-FT (-DEXP), skipping the finetuning phase (CILR-ZS) and applying other prompting methods (IRAC-ZS, VP-ZS).\nOverall, the ablation results show that removing the expert-annotated rationales from the training set used for finetuning the SLM, incurs performance loss in providing the correct assessment for given hypotheses (0.63, 0.70). Also, prompting language models without reliance on CIKR is detrimental (0.66, 0.67), as the premises extracted from the CIKB play a key role in helping them make accurate legal assessments on hypotheses. Notably, other prompt-ing methods especially the IRAC prompting method (0.01, 0.03) fell extremely behind our proposed CILR prompting method even without finetuning (0.53, 0.52) or vanilla prompting method (0.13, 0.20)."}, {"title": "5 ANALYSIS", "content": "We deployed LAPIS in an actual crime investigation scenario and evaluated its practicability based on its generated response in com-parison with GPT-4. Throughout the timeline of this scenario, the current context of crime investigation changes, bringing new legal hypotheses to the police officer regarded as the end user of this system. Figure 3 illustrates how LAPIS offers legal guidance to the police officer at each step of this timeline through accurate assess-ment of their hypothesis associated with its generated rationale specialized in crime investigation knowledge.\n5.1 (T1) Initial Assessment of Crime Scene\nAt this step, the police officer receives an initial witness report about the victim being stabbed by the perpetrator's knife which caused excessive bleeding that eventually lead to victim's death. The autopsy report released by the National Forensic Service states that the wound was 6cm long, 17cm deep, cutting through the left pericardium. Having known that this incident began with a quarrel between the victim and perpetrator, the police officer questions a legal hypothesis of whether murder intent can be recognized in this case.\nThe retrieved premises from the crime investigation knowledge-base are the following,\n\u2022 Given that the accused stabbed the victim's heart with a fruit knife held in their right hand and fled immediately after the victim died from excessive blood loss, the depth and location of the wound suggest that this was not an accidental action"}, {"title": "5.2 (T2) Acquisition of Witness Statements", "content": "At this step, the police officer has recognized the essence of this criminal case which is intended murder. A witness contacts the police officer, claiming that they can describe the perpetrator's ap-pearance which may lead to their identification. The police officer thinks that obtaining only the key details may not only help identify the perpetrator but also bring forward closing the case. This hy-pothesis should be deemed as False since the implied investigative action may lead to cognitive investigation bias.\nThe retrieved premises from the crime investigation knowledge-base are the following,\n\u2022 The witness should disclose everything, even details that seem minor or irrelevant to the criminal case. Every single piece of information can be gathered to potentially become significant clues in this investigation (textbook).\n\u2022 The investigator should encourage the witness to recall their psychological and physical state during the incident. Addi-tionally, the investigator should guide the witness to remem-ber the details step by step, gradually reconstructing the entire context. Allowing intervals of a few seconds between each step can help the witness recall their memory with greater precision and detail.\n\u2022 A person's memory based on their experience may fade over time rather than the opposite. Therefore, if the testimony of a witness repeatedly changes over time towards alignment to the fact of indictment without any specific reason, its credibility must be questioned (Ref No:84do22).\nLAPIS successfully assessed the hypothesis as False, stating one of the fundamental principles stated in crime investigation text-books which is \"testimony should be obtained as detailed as pos-sible\". However, GPT4 solely relied on its parametric knowledge,"}, {"title": "5.3 (T3) Prevention of Illegal Coercive Measures", "content": "At this step, the suspect identified by the police officer volunteering came to the police station in order to take part in the investigation. However, as the suspect is posed with provocative questions by the police officer, they refuse to answer any more questions and decides to leave the police station. The police officer considers to prevent the suspect from leaving and formulates an hypothesis whether it is legal to perform coercive measures.\nIn this case, there are no premises directly relevant to the above-mentioned crime investigation context and hypothesis. Despite that, LAPIS does not fully exploit the premises but extrapolates its legal reasoning process based on one of the retrieved premises which is a precedent that concludes the eligibility of using coercive measures only when the suspect is exhibiting violent behavior. On the other hand, GPT-4 fails to cite appropriate grounds and provides less specific responses, highlighting a difference in practicability."}, {"title": "6 CONCLUSION AND FUTURE WORK", "content": "We introduce LAPIS, a police investigation system consisting of two main components which are the evaluator and retriever. The evaluator is a finetuned SLM which showed notable performance in the legal reasoning task. The retriever provides the evaluator with relvant premises automatically obtained from our created domain-specific knowledgebase. In addition, simulation results on LAPIS being deployed in a real-world crime scene support our pipeline design. As the central approach of our work is enhancing LM with criminal investigation specialized legal reasoning skills, we expect it to be one of key insights in developing AI-assisted crime investigation systems.\nHowever, there are several limitations of this work to be ad-dressed. First, our constructed dataset, knowledgebase and fine-tuned SLM is exclusively based on Korean language. We plan to seek ways to incorporate multilingual modeling approaches so that other nations can benefit greatly from our system design approach. Second, even though we used 10 years of released national exam questions to construct our dataset, the lack of training data in-stances address the need of data augmentation techniques. We plan to employ automated approaches to generate more training data built from recently updated criminal cases. Finally, while LAPIS exhibits promising performance in legal reasoning tasks, it does not explicitly suggest possible investigative actions to the police officer. We plan to add this functionality to facilitate more practicability for law enforcement agencies.\nOur work is part of the development project affiliated Korean National Police Agency. The aim of this study is to develop an Al-assisted crime investigation decision support system tailored for police officers. We expect LAPIS and its future work to benefit criminal investigators in not only Korea but also other countries and result in reduction of crime rates."}]}