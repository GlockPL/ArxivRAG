{"title": "A Pre-Trained Graph-Based Model for Adaptive Sequencing of Educational Documents", "authors": ["Jean Vassoyan", "Anan Sch\u00fctt", "Jill-J\u00eann Vie", "Arun-Balajiee Lekshmi-Narayanan", "Elisabeth Andr\u00e9", "Nicolas Vayatis"], "abstract": "Massive Open Online Courses (MOOCs) have greatly contributed to making education more accessible. However, many MOOCs maintain a rigid, one-size-fits-all structure that fails to address the diverse needs and backgrounds of individual learners. Learning path personalization aims to address this limitation, by tailoring sequences of educational content to optimize individual student learning outcomes. Existing approaches, however, often require either massive student interaction data or extensive expert annotation, limiting their broad application. In this study, we introduce a novel data-efficient framework for learning path personalization that operates without expert annotation. Our method employs a flexible recommender system pre-trained with reinforcement learning on a dataset of raw course materials. Through experiments on semi-synthetic data, we show that this pre-training stage substantially improves data-efficiency in a range of adaptive learning scenarios featuring new educational materials. This opens up new perspectives for the design of foundation models for adaptive learning.", "sections": [{"title": "1 Introduction", "content": "One-on-one tutoring has been shown to yield higher learning gains than one-to-many teaching [Bloom, 1984], encouraging the development of adaptive learning as a research area, with a wide range of open problems. Learning path personalization is one of them [Brusilovsky and Mill\u00e1n, 2007]: given an e-learning platform with a corpus of educational documents, how can we recommend a sequence of these documents to any student in order to maximize individual learning gains? Personalization is common in computerized adaptive testing, where the questions are chosen on-the-fly based on the performance of the examinee. Knowledge tracing, the task of modeling the acquisition of knowledge, has been done either explicitly using graphical models [Corbett and Anderson, 1994, Doignon and Falmagne, 1985, Leighton et al., 2004], or implicitly using neural networks [Piech et al., 2015, Ghosh et al., 2020].\nThe problem of learning path personalization can be formulated as a Markov decision process (MDP), where each episode is a learning session with a student, each action is a recommendation (of document) and the reward signal is the learning gains of the student. Consequently, many attempts have been made to tackle this problem with reinforcement learning (RL) algorithms [Clement et al.,"}, {"title": "2 Formalization of the problem", "content": "Given a set of educational corpora 6 and a student population P, we formalize the problem of learning path personalization as a set of POMDPs. Each episode starts by sampling a corpus C from C and a student u from P. The task consists in recommending a sequence of documents from C to maximize the learning gains of student u. We first model the joint distribution over (u, C) as a random graph, then we show how it can be used to formalize the problem as a collection of POMDPS that can be partitioned into source and target tasks."}, {"title": "2.1 Student and corpus distributions", "content": "In the literature on adaptive learning, a corpus C of educational materials is usually characterized by three elements [Thaker et al., 2020, Leighton et al., 2004]:\n\u2022 a set of documents D = {d1, d2, . . . };\n\u2022 a set of knowledge components V = {k1,k2, . . . }; a knowledge component (KC) is a small unit of knowledge taught by a document; we denote d CV the set of KCs taught by document d;\n\u2022 a set of prerequisite relationships Eprereq CV2 between these KCs ; (ki \u2192 kj) \u2208 Eprereq means that ki is a prerequisite for kj.\nOn the other hand, the behavior of a student u interacting with C is determined by these main components:\n\u2022 his prior knowledge x(u) \u2208 {0,1}||: this is a binary vector stating which KCs were already known by the student prior to the learning session;\n\u2022 his learning preferences &(u) C V2: these are similar to the prerequisite relationships Eprereq but depend on the student; we denote E(u) = Eprereq U Ef; we also denote d(u) CV the requirements of document d for student u: d(u) = \u222a {k'|(k' \u2192 k) \u2208 E(u)};\n\u2022 his ability to demonstrate his knowledge when the opportunity arises; this is typically modeled as a function that maps a knowledge state s and a document d to an observation o of the student's knowledge, through a likelihood function: Z(s, d, o) = P(ot = 0 | St = s, d\u2081 = d); we assume that Z is identical for all students.\nWe drop superscripts (u) in the following. All previously defined variables play a role in the sampling of a student-corpus pair (u,C). However, in our probabilistic modeling, we only write the key variables (V, E, x), as they are the only sources of variability among students. Consequently, a student-corpus pair (u, C) can be modeled as a graph G = (V, E, x) and the joint distribution over (u, C) can be expressed as a random graph G ~ P(V,E, x). Note that & and x are not independent since any knowledge state has to be consistent with the requirements. In practice, we carry out the sampling process in two steps: sampling a corpus, then sampling a student \nP(u,C) = P(u|C)P(C) = P(Epref, X|V, Eprereq)P(V, Eprereq)"}, {"title": "2.2 Definition of the domain", "content": "We now define the domain, i.e. the set of tasks, as a collection of POMDPs. Given a corpus C = (V, Eprereq), a recommendation task is a POMDP M(C) = (S, A, O,T,R, Z). S \u2208 {0,1}|| \u00d7 V2 is the state space, which means that each student state st := (xt, Epref) is defined as a combination of the student's knowledge and learning preferences (we assume Epref remains constant throughout the episode). at \u2208 A is the document recommended at step t (also denoted dt). ot \u2208 O is an observation of the student's knowledge at time t: in our setting, ot is a feedback signal qualifying the student's understanding of dt. This feedback can take 3 possible values: ot = f< if the student did"}, {"title": "2.3 Partition of the domain", "content": "We split the space of corpora into two subspaces: sequential corpora and graph corpora (see Figure 1). On the one hand, sequential corpora relate to \u201cstandard\u201d courses, designed to be fully completed, following an identical path for each student. We argue that the set of sequential corpora is a great source of pre-training data for three reasons. First, they represent a huge amount of data (most e- learning curricula are designed that way). Second, since they are designed to be followed sequentially, we consider that each corpus can be reasonably approximated with a chain of KCs where each document teaches one KC (this is reasonable if the documents are small enough): for C = (V, Eprereq) with V = {k1,..., kn }, we have Eprereq = {(ki \u2192 ki+1)}1<i<n and di\u2192 = {ki} for all i = 1, . . ., n."}, {"title": "3 Recommender system: encoder and policy", "content": "In this section, we present the architecture of our recommender system. A frequently used approach to solve POMDPs is to leverage information from past observations in order to build an estimate of the current state, i.e to find a function 4: 01 ... \u039f\u0165 \u2192 Zt such that zt is a good representation of st [Moerland et al., 2023]. Then this estimation is used to take the next action with a function : Ztat. & acts as an encoder and 4 acts as a policy. We define our recommender system as a composition of the two functions: F = \u03c8 \u03bf \u03c6.\nIn educational contexts, zt is often taken as an estimate of the student's knowledge - usually referred to as the knowledge state [Bassen et al., 2020, Reddy et al., 2017]. This knowledge state is traditionally built upon the space of KCs. However, these KCs are difficult to infer in practice. Therefore, following the idea from Vassoyan et al. [2023], we have built our estimate upon a space of concepts (or \u201ckeywords\u201d). In this context, a \u201ckeyword\u201d is a word or group of words that refers to a technical concept closely related to the academic topic of the corpus. These are much easier to extract than KCs, and therefore better suited for our generalization purposes (we detail in Appendix F how we automatically extract keywords from corpora using an LLM). Consequently, we model the student's knowledge state as a collection of keyword vectors zt = (hw\u2081, hw2, . . . ) intended to capture his knowledge of each concept \nRegarding the architecture of and 4, note that our framework requires a flexible model that must be able to run on multiple corpora (with different sizes). Graph neural networks (GNN) have long been identified as an efficient way to make recommendations on flexible data structures: indeed, their number of parameters does not depend on the size of the support [Wang et al., 2019]. Therefore we define & and 4 as GNNs operating on a bipartite graph of documents and keywords B = ((VD,VW), E\u00df, (E, F)), where VD is the set of documents, Vw is the set of keywords and E\u00df the set of edges with (d, w) \u2208 E\u00df if the document d contains the keyword w. Regarding the node features, we have used pre-trained word embeddings E for the keyword nodes and the student's past feedback F for the document nodes. Eventually, for the layers of the GNNs, we have used the graph transformer operator from Shi et al. [2021]:\n$h_i^{(l+1)} = W_1 h_i^{(l)} + \\sum_{j \\in N(i)} \\alpha_{i,j} W_2 h_j^{(l)}$ with $\\alpha_{i,j} = softmax \\left( \\frac{(W_3 h_i^{(l)})^T (W_4 h_j^{(l)})}{\\sqrt{n}} \\right)$,\nwhere h \u2208 R is the embedding of node i at layer 1 (h) are the features of the nodes), W1, W2, W3, W4 \u2208 Rn\u00d7n are the weight matrices and ai,j \u2208 R are the attention coefficients, computed via multi-head dot product attention. This model is similar to the one provided by [Vassoyan et al., 2023]."}, {"title": "4 Pre-training on source tasks", "content": "In this section, we present our approach for pre-training our recommender system on sequential corpora."}, {"title": "4.1 Data distribution", "content": "Corpus For the corpus distribution, we have used 14 real-world sequential corpora scraped from 3 popular e-learning platforms. Each corpus contains a sequence of videos that are meant to be viewed one after another, as they build up from each other. These corpora address educational topics related to machine learning, statistics, and computer science. We automatically extracted keywords from the transcriptions of these videos using an LLM, as described in Appendix F. For the keyword features, we have used pre-trained embeddings from Wikipedia2Vec [Yamada et al., 2020].\nPopulation For a sequential corpus, Epref = \u00d8. Therefore the only degree of freedom is the distribution over prior knowledge P(x|V, Eprereq) with Eprereq = k1 \u2192 k2\u2026 \u2192 kn. For this pre- training task, we assumed a population with zero prior knowledge for simplicity. This means that for each student, x0 = (0...0) at the beginning of the learning session."}, {"title": "4.2 Pre-training", "content": "The pre-training was carried out in two stages. In the first stage, we trained the model to match the predictions of an oracle, in a supervised learning way. Our oracle is simply an algorithm that has access to the environment graph and therefore knows exactly which document to recommend in each situation. Note that this first stage is quite similar to the way LLMs are pre-trained: instead of predicting the next token, we predict the next document in a predefined sequence. In the second stage, a reinforcement learning training was performed with the REINFORCE algorithm [Sutton et al., 1999]. This stage is crucial as, with a discount factor greater than zero, the model can learn to make \"useful\u201d mistakes that is, recommendations that do not facilitate student learning but provide valuable information about his current knowledge. The choice of not using any algorithm involving an approximate value function, although these are known to be more stable [Mnih et al., 2013, Haarnoja et al., 2018, Mnih et al., 2016], was motivated by the difficulty for GNNs to reason at the scale of"}, {"title": "5 Fine-tuning on target task", "content": "To evaluate our recommender system in a complex adaptive learning scenario, we have designed a corpus of 22 written documents teaching machine learning basics. We have conceived it in a way that the dependencies between knowledge components are easy to establish manually. The resulting graph is a grid of KCs with 3 rows and 11 columns, depecting prerequisite relationships among all documents. We have also included an additional \"background\" KC that isn't taught by any document but conditions the access to some of them, thus bringing greater diversity to the student population. More details about the design of this corpus along with a graphical representation are provided in Appendix D.1.\nIn our framework, choosing a student distribution is equivalent to defining P(Epref|C) and P(x Epref, C). Regarding P(Epref|C), we considered that in the specific case of our corpus, it made sense to model learning preferences as a set of extra \u201cvertical\" dependencies (edges) between knowledge components. Therefore, for each new student, a random set of such edges was generated, following a binomial distribution of parameter p = 0.3. So for any ki,j \u2208V, P(ki,j \u2192 ki+1,j \u2208 Epref) = 0.3. An interpretation of this modeling of learning preferences is provided in Appendix D.1. As for the distribution over prior knowledge P(x|Epref, C), we have considered 3 possible scenarios:\nScenario 1 (none): the learners have no prior knowledge, i.e. x = (0 . . . 0) for all students;\nScenario 2 (decreasing exponential): the number of KCs known by the students prior to the learning session follows a decreasing exponential distribution; this allows to model a population where most students have little knowledge about the corpus, but not all of them;\nScenario 3 (uniform): the number of KCs known by the students prior to the learning session follows a uniform distribution; this is the most challenging environment as uncertainty is maximal.\""}, {"title": "5.2 Training", "content": "For each sampled student, some paths in the corpus are reachable while some others are not (depending on their prior knowledge and learning preferences). To avoid that the agent always chooses the safest path (instead of adapting to the student's profile), we slightly modified the reward function, in order to give greater rewards to \u201cdifficult\u201d paths. Rather than summing the newly acquired knowledge components as depicted in Equation 4, we computed a weighted sum by multiplying each KC by its respective value. More details about the values of the KCs are provided in Appendix D.1.\nThe fine-tuning was performed on 10 epochs, where 5 new students were sampled on each epoch. Therefore, it was carried out on a total of 50 students. The maximum size of each episode was set to 11 (because of the 11 \"major\" concepts, cf. Appendix D.1). On each epoch, we tested our model on 20 test episodes (~ 20 students) and aggregated our results over 30 random seeds. We did not perform any hyperparameter search in the fine-tuning stage so as not to give an advantage to our pre-trained model. Instead, we simply adopted the hyperparameters used by Vassoyan et al. [2023] as they provided good performance for training on a single corpus"}, {"title": "5.3 Baselines", "content": "Although numerous approaches had been explored in the literature on learning path personalization, for a fair comparison we selected only models that did not use the corpus's prerequisite graph for making predictions. Consequently, we compared our approach against three baselines."}, {"title": "5.4 Results and discussion", "content": "The results of our fine-tuning experiments are presented in Figure 4 and Table 1. The four recom- mendation engines are compared in each of the three scenarios described in 5.1. The performance of each model is measured in learning gains per student, which, in our setting, is equivalent to the undiscounted episodic return. These learning gains are plotted against the number of students, where each student can be regarded as an episode. The maximum episode length is 11, which puts us in a very low data regime. The margins of error in Figure 4 were estimated using a studentized bootstrap method, with 10,000 resamples and a 95% confidence interval.\nThe first observation that can be made from these plots is that our pre-trained model outperformed all other approaches in all scenarios. As expected, the performance gap was most pronounced at the beginning of the training sessions, where our model benefited from a strong warm start. Moreover, it maintained its lead throughout the entire training sessions and converged to values well above those of its non-pre-trained counterparts. This suggests that the pre-training process has given our"}, {"title": "6 Related work", "content": "Previous works have used reinforcement learning to decide on the pedagogical action in computer- based education to increase the student's learning gain. Many works used RL agents with small state and action spaces to accommodate the small amount of data available. For such cases, a tabular RL algorithm was used to train an RL agent. One example of this is the work by Chi et al. [2011], where the RL agent takes a state vector containing e.g. the simplicity of the concept to explain, and decides between hinting and telling the student how to solve an exercise. Similar approaches have been shown to work in practice in specific and tightly constrained settings [Gordon et al., 2016, Park et al., 2019]. Because of the simplicity of the state space, these works are limited to small and fixed, specific sets of interactions.\nAnother branch of approaches used simulated students to allow for more learning iterations. Among the first was the work by Iglesias et al. [2009], where tabular Q-learning was used to choose the types of learning material for simulated students. Later works have used RL algorithms that can handle more complex state and action spaces [Lan and Baraniuk, 2016, Rafferty et al., 2016], and in particular deep RL [Reddy et al., 2017, Subramanian and Mostow, 2021]. Although simulated students allow RL agents to train for virtually unlimited episodes, and so handle more complex dynamics, there is a strong reliance on the accuracy and realism of the simulated students. We alleviate this by using simulated students for pre-training, then evaluate the potential of the RL agent to generalize to an unseen learning environment.\nClosely related to our work was by Bassen et al. [2020], which applied deep RL to recommend different educational materials from a pool of 12. They used data collected from 1,830 participants to train the agent. They used one-hot encoding to represent the materials, meaning that the agent needs to be retrained to work with another set of materials. Their approach also required a large number of real student data because of the sparse reward, coming only once at the end of an episode, showing the importance of sample efficiency in real-world applications. We improve upon this by using meaningful embeddings to represent the materials to recommend.\nDesigning simulated students requires modeling how knowledge works. A student's knowledge is broken down into Knowledge Components (KCs), which are small units of knowledge that a student can learn and hold (e.g. a fact or a skill). Based on this, different exercises or content can be associated with different KCs, creating a binary matrix called the q-matrix [Barnes, 2005], allowing interactions with an exercise to act as evidence for the associated KCs. Building up further, the theory of knowledge space and the attribute hierarchy method both suggest an order of prerequisites between these KCs, which can be represented as a graph"}, {"title": "7 Conclusion", "content": "Our study shows that when dealing with an adaptive learning scenario, one efficient strategy to improve sample-efficiency is to gather a set of closely related sequence corpora and pre-train a recommender system on them. This pre-training procedure does not involve any annotator to tag documents nor real students to interact with them, but requires a flexible enough recommender"}, {"title": "A Details about the environment", "content": ""}, {"title": "A.1 Learning preferences", "content": "We argue that learning preferences can be modelled without loss of generality through a set of additional dependencies between knowledge components (if necessary by adding more knowledge components). To illustrate this point, let's consider two students u\u2081 and u2 mastering the same set of knowledge components: Xu\u2081 = Xu2 = x. Let's suppose that u1 and 42 hold different learning preferences: this means that there exists at least one document d for which u\u2081 and u2 will react differently, for example u\u2081 understands it while u2 does not. Assuming that d is not definitively out of scope for student u2, there must exist a minimal set of documents D' whose reading will enable him to understand document d. Denoting K = d\u2192 and K' = Ud' \u2208D'd', this translates into an extra set of dependencies K' \u2192 K for student 42."}, {"title": "A.2 Transition probability function", "content": "To describe the transition probability of the student's dynamics, we start with the base case, where there is only one KC in the dynamics. We model the student's knowledge state as a binary \u201cknown\" or \"unknown\" state on the KC. The student never forgets, so a known KC remains known for the rest of the episode. Learning can occur when a student interacts with a document that teaches a KC that the student previously did not know. If the student knows all the prerequisite KCs required to understand the document, then the student will learn all the KCs taught by that document. Otherwise, the student will not learn any of the KCs taught. As a result, the transition of the student's state is fully deterministic, dependent on the stochastic and unknown prerequisites of the documents. Formally, the transition probability in the case of 1 KC is described as the following:\nT(x, d, x) = P(St+1 = x | St = x, at = d):\nif (x = 1, x = 1)\nif (x = 1, x = 0)\nT(x, d, x) =\n+1(ki \u2209 d),\nif (x = 0, x = 0)\nif (x = 0, x = 1)"}, {"title": "A.3 Observation function", "content": "Next is the observation function, which describes how a student responds to a recommended document. There are three possible interactions for the student: right level, too easy, or too hard, denoted fo, f>, f< respectively. The student deems the document too easy when the student has already mastered the KCs that the document teaches. In contrast, the student deems the document too hard when the student did not master all the prerequisite KCs of the document at the time. Otherwise, the document is at the right level, making the student master new KC(s). Formally, the observation function Z(s, d, o) is described as follows, where s = (x, Epref):\nZ(s, d, o) =\nif (o = f<)\nif (o = f>)\n1(x\u2287 d\u2190 \u2227 xi \u2229 d\u2192 \u2260 xi), if (o = fo)"}, {"title": "B Architecture of the recommender system", "content": "Our recommender system F = \u03c8 \u03bf \u03c6 is a composition of two graph neural networks operating on the bipartite graph B defined in Section 3. GNN layers are implemented with directed edges, successively used from documents to keywords, and from keywords to documents. Moreover, & combines a GNN architecture with a multi-layer perceptron (MLP) that produces embeddings of the feedback signals. These feedback embeddings are then combined with the embeddings of their associated document nodes with a Hadamard product.\nBelow is the complete architecture of our recommender system:\nH(1) = Linear(E)\nH (2)W = TransformerConvdoc\u2192kw(H(1))\nHD = TransformerConvkw\u2192doc(H(2))\n\u03a6\nH = H MLP(FD)\n(3)W = TransformerConvdoc\u2192kw(H(3))\nHD(4) = TransformerConvkw\u2192doc(H(3))\nZD = Linear(H4))\n\u03c8\nwhere H(l) \u2208 R|V|\u00d7k is the node embeddings at layer l, with HD \u2208 RIVDIxk and HW \u2208R/Vw|xk are the restrictions of H(1) to document and keyword nodes respectively. Note that H 4(3) is actually the latent representation Zt defined in section 3. E \u2208 Rnxn is the input node features. FD is the matrix of past feedback signals (one feedback per document, with a \u201cnone\u201d feedback for documents that have not been visited yet). TransformerConv(\u00b7) is the operator formulated in Equation 5, with the subscripts doc \u2192 kw and kw \u2192 doc denoting the directions of edges. Linear(\u00b7) is a linear transformation. MLP(\u00b7) is a two layers perceptron with one hidden layer. O is the Hadamard product. An extra linear layer is added after the final TransformerConv to map document representations to scores (then converted to probability distribution via softmax)."}, {"title": "C Pre-training on source tasks", "content": "The learning curve and hyperparameters we have used for the pre-training on source tasks are provided in Figure 6. The batch size refers to the number of graphs passed as input to the model"}, {"title": "D Fine-tuning on target task", "content": ""}, {"title": "D.1 Graph corpus", "content": "The graph corpus contains a set of written documents on machine learning, which are distinct from the ones in the sequential corpora, albeit they share some keywords. We have designed this corpus in such a way that it is aimed at two types of student: those with Computer Science (CS) background, and those without CS background. Consequently, the corpus teaches 11 major concepts and each concept is addressed by 2 documents, from 2 different angles: the \u201ccomputer science\u201d angle (often involving linear algebra or IT concepts) and the \u201cnon-computer science\u201d angle. To model this, we have adopted a 3-line system of knowledge components, where each major concept is broken down into three knowledge components (one at each level): the middle KC represents the major concept to be taught, the top one represents its \"non-CS\" angle and the bottom one represents its \"CS\" angle. Consequently, all the bottom KCs are conditioned by a \"background\" KC, which states whether the student has a \"CS\" background or not. Non-CS students can only learn from non-CS documents, as they lack the CS prerequisite. CS students can learn from both types of documents. Prerequisites relationships Eprereq were modeled as horizontal dependencies in the two bottom levels. As for learning preferences Epref, these were modeled as \u201cvertical\u201d dependencies. Here is an example to motivate this choice: consider that one major concept of the corpus is the artificial neuron. It can be taught using CS notions (like linear algebra) or without these notions (for instance using a biological analogy). For some CS students, the mathematical explanation may be sufficient to enable them to understand the concept intuitively. But for some others, although they have the necessary CS background, some non-mathematical explanation might help in grasping the concept intuitively. Hence the existence of certain vertical dependencies between the \u201cnon-CS\u201d and \u201cCS\u201d levels, which we model as learning preferences. Overall, the graph corpus aims to show that the RL agent can generalize its knowledge from the sequential corpora, and that the RL agent can learn to adapt to different types of students.\nThe \"value\" of each KC depends on its position on the grid: the value is 1 for row 1, 2 for row 2 and 3 for row 3 (the most difficult to access are the most valuable)."}, {"title": "D.2 Fine-tuning process", "content": "The hyperparameters we have used for the fine-tuning of the model on the target task are listed in Table 3."}, {"title": "E Other pre-training strategies", "content": "In this section we provide experimental results for two other pre-training strategies. Both of them are performed on the same source tasks (sequential corpora) we have used in the main experiment. The first strategy is just the same as the one we presented in the core of the paper, without the RL stage. This means the model was solely pre-trained on expert data, allowing to evaluate the importance of the RL stage. The second strategy consists in training the model to predict student's feedback on each next document (instead of choosing next document). This provides a target signal slightly more informative than the sole good/bad recommendation signal we have used for pre-training on expert data. Therefore, this could lead to more accurate internal representations. The learning curves are presented in Figure 8 (our final model is also displayed for comparison). The margins of error were estimated using a studentized bootstrap method, with 10,000 resamples and a 95% confidence interval."}, {"title": "F Keywords extraction", "content": "The main difficulty in our keyword-extraction setting is that we did not extract \"regular\" keywords but only keywords related to Wikipedia articles. Indeed, we have chosen to use Wikipedia2Vec pre-trained embeddings as features of the keywords, mainly because we consider that embeddings which primarily contain \"encyclopedic\" information would be more suitable for this task. Since modern large language models usually have a good knowledge of Wikipedia, we simply prompted GPT-4 to achieve this task, using the prompt below (adapted for each document):\nYou are a helpful assistant who extract keywords from educational documents. A user will pass an educational document. First, you extract the academic topic of the document. This could be the title of the document in a course sequence. Don't write anything else. Then, you examine every single term in this document and extract them if they refer to a technical concept closely related to the academic topic of the document. Avoid including keywords that are only used in examples and don't have much to do with the subject taught in the document. You directly output a python list of strings for example: \u201cmachine learning\u201d, \u201cneural network\u201d etc., without duplicate. There should never be more than thirty keywords or so, so choose the most important ones. Again, don't write anything else. Eventually, you associate each term with its corresponding Wikipedia page (Wikipedia ID) if it exists. Sometimes this needs to be done cleverly: for example, \"sequential data\" should be associated with the Wikipedia ID \"Sequence\". Drop the terms that don't have a Wikipedia page. Directly output a python list of strings of Wikipedia IDs for example: . Again, don't write anything else."}, {"title": "G Software", "content": "Our GNN was implemented using the Python library Pytorch-Geometric and the reinforcement learning agent was trained with Tianshou . The keyword extraction process was implemented using Langchain ."}]}