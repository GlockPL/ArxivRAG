{"title": "Leveraging Graph Neural Networks to Forecast Electricity\nConsumption", "authors": ["Eloi Campagne", "Yvenn Amara-Ouali", "Yannig Goude", "Argyris Kalogeratos"], "abstract": "Accurate electricity demand forecasting is essential for several reasons, especially\nas the integration of renewable energy sources and the transition to a decentralized network\nparadigm introduce greater complexity and uncertainty. The proposed methodology lever-\nages graph-based representations to effectively capture the spatial distribution and relational\nintricacies inherent in this decentralized network structure. This research work offers a novel\napproach that extends beyond the conventional Generalized Additive Model framework by\nconsidering models like Graph Convolutional Networks or Graph SAGE. These graph-based\nmodels enable the incorporation of various levels of interconnectedness and information shar-\ning among nodes, where each node corresponds to the combined load (i.e. consumption) of a\nsubset of consumers (e.g. the regions of a country). More specifically, we introduce a range of\nmethods for inferring graphs tailored to consumption forecasting, along with a framework for\nevaluating the developed models in terms of both performance and explainability. We conduct\nexperiments on electricity forecasting, in both a synthetic and a real framework considering\nthe French mainland regions, and the performance and merits of our approach are discussed.", "sections": [{"title": "1 Introduction", "content": "The effective operation of the electrical system relies on maintaining a balance between electric-\nity supply and demand. Since electricity cannot be efficiently stored, its production needs to be\nconstantly adjusted to match consumption. Providing accurate forecasts for short-term electricity\ndemand is therefore crucial for all participants in the energy market. The shift toward a decentral-\nized electricity network introduces new uncertainties, which pose additional challenges for demand\nforecasting. In addition, the increasing contribution of renewable energy sources, like solar and wind\npower, brings fluctuations and intermittency to the electricity market. These fluctuations and inter-\nmittency occur at various spatial scales due to the presence of wind farms and photovoltaic power\nplants. The crisis brought by Covid-19, along with the current economic downturn, add further\ncomplexity to forecasting due to the non-stationarity in consumption patterns [2]. The availability\nof new geolocated data and individual electricity consumption data can be exploited by models that\nare able to take advantage of additional information and help in minimizing forecast uncertainty"}, {"title": "2 Preliminaries and Background", "content": "In this section, we introduce the basics of GNNs, additive models and expert aggregation."}, {"title": "2.1\nGraph Neural Networks", "content": "In graph theory, objects are represented by nodes, and the relationships between them are repre-\nsented by edges. Formally, a graph G = (V,E) is a couple where V is a set of nodes and E a set of\nedges, i.e. E = {lij = ViVj | Vi, Vj \u2208 V}. A graph can be represented either using a binary-weighted\nadjacency matrix A = (Aij) \u2208 RN\u00d7N such that Aij = 1 if and only if eij \u2208 E, or a more flexible real-\nvalued weight matrix W. We denote the neighborhood of node v by the set N = {u \u2208 V, Auv = 1},\nor equivalently {u \u2208 V, Wuv > 0}. Note that we consider symmetric graphs, therefore A = AT\nand W = WT. In the context of electricity load forecasting in France, regions and the unknown\nlinks between them can respectively be seen as nodes and edges. Both regression and classification\ntasks can be performed on graphs at different levels: node-level, edge-level, graph-level.\nThe node-level focuses on individual nodes within a graph. It involves analyzing the properties\nor attributes of each node. For example, in the context of electricity forecasting, a node-level\ntask could be to predict the consumption for each region.\nThe edge-level pertains to the analysis of the edges or connections between nodes in a graph.\nIt involves examining the relationships, weights, or properties associated with each edge. For\nexample, in the context of electricity forecasting, an edge-level task could be to quantify the\nrelationships between the regions.\nThe graph-level refers to the analysis of the entire graph structure as a whole. It involves\nexamining global properties, overall connectivity, or emergent behaviors of the graph. For ex-\nample, in the context of electricity forecasing, a graph-level task could be to predict the national\nconsumption.\nIn the context of GNNs, message passing refers to the process of exchanging information be-\ntween nodes, edges, and the global level of a graph, see Figure 1. Message passing is a fundamental\noperation in GNNs that enables nodes to gather and aggregate information from their neighbors,\nincorporate it into their own representations, and propagate it throughout the graph. Hence, a\nGNN corresponds to a set of layers that use the message-passing mechanism. Node representations\nare therefore updated as the graph is iterated through (in other words, at each layer traversed,\nrepresentations are updated). A message passing layer therefore enables a node to update its em-"}, {"title": "2.2\nGeneralized Additive Models", "content": "GAMs is a class of semi-parametric regression models that was developed in [19, 40] and are now\nwidely used in electricity consumption forecasting [13]. Indeed, GAMs are interesting in practice,\nsince their additive aspect makes them highly explainable, but this also means that the choice\nof variables must be meticulous. Consider a prediction model aiming to predict for each time t a\nvariable of interest y\u0142 using (xj)j=1...d explanatory variables such that yt = \u03b2o + \u2211j=1 fj(xt,j) + Et,\nwhere Bo is the intercept and (et) is independent and identically distributed random variable. Here\nwe consider that each non-linear effect f; is decomposed on a spline basis (Bj,k) with coefficients\n\u03b2; where m; is the chosen spline basis dimension, such that f;(x) = \u22111 \u03b2j,kBj,k(x). These\ncoefficients are then estimated by minimizing the ridge-regression criterion ensuring the smoothness\nof the functions f; by controlling the second derivatives [42]."}, {"title": "2.3 Aggregation of Experts", "content": "Several models have been developed in the literature, each with its own distinctive features, which\nmay also complement each other. Expert aggregation is an ensemble technique that allows to benefit\nfrom the advantages of each model: we can combine them using robust online aggregation of experts,\nas developed in [6]. For each instant in the prediction, a weight is assigned to each expert according\nto its previous forecasts: the better the past forecasts, the greater the weight at time t. Let xj,t\nbe the jth expert at time t and pj,t its corresponding weight, then the expression of the predicted\nload at time t is given by \u0177t = \u2211j=1Pj,txj,t, where K is the number of experts in the mixture.\nOne way to compute the weights is to use polynomially weighted averages with multiple learning\nrate (ML-Poly), an algorithm developed in [14]. A key advantage lies in the upper bound of the\nK"}, {"title": "3 Developing Robust Models with GNNs", "content": "This section presents our methodology for building robust GNNs for load forecasting: from the\ninference of suitable graphs, to the explanation of the forecasts obtained by the models."}, {"title": "3.1 Inferring Graphs from Data", "content": "Geographical Data. To capture the relationships between the nodes of a graph, a first approach\nis to study the similarity matrix of the geographical positions of these nodes. We can therefore\ndefine the weight matrix as follows:\nWx = (Wi,j)1<i,j\u226412 = {exp {\u2212dist(i, j)2\u03c32 } if exp {\u2212dist(i, j)2\u03c32 }> \u03bb,0otherwise.(3)\nwhere \u03bb \u2208 (0,1) is a threshold that controls the connectivity of the graph, dist(i, j) is the geodesic\ndistance between nodes i and j, and ois a bandwidth term. In practice, A is picked such that\nthe graph induced by W\u2081 is minimally connected, and ois the median of all the distances. Other\nheuristics can be used to calculate the bandwidth of the Gaussian kernel, but in practice this one\ngives good results and is robust to outliers [15, 28]. Figure 2 shows the spatial matrix corresponding\nto x = 0.71 and \u03c3 = 478.3. Note that this approach does not take geographic distances into account:\nwe are using a simple approach here, but we could consider reducing the weights of regions separated\nby physical obstacles (sea, mountains, etc.). A slightly different approach might be to merge the\nspatial graph as presented above, with a graph encoding the different geographical clusters of the\ngraph (1 if nodes belong to the same cluster, 0 otherwise). We could, for example, consider coastal,\nmountain, urban and rural areas.\nElectricity and Weather Data. Another way of capturing relationships between nodes is to look\nat spatio-temporal nodal characteristics, such as temperature, cloud cover or wind signals, which\nare used in practice in load forecasting. In practice, to build the graphs, we group all the scaled\nelectricity and weather signals by region and we construct n matrices of dimension (d, T), where\nn is the number of nodes in the graph, d is the dimension of the feature space, and T the number\nof instants in the time-series, which we project using a singular value decomposition (SVD) into\na space of dimension (1,T). In this way, we end up with a global matrix of dimension (n,T) on\nwhich we can apply various algorithms, see Figure 3. In the study, we computed the DTW distance\nwith FastDTW [34], an approximate Dynamic Time Warping algorithm that offers near-optimal\nalignments with linear time and memory complexity, between the reduced regional signals. We also\ntried a slightly different approach that involves estimating regional temperature effects on load\n(using splines, for example) and then calculating a matrix of correlated distances (such as the L2-\ndistance) between the different splines. We also implemented the GL3SR algorithm [20], based on\ntwo key assumptions about the signal: first, that the signal is smooth with respect to relative to\nthe graph structure (i.e. adjacent nodes have similar values, which is the case for weather and load\nsignals across the mainland France), and second, that the signal is bandlimited and therefore has a\nsparse representation in the spectral domain."}, {"title": "3.2 Explainability", "content": "GAMs have been used for electricity forecasting because they have the advantage of being explain-\nable. With GNNs we want to know the hidden links between the different regions. This subject has\nbeen studied in [43] with subgraphs, where the GNNExplainer algorithm was developed, which aims\nat explaining both the graph structure and the features. The idea is to differentiate the subgraphs\nthat are useful in the prediction from the ones that are not. Thus, let us write G = Gs + AG where\nGs is the explaining subgraph, and AG the subgraph with irrelevant edges. Then, we want to max-\nimize the mutual information (MI) between the predictions Yg and the subgraph Gs that is given\nby solving the optimization problem maxgs MI(YG,Gs) = H(Y\u04ab) \u2013 H(Y\u04ab | G = Gs, X = Xs),\nwhere H is the entropy function and Xs is a subset of explaining features. In the previous equation,\nH(YG) is constant therefore the optimization problem is equivalent to finding the minimum of the\nconditional entropy H(YGG = Gs, X = Xs), which amount to minimizing the uncertainty of the\nprediction Yg. Supposing that Gs is a random graph variable following fg, the algorithm seeks to\nminimize H(YG | G = Efc [Gs], X = Xs), where Efc [Gs] is computed with a mean-field approxi-\nmation. In other words, the objective is to pinpoint a compact subgraph along with a limited set\nof node attributes that greatly enhance a GNN's prediction certainty."}, {"title": "4\nExperiments", "content": "In this section, we outline the experimental procedure used to assess GNNs, covering everything\nfrom dataset preparation to result analysis, including model parameterization."}, {"title": "4.1 Datasets", "content": "We present the datasets used in our experiments: in particular we explain the generation of synthetic\ndata and describe the real data. For both synthetic and real datasets, we consider the 12 regions of\nFrench mainland - excluding Corsica.\nSynthetic Dataset. To evaluate the GNNs performance, we synthetically generate data. In this\nway, we can manually add spatial and temporal correlations between different graph nodes and\nobtain a lower bound on the model performance. Let us denote by Tsen(t) and Len(t) (respectively\nTobs(t) and Lobs(t)) the generated temperature and load (respectively the observerd temperature\nand load) at time t and node j. We have Tsen(t) = at + bj(cosw\u2081t + cosw2t), where a is a trend\ncoefficient, w\u2081 and w2 being respectively a daily and a yearly pulse, bj a random term such that\nb = (bj)1\u2264j\u226412 ~ N(\u03bc, \u0108) with \u00fb and \u0108 being respectively the empirical mean and covariance\nof the observed temperatures. Temperatures are then rescaled to ensure that they lie between\nthe observed minima and maxima of each region. Then, we fit a cubic spline basis [41] such that\nf; \u2208 arg arg min (f; (Tobs) \u2013 Lobs) with f; e span(sj,1,..., sj,k) and k being the number of knots.\nIt follows that Len(t) = f; (Ten) (t) + \u025bj(t), where \u025b = (Ej)1\u2264j\u226412 ~ N(0, \u03a3). We simulate two\ndatasets: one with \u2211 = p(Wx) associated to pairwise influence between the regions, and one with\n\u03a3 = I associated to independent regions.\nReal Dataset. We also tested the GNNs on regional data provided by RTE (R\u00e9seau de Transport\nd'Electricit\u00e9), which is the electricity transmission system operator of France. We enriched the\ndataset with a variety of features related to electricity consumption and weather conditions in\nFrance. It includes generic calendar columns such as an identifier index (used as a trend), multiple\ndate formats, month and year indicators, time of day and year, week number, type of day (weekdays,\nbank holidays, weekends), specific holiday periods like national, Christmas, summer holidays and a\nbinary indicator for daylight saving time changes. The targeted feature in this dataset is the French\nnational load (in megawatts). Table 1 gives the description of the features in the dataset."}, {"title": "4.2\nExperimental Settings", "content": "We place ourselves in a regression setting: we want to forecast the electricity consumption at each\ntime instant t based on features measured at that time.\nTraining Procedure. Denote by X \u2208 RnxdxT and y \u2208 Rn\u00d7T, respectively, the feature and the\ntarget vectors, where n\u2208 N is the number of nodes in the graph, d\u2208 N is the number of features,\nand T\u2208 N is the number of timesteps to predict. We scale the vectors such that the range of the\nvalues is in [0, 1] and the scaled versions of the input vector is denoted by X. We want to find the\nbest set of parameters 0* that minimizes the global loss l such that 0* \u2208 arg mine l(Po(G,X), y),\nif such a solution exists. In practice, we seek to optimize the mean squared error loss defined by:\nRMSE(y, y) = \u221a1Tn\u2211Tt=1\u2211ni=1(yi,t \u2212 \u0177i,t)2.(4)\nThe set of parameters is computed iteratively using stochastic optimization with batch sampling,\nand in particular we used the Adam algorithm [25].\nEvaluation Metrics. We used traditional loss functions: Mean Absolute Percentage Error (MAPE)\nand Root Mean Square Error (RMSE), which are commonly used to evaluate the performance of\nforecasting models. MAPE measures the average percentage difference between the forecasted and\nactual load values, providing an indication of the relative error:\nMAPE(y, y) = 1T\u2211Tt=1\u2211ni=1 |yi,t \u2212 \u0177i,t|\u2211ni=1 yi,t.(5)\nRMSE measures the square root of the mean squared difference between the forecasted and actual\nload values, i.e. the square root of Equation 4. MAPE is chosen for its interpretability as it provides\na percentage error that is easy to understand and compare across different scales. This is particularly\nuseful in electricity forecasting as stakeholders need clear insights into the accuracy of predictions\nrelative to actual demand. RMSE, on the other hand, is sensitive to large errors, making it a suitable\nmetric for applications where minimizing significant deviations is important [21]."}, {"title": "5 Discussion", "content": "The experiments are set in a regression context for a given instant: future experiments could aim\nto integrate previous instants into the forecast for the target instant, e.g. by exploiting temporal\nGNN models [33]. The inference methods presented here could also be coupled with explainability\nmethods, and could therefore be split into two steps: first, \"classical\" inference as presented in\nthis work, then multiplication of the inferred matrix by a mask. Future experiments could also\ninclude renewable production data (solar and wind) to take into account the evolution of the grid\ntowards a decentralized network. Considering the results obtained with distance-based graphs (such\nas DTW and spline effect distances), we plan to derive other graphs based on socio-economic data."}, {"title": "6\nConclusion", "content": "In this paper, we introduced a method for constructing graphs tailored to the problem of electricity\nconsumption forecasting. Through diverse inference methods, graph fusion, and the aggregation of\ndifferent models, the final graph is robust and enhances the performance of GAMs when the data\nhas an underlying graph structure. The explanatory sub-graphs help understand the connections\nbetween different regions, validate or refute hypotheses about these links, and consequently propose\na corrected version of the input graph. Areas for improvement include incorporating a temporal\nstructure into the models and developing specialized models for different times of the year, such as\nwinter and summer. Ultimately, the outcomes achieved with GNNs show promise: in cases where\ndata exhibits a graph-based structure, these models perform much better, contributing to diverse\nenhancements through improved expert aggregation."}]}