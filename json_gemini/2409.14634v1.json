{"title": "Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination", "authors": ["Marissa Radensky", "Simra Shahid", "Raymond Fok", "Pao Siangliulue", "Tom Hope", "Daniel S. Weld"], "abstract": "The scientific ideation process often involves blending salient aspects of existing papers to create new ideas. To see if large language models (LLMs) can assist this process, we contribute SCIDEATOR, a novel mixed-initiative tool for scientific ideation. Starting from a user-provided set of papers, SCIDEATOR extracts key facets purposes, mechanisms, and evaluations - from these and relevant papers, allowing users to explore the idea space by interactively recombining facets to synthesize inventive ideas. SCIDEATOR also helps users to gauge idea novelty by searching the literature for potential overlaps and showing automated novelty assessments and explanations. To support these tasks, SCIDEATOR introduces four LLM-powered retrieval-augmented generation (RAG) modules: Analogous Paper Facet Finder, Faceted Idea Generator, Idea Novelty Checker, and Idea Novelty Iterator. In a within-subjects user study, 19 computer-science researchers identified significantly more interesting ideas using SCIDEATOR compared to a strong baseline combining a scientific search engine with LLM interaction.", "sections": [{"title": "1 INTRODUCTION", "content": "Scientists are continuously brainstorming research ideas on which to work next. A good idea should be relevant to the scientist's interests and novel within the scientific community. Research papers are a major source of inspiration for relevant and novel ideas, as they expose scientists to relevant concepts to re-combine and form new ideas [4, 21, 36]. However, generating relevant and novel scientific ideas by recombining concepts from research papers is difficult for multiple reasons. For one, scientists must wade through an ever-expanding scientific literature to find relevant concepts [2, 19]. Moreover, the phenomenon of fixation biases scientists against considering more diverse concepts and concept recombinations for their research; instead, they are predisposed to thinking about a problem in familiar terms, which hinders the stimulation of novel ideas [11, 37]. Even if a scientist manages to identify interesting concept recombinations to form potential research ideas, assessing the ideas' novelty in comparison to the existing literature is a cumbersome yet critical task.\nBuilding a fully or semi-automated ideation system has been an ambition of researchers for decades, and SCIDEATOR builds on strong prior work from many other researchers, filling a unique niche. We extend a line of work that presents systems for finding analogies between research papers [4, 21, 36], adopting their facet-based framework but using modern large language model (LLM) methods to identify relevant facets and perform facet recombinations. We are also inspired by recent work showing that LLMs have promise to assist ideation in domains outside science, helping people to generate more ideas [6] and more diverse ideas [27, 40]. While some of this LLM-based work employs facetrecombination [6, 43], it fails to account for scientific ideation's important requirements- that ideas be grounded in the literature and novel relative to prior work. Yet other work applies LLMs to scientific ideation without reasoning about analogous facets [28]; one problem noted by their participants was the generation of potentially unoriginal ideas. In contrast, our approach to ideation provides two mechanisms to increase the originality of candidate scientific ideas: 1) facet recombination and 2) explicit novelty assessment.\nIn this work, we present SCIDEATOR, an LLM-powered tool for scientific ideation that extracts facets (purpose, mechanism, and evaluation) from existing papers and helps recombine them in novel research ideas, carefully checking the literature to avoid overlap with prior work. As in prior work, the purpose facet describes the problem being addressed by the paper, while the mechanism facet describes the paper's proposed solution to the problem [4, 21, 36]. We also"}, {"title": "2 RELATED WORK", "content": "In ideation, there are two main stages of thinking: divergent and convergent [8, 39]. While engaging in divergent thinking, the ideator is not worried about generating the most high-quality ideas. Instead, they aim to produce as many ideas as possible in an effort to leave no stone unturned in considering potential solutions to their problem. At this stage of the ideation process, avoiding fixation on familiar concepts is important [11, 37]. Otherwise, the ideator may miss strong candidate ideas simply because they utilize more distant concepts. In contrast, while engaging in convergent thinking, the ideator concentrates on narrowing down their ideas and determining which ideas to pursue. In this work, we focus on divergent thinking. In scientific ideation, this equates to gathering inspiration from many sources and coming up with several potential research ideas. Our tool SCIDEATOR also supports evaluating ideas for novelty. While idea evaluation is generally aligned with convergent thinking, we utilize this evaluation to help users consider even more ideas when there are not enough existing novel candidate ideas."}, {"title": "2.2 Concept Combination and Analogy", "content": "Concept combination and analogy are key methods for creating ideas [15, 22, 46]. Often, concept combination refers to the fusing of two concepts into a new emergent concept. In the rest of this paper, we use the phrase \"concept combination\" more broadly to refer to the use of multiple concepts in creating a new idea. Related work has investigated how concept combination may be used in LLM-powered tools for ideation. Through CreativeConnect, users can recombine keywords to generate a graphic sketch [6], and through Luminate, users can recombine values of various dimensions to generate diverse LLM responses [43]. Prior works have explored combining facets from an input artifact and analogous artifact in order to produce a new idea [5, 42]. We build upon these works by developing and evaluating a tool that supports exploration of a scientific idea space grounded in the literature.\nOf particular note to scientific ideation is a line of work that describes ideas in terms of two facets: the purpose (i.e., the problem) and the mechanism (i.e., the proposed solution to the problem). Hope et al. found that this faceted idea framework helps identify useful analogies for ideation [16]. If two ideas have similar purposes, then the mechanism of one idea may apply well to the purpose of the other idea. Similarly, if two ideas have similar mechanisms, then the purpose of one may combine well with the mechanism of the other. Subsequently, the framework has been shown to facilitate the creation of analogies between product ideas [16, 18], biological and design ideas [20], research papers [4, 21], and research-paper authors [36]. Utilizing this faceted framework, our mixed-initiative tool not only presents researchpaper facets to recombine but also supports rapid exploration of the design space of potential facet recombinations and associated ideas using the power of LLMs."}, {"title": "2.3 Human-Al Scientific Ideation", "content": "Several prior works have looked into automating scientific ideation [1, 25, 48], but automatic methods are currently insufficient for formulating novel, impactful research ideas [17, 48]. In response, many works have studied the benefits of human-Al collaboration on scientific ideation [13, 49]. A number of studies have demonstrated that scientists and AI are able to work together to identify inspirational analogies between two scientific papers or paper authors [4, 21, 36]. With the rapid advancement of LLMs, recent work has started introducing LLM-powered scientific ideation tools. The tool SeeChat X Ideas takes a problem and scientific areas as input and returns a detailed research idea with citations and an associated literature review [14]. Liu et al.'s CoQuest helps scientists generate potential research questions in a depth-first or breadth-first manner, with open-ended textual feedback to the system and a paper graph visualizer that surfaces papers relevant to a generated research question [28]. In an effort to help scientists generate more novel and relevant ideas, we build on this prior work with a tool that proposes ideas grounded directly in recombinations of relevant paper facets and supports users in evaluating and improving an idea's novelty."}, {"title": "2.3.1 Research Idea Novelty Evaluation.", "content": "Dean et al. determined novelty, relevance, feasibility, and specificity as the most prominent metrics to constitute a \"good\" idea [10]. We focus on the aspect of novelty that they referred to as originality, which is defined as \"the degree to which the idea is not only rare but is also ingenious, imaginative, or surprising.\" There has been an increase in work on automatic evaluation of research idea novelty [29, 30, 48]. Meanwhile, Nigam et al. introduced Acceleron, a mixed-initiative, LLM-powered tool that uses an agent-based architecture with distinct personas to assess the novelty of a research proposal relative to similar papers [33, 34]. However, Acceleron's evaluation only involved three researchers. Related work has also emerged regarding automatic paper reviews, which often involve assessing the paper's novelty [9, 26]. Sun et al. presented an LLM-powered tool to support novice peer reviewers, which included in-situ knowledge support for novelty evaluation [44]. We build on these works with an evaluation of the mixed-initiative use of SCIDEATOR's idea novelty checker."}, {"title": "3 SYSTEM", "content": "We developed SCIDEATOR with two design goals in mind.\n\u2022 DG1: Help scientists to generate potential research ideas that are relevant to them.\n\u2022 DG2: Help scientists to generate potential research ideas that are novel.\nScientists want to work on research ideas relevant to their interests. To address DG1, our system retrieves facets relevant to the user's input papers that can be mixed and matched to the user's liking in order to form research ideas. The user can also add their own facets. In addition, to enhance the expressiveness of the faceted idea framework consisting of purpose and mechanism facets, we introduce the facet of evaluation, or the method to determine whether or not the proposed solution solves the problem.\nScientists want to work on research ideas that are novel in order to make meaningful contributions to the scientific community. To address DG2, we include features to address functional fixedness and fixation [11, 37]. Prior work illustrates how humans are predisposed to thinking about a problem in only one manner- the first manner to which they were exposed. When attempting to brainstorm solutions for a problem, humans are impeded by this predisposition. SCIDEATOR generates facets of varying distance from its input papers in order to encourage exploration of facets outside the user's filter bubble, and the user can view the scope of facets utilized thus far to encourage more diverse exploration."}, {"title": "4 METHODS", "content": "\u2022 RQ1: Which tool leads to more saved ideas?"}, {"title": "4.1 Research Questions", "content": "\u2022 RQ2: Which tool leads to higher average confidence in the novelty of saved ideas?\n\u2022 RQ3: Which tool leads to higher average excitement for saved ideas?\n\u2022 RQ4: How do researchers utilize each tool for ideation?"}, {"title": "4.2 Participants", "content": "Nineteen computer-science researchers (W: 10, M: 8, NB: 1) were recruited through institutional mailing lists and academic social networks to participate in the study. We compensated participants with a $50 Amazon gift card. Those who participated in a follow-up survey received an additional $10. The participants were from various fields of computer science, most commonly natural language processing (N=8) and human-computer interaction (N=5). They were at various stages of their research career (undergraduate student: 2, master's student: 1, engineer with master's: 1, PhD student: 12, postdoc: 2, professor: 1). Generally, the participants interacted with LLMs often (at least once per... month: 2, week: 5, day: 12)."}, {"title": "4.3 Study Design", "content": "The study was within-subjects and had two conditions. In the treatment-first condition, participants interacted with SCIDEATOR followed by the baseline tool. In the baseline-first condition, the reverse was true. During the treatment portion, participants were provided SCIDEATOR and their starting paper link. During the baseline portion (Figure 8), participants were provided their starting paper link, a link to the scientific search engine Semantic Scholar, and a baseline tool.\nThe baseline tool provided the ability to prompt gpt-40-2024-05-13, the same version of the LLM that we used for most of SCIDEATOR'S functionality. We used OpenAI's Assistants API to create a thread for each participant so that the system would remember and contextualize their conversation. We gave the assistant the name \"Scientific Research Ideator\" and the instructions \"You are ScientistGPT, an intelligent assistant that helps researchers come up with coherent, novel, and useful research ideas.\" We otherwise left it on its default settings, which includes a temperature of 1.0. We also provided a button for participants to generate a more detailed version of their instructions. We included this functionality so that participants would have some support in prompt engineering. This button called Anthropic's"}, {"title": "4.4 Procedure", "content": "Each within-subjects study session was 90 minutes, and the sessions were recorded and transcribed using Google Meet. Participants interacted with SCIDEATOR and the baseline tool in randomized order. For each part of the study (treatment and baseline), the session coordinator provided the participant with a link to the assigned tool as well as a reminder of the broad purpose, broad mechanism, and paper that the participant wanted to use as a starting point for ideation. The coordinator provided the link for the starting paper as well. In the baseline, the coordinator also supplied a link to the scientific search engine Semantic Scholar. In the treatment, the participant entered their starting paper's provided corpus ID in order to load the tool with facets and ideas based on their starting paper. After both the tool and paper links were loaded, the coordinator gave the participant a tutorial describing the assigned tool's features. Next, the coordinator instructed the participant to spend 20 minutes coming up with as many research ideas as possible that they thought were both novel and interesting to think about further, keeping in mind the chosen paper, broad purpose, and broad mechanism as a starting point. The coordinator further explained that every research idea that met these criteria should be saved.\nThe instructions noted that we define a research idea as one or more sentences (no more than 1000 characters) describing a potential research project, and an idea is a statement rather than a question. The instructions also defined the novelty of an idea as \"the degree to which the idea is not only rare but is also ingenious, imaginative, or surprising,\" which is Dean et al.'s definition of idea originality. The coordinator alerted the participant when five minutes remained and reminded participants to save all ideas that they thought were novel and interesting to think about further. The coordinator also explained that, if the participant could not generate three ideas that they found interesting and novel, they should still save three ideas to rate at the end of the five minutes. Once 20 minutes had passed, the participant rated each idea with respect to how confident they were in its novelty and how excited they were to continue thinking about it. Each rating was on a seven-point Likert-type scale, with 7 being most positive. When they were done rating the ideas, the coordinator engaged them in a semi-structured interview for up to 15 minutes, as time permitted. The interview covered the participant's idea generation experience and process of deciding whether or not to save an idea. For the treatment, if there was time, the interview also addressed the participant's thoughts on SCIDEATOR'S facet breakdown and novelty checker."}, {"title": "5 RESULTS", "content": ""}, {"title": "5.1 RQ1: Number of Saved Ideas", "content": "5.1.1 Primary Analysis. To answer RQ1, we obtained the number of ideas that participants saved in the treatment versus baseline. There was an outlier, violating an assumption of our originally planned paired-samples t-test. Therefore, we conducted a Wilcoxon signed-rank test over the participants' paired results as well as a paired-samples t-test of the results without the outlier. We find that participants identify more ideas that they think are novel and interesting to ponder further (i.e., save more ideas) with SCIDEATOR (M=7.58, SD=3.66) than with the baseline tool (M=6.37, SD=4.04) (Figure 9). This difference is statistically significant when the outlier is removed (Paired Samples t-test, t(17)=-2.85, p<.05). The difference is not statistically significant when the outlier is included (Wilcoxon Signed-Rank Test, V=126, p=n.s.). As a reminder, the participants were instructed to save all ideas that they found novel and interesting, but if they could not generate any ideas that were interesting, they were still required to save at least three ideas to rate."}, {"title": "5.1.2 Exploratory Analysis: Learning Effect.", "content": "We observed a strong and interesting learning effect in which the participants who experienced the treatment first went on to save over 96% more ideas in the baseline than their counterparts who experienced the baseline first (treatment-first: M=8.30, SD=4.74; treatment-second: M=4.22, SD=1.30) (Figure 10). Thus, SCIDEATOR may have helped the participants to get into an appropriate mindset for divergent ideation, in which one tries to generate as many potential ideas as possible, as opposed to convergent ideation, in which one tries to determine the single best idea [8, 39]. Out of the 10 participants who saw the treatment first, eight generated multiple clear idea lists using the baseline tool. On the other hand, only 3 of 9 participants who experienced the baseline first generated multiple clear idea lists with the baseline tool. This provides some evidence, though limited, that participants were in a better mindset to generate several ideas after experiencing the treatment. A related discussion comparing the treatment and baseline ideation patterns may be found in Section 5.4.3."}, {"title": "5.1.3 Exploratory Analysis: Juniors vs Seniors.", "content": "We split participants into two groups based on seniority, which we define in terms of the participant's number of first-author and last-author papers. Juniors (N=10) had <= 3 such papers, and seniors (N=9) had >= 5 such papers. We investigated the benefits of SCIDEATOR for each group and found that juniors (M=1.30, SD=3.65) had a greater increase in number of saved ideas than seniors (M=1.11, SD=3.18) when using SCIDEATOR compared to the baseline (Figure 11). This may be due to more openness to diverse ideas, which is further discussed in Section 5.4.1 below."}, {"title": "5.2 RQ2: Confidence in Idea Novelty", "content": "5.2.1 Primary Analysis. To answer RQ2, we calculated the average of each participant's ratings for confidence in the novelty of their saved ideas. We observed no significant difference between participants' average confidence in the novelty of their saved ideas in the treatment (M=5.32, SD=0.84) versus baseline (M=5.55, SD=0.68) (Wilcoxon Signed-Rank Test, V=112, p=n.s.). Thus, SCIDEATOR helped participants to generate more ideas worth saving without significantly decreasing participants' average confidence in the novelty of their saved ideas."}, {"title": "5.2.2 Exploratory Analysis: Novelty Checker.", "content": "The novelty checker was used 116 times during the study, with participants using it six times on average (SD=3). Only two participants, one junior and one senior, did not use the novelty checker at all.\nOn average, we observed that when participants used the novelty checker, they were more likely to save the idea (Figure 12 (a)) suggesting the module did not reduce their confidence in the idea's novelty. Furthermore, seniors used the novelty checker more frequently (M=6.4, SD=4.6) than juniors (M=5.8, SD=3) and saved a higher proportion of these ideas (Figure 12 (b))."}, {"title": "5.2.3 Exploratory Analysis: Newness of Idea to Participant.", "content": "While a participant may be confident in the novelty of a saved idea relative to the literature, they may have thought of it before using the ideation tools in the study. Therefore, we conducted a post-study survey on how new the participants' saved ideas were to them. In particular, we asked available participants to rate their agreement with the statement \"The idea above reminds me of an idea that I thought of before participating in the study.\" The rating was on a seven-point Likert-type scale with seven indicating the strongest agreement. With 13 participant responses, we observed a similar average lack of newness in saved ideas across the two tools (treatment: M=4.29, SD=0.75; baseline: M=4.43, SD=1.26). In both the treatment and baseline, participants thus seem to have saved ideas that were fairly new to them. While SCIDEATOR helped participants to produce more ideas that they thought were novel and interesting to think about further, it did not diminish the average newness of saved ideas to participants.\nWith respect to SCIDEATOR in particular, we found that participants generally felt more confident in an idea's novelty when they had previously thought of the idea before (Figure 13). Participants were both familiar with the idea and confident in its novelty in 50 cases, whereas they were unfamiliar yet confident in the idea's novelty in 33 cases. We also observed that participants frequently used the novelty checker for ideas with which they were already familiar"}, {"title": "5.3 RQ3: Excitement about Idea", "content": "5.3.1 Primary Analysis. To answer RQ3, we conducted the same analysis as for RQ2 but using participants' ratings for excitement to continue thinking about their saved ideas. We found that the treatment and baseline led to similar average levels of excitement about saved ideas, which were fairly high (treatment: M=5.34, SD=0.67; baseline: M=5.50, SD=0.57) (Wilcoxon Signed-Rank Test, V=107, p=n.s.). Thus, SCIDEATOR helped participants to generate more ideas worth saving without significantly decreasing participants' average excitement about their saved ideas."}, {"title": "5.4 RQ4: Ideation Patterns", "content": "To answer RQ4, we analyzed interaction logs of participants' actions while using each tool. We also analyzed participants' semi-structured interview responses using inductive thematic analysis [3]. When participants are quoted, they are named in terms of their unique ID number, seniority group, and tool they were using at the time (e.g., P1-senior-treatment).\n5.4.1 Treatment Ideation: Types of Facets in Saved Ideas. In their interviews, participants by and large found the breakdown of facets into purposes and mechanisms to be useful. Two participants described how the facet breakdown helped them to control the ideas generated, filtering out facets in which they were not interested. P5-junior-treatment observed, \"I like the combination of purpose, mechanism, and evaluation. It kind of helped me filter out those facets that are not relevant enough to kind of save me time.\" On a related note, P9-junior-treatment explained how the facet breakdown helped them to better understand from where the generated ideas came. They commented, \"This tool gives us more interpretability because it is exactly telling you that, okay, it is choosing one facet from every column and trying"}, {"title": "5.4.2 Treatment Ideation: Path Analysis.", "content": "Submitted ideas typically involved longer interaction paths (M=6.47, STD=2.29) compared to unsubmitted ideas (M=3.16, STD=2.81). This implies that saving an idea often required more exploration and interaction (Figure 18 (a)). Junior participants, in particular, engaged more with saved ideas and their facets (M=6.97, STD=2.44) compared to seniors (M=5.88, STD=1.97) (Figure 18 (b)). Juniors appeared to explore the system more thoroughly, interacting with different parts of SCIDEATOR like facet selection, novelty checker, etc., while seniors reached conclusions faster, spending less time with the ideas that they ultimately saved. Notably, there was an outlier, which was an idea that was not submitted but still had a long interaction path. In this case, the senior participant used the idea's facets to generate new ideas, even though it was ultimately not saved.\nFor the ideas that were saved, the number of interactions juniors had with these ideas seemed to correlate with their excitement levels. As shown on the left side of Figure 19, juniors had longer interactions with ideas before saving them, and subsequently rated these saved ideas with higher excitement (5, 6, 7), suggesting a correlation between their level of engagement and excitement. In contrast, seniors exhibited less variation in number of interactions based on excitement ratings. As shown on the right side of Figure 19, juniors engage more with ideas they had thought of before the study, while seniors interact more with unfamiliar ideas."}, {"title": "5.4.3 Comparing Baseline and Treatment Ideation Patterns.", "content": "While a commonly acknowledged benefit of the treatment was its facet breakdown (see Section 5.4.1), the overarching benefit of the baseline that participants cited was its flexibility. A commonly raised advantage of the increased flexibility was that participants could request specific details about how to implement a research idea, alluding to convergent ideation. On the other hand, participants noted that SCIDEATOR felt restrictive when they wanted to take actions such as getting more details on an idea or learning more about a topic. In particular, participants using SCIDEATOR expressed concerns about the feasibility of some ideas and wanted to better understand how they would work. For example, P15-senior-treatment noted, \"A lot of times the tool uses these words like 'character profile analysis' or something like 'disparity analysis.' Saying this is just easier than saying"}, {"title": "6 DISCUSSION", "content": "Grounding mixed-initiative scientific ideation in research-paper facets shows promise for supporting divergent ideation. We introduced SCIDEATOR, a mixed-initiative, LLM-powered tool for scientific ideation through research-paper facet recombination. While prior work established the utility of extracting purpose and mechanism facets from research papers for identifying scientific analogies [4, 21, 36], we are the first to apply this framework to a human-LLM interaction for scientific ideation. Aligned with our goal of supporting divergent ideation [8, 39], results from a within-subjects study show that participants were able to find more ideas that they thought were both novel and interesting to think about further when using SCIDEATOR as opposed to the baseline of access to an LLM and scientific search engine. Through semi-structured interview responses, we observed that participants appreciated being able to mix and match relevant purposes and mechanisms for research idea generation.\nProviding support for mixed-initiative idea novelty assessment may be beneficial for divergent scientific ideation. Participants often found value in having an idea novelty checker that they could activate for ideas of interest. Indeed, participants used the novelty checker an average of 6 times. That said, in their interviews, participants also noted a couple concerns regarding the novelty checker. Two common concerns were that the novelty checker classified ideas as \"novel\" too often and that the set of most related papers was sometimes missing important works. Both of"}, {"title": "7 LIMITATIONS AND FUTURE WORK", "content": "The study has a number of limitations that we should note. First, the participants were only computer-science researchers who are moderately to very familiar with LLMs. Future work may investigate how other scientists might work with a tool like SCIDEATOR. Second, there were only 19 participants. Given the small sample size, future work may be done to validate the results observed here. Third, participants had a limited amount of time (20 minutes) to interact with the tools. A few participants mentioned that they might have tried some actions with SCIDEATOR that they did not get to do had they had more time with it. Future studies may explore how scientists utilize a tool like SCIDEATOR over a longer period of time. Fourth, we compared SCIDEATOR to a strong baseline combining interaction with an LLM and scientific search engine. However, it would be interesting to explore how interaction with SCIDEATOR compares to other tools for scientific ideation such as CoQuest [28]. Fifth, due to latency constraints, our Idea Novelty Checker module utilized only 10 relevant papers to assess the novelty of an idea during the study. Future work could look into how scientists"}]}