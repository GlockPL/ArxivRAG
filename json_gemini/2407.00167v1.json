{"title": "Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach", "authors": ["Sai Krishna Revanth Vuruma", "Dezhi Wu", "Saborny Sen Gupta", "Lucas Aust", "Valerie Lookingbill", "Wyatt Bellamy", "Yang Ren", "Erin Kasson", "Li-Shiun Chen", "Patricia Cavazos-Rehg", "Dian Hu", "Ming Huang"], "abstract": "In recent years, the United States has witnessed a significant surge in the popularity of vaping or e-cigarette use, leading to a notable rise in cases of e-cigarette and vaping use-associated lung injury (EVALI) that caused hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting the urgency to comprehend vaping behaviors and develop effective strategies for cessation. Due to the ubiquity of social media platforms, over 4.7 billion users worldwide use them for connectivity, communications, news, and entertainment with a significant portion of the discourse related to health, thereby establishing social media data as an invaluable organic data resource for public health research. In this study, we extracted a sample dataset from one vaping sub-community on Reddit to analyze users' quit-vaping intentions. Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit vaping intention detection, this study compares the outcomes of this model against layman and clinical expert annotations. Using different prompting strategies such as zero-shot, one-shot, few-shot and chain-of-thought prompting, we developed 8 prompts with varying levels of detail to explain the task to GPT-4 and also evaluated the performance of the strategies against each other. These preliminary findings emphasize the potential of GPT-4 in social media data analysis, especially in identifying users' subtle intentions that may elude human detection.", "sections": [{"title": "1 Introduction", "content": "Studies indicate that epidemic levels of consumption was observed among adolescents and young adults during the last decade, with a massive increase in sale and usage of e-cigarettes and other disposable vaping products [5, 24] leading to the EVALI outbreak in 2019. With the nation's youth emerging as the high risk population, research suggests that many e-cigarette users are unaware of the potential dangers of vaping such as Vape Dependence [23] and Stealth-vaping [30], with vape frequency directly associated with perceived satisfaction while being indirectly associated with perceived danger [13]. Vaping products contain cancer-causing agents, toxins, heavy metals, and other harmful particles that are substantially linked to lung, heart, and brain damage [18]. Recent efforts towards educating the young populace about the negative impacts of vaping have resulted in a large number of e-cigarette users intending to quit vaping [25], with about 45% of young vapers reporting interest in quitting, while 25% attempted to quit in 2020-2021 [22]. The goal is to now identify these users and help them quit vaping by proving the necessary resources to support them along the way.\nContemporary research studies have leveraged popular social media platforms such as Twitter and Reddit for public surveillance of health topics. Approximately, more than 70% of people use at least one social media platform and the number of new users in any of these popular platforms is increasing everyday especially among users aged 18-29 [14]. The utilization of social media data emerges as a nascent source of public health information, offering novel insights into public health trends and enhancing the capabilities of public health surveillance.\nPrevious vaping studies such as [10, 29] used topic modeling and sentiment analysis along with clinical insights on social media data to show users on these platforms might benefit from digital intervention programs for vaping cessation. For clinicians to potentially employ proactive outreach strategies to engage vaping patients for education and treatment on social media platforms, it is imperative to conduct further research into the analysis of vaping discourse on these platforms [12], aiming to develop Artificial Intelligence (AI)-based approaches to more efficiently and accurately identify these users' vaping behaviors and develop targeted vaping prevention and intervention programs for the youth population.\nIn this preliminary study, we aim to employ and evaluate OpenAI's GPT-4 model against layman and clinical expert annotators on a sentence-level annotation task to identify vaping cessation interests among Reddit users. Our preliminary findings indicate that the GPT-4 model performs impressively, but it still has a ways to go before replacing human annotators."}, {"title": "2 Literature Review", "content": "Interpretation of natural language data extracted from social media platforms requires deep contextual knowledge and understanding, lack of which can lead to incorrect labeling and annotations [16]. Manual annotations of these texts"}, {"title": "3 Methodology", "content": "The workflow adopted for this study is illustrated in Figure 5. Each stage of the pipeline will be discussed in detail in the respective subsections. First the data is extracted from Reddit and cleaned, then it is sent to the annotators: layman, expert and the GPT-4 model for annotation. The performance of all three annotators is compared at the end to draw conclusions. With the expert annotated dataset as the ground truth, we will use two types of metrics: qualitative and quantitative for formulating the results."}, {"title": "3.1 Data Collection & Preparation", "content": "In the popular social media platform Reddit, r/Quit Vaping is the largest subreddit dedicated to help users quit vaping and other tobacco products with around 40,000 subscribers. Using Reddit's Async PRAW API, we extracted a total of"}, {"title": "3.2 Human Annotation", "content": "Layman Annotation Two layman annotators were tasked with labeling the cleaned sentences as 'YES' if the speaker explicitly mentions their idea, desire, decision, plan, or action to quit vaping. And to label them as 'NO' otherwise. For a sentence to be labeled as 'YES', there must be a clear indication that the speaker intends to quit vaping. Discrepancies (n=28) were resolved internally with an Inter-coder Reliability score (ICR) of 0.78.\nExpert Annotation Two clinical experts from the School of Medicine, Washington University were asked to perform the expert annotation by following the same guidelines mentioned above. The coders independently reviewed the dataset and coded all the sentences. The second coder resolved discrepancies (n=22)."}, {"title": "3.3 GPT-4 Annotation", "content": "Interaction with the GPT-4 model can be done via prompts that must be carefully constructed to get the best performance out of the model. Each prompt let's you assign a 'role' which indicates who the sender of that message (prompt) is. Taking inspiration from the prompt templates used in [8,31] we devised the prompts for our study using approaches like zero-shot, one-shot, few-shot and chain-of-thought prompting.\nGiven a sentence, the model was tasked to return a label, a numerical confidence score and its reasoning for choosing that label for that sentence. Figure 6 shows the system prompt that we used to introduce the context of the task to the GPT-4 model, while Figure 1 contains a sample user prompt that passes the input data along with instructions on how the model should respond.\nAs shown in Table 1, we developed 8 prompts using different prompting strategies plus another variable called 'detail'. The low detail prompts (P1-P4) have the structure shown in Figure 1a with the question phrased using simpler language, i.e., \"Does the speaker intend to quit vaping?\", while the high detail prompts (P5-P8) use a more directed question as shown in Figure 1b. The one-shot and few-shot variants include examples in the user prompt, while the chain-of-thought prompts include the phrase \"think step-by-step\" in the question."}, {"title": "4 Results", "content": "Figure 2 shows the class distribution after annotation by all three annotators: layman, expert and GPT-4. Here, P1-P8 denote which prompt was sent to the GPT-4 model, while Layman and Expert denote which human annotator annotated the records. From the figure, we can infer that while both the human annotators were more conservative in assigning the YES label to a sentence, GPT-4 was more sensitive across all 8 prompts. Another key observation is that the model sensitivity goes down with increased detail in the prompt, while the number of examples provided did not have a significant impact.\nConsidering the clinical expert annotated dataset as the ground truth or baseline, we perform two types of evaluation to compare the performance of GPT-4 against layman annotators using qualitative and quantitative metrics. In addition, we also make comparisons between the 8 prompts that were used."}, {"title": "4.1 Qualitative Evaluation", "content": "We calculated the Cohen's Kappa and Jaccard's similarity scores for the layman and GPT-4 annotated datasets for each label individually. As shown in Figure 3, the layman annotators' labels were much closer to those of the experts with a Jaccard Similarity score of 0.95 and Cohen's Kappa of 0.8. In contrast, GPT-4 had weak agreement with the expert annotators with the best performing prompt getting scores of 0.71 and 0.22 respectively.\nComparing the individual prompts, all four high detail prompts (P5-P8) scored higher on both similarity metrics than their low detail counterparts (P1-P4)."}, {"title": "4.2 Quantitative Evaluation", "content": "For quantitative evaluation, we used standard classification metrics namely accuracy, precision, recall and f1 score to compare the performance of each annotator. From Figure 4, we can infer that the layman annotators' annotations were closest to the ground truth with an overall F1 score of 0.97, while the best performing prompt for GPT-4 had an overall F1 score of 0.84. Breaking down the classification label-wise, although both annotators made false annotations (predictions), GPT-4 predicted more False Positives (FPs) than the layman annotator resulting in the low precision scores seen in Figure 4a."}, {"title": "4.3 Discussion", "content": "Although the results from GPT-4 aren't up to the mark of the layman or expert annotators, there are positives that we can build on. As shown in Figure 1, along with its prediction for each sentence, GPT-4 is tasked to return a numerical confidence score and its reasoning for that prediction. Observing the annotated dataset in the context of these two columns provides some valuable insights. In addition, the prompting strategy employed has also affected model performance as discussed in the previous sections.\nPrompting Strategy From our earlier experiments, we noticed that GPT-4 performs best when it has more data to work with and this is supported in the fact that all of the high detail prompts (P5-P8) that we employed did better than the low detail variants (P1-P4). However, too much data can also hurt the model as seen in Figure 4a where the one-shot (P7) and few-shot (P8) prompts have a better recall but a similar F1 score to the zero-shot prompts (P5, P6). Chain-of-Thought prompting is known to improve LLM performance on analytical tasks by asking the model to think step-by-step [28]. Given that our task was sentence-level, the model didn't have enough context to fully exploit the benefits of this prompting strategy.\nModel Confidence & Reasoning Whenever the model is not confident about the context of the sentence, it makes certain assumptions to arrive at a conclusion (or annotation in this case). And this is reflected in the confidence score attached with that annotation plus the reasoning the model provides. For example, in Table 2 we can see how the model assigns a low confidence score while making assumptions about the context of a sentence and also mentioning the same in the reasoning. The rich data from these two columns can be used to optimize the performance further.\nError Analysis Evaluating the performance of GPT-4 on the best performing prompt so far, i.e., P5 (high detail, zero-shot), the model predicted 149 false positives which greatly decreased its precision and f1 score. Upon careful observation, of the sentences that GPT-4 falsely predicted as YES instances, the speaker:\nHas Already Quit Vaping or\nIs talking about Negative Health Outcomes, side effects of vaping or\nIs planning on Reducing Vaping\nThese sub-categories don't fit into the hypothesis of this study for identifying users that are actively trying to quit vaping. However, this presents an interesting dynamic of the discourse on vaping and quitting in general. Users have different quitting behaviors some choose to quit outright while others may prefer a more gradual approach."}, {"title": "5 Conclusion", "content": "Through this preliminary study, we compared the performance of OpenAI's GPT-4 model against layman and clinical experts on a sentence-level annotation task to identify users that are trying to quit vaping on Reddit. We found that although GPT-4's performance doesn't match that of either human annotator, the results are promising.\nIn the future, we plan to expand this study by building a larger and more diverse dataset with posts and comments from popular vaping subreddits and randmoized data from unrelated subreddits to make the model more robust. As mentioned in the Discussion section, different users have different quitting behaviors. Expanding the task to a multi-label or multi-layer classification will provide more granular insights and help identify users that are at different stages of their quitting journey. In addition, to address hallucinations by the GPT-4 model, post-level annotation can be used to give more context to the model through in-context learning and thus improve its performance."}, {"title": "Appendix", "content": ""}]}