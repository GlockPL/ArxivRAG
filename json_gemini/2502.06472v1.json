{"title": "KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment", "authors": ["Yuxing Lu", "Jinzhuo Wang"], "abstract": "Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical for modern AI systems, but manual curation struggles to scale with the rapid growth of scientific literature. This paper presents KARMA, a novel framework employing multi-agent large language models (LLMs) to automate KG enrichment through structured analysis of unstructured text. Our approach employs nine collaborative agents, spanning entity discovery, relation extraction, schema alignment, and conflict resolution that iteratively parse documents, verify extracted knowledge, and integrate it into existing graph structures while adhering to domain-specific schema. Experiments on 1,200 PubMed articles from three different domains demonstrate the effectiveness of KARMA in knowledge graph enrichment, with the identification of up to 38,230 new entities while achieving 83.1% LLM-verified correctness and reducing conflict edges by 18.6% through multi-layer assessments.", "sections": [{"title": "1 Introduction", "content": "Knowledge graphs (KGs) are essential for structuring and reasoning over complex information across diverse fields (Hogan et al., 2021; Ji et al., 2021; Lu et al., 2025). By encoding entities and their relationships in machine-readable formats, widely adopted KGs such as Wikidata (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014) and DBpedia (Lehmann and Kleber, 2015) have become foundational to both industry and academic research. Yet, the exponential growth of scientific literature, with over 7 million articles published annually (Bornmann et al., 2021), exposes a significant bottleneck: the widening gap between unstructured knowledge in texts and its structured representation in KGs.\nThe challenge of enriching KGs becomes even more apparent in fields with complex and specialized terminology, such as healthcare, finance, or autonomous systems. Traditional approaches to KG enrichment, such as manual curation, are reliable but unsustainable at scale. Automated methods based on conventional natural language processing (NLP) techniques often struggle to handle domain-specific terminology and context-dependent relationships found in scientific and technical texts (Nasar et al., 2018). Moreover, extracting and integrating knowledge into existing KGs requires robust mechanisms for schema alignment, consistency, and conflict resolution (Euzenat et al., 2007). In high-stakes applications, the costs of inaccuracies in these systems can be severe.\nRecent advances in large language models (LLMs) (GLM et al., 2024; Achiam et al., 2023; Liu et al., 2024) have demonstrated remarkable improvements in contextual understanding and reasoning (Wu et al., 2023). Building on these advances, the research community has increasingly explored multi-agent systems, where several specialized agents work in concert to tackle complex tasks (Guo et al., 2024). These systems harness the strengths of individual agents, each optimized for a particular subtask, and enable cross-agent verification and iterative refinement of outputs. Such multi-agent frameworks have shown promise in areas ranging from decision-making to structured data extraction (Fourney et al., 2024; Lu et al., 2024), offering robustness through redundancy and collaboration. However, directly applying these systems to KG enrichment remains challenging due to issues like domain adaptation, systematic verification requirements (Irving et al., 2018), and"}, {"title": "2 Related Work", "content": "The quest to transform unstructured text into structured knowledge has evolved through three generations of technical paradigms. First-generation systems (1990s-2010s) like WordNet (Miller, 1995) and ConceptNet (Liu and Singh, 2004) relied on hand-crafted rules and shallow linguistic patterns, achieving high precision at the cost of limited recall and domain specificity. The neural revolution (2010s-2022) introduced learned representations through architectures like BioBERT (Lee et al., 2020) and SapBERT (Liu et al., 2021), which achieved improvements on biomedical NER through domain-adaptive pretraining. However, these methods require expensive supervised tuning (3-5k labeled examples per relation type (Zhang et al., 2023)) and fail to generalize beyond predefined schema, which is a critical limitation when processing novel scientific discoveries. The current LLM-powered generation (2022-present) attempts to overcome schema rigidity through instruction tuning (Pan et al., 2024; Zhu et al., 2024). This progression reveals an unresolved tension: neural"}, {"title": "2.1 Knowledge Graph Construction", "content": "The complexity of integrating outputs into heterogeneous knowledge structures.\nIn this paper, we propose KARMA\u00b9, a novel multi-agent framework that harnesses LLMs through a collaborative system of specialized agents (Figure 1). Each agent focuses on distinct tasks in the KG enrichment pipeline. Our framework offers three key innovations. First, the multi-agent architecture enables cross-agent verification, enhancing the reliability of extracted knowledge. For instance, Relationship Extraction Agents validate candidate entities against Schema Alignment outputs, while Conflict Resolution Agents resolve contradictions through LLM-based debate mechanisms. Second, domain-adaptive prompting strategies allow the system to handle specialized contexts while preserving accuracy. Third, the modular design ensures extensibility and supports dynamic updates as new entities or relationships emerge. Through proof-of-concept experiments on datasets from three distinct domains, we demonstrate that KARMA can efficiently extract high-quality knowledge from unstructured texts, substantially enriching existing knowledge graphs with both precision and scalability."}, {"title": "2.2 Multi-Agent Systems", "content": "Early multi-agent systems focused on distributing subtasks across specialized modules, such as separate agents for named entity recognition and relation extraction (Carvalho et al., 1998). These systems relied on predefined pipelines and handcrafted coordination rules, limiting adaptability to new domains. Recent advances in LLMs have enabled more dynamic architectures and rediscovered multi-agent collaboration as a mechanism for enhancing LLM reliability (Talebirad and Nadiri, 2023; Lu et al., 2024). Building on classic blackboard architectures, contemporary systems like AutoGen (Wu et al., 2023) show that task decomposition with specialized agents reduces hallucination compared to monolithic models. For knowledge graph construction, (Liang et al., 2023) demonstrated that task decomposition across specialized agents (e.g., entity linker, relation validator) improves schema alignment on Wikidata benchmarks. maintaining linear time complexity relative to input text length.\nKARMA synthesizes insights from these research threads while introducing key innovations: (1) a modular, multi-agent architecture that allows for specialized handling of complex tasks in knowledge graph enrichment, (2) domain-adaptive prompting strategies that enable more accurate extraction across diverse scientific fields, (3) LLM-based verification mechanisms that mitigate issues such as hallucination and schema inconsistency."}, {"title": "3 Methodology", "content": "In this section, we introduce KARMA, a hierarchical multi-agent system (see Figure 2) that leverages specialized LLMs to perform end-to-end KG enrichment. Our approach decomposes the overall task into modular sub-tasks, ranging from document ingestion to final KG integration, each handled by an independent LLM-based agent. We first present a formal problem formulation and then detail the design and mathematical foundations of each agent within the pipeline."}, {"title": "3.1 Problem Formulation", "content": "Let $G = (V, E)$ denote an existing KG, where V is the set of entities (e.g., genes, diseases, drugs) and E the set of directed edges representing relationships. Each relationship is defined as a triplet $t = (e_h,r,e_t)$ with $e_h, e_t \\in V$ and r specifying the relation type (e.g., treats, causes). We are provided with a corpus of unstructured publications $P = P_1,..., P_n$. The objective is to automatically extract novel triplets $t \\notin E$ from each document $p_i$ and integrate them into G to form an augmented graph $G_{new}$.\n$G_{new} = G \\cup \\bigcup_{i=1}^{n} K_i$, where $K_i$ = Extract($p_i$),  (1)\nwhere Extract($p_i$) is the set of valid triplets obtained from publication $p_i$. To maintain consistency and accuracy, each candidate triplet is evaluated by an LLM-based verifier prior to integration."}, {"title": "3.2 System Overview", "content": "KARMA comprises multiple LLM-based agents operating in parallel under the orchestration of a Central Controller Agent (CCA). Each agent uses specialized prompts, hyper-parameters, and domain knowledge to optimize its performance. In KARMA, we define a set of agents (A):\n\u2022 Ingestion Agents (IA): Retrieve and normalize input documents (A.3).\n\u2022 Reader Agents (RA): Parse and segment relevant text sections (A.4).\n\u2022 Summarizer Agents (SA): Condense relevant sections into shorter domain-specific summaries (A.5).\n\u2022 Entity Extraction Agents (EEA): Identify and normalize topic-related entities (A.6).\n\u2022 Relationship Extraction Agents (REA): Infer relationships between entities (A.7).\n\u2022 Schema Alignment Agents (SAA): Align entities and relations to KG schemas (A.8).\n\u2022 Conflict Resolution Agents (CRA): Detect and resolve logical inconsistencies with existing knowledge (A.9).\n\u2022 Evaluator Agents (EA): Aggregate multiple verification signals and decide on final integration (A.10,A.11,A.12)."}, {"title": "3.3 Central Controller Agent (CCA)", "content": "The CCA orchestrates task scheduling, prioritization, and resource allocation among the agents. We formalize its operation in two steps:\nTask Prioritization. The CCA manages the scheduling and load balancing of tasks (document ingestion, entity extraction, etc.) across agents. Let T denote a task and s the current state of the system (e.g., available agents, data backlog). We employ an LLM-based scoring function LLMctl(T, s) to compute a base utility:\n$U(t,s) = \\text{LLMctl} (T, S),\\quad$(2)\nwhere specialized prompts define how the LLM estimates the \"value\" of completing task \u315c next. Inspired by multi-armed bandits, we incorporate an exploration term:\n$P(T|S) = U(\u03c4,\u03c2) + \u03b1 \\sqrt{\\frac{\\ln(t)}{\u03b1\\cdot V1+n}},\\quad$(3)\nwhere t is the total number of tasks completed thus far, n, is the number of times 7 has been attempted, and a is an exploration parameter balancing exploitation (high U(t, s)) against exploring less attempted tasks. Each 7 is inserted into a priority queue Q using a combined metric:\n$\\pi(\\tau) = \u03c9_1 P(T|S) + W_2 \\text{urge}(\\tau) + W_3 \\text{cost}(\\tau),$(4)\nwhere urge(t) and cost(7) are LLM-inferred signals that weigh deadline constraints and compute load, respectively.\nResource Allocation. Given a set of agents A = {$a_1,...,a_m$}, the CCA assigns tasks to agents while respecting their capacity limits. Each agent $a_j$ can handle up to $k_j$ units of resources, and each task \u03c4 requires \u03c1(\u03c4) units of resources. The goal is to minimize the total weighted resource cost $\\pi(\\tau)\u03c1(\\tau)$, where $\\pi(\\tau)$ represents the priority of task T. Let $X_{\\tau,j}$ be a binary variable:\n$X_{\\tau,j} = \\begin{cases} 1 & \\text{if task is assigned to agent } a_j,\\ 0 & \\text{otherwise}.\\end{cases}$   (5)\nThe optimization problem is:\n$\\min \\Sigma \u03b1_{\\tau,j} \\cdot \\pi(\\tau)\u03c1(\\tau), \\quad$(6)\nThis ensures high-priority tasks (with larger $\\pi(\\tau)$) are prioritized for assignment, while workloads are balanced across agents."}, {"title": "3.4 Ingestion Agents (IA)", "content": "The Ingestion Agents are LLM-based modules specialized in document retrieval, format normalization, and metadata extraction. Let $p_i$ be a raw publication. IA includes:\n$IA(p_i) = (normalize(p_i), metadata(p_i)),\\quad$(7)\nwhere normalize($p_i$) uses an LLM prompt Pingest to handle complexities like OCR errors, or structural inconsistencies. The output is a standardized textual representation plus key metadata (journal, date, authors, etc.). This representation is then placed into a data queue for Reader Agents."}, {"title": "3.5 Reader Agents (RA)", "content": "Reader Agents parse normalized text into coherent segments (abstract, methods, results, ect.) and filter out irrelevant content. Let p' be the normalized document. RA splits p into {$s_1, s_2,..., s_m$;}. Each segment $s_j$ is assigned a relevance score R($s_j$) by:\n$R(s_j) = \\text{LLMreader} (s_j, G),\\quad$(8)\nwhere LLMreader is prompted with domain-specific instructions to assess the segment's biomedical significance relative to the current KG G. RA discards segments if R($s_j$) < d, where d is a domain-calibrated threshold. Surviving segments are passed along to Summarizer Agents."}, {"title": "3.6 Summarizer Agents (SA)", "content": "To reduce computational overhead, each RA segment $s_j$ is condensed by Summarizer Agents into a concise representation $u_j$. Formally, we define:\n$u_j = \\text{LLMsumm} (s_j, P_{\\text{summ}}),\\quad$(9)\nwhere $P_{\\text{summ}}$ is a prompt for LLM to retain critical entities, relations, and domain-specific terms. This summarization ensures Entity Extraction Agents and Relationship Extraction Agents receive textual inputs that are both high-signal and low-noise."}, {"title": "3.7 Entity Extraction Agents (EEA)", "content": "LLM-Based NER. Each summary $u_j$ is routed to an LLM-based NER pipeline that identifies mentions of topic-related entities. Define:\n$E(u_j) = \\text{LLM}_E (U_j,P_E) \\qquad D_E,  (10)\nwhere LLME is an specialized entity-extraction LLM with prompt $P_E$, and DE indicates a dictionary/ontology-based filtering. This step filters out false positives and normalizes entity mentions to canonical forms (e.g., mapping \"acetylsalicylic acid\" to \"Aspirin\u201d)."}, {"title": "Entity Normalization.", "content": "Let e be a raw entity mentioned from E($u_j$). We map e to a normalized entity \u00ea \u2208 V by minimizing a distance function in a joint embedding space:\n$\\hat{e} = \\arg \\min_{v\\in V} d(\u03c6(e), \u03c8(v)),  (11)\nwhere \u03c6 maps textual mentions to embeddings (using, e.g., a BERT-based model), and \u03c8 maps known KG entities to the same embedding space. The distance metric d(\u00b7, \u00b7) can be cosine distance or a domain-specific measure. Any entity with $\\min_{v\\in v} d(\u03c6(e), \u03c8(v)) > p$ is flagged as new and added to the set of candidate vertices V+."}, {"title": "3.8 Relationship Extraction Agents (REA)", "content": "After entity normalization, each pair (\u00ea\u00bf, \u00eaj) within summary uj is fed to an LLM-based classifier:\n$p(r | \\hat{e_i}, \\hat{e_j}, u_j) = LLM_R(\\hat{e_i}, \\hat{e_j}, u_j, P_R), (12)\nwhere p(r) is the probability distribution over possible relationshipsr \u2208 {r1,...,rk}. The prompt PR instructs the LLM to focus on domain relationship candidates. We select any relationship r for which $p(r|\\hat{e_i}, \\hat{e_j}) > \u03b8_r$ and form a triplet (\u00eai, r, \u00eaj). In certain passages, more than one relationship can be implied. We allow multi-label predictions by setting an indicator variable:\n$I(r) = I\\{p(r | \\hat{e_i}, \\hat{e_j}) \u2265 \u03b8_r\\}, (13)\nHence, R($u_j$) is the set of triplets (\u00eai, r, \u00eaj) such that I(r) = 1."}, {"title": "3.9 Schema Alignment Agents (SAA)", "content": "If a new entity v \u2208 V+ or a new relation r does not match existing KG types, the Schema Alignment Agent performs a domain-specific classification. For entities, the SAA solves:\nTET\nT* = arg max LLMSAA (V, T, Palign), (14)\nwhere T is the set of valid entity types (Disease, Drug, Gene, etc.), and LLMSAA estimates the probability that v belongs to type \u03c4. A similar approach is used for mapping new relation r to known KG relation types. If no suitable match exists, the SAA flags v or r as candidate additions for review."}, {"title": "3.10 Conflict Resolution Agents (CRA)", "content": "New triplets can contradict previously established relationships. Let t = (\u00ean, r, \u00eat) be a newly extracted triplet, and let t' = (\u00ean, r', \u00eat) be a conflicting triplet in G if r is logically incompatible with r'. We define:\n$conflict(t, G) = \\begin{cases}\n1, & \\text{if } t' \\text{ that contradicts t,}\n0, & \\text{otherwise}.\n\\end{cases} \t$(15)\nThe CRA uses an LLM-based debate prompt:\nLLMCRA (t, t') \u2192 {Agree, Contradict}, (16)\nIf LLMCRA yields Contradict, t is then discarded or queued for manual expert review, depending on the system's confidence."}, {"title": "3.11 Evaluator Agents (EA)", "content": "Finally, the Evaluator Agents aggregate multiple verification signals and compute global confidence C(t), clarity Cl(t), and relevance R(t) for each triplet t.\nConfidence: C(t) = \u03c3 ($\u03a3\u03b1_i v_i(t)$), (17)\nClarity: Cl(t) = \u03c3 ($\u03a3\u03b2_j c_j (t)$), (18)\nRelevance: R(t) = \u03c3 ($\u03a3_k r_k(t)$), (19)\nwhere \u03c3(x) = $\\frac{1}{1+e^{-x}}$ and {$\u03b1_i, \u03b2_j, k$} reflect the trustworthiness of each verification source, and vi, cj, rk are verification signals for confidence, clarity, and relevance respectively. We finalize t for integration using the mean score:\n$integrate(t) = \\begin{cases}\n1, & \\text{if } \\frac{C(t)+Cl(t)+R(t)}{3} > \u0398\n0, & \\text{otherwise}.\n\\end{cases} \t$(20)\nAltogether, this multi-agent pipeline, fully powered by specialized LLMs in each stage, enables robust, scalable, and accurate enrichment of large-scale KG. Future extensions can easily incorporate new domain ontologies, additional specialized agents, or updated LLM prompts as tasks continues to evolve."}, {"title": "4 Experimental Setup", "content": "This section presents a comprehensive proof-of-concept evaluation settings of the proposed KARMA framework. Unlike conventional NLP tasks that rely on a gold-standard dataset of biomedical entities and relationships, our evaluation adopts a multi-faceted approach. We integrate LLM-based verification with specialized graph-level metrics to assess the quality of the generated knowledge graph. The evaluation spans genomics, proteomics, and metabolomics, showcasing KARMA's adaptability across diverse biomedical domains."}, {"title": "4.1 Data Collection", "content": "We curate scientific publications from PubMed (White, 2020) across three primary domains:\nGenomics Corpus: This collection includes 720 papers focused on gene variants, regulatory elements, and sequencing studies.\nProteomics Corpus: This collection includes 360 papers related to protein structures, functions, and protein-interaction networks.\nMetabolomics Corpus: This collection includes 120 papers discussing metabolic pathways, metabolite profiling, and clinical applications.\nAll articles are stored in PDF format and processed by the Ingestion Agent within KARMA."}, {"title": "4.2 LLM Backbones", "content": "We evaluate three general-purpose LLMs as the backbone for KARMA's multi-agent knowledge graph enrichment pipeline using their APIs.\nGLM-4 (GLM et al., 2024): An open-source 9B-parameter model, achieving 72.4 on the MMLU NLP benchmark.\nGPT-40 (Achiam et al., 2023): A proprietary multimodal model optimized through RLHF. It has demonstrated strong adaptability in scientific knowledge extraction and concept grounding (Dagdelen et al., 2024).\nDeepSeek-v3 (Liu et al., 2024): An open-source 37-billion-activated-parameter mixture-of-experts (MoE) model with strong focus on STEM domains.\nEach KARMA agent (e.g., Reader, Summarizer, Extractor) shares the same LLM backbone per experiment. All LLM-based evaluations employ DeepSeek-v3. Prompting strategies, detailed in Appendix A, are minimally modified to ensure comparability across LLMs and domains. We analyze variations in the final constructed knowledge graph based on different LLM backbones."}, {"title": "4.3 Metrics", "content": "Even in the absence of a gold-standard reference, we employ a multi-faceted evaluation procedure for evaluation. Specifically, we measure:\nCore Metrics. We use the following structural and LLM-based indicators to evaluate the newly added triples:\nAverage Confidence Mcon: Mean of the confidence scores across all new triples.\nAverage Clarity Mcla: Mean of the clarity scores, indicating how unambiguous or direct each relation is."}, {"title": "Average Relevance MRel:", "content": "Mean of the relevance scores, reflecting domain significance.\nGraph Statistics. Structural properties of the augmented knowledge graph (KG) are quantified using:\nCoverage Gain Acov: Number of newly introduced entities not previously in the knowledge graph.\nConnectivity Gain Acon: Net increase in node degrees (summed over existing entities).\nQuality Indicators. To assess reliability and usability, we compute:\nConflict Ratio RCR: Fraction of newly extracted edges removed by the CONFLICTRESOLUTIONAGENT due to internal or external contradictions.\nLLM-based Correctness RLC: A hold-out LLM judges each new triple (head, r, tail) as likely correct, uncertain, likely incorrect. The\n#(likely correct)\ncorrectness rate is: RLC = #(all new triples).\nQuestion-Answer Coherence CQA: For a curated set of domain-specific questions answerable via KG traversal, CQA is computed as the fraction of KG-derived answers deemed plausible.\nThese complementary metrics provide insights into the structural integrity, internal consistency, correctness, and practical utility of the enriched knowledge graph."}, {"title": "5 Results", "content": "Our comprehensive evaluation (Table 1, with examples in Appendix B.1,B.2,B.3) demonstrates that KARMA significantly extends domain-specific knowledge graphs through its multi-agent architecture. Four key findings emerge: (1) The framework demonstrates superior performance compared to the GLM-4-based single-agent approach, which extracts all triples in a single generation, (2) The framework exhibits varying performance across distinct domains; it identifies the most entities in prevalent fields such as genomics (53.1/article), achieving 3.6\u00d7 higher coverage gain (ACov) per article than metabolomics (14.6/article); (3) LLM backbone selection substantially impacts KG quality, with DeepSeek-v3 achieving superior performance on 17/24 (71%) metrics across domains; (4) Evaluating knowledge and resolving conflicts automatically can enhance the quality of the extracted knowledge graph, improving LLM-based accuracy by 4.6%-14.4%."}, {"title": "5.2 Domain-Level Observations.", "content": "The genomics domain (720 papers) exhibits the most pronounced model differentiation. DeepSeek-v3 achieves Acov = 38,230 while maintaining a competitive correctness score RLC = 0.831, only 5.6% below GPT-4o's peak. This suggests that MoE architectures can balance recall and precision in large-scale extraction.\nWith 360 papers, proteomics reveals balanced gains: DeepSeek-v3 leads in both core metrics (Mcon = 0.845) and structural gains (Acon = 1.468), while GLM-4 achieves peak QA coherence (CQA = 0.617). The 19.1% higher \u2206\u03c4\u03bf\u03c5 for DeepSeek-v3 versus GPT-40 indicates greater sensitivity to protein interaction nuances.\nDespite the smallest corpus (120 papers), GLM-4 delivers superior clarity (Mcla = 0.790) and GPT-40 excels in correctness (RLC = 0.683). However, DeepSeek-v3's Acon = 1,752 is 127% higher than GPT-40, demonstrates unique capability to extrapolate metabolic pathways from limited data."}, {"title": "5.3 Analysis of LLM Backbones", "content": "Our comparison reveals strengths of different backbones: DeepSeek-v3 drives unparalleled coverage gains, outpacing GPT-40 by 3.9\u00d7 in genomics and 2.3x in metabolomics while maintaining competitive correctness (RLC = 0.831 vs GPT-40's 0.880 in genomics). This contrasts with GPT-40's precision-first profile, where it achieves peak RLC scores (0.880 genomics, 0.740 proteomics) but yields 41% lower connectivity gains than DeepSeek-v3, reflecting underutilized implicit relationships. GLM-4, though smaller (10B parameters), demonstrates domain-specific prowess: its biomedical tuning delivers best-in-class metabolomics clarity (Mcla = 0.762) and proteomics QA coherence (CQA = 0.617), while its conflict ratio (RCR = 0.188) remains competitive despite lower parameter count. The trade-offs (DeepSeek-v3's coverage balance for correctness, GPT-40's precision sacrifice for completeness, GLM-4's niche adaptation) underscore why KARMA's multi-agent framework strategically decouples extraction, validation, and can utilize the strengths of each backbone. Different backbones also lead to variations in the distribution of key evaluation metrics (Figure B.1,\u0392.2,\u0392.3)."}, {"title": "5.4 Cost Analysis", "content": "The evaluation of computational costs (Figure 3) demonstrates distinct trade-offs in token usage and processing time across different domains. The variations in article lengths and information density naturally lead to differences in token consumption and processing times. Notably, genomics shows higher completion token distributions (mean = 550.64, std = 232.92), explaining KARMA'S higher Acov in this domain. Meanwhile, proteomics exhibits broader processing time distributions (mean = 96.58, std = 46.90), which correlates with its stronger performance in knowledge quality metrics (RLC and CQA), suggesting that longer processing times contribute to more thorough relationship analysis and validation."}, {"title": "5.5 Ablation Study", "content": "To better quantify the contributions of each specialized agent in KARMA, we conduct an ablation study (Table 2) by systematically removing or replacing selected agents and measure the resulting performance across the three domains. Specifically, we evaluate:\n\u2022 KARMA-Full: All agents active, including Summarizer, Conflict Resolution, and Evaluator modules.\n\u2022 w/o Summarizer: Bypasses the Summarizer Agents, passing all text directly from Reader Agents to Entity and Relationship Extraction.\n\u2022 w/o Conflict Resolution: Disables the Conflict Resolution Agent, allowing potentially contradictory edges into the final graph.\n\u2022 w/o Evaluator: Omits the final confidence, clarity, and relevance evaluation and aggregation, integrating relationships without filtering.\nWe conduct these ablations using the same LLM backbone (DeepSeek-v3 in our experiments) for consistency. Table 2 summarizes the impact on evaluation metrics (RLC, CQA) for each domain. The ablation study highlights the importance of each agent in KARMA's performance. Removing the Summarizer Agent produce much more entities and triples, but reduces accuracy (CQA drop 22.9% (0.612 \u2192 0.472) in genomics) and coherence (RLC drop 18.2% (0.772 \u2192 0.632) in proteomics), as unfiltered text introduces noise. Disabling the Conflict Resolution Agent significantly lowers correctness (CQA drop 4.9% (0.831 \u2192 0.790) in genomics), especially in resolving contradictions like conflicting gene-disease associations. Omitting the Evaluator Agents has the most impact on usability, as unfiltered, low-confidence edges degrade answer quality (RLC drop 9.7% (0.668 \u2192 0.603) in metabolomics). Across all domains, conflict resolution proves critical for maintaining logical consistency, while summarization and evaluation ensure focused extraction and high-quality integration. This demonstrates that KARMA's multi-agent design is essential for balancing accuracy, consistency, and usability in KG enrichment."}, {"title": "6 Conclusion", "content": "We introduce KARMA, a multi-agent LLM framework designed to tackle the challenge of scalable knowledge graph enrichment from scientific literature. By decomposing the extraction process into specialized agents for entity discovery, relationship validation, and conflict resolution, KARMA ensures adaptive and accurate knowledge integration. Its modular design reduces the impact of conflicting edges through multi-layered assessments and cross-agent verification. Experimental results across genomics, proteomics, and metabolomics demonstrate that multi-agent collaboration can overcome the limitations of single-agent approaches, particularly in domains that require complex semantic understanding and adherence to structured schemas."}, {"title": "Limitations", "content": "Despite the promising performance of KARMA, several limitations remain. First, our evaluation relies primarily on LLM-based metrics rather than direct human expert validation. While we employ multi-faceted metrics (e.g., QA coherence, conflict resolution) to assess the quality of the extracted knowledge, we recognize that domain experts must ultimately verify critical biomedical claims before applying them in clinical settings. Furthermore, performance varies across domains; for instance, metabolomics shows 12.4% and 11.9% lower QA coherence than proteomics and genomics, respectively, indicating challenges in modeling sparse and rare relationships in this field. These limitations highlight opportunities for future improvements, such as integrating hybrid neuro-symbolic approaches and optimizing agent coordination protocols."}, {"title": "Ethical Impact", "content": "KARMA holds significant potential for automating the enrichment of knowledge graphs, particularly in complex fields like healthcare and biomedical research. However, as with any automated system, there are ethical concerns, particularly regarding bias in LLMs. Since LLMs are trained on vast and diverse datasets, they may inadvertently reflect outdated or biased information, leading to incorrect associations in the knowledge graph. Although KARMA incorporates mechanisms for verification and conflict resolution, human oversight remains essential to ensure the accuracy of critical knowledge. Additionally, considerations around data privacy are important, especially when dealing with sensitive research data. Going forward, balancing automation with human judgment will be crucial to ensuring the system operates responsibly and adheres to ethical standards. With careful attention to these challenges, KARMA has the potential to be a transformative tool for advancing knowledge while minimizing unintended consequences."}, {"title": "A Detailed propmts for KARMA agents", "content": "This appendix provides example prompts for each agent in the KARMA framework. All agents operate via LLMs with specialized prompt templates. We emphasize confidence, clarity, and domain relevance. Where applicable, we include sample inputs, outputs, and negative examples to illustrate how each agent handles complexities in the context."}, {"title": "A.1 Function summaries of different agents", "content": "The KARMA framework comprises nine specialized LLM-powered agents, each handling distinct stages of the knowledge extraction and integration task. Below are their core functions:\n\u2022 Central Controller Agent (CCA): Orchestrates task scheduling and resource allocation. Uses LLM-based utility scoring and multi-armed bandit-inspired exploration to prioritize tasks (e.g., ingestion vs. conflict resolution) while balancing agent workloads.\n\u2022 Ingestion Agents (IA): Retrieve raw documents (PDF/HTML), normalize text (handling OCR errors, tables), and extract metadata (authors, journal, publication date).\n\u2022 Reader Agents (RA): Split documents into sections, score segment relevance using KG context, and filter non-revelant content (e.g., acknowledgments).\n\u2022 Summarizer Agents (SA): Condense text segments into concise summaries while preserving entity relationships (e.g., \"Drug X inhibits Protein Y, reducing Disease Z symptoms\" \u2192 \"X inhibits Y; Y linked to Z\").\n\u2022 Entity Extraction Agents (EEA): Identify entities via few-shot LLM prompts, then normalize them to KG canonical forms using ontology-guided embedding alignment.\n\u2022 Relationship Extraction Agents (REA): Detect relationships (e.g., treats, causes) between entity pairs using multi-label classification, allowing overlapping relations (e.g., \"Drug A both inhibits Protein B and triggers Side Effect C\").\n\u2022 Schema Alignment Agents (SAA): Map novel entities/relations to KG schema types (e.g., classifying \"CRISPR-Cas9\" as Gene-Editing Tool) or flag them for ontology expansion.\n\u2022 Conflict Resolution Agents (CRA): Resolve contradictions (e.g., new triplet \"Drug D treats Disease E\" vs. existing \"Drug D exacerbates Disease E\") via LLM debate and evidence aggregation.\n\u2022 Evaluator Agents (EA): Compute integration confidence using weighted signals (confidence, relevance, clarity) and apply threshold-based final approval."}, {"title": "A.2 Additional Notes on Prompt Engineering", "content": "In practice, each agent's prompt can be extended with short examples of input-output pairs to provide the LLM with more context, thereby improving the accuracy and consistency of its responses. For instance, the EEA prompt might include examples of drug-disease pairs, while the CRA prompt might illustrate how to handle partial contradictions vs. direct contradictions.\nTo increase robustness, each agent can be provided with negative examples or clarifications on error-prone cases. For example, the Summarizer Agent might be shown how not to remove important numerical dosage information; the EEA might have a demonstration of ignoring location references that are not topic-related entities (e.g., \u201cParis\u201d is not a Disease).\nAs knowledge evolves, so do the vocabularies and relationship types. Agents can be periodically re-trained or their prompts updated to handle newly emerging entities (e.g., novel viruses, new drug classes) and complex multi-modal relationships. The modular structure of the prompts eases integration of these updates without redesigning the entire pipeline.\nCollectively, these prompts enable KARMA to harness LLMs at every stage of the knowledge extraction and integration process, resulting in a dynamic, scalable, and accurate knowledge enrichment."}, {"title": "A.3 Ingestion Agent (IA) Prompt"}]}