{"title": "Online SLA Decomposition: Enabling Real-Time Adaptation to Evolving Systems", "authors": ["Cyril Shih-Huan Hsu", "Danny De Vleeschauwer", "Chrysa Papagianni"], "abstract": "When a network slice spans multiple domains, each domain must uphold the End-to-End (E2E) Service Level Agreement (SLA). This requires decomposing the End-to-End (E2E) Service Level Agreement (SLA) into partial SLAs for each domain. In a two-level network slicing management system with an E2E orchestrator and local controllers, we propose an online learning-decomposition framework that dynamically updates risk models using recent feedback. This approach utilizes online gradient descent and FIFO memory buffers to enhance stability and robustness. Our empirical study shows the proposed framework outperforms state-of-the-art static methods, offering more accurate and resilient SLA decomposition under varying conditions and sparse data.", "sections": [{"title": "I. INTRODUCTION", "content": "The fifth generation (5G) of mobile communication technology introduced a versatile, multi-service network designed to support a wide range of vertical industries with a diverse set of service requirements. In 5G and beyond, network slicing plays a pivotal role by enabling the establishment and management of multiple End-to-End (E2E) logical networks. These slices are built on shared infrastructure and are specifically customized to meet the particular requirements of a given service, which is outlined in Service Level Agreements (SLAs). SLAS function as contracts between service providers and tenants, defining the expected Quality of Service (QoS) through well-defined, measurable benchmarks known as Service-Level Objectives (SLOs). These objectives encompass various performance metrics such as data throughput, latency, reliability, and security, among others. A single network slice may traverse multiple segments of the network, including access, core, and transport networks, and it may involve collaboration between different operators and infrastructure providers. To ensure that the service meets the agreed-upon SLOs across these domains, it is essential to adjust the service parameters accordingly. As a result, the E2E SLA linked to a network slice must be broken down into specific SLOs for each domain, allowing for effective resource allocation within each segment. The authors in [1] highlight the importance of E2E SLA decomposition for resource allocation, while [2] indicates that AI-assisted SLA decomposition is key to automating complex 6G business.\nFollowing the scenarios in [3], [4], in this paper we consider a two-level management architecture with an E2E service orchestrator handling network service lifecycle management, and local domain controllers managing slice instantiation within their domains (Fig. 1). The orchestrator determines the SLA decomposition for incoming service requests, while domain controllers handle admission control and resource allocation. We assume the orchestrator lacks real-time knowledge of the infrastructure state but has access to historical feedback (i.e., request acceptance or rejection) from each domain. This allows the orchestrator to make informed decisions using domain-specific risk models based on the available data."}, {"title": "II. PROBLEM DESCRIPTION", "content": ""}, {"title": "A. SLA Decomposition and Risk Models", "content": "An E2E SLA, denoted by $S_{e2e}$, is a collection of Service Level Objectives (SLOs) linked to specific performance indicators. The SLO vector outlines the SLA's performance requirements in a sequential manner. For example, an SLA encompassing E2E delay and throughput is expressed as $S_{e2e} = (T_{e2e}, \\theta_{e2e})$. This implies that the network slice must operate in a way that meets constraints imposed by $T_{e2e}$ for delay and $\\theta_{e2e}$ for throughput, ensuring $T < T_{e2e}$, and $\\theta \\geq \\theta_{e2e}$. Considering a network slice distributed across $N$ domains (where n ranges from 1 to N), we introduce $s_n$ to represent the SLOs of the n-th domain. The relationship between individual domain SLOs and the overall E2E objective $S_{e2e}$ is defined by $S_{e2e} = G(s_1, s_2, ..., s_N)$. For instance, the E2E delay is the sum of all delays for the involved domains, while the E2E throughput is determined by the lowest throughput across all domains. Mathematically, this is represented as $T_{e2e} = \\sum_{n=1}^{N} t_n$ and $\\theta_{e2e} = \\min{\\{\\theta_1, \\theta_2, ..., \\theta_N\\}}$.\nWe can model the ability of a domain to support a partial SLA $s_n$ with a risk model, and the risk models of all involved domains can then be used in the SLA decomposition process. The risk model is defined as $\u2013 \\log P_n(s_n)$, where $P_n(s_n)$ represents the probability that a request in the n-th domain with SLOs $s_n$ is accepted. Under the assumption of independent decision-making by each domain, the overall E2E acceptance probability is calculated as the product of the individual acceptance probabilities of all involved domains. Therefore, the E2E decomposition can be formulated as an optimization problem that minimizes the overall risk in objective (1) under the constraints (2):"}, {"title": "B. Determining Neural Network-based Risk Models", "content": "We determine the risk model per domain with a parameterized Neural Network (NN) $F$ [4], where the probability $P_n(s_n)$ is modelled as $F_n(s_n)$. When a domain is presented with a new service request with specific SLOs, denoted by s (domain subscript omitted for simplicity), a controller must determine whether to accept or reject the request. This decision depends not only on the requested SLOs but also on the current infrastructure state, represented by w. The infrastructure state encompasses factors such as link and server utilization, network hop delays, and available backup paths, etc. Therefore, the decision to accept or reject a service request depends jointly on the SLOs s and infrastructure state w. While the domain controller has granular visibility of the infrastructure state, the orchestrator lacks this level of detail. Accordingly, although the controller's decision-making process is deterministic, the orchestrator perceives it as stochastic due to the unknown infrastructure state w.\nNevertheless, the acceptance probability $P$ can be estimated by analyzing the domain controller's responses to past requests. Given a set of $K$ responses to previous requests $\\{(X_1,Y_1), (X_2,Y_2), ..., (x_K, Y_K)\\}$, each represented by a proposed SLO x and its corresponding acceptance decision y (0 for rejection, 1 for acceptance), we can model the acceptance probabilities for SLO vectors with parameterized neural networks $F$ by maximizing the overall likelihood on the dataset:\nFurthermore, the acceptance probability exhibits a partial ordering relation [3], which incorporates the concept of SLA strictness, i.e., given a set of $K$ SLOs $S = \\{x_1, x_2, ..., x_K \\}$, the acceptance probability has the following property:\nThe property indicates that a stricter SLO $x_i$ is less likely to be accepted compared to $x_j$. The authors in [4] proposed several effective methods to bake this property into NN-based risk models without incurring any architectural constraints."}, {"title": "C. Dynamicity", "content": "The dynamicity of the system is crucial for accurately managing SLAs in network domains. Multiple factors contribute to this dynamicity, including traffic intensity fluctuations, changes in user behavior, varying network conditions and security threats. As these factors change, the acceptance probability of requests within a domain varies, impacting overall network performance. Particularly, the acceptance probability becomes time-dependent. At a discrete time step t, the acceptance probability (in a single domain) of the SLA request s is denoted as $P_t(s)$, which is influenced by the state $w_t$ of the domain, as stated in Section II-B. Given that $w_t$ evolves over time, the acceptance probability $P_t(s)$ also varies, even for the same SLOs. This behavior necessitates continuous learning and adaptation of the risk models. Dynamic systems require periodic updates to risk models based on the recent feedback"}, {"title": "III. APPROACHES", "content": "In this section, we present the proposed framework Real-time Adaptative DEcomposition (RADE)."}, {"title": "A. Two-step Decomposition with NN-based Risk Models", "content": "A two-step decomposition approach was proposed in [3], [4]. A dedicated risk model is learned first for each domain, given the historical feedback (i.e., proposed SLAs and their corresponding acceptance/rejection decisions made by controllers) from domain controllers. Once the risk models are built, an optimization proceeds to search for the decomposition that maximizes the E2E acceptance probability, as formulated in (1) and (2). However, in the previous work, the risk models are trained once and the weights are kept fixed for all future SLA decompositions. This approach is impractical for real-world systems, which are typically dynamic and time-dependent. The static models often lead to sub-optimal performance. We describe our extended solution to tackle this problem in the next subsection."}, {"title": "B. Online Learning Framework", "content": "To capture the dynamic nature of the environment, where the decision-making process of controllers evolves over time, it is essential to constantly update risk models based on the recent feedback. To this end, we propose an online learning-decomposition framework RADE, which is capable of running stable update as well as providing resilience against noisy samples. The following are the key components of RADE: Base model. Following the design in [4], the base model is an NN. To account for monotonicity, we specifically choose Absolute Weight Transformation (AWET) model that shows prominent performance while requiring the least training effort, as suggested in [4].\nOnline update. Unlike traditional static models, which are trained once and applied indefinitely, our approach involves periodic updates to the model based on the most recent feedback collected within each discrete time step. As illustrated in Fig. 2, the loop begins with a base model and employs simple Online Gradient Descent (OGD) [6] to perform updates. The continuously updated model is then used for real-time decomposition, ensuring that the system adapts promptly to the latest conditions.\nFIFO memory buffer. Updating the model solely based on the most recent observations can lead to instability. For instance, the model may overfit when the feedback data is sparse, or learning may be compromised if feedback data contains errors. To mitigate these issues, we propose using a FIFO buffer with finite capacity for storing feedback. The FIFO buffer ensures a more stable and reliable learning process by maintaining a portion of historical feedback alongside all recent feedback [7]. The limited capacity is necessary to ensure that outdated information is discarded, allowing the dataset to remain current and relevant for ongoing learning. This component helps prevent overfitting by providing a more diverse set of training samples and safeguards against the detrimental effects of occasional corrupted feedback.\nOnline decomposition. Besides the learning loop, the inference loop is also running in parallel. Upon receiving a new request, the associated E2E SLA will be decomposed with the latest risk models. The optimization-based decomposition follows the one proposed in [4]. By leveraging up-to-date risk models, the inference loop ensures that the decomposition accurately reflects the current state of the corresponding domains."}, {"title": "IV. EXPERIMENTAL SETUP", "content": ""}, {"title": "A. Simulation Environment", "content": "We follow the analytic model and data generation process proposed in [3], [4] to generate data for three domains. This analytic model maps a decomposition assignment to a probability, indicating how possible the given assignment will be accepted by the current domain controllers. To introduce dynamicity into domain controller's decision-making process over time, we assume that the acceptance probability is inversely proportional to the current traffic intensity. Specifically, we define a time-dependent factor:"}, {"title": "B. Evaluation scenarios and metrics", "content": "Average acceptance probability over time. We run Alg. 1 within the simulation environment detailed in Section IV-A. Given the response to each decomposition assignment is represented as a probability value \u2208 [0, 1], the E2E acceptance probability at each time step t is calculated as the product of the individual acceptance probabilities across all three domains. The average acceptance probability is then reported over the entire simulation period:\nwhere T denotes the number of total time steps, Mt is the number of requests at time t, D is the number of involved domains (which is set to 3 in this paper), $P_{am}$ represents the analytic model, and $s_{m,d,t}$ is the decomposed partial SLA of the m-th request that is assigned to the d-th domain at time t. The number of requests Mt at time t is sampled from the Poisson distribution with \u5165 = At described in (5). The E2E SLA for each request is given as (Te2e, 0e2e), where Te2e and 0e2e are sampled uniformly from [90ms, 110ms] and [0.4Gbps, 0.6Gbps], respectively.\nResilience test. To assess the framework's resilience against corrupted feedback labels, we perform a resilience test on top of the aforementioned test, where each feedback has a corruption probability $p_c$ of being corrupted (i.e., the request is always rejected), which can result from issues like network delays, transient errors, or misconfiguration in domain controllers. Specifically, we track how the model's accuracy is affected as $p_c$ increases. This resilience test offers crucial insights into the effectiveness of the use of FIFO memory buffer mentioned in Section III-B, and the overall robustness of our framework under challenging conditions."}, {"title": "C. Configurations", "content": "To evaluate the contribution of each component proposed in Section III-B, we perform an ablation study by incrementally adding improvements at three stages, with each stage forming a distinct comparison method. Furthermore, two additional methods (Random and OPT) are included as benchmarks.\nRandom. The Random method does not employ any risk models and instead decomposes each incoming request's E2E SLA uniformly at random. This method is used as a baseline to verify the effectiveness of the proposed methods.\nStatic. The Static method involves a one-time training of risk models using feedback collected from a single prior run with the Random method. The weights of these risk models are then fixed and applied to all subsequent decompositions over time. The configuration of the NN-based risk models is consistent with that described in [4]: a 3-layer multilayer perceptron (MLP), with 8 neurons each. The hyperbolic tangent (Tanh) activation function and Batch Normalization (BN) are applied for hidden layers in the order of linear-Tanh-BN.\nRADE/RADE*. RADE represents the full method described in Section III-B, whereas RADE* is a variant of RADE that omits the FIFO memory buffer. In RADE*, risk models are updated using only the most recent feedback. Both RADE and RADE* utilize the Static method to initialize the risk models.\nOPT. An exhaustive search is conducted at every time step to find the decomposition assignment that yields the largest E2E acceptance probability. This method provides the maximum theoretical performance achievable."}, {"title": "V. RESULTS", "content": "Fig. 3 presents the average E2E acceptance probability across different arrival rates for four methods: Static, RADE*, RADE, and OPT. The arrival rates vary between 0.3, 0.5, and 0.7, representing different traffic intensities in the system. Across all arrival rates, the Static method consistently exhibits the lowest average E2E acceptance probability. This suggests that the Static method's one-off trained risk models are less adaptable to varying traffic conditions, leading to sub-optimal performance, particularly under higher traffic loads. RADE* shows improved performance over the Static method, which indicates that dynamically updating the risk models, even without the FIFO memory buffer, leads to a better adaptability than the Static approach. The RADE method, which includes the FIFO memory buffer for maintaining historical feedback, outperforms both Static and RADE*, highlighting the importance of the use of the FIFO buffer in enhancing the robustness and stability of the framework, particularly under varying traffic conditions. It is interesting to see that the performance of RADE* and RADE becomes nearly identical at higher arrival rates because, under heavy traffic, the system receives a large volume of recent feedback. This plenty of fresh data diminishes the impact of the FIFO memory buffer in RADE, as the most recent observations dominate the learning process. As expected, the OPT method achieves the highest performance, which serves as a theoretical upper bound. In contrast, the Random method performs significantly worse than the other approaches in general, with results of 0.42, 0.38, and 0.35 for arrival rates of 0.3, 0.5, and 0.7, respectively. Due to the consistently low performance of the Random method, we exclude its results from all subsequent figures to focus on the more meaningful comparisons."}, {"title": "VI. CONCLUSION", "content": "This paper has introduced an online learning-decomposition framework for SLA management in dynamic multi-domain environments. The proposed framework updates domain-specific risk models in real-time based on recent feedback, hence effectively addressing the challenges posed by the dynamicity of real-world systems. With the use of online update and FIFO memory buffers, the proposed framework enhances the stability and robustness of SLA decomposition, ensuring that the system is able to adapt promptly to changes in network conditions. Empirical results demonstrate that our framework outperforms state-of-the-art static methods, offering a more resilient and accurate decomposition of SLAs, even with limited data availability. In future work, we will investigate the potential of Deep Reinforcement Learning (DRL) to further enhance the SLA decomposition process. DRL could be a promising choice for this task due to its ability to learn optimal long-term policies through interaction with dynamic environments, which makes it an attractive option for improving SLA management in next-generation networks."}], "equations": ["A_t = \\frac{1}{2}(\\frac{\\sin(2 \\pi * t)}{N} + 1) * 0.9 + 0.1,", "P_{avg} = \\frac{1}{T} \\sum_{t=1}^{T} \\frac{1}{M_t} \\sum_{m=1}^{M_t} \\prod_{d=1}^{D} P_{am} (s_{m,d,t}),", "\\sum_{n=1}^{N} \\log P_n (s_n)", "S_{e2e} = G(s_1, s_2, ..., s_N)", "K\\sum_{i=1} [y_i *log(F(x_i)) + (1 \u2212 y_i) * log(1 \u2013 F(x_i))].", "\u2200x_i, x_j \u2208 S, P(x_i) < P(x_j) if X_i < X_j,", "\u2200x_i, x_j \u2208 S, P(x_i) < P(x_j) if X_i < X_j,", "\u2200xi, xj \u2208 S, P(xi) < P(xj) if Xixj,"]}