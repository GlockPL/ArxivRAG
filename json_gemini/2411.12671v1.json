{"title": "Neurosymbolic Graph Enrichment for Grounded World Models", "authors": ["Stefano De Giorgis", "Aldo Gangemi", "Alessandro Russo"], "abstract": "The development of artificial intelligence systems capable of understanding and reasoning about complex real-world scenarios is a significant challenge. In this work we present a novel approach to enhance and exploit LLM re-active capability to address complex problems and interpret deeply contex-tual real-world meaning. We introduce a method and a tool for creating a multimodal, knowledge-augmented formal representation of meaning that combines the strengths of large language models with structured semantic representations. Our method begins with an image input, utilizing state-of-the-art large language models to generate a natural language description. This description is then transformed into an Abstract Meaning Representa-tion (AMR) graph, which is formalized and enriched with logical design pat-terns, and layered semantics derived from linguistic and factual knowledge bases. The resulting graph is then fed back into the LLM to be extended with implicit knowledge activated by complex heuristic learning, including semantic implicatures, moral values, embodied cognition, and metaphorical representations. By bridging the gap between unstructured language models and formal semantic structures, our method opens new avenues for tackling intricate problems in natural language understanding and reasoning.", "sections": [{"title": "1. Introduction", "content": "The development of artificial intelligence systems capable of understand-ing and reasoning about complex real-world scenarios remains a significantchallenge in computer science. This challenge is particularly evident whenconsidering the distinct paradigms of generative AI and knowledge-based AI.Generative Als, including Large Language Models (LLMs), function as signalprocessing machines: they learn activation patterns from input of any modal-ity and provide symbolic output at inference time. In contrast, knowledge-based Als operate as logical machines, extracting and designing symbolicrepresentation patterns of the world with model-theoretical interpretationsto ensure correct inference.\nWhile both approaches have demonstrated remarkable capabilities, theyoften lack the comprehensive understanding necessary to build GroundedWorld Models (GWM) [62, 64], i.e., models of the world as experiencedor constructed by humans (and other organisms). GWMs are multivaried,encompassing physical, neurocognitive, social, and cultural dimensions. Thismultidimensional approach is intended to better mirror the complexity ofhuman understanding.\nThis paper presents a novel neurosymbolic approach that aims to bridgethis gap by leveraging LLMs\u2019power of automated generation from latentknowledge, and the heuristic power of ontology-based knowledge graphs.\nAt the core of our approach is the assumption that human-like under-standing requires the integration of multiple layers of knowledge, rangingfrom sensorimotor experiences to abstract conceptual structures. As arguedby Lakoff and Johnson [53], human cognition is grounded in embodied ex-periences, which give rise e.g. to image schemas and conceptual metaphorsthat shape our understanding of more abstract domains. An interesting con-sequence, which was not noticed until the appearance of LLMs [65], is thatabstract knowledge (as represented in natural language, logical and statisti-cal models, knowledge bases, sensor data) can work as a supramodal systemthat bears correspondences to the physical, social, cognitive worlds.\nConsequentially, we propose a framework for developing GWMs trainedwith, and capable of generating, knowledge graphs. Training includes ei-ther in-context learning or fine-tuning of pre-trained (multimodal) LLMsreinforced to generate multilayered knowledge, including highly contextualimplicit knowledge. Implicit knowledge includes e.g. presuppositions, con-versational implicatures, factual impacts, image schemas, metonymic andsymbolic coercions, event sequences, causal relations, and moral value-drivenreasoning.\nA key innovation in our approach is the use of LLMs not as expert sys-tems, but as reactive engines to extract implicit contextual knowledge. Be-"}, {"title": "2. Related Work", "content": "Our approach is positioned in the quickly growing field of Large LanguageModels and Knowledge Graphs hybrid neurosymbolic methods. The synergybetween neural and symbolic approaches has been extensively explored inmultiple surveys [26, 20, 21, 22, 24], some of them focusing explicitly ongraph neural networks and symbolic components [23], reasoning over graphstructures [27], dynamic knowledge graphs [31], and natural language infer-ence [25], reflecting the growing interest in hybrid methodologies.\nWhile an exhaustive survey lies be-yond the scope ofthis paper, we canposition our methodwithin the broaderlandscape of recentadvancements: (i)within the landscapeof interactions be-tween LLMs and KGSin joint methods ,and (ii) in relation topopular techniquessuch as Graph RAG(Retrieval-AugmentedGeneration) that haverecently garnered sig-nificant attention.\nRegarding joint LLMs and KGs methods, according to [41], as shown inFigure 1, our approach would be both \u201cLLM augmented KG\u201d and \u201cSyn-ergized LLMs + KGs\", and in particular \u201cLLMs - augmented KGs con-struction\" focusing on \u201cEnd-to-end construction\u201d and \u201cDistilling KGs fromLLMs\", as well as \u201cLLMs-augmented KGs to text generation\" focusing on\u201cLeveraging knowledge from LLMs\", and partially \u201cLLM-augmented KG forquestion answering\" adopting \"LLMs as entity/relations extractors\u201d.Considering Kautz' taxonomy of neurosymbolic systems [18], as well as Hamil-ton contextualization in the domain of natural language understanding [17],our pipeline qualifies as Type 2 (\u201cSymbolic[Neuro] (Nested)\") - Type 3(\"Neuro; Symbolic (Cooperative)\u201d) architecture. Type 2 is defined as nestedarchitecture, where a symbolic reasoning system is the primary system withneural components driving certain internal decisions, while Type 3 coverscases in which a neural network focuses on one task, e.g. entity linking, wordsense disambiguation, etc., and interacts via input/output with a symbolicreasoner specializing in a complementary task, in our case, building semantictree dependencies in RDF format while aligning entities to Framester [19]hub of ontologies, maintaining correct OWL2 syntax.\nConsidering Graph RAG approaches, in recent years the integration ofLLMs and knowledge graphs has gained significant traction [3], particularlyusing models for knowledge graph completion [6], and through the devel-opment of Retrieval-Augmented Generation (RAG) and Graph RAG tech-niques. Different models (GPT, Llama, Claude, Gemini, etc.) have showndifferent specific capabilities but similar structural limitations [1]. Whilereditional RAG focuses on retrieving precise information from unstructuredor vector-compressed resources, Graph RAG has demonstrated remarkableefficacy and compliance with graph-structured data [5]. The Graph RAGapproach extends beyond mere text vectorisation, encompassing a two-foldprocess: entity recognition and relation extraction, culminating in the gen-eration of semantic triples.\nClassic applications of Graph RAG have been in question-answering [4],starting from textual information transposed to knowledge graph embeddings[7], or summarization systems designed to retrieve specific information fromestablished knowledge bases [5]. However, certain layers of meaning remainchallenging to capture and formalize, including moral reasoning, pragmaticimplicatures, and tacit knowledge derived from real-world experiences.\nThe topic of knowledge graph generation from text is of some relevancein several overlapping communities, such as the Semantic Web one [8], aswell as the broader knowledge-graph-oriented one\u00b9 [5].\nFor this reason, our research expands beyond Graph RAG. We leverageLLMs as latent reactors that can provide approximate, implicit, common-sense knowledge when activated with appropriate heuristics, rather than asools for compressed information retrieval. Our approach, partially posi-"}, {"title": "3. Methodology", "content": "In this section we describe our approach, detailing (i) the technical struc-ture, and (ii) the knowledge layers we have chosen to include in our heuristics.It is important to note that the selection of the heuristics is not exhaustiveand can be incrementally expanded to incorporate additional knowledge are-as as needed, as envisioned in Section 5.\nXKG Generation Pipeline. Our modular pipeline combines natural lan-guage processing, knowledge representation, and large language models (LLMs)to extract and enrich semantic information from textual or visual inputs. Thewhole process is shown in Figure 2, and begins on the top left, with eitheruser-provided text or an LLM-generated description of an input image, usinga carefully crafted prompt.\nConsidering the case in which we provide a picture as starting input,following Figure 2, this original content is passed to a Multimodal LLM(MLLM), prompted to provide a description of the picture in natural lan-guage.\nIn our current implementation, after several tests, we retrieved that GPT-40 is the best model at providing a textual description when given as inputan image. Therefore, starting from an image, we rely on GPT-40 to get asoutput a textual description. In Section 4 we provide an example of input"}, {"title": "3.1. Knowledge Heuristics", "content": "We describe here the 11 heuristics currently implemented in the imple-mented tool. These heuristics are chosen according to an analysis of theessential elements that constitute daily human understanding and sense-making activity in building and using Grounded World Models. The heuris-tics list includes: Presuppositions, based on previous background knowledge;Conversational Implicatures, which often contributes in making sense of in-complete information in linguistic exchanges; Factual Impact, which groundslinguistic entities to factual knowledge; Image Schemas, basic building blocksof cognition which grounds our way of conceiving the world in our sensori-motor bodily perception (grounding e.g. cognitive metaphors and severalother entities); Metonymic Coercions, which allows understand propositionswhose truth value would be zero, but differ from metaphorical speech ground-ing the relation between entities on the parthood-whole relation; Moral ValueDriven Coercion, applied everyday in appraisal and moral evaluative pro-cesses, values nudge our daily behavior; Symbolic Coercion, in Peirce termi-nology [60], used to anchor meaning to various entities of the world; EventSequences, determinant in our plan-making capability and ability to designplausible scenarios and outcomes; Causal Relations, establishing relations ofcause-effect between processes and events, to avoid either having only (i)temporal sequences and (ii) statistical correlation; Implied Future Events, aspecification of Event Sequences, for temporal projection in the future; andImplied Non-Events, an infinite set of events, but, referring to the Frameproblem, focusing on those more closely related to a specific Event Sequence.\nPresuppositions. Presuppositions are implicit assumptions necessary forstatements to be meaningful [47, 46, 45]. They play a crucial role in hu-man cognition, enabling efficient communication through shared backgroundknowledge. In natural language, presuppositions help infer unstated informa-tion and enhance contextual understanding. By formalizing and integratingthese implicit meanings into knowledge structures, the approach capturesnuanced understandings often taken for granted in human communication.For example, the statement \u201cThe athlete won the gold medal\u201d presupposesthat there was a competition, possibly an Olympic one, illustrating how pre-suppositions convey information beyond the explicit content of a sentence.\nConversational Implicatures. Conversational implicatures are impliedmeanings that arise from the context of a conversation rather than literal in-terpretation. Defined in Grice's pragmatics [48], they are essential to humancommunication, allowing speakers to convey more information than explicitlystated [49]. By formalizing and integrating these implicatures into knowledgestructures, the approach captures nuanced, context-dependent interpreta-tions that humans naturally derive from conversations. This enhances thesystem's ability to understand and reason about complex linguistic phenom-ena. For example, if someone asks \"Is there a gas station nearby?\" andreceives the answer \u201cThere's one around the corner,\" the implicature here isthat the gas station should be open and operational, even though this isn'texplicitly stated.\nFactual Impact. Factual impact refers to the physical, social, and cog-nitive consequences of events on participants, including expected emotions,sensations, and changes in mental states [50]. This concept is crucial for"}, {"title": "4. Experimental Evaluation", "content": "In this section we evaluate the output generated from the full pipeline de-scribed in Section 3: we provide an example of knowledge extension startingfrom an image to the complete XKGs extension with all 11 heuristics.\nWe adopt a comprehensive three-tieredevaluation framework designed to rigorouslyassess our model's performance, and vali-date the integrity of the XKGs. The evalua-tion process encompasses: (i) logical valida-tion of the triples, encompassing both syn-tactic correctness and proper anchoring topre-existing nodes in the Base Graph; (ii)evaluation of foundational ontology align-ment adequacy, and (iii) human assessmentof the plausibility and adequacy of asser-tions within the triples generated for eachheuristic.\nTo further ensure the robustness of ourevaluation, we perform graph extension using an image captured after May2024, shown in Figure 3. This temporal selection is significant as it postdatesthe release of GPT-40, thereby guaranteeing that the image is not part ofthe model's training dataset.\nDue to space constraints, we present a detailed analysis and evaluationof a single knowledge extension instance, utilizing the image shown in Figure3, from the \u201csport\u201d domain. Additional examples of knowledge extension,particularly focusing on \"politics\u201d and \u201ceveryday life\u201d topics, are available inour dedicated GitHub repository11. We chose this image since it captures a"}, {"title": "Logical Integrity and Foundational Ontologies Compliance", "content": "To en-sure the structural integrity and logical consistency of all XKGs, we use theHermit 1.4.3.456 reasoner [11] as part of our evaluation framework, as wellas OOPS! - OntOlogy Pitfall Scanner [9].\nThe reasoner's check is meant to ver-ify soundness and consistency of the newlyintroduced LLM-generated triples, therebyensuring that the extended knowledge re-mains sound and usable for downstream ap-plications and inference tasks. In particular,we use Hermit via Prot\u00e9g\u00e9 5.5.0 interfaceand OOPS! web interface15. Passing eachand every XKG graph to OOPS!, the pitfallscanner yields minor issues for all of them,mainly related to the absence of metadatasuch as rdfs:comment describing entities.\nOccasional instances of hallucination canbeen observed, particularly in the applica-tion of prefixes. An example occurs in theMetonymic coercion file, where the prefix\"pbrs\u201d (denoting PropBank Role Set, whichPropBank utilized for frame-like structures) is erroneously employed insteadof the correct prefix \"pblr\u201d (PropBank Local Role), which is the appropriatedesignation for occurrences of PropBank roles. Such inconsistencies, whileminor, underscore the importance of rigorous post-processing and validationin ensuring the accuracy and reliability of the model's semantic annotations,as described in Section 5.\nFor soundness validation, we checked each XKG importing both the BaseGraph and DOLCE Zero, in order to ensure complete coherence with theAMR2FRED original graph, as well as the DOLCE foundational ontology.\nAn isolated instance of inconsistency is identified in the Metonymic Co-ercions heuristic graph, suggesting the fact this XKG could present problemson several sides. This anomaly manifested as a conflicting chain of subsump-tions (athlete_1 \u2192 Athlete \u2192 Person \u2192 Agent \u2192 Object) wherein a single"}, {"title": "XKGs Human Evaluation", "content": "To ensure the quality and reliability of thegenerated triples, we conduct a comprehensive human evaluation process.The validation was performed by 5 annotators, all of whom possess profi-ciency in Resource Description Framework (RDF) and Turtle syntax, butare not domain experts across all 11 heuristics considered. Each triple pro-duced in our extension undergoes scrutiny and is labeled using a 5-pointLikert scale, where 1 represents \u201cNot at all plausible/adequate\" and 5 indi-cates \"Completely plausible/adequate\u201d. This approach allows for a nuancedassessment of the triples' validity and relevance within their respective do-mains. By employing annotators with RDF expertise but varying levels ofdomain-specific knowledge, we aims to balance technical accuracy with ageneralist perspective, mirroring real-world scenarios where RDF data maybe consumed by users with diverse backgrounds.\nFurthermore, to ensure the reliability and consistency of our ratings, weemploys multiple statistical measures. Inter-rater agreement is calculated toassess the overall concordance among raters. Krippendorff's alpha is chosenfor its ability to handle ordinal data and accommodate multiple raters, pro-viding a robust measure of reliability. Cohen's Kappa, while typically usedfor binary ratings, is adapted to evaluate pairwise agreement between raters.Mean ratings are computed to provide a central tendency measure of theperceived quality of the generated triples. Finally, we calculate the standarddeviation to quantify the dispersion of ratings, to get further insight into the"}, {"title": "Mean Ratings and Standard Deviation", "content": "It is important to highlightthat, given the 5 point Likert scale, almost all the heuristics overall passedthe threshold of 3, with the exception of Implied Future Events, which stillshows a rating of 2.94. This means that, overall, the XKGs present at least\u201cfairly plausible\u201d knowledge extension for all the domains. This is per sea remarkable achievement, given the disparity among the domains, which cou-pled with symbolic reasoning inference regarding e.g. sequences of events,mentioned above, opens to very promising further neurosymbolic methodol-ogy exploration.\nFurthermore, the analysis of mean ratings and standard deviations acrossvarious heuristics shown in Figure 6 reveals interesting patterns in the per-formance and consistency of different evaluation criteria. Factual Impact,Conversational Implicatures, and Moral Value-driven Coercions emerge asthe top-performing heuristics, with mean ratings exceeding 4.29 on a 5-pointscale. This suggests a high degree of plausibility or adequacy in these areas.Conversely, Potential Non-Events and Image Schemas received the lowestmean ratings (2.94 and 3.64, respectively), indicating potential areas for im-provement in the language model's output. Notably, the standard deviationsexhibit considerable variation, with Implied Future Events showing the high-est variability (SD = 1.57) and Moral Value-driven Coercions demonstrating"}, {"title": "Mean Scores per Annotator", "content": "The analysis of mean scores by annota-tor for each heuristic, shown in Figure 7, reveals significant insights intothe evaluation process and possibly the nature of the heuristics themselves. No-tably, there is considerable variation in scoring patterns across annotators,suggesting potential differences in interpretation or application of the evalu-ation criteria. Annotator 1 consistently provided higher scores across mostheuristics, particularly for Conversational Implicatures (4.87) and FactualImpact (4.75), while Annotator 3 tended to score more conservatively, es-pecially for Implied Future Events (1.43). The heuristics of Factual Impactand Causal Relations demonstrated relatively high consensus among anno-tators, with most scores clustering above 4.0, indicating their robustness andclarity. Conversely, Implied Future Events and Potential Non-events exhib-"}, {"title": "Agreement Measures", "content": "Figure 8 shows how Moral Value-driven Coercionsdemonstrate the highest overall agreement, with an inter-rater agreement of0.75 and a Cohen's Kappa of 0.51, suggesting strong consistency among ratersfor this heuristic. Conversely, Implied Future Events show the lowest agree-ment across all measures, indicating a potential need for refinement in itsdefinition or evaluation criteria. Notably, Krippendorff's Alpha consistentlyyields lower values compared to other measures, with several heuristics show-ing negative values, particularly for Metonymic Coercions and Moral Value-"}, {"title": "5. Ongoing and Future Work", "content": "In our ongoing efforts to refine and enhance the generation of XKGs,several specific improvements are being explored. Prompt refinement for in-context learning has emerged as a crucial area for development, particularlyin light of insights gained from image schemas. Our current approach utilizesa standard template, but evidence suggests that more adapted heuristic-specific prompts could yield superior results.\nAnother area of focus is the refinement of property assignments. Cur-rently, many triples are generated using the broad dul:associatedWithtop property. Efforts are underway to specialize this property further, align-ing newly introduced properties with DOLCE Zero. While this integrationmay increase the risk of ontological inconsistencies, it also promises enhancedinferential capabilities.\nWe are also reevaluating our validation methodology. The current sys-tem17, which informs annotators of the heuristic definition they are validat-ing, may be influencing results. An alternative approach, such as presentinguncontextualized triples for evaluation, could potentially yield different out-comes in human assessment.\nLastly, we are exploring alignment with domain-specific ontologies, par-ticularly those focused on Image Schemas [36], moral and cultural values[69], and other cognitive entities such as emotions. This could involve refin-ing prompts to incorporate either complete ontology schemas (when feasible)or at least excerpts of top taxonomy classes, potentially leading to more nu-anced and domain-specific knowledge.\nFuture work will focus on several key areas to enhance the capabilitiesand applicability of our graph enrichment process. A primary objective is thetopicalization of enrichment when starting from images, which involves local-izing triples related to specific heuristics to particular portions of an image.This can be achieved through the utilization of existing labeled repositories"}, {"title": "6. Conclusions", "content": "Our research presents a significant step forward in the development ofa hybrid neurosymbolic method for grounded world models that can effec-tively integrate multiple layers of knowledge, bridging the gap between thepattern-matching reactive capabilities of LLMs, and the structured reasoningapplied on Knowledge Bases and traditional symbolic reasoning. By lever-aging LLMs as repositories of implicit commonsense knowledge rather thanexpert systems, we have demonstrated a novel approach to knowledge baseextension that is both agile and comprehensive.\nThese results also add to a growing corpus of results about the hidden"}]}