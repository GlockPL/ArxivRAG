{"title": "From RAG to Memory: Non-Parametric Continual Learning for Large Language Models", "authors": ["Bernal Jim\u00e9nez Guti\u00e9rrez", "Yiheng Shu", "Weijian Qi", "Sizhe Zhou", "Yu Su"], "abstract": "Our ability to continuously acquire, organize, and leverage knowledge is a key feature of human intelligence that AI systems must approximate to unlock their full potential. Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new information. However, its reliance on vector retrieval hinders its ability to mimic the dynamic and interconnected nature of human long-term memory. Recent RAG approaches augment vector embeddings with various structures like knowledge graphs to address some of these gaps, namely sense-making and associativity. However, their performance on more basic factual memory tasks drops considerably below standard RAG. We address this unintended deterioration and propose HippoRAG 2, a framework that outperforms standard RAG comprehensively on factual, sense-making, and associative memory tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in HippoRAG and enhances it with deeper passage integration and more effective online use of an LLM. This combination pushes this RAG system closer to the effectiveness of human long-term memory, achieving a 7% improvement in associative memory tasks over the state-of-the-art embedding model while also exhibiting superior factual knowledge and sense-making memory capabilities. This work paves the way for non-parametric continual learning for LLMs.", "sections": [{"title": "1. Introduction", "content": "In an ever-evolving world, the ability to continuously absorb, integrate, and leverage knowledge is one of the most important features of human intelligence. From lawyers navigating shifting legal frameworks to researchers tracking multifaceted scientific progress, much of our productivity relies on this incredible capacity for continual learning. It is imperative for AI systems to approximate this capability in order to become truly useful human-level assistants.\nIn recent years, large language models (LLMs) have made remarkable progress in many aspects of human intelligence. However, efforts to endow these models with our evolving long-term memory capabilities have faced significant challenges in both fully absorbing new knowledge (Zhong et al., 2023; Hoelscher-Obermaier et al., 2023) and avoiding catastrophic forgetting (Cohen et al., 2024; Gu et al., 2024), due to the complex distributional nature of their parametric knowledge. Retrieval-augmented generation (RAG) has emerged as a way to circumvent these obstacles and allow LLMs to access new information in a non-parametric fashion without altering an LLM's parametric representation. Due to their simplicity and robustness (Zhong et al., 2023; Xie et al., 2024), RAG has quickly become the de facto continual learning solution for production LLM systems. However, their reliance on simple vector retrieval results in the inability to capture two vital aspects of our interconnected long-term memory system: sense-making (Klein et al. (2006); the ability to interpret larger, more complex, or uncertain contexts) and associativity (Suzuki (2005); the capacity to draw multi-hop connections between disparate pieces of knowledge).\nSeveral RAG frameworks that engage an LLM to explicitly structure its retrieval corpus have been recently proposed to address these limitations. To enhance sense-making, such structure-augmented RAG methods allow an LLM to either generate summaries (Edge et al., 2024; Sarthi et al., 2024; Chen et al., 2023) or a knowledge graph (KG) structure (Guo et al., 2024) to link groups of disparate but related passages, thereby improving the RAG system's ability to understand longer and more complex discourse such as long stories. To address the associativity gap, the authors of HippoRAG (Guti\u00e9rrez et al., 2024) use the Personalized"}, {"title": "2. Related Work", "content": "Continual learning methods applied to LLMs aim to allow them to acquire and integrate new knowledge over time while preserving past information. Given the high computational cost of full-scale LLM pretraining, various techniques have been used to achieve this goal. These approaches gen-"}, {"title": "2.1. Continual Learning for LLMs", "content": ""}, {"title": "2.2. Non-Parametric Continual Learning for LLMs", "content": "Encoder model improvements, particularly with LLM backbones, have significantly enhanced RAG systems by generating high-quality embeddings that better capture semantic relationships, improving retrieval quality for LLM generation. Recent models (Li et al., 2023; Muennighoff et al., 2024; Lee et al., 2025) leverage LLMs, large corpora, improved architectures, and instruction fine-tuning for notable retrieval gains. NV-Embed-v2 (Lee et al., 2025) serves as the primary comparison in this paper.\nSense-making is the ability to understand large-scale or complex events, experiences, or data (Koli et al., 2024). Standard RAG methods are limited in this capacity since they require integrating information from disparate passages, and thus, several RAG frameworks have been proposed to address it. RAPTOR (Sarthi et al., 2024) and GraphRAG (Edge et al., 2024) both generate summaries that integrate their retrieval corpora. However, they follow distinct processes for detecting what to summarize and at what granularity. While RAPTOR uses a Gaussian Mixture Model to detect document clusters to summarize, GraphRAG uses a graph community detection algorithm that can summarize documents, entity clusters with relations, or a combination of these elements. LightRAG (Guo et al., 2024) employs a dual-level retrieval mechanism to enhance comprehensive information retrieval capabilities in both low-level and high-level knowledge, integrating graph structures with vector retrieval.\nAlthough both GraphRAG and LightRAG use a KG just like our HippoRAG 2 approach, our KG is used to aid in the retrieval process rather than to expand the retrieval corpus itself. This allows HippoRAG 2 to introduce less LLM-generated noise, which deteriorates the performance of these methods in single and multi-hop QA tasks.\nAssociativity is the capacity to draw multi-hop connections between disparate facts for efficient retrieval. It is an important part of continual learning, which standard RAG cannot emulate due to its reliance on independent vector retrieval. HippoRAG (Guti\u00e9rrez et al., 2024) is the only RAG framework that has addressed this property by leveraging the PPR algorithm over an explicitly constructed open KG. HippoRAG 2 is closely inspired by HippoRAG, which allows it to perform very well on multi-hop QA tasks. However, its more comprehensive integration of passages, queries, and triples allows it to have a more comprehensive performance across sense-making and factual memory tasks as well."}, {"title": "3. HippoRAG 2", "content": ""}, {"title": "3.1. Overview", "content": "HippoRAG (Guti\u00e9rrez et al., 2024) is a neurobiologically inspired long-term memory framework for LLMs, with each component designed to emulate aspects of human memory. The framework consists of three primary components: the artificial neocortex (LLM), the parahippocampal region (PHR encoder), and the artificial hippocampus (open KG). These components collaborate to replicate the interactions observed in human long-term memory.\nFor HippoRAG offline indexing, an LLM processes passages into KG triples, which are then incorporated into the artificial hippocampal index. Meanwhile, the PHR is responsible for detecting synonymy to interconnect information. For HippoRAG online retrieval, the LLM neocortex extracts named entities from a query, while the PHR encoder link these entities to the hippocampal index. Then, the Personalized PageRank (PPR) algorithm on the KG is conducted for context-based retrieval. Although HippoRAG seeks to construct memory from non-parametric RAG, its effectiveness is hindered by a critical flaw: an entity-centric approach that causes context loss during both indexing and inference, as well as difficulties in semantic matching.\nBuilt on the neurobiologically inspired long-term memory framework proposed in HippoRAG (Guti\u00e9rrez et al., 2024), the structure of HippoRAG 2 follows a similar two-stage process: offline indexing and online retrieval, as shown in Figure 2. Additionally, however, HippoRAG 2 introduces several key refinements that improve its alignment with"}, {"title": "3.2. Dense-Sparse Integration", "content": "The nodes in the HippoRAG KG primarily consist of phrases describing concepts, which we refer to as phrase nodes in this paper. This graph structure introduces limitations related to the concept-context tradeoff. Concepts are concise and easily generalizable but often entail information loss. In contrast, context provide specific circumstances that shape the interpretation and application of these concepts, enriching semantics but increasing complexity. However, in human memory, concepts and contexts are intricately interconnected. The dense and sparse coding theory offers insights into how the brain represents and processes information at different granularities (Beyeler et al., 2019). Dense coding encodes information through the simultaneous activation of many neurons, resulting in a distributed and redundant representation. Conversely, sparse coding relies on minimal"}, {"title": "3.3. Deeper Contextualization", "content": "Building upon the discussion of the concept-context tradeoff, we observe that query parsing in HippoRAG, which relies on Named Entity Recognition (NER), is predominantly concept-centric, often overlooking the contextual alignment within the KG. This entity-focused approach to extraction and indexing introduces a strong bias toward concepts, leaving many contextual signals underutilized (Guti\u00e9rrez et al., 2024). To address this limitation, we explore and evaluate different methods for linking queries to the KG, aiming to more effectively align query semantics with the starting nodes of graph searches. Specifically, we consider three approaches: 1) NER to Node: This is the original method used in HippoRAG, where entities are extracted from the query and subsequently matched with nodes in the KG using text embeddings. 2) Query to Node: Instead of extracting individual entities, we leverage text embeddings to match the entire query directly to nodes in the KG. 3) Query to Triple: To incorporate richer contextual information from the KG, we match the entire query to triples within the graph using text embeddings. Since triples encapsulate fundamental contextual relationships among concepts, this method provides a more comprehensive understanding of the query's intent. By default, HippoRAG 2 adopts the query-to-triple approach, and we evaluate all three methods later (\u00a76.1)."}, {"title": "3.4. Recognition Memory", "content": "Recall and recognition are two complementary processes in human memory retrieval (Uner & Roediger III, 2022). Recall involves actively retrieving information without external cues, while recognition relies on identifying information"}, {"title": "3.5. Online Retrieval", "content": "We summarize the online retrieval process in HippoRAG 2 after introducing the above improvements. The task involves selecting seed nodes and assigning reset probabilities for retrieval. HippoRAG 2 identifies phrase nodes from filtered triples generated by query-to-triple and recognition memory. If no triples are available, it directly retrieves top-ranked passages using the embedding model. Otherwise, up to k phrase nodes are selected based on their average ranking scores across filtered triples they originate. All passage nodes are also taken as seed nodes, as broader activation improves multi-hop reasoning. Reset probabilities are assigned based on ranking scores for phrase nodes, while passage nodes receive scores proportional to their embedding similarity, adjusted by a weight factor (\u00a76.2) to balance the influence between phrase nodes and passage nodes."}, {"title": "4. Experimental Setup", "content": ""}, {"title": "4.1. Baselines", "content": "We select three types of comparison methods: 1) The classic retrievers BM25 (Robertson & Walker, 1994), Contriever (Izacard et al., 2022) and GTR (Ni et al., 2022). 2) Large embedding models that perform well on the BEIR leaderboard (Thakur et al., 2021), including Alibaba-NLP/GTE-Qwen2-7B-Instruct (Li et al., 2023), GritLM/GritLM-7B (Muennighoff et al., 2024), and nvidia/NV-Embed-v2 (Lee et al., 2025). 3) Structure-augmented RAG methods, including RAPTOR (Sarthi et al., 2024), GraphRAG (Edge et al., 2024), LightRAG (Guo et al., 2024), and HippoRAG (Guti\u00e9rrez et al., 2024)."}, {"title": "4.2. Datasets", "content": "To evaluate how well RAG systems retain factual memory while enhancing associativity and sense-making, we select datasets that correspond to three critical challenge types: 1) Simple QA primarily evaluates the ability to recall and retrieve factual knowledge accurately. 2) Multi-hop QA measures associativity by requiring the model to connect multiple pieces of information to derive an answer. 3) Discourse understanding evaluates sense-making by testing the"}, {"title": "4.3. Metrics", "content": "Following HippoRAG (Guti\u00e9rrez et al., 2024), we use passage recall@5 to evaluate the retrieval task. For the QA task, we follow evaluation metrics from MuSiQue (Trivedi et al., 2022) to calculate F1 scores for the final answer."}, {"title": "4.4. Implementation Details", "content": "For HippoRAG 2, we use the open-source Llama-3.3-70B-Instruct (AI@Meta, 2024) as both the extraction (NER and OpenIE) and triple filtering model, and we use nvidia/NV-Embed-v2 as the retriever. We also reproduce the compared structure-augmented RAG methods using the same extractor and retriever for a fair comparison. For the triple filter, we use DSPy (Khattab et al., 2024) MIPROv2 optimizer and Llama-3.3-70B-Instruct to tune the prompt, including the instructions and demonstrations."}, {"title": "5. Results", "content": "We now present our main QA and retrieval experimental results, where the QA process uses retrieved results as its context. QA Performance. HippoRAG 2 achieves the highest average F1 score, demonstrating robustness across different settings. ."}, {"title": "6. Discussions", "content": ""}, {"title": "6.1. Ablation Study", "content": "We design ablation experiments for the proposed linking method, graph construction method, and triple filtering method. Each introduced mechanism boosts HippoRAG 2. query-to-triple improves Recall@5 by 12.5% compared to NER-to-node. over NER-to-node."}, {"title": "6.2. Controlling Reset Probabilities", "content": "When setting the reset probability before starting PPR, we find that it is necessary to balance the reset probabilities between two types of nodes: phrase nodes and passage nodes. is multiplied by a weight factor to balance the importance of"}, {"title": "6.3. Dense Retriever Flexibility", "content": "The dense retriever employed by HippoRAG 2 is fully plug-and-play, offering seamless integration. HippoRAG 2 consistently surpasses direct dense retrieval used."}, {"title": "6.4. Qualitative Analysis", "content": "We show examples from PopQA and MuSiQue in Table 7."}, {"title": "7. Conclusion", "content": "We introduced HippoRAG 2, a novel framework designed to address the limitations of existing RAG systems in approximating the dynamic and interconnected nature of human"}, {"title": "Impact Statement", "content": "This paper presents work on Retrieval-Augmented Gener-ation (RAG) to advance the field of long-term memory forlarge language models. While our work may have varioussocietal implications, we do not identify any concerns thatwarrant specific emphasis beyond those generally asso-ciated with large language models and information retrievalsystems."}, {"title": "Appendices", "content": "Within this supplementary material, we elaborate on the following aspects:\n\u2022 Appendix A: LLM Prompts\n\u2022 Appendix B: HippoRAG 2 Pipeline Example\n\u2022 Appendix C: Detailed Experimental Results\n\u2022 Appendix D: Graph Statistics\n\u2022 Appendix E: Error Analysis\n\u2022 Appendix F: Cost and Efficiency\n\u2022 Appendix G: Implementation Details and Hyperparameters"}, {"title": "A. LLM Prompts", "content": "We show LLM prompts for triple filter in Figure 3, including the instruction, the few-shot demonstrations and the inputformat."}, {"title": "B. Pipeline Example", "content": "We show a pipeline example of HippoRAG 2 online retrieval in Figure 4, including query-to-triple, triple filtering and usingseed nodes for PPR."}, {"title": "C. Detailed Experimental Results", "content": "We show QA performance and retrieval performance with the proprietary model GPT-40-mini as well as more metrics here,as shown in Table 8 and Table 9."}, {"title": "QA Performance", "content": "As shown in Table 8, when using GPT-40-mini for indexing and QA reading, HippoRAG 2 consistentlyachieves competitive EM and F1 scores across most datasets. Retrieval Performance"}, {"title": "D. Graph Statistics", "content": "We show the knowledge graph statistics using Llama-3.3-70B-Instruct or GPT-40-mini for OpenIE in Table 10."}, {"title": "E. Error Analysis", "content": "We provide an error analysis of 100 samples generated by HippoRAG 2 with recall@5 less than 1.0.Triple filtering and the graph searchalgorithm are the two main sources of errors."}, {"title": "Recognition Memory", "content": "In 7% of the samples, no phrase from the supporting documents is matched with the phrases obtainedby the query-to-triple stage before triple filtering. Overall, thoughrecognition memory is an essential component, the precision of the triple filter has room for further improvement."}, {"title": "Graph Construction", "content": "Graph construction is challenging to evaluate, but we find that only 2% of the samples do not containany phrases from the supporting passages within the one-hop neighbors of the linked nodes."}, {"title": "Personalized PageRank", "content": "In 50% of the samples, at least half of the linked phrase nodes appear in the supporting documents."}, {"title": "F. Cost and Efficiency", "content": "For LLM deployment, we run Llama-3.3-70B-Instruct on a machine equipped with four NVIDIA H100 GPUs, utilizingtensor parallelism via vLLM"}, {"title": "Comparison With Structure-Augmented RAG Methods", "content": "We count the token usage across different structure-augmentedRAG methods when indexing the MuSiQue corpus using the Llama-3.3-70B-Instruct model, and we compare the number ofinput and output tokens against"}, {"title": "G. Implementation Details and Hyperparameters", "content": ""}, {"title": "G.1. HippoRAG 2", "content": "We provide a detailed explanation of the PPR initialization process used in HippoRAG 2 here. The key goal is to determinethe seed nodes for the PPR search and assign appropriate reset probabilities to ensure an effective retrieval process."}]}