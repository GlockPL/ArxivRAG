{"title": "Covariance-based Space Regularization for Few-shot Class Incremental Learning", "authors": ["Yijie Hu", "Guanyu Yang", "Zhaorui Tan", "Xiaowei Huang", "Kaizhu Huang", "Qiu-Feng Wang"], "abstract": "Few-shot Class Incremental Learning (FSCIL) presents a challenging yet realistic scenario, which requires the model to continually learn new classes with limited labeled data (i.e., incremental sessions) while retaining knowledge of previously learned base classes (i.e., base sessions). Due to the limited data in incremental sessions, models are prone to overfitting new classes and suffering catastrophic forgetting of base classes. To tackle these issues, recent advancements resort to prototype-based approaches to constrain the base class distribution and learn discriminative representations of new classes. Despite the progress, the limited data issue still induces ill-divided feature space, leading the model to confuse the new class with old classes or fail to facilitate good separation among new classes. In this paper, we aim to mitigate these issues by directly constraining the span of each class distribution from a covariance perspective. In detail, we propose a simple yet effective covariance constraint loss to force the model to learn each class distribution with the same covariance matrix. In addition, we propose a perturbation approach to perturb the few-shot training samples in the feature space, which encourages the samples to be away from the weighted distribution of other classes. Regarding perturbed samples as new class data, the classifier is forced to establish explicit boundaries between each new class and the existing ones. Our approach is easy to integrate into existing FSCIL approaches to boost performance. Experiments on three benchmarks validate the effectiveness of our approach, achieving a new state-of-the-art performance of FSCIL.", "sections": [{"title": "1. Introduction", "content": "Provided with a substantial amount of stationary data, recent advancements in deep learning have enabled neural networks to excel in classification tasks [9, 17, 30, 31, 35]. However, it is not feasible to directly deploy neural networks into the open world, where the data may emerge in a non-stationary way, such as recognizing new types of diseases or new vehicles in autonomous driving. Simply retraining or fine-tuning the model with new data introduces the well-known catastrophic forgetting problem [7, 24]. To address this challenge, Class Incremental Learning (CIL) has been extensively researched to broaden the application scope of neural networks [33, 52]. By simulating the scenario where disjoint new data appears in incremental sessions, CIL aims to learn new concepts without forgetting old knowledge.\n\nThe conventional CIL setting assumes the amount of new data is usually sufficient, which may not be realistic as labeling new data can be expensive. To handle this issue, few-shot class incremental learning (FSCIL) has attracted much attention recently, where only a few training samples from new classes are available during incremental sessions [18, 32, 47]. The framework of FSCIL typically involves two key stages. Initially, the model is trained on a base dataset, where all classes (referred to as base classes or old classes) contain sufficient instances. Subsequently, the"}, {"title": "2. Related Works", "content": "Few-shot Class Incremental Learning (FSCIL) involves the techniques of both class incremental learning and few-shot learning."}, {"title": "2.1. Class Incremental Learning", "content": "Class Incremental Learning (CIL) aims to learn new classes from a sequence of classification tasks without access to previously encountered data. The primary objective of CIL is to effectively learn new classes while minimizing the forgetting of old classes. Recent research in CIL can be broadly categorized into three approaches. The first and most straightforward method is to retain old data or knowledge during the learning process. Recent works [12, 26, 27, 50, 52] propose to mitigate the forgetting issue by rehearsing and generating previously retrained class data. Another common approach involves identifying key model parameters associated with previously learned classes and dynamically updating only the remaining parameters during incremental sessions [14, 20, 41, 45]. The third category focuses on addressing the bias inherent in CIL methods, which tend to favor the most recently learned classes [2, 11,40]."}, {"title": "2.2. Few-Shot Learning", "content": "Few-Shot Learning (FSL) aims to develop a classification model with very limited data. To generalize on few-shot classes, metric-based methods focus on learning a similarity metric that can effectively distinguish between classes with minimal examples [28, 34, 37, 46]. Hallucination-based approaches utilize data augmentation techniques, such as geometric transformations, style transfer and statistical augmentations, to increase the amount of training data [3, 8, 39, 43]."}, {"title": "2.3. Few-Shot Class Incremental Learning", "content": "Few-Shot Class Incremental Learning (FSCIL) aims to learn new classes with limited incoming data in an incremental manner [32, 44, 47, 49, 51]. TOPIC [32] first introduces this setting and employs a neural gas algorithm to preserve the topology in the embedding space. To address the challenge of limited data in incremental sessions, prototype learning [19, 28, 42] has been widely adopted in FSCIL to enhance the model's generalization to new or unseen data. To mitigate the catastrophic forgetting of old classes, recent studies [10, 44, 47] propose freezing the feature extraction backbone after training the base sessions and computing new class prototypes during incremental sessions. To learn more representative prototypes, Zhu et al. [53] introduces a self-promoted prototype refinement mechanism to develop extensible feature representations in the base session. LDC [21] utilizes a recurrent calibration module to learn new prototypes from sampled data, though this can be inefficient due to its recurrent nature. Unlike previous methods, our approach boosts FSCIL by regularizing the feature space for the few-shot new classes."}, {"title": "3. Methodology", "content": "In this section, we first give the problem formulation of FSCIL in Sec. 3.1. We then describe our proposed FSCIL method in detail via two sections, i.e., Covariance Constraint Loss (CCL) in Sec. 3.3 and Semantic Perturbation Learning (SPL) in Sec. 3.4, respectively."}, {"title": "3.1. Preliminaries", "content": ""}, {"title": "3.1.1 Problem Formulation", "content": "FSCIL aims to train a classification model with T sequential sessions {$\\mathcal{D}^0, \\mathcal{D}^1, . . ., \\mathcal{D}^T$}, where $\\mathcal{D}^t = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{D_t}$ is the training dataset at the t-th session. $\\mathbf{x}_i$ is the i-th input sample and its label $y_i \\in \\mathcal{C}^t$. The label space $\\mathcal{C}^t$ of dataset $\\mathcal{D}^t$ is disjoint between different sessions, i.e., $\\forall t_1 \\neq t_2, \\mathcal{C}^{t_1} \\cap \\mathcal{C}^{t_2} = \\emptyset$. The first session $\\mathcal{D}^0$ is called the base session, which usually contains a sufficient amount of training samples for each old class $c \\in \\mathcal{C}^0$. In the next incremental session $\\mathcal{D}^t$, there are N new classes with K training samples (usually 1 or 5 samples) in each class, formulating a N way K shot problem, i.e. $|\\mathcal{D}^{t}| = N \\cdot K$. In the t-th session, previous datasets {$\\mathcal{D}^0, \\mathcal{D}^1, ..., \\mathcal{D}^{t-1}$} are not available, the model can only access the data in $\\mathcal{D}^t$. After training in session t, the model is evaluated on all seen classes $\\mathcal{C}_t = \\mathcal{C}^0 \\cup \\mathcal{C}^1 \\cup ... \\cup \\mathcal{C}^t$."}, {"title": "3.1.2 Prototype-based Model", "content": "Researchers [28, 29, 49, 54] commonly adopt the prototype-based framework in FSCIL, where classifier weights are treated as prototypes. During the base session, given the feature extractor $f_{\\theta} : \\mathbf{x} \\rightarrow \\mathbf{x} \\in \\mathbb{R}^d$ and the classifier $\\mathbf{W}^0 = \\{\\mathbf{w}_1^0, \\mathbf{w}_2^0,...,\\mathbf{w}_{C_0}^0\\}$, the model is trained using the cross-entropy loss:\n\n$\\mathcal{L}_{ce}(\\mathbf{x}, y) = \\mathbb{E}_{(\\mathbf{x}, y) \\sim \\mathcal{D}^0} -\\log p(y = c \\mid \\mathbf{x}^\\theta),$\n\nwhere $\\mathbf{x}^\\theta = f_{\\theta}(\\mathbf{x})$ denotes the extracted feature, $p(y = c \\mid \\mathbf{x})$ computes the confidence score of each sample using softmax of the cosine similarities:\n\n$p(y = c \\mid \\mathbf{x}) = \\frac{\\exp{(\\cos(\\mathbf{w}_c, \\mathbf{x}'))}}{\\sum_{c=1}^{C_0} \\exp{(\\cos(\\mathbf{w}_c, \\mathbf{x}'))}}.$\n\nFor each incremental session t > 0, the feature extractor $f_{\\theta}$ is frozen, and the classifier is updated by adding new class prototypes: $\\mathbf{W}^t = \\{\\mathbf{w}_1^0, \\mathbf{w}_2^0,...,\\mathbf{w}_{C_0}^0\\} \\cup \\{\\mathbf{w}_1^t ..., \\mathbf{w}_{C_t}^t\\}$, where each new class prototype is computed by averaging samples from its corresponding class:\n\n$\\mathbf{w}_{c}^{t} = \\frac{1}{\\mid D_t\\mid} \\sum_{i=1}^{\\mid D_t\\mid} f_{\\theta}(\\mathbf{x}_i^t).$"}, {"title": "3.2. Overview of the Framework", "content": "Our framework follows the two-stage learning procedure in most of recent works [10, 18, 44], which begins with pre-training the model using the base classes. The pretraining stage is called the base session, where we integrate"}, {"title": "3.3. Covariance Constraint Loss", "content": "Recent wisdom [5, 29, 55] has demonstrated a good pretrained model benefits the learning of incoming few-shot new classes. The common attempt in recent works is to learn very compact base class representations by pushing data to the learned prototypes via fantasizing new classes or metric-based classification losses [18, 29, 49]. However, simply pushing the data close to the class centroid does not explicitly constrain the span of each class distribution, which may lead to representation confusion when learning new classes (Fig. 1(a)). Hence, we apply a covariance constraint to each base class during training, ensuring distinct means but identical covariance across classes, as shown in Fig. 2(a).\n\nIn order to constrain the covariance of each distribution, it is vital to estimate base class distributions $p(x, y)$. However, it is generally computational intractable. To solve this issue, previous works [6, 15, 16] adopt the variational inference, which involves a parametric posterior function $q_{\\phi}(z|x, y)$ to approximate the true posterior by maximizing the evidence lower bound (ELBO):\n\n$\\log p_{\\theta} (x, y)$\n\n$= \\log p_{\\theta} (y \\mid x) + \\log p_{\\theta} (z) + \\log \\frac{p_{\\theta}(x \\mid z)}{p_{\\theta}(z \\mid x)}$\n\n$= \\log p_{\\theta} (y \\mid x) + \\log p_{\\theta} (z) + \\log \\int q_{\\phi}(z \\mid x, y) \\{\\log \\frac{p_{\\theta} (x \\mid z)}{p_{\\theta} (z \\mid x)} \\} dz$\n\n$= \\int q_{\\phi}(z \\mid x, y) \\{\\log p_{\\theta} (y \\mid x) - \\log \\frac{q_{\\phi}(z \\mid x, y)}{p_{\\theta}(z)} + \\log \\frac{q_{\\phi}(z \\mid x,y)p_{\\theta} (x \\mid z)}{p_{\\theta} (z \\mid x)} \\} dz$\n\n$\\geq \\mathbb{E}_{q_{\\phi}(z|x,y)}[\\log p_{\\theta} (y \\mid x)] - D_{KL} \\Big[q_{\\phi} (z \\mid x, y) || p_{\\theta}(z)\\Big],$\n\nwhere $\\phi$ and $\\theta$ are modeled by neural networks. The first term in Eq. (4) aims to maximize the likelihood by improving the confidence of the prediction. When optimizing the first term, the optimizing process can be written as\n\n$\\underset{q_{\\phi} (z \\mid x,y)}{\\arg \\max} \\int \\sum_y p(x,y) q_{\\phi}(z \\mid x, y) \\log p_{\\theta} (y \\mid x)$\n\n$= \\underset{q_{\\phi} (z \\mid x,y)}{\\arg \\max} \\int \\sum_y p(x) q(z \\mid x, y) p(y \\mid x) \\log p_{\\theta} (y \\mid x).$\n\nAs $q(z \\mid x, y)$ is a probability distribution, the integral is upper bounded by $\\max \\sum_y p(y \\mid x) \\log p_{\\theta}(y \\mid x)$, which is equivalent to minimizing the cross entropy loss in Eq. (1). The second KL divergence minimizes the divergence be-"}, {"title": "3.4. Semantic Perturbation Learning", "content": "In order to prevent the model from overfitting the few-shot new classes during incremental sessions, recent approaches [10, 18, 29] attempt to freeze the feature extractor"}]}