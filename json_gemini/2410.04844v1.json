{"title": "POSTEDIT: POSTERIOR SAMPLING FOR EFFICIENT\nZERO-SHOT IMAGE EDITING", "authors": ["Feng Tian", "Yixuan Li", "Yichao Yan", "Shanyan Guan", "Yanhao Ge", "Xiaokang Yang"], "abstract": "In the field of image editing, three core challenges persist: controllability, back-\nground preservation, and efficiency. Inversion-based methods rely on time-\nconsuming optimization to preserve the features of the initial images, which re-\nsults in low efficiency due to the requirement for extensive network inference.\nConversely, inversion-free methods lack theoretical support for background simi-\nlarity, as they circumvent the issue of maintaining initial features to achieve effi-\nciency. As a consequence, none of these methods can achieve both high efficiency\nand background consistency. To tackle the challenges and the aforementioned dis-\nadvantages, we introduce PostEdit, a method that incorporates a posterior scheme\nto govern the diffusion sampling process. Specifically, a corresponding measure-\nment term related to both the initial features and Langevin dynamics is introduced\nto optimize the estimated image generated by the given target prompt. Extensive\nexperimental results indicate that the proposed PostEdit achieves state-of-the-art\nediting performance while accurately preserving unedited regions. Furthermore,\nthe method is both inversion- and training-free, necessitating approximately 1.5\nseconds and 18 GB of GPU memory to generate high-quality results. Code is\navailable at https://github.com/TFNTF/PostEdit.", "sections": [{"title": "INTRODUCTION", "content": "Large text-to-image diffusion models Saharia et al. (2022); Pernias et al. (2024); Podell et al. (2024);\nRamesh et al. (2022) have demonstrated significant capabilities in generating photorealistic images\nbased on given textual prompts, facilitating both the creation and editing of real images. Current\nresearch Cao et al. (2023); Brack et al. (2024); Ju et al. (2024); Parmar et al. (2023); Wu & la Torre\n(2022); Xu et al. (2024) highlights three main challenges in image editing: controllability, back-\nground preservation, and efficiency. Specifically, the edited parts must align with the target prompt's\nconcepts, while unedited regions should remain unchanged. Additionally, the editing process must\nbe sufficiently efficient to support interactive tasks. There are two mainstream categories of image\nediting approaches, namely inversion-based and inversion-free methods, as illustrated in Fig. 1.\nInversion-based approaches Song et al. (2021a); Mokady et al. (2023); Wu & la Torre (2022);\nHuberman-Spiegelglas et al. (2024) progressively add noise to a clean image and then remove the\nnoise conditioned on a given target prompt, utilizing large text-to-image diffusion models (i.e. Stable\nDiffusion Rombach et al. (2022)), to obtain the edited image. However, directly inverting the diffu-\nsion sampling process (e.g., DDIM Song et al. (2021a)) for reconstruction introduces bias from the\ninitial image due to errors accumulated by an unconditional score term, as discussed in classifier-free\nguidance (CFG) Ho & Salimans (2022) and proven in App. A.1. Consequently, the editing quality\nof inversion-based methods is primarily constrained by the similarity in unedited regions. Several\napproaches address this issue by optimizing the text embedding Wu et al. (2023), employing iter-\native guidance Kim et al. (2022); Garibi et al. (2024), or directly modifying attention layers Hertz\net al. (2023); Mokady et al. (2023); Parmar et al. (2023) to mitigate the bias introduced by the un-\nconditional term. However, the necessity of adding and subsequently removing noise predicted by"}, {"title": "PRELIMINARIES", "content": "A continuous diffusion process as shown in Song et al. (2021b) is adopted in this paper to sample\nthe estimated initial image $x_0$. Specifically, the forward diffusion process can be modeled as the\nsolution to an It\u00f4 SDE:\n$$dx = f(x)dt + g_tdw,$$\nwhere $f$ is defined as the drift function and $g$ denotes the coefficient of noise term. Furthermore, the\ncorresponding reverse form of Eq. 2 can be written as\n$$dx = [f(x) - g_t\\nabla_x log p_t(x)] dt + g_tdw,$$\nwhere $w$ represents the standard Brownian motion. As shown in Song et al. (2021b), there exists a\ncorresponding deterministic process whose trajectories share the same marginal probability densities\nas the SDE according to Eq. 2. This deterministic process satisfies an ODE\n$$dx = (f(x) - \\frac{1}{2}g_t^2\\nabla_x log p_t(x)) dt.$$\nThe ODE is able to compute the exact likelihood of any input data by leveraging the connection to\nneural ODEs Chen et al. (2018). In order to approximate the log density of noised data distribution\n$\\nabla_x log p_t(x)$ for each sampling step, a network Song et al. (2021b) $s_\\theta(x_t, t)$ is trained to learn the\ncorresponding log density\n$$E_{x_0,x_t~p(x_t|x_0)} [||s_\\theta(x_t, t) - \\nabla_x log p(x_t|x_0)||^2].$$"}, {"title": "DDIM SOLVER AND CONSISTENCY MODELS", "content": "The DDIM solver is widely applied in training large text-to-image diffusion models. The iterative\nscheme for sampling the previous step is defined as follows\n$$x_{t-1} = \\frac{\\sqrt{\\alpha_{t-1}}}{\\sqrt{\\alpha_t}} (x_t - \\sqrt{1 - \\alpha_t}\\epsilon_\\theta(x_t, t)) + \\sqrt{1 - \\alpha_{t-1}}\\epsilon_0(x_t, t),$$\nwhere $\\epsilon_\\theta(x_t, t)$ is the predicted noise from the network. According to Eq. 6, the sampling process\ncan be regarded as first estimating a clean image $x_0$, and then using the forward process of the\ndiffusion models with noise predicted by the network to the previous step $x_{t-1}$. Therefore, the\npredicted original sample $\\hat{x}_0$ is defined as\n$$\\hat{x}_0 = \\frac{x_t - \\sqrt{1 - \\alpha_t}\\epsilon_\\theta(x_t, t)}{\\sqrt{\\alpha_t}}.$$"}, {"title": "POSTERIOR SAMPLING IN DIFFUSION MODELS", "content": "After obtaining $s_\\theta(x_t,t)$, we can infer an unknown $x \\in \\mathbb{R}^d$ through the degraded measurement\n$y \\in \\mathbb{R}^n$. Specifically, in the forward process, it is well-posed since the mapping $x \\rightarrow y : \\mathbb{R}^d \\rightarrow \\mathbb{R}^n$\nis many-to-one, while it is ill-posed for the reverse process since it is one-to-many when sampling\nthe posterior $p(x_0|y)$, where it can not be formulated as a functional relationship. To deal with this\nproblem, the Bayes rule is applied to the log density terms and we can derive that\n$$\\nabla_{x_t} log p(x_t|y) = \\nabla_{x_t} log p(x_t) + \\nabla_{x_t} log p(y|x_t),$$\nwhere the first term in the right side hand of the equation is the pre-trained diffusion model and\nthe second one is intractable. The measurement $y$ can be regarded as a vital term that contains the\ninformation of the prior $p(x)$, which supervises the generation process towards the input images.\nIn order to work out the explicit expression of the second term, existing method DPS Chung et al.\n(2023) presents the following approximation\n$$p(y|x_t) = E_{x_0~p(x_0|x_t)}[p(y|x_0)] \\approx p(y|\\hat{x}_0)\n= E_{x_0~p(x_0|x_t)}[\\hat{x}_0],$$\nwhere the Bayes optimal posterior $\\hat{x}_0$ can be obtained from a given pre-trained diffusion models\nor Tweedie's approach to iterative descent gradient for the case of VP-SDE or DDPM sampling.\nHence, each step can be written as $p(x_{t-1}|x_t, y)$ according to Eq. 10.\nWhen the transition kernel is defined, since the solvers utilize the unconditional scores to estimate\n$\\hat{x}_0$, the measurement term is then introduced through a gradient descent way to optimize $x$\n$$x_{t-1} = f (x_t, \\hat{x}_0, \\epsilon) + \\eta\\nabla_{x_t} ||y - A(\\hat{x}_0)||^2, \\epsilon ~ \\mathcal{N} (0, I),$$\nwhere the function $f$ is defined as the approximation of the unconditional counterpart of\n$p(x_{t-1}|x_t, y)$ and $\\eta$ denotes the learning rate."}, {"title": "METHOD", "content": "We propose a new sampling process equipped with a designed optimization process to improve the\nquality of image reconstruction and editing, and the adopted SDE/ODE solver is based on DDIM\nshown in Eq. 6. Denote $z \\sim \\mathcal{E}(x_0), z \\in \\mathbb{R}^p$ where $\\mathcal{E}$ is an encoder and $x_0$ is an initial image.\nOur method operates in latent space and leverages the theory of the posterior sampling to correct\nthe bias from the initial features and introduce the target concepts. The core insight is using the\nmeasurements $y$, estimated $\\hat{x}_0$ and Langevin dynamics as the optimization terms to correct the\nerrors of the sampling process. The importance of reconstruction and the algorithm are introduced\nspecifically in (Sec. 3.1). The implementation details of the editing process are illustrated in detail\n(Sec. 3.2). Our method takes around 1.5 seconds and 18 GB memory costs on a single NVIDIA\nA100 GPU."}, {"title": "POSTERIOR SAMPLING FOR IMAGE RECONSTRUCTION", "content": "The quality of reconstruction is a crucial indicator for evaluating the editing capabilities of a method.\nTo preserve the features of the background (areas unaffected by the target prompt), Mokady et al."}, {"title": "PROOF OF PROPOSITION 2", "content": "According to Eq. 14, the distribution of $z_{t-1}$ depends on $z_t$ and $\\hat{z}_0$. The marginal distribution\nrelating to timestep $t - 1$ can be rewritten by Proof. We first factorize the measurement conditioned\ntime-marginal $p (z_{t2} | y)$ by\n$$p(z_{t-1} | y, c) = \\int\\int P(z_{t-1}, z_0, z_t | y) dz_0 d\\hat{z}_t\n= \\int\\int p(z_t | y, c) p (\\hat{z}_0 | z_t, y, c) p (z_{t-1} | \\hat{z}_0, z_t, y, c) dz_0 d\\hat{z}_t,$$\naccording to the proposition 1, the above equation can be written as\n$$p(z_{t-1} | y, c) = \\int\\int p(z_t | y, c) p (\\hat{z}_0 | z_t, y, c) p (\\hat{z}_0 | z_t, y, c) P (z_{t-1} | \\hat{z}_0, z_t, y, c) dz_0 d\\hat{z}_t\n= \\int\\int p (z_t | y, c) p (\\hat{z}_0 | z_t, y, c) p |z_t, y, c) P (z_{t-1} |\\hat{z}_0) d \\hat{z}_0 dzt\np (z_t | y) p (\\hat{z}_0 | z_t, y, c) p (z_{t-1} | \\hat{z}_0, z_t, y) d \\hat{z}_0\n= \\int\\int p (z_t | y) [(1 - w) \\cdot p (z_0 | z_t, y, c) + w \\cdot p (z_{in} | z_t, y)]\np (z_{t-1} | (1 - w) \\cdot z_0, z_t, y) d ((1 - w) \\cdot z_0 + w \\cdot z_{in}) dzt\n= \\int\\int p (z_t | y) p ((1 - w) \\cdot z_0 | z_t, y, c)\np (z_{t-1} | (1 - w) \\cdot z_0, z_t, y) d ((1 - w) \\cdot z_0) dzt\n= \\int\\int p(z_t | y) p (\\hat{z}_0 | z_t, y, c) p (z_{t-1} | z_0, z_t, y) dz_0 dzt\n= \\int\\int p(z_t | y) p (z_0 | z_t, y, c) p (z_{t-1} | z_0) dz_0 dzt\n= E_{z_t~p(z_t|y)}E_{z_0~p(z_0z_t|,y,c)} p (z_{t-1} | z_0)\n= E_{z_0~p(z_0 | z_t, y, c)}N (z_{t-1};z_0, \\sigma^2_{t-1}I),$$\nwhere (i) is dues to independent relationships and (ii) is derived by variable substitution and c is\nthe given target prompt. (iii) is derived directly according to the process defined in Eq. 15, whose\nindependent variant is substituted by $\\hat{z}_0$ instead of $\\hat{z}_w$."}, {"title": "IMPLEMENTATION DETAILS", "content": "GPU. All our experiments are performed on a single NVIDIA A100 GPU with 80GB memory.\nParameters in Alg. 1. N is set to 5 for schedule $\\{T_i\\}_{i=1}^N$. For better quality of editing, we sometimes\nsample $z_N$ by\n$$z_N ~ \\mathcal{N} (\\sqrt{\\bar{\\alpha}_t}z_0, \\sqrt{1 - \\bar{\\alpha}_t}I),$$\nwhere t is set to 501 generally according to the DDPM schedule Ho et al. (2020). The reconstruction\nprocess is not restricted to this setting. For Eq. 16, m is set as 0.01 for both the reconstruction and\nediting task while $\\sigma_t^2$ can be referred to the corresponding timestep of DDPM scheduler Ho et al.\n(2020). Generally, we apply Eq. 8 for 1 step to estimate $\\hat{z}_0$, and then according to the following\nschedule to make $z_{T_i}$ progressively converge to $\\hat{z}_0$.\n$$\\{T_i\\}_{i=1}^N = \\{501, 401, 301, 201, 101,1\\}.$$\nThe parameter w is usually set to a minimal value such as 0.05 for most cases or 0 and 0.1 for easy\nand hard cases. Additionally, h is always set to 1e-5 for image edting and reconstruction tasks."}, {"title": "POSTERIOR SAMPLING FOR IMAGE EDITING", "content": "In this section, we provide a detailed illustration of the sampling process for high-quality image\nediting using the DDIM solver Luo et al. (2023a), as shown in Eq. 6. Unlike the ODE solver and\nmeasurement y used in the image reconstruction task described in Sec. 3.1, image editing requires a\nmasked measurement derived from $\\hat{z}_0$ and an ODE solver with higher accuracy to estimate $\\hat{z}_0$. The\nmeasurement y for image editing is defined as\n$$y ~ \\mathcal{N} (Pz, \\sigma^2I),$$\nwhere $P \\in \\{0,1\\}^{n\\times p}$ represents a masking matrix composed of elementary unit vectors. This mea-\nsurement setup not only serves as a specialized configuration for image editing but also demonstrates\nits capacity to deliver high-quality image reconstruction results, even when $\\hat{z}_0$ is masked. The set-\ntings in Eq.17 have been validated to yield high-quality reconstruction results, as shown in Sec.4.4,\nproviding strong evidence of the method's ability to preserve the features of the initial image.\nFurthermore, to minimize the number of sampling steps, improving the accuracy of the estimated\n$\\hat{z}_0$ is crucial. We employ the LCM solver Luo et al. (2023a) to predict $\\hat{z}_0$ from the noised input\nimage $z_T$ less than 4 steps, where the LCM is distilled from the models based on the DDIM solver.\nExperimental results show that the superior denoising capabilities of the LCM solver significantly\naccelerate the convergence rate and produce more accurate $\\hat{z}_0$ estimates that align with the target\nprompt. The measurement characteristics y, as defined in Eq.17, involve randomly masking each\nelement of $z_0$ with a probability p. Since one of the optimization terms focuses on only a small\nportion of the initial image, both terms in Eq.16 guide the gradient descent in the same direction.\nAs the sampling process progresses, the edited $x_{tgt}$ gradually inherits features from both $x$ and the\ntarget prompt by selectively replacing the necessary attributes. The experimental results of different\nsettings for the optimization defined in Eq.16 are presented in Sec.4.4. The rest of the process\nmirrors the reconstruction phase, allowing us to progressively achieve the edited $\\hat{z}_0$. In summary,\nthe algorithm's procedure is detailed in Alg. 1, with implementation specifics provided in App.A.4."}]}