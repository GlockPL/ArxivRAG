{"title": "Make Shuffling Great Again: A Side-Channel Resistant Fisher-Yates Algorithm for Protecting Neural Networks", "authors": ["Leonard Pu\u0161k\u00e1\u010d", "Marek Benovi\u010d", "Jakub Breier", "Xiaolu Hou"], "abstract": "Neural network models implemented in embedded devices have been shown to be susceptible to side-channel attacks (SCAs), allowing recovery of proprietary model parameters, such as weights and biases. There are already available counter-measure methods currently used for protecting cryptographic implementations that can be tailored to protect embedded neural network models. Shuffling, a hiding-based countermeasure that randomly shuffles the order of computations, was shown to be vulnerable to SCA when the Fisher-Yates algorithm is used. In this paper, we propose a design of an SCA-secure version of the Fisher-Yates algorithm. By integrating the masking technique for modular reduction and Blakely's method for modular multiplication, we effectively remove the vulnerability in the division operation that led to side-channel leakage in the original version of the algorithm. We experimentally evaluate that the countermeasure is effective against SCA by implementing a correlation power analysis attack on an embedded neural network model implemented on ARM Cortex-M4. Compared to the original proposal, the memory overhead is 2\u00d7 the biggest layer of the network, while the time overhead varies from 4% to 0.49% for a layer with 100 and 1000 neurons, respectively.", "sections": [{"title": "I. INTRODUCTION", "content": "Neural network (NN) implementations have become increasingly deployed in embedded devices, being used for various applications from autonomous vehicles to smart IoT devices. While these deployments offer great computational efficiency and real-time performance, they also introduce vulnerability to hardware-based attacks such as side-channel attacks (SCAs) [1]. SCAs exploit physical emanations, such as power consumption, electromagnetic leaks, or timing variations to extract the sensitive values used during the computation [2]. Such physical emanations, commonly referred to as leakages, can lead to the compromise of intellectual property by revealing model parameters \u2013 weights and biases [3]. As the area of hardware security has been researched for decades in the field of cryptography, it is natural to assess which protection techniques can be adapted for NN implementations. Masking, while providing strong security guarantees, incurs significant overhead when applied to the whole network [4]. The number of parameters in NNs, ranging to millions, naturally calls for lightweight countermeasures that do not significantly increase the required memory or execution time. This is especially true for embedded applications running on resource-constrained computing units. Hiding-based countermeasures, such as shuffling, on the other hand, can greatly increase the attacker's effort while keeping the overhead manageable even in embedded systems [2]. There have been several proposals to use shuffling for neural network implementations. Nozaki and Yoshikawa [5], and Brosch et al. [6] proposed a software-based shuffling of multiplications within a neuron to make the parameter recovery infeasible. The random shuffle algorithm that is commonly used in such cases is the Fisher-Yates algorithm [7] as it provides optimal O(n) time complexity and produces an unbiased permutation. However, it was shown by Ganesan et al. [8] that this shuffling method can be easily broken by an SCA targeting the division operation. They provided a way to reorder the parts of SCA traces back to the original order, thus allowing the parameter recovery. To counteract this attack, they proposed to realize the shuffling in hardware, avoiding the usage of the Fisher-Yates algorithm. While their method is secure and efficient, it requires an additional hardware implementation which is not an option for general-purpose microcontrollers. In this paper, we aim to overcome this limitation by developing a side-channel secure way to realize shuffling in software. Our contribution. In this paper, we investigate the possibility of using a shuffling-based countermeasure in software to shuffle the multiplications within a NN layer. As the original shuffling proposals in [5] and [6] leak the shuffling order via side-channels due to the usage of the Fisher-Yates algorithm [8], we alter the algorithm in a way that the attack shown in [8] is not possible anymore. Figure 1 shows a high-level depiction of the proposed protection. The timing overhead over the original method ranges from 4% for a single layer with 100 neurons and further reduces to 0.49% for a layer with 1000 neurons. As the masking itself requires additional storage, the memory overhead comprises two secret arrays of the size of the biggest layer in the network. To show that the proposed method does not influence the security level of the original Fisher-Yates shuffle, we experimentally evaluate this countermeasure proposal on a small network. This shows the best-case scenario for the attacker as the number of ways to shuffle such a network is limited. Our results, performed on an ARM Cortex-M4 processor measured with a ChipWhisperer Lite evaluation platform, show that the proposed shuffling method effectively thwarts the attacker's effort to recover model parameters. Organization. The rest of this paper is organized as follows. Section II provides the necessary background and overviews the related work. Section III presents the main idea of our shuffling-based countermeasure proposal. Section IV shows"}, {"title": "II. BACKGROUND", "content": "In this section, we will first give an overview of side-channel attacks and countermeasures. Later, we will detail the current state-of-the-art in the protection of NNs against side-channel attacks."}, {"title": "A. Side-Channel Attacks", "content": "SCAs are a class of cybersecurity threats that exploit indirect information leakage from a device rather than targeting its primary algorithmic or protocol vulnerabilities. These attacks utilize physical or behavioral characteristics generated during the sensitive computation, such as execution timing, power consumption, electromagnetic emanation, or cache activation to recover secret data. Originally, SCAs have been proposed for the recovery of cryptographic keys [1]. However, they can be used for recovering any kind of secret data used in the computation, such as parameters of machine learning models that are an intellectual property [3]. Generally, there are two types of SCA analysis methods: profiled and non-profiled. In the profiled setting, the attacker is assumed to possess an identical copy of the device under test (DUT), being able to build the model of the device with preliminary measurements. After this model is created, the attacker can then launch the actual attack on the DUT requiring only a few executions of the sensitive computation in the ideal case. In the non-profiled setting, the attacker only has the DUT in their possession, and therefore, launches the attack directly without creating the device model. One of the main non-profiled side-channel analysis methods is correlation power analysis (CPA) [9]. In CPA, the attacker first creates a set of hypotheses on a small part of the secret data this can be, for example, a byte. Then, the attacker measures the power consumption traces capturing the part of the execution utilizing that portion of the secret data while varying the non-secret input. Finally, a statistical correlation is calculated between the hypothetical power consumption (based on the hypotheses of the secret data) and the measured power traces. If the experimental setting is correct, for the correct hypothesis, the absolute correlation is significantly higher than for incorrect ones. Apart from being able to recover secret keys of unprotected block cipher implementations, this type of attack has been shown capable of recovering model parameters of neural networks [10]. In this paper, we utilize CPA to first show how the attack works on unprotected NN implementation and then to show the effectiveness of the proposed countermeasure."}, {"title": "B. Side-Channel Countermeasures", "content": "There are two broad categories of side-channel countermea- sures: masking and hiding [2]. The goal of masking is to randomize the intermediate values processed by the DUT to make the leakage independent of these values. For this purpose, we generate a random value, called mask, by which the secret intermediate value is concealed using a binary operation. Masking has been shown to be provably secure under certain conditions [11]. The goal of hiding is to either balance or randomize the leakages coming from the DUT to remove the data or operation dependency. This can be done by various techniques implemented either in software or hardware. For example, a so-called dual-rail precharge logic utilizes wires carrying complementary values to balance the leakage in hardware. In software, dummy operations and balanced data encoding [12] are some of the approaches. Generally, hiding-based methods can be overcome with a high number of measurements, however, they can make the attack much harder to execute. They are also often combined with masking-based countermeasures that suffer from the threat of higher-order CPA attacks [13]."}, {"title": "C. Related Work", "content": "1) SCAs on Neural Networks: The seminal work by Batina et al. [3] showed how to recover the type of activation function, number of layers and neurons, and weights. The type of activation function was recovered by a timing attack, the number of layers/neurons by visual inspection of the traces, and the weights by CPA. The networks were implemented on 8-bit ATmega328P and 32-bit ARM Cortex-M3 microcontrollers. This was followed by a myriad of works focusing on the practical recovery of various network information imple- mented on different devices. To mention a few, [14] showed the practical attack on ZYNQ XC7000 SoC on Pynq-Z1 board, [15] on Intel i7-7700 processor, [16] on Nvidia Jetson Nano, and [17] on Google Edge TPU. An embedded OpenVINO framework for implementing models on generic Edge devices was analyzed in [18]. These research efforts show that SCAs on neural network implementations are indeed a practical attack scenario and it is of interest to explore various ways to protect these models. 2) Countermeasures against SCAs on Neural Networks: Masking has been applied to NNs previously in [19]. They proposed a novel design of components such as masked adder trees and masked ReLUs. Apart from the need for a pseudo-random number generator to provide the randomness, the design requires twice the latency and needs 2.7\u00d7 more look-up tables, 1.7\u00d7 more flip-flops, and 1.3\u00d7 more BRAM. The work was later extended in [20] to the entire neural network, resulting in 3.5\u00d7 latency overhead and 5.9\u00d7 area overhead. They further improved their masked design in [4] by utilizing modular arithmetic in neural networks, allowing more efficient application of masking. However, it was later shown that such an implementation can be broken by a heat-induced power leakage [21]. Hiding has been utilized in the form of shuffling [5] and desynchronization [22]. In [5] the authors shuffle the order of multiplications within a neuron to drastically lower the success rate of a successful attack. In [6], the authors shuffle both the neurons within a network and the multiplications within a neuron. They realize an electromagnetic SCA on an ARM Cortex-M4 microcontroller and provide theoretical estimations on the number of measurements required for a successful attack. For example, even a small network with three layers of 15, 10, 10 neurons per layer would require \u2248 47 million SCA measurements, making the attack impractical. However, both of the shuffling approaches utilize software shuffling based on the Fisher-Yates algorithm In [8] it was shown that the division operation of this algorithm leaks side- channel information that can be used to reorder the shuffled parts of the traces back to their original order. Instead, they propose a hardware-based shuffling that avoids the use of that algorithm. Naturally, a hardware solution is efficient and provides a good security level. However, it requires an additional circuit to perform the shuffle, thus such protection needs to be added during the design phase of the chip and is not applicable to general-purpose hardware. In this paper, we aim to overcome this limitation by improving the Fisher-Yates algorithm to make it secure against SCA."}, {"title": "III. COUNTERMEASURE PROPOSAL", "content": "We propose utilizing a protected version of the Fisher-Yates shuffling algorithm to randomize multiplication operations as a countermeasure against CPA attacks. The standard Fisher- Yates algorithm, widely known for its efficiency in shuffling, is detailed in Algorithm 1. This algorithm was previously used for shuffling multipli- cations in neural networks to defend against CPA attacks, as demonstrated in [5], [6]. However, the algorithm's security was compromised in [8]. In this paper, the authors demonstrated that when a division operation is performed, the values of the dividend and divisor can be deduced by analyzing power variations. Since division is employed during the computation of modular reduction in line 3 of the algorithm, the value of j can be recovered. Consequently, each swapping operation in line 4 can be reversed, allowing the attacker to reorder segments of traces corresponding to individual multiplication operations and align them correctly."}, {"title": "A. Blakely's method for modular multiplication", "content": "Let $n \\geq 2$ be an integer. Consider two integers $a, b$ such that $0 \\leq a, b Let $a = a_{l_a-1}a_{l_a-2} \\dots a_1a_0$, where $l_a$ is the bit length of $a$. The product $ab$ can then be computed as follows\n$ab = (\\sum_{i=0}^{l_a-1} 2^ia_i)b = \\sum_{i=0}^{l_a-1} 2^ia_ib$. (1)\nBlakely's method for computing the modular multiplication $ab \\mod n$ leverages this representation. The step-by-step de- tails are provided in Algorithm 2. In the Algorithm, line 4 computes the product $ab$ as de- scribed in Equation (1). Subsequently, lines 5 8 calculate $R \\mod n$. Specifically, when $i = l_a - 1$, in line 3, we have\n$R = ab The value of $R$ becomes\n$R = 2R + a_ib \\leq 2(n - 1) + (n - 1) = 3n - 3$.\nThus, by comparing $R$ with $n$ twice, $R \\mod n$ can be effi- ciently computed. This approach avoids performing division operations and is therefore resistant to the attack described in [8]."}, {"title": "B. Masked Shuffling", "content": "To make the shuffling algorithm secure, we introduce masking for the modular reduction operation in line 3 of Algorithm 1 utilizing two secret arrays. The arrays, $S_1$ and $S_2$, are generated such that $S_1$ contains random positive integers $S_1[k]$ coprime with $k + 3$, while $S_2[k]$ represents the corresponding multiplicative inverse of $S_1[k]$ modulo $k + 3$. More specifically, for $k = 0,1,..., N \u2013 3$, the arrays satisfy the following properties:\n$gcd(S_1[k], k+ 3) = 1, S_1[k] > 0$, (2)\nand\n$S_2[k] = S_1[k]^{-1} \\mod (k + 3)$, (3)\nwhere N denotes the total number of elements to be shuffled. In particular, the following condition holds:\n$1 \\leq S_2[k] \\leq k + 2$, $k = 0, 1, . . ., N \u2212 3$.\nThe details of our protected Fisher-Yates shuffling algorithm are outlined in Algorithm 3. In this algorithm, r from line 2 and r' from line 3 are both random nonnegative integers. Line 4 computes\n$t = (rS_1[i-2]+r'(i+1)) \\mod (i+1) = rS_1[i-2] \\mod (i+1)$,\nwhere by design, $S_1[i-2]$ is a random integer coprime with i + 1 (see Equation (2)). From Equation (3), $S_2[i-2]$ is the multiplicative inverse of $S_1[i \u2013 2] modulo (i + 1), we have\n$S_1 [i-2]S_2[i-2] \\mod (i + 1) = 1$.\nThus, using Blakely's method, line 5 computes\n$j =(tS_2[i-2] \\mod (i + 1)) = rS_1 [i-2]S_2[i - 2] \\mod (i + 1) = r \\mod (i + 1)$\nWe have shown that lines 4 and 5 in Algorithm 3 implement\n$j = r \\mod (i + 1)$. Consequently, lines 2 to 6 in Algorithm 3 correspond to lines 2 to 4 in Algorithm 1 for i = N \u2212 1, N \u2013 2,..., 2. It is easy to see that lines 7 to 9 in Algorithm 3 implement lines 2 to 4 from Algorithm 1 for the case i = 1."}, {"title": "C. Security of the implementation against the attack in [8]", "content": "We have established that Blakely's method for computing modular multiplication is secure against the attack presented in [8], as it does not involve any division in its computation. In the context of Algorithm 3, the only potentially vulnerable line is line 4. According to the attack described by the authors, the attacker can recover the values of t and\n$rS_1[i-2] + r'(i + 1)$. However, knowing the value of t does not help the attacker in recovering the value of j, since j is computed by multi- plying t with a random number modulo i + 1. Furthermore, as $S_1[i-2]$ is a secret value and both r and r' are random numbers, knowledge of $rS_1[i - 2] + r\u2032(i + 1)$ also provides no useful information to the attacker. The shuffling algorithm is executed prior to each inference computation. Consequently, each time, the attacker can recover few other values $r'S_1[i-2]+r\u00ed (i+1)$. In general, the attacker could obtain a series of values:\n$\\lambda_1S_1[i \u2013 2] + \\beta_1, \\lambda_2S_1[i \u2013 2] + \\beta_2,$.\nwhere the $\\lambda$s and $\\beta$s are random numbers. It is worth noting that without the $\\beta$s, the attacker might be able to deduce $S_1 [i- 2]$ by computing the greatest common divisor (GCD) of the values\n$\\lambda_1S_1 [i-2], \\lambda_2S_1 [i \u2013 2], .\nHowever, with the $\\beta$s being added to each value, the recovered values no longer provide any meaningful information about $S_1[i-2]$. Consequently, no information about $S_2[i-2]$ is revealed, which is essential for determining the value of j."}, {"title": "D. Shuffling multiplication", "content": "Before each inference computation, we generate a shuffled array for each layer of the network as follows. Let N represent the number of input neurons in the layer, and define:\narray = {1, 2, . . ., N},\nwhere each element corresponds to a specific input neu- ron. The array is shuffled using Algorithm 3, and the resulting shuffled sequence of indices is used to reorder the multiplication operations in the layer's computation during inference. Specifically, for each output neuron in the layer, the multiplications are shuffled independently using the same shuffled array. It is worth noting that it is unnecessary to create separate secret arrays $S_1$ and $S_2$ for each layer. Instead, $S_1$ and $S_2$ can be computed based on the maximum number of neurons in any layer of the network. The shuffling for other layers can then utilize the relevant entries from $S_1$ and $S_2$ to perform the protected shuffling. To evaluate the security of the implementation against the attack proposed in [8], one might argue that brute-forcing the values in $S_2$ is feasible, given that $S_2[k]$ is known to be between 1 and $k+2$. More specifically, since $S_2[k]$ is coprime with $k + 3$, the total number of possible values for $S_2[k]$ is $\\varphi(k + 3)$, where $\\varphi$ denotes Euler's totient function. For an integer $n \\geq 2$,\n$\\varphi(n) = |{\\alpha | \\alpha \\in Z, 1 \\leq a \\leq n \u2212 1, gcd(a, n) = 1}|$.\nConsequently, the total number of possible values in $S_2$ is given by:\n$\\prod_{k=0}^{N-3} \\varphi(k + 3) = \\prod_{k=3}^{N} \\varphi(k)$.\nFor example, when N = 20, the number of possible values in $S_2$ is approximately\n$\\prod_{k=3}^{20}\\varphi(k) \\approx 2^{45}$.\nTo execute a brute-force attack, the attacker must recover all the weight values to test whether the output for a given input matches (or approximates) a known correct output of the network. This involves re-shuffling the multiplications for each neuron in the hidden layer for every trace. The attacker would then use the recovered weights to deduce the next layer's weights iteratively, continuing this process until the output layer's weights are fully recovered. Assuming each attack requires at least 1 second, the time needed to brute- force all the possible values in $S_2$ for a network with at most 20 neurons in each layer would be approximately:\n$2^{45}$ seconds \u2248 $2^{20}$ years.\nThis duration is clearly impractical, particularly considering the rapid advancements in AI. It is reasonable to anticipate that within a few years (or months), the secret AI model attacker is trying to recover will likely be replaced by a more advanced and efficient one, rendering such an attack even less relevant."}, {"title": "IV. EXPERIMENTAL EVALUATION", "content": "As in [3], we adopt an approach to recover the different components of a secret weight individually. We begin by recalling the 32-bit (single-precision) floating-point represen- tation as defined by the IEEE 754 standard. Specifically, the binary string $b_{31}b_{30} \\dots b_0$ represents the floating-point number:\n$(-1)^{b_{31}} \\times 2^{b_{30}b_{29}\\dots b_{23}-127} \\times 1.b_{22}b_{21} \\dots b_0$,\nwhere $b_{30}b_{29}\\dots b_{23}$ denotes the integer\n$b_{30}2^{8} + b_{29}2^{7} + \\dots +b_{23}$\nand $1.b_{22}b_{21} \\dots b_0$ represents the value\n$1+\\frac{b_{22}}{2} + \\frac{b_{21}}{2^2} + \\dots +\\frac{b_{0}}{2^{23}}$.\nIn this representation, $b_{31}$ is referred to as the sign bit, $b_{30}b_{29}\\dots b_{23}$ as the exponent, and $b_{22}b_{21} \\dots b_0$ as the man- tissa. Additionally, we refer to $b_{22}b_{21} \u00b7 \u00b7 \u00b7 b_{16}, b_{15}b_{14}\u00b7\u00b7\u00b7 b_{7}$, and $b_{6}b_{5} \\dots b_0$ as the first byte, second byte, last seven bits of the mantissa. Although similar approaches have been used in various works for recovering secret weight values during neural net- work computations, the specific CPA attack steps and success- ful recovery of the sign bit and exponent bits have not been comprehensively detailed in the literature. To ensure the completeness of our evaluation, in Subsec- tion IV-A, we will outline the CPA attack methodology for recovering the different components of a secret weight value, ultimately reconstructing the entire weight. Subsequently, in Subsection IV-B, we will demonstrate how the different com- ponents of a secret weight value can be successfully recovered in an unprotected implementation, as well as how our proposed countermeasure effectively mitigates such an attack."}, {"title": "A. CPA Attack Steps", "content": "Below, we detail the steps to recover the first secret weight value of the first neuron in the first hidden layer. Other weight values can be recovered in a similar manner. \u2460 Collect attack traces. To target the first secret weight value, traces are collected with all inputs fixed ex- cept for the first neuron in the input layer. Let $T = {t_0,t_1,...,t_{M_1-1}}$ represent the set of $M_1$ attack traces. For each trace $t_i$, $a_i (i = 0,1,..., M_1 - 1)$ denotes the corresponding random input to the first neuron. \u2461 Identify target range of time samples. As demonstrated before, visual inspection of traces can reveal the time samples corresponding to the first multiplication compu- tation for unprotected implementations [3]. In the case of shuffled implementations, the precise location of the multiplication is unknown, so the entire multiplication computation segment for the first hidden neuron is con- sidered as the target duration. Let $q_s$ and $q_e$ denote the start and end time samples of the identified range, with $q := q_e - q_s + 1$ representing the total number of time samples in this range. \u2462 Compute hypothetical weights. Given the vast number of possible weight values, it is impractical to consider every single value. To overcome this issue, we first determine the desired precision, defined by the number of decimal places to be recovered. A reasonable range for the weight values can also be assumed, same as in [3]. Let $W = {w_0, w_1,...,w_{M_W\u22121}}$ represent the set of all possible weight values. \u2463 Compute hypothetical leakages. For each weight value $w_j$, the hypothetical leakage for input $a_i$ is computed as the Hamming weight (HW) of the product $w_ja_i$ the number of 1s in the binary representation of the 32-bit floating-point number $w_ja_i$, as defined by the IEEE 754 standard. Specifically, construct the matrix H of size $M_W \\times M_L$ such that\n$H[j, i] = HW(w_ja_i)$,\nfor $j = 0,1,..., M_W - 1$ and $i = 0,1,..., M_L \u2013 1$. \u2464 Compute correlations. For each weight value $w_j$ and each time sample t in the target range, calculate the absolute value of the correlation coefficient between the hypothetical and real leakages. Let L denote the array of real leakages in the target range:\n$L[t, i] = l_i[t + q_s]$,\nfor $i = 0, 1, ..., M_L - 1$ and $t = 0, 1, . . ., q - 1$. Compute the $M_W \\times q$ matrix r such that\n$r[j,t] = \\frac{\\sum_{i=0}^{M_L-1}(H[j, i] \u2013 \\overline{H[j]})(L[t, i] \u2013 \\overline{L[t]})}{\\sqrt{Var(H[j])Var(L[t])}}$,\nwhere $\\overline{H[j]}$ (resp. $\\overline{L[t]}$) and $Var(H[j])$ (resp. $Var(L[t])$) represent the mean and variance of the values in the jth (resp. tth) row of H (resp. L) \u2465 Recovery of weight value. As previously mentioned, the recovery process involves extracting different parts of the weight separately. For example, the algorithm for recovering the exponent bits of the weight is detailed in Algorithm 4. For each time sample (line 6), we record the highest absolute value of the correlation coefficient for each exponent value (lines 7 and 8) in the array $r_e$. To determine the exponent bits, we plot the absolute correlations corresponding to each exponent value against all q time samples. The exponent value achieving the highest peaks is identified as the correct one. Similarly, the sign bit, the first byte, second byte, and the last seven bits of the mantissa can be recovered using the same approach."}, {"title": "B. Results", "content": "To demonstrate our approach, we evaluate it using a small multilayer perceptron (MLP) comprising four layers with 7, 5, 4, 3 neurons, respectively. The hidden layers utilize ReLU activation functions, while the output layer employs a sigmoid activation function. The weight values are randomly generated within the range [-2, 2] with a precision of up to two decimal places. The power traces for the first hidden layer computations are illustrated in Figure 2 for both the unprotected network and the network with shuffled multiplications. As shown, the computations for the five neurons are clearly distinguishable in both cases, marked by the red dotted lines. These observations indicate that recovering the network architecture (e.g., the number of neurons per layer) through visual inspection of the power traces remains feasible in both scenarios. This is expected as our countermeasure is not designed to conceal the network architecture but rather to protect the secret weight parameters from being extracted using CPA. To recover the first secret weight, we zoom into the com- putation of the first neuron. The resulting plots are depicted in Figure 3. For both unprotected and protected networks, the seven multiplications are distinguishable, as marked by the red dotted lines. However, in the unprotected network, the first multiplication (occurring between time samples 490 and 1010) corresponds to the first input neuron, whereas in the protected case, the correspondence between multiplications and input neurons are unknown. To perform CPA attacks, we follow the steps outlined in Subsection IV-A. For trace collection in Step 1, the first neuron inputs are randomly generated within [-2,2], while all other input values are set to 0.5. We collect $M_L$ = 2000 traces for the unprotected implementation and $M_L$ = 10,000 for the protected implementation. For Step 2, the target time sample range is identified as follows: for the unprotected implementation, as observed in Figure 3(a), the first multiplication occurs between time samples $q_s$ = 490 and $q_e$ = 1010. For the protected imple- mentation, the start time sample remains $q_s$ = 490, but due to shuffling, the range extends to $q_e$ = 4300 (see Figure 3(b)), which corresponds to the end of the seventh multiplication. The weight values are randomly generated within [-2, 2] with a precision of 0.01, resulting in the set:\n$W = {-2, -1.99, -1.98, . . ., -0.01, 0, 0.01, ..., 1.99, 2}$.\nFollowing the notation from Step 3, the number of hypothet- ical weight values is $M_W$ = 401. The weight value we used for the first input neuron is 1.43, corresponding to a sign bit of 0, an exponent value of 127, and mantissa bytes as follows: the first byte is 110, the second byte is 20, and the last seven bits represent the value 61. The CPA attack results for the unprotected and protected implementations are presented in Figures 4 and 5 respectively, where the absolute correlations for the correct values are highlighted in red, while those for incorrect values are shown in gray. For the first byte of the mantissa, only the maximum absolute correlation among incorrect values for each time sample is plotted due to the large number of possible values. For the attacks on the unprotected implementation, Figure 4 clearly demonstrates that the correct weight value can be successfully recovered. For attacks on the protected implementation, Figure 5(a) shows that the sign bit of the weight can still be recovered. We believe the reason lies in the composition of the network's weights and inputs. Among the seven weights used, four are positive. Additionally, the inputs to other neurons were set to 0.5, increasing the likelihood of intermediate values being positive. Consequently, the sign bit value of 0 exhibits higher absolute correlations. We would like to note that recovering the sign bit itself does not significantly reduce the search com- plexity of the entire floating point value. For other components of the weight value, the peaks corresponding to the correct values are significantly lower compared to those of incorrect values. Moreover, in all cases, the absolute correlations for the protected implementation remain far from 1, in contrast to the results for the unprotected implementation. These findings demonstrate that the CPA attack is ineffective in recovering the target weight value in the presence of our proposed countermeasure."}, {"title": "V. DISCUSSION", "content": "Compared to the original Fisher-Yates shuffling method, the masked shuffling introduces an overhead of 3.38\u00d7 for N = 1000 (i.e., with 1000 input neurons) and 2.48\u00d7 for N = 100. For a single layer's shuffled computation, incorporating our proposed shuffling operation (Algorithm 3) introduces an overhead of 4% compared to the standard shuffled computation using the original Fisher-Yates algorithm (Algorithm 1) when the layer has 100 input neurons and 100 output neurons, with ReLU as the activation function. When the number of input and output neurons increases to 1000, the overhead decreases to 0.49%. A plot illustrating the overhead as a function of the number of neurons (assuming an equal number of input and output neurons) is provided in Figure 6. The memory overhead compared to Fisher-Yates shuffling- based countermeasures arises from storing the two secret arrays, $S_1$ and $S_2$. As previously noted, the size of $S_1$ and"}, {"title": "VI. CONCLUSION", "content": "It was shown before that the shuffling-based countermeasure is effective in significantly increasing the attacker's effort required to reverse-engineer the model parameters utilizing a side-channel attack [5], [6]. However, software-based shuffling using the Fisher-Yates algorithm leaks side-channel informa- tion through its division operation, making it possible for the attacker to recover the model parameters [8]. In this paper, we showed how to make the algorithm resistant to that type of attack. Our experimental results indicate that the adjusted algorithm provides the expected level of resistance while adding a small overhead that is negligible when considering the entire model computation. For the future work, it would be interesting to evaluate a combination of different hiding-based countermeasures, such as shuffling and desynchronization, or a combination of hiding and masking."}]}