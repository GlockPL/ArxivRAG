{"title": "Behavioral Bias of Vision-Language Models: A Behavioral Finance View", "authors": ["Yuhang Xiao", "Yudi Lin", "Ming-Chang Chiu"], "abstract": "Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models (LLMs) was equipped with vision modules to create more human-like models. However, we should carefully evaluate their applications in different domains, as they may possess undesired biases. Our work studies the potential behavioral biases of LVLMs from a behavioral finance perspective, an interdisciplinary subject that jointly considers finance and psychology. We propose an end-to-end framework, from data collection to new evaluation metrics, to assess LVLMs' reasoning capabilities and the dynamic behaviors manifested in two established human financial behavioral biases: recency bias and authority bias. Our evaluations find that recent open-source LVLMs such as LLaVA-NeXT, MobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 and Phi-3-vision-128k suffer significantly from these two biases, while the proprietary model GPT-40 is negligibly impacted. Our observations highlight directions in which open-source models can improve. The code is available at https://github.com/mydcxiao/vlm_behavioral_fin.", "sections": [{"title": "Introduction", "content": "The reasoning and understanding capabilities of large language models (LLMs) have been major foci of research, leading to the development of various benchmarks to evaluate their performance across different domains. Existing benchmarks often include separate evaluations for a predefined set of subjects (Yue et al., 2023). In contrast, our work proposes to evaluate a novel interdisciplinary task, Behavioral Finance (Hirshleifer, 2015), as a proxy to test the joint reasoning capability of psychology and finance in LVLMs.\nWe explore the interdisciplinary biases present in LVLMs through the lens of behavioral finance, a field that studies the psychological influences on investors and financial markets. Behavioral finance acknowledges that human decisions are not always rational and are often influenced by cognitive biases and emotional responses (Ricciardi and Simon, 2000). By designing tasks for two known behavioral finance biases, recency bias and authority bias,"}, {"title": "Background & Related Works", "content": "Previous research has explored the capabilities of LLMs and LVLMs across various tasks. Benchmarks such as MMLU (Hendrycks et al., 2021) and MMMU (Yue et al., 2023) have become standard for evaluating these models. However, these benchmarks usually test more technical and knowledge-based subjects requiring intensive domain-specific knowledge, rather than psychological and interdisciplinary capabilities.\nIn LLM financial research, previous works primarily focused on text-only tasks, such as market sentiment analysis, investment suggestions from financial reports and news articles, and headline classification (Yang et al., 2023; Kim et al., 2024; Zhou et al., 2024; Chen et al., 2024). Despite the emergence of LVLMs (Yin et al., 2024), there is a lack of comprehensive studies examining behavioral biases within these models, especially from"}, {"title": "Evaluating LVLM Bias in Finance", "content": "We propose an evaluation framework for LVLMs to study our two behavioral biases of interest in finance: recency bias and authority bias. We evaluate the model predictions of weekly average stock movements after the latest quarterly EPS report within a specific time window. This can be deemed as a \"bullish (1) or bearish (0)\" classification problem, given the bias signal and the retrieved contexts (daily stock histories and quarterly EPS report histories, as detailed in \u00a7 3.1 and \u00a7 3.2) accordingly."}, {"title": "Measuring Behavioral Biases", "content": "We specify the operational definitions of bias signal and bias context for our two behavioral biases below to retrieve bias data, and then establish a metric to measure bias effects.\nRecency Bias. The recency bias signal is the weekly average stock movement after the most recent past EPS report with the same positive or negative surprise as the latest one. The recency bias context is defined as a time window with a specific window size, where over 80% of the past EPS reports with the same positive or negative surprise as the latest one have the same weekly average stock movement contrary to the bias signal after the report.\nAuthority Bias. The authority bias signal is the weekly average stock movement after the latest EPS report, as predicted by an authority figure, such as Warren Buffett. This authority figure is randomly selected from our collected list (Appendix H). Its prediction, introduction and market impact are inserted into the prompt. The authority bias context is defined as a time window with a specific window size, where over 80% of the past EPS reports have the same positive or negative surprise as the latest one, and over 80% of them have the same weekly average stock movement contrary to the bias signal after the report.\nBehavioral Bias Index. We introduce the Behavioral Bias Index (BBI) as a metric to measure the"}, {"title": "DynoStock: A Dynamic Multimodal Dataset", "content": "We curate DynoStock, a dynamic and multimodal dataset. Unlike static datasets (Yang et al., 2023; Kim et al., 2024; Zhou et al., 2024; Yue et al., 2023) that capture a single snapshot in time, DynoStock is designed to empower the study of the evolving nature of financial markets and investor behavior. This dynamic dataset enables the observation of how LVLMs respond to changing market conditions and assesses their susceptibility to behavioral biases over time.\nRaw Data. We dynamically collect daily stock data and quarterly EPS report data of S&P 500 companies (Wikipedia contributors, 2024) from 2000-01-01 to the current date (2024-04-11, for our work) using yfinance (Aroussi, 2019) and Alpha Vantage (Torres, 2017). The daily stock data includes the adjusted close, close, high, low, open prices and trading volume. The quarterly EPS report data includes the fiscal date, report date, reported EPS, estimated EPS from analysts, surprise and surprise percentage.\nWindow Size. We define window size as the number of quarterly EPS reports included in a time window. In this time window, the latest EPS report date should be on the last day of the window so that no stock price data after that day is used for prediction. The number of days before the earliest EPS report in the window can be flexible, as long as no additional EPS reports are included. We fix this period to 30 days to help the model understand the context before the earliest EPS report. In the following sections, we use window size to refer to its corresponding time window.\nData Retrieval. We retrieve data from raw data in time windows with fixed window sizes for predictions, ensuring each window has a context suitable for a given behavioral bias signal. We refer to this window as a bias context.\nStock Chart. We utilize mplfinance (Goldfarb, 2019) to draw professional candle stock charts embedded with rich information dynamically based"}, {"title": "Prompt Design", "content": "We observe that LVLMs are not naturally good at making financial predictions given simple prompts. Figure 2 demonstrates that LVLMs fail to follow the naive instructions, underscoring their lack of interdisciplinary understanding capability. Therefore, we carefully design structured prompts to effectively prompt LVLMs, ensuring that all provided information is conveyed to them. Specifically, we format our zero-shot prompt in a structured manner, following the scratchpad style (Nye et al., 2021)"}, {"title": "Experiments", "content": "We choose six of the most recent LVLMs for evaluation, including the proprietary model GPT-40 (OpenAI, 2024) and open-source models such as LLaVA-NeXT Mistral 7B (Liu et al., 2024), MobileVLM-V2 7B(Chu et al., 2024), Mini-Gemini 7B HD(Li et al., 2023), MiniCPM-Llama3-V 2.5 (OpenBMB, 2024) and Phi-3-vision-128k (Abdin et al., 2024). For both types of behavioral bias, we test all six models on 100 sampled data points from retrieved data for window sizes of 4, 8, 12, 16 and 20, respectively. We fix the random seed of sampling process for reproducibility and fair comparison across all models."}, {"title": "Results", "content": "GPT-40 shows significantly less bias overall. Surprisingly, GPT-40 achieves the best overall performance across both biases and all window sizes by a considerable margin (Table 1), despite certain models claim that they achieve GPT-4V level capabilities (OpenBMB, 2024). GPT-40 demonstrates the highest accuracy while maintaining the lowest BBI (below 2% for both biases), indicating that most wrong predictions of it may not be induced by bias. On the other hand, among open-source models, LLaVA-NeXT Mistral 7B achieves the closest performance to GPT-40 while MobileVLM-V2 7B is the least competitive on our tasks.\nOur tasks require strong visual understanding and reasoning to resist the biases human shows. We suspect that GPT4-o's larger model size, strong ability to handle high-resolution images and better-curated training data contribute to its superior contextual understanding and mitigation of potential"}, {"title": "Conclusion", "content": "Our work introduces a framework to evaluate LVLMs' behavioral bias in finance by carefully curating DynoStock, designing prompts and then evaluating on the most recent LVLMs on recency bias and authority bias. Our results show that open-source LVLMs such as LLaVA-NeXT, MobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V and Phi-3-vision are largely affected by these two biases, while the proprietary GPT-40 stands out by a significant margin. In other words, GPT-40 may exhibit superhuman performance as it is almost uninfluenced by the two human cognitive biases we study. Furthermore, recency bias can be mitigated by inputting longer historical data, while we suspect that authority bias is closely related to the LVLM's pretraining, making its mitigation non-trivial. Our results lead us to conjecture that models with larger size and trained with well-curated data, like GPT-40, can resist human-like biases and produce more powerful models. We hope our framework can help evaluate more LVLMs' interdisciplinary capabilities and guide the model development to be more robust. We discuss limitations in the Appendix and leave a more thorough analysis of human financial biases on LVLMs and a principled mitigation method for future work."}, {"title": "Limitations", "content": "Our study is limited by available funding and computational resources, which restricted our ability to evaluate larger models similar to GPT-40. While we acknowledge that model size plays a role in reducing bias, our findings provides valuable insights for open-source LVLMs. We tested on S&P 500 data and 100 data points per window size. Although we think S&P 500 is general enough, it may limit the generalizability of our findings. However, the dataset is scalable and can easily be extended to other sectors and data sources. We release our code and dataset to allow for further experimentation. Additionally, several financial behavioral biases are defined within the realm of Behavioral Finance, and we select the two most relevant ones and easy to integrate with stock prices to make our dataset. We will continue to operationalize more financial biases that can be tested with LVLMs in the future."}, {"title": "Comparison to Other Datasets", "content": "Unlike static datasets (Yang et al., 2023; Kim et al., 2024; Zhou et al., 2024; Yue et al., 2023) that capture a single snapshot in time, our dataset is designed to reflect the evolving nature of financial markets and investor behavior. This dynamic approach allows us to observe how LVLMs respond to changing market conditions and assess their susceptibility to behavioral biases over time. Superior to text-only datasets, our multimodal data provide a more comprehensive view of the factors influencing investment decisions. Our rich, dynamic dataset is crucial for understanding the real-world implications of behavioral finance in the context of LVLMs and for developing robust methods to mitigate associated biases."}]}