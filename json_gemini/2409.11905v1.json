{"title": "AlignBot: Aligning VLM-powered Customized Task Planning with User Reminders Through Fine-Tuning for Household Robots", "authors": ["Zhaxizhuoma", "Pengan Chen", "Ziniu Wu", "Jiawei Sun", "Dong Wang", "Peng Zhou", "Nieqing Cao", "Yan Ding", "Bin Zhao", "Xuelong Li"], "abstract": "This paper presents AlignBot, a novel framework designed to optimize VLM-powered customized task planning for household robots by effectively aligning with user reminders. In domestic settings, aligning task planning with user reminders poses significant challenges due to the limited quantity, diversity, and multimodal nature of the reminders. To address these challenges, AlignBot employs a fine-tuned LLaVA-7B model, functioning as an adapter for GPT-40. This adapter model internalizes diverse forms of user reminders-such as personalized preferences, corrective guidance, and contextual assistance-into structured instruction-formatted cues that prompt GPT-40 in generating customized task plans. Additionally, AlignBot integrates a dynamic retrieval mechanism that selects task-relevant historical successes as prompts for GPT-40, further enhancing task planning accuracy. To validate the effectiveness of AlignBot, experiments are conducted in real-world household environments, which are constructed within the laboratory to replicate typical household settings. A multimodal dataset with over 1,500 entries derived from volunteer reminders is used for training and evaluation. The results demonstrate that AlignBot significantly improves customized task planning, outperforming existing LLM- and VLM-powered planners by interpreting and aligning with user reminders, achieving 86.8% success rate compared to the vanilla GPT-40 baseline at 21.6%, reflecting a 65% improvement and over four times greater effectiveness.", "sections": [{"title": "I. INTRODUCTION", "content": "Household robots hold the promise of becoming essential in human daily life, providing long-term customized service to families in their home environments [1], [2], [3], [4]. \u03a4\u03bf operate effectively in different homes, robots need to adapt their foundational capabilities, such as task planning to individual users and their unique household contexts. To ensure user satisfaction, these robots need to interact naturally with users, collecting their reminders and continuously optimizing the customized task planning through iterative updates based on the collected data.\nVision-Language Models (VLMs) are emerging as a new paradigm in robotic task planning [5], [6], [7], [8], [9], [10], [11], [12]. Compared to Large Language Models (LLMs), VLMs can leverage both visual and language information, and obtain a more comprehensive understanding of the task context. However, aligning VLM-powered task planners for household robots with user reminders is challenging due to the limited quantity of reminders, their diversity in type, and their multimodal nature. In a home setting, user-robot interactions are relatively infrequent, resulting in a sparse reminder dataset, which makes it extremely challenging to fine-tune a VLM with a large number of parameters, such as GPT-40 [13]. Moreover, user reminders are inherently diverse, including personalized preferences, corrective guidance, and contextual assistance [14], [15], [2], [16], [3], [17], as illustrated in Fig. 1. This diversity necessitates a model with strong generalization capabilities to effectively process and learn from the varied reminders. Additionally, the multimodal nature of user reminders, which frequently involves both text and visual elements that are closely linked, increases the alignment complexity, posing challenges that single-modality models cannot fully address.\nTo the best of our knowledge, in the domain of robotics, few existing VLM-powered task planning approaches effectively align with customized user reminders. Previous works on VLM grounding has primarily focused on aligning these models with the physical context of tasks by translating generated plans into executable actions and incorporating contextual information such as affordances or environmental feedback [18], [19], [20], [21]. Some works on LLMs in task planning have explored diverse alignment strategies [22], [3], [23], [24]. The most closely related recent work is LLM-Personalized [16], which connects an LLM planner with personalized user preferences, primarily within the domain of housekeeping, using reinforced self-training techniques. However, this approach does not account for the broader range of user reminders, such as corrective guidance, leaving the challenge of aligning customized task planning with complex user reminders, particularly beyond housekeeping tasks, largely unaddressed.\nTo this end, we introduce AlignBot, an advanced framework designed to effectively align diverse and multimodal user reminders with robotics customized task planning for everyday household activities. Within AlignBot, a fine-tuned LLaVA-7B model functions as an adapter for GPT-40 [25], [13], [26], [27], internalizing user reminders to generate instruction-formatted cues that guide GPT-40 in task planning. By \"freezing\" GPT-40 and fine-tuning only the much smaller LLaVA-7B model, we significantly reduce data requirements while leveraging LLaVA-7B's multimodal capabilities to handle multimodal reminders. Within our data collection pipeline, we address the diversity of user-robot interactions by generating standardized instruction-formatted cues that transform complex dialogue inputs into consistent prompts. These cues streamline the processing of diverse reminders and optimize GPT-40's performance, given its strength in interpreting and executing structured prompts [28]. To address action omissions and sequence errors in long-term tasks, we also implement a dynamic retrieval mechanism that selects relevant cases from historically successful task plans as prompts for GPT-40, thereby improving task execution accuracy.\nTo empirically evaluate AlignBot, we establish a training setup that realistically simulates a household environment, consisting of three diverse scenarios and involving a collection of 81 objects. Multiple volunteers participated by providing reminders during the robot's execution of 20 everyday tasks, resulting in a multimodal, structured dataset comprising over 1,500 entries for fine-tuning the LLaVA-7B model. We assess the quality of the cues generated by LLaVA using real user ratings and measure the success rate of the task plans produced by GPT-40. The results demonstrate that AlignBot enhances task plan generation quality, outperforming the most advanced LLM- and VLM-powered planners, largely due to its superior capability to interpret and align with user reminders."}, {"title": "II. RELATED WORK", "content": "VLM-Powered Robotic Task Planning: VLMs have only recently emerged as a promising paradigm, rapidly gaining significant attention within the field [18], [19], [29], [30], [7], [8], [9], [10], [31]. Unlike LLM-powered approaches [32], [33], [34], [35], [36], [37], [1], VLMs provide a distinct advantage by integrating visual data, effectively addressing the perceptual limitations of LLMs in real-world environments. Notable examples include COME-robot [18] and VILA [19]. Despite their great potential, VLM-powered methods remain relatively underexplored compared to the extensively studied LLM-powered approaches. This limited exploration may contribute to the persistent challenges these methods face, particularly in terms of scalability for long-term planning. To address these issues, ViLaIn [29] combines VLMs with classical symbolic planning, leveraging Planning Domain Definition Language (PDDL) [38] to refine problem descriptions through error feedback to enhance the accuracy of long-horizon task execution. Additionally, DKPROMPT [30] automates VLM prompting using domain knowledge from PDDL, improving task planning in open-world environments. Unlike methods that rely solely on traditional planners such as PDDL, our approach, AlignBot, improves scalability by dynamically retrieving contextually relevant examples and integrating them into the prompt, effectively leveraging the in-context learning capabilities of GPT.\nContextual Alignment of VLMs in Household Robotics:\nSuch alignment is crucial, as robots must adapt to complex real-world environments and interact effectively with human users. Common approaches to achieving this alignment include prompt engineering and fine-tuning. While prompt engineering is computationally efficient, its success depends on the VLMs' intrinsic capabilities and may not fully achieve the necessary contextual alignment. Fine-tuning can enhance performance but requires considerable computational resources and extensive annotated data. A comparative study by Akiyama et al. [39] evaluates these two kinds of methods in the context of VLM-powered robotic planning. Most existing research emphasizes leveraging prompt engineering to align VLMs with real-world environments [20], [21], [40]. Beyond environment-based alignment, user reminders are another crucial aspect of contextual alignment. Few studies have incorporated user reminders into the VLM alignment process. The most relevant is LLM-Personalized [16]. This approach, however, remains limited, focusing primarily on individual personalization rather than broader contextual alignment. In contrast, AlignBot incorporates a wider range of user reminders, enabling more adaptive and robust robotic task planning."}, {"title": "III. PROBLEM FORMULATION", "content": "In this work, we address the problem of aligning robotic customized task planning with customized user reminders. Traditional task planning for robots typically involves generating action sequences to accomplish a specified task within a given environment, often without considering user reminders. In contrast, our problem setting focuses on a realistic scenario where a robot operates in a household with multiple users and is continuously evaluated on its task planning capabilities. This scenario introduces user id and their reminders directly into the task planning framework.\nFor each task planning problem i, the system receives as input a unique user identifier $u_j$ corresponding to one of the household users, observations $o_i$ of the specific task environment, and a task description $t_i$ provided by the user. The complete set of input parameters is denoted as $(u_j, o_i, t_i)$. The system outputs a sequence of actions, denoted as $p_i$, aimed at fulfilling the task specified by $t_i$ within the environment described as $o_i$. The output is considered successful when the task description $t_i$ is achieved, and the user expresses satisfaction with the action plan $p_i$, offering no further corrective feedback. The system also facilitates multi-round dialogue $q_i$, enabling continuous interaction and iterative task-specific user reminders during and after execution. As the robot continues to execute tasks, successful completions, along with their corresponding multimodal inputs, are stored as historical data, denoted as D, where each entry is denoted as $d_i = (u_j, o_i, t_i, q_i, p_i)$. This accumulated dataset forms the foundation for continuous optimization, allowing the system to progressively refine its task planning capabilities. We assume the presence and accessibility of all objects required for task execution within the environment, ensuring that the robot is able to complete tasks are instructed. The objective is to maximize the success rate of task completion by effectively aligning the robot's actions with user reminders, thereby improving performance across successive tasks."}, {"title": "IV. THE ALIGNBOT APPROACH", "content": "Fig. 2 illustrates the architecture of AlignBot, which comprises two primary components: a fine-tuned LLaVA and GPT-40. The LLaVA model generates instruction-formatted cues to guide GPT-40 in task planning, ensuring alignment with customized user reminders. Each user-GPT interaction-such as user inputs and GPT responses-is stored in a multimodal database. This historical data is used to continually fine-tune LLaVA, enabling the system to improve over time by learning from past interactions and aligning more effectively with user-specific reminders. AlignBot's effectiveness is built upon two key techniques: (1) the fine-tuning of LLaVA to better align with user reminders; and (2) a case-based learning approach that refines GPT-40's prompting by integrating relevant historically successful action plans, specifically designed to address action omissions and sequence errors in complex, long-horizon tasks."}, {"title": "A. Fine-Tuning LLaVA with User Reminders", "content": "User Reminder: The raw dataset, denoted as $D_u$, is collected through a structured data pipeline, which systematically captures detailed user-GPT interactions. Each dialogue $q_i$ in the dataset encapsulates task-specific user reminders on the generated task plans. This reminder is typically classified into three categories [14], [15], [2], [16], [3]. Personalized preferences reflect the unique needs of a user, such as a household requiring the robot to provide only sugar-free drinks for a family member with diabetes. Corrective guidance refers to adjustments provided by users when the robot's plan contains errors, such as omitting the step to turn off the stove after cooking. Contextual assistance is invoked when the robot needs help interpreting its environment, such as correctly identifying hazardous materials (e.g., a bottle of household cleaner) that require special handling.\nDatasets for Finetuning: From the raw dataset D, two specialized training datasets are derived: one for enhancing LLaVA's semantic grounding and the other for generating cues to be used as prompts for GPT-40. The need for semantic grounding emerges from instances where LLaVA exhibited difficulties in accurately recognizing objects and their states as described in user reminders, leading to misalignment in task execution. Both datasets are constructed in a structured Question-Answer (Q&A) format, as shown in Fig. 3 (right side). The semantic grounding dataset, referred to as Ds, addresses two core aspects: task-relevant object recognition and state recognition. For object recognition, multiple images of each object are sourced from the database, covering a range of positions, angles, and distances within the scene, as well as instances where objects are partially occluded. Image augmentation techniques, such as cropping, are applied where necessary to ensure comprehensive data coverage. For state recognition, the dataset includes visual examples depicting objects in different states (e.g., a refrigerator door is open or closed), under varying lighting conditions, angles, and partial occlusions. By drawing from a diverse set of visual representations, the Ds dataset serves as a comprehensive resource, enabling LLaVA to more effectively map visual inputs to their corresponding semantic interpretations, thereby improving both object identification and state recognition.\nThe cue generation dataset, denoted as $D_c$, consists of structured entries, each comprising an observation captured during task execution, along with the task description, user identifier, and extracted human reminder in the form of the instruction-formatted cue. These cues, representing user reminders distilled from the dialogues qi, are collected manually. In cases where multiple reminder instances appear within a single dialogue, these entries are consolidated into one, ensuring that LLaVA generates all necessary cues in a single inference step, thereby accommodating the cumulative reminder typical of multi-round user interactions. The dataset was generated from three primary scenarios: kitchen, living room, and tabletop settings, with the objects spanning a wide range (refer to Appendix A for details). To enhance GPT-40's comprehension of the cues generated by LLaVA, we formulated specific guidelines from practical experience. These guidelines prioritize clarity, contextual relevance, and precise execution, as detailed in Appendix B.\nLLaVA Fine-Tuning: For fine-tuning, we employ the LLaVA-7B model, integrating it with GPT-40 by freezing the GPT-40 parameters and exclusively fine-tuning LLaVA. This approach preserves GPT's task planning capabilities while enabling LLaVA to achieve better performance in both semantic grounding and cue generation tasks. LLaVA-7B is selected over LLaVA-13B due to its lower data requirements, rendering it more suitable for contexts with limited training data. Although LLaVA-7B exhibits comparatively weaker reasoning capabilities than LLaVA-13B, the latter demonstrates no significant performance gains when trained on small datasets, thereby making LLaVA-7B a more computationally efficient choice under our constraints. To further optimize LLaVA-7B's fine-tuning, we leverage the LORA method [26]. This method enables efficient fine-tuning by reducing the number of trainable parameters, allowing the model to swiftly capture critical details even in low-data settings.\nWe identify two distinct fine-tuning objectives: semantic grounding and cue generation. Initial attempts at joint training under a single loss function are abandoned due to task interference, as the objectives of semantic grounding and cue generation inherently diverge. Consequently, we adopt a phased fine-tuning strategy, initially concentrating on semantic grounding before transitioning to cue generation. This sequential approach allows the model to build upon the knowledge gained during the semantic grounding phase, such as object and state recognition, thereby enhancing its capacity to generate more accurate cues aligned with user reminders. We further observe that extended prompts negatively impacted the performance of the LLaVA-7B model. To mitigate this, we design concise prompts, such as: Can you provide some cues to the robot? This approach ensured that the prompts remained clear and focused on the task at hand, minimizing the risk of performance degradation caused by overly complex inputs. During inference, we incorporate zero-shot chain-of-thought reasoning by adding the prompt \u201cLet's think step by step\u201d, which guides the model to generate more coherent and detailed reasoning in its responses. This helps maintain the model's reasoning abilities without relying on lengthy prompts that could reduce clarity.\nThe fine-tuning process is optimized with the Cross-Entropy Loss function [26]. The number of epochs is carefully set to 40 for our fine-tuning process, representing a substantial increase compared to the majority of existing studies, which typically employ fewer than 10 epochs. This decision is motivated by the specific context of our work: a single household environment with task repetition and user-specific details. Although increasing the number of epochs can reduce generalization, this trade-off is acceptable in our case, as the model needed to retain detailed information for long-term adaptation to a particular user. We also explore the cold-start problem, particularly when working with very small datasets (e.g., dozens of samples). In such cases, we increase the number of epochs to 60 to help the model memorize the initial reminder. As the dataset size expands, we gradually reduce the epochs back to 40 to ensure the model can adapt to new tasks without losing the ability to recall past interactions. We experimented with learning rates ranging from $1 \\times 10^{-5}$ to $5 \\times 10^{-5}$ and found no significant differences in performance across this range. Further details on hyperparameters are provided in Appendix B."}, {"title": "B. Case-Based Learning for Enhanced GPT Prompting", "content": "Long-horizon task planning in household robotics frequently encounters issues such as action omissions and sequence errors, undermining execution reliability. For example, a robot may attempt to place an object without first executing the necessary action of grasping it. To address these challenges, we propose a case-based learning approach that enhances GPT-40's planning capabilities by incorporating relevant historical cases into the prompting process. This method involves dynamically retrieving the top-k most relevant cases-specifically, past action plans that were both successful and approved by users-from historical dialogue data. Here, we refer to these as cases. The retrieved cases serve as reference examples for GPT-40, providing contextual guidance based on prior successful executions. By leveraging similar and correct action sequences from past cases, we aim to improve the accuracy and robustness of the generated plans. The rationale behind this approach is that previous successful plans encapsulate effective solutions that can help prevent common errors in new tasks. However, retrieving relevant cases in a multimodal context poses challenges due to the complexity of assessing similarity across different modalities [41]. To overcome this, we first select successful plans that match the same task description. We then utilize GPT-40's feedback to evaluate and rank these plans based on their relevance and effectiveness. By dynamically integrating the most appropriate cases as references, GPT-40 can generate more accurate and comprehensive action sequences, thereby reducing omissions and enhancing overall task execution.\nConsider a subset $D_r$ of raw dataset D, defined as $D_r = \\{(p_1, t_1), (p_2, t_2),...\\}$, where each action plan $p_i$ is linked to a historical corresponding task description $t_i$. Each plan $p_i$ is assigned an initial priority score $f_i = f_0$. When a new task $t_{new}$ is introduced, the system selects a subset $D' \\subset D_r$ of action plans relevant to $t_{new}$, determined by the similarity function $sim(t_i, t_{new})$. Specifically, $D'_r = \\{p_i | sim(t_i, t_{new}) > \\tau\\}$, where $\\tau$ is a predefined similarity threshold. Here, the similarity function is computed using TF-IDF [42] combined with cosine similarity. The action plans in $D'_r$ are then sorted based on their priority scores $f_i$, resulting in an ordered set. To normalize these priority scores and prevent over-reliance on a limited set of action plans, a Softmax function is applied: $f_{i;}^{\\prime} = exp(f_i)/\\Sigma_{k = 1}^K exp(f_k)$. To dynamically adjust priorities based on effectiveness, we introduce a gradient-based update mechanism. Each action plan $p_i$ is associated with a gradient value $\\Delta f$, representing the rate of change in its priority. The gradient is updated depending on the utility of the action plan in the current task: $\\Delta f_{positive} = \\Delta f_{positive} exp(-\\alpha n_{i;})$, $\\Delta f_{negative} = \\Delta f_{negative} exp(-\\beta n_{i;})$, where $\\alpha$ and $\\beta$ are decay factors controlling how quickly priorities change with repeated use, and $n_{i;}$ denotes the usage frequency of plan $p_i$. The initial gradient $\\Delta f^0$ is a fixed value controlling the amplitude of updates, preventing unbounded growth or decay of priority scores over time. After updating the gradient, the priority score $f_i$ is adjusted accordingly: $f_i = min(max(f_i + \\Delta f, 0.1), 1.0)$. The selection of action plans is governed by an $\\varepsilon$-Greedy strategy to balance exploration and exploitation. Specifically, with probability $\\varepsilon$, a random action plan $F_{random}$ is chosen to encourage exploration, while with probability $1 - \\varepsilon$, the highest-priority plan $F_{max}$ is selected to exploit known effective strategies. The parameter $\\varepsilon$ controls this balance, ensuring adaptability without over-reliance on a limited set of strategies. By iteratively applying this method, the system refines its task planning, continuously adapting to user preferences and specific task contexts. Further details can be found in Appendix B."}, {"title": "C. Action Policy for Task Execution", "content": "After GPT outputs the task plan and receives user approval, the robot proceeds to execute each action in sequence, such as opening a drawer. To execute complex actions such as opening drawers, we employ the ACT algorithm [43], while simpler tasks like pick-and-place operations are handled using the AnyGrasp method [44] to achieve more efficient execution. For more technical details, see Appendix B."}, {"title": "V. EXPERIMENTS", "content": "We assess the performance of AlignBot from two key perspectives: the quality of task plans generated by GPT-40 and the quality of cues produced by the fine-tuned LLaVA.\nBaselines: As no existing methods closely match our approach for direct comparison, we designed three baselines to systematically evaluate AlignBot's performance.\nVanilla GPT-40: In this baseline, GPT-40 is used solely for task planning, relying only on the given task description and observation. Unlike AlignBot, it does not utilize cues generated by the fine-tuned LLaVA or incorporate dynamic retrieval of task-relevant cases. This setup serves as a fundamental comparison point to evaluate the standalone performance of GPT-40 without additional enhancements.\nGPT-40 + Raw Reminder: This baseline investigates the impact of integrating GPT-40 with randomly retrieved, unprocessed user-robot interaction data. These interactions correspond to the cues and task-relevant cases used in AlignBot but are not structured or instruction-formatted. These raw interactions, which may include irrelevant or conflicting information, are directly incorporated into GPT-40's prompts. This baseline evaluates the significance of LLaVA-powered cue generation and relevance filtering in enhancing GPT-40's task planning capabilities, as implemented in AlignBot.\nGPT-40 + Fine-tuned LLaMA: This baseline evaluates the effectiveness of using a single-modal language model to generate cues for GPT-4o. Specifically, LLaMA2-7b [34] is fine-tuned solely on text data, generating text-based cues for the goal. GPT-40 then uses these cues to generate a plan. By comparing performance when visual data is excluded, this setup highlights the importance of multimodal models.\nExperimental Setup: We develop a benchmark dataset in a controlled laboratory environment, constructing three distinct scenes: a kitchen, a living room, and a tabletop setting. These settings encompass a total of 20 distinct everyday tasks, such as organizing fruits into a bowl. Half of the tasks replicate those from prior work [15], while the other half are newly designed for this study. The tasks involve six categories of objects, including kitchen utensils and fruits, comprising over 80 unique items. Task complexity varies, ranging from simple to long-term, multi-step tasks. Each task scene consists of 2-6 operative objects and 1-3 non-target objects, with variations in object position, state, and viewing angle. Approximately 50\u2013150 images are captured per task, resulting in a total of over 1,500 task scenes for training LLaVA, where three volunteers are involved in interacting with GPT-40. Separately, for the evaluation of AlignBot, we generate 600 task executions from 20 tasks across 5 scenarios per task, varying in object positions, states, and distractor items. The same three volunteers perform each task twice, providing a total of 600 evaluations. These volunteers assess whether the generated plans are reasonable and whether task goals are successfully achieved. Further details are provided in Appendix C.\nRating Criteria: We assess the methods' effectiveness by comparing their planning success rates, where the methods are anonymized to volunteers for fair evaluation. To evaluate the quality of the generated cues, we select two scenes for each task, and the volunteers rate the cues without knowing which method generates them, ensuring objectivity. The user rating scale ranges from 0 to 3, with higher scores indicating better cue quality. The rating guidelines for human raters in the experiments are available in Appendix C.\nAlignBot vs. Baselines: TABLE I shows the comparison result between AlignBot and the three baselines. AlignBot outperforms all baselines, demonstrating superior performance in aligning task planning with customized user reminders. Compared to Vanilla GPT-40, AlignBot addresses significant limitations in semantic grounding, such as recognizing the object states (e.g., whether a drawer is open or closed). Vanilla GPT-40 tends to make random decisions in tasks due to missing user-specific information, while AlignBot, through its database of user reminders and fine-tuned cues, delivers much more accurate and effective task plans. When compared to GPT-40 + Raw Reminder, AlignBot again proves more effective, as GPT-40 + Raw Reminder often struggles to filter and apply the correct historical data for the current scenario, resulting in planning failures. The context-specific cues generated by AlignBot's adapter are essential for accurate task planning, particularly in complex environments. Finally, while GPT-40 + Fine-tuned LLaMA can remember user preferences and correct some common planning errors, its lack of multimodal capabilities limits its understanding of the scene and the arrangement of objects, leading to less reliable cues. AlignBot's ability to integrate multimodal inputs ensures better scene awareness and task alignment, demonstrating the necessity of multimodal adapters in improving task planning.\nQuality of Cues: Our AlignBot demonstrates superior performance in cue generation compared to baselines. It receives high ratings from volunteers for its ability to combine task descriptions with image context, which allows it to deliver highly effective, scene-based cues. It also excels at remembering personalized user preferences, making its responses more accurate and tailored to individual needs, which significantly enhances its utility in real-world applications. When compared to Fine-tuned LLaMA, AlignBot's multimodal capabilities are a clear advantage. While Fine-tuned LLaMA can remember user preferences, its single-modal nature limits its effectiveness, especially in tasks requiring visual input. Without image guidance, Fine-tuned LLaMA randomly selects from past reminders and fails to provide accurate or context-specific cues, underscoring the importance of multimodal inputs in personalized tasks. In contrast, the LLaVA without Fine-tuning further highlights AlignBot's strengths, as it struggles with image-based reasoning often providing vague or generic descriptions of task-relevant items. LLaVA without Fine-tuning lacks the ability to interpret detailed visual information or infer operational errors, making it far less effective in guiding robots through real-world tasks. Additionally, without fine-tuning to incorporate user-specific data, its responses remain generic and less relevant, reinforcing the importance of AlignBot's tailored and fine-tuned approach to cue generation."}, {"title": "VI. CONCLUSION", "content": "To summarize, AlignBot demonstrates significant improvements in aligning robotic task planning with diverse, multimodal user reminders. By fine-tuning LLaVA-7B as an adapter for GPT-40, the framework effectively handles the challenges posed by the nature of user reminders in household environments. The combination of instruction-formatted cues and case-based learning enables AlignBot to generate more accurate task plans. Empirical results show that AlignBot outperforms baselines."}]}