{"title": "Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective", "authors": ["Pooriya Jamie", "Reyhaneh Hajihashemi", "Sharareh Alipour"], "abstract": "Integrating large language models (LLMs) like ChatGPT is revolutionizing the field of computer science education. These models offer new possibilities for enriching student learning and supporting teaching assistants (TAs) in providing prompt feedback and supplementary learning resources. This research delves into the use of ChatGPT in a data structures and algorithms (DSA) course, particularly when combined with TA supervision. The findings demonstrate that incorporating ChatGPT with structured prompts and active TA guidance enhances students' understanding of intricate algorithmic concepts, boosts engagement, and elevates academic performance. However, challenges exist in addressing academic integrity and the limitations of LLMs in tackling complex problems. The study underscores the importance of active TA involvement in reducing students' reliance on AI-generated content and amplifying the overall educational impact. The results suggest that while LLMs can be advantageous for education, their successful integration demands continuous oversight and a thoughtful balance between AI and human guidance.", "sections": [{"title": "1 INTRODUCTION", "content": "Integrating large language models (LLMs) such as ChatGPT into educational settings increasingly transforms how we approach teaching and learning [22, 27]. Despite this growing interest, there remains a notable gap in the literature concerning the specific ways in which teaching assistants (TAs) can effectively supervise the use of LLMs, particularly in data structures and algorithms (DSA) courses, which are fundamental to computer science education.\nDSA courses play a crucial role in developing students' understanding of algorithms, programming skills, and problem-solving strategies [6]. Mastery of DSA enables students to choose optimal algorithms regarding execution time and memory usage, which is essential for their academic and professional success. However, the complexity of these courses often presents significant challenges for students, underscoring the need for innovative teaching aids.\nThis is where LLMs, like ChatGPT, can make a significant impact [19]. This study uniquely focuses on the supervised application of ChatGPT, exploring how structured prompts and active TA support can enhance educational outcomes. Our work also integrates two versions of ChatGPT-ChatGPT-4o and ChatGPT o1-each contributing uniquely: ChatGPT-4o supports routine educational tasks, while ChatGPT o1 enhances complex problem-solving through improved reasoning, thereby addressing the limitations of using LLMs independently.\n\u2022 RQ1: How does ChatGPT impact students' learning and exam readiness when supervised by TAs?\n\u2022 RQ2: What challenges arise in utilizing ChatGPT to answer DSA questions?\n\u2022 RQ3: How can the different versions of ChatGPT (4o and o1) overcome limitations and support each other to enhance student learning outcomes?\nTraditionally, TAs have been instrumental in leading discussion sections, grading assignments, and providing support during office hours. With the advent of AI tools like ChatGPT, the role of TAs is evolving to include overseeing AI chatbots that aid in student learning, debugging codes, and generating additional practice problems. This evolution necessitates that TAs update their skills to effectively integrate AI into their teaching strategies.\nHowever, this transition is accompanied by challenges. Maintaining academic integrity becomes more complex, as TAs must establish clear guidelines, such as prohibiting direct use of AI-generated code in assignments without modification, to prevent the misuse of AI for dishonest purposes [9]. Additionally, TAs must be aware of ChatGPT's limitations and balance traditional teaching methods with new technological approaches to uphold the quality of education. Despite these challenges, the strategic use of AI can significantly enhance educational outcomes when supervised and guided by TAs.\nTo address these research questions, we conducted an assessment of how ChatGPT impacted student learning outcomes and exam preparation when used under the supervision of a TA. Throughout this evaluation, we identified several challenges, particularly related to ChatGPT's limitations in handling complex and visual tasks. We employed ChatGPT-4o for routine tasks and integrated ChatGPT o1 to provide deeper reasoning for complex problems. This hybrid approach mitigated limitations and enhanced the overall learning experience, offering a balanced solution that requires fewer resources and can be easily adapted for larger classes, making Al integration in education scalable and effective."}, {"title": "2 RELATED WORK AND OUR CONTRIBUTION", "content": "Despite the growing interest, there is a notable gap in research focusing specifically on how LLMs can be effectively utilized by teaching assistants (TAs) in advanced computer science courses, particularly data structures and algorithms (DSA). While much of the existing literature evaluates LLMs as general learning aids, the specific challenges and opportunities associated with TA-guided LLM use in complex subject areas, such as providing structured guidance and addressing misconceptions, are underexplored.\nResearch studies examining LLMs' impact on education typically fall into two categories: those that highlight the benefits of LLMs as effective educational tools, and those that point out their drawbacks, considering LLMs as potentially detrimental in educational settings [1, 5, 14\u201317, 24].\nFarrokhnia et al. [12] provide a comprehensive analysis of the strengths, weaknesses, opportunities, and threats (SWOT) associated with the use of ChatGPT in educational settings. Becker et al. [7] suggest that LLMs offer promising opportunities for enhancing learning through the generation of example solutions. Yiyin Shen et al. [25] found that prompt engineering could improve ChatGPT's effectiveness in data science assignments, particularly when performance was initially low, highlighting the role of LLMs and the importance of prompt engineering in education."}, {"title": "2.1 LLMs in Computer Science Education", "content": "Despite the growing interest, there is a notable gap in research focusing specifically on how LLMs can be effectively utilized by teaching assistants (TAs) in advanced computer science courses, particularly data structures and algorithms (DSA). While much of the existing literature evaluates LLMs as general learning aids, the specific challenges and opportunities associated with TA-guided LLM use in complex subject areas, such as providing structured guidance and addressing misconceptions, are underexplored.\nResearch studies examining LLMs' impact on education typically fall into two categories: those that highlight the benefits of LLMs as effective educational tools, and those that point out their drawbacks, considering LLMs as potentially detrimental in educational settings [1, 5, 14-17, 24].\nFarrokhnia et al. [12] provide a comprehensive analysis of the strengths, weaknesses, opportunities, and threats (SWOT) associated with the use of ChatGPT in educational settings. Becker et al. [7] suggest that LLMs offer promising opportunities for enhancing learning through the generation of example solutions. Yiyin Shen et al. [25] found that prompt engineering could improve ChatGPT's effectiveness in data science assignments, particularly when performance was initially low, highlighting the role of LLMs and the importance of prompt engineering in education."}, {"title": "2.2 Impact on Learning Outcomes", "content": "The integration of LLMs in education has been linked to improvements in student engagement and academic performance [8]. For example, Kwan Lo [18] demonstrated that ChatGPT can personalize learning and automate administrative tasks, resulting in more effective online learning environments. Singh et al. [26] further demonstrated that ChatGPT enhances student satisfaction and academic achievements due to the accessible academic support it provides. Dempere et al. [10] also discussed ChatGPT's role in supporting research and automating grading, which improves teaching methodologies and student retention.\nHowever, these benefits are counterbalanced by notable concerns, such as potential academic dishonesty, reduced creativity, diminished human interaction, and the risk of LLMs providing incorrect information [10, 20, 23, 26]. Additionally, some articles discuss the possibility of LLMs acting as replacements for teachers, which raises concerns about the appropriateness and limitations of these technologies in classrooms."}, {"title": "2.3 LLMs in Data Structures and Algorithms", "content": "The impact of LLMs in advanced computer science subjects, such as DSA, has received significant attention. Prior research has primarily focused on the effectiveness of LLMs as standalone tools for supporting student learning and helping with coding tasks [3, 13].\nThese studies indicate that LLMs can increase productivity, particularly for beginners, by assisting with coding, programming, and understanding algorithmic concepts. However, concerns remain regarding potential errors in generated code and an incomplete understanding of programming fundamentals."}, {"title": "2.4 Our Contribution", "content": "Our study investigates the practical integration of ChatGPT in a data structures and algorithms course, with the guidance of an experienced TA. This combination of ChatGPT and human oversight addresses common challenges in DSA education, such as student over-reliance on AI-generated content and incomplete understanding of the material. By using structured prompts alongside TA supervision, our approach ensures that students critically engage with the content rather than passively accepting generated responses.\nWe provide practical insights into leveraging ChatGPT with active TA involvement. Our approach shows how structured prompts, continuous feedback, and human expertise can enhance the learning experience. Our findings highlight how ChatGPT-4o and o1 versions were specifically used to address key challenges, such as generating creative problem sets and improving explanations for complex algorithms, contributing to an improved overall educational experience."}, {"title": "3 METHODOLOGY", "content": "Our study took place in a data structures and algorithms (DSA) course offered to 40 undergraduate students at a top-tier university. Participants were in their second or third year, with equal representation of male and female students. The study attempted to control for confounding variables by ensuring that students in each group had similar prior knowledge and study habits. The TA, an experienced assistant with 16 previous related courses, played a crucial role in facilitating classroom activities, providing personalized feedback, and iteratively refining the prompts used in the study, while also working closely with the research team and the course instructor to ensure the methodology was effectively implemented.\nChatGPT-4o and ChatGPT o1 were integrated into the course as educational assistants, used to generate diverse practice problems, assist in debugging student code, and improve teaching methods. ChatGPT was employed by both students and TAs to facilitate deeper understanding and enhance learning efficiency under TA supervision, which helped mitigate improper use.\nOur experiment aimed to examine the impact of ChatGPT on students' learning and exam preparation under TA supervision. We focused on exercises from the DSA course, addressing the tendency of students to accept ChatGPT's answers without fully understanding the concepts. To tackle this issue, we introduced structured prompts and TA oversight to guide students through problem-solving. The prompt highlighted elements such as problem understanding, key characteristics, common operations, algorithm descriptions, real-world scenarios, and code snippets. Twenty undergraduate students participated in the study, and their learning progress was evaluated based on student satisfaction and exam performance. We also assessed ChatGPT's limitations by generating and evaluating responses to syllabus-based questions. The introduction of ChatGPT-4o and o1 enhanced our methodology by enabling the TA to create more diverse questions, facilitate interactive sessions, troubleshoot effectively, and provide in-depth feedback, significantly improving students' understanding and performance.\nWe established a feedback loop to refine the methodology in real-time. Weekly review meetings with students and the research team discussed findings and areas for improvement. We collected qualitative feedback and analyzed survey and exam data to adjust prompts, TA strategies, and ChatGPT use. A comprehensive mid-study review analyzed results and made necessary adjustments, allowing us to adapt and improve our educational approach effectively."}, {"title": "3.1 ChatGPT-Driven Learning Under TA Guidance", "content": "The primary objective was to examine the impact of ChatGPT on students' learning and exam preparation under TA supervision. To achieve this, We focused on DSA exercises, crucial for understanding the subject and performing well in exams. With the introduction of ChatGPT, we noticed a trend where students would input questions into the model and accept its answers without understanding the underlying concepts. This approach undermined the purpose of the exercises, which is to promote comprehension and readiness for the exam.\nWe addressed this issue by introducing structured prompts and active TA supervision. Several versions of the prompts were tested and iteratively improved based on feedback from students and the TA. For example, students indicated that the prompts needed clearer guidance on common pitfalls, which led us to add specific warnings and additional explanations for challenging steps. This process led to a final prompt version that effectively guided students through problem-solving, ensuring engagement with the material rather than relying solely on ChatGPT for answers.\nWe compared two groups: one using ChatGPT with TA supervision and the other relying solely on TA support. This comparison helped isolate the effects of ChatGPT on student learning outcomes, specifically by evaluating metrics such as exam scores, problem-solving abilities, and student engagement during class activities."}, {"title": "3.1.1 Setup and Supervision", "content": "The primary objective was to examine the impact of ChatGPT on students' learning and exam preparation under TA supervision. To achieve this, We focused on DSA exercises, crucial for understanding the subject and performing well in exams. With the introduction of ChatGPT, we noticed a trend where students would input questions into the model and accept its answers without understanding the underlying concepts. This approach undermined the purpose of the exercises, which is to promote comprehension and readiness for the exam.\nWe addressed this issue by introducing structured prompts and active TA supervision. Several versions of the prompts were tested and iteratively improved based on feedback from students and the TA. For example, students indicated that the prompts needed clearer guidance on common pitfalls, which led us to add specific warnings and additional explanations for challenging steps. This process led to a final prompt version that effectively guided students through problem-solving, ensuring engagement with the material rather than relying solely on ChatGPT for answers.\nWe compared two groups: one using ChatGPT with TA supervision and the other relying solely on TA support. This comparison helped isolate the effects of ChatGPT on student learning outcomes, specifically by evaluating metrics such as exam scores, problem-solving abilities, and student engagement during class activities."}, {"title": "3.1.2 Interaction Process", "content": "The structured prompt was a key part of our methodology, including essential elements for comprehending and solving DSA problems:\n\u2022 Problem Understanding: Clarifying the problem statement.\n\u2022 Key Characteristics: Identifying the essential properties of the problem.\n\u2022 Common Operations: Discuss typical operations related to the problem.\n\u2022 Algorithm Description: Outlining potential algorithms for solving the problem.\n\u2022 Real-World Scenario: Providing context to relate the problem to real-life applications.\n\u2022 Code Snippet: Offering a basic code structure."}, {"title": "3.1.3 Evaluation", "content": "To evaluate the effectiveness of ChatGPT integration, we established specific, measurable objectives for student satisfaction and exam performance.\nWe used a structured survey at the end of the course to gauge student satisfaction, including how helpful students found ChatGPT, their understanding of complex concepts, and overall satisfaction. To measure learning outcomes, we compared exam scores of two groups: one using ChatGPT under TA supervision and the other relying solely on TA support. We also analyzed their performance on various types of questions to identify improvement areas, such as problem-solving and theoretical understanding.\nBy incorporating TA supervision and structured prompts, we aimed to create an environment where students used ChatGPT as a learning tool rather than a shortcut. Our comparative study demonstrated that guided ChatGPT interactions led to better learning outcomes and higher exam scores compared to traditional TA-only instruction."}, {"title": "3.2 Identifying ChatGPT's Limitations", "content": "Through our experiment with ChatGPT-driven learning under TA guidance, we observed several limitations in ChatGPT's ability to interact with DSA-related questions. These limitations became evident in areas such as difficulty generating creative, novel problems and struggles with visual representation and complex algorithmic reasoning. These shortcomings prompted us to conduct a thorough analysis of ChatGPT's performance on the DSA syllabus, aiming to pinpoint specific weaknesses and identify opportunities for improvement.\nWe developed a method to evaluate both the strengths and weaknesses of ChatGPT in addressing DSA concepts, as understanding these aspects is crucial for making targeted educational improvements. This involved generating a diverse set of theoretical and practical questions covering key DSA topics. We evaluated ChatGPT's responses based on several criteria, including accuracy, problem-solving depth, and its ability to handle novel scenarios."}, {"title": "3.2.1 Evaluation Criteria", "content": "Our evaluation methodology consisted of the following steps: we explored the university's DSA syllabus to create a comprehensive framework for assessing ChatGPT's performance. For each topic, we designed a set of theoretical and practical questions to evaluate ChatGPT's comprehension of core DSA concepts. These questions ranged from basic data structures (arrays, linked lists) to advanced topics (graph traversal algorithms, dynamic programming). Additionally, we tasked ChatGPT with generating its own questions for each topic, allowing us to assess its capacity for creative question generation.\nWe assessed ChatGPT's responses on the following dimensions:\n\u2022 Accuracy: We analyzed whether ChatGPT provided correct answers, particularly for complex DSA problems involving recursion and dynamic programming.\n\u2022 Depth of Explanation: We evaluated whether ChatGPT offered thorough, step-by-step explanations for algorithmic problems, ensuring sufficient clarity.\n\u2022 Handling Novel Scenarios: We examined ChatGPT's ability to respond to creative questions outside its pre-trained dataset, noting its tendency to provide incomplete or superficial answers for novel problems.\n\u2022 Visual Representation and Code Generation: We tested ChatGPT's ability to visually represent problems, such as tree structures or graph traversals.\nTo further investigate ChatGPT's limitations, we collected feedback from students and professors who utilized ChatGPT in their studies and teaching. Their experiences highlighted key challenges, such as the model's inability to generate creative exercises and its occasional production of code snippets that were syntactically correct but logically flawed, requiring further refinement. These insights emphasized the need for expert oversight when using ChatGPT for complex educational tasks."}, {"title": "3.3 Enhanced TA Classes Using ChatGPT-4o and o1 Series", "content": "To address the challenges observed in TA-assisted learning with ChatGPT-40, such as limited reasoning depth, incomplete solutions for complex problems, and insufficient support for advanced algorithmic concepts, we sought a more advanced alternative with improved problem-solving capabilities. With the release of the ChatGPT o1 series on September 12, 2024, we incorporated both models to determine how each could uniquely contribute to overcoming the limitations of the other.\nChatGPT-40 introduced improvements in speed, multi-modal input handling (text, images, video), and multi-language support, which enhanced the generation of diverse class materials and real-time feedback. However, ChatGPT o1 went beyond these features, providing superior reasoning for complex, multi-step problems, such as recursive algorithms and advanced data structure manipulation. This allowed us to explore how different versions of ChatGPT could support TA-led learning in various ways."}, {"title": "3.3.1 Classroom Integration", "content": "In TA-led sessions, both models were integrated into the classroom activities in the following ways:\n\u2022 Preparation: The TA used ChatGPT-40 to create a diverse set of basic questions from the teacher's booklet. For complex problems like graph traversal and dynamic programming, ChatGPT-40's solutions were often incomplete due to insufficient reasoning depth, leading to oversimplified or incorrect steps in multi-part solutions. Therefore, we integrated ChatGPT 01 for its advanced reasoning capabilities, enabling it to provide more thorough explanations.\n\u2022 Interactive Sessions: During class discussions, the TA presented questions from both models. ChatGPT 01's chain-of-thought reasoning was especially valuable for guiding students through complex concepts such as dynamic programming, fostering engagement and critical thinking.\n\u2022 Troubleshooting and Clarification: For detailed problem-solving, ChatGPT 01 excelled in breaking down concepts into logical steps. When visual aids were required, ChatGPT-40 handled image-related tasks, though TA supervision ensured precision and correctness.\n\u2022 Assessment and Feedback: ChatGPT-40 was initially used to review student responses and provide general feedback. ChatGPT 01 was then used to refine the feedback by identifying deeper logical issues, enhancing the overall quality of the feedback.\nBy combining ChatGPT-40 for foundational content and ChatGPT 01 for advanced reasoning tasks, we created a more dynamic learning environment, allowing us to assess how different models could support both student learning and TA tasks."}, {"title": "4 RESULTS", "content": "In this section, we analyze the outcomes of ChatGPT-driven learning under TA guidance, focusing on key metrics such as student performance, engagement, and exam results. Students were divided into two groups: the first group used ChatGPT with TA supervision and structured prompts, while the second group received traditional TA support without ChatGPT. This comparison allowed us to assess the impact of ChatGPT under guided conditions versus traditional TA-only instruction."}, {"title": "4.1 Student Performance Analysis", "content": "In this section, we analyze the outcomes of ChatGPT-driven learning under TA guidance, focusing on key metrics such as student performance, engagement, and exam results. Students were divided into two groups: the first group used ChatGPT with TA supervision and structured prompts, while the second group received traditional TA support without ChatGPT. This comparison allowed us to assess the impact of ChatGPT under guided conditions versus traditional TA-only instruction.\nfluctuating scores, particularly in more complex exercises, indicating partial comprehension of the material. This led to weaker exam performance compared to the ChatGPT-assisted group. In contrast, the ChatGPT-assisted group demonstrated stable and higher performance, reflecting the benefits of using structured prompts in combination with ChatGPT, under TA supervision.\nAn unpaired t-test, suitable for comparing means of two independent groups, was used to assess the statistical significance of the observed differences between Group 1 (ChatGPT + TA guidance) and Group 2 (TA only). The two-tailed p-value was 0.0009, indicating an extremely statistically significant difference. The mean score difference between Group 1 and Group 2 was 16.50, with a 95% confidence interval ranging from 8.04 to 24.97. Group 1 had a mean score of 90.15, while Group 2 had a mean score of 73.65. These results suggest that ChatGPT, when used with TA guidance, significantly enhances student performance, particularly in complex problem-solving.\nStudents in the ChatGPT-supervised group performed better across various topics, especially in advanced DSA topics like recursion and dynamic programming, with average scores 15-20% higher than the TA-only group. Structured prompts and TA guidance, particularly in clarifying problem requirements, providing step-by-step walkthroughs, and offering targeted hints, helped students break down problems, think through steps, and apply concepts actively.\nWe gathered feedback on student satisfaction with prompts and TA supervision. Students highlighted the usefulness of structured prompts, the importance of active engagement, and ChatGPT's limitations in handling unique questions. One student appreciated ChatGPT's explanations when using structured prompts but emphasized the need for student input on complex questions. Another student found ChatGPT-40 helpful for learning DSA, noting its role as an educational assistant, though not a substitute for a teacher. A third student viewed LLMs as powerful search engines, providing summaries and solutions but lacking the depth needed for novel problem-solving.\nThese findings support our hypothesis that structured prompts and TA oversight, when paired with ChatGPT, lead to improved learning outcomes and higher exam performance compared to traditional instruction methods."}, {"title": "4.2 ChatGPT Limitations", "content": "We tasked ChatGPT with solving and generating a variety of theoretical and practical DSA questions. Our evaluation revealed several limitations, particularly with complex, visually-oriented, and advanced algorithmic concepts.\nChatGPT faced significant challenges when dealing with advanced topics in the DSA syllabus. In particular, it struggled with algorithm time complexity analysis, specifically when generating accurate graphs or adapting code for specific time complexities. For example, when tasked with generating a graph to illustrate the time complexity of different sorting algorithms, ChatGPT often produced misleading visual outputs with incorrect node connections. Similarly, when adapting code to fit a specified time complexity, such as optimizing a sorting algorithm to achieve O(nlogn), the model frequently failed to produce correct or efficient solutions. Often, this led to incorrect outputs, highlighting limitations in efficiently adapting to varying computational constraints.\nSignificant challenges emerged when working with graph and tree visualizations. Tasks like DFS, BFS, and tree traversals often resulted in misleading or incomplete visual outputs, primarily due to ChatGPT's limited ability to accurately represent node relationships and connections in complex structures.\nIn hashing-related tasks, ChatGPT struggled with practical implementations for techniques like chaining and linear probing, which lacked robustness and often resulted in logical errors or inefficiencies. Similarly, ChatGPT's handling of optimization problems, such as the 0/1 and fractional knapsack problem, revealed insufficient detail in its explanations, particularly in illustrating key steps like choosing items based on their value-to-weight ratio or demonstrating the dynamic programming approach. It often failed to break down these problems into understandable steps for students.\nFeedback from both students and professors was consistent. Students found ChatGPT helpful for addressing basic questions but reported struggles when tackling complex queries. Professors highlighted that, while generated code was often syntactically correct, it contained logical flaws, requiring manual corrections and expert oversight for advanced tasks.\nOverall, these findings suggest that while ChatGPT holds promise as an educational tool for standard and simpler content, it requires significant improvements in areas involving creativity, depth of"}, {"title": "4.3 ChatGPT-40 and o1 Integration's Results", "content": "The integration of ChatGPT-40 and o1 significantly enhanced the teaching and learning experience in TA-led DSA courses, particularly by improving students' understanding of complex algorithms, fostering critical thinking, and providing more detailed feedback during problem-solving. ChatGPT ol's advancements in reasoning capabilities improved students' ability to solve intricate tasks, such as dynamic programming and graph traversal, which enhanced their engagement and critical thinking skills, ultimately leading to better overall performance.\nChatGPT-40 Results: ChatGPT-40 effectively supported routine tasks, such as generating diverse class materials (e.g., lecture notes and practice exercises) and providing real-time feedback for visual-based learning. However, it exhibited limited accuracy in image processing (around 20%), often requiring TA intervention, and faced difficulties generating novel, complex problem sets.\nChatGPT 01 Results: ChatGPT 01, however, excelled in areas where GPT-40 had limitations. Its ability to handle multi-step reasoning allowed it to assist students with more complex problems, such as dynamic programming, graph theory, and recursive algorithms. o1's step-by-step reasoning capabilities enabled the TA to provide more detailed explanations, improving students' grasp of difficult concepts. This feature also allowed students to gain a deeper understanding of how solutions were derived, thus improving problem-solving skills.\nAssessment and Feedback: While ChatGPT-40 offered immediate responses for assessments, ChatGPT 01 identified deeper logical errors, such as missing break statements in nested loops, and provided alternative solutions, which led to a more thorough understanding of the subject matter among students.\nOverall, the combination of ChatGPT-40 for routine tasks and ChatGPT 01 for complex reasoning provided a well-rounded solution, allowing for both breadth and depth in the educational process."}, {"title": "5 DISCUSSION AND FUTURE WORK", "content": "This study evaluated the impact of integrating ChatGPT into a data structures and algorithms (DSA) course under the supervision of a teaching assistant (TA). Our results demonstrated that structured prompts and active TA supervision enhanced student engagement and academic performance, as indicated by increased participation rates, improved quiz scores, and higher final exam performance. The combination of ChatGPT with TA supervision is the novel contribution of this study, as previous research often evaluated these tools independently. Students who used ChatGPT under these conditions demonstrated a better understanding of complex concepts and achieved higher exam scores compared to those who only received TA support without ChatGPT integration."}, {"title": "5.1 Summary and Key Findings", "content": "This study evaluated the impact of integrating ChatGPT into a data structures and algorithms (DSA) course under the supervision of a teaching assistant (TA). Our results demonstrated that structured prompts and active TA supervision enhanced student engagement and academic performance, as indicated by increased participation rates, improved quiz scores, and higher final exam performance. The combination of ChatGPT with TA supervision is the novel contribution of this study, as previous research often evaluated these tools independently. Students who used ChatGPT under these conditions demonstrated a better understanding of complex concepts and achieved higher exam scores compared to those who only received TA support without ChatGPT integration."}, {"title": "5.2 Interpretations and Implications", "content": "The combination of ChatGPT, structured prompts, and TA support significantly enhanced the learning experience. Unlike previous research evaluating these tools independently, this study shows that structured prompts encourage critical thinking rather than passive acceptance of answers. TA supervision ensured meaningful engagement and prevented misuse. These insights align with existing literature, while also highlighting the effectiveness of integrating TA support with ChatGPT to achieve better learning outcomes.\nThis study contributes to understanding LLMs in education by demonstrating how combining ChatGPT with active supervision can complement traditional teaching, reduce educator workload, and provide personalized learning. This integration supports educators in focusing on complex instructional activities while automating routine tasks and delivering tailored feedback, ultimately enhancing student learning."}, {"title": "5.3 Balancing LLMs and Human Instruction", "content": "Previous research often explored LLMs as educator replacements [2, 4]. In contrast, this study implemented a balanced, hybrid model where ChatGPT provided supplementary support for routine tasks while human instructors guided critical thinking, managed learning pathways, and addressed individual needs. The positive outcomes observed reinforce the potential of LLMs as support tools rather than replacements, suggesting that the hybrid approach yields superior educational outcomes."}, {"title": "5.4 Challenges and Limitations", "content": "The study also identified several limitations. ChatGPT struggled with tasks requiring visual elements, such as graph and tree structures, and sometimes provided inconsistent responses. TA supervision was crucial to ensure accuracy. While ChatGPT 01 improved some aspects, issues with generating novel problem sets or solving complex and creative questions persisted, indicating the need for further refinement and human oversight."}, {"title": "5.5 Future Directions and Recommendations", "content": "Future research should focus on optimizing LLM integration by developing better prompts, improving the handling of visual and complex problems, and including larger, more diverse samples. Expanding the use of LLMs to other subjects and educational levels can further explore their potential and limitations, enhancing learning experiences and outcomes in DSA courses and beyond. Moreover, as LLMs are improving rapidly, researchers should study how new versions of LLMs, especially OpenAI's ChatGPT, can be integrated and how they can improve educational outcomes."}]}