{"title": "Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in Foundation Model based Systems", "authors": ["Md Shamsujjoha", "Qinghua Lu", "Dehai Zhao", "Liming Zhu"], "abstract": "The rapid advancement and widespread deployment of foundation model (FM) based systems have revolutionized numerous applications across various domains. However, the fast-growing capabilities and autonomy have also raised significant concerns about responsible AI and AI safety. Recently, there have been increasing attention toward implementing guardrails to ensure the runtime behavior of FM-based systems is safe and responsible. Given the early stage of FMs and their applications (such as agents), the design of guardrails have not yet been systematically studied. It remains underexplored which software qualities should be considered when designing guardrails and how these qualities can be ensured from a software architecture perspective. Therefore, in this paper, we present a taxonomy for guardrails to classify and compare the characteristics and design options of guardrails. Our taxonomy is organized into three main categories: the motivation behind adopting runtime guardrails, the quality attributes to consider, and the design options available. This taxonomy provides structured and concrete guidance for making architectural design decisions when designing guardrails and highlights trade-offs arising from the design decisions.", "sections": [{"title": "I. INTRODUCTION", "content": "A foundation model (FM) is a large-scale machine learning model pre-trained on massive amounts of datasets using self-supervision at scale. These models are designed to be highly versatile and can adapt to a wide range of downstream tasks. The term 'foundation' reflects their role as the fundamental base upon which many specialized models are built [1]. FMs possess emergent capabilities, meaning their behaviors and susceptibilities arise implicitly from the training data rather than being explicitly programmed. This allows them to perform tasks that were not originally anticipated during their initial training [2].\nAn FM-based system refers to an application system that utilizes an FM as a core component, interacting with other AI or non-AI components to perform tasks [3]. FM-based systems have experienced significant growth in recent years. For example, approximately 67% of organizations globally have adopted FM-based products [4]. Additionally, their market size is expected to grow at a compound annual growth rate of 36.5% over the next six years [5-7].\nThe fast-growing capabilities and autonomy of FM-based systems introduce significant concerns about responsible AI and AI safety, such as generating harmful or offensive content, producing dangerous or unintended outcomes, exhibiting discriminatory behavior, compromising user privacy, spreading misinformation, facilitating cyberattacks, etc [1, 6, 8].\nTo address these challenges, runtime guardrails are required to be incorporated into FM-based systems to ensure the behavior of the system is responsible and safe. There have been some initial efforts on guardrails, such as input filtering [1, 9], output modification [10, 11], adaptive fail-safes that can prevent harmful outputs [12, 13], real-time monitoring and detection [14\u201317], continuous output validation to ensure adherence to ethical standards [18-20] etc.\nHowever, the existing runtime guardrails mainly focus on inputs and outputs of foundation models, which do not capture the complexity of FM-based systems. FM-based systems are compound Al systems [21], which include foundation models, narrow models for specific tasks, and non-AI components (such as data retriever and external tools). Guardrails need to be placed at different components, taking into account the operational and environmental context. Also, most of the current work primarily addresses functional correctness of guardrails. Quality attributes, such as customizability and interpretability, are often not considered when designing guardrails.\nTherefore, in this paper, we present a taxonomy for guardrails from a software architecture perspective. The taxonomy classifies and compares the characteristics and design options of guardrails. There are three main categories in the taxonomy: the motivation for adopting runtime guardrails, the quality attributes that should be addressed in the guardrails design, and the design options available. We developed this taxonomy based on the results of a systematic literature review (SLR). The main contributions of this paper are as follows:\n\u2756 The taxonomy offers a comprehensive comparative anal-ysis of different design options and provides structured and concrete guidance for making architectural design decisions about guardrails to achieve AI-safety-by-design. The design options are classified into actions, targets, scopes, rules, autonomy, modalities, and underlying tech-niques."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "FMs have significantly impacted the architecture of AI systems [1, 20]. Although guardrails for FM-based systems have been explored in various contexts, this paper is the first study assessing existing work to provide a comprehensive understanding. Below, we present key background and related works required to understand guardrails and the research gap.\n\nThe terms foundation models (FM) and large language models (LLMs) are often used interchangeably in the liter-ature. However, they are not the same [22, 23]. Foundation models are large-scale machine learning models pre-trained on massive amounts of diverse datasets (such as text, images, videos) using self-supervised learning techniques [6]. They can perform a wide range of tasks across various application domains, including multimodal tasks. LLMs are a subset of FMs focused on language-related tasks and analyze data to perform natural language processing (NLP) tasks [22, 24]. Both FMs and LLMs are pre-trained on large datasets [25] and adapted for specific tasks using techniques like fine-tuning, in-context learning, distillation, and Retrieval-Augmented Gener-ation (RAG) to improve response quality [24].\nFM-based systems incorporate FMs as core components within larger architectures designed to utilize their capabili-ties [3]. These systems integrate FMs with additional com-ponents such as data retrievers (e.g., RAG), external tools and others. The complexity of FM-based systems lies in ensuring seamless interoperability among these components while ensuring responsible AI and AI safety [1].\nIn 2021, Bommasani et al.[1] provided a comprehensive discussion on foundation models, illustrating the essential elements and relationships between them. The authors also discussed the practical applications of FM-based systems, highlighting their economic and operational advantages over traditional systems. Two years later, Zhou et al. covered recent research advancements, challenges, and opportunities for pre-trained foundation models in text, image, graph, and other data modalities in their survey paper [20]. Both works offer excellent insights into future research directions to address open problems and associated risks. Studies [1, 26] mention that foundation model-based systems often inherit responsible AI and AI safety issues and can cause negative consequences.\nLu et al. developed a taxonomy of FM-based systems focusing on their pretraining, adaptation, architectural design, and responsible-AI-by-design [27]. The taxonomy aids soft-ware architects and developers in evaluating and integrating foundation models into complex systems. The authors also highlighted considerations for cost, accuracy, and responsible AI related quality attributes for the systems. The authors later proposed a reference architecture for designing respon-sible and safe foundation model based systems in [3]. The works [28, 29] explore the risks associated with deploying LLMs and evaluate current approaches to mitigate such risks through model alignment. Recently, Lu et al. discussed that responsible AI practices are highly recommended for FM-based systems [2, 30]. This includes technical solutions and adherence to regulatory and ethical guidelines to maintain public trust and safety [31]. They also emphasized that FM-based systems must ensure they are developed and deployed in a responsible, safe, and legal way [32-34].\nThere exist several frameworks and tools for designing guardrails at design time and runtime. Significant have been put into model alignment during design time, which fo-cuses on aligning the FM's outputs with human values and ethical standards. Pre-training and adaptation strategies play a significant role in mitigating risks in FM-based systems through guardrails. Pre-training models on diverse and eth-ically sourced datasets helps align them more closely with ethical standards. Continuous adaptation through fine-tuning further reduces AI risks [1]. Ensuring ethical and responsible AI practices involves not only technical solutions but also adherence to regulatory and ethical guidelines within the systems. The adoption of comprehensive AI frameworks that incorporate ethical principles into the design and deployment of FMs is crucial for maintaining public trust and safety [31].\nSome initial efforts have been made toward runtime guardrails. Zhou et al. [20] present an excellent discussion of the literature that addresses the monitoring and controlling behavior of FM-based systems. Various tools and frameworks have also been developed to tackle these challenges. NeMo Guardrails[16] provides programmable guardrails to ensure that models operate within safe parameters by monitoring inputs and outputs in real-time, dynamically adjusting behav-ior to prevent harmful outcomes[27]. OpenAI's Moderation API [35] monitors and filters harmful content generated by models to protect user interactions. The GuardAgent frame-work [36] utilizes an LLM agent to oversee and safeguard other agents. It demonstrates strong generalization and low op-erational overhead by dynamically generating guardrail code.\nWe also found that the continuous validation ensures that the outputs from FM-based systems adhere to predefined ethical standards and guidelines. Techniques such as auditing models [18] through multi-layered approaches [18, 37] system-"}, {"title": "III. METHODOLOGY", "content": "This study focuses on two primary concepts: (i) founda-tion model-based systems and (ii) runtime guardrails. We adopted the Petticrew and Roberts approach [39] to define the Population, Interventions, Comparison, Outcomes, and Context (PICOC), within which the intervention in this study is delivered. Using these PICOC components and following Kitchenham's guidelines [40], we develop the protocol for this study. The fol-lowing subsections detail the steps and processes undertaken in this study."}, {"title": "C. Search string formulation", "content": "Relevant primary studies for this SLR were identified based on the RQs defined in Section III-B. With the assistance of the PICOC approach (shown in Table I), our search terms were divided into two primary concepts, as shown in Table II. These concepts helped us to set a well-formulated search string.\nWe also used synonyms, abbreviations, and alternative spellings of search terms to increase the number of relevant research papers. We used truncation and wildcard operators to save time and effort in finding these alternative keywords. Moreover, different supplementary key terms or phrases dis-covered during search iterations were added to our search string to enhance our search strategy. Our supposition is that they will collect all relevant articles that contains guardrails for FM-based system. When constructing the final search query, the identified keywords, their alternatives and related terms were linked with Boolean AND (&&), OR (||) and NOT (\u00ac) operators as follows as follows:\n\n{(C_{11}||C_{12}||...||C_{1n})AND(C_{21} ||C_{22}||...|| C_{2n})\nNOT(UC_{1}||UC_{2}||...||UC_{n})]\n(1)\nwhere $C_{11}$ ...$1n$, and $C_{21}$ ...$2n$ & Co1 and Co2 of Table II, respectively; and $UC_{1} . . . UC_{n}$ refers the Exclude Context defined earlier in PICOC table (Table I)."}, {"title": "D. Selection of papers: Inclusion and exclusion criterion", "content": "Table III and Table IV present the Inclusion Criteria (IC) and Exclusion Criteria (EC) that have been used to iden-tify the studies for this SLR, respectively. We found that a considerable amount of work on guardrails exists in gray literature; however, we excluded them as they often lack peer review and a rigorous validation process. While some sources [42] argue that gray literature is an important resource for systematic literature reviews (SLRs), such literature can be misleading and introduce biases and inconsistencies in the"}, {"title": "E. Study Search and Filtering Process", "content": "Our filtration process is further detailed in Figure 2. Initially we ran the formatted query on four major databases that returned 1,733 research papers. We then applied filtering and classified the studies found according to the guidelines presented in [40, 41]. In our initial filtration process, we removed 108 papers due to being duplicated articles, editorial or key notes. After reading the title, abstract, conclusion and skimming through the introduction, methodology and results, we applied our exclusion criterion defined in Table IV, and 1524 further papers were removed. During the third step of filtration, we applied inclusion criteria and removed 80 papers as these studies did not meet ICs shown in Table IV. In parallel, we did a manual search and found 189 papers that meet our key concepts defined in Table II but not contain any unwanted content (UC). After applying ICs and ECs, 15 out of 189 papers were selected. Finally, we did a cross-check and ended up with 32 papers."}, {"title": "F. Data Extraction and Quality Assessment", "content": "We used a semi-automated process [44] for data extraction from the selected studies to answer our RQs. Key qualita-tive information extracted from each selected study includes guardrails definitions, motivations, reported key quality at-tributes, and design options. We also extracted several relevant pieces of information to understand the context and consider-ations in designing and evaluating runtime guardrails.\nWe then evaluated each study based on the following five Quality Assessment Criteria (QAC) on a scale from 1 (Very Poor) to 5 (Excellent). If a study's average score was less than 2, it was excluded from further analysis. Otherwise, we used the qualitative information to decide this. The QAC for this study are as follows:\n\u2756 Relevance to guardrails for FM-based systems.\n\u2756 Clear methodology for guardrail design.\nAdequate data collection, analysis, and evaluation.\n\u2756 Discussion of challenges in designing guardrails.\n\u2756 Practical applicability of findings for guardrails."}, {"title": "IV. DESIGN TAXONOMY FOR GUARDRAILS IN\nFOUNDATION MODEL-BASED SYSTEMS", "content": "In this section, we present our taxonomy of runtime guardrails for FM-based systems. As illustrated in Figure 3, this taxonomy is organized into categories based on identified problems, quality attributes, and available design options, which we use in the following sub-sections to answer our key research questions"}, {"title": "A. Motivation for adopting runtime guardrails (RQ1)", "content": "Our first research question investigates the fundamental reasons for integrating guardrails into FM-based systems. We found that guardrails are primarily implemented to mitigate bias, harmful content, and unintended behaviors. Additionally, guardrails better maintain ethical and safety standards in areas such as accuracy, privacy, security, safety, fairness, IP protection, and compliance, as discussed below."}, {"title": "B. Quality Attributes Considered in the Design of Guardrails\n(RQ2)", "content": "We identified eight key quality attributes essential for the design of runtime guardrails in FM-based systems. Below, we discuss these attributes in detail, highlighting their roles and importance.\n1) Accuracy: Guardrail accuracy refers to the precision in identifying and mitigating risks, i.e., preventing undesired behaviors or outputs [45]. Functional accuracy emphasizes how well guardrails perform their intended tasks to meet user expectations and requirements. For instance, a guardrail used for a customer service chatbot must accurately block sensitive information from being disclosed. If a customer asks, \u2018What is my current account balance?' the guardrail must prevent disclosing the balance, instead providing a safe response like, 'For security reasons, please check your balance through our secure app.' If it fails to do so (false negatives) or incorrectly flags benign information (false positives), it compromises functional accuracy. Predictive accuracy involves the chatbot's correct understanding and response to inquiries. We found that the accuracy of guardrails is evaluated using automated methods, primarily considering the systems' performance [16], output quality [55], overall trustworthiness [10, 49], and sys-tem adaptability [26, 49].\n2) Generalizability: Generalizability in guardrails refers to their ability to function effectively across diverse applica-tions [63]. Such guardrails ensure that the protective measures are not overly specific to a single use case but can adapt to various contexts and still perform reliably. For example, a chatbot must comply with different financial regulations across countries to ensure compliance without reconfiguration. Dong et al.[15] and Wang et al.[64] emphasize the need for guardrails that can extend their applicability to new domains without significant reconfiguration or loss of performance, even during unexpected inputs or data types. Furthermore, gen-eralizability enhances the ability to handle diverse linguistic, cultural, and operational contexts to provide robust protection and to enhance the system's resilience and reliability [1, 12].\n3) Customizability: Customizable guardrails provide tai-lored protection that meets specific requirements and supports diverse operational needs in FM-based systems [1, 65]. They allow for adjustments and configurations that align with par-ticular operational goals, data characteristics, and regulatory environments. For example, a customer service chatbot can enable priorities for different guardrails and adjust data han-dling based on the user's location, ensuring compliance with GDPR in Europe and CCPA in the U.S. [66]. Customizability also includes the capability to integrate user-defined rules and policies, ensuring that the guardrails can support diverse operational contexts and evolving needs [64].\n4) Adaptability: Adaptability in guardrails is known as their capability to adjust and remain effective under varying conditions and data landscapes as context evolves [24, 26]. This attribute ensures robust and continuous protection by dy-namically responding to changes in input data, usage patterns, and emerging threats without manual reconfiguration [15]. For example, a customer service chatbot can automatically update its guardrails to detect and block new offensive terms during interactions. This includes the ability to incorporate new knowledge and advancements in threat detection tech-niques [1, 54].\n5) Traceability: The traceability attribute of guardrails tracks and records the origins, processes, and decision paths, such as input and output of FMs, external tools, etc. [27]. It involves maintaining detailed logs and records that can be audited to understand how decisions are made. For example, in a customer service chatbot, traceability ensures that every recommendation can be traced back to the data sources and algorithms used. This includes logging which data inputs influenced the response and what external APIs or tools were accessed, providing a clear audit trail for transparency and accountability. Traceability also aids in identifying the root causes of issues. This enables timely and accurate trou-bleshooting and improvement [26], and helps in maintain-ing user trust and meeting regulatory requirements [10, 16]. Additionally, comprehensive documentation of data sources and model modifications better support effective auditing and compliance checking [12].\n6) Portability: Portability in guardrails for FM-based sys-tems refers to the ability of these protective measures to be easily adapted and applied across different foundation model (FM) systems and platforms [27]. This includes ensuring that the guardrails function consistently across various FM archi-tectures and environments, thereby maintaining their effective-ness and integrity regardless of the underlying system [26]. For example, the same guardrail can be applied for content moderation in both a customer service chatbot and a social media platform, regardless of their underlying technology. The benefits of designing portable guardrails include compatibility across multiple programming languages and frameworks fa-cilitate their integration into diverse technological stacks [49]. These capabilities ensure that the guardrails remain effective and operational as the system evolves or migrates to new environments. Portable guardrails also support seamless up-dates and improve scalability to maintain high standards of security and compliance while adapting to new technological advancements within systems [16].\n7) Interoperability: Interoperable guardrails work seam-lessly across different systems and technologies [27]. They ensure that security, privacy, and compliance protocols can be applied consistently, even in heterogeneous environments that utilize varied software and hardware components, or diverse technological ecosystems [16, 67]. Guardrails that interface with various APIs and data formats also enable smooth com-munication and operation across different systems [26]. For example, they enable a customer service chatbot and internal support system to share data securely and consistently. This promotes cohesive and unified security management, reducing the complexity of maintaining multiple disparate protective measures [1], and better support collaborative efforts and data sharing [49]."}, {"title": "C. Design of Guardrails (RQ3)", "content": "This section presents a structured taxonomy for designing guardrails, focusing on identifying various design alternatives.\n1) Guardrail Actions: Guardrail actions are crucial for addressing the specific needs of FM-based system components. We have identified the following guardrail actions as key elements for FM-based systems:\n\u2756 Block: The block action prevents specific inputs (such as user prompts) or outputs (such as content generated by FMs) from being processed or sent by various compo-nents (such as FMs and tools) in FM-based systems [54]. For example, the block action can reject the user prompts containing harmful instructions, thus preventing unde-sired outcomes.\nFilter: The filter action involves scanning and removing undesired or irrelevant content from the inputs or outputs of different components in FM-based systems [69, 70]. For instance, a filter may remove any personal data contained in the user prompts or the output generated by FMs.\n\u2756 Flag: The flag action is used to mark specific inputs, outputs, operations within FM-based systems [16]. For example, unusual transactions requested by the FM-based agent can be flagged for human review to ensure they comply with organizational policies [1, 30].\n\u2756 Modify: The modify action allows for the adjustment of inputs or outputs of various components in the FM-based systems to meet specific requirements or standards [9]. For example, the system can modify the user prompts by adding more context and examples, making it easier for the FM to accurately interpret the user's intentions and provide more relevant responses.\n\u2756 Validate: The validate action checks inputs, outputs, intermediate results against predefined criteria to ensure they meet specified requirements or standards [26, 70]. For example, the customer service chatbot could validate if the output generated by the FM-based system contains any sensitive company information.\n\u2756 Prioritize: The prioritize action enables the FM-based system to allocate resources and attention based on the importance of specific tasks, e.g., processing urgent user queries first [28].\n\u2756 Rate limit: The rate limit action controls the frequency and volume of requests or outputs processed by the system/component within a given time frame [16, 53]. For example, a rate limit can be set to restrict the number of API calls a single user can make.\n\u2756 Parallel calls: The parallel calls action can send multiple requests to the system/component to improve respon-siveness, e.g., a user can send a prompt to the system multiple times at the same time and select the better response [16, 53].\nRetry: The retry action involves attempting a request again after an initial failure or unsatisfactory result [13].\n\u2756 Fall back: When the system is unable to handle a request, the fall back action can redirect to the previous state or an alternative solution [13, 16, 71].\nHuman intervention: The human intervention action requires humans to review and approve specific outputs or decisions [16, 53, 55]. For example, responses involving sensitive medical advice might be flagged for human approval before being communicated to users.\n\u2756 Defer: The defer action postpones the processing of a request or task until specific conditions are met or additional information is available [72].\n\u2756 Isolate: The isolate action involves segregating a specific entity (e.g., user) or component to prevent interaction with the system [19, 57, 60]. For example, a system might isolate a compromised narrow AI model suspected of being poisoned with malicious data in a sandbox envi-ronment, preventing potential harm to the main system.\n\u2756 Simulate: The simulate action involves running tests in a controlled environment to predict and analyze potential outcomes [1]. For instance, a system might simulate different configurations to determine the most effective plan.\n\u2756 Redundancy: The redundancy action involves imple-menting backup processes or components to ensure con-tinuity and reliability in case of failures [16, 26]. For example, an agent can implement two similar workflows in parallel, so if one workflow encounters an issue, the other can continue operating without interruption.\nLog: The log action involves recording system activities, interactions, and events [11, 70]. For instance, logging all user interactions with an FM-based chatbot allows for the analysis of user interests."}, {"title": "2) Targets for Guardrails", "content": "The key targets guardrails can be applied to include prompts, models, external data, non-AI components, and agent-specific targets.\n\u2756 Prompts: Prompts are the initial user inputs or queries. Guardrails on prompts help ensure that user prompts are relevant, appropriate, formatted correctly, and easier for FMs to understand [37, 56, 70].\n\u2756 Models: Models include FMs and narrow models for specific tasks. Guardrails ensures the outputs generated by models are relevant, appropriate and safe. Also, guardrails oversee the utilization of both FMs and narrow models, preventing misuse and ensuring their application under appropriate conditions [1, 20].\n\u2756 External Data: Guardrails enforce stringent monitoring and validation of external data sources, particularly in Re-trieval augmented generation scenarios [17]. For example, they can prevent the integration of unverified news that could potentially mislead the system's outputs, ensuring that only reliable and accurate information is used [73].\n\u2756 Non-AI Components: Guardrails also apply to non-AI components, e.g. when making calls APIs [1, 71]. For instance, they can monitor API calling to prevent data leaks [74], such as restricting access to sensitive information.\n\u2756 Agent-Specific Targets: Guardrails target following key aspects of agents:\nGoals: Ensuring that agents' goals align with human values and do not deviate from the human's intended goals [16, 49].\nContext: Monitoring the context that agents collect to ensure it is relevant information and appropriate [36].\nMemory: Managing the agents' memory to retain rel-evant data and discard outdated or irrelevant informa-tion, while also preventing memory poisoning [36, 64].\nReasoning: Enhancing agents' reasoning capabili-ties to ensure accurate analysis and sound decision-making [30].\nPlans: Ensuring the generated plans align with human goals [30, 54].\nActions: Monitoring agents' actions to ensure they are safe and effective in achieving desired outcomes [36].\nTools: Overseeing the proper use of tools by agents, including implementing access controls, restricting tool capabilities, and detecting potential vulnerabilities [36, 49].\nOther Agents: Managing interactions between agents to ensure collaboration, prevent conflicts, and mitigate risks associated with malicious behaviors [30, 49].\nIntermediate Results: Intermediate results are the outputs generated at various stages during the workflow generation of agents, before reaching the final outputs. By monitoring intermediate results, guardrails can de-tect anomalies or inaccuracies before they propagate to the final results.\nFinal Results: Final results are the end outputs gen-erated by agents, which are delivered to users or downstream systems. Guardrails ensure that the final results meet user expectations and comply with ethical guidelines and legal regulations."}, {"title": "3) Guardrails Scopes", "content": "The scope of guardrails in FM-based systems ranges from individual preferences to industry standards. At the user level, guardrails reflect individual pref-erences and requirements. This involves adjusting the system's behavior based on user-defined settings to align outputs with both user expectations and ethical considerations. Incorporat-ing user preferences into guardrails provides a personalized experience while maintaining safety and compliance [55, 69]. Such guardrails ensure that the system respects user autonomy and produces outputs that are relevant and acceptable.\nAt the organizational level, guardrails align with internal policies and procedures governing the operation and use of FM-based systems. This includes compliance with corporate governance, data protection policies, and ethical guidelines established by the organization [12]. Guardrails also ensure consistency and accountability across different departments and functions within the organization."}, {"title": "4) Rules", "content": "Guardrails rules can be configured in different ways: including uniform rules, priority-enabled rules, context-dependent rules, and negotiable rules. A uniform strategy applies the same set of guardrails consistently across all sce-narios, ensuring simplicity and uniformity [67]. It is particu-larly effective in environments with stable and well-understood risks. It largely reduces the complexity of managing diverse guardrails [55]. A priority-enabled strategy prioritizes certain guardrails based on the criticality and sensitivity of operations or data. Context-dependent strategies adjust the implementa-tion of guardrails based on the system's specific operational context. This allows for dynamic adjustments to guardrails in response to changing conditions, user needs, and operational environments [49]. The negotiability of guardrails, categorized into hard and soft, defines the level of flexibility in enforcing rules. Soft guardrails allow adjustments based on context and situational demands, providing a balance between protection and operational flexibility [49]. In contrast, hard guardrails are rigid and non-negotiable, ensuring adherence to critical legal, ethical, or safety standards [12, 32]."}, {"title": "5) Autonomy", "content": "Guardrails vary based on the level of auton-omy in the system. They can be either automatic or require human intervention. Automatic guardrails function without human oversight, relying on pre-defined rules and real-time monitoring to enforce protections [53]. This is useful in scenarios requiring immediate response to potential threats. In contrast, human intervention guardrails involve manual oversight, where human operators review and approve critical outputs or actions flagged by the system [32]. This approach is essential in high-stakes environments, such as financial sys-tems, where human judgment can provide an additional layer of scrutiny and ensure compliance with regulatory standards."}, {"title": "6) Modality", "content": "The modality of guardrails refers to the types of data and interactions they manage. Guardrails can be designed for single modal or multimodal systems. Single modal systems operate with one type of data input or output, such as text, image, or audio. For instance, in text-based systems, guardrails focus on addressing issues like offensive language, misinformation, and data privacy [49]. In image-based systems, they may involve techniques for detecting explicit content or ensuring image quality standards [26]. Multimodal guardrails address the combined risks of han-dling multiple data types. They synchronize protections across different data types, ensuring comprehensive security and compliance [55]. For example, a system that generates text based on image inputs must ensure accurate and ethical representation of the image content. This requires advanced cross-modal analysis and validation techniques to ensure the system operates reliably and ethically across all data types it handles [53]."}, {"title": "7) Underlying Technique", "content": "The underlying techniques of guardrails include rule-based, hybrid, and machine learning models, with each representing a distinct design option to meet specific requirements. These techniques offer the nec-essary flexibility, adaptability, and robustness to protect the systems [3, 27]\nRule-based models utilize predefined rules to monitor and control FM-based system behavior. These models implement strict and deterministic guidelines that the system must follow to ensure compliance with regulatory requirements for data access and processing [49]. They are particularly effective in environments where operational parameters are well-defined and stable. Rule-based systems can be updated and are somewhat flexible. However, they may still struggle with unexpected scenarios, such as detecting novel AI-generated content that falls outside predefined rules. This reliance on static rules can limit their adaptability and regular updates are needed [16, 71].\nIn contrast, machine learning models dynamically adapt and improve guardrails based on new data and scenarios. These models can also learn from historical data and identify patterns that indicate potential risks or compliance issues [64]. Machine learning models can be further subclassed into narrow models and foundation models. Narrow models are special-ized systems designed for specific tasks or domains. They require targeted guardrails to address domain-specific risks and compliance needs [15]. Foundation models are large, general-purpose models that serve as the backbone for multiple ap-plications and tasks. These models necessitate comprehensive and scalable guardrails to handle a wide range of risks and compliance issues across different applications [26]. Never-theless, they can be computationally intensive and require substantial data for training.\nHybrid models integrate rule-based systems with the adapt-ability of machine learning models to respond to new threats and evolving data patterns [53]. For instance, Khorramrouz et al.[59] demonstrate the use of the PaLM 2 framework to process user input and dynamically implement rule-based decisions. This framework tests the system's limits by itera-tively generating toxic content to evaluate PaLM 2's safety guardrails. However, integrating hybrid models can increase system complexity and create additional challenges [53]."}, {"title": "V. THREATS TO VALIDITY", "content": "Our study is subject to standard literature search and se-lection bias threats. We addressed these threats by searching the most commonly used databases in the IT and software engineering domains. We adjusted our search strings several times during the automatic search to maximize the number of relevant articles matching two key concepts: 'guardrails' and 'FM-Based systems'. We also kept our search string generic to search through the titles, abstracts, keywords, and full text of articles to cover the maximum number of relevant papers. We then conducted a manual search on Google Scholar to complement the automatic search using a snowballing strategy. Furthermore, predefined review protocols with detailed inclu-sion and exclusion criteria helped us reduce bias in selecting primary studies. We applied several quality assessment criteria (shown in Section III-F) to estimate the quality of the selected primary studies. Even though the proposed criteria were not too strict, applying them indeed caused several initially se-lected papers to be excluded. To mitigate the risk of missing important data from the primary studies, we reinstated the excluded papers closely related to the primary studies.\nMoreover, our definitions and categorizations may not cap-ture all relevant aspects of guardrails in FM-based systems. To mitigate this threat, we validated the taxonomy through extensive literature review and expert feedback. However, this introduces a risk of producing biased results that address only expert needs, as the people involved in the feedback process have extensive experience in the AI and software engineering domains. Our review protocols helped us to reduce such bias.\nWe prepared a guardrails taxonomy and conducted a com-parative analysis of its components to help the reader better understand their design and evaluation. We critically examined the strength and consistency of relationships in the selected studies for a reliable taxonomy structure and drew conclusions. Nonetheless, the generalizability of guardrails to different contexts and types in FM-based systems remains a potential limitation, and specific adaptations might be necessary for certain systems, such as those used in healthcare or financial organizations. Additionally, our findings face a challenge as some of them may become outdated due to the rapid evolution of FM-based systems and associated guardrails."}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "To better understand runtime guardrails in FM-based sys-tems, this paper developed and presented a comprehensive guardrail taxonomy and provided a comparative study of its components based on a systematic literature review. Our proposed taxonomy categorizes guardrails based on their fun-damental objectives, essential quality attributes, performed actions, targeted aspects, covered scopes, employed rules, autonomy, modalities, and underlying techniques.\nOur key findings emphasize that the effective integration of guardrails mitigates risk such as biases, harmful content, and unintended behaviors in FM-based systems. Practitioners can use the proposed taxonomy to improve the design of guardrails are responsible and safe. Moreover, the taxonomy provides a theoretical framework that researchers and policymakers can use to develop guidelines and standards that promote AI-safety-by-design in FM-based systems. In the future, we plan to develop a guardrails service for FM-based agents, integrating various design options outlined in this taxonomy."}]}