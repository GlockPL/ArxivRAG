{"title": "Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in Foundation Model based Systems", "authors": ["Md Shamsujjoha", "Qinghua Lu", "Dehai Zhao", "Liming Zhu"], "abstract": "The rapid advancement and widespread deployment of foundation model (FM) based systems have revolutionized numerous applications across various domains. However, the fast-growing capabilities and autonomy have also raised significant concerns about responsible AI and AI safety. Recently, there have been increasing attention toward implementing guardrails to ensure the runtime behavior of FM-based systems is safe and responsible. Given the early stage of FMs and their applications (such as agents), the design of guardrails have not yet been systematically studied. It remains underexplored which software qualities should be considered when designing guardrails and how these qualities can be ensured from a software architecture perspective. Therefore, in this paper, we present a taxonomy for guardrails to classify and compare the characteristics and design options of guardrails. Our taxonomy is organized into three main categories: the motivation behind adopting runtime guardrails, the quality attributes to consider, and the design options available. This taxonomy provides structured and concrete guidance for making architectural design decisions when designing guardrails and highlights trade-offs arising from the design decisions.", "sections": [{"title": "I. INTRODUCTION", "content": "A foundation model (FM) is a large-scale machine learning model pre-trained on massive amounts of datasets using self-supervision at scale. These models are designed to be highly versatile and can adapt to a wide range of downstream tasks. The term 'foundation' reflects their role as the fundamental base upon which many specialized models are built [1]. FMs possess emergent capabilities, meaning their behaviors and susceptibilities arise implicitly from the training data rather than being explicitly programmed. This allows them to perform tasks that were not originally anticipated during their initial training [2].\nAn FM-based system refers to an application system that utilizes an FM as a core component, interacting with other AI or non-AI components to perform tasks [3]. FM-based sys- tems have experienced significant growth in recent years. For example, approximately 67% of organizations globally have adopted FM-based products [4]. Additionally, their market size is expected to grow at a compound annual growth rate of 36.5% over the next six years [5-7].\nThe fast-growing capabilities and autonomy of FM-based systems introduce significant concerns about responsible AI and AI safety, such as generating harmful or offensive con- tent, producing dangerous or unintended outcomes, exhibiting discriminatory behavior, compromising user privacy, spreading misinformation, facilitating cyberattacks, etc [1, 6, 8].\nTo address these challenges, runtime guardrails are re- quired to be incorporated into FM-based systems to ensure the behavior of the system is responsible and safe. There have been some initial efforts on guardrails, such as input filtering [1, 9], output modification [10, 11], adaptive fail-safes that can prevent harmful outputs [12, 13], real-time monitoring and detection [14\u201317], continuous output validation to ensure adherence to ethical standards [18-20] etc.\nHowever, the existing runtime guardrails mainly focus on inputs and outputs of foundation models, which do not capture the complexity of FM-based systems. FM-based systems are compound Al systems [21], which include foundation models, narrow models for specific tasks, and non-AI components (such as data retriever and external tools). Guardrails need to be placed at different components, taking into account the op- erational and environmental context. Also, most of the current work primarily addresses functional correctness of guardrails. Quality attributes, such as customizability and interpretability, are often not considered when designing guardrails.\nTherefore, in this paper, we present a taxonomy for guardrails from a software architecture perspective. The tax- onomy classifies and compares the characteristics and design options of guardrails. There are three main categories in the taxonomy: the motivation for adopting runtime guardrails, the quality attributes that should be addressed in the guardrails design, and the design options available. We developed this taxonomy based on the results of a systematic literature review (SLR). The main contributions of this paper are as follows:\n\u2756 The taxonomy offers a comprehensive comparative anal- ysis of different design options and provides structured and concrete guidance for making architectural design decisions about guardrails to achieve AI-safety-by-design. The design options are classified into actions, targets, scopes, rules, autonomy, modalities, and underlying tech- niques."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "FMs have significantly impacted the architecture of AI systems [1, 20]. Although guardrails for FM-based systems have been explored in various contexts, this paper is the first study assessing existing work to provide a comprehensive understanding. Below, we present key background and related works required to understand guardrails and the research gap.\nBackground\nThe terms foundation models (FM) and large language models (LLMs) are often used interchangeably in the liter- ature. However, they are not the same [22, 23]. Foundation models are large-scale machine learning models pre-trained on massive amounts of diverse datasets (such as text, images, videos) using self-supervised learning techniques [6]. They can perform a wide range of tasks across various application domains, including multimodal tasks. LLMs are a subset of FMs focused on language-related tasks and analyze data to perform natural language processing (NLP) tasks [22, 24]. Both FMs and LLMs are pre-trained on large datasets [25] and adapted for specific tasks using techniques like fine-tuning, in-context learning, distillation, and Retrieval-Augmented Gener- ation (RAG) to improve response quality [24].\nFM-based systems incorporate FMs as core components within larger architectures designed to utilize their capabili- ties [3]. These systems integrate FMs with additional com- ponents such as data retrievers (e.g., RAG), external tools and others. The complexity of FM-based systems lies in ensuring seamless interoperability among these components while ensuring responsible AI and AI safety [1].\nIn 2021, Bommasani et al.[1] provided a comprehensive discussion on foundation models, illustrating the essential elements and relationships between them. The authors also discussed the practical applications of FM-based systems, highlighting their economic and operational advantages over traditional systems. Two years later, Zhou et al. covered recent research advancements, challenges, and opportunities for pre- trained foundation models in text, image, graph, and other data modalities in their survey paper [20]. Both works offer excellent insights into future research directions to address open problems and associated risks. Studies [1, 26] mention that foundation model-based systems often inherit responsible AI and AI safety issues and can cause negative consequences.\nLu et al. developed a taxonomy of FM-based systems focusing on their pretraining, adaptation, architectural design, and responsible-AI-by-design [27]. The taxonomy aids soft- ware architects and developers in evaluating and integrating foundation models into complex systems. The authors also highlighted considerations for cost, accuracy, and responsible AI related quality attributes for the systems. The authors later proposed a reference architecture for designing respon- sible and safe foundation model based systems in [3]. The works [28, 29] explore the risks associated with deploying LLMs and evaluate current approaches to mitigate such risks through model alignment. Recently, Lu et al. discussed that responsible AI practices are highly recommended for FM- based systems [2, 30]. This includes technical solutions and adherence to regulatory and ethical guidelines to maintain public trust and safety [31]. They also emphasized that FM- based systems must ensure they are developed and deployed in a responsible, safe, and legal way [32-34].\nRelated Work\nThere exist several frameworks and tools for designing guardrails at design time and runtime. Significant have been put into model alignment during design time, which fo- cuses on aligning the FM's outputs with human values and ethical standards. Pre-training and adaptation strategies play a significant role in mitigating risks in FM-based systems through guardrails. Pre-training models on diverse and eth- ically sourced datasets helps align them more closely with ethical standards. Continuous adaptation through fine-tuning further reduces AI risks [1]. Ensuring ethical and responsible AI practices involves not only technical solutions but also adherence to regulatory and ethical guidelines within the systems. The adoption of comprehensive AI frameworks that incorporate ethical principles into the design and deployment of FMs is crucial for maintaining public trust and safety [31].\nSome initial efforts have been made toward runtime guardrails. Zhou et al. [20] present an excellent discussion of the literature that addresses the monitoring and controlling behavior of FM-based systems. Various tools and frameworks have also been developed to tackle these challenges. NeMo Guardrails[16] provides programmable guardrails to ensure that models operate within safe parameters by monitoring inputs and outputs in real-time, dynamically adjusting behav- ior to prevent harmful outcomes[27]. OpenAI's Moderation API [35] monitors and filters harmful content generated by models to protect user interactions. The GuardAgent frame- work [36] utilizes an LLM agent to oversee and safeguard other agents. It demonstrates strong generalization and low op- erational overhead by dynamically generating guardrail code.\nWe also found that the continuous validation ensures that the outputs from FM-based systems adhere to predefined ethical standards and guidelines. Techniques such as auditing models [18] through multi-layered approaches [18, 37] system-"}, {"title": "III. METHODOLOGY", "content": "This study focuses on two primary concepts: (i) founda- tion model-based systems and (ii) runtime guardrails. We adopted the Petticrew and Roberts approach [39] to define the Population, Interventions, Comparison, Outcomes, and Context (PICOC), within which the intervention in this study is delivered. Using these PICOC components and following Kitchenham's guidelines [40], we develop the protocol for this study. The fol- lowing subsections detail the steps and processes undertaken in this study."}, {"title": "A. Research Scope and Protocol Development", "content": "The high-level research approach for this study is shown in Figure 1. Initially, we determined the research scope and devel- oped a protocol following Kitchenham's guidelines [40, 41]. The protocol guided the entire study\u00b9 by defining relevant scientific databases and resources, formulating keywords and search strings, outlining qualitative and quantitative checklists, and specifying criteria for the inclusion and exclusion of studies."}, {"title": "B. Research Questions", "content": "When formulating our Research Questions (RQ), we wanted to ensure that they were broad enough to capture the diverse aspects of runtime guardrails while being specific enough to provide actionable insights. We captured these diverse aspects through the following three Research Questions (RQs).\nRQ1: Why are runtime guardrails adopted?\nOur first research question investigates the fundamental motivations for designing runtime guardrails in FM-based systems. It explores the responsible AI and AI safety concerns that require the adoption of runtime guardrails to prevent harmful content and unintended behaviors.\nRQ2: What are the key quality attributes for designing runtime guardrails?\nOur second research question identifies quality attributes that should be considered when designing effective guardrails in FM-based systems.\nRQ3: What are the design options for runtime guardrails?\nThis question examines the design options for runtime guardrails in FM-based systems from different perspectives, such as action and scope."}, {"title": "C. Search string formulation", "content": "Relevant primary studies for this SLR were identified based on the RQs defined in Section III-B. With the assistance of the PICOC approach (shown in Table I), our search terms were divided into two primary concepts, as shown in Table II. These concepts helped us to set a well-formulated search string.\nWe also used synonyms, abbreviations, and alternative spellings of search terms to increase the number of relevant research papers. We used truncation and wildcard operators to save time and effort in finding these alternative keywords. Moreover, different supplementary key terms or phrases dis- covered during search iterations were added to our search string to enhance our search strategy. Our supposition is that they will collect all relevant articles that contains guardrails for FM-based system. When constructing the final search query, the identified keywords, their alternatives and related terms were linked with Boolean AND (&&), OR (||) and NOT (\u00ac) operators as follows as follows:\n\\[\\begin{aligned}\n[\\{(C_{11}||C_{12}||...||C_{1n})\\text{AND}(C_{21} ||C_{22}||...|| C_{2n})\\\\\n\\text{NOT}(UC_{1}||UC_{2}||...||UC_{n})\\}]\n\\end{aligned}\\]\nwhere $C_{11}...1n$, and $C_{21}...2n \\& Col$ and $Co2$ of Table II, respectively; and $UC\u2081 . . . UCn$ refers the Exclude Context defined earlier in PICOC table (Table I)."}, {"title": "D. Selection of papers: Inclusion and exclusion criterion", "content": "Table III and Table IV present the Inclusion Criteria (IC) and Exclusion Criteria (EC) that have been used to iden- tify the studies for this SLR, respectively. We found that a considerable amount of work on guardrails exists in gray literature; however, we excluded them as they often lack peer review and a rigorous validation process. While some sources [42] argue that gray literature is an important resource for systematic literature reviews (SLRs), such literature can be misleading and introduce biases and inconsistencies in the"}, {"title": "E. Study Search and Filtering Process", "content": "Our filtration process is further detailed in Figure 2. Initially we ran the formatted query on four major databases that returned 1,733 research papers. We then applied filtering and classified the studies found according to the guidelines presented in [40, 41]. In our initial filtration process, we removed 108 papers due to being duplicated articles, editorial or key notes. After reading the title, abstract, conclusion and skimming through the introduction, methodology and results, we applied our exclusion criterion defined in Table IV, and 1524 further papers were removed. During the third step of filtration, we applied inclusion criteria and removed 80 papers as these studies did not meet ICs shown in Table IV. In parallel, we did a manual search and found 189 papers that meet our key concepts defined in Table II but not contain any unwanted content (UC). After applying ICs and ECs, 15 out of 189 papers were selected. Finally, we did a cross-check and ended up with 32 papers."}, {"title": "F. Data Extraction and Quality Assessment", "content": "We used a semi-automated process [44] for data extraction from the selected studies to answer our RQs. Key qualita- tive information extracted from each selected study includes guardrails definitions, motivations, reported key quality at- tributes, and design options. We also extracted several relevant pieces of information to understand the context and consider- ations in designing and evaluating runtime guardrails.\nWe then evaluated each study based on the following five Quality Assessment Criteria (QAC) on a scale from 1 (Very Poor) to 5 (Excellent). If a study's average score was less than 2, it was excluded from further analysis. Otherwise, we used the qualitative information to decide this. The QAC for this study are as follows:\n\u2756 Relevance to guardrails for FM-based systems.\n\u2756 Clear methodology for guardrail design.\nAdequate data collection, analysis, and evaluation.\n\u2756 Discussion of challenges in designing guardrails.\n\u2756 Practical applicability of findings for guardrails."}, {"title": "IV. DESIGN TAXONOMY FOR GUARDRAILS IN FOUNDATION MODEL-BASED SYSTEMS", "content": "In this section, we present our taxonomy of runtime guardrails for FM-based systems. As illustrated in Figure 3, this taxonomy is organized into categories based on identified problems, quality attributes, and available design options, which we use in the following sub-sections to answer our key research questions\nMotivation for adopting runtime guardrails (RQ1)\nOur first research question investigates the fundamental reasons for integrating guardrails into FM-based systems. We found that guardrails are primarily implemented to mitigate bias, harmful content, and unintended behaviors. Additionally, guardrails better maintain ethical and safety standards in areas such as accuracy, privacy, security, safety, fairness, IP protection, and compliance, as discussed below."}, {"title": "Accuracy", "content": "Accuracy in FM-based systems is a critical concern, particularly regarding the generation of hallucina- tions, misinformation, and disinformation [45]. Hallucinations occur when models generate information that is factually incorrect or fabricated. Such inaccuracies can mislead users and damage the credibility of the systems [10]. Misinformation refers to the unintentional spread of false information, while disinformation involves the deliberate dissemination of false-hoods to deceive users [2]. These phenomena pose significant risks, as they can propagate false narratives and influence public opinion [20]. Guardrails mitigate these risks by detect- ing and filtering potentially inaccurate information [16]. For example, OpenAI uses guardrails to clearly label AI-generated content to prevent deepfakes and misinformation [46], such as in one case where it was reported to prevent misleading voters in the upcoming US elections [47, 48]. Therefore, guardrails improve the overall integrity of the systems [1, 46]."}, {"title": "Privacy", "content": "In FM-based systems, privacy is a critical concern due to the risks of handling large amounts of personal and sensitive data. Without proper guardrails, these systems can inadvertently expose or misuse this data [1, 12]. One key privacy risk is data leakage, where sensitive information is inadvertently revealed through model outputs. For instance, an FM-based LLM trained on private conversations might accidentally generate text that includes personal information such as names, addresses, or financial details [49]. This leakage can occur through direct responses or statistical in-ferences. For example, an FM-based customer service chatbot might inadvertently include sensitive information. In April- May 2023, a notable incident involved Samsung employees leaking proprietary information into ChatGPT, leading to Samsung banning ChatGPT [50]."}, {"title": "Security", "content": "Security in FM-based systems involves pro- tecting them from malicious activities that could compromise their integrity and functionality [6, 14, 19]. For example, an FM-based system could be targeted by hackers to manipu- late data, producing incorrect or harmful outputs that affect decision-making processes [51]. An incident similar to this re- ported in [52], where malicious users manipulated Microsoft's Tay chatbot to produce inappropriate and offensive content, resulting in its shutdown. Additionally, FM-based systems are vulnerable to various threats [53]. Hackers can exploit vulnerabilities to access sensitive data, leading to breaches of confidentiality. Even with authorized access, there is a risk of data misuse by third-party providers [54]. FM-based systems are also prone to adversarial attacks, where specially designed queries extract sensitive information.\nGuardrails mitigate these risks by detecting and responding to real-time threats, safeguarding system integrity and perfor- mance [1, 51]. They also prevent unauthorized access and the exploitation of vulnerabilities. For example, a financial FM- based system with guardrails can detect unusual transaction patterns and initiate defensive measures, such as temporarily suspending transactions [51]. Thus, guardrails better maintain confidentiality [49, 55, 56], system integrity [10, 19], and availability [11, 18, 26, 53, 57], prevent model misuse [26, 54]."}, {"title": "Safety", "content": "FM-based systems face significant safety is-sues, particularly in generating harmful or misleading outputs. These issues can arise when models produce content that is inappropriate, offensive, or incorrect [1, 3]. For example, in applications where FM-based systems handle critical data, such as in medical diagnosis or or self-driving cars, incorrect outputs can lead to dangerous consequences [32]. Additionally, there is a risk of generating ethically or morally questionable content, which can damage the credibility and acceptance of the system [53].\nGuardrails mitigate these risks by detecting and filtering out harmful output in real-time. For instance, in an FM-based virtual assistant used for mental health support, guardrails ensure the responses are benign and non-triggering. They also effectively detect and correct errors in real time, thus mitigating the effects of adversarial attacks [13, 15, 58\u201360]."}, {"title": "Fairness", "content": "FM-based systems can face bias and discrim- ination in model outputs. These biases can emerge from the training data, model algorithms, or deployment context [2, 61]. For instance, a language model used in recruitment for initial screening of CVs and responses to selection criteria might inadvertently favor candidates from certain demographics, cultures, and languages [8, 26], which ultimately undermines the credibility of the systems. Guardrails address these fairness issues and ensure equitable outcomes through model param- eter adjustments. For instance, in our recruitment example, they can analyze the model's decisions and correct poten- tial biases. Furthermore, guardrails promote transparency and accountability by providing insights into how decisions are made [1, 18], and avoid harmful stereotypes [53]."}, {"title": "IP Protection", "content": "In FM-based systems, another key prob- lem is the unauthorized use of generated content, where users might exploit outputs created by these systems without proper attribution or licensing, making them vulnerable to unautho- rized use, duplication, or distribution [10, 26, 55]. Guardrails help mitigate these problems and better protect content's copyright [49]. They also aid in compliance with copyright laws and licensing agreements to mitigate legal risks [12, 19]. Techniques such as watermarking, fingerprinting, and labeling ensure the copyright and ownership of data [1, 10].."}, {"title": "Compliance", "content": "Compliance in FM-based systems involves adhering to legal and regulatory standards [16, 20]. These issues are critical because non-compliance can lead to le- gal penalties, reputational damage, and loss of user trust. Guardrails reduce these risks by ensuring alignment with data protection regulations, industry standards, and guide-lines [16, 26, 54]. They also facilitate better auditing and monitoring of the systems [18]. For instance, an FM-based system in a financial organization might use guardrails to mon- itor transactions, flag deviations from protocols, and ensure corrective actions are taken promptly. Additionally, guardrails assist in automating compliance checks and improving mon- itoring accuracy. They ensure that all aspects of the FM- based system's operations align with the necessary legal and regulatory frameworks [36, 62], and better support internal audits and external regulatory reviews [12]."}, {"title": "B. Quality Attributes Considered in the Design of Guardrails (RQ2)", "content": "We identified eight key quality attributes essential for the design of runtime guardrails in FM-based systems. Below, we discuss these attributes in detail, highlighting their roles and importance.\nAccuracy: Guardrail accuracy refers to the precision in identifying and mitigating risks, i.e., preventing undesired behaviors or outputs [45]. Functional accuracy emphasizes how well guardrails perform their intended tasks to meet user expectations and requirements. For instance, a guardrail used for a customer service chatbot must accurately block sensitive information from being disclosed. If a customer asks, \u2018What is my current account balance?' the guardrail must prevent disclosing the balance, instead providing a safe response like, 'For security reasons, please check your balance through our secure app.' If it fails to do so (false negatives) or incorrectly flags benign information (false positives), it compromises functional accuracy. Predictive accuracy involves the chatbot's correct understanding and response to inquiries. We found that the accuracy of guardrails is evaluated using automated methods, primarily considering the systems' performance [16], output quality [55], overall trustworthiness [10, 49], and sys- tem adaptability [26, 49].\nGeneralizability: Generalizability in guardrails refers to their ability to function effectively across diverse applica- tions [63]. Such guardrails ensure that the protective measures are not overly specific to a single use case but can adapt to various contexts and still perform reliably. For example, a chatbot must comply with different financial regulations across countries to ensure compliance without reconfiguration. Dong et al.[15] and Wang et al.[64] emphasize the need for guardrails that can extend their applicability to new domains without significant reconfiguration or loss of performance, even during unexpected inputs or data types. Furthermore, gen- eralizability enhances the ability to handle diverse linguistic, cultural, and operational contexts to provide robust protection and to enhance the system's resilience and reliability [1, 12].\nCustomizability: Customizable guardrails provide tai- lored protection that meets specific requirements and supports diverse operational needs in FM-based systems [1, 65]. They allow for adjustments and configurations that align with par- ticular operational goals, data characteristics, and regulatory environments. For example, a customer service chatbot can enable priorities for different guardrails and adjust data han- dling based on the user's location, ensuring compliance with GDPR in Europe and CCPA in the U.S. [66]. Customizability also includes the capability to integrate user-defined rules and policies, ensuring that the guardrails can support diverse operational contexts and evolving needs [64].\nAdaptability: Adaptability in guardrails is known as their capability to adjust and remain effective under varying conditions and data landscapes as context evolves [24, 26]. This attribute ensures robust and continuous protection by dy- namically responding to changes in input data, usage patterns, and emerging threats without manual reconfiguration [15]. For example, a customer service chatbot can automatically update its guardrails to detect and block new offensive terms during interactions. This includes the ability to incorporate new knowledge and advancements in threat detection tech- niques [1, 54].\nTraceability: The traceability attribute of guardrails tracks and records the origins, processes, and decision paths, such as input and output of FMs, external tools, etc. [27]. It involves maintaining detailed logs and records that can be audited to understand how decisions are made. For example, in a customer service chatbot, traceability ensures that every recommendation can be traced back to the data sources and algorithms used. This includes logging which data inputs influenced the response and what external APIs or tools were accessed, providing a clear audit trail for transparency and accountability. Traceability also aids in identifying the root causes of issues. This enables timely and accurate trou- bleshooting and improvement [26], and helps in maintain- ing user trust and meeting regulatory requirements [10, 16]. Additionally, comprehensive documentation of data sources and model modifications better support effective auditing and compliance checking [12].\nPortability: Portability in guardrails for FM-based sys- tems refers to the ability of these protective measures to be easily adapted and applied across different foundation model (FM) systems and platforms [27]. This includes ensuring that the guardrails function consistently across various FM archi- tectures and environments, thereby maintaining their effective- ness and integrity regardless of the underlying system [26]. For example, the same guardrail can be applied for content moderation in both a customer service chatbot and a social media platform, regardless of their underlying technology. The benefits of designing portable guardrails include compatibility across multiple programming languages and frameworks fa- cilitate their integration into diverse technological stacks [49]. These capabilities ensure that the guardrails remain effective and operational as the system evolves or migrates to new environments. Portable guardrails also support seamless up- dates and improve scalability to maintain high standards of security and compliance while adapting to new technological advancements within systems [16].\nInteroperability: Interoperable guardrails work seam- lessly across different systems and technologies [27]. They ensure that security, privacy, and compliance protocols can be applied consistently, even in heterogeneous environments that utilize varied software and hardware components, or diverse technological ecosystems [16, 67]. Guardrails that interface with various APIs and data formats also enable smooth com- munication and operation across different systems [26]. For example, they enable a customer service chatbot and internal support system to share data securely and consistently. This promotes cohesive and unified security management, reducing the complexity of maintaining multiple disparate protective measures [1], and better support collaborative efforts and data sharing [49]."}, {"title": "Interpretability", "content": "Interpretability refers to the clarity and transparency with which guardrails and protective measures operate. This allows users and stakeholders to understand how decisions are made and actions are taken by models. Thus increasing trust and accountability [10, 68]. For example, a chatbot in healthcare, can explain why certain advice is given or restricted. Transparent guardrails better facilitate auditing and compliance [18]. They also help users to understand that actions taken by guardrails can be clearly understood and verified [55]. This is essential for identifying and correcting errors, as well as for ensuring that the system's operations align with standards."}, {"title": "C. Design of Guardrails (RQ3)", "content": "This section presents a structured taxonomy for designing guardrails, focusing on identifying various design alternatives.\nGuardrail Actions: Guardrail actions are crucial for addressing the specific needs of FM-based system components. We have identified the following guardrail actions as key elements for FM-based systems:\n\u2756 Block: The block action prevents specific inputs (such as user prompts) or outputs (such as content generated by FMs) from being processed or sent by various compo- nents (such as FMs and tools) in FM-based systems [54]. For example, the block action can reject the user prompts containing harmful instructions, thus preventing unde- sired outcomes.\nFilter: The filter action involves scanning and removing undesired or irrelevant content from the inputs or outputs of different components in FM-based systems [69, 70]. For instance, a filter may remove any personal data contained in the user prompts or the output generated by FMs.\n\u2756 Flag: The flag action is used to mark specific inputs, outputs, operations within FM-based systems [16]. For example, unusual transactions requested by the FM-based agent can be flagged for human review to ensure they comply with organizational policies [1, 30].\n\u2756 Modify: The modify action allows for the adjustment of inputs or outputs of various components in the FM-based systems to meet specific requirements or standards [9]. For example, the system can modify the user prompts by adding more context and examples, making it easier for the FM to accurately interpret the user's intentions and provide more relevant responses.\n\u2756 Validate: The validate action checks inputs, outputs, intermediate results against predefined criteria to ensure they meet specified requirements or standards [26, 70]. For example, the customer service chatbot could validate if the output generated by the FM-based system contains any sensitive company information.\n\u2756 Prioritize: The prioritize action enables the FM-based system to allocate resources and attention based on the importance of specific tasks, e.g., processing urgent user queries first [28].\n\u2756 Rate limit: The rate limit action controls the frequency and volume of requests or outputs processed by the system/component within a given time frame [16, 53]. For example, a rate limit can be set to restrict the number of API calls a single user can make.\n\u2756 Parallel calls: The parallel calls action can send multiple requests to the system/component to improve respon- siveness, e.g., a user can send a prompt to the system multiple times at the same time and select the better response [16, 53].\nRetry: The retry action involves attempting a request again after an initial failure or unsatisfactory result [13].\n\u2756 Fall back: When the system is unable to handle a request, the fall back action can redirect to the previous state or an alternative solution [13, 16, 71].\nHuman intervention: The human intervention action requires humans to review and approve specific outputs or decisions [16, 53, 55]. For example, responses involving sensitive medical advice might be flagged for human approval before being communicated to users.\n\u2756 Defer: The defer action postpones the processing of a request or task until specific conditions are met or additional information is available [72].\n\u2756 Isolate: The isolate action involves segregating a specific entity (e.g., user) or component to prevent interaction with the system [19, 57, 60]. For example, a system might isolate a compromised narrow AI model suspected of being poisoned with malicious data in a sandbox envi- ronment, preventing potential harm to the main system.\n\u2756 Simulate: The simulate action involves running tests in a controlled environment to predict and analyze potential outcomes [1]. For instance, a system might simulate different configurations to determine the most effective plan.\n\u2756 Redundancy: The redundancy action involves imple- menting backup processes or components to ensure con- tinuity and reliability in case of failures [16, 26]. For example, an agent can implement two similar workflows in parallel, so if one workflow encounters an issue, the other can continue operating without interruption.\nLog: The log action involves recording system activities, interactions, and events [11, 70]. For instance, logging all user interactions with an FM-based chatbot allows for the analysis of user interests.\nTargets for Guardrails: The key targets guardrails can be applied to include prompts, models, external data, non-AI components, and agent-specific targets. Overview of targets and corresponding guardrail actions.\n\u2756 Prompts: Prompts are the initial user inputs or queries. Guardrails on prompts help ensure that user prompts are relevant, appropriate, formatted correctly, and easier for FMs to understand [37, 56, 70]."}, {"title": "Aspects of agents:", "content": "Goals: Ensuring that agents' goals align with human values and do not deviate from the human's intended goals [16, 49].\nContext: Monitoring the context that agents collect to ensure it is relevant information and appropriate [36].\nMemory: Managing the agents' memory to retain rel- evant data and discard outdated or irrelevant informa- tion, while also preventing memory poisoning [36, 64].\nReasoning: Enhancing agents' reasoning capabili- ties to ensure accurate analysis and sound decision-making [30].\nPlans: Ensuring the generated plans align with human goals [30, 54].\nActions: Monitoring agents' actions to ensure they are safe and effective in achieving desired outcomes [36].\nTools: Overseeing the proper use of tools by agents, including implementing access controls, restricting tool capabilities, and detecting potential vulnerabilities [36, 49].\nOther Agents: Managing interactions between agents to ensure collaboration, prevent conflicts, and mitigate risks associated with malicious behaviors [30, 49].\nIntermediate Results: Intermediate results are the outputs generated at various stages during the workflow generation of agents, before reaching the final outputs. By monitoring intermediate results, guardrails can de- tect anomalies or inaccuracies before they propagate to the final results.\nFinal Results: Final results are the end outputs gen- erated by agents, which are delivered to users or downstream systems. Guardrails ensure that the final results meet user expectations and comply with ethical guidelines and legal regulations.\nGuardrails Scopes: The scope of guardrails in FM- based systems ranges from individual preferences to industry standards. At the user level, guardrails reflect individual pref- erences and requirements. This involves adjusting the system's behavior based on user-defined settings to align outputs with both user expectations and ethical considerations. Incorporat- ing user preferences into guardrails provides a personalized experience while maintaining safety and compliance [55, 69]. Such guardrails ensure that the system respects user autonomy and produces outputs that are relevant and acceptable.\nAt the organizational level, guardrails align with internal policies and procedures governing the operation and use of FM-based systems. This includes compliance with corporate governance, data protection policies, and ethical guidelines established by the organization [12]. Guardrails also ensure consistency and accountability across different departments and functions within the organization."}, {"title": "Industry-level regulations and standards", "content": "provide the broader regulatory framework within which FM-based systems must operate. Guardrails designed to comply with these regulations guarantee that the system adheres to industry best practices and legal requirements [16", "26": "."}]}