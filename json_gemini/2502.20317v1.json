{"title": "Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases", "authors": ["Yongjia Lei", "Haoyu Han", "Ryan A. Rossi", "Franck Dernoncourt", "Nedim Lipka", "Mahantesh M Halappanavar", "Jiliang Tang", "Yu Wang"], "abstract": "Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for answering queries by providing textual and structural knowledge. However, current retrieval methods often retrieve these two types of knowledge in isolation without considering their mutual reinforcement and some hybrid methods even bypass structural retrieval entirely after neighboring aggregation. To fill in this gap, we propose a Mixture of Structural-and-Textual Retrieval (MOR) to retrieve these two types of knowledge via a Planning-Reasoning-Organizing framework. In the Planning stage, MoR generates textual planning graphs delineating the logic for answering queries. Following planning graphs, in the Reasoning stage, MoR interweaves structural traversal and textual matching to obtain candidates from TG-KBs. In the Organizing stage, MoR further reranks fetched candidates based on their structural trajectory. Extensive experiments demonstrate the superiority of MoR in harmonizing structural and textual retrieval with insights, including uneven retrieving performance across different query logics and the benefits of integrating structural trajectories for candidate reranking. Our code is available at https://github.com/Yoega/MoR.", "sections": [{"title": "1 Introduction", "content": "Text-rich Graph Knowledge Bases (TG-KBs), due to their structured representation of textual documents, ubiquitously store textual and structural knowledge (Jin et al., 2024b). For example, scholars retrieve relevant research from paper management systems to advance scientific discoveries where nodes represent papers and edges denote references (Lu et al., 2024). With large language models (LLMs)-powered generators approaching human intelligence in language comprehension and generation, retrieving supporting knowledge from TG-KBs to contextualize and ground generation has become increasingly crucial for correctly answering queries (Gao et al., 2023b; Ni et al., 2025).\nSince supporting knowledge in TG-KBs typically exhibits in both the textual and structural formats (Jin et al., 2024b; Kolomiyets and Moens, 2011), retrieval methods should be tailored to both formats effectively as shown in Figure 1(a). Textual retrieval methods retrieve textual knowledge such as indexed documents based on its similarity to the given query and can be broadly categorized into lexical methods (e.g., BM25) and semantic methods (e.g., Contriever) (Karpukhin et al., 2020; Izacard et al., 2022). Structural retrieval methods retrieve structural knowledge such as neighboring entities (Edge et al., 2024; Jiang et al., 2023; Wang et al., 2024) by applying graph traversal and graph machine learning (Tian et al., 2024; Yasunaga et al., 2021). Despite the advancements in both textual and structural retrieval, they are often applied independently and fail to mutually reinforce each other. As shown by Figure 1(b), neither structural retrieval by following the logical structure of the query nor textual retrieval by conducting Top-K BM25 matching can achieve better performance on both Amazon and MAG datasets simultaneously.\nTo effectively retrieve both textual and structural knowledge from TG-KBs, recent works (Xia et al., 2024; Li et al., 2024) aggregate neighboring documents to fuse structural knowledge into textual narratives followed by textual retrieval, with Xia et al. (2024) filtering irrelevant neighbors by their relations and Li et al. (2024) weighted aggregating neighbors based on their fields. However, three challenges remain. First, rewording aggregated neighbors requires frequently invoking LLMs, resulting in prohibitive resources for long documents with exponentially growing neighbors. Second, structural signals humans use to form logical plans are completely discarded after neighbor aggregation. Third, rigid neighbor aggregation overlooks varying desires for structural and textual knowledge for different queries and TG-KBs. In Figure 1(c), even within MAG, queries answered by textual retrieval (i.e., $Q_{Text}$) are different from queries answered by structural retrieval (i.e., $Q_{Struct}$). To address the above three challenges, we infuse the mixture-of-expert philosophy into retrieval design and propose a Mixture of Structural-and-Textual Retrieval (MoR) in Figure 2. MoR begins with a planning module that generates planning graphs outlining query logics that preserve structural signals without rewording aggregated neighbors, overcoming the first and second challenges. Next, MoR interleaves structural traversal and textual matching in the reasoning module, enabling these two retrieval to reinforce each other. Finally, MoR devises a structure-aware reranker in the organization module that adaptively adjusts the importance of retrieved textual/structural knowledge, addressing the third challenge. Via Planning-Reasoning\u2013Organizing, MoR intelligently retrieves structural and textual knowledge based on query logical structure. Our key contributions are:\n\u2022 Planning via Textual Graph Generation: We define retrieval planning as generating textual graphs that outline the logical structure, i.e., the plan, for identifying entities relevant to the query.\n\u2022 Reasoning via Mixture of Structural-and-Textual Traversal: We devise a mixed traversal by interweaving textual matching and structural traversal to retrieve knowledge following query logical structure depicted by the generated plan.\n\u2022 Organizing via Structure-aware Rerank: With candidates obtained from mixed traversal, we propose a Structure-aware Rerank to select Top-K candidates based on their traversal trajectory."}, {"title": "2 Preliminary", "content": "Notations: A Text-rich Graph Knowledge Base (TG-KB) B generally consists of a set of connected nodes V in the graph with each node $v \\in V$ associated with its corresponding document $D \\in \\mathcal{D}$ and category $E_v \\in \\mathcal{E}$. When retrieving nodes with supporting documents from B for answering a given query $Q \\in \\mathcal{Q}$, we typically follow certain rationale encapsulating the underlying logic of that query (Xu et al., 2024; Xue et al., 2024), which can be characterized by a text-attributed planning graph G. In many existing works (Jin et al., 2024a; Wu et al.), this planning graph can be usually decomposed into multiple reasoning paths $G = \\{P_i\\}$. where the ith reasoning path $P_i = (P_{i1} \\rightarrow P_{i2} \\rightarrow, ..., \\rightarrow P_{iL_i})$ is a distinctive reasoning chain of length $L_i$ encoding a unique logic and the $j^{th}$ node $p_{ij}$ corresponds to an entity in B with its own category $E_{p_{ij}}$ and textual restriction $T_{p_{ij}}$ extracted from the query. For example, in Figure 1(a), the query Publications by Point... has a planning graph with two paths, i.e., $P_1 = (Institution \\rightarrow Author \\rightarrow Paper)$ and $P_2 = (Field-of-Study \\rightarrow Paper)$, where the category and textual restriction of the first node on $P_1$ are $E_{p_{11}} = Institution$ and $T_{p_{11}} =< Point Park Univerisity>$, respectively. Comprehensive notations are summarized in Table 4 in Appendix A.\nProblem Setup: With the above notations, the investigated problem here is to retrieve entities $C \\subset V$ supporting answering a given query Q.\nTextual Retrieval retrieves candidates based on the textual signals of both the query and documents. One common strategy is to retrieve candidates $C$ from the whole documents $\\mathcal{D}$ that have Top-K textual similarity to query Q measured by lexical or semantic similarity (Vijaymeena and Kavitha, 2016). The textual retrieval used in MoR retrieves documents for a given query by matching them with textual descriptions in the query, e.g., matching stellar populations in tidal tails shown in Figure 1.\nStructural Retrieval retrieves candidates by applying prescribed rules to structured databases such as knowledge graphs and SQL (Guo et al., 2023). Common strategies include graph-based traversal (e.g., BFS, DFS) and rule fetching (Jiang et al., 2023). Specifically, MoR conducts structural retrieval by traversing neighbors of certain categories from the generated planning graph. For example, in Figure 1(a), only \"Paper\" typed neighbors of the Author can be traversed by our structural retrieval."}, {"title": "3 Framework", "content": "In a nutshell, we formulate our MoR as the conditional distribution $P_{\\Theta}(\\mathcal{C}|Q, \\mathcal{B})$ of retrieved candidates $\\mathcal{C}$ given the user input query $Q$ over TG-KB $\\mathcal{B}$, which is further factorized into three distributions corresponding to our proposed three modules: planning via generating the text-attributed planning graph $\\mathcal{G}$, reasoning via conducting mixture of structural-and-textual traversal to obtain intermediate candidates $\\mathcal{C}$ following the generated planning graph $\\mathcal{G}$, and organizing via applying structure-aware reranking to the obtained candidates $\\mathcal{C}$, obtaining final candidates $\\mathcal{C}$:\n$P_{\\Theta}(\\mathcal{C}|Q, \\mathcal{B}) = \\sum_{\\mathcal{G} \\in \\mathcal{G}} \\sum_{\\mathcal{C} \\in \\mathcal{C}} P_{\\Theta_3}(\\mathcal{C}|\\mathcal{C}, \\mathcal{G}, Q, \\mathcal{B}) \\times P_{\\Theta_2}(\\mathcal{C}|\\mathcal{G}, Q, \\mathcal{B}) \\times P_{\\Theta_1}(\\mathcal{G}|Q, \\mathcal{B})$\nwhere $P_{\\Theta_1}(\\mathcal{G}|Q, \\mathcal{B})$ is the probability distribution of generating the text-attributed planning graph $\\mathcal{G}$ given the input query $Q$ and TG-KB $\\mathcal{B}$; $P_{\\Theta_2}(\\mathcal{C}|\\mathcal{G}, Q, \\mathcal{B})$ is the probability distribution of retrieving intermediate candidates $\\mathcal{C}$ given the planning graph $\\mathcal{G}$ and the query $Q$ via our mixed traversal; $P_{\\Theta_3}(\\mathcal{C}|\\mathcal{C}, \\mathcal{G}, Q, \\mathcal{B})$ is the probability distribution of reranking the intermediate candidates so that Top-K positions form the ground-truth entities $\\mathcal{C}$. $\\mathcal{G}/\\mathcal{C}$ denotes the space of all possible planning graphs and all possible configurations of size-K candidate node sets from all nodes V in TG-KB $\\mathcal{B}$. The overall objective is to maximize the likelihood of retrieving ground-truth candidates $\\mathcal{C}$ for each input query $Q \\in \\mathcal{Q}$:\n$\\Theta^* = \\arg \\max_{\\Theta} \\prod_{Q \\in \\mathcal{Q}} P_{\\Theta}(\\mathcal{C}|Q, \\mathcal{B})$ (1)\nFollowing the above paradigm, we next introduce the three components: Planning via textual graph generation in Section 3.1, Reasoning via mixed traversal in Section 3.2, and Organizing via structure-aware reranking in Section 3.3."}, {"title": "3.1 Planning via Textual Graph Generation", "content": "To effectively reason over the underlying logic of queries and answer them, we propose a planning module that constructs a planning graph to capture their underlying logical structures. Unlike conventional approaches relying on rigid heuristics, e.g., shortest-path retrieval in knowledge graphs (Luo et al.; Delile et al., 2024), or step-by-step prompting of LLMs, which incurs high computational costs (Sun et al., 2023; Wang et al., 2024), our method generates the entire planning graph in one shot, eliminating repeated LLM calls. More importantly, as planning graphs integrate entity restrictions encoding query-specific constraints and entity categories capturing broader logical structure, our MoR can generalize learned patterns and efficiently adapt to new queries with the same underlying logic. For example, any query with the form Papers associated with <institution> and are in the field of <field> shares the same patterns with the query in Figure 2. Below, we first formalize the planning graph and then optimize its generation."}, {"title": "3.1.1 Planning Graph Formulation", "content": "A planning graph G is a structured representation where nodes represent entities and edges denote their logical relations. Each entity is associated with both a category and query-specific restriction. For example, given the query Can you give me publications by Point Park University authors on stellar populations in tidal tails, the generated planning graph is: G = (Institution<Point Park University> \u2192 Author \u2192 Paper \u2190 Field-of-Study<Stellar Population>) with Institution, Author, Paper, Field-of-Study as categories and <Point Park University>, <Stellar Populations> as restrictions. Note that edges in our planning graph can also possess different categories. For example, in the biomedical TG-KBs, the relation between Disease and Drug entities could be Indication or Contra-indication (Wu et al.), adding a finer level of semantic distinction to the relation."}, {"title": "3.1.2 Planning Graph Optimization", "content": "To ensure that our generated planning graph captures the query logic, we train a textual graph generator to maximize the likelihood of generating ground-truth planning graphs given their queries. Formally, given the joint distribution of the training pairs between queries and planning graphs $P_{Train}$, we optimize the planning module $P_{\\Theta_1}$ by solving:\n$\\arg \\max_{\\Theta_1} E_{(Q,G)\\sim P_{Train}} log P_{\\Theta_1} (G|Q, \\mathcal{B})$ (2)\nTo avoid the combinatorial explosion of exponentially growing planning graph candidates (You et al.), we decompose each planning graph into multiple reasoning paths $\\mathcal{G} = \\{P_i\\}_{\\mathcal{G}}$. Each path $P_i = (P_{i1} \\rightarrow, ..., \\rightarrow P_{iL_i})$ represents a distinct reasoning chain, where node $p_{ij}$ denotes an entity in TG-KB sharing the same textual category $E_{p_{ij}}$ and satisfying the restriction $T_{p_{ij}}$ from the query. Given the sequential nature and textual formats of these decomposed reasoning paths, LLMs can be naturally employed here as the planning graph generator, which conducts next-token prediction by predicting $j^{th}$ token $t_j$ conditioned on preceding tokens $t_{<j}$, the query Q and the TG-KB B:\n$P_{\\Theta_1} (G|Q) = \\prod_1^n P_{\\Theta_1} (t_j|t_{<j}, Q, \\mathcal{B})$. (3)\nNote that our proposed planning graph generator is not limited to LLMs. Any graph generative model preserving both structural dependencies and textual associations can be employed (Zhu et al.)."}, {"title": "3.2 Reasoning via Mixed Traversal", "content": "Following the reasoning paths of the above planning graph $\\mathcal{G} = \\{P_i\\}_{\\mathcal{G}}$, the reasoning module conducts a mixed traversal by interweaving neighbor fetching and textual matching to form intermediate candidates $\\mathcal{C}$, which are introduced next."}, {"title": "3.2.1 Structural Traversal", "content": "Following the definition in Section 2 that structural retrieval follows prescribed rules for knowledge retrieval, here we set these prescribed rules to be iteratively performing layer-wise breadth-first-search that traverses neighboring entities with categories aligning with those in the reasoning paths. Concretely, reasoning at the $l^{th}$-step of the planning path $P_i$, we check for each node $v$ in candidates set of last layer $v \\in \\mathcal{C}^{l-1}$ and fetch its neighbors $N_v$ with the same category as the corresponding node $p_{il}$ (i.e., $E_u = E_{p_{il}}$) in the reasoning path, which can be mathematically formulated as:\n$\\mathcal{C}^{l,Struct} = \\bigcup_{v \\in \\mathcal{C}^{l-1}}\\{u | u \\in N_v, E_u = E_{p_{il}}\\}$ (4)\nwhere $\\mathcal{C}^{l,Struct}$ denotes the set of structurally retrieved entities at the $l^{th}$ reasoning step according to the path $P_i$ and $E_u = E_{p_{il}}$ ensures that the category of the traversed neighbor u matches the corresponding entity category routine by the planning graph, resonating the nature of rule-based structural retrieval. Note that the seeding candidates $\\mathcal{C}_i^{1, Struct}$ at the very first layer are initialized by retrieving Top-K entities through textual matching, i.e., $\\mathcal{C}_i^{1, Struct} = \\mathcal{C}_i^{1, Text}$, which is introduced next."}, {"title": "3.2.2 Textual Matching", "content": "In addition to retrieving structural knowledge, our MoR also retrieves textual knowledge via Textual Matching, which retrieves candidates based on their textual similarity to queries. For each reasoning node $p_{il}$ at $l^{th}$ reasoning step along the reasoning path $P_i$, we concatenate the query and the textual restriction of $p_{il}$, i.e., $Q' = [Q : T_{p_{il}}]$, then compute its textual similarity to documents of nodes in TG-KB, i.e., $\\varphi(Q', D_v), \\forall v \\in V$, and finally retrieve the Top-K scored candidates:\n$\\mathcal{C}_i^{l, Text} = TopK(\\{v | v \\in V, E_v = E_{p_{il}}\\}, \\varphi(Q', D_v))$ (5)\nIntegrating candidates from structural traversal and textual matching together, the final candidates at $l^{th}$-step of $P_i$ are formed as:\n$\\mathcal{C}_i^l = \\mathcal{C}_i^{l,Struct} \\cup \\mathcal{C}_i^{l,Text}, \\forall \\mathcal{C}_i^{l,Struct}, \\mathcal{C}_i^{l,Text}, \\forall l \\in \\{1, 2, ..., L_i\\}$ (6)\nThe integrated candidates $\\mathcal{C}_i^l$ serve as seeding nodes initializing the next round of planning graph-guided structural traversal and textual matching, which creates a mutual reinforcement between structural and textual knowledge since previously retrieved two knowledge can both inform next round of structural/textual knowledge retrieval.\nWe iteratively conduct mixed traversal for every reasoning path $P_i \\in \\mathcal{G}$ and integrate retrieved entities together by taking their intersection, i.e., $\\mathcal{C} = \\bigcap_{P_i \\in \\mathcal{G}} \\mathcal{C}_i^{L_i}$, adhering to the fact that candidates should simultaneously satisfy the logic routine by all reasoning paths. Note that no training is involved in the mixed graph traversal, i.e., $P_{\\Theta_2}(\\mathcal{C}|\\mathcal{G},Q,\\mathcal{B}) = P(\\mathcal{C}|\\mathcal{G},Q, \\mathcal{B})$. Future works could explore optimizing graph traversal by rewards from agent-environment interactions (Nguyen et al., 2024)."}, {"title": "3.3 Organizing via Structure-aware Rerank", "content": "Although the retrieved candidates from Section 3.2 strictly adhere to the prescribed rule given by the planning graph, the sheer volume of candidates misaligns with realistic constraints (e.g., Top-20 retrieval budget (Zeng et al., 2024)) and may even cause difficulty to downstream executors such as long-context challenges for LLMs. To better emulate human reasoning, where multiple clues are gathered, analyzed in relation to the query, and synthesized into a coherent answer, we propose a structure-aware reranker to organize and rerank the candidates $\\mathcal{C}$, and select Top-K ones as the final retrieved answers $\\mathcal{C}$. Instead of relying only on textual features (Hu et al., 2019), our reranker assigns a ranking score based on features of structural trajectories obtained from the mixed traversal in Section 3.2, innovatively leveraging both structural and textual knowledge in reranking.\nPreviously, $\\mathcal{C}$ is defined as intermediate retrieved entities. To consider structural features in reranking, we pair each retrieved candidate in $\\mathcal{C}$ with its corresponding traversal trajectory obtained from the reasoning module. Specifically, each trajectory $P_i$ of length $L_i$ is featuring three types of attributes:\n\u2022 Textual Fingerprint (TF): Concatenation of similarity scores between the expanded query and each node on the path: $||_{l=1}^{L_i} \\varphi(Q', D_{p_{il}})$.\n\u2022 Structural Fingerprint (SF): Concatenation of node categories at each step on the path: $||_{l=1}^{L_i} E_{p_{il}}$\n\u2022 Traversal Identifier (TI): Concatenation of the indicator specifying whether each step uses a structural or textual retrieval: $||_{l=1}^{L_i} I_{p_{il}}$\nWe then train a reranker on these trajectories using the cross-entropy loss. For a training query Q and its associated candidate trajectory $P_i$, the loss is computed as follows:\n$L_{\\Theta_3} = -\\sum_i \\sum_j y log(\\sigma(f(\\frac{||_{l=1}^{L_i} \\varphi(Q', D_{p_{il}})}{Textual Fingerprint}, \\frac{||_{l=1}^{L_i} E_{p_{il}}}{Structural Fingerprint}, \\frac{||_{l=1}^{L_i} I_{p_{il}}}{Traversal Identifier} ) ))$. (7)\nwhere $f()$ is the reranker producing a score for each (Q, $P_i$) pair, $\\sigma(\\cdot)$ denotes the softmax function, and $y \\in \\{0,1\\}$ indicates whether the i-th candidate is a correct (positive) or incorrect (negative) match for Q. This formulation encourages the reranker to assign higher scores to positive trajectories, thereby improving ranking performance."}, {"title": "4 Experiment", "content": "We briefly introduce experimental settings to verify our proposed MoR, including Datasets & Baselines, Implementation Details, and Evaluation Metrics. More details are in Appendix B."}, {"title": "4.1 Experimental Setup", "content": "Datasets & Baselines: We use three TG-KBs from STaRK (Wu et al.) covering three knowledge domains, including E-commerce Products (Amazon), Academic Papers (MAG), and Biomedicine (Prime). We compare our MoR with baselines established by Wu et al. and categorize them into textual/structural/hybrid-based ones. More recent state-of-the-art hybird retrieval approaches fro TG-KBs such as KAR (Xia et al., 2024) and MFAR* (Li et al., 2024) are also compared.\nImplementation Details: To enhance the planning capability of our planning module, we finetune the Llama 3.2 (3B) on 1000 sampled queries with their corresponding ground-truth planning graphs, serving as the textual graph generator. In the absence of ground-truths, we synthesize them using LLMs. For the Prime dataset, we empirically find that directly prompting LLMs can hardly generate accurate planning graphs due to the lack of biomedical domain knowledge (Shen et al.). Therefore, we adopt an alternative approach. First, we instruct LLMs to extract triplets from each query and then construct the planning graphs by merging triplets with shared entities. During mixed traversal, textual matching can be implemented using any lexical or semantic methods. For this study, we employ BM25 for Amazon and MAG and finetune a contriever to complement the biomedical knowledge for Prime. To initialize the structural traversal, we employ textual matching to locate the top 5 nodes that are most relevant to the query as seeds. Additionally, at each layer, we incorporate the top 10 nodes retrieved via textual matching and append them to the current candidate set for the next round of traversal. Notably, due to the uncertainty of LLMs, the generated planning graphs can be invalid. In this case, we will directly conduct textual matching to retrieve candidates. For our ablations without reranker, we employ Ada-002 (Wu et al.) with cosine similarity as the scorer to rank candidates for evaluating performance.\nEvaluation Metrics: We follow Wu et al. for evaluation by reporting Hit@1 (H@1), Hit@5 (H@5), Recall@20 (R@20), and mean reciprocal rank MRR to evaluate in the full spectrum."}, {"title": "4.2 Overall Retrieval Performance", "content": "We compare MoR with other baselines on three TG-KBs in Table 1. Generally, hybrid methods, AvaTAR, KAR, MFAR*, and our MoR, achieve better performance than purely textual or structural methods owing to their ability to integrate both structural and textual knowledge. Among all baselines, our proposed MoR achieves the overall best performance with a substantial margin on average, with the first ranking on MAG and the second ranking on Amazon/Prime datasets. This demonstrates the effectiveness of our proposed mixture of structural and textual knowledge retrieval. Textual retrieval performs better on Amazon than on MAG, suggesting that Amazon queries rely more on textual knowledge. In contrast, its weaker performance on MAG is due to MAG's lower textual richness and stronger structural signals. This disparity aligns with the distribution analysis presented by Wu et al. and supports our hypothesis that queries in different TG-KB datasets require varying desires for textual and structural knowledge. Meanwhile, structural retrieval methods such as conventional knowledge graph-based ones perform poorly because they are designed for graphs with minimal textual information compared to TG-KBs. Different from Amazon and MAG, all existing methods without supervised tuning (e.g., Ada-002) exhibit significantly lower performance on Prime. This is due to the extreme domain expertise required in biology, where word-count-based, pre-trained textual similarity-based, and even more powerful LLMs are all poorly applicable here. Through fine-tuning, MFAR* and our proposed MoR generally achieve better performance, demonstrating the necessity of domain-specific knowledge for answering queries in knowledge-intensive domains."}, {"title": "4.3 Ablation Study", "content": "After verifying the superiority of MoR, we conduct ablation studies to assess its different components, including module and feature ablation."}, {"title": "4.3.1 Module Ablation", "content": "To assess the contribution of each module in MoR, namely, Text Matching-based Retrieval, Neighborhood-Fetching-based Structural Retrieval, and Reranker, we conduct a series of ablation experiments. First, we remove the Reranker, resulting in the variant MoR$_{\\text{w/o R}}$. On top of that, we further separately eliminate Text Retrieval and Structural Retrieval, yielding MoR$_{\\text{w/o RT}}$ and MoR$_{\\text{w/o RS}}$, respectively. As shown in Table 1, the complete MoR framework consistently achieves the highest performance across all datasets, demonstrating the synergistic effect of the Textual Retriever, Structural Retriever, and Reranker. After removing Reranker, MoR$_{\\text{w/o R}}$ exhibits a consistent performance drop across all datasets and evaluation metrics. This underscores the importance of the Reranker in refining retrieval by filtering noisy candidates from the intermediate reasoning stage. Eliminating Text Retrieval, i.e., MoR$_{\\text{w/o RT}}$, leads to a notable performance drop on Amazon but an unexpected improvement on MAG. This suggests that while textual knowledge benefits Amazon, it introduces misleading hard negatives that compromise the ranking method (e.g., Ada-002) for MAG. Conversely, removing Structural Retrieval, MoR$_{\\text{w/o RS}}$, results in a slight performance decrease further on MAG, reinforcing the importance of structural knowledge in MAG-related queries. These results underscore the Reranker's crucial role in adaptively harmonizing, balancing, and selecting knowledge from both structural and textual retrieval experts."}, {"title": "4.3.2 Feature Ablation", "content": "The above ablation study highlights the crucial role of Structure-aware Reranker in adaptively integrating structural and textual knowledge. To further analyze the contributions of its three key features, Textual Fingerprint (TF), Structural Fingerprint (SF), and Traversal Identifier (TI) defined in Section 3.3, we conduct a feature ablation analysis and report retrieval performance across different feature configurations in Table 2. Overall, using three features together yields the best performance on both MAG and Amazon, highlighting their synergistic effect. Individually, TF contributes the most and outperforms SF and TI on both datasets. The reason is that based on the definition in Section 3.3, TF directly captures the relevance between the query and the retrieved nodes along the trajectory, whereas SF and TI primarily characterize the structural patterns and retrieval types, serving more as complementary factors. Therefore, equipping TF with these complementary factors (i.e., SF or TI) yields around 10% additional gains on MAG. This is because SF and TI help the reranker selectively emphasize the relevance scores given by TF for certain nodes along the path. However, this boost is not observed on Amazon. We hypothesize that the textual knowledge needed there is predominantly derived from the final node on each path, making the structural cues provided by SF and TI less beneficial and even prone to overfitting. A deeper analysis to further justify this hypothesis is in Section 4.4. Overall, these findings underscore the varying importance of structural features in ranking across datasets."}, {"title": "4.4 Further Analysis", "content": "This section understands MoR's behavior by examining three questions, each of which enriches our insight into MoR's functionality and offers novel perspectives inspiring future query retrieval research.\nDo structure signals affect reranking? To assess the impact of trajectory information on the Reranker's decision-making, we introduce a node-based Reranker that constructs trajectory features using only TF/SF/TI of the last node. In Table 3, the path-based Reranker outperforms the node-based variant, especially on MAG. This highlights the critical role of trajectory features/structural knowledge in reranking. The minor performance boost on Amazon after switching to the full path trajectory indicates its textual knowledge preference over the last node rather than the whole trajectory.\nHow does MoR perform on different logical structures? Figure 3 shows the average performance of MoR on each query group categorized by their logical structures, where \"Others\" refer to queries with undefined logical structures in Wu et al. MoR consistently outperforms structural and textual retrievers across different logical structures. Among all queries, MoR performs the worst on \"P \u2192 P\" queries due to the ambiguity, although well-known, uniquely caused by repeated product entities from multi-step traversal. The average-performing \u201cOthers\u201d group underscores the utility of diverse planning strategies for the same query. Lastly, the skewed query distribution and retrieval performance across planning patterns reflect the varying nature of real-world planning needs. We hope these insights inspire research on data-centric reasoning designs and error control of planning."}, {"title": "5 Related Work", "content": "Retrieval-augmented Generation (RAG): RAG enhances generative tasks by retrieving relevant information from external knowledge sources (He et al., 2025; Gao et al., 2023c) and has been widely used to improve question-answering (Liu et al., 2023). With LLMs, RAG has been used for mitigating hallucinations (Yao et al., 2023), enhancing interpretability (Gao et al., 2023a), and enabling dynamic knowledge updates (Wang et al., 2024). This work essentially leverages the idea of RAG to retrieve supporting entities from TG-KBs to contextualize answer generation. Depending on concrete types of knowledge being retrieved, existing retrievers can be categorized into structural and textual retrieval, which are reviewed next.\nTextual and Structural Retrieval: Early textual retrieval models, such as TF-IDF and BM25 (Robertson et al., 2009), rely on lexical similarity and keyword matching (Chen et al., 2017; Yang et al., 2019; Mao et al., 2021). Modern approaches address this limitation by learning dense representations (Karpukhin et al., 2020). Beyond textual retrieval, structural retrieval leverages graph-based techniques to extract structured knowledge. Methods such as graph traversal (Wang et al., 2024; Jiang et al., 2023), community detection (Edge et al., 2024), and graph machine learning models, including graph neural networks (Yasunaga et al., 2021; Mavromatis and Karypis, 2024), play a crucial role in structural retrieval. Our approach integrates the strengths of both textual and structural retrieval by infusing the mixture-of-expert philosophy into retrieval design."}, {"title": "6 Conclusion", "content": "In this work, we propose a mixture of structural and textual retrieval (MoR) to adaptively retrieve structural and textual knowledge based on query desire, which first utilizes a textual graph generator to generate the planning graph, then performs a mixed traversal and conducts organizing via a structure-aware reranker to obtain final candidates. Experiments demonstrate the advantages of our MoR in harmonizing the retrieval of both textual and structural knowledge with insightful discoveries, including balancing retrieval performance across queries with different patterns and query-adaptive knowledge desire for structural/textual knowledge."}, {"title": "7 Limitations", "content": "In this paper, we integrate a mixture of expert philosophy into retrieval design and propose a Mixture of structural-and-textual Retrieval (MOR) to adaptively retrieve textual and structural knowledge. The limitations of MoR can be categorized into two main aspects in the following:\nLack of Domain-Specific Knowledge: Our proposed MoR, similar to other baselines, does not exhibit significantly higher performance on PRIME than AMAZON and MAG. The reason is the lack of biomedical knowledge required to comprehend biomedical questions, extract key information, navigate relevant entities and relations, and rerank retrieved candidates. This suggests that current state-of-the-art retrieval models, even paired with LLMs' intelligence, still struggle to handle domain-specific knowledge effectively. Such limitations may extend to other specialized domains, such as finance and law. Future research could integrate domain-specific knowledge into retrieval.\nReranking at Every Traversal Layer: Our current MoR adaptively routes retrieved candidates into the Top-K positions at the final layer via reranking, effectively implementing a conventional Mixture of Experts (MoE) routing mechanism. Despite the state-of-the-art performance we have achieved in Table 1, this routing mechanism could also be applied to intermediate layers, where after each retrieval step, candidates are reranked, and only Top-K proceeds to the next round of traversal and retrieval. This enables every layer of mixed traversal to emulate the router design of the MoE.\nMulti-Trajectory Reranking: While our current Structural Reranker is designed to compute ranking scores by leveraging the full spectrum of trajectory information from multiple traversed paths ending at each candidate (as illustrated in Figure 2), our implementation currently utilizes only the most informative trajectory (i.e., the one with the longest traversed path) due to implementation complexity. Future work should explore adaptive methods to fully integrate the complete set of traversed paths into the candidate ranking process and compare the effectiveness of leveraging traversed paths at different levels."}, {"title": "B Experimental Details", "content": "To evaluate the effectiveness of our proposed framework", "answer.\nAmazon": "a dataset provides a realistic simulation of product search and recommendation. Its textual graph consists of four categories of nodes: product", "reviews.\nMAG": "a comprehensive resource for academic paper retrieval. In the textual graph, papers can be connected to other nodes, such as"}]}