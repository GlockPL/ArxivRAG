{"title": "CALICO: Conversational Agent Localization via Synthetic Data Generation", "authors": ["Andy Rosenbaum", "Lu Zeng", "Gokmen Oz", "Pegah Kharazmi", "Chris DiPersio", "Clement Chung", "Fabian Triefenbach", "Ershad Banijamali", "Pan Wei", "Karolina Owczarzak", "Wael Hamza"], "abstract": "We present CALICO, a method to fine-tune Large Language Models (LLMs) to localize conversational agent training data from one language to another. For slots (named entities), CALICO supports three operations: verbatim copy, literal translation, and localization, i.e. generating slot values more appropriate in the target language, such as city and airport names located in countries where the language is spoken. Furthermore, we design an iterative filtering mechanism to discard noisy generated samples, which we show boosts the performance of the downstream conversational agent. To prove the effectiveness of CALICO, we build and release a new human-localized (HL) version of the MultiATIS++ travel information test set in 8 languages. Compared to the original human-translated (HT) version of the test set, we show that our new HL version is more challenging. We also show that CALICO out-performs state-of-the-art LINGUIST (which relies on literal slot translation out of context) both on the HT case, where CALICO generates more accurate slot translations, and on the HL case, where CALICO generates localized slots which are closer to the HL test set.", "sections": [{"title": "Introduction and Related Work", "content": "Conversational agents usually apply Intent Classification (IC) and Slot Tagging (ST) (also known as Named Entity Recognition or NER) to infer semantics from the text of an agent-directed request (Tur and De Mori, 2011). In order to support global user bases, these agents are often multilingual.\nIC+ST training data is typically scarce, especially in multilingual settings. While Large Langauge Models (LLMs) can perform IC+ST from few examples (e.g. Parikh et al. (2023)), lightweight\nmodels such as encoder-only Transformers (Chen et al., 2019; Xu et al., 2020) are still useful for cost- and latency-sensitive applications that support very high throughput.\nSynthetic Data Generation (SDG) from Large Language Models (LLMs) has become a popular trend to address the data scarcity problem (Rosenbaum et al., 2023). SDG approaches relevant to the IC and ST tasks include back-translation, (Bannard and Callison-Burch, 2005; Sennrich et al., 2016; Edunov et al., 2018; Xie et al., 2020) paraphrasing (Kumar et al., 2020; Cho et al., 2019; Malandrakis et al., 2019; Jolly et al., 2020; Panda et al., 2021) word replacement (Zhang et al., 2020; Dai and Adel, 2020; Wei and Zou, 2019), and carrier phrase regeneration (Kumar et al., 2022). A related thread is in-context generation of multilingual semantic parsing data (Rosenbaum et al., 2022a) and multi-party dialogs (Chen et al., 2023).\nIn terms of cross-lingual SDG for IC+ST, Machine Translation with Slot Alignment (MT-SA) is a strong baseline (Xu et al., 2020), however the separate alignment step a posteriori introduces noise, which negatively impacts the quality of the generated data and the downstream task model.\nRecently proposed LINGUIST (Rosenbaum et al., 2022b) avoids the alignment problem by first machine-translating the slot values (out-of-context entities like \u201cnew orleans\u201d or \u201cdecember six-teenth\"), and then generating a slot-annotated utterance in the target language incorporating the machine-translated slot values. (An example of LINGUIST output is \"book a flight to [1 new orleans] on [2 december sixteenth ]\", where 1 and 2 indicate slot labels to_city and date respectively. )\nIn this work, we propose CALICO for cross-lingual SDG of IC+ST training data, which resolves two important limitations of LINGUIST (see Figure 1):\n(i) Contextualized Slot Value Translation: LINGUIST translates the slots a priori and out of context, which can lead to cascading errors, due to the translation model choosing the wrong grammatical form in morphologically inflected languages, or choosing the wrong semantic translation altogether.\""}, {"title": "Methodology", "content": "Like LINGUIST, CALICO is a generative Large Language Model (LLM) fine-tuned on an instruction prompt to generate synthetic training data for IC+ST. CALICO takes inspiration from the LINGUIST prompt, and supports additional slot operations."}, {"title": "CALICO Prompt Design", "content": "The CALICO prompt (Figure 1) differs from LINGUIST by adding controls at the slot level for three operations: unchanged, indicating a verbatim copy (e.g. for flight numbers), literal translation, and localization, i.e. replacement with a value more appropriate in the target language.\nThe translation operation of CALICO improves the slot translation quality compared to out-of-context MT applied a priori to LINGUIST. For example, without any context, the word \u201csecond\u201d in English could be reasonably translated to Spanish as either \u201csegundo\u201d, \u201csegunda\u201d, \u201csegundos\", or \"segundas\", depending on the plurality and grammatical gender of the Spanish noun it modifies. Furthermore, if \"second\u201d is part of the phrase \"the second of september\u201d, then it should be translated as \"dos\u201d, meaning \"two\". CALICO attends to the entire input English sentence when generating translated values, and therefore can disambiguate such cases.\""}, {"title": "Training the CALICO Model", "content": "Similar to LINGUIST, we fine-tune CALICO from AlexaTM 5B seq2seq on cross-lingual prompts extracted from MASSIVE (FitzGerald et al., 2022b). See details in Section 3.2.1. Models are finetuned for 10 epochs using a batch size of 16."}, {"title": "Inference", "content": "For the target dataset, we take the English training data and instruct CALICO to generate corresponding data in the target language. We sample 8 outputs with top_p 0.95 and temperature 1.0 and then filter down to select only one as described next."}, {"title": "Iterative Filtering Mechanism (IFM)", "content": "We extend the post-processing pipeline of LINGUIST to include an Iterative Filtering Mechanism (IFM) to select higher quality samples from among the n-best CALICO-generated outputs.\nSimilar to LINGUIST, we first discard any outputs that do not pass heuristic string-based validation such as missing or extra brackets. We then apply English-IC filtering and backoff to the original English example in case no output is valid, in order to maintain the original per-intent distribution.\nIn the first round, we randomly select one of the remaining CALICO outputs and fine-tune the IC+ST task model on real English data plus the selected CALICO outputs in the other languages.\nThen, we re-select from among the CALICO n-best outputs: we discard samples where the IC+ST model hypothesis disagrees with the intent and slot labels prompted for, then randomly select a single output again, using a different random seed to ensure that we don't always re-select the same output.\nWe apply this IFM repeatedly until performance plateaus (two iterations in all of our experiments)."}, {"title": "Experiments", "content": null}, {"title": "Models", "content": "We fine-tune AlexaTM 5B seq2seq model (Rosenbaum et al., 2022b; Soltan et al., 2022; FitzGerald et al., 2022a) as the CALICO data generaiton model. For the downstream task IC+ST model and iterative filtering model, we fine-tune xlm-roberta-base (Conneau et al., 2020) (12 layers, 768 hidden dimension), from the HuggingFace (Wolf et al., 2020) implementation."}, {"title": "Datasets", "content": "We fine-tune CALICO on cross-lingual prompts extracted from MASSIVE, which contains parallel IC+ST annotated data in 51 languages. We fine-tune on 6 languages: German, Spanish, French, Hindi, Japanese, and Portuguese, each parallel to English.\nAfter the CALICO data generation model is trained, we apply it on two IC+ST datasets, MultiATIS++ and MultiSNIPS, to localize training data from English into the target languages. The CALICO model has never seen the specific intent and slot names, annotation scheme, or data conventions of the target downstream tasks, and therefore must generalize at inference."}, {"title": "MASSIVE", "content": "MASSIVE (FitzGerald et al., 2022b), Multilingual Amazon SLURP (SLU resource package) for Slot Filling, Intent Classification, and Virtual-Assistant Evaluation, contains 19,521 English realistic, labeled virtual-assistant utterances spanning 18 domains, 60 intents, and 55 slots. It is a parallel dataset, where each English utterance is localized or translated into 50 typologically diverse lan-guages. The dataset includes annotations on the human-chosen replacement method for each slot (i.e. translation or localization or unchanged) for each pair of English and parallel target language utterance. Crucially, we use these slot-level annotations in the prompts for CALICO fine-tuning so that the model learns to follow instructions like localization (Figure 1)."}, {"title": "MultiATIS++", "content": "MultiATIS++ dataset extends the English-only Air Travel Information Services dataset ATIS to 9 languages via human translation. Our work focuses on the 7 languages MultiATIS++ shares with our pre-trained model: English (EN), German (DE), Spanish (ES), French (FR), Hindi (HI), Japanese (JA), Portuguese (PT), with 4488 (HI: 1440) training utterances, 490 (HI: 160) validation utterances, and 893 test utterances, over 18 (HI: 17) intents and 84 (HI: 75) slots. (The test set release also contains Turkish and Chinese.)\nSince the original test set is human-translated from English, it contains only translated slot values (e.g. for \"new orleans\" in English, the Spanish version would be \"nueva orleans\"), but not localized entities. To showcase the effectiveness of CALICO, we create a new version of the MultiATIS++ test set in all 8 non-English languages, by asking human experts to localize the slot values for 8 slot types. Specifically, the human experts replace the original human-translated English slot value (e.g. \"nueva orleans\u201d in Spanish) with a value more appropriate value in the target language (e.g. \"madrid\"). The localized slot types are airline_code, airline_name, airport_code, airport_name, city_name, country_name, state_code, state_name.\nWe also ask the experts to modify the carrier phrase text as needed to make the entire request grammatically correct. For example, in French the experts might change the form of the definite article \"le\", \"la\u201d, \u201cles\u201d, or \u201cl\u201d (all meaning \u201cthe\u201d) to match the plurality, gender, and pronunciation of the newly chosen slot value. The rest of the slot types and text remain as they are in the original."}, {"title": "MultiSNIPS", "content": "The MultiSNIPS dataset (Stickland et al., 2023) contains human translations of the SNIPS (Coucke et al., 2019) dataset into three languages: Spanish (ES), French (FR), and Hindi (HI)."}, {"title": "Results", "content": "MultiATIS++ Results are shown in Tables 1 and 2, where the upper block reports IC Accuracy, and the lower block reports ST F1 Score. Table 1 is reported on the original test set, which contains human-translated slot values, whereas Table 2 is on our new version of the test set, where the slots are human-localized to versions more common in the target language.\n\"Lower bound\" indicates the IC+ST model trained only on the English training data. \u201cUpper bound\" indicates the IC+ST model trained on MultiATIS++ training data for all 7 languages. The remaining columns indicate IC+ST models trained on the concatenation of original English training data with synthetic training data for the other 6 languages from one or more methods. \u201cLINGUIST (our repro)\" is our reproduction of LINGUIST.\n\u201cCALICO (IFM)\u201d is our candidate approach, where we apply the localization, translation, and copy operations to specific slot values as shown in Table 6 (Appendix C), along with post-generation iterative filtering mechanism. \u201cCALICO (All Transl.)\" is our candidate model with the translation operation applied to all slots at inference time. In \u201cCALICO (No IFM)\u201d, we do an ablation setup on the iterative filtering mechanism, where we do not perform iterative filtering. And finally in the column \"IFM Comb all\u201d, we include the synthetic data from \u201cCALICO (IFM)\" combined with \u201cLINGUIST (our repro)\u201d and \u201cCALICO (All Translate)\".\nWe primarily focus on \"AVG non EN\u201d, which is the average across the non-English languages. On the original test set (Table 1), we find that \u201cCALICO (IFM)\" is the best performing single method on average, surpassing LINGUIST by 2.95 points absolute on IC (from 94.01 to 96.96) and 2.04 points absolute on ST F1 (from 83.54 to 85.58).\nThe improvement of CALICO over LINGUIST is reflected on most languages, however Japanese (JA) shows the most improvement, having +7.55 / +5.56 (from 89.30 to 96.85 / from 85.15 to 90.71) points improvement on IC / ST. This suggests that Japanese was being limited the most by the drawbacks of LINGUIST, e.g. making translation mistakes out of context.\nOn the new localized test data (Table 2), both versions of CALICO improve over LINGUIST, and IFM improves even further. With CALICO plus IFM, we improve on IC from 93.94 LINGUIST to 96.15 (for 2.21 points absolute) and ST from 80.49 LINGUIST to 84.81 (i.e. 4.32 points absolute). As with the HT test set, the improvement is particularly large for Japanese (JA).\nOn both settings, we combine data from LINGUIST and both versions of CALICO, however find that the gains are not consistently synergistic.\nWe see the performance improvement of CALICO over LINGUIST is directly correlated with the \"Success Rate\" (Table 4 in Appendix B, filtering to keep only those outputs which pass string-matching heuristics and IC hypothesis filtering), indicating that the data produced from CALICO is cleaner and more usable than that of LINGUIST.\nAll data generation models and even the Upper Bound of including human-translated training data perform significantly worse on the test data with human-localized slots compared to the original human-translated test data, indicating that the human-localized test set is more challenging, and motivating future work on conversational agent localization.\nMultiSNIPS Results are show in Table 3. Here, in the AVG non EN there are small differences overall compared to LINGUIST: CALICO (All Translate) is 0.74 points absolute worse on IC (from 98.62 to 97.88) and +1.55 points absolute better on ST (from 85.86 to 87.41). However, similarly to the MultiATIS++ results, CALICO (All Translate) out-performs LINGUIST. All models are close to the upper bound, however, indicating that this dataset may not be particularly challenging."}, {"title": "Conclusion and Future Work", "content": "We introduced CALICO, a novel pipeline for synthetic annotated data generation in new languages, via fine-tuning a largescale pre-trained multilingual seq2seq model. We demonstrated that unlike prior techniques that would translate slots out of context, CALICO can generate annotated slots based on the context and localize them with values more appropriate to the target language. In future, we plan to extend and leverage a reward model into a reinforcement learning setup to further improve the quality of the generated data. We would also like to explore ways to combine the positive effects of LINGUIST paraphrasing with CALICO localization."}, {"title": "Prompt Comparison", "content": null}, {"title": "Success Rates", "content": null}, {"title": "CALICO Slot Operations", "content": null}]}