{"title": "Enhanced Prediction of Multi-Agent Trajectories via Control Inference and State-Space Dynamics", "authors": ["Yu Zhang", "Yongxiang Zou", "Haoyu Zhang", "Zeyu Liu", "Houcheng Li", "Long Cheng"], "abstract": "In the field of autonomous systems, accurately predicting the trajectories of nearby vehicles and pedestrians is crucial for ensuring both safety and operational efficiency. This paper introduces a novel methodology for trajectory forecasting based on state-space dynamic system modeling, which endows agents with models that have tangible physical implications. To enhance the precision of state estimations within the dynamic system, the paper also presents a novel modeling technique for control variables. This technique utilizes a newly introduced model, termed \"Mixed Mamba,\" to derive initial control states, thereby improving the predictive accuracy of these variables. Moverover, the proposed approach ingeniously integrates graph neural networks with state-space models, effectively capturing the complexities of multi-agent interactions. This combination provides a robust and scalable framework for forecasting multi-agent trajectories across a range of scenarios. Comprehensive evaluations demonstrate that this model outperforms several established benchmarks across various metrics and datasets, highlighting its significant potential to advance trajectory forecasting in autonomous systems.", "sections": [{"title": "I. INTRODUCTION", "content": "THE transition of autonomous vehicles (AVs) from a futuristic vision to a practical reality is accelerating, with technological advancements enabling trials and limited public road deployments [1]. However, the progression towards fully operational self-driving cars hinges on a natural comprehen-sion of social norms and behaviors. The effectiveness of this understanding hinges on the capability to reliably predict the behaviors of other road users. The complex interplay among traffic participants, wherein the actions of an individual can markedly influence the decision-making of others, highlights the imperative to refine predictive models. These models are essential for the robust development of autonomous driving strategies [2]\u2013[7]. As sensing technology progresses and com-puting power escalates, there is a corresponding surge in the availability of high-quality data. The convergence of these ad-vancements significantly amplifies the capacity to adopt data-driven methodologies for behavior prediction. Notably, the vision-based systems integral to many vehicles have already endowed them with considerable computational capabilities, thereby facilitating the implementation of such predictive analytics. The utilization of Graph Neural Networks (GNNs) has risen as a particularly effective strategy for addressing the problem under consideration. This is largely attributable to their robust relational inductive bias. Additionally, GNNs inherently excel at forecasting the behavior of multiple agents due to their ability to represent and reason about the rela-tionships among participants within the problem domain. [8]. Moreover, the ability of GNNs to forecast the behavior of multiple agents is a natural outcome of their structure. By representing road participants as nodes within a graph, GNNS can generate simultaneous predictions for numerous targets. This approach significantly enhances the comprehensiveness of forecasting model. Although Transformers have significantly improved mod-eling capabilities, their application to sequence data is often impeded by the quadratic computational cost inherent in their attention mechanism. In contrast, RNN-based models are inherently adept at processing sequential information. To address the issue of context compression in sequence modeling, Mamba, a selective State Space Model (SSM), has been introduced [9]. Unlike the attention-based approach, Mamba leverages the framework of SSMs to encode context through hidden states during recurrent iterations. A pivotal feature of Mamba is its selection mechanism, which facilitates the precise control over input segments that contribute to the formation of hidden states, thereby exerting a consequential influence on subsequent embedding updates. This selection process can be conceptualized as a data-driven node selection in graph modeling, where Mamba selectively filters relevant nodes at each recurrent step, focusing only on the chosen context. This targeted approach to context sparsification aligns with the objectives of attention sparsification and presents a viable alternative to random subsampling techniques. Furthermore, the Mamba module is meticulously engineered to achieve linear time complexity and a minimized memory footprint, thereby significantly enhancing efficiency in large-scale graph training tasks. Despite their versatility and superior performance across a range of tasks, deep neural networks often fail to match the interpretability offered by conventional state-estimation methods. However, recent advancements have shown promise by applying deep neural networks to determine the optimal inputs for an intrinsic motion model, which in turn improves interpretability by ensuring that predictions are consistent with physical laws [10]\u2013[12]. These strategies are well-founded, drawing from an extensive body of literature on motion mod-eling [13], [14]. While the dynamics of different road users, including pedestrians, bicycles, and cars, vary considerably, this diversity may necessitate a distinct set of models for each. A promising solution to this challenge is the application of a more adaptable class of methods. One such approach is the use of Neural Ordinary Differential Equations (neural ODEs) [15]. Neural ODEs provide the adaptability to model and learn the intrinsic differential constraints unique to each category of road user, as utilized in the original MTP-GO [3]. However, directly modeling may result in poor generalization performance. In contrast, this paper use the SSM model to addresses this challenge. As depicted in Figure 1, the proposed framework diverges significantly from the conventional data-driven techniques, which rely on a two-step neural network process. These techniques map agent trajectories into an implicit latent space and then evolve these states to project future positions. In contrast, the approach initiates with SSM to encapsulate the dynamics of multiple agents. When appropriately designed, SSM modeling can be viewed as a specific case of Koopman modeling., offering a structured perspective on system dy-namics. Employing a neural network to predict the control variables that is essential for the SSM. These variables are then further evolved within the control space by another neural network. The process concludes with the computation of the predicted agent states through the SSM, harnessing the fully evolved control variables. A key advantage of the proposed framework is the tangible physical meaning conveyed by the control variables. This is in marked contrast to the elusive implicit states characteristic of traditional methods, which often lack clear physical inter-pretations. The main contribution of the paper are listed as follows: \n\u2022 SSM dynamic system: In this study, a DS approach to model the behavior of agents is used, offering a nuanced and flexible framework for the analysis of complex and nonlinear phenomena. The proposed methodology inte-grates the use of SSM, which effectively harnesses the precision of linear analysis techniques while addressing the intrinsic nonlinearity of the systems under investi-gation. By doing so, both the predictive accuracy and interpretability of the model are enhanced, thereby providing deeper insights into the underlying dynamics\n\u2022 Selection state space: GNNs are adept at capturing the spatial relationships among various agents. While the selection mechanism are proficient in capturing temporal sequences, combining Mamba with the graph neural networks help to catch the spatio-temporal relationship. A unique mixed Mamba structure is proposed to augment the system's analytical capabilities.\n\u2022 State space modeling of control variables: In this paper, the control variables are formulated as SSM contingent upon the estimated past states and predicted states of the agents. These evolving control variables are then integrated into the DS model, which in turn influences the evolution of the agents' states.\n\u2022 The proposed algorithm demonstrates superior perfor-mance over several state-of-the-art methods across three distinct public datasets.\n The structure of this paper is outlined as follows: Section II provides an exhaustive examination of the pertinent literature. Section III delves into the detail of the proposed framework to predict multi-agent trajectories. In Section IV, a comparative analysis of the performance of the refined algorithm against several state-of-the-art methods is presented, showcasing the results of the evaluations across a spectrum of metrics and datasets. Finally, Section V encapsulates the findings and concludes the paper, offering insights into the implications of the research and potential directions for studies."}, {"title": "II. RELATED WORK", "content": "Over the past decade, the field of behavior prediction has garnered substantial attention within the academic community. Thorough insights and extensive analyses on this topic are meticulously presented in several research surveys [16]\u2013[18]. Broadly speaking, the field of behavior prediction is typically divided into three primary categories: intention prediction, motion prediction, and social interactions prediction. These categories often utilize sequential input data, such as histor-ical agent positions, to forecast outcomes. Recurrent Neural Networks (RNNs), and notably Long Short-Term Memory (LSTM) networks, are commonly employed in the domain of this predictive task. The principal aim of intention prediction methodologies is to infer high-level decision-making processes that are intrinsic to the dynamics of the traffic scene. This encompasses the anticipation of actions at intersections, as discussed in [19], as well as the estimation of the probability of lane changes on highways, as detailed in [20]. Within these methodologies, agent trajectories are meticulously annotated in accordance with user-defined maneuvers, and predictive models are sub-sequently constructed within a supervised learning paradigm. While intention prediction is fundamentally characterized as a classification problem, in contrast, motion prediction is inherently framed as a regression task, with distance-based metrics commonly serving as the learning objectives. However, these two predictive endeavors are not mutually"}, {"title": "B. GNNs for Trajectory Prediction", "content": "GNNs constitute the deep learning models that are specifi-cally tailored for processing graph-structured data [32]. When provided with a graph structure and an associated set of features, GNNs are capable of learning meaningful represen-tations for individual nodes, edges, or the entire graph. [33]. These learned features serve as a foundation for a myriad of prediction tasks, enabling GNNs to be applied across a diverse array of applications Temporal GNNs are designed to analyze graph-structured data that is collected sequentially over time. This data forms time series, where each point in the series is associated with a graph. Therefore, temporal GNNs extend the capabilities of traditional GNNs by incorporating mechanisms that explicitly account for the temporal evolution within the data. These models are capable of integrating various models to capture temporal patterns effectively. In-clude RNNs [34], Convolutional Neural Networks (CNNs) [35], or attention mechanisms [10]. Traditionally, the majority of temporal GNNs function on the premise of fixed and known graph structures, as discussed in [35], [36]. Meanwhile, recent research has ventured into the dynamic learning of graph structures themselves, as explored in [37]. Furthermore, GNNs are particularly adept at addressing trajectory prediction problems. This is achieved by conceptualizing the edges within the graph as representations of interactions among agents. The proposed model in [38], employs an encoder-decoder frame-work to forecast the trajectories of physical objects that are in interaction with each other. Within this framework, a GNN is utilized to encode historical information of the system's state, and subsequently a neural ODE decoder is applied to forecast the future trajectories. In the study [39], the application of diverse GNNs to model interactions among traffic participants for motion prediction was explored. Despite being an early foray into this area, the research yielded encouraging outcomes for Interaction-aware (IA) modeling. GRIP++, as introduced in [40], is a graph-structured recurrent framework specifically tailored for the prediction of vehicle trajectories. It translates the scene into a latent representation by employing layers of GNNs, as discussed in [41], the latent representation is subsequently fed into a RNN-based framework for the purpose of trajectory forecasting. The SCALE-net, as discussed in [42], demonstrates proficiency in managing arbitrary interacting agents. Unlike GRIP++, SCALE-net employs an attention mechanism, which is influenced by graph edge features, to encode node feature updates, as elaborated in [43]. In [44], a method was proposed for learning node-wise interactions using solely a graph-attention mechanism, as described in [45]. Following this, the graph encoding is channeled into a LSTM-based decoder, which is utilized for the prediction of vehicle trajectories. The MTP-GO model [3], however, is motivated by the significance of interaction-aware features and consistently maintains the graph structure throughout the entire prediction process. This approach ensures that crucial interactions are preserved for the entire duration of the prediction."}, {"title": "C. Applications of State Space Models", "content": "SSMs serve as a fundamental scientific framework across various disciplines, including control theory and computa-tional neuroscience. These models are characterized by a straightforward equation that maps control signals $u_t$ to an underlying state $x_t$, which is then projected to generate output signals. The latent states within SSMs are often represented using Hidden Markov Models (HMMs), providing a robust mechanism for modeling and analyzing dynamic systems.\n$x = Ax_t + Bu_t$ \n$Y_t = Cx_t$ (1)\nWhen the parameters A, B, and C in (1) are also time-variant, the SSM evolves into Mamba. Mamba introduces an innovative approach that efficiently captures long-range dependencies with a linear computational complexity. This method effectively addresses the computational inefficiencies typically associated with Transformers, while fully preserving their ability to model global information. Due to its excellent performance, Mamba has rapidly garnered significant attention from a substantial number of researchers in the field. U-Mamba [46] and VM-UNet [47] have integrated the Mamba block into the U-net architecture, specifically tailoring it for addressing challenges in biomedical image segmentation. To augment the flow of information on a per-channel basis, the MambaMixer architecture, as detailed in [48], has been further developed to include channel-mixing Mamba blocks. This enhancement has successfully broadened the application scope of MambaMixer to encompass not only image recognition but also time series forecasting. However, the current U-shaped Mamba architectures lack the integration of channel-wise Self-Similarity Module (SSM) components. These modules are crucial for effectively compressing and reconstructing features, especially when dealing with the rich contextual information present within channel dimensions. [49] introduce an innova-tive dual-directional Mamba U-Net model that addresses this gap. Our proposed model simultaneously considers both global contextual information and channel correlations, offering an efficient and effective approach to image restoration."}, {"title": "III. PRELIMINARIES", "content": "In the realm of model-based control theory, the precise representation of the dynamics between the system's input $u$, and its state, represented by $x$, is fundamental for constructing robust and efficient control models. These models are often differentiated into two types: the forward model and the inverse model. The forward model, denoted as $f$, projects the current state $x_t$ and control input $u_t$ onto the subsequent state $X_{t+1}$. Conversely, the inverse model, denoted as $f^{-1}$, infers the required control input $u_t$ from the current state $X_t$ and system next state $X_{t+1}$. This relationship can be mathematically formalized as follows:\n$f(x_t, u_t; \\theta) = X_{t+1}, f^{-1} (X_t, X_{t+1}; \\theta) = u_t,$ (2)\nwhere $\\theta$ represents the parameters of the model.\nHere's a refined version of your academic writing:\nUpon completing the model construction, it is crucial to ap-ply an appropriate numerical integration technique. Several op-tions are available: the explicit Euler method, which is known for its simplicity; the Runge-Kutta methods, which strike a balance between accuracy and computational efficiency; and symplectic integrators, which are especially advantageous for preserving the phase space structure in Hamiltonian systems. These integrators enable accurate prediction of the system's future state, rather than just estimating state transitions."}, {"title": "A. Model engineering", "content": "The primary methodology in robotics is model engineering, which is widely used across various industries. This approach involves using the transfer function $f$, which represents the equations of motion, along with model parameters that de-scribe the robot's physical characteristics, such as mass, center of gravity, dimensions, and moments of inertia. Deriving these equations of motion is a manual process tailored to each robotic system. It typically requires assuming that the robot consists of ideal rigid bodies connected by perfect joints and applying Newtonian, Lagrangian, or Hamiltonian mechanics, in conjunction with the system's structure, to formulate the equations."}, {"title": "B. Data-driven system identification", "content": "Similar to model engineering, data-driven system identifica-tion also uses the analytic equations of motion as the transfer function. However, in contrast to model engineering, the model parameters in data-driven system identification are derived from observed data rather than direct measurements. This approach still requires the manual derivation of the equations of motion, but the parameters are learned through data analysis rather than being directly measured. Simple dynamic parameters can be extracted using linear regression with hand-designed features. This method is com-monly used as the standard system identification technique for robot manipulators. However, it has limitations. It does not inherently guarantee that the derived parameters are physically plausible, as dynamic parameters must satisfy specific con-straints. For example, this approach may result in unrealistic outcomes such as negative masses, an inertia matrix that is not positive definite, or violations of the parallel axis theorem. The drawbacks of this approach include its inability to infer more than linear combinations of dynamic parameters. Formulating inverse dynamics can also be problematic, as it may not have a unique solution, particularly due to friction [52]. To address these issues, some researchers have proposed projection-based approaches, while others have employed vir-tual parameterizations to ensure physically plausible parame-ters [53], [54]. The latter approach involves a more complex optimization process than linear regression, often requiring gradient descent for solution. In summary, this data-driven approach relies solely on the analytic form of the equations of motion and learns the dynamical parameters from observational data. Although it is less labor-intensive than model engineering, collecting high-quality data is crucial for effective learning."}, {"title": "C. Black-box model learning", "content": "In contrast to traditional methods that require a detailed understanding of the individual kinematic chain to derive the equations of motion, black-box approaches operate without prior knowledge of the system. These methodologies use any black-box function approximator as the transfer function and adjust the model parameters to fit the observed data. For instance, the existing literature has utilized various techniques such as Gaussian Mixture Models ([55], [56]), Gaussian Processes ( [57], [58]), feedforward networks ([59], [60]), and recurrent neural networks ([61]) to learn the dynamics model. Black-box models typically focus on learning either the forward or inverse model, and their validity is confined to the distribution of the training data. In contrast, traditional methods based on analytic equations of motion can derive both models simultaneously and generalize beyond the data distribution, as the learned physical parameters are globally applicable. However, black-box models have the advantage of not requiring prior assumptions about the system, enabling them to learn systems that involve contacts. Traditional approaches, which rely on rigid body dynamics, can only model articulated bodies using reduced coordinates and without considering contacts. Consequently, black-box models can potentially offer more accurate predictions for real-world systems where the underlying assumptions of traditional methods are not valid. Despite this, black-box models are generally limited to the training domain and rarely extrapolate beyond it."}, {"title": "IV. THE PROPOSED MODEL", "content": "Nowadays, the multi-agent trajectory prediction models [3], [40], [42], [44] integrate the GNN-based encoder-decoder module, which processes historical observations and feeds them into a neural motion model to facilitate trajectory fore-casting have been proven effective. In this paper, this frame-work is continually utilized but is introduced from different views."}, {"title": "A. Dynamic modeling", "content": "This is originated from that multi-agent systems can be viewed as a collection of individual systems, each operating under the influence of physical laws. These systems' dynamics can be precisely captured through the use of differential equations. The specific differential equation that models the behavior of such a system is presented as follows:\n$\\dot{x} = Ax + Bu, $ (3)\nwhere $Ax$ can be seen as the free response for the system while $Bu$ denotes the response due to external forces. Due to the inherent physical characteristics of the system's dynamics, both $A$ and $B$ remain constant over time. These properties can be effectively modeled using neural networks and learned through data-driven approaches. Which can be enforced by the following loss function: $||X_t \u2013 Ax_t \u2013 Bu_t||_2$, where $A$ and $B$ are a matrices learned automatically, $||\u00b7||_2$ denotes the $L2$-norms. In comparison to direct using SSM model, the Koopman operator has emerged as a pivotal mathematical instrument within an array of scientific fields. This operator transforms the nonlinear dynamics into a linear representation by defining a state space through observable functions. The adoption of the Koopman operator framework not only endows the model with interpretability but also streamlines the automatic derivation of observable functions. This is accomplished through the integration of deep neural networks, a strategy corroborated by recent scholarly work [50]. In the realm of unforced dynamics, [51] introduces an autoencoder framework designed to learn a dictionary of observable functions. This is achieved by approximating the Koopman operator, a key concept in dynamical systems theory, using a finite-dimensional representation. The approximation process leverages a least-squares optimization approach to ensure accuracy and efficiency in the derivation. The Koop-man operator, an infinite-dimensional linear transformation, provides a powerful framework for predicting the future tra-jectories of nonlinear dynamical systems, which acts on a space of observable functions. By decomposing the Koopman operator spectrally, one can uncover the intrinsic dynamics of the system. This decomposition reveals the eigenvalues and eigenfunctions that correspond to the system's behavior, offering a deeper understanding of its underlying mechanisms. By omitting parameter $\\theta$, the Koopman operation $K$ can be represented as:\n$Kg(x_t) = g(f(x_t, u_t)) = g(\\hat{x}_t), (4)$\nwith the DS is represented as:\n$\\hat{x}_t = f(x_t, u_t). (5)$\nUtilizing the fitting capabilities of neural networks to learn an approximate Koopman operator typically requires an encoder-decoder architecture. The encoder maps the original data from its native space to a finite-dimensional space where the dynamics can be approximated linearly. Subsequently, the decoder is employed to map the transformed data back to the original space. With a slight abuse of notation, the approximately linear constraint can be enforced by the loss function $||\\varphi(x_t) \u2013 A14(x_t) \u2013 B2u_t||_2$, where $\\varphi(\u00b7)$ is the encoder learned during training. Additionally, the decoder, denoted by $\\eta(\u00b7)$ is employed to output the state through the following loss function $||x - \\eta(\\varphi(x_t))||_2$. To ensure that the transformation $\\eta(\\varphi(x_t))$ yields the original input $x_t$, one effective approach is to define $\\varphi(x_t)$ as the concatenation of $x_t$ with a set of learnable features. In this scenario, the function $\\eta(\u00b7)$ performs a truncation operation, which can be effectively represented by multiplication with a constant matrix $C$, effectively intercepting the input without altering it. Consequently, the decoder of the Koopman neural network does not introduce extra parameters and the loss function $||x_t \u2013 \\eta(\\varphi(x_t))||_2$ can be omitted, simplifying the training process. In this way, the deep Koopman modeling can be represented as:\n\\begin{cases}\n        \\varphi(x_t) = A14(x_t) \u2013 B_1u_t \\\\\n        x_t = C\\varphi(x_t).\n        \\end{cases} (6)\nWhich can be rewritten as:\n$\\dot{x} = CA14(x) + CB\u2081u, (7)$\nUpon examination of Equation (3), it is observed that when the function $\\varphi(\u00b7)$ is defined as a identity operation, as $\\varphi(x) = x$, they are equivalent. This equivalence implies that under the specified condition, SSM formulation can be regarded as a particular case of a Koopman operator-based dynamical system. Consequently, the Koopman operator exhibits a more robust capacity for expressing non-linear dynamics compared to the traditional SSMs. However, this study encounters a challenge with the control variable u within the DS remaining unknown, which compli-cates the evolution of multi-agent states. When using SSM, the nonlinear expressiveness of the proposed algorithm arises solely from the modeling of these control variables $u$. In contrast, when employing the Koopman operator to model the DS, the nonlinear expressiveness derives from both the observable functions $\\varphi(\u00b7)$ and the control variable $u$. This dual source of nonlinearity may shift the focus of training and impact the representation of potential physical characteristics. A interesting result is when considering the control variables $u$ as the observable functions $\\varphi(x)$ in the Koopman operator framework, equation (3) becomes\n$\\dot{x} = (x^T||\\Phi(x))^T(A^T||B^T), (8)$\nwhere $||$ denotes concatenate. In this context, the SSM can still be regarded as a specialized case within the Koopman operator framework for predicting multi-agent trajectories. For simplicity, this model is still referred to as an SSM in this paper."}, {"title": "B. Graph mixed Mamba encoder", "content": "Although the dynamics of the multi-agent system are en-capsulated within the DS model, the control variables for these agents remain unobserved within the available datasets. Consequently, it is essential to infer the control variables from the historical data using advanced inference techniques. In this context, a neural network encoder is employed to perform this task, leveraging its capability to capture complex patterns and relationships within the data. The encoder meticulously processes the historical dataset $H$, which includes data from all agents, to produce a com-prehensive set of representational vectors. These vectors are instrumental for predicting future trajectories. Moreover, these vectors serve as the control variables within the DS model, as discussed in Section IV-A. Historical data, which maybe unstructured, can be effectively processed by GNNs. These networks are constructed with multiple layers that operate on all nodes simultaneously. Each layer's operation is node-centric, meaning it focuses on individual nodes within the graph. A key feature of GNNs is the sharing of learnable parameters across all nodes within each layer. This proposed approach incorporates a GAT+ GNN layer [63], which employ an attention mechanism to calculate a set of aggregation weights across the inclusive neighborhood $N(v)$ of each node $v$. This approach allows the GNNs to allocate greater importance to specific neighbors within the graph. In this paper, the modified version is utilized, the dynamic attention are calculated and the attention weights are determined by:\n$\\tilde{\\alpha}_{t,v} = \\frac{\\exp(a(\\mathbf{W}_a[h^{\\circledR}||h^{u}||e_{v,u}]))}{\\Sigma_{u \\in N(v)} \\exp(a(\\mathbf{W}_a[h^{\\circledR}||h^{u}||e_{v,u}]))},$ (9)\nwhere $a$ and $\\mathbf{W}_a$ represent learnable parameters that are piv-otal for the performance. Function $\\gamma(\u00b7)$ is utilized to apply the leaky (Rectified Linear Unit) ReLU activation function, which introduces a non-zero gradient for the negative input values. Additionally, $e_{v,u}$ denotes the edge weight that is instrumental in the computation of $\\alpha_{t,v}$ and finally, the representation can be derived using the following equation:\n$h_t = b + \\mathbf{W}_1h^o + \\sum_{\\tau \\in N(v)} \\tilde{\\alpha}_{t,v} \\mathbf{W}_2h^{\\tau}, (10)$\nGAT+ layers commonly employ multiple attention heads, which are distinct instances of the attention mechanism pre-viously described. Each head operates independently to focus on different facets of the data, thereby generating a set of distinct representation vectors. These vectors capture various aspects of the input data, enhancing the model's ability to learn complex patterns. Subsequently, the individual vectors are combined through concatenation or averaging to form a comprehensive new representation. This process allows the GAT+ layer to integrate information from multiple per-spectives, enriching the model's understanding of the input. represents an enhanced iteration of GAT+ architecture. GNNs provide structured feature representations that cap-ture the essence of spatio-temporal dynamics. These features, when conceptualized as time series, offer a robust framework for deciphering the underlying control variables within the DS across temporal dimensions. Recently, a novel modeling approach known as Mamba has been introduced for handling sequence information. With a bit abuse of notation, Mamba leverages a linear ODE to model the mapping from an input sequence $x(t) \\in \\mathbb{R}^N$ to an output sequence $y(t) \\in \\mathbb{R}^N$ via a latent state representation $h(t) \\in \\mathbb{R}^N$.\n\\begin{align}\n  h'(t) &= A_2 h(t) + B_2 x(t), \\\\\n  y(t) &= C_2 h(t),\n\\end{align} (11)\nwhere $A_2$, $B_2$, and $C_2$ represent the state matrix, input ma-trix, and the output matrix, respectively. While N is a positive integer denoting the dimension of the state. When operating in continuous time, the output states are often difficult to solve analytically. Meanwhile, the input data are sampled evenly, represent discrete values. The system described by Equation (10) can be discretized as follows:\n\\begin{align}\n  h_t &= \\overline{A}h_{t-1} + \\overline{B}x_t, \\\\\n  y_t &= Ch_t,\n\\end{align} (12)\nwhere $\\overline{A} = \\exp(\\Delta \\cdot A_2)$, $\\overline{B} = (\\Delta \\cdot A_2)^{-1}(\\exp(\\Delta \\cdot A_2) - I) \\cdot \\Delta \\cdot B_2$, $\\Delta$ represents the discretization step size and $I$ is the identity matrix. After the parameters are transformed using a discrete approach, Mamba incorporates a selection mechanism into the model. This mechanism solely affects the interaction along the time series, making $A_2$, $B_2$, and $C_2$ input-dependent. The purpose of this is to compress the time series information into a more compact state representation. In the context of this paper, the encoder's role is to generate the hidden state vectors, which are assumed to represent the initial control variables. In an effort to enhance the representa-tional capabilities of the Mamba model, this paper introduces a novel mixed Mamba, which integrates diverse features to improve its performance and applicability, the details of which are illustrated in Fig. 3. The output features produced by the GNNs are represented as $x_i$, where $i$ ranges from 1 to $t$. When employing the Mamba block, the calculation of $h_t$ is performed as follows:\n$h_t = \\prod_{k=2}^m \\overline{A}_k \\overline{B}_1x_1 + \\prod_{k=3}^m \\overline{A}_k \\overline{B}_2x_2 + ... + \\overline{B}x_t$ (13)\nGiven that A represents the Hippo matrix, which implicitly contain temporal information, and B is a state depend matrix, Mamba can retain all pertinent information. The encoder's primary role is to create a hidden state vector that captures the initial control variables for the DS model, which is essential for accurately forecasting future time series trajectories. To maximize predictive accuracy, it is crucial to fully leverage the temporal historical data. However, the information encoded within a single Mamba block may not be adequate for all applications. Furthermore, the integration of a mixed Mamba variant is anticipated to significantly enhance the encoder's performance. This innovative approach involves deploying one Mamba block to process the original time series data and a separate Mamba block to handle the inverse time series multiplying with the other time series data. This combined sum is subse-quently refined by the final Mamba block, which is expected to bolster the model's predictive accuracy for future time series trajectories."}, {"title": "C. Control variable SSM", "content": "In the prediction of future trajectories for multiple agents, their motion patterns are typically not subject to drastic changes that are unpredictable even to human observers. Consequently, the control variables within an approximate physical DS model should also exhibit minimal variation. Such a scenario can be effectively captured using a separate SSM. With a bit abuse of notation, this equation can be expressed as:\n$u_{t+1} = A_3u_t + B_3g(x_t, u_t), (14)$\nWhere $A_3$ and $B_3$ are constant matrices learned through automation, $x_t$ denotes the estimated states of the multi-agents derived from the modeled DS. When $B_3g(x, u_t)$ is considered as the response to external forces, this model can be viewed as another instance of SSM. The detailed design of the evolution of the control variables from $u_t$ and $x$ to $u_{t+1}$ is illustrated in Fig. 4. The progressive refinement of control variables enables the model to generate a sequence of features corresponding to different future time steps. This capability enhances the model's ability to forecast future trajectories. Greater accuracy in predicting control variables is directly linked to the precision of trajectory forecasts. Therefore, utilizing more information to refine these control variables can significantly improve the model's predictive performance. The most commonly used function $g(x_t, u_t)$ employs a neural network with $x_t$ and $u_t$ concatenated as inputs. While directly incorporating predicted states $x_t$ and control inputs $u_t$ into a neural network does not inherently account for obser-vations or interactions with other agents, accurate trajectory prediction in multi-agent systems requires considering these inter-agent dynamics. To address this, the graph formulation is reintroduced. GNNs not only evaluate the state of the node representing an agent but also consider the states of neighboring nodes within the graph, capturing spatial relationships and interactions among agents. By integrating GNNs into the evolution of control variables, the model preserves the spatial properties of the multi-agent system throughout both the encoding and decoding stages. This integration facilitates a more intuitive understanding of the system's dynamics, which is crucial for predicting future trajectories of each agent with greater accuracy. Therefore, in this paper, $g(x_t, u_t)$ integrates estimated states processed by a GNN and a MLP. The outputs from these networks are concatenated and then multiplied by the tensor output from another MLP, which takes the most recent control variables as its input. However, since future graph features are not directly ob-servable when forecasting future trajectories, the model uses the most recent graph state as a proxy for evolving the control variables. Thus, when predicting future trajectories, the evolution of control variables relies on the current graph information. The proposed framework for predicting the trajectories of multiple agents can be conceptualized as an encoder-decoder architecture, complemented by a motion model. In this frame-work, the initial control variables are extracted by the encoder, while the decoder is responsible for their subsequent evolution. The motion model, in turn, employs a SSM to enhance the predictive accuracy."}, {"title": "D. EKF", "content": "Furthermore", "form": "n$X_{t+1"}, "x_t + (x_t+||\\Phi^T(x_t))^T(A^T||B^T) \\triangle T + w_k, (16)$\nwhere $\\triangle T$ denotes a sampling interval and $\\psi(x_t) = x_t + (x_t+||\\Phi^T(x_t))^T(A^T||B^T) \\triangle T$. To estimate the process noise using the EKF, one must initially compute the Jacobian matrix through a first-order Taylor expansion as:\n$F_t=\\frac{\\partial \\psi}{\\partial x_t}|_{x_t = x_t} (17)$\nwhere $x_t$ is the estimated state. The prediction step can be mathematically expressed as follows:\n\\begin{aligned}\n    & \\hat{x}_{t+1} = \\psi(\\hat{x}_t), \\\\\n    & \\hat{P}_{t+1} = \\mathbf{F}_t \\hat{"]}