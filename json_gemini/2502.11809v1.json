{"title": "Revealing Bias Formation in Deep Neural Networks Through the Geometric Mechanisms of Human Visual Decoupling", "authors": ["Yanbiao Ma", "Bowei Liu", "Wei Dai", "Jiayi Chen", "Shuo Li"], "abstract": "Deep neural networks (DNNs) often exhibit biases toward certain categories during object recognition, even under balanced training data conditions. The intrinsic mechanisms underlying these biases remain unclear. Inspired by the human visual system, which decouples object manifolds through hierarchical processing to achieve object recognition, we propose a geometric analysis framework linking the geometric complexity of class-specific perceptual manifolds in DNNs to model bias. Our findings reveal that differences in geometric complexity can lead to varying recognition capabilities across categories, introducing biases. To support this analysis, we present the Perceptual-Manifold-Geometry library, designed for calculating the geometric properties of perceptual manifolds.\nBias formation in deep neural networks (DNNs) remains a critical yet poorly understood challenge, influencing both fairness and reliability in artificial intelligence systems. While previous studies have primarily focused on statistical imbalances in training data, recent advances suggest that the intrinsic geometry of feature representations may play a fundamental role in shaping classification biases. Motivated by findings in cognitive science and geometric deep learning, this study introduces a theoretical framework to analyze how perceptual manifold geometry affects class-wise recognition performance. By quantifying manifold complexity through curvature, dimensionality, and topological measures, this work reveals a strong correlation between geometric structure and classification bias. These findings contribute to a deeper theoretical foundation for understanding chaos and complexity in modern learning systems, offering new perspectives at the intersection of machine learning, neuroscience, and nonlinear dynamics.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep neural networks (DNNs), with their powerful learning and generalization capabilities, have been widely applied in visual tasks such as image classification and object detection 1,2. However, the biases exhibited by DNNs toward different categories significantly limit their fairness and reliability in real-world applications3,4. Traditional theories mainly attribute these biases to the long-tailed distribution of training samples5,6. Nonetheless, research and practical observations suggest that even with balanced datasets, DNNS still show substantially better recognition performance for certain categories over others7,8. This indicates that the mechanisms underlying such biases are more complex and remain poorly understood.\nThe human visual system provides critical insights into understanding the origins of biases in DNNs. When neurons in the visual cortex are stimulated by different physical attributes of objects belonging to the same category, they form Object manifolds9,10. As shown in Figure.1a, the human visual cortex gradually disentangles and reduces the dimensionality of complex Object manifolds layer by layer, making them easier to distinguish in deeper cortical areas, thereby achieving object recognition10,11. This process suggests that the geometric complexity of Object manifolds influences the difficulty of disentanglement and recognition performance10,12,13.\nConsidering that the architecture of DNNs mimics this multi-layer disentanglement mechanism14,15, and recent studies16\u201318 demonstrate that the responses of DNNs to images exhibit manifold-like properties similar to those of the human visual system, we refer to the point-cloud manifolds formed by the embeddings of data in the feature space of a trained DNN's representation network as class-specific perceptual manifolds. Formally, given a dataset $\\mathcal{X} = [x_1,...,x_m]$ belonging to a specific class and a trained deep neural network $\\text{Model} = {f(x, \\theta_1), g(z, \\theta_2)}$, where $f(x, \\theta_1)$ represents the representation network and $g(z, \\theta_2)$ denotes the classifier, we extract the $p$-dimensional embeddings $Z = [Z_1,...,Z_m] \\in \\mathbb{R}^{p \\times m}$ using the representation network, with each $Z_i = f(x_i, \\theta_1) \\in \\mathbb{R}^p$. The point-cloud manifold formed by Z is referred to as the class-specific perceptual manifold within the DNN. If the recognition process of DNNs can be viewed as the representation network disentangling, reducing the dimensionality of, and separating class-specific perceptual manifolds, followed by the classifier making decisions (as illustrated in Figure.1b), we hypothesize that: (1) The higher the geometric complexity of a class-specific perceptual manifold produced by the representation network, the more challenging it becomes for the classifier to decode and recognize the corresponding class. (2) Differences in geometric complexity across classes lead to inconsistent recognition capabilities, thus introducing biases."}, {"title": "RESULTS", "content": "To validate this hypothesis, we conducted experiments on widely used image datasets with balanced class samples, including CIFAR-10, CIFAR-10019, Mini-ImageNet20, and Caltech-10121, to eliminate the influence of sample quantity."}, {"title": "METHODS", "content": "To facilitate the study of perceptual manifolds in DNNs, we developed the Perceptual-Manifold-Geometry toolkit, which provides a comprehensive framework for analyzing the geometric characteristics of class-specific perceptual manifolds. The toolkit includes modules for intrinsic dimensionality estimation, Gaussian curvature calculation, and topological quantification, focusing particularly on the number of topological holes. These features enable systematic analysis of the relationships between manifold geometry and recognition performance."}, {"title": "Estimation of the Intrinsic Dimension", "content": "Given a set of embeddings $Z = [Z_1,...,Z_n] \\in \\mathbb{R}^{p \\times n}$ corresponding to an image dataset, Z is typically distributed near a low-dimensional perceptual manifold $\\mathcal{M}$ embedded in the $p$-dimensional space, akin to a two-dimensional plane in three-dimensional space. The intrinsic dimension $ID(\\mathcal{M})$ of the perceptual manifold is such that $d < p$. A higher intrinsic dimension indicates a more complex perceptual manifold. The following describes how to use TLE to estimate the intrinsic dimension of the perceptual manifold formed by $Z = [z_1,..., z_n] \\in \\mathbb{R}^{p \\times n}$.\nThe primary method for estimating intrinsic dimension involves analyzing the distribution of distances between each point in the dataset and its neighboring points, and then estimating the dimensionality of the local space based on the rate of growth of distances or other statistic. Assuming that the distribution of samples is uniform within a small neighborhood, and then uses a Poisson process to simulate the number of points discovered by random sampling within neighborhoods of a given radius around each sample24. Subsequently, by constructing a likelihood function, the rate of growth in quantity is associated with the surface area of a sphere. Given any embedding $z_i$ in the dataset and its set of $k$ nearest neighbors $\\mathcal{V}$, the Maximum Likelihood Estimator (MLE) of the local intrinsic dimensiona at $z_i$ is given by:\n$ID_{MLE}(z_i) = \\left(\\frac{1}{k} \\sum_{j=1}^{k} \\ln \\frac{r_j(z_i)}{r_k(z_i)}\\right)^{-1}$\nwhere $r_j(z_i)$ represents the distance between $z_i$ and its $j$-th nearest neighbor. TLE25 no longer assumes uniformity of sample distribution in local neighborhoods, thus closer to the true data distribution. It assumes the local intrinsic dimension to be continuous, thereby utilizing nearby sample points to stabilize estimates at $z_i$. Specifically, the estimate of the intrinsic dimension at $z_i$ using TLE is given by\n$\\begin{aligned}\nID_{TLE}(z_i) = \\left(\\frac{1}{|V|^2} \\sum_{v \\in V} \\sum_{\\substack{w \\in V \\ v \\neq w}} \\left[\\ln \\frac{d_{z_i}(v, w)}{r_k(z_i)} \\right]_{+} \\left[\\ln \\frac{d_{z_i}(2z_i - v, w)}{r_k(z_i)}\\right]_{+} \\right)^{-1}\n\\end{aligned}$\nwhere $V = V \\cup {z_i}$, and $d_{z_i}(v, w)$ is defined as $(r_k(z_i) (w - v) \\cdot (w - v))/(2(z_i - v) \\cdot (w \u2013 v))$. Furthermore, the global intrinsic dimensionality of the perceptual manifold is estimated as the average of local intrinsic dimensionalities:\n$ID_{TLE}(Z) = \\frac{1}{n} \\sum_{i=1}^{n} ID_{TLE}(z_i).$"}, {"title": "Estimation of the Gaussian curvature", "content": "Given a point cloud perceptual manifold $\\mathcal{M}$, which consists of a $p$-dimensional point set $Z = [Z_1,...,Z_n] \\in \\mathbb{R}^{p \\times n}$, our goal is to calculate the Gauss curvature at each point. First, the normal vector at each point on $\\mathcal{M}$ is estimated by the neighbor points. Denote by $z'_j$ the $j$-th neighbor point of $z_i$ and $u_i$ the normal vector at $z_i$. We solve for the normal vector by minimizing the inner product of $z'_j \u2013 c_i, j = 1,...,k$ and $u_i^{26}$, i.e.,\n$\\min_{\\left|u_i\\right|=1} \\sum_{j=1}^{k} ((z'_j - c_i)^T u_i)^2,$"}, {"title": null, "content": "where $c_i = \\frac{1}{k} \\sum_{j=1}^k z'_j$ and $k$ is the number of neighbor points. Let $y_j = z'_j - c_i$, then the optimization objective is converted to\n$\\min_{\\left|u_i\\right|=1} \\sum_{j=1}^{k} (y_j^T u_i)^2 = \\min_{\\left|u_i\\right|=1} \\sum_{j=1}^{k} u_i^T y_j y_j^T u_i = \\min_{\\left|u_i\\right|=1} (u_i^T (\\sum_{j=1}^{k} y_j y_j^T) u_i).$\n$\\sum_{j=1}^{k} y_j y_j^T$ is the covariance matrix of $k$ neighbors of $z_i$. Therefore, let $Y = [y_1,...,y_k] \\in \\mathbb{R}^{p \\times k}$ and $\\sum_{j=1}^{k} y_j y_j^T = YY^T$. The optimization objective is further equated to\n$\\begin{cases}\n    f(u_i) = u_i^T YY^T u_i, YY^T \\in \\mathbb{R}^{p \\times p},\n    \\min (f(u_i)),\\\\\n    s.t. u_i^T u_i = 1.\n\\end{cases}$\nConstruct the Lagrangian function $\\mathcal{L}(u_i, \\lambda) = f(u_i) - \\lambda (u_i^T u_i \u2013 1)$ for the above optimization objective, where $\\lambda$ is a parameter. The first-order partial derivatives of $\\mathcal{L}(u_i, \\lambda)$ with respect to $u_i$ and $\\lambda$ are\n$\\begin{aligned}\n    \\frac{\\partial \\mathcal{L}(u_i, \\lambda)}{\\partial u_i} &= \\frac{\\partial}{\\partial u_i} [ f(u_i) - \\lambda (u_i^T u_i \u2013 1)] = 2(YY^T u_i - \\lambda u_i), \\\\\n    \\frac{\\partial \\mathcal{L}(u_i, \\lambda)}{\\partial \\lambda} &= u_i^T u_i - 1.\n\\end{aligned}$\nLet $(\\frac{\\partial \\mathcal{L}(u_i, \\lambda)}{\\partial u_i})$ and $(\\frac{\\partial \\mathcal{L}(u_i, \\lambda)}{\\partial \\lambda})$ be 0, we can get $YY^T u_i = \\lambda u_i, u_i^T u_i = 1$. It is obvious that solving for $u_i$ is equivalent to calculating the eigenvectors of the covariance matrix $YY^T$, but the eigenvectors are not unique. From $\\langle YY^T u_i, u_i \\rangle = \\langle \\lambda u_i, u_i \\rangle$ we can get $\\lambda = \\langle YY^T u_i, u_i \\rangle = u_i^T YY^T u_i$, so the optimization problem is equated to $\\underset{\\lambda_i}{\\text{argmin}} \\lambda$. Performing the eigenvalue decomposition on the matrix $YY^T$ yields p eigenvalues $\\lambda_1,..., \\lambda_p$ and the corresponding $p$-dimensional eigenvectors $[\\xi_1,..., \\xi_p] \\in \\mathbb{R}^{p \\times p}$, where $\\lambda_1 > ... > \\lambda_p \\geq 0, ||\\xi_i||_2 = 1, i = 1,...,p, \\langle \\xi_a,\\xi_b \\rangle = 0 (a \\neq b)$. The eigenvector $\u03be_{m+1}$ corresponding to the smallest non-zero eigenvalue of the matrix $YY^T$ is taken as the normal vector $u_i$ of $\\mathcal{M}$ at $z_i$.\nConsider an m-dimensional affine space with center $z_i$, which is spanned by $\u03be_1,..., \u03be_m$. This affine space approximates the tangent space at $z_i$ on $\\mathcal{M}$. We estimate the curvature of $\\mathcal{M}$ at $z_i$ by fitting a quadratic hypersurface in the tangent space utilizing the neighbor points of $z_i$. The $k$ neighbors of $z_i$ are projected into the affine space $z_i + (\u03be_1,..., \u03be_m)$ and denoted as\n$o_j = [(z'_j - z_i) \\cdot \u03be_1,..., (z'_j - z_i) \\cdot \u03be_m] \\in \\mathbb{R}^m, j = 1,...,k.$\nDenote by $o_j[m]$ the $m$-th component $(z'_j - z_i) \\cdot \u03be_m$ of $o_j$. We use $z_i$ and $k$ neighbor points to fit a quadratic hypersurface $f(o)$ with parameter $\u0398 \\in \\mathbb{R}^{m \\times m}$. The hypersurface equation is denoted as\n$f(o_j, \u0398) = \\frac{1}{2} \\sum_{a,b} \u0398_{a,b} o_j [a] o_j [b], j \\in \\{1,...,k\\},$\nfurther, minimize the squared error\n$E(\u0398) = \\frac{1}{2} \\sum_{j=1}^k (\\sum_{a,b} \u0398_{a,b} o_j [a] o_j [b] - (z'_j - z_i) \\cdot u_i)^2.$"}, {"title": null, "content": "Let $\\frac{\\partial E(\u0398)}{\\partial \u0398_{a,b}} = 0, a,b \\in \\{1,...,m\\}$ yield a nonlinear system of equations, but it needs to be solved iteratively. Here, we propose an ingenious method to fit the hypersurface and give the analytic solution of the parameter \u0398 directly. Expand the parameter \u0398 of the hypersurface into the column vector\n$\u03b8 = [\u0398_{1,1},..., \u0398_{1,m}, \u0398_{2,1},..., \u0398_{m,m}]^T \\in \\mathbb{R}^{m^2}.$\nOrganize the k neighbor points $\\{o_j\\}_{j=1}^k$ of $z_i$ according to the following form:\n$\\mathcal{O}(z_i) = \\begin{bmatrix}\n    o_1[1] o_1[1] & o_1[1] o_1[2] & ... & o_1[m] o_1[m] \\\\\n    o_2[1] o_2[1] & o_2[1] o_2[2] & ... & o_2[m] o_2[m] \\\\\n    ... & ... & ... & ... \\\\\n    o_k[1] o_k[1] & o_k[1] o_k[2] & ... & o_k[m] o_k[m]\n\\end{bmatrix} \\in \\mathbb{R}^{k \\times m^2}.$\nThe target value is\n$T = [(z'_1 - z_i) \\cdot u_i, (z'_2 - z_i) \\cdot u_i, ..., (z'_k - z_i) \\cdot u_i]^T \\in \\mathbb{R}^k.$\nWe minimize the squared error\n$E(\u03b8) = \\frac{1}{2} \\text{tr} [(\\mathcal{O}(z_i) \u03b8 - T)^T (\\mathcal{O}(z_i) \u03b8 - T)],$\nand find the partial derivative of $E(\u03b8)$ for $\u03b8$:\n$\\frac{\\partial E(\u03b8)}{\\partial \u03b8} = \\frac{1}{2} (\\frac{d \\text{tr}(\u03b8^T \\mathcal{O}(z_i)^T \\mathcal{O}(z_i) \u03b8)}{d \u03b8} - \\frac{d \\text{tr}(\u03b8^T \\mathcal{O}(z_i)^T T)}{d \u03b8}) = \\mathcal{O}(z_i)^T \\mathcal{O}(z_i) \u03b8 - \\mathcal{O}(z_i)^T T.$\nLet $\\frac{\\partial E(\u03b8)}{\\partial \u03b8} = 0$, we can get\n$\u03b8 = (\\mathcal{O}(z_i)^T \\mathcal{O}(z_i))^{-1} \\mathcal{O}(z_i)^T T.$\nThus, the Gauss curvature of the perceptual manifold $\\mathcal{M}$ at $z_i$ can be calculated as\n$G(z_i) = \\text{det}(\u0398) = \\text{det}((O(z_i)^T O(z_i))^{-1} O(z_i)^T T).$\nUp to this point, we provide an approximate solution of the Gauss curvature at any point on the point cloud perceptual manifold $\\mathcal{M}$. Recent research27 shows that on a high-dimensional dataset, almost all samples lie on convex locations, and thus the complexity of the perceptual manifold is defined as the average $\\sum_{i=1}^k G(z_i)$ of the Gauss curvatures at all points on $\\mathcal{M}$. Our approach does not require iterative optimization and can be quickly deployed in a deep neural network to calculate the Gauss curvature of the perceptual manifold."}, {"title": "Estimation of the Number of Holes", "content": "To analyze the geometric complexity of perceptual manifolds, this study employs Persistent Homology, a technique"}, {"title": "CONFLICT OF INTEREST STATEMENT", "content": "The author (authors) has (have) no conflicts to disclose."}, {"title": "AUTHOR CONTRIBUTIONS", "content": "Yanbiao Ma: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, Writing \u2013 original draft. Bowei Liu: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software. Wei Dai: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software. Jiayi Chen: Resources, Writing \u2013 review & editing. Shuo Li: Funding acquisition, Validation. All authors have read and agreed to the published version of the manuscript."}, {"title": "DATA AVAILABILITY", "content": "All deep neural networks used in this study have been appropriately cited in the main text. All datasets utilized in this research are open access and have been referenced in the paper. The web links to the datasets are as follows: CIFAR-10/100 (https://www.cs.toronto.edu/~kriz/cifar.html), Caltech-101 (https://www.vision.caltech.edu/datasets/). The Mini-ImageNet dataset is derived from ImageNet and can be generated using the MLclf package (https://github.com/tiger2017/MLclf). Additionally, the toolkit developed for calculating the geometric properties of perceptual manifolds has been officially released and is available at https://github.com/mayanbiao1234/Geometric-metrics-for-perceptual-manifolds."}]}