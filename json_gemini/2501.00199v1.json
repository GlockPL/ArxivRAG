{"title": "GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study", "authors": ["Giuliano Lorenzoni", "Pedro Elkind Velmovitsky", "Paulo Alencar", "Donald Cowan"], "abstract": "depression has impacted millions of people worldwide and has become one of the most prevalent mental disorders. Early mental disorder detection can lead to cost savings for public health agencies and avoid the onset of other major comorbidities. Additionally, the shortage of specialized personnel is a critical issue because clinical depression diagnosis is highly dependent on expert professionals and is time-consuming.\nIn this study, we explore the use of GPT-4 for clinical depression assessment based on transcript analysis. We examine the model's ability to classify patient interviews into binary categories: depressed and not depressed. A comparative analysis is conducted considering prompt complexity (e.g., using both simple and complex prompts), as well as varied temperature settings, to assess the impact of prompt complexity and randomness on the model's performance. Results indicate that GPT-4 exhibits considerable variability in accuracy and F1-Score across configurations, with optimal performance observed at lower temperature values (0.0-0.2) for complex prompts. However, beyond a certain threshold (temperature \u2265 0.3), the relationship between randomness and performance becomes unpredictable, diminishing the gains from prompt complexity. These findings suggest that, while GPT-4 shows promise for clinical assessment, the configuration of the prompts and model parameters requires careful calibration to ensure consistent results. This preliminary study contributes to understanding the dynamics between prompt engineering and large language models, offering insights for future development of AI-powered tools in clinical settings.", "sections": [{"title": "I. INTRODUCTION", "content": "Depression affects millions of people worldwide and is recognized as one of the most prevalent mental disorders. Early detection of mental health disorders can significantly reduce healthcare costs and prevent the development of severe comorbidities. However, the shortage of specialized professionals required for precise diagnoses is an increasing concern, as the process heavily relies on experts and demands considerable time.\nIn this study, we propose an innovative approach to clinical depression assessment by leveraging GPT-4 as a diagnostic support tool. Through the analysis of interview transcripts, we aim to explore how artificial intelligence can replicate the clinical sensitivity and diagnostic abilities of human professionals. Beyond simple and direct prompts, we investigate the impact of more sophisticated prompt designs, enriched with detailed examples and fine-tuned temperature settings, to optimize the model's accuracy and consistency. This study not only evaluates GPT-4's capacity to identify depression cases but also explores how prompt structure and temperature calibration influence the stability and predictability of responses, setting new standards for the use of AI in mental health care.\nTo guide our investigation and deepen the analysis, we formulated the following research questions:\n\u2022 RQ1: Can Foundational LLMs accurately diagnose clinical depression using simple binary classification approaches?\n\u2022 RQ2: Does few-shot prompting with examples of therapy sessions help foundational LLMs' accurately diagnose clinical depression?\n\u2022 RQ3: Does more complex prompt engineering improve LLMs' ability to diagnose clinical depression?\n\u2022 RQ4: What is the effect of temperature on LLMs' ability to diagnose depression?\n\u2022 RQ5: How does output variability influence the reliability of GPT-4 in clinical depression diagnosis?\nThis paper is structured into six main sections. Section 2 presents a review of the relevant literature, discussing the state- of-the-art language models applied to mental health and clinical diagnostics. Section 3 outlines the experimental design, covering data usage and the prompt engineering strategies applied to GPT-4. Section 4 presents the results obtained under different prompt configurations and temperature settings, analyzing the model's performance for each approach. Section 5 discusses the findings, highlighting the role of randomness, dataset imbalance, and the sensitivity of evaluation metrics under varying temperature conditions. Finally, Section 6 provides the conclusions and suggests avenues for future research, including advancements with more sophisticated techniques such as RAG and fine-tuning, to enhance diagnostic accuracy and promote the adoption of AI in mental healthcare."}, {"title": "II. RELATED WORK", "content": "Several studies have employed the DAIC-WOZ database for depression diagnosis, focusing on Machine Learning (ML) techniques rather than Large Language Models (LLMs). Some authors [1] applied Support Vector Machines (SVMs) and TextCNN to text-based emotional analysis, exploring the potential of these models to detect linguistic patterns associated with depression. Other authors [2] investigated emotion recognition using speech patterns within the DAIC-WOZ dataset, leveraging acoustic features for depression detection. Similarly, one study [3] used DAIC-WOZ, emphasizing the importance of acoustic features in building robust models for mental health assessments. While these studies utilize the DAIC-WOZ dataset, their focus on ML techniques distinguishes them from our work, which explores LLM-based classification for clinical purposes.\nIn addition to research using DAIC-WOZ, several other studies have explored ML techniques for depression diagnosis and sentiment analysis, leveraging different datasets and methodologies. These studies address challenges such as emotion analysis on social media, multimodal data integration, and enhanced prediction through feature selection and parameter tuning. Examples include the works described in [4], [5], [6], [7], [8], [9], [10], [11], [12], and [13]. Although these studies do not use the same dataset or employ LLMs, they offer complementary perspectives, showcasing the role of ML in mental health diagnostics and sentiment analysis.\nSpecifically, regarding LLM-based approaches, a few studies provide insights into how LLMs are being applied across fields, offering complementary perspectives for the improvement of our approach. Some authors [14] investigate the use of LLMs for depression detection through text analysis, using the E-DAIC dataset, an extension of the DAIC-WOZ dataset. The primary goal of this research is to predict PHQ-8 scores through automated techniques, replacing manual feature extraction. This study achieved a Mean Absolute Error (MAE) of 3.65, demonstrating the model's capability to evaluate depression severity effectively. Our work aligns with this study as we also employ the DAIC-WOZ dataset; however, our approach diverges by focusing on binary classification (depressed or not depressed). Additionally, we explore the impact of various prompt strategies and temperature calibration to optimize the stability and accuracy of the classification task. While this article is the most comparable to our research, we emphasize stability and performance optimization in clinical tasks, extending the potential of LLMs in healthcare.\nIn addition to healthcare, several studies from other fields employ methodologies and techniques relevant to our work. The study described in [15] explores the use of LLMs to automate variable extraction from scientific software manuals, removing the need for manual intervention. Similar to our study, it emphasizes the importance of prompt design and parameter calibration using few-shot examples and temperature adjustments to enhance performance. Although our study also focuses on variable extraction for scientific testing, it applies LLMs in clinical classification, introducing unique challenges such as minimizing false negatives to avoid clinical risks. Both studies share the need to ensure accuracy and stability in the output.\nOthe authors [16] explore using LLMs to estimate the state of charge (SOC) of lithium-ion batteries. While the context differs, there are meaningful parallels between the two studies, as both utilize prompt-based strategies. Our focus lies on binary classification for depression diagnosis, whereas this article applies LLMs for numerical estimation in an industrial context. Moreover, the referenced study employs a hybrid approach with task-specific knowledge through soft prompts, offering potential inspiration for future healthcare applications by enabling the seamless integration of clinical data into prompts.\nAnother study [17] investigates the use of LLMs for automating test generation from bug reports through the LIBRO pipeline. This study compares 15 LLMs, assessing their effectiveness in bug reproduction through different parameters, including model size and temperature. Although in a distinct context, both studies rely on prompt strategies and temperature calibration to optimize performance. The difference lies in the focus: our study addresses clinical classification, while theirs explores software bug reproduction. However, both emphasize the importance of consistent predictions and temperature tuning, showing that insights from one domain can be valuable in another.\nFinally, another relevant study explores the use of GPT-3.5 and GPT-4 to generate automated annotations for emotion, sentiment, and cognitive dissonance in financial conference calls, comparing them to human-annotated data. This study [18] demonstrates that LLMs not only outperform human annotators in terms of consistency and reliability but also offer significant cost and time efficiencies. Additionally, it examines the impact of different prompt strategies on annotation quality, particularly the role of contextual information. While the referenced article focuses on emotions and sentiment analysis within the financial sector, our work applies binary classification to mental health, highlighting the adaptability of LLMs across diverse fields and the importance of tailoring prompt strategies to specific tasks.\nIn summary, while our study shares similarities with works from various domains, it uniquely contributes to the growing body of research on LLMs in mental health by focusing on binary classification for depression detection. Through prompt design and temperature calibration, we aim to optimize performance and stability in a clinical context. A key novelty of our experimental approach lies in its consideration of variabilities related to prompt complexity, the level of randomness as measured by temperature, and performance metrics. The insights from these related studies, although applied in different fields, provide valuable perspectives that can inspire future improvements in healthcare-focused LLM applications."}, {"title": "III. EXPERIMENT DESIGN", "content": "This study leverages collected data exclusively for testing and evaluation, without any training phase, ensuring the validity of results. The approach relies on carefully designed prompts and their interaction with GPT-4's classification capabilities, utilizing responses generated via the OpenAI API. Key examples from the dataset, including two positive and two negative cases, were selected to enhance the prompts. The prompt engineering process involved four stages: (1) A simple binary classification using GPT-4 with a basic prompt (\u201cdepressed\u201d or \u201cnot depressed\u201d), (2) Improving precision by integrating four representative examples, (3) Refining the approach with an elaborate prompt that adds clinical context alongside the examples, and (4) Exploring the impact of temperature calibration (0.0, 0.1, 0.2, etc.) to optimize accuracy and F1-Score. Computationally, the study utilized the OpenAI API to access GPT-4, with Pandas and NumPy for data management, scikit-learn for performance metrics calculation, and Matplotlib/Seaborn for visualizing the outcomes.\nWe based our research on the Distress Analysis Interview Corpus - Wizard-of-Oz (DAIC-WOZ), a dataset designed to support the diagnosis of mental disorders such as depression, anxiety, and post-traumatic stress disorder. DAIC is a database that is part of a larger corpus [19] available to the research community by request. We have submitted a request and the data released refers only to the depressed patients' database. This database contains clinical interviews conducted by humans, human-controlled agents, and autonomous agents. The computer agent is an animated virtual interviewer robot called Ellie that identifies mental illness indicators. Data includes 189 sessions of interviews which correspond to questionnaire responses and audio and video recordings. Each interview is identified by a session number and has a correspondent folder of files which includes files related to video features, audio, transcript, and audio features. This dataset contains training, development, and test subsets. Interviewees are both distressed and non-distressed individuals.\nWe used the text files related to the transcript of the interviews. The Patient Health Questionnaire depression scale (PHQ-8) defines the depression diagnostic and severity measure. and the PHQ-8 file which described the score of each patient according to the depression scale described in [20].\nThis section outlines the different strategies employed to develop and refine prompts for evaluating the GPT-4 model's ability to classify between \"depressed\" and \"not depressed.\u201d Progressively more sophisticated approaches were explored, culminating in temperature calibration to optimize accuracy and response stability.\n1) RQ1 Method - Simple Prompt: In this initial approach, a basic prompt was used, asking GPT-4 to provide a binary classification between \"depressed\" and \"not depressed\" for each transcript. The goal of this stage was to assess the model's performance with a straightforward instruction, without any additional context. This method serves as a baseline, offering a reference point for comparison with more advanced approaches.\n2) RQ2 Method Prompt with Examples: To improve the model's accuracy, four examples from the dataset were introduced: two positive examples (classified as \"depressed\") and two negative examples (classified as \"not depressed\"). The four examples were selected to provide a baseline of interview cases for each category without introducing additional criteria. The primary goal was to ensure the examples resembled other interviews of the same classification to avoid overfitting or introducing artifacts unrelated to the classification task. The choice to use four examples aimed at balancing the need for context enrichment with minimizing the reduction in available observations for analysis. While the distribution of examples was balanced at 50% per class, this slightly deviates from the original dataset distribution of approximately 30% \"depressed\" cases. However, care was taken to ensure the overall proportion of test data remained representative of the dataset.\nThese examples were incorporated into the prompt to provide GPT-4 with additional context regarding the expected classification. The inclusion of these examples had a significant impact, enhancing the model's ability to generalize and refine its predictions.\n3) RQ3 Method - Detailed Prompt with Examples: In this phase, the prompt was further refined to include more detailed instructions and a richer clinical context. In addition to the four examples used previously, the prompt was expanded to simulate the perspective of an expert in psychopathology, guiding the model to deliver a more robust and accurate analysis. This approach aimed to evaluate how the complexity of the prompt influences performance, especially for tasks requiring contextualized analysis.\n4) RQ4 Method - Effect of Temperature on LLM's Inferences: To investigate the impact of temperature on the stability and performance of classifications, different temperature values (0.0, 0.1, 0.2, 0.3, and 0.5) were tested.\n5) RQ5 Method - Temperature Calibration and Stability Analysis: Temperature controls the degree of randomness in the model's responses: lower values tend to produce more consistent responses, while higher values increase response diversity. The goal of this analysis was to explore the balance between stability and diversity, identifying the optimal setting to maximize the model's performance in complex classification tasks.\nThe computational framework for this study was built using various Python libraries and tools to ensure an efficient and reproducible experimental pipeline. The following packages were utilized:\n\u2022 OpenAI API: Provides access to GPT-4, which was used for binary classification tasks in the context of clinical depression assessment. The API allowed dynamic prompt engineering, integration of contextual examples, and parameter tuning, such as temperature adjustments, to explore model performance.\n\u2022 Pandas and NumPy: These libraries were essential for data manipulation and analysis. Pandas facilitated data cleaning, handling data structures such as DataFrames, and exporting the results to Excel files. NumPy was used to support mathematical operations throughout the experiment.\n\u2022 scikit-learn: This library was employed to calculate key performance metrics such as Accuracy, Precision, Recall,"}, {"title": "IV. RESULTS", "content": "This subsection presents the results of using a simple prompt to classify texts as \"depressed\" or \"not depressed\". The model achieved an accuracy of 70.74%, but the recall was only 10.71%, indicating that while the model successfully identified most negative cases, it struggled to correctly detect positive cases (depressed).\nThe use of a simple prompt for classification presented significant limitations, as evidenced by the low F1-Score of 17.91%. This is due to the model's inability to balance precision and recall. Although the accuracy is relatively high (70.74%), the recall of only 10.71% indicates that the model failed to correctly identify most positive depression cases, resulting in a high number of false negatives (50). This shortcoming is critical in clinical diagnostic applications, where sensitivity is essential to ensure that patients in need of intervention are not overlooked. The simplicity of the prompt may have led the model to miss important nuances present in the data, thus reducing its effectiveness for the intended task.\nThis approach introduces four examples in the prompt (two for each class), resulting in a significant improvement in recall to 77.78% and an F1-Score of 60.87%. However, the accuracy dropped slightly to 70.49%, reflecting increased sensitivity to positive cases but at the cost of more false positives.\nUsing the simple prompt with accompanying classification examples demonstrated significant improvements, as reflected in the substantial increase in recall to 77.78% and the F1-Score. The inclusion of two examples for each class (depressed and not depressed) provided the model with clearer contextual references, enabling it to better capture the nuances required for accurate classification. This strategy reduced the number of false negatives, significantly improving the model's sensitivity-a critical aspect for clinical applications. While the accuracy decreased slightly to 70.49%, this trade-off is justified, as the enhanced recall ensures that a larger proportion of individuals with depression are correctly identified. The improved balance between precision and recall highlights the effectiveness of example-based prompts in guiding the model toward more reliable predictions.\nThis configuration uses a more detailed prompt, including clinical context and the same classification examples. However, despite the added sophistication, the results showed that accuracy dropped to 69.23% and the F1-Score was 51.72%.\nIn Table VI, four examples were again incorporated, resulting in 184 available observations. In this case, two observations were not processed due to failures similar to those identified in the previous experiment. These inconsistencies can be attributed to the increased complexity of the prompts, which may have intensified the model's sensitivity to data variations.\nThe use of a complex prompt with classification examples, despite its added sophistication, yielded inferior results compared to the simpler prompt with examples. One plausible explanation for this degradation lies in the default temperature setting, which introduces randomness into the model's output. Complex prompts may amplify this randomness, as the model processes additional contextual details that increase the likelihood of divergent interpretations. This effect is particularly noticeable in scenarios requiring precise classifications, where simpler prompts may reduce ambiguity and maintain focus on the core task. Exploring temperature calibration in RQ4 provides further insights into managing this variability.\nThese challenges are reflected in the observed metrics: the accuracy dropped to 69.23%, and the F1-Score decreased to 51.72%. This suggests that increasing the complexity of the prompt introduced unintended variability in the model's responses, possibly making the task more ambiguous for the GPT-4 model. While the complex prompt provided more detailed clinical context, this added information might have led the model to overfit specific details or deviate from the intended binary classification task. The lower recall of 55.56% further indicates that the model struggled to identify a sufficient number of positive cases, diminishing its practical utility for clinical applications where high sensitivity is essential. Thus, the results highlight that more elaborate prompts may not always enhance performance and can even hinder the model's consistency, particularly when clarity and precision are paramount.\nIn the temperature calibration experiments, the pipeline was enhanced to address the previously identified issues. These enhancements, combined with the robustness of the adjusted pipeline, allowed all 184 observations to be processed successfully, regardless of the temperature settings explored.\n\u2022 Temperature 0.0: The model achieved 72.28% accuracy and an F1-Score of 61.07%, indicating increased predictability and consistency.\n\u2022 Temperature 0.1: Lowering the temperature to 0.1 further improved accuracy to 73.37% and the F1-Score to 63.70%.\n\u2022 Temperature 0.2: At 0.2, recall increased to 81.48%, but accuracy dropped to 71.74%.\n\u2022 Temperature 0.3: At 0.3, performance dropped significantly, with an F1-Score of 54.26% and accuracy of 67.93%.\n\u2022 Temperature 0.5: Finally, at 0.5, the model achieved 68.48% accuracy and an F1-Score of 57.35%.\nThe adjustments in temperature settings played a crucial role in optimizing the model's performance. Lower temperatures (0.0 to 0.2) provided greater predictability and stability, resulting in more consistent classifications, as evidenced by the gradual improvement in accuracy and F1-Score at temperatures 0.0 and 0.1.\nThe analysis of temperature calibration revealed critical insights into GPT-4's performance in sensitive clinical classification tasks. The use of structured prompts with illustrative examples proved effective, providing a solid foundation for achieving consistent metrics, particularly in terms of Accuracy and F1-Score. Stability in the results was primarily observed within the temperature range between 0.0 and 0.2, where the model's responses were predictable, minimizing unwanted variations and promoting reliable behavior.\nAdjustments within this temperature range optimize the trade-off between predictability and performance, ensuring that the model's classifications remain consistent, especially for high-stakes clinical contexts such as depression detection. As the temperature increased beyond 0.3, we observed a marked rise in output randomness, compromising the model's precision and leading to more inconsistent classifications.\nThis behavior suggests the existence of an optimal temperature range for complex prompts with clinical examples. Lower temperatures (between 0.0 and 0.2) offer the best balance between stability and sensitivity, whereas higher temperatures introduce unpredictability, making the model less suitable for clinical use. Proper calibration of this parameter is therefore essential to balance the model's inherent randomness with the need for stability in clinical settings. This balance is crucial to ensure that the model can provide reliable responses aligned with healthcare professionals' expectations, minimizing risks associated with false diagnoses or inconsistent classifications."}, {"title": "V. DISCUSSION", "content": "In our experiments, we observed that even with the same parameter configuration, results varied due to the presence of random components in the model. This variation can influence both accuracy and F1-Score, particularly across different runs with the same temperature and prompt. A potential solution to mitigate this effect would be to calculate the average of results over several runs using the same configuration. This approach would reduce the impact of randomness, providing a more robust and consistent evaluation of the model's performance.\nThe dataset used in this study is significantly unbalanced, with 56 out of 188 interviews showing symptoms of depression, while the rest represent subjects without depression. This uneven distribution suggests that the F1-Score is a particularly relevant metric, as it balances precision and recall, better reflecting the model's ability to identify both classes. It is worth noting that the dataset exhibits a disproportionately high ratio of depressed cases (56 out of 188, approximately 30%), which is significantly higher than the estimated global prevalence of depression in the general population. This imbalance would create a bias toward the classification of subjects as \"depressed,\" potentially inflating recall metrics at the cost of generalizability to real-world scenarios. However, since the study does not involve a training process but instead performs direct classification on the dataset, accuracy remains an important metric.\nIn experiments with different temperature values, it was expected that gradually reducing the temperature would improve both accuracy and F1-Score, particularly for complex prompts with classification examples. The rationale behind this expectation is that a lower temperature should reduce the randomness in responses, leading to more consistent predictions. However, the results revealed a non-linear behavior. Temperatures between 0.0 and 0.2 achieved the best balance between precision and stability, while higher values, such as 0.3 and above, introduced greater variability, negatively affecting the consistency of predictions. This suggests the existence of an optimal temperature where the model maintains both stability and the necessary sensitivity for the task. The non-linear behavior emphasizes the importance of careful calibration and the need for further studies to understand how variability influences results in complex clinical scenarios, such as depression detection.\nIn clinical diagnostics, especially for conditions like depression, minimizing false negatives is critical, as failing to correctly identify a depressed patient may delay treatment and lead to severe mental health consequences. Although high sensitivity is desirable, increasing the model's ability to detect all positive cases can result in a higher number of false positives. However, in healthcare contexts, this trade-off is often acceptable, as it is preferable to investigate more suspected cases than to miss patients who require care.\nIn our experiments, temperature parameters were selected through a series of exploratory experiments to identify configurations that balance sensitivity and stability. The process involved iteratively testing temperature values within a predefined range (0.0 to 0.5) and analyzing their impact on accuracy, F1-Score, and variability. Lower temperatures demonstrated greater consistency in responses, while higher temperatures introduced randomness, highlighting the trade-offs between predictability and diversity.\nWe observed that the intrinsic variability of the model could affect this calibration. Temperature plays a central role here: reducing randomness yields more consistent and predictable responses but may result in missing some positive cases (false negatives). Conversely, higher temperature values increase variability, potentially improving the model's sensitivity but also raising the incidence of false positives.\nTherefore, careful calibration of the model parameters is essential to balance sensitivity and specificity. In clinical settings, this calibration requires a deep understanding of how variability influences results.\nA potential future approach would be to explore the concept of controlled variability, where multiple runs are performed, and the results are aggregated to increase diagnostic stability. This strategy would help mitigate the impact of inconsistent responses while preserving the model's ability to correctly identify positive cases. The exploration of this concept could pave the way for automating the calibration process, enabling more efficient and consistent adjustments in clinical settings."}, {"title": "VI. CONCLUSIONS AND FUTURE WORK", "content": "This preliminary study demonstrates the potential of GPT-4 as a supplementary tool for clinical depression assessment through transcript-based classification. By examining the model's performance across a range of prompt complexities and temperature settings, we have highlighted important insights into how large language models can be optimized for clinical tasks.\nThe results indicate that the combination of structured prompts with illustrative examples yields promising outcomes, achieving solid performance metrics in both accuracy and F1-Score. Models leveraging complex prompts perform particularly well when temperatures are calibrated between 0.0 and 0.2, ensuring stability and consistency in classification outputs. However, temperatures beyond 0.3 introduced variability, revealing that balancing randomness and stability remains a critical factor in configuring GPT-4 for sensitive clinical use cases.\nOverall, our findings suggest that prompt engineering and parameter tuning can greatly enhance the practical utility of GPT-4 in clinical environments. Despite its limitations, this study establishes that GPT-4 can serve as a viable option for mental health assessment, achieving reliable classifications without additional data pre-processing or fine-tuning.\nFuture advancements in this line of research could further enhance model performance by exploring retrieval-augmented generation (RAG) techniques, expanding the variability analysis of temperature for specific clinical applications such as depression detection, and investigating the role of advanced prompt engineering to optimize outcomes across different scenarios. Additionally, fine-tuning with domain-specific datasets and integrating external medical knowledge bases would help align the model more closely with clinical expectations, fostering AI adoption in healthcare settings.\nThis study lays a foundation for future work in applying large language models to clinical mental health assessments, demonstrating both the potential and challenges inherent in leveraging state-of-the-art AI tools for patient care."}]}