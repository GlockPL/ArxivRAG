{"title": "A Beam's Eye View to Fluence Maps 3D Network for Ultra Fast VMAT Radiotherapy Planning", "authors": ["Simon Arberet", "Florin C. Ghesu", "Riqiang Gao", "Martin Kraus", "Jonathan Sackett", "Esa Kuusela", "Ali Kamen"], "abstract": "Background: Volumetric Modulated Arc Therapy (VMAT) revolutionizes cancer treatment by precisely delivering radiation while sparing healthy tissues. Fluence maps generation, crucial in VMAT planning, traditionally involves complex and iterative, and thus time consuming processes. These fluence maps are subsequently leveraged for leaf-sequence. The deep-learning approach presented in this article aims to expedite this by directly predicting fluence maps from patient data.\nPurpose: To accelerate VMAT treatment planning by quickly predicting fluence maps from a 3D dose map. The predicted fluence maps can be quickly leaf sequenced because the network was trained to take into account the machine constraints.\nMethods: We developed a 3D network which we trained in a supervised way using a combination of L\u00b9 and L2 losses, and RT plans generated by Eclipse and from the REQUITE dataset, taking the RT dose map as input and the fluence maps computed from the corresponding RT plans as target. Our network predicts jointly the 180 fluence maps corresponding to the 180 control points (CP) of single arc VMAT plans. In order to help the network, we pre-process the input dose by computing the projections of the 3D dose map to the beam's eye view (BEV) of the 180 CPs, in the same coordinate system as the fluence maps. We generated over 2000 VMAT plans using Eclipse to scale up the dataset size. Additionally, we evaluated various network architectures and analyzed the impact of increasing the dataset size.\nResults: We are measuring the performance in the 2D fluence maps domain using image metrics (PSNR, SSIM), as well as in the 3D dose domain using the dose-volume histogram (DVH) on a validation dataset. The network inference, which does not include the data loading and processing, is less than 20ms. Using our proposed 3D network architecture as well as increasing the dataset size using Eclipse improved the fluence map reconstruction performance by approximately 8 dB in PSNR compared to a U-Net architecture trained on the original REQUITE dataset. The resulting DVHS are very close to the one of the input target dose.\nConclusions: We developed a novel deep learning approach for ultra fast VMAT planning by predicting all the fluence maps of a VMAT arc in one single network inference. The small difference of the DVH validate this approach for ultra-fast VMAT planning.", "sections": [{"title": "Introduction", "content": "Volumetric modulated arc therapy (VMAT) is a modern radiation therapy technique that allows for the delivery of highly conformal dose distributions to tumors. One of the key steps in VMAT planning is the generation of fluence maps, which are used to control the intensity of the radiation beam as it rotates around the patient.\nTraditionally, fluence maps for VMAT planning are generated within an optimization algorithm 1,2. These algorithms can be computationally expensive and time-consuming, especially for complex cases. Indeed they need to perform many iterations between a leaf-sequencing step which tries to reproduce a target fluence map, and a gradient step which tries to minimize a dose objective, and also rely on a multi-resolution approach which divide the arc in multiple sectors in order to avoid converging into local minima.\nOn the other hand, recent developments in predicting 3D radiation dose distributions from planning structure sets have shown promise in the literature3,4,5,6. In this article, we leverages this progress, offering a modular framework for fluence map prediction from 3D dose maps. This modularization aims to simplify the radiation therapy planning process and improve prediction accuracy.\nRecent articles have explored the application of deep learning for direct fluence map pre-diction in Intensity-Modulated Radiation Therapy (IMRT). However, existing methods 7,8,9 adopt an approach that processes each fluence map independently, inadvertently preventing the maps from synergistically contributing to the global treatment objective. This approach neglects the potential benefits of leveraging the complementarity between fluence maps.\nFor VMAT, it's even more crucial to process all fields together because the continuous motion of the MLC requires an interconnected prediction strategy. Independent processing of individual fluence maps misses the necessary continuity of the MLC's dynamic leaf sequence. Fluence map estimation for VMAT has also been explored in other studies 10,11,12, where the authors used a 3D U-Net network to predict the fluence maps.\nIn this article, we introduce a novel deep learning approach for predicting fluence maps in VMAT planning. Our method involves an initial transformation of the input 3D dose map into a new 3D representation, where the gantry's rotation corresponds to a translation that can be effectively utilized by CNNs. This transformation is achieved by projecting the dose map into the beam eye views (BEV) of each control point. Subsequently, we employ a 3D convolutional neural network architecture featuring advanced ConvNeXt 13 building blocks to predict all fluence maps simultaneously. The advantage of having a 3D CNN compared to a 2D CNN is that the convolution in the depth dimension which corresponds to the gantry rotation dimension is also processed with convolutions and the dynamic of the leaf-pairs motions and other gantry rotation equivariance behaviours can be well captured by convolutions thanks to their translation equivariance property. On the other hand the final dose is the result of the contribution of all the fluence maps without any particular order, and as such long range dependencies along the gantry dimension are also important and it is where ConvNeXt blocks that mimic Transformers operations can help compared to"}, {"title": "Methods", "content": "In order to train a network to predict the fluence maps from a 3D dose map, we are using a dataset of RT plans which contains the optimized MLC positions and MU values of each of the control points covering the single VMAT arc as well as the 3D dose map calculated from these optimized MLC positions and MU values. Using the MLC positions and MU values, we compute the fluence maps. Our fluence maps calculation model includes the leaf leakage and motion in between control points but ignores tongue-and-groove effect. In order to simplify the task of the network, we transform the 3D dose map in the BEV of each control point, such that these dose projections are in the same geometry as the fluence maps. Also as in this new representation, rotation of the gantry is transformed into a translation, we are using for the first time a 3D convolutional network architecture, instead of 2D as usually done in the litterature 10,11, in order to exploit translation equivariance in the gantry direction."}, {"title": "Data", "content": "We are using the REQUITE dataset and focus on Varian single arc VMAT plans. The original REQUITE dataset 16 contains 117 plans (which we split in 96 for training, 11 for validation), all prostate cases, with arcs covering a range of 358\u00b0 (almost full rotation) in 178 control points. In this collection of RT Plans, collimators angle varies depending of the plan but most of the cases have 30\u00b0 or 45\u00b0 angles and stay fix during each arc. The couch angle is zero for all the cases. Among these 117 cases, 69 cases are using the Varian High-Definition 120 MLC (HD120) model from Varian, and 48 are using the Varian Millennium 120 ( M120) model. Both of these models are using 60 leaf pairs, but the HD120 model have a smaller leaf width (2.5 mm for the 32 inner leaf pairs and 5 mm for the 28 outer leaf pairs, vs 5 mm for the 40 inner leaf pairs and 10 mm for the 20 outer leaf pairs for the M120 model). Most of the arc rotation directions are clock-wise and only 6 follow a counter clock-wise direction. Anyway, we arrange the 178 control points in increasing degree order (counter clock-wise) so that the network is agnostic to the rotation direction. The plan can be executed in the other direction by simply reversing the order of the control points.\nAs this dataset is very small, one of our contribution is to increase the dataset size by"}, {"title": "Preprocessing", "content": "We compute the fluence maps of the 180 control points of the single VMAT arc, as well as their corresponding dose BEV projections which are stacked to create a 3D tensor that is passed to our 3D network as illustrated in figure 1. We also compare our 3D network, which we present in the next section, with a 3D U-Net, and a 2D U-Net where the BEV projections are passed to the network in the input channel dimension. The calculation of these BEV projections take into account the gantry angle, the collimator angle, the couch angle (which was zero in all our experiments so actually had no effect in the projection), the isocenter, and the spacing and origins of the fluence maps and 3D dose maps respectively."}, {"title": "Network architecture", "content": "The 180 dose BEV projections are stacked to create a 3D tensor which is fed to the 3D network. These 180 BEV projections are sorted in increasing gantry angle degrees so that the network is agnostic to the gantry rotation direction. The network predicts the corresponding 2D fluence maps on the 180 slices of the network output 3D volume.\nOur network architecture, depicted in figure 2, has four downsampling steps which decrease the three dimensions of the feature maps by a factor 2. In order to accommodate for these 4 downsampling steps by a factor 2, we first perform a circular padding in order to increase the gantry dimension from 180 to 192, and then the output of the network is cropped accordingly to reduce the gantry dimension back to 180.\nThe network architecture is a 3D MedNeXt architecture18, which is a 3D U-Net like encoder-decoder architecture, but where residual ConvNeXT blocks 13 are used in place of"}, {"title": "Experiments", "content": "We trained our networks in a supervised way, using a combination of L1 and L2 loss, ADAM optimizer with a learning rate of 0.0001 and a batch size of 1.\nOur dataset of 2266 plans was split in 1868 plans for the training and 193 for the vali-"}, {"title": "Results", "content": "The quantitative results on the original REQUITE dataset are depicted in table 2. As can be observed, the propose 3D network improved PSNR and SSIM, 5.58 dB compared to 2D U-Net is and 3 dB compared to 3D U-Net.\nThe quantitative results on the Eclipse generated dataset are depicted in table 3 and an example of fluence maps prediction is depicted in figure 3. We can observe again that our 3D network improves significantly the PSNR and SSIM over the 2D and 3D U-Net, 5.55 dB compared to 2D U-Net is and 6.51 dB compared to 3D U-Net. We can also notice that increasing the dataset size improved significantly the performance. For our 3D MedNeXt, the increase from ~100 (Ecl. 117) plans to ~400 (Ecl. 500) plans in the training led to an increase of performance of 2.1 dB, and the increase from ~400 plans (Ecl. 500) to ~1900 plans (Ecl. full) led to an increase of performance of 2.69 dB. So the total increase of"}, {"title": "Discussion", "content": "The proposed approach introduces a 3D deep-learning network that predicts all the fluence maps of single arc VMAT plan with a single network inference, requiring less than 20ms. Of course other modules are necessary to perform the inverse planning such as dataloading and preprocessing, dose prediction and leaf sequencing, so the total time for an inverse planning will be significantly longer.\nThe main idea of our method is to first performing a BEV transform of the input dose in order to transform the 3D dose map in a more practical representation. This BEV representation has the advantage of 1) having the dose projection in the same geometry as the fluence maps in order to help the network, and 2) transforming the gantry rotation to a translation in the BEV space, which is convenient in order to take advantage of the convolutions that are the core component of CNNs. For this reason we used a 3D CNN architecture as opposed to a 2D CNN, so that in addition to the two spatial dimensions of the fluence maps, the gantry motion/rotation is also processed with convolutions. This local processing is accounting for all the local shape (spatial dimensions), and dynamics of the MLC (gantry dimension). While the shape and dynamics of the MLC can be well captured by the local 3D convolutional kernels, there are also global features that need to be capture such as the fact that the total dose is the result of the contribution of all the control points. For this reason, ConvNeXt blocks which implement fully connected layers in the feature dimension though 1x1x1 convolutions and mimics the architectures of Transformers allow such processing as opposed to classical U-Net architectures based on convolutional blocks or ResNet blocks.\nAnother important contribution of this paper was to create additional plans and show the importance of scaling-up the training dataset size for the overall performance of AI-based fluence prediction. In particular, our ablation study showed an increase of performance of about 2.5 dB in PSNR each time the dataset size was multiplied by a factor 4.\nThis advancement offers promising prospects for ultra-fast inverse planning within an end-to-end framework, where dose computation6 precedes fluence map generation, followed by leaf-sequencing22. Additionally, it could serve as an initialization for established VMAT optimizers like the Photon Optimization Algorithm (PO) of Varian 23. It's noteworthy that, while this study focused on prostate plans, future endeavors aim to extend the methodology to encompass other anatomical regions such as lung and head and neck. We also envisage extending the method to accommodate multiple arcs VMAT and Hybrid IMRT/VMAT plans.\nIn order to improve the fluence maps prediction, we considered inputting other infor-mations to the network such as the CT scan, the organ contours, and in particular the PTV. These data could be incorporated similar to the dose data, as an extra input channel through the computation of their BEV projections. While we explored this approach, our experi-ments did not reveal significant improvements. One possible explanation could be that a substantially larger dataset might be required to fully exploit the potential of the additional information."}, {"title": "Conclusion", "content": "We have developed a novel AI-based method for fluence maps prediction of VMAT plans from 3D dose maps. Our method predicts all the fluence maps of a VMAT arc at once using a 3D network that takes as input the beam's eye view projections of the 3D dose map. We also improved the performance of our fluence prediction by generating more than 2000 plans using Eclipse and showed the importance of scaling up the dataset size for improved performance. Our network inference is very fast (less than 20ms) enabling ultra-fast inverse planning, while simultaneously enhancing PSNR by 24% compared to a 2D U-Net trained on the same dataset and even 49% compared to a 2D U-Net trained on the original REQUITE dataset. We studied variants of the network (2D and 3D U-Net vs 3D MedNeXt) as well as the effect of the dataset size. We think that our proposed 3D network can be used as a module within an ultra-fast inverse planning framework, or as an improved initialization method for an iterative VMAT optimizer. Future research directions include extending the method to multiple arcs VMAT and augmenting the training dataset size to further enhance its efficacy and generalizability."}, {"title": "Disclaimer", "content": "The concepts and information presented in this paper / presentation are based on research results that are not commercially available. Future commercial availability cannot be guar-anteed."}]}