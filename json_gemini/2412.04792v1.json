{"title": "Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models", "authors": ["Mahfuzul Haque", "Abu Saleh Musa Miah", "Debashish Gupta", "Md. Maruf Al Hossain Prince", "Tanzina Alam", "Nusrat Sharmin", "Mohammed Sowket Ali", "Jungpil Shin"], "abstract": "Heart disease is a leading cause of premature death worldwide, particularly among middle-aged and older adults, with men experiencing a higher prevalence. According to the World Health Organization (WHO), non-communicable diseases, including heart disease, account for 25% (17.9 million) of global deaths, with over 43,204 annual fatalities in Bangladesh. However, the development of heart disease detection (HDD) systems tailored to the Bangladeshi population remains underexplored due to the lack of benchmark datasets and reliance on manual or limited-data approaches. This study addresses these challenges by introducing new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which incorporates comprehensive data on symptoms, examination techniques, and risk factors. Using advanced machine learning techniques, including Logistic Regression and Random Forest, we achieved a remarkable testing accuracy of up to 96.6% with Random Forest. The proposed AI-driven system integrates these models and datasets to provide real-time, accurate diagnostics and personalized healthcare recommendations. By leveraging structured datasets and state-of-the-art machine learning algorithms, this research offers an innovative solution for scalable and effective heart disease detection, with the potential to reduce mortality rates and improve clinical outcomes.", "sections": [{"title": "I. INTRODUCTION", "content": "Heart disease is a severe and urgent medical problem affecting a significant portion of the population [1] beside the other diseases. The potential severity of delayed diagnosis makes rapid diagnosis essential [2]. Current classification approaches often fall short in practical viability, and there is a need for a comprehensive framework suitable for real-life applications in detecting and classifying this condition [3]\u2013[6].\nTo address this problem, a revolutionary software solution is being developed to help healthcare practitioners identify early-stage cardiac diseases by leveraging computer technology and machine learning approaches [7]. Early identification of heart disease by evaluating a person's present cardiac difficulties and risk factors promises to reduce mortality rates [8]. Given the complexity of heart disease detection and classification, existing approaches that rely on pre-processed datasets with few variables must be updated [9]. A comprehensive examination, including general assessments, systemic evaluations of symptoms, risk factors and detailed investigative diagnoses are required due to the disease's complexity [10].\nAs discussed in [11], feature selection techniques are critical in improving heart disease prediction. These techniques help identify the most relevant features from a large set of available data, thus improving the model's performance and reducing overfitting.\nStandard datasets often lack applicability and relevance for real-world implementation, making precise detection and classification challenging [12]. Heart disease identification heavily relies on symptoms, risk factors, and specific investigative data, which are frequently missing from traditional datasets dominated by synthetic data [13]. This work, in contrast, presents a meticulously constructed structured dataset for disease categorization, consisting of over 45,000 accurate patient records from government hospitals, diagnostic centers, and online archives, supplemented with ongoing data augmentation [14]. This extensive dataset is poised to improve model training, resulting in consistently more accurate predictions [15].\nThe paper's groundbreaking paradigm enables individualized disease classification and prediction by integrating cardiac disease diagnosis, categorization, and prognosis [16]. The creation of specialized datasets like HDD (Heart Disease Detection), and CD (Combined Dataset), as well as a sophisticated model using classifiers from Logistic Regression to ensemble model like Random Forest, highlights the potential for precise predictions [17].\nIn summary, in this paper, we make the following contributions:\n\u2022\tWe newly collected HDD and CD datasets from two different sources and classified them into different classes.\n\u2022\tTo compare the effectiveness of our suggested strategies, we carried out an experimental study.\n\u2022\tWe performed experimental evaluations to compare our proposed models with existing models.\nThis paper, divided into six chapters in which literature review is covered in II, dataset description in III, proposed methodology in IV, experimental results in V, and conclusion in VI."}, {"title": "II. LITERATURE REVIEW", "content": "Machine learning models are being used in various domains for their excellence [18]\u2013[20]. There are many researches also have been done to develop various human disease recognition system using various machine learning and deep learning approaches [21], [22]. Lakshmanaro et al. used feature selection and ensemble learning techniques to predict heart disease [23]. They have used ensemble learning effectively. They have also successfully used an ensemble model to forecast cardiac disease. Beulah C. et al [24] developed the ensemble classification to increase the accuracy of less robust algorithms that integrate multiple different classifiers. Jaymin Patel compares various classification methods for decision trees in his research [25]. Rani et al. proposed a hybrid system using a Support Vector Machine, Naive Bayes, Logical Regression, Random Forest, and AdaBoost classifiers in the final stage of the system's development, as Pooja Rani showed [26]. This one's accuracy of 86.6% outperforms other algorithms for predicting heart disease discovered in the scientific literature. Lerina Aversano et al. employed machine learning for the early prediction of heart disease, showing promising outcomes in early diagnosis [27]. Dimitris Bertsimas et al. demonstrated the effectiveness of machine learning for real-time heart disease prediction [28]. Additionally, Richard Raymond Bomford and Adair Stuart Masons clinical methods have laid the foundation for many modern diagnostic techniques [29]. A. H. Chen et al. developed HIPS Heart Disease Prediction System, an early attempt at integrating data mining and heart disease prediction [30]. Abderrahmane Ed-Daoudy and Khalil Maalmi applied real-time machine learning techniques to big data for early detection of heart disease [31]. Aditi Gavhane et al. predicted heart disease using various machine learning algorithms, showcasing the diverse applicability of these techniques [32].\nFurthermore, M. Akhil Jabbar et al. explored lazy associative classification for heart disease prediction, providing insights into alternative classification methods [33]. Pahulpreet Singh Kohli and Shriya Arora applied machine learning in disease prediction, contributing to the growing field of AI in healthcare [34]. Jian Ping Li et al. developed a heart disease identification method using machine learning classification in e-healthcare, reflecting the integration of AI in healthcare systems [35]. Senthilkumar Mohan et al. effectively used hybrid machine learning techniques for heart disease prediction, highlighting the benefits of combining multiple algorithms [36]. Lastly, the study by Anjan Nikhil Repaka, Sai Deepak Ravikanti, and Ramya G Franklin focused on using naive Bayesian methods for heart disease prediction, adding to the array of predictive models available [37]. Priyanka S. Single et al. reviewed methodologies and techniques for heart disease classification and prediction, providing a comprehensive overview of existing approaches [38]. Vijeta Sharma et al. examined machine learning techniques for heart disease prediction, reinforcing the importance of continuous innovation in this field [39]. Archana Singh and Rakesh Kumar compared various machine learning algorithms for heart disease prediction, offering valuable insights into their comparative performance [40]. Jagdeep Singh et al. explored associative classification for heart disease prediction, presenting another dimension of classification techniques [41]. J. Thomas and R Theresa Prince utilized data mining techniques for heart disease prediction, contributing to the expanding literature on data-driven healthcare solutions [42]."}, {"title": "III. DATASET", "content": "The dataset was collected from government hospitals, diagnostic centers, and validated online repositories. Data from 45,779 participants (aged 3-17) were used, with 5,218 children diagnosed with ADHD. The data are binary (1 for Yes, 0 for No) and identifies symptoms like chest pain, shortness of breath, and risk factors. The dataset encompasses both affected and non-affected individuals. Ethical clearance for data collection was obtained from the Ethical Review Board of the respective institutions.\nThe dataset can be accessed from Kaggle: Dataset Link: Heart Disease Dataset.\nA. HDD Dataset\nHDD stands for Heart Disease Detection, we have used heart disease symptoms, examine techniques, risk factors, investigation, and diagnosis information mentioned in [43] and [44]. Nineteen symptoms frequently occur across twenty-seven heart diseases. Risk factors are also present. This dataset exclusively represents patterns associated with heart disease patients. It can identify all twenty-seven heart disease categories. Additionally, the dataset allows for binary classification of heart disease for atypical samples.\nB. BIG-Dataset\nIn 2022, over 1700 people datasets with 15 attributes were collected from hospitals and 1200 from online sources. Non-affected users' data is stored in the BIG-D dataset. The sample of this dataset is shown in Table II\nC. CD Dataset\nCD stands for the combined dataset. We named this dataset according to its action. This dataset is developed from combining the HDD and BIG dataset. In this dataset, data for affected people and non-affected people are combined. We have developed this dataset to train advanced models for better accuracy and to make them usable in advanced technology. This dataset consisted of two labels, including a normal person and a person with heart disease. According to the dataset HDD, which was created with 27 diseases, there are 19 symptoms and four risk factors. The 19 symptoms have two levels: some are major symptoms, and some are minor symptoms. The correlation matrix of the features are shown in Fig. 2.\nD. Dataset Limitations\nWhile comprehensive, the dataset exhibits certain limitations, such as a bias toward specific population groups, which could potentially impact generalization to other demographics. Future studies should consider incorporating more diverse data."}, {"title": "IV. PROPOSED METHODOLOGY", "content": "In this study, we introduced a new heart disease dataset and a model for classification of heart disease. Unlike previous research using existing datasets, our framework is unique, utilizing real-life data from government hospitals, diagnostic clinics, and online sources. The workflow of our proposed methodology is shown in Fig. 3\nA. Feature Engineering\nFeatures were selected based on clinical significance, including 19 symptoms and 4 risk factors based on [43], [44]. Logistic Regression was chosen for its interpretability, while Random Forest was employed for its ability to handle complex, non-linear relationships. The ensemble approach of random forest mitigates overfitting and ensures robust predictions.\nB. Classification\n1) Logistic Regression: In the study, we employed logistic regression to classify the disease and normal people, as well as the severity classification of the patient. Logistic regression is a supervised classification algorithm commonly used for predictive analysis based on probability. This technique evaluates the relationship between the dependent variable and independent variables or risk factors by calculating probabilities using the logistic function, also known as the sigmoid function [45]. The logistic function is expressed as:\n$h(x) = \\frac{1}{1+e^{-(\\beta_0+\\beta_1x_1+\\beta_2x_2++\\beta_nx_n)}}$         (1)\nWhere h(x) represents the probability that the dependent variable is 1 (e.g., the presence of heart disease), $\\beta_0$ is the intercept, and $\\beta_1, \\beta_2,..., \\beta_n$ are the coefficients of the independent variables $X_1,X_2,..., X_n$.\nThe logistic function constrains the output between 0 and 1, which is essential for binary classification problems. Logistic regression is particularly suitable for predicting binary outcomes (e.g., diseased vs. not diseased). The primary applications of logistic regression include prediction and estimating the probability of success. In this context, logistic regression reveals a statistically significant link between the risk factors and the likelihood of developing heart disease.\nThe cost function used in logistic regression is derived from the sigmoid function and is expressed as:\n$J(\\beta) = \\frac{1}{m} \\sum_{i=1}^{m} [y_i log(h(x_i)) + (1 - y_i) log(1 - h(x_i))]$       (2)\nwhere $J(\\beta)$ is the cost function, $m$ is the number of training examples, $y_i$ is the actual output for the i-th example, and $h(x_i)$ is the predicted probability for the i-th example.\n2) Random Forest: In the study, we also employed Random Forest to classify the disease and normal people, as well as the severity classification of the patient. This algorithm designed to mitigate the overfitting issue commonly associated with single decision trees. Single decision trees often learn from only one pathway of decisions, resulting in poor generalisation to new datasets [22], [46], [47]. Random Forest addresses this by constructing multiple clusters of decision trees with controlled variation, enhancing overall prediction accuracy.\nThe Random Forest algorithm operates by merging random selections of input features and using Breimans bagging (Bootstrap Aggregating) sampling techniques. The bagging algorithm improves robustness by drawing observations with replacements from the training data and randomly splitting nodes to achieve the best split within a random subset of features. The decision function in Random Forest can be expressed as:\n$\\hat{y} = mode\\{h_1(x), h_2(x),..., h_B(x)\\}$   (3)\nwhere $\\hat{y}$ is the predicted class, $h_i(x)$ is the prediction from the i-th decision tree, and B is the total number of trees in the forest. In our case, we optimized the hyperparameters of the Random Forest algorithm using a randomized search algorithm with cross-validation. This process involved tuning parameters such as the number of trees, maximum depth, and the number of features considered for splitting at each node to achieve the best performance on the validation set. The Random Forest can also help reduce the noise and overfitting of the system [48]."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "We used Random Forest and Logistic Regression on the HDD, BIG dataset and CD datasets.\nA. Performance With HDD dataset and BigD Dataset\nTable III demonstrates the performance accuracy of the HDD dataset using different models. Random Forest achieved 92.77% training accuracy and 91.90% testing accuracy, while Logistic Regression achieved 95.00% training accuracy and 93.87% testing accuracy. Besides, the Random forest for the BigD dataset shows 90.80% accuracy."}, {"title": "VI. CONCLUSION", "content": "This research assessed machine learning algorithms for cardiac disease identification utilizing the HDD, BIG, and CD datasets.\nThese findings underscore the importance of dataset diversity in enhancing model efficacy. The HDD dataset is superior for disease-specific classification, while the BIG and CD datasets facilitate wider real-world applicability. Random Forest exhibited versatility in handling complex datasets, rendering it appropriate for clinical applications.\nFuture research may augment these datasets with supplementary features and investigate explainability frameworks to improve diagnostic precision and reliability. This study advances the creation of scalable, dependable instruments for cardiac disease detection."}]}