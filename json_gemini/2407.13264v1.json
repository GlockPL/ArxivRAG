{"title": "Underwater Acoustic Signal Denoising Algorithms: A Survey of the State-of-the-art", "authors": ["Ruobin Gao", "Maohan Liang", "Heng Dong", "Xuewen Luo", "P. N. Suganthan"], "abstract": "This paper comprehensively reviews recent advances in underwater acoustic signal denoising, an area critical for improving the reliability and clarity of underwater communication and monitoring systems. Despite significant progress in the field, the complex nature of underwater environments poses unique challenges that complicate the denoising process. We begin by outlining the fundamental challenges associated with underwater acoustic signal processing, including signal attenuation, noise variability, and the impact of environmental factors. The review then systematically categorizes and discusses various denoising algorithms, such as conventional, decomposition-based, and learning-based techniques, highlighting their applications, advantages, and limitations. Evaluation metrics and experimental datasets are also reviewed. The paper concludes with a list of open questions and recommendations for future research directions, emphasizing the need for developing more robust denoising techniques that can adapt to the dynamic underwater acoustic environment.", "sections": [{"title": "I. INTRODUCTION", "content": "UNDERWATER Underwater acoustic data are crucial for various applications [1], [2]. The efficient and intelligent processing of these data is vital for enhancing state-of-the-art underwater technologies. While numerous technologies have been developed specifically for terrestrial and aerial environments, the unique characteristics of the underwater environment make acoustic signals particularly effective for capturing its conditions. However, severe noise interference presents significant challenges to receivers in underwater communications [3]\u2013[5]. The complex underwater settings, unpredictable transmission channels, and varying motion states significantly affect real-world underwater acoustic signals (UAS), potentially obscuring the inherent features of targets [6]\u2013[8].\nConsequently, developing advanced technologies for UAS denoising has become a critical and burgeoning research area in underwater scenarios. Since the UAS contains intensive noise, extracting noise-resistant features is essential for underwater recognition tasks [9]. The UAS denoising can be categorized into four groups: Conventional approaches, decomposition-based framework, deep learning (DL) algorithm, and hybrid schemes. The overall framework of UAS denoising is shown in Figure 1. Conventional frameworks employ handcrafted statistical measurements to obtain the feature set, which is utilized to train the learning-based recognition model [9]. For instance, two recognition models based on neural networks are trained using eighty-eight features computed from the UAS [9]. Although these handcrafted features are interpretable, they may not effectively capture the high-level abstractions in underwater data that are essential for tasks involving complex patterns. Moreover, defining suitable handcrafted features for specific tasks requires extensive domain knowledge and offers limited flexibility.\nInspired by the 'divide and conquer' strategy, the UAS denoising community has explored the decomposition of complex UAS into simpler components, which are then individually or collectively denoised. The family of signal decomposition algorithms in UAS denoising is extensive, including empirical mode decomposition (EMD) [10], variational mode decomposition (VMD) [11], discrete wavelet transform (DWT) [12], empirical wavelet transform (EWT) [13], and their advanced variants [14]. Following decomposition, criteria are established and applied to classify components into signal-dominated, noise-dominated, and pure noise groups. Specific processing or denoising techniques are then tailored to each category. Noise components are discarded, while signal components are preserved. The final step involves the aggregation of these processed components to produce a denoised UAS.\nIn recent years, DL algorithms have succeeded across various fields due to their robust representation capabilities and minimal assumptions about the input data [15]. The feature extraction prowess of DL algorithms has prompted researchers to explore their effectiveness in UAS denoising [16]\u2013[19]. DL-based frameworks for UAS denoising typically utilize different neural network architectures to reconstruct clean signals from noisy inputs and maximize the signal-to-noise ratio (SNR). These models often employ an autoencoder architecture. The design of an efficient DL-based UAS denoising model depends on the choice of architectures and loss functions. The advantages of DL-based techniques include their consistency in denoising and applicability to subsequent tasks such as recognition or analysis based on UAS. Thus, the denoising process is task-oriented, aiming to ensure satisfactory performance across these applications.\nThe underwater data mining and signal process community has been dedicated to imagery data [20]\u2013[22], but much less effort on acoustic data. Although there are some reviews about underwater sensing, they neglect a crucial role of UAS denoising [23]\u2013[25]. Meanwhile, a comprehensive review of the state-of-the-art UAS denoising research needs to be conducted. This article comprehensively reviews recent advances in UAS denoising and contributes to the literature from the following perspectives:\n1 Despite the extensive research on UAS denoising algorithms, a comprehensive review systematically summarizing and discussing these diverse approaches is absent. This deficiency poses a significant challenge for researchers and practitioners aiming to thoroughly understand the landscape of UAS denoising techniques.\n2 We systematically analyze UAS denoising algorithms, from conventional signal processing methods to advanced DL algorithms. Furthermore, we introduce a taxonomy of UAS denoising techniques, marking the first instance of such classification in the literature. This taxonomy meticulously delineates the current landscape of UAS research, revealing insightful connections among each category.\n3 We outline the prevailing challenges encountered in UAS denoising and explore potential solutions. Spanning from methodological intricacies to real-world applications, these challenges offer valuable insights and point towards promising avenues for future research in UAS denoising.\n4 We elucidate the diverse applications of UAS denoising techniques, underscoring their essential role in various underwater applications. This exploration holds significant interest for readers and practitioners alike, highlighting the critical importance of UAS denoising in underwater contexts."}, {"title": "II. OVERVIEW OF UAS DENOISING RESEARCH", "content": "This section first conducts a bibliometric analysis of the reviewed UAS denoising literature. Then, we discuss the unique challenges in denoising UAS data."}, {"title": "A. Bibliometric Analysis", "content": "This survey reviews research in UAS denoising techniques, predominantly published in academic journals or conferences related to ocean engineering, measurement, signal processing, and artificial intelligence (AI). Notable venues include IEEE Transactions on Instrumentation and Measurement, Ocean Engineering, IEEE Journal of Ocean Engineering, Journal of Marine Science and Engineering, Applied Acoustics, Applied Ocean Research, Measurement, and The Journal of the Acoustical Society of America. Figure 2 visualizes the scope of UAS denoising studies addressed in this survey. Figure 2a illustrates a consistent upward trend in the number of studies within the UAS denoising field, despite a drop in publications in 2024, which only encompasses the first half of the year. Figure 2b summarizes the top ten authors by the volume of their contributions to UAS denoising research. According to Figure 2c, the journals Applied Acoustics and Ocean Engineering publish the most research on UAS denoising, given their specific focus on acoustics and ocean engineering. Recently, with advancements in AI, AI-related journals such as EAAI and ESWA have also shown increased receptivity to UAS denoising research. Finally, Figure 2d displays the network graph of co-authorship within the UAS denoising literature, highlighting five collaborative communities and the extent of their interactions."}, {"title": "B. Why UAS denoising is challenging", "content": "The low SNR of the UAS presents significant challenges; however, the complexities of the underwater environment introduce unique difficulties that distinguish UAS denoising from typical signal denoising tasks [4], [26]. Various noise sources exist in underwater environments, as shown in Figure 3. In underwater settings, the noise sources vary and include natural and anthropogenic elements. Natural sources such as marine life activity, wind-driven waves, and precipitation contribute significantly to the background noise. On the other hand, anthropogenic sources include ship traffic, industrial activities, sonar systems, and other man activities, all adding complexity to the noise environment [27], [28]. These diverse noise sources necessitate specialized approaches in UAS denoising to effectively separate the signal from the noise, ensuring clarity and accuracy in data interpretation.\n1) Complex sources: In the underwater scenario, the noise sources contributing to the complexity of acoustic signals can be broadly categorized into natural, anthropogenic, and system-based sources, each adding layers of challenges to UAS denoising:\n1. Natural Noise Sources:\n\u2022 Biological Noise: This includes sounds from marine life, such as whales, dolphins, and fish [29]. These biological entities often produce sounds for communication, navigation, and foraging, which can overlap in frequency and time with the signals of interest.\n\u2022 Geophysical Noise: Phenomena such as wind, rain, and sea state contribute to background noise [30]. Turbulence caused by waves breaking on the surface and interactions between water and seabed during storms generates significant noise levels [31].\n\u2022 Thermal Noise: Caused by the random motion of water molecules, thermal noise is more prevalent in deeper and warmer waters and acts as a constant background noise across all frequencies [32].\n2. Anthropogenic Noise Sources:\n\u2022 Shipping Traffic: Noise from commercial and recreational vessels is a dominant noise source in many oceanic environments. The sound from engines, propellers, and hull movement is pervasive at various frequencies and intensities [33], [34].\n\u2022 Industrial Activities: Underwater construction, oil drilling, and other marine operations involve heavy machinery that emits substantial acoustic signals [35], [36].\n\u2022 Sonar and Naval Exercises: Active sonar systems used by the military and some commercial ships emit powerful sound pulses that can interfere with and mask natural acoustic signals [37].\n3. System-based Noise Sources:\n\u2022 Instrument Noise: Noise inherent to the recording devices, such as electronic noise from sensors and recording equipment, can affect the data quality [38].\n\u2022 Data Transmission Noise: In wireless underwater communication, signals can be corrupted by noise introduced during transmission, including reflections and refractions from the water's surface or the seabed.\nEach noise source interacts differently with the underwater environment, making it challenging to isolate and remove unwanted noise from valuable data. Effective denoising thus requires a deep understanding of both the characteristics of these noises and the acoustic properties of the environment. Advanced signal processing techniques, adaptive filtering, and machine learning models are typically employed to enhance the clarity and reliability of the extracted signals in such complex scenarios.\n2) Energy imbalance: In underwater environments, the fusion of multi-source signals frequently results in an imbalanced energy distribution within the captured acoustic data. This imbalance complicates the signal processing tasks, particularly the denoising of UAS. Factors such as varying signal intensities, overlapping frequency ranges, and sporadic or persistent noise sources further exacerbate the challenge. These complexities necessitate sophisticated denoising techniques that effectively distinguish between noise and actual acoustic signals of interest. Moreover, the dynamic nature of underwater environments, including changes in water density, temperature, and movement, adds additional layers of variability that denoising algorithms must account for. Consequently, improving the accuracy of UAS denoising involves addressing the imbalance in signal fusion and adapting to the inherently noisy and unpredictable underwater acoustic landscape.\n3) Disparate optimization objectives: Since UAS denoising is usually the first stage for underwater recognition tasks, recognition models must be developed. Most literature treats denoising and recognition as two independent stages [39]. When designing UAS denoising algorithms, researchers may not consider the requirements of recognition tasks. The denoising stage is unsupervised, and recognition labels are unavailable. The objectives of developing denoising and recognition models are different, challenges in unifying these two stages."}, {"title": "III. CONVENTIONAL METHODS", "content": "Conventional UAS denoising is usually based on hand-craft features [40] and linear filtering [41]. UAS is split into various barks denoised by wavelet thresholding algorithms [19]. Frame-Based Time-Scale Filters method is proposed to improve the standard wavelet soft-thresholding in reducing distortions in the joint time-frequency space [42]. A two-stage denoising framework consisting of adaptive window median filter and wavelet threshold optimization is designed to eliminate Gaussian and non-Gaussian noise, respectively [43]. This article focuses on the most recent advancement in UAS denoising. For conventional signal processing and thresholding techniques, we suggest referring to these survey studies [44]-[46]."}, {"title": "IV. SIGNAL DECOMPOSITION", "content": "Signal decomposition techniques can decompose complex signals into various components or modes, carrying information of different frequencies. Individual modes are easier to analyze, process, and denoise [47]. The general framework of decomposition-based denoising methods is shown in Fig. After obtaining modes with the help of decomposition, suitable denoising algorithms are applied to these modes. Finally, denoised modes are aggregated to reconstruct the input signal. The overall framework of decomposition-based UAS denoising is visualized in Fig. 4."}, {"title": "A. Wavelet transform", "content": "1) Theoretical development: Fourier transform (FT) has historically been the method of choice for spectral analysis until the advent of wavelet transform. The Fourier transform's limitations, particularly its inefficiencies in local time-frequency representation and its poor performance with non-stationary signals, have led to its replacement by wavelet transform. This newer method has subsequently demonstrated significant success in the analysis of time series data. DWT is calculated as Equation 1,\n$$f(j, k) =< x(t), \\phi_{j,k}(t) >= \\int x(t), \\phi_{j,k}(t)dt,$$\nwhere $\\phi_{j,k}(t) = 2^{j/2}\\phi(2^{j}t \u2013 k), j, k \\in Z$ is the wavelet function in DWT. In a practical forecasting problem, signal x(t) and $\\phi_{j,k}(t)$ are both discrete as t is the discrete time index. In reality, finite-length times series $x(t) \\in L\u00b2(R)$ are all applicable to DWT.\nIn 1988, Daubechies first introduced the construction of a finite-support orthogonal wavelet named the db wavelet family. For a specific wavelet, there is a pair of scaling function $\\phi_{j,k}(t)$ and wavelet function $\\psi_{j,k}(t)$ for scale j.\nThe most important property for a scaling function and wavelet function to satisfy the multi-resolution analysis (MRA) is the dilation equation in Equation 2 and 3 based on which MRA is built. It indicates that the coarser basis $\\phi(t)$ with larger support is a weighted sum of the finer basis $\\phi(2t - k)$ with shorter support and {hk, k \u2208 Z} is the weight.\n$$\\phi(t) = \\sqrt{2} \\sum_{k \\in Z} h_k\\phi(2t \u2013 k)$$\n$$\\psi(t) = \\sqrt{2} \\sum_{k \\in Z} g_k\\phi(2t \u2013 k)$$\nAs {$\\phi_{j,k}(t), k \\in Z$} spans space of scale j (Vj), any function f;(t) in V; can be written as a linear combination of the orthogonal base {$\\phi_{j,k}(t), k \\in Z$} as\n$$f_j(t) = \\sum_{k=-\\infty}^{\\infty} c_j[k]\\phi_{j,k},$$\nwhere cj [k] is the coefficient of a corresponding basis $\\phi_{j,k}$. Based on this representation and Equation 2, 3, the nestedness between space {$V_j, j \\in Z$} can be derived as Equation 5.\n$$V_j \\subset V_{j+1} \\subset \u2026 V_j, j < J$$\nMoreover, the difference(residual) space of two adjacent spaces written as $W_j = V_{j+1} - V_j$ is spanned by wavelet functions $\\psi_{j,k}, (k\\in Z)$ due to the orthogonality between $\\phi_{j,k}$ and $\\phi_{j,k}$ we can effortlessly know that $W_j | V_j$.\nThe scale j of V; is contingent upon the selected wavelet, with different wavelet functions (bases) yielding distinct spaces. A fundamental principle of MRA dictates that the scaling function $\\phi_{j,k}$ exhibits a diminishing support length as j increases, which enhances its resolution and vice versa. Employing MRA in time series analysis provides an effective means to decompose a high-resolution signal into its constituent components, such as the rough trend and various cyclic frequencies, by utilizing different wavelet bases (scaling functions) at various scales.\n2) WT-based UAS denoising: Classical wavelet threshold denoising techniques effectively suppress noise by leveraging thresholds derived from wavelet coefficients, thereby retaining stronger signals [48], [62], [63]. Thresholding within this context can be classified into hard, soft, and hybrid categories [48]. However, classical wavelet thresholding algorithms struggle with non-Gaussian, non-linear, and non-stationary noise types. Moreover, selecting an appropriate threshold remains a significant challenge. To overcome these issues, some researchers have proposed using the posterior probability distribution of wavelet coefficients obtained from the DWT as the threshold to eliminate non-dominant coefficients [52]. Additionally, integrating the lifting wavelet transform with soft thresholding has been investigated as a strategy to mitigate the shortcomings of the first-generation wavelet transform [57]."}, {"title": "B. Empirical wavelet transform", "content": "1) Theoretical development: The EWT represents an automated approach in signal processing, underpinned by robust theoretical foundations for decomposing non-stationary time series data [64]. Contrasting with DWT and EMD [65], EWT conducts a meticulous analysis of time series in the Fourier domain subsequent to the application of a Fast Fourier Transform (FFT). This technique involves the segmentation of the spectrum through data-driven band-pass filtering.\nIn the EWT, limited freedom is provided for selecting wavelets. The algorithm employs Littlewood-Paley and Meyer's wavelets because of the analytic accessibility of the Fourier domain's closed-form formulations [66]. We represent the normalized frequency as w \u2208 [0, \u03c0]. We utilize wn to represent the limits between the segments that are obtained from the Fourier support [0, \u03c0]. These band-pass filters' formulations are denoted using Equations 6 and 7\n$$\\eta (w) = \\begin{cases} \\cos [\\frac{\\pi}{2\\gamma w_{\\eta}} (|w| - (1 - \\gamma)w_{\\eta}) ] & \\text{if } (1 - \\gamma)w_{\\eta} \\leq |w| \\leq (1 + \\gamma)w_{\\eta} \\\\\n0 & \\text{otherwise,} \\end{cases}$$\n$$\\psi_{\\eta} (w) = \\begin{cases} \\cos [\\frac{\\pi}{2\\gamma} (2 + \\frac{1}{w_{\\eta+1}} (1 - \\gamma) - \\frac{|w|}{w_{\\eta+1}}) ] & \\text{if } (1 + \\gamma)w_{\\eta} \\leq |w| \\leq (1 - \\gamma)w_{\\eta+1} \\\\\n\\sin [\\frac{\\pi}{2\\gamma} (\\frac{2w}{|w|} - \\frac{|w|}{w_{\\eta}} - (1 - \\gamma)w_{\\eta}) ] & \\text{if } (1 - \\gamma)w_{\\eta} \\leq |w| \\leq (1 + \\gamma)w_{\\eta} \\\\\n0 & \\text{otherwise,} \\end{cases}$$\nwith a transitional band width parameter \u03b3 satisfying \u03b3 < minn $w_{\\eta+1}-w_{\\eta}$. The most common function ((x) in Equations 6 and 7 are presented in Equation 8.\n$$\u03b2(x) = x\u00b2(35 - 84x + 70x\u00b2 \u2013 20x\u00b3)$$\nThis empowers the formulated empirical scaling and wavelet function {$\\phi_1(w), {\\psi_n(w)}_{n=1}$} to be a tight frame of L2(R). It can be observed that {$\\phi_1(w), {\\psi_n(w)}_{n=1}$} are used as band-pass filters centered at assorted center frequencies.\n2) EWT-based UAS denoising: Although EWT achieved tremendous success in other sequence tasks, the UAS community has not researched its denoising ability [47]. The EWT is employed to decompose the UAS into several sub-series and utilize the sub-series of highest energy to train a recognition model [61]."}, {"title": "C. Empirical mode decomposition", "content": "1) Theoretical development: The EMD is a wholly data-driven approach for decomposing time-domain signals into distinct oscillatory modes and a residual component [10]. Each mode, defined as an Intrinsic Mode Function (IMF), must satisfy two specific criteria to be classified as such.\n1. The number of extremums in the oscillation and the number of zero crossings must equal or differ by at most one.\n2. The mean of the envelopes defined by the local maxima and the local minima shall equal zero.\nThe signal decomposed by EMD can be expressed as the sum of a finite number of IMFs and a residual value.\n$$x(t) = \\sum_{m=1}^{k} IMF_m(t)+r_k(t),$$\nwhere k is the IMF number and rk(t) is the final residual value.\nThe set of IMFs constitutes a complete, adaptive, and nearly orthogonal basis for the original signal. The algorithm for the iterative process of EMD is as follows:\n1) Find all the minima and maxima in x(t).\n2) Perform cubic spline interpolation of minima to obtain the lower envelope $e_m(t)$ and that of maxima for upper envelope $e_x(t)$.\n3) Find the mean of the two envelopes using $m(t) = \\frac{e_m(t)+e_i(t)}{2}$.\n4) Subtract the mean from the signal as d(t) = x(t)-m(t).\n5) Applying the abovementioned factors, check whether d(t) is an IMF.\n6) If d(t) is not an IMF, iterate from step (2) to (5) considering input as d(t) to find the IMF.\n7) If d(t) is an IMF, find the residue r(t) = x(t) \u2013 d(t).\n8) If r(t) has greater than two extrema, i.e., one maximum and one minimum and a single zero crossing the stopping criterion not satisfied, iterate from step (2) to (5), considering r(t) as input to find the subsequent IMF.\n9) If r(t) has less than or equal to 2 extrema, i.e., one maximum, one minimum, and a single zero-crossing, the stopping criterion is satisfied, r(t) is the final residue, and the EMD process is complete.\nThe EMD method preserves the signal in the time domain. Each IMF encapsulates information on the variations in amplitude and frequency of the original signal over time. IMFs consist of a single or a narrow band of frequencies with no overlap. Furthermore, these functions or signals are orthogonal to the original signal [67].\n2) EMD-based UAS denoising: EMD and its variants have achieved tremendous success in UAS denoising [51], [68], [69]. The application of the EMD technique offers a novel approach to detecting and classifying marine mammal vocalizations in underwater acoustics, which traditionally requires extensive manual analysis by skilled acousticians. This method efficiently identifies and labels sound sources in a recording without prior knowledge or extensive pre-processing, streamlining the task through minimal post-processing quality control [70]. The non-stationarity of each decomposition mode is utilized to select noise components obtained by the ensemble EMD (EEMD) [71].\nThe CEEMD is employed to denoise the original signal first, and a bidirectional denoising autoencoder is developed to learn robust representations [72]. The complete ensemble empirical mode decomposition with adaptive selective noise (CEEMDAN) is adopted to decompose UAS into IMFs, and IMF with the minimum difference between the energy distribution ratio and average energy distribution ratio is selected [73]. While decomposing the acoustic target signal, the correlation coefficient between each IMF and the original signal is utilized as a threshold to determine signal-dominated IMFs. In addition to utilizing threshold to drop out noisy IMFs, the literature also employs denoising algorithms to denoise noisy IMFs [58]. A criterion determining noisy IMFs is designed, and then noisy IMFs are denoised. Different criterion is proposed in the literature, such as minimum mean square variance [58], energy concentration property [74]. For denoising IMFs, researchers have tried on least mean square filter [58].\nModified uniform EMD is employed to decompose the input into IMFs, and a double threshold is obtained according to hierarchical amplitude-aware permutation entropy (PE). The threshold assists in dividing IMFs into clean, mixed, and noisy IMFs. Since mixed IMFs contain noisy information, an evolutionary improved wavelet threshold denoising method denoises mixed IMFs [49].\nRecently, secondary decomposition outperforms one-time approaches [53], [75]. Implementing a secondary decomposition assists in extracting high-level features and further denoising IMFs containing indistinguishable noise [76]. VMD decomposes signals denoised by wavelet thresholding further [52]. Then, the IMFs of high mutual information are selected for the following recognition tasks. Adaptive chirp mode decomposition, an advanced extension of EMD, is recently explored in [77]."}, {"title": "D. Variational mode decomposition", "content": "1) Theoretical development: VMD can decompose the non-stationary signals into several sub-series called modes [11]. The VMD can be considered as the following problem\n$$\\min_{\\{m_k\\}, \\{w_k\\}} \\{\\sum_k |\\delta_t [(\\delta(t) + x) * m_j(t)] e^{kw_kt}||^2_2}$$\nwith the constraints as\n$$\\sum_k m_k = x(t),$$\nwhere mk is mode k, wk is mk's central frequency, K is the number of modes, x(t) represents the input time series. The problem shown in Equation 10 is transformed into Equation 12 when introducing the L2 penalty and Lagrange multiplier\n$$L(\\{m\\}, \\{k\\}, 1) = \u03b1\\{\\sum_k||\\delta_t [(\\delta(t) + x) * m_\u2081(t) e^{kw_kt}||^2_2 + |x(t) \u2013 \\sum m_k|| + (x(t), x(t) - \\sum m_k)$$\nThe alternating direction method of multipliers (ADMM) algorithm is utilized to solve the above problem in VMD. Then, the modes mk and wk are obtained during the shifting process. According to the ADMM algorithm, the mk and wk can be computed from the following equations,\n$$m^{n+1} = \\frac{\\hat{y}(\u03c9) \u2013 \\sum_{itk} m_k(\u03c9) +)}{\\frac{1}{2} + 2\u03b1(\u03c9 \u2013 \u03c9_k)^2}$$\n$$\u03c9^{n+1} = \\frac{\\int_0^\u221e \u03c9|m_j (\u03c9)|^2 d\u03c9}{\\int_0^\u221e|m_j (\u03c9)|^2 d\u03c9}$$\nwhere n represents the number of iterations, \u0177(\u03c9), $m_j(\u03c9)$, $$\\hat{\u03bb}$$ (\u03c9) and $m^{n+1}$ represent the Fourier transform of x(t), mj(t), x(t) and $m^{n+1}$, respectively.\n2) VMD-based UAS denoising: To overcome the theoretical limitations of EMD, [11] propose the variational mode decomposition (VMD) algorithm with solid theoretical development. VMD has successfully handled noisy UAS [57], [60], [78]. For instance, [57] employ VMD to decompose the input signal. Then, the authors apply the Savitzky-Golay filter and Lift wavelet threshold (LWTD) algorithms to denoise low-frequency and high-frequency components, respectively. Finally, all components are aggregated for reconstruction. Another principle of denoising IMFs is to classify noise-dominated and signal-dominated IMFs. Different denoising algorithms can be applied to noise-dominated and signal-dominated IMFs [56]. For instance, wavelet-thresholding algorithm and Savitzky-Golay filtering are employed to denoise noise-dominated and signal-dominated IMFs, respectively [56]. Their results demonstrate the superiority of VMD over EMD for UAS denoising tasks."}, {"title": "E. Other decompositions", "content": "The improved symplectic geometry modal decomposition generates IMFs in [79]. Unlike most literature, which utilizes some criterion to group IMFs into clean signal and noisy parts, spectral clustering is employed to cluster IMFs into mixed and noise clusters. Finally, wavelet thresholding techniques filter out noise in mixed clusters. The authors employ intrinsic timescale decomposition and correlation coefficients to denoise UAS data [80]."}, {"title": "F. Thresholding", "content": "Thresholding is a fundamental step in the decomposition-based denoising framework. It eliminates noisy information from all decomposed components based on a predefined threshold [49]. This technique comprises two main stages: threshold determination and the thresholding function application. The first stage, threshold determination, primarily involves calculating threshold values using an appropriate criterion. The second stage, the thresholding function, is concerned with removing noise components while preserving the significant signal elements according to the established threshold.\n1) Threshold determination: When decomposing signals, distinguishing between meaningful components and noise is crucial. Noise components typically have little to no informational overlap with the original signal. The first stage of thresholding is to determine the threshold value. A good threshold value should assist in retaining signal-dominated information and eliminating noise as much as possible. Researchers have utilized a variety of criteria to compute the threshold value. For instance, correlation coefficients between IMFs and original signals are employed to determine the threshold [81]. Signal-dominated components should show a much higher correlation than noise-dominated components. However, correlation coefficients cannot measure the non-linear dependency between decomposed components and original UAS, which is essential in complex signal environments.\nIn addition to linear criterion, the entropy is an essential indicator to reflect information in each IMF [82]. Hence, the literature has explored various entropy-based metrics to compute the threshold, such as permutation entropy (PE) [83]\u2013[87], amplitude-aware PE [49], [82], dispersion entropy (DE) [58], [59], [88], fluctuation-based DE [78], [89], slope entropy [86], weighted PE[90], neural network estimation time entropy [55].\nMutual information quantifies the amount of information obtained about one random variable through another random variable. In the context of signals, it measures how much information the presence of one signal can tell about another signal. This is particularly useful when determining how much of one signal (such as the original) is present in another (like a decomposed signal component). Mutual information [83]."}, {"title": "G. Hyper-parameters of signal decomposition", "content": "A practical issue of the decomposition-based denoising framework is determining the hyper-parameters of decomposition algorithms [52]. Signal decomposition algorithms share an essential hyper-parameter, the decomposition level. Smaller decomposition levels lead to significant mode mixing issues. However, high decomposition levels may generate components of fake frequencies and deteriorate the denoising performance. Meanwhile, each additional level of decomposition increases the computational burden.\nResearchers attempted to directly apply the decomposition level of EMD to VMD to retain the advantages of VMD while incorporating the adaptive capabilities of EMD [52]. Spearman correlation coefficients are utilized as a threshold to determine whether the decomposed component is unsubtle [56]. Measuring correlations between reconstructed and original UAS can also guide the selection of decomposition level [91]. Evolutionary optimization successfully determines hyperparameters of signal decomposition algorithms in the UAS denoising literature [81]. Researchers employ various evolutionary algorithms to search for threshold, decomposition, and other crucial parameters [43]."}, {"title": "V. DEEP LEARNING", "content": "Deep learning (DL) algorithms employ a deep neural network to reconstruct clean signals from noisy input [92]\u2013[95]. Most literature has followed the framework of autoencoder for reconstruction [96]. Designing suitable architectures and novel loss functions to extract noise-resistant features efficiently is crucial [97]-[100]. Table III summarizes representative DL-based UAS denoising in recent years."}, {"title": "A. DL-based UAS denoising methodology", "content": "Unlike traditional denoising algorithms and signal decomposition techniques, neural networks operate without preset assumptions about the noise characteristics [100]. Various deep learning architectures have demonstrated efficacy in UAS denoising, including convolutional neural networks (CNNs) [16]\u2013[19], [113], [114], recurrent neural networks (RNNs) [101], and attention-based neural networks [102]. The reconstruction-based DL denoising algorithms pipeline is visualized in Figure 5. Time-frequency transformation is optional because the DL model can directly process the original UAS. This framework trains a denoising DL model based on reconstruction loss and SNR-related loss. Reconstruction loss can be computed based on the spectrum when any Time-Frequency transform is adopted.\nAn ideal binary mask (IBM) is initially estimated using features derived from clean and noisy signals, followed by training a deep multilayer perceptron (MLP) to predict the IBM for effective denoising [115]. To reconstruct the noisy input, a stacked convolutional sparse denoising autoencoder is employed, leveraging sparse representations [116]. Furthermore, a Multiscale Residual Unit (MSRU) incorporating various convolutional kernels has been proposed to extract robust noise-resistant features [18]. Additionally, CNN features can be enhanced through a dual-path recurrent neural network, significantly improving the denoising performance for UAS [101]. Considering the high dimensionality of the original time series, Mel-frequency cepstral coefficients (MFCCs) are extracted as training samples from both the original and denoised UAS using CEEMDAN [72].\nResearchers have investigated the denoising capabilities of Generative adversarial networks (GANs) for UAS [103], [105]. Specifically, the GAN algorithm has been employed to mitigate underwater ambient noise [105]. Initially, the short-time Fourier transform (STFT) is applied, using magnitude and phase features as inputs for the GAN. Clean signals are then reconstructed from the GAN's output using the inverse STFT (ISTFT). In another approach, a GAN is utilized to generate clean signals, with the discriminator designed to distinguish between real noisy signals and the combination of clean signals with ambient noise [104]. This denoising model incorporates a 1D convolutional layer for feature extraction. Experimental results indicate that the GAN model surpasses both EMD and wavelet methods in performance.\nRecently, the attention mechanism has been integrated into denoising UAS. [106] developed a dual-branch attention-based neural network to reconstruct clean signals from noisy complex spectra. Comparative studies have demonstrated that this deep learning approach surpasses traditional Wavelet-based and EMD-based denoising algorithms. Additionally, [107] proposed a deep learning model incorporating Residual (Res) blocks and attention modules to effectively separate a noisy waveform into noise and a denoised waveform. Furthermore, a Transformer model, trained to maximize the SNR, has been utilized for acoustic signal denoising [108]. Another innovative deep learning model, featuring channel, frequency, and time attention modules, has been introduced to extract robust noise-resistant features across multiple domains [109].\nAnother significant challenge involves the disparate optimization objectives between denoising and recognition tasks in UAS processing [39]. To address this, a joint training framework utilizing a modified Transformer neural network has been proposed, which successfully achieves both denoising and recognition [39]. The loss function in this framework is dual-part; it includes a denoising component where the mean squared error between the noisy and the clean signal is minimized.\nA self-supervised, dual-channel self-attention encoder has been proposed to learn robust, noise-resistant features of UAS [110]. This self-supervised learning approach compels the UAS model to identify and retain the most informative and stable patterns for succeeding in the pretext task. Additionally, this method inherently encourages the model to learn features invariant to minor perturbations or variations (i.e., noise) in the input data, focusing on attributes crucial for distinguishing between fundamentally different classes or scenarios. Furthermore, data augmentation has been demonstrated to enhance the accuracy and noise robustness of the UAS model [111], [117].\nDiversity in architectures is crucial for deep learning-based approaches in UAS processing. For example, multiple classifiers are constructed to handle different types of noise [112]. The pivotal principle in designing deep learning models for UAS-related tasks lies in extracting robust and noise-resistant features. A diverse set of feature extractors facilitates the extraction of multi-scale features, ultimately enhancing noise resistance. The literature demonstrates using convolutional filters with diverse kernel sizes to capture these multi-scale features [102], [118]\u2013[1```json\n120]. Different convolutional kernels aid in automatically learning features across various frequencies. Moreover, [120] propose a parallel architecture to jointly learn from UAS data, optimizing feature extraction for enhanced performance.\nDesigning suitable loss functions is essential for deep-learning denoising methods. Generally, DL-based UAS denoising algorithms employ reconstruction-based loss [16], [72], [121]. They train a DL model to reconstruct clean signal-dominated components from noisy UAS [106]. For recognition-based DL models, supervised classification losses are employed [18]. Besides reconstruction-based and recognition-based terms, other terms assisting in enhancing noise-resistance representations and generalizations are designed and employed [16]. For instance, the distance between learned features and feature centroid is minimized to enhance the noise-resistance of features [118]. Correspondingly, a passive attention loss is defined. Some studies train the neural network to maximize SNR [39], [101]."}, {"title": "B. Input formulation", "content": "Appropriate formulations of the input for UAS are critical for the performance of deep learning denoising methods [17]. Although directly processing raw UAS data is a straightforward choice, a meaningful formulation significantly aids in training deep learning models. Typically, the UAS community utilizes time-frequency transformations of the raw signal, such as the STFT [122], Mel-Spectrum [109], Bark spectrum [111], and hand-crafted features [9], [123]. Experimental studies have demonstrated that features like the magnitude STFT spectrum, complex-valued STFT spectrum, and log-mel spectrum notably enhance the performance of deep CNNs in underwater recognition tasks [17]. Additionally, Mel-frequency cepstral coefficients are employed as inputs for a deep CNN to improve recognition accuracy further [114]."}, {"title": "C. Data augmentation", "content": "Data augmentation is a critical technique in improving the noise resistance of deep learning models and achieved significant success in sequential tasks [117], [124]. Data augmentation artificially expands the training dataset by creating modified versions of the existing UAS. These modifications might include adding noise, cropping, or changing lighting conditions. This variety assists in training denoising and recognition models based on diverse samples. By training on a more diverse data set, data augmentation acts as a form of regularization. It effectively prevents the model from memorizing the training UAS (overfitting), encouraging more robust generalization abilities.\nUAS denoising models are usually developed based on the time-frequency transformation of the original UAS [102]. Data augmentations can be directly applied to the original UAS in the time domain by adding noise [102]. Adding noise is naturally advantageous for underwater tasks due to the noisy and complex characteristics of the underwater environment [117]. After transforming the original UAS into time-frequency representations, masking is a common and straightforward augmentation strategy [111]. For instance, time-masking and frequency-masking are implemented on representations obtained from Mel filter bank [102].\nConventional data augmentation strategies in UAS processing involve training denoising or recognition models using both raw and augmented samples. However, the direct contribution of augmented samples to training losses may lead to performance degradation [111]. To address this issue, a smoothness-inducing regularization technique has been proposed to minimize the distance between representations of raw and augmented samples, thereby improving the consistency and effectiveness of the training process [111]. Additionally, a local masking and replicating technique has been developed, which randomly selects two samples, applies local masking, and mixes them to create a new augmented sample [111]. Experimental results indicate that these proposed augmentation techniques outperform GAN-based algorithms in terms of enhancing model robustness and recognition accuracy [125], [126]."}, {"title": "VI. OTHER METHODS", "content": "In addition to the above UAS denoising techniques, the literature has explored other techniques, such as dictionary learning [127] and Least mean squares (LMS) denoising [128]. The study has demonstrated that the LMS denoising algorithm outperforms EMD and VMD [128]."}, {"title": "VII. EVALUATION METRICS", "content": "Performance evaluation is crucial for assessing the effectiveness of UAS denoising techniques [121]. Various metrics are utilized in the literature to evaluate UAS denoising performance. Predominantly, these metrics are based on the signal-to-noise ratio (SNR), which quantifies the desired signal level relative to the background noise. Additionally, some studies employ recognition accuracy as a direct measure of performance, primarily when denoising is intended to improve the accuracy of subsequent recognition tasks. This section summarizes the evaluation metrics commonly used in UAS denoising research."}, {"title": "A. Signal quality metrics", "content": "1) Signal-to-noise ratio: The signal-to-noise ratio (SNR) quantifies the proportion of signal power to noise power. Higher SNR values indicate lower noise content in the signal, whereas lower SNR values suggest higher noise content. The SNR is defined as:\n$$SNR = 10 log_{10} (\\frac{P_{signal}}{P_{noise}})$$\nwhere Psignal and Pnoise represent the power of pure UAS and noisy signals, respectively. SNR is a necessary and popular evaluation metric for UAS denoising [57].\n2) Peak signal-to-noise ratio: The peak signal-to-noise ratio (PSNR) is a significant metric for evaluating UAS denoising quality. For the UAS, PSNR measures the ratio of the maximum possible power of a signal to the power of corrupting noise that affects the fidelity of its representation [100]. The PSNR can be computed by\n$$PSNR = 10 log_{10} (\\frac{MAX_I}{MSE}),$$\nwhere MSE is the mean squared error between the original and the denoised signal. A higher PSNR value indicates that the denoised signal is higher quality than the noise level. The denoising process effectively reduces the noise while preserving the integrity and strength of the original signal.\n3) Signal-to-distortion ratio: The signal-to-distortion ratio (SDR) specifically focuses on the distortion between the original signal and the estimated signal [106]. The SDR is defined as,\n$$SDR = 10 log_{10} (\\frac{P_{signal}}{P_{distortion}})$$\n4) Signal-to-distortion ratio improvement: The Signal-to-Distortion Ratio Improvement (SDRi) measures the improvement in SDR due to some processing or alteration of a signal. The SDRi is calculated by comparing the SDR before and after the processing [106].\n$$SDRi = SDR_{after} - SDR_{before}$$\n5) Scale-invariant signal-to-noise ratio improvement: The Scale-Invariant SNR Improvement (SI-SNRi) is a measure often used in audio and speech processing to evaluate the effectiveness of enhancement algorithms, particularly when the absolute scale of the signal may not be consistent or important. This metric adjusts for scaling differences between the processed and original signals, providing a more robust comparison.\n$$SI-SNRI = SI-SNR_{after} - SI-SNR_{before}$$\nThe scale-invariant SNR is calculated differently from the traditional SNR to account for scaling factors between the target and estimated signals. It involves normalizing the signal relative to a reference before computing the power ratio:\n$$SI-SNR = || \\text{target} ||^2 || \\frac{||\u03b1 \u00b7 \\alpha(n)||^2}{|| \\alpha(n) \u2013 \u03b1 \u00b7 \u03b1(n) ||^2}$$\nwhere $\\alpha = \\frac{\\<estimate, target\\>}{|| target ||^2}$ scales the target signal to best fit the estimate in a least-squares sense. This normalization allows the SI-SNR to be independent of the signal's scale, focusing solely on the noise and distortion relative to the target's shape and structure [106].\n6) Segment signal-to-noise ratio: The Segment SNR (SSNR) averages the SNR values computed for each segment, giving a more detailed measure of signal quality across different parts of the signal, which is especially useful in cases where signal characteristics vary over time [106]. The SSNR can be computed by\n$$SSNR = \\frac{10}{M} \\sum_{m=1}^{M} log_{10} (\\frac{P_{signal}^{m}}{P_{noise}^{m}}),$$\nwhere $P_{signal}^{m}$ and $P_{noise}^{m}$ represent the power of the mth segment of the signal and noise, respectively."}, {"title": "B. Reconstruction error", "content": "Reconstruction error measures the deviations between the pure signal and noise reduction signal. An outstanding denoising algorithm should precisely reconstruct the pure signal and achieve a small reconstruction error. There are various reconstruction errors in the literature [57]."}, {"title": "VIII. EXPERIMENTAL DATASET", "content": "The literature on UAS denoising algorithms has been evaluated using a variety of datasets due to the challenges inherent in the underwater environment and the difficulties associated with real-world data collection. Consequently, many studies have utilized synthetic data and artificial noise to test their algorithms. On the other hand, some studies have conducted experiments with real-world UAS datasets. The table below provides a summary of popular datasets used in UAS denoising research."}, {"title": "A. Synthetic data", "content": "Due to the limited availability of UAS datasets, researchers have purposefully simulated synthetic pure and noise signals to test denoising algorithms."}, {"title": "B. Real-world data", "content": "In addition to the synthesized data discussed earlier, the literature also examines UAS denoising algorithms using real-world datasets. Unfortunately, most datasets gathered by respective authors are not publicly accessible. Among the publicly available datasets, ShipsEar and DeepShip are the most notable. The ShipsEar dataset comprises underwater acoustic recordings of ships and boats, featuring 90 recordings across 11 vessel types, totaling 6189 seconds of audio. In contrast, the DeepShip dataset includes 47 hours and 4 minutes of real-world underwater recordings, capturing 265 different ships categorized into four classes. These recordings were made throughout various seasons, featuring diverse sea states and noise levels. The DeepShip dataset contains nearly seven times more recordings and is approximately 25 times longer in total duration than the ShipsEar dataset. Usually, each record is segmented into small windows to train denoising algorithms [72]."}, {"title": "IX. APPLICATIONS", "content": "UAS denoising is a necessary component for various underwater applications. This section presents some major roles of UAS denoising technologies in real-world applications.\n1. Maritime Navigation and Safety\nImproved denoising techniques help in clearer detection of obstacles, other vessels, and navigational aids, reducing the risk of collisions and grounding in poor visibility conditions [135], [136].\n2. Submarine Communications\nIn underwater environments, where radio waves cannot be effectively used, acoustic signals serve as the primary communication medium [137]. Denoising these signals ensures more reliable and clearer communications between submarines and surface vessels.\n3. Marine Life Monitoring\nAcoustic signals are used to monitor the presence, movement, and behavior of marine species. Effective denoising is essential to accurately identify species from their sounds, which is crucial for ecological studies and conservation efforts [138].\n4. Shoreline surveillance\nShoreline surveillance refers to the monitoring and observation activities conducted along coastlines to ensure security, safety, and environmental integrity. This practice involves the use of various technologies and strategies to detect, track, and respond to activities and natural phenomena that occur near the shore [25]."}, {"title": "X. OPEN QUESTIONS AND FUTURE DIRECTIONS", "content": "The UAS community has delved into advanced decomposition frameworks, thresholding techniques, and DL algorithms. Nevertheless, numerous unexplored avenues remain, warranting further extensive research and exploration.\n1 Signal decomposition is widely used to denoise the UAS, yet identifying the optimal decomposition level continues to pose a significant challenge. While the sensitivity analysis of decomposition levels across different algorithms has been explored, it remains largely cursory. Treating the decomposition level as a hyperparameter and applying hyperparameter optimization algorithms could be a promising strategy. However, this approach is often too time-consuming and impractical for underwater applications, which demand real-time processing capabilities.\n2 There is no consensus in the literature regarding the most effective signal decomposition algorithm for denoising the UAS. Benchmarking studies comparing different signal decomposition algorithms are notably absent. While some studies claim the superiority of specific algorithms based on outcomes from signal decomposition research, UAS present unique challenges that necessitate further specialized investigation.\n3 The literature employs different steps and parameters, such as normalization, sampling rate, and window length, to preprocess the UAS data before establishing the following denoising model. Differences in preprocessing lead to different conclusions and findings in terms of the performance of denoising and recognition models. A specific UAS denoising model may obtain outstanding performance on a small window and become much worse on long windows. Therefore, the standard framework to identify preprocessing schemes for any UAS dataset needs to be well-researched.\n4 Although researchers have explored various advanced DL architectures, underwater applications require extremely high computing speed. When deploying the technology in underwater scenarios, the denoising model must adapt to new contexts quickly. Therefore, gradient-based DL models may fail to satisfy these requirements. However, deep randomized neural networks are suitable candidates due to their strong non-linear feature extraction ability and fast training speed [139].\n5 Automated learning, encompassing the fine-tuning of hyperparameters and training of learning-based UAS denoising algorithms, is imperative. The varied applications of UAS denoising techniques necessitate an automated framework, enabling practitioners to seamlessly employ these methods across diverse applications. Regrettably, current research overlooks the critical need for and significance of automated learning. Manual selection of hyperparameters and training algorithms diminishes the flexibility and practicality of UAS denoising techniques. Therefore, developing a environment-agnostic automatic learning framework of the UAS denoising techniques is worthy to explore.\n6 Advanced ensemble learning techniques have demonstrated their efficacy in enhancing model robustness through the creation of a diverse array of base models [140]. In the realm of UAS-related tasks, the extraction of noise-resistant features and the development of robust models are imperative. However, the existing literature largely neglects the significance of an ensemble UAS denoising framework. Such a framework holds the potential to mitigate the weaknesses inherent in individual UAS denoising models, thereby enhancing overall denoising performance. Given the diversity and complexity of underwater environments, a single UAS denoising technique may struggle to achieve optimal performance across all scenarios. Nevertheless, through ensemble learning, various base models can collectively address different types of noisy signals, thus culminating in improved accuracy.\n7 Efficient exploration of the marine environment and accurate detection of underwater events necessitate the deployment of diverse data collection systems, including UUV swarms and acoustic sensor networks. Each individual UUV and sensor unit possesses the capability to gather acoustic signals from distinct spatial coordinates. However, the integration of these disparate UUV systems and the development of a denoising algorithm based on the amalgamated data remains an uncharted territory. The potential schemes for dynamically fusing these data sources and denoising the resulting signal hold significant promise and merit further exploration.\n8 Many UAS denoising algorithms operate within an offline framework, assuming all UAS data is available for model establishment. However, as UAS data is inherently sequential and underwater applications often occur in real-time scenarios, online processing is essential. The denoising step of UAS data typically precedes control or detection systems, which operate continuously in real-world applications. Thus, there's a need to extend decomposition-based and DL-based UAS denoising techniques to online variants. These online algorithms can incorporate online signal decomposition methods, real-time training algorithms for DL models, and online adaptation of DL architectures, among other considerations.\n9 While many UAS denoising algorithms rely on unsupervised reconstruction, a few pioneering studies have delved into the potential of self-supervised learning for UAS denoising. However, a plethora of advanced self-supervised learning techniques remain unexplored and under-investigated. Crafting appropriate pretext tasks is crucial for the efficacy of self-supervised learning algorithms, especially given the unique challenges posed by UAS data. Moreover, there is ample opportunity to design pretext tasks tailored to UAS characteristics. Furthermore, integrating self-supervised learning with existing decomposition-based denoising algorithms holds promise. The development of a self-supervised decomposition-based denoising scheme represents a particularly promising avenue for future research."}, {"title": "XI. CONCLUSION", "content": "Underwater acoustic signals (UAS) are the most commonly collected data in underwater environments and play a pivotal role in a variety of applications. However, the inherent complexity of these environments poses significant challenges for the transmission, recognition, feature extraction, and interpretation of UAS. As a result, denoising UAS is a critical technological step essential for various applications. This review paper provides an overview of the developments in UAS denoising, from theoretical underpinnings to practical applications. Denoising involves the removal of extraneous noise and the extraction of signal-dominated information, which is then utilized for tasks such as target recognition. Traditional methods typically rely on signal processing and wavelet thresholding algorithms for noise removal. The majority of UAS denoising solutions employ signal decomposition techniques, which facilitate the separation of the complex original UAS into multiple modes. Subsequently, specific denoising algorithms are applied to each mode to eliminate noise. Finally, all denoised modes are recombined to produce the cleaned UAS.\nRecently, the rapid advancement of deep learning (DL) algorithms has spurred the UAS community to develop sophisticated DL-based denoising methods. These algorithms are typically trained to reconstruct signal-dominated information and maximize the signal-to-noise ratio. Given that a DL model's loss function can comprise multiple terms, researchers have the ability to combine denoising and recognition objectives within a single loss function. Consequently, DL-based denoising is not only task-oriented but also highly flexible, adapting to specific application needs with greater efficacy."}]}