{"title": "A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges", "authors": ["Aditi Singh", "Akash Shetty", "Abul Ehtesham", "Saket Kumar", "Tala Talaei Khoei"], "abstract": "Text-to-SQL systems facilitate smooth interaction with databases by translating natural language queries into Structured Query Language (SQL), bridging the gap between non-technical users and complex database management systems. This survey provides a comprehensive overview of the evolution of AI-driven text-to-SQL systems, highlighting their foundational components, advancements in large language model (LLM) architectures, and the critical role of datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examine the applications of text-to-SQL in domains like healthcare, education, and finance, emphasizing their transformative potential for improving data accessibility. Additionally, we analyze persistent challenges, including domain generalization, query optimization, support for multi-turn conversational interactions, and the limited availability of datasets tailored for NoSQL databases and dynamic real-world scenarios. To address these challenges, we outline future research directions, such as extending text-to-SQL capabilities to support NoSQL databases, designing datasets for dynamic multi-turn interactions, and optimizing systems for real-world scalability and robustness. By surveying current advancements and identifying key gaps, this paper aims to guide the next generation of research and applications in LLM-based text-to-SQL systems.", "sections": [{"title": "I. INTRODUCTION", "content": "The task of translating natural language questions into Structured Query Language (SQL) statements, known as text-to-SQL, has garnered significant attention within the fields of natural language processing and database management. This capability democratizes data access and analysis, enabling users to interact with databases without requiring in-depth knowledge of query languages. The development of AI-driven text-to-SQL systems has been critical in achieving this goal. [1]\nEarly approaches to text-to-SQL relied heavily on rule-based systems and semantic parsing techniques. These methods, while foundational, often struggled with the diversity and complexity inherent in natural language queries. The advent of deep learning and neural network models marked a significant shift, introducing sequence-to-sequence architectures that improved the translation of natural language to SQL [2].\nThe integration of large pre-trained language models (PLMs) and large language models has further advanced the field [3], enhancing the understanding of natural language semantics and the generation of accurate SQL queries. Recent surveys have highlighted the impact of PLMs on text-to-SQL parsing, noting their ability to capture complex linguistic patterns and improve performance across benchmarks [4].\nDespite these advancements, challenges remain, particularly in handling complex and cross-domain queries. The development of large-scale, human-labeled datasets, such as Spider, has been instrumental in evaluating and advancing text-to-SQL systems. These datasets provide diverse and complex queries that test the robustness and adaptability of current models. [1].\nThis survey aims to provide a comprehensive overview of the evolution of text-to-SQL systems, emphasizing the integration of artificial intelligence methodologies. We explore foundational concepts, current benchmarks, datasets, and models, offering insights into the advancements and challenges in the field. By examining the trajectory of text-to-SQL research, we aim to highlight the progress made and identify areas for future exploration."}, {"title": "II. NEED FOR TEXT-TO-SQL", "content": "Text-to-SQL systems provide a specialized solution for translating natural language queries into precise SQL statements, allowing users to interact directly with databases without requiring expertise in SQL syntax. While general-purpose AI models like ChatGPT can assist in generating SQL queries, they often lack the domain-specific optimizations and accuracy that dedicated text-to-SQL systems are designed to offer. These systems are tailored to manage complex database schemas and ensure the generation of syntactically correct and efficient SQL queries, significantly enhancing data retrieval and analysis processes. By focusing exclusively on the task of converting natural language to SQL, text-to-SQL systems deliver more reliable and contextually appropriate results. This makes them invaluable in scenarios where precise data manipulation is critical, such as in healthcare, finance, and business intelligence. Furthermore, the development of such systems incorporates advancements in natural language understanding, database schema modeling, and semantic parsing, contributing to their robustness and usability across diverse application domains."}, {"title": "III. FOUNDATIONS OF TEXT-TO-SQL", "content": "Text-to-SQL systems are designed to translate natural language queries into Structured Query Language (SQL) statements, enabling users to interact with databases without requiring expertise in SQL syntax. The foundational components of these systems as shown in Figure 2 include:\n1) Natural Language Understanding (NLU): This involves parsing and interpreting the user's query to comprehend its intent and semantics. Techniques such as tokenization, part-of-speech tagging, and syntactic parsing are employed to analyze the structure and meaning of the input.\n2) Schema Linking: This process connects elements of the natural language query to the corresponding components in the database schema, such as tables and columns. Effective schema linking is crucial for accurately mapping user intents to database structures.\n3) Semantic Parsing: This step involves converting the natural language query into an intermediate logical form that represents its meaning. Semantic parsing serves as a bridge between the user's intent and the formal SQL query.\n4) SQL Generation: The final component translates the intermediate logical form into a syntactically correct and executable SQL statement. This requires understanding SQL syntax and ensuring that the generated query aligns with the database schema.\nAdvancements in artificial intelligence, particularly in deep learning and natural language processing, have significantly enhanced the performance of text-to-SQL systems. For instance, the integration of large pre-trained language models has improved the systems' ability to understand complex queries and generate accurate SQL statements [4].\nDespite these advancements, challenges remain, especially in handling complex and cross-domain queries. Ongoing research focuses on improving the robustness and adaptability of text-to-SQL systems to address these challenges [2]."}, {"title": "IV. CURRENT BENCHMARKS, MODELS, AND DATASETS", "content": "Evaluating text-to-SQL systems necessitates robust benchmarks and datasets. Notable among these are:\nA. Benchmarks Datasets\n\u2022 Spider: A large-scale, complex, and cross-domain text-to-SQL dataset designed to evaluate the generalization capabilities of models across different databases and query structures [1].\n\u2022 Spider 2.0: An advanced evaluation framework featuring 632 real-world text-to-SQL workflow problems from enterprise databases. These databases, often hosted on platforms like BigQuery and Snowflake, include over 1,000 columns. Spider 2.0 challenges models with complex tasks requiring interaction with SQL workflows, reasoning over extensive contexts, and generating multi-query SQL operations exceeding 100 lines, making it essential for assessing language models in enterprise scenarios [6].\n\u2022 WikiSQL: Comprising over 80,000 natural language questions and corresponding SQL queries, this dataset is derived from Wikipedia tables and focuses on simple SQL queries [7].\n\u2022 BIRD (BIg Bench for Large-Scale Database Grounded Text-to-SQL Evaluation): A comprehensive dataset containing 12,751 question-SQL pairs across 95 databases, totaling 33.4 GB. It spans over 37 professional domains, including blockchain, hockey, healthcare, and education, emphasizing challenges such as handling extensive database contents and integrating external knowledge [8].\n\u2022 CSpider: A Chinese large-scale, complex, cross-domain text-to-SQL dataset, translated from the original Spider dataset. It comprises 10,181 questions and 5,693 unique SQL queries across 200 databases, aiming to facilitate the development of natural language interfaces for Chinese databases [9].\n\u2022 UNITE: A unified benchmark composed of 18 publicly available text-to-SQL datasets, encompassing natural language questions from more than 12 domains, SQL queries from over 3,900 patterns, and 29,000 databases. It introduces approximately 120,000 additional examples and a threefold increase in SQL patterns compared to the Spider benchmark [10].\n\u2022 CoSQL: The CoSQL dataset is a dialogue-based benchmark designed for multi-turn text-to-SQL interactions. It comprises over 30,000 turns and more than 10,000 annotated SQL queries, collected from 3,000 dialogues across 200 complex databases spanning 138 domains. Unlike static text-to-SQL datasets, CoSQL emphasizes natural conversational interactions, simulating real-world scenarios where users refine, clarify, and expand their queries. This makes CoSQL a critical resource for advancing dialogue-based database interfaces. [11].\nB. Models\nThe progression of text-to-SQL models has been marked by several key developments (Table I):\n\u2022 Seq2SQL: An early model that employs a sequence-to-sequence approach with reinforcement learning to generate SQL queries from natural language [7].\n\u2022 SQLNet: Introduces a sketch-based approach to predict the SQL query structure before filling in specific details, improving accuracy and efficiency [12].\n\u2022 TypeSQL: Enhances SQLNet by incorporating type information, enabling the model to handle more complex queries involving different data types [13].\n\u2022 IRNet: Utilizes a graph-based encoder to capture the relationships between database schema elements and natural language questions, leading to improved performance on complex queries [14].\n\u2022 T5-3B: A transformer-based model fine-tuned on text-to-SQL tasks, demonstrating significant improvements in generating accurate SQL queries [15].\n\u2022 MedT5SQL: Tailored for healthcare, MedTS generates SQL queries for patient records using a BERT-based encoder and LSTM decoder trained on the MIMICSQL dataset. [16].\n\u2022 EDU-T5: Optimized for educational data, EDU-T5 translates academic queries into SQL, using a T5-based model with cross-attention mechanisms. [15].\n\u2022 SQLova: Built on WikiSQL, SQLova generates high-precision general-purpose SQL queries by combining a BERT-based encoder and column attention. [17].\n\u2022 RAT-SQL: Trained on WikiSQL and Spider, RAT-SQL uses a relation-aware transformer with schema encoding to manage complex multi-table queries. [18].\n\u2022 X-SQL: Enhances schema representation by integrating contextual outputs from BERT-style models, achieving state-of-the-art performance on the WikiSQL dataset. [19].\n\u2022 EHRSQL: A benchmark designed for generating SQL queries from electronic health records, emphasizing domain-specific challenges and evaluation [20].\n\u2022 RASAT: A relation-aware self-attention transformer model optimized for complex queries and integrated with dialogue-based datasets like CoSQL [21].\n\u2022 PICARD: Parsing incrementally for constrained auto-regressive decoding, PICARD improves the performance of language models like T5-3B on dialogue-based and multi-turn SQL generation tasks [22]."}, {"title": "C. Evaluation Metrics", "content": "The performance of Text-to-SQL systems is assessed using several evaluation metrics that capture different aspects of query generation quality and system usability:\n\u2022 Exact Set Match Accuracy: Measures the proportion of SQL queries that match the ground truth exactly, ensuring structural correctness [23].\n\u2022 Execution Accuracy: Evaluates the system's ability to generate executable queries by checking if the generated query returns the correct results when executed on the database [23].\n\u2022 Question Match Accuracy: Assesses how well the generated query corresponds to the natural language question [23].\n\u2022 Interaction Match Accuracy: Specifically for multi-turn datasets, measures the system's ability to maintain context and generate coherent queries across dialogue turns [23].\nThese metrics provide insights into the accuracy, robustness, and practical usability of Text-to-SQL systems across different scenarios."}, {"title": "V. APPLICATION AND USE CASES", "content": "Text-to-SQL systems serve as a pivotal tool across diverse industries, enabling natural language interaction with databases to facilitate data retrieval, analysis, and decision-making. These systems simplify complex data queries, empowering non-technical users to unlock valuable insights from structured data. Table II summarizes the practical applications, challenges, and benefits of Text-to-SQL systems across key domains. Below, we detail specific applications in healthcare, education, finance, and business intelligence, showcasing the transformative potential of these systems in addressing industry-specific challenges.\nA. Healthcare and Medical Records - Data Management\n\u2022 Clinical Decision Support: Text-to-SQL systems assist healthcare professionals in querying patient records, retrieving relevant medical histories, or aggregating patient data for epidemiological studies.\n\u2022 Patient Record Management: Allows healthcare providers to retrieve complex patient information, such as identifying all patients with certain conditions or recent test results, enabling faster access to critical data.\n\u2022 Medical Research: Facilitates large-scale data retrieval from medical databases for research on disease patterns, drug efficacy, or population health studies.\nB. Educational Tool\n\u2022 Adaptive Learning Systems: Text-to-SQL can be integrated into educational platforms to create adaptive learning tools that personalize content based on student data stored in databases.\n\u2022 Academic Analytics: Enables querying of student performance data, helping in curriculum assessment, identifying at-risk students, and evaluating the impact of educational interventions.\n\u2022 Student Self-Service: Allows students to query databases for information on course requirements, academic records, or library resources without needing technical expertise.\nC. Finance and Banking\n\u2022 Financial Reporting and Analytics: Enables financial analysts and executives to interact with databases for generating real-time financial reports, trend analyses, and risk assessments.\n\u2022 Customer Service and Query Resolution: Empowers customer service agents to query customer data efficiently, providing personalized and accurate information in real-time.\n\u2022 Fraud Detection and Prevention: Allows for rapid query formulation to monitor transactions for patterns indicative of fraud, ensuring timely responses to suspicious activities.\nD. Business Intelligence and Analytics\n\u2022 Market Analysis and Trend Detection: Text-to-SQL streamlines data retrieval for analyzing customer behavior, tracking sales performance, and identifying emerging market trends.\n\u2022 Inventory and Supply Chain Management: Assists businesses in monitoring inventory levels, supply chain metrics, and order statuses to improve operational efficiency.\n\u2022 Employee Productivity and HR Analytics: Enables querying workforce management data, allowing companies to monitor employee productivity, analyze turnover rates, or assess training needs."}, {"title": "VI. CHALLENGES AND FUTURE DIRECTIONS", "content": "Despite significant advancements, several challenges remain in the development of text-to-SQL systems. Future research aims to address these challenges through the following directions.\nA. Industry-Specific Challenges and Solutions\nHealthcare:\n\u2022 Handling highly sensitive patient data requires robust privacy-preserving techniques in text-to-SQL systems.\n\u2022 Queries often require contextual medical knowledge not present in the database schema.\nFinance:\n\u2022 The prevalence of NoSQL databases adds complexity to adapting text-to-SQL systems.\n\u2022 Ambiguities in financial terminologies, such as risk-related queries, require domain-specific language models.\nEducation:\n\u2022 Diverse grading structures and course formats lead to variability in database schema, complicating schema linking.\n\u2022 Lack of standardized datasets reflecting academic systems globally limits model generalization.\nB. Generalization Across Domains\n\u2022 Challenge: Many text-to-SQL models struggle with domain adaptation, particularly when faced with unfamiliar database schemas or industries.\n\u2022 Future Direction: Developing universal or multi-domain models that can interpret and generate accurate SQL for varied domains without additional retraining or extensive customization."}, {"title": "C. Handling Ambiguity in Natural Language", "content": "\u2022 Challenge: Natural language queries can be ambiguous or lack specific details required for accurate SQL generation (e.g., missing parameters, vague terms).\n\u2022 Future Direction: Implementing advanced disambiguation techniques or interactive clarification processes, where the model seeks clarification for ambiguous inputs to ensure query accuracy."}, {"title": "D. Incorporating External Knowledge", "content": "\u2022 Challenge: Domain-specific queries often require contextual knowledge not present in the database schema, such as industry-specific terms or common data patterns.\n\u2022 Future Direction: Integrating external knowledge bases or ontologies to enhance the model's contextual understanding and allow it to interpret queries with a broader scope."}, {"title": "E. Optimizing SQL Efficiency", "content": "\u2022 Challenge: While accuracy is essential, the efficiency of SQL queries is also important, especially for large databases where complex queries can be resource-intensive.\n\u2022 Future Direction: Researching optimization techniques for SQL generation, such as index-aware querying or using machine learning to predict and avoid performance bottlenecks in query structures."}, {"title": "F. Human-in-the-Loop Systems", "content": "\u2022 Challenge: Fully automated systems may not meet the nuanced requirements of real-world applications.\n\u2022 Future Direction: Developing interactive text-to-SQL systems where users can validate or edit SQL outputs, providing an extra layer of accuracy and flexibility for complex queries."}, {"title": "G. Improved Interpretability and Debugging", "content": "\u2022 Challenge: Debugging and interpreting complex SQL statements generated by AI models can be challenging, particularly in mission-critical applications.\n\u2022 Future Direction: Focusing on interpretability in model design, enabling end-users to understand how the generated SQL queries relate to the original natural language inputs, potentially through visual representations or explanations."}, {"title": "H. Extending Text-to-SQL to NoSQL Databases", "content": "NoSQL databases, such as MongoDB, Cassandra, and Redis, are crucial for handling unstructured, semi-structured, or rapidly changing data. Their flexible schema and distributed architecture make them essential for industries like finance, healthcare, e-commerce, and social networks, where scalability and real-time analytics are critical.\nDespite advancements in Text-to-SQL systems for relational databases, there is a lack of models and datasets designed to query NoSQL systems, as shown in Table III.\n\u2022 Challenge: Existing benchmarks and models focus on SQL's structured schemas, while NoSQL databases require support for dynamic, document-based schemas.\n\u2022 Potential Solution: Developing datasets tailored to NoSQL with JSON-like structures and models leveraging LLMs for unstructured data analytics [24]. This approach could bridge the gap between structured and unstructured data paradigms."}, {"title": "VII. CONCLUSION", "content": "This paper concludes by highlighting the transformative potential of text-to-SQL systems in bridging the gap between natural language queries and database interactions, empowering non-technical users across various domains. While significant advancements have been achieved through Al-driven models and extensive benchmarks, critical challenges such as handling domain-specific complexities, extending support to NoSQL databases, and improving query efficiency remain. The survey underscores the need for future research to develop specialized datasets, enhance model generalization, and integrate contextual knowledge to address these gaps, thereby expanding the scope and utility of text-to-database technologies."}]}