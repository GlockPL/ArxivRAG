{"title": "Neural Algorithmic Reasoning with Multiple Correct Solutions", "authors": ["Zeno Kujawa", "John Poole", "Danilo Numeroso", "Dobrik Georgiev", "Pietro Li\u00f2"], "abstract": "Neural Algorithmic Reasoning (NAR) aims to optimize classical algorithms. However, canonical implementations of NAR train neural networks to return only a single solution, even when there are multiple correct solutions to a problem, such as single-source shortest paths. For some applications, it is desirable to recover more than one correct solution. To that end, we give the first method for NAR with multiple solutions. We demonstrate our method on two classical algorithms: Bellman-Ford (BF) and Depth-First Search (DFS), favouring deeper insight into two algorithms over a broader survey of algorithms. This method involves generating appropriate training data as well as sampling and validating solutions from model output. Each step of our method, which can serve as a framework for neural algorithmic reasoning beyond the tasks presented in this paper, might be of independent interest to the field and our results represent the first attempt at this task in the NAR literature.", "sections": [{"title": "1 Introduction", "content": "Classical algorithms such as Merge Sort guarantee correctness and generalize perfectly on abstract inputs [1]. Unfortunately, real problems are rarely abstract inputs. Consider pathfinding: to give traffic directions via a shortest paths algorithm, one must compress physical distance and multi-dimensional congestion data for each street into edge labels, thereby losing information. Bad edge labels mean bad directions, even despite a good algorithm. Neural Networks (NNs) avoid this problem by directly operating on high-dimensional data. Instead of compressing distance and congestion to a single path-length edge label, an NN can operate directly on distance and congestion data. The chief hurdle to NN performance is failure to generalize: common architectures are fragile to changes in input size and structure \u2014 exactly where algorithms succeed [1]. It is thus natural to wonder whether an NN might learn to generalize from an algorithm. To that end, Neural Algorithmic Reasoning trains NNs to mimic the running of classical algorithms [1]. A benefit of this approach is staying high-dimensional: no information is lost when projecting high-dimensional real data into a single abstract output for a classical algorithm [1]. Thus far, NNs have been trained to mimic algorithms which recover one solution from the space of possible correct solutions [2-8]. Ordinarily, an NN trained to perform DFS produces an array, which one can view as a distribution containing the probabilities of different solutions, from which the likeliest solution is returned as the model output. We adapt the model input to reflect multiple correct solutions and present methods of retrieving multiple solutions from the model output distribution. Using only one solution in NAR may be vulnerable to local minima in the model training. By diversifying the space of solutions returned by NAR, we may decrease the"}, {"title": "1.1 Contributions", "content": "We give the first analysis of Neural Algorithmic Reasoners which return more than one solution. For training examples, we create distributions of solutions from multiple runs of classical algorithms with randomized tie-breaking. We train NNs to predict the generated distribution of solutions; and we leverage randomness in algorithm-specific ways to extract distinct solutions from the NN-predicted distributions. We also discuss methods of evaluating the solutions obtained through our methods. Thus we offer three contributions that might each be of independent interest: (1) a method for training a neural network on a distribution of correct solutions, (2) a method for extracting multiple solutions from the distribution the NN predicts, (3) an evaluation of the diversity and correctness of solutions our method yields. Together, these three contributions can serve as a framework for further research into Neural Algorithmic Reasoning with multiple solutions for each problem instance."}, {"title": "2 Methodology", "content": "To produce multiple solutions for a single graph, we train an NN to predict a distribution of solutions for each individual graph. Ordinarily, the CLRS benchmark [2] generates training data by running classical algorithms with deterministic tie-breaking. For example, the input graph in Figure 1 has two valid orders of depth-first traversal, but classical DFS will only return one based on which edge it explores first. To create our training examples, we run a classical algorithm (e.g. DFS) multiple times with randomized tiebreaking, and average the outputs (e.g. individual DFS trees) into a distribution of solutions (refer to Appendices A.1.1 and A.2.1). As we want the NN to predict a distribution, we train to minimize a distribution divergence (Kullback-Leibler: KL) [9]. Our final goal is to recover multiple solutions for an input graph (solutions being individual DFS trees or BF paths); so, we develop stochastic, algorithm-specific sampling methods. Stochasticity of sampling methods means samples are likely to have multiple different solutions. For DFS, we sample the immediate parents of vertices until we reach the root vertex (which can be seen as executing DFS in reverse on a graph); our two DFS extractors, which we call Upwards and AltUpwards, differ in the manner in which they discard potential solutions (Appendix A.1.2). For BF, Beam samples a number of parents for non-source vertices according to parent-probabilities and chooses the lowest cost path arising (Appendix A.2.2). Also for BF, Greedy samples parents for each non-source vertex and chooses the parent with the lowest-cost outgoing edge for each non-source vertex (Appendix A.2.2)."}, {"title": "3 Experiments", "content": "Addressing the lack of evaluation methods for NAR with multiple solutions, we propose metrics to evaluate the validity and diversity of solutions. For a single graph, our NN predicts one solution distribution. From this distribution, we sample 5 solutions and count the number of distinct and valid solutions. For Bellman-Ford, a solution is valid if and only if it gives all shortest paths from the source vertex. For DFS, we say a solution is valid if and only if it does not contradict some necessary conditions (sufficient conditions not being known in graph theory). We investigate the coverage of the solution space by our method in Appendix C.\nWe run our experiments using the CLRS Benchmark [2], which handles data generation, model training, and model evaluation in a unified way. CLRS generates graphs of size 4, 7, 11, 13, and 16 to train our models on. In keeping with established methodology [2, 3], we test our models on graphs within and outside the range of our training sizes. For within-sample testing, we choose n = |V(G)| = 5, as solutions on these graphs are easily manually verifiable and fast to compute at scale. For our out-of-distribution evaluation, we use the default CLRS-30 benchmark testing size n = 64. The models are trained with default CLRS-30 benchmark model parameters [2]."}, {"title": "3.1 Results for Bellman-Ford", "content": "On small graphs, (n = 5), sampling methods extract a single correct minimum-cost path with perfect accuracy from both the NN-predicted distributions. We also extract solutions from the empirical distributions in order to validate our sampling methods, as we would expect suitable sampling methods to return sensible solutions from distributions that are close to optimal. Similar results for empirical and predicted distributions suggest the NN predicts a good distribution for n = 5 graphs. The lack of variety in solutions, with sampling methods always extracting the same solution, is expected for small graphs as there is likely only one minimum-cost path. Diversity increases in the case of n = 64, where for each method, sampling a predecessor array \u03c0 five times gives a new solution in nearly all cases.\nFor larger graphs, our sampling methods successfully yield correct minimum-cost paths through the graphs on the empirical distributions (denoted as P), thus validating our sampling methods. However, the distributions of solutions predicted by our models, which we denote P, are not sufficiently accurate to consistently have correct solutions sampled from them. These results permit us to conclude that our models perform very well on small graphs, but have difficulty scaling outside of their training distribution. While comparing our approach with the deterministic algorithmic frameworks of Veli\u010dkovi\u0107 et al. [2] and Ibarz et al. [3] is disadvantageous to our method due to its broader scope, it is worth noting that our results are markedly worse than those in [2, 3]. However, our results are encouraging for future work, as we have demonstrated the feasibility of training neural networks to emulate a version of Bellman-Ford that is more powerful than its deterministic variant."}, {"title": "3.2 Results for Depth-First Search", "content": "In most cases, our sampling methods perform worse than simply using the most likely predecessor for all v \u2208 V(G), but have the advantage of recovering multiple solutions. Table 2 shows that AltUpwards sampling outperforms Upwards sampling, even being within the margin of error of Argmax for P in some experiments. On smaller graphs, AltUpwards performs well on the model distributions, returning a valid DFS-tree around half of the time. DFS is known to be difficult for neural algorithmic reasoning, with neural algorithmic reasoners giving correct (single) solutions only around a third of the time [2, 3]. This contextualises our results and demonstrates the promise of our approach compared to both classical algorithms and previous work in neural algorithmic reasoning.\nIn terms of the ability of recovering multiple solutions,  shows that for both considered graph sizes, many unique solutions are obtained, with better accuracy scores for P than for P, particularly for large graphs, where accuracy is low in general. In fact, for the out-of-distribution testing, our NAR method for DFS performs significantly worse than the current state of the art [3]. Because our method is non-deterministic, this should not be taken as a conclusively negative result: we would expect our method for returning multiple solutions to perform worse than the results for models giving single solutions in [3], as predicting multiple solutions is a more difficult task with more noise. Furthermore, AltUpwards is generally able to recover more unique and more valid solutions than Upwards, but at a high computational cost.Table 1 shows that for large graphs, both sampling methods yield many unique solutions, but these solutions are hardly ever valid for large graphs."}, {"title": "Conclusion", "content": "We outline a two-part approach to Neural Algorithmic Reasoning with multiple solutions: we first train models to predict distributions of solutions and second stochastically extract solutions from those distributions. We demonstrate that accurate stochastic extraction of multiple solutions from distributions of solutions is feasible, given a good distribution, but also that NNs do not easily learn to predict good distributions, which means our methods will improve with advances in NN training in this field. We attribute this difficulty to a number of factors. First, Neural Algorithmic Reasoning is difficult: previous work has shown that NNs only learn up to 30% accuracy on deterministic DFS without hint pointer reversal [4]. Second, training a model to fit a distribution of solutions does not directly optimize for correct solutions. Solutions must still be extracted from the distribution via stochastic methods, to which the loss metric does not extend (Figure 7). Improving methods for extracting solutions remains an important algorithmic task. Still, with the promise of sampling multiple solutions from a distribution demonstrated, we believe our modifications of the CLRS benchmark act as proof-of-concept for further work. While typically straightforward to apply our method to an algorithm, a downside is it requires tailored work per algorithm (especially in designing sampling methods). A more general method not requiring algorithm-specific work would be ideal, if difficult to achieve. Having multiple solutions adds essential flexibility to applications of NAR such as cyberphysical systems and might aid in explaining NAR models."}, {"title": "A Methodology", "content": "We discuss our methods for randomising the deterministic (canonical) versions of Depth-First Search and the Bellman-Ford algorithm in order to use the resulting distributions over solutions as inputs to the CLRS-30 baseline. We also present our methods of extracting candidate solutions from model outputs and give approaches towards verifying them as correct solutions of the respective deterministic algorithms our sampling methods are aiming to emulate."}, {"title": "A.1 DFS", "content": "We consider a generalization of the deterministic DFS setting implemented in the CLRS benchmark [2]. In our setting, edge-exploration is random: from a given vertex, any of the outgoing edges may be explored first. Still, we require that once DFS backtracks at the root of a connected component, it restarts its search at the next vertex in a linear ordering of the vertices. We think the generalization is natural, modelling a setting where one conducts DFS according to a chosen sequence of starting points, without assumptions about which edges to pursue first."}, {"title": "A.1.1 Randomness in training", "content": "We generate a ground-truth parent distribution P for each graph in the test set, and train the model to minimize the KL-divergence between its predicted distribution P and P. We obtain P by combining 20 solutions generated by a DFS algorithm that randomly tiebreaks between outgoing edges."}, {"title": "A.1.2 Randomness in sampling", "content": "We compare 4 methods for extracting valid DFS solutions from a parent distribution, P. First, argmax sampling assumes the parent of each node x to be the node u such that\n$u = \\underset{v\\in V(G)}{max} P_{u,v}$ (1)\nwhere $P_{u,v}$ is the probability of an edge (v, u) according to P. Argmax sampling is deterministic and can return only one solution. We include it in our discussion as a good baseline which corresponds to the internal mechanism of the CLRS-30 benchmark [2]. To extract multiple solutions for DFS, we introduce stochasticity according to Upwards Sampling, which is described in Algorithm 2.\nIn Upwards Sampling (Algorithm 2), we first determine how likely each node is to be a parent node of any other node. We do so by summing the probabilities of each vertex $u \\in V$ to be the parent of each vertex $v \\in V$ and then sorting this list in ascending order, as done in Line 4. In each iteration of the outer loop (Line 5), we begin by taking the \"leafiest\" vertex (the vertex with the lowest probability of being a parent) and sampling its parent according to $P_{leaf}$ (Line 7). After having done so, we remove the leaf from future consideration as a leaf and as a parent (as a leaf by definition will not be the parent of another node). Next, we sample the parent of $\u03c0[leaf]$ until we encounter a node that already has a parent (Line 5). This ensures we do not overwrite previously sampled parents. We have chosen this sampling method as it works similarly to DFS while respecting the inherent stochasticity resulting from returning P rather than one unambigous solution, as has been done in [2] and [3]."}, {"title": "A.1.3 Checking Validity", "content": "Reconstructing multiple solutions from a matrix of probabilities introduces the possibility of error. We test the solutions we extract from our models against the following necessary conditions for correctness.\nWe say purported parent tree $\u03c0 := (v_0, v_1, ..., v_{|V|-1})$ is DFS-valid for a graph $G := (V, E)$ with linearly ordered vertices V only if the following 5 conditions hold:\nThe start node is correct:\nThe least element of the linear ordering on Vertices is its own parent: $\u03c0[0] := v_0 = V[0]$.\nThe edges are correct:\nAll edges suggested by the parent tree are in fact edges in the graph:\n$\u2200t \\in V, t == \u03c0[t] \\lor E(\u03c0[t], t)$."}, {"title": "A.2 Bellman-Ford", "content": "The Bellman-Ford algorithm computes the minimum-cost paths from a single source vertex s to each other vertex v in the graph. As is the case for DFS, the solutions are represented as a predecessor array \u03c0."}, {"title": "A.2.1 Randomness in training", "content": "Similarly to randomising DFS, our implementation of a randomised Bellman-Ford algorithm relies on randomising the order in which paths are considered by shuffling the lists of nodes. Figure 6 illustrates a situation in which multiple valid Bellman-Ford predecessor arrays are possible. However, the final output of the canonical Bellman-Ford algorithm will only be influenced by such a randomisation procedure if there are multiple minimal-weight paths from the source node s to at least one v \u2208 V\\{s}. As the CLRS-30 benchmark samples Erd\u0151s-R\u00e9nyi graphs with real-valued edge weights, the probability of two paths (s, v) for any $v \\in V\\{s\\}$ having the same cost is vanishingly low. To this end, we use a smaller set of possible weights such that for each weight $W_{ij} \\in \\{1,2,3\\}$, which we normalise for training purposes. As for DFS, we obtain a distribution of parent nodes by re-running the algorithm 20 times and computing the frequency of each parent for each node."}, {"title": "A.2.2 Randomness in sampling", "content": "We use an algorithm we call BF Beamsearch to sample predecessor arrays representing the minimum-cost (s, v)-paths for each $v \\in V(G)$. This algorithm closely resembles standard Beam-"}, {"title": "A.2.3 Checking Validity", "content": "In contrast to DFS, the task of deciding whether a predecessor array sampled from a model output distribution P is a valid output of running the Bellman-Ford algorithm is straightforward. To this end, we implement a simple algorithm called check valid BF path, which is given in Algorithm 3."}, {"title": "B Using different numbers of algorithm re-runs", "content": "When creating our training data by generating distributions over parents for DFS and Bellman-Ford, we need to consider how often we run the randomised versions of the deterministic algorithms on a graph in order to obtain a good distribution over solutions. To this end, we consider the graph sizes n\u2208 {5,..., 64} and generate 100 graphs for each size and run an algorithm (DFS or BF) 20, 50, and 100 times for each graph. For each graph, we then consider the KL-Divergence between each pair of distributions generated by a different number of algorithm re-runs (we compare the distribution generated from 20 runs to the distribution generated from 50 runs and to the one generated from 100 runs, et cetera). We plot the mean KL-Divergence along with its standard deviation for each pairwise comparison between re-run numbers for all considered sizes. In Figure 7, we see that while there are differences between the distributions generated from a varying number of algorithm re-runs, the distribution differences do not change markedly when going from 20 to 100 versus from 50 to 100 re-runs. Therefore, by increasing the number of re-runs, it appears that we do not gain enough information to justify the added computational cost of an increased re-run number. Therefore, we settle on 20 as a reasonable value for the number of algorithm re-runs."}, {"title": "C Validating the model output distributions", "content": "Going beyond our analysis of the validity of solutions obtained from the method presented in this paper, we investigate the coverage of the space of all solutions (i.e. the space of possible solutions we can obtain from executing an algorithm on a given graph G) of our methods. Using DFS as an example, we compare the average number of solutions when using DFS on graphs of a given size to the average number of unique and valid solutions when using our sampling method on the outputs of our model on the test data generated from those same graphs. This affords insight into the proportion of the space of possible solutions our method is capable of covering, which is particularly relevant to applications of Neural Algorithmic Reasoning in which using many different solutions is important, such as in cyberphysical systems."}, {"title": "C.1 Validating model output distributions for Bellman-Ford", "content": "Figure 8a shows that our sampling methods simply find the one valid solutions that exists for graphs of size 5 in all cases, which validates both our model and the sampling methods. In Figure 8b, we can see that even for out-of-distribution graphs, the model output distributions are good enough for our sampling methods to return a high diversity of valid solutions, even within the margin error of straightforwardly applying BF to the input graph. This coverage of the solution space is very encouraging for further research into NAR with multiple solutions, as it shows the potential advantage of using NAR to find all possible solutions, which is relevant to many applications, as discussed in the body of the paper."}, {"title": "C.2 Validating model output distributions for DFS", "content": "Figure 11a shows the marked advantage of AltUpwards over Upwards, as AltUpwards finds as many solutions as DFS on small graphs, where Upwards struggles to return any diversity of solutions. However, we can see the difficulty of emulating DFS using NAR on large graphs in Figure 11b, where the diversity of valid solutions remains small over many samples from the model output distributions."}]}