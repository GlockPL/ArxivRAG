{"title": "Enhancing kelp forest detection in remote sensing images using crowdsourced labels with Mixed Vision Transformers and ConvNeXt segmentation models", "authors": ["Ioannis Nasios"], "abstract": "Kelp forests, as foundation species, are vital to marine ecosystems, providing essential food and habitat for numerous organisms. This study explores the integration of crowdsourced labels with advanced artificial intelligence models to develop a fast and accurate kelp canopy detection pipeline using Landsat images. Building on the success of a machine learning competition, where this approach ranked third and performed consistently well on both local validation and public and private leaderboards, the research highlights the effectiveness of combining Mixed Vision Transformers (MIT) with ConvNeXt models. Training these models on various image sizes significantly enhanced the accuracy of the ensemble results. U-Net emerged as the best segmentation architecture, with UpperNet also contributing to the final ensemble. Key Landsat bands, such as Short Wave InfraRed (SWIR1) and Near-InfraRed (NIR), were crucial while altitude data was used in postprocessing to eliminate false positives on land. The methodology achieved a high detection rate, accurately identifying about three out of four pixels containing kelp canopy while keeping false positives low. Despite the medium resolution of Landsat satellites, their extensive historical coverage makes them effective for studying kelp forests. This work also underscores the potential of combining machine learning models with crowdsourced data for effective and scalable environmental monitoring.", "sections": [{"title": "1. Introduction", "content": "Kelp forests are highly productive components of cold water that are found in rocky marine coastlines globally (roughly in the 25% of the world's coastlines). These are physiologically constrained by light at high latitudes and by nutrients and warm temperatures at low latitudes. Within mid latitude belts, well developed kelp forests are most threatened by herbivores, usually from sea urchins. Overfishing and extirpation of highly valued predators often triggered herbivore population increases, leading to widespread kelp deforestation (Steneck et al. 2002). As it was not clear whether it was nutrient availability or grazers (sea urchins) that had the most influence over kelp forest health, size and longevity, after using Landsat imagery to look at long-term trends, and comparing those trends to known differences between Central and Southern California waters, Cavanaugh et al. (2011) found that it was a third force affecting kelp dynamics, the wave disturbance. Strong waves generated by storms uproot the kelp from their holdfasts and can devastate the forests far more than any grazer. Furthermore, climate-driven increases in storm frequency simplify kelp forest food webs as species go locally extinct (Byrnes et al. 2011) while climate change impacts on kelp forests for a variety of reasons has risen sharply (Smale 2020). Kelp is a foundation species, as it provides food for diverse types of herbivores from tiny shrimps to ravenous sea urchins to grazing fish. Giant kelp particularly is extraordinary as it has one of the widest global distributions and is one of the easiest to see from space even using medium resolution satellites as Landsat. Over the last years, many have used satellite data to study kelp forests distribution and characteristics. To tease apart signals due to anthropogenic effect from natural variability, a long-term analysis trends is critical. Bell et al. (2020) used three decades of Landsat data to study the variability in California's giant kelp forests, while Filbee-Dexter et al. (2019) studied their diversity, resilience and future.\nGiant kelp forests are among Earth's most productive habitats, and their great diversity of plant and animal species supports many fisheries around the world. They are the world's largest marine plants and regularly grow up to 35 meters tall. They live for seven years at most, and often they disappear before that because of winter storms or over-grazing by other species. Given the right balance of conditions, giant kelp can grow as much as 50 centimeters per day, and this robust growth makes it possible for kelp fronds to be commercially harvested. Today, only a few thousand tons of giant kelp are harvested each year, some by hand and some by mechanical harvesters. The kelp can be trimmed no lower than 4 feet below the water surface for harvesting to be sustainable. Studies have shown that negative affects are negligible, although some fish populations are temporarily displaced, (Rocchio 2014).\nAs kelp forests comprise one of the most important earth's ecosystems, mapping and monitoring them is essential. Several methods have been developed over the last years as earth observation tools have been improved and many are freely available. Mora-Soto et al. (2020) have proposed a method for high resolution kelp mapping with sentinel-2 imagery using computational filters-indexes. Also Gendall et al. (2023) proposed a multi-satellite mapping framework that leverage the monitoring of floating kelp forest ecosystems using medium-resolution imagery from the 1970s onwards, and more recently, using high-resolution imagery from the early 2000s onwards. Satellite imagery enables the mapping of existing and historical giant kelp populations in understudied regions, but automating the detection of giant kelp using satellite imagery requires approaches that are robust to the optical complexity of the shallow, nearshore environment. Houskeeper et al. (2022) studied the automated satellite remote sensing of giant kelp at the Falkland islands which is also the study area of current research.\nVarious segmentation models, provided in python libraries, are built upon the pytorch framework. Among the most popular is the segmentation_models_pytorch (SMP) (Iakubovskii 2019) which is also very easy to use. SMP provides easy access to many encoder models and also easy access to the timm encoder models (Wightman 2019). Furthermore, SMP has implemented some famous segmentation architectures which can be combined with the provided encoders. Transformer models first developed for Natural Language Processing (NLP) tasks but over the last years are widely used in computer vision tasks as well. The UpperNet segmentation architecture which is also used in our here, is included in the transformers library (Wolf et al. 2020) along with"}, {"title": "2. Methodology", "content": "Current research is based on a machine learning competition in which the author participated and exploited. The competition Kelp Wanted: Segmenting Kelp Forests was a semantic segmentation competition with Landsat satellite data, aiming in mapping kelp forests areas. The competition was sponsored by Mathworks and included partners as the Byrnes Lab of UMass Boston and the Woods Hole Oceanographic Institution which also provided the raw data. Desideratum was a machine learning model that can be used around the planet to swiftly and efficiently classify giant kelp with at least the same accuracy as the human eye."}, {"title": "2.1. Data", "content": "The provided dataset was consisted by the feature data, meaning the satellite imagery from the Landsat satellite missions, the elevation information and the cloud masks. There was also the label data, the binary masks indicating the presence or absence of kelp canopy which were created by citizen scientists via the Floating Forests platform. Details for the creation of these kelp labels, such as how many citizens should have marked the kelp canopy to be set as kelp, was not shared. For competition purposes, a test dataset containing only satellite images (without labels) was also provided. Scoring on this dataset was available exclusively through the competition leaderboard.\nThe training dataset is consisted of 5635 square images (chips) of size 350 (pixels) and corresponding kelp forests masks. This image size was selected as similar to the image size given to citizen scientist for labelling. As Landsat resolution is 30m, each chip covers an area of about 10.5*10.5 square Km. Each image contains 7 channels, 5 Landsat channels (Blue, Green, Red, NIR, SWIR1), 1 channel containing a cloud mask indicating the presence or absence of clouds and 1 channel containing the Digital Elevation Model (DEM), with elevation measured in meters from sea-level, as derived from the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) data, which is utilized to generate a land-sea mask. Images from Landsat 5, 7 and 8 was used to span multiple decades, for a comprehensive view of the region's kelp forests over time, but the information of the Landsat product that each chip came from and with this the timestamp it belongs to was not available.\nThe most useful bands for vegetation in general and kelp forests in particulate are the SWIR1 band (Shortwave Infrared), which is useful for distinguishing between different types of vegetation as well as for detecting moisture content in soil and vegetation and the NIR band (Near-Infrared) as healthy vegetation reflects a significant amount of NIR light. Together with the Red, Green and Blue bands, capture a broad spectrum of electromagnetic radiation and have been selected by host for their usefulness in monitoring coastal environments. This also shown in various studies for detecting and analyzing vegetation characteristics as Bartold and Kluczek (2024) also shown in plant stress detection at peatlands using Sentinel-2 satellite imagery. A plant leaf typically"}, {"title": "2.2. Annotation errors", "content": "Since the ground truth labels were provided by citizen scientists based on their visual interpretation of processed satellite images, there is some uncertainty regarding their accuracy. An ideal annotation should had been created by scuba divers or by dredging up samples from the deep. This would require a lot of effort to be collected and at the same time it would be limited to reachable places and would induce an increased cost. Fortunately, this important megastructures in the sea can be seen from space, alleviating the need for in situ sampling. There are although some false annotations which downgrades the quality of the produced models but as developed methodology here is robust, a curated dataset could significantly improve method's performance."}, {"title": "2.3. Metric", "content": "To evaluate the performance in this binary semantic segmentation task, the Dice Coefficient (also known as the Sorensen-Dice Index) is used as the performance metric. The Dice Coefficient quantifies the similarity between the predicted and ground-truth binary masks. A higher Dice Coefficient indicates better segmentation accuracy.\nThe Dice Coefficient is calculated on a per-pixel basis, where each pixel of the predicted mask is compared to the corresponding pixel in the ground-truth mask. As the metric is calculated for the whole test dataset and is not averaged per image, it provides a more accurate measurement in kelp forest detection.\nThe Dice Coefficient is defined as:\nDiceCoe f ficient =  $\\frac{2 * A \u2229 B}{|A| + |B|}$ \nwhere:\n\u2022 | A | represents the size of set A (ground truth).\n\u2022 | B | represents the size of set B (predicted class).\n\u2022| A \u2229 B | represents the size of the intersection of sets A and B."}, {"title": "2.4. Modelling", "content": ""}, {"title": "2.4.1. Data used and preprocessing", "content": "Out of 7 available input channels, only 4 of them were used. The 3 of them were used in model training while the fourth in post processing. SWIR1, NIR and Green bands were used as input to the models after preprocessing and the DEM band was used in the post processing phase by applying a land-sea mask. Training bands preprocessing includes clipping values between a minimum (6000) and a maximum (24000) value while the value of zero was set to missing data. Afterwards a division with this maximum brought all data within 0-1 range. Final step includes subtracting and dividing with imagenet's means and standard deviations (reduced) per channel.\nimg01 = (img01 - [0.485, 0.456, 0.406])/([0.229, 0.224, 0.225])"}, {"title": "2.4.2. Models", "content": "The training of segmentation models was done using the pytorch framework and specif- ically the segmentation_models_pytorch (SMP) and the transformers libraries. MIT and ConvNeXt models were trained in various image sizes and combined effectively."}, {"title": "2.4.3. Training parameters and augmentation", "content": "Training image augmentation performed using the albumentation library (Buslaev et al. 2020) and included vertical and horizontal flipping as well as random number of 90 degrees rotations (all with 50% chance). A few models also included a custom augmentation for holes in both the image and the mask (chance 25%). Images and masks are resized in various sizes (512, 640 or 768) using the bicubic interpolation for enlarging the images as this is preferred to bilinear and nearest-neighbor, (Triwijoyoa and Adila 2021) for segmentation tasks.\nThe loss function that was optimized, was the dice loss directly, which equals \"1 - dice coefficient\", which is the competition's metric. A custom cosine annealing scheduler with 30-35 epochs in 1 snapshot and 0-2 additional epochs for warming up, was used for all models. The U-Net segmentation models needed about 5 epochs more training than the UpperNet. The learning rate dropped from 0.00005 to 0.0000005 over these epochs while 0.000001 used at the warming up phase. In all U-Net decoders, this learning rate was always 10 times higher, meaning that in U-Net models, encoder and decoder trained with different learning rates. Finally, the AdamW optimizer was used with the default weight decay and all other parameters (Loshchilov and Hutter 2017)."}, {"title": "2.4.4. Validation scheme", "content": "An 80-20% single train-validation split was used instead of a more precise k-fold split to prioritize experimentation speed. This speed-accuracy trade-off is more feasible for segmentation tasks than for classification or regression, as the large number of pixels in segmentation provides an effectively larger validation set. This split was not random but as original satellite images was not given, an attempt towards a grouped split was made utilizing custom jigsawing. This jigsawing attempt, was initially meant for augmentation purposes but as experiments didn't turn out to be as expected only used for the local validation split. For every experiment regardless the image training size the reported scoring was done in the original image size. For all experiments, scoring was reported on the original image size, while training loss was calculated on resized images, optimizing for later model ensembling across various training sizes."}, {"title": "2.4.5. Final predictions", "content": "Individual model predictions on the test dataset was done with test time augmentation, using simple average of all 4 possible flip states. The final predictions was the average of the individual models predictions. These predictions are probabilities as the sigmoid function was used at the end. This probabilities turn to binary masks by applying a 0.43 threshold. Finally, the land-sea mask was applied to erase possible predicted masks on land."}, {"title": "3. Results and discussion", "content": "The MIT model family contain the encoders from the SegFormer model (Xie et al. 2021) pretrained on the Imagenet (Deng et al. 2009). These transformer encoders proved highly efficient for the task and outperformed many other encoders tried in local validation. Furthermore, the U-Net decoder used here (Ronneberger et al. 2015) was the best as it scored better than PSPNet, FPN and MANET decoders locally, as seen in Table 3. MANet models performed quite well too and ensembling U-Net with MANet predictions initially improved local results but at the final ensembling where many U-Nets were ensembled together, including MANet(s) decreased overall performance. Many other segmentation architectures were not available for the MIT encoders and therefore no comparison was possible. The overall solution improved upon ensembling predictions from the MIT U-Net models with those of the ConvNeXt encoder models (Liu et al. 2022). ConvNeXt models used the UpperNet decoder (Xiao et al. 2018), increasing the variation of the decoders used and increasing the ensembling score."}, {"title": "3.1. Insights", "content": "Many things were tried along the way in order to improve model performance. As Table 8 shows, using test time augmentation with 4 all possible flips was very helpful both at individual and at ensembling models level. Attempts to use TTA with rotations of 90 degrees (either alone or combined with flips) didn't improve results. Converting targets to floats before resizing, making target masks to include decimal values for a few pixels, further improved results. Finally, setting grads to nan upon zero_grad call, also gave small improvement. The gradient update with batch accumulation, updating not on every training batch but every 3 batches, also proved beneficial with this small batch size (2-4 depending on image resize). Had a larger GPU been used, a larger batch size could had been used also and the importance of the batch accumulation may had been insignificant.\nPost-competition experiments revealed that certain strategies, initially believed to enhance the method's performance, were not as effective as expected. Increasing the U-Net decoder's learning rate 10 times, which improved performance in smaller models and image sizes, did not yield the same results for larger models. A more conservative increase (2-3 times) might be a safer option for testing. Additionally, the use of cubic"}, {"title": "3.2. Perspectives", "content": "Although extensive experimentation was conducted with this dataset, there are still opportunities to further enhance the presented approach. Future experiments could incorporate strategies from other top-ranked solutions, such as including calculated indices in the training data, applying blur to training targets, training with boundary loss, and utilizing a custom weighted sampler or quantile normalization. These ideas could potentially improve the effectiveness of the method.\nWhile the trained models can be effectively applied in real-world scenarios, ideally, they should be retrained using a curated dataset for optimal performance. This could be achieved, not necessarily by reannotating the entire dataset but by excluding images with significant annotation errors. Moreover, if the complete, uncut satellite data had been available, techniques like random crop resize could have artificially increased the training dataset, potentially enhancing model performance. Additionally, if the used for training image size of 350x350 pixels was expanded it could further improve results, as larger images provide more contextual information. Finally, as this is a relative small and from a specific area, using an even larger and more diverse dataset (including other regions, not just Falkland islands) could increase method's performance.\nThe inclusion of higher-resolution satellites, such as the Copernicus Sentinels, could enhance the detection of kelp forests. However, their shorter historical record limits their effectiveness for long-term study. Exploring a combination of both Landsat and Sentinel satellites could be valuable. ED Chaves et al. (2020) found that using these sources together allows researchers to improve operational classification and change detection, offering deeper insights into landscape and intrinsic processes, such as deforestation and agricultural expansion.\nThe integration of these advanced models, paired with state-of-the-art training techniques applied to meticulously processed earth observation data, has greatly improved the accuracy and quality of kelp forest area predictions. While this approach has proven effective within the remote sensing domain, similar results may vary across other fields. However, given that these models have also shown strong performance with other types of datasets, their application is promising for a broad range of segmentation tasks. Consequently, testing these models in the experimentation phase of any segmentation project is highly recommended to assess their potential for delivering precise and reliable outcomes.\nAs relative research highlighted, wave dynamics and winter conditions are essential for the survival and health of kelp forests. Incorporating weather data, such as wave height, as inputs could significantly enhance our methodology's performance in moni-"}, {"title": "4. Conclusions", "content": "Kelp forests are vital ecosystems that support diverse species and play a key role in fisheries, making their conservation essential. This study demonstrates that combin- ing Landsat imagery and crowdsourced labels with advanced machine learning models significantly enhances the accuracy of kelp forest detection in remote sensing images, providing a scalable, cost-effective solution for monitoring these habitats. Crowdsourced labeling emerges as a viable alternative to traditional annotation methods. Notably, U- Net models with MIT encoders performed exceptionally well for kelp mapping, while UpperNet architectures with ConvNeXt encoders also delivered strong results. Inte- grating predictions from both model types and blending outputs from models trained on varied image sizes further optimized performance. The analysis focused on three key Landsat bands-SWIR1, NIR, and Green-while altitude data was used to create a land-sea mask, reducing false positives on land. Using Level-2 data across differ- ent Landsat series eliminated the need for intercalibration while Landsat's resolution and 40-year archive make it well-suited for long-term kelp forest studies. Although the methodology proved effective for monitoring kelp forests, accuracy could further im- prove with a larger, more precisely labeled dataset or the application of this approach to higher-resolution satellite imagery. This combination of advanced models and train- ing techniques has not only enhanced kelp forest prediction accuracy but also shows promise for other segmentation applications."}]}