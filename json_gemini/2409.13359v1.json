{"title": "EmotionQueen: A Benchmark for Evaluating Empathy of Large Language Models", "authors": ["Yuyan Chen", "Hao Wang", "Songzhou Yan", "Sijia Liu", "Yueze Li", "Yi Zhao", "Yanghua Xiao"], "abstract": "Emotional intelligence in large language models (LLMs) is of great importance in Natural Language Processing. However, the previous research mainly focus on basic sentiment analysis tasks, such as emotion recognition, which is not enough to evaluate LLMs' overall emotional intelligence. Therefore, this paper presents a novel framework named EmotionQueen for evaluating the emotional intelligence of LLMs. The framework includes four distinctive tasks: Key Event Recognition, Mixed Event Recognition, Implicit Emotional Recognition, and Intention Recognition. LLMs are requested to recognize important event or implicit emotions and generate empathetic response. We also design two metrics to evaluate LLMs' capabilities in recognition and response for emotion-related statements. Experiments yield significant conclusions about LLMs' capabilities and limitations in emotion intelligence.", "sections": [{"title": "1 Introduction", "content": "Emotional intelligence in humans has long been a topic of interest in psychological research (Chen and Xiao, 2024). Emotionally intelligent individuals possess the capability to perceive, use, understand, and manage emotions effectively (Colman, 2015; Chen et al., 2023e, 2024e). The concept of emotional intelligence has been widely recognized, and many researchers argue that it can be considered as a form of intelligence. Various tests and assessments have been developed to evaluate different aspects of emotional intelligence, which provide scores for each branch of emotional intelligence as well as an overall score (Mayer et al., 2003; Chen et al., 2024d,b).\nIn recent years, there has been a growing interest in evaluating the emotional intelligence of large language models (LLMs). Early efforts primarily fo-"}, {"title": "2 Datasets and Task Setups", "content": "We categorize the empathy benchmark into four distinct tasks: Key Event Recognition, where LLMs are expected to identify the more significant event in a user's statement that includes both a significant event and a routine event. Mixed Event Recognition, where LLMs are tasked with simultaneously responding to both aspects when the user's statement contains two events of similar importance. Implicit Emotional Recognition, focusing on LLMs identifying underlying deep emotions in the user's statements. Intent Recognition, where LLMs should comprehend the user's real purpose and provide specific suggestions, going beyond just offering comfort. Based on the aforementioned four dimensions, we concentrate on generating 10,000 statements across five primary life scenarios using GPT-4 1, with an equal number of statements for each scenario. These scenarios are achievements, family and friends, health status, economic status, and ac-cidents. Some statement examples are displayed in Table 14 (positive statement), and figures from Fig. 8 to Fig. 21 (negative statement). The portion of positive and negative statements are 3:7 in our generated statements, which caters for the real situation that positive statements often require less complex emotional expressions compared to negative ones. The tasks' overview is depicted in Fig. 2, and the user statement generation prompts are detailed in Table 13."}, {"title": "2.1 Task setups", "content": "Key Event Recognition focuses on identifying and understanding significant events expressed by users and their emotional impact. Based on the Emotion-Focused Theory in psychology developed by Greenberg (2004), this approach encourages awareness and expression of emotions, including those neglected or not fully understood, and supports emotional transformation through exploring and processing emotional experiences. For instance, when a user's statement contains multiple points of information (usually a significant event and a routine event), the LLM should identify the most significant event and ask questions based on it. For example, if a user says, \u201cI ran into an old middle school classmate on my way to buy medicine,\" the LLM should inquire about the reason for buying medicine rather than the meeting with the classmate. The LLM does not need to address both aspects simultaneously, meaning it should not respond to both the medicine purchase and the classmate encounter.\nMixed Event Recognition focuses on responding to both aspects simultaneously when the user's statement includes two events of similar impor-tance, differing from Key Event Recognition, which deals with a single important event. Based on the concept of emotional complexity developed"}, {"title": "2.2 Evaluation metrics", "content": "We propose employing PASS rate and WIN rate to evaluate four tasks using GPT-4, where each LLM response is rated as either 0 or 1, disregarding ambiguous middle results. Because it can be quite challenging to measure the difference between intermediate levels such as 3 or 4 objectively in 1-5 scale. The PASS rate assesses an LLM's accuracy in recognizing emotion-related events, while the WIN rate evaluates its ability to provide an empathetic response.\nIn the Key Event Recognition task, if an LLM correctly identifies a key event, it earns 1 point in PASS, otherwise 0; if it also presents an empathetic response for that event, it scores 1 in WIN, otherwise 0. For instance, if a user says, \u201cI visited my sick mother in the hospital today, then went to the supermarket,\u201d and the LLM correctly recognizes \u201cvisiting the sick mother in the hospital\u201d as the key event, it scores 1 in PASS. If the LLM responds with \u201cIs your mother okay?\u201d, it is deemed appropriate and scores 1 in WIN. Responses like \"It's troublesome that your mother is sick, hope she doesn't keep you too busy\u201d or \u201cEveryone's mother gets sick eventually\u201d score 0.\nIn the Mixed Event Detection task, if an LLM recognizes both mentioned events, it scores 1 in PASS; if it provides an empathetic response to both, it scores 1 in WIN. For example, if a user mentions, \u201cI got promoted but also need to move to a new city,\u201d and the LLM identifies both \u201cgot promoted\u201d and \u201cmove to a new city\u201d correctly, it scores 1 in PASS. An LLM response like \u201cCongratulations on the promotion! Is moving to a new city a challenge"}, {"title": "3 Experiments", "content": "In this section, we conduct extensive experiments to evaluate different LLMs' performance in the proposed EmotionQueen."}, {"title": "3.1 Experimental Setups", "content": "Our experiments are conducted on 8 Nvidia A100 GPUs, each with 80GB of memory, and we use Py-Torch 2 in Python. We set the maximum sequence length for both input and output sequences to maximum 100 tokens, ensuring the responses not over lengthy. We also conduct an analysis of the average response length from LLMs and find it to be 52.3 tokens, demonstrating the reasonableness of the set sequence length."}, {"title": "3.2 Datasets, Baselines and Metrics", "content": "The baseline LLMs for this evaluation are BLOOM-7B (Workshop et al., 2023) BLOOM-176B (Workshop et al., 2023), Claude2 (Bai et al., 2022), Falcon-7B (Almazrouei et al., 2023), Falcon-180B (Almazrouei et al., 2023), GPT3.5 (Brown"}, {"title": "3.3 Main results", "content": "Question 1:Which LLM is the winner of the EmotionQueen? Answer 1: LLaMA-70B! But Claude2 is slightly fall behind!\nPerformance of different LLMs across four tasks is shown in Table 1, Table 2, Table 3 and Table 4. We rank them based on the average of PASS rate and WIN rate, and compare the their comprehensive empathy capabilities as shown in Table 5 and Fig. 3. In the aspect of key event recognition (denoted as \u201cKER\u201d), Claude2, BLOOM-176B, and LLaMA2-70B show nearly perfect PASS rate, demonstrating their strong capability in capturing the core events of user statements. In WIN rate, Claude2 maintains a lead, other LLMs such as Vicuna-33b and LLaMA2-70B fall slightly short. In the aspect of mixed event recognition (denoted as \u201cMER\u201d), Claude2 also excels in identifying multiple events, showing its capability in handling complex scenarios. But the WIN rate generally decreases for all LLMs, suggesting potential room for improvement in understanding and balanced responses to mixed events. Regarding implicit emotion recognition (denoted as \u201cIER\u201d), LLaMA2-70B, Vicuna-33B, and GPT4 perform well. However, the WIN rate analysis shows that, except for LLaMA2- 70B, other LLMs like Vicuna-33B and GPT4 have gaps in response appropriateness. In intent recognition (denoted as \u201cIR\u201d), most LLMs, especially Claude2 and LLaMA2-70B, show a high PASS rate, but they still show potential in providing effective guidance. Overall, although most LLMs excel in identifying the key content of user statements, they still have room for improvement in providing empathetic responses.\nWe also explore the emotional intelligence of"}, {"title": "3.4 Case Study", "content": "We shown some cases in Fig. 7 and more cases are shown in figures from Fig. 8 to Fig. 21.\nFor example, in key event recognition, Claude2 not only accurately captures the significant event of user getting their dream job but also further inquires about the user's favorite aspects of the new job. Similarly, in mixed event detection, Claude2 can simultaneously focus on the sadness of friends moving away and the content of the package. This demonstrates its capability to deeply understand user's situation and effectively com-municate. Looking further, in implicit emotion recognition, LLaMA2-70B not only identifies the underlying stress but also delves into the user's feelings about the exams, providing emotional sup-port. In intention recognition, addressing real-life problems of users, such as \u201cMy phone keeps dy-ing...\", Claude2 offers practical advice, like reduc-ing screen brightness, showing its capability to dis-cern user needs and provide practical help.\nThere are also some bad cases from several LLMs as shown in Table 15. For example, GPT3.5 echoes the original statement without adding em-pathy in the key event recognition. GPT4 acknowl-edges the implied emotion but behaves more like questioning than offering support. Claude2 shows\""}, {"title": "4 Related Work", "content": ""}, {"title": "4.1 Emotion recognition", "content": "LLMs has seen significant advancements in different scenarios (Chen et al., 2023a; Ren et al., 2024; Tao et al., 2024; Chen et al., 2024c,a). For example, in emotion recognition, Li et al. (2022a) introduce the BiERU for conversational sentiment analysis; Wake et al. (2023) adopt ChatGPT to recognize emotions from text; Feng et al. (2023) study the capability of LLMs in recognizing hu-man affect in the conversation; Li et al. (2023a) introduce a new emotion task called conversational aspect-based sentiment quadruple analysis; Mao et al. (2023) conduct an empirical study on prompt-based sentiment analysis and emotion detection; Huang et al. (2023) shows modalities perception"}, {"title": "4.2 Empathetic dialogue", "content": "LLMs are demonstrated have great performance in empathetic dialogues. For example, Zhao et al. (2023) assessing ChatGPT's performance in understanding and generating emotional dialogue; Lee et al. (2022) explore empathetic dialogue gener-ation with GPT-3; Li et al. (2023b) delve into LLMs' understanding of and response to emotional stimuli in the conversation; Qian et al. (2023) ex-plore the use of LLMs for generating empathetic dialogue responses; Zheng et al. (2023a) address the dialogue augmentation challenge in emotional support conversation; tse Huang et al. (2023) pro-pose EmotionBench to evaluate LLMs' empathy by assessing their emotional responses to specific situations; Zheng et al. (2023c) discuss the chal-lenges in building emotional support chatbots and create a emotional support dialogue dataset; Tian et al. (2023)introduce ChatPLUG, a Chinese open-domain dialogue system enhanced; While it is ac-knowledged that current LLMs possess a certain degree of capability for emotional dialogue, there is not a comprehensive benchmark that evaluate LLMs' emotion intelligence in handling more com-plex emotion-related scenarios."}, {"title": "5 Conclusions and Future Work", "content": "In conclusion, our study introduces a novel framework named EmotionQueen to evaluate the emo-tional intelligence of LLMs. We design four emotion-focused tasks, including Key Event Recog-nition, Mixed Event Recognition, Implicit Emo-tional Recognition, and Intention Recognition, asking LLMs to recognize and respond to emotional intentions in user statements. Our findings under-score Claude2 and LLaMA-70B achieve great per-formance in EmotionQueen, providing significant insights about LLMs' capabilities and limitations in emotion intelligence. Looking to the future, we aim to extend the framework to capture an even broader spectrum of emotional intelligence facets with more robust metrics for precisely evaluating emotion intelligence of LLMs."}, {"title": "Limitations", "content": "The limitations of our study pertain to two main areas. First, LLMs may generate harmful or inap-propriate utterances, which may not be discovered by our evaluation metrics. Despite efforts to miti-gate such outputs, the complex nature of language and context can lead to scenarios where the LLMS' responses are offensive or ethically dubious. Second, while our evaluation framework is designed to assess the emotional intelligence of LLMs, it is not immune to subjectivity. The interpretation of emotional events and the judgment of the quality of responses can be influenced by the personal biases of the assessors. In light of these limitations, future research must focus on enhancing the ethical safe-guards of responses of LLMs and on refining the objectivity of emotional intelligence evaluations."}]}