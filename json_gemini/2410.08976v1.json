{"title": "LEARNING REPRESENTATIONS OF INSTRUMENTS FOR PARTIAL IDENTIFICATION OF TREATMENT EFFECTS", "authors": ["Jonas Schweisthal", "Dennis Frauen", "Maresa Schr\u00f6der", "Konstantin Hess", "Niki Kilbertus", "Stefan Feuerriegel"], "abstract": "Reliable estimation of treatment effects from observational data is important in many disciplines such as medicine. However, estimation is challenging when unconfoundedness as a standard assumption in the causal inference literature is violated. In this work, we leverage arbitrary (potentially high-dimensional) instruments to estimate bounds on the conditional average treatment effect (CATE). Our contributions are three-fold: (1) We propose a novel approach for partial identification through a mapping of instruments to a discrete representation space so that we yield valid bounds on the CATE. This is crucial for reliable decision-making in real-world applications. (2) We derive a two-step procedure that learns tight bounds using a tailored neural partitioning of the latent instrument space. As a result, we avoid instability issues due to numerical approximations or adversarial training. Furthermore, our procedure aims to reduce the estimation variance in finite-sample settings to yield more reliable estimates. (3) We show theoretically that our procedure obtains valid bounds while reducing estimation variance. We further perform extensive experiments to demonstrate the effectiveness across various settings. Overall, our procedure offers a novel path for practitioners to make use of potentially high-dimensional instruments (e.g., as in Mendelian randomization).", "sections": [{"title": "INTRODUCTION", "content": "Estimating the conditional average treatment effect (CATE) from observational is an important task for personalized decision-making in medicine (Feuerriegel et al., 2024). For example, a common question in medicine is to estimate the effect of alcohol consumption on the onset of cardiovascular diseases (Holmes et al., 2014). There are many reasons, including costs and ethical concerns, why CATE estimation is often based on observational data (such as, e.g., electronic health records, clinical registries).\nHowever, identifying the CATE from observational data is challenging as it typically requires strong assumptions in the form of unconfoundedness (Rubin, 1974). Unconfoundedness assumes there exist no additional unobserved confounders U between treatment A and outcome Y. If the unconfoundedness assumption is violated, a common strategy is to leverage instrumental variables (IVs) Z. IVs affect only the treatment A but exclude unobserved confounding between Z and Y, which often can be ensured by design such as for randomized studies with non-compliance (Imbens & Angrist, 1994). The causal graph for the IV setting is shown in Fig. 1.\nMotivational example: Mendelian randomization. Mendelian randomization (Pierce et al., 2018) refers to the use of genetic information as instruments Z to estimate"}, {"title": "RELATED WORK", "content": "Machine learning for CATE estimation with IV: Existing works have different objectives. One literature stream leverages IVs for CATE estimation but focuses on settings where the treatment effect can be identified from the data. This includes work that extends the classical two-stage least-squares"}, {"title": "PROBLEM SETUP", "content": "Setting: We focus on the standard IV setting (Angrist et al., 1996; Wooldridge, 2013). Hence, we consider instruments (e.g., gene data, text, images) given by $Z \\in \\mathcal{Z} \\subseteq \\mathbb{R}^d$ but, unlike previous research,"}, {"title": "PARTIAL IDENTIFICATION OF CATE WITH COMPLEX INSTRUMENTS", "content": "We now present our proposed method to solve the partial identification problem from Eq. (1). Solving Eq. (1) directly is infeasible because it involves the unknown CATE $\\tau(x)$. Hence, we propose the following approach:\nOutline:  We learn a discretized representation (also called partitioning) $\\Phi(Z)$ of the instrumental variable $Z$.  We then derive closed-form bounds given the discrete representation $\\Phi$.  We transform the closed-form bounds back to our original bounding problem and, in particular, express all quantities involved as quantities that can be estimated from observational data.\nBelow, we first explain why existing closed-form bounds are not directly applicable and why deriving such bounds is non-trivial. We then proceed by providing the corresponding theory for the above method. Specifically, we first take a population view to show theoretically that our bounds are valid (Sec. 4.2). Then, we take a finite-sample view and present an estimator (Sec. 4.3)."}, {"title": "POPULATION VIEW", "content": "In the following theorem, we provide a novel theoretical result of how to obtain valid bounds based on discrete representations $\\Phi(Z)$ of the instrument $Z$.\nTheorem 1 (Bounds for arbitrary instrument discretizations). Let $\\Phi : \\mathcal{Z} \\rightarrow \\{0,1,..., k\\}$ be an arbitrary mapping from the high-dimensional instrument $Z$ to a discrete representation. We define\n$\\mu_a^{\\Phi}(x, l) = \\frac{\\int_{\\mathcal{Z}} \\mu_a(x, z) P(\\Phi(Z) = l | Z = z) P(A = a | Z = z) P(Z = z) dz}{P(A = a, \\Phi(Z) = l)}$ and\n$$\\pi_{\\Phi}(x, l) = \\frac{\\int_{\\mathcal{Z}} \\pi(x, z) P(\\Phi(Z) = l | Z = z) P(Z = z) dz}{P(\\Phi(Z) = l)}.$$\nThen, under Assumptions 1, 2, and 3, the CATE $\\tau(x)$ is bounded by\n$$b^{-}(x) \\leq \\tau(x) \\leq b^{+}(x),$$\nwith\n$$b^{+}(x) = \\min_{l,m} b_{\\Phi;l,m}^{+}(x) \\text{ and } b^{-}(x) = \\max_{l,m} b_{\\Phi;l,m}^{-}(x),$$\nwhere\n$$b_{\\Phi;l,m}^{+}(x) = \\pi_{\\Phi}(x, l) \\mu_1^{\\Phi}(x, l) + (1 - \\pi_{\\Phi}(x, l)) s_2 - (1 - \\pi_{\\Phi}(x, m)) \\mu_0^{\\Phi}(x, m) - \\pi_{\\Phi}(x, m) s_1,$$\n$$b_{\\Phi;l,m}^{-}(x) = \\pi_{\\Phi}(x, l) \\mu_1^{\\Phi}(x, l) + (1 - \\pi_{\\Phi}(x, l)) s_1 - (1 - \\pi_{\\Phi}(x, m)) \\mu_0^{\\Phi}(x, m) - \\pi_{\\Phi}(x, m) s_2.$$\nTheorem 1 states that, in population, we yield valid closed-form bounds for $\\tau(x)$ for arbitrary representations $\\Phi$. In particular, we can relax the optimization problem from Eq. (1) and obtain valid bounds $b_{\\Phi^{*}}^{+}(X) \\geq b^{+}(X)$ and $b_{\\Phi^{*}}^{-}(X) \\leq b^{-}(X)$ by solving\n$$\\Phi^{*} \\in \\arg \\min_{\\Phi \\in \\mathcal{\\Phi}} E_X [b_{\\Phi}^{+}(X) - b_{\\Phi}^{-}(X)].$$\nImplications of Theorem 1: Our derivation of closed-forms bounds for arbitrary discrete representations of complex Z comes with an important additional benefit: The bounds only depend on (i) discrete probabilities, (ii) quantities which are independent of $\\Phi$ and thus do not change for different $\\Phi$, and (iii) the discrete representation mapping to be learned itself. As a result, this allows us to directly learn $\\Phi$ wrt. Eq. (8). As such, we circumvent the need for adversarial or alternating training, which results in more robust estimation."}, {"title": "FINITE-SAMPLE VIEW", "content": "In practice, we have to estimate the bounds from Theorem 1 from finite observational data. For this purpose, we start with arbitrary initial estimators: $\\hat{\\pi}(x, z)$ is the estimator of the propensity score $\\pi(x, z)$, $\\hat{\\mu}_a(x, z)$ of the response function $\\mu_a(x, z)$, and $\\hat{\\eta}(z)$ of $\\eta(z) = P(A = 1 | Z = z)$.\nOnce the initial estimators are obtained, we can estimate our second-stage nuisance functions defined in Eq. (22) and (23) via\n$$\\hat{\\mu}_a^{\\Phi}(x, l) = \\frac{1}{n} \\sum_{j=1}^n \\mathbb{1}\\{\\Phi(z_j) = l, a_j = a\\} \\approx \\frac{\\sum_{j=1}^n \\hat{\\mu}_a(x, z_j) \\mathbb{1}\\{\\Phi(z_j) = l\\} (a \\hat{\\eta}(z_j) + (1 - a)(1 - \\hat{\\eta}(z_j)))}{\\sum_{j=1}^n \\mathbb{1}\\{\\Phi(z_j) = l\\}},$$\nand via\n$$\\hat{\\pi}_{\\Phi}(x, l) = \\frac{1}{n} \\sum_{j=1}^n \\mathbb{1}\\{\\Phi(z_j) = l\\} \\approx \\frac{\\sum_j \\hat{\\pi}(x, z_j) \\mathbb{1}\\{\\Phi(z_j) = l\\}}{\\sum_j \\mathbb{1}\\{\\Phi(z_j) = l\\}}.$$\nFinally, we can directly 'plug in' these estimators into Eq. (5) to compute estimates of the upper and lower bound $\\hat{b}^{-}(x), \\hat{b}^{+}(x)$.\nA na\u00efve approach would now directly use $(\\hat{b}^{-}(x), \\hat{b}^{+}(x))$ to solve the optimization in Eq. (8). However, for finite samples, it turns out this is infeasible without restricting the complexity of the representation function. The reason is outlined in the following theoretical results.\nLemma 1 (Tightness-bias-variance tradeoff). Let $E_n$ and $Var_n$ denote the expectation and variance with respect to the observational data (of size $n$). Then, it holds\n$$E_n [(\\hat{b}^{+}(x) - b^{*}(x))^2] \\leq 2 \\bigg( (b^{+}(x) - b^{*}(x))^2 + E_n [\\hat{b}^{+}(x) - b^{+}(x)]^2 + Var_n(\\hat{b}^{+}(x)) \\bigg).$$\nLemma 1 shows that the mean squared error (MSE) between the estimated representation-based bound $\\hat{b}_{\\Phi}^{+}(x)$ and the ground-truth optimal bound $b^{*}(x)$ can be decomposed into the following three components: (i) population tightness, (ii) estimation bias, and (iii) estimation variance. Term (i) describes the discrepancy between the tightest achievable representation-based bound $b^{*}$ and the ground-truth bound $b^{+}(x)$. It will decrease if we allow for more complex representations $\\Phi$, for example by increasing the number of partitions $k$. Term (ii) describes the estimation bias due to using finite-sample estimators for estimating the bounds. It will generally depend on the type of estimators we employ for $\\hat{\\eta}(x, z)$, $\\hat{\\mu}_a(x, z)$, and $\\hat{\\eta}(z)$. Finally, term (iii) characterizes the variance due to using finite-sample estimators. In contrast to term (i), it will increase when we allow the representation to be more complex.\nTo make point (iii) more explicit, we derive the asymptotic distributions of the estimators from Eq. (9) and Eq. (10) that are used to estimate the final bounds.\nTheorem 2 (Asymptotic distributions of estimators). It holds that\n$$\\sqrt{n} (\\hat{\\mu}_a^{\\Phi}(x, l) - \\mu_a^{\\Phi}(x, l)) \\xrightarrow[]{d} \\mathcal{N} \\bigg( 0, \\frac{1}{P_{l, \\Phi}} \\Big( Var(g(Z) | \\Phi(Z) = l) + c\\Big) \\bigg)$$\n$$\\sqrt{n} (\\hat{\\pi}_{\\Phi}(x, l) - \\pi_{\\Phi}(x, l)) \\xrightarrow[]{d} \\mathcal{N} \\bigg( 0, \\frac{1}{P_{l, \\Phi}} Var(h(Z) | \\Phi(Z) = l) \\bigg)$$\nfor $c, d > 0$ and where $p_{\\epsilon, l} = P(\\Phi(Z) = l)$, $g(Z) = \\mu_a(x, Z)(a\\eta(Z) + (1 - a)(1 - \\eta(Z))$, and $h(Z) = \\pi(x, Z)$."}, {"title": "NEURAL METHOD FOR LEARNING CATE BOUNDS WITH COMPLEX INSTRUMENTS", "content": "In this section, we propose a neural method for our objective to learn tight and valid bounds. Our method consists of two separate stages (see Algorithm 1): 1 we learn initial estimators of the three nuisance functions, and 2 we learn an optimal representation $\\Phi^{*}$, so that the width of the bounds is minimized. Note that our method is completely model-agnostic. Hence, arbitrary machine learning models can be used in the first and second stages in order to account for the properties of the data. For example, for instruments with gene data, one could use pre-trained encoders to further optimize the downstream performance. We give an overview of the workflow of our method in Fig. 3 (see Algorithm 1 for pseudocode).\nInitial nuisance estimation: In the first stage, we can use arbitrary machine learning models (e.g., feed-forward neural network) to learn the first-stage nuisance functions $\\hat{\\mu}_a(x, z) = \\hat{E}[Y | X = x, A = a, Z = z]$, $\\hat{\\pi}(x, z) = P(A = 1 | X = x, Z = z)$, and $\\hat{\\eta}(z) = P(A = 1 | Z = z)$.\nRecall that we consider Z and X, which are both potentially high-dimensional. Hence, for $\\hat{\\mu}_a(x, z)$ and $\\hat{\\pi}(x, z)$, we use network architectures that have (i) different encoding layers for X and Z, so that we capture structured information within the variables and (ii) shared layers on top of the encoding to learn common structures. Further, for $\\hat{\\mu}_a(x, z)$, we use two outcome heads for both treatment options $A \\in \\{0, 1\\}$ to ensure that the influence of the treatment on the outcome prediction does not \u2018get lost' in the high-dimensional space of X and Z (Shalit et al., 2017).\n Representation learning: In the second stage, we train a neural network to learn discrete representations of the instruments with the objective of obtaining tight bounds but with constraints"}, {"title": "EXPERIMENTS", "content": "Baselines: Existing methods (see Sec. 2) focus either on (a) point identification with strong assumptions, (b) partial identification with continuous treatment variables, or (c) discrete instruments. We instead focus on a setting with complex instruments and binary treatments. Hence, existing methods are not tailored to our setting, because of which a fair comparison is precluded. Instead, we thus demonstrate the validity and tightness of our bounds. Further, for comparison, we propose an additional NA\u00cfVE baseline, which first learns a discretization of the instruments (via k-means clustering) and then learns the nuisance functions wrt. to the discretized instruments to apply the existing bounds for discrete instruments from Lemma 2 on top.\nData: We perform ex- periments mimicking Mendelian Randomization but where we simulate the data to have access to the ground-truth CATE for performance evaluations, so that we can check for coverage and validity of the bounds. We consider three different realistic settings. For Datasets 1 and 2, we consider a one-dimensional continuous instrument $ \\tau(x, z)$, representing a polygenic risk score (Pierce et al., 2018). Further, in Dataset 1, we model the true $ \\pi(x, z)$ as a rather simple function to check if our method is already competitive in such settings. In Dataset 2, we model $ \\pi(x, z)$ as a complex function to evaluate the performance in more challenging settings. We use the same CATE for Dataset 1 and Dataset 2 to allow for comparisons between both. In Dataset 3, we model high-dimensional instruments with single nucleotide polymorphisms (SNPs, i.e., genetic variants; Burgess et al., 2020) to test our method in an additional realistic and even more complex setting. In all datasets, we model the CATE to be heterogeneously conditioned on X to check whether the bounds adapt to different subpopulations. Details are in Appendix D.\nPerformance metrics: We report the following metrics to assess the validity and robustness of the estimated bounds: (i) The coverage, i.e., how often the true CATE lies within the estimated bounds. (ii) The average width of bounds, where lower values indicate more informative bounds. (iii) The mean squared difference MSD(k) of the predicted bounds over different values of k, indicating the robustness wrt. to the selection of the hyperparameter. Further, for Dataset 3, we model $ \\pi(x, z)$ to be dependent on some latent discrete representation of the observed Z, such that we can approximate oracle bounds. Thus, we can evaluate the (iv) MSE and (v) the coverage wrt. to the oracle bounds."}, {"title": "IMPLEMENTATION AND TRAINING DETAILS", "content": "Model architecture: For all our models, we use MLPs with ReLU activation function. For $\\hat{\\mu}$, we use 2 layers to encode X and 3 layers to encode Z. Then, we concatenate the outputs and add 2 additional shared layers. Finally, we calculate the outputs by a separate treatment head for A = 0 and A = 1 to ensure the expressiveness of A for predicting Y. For $\\hat{\\pi}$, we use the same architecture. For $\\hat{\\eta}$, we use 3 layers. For $\\phi$, we also use 3 layers and apply discretization on top of the K outputs (Jang et al., 2017). For the nuisance parameters of the k-means baseline, we use the same models as for $\\hat{\\mu}$ and for a fair comparison. We use a neuron size of 10 for all hidden layers.\nTraining details: For training our nuisance functions, we use an MSE loss for the functions learning the continuous outcome Y and a cross-entropy loss for functions learning the binary treatment A. For all models, we use the Adam optimizer with a learning rate of 0.03. We train our models for a maximum of 100 epochs and apply early stopping. For our method, we fixed $ \\lambda = 1$ and performed random search to tune for $[0, 1]$ for $ \\gamma$. We use PyTorch Lightning for implementation. Each training run of the experiments could be performed on a CPU with 8 cores in under 15 minutes."}, {"title": "DATA DESCRIPTION", "content": "Dataset 1: We simulate an observed confounder $X \\sim Uniform[-1,1]$ and an unobserved confounder $U \\sim Uniform[-1,1]$.\nThe instrument Z is defined as\n$$Z \\sim Mixture\\bigg( \\frac{1}{2} Uniform[-1,1], \\frac{1}{4} Beta(2, 2), + \\frac{1}{4} (-Beta(2, 2))\\bigg).$$\nWe define $\\rho$ as\n$$\\rho = \\frac{1}{1 + exp(- ((2|Z| - max(Z)) + X + 0.5 \\cdot U))}.$$\nThen, the propensity score is given by\n$$\\pi = (\\rho \u2013 0.5) \\cdot 0.9 + 0.5.$$\nWe then sample our treatment assignments from the propensity scores as\n$$A \\sim Bernoulli(\\pi).$$\nThe conditional average treatment effect (CATE) is defined as\n$$\\tau(X) = \\frac{(2.5X)^{4} + 12 sin(6X) + 0.5 cos(X)}{80} + 0.5.$$\nThe outcome Y is then generated by\n$$Y = (X + 0.5U + 0.1 \\cdot Laplace(0, 1)) \\cdot 0.25 + \\tau(X) \\cdot A.$$\nDataset 2: We keep the other properties but change the propensity score to be more complex, which results in harder-to-learn optimal representations of Z for tightening the bounds. The propensity score is given by\n$$\\pi = sin(2.5Z + X + U) \\cdot 0.48 + 0.48 + \\frac{0.04}{1 + exp(-3|Z|)}.$$\nDataset 3: We simulate X and U as above. Then, we sample a d-dimensional $Z \\in \\{0,1\\}^{d}$ with $d = 20$ as\n$$Z \\sim Binomial(d, 0.5).$$\nThus, our modeling is here inspired by using multiple SNPs (appearances of genetic variations) as instruments (Burgess et al., 2020), where we simulate potential variations for 20 genes.\nThen, we define\n$$\\rho = \\sum_{j=1}^{d} [1\\{j \\leq 5\\}Z_{j}]$$\nand the propensity score, inspired by the more complex setting of Dataset 2, as\n$$\\pi = 0.48 sin(10\\rho + X + U) + 0.48 + \\frac{0.04}{1 + exp(-3|5\\rho|)}.$$\nThen, we define the CATE as\n$$\\tau(X) = \\frac{-(1.6X + 0.5)^{4} + 12 sin(4X + 1.5) + cos(X)}{80} + 0.5.$$\nand the outcome dependent on $\\tau$, X and U analogously as for Datasets 1 and 2.\nBy Eq. (60), we ensure that some of the modeled SNPs are irrelevant for $\\pi$ and thus do not affect the treatment or exposure A. Thereby, we focus on realistic settings in practice, where the relevance of instruments cannot always be ensured which imposes challenges especially for existing methods for"}]}