{"title": "Human-inspired Perspectives: A Survey on Al Long-term Memory", "authors": ["Zihong He", "Weizhe Lin", "Hao Zheng", "Fan Zhang", "Matt Jones", "Laurence Aitchison", "Xuhai Xu", "Miao Liu", "Per Ola Kristensson", "Junxiao Shen"], "abstract": "With the rapid advancement of Al systems, their abilities to store, retrieve, and utilize information over the long term - referred to as long-term memory - have become increasingly significant. These capabilities are crucial for enhancing the performance of Al systems across a wide range of tasks. However, there is currently no comprehensive survey that systematically investigates Al's long-term memory capabilities, formulates a theoretical framework, and inspires the development of next-generation Al long-term memory systems. This paper begins by systematically introducing the mechanisms of human long-term memory, then explores Al long-term memory mechanisms, establishing a mapping between the two. Based on the mapping relationships identified, we extend the current cognitive architectures and propose the Cognitive Architecture of Self-Adaptive Long-term Memory (SALM). SALM provides a theoretical framework for the practice of Al long-term memory and holds potential for guiding the creation of next-generation long-term memory driven Al systems. Finally, we delve into the future directions and application prospects of Al long-term memory.", "sections": [{"title": "1 INTRODUCTION", "content": "Over the past few decades, AI has demonstrated significant develop-ment potential and astonishing capabilities, thanks to the computational power supported by hardware and advanced machine learning algorithms [1, 2, 3, 4, 5]. As AI evolves and its applications span various industries, endowing it with long-term memory becomes increasingly important. Long-term memory in AI systems can be understood by analogy with human long-term memory, which stores information for a relatively long period [6]. Long-term memory assists AI systems in several ways. First, it helps acquire general understanding, such as integrating learned knowledge to enhance question-answering systems [7, 8, 9, 10]. Additionally, it establishes connections between current and past scenarios by storing key features from frames for timely retrieval, benefiting applications like video understanding [11, 12, 13, 14, 15]. Furthermore, it aids in mastering procedural abilities, such as developing strategy selection capabilities through production rules or reinforcement learning, thus enhancing agents' adaptability [16, 17, 18, 19, 20, 21, 22].\nThe human memory system offers valuable insights for designing AI long-term memory, as evidenced by recent AI developments that have, to varying degrees, emulated and incorporated structures akin to those in human long-term memory. For instance, some video understanding systems [11, 14] draw upon the Atkinson-Shiffrin Model [6] (a highly influential human memory model, detailed in Sec. 3) to construct hierarchical memory systems. These systems integrate short-term memory, which temporarily stores visual information, with long-term memory, which recalls historical data to enhance task effectiveness. Moreover, cognitive architectures introduced in works such as [20, 23] adopted pivotal components of human long-term memory: episodic, semantic, and procedural memory (also discussed in Sec. 3). These cognitive architectures leverage the history event flow to form episodic memory, knowledge sources to form semantic memory, and production rules, code or reinforcement learning to form procedural memory, enabling the creation of agents capable of self-learning and experience accumulation. Moreover, other works, although not explicitly grounded in human long-term memory theories, employ methodologies that closely mirror the processing mechanisms of human long-term memory, as explored later in Sec. 4 and Sec. 5. Therefore, the principles underlying human long-term memory present a promising theoretical foundation for AI researchers to develop more advanced AI systems with robust long-term memory capabilities.\nOur research identifies a gap in the existing literature, as there are no comprehensive surveys on AI long-term memory that are grounded in human memory theories (Sec. 2). To bridge this gap, this paper provides a survey of AI long-term memory from the perspective of human long-term memory theory, filling the void in the academic community regarding the prototypes, taxonomies, associated challenges, and system design of AI long-term memory. This survey offers researchers with valuable insights for constructing and optimizing AI systems that utilize long-term memory. The main content of this survey is outlined as follows.\nIn Sec. 3, we introduce human memory categorized by stages of information processing [6], focusing on episodic memory, semantic memory, and procedural memory, the three key components of human long-term memory [24, 25, 26]. We then classify AI long-term memory into non-parametric and parametric memory in Sec. 4, based on the form of storage [27, 28]. We also discuss the processing mechanisms and the challenges associated with them. In Sec. 5, we make an attempt to establish the relationships between Al's and human's long-term memory based on the review. Following that, in Sec. 6, we proposed the Cognitive Architecture of Self-Adaptive Long-term Memory (SALM) by integrating theories of AI long-term memory. This framework addresses the limitations of long-term memory modules in current cognitive architectures and has the potential to exceed the adaptability of human long-term memory processing mechanisms [29, 30, 31, 32]. It has the promise of serving as a guiding framework for the next generation of AI systems driven by long-term memory. Finally, in Sec. 7, we introduce practical measurement methods and potential applications for AI long-term memory.\nIn summary, the key contributions of our survey are:\n\u2022 We conduct a narrative review of the relevant work on long-term memory of both human and AI.\n\u2022 We develop a taxonomy of AI long-term memory based on the human memory theories, highlighting the strong associative relationships between these two.\n\u2022 We propose a cognitive architecture that integrates AI long-term memory theories with adaptive mechanisms for long-term memory processing, offering a potential guiding framework for the next generation of AI systems driven by long-term memory.\n\u2022 We examine the metrics and applications for AI long-term memory modules, advancing the implementation of AI systems driven by long-term memory."}, {"title": "2 RESEARCH BACKGROUND AND METHODOLOGIES", "content": "Research Background. We conduct a comprehensive analysis of articles from 2015 onward, relevant to AI memory surveys. Our search, conducted on October 7th, 2024, utilized the following search terms: (Review(s) or Survey(s) or Taxonomy(ies)) and Memory(ies) and (AI or Artificial Intelligence or Agent(s) or Deep Learning or Machine Learning or Neural Network(s)), and organized the research subjects, related publishers and preprint servers of these articles, as depicted in Fig. 2. The majority of the reviewed articles focus on computer memory and recurrent neural networks (RNNs). The computer memory domain primarily addresses data storage and retrieval, rather than exploring memory taxonomy from an AI perspective [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]. In contrast, RNNs, particularly long short-term memory networks (LSTMs), focus on managing hidden states for storing and utilizing sequential historical information, which is not generalizable across all AI domains [46, 47, 48, 49, 50, 51, 52, 53]. The survey by Savya et al. [54] provides a broader analysis of neural network models, including Transformers [3] and Neural Turing Machines [55], and examines the implications of human memory theories, such as the Atkinson-Shiffrin Model [6], for AI memory. However, they focused on the implementation of memory within specific model architectures, and they did not further categorize long-term memory into types such as episodic, semantic, or procedural memory [26] to assess their relevance to AI. On the other hand, the development of Large Language Models (LLMs) [5] has recently accelerated research on memory in intelligent agents. Zhang et al. [56] categorized the memory types in LLM-based agents into textual and parametric forms, which aligned with the long-term memory characteristic of retaining information for an extended period [6]. However, their work does not explicitly incorporate human memory theories to structure the discussion. In summary, current research on memory in AI faces several limitations:\n\u2022 Current reviews related to memory, particularly long-term memory, are insufficient to encompass the field of artificial intelligence.\n\u2022 Current reviews on AI-related memory, particularly long-term memory, lack a framework that incorporates theories of human memory.\nResearch Methodologies. To address these limitations, we adopt human memory theories as the foundation for structuring our review of AI long-term memory. We begin by reviewing literature on human memory theories and their processing stages, with a focus on cognitive science and neuroscience (Sec. 3). We then explore the hierarchy and processing mechanisms of human long-term memory as prototypes to identify AI-related papers exhibiting similar characteristics. Our approach begins with a review of literature on human memory, focusing on its stages of processing as discussed in cognitive science and neuroscience (Sec. 3). We then examine the hierarchy and processing mechanisms related to human long-term memory (Fig. 3), using these"}, {"title": "3 LONG-TERM MEMORY IN HUMAN BRAIN", "content": "Human long-term memory is a subject of extensive research spanning various fields, including cognitive psychology, neuroscience, and computational neuroscience. Insights into human long-term memory enhance our understanding of brain function for researchers in these domains and also offer valuable guidance for AI researchers in constructing effective AI long-term memory. In this section, we provide a comprehensive overview of human memory's hierarchy (Sec. 3.1) and processing (Sec. 3.2) that are closely related to long-term memory. The overview of the human memory system is illustrated in Fig. 3."}, {"title": "3.1 Human Memory Hierarchy", "content": "Before introducing the hierarchy of human memory, it is important to note the close connection between research on human memory and the development of cognitive psychology. Traditional Behaviorism focuses on the environment and observable behaviors [57], while cognitive psychology, established in the 1960s, emphasizes the \"internal system\" involved in the formation of mental phenomena [58]. This shift is considered a major breakthrough in psychology and has spurred extensive research on human memory. Several influential theories have emerged from the development of cognitive psychology, including the \u201cLevels of Processing\u201d theory, which highlights the relationship between memory processing and its effects [59], the \"Working Memory\" theory, which focuses on the active maintenance and manipulation of information [60], and the \"Atkinson-Shiffrin model\" [6], which emphasizes the hierarchical structure of human memory.\nAmong these models, Atkinson-Shiffrin model, proposed by Atkinson et al., stands out as a significant milestone in memory research. It is recognized for its foundational and comprehensive approach to explain the hierarchical division of memory and its substantial influence on subsequent research in the field. Consequently, we use this model as the theoretical basis for explaining the hierarchy of human memory. Notably, this model and its derivative theories are frequently referenced in AI memory research [61, 11, 14], bridging the fields of human and AI memory studies. The Atkinson-Shiffrin model categorizes the human memory system into three levels: Sensory Register (Sec. 3.1.1), Short-term Store (Working Memory) (Sec. 3.1.2), and Long-term Store (Long-term Memory) (Sec. 3.1.3)."}, {"title": "3.1.1 Sensory Register", "content": "The sensory register is responsible for receiving and temporarily storing information from sensory systems, allowing visual information to be retained in a highly precise form for a short period. Atkinson et al. [6] used Sperling et al.'s 1960 visual exposure experiment [62] to illustrate the existence of the sensory register. In Sperling et al.'s experiment, subjects were briefly exposed to a series of printed letters and then asked to recite them after exposure. They discovered that for exposures lasting between 15 to 500 milliseconds, subjects could correctly report an average of slightly over four letters. When the stimuli contained four or fewer letters, subjects could report them with almost 100% accuracy. This finding demonstrated that individuals can retain brief visual stimuli through a mechanism that reflects the function of the sensory register. Information stored in the sensory register rapidly decays and either vanishes or is transferred to short-term memory within a very short time, providing raw material for subsequent memory processing [6]. This underscores the sensory register's critical role in the initial stages of information processing and memory formation."}, {"title": "3.1.2 Working Memory", "content": "In 1968, Atkinson et al. [6] summarized the concept of \"short-term storage\" based on previous research findings. These findings included the work of Peterson et al. [63], who observed variations in participants' ability to recall consonant letters\u00b9 at different time intervals, and Milner et al. [64, 65, 66], who discovered that patients who had their bilateral hippocampal region removed could recall short-term information like normal individuals, but could not retain new long-term information. Atkinson et al. indicated that short-term storage temporarily holds information, and if this information is not maintained through control"}, {"title": "3.1.3 Long-term Memory", "content": "In 1968, Atkinson et al. [6] suggested that the short-term store includes a mechanism for transferring information to the long-term store. Unlike the sensory register and short-term store, information in the long-term store does not rapidly decay or vanish. This information is relatively permanent, although it can be modified by other information or become temporarily inaccessible. According to Atkinson et al., the information in long-term store, referred to as \"traces\", does not strictly conform to the \"all-or-none\" characteristic. Instead, \"traces\" can exist in intermediate states such as \"decay\" and \"interference\". \"Decay\" refers to the weakening of long-term store \"traces\", such as information that deteriorates over time due to a lack of review, for example, certain words in a long sentence. \"Interference\" describes the mutual influence between \"traces\", such as when learning word A followed by a similar word B leads to confusion during recall. The term \"long-term store\" used by Atkinson et al. refers specifically to memory as a physical or functional analogy for information storage. In a broader context, this concept is referred to as \"long-term memory\".\nIn 1972, Tulving et al. [24] highlighted the complex nature of long-term memory by introducing two distinct types: episodic memory and semantic memory. Episodic memory relates to personal past events and experiences, such as an experience of mountain climbing or a recent vacation. In contrast, semantic memory relates to general information, such as \"Paris is the capital of France\" or understanding the concept of gravity. Furthermore, in 1985, Tulving et al. [26] classified memory involving the acquisition of perceptual feedback and motor skills as procedural memory [71, 72, 73]. An example of this is learning to ride a bicycle, which requires acquiring motor skills through balance feedback. Based on these existing findings, Tulving et al. [26] assumed three memory systems: procedural memory, semantic memory, and episodic memory.\nGraf et al. [74] introduced an alternative method of memory classification based on whether the memory can be consciously recalled, categorizing memory into explicit and implicit types. Implicit memory operates without conscious recollection; for example, maintaining balance on a bicycle after learning to ride involves implicit memory, as it does not require active thought. In contrast, explicit memory necessitates conscious recollection, such as when recalling a specific experience or piece of knowledge while writing an article. According to the classification proposed by Tulving et al. [26], episodic memory and semantic memory are types of explicit memory [24], whereas procedural memory falls under implicit memory [75].\nHaving established the categorization of long-term memory types, we now discuss the specifics of episodic, semantic, and procedural memory and show them briefly in Fig. 3:\n\u2022 Episodic Memory. Tulving et al. [24] defined episodic memory in 1972 as a type of memory specific to individuals, related to time and space, involving personal experiences, events, and contexts. In 1973, Tulving et al. [25] noted that input stimuli such as sound and visual information are processed for episodic memory storage through specific encoding, which combines perceived information with specific contexts and experiences to form memory trace (discussed in the leading paragraph of Sec. 3.1.3) that aids in subsequent retrieval. For successful recall of this trace, similar input stimuli need to be provided. For example, adults often recall childhood experiences upon seeing childhood photos, which stimulates the recall of relevant long-term memory traces. In 1985, Tulving et al. [26] explored the relationship between memory and consciousness, suggesting that episodic memory is associated with autonoetic consciousness. This form of consciousness allows individuals to associate the present situation with specific personal events from the past, with an awareness that the situation are genuine parts of their past experiences. Furthermore, episodic memory also facilitates learning from past experiences and applying this knowledge to future decisions, thereby enhancing an individual's ability to adapt to their environment [76].\n\u2022 Semantic Memory. According to Tulving et al.'s perspective [24] in 1972, semantic memory encompasses an individual's knowledge about words and other linguistic symbols, including the relationships between them, and the rules, formulas, and algorithms for manipulating them. It functions to receive, retain, and convey semantic information about words and concepts. Unlike episodic memory, which is tied to personal experiences, semantic memory deals with general information. An example of semantic memory is the long-term memory formed by learning knowledge in a specific field or by extracting general rules from past experiences. In 1985, Tulving et al. [26] further explored the relationship between memory and consciousness, indicating that the type of consciousness associated with semantic memory is termed noetic consciousness. Noetic consciousness is an internal, non-physical state of awareness that allows individuals to perceive certain objects without external stimuli and is more closely associated with intuition, insight, and internal knowledge. For example, when a person recalls the definition of a word or a mathematical formula, they do so through noetic consciousness, which does not need to be called up based on a certain scene. This contrasts with autonoetic consciousness, which connects the present scene to episodic memory.\n\u2022 Procedural Memory. Tulving et al. [26] describe procedural memory as the memory developed from learning motor skills through feedback and perceptual abilities. This type of memory is intrinsically linked to the immediate temporal and spatial contexts and does not depend on information beyond the current stimuli. This allows for instantaneous reactions based on direct perception. For example, learning to ride a bicycle involves the sensation of losing balance, which triggers discomfort and gradually leads to the development of balancing skills. Once these skills are fully acquired, individuals can effortlessly maintain balance while riding, demonstrating the role of procedural memory in learning motor skills."}, {"title": "3.2 Human Memory Processing", "content": "In the previous section, we divide human memory into sensory register, short-term store, and long-term store (long-term memory) following the Atkinson-Shiffrin Model and its related theories. These theories explain human memory in terms of its hierarchical structure. However, understanding human memory can also be approached from the perspective of the entire memory processing cycle. This perspective allows for a deeper investigation into the \"black box\" of the brain by dividing the entire process into separate stages.\nSince the mid-19th century, advancements in brain science, computational neuroscience, and cognitive psychology have given rise to theories related to memory processing. In 1963, Melton et al. [77] emphasized the significance of Memory Storage and Memory Retrieval in memory theory research. Storage refers to the mechanism by which memory is placed in the brain, while retrieval refers to the mechanism by which memory is recalled from the brain. The units of memory storage, known as \"traces\", can be strengthened through active rehearsal or consistent use [78]. Conversely, unused memory traces will decay over time [79]. Melton et al. also suggested that the storage of memory traces is closely related to their subsequent retrieval, which may be influenced by factors such as trace integrity, interference, and repetition. Interference can compromise the integrity of memory traces, with lower integrity leading to less effective retrieval. For example, learning a new word may interfere with the memory of a similar old word, affecting its usage in writing. Repetition, on the other hand, can enhance the strength of memory traces, thereby improving retrieval efficiency; for instance, repeated review before an exam leads to better grades. Additionally, in 1969, Atkinson et al. [29] proposed that memory storage and retrieval in long-term memory function as parallel processes that correspond to each other. Later, in 1973, Tulving et al. [25] noted that memory storage and retrieval are distinct research directions. Based on these studies, we establish two independent subsections, Sec. 3.2.1 and Sec. 3.2.2, to elaborate on the processes of storage and retrieval in human memory in detail.\nHowever, as mentioned earlier, memory storage and retrieval only address how memory are formed and utilized. There also exists a mechanism facilitating memory extinction, which we refer to as Memory Forgetting. Specifically, the research by Ebbinghaus et al. [80] in the late 19th century sparked continued interest among subsequent neuroscientists in the field of memory forgetting, leading to a series of experimental analyses and ongoing attention [81, 82, 83]."}, {"title": "3.2.1 Memory Storage", "content": "Based on the perspective of Tulving et al. [25], memory storage is achieved by processing input stimuli through specific encoding (detailed in the episodic part of Sec. 3.1.3). According to Atkinson et al. [29], sensory register, short-term store, and long-term store have distinct methods for storing and encoding information at different stages of the memory process. The long-term store, in particular, is viewed as a permanent repository of information. It encodes memory through four distinct encoding strategies: \u201cmeaning\u201d, \u201cassociation\u201d, \u201crepetition\u201d, and \"organization\", as discussed below:\n\u2022 Meaning refers to encoding information that holds significant importance, such as events that deeply impact individuals.\n\u2022 Association involves pairing related objects with the encoded information, like remembering a \"bird\" based on characteristics such as flying.\n\u2022 Repetition indicates the likelihood of information being transferred to the Long-term Store, as repeated exposure to scenes enhances memory retention.\n\u2022 Organization suggests that the storage location in the Long-term Store is influenced by the content itself, such as recalling \"hamburger\" in the brain's \"food section\".\nIn summary, it is evident that memory storage, especially for long-term memory, is a relatively complex process. It involves processing perception, which we call \"encoding\", to produce information stored in the brain. The quality of memory storage largely determines the subsequent quality of memory retrieval and the rate of memory forgetting."}, {"title": "3.2.2 Memory Retrieval", "content": "According to Tulving et al. [25], memory retrieval involves a conscious search and identification of information stored in memory. They emphasized that this process is not merely the activation of learned associations or the recall of stored traces. Instead, it involves complex interactions between stored information and specific features of the current retrieval context. Providing cues similar to the original stimuli that formed the memory can enhance retrieval effectiveness. An example of this is individuals visiting a place they have previously stayed at, which is likely to evoke the events they experienced there.\nDuring the 1970s, one of the most prominent theories of memory retrieval, coinciding with Tulving et al.'s research, was the Generation-Recognition Theory [29, 90, 25]. This theory outlines the stages of memory retrieval, dividing them into the generation stage and the recognition stage. In the generation stage, individuals attempt to implicitly generate possible responses from memory, such as words, images, or other information associated with given cues. The recognition stage involves evaluating the responses generated in the generation stage to determine whether they meet specific acceptance criteria. In the recognition stage, the generated responses are matched against stored memory traces to see if they align with the specific information that was originally learned. Recognition requires not only identifying whether the response is familiar, but also confirming its context and correctness. For instance, it involves determining whether a recalled fact was encountered in a specific learning context or whether an image accurately represents an event experienced previously. It is concluded that the effectiveness of retrieval is enhanced if the process provides cues similar to those used during encoding [25, 91]."}, {"title": "3.2.3 Memory Forgetting", "content": "Memory forgetting is commonly perceived as the erasure of memory from storage. However, Atkinson et al. [29] proposed in 1969 that memory forgetting and related phenomena are often not due to the disappearance of information from long-term storage, but rather failures in the retrieval process. As individuals are exposed to increasing amounts of external information, their long-term memory grows correspondingly vast. The expanding scope of memory retrieval can cause interference between similar memory, leading to retrieval failures. This interference leads to the phenomenon known as \u201cmemory forgetting\", which is a form of passive forgetting. On the other hand, some studies [92, 93, 94, 95] suggested that in addition to passive forgetting, humans can also achieve active regulation of the memory system through a mechanism that suppresses redundant information to facilitate the storage and retrieval of key memory. This type of forgetting mechanism is termed \"active forgetting\".\nThe systematic study of memory forgetting dates back to the late 19th century. In 1885, Ebbinghaus et al. [80] demonstrated that 38 repetitions over three days had a similar effect to 68 repetitions in one day. In 1897, Jost's Law [81] indicated that the probability of forgetting distant memory is higher than that of recent memory. Later, in 1957, Underwood et al. [96] explained a phenomenon where previously learned or concurrently learned information affects the forgetting of specific memory, which is termed \u201cinterference\". These studies elucidate factors that can be utilized to reduce the probability of memory forgetting, including long intervals, high recency, and low interference, providing insights into effective strategies for retaining key information. For instance, leveraging the three strategies, individuals can improve word test results by reviewing words over extended intervals instead of repeating them in a short period (long intervals), focusing on word review as tests approach (high recency), and using specific markers to distinguish easily confused words (low interference). Moreover, there are active mechanisms in the brain to alleviate memory forgetting. Some studies suggest that the hippocampus engages in memory replay during certain phases, such as sleep, to consolidate memory and prevent forgetting. For example, place cells in the hippocampus spontaneously replay past trajectories to strengthen spatial memory [97]. Additionally, coordinated activity between the hippocampus and the visual cortex supports the replay of episodic memory, further aiding memory consolidation [98]."}, {"title": "3.3 Summary", "content": "Human memory exhibits a complex hierarchy, along with storage, retrieval, and forgetting mechanisms. External stimuli briefly stay in the sensory register, with some information transitioning to short-term memory (working memory). Subsequently, information can be stored in long-term memory, forming more enduring memory. Information in long-term memory can be retrieved based on specific cues, playing a crucial role in using personal experiences, general knowledge to solve daily problems, and mastering skills such as riding a bicycle. Human memory, particularly long-term memory, also has its flaws, such as forgetting due to memory interference. Understanding human memory, especially long-term memory, from the perspectives of brain science and cognitive science can help us to better understand AI systems that employ similar mechanisms.\nAdditionally, some research indicates that human long-term memory cannot adapt its processing mechanisms through environmental changes and that this adjustment is only achievable through evolution [30, 31, 32]. The evolutionary traits of human long-term memory that aid in survival are not necessarily well-suited for handling complex tasks in modern society, such as quickly grasping intricate knowledge for exams. Addressing similar limitations in AI long-term memory systems presents significant research value."}, {"title": "4 LONG-TERM MEMORY OF AI: ON STORAGE FORMATS", "content": "In the previous sections, we examined the hierarchy and processing methods related to long-term memory in the human brain. Long-term memory, however, is not exclusive to humans; AI also possesses long-term memory mechanisms. AI long-term memory serves various purposes: it records episodic information from past events [183, 181], learns semantic information [176, 9], and gains experience from observations or feedback [182, 238]. AI long-term memory mirrors certain aspects of human long-term memory, including storage, retrieval, and forgetting processes; some AI long-term memory research is directly inspired by human long-term memory [239, 11, 14, 184, 185], while other studies align with human long-term memory processing mechanisms without intentional imitation.\nAkin to the human brain, AI can process input stimuli to form long-term memory and schedule them appropriately. For instance, training of neural network models [240, 103] serves as a process of forming long-term memory of the models. During training, the model adjusts its weights through gradient descent [241], while during inference, the updated weights are utilized to compute the model's output, such as predicting the category of an image [103, 104]. If the model and training method are properly applied, the updated weights compared to the original weights can enable the model to better predict image categories. This process is analogous to how humans learn from images to store long-term memory (Sec. 3.2.1) and retrieve these long-term memory at appropriate times to recognize specific images (Sec. 3.2.2).\nThe aforementioned example shows that AI long-term memory can be implicitly stored in the parameters of AI models [242, 243]. On the other hand, ome AI systems store long-term memory in external storage medias, such as databases, outside the AI models [235, 244, 13]. Such long-term memory can be stored in its raw form, like text notes or structured labels, in format of relational model [235, 10], enabling AI systems to retrieve and utilize this information when needed to support it in performing tasks; memory stored in external media can also take the form of vectors [244, 245], which more closely resembles the specific encoding process of human brains [25] (Sec. 3.2.1).\nBased on these observations, we categorize AI long-term memory into non-parametric memory (Sec. 4.1) and parametric memory (Sec. 4.2), following the criteria illustrated by Lewis et al. [27] and Mallen et al. [28] and depicted in Fig. 5. Specifically, non-parametric memory refers to AI long-term memory stored in external media, while parametric memory refers to AI long-term memory stored within the model's parameters. A key distinction is that the model parameters are updated during the storage process only in the case of parametric memory. The processing mechanisms of non-parametric and parametric memory are shown in Fig. 4. In the subsequent sections, we offer a comprehensive discussion on the categorization of AI's long-term memory, review relevant literature, and identify both key challenges and potential solutions. Recognizing the prominent role of (large) language models in related works, we highlight these models as illustrative examples of AI systems in certain sections, while maintaining a broader scope."}, {"title": "4.1 Non-Parametric Memory", "content": "Non-parametric memory refers to long-term memory that is stored externally to the AI models. This type of memory can be retrieved based on specific cues when performing tasks. Retrieval-Augmented Generation (RAG) [246, 247] is an example framework that leverages non-parametric memory. RAG retrieves information from external data sources (\"non-parametric memory\") and produces responses that are informed by the retrieved information. We explore the related work of storage, retrieval and forgetting of non-parametric memory in Sec. 4.1.1, Sec. 4.1.2 and Sec. 4.1.3."}, {"title": "4.1.1 Storage of Non-Parametric Memory", "content": "Non-parametric memory can be stored in various media, such as databases, file systems, and computer memory. File systems are used by computer operating systems to efficiently store, organize, manage, and access data on disks [248, 249]. Computer memory, on the other hand, provides temporary storage space for a computer [250, 251]. Among these storage options, databases are particularly noteworthy for their scalability and maintenance efficiency, making them the preferred medium for accessing non-parametric memory. The databases provide diverse storage options for different types of non-parametric memory. For example, sparse features derived from user interactions can be stored in relational databases [237] for use in recommender systems [252], whereas vectorized document chunks can be stored in vector databases [233, 234] for RAG systems [246, 247]. The following sections illustrate how these two types of database are utilized for storing non-parametric memory.\n\u2022 Relational database. Relational databases store data using a relational model [236, 237]. For example, consider a structured data \"tiger\" - \"belongs to\" - \"feline\". In a relational database, this can be stored as a record in a table representing a collection of animals. These databases support encoding of structured non-parametric memory. Operations on data in relational databases can be performed using Structured Query Language (SQL) [253]. Several studies leveraged LLMs to generate SQL operations for storing, manipulating, and retrieving non-parametric memory in relational databases. For instance, Luo et al. [10] utilized LLMs to generate SELECT SQL operations, which are used to select entries that satisfy given conditions, to retrieve long-term memory from a relational database. Similarly, Hu et al. [235] used LLMs to convert the original queries to multi-step SQL commands to perform INSERT (insert a new entry), UPDATE (update an existing entry), SELECT, and DELETE (remove an existing entry) operations, which enables the flexible handling of non-parametric memory.\n\u2022 Vector Database. Traditional relational databases require highly structured data and are not effective at data types like texts, images, and audios [254]. To address this limitation, vector databases have been developed to store vectors encoded from various types of data, making them more suitable for unified storage of these unstructured data types, and supports more efficient retrieval based on vector similarity [233, 234]. Non-parametric memory suitable for storage in vector databases can be derived from representation vectors of different modalities (e.g., text, images) obtained through contrastive learning [228, 229, 255], language representation vectors acquired via pre-training methods like masked word prediction and next sentence prediction [225, 256, 257], or key and value vectors from the attention mechanism in Transformer models [258, 259, 260, 192]. Moreover, compared to traditional indexing techniques in relational databases such as B-trees and hash tables, indexing techniques specialized for high-dimensional vectors can be adopted in vector databases, such as indexing of Locality-Sensitive Hashing (LSH) [218] and Hierarchical Navigable Small World (HNSW) graphs [221]. These indexing methods enable the efficient storage of non-parametric memory. Multiple studies have demonstrated the advantages of using vector databases to store non-parametric memory. For example, Zhang et al. [244] utilized vector databases to provide personalized long-term memory for LLMs, which enhances the personalization of AI assistants. Shen et al. [13] explored the use of vector databases to enhance the long video understanding capability of AI systems by encoding the natural language descriptions of video frames into vectors. This can be considered as long-term memory within video contexts.\nIn summary, relational databases can be used to store structured data in non-parametric memory [236, 237, 10, 235], while vector databases are suitable for storing non-parametric memory of various modalities [233, 244]. Considering the diversity of non-parametric memory, vector databases are often more appropriate for their storage."}, {"title": "4.1.2"}]}