{"title": "Run-time Monitoring of 3D Object Detection in Automated Driving Systems Using Early Layer Neural Activation Patterns", "authors": ["Hakan Yekta Yatbaz", "Mehrdad Dianati", "Konstantinos Koufos", "Roger Woodman"], "abstract": "Monitoring the integrity of object detection for errors within the perception module of automated driving systems (ADS) is paramount for ensuring safety. Despite recent advancements in deep neural network (DNN)-based object detectors, their susceptibility to detection errors, particularly in the less-explored realm of 3D object detection, remains a significant concern. State-of-the-art integrity monitoring (also known as introspection) mechanisms in 2D object detection mainly utilise the activation patterns in the final layer of the DNN-based detector's backbone. However, that may not sufficiently address the complexities and sparsity of data in 3D object detection. To this end, we conduct, in this article, an extensive investigation into the effects of activation patterns extracted from various layers of the backbone network for introspecting the operation of 3D object detectors. Through a comparative analysis using Kitti and NuScenes datasets with PointPillars and CenterPoint detectors, we demonstrate that using earlier layers' activation patterns enhances the error detection performance of the integrity monitoring system, yet increases computational complexity. To address the real-time operation requirements in ADS, we also introduce a novel introspection method that combines activation patterns from multiple layers of the detector's backbone and report its performance.", "sections": [{"title": "1. Introduction", "content": "Effective and faithful perception of the surroundings is crucial for automated driving systems (ADS), as failure to capture the road traffic conditions can pose serious safety concerns, possibly leading to incidents that may involve fatalities or severe injuries. This highlights the need for perception systems which can robustly handle runtime errors, necessitating continuous monitoring mechanisms of the perception system's integrity. Once a perception error is detected, the integrity monitoring systems issue an alert that can trigger a driver takeover in Level 3 or execution of a Minimum Risk Manoeuvre in Level 4 ADS.\nState-of-the-art (SOTA) object detection mechanisms that leverage various types of deep neural networks (DNNs) have recently shown remarkable performance on several benchmarks and continue to improve. Despite these advancements, object detectors in ADS are not infallible, especially in the complex and dynamic driving domain, due to the broad range and complexity of driving scenarios involving several road users as well as due to the sensitivity of perception sensors to various impairments, noise, occlusions and faults. A common approach to enhance safety and trust in ADS is the deployment of runtime monitoring or \"introspection\" mechanisms that continuously assess the integrity of perception outputs."}, {"title": "2. Related Work", "content": "This section offers a concise review of introspection methods in ADS for object detection. Introspection mechanisms are categorised into confidence-based, performance-based, inconsistency-based, and past experience-based methods. The majority of the SOTA is concerned with introspecting camera-based 2D object detection, while there are only a few studies focusing on 3D object detection. Those studies model or estimate realistic confidence and uncertainty values at the object level, concerning more on the probabilistic nature of the models rather than the safety of the overall system. Hence, what we do in this paper constitutes a novel contribution to the SOTA introspection of LiDAR-based 3D object detection.\nConfidence-based Introspection: This category contains the studies modelling the uncertainty/confidence in object detection. Key studies include testing various confidence mechanisms on point cloud datasets, and Cen et al.'s unsupervised clustering approach for open-set 3D object detection, where uncertainty is quantified using Euclidean distances from raw points to class-specific 'prototypes'.\nPerformance-based Introspection: This method focuses on detecting performance drops in object detection metrics, where mAP is the common metric used. For instance, the authors in employed global pooling to extract features like mean and standard deviation from CNN outputs, predicting mAP drops for error detection. The study in enhanced this approach with temporal infor-"}, {"title": "3. Method", "content": "This section introduces a novel introspection mechanism for 3D object detection on a per-frame basis, leveraging extracted activation maps from various stages of the object detector's backbone network, as well as the processed point cloud data. Unlike existing introspection studies on 2D object detection that predominantly focus on latent activation patterns for error identification, our approach addresses the unique challenges of 3D object detection with point cloud data. Point clouds, characterised by inherent sparsity, present significant challenges in 3D object detection tasks, differing from the dense information present in images. Furthermore, while 2D introspection models, such as those in, learn the relationship between activation patterns and mAP, the authors in have highlighted that mAP can be misleading when there are different classes of objects present in the frame. For example, if a scene consists of multiple vehicles and a single pedestrian, where the pedestrian and majority of the vehicles are detected, but few vehicles are missed, the frame can still be labelled as no-error regardless of the missed vehicles' location. Hence, in this paper, we opt to identify the relationship between activation patterns and missed objects (false negatives) from the 3D point cloud to provide better safety, i.e., if at least one object is not detected, the frame is classified as 'Error'.\nAcknowledging the above-mentioned limitations, the proposed mechanism employs an early-level fusion strategy, concatenating early-layer, mid-layer and output activation patterns from the backbone network into the introspection model. Including earlier and middle layers that have less fine-tuned activation patterns than the latent features aims at enhancing the introspector's ability to discern patterns indicative of missed objects. Consequently, it provides a robust introspective analysis, yielding a better understanding of the data and the intricacies of the neural network's processing without increasing the computational complexity and, hence, without compromising the model's real-time performance."}, {"title": "4. Performance Evaluations", "content": "This section presents the experimental setup and performance evaluation of our study comparing introspection mechanisms for 3D object detection in ADS utilising neural activation patterns from different layers. Before that, we justify the selection of object detectors, driving datasets, adapted SOTA introspection mechanisms, and key performance indicators."}, {"title": "4.1. Object Detectors", "content": "We investigate the behaviour of introspection systems on 3D object detection using two popular models. First, we utilise PointPillars , a widely used baseline model in 3D object detection in ADS. PointPillars proposes a novel encoder architecture, transforming the irregular and sparse 3D point clouds generated by LiDAR sensors into a structured format called \"pillars\". These pillars are essentially vertical columns that capture the points in a defined columnar space, simplifying the complexity of 3D data processing. Once the data is organised into pillars, PointPillars employs a neural network to learn distinctive features from each pillar. The model projects these learned features onto a pseudo-image, enabling the use of a 2D CNN for further processing. PointPillars is used as the 3D object detector in the earlier version of the Autoware Foundation's open-source software for self-driving vehicles.\nAdditionally, for a comprehensive evaluation of introspection in recent detection mechanisms, we employ the CenterPoint model. This model is distinct in its approach to object detection, as it focuses on identifying the center of objects first, and then regresses to define the bounding box. This is in contrast with other detectors that directly regress the corners of the bounding box. The fundamental motivation behind CenterPoint is the property that the centers of objects remain invariant to rotation. That ensures reliable detection even when vehicles assume different orientations due to varying road conditions. In addition, CenterPoint is the model utilised in Autoware Foundation's never versions, \"Autoware.Universe\". In terms of implementation and training of these models, we have employed OpenMMLab's OpenMMDet3D framework and utilised the pre-trained models on Kitti and NuScenes datasets. In this framework, both models utilise a network called SECOND, which applies sparse convolution operations to provide faster operation with the sparsity of the LiDAR's point cloud data."}, {"title": "4.2. Datasets", "content": "To measure the performance of introspection mechanisms, we utilise two widely-used datasets based on their use in both introspection and ADS domains: Kitti and NuScenes. The Kitti dataset consists of over 14,000 annotated images captured by a camera and a Velodyne LiDAR mounted on a car driving through urban environments in Karlsruhe, Germany. The training set contains 7,481 annotated samples, while test set includes 7,518. The benchmarking is typically done using only three classes: car, pedestrian, and cyclist. Additionally, the data labelling only covers objects in front of the vehicle.\nThe NuScenes dataset contains 1,000 diverse driving scenes captured across various urban locations. It contains, featuring multiple camera feeds, RADAR, and a full 360-degree LiDAR. In total, the NuScenes dataset includes 1.4 million images, 390k LiDAR sweeps, and 1.4 million 3D bounding box annotations across 23 object classes. The dataset is split into a training set, a validation set, and a test set. Additionally, the dataset provides detailed annotations not just for objects in front of the vehicle but in its entire surroundings, offering a 360-degree perspective."}, {"title": "4.3. Introspection Mechanisms", "content": "For comparison purposes, we adapt the operation of two SOTA introspection mechanisms for 2D object detection, which demonstrated strong performance in the field, to become capable of handling 3D point cloud data. Each method applies a distinct processing technique on the raw activation layers, as explained below."}, {"title": "4.4. Introspection Training and Implementation", "content": "To generate the error datasets, we perform object detection using Kitti and NuScenes datasets with their corresponding 3D object detection model. In this process, we extract the activation maps and generate the error labels. To label a sample as an error, we go through each ground truth object and check if there is no predicted bounding box that has an intersection over a union greater than 0.7 with the ground truth object bounding box.\nTo train the introspection network, we have utilised stochastic gradient descent (SGD) optimiser with focal loss function [25]. Due to the imbalance in the error datasets, we have calculated class weights using training data and fed to the loss calculation along with a gamma ($\\gamma$) value of five to mitigate the issue. We also implemented an early stop mechanism with a patience setting of 15 epochs, coupled with a learning rate scheduler that scales down the learning rate by a factor of 0.7 after a patience period of 10 epochs. All networks were trained for a total of 200 epochs using this approach. We have experimented with learning rates of 0.01, 0.001, and 0.0005, among which 0.01 yielded the best performance. The batch size for this training was set at 64. Additionally, for neural network development and training, PyTorch and Torchvision were utilised. Detection evaluation and metric calculation is done with Torchmetrics [13]. Complexity calculation and inference time calculation are done with thop and time library in Python. Finally, all experiments are done on a machine equipped with an Intel(R) Core(TM) i9-10980XE CPU and NVIDIA RTX 3090 GPU."}, {"title": "4.5. Performance Metrics", "content": "Since the design of the introspection method is based on a binary classification output for all models considered in this paper, the following metrics are selected to evaluate the performance.\n*   Area Under Receiver Operating Characteristic Curve (AUROC): It provides an indicator of how well a classifier distinguishes between the positive ('error') and negative ('no-error') classes. It measures the model's ability to avoid false classifications, with a higher AUROC indicating better performance.\n*   Recall (Positive and Negative): It measures the classifier's ability to correctly identify true positives and true negatives. Positive Recall (also known as Sensitivity or True Positive Rate) quantifies the proportion of actual positives correctly identified by the model. Negative Recall (also known as Specificity or True Negative Rate) quantifies the proportion of actual negatives that are cor-"}, {"title": "4.6. Performance Comparison", "content": "In this section, we present a thorough evaluation of error detection mechanisms for 3D object detection in ADS encompassing (i) the proposed introspection method jointly leveraging the processed point cloud (PPC), mid-layer activation patterns (MLA) and last layer activation patterns (LLA), (ii) an introspection model using either the PPC, or activation patterns from the mid-layer or the last layer, and (iii) the method based on statistical features (SF). We explore how activation patterns in different layers influence the model's confidence and the error detection efficiency providing useful insights on the quality of different learning representations for introspection in 3D object detection. Activation maps are also presented for qualitative analysis. Finally, we assess the practicality of these mechanisms in real-world ADS through a computational complexity analysis confirming their feasibility for real-time applications."}, {"title": "4.6.1 Detection Performance", "content": "As presented on , the proposed model provides a competitive result in all metrics compared to the ones using earlier layer activations in Kitti dataset. Unlike other models, where more balanced performance is presented, our proposed model has a tendency around positive class reducing false negative rate. On the other hand, in the NuScenes dataset, the proposed model provides a more balanced result while maintaining overall performance, indicating its adaptability and effectiveness in a more complex driving dataset.\nAlternatively, the earlier layers, PPC and MLA, show promising and competitive results. In the Kitti dataset, PPC shows a preference for negative class detection, while MLA demonstrates a slightly more balanced approach with second-best AUROC. We also see our model provides competitive performance with a tendency to positive class detection. In the NuScenes dataset, both PPC and MLA perform well with MLA having highest AUROC, but still doesn't match the balanced efficiency of the proposed model. Also, it is evident that both PPC and MLA outperform LLA which is in line with our hypothesis on this study.\nLastly, the LLA and SF models exhibit disparities in their performance. LLA shows moderate effectiveness, but its lower recall for the negative class in both datasets indicates a potential tendency in detecting 'error' cases. This trait is accentuated in the SF model whose very low recall for the negative class and lowest AUROC, especially in the Kitti dataset, suggests a model that is highly skewed towards positive class detection, potentially at the expense of overall predictive accuracy."}, {"title": "4.6.2 Model Confidence", "content": "provides a comparative analysis of the confidence distributions for four distinct cases evaluated against the two datasets, Kitti and NuScenes. Specifically, the data is organised into four columns/categories True Positives (TP), False Positives (FP), False Negatives (FN), and True Negatives(TN) with confidence values (softmax outputs) that range between 0.5 and 1. One may see that the distribution of confidence scores varies between the datasets, indicating that each dataset has unique learned characteristics that influence the introspector's confidence.\nThe PPC mechanism reveals higher median confidence for TN and TP than FP and FN cases in both datasets, while the distinction is more apparent on Kitti dataset. This suggests that, in Kitti, this mechanism may perform better compared to other mechanisms, which is in accordance with the results depicted in Table 1. Additionally, we see the introspection is more confident for TP compared to TN in NuScenes dataset which is also reflected in Table 1 indicating that the model is correct with TP and TN predictions.\nThe MLA mechanism demonstrates consistent high confidence in both TPs and TNs in NuScenes, where it performs the best according to Table 1. For FP and FN, although the ranges are wide, the majority of the predictions attain low confidence suggesting a dependable performance in correctly identifying positive and negative outcomes. In the Kitti dataset, while showing a similar pattern, the con-"}, {"title": "4.6.3 Computational Complexity", "content": "In this section, the computational requirements of each mechanism, focusing on the inference time and the number of floating point operations (FLOPs) metrics are considered. For this purpose, inference times of each model both on CPU and GPU, along with the FLOPs values, are provided for computational complexity comparison in Table 2. The 'Proposed' method exhibits the lowest inference time on the CPU and a close second on GPU, significantly surpassing the performance requirements with GPU times under 2ms. The 'PPC' method, while still under the threshold of 100ms, is considerably slower on the CPU, which may be critical in CPU-dependent scenarios. The reason for the slower inference is the higher resolution of earlier layers. On the other hand, the 'MLA' and 'LLA' methods offer a balanced trade-off between inference speed and FLOPs. In terms of FLOPs values, we see a similar trend with PPC being the highest, and again due to the resolution of the activation maps we have the lowest with LLA. As presented in the Table 2, the proposed mechanism offers a significant reduction compared to the 'PPC' mechanism and a slight improvement compared to 'MLA' while preserving the error detection performance characteristics presented in Table 1."}, {"title": "4.6.4 Qualitative Comparison", "content": "This section aims to provide an intuitive understanding of the effects that the activation patterns have on the decision-making of the introspection models considered in this pa-"}, {"title": "5. Summary & Conclusions", "content": "In this research, we investigated the impact of earlier and concatenated layers of neural activation patterns on the error detection performance of 3D object detection in automated driving systems (ADS). We hypothesised that in the context of point-cloud data, characteristic of 3D environments, early layers can enhance the error detection capabilities. To test this, we employed PointPillars and CenterPoint to extract activations from various network stages and create an error dataset, focusing on the identification of false negatives to enhance safety and trust in ADS. We then trained a separate neural network on the error dataset using either the early layer activations or a combination of activations.\nOur findings reveal that using early layer neural activation patterns enhances the error detection capability in 3D object detection, as compared to using only the last layer activations, at the cost of processing time and computational resources owing to the higher resolution. Combining activations from multiple layers into the introspection framework offers a more balanced approach in terms of performance and complexity. In addition, it empowers the introspection model with the capability to successfully identify object detection errors without raising unnecessary alerts, which is paramount for ADS. Given that introspection in 3D object detection, particularly in ADS, is a relatively unexplored subject, further research is imperative. Future studies should focus on developing metrics for constructing error datasets, evaluating introspection performance in various 3D object detection applications, and assessing the domain-shift capabilities of introspection mechanisms. Moreover, more sophisticated methods for utilising activation patterns from multiple neural network layers should be explored."}]}