{"title": "RSMLP: A light Sampled MLP Structure for Incomplete Utterance Rewrite", "authors": ["Lunjun Liu", "Weilai Jiang", "Yaonan Wang"], "abstract": "The Incomplete Utterance Rewriting (IUR) task has garnered significant attention in recent years. Its goal is to reconstruct conversational utterances to better align with the current context, thereby enhancing comprehension. In this paper, we introduce a novel and versatile lightweight method, Rewritten-Sampled MLP (RSMLP). By employing an MLP-based architecture with a carefully designed down-sampling strategy, RSMLP effectively extracts latent semantic information between utterances and makes appropriate edits to restore incomplete utterances. Due to its simple yet efficient structure, our method achieves competitive performance on public IUR datasets and in real-world applications.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, conversation-based tasks have gained in-creasing attention, such as dialogue response generation [1] [2] and dialogue understanding [3] [4]. The advent of Large Language Models (LLMs) has shifted the focus from single-turn to multi-turn dialogues. In multi-turn dialogue scenarios, users tend to use incomplete utterances, which often omit or reference entities or concepts from previous dialogue context, a phenomenon known as ellipsis and anaphora. Studies have shown that over 70% of utterances exhibit these phenomena [5], which significantly impacts the accuracy of semantic understanding in dialogue systems.\nTo address this issue, recent research has introduced the Incomplete Utterance Rewriting (IUR) task [6] [7] [8]. The goal of the IUR task is to rewrite incomplete utterances into new sentences with the same semantics, where the new sentences can be understood without referring to the context. As shown in Table I, (u1, u2, u3) form a multi-turn dialogue, where u3 is an incomplete utterance that omits \"Shenzhen\" and uses \"this\" to refer to \"wet\". The revised u4 is a complete sentence that can be understood independently. By explicitly rewriting the omitted information into the latest utterance, downstream dialogue models only need to process the final utterance. This significantly alleviates the model's burden during long-term reasoning.\nAlthough significant progress has been made in previous work, balancing the quality of sentence rewriting with autoregressive generation speed remains a challenge for the IUR task. To improve speed, RUN [9] framed the IUR task as a semantic segmentation problem based on feature mappings constructed from word embeddings. RAU [10] extracted coreference and ellipsis relationships from the self-attention weight matrices of transformers. Both approaches utilize U-Net, a complex model that significantly impacts rewriting efficiency. To enhance quality, SRL [11] trained a semantic role labeling model to emphasize the core meaning of each input dialogue, preventing the rewriter from violating key content. They manually annotated SRL information for over 27,000 dialogue turns, a time-consuming and costly process. PAC [7] constructs a \"pick-and-combine\" model to extract omitted tokens from the context in order to restore incomplete sentences. RAST [12] formulated the IUR task as a span prediction problem of deletion and insertion, using reinforcement learning to improve fluency, which heavily depends on the encoder's output.\nIn this paper, we explore the use of a light neural network architecture for sentence rewriting, specifically utilizing a simple MLP architecture based on a down-sampling strategy. Our approach involves using down-sampling and MLP to sequentially refine local and global semantic information. Subsequently, we perform similarity calculations on the output semantic matrices to obtain similarity feature maps, which are then used to construct a token-level edit matrix. Finally, we edit incomplete utterances based on the predicted edit type tokens to generate the rewritten sentences. Our contributions are summarized as follows:"}, {"title": "II. RELATED WORKS", "content": null}, {"title": "III. METHOD", "content": "In this section, we will provide a detailed explanation of our method."}, {"title": "A. Problem Definition", "content": "We formally define the utterances that need to be rewritten. For multi-turn dialogue utterances (u1, u2, ..., ut), we con-catenate all the context utterances (u1, u2, ..., ut\u22121) into a word sequence of length M, denoted as c = (c1, c2, ..., cM ), and use a special [SEP] token to separate utterances from different contexts. The final utterance ut in the dialogue is defined as the incomplete utterance, represented as a word sequence of length N, x = (x1, x2, ..., xN )."}, {"title": "B. Architecture", "content": "As shown in Figure 1, we propose a simple model archi-tecture composed of four components: an Encoder, a Local Feature Extraction Unit, a Global Feature Extraction Unit, and a Similarity Feature Matrix. Since our core concept is an MLP based on a sampling mechanism, we named the model Rewritten-Sampled MLP (RSMLP).\nEncoder We use BERT [13] as our Encoder to extract contextual information between utterances. First, we concatenate the context utterance c with the incomplete utterance x, forming a joint token sequence of length L = M + N. This sequence is then fed into BERT to produce a word embedding matrix A \u2208 RL\u00d7D.\nLocal Feature Extraction Unit To capture both local and global information, we divide the core of our framework into two components: the Local Feature Extraction Unit and the Global Feature Extraction Unit. The design of the Local Feature Extraction Unit is primarily inspired by the concept of down-sampling. Since our sentence rewriting task involves editing and replacing parts of the original sentence-similar to classification tasks-down-sampling effectively balances the model's ability to recognize different categories, thereby enhancing its rewriting capabilities. To address the issue of potential information loss caused by na\u00efve down-sampling methods, we introduce continuous sampling, which helps the model capture local information more accurately.\nOur sampling method converts each multi-turn dialogue sequence of length L into multiple non-overlapping subsequences of length B, resulting in \\frac{L}{B} subsequences. The word matrix can then be decomposed as:\nA = {A1, A2, ..., A\\frac{L}{B}}\nwhere each Ai \u2208 RB\u00d7D, i \u2208 [1, \\frac{L}{B}] is a submatrix, and A\u2208 RB\u00d7\\frac{L}{B}\u00d7D. This segmentation divides the sequence into continuous short fragments, allowing the model to focus more on local semantic information. Additionally, this design improves training and inference efficiency, as the model only processes a small portion of the sequence at a time.\nNext, we feed the subsequences into the Local Mix Block, which is the basic building block designed for local information exchange, primarily consisting of MLPs. The Local Mix Block includes two fully connected layers and a non-linear activation function, all applied to 2D matrices. The purpose of the Local Mix Block is to facilitate information exchange along two different dimensions, producing another feature matrix. The resulting matrix can be viewed as the feature extraction of the input matrix. The information exchange along the embedding dimension is referred to as input projection:\nZ = W2(\u03c3(W1A + B1))T + B2\nwhere Z = {Z1, Z2, ..., Z\\frac{L}{B}} \u2208 RB\u00d7\\frac{L}{B}\u00d7S is the output matrix, and W1, B1, W2, B2 represent the weights and biases"}, {"title": "IV. EXPERIMENTS", "content": null}, {"title": "A. Experimental Setup", "content": "Datasets We conducted experiments on IUR benchmarks from three different domains and languages: Restoration 200k [7], REWRITE [5], and CANARD [18]. The datasets were split into training, evaluation, and testing sets with the following proportions: 80%/10%/10% for Restoration - 200k, 90%/10%/- for REWRITE, and 80%/10%/10% for CANARD. These datasets consist of multi-turn dialogue contexts, in-complete sentences to be rewritten, and examples of correct rewrites.\nBaselines We compared the performance of RSMLP with the following methods: transformer-based pointer generator (T-Ptr-Gen) [19], Seq2Seq model L-Gen [20], the hybrid pointer generator (L-Ptr-Gen) [19], L-Ptr-\\lambda/T-Ptr-\\lambda [5], PAC [7], CSRL [21], SARG [22], RAST [12] and RUN (BERT) [9].\nEvaluation Following previous practices, we used BLEU [23], ROUGE [24], Exact Match (EM), and Restoration Score [7] as automatic evaluation metrics to compare our proposed method with other approaches.\nModel Setting We used bert-base-chinese from the HuggingFace community [25] as our pre-trained BERT model and fine-tuned it as part of the training process. The model has 12 layers and 12 attention heads. We optimized the model using Adam [26] with a learning rate of 1e-5 and computed the loss using weighted cross-entropy."}, {"title": "B. Main Results", "content": "Tables II and III present the experimental results on the Restoration-200K and Rewrite datasets, respectively. For the Restoration dataset, our proposed RSMLP model outperforms the previously best-performing model, RUN (BERT), on nearly all metrics. In particular, the metrics P1, P2, and P3 show an average improvement of 3.5 points, while F1, F2, and F3 also exhibit significant gains. This demonstrates the effectiveness of our architecture, as RSMLP successfully captures both local and global information, thereby enhancing the rewriting capability. Furthermore, although the differences are small, RSMLP also surpasses previous models in terms of BLEU and ROUGE scores, supporting the robustness of our model.\nFor the Rewrite dataset, RSMLP similarly achieves better performance across nearly all metrics. Notably, our method improves the EM score by 1.5 points. This indicates that the rewritten sentences generated by our model perfectly match the reference sentences, showcasing its deep understanding of contextual semantics."}, {"title": "C. Inference Speed", "content": "Table IV presents the inference speed results for a single sentence. All models were run on a single NVIDIA 3070 Laptop, implemented using PyTorch. We can observe that compared to the state-of-the-art (SOTA) methods, our RSMLP model achieves the fastest inference speed. Specifically, it is 21 times faster than T-Ptr-Gen (n_Beam=1). Furthermore, compared to the second-fastest model, RUN (BERT), our approach also demonstrates superior speed. This highlights that our lightweight MLP architecture significantly enhances sentence inference speed while maintaining high rewriting quality."}, {"title": "D. Ablation Study", "content": "To validate the effectiveness of the Local Feature Extraction Unit (LU) and Global Feature Extraction Unit (GU), we conducted a comprehensive ablation study, as presented in Table V.\nAs expected, the absence of both feature extraction units resulted in a decrease across all metrics, demonstrating that our framework significantly enhances model performance. Moreover, using only one of the units also yielded suboptimal results due to the lack of understanding of certain aspects of the information. This further confirms that RSMLP achieves outstanding performance only when both local and global semantic information are simultaneously utilized."}, {"title": "E. Real-World Experiment", "content": "We integrated RSMLP into the vehicle-based Retrieval Augmented Generation (RAG) pipeline for real-world experimentation. This system is designed to quickly address issues users encounter while operating their vehicles. In this real-world scenario, referential and elliptical phenomena in multi-turn dialogues lead to difficulties in retrieving the correct documents on the RAG recall side. Our experiments aim to address this issue. As shown in Table VI, after integrating RSMLP, the RAG model achieved a recall accuracy of 96% in multi-turn scenarios, with an inference speed of only 70 milliseconds per sentence. Moreover, our model's ROM usage is only slightly larger than that of BERT, making it highly suitable for edge devices with limited computational power and memory, and demonstrating excellent applicability in such environments."}, {"title": "V. CONCLUSIONS", "content": "In this paper, we propose a simple and efficient model for the IUR task, which utilizes an MLP architecture based on a down-sampling strategy. Our model achieves advanced performance and inference speed on public IUR datasets. Future work will involve exploring the extension of this framework to other conversational domains."}]}