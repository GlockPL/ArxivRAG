{"title": "Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning", "authors": ["Abdulkadir \u00c7elikkanat", "Andres R. Masegosa", "Thomas D. Nielsen"], "abstract": "Obtaining effective representations of DNA sequences is crucial for genome analysis. Metagenomic binning, for instance, relies on genome representations to cluster complex mixtures of DNA fragments from biological samples with the aim of determining their microbial compositions. In this paper, we revisit k-mer-based representations of genomes and provide a theoretical analysis of their use in representation learning. Based on the analysis, we propose a lightweight and scalable model for performing metagenomic binning at the genome read level, relying only on the k-mer compositions of the DNA fragments. We compare the model to recent genome foundation models and demonstrate that while the models are comparable in performance, the proposed model is significantly more effective in terms of scalability, a crucial aspect for performing metagenomic binning of real-world datasets.", "sections": [{"title": "1 Introduction", "content": "Microbes influence all aspects of our environment, including human health and the natural environment surrounding us. However, understanding the full impact of the microbes through the complex microbial communities in which they exist, requires insight into the composition and diversity of these communities [19].\nMetagenomics involves the study of microbial communities at the DNA level. However, sequencing a complex microbial sample using current DNA sequencing technologies [27] rarely produces full DNA sequences, but rather a mixture of DNA fragments (called reads) of the microbes present in the sample. In order to recover the full microbial genomes, a subsequent binning/clustering step is performed, where individual DNA fragments are clustered together according to their genomic origins. This process is also referred to as metagenomic binning [19, 9]. The fragments being clustered during the binning process consist of contiguous DNA sequences (contigs) obtained from the reads through a so-called assembly process [29] (contigs are generally longer and less error-prone than the reads).\nMetagenomic binning typically involves comparing and clustering DNA fragments using a distance metric in a suitable genome representation space. State-of-the-art methods for metagenomic binning typically rely on representations that include or build on top of the k-mer profiles of the contigs [17, 12, 18]. These representations have mostly been studied from an empirical perspective [6], although general theoretical analyses into their representational properties have also been considered [25]. With k = 4 (i.e., tetra-nucleotides) a 256-dimensional vector is used to describe the genome, each entry in the vector encoding the frequency of a specific k-mer (e.g., ACTG, ATTT) in the genome sequence. The k-mer representation of a sequence thus has a fixed size and is independent of sequence length and downstream analysis tasks, providing a computationally efficient representation."}, {"title": "2 Backgroud and Related Works", "content": "When analyzing the microbial content of biological samples (e.g., soil samples or samples from the intestine), we deal with genomic material originating from multiple different species. For such analyses, the general workflow consists of sequencing the DNA fragments in the sample, producing electrical signals that are subsequently converted into sequences of letters corresponding to the four DNA bases (A, C, T, G). During the sequencing process, the full DNA sequences are fragmented into smaller subsequences (called reads), resulting in millions or even billions of reads for each sample. Depending on the sequencing technology being used, reads are typically either classified as short reads (100-150 bases) or long reads (2k-30k bases), and while long reads are generally preferable, they are also more prone to translation errors.\nIdentifying the microbial composition of a sample involves clustering the DNA fragments according to their genomic origin (a process referred to as metagenmoic binning). Clustering the DNA fragments relies not only on a representation of the genome fragments, but typically also includes information about the read coverages in the sample, reflecting the relative abundances of the individual species that make up the sample[2].\nFor the current paper, the focus is on representations of DNA fragments. Existing works on metagenomic binning typically either rely on predefined features (e.g., [9, 17, 12]) or, more recently, on genome foundation models (e.g., [5, 16, 32]) for representing the DNA fragments. Predefined features for metagenomic binning include the k-mer frequencies of the genome (e.g., for k = 4, the genome is represented by a 256-dimensional vector), which have shown to exhibit a degree of robustness across different areas of the same genome [4]. These k-mer vectors/profiles are either used as direct representations of the DNA fragments as in, e.g., METABAT2[9], VAMP [17], and SEMIBIN2 [18] or is used for learning k-mer-based embeddings [15, 21] in the spirit of WORD2VEC [14].\nMore recently, genome foundation models have also been proposed, which include DNABERT [8], DNABERT-2 [31], HYENADNA [16], and DNABERT-S [32]. These foundation models provide embedding of the raw DNA fragments as represented by the sequences of four nucleotide letters.\nIn this work, we show that although the contextualized embeddings produced by foundation models provide a strong basis for downstream genome analysis tasks, the complexity of the models also makes them less scalable to the vast amounts of data currently being generated by the state-of-the-art sequencing technologies. Consequently, we consider more lightweight models and explore the use and theoretical basis for models relying on k-mer representations of DNA fragments."}, {"title": "3 k-mer embeddings", "content": "As we discussed in the previous section, the metagenomic binning problem aims to cluster the sequences (i.e. reads) according to their respective genomes. For the sake of the argument, we denote with $\\ell : \\mathcal{R} \\rightarrow [K]$ the function that maps each read to the (index) ground-truth genome from which the read originates. Here, we use $\\mathcal{R}$ to denote the set of reads where each read is supposed to originate from one of the $K$ genomes.\nPerforming clustering directly on the reads has been shown to provide very poor performance [11], mainly because reads lie in a complex manifold in a very high dimensional space. A well-tested approach is to instead embed each of the objects in a lower dimensional space, known as the embedding or latent space, whose structure is much closer to Euclidean space, where clustering is far simpler to perform. More formally, we characterize the problem as follows:\nProblem Definition. Let $\\mathcal{R} \\subset \\Sigma^+$ be a finite set of reads with a genome mapping function $\\ell$ where $\\Sigma = \\{A,C,T, G\\}$. For a given threshold value $\\gamma\\in \\mathbb{R}^+$, the objective is to learn an embedding function $\\mathcal{E}: \\mathcal{R} \\rightarrow \\mathbb{R}^d$ that embeds reads into a low-dimensional metric space $(\\mathcal{X}, d_{\\mathcal{X}})$, usually a Euclidean space, such that $d_{\\mathcal{X}}(\\mathcal{E}(r), \\mathcal{E}(q)) \\leq \\gamma$ if and only if $\\ell(r) = \\ell(q)$ for all reads $r, q \\in \\mathcal{R}$ where $d < \\mathbb{R}$.\nOnce we establish an embedding function like the one described earlier, it becomes, in principle, straightforward to employ a simple clustering algorithm to bin or group the reads. However, for this purpose, the embedding function $\\mathcal{E}$ must be capable of distinguishing the intrinsic features of the various genomes, producing similar latent representations for reads that originate from the same"}, {"title": "3.1 k-mers are a powerful representation of reads", "content": "The use of k-mer profiles to represent reads helps overcome several challenges encountered during the clustering or binning of reads. These challenges include (i) the variation in read lengths in practical scenarios, such as in genome sequencing where read lengths can differ significantly, (ii) ambiguity in read direction, which is a result of reads lacking inherent directionality, complicating the analysis, and (iii) the equivalence of a DNA sequence to its complementary sequence because DNA is composed of two complementary strands, meaning the information from one strand corresponds to that from its complementary strand.\nAn initial important question concerns the identifiability of reads, which examines to what extent different reads share the same k-mer profiles. We will call the reads that can be uniquely reconstructed from their given k-mer profile as identifiable and this is crucial because if many reads possess the same k-mer profile, they will invariably be grouped into the same cluster, potentially leading to the loss of significant information. In this context, Ukkonen et al. [25] conjectured in their study on the string matching problem that two sequences sharing the same k-mer profile could be transformed into one another through two specific operations, and this claim was later proved by Pevzner [20]. However, these specified operations fail to consider cases where sequences include repeated overlapping occurrences of the same k-mer.\nIn this regard, in Theorem 3.1, we demonstrate that a read can be perfectly reconstructed from its k-mer profile under certain conditions, which become less restrictive with larger k values. In the following theorem, we use $r_i \\cdots r_j$, with $i < j$, to denote any subsequence of a read $r$ that includes consecutive nucleotides from position $i$ to position $j$.\nTheorem 3.1. Let $r$ be a read of length $l$. There exists no other distinct read having the same k-mer profile if and only if it does not satisfy any of the following conditions:\n1. $r_1\\cdots r_{k-1} = r_{\\ell-k-2}\\cdots r_{\\ell}$ and $r_i \\neq r_1$ for some $1 < i < \\ell-k-2$.\n2. $r_i\\cdots r_{i+k-2} = r_j\\cdots r_{j+k-2}$ and $r_g\\cdots r_{g+k-2} = r_h\\cdots r_{h+k-2}$ for some indices $1 < i < g<j<h<\\ell- k + 2$ where $r_{i+k-1}\\cdots r_{g-1} \\neq r_{j+k-1}\\cdots r_{h-1}$.\n3. $r_i\\cdots r_{i+k-2} = r_j\\cdots r_{j+k-2} = r_h\\cdots r_{h+k-2}$ for some indices $1 < i < j < h <\\ell-k+2$ where $r_{i+k-1}\\cdots r_{j-1} \\neq r_{j+k-1}\\cdots r_{h-1}$.\nIt is important to note that it is always possible to find an optimal $k^*$ value that ensures that each read does not meet any of the previously mentioned conditions and, in consequence, becomes identifiable. Clearly, when $k$ is equal to the length of the reads, all reads become identifiable. However, as $k$ increases, the k-mer profiles become more prone to errors, and it will be harder to identify the underlying patterns in the reads (in the extreme case scenario where $k$ equals the length of the reads, each read will correspond to a unique k-mer). Thus, using large values of $k$ is impractical. However, the results show that even with smaller $k$ values, identifiability could still be potentially achieved if not by all but by some of the reads. We hypothesize that the effectiveness of k-mer representations stems, in part, from this fact.\nAnother perspective to consider is the extent to which two similar reads share a similar k-mer profile. The identifiability approach from the previous result addresses this issue by establishing that if two reads have identical profiles, then the reads themselves are identical. However, identifiability is limited by the conditions outlined in Theorem 3.1, which may not always be met. The observation given in Proposition 3.2 provides a broader and more applicable finding.\nIt demonstrates that if two k-mers are similar according to the $\\ell_1$ distance, then the corresponding reads are also similar according to the Hamming distance in the read space. It is important to note that both the $\\ell_1$ and Hamming distances are natural measures for evaluating similarity in this context. Technically speaking, we show that the $\\ell_1$ distance between k-mer profiles can be upper"}, {"title": "3.2 Linear read embeddings", "content": "Below we consider two simple genome sequence models defining the embedding of a read as a linear combination of the k-mer representations. The first model (k-mer profile) does not involve any learning procedure and it is simply defined by the k-mer counts of the read, whereas the second model (Poisson model) expands on the k-mer profile model by explicitly representing the dependencies between k-mers. Both models will serve as baselines for more complex models.\nk-mer profile: First, consider the definition of k-mer profiles:\n$\\mathcal{E}_{KMER}(r) := \\sum_{x \\in \\Sigma^k} C_r(x) z_x$ (2)\nwhere $z_x$ represents the canonical basis vector for the k-mer $x \\in \\Sigma^k$, i.e. ($z_x \\in \\{(U_1,..., U_{|\\Sigma^k|}) \\in \\{0,1\\}^{|\\Sigma^k|} : \\sum_i U_i = 1\\} $).\nAs previously mentioned, our primary objective is to represent reads in a lower-dimensional space, where their relative positions in a latent space reflect their underlying similarities. By Equation 2, the k-mer profile of a read can also be considered as its embedding vector, but its entries are not independent. In other words, if we change one letter in a read, it can affect at most k different k-mer counts. In this regard, it might be possible to learn better representations than simple k-mer profiles.\nPoisson model: For a given read $r := (r_1 . . .r_{\\ell})$, it is easy to see that the consecutive k-mers in the read are not independent. For instance, the k-mers located at position indices $i$ and $i + 1$, (i.e. $x := r_i r_{i+k-1}$ and $y := r_{i+1}\\cdots r_{i+k}$), share the same substring $r_{i+1}\\cdots r_{i+k-1}$, which highlights the inherent dependencies between k-mers. Hence, we will learn the representation, $z_x$, of each k-mer, $x$, instead of using the canonical basis vectors. We propose to model the co-occurrence frequency of specific k-mer pairs within a fixed window size, $w$, using the Poisson distribution. In other words, $O_{x,y} \\sim Pois(\\lambda_{x,y})$, where $o_{x,y}$ indicates the number of co-appearances of k-mers, $x := r_i\\ldots r_{i+k-1}$ and $y := r_j\\cdots r_{j+k-1}$ for $|i - j| \\leq w$.\nIn order to achieve close representations for highly correlated k-mers, and distant embeddings for the dissimilar ones, we define the rate of the Poisson distribution as follows:\n$\\lambda_{x,y} := exp(-||z_x - z_y||^2) .$ (3)\nThe loss function used for training the embeddings with respect to the reads is simply defined in terms of the Poisson distribution model of the k-mer pairs:\n$\\mathcal{L}_{POIS}(\\{o_{x,y}\\}_{x,y}, \\Gamma, \\{\\vec{z}_x\\}_{x\\in\\Sigma^k}) := \\sum_{x \\in \\Sigma^k} \\sum_{y \\in \\Sigma^k} o_{xy} ||z_x - z_y||^2 + exp(-||z_x - z_y||^2) $ (4)"}, {"title": "3.3 Non-linear read embeddings", "content": "In the experimental section, we will show that the linear k-mer embeddings described previously outperform raw k-mer profiles in metagenomic binning tasks. However, the literature on machine learning frequently emphasizes that non-linear embeddings typically provide superior results when the data, such as genomic sequences in this context, exist in complex high-dimensional manifold spaces [33].\nWe design a simple and efficient neural network architecture utilizing self-supervised contrastive learning. Our model consists of two linear layers, and the first one takes k-mer profile features as input, projecting them into a 512-dimensional space. A sigmoid activation function is applied, followed by a batch normalization operation and a dropout with a ratio of 0.2. The second layer maps them into the final 256-dimensional embedding space.\nOur approach is inspired by previous methods in the context of metagenomic binning at the contig level [18]. The primary aim here is not to introduce a novel methodology for learning embeddings but to demonstrate that simple non-linear embeddings, built upon k-mer representations, can match the effectiveness of existing state-of-the-art genomic foundation models for metagenomic binning tasks while being significantly more scalable.\nThe methodology is graphically depicted in Figure 2. Initially, we create positive and negative pairs of read segments using the dataset provided. To create a positive pair, we split an existing read into two equal-sized segments. Conversely, a negative pair is formed by combining two segments originating from the splitting of two distinct reads chosen at random. Subsequently, for each pair, we calculate the k-mer profile for the two segments in the pair. These two k-mer profiles are then input into the same neural network, which maps them to two vectors within the embedding space. The loss function evaluates the quality of these two embeddings; it penalizes distant embeddings in positive pairs and close embeddings in negative pairs. The learning process involves optimizing the neural network's weights to minimize this loss function across numerous positive and negative samples.\nLet $\\mathcal{R} = \\{r_i\\}_{i=1}^{N}$ be the set of reads and $r_i^l$ and $r_i^r$ are the segments indicating the left and right halves of read $r_i \\in \\mathcal{R}$. As described above, we use these segments to construct the positive and negative pair samples required for the self-supervised contrastive learning procedure. Let $\\{(r_i^l, r_i^r, Y_{ij})\\}_{(i,j)\\in \\mathcal{I}}$ be the set of triplets where $\\mathcal{I} \\subseteq [N] \\times [N]$ is the index set for the pairs, and the symbol, $Y_{ij} \\in \\{0,1\\}$ is"}, {"title": "4 Experiments", "content": "In this section, we will provide the details regarding the experiments, datasets, and baseline approaches that we consider to assess the performance of the proposed linear and non-linear models.\nDatasets. We utilize the same publicly available datasets used to benchmark the genome foundation models [32]. The training set consists of 2 million pairs of non-overlapping DNA sequences, each 10,000 bases in length, constructed by sampling from the dataset, including 17,636 viral, 5,011 fungal, and 6, 402 distinct bacterial genomes from GenBank [3]. For model evaluation, we use six datasets derived from the CAMI2 challenge data [13], representing marine and plant-associated environments and including fungal genomes. These datasets propose realistic and complex reads, making them one of the most utilized benchmarks for the metagenomics binning task. Additionally, the synthetic datasets consist of randomly sampled sequences from the fungi and viral reference genomes, excluding any samples from the training data [32].\nBaselines and proposed models. For our experiments, we have employed the recent genome foundation models to assess the performance of our approach. (i) KMER is one of the most widely used baselines, and it also serves as a fundamental component of our model. The DNA sequences are represented as 4-mer profiles Tetranucleotide Frequencies given in Eq. 2 so each read is represented by a 256-dimensional vector. (ii) HYENADNA [16] is a genome foundation model, HYENADNA, pre-trained on the Human Reference Genome [7] with context lengths up to 106 tokens at single nucleotide resolution. (iii) DNABERT-2 [31] is another foundation model pre-trained on multi-species genomes, and it proposes Byte Pair Encoding (BPE) for DNA language modeling to address the computational inefficiencies related to k-mer tokenization. It also incorporates various techniques, such as Attention with Linear Biases (ALiBi) and Low-Rank Adaptation (LoRA), to address the limitations of current DNA language models. (iv) DNEBERT-S [32] aims to generate effective species-aware DNA representations and relies on the proposed Manifold Instance Mixup (MI-Mix) and Curriculum Contrastive Learning approaches. It relies on the pre-trained DNABERT-2 model as the initial point of contrastive training. (v) OURS(KMER-l1) is similar to the KMER approach presented in (i), but it uses $\\ell_1$ distance instead of the cosine-similarity distance so we will also name the first one as OURS(KMER-COSINE) to distinguish both models. (vii) OURS(POIS) refers to the Poisson approach described in Section 3.2. (vi) OURS(NL) refers to the non-linear k-mer embedding approach based on self-supervised constractive learning described in Section 3.3.\nParameter Settings. Our proposed models were trained on a cluster equipped with various NVIDIA GPU models. For the optimization of our models, we employed the Adam optimizer with a learning rate of 10-3. We used smaller subsets of the dataset for training our models, and we sampled 104 reads for OURS(POIS) and 106 sequences for OURS(NL). The OURS(NL) model was trained for 300 epochs with a mini-batch size of 104, while OURS(POIS) was trained for 1000 epochs using"}, {"title": "4.1 Metagenomics Binning Task", "content": "We assess the performance of the models based on the number of detected species/clusters and these clusters are classified into five different quality levels in terms of their F1 scores. Our methods and each baseline approach generate embeddings for the reads, and we cluster these read representations by following the work [32] with the modified K-Medoid algorithm. We refer readers to the cited work for further details on this approach. In line with standard practices in the field, we use cosine similarity for the baseline methods to measure the similarity between read embeddings required for the K-Medoid algorithm. For OURS(KMER-l1), we employed the $exp(-dist(\\cdot, \\cdot))$ function with $\\ell_1$ distance, while Euclidean distance was used for OURS(POIS) and OURS(NL).\nFigure 3 highlights the number of detected bins/clusters across different quality levels. For instance, the number of bins/species whose F1 scores above 0.9 is represented in dark blue while those with F1 scores between 0.5 and 0.6 are highlighted in red. Since we observe that the deviation in the number of detected species in most cases changes between at most $\\pm 5$, the error bars were not included.\nThe results underscore the effectiveness of k-mer features, which are central to our paper\u2019s focus. More specifically, as it was observed in the study [32], k-mer feature vectors (i.e., KMER-COSINE) surpass some genome foundation models like HYENADNA and DNABERT-2. Furthermore, we highlight the importance of choosing an appropriate similarity measure by showcasing the performance of the OURS(KMER-l1) variant. We note that Proposition 3.2 establishes a link between k-mer space equipped with $\\ell_1$ distance and read space with edit or Hamming distance. Thus, leveraging an appropriate metric in defining the similarities between reads in the binning stage also contributes to the performance improvement of OURS(KMER-l1)."}, {"title": "4.2 Ablation Study", "content": "We conduct a series of ablation studies in order to gain deeper insights into different components of the proposed architectures. We will start first by examining the impact of the parameter k which is used to define the k-mer profiles. It plays a fundamental role in the paper because all the model variants that we introduced rely on it. As also explained in Section 3, the selection of k also influences the identifiability of reads. In this regard, we evaluate the performance of the OURS(KMER-l1) model across various k values. Figure 4 shows the number of high-quality bins (i.e., F1 > 0.9) for different k settings and reveals that the optimal performance is generally achieved when k is set to 4 on different datasets. It also holds true across our different architectures, so we have set k = 4 in our models.\nWe also examine the influence of the output dimension size on the performance for the OURS(NL) model. We employed a very shallow architecture as described in Section 3.3, so the output dimension size plays a vital role in the computational cost and performance. As can be observed in Figure 5, the increase in dimension size also positively contributes to the number of detected high-quality bins, and the performance mostly saturates after 27. In order to have a fair comparison with the baselines, we also used 28 as an output dimension size in our architectures.\nFor the OURS(NL) architecture, it is very natural to use Bernoulli distribution to model whether a given pair of reads belongs to the same genome or not. However, different organisms might share similar regions in their genetic codes; therefore, assuming binary interactions might not suit well in every situation. In this regard, we rewrite Eq. 6 by Poisson distribution that we also employed for the OURS (POIS) architecture as follows:\n$\\mathcal{L}^{NL}_{poisson} = \\frac{1}{|\\mathcal{I}|}\\sum_{(i,j) \\in \\mathcal{I}} - Y_{ij} log d_{ij} + \\lambda_{ij}$"}, {"title": "5 Conclusion", "content": "In this study we have shown the efficacy of non-linear k-mer-based embeddings for metagenomic binning tasks, providing a compelling alternative to more recently proposed complex genome foundation models. Our work revisits and expands the theoretical framework surrounding k-mers, specifically addressing the identifiability of DNA fragments through their k-mer profiles and establishing new bounds on the distances defining relevant metric spaces. This theoretical insight not only reinforces the validity of using k-mer-based approaches for genome representation but also highlights their broader applicability in genomic research, such as taxonomic profiling/classification [22, 26] and phylogenetic analysis [30].\nThe lightweight model being proposed in the paper, grounded in these theoretical principles, shows considerable promise in the field of metagenomic binning. It achieves a performance comparable to that of state-of-the-art genome foundation models while requiring orders of magnitude fewer computational resources. This feature is especially important for large-scale genomic analyses that are currently driven by recent advances in sequencing technologies and where computational efficiency is paramount."}, {"title": "Limitations and Societal Impact", "content": "The ability to scale up metagenomic binning holds the potential for broader societal impacts through an improved understanding of the diversity and function of the microbial communities that influence our health and environment. Insights into these communities can also play an essential role in achieving the sustainability goals [24, 1], in particular good health and well-being (SDG-3), life below water (SDG-14), and life on land (SDG-15), to name a few. The current study is partly limited by the experimental setup, which is only based on synthetically generated genomic data following the experimental setup of similar studies such as [31, 32]. While the discussions about computational resources are not expected to be significantly affected by the type of data being used, the evaluations and comparisons of the quality of the recovered genomes most likely will. For instance, samples containing genomes of closely related species or strains of the same species will generally be more difficult to separate into distinct clusters. As part of future work, we plan to pursue a more rigorous analysis of the binning quality using long-read sequences from real-world data."}, {"title": "A Appendix", "content": "A.1 Theoretical Analysis\nLemma A.1. Let $r = r_1\\cdots r_{\\ell"}, "be a read satisfying $c_r(x_i) = 1$ for its every $(k - 1)$-mer, $x_i := r_i r_{i+k-2}$ where $1 < i < i^*$ for some $i^* \\in \\{1, . . ., \\ell - k + 2\\}$. If there exists a read $q = q_1\\cdots q_{\\ell}$ having the same k-mer profile as $r$, then $r_i = q_i$ for all $1 < i < i^* + k - 2$.\nProof. Let $r$ be a read where $(k - 1)$-mers, $x_i := r_i r_{i+k-2}$, appears only once in $r$ for all $1 < i < i^*$. As a basis step, we first show that the initial k-mer of $q$ must be the same as that of $r$, i.e., $q_1\\cdots q_k = r_1\\cdots r_k$. Suppose this is not the case, then there must exist an index $1 \\leq j \\leq \\ell-k+1$ such that $q_j q_{j+k-1} = r_1r_k$ since they have identical k-mer profiles by initial assumption. Note that $j\\neq 1$; otherwise, the reads would share the same prefixes. Therefore, $q_{j-1}\\cdots q_{j+k-2}$ is another k-mer of $q$, and it must also be present in $r$ because they share the same k-mer profile. Since $r_1\\cdots r_{k-1} = q_j\\cdots q_{j+k-2}$, k-mer $q_{j-1} q_{j+k-2}$ must be the prefix of $r$; otherwise $(k - 1)$-mer $q_j...q_{j+k-2}$ (i.e. $r_1 ... r_{k-1}$) appears in $r$ more than once and it violates the assumption that $c_r(x_i) = 1$ for all $x_i = r_i r_{i+k-2}$ where $i \\in \\{1,...,i^*\\}$. However, if $q_{j-1}\\cdots q_{j+k-2}$ is the prefix of $r$, then it enforces that $q_{j-1} = q_j = ... = q_{j+k-2} = q_{j+k-1}$ and a $(k - 1)$-mer occurs more than once in the substring $r_1\\cdots r_{i^*}$ so reads $r$ and $q$ must have the same initial k-mer.\nFor the inductive step, suppose that reads $r$ and $q$ agree up to position index $j$ where $k \\leq j < i^* - k - 2$, i.e., $r_i = q_i$ for all $1 < i < j$. We will show that $r_{j+1}$ and $q_{j+1}$ are also the same. Since $j < i^* - k + 2$, substring $q_{j-k+2}...q_{j+1}$ is also a k-mer of $q$. Since reads have the same k-mer profiles, $r$ also includes it. By the inductive hypothesis, we have $q_{j-k+2}\\cdots q_j = r_{j-k+2}\\cdots r_j$, and we know $(k - 1)$-mer $r_{j-k+2}\\cdots r_j$ occurs only once so it implies that $q_{j-k+2}\\cdots q_{j+1} = r_{j-k+2}\\cdots r_{j+1}$, i.e. $r_{j+1} = q_{j+1}$. In conclusion, we have $r_i = q_i$ for all $1 < i < i^* - k + 2$. \nCorollary A.2. If the $(k - 1)$-mer profile of a read contains at most one occurrence for each of its $(k - 1)$-mers, then there is no other read having the same k-mer profile.\nProof. Let $r = r_1\\cdots r_{\\ell}$ and $q = q_1\\cdots q_{\\ell}$ be reads having the same k-mer profile and each of their $(k-1)$-mers appear only once. By Lemma A.1, we have $r_i = q_i$ for all $1 < i < \\ell$ since $c_r(x_i) = 1$ for all $(k-1)$-mers $x_i = r_i \\ldots r_{i+k-2}$ where $0 \\leq i \\leq \\ell - k +1$\nTheorem A.3. Let $r$ be a read of length $l$. There exists no other distinct read having the same k-mer profile if and only if it does not satisfy any of the following conditions:\n1. $r_1\\cdots r_{k-1} = r_{\\ell-k-2}\\cdots r_{\\ell}$ and $r_i \\neq r_1$ for some $1 < i < \\ell - k - 2$.\n2. $r_i\\cdots r_{i+k-2} = r_j\\cdots r_{j+k-2}$ and $r_g\\cdots r_{g+k-2} = r_h\\cdots r_{h+k-2}$ for some indices $1 < i < g<j<h<\\ell- k + 2$ where $r_{i+k-1}\\cdots r_{g-1} \\neq r_{j+k-1}\\cdots r_{h-1}$.\n3. $r_i r_{i+k-2} = r_j r_{j+k-2} = r_h r_{h+k-2}$ for some indices $1 < i < j < h \\leq \\ell-k+2$ where $r_{i+k-1}\\cdots r_{j-1} \\neq r_{j+k-1}\\cdots r_{h-1}$.\nProof. Let $r = r_1\\cdots r_{\\ell}$ be a read of length $\\ell$, and we will first show that if a read satisfies one of these conditions, then we can find a read other than $r$ having the same k-mer profile. (i) Suppose that we have $r_1\\cdots r_{k-1} = r_{\\ell-k+2}\\cdots r_{\\ell}$, then the read defined as $r' = r_i r_{i+1}\\cdots r_{\\ell-k+2}\\cdots r_{\\ell-1}r_{\\ell}r_k r_{k+1}\\cdots r_{i-2}r_{i-1}$ will be distinct from $r$ for some $i \\in \\{k,..., \\ell - k + 1\\}$, and it shares the same k-mer profile. (ii) Let $r$ be a read holding the second condition so we have $r_i\\cdots r_{i+k-2} = r_j\\cdots r_{j+k-2}$ and $r_g\\cdots r_{g+k-2} = r_h\\cdots r_{h+k-2}$ for some indices $1 < i < g < j < h < \\ell$. Then, we can construct a different read having the same k-mer profile by interchanging the substrings $"]}