{"title": "AI-Managed Emergency Documentation with a Pretrained Model", "authors": ["David Menzies", "Sean Kirwan", "Ahmad Albarqawi"], "abstract": "This study investigates the use of a large language model (LLM)-based system to improve efficiency and quality in Emergency Department (ED) discharge letter writing. Time constraints and infrastructural deficits make compliance with current discharge letter targets difficult. We explored potential efficiencies from an Artificial Intelligence (AI) software model in the generation of ED discharge letters and the attitudes of doctors toward this technology. The evaluated LLM system leverages advanced techniques to fine-tune a model to generate discharge summaries from short-hand inputs, including voice, text, and Electronic Health Record (EHR) data. Nineteen physicians with emergency medicine experience evaluated the system's text and voice-to-text interfaces against manual typing. The results showed significant time savings with MedWrite LLM interfaces compared to manual methods.", "sections": [{"title": "1 Introduction", "content": "Effective communication with General Practitioners (GPs) is crucial for ensuring seamless, safe continuity of care for patients discharged from Emergency Departments (EDs). However, this aspect of healthcare delivery has been identified as a risk area, characterized by poor compliance and challenges related to the content, timeliness, and legibility of discharge letters.\nRecently, the integration of artificial intelligence (AI) has revolutionised various facets of medical practice, offering innovative solutions to complex challenges. In the context of EDs, where there are combined pressures for both efficiency and accuracy, AI has the potential to streamline documentation processes and also enhance patient care outcomes.\nOne such aspect of ED workflow is the composition of discharge letters, which are important communication tools summarizing a patient's visit, diagnoses, treatments, and follow-up instructions for other healthcare providers (such as their General Practitioner) and potentially also for the patient themselves. The writing of ED discharge letters represents a significant burden on healthcare providers in the ED, requiring careful attention to detail while simultaneously managing other cases. Manual composition of these letters can be time-consuming, susceptible to errors, and variable between healthcare providers. This can lead to delays in communication and difficulties in ensuring appropriate follow-up care.\nGP letters are an important means of sharing clinical information between the hospital system and a patient's primary care provider. These letters should be issued in a timely fashion and contain pertinent information regarding a patient's care [1]. Such communication is also often a regulatory requirement on the discharging doctor [2]\nCompliance with both the timeliness and content of such communications is known to be poor [3]. Adverse events are recognized as a problem post-patient discharge as well as in the hospital [4]. The transfer of information between hospital and outpatient settings has been recognized as a potential contributory factor to adverse events [5]. Multiple risk factors have been identified in association with discharge letters and the potential impact on patient care [6].\nThere is a growing interest in exploring the potential efficiencies offered by AI software models in healthcare, including in the generation of ED discharge documentation. Given these challenges, we hypothesized that an AI solution could mitigate the burden associated with ED discharge letter writing while simultaneously improving the efficiency and quality of documentation. The rationale behind this hypothesis lies in the capabilities of AI to analyse data, recognize patterns, and generate appropriate content.\nThe potential of generative AI to assist with medical tasks has been explored in several areas, including patient-friendly discharge [7] and informed consent [8].\nSeveral studies have explored the usage of pre-trained language models for biomedical and clinical tasks, including comparison of various language models and demonstration of the effectiveness of fine-tuning for domain-specific applications like biomedicine [9]. Fine-tuning provided significant enhancement to biomedical tasks, in addition to clinical tasks.\nThe challenges of obtaining labelled medical data due to privacy regulations are recognised by Chintagunta et al. [10]. Combining human-labelled and synthetic data generated by a model for medical dialogue summarization using GPT-3 has been demonstrated to be effective. The use of natural language processing and machine"}, {"title": "2 System Development", "content": "The system core component is GPT-3 Davinci model [14], fine-tuned to specialize in the medical writing domain. This fine-tuning process enables the model to create compliant discharge letters tailored to the healthcare systems in Ireland and the UK without requiring lengthy prompting.\nThe training data was created with the help of third-party medical writers to generate synthesized patients' medical cases for the emergency department and write the related discharge letters; then, the letters will be processed to add metadata for the training process, such as the target department and country writing style.\nThe system also uses the open-source whisper model [15] for accurate speech-to-text dictation. The model is prompted with medical context and terminology to ensure precise speech recognition capabilities, and the prompt is tuned over multiple iterations to eliminate common errors in translating some medical terms.\n2.1 System Architecture\nThe architecture integrates three key components for efficient data flow and improved medical discharge letter generation:\n\u2022 User Interface: This component enables healthcare professionals to create medical discharge letters and report any hallucinations (fabricated information generated by the AI model) for continuous improvement.\n\u2022 Data Processing Pipeline: This layer strips any personally identifiable information from the doctor's notes to ensure compliance with data protection standards, and it also adds relevant metadata for the training process."}, {"title": "3 Methods", "content": "An unblinded cohort methodology was used to test both the hypothesis that Med-Write would improve the efficiency of ED discharge letter-writing, and to evaluate the software's user interface (UI).\nNineteen physicians with at least six months experience working in Emergency Medicine participated in the study (Table 2). Recruitment was via email to an emailing list of Emergency Medicine groups and via social media.\nPre-participation information regarding the MedWrite model was provided to par-ticipants. The MedWrite model was also demonstrated to participants online as part of the study, and all participants were provided with an opportunity to practice generating a discharge letter.\nTwo of the authors (D. Menzies and S. Kirwan) conducted the interviewing and testing over Microsoft Teams, facilitating accurate timing of each part of the process. Each participant undertook three timed tasks to generate an ED discharge letter based on a fictional EHR: manual composition (typing), AI text input, and AI voice-to-text interface.\nIn the case of the manual composition, participants were asked to write a letter to their usual work practice standard. In the case of the AI-assisted letters, participants were asked to edit the AI output until it met their usual standard. In addition to timed tasks, the participants' experiences and attitudes towards Emergency Medicine Dis-charge Letter-Writing, MedWrite and their experience with the software were explored through a semi-structured interview.\nAll participants were provided with a Participant Information Leaflet in advance of the study and were given an opportunity to ask any clarifying questions. All par-ticipants opted into participation and all consented to participation in the study prior to commencing."}, {"title": "4 Results", "content": "The time taken to generate discharge letters was measured as shown in Table 1.\nParticipants took a mean time of 196.737 seconds (range 86-355 seconds) to complete a manual (typed) discharge letter.\nThe AI text interface is a simulation of using an EHR system where the user copies the patient details from it and generates the letters using the LLM, it took a mean time of 94.58 seconds (range 34-147 seconds), representing a mean time savings of 102.157 seconds. This equates to an average time saving of 51.9%."}, {"title": "5 Discussion", "content": "This study investigated the efficiency of using a large language models-based system to improve the efficiency of emergency department (ED) discharge letter writing, requires minimal editing of the generated letter instead of manually writing it from scratch.\nThe findings support the proposition that the MedWrite fine-tuned model can reduce completion time compared to manual typing, 15 of the participants indicated they would try where it is available, and 12 indicated they would definitely use it. Voice dictation was preferred over manual note writing. Both text-based and voice-to-text interfaces resulted in substantial time savings and improved writing quality.\nParticipants identified several administrative burdens in the emergency depart-ment, including access to Information and Communication Technology (ICT), which impacted their ability to complete discharge letters. Most participants also reported that a product such as MedWrite would reduce these burdens and improve compliance.\nThe Royal College of Emergency Medicine recognises that AI has a potential benefit in Emergency Medicine and provides some guidance on how it should be implemented [16], however this focuses largely on the use of AI as a decision or diagnosis support tool rather than automating administrative tasks."}, {"title": "6 Limitations", "content": "Despite promising results, some limitations are present in this study. The study was conducted in a simulated environment and applying the system in a real-world hospital"}, {"title": "7 Conclusion", "content": "In conclusion, emergency department discharge letters are recognized as an important part of communication regarding patient care, ensuring continuity of care, post-discharge instructions, and patient education. Compliance with the timeliness and content of these letters is variable.\nGenerative AI, particularly with trained LLMs, has the potential to add efficiencies to labour-intensive administrative tasks in healthcare. We hypothesized that a trained LLM could accurately generate plain English discharge letters using a variety of inputs including electronic healthcare records, free text, and speech. We fine-tuned the GPT3 Davinci model which helped tailor the discharge letter writing style and incorporate the feedback of physicians.\nWe tested this hypothesis in a medical interface MedWrite among 19 emergency medicine doctors. This study suggests that AI-assisted systems have the potential to reduce the time taken to generate suitable discharge letters while retaining comparable levels of content."}, {"title": "8 Declarations", "content": "MedWrite system received funding from the Wicklow Local Enterprise office.\nEthical approval for the study was obtained from the University College Dublin, Human Research Ethics Committee (UCD HREC) with reference number: LS-C-23-116-Menzies."}, {"title": "9 Data Availability", "content": "The data supporting the findings of this study is available on request."}, {"title": "10 Author Contributions", "content": "All authors contributed equally to the writing of the manuscript. David Menzies (DM) was the main driver of the study interviews. Sean Kirwan (SK) compiled the study results and participated in the interviews. Ahmad Albarqawi (AA) fine-tuned the language model and developed the system interface."}, {"title": "11 Appendix", "content": ""}]}