{"title": "PSL: Rethinking and Improving Softmax Loss from Pairwise Perspective for Recommendation", "authors": ["Weiqin Yang", "Jiawei Chen", "Xin Xin", "Sheng Zhou", "Binbin Hu", "Yan Feng", "Chun Chen", "Can Wang"], "abstract": "Softmax Loss (SL) is widely applied in recommender systems (RS) and has demonstrated effectiveness. This work analyzes SL from a pairwise perspective, revealing two significant limitations: 1) the relationship between SL and conventional ranking metrics like DCG is not sufficiently tight; 2) SL is highly sensitive to false negative instances. Our analysis indicates that these limitations are primarily due to the use of the exponential function. To address these issues, this work extends SL to a new family of loss functions, termed Pairwise Softmax Loss (PSL), which replaces the exponential function in SL with other appropriate activation functions. While the revision is minimal, we highlight three merits of PSL: 1) it serves as a tighter surrogate for DCG with suitable activation functions; 2) it better balances data contributions; and 3) it acts as a specific BPR loss enhanced by Distributionally Robust Optimization (DRO). We further validate the effectiveness and robustness of PSL through empirical experiments. The code is available at https://github.com/Tiny-Snow/IR-Benchmark.", "sections": [{"title": "Introduction", "content": "Nowadays, recommender systems (RS) have permeated various personalized services [1-4]. What sets recommendation apart from other machine learning tasks is its distinctive emphasis on ranking [5]. Specifically, RS aims to retrieve positive items in higher ranking positions (i.e., giving larger prediction scores) over others and adopts specific ranking metrics (e.g., DCG [6] and MRR [7]) to evaluate its performance.\n\nThe emphasis on ranking inspires a surge of research on loss functions in RS. Initial studies treated recommendation primarily as a classification problem, utilizing pointwise loss functions (e.g., BCE [8], MSE [9]) to optimize models. Recognizing the inherent ranking nature of RS, pairwise loss"}, {"title": "Preliminaries", "content": "Task formulation. We will conduct our discussion in the scope of collaborative filtering (CF) [25], a widely-used recommendation scenario. Given the user set U and item set I, CF dataset \\(D \\subset U \\times I\\) is a collection of observed interactions, where each instance (u, i) \\(\\in D\\) means that user u has interacted with item i (e.g., clicks, reviews, etc). For each user u, we denote \\(P_u = \\{i \\in I : (u, i) \\in D\\}\\) as the set of positive items of u, while \\(I \\backslash P_u\\) represents the negative items.\n\nThe goal of recommendation is to learn a recommendation model, or essentially a scoring function \\(f(u, i) : U \\times I \\rightarrow \\mathbb{R}\\) that quantifies the preference of user u on item i accurately. Modern RS often adopts an embedding-based paradigm [26]. Specifically, the model maps user u and item i into d-dim embeddings \\(u, v \\in \\mathbb{R}^d\\), and predicts their preference score f(u, i) based on embedding similarity. The cosine similarity is commonly utilized in RS and has demonstrated particular effectiveness [27]. Here we set \\(f(u, i) = \\frac{u \\cdot v}{\\|u\\| \\cdot \\|v\\|}\\), where the scaling factor \\(\\frac{1}{\\|u\\| \\cdot \\|v\\|}\\) is introduced for faciliating analyses"}, {"title": "Analyses on Softmax Loss from Pairwise Perspective", "content": "In this section, we aim to first represent the Softmax Loss (SL) in a pairwise form, followed by an analysis of its relationship with the DCG metric, where two limitations of SL are exposed.\n\nPairwise form of SL. To facilitate the analysis of SL and to build its relationship with the DCG metric, we rewrite SL (cf. Equation (2.4)) in the following pairwise form:\n\\[L_{SL}(u) = \\sum_{i\\in P_u} \\log \\frac{1}{\\sum_{j \\in I} exp(\\delta_{uij}/\\tau)} ,  \\text{where } \\delta_{uij} = f(u, j) - f(u, i)\\]\nEquation (3.1) indicates that SL is penalized based on the score gap between negative-positive pairs, i.e., \\(\\delta_{uij} = f(u, j) - f(u, i)\\). This concise expression is fundamental for ranking, as it optimizes the relative order of instances rather than their absolute values."}, {"title": "Connections between SL and DCG", "content": "We now analyze the connections between SL and the DCG metric (cf. Equations (2.1) and (3.1)), which could enhance our understanding of the advantages and disadvantages of SL. Our analysis follows previous work [11, 14], which begins by relaxing the negative logarithm of DCG with\n\\[- \\log DCG(u) + \\log |P_u| \\leq - \\log \\left(\\frac{1}{|P_u|} \\sum_{i \\in P_u} \\frac{1}{\\pi_u(i)} \\right) \\leq \\frac{1}{|P_u|} \\sum_{i \\in P_u} \\pi_u(i)\\]\nwhere the first inequality holds due to \\(\\log_2(1 + \\pi_u(i)) \\leq \\pi_u(i)\\), and the second inequality holds due to Jensen's inequality [34]. Note that the ranking position \\(\\pi_u(i)\\) of item i can be expressed as\n\\[\\pi_u(i) = \\sum_{j \\in I} \\mathbb{I}(f(u, j) \\geq f(u, i)) = \\sum_{j \\in I} \\delta(d_{uij})\\]\nwhere \\(\\delta(\\cdot)\\) denotes the Heaviside step function, with \\(\\delta(x) = 1\\) for \\(x > 0\\) and \\(\\delta(x) = 0\\) for \\(x < 0\\). Since \\(\\delta(d_{uij}) < exp(d_{uij}/\\tau)\\) holds for all \\(\\tau > 0\\), we deduce that SL is a smooth upper bound of Equation (3.2), and thus serves as a reasonable surrogate loss for DCG and MRR metrics\u00b9.\n\nHowever, our analysis also reveals two limitations of SL:\n\nLimitation 1: SL is not tight enough as a DCG surrogate loss. There remains a significant gap between the Heaviside step function \\(\\delta(\\cdot)\\) and the exponential function \\(exp(\\cdot)\\), especially when \\(d_{uij}\\) reaches a relatively large value, where \\(exp(\\cdot)\\) becomes substantially larger than \\(\\delta(\\cdot)\\). This gap is further exacerbated by the temperature \\(\\tau\\). Practically, we find that the optimal \\(\\tau\\) is usually chosen to be less than 0.2 (cf. Appendix B.5.2). Given the explosive nature of \\(exp(\\cdot)\\), the gap becomes extremely large, potentially leading to suboptimal performance of SL in optimizing DCG.\nLimitation 2: SL is highly sensitive to noise (e.g., false negative instances). False negative instances [15] are common in the typical RS. This is often due to the exposure bias [16], where a user's lack of interaction with an item might stem from unawareness rather than disinterest. Unfortunately, SL is highly sensitive to these false negative instances. On one hand, these instances (u, j), which may exhibit patterns similar to true positive ones, are difficult for the model to differentiate and often receive larger predicted scores, thus bringing potentially larger \\(d_{uij}\\) for positive items i. As analyzed in Limitation 1, these instances can significantly enlarge the gap between SL and DCG due to the exponential function, causing the optimization to deviate from the DCG metric.\n\nGradient analysis of SL. Another perspective to support the view of Limitation 2 comes from the gradient analysis. Specifically, the gradient of SL w.r.t. \\(d_{uij}\\) is\n\\[\\frac{\\partial L_{SL}(u)}{\\partial d_{uij}} = \\frac{exp(d_{uij}/\\tau)/\\tau}{|I|\\mathbb{E}_{j'\\sim I}[exp(d_{uij'}/\\tau)]}\\]\nAs can be seen, SL implicitly assigns a weight to the gradient of each negative-positive pair, where the weight is proportional to \\(exp(d_{uij}/\\tau)\\). This suggests that instances with larger \\(d_{uij}\\) will receive larger weights. While this property may be desirable for hard mining [11], which can accelerate convergence, it also means that false negative instances, which typically have larger \\(d_{uij}\\), will obtain disproportionately large weights, as shown in the weight distribution of SL in Therefore, the optimization of SL can be easily dominated by false negative instances, leading to performance drops and training instability.\n\nDiscussions on DRO robustness and noise sensitivity. Recent work [15] claims that SL exhibits robustness to noisy data through Distributionally Robust Optimization (DRO) [19]. However, we argue that this is not the case. DRO indeed can enhance model robustness to distribution shifts, but it also increases the risk of noise sensitivity, as demonstrated by many studies on DRO [35, 36]. Intuitively, DRO emphasizes hard instances with larger losses, making noisy data contribute more rather than less to the optimization. This is also demonstrated from the experiments with false negative instances (cf. Figure 8 in [15]), where the improvements of SL over other baselines in Noise setting do not increase significantly but sometimes decay."}, {"title": "Methodology", "content": "Pairwise Softmax Loss\n\nRecognizing the limitations of SL, particularly its reliance on the unsatisfactory exponential function, we propose to extend SL with a more general family of losses, termed Pairwise Softmax Loss (PSL). In PSL, the exponential function \\(exp(\\cdot)\\) is replaced by other surrogate activations \\(\\sigma(\\cdot)\\) approximating the Heaviside step function \\(\\delta(\\cdot)\\). For each user u, the PSL is defined as\n\\[L_{PSL}(u) = \\sum_{i \\in P_u} \\log \\frac{1}{\\sum_{j \\in I} \\sigma(d_{uij})^{1/\\tau}}\\]\nOne might wonder why we apply the temperature outside the activation function (i.e., extending \\(exp(d_{uij})^{1/\\tau}\\) to \\(\\sigma(d_{uij})^{1/\\tau}\\)) rather than within it (i.e., extending \\(exp(d_{uij}/\\tau)\\) to \\(\\sigma(d_{uij}/\\tau)\\)). This subtlety will be elucidated later as we demonstrate that the form in Equation (4.1) offers superior properties over the alternative.\n\nOur PSL provides a flexible framework for selecting better activation functions, allowing the loss to exhibit improved properties compared to SL. We advocate for three activations, including PSL-tanh: \\(\\sigma_{tanh} = \\frac{tanh(d_{uij}) + 1}{2}\\), PSL-atan: \\(\\sigma_{atan} = \\frac{arctan(d_{uij}) + 1}{2}\\), and PSL-relu: \\(\\sigma_{relu} = ReLU(d_{uij} + 1)\\). In the following, we will discuss the advantages of PSL and provide evidence for the selection of these surrogate activations.\n\nAdvantage 1: PSL is a better surrogate for ranking metrics. To highlight the advantages of replacing \\(exp(\\cdot)\\) with alternative surrogate activations, we present the following lemma:\n\nLemma 4.1. If the condition\n\\[\\delta(d_{uij}) \\leq \\sigma(d_{uij}) \\leq exp(d_{uij})\\]\nis satisfied for any \\(d_{uij} \\in [-1, 1]\\), then PSL serves as a tighter DCG surrogate loss compared to SL.\n\nThe proof is presented in Appendix A.1. This lemma reveals that PSL could be a tighter surrogate loss for DCG compared to SL. Additionally, it provides guidance on the selection of a proper surrogate activation - we may choose the activation that lies between \\(exp(\\cdot)\\) and \\(\\delta(\\cdot)\\). As demonstrated our chosen surrogate activations \\(\\sigma_{tanh}\\), \\(\\sigma_{atan}\\), and \\(\\sigma_{relu}\\) adhere to this principle.\n\nAdvantage 2: PSL controls the weight distribution. The gradient of PSL w.r.t. \\(d_{uij}\\) is\n\\[\\frac{\\partial L_{PSL}(u)}{\\partial d_{uij}} = \\frac{\\sigma'(d_{uij}) \\cdot \\sigma(d_{uij})^{1/\\tau - 1/\\tau}}{|I|\\mathbb{E}_{j'\\sim I}[\\sigma(d_{uij'})^{1/\\tau}]}\\]\nThis implies that the shape of the weight distribution is determined by the choice of surrogate activation. By selecting appropriate activations, PSL can better balance the contributions of instances during training. For example, the three activations advocated before can explicitly mitigate the explosive issue on larger \\(d_{uij}\\) (cf. Figure 1b), bringing better robustness to false negative instances.\n\nOne might argue that adjusting \\(\\tau\\) in SL could improve noise resistance. However, such adjustments do not alter the fundamental shape of the weight distribution, which remains exponential. Furthermore, as we discuss subsequently, \\(\\tau\\) plays a crucial role in controlling robustness against distribution shifts. Thus, indiscriminate adjustments to \\(\\tau\\) may compromise out-of-distribution (OOD) robustness.\n\nAdvantage 3: PSL is a DRO-empowered BPR loss. We establish a connection between PSL and BPR [10] based on Distributionally Robust Optimization (DRO) [19, 37]. Specifically, optimizing PSL is equivalent to applying a KL divergence DRO on negative item distribution over BPR loss (cf. Equation (2.3)), as demonstrated in the following theorem\u00b3:\n\nTheorem 4.2. For each user u and its positive item i, let P = P(j|u, i) be the uniform distribution over I. Given a robustness radius \\(\\eta > 0\\), consider the uncertainty set Q consisting of all perturbed distributions Q = Q(j|u, i) satisfying: (i) Q is absolutely continuous w.r.t. P, i.e., Q \\(\\ll\\) P; (ii) the KL divergence between Q and P is constrained by \\(\\eta\\), i.e., DKL(Q||P) \\(\\leq \\eta\\). Then, optimizing PSL is equivalent to performing DRO over BPR loss, i.e.,\n\\[\\min_{\\Theta} \\mathbb{E}_{i \\sim P_u} \\left[ \\log \\mathbb{E}_{j \\sim I} \\left[ e^{\\log \\sigma(d_{uij})/\\tau} \\right] \\right] \\Longleftrightarrow  \\min_{\\Theta} \\mathbb{E}_{i \\sim P_u} \\left[ \\sup_{Q \\in Q} \\mathbb{E}_{j \\sim Q(j|u,i)} \\left[ \\log \\sigma(d_{uij}) \\right] \\right]\\]\nwhere \\(\\tau = \\tau(\\eta)\\) is a temperature parameter controlled by \\(\\eta\\).\n\nThe proof is presented in Appendix A.2. Theorem 4.2 demonstrates how PSL, based on the DRO framework, is inherently robust to distribution shifts. This robustness is particularly valuable in RS, where user preference and item popularity may shift significantly. Therefore, PSL can be regarded as a robust generalization of BPR loss, offering better performance in OOD scenarios.\n\nIn addition, Theorem 4.2 also gives insights into the rationality of PSL that differs from serving as a DCG surrogate loss, but rather as a DRO-empowered BPR loss:\n\nRationality of surrogate activations: The activation function in BPR is originally chosen as an approximation to the Heaviside step function [10]. Since PSL is a generalization of BPR as stated in Theorem 4.2, it is reasonable to select the activations in PSL that aligns with the ones in BPR. Interestingly, this principle coincides with our analysis from the perspective of DCG surrogate loss.\nRationality of the position of temperature: Theorem 4.2 also rationalizes the extension form that places the temperature on the outside rather than inside. For the outside form (i.e., \\(\\sigma(d_{uij})^{1/\\tau}\\)), Theorem 4.2 holds, and the temperature \\(\\tau\\) can be interpreted as a Lagrange multiplier in DRO optimization, which controls the extent of distribution perturbation. However, for the inside form (i.e., \\(\\sigma(d_{uij}/\\tau)\\)), Theorem 4.2 no longer holds, and it would be challenging to establish the relationship between PSL and BPR.\nRationality of pairwise perspective: Recent work such as BSL [15] also reveals the DRO property of SL (cf. Lemma 1 in [15]). However, we wish to highlight the distinctions between Theorem 4.2 and Wu et al. [15]'s analyses: 1) Wu et al. [15] views SL from a pointwise perspective and associates it with a specific, less commonly used pointwise loss. In contrast, our analyses adopt a pairwise perspective and establish a relationship between PSL and the widely used BPR loss. 2) We construct a link between two families of losses with flexible activation selections, and Wu et al. [15]'s analyses can be regarded as a special case within our broader framework.\n\nThe above analyses underscore the advantages of PSL and provide the principles to select surrogate activations. Remarkably, PSL is easily implemented and can be integrated into various recommendation scenarios. This can be achieved by merely replacing the exponential function \\(exp(\\cdot)\\) in SL with another activation \\(\\sigma(\\cdot)\\) surrogating the Heaviside step function, requiring minimal code modifications."}, {"title": "Discussions", "content": "Comparisons of two extension forms. In previous discussions, we highlight the advantages of the form that positions the temperature outside (i.e., \\(\\sigma(d_{uij})^{1/\\tau}\\)) over the inside (i.e., \\(\\sigma(d_{uij}/\\tau)\\)). As discussed in the analyses of Theorem 4.2, the outside form can be regarded as a DRO-empowered BPR, while the inside form cannot, which ensures the robustness of PSL against distribution shifts.\n\nHere we provide an additional perspective on the advantages of the outside form. In fact, the outside form facilitates the selection of surrogate activations. For instance, to ensure that PSL serves as a tighter DCG surrogate loss compared to SL (i.e., ensure Lemma 4.1 holds), the outside form only need to consider the condition (4.2) on the range of \\(d_{uij} \\in [-1, 1]\\). However, for the inside form, this condition should be satisfied on the entire domain of the activation \\(\\sigma(\\cdot)\\), which complicates the selection of activation functions. Therefore, the outside form is more flexible and easier to implement. We further provide empirical evidence in Appendix C.3, demonstrating that the inside form will lose the advantages of achieving tighter DCG surrogate loss, leading to compromised performance.\n\nConnections with other losses. We further discuss the connections between PSL and other losses:\n\nConnection with AdvInfoNCE [38]: According to Theorem 3.1 in Zhang et al. [38], AdvInfoNCE can indeed be considered as a special case of PSL with \\(\\sigma(\\cdot) = exp(exp(\\cdot))\\). We argue that this activation is not a good choice as it would enlarge the gap between the loss and DCG. In fact, we have \\(- \\log DCG < L_{PSL} \\leq L_{SL} \\leq L_{AdvInfoNCE}\\) (cf. Appendix A.3 for proof). While AdvInfoNCE may achieve good performance in some specific OOD scenarios as tested in Zhang et al. [38], we argue that AdvInfoNCE is a looser DCG surrogate loss and would be highly sensitive to noise (cf. Table 1 and Figure 2 in Section 5.2 for empirical validation).\n\nConnection with BPR [10]: Besides the DRO relation stated in Theorem 4.2, we also derive the bound relation between BPR and PSL with the same activation, i.e., \\(- \\log DCG < L_{PSL} < log L_{BPR}\\) (cf. Appendix A.3 for proof). This relation clearly demonstrates the effectiveness of PSL over BPR - performing DRO over BPR results robustness to distribution shifts, while also achieving a tighter surrogate of DCG, which is interesting (cf. Tables 1 and 2 in Section 5.2 for empirical validation). An intuitive explanation is that DCG focuses more on the higher-ranked items. Given that DRO would give more weight to the hard negative instances with larger prediction scores and higher positions, it would naturally narrow the gap between BPR and DCG."}, {"title": "Experiments", "content": "Experimental Setup\n\nTesting scenarios. We adopt three representative testing scenarios to comprehensively evaluate model accuracy and robustness, including: 1) IID setting: the conventional testing scenario where training and test data are randomly split and identically distributed; 2) OOD setting: to assess the model's robustness on the out-of-distribution (OOD) data, we adopt a debiasing testing paradigm where the item popularity distribution shifts. We closely refer to Zhang et al. [20], Wang et al. [24], and Wei et al. [39], sampling a test set where items are uniformly distributed while maintaining the long-tail nature of the training dataset; 3) Noise setting: to evaluate the model's sensitivity to noise, following Wu et al. [15], we manually impute a certain proportion of false negative items in the training data. The details of the above testing scenarios are provided in Appendix B.1.\n\nDatasets. Four widely-used datasets including Amazon-Book, Amazon-Electronic, Amazon-Movie [40, 41], and Gowalla [42] are used in our experiments. Considering the item popularity is not heavily skewed in the Amazon-Book and Amazon-Movie datasets, we turn to other conventional datasets, Amazon-CD [40, 41] and Yelp2018 [43], as replacements for OOD testing. All datasets are split into 80% training set and 20% test set, with 10% of the training set further treated as the validation set. The details of the above datasets are summarized in Appendix B.1.\n\nMetrics. We closely refer to Wu et al. [15] and Zhang et al. [38], adopting Top-K metrics including NDCG@K [6] and Recall@K [29] for performance evaluation, where NDCG is the normalized DCG, i.e., dividing DCG by the ideal value. Here we simply set K = 20 as in recent work [15, 38] while observing similar results with other choices. For more details, please refer to Appendix B.2."}, {"title": "Performance Comparisons", "content": "Results under IID setting. Table 1 presents the performance of our PSL compared with baselines.\n\nPSL outperforms SL and other baselines. Experimental results demonstrate that PSL, with three carefully selected surrogate activations, consistently outperforms SL across all datasets and backbones, with only a few exceptions. For instance, on the MF backbone, compared to the marginal improvements or sometimes even degradation of AdvInfoNCE (-3%~0.5%) and BSL (0.0%~0.5%), PSL shows a significant enhancement over SL (1%~3%). Moreover, our PSL surpasses all compared baselines in most cases, clearly demonstrating its effectiveness.\n\nPSL achieves tighter connections with ranking metrics. We observe that the results align well with our theoretical analyses of PSL's Advantage 1 in Section 4. By replacing the exponential function with other suitable surrogate activations, PSL establishes a tighter relationship with ranking"}, {"title": "Conclusion and Limitations", "content": "In this work, we introduce a new family of loss functions, termed Pairwise Softmax Loss (PSL). PSL theoretically offers three advantages: 1) it serves as a better surrogate for ranking metrics with appropriate surrogate activations; 2) it allows flexible control over the distribution of the data contribution; 3) it can be interpreted as a specific BPR loss enhanced by Distributionally Robust Optimization (DRO). These properties demonstrate that PSL has greater effectiveness and robustness compared to Softmax Loss. Our extensive experiments across three testing scenarios validate the superiority of PSL over existing methods.\n\nOne limitation of both PSL and SL is inefficiency, as they require sampling a relatively large number of negative instances per iteration. How to address this issue and improve the efficiency of these losses is an interesting direction for future research."}]}