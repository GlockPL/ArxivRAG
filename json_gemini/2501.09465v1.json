{"title": "RE-POSE: Synergizing Reinforcement Learning-Based Partitioning and Offloading for Edge Object Detection", "authors": ["Jianrui Shi", "Yong Zhao", "Zeyang Cui", "Xiaoming Shen", "Minhang Zeng", "Xiaojie Liu"], "abstract": "Object detection plays a crucial role in smart video analysis, with applications ranging from autonomous driving and security to smart cities. However, achieving real-time object detection on edge devices presents significant challenges due to their limited computational resources and the high demands of deep neural network (DNN)-based detection models, particularly when processing high-resolution video. Conventional strategies, such as input down-sampling and network up-scaling, often compromise detection accuracy for faster performance or lead to higher inference latency. To address these issues, this paper introduces RE-POSE, a Reinforcement Learning (RL)-Driven Partitioning and Edge Offloading framework designed to optimize the accuracy-latency trade-off in resource-constrained edge environments. Our approach features an RL-Based Dynamic Clustering Algorithm (RL-DCA) that partitions video frames into non-uniform blocks based on object distribution and the computational characteristics of DNNs. Furthermore, a parallel edge offloading scheme is implemented to distribute these blocks across multiple edge servers for concurrent processing. Experimental evaluations show that RE-POSE significantly enhances detection accuracy and reduces inference latency, surpassing existing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "With rapid advancements in Deep Neural Networks (DNNs) and the widespread deployment of camera-equipped devices, smart video analysis has become essential in applications like autonomous driving, security surveillance, smart cities, and robot navigation [1]. Central to this technology is object detection, which enables real-time detection and tracking of objects, supporting functionalities such as situational awareness and automated responses [2].\nDeploying smart video analysis at the edge offers significant advantages over cloud-based solutions, including reduced latency and enhanced privacy by processing data locally [3]. However, edge devices often have limited computational and storage resources, making it hard to run resource-intensive DNN-based object detection models on high-resolution video streams. High-resolution inputs require substantial computational power for real-time inference, and current mitigation strategies-like down-sampling or using smaller models-typically trade off accuracy for reduced latency [4], [5].\nTo address these challenges, various model compression techniques have been developed, including weight and branch pruning [6], weight sharing [7], tensor quantization [8], knowledge distillation [9], and network architecture search [10]. While these methods effectively reduce model size for edge deployment, they often results in decreased accuracy.\nAdditionally, several acceleration methods targeting video tasks have been proposed. Some methods, like [11], [12], divide high-resolution images into smaller blocks, processing only those likely to contain pedestrians. However, [11] has limitations such as outdated performance estimations, inadequate background removal in crowded areas, and overly fine partitions that degrade accuracy. Similarly, Elf [12] uses an attention-based LSTM to predict pedestrian locations, but it can be slow in densely populated scenes due to multiple inferences.\nTo overcome these limitations, we introduce RE-POSE (Reinforcement Learning-Driven Partition-Offloading Synergy at Edge), a framework that optimizes the balance between detection accuracy and inference latency in resource-constrained edge environments. RE-POSE leverages Reinforcement Learning (RL) to adaptively partition high-resolution video frames into blocks and offload them to multiple edge servers for parallel inference, improving detection performance while maintaining latency constraints.\nOur main contributions are as follows:\n\u2022 RE-POSE Framework: Presents a novel RL-driven architecture that performs non-uniform partitioning and parallel offloading, achieving superior real-time object detection performance at edge.\n\u2022 RL-Based Dynamic Clustering Algorithm (RL-DCA): Dynamically partitions video frames into non-uniform blocks based on coarse object detection and RL, enhancing detection accuracy and computational efficiency."}, {"title": "II. SYSTEM OVERVIEW", "content": "The RE-POSE framework adopts RL-driven partitioning and parallel offloading to achieve accurate object detection on edge devices. It includes two main modules: RL-DCA Partitioning and Parallel Edge Offloading, shown in Fig. 1.\n A. RL-DCA Partitioning\nThe input is a high-resolution video frame, initially divided into uniform blocks for coarse detection using YOLOv8 model with a low confidence threshold to ensure high recall. Detected objects are clustered with MeanShift to form initial clusters. RL-DCA then refines these clusters using a PPO-based RL agent that dynamically merges or splits clusters to achieve compact, homogeneous groupings. This adaptive clustering step ensures that each cluster can be handled by a suitable model without unnecessary computational overhead. (III-A)\nB. Parallel Edge Offloading\nAfter clustering, a bounding box (i.e, image block) is generated for each cluster, including all detection boxes within it. Using these bounding boxes, a Dynamic Programming (DP)-based plan generator uses a latency-precision profile of various YOLOv8 models to assign the optimal model to each block. This selection maximizes accuracy under a global latency constraint. The selected models are offloaded in parallel to multiple edge servers, enabling parallel processing. Finally, the detected objects from each cluster are aggregated into the final output. (III-B)"}, {"title": "III. PROPOSED METHODOLOGY", "content": "A. Partitioning Scheme\nThis section presents our RL-based Dynamic Clustering Algorithm (RL-DCA). Unlike existing methods [5], [11], [12] that rely on predefined parameters or heuristics, RL-DCA is fully self-adaptive. RL-DCA can perform reasonable partition of the current frame without relying on any historical frame information. This is because the RL agent learns rich representations to handle diverse object scenarios in the training phase. In the following subsections, we describe the components and functioning of RL-DCA.\n1) Coarse Detection: For each input video frame, we first partition the frame into n \u00d7 E equally sized blocks, where E represents the number of edge devices in the system. This partitioning strategy ensures that each edge device processes a smaller portion of the frame, thereby evenly distributing the computational load and fully leveraging the collective computational power of the edge devices. Furthermore, after partitioning, the size of the objects in each block increases relative to the block resolution, making them more prominent in the feature maps. This improvement in object-to-pixel ratio enhances the detection accuracy and minimizes the risk of missing objects. Next, coarse detection is performed on the partitioned blocks. To maximize recall and ensure no objects are overlooked, we lower the confidence threshold appropriately. Missed detections, which are often caused by severe occlusion in densely packed areas, are mitigated in subsequent stages through clustering processes that leverage surrounding detections to recover the missed objects. Detection results from the edge devices are aggregated using Non-Maximum Suppression (NMS) to produce a unified set of object detections.\n2) Initial Clustering: Following the aggregation of detection results, RL-DCA uses the MeanShift algorithm for initial clustering of detected objects. MeanShift is a density-based method that identifies clusters of arbitrary shapes without requiring a predefined number of clusters, making it ideal for varying object distributions. This initial clustering organizes objects based on their spatial locations, forming preliminary clusters that serve as a foundation for further refinement by the RL agent.\nTo address the stratified distribution of object sizes in high-resolution frames-where upper blocks contain smaller, densely packed objects and lower blocks have larger, sparsely distributed objects-we apply a non-linear transformation to the y-coordinates of detected objects:\n$y_T = y^{\\alpha_T}$ (1)\nwhere y is the normalized y-coordinate of the object center in the range [0, 1], $\\alpha_T$ is a tunable parameter (0 < $\\alpha_T$ < 1) that controls the degree of transformation for the y-values. Stretching y-coordinates in the upper blocks improves separability, while compressing them in the lower blocks prevents unnecessary splitting of larger objects.\n3) PPO-based Cluster Adjustment: To address the limitation of MeanShift clustering, which solely considers the center points of detection boxes, we integrate RL policy network into our clustering pipeline.\nSpecifically, we employ the Proximal Policy Optimization (PPO) [13] algorithm, an actor-critic policy gradient method renowned for its balance between performance and computational efficiency. In this framework, the actor (policy network) interacts with the environment by selecting actions, while the critic network estimates the value function, predicting the expected cumulative rewards from given states.\na) Algorithm Overview: In RL-DCA, the policy network selects actions (keep, merge, or split clusters) based on the current clustering state, while the critic network evaluates the resulting state-action sequence to provide value estimates. By incorporating a custom reward function that quantifies clustering quality, PPO guides the policy network to learn optimal clustering adjustment strategies. Below, we detail the integration of PPO into RL-DCA, including the mathematical"}, {"title": "III. PROPOSED METHODOLOGY", "content": "b) State Representation: The state representation C = {C1, C2,...,CN} as a feature vector s. This state vector provides the actor and critic networks with sufficient information to make decisions and evaluate them. It has following features:\n\u2022 Centroids (\u03bc\u03b1, \u03bcy): Spatial center of each cluster.\n\u2022 Average Object Size (\u03bc\u03c9, \u03bc\u03b7): Mean width and height of the bounding box in the cluster.\n\u2022 Cluster Size (Si): Number of objects within each cluster.\n\u2022 Cluster Count (N): Total number of clusters.\nThe state vector for N clusters at step t is represented as:\n$s_t = [\\mu_x^{(1)}, \\mu_y^{(1)}, \\mu_w^{(1)}, \\mu_h^{(1)}, S_1, ..., \\mu_x^{(N)}, \\mu_y^{(N)}, \\mu_w^{(N)}, \\mu_h^{(N)}, S_N]$ (2)\nAs the input of policy network, the state will be padded or truncated to a fixed size to ensure consistency.\nc) Action Space: The policy network in RL-DCA selects one of the following discrete actions at based on the current state st:\nKeep: Maintain the current clustering configuration without changes. We define it as akeep. As a result:\n$s_{t+1} = s_t$, $C_{t+1} = C_t$ (3)\nThis action does not alter the state vector and is used when the clustering configuration is already optimal.\nMerge: The actor chooses two clusters closest in centroid distance to merge, this approach reduces redundant clusters and ensures that closely positioned objects are grouped together. The pair with the minimum distance is selected for merging, we define the merge action as:\n$a_{merge} (C_i, C_j)$ where $(i, j) = arg \\min_{i\\neq j} d_{ij}$ (4)\nThe state transition and clustering configuration change for merge action are:\n$s_{t+1} = Update(s_t, a_{merge} (C_i, C_j))$ (5)\n$C_{t+1} = {C_t \\backslash {C_i, C_j}} \\cup {C_{new}}$ (6)\nSplit: Select a cluster Ci and divide it into two sub-clusters $C_{new1}$ and $C_{new2}$. The process involves analyzing the spatial distribution of object centers within the cluster and applying 1D K-Means clustering along the most varied dimension (x-axis or y-axis). We define the split action as $a_{split}(C_i)$.\nWhy 1D K-Means? (i)As observed in III-A2, objects in the vertical (y-axis) dimension often exhibit significant variations in size and density, using 1D K-Means clustering along the y-axis can effectively separate clusters with vertically distinct object sizes; (ii)Object detection algorithms process rectangular blocks as inputs. By splitting clusters along a single dimension, the overlap between resulting sub-clusters is minimized; (iii)1D K-Means is computationally simpler than 2D K-Means.\nWe first compute the variance of detection box centers in both x- and y-directions, then select the dimension with the larger variance as the splitting direction D:\n$D = arg \\min_{d\\in{x,y}} Var_d$ (7)\nthe clustering process is:\n${C_{new1}, C_{new2}} = K-Means(C_i, k = 2, direction = D)$ (8)\nwhere k = 2 specifies that the cluster will be split into two sub-clusters. The new cluster information including bounding box distribution xk, yk, wk, hk and size $S_{new1}$ and $S_{new2}$ can be obtained after the K-Means process.\nThe state transition and clustering configuration change for split action are:\n$s_{t+1} = Update(s_t, a_{split}(C_i))$ (9)\n$C_{t+1} = {C_t \\backslash {C_i}}\\cup{C_{new1}, C_{new2}}$ (10)\nAfter all the discussion, the action space A can be expressed as:\n$A = {a_{keep}}\\cup{a_{merge}(C_i, C_j)} \\cup {a_{split}(C_i)}$ (11)\nd) Reward Function: At each decision step, after the actor selects an action and the environment updates the clustering configuration accordingly, a reward is computed, which guides the PPO agent to improve cluster quality over time."}, {"title": "III. PROPOSED METHODOLOGY", "content": "This reward is based on multiple metrics that reflect the desired properties of the clusters:\nCluster Tightness Penalty: For each cluster Ci, compute the mean distance of all its objects to the cluster centroid (\u03bc\u03b1, \u03bcy), then average this quantity over all N clusters:\n$R_t^{(1)} = \\frac{1}{N}\\sum_{i=1}^{N}\\frac{1}{S_i}\\sum_{(x,y) \\in C_i} ||(x, y) - (\\mu_x^{(i)}, \\mu_y^{(i)})||$ (12)\nThis ensures that the objects within a cluster are compactly grouped in the sub-image, reducing the proportion of background and enhancing detection accuracy.\nBy penalizing intra-cluster distances, the agent is incentivized to perform splits that yield more compact clusters, as much splits always reduce this penalty.\nObject Area Variance Penalty: For each cluster Ci, compute variance of object areas Aik, then average these variances across all clusters:\n$R_t^{(2)} = \\frac{1}{N}\\sum_{i=1}^{N} Var(A_{i1}, A_{i2}, ..., A_{iS_i})$ (13)\nThis ensures that objects within the same cluster have relatively uniform bounding box areas, minimizing heterogeneity in object sizes. Since the size of bounding boxes is often strongly correlated with the y-axis position, this penalty inherently encourages vertical splits for clusters with significant size variation.\nBy penalizing object area variance, the agent is encouraged to group objects of similar size together, possibly by splitting large, diverse clusters into more homogeneous sub-clusters or merging smaller, uniformly sized object clusters.\nCluster Count Penalty: A penalty is applied if the number of clusters N falls outside the acceptable range (Nmin, Nmax), increasing proportionally to the deviation from the minimum or maximum limits. No penalty is applied if N is within the range:\n$R_t^{(3)} = \\begin{cases} 0 & \\text{if } N_{min} \\le N \\le N_{max} \\\\ (N_{min} - N) & \\text{if } N < N_{min} \\\\ (N - N_{max}) & \\text{if } N > N_{max} \\end{cases}$ (14)\nThis reward means to keep the number of clusters N within a desirable range. This ensures that the clustering is neither too coarse (too few clusters) nor too fragmented (too many clusters), helps stabilize the clustering configuration, preventing extreme actions that would produce too many or too few clusters. The agent learns to split or merge just enough times to keep N within (Nmin, Nmax).\nClose Cluster Penalty: For each pair of distinct clusters (Ci, Cj), check if the distance between their centroids is less than dm, each pair that violates the separation threshold @ adds to the penalty:\n$R_t^{(4)} = -\\sum_{i=1}^{N} \\sum_{j=1, j\\neq i}^{N} I(||(\\mu_x^{(i)}, \\mu_y^{(i)}) - (\\mu_x^{(j)}, \\mu_y^{(j)})|| < d_m)$ (15)\nThe agent is encouraged to maintain adequate spacing between clusters, but more importantly, this penalty is designed to prevent the agent from repeatedly splitting the same cluster or its sub-clusters, leading to highly imbalanced cluster sizes and premature convergence once the desired number of clusters is reached. By discouraging excessively close clusters, the agent is incentivized to identify and prioritize clusters that genuinely require splitting, ensuring a more balanced and meaningful clustering configuration.\nCombined Reward Function: The final reward at time t after taking an action is:\n$R_t = \\alpha R_t^{(1)} + \\beta R_t^{(2)} + \\gamma R_t^{(3)} + \\delta R_t^{(4)}$ (16)\nThe parameters \u03b1, \u03b2, \u03b3, \u03b4 serve as weighting factors for the respective components of the reward function. This comprehensive reward function guides the RL agent towards producing more meaningful, efficient, and accurate clustering configurations in RL-DCA.\ne) Inference Stage: Overall, RL-DCA dynamically refines clusters by merging or splitting them based on learned policies, as detailed in Algorithm 1. After obtaining the final clusters, the blocks including all the detection boxes within each cluster will be used as blocks for offloading tasks."}, {"title": "III. PROPOSED METHODOLOGY", "content": "Algorithm 1: RL-DCA Inference\nInput: F: input frame, n: partition parameter, E: number of edge devices, \u03b1\u03c4: transform parameter, \u03c0\u03bf: policy network, Tmax: max steps\nOutput: Cfinal: final clustering configuration\n1 Step 1: Partitioning and Detection\n2 Divide F into n \u00d7 E segments and perform object detection on each segment. Aggregate detections and apply NMS to obtain results B.\n3 Step 2: Initial Clustering\n4 Transform y-coordinates using the formula: \u0443\u0442 = \u0443\u0441\u0442 Apply MeanShift clustering to form initial clusters C(0).\n5 Step 3: Cluster Adjustment\n6 for t 1 to Tmax do\n7 Compute state st from current clusters C(t-1);\n8 Select action at = arg maxa \u03c0\u03c1(\u03b1|St);\n9 Update clusters C(t) based on at;\n10 end\n11 return Cfinal = C(Tmax);\nB. Task Offloading Scheme\n1) Problem Formulation: We formulate the model selection task within each partition in II-B as a Multi-Choice Knapsack Problem (MCKP), aiming to maximize the overall detection accuracy under a global computational latency constraint. By modeling this decision-making process as an MCKP, we can systematically choose the most suitable object detection model for each partition given limited computational latency and diverse object characteristics.\na) Rationale for Partition-Level Model Selection: The input image is partitioned into several blocks based on object size, distribution, and presence of the object. Using YOLOv8"}, {"title": "III. PROPOSED METHODOLOGY", "content": "models for object detection, these blocks are processed under specific computational constraints. Each YOLOv8 model j has a fixed processing latency dj and accuracy pj for different detection scales. For each block, the goal is to select a model that maximizes overall accuracy while adhering to a global computational latency constraint Dcap.\nb) Definitions: For each bounding box cluster i (partition i) in the image:\n\u2022 Wi, Hi: Width and height of the original resolution of partition i.\n\u2022 Mi: Number of bounding boxes within cluster i.\n\u2022 Aik: Original area of the kth bounding box in partition i.\nWe consider five YOLOv8 models for selection: YOLOv8n (640x640), YOLOv8s (768 \u00d7 768), YOLOv8m (896\u00d7896), YOLOv81 (1024\u00d71024) and YOLOv8x (1280\u00d71280). When model j processes partition i, the image block is resized to Sjx Sj, and the bounding box area scales proportionally as:\n$A_{ik} (j) = A_{ik} \\times \\frac{S_j}{W_i \\times H_i}$ (17)\nThe precision mapping function pj determines the accuracy corresponding to the resized area $A_{ik}(j)$. The average precision Pij for partition i using model j is:\n$P_{ij} = \\frac{1}{M_i} \\sum_{k=1}^{M_i}P_j (A_{ik} (j))$ (18)\nc) Decision Variables: We define the binary decision variable Xij:\n$X_{ij} \\begin{cases} 1 & \\text{if model j is selected for partition i} \\\\ 0 & \\text{otherwise} \\end{cases}$ (19)\nd) Objective Function: The objective is to maximize the overall accuracy across all partitions:\n$max \\sum_{i=1}^{N}\\sum_{j} P_{ij}x_{ij}$ (20)\ne) Constraints:\n\u2022 Model Selection for Each partition: Each partition i must select exactly one model:\n$\\sum_{j}x_{ij} = 1, i = 1, ..., N$ (21)\nGlobal Latency Constraint: The total processing latency must not exceed the specified limit Dmax:\n$\\sum_{i=1}^{N}\\sum_{j}d_jx_{ij} \\le D_{max}$ (22)\n2) DP-based Task Offloading: To address MCKP problem, we propose a DP-based approach to optimally assign image blocks to detection models across multiple edge servers. This method aims to maximize detection accuracy while ensuring that inference latency remains within the threshold Dmax \u2022\nSpecifically, we first determine the detection precision for each image block and the inference latency for each model."}, {"title": "IV. PERFORMANCE EVALUATION", "content": "A. Experimental Setup\nPlatforms: We implement RE-POSE on four (E = 4) NVIDIA Jetson Orin NX (16GB) devices (shown in Fig. 2). The Jetson power mode is set to MAXN to ensure maximum performance. PyTorch is utilized as the inference engine on GPUs for object detection tasks.\nModels: The YOLOv8 family forms the network unit of our RE-POSE framework. In particular, we deploy different YOLOv8 models on each Jetson Orin to account for computational constraints. Specifically, each edge server is equipped with a distinct YOLOv8 model paired with the YOLOv81 model for coarse detection.\nRL-DCA parameters: The parameters we use for RL-DCA training and inference are shown in the supplemental material. For policy network \u03c0\u0e2d and critic network Vo, we use two multilayer perceptrons (MLP) consist of two hidden layers with 128 neurons each and ReLU activation functions.\nDataset: We evaluate RE-POSE using the PANDA [14] dataset, resizing the images from their original resolutions to 4K (3840 x 2160).\nBaselines: Our baselines consist of two high-resolution object detection solutions:\n\u2022 Simple Partitioning with Basic Object Detection: We uniformly partition the original image into 2 \u00d7 2 blocks and perform object detection on each block independently. The results are then concatenated. An overlap ratio of 30% is applied to prevent objects from being truncated during partitioning.\n\u2022 REMIX [5]: REMIX is a well-established solution that enhances inference accuracy within a latency budget. It employs a prune-and-search-based method to generate"}, {"title": "IV. PERFORMANCE EVALUATION", "content": "partition plans, assigning an appropriate model to each block based on object distribution in historical frames.\nMetrics: The experiments utilize mean Average Precision (mAP) at Intersection over Union (IoU) thresholds ranging from 50% to 95% (mAP50:95) and processing latency (T\u2081) as the primary evaluation metrics.\nB. Experimental Results\n1) Overall Performance: As illustrated in Fig. 3, RE-POSE outperforms all baselines, achieving up to a 25% increase in mAP50:95 under similar latency conditions. This superior performance is attributed to two main factors:\nFirst, RE-POSE efficiently utilizes computational resources through parallel coarse detection and task offloading, enabling focused detection on critical scene areas. In contrast, Remix relies on historical frame statistics, which may not accurately capture the current object distribution.\nSecond, traditional partitioning methods often fragment target objects in dense scenes, leading to significant precision loss despite attempts to mitigate this with overlapping blocks. RE-POSE's RL-DCA addresses partition loss by employing one-dimensional clustering, maintaining high detection accuracy even in densely packed environments.\n2) Evaluation of Coarse Detection: The quality of coarse detection significantly impacts overall performance. Fig. 4 shows that performing coarse detection on uniformly partitioned images (2\u00d72) consistently outperforms no partitioning under the same latency constraints. This improvement is due to better object coverage, as coarse detection on the full image misses certain objects, limiting the effectiveness of subsequent detection stages.\n3) Evaluation of RL-DCA: Replacing RL-DCA with the MeanShift algorithm, as showed in Fig. 5, results in a noticeable decline in performance. MeanShift does not account for the correlation between object positions and sizes, leading to imbalanced clusters and inaccurate detections, especially in dense scenes. Additionally, MeanShift's inability to control the number of clusters exacerbates these issues. In contrast, RL-DCA maintains high accuracy with acceptable latency by effectively managing cluster sizes and distributions."}, {"title": "V. CONCLUSION", "content": "In this paper, we introduced RE-POSE, a RL-driven framework that adaptively partitions high-resolution video frames and efficiently offloads tasks among edge servers, significantly improving object detection accuracy under given latency constraints. Experimental results demonstrate that RE-POSE outperforms existing solutions for high-resolution real-time object detection."}]}