{"title": "Large Language Models as Zero-shot\nDialogue State Tracker through Function Calling", "authors": ["Zekun Li", "Zhiyu Zoey Chen", "Mike Ross", "Patrick Huber", "Seungwhan Moon", "Zhaojiang Lin", "Luna Dong", "Adithya Sagar", "Xifeng Yan", "Paul A. Crook"], "abstract": "Large language models (LLMs) are increasingly prevalent in conversational systems due\nto their advanced understanding and generative\ncapabilities in general contexts. However, their\neffectiveness in task-oriented dialogues (TOD),\nwhich requires not only response generation\nbut also effective dialogue state tracking (DST)\nwithin specific tasks and domains, remains less\nsatisfying. In this work, we propose a novel ap-\nproach FNCTOD for solving DST with LLMs\nthrough function calling. This method im-\nproves zero-shot DST, allowing adaptation to\ndiverse domains without extensive data collec-\ntion or model tuning. Our experimental results\ndemonstrate that our approach achieves ex\u0441\u0435\u0440-\ntional performance with both modestly sized\nopen-source and also proprietary LLMs: with\nin-context prompting it enables various 7B or\n13B parameter models to surpass the previous\nstate-of-the-art (SOTA) achieved by ChatGPT,\nand improves ChatGPT's performance beating\nthe SOTA by 5.6% Avg. JGA. Individual model\nresults for GPT-3.5 and GPT-4 are boosted by\n4.8% and 14%, respectively. We also show\nthat by fine-tuning on a small collection of di-\nverse task-oriented dialogues, we can equip\nmodestly sized models, specifically a 13B pa-\nrameter LLaMA2-Chat model, with function-\ncalling capabilities and DST performance com-\nparable to ChatGPT while maintaining their\nchat capabilities. We will open-source experi-\nmental code and model.", "sections": [{"title": "1 Introduction", "content": "Recent years have seen the rapid development of\nlarge language models (LLMs) that have demon-\nstrated exceptional natural language understand-\ning and generation capabilities. The integration\nof LLMs into industry applications, particularly as\nconversational assistants, is a notable trend. Fine-\ntuned with conversations between users and assis-"}, {"title": "2 Related Work", "content": null}, {"title": "2.1 Dialogue State Tracking", "content": "DST is an essential, yet challenging task in the con-\nstruction of TOD systems. Its primary purpose is to\nextract and track user goals at each turn throughout\nthe conversation. The tracked dialogue state is usu-\nally represented in the slot values of the predefined\nschema for specific domains. This requires the\nslot values to adhere closely to the domain-specific\nschema. Consequently, previous methods have re-\nlied on the collection and annotation of domain-\nspecific dialogues for model training (Lee et al.,\n2019; Wu et al., 2019; Heck et al., 2020; Hosseini-\nAsl et al., 2020; Peng et al., 2020; Lin et al., 2020)\nHowever, obtaining training data is notoriously ex-\npensive, even with methods that utilize GPT-3 to\nautomatically simulate such data (Li et al., 2022).\nFurthermore, these approaches are limited to han-\ndling only the domains covered in the training data.\nTo address zero-shot DST in unseen domains,\nprevious cross-domain transfer strategies based on\nsmall models typically leverage extra dialogue cor-\npora in similar domains (Wu et al., 2020; Lin et al.,\n2021b; Su et al., 2021) or redefining DST in terms\nof other types of tasks, such as question answer-\ning (Lin et al., 2021c) or summarization (Shin et al.,\n2022) to find appropriate additional training data.\nDespite these efforts, their overall zero-shot perfor-\nmance remains relatively low."}, {"title": "2.2 Leveraging LLMs for Dialogue Tasks", "content": "LLMs (Brown et al., 2020; Chowdhery et al., 2023;\nOpenAI, 2023) have demonstrated remarkable ca-\npabilities in handling various tasks without requir-\ning further tuning. Recent chat/instruction-tuned\nmodels further exhibit impressive performance in\nconversational contexts (Touvron et al., 2023; Chi-\nang et al., 2023; Yang et al., 2023). However, cur-\nrent chat models primarily focus on general con-\nversation, often omitting task-oriented dialogues\n(TOD). TOD differs from general conversation\nin that it requires models to not only generate\nresponses but also track dialogue states accord-\ning to domain-specific schemas. While ChatGPT\nhas shown effectiveness in response generation\nwithin TOD (Li et al., 2023c), their performance of\nzero-shot DST, as explored in recent research on\nprompting approaches (Hu et al., 2022; Bang et al.,\n2023; Hude\u010dek and Du\u0161ek, 2023; Heck et al., 2023;\nZhang et al., 2023; Chung et al., 2023), are still not\nsatisfying, which remains a significant challenge."}, {"title": "2.3 Tool Usage within LLMS", "content": "Early work on tool usage (Parisi et al., 2022;\nSchick et al., 2023) and the recent launch of GPT-\n4 plug-in and function calling features (OpenAI,\n2023), have highlighted the importance of func-\ntion calling for LLMs, encouraging follow-up\nwork (Patil et al., 2023; Shen et al., 2023; Li et al.,\n2023a). Commonly integrated tools include web\nbrowsers, calculators (Cobbe et al., 2021), trans-\nlation systems, and so on. We are the first to uti-\nlize this tool usage/function calling capability to\nsolve the challenging DST task in TOD with LLMs,\nbridging the gap between general conversation and\ntask-oriented dialogues."}, {"title": "3 Background", "content": null}, {"title": "3.1 Chat-tuned LLMs", "content": "Chat-tuned LLMs are models specifically fine-\ntuned to interact with users in a conversational\nmanner. This category encompasses proprietary\nmodels such as ChatGPT and Claude, as well as\nopen-source models such as Vicuna (Chiang et al.,\n2023), LLaMA2-Chat (Touvron et al., 2023), and\nBaichuan (Yang et al., 2023). These chat models\ntypically start as base models that are further fine-\ntuned with a dialogue format, enabling them to\nfunction effectively as conversational agents. As\ndepicted in Figure 2, the dialogue format typically\nfeatures three distinct roles within two components:\n(1) the system role in the system prompt section,\nwhich defines the assistant's roles, responsibilities,\nand expected behaviors; and (2) the user and assis-\ntant roles in the dialogue context section, encom-\npassing their conversation. The model is typically\ntasked to produce the assistant's responses to the\nuser's input. These chat models are primarily de-\nsigned to generate helpful, detailed, and friendly\nresponses to general user inquiries, rather than han-\ndling task-specific conversations as in TOD."}, {"title": "3.2 DST Task Formulation", "content": "In TOD, at each turn of conversation, the task of\nDST is to summarize the dialogue state $S_t$ given\nthe dialogue context $C_t = {A_1, U_1,\\cdots, A_t, U_t}$,\nwhere $U_t$ and $A_t$ represent the user utterance and\nassistant response at the t-th turn. For simplicity,\nwe will omit the turn index t in subsequent discus-\nsions. The dialogue state $S$ is a set of slot-value\npairs:\n$S = {($s_{1,D_1}$, $v_{1,D_1}$), \\cdots, ($s_{i,D_j}$, $v_{i,D_j}$)}.$"}, {"title": "4 Approach", "content": "Our method redefines DST as function calling,\ntreating each domain as a distinct function, and\nthe slot values within the domain as its arguments.\nAs shown in Figure 2, this paradigm is represented\nin chat-tuned models by embedding function speci-\nfications within system prompts, as shown in Fig-\nure 3. The model is tasked with generating function\ncalls followed by a response, as shown in Figure 4.\nWe provide more details of our approach below."}, {"title": "DST as Function Calling", "content": "In our formalization,\nDST is conceptualized as function calling. Each\ndomain $D_j$ is modeled as a unique function $F_j$,\nwith the associated slot values serving as arguments.\nConsequently, at each turn of the conversation, the\nDST task transforms into identifying the correct\nfunction $F_j$ and its arguments $S_{D_j}$:\n<fn_call> $F_j$($s_{1,D_1} = v_{1,D_1}$, $s_{2,D_1} = v_{2,D_1}$,\n$\\cdots$, $s_{i,D_j} = v_{i,D_j}$) </fn_call>,\nwhere \"<fn_call>\" and \"</fn_call>\" are special\ntokens. In practice, we use \u201c<function_call>\"\nand \u201c</function_call>\u201d to represent them and\ngenerate the function call in JSON format. Some\nexamples of function calls generated within a con-\nversation are shown in Figure 4."}, {"title": "Dialogue Prompt Format", "content": "As shown in Figure 4,\nwe incorporate this function calling as an integral\npart of the conversation. At each turn of the con-\nversation, given the current conversation context,\nthe chat model is tasked with first generating the\nfunction call, followed by the response. To achieve\nthat, we convert the domain schema into function\nspecifications, using JSON, and include them in\nthe system prompt within the dialogue prompt, as"}, {"title": "Function Call Decomposition", "content": "As outlined, the\nmodel is required to predict not just which func-\ntion to call (i.e., function name) but also generate\narguments for the predicted functions. To stream-\nline this process and enhance control, we split it\ninto two consecutive steps: Function Selection\nand Argument Generation. As shown in Figure 2,\nfor each turn of the conversation, the model first\nselects a function $F_j$ from the supported functions.\nIn this step, we only include the function descrip-\ntions in the system prompt and prompt the model to\ngenerate only the selected domain/function, sur-\nrounded by the special tokens \u201c<domain>\u201d and\n\u201c</domain>\u201d. Subsequently, we include the full\nspecification of the chosen function $F_j$ in the sys-\ntem prompt, prompting the model to generate the\ncorresponding arguments for the function $F_j$."}, {"title": "In-context Prompting", "content": "Since the current open-\nsource models are not specifically fine-tuned to gen-\nerate function calls, there is no guarantee that the\nmodel could always generate the correct formats.\nTo address that, we also include in-context example\nconversations as shown in Figure 4, along with the"}, {"title": "Model Fine-tuning", "content": "To equip open source models\nwith function calling capabilities without needing\ndemonstration examples, we fine-tune a LLAMA2-\n13B-CHAT model using a collection of heteroge-\nneous task-oriented dialogue datasets - including\nWOZ (Mrk\u0161i\u0107 et al., 2016), CamRest676 (Wen\net al., 2016b,a), MSR-E2E (Li et al., 2018),\nTaskMaster (Byrne et al., 2019) and Schema-\nGuided Dialogues (SGD) (Rastogi et al., 2020).\nNote that we deliberately exclude the whole tar-\nget test dataset. From these datasets, we choose\n36 distinct domains/functions with high-quality an-\nnotations. Instead of using all the data in those\ndatasets, we randomly sampled 200 dialogues from\neach domain across the datasets, totaling 7,200 di-\nalogues for training. This sample size has already\nproved sufficient for effective results.\nDuring training, we incorporate the specifica-\ntions of all functions invoked in each conversation's\nsystem prompt. Our loss calculation focused solely\non the function calling aspect of the assistant's\ngeneration. We refrained from fine-tuning the re-\nsponse generation component, in consideration of\nthe LLMs' existing competence in producing coher-\nent responses and the scarcity of function-calling\nexamples in our dataset. The fine-tuned model is\ndubbed FNCTOD-LLAMA2-13B."}, {"title": "5 Experiments", "content": null}, {"title": "5.1 Experimental Setup", "content": "Dataset and Metrics We evaluate on the widely-\nused task-oriented multi-domain dataset Multi-\nWOZ 2.1 (Budzianowski et al., 2018; Eric et al.,\n2020). We used the 1,000 dialogues in the test split\nand measured joint goal accuracy (JGA), which\nmeasures the percentage of turns for which all slot\nvalues are correctly predicted. This test set spans 5\ndomains, with each conversation potentially cover-\ning multiple domains.\nBaselines We compare our approach with two\ndistinct approaches: (1) Cross-domain transfer ap-\nproaches, which involve training on MultiWOZ\nwith one domain excluded and then evaluating\non the held-out domain. This category includes\nmethods including TRADE (Wu et al., 2019),\nMA-DST (Kumar et al., 2020), TransferQA (Lin\net al., 2021b), T5DST (Lin et al., 2021c), and"}, {"title": "5.2 Zero-shot DST Evaluation", "content": "Table 2 presents the zero-shot DST performance\ncomparison, with observations summarized below.\nOur approach empowers moderately-sized open-\nsource models to surpass previous SOTA re-\nsults achieved with advanced ChatGPT. Previ-\nous prompting approaches showed promising re-\nsults exclusively with advanced proprietary mod-"}, {"title": "5.3 Zero-shot End-to-End TOD Evaluation", "content": "In practical settings, a TOD system queries a knowl-\nedge base or API using the tracked dialogue states\nto ground responses. We perform an end-to-end\nevaluation of both DST and response generation,\nwhich is a more realistic and challenging setting.\nOur FNCTOD approach enables the generation of\nboth dialogue states, i.e., function calls, and re-\nsponses in the assistant's output. This contrasts\nwith the prompting methods that typically treat\nDST as a standalone task. Consistent with the\nprevious work on end-to-end zero-shot TOD eval-\nuation (Hude\u010dek and Du\u0161ek, 2023), we evaluated\nusing the MultiWOZ 2.2 dataset (Zang et al., 2020)\nwith delexicalized responses. Our evaluation met-\nrics include JGA for DST and Success rate for the\ngenerated response. Success measures the percent-\nage of dialogues in which the user's goals were\nfully met. The results are presented in Table 3."}, {"title": "5.4 Ablation Studies", "content": "Impact of different numbers of in-context exam-\nples Our initial investigation focuses on the influ-\nence of varying the number of in-context examples\nwhen conducting few-shot prompting with open-\nsource models, which were not originally trained\nfor function call generation. We assessed the perfor-\nmance of various models with different numbers of\nin-context examples, ranging from 0 to 5. We note\nthat using more than five examples might surpass\nthe context-window capacity (such as 4096 tokens)\nfor some models. The findings are illustrated in Fig-\nure 5. The results indicate that the models perform\nsignificantly better when in-context examples are\nutilized compared to zero-shot prompting. Further-\nmore, there is a consistent performance improve-\nment as the number of examples increases, across\nmost domains and models. This underscores the\ncrucial role of in-context examples when leverag-\ning open-source models for DST through function\ncalling, which is reasonable given that these models\nwere not fine-tuned to equip with the capability to\ngenerate function calls in the required format solely\naccording to the function specification within the\nsystem prompt."}, {"title": "6 Conclusion", "content": "We introduce a new approach to tackle the challeng-\ning task of zero-shot DST with LLMs, enabling\nthem to handle both general conversations and\ntask-oriented dialogues in diverse domains with-\nout the need for additional data collection. Our\nexperimental results on MultiWOZ demonstrate\nthat our approach not only delivers exceptional per-\nformance in advanced ChatGPT models (setting a\nnew benchmark) but also across a range of moder-\nately sized open-source LLMs. Furthermore, we\ndemonstrate that we can fine-tune the open-source"}, {"title": "7 Limitations", "content": "In this work, we propose a novel approach to solve\nzero-shot DST with LLMs. Our approach achieves\noutstanding performance with various LLMs, both\nmodestly-sized open-source and advanced propri-\netary LLMs, setting the new state-of-the-art. How-\never, it is important to recognize that the current\naccuracy may still not yet be high enough for the\npractical deployment of such zero-shot systems.\nWe anticipate that with further advancements in\nthe NLU and NLG capabilities of base LLMs, our\napproach could achieve even greater performance\nlevels. In addition, while our approach can han-\ndle both the DST and response generation task in\nTOD, it is worth noting that due to the current\nlack of a more realistic evaluation setting for re-\nsponse generation in TOD, we used delexicalized\nresponses for evaluation as this is widely used in\nprior work. This setting and associated metrics\nhave some known shortfalls in terms of being able\nto game-the-metrics with nonnatural responses as\nwell as presenting a data mismatch with how LLMs\nare trained. In the era of LLMs, we advocate for\nthe development of more realistic evaluation ap-\nproaches for full-natural-language-response gener-\nation in TOD."}, {"title": "A Appendix", "content": null}, {"title": "A.1 Evaluation Details", "content": "We evaluated two versions of ChatGPT and six\nleading chat/instruction-tuned LLMs representing\nvarying sizes and instruction-following and con-\nversational capabilities. The six evaluated open-\nsource models include: ZEPHYR-7B-BETA (Tun-\nstall et al., 2023) is an instruction-tuned version\nof Mistral-7B (Jiang et al., 2023), which is the\nleading model among its size on the AlpacaE-\nval leaderboard (Li et al., 2023b). VICUNA-7B-\nV1.5 and VICUNA-13B-v1.5 (Chiang et al., 2023)\nare LLAMA-2 models fine-tuned on user conver-\nsations with ChatGPT. LLAMA2-7B-CHAT and\nLLAMA2-13B-CHAT are chat-tuned versions of\nLLAMA2 models with varying sizes (Touvron\net al., 2023). BAICHUAN2-13B-CHAT is also a\nLLAMA2-13B model further fine-tuned on exten-\nsive corpus (Baichuan, 2023). we utilized their\ncheckpoints available on Huggingface. The spe-\ncific paths for these models are detailed in Table 8.\nFor inference, the temperature was fixed as 0.3,\ntop_p as 0.2, and max_tokens as 128. For each test\ncase, we conducted a single inference run. All in-\nferences were executed on a cluster equipped with\neight 48G NVIDIA RTX A6000 GPUs."}, {"title": "A.2 Training Details", "content": "Training Data For constructing our fine-tuning\ndataset, we selected five high-quality, multi-turn\nTOD corpora, excluding MultiWOZ, as detailed in\nTable 9. Each dataset encompasses one or multiple\ndomains. We excluded several domains with low-\nquality annotations, retaining a total of 36 domains.\nFor our fine-tuning, we exclusively sampled data\nfrom the training sets of these datasets to constitute\nour training data."}, {"title": "Hyperparameters", "content": "We fine-tuned the LLaMA-2-\n13b-Chat checkpoint from Hugginface. We uti-\nlize Low Rank Approximation (LoRA) (Hu et al.,\n2021) and limited our fine-tuning to the parameters\nin the q_proj and v_proj modules. Further de-\ntails about the fine-tuning hyperparameters can be\nfound in Table 6. The fine-tuning was conducted\non 4 A6000 48GB GPUs."}, {"title": "A.3 More Results", "content": null}, {"title": "A.3.1 Function Selection Accuracy", "content": "In our approach, we divide the function call gener-\nation process into two steps: (1) Function/domain\nselection: The model selects a function/domain\nto call from the list of all supported functions by\ngenerating the function name. (2) Argument gener-\nation: The model generates the arguments for the\nselected function. We present the results using the\npredicted domains instead of oracle domains in Ta-\nble 2. Additionally, we provide the accuracy of the\nfunction/domain prediction in Table 7. It is evident\nthat function/domain selection is a straightforward\ntask for all the evaluated models."}, {"title": "A.3.2 Ablation Studies", "content": "We conduct more investigation focused on effec-\ntive prompt strategies, including the effective dia-\nlogue prompt format and methods for describing\nsupported functions."}, {"title": "Impact of the unified dialogue prompt", "content": "We ini-\ntiated our analysis into effective prompt strategies\nfor in-context prompting using open-source models.\nIn our approach, we seamlessly integrated function\ncalls into the assistant's output, incorporating them\nwithin the conversation context rather than treating\nthem as a separate task. To evaluate its impact,\nwe compared scenarios where function calls were\nincluded or omitted from the conversation context."}]}