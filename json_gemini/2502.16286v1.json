{"title": "Verification of Bit-Flip Attacks against Quantized Neural Networks", "authors": ["YEDI ZHANG", "LEI HUANG", "PENGFEI GAO", "FU SONG", "JUN SUN", "JIN SONG DONG"], "abstract": "In the rapidly evolving landscape of neural network security, the resilience of neural networks against bit-flip attacks (i.e., an attacker maliciously flips an extremely small amount of bits within its parameter storage memory system to induce harmful behavior), has emerged as a relevant area of research. Existing studies suggest that quantization may serve as a viable defense against such attacks. Recognizing the documented susceptibility of real-valued neural networks to such attacks and the comparative robustness of quantized neural networks (QNNs), in this work, we introduce BFAVerifier, the first verification framework designed to formally verify the absence of bit-flip attacks or to identify all vulnerable parameters in a sound and rigorous manner. BFAVerifier comprises two integral components: an abstraction-based method and an MILP-based method. Specifically, we first conduct a reachability analysis with respect to symbolic parameters that represent the potential bit-flip attacks, based on a novel abstract domain with a sound guarantee. If the reachability analysis fails to prove the resilience of such attacks, then we encode this verification problem into an equivalent MILP problem which can be solved by off-the-shelf solvers. Therefore, BFAVerifier is sound, complete, and reasonably efficient. We conduct extensive experiments, which demonstrate its effectiveness and efficiency across various network architectures, quantization bit-widths, and adversary capabilities.", "sections": [{"title": "1 Introduction", "content": "Neural networks have demonstrated their potential to achieve human-level performance in multiple domains [17, 53]. However, they are fragile in many ways and can be easily manipulated through various attacks [8, 10-12, 30, 38, 50, 67, 82, 89]. Recently, bit-flip attacks (BFAs) [16, 46, 59, 61] have become a critical class of hardware-based adversarial threats that exploit the physical vulnerability of neural networks. These attacks involve maliciously flipping the bits in the memory cells that store the parameters of a neural network during the deployment stage or changing the real-time activation values during the inference stage. Such attacks have been demonstrated to be feasible in practice for altering the behavior of networks in multiple cases [7, 70, 73]. For instance, RowHammer [54, 69] is one of the most widely used BFA methods which exploits a vulnerability in DRAM by repeatedly accessing memory rows to induce unintended bit flips in adjacent rows, compromising data integrity and security for network parameters. Unlike traditional software-level adversarial attacks, which typically require modifications to input data, BFAs directly target the underlying hardware (e.g., memory), making them particularly effective and difficult to defend against.\nModern DNNs, characterized by their large sizes and 32-bit floating-point parameters, face high computational and storage demands, hindering their deployment on resource-limited embedded devices. Quantization [24, 27, 33], reducing the precision of parameters and/or activation values, offers a promising solution to compress the network, and enables the deployment of quantized neural networks (QNNs) on such devices. For example, the Tesla-FSD chip [78] employs an 8-bit integer format to store all network weights. On the other hand, QNNs have been demonstrated to exhibit greater resilience to BFAs compared to their real-valued counterparts. Specifically, DNNs are highly susceptible to BFAs, with successful attack rates reaching nearly 99% [30], particularly through the manipulation of the exponential bit of compromised parameters. In response, numerous defense strategies have been proposed [39, 48, 68], leveraging parameter quantization to fortify network security against bit-flip attacks. Despite these measures, QNNs remain vulnerable to BFAs, as existing defense techniques fall short of providing formal security assurances against such attacks. This vulnerability underscores the critical need for developing a rigorous verification method to ascertain the absence of BFAs, ensuring the integrity and reliability of QNNs in security-sensitive applications.\nMain contributions. In this work, we propose the first Bit-Flip Attacks Verification method (BFAVerifier) to efficiently and effectively verify if the bit-flip attacks are absent given a QNN, concerning a given input region, that is also sound and complete. It guarantees the safety of the QNN (such as robustness with respect to a specified input region) when facing potential bit-flip attacks. Given a QNN and an input region, BFAVerifier first conducts a novel reachability analysis"}, {"title": "2 Preliminary", "content": "We denote by R (resp. N) the set of real (resp. integer) numbers. Given a positive integer n, we denote by [n] the set of positive integers {1, 2, . . ., n}. We use x, x', . . . to denote scalars, x, x', . . . to"}, {"title": "2.1 Neural Network and Quantization", "content": "In this section, we provide the minimal necessary background on neural networks and the quantization scheme considered in this work. Specifically, we focus on feedforward deep neural networks (DNNs) used for classification problems.\nNeural networks. A DNN consists of an input layer, multiple hidden layers, and an output layer. Each layer contains neurons connected via weighted edges to the neurons in the subsequent layer. Specifically, each neuron in a non-input layer is additionally linked with a bias term. Given an input, a DNN computes an output by propagating it through the network layer by layer and gets the classification result by identifying the dimension with the highest value in the output vector. A DNN with d layers can be represented by a non-linear multivariate function $N: \\mathbb{R}^n \\rightarrow \\mathbb{R}^s$. For any input $x \\in \\mathbb{R}^n$, let $x = x^1$, the output $N(x) = W^dx^{d-1} + b^d$ can be obtained via the recursive definition $x^i = ReLU(W^ix^{i-1} + b^i)$ for $i \\in \\{2, 3, ..., d - 1\\}$, where $W^i$ and $b^i$ (for $2 \\leq i \\leq d$) are the weight matrix and bias vector of the $i$-th layer. We refer to $x_j^i$ as $j$-th neuron in the $i$-th layer and use $n_i$ to denote the dimension of the $i$-th layer. $n = n_1$ and $s = n_d$.\nQuantization. Quantization is the process of converting high-precision floating-point values into a finite range of lower-precision ones, i.e., fixed-point numbers, without significant accuracy loss. A quantized neural network (QNN) is structurally similar to a DNN, except that the parameters and/or activation values are quantized into fixed-pointed numbers, e.g., 4-bit or 8-bit integers. In this work, we adopt the symmetric quantization scheme widely utilized in prior research concerning bit-blip attack (BFA) strategies on QNNs [16], where only parameters are quantized to reduce the memory requirements [27, 83, 91]. During inference, we assume that the parameters are de-quantized and all operations within the quantized networks are executed using floating-point arithmetic.\nGiven the weight matrix $W^i$ and the bias vector $b^i$, their signed integer counterparts $\\widehat{W}^i$ and $\\widehat{b}^i$ with respect to quantization bit-width Q are respectively defined as follows. For each $j, k$,\n$\\widehat{W}_{j,k}^i = \\lfloor W_{j,k}^i/\\Delta w^i \\rceil$, $\\widehat{b}_j^i = \\lfloor b_j^i/\\Delta w^i \\rceil$\nwhere $\\Delta w^i = maxAbs(W^i, b^i)/(2^{Q-1} - 1)$ is the quantization step size of the $i$-th layer and the max function returns the maximal value of $W^i$ and $b^i$. $\\lfloor \\cdot \\rceil$ is the rounding operator, $maxAbs(W^i, b^i)$ means finding the maximum absolute value among all the entries from $W^i$ and $b^i$.\nOnce quantized into an integer, the parameter will be stored as the two's complement format in the memory. In the forward pass, the parameters will be de-quantized by multiplying the step size $\\Delta w^i$. Taking a quantized parameter $\\widehat{W}_{j,k}^i$ as an example and let $t(\\cdot)$ denote the operation that converts an integer into its two's complement expressions. Assume that $t(\\widehat{W}_{j,k}^i) = [v_0; v_{Q-1}; ... ; v_1]$, then"}, {"title": "2.2 Bit-Flip Attacks", "content": "Bit-flip attacks (BFAs) are a class of fault-injection attacks that were originally proposed to breach cryptographic primitives [3, 5, 6]. Recently, BFAs have been ported to neural networks.\nAttack scenarios and threat model. Recent studies [40, 60, 82] have revealed vulnerabilities in DRAM chips, which act as a crucial memory component in hardware systems. Specifically, an adversary can induce bit-flips in memory by repeatedly accessing the adjacent memory rows in DRAM, without direct access to the victim model's memory, known as Rowhammer attack [40]. Such attacks exploit an unintended side effect in DRAM, where memory cells interact electrically by leaking charges, potentially altering the contents of nearby memory rows that were not originally targeted in the memory access. Although such attacks do not grant adversaries full control over the number or precise location of bit-flips and the most prevalent BFA tools such as DeepHammer [82] can typically induce only a single bit-flip, the recent study [16] has demonstrated that an adversary can effectively attack a QNN by flipping, on average, just one critical bit during the deployment stage. While indirectly flipping multiple bits is theoretically feasible, achieving this would require highly sophisticated techniques that are both extremely time-intensive and have a low likelihood of success in practice [60]. Therefore, in this study, we assume that the adversary can indirectly manipulate only a minimal number of parameters in a QNN, by default 1. More powerful attacks that can directly manipulate memory go beyond the scope of this work. On the other hand, though most of the existing BFAs target weights only [16, 30, 46, 61], in this work, we consider a more general setting where all parameters (weights and biases) of QNNs are vulnerable to BFAs [68]."}, {"title": "3 Bit-Flip Attack Verification Problem", "content": "In this section, we define the verification problem considered in this work and discuss a naive baseline solution based on DeepPoly."}, {"title": "3.1 Problem Definition", "content": "Definition 3.1 (BFA-tolerance). Let $N: \\mathbb{R}^n \\rightarrow \\mathbb{R}^s$ be a QNN. Given a pre-condition $\\phi$ over the input $x \\in \\mathbb{R}^n$ and post-condition $\\psi$ over the output $N(x) \\in \\mathbb{R}^s$. We use $N\\models_{m,n} \\langle \\phi, \\psi \\rangle$ to denote that for any $(m, n)$-attack vector $\\rho$, $\\phi(x) \\Rightarrow \\psi(N^{\\rho}(x))$ always holds, where $N^{\\rho}$ is the network obtained from $N$ given the attack vector $\\rho$.\nIf $N\\models_{m,n} \\langle \\phi, \\psi \\rangle$ holds, we say that $N$ is BFA-tolerant to the property $(\\psi, \\phi)$. Note that, such a formulation of the problem is expressive enough to cover a range of desired neural network properties, including safety, robustness, (counterfactual) fairness, and backdoor-absence.\nTHEOREM 3.2. Verifying whether $N\\models_{m,n} \\langle \\phi, \\psi \\rangle$ holds is NP-complete.\nIn the following, for the sake of readability, our discussion focuses on the following general BFA-tolerant robustness property.\nDefinition 3.3 (BFA-tolerant Robustness). Let $N: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ be a QNN, $I \\subset \\mathbb{R}^n$ be an input region, and g is a target class. N is BFA-tolerant for robustness with respect to the region I and the class g if $N\\models_{m,n} \\langle \\phi, \\psi \\rangle$ returns true, where $\\phi(x) := x \\in I$, $\\psi(y) := argmax(y) = g$."}, {"title": "3.2 A Naive Method by DeepPoly", "content": "Next, we present a baseline approach that reduces the BFA verification problem to a classic neural network verification problem so that the existing verifier, such as DeepPoly [66], can be used to verify the above BFA-tolerant properties.\nReview of DeepPoly. The key idea of DeepPoly is to approximate the behavior of the neural network based on an abstract interpreter specifically tailored to the setting of neural networks. Specifically, the abstract domain A is a combination of polyhedra, coupled with abstract transformers for neural network functions, including affine functions and activation functions. To achieve this, each neuron in the hidden layer $x_j^i$ (the $j$-th neuron in the $i$-th layer) with $x_j^i = ReLU(W_j^ix^{i-1} + b^i)$ is seen into two nodes $x_{j,1}^i$ and $x_{j,2}^i$ such that $x_{j,1}^i = W_j^ix^{i-1} + b^i$ and $x_{j,2}^i = ReLU(x_{j,1}^i)$, where $x_k^{i-1} = x_{k,1}^{i-1}$ for $k \\in [n_{i-1}]$. Formally, the abstract element $a^i \\in \\mathcal{A}$ for each neuron $x_j^s$ ($s \\in \\{1,2\\}$) is a tuple $(\\underline{a}_j^{i,s}, \\overline{a}_j^{i,s}, l_j^{i,s}, u_j^{i,s})$, where $\\underline{a}_j^{i,s}$ (resp. $\\overline{a}_j^{i,s}$) is a symbolic lower (resp. upper) bound in the form of a linear combination of variables which appear before it and $l_j^{i,s} u_j^{i,s} \\in \\mathbb{R}$. For an affine function $x_{j,1}^i = W_j^ix^{i-1} + b^i$, the abstract transformer sets $\\underline{a}_{j,1}^{i} = W_{j,:}^i\\underline{x}^{i-1}+ b^i$. To compute the concrete lower (resp. upper) bound $l_{j,1}^i$ (resp. $u_{j,1}^i$), we first repeatedly substitute the variables in $\\underline{a}_{j,1}^{i}$ (resp. $\\overline{a}_{j,1}^{i}$) with their symbolic bounds according to the coefficient until no further substitution is possible. Then, we can obtain a sound lower (resp. upper) bound in the form of the linear combination of input variables, and $l_{j,1}^i$ (resp. $u_{j,1}^i$) can be computed immediately from the input domain. For an activation function $x_{j,2}^i = ReLU(x_{j,1}^i)$, the abstract transformers set the abstract element $a_{j,2}^i = (\\underline{a}_{j,2}^{i}, \\overline{a}_{j,2}^{i}, l_{j,2}^{i}, u_{j,2}^{i})$ as follows:\n*   If $l_{j,1}^i \\geq 0$: $\\underline{a}_{j,2}^{i} = \\underline{a}_{j,1}^{i}$, $\\overline{a}_{j,2}^{i} = \\overline{a}_{j,1}^{i}$, $l_{j,2}^{i} = l_{j,1}^{i}$, and $u_{j,2}^{i} = u_{j,1}^{i}$;\n*   If $u_{j,1}^i \\leq 0$: $\\underline{a}_{j,2}^{i} = \\overline{a}_{j,2}^{i} = l_{j,2}^{i} = u_{j,2}^{i} = 0$;\n*   If $l_{j,1}^i < 0 < u_{j,1}^i$: $\\underline{a}_{j,2}^{i} = \\lambda \\frac{u_{j,1}^{i} (\\underline{x}_{j,1}^{i} - l_{j,1}^{i})}{u_{j,1}^{i} - l_{j,1}^{i}}$, $\\overline{a}_{j,2}^{i} = \\lambda \\overline{x}_{j,1}^{i}$, where $\\lambda \\in \\{0, 1\\}$ such that the area of resulting shape by $\\underline{a}_{j,2}^{i}$ and $\\overline{a}_{j,2}^{i}$ is minimal, $l_{j,2}^{i} = \\lambda l_{j,1}^{i}$ and $u_{j,2}^{i} = \\lambda u_{j,1}^{i}$.\n\nA naive method. Given the problem of verifying whether $N\\models_{m,n} \\langle \\phi, \\psi \\rangle$ holds, a naive solution is to iteratively create an attacked network $N^{\\rho}$ for each possible $(m, n)$-attack vector $\\rho$ and check the vanilla robustness verification problem $N^{\\rho} \\models \\langle \\phi, \\psi \\rangle$ by DeepPoly, which conducts a reachability analysis and returns a sound and incomplete verification result. Following this method, the number of possible attack vectors increases quickly with $m, n$, and the number of parameters in $N$, causing the infamous combinatorial explosion problem. For instance, suppose the number of parameters of a QNN is K and the quantization bit-width is Q, the number of possible attack vectors (or the number of attacked networks $N^{\\rho}$) is ${K \\choose m} \\times {Q \\choose n}^m$."}, {"title": "4 Methodology of BFAVerifier", "content": "In this work, we operate under the assumption that the adversary is limited to attacking a small number of parameters in a QNN, specifically targeting only one parameter by default ($m = 1$). Note that even if the adversary is limited to flipping only one parameter, the number of possible (1, n)-attack vectors is still $K \\cdot \\Sigma_{i=1}^{n} {Q \\choose i}$. Consider a QNN N which is quantized by Q and comprises K parameters. The naive method introduced in Section 3.1 can only verify each (1, n)-attack vector"}, {"title": "4.1 Overview of BFAVerifier", "content": "The overall verification procedure is given in Algorithm 1. Given a QNN N, an input region I, a target class g, and the maximum number of bits to flip n, we firstly traverse each parameter w, performing a reachability analysis via function BFA_RA(\u00b7) independently (lines 3-4) to compute a sound output range for N considering all potential $2^{\\Sigma_{i=1}^{n} {Q \\choose i}}$ attack vectors with respect to parameter w, and subsequently identify all parameters potentially susceptible to bit-flip attacks (line 5). If the set $\\xi$ is empty, we return True which means all parameters are safe to BFA and the network N is BFA-tolerant with respect to the region I and class g. Otherwise, it implies the existence of at least one parameter for which the reachability analysis fails to confirm safety against such attacks. In this case, we reformulate the verification problem into an equivalent MILP problem based on the intermediate results (i.e., all susceptible parameters $\\xi$) derived before, which can then be solved using off-the-shelf solvers. Therefore, the whole verification process BFAVerifier is sound, complete yet reasonably efficient. We remark that the MILP-based verification method is often more time-consuming and thus the first step allows us to quickly verify many tasks first or identify all vulnerable parameters soundly and formally.\nBelow, we present the details of functions BFA_RA and BFA_MILP. We first introduce an abstract domain designed for networks with symbolic parameters, which will be utilized throughout our reachability analysis procedure."}, {"title": "4.2 SymPoly: An Abstract Domain for Networks with Symbolic Parameters", "content": "In this section, we introduce a new abstract domain SymPoly designed for networks with symbolic parameters, equipped with abstract transformers tailored to our bit-flip attack setting to conduct a sound reachability analysis.\nLet us consider the (i + 1)-th layer with neuron function $x_{j,1}^{i+1} = ReLU(W_{j,:}^{i+1}x^i + b^{i+1})$ in a QNN N such that $W_{j,k}^{i+1}$ (for some $k \\in [n_i]$) or/and $b_j^{i+1}$ may be replaced by symbolic parameters. Following DeepPoly, we first split each neuron (e.g., $x_j^{i+1}$) into two nodes (e.g., $x_{j,1}^{i+1}$ and $x_{j,2}^{i+1}$) and reformulate the neuron function as follows:\n$x_{j,1}^{i+1} = \\sum_{t \\in [n_i]} W_{j,t}^{i+1}x_t^i + b_j^{i+1}$, $x_{j,2}^{i+1} = ReLU(x_{j,1}^{i+1})$\n4.2.1 Abstract domain. We inherit the abstract domain $\\mathcal{A}$ introduced in DeepPoly which consists of a set of polyhedral constraints, each relating one variable to a linear combination of the variables"}, {"title": "4.2.2 Affine abstract transformer for symbolic weights", "content": "Without loss of generality, we consider the transformer for the case where there is only one concrete parameter is replaced by a symbolic one, e.g., $W_{j,k}^{i+1}$ for some $k \\in [n_i]$. For all nodes other than $x_{j,1}^{i+1}$, we directly inherit the abstract transformers from DeepPoly.\nIn this work, we need to abstract affine functions with symbolic parameters and the ReLU function, both of which contribute to precision loss. To improve accuracy, we abstract them jointly as a symbolic weighted ReLU function with ReLU applied internally, as shown in Figure 3b. For the very first affine layer, we abstract the affine function solely, since there is no preceding ReLU, as given later at the end of this section. We remark that our abstract transformations can be compositionally applied to settings involving multiple symbolic parameters.\nSymbolic weights on hidden neurons. Consider a symbolic weight parameter $W_{j,k}^{i+1}$ constrained by an interval range $[w_l, w_u]$. Then, the updated neuron function for $x_{j,1}^{i+1}$ is as follows:\n$x_{j,1}^{i+1} = \\sum_{t \\in [n_i]\\backslash k} W_{j,t}^{i+1}x_t^i + W_{j,k}^{i+1}x_k^i + b_j^{i+1}$\nTo perform abstract transformations on $W_{j,k}^{i+1}x_k^i$, an intuitive idea is to directly make an affine transformation with respect to symbolic parameter $W_{j,k}^{i+1}$ on the abstract element of $\\overline{x}_{k,2}^i$. However, it will lead to an over-approximate result compared to abstracting the symbolic-weighted ReLU function. To illustrate it, let us consider the setting where $(l_{k,1}^i < 0 < u_{k,2}^i) \\wedge (\\underline{x}_{j,1}^2 + \\overline{x}_{j,2}^2 > 0)$ and $w_l \\geq 0$. As shown in Figure 3(a), the areas within the yellow boundaries and the green boundaries are captured by the weighted abstract elements $w_u \\cdot a_{\\overline{x}_{k,2}}^i$ and $w_l \\cdot a_{\\overline{x}_{k,2}}^i$, respectively, with $\\gamma(w_u \\cdot a_{\\overline{x}_{k,2}}^i) = \\{w_u \\cdot x \\in \\mathbb{R} \\mid a_{\\underline{x}_{k,2}}^i \\leq x \\leq a_{\\overline{x}_{k,2}}^i\\}$ and $\\gamma(w_l \\cdot a_{\\overline{x}_{k,2}}^i) = \\{w_l \\cdot x \\in \\mathbb{R} \\mid a_{\\underline{x}_{k,2}}^i \\leq x \\leq a_{\\overline{x}_{k,2}}^i\\}$. It is obvious that the area captured by the dotted polyhedra in Figure 3(a) is larger than that in Figure 3(b), whose area is captured by directly abstracting the weighted ReLU function $W_{j,k}^{i+1}ReLU(x_{k,1}^i)$. Therefore, our idea is to abstract the symbolic-weighted ReLU function directly. To achieve it, we initially introduce an additional node $\\widehat{x}_{k,2}^i$ for the symbolic parameter $W_{j,k}^{i+1}$. With such that $x_{j,1}^{i+1}- ReLU(x_{k,1}^i) = W_{j,k}^{i+1}ReLU(x_{k,1}^i)$. After that, we set the weight as 1 between $\\widehat{x}_{k,2}^i$ and $x_{j,1}^{i+1}$, and set the weight between $\\widehat{x}_{k,2}^i$ and $x_{j,1}^{i+1}$ as 0. An illustration of the construction can be found in Figure 4.\nThen, given the abstract element of $\\widehat{x}_{k,2}^i$ as $a_{\\widehat{x}_{k,2}}^i = (a_{\\underline{x}_{k,2}}^i, a_{\\overline{x}_{k,2}}^i, l_{\\widehat{x}_{k,2}}^i, u_{\\widehat{x}_{k,2}}^i)$ of neuron $x_{j,1}^{i+1}$, we define the abstract element $a_{x_k,2}^i$ as follows:\n*   If $w_l \\geq 0$: $a_{\\underline{x}_k,2}^i = w_l \\cdot a_{\\underline{x}_{k,2}}^i$, $a_{\\overline{x}_k,2}^i = w_u \\cdot a_{\\overline{x}_{k,2}}^i$, $l_{\\widehat{x}_{k,2}}^i = w_l l_{\\widehat{x}_{k,2}}^i$, and $u_{\\widehat{x}_{k,2}}^i = w_u u_{\\widehat{x}_{k,2}}^i$;\n*   If $w_u \\leq 0$: $a_{\\underline{x}_k,2}^i = w_u \\cdot a_{\\overline{x}_{k,2}}^i$, $a_{\\overline{x}_k,2}^i = w_l \\cdot a_{\\underline{x}_{k,2}}^i$, $l_{\\widehat{x}_{k,2}}^i = w_u l_{\\widehat{x}_{k,2}}^i$, and $u_{\\widehat{x}_{k,2}}^i = w_l u_{\\widehat{x}_{k,2}}^i$;\n*   If $w_l < 0 < w_u$: $a_{\\underline{x}_k,2}^i = w_l \\cdot a_{\\overline{x}_{k,2}}^i$, $a_{\\overline{x}_k,2}^i = w_u \\cdot a_{\\overline{x}_{k,2}}^i$, $l_{\\widehat{x}_{k,2}}^i = w_l u_{\\widehat{x}_{k,2}}^i$, and $u_{\\widehat{x}_{k,2}}^i = w_u u_{\\widehat{x}_{k,2}}^i$.\nAn illustration of the above abstract transformer for the weighted-ReLU function can be found in Figure 5."}, {"title": "4.2.3 Affine abstract transformer for symbolic biases", "content": "Similar to the affine transformer for symbolic weights, for all nodes other than $x_{j,1}^{i+1}$, we adopt the abstract transformers from DeepPoly. Our abstract transformations can be compositionally applied to settings involving multiple symbolic parameters.\nConsider a symbolic bias parameter $b_j^{i+1}$ constrained by an interval range $[w_l, w_u]$. Then, the updated neuron function is $x_{j,1}^{i+1} \\sum_{t \\in [n_i]} W_{j,t}^{i+1}x_t^i +  W_{j,k}^{i+1}x_k^i + b_j^{i+1}$. Then, we define the abstract element $a_{j,1}^{i+1} = (\\underline{a}_{j,1}^{i+1}, \\overline{a}_{j,1}^{i+1}, l_{j,1}^{i+1}, u_{j,1}^{i+1})$ of neuron $x_{j,1}^{i+1}$ as follows:\n$\\underline{a}_{j,1}^{i+1} = \\sum_{t \\in [n_i]} W_{j,t}^{i+1}x_t^i + w_l$, $\\overline{a}_{j,1}^{i+1} = \\sum_{t \\in [n_i]} W_{j,t}^{i+1}x_t^i + w_u$\nwhere $l_{j,1}^{i+1}$ and $u_{j,1}^{i+1}$ can be determined with corresponding lower/upper bounds computation methods (cf. Section 3.2).\nTHEOREM 4.3. The affine abstract transformer for symbolic biases preserves both soundness and the invariant.\nOther abstract transformers. In this work, for other network functions, such as the ReLU function and the maxpool operator, we directly adopt the corresponding abstract transformers from DeepPoly. Hence, SymPoly is sound."}, {"title": "4.5 Extension to Other Networks", "content": "This work primarily focuses on feedforward neural networks with ReLU activations. In this section, we demonstrate the extensibility of our framework to other networks, including those with sigmoid or tanh activations and architectures incorporating convolutional layers.\n4.5.1 Other activation functions. Following the idea of symbolic weights on hidden neurons in Section 4.2.2 and the abstract transformers proposed in DeepPoly for sigmoid and tanh, for an activation function $g(x)$ that is continuous and twice-differentiable such that the first derivative $g'(x) > 0$ and the second derivative $g'' \\geq 0 \\Leftrightarrow x \\leq 0$, we also construct an additional node $\\widehat{x}_{k,2}^i$ (the same as in Figure 4) and study its abstract domain according to $\\widehat{x}_{k,2}^i =  W_{j,k}^{i+1}g(x_k^i )$. The corresponding abstract transformers for Sigmoid and Tanh considering the node $\\widehat{x}_{k,2}^i$ are given in Table 1. For the other network functions with constant parameters, we can reuse the corresponding abstract transformers from DeepPoly directly.\nTHEOREM 4.5. Both the weighted Sigmoid and the weighted Tanh abstract transformers are sound and preserve the invariant $\\gamma(a_{\\widehat{x}_{k,2}}^i) \\subseteq \\gamma(\\widehat{x}_{k,2}^i)$.\nFor the MILP encoding of other activation functions, the piecewise linear approximation can be employed to encode the sigmoid and tanh functions using linear constraints. We argue that such an approximation-based MILP encoding approach is sound, however, not incomplete, Therefore, for"}, {"title": "4.5.2 Other network architectures", "content": "This work focuses on feed-forward network architectures, however, our approach can be generalized to shared-parameter architectures\u2014such as convolutional networks-without additional technical challenges. Figure 6 illustrates how a convolutional layer subjected to bit-flip attacks on the parameter w can be transformed into an equivalent affine layer, to which BFAVerifier can be directly applied. Note that, although multiple copies are under bit-flip attack, they share the same parameter w in the original convolutional layer, and consequently, the attack effect is identical. Therefore, no additional combinatorial explosion occurs and the computational complexity remains equivalent to the case when m = 1.\nAlthough no additional technical challenges occurs, BFAVerifier may suffer from significant abstraction precision loss on CNNs, compared to DNNs, due to multiple abstractions in weighted activation function and input neurons even when m = 1 (in contrast to only single abstraction in feedforward networks), both contributing to higher loss than in cases without symbolic weighting."}, {"title": "4.5.3 Other quantization schemes and network precisions", "content": "BFAVerifier can be adapted to support other quantization schemes. For instance, when addressing a mixed-precision quantization scheme, only the weight interval associated with each symbolic parameter under bit-flip attacks needs to be adjusted for the BFA_RA procedure, while no modifications are required for BFA_MILP.\nFor floating-point neural networks (FPNNs), parameters are typically stored as IEEE 754 32-bit single-precision floating-point numbers, where flipping the exponent bit can cause drastic value changes (e.g., altering 0.078125 to 1.25 \u00d7 2124). BFAVerifier can be adapted to FPNNs by adjusting the parameter interval derived from bit-flipping, but the performance remains uncertain and is left for"}, {"title": "5 Implementation and Evaluation", "content": "To validate the effectiveness of our method", "questions": "nRQ1. How effective and efficient is BFA_RA for providing the sound verification result on potential attack vectors, compared with the naive baseline method (cf. Section 3.2)?\nRQ2. Can the absence of BFAs be verified with a conclusive result for a specific network using BFAVerifier, and how effective is the MILP-based method for providing a sound and complete verification result, as a complementary approach to BFA_RA?\nRQ3. How efficient and effective is BFAVerifier for verifying the absence of BFAs on larger networks with various activation functions?\nImplementation. We implemented our verification method as an end-to-end tool BFAVerifier with Gurobi [26", "64": "an open-source GPU implementation [52", "1": "floating-point number format for arithmetic operation. The floating-point number soundness flag in the implementation [52"}]}