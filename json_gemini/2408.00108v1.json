{"title": "Preference-Based Abstract Argumentation for Case-Based Reasoning (with-Appendix)", "authors": ["Adam Gould", "Guilherme Paulino-Passos", "Seema Dadhania", "Matthew Williams", "Francesca Toni"], "abstract": "In the pursuit of enhancing the efficacy and flexibility of interpretable, data-driven classification models, this work introduces a novel incorporation of user-defined preferences with Abstract Argumentation and Case-Based Reasoning (CBR). Specifically, we introduce Preference-Based Abstract Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users to define multiple approaches to compare cases with an ordering that specifies their preference over these comparison approaches. We prove that the model inherently follows these preferences when making predictions and show that previous abstract argumentation for case-based reasoning approaches are insufficient at expressing preferences over constituents of an argument. We then demonstrate how this can be applied to a real-world medical dataset sourced from a clinical trial evaluating differing assessment methods of patients with a primary brain tumour. We show empirically that our approach outperforms other interpretable machine learning models on this dataset.", "sections": [{"title": "1 Introduction", "content": "Abstract argumentation is a formalism for representing arguments and relationships between them, and for computing which arguments to accept (Dung 1995). It has been shown to be effective for recommendation systems (Rago et al. 2020), decision-making tasks (Amgoud and Prade 2009), reasoning with incomplete knowledge (Briguez et al. 2014) and approaches to explainable artificial intelligence (\u010cyras et al. 2021b).\nCase-based reasoning (CBR) is a problem-solving methodology where new problems are solved by retrieving and adapting solutions from similar past cases. Approaches to combine CBR with abstract argumentation are successful for explaining the output of machine learning (Prakken and Ratsma 2022) or for making predictions (Cocarascu et al. 2020). Abstract Argumentation for Case-Based Reasoning (AA-CBR) (\u010cyras, Satoh, and Toni 2016) is a data-driven interpretable classification and explanation model which has been shown to have utility in many tasks, for example, as an interpretable binary classifier (Cocarascu, \u010cyras, and Toni 2018; Cocarascu et al. 2020; Paulino-Passos and Toni 2023), for cautiously monotonic reasoning (Paulino-Passos and Toni 2021a) or for explaining known legislative outcomes (\u010cyras et al. 2019).\nAs a result, AA-CBR represents a novel paradigm as an intrinsically explainable classification model. The need for such models in high-stakes decision-making is becoming increasingly apparent. In medical domains, for instance, decision-support tools need to be understood by a clinician for trust to be established and disagreements to be resolved (Amann et al. 2020). Moreover, legal requirements, such as those established by GDPR (Goodman and Flaxman 2017), require explainable AI to varying extents.\nHowever, previous approaches to AA-CBR are missing the ability to compare cases by user-defined preferences. Preferences allow stakeholders to influence a decision-making tool and inject domain-specific knowledge, resulting in more desirable reasoning systems or better-performing models. Preferences have been integrated with argumentation systems through a variety of approaches, for example, preferences defined over abstract arguments in preference-based argumentation frameworks (Amgoud and Cayrol 1998); preferences defined over structured arguments in ASPIC+ (Modgil and Prakken 2013); preferences defined over values assigned to arguments as in value-based argumentation frameworks (Bench-Capon 2003); preferences defined by defeats of attack relations as with extended argumentation frameworks (Modgil 2009); preferences defined over constituents of an argument such as with Assumption-Based Argumentation with Preferences (ABA+) (Cyras and Toni 2016); and preferences over constituents of cases in which arguments are derived such as with case models\u00b9 (Zheng, Grossi, and Verheij 2020).\nWithin healthcare, preferences allow for specialist expertise and patient goals to affect the decision-making process, leading to more agreeable courses of action (Politi et al. 2013). Moreover, preferences with argumentation have many applications within the medical domain (\u010cyras et al. 2021a; Kakas, Moraitis, and Spanoudakis 2018; Hunter and Williams 2012; Williams et al. 2015).\nDespite this, there is yet to be an AA-CBR-based approach that can integrate preferences over the constituents of arguments. Considering the benefits of AA-CBR as an interpretable classification model, adding preferences will"}, {"title": "2 Preliminaries", "content": "2.1 Abstract Argumentation\nAn abstract argumentation framework (AF) (Dung 1995) is a pair (Args,\u2192) where Args is a set of arguments and \u2192 \u2286 Args \u00d7 Args is a binary relation between arguments. For arguments, \u03b1, \u03b2 \u2208 Args, a attacks \u1e9e if a \u2194 \u03b2. An AF can be represented as a directed graph where nodes are arguments and edges represent attacks. A set of arguments E \u2286 Args defends an argument \u1e9e \u2208 Args if for all a \u2194 \u03b2 there exists \u03b3\u2208 E such that \u03b3 \u2194 \u03b1. For determining which arguments to accept, we focus on the grounded extension (Dung 1995), which can be iteratively computed as G = Ui\u22650 Gi, where Go is the set of unattacked arguments and Vi \u2265 0, Gi+1 is the set of all arguments that Gi defends.\n2.2 Abstract Argumentation for Case-Based Reasoning (AA-CBR)\nAA-CBR is a binary classification model utilising argumentation as the reasoner. It operates on a casebase D comprised of labelled examples of a generic characterisation. Given D and a new unlabelled example, N, AA-CBR assigns a label to the new case. Formally:\nDefinition 1 (Adapted from (Paulino-Passos and Toni 2021a; Cocarascu et al. 2020)). Let D \u2286 X \u00d7 Y be a finite casebase of labelled examples where X is a set of characterisations and Y = {\u03b4, \u03b4} is the set of possible outcomes. Each example is of the form (x, y). Let (x\u03b4, d) be the default argument with d the default outcome. Let N be an unlabelled example of the form (xN, Y?) with y? an unknown outcome. The function AA-CBR(D,xn) assigns the new case an outcome as follows:\nAA-CBR(D, XN) = {\u03b4 if (xs, \u03b4) \u2208 G, otherwise.}\nwhere G is the grounded extension of the argumentation framework derived from D and xn, known as AF(D,XN).\nAF(D,XN) is constructed with cases of differing outcomes modelled as arguments. It is assumed that characterisations of the data points are equipped with a partial order, which determines the direction of attacks within the casebase and is used to ensure attacks occur between cases with minimal difference. The new case (XN,Yy?) is added to the AF by attacking cases considered irrelevant to it, as defined by a provided irrelevance relation x.\nDefinition 2 (Adapted from (Paulino-Passos and Toni 2021a; Cocarascu et al. 2020)). Let \u2265 and be a partial order and binary relation defined over X, respectively. The argumentation framework AF(D,xn) mined from D and XN is (Args, \u2194) in which:\n\u2022 Args = DU {(xs, \u03b4)} \u222a {N}\n\u2022 for (xa, Ya), (x\u03b2,y\u03b2) \u2208 DU {(xs,d)}, it holds that (xa, Ya) \u2192 (X\u03b2, Y\u00df) iff\n1. Ya \u2260 y\u00df, and\n2. either \u03a7\u03b1 \u2013 \u03c7\u03b2 and A(xy,Ya) \u2208 DU {(xs, \u03b4)} with Xa X X\u03b2\n3. or xa = \u03a7\u03b2;\n\u2022 for (xa, ya) \u2208 DU {(xs, d)}, it holds that N \u2192 (xa, Ya) iff Nx (xa, Ya).\nA casebase D is coherent iff there are no two cases (\u03a7\u03b1,\u03c8\u03b1), (\u03a7\u03b2, \u03c8\u03b2) \u2208 D such that xa x\u03b2 and ya \u2260 \u0423\u0432, and it is incoherent otherwise.\nThe second bullet of Definition 2 defines attacks between the cases in the casebase. Condition 2 ensures that attacks occur from greater cases to smaller ones according to the provided partial order. When multiple possible attacks occur, we enforce that attacks originate from the case with minimal difference compared to the attacked case. We refer to this as the most concise possible attack. Condition 3 defines symmetric attacks for an incoherent casebase.\n2.3 AA-CBR with Stages\nAn extension to AA-CBR (\u010cyras et al. 2019) employs stages in the characterisations to represent dynamic features. Stages represent the time at which a case was recorded. If two cases have the same set of features, then the time measure is used to distinguish the cases. If the only difference between two cases is the time measure and the outcome, then it is possible that the change in outcome by the latter case is a result of features that have not been recorded. This approach recognises that not all data may be available and so uses a time measure as a proxy to reason about unknown data. This version of AA-CBR is not defined generally for any characterisation but instead only for a set of features and stages."}, {"title": "3 Motivations", "content": "The partial order used to define attacks in the casebase is a key choice affecting the performance and explanations generated by an AA-CBR model. Selecting a different partial order at model construction may result in varying model performance even when using the same dataset. Additionally, different partial orders have different semantic meanings, so the explanations will differ when describing how an"}, {"title": "4 Preference-Based Abstract Argumentation for Case-Based Reasoning", "content": "We introduce AA-CBR-P and its regular variant AA-CBR-P\u27e8\u27e9, where a user can employ various preorders\u2074 defined over constituent parts of an argument. The preorders are sorted by preferences and applied using a lexicographic strategy. We begin by defining the collection of preorders.\nDefinition 4 (Preference Ordering). Let P = (\u22651,\u2026\u2026\u2026, n) be a sequence of preorders, each defined over X. Each preorder, i, is a reflexive and transitive relation, with a corresponding strict preorder, i (which is irreflexive and transitive), and an equivalence relation, =\u00bf (which is reflexive, symmetric, and transitive). For cases (xa, Ya), (x\u03b2,y\u03b2) \u2208 DU {(xs, d)}, we define:\n\u2022 xa i x\u00df iff xa di x\u00df and x\u00df \u0395\u03af \u03a7\u03b1\n\u2022 xa =i x\u00df iff xa di x\u00df and x\u00df \u03c4\u03af \u03a7\u03b1\nIn simple terms, the ordering of P determines the preferences of the preorders. If two cases are equivalent by the first preorder, then a comparison under the second order can be used. If they are also equivalent by the second order, the third can be used. This process continues, using subsequent preorders when equivalence occurs. By incorporating multiple methods for comparing cases, we afford flexibility to select the approach that optimises performance and injects domain relevance. Consequently, we can create a new AA-CBR-based model that utilises P. To do so, we make use of the following shorthand:\nNotation 1. We use xa[j:k] X\u00df, where j \u2264 k, to mean Xa is equivalent or larger than xe on all preorders between orders \u2265j and \u2265k (inclusive). Formally:\nXa[j:k] X\u1e9e iff Vi \u2208 [j, k], xa di X\u03b2.\nShorthands for =[j:k] and [j:k] are defined analogously.\nWith this, we can create a definition similar to Definition 2 that enforces attacks in the direction defined by the sequence of partial orders and that attacks only originate from the most concise case possible, thus representing minimal change between cases. With the addition of multiple preorders, the concision condition must now consider the lexicographic application of the orders. We first define a notion of potential attacks for a particular order i, which describes attacks that would transpire if we do not consider concision.\nPrevious incarnations of AA-CBR use a partial order; as we use multiple orders to compare cases, each can be a preorder. For example, we have ({c,d}, {a}) \u2265\u043d ({c,d}, {b}) and ({c,d}, {b}) 2H ({c,d}, {a}) but these two characterisations are not equivalent.\nDefinition 5 (Potential Attacks). Let a = (xa, Ya) and \u03b2 = (\u03c7\u03b2, \u03c8\u03b2). For \u03b1,\u03b2\u03b5 DU {(xs,d)}, we define a potential attack on order vi as:\ni ya \u2260 y\u00df, and\nii xai x\u00df, and\niii Xa =[1:i-1] \u03a7\u03b2.\nIntuitively, a potentially attacks \u1e9e on order \u2265 when the outcomes of the cases are different (i), xa is strictly greater than x by order >\u00bf (ii) and they are equivalent on all orders before i (iii). Conditions (ii) and (iii) apply P lexicographically. We can subsequently restrict attacks to the most concise attacks.\nDefinition 6 (Casebase Attacks). Leta = (xa, Ya) and \u03b2 = (\u03c7\u03b2, y\u03b2). For \u03b1,\u03b2\u2208 DU {(xs, 8)}, we define an attack on order i: ai \u1e9e iff\ni ai \u1e9e and\nii #y = (xy, ya) \u2208 DU {(xs, d)} with xa [1:n] Xy and\n(a) either i\u03b2 and \u2203l > i, xa >1 Xy,\n(b) or yi \u03b2 and \u2203l > i, \u03b3 \u03b9 \u03b2.\nThis definition states that case a attacks case \u1e9e on order if two conditions are met. Firstly, a potentially attacks \u1e9e on order \u2265i (i), and secondly, a is the most concise case capable of such an attack (ii). We illustrate the two conditions of concision in Figure 3, utilising the same characterisation approach as Example 2 and letting P = (2H, 2L)."}, {"title": "5 Nearest and Preferred Cases", "content": "With a coherent casebase, D, and a regular AF, we can identify cases which, when in agreement on an outcome, precisely determine the outcome predicted by AA-CBR-P. In this section, we will present this formally5. Note that when D is coherent, the argumentation framework is guaranteed to be acyclic.\nProposition 1. The argumentation framework corresponding to AA-CBR-P\u27e8\u27e9 is guaranteed to be acyclic for a coherent D.\nPrevious approaches to AA-CBR have shown that for a coherent casebase if all cases that are nearest to the new case N have the same outcome, then that outcome"}, {"title": "6 Empirical Evaluation", "content": "In this section, we showcase how to utilise AA-CBR-P models in a medical classification task with preferences defined over features derived from varying data sources. BrainWear (Dadhania et al. 2021; Dadhania et al. 2023) is a study exploring the utility of physical activity (PA) data collected via wrist-worn accelerometers in patients with a primary brain tumour. PA data complements traditional questionnaires, that allow patients to report their health status, known as patient reported outcomes (PRO). We can predict disease progression in new patients using AA-CBR-P, with preferences defined over features derived from PA and PRO data7.\n6.1 Methodology\nEach completed questionnaire is matched with an 8-week average of PA data centred on the questionnaire date. The objective is to predict if the patient has progressive disease or not, as labelled by the outcome of the next MRI scan following the questionnaire or the patient's mortality status. Furthermore, we can incorporate the number of previous instances of progressive disease for each patient, serving as a proxy for cancer progression. We conduct two experiments to evaluate the models. The first experiment solely utilises PA and PRO data, while the second incorporates both PA and PRO data along with the proxy measurement as stages. Each experiment consists of multiple AA-CBR(-P) models compared against similarly interpretable baseline models: a decision tree and a K-Nearest Neighbor (kNN).\nIn the first experiment, we compare AA-CBR with the relation as defined in Example 1 (we denote this"}, {"title": "7 Related Work and Discussion", "content": "Preferences over arguments have been shown to resolve situations in which the direction of an attack is unclear.\nComplexity results can be found in Appendix C."}, {"title": "8 Conclusion", "content": "In this paper, we introduced AA-CBR-P as a novel method of including preferences with an AA-CBR-based approach. We have shown how preferences allow domain-specific knowledge or individual choices to guide the model and that existing approaches to AA-CBR cannot support this. Moreover, we prove that the desirable property of predictions abiding by the nearest cases, hold for AA-CBR-P\u27e8\u27e9 and present a stronger condition for preferred cases. Given this and that individual attacks always occur by the most preferred order, we conclude that the model inherently abides by the preferences by construction. We then show that the addition of preferences and the enforcement of the nearest and preferred cases conditions can empirically lead to increased performance in a medical classification task, outperforming that of other interpretable baseline models.\nWe have not explored methods of automatically deriving a preference ordering that directly optimises the model's performance. Methods such as the DEAr Methodology (Cocarascu et al. 2020) could be applied to utilise AA-CBR-P to find characterisations and preference orderings that lead to the most optimal performance possible whilst still allowing for flexibility in user-defined preferences. Furthermore, we leave for future work the exploration of AA-CBR-P\u27e8\u27e9 variants, such as a cumulative model akin to cAA-CBR of (Paulino-Passos and Toni 2021a)."}, {"title": "A Theorem Proofs", "content": "A.1 Proof of Theorem 3\nThis proof generalises that of (Paulino-Passos and Toni 2021b).\nProof. We begin by establishing that for a coherent D, and when every preferred case to N is in the form of (xa, y), each argument in G\u2081 is either labelled as N or corresponds to a case (x,y), where G is the union of all Gi sets. In simpler terms, every case within the subsets of the grounded set is either labelled as N or shares the same outcome as the preferred cases. We prove this by induction on i:\n1. For the base case, we must show this property holds for Go which contains only unattacked arguments. N is always unattacked and so is an element of Go. Other unattacked cases may also be in Go so we let \u03b2 =(\u03c7\u03b2, y\u03b2) \u2208 Go be such a case. We must show that y\u00df = y. If \u03b2 is preferred for N then y\u00df = y as required. We now consider if \u03b2 is not preferred for N. If \u2203i, xn \u2260i x\u00df, then, as we are dealing with regular AA-CBR-P, N \u03c4\u03b2,\nleading to NB which cannot be as \u03b2 is unattacked. So we must have have that XN [1:n] X\u03b2. Assume towards contradiction that y\u00df \u2260 0. \u00c1s \u03b2 is not a preferred case, there must exist a preferred case a = (xa, y) such that xai xp for some i. We know a must exist by definition of preferred cases and because D is finite. By Definition 6, either ai \u03b2 or there exists a case \u03b3 = (x, y) that is a more concise attacker of \u1e9e and we have l\u2265 i, y \u03b9 \u03b2. In either circumstance, this cannot be as \u1e9e must be unattacked. Thus, we have a contradiction, so our previous assumption, that y\u00df \u2260 0, does not hold and we have y\u00df = y as required.\n2. In the inductive step, we assume the property holds for Gi and show it holds for Gi+1. Let \u03b2 =(x\u03b2, \u03c8\u03b2) \u2208 Gi+1\\Gk (if \u03b2\u2208 Gi, the property holds by the induction hypothesis). So, by definition of the grounded extension, \u1e9e is defended by Gi, which is conflict-free so N cannot attack B, thus we have XN [1:n] X\u03b2. Again, if \u1e9eisa preferred case to N, then y\u1e9e = y as required. We now consider when \u1e9e is not a preferred case. Assume towards contradiction that y\u00df \u2260 0. As \u1e9e is not a preferred case, there must exist a preferred case a = (x,y) such that xai xp for some i. As before, either a \u2194i \u03b2 or there exists a case y = (x, y) that is a more concise attacker of \u1e9e, and we have \u2203l \u2265 i, \u03b3 \u03b9 \u03b2. Let \u03b7 be the attacker of \u00df. As Gi defends \u1e9e, there must exist a\u03b8\u2208 Gi such that \u03b8 \u03b7. By the inductive hypothesis, @ is either N or 0 = (\u0445\u04e9, \u0443). \u04e8 cannot be N as for \u03b7 to be equal to a or a more concise case than a, we must have Xa\u2265[1:n] \u03a7\u03b7 and as a is a preferred case to N, we have XN [1:n] \u03a7\u03b1\u00b7 So XN [1:n] X\u03b7, which means \u03b7 is not irrelevant to N and, thus, cannot be attacked by N. So we have instead 0 = (x, y). But in this case, 0 cannot possibly attack \u03b7 in defence of \u1e9e because yo = Yn = y. We, therefore, have a contradiction, so y\u00df = y as required.\nWe can thus conclude that every argument in the grounded set, G, is either N or of the form (x,y).\nAs a consequence, if y = \u03b4, (that is all preferred cases agree on the non-default outcome), then (28,8) & G because as we have just shown, all arguments in G excluding N must have the outcome o. As a result, the predicted outcome for N must be o as required by the theorem.\nIf y = d, then we must show that (x8, \u03b4) \u2208 G. If (x8, \u03b4) is unattacked, the default case is in the grounded extension as required. Consider instead if (x8, 8) is attacked by a case \u03b2. As we are dealing with regular AA-CBR-P\u27e8\u27e9, (x8, 8) can never be irrelevant to N and so \u03b2 cannot be N. Thus, \u1e9e is of the form (\u03b1\u03b2, \u03b4) and is therefore not in G because, as have shown, all arguments in G must have outcome o. We know that D is coherent, so the AF is acyclic by Proposition 1 and G is a stable extension, meaning every argument not in G is attacked by an argument in it. So there exists some argument in G that attacks \u1e9e and defends the default argument. By definition, G contains every argument it defends, so the default argument is also in G. Therefore, the outcome predicted for N will be o as required by the theorem."}, {"title": "A.2 Proof of Proposition 1", "content": "Proof. First, as D is coherent, the set of incoherent attacks will be empty, so there will not be any symmetric attacks. Secondly, as N cannot be attacked, it cannot be part of cycles in the graph. As \u2248 only originates from N, we do not need to consider these.\nWe now consider only = (U=1\u2194i), where n corresponds to the size of P. For any attack (xa, Ya) \u2192 (x,y\u03b2), we know that either (xa 1 x\u03b2) or (i > 1,\u03a7\u03b1 =1 x\u03b2 and xa \u27a2i x\u03b2). This means that across a path"}, {"title": "B Deriving Existing Formulations from AA-CBR-P", "content": "B.1 Deriving AA-CBR from AA-CBR-P\nTo capture Definition 2 in AA-CBR-P, we must show that we can precisely derive Args and \u2192 when instantiating with P = <>) where \u2265 is an arbitrary partial order defined over the characterisations of the casebase. By Definition 10, we have:\n\u2022 Args = DU {(xs, \u03b4)} \u222a {N},\n\u2022\n=1UU.\nArgs is as required. We will now show that \u2192 corresponds to that of Definition 2. By Definition 6 we have \u03b11 \u03b2 iff\ni \u03b11 \u03b2 and\nii #y = (xy, Ya) \u2208 DU {(xs, d)} with xa \u22651 xy and\n(a) either 1 \u03b2 and \u2203l > 1, x\u03b1 >\u03b9 \u03a7\u03b3,\n(b) or \u03b3 \u00a31 \u03b2 and \u2203l > 1, \u03b3 \u03b9 \u03b2.\nWe know that condition ii (b) cannot hold as there is only one order. By this same reasoning, we also know that in condition ii (a), we can only let l = 1. Furthermore, by utilising Definition 5 we get a 1 \u1e9e iff\ni ya \u2260 y\u00df, and\nii xa 1 xp, and\niii #y = (xy,Ya) \u2208 DU {(xs, \u03b4)} and xy \u00d71 Xx\u00df and \u03a7\u03b1 1 \u03a7\u03b3,"}, {"title": "B.2 Deriving a variant of AA-CBR With Stages from AA-CBR-P\u27e8\u27e9", "content": "We aim to capture Definition 3 in AA-CBR-P but with condition 2. (b) i altered to FaFy FB and Sa Sy. Moreover, Definition 3 was defined only for a coherent case-base and does not include symmetric attacks, we will include these in our derivation. We will refer to this as capturing a 'variant of Definition3'. Note that we use a regular variant here because AA-CBR with Stages is defined utilising the default case containing the smallest elements by the and relations and is defined in terms of these orders akin to Definition 11.\nWe must show that we can derive Args and \u2192 from Definition 10. We let P = (2,\u2287), and x8 = (\u00d8, ()). By Definition 10, we have that Args = DU {(xs, d)} \u222a {N} as required.\nAgain by Definition 10, we have \u2194=1U 2U N U.\nBy Definition 6, we have a 1 \u03b2 iff\ni \u03b11 \u03b2 and\nii #y = (xy,Ya) \u2208 DU {(xs,d)} with xa \u22651 xy and Xa 2 xy and\n(a) either \u03b3 1 \u03b2 and \u2203l > 1, x\u03b1 >\u03b9 \u03a7\u03b3,\n(b) or \u03b3 \u00a31 \u03b2 and \u22031 > 2, \u03b3 \u03b9 \u03b2.\nAs there are two orders, we know that in ii (a), we can set l to either 1 or 2 and in ii (b) l can only be set to 2. Substituting this we get a 1 Biff\ni \u03b11\u03b2 and\n\u2171 \u2260y = (xy,Ya) \u2208 DU {(xs,d)} with xa \u22651 Xy and Xa 2 xy and"}, {"title": "C Complexity Results", "content": "The time complexity of AA-CBR-P can be divided into three main parts: AF construction with the casebase, identification of new case attacks, and computing the grounded extension. The construction of the AF using the casebase is a one-time cost that can be amortised over the number of times that a prediction is made for a new case. Assuming that each partial order takes O(1) to compute, the one-time cost of AF construction has a worst-case time complexity of O(n\u00b3m) where n is the size of the casebase, and m is the number of partial orders in P. This is compared to AA-CBR, which has a worst-case time complexity of O(n\u00b3). For regular AA-CBR-P\u27e8\u27e9, the time complexity of finding new case attacks is O(nm), compared to O(n) for AA-CBR. The computation of the grounded extension is the same for both AA-CBR and AA-CBR-P and is known to be in P (Dunne and Wooldridge 2009). The increase in time complexity when adding preferences to AA-CBR is marginal given that it is expected that m << n."}, {"title": "D Experiment Methodology", "content": "D.1 Data\nData from 78 patients was provided by the BrainWear study (Dadhania et al. 2023). All patient data was collected with informed, written consent. The original study was approved by the South West-Cornwall & Plymouth Research Ethics Committee (18/SW/0136). 17 Patients without a high-grade glioma (the disease of focus) were excluded, followed by 2 patients with insufficient Physical Activity data quality, 21 patients who did not complete at least two PRO questionnaires and 5 who lacked data from a least one scan. This left 31 eligible patients.\nWe extracted 110 data points from the 31 patients with applicable data. Each data point can be represented by a binary set of features extracted from a questionnaire and the surrounding physical activity data and labelled by the outcome of the MRI scan following the questionnaire or survival status at the end of the study. Additionally, each data point can be assigned a proxy time measure of the patient's cancer journey.\nPatient Reported Outcome (PRO) Questionnaires During the study, patients periodically completed questionnaires reporting their symptoms, outlooks, ability to function, and overall quality of life. We focus on the EORTC QLQ-C30 questionnaire and brain tumour-specific BN20 module (Aaronson et al. 1993). Each scale is scored from 1-100 (Fayers et al. 2001). We utilised the following five scales: fatigue (fa), global health QoL (ql), physical functioning (pf), future uncertainty (fu) and motor dysfunction (md) in accordance with (Dadhania et al. 2023). For each scale, a binary feature is extracted, denoting an observed change of at least 50% compared to a baseline questionnaire completed by each patient. We take an increase and a decrease of 50% as distinct features. We, therefore, have the following PRO features Fpro ={faI, faD,qlI,qlD,pfI,pfD, fuI, fuD,mdI,mdD} where the suffixes 'I' and 'D' represent an increase and decrease of the scale respectively."}, {"title": "D.2 Baseline Models", "content": "The decision tree (gini criteria) was selected due to providing tree-like explanations which can also be provided for AA-CBR (\u010cyras et al. 2019). The kNN (with k=3 and utilising hamming distance) was selected because this model also utilises case-based reasoning. For these baseline models, a binary feature vector is constructed, where for each value in Fpa UFpro, a 1 represents that the feature is present and a 0 otherwise. Stages were one-hot encoded and appended to the feature vector for experiments that utilised them."}]}