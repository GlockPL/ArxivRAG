{"title": "RE-tune: Incremental Fine Tuning\nof Biomedical Vision-Language Models\nfor Multi-label Chest X-ray Classification", "authors": ["Marco Mistretta", "Andrew D. Bagdanov"], "abstract": "In this paper we introduce RE-tune, a novel approach for fine-tuning pre-trained\nMultimodal Biomedical Vision-Language models (VLMs) in Incremental Learning\nscenarios for multi-label chest disease diagnosis. RE-tune freezes the backbones\nand only trains simple adaptors on top of the Image and Text encoders of the VLM.\nBy engineering positive and negative text prompts for diseases, we leverage the\nability of Large Language Models to steer the training trajectory. We evaluate\nRE-tune in three realistic incremental learning scenarios: class-incremental, label-\nincremental, and data-incremental. Our results demonstrate that Biomedical VLMs\nare natural continual learners and prevent catastrophic forgetting. RE-tune not\nonly achieves accurate multi-label classification results, but also prioritizes patient\nprivacy and it distinguishes itself through exceptional computational efficiency,\nrendering it highly suitable for broad adoption in real-world healthcare settings.", "sections": [{"title": "Introduction", "content": "Chest X-rays are a cornerstone of non-invasive disease diagnosis, but their interpretation poses\nunique challenges and relies on discernment of subtle gray-scale variations. Misinterpretation\ncan lead to delayed treatment or missed diagnoses, emphasizing the need for more efficient and\naccurate diagnostic methods. The advent of deep vision models has yielded remarkable advances\nin medical image analysis [5]. Simultaneously, transformer-based Large Language Models (LLMs)\nhave empowered AI systems to comprehend the complex language of radiology reports [3, 9].\nSynergy between vision and language has led to the emergence of Multimodal Biomedical Vision-\nLanguage models (VLMs) capable of interpreting both images and associated reports. Biomedical\nVLMs offer a more comprehensive analysis of patient condition [1, 4, 10]. Despite promising capa-\nbilities, significant challenges persist in the practical implementation of these technologies. When\nzero-shot performance is insufficient, VLMs require massive computational power and massive\ndatasets for fine-tuning, posing feasibility issues in resource-limited environments. Furthermore, med-\nical data are constantly generated in hospitals, and traditional models are susceptible to catastrophic\nforgetting, where the introduction of new data leads to the loss of previously learned information.\nTo overcome these challenges, incremental learning techniques have been developed [7], but many\nrely on storing of training data (exemplars), which raises important privacy and security concerns\nparticularly relevant in the context of healthcare. In this paper we propose RE-tune, a privacy-\npreserving, computationally efficient, and exemplar-free approach to incremental fine-tuning of\nBiomedical VLMs for multi-label chest disease classification."}, {"title": "Proposed Method", "content": "Our experiments focus on fine-tuning BioViL [1], a publicly available state-of-the-art Multimodal\nBiomedical model. BioViL's zero-shot performance and its specialized text modeling makes it\nthe ideal candidate to fine-tune. Importantly, BioViL has not been pre-trained on CheXpert [5], a\nwell-established and widely adopted dataset of multi-labelled chest X-rays, we use in our experiments.\nFreezing backbones and extending with adaptors. The initial phase involves the straightforward\nstep of freezing the backbones: the Image Encoder Eimg and the Text Encoder Etxt (Fig. 1a). This\nensures that the learned representations at their core remain intact during fine-tuning and reduces\ncomputational demands. Afterward we expand the pre-trained architecture by adding additional\ncomponents, that we call adaptors, on top of the Encoders (Fig. 1a). Simple adaptors such as Dense\nLayers or Multi Layers Perceptrons have been evaluated in all the combinations, including applied\nexclusively to the Image Encoder, exclusively to the Text Encoder, to both or shared between them.\nNote that the adaptors output size is equal to its input size, which is equal to the joint embedding size.\nRE-tune incrementally adapts the embedding space to REmember previously learned information.\nDefining the text prompts. Consider a batch B of N radiology images and corresponding labels,\nexpressed as B = (xi, Yi)=1. Here, xi represents the input image, and yi \u2208 {0, 1}C denotes the\nbinary labels associated with the image, indicating the absence (yi = 0) or presence (Yi = 1) of\nC evaluated different diseases (i.e. the five CheXpert competition tasks defined in [5]). For each\nevaluated disease, we construct a positive and a negative text prompt to signify the presence or\nabsence of the respective disease (Fig. 1b). We evaluated three types of prompts: Template Prompts,\nwhich represents the classic prompts used in zero-shot classification [1], Generative Prompts that\nwe obtain by summarizing labeled medical reports [6, 8] with a recent T5 model [2], and Random\nPrompts that are used in order to verify if text semantics matter during fine-tuning.\nFine-tuning. The Image Encoder Eimg extracts image embeddings \u0113img, and the Image Adaptor Aimg\nfurther projects these embeddings (eimg = Aimg(\u0113img)). The positive and negative text prompts are\ngiven to the Text Encoder, which extracts the positive \u0113t and the negative ext text embeddings. The\nText Adaptor Atxt further projects these embeddings, resulting in ext = Atxt(ext) and ext = Atxt(txt).\nThen, the positive cosine similarity S+, and the negative cosine similarity S\u00af, are calculated for each\nlabel j using the following formulations: $S^+_j = \\frac{e_{img}^{T}e_{txt}^+}{\\lVert e_{img}\\rVert \\lVert e_{txt}^+ \\rVert} , S^-_j = \\frac{e_{img}^{T}e_{txt}^-}{\\lVert e_{img}\\rVert \\lVert e_{txt}^- \\rVert}, \\forall j \\in [1,..., C]$.\nThe loss function employed is the Binary Cross Entropy where we propose to employ the difference\nbetween the positive and negative cosine similarities as logits:\n$L_{BCE} = \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{C} Y_{ij}log(\\sigma(S_{ij}^{+} - S_{ij}^{-})) + (1 - Y_{ij})log(1 - \\sigma(S_{ij}^{+} - S_{ij}^{-}))$.(1)"}, {"title": "Results and Discussion", "content": "RE-tune with Template Prompts demonstrates remarkable class-incremental learning capabilities\n(Fig. 2a): the use of semantically rich prompts as knowledge transmitters evidently prevents catas-\ntrophic forgetting between tasks even in such a complex setting. In the label- and data-incremental\nsettings, RE-tune reaches joint training performance even using Generative or Random Prompts\n(Figs. 2b and 2c). RE-tune in fact exploits the ability of the Image Encoder to differentiate between\nX-rays of diseased and non-diseased subjects based solely on visual features, and takes advantage of\ntext prompt to create separate attractors, demonstrating that Biomedical VLMs are natural continual\nlearners. Additionally, in the data-incremental scenario, RE-tune is data efficient, achieving upper\nbound performance using only 40% of the dataset (Fig. 2c). Ablations on prompts and architectures\nvalidate the aforementioned phenomena (Tab. 1). In Sec. 2 we proposed to extend the pre-trained\narchitecture with two adaptors, which is the most effective configuration. MLP on both Image and\nText Encoders with Template Prompts yields the best performance in all evaluated scenarios.\nDespite its robustness and efficiency, RE-tune is not without limitations. Our experiments show that\nthe quality of textual prompts plays a pivotal role in performance. We experimented with automated\nprompt generation, but found that the best-performing prompts are still manually engineered ones.\nAlso, while the model shows consistent performance across different adaptor variants, some scenarios\nexhibit a higher degree of noise (see Tab. 1), indicating opportunities to further improve generalization.\nThe use of text prompts as a knowledge transmission mechanism is an exciting direction for future\nresearch, with the potential to transform not just the medical imaging field but any domain where the\nability to learn continuously and adaptively in privacy-preserving ways is of paramount importance.\nWe believe this will help facilitate the adoption in real-world healthcare scenarios."}, {"title": "Potential Negative Societal Impacts", "content": "While incremental learning for chest X-ray diagnosis using\napproaches like RE-tune offers numerous benefits, it also raises certain potential problems and\nconcerns that need to be carefully addressed to ensure its responsible and ethical deployment in\nhealthcare settings:\n\u2022 Bias and Fairness: Incremental learning models are highly dependent on the data they\nare exposed to during training. If the initial dataset used for training is biased in terms of\ndemographics, disease prevalence, or image quality, the model may inherit and perpetuate\nthese biases. This could lead to disparities in diagnosis and treatment for different patient\npopulations, exacerbating existing healthcare inequalities.\n\u2022 Data Privacy: Privacy is a critical concern in healthcare, and incremental learning ap-\nproaches must be designed with strong data privacy safeguards. While RE-tune is exemplar-\nfree and privacy-preserving in terms of not storing patient-specific data, it still relies on\naccess pre-deidentified medical image and medical reports, which can still contain sensitive\npatient information. Ensuring the secure handling of such data and implementing robust\ndata anonymization techniques is essential to protect patient privacy.\n\u2022 Transparency and Explainability: Incremental learning models, particularly those based\non complex architectures like VLMs, can be difficult to interpret. Understanding how the\nmodel arrives at a particular diagnosis or decision is crucial for gaining the trust of healthcare\npractitioners and patients. Ensuring transparency and explainability in the decision-making\nprocess is an ongoing challenge in the field of AI in medicine."}]}