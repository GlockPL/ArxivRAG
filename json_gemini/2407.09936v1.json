{"title": "WojoodNER 2024:\nThe Second Arabic Named Entity Recognition Shared Task", "authors": ["Mustafa Jarrar", "Nagham Hamad", "Mohammed Khalilia", "Bashar Talafha", "AbdelRahim Elmadany", "Muhammad Abdul-Mageed"], "abstract": "We present WojoodNER-2024, the second\nArabic Named Entity Recognition (NER)\nShared Task. In WojoodNER-2024, we fo-\ncus on fine-grained Arabic NER. We provided\nparticipants with a new Arabic fine-grained\nNER dataset called WojoodFine, annotated\nwith subtypes of entities. WojoodNER-2024\nencompassed three subtasks: (i) Closed-Track\nFlat Fine-Grained NER, (ii) Closed-Track\nNested Fine-Grained NER, and (iii) an Open-\nTrack NER for the Israeli War on Gaza. A\ntotal of 43 unique teams registered for this\nshared task. Five teams participated in the\nFlat Fine-Grained Subtask, among which two\nteams tackled the Nested Fine-Grained Sub-\ntask and one team participated in the Open-\nTrack NER Subtask. The winning teams\nachieved F\u2081 scores of 91% and 92% in the Flat\nFine-Grained and Nested Fine-Grained Sub-\ntasks, respectively. The sole team in the Open-\nTrack Subtask achieved an F\u2081 score of 73.7%.", "sections": [{"title": "Introduction", "content": "NER plays a crucial role in various Natural\nLanguage Processing (NLP) applications, such\nas question-answering systems (Shaheen and\nEzzeldin, 2014), knowledge graphs (James, 1991),\nand semantic search (Guha et al., 2003), informa-\ntion extraction and retrieval (Jiang et al., 2016),\nword sense disambiguation (Jarrar et al., 2023b;\nAl-Hajj and Jarrar, 2021), machine translation\n(Jain et al., 2019; Khurana et al., 2022), automatic\nsummarization (Summerscales et al., 2011; Khu-\nrana et al., 2022), interoperability (Jarrar et al.,\n2011) and cybersecurity (Tikhomirov et al., 2020).\nNER involves identifying mentions of named\nentities in unstructured text and categorizing them\ninto predefined classes, such as PERS, ORG, GPE, LOC,\nEVENT, and DATE. Given the relative scarcity of re-\nsources for Arabic NLP, research in Arabic NER\nhas predominantly concentrated on \"flat\" entities\nand has been limited to a few \"coarse-grained\" en-\ntity types, namely PERS, ORG, and LOC. To address\nthis limitation, the WojoodNER shared task series\nwas initiated (Jarrar et al., 2023a). It aims to en-\nrich Arabic NER research by introducing Wojood\nand Wojood Fine (Liqreina et al., 2023), nested and\nfine-grained Arabic NER corpora.\nIn WojoodNER-2024 we provide a new ver-\nsion of Wojood, called WojoodFine. WojoodFine\nenhances the original Wojood corpus by offer-\ning fine-grained entity types that are more gran-\nular than the data provided in WojoodNER-\n2023. For instance, GPE is now divided into\nseven subtypes: COUNTRY, STATE-OR-PROVINCE, TOWN,\nNEIGHBORHOOD, CAMP, GPE_ORG, and SPORT. LOC, ORG, and\nFAC are also divided into subtypes as shown in Fig-\nure 1. WojoodFine contains approximately 550k\ntokens and annotated with 51 entity types and sub-\ntypes, covering 47k subtype entity mentions. It is\nworth mentioning that SinaTools supports Wojood"}, {"title": "Literature Review", "content": "NER has been an area of active research for many\nyears, witnessing notable progress recently. This\nsection will cover the evolution from initial efforts\nin recognizing flat-named entities to the current\nfocus on nested NER, with a particular emphasis\non Arabic NER, including discussions on corpora,\nmethodologies, and shared tasks.\nCorpora. The majority of Arabic NER corpora\nare designed for flat NER annotation. ANER-\nCorp (Benajiba et al., 2007), derived from news\nsources, contains approximately 150k tokens and\nfocuses on four specific entity types. CANER-\nCorpus (Salah and Zakaria, 2018) targets Classi-\ncal Arabic (CA) and includes a dataset of 258k\ntokens annotated for 14 types of entities related to\nreligious contexts. The ACE2005 (Walker et al.,\n2005) corpus is multilingual and includes Arabic\ntexts annotated with five distinct entity types. The\nOntonotes5 (Weischedel et al., 2013) dataset fea-\ntures around 300k tokens annotated with 18 differ-\nent entity types. However, these corpora are some-\nwhat dated and primarily cover media and polit-\nical domains, which may not accurately reflect\ncontemporary Arabic usage, particularly as lan-\nguage models are sensitive to changes over time\nand across domains. Recently, (Jarrar et al., 2022)\nintroduced Wojood, the largest Arabic NER cor-\npus to date, notable for supporting both flat and\nnested entity annotations. This corpus, essential\nfor this shared task, includes about 550k tokens\nand covers 21 unique entity types across Modern\nStandard Arabic (MSA) and two Arabic dialects\n(Palestinian Curras2 and Lebanese Baladi corpora\n(Haff et al., 2022)). Wojood Fine (Liqreina et al.,\n2023), an extension of Wojood adds support for\nentity sub-types, with a total of 51 entities orga-\nnized in two-level hierarchy. It is important to note\nthat Wojood has been recently extended to include\nrelationships (Aljabari et al., 2024).\nMethodologies. Research in Arabic NER em-\nploys a variety of approaches, ranging from rule-\nbased systems (Shaalan and Raza, 2007; Jaber\nand Zaraket, 2017) to machine learning techniques\n(Settles, 2004; Abdul-Hamid and Darwish, 2010;\nZirikly and Diab, 2014; Dahan et al., 2015; Dar-\nwish et al., 2021). Recent studies have adopted\ndeep learning strategies, utilizing character and\nword embeddings in conjunction with Long-Short\nTerm Memory (LSTM) (Ali et al., 2018), and BiL-\nSTM architectures paired with Conditional Ran-\ndom Field (CRF) layer (El Bazi and Laachfoubi,\n2019; Khalifa and Shaalan, 2019). Deep Neural\nNetworks (DNN) are explored in (Gridach, 2018),\nalongside pretrained Language Models (LM) (Jar-\nrar et al., 2022; Liqreina et al., 2023). Wang et al.\n(2022) conducted a comprehensive review of var-\nious approaches to nested entity recognition, in-\ncluding rule-based, layered-based, region-based,\nhypergraph-based, and transition-based methods.\nFei et al. (2020) introduced a multi-task learning\nframework for nested NER using a dispatched at-\ntention mechanism. Ouchi et al. (2020) developed\na method for nested NER that calculates all region\nrepresentations from the contextual encoding se-\nquence and assigns a category label to each. Read-\ners can also refer to the WojoodNER-2023 shared\ntask for DNN techniques used for flat and nested\nArabicNER (Jarrar et al., 2023a)."}, {"title": "Task Description", "content": "WojoodNER-2024 confronts the intricacies of\nArabic NER with three distinct subtasks: Flat\nFine-Grained NER, Nested Fine-Grained NER,\nand Open-Track NER. These subtasks provide an\nevaluation environment, allowing researchers to\nexperiment with diverse approaches for identify-\ning and classifying named entities, along with\ntheir subtypes, under controlled (closed) and flex-\nible (open) settings.\nRemark:\nthe Wojood dataset used in\nWojoodNER-2023 (Jarrar et al., 2023a) can-\nnot be used in this Shared Task because the two\ndatasets follow different annotation guidelines.\n3.1\nClosed-Track Flat Fine-Grained NER\nIn this subtask, we provide the Wojood Fine Flat\ntrain (70%) and development (10%) datasets. The\nfinal evaluation of the submitted contributions\nfrom participants is conducted on the test set\n(20%). The flat NER dataset follows the same split\nas the nested NER dataset. The key difference in\nflat NER is that each token is assigned a single tag,\ncorresponding to the first high-level tag assigned\nin the nested NER dataset, and followed by a sin-\ngle tag in the second level (subtype). This subtask\nis a closed track, thus participants can only use the\nprovided datasets to train their systems, with no\nexternal datasets permitted.\n3.2 Closed-Track Nested Fine-Grained NER\nThis subtask is similar to Subtask 1. We provide\nthe Wojood-Fine Nested train (70%) and devel-\nopment (10%) datasets, with the final evaluation\nconducted on the test set (20%). This subtask is\na closed track, which means participants can only\nuse the provided datasets to train their systems.\n3.3 Open-Track NER - Israeli War on Gaza\nThis subtask aims to enable participants to explore\nthe benefits of NER in real-world scenarios. Par-\nticipants can use external resources and are en-\ncouraged to experiment with generative models in\nvarious ways, such as fine-tuning, zero-shot learn-\ning, and in-context learning. The emphasis on\ngenerative models in this subtask is intended to\nhelp the Arabic NLP research community gain a\nbetter understanding of the capabilities and perfor-\nmance gaps of Large Language Models (LLMs)\nin information extraction, which is currently a less\nexplored area.\nWe have curated NER dataset called\nWojoodGaza pertaining to the ongoing Israeli\nWar on Gaza, based on the assumption that\ndiscourse about recent global events will involve\nmentions from different data distributions. For\nthis subtask, we have collected data from five\nnews domains related to the War, while keeping\nthe identities of these domains confidential. Par-\nticipants have been provided with a development\ndataset (10k tokens, 2k from each of the five\ndomains) and a testing dataset (50k tokens, 10k\nfrom each domain). Both datasets have been\nmanually annotated with fine-grained named\nentities, following the same annotation guidelines\nas in Subtask 1 and Subtask 2, as outlined in\n(Liqreina et al., 2023). This subtask is divided\ninto two subtasks: 3A-flat and 3B-nested.\n3.4 Restrictions\nThis section outlines the guidelines for participat-\ning in the WojoodNER-2024 Shared Task. These\nrules have been put in place to ensure fairness and\ntransparency for all participants. They also aim\nto uphold the credibility of the task's assessment\nprocess, which is further elaborated on the official\nshared task FAQ page.\nExternal data. For Subtask 1 and 2, partici-\npants are strictly forbidden from using external\ndata from previously labeled datasets or employ-\ning taggers previously trained to predict named en-\ntities. The use of any resources with prior knowl-\nedge of NER is not permitted. On the contrary,\nSubtask 3 allows the use external resources.\nData format constraints. Submissions for the\ntask must be in a single file containing the model's\npredictions in CoNLL format. This format in-\ncludes multiple space-separated columns: the first\ncolumn for tokens and the subsequent columns\nfor tags. For both flat and nested NER, the tag\ncolumns follow a predefined order specified on the\nshared task webpage. The IOB2 scheme (Sang and\nVeenstra, 1999) is used for submissions, consis-"}, {"title": "Datasets and Evaluation Metrics", "content": "tent with the Wojood dataset. Additionally, text\nsegments are separated by a blank line.\n4 Datasets and Evaluation Metrics\nIn this section, we will describe the dataset, evalu-\nation metrics, and the submission procedure.\nDatasets The WojoodNER-2024 shared task\nutilizes the Wojood Fine corpus as a dataset for\nSubtasks 1 and 2 (Liqreina et al., 2023). For\nSubtask 3, a different dataset called WojoodGaza\nis utilized that is related to the War on Gaza.\nThe Wojood Fine corpus comprises approximately\n550k tokens, annotated with nest named entities,\nusing 51 entity types. For the purposes of the\nshared task, we created a flat NER dataset based\non the nest NER dataset. That is, the flat NER\ndataset is created by simplifying the nested NER\nand reducing subtypes to the top level only as il-\nlustrated in Figure 2 and 3. For both Subtask 1 and\nSubtask 2, we partitioned the data at the domain\nlevel into training, development, and test datasets\nwith a split of 70:10:20, respectively.\nTable 1 presents the details of the datasets used\nin Subtask 1 (FlatNER) and Subtask 2 (NestNER).\nDATE\nORG\n\u2193\nT\nORG-FAC\nSCI BUILDING-OR-GROUNDS\nFigure 2: Flat NER example.\nDATE\nGPE\n\u2193\nORG\nTown\nORG-FAC\nT\nSCI BUILDING-OR-GROUNDS\nFigure 3: Nested NER example.\nThe dataset for Subtask 3 is called WojoodGaza.\nIt includes 60k tokens that we collected and an-\nnotated specifically for this shared task. The cor-\npus was collected from online news articles pub-\nlished at these outlets: Institute for Palestine Stud-\nies, World Health Organization, Palestinian Min-\nistry of Health, Palestine Monetary Authority, Al-\njazeera, Palestine Economy Portal, Wafa, BNews,\nAlAraby, Law for Palestine, United Nations, CNN\nBusiness, Al Arabiya, Sky News, CNBC Arabia,\nRT Arabic, Euro News, BBC Arabic.\nThe articles that were collected from the period\nof January-March 2024, covering one of these five\ndomains (politics, law, economy, finance, health)\nand were directly related to the War on Gaza.\nFor each domain, we collected about 12k tokens.\nParticipants are provided with the development\ndataset (10k tokens, 2k from each of the five do-\nmains), and a testing dataset (50k tokens, 10k\nfrom each domain). Domain names are not pro-\nvided to the participants. WojoodGaza was anno-\ntated following the same guidelines as WojoodFine\n(Liqreina et al., 2023).\nEvaluation metrics. The official and primary\nevaluation metric for Subtask 1, Subtask 2, and\nSubtask 3 is the micro-averaged F\u2081 score. In ad-\ndition to this metric, we also report system per-\nformance in terms of Precision, Recall, and Accu-\nracy.\nSubmission rules. Participating teams were al-\nlowed to submit up to four runs for each test set\nacross the three subtasks. For each team's submis-\nsions, we retained only the highest score per task.\nAlthough the official results were derived exclu-\nsively from the blind test set, we streamlined the\nevaluation process by establishing four separate\nCodaLab competitions, one for each subtask\u00b9. We\nare keeping the CodaLab for each subtask active\neven after the official competition has concluded.\nThis is aimed at facilitating researchers who wish\nto continue training models and evaluating sys-\ntems with the shared task's blind test sets. As a\nresult, we will not disclose the ground truth labels\nfor the test sets for any of the subtasks."}, {"title": "Shared Task Teams & Results", "content": "5 Shared Task Teams & Results\n5.1 Participating Teams\nOverall, we received 43 unique team registrations,\n26 of them registered in the CodaLab, and only\nseven teams have submitted their results. These\nseven teams have submitted 263 valid entries dur-\ning the testing phase. Specifically, 76 submis-\nsions for FlatNER were received from six teams,\n168 submissions for NestedNER came from four\nteams, eight submissions for Gaza-Flat from one\nteam, and 11 submissions for Gaza-Nested from 1\nThe different CodaLab competitions are available at the\nfollowing links: Subtask 1, Subtask 2 and Subtask 3A,\nSubtask 3B."}, {"title": "Baselines", "content": "5.2 Baselines\nFor Subtask 1 and Subtask 2, we fine-tuned\nthe AraBERTV2 (Antoun et al., 2020) pre-trained\nmodel using subtask-specific training data for 20\nepochs, with a learning rate of le\u00af5 and a batch\nsize of 8. To ensure optimal model performance,\nwe incorporated early stopping with a patience\nsetting of 5. After each epoch, we evaluated\nthe model's performance and selected the best-\nperforming checkpoints based on their perfor-\nmance on the respective development sets. We\nthen present the performance metrics of the best-\nperforming model on the test datasets."}, {"title": "Results", "content": "5.3 Results\nTable 3, Table 4, and Table 5 presents the\nleaderboards for Subtask 1\u2013FlatNER, Subtask 2-\nNestedNER, and Subtask 3A-Gaza respectively,\norganized in descending order based on the micro-\nF\u2081 scores. The micro-F\u2081 score listed for each team\nreflects their highest score out of the four allowed\nsubmissions for each task.\nF\u2081 Pre. Rec.\nmucAI 91 91 90\nmuNERa 90 91 89\nAddax 90 89 91\nBaseline-I (ARBERT\u221a2) 89 90\nDRU - Arab Center 87 86 86\nBangor 86 88 85\nTable 3: Results of Subtask 1-FlatNER.\nFor FlatNER, the mucAI team (Abdou and\nMohsen, 2024) achieved the highest F\u2081 score of\n91, with muNERa (Alotaibi et al., 2024) and Addax\n(Issam AIT YAHIA, 2024) securing second place\nwith 90, DRU taking third place with 87, and\nBangor taking fourth place with 86. Notably,\nthree teams outperformed our baseline, as shown\nin Table 3. The winning team mucAI(Abdou and\nMohsen, 2024) surpassed the baseline by 2%. The\nperformance gap between our baseline and the\nlowest-performing model is approximately 3%.\nFurthermore, the difference in F\u2081 scores among\nthe teams is minimal, with a standard deviation of\n\u03c3 = 1.94.\nF1 Pre. Rec.\nBaseline-I (ARBERTV2) 92 92 93\nmuNERa 91 92 90\nDRU - Arab Center 90 90 90\nTable 4: Results of Subtask 2 - NestedNER.\nFor NestedNER, none of the teams outper-\nformed the baseline. The muNERa team (Alotaibi\net al., 2024) achieved the highest F\u2081 score of 91,\nbut still 1% below the baseline, followed by DRU\nteam (Hamoud et al., 2024) with a score of 90.\nF\u2081 Pre. Rec.\nDRU - Arab Center 73.7 71.9 75.6\nTable 5: Results of Subtask 3 - Gaza-FlatNER.\nFor the open-track Gaza-FlatNER, only DRU\nteam (Hamoud et al., 2024) reported their results\nwith a recall of 75.9 and F\u2081 score of 73.5."}, {"title": "General Description of Submitted Systems", "content": "5.4 General Description of Submitted\nSystems\nFor Subtask 1 and Subtask 2, all models submitted\nto the shared task employed the transfer learning\napproach, utilizing pre-trained models trained on\ndiverse data sources. For Subtask 3, LLMs with\nin-context learning techniques were utilized.\nAddax (Issam AIT YAHIA, 2024) proposed a\ncombined tagging approach that merges the main\nentity type and its subtypes into a single cate-\ngory (e.g., \"B-GPE+B-COUNTRY\" for \"Palestine\").\nThis method follows the IOB2 scheme for entity\nboundaries and simplifies training by focusing on\na single combined tag per entity, integrating both\nmain and subtype information. The model archi-\ntecture utilizes a two-channel parallel hybrid neu-\nral network with an attention mechanism. It em-\nploys BERT-based model (AraBERTv0.2-Twitter)\nembeddings for contextualized word representa-\ntions and consists of two distinct channels: one us-\ning Conv1D layers for local feature extraction and\nanother with Bi-GRU layers to capture long-range\ndependencies. Additionally, an attention layer fo-\ncusing on the most relevant input features has been\nadded in each channel.\nBangor (Alshammari and Teahan, 2024) added\na linear layer on top of a BERT-based model (bert-\nbase-arabic-camelbert-mix) to classify each token\ninto one of 51 different entity types and subtypes,\nas well as the \"0\" label for non-entity tokens. This\nlinear layer maps the contextualized embeddings"}, {"title": "Conclusion", "content": "produced by BERT to the desired output labels.\nmuNERa (Alotaibi et al., 2024) team adapted\nWojood dataset to fit the input requirements of\nthe Translation between Augmented Natural Lan-\nguages (TANL) framework (Paolini et al., 2021).\nThe preprocessing steps included extracting hier-\narchical tags (parent, subtype, sub-subtype) and\ntheir spans using the IOB2 scheme. Each to-\nken and its corresponding labels were reformat-\nted to align with the TANL framework's specifi-\ncations. TANL was used for Subtask 1 and Sub-\ntask 2. In this framework, both input and output\nare structured in augmented natural languages and\nenclosed in square brackets (e.g., [ token | entity\ntype ]). For nested entities, TANL can represent\nentity hierarchies, such as [ token [ token | entity\ntype1] | entity type2 ]. They utilized two distinct\nTANL models for handling flat and nested entities.\nA decoder-encoder model (AraT5v2) is used as\nbase for the TANL model. Additionally, they used\na FastText (FT) classifier as a secondary tagger,\nfirst using TANL to detect spans and assign level-\n1 (parent) tags, and then applying the FT classifier\nto tag the detected spans with level-2 and level-3\ntags. The best-performing TANL architecture was\nachieved without using FT.\nmucAI (Abdou and Mohsen, 2024) team pro-\nposed a two-step methodology: joint vanilla fine-\ntuning followed by k-Neared Neighbor (KNN) at\ninference time. BERT (AraBERTv02) is used as\nthe backbone for generating word embeddings.\nThese embeddings are then fed into two multi-\nlayer perceptrons (MLP) that are trained jointly.\nThe first head predicts one of the predefined 21\nmain entity tags. The second head predicts one of\nthe predefined 31 sub-entities. A \u201cDatastore\" is\nconstructed as a database that has a contextualized\nrepresentation for each token alongside the label\nin each sentence in the training set. The \"Datas-\ntore\" was queried during inference to retrieve the\nk nearest neighbors based on a similarity score,\nderive the distribution of labels from these neigh-\nbors, and then interpolate this distribution with the\nmain MLP model's distribution using an interpo-\nlation factor to obtain the final label probabilities.\nDRU-Arab Center (Hamoud et al., 2024) pro-\nposed three strategies to deal with the Flat and\nNested subtasks. (1) A single-layer approach,\nwhere they fine-tuned different BERT-based mod-\nels to predict all types and subtypes in one shot, us-\ning a 103-length one-hot encoded vector for each\ntype and subtype, including the \"0\" tag. They\nexperimented with GEMMA (Team et al., 2024),\nand AraBERTv2 (Antoun et al., 2020), and fine-\ntuned BLOOMZ-7b-mt on a high-quality Arabic\ndataset (Muennighoff et al., 2023). (2) Another\nattempt was the Onex1 classifier method, which\nseparated type and subtype classification by ded-\nicating a model for each, training one instance\nof (AraBERTv2) exclusively for predicting main\ntypes and another instance for predicting sub-\ntypes. (3) In the One\u00d74 Classifier Method, instead\nof only one model for subtypes, they trained four\ninstances, each specialized in the sub-types of a\nspecific group: GPE, ORG, FAC, LOC, as the other main\ntypes have no subtypes. Among these strategies,\nthe Onex1 approach achieved the highest perfor-\nmance on both Subtask 1 and Subtask 2.\nFor the open track Subtask 3, (Hamdan et al.,\n2024), DRU-Arab Center utilized LLMs (Co-\nhere's Command R model (Command R Team))\nand in-context learning to solve this task. In\nthe prompt design, they wrote a detailed system\nprompt that outlines the steps for tagging tokens\naccording to the Wojood Fine annotation guide-\nlines. The prompt instructs the LLM to perform\nNER for Arabic text by predicting up to three lev-\nels of tags-high-level tags, subtypes, and specific\nsubtypes for certain entities-while simplifying\nthe task to two tag levels for practical purposes,\nand outputting predictions in CSV format; illus-\ntrative examples are provided to guide the model,\nand specific instructions ensure the correct appli-\ncation of the IOB2 schema and handle complex\nsubtypes during post-processing. Command R's\noutput quality issues included producing extra or\nmissing tokens. To solve that, they post-processed\nthe generated output to match the expected for-\nmat by assigning the tag \"0\" to ground truth tokens\nwithout corresponding predicted tokens or halluci-\nnated tags, and by converting the remaining format\nissues to the expected output.\n6 Conclusion\nIn this paper, we present the outcomes of the sec-\nond edition of WojoodNER shared task. The re-\nsults from the participating teams highlight the on-\ngoing difficulties in NER, yet it is encouraging\nto see that various innovative approaches, particu-\nlarly those leveraging the power of language mod-\nels, have proven effective in tackling this complex\ntask. As we progress, we are dedicated to advanc-"}, {"title": "Limitations", "content": "ing research in this field. Our vision includes con-\ntinuous efforts to improve Arabic NER, drawing\non the valuable insights from WojoodNER-2024\nand exploring new solutions. Additionally, we\nplan to expand the Wojood Fine corpus to encom-\npass more dialects.\nLimitations\nSimilar to WojoodNER-2023, WojoodNER-2024\naimed for the broadest possible coverage, primar-\nily focusing on MSA data. This dataset used this\nyear, Wojood Fine, includes limited data from di-\nalects. It only includes text from Palestinian and\nLebanese Arabic. We plan to include the other di-\nalects, especially the Syrian Nabra dialects (Nay-\nouf et al., 2023) as well as the four dialects in the\nLisan (Jarrar et al., 2023c) corpus. Additionally,\nthe WojoodGaza dataset used in Subtask 3 covers\nonly the initial phase of the Israeli War on Gaza,\nexcluding the subsequent genocidal and starvation\nevents."}, {"title": "Ethics Statement", "content": "Ethics Statement\nThe datasets provided for this shared task are de-\nrived from public sources, eliminating specific pri-\nvacy concerns. The results of the shared task will\nbe made publicly available to enable the research\ncommunity to build upon them for the public good\nand peaceful purposes. Our datasets and research\nare strictly intended for non-malicious, peaceful,\nand non-military purposes."}, {"title": "Acknowledgements", "content": "Acknowledgements\nThis research is partially funded by the Palestinian\nHigher Council for Innovation and Excellence and\nby the research committee at Birzeit University.\nMuhammad Abdul-Mageed acknowledges sup-\nport from Canada Research Chairs (CRC), the\nNatural Sciences and Engineering Research Coun-\ncil of Canada (NSERC; RGPIN-2018-04267), the\nSocial Sciences and Humanities Research Council\nof Canada (SSHRC; 435-2018-0576; 895-2020-\n1004; 895-2021-1008), Canadian Foundation for\nInnovation (CFI; 37771), Digital Research Al-\nliance of Canada,\u00b2 and UBC ARC-Sockeye.\nWe extend our gratitude to Taymaa Hammouda\nfor the technical support and to the students who\nhelped and supported us during the annotation pro-\ncess, especially Haneen Liqreina, Lina Duaibes,"}]}