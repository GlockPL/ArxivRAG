{"title": "LinSATNet: The Positive Linear Satisfiability Neural Networks", "authors": ["Runzhong Wang", "Yunhao Zhang", "Ziao Guo", "Tianyi Chen", "Xiaokang Yang", "Junchi Yan"], "abstract": "Encoding constraints into neural networks is attractive. This paper studies how to introduce the popular positive linear satisfiability to neural networks. We propose the first differentiable satisfiability layer based on an extension of the classic Sinkhorn algorithm for jointly encoding multiple sets of marginal distributions. We further theoretically characterize the convergence property of the Sinkhorn algorithm for multiple marginals. In contrast to the sequential decision e.g. reinforcement learning-based solvers, we showcase our technique in solving constrained (specifically satisfiability) problems by one-shot neural networks, including i) a neural routing solver learned without supervision of optimal solutions; ii) a partial graph matching network handling graphs with un-matchable outliers on both sides; iii) a predictive network for financial portfolios with continuous constraints. To our knowledge, there exists no one-shot neural solver for these scenarios when they are formulated as satisfiability problems. Source code is available at https://github.com/Thinklab-SJTU/LinSATNet.", "sections": [{"title": "1. Introduction", "content": "It remains open for how to effectively encode the constraints into neural networks for decision-making beyond unconstrained regression and classification. Roughly speaking, we distinguish two categories of such constrained problems: optimization and decision. Optimization problems consider explicit objective functions that are directly related to downstream tasks, whereby their optimization forms are usually more complicated. Decision problems do not consider the objective of the downstream task, or the downstream task may not have any explicit objectives. It is possible that decision problems also have underlying forms, however, their objectives are usually interpreted as \"finding a feasible solution nearest to the input\". In particular, the decision problem can be divided into two cases: i) only judge if there exists a feasible solution or not; ii) output a feasible solution close to an unconstrained input. This paper focuses on the latter case for decision problem, and we term it as satisfiability problem if not otherwise specified.\nNotably, machine learning has been well adopted in solving both optimization and decision problems, especially for combinatorial optimization (CO) (Bengio et al., 2021) and SAT problem (Guo et al., 2023; Li et al., 2023). It is relatively easy to introduce learning into problem-solving as a building block under the traditional solving framework (Wang et al., 2021b;a), yet it is more attractive to develop a learning-based framework in a more systematic manner. In this regard, reinforcement learning (RL) (Liu et al., 2023) or alternative sequence-to-sequence models (Vinyals et al., 2015) that solve the problem in an auto-regressive way is of prominence adoption, while they are often less efficient for their sequential decision nature. Thus efforts have also been put into one-shot problem solving, and a popular alternative is designing certain penalties in the loss (Karalias & Loukas, 2020) to respect the constraints. Being more thought-provoking, a more aggressive ambition is to develop end-to-end differentiable neural networks whereby the constraints are seamlessly encoded in their architecture, such that the efficiency of neural networks for one-shot solving can be fulfilled."}, {"title": "2. Related Work", "content": "Sinkhorn Algorithm (Sinkhorn & Knopp, 1967) projects a positive matrix to a doubly-stochastic matrix by alternatively normalizing its rows and columns, and Cuturi (2013) identifies the connection of Sinkhorn and optimal transport. Its effectiveness also motivates recent theoretical studies concerning its convergence rate (Altschuler et al., 2017; Knight, 2008), whereby Chakrabarty & Khanna (2021) offers a comprehensive theory. Due to its differentiability, Sinkhorn is widely applied in vision (Cruz et al., 2017; Wang et al., 2019b) and learning (Adams & Zemel, 2011; Xie et al., 2020) by enforcing specific constraints. However, as summarized in Table 1, the types of constraints studied in the previous works are less general than the positive linear constraints studied in this paper. Our paper also differs from the existing study of multi-marginal optimal transport (Pass, 2015) since their \u201cmulti-marginal\u201d means moving one source distribution to multiple targets, while we are moving multiple sources to multiple targets. To distinguish, we name our algorithm as \u201cSinkhorn for multi-set marginals\u201d.\nApproximate Solvers for Positive Linear Programming is also an active topic in theoretical computer science. Despite their solid theoretical groundings, this line of works may not be readily integrated into neural networks. For example, Awerbuch & Khandekar (2008); Allen-Zhu & Orecchia (2014) are non-differentiable because their algorithms involve max operations and thresholding functions, respectively. Young (2001); Luby & Nisan (1993) are neither differentiable due to their incremental steps. Another drawback of these methods is that most of them cannot handle a mix of packing ($Ax \\le b$) and covering ($Cx \\ge d$) constraints except for Young (2001). In this paper, we emphasize differentiability to make it compatible with neural networks, and our method could handle any combinations of packing, covering, and equality constraints.\nDifferentiable Solvers for Constrained Optimization address the problem with objective functions and constraints whereby deep graph matching (Yan et al., 2020; Yu et al., 2020) has been a prominent topic with a quadratic objective. Amos & Kolter (2017) shows the differentiability at optimal solutions via KKT conditions and presents a case study for quadratic programming. Wang et al. (2019a) approximately solves MAXSAT by a differentiable semi-definitive solver. Another line of works develops approximate gradient wrappers for combinatorial solvers: Pogan\u010di\u0107 et al. (2019) estimates the gradient by the difference of two forward passes; Berthet et al. (2020) estimates the gradient via a batch of random perturbations.\nOur approach is devoted to the satisfiability setting whereby no explicit objective function is given for the downstream task (Selsam et al., 2019). Note that this is more than just a mathematical assumption: in reality, many problems cannot be defined with an explicit objective function, either due to e.g. the missing of some key variables in noisy or dynamic environments, especially when the objective concerns with a future outcome as will be shown in case studies on partial graph matching (Sec. 5) and predictive portfolio allocation (Sec. 6). However, existing neural networks for optimization (e.g. Butler & Kwon (2021) for asset allocation) do not adapt smoothly to these realistic scenarios.\nFinally, note that the boolean satisfiability problem (Cook, 1971) also receives attention from machine learning community (Guo et al., 2023), whereby end-to-end neural nets have also been actively developed e.g. NeuroSAT (Selsam et al., 2019) and QuerySAT (Ozolins et al., 2021). As we mentioned in Table 1, the boolean-SAT cannot be covered by our constraint and is orthogonal to this work."}, {"title": "3. Methodology", "content": "Sec. 3.1 formulates the classic Sinkhorn algorithm handling a single set of marginal distributions. Sec. 3.2 proposes the generalized multi-set Sinkhorn with a convergence study. In Sec. 3.3 we devise LinSAT layer to enforce the positive linear constraints, by connecting to the marginal distributions.\n\nWe first revisit the classic Sinkhorn algorithm in Algorithm 1, which is a differentiable method developed by Sinkhorn & Knopp (1967) to enforce a single set of marginal distributions to a matrix. Given non-negative score matrix $S \\in \\mathbb{R}^{m\\times n}$ and a set of marginal distributions on rows $v \\in \\mathbb{R}^m_{\\ge 0}$ and columns $u \\in \\mathbb{R}^n_{\\ge 0}$ (where $\\Sigma_{i=1}^m v_i = \\Sigma_{j=1}^n u_j = h$), the Sinkhorn algorithm outputs a normalized matrix $\\Gamma \\in [0,1]^{m\\times n}$ so that $\\Sigma_{j=1}^n \\Gamma_{i,j}u_j = v_i, \\Sigma_{i=1}^m \\Gamma_{i,j}v_i = u_j$. Conceptually, $\\Gamma_{i,j}$ means the proportion of $u_j$ moved to $v_i$. Note that $\\Gamma_{i,j}$ usually has no same meaning in the \u201creversed move\u201d from $v_i$ to $u_j$ if $v_i \\neq u_j$.\nAt iteration t, $\\Gamma'(t)$ is obtained by normalizing w.r.t. the row-distributions v, and $\\Gamma(t+1)$ is obtained by normalizing w.r.t the column-distributions u. $\\Gamma(t), \\Gamma'(t) \\in [0,1]^{m\\times n}$ are"}, {"title": "Theorem 3.1", "content": "For any $\\epsilon > 0$, the Sinkhorn algorithm for single-set marginals returns a matrix $\\Gamma(t)$ or $\\Gamma'(t)$ with L\u2081 error < $\\epsilon$ in time $t = O\\left(\\frac{h^2}{\\epsilon^2} log(\\Delta/\\alpha) \\right)$, where $\\alpha = \\min_{i,j:s_{i,j}>0} s_{i,j}/\\max_{i,j} s_{i,j}$, $\\Delta = \\max_j |\\{i : s_{i,j} > 0\\}|$ is the max number of non-zeros in any column of S, and recall that $\\Sigma_{i=1} v_i = \\Sigma_{j=1} u_j = h$."}, {"title": "3.2. Generalizing Sinkhorn Algorithm for Multiple Sets of Marginal Distributions", "content": "Existing literature about the Sinkhorn algorithm mainly focuses on a single set of marginal distributions. In the following, we present our approach that extends the Sinkhorn algorithm into multiple sets of marginal distributions.\nFollowing Cuturi (2013), we view the Sinkhorn algorithm as \u201cmoving masses\u201d between marginal distributions: $\\Gamma_{i,j} \\in [0, 1]$ means the proportion of $u_j$ moved to $v_j$. Interestingly, it yields the same formulation if we simply replace u, v by another set of marginal distributions, suggesting the potential of extending the Sinkhorn algorithm to multiple sets of marginal distributions. To this end, we devise Algorithm 2, an extended version of the Sinkhorn algorithm, whereby k sets of marginal distributions are jointly enforced to fit more complicated real-world scenarios. The sets of marginal distributions are $u_\\eta \\in \\mathbb{R}^n_{\\ge 0}$, $v_\\eta \\in \\mathbb{R}^m_{\\ge 0}$, and we have:\n$\\forall \\eta \\in \\{1,..., k\\} : \\sum_{i=1}^m v_{\\eta,i} = \\sum_{j=1}^n u_{\\eta,j} = h_\\eta$.\nIt assumes the existence of a normalized $Z \\in [0, 1]^{m\\times n}$ s.t.\n$\\forall \\eta \\in \\{1,\\dots, k\\} : \\sum_{i=1}^m Z_{i,j}u_{\\eta, j} = u_{\\eta,j}, \\sum_{j=1}^n Z_{i,j}u_{\\eta,j} = v_{\\eta,i}$,\ni.e., the multiple sets of marginal distributions have a non-empty feasible region (see Appendix D for details). Multiple sets of marginal distributions could be jointly enforced by traversing the Sinkhorn iterations over k sets of marginal distributions. We extend Eq. (3) for multiple marginals,\n$\\Gamma^{(t)}_{i,j} = \\frac{\\Gamma^{(t-1)}_{i,j} v_{\\eta,i}}{\\Sigma_{j=1}^n \\Gamma^{(t-1)}_{i,j} v_{\\eta,i}}, \\Gamma^{(t+1)}_{i,j} = \\frac{\\Gamma^{(t)}_{i,j} u_{\\eta,j}}{\\Sigma_{i=1}^m \\Gamma^{(t)}_{i,j} u_{\\eta, j}}$,\nwhere $\\eta = (t \\mod k) + 1$ is the index of marginal sets. Similarly to Algorithm 1, this generalized Sinkhorn algorithm finds a normalized matrix that is close to S."}, {"title": "Theoretical Characterization of the Convergence of Multi-set Sinkhorn", "content": "In the following, we show that our proposed Algorithm 2 shares a similar convergence pattern with Algorithm 1 and Theorem 3.1. We generalize the theoretical steps in Chakrabarty & Khanna (2021) as follows.\nWe first study the convergence property of Algorithm 2 in terms of Kullback-Leibler (KL) divergence. In the following, we have $\\eta = (t \\mod k)+1$ unless otherwise specified. We define the probability over marginals $\\pi_{v_{\\eta},i} = v_{\\eta,i}/h_\\eta$, and similarly for $\\pi_{u_{\\eta},j}$. $\\pi_{v_\\eta}^{(t)}$, $\\pi_{u_\\eta}^{(t)}$, $v^{(t)}, u^{(t)}$ are the $\\eta$-th marginal distributions achieved by $\\Gamma^{(t)}$ and $\\Gamma'^{(t)}$, respectively,\n$D_{KL}(\\pi_{v_{\\eta}} || \\pi_{v_\\eta}^{(t)}) = \\sum_{i=1}^m \\frac{v_{\\eta,i}}{h_\\eta} \\log \\frac{v_{\\eta,i} / h_\\eta}{\\Sigma_{j=1}^n \\Gamma^{(t)}_{i,j} u_{\\eta, j} / h_\\eta}$.\nTheorem 3.2 (Converge Rate for KL divergence). For any $\\delta > 0$, the Sinkhorn algorithm for multi-set marginals returns a matrix $\\Gamma^{(t)}$ or $\\Gamma'^{(t)}$ with KL divergence $<\\delta$ in time $t = O\\left(\\frac{h^2}{\\epsilon^2} k log(\\Delta/\\alpha) \\right)$, where $\\alpha = \\min_{i,j:s_{i,j}>0} s_{i,j}/\\max_{i,j} s_{i,j}$, $\\Delta = \\max_j |\\{i : s_{i,j} > 0\\}|$ is the max number of non-zeros in any column of S, and recall that k is the number of marginal sets."}, {"title": "Lemma 3.3", "content": "For any $\\eta, D(Z, \\Gamma^{(0)}, \\eta) < log(1 + 2\\Delta/\\alpha)$."}, {"title": "Lemma 3.4", "content": "For $\\eta = (t \\mod k) + 1, \\eta' = (t + 1 \\mod k) + 1$, we have\n$D(Z, \\Gamma^{(t)}, \\eta) \u2013 D(Z, \\Gamma'^{(t)}, \\eta) = D_{KL}(\\pi_{v_{\\eta}} || \\pi_{v_{\\eta}}^{(t)})$\n$D(Z, \\Gamma'^{(t)}, \\eta) \u2013 D(Z, \\Gamma^{(t+1)}, \\eta') = D_{KL}(\\pi_{u_{\\eta}} || \\pi_{u_{\\eta}}^{(t)})$"}, {"title": "Corollary 3.5", "content": "For any $\\epsilon > 0$, the Sinkhorn algorithm for multi-set marginals returns a matrix $\\Gamma^{(t)}$ or $\\Gamma'^{(t)}$ with L\u2081 error < $\\epsilon$ in time $t = O\\left(\\frac{h^2 k log(\\Delta/\\alpha)}{\\epsilon^2}\\right)$ where $h = \\max_{\\eta} \\Sigma_{i=1} u_{\\eta,i}$."}, {"title": "3.3. LinSAT: Enforcing Positive Linear Satisfiability", "content": "Denote y as an l-length vector that can be the output of any neural network. Our LinSAT develops an satisfiability layer that projects y into $x \\in [0,1]^l$, $\\texttt{LinSAT}(y, A, b, C, d, E, f) \\rightarrow x$, where $Ax \\le b, Cx \\ge d, Ex = f$. x is dependent on y (following Eq. (11)) and, in the meantime, lies in the feasible space. We firstly show how to encode y and x by our proposed Algorithm 2.\nEncoding Neural Network's Output. For an l-length vector denoted as y, the following matrix is built\n$W = \\begin{bmatrix} y_1 & y_2 & \\dots & y_l & 0 \\\\ \\beta & \\beta & \\dots & \\beta & \\psi \\end{bmatrix}$,\nwhere W is of size $2 \\times (l+1)$, and $\\beta$ is the dummy variable e.g. $\\beta=0$. y is put at the upper-left region of W. The entropic regularizer is then enforced to control discreteness and handle potential negative inputs:\n$S = \\exp(\\frac{W}{\\tau})$\nThe score matrix S is taken as the input of Algorithm 2. LinSAT then enforces positive linear constraints to the corresponding region of y by regarding the constraints as marginal distributions.\nFrom Linear Constraints to Marginal Distributions. We discuss the connections between positive linear constraints and marginal distributions for $Ax \\le b, Cx \\ge d, Ex = f$, respectively. For notation's simplicity, here we discuss with only one constraint. Multiple constraints are jointly enforced by multiple sets of marginals.\nPacking constraint $Ax \\le b$. Assuming that there is only one constraint, we rewrite the constraint as $\\sum_{i=1}^l a_i x_i \\le b$. The marginal distributions are defined as\n$u_p = [a_1 \\; a_2 \\; \\dots \\; a_l \\; b], v_p = \\begin{bmatrix} \\Sigma_{i=1}^l a_i \\\\ b \\end{bmatrix}$.\nFollowing the \u201ctransportation\u201d view of Sinkhorn (Cuturi, 2013), the output x moves at most b unit of mass from $a_1,a_2,..., a_l$, and the dummy dimension allows the inequality by moving mass from the dummy dimension. It is also ensured that the sum of up equals the sum of vp.\nCovering constraint $Cx \\ge d$. Assuming that there is only one constraint, we rewrite the constraint as $\\sum_{i=1}^l c_i x_i \\ge d$. The marginal distributions are defined as\n$u_c = [c_1 \\; c_2 \\; \\dots \\; c_l \\; \\gamma d], v_c = \\begin{bmatrix} \\Sigma_{i=1}^l c_i \\\\ (\\gamma+1)d \\end{bmatrix}$\nwhere the multiplier $\\gamma = [\\Sigma_{i=1}^l c_i/d - 1]$ is necessary because we always have $\\sum_{i=1}^l c_i > d$ (else the constraint is infeasible), and we cannot reach the feasible solution where all elements in x are 1s without this multiplier. This formulation ensures that at least d unit of mass is moved from $c_1, c_2,..., c_l$ by x, thus representing the covering constraint of \"greater than\". It is also ensured that the sum of u equals the sum of ve.\nEquality constraint $Ex = f$. Representing the equality constraint is more straightforward. Assuming that there is only one constraint, we rewrite the constraint as $\\sum_{i=1}^l e_i x_i = f$. The marginal distributions are defined as\n$u_e = [e_1 \\; e_2 \\; \\dots \\; e_l \\; 0], v_e = \\begin{bmatrix} f \\\\ \\Sigma_{i=1}^l - f \\end{bmatrix}$,\nwhere the output x moves $e_1, e_2, \\dots, e_l$ to f, and we need no dummy element in ue because it is an equality constraint. It is also ensured that the sum of ue equals the sum of ve.\nEnforcing Multiple Constraints by Sinkhorn. The constraints are firstly modulated as multiple sets of marginals and then stacked into $U \\in \\mathbb{R}^{k \\times (l+1)}, V \\in \\mathbb{R}^{k \\times 2}$, where k is the number of constraints. By building W from y, getting $S = \\exp(W/\\tau)$ and calling Algorithm 2 based on S, U, V, the satisfiability of positive linear constraints is enforced to the output of neural networks.\nImplementation Details. We set separate dummy variables for different constraints to handle potential conflicts among different sets of marginals (see explanations in Appendix D)."}, {"title": "4. Case Study I: Neural Solver for Traveling Salesman Problem with Extra Constraints", "content": "The Traveling Salesman Problem (TSP) is a classic NP-hard problem. The standard TSP aims at finding a cycle visiting all cities with minimal length, and developing neural solvers for TSP receives increasing interest (Vinyals et al., 2015; Kool et al., 2019; Kwon et al., 2021). Beyond standard TSP, here we develop a neural solver for TSP with extra constraints using LinSAT layer."}, {"title": "4.2. Constraint Formulation for LinSAT", "content": "We consider 1) TSP with starting and ending cities constraint (TSP-SE); 2) TSP with priority constraint (TSP-PRI).\nGiven n cities and two of them are the starting and ending cities s, e \u2208 {1,..., n}. The distance matrix D \u2208 Rn\u00d7n records the distances between city pairs. TSP-SE finds the shortest tour starting from city s, visiting other cities exactly once, and ending in city e. TSP-SE can be formulated with the following objective function and constraints:\n$\\min_{X} \\sum_{k=1}^{n-1} \\sum_{i=1}^n \\sum_{j=1}^n D_{ij} X_{i,k} X_{j,k+1}$,\ns.t. $\\sum_{i=1}^n X_{i,k} = 1,\\forall k \\in \\{1, ..., n\\}$,\n$\\sum_{k=1}^n X_{i,k} = 1, \\forall i \\in \\{1, ..., n\\}$,\n$X_{s,1} = 1, X_{e,n} = 1$,\n$X_{i,k} \\in \\{0,1\\}, \\forall i, j\\in \\{1, ..., n\\}$,\nwhere $X \\in \\{0,1\\}^{n\\times n}$ is a binary matrix and $X_{ik} = 1$ indicates city i is the k-th visited city in the tour. Constraints ensure X to be a valid tour and constraint defines the starting and ending cities. If $X_{i,k}X_{j,k+1} = 1$ for some k, then the k-th step of the tour is from i to j, and $D_{i,j}$ will be counted into the objective."}, {"title": "2) TSP-PRI", "content": "In practice, some cities may have higher priority and need to be visited earlier. In TSP-PRI we consider: in the given n cities, the priority city p \u2260 s, e has to be visited within the first m steps. We add a new constraint to TSP-SE to formulate TSP-PRI:\n$\\sum_{k=1}^{m+1} X_{p,k} = 1$.\nTo fit with the continuous nature of neural networks, we relax the binary constraint to continuous ones $X_{i,k} \\in [0, 1]$ which is automatically satisfied by LinSAT. A neural network takes the instance as input and outputs the pre-projected matrix $Y \\in \\mathbb{R}^{n\\times n}$. Y is flattened into a n\u00b2-dimensional vector and projected via LinSAT to enforce all the aforementioned constraints. Note that the neural network itself is a solver to an optimization problem, enforcing the constraint satisfiability by LinSAT is a reasonable choice instead of optimizing some other auxiliary objectives."}, {"title": "4.3. Network Design Details", "content": "Following the Attention Model for standard TSP (Kool et al., 2019), we use a Transformer (Vaswani et al., 2017) without positional encoding to encode each of the n nodes into a hidden vector hi. Learnable embeddings to mark starting, ending and priority cities are added to the corresponding embeddings before input to the Transformer. After encoding, h\u00a1 is projected into $Y_i \\in \\mathbb{R}^n$ using an MLP. All $Y_i, i \\in \\{1, . . ., n\\}$ form the pre-projected matrix $Y \\in \\mathbb{R}^{n\\times n}$. In training, the objective Eq. (17) with continuous X as the decision variable is used as the unsupervised loss. For inference, we first output X. As X satisfies constraints (17a) and (17b), it can be viewed as the marginal distributions of the binary X (Adams & Zemel, 2011). We perform beam search on X to get X in post-processing."}, {"title": "5. Case Study II: Partial Graph Matching with Outliers on Both Sides", "content": "Standard graph matching (GM) assumes an outlier-free setting namely bijective mapping. One-shot GM neural networks (Wang et al., 2022) effectively enforce the satisfiability of one-to-one matching constraint by single-set Sinkhorn (Algorithm 1). Partial GM refers to the realistic case with outliers on both sides so that only a partial set of nodes are matched. There lacks a principled approach to enforce matching constraints for partial GM. The main challenge for existing GM networks is that they cannot discard outliers because the single-set Sinkhorn is outlier-agnostic and tends to match as many nodes as possible. The only exception is BBGM (Rol\u00ednek et al., 2020) which incorporates a traditional solver that can reject outliers, yet its performance still has room for improvement."}, {"title": "5.2. Constraint Formulation for LinSAT", "content": "Denote a graph pair by $G_1 = (V_1, E_1), G_2 = (V_2, E_2)$, where $|V_1| = n_1, |V_2| = n_2$. In mainstream GM networks, a matching score matrix $M \\in \\mathbb{R}^{n_1\\times n_2}$ is expected to describe the correspondences of nodes between $G_1$ and $G_2$, where $M_{i,j}$ refers to the matching score between node i in G\u2081 and node j in G2. In previous bijective GM networks, the one-to-one node matching constraint that a node corresponds to at most one node is enforced by the off-the-shelf Sinkhorn algorithm in Algorithm 1. It cannot take the outliers into consideration, as it forcibly matches all nodes. The partial GM problem can be formulated by adding a partial matching constraint: assume that the number of inliers is $\\phi$, so the number of matched nodes should not exceed $\\phi$.\nWith a little abuse of notations, denote X \u2208 [0,1]n\u2081\u00d7n\u2082 as the output of our partial GM network, the partial GM problem has the following constraints,\n$\\sum_{i=1}^{n_1} X_{i,j} \\le 1, \\forall j \\in \\{1, ..., n_2\\}$,\n$\\sum_{j=1}^{n_2} X_{i,j} \\le 1, \\forall i \\in \\{1, ..., n_1\\}$,\n$\\sum_{i=1}^{n_1} \\sum_{j=1}^{n_2} X_{i,j} \\le \\phi$.\nThe constraint (19a) and (19b) denotes the node-matching on rows and columns, respectively, and they ensure (at most) one-to-one node correspondence. Constraint (19c) is the partial matching constraint ensuring that the total number of matched node pairs should not exceed $\\phi$. All constraints are positive linear and can be enforced by LinSAT layer. We implement our partial GM neural network by flattening M into a $n_1n_2$-dimensional vector to feed into LinSAT."}, {"title": "5.3. Network Design Details", "content": "We follow the SOTA GM network NGMv2 (Wang et al., 2022) and replace the original Sinkhorn layer with LinSAT to tackle the partial GM problem on natural images. Specifically, a VGG16 (Simonyan & Zisserman, 2014) network is adopted to extract initial node features and global features from different CNN layers. The node features are then refined by SplineConv (Fey et al., 2018). The edge features are produced by the node features and the connectivity of graphs. The matching scores are predicted by the neural graph matching network proposed by Wang et al. (2022), finally generating the matching scores M. We replace the original single-set Sinkhorn layer by LinSAT to enforce the constraints in Eq. (19). The output of LinSAT is reshaped into matrix M, which is used for end-to-end training with permutation loss (Wang et al., 2019b). During inference, the Hungarian algorithm (Kuhn, 1955) is performed on M and we retain the $\\phi$-highest matching scores from M, and the remaining matches are discarded."}, {"title": "6. Case Study III: Portfolio Allocation", "content": "Predictive portfolio allocation is the process of selecting the best asset allocation based on predictions of future financial markets. The goal is to design an allocation plan to best trade-off between the return and the potential risk (i.e. the volatility). In an allocation plan, each asset is assigned a non-negative weight and all weights should sum to 1. Existing learning-based methods (Zhang et al., 2020; Butler & Kwon, 2021) only consider the sum-to-one constraint without introducing personal preference or expert knowledge. In contrast, we achieve such flexibility for the target portfolio via positive linear constraints: a mix of covering and equality constraints, which is widely considered for its real-world demand."}, {"title": "6.2. Constraint Formulation for LinSAT", "content": "Given historical data of assets, we aim to build a portfolio whose future Sharpe ratio (Sharpe, 1998) is maximized. Sharpe ratio = risk return-rfrisk , where rf denotes the risk-free return and is assumed to be 3% (annually). Besides the sum-to-one constraint, we consider the extra constraint based on expert preference: among all assets, the proportion of assets in set C should exceed p. This is reasonable as some assets (e.g. tech giants) have higher Sharpe ratios than others in certain time periods. Formally, the constraints are formulated as:\n$\\sum_{i=1}^n x_i = 1, \\sum_{i\\in C} x_i \\ge p$,\nwhere x \u2208 [0, 1]n is the predicted portfolio. The first constraint is the traditional sum-to-one constraint and the second one is the extra preference constraint."}, {"title": "6.3. Network Design Details", "content": "We adopt LSTM (Hochreiter & Schmidhuber, 1997) and StemGNN (Cao et al., 2020) as two variants of portfolio allocation networks for their superiority in learning with time series. Our network has two output branches, one predicts future asset prices and the other predicts the portfolio. LinSAT is applied to the portfolio prediction branch to enforce constraints in Eq. (20). The network receives supervision signals by a weighted sum of maximizing the Sharpe ratio and minimizing the prediction error on future asset prices (based on the historical data in the training set)."}, {"title": "7. Conclusion and Outlook", "content": "We have presented LinSAT, a principled approach to enforce the satisfiability of positive linear constraints for the solution as predicted in one-shot by neural network. The satisfiability layer is built upon an extended Sinkhorn algorithm for multi-set marginals, whose convergence is theoretically characterized. We showcase three applications of LinSAT. Future work may be improving the efficiency of both forward and backward of LinSAT."}, {"title": "A. Comparison with the Notations from Cuturi (2013)", "content": "The formulation used in this paper (regarding \u0393) is an equivalent adaptation from the notations used in existing single-set Sinkhorn papers e.g. Cuturi (2013). As we explained in the footnote in page 3", "algorithm": "n\u2022 This paper's notations:\nThe transportation matrix is \u0393\u2208 [0", "1": "m\u00d7n", "are": "nrepeat:\n$\\Gamma'_{i", "notations": "nThe transportation matrix is P \u2208 Rmn +"}, {"are": "nrepeat:\n$P'_{i,j} = \\frac{P_{i,j}v_i}{\\Sigma_{j=1}^n P_{i,j}}$; \u25b7 normalize w.r.t. v\n$P_{i,j} = \\frac{P'_{i,j}u_j}{\\Sigma_{i=1}^m P'_{i,j}}$; \u25b7 normalize w.r.t. u\nuntil convergence.\nThe equivalence between the above formulations becomes clear if we substitute Pi,j by \u0393i,juj and Pi,j by \u0393i,juj in all the above definitions and algorithm steps. We would like to highlight that such different notations are necessary because making \u0393i,j as the proportion"}]}