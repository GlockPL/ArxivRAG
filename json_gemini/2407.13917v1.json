{"title": "LinSATNet: The Positive Linear Satisfiability Neural Networks", "authors": ["Runzhong Wang", "Yunhao Zhang", "Ziao Guo", "Tianyi Chen", "Xiaokang Yang", "Junchi Yan"], "abstract": "Encoding constraints into neural networks is attractive. This paper studies how to introduce the popular positive linear satisfiability to neural networks. We propose the first differentiable satisfiability layer based on an extension of the classic Sinkhorn algorithm for jointly encoding multiple sets of marginal distributions. We further theoretically characterize the convergence property of the Sinkhorn algorithm for multiple marginals. In contrast to the sequential decision e.g. reinforcement learning-based solvers, we showcase our technique in solving constrained (specifically satisfiability) problems by one-shot neural networks, including i) a neural routing solver learned without supervision of optimal solutions; ii) a partial graph matching network handling graphs with un-matchable outliers on both sides; iii) a predictive network for financial portfolios with continuous constraints. To our knowledge, there exists no one-shot neural solver for these scenarios when they are formulated as satisfiability problems. Source code is available at https://github.com/Thinklab-SJTU/LinSATNet.", "sections": [{"title": "1. Introduction", "content": "It remains open for how to effectively encode the constraints into neural networks for decision-making beyond unconstrained regression and classification. Roughly speaking, we distinguish two categories of such constrained problems: optimization and decision. Optimization problems consider explicit objective functions that are directly related to downstream tasks, whereby their optimization forms are usually more complicated. Decision problems do not consider the objective of the downstream task, or the downstream task may not have any explicit objectives. It is possible that decision problems also have underlying forms, however, their objectives are usually interpreted as \"finding a feasible solution nearest to the input\". In particular, the decision problem can be divided into two cases: i) only judge if there exists a feasible solution or not; ii) output a feasible solution close to an unconstrained input. This paper focuses on the latter case for decision problem, and we term it as satisfiability problem if not otherwise specified.\nNotably, machine learning has been well adopted in solving both optimization and decision problems, especially for combinatorial optimization (CO) (Bengio et al., 2021) and SAT problem (Guo et al., 2023; Li et al., 2023). It is relatively easy to introduce learning into problem-solving as a building block under the traditional solving framework (Wang et al., 2021b;a), yet it is more attractive to develop a learning-based framework in a more systematic manner. In this regard, reinforcement learning (RL) (Liu et al., 2023) or alternative sequence-to-sequence models (Vinyals et al., 2015) that solve the problem in an auto-regressive way is of prominence adoption, while they are often less efficient for their sequential decision nature. Thus efforts have also been put into one-shot problem solving, and a popular alternative is designing certain penalties in the loss (Karalias & Loukas, 2020) to respect the constraints. Being more thought-provoking, a more aggressive ambition is to develop end-to-end differentiable neural networks whereby the constraints are seamlessly encoded in their architecture, such that the efficiency of neural networks for one-shot solving can be fulfilled."}, {"title": "2. Related Work", "content": "Sinkhorn Algorithm (Sinkhorn & Knopp, 1967) projects a positive matrix to a doubly-stochastic matrix by alternatively normalizing its rows and columns, and Cuturi (2013) identifies the connection of Sinkhorn and optimal transport. Its effectiveness also motivates recent theoretical studies concerning its convergence rate (Altschuler et al., 2017; Knight, 2008), whereby Chakrabarty & Khanna (2021) offers a comprehensive theory. Due to its differentiability, Sinkhorn is widely applied in vision (Cruz et al., 2017; Wang et al., 2019b) and learning (Adams & Zemel, 2011; Xie et al., 2020) by enforcing specific constraints. However, as summarized in Table 1, the types of constraints studied in the previous works are less general than the positive linear constraints studied in this paper. Our paper also differs from the existing study of multi-marginal optimal transport (Pass, 2015) since their \u201cmulti-marginal\" means moving one source distribution to multiple targets, while we are moving multiple sources to multiple targets. To distinguish, we name our algorithm as \u201cSinkhorn for multi-set marginals\".\nApproximate Solvers for Positive Linear Programming is also an active topic in theoretical computer science. Despite their solid theoretical groundings, this line of works may not be readily integrated into neural networks. For example, Awerbuch & Khandekar (2008); Allen-Zhu & Orecchia (2014) are non-differentiable because their algorithms involve max operations and thresholding functions, respectively. Young (2001); Luby & Nisan (1993) are neither differentiable due to their incremental steps. Another drawback of these methods is that most of them cannot handle a mix of packing ($\\mathbb{A}x \\leq b$) and covering ($\\mathbb{C}x \\geq d$) constraints except for Young (2001). In this paper, we emphasize differentiability to make it compatible with neural networks, and our method could handle any combinations of packing, covering, and equality constraints.\nDifferentiable Solvers for Constrained Optimization address the problem with objective functions and constraints whereby deep graph matching (Yan et al., 2020; Yu et al., 2020) has been a prominent topic with a quadratic objective. Amos & Kolter (2017) shows the differentiability at optimal solutions via KKT conditions and presents a case study for quadratic programming. Wang et al. (2019a) approximately solves MAXSAT by a differentiable semi-definitive solver. Another line of works develops approximate gradient wrappers for combinatorial solvers: Pogan\u010di\u0107 et al. (2019) estimates the gradient by the difference of two forward passes; Berthet et al. (2020) estimates the gradient via a batch of random perturbations.\nOur approach is devoted to the satisfiability setting whereby no explicit objective function is given for the downstream task (Selsam et al., 2019). Note that this is more than just a mathematical assumption: in reality, many problems cannot be defined with an explicit objective function, either due to e.g. the missing of some key variables in noisy or dynamic environments, especially when the objective concerns with a future outcome as will be shown in case studies on partial graph matching (Sec. 5) and predictive portfolio allocation (Sec. 6). However, existing neural networks for optimization (e.g. Butler & Kwon (2021) for asset allocation) do not adapt smoothly to these realistic scenarios.\nFinally, note that the boolean satisfiability problem (Cook, 1971) also receives attention from machine learning community (Guo et al., 2023), whereby end-to-end neural nets have also been actively developed e.g. NeuroSAT (Selsam et al., 2019) and QuerySAT (Ozolins et al., 2021). As we mentioned in Table 1, the boolean-SAT cannot be covered by our constraint and is orthogonal to this work."}, {"title": "3. Methodology", "content": "Sec. 3.1 formulates the classic Sinkhorn algorithm handling a single set of marginal distributions. Sec. 3.2 proposes the generalized multi-set Sinkhorn with a convergence study. In Sec. 3.3 we devise LinSAT layer to enforce the positive linear constraints, by connecting to the marginal distributions.\nWe first revisit the classic Sinkhorn algorithm in Algorithm 1, which is a differentiable method developed by Sinkhorn & Knopp (1967) to enforce a single set of marginal distributions to a matrix. Given non-negative score matrix $S \\in \\mathbb{R}^{m\\times n}$ and a set of marginal distributions on rows $v \\in \\mathbb{R}^m_{\\geq 0}$ and columns $u \\in \\mathbb{R}^n_{\\geq 0}$ (where $\\sum_{i=1}^m v_i = \\sum_{j=1}^n u_j = h$), the Sinkhorn algorithm outputs a normalized matrix $\\Gamma \\in [0, 1]^{m\\times n}$ so that $\\sum_{j=1}^n \\Gamma_{i,j} u_j = v_i, \\sum_{i=1}^m \\Gamma_{i,j} u_j = u_j$. Conceptually, $\\Gamma_{i,j}$ means the proportion of $u_j$ moved to $v_i$. Note that $\\Gamma_{i,j}$ usually has no same meaning in the \"reversed move\u201d from $v_i$ to $u_j$ if $v_i \\neq u_j$.\nAt iteration t, $\\Gamma^{\\prime(t)}$ is obtained by normalizing w.r.t. the row-distributions $v$, and $\\Gamma^{(t+1)}$ is obtained by normalizing w.r.t the column-distributions $u$. $\\Gamma^{(t)}, \\Gamma^{\\prime(t)} \\in [0, 1]^{m\\times n}$ are"}, {"title": "3.2. Generalizing Sinkhorn Algorithm for Multiple Sets of Marginal Distributions", "content": "Existing literature about the Sinkhorn algorithm mainly focuses on a single set of marginal distributions. In the following, we present our approach that extends the Sinkhorn algorithm into multiple sets of marginal distributions.\nFollowing Cuturi (2013), we view the Sinkhorn algorithm as \u201cmoving masses\u201d between marginal distributions: $\\Gamma_{i,j} \\in [0, 1]$ means the proportion of $u_i$ moved to $v_j$. Interestingly, it yields the same formulation if we simply replace $u, v$ by another set of marginal distributions, suggesting the potential of extending the Sinkhorn algorithm to multiple sets of marginal distributions. To this end, we devise Algorithm 2, an extended version of the Sinkhorn algorithm, whereby $k$ sets of marginal distributions are jointly enforced to fit more complicated real-world scenarios. The sets of marginal distributions are $u_\\eta \\in \\mathbb{R}^n_{\\geq 0}, v_\\eta \\in \\mathbb{R}^m_{\\geq 0}$, and we have:"}, {"title": "Theoretical Characterization of the Convergence of Multi-set Sinkhorn.", "content": "In the following, we show that our proposed Algorithm 2 shares a similar convergence pattern with Algorithm 1 and Theorem 3.1. We generalize the theoretical steps in Chakrabarty & Khanna (2021) as follows.\nWe first study the convergence property of Algorithm 2 in terms of Kullback-Leibler (KL) divergence. In the following, we have $\\eta = (t \\bmod k)+1$ unless otherwise specified. We define the probability over marginals $\\pi_{v_{\\eta, i}} = v_{\\eta, i} / h_\\eta$, and similarly for $\\pi_{u_{\\eta, j}}$, $v^t, u^t$ are the $n$-th marginal distributions achieved by $\\Gamma^{(t)}$ and $\\Gamma^{\\prime(t)}$, respectively."}, {"title": "3.3. LinSAT: Enforcing Positive Linear Satisfiability", "content": "Denote y as an l-length vector that can be the output of any neural network. Our LinSAT develops an satisfiability layer that projects y into $x \\in [0,1]^l$, $\\textrm{LinSAT}(y, A, b, C, D, E, 1 , C, d, E, f) \\rightarrow x$, where $Ax \\leq b, Cx \\geq d, Ex = f$. $x$ is dependent on $y$ (following Eq. (11)) and, in the meantime, lies in the feasible space. We firstly show how to encode $y$ and $x$ by our proposed Algorithm 2.\nEncoding Neural Network's Output. For an l-length vector denoted as y, the following matrix is built"}, {"title": "From Linear Constraints to Marginal Distributions.", "content": "We discuss the connections between positive linear constraints and marginal distributions for $Ax \\leq b, Cx \\geq d, Ex = f$, respectively. For notation's simplicity, here we discuss with only one constraint. Multiple constraints are jointly enforced by multiple sets of marginals.\nPacking constraint $Ax \\leq b$. Assuming that there is only one constraint, we rewrite the constraint as $\\sum_{i=1}^l a_i x_i \\leq b$. The marginal distributions are defined as\nFollowing the \u201ctransportation\u201d view of Sinkhorn (Cuturi, 2013), the output $x$ moves at most $b$ unit of mass from $\\alpha_1, \\alpha_2, ..., \\alpha_l$, and the dummy dimension allows the inequality by moving mass from the dummy dimension. It is also ensured that the sum of $u_p$ equals the sum of $v_p$.\nCovering constraint $Cx \\geq d$. Assuming that there is only one constraint, we rewrite the constraint as $\\sum_{i=1}^l c_i x_i \\geq d$. The marginal distributions are defined as\nwhere the multiplier $\\gamma = \\left[ \\frac{\\sum_{i=1}^l c_i / d}{(\\gamma + 1)d} \\right]$ is necessary because we always have $\\sum_{i=1}^l c_i > d$ (else the constraint is infeasible), and we cannot reach the feasible solution where all elements in $x$ are 1s without this multiplier. This formulation ensures that at least $d$ unit of mass is moved from $c_1, c_2, ..., c_l$ by $x$, thus representing the covering constraint of \"greater than\". It is also ensured that the sum of $u_c$ equals the sum of $v_c$.\nEquality constraint $Ex = f$. Representing the equality constraint is more straightforward. Assuming that there is only one constraint, we rewrite the constraint as $\\sum_{i=1}^l e_i x_i = f$. The marginal distributions are defined as"}, {"title": "Enforcing Multiple Constraints by Sinkhorn.", "content": "The constraints are firstly modulated as multiple sets of marginals and then stacked into $U \\in \\mathbb{R}^{k \\times (l+1)}, V \\in \\mathbb{R}^{k \\times 2}$, where $k$ is the number of constraints. By building $W$ from $y$, getting $S = \\exp(W / \\tau)$ and calling Algorithm 2 based on $S, U, V$, the satisfiability of positive linear constraints is enforced to the output of neural networks.\nImplementation Details. We set separate dummy variables for different constraints to handle potential conflicts among different sets of marginals (see explanations in Appendix D)."}, {"title": "4. Case Study I: Neural Solver for Traveling Salesman Problem with Extra Constraints", "content": "The Traveling Salesman Problem (TSP) is a classic NP-hard problem. The standard TSP aims at finding a cycle visiting all cities with minimal length, and developing neural solvers for TSP receives increasing interest (Vinyals et al., 2015; Kool et al., 2019; Kwon et al., 2021). Beyond standard TSP, here we develop a neural solver for TSP with extra constraints using LinSAT layer.\nWe consider 1) TSP with starting and ending cities constraint (TSP-SE); 2) TSP with priority constraint (TSP-PRI).\nGiven n cities and two of them are the starting and ending cities $s, e \\in \\{1, ..., n\\}$. The distance matrix $D \\in \\mathbb{R}^{n \\times n}$ records the distances between city pairs. TSP-SE finds the shortest tour starting from city s, visiting other cities exactly once, and ending in city e. TSP-SE can be formulated with the following objective function and constraints:"}, {"title": "5. Case Study II: Partial Graph Matching with Outliers on Both Sides", "content": "Standard graph matching (GM) assumes an outlier-free setting namely bijective mapping. One-shot GM neural networks (Wang et al., 2022) effectively enforce the satisfiability of one-to-one matching constraint by single-set Sinkhorn (Algorithm 1). Partial GM refers to the realistic case with outliers on both sides so that only a partial set of nodes are matched. There lacks a principled approach to enforce matching constraints for partial GM. The main challenge for existing GM networks is that they cannot discard outliers because the single-set Sinkhorn is outlier-agnostic and tends to match as many nodes as possible. The only exception is BBGM (Rol\u00ednek et al., 2020) which incorporates a traditional solver that can reject outliers, yet its performance still has room for improvement.\nDenote a graph pair by $\\mathcal{G}_1 = (\\mathcal{V}_1, \\mathcal{E}_1), \\mathcal{G}_2 = (\\mathcal{V}_2, \\mathcal{E}_2)$, where $|\\mathcal{V}_1| = n_1, |\\mathcal{V}_2| = n_2$. In mainstream GM networks, a matching score matrix $M \\in \\mathbb{R}^{n_1 \\times n_2}$ is expected to describe the correspondences of nodes between $\\mathcal{G}_1$ and $\\mathcal{G}_2$, where $M_{i,j}$ refers to the matching score between node $i$ in $\\mathcal{G}_1$ and node $j$ in $\\mathcal{G}_2$. In previous bijective GM networks, the one-to-one node matching constraint that a node corresponds to at most one node is enforced by the off-the-shelf Sinkhorn algorithm in Algorithm 1. It cannot take the outliers into consideration, as it forcibly matches all nodes. The partial GM problem can be formulated by adding a partial matching constraint: assume that the number of inliers is $\\phi$, so the number of matched nodes should not exceed $\\phi$.\nWith a little abuse of notations, denote $X \\in [0,1]^{n_1 \\times n_2}$ as the output of our partial GM network, the partial GM problem has the following constraints,"}, {"title": "5.3. Network Design Details", "content": "We follow the SOTA GM network NGMv2 (Wang et al., 2022) and replace the original Sinkhorn layer with LinSAT to tackle the partial GM problem on natural images. Specifically, a VGG16 (Simonyan & Zisserman, 2014) network is adopted to extract initial node features and global features from different CNN layers. The node features are then refined by SplineConv (Fey et al., 2018). The edge features are produced by the node features and the connectivity of graphs. The matching scores are predicted by the neural graph matching network proposed by Wang et al. (2022), finally generating the matching scores M. We replace the original single-set Sinkhorn layer by LinSAT to enforce the constraints in Eq. (19). The output of LinSAT is reshaped into matrix M, which is used for end-to-end training with permutation loss (Wang et al., 2019b). During inference, the Hungarian algorithm (Kuhn, 1955) is performed on M and we retain the $\\phi$-highest matching scores from M, and the remaining matches are discarded."}, {"title": "5.4. Experiments", "content": "We do experiments on Pascal VOC Keypoint dataset (Everingham et al., 2010) with Berkeley annotations (Bourdev & Malik, 2009) under the \u201cunfiltered\" setting following Rol\u00ednek et al. (2020) and report the matching F1 scores between graph pairs. We assume that the number of inliers $\\phi$ is given (e.g. estimated by another regression model) and focus on the GM networks. As there are no one-shot partial GM networks available, we compare with bijective matching networks: PCA-GM (Wang et al., 2019b) and BBGM (Rol\u00ednek et al., 2020). We also build a partial GM baseline by post-processing retaining only the top-$\\$\\phi$ matches. Table 3 shows that our method performs the best. Note that BBGM (matching type=bijective) is an example of applying black-box solvers to an ill-posed optimization problem because the objective function does not consider the outliers, leading to inferior performance."}, {"title": "6. Case Study III: Portfolio Allocation", "content": "Predictive portfolio allocation is the process of selecting the best asset allocation based on predictions of future financial markets. The goal is to design an allocation plan to best trade-off between the return and the potential risk (i.e. the volatility). In an allocation plan, each asset is assigned a non-negative weight and all weights should sum to 1. Existing learning-based methods (Zhang et al., 2020; Butler & Kwon, 2021) only consider the sum-to-one constraint without introducing personal preference or expert knowledge. In contrast, we achieve such flexibility for the target portfolio via positive linear constraints: a mix of covering and equality constraints, which is widely considered (Sharpe, 1971; Mansini et al., 2014) for its real-world demand."}, {"title": "6.2. Constraint Formulation for LinSAT", "content": "Given historical data of assets, we aim to build a portfolio whose future Sharpe ratio (Sharpe, 1998) is maximized. $\\textrm{Sharpe ratio} = \\frac{\\textrm{risk}}{\\textrm{return}-r_f}$, where $r_f$ denotes the risk-free return and is assumed to be 3% (annually). Besides the sum-to-one constraint, we consider the extra constraint based on expert preference: among all assets, the proportion of assets in set $\\mathcal{C}$ should exceed $p$. This is reasonable as some assets (e.g. tech giants) have higher Sharpe ratios than others in certain time periods. Formally, the constraints are formulated as:"}, {"title": "6.3. Network Design Details", "content": "We adopt LSTM (Hochreiter & Schmidhuber, 1997) and StemGNN (Cao et al., 2020) as two variants of portfolio allocation networks for their superiority in learning with time series. Our network has two output branches, one predicts future asset prices and the other predicts the portfolio. LinSAT is applied to the portfolio prediction branch to enforce constraints in Eq. (20). The network receives supervision signals by a weighted sum of maximizing the Sharpe ratio and minimizing the prediction error on future asset prices (based on the historical data in the training set)."}, {"title": "6.4. Experiments", "content": "We consider the portfolio allocation problem where the network is given the historical data in the previous 120 trading days, and the goal is to build a portfolio with maximized Sharpe ratio for the next 120 trading days. The training set is built on the real prices of 494 assets from the S&P 500 index from 2018-01-01 to 2020-12-30, and the models are tested on real-world data from 2021-03-01 to 2021-12-30. Without loss of generality, we impose the expert preference that in the period of interest, the following tech giants' stocks could be more profitable: $\\mathcal{C}$ = {AAPL, MSFT, AMZN, TSLA, GOOGL, GOOG}, and the preference ratio is set to $p = 50$%. \nWe build two baselines: 1) A neural network portfolio allocator without preference, and the sum-to-one constraint is enforced by softmax following Zhang et al. (2020); 2) A two-stage allocator that first predicts future prices and then uses Gurobi (Gurobi Optimization, 2020) to solve a constrained optimization problem whose objective function is based on the predicted prices. See results in Table 4. Compared with an allocator without preference, the expert preference information improves the performance; Compared with the two-stage allocator, our allocator reduces the issue of error accumulation and builds better portfolios. Note that the objective function in the two-stage allocator is ill-posed because the first-stage prediction unavoidably contains errors."}, {"title": "7. Conclusion and Outlook", "content": "We have presented LinSAT, a principled approach to enforce the satisfiability of positive linear constraints for the solution as predicted in one-shot by neural network. The satisfiability layer is built upon an extended Sinkhorn algorithm for multi-set marginals, whose convergence is theoretically characterized. We showcase three applications of LinSAT. Future work may be improving the efficiency of both forward and backward of LinSAT."}, {"title": "A. Comparison with the Notations from Cuturi (2013)", "content": "The formulation used in this paper (regarding $\\Gamma$) is an equivalent adaptation from the notations used in existing single-set Sinkhorn papers e.g. Cuturi (2013). As we explained in the footnote in page 3, this new formulation is preferred as we are generalizing the scope of Sinkhorn to multi-set marginal, and the existing formulation cannot seamlessly handle marginals with different values.\nSpecifically, we make a side-by-side comparison with the notations used in this paper and the notations used in Cuturi (2013) on single-set Sinkhorn algorithm:\n\u2022 This paper's notations:\nThe transportation matrix is $\\Gamma\\in [0, 1]^{m\\times n}$, and the constraints are"}, {"title": "B. Proof of Theorem 3.2.", "content": "To prove the upper bound of convergence rate, we define the Kullback-Leibler (KL) divergence for matrices $Z$ and $\\Gamma$, whereby the KL divergence is originally defined for probability vectors,"}, {"title": "C. Further Discussions with the Entropic Regularizer", "content": "In the main paper, we write our algorithms after the regularization term for simplicity. On one hand, the entropic regularizer may be omitted if the score matrix is non-negative (e.g. activated by ReLU). On the other hand, our theoretical insights could naturally generalize with the regularizer. We provide the detailed discussions as follows."}, {"title": "C.1. The Underlying Formulation of Algorithm 2", "content": "Recall that given real-valued matrix $W \\in \\mathbb{R}^{m\\times n}$, regularizer $\\tau$, and a set of target marginals $u_\\eta \\in \\mathbb{R}^n_{\\geq 0}, v_\\eta \\in \\mathbb{R}^m_{\\geq 0}$, our multi-set marginal Sinkhorn algorithm maps $W$ to $\\Gamma\\in [0,1]^{m\\times n}$ such that $\\forall \\eta \\in \\{1,...,k\\} : \\sum_{i=1}^m \\Gamma_{i,j} u_{\\eta, j} = u_{\\eta, j}, \\sum_{j=1}^n \\Gamma_{i,j} u_{\\eta, j} = v_{\\eta, i}$. In the following, we discuss the underlying formulation for a special (but general enough) case, when the values of $u_{\\eta, j}$ are binary.\nFormally, if $u_{\\eta, j}$ is binary, i.e. either $u_{\\eta, j} = 0$ or $u_{\\eta, j} = c$ for all $\\eta, j$, the following entropic regularized problem is considered:"}, {"title": "C.2. The Algorithm with Entropic Regularizer", "content": "Algorithm 3 Sinkhorn for Multi-Set Marginals with Entropic Regularizer"}, {"title": "C.3. Theoretical Results with Entropic Regularizer", "content": "If the entropic regularizer is involved, the converging rate of multi-set Sinkhorn w.r.t. $L_1$ error becomes:"}, {"title": "C.4. Empirical Further Study of the Entropic Regularizer", "content": "Our LinSAT can naturally handle continuous constraints. For continuous optimization problems (e.g. portfolio allocation) the output can be directly used as the feasible solution. When it comes to problems requiring discrete decision variables, we show in the following study that our LinSAT still owns the ability to encode the constraints by adjusting $\\tau$."}, {"title": "D. The Feasibility Assumption Explained", "content": "For multi-set Sinkhorn, an assumption is made in Eq. (6) that the marginal distributions must have a non-empty feasible region. We explain this assumption with an example derived from positive linear constraints.\nAs shown in Section 3.3, every set of positive linear constraints could be equivalently viewed as a set of Sinkhorn marginals.\nIf we transform the positive linear constraints to Sinkhorn's marginals:"}, {"title": "E. Details of Case Study I: Neural Solver for Traveling Salesman Problem with Extra Constraints", "content": "In both TSP-SE and TSP-PRI, we use a 3-layer Transformer to encode the 2-D coordinates into hidden vectors. Then the hidden vectors are projected into the pre-projected matrix using a 3-layer MLP with ReLU activation. Dimensions of hidden states for both the Transformer and the MLP are set to 256, and the head number of multi-head attention in the Transformer is set to 8.\nWe train the model for 100 epochs for both TSP-SE and TSP-PRI. In each epoch, we randomly generate 256,000 instances as the training set of this epoch. The batch size is set to 1,024. Adam optimizer is used for training and the learning rate is set to 1e-4.\nDuring inference, we use beam search to post-process the continuous matrix X output by the network to get the binary matrix $\\mathcal{X}$. The width of the beam for beam search is set to 2,048.\nOur model runs on a single NVIDIA GeForce RTX 2080Ti GPU with 11GB memory."}, {"title": "E.2. Baseline Methods", "content": "MIP MIP methods directly use Gurobi to solve the formulation in Sec.4.2, e.g. an integer programming problem with linear constraints and quadratic objective. The time limit per instance is set to 2s/20s.\nNearest Neighbor Nearest Neighbor is a greedy heuristic for TSP. For TSP-SE, in each iteration, the nearest node (except the ending node) to the starting node is selected as the next node to visit. Then the selected node becomes the new starting node in the next iteration. After all nodes except the ending node are visited, the tour directly connects to the ending node.\nFor TSP-PRI, in the m-th iteration, if the priority node has not been visited, the priority node will be selected as the next node to satisfy the priority constraint.\nInsertion Heuristic Insertion Heuristic first uses the starting and ending nodes to construct a partial tour. In each iteration, a new node is selected and inserted to the partial tour to extend it. For a selected node, it is inserted in the position where the tour length increase is minimized. Formally, we use $\\mathcal{T} = \\{\\pi_1, \\pi_2, ..., \\pi_m\\}$ to denote a partial tour with $m(m < n)$ nodes. Assuming the selected new node is $u^*$, then it is inserted behind the $i^*$-th node in the partial tour:\nAccording to the different new node selection processes, there are different variants of insertion heuristic:\nNearest Insertion selects the nearest node to the partial tour:\nFarthest Insertion selects the farthest node from any node in the partial tour:\nRandom Insertion randomly selects the new node to insert.\nTo satisfy the priority constraint of TSP-PRI, if the priority node is already the ($m + 1)$-th node in the partial tour, we can not insert new nodes in front of it.\nStandard Solver TSP-SE can be converted to standard TSP by adding a dummy node. The distance from the dummy node to starting and ending nodes is 0 and the distance to other nodes is infinity. Then we can use start-of-the-art methods for standard TSP, i.e. Gurobi(MTZ)/Concrode/LKH3, to solve TSP-SE.\nHowever, converting TSP-PRI to standard TSP is non-trivial, making it hard to use standard solvers to solve TSP-PRI.\nAttention Model Attention Model (Kool et al., 2019) is an RL-based autoregressive model for standard TSP. We modify its decoding process so that it can solve TSP-SE and TSP-PRI. Because TSP-SE ends in the ending node instead of constructing a circle, we use the ending node embedding to replace the first node embedding in the original paper during decoding. For TSP-PRI, if the priority node has not been visited within the first $m$ - 1 steps, it will be visited in the m-th step. The training process and hyper-parameters are the same as our model in Sec. E.1."}, {"title": "E.3. Further Ablation Study", "content": "In the following study, we show that LinSAT can normalize matrices outside a neural network. The study involves two variants of our TSP solver presented in Section 4: 1) Random Pre-Projected Matrix: Apply our LinSAT to a randomly generated matrix and do beam search over it; 2) Trainable Pre-Projected Matrix: Randomly initialize the pre-projected matrix, view the matrix as trainable parameters and use the same training process as in the main paper to optimize it. Transformer Feature Matrix is our TSP solver in Section 4.\nThe average tour length and total inference time are shown in Table 7. The Random Pre-Projected Matrix cannot provide useful guidance to beam search, thus its performance is poor. Trainable Pre-Projected Matrix performs better, but it is easy to stick at local optima without global features extracted by the neural network. Moreover, updating the pre-projected matrix requires multiple forward and backward passes of LinSAT, making this method much more time-consuming.\nThis ablation study proves the feasibility of LinSAT working outside a neural network, while it also shows the necessity of neural networks to get high-quality solutions in an efficient time."}, {"title": "F. Experiment Testbed", "content": "All our experiments are run on our workstation with Intel(R) Core(TM) i7-7820X CPU, NVIDIA GeForce RTX 2080Ti GPU, and 11GB memory."}, {"title": "G. Study of Time Costs", "content": "In our case studies, LinSAT has higher time costs than neural networks, which is in our expectation because the cost of one Sinkhorn iteration could be roughly viewed as one layer of neural network from the unfolding perspective. The complexity of neural networks in our case studies is relatively low, since too many layers may cause the over-smoothing issue, and designing new networks is beyond the scope of this paper. We summarize the proportion of inference time in all 3 case studies in Tables 8 to 10.\nBesides, we compare the timing statistics of LinSAT with another regularized projection method \u2013 the differentiable CVXPY layers (Agrawal et al., 2019). Specifically, we conduct a case study of transforming a random matrix into a doubly-stochastic matrix. Both methods achieve doubly-stochastic matrices, and the timing statistics are in Table 11. LinSAT is more efficient in this case studyContinue where u left off generating the json\n. Extra speed-up may be achieved when the input scales up and switching LinSAT to GPU (CVXPY is CPU-only)."}]}