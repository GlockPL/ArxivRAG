{"title": "Watermarking Techniques for Large Language Models: A Survey", "authors": ["Yuqing Liangl", "Jiancheng Xiaola", "Wensheng Gan", "Philip S. Yu"], "abstract": "With the rapid advancement and extensive application of artificial intelligence technology, large language models (LLMs) are extensively used to enhance production, creativity, learning, and work efficiency across various domains. However, the abuse of LLMs also poses potential harm to human society, such as intellectual property rights issues, academic misconduct, false content, and hallucinations. Relevant research has proposed the use of LLM watermarking to achieve IP protection for LLMs and traceability of multimedia data output by LLMs. To our knowledge, this is the first thorough review that investigates and analyzes LLM watermarking technology in detail. This review begins by recounting the history of traditional watermarking technology, then analyzes the current state of LLM watermarking research, and thoroughly examines the inheritance and relevance of these techniques. By analyzing their inheritance and relevance, this review can provide research with ideas for applying traditional digital watermarking techniques to LLM watermarking, to promote the cross-integration and innovation of watermarking technology. In addition, this review examines the pros and cons of LLM watermarking. Considering the current multimodal development trend of LLMs, it provides a detailed analysis of emerging multimodal LLM watermarking, such as visual and audio data, to offer more reference ideas for relevant research. This review delves into the challenges and future prospects of current watermarking technologies, offering valuable insights for future LLM watermarking research and applications.", "sections": [{"title": "1. Introduction", "content": "With the emergence of GPT-3.5 [170] in late 2022, its outstanding capabilities have attracted worldwide attention. Numerous large language models (LLMs) [279] with diverse functionalities have also been continuously developed and are being widely applied in various aspects of people's lives and production. So far, due to the abilities of model-as-a-service [83], LLMs have achieved preliminary intelligent applications in fields such as education [82, 114, 254], scientific research [17, 210], healthcare [221, 285], programming [40, 253], law [54, 124], and robotics [271], demonstrating remarkable performance that can efficiently assist or even replace some human tasks. Compared to traditional data mining [80, 81], natural language processing (NLP) [47, 162], and AI systems [157, 247], LLMs have exhibited unprecedented capabilities enhancements. In the future, LLMs may become as ubiquitous in human society as smart computers and smartphones [121], and may even be deployed on every intelligent device. Besides, we should also be aware of the potential negative impacts and risks of LLMs [238]. 1) LLMs may be misused, such as for automated hacking attacks [238] or fraud bots [240]. 2) The high training cost of LLMs means that their leakage could lead to significant profits for competitors. 3) LLMs can cause data pollution and be used to create inappropriate content, including pornography or extremist content [6]. 4) LLMs can potentially leak user personal information or sensitive data during data processing [143]. 5) LLMs may lead to serious academic and intellectual property (IP) disputes, as the vast datasets used for their training may contain unauthorized data or infringe on IP rights, and the content generated by the models may also violate copyrights [173]. 6) The content generated by LLMs may involve academic misconduct [240], as the models have learned a large amount of online data during training, and their generated text may be highly similar or even identical to existing online content. To address the potential issues of LLMs, some research suggests that reviewing the data generated by these models could be a solution. However, in practice, this may raise more problems: 1) reviewing the generated data could significantly reduce the reaction speed of LLMs, affecting their efficiency, especially in time-sensitive scenarios; 2) it is difficult to establish relevant review standards, and this may overly restrict the creative freedom of LLMs; 3) the further introduction of review procedures or review agencies may lead to even more serious privacy data leakage [123]; 4) the cost of the review process may lead to further increases in the costs of LLMs companies; 5) the high cost and relatively low efficiency of reviewing each generated data item, with only a small portion being used for malicious purposes. Compared to reviewing the data generated by LLMs [35], a feasible solution is to trace the source of the different forms of data (including text, images, videos, and sound) generated by each LLM. Through data tracing, the potential problems of LLMs can be effectively solved. We can trace the source of single or multiple data items generated by LLMs to identify the specific model that generated the data. Data tracing can effectively detect and quickly block auto-mated hacking attacks and fraud bots, prevent the illegal use of LLMs by other companies, and find the source of privacy data leaks, quickly locating and repairing the problematic prompts that led to the generation of harmful information. The challenge is how to implement the data tracing of LLMs. In the past, digital watermarking [50] has been a common approach. A digital watermark is subtly integrated into conventional multimedia content that needs to be traced, with the watermark carrier including text, images, audio, video, documents, web pages, databases, and more. Digital watermarking can be used to achieve data tracing, digital rights authentication, and integrity verification. Research suggests using watermarking to safeguard the intellectual property of LLMs, to enable tracking or identification of the multimedia information generated by these models, and to prevent their misuse.\nLLM watermarking can be divided into three categories based on functionality: 1) Data traceability function [136], which can efficiently detect the ownership of the invoked LLMs when the LLMs are used for illegal purposes; 2) Copyright protection function [111], which is used to realize the copyright recognition of multimedia data generated by LLMs; 3) Function to identify content generated by LLMs, i.e., to identify whether the content is generated by LLMs [79]. From the perspective of modality, it can be divided into four categories: 1) Text domain data [233, 239]: The text is the most common multimedia generation data in current LLMs, and is also the most common watermark embedding carrier in this research field; 2) Image domain data [241, 274]: Images are common multimedia data in current LLMs, mainly manifested in text-to-image in AI-generated content (AIGC) [245]; 3) Video domain data: Except for the untested Sora, there are currently no stable and efficient video-generating LLMs, and there are no watermarks for video domain LLMs; 4) Audio domain data [38, 44]: Audio LLMs are mainly focused on functions such as speech generation and music production. In the current research, the main problems encountered by LLM watermarking are as follows: 1) Watermark robustness problem: The current LLM watermarks are focused on text watermarks, and difficult to solve problems such as text clipping and paraphrasing attacks. 2) Semantic invariance problem: Embedding watermarks in text data may affect its semantics, affecting the model's answer effectiveness or making the text watermark less imperceptible, and may also lead to semantic shifts in generated multimedia data such as images/videos/audios. 3) Security vulnerability problem: LLM watermarking may require access to the inner structure and settings of the LLMs, which may pose security risks. 4) System consumption problem: LLM watermarking may lead to increased model system power consumption and computational complexity, thereby increasing model running costs.\nResearch gaps: Currently, there are many studies related to LLMs or watermarking, and details are summarized in Table 1. Boenisch et al. [20] proposed an LLM watermarking classification framework to identify and analyze different types of LLM watermarking schemes, and introduced a unified LLM watermarking threat model for systematic analysis and evaluation of watermarking methods' effectiveness across different scenarios. It also introduced the security requirements for LLM watermarking and the types of attacks against them and conducted a survey and classification of the relevant literature based on this framework. Finally, it discussed the shortcomings and limitations of existing LLM watermarking methods and looked forward to future research directions of LLM watermarking. Liu et al. [139] discussed the role of text watermarking technology in the age of LLMs. Text watermarking technology is crucial for protecting the intellectual property rights of text material, mainly by inserting imperceptible watermark information within the text material to achieve copyright protection. With the development of LLMs technology, text watermarking technology has made significant progress in both technology and application scenarios (i.e., application in LLMs). It introduces in detail the definition, key attributes, classification, and evaluation indicators of LLM watermarking techniques, covering success rate, robustness, text quality, and resistance to forgery, explores the use of LLM watermarking in practical application scenarios, and emphasizes the ethical application of AI technology in LLMs. Hwang et al. [104] introduce the adoption of watermarking technology in generative AI. The research discusses the significant potential of generative AI in text and image generation while highlighting the challenges that accompany advancements in AI technology, such as AI misuse and the creation of misinformation. This research states that various countries and regions are considering or have already implemented relevant AI regulations, using watermarking technology to identify AIGC [245]. It also analyzes how leading tech companies incorporate watermarking technology into their AI generation services, focusing on LLM watermarking technology and related laws and regulations. To summarize, we can observe the following limitations in the above reviews about LLM watermarking research: 1) Focusing mainly on LLMs text watermarking, lacking watermarking of other modalities, and lacking integration with the current development trends of LLMs; 2) Lacking consideration of technological inheritance, lacking analysis and discussion of traditional digital watermarking, not comparing current LLM watermarking with traditional digital watermarking, and not analyzing what current LLM watermarking can learn from traditional digital watermarking [29].\nContributions: The differences between this review and the existing studies are: 1) Not only exploring LLM watermarking, but also innovatively combining the current multi-modal trend of LLMs, and conducting a detailed analysis of the watermarking of emerging multi-modal LLMs such as image/audio; 2) Conducting a relatively detailed analysis of traditional digital watermarking and LLM watermarking technology, exploring the technological inheritance between LLM watermarking and traditional watermarking; 3) Analyzing in detail the distinctions between traditional digital watermarking and watermarking for LLMs in the same modality or the same application scenario. To fill these gaps, we provide a comprehensive investigation and analysis of LLM watermarking technology in detail. In summary, the main contributions of this review are as follows:\n\u2022 Comprehensive analysis of the research status of watermarking for LLMs: This review offers an in-depth examination of the background, and current status, along with the technical development in watermarking research for LLMs, offering a comprehensive analysis and overview of this field.\n\u2022 Innovative analysis incorporating multimodal trends: This review incorporates the current multimodal development trends of LLMs, and provides a detailed analysis of watermarking for emerging multimodal LLMs, such as those for images and audio. This helps us understand the technologies and development of watermarking for multimodal LLMs, in line with the technological trends.\n\u2022 In-depth analysis of the relationship between traditional digital watermarking and watermarking for LLMs: Based on a detailed analysis of traditional digital watermarking, this review systematically analyzes and discusses the watermarking technologies for LLMs, delving into and analyzing the technical inheritance between them.\n\u2022 Analysis of challenges and future development directions: This review provides a thorough examination of the challenges facing watermarking for LLMs and their future development directions, and proposes some corresponding solutions.\n\u2022 Potential impact and significance: This review helps to understand the development trajectory of digital watermarking technology and watermarking for LLMs, and to apply traditional digital watermarking technology to related LLM watermarking, enabling effective utilization of the technical achievements of traditional digital watermarking research."}, {"title": "2. Relevant Background", "content": "2.1. Background of LLMs\nLLMs refer to machine learning models with large-scale parameters and complex computational structures. LLMs are mainly built on deep neural networks (DNN) [214] and usually have a huge number of parameters. The main difference between LLMs and traditional small models lies in the number of parameters [258]. Small models [198] usually refer to models with fewer neural network parameters, fewer layers, and smaller models. The advantage of small models is that they are small and suitable for scenarios with relatively small computational resources and data volume, and can be used for various lightweight applications such as embedded devices, IoT devices, connected vehicles, and mobile devices. LLMs typically have hundreds of billions or even trillions of parameters, which is a feature of having a huge number of parameters compared to general DNN.\nFrom the perspective of the model scale, LLMs have experienced three stages [91, 272]: pre-trained models, large pre-trained models, and super pre-trained models. The parameter scale increases at least tenfold per year, from hundreds of millions to tens of billions. LLMs with parameter scales in the hundreds of billions have become mainstream. As the training data, network parameters, and network layers of the model constantly expand, until a certain critical point is broken, the model will exhibit more complex and powerful capabilities, able to learn deeper features from the training data. This phenomenon is called an emergent phenomenon. Currently, AI models with emergent phenomena are considered LLMs, which is one of the main differences between large models and small models [238]. The development of LLMs can be categorized into three stages: the germination period, the precipitation period, and the explosion period.\nFrom 1950 to 2005 was the germination period of the AI model. This period was represented by the convNet (CNN) [252], signifying the emergence and evolution of traditional neural network models. In 1956, computer expert John McCarthy first proposed the notion of \"artificial intelligence\" (AI), initiating research in the AI field. In subsequent development, AI gradually evolved from the initial stage based on small-scale expert knowledge to the stage based on machine learning. In 1980, CNN provided an important tool for research in computer vision (CV) [230] and NLP. In 1998, the basic structure of modern CNN, LeNet-5 [127], was born, marking the transformation of machine learning methods from early models based on shallow machine learning to models based on deep learning. This stage laid the relevant mathematical foundations for the development of deep learning frameworks and LLMs, and had a far-reaching impact on research in CV and NLP.\nFrom 2006 to 2018 was the precipitation period of LLMs, during which the brand-new neural network model represented by Transformer began to emerge. In 2013, the well-known Word2Vec [153] was introduced, proposing the \"word vector model\" that converts words into vectors for the first time, providing a foundation for AI to better understand and process text data. In 2014, the generative adversarial network (GAN) [88] was proposed, marking the entry of deep learning into a new stage of generative model research. In 2017, Google introduced the Transformer architecture [227] using a self-attention mechanism, establishing the basis for pre-training large models. In 2018, OpenAI and Google successively launched large pre-trained models like GPT-1 [182] and BERT [61], making pre-trained LLMs the mainstream in NLP. During the precipitation period, the brand new neural network architecture represented by Transformer laid a solid foundation for the development of large models, greatly improving the performance of LLMs.\nFrom 2019 to the present, the explosion period of LLMs. OpenAI improved based on GPT-1 and released the GPT-2 model [183]. In 2020, OpenAI unveiled GPT-3 [26] featuring 175 billion parameters. In 2022, OpenAI released the groundbreaking ChatGPT (GPT-3.5) [170], triggering a new round of LLMs fever. 2022 was called the year of the element of LLMs, with Google releasing the PaLM [48] and Microsoft releasing the BEIT-3 [235], marking the arrival of the era of multimodal LLMs [246]. In 2023, OpenAI released the more powerful GPT-4.0 [5] with support for multimodality and file reading; Google released PaLM2 [11] and LaMDA [222]; Meta released the LLaMA [223] and LLaMA2 [223]; Microsoft released the ChatGPT-supported Bing search engine. In 2024, OpenAI released the Sora [177], which performed well in long-term video generation, and has excellent visual and multi-modal capabilities [71]. LLMs have penetrated various areas of daily life and become essential elements of everyday existence.\nIn terms of technical architecture, the Transformer architecture is the mainstream algorithmic foundation. Therefore, two main technical routes of GPT and BERT have formed [42]. Currently, GPT has gradually become the mainstream route of LLMs, and the vast majority of LLMs with parameters exceeding hundreds of billions adopt the GPT pattern. From the perspective of modality, LLMs can cover text, images, videos, audio, and other modalities. The modalities supported by LLMs are becoming more diversified, from unimodal to multimodal [246], so that LLMs can better perceive the world and learn various knowledge. From the perspective of task completion, LLMs can complete more and more tasks, from machine translation to article writing, from code writing to scientific computing, LLMs can efficiently complete various types of tasks. In terms of application areas, LLMs can be divided into general-purpose [42] and industry-specific (expert) [236] types. General-purpose models have strong generalization capabilities and can complete tasks in various scenarios, including ChatGPT and BERT. Industry-specific (expert) models are fine-tuned based on industry knowledge to meet the needs of specific fields, such as BloombergGPT [248] for finance and Med-PaLM [202] for medicine.\n2.2. Background of Digital Watermarking\nDigital watermarking [50] is a method of embedding specific information into digital signals to verify the integrity and originality of digital material. The development of digital watermarking dates back to the mid-20th century. In 1954, the American firm Muzac filed a patent for \"identification of sound and lide signals\", which outlined a technique for embedding an imperceptible identification code into music to verify ownership. This is the earliest known digital watermarking technology. In 1994, Tirkel et al. [226] formally introduced the idea of digital watermarking, but the proposed watermarking was implemented in the least significant bits of grayscale images, with relatively poor robustness. Since 1994, digital watermarking has shown importance in information security and economics. It has received active participation and investment support from research institutions, universities, and business groups around the world. In addition, companies such as IBM, Hitachi, NEC, Pioneer Electronics, and Sony have also announced joint research on electronic watermarking based on information hiding. In 1995, text digital watermarking [25] was introduced, and Macq et al. [151] initiated research on video watermarking. In 1996, Cox et al. [226] introduced a digital watermarking method utilizing spread-spectrum communication, which improved the digital watermarking scheme's robustness. Cox et al. [51] embedded the watermark information in the DCT domain to enhance the watermark's robustness, but their watermark algorithm was a non-blind watermark extraction technique. It required the participation of the original image for watermark extraction, which restricted the application.\nThe international academic community has also published a large number of articles on digital watermarking and held many influential international conferences and special journals. For example, in 1998, a special session on digital watermarking was established by the International Conference on Image Processing (ICIP). In 1999, at the third international workshop on information hiding, 18 out of 33 works focused on digital watermarking research. Venkatesan et al. [228] introduced a technique for blind watermarking capable of extracting the watermark without the original image. In the late 1990s, some companies began to formally sell digital watermarking products. For example, the American company Digimarc was the first to launch a commercial digital watermarking software and integrated it into Adobe's Photoshop and Corel Draw image processing software. As a security product designed for printed documents, AlpVision's Safe Work is capable of hiding watermark information on the back of the document to verify its authenticity and identify its ownership. In 2002, the National Strategy for Securing Cyberspace, which focused on the use of digital watermarking, was released by the U.S. Department of Homeland Security. Today, digital watermarking has emerged as a crucial tool for protecting the IP rights of multimedia data and has become an indispensable part of the Internet. The functions of current digital watermarking are constantly expanding, from initial copyright protection to data integrity verification, data content authentication, data tampering detection and tracing, and data traceability.\n2.3. LLM Watermarking\nLLM watermarking [49, 116] and traditional digital watermarking have similarities and differences. Simply put, their similarity lies in the fact that LLM watermarking and digital watermarking serve similar functions, both achieving the purpose of copyright protection and ownership identification through embedding specific identifiers. The difference is that LLM watermarking is more similar to traditional neural network watermarking, while it differs greatly from traditional digital watermarking algorithms. The development of LLM watermarking is relatively recent. With the emergence of LLMs that have shown powerful generation and understanding capabilities, becoming a prominent research area in AI, research on LLM watermarking has gradually emerged. Because of the exceptionally high costs associated with training and deploying LLMs, safeguarding the IP rights of LLMs has become especially crucial, which has sparked research interest in LLM watermarking research. In 2023, Kirchenbauer et al. [116] proposed an LLMs text watermarking approach that uses red-green token patterns to achieve embedding and detection of LLM watermarks. This innovation laid the foundation for the development of LLM watermarking and inspired academic and industrial interest in this research area.\nLLM watermarking is similar to traditional neural network watermarking, mainly by embedding specific patterns or structures during the model training process and modifying model parameters or structures, so that the generated content or the model itself carries hidden identity information. This method can not only embed text watermarks, but can also be extended to image, video, and audio data. For example, LLM-based image watermarking can embed imperceptible watermark information in the generated images, LLM video watermarking can embed imperceptible watermark information in specific frames of the generated videos, and LLMs audio watermarking can embed watermark information that is inaudible to humans in the generated audio. These approaches seek to safeguard the models' IP and prevent unauthorized use and alterations. Currently, research has proposed LLM watermarking methods for images [241], audio [44], and multimodal settings [217].\nAs LLMs continue to develop, LLM watermarking has become a research hotspot to safeguard the IP of LLMs and prevent their misuse for unlawful activities. The research and application of LLM watermarking are rapidly evolving and have emerged as a key focus area in LLMs research. As the application of LLMs becomes increasingly widespread in various fields, protecting the IP of these LLMs has become increasingly important. LLM watermarking can not only be used for copyright protection but also for marking multimedia data generated by LLMs, preventing malicious tampering and forgery using LLMs. For example, in news and social networks, watermarking technology can ensure the source and authenticity of content, quickly identify false content generated by LLMs, and prevent the spread of false information generated by LLMs. However, the research on LLM watermarking also faces many problems and challenges [20], such as how to improve the robustness and undetectability of LLM watermarks, how to embed watermarks without affecting the performance of LLMs, and how to improve the embedding speed of LLM watermarks to reduce interaction latency with LLMs. These are important issues that need to be solved for the development of LLM watermarking."}, {"title": "3. Traditional Digital Watermarking Techniques", "content": "3.1. Watermark Properties\n3.1.1. Embedding Capacity-based Classification\nEmbedding capacity-based classification: Zero watermarking [186", "152": ".", "186": "was proposed", "perceptibility": "visible and invisible watermarks [52", "59": ".", "193": "such as the human visual system is more responsive to low-frequency information", "262": ".", "images": 1, "175": "has proposed various improvements to the LSB algorithm to improve its robustness. 2). Transform domain invisible watermarking [46", "195": "is a discrete version of the Fourier transform", "30": ".", "32": "introduced an enhanced watermarking algorithm based on the DFT that employs the particle swarm optimization (PSO) algorithm [232", "267": "is a specific instance of the discrete Fourier transform", "211": ".", "energy compaction\" characteristic, which ensures that most of the signal energy is concentrated in its low-frequency components. This property is beneficial for lossy compression of signals and images. The classic applications of DCT include the still image coding standard JPEG, the video coding standards MJPEG and MPEG, as well as some audio coding techniques. Several invisible watermarking techniques [7": "based on DCT have also been proposed", "46": "proposed a method for invisible digital watermarking utilizing the DCT transform and image permutation. It incorporates the watermark information by swapping the classical coefficients at specific positions (e.g.", "176": "is a type of wavelet transform where the wavelets are sampled discretely [199"}, {"176": "developed an invisible digital image watermark utilizing DWT", "steps": "embedding and extraction. The watermark embedding process is invertible", "156": "can embed and extract color image watermarks in digital images", "276": ".", "categories": "white-box", "types": 1, "weights": "The parameters representing the connection strength between neurons in a neural network model are called weights. Weight-box watermarking involves inserting a watermark by altering the internal neural network parameters of the target model. Lim et al. [134", "89": "to safeguard an image captioning model. They proposed two embedding operations: Element-wise addition and multiplication to integrate the key into the hidden state of the LSTM unit. Kuribayashi et al. [122", "structure": "Structural-based white-box watermarking embeds the watermark by altering the internal architecture of the target neural network model. The white-box watermark is easy to discover or remove, causing the watermark to become invalid. To effectively resist such removal attacks, it is common to use neural"}]}