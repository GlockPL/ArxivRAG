{"title": "Open-Vocabulary Object Detection via Language Hierarchy", "authors": ["Jiaxing Huang", "Jingyi Zhang", "Kai Jiang", "Shijian Lu"], "abstract": "Recent studies on generalizable object detection have attracted increasing attention with additional weak supervision from large-scale datasets with image-level labels. However, weakly-supervised detection learning often suffers from image-to-box label mismatch, i.e., image-level labels do not convey precise object information. We design Language Hierarchical Self-training (LHST) that introduces language hierarchy into weakly-supervised detector training for learning more generalizable detectors. LHST expands the image-level labels with language hierarchy and enables co-regularization between the expanded labels and self-training. Specifically, the expanded labels regularize self-training by providing richer supervision and mitigating the image-to-box label mismatch, while self-training allows assessing and selecting the expanded labels according to the predicted reliability. In addition, we design language hierarchical prompt generation that introduces language hierarchy into prompt generation which helps bridge the vocabulary gaps between training and testing. Extensive experiments show that the proposed techniques achieve superior generalization performance consistently across 14 widely studied object detection datasets.", "sections": [{"title": "1 Introduction", "content": "Object detection aims to locate and identify objects in images by providing basic visual information of \"where and what objects are\". Thanks to the recent advances of deep neural networks, it has achieved great success with various applications in autonomous driving [1, 2, 3, 4], intelligent surveillance [5, 6, 7, 8], wildlife tracking [9, 10, 11], etc. However, learning a generalizable object detector for various downstream tasks that have different data distributions and data vocabularies remains an open research challenge. To this end, weakly-supervised object detection (WSOD) [12, 13, 14, 15], which allows access of large-scale image-level datasets (e.g., ImageNet-21K [16] with 14M images of 21K classes) with super rich data distributions and data vocabularies, has reignited new research interest under the context of learning generalizable detectors.\nWhile exploiting WSOD to learn generalizable detectors, one typical challenge is that the provided image-level labels do not convey precise object information [15] and often mismatch with box-level labels. Recent methods address this challenge by designing various label-to-box assignment strategies that assign the image-level labels to the predicted top-score [13, 14] or max-size [15] object proposals. However, the mismatch problem remains due to the restriction of the raw image-level labels [17]. At the other end, self-training [18, 19, 20] with the detectors pre-trained with [13, 14, 15] can generate box-level pseudo labels without the restriction of image-level labels. It allows learning from more object proposals without the image-to-box label mismatch issue, but it does not benefit much from the provided image-level label supervision."}, {"title": "2 Related Work", "content": "Weakly-supervised object detection (WSOD) aims to train object detectors using image-level supervision. Traditional WSOD methods [23, 24, 25, 26, 27] use image-level annotations only without any box annotations and thus focus on low-level proposal mining techniques [28, 29, 12, 30, 31, 32], leading to unsatisfying localization performance. Semi-supervised WSOD [33, 34, 35, 36, 37, 38, 39]"}, {"title": "3 Method", "content": "This work focuses on learning generalizable object detectors via weakly-supervised detector train-ing [15], which leverages additional large-scale image-level datasets to enlarge the data distributions and data vocabularies in detector training. We first describe the task definition with training and evaluation setups. Then, we present our proposed DetLH which is detailed in two major aspects on Language Hierarchical Self-training (LHST) that introduces language hierarchy into detector training, and Language Hierarchical Prompt Generation (LHPG) that introduces language hierarchy into prompt generation."}, {"title": "3.1 Task Definition", "content": "Training setup. The training data consists of two parts: 1) a detection dataset $D_{det}$ = ${ (x, y_{det})_i }_{i=1}^{|D_{det}|}$, where x denotes an image while $y_{det}$ stands for the class and bounding box labels for x; 2) an image classification dataset $D_{cls}$ = ${ (x, y_{cls})_i }_{i=1}^{|D_{cls}|}$ where $y_{cls}$ denotes the image-level label (i.e., a one-hot vector) for x. Given the two datasets, the goal is to learn a generalizable detection model F by jointly optimizing F over $D_{det}$ and $D_{cls}$:\n$Loss = \\sum_{(x,ydet) \\in D_{det}} L_{det} (F(x), y_{det}) + \\sum_{(x,ycls) \\in D_{cls}} L_{weak} (F(x), y_{cls}),$                                     (1)\nwhere $L_{det}(\\cdot) = L_{rpn}(\\cdot) + L_{reg}(\\cdot) + L_{cls}(\\cdot)$ is the fully-supervised detection loss function while $L_{rpn}(\\cdot)$, $L_{reg}(\\cdot)$, and $L_{cls}(\\cdot)$ denote RPN, Regression, and Classification loss functions, respectively. $L_{weak}$ is the weakly-supervised loss function to train detectors with image-level labels.\nEvaluation setup. As the goal is to learn a generalizable detection model that works well on various unseen downstream tasks, we conduct zero-shot cross-dataset evaluation\u00b2 to assess the generalization performance of the trained detection model. Note, different domain adaptation [72, 73, 74, 75] that generally uses downstream data in training, our setup is similar to domain generalization [76, 77] that does not involve downstream data in training."}, {"title": "3.2 Language Hierarchical Self-training", "content": "The proposed LHST utilizes WordNet's language hierarchy to expand the image-level labels, which enables co-regularization between the expanded image-level labels and self-training as illustrated in Figure 2.\nOverview. For fully supervised detector training over the detection dataset, we feed box-level annotated samples $(x, y_{det}) \\in D_{det}$ to the detection model F and optimize F with the standard fully supervised detection loss, i.e., the first term of Eq. 1. For weakly-supervised detector training over the image-level annotated dataset $(x, y_{cls}) \\in D_{cls}$ shown in Figure 2, we first leverage WordNet's language hierarchy to expand the raw image-level label $y_{cls}$ into $y^{hier}_{image}$ (the hierarchical image-level label), and merge $y^{hier}_{image}$ and the generated pseudo box label $\\hat{y}_{box}$ to acquire $\\hat{y}^{hier}_{box}$ (the hierarchical box-level pseudo label). Then, we optimize the detector with $(y^{hier}_{box}, w^{hier}_{box})$ and $(y^{hier}_{image}, w^{hier}_{image})$, where $w^{hier}_{box}$ and $w^{hier}_{image}$ denote the predicted reliability scores of the expanded logits '1' in $y^{hier}_{image}$ and $y^{hier}_{box}$ and are used to weight the labels in loss calculation.\nExpanding image labels with language hierarchy. Given image-level annotated dataset $(x, y_{cls}) \\in D_{cls}$ ($y_{cls}$ is a label vector with length C and C denotes the number of classes), we leverage WordNet's class name hierarchy [21] to expand $y_{cls}$ into $y^{hier}_{image}$ as the following:"}, {"title": "4 Experiments", "content": "We evaluate our DetLH on 14 widely adopted detection benchmarks. We follow the zero-shot cross-dataset object detection setting proposed in [17, 15]. More details like Dataset and Implementation Details are provided in the appendix."}, {"title": "4.1 Comparison with the state-of-the-art", "content": "We conduct extensive experiments to benchmark our proposed DetLH with state-of-the-art methods. We evaluate them on 14 widely studied object detection datasets to assess their zero-shot cross-dataset generalization ability. Tables 1- 5 report zero-shot cross-dataset detection results for common objects, autonomous driving, intelligent surveillance, and wildlife detection, respectively. More details are to be described in the following paragraphs."}, {"title": "4.2 Ablation Studies", "content": "We perform ablation studies with Swin-B [84] based CenterNet2 [54] over the large-scale Object365 dataset as shown in Table 6. As the core of our proposed DetLH, we examine how our designed LHST and LHPG contribute to the overall performance of zero-shot cross-dataset object detection. As shown in Table 6, the baseline (Box-Supervised [15]) does not perform well as it uses box-level training data only. It can be observed that LHST outperforms the baseline clearly, showing that LHST can effectively leverage the large-scale image-level annotated dataset to significantly enlarge the data distribution and data vocabulary involved in detector training, leading to much better zero-shot cross-dataset detection performance. In addition, LHPG brings clear performance improvements in zero-shot cross-dataset detection by introducing language hierarchy into prompt generation, demonstrating the effectiveness of LHPG in mitigating the vocabulary gaps between training and testing. Moreover, the inclusion of both LHST and LHPG in the proposed DetLH performs clearly the best, indicating the complementary property of our two designs."}, {"title": "4.3 Discussion", "content": "Generalization across various detection tasks: We study the generalization of our DetLH by conducting zero-shot cross-dataset object detection on 14 widely studied object detection datasets. Tables 1-5 show that DetLH achieves superior performance consistently across all the detection applications. Besides, Table 7 summarizes the detection results averaged on 14 datasets, showing that DetLH clearly outperforms the state-of-the-art methods.\nGeneralization across various network architectures: We study the generalization of the proposed DetLH from the perspective of network architectures. Specifically, we perform extensive evaluations with four representative network architectures, including one Transformer-based (i.e., Swin-B) and three CNN-based (i.e., ConvNeXt-T, ResNet-50 and ResNet-18). Experimental results in Table 8 show that the proposed DetLH outperforms the state-of-the-art method consistently over different network architectures."}, {"title": "5 Conclusion", "content": "This paper presents DetLH, a Detector with Language Hierarchy that combines language hierarchical self-training (LHST) and language hierarchical prompt generation (LHPG) for learning generalizable object detectors. LHST introduces WordNet's language hierarchy to expand the image-level labels and accordingly enables co-regularization between the expanded labels and self-training. LHPG helps mitigate the vocabulary gaps between training and testing by introducing WordNet's language hierarchy into prompt generation. Extensive experiments over multiple object detection tasks show that our DetLH achieves superior performance as compared with state-of-the-art methods. In addition, we demonstrate that DetLH works well with different network architectures such as Swin-B, ConvNeXt-T, ResNet-50, etc. Moving forward, we will explore language hierarchy to further expand the labels in an open-vocabulary manner in addition to the closed ImageNet-21K's vocabulary."}]}