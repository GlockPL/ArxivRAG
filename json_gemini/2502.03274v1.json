{"title": "A Scalable Approach to Probabilistic Neuro-Symbolic Verification", "authors": ["Vasileios Manginas", "Nikolaos Manginas", "Edward Stevinson", "Sherwin Varghese", "Nikos Katzouris", "Georgios Paliouras", "Alessio Lomuscio"], "abstract": "Neuro-Symbolic Artificial Intelligence (NeSy AI) has emerged as a promising direction for integrating neural learning with symbolic reasoning. In the probabilistic variant of such systems, a neural network first extracts a set of symbols from sub-symbolic input, which are then used by a symbolic component to reason in a probabilistic manner towards answering a query. In this work, we address the problem of formally verifying the robustness of such NeSy probabilistic reasoning systems, therefore paving the way for their safe deployment in critical domains. We analyze the complexity of solving this problem exactly, and show that it is NP#P-hard. To overcome this issue, we propose the first approach for approximate, relaxation-based verification of probabilistic NeSy systems. We demonstrate experimentally that the proposed method scales exponentially better than solver-based solutions and apply our technique to a real-world autonomous driving dataset, where we verify a safety property under large input dimensionalities and network sizes.", "sections": [{"title": "1 Introduction", "content": "Neuro-Symbolic Artificial Intelligence (NeSy AI) [Hitzler and Sarker, 2022; Marra et al., 2024] aims to combine the strengths of neural-based learning with those of symbolic reasoning. Such techniques have gained popularity, as they have been shown to improve the generalization capacity and interpretability of neural networks (NNs) by seamlessly combining deep learning with domain knowledge. We focus on NeSy approaches that perform probabilistic reasoning. Such systems are typically compositional; first, a NN extracts symbols from sub-symbolic input, which are then used for formal reasoning by a symbolic component. They rely on formal probabilistic semantics to handle uncertainty in a principled fashion [Marra et al., 2024], and are for this reason adopted by several state-of-the-art NeSy systems [Manhaeve et al., 2018; Winters et al., 2022].\nIn order to deploy such NeSy systems in mission-critical applications, it is often necessary to have formal guarantees of their reliable performance. Techniques for NN verification are valuable to that end, since they are able to derive such guarantees for purely neural systems. Still, verifying properties on top of hybrid systems combining neural and symbolic components remains largely under-explored. In this work we address this challenge, focusing on verifying the robustness of probabilistic NeSy systems, i.e., verifying the property that input perturbations do not affect the reasoning output. We do so by lifting existing NN verification techniques to the NeSy setting.\nA few related verification approaches, often termed Neuro-Symbolic, have been proposed in the literature [Akintunde et al., 2020; Xie et al., 2022; Daggitt et al., 2024]. Such methods go beyond neural classification robustness, by verifying more complex properties on top of a NN [Xie et al., 2022], or by verifying the correct behaviour of hybrid systems consisting of neural and symbolic components. In the latter case, the symbolic component includes some form of control logic over the neural outputs [Akintunde et al., 2020], or programs that make use of such outputs in the context of neuro-symbolic programming [Daggitt et al., 2024]. These methods differ substantially from our proposed approach, which targets systems that perform probabilistic reasoning, a task that is beyond the reach of the aforementioned techniques. Moreover, existing methods rely on solver-based verification techniques, which translate the verification query into a satisfiability modulo theories (SMT) problem [Xie et al., 2022; Daggitt et al., 2024] or into a mixed-integer linear programming (MILP) instance [Akintunde et al., 2020]. While such techniques result in approaches that are sound and complete, they suffer from serious scalability issues, which often renders them impractical.\nThese scalability issues motivate the use of relaxation-based verification approaches, which sacrifice completeness for efficiency. Such techniques reason over a relaxed version of the verification problem by over-approximating the exact bounds [Ehlers, 2017a; Xu et al., 2020]. Our proposed approach extends relaxation-based NN verification methods to the NeSy setting, by relying on knowledge compilation (KC) [Darwiche and Marquis, 2002]. KC is widely used (e.g. in [Xu et al., 2018; Manhaeve et al., 2018]) to represent the probabilistic symbolic component of the system as an algebraic computational graph comprised solely of addition, subtraction, and multiplication nodes. This can in turn be appended to the output layer of the neural component. The re-"}, {"title": "2 Background", "content": ""}, {"title": "2.1 Probabilistic NeSy Systems", "content": "Probabilistic NeSy AI aims to combine perception with probabilistic logical reasoning. We provide a brief overview of the operation of such a system based on [Marconato et al., 2024]. Given input $x \\in \\mathbb{R}^n$, the system utilizes a NN, as well as symbolic knowledge $K$, to infer a (multi-)label output $y \\in \\{0, 1\\}^m$. In particular, the system computes $p_{\\Theta}(y \\vert x; K)$, where $\\Theta$ refers to the trainable parameters of the NN. This is achieved in a two-step process. First, the system extracts a set of latent concepts $c \\in \\{0,1\\}^k$, through the use of a parameterized neural model $p_{\\Theta}(c \\vert x)$. These latent concept predic-"}, {"title": "2.2 Knowledge Compilation", "content": "Probabilistic reasoning in NeSy systems is often performed via reduction to Weighted Model Counting (WMC), which we briefly review next. Consider a propositional logical formula $\\phi$ over variables $V$. Each boolean variable $v \\in V$ is assigned a weight $p(v)$, which denotes the probability of that variable being true. The Weighted Model Count (WMC) of formula $\\phi$ is then defined as:\n\\[WMC(\\phi) = \\sum_{\\omega \\models \\phi} \\prod_{v \\in \\omega} p(v) \\prod_{v \\notin \\omega} 1 - p(v). \\tag{1}\\]\nIn essence, the WMC is the sum of the probability of all worlds $\\omega$ that are models of $\\phi$. WMC is #P-hard, since it generalizes a #P-complete problem, #SAT, by incorporating weights [Chavira and Darwiche, 2008].\nA widely-used approach for solving the WMC problem is knowledge compilation (KC) [Darwiche and Marquis, 2002; Chavira and Darwiche, 2008]. According to this approach, the formula $\\phi$ is first compiled into a tractable representation, which is used at inference time to compute a large number of queries - in our case, instances of the WMC problem - in polynomial time. KC techniques push most of the computational effort to the \"off-line\" compilation phase, resulting in computationally cheap \u201con-line\u201d query answering, a concept termed amortized inference."}, {"title": "2.3 Verification of Neural Networks", "content": ""}, {"title": "NN Robustness.", "content": "Verifying the robustness of NN classifiers amounts to proving that the network's correct predictions remain unchanged if the corresponding input is perturbed within a given range $\\epsilon$ [Wong et al., 2018]. Contrary to empirical machine learning evaluation techniques, NN verification methods reason over infinitely-many inputs to derive certificates for the robustness condition. For a given network $f$, this is formalized as follows: for all inputs $x$, such that $f(x)$ is a correct prediction, and for all $x'$, such that $\\lVert x - x'\\rVert \\leq \\epsilon$, it holds that $f(x) = f(x')$.\nChecking if the robustness condition holds for some $\\epsilon$ can be achieved by reasoning over the relations between the network's un-normalized predictions (logits) at the NN's output layer. In particular, it can be seen that if for any $x'$ in an $\\epsilon$-ball of $x$, it holds that $Y_{true} - Y_i > 0$, for all $y_i \\neq Y_{true}$, then the network is robust for $\\epsilon$ [Gowal et al., 2018]. Here $Y_{true}$ is the logit corresponding to the correct class and $y_i$ are the logits corresponding to all other labels. This condition can be checked by computing the minimum differences of the predictions for all points in the $\\epsilon$-ball. If that minimum is positive, the robustness condition is satisfied. However, finding that minimum is NP-hard [Katz et al., 2017]."}, {"title": "Solver-Based Verification.", "content": "Early verification approaches include Mixed Integer Linear Programming (MILP) [Lomuscio and Maganti, 2017; Tjeng et al., 2019; Henriksen and Lomuscio, 2020] and Satisfiability Modulo Theories (SMT) [Ehlers, 2017b; Katz et al., 2017]. MILP approaches encode the verification problem as an optimization task over linear constraints, which can be solved by off-the-shelf MILP-solvers. SMT-based verifiers translate the NN operations and the verification query into an SMT formula and use SMT solvers to check for satisfiability. Although these methods are precise and provide exact verification results, they do not scale to large, deep networks, due to their high computational complexity. As such, they are impractical for real-world applications with high-dimensional inputs like images or videos."}, {"title": "Relaxation-Based Verification.", "content": "As the verification problem is NP-hard [Katz et al., 2017], incomplete techniques that do not reason over an exact formulation of the verification problem, but rather an over-approximating relaxation, are used for efficiency. A salient method that is commonly used is Interval Bound Propagation (IBP), a technique which uses interval arithmetic [Sunaga, 1958] to propagate the input bounds through all the layers of a NN [Gowal et al., 2018]. As a non-exact approach to verification, it is not theoretically guaranteed to solve a problem. However, the approach is sound, in that if the lower bound is shown to be positive the network is robust. Therefore, once the bounds of the output layer are obtained, an instance is safe if the lower bound of the logit corresponding to the correct class is greater than the upper bounds of the rest of the logits, since this ensures a correct prediction, even in the worst case."}, {"title": "3 Probabilistic Neuro-Symbolic Verification", "content": ""}, {"title": "3.1 Problem Statement", "content": "We now formally define the aim of relaxation-based techniques in the context of NeSy probabilistic reasoning systems. Given a NeSy system, as defined in Section 2.1, our aim is to compute:\n\\[\\min_{y_i} p(y_i \\vert x'), \\max_{y_i} p(y_i \\vert x'')\\qquad\\forall x' \\text{ s.t. } \\lVert x' - x \\rVert \\leq \\epsilon \\tag{2}\\]\nfor all $y_i$ in $y$. That is, we wish to calculate the minimum and maximum value of each of the probabilistic outputs of"}, {"title": "3.2 Exact Solution Complexity", "content": "Let us now assume that via known techniques described in Section 2.3 we have obtained bounds in the form of a probability range for each output of the NN. Next, we turn to the task of propagating these bounds through the symbolic component, in order to obtain maxima/minima on the reasoning output, and investigate the complexity of doing so exactly.\nFirst, we show that, in the worst case, to find the solution we have to check all combinations of lower/upper bounds for all NN outputs. To illustrate this, we utilize the circuit representation of the symbolic component obtained via KC. It is known that such circuits represent multi-linear polynomials of the input variables [Choi et al., 2020]. For example, a simple traversal of the SDD of Figure 2a yields the polynomial:\n\\[p = (1 - p(\\text{car in front})) \\times (1 \u2013 p(\\text{red light})) \\\\\n\\times p(\\text{accelerate}) + p(\\text{brake})\\]\nGiven this formulation, it is possible to obtain bounds on the circuit root node by solving a constrained optimization problem, in which we find the extrema (maximum and minimum) of the polynomial, subject to the bounded domains of the input variables (the NN outputs). We observe that this circuit polynomial is defined on a rectangular domain, since all input variables are defined in a closed interval (e.g. red light $\\in [0.3, 0.4]$, brake $\\in [0.6,0.9]$). It is known that in this case the extrema lie on the vertices of the domain [Laneve et al., 2010], i.e., at the extrema each variable is assigned either its lower or upper bound, not something in between. Thus, in the worst case, to find the extrema one needs to search the combinatorial space of $2^n$ possible solutions.\nIn order to calculate the maximum and minimum output of the symbolic component, for each of the $2^n$ points we have to solve one instance of the WMC problem. Indeed, since each possible solution represents a probability assignment to all input variables, we can use WMC to compute the probabilistic output of the reasoning module under that weight assignment, and then select the maximum and minimum value obtained over all assignments.\nGiven the two steps above, it can be seen that starting with the formula, i.e., without first compiling it into a circuit, exact"}, {"title": "3.3 Relaxation-Based Approach", "content": "The NP-hardness of exact bound computation through the compiled symbolic component motivates the use of relaxation-based techniques. We now show how these can be extended to the NeSy setting in order to provide a scalable solution to Equation 2.\nCompositional probabilistic NeSy systems can be viewed as a single computational graph, by providing the outputs of the neural network as the inputs of the symbolic probabilistic circuit. In the case of the running example of Figure 1, the outputs of each of the two networks are concatenated into a single vector and used as input to the arithmetic circuit which represents the constraints. Hence, a NeSy system can be seen as an end-to-end differentiable algebraic computational graph, which accepts an input, an image in this case, and outputs a vector of probabilities. These characteristics allow one to construct the NeSy system as a single module comprising an arbitrary number of neural networks and a single arithmetic circuit. Such a module can be constructed in a machine learning library, such as Pytorch, and subsequently exported as an Open Neural Network Exchange (ONNX) graph [developers, 2021]. Figure 3 depicts the ONNX representation of the NeSy system of the running example.\nONNX is a widespread NN representation, and is the stadard input format for NN verifiers [Brix et al., 2024]. This includes both solver-based verification tools, such as Marabou [Katz et al., 2019], and relaxation-based ones, such as auto_LiRPA [Xu et al., 2020] and VeriNet [Henriksen and Lomuscio, 2020]. Thus, by representing a NeSy system as an end-to-end computational graph and exporting it to this format, it is possible to utilize state-of-the-art tools to perform verification in an almost \"out-of-the-box\" fashion. While our proposed framework is, in principle, compatible with all the aforementioned tools, we focus on relaxation-bsed verifiers, in order to showcase scalable probabilistic NeSy verification. Such verifiers allow us to perturb the input and compute bounds directly on the output of the NeSy system, that is, without computing intermediate bounds on the NN outputs."}, {"title": "4 Experimental Evaluation", "content": "In this section we empirically evaluate the effectiveness and applicability of our approach. We assess the scalability of the proposed method via a synthetic task based on MNIST addition, a standard benchmark from the NeSy literature [Manhaeve et al., 2018]. Further, we apply our approach to a real-world autonomous driving dataset and verify a safety driving property on top of two 6-layer convolutional NNs. In"}, {"title": "4.1 Multi-Digit MNIST Addition", "content": "In this experiment we evaluate the scalability of our approach as the complexity of the probabilistic reasoning component increases. Specifically, we explore how the approximate nature of our method enhances scalability, while also considering the corresponding trade-off in the quality of verification results.\nTo this end, we compare the following approaches:\n1.  End-to-End relaxation-based verification (E2E-R) An implementation of our method in auto_LiRPA, a state-of-the-art relaxation-based verification tool. The input to auto_LIRPA is the NeSy system under verification, which is translated internally into an ONNX graph. The verification method used is IBP, as implemented in auto_LiRPA.\n2.  Hybrid verification (R+SLV) A hybrid approach consisting of relaxation-based verification for the neural part of the NeSy system and solver-based bound propagation through the symbolic part. The former is implemented in auto_LiRPA using IBP. The latter is achieved by transforming the circuit into a polynomial (see Section 3.2), and solving a constrained optimization problem with the Gurobi solver. The purpose of comparing to this baseline is to assess the trade-off between scalability and quality of results, when using exact vs approximate bound propagation through the symbolic component.\n3.  Solver-based verification (MARABOU) Exact verification using Marabou, a state-of-the-art SMT-based verification tool, also used as a backend by most NeSy verification works in the literature [Xie et al., 2022; Daggitt et al., 2024]. Marabou is unable to run on the full NeSy architecture, as the current implementation does not support several operators, such as Softmax and tensor indexing. To obtain an indication of Marabou's performance, we use it to verify only the neural part of the NeSy system, a subtask of NeSy verification. Specifically, we verify the classification robustness of the CNN performing MNIST digit recognition.\nDataset. We use a synthetic task, where we can controllably increase the size of the symbolic component, while keeping the neural part constant. In particular, we create a variant of multi-digit MNIST addition [Manhaeve et al., 2018], where each instance consists of multiple MNIST digit images, and is labelled by the sum of all digits. We can then control the number of MNIST digits per sample, e.g. for 3-digit addition, an instane would be ((4,7,2), 13). We construct the verification dataset from the 10K samples of the MNIST test set, using each image only once. Thus, for a given #digits the verification set contains 10K/#digits test instances.\nExperimental setting. The NN is a convolutional neural network tasked to recognize single MNIST digits. The CNN is trained in a standard supervised fashion on the MNIST train dataset, consisting of 60K images, and achieves an accuracy of 98% on the test set. The symbolic part consists of the rules of multi-digit addition. It accepts the CNN predictions for the input images and computes a probability for each sum. As the number of summand digits increases, so does the size of the reasoning circuit, since there are more ways to construct a given sum using more digits (e.g. consider the"}, {"title": "4.2 Autonomous Driving", "content": "In this experiment we apply our proposed approach to a real-world dataset from the autonomous driving domain. The purpose of the experiment is to assess the robustness of a neural autonomous driving system with respect to the safety and common-sense properties of Figure 1, i.e., to evaluate whether input perturbations cause the neural systems to violate the constraints that they previously satisfied.\nDataset. To that end, we use the Road event Awareness Dataset with logical Requirements (ROAD-R) [Giunchiglia et al., 2023]. ROAD-R consists of 22 videos of dashcam footage from the point of view of an autonomous vehicle (AV), and is annotated at frame-level with bounding boxes. Each bounding box represents an agent (e.g. a pedestrian, vehicles of different types, etc.) performing an action (e.g."}, {"title": "Experimental Setting.", "content": "We focus on a subset of the dataset that is relevant to the symbolic constraints of Figure 1. Consequently, we select a subset of frames which adhere to these constraints. Specifically, either the AV is moving forward, there is no red traffic light in the frame, and no car stopped in front of the AV, or the AV is stopped, and there is either a red traffic light or a car stopped in front. By sampling the videos every 2 seconds, we obtain a dataset of 3143 examples, where each example contains a 3 \u00d7 240 \u00d7 320 image, and four binary labels: red light, car in front, stop, move forward.\nThe neural part of the system comprises two 6-layer CNNs, responsible for object detection and action selection respectively. The two networks are trained in a standard supervised fashion using an 80/20 train/test split over the selected frames. The object detection and action selection networks achieve accuracies of 97.2% and 96.3% on the respective test sets. We add L\u221e-norm perturbations to the test input images for five values of perturbation size \u03f5: {10\u22125, 5 \u00b7 10\u22125, 10\u22124, 5 \u00b7 10\u22124, 10\u22123}.\nTable 2 presents the results. We report robustness, i.e., the fraction of robust instances over the total number of instances in the test set, and verification runtime for E2E-R. Since this task consists of a small arithmetic circuit and a significantly larger neural component, it is the latter that predominantly affects both the computational overhead and the accumulated errors of bound propagation. Therefore, E2E-R and R+SLV, which differ only in the symbolic component, provide nearly identical results that are omitted.\nAs expected, robust accuracy falls as the perturbation size increases. Regarding the verification runtime, this experiment reinforces our results from Section 4.1, by demonstrating that the runtime of our approach remains largely unaffected by changes in the value of the perturbation size \u03f5."}, {"title": "5 Related Work", "content": "Although NN verification and NeSy AI have both seen rapid growth over the last few years, their intersection is underexplored, with some related work existing in the literature. In [Akintunde et al., 2020], the authors address the problem of verifying properties accociated with the temporal dynamics of multi-agent systems. The agents of the system combine a neural perception module with a symbolic one, encoding action selection mechanisms via traditional control logic. The verification queries are specified in alternating-time temporal"}, {"title": "6 Conclusion", "content": "We presented a scalable technique for verifying the robustness of probabilistic neuro-symbolic reasoning systems. Our method combines relaxation-based techniques from the NN verification domain with knowledge compilation, in order to assess the effects of input perturbations on the probabilistic logical output of the system. We motivated our approach via a theoretical analysis, and demonstrated its efficacy via experimental evaluation on synthetic and real-world data. Future work includes extending our method to more sophisticated neural verification techniques, such as (Reverse) Symbolic Interval Propagation [Gehr et al., 2018; Wang et al., 2021], towards obtaining tighter bounds. Further, integrating certified training techniques [M\u00fcller et al., 2023; Palma et al., 2024] would substantially increase the magnitude of perturbations that our approach can verify, as such training explicitly optimizes for easier verification."}]}