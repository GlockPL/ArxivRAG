{"title": "CFT-RAG: An Entity Tree Based Retrieval Augmented Generation Algorithm With Cuckoo Filter", "authors": ["Zihang Li", "Yangdong Ruan", "Wenjun Liu", "Zhengyang Wang", "Tong Yang"], "abstract": "Although retrieval-augmented generation(RAG) significantly improves generation quality by retrieving external knowledge bases and integrating generated content, it faces computational efficiency bottlenecks, particularly in knowledge retrieval tasks involving hierarchical structures for Tree-RAG. This paper proposes a Tree-RAG acceleration method based on the improved Cuckoo Filter, which optimizes entity localization during the retrieval process to achieve significant performance improvements. Tree-RAG effectively organizes entities through the introduction of a hierarchical tree structure, while the Cuckoo Filter serves as an efficient data structure that supports rapid membership queries and dynamic updates. The experiment results demonstrate that our method is much faster than naive Tree-RAG while maintaining high levels of generative quality. When the number of trees is large, our method is hundreds of times faster than naive Tree-RAG. Our work is available at https://github.com/TUPYP7180/CFT-RAG-2025.", "sections": [{"title": "1. Introduction", "content": "In the era of information explosion, Retrieval-Augmented Generation (RAG), a technology integrating retrieval mechanisms with generative models, has gained significant attention. It allows models to draw on external knowledge bases during text generation, effectively overcoming the limitations of traditional generative models in knowledge-intensive tasks (Lewis et al., 2020). The knowledge base, a vital part of the RAG system, stores a wealth of structured and unstructured knowledge, acting as the main source of external information for the model. However, with the continuous expansion of the knowledge base and the rapid pace of knowledge update, the challenge of efficiently retrieving relevant and accurate information from it has become a major obstacle to improving the performance of RAG system. Enhancing the retrieval speed and accuracy of the knowledge base is crucial for boosting the overall performance of the RAG system. Faster and more accurate retrieval enables the model to access relevant knowledge promptly, improving response speed and the quality of generated content. In contrast, inefficient or inaccurate retrieval can result in incorrect or irrelevant outputs, degrading user experience and system usability. Therefore, exploring ways to optimize the knowledge base retrieval mechanism is of great theoretical and practical importance, and this paper will focus on this key issue.\nKnowledge bases in Retrieval-Augmented Generation (RAG) systems are mainly of three types: text-based, graph-based, and tree-based. Text-based ones store information as text, easy to manage but slow in retrieval due to complex language processing. Graph-based knowledge bases represent knowledge as graphs, excelling in handling complex relationships with relatively fast retrieval for certain queries, thanks to graph neural networks. Tree-based knowledge bases structure knowledge hierarchically.\nDespite text-based and graph-based knowledge bases having made good progress, the retrieval speed of all three types, especially tree-based ones, needs improvement. For RAG systems to provide faster and more accurate responses, optimizing retrieval from these knowledge bases, particularly tree-RAG, is a key research challenge.\nTree-RAG, an extension of RAG, improves on traditional RAG frameworks by using a hierarchical tree structure to organize the retrieved knowledge, thus providing richer context and capturing complex relationships among entities. In Tree-RAG, entities are arranged hierarchically, allowing the retrieval process to more effectively traverse related entities at multiple levels. This results in enhanced response accuracy and coherence, as the tree structure maintains connections between entities that are essential for contextually rich answers (Fatehkia et al., 2024). However, a critical limitation of Tree-RAG lies in its computational inefficiency: as the datasets and tree"}, {"title": "1.1. Related Work", "content": "Bloom Filter Bloom Filter is an efficient probabilistic data structure for set membership queries (Bloom, 1970). The structure maps elements to bit arrays by using multiple hash functions to quickly determine whether an element exists. On insertion, the locations corresponding to all hash functions are set to 1; in query, if all relevant bits are 1, the element may exist, and if any bit is 0, it must not exist. This design results in false positives but no false negatives for bloom filters. Bloom filters are widely used in scenarios such as databases, caches and distributed systems to quickly filter irrelevant candidates, thus speeding up the retrieval process (Patgiri et al., 2019). Despite its spatial efficiency, the fixed false positive rate and the limitation of not being able to delete elements make it limited in some occasions.\nCuckoo Filter Cuckoo Filter is an efficient data structure for supporting fast element lookup and deletion operations, which is mainly used for collection operations and data stream processing (Fan et al., 2014). It is developed based on the idea of Cuckoo Hashing (Pagh & Rodler, 2001). Cuckoo Filter outperforms traditional Bloom filters in terms of storage efficiency and query performance, especially in scenarios where frequent insertion and deletion of elements are required. The main advantage of Cuckoo Filter is its support for dynamic updates. The main advantage of Cuckoo Filter is its support for dynamic updates, which enables it to efficiently handle element changes in a collection. Unlike Bloom Filter, Cuckoo Filter can not only query whether an element exists or not, but also support the deletion operation of an element, a feature that is important in many practical applications (Gupta & Breitinger, 2015). The working principle of Cuckoo Filter is based on multiple hash functions and a bucket structure, which is utilized by storing the elements in fixed-size buckets and using the hash conflicts to achieve fast lookup of elements. This efficient data structure provides new ideas for handling large-scale datasets, which can accelerate the retrieval process and improve response efficiency.\nRetrieval Augmented Generation Retrieval Augmented Generation(RAG) is a state-of-the-art method that combines information retrieval with large language models, with the aim of addressing the limitations of it in the absence of specific knowledge (Lewis et al., 2020). The core idea of RAG is to utilize an external knowledge base for retrieval and to incorporate relevant information into the generation process. Specifically, RAG first retrieves multiple relevant documents from the knowledge base on the basis of the input query, and then combines the retrieved knowledge with the input query to form the"}, {"title": "2. Data Pre-processing", "content": "It is important to recognize entities and construct hierarchical relationships (e.g., tree diagrams) between entities from datasets. It mainly involves the steps of entity recognition, relationship extraction and filtering. For existing hierarchical data, binary pairs representing parent-child relationships are directly extracted. For raw textual data, text cleansing is first performed manually to remove irrelevant information."}, {"title": "2.1. Entities Recognition", "content": "SpaCy is a Python library, and its entity recognition function is based on deep learning models (e.g., CNN and Transformer). It captures information by transforming the text into word vectors and feature vectors. The models are trained on a labeled corpus to recognize named entities in the text, such as names of people and places. We adopt the method in T-RAG by using the spaCy library to recog-"}, {"title": "2.2. Relationship Extraction", "content": "Various relationships are identified from the data, including organizational, categorization, temporal, geographic, inclusion, functional, and attribute relationships. The relationships manifest through grammatical structures such as noun phrases, prepositional phrases, relative clauses, and appositive structures (Vaswani et al., 2017; Devlin et al., 2019). We focus on extracting relationships that express dependency, such as \"belongs to,\" \"contains,\" and \"is dependent on.\"\nWe use several dependency parsing models(gpt-4 and open-source NLP libraries) to analyze the grammatical structure of the data. This helps identify relationships between words, such as subject-verb-object or modifier relationships.\nWe define rules to identify hierarchical relationships. If a word modifies another noun, it can be interpreted as a child-parent relationship; If there are conjunctions (e.g., \"and\", \"or\"), handle them to group entities under the same parent. As a result, there is a list of tuples representing the hierarchical structure."}, {"title": "2.3. Relationship Filtering", "content": "After extracting relations, certain relationships are filtered out to ensure maintain the tree structure:\n\u2022 Transitive Relations: If transitive relations are detected (e.g., \"A belongs to B\", \"B belongs to C\" and \"A belongs to C\"), remove distant relations.\n\u2022 Cycle Relations: If cycles are detected (e.g., \"A belongs to B\" and \"B belongs to A\"), only the closest relationship is retained.\n\u2022 Self-Pointing Edges: Any relation where a node points to itself is removed.\n\u2022 Duplicate Edges: Multiple edges between the same nodes are pruned, leaving only one edge."}, {"title": "3. Methodology", "content": "In this section, we propose a novel design of Cuckoo Filter that combines the advantages of traditional Cuckoo Hashing and applies it to Tree-RAG by introducing additional designs that greatly improve the speed of knowledge retrieval in Tree-RAG."}, {"title": "3.1. Storage Mode", "content": "In addition to entity trees, we set up an additional Cuckoo Filter to store some entities to improve retrieval efficiency. Based on the naive Cuckoo Filter, we introduce the block linked list for optimization, which can greatly reduce memory fragmentation. We first find out all locations of each entity in the forest and then store these addresses in a block linked list.\nTo further optimize the retrieval performance, we propose an adaptive sorting strategy to reorder the entities in each bucket in the Cuckoo Filter based on the temperature variable which is stored at the head of the block list. The temperature variable records how often each entity is accessed, and entities with high-frequency access are prioritized to be placed at the front of the bucket. Since the Cuckoo Filter looks up the elements in the buckets linearly, this reordering mechanism can significantly optimize the query process, which can further improve the response speed of the model. In summary, in each entry of the bucket, an entity's fingerprint, its temperature, and head pointer of its block linked list are stored."}, {"title": "3.2. Entity Insertion Strategy", "content": "The fingerprint is a shorter hash representation of an entity x, which is usually represented in fixed-length bits. Thus, we introduce fingerprints to save memory. After the tree structure is constructed, the fingerprint is first computed for each entity before inserting. Furthermore, the insertion and eviction strategy is consistent with the traditional Cuckoo Filter, where the locations of the fingerprint are determined by two hash functions (Fan et al., 2014). When inserting an entity by applying the Cuckoo Filter, it first tries to store its fingerprint in the empty position $i_1$ or $i_2$, which can be calculated as:\n$i_1 = h(x), i_2 = i_1 + h(f(x)) \t\t\t(1)$"}, {"title": "3.3. Entity Eviction Strategy", "content": "In the eviction mechanism, the Cuckoo Filter randomly selects a location from $i_1$ or $i_2$ to evict the fingerprints therein and then calculate the alternative position j of the fingerprint. Next, it inserts the fingerprint into the empty slot of j. If it is already occupied, the eviction operation is repeated until an empty location is found or the maximum number of iterations is reached."}, {"title": "3.4. Lookup Process and Context Generation", "content": "When an entity needs to be looked up, its location is calculated in the same way as $i_1$ and $i_2$ above. Therefore, we only need to check these two locations for the presence of the entity. If the fingerprint of the target entity is found, the temperature of the entity is added by one and a pointer to the head of the corresponding block linked list of that entity is returned. From this pointer, the location of the entity node in different trees including multi-level parent nodes, child nodes, etc. can be accessed through the address stored in the block list. If no matching fingerprint is found, the null pointer is returned. For the queried entity and its parent and child nodes in different trees, we form a context between the entity and its relevant nodes based on the set template. For instance, the upward hierarchical relationship of entity A are: B, C and D. Finally, we fuse this information with the query to generate the augmented context. After that, the augmented context combined with system prompt and query is regarded as the prompt. The lookup and context generation process is stated in Figure 4."}, {"title": "4. Experiments", "content": "In this section, we describe our experimental setup, baseline methods, and Cuckoo Filter T-RAG, and comprehensively evaluate the results. Our experiments aim to assess the efficiency of Cuckoo Filter T-RAG approaches under diverse experimental conditions, particularly in terms of retrieval speed and computational overhead."}, {"title": "4.1. Baseline", "content": "To benchmark the effectiveness of the proposed Cuckoo Filter T-RAG, we compare it against several baseline models. Our baselines include the Naive T-RAG without filtering mechanisms, T-RAG with Bloom Filter, and Improved Bloom Filter T-RAG. These baselines allow us to quantify the improvements introduced by Cuckoo Filter T-RAG.\nNaive T-RAG This basic implementation of T-RAG does not include any filtering optimizations. The method constructs an entity tree using entities extracted from the dataset and employs a Breadth-First Search (BFS) algorithm for entity lookup. Although this approach has high time complexity and prolonged search time, it provides a straightforward baseline for evaluating the benefits of incorporating filtering mechanisms.\nBloom Filter T-RAG In this model, we incorporate a Bloom Filter at each node in the entity tree. The Bloom Filter of each node indicates whether an entity exists in the node or its descendants. During retrieval, if a Bloom Filter suggests that an entity is absent, the search path is pruned, thereby reducing the search time significantly. This model serves to evaluate the potential time savings achievable through probabilistic filtering.\nImproved Bloom Filter T-RAG Building upon the Bloom Filter T-RAG, we optimize Bloom Filter usage by skipping Bloom Filter checks at nodes just above the leaf level. This change reduces unnecessary filter operations, lowering the time complexity further while maintaining high retrieval accuracy. The efficiency gains from this improvement are compared against the standard Bloom Filter T-RAG to showcase its effectiveness."}, {"title": "4.2. Cuckoo Filter T-RAG", "content": "Using Cuckoo Filter has more prominent advantages including time efficiency than Bloom Filter. Cuckoo Filter supports entity deletion operation, which is suitable for ongoing data update, and it has a lower false positive rate and is more space efficient.\nThe Cuckoo Filter T-RAG method stores the individual nodes of the entity in the forest in each bucket of the Cuckoo Filter, i.e. it merges the Cuckoo Hash with the Cuckoo Filter. After the entity tree is generated, the nodes with the same entity details in each tree are concatenated into a block list, where the pointer to the head of the list corresponds to the fingerprint, and stored together in buckets.\nAn improved Cuckoo Filter T-RAG is to maintain access popularity of each entity, called temperature, at the head node of each block list, and raise the level of temperature corresponding to the hit entity during retrieval. For each bucket, if there is a bucket that has not been searched, i.e. if it is free, the fingerprints and block list header pointers in the bucket can be sorted according to temperature, and the fingerprints with higher access popularity are placed at the front of the bucket, which can take advantage of the locality of the entities contained in the user questions to improve the running speed of the algorithm."}, {"title": "4.3. Datasets and Entity Forest", "content": "Our experiments use two datasets: the English dataset of the UNHCR organizational chart mentioned in T-RAG and a real-world Chinese dataset of hospital histories. The UNHCR dataset is pre-segmented into entities, allowing us to focus on entity extraction from the hospital histories dataset. We leverage dependency parsing models to extract entities and relationships among them and construct the entity forest based on these extracted entities and relationships. The resulting entity forest is structured to allow efficient retrieval and provides a practical evaluation scenario for our approach."}, {"title": "4.4. Setup", "content": "We implement the core RAG architecture in Python, while key data structures, including the Bloom and Cuckoo Filters, are optimized in C++ for performance. All experiments were conducted on a system equipped with an Nvidia H100 GPU, 22 CPU cores, and 220 GiB of memory. Each algorithm was repeated 100 times to account for variability and ensure reliable results, with averages calculated across runs to mitigate the influence of outliers. We apply the langsmith framework to evaluate the accuracy of answers, where the OpenAI scoring model used by langsmith was replaced with doubao."}, {"title": "4.5. Results and Evaluations", "content": "### 4.5.1. COMPARISON EXPERIMENT\nTable 1 summarizes the performance metrics for each model when the number of trees is different. In the experiments comparing the retrieval speeds of the different methods, only a small number of entities are included in the user query (the number of entities in the query is set to 5, 10, and 20). By integrating the Bloom Filter, retrieval time is partially reduced, as the filter prunes non-relevant paths in the entity tree. The improved Bloom Filter T-RAG achieves an additional speedup, attributed to the selective omission of Bloom Filter checks on near-leaf nodes, which minimizes overhead without sacrificing accuracy. From Table 1, we can observe that the optimization range increases with the number of trees in the database. For example, when the tree number is 600, our method is 138 times faster than naive Tree-RAG while maintaining the same accuracy."}, {"title": "4.5.2. ABLATION EXPERIMENT", "content": "Sorting the fingerprints and head pointers of the block linked lists by temperature can optimize the retrieval time without occupying any extra space, which is eminently useful when the query given by the user contains a large number of entities.\nWe design experiments to measure the effect of having or not having the sorting design on the result. In figure 5, we can observe that the retrieval time after the first round is significantly shorter than that of the first round. This is because the temperatures are updated according to the access frequency in each round and after each query, the Cuckoo Filter sorts the entities according to the entities' temperatures. This sorting design allows the 'hot' entities to be found more quickly in subsequent queries."}, {"title": "5. Conclusion", "content": "In this paper, we have introduced an efficient acceleration method for the Tree-RAG framework by integrating the improved Cuckoo Filter into the knowledge retrieval process. Tree-RAG, which combines hierarchical tree structures for knowledge representation with generative models, holds great promise for improving the quality and contextual relevance of generated responses. However, its performance is hindered by the computational inefficiencies of retrieving and organizing large-scale knowledge within complex tree structures.\nBy leveraging the Cuckoo Filter, which supports fast membership queries and dynamic updates, we have significantly enhanced the speed and efficiency of the retrieval process in Tree-RAG. Our experimental results show that the Cuckoo Filter improves retrieval times without sacrificing the quality of generated responses, making the system more scalable for real-world applications. This acceleration is particularly valuable in scenarios where real-time knowledge updates and rapid information retrieval are critical, such as in large-scale question answering, decision support systems, and conversational agents.\nFuture work could explore further optimizations, such as adapting the method for different knowledge structures or extending it to more complex multimodal tasks. Overall, this research demonstrates the potential of efficient data structures to enhance the performance of large language models in retrieval-intensive applications."}]}