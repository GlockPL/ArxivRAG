{"title": "Enhancing Visual Inspection Capability of Multi-Modal Large Language Models on Medical Time Series with Supportive Conformalized and Interpretable Small Specialized Models", "authors": ["Huayu Li", "Xiwen Chen", "Ci Zhang", "Stuart F. Quan", "William D.S. Killgore", "Shu-Fen Wung", "Chen X. Chen", "Geng Yuan", "Jin Lu", "Ao Li"], "abstract": "Large language models (LLMs) exhibit remarkable capabilities in visual inspection of medical time-series data, achieving proficiency comparable to human clinicians. However, their broad scope limits domain-specific precision, and proprietary weights hinder fine-tuning for specialized datasets. In contrast, small specialized models (SSMs) excel in targeted tasks but lack the contextual reasoning required for complex clinical decision-making. To address these challenges, we propose ConMIL (Conformalized Multiple Instance Learning), a decision-support SSM that integrates seamlessly with LLMs. By using Multiple Instance Learning (MIL) to identify clinically significant signal segments and conformal prediction for calibrated set-valued outputs, ConMIL enhances LLMs' interpretative capabilities for medical time-series analysis. Experimental results demonstrate that ConMIL significantly improves the performance of state-of-the-art LLMs, such as ChatGPT4.0 and Qwen2-VL-7B. Specifically, ConMIL-supported Qwen2-VL-7B achieves 94.92% and 96.82% precision for confident samples in arrhythmia detection and sleep staging, compared to standalone LLM accuracy of 46.13% and 13.16%. These findings highlight the potential of ConMIL to bridge task-specific precision and broader contextual reasoning, enabling more reliable and interpretable AI-driven clinical decision support.", "sections": [{"title": "I. INTRODUCTION", "content": "Medical time series, such as electrocardiograms (ECGs) and electroencephalograms (EEGs), offer a wealth of information about a patient's health status through sequentially sampled physiological signals. Traditionally, clinicians have relied on visual inspection to interpret these signals, identifying trends and anomalies that guide diagnoses and treatment decisions. However, this manual process is time-intensive and prone to human error, especially in complex cases or under high workload conditions. Artificial Intelligence (AI) has emerged as a powerful tool to address these challenges, enabling automated interpretation of medical time series. For clinicians, Al systems offer efficiency and accuracy by processing vast amounts of complex data and detecting critical patterns that may elude human observers. For patients, these systems can lead to earlier disease detection and more personalized care, particularly in underserved regions.\nDespite these benefits, existing AI solutions face limitations. Small specialized models (SSMs) [1]\u2013[6] are task-focused and small-scale architectures designed for specific tasks such as arrhythmia detection or sleep stage classification. SSMs are the mainstream of medical time series domain which usually directly process the raw time series data. SSMs excel in their narrow domains but lack the broader reasoning ca- pabilities required for complex clinical decision-making. On the other hand, large language models (LLMs) have rapidly gained traction in healthcare [7]\u2013[9]. The ability of LLMs to process visual-language tasks enable them performs medical time series interpretation by visual inspection [10]\u2013[14] with reasoning processes that mimic human clinicians. LLMs hold the promise of context-aware, intuitive decision-making, but their broad scope comes with drawbacks: limited domain- specific precision, high computational costs for fine-tuning, and restricted accessibility due to proprietary weights.\nThese contrasting strengths and weaknesses reveal a sig- nificant opportunity: How can we combine the task-specific expertise of SSMs with the contextual reasoning capabilities of LLMs to enable robust, interpretable, and reliable visual inspection for medical time series? To address this, we must reconsider the role of SSMs in the medical time series domain. Rather than functioning as standalone predictors, SSMs can be reimagined as specialized, complementary modules that enhance the reasoning capabilities of LLMs. This reframing leads to a central question: How can we effectively integrate SSMs into the LLM workflow to maximize their utility while addressing their inherent limitations? Achieving this synergy requires a thoughtfully designed framework that aligns with clinical workflows and ensures that the outputs of SSMs are both interpretable and actionable. By embedding the insights of SSMs into the LLM decision-making process, we can enable more informed, transparent, and collaborative clinical decisions, bridging the gap between task-specific precision and broad, context-aware reasoning.\nA critical consideration is how to use the predictions of SSMs to guide LLMs in their decision-making. Ideally, SSMs should reduce the likelihood of errors made by LLMs by providing higher prediction accuracy on specialized tasks.\nHowever, in practice, SSMs may not always surpass the accuracy of LLMs, even when trained specifically on medical time series data. Erroneous predictions from SSMs could potentially mislead LLMs, undermining their decision-making rather than enhancing it. Furthermore, when SSM and LLM predictions conflict, it can be difficult for users to determine which model to trust. Beyond merely generating predictions, SSMs should offer deeper insights into the medical time series data, enabling LLMs to validate and contextualize their out- puts. This highlights the need for an integrated approach that ensures both interpretability and reliability, empowering LLMs to make more accurate and trustworthy clinical decisions.\nTo address these limitations, we need approaches that of- fer both interpretability and uncertainty quantification. One promising strategy is the integration of Multiple Instance Learning (MIL) and conformal prediction. MIL is a weakly supervised learning technique that treats medical time series data as collections of instances, such as individual time segments. It identifies which segments have most influence on a given classification or prediction [5], [6]. This detailed perspective not only enhances transparency but also allows LLMs to validate predictions by tracing them back to specific, clinically meaningful intervals. However, while MIL excels at interpretability, it does not inherently quantify uncertainty. Conformal prediction addresses this gap by producing set- valued predictions at predefined confidence levels [15], thereby providing an clear measure of reliability. By combining MIL's interpretability with conformal prediction's reliability, we cre- ate a compelling paradigm that can bolster both transparency and trustworthiness. Ultimately, this integration can transform SSMs into safer and more actionable supportive plug-in for visual inspection of LLMs on medical time series.\nWe introduce ConMIL (Conformalized Multiple Instance Learning), a supportive SSM to enhance the visual inspection capabilities of LLMs on Medical time series data. ConMIL offers two main advantages: First, unlike conventional MIL methods that only handle single positive class (e.g., single diagnosis), we proposed QTrans-Pooling mechanism. This mechanism uses learnable class tokens and cross-attention to identify the most salient data segments for each class, facil- itating intuitive understanding. This is particularly beneficial in scenarios with multiple diagnoses, outcomes, or treatment options. Second, ConMIL incorporates conformal prediction to deliver class-specific confidence measures by dynamically adjusting prediction thresholds based on calibration sets. This approaches ensures that every reported prediction is supported by a rigorously quantified level of reliability. To our knowl- edge, ConMIL is the first to combine conformal prediction with MIL, marking a notable advancement in healthcare AI. Crucially, ConMIL embodies a strategic shift in how SSMs enhance clinical decision-making by leveraging LLMs for visual inspection of medical time series data. By providing in- terpretable, confidence-calibrated set-valued outputs, ConMIL reduces the risk of misdiagnoses and misclassifications com- pared to opaque black-box models. The synergy between MIL's interpretability and conformal prediction's uncertainty quantification is designed to meet the demands of high-stakes healthcare contexts. Through comprehensive evaluations, including sleep stage and arrhythmia classification (see Section V-C), we demonstrate that integrating ConMIL with LLMs substantially improves diagnostic accuracy. These findings underscore the importance of combining interpretability and set-valued prediction to advance reliable and effective AI-informed clinical decision support."}, {"title": "II. RELATED WORKS", "content": "Medical time series, such as ECG and EEG signals, are crit- ical for monitoring health, diagnosing diseases, and predicting clinical outcomes. Tasks like detecting arrhythmias from ECG [16], predicting seizures from EEG [17], and classifying sleep stages [18] rely on accurate classification. While traditional approaches used feature engineering and classical machine learning [19], [20], deep learning models, including CNNs [3], [21]\u2013[23], and transformer-based architectures [4], [24]\u2013[26] now dominate the field due to their ability to handle complex temporal patterns.\nMIL addresses tasks where labels exist at the bag level, with only some instances within a bag relevant to the label [27]. Applied to time series, MIL identifies critical segments that contribute to classification [5], [6], making it highly interpretable and effective in noisy medical data. Unlike post-hoc interpretation methods such as SHAP [28] or LIME [29], MIL directly integrates interpretability into the modeling process, ensuring robust performance and precision in high-stakes domains like healthcare.\nConformal prediction [15] offers set-valued predictions with predefined coverage, ensuring rigorous uncertainty quantifi- cation. Its adaptability to complex tasks like MIL remains underexplored but holds promise for enhancing reliability and interpretability in medical time series classification. Compared to Bayesian approaches [30] or Monte Carlo dropout [31], conformal prediction guarantees valid coverage, is compu- tationally efficient, and is non-parametric, making it partic- ularly suited for medical applications where accuracy and interpretability are critical.\nLLMs are transforming clinical decision-making by sup- porting diagnostics, treatment recommendations, and risk as- sessment. Models like Med-PaLM [8] have demonstrated near-expert-level performance in standardized exams through domain-specific pre-training and structured prompts. These models excel in nuanced medical reasoning, including step-by- step diagnostic queries, and have shown promise in analyzing visual data like ECGs [10] and supporting applications in sleep medicine [9]. The integration of LLMs into clinical workflows enhances accuracy, reduces cognitive load, and broadens AI's utility in healthcare."}, {"title": "III. CONFORMALIZED MULTIPLE INSTANCE LEARNING", "content": "This section delves into the motivations, foundational prin- ciples, and algorithmic underpinnings of ConMIL, providing a comprehensive explanation of its design and technical validity.\nWe first formulate the problem of time series classification in the context of medical data. Given a time series input X = [x\u2081,x\u2082,...,x\u209c], where each x\u209c \u2208 \u211d\u207f represents a n-variates feature vector recorded at time t, the goal is to assign the correct class label y \u2208 \ud835\udcb4 = {1, ...,\ud835\udc3e} from K possible classes. These classes may represent different medical conditions or diagnostic categories, such as arrhythmia types, sleep stages, or seizure events.\nTime series classification can naturally be formulated as a MIL problem by treating each time series as a \"bag\", where each time step is considered an instance. In conventional MIL, the model learns a binary mapping f : \ud835\udcb3 \u2192 \u0177, which aggregates information across all instances within the bag to predict the bag-level label. This can be formally defined as:\nYi = \\{\n0, iff \u03a3\u209c=\u2081\u1d57 \u0177\u209c = 0, y \u2208 {0,1}\n1, otherwise,\n(1)\nwhere y represents the instance-level label at time point, indicating whether an event of interest has occurred at that time step x. For a multi-class classification problem with K classes, time series classification can be extended by perform- ing several one-vs-rest binary MIL tasks without violating the assumptions of MIL. Formally, this is defined as:\nYi,k = \\{\n0, iff \u03a3\u209c=\u2081\u1d57 \u0177\u209c,k = 0, \u0177\u209c,k \u2208 {0,1}\n1, otherwise,\n(2)\nwhere \u0177\u2096 denotes the instance-level label at time point t, representing the contribution to class k \u2208 {1,..., \ud835\udc3e}. The final bag-level prediction is determined by selecting the class with the highest probability, indicated by \u0177\u1d62 = arg max\u2096 Yi,k.\nConformal prediction is a framework designed to provide reliable uncertainty estimates for model predictions. Instead of outputting a single predicted label, conformal prediction gen- erates a set-valued prediction that contains the true label with a user-defined probability, known as the coverage. In medical settings, for instance, conformal prediction can offer a set of possible diagnoses, guaranteeing that the correct diagnosis is included in this set with at least 1 - \u03b1 confidence, where \u03b1 represents the error rate or miscoverage rate. Formally, given the ground truth label y, the input time series, our goal is to construct a set-valued prediction S\u03b1(\ud835\udcb3) \u2286 \ud835\udcb4 such that:\nP(y \u2208 S\u03b1(\ud835\udcb3)) \u2265 1 \u2013 \u03b1,\n(3)\nfor a pre-specified miscoverage rate, such as 10%.\nWe first recap the approximation of the general MIL meth- ods stated in [32], [33],\nTheorem 1. Suppose the score function S is a (\u03b4\u03b5,\u03b5)- continuous symmetric function w.r.t Hausdorff distance dH(\u00b7,\u00b7). For any invertible map \u03c8 : \ud835\udcb3 \u2192 \u211d\u1d48, S can be approximated by certain continuous functions g and f:\n|S(Xi) \u2013 g(\u03c8{\u03c6(x) : x \u2208 X\u00ec})| < \u03b5,\n(4)\nwhere x denotes the tth instance of the bag Xi.\nThis theorem presents the pipeline of MIL paradigm that exist- ing architectures typically consist of three main components: 1) a feature extractor \u03c6(\u00b7), which processes the input time se- ries \ud835\udcb3 and extracts a set of d-dimensional feature embeddings Z\u2208 \u211d\u1d40\u00d7\u1d48 = [z\u2081, z\u2082,..., z\u209c]; 2) a MIL pooling layer \u03c8(\u00b7), which computes a weighted feature vector Zpool \u2208 \u211d\u1d48 along with corresponding attention weights A = [a\u2081, a\u2082,..., a\u209c], where at \u2208 {0,1}, for each instance, offering interpretability by highlighting the contributions of individual time steps to the final decision; and 3) a classifier g(\u00b7) which takes the pooled feature vector Zpool as input and outputs class probabilities. Formally, the MIL can be formulated as following general process:\nZ = \u03c6(\ud835\udcb3), {Zpool, A} = \u03c8(Z), \u0177 = g(Zpool) (5)\nOur study begins by examining the limitations of two recent MIL methods\u2014Conjunctive Pooling [6] and Trans-Pooling [5]\u2014within the context of time series analysis. Conjunctive pooling [6] is a novel pooling method that independently ap- plies instance-wise attention and classification to the time point embeddings, followed by scaling the time point predictions using the corresponding attention values. Slightly different from the general process, conjunctive pooling is defined as:\nYt = g(zt), \u0177 = (1/T)\u03a3\u209c=\u2080\u1d40(at\u0177t), at \u2208 {0,1} = \u03c3(WAzt). (6)\nIn this formulation, at is the attention value assigned to each time point t, calculated by applying a sigmoid activation \u03c3 to the feature vectors WAzt.\nOn the other hand, Trans-Pooling [5] introduces the use of Transformers [24] in MIL, leveraging their self-attention mechanism to capture dependencies between a learnable class"}, {"title": "token", "content": "zels and each instance. Formally, the process is defined\n\u0177 = g(cls),\n2 = Attention(WQZcls, WK Zcls, WV Zcls)WO\n= [cls, 21,..., 2T],\nwhere WQ, WK, WV,and WO are trainable parameters, the\nself-attention mechanism is computed as:\nAttention(Q, K, V) = softmax((QK\u1d40)/\u221ad)V,\n(7)\nand 2 = [zcls, Z1,..., ZT] is the concatenation of the class token zcls and the instance embeddings 21,..., Z. The atten- tion mechanism enables the model to weigh the importance of each instance in relation to the class token, refining the pooled representation cls for final classification.\nWe observed that these while both methods were helpful, they did not fully meet our objective of per-class interpretabil- ity. These methods focus on providing insight into the model's final prediction by identifying which time steps are most influential to the overall classification. However, they do not offer insights into the contributions of individual time steps for each potential class. In other words, while the attention mechanisms in both conjunctive pooling and Trans-Pooling provide useful explanations for the final decision, they do not offer a breakdown of how each instance relates to every possible class in multi-class classification tasks.\nTo address this, we proposed the QTrans-Pooling used in ConMIL as illustrated in Fig. 1. Inspired by the work of [5], we also implement QTrans-Pooling with learnable class tokens and Transformers. Considering the instance importance can be measured by the attention maps between class tokens and instances, to achieve per-class interpretability can be imple- mented via assigning each class an independent class token. To this end, we introduce a separate class token zils, allowing the model to compute class-specific attention weights for each instance. In QTrans-Pooling, cross-attention between the class tokens and instance embeddings used to achieve per-class interpretability. Given the class tokens Zcls = [zqls,...,zels], and instance embeddings Z = [21,..., zT], the cross-attention is computed as follows:\nAttention(Q, K, V) = \u03c3((QK\u1d40)/(a + b)V), b = -log(T),\n(8)\nwith Q = WQZcls, K = WKZ, V = WVZ. The bias term is defined as b and ois the Sigmoid function. Sigmoid attention [34] is used since the softmax function may possibly cause attention to focus on a few features while ignoring other information. This process allows the class token zels to attend to the embeddings of the instance, resulting in an attention map Ak = [ak,1, ak,2,..., ak,T], where each ak,t represents the importance of time step t for class k.\nThe use of cross-attention between class tokens and instance embeddings is pivotal for achieving per-class interpretability. By assigning a distinct learnable class token to each class, the model can independently compute the relevance of each instance to each class. This capability is particularly significant in multi-class medical time series classification tasks, where understanding the contribution of individual time segments to multiple potential diagnoses is critical for informed clin- ical decision-making. Moreover, the use of independent class tokens allows the model to disentangle overlapping features across different classes, resulting in more precise and inter- pretable predictions. For example, in ECG analysis, specific time segments may correspond to different heart rhythm abnormalities, and per-class tokens help clarify which signal features are relevant to each diagnosis. We further provide an information-theoretical justification to validate this property.\nTheorem 2. Compared with Trans-Pooling [5], ap- plying QTrans-Pooling with Per-Class Interpretability may lower class-wise variability and hence reduce the complexity of developing a good classifier in latent space. We use class-conditioned entropy to describe the homogeneity of feature space in a specific class:\nH(2zqds,..., zus) \u2264 H(\u017b|zcls),\n(9)\nwhere H(\u017b|zals,\u2026\u2026\u2026, z) denotes modeling instances within a class with per-class token by our method while H(2|cls) denotes modeling instances within a class with only one global token by Trans-Pooling.\nProof. The proof is straightforward, as conditioning on addi- tional information can only maintain or lower the conditional information [35].\nA reduction in class-conditioned entropy implies that features within the same class form tighter clusters, thereby reducing variability between classes. Consequently, minimizing class-wise variability across all classes facilitates the identification of simpler and more robust decision boundaries for classification.\nLower class-conditioned entropy enhances confidence in assigning instances to their correct classes, improving classification reliability and inter- pretability.\nWe now discuss how to achieve reliable set-valued predic- tion with per-class coverage guarantees by integrating confor- mal prediction into ConMIL. To this end, we aim to construct set-valued prediction that control the FNR for each class k, ensuring that the true class is included in the set-valued prediction with high probability. We consider implementing ConMIL under the split conformal prediction setting [36]. We reserve a dataset calibration dataset which remains unseen"}, {"title": "during training", "content": "the MIL model, we seek to seek to construct\na set-valued prediction Sa (Xtest) of the new test data which\nis valid in the following sense:\nP(Ytest \u2208 Sa (Xtest) | Ytest = k) \u2265 1 -\u03b1,\n\u2200k \u2208 {1,..., \ud835\udc3e},\n(10)\nwhere \u03b1 is the predefined confidence level and Sa (X) repre- sents the set-valued prediction for input X. This guarantees that for each class k, the true class is captured with at least 1 - \u03b1 probability, controlling the likelihood of missing a true positive (i.e., controlling the FNR).\nFor each class k, the FNR in a dataset \ud835\udc9f =\n{(X\u2081,Y\u2081), ..., (X\ud835\udc41, Y\ud835\udc41)}, where N represents the number of samples, can be defined in terms of a risk function. The risk function quantifies the empirical likelihood that the presence of class k is not correctly predicted in the data set. Formally, the risk for class k is defined as:\nRk(\ud835\udc9f) = 1/Nk \u03a3\u1d62\u208c\u2080\u1d3a \u2161(Yi \u2208 Sa(Xi)),\n(11)\nwhere Nk is the number of samples in \ud835\udc9f with true class label k, \u2161 is the indicator function that equals 1 if the condition is satisfied and 0 otherwise, Yi \u2208 Sa(Xi) indicates whether the true label is included in the set-valued prediction. In binary classification, the model's final prediction is often decided by thresholding the predicted probability with a predefined thresh- old \u03bb. The binary prediction \u0177\u1d62 is determined by rounding the predicted probability p(Xi):\n\u0176i = \\{\n1, if p(Xi) \u2265 1 \u2013 \u03bb,\n0, otherwise.\n(12)\nThe per-class FNR is controlled by selecting an appropriate threshold \u03bb such that the set-valued prediction includes the true class label with the desired coverage probability. To generalize this for multi-class classification, we assign a threshold \ud835\udf06 for each class k, forming a set of thresholds \u03bb = {\u03bb\u2081,...,\u03bb\u03ba}. These thresholds act as additional parameters for constructing the set-valued prediction Sa (Xi, \u03bb), which is defined as:\nSa(Xi, \u03bb) := {\u0177i,k : p(Xi) \u2265 1 \u2212 \u03bb\u2096}.\n(13)\nThis formulation ensures that the set-valued prediction in- cludes all classes for which the predicted probability exceeds the class-specific threshold \u03bb\u03ba.\nFor picking the threshold \u03bb, Conformal Risk Control (CRC) [37] is a natural choice, as it provides a principled framework for balancing coverage guarantees with risk control. CRC extends traditional conformal prediction by incorporating the notion of risk minimization, allowing us to adjust thresholds dynamically to ensure that the set-valued prediction achieves a predefined level of reliability while controlling FNRs across multiple classes.\nGiven an arbitrary bounded risk function R\u03bb(\u00b7) \u2208 (-inf, B] for some B < inf that is monotonically non-increasing with respect to the threshold \u03bb, the goal of CRC is to select the smallest possible threshold such that the risk remains controlled at a predefined level. Formally, for a given calibration dataset \ud835\udc9fcal and a risk level \u03b1, CRC selects \u03bb such that the risk on the test data \ud835\udc9ftest is controlled:\nE[R(\ud835\udc9ftest)] \u2264 \u03b1,\n(14)\nwhere the optimal threshold \u00c2 is selected by solving the following optimization problem:\n\u03bb: = inf{\u03bb: (N+1/N ) R\u03bb(\ud835\udc9fcal) + (\u03b1/\u03b1+1)\u2264\u03b1} (15)\nwhere R\u03bb(\ud835\udc9fcal) is the empirical risk based on the cali- bration data.\nBy using CRC, we are able to dynamically adjust the threshold \u03bb on the calibration dataset to achieve the per- class coverage. To demonstrate that CRC provides guarantees, we first relax the assumption of independent and identically distributed (i.i.d.) data and instead consider an exchangeable data distribution.\nLet \ud835\udcb3 and \ud835\udcb4 represent the time series input and label space, respectively. A data distribution in \ud835\udcb3 \u00d7 \ud835\udcb4 is said to be exchangeable if and only if the following condition holds:\nP((X\u03c0(1), Y\u03c0(1)),..., (X\u3160(N), Y\u03c0(N)))\n= P((X1,Y1), ..., (XN, YN))\n(16)\nfor any finite sample {(Xn, Yn)}n=1 , where \u03c0(\u00b7) denotes an arbitrary permutation of the dataset indices.\nUnder the assumption of an exchangeable data distribution, CRC provides exact guarantees as stated in the following theorem."}, {"title": "Theorem 3.", "content": "(Conformal risk control over exchange- able data distribution) Given a risk function R\u03bb that is right-continuous and non-increasing with respect to \u03bb, and a calibration dataset \ud835\udc9fcal = {Dn}n=1 containing N data points, we also denote any test point as DN+1. If the calibration and test datasets are sampled from an exchangeable distribution \ud835\udcb3 \u00d7 \ud835\udcb4, then the following conditions hold:\nR\u03bbmax (Dn) \u2264 \u03b1,\nsup R\u03bb (Dn) \u2264 B < \u221e almost surely. (17)\nand thus,\nE[R\u03bb(DN+1)] \u2264 \u03b1.\n(18)\nwhere \u03bb is the optimal threshold selected by CRC as per Eq. 15.\nLet the risk over the union of the calibration set and a test point be denoted as:\nR\u03bb(Dun) = R\u03bb (\ud835\udc9fcal UDN+1)\n= (1/(N+1)) \u03a3\u2099=1\u1d3a\u207a\u00b9 R\u03bb (Dn).\n(19)\nWe aim to find the smallest \u03bb that satisfies:\n\u03bb' = inf {\u03bb: R\u03bb(Dun) \u2264 \u03b1}.\n(20)\nGiven that inf\u03bb R\u03bb(Dn) = R^max (Dn) \u2264 \u03b1 and R\u03bb(DN+1) < B, we can compute:\nR\u03bb(Dun) = (N/(N+1)) R\u03bb(\ud835\udc9fcal) + (1/(N+1)) R\u03bb(DN+1)\n= (N/(N+1)) R\u03bb(\ud835\udc9fcal) + (1/(N+1)) B\n< (N/(N+1)) R\u03bb(\ud835\udc9fcal) + (1/(N+1)) B.\n(21)\nThus, we have the condition:\n(N/(N+1)) R\u03bb(\ud835\udc9fcal) + (1/(N+1)) B<a \u21d2 R\u03bb(Dun) \u2264 \u03b1.\n(22)\nIf the inequality holds for some \u03bb, \u03bb' < \u00c2. Conversely, if the inequality fails for all a, then \u00c2 = \u03bbmax \u2265 \u03bb'. Therefore, we have \u03bb' < \u00c2 almost surely.\nFinally, since R\u03bb non-increasing in \u03bb, we conclude:\nE[R\u03bb(DN+1)] \u2264 E[R\u03bb' (DN+1)].\n(23)\nNow, to complete the proof, we need to showE[R\u03bb' (DN+1)] < \u03b1.\nGiven the exchangeability of the datasets, let \u2130 represent the multiset of risks {R\u03bb(D\u2081), ..., R\u03bb(DN+1)}. The threshold \u03bb is a constant conditional on \u2130, meaning that:\nR\u03bb(Dn)|\u2130 ~ Uniform({R\u03bb(D\u2081), ..., R\u03bb(DN+1)}).\n(24)\nSince R\u03bb is right-continuous, we have:\nE[R\u03bb' (DN+1)|\u2130] = (1/(N+1)) \u03a3\u2099=1\u1d3a\u207a\u00b9 R\u03bb (Dn) \u2264 \u03b1.\n(25)\nThus, we conclude that CRC provides the risk guarantee:\nE[R\u03bb(DN+1)] < \u03b1\n(26)\nIn real-world applications, medical time series data are often sampled from non-stationary distributions, meaning the datasets may not adhere to the assumption of exchangeable data distribution. For instance, data might be collected from different individuals, across diverse demographic groups, or using various hardware conditions. In such cases, it becomes essential to assess the conformal guarantees under distribu- tional shifts.\nTo address this, we rely on the results of non-exchangeable split conformal prediction as introduced by [38], which allows us to quantify the coverage gap \u0394cov = \u03b1 \u2212 \u03b1*, where \u03b1 is the specified risk level and \u03b1* is the observed risk level. This gap can be bounded using the total variation (TV) distance.\nGiven a bounded function h : S \u2192 [0, B] on a measurable space (S,A) and let P and Q be two probability measures on (S, A), then:\n|Ep[h] - EQ[h]| \u2264 Bdtv(P,Q)\n(27)\nwhere dtv(P,Q) = suph |Ep[h] \u2013 EQ[h]].\nIntuitively, dtv measures the largest distance between two distributions. Using this measure, we can bound the coverage guarantee of CRC when the test data comes from a non- exchangeable distribution. In this scenario, we assume that while the calibration set is sampled from an exchangeable distribution, the test samples are drawn from a distinct dis- tribution.\n(Conformal risk control over non- exchangeable data distribution) Given risk function R\u03bb with the same properties as Theorem 3, assume that the calibration data \ud835\udc9fcal = {Dn}n=1 and the test data point DN+1 are sampled from non-exchangeable distributions. Under these conditions, CRC provides the following coverage guarantee:\nE[R\u03bb(DN+1)] < \u03b1 + B \u03a3\u2099=1\u1d3a dtv (Dn, DN+1).\n(28)\nwhere the coverage gap is bounded by the total varia- tion distance:\n\u0394cov = B \u03a3\u2099=1\u1d3a dtv(Dn, DN+1)\n(29)\nLet the risk values R\u03bb (Dn) for the calibration and test data form a sequence of random variables R = {R\u2081, ..., RN, RN+1}. Define another sequence of random variables R' = {R'\u2081, ..., R'N, RN+1}, where Rin = Rn+1. By the properties of total variation, let e =\n \u0392\u03a3\u2099=1 drv (Rn, Rn), and since drv(Rn, Rn) \u2264 Be by sublinearity. We can write:\n|ER[h] \u2013 ER' [h]| \u2264 \u0392\u20ac.\n(30)\nwhere h(R) = R\u03bb(DN+1). Since R' are exchangeable, we apply Theorem 3 to ER' [h], and substituting this into the equation above yields:\nE [R\u03bb(DN+1)] \u2264 a + B\u03a3\u2099=1\u1d3a drv (Dn, DN+1).\n(31)\nThus, in the non-exchangeable setting, the coverage guaran- tee provided by CRC remains valid, albeit with an additional term  Cov = \u0392\u03a3\u2099=1\u1d3adtv (Dn, DN+1), which quantifies the deviation of the test distribution from the calibration distribution. This term ensures that CRC accounts for the"}, {"title": "shift between", "content": "the two distributions, providing a more realistic coverage estimate under non-stationary conditions.\nThis section explores how ConMIL enhances the ability of LLMs to perform visual inspection of time series data, detailing its integration and functional contributions within the workflow.\nAs previously noted, fine-tuning LLMs often encounters significant barriers. To address this, ConMIL, as a support- ive SSM, serves as the primary domain-specific model. It augments pretrained LLMs, enabling robust and interpretable visual inspection of medical time series data. The integration of ConMIL with LLMs follows a two-phase pipeline, as illustrated in Fig. 2 (A).\nDuring the training phase, ConMIL leverages a MIL model equipped with the QTrans-Pooling mechanism (discussed in Section III-B) to extract meaningful patterns from medical time series data. This approach ensures that the model iden- tifies clinically significant features while preserving inter- pretability for each class. Such interpretability is crucial for multi-class medical tasks, including differentiating between sleep stages or types of arrhythmia.\nIn the calibration phase, the supervised MIL model is con- formalized using CRC techniques (Section III-C) to calibrate the MIL model on the calibration set, resulting in reliable conformal thresholds. These thresholds enable ConMIL to generate set-valued predictions with predefined confidence guarantees, accompanied by rigorous uncertainty quantifica- tion. This calibration step enhances the reliability of clinical decision-making.\nPost-deployment, ConMIL generates set-valued predictions for new medical time series data, supplemented by interpre- tive visual and textual prompts. These outputs are processed by LLMs, which apply their broader contextual reasoning to refine diagnostic conclusions. For instance, ConMIL can highlight key time-series segments associated with specific di- agnoses on visual plots while providing confidence-calibrated predictions. LLMs interpret these inputs to generate actionable insights, ensuring they are guided by domain-specific expertise while maintaining versatility in clinical workflows.\nThe decision rules governing the integration of ConMIL and LLMs, as shown in Fig. 2 (B), are designed to enhance reliability and trustworthiness in clinical settings. These rules leverage the set-valued predictions from ConMIL and their interpretation by LLMs.\nWhen ConMIL generates a singleton prediction (a single class in the prediction set), LLMs interpret the result directly using the associated interpretability prompts. The (1 \u2013 a)% confidence guarantee ensures high reliability, enabling the generation of precise clinical recommendations with minimal uncertainty.\nFor predictions containing multiple possible classes, LLMs rely on the per-class interpretability provided by ConMIL to prioritize the most likely diagnosis. The decision is guided by visual and textual explanations for each potential class, fostering a transparent and collaborative diagnostic process. For example, the LLMs can explain why one diagnosis is more plausible than others based on key features highlighted by ConMIL.\nIf ConMIL pro- duces a prediction set encompassing all possible classes, signaling low confidence, the case is flagged for clinician review. This ensures that ambiguous or high-risk scenarios are escalated to human experts, prioritizing patient safety and preventing potential misdiagnoses."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "We conduct our experiments using the SleepEDF [39] and PTB-XL [40] datasets. These datasets are used for sleep stage classification and arrhythmia classification, re- spectively-tasks that are typically performed through visual inspection by clinicians or specialists in clinical settings.\nThe SleepEDF dataset comprises 153 full-night polysomnographic (PSG) recordings, which include EEG, EOG, chin EMG, and event markers. These recordings were collected as part of a study conducted between 1987 and 1991 to examine the effects of aging on sleep in healthy Caucasians aged 25 to 101 years. No sleep-related medications were administered during the study, ensuring that the data reflect natural sleep patterns. Sleep stages are annotated in 30-second epochs based on the Rechtschaffen and Kales (R&K) standard [41], categorized into Wake (W), REM, and Non-REM (N1, N2, N3). For this study, we focus on the Fpz-Cz EEG channel and segment the recordings into 3000- point windows corresponding to the annotated sleep stages. A subject-wise split is implemented, with 60% of subjects allocated to the training set, 20% to the validation set, and 20% to the test set.\nThe PTB-XL dataset is a compre- hensive and publicly available ECG dataset containing 12- channel recordings from 18,869 subjects. These recordings are labeled with five diagnostic categories, including four types of heart disease and one healthy control. To ensure consistency, only subjects with uniform diagnoses across all trials are included, reducing the dataset to 17,596 subjects. The dataset is available at two sampling frequencies: 100Hz and 500Hz. For this study, we use the 500Hz recordings, which are subsequently downsampled to 250Hz. Standard scaling is applied to normalize the data. Each 10-second recording is segmented into non-overlapping 5-second samples, yielding a total of 191,400 samples. A subject-independent split is used to ensure robust evaluation, with 60% of subjects assigned to the training set, 20% to the validation set, and 20% to the test set.\nTo underscore the importance of rethinking the role of SSMs, we compare the"}, {"title": "performance of", "content": "Con"}]}