{"title": "Skillful High-Resolution Ensemble Precipitation Forecasting with an Integrated Deep Learning Framework", "authors": ["Shuangshuang He", "Hongli Liang", "Yuanting Zhang", "Xingyuan Yuan"], "abstract": "High-resolution precipitation forecasts are crucial for providing accurate weather pre- diction and supporting effective responses to extreme weather events. Traditional nu- merical models struggle with stochastic subgrid-scale processes, while recent deep learn- ing models often produce blurry results. To address these challenges, we propose a physics- inspired deep learning framework for high-resolution (0.05\u00b0\u00d7 0.05\u00b0) ensemble precipi- tation forecasting. Trained on ERA5 and CMPA high-resolution precipitation datasets, the framework integrates deterministic and probabilistic components. The determinis- tic model, based on a 3D SwinTransformer, captures average precipitation at mesoscale resolution and incorporates strategies to enhance performance, particularly for moder- ate to heavy rainfall. The probabilistic model employs conditional diffusion in latent space to account for uncertainties in residual precipitation at convective scales. During infer- ence, ensemble members are generated by repeatedly sampling latent variables, enabling the model to represent precipitation uncertainty. Our model significantly enhances spa- tial resolution and forecast accuracy. Rank histogram shows that the ensemble system is reliable and unbiased. In a case study of heavy precipitation in southern China, the model outputs align more closely with observed precipitation distributions than ERA5, demonstrating superior capability in capturing extreme precipitation events. Addition- ally, 5-day real-time forecasts show good performance in terms of CSI scores.", "sections": [{"title": "Plain Language Summary", "content": "Deep learning models often produce blurring results and reduced intensity in pre- cipitation predictions. We developed a deep learning framework that achieves skillful high- resolution precipitation forecasting in this study. Our model combines deterministic and probabilistic components to capture large-scale precipitation patterns and the uncertain- ties associated with smaller, intense convective activity. Using coarse-resolution (0.25\u00b0) atmospheric variables (temperature, pressure, humidity, geopotential and wind) from NWP or data-driven models as inputs, the model is able to generate high-resolution (0.05\u00b0) pre- cipitation predictions. The evaluation results show that our ensemble forecasting sys- tem exhibits unbiased results and demonstrates superior performance in capturing ex- treme precipitation events. Additionally, we implemented a real-time forecasting system using ECMWF open data, which further demonstrates the model's robustness and re- liability."}, {"title": "1 Introduction", "content": "Accurate prediction of precipitation, particularly at high spatial and temporal res- olutions, is critical for numerous applications, including flood forecasting, water resource management, and disaster mitigation (Trenberth et al., 2011). However, precipitation forecasting remains one of the most challenging tasks in atmospheric sciences due to the inherent complexity and stochastic nature of small-scale atmospheric processes (Bauer et al., 2015).\nIn traditional numerical weather prediction (NWP) models, precipitation is often parameterized due to their inability to explicitly resolve small-scale convective processes and microphysical processes (Molinari & Dudek, 1992; Iorio et al., 2004; Skamarock et al., 2005). These parameterization schemes attempt to approximate the effects of un- resolved processes on grid-scale fields, but they introduce significant biases and errors (Tiedtke, 1989; Kain & Fritsch, 1993; Molteni et al., 1996; Palmer et al., 2005). As a re- sult, the accuracy of traditional models in predicting small-scale precipitation events, such as convective storms or heavy rainfall, is often limited (Zhao et al., 2021; Allen et al., 2022). Moreover, running sophisticated NWP models at high spatial resolutions to bet- ter resolve precipitation processes comes with immense computational costs, making real- time operational forecasting a challenge (Tang et al., 2013). This trade-off between model"}, {"title": "resolution and computational cost remains a significant limitation of traditional weather prediction approaches.", "content": "Recent advancements in deep learning offer promising alternatives to improve both the accuracy and efficiency of weather forecasting. Models such as Pangu-Weather, Graph- Cast, and Fuxi have demonstrated the potential of data-driven approaches to produce accurate weather forecasts at a fraction of the computational cost of traditional NWP models (Bi et al., 2023; Lam et al., 2023; Chen et al., 2023). These models utilize large datasets and leverage architectures like transformers or graph neural networks (GNN) to capture complex atmospheric patterns from data, making it possible to generate faster predictions without the need for explicit physical modeling. Despite these advancements, challenges persist in precipitation forecasting, particularly in maintaining spatial detail over longer forecast lead times. Many deep learning models tend to produce overly smoothed and weaker outputs, losing the necessary detail required for accurate short-term precip- itation forecasting (Charlton-Perez et al., 2024; C.-C. Liu et al., 2024). Furthermore, mod- els trained on coarser-resolution data (e.g., 0.25\u00b0 spatial resolution and 6-hour tempo- ral intervals) are typically unable to capture the small-scale convective processes required for accurate precipitation prediction. Unlike variables such as temperature, wind, and pressure, which are directly governed by physical laws, precipitation is influenced by highly complex and stochastic microphysical processes (Ritchie et al., 1995), making it more challenging for deep learning models to predict. Some models, such as FourCastNet, have attempted to address this by training a separate diagnostic model using the outputs of the backbone network to predict precipitation (Pathak et al., 2022). However, most of the approaches still result in overly smoothed outputs (Zhou et al., 2022; H. Liu et al., 2024).\nRecently, diffusion models have emerged as a powerful probabilistic generative ap- proach, originally achieving remarkable success in image generation (Ho et al., 2020; Song et al., 2022; Rombach et al., 2022). Diffusion models add noise gradually, transforming complex distributions into simple Gaussian forms and then generating high-fidelity im- age samples through a reverse process. This framework offers unique advantages in cap- turing complex probability distributions, making it particularly useful for handling small- scale phenomena with high uncertainty. Some studies have already begun exploring the use of diffusion models for precipitation nowcasting (Gao et al., 2023; Asperti et al., 2023; Gong et al., 2024), showing promise in capturing uncertainties associated with convective- scale precipitation.\nIn this study, we propose a physics-inspired deep learning framework that combines the strengths of deterministic and probabilistic modeling approaches to address the chal- lenges of accurate high-resolution precipitation forecasting. The deterministic model cap- tures the meso-scale evolution of precipitation, while the probabilistic component, based on latent conditional diffusion, accounts for the uncertainties associated with small-scale convective precipitation. This approach allows the model to generate ensemble forecasts, providing a more comprehensive representation of uncertainty, particularly for extreme precipitation events. Our framework takes coarse-resolution atmospheric variables, such as temperature, pressure, geopotential, humidity, and wind at a 0.25\u00b0 resolution (from either traditional NWP or data-driven forecasts) as input and generates high-resolution precipitation forecasts at a 0.05\u00b0 resolution, with hourly predictions.\nThe key contributions of this paper are:\n1. We propose a novel deep learning framework for high-resolution ensemble precip- itation forecasting, combining a deterministic model to represent meso-scale evo- lution and a probabilistic model that captures uncertainties at the convective scale through diffusion model in the latent space.\n2. Our results demonstrate that the ensemble forecasts are nearly unbiased and the probabilistic distributions closely match the target precipitation distributions."}, {"title": "3. We successfully implemented a real-time forecast system for up to five days, with good performance on Critical Success Index(CSI) over the forecast horizon.", "content": "2 Data\n2.1 ERA5\nFor training our model, we built our datasets from ERA5 archive, the fifth gener- ation of ECMWF reanalysis dataset (Hersbach et al., 2020). ERA5 is generated using ECMWF's Integrated Forecast System (IFS) cycle 42r1, operational for most of 2016. It employs an ensemble 4D-Var data assimilation scheme that incorporates 12-hour win- dows of observations from 21-09 UTC and 09-21 UTC, along with previous forecasts, al- lowing for a dense representation of the weather's state for each historical date and time. ERA5 assimilates high-quality global observations, making it widely regarded as the most accurate and comprehensive reanalysis archive.\nWe use a subset of ERA5 dataset on a 0.25\u00b0 equiangular grid spanning 0-60\u00b0 N, 70- 140\u00b0 E. The grid overall contains 241 \u00d7 281 grid points for latitude and longitude, re- spectively. 5 surface variables and 5 upper-air variables at 13 pressure levels (correspond- ing to the levels of the WeatherBench (Rasp & Thuerey, 2021) benchmark: 50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, and 1000 hPa). The 5 upper-air atmospheric variables are geopotential(Z), temperature(T), u component of wind(U), v component of wind(V), and specific humidity(SH). Additionally, 5 surface variables are 2-meter tem- perature(T2M), 10-meter u wind component(U10), 10-meter v wind component(V10), mean sea level pressure(MSLP), and total precipitation(TP).\n2.2 CMPA\nA high-resolution precipitation dataset, CMPA, was utilized in this study (Xie & Xiong, 2011). Developed by the China Meteorological Administration (CMA), \u0421\u041c\u0420\u0410 combines multiple data sources, including observations from 30,000 to 40,000 ground- based stations, radar-derived quantitative precipitation estimates, and satellite precip- itation retrievals from FY-2E and CMORPH (CPC MORPHing technique). By merg- ing these sources, CMPA enhances the accuracy and resolution of precipitation measure- ments. It provides data at a high spatiotemporal resolution of 0.01\u00b0\u00d7 0.01\u00b0 and 1-hour intervals, covering the region from 15\u00b0N to 60\u00b0N and 70\u00b0E to 140\u00b0E (4500 latitude \u00d7 7000 longitude grid points).\nTo reduce computational burden, we applied nn. AvgPool2d with PyTorch to trans- form the dataset into a lower resolution of 0.05\u00b0 \u00d7 0.05\u00b0.\n2.3 ECMWF real-time forecasts\nSince February 2024, ECMWF has made open real-time medium-range forecast data (ECMWF, 2023) from the Integrated Forecasting System (IFS) available at an improved resolution of 0.25\u00b0\u00d7 0.25\u00b0. This dataset is publicly available and is well-suited for ma- chine learning applications, providing a valuable resource for enhancing forecast accu- racy. To generate high-resolution ensemble precipitation predictions, we use the forecast data from the 00 and 12 UTC initializations, spanning the next 120 hours at 3-hour in- tervals.\n2.4 Preprocessing\nAll other variables are normalized using the mean and standard deviation except for precipitation,. Specifically, for precipitation, we first convert the 1-hour accumulated precipitation TP (mm) to reflectivity (dBZ) using the following formula (Marshall & Palmer,"}, {"title": "1948):", "content": "dBZ = 10 \\times log_{10}(200 \\times TP^{1.6})\nAfterward, the ERA5 and CMPA precipitation data are typically normalized to the [0, 1] range using the spatial maximum averaged over time, following the method outlined by Bodnar et al. (2024):\ndBZscale = \\frac{1}{N} \\sum_{t=1}^{N}  \\frac{dBZ}{\\max \\{X_{t,i,j}: i = 1, ..., H; j = 1, ..., W\\}}"}, {"title": "3 Methodology", "content": "3.1 Problem formulation\nInspired by the approach used in numerical weather models, where physical vari- ables in the atmospheric governing equations can be represented as a combination of mean values and perturbations. The mean values correspond to the grid point values, and the perturbations account for sub-grid scale processes. These sub-grid processes are repre- sented using physical parametrization schemes.\nX_t = \\overline{X} + X'\nSimilarly, we assume that high-resolution precipitation is composed of the average pre-"}, {"title": "ERA5\nResidual", "content": "cipitation over a meso-scale $\\overline{TP}$, plus the residual precipitation at the sub-grid scale TP'.\nWe derive the residual precipitation TP' from the difference between scaled CMPA and ERA5 precipitation. ERA5 precipitation was interpolated to a 0.05\u00b0 grid resolution us- ing the nearest-neighbor method to match CMPA's resolution. As shown in Figure 2, we utilize a deterministic component for the mean precipitation and a latent diffusion component for the residual precipitation. Considering that processes on the sub-grid scale often exhibit randomness and uncertainty, we employ ensemble forecasting to capture and quantify these uncertainties. We run multiple stochastic sampling processes through the conditional diffusion model. Each sample represents a possible realization of the pre- cipitation field, conditioned on the same input atmospheric states.\nE = \\{TP_i : \\overline{TP} + TP'_i, i \\in [1, 11]\\}\n3.2 Deterministic model\n3.2.1 Model input\nThe deterministic model uses four ERA5 surface variables (T2m, U10m, V10m, and MSLP, with a shape of 4 \u00d7 241 \u00d7 281) and upper air variables at 13 pressure levels (T,"}, {"title": "Decoder\nTP", "content": "U, V, SP, and Z, with a shape of 5 \u00d7 13 \u00d7 241 \u00d7 281) of two consecutive time steps ([Xt\u22121, Xt]) to predict 1-hour accumulated precipitation at Xt. In addition to these variables, we also incorporated static features such as the binary land-sea mask, geopotential at the sur- face, soil type, latitude and longitude in radians, as well as temporal features including the sine and cosine of the local time of day and the sine and cosine of the yearly progress. These additional features were shown to improve the diagnostic prediction of precipita- tion, as demonstrated in the 4.1.\n3.2.2 Model architecture\nThe deterministic model architecture consists of three main components:\n1. Patch embedding, which divides the input variables into small patches and em- beds them into high-dimensional feature representations.\n2. 3D Swin-Transformer, which processes the embedded data by capturing both lo- cal and global features through multi-head self-attention mechanisms in spatial and temporal dimensions.\n3. Upsampler, which process the output of the 3D-Swin Transformer to produce the final precipitation prediction at the original data resolution.\nIn a standard patch embedding for vision transformers, convolution is typically used to project the input data into embedded patches. However, this approach produces out- puts that reflect only the linear relationships between the variables after convolution. To address this, we propose an non-linear approach: applying separate convolutions to each variable individually, followed by a GELU (Gaussian Error Linear Unit) activation. The outputs are then passed through an MLP layer and another GELU activation, ensuring that each patch integrates nonlinear information from the variables. We use a 4\u00d74 con- volution kernel for surface variables and a2 \u00d7 4 \u00d7 4 convolution kernel for upper air variables. This results in an output with a shape of C\u00d71\u00d761\u00d771 for the surface vari-"}, {"title": "Denoise\nModel\n\u03a4\u03a1'", "content": "ables and C \u00d7 7 \u00d7 61 \u00d7 71 for the upper-air variables. After patch embedding, these two outputs are concatenated along the channel dimension, creating a combined input with a shape of C \u00d7 8 \u00d7 61 \u00d7 71.\nThe input data, with a size of C \u00d7 8 \u00d7 61\u00d7 71, is processed through a 3D Swin- Transformer (Z. Liu et al., 2021) consisting of three layers. The first layer has 3 blocks and is followed by a patch merging operation that downsamples the data to 2C \u00d7 8 \u00d7 31\u00d736. In the second layer, which contains 9 blocks, the data is further processed and then upsampled back to its original size of C\u00d78\u00d761\u00d771 before being passed into the third layer, which also has 3 blocks. The output of the first layer is added to the out- put of the second layer through a skip connection. The outputs from both the first and second layers are added to the third layer's output via skip connections.\nFor generating the final output, we validated two methods. In the first method (Up- sampler1), we used a 3D convolution with a kernel size of (8 \u00d7 1 \u00d7 1), followed by bi- linear upsampling, which doubled the height and width dimensions as a shape of C \u00d71\u00d7 121 x 141. We then applied a 2D convolution with bilinear upsampling to restore the data to its original resolution of 1 \u00d7 241 \u00d7 281. In the second method (Upsampler2), we used a 3D convolution with a (8 \u00d7 1 \u00d7 1) kernel and a GELU activation to reduce the height dimension to 1. Afterward, we adopted an image reconstruction technique used by SwinIR (Liang et al., 2021), which includes several convolutional layers: one before upsampling, followed by others for further processing. These layers consist of LeakyReLU activations and multiple convolutions to refine the output, ultimately restoring the high- resolution data. A comparison of the results produced by these two methods can be found in the 4.1.\n3.2.3 Weighted loss function\nThe loss function used is the weighted L2 and SIMM (Structural Similarity Index Measure) loss, which is defined as follows:\nLoss = \\lambda_1 * (X_{i,j} - \\hat{X}_{i,j})^2 + \\lambda_2 * (1 - SSIM(X_{i,j} - \\hat{X}_{i,j}))\nwhere 11 and 12 are weights that balance L1 and SSIM, is set to 0.5 and 1.5 respectively. The SSIM loss (Wang et al., 2004) is sensitive to changes in contrast, luminance, and texture, making it more effective at preserving the spatial distribution and intensity of features like heavy rainfall.\n3.3 Probabilistic model\nThe probabilistic model is designed to generate residual precipitation, using the current atmospheric state plus mean precipitation as a conditional input. Two key ap- proaches are employed in this model: Variational Autoencoder (VAE) and Conditional Diffusion.\n3.3.1 Variational autoencoder\nTo improve the training efficiency of the diffusion model, we use a VAE model to encode the residual precipitation data, with dimensions 1 \u00d7 900 \u00d7 1400, into a latent representation of size 16\u00d790\u00d7140. The VAE is used to encode samples from the pixel space to a continuous latent space and then decode them back to the pixel space (Kingma & Welling, 2022). We train our autoencoder models following Rombach et al. (2022), which uses an adversarial manner to enhance the generative quality of the model. The encoder and decoder components of the VAE in this study are constructed as 2D convolutional networks. In the encoder, the first three layers contain two ResNet-type residual blocks and a downsampling block, each layer reduces the spatial dimensions by a factor of 2, while the final layer consists of two ResNet blocks without downsampling. Since our tar-"}, {"title": "Patchify\n\u2191\n\u2191\nEmbedding\n\u2191\nZT\nt", "content": "get size is not a power of 2, the feature maps are interpolated to the target resolution 90\u00d7140. The decoder mirrors the encoder structure, using upsampling to progressively restore the spatial resolution, and interpolation to match the final output size to the in- put. The latent space is regularized using a Kullback-Leibler (KL) divergence loss to align the latent variables with a multivariate standard normal distribution.\n3.3.2 Conditional latent diffusion model\nThe conditional diffusion model we use is based on the Denoising Diffusion Prob- abilistic Model (DDPM), which progressively corrupts a data sample by adding Gaus- sian noise over a series of timesteps. A neural network is then trained to reverse this nois- ing process, recovering the original data. The conditional latent diffusion model train-"}, {"title": "Patchify\n\u2191\n\u2191\nEmbedding\n\u2191\nZt", "content": "ing objective can be formulated as:\nL = E_{embedding(x),y,\\epsilon \\sim N(0,1),t} ||\\epsilon - \\epsilon_{\\theta}(Z_t, t, cond)||^2\nwhere x is the condition, which is the atmospheric state, y is the residual precip- itation, e is random noise, $t \\in [1,1000]$ is the time step of the denoising process, zt is the noisy latent-space sample at step t, eo is the denoiser and 0 represents the trainable parameters of the networks. In our setup, we train the denoise model conditioned on ERA5 surface variables (T2m, U10m, V10m, MSLP and TP) and upper air variables at 13 pres- sure levels (T, U, V, SP, and Z) to guide the denoising process and improve the accu- racy of the generated residual precipitation. During inference, we replace ERA5 precip- itation with the predicted 1-hour precipitation from the deterministic model.\nThe denoising network ee of our model referred to the DiT (Diffusion Transformer) architecture, a transformer-based model specifically designed for diffusion processes (Peebles & Xie, 2023). DiT utilizes self-attention mechanisms to capture both global and local dependencies in the data. The conditioning variables are first processed through a 2D patch embedding as the improved approach we proposed in 3.2.2. The patch size for the"}, {"title": "4 Results", "content": "4.1 Ablation study of deterministic model\nDue to the tendency of deterministic models to underestimate precipitation inten- sity and blurriness, we adopted several methods to improve the performance of precip- itation forecasting. These methods are as follows (For more details about these meth- ods, refer to 3.2.2:\n1. Exp-d1: Weighted MSE and SSIM loss: MSE ensures pixel-wise accuracy, while SSIM helps the model preserve the spatial distribution and intensity of features like heavy rainfall.\n2. Exp-d2:Incorporation of static and temporal (ST) features: Enables the model bet- ter learn local and temporal variations.\n3. Exp-d3:Non-linear patch embedding: Enhances the patch embedding by apply- ing depth-wise convolution and activation layers, allowing each patch to extract more non-linear interactions.\n4. Exp-d4:Refined upsampler: Employs additional convolutional layers in the upsam- pling decoder to improve the recovery of precipitation details.\nThe data from 2016 to 2019 were used as training dataset for the ablation study, with August, 2020 serving as the validation set. Figure 4 shows the CSI scores of dif- ferent experiments under various rainfall thresholds. From Figure 4, it is evident that all methods improved CSI scores for precipitation, with the enhancement becoming more pronounced as the precipitation intensity increases. In exp-d1, the use of weighted SSIM and MSE loss, compared to using only MSE as the loss function, improved the CSI scores for rainfall above thresholds of 2 mm, 5 mm, 10 mm, 15 mm, and 20 mm by 3.3%, 7.3%, 16.3%, 33%, and 50%, respectively. Building on exp-d1, we introduced static and tem- poral features in exp-d2. When compared to exp-d1, exp-d2 shows improvements at all thresholds, specifically by 1.3%, 3.2%, 5.1%, 14.6%, 34%, and 56.2%. Exp-d3 introduces nonlinear patch embedding compared to exp-d2. While the improvements are not very significant for lighter rainfall, with no noticeable gain at the 0.1 mm/h threshold and only"}, {"title": "4.2 Ensemble forecast evaluation", "content": "We conducted several evaluations using ERA5 variables as input to assess the model's performance, focusing on the period of August 2021.\n4.2.1 Real case-August 1, 2021\nThe results begin with a case study that effectively demonstrates the model's in- ference process. First, a deterministic precipitation forecast is generated at a 0.25\u00b0 grid resolution using the deterministic model. As shown in Figure 5, the overall precipita- tion distribution captures the spatial patterns of the target quite well, although the pre- dicted precipitation intensity is lower than the target.\nNext, Gaussian noise is sampled from the latent space and used as input for the denoising process, conditioned on both the atmospheric state and the deterministic pre-"}, {"title": "4.3 Real-time ensemble forecasting", "content": "We also develop a real-time high-resolution precipitation forecasting system using publicly available ECMWF data as input for our model. Since the ECMWF real-time open dataset provides forecasts at 3-hour intervals, we employ the Pangu-Weather model to perform 2-hour extrapolations, allowing us to obtain hourly atmospheric forecasts. Based on this data, we construct a high-resolution ensemble precipitation forecasting sys- tem for the next 120 hours.\nTo evaluate the system's performance in real-world scenarios, we compare the fore- cast results against CMPA precipitation as a reference. We assess the Critical Success Index (CSI), Probability of Detection (POD), and False Alarm Ratio (FAR) metrics. The forecast initialization times are at 12:00 UTC for each day from August 1 to August 31, 2021, with a forecast range of 120 hours."}, {"title": "5 Conclusion", "content": "This study proposes a physics-inspired deep learning framework that combines de- terministic and probabilistic modeling approaches to significantly improve the accuracy and spatial resolution of high-resolution precipitation forecasting. The model is trained using ERA5 and CMPA datasets, with atmospheric variables such as temperature, geopo- tential, humidity, and wind as input, and produces high-resolution precipitation forecasts at 0.05\u00b0 resolution. Built on a 3D Swin Transformer backbone, the deterministic model significantly improves diagnostic accuracy, especially for moderate to heavy rainfall, through improvements in patch embedding/recovery, loss function, and the incorporation of ge- ographic and temporal features. With atmospheric state and meso-scale precipitation as a constraint, a conditional diffusion model in latent space is applied to capture un- certainties at convective scales after compressing the data using VAE. During inference, ensemble forecasts are generated by random sampling of Gaussian noise in the latent space. Our evaluation shows that the constructed ensemble forecast system is nearly unbiased, and its precipitation distribution is closer to CMPA compared to ERA5. Additionally, we developed a real-time forecast system based on ECMWF's public dataset, which demon- strated robust performance in terms of CSI scores.\nOverall, this study presents a novel approach to high-resolution precipitation fore- casting. Due to data limitations, when transferring the model trained on ERA5 to ECMWF data, we didn't apply fine-tuning beyond adjusting the precipitation data scale in this study. Despite the high homogeneity between the two datasets, differences in resolution and other factors still introduce some discrepancies. In the future, as more data becomes available, we will apply model fine-tuning to further enhance the real-time forecast sys- tem's performance."}, {"title": "Data Availability", "content": "The ERA5 dataset used in this study was accessed from the Google Cloud pub- lic data archive, which can be found at https://console.cloud.google.com/storage/browser/gcp- public-data-arco-era5. The ECWWF open real-time forecast with 0.25\u00b0 resolution is avail- able at https://console.cloud.google.com/marketplace/product/bigquery-public-data/open- data-ecmwf; The CMPA precipitation dataset was provided by the China Meteorolog- ical Administration's National Meteorological Information Center."}, {"title": "Code Availability", "content": "Acknowledgments\nWe would like to thank the researchers at ECMWF for their invaluable work in offer- ing the ERA5 dataset and open operational data; and the colleagues for discussions and suggestions at ColorfulClouds Tech."}, {"title": "Appendix A Evaluation metrics", "content": "A1 POD, FAR and CSI\nPOD (Probability of Detection), FAR (False Alarm Ratio), and CSI (Critical Suc- cess Index) are widely used in forecast evaluations. The POD measures the fraction of observed events that were correctly predicted; the FAR measures the fraction of predicted events that did not occur; and the CSI quantifies the success of forecasts for hit rates.\nPOD = \\frac{Hits}{Hits + Misses}\nFAR = \\frac{False Alarms}{Hits + False Alarms}\nCSI = \\frac{Hits}{Hits + Misses + False Alarms}\nA2 Rank histogram\nThe rank histogram (Talagrand, 1999) shows the position of the ground truth within the ensemble distribution. For each time step and grid cell, rank the N ensemble mem- bers from lowest to highest for each observation and identify the rank of the observa- tion with respect to the forecasts. Rank histograms can help detect under or over-dispersion (Hamill, 2001; Wilks, 2011). Under-dispersion causes the ground truth to fall near or out- side the outer ensemble limits, creating a U-shaped histogram. Over-dispersion places the ground truth near the center, resulting in a n-shaped histogram. Peaks at either end may indicate bias in predictions. A flat rank histogram indicates unbiased ensemble fore- casts, with the true value equally likely to fall between any two ensemble values."}]}