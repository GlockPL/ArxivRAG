{"title": "The Recurrent Sticky Hierarchical Dirichlet Process Hidden Markov Model", "authors": ["Miko\u0142aj S\u0142upi\u0144ski", "Piotr Lipi\u0144ski"], "abstract": "The Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM) is a natural Bayesian nonparametric extension of the classical Hidden Markov Model for learning from (spatio-)temporal data. A sticky HDP-HMM has been proposed to strengthen the self-persistence probability in the HDP-HMM. Then, disentangled sticky HDP-HMM has been proposed to disentangle the strength of the self-persistence prior and transition prior. However, the sticky HDP-HMM assumes that the self-persistence probability is stationary, limiting its expressiveness. Here, we build on previous work on sticky HDP-HMM and disentangled sticky HDP-HMM, developing a more general model: the recurrent sticky HDP-H\u039c\u039c (RS-HDP-HMM). We develop a novel Gibbs sampling strategy for efficient inference in this model. We show that RS-HDP-HMM outperforms disentangled sticky HDP-HMM, sticky HDP-HMM, and HDP-HMM in both synthetic and real data segmentation.", "sections": [{"title": "1 INTRODUCTION", "content": "Hidden Markov Models (HMMs) are more and more popular techniques for modeling not only simple time series but also more complex spatio-temporal data. They have been successfully applied to natural language processing (Suleiman et al., 2017), speech recognition (Yuan, 2012), financial time series analysis (Maruotti et al., 2019), recognition of objects movement (Arslan et al., 2019; Fielding and Ruck, 1995), etc. HMMs posit that the time series values are closely linked to hidden, time-varying states, determining the characteristics of these values. They treat the recorded time series values as observations of a certain random variable, with the current hidden state influencing its probabilistic distribution. Hidden states themselves are modeled as observations of a latent random vari-"}, {"title": "2 BACKGROUND", "content": ""}, {"title": "2.1 Hierachical Dirichlet Prior Hidden Markov Models", "content": "The HDP-HMM enables full Bayesian inference of HMMs. The concept is to draw a prior global transition distribution from a Dirichlet process. Then, for each hidden state, a transition distribution is taken from the shared global prior. We start by introducing some notation for the Dirichlet process (DP).\nGiven a base distribution H on a parameter space \u0398 and a positive concentration parameter \u03b3, we construct a Dirichlet process $G \\sim DP(\\gamma, H)$ (sometimes also denoted by DP(H)) by the following stick-breaking procedure: let\n$\\beta \\sim GEM(\\gamma), \\theta_i \\overset{iid}{\\sim} H, i = 1,2,\\ldots,$,\nwhere $\\beta \\sim GEM(\\gamma)$ is a random probability mass function (p.m.f.) defined on a countably infinite set as follows:\n$\\nu_i \\sim Beta(1, \\gamma), \\beta_i = \\nu_i \\prod_{l=1}^{i-1} (1 - \\nu_l), i = 1, 2, \\ldots .$\nThe discrete random measure $G = \\sum_{i} \\beta_i \\delta_{\\theta_i}$ is a sample from DP(H), where $\\delta_{\\theta_i}$ denotes the Dirac measure centered on $\\theta_i$.\nThe HDP-HMM uses the DP to set a prior on the rows of the HMM transition matrix in a situation where the number of latent states may be potentially infinite. HDP-HMM is defined as\nDP shared global prior: $\\beta \\sim GEM(\\gamma)$,\n$\\theta_j \\overset{iid}{\\sim} H, j = 1,2,\\ldots,$\nTransition matrix prior: $\\pi_j \\overset{iid}{\\sim} DP(\\alpha \\beta), j = 1, 2, \\ldots,$\nLatent states: $z_t \\sim \\pi_{z_{t-1}}, t = 1,\\ldots,T,$\nObservations: $y_t \\sim f(y \\mid \\theta_{z_t}), t = 1,\\ldots,T.$\nHere, $\\beta$ and $\\{\\theta_j\\}_{j=1}^\\infty$ are specified as in the DP previously described, and then each transition distribution $\\pi_j$ for the state j is taken as a random sample from a second DP with the base measure $\\beta$ and the concentration parameter \u03b1. This parameter \u03b1 determines how close $\\pi_j$ is to the global transition distribution $\\beta$. At time t, the state of a Markov chain is indicated by $z_t$, and the observation $y_t$ is independently distributed given the latent state $z_t$ and the parameters $\\{\\theta_j\\}_{j=1}^\\infty$, with the emission distribution f(\u00b7). The sticky HDP-HMM from Fox (2009) modifies the transition matrix prior by introducing a point mass distribution with a stickiness parameter \u03ba to encourage state persistence. This is done by setting the transition matrix prior to $\\pi_j \\sim DP(\\alpha \\beta + \\kappa \\delta_j), j = 1,2,\\ldots,$ where $\u03b4_j$ is the Dirac measure centered on j.\nZhou et al. (2021) proposed a new model - Disentangled Sticky HDP-HMM, separating the strength of self-persistence from the similarity of the transition probabilities. The authors modified the transition matrix prior as"}, {"title": "2.2 Hierachical Dirichlet Prior Hidden Markov Models", "content": "The HDP-HMM enables full Bayesian inference of HMMs. The concept is to draw a prior global transition distribution from a Dirichlet process. Then, for each hidden state, a transition distribution is taken from the shared global prior. We start by introducing some notation for the Dirichlet process (DP).\nGiven a base distribution H on a parameter space \u0398 and a positive concentration parameter \u03b3, we construct a Dirichlet process $G \\sim DP(\\gamma, H)$ (sometimes also denoted by DP(H)) by the following stick-breaking procedure: let\n$\\beta \\sim GEM(\\gamma), \\theta_i \\overset{iid}{\\sim} H, i = 1,2,\\ldots,$\nwhere $\\beta \\sim GEM(\\gamma)$ is a random probability mass function (p.m.f.) defined on a countably infinite set as follows:\n$\\nu_i \\sim Beta(1, \\gamma), \\beta_i = \\nu_i \\prod_{l=1}^{i-1} (1 - \\nu_l), i = 1, 2, \\ldots .$\nThe discrete random measure $G = \\sum_{i} \\beta_i \\delta_{\\theta_i}$ is a sample from DP(H), where $\\delta_{\\theta_i}$ denotes the Dirac measure centered on $\\theta_i$.\nThe HDP-HMM uses the DP to set a prior on the rows of the HMM transition matrix in a situation where the number of latent states may be potentially infinite. HDP-HMM is defined as\nDP shared global prior: $\\beta \\sim GEM(\\gamma)$,\n$\\theta_j \\overset{iid}{\\sim} H, j = 1,2,\\ldots,$\nTransition matrix prior: $\\pi_j \\overset{iid}{\\sim} DP(\\alpha \\beta), j = 1, 2, \\ldots,$\nLatent states: $z_t \\sim \\pi_{z_{t-1}}, t = 1,\\ldots,T,$\nObservations: $y_t \\sim f(y \\mid \\theta_{z_t}), t = 1,\\ldots,T.$\nHere, $\\beta$ and $\\{\\theta_j\\}_{j=1}^\\infty$ are specified as in the DP previously described, and then each transition distribution $\\pi_j$ for the state j is taken as a random sample from a second DP with the base measure $\\beta$ and the concentration parameter \u03b1. This parameter \u03b1 determines how close $\\pi_j$ is to the global transition distribution $\\beta$. At time t, the state of a Markov chain is indicated by $z_t$, and the observation $y_t$ is independently distributed given the latent state $z_t$ and the parameters $\\{\\theta_j\\}_{j=1}^\\infty$, with emission distribution f(\u00b7). The sticky HDP-HMM from Fox (2009) modifies the transition matrix prior by introducing a point mass distribution with a stickiness parameter \u03ba to encourage state persistence. This is done by setting the transition matrix prior to $\\pi_j \\sim DP(\\alpha \\beta + \\kappa \\delta_j), j = 1,2,\\ldots,$ where $\u03b4_j$ is the Dirac measure centered on j.\nZhou et al. (2021) proposed a new model - Disentangled Sticky HDP-HMM, separating the strength of self-persistence from the similarity of the transition probabilities. The authors modified the transition matrix prior as"}, {"title": "2.3 Limitations of HDP-HMM, sticky HDP-HMM and disentangled sticky HDP-HMM", "content": "The HDP-HMM uses the concentration parameter \u03b1 to modify the prior strength of the transition matrix or the similarity of the rows of the transition matrix. A high value \u03b1 implies that the transition probability for each state is close to the global transition distribution \u03b2.\nThe sticky HDP-HMM introduces a parameter \u03ba in comparison to the HDP-HMM. The ratio \u03ba/(\u03b1 + \u03ba) determines the average probability of self-persistence or the mean of the diagonal of the transition matrix. Both the similarity of the rows of the transition matrix and the strength of prior self-persistence are regulated by \u03b1 + \u03ba. The beta prior of disentangled sticky HDP-HMM ($p_1, p_2$) has the ability to control both the expectation of self-persistence and the variability of self-persistence. At the same time, \u03b1 is free to control the variability of the transition probability around the mean transition \u03b2.\nAll of the models based on HDP-HMM assume that the state transition is stationary. This is especially problematic for spatio-temporal systems, where the states may be dependent on the position. To clarify, our objective is to introduce a dependency of our self-persistence parameter on the observation $y_t$. This"}, {"title": "2.4 P\u00f3lya-Gamma augmentation", "content": "One strategy that has been employed in other recurrent models for enabling efficient and quick inference (Linderman et al., 2017; Nassar et al., 2019) involves the utilization of P\u00f3lya-Gamma augmentation.\nThe main result of Polson et al. (2013) is that binomial probabilities can be expressed as a combination of Gaussians in terms of a P\u00f3lya-Gamma distribution. The fundamental integral identity that lies at the heart of their discovery is that, for b > 0,\n$\\frac{(e^\\lambda)^a}{(1+e^\\lambda)^b} = 2^{-b} e^{\\lambda(a-b)/2} \\int_0^{\\infty} e^{-\\omega \\lambda^2/2} p(\\omega) d\\omega.$\nThe value of \u03bb is calculated as the difference between a and b divided by two. The conditional distribution of \u03c9 given \u03bb is a P\u00f3lya-Gamma one, which makes it possible to use a Gibbs sampling approach for a variety of binomial models. This requires drawing from a Gaussian distribution for the main parameters and from a P\u00f3lya-Gamma distribution for the latent variables.\nSuppose the observation of the system at time t follows\n$p(w_{t+1} | x_t) = Bern (\\sigma (v_t)) = \\frac{(e^{v_t})^{w_{t+1}}}{1+ e^{v_t}},$\n$v_t = R^T x_t + r,$\nwhere $R \\in R^{d}$, $r \\in R$, \u03c3 is logistic function, and Bern denotes Bernoulli distribution. Then if we introduce the PG auxiliary variables $n_{n,t}$, conditioning on $n_{1:T}$, (22) becomes\n$p(w_t | x_t, n_t) = e^{-(n_t v_t - \\frac{1}{2} w_t v_t)},$\n$x \\sim N (R^T x_t + r \\mid w_t/n_t, 1/n_t),$\nwhere $w_t = w_t - \\frac{1}{2}.$"}, {"title": "3 Related work", "content": "In recent years, significant work has focused on recurrent modeling. Linderman et al. (2017) introduced a method for modeling recurrence in recurrent switching linear dynamical systems (rSLDS, also known as augmented SLDS (Barber, 2005)), reducing it to a recurrent autoregressive HMM (rARHMM) via PG augmentation, similar to our approach.\nOther approaches use neural networks for recurrent connections, including recurrent Hidden Semi Markov Models (Dai et al., 2016), Switching Nonlinear Dynamical Systems (Dong et al., 2020), and Recurrent Explicit Durations Switching Dynamical Systems (Ansari et al., 2021). Recently, Geadah et al. (2023) proposed the infinite recurrent switching linear dynamic system (irSLDS). Both methods address recurrence in switching dynamics but differ substantially. Our model incorporates recurrence to influence self-persistence, unlike irSLDS, which integrates it into the state switch probability (see Eq.4).\nWe use P\u00f3lya-Gamma augmentation for efficient inference, whereas in irSLDS this results in intractable inference (see the Appendix of (Geadah et al., 2023)). Additionally, irSLDS uses the variational Laplace-EM algorithm for approximate posterior fitting, while we offer two MCMC sampling algorithms."}, {"title": "4 Recurrent sticky HDP-HMM", "content": "One of the problems of models based on HDP-HMM is that they assume stationarity of state-transition. It is especially problematic in a setting where we try to model motion.\nLet us imagine that we want to model the car's behavior. We want to make the vehicle more likely to be in the \"turn\" state, when it is closer to the obstacle.\nTo achieve position dependence we condition self-persistence on the previous observation. We can do that by performing logistic regression (given by Eq. (22)) in computing the parameter \u03ba. To do that we use P\u00f3lya-Gamma augmentation (see Eq. (21)), which allows us for efficient Gibbs sampling. Therefore, we propose following model using notation that is in line with the conventions outlined in Section 2.2(presented in the Figure 1(c)):\nTransition prior: $\\kappa_{j,1} \\overset{iid}{\\sim} beta (p_1, p_2)$,\n$v_{j,t} = R y_t + r_j,$\n$\\kappa_{j,t+1} = \\frac{(e^{v_{j,t}})}{1 + e^{v_{j,t}}},$\n$\\pi_{j} \\overset{iid}{\\sim} DP(\\alpha \\beta),$\n$\\pi_{j,t} = \\kappa_{j,\\delta j} + (1 - \\kappa_{j,t}) \\overline{\\pi}_j,$\nj = 1,2,... and t = 1,..., T.\nAn equivalent formulation of $z_t \\sim \\pi_{z_{t-1}}$ in the disentangled sticky HDP-HMM is as follows:\nLatent states :\n$w_t \\sim Bern (\\kappa_{z_{t-1},t}),$\n$z_t \\sim w_t \\delta_{z_{t-1}} + (1 - w_t) \\overline{\\pi}_{z_{t-1}},$\nt = 1,...,T,\nIn this way, our self-persistance probability becomes position- and state-dependent. When considering motion, the likelihood of transitioning to a different state is contingent upon one's location."}, {"title": "5 Inference and Learning", "content": ""}, {"title": "5.1 Direct Assignment Sampler", "content": "The direct assignment sampler marginalizes transition distributions $\u03c0_j$ and parameters $\u03b8_j$ and sequentially samples $z_t$ given all the other states $z\\backslash_t$, observations ${\\{y_t\\}}_{t=1}^T$, and the global transition distribution \u03b2.\nOur direct assignment sampler is based on the direct assignment sampler for DS-HDP-HMM, which means that instead of only sampling $z_t$ (as in the sampler for HDP-HMM), we sample ${\\{z_t, w_t, w_{t+1}\\}}_{t=1}^T$ in blocks. We sample \u03b1, \u03b2, \u03b3 only using $z_t$ that switch to other states by $z_{t\u22121}$ ($w_t = 0$), and sample ${\\{\\kappa_{j,t}\\}}_{t=1}^T, p_1, p_2$ only using $z_t$ that stick to state $z_{t\u22121}$ ($w_t = 1$). The main difference between the samplers presented by Fox et al. (2011); Zhou et al. (2021) comes from the fact that $\u03ba_j$ is now a vector and we have to additionally sample the auxiliary variables.\nAlgorithm 1 presents direct assignment sampler steps. For Step 1, we compute the probability of each possible posterior case of\n$p(z_t, z_t, w_t, \\overline{w_{t+1}} | z\\backslash_t, w\\{t,t+1\\}, {Y}{=1, \u03b1, \u03b2, 5,1:T}+1)$\nin sequence and sample the corresponding categorical distribution for ${\\{z_t, w_t, w_{t+1}\\}}$, where all states except $z_t$ are denoted by $z\\backslash_t$, and all $w_t$ except for $w_t$ and $w_{t+1}$ are represented by $w\\{t,t+1\\}$. If $z_t = K + 1$, that is, a new state appears, we increment K, sample the regression parameters $R_{K+1}$ for the new state from the prior state, and update \u03b2 using stick breaking. This requires O(TK) operations.\nFor Step 2, given $w_{t+1}$ whose corresponding $z_t$ is j, we sample $\u03ba_{j,1}$ using beta-binomial conjugacy and compute $\u03ba_{j,t}$ using Equation (22), performing the O(TK) steps.\nStep 3 involves sampling T(K+1) auxiliary variables, requiring O(TK) steps.\nStep 4 involves introducing auxiliary variables ${\\{m_{jk}\\}}_{j,k=1}^K$ and sampling \u03b2 using Dirichlet categorical conjugacy, which requires O(K) draws.\nStep 5 computes the empirical transition matrix ${\\{n_{jk}\\}}_{j,k=1}^K$, where $n_{jk}$ is the number of transitions from state j to k with $w_t = 0$ in ${\\{2+1\\}}_{t=1}^T$, and introduces additional auxiliary variables. Then the posteriors of \u03b1 and \u03b3 are conjugated with Gamma, given the auxiliary variables. We approximate the posterior of $p_1, p_2$ by finite grids. This last step has a computational complexity of O(K). The total complexity per iteration is O(TK).\nAs mentioned in the study by Fox et al. (2011), when the entire latent sequence ${\\{z_t, w_t\\}}_{t=1}^T$ is sampled jointly, it significantly improves the mixing rate. This is particularly crucial for models with dynamics, such as ARHMM and SLDS, where the correlated observations can further slow down the mixing rate of the direct assignment sampler. For this reason, we did not utilize this sampler in our experiments. However, we have included its description for the sake of comprehensiveness in this study."}, {"title": "5.2 Weak-Limit Sampler", "content": "The weak-limit sampler for the sticky HDP-HMM takes advantage of the fact that the Dirichlet process is a discrete measure to produce a finite approximation of the HDP prior. This approximation converges to the HDP prior when the number of components, L, goes to infinity (Ishwaran and Zarepour, 2000, 2002). The standard HMM forward-backward procedure can be used to sample latent variables ${\\{z_t\\}}_{t=1}^T$ with the help of this approximation, which increases the mixing rate of the Gibbs sampler. Our weak-limit Gibbs sampler is based on the sampler for DS-HDP-HMM, so it samples pairs ${\\{z_t, w_t\\}}_{t=1}^T$.\nAlgorithm 2 presents weak-limit sampler steps. In Step 1, we use the forward-backward procedure to jointly sample the two-dimensional latent variables"}, {"title": "6 Experiments", "content": ""}, {"title": "6.1 NASCAR\u00ae", "content": "We begin with a straightforward illustration where the dynamics take the form of oval shapes, resembling a stock car on a NASCAR\u00ae track. The dynamics is determined by four distinct states, $z_t \\in \\{1,..., 4\\}$, which regulate a continuous latent state in two dimensions, $y_t \\in R^2$.\nFor this experiment, we performed ten runs with different random seeds. The results are averaged.\nWe can distinguish four states here, which are presented in Figure 2. To make the states more distinguishable, the car uses four different velocities (which can be observed in Figure 5, as the segments differ significantly in length).\nIt is evident that the state of the system is influenced by its position. As the car completes each lap, it spends a greater amount of time in the \"straight-on\" states. This poses a challenge for models that have a constant transition matrix, as the probability of self-persistence follows a Geometric distribution."}, {"title": "6.2 Dancing Bee", "content": "We employed the publicly available dancing bees dataset (Oh et al., 2008), which is renowned for its intricate characteristics and has previously been studied in the field of time series segmentation.\nThe dataset consists of the trajectories followed by six honey bees while performing the waggle dance, including their 2D coordinates and heading angle at each time step. The bees demonstrate three types of motion: waggle, turn right, and turn left.\nwise or counterclockwise. The data consist of $y_t = [cos (\\theta_t), sin (\\theta_t), x_t, y_t ]$, where $(x_t, y_t)$ denotes the 2D coordinates of the body of the bee and $\u03b8_t$ its head angle.\nFor this experiment, we performed ten runs with different random seeds. The results are averaged.\nWe can see in Table 2 that our model performed on a par with S-HDP-HMM in terms of accuracy and weighted F1. However, in Figure 7 we can observe that the segmentation obtained from our model is the smoothest.\nIn the same graph, it is evident that the values observed during the \"waggle\" phase are significantly smaller in magnitude compared to those obtained during turning. We hypothesize that this characteristic enables our model to achieve a more seamless segmentation."}, {"title": "6.3 Mouse Behavior", "content": "Our model was also tested on a publicly accessible mouse behavior dataset. In the described experiment, the mouse was immobilized by fixing its head position during a visual decision-making task. During this task, neural activities in the dorsal cortex were monitored through wide-field calcium imaging. The behavioral video data comprised grayscale frames with a resolution of 128x128 pixels. This video was recorded from two different angles using two cameras, one for the side view and another for the bottom view. To manage the high-dimensional nature of the video data, we adopted dimension reduction techniques previously established. These involved 9-dimensional continuous variables derived through a convolutional autoencoder (Batty et al., 2019).\nIn real-world scenarios, ARHMM models often suffer from a problem called over-segmentation. This refers to the situation where behaviors that seem similar to a human expert are divided into separate clusters. According to the hypothesis proposed by Costacurta"}, {"title": "7 Conclusions and Future Work", "content": "The paper presents a new modeling technique that combines latent states with position- and state-dependent self-persistence probability. This technique is particularly suitable for motion data, where the likelihood of transitioning to a different state depends on the subject's location.\nA central contribution of this paper is introducing dependence of stickiness factor on the previous observations.\nThe RS-HDP-HMM addresses a significant limitation in conventional HMMs: their inability to effectively model non-Markovian temporal dependencies. Many real-world processes exhibit behaviors where the current state depends not just on the immediate past state (as in hidden Markov models), but on a more complex history of previous states. Similar level of contribution was introduced by RSLDS or iRSLDS bringing similar dependece to SLDS.\nThe recurrent model consistently demonstrates better performance metrics, showcasing its strength in capturing data nuances, and the obtained states are more robust to small noise, as it is shown by mouse behavior dataset.\nSimilarly to Zhou et al. (2021) who modified the algorithms introduced by Fox (2009), we introduce two sampling schemes for our model."}, {"title": "A Sampling Scheme", "content": "Step 1 is analogous to Fox et al. (2011) and Zhou et al. (2021). We describe it here for completeness.\nStep 1: Sequentially Sample $z_t, w_t, w_{t+1}$ : The posterior distribution of $z_t, w_t$, and $w_{t+1}$ is expressed as follows:\n$p(z_t = \\overline{k, w_t}, w_{t+1}, | z\\backslash_t, w\\{t,t+1\\}, Y_{1:T}, \u03b1, \u03b2, {\\kappa_{j,1:T}\\}j=1)$\n$\\propto p (z_t = k, w_t, w_{t+1} | z\\backslash_t, w\\{t,t+1\\}, \u03b1, \u03b2, {\\kappa_{j,1:T}\\}j+1) \\cdot P (y_t | y\\backslash_t, z_t = k, z\\backslash_t) .$\nwhere all observations except $y_t$ are denoted by $y\\backslash_t$, and all $w_t$ except for $w_t$ and $w_{t+1}$ are represented by $w\\{t,t+1\\}$.\nThe predictive observation likelihood $p (y_t | y\\backslash_t, z_t = k, z\\backslash_t)$ can be quickly calculated if we use a conjugate prior on the parameter in the observation likelihood.\n$p(z_t = \\overline{k, w_t}, w_{t+1}, z_{t+1} | z\\{t,t+1\\}, w\\{t,t+1\\}, \u03b1, \u03b2, {\\kappa_{j,1:T}\\}j+1)$\n$p = k, w_t, w_{t+1} | z\\backslash_t, w\\{t,t+1\\}, \u03b1, \u03b2, {\\kappa_{j,1:T}\\}j+1)$\n$\\propto p (w_t | \\kappa_{z_{t-1},t}) p (z_t | w_t, \\overline{\\pi}_{z_{t-1}}) p (w_{t+1} | \\kappa_{z_t,t+1}) p (z_{t+1} | w_{t+1}, \\overline{\\pi}_{z_{t}})$$\\\\ \\propto \\int \\prod_{ i}\n p(\\pi i |\u03b1, \u03b2) p (2\\overline{\\tau} |\u03c0_i)$\\\\\\$$\\{\\tau\\}-1=i,w\u2081=0,\\tau\\neq t,t+1}\n/p (w_t | \\kappa_{z_{t-1},t}) p (z_t | \\overline{2} w_t, \\overline{\\pi}_{z_{t-1}}) p (w_{t+1} | \\kappa_{z_t,t+1}) p (z_{t+1} | w_{t+1}, \\overline{\\pi}_{z_{t}})$\n\\cdot\\prod_{i} p(\\pi_i |\\{T|z_{\\tau-1} = i, w_\\tau = 0,1 \\neq t,t + 1\\}, \u03b1, \u03b2) d\\pi.$\nLet $z_{t-1} = j, z_{t+1} = l$, then Equation (29) simplifies to"}, {"title": "B Weak limit-sampler", "content": "Step 1: Sample ${\\{z_t, w_t\\}}_{t=1}^T$ The combined conditional distribution of z_{1:T}, w_{1:T} is determined by\n$\\overline{p(z_{1:T}}, w_{1:T} | \\overline{Y | Y_{1:T}}, \\overline{\\pi}, {\\kappa_{j} \\{j\\}=1,\\theta)=p(z,\\overline{W_T | T-1,Y_{1:T}}, \\overline{\\pi}, \\kappa {\\kappa_{j,1:T}\\}j=1,\\theta)}}$\n$\\overline{p(z_{T-1}, z_{T-1}, w_{T-1} z_{T-2}, Y_{1:T}}, \\overline{\\pi}, {5,1:T}=1,\\theta)}$\n$.\\.\\.P (z_1 | 9_{1:T}, \\overline{\\pi}, \\kappa {\\kappa_{j,1:T}\\}j=1,\\theta)}.$\nThe conditional probability distribution of $z_1$ is given by:\n$\\overline{j=1,\\theta)}$\\overline{p (2_1 | Y_{1:T}, \\overline{\\pi}, 5,1:T}\\\\xp p (2_1) P (Y_1 | \\theta_{z_1}) P\nThe conditional distribution of $z_t, t > 1$ is given by:\n$\\overline{P (z_t, w_t | z_{t-1}, Y_{1:T}, \\overline{\\pi}, {kj,1:T}\\\\xp 2_{t, w_t, Y_{1:T} | z_{t-1}, \\overline{\\pi}, {k_{j,1:T}+1}=1,\\theta)}$\n\\theta)}\n$\\overline{-1, 0)}$$\\\\\\overline{=P (z_t | tzt-1, w_t) P (Wt | zt-1, {Kj,t}=1) P (Yt:T | Zt,, Kj,t:T}}p, w, {p(zt|\\xp\\overline{P (Wt | z_{t-1}, {Kj,t}=1) P (Yt:T|zt,, {kj,t:T}}\\\\\\ =p(zt|zt\u22121, Wtwt) p\\$\\overline{j,t}=1) P (Y_t | O_z) M_{t+1,t} (z_t),$\nThe backward message passed from $z_t$ to $z_{t\u22121}$, denoted by $m_{t+1,t}(z_t)$, is the probability of observing $y_{t+1:T}$ given"}, {"title": "CMNIW Prior", "content": "In the autoregressive emission, the MNIW prior is established by assigning a matrix-normal prior \u039c\u039d(\u039c, \u03a3;, V) to Aj conditioned on \u03a3j:\n$p (A_j | \\Sigma_j) = \\frac{1}{(2\\pi)^{dj^2/2}|V|^{d/2} |\\Sigma_j|^{d/2}} exp\\left(-\\frac{1}{2}tr [(A_j -M)^T \\Sigma_j^{-1} (A_j - M) V^{-1}]\\right)$,\nwhere M is d\u00d7 d matrix, \u03a3;, V are d \u00d7 d positive-definite matrix, d is the dimension of observation yt; and an inverse-Wishart prior IW (So, no) on \u03a3j:\n$\\overline{p (\\Sigma_j) = \\frac{|S_o|^{n_o/2}}{\\Gamma d(n_o/2)} |\\Sigma_j|^{-(n_o+d+1)/2} exp\\left(-\\frac{1}{2}tr (S_o\\Sigma_j)\\right)},$\nwhere \u0393d(\u00b7) denotes the multivariate gamma function. We define M = 0, V = Idxd, no = d + 2, and So = 0.42, with being $\\sum_{i=1}^T (x_t - \\overline{x_t})^T (x_t - \\overline{x_t})$, and xt = Yt+1."}]}