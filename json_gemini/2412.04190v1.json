{"title": "Directed Structural Adaptation to Overcome Statistical Conflicts and Enable\nContinual Learning", "authors": ["Zeki Doruk Erden", "Boi Faltings"], "abstract": "Adaptive networks today rely on overparameterized fixed\ntopologies that cannot break through the statistical conflicts\nthey encounter in the data they are exposed to, and are prone\nto \"catastrophic forgetting\" as the network attempts to reuse\nthe existing structures to learn new task. We propose a struc-\ntural adaptation method, DIRAD, that can complexify as\nneeded and in a directed manner without being limited by sta-\ntistical conflicts within a dataset. We then extend this method\nand present the PREVAL framework, designed to prevent\n\"catastrophic forgetting\" in continual learning by detection\nof new data and assigning encountered data to suitable mod-\nels adapted to process them, without needing task labels any-\nwhere in the workflow. We show the reliability of the DIRAD\nin growing a network with high performance and orders-of-\nmagnitude simpler than fixed topology networks; and demon-\nstrate the proof-of-concept operation of PREVAL, in which\ncontinual adaptation to new tasks is observed while being\nable to detect and discern previously-encountered tasks.", "sections": [{"title": "Introduction", "content": "Past decade has shown that complex networks should be at\nthe core of any AI system that needs to be of robust use\nin any task of reasonable complexity. It has, however, been\nunfortunate that over the same period, the field of machine\nlearning (ML) has been stuck in the twin limiting paradigms\nof static topologies and statistical fine-tuning, attempting\nto make up for the limitations of both of these by using\nbrute force, in form of overparameterization and computa-\ntional requirements accompanying it. Limitations imposed\nby these paradigms also prevent solving the crucial prob-\nlem of \"catastrophic forgetting\" in continual learning. In this\nwork, we first propose a novel method of structural adapta-\ntion, operating with gradient descent, with a strong bias to-\nwards minimal complexity. Our framework, first of its kind\nto the best of our knowledge, is neither limited by statistical\nconflicts between samples (a term, detailed in the text, we\nuse to refer to conflicting requirements within a dataset that\nresult in net zero adaptive pressure on parameters, despite\nnonzero change requirements for any individual sample) nor\nreliant on excess complexity to find a solution with strong\nguarantees. We apply this method to construct a system to\nprevent \"catastrophic forgetting\u201d by recognizing unexpected\ndata, constructing new components (models) to process such\nnew data without affecting past responses, and then select-\ning the suitable one over an existing array of such models\nwhen data from a past task is provided - a unified contin-\nual learning framework that does not require task labels or\nswitching signals anywhere, neither during adaptation nor\ndeployment. Finally, we provide positive results on both of\nthese frameworks.\nNote on terminology The mechanisms we propose in this\npaper are not biologically plausible at neuronal level, and\nsharing a nonlinear weighted-sum paradigm is not enough to\njustify an analogy with neural systems given the additional\nmechanisms we introduce. To avoid implying such an anal-\nogy and to accurately describe these mechanisms, we use the\nterms node and edge instead of \"neuron\" and \"synapse\". We\nalso refrain from using the term \"neural network (NN) and\nsimply use network when referring to our design."}, {"title": "Background and Related Work", "content": "Structural adaptation Structural adaptation in NNS\nhasn't gained as much attention as other aspects of this tech-\nnology, as many of these methods involve an additional step\nand often don't provide a significant benefit compared to the\nadded complexity. One subfield in literature, called \"neu-\nral architecture search,\u201d focuses on optimizing the architec-\nture itself explicitly (Liu, Simonyan, and Yang 2018; Shin,\nPacker, and Song 2018; Baker et al. 2016; Stanley et al.\n2019; Liu et al. 2017; Miikkulainen et al. 2019). Some other\nworks view \"structural adaptation\" as starting from scratch\nor growth, sometimes referred to as Artificial Embryogen-\nesis (Kowaliw et al. 2014), often using evolutionary algo-\nrithms. Recent methods for expanding neural networks, sim-\nilar to our design choices, can also be found in the liter-\nature (Dai, Yin, and Jha 2019; Evci et al. 2022; Mitchell,\nMundt, and Kersting 2023). Our approach aligns more with\nthe group that designs developmental methods rather than\nrelying on external loops or added pressures for architecture\noptimization. We use structural adaptation not for topology\noptimization but to drive further response adaptation. How-\never, our approach differs from this group in that we pri-\noritize minimal complexity and address statistical conflicts\nwhile operating outside the conventional NN paradigm."}, {"title": "Continual adaptation", "content": "A significant issue with continual\nlearning or adaptation is \"catastrophic forgetting\" or, as we\ncall it, \"destructive adaptation\"\u00b9 (DA) - when the new in-\nstances differ significantly from previously observed exam-\nples, they cause the new information to overwrite previously\nlearned knowledge in the network, a problem until today re-\nmains without a reliable solution (Hadsell et al. 2020; Parisi\net al. 2019). Systems with fixed capacity cannot deal with\nthe problem adequately: An existing capacity is always used\ncompletely for the previous tasks (since information is en-\ngrained in a neural network in a distributed manner), and\nexisting information will be eventually (often immediately)\nlost as new tasks differing significantly from the previous\nones arrive. The methods that work by the addition of ca-\npacity, on the other hand, are imprecise in terms of when to\nadd capacity, how to assign different added components to\ndifferent tasks, and how to choose among components when\npresented with one of the past tasks (e.g. (Rusu et al. 2016))\nthe same limitation also applies to methods that explic-\nitly store information about the solutions of past tasks as\nwell (e.g. (Kirkpatrick et al. 2017)). Some extensions of such\nmethods that partially try to address these questions require\ntask labels during adaptation phase and have no mechanism\nthat can detect new tasks (e.g. (Jacobson et al. 2022)), hence\ncannot constitute systems with autonomous continual adap-\ntation capability. We are unaware of a framework proposed\nagainst DA that can reliably add capacity as needed that also\nanswers these questions, and designing such a method is\nwhat we do in this work."}, {"title": "Novelty/anomaly detection", "content": "Methods of novelty/anomaly\ndetection are those that are interested in classifying certain\nencounters as novel or not. Detailed survey of such methods\nis beyond our scope, interested readers can find a review in\n(Pimentel et al. 2014). The field itself is not of primary in-\nterest to us except as a sub-goal, since it concerns itself with\nsystems designed to classify samples as novel or not, while\nwe want to both quantify and localize this novelty, doing that\nwithin a system that is actually used for the performation of a\nparticular task. Furthermore, as methods susceptible to sta-\ntistical conflicts, they are not suitable for our purposes (as\nwill be discussed in the following sections)."}, {"title": "Mechanisms of Structural Adaptation", "content": "In this section, we describe our structural adaptation and net-\nwork growth mechanism. The mechanisms described here\nare not directly aimed at the prevention of destructive adap-\ntation (DA), but are general adaptive processes that can be\nused in any ML problem. Throughout the section, we dis-\ncuss a single task. Here we only provide a summary of the\nmethod and its core points. The full theoretical development,\nwith justifications of design choices and practical considera-\ntions, can be found in the Appendix. To illustrate the process\nin action, we provide an example path of adaptation in Fig-\nure 1, to which we refer throughout our narrative below.\nWe think \"catastrophic forgetting\u201d is unnecessarily anthropo-\nmorphized (the phenomenon is a challenge to all adaptive systems)\nand does not correspond to the gradual process of \"forgetting\" as\ncommonly understood but to active destruction of past information.\nWe always assume a network starting with only the input\nand output nodes, and no hidden nodes (neither input nor\noutput) - however the mechanisms we designed\ncan operate locally within networks of arbitrary standing\ncomplexity. Our aim is to develop a network that can com-\nplexify as needed, but not more (prioritizing parameter adap-\ntation where possible); and that is not limited by statistical\ntrade-offs between different samples in a batch. We call the\nprocesses that grow the network by introducing new compo-\nnents as generative processes (GPs), each of which is neu-\ntral: No node's response is changed due to a GP; and all\nchanges in net response occur under the influence of gradi-\nents to ensure no harm to performance. Parameter adaptation\nwithin network (edge weights and node biases) are done by\nstandard gradient descent via backpropagation algorithm."}, {"title": "Adaptive potentials (APs)", "content": "The immediate AP of an edge\n(i, j) is defined as the net gradient that this edge's weight\ngets over a given batch, i.e. $\\partial C/\\partial w_{ij}$ where C is the cost/er-\nror. We say that the immediate AP of edge is exhausted if\n$\\partial C/\\partial w_{ij} \\approx 0$. Analogously, we say that the immediate AP\nof a node j is exhausted if $\\partial C/\\partial z_j = \\delta_j \\approx 0$ (where $z_j$\nis the activation) and the immediate AP of all its in-edges\nis exhausted as well. We define the total AP of a node as\n$\\sum_m |\\delta_m|$, (m is the sample index), as a measure of the total\nadaptive gain that can be obtained by a change in the activa-\ntion of that node $z_j$, if it can be exploited. Analogously, we\ndefine the total AP of an edge (i,j) as $\\sum_m |\\partial C_m/\\partial w_{ij}|."}, {"title": "Edge generation", "content": "The first GP, edge generation, generates\nan in-edge with an initial weight of 0 to a node j. The source\nof the edge is chosen among the candidates to be the one\nthat maximizes the magnitude of the expected immediate\ngradient update on the edge, i.e. the value $|\\partial C/\\partial w_{ij}| \\times\n\\sum_m |a_i|$ and where am is the state (response) of node i. We\ngenerate an edge for a node if the immediate AP of the node\nis exhausted, but its total AP is not (i.e. is nonzero), see Fig-\nure 1b. Intuitively, this operation allows us to take a node\nwith a nonzero total AP out of the exhaustion of its imme-\ndiate AP provided that there are sources that can be a good\nmatch with the change directions requested by the gradients."}, {"title": "Edge-node conversion (ENC) and resolving statistical\nconflicts", "content": "The ENC mechanism is designed to operate\nwhere the immediate AP of an edge is exhausted while its\ntotal AP is not. Recall that total AP quantifies the total adap-\ntive gain that can be obtained from a given edge. This po-\ntential, no matter how large, cannot be utilized in NNs if\nthe immediate AP of the edge is exhausted (net gradient 0).\nENC mechanism provides a solution to that by modulating\nthe gradients of the original edge (upon the progression of\nadaptation) so that they become aligned instead of opposing.\nHere we only describe the final design of the ENC operation\nwith brief intuition on their justifications where applicable -\nfor detailed reasoning, the reader is referred to the Appendix.\nWhen an edge (i, j) undergoes ENC, it is replaced with\na new node k and two edges (i,k) and (k, j) that become\nthe new path connecting i to j. The new node is modulatory,\nwhose state is computed by the multiplication of two terms:"}, {"title": null, "content": "$a_x^m = \\prod_{i \\in \\{0,1\\}} \\sigma_i(\\sum_{y \\in ini(x)} W_{yx}a_y^m + b_{x,i})$         (1)\nwhere subscripts x, i refer to node x, term i. We also\nassume two distinct transfer functions $\u03c3_0$ and $\u03c3_1$, where\n$\u03c3_0(z) = z$ in our design and $\u03c3_1$ is given as $\u03c3_1(x) =$\\n$4/(1 + e^{-Kx}) - 1$, where K = 1/Wij is a node-specific\nproperty. This function can take values in the range (-1,3),\nand hence is able to invert the sign of the previously op-\nposing gradients. Nonlinearity in network is realized by the\nmultiplication operation and the nonlinear $\u03c3_1$. The two terms\nin modulatory nodes will have distinct delta values, $\u03b4_{x,i}$; and\nthey will form in-edges distinctly for these two terms. We as-\nsume that at the time of ENC, the original source i connects\nto term 0 of the new node k and no node is connected to term\n1. We further set the bias of the first term to a fixed 0, and\nwe set the weights of new edges as $w_{ik}$ = 1 and $w_{kj}$ = Wij.\nIt is shown in the appendix that this design of a modu-\nlatory node satisfies our neutrality criterion. It can also be\nshown that immediately after this conversion, the deltas for\nterm 1 of the new node are equal to the gradients of the orig-\ninal edge, $\u03b4_1 = \u2202C/\u2202w_{ij}$. By ENC, we effectively trans-\nferred the weight gradients of the original edge (which can-\nnot be treated as a vector for adaptive purposes, but only in\nterms of their average effect) to the deltas of a node (which\ncan be treated as a vector that can create an adaptive change\neven if their average is 0). If a proper source l can be found\nfor term 1 of node k that yields a nonzero $\u2202C/\u03b8\u03c9_{lk}$, then the\nnet gradient of the new edge (k, j) will start going nonzero\nas state of term 1 of node k is adapted under the influence of\nthe gradients which are proportional to that of gradients of\nthe original edge, hence getting out of what would be a local\noptimum had we have a static network (Figures 1c and 1d).\nIn the appendix, we show that the chain of ENC opera-\ntions will continue, resulting eventually in nonzero net gra-\ndients, and hence adaptation will proceed across the net-\nwork, as long as the following condition does not hold:"}, {"title": null, "content": "$Cov(\\prod_{x \\in A} \\frac{\\partial C^m}{\\partial w_{ij}} ) = 0, \u2200A \u2208 P(N)$                                      (2)\nwhere N is the set of all available candidate sources (at\nthe very least, covering all input nodes) and P(N) its power\nset. In the most relaxed case, this condition states that adap-\ntation will proceed as long as there is any nonzero correla-\ntion between the gradient vector of the edge that we are try-\ning to get out of adaptive exhaustion and any of the potential\nmultiplicative combinations of the input nodes of the net-\nwork. This is a condition much more strict than simply hav-\ning a mean $\u2202C/\u2202w_{ij}$ as 0, as static networks would have; and we\nintuitively suspect, but did not verify mathematically, that it\nmay correspond to a global optimum. The theoretical nature\nof this condition should not be forgotten, however, limited\nby finite step sizes and practical considerations.\nTo limit the number of GPs executed and limit complexity\nincrease to when it would be absolutely necessary, we can\nintroduce a priority ordering mechanism, which chooses a"}, {"title": "Novelty Detection via Prediction Validations", "content": "Our aim now is to create a network that can detect if the sam-\nples observed currently by the network are actually among\nthe same type that it had adapted to, or if they are actually\nnew, resulting in unexpected responses by the network. Be-\nlow, we describe the PREVAL (from prediction validation)\nframework that can predict the states of the nodes in the\nnetwork using information from higher levels of computa-\ntion, and then uses mismatches in these predictions to detect\nnovel encounters, and finally use this information to realize\ncontinual adaptation in a system with multiple models.2"}, {"title": "L0 and L1 networks", "content": "In a supervised learning task, let\nLO network be our task network. Suppose that upon accom-\nplishment of a designer-specified condition (e.g. errors no\nlonger decreasing), LO is stabilized - i.e. no more param-\neter updates or generative processes, the response of every\nnode to a given input is fixed. In PREVAL, we create a new\nnetwork, a directed acyclic graph (DAG) within itself, the\nL1 network, following the stabilization of LO. Target nodes\nof L1 are all the nodes (including inputs) in LO except out-\nput nodes, and its task is to predict the states of these target\nnodes as computed by LO in response to a given input. L1\ncan use as inputs any of the nodes in LO, potentially includ-\ning output nodes, as long as the following condition is not\nviolated: For any node no \u2208 L0, no node n\u2081 \u2208 L0 can have\na path to no via L1 if it also has a path to no via LO - making\nsure that only the nodes at a higher level of computation pre-\ndict the states of those in the lower levels of computation, i.e.\nabstract information predicts the concrete observation, not\nvice-versa. Hence in L1, we prevent simply performing\nthe trivial replication of the pathways in LO. Given this new de-\nscription of inputs, outputs, targets, and the additional con-\nstraint regarding connectivity; L1 can be adapted as usual\nwith DIRAD and stabilized in the same manner as LO."}, {"title": "Multiple models", "content": "We define a model as any system within\nour framework that has a particular response pattern to the\ninput. In our implementation, we interpret models as dis-\ntinct, unrelated networks; though alternative conceptualiza-\ntions, such as a subset of connections or subnetworks ex-\npressed within one network, or networks that are duplicated\nand differentiated from one another, are also possible and ev-"}, {"title": "Validation and interfacing models", "content": "An adapted L1 net-\nwork can provide us with the mismatch information between\nthe actual state of an input or internal node and its predicted\nstate based on the state of the network at higher levels of\ncomputation; which can in turn be used to validate whether\na new sample (during deployment) or batch (during ongoing\nadaptation) is consistent with what is expected based on\nthe data that the current model was adapted to. Notice that this\npertains to the conversion of a continuous metric (amount of\nmismatch in L1 nodes) to a discrete one (model validated/in-\nvalidated on a sample). Furthermore, when one is comparing\nmultiple models in this regard (finding the model that \"best\nmatches\" to the sample), there is no one-to-one correspon-dence between different models since they will have distinct\nL1 networks, with different targets possibly differing even in\nthe order of magnitude of their numbers. Hence, there is no\nsingle best way to perform this validation. Here, we describe\n(and use in our experiments) one particular framework, re-\ncursive processes of validation across the hierarchy starting\nfrom node responses to whole batches.\nAt time of stabilization, we classify a target node n of\nthe L1 network as confidently predicted (CP) if the mean\nprediction error (PE) of this node across the last batch is\nlower than a threshold TCP; and record the mean \u00b5\u03b7 and\nstandard deviation on of observed PE that node across the\nlast batch. When processing a new sample, the response of\nthe model (and hence retrospective predictions of L1 target\nnodes) are obtained. We classify the CP node n in a model\nas conflicted if the observed PE in that node for that sample\nEn > \u00b5\u03b7 +Tconfon for a preset multiplier Tcon f. A model\nis said to be validated on a sample if, in its response to that\nsample, the ratio of conflicted nodes to total number of CP\nnodes Nconf/NCP < Tsv for a preset threshold Tsv.\nDuring stabilization of a model M, we record the num-\nber of invalidated samples in the last batch that the model\nobserved, RS. During adaptation, model validation is per-formed over whole batches. A model is said to be validated"}, {"title": "Discussion and Conclusions", "content": "DIRAD One limitation of DIRAD is computational com-\nplexity. DIRAD's priority ordering makes it computation-\nally more demanding than a standard NN in training, which\nis alleviated, but not completely removed, by architectural\nsimplicity of resultant networks. Furthermore, flexibility in\nnetwork topologies make it unsuitable for mainstream hard-ware acceleration methods. Choosing a more computation-\nally feasible priority ordering algorithm would address this\nissue. With developments in the area of structural adaptation,\nalgorithmic or hardware solutions will also be developed to\nalleviate the computational complexity associated with the\noperations such systems use, like GPUs in case of NNs.\nPREVAL To the best of our knowledge, PREVAL is the\nfirst framework that can handle continual adaptation with\nhigh accuracy & retention of past information, while doing\nboth new task detection & discernment among past tasks\nwithin a unified framework that does not require task la-\nbels anywhere in the flow. The degree to which this hap-pens with PREVAL, however, is dependent upon the dis-cernability of different tasks within the system; and is cur-rently still lower compared to what would be in case of a\nperfect discernability. We furthermore saw that failure in\nrecognition of new tasks is a major culprit for remaining\nreductions in performance. It may not be possible to ac-count for this remaining gap in performance due to failure\nin discerneability completely via further refinements on DI-RAD or via tuning validation/discerneability parameters of\nsystem: With the PREVAL framework, there is no guaran-tee that each task or class would be perfectly discerneable\nwithin limitations, even if they are discerneable in theory. Some information may be lost as information is propagated\nto higher levels of computation (e.g. state saturation) and its\nconstituents cannot be retrieved; or a majority of CP nodes\nmay be of trivial features common across multiple tasks, and\nhence no threshold ratio can account for all the tasks the sys-tem will encounter completely. Situations like these would\nimpose constraints on the maximum discernibility of tasks\nwith PREVAL, which cannot be overcome with different pa-rameter choices or improvements in adaptation processes.\nTo develop the idea behind PREVAL to a perfect continual\nadaptation framework, one may need to go beyond the tra-ditional conceptualization of ML systems & problems into a\nnew domain in which these limitations do not exist.\nA weakness of PREVAL that would show itself in paral-lelized hardware implementations is the requirement to cal-culate an overall statistic across nodes, which cannot be done\nin a fully distributed manner. Potential alternatives exist to address this and allow the nodes to reach to an agreement\nabout the validity of a model in a distributed manner, e.g.\nvoting-based schemes (Li et al. 2020) or other consensus\nprotocols (Castro, Liskov et al. 1999; Fadda et al. 2022).\nWe used PREVAL with an interface in which different models were represented with different networks. This pre-vents destructive adaptation (DA), but does not harness the potential of transfer learning (Zhuang et al. 2020) since net-works are all created from scratch. In case of need, the defi-nition of a \"model\" can be modified to allow for this; e.g. via adding capacity to a shared network while selectively stabi-lizing the previous pathways so that past responses won't be affected (possible without loss of expressivity potential with DIRAD), modifying existing components while storing al-ternatives in different models, and many others. There already exist methods that work via the addition of capacity to alleviate DA (Rusu et al. 2016; Yoon et al. 2017; Terekhov, Montone, and O'Regan 2015) - approaches like that can be applied to PREVAL without changes in basic system con-ceptualization on either side. PREVAL can also be used with methods that rely on storing past structure (like (Kirkpatrick et al. 2017)), to give them a means of detecting new tasks. PREVAL has been designed to operate as a mechanism at a level above the network adaptation process. Hence, it can work in tandem with any method modifying network adap-tation dynamics that also aim to reduce the effect of DA, or is geared towards any other purpose."}]}