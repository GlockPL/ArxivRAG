{"title": "TIFeD: a Tiny Integer-based Federated learning algorithm\nwith Direct feedback alignment", "authors": ["Luca Colombo", "Alessandro Falcetta", "Manuel Roveri"], "abstract": "Training machine and deep learning models directly on extremely\nresource-constrained devices is the next challenge in the field of\ntiny machine learning. The related literature in this field is very lim-\nited, since most of the solutions focus only on on-device inference\nor model adaptation through online learning, leaving the training\nto be carried out on external Cloud services. An interesting tech-\nnological perspective is to exploit Federated Learning (FL), which\nallows multiple devices to collaboratively train a shared model in a\ndistributed way. However, the main drawback of state-of-the-art\nFL algorithms is that they are not suitable for running on tiny de-\nvices. For the first time in the literature, in this paper we introduce\nTIFeD, a Tiny Integer-based Federated learning algorithm with Di-\nrect Feedback Alignment (DFA) entirely implemented by using an\ninteger-only arithmetic and being specifically designed to operate\non devices with limited resources in terms of memory, computation\nand energy. Besides the traditional full-network operating modality,\nin which each device of the FL setting trains the entire neural net-\nwork on its own local data, we propose an innovative single-layer\nTIFeD implementation, which enables each device to train only a\nportion of the neural network model and opens the door to a new\nway of distributing the learning procedure across multiple devices.\nThe experimental results show the feasibility and effectiveness of\nthe proposed solution. The proposed TIFeD algorithm, with its full-\nnetwork and single-layer implementations, is made available to the\nscientific community as a public repository.", "sections": [{"title": "1 INTRODUCTION", "content": "Tiny Machine Learning (TinyML) is a new emerging research area\naiming at bringing Machine Learning (ML) and Deep Learning (DL)\nalgorithms on embedded systems and Internet-of-Things (IoT) de-\nvices [1]. The main reason behind this paradigm is that, in recent\nyears, the scientific trend is to move the processing of data as close\nas possible to where they are generated. This leads to several advan-\ntages. First, it enables decision making directly on devices, hence\nreducing the latency between data production and data processing\nand supporting real-time applications. Second, it increases the en-\nergy efficiency, given that sending data is more power-consuming\nthan performing computations on device. Third, it enhances privacy\nand security because sensitive data remain on the IoT units and are\nnot transmitted to remote servers [15].\nThe main drawback of TinyML, however, is that on-device train-\ning of DL models is, in most cases, challenging or even impossible\ndue to the severe technological constraints on memory, computa-\ntion and energy characterizing IoT units. In the related literature,\nonly a few works, such as [3, 16], have attempted to implement\nan incremental mechanism, based on transfer learning, to locally\nadapt the model as new data become available.\nTo provide on-device training within an IoT system, an inter-\nesting technological perspective is to leverage Federated Learning\n(FL), which is a distributed approach that allows multiple devices\nto collaboratively train a shared model. Each device performs a\nlocal training with its own data, and then sends the model updates\nto a central server that aggregates the locally computed updates\nof all the devices in the network [2]. The main drawback of state-\nof-the-art FL algorithms is that they are designed to operate on\nedge devices such as smartphones and tablets, which are signifi-\ncantly more powerful from the technological point of view than IoT\nunits. For this reason, traditional FL is not suitable for running on\nresource-constrained devices, given that: (i) the traditional learning\nprocedure with Backpropagation (BP) may not be feasible since it\nis computationally expensive; (ii) the Neural Network (NN) must\nbe shallow and with few parameters; (iii) the training dataset has\nto be small enough to fit into the device's memory.\nIn this perspective, the aim of this paper is to address the follow-\ning research question: how can we train deep and complex machine\nlearning models directly on extremely resource-constrained devices in\na federated way? To the best of our knowledge, we propose for the\nfirst time in the literature a Tiny Integer-based Federated learning\nalgorithm with Direct feedback alignment (TIFeD) that introduces\nthe following innovations:\n\u2022 It enables resource-constrained devices to train a NN with-\nout having to rely on external Cloud services by leveraging\nfederated learning. In this way, we can exploit all the ad-\nvantages of TinyML also during the learning phase and not\nonly for the inference.\n\u2022 It allows only single layers to be trained, thus reducing\nthe computational and memory demands on the micro-\ncontrollers. A direct consequence is that sending weights\nupdates also requires less data since only a portion of the"}, {"title": "2 RELATED LITERATURE", "content": "This section describes the related literature in the field of federated\nlearning and the available works aiming at implementing the most\nused FL algorithm, namely Federated Averaging (FedAvg), on tiny\ndevices.\nThe most popular FL algorithm, introduced by Google in 2016, is\nFederated Averaging [11]. In FedAvg, each node performs multiple\niterations of mini-batch Stochastic Gradient Descent (SGD) with\nBP to update the local model before sending the gradients to the\nserver. In the central server, received model updates are aggregated\ntogether by using an averaging function to combine knowledge\nlearned from different datasets. The main disadvantage of FedAvg\nis that it has not been designed to operate on resource-constrained\ndevices, as it requires a large amount of memory and high pro-\ncessing power to perform the local learning procedure, and thus\nit is not suitable in a TinyML scenario. Other works in the field,\nsuch as [4, 6, 18], try to optimize the FedAvg algorithm either by\nimproving its efficiency or by using more complex and sophisti-\ncated aggregation functions, but without addressing the issue of\nTinyML-specific design.\nOn the other hand, [7, 10] are the first papers implementing Fe-\ndAvg on a device with limited resources, the Arduino Nano 33 BLE\nSense board. In particular, Kopparapu et al. [7] exploited transfer\nlearning to solve a binary image classification task, while Llisterri\net al. [10] implemented a feed-forward neural network on a simpler\nkeyword spotting task. Given the aforementioned limitations of\nFedAvg in working on tiny devices, however, both works are only\nable to train the last fully-connected layer of the considered neural\nnetworks.\nDifferently from the literature, the solution proposed in this\npaper provides some fundamental aspects for on-device training\nof ML models, as summarized in Table 1. In particular, TIFeD is\nspecifically designed for operating on resource-constrained devices\nand it is entirely implemented using an integer-only arithmetic.\nMoreover, the single-layer TIFeD implementation introduces a new"}, {"title": "3 BACKGROUND", "content": "This section introduces the basic concepts on both the DFA training\nalgorithm and the Federated Learning approach."}, {"title": "3.1 Direct Feedback Alignment (DFA)", "content": "Direct Feedback Alignment [12] is a new learning method for ML\nand DL models based on the Feedback Alignment (FA) [9] principle.\nFA showed that the symmetry of weights used in the forward and\nbackward phases, which is required in the BP algorithm, is not\nnecessary. In simpler terms, the network can learn to effectively\nuse fixed and random feedback weights to reduce the error.\nThe FA training algorithm is based on two insights [9]:\n(1) The feedback weights do not need to be exactly equal to the\nforward weights W, but it is sufficient that, for any random\nmatrix B whose elements are uniformly distributed, on\naverage\n$$e^T W B e > 0$$\nwhere e is the error of the network.\n(2) In order to guarantee Eq. (1), instead of adjusting B, we can\nkeep it fixed and adjust W accordingly. From a geometrical\npoint of view, Eq. (1) means that the teaching signal used\nby FA (i.e., Be) lies within 90\u00b0 of the signal used by BP (i.e.,\neT W), that is, B pushes the weights in roughly the same\ndirection as BP. This alignment of signals implies that B\nacts as WT and, since B is fixed, the alignment is driven by\nchanges in the forward weights W. In this way, even ran-\ndom feedback weights convey useful teaching information\nthroughout the network.\nWhen adopted in deep networks with more than one hidden\nlayer, however, even FA back-propagates the error from the output\nlayer through the upper layers. On the other hand, DFA propagates\nthe output error directly to each of the hidden layers and exploits\nthe FA principle to train them independently of the rest of the\nneural network.\nLet H be the number of hidden layers of a feed-forward NN.\nFormally, the layer's update directions for FA \u2013 denoted by\nh = 1, ..., H are calculated as:\n$$S^{FA}_h = \\begin{cases}L'act'_h(a_h) & \\text{for } h = H\\\\S^{FA}_{h+1}B_hact'_h(a_h) & \\text{for } 1 < h < H-1\\end{cases}$$"}, {"title": "3.2 Federated Learning", "content": "Federated learning allows multiple clients to train a shared ML\nmodel on decentralized data sources. It addresses the drawbacks\nof classical ML (i.e. data privacy and security) by distributing the\nlearning procedure across several nodes, thus allowing the data to\nremain local. Instead of collecting and sending acquired data to an\nexternal Cloud service, each device performs a local training by us-\ning a shared model as initialization and exchanges only the weights\nupdates with a central server. Local updates are then aggregated\nby the server to create a global model that will be forwarded to the\nclients. This process is repeated iteratively until the global model\nreaches the desired level of accuracy [5, 6]."}, {"title": "4 THE PROPOSED SOLUTION", "content": "This section details the proposed TIFeD algorithm. We emphasize\nthat, as stated in Section 2 and outlined in Table 1, our work intro-\nduces the following innovations compared with the literature. First,\nTIFeD is specifically designed to operate on resource-constrained\ndevices, taking into account their technological limitations in terms\nof memory, computation and energy. Second, inspired by [14],\nTIFeD is implemented using an integer-only arithmetic, which en-\nables a reduction in memory consumption by using integers less\nthan 32 bit long and, in addition, allows DL models to be trained on\ndevices without a floating-point unit. Third, the single-layer TIFeD\nimplementation introduces a new way of distributing the learning\nprocedure across multiple devices, allowing each IoT unit to train\nonly a portion of the whole NN."}, {"title": "4.1 Overview", "content": "An overview of the proposed TIFeD algorithm operating in a FL\nscenario is shown in Fig. 1. Without any loss of generality, in the\nfollowings a supervised learning image classification task is con-\nsidered as a reference.\nConsider a pervasive system consisting of M IoT units, each of\nwhich collects local data Xm through some sensors. The objective\nis to obtain a ML model trained directly on-device by the IoT units,\nwithout relying on external Cloud services. To achieve this goal,\nthe proposed TIFeD algorithm, detailed in the next subsections,\nexploits FL. The key role in this setup is played by the central\nserver S, which is the orchestrator of the entire architecture. At\neach communication round t, the server S sends the global model Ot\nto all the M IoT units, that perform a local computation of the DFA\nalgorithm based on their dataset Xm. Once the learning procedure\nis completed, each IoT unit m, with m = 1, . . ., M, submits the local\nupdates 01 to the server S, which is in charge of aggregating the\nresults into a new global model.\nIn particular, the proposed TIFeD algorithm can operate in two\nmodalities. The first, called full-network implementation (detailed\nin Subsection 4.2), allows each IoT unit to train all the H hidden\nlayers of the DL model. In this case, the result of the computation\nwill be a set containing the weights and bias updates for each\nlayer h = 1,..., H. The second, named single-layer implementation\n(explained in Subsection 4.3), enables the IoT units to train only\nthe h-th layer of the NN. The result of the computation, in this\nsecond scenario, will be a single tuple containing the weights and\nbias updates related to layer h."}, {"title": "4.2 From DFA to Federated DFA", "content": "In the federated learning setting, we consider a fixed set of clients\nM, each with a local dataset Xm, and a global model e composed\nof H hidden layers. At the beginning of each round t, the central\nserver sends the current model parameter\n$$\u03b8_t = \\{[W^1_t, b^1_t], ..., [W^H_t, b^H_t]\\},$$\nbeing wh and be the matrix of weights and the bias vector of layer\nh respectively, to each of the clients, which perform a local compu-\ntation of the DFA algorithm. Once the weight updates have been\ncomputed by each client m on its dataset Xm, the new local model\nparameters 01 are sent to the central server, which aggregates all\nthe results and updates its global state with the new model Ot+1.\nIt is important to note that since we are in an embedded sce-\nnario where devices have a limited amount of memory (e.g., the\nArduino Nano 33 BLE Sense board has 256kB of SRAM), the local\ndataset Xm cannot be arbitrarily big, because it must fit into the\ndevice's memory. This is a major limitation compared to traditional\nFL, where learning procedures benefit from very large and varied\ndatasets.\nMore in detail, the full-network TIFeD algorithm implementation,\nsummarized in Algorithm 1, can be divided into two blocks: the\ncentral server component and the IoT units component. Concerning\nthe former part, executed by the central server, it works as follows:\n(1) The node initializes, for each hidden layer h of the network,\nthe matrix of feedback weights Bh by sampling values from\na uniform distribution, and sends them to each client m.\n(2) For each round t = 1,..., T, the node sends the current\nmodel parameters \u03b8t to the clients in order to let them\nperform local updates using DFA.\n(3) After receiving the M local updates 01 from the clients,\nthe node upgrades the global model 0t+1 by aggregating\nthe results with the average function:\n$$\u03b8_{t+1} \\leftarrow \\frac{1}{M} \\sum^M_{m=1} \u03b8^m_{t+1}$$\nRegarding the NodeUpdate function, executed by each IoT unit,\nit works as follows:\n(1) The node splits its local part of the dataset Xm (relative to\nthe current round t) into mini-batches a of size bs.\n(2) For each local epoch e and for each mini-batch a, the node\ncomputes the weights updates through the DFA learning\nalgorithm, as shown in Eq. (3), and applies them to the\ncurrent model parameters \u03b8\u03c4.\n(3) Once the computation is completed, the node sends the\nnew model parameters 0t+1 back to the central server.\nThe models aggregation can be done at different points: after\neach mini-batch a, after the entire buffer X, or after the number\nof training passes e each client makes on the current buffer Xm\nThe choice of the aggregation point represents a trade-off between"}, {"title": "4.3 Single layers training", "content": "One of the main advantages of the DFA learning algorithm is the\nability to train each NN layer independently. Indeed, as shown in\nEq. (2), the layer's update direction formula SBFA is not recursive\nand, for each hidden layer h, depends only on the derivative of\nthe Loss Function L', the fixed matrix of feedback weights Bh and\nthe derivative of the activation function act'h(.). This means that,\nunlike BP, the network error is propagated directly to each hidden\nlayer and does not have to traverse the entire network.\nBy exploiting this feature, it is possible to design a federated algo-\nrithm in which each IoT unit, instead of training an entire network\non its local dataset, trains only a single layer of the global model.\nThis results in two benefits: (i) the algorithm is more lightweight\nin terms of computational and memory demands and can therefore\nrun on devices with tighter resource constraints, and (ii) the com-\nmunication between the devices and the central server requires the\nexchange of a smaller amount of data since only a portion of the\nnetwork (i.e., only the updates omh of the h-th layer) needs to be\nsent, resulting in energy savings. On the other hand, the drawbacks\nare that some overhead is added to the central server that has to\ndecide which device trains which layer, and that there is a loss in\nthe accuracy of the final global model. More accurate analyses are\nprovided in Section 5.\nThe single-layer TIFeD algorithm implementation is shown in\nAlgorithm 2 and works as follows:\n\u2022 The central server also defines, for each round t, the set\nSh which contains a random splitting of the clients into H\ndifferent groups of size s \u2190\u2190\u2190 [1]. Each group is in charge\nof training only the h-th layer of the network.\n\u2022 The IoT units compute the weights update related only to\nthe h-th layer through the DFA learning algorithm, apply\nit to the current model parameters of, and send the new\nmodel parameters 01 back to the central server.\n\u2022 After receiving the M local updates om from the clients,\nthe server updates the global model 0t+1 by aggregating\nthe results with the average function, layer-by-layer:\n$$\u03b8_{t+1} \\leftarrow \\{\u03b8^{t+1}_1,...,\u03b8^{t+1}_H\\},\\\\\u03b8^{t+1}_h \\leftarrow \\frac{1}{S} \\sum^S_{m=1} \u03b8^{m,h}_{t+1},$$\nfor h = 1,..., H."}, {"title": "5 EXPERIMENTAL RESULTS", "content": "In this section, the proposed TIFeD algorithm with its full-network\nand single-layer implementations are evaluated from different points\nof view. The code of the following experiments, written in Python,\ncan be found in the code repository\u00b9."}, {"title": "5.1 Datasets", "content": "A brief description of the datasets employed in our study is given\nin the following."}, {"title": "5.1.1 MNIST.", "content": "The first considered dataset is the MNIST (Modified\nNational Institute of Standards and Technology) database [19], a\ncollection of handwritten digits commonly used for training and\ntesting ML models able to recognize images. The elements are grey-\nscale images of size 28 \u00d7 28. The dataset is composed of 60000\ntraining images and 10000 testing images from 10 different classes,\neach one representing a digit from 0 to 9."}, {"title": "5.1.2 FashionMNIST.", "content": "The FashionMNIST database [17] was cre-\nated in 2017 as an improvement of the original MNIST dataset\nfor benchmarking ML algorithms. FashionMNIST consists in gray-\nscale images of dimension 28\u00d728 of Zalando's articles. The training\ndataset contains 60000 elements, while the testing dataset includes\n10000 elements. Each image is then associated with a label from 10\ndifferent classes."}, {"title": "5.1.3 CIFAR10.", "content": "Lastly, the CIFAR10 (Canadian Institute for Ad-\nvanced Research) dataset [8] is considered. CIFAR10 is a collection\nof colour images representing objects with size 32 \u00d7 32 belonging\nto 10 different classes. The dataset is divided into 50000 training\nsamples and 10000 test samples."}, {"title": "5.2 Feed-forward neural network training", "content": "The goal of the first experiment is to show that the proposed TIFeD\nalgorithm is able to train a feed-forward neural network from\nscratch. To this end, we trained a neural network composed of\ntwo fully-connected layers (NN-1 in Table 2) in a federated set-\ntting with M = 8 worker nodes on the MNIST and FashionMNIST\ndatasets with the following set of hyperparameters: length of the lo-\ncal dataset Xm = 7.5k images, buff_len = 50, bs = 25, and e = 5. We\nevaluated the test accuracy for both the full-network and single-layer\nimplementations with three different values of the learning rate\nand for 100 different initialization of the DFA random-feedback\nweights Bh.\nAs we can see in Figure 2, the M worker nodes are able to train a\nshared model initialized with zero-valued weights by using the pro-\nposed TIFeD algorithm. It is important to note that the single-layer\nimplementation performs worse than the full-network implementa-\ntion. This can be easily explained by the fact that, in the former case,\neach FC layer of the NN was trained by 4 out of 8 nodes, while, in\nthe latter case, each NN layer is trained by all the 8 nodes in the fed-\nerated setting. On the other hand, the computational, memory, and\nenergy demands of the nodes are halved in the single-layer imple-\nmentation compared to the full-network implementation, given that\nweight updates have to be computed and sent for only one layer h.\nAs a consequence, the single-layer implementation is more suitable\nwhen devices are extremely constrained in terms of resources."}, {"title": "5.3 Transfer learning for convolutional neural\nnetworks training", "content": "In a TinyML environment, the ability to adapt a general and complex\nML model to the specific application scenario is a fundamental\naspect. This second experiment aims to prove that, in addition to\nfeed-forward NNs, it is possible to use TIFeD to train the classifier"}, {"title": "5.4 Exploring TIFeD as the number of worker\nnodes increases", "content": "In this third experiment, the behaviour of TIFeD as the number of\nworker nodes M increases is analyzed. As a reference, we consider\nthe state-of-the-art FL algorithm, i.e., Federated Averaging. We\nemphasize that this experiment is not intended to compare the final\naccuracy achieved by our TIFeD algorithm with respect to FedAvg.\nIn fact, as previously mentioned, they are tailored for two deeply\ndifferent application scenarios: TIFeD is specifically designed to\nrun on resource-constrained devices, while FedAvg would not be\nable to be executed on tiny devices.\nWe trained the classifier of CNN-1 on the FashionMNIST dataset\nfor different values of M. In particular, we set a fixed number of\n100 images per worker and trained both FedAvg, which uses 32-bit\nlong floating-point values, and the full-network and single-layer\nimplementations of the TIFeD algorithm, which operate with 16-bit\nlong integers and an integer-only arithmetic. The experiment was\nperformed using the following set of hyperparameters for both\nalgorithms: length of the local dataset Xm = 100 images, bs = 10,\nand e = 10. To take into account the lower memory consumption of\nTIFeD with respect to FedAvg, we set buff_len = 20 for the former,\nbuff_len = 10 for the latter.\nThe results in Figure 5 show that the full-network and single-layer\nTIFeD implementations behave exactly as FedAvg when increasing\nthe number of worker nodes M. It should be noted that for the\nsame number of nodes M, FedAvg performs twice as many com-\nmunication rounds than the full-network TIFeD implementation,\nsince its buffer length is half as large, resulting in a longer and more\nenergy-consuming training."}, {"title": "5.5 The impact of the aggregation point within\nthe TIFeD algorithm", "content": "Lastly, an experiment to evaluate the impact of the aggregation\npoint within the TIFeD algorithm, is proposed. As explained in\nSection 4.2, the aggregation of the weights updates by the central\nserver can occur at three different points: after each mini-batch a,\nafter the entire buffer Xm, or after the number of training epochs e.\nTo this end, we performed the learning of the CNN-1 classifier with\nboth the implementations of TIFeD on the FashionMNIST dataset,\nusing the following set of hyperparameters: M = 128, Xm = 100\nimages, buff_len = 20, bs = 10, e = 10, and = 2048.\nAs summarized in Table 3, the choice of the aggregation point\nrepresents a trade-off between the final test accuracy and the num-\nber of required communication rounds for both the full-network and\nsingle-layer implementations. In particular, the Epochs aggregation\npoint represents the one with the lowest number of required rounds,\nbut it results in a final accuracy drop of 1.5% and 1.8% compared to\nthat provided by the Buffer aggregation point. On the other hand,\nthe latter requires e times more communication rounds than the\nformer, resulting in more energy consumption by the tiny devices."}, {"title": "6 CONCLUSIONS", "content": "The aim of this paper was to present a novel federated learning\nalgorithm specifically designed for training ML and DL models\ndirectly on extremely resource-constrained devices. Specifically,\nwe introduced TIFeD, a Tiny Integer-based Federated learning al-\ngorithm with Direct feedback alignment, with its two variants:\nthe full-network implementation, which allows each node in the\nfederated setting to train all the fully-connected layers of the neu-\nral network, and the single-layer implementation, that enables the\ndevices to train only a single layer of the entire NN, resulting in\na more lightweight algorithm in terms of computation, memory\nand energy required. The experimental results show the feasibility\nand effectiveness of the proposed solution. Future works will con-\nsider new models as well as further optimizations in the learning\nprocedure."}]}