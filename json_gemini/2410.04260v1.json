{"title": "Pareto Control Barrier Function for Inner Safe Set Maximization Under Input Constraints", "authors": ["Xiaoyang Cao", "Zhe Fu", "Alexandre M. Bayen"], "abstract": "This article introduces the Pareto Control Barrier Function (PCBF) algorithm to maximize the inner safe set of dynamical systems under input constraints. Traditional Control Barrier Functions (CBFs) ensure safety by maintaining system trajectories within a safe set but often fail to account for realistic input constraints. To address this problem, we leverage the Pareto multi-task learning framework to balance competing objectives of safety and safe set volume. The PCBF algorithm is applicable to high-dimensional systems and is computationally efficient. We validate its effectiveness through comparison with Hamilton-Jacobi reachability for an inverted pendulum and through simulations on a 12-dimensional quadrotor system. Results show that the PCBF consistently outperforms existing methods, yielding larger safe sets and ensuring safety under input constraints.", "sections": [{"title": "I. INTRODUCTION", "content": "Control Barrier Functions (CBFs) provide a powerful method to ensure the safety of autonomous systems by maintaining system trajectories within a predefined safe set [1]. They have been successfully applied in various domains, including robotics [2] and autonomous vehicles [3].\nHowever, ensuring safety becomes challenging when systems operate under input constraints [4]\u2013[7]. Traditional CBFs typically assume the availability of arbitrary control inputs [8], [9], which allows the system to be guided within the safe set without limitations. However, this assumption often overlooks the practical reality that control inputs are constrained by physical limitations of actuators, energy resources, or other system-specific constraints. As a result, the safe set may no longer be forward invariant under such restricted inputs [4].\nCBFs under input constraints: Recent research has tried to address this problem. Agrawal and Panagou [4] introduced Input Constrained CBFs (ICCBFs), iteratively defining functions to form an inner safe set $C^*$ that is forward invariant under input constraints. Breeden and Panagou [5] introduced Zeroing CBFs (ZCBFs) for high-relative-degree systems, ensuring forward invariance by converting higher-order constraints into ZCBFs. However, both approaches tend to be overly conservative, as they do not guarantee the largest possible safe set, potentially limiting the system's operational flexibility.\nNeural CBFs: Neural CBFs (NCBFs) have emerged as an effective approach for ensuring safety in complex, high-dimensional systems, where traditional CBFs may be difficult to design [10]. These methods have been extended to handle parametric uncertainties, unknown dynamic environments, and safe navigation tasks [11]\u2013[13]. However, few works have integrated input constraints into NCBFs. Liu et al. proposed the non-saturating CBF (NSCBF) to handle input constraints solving a min-max optimization [6]. Though effective, the complexity of this approach leads to longer training times. Oswin et al. introduced a policy NCBF based on policy iteration [7]. However, their method doesn't guarantee the largest possible inner safe set either.\nHJ reachability: Hamilton-Jacobi (HJ) reachability analysis theoretically computes the largest control-invariant set [14]. Recent work has combined HJ reachability with CBFs to mitigate the overly conservative problem of HJ policies [15]. However, HJ reachability is computationally intensive and practically limited to systems with fewer than five dimensions, restricting its applicability in higher-dimensional dynamical systems.\nWe summarize our contributions as follows:\n\u2022 Maximizing Inner Safe Set: We propose the PCBF algorithm (Algorithm 1) to determine the largest inner safe set under input constraints.\n\u2022 Reduced Training Time: We enhance training efficiency by applying a Gaussian sampling method to the inner safe set's interior.\n\u2022 Validation on Benchmark Systems: We validate our method by comparing PCBF results for the inverted pendulum with HJ reachability and through simulations on a 12-dimensional quadrotor system.\nThe remainder of this article is organized as follows: Section II provides preliminaries, including problem definition, CBFs, Neural CBFs, and Pareto Multi-task Learning. Section III presents our methodology, detailing the PCBF algorithm. Section IV demonstrates the effectiveness of our approach through experiments on an inverted pendulum and a quadrotor system. Finally, Section V concludes the paper and discusses future work directions."}, {"title": "II. PRELIMINARIES", "content": "We consider continuous-time, control-affine dynamics:\n$\\dot{x} = f(x) + g(x)u,$\\nwhere $x \\in \\mathcal{X} \\subseteq \\mathbb{R}^n$, $u \\in \\mathcal{U} \\subseteq \\mathbb{R}^m$, and $f, g$ are locally Lipschitz continuous functions. To ensure safety, we introduce the concept of a safe set."}, {"title": "A. Problem Definition", "content": ""}, {"title": "Definition 1 (Safe Set)", "content": "The Safe Set $S$ is defined as:\n$S = \\{x \\in \\mathcal{X} : h(x) \\geq 0\\},$\\nwhere $h : \\mathcal{X} \\rightarrow \\mathbb{R}$ is a continuously differentiable function.\nThe safe set $S$ is defined to include all states $x$ in which the system remains safe during operation. In practice, the safe set often comes from the physical constraints and safety requirements inherent in the system, such as avoiding collisions or maintaining stability. However, due to the presence of input constraints, ensuring forward invariance of the entire safe set is challenging [4]. Thus, the concept of an inner safe set is introduced."}, {"title": "Definition 2 (Forward Invariant)", "content": "A set $C \\subseteq \\mathbb{R}^n$ is forward invariant under a dynamical system (1) if for any initial condition $x(0) \\in C$, the trajectory $x(t) \\in C$ for all $t \\geq 0$."}, {"title": "Definition 3 (Inner Safe Set [4])", "content": "An Inner Safe Set $C$ is a non-empty, closed subset of the safe set $S$ such that there exists a feedback controller $\\pi : C \\rightarrow \\mathcal{U}$ that renders $C$ forward invariant under the system dynamics.\nThe goal of this research is to find the largest such inner safe set given the system's input constraints. The problem is formulated as below:"}, {"title": "Problem 1 (Inner Safe Set Maximization)", "content": "Given a dynamical system (1) and a safe set $S \\subseteq \\mathcal{X}$, determine the largest possible inner safe set $C^* \\subseteq S$ and a control policy $\\pi: C^* \\rightarrow \\mathcal{U}$ such that $C^*$ remains forward invariant under the system dynamics."}, {"title": "B. Control Barrier Functions", "content": "Definition 4 (Control Barrier Functions (CBFs)). A function $h: \\mathcal{X} \\rightarrow \\mathbb{R}$ is considered a CBF if there exists an extended class-$\\mathcal{K}$ function such that for all states $x \\in \\mathcal{X}$, the following inequality holds:\n$\\sup_{u \\in \\mathcal{U}} [L_f h(x) + L_g h(x) u] \\geq -\\alpha(h(x)),$\nwhere $L_f h(x) = \\nabla h(x) \\cdot f(x)$ and $L_g h(x) = \\nabla h(x) \\cdot g(x)$ are the Lie derivatives of $h(x)$ along the vector fields $f(x)$ and $g(x)$, respectively.\nCBFs provide a systematic approach to ensuring the forward invariance of safe sets by applying the following lemma [1]:\nLemma 1 (Ames et al. [1]). Given a set $C = \\{x \\in \\mathcal{X} : h(x) \\geq 0\\}$ defined by a CBF $h(x)$, the set $C$ is forward invariant under the control input $u \\in \\mathcal{U}$ if there exists a feedback controller $\\pi(x)$ such that:\n$L_f h(x) + L_g h(x) \\pi(x) \\geq -\\alpha(h(x)), \\quad \\forall x \\in C.$\nThe CBF Quadratic Program (CBF-QP) is formulated to find the optimal control input $u(x)$ that minimizes the deviation from the desired control $u_{\\text{des}}$ while satisfying the CBF's safety constraints:"}, {"title": "Problem 2 (CBF-QP)", "content": "$\\min_{u \\in \\mathcal{U}} ||u - u_{\\text{des}}(x)||^2 \\\\\n \\text{s.t.} \\quad L_f h(x) + L_g h(x) u \\geq -\\alpha(h(x)).$\\nJustification for the need of an inner safe set: When $\\mathcal{U}$ is unbounded, since (3) is linear in $u$, it is always possible to find a valid CBF and corresponding control input $u$ satisfying (3) if $L_g h(x) \\neq 0$.\nHowever, when input constraints exist, the control input $u$ satisfying (3) may not always comply with the constraints. Certain states within the safe set may no longer be forward invariant. Therefore, the challenge becomes identifying the largest subset of the safe set, the maximum inner safe set."}, {"title": "C. Neural CBFs", "content": "NCBFs address the difficulty of hand-designing CBFs for complex systems by using neural networks to approximate a valid CBF $h_{\\theta_1}(x)$ and its corresponding controller $\\pi_{\\theta_2}(x)$, where $\\theta_1$ and $\\theta_2$ are the parameters of the neural networks for the CBF and controller, respectively [10], [16]. For a given safe set $S$, NCBFs define three loss functions: $\\mathcal{L}_{\\text{safe}}$, $\\mathcal{L}_{\\text{unsafe}}$, and $\\mathcal{L}_{\\text{feas}}$. To compute these losses, we sample a set of points $\\mathcal{X} = \\{x_1, ..., x_N\\} \\subset \\mathcal{X}$, where $N$ is the number of sampled points. Let $N_{\\text{safe}}$ and $N_{\\text{unsafe}}$ denote the number of sampled points from the safe set $S$ and the complement of the safe set $\\mathcal{X} \\backslash S$.\n$\\mathcal{L}_{\\text{safe}} = \\frac{1}{N_{\\text{safe}}} \\sum_{x_i \\in S} \\max\\{0, -h_{\\theta_1}(x_i)\\},$\n$\\mathcal{L}_{\\text{unsafe}} = \\frac{1}{N_{\\text{unsafe}}} \\sum_{x_i \\in \\mathcal{X} \\backslash S} \\max\\{0, h_{\\theta_1}(x_i)\\},$\n$\\mathcal{L}_{\\text{feas}} = \\frac{1}{N_{\\text{safe}}} \\sum_{x_i \\in \\mathcal{X} \\cap S} \\max\\{0, -[L_f h_{\\theta_1}(x_i) + L_g h_{\\theta_1}(x_i) \\pi_{\\theta_2}(x_i) + \\alpha(h_{\\theta_1}(x_i))]\\}.$\n$\\mathcal{L}_{\\text{safe}}$ and $\\mathcal{L}_{\\text{unsafe}}$ penalize states where $h_{\\theta_1}(x)$ misclassifies safety, either within the safe set or outside it, while $\\mathcal{L}_{\\text{feas}}$ ensures $\\pi_{\\theta_2}(x)$ satisfies the feasibility condition (4) for forward invariance.\nHowever, such NCBFs still require a predefined safe set. Liu et al. [6] proposed the NSCBF $h_{\\theta}(x)$, which removes the need for a predefined safe set and directly handles input constraints:\n$h_{\\theta}(x) = h(x) - (\\text{nne}(x) - \\text{nne}(x_e))^2,$\\nwhere $\\text{nne}(x)$ is a neural network with parameter $\\theta \\in \\mathbb{R}^P$, and $x_e$ is a known safe state that must be included in the learned inner safe set. Typically, in problems aimed at maintaining the system's proximity to a stable point, $x_e$ is the stable point itself. For obstacle avoidance problems, $x_e$ can be a point far"}, {"title": "III. METHODOLOGY", "content": "We introduce the Pareto multi-task learning framework [17] into traditional NCBFs to propose the PCBF algorithm. This approach achieves a balance between ensuring safety and maximizing the inner safe set under input constraints. We use the NCBF formulation from equation (9) in this study."}, {"title": "A. Loss Function Design", "content": "Our loss function consists of two main components: the feasibility loss and the volume loss. Computing these two losses require sampling in the state space. To ensure sufficient data density near the known safe state $x_e \\in \\mathcal{X}$, we employ a multivariate Gaussian sampling method $\\mathcal{X} = \\{x_i | x_i \\stackrel{i.i.d}{\\sim} \\mathcal{N}(x_e, \\Sigma), i = 1, 2, ..., N_N \\} \\subset \\mathcal{X}$, where $N_N$ is the number of sampled points. The covariance matrix $\\Sigma$ is diagonal, with each diagonal element defined as $\\sigma_{ii} = \\frac{A_i}{k}$, where $A_{x_i}$ is the state space length in the $i$-th dimension, and $k$ is a positive hyperparameter. The feasibility loss $\\mathcal{L}_{\\text{feas}}$ ensures that the learned inner safe set $\\mathcal{C}_{\\theta}$ is forward invariant:\n$\\mathcal{L}_{\\text{feas}} = \\frac{1}{N_N} \\sum_{x_i \\in \\mathcal{X}_{N_N} \\cap \\mathcal{C}_h} \\max\\{0, - \\sup_{u \\in \\mathcal{U}} \\varphi_{\\theta}(x_i, u)\\},$\n$\\varphi_{\\theta}(x, u) = L_f h_{\\theta}(x) + L_g h_{\\theta}(x) u + \\alpha(h_{\\theta}(x)),$\nFor simplicity, we assume linear input constraints, making $\\mathcal{U}$ a polyhedron. Since $\\varphi_{\\theta}(x, u)$ is affine in $u$, the supremum over $\\mathcal{U}$ is necessarily achieved at some vertex of $\\mathcal{U}$, allowing closed-form computation of $\\mathcal{L}_{\\text{feas}}$.\n$\\sup_{u \\in \\mathcal{U}} \\varphi_{\\theta}(x, u) = \\max_{u \\in \\mathcal{V}(\\mathcal{U})} \\varphi_{\\theta}(x, u),$\nwhere $\\mathcal{V}(\\mathcal{U})$ is the set of vertexes of $\\mathcal{U}$. The volume loss $\\mathcal{L}_{\\text{vol}}$ is designed to encourage the expansion of the learned inner safe set by minimizing the deviation from $S$:\n$\\mathcal{L}_{\\text{vol}} = \\frac{1}{N_N} \\sum_{x_i \\in \\mathcal{X}_{N_N} \\cap \\mathcal{C}_h} (\\text{nne}(x) - \\text{nne}(x_e))^2,$"}, {"title": "B. Pareto Multi-task Learning (PMTL)", "content": "Consider $M$ correlated tasks with a loss vector:\n$\\mathcal{L}(\\theta) = [\\mathcal{L}_1(\\theta) \\quad \\mathcal{L}_2(\\theta) \\quad ... \\quad \\mathcal{L}_M(\\theta)], \\quad \\theta \\in \\mathbb{R}^P,$\nwhere $\\mathcal{L}_i(\\theta)$ is the loss of the $i$-th task. In general, it is impossible to find a single solution $\\theta$ that simultaneously optimizes all the objectives. Instead, we can identify a collection of Pareto optimal solutions, each representing a distinct optimal trade-off among the various objectives [17].\nDefinition 5 (Pareto Dominance). A solution $\\theta$ dominates another solution $\\theta'$ if:\n$\\bullet \\quad \\forall i \\in \\{1, ..., M\\}, L_i(\\theta) \\leq L_i(\\theta'),$\n$\\bullet \\quad \\exists j \\in \\{1, ..., M\\} \\text{ such that } L_j(\\theta) < L_j(\\theta').$\nDefinition 6 (Pareto Optimality). A solution $\\theta$ is Pareto optimal if no other solution $\\theta'$ exists that dominates $\\theta$.\nIn other words, a solution $\\theta$ is considered Pareto optimal if no other feasible solution $\\theta$ exists that can reduce any loss without simultaneously increasing at least one other loss.\nDefinition 7 (Pareto Front). The Pareto Front $\\mathcal{P}_c$ is the set of all loss vectors associated with the Pareto optimal solutions:\n$\\mathcal{P}_c = \\{L(\\theta) | \\theta \\in \\mathbb{R}^P \\text{ is Pareto optimal}\\}.$\nThe Pareto front represents the best possible trade-offs among the competing objectives that can be achieved by any solution. PMTL provides a framework for simultaneously optimizing multiple objectives and converge to the Pareto front. Two common PMTL methods are:\nLinear combination: A non-negative linear weighted sum is utilized to aggregate the losses of all tasks into a single loss: $L(\\theta) = \\sum_{i=1}^M \\lambda_i L_i(\\theta)$, where $\\lambda_i \\geq 0$ is the weight for the $i$-th task. While straightforward, this approach has some limitations: firstly, selecting appropriate values for $\\lambda_i$ is challenging and often requires extensive empirical tuning; secondly, this method can only yield solutions on the convex portion of the Pareto front [18].\nGradient-based method: Fliege and Svaiter [19] proposed a gradient-based method generalizing the single objective steepest descent algorithm. The algorithm's update rule is given by: $\\theta_{t+1} = \\theta_t + \\eta d_t$, where $\\eta > 0$ is the learning"}, {"title": "C. Pareto Control Barrier Function (PCBF)", "content": "Problem 1 can be reformulated as a PMTL problem involving two competing objectives: volume loss $\\mathcal{L}_{\\text{vol}}$ and feasibility loss $\\mathcal{L}_{\\text{feas}}$. The desired Pareto optimal solution, denoted as $\\theta^*$, achieves zero feasibility loss while minimizing the volume loss:\nProblem 3 (Reformulation of Inner Safe Set Maximization).\n$\\theta^* = \\arg \\min_{\\theta \\in \\mathbb{R}^P} L_{\\text{vol}}(\\theta) \\\\\n\\text{s.t.} \\quad L_{\\text{feas}}(\\theta) = 0.$"}, {"title": "IV. EXPERIMENTS", "content": "In this section, we evaluate the performance of the PCBF algorithm. First, we use a 2D inverted pendulum example, where the low dimensionality allows HJ Reachability to compute the infinite-time viability kernel as the ground truth for the largest inner safe set. Comparing PCBF results with HJ validates its effectiveness. Next, we extend to a 12-dimensional quadrotor obstacle avoidance scenario and run simulations to assess PCBF's performance in this more complex setting. Neural CBFs trained with linear combination loss (LCCBF) serve as our baseline. All neural networks are trained until convergence and share the same architecture (3 layers with 512, 256, 128 neurons and tanh activations)."}, {"title": "A. Inverted Pendulum", "content": "The inverted pendulum dynamics are $\\dot{\\omega}, \\ddot{\\omega} = \\sin(\\theta) + u$, where $\\theta$ is the angle of the pendulum from the upright position, $\\omega$ is the angular velocity and $u$ is the control input. The safe set is defined as $|\\theta| \\leq 1$, and the input constraint is $|u| \\leq 1$.\nThe left subfigure of Figure 3 shows a strong overlap between the inner safe set generated by PCBF and the infinite-time viability kernel from HJ reachability. Almost all states in the PCBF inner safe set fall within the viability kernel, demonstrating that PCBF effectively maximizes the safe set while ensuring safety. In contrast, the LCCBF-generated set shows significant discrepancies, with many states outside the kernel, leading to potential safety violations in practice.\nWe visualized the training process of PCBF and LCCBF in the right subfigure in Figure 3. Initially, LCCBF effectively approximates the boundary of the largest inner safe set,"}, {"title": "B. Quadrotor", "content": "The state of the quadrotor involves its position $x, y, z$, velocity $v_x, v_y, v_z$, Euler angles $\\phi, \\theta, \\psi$, and angular velocity $\\omega_x, \\omega_y, \\omega_z$. The state dimension is 12 and the control dimension is 4. The system dynamics and input constraint can be found in [20]. A rectangular obstacle is placed in the scenario and the safe set is defined such that the quadrotor must maintain a minimum distance from the obstacle. Specifically, the safe set is $x < -1.5$ or $x > -0.75$ or $y < -0.375$ or $y \\geq 0.375$.\nFigure 4 illustrates the inner safe sets of PCBF and LCCBF in various dimensions through 2D slices. Notably, the PCBF consistently yields a significantly larger inner safe set slice compared to the LCCBF across all slices. For example, in the left subfigure in Figure 4, where all states except $x$ and $y$ are set to zero, the quadrotor can hover in any unobstructed region. Consequently, the area outside the black region is safe. The inner safe set of the PCBF encompasses a substantial portion of the safe state, while the LCCBF's inner safe set is confined to a relatively small area. The volume of the inner safe set for the LCCBF is only 14% of that for the PCBF in the entire 12-dimensional state space.\nWe conducted simulations using RotorPy [21] in a wind-less environment with a refresh rate of 300 Hz. The nominal policy is based on the control algorithm proposed by [22]."}, {"title": "V. CONCLUSIONS", "content": "In this paper, we introduce the Pareto Control Barrier Function (PCBF) framework to maximize the inner safe set under input constraints. Using a Pareto multi-task learning approach, we balanced safety and set size, with PCBF significantly outperforming LCCBF methods. Comparisons with HJ reachability for the inverted pendulum showed that PCBF closely approximates the largest inner safe set. Simulations with the quadrotor system further demonstrated PCBF's effectiveness in complex, high-dimensional environments. Future work will focus on adapting the PCBF framework to handle uncertainties in system dynamics and external disturbances."}, {"title": "APPENDIX", "content": "A. Proof of lemma 3\nLet $\\theta^*$ be the solution to problem 3. Suppose $\\theta^*$ is not Pareto optimal. Then there exists a Pareto optimale $\\theta$ such that:\n$L_{\\text{feas}}(\\theta) \\leq L_{\\text{feas}}(\\theta^*) = 0$\n$L_{\\text{vol}}(\\theta) \\leq L_{\\text{vol}}(\\theta^*)$\nwith at least one of the inequalities being strict. However, since $L_{\\text{feas}}(\\theta^*) = 0$, we must have $L_{\\text{feas}}(\\theta) = 0$ as well. This means $\\theta$ is also a feasible solution to problem 3. If $L_{\\text{vol}}(\\theta) < L_{\\text{vol}}(\\theta^*)$, then $\\theta$ would be a better solution to problem 3 than $\\theta^*$, which contradicts the assumption that $\\theta^*$ is the solution to this problem. If $L_{\\text{vol}}(\\theta) = L_{\\text{vol}}(\\theta^*)$, then $\\theta$ is also an optimal solution to problem 3, and thus satisfies the conditions of the lemma.\nTherefore, our assumption must be false, and $\\theta^*$ is indeed Pareto optimal. By definition, $[L_{\\text{feas}}(\\theta^*), L_{\\text{vol}}(\\theta^*)]^T$ must lie on the Pareto front.\nB. Analytical solution for PCBF subproblems\nSubproblems (20), (21), and (22) are special cases of problem (16) with $M = 2$. We first provide the general solution for problem (16). For $M = 2$, the problem becomes:\n$(d_t, \\alpha_t) = \\arg \\min_{d \\in \\mathbb{R}^P, \\alpha \\in \\mathbb{R}} \\frac{1}{2} \\alpha + \\frac{1}{2} ||d||^2$\ns.t. $\\nabla L_1(\\theta_t)^T d \\leq \\alpha$\n$\\nabla L_2(\\theta_t)^T d \\leq \\alpha$\nAs problem (25) is a QP problem, we can apply the KKT conditions:\nd_t + \\lambda_1 \\nabla L_1(\\theta_t) + \\lambda_2 \\nabla L_2(\\theta_t) = 0\n\\lambda_1 + \\lambda_2 = 1\n\\lambda_1 (\\nabla L_1(\\theta_t)^T d_t - \\alpha_t) = 0\n\\lambda_2 (\\nabla L_2(\\theta_t)^T d_t - \\alpha_t) = 0\n\\lambda_1, \\lambda_2 \\geq 0\n\\nabla L_1(\\theta_t)^T d_t - \\alpha_t \\leq 0\n\\nabla L_2(\\theta_t)^T d_t - \\alpha_t \\leq 0$\nFrom the first two conditions, we get:\nd_t = - \\lambda_1 \\nabla L_1(\\theta_t) - \\lambda_2 \\nabla L_2(\\theta_t)\n\\lambda_1 + \\lambda_2 = 1\nLet $\\lambda_1 = \\lambda$ and $\\lambda_2 = 1 - \\lambda$. Then:\nd_t = - \\lambda \\nabla L_1(\\theta_t) - (1 - \\lambda) \\nabla L_2(\\theta_t)"}]}