{"title": "XAI-based Feature Ensemble for Enhanced Anomaly Detection in Autonomous Driving Systems", "authors": ["Sazid Nazat", "Mustafa Abdallah"], "abstract": "The rapid advancement of autonomous vehicle (AV) technology has introduced significant challenges in ensuring transportation security and reliability. Traditional AI models for anomaly detection in AVs are often opaque, posing difficulties in understanding and trusting their decision-making processes. This paper proposes a novel feature ensemble framework that integrates multiple Explainable AI (XAI) methods SHAP, LIME, and DALEX-with various AI models to enhance both anomaly detection and interpretability. By fusing top features identified by these XAI methods across six diverse AI models (Decision Trees, Random Forests, Deep Neural Networks, K-Nearest Neighbors, Support Vector Machines, and AdaBoost), the framework creates a robust and comprehensive set of features critical for detecting anomalies. These feature sets, produced by our feature ensemble framework, are evaluated using independent classifiers (CatBoost, Logistic Regression, and LightGBM) to ensure unbiased performance. We evaluated our feature ensemble approach on two popular autonomous driving datasets (VeReMi and Sensor) datasets. Our feature ensemble technique demonstrates improved accuracy, robustness, and transparency of AI models, contributing to safer and more trustworthy autonomous driving systems.", "sections": [{"title": "1 Introduction", "content": "The rapid advancement of autonomous vehicle (AV) technology has introduced significant challenges in transportation security. As AVs become more prevalent, ensuring their safety and reliability is paramount [1]. Artificial Intelligence (AI) models have shown promise in detecting anomalies in the behavior of AVs [2], but their black-box nature poses considerable obstacles to understanding and trusting their decision-making processes. This lack of interpretability is particularly concerning in the safety-critical domain of autonomous driving, where explainable decisions are crucial for public safety, user trust, and regulatory compliance [3].\nCurrent anomaly detection systems for AVs often rely on single AI models [4] or individual explainable AI (XAI) methods [5]. While these approaches have demonstrated promising results, they frequently fall short in capturing the full complexity of anomaly detection and providing robust and reliable explanations [6]. The key challenges in this context include:\n\u2022 Incomplete Feature Importance Assessment: Individual XAI methods often provide limited insights into feature importance, failing to capture the comprehensive set of factors influencing anomaly detection model's decisions [7].\n\u2022 Lack of Consensus Among XAI Methods: Different XAI methods can yield conflicting interpretations, making it difficult to derive a consistent understanding of anomaly detection model's behavior [8].\n\u2022 Insufficient Utilization of Multiple AI Models: Relying on a single AI model limits the robustness of anomaly detection [3], as different models may excel in different aspects of data interpretation.\n\u2022 Challenges in Feature Selection Optimization: Effective anomaly detection requires identifying the most relevant features, a process that can be hindered by the limitations of using single XAI method [5].\nTo help address these issues, this paper proposes a novel XAI-based feature ensemble framework that integrates multiple XAI methods (SHAP [9], LIME [10], and DALEX [11]) with various AI models to enhance anomaly detection in autonomous driving systems. Our approach combines insights from different XAI methods to provide a more representative set of features that can better explain decision-making of anomaly detection models for AVs.\nOverview of Our Feature Ensemble Framework: Our framework operates as follows. We use a diverse set of AI models, including Decision Trees (DT), Random Forests (RF), Deep Neural Networks (DNN), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), and Adaptive Boosting (AdaBoost), to build anomaly detection models using the input data from autonomous vehicles. We then apply XA\u0399 methods (here SHAP, LIME, and DALEX) to these models to extract top features, providing a multi-faceted view of feature importance. The top features identified by each XAI method are combined using a frequency analysis technique to create a unified set of features, capturing the most critical aspects of the data.\nWe evaluate our framework using two autonomous driving datasets, VeReMi [12] and Sensor [13], which represent different aspects of autonomous vehicle behavior. The VeReMi dataset focuses on vehicular positioning and speed in x, y, and z directions, while the Sensor dataset encompasses data from multiple sensors used in"}, {"title": "1.1 Summary of Contributions", "content": "The main contributions of this paper can be summarized as follows.\n\u2022 We propose a novel feature ensemble approach that combines SHAP, LIME, and DALEX \u03a7\u0391\u0399 methods to enhance feature importance analysis, leveraging the strengths of each method for a more comprehensive understanding. The proposed approach is a frequency-based feature ensemble technique that creates a unified set of top features.\n\u2022 We apply our feature ensemble approach using six diverse AI models (DT, RF, DNN, KNN, SVM, AdaBoost) to gain insights into feature importance,"}, {"title": "2 Related Works", "content": null}, {"title": "2.1 Anomaly detection in Autonomous Driving", "content": "Numerous studies have investigated anomaly detection in autonomous driving systems [15-17]. For instance, in [15], a modified convolutional neural network (M-CNN) was applied to onboard and external sensor measurements to detect instantaneous anomalies in an autonomous vehicle (AV). This approach focuses on identifying sudden changes or spikes in sensor data values or abrupt changes in GPS location coordinates. The study [16] employed a combination of convolutional neural networks (CNN) and Kalman filtering to detect abnormal behaviors in AVs. Meanwhile, the authors in [17] used long short-term memory (LSTM) networks to identify false data injection (FDI) attacks, ensuring the stable operation of AVs. Our work, however, emphasizes anomaly detection through the lens of explainable AI (XAI) and feature understanding. Several works have also explored anomaly detection in networks of vehicles [18-21]. The study [18] proposed a hybrid deep anomaly detection (HDAD) framework, enabling AVs to detect malicious behavior based on shared sensor network data. Additionally, the research [19] utilized time-series anomaly detection techniques to identify cyber attacks or faulty sensors. The prior work [20] leveraged a CNN-based LSTM to classify signals from multiple sources as either anomalous or healthy in AVs. In contrast, our framework introduces a novel method to identify significant features of an AV which are taken into account to classify the AV as benign or anomalous using different well-known XAI techniques."}, {"title": "2.2 Explanation using \u03a7\u0391\u0399", "content": "In the AI domain, several studies have employed XAI methods to enhance the performance of AI models. Previous research [22] utilized various XAI techniques, such as Saliency, Guided Backpropagation, and Integrated Gradients, to determine if these methods could improve model performance beyond merely providing explanations in the context of image classification. Another study [23] introduced an innovative XAI-based masking approach that uses integrated gradients explanations to enhance image classification systems. Additionally, [24] examined the explanations generated by XAI methods for an EEG emotion classification system. However, none of these"}, {"title": "2.3 Contributions of This Work", "content": "In our work, we consider the top features from three XAI methods from six AI models and fuse them using frequency analysis in order to get a more stable and robust set of features that are responsible for the classification of AVs. Afterwards, we feed these feature sets to three independent classifiers to make sure there is no bias in the performance. This multi-layered approach offers a more holistic and dependable method for identifying critical features in anomaly detection for AVs, addressing the limitations of previous single-AI or single-XAI approaches.\nOur framework leverages multiple explainable AI (XAI) methods across various black-box AI models. Specifically, we employ three XAI methods (SHAP, LIME, and DALEX) in conjunction with six AI models (Decision Trees, Random Forests, Deep Neural Networks, K-Nearest Neighbors, Support Vector Machines, and AdaBoost) to identify important features. We then use a frequency-based fusion approach to consolidate these features into a unified set. The effectiveness of this fused feature set is evaluated using three independent classifiers (CatBoost, LightGBM, and Logistic Regression) and compared against the performance of individual XAI methods on two distinct datasets."}, {"title": "3 The Problem Statement", "content": "We now outline the key challenges in anomaly detection for autonomous driving systems, including the limitations of black-box AI models, and present our proposed framework that integrates multiple XAI methods and AI models to enhance accuracy and interpretability of these systems."}, {"title": "3.1 Challenges in Anomaly Detection for Autonomous Vehicles", "content": "Ensuring the safety and reliability of AVs has become paramount. Al models have shown promise in detecting anomalies in AV behavior [28], but their black-box nature poses considerable obstacles to understanding and trusting their decision-making processes. This lack of interpretability is particularly concerning in the safety-critical domain of autonomous driving, where explainable decisions are crucial for public safety, user trust, and regulatory compliance [29].\nCurrent anomaly detection systems for AVs often rely on single AI models or individual XAI methods. While these approaches have demonstrated some success, they have several limitations. First, a single XAI method may fail to identify all critical features necessary for effective anomaly detection. Second, relying on a single AI model for anomaly detection limits the ability to leverage the diverse strengths of various machine learning algorithms. Third, determining the optimal set of features for anomaly detection is a complex task that requires balancing model performance with interpretability and computational efficiency. Traditional methods may struggle to achieve this balance.\nTo address these challenges, a more robust and comprehensive approach is needed one that integrates multiple AI models and XAI methods to provide a holistic understanding of feature importance and anomaly detection. This approach should aim to enhance the interpretability, reliability, and overall effectiveness of anomaly detection systems for autonomous vehicles."}, {"title": "3.2 Main Objectives for Enhanced Anomaly Detection in\nAutonomous Vehicles", "content": "To address these challenges, there is an imperative need for a novel framework that integrates multiple Explainable AI (XAI) methods and AI models to enhance the accuracy and interpretability of anomaly detection in autonomous driving systems. Such a framework should be designed with the following key objectives:\na) Synthesize Insights from Various X\u0391\u0399 Techniques: By employing a range of XAI methods, such as SHAP, LIME, and DALEX, the framework can provide a holistic and detailed understanding of feature importance. Each XAI technique offers unique insights and strengths, and their combined application can uncover critical features that may be overlooked when using a single method. This comprehensive synthesis ensures a deeper and more accurate analysis of the features influencing AV's behavior.\nb) Develop a Fusion Methodology: The framework must incorporate a robust fusion methodology to reconcile potentially conflicting feature rankings generated"}, {"title": "4 Framework", "content": null}, {"title": "4.1 Adversary and Defense Models", "content": "Adversary Model: To rigorously test the robustness of our XAI-enhanced anomaly detection framework, we describe the adversary model featuring a sophisticated threat actor targeting Vehicular Ad-hoc Networks (VANETs). We focus on data falsification attack scenario, where sensor readings (e.g., position and speed in x, y, and z directions for the VeReMi dataset) are subtly altered by the attacker. The adversary has limited knowledge of the defense model's architecture, the capacity to introduce or compromise AVs, however it can generate and inject realistic falsified data. This model challenges our defense system to validate the efficacy and robustness of our XAI-based feature ensemble approach in identifying subtle and sophisticated anomalies.\nDefense Model: In our defense model for autonomous vehicles (AVs), we equip each AV with different distinct sensors to gather data during inter-vehicle communications, mirroring previous research methodologies [13]. This sensor data is concatenated to form a comprehensive input for our anomaly detection classifiers. Our innovative approach involves applying multiple X\u0391\u0399 methods-SHAP, LIME, and DALEX to this data across various AI models. We then employ a feature ensemble technique, consolidating the top features identified by each XAI method through frequency analysis. This fused feature set is used to train independent classifiers, enhancing the accuracy and interpretability of anomaly detection in"}, {"title": "4.2 An End-to-End Feature Ensemble Pipeline for\nAutonomous Driving Systems", "content": "The primary objective of this research is to develop a pipeline that enhances our understanding of the main features of autonomous vehicles (AVs) and the decision-making processes of anomaly detection AI models in autonomous driving systems. To accomplish this, we propose a comprehensive end-to-end framework that leverages the synergistic power of multiple explainable AI methods. Our approach uniquely combines SHAP, LIME, and DALEX to analyze feature importance across diverse AI models, including decision trees, random forests, k-nearest neighbors, support vector machines, and adaptive boosting. By fusing the outputs of these XAI methods through frequency analysis, we derive a consolidated set of top features for each dataset. This novel feature ensemble methodology aims to provide a better understanding of critical factors in anomaly detection for autonomous driving systems.\nThe different components of our pipeline (shown in Figure 1) are explained in details below.\nLoading Autonomous Driving Dataset: In this study, we employ two distinct datasets for the anomaly classification of autonomous vehicles (AVs). The first dataset is the Vehicular Reference Misbehavior (VeReMi) dataset, designed to analyze misbehavior detection mechanisms in vehicular ad hoc networks (VANETs). Generated from a simulation environment, it provides message logs of on-board units (OBU) and labeled ground truth data [30]. The second dataset is based on Sensor data [13], aimed at monitoring unusual activity from an AV using data gathered from ten distinct sensors on the vehicle. It is important to note that, when selecting the Sensor data for each AV, we adhered to the data ranges specified in previous works [31], [32].\nFeature Extraction: After loading the datasets, we select the essential features from each dataset to build our AI models. Feature extraction is crucial in autonomous driving to mitigate adversarial attacks [33]. By identifying features indicative of attacks, the overall attack surface can be reduced. For the VeReMi dataset, we selected"}, {"title": "4.3 Lists of Top Features for Anomaly Detection in the Used\nAutonomous Driving Datasets", "content": "We now present the complete lists of primary characteristics (features) used in constructing our anomaly detection AI models, along with their explanations, for the VeReMi and Sensor datasets utilized in our framework. Tables 1 and 2 describe each feature in the Sensor and VeReMi datasets, respectively. Our \u03a7\u0391\u0399 framework will be employed to derive key insights from these features for detecting anomalous AV behavior in these datasets (as will be shown in Section 5)."}, {"title": "4.4 Illustrations of Global Explanations by the Three \u03a7\u0391\u0399\nmethods", "content": "We now present three illustrative instances of XAI global explanations drawn from the three \u03a7\u0391\u0399 models considered in this work. We utilized DT to illustrate the \u03a7\u0391\u0399 approaches we are using in this work, as an example of how we see the features and their contributions to our VeReMi dataset.\nGlobal Explanations using SHAP: Figure 2a illustrates the top four features in the VeReMi dataset that had the greatest impact on anomaly identification for AVs in the x, y, and z directions for both position and speed in SHAP. Furthermore, for SHAP, the figure demonstrates that in this particular scenario, the spd_z and pos_Z features do not contribute in any way to the detection of anomalies.\nGlobal Explanations using LIME: Now in Figure 2b, it is depicted that spd-y is the top ranked feature in case of LIME. On the other hand, spd_x, pos_x, and pos_y comes in second, third and fourth position respectively in the anomaly detection contribution for VeReMi dataset. Again, for this case, pos_z and spd_z did not have any impact.\nGlobal Explanations using DALEX: In Figure 2c, the top ranked feature for DALEX is pos_x. pos_y, spd_x and spd_y come subsequently to contribute to the"}, {"title": "5 Foundations of Evaluation", "content": "We next present our detailed evaluation setup. Our evaluation aims to answer the following questions:\n\u2022 What is the overall performance of different AI models when applied to the autonomous driving datasets (VeReMi and Sensor)?"}, {"title": "5.1 Dataset Description", "content": "VeReMi dataset [30]: The VeReMi dataset serves as a significant resource for anomaly detection research in autonomous driving systems. It encompasses a range of attack scenarios, including Denial of Service (DoS), Sybil attacks, and message falsification within Vehicular Ad-hoc Networks (VANETs). The dataset's strength lies in its provision of real-world data, complete with sensor readings and corresponding ground truth labels for each attack type. Comprising 225 distinct scenarios and five attacker classifications, VeReMi includes both autonomous vehicle (AV) message logs and attacker ground truth files [30]. These components enable researchers to analyze attacker characteristics in depth. The dataset's comprehensive nature has established it as a benchmark in autonomous driving security research.\nIn our analysis, we focused on extracting features that best characterize AV behavior. Through a process of feature selection, we narrowed our focus to six key variables: pos_x, pos-y, pos_z, spd_x, spd_y, and spd_z. These parameters represent the three-dimensional position and velocity components of an AV, respectively. We determined that other available features did not contribute substantial additional information to our analysis. This targeted approach to feature selection allows for a more focused examination of AV dynamics-related features while potentially reducing computational complexity in subsequent analyses.\nSensor dataset: In our research, we also utilized the Sensor dataset to evaluate our framework, following the methodology outlined in the work [32]. This dataset comprises ten features, each simulating a distinct sensor presumed to be present in autonomous vehicles (AVs). These sensors include formality, location, speed, frequency, correlation, lane alignment, headway time, protocol, plausibility, and consistency. Each sensor serves a specific function in monitoring AV behavior, described as follows.\n\u2022 The formality sensor verifies message size and header integrity.\n\u2022 Location sensor confirms message delivery to the intended recipient.\n\u2022 Speed sensor ensures data remains within prescribed speed limits.\n\u2022 Frequency sensor monitors message timing behavior."}, {"title": "5.2 Experimental Setup", "content": "Coding Tools: We used several open-source tools (based on Python) and various black-box AI models using well-known libraries like Keras [38] and Scikit-learn [37] in order to create our feature ensemble framework.\n\u03a7\u0391\u0399 Methods: Our framework incorporates three \u03a7\u0391\u0399 methods: SHAP, LIME, and DALEX, detailed below.\n(a) SHAP [39]: SHAP explains AI model predictions by evaluating feature importance. Rooted in game theory (Shapley values), it assesses the contribution of each feature to the model's classification decisions.\n(b) LIME [40]: LIME is an XAI method that provides local explanations for AI model predictions, making each prediction comprehensible on an individual basis. For each instance, LIME generates a local surrogate model that approximates the global"}, {"title": "6 Evaluation Results", "content": "Having provided the main foundations for our evaluation, we next show our detailed evaluation results to answer the aforementioned research questions."}, {"title": "6.1 Overall Performance of Black-box AI Models", "content": "We begin by examining the overall performance of various black-box AI models in classifying anomalous AVs on both VeReMi and Sensor datasets. Tables 4 and 5 summarize the key performance metrics accuracy, precision, recall, and F1 score-collected for each model on both datasets.\nTable 4 demonstrates that, among the models tested on the VeReMi dataset, the Random Forest (RF) classifier achieves the best overall performance, with an accuracy of 0.80, precision of 0.83, recall of 0.88, and an F1 score of 0.86. The Decision Tree (DT) and K-Nearest Neighbors (KNN) models also perform relatively well, with comparable F1 scores of 0.84. The Deep Neural Network (DNN) and Support Vector Machine (SVM) models exhibit lower overall performance, although the DNN achieves the highest recall at 0.96. AdaBoost, while demonstrating solid recall at 0.91, shows lower precision and F1 scores compared to the random forest (RF) classifier.\nIn contrast, Table 5 reveals that for the Sensor dataset, the AdaBoost model outperforms all other models with an impressive accuracy of 0.99, precision of 0.99, recall of 1.00, and an F1 score of 0.99. This is followed closely by the RF model,"}, {"title": "6.2 Ranking of Top Features for each XAI models", "content": "Now, we provide the ranking of the top features for VeReMi and Sensor dataset for all of the three \u03a7\u0391\u0399 methods considered in this work. These features are obtained from six AI models used in our framework both for binary and multiclass classification problems for anomaly detection."}, {"title": "6.2.1 Binary Classification of VeReMi Dataset", "content": "Top Features for SHAP: We obtained six sets of top features for six of our AI models using SHAP for binary classification. Table 6 shows the list of top features for six different AI models elicited from SHAP. Among the features, \"pos_x\" consistently ranks highest across most methods, while \"pos_z\" consistently ranks lowest. Other features like \"spd_y\" and \"spd_x\" have varying ranks, indicating their differing importance across the methods.\nTop Features for LIME: We now provide the six sets of top features for our six AI models extracted by LIME for binary classification. Table 7 depicts that feature \"spd_y\" is often considered the most significant across various methods, highlighting"}, {"title": "6.2.2 Binary Classification of Sensor Dataset", "content": "Top Features for SHAP: Through the same aforementioned process, we obtained that most AI algorithms consistently place features like \"Lane Alignment\" at the top position underscoring their high significance. The importance of other"}, {"title": "6.2.3 Multiclass Classification of VeReMi Dataset", "content": "Top Features for SHAP: Using SHAP values, Table 12 ranks the features from VeReMi data based on their influence in multiclass classification setup for anomaly detection across various models. Features such as \"pos_x\" and \"pos_y\" consistently demonstrate high significance across these models, whereas \"spd_z\" generally exhibits lower impact.\nTop Features for LIME: Table 13 presents a hierarchical arrangement of features from the VeReMi dataset, based on their significance in multiclass classification tasks. The ranking is derived from LIME analysis applied to a diverse set of machine learning models. Notably, \"pos_x\" consistently ranks as the most important feature across all models. \"pos_y\" also shows significant importance, especially for SVM and AdaBoost"}, {"title": "6.3 Fusion of Features and their performance on Independent\nClassifiers", "content": "We will first evaluate the aforementioned three setups using feature sets generate by our feature ensemble approach. The consolidated feature sets are subsequently used to train three independent classifiers: CatBoost, LGBM, and LR. We then compare the"}, {"title": "6.3.1 VeReMi Binary Class Classification", "content": "Recall, we do the leveled-feature fusion in three phases. First, we get three sets of features for each of our XAI methods (SHAP, LIME, and DALEX) for each of our six AI models. Secondly, for each AI model we fuse the three sets features (obtained from the first phase) from the three XAI methods and get one set of features for each of the six AI models. In the end, we combine the six features from six AI models into a single set of fused features depending on their frequency.\nWe now feed the set top features from fusion of features for just SHAP, LIME, and DALEX from all the six models to three of our independent classifiers and observe the comparison of performance against the independent models fed with top features from leveled-feature fusion technique. We emphasize that for VeReMi dataset we focus on top-4 features. The top-4 features we used for the experiment are shown in VeReMi binary classification in Table 15. \"pos_x,\" \"pos_y,\" and \"spd_x\" are the overall top features for VeReMi dataset (in both binary and multiclass setups) while \"Location\" and \"Lane Alignment,\" and \"Consistency\" are the overall top features for Sensor dataset.\nVeReMi binary classification in Table 16 shows that the CatBoost classifier maintains consistent performance across all methods (SHAP, LIME, DALEX, and Leveled) with an accuracy of 0.82, precision of 0.86, recall around 0.91-0.92, and F1-score of 0.89. LGBM and Logistic Regression also show minor variations across methods, but generally, the novel feature fusion method (Leveled) performs comparably to individual XAI methods, indicating that Leveled features are effective in maintaining classifier performance."}, {"title": "6.3.2 Binary Classification of Sensor Dataset", "content": "In the next phase of our analysis, we utilize the top features derived from the fusion of SHAP, LIME, and DALEX outputs across all six models. These consolidated feature sets are then fed into three independent classifiers. We compare the performance of these classifiers against the same models when trained on features selected through our leveled-feature fusion technique. It is important to note that for the Sensor dataset, our focus is specifically on the top-5 features. The specific set of top-5 features employed in this experimental setup is detailed in Sensor classification in Table 15. This approach allows us to evaluate the efficacy of our feature fusion methodology in the context of the Sensor dataset.\nSensor classification in Table 16 compares the performance of CatBoost, LGBM, and Logistic Regression classifiers on the Sensor dataset employing SHAP, LIME, DALEX, and a novel feature ensemble method (Leveled) for binary classification. Across all classifiers, the Leveled technique consistently produces competitive results, frequently matching or slightly beating specific XAI methods. Notably, the CatBoost classifier performs well with Leveled features, with an accuracy of 0.82, precision of 0.86, recall of 0.92, and F1-score of 0.89, demonstrating the Leveled method's efficiency in improving classification performance."}, {"title": "6.3.3 Multiclass Classification of VeReMi Dataset:", "content": "Next, we take into account the multiclass classification for VeReMi dataset and we compare the results of our independent classifiers on different sets of top-4 features following the aforementioned procedures. The top-4 features for VeReMi dataset for multiclass which are fed to the independent classifiers are shown in VeReMi multiclass classification in Table 15.\nVeReMi multiclass classification in Table 16 presents a comparison of the performance of CatBoost, LGBM, and Logistic Regression classifiers for VeReMi multiclass classification. The evaluation is done using SHAP, LIME, DALEX, and a novel feature ensemble method called Leveled. All classifiers consistently attain similar levels of accuracy and precision, with values around 0.67 for accuracy and precision, and 0.80 for F1-score. The recall rate is continuously high at 1.00 for most approaches, except for LGBM with Leveled features, which has a slightly lower recall rate of 0.93. The Leveled technique often achieves comparable performance to the various \u03a7\u0391\u0399 methods, with a modest enhancement in F1-score observed for LGBM."}, {"title": "7 Limitations and Discussion", "content": null}, {"title": "7.1 Limitations", "content": "While our proposed XAI-based feature ensemble framework demonstrates promising results for enhancing anomaly detection in autonomous driving systems, it is important to acknowledge several limitations in our current study and discuss their implications along with future enhancements.\nDataset Limitations: Our study primarily relied on two datasets - VeReMi and Sensor. While these datasets are widely used in the field, they may not fully represent the complexity and diversity of different real-world autonomous driving scenarios. The"}, {"title": "7.2 Discussion", "content": "Despite the identified limitations, our XAI-based feature ensemble framework offers notable advantages and paves the way for new research avenues. The consistent performance improvements across various classifiers indicate that our approach effectively captures essential features for anomaly detection for autonomous driving systems.\nBy integrating insights from multiple \u03a7\u0391\u0399 methods, we achieve a better understanding of feature importance (via the features identified by frequency analysis of the features identified from the different XAI methods), potentially reducing biases inherent in individual techniques[44]. The framework's ability to maintain or slightly enhance performance while improving interpretability is particularly significant in the context of autonomous driving, where both accuracy and explainability are crucial.\nOur results emphasize the value of combining multiple AI models and XAI methods, reflecting the complexity of anomaly detection and the need for multi-faceted approaches. Future research could explore unsupervised anomaly detection methods, incorporate domain knowledge into the feature ensemble (or fusion) process, and develop advanced feature ensemble techniques to capture non-linear feature interactions. Additionally, assessing the framework's performance on multi-modal data (e.g., combining sensor data with visual inputs) could enhance the evaluation of anomaly detection in autonomous driving systems."}, {"title": "8 Conclusion", "content": "This paper introduced a novel XAI-based feature ensemble framework that enhances anomaly detection in autonomous driving systems by integrating features from multiple XAI methods (SHAP, LIME, and DALEX) with various AI models to develop a feature fusion technique. Evaluated on the VeReMi and Sensor datasets, our approach consistently matches or outperforms individual XAI methods across different independent classifiers (CatBoost, LGBM, and Logistic Regression). Key findings include robust anomaly indicators from fused features, high performance in both binary and multiclass classification, and improved interpretability essential for stakeholder trust and regulatory compliance. While limitations such as dataset constraints and computational overhead exist, our work lays the foundation for future research in using XAI-based feature ensemble for enhancing understanding of anomaly detection process for autonomous driving. The main related future avenues for research include real-world validation, temporal analysis, and adversarial robustness. This research advances the development of more reliable, and secure autonomous driving systems, bridging the gap between high-performance anomaly detection and feature analysis using explainable AI."}, {"title": "Appendix A\nHyperparameters of AI Models", "content": "(1) Decision Tree (DT): Decision tree classifier was our first AI model that we experimented on the datasets. The best hyperparameter choice for this model was when the criterion was set to \"gini\" for measuring impurity and the max depth of the tree was 50 which means the number of nodes from root node to the last leaf node was 50. The minimum number of samples required to be present in a leaf node was 4 (min_samples_leaf = 4) and the minimum number of samples required to split a"}]}