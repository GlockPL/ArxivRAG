{"title": "LEGAL-UQA: A Low-Resource Urdu-English Dataset for Legal Question Answering", "authors": ["Faizan Faisal", "Umair Yousaf"], "abstract": "We present LEGAL-UQA, the first Urdu legal question-answering dataset derived from Pakistan's constitution. This parallel English-Urdu dataset includes 619 question-answer pairs, each with corresponding legal article contexts, addressing the need for domain-specific NLP resources in low-resource languages. We describe the dataset creation process, including OCR extraction, manual refinement, and GPT-4-assisted translation and generation of QA pairs. Our experiments evaluate the latest generalist language and embedding models on LEGAL-UQA, with Claude-3.5-Sonnet achieving 99.19% human-evaluated accuracy. We fine-tune mt5-large-UQA-1.0, highlighting the challenges of adapting multilingual models to specialized domains. Additionally, we assess retrieval performance, finding OpenAI's text-embedding-3-large outperforms Mistral's mistral-embed. LEGAL-UQA bridges the gap between global NLP advancements and localized applications, particularly in constitutional law, and lays the foundation for improved legal information access in Pakistan.", "sections": [{"title": "Introduction", "content": "While Natural Language Processing (NLP) has seen major advancements in recent years, the benefits of these advancements remain disproportionately skewed towards a small subset of global languages, specifically English (Krasadakis et al., 2024). This linguistic imbalance results in significant accessibility gaps, particularly in critical domains like law.\nUrdu is Pakistan's national language and currently the tenth most spoken language in the world when combining first and second language speakers (Central Intelligence Agency, 2023). It is the first language of over 2.2 million people in Pakistan (Pakistan Bureau of Statistics, 2023). While English serves as Pakistan's official language alongside Urdu, most government, legal, and administrative documentation is conducted in English. However, only a small fraction of judges, lawyers, litigants, and defendants are proficient in English for court proceedings. This limited English proficiency often hinders justice, particularly for marginalized groups, especially women (Ahmad et al., 2020).\nRecognizing this, the Pakistani constitution states:\n\"English language may be used for official purposes until arrangements are made for its replacement by Urdu.\" (Pakistan National Assembly, 2023)\nPakistan's technology landscape is currently lagging, particularly in the legal domain. Studies such as (Khan et al., 2024) highlight how legal chatbots can provide instant, round-the-clock guidance on basic legal queries, procedures, and rights, helping users navigate legal processes and understand legal jargon.\nWe propose the first Urdu-based legal Question-Answering (QA) dataset, derived from the constitutional law of Pakistan. We aim to develop a resource that is both foundational and broadly applicable, covering essential legal rights and obligations that are of public interest. The dataset is a closed-domain Generative QA dataset, where the abstractive answer to a question is generated by a generative model, in contrast to an Extractive QA dataset, where the answer is directly extracted from the provided context (Wang, 2022). We open-source all our code\u00b9, dataset\u00b2, and fine-tuned model\u00b3.\nOur contributions are threefold:"}, {"title": "1. Dataset Creation:", "content": "We introduce a parallel QA dataset containing questions, answers, and their corresponding relevant context (each law article present in the constitution). It is designed to support machine learning models in understanding legal queries in Urdu. Article-wise chunking in the dataset also opens doors for Retrieval-Augmented Generation (RAG)-based legal chatbots (Lewis et al., 2020)."}, {"title": "2. Domain-Specific Focus and Linguistic Relevance:", "content": "As discussed later in Section 2, while large Urdu QA datasets exist, domain-specific datasets are scarce. We contribute to the growing body of work in multilingual NLP, offering a resource that bridges the gap between global NLP research and localized, culturally relevant applications."}, {"title": "3. Experimentation with LLMS:", "content": "Our study evaluates the dataset using a variety of the latest Large Language Models (LLMs). Additionally, we fine-tune mt5-large-UQA-1.0 (Arif et al., 2024) to compare its results with those of generalist models."}, {"title": "2 Related Work", "content": "While there exist several Urdu question-and-answer (QA) datasets, to the best of our knowledge, none are adapted for the legal domain, resulting in a significant gap in this sector. Finding diverse datasets for low-resource languages is challenging, and a common technique involves translating existing datasets into the required language."}, {"title": "2.1 Urdu QA Datasets", "content": "UQA (Arif et al., 2024), introduced in May 2024, is built on SQuAD2.0 (Rajpurkar et al., 2018) and contains ~88k answerable questions and ~47k non-answerable questions. The authors used seamless M4T (Barrault et al., 2023) to translate the question-answer pairs.\nUQUAD (Urdu Question-Answer Dataset)\u2074 includes 27 paragraphs and 499 question-answer pairs, and is available on GitHub.\nUQuAD1.0 (Kazi and Khoja, 2021) contains ~46.5k questions across ~18.8k paragraphs, derived from a range of Wikipedia articles. These articles are distributed across various categories such as politics, religion, education, music, and miscellaneous. This dataset was created through"}, {"title": "2.2 Legal QA Datasets", "content": "In the legal QA domain, several datasets exist. The JEC-QA Legal QA dataset (Zhong et al., 2019), created from China's National Judicial Examination, contains 26,365 multiple-choice and multiple-answer questions. Its objective is to predict answers based on questions and relevant legal articles, and it is in Chinese.\nLeDQA (Liu et al., 2024), another Chinese dataset, includes legal case documents with corresponding QA pairs that can be answered using the document as context. It comprises 100 case documents, 4,800 case-question-answer triplets, and 132,048 sentence-level relevance annotations. Models such as Qwen-7b-chat (Bai et al., 2023), GPT-3.5-turbo\u2077, and ChatLaw (Cui et al., 2023) have been tested on this dataset.\nEQUALS (Chen et al., 2023) contains 6,914 (question, article, answer) triplets, along with a pool of law articles covering 10 Chinese law collections. The questions and answers are sourced from a legal consultation forum, with law article spans annotated by senior law students, ensuring high quality."}, {"title": "3 Dataset Description", "content": ""}, {"title": "3.1 Document Parsing for Contexts", "content": "We used the official document of the Constitution, which is available in English on the official gov-"}, {"title": "3.2 English QA Pairs", "content": "To determine the number of questions to generate from each article, we classified the English articles into three categories\u2014small, medium, and large-based on word count. The bottom 25% were classified as small, and the top 25% as large. To create a dataset consisting of question-answer"}, {"title": "3.3 Urdu QA Pairs", "content": "To generate Urdu versions of the English QA pairs, we used OpenAI's GPT-40 model, providing it with an English context (a single English article), a corresponding English QA pair and Urdu context. The Urdu context was provided to ground the model in the Urdu language style used in the official Urdu Constitution document. The model was prompted to translate the English QA pair while maintaining the style and tone of the Urdu context."}, {"title": "3.4 Post-Processing", "content": "We combined the features of the dataset, which consists of 619 QA pairs and their corresponding contexts. The features are as follows:\n\u2022 question_eng: The question in English.\n\u2022 question_urdu: The question in Urdu.\n\u2022 context_eng: The context in English.\n\u2022 context_urdu: The context in Urdu.\n\u2022 answer_eng: The answer in English.\n\u2022 answer_urdu: The answer in Urdu.\n\u2022 context_index: A unique identifier for each context/article.\nThis is a Generative QA dataset, as opposed to an Extractive QA dataset, where answer spans are included, and answers are exact phrases from the provided context (Wang, 2022)."}, {"title": "4 Experiments & Evaluation", "content": "We conducted experiments on several generative LLMs. We created a validation set consisting of 124 QA pairs and a training set with 495 data points. We fine-tuned the mt5-large-UQA-1.0 model on our dataset. This model is a fine-tuned version of mt5-large (Xue et al., 2021), trained on the UQA corpus. We used a single NVIDIA A100 GPU on Google Colab\u00b9\u00b9. We used a learning rate of 5e-5 and fine-tuned the model for 10 epochs, achieving the lowest validation accuracy in epoch 2, whose weights were used in all subsequent experiments.\nFurthermore, we conducted experiments with the latest models from Google (Google, 2024a), Anthropic (Anthropic, 2024), and Mistral (Mistral, 2024). We did not evaluate OpenAI models to avoid any potential bias, as they are used to augment the dataset.\nTo evaluate the QA results, we used F1 (Rajpurkar et al., 2016), METEOR (Banerjee and Lavie, 2005), and SacreBLEU (Post, 2018). Additionally, the accuracy of the answers was manually assessed. The answers were marked as correct (1) or incorrect (0) based on whether the question was accurately answered.\nClaude-3.5-Sonnet (Anthropic, 2024) outperformed the other models with a human accuracy of 99.19% (Table 2). Gemini (Google, 2024a) models exhibited lower performance on the metrics despite achieving high human accuracy. While Gemini's outputs were correct, they were extremely concise"}, {"title": "5 Conclusion and Future Work", "content": "Our study introduces LEGAL-UQA, the first legal QA dataset in Urdu, derived from Pakistan's constitution.\nExperiments, particularly with the mT5 model, reveal challenges for low-resource languages in specialized domains. We plan to expand the dataset to include criminal, civil, and administrative law, enhancing its applicability. Additionally, we aim to explore more open-source models. The dataset's parallel nature could also improve legal translations.\nThese initiatives seek to enhance access to legal information for Urdu speakers in Pakistan and advance multilingual NLP for low-resource languages in the legal domain."}, {"title": "6 Limitations", "content": "The LEGAL-UQA dataset, while the first of its kind, consists of a relatively small set of 619 QA pairs in the context of LLMs. Although the dataset covers Pakistan's constitutional law, it does not encompass the broader legal landscape of criminal or civil law, limiting its applicability. Additionally, the use of GPT-4 to generate the QA pairs may introduce subtle errors in style or tone.\nAnother limitation is the reliance on pre-trained models and embeddings that are not optimized for legal text, particularly in low-resource languages like Urdu. Although we fine-tuned the mT5 model, its overall performance lagged behind other state-of-the-art models. Additionally, the evaluators, while fluent in Urdu, had limited legal expertise."}, {"title": "7 Ethical Considerations", "content": "Building legal datasets can pose risks of misinterpretation by machine learning models. This dataset is intended to assist and promote research in the area and does not aim to replace legal counsel."}, {"title": "A QA Pair Generation", "content": "The following prompts were used to generate English QA pairs:\nSystem Prompt\nYou are an expert in interpreting Pakistani legal documents. Given an article text from a legal document, you generate a set of questions and their corresponding answers.\nTask Prompt\nYour task is to generate up to {number_of_questions} unique question(s) and answer (s) based on the following article text:\nArticle Text: \"\"{article_text}\"\"\nInstructions:\nIf it is not possible to generate {number_of_questions} question(s), provide as many questions and answers as you can based on the content.\nIf no question can be generated, respond with 'NONE'.\nEnsure that each question is unique and related to the text provided.\nThe answer should be based on the information provided in the article text only.\nDo not mention article numbers in the questions.\nDo not mention the article text in the questions.\nYou are to ask questions as a layman would ask naturally, not as a legal expert. They should be from the perspective of a person who is trying to find out what the constitution says about a particular topic.\nThe questions should not be too specific or too general.\nAvoid using the same words or phrases from the article text in the questions.\nThe answers can use the same words or phrases from the article text.\nExample Output Format:\nQuestion: What is the official name of the country Pakistan?\nAnswer: The official name of the country is the Islamic Republic of Pakistan.\nQuestion: Which regions are part of Pakistan?\nAnswer: The regions mentioned as parts of Pakistan are Balochistan, Khyber Pakhtunkhwa, Punjab, Sindh, and the Islamabad Capital Territory.\nWhere:\n{number_of_questions} is the number of QA pairs to be generated"}, {"title": "B Refining Urdu OCR Detections", "content": "The following prompts were used on the results of the end-to-end Urdu OCR pipeline to refine the detections.\nSystem Prompt\nYou are an expert in both English and Urdu languages.\nTask Prompt\nYou are given an English text and its Urdu translation, which contains formatting and grammatical errors.\nYour task is to:\nCorrect any grammatical or formatting mistakes in the Urdu text.\nProperly format bullet points or lists.\nRe-order sentences if they appear jumbled.\nOutput Instructions:\nOnly provide the corrected Urdu text without any explanations or comments.\nEnglish Text:\n\"\"{article_text_eng}\"\"\nUrdu Text:\n{article_text_urdu}\nWhere:\n{article_text_eng} is the original English context\n{article_text_urdu} is the unrefined Urdu context"}, {"title": "C Translation", "content": "The following prompt instruction was used in our study for translation of English QA pairs to Urdu:\nTranslation Prompt\nYou are provided with the **context in English** as well as the **Q&A pair in English**. You will also be given the **context in Urdu**.\nYour task is to translate the English Q&A pair into Urdu, ensuring that the translation aligns with the style and tone of the Urdu context provided.\n**Context in English:** {context_en}\n**Question (in English):** {question}\n**Answer (in English):** {answer}\n**Context in Urdu:** {context_ur}\n{format_instructions}\nWhere:\n{context_en} represents the context provided in English.\n{question} is the question in English.\n{answer} is the answer in English.\n{context_ur} represents the context provided in Urdu.\n{format_instructions} are additional py-dantic formatting instructions given to the model to parse the output."}]}