{"title": "Facilitate Collaboration between Large Language Model and Task-specific Model for Time Series Anomaly Detection", "authors": ["Feiyi Chen", "Leilei Zhang", "Guansong Pang", "Roger Zimmermann", "Shuiguang Deng"], "abstract": "In anomaly detection, methods based on large language models (LLMs) can incorporate expert knowledge, while task-specific smaller models excel at extracting normal patterns and detecting value fluctuations. Inspired by the human nervous system-where the brain stores expert knowledge and the peripheral nervous system and spinal cord handle specific tasks like withdrawal and knee-jerk reflexes-we propose CoLLaTe, a framework designed to facilitate collaboration between LLMs and task-specific models, leveraging the strengths of both. In this work, we first formulate the collaboration process and identify two key challenges in the collaboration between LLMs and task-specific models: (1) the misalignment between the expression domains of LLMs and smaller models, and (2) error accumulation arising from the predictions of both models. To address these challenges, we introduce two key components in CoLLaTe: the alignment module and the collaborative loss function. Through theoretical analysis and experimental validation, we demonstrate that these components effectively mitigate the identified challenges and achieve better performance than LLM based methods and task-specific smaller model.", "sections": [{"title": "1. Introduction", "content": "Recently, methods based on Large Language Models (LLMs) have demonstrated strong generalization capabilities, effectively leveraging human expertise to complete a wide range of tasks. However, they are often insensitive to the value fluctuations in time series data, and their NLP-based representations do not align well with the characteristics of time series data (Jin et al., 2024). In contrast, task-specific methods, such as anomaly detection models, typically lack the broad generalization capabilities of LLMs across multiple tasks. However, these models are specifically designed for particular tasks and often exhibit superior performance when applied to well-matched anomaly detection datasets (Zhou et al., 2023). Despite their strengths, task-specific models also have notable limitations. First, for different application scenarios, researchers need to adapt anomaly detection models to incorporate domain-specific expertise to achieve optimal performance. For instance, anomaly detection methods tailored for cloud service monitoring (Ma et al., 2021; Chen et al., 2024b) or aircraft monitoring (e Silva & Murcca, 2023) have been modified to suit these specific contexts. Second, in many practical scenarios, such as aircraft monitoring (Nanduri & Sherry, 2016), it is not feasible to collect data for all possible flight conditions. These conditions often represent distinct distributions and normal patterns in the monitoring data. This lack of comprehensive data coverage significantly hinders the performance of task-specific anomaly detection models.\nInspired by the human nervous system which relies on the brain to store expert knowledge and extract general principles, while using the peripheral nervous system and spinal cord for specific tasks like the withdrawal reflex and knee-jerk reflex-we propose a framework called CoLLaTe. This framework facilitates the Collaboration between a Large Language model (LLM, analogous to the brain) and a Task-specific model (analogous to the peripheral nervous system and spinal cord). CoLLaTe leverages the complementary strengths of both LLMs and task-specific anomaly detection methods. By enabling collaboration between an LLM and a task-specific anomaly detection model, we can integrate domain expertise from various application scenarios into the task-specific model without making any adaptation to the model. This approach also mitigates performance degradation caused by insufficient monitoring data across diverse operational conditions, because LLMs excel at utilizing professional documents to incorporate domain knowledge, which is often expressed in natural language."}, {"title": "2. Preliminary", "content": "Given a task-specific small model and a LLM, they gives an anomaly score and a representation to each time slot of a time series X, as shown in Eq. 1-Eq. 2, where s and S are anomaly scores given by different models respectively and R is the representation of time slots. \\(X_i\\) is the ith time slot of X. \\(s_i\\) and \\(S_i\\) are anomaly score of ith time slot respectively. \\(y_i\\) is 1 when \\(X_i\\) is anomalous. Otherwise, it is 0. CoLLaTe uses the representation R as condition to synthesize the anomaly score of small model and the one of LLM, as shown in Eq. 3. CoLLaTe makes collated anomaly score \\(\\hat{S}\\) approach y unsupervisedly and overpasses the performance of task-specific small model and LLM.\n\\(s, R = SmallModel(X)\\) (1)\n\\(S = LLM(X)\\) (2)\n\\(\\hat{S} = CoLLaTe(s, S; R)\\) (3)"}, {"title": "3. Method", "content": ""}, {"title": "3.1. Overview", "content": "The architecture of CoLLaTe is shown in Fig. 2. The anomaly scores s and S are obtained from a task-specific small model and a LLM respectively, where the LLM uses a set-up pitch prompt illustrated in subsection. 3.2. Anomaly scores s and S ususally have different understandings of anomaly scores, i.e. LLM and task-specific model can use same score to denote different anomalous degrees. Thus, we propose an Alignment module to align the different understandings of LLM and task-specific model for same anomaly scores. After that, we use a conditional network to synthesize aligned scores of task-specific model and LLM with the representation as condition. In this way, we obtain the collated anomaly score \\(\\hat{S}\\). Furthermore, we propose a collaborative loss function, which can effectively leverage the compensative effect between LLM and task-specific small model and LLM. Besides, it is proven it can avoid error accumulation during the collaborative pross of task-specific small model and LLM."}, {"title": "3.2. Set-up-pitch Prompt", "content": "There are many works prove that invoking similar historical examples in prompt can significantly improve the anomaly detection performance (Liu et al., 2024b). Thus, our prompt consisted of four parts: the expertise supplementation, task description, input data, examples. The expertise supplementation section encompasses the specific meanings of different dimensions of input data within the application domain, as well as the relevant professional expertise, such as value ranges and the relationships between different dimensions. The task description section instruct the large language model to judge whether the given time slot is anomalous and stipulate the output formation. The example section contains a positive and a negative example. We list the concrete prompt in appendix A.5. Recent works invoke examples from a fixed dataset. However, the normal pattern always varies as time pass by in many application scenarios. For example, in cloud server monitoring, the cloud environment always changes from time to time as the services update, deployment and revocation (Chen et al., 2024a; Ma et al., 2021). In aircraft monitoring, the normal patterns change as the condition of flight and aircraft changes. As shown in Fig. 3(a), we made an experiment on our aircraft monitoring data, which prove that the longer time distance between the given time slot for anomaly detection and time slot of example, the worse the performance of GPT4 is. Therefore, with the assistance of a small task-specific model for anomaly detection, we regularly update the collection of examples."}, {"title": "3.3. Alignment Module", "content": "Task-specific small model and LLM usually have different understanding of anomaly score, i.e. they use same anomaly score to denote different serious degree of anomalies. There are two factors contribute to this problem: the value range and distribution misalignment. Most of reconstruction-based small models use reconstruction error as the anomaly score, which makes the range of anomaly score various. However, the anomaly score of LLM is constrained to [0, 1]. The huge gap between the anomaly score ranges of LLM and task-specific small model will cause different understanding of anomaly scores and degrade the collaboration performance. To solve this problem we firstly scale anomaly score of small model by Eq. 4, where d is a hyperparameter, \\(s_{max}\\) and \\(s_{min}\\) are the maximum and minimum values of small model anomaly scores.\n\\(\\.\\tilde{s}=\\frac{s-s_{min}}{s_{max}-s_{min}}\\) (4)\nEven if scaled anomaly scores of small model, different anomaly score distribution will cause different understanding of anomaly scores. As shown in Fig. 3(b), we use a half-gaussian distribution, which will be elaborated in the following, to fit the histogram of LLM anomaly scores. Then, we shift the fitted curve to the histogram of task-specific small model anomaly score in Fig. 1(b), where we can find that most anomaly scores are under 0.3 for LLM, while the anomaly scores of small model centered at [0.3, 0.4]. Thus, the anomaly score of 0.4 may mean moderate anomaly risks for LLM, while it may only mean normal for"}, {"title": "3.4. Collaborative Loss", "content": "Many anomaly detection works divides anomalies into contextual anomaly and point anomaly (Schmidl et al., 2022; Tuli et al., 2022). We made experiments on 4 plane monitoring datasets, which are described in Appendix. A.7. The results in Tab. 1 demonstrated the compensative performance of task-specific small model and LLM on contextual anomaly and point anomaly, where F1 score of contextual anomaly for small model is better than the one of GPT4, while F1 score of point anomaly for GPT4 is better than the one of small model. Thus, we introduce a conditional network, which uses the representation R of input data obtained by small model as the condition, the aligned anomaly score of small model and LLM as input and output a collated anomaly score, as show in Eq. 8, where P is the trainable parameter of the conditional network.\n\\(\\hat{S} = ConditionalNet(M(s), S, R; P)\\) (8)\nTo leverage the compensative performance of small model and GPT4, we design a loss function to adaptively adjust the collated anomaly score. We firstly divide the time series into patches (Nie et al., 2023). For each time slot we compute the average distance between present time slot with other time slots in same patch and denote it by \\(D_{intra}\\). Then, we compute the average distance between the patch of present time slot and other patches and denote it by \\(D_{inter}\\). The bigger difference between \\(D_{intra}\\) and \\(D_{inter}\\) is, the more likely that the present time slot is a point anomaly and LLM can judge it more accurate and vice versa. Thus, we design the loss function as in Eq.9, where L(a, b) represent a loss function measuring the distance between a and b.\n\\(L_{b} = \\frac{D_{intra}}{D_{intra}+D_{inter}} L(s, \\hat{S}) + \\frac{D_{inter}}{D_{intra}+D_{inter}} L(S, \\hat{S})\\) (9)\nIf we choose some popular loss function formation, such as L(a, b) = \\((a - b)^2\\), it will accumulate the prediction error of small model and LLM in the process of gradient descent, as show in Theorem 2, which is proven in Appendix. A.2.\nAssumption 1. The anomaly score prediction error of task specific small model is \\(\\epsilon_s\\), where \\(\\epsilon_s\\) obeys an unknown distribution \\(D_{\\zeta}(\\mu_{\\zeta}, \\sigma_{\\zeta})\\), \\(\\mu_{\\zeta} \\neq 0\\).\nAssumption 2. The anomaly score prediction error of LLM is \\(\\epsilon_s\\), where \\(\\epsilon_s\\) is the LLM prediction error, which obeys an unknown distribution \\(D_S(\\mu_{\\varsigma},\\sigma_{\\varsigma})\\), \\(\\mu_{\\varsigma} \\neq 0\\).\nAssumption 3. L' is L-Lipschitz continuous.\nTheorem 2. Given Assumption 1 - Assumption 2, when L(a,b) = \\((a - b)^2\\), the difference between optimal solution \\(S^*\\) of \\(L_b\\) and ground truth y is \\(E[(\\hat{S}^* - y)^2] \\geq (\\lambda_1 \\mu_{\\varsigma} + \\lambda_2 \\mu_{\\varsigma})^2\\), where \\(\\lambda_1 = \\frac{D_{intra}}{D_{intra} + D_{inter}}\\) and \\(\\lambda_2 = \\frac{D_{inter}}{D_{intra} + D_{inter}}\\) \nFrom Theorem 2, we can find that when using MSE as L, the expectation prediction error of conditional network is greater than the weighted sum of the expectation of small model prediction error and the one of LLM, which denotes the error accumulation between small model and LLM. This phenomenon is also observed in experiment and discussed in subsection. 4.4.\nTo solve this problem we propose collaborative loss function as show in Eq. 10, where \\(\\hat{S}_i\\), \\(s_i\\) and \\(S_i\\) are anomaly scores of ith sample output by conditional network, small model and LLM respectively. In Lemma 1, we prove that using the collaborative loss function is approximate to using loss function in Eq. 11, which proves that Eq. 10 avoid error of small model and LLM to accumulate, since Eq. 11 directly let the difference between collated anomaly scores of two samples approach the ground truth. We also experimentally prove Eq. 10 can avoid error accumulation and discuss it in subsection. 4.4. Furthermore, in Theorem 3, we prove the optimal solution of Eq. 10 has two properties. The property 1 denotes that if the anomaly degree of time slot r is more serious than the on of time slot k, the optimal"}, {"title": "3.5. Train and Inference", "content": "During the training process, we use \\(L_a + L_b\\) as the loss function. During the inference process, we use the collated anomaly score output by conditional network as the anomaly score and use POT algorithm to determine the threshold (Siffer et al., 2017). When anomaly score is higher than the threshold, the time slot is judged as anomaly."}, {"title": "4. Experiment", "content": "We have made extensive experiments to on four datasets and make following contributions:\n*   CoLLaTe can achieve the best performance compared with SOTA LLM-based anomaly detection methods and small-model-based anomaly detection methods.\n*   We locate the hyperparameters that are important to CoLLaTe performance and analyze their effect."}, {"title": "4.1. Experiment Setup", "content": "Baselines. We compare CoLLaTe with SOTA anomaly detection methods: DCdetector (Yang et al., 2023), AnomalyTransformer (Xu et al., 2022), TranAD (Tuli et al., 2022), OmniAnomaly (Su et al., 2019), MSCRED (Zhang et al., 2019). Besides, we also introduce SOTA LLM-based anomaly detection methods: GPT4, LLMAD (Liu et al., 2024b), sigLLM (Alnegheimish et al., 2024). Besides, we use CoLLaTet, CoLLaTe\u2021, CoLLaTe* to denote CoLLaTe removing alignment module, changing collaborative loss to MSE, changing \\(\\frac{D_{inter}}{D_{inter}+D_{intra}}\\) and \\(\\frac{D_{inter}}{D_{inter}+D_{intra}}\\) to 1. We use CoLLaTe* to denote CoLLaTe removing LLM and conditional network."}, {"title": "4.2. Prediction Accuracy", "content": "The four datasets used in our experiment all contain many subsets. We take 40% of each subset as the training set, 10% as the validate set, and the remaining 50% as the testing set. We compute precision, recall and F1 score for each subset, compute the average results and show them in Tab. 2, where we use \"prec\" and \"rec\" to denote precision and recall, and use \"OmniAnom\" and \"AnomalyTr\" for \"OmniAnomaly\" and \"Anomaly Transformer\u201d. Since sigLLM is designed for univariate time series and can not apply to datasets Mustang Flight 1 and Flight 2, we do not list its performance on these datasets. As shown in Tab. 2, CoLLaTe can achieve best F1 score across four datasets. In Tab. 2, GPT4 is the LLM method used set-up-pitch prompt, which is exactly the LLM part of CoLLaTe. By comparing the performance of GPT4 and some other LLM-based anomaly detection methods, such as sigLLM and LLMAD, we can find that set-up-pitch prompt can greatly improve the anomaly detection accuracy of LLM. In Fig. 4(a), we use the precision and recall of best F1 score as the coordinates and draw the performance distribution of CoLLaTe, GPT4 and CoLLaTe*, from which we can find that LLM and task-specific small model (CoLLaTe*) either has poor precision or poor recall and CoLLaTe can achieve good performance on both metrics. This observation verifies that CoLLaTe can let task-specific small model and LLM collaborate with each other effectively and achieve better performance."}, {"title": "4.3. Hyperparameter Sensitivity", "content": "We explore the impact of d in Eq. 4, patch size for \\(D_{inter}\\) and \\(D_{intra}\\), learning rate, \\(\\lambda_1\\) and \\(\\lambda_2\\) in Eq. 7 on the performance of CoLLaTe. When \\(\\lambda_1\\) and \\(\\lambda_2\\) change from [0.01, 0.9], the change of F1 score of CoLLaTe is within 0.01. Thus, we mainly analyze the impact of d, patch size and learning rate. In Fig. 4(b), we test the F1 score of CoL-"}, {"title": "4.4. Effectiveness of Each Module", "content": "Ablation experiment. In CoLLaTe\u2020, we remove align module. In CoLLaTe\u2021, we change L(a, b) to MSE. In CoLLaTe*, we change \\(\\frac{D_{inter}}{D_{intra}}\\) and \\(\\frac{D_{inter}}{D_{inter}+D_{intra}}\\) to 1. We compare their performance with CoLLaTe in Tab. 2, where CoLLaTe outperform all of them. This proves that each module in CoLLaTe contributes to its performance.\nEffectiveness of Collaborative Loss. CoLLaTe* is the small model used in CoLLaTe. By comparing the performance of CoLLaTe, GPT4 and CoLLaTe*, by collaborating small model CoLLaTe* and LLM-based model GPT4, CoLLaTe can work better than both of them, which verifies CoLLaTe effectively avoid error accumulation in the process of collaborating GPT4 and CoLLaTe*.\nEffective of the design of L(a, b). Moreover, as mentioned above, CoLLaTe\u2021 is the method that changes L(a, b) in collaborative loss function to MSE. On dataset MGAB, the performance of CoLLaTe is even worse than both"}, {"title": "4.5. Compensative Effect", "content": "In CoLLaTe, we mainly utilize the the performance difference of LLM and task-specific small model on point anomaly and contextual anomaly. Actually, there are other compensative effect between small model and LLM by using other binary classification standard, and we explore them in this subsection. We introduce two kinds of binary classification standard: the anomalies needed expertise knowledge to detect and the anomalies can be detected only by data pattern, the gradual anomalies and mutual anomalies. These anomalies are illustrated in detail in Appendix. A.6. We divide Flight 2 in pieces and gather the pieces only obtain only one kind of anomalies. We test GPT4 and CoLLaTe* on them and compute their average F1 score, which is shown in Fig. 5(b). In Fig. 5(b), we can see that LLM always has better performance on one kind of anomalies and has poorer performance on another in each binary anomaly classification."}, {"title": "5. Related work", "content": "Anomaly detection methods roughly fall into two streams: the classical anomaly detection methods and neural network based methods. The classical anomaly detection methods mainly utilize statistical model (Eskin, 2000; Wang et al., 2016), linear model (Ma & Perkins, 2003; Amer et al., 2013; Hu et al., 2003), and proximity analysis (Li et al., 2021; Izakian & Pedrycz, 2014) to figure out anomalies. The statistical models formulate the distribution of time series and judge anomalies based on the probability of each time series according to the fitted distribution. These methods rely on specific assumptions that limit their robustness in detecting anomalies in highly dynamic application scenarios (Ma et al., 2021). The linear-model-based methods transform the original time series to other space and figure out the boundaries between anomalies and normalities. The proximity-analysis-based methods using clustering models to classify anomalies and normalities. These methods do not consider the temporal dependency in time series and could not figure out contextual anomalies that violates temporal dependency (Wang et al., 2024). The neural-network-based methods can be divided into prediction-based methods (Malhotra et al., 2015; Hundman et al., 2018; Zong et al., 2018; Chen et al., 2022a), reconstruction-based methods (Chen et al., 2022b; You et al., 2022; Jiang et al., 2022; Shen et al., 2021; Tian et al., 2019) and LLM-based methods (Liu et al., 2024b; Russell-Gilbert et al., 2024; Liu et al., 2024a). The prediction-based methods detect anomalies by comparing the difference between prediction value and the ground truth. However, these methods are vulnerable to the historical inference (Wang et al., 2024). The reconstruction based methods can conquer this deficiency and show strong advantages over other methods, but they can not utilize expert knowledge in application scenario without model adaptation. Besides, they distinguish anomalies by learning the normal patterns from training data and pick data samples different from learned patterns as anomalies. However, in the application scenarios, where we can not observe and collect all the normal patterns of the anomaly detection objective, such as airplane monitoring, reconstruction-based methods can not work. In contrast, LLM based methods can effectively introduce the expertise knowledge by retrieval-augmented generation (RAG) (Lewis et al., 2020) and chain of thought (COT) (Wei et al., 2022), which do not require model modification. However, as a natural-language-based model, LLM is insensitive to value fluctuation and normal"}, {"title": "6. Conclusion", "content": "Considering the compensative effect between LLM and task-specific small model, where LLM are more generalizable and can effectively embed expertise knowledge without model modification, and task-specific small model is more sensitive to value fluctuation and normal pattern extraction, we firstly formulate the collaboration process between LLM and task-specific, inspired by human nervous system. We firstly identify the collaboration challenges and propose a collaborative framework, called CoLLaTe to solve them. We have made solid mathematical proof and extensive experiments to verify the effectiveness of proposed methods."}, {"title": "A. Appendix", "content": ""}, {"title": "A.1. Proof of Theorem 1", "content": "\\(min.\\frac{c_i}{N}log[\\frac{\\int_{(i-1)b/N}^{i_b/N} f(S)dS}{\\sum_{j=1}^{N} c_j}]\ns.t.\\frac{1}{n} \\sum_{k=1}^{n}M(s_k) = \\mu\\\n\\frac{1}{n}\\sum_{k=1}^{n}[M(s_k) - \\mu_\\mu]^2 = \\hat{o}^2\\)(12)\nIn this part, we prove formation in Eq. 12 can be transformed to Eq. 14, when let N approach infinite. When N approach infinite, the optimization objective in Eq. 12 can be transformed to \\(min \\lim_{N \\rightarrow \\infty} - \\frac{c_i}{ \\sum_{j=1}^{N} c_j} = log(\\frac{c_i}{N})\\). For each ci, there will be two situations. One is that there is no M(sj) = 1, j \\( \\in \\) [1, n], then \\(c_i\\) = 0 and the item including \\(c_i\\) can be omitted. Another one is that there are some M(sj) = 1, j \\( \\in \\) [1, n], then \\(c_i\\) is equal to the number of times that \\(\\tilde{s}\\) appears in {M(sj)|sj\\( \\in \\) {\\(s_i\\)\\}\\(_{i=1}^n\\)}. In this situation, the original item \\(log \\frac{f(c_i)}{(\\sum_{j=1}^{N} c_j)}\\) can be transformed to \\(a log f(M(s_j))\\), since \\(\\sum_{j=1}^{N} c_j = n\\). We cluster the mapping scores with a same value as a group, from which we can obtain M groups with values of {M(sj)}\\(_{j=1}^M\\). The size of \\(i^{th}\\) group is exactly ci, where \\(\\frac{i_b}{N} = M(s_j)\\). We denote the \\(c_i\\) as cz. The {\\(c_i\\)\\}\\(_{j=1}^M\\) consist of the non-zero part of {c}\\(_{i=1}^N\\). Then the original formation can be transformed to \\(min.\\frac{1}{n} \\sum_{i=1}^{n}log f(M(s_i))\\), which is exactly equal to traversing all the M(si), si \\( \\in \\) {\\(s_i\\)\\}\\(_{i=1}^n\\), sum them up as \\(\\sum_{i=1}^{n}log(f(M(s_i)))\\), and combine the items with same value of mapping scores.\n\\(min.\\frac{1}{n} \\sum_{i=1}^{n}log(f(M(s_i)))\\)\ns.t.\\frac{1}{n}\\sum_{k=1}^{n}M(s_k) = \\mu\\\n\\frac{1}{n}\\sum_{k=1}^{n}[M(s_k) - \\mu_\\mu]^2 = \\hat{o}^2(13)\nThen, we obtain Eq. 13. After that, by using Lagrange Multiplier method, we can transform Eq. 13 to Eq. 14, where \\(\\lambda_1\\) > 0, \\(\\lambda_2\\) > 0."}, {"title": "A.2. Proof of Theorem 2", "content": "When L(a, b) = \\((a - b)^2\\), we can transform Eq. 9 to Eq. 15, where \\(\\lambda_1 = \\frac{D_{intra}}{D_{intra} + D_{inter}}\\) and \\(\\lambda_2 = \\frac{D_{inter}}{D_{intra} + D_{inter}}\\) . According to KKT condition (Boyd & Vandenberghe, 2004), the optimal solution of \\(L_b\\) should satisfy Eq. 16. As shown in Appendix A.9, the gradient of architecture of conditional network can not be equal to 0. Thus, \\(2\\lambda_1(y+\\epsilon_s - \\hat{S}^*(P)) + 2\\lambda_2(y+\\epsilon_s - \\hat{S}^*(P))) = 0\\). Then, \\(\\hat{S}^*(P) = y + \\lambda_1\\epsilon_s + \\lambda_2 \\epsilon_s\\). Thus, \\(E[(\\hat{S}^*(P) - y)^2] = E[(\\lambda_1\\epsilon_s + \\lambda_2 \\epsilon_s)^2]\\). Since f(x) = \\(x^2\\) is a convex function, according to Jensen's Inequality, \\(E[(\\lambda_1\\epsilon_s + \\lambda_2 \\epsilon_s)^2] > [E(\\lambda_1\\epsilon_s + \\lambda_2 \\epsilon_s)]^2\\). Since \\(\\epsilon_1 \\sim D_{\\zeta}(\\mu_{\\zeta}, \\sigma_{\\zeta})\\), \\(\\epsilon_2 \\sim D_{\\varsigma}(\\mu_{\\varsigma},\\sigma_{\\varsigma})\\),"}, {"title": "A.3. Proof of Lemma 1", "content": "When using stochastic gradient descent algorithm, the gradient of Eq. 9 and Eq. 11 is shown in Eq. 17 and Eq. 18 respectively, where B is the set of sample in batch and |B| is the size of set {(r,t)|r \\( \\in \\) B,t \\( \\in \\) B}. Let \\(g_i\\),j denote the item in Eq. 18, whose index is (i, j). Let gi,j denote the item in Eq. 17, whose index is (i, j). gi,j can be transformed to\n\\(g_{i,j} + [\\lambda_1(\\epsilon_{s,i} - \\epsilon_{s,j}) + \\lambda_2(\\epsilon_{\\varsigma,i} - \\epsilon_{\\varsigma,j})](\\hat{S}_i - \\hat{S}_j)\\frac{\\partial(S_i - S_j)}{\\partial P}\\) Thus, the gradient of Eq. 9 can be deemed as the gradient of Eq. 11 add some random noise scaled by \\((\\hat{S}_i - \\hat{S}_j)\\frac{\\partial(S_i - S_j)}{\\partial P}\\)for each sample. Let \\(\\hat{S}^{\\dagger}\\) denote the optimal solution of Eq. 11. Thus, \\(L'(\\hat{S}) \\geq L'(\\hat{S}^{\\dagger}), \\forall\\hat{S}\\), and it satisfies Assumption 5.1 in (Bu et al., 2024)."}, {"title": "A.5. Prompt Design", "content": "For each dataset, their prompts contain four parts: the expertise supplement, the input data, the task description and examples, where examples are chosen by the standard illustrated in set-up-pitch prompt. We list the concrete prompts for different datasets below. Since the prompt of aircraft monitoring datasets (Flight 1 and Flight 2) refers to trade secrets of the airline company, we do not list them below. Due to the randomness of LLM, we run multiple times and pick the one with best performance to collaborate with task-specific small model."}, {"title": "A.6. Anomaly classification", "content": "We use different binary classification standard to classify the anomalies in Flight 1 and Flight 2. Among them, the most common binary classification standard is point anomaly and contextual anomaly, which is illustrated in (Lai et al., 2024). Besides, we also introduce other two kinds of binary classification standard for aircraft monitoring dataset to explore the compensative effect between LLM and task-specific small model. According to the degree of reliance on expert knowledge for anomaly detection, we can divide anomalies into background anomaly and data pattern anomaly. The background anomalies highly rely on expertise knowledge, while the data pattern anomaly can be identified only by task-specific small model. As shown in Fig. 6(a), the valid range of dependent variable is decided by the independent variable, which should satisfy the laws of physics between different parameters. It is usually hard for neural network to clearly identify the valid range of the dependent variable, given independent variable. Thus, in this case, it rely on expertise knowledge and belongs to background anomaly. In contrast, in Fig. 1(a), the redundant channel mechanism usually requires most of redundant channel can reach a consensus. Thus, different redundant channels should always be similar to each other in normal status. In this situation, the neural network can identify the similarity between different channels without expertise knowledge. Thus, it belongs to data pattern anomaly. According to the similarity between anomaly and surrounding time series, we can divide anomalies into gradual anomalies and mutant anomalies. As shown in Fig. 6(c), the anomalies are quite different from surrounding normal time series and they should belong to mutant anomalies. In Fig. 6(d), the anomalies are similar to surrounding normal time series and they should belong to gradual anomaly."}, {"title": "A.7. Datasets", "content": "In our experiments, we used four datasets from different scenarios: the cloud service monitoring, the aircraft monitoring, the mathematical-assumption-based anomaly datasets. We introduce these datasets in the following."}, {"title": "A.8. Hyperparameters", "content": "We illustrate the meaning of each hyperparameter in Tab. 3 and list the value of hyperparameter in Tab. 4. Since the datasets used in our experiments consist of several subsets. In some dataset, we set different hyperparameter values for different subsets and we list the values used in the Tab. 4. In these situations, we use grid search to find the optimal combinations of these hyperparameters for each subset."}, {"title": "A.9. Architecture of conditional network", "content": "The conditional network uses the data representation obtained from task-specific small model as the condition and leverage the aligned anomaly score of small model and anomaly score of LLM to output collate anomaly score. As shown in Eq. 23, we firstly concat data representation, aligned anomaly score of small model and anomaly score of LLM as many conditional network do (Rakelly et al., 2018). After that, we use multilayer perceptrons to output collated anomaly score as shown in Eq. 24, where W\u2081 and W\u2082 are trainable parameters, \\(\\sigma_1\\) is leaky relu, and \\(\\sigma_2\\) is sigmoid function.\n\\(\\hat{S} = Concat(S, s, R)\\) (23)\n\\(\\hat{S} = \\sigma_2(W_2\\sigma_1(W_1 \\cdot \\hat{S}))\\) (24)"}]}