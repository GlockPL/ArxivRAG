{"title": "SPICEPilot: Navigating SPICE Code Generation and Simulation with AI Guidance", "authors": ["Deepak Vungarala", "Sakila Alam", "Arnob Ghosh", "Shaahin Angizi"], "abstract": "Large Language Models (LLMs) have shown great potential in automating code generation; however, their ability to generate accurate circuit-level SPICE code remains limited due to a lack of hardware-specific knowledge. In this paper, we analyze and identify the typical limitations of existing LLMs in SPICE code generation. To address these limitations, we present SPICEPilot\u2014a novel Python-based dataset generated using PySpice, along with its accompanying framework. This marks a significant step forward in automating SPICE code generation across various circuit configurations. Our framework automates the creation of SPICE simulation scripts, introduces standardized benchmarking metrics to evaluate LLM's ability for circuit generation, and outlines a roadmap for integrating LLMs into the hardware design process. SPICEPilot is open-sourced under the permissive MIT license at https://github.com/ACADLab/SPICEPilot.git.", "sections": [{"title": "I. INTRODUCTION", "content": "The escalating complexity of modern software and the rapid advancements in hardware technologies present significant challenges in developing innovative circuit solutions. As software systems grow more intricate, the hardware that supports them must also evolve, leading to an intertwined cycle of increasing complexity in both domains. Traditional methods of circuit design and simulation struggle to keep pace with these developments, necessitating new approaches that can efficiently handle the growing demands [1], [2], [3], [4]. Recently, Large Language Models (LLMs) or Language Models (LMs) have demonstrated remarkable capabilities in generating Python code, offering potential avenues for automating aspects of software development. However, their application in hardware design remains limited due to a lack of inherent hardware domain knowledge. This gap poses a significant obstacle, as hardware design requires a deep understanding of architectural, micro-architectural, and logic levels as well as electronic components, circuit behaviors, and simulation processes that LLMs are not typically trained on [1], [3].\nLLMs have recently shown promising solutions for generating digital and micro-architectural designs, e.g., MEV-LLM [5] proposes multi-expert LLM architecture for Verilog code generation. RTLLM [2], GPT4AIGChip [6], and SA-DS [7] enhance design efficiency, showcasing LLMs' ability to manage complex design tasks and broaden access to AI accelerator design. Nevertheless, the application of LLM in analog circuit design has been limited to a few works. To the best of our knowledge, AnalogCoder [3] is among the first Analog circuit generators.\nThe research presented here opens up a vast array of intriguing research questions that are yet to be explored. Our aim is to address the most pressing of these and propose a structured path for future works. Key questions include: (RQ1): How reliable are LLMs in the context of analog circuit design, and what are their foundational limitations in this domain? (RQ2): What steps are required to develop a specialized LLM tailored specifically for analog circuit design? (RQ3): How can the challenge of data scarcity be addressed in the niche field of analog circuit design? (RQ4): Are there methodologies that would enable LLMs to autonomously generate or enhance datasets needed for analog circuit design? (RQ5): How can LLMs be equipped with logical reasoning capabilities specific to circuit design to ensure effective interpretation and solution of hardware-specific problems? (RQ6): What new metrics and benchmarks should be established to accurately assess the performance, accuracy, and reliability of LLMs in executing hardware design tasks? These research questions form the basis of our investigation, with the ultimate goal of advancing LLM-driven hardware design solutions.\nIn this paper, we propose a novel framework that leverages the strengths of LLMs in Python code generation to assist in analog circuit design creation and simulation. By utilizing PySpice\u00b9, a Python library for SPICE simulation, we generate a comprehensive dataset of Python-based SPICE codes that correspond to various transistor models and circuit configurations. This approach effectively bridges the gap between software and hardware domains, enabling the use of LLMs to facilitate SPICE simulations and accelerate the design process. Moreover, we introduce standardized benchmarking criteria to evaluate the performance and accuracy of the generated circuits. This standardization is crucial for comparing different designs and ensuring that the innovations meet the required specifications and industry standards. Our framework lays the groundwork for future research directions, highlighting the potential for integrating LLMs more deeply into hardware design workflows and paving the way for automated, intelligent circuit generation and optimization.\nThis research addresses many of the key questions outlined earlier, as we explore the capabilities of LLM's in the analog domain. Noteworthy contributions include:\n\u2022\tWe evaluate LLM performance in SPICE code generation, where both open-source and proprietary models are"}, {"title": "II. BACKGROUND", "content": "LLM for Hardware Design. LLMs show promise in generating Hardware Description Language (HDL) and High-Level Synthesis (HLS) code. VeriGen [8] and ChatEDA [17] refine hardware design workflows, automating the RTL to GDSII process with fine-tuned LLMs. AssertLLM incorporates three customized LLM and finally generate multiple system verilog assertions each performing different functionalities [13]. ChipGPT [9] and Autochip [11] integrate LLMs to generate and optimize hardware designs, with Autochip producing precise Verilog code through simulation feedback. MG-Verilog [1] created a hardware dataset with over 11,000 verilog code. Chip-Chat [10] demonstrates interactive LLMs like ChatGPT-4 in accelerating design space exploration. MEV-LLM [5] proposes multi-expert LLM architecture for Verilog code generation. RTLLM [2] and GPT4AIGChip [6] enhance design efficiency, showcasing LLMs' ability to manage complex design tasks and broaden access to AI accelerator design. In VerilogReader [18] the LLM accurately grasp the code logic and generate stimuli to reach the unexplored code branches. To the best of our knowledge, GPT4AIGChip [6] and SA-DS [7] are a few initial works focus on an extensive framework specifically aimed at the generation of domain-specific AI accelerator designs where SA-DS focus on creating a dataset in HLS and employ fine-tuning free methods such as single-shot and multi-shot inputs to LLM. LLMCompass [19] is able to describe and evaluate different hardware design. However, the absence of prompt optimization, tailored datasets, model fine-tuning, and LLM hallucination pose a barrier to fully harnessing the potential of LLMs in such frameworks [17], [7]. This limitation confines their application to standard LLMs without fine-tuning or In-Context Learning (ICL) [17], which are among the most promising methods for optimizing LLMs [20]. AnalogCoder [3] to our knowledge is among the first Analog circuit generator and generated the circuit through prompt engineering ICL. AmpAgent [16] is designed for performance porting.\nSPICE. SPICE is a computer-based tool widely used by engineers for simulating and modeling electronic circuits. By performing mathematical analysis, it allows for the prediction of circuit behavior. SPICE can simulate a variety of components, from basic passive elements like resistors and capacitors to more advanced semiconductor devices like MOSFETS, making it essential for circuit design and optimization. Components are defined by their names, the nodes they are connected to, and their values, including resistors (R), capacitors (C), inductors (L), and transistors (M for MOSFETs, Q for BJTs). The netlist describes the interconnections of these components across the circuit's nodes."}, {"title": "III. HOW TALL DOES LLM STAND IN SPICE CODE GENERATION?", "content": "While LLMs demonstrate exceptional performance across various generative tasks, such as question answering, language translation, and conversational agents, these applications primarily involve natural language processing, an area in which LLMs receive extensive training. In contrast, their proficiency in managing specialized languages and tasks that are less frequently encountered during pretraining, such as generating SPICE code for hardware design, remains uncertain. Therefore, to effectively employ LLMs in automating hardware design tasks like SPICE code generation, it is essential to develop a comprehensive understanding of the capabilities and limitations of state-of-the-art LLMs. This understanding can prevent both undue optimism and unwarranted pessimism regarding their application. Our evaluation aims to provide this insight, establishing a foundation for future advancements in LLM-driven automated hardware design. To achieve this objective, we conducted an in-depth exploration and identified the common limitations of existing LLMs in the context of SPICE code generation. Ultimately, by addressing the identified shortcomings, we can reevaluate the potential of LLMs for practical automation in SPICE-based hardware design."}, {"title": "A. Misconception of Gate Width and Length", "content": "In SPICE code simulation, the precise definition and selection of gate lengths and widths are paramount to accurate circuit simulation and analysis. However, LLMs exhibit notable misconceptions in this area, and these misconceptions have a direct impact on circuit performance. Specifically, LLMs need a more foundational understanding of critical circuit design principles, such as the 2:1 PMOS to NMOS"}, {"title": "IV. SPICEPILOT", "content": "In this section, we address RQ3, RQ4, and RQ5 posed in the introduction. The proposed SPICEPilot framework focuses on leveraging the capabilities of LLM to generate hardware SPICE code within a Python environment using PySpice, while avoiding the costly process of fine-tuning. Given the scarcity of data, the goal is to enable the LLM to reason and creatively contribute to the development of intelligent models in circuit design. This is achieved by embedding fundamental circuit logic, reasoning, and error identification mechanisms. In the SPICEPilot framework, we introduce a computation-friendly method that leverages a reference containing step-by-step guidelines for code generation. This reference minimizes trivial errors and limits the need for extensive hardware knowledge, helping to avoid common mistakes that we discussed in Section III. The reference is used to validate every output generated by the LLM, significantly reducing errors. This approach is akin to ICL2."}, {"title": "A. Framework", "content": "Fig. 2 illustrates the initial methodology designed for data augmentation in circuit generation using LLMs. The process begins with the 1 User Input, where the user provides specifications for the desired circuit. This input is then processed through the Pilot Prompt (2), which integrates hardware knowledge to help the LLM mitigate common errors and offer insights into PySpice modules and coding styles. Leveraging this refined prompt, the LLM generates the corresponding PySpice code (3). The generated code undergoes a Validation process (4) to ensure the netlist correctness, where a human expert reviews and corrects trivial errors such as keyword mismatches in Python with PySpice. Successfully validated code is added to the Dataset (5). If the netlist is improperly constructed, the code is deemed invalid, and additional comments detailing the errors are sent back to the LLM (6), prompting a revision. This iterative cycle (3\ncontinues until valid code is produced (5). Concurrently, the identified errors contribute to the ongoing optimization of the Pilot Prompt (7), which is updated either manually by a human expert or automatically via scripting based on the errors encountered. The valid PySpice in step 3 also allows us to generate the SPICE netlist, which is processed to extract key parameters such as the number of transistors after code verification step 4. From the analysis, we obtain metrics such as gain while maintaining associated metadata as data points. The curated dataset will then be effectively utilized in our future works to enhance the LLM through ICL or fine-tuning, aiming to generate more robust designs in PySpice and SPICE (step 3). The enhanced model continues to produce code that is subjected to functional validation, adhering to the valid and invalid classifications (step \u2468). In cases of invalid code generation, the model receives specific error feedback to facilitate continuous improvement. The ultimate goal of this methodology is to iteratively refine the LLM's capability to generate accurate and functional circuit designs based on user inputs, leveraging continuous validation and prompt optimization to enhance performance and reliability. Ultimately, the framework outputs the functional SPICE (.sp) and PySpice (.py) codes."}, {"title": "B. Dataset Generation and Benchmarking", "content": "The data points currently are stored with each point representing both the Pyspice model and its corresponding SPICE representation. This dual representation enables our dataset to be utilized to generate SPICE models using conventional methods or for rapid simulations within a Python environment. To address RQ6, we aim to establish a baseline evaluation for the community. Our selection criteria for benchmarking are based on the transistor count within the circuit. This benchmark consists of both Digital and Analog circuits as depicted in Table III. We classify circuits as follows: those with a transistor count of 10 or fewer are categorized as \"easy\"; those ranging from 11 to 25 as \"medium\"; circuits with 26 to 45 transistors are deemed \"hard\"; and circuits exceeding 45 transistors are classified as \"extreme.\" This initial benchmarking framework can be further refined and expanded by considering additional factors, such as the number of nodes, which would enhance the understanding of circuit complexity and improve overall benchmarking for the community.\nPrevious studies in this domain, such as [3], have discussed benchmarking with a limited set of circuits. For our benchmark, we conducted a meticulous search and selected 60 unique circuits, which is 150% larger than the Analogcoder benchmark [3], over 7.5\u00d7 the number of circuits included in the ChipChat benchmark [10], and offers 250% more circuits compared to the VeriGen benchmark [8]."}, {"title": "V. EXPERIMENTAL ANALYSIS", "content": "This section presents the SPICEPilot implementation and evaluation in two key aspects: (i) Demonstrating the framework's ability to generate results that surpass current standards, and (ii) Establishing a comprehensive benchmark for robust evaluation. The above experiments are conducted to critically evaluate and gain insights necessary for establishing more concrete standardization for the LLMs. The identified capabilities and limitations are further discussed in Section VI. We extensively evaluate the capability of LLMs in circuit design, including CodeLlama-70B-Instruct [21], Wizardcoder-33B-V1.1 [22], Llama3-70B [23], GPT-3.5 [24], and GPT-40. CodeLlama and WizardCoder are code generation LLMs, fine-tuned on Llama2 [25] and StarCoder [26], respectively. Llama-3 is the newest open-source general LLM. WizardCoder and Llama-3 are LLMs that outperformed GPT-3.5 on the HumanEval [27] coding tasks [28]. We adopt the 'Pass@k' metric [29] (k=1, 5) as our main evaluation standard, a widely used approach in code generation tasks [21], [22]. This metric quantifies the proportion of correct generations within k independent attempts, where higher values denote better performance. We conduct n trials (n \u2265 k) and compute Pass@k using the formula $1 - \\binom{n}{c} / \\binom{n}{k}$, where c denotes the number of successful attempts.\nIn our experiment, we utilize the setup illustrated in Fig. 2, employing Claude-3.5 Sonnet as the backbone LLM. The Pilot prompt is provided as an initial reference for learning. Subsequently, we prompt the LLM to generate solutions for each task in the Analogcoder Benchmark (ACB) [3]. Since our framework emphasizes prompt engineering, we adapted the ACB prompts to include more detailed verbal descriptions of the circuit design, as outlined in Table III. Table IV demonstrates the superior performance of our framework, with notable improvement of 52.90% in Pass@1 scores and improvement of 1.91% at pass@5 and generating all 24 circuits in the benchmark, validating the efficacy of fine-tuning free approach with our prompt-engineered to augment the data in enhancing circuit design automation\nIn the second experiment, we employed two closed-source models, integrating the Pilot prompt to infer circuits from their internal knowledge. We randomly selected 10 circuits from our versatile benchmarking in varying levels of complexity, ranging from simple to challenging, to evaluate the performance of the LLM. The results in Table V indicate a high pass ratio, with the models successfully generating circuits with different transistor counts. The initial percentage for hard circuits in benchmarking V is low, and our observation revealed it is due to various factors, such as module definition in Python, which is not supported by Spice, and the tuning of the circuit, which can be later resolved by either using Chain-of-Thought (CoT) or simple repetitive asking. Additionally, our framework automates waveform generation in PySpice and SPICE code generation, facilitating easy validation of the circuits. The model outputs are further subjected to verification, ensuring the correct creation of circuit netlists. It is important to note that numerous parameters must be fine-tuned for functional verification of analog circuits, including the adjustment of resistors and coupling capacitors, which play a critical role in analog domain performance."}, {"title": "VI. DISCUSSIONS AND FUTURE WORKS", "content": "The research delves into the functionality of LLMs, revealing that while the framework generates accurate netlists in our experiments, achieving functional efficiency and meeting key parameters such as gain requires further knowledge instillation. This need arises due to the LLM's limited circuit-specific intelligence. To address this, we plan to enhance the LLM by providing it with high-definition circuit knowledge, enabling it to better integrate and resonate with detailed circuit behavior and design requirements. Figure 2 presents the proposed framework aimed at addressing the significant data bottleneck in circuit generation through automated data augmentation, extension of it's applicability. This framework offers the community an initial methodology to streamline data generation processes. The approach can be extended to leverage multi-modal LLM by incorporating circuit images as inputs. Utilizing Python packages, the framework can be enhanced to the drawing of circuit and waveform representations for a better decoding, thereby facilitating reasoning based on visual inputs. The use of Python also allows for the implementation of class functions to construct circuits that can be integrated into more extensive design projects seamlessly. Additionally, the SPICE code generation dataset can be enhanced by incorporating detailed descriptions, similar to the methodology proposed in [1]. This enhancement assists LLMs in generating more sophisticated and accurate SPICE models, thereby advancing the capabilities of SPICE generation in LLM's."}, {"title": "VII. CONCLUSION", "content": "This paper presents SPICEPilot, an innovative approach to bridging the gap between software automation and hardware design in the realm of analog and digital circuits. By leveraging LLMs and PySpice, SPICEPilot automates the generation of SPICE code and introduces a reliable framework for benchmarking circuit performance. Our evaluation of both open-source and proprietary LLMs underscores the current limitations and future potential of AI-driven code generation in hardware design. Moreover, our proposed framework offers a solution to data scarcity through the generation of open-source datasets, paving the way for further advancements in the field. This work lays the foundation for future research aimed at optimizing LLMs for analog circuit applications, accelerating innovation in circuit design and automation"}]}