{"title": "FEDL2G: LEARNING TO GUIDE LOCAL TRAINING IN\nHETEROGENEOUS FEDERATED LEARNING", "authors": ["Jianqing Zhang", "Yang Liu", "Yang Hua", "Jian Cao", "Qiang Yang"], "abstract": "Data and model heterogeneity are two core issues in Heterogeneous Federated\nLearning (HtFL). In scenarios with heterogeneous model architectures, aggregat-\ning model parameters becomes infeasible, leading to the use of prototypes (i.e.,\nclass representative feature vectors) for aggregation and guidance. However, they\nstill experience a mismatch between the extra guiding objective and the client's\noriginal local objective when aligned with global prototypes. Thus, we propose a\nFederated Learning-to-Guide (FedL2G\u00b9) method that adaptively learns to guide\nlocal training in a federated manner and ensures the extra guidance is beneficial\nto clients' original tasks. With theoretical guarantees, FedL2G efficiently imple-\nments the learning-to-guide process using only first-order derivatives w.r.t. model\nparameters and achieves a non-convex convergence rate of O(1/T). We con-\nduct extensive experiments on two data heterogeneity and six model heterogene-\nity settings using 14 heterogeneous model architectures (e.g., CNNs and ViTs) to\ndemonstrate FedL2G's superior performance compared to six counterparts.", "sections": [{"title": "1 INTRODUCTION", "content": "With the rapid development of AI techniques (Touvron et al., 2023; Achiam et al., 2023), public\ndata has been consumed gradually, raising the need to access local data inside devices or institu-\ntions (Ye et al., 2024). However, directly using local data often raises privacy concerns (Nguyen\net al., 2021). Federated Learning (FL) is a promising privacy-preserving approach that enables col-\nlaborative model training across multiple clients (devices or institutions) in a distributed manner\nwithout the need to move the actual data outside clients (Kairouz et al., 2019; Li et al., 2020). Nev-\nertheless, data heterogeneity (Li et al., 2021; Zhang et al., 2023d;a) and model heterogeneity (Zhang\net al., 2024b; Yi et al., 2023) remain two practical issues when deploying FL systems. Personalized\nFL (PFL) mainly focuses on the data heterogeneity issue (Zhang et al., 2023e), while Heteroge-\nneous FL (HtFL) considers both data and model heterogeneity simultaneously (Zhang et al., 2024a).\nHtFL's support for model heterogeneity enables a broader range of clients to participate in FL with\ntheir customized models.\nIn HtFL, sharing model parameters, a widely used technique in traditional FL and PFL, is not ap-\nplicable (Zhang et al., 2024b). Instead, lightweight knowledge carriers, including small auxiliary\nmodels (Shen et al., 2020; Wu et al., 2022; Yi et al., 2024), tiny homogeneous modules (Liang et al.,\n2020; Yi et al., 2023), and prototypes (i.e., class representative feature vectors) (Jeong et al., 2018;\nTan et al., 2022b), can be shared among clients. Of these, prototypes offer the most significant\ncommunication efficiency due to their compact size.\nHowever, representative prototype-based methods FedDistill (Jeong et al., 2018) and FedProto (Tan\net al., 2022b), still suffer from a mismatch between the prototype-guiding objective and the client's"}, {"title": null, "content": "original local objective. These methods typically introduce an extra guiding objective alongside the\noriginal local objective, aiming to guide local features to align with the global ensemble prototypes.\nDue to the significant variation in width and depth among clients' heterogeneous models, their fea-\nture extraction capabilities also differ considerably (Zhang et al., 2024a;b). On the other hand, the\ndata distribution also diverges across clients (McMahan et al., 2017; Li et al., 2022). Since the global\nprototypes are derived from aggregating diverse local prototypes, they inherently cannot fully align\nwith specific client models and their respective data. Consequently, directly optimizing the guiding\nand local objectives together without prioritizing the original local objective has the potential to un-\ndermine the local objective of each client due to the objective mismatch. We illustrate an example of\nthis mismatch problem in Fig. 1, where the \u201cnegative effect\" is measured by the maximum increase\nbetween the current local loss and the previous lowest local loss during federated training.\nTo address the issue of objective mismatch, we propose a\nnovel Federated Learning-to-Guide (FedL2G) method.\nIt gives priority to the original local objective while learn-\ning the guiding objective, ensuring that the guiding objec-\ntive can facilitate each client's original local task rather\nthan causing negative effects. This is why we term it\n\"learning to guide\". Specifically, we hold out a tiny quiz\nset from the training set and denote the remaining set as\na study set on each client. Then we learn guiding vectors\nin a federated manner, ensuring that updating client mod-\nels with both the extra guiding loss and the original local\nloss on their study sets consistently reduces the original\nlocal loss on their quiz sets (which are not used for train-\ning and testing). The minimal negative effect (close to\nzero) and the superior test accuracy illustrated in Fig. 1\nembody the design philosophy and effectiveness of our\nFedL2G. Moreover, in contrast to learning-to-learn (Finn\net al., 2017; Jiang et al., 2019; Fallah et al., 2020a), the\nlearning-to-guide process in our FedL2G only requires first-order derivatives w.r.t. model parame-\nters, making it computationally efficient.\nWe assess the performance of our FedL2G across various scenarios. In addition to test accuracy,\nwe also evaluate communication and computation overhead. We summarize our contributions as:\n\u2022 In the context of HtFL with data and model heterogeneity, we analyze and observe the ob-\njective mismatch issue between the extra guiding objective and the original local objective\nwithin representative prototype-based methods.\n\u2022 We propose a FedL2G method that prioritizes the original local objective while using the\nextra guiding objective, thus eliminating negative effects.\n\u2022 We theoretically prove that FedL2G achieves efficiency using only first-order derivatives\nw.r.t. model parameters, with a non-convex convergence rate of O(1/T).\n\u2022 To demonstrate our FedL2G 's priority, we conducted extensive experiments covering two\ntypes of data heterogeneity, six types of model heterogeneity (including 14 distinct model\narchitectures such as CNNs and ViTs), and various system settings."}, {"title": "2 RELATED WORK", "content": null}, {"title": "2.1 HETEROGENEOUS FEDERATED LEARNING (HTFL)", "content": "Presently, FL is one of the popular collaborative learning and privacy-preserving techniques (Zhang\net al., 2023d; Li et al., 2020) and HtFL extends traditional FL by supporting model heterogene-\nity (Ye et al., 2023). Prevailing HtFL methods primarily consider three types of model hetero-\ngeneity: (1) group heterogeneity, (2) partial heterogeneity, and (3) full heterogeneity (Zhang et al.,\n2024b). Among them, the HtFL methods considering group model heterogeneity extract different\nbut architecture-constraint sub-models from a global model for different groups of clients (Diao\net al., 2020; Horvath et al., 2021; Wen et al., 2022; Luo et al., 2023; Zhou et al., 2023). Thus, they"}, {"title": null, "content": "cannot support customized client models and are excluded from our consideration. Additionally,\nsharing and revealing model architectures within each group of clients also raises privacy and in-\ntellectual property concerns (Zhang et al., 2024a). As the server is mainly utilized for parameter\naggregation in prior FL systems (Tan et al., 2022a; Kairouz et al., 2019), training a server module\nwith a large number of epochs, like (Zhang et al., 2024b;a; Zhu et al., 2021), necessitates addi-\ntional upgrades or the purchase of a new heavy server, which is impractical. Thus, we focus on the\nserver-lightweight methods.\nBoth partial and full model heterogeneity accommodate customized client model architectures, but\npartial heterogeneity still assumes some small parts of all client models to be homogeneous. For\nexample, LG-FedAvg (Liang et al., 2020) and FedGH (Yi et al., 2023) stand out as two representative\napproaches. LG-FedAvg and FedGH both partition each client model into a feature extractor part\nand a classifier head part, operating under the assumption that all classifier heads are homogeneous.\nIn LG-FedAvg, the parameters of classifier heads are uploaded to the server for aggregation, whereas\nFedGH uploads prototypes to the server and trains the lightweight global classifier head for a small\nnumber of epochs. Both methods utilize the global head for knowledge transfer among clients but\noverlook the inconsistency between the global head and local tasks.\nIn the case of full model heterogeneity, mutual distillation (Zhang et al., 2018) and prototype guid-\nance (Tan et al., 2022b) emerge as two prevalent techniques. Using mutual distillation, FML (Shen\net al., 2020) and FedKD (Wu et al., 2022) facilitate knowledge transfer among clients through a\nglobally shared auxiliary model. However, sharing an entire model demands substantial communi-\ncation resources, even if the auxiliary model is typically small (Zhang et al., 2024b). Furthermore,\naggregating a global model in scenarios with data heterogeneity presents numerous challenges, such\nas client-drift (Karimireddy et al., 2020), ultimately leading to a subpar global model (Li et al.,\n2022; Zhang et al., 2023a;b;c). As representative prototype guidance methods, FedDistill (Jeong\net al., 2018) and FedProto (Tan et al., 2022b) gather prototypes on each client, aggregate them on\nthe server to create the global prototypes, and guide client local training with these global proto-\ntypes. Specifically, FedDistill extracts lower-dimensional prototypes than FedProto. This difference\nstems from FedDistill applying prototype guidance in the logit space, whereas FedProto uses the\nintermediate feature space. Sharing higher-dimensional prototypes can transfer more information\namong clients; however, it may also exacerbate the negative effects of objective mismatch."}, {"title": "2.2 STUDENT-CENTERED GUIDANCE", "content": "Our learning-to-guide philosophy draws inspiration from student-centered knowledge distillation\napproaches (Yang et al., 2024). They are based on the insight that a teacher's subject matter ex-\npertise alone may not match the student's specific studying ability and style, resulting in negative\neffects (Sengupta et al., 2023; Yang et al., 2024). To address the mismatch between the teacher's\nknowledge and the needs of the student, updating the teacher model with concise feedback from\nthe student on a small quiz set represents a promising direction (Ma et al., 2022; Zhou et al., 2022;\nSengupta et al., 2023).\nHowever, these student-centered approaches are built upon a teacher-student framework, assuming\nthe presence of a well-trained large teacher model. They concentrate on a central training scheme\nwithout factoring in distributed multiple students and privacy protection (Lee et al., 2022; Hu et al.,\n2022), rendering them inapplicable in the context of HtFL. Additionally, modifying and extending\nthese student-centered approaches to HtFL requires significant communication and computational\nresources to update a shared large teacher model based on student feedback (Zhou et al., 2022; Lu\net al., 2023). Nevertheless, the student-centered guidance concept inspires us to propose a learning-\nto-guide approach in HtFL. This involves substituting the large teacher model with compact guiding\nvectors and updating these guiding vectors based on clients' feedback from their quiz sets, making\nour FedL2G lightweight, efficient, and adaptable."}, {"title": "3 FEDERATED LEARNING-TO-GUIDE: FEDL2G", "content": null}, {"title": "3.1 NOTATIONS AND PRELIMINARIES", "content": "Problem statement. In an HtFL system, N clients, on one hand, train their heterogeneous\nlocal models (with parameters 01,...,0N) using their private and heterogeneous training data"}, {"title": null, "content": "D1,..., DN. On the other hand, they share some global information, denoted by G, with the as\nsistance of a server to facilitate collaborative learning. Formally, the typical objective of HtFL is\n$\\min \\limits_{\\theta_1,...,\\theta_N} \\sum \\limits_{i=1}^N \\frac{|D_i|}{n} -\\mathcal{L}_{D_i} (\\theta_i, G),$ (1)\nwhere $|D_i|$ represents the size of the training set $D_i$, $n = \\sum_{i=1}^N |D_i|$, and $\\mathcal{L}_{D_i}$ denotes a total client\ntraining objective over $D_i$.\nPrototype-based HtFL. Sharing class-wise prototypes of low-dimensional features in either\nthe intermediate feature space or the logit space among clients has become a prevalent and\ncommunication-efficient solution to address model heterogeneity in HtFL (Ye et al., 2023). Take\nthe popular scheme (Jeong et al., 2018) for example, where prototypes are shared in the logit space,\nG (the set of global prototypes) is defined by\n$\\mathcal{G} = \\{g^y\\}_{y=1}^C, \\quad g^y = \\text{agg}(\\{g_1^y, ..., g_N^y\\}), \\quad g_i^y = \\mathbb{E}_{(x,y)\\sim D_{i,y}} [f_i(x, \\theta_i)],$ (2)\nand C represents the total number of classes of clients' original local tasks. $g^y$ and $g_i^y$ denote the\nglobal and local prototypes of class $y$, respectively. Besides, agg is an aggregation function defined\nby each prototype-based HtFL method, $D_{i,y}$ stands for a subset of $D_i$ containing all the data of\nclass $y$, and $f_i$ represents the local model of client $i$. Given a global G, client $i$ then takes prototype\nguidance for knowledge transfer among clients via\n$\\mathcal{L}_{D_i} (\\theta_i, \\mathcal{G}) := \\mathbb{E}_{(x,y)\\sim D_i} [l_{ce}(f_i(x, \\theta_i), y) + l_{g}(f_i(x, \\theta_i), g^y)],$ (3)\nwhere the weight of $l_{g}$ is set to one to balance two objectives equally here, $l_{ce}$ is the original local\ncross-entropy loss (Zhang & Sabuncu, 2018), and $l_{g}$ is the guiding loss."}, {"title": "3.2 LEARNING TO GUIDE", "content": "Motivation. Initially, heterogeneous client models trained by $l_{ce}$ can adapt to their individual local\ndata with diverse feature extraction capabilities. However, directly adding $l_{g}$ without prioritizing\n$l_{ce}$ can cause the model of each client to deviate from $l_{ce}$. On the other hand, since all feature\nvectors are extracted on heterogeneous client data, the aggregated global prototype, e.g., $g^y$, is data-\nderived, which may deviate from the features regarding class $y$ on each client. Both the model\nand data heterogeneity result in the objective mismatch issue between $l_{ce}$ and $l_{g}$, which causes the\nnegative effect to $l_{ce}$ when using $l_{g}$, as shown in Fig. 1 and discussed further in Sec. 4.5. Therefore,\nwe propose a novel FedL2G method, which substitutes the data-derived prototypes with trainable\nguiding vectors $\\mathcal{G} = \\{v^y\\}_{y=1}^C$ and ensures that G is learned to reduce $l_{ce}$ when guided by $l_{g}$.\nFormally, we replace Eq. (3) with a new loss to train the client model:\n$\\mathcal{L}_{D_i} (\\theta_i,\\mathcal{G}) := \\mathbb{E}_{(x,y)\\sim D_i}[l_{ce}(f_i(x, \\theta_i), y) + l_{g}(f_i(x, \\theta_i), v^y)],$ (4)\nwhere the learning of guiding vectors G is the key step.\nLearning guiding vectors. Without relying on data-derived information, we initialize the global G\nrandomly on the server and update it based on the aggregated gradients from participating clients in\neach communication iteration. Inspired by the technique of outer-inner loops in meta-learning (Zhou\net al., 2022), we derive the gradients of client-specific $v^y$ in the outer-loop, while focusing on\nreducing the original local loss, i.e., $l_{ce}$, in the inner-loop on each client. To implement the learning-\nto-guide process, we hold out a tiny quiz set $\\mathcal{D}_i^q$ (one batch of data) from $D_i$ and denote the remaining\ntraining set as the study set $\\mathcal{D}_i^s$. Notice that we exclusively conduct model updates on $\\mathcal{D}_i^s$ and never\ntrain $\\theta_i$ on $\\mathcal{D}_i^q$. In particular, $\\mathcal{D}_i^q$ is solely used to evaluate $\\theta_i$'s performance regarding the original\nlocal loss and derive the gradients (feedback) w.r.t. $v^y$. Below, we describe the details of FedL2G in\nthe $t$-th iteration, using the notation $t$ solely for the global G for clarity. We illustrate total processes\nin Fig. 2. Recall that $\\mathcal{G} = \\{v^y\\}_{y=1}^C$, we use the general notation G in the following descriptions for\nsimplicity, although all operations correspond to each $v^y$, $y \\in \\{1, ..., C\\}$ within G.\nFirstly, in step \u2460, we download $\\mathcal{G}^{t-1}$ from the server to client $i$. Then, in step \u2461, we perform\nregular training for $\\theta_i$ on $\\mathcal{D}_i^s$ using $\\mathcal{L}_{D_i} (\\theta_i, \\mathcal{G}^{t-1})$ (see Eq. (4)). Sequentially, the pivotal steps \u2462\nand \u2463 correspond to our objective of learning-to-guide. In step \u2462, we execute a pseudo-train step\n(without saving the updated model back to disk) on a randomly sampled batch $\\mathcal{B}^s$ from $\\mathcal{D}_i^q$, i.e.,\n$\\theta_i(\\mathcal{G}^{t-1}) \\leftarrow \\theta_i - \\eta_c \\nabla_{\\theta_i}L_{\\mathcal{B}^s} (\\theta_i, \\mathcal{G}^{t-1}),$ (5)\nwhere $\\eta_c$ is the client learning rate, and we call $\\theta_i(\\mathcal{G}^{t-1})$ as the pseudo-trained local model param-\neters, which is a function of $\\mathcal{G}^{t-1}$. In step \u2463, our aim is to update the $\\mathcal{G}^{t-1}$ in $L_{\\mathcal{B}^q} (\\theta_i, \\mathcal{G}^{t-1})$ (see\nEq. (4)) to minimize $l_{ce}$ with $\\theta_i(\\mathcal{G}^{t-1})$ on $\\mathcal{D}_i^q$, thus we compute the gradients of $\\mathcal{G}^{t-1}$ w.r.t. $l_{ce}$\non $\\mathcal{D}_i^q$: $\\nabla_{\\mathcal{G}^{t-1}}\\mathbb{E}_{(x,y)\\sim\\mathcal{D}_i^q} [l_{ce} (f_i(x, \\theta_i'(\\mathcal{G}^{t-1})), y)]$ (see Sec. 3.3 for details). Afterwards, we upload\nclients' gradients of $\\mathcal{G}^{t-1}$ in step \u2464 and aggregate them in step \u2465. Then, in step \u2466, we update the\nglobal $\\mathcal{G}^{t-1}$ on the server with the aggregated gradients. Put steps \u2462, \u2463, \u2464, \u2465, \u2466 together, we\nhave\n$\\mathcal{G}^{t} = \\mathcal{G}^{t-1} - \\frac{1}{N_s} \\eta_s \\sum\\limits_{i \\in \\mathcal{I}_t}  \\nabla_{\\mathcal{G}^{t-1}}\\mathbb{E}_{(x,y)\\sim\\mathcal{D}_i^q} [l_{ce} (f_i(x, \\theta_i - \\eta_c \\nabla_{\\theta_i}L_{\\mathcal{B}^s} (\\theta_i, \\mathcal{G}^{t-1})), y)],$ (6)\nwhere $\\eta_s$ is the server learning rate and $\\mathcal{I}_t$ is the set of participating clients in the $t$-th iteration. We\nutilize the weight $\\frac{1}{\\left|\\mathcal{I}_t\\right|}$ here, considering that all participating clients execute step \u2462 and \u2463 with\nidentical sizes of $\\mathcal{B}^s$ and $\\mathcal{D}_i^q$, $i \\in \\{1, ..., N\\}$. Since some classes may be absent on certain clients,\nwe only upload and aggregate the non-zero gradient vectors to minimize communication costs. We\ncan easily implement Eq. (6) using popular public tools, e.g., higher (Grefenstette et al., 2019).\nWarm-up period. Since G is randomly ini-\ntialized, using an uninformative G misguides\nlocal model training in Eq. (4). Therefore, be-\nfore conducting regular client training in step\n\u2461, FedL2G requires a warm-up period of T'\niterations (T' = 50 is enough) with step 1, 3\n4, 5, 6, 7. Without step 2, the warm-up\nprocess only involves one batch of each client's\nquiz set, thus demanding relatively small com-\nputation overhead.\nTwin HtFL methods based on FedL2G. The\nabove processes assume sharing information in\nthe logit space, denoted as FedL2G-l. Addi-\ntionally, when considering the intermediate fea-\nture space, we can rephrase all the correspond-\ning $l_{g}$, for instance, rewriting $l_{g} (h_i (x, \\theta_h), v^y)$"}, {"title": null, "content": "in Eq. (4), where $h_i$ represents the feature ex-\ntractor component in $f_i$, $\\theta_h \\subset \\theta$ denotes the\nassociated model parameters, and $v^y$ resides\nin the intermediate feature space. We denote\nthis twin method as FedL2G-f. The server\nlearning rate $\\eta_s$ is the unique hyperparameter\nin our FedL2G-l or FedL2G-f. Due to space constraints, we offer a detailed algorithm of our\nFedL2G-l in Algorithm 1. Extending it to FedL2G-f only requires necessary substitutions."}, {"title": "3.3 EFFICIENCY ANALYSIS", "content": "As we compute gradients for two different entities in the outer-loop and inner-loop, respectively,\nwe eliminate the necessity for calculating the second-order gradients of model parameters w.r.t. $l_{ce}$\nas well as the associated computationally intensive Hessian (Fallah et al., 2020b). Our analysis\nis founded on Assumption 1 and Assumption 2 in Appendix C. Due to space limit, we leave the\nderivative details to Eq. (C.11) and show client $i$'s gradient w.r.t. G here:\n$\\pi_i^t = -\\eta_c\\mathbb{E}_{(x,y)\\sim \\mathcal{D}_i^q}\\{\\nabla_1l_{ce}\\cdot\\nabla_2f_i\\cdot\\mathbb{E}_{(x',y')\\sim\\mathcal{B}^q} [\\nabla^2_{2fi}\\nabla_{\\mathcal{G}^{t-1}}\\nabla_1l_g]\\},$ (7)\nwhere $\\nabla_1l_{ce} := \\nabla_{a_1}l_{ce}(a_1, a_2)$, indicating the derivative of $l_{ce}$ w.r.t. the first variable, and so for\n$\\nabla_2f_i$ and $\\nabla_1l_g$. The operation $\\cdot$ denotes multiplication. Computing $\\nabla_1l_{ce}$ and $\\nabla_2f_i$ is a com-\nmon practice in deep learning (Zhang & Sabuncu, 2018) and calculating the $\\nabla_{\\mathcal{G}^{t-1}}\\nabla_1l_g$ term is\npivotal. To simplify the calculation, we choose the MSE loss as our $l_g$, so $l_{g}(f_i(x', \\theta_i), v^{y'}) =$\n$\\sum_{m=1}^M[f_i(x', \\theta_i)_m - v^{y'}]^2$, where M is the dimension of $v^{y'}$. Given $\\mathcal{G} = \\{v^y\\}_{y=1}^C$, we have\n$\\nabla_{\\mathcal{G}^{t-1}}\\nabla_1l_g = \\sum_{m=1}^M \\nabla_{\\mathcal{G}^{t-1}} (f_i(x', \\theta_i)_m - v_m^{y'}) = \\sum_{m=1}^M 2 = 2.$ (8)"}, {"title": "3.4 CONVERGENCE ANALYSIS", "content": "Given notations, assumptions, and proofs in Appendix C, we have\nTheorem 1 (One-iteration deviation). Let Assumption 1 to Assumption 3 hold. For an arbitrary\nclient, after every communication iteration, we have\n$\\mathbb{E}[\\mathcal{L}_E^{(t+1)E+1/2}] < \\mathcal{L}_E^{tE+1/2} + (\\frac{L_1\\eta_c - \\eta_c}{2}) \\sum \\limits_{e=1/2}^{E-1} ||\\nabla\\mathcal{L}_E^{tE+e}||^2 + \\frac{L_1 \\mathbb{E}\\eta_c \\sigma^2}{2} + 2\\eta_c^2\\eta_s L_2 R'E_R.$\nTheorem 2 (Non-convex convergence rate of FedL2G). Let Assumption 1 to Assumption 3 hold\nand $\u2206 = \\mathcal{C}^0 \u2212 \\mathcal{L}^\u2217$, where $\\mathcal{L}^\u2217$ refers to the local optimum. Given Theorem 1, for an arbitrary client\nand an arbitrary constant \u03f5, our FedL2G has a non-convex convergence rate O(1/T) with\n$\\sum\\limits_{t=0}^{T-1}\\sum\\limits_{e=1/2}^{E-1} \\mathbb{E}[||\\nabla\\mathcal{C}_E^{tE+e}||^2] < \\frac{2\u03f5}{T}, \\text { where } 0<\u03b7_c<\\frac{2\\Delta +L_1 E\u03b7_c^2 \u03c3^2 + 4\u03b7_c^2 \u03b7_s L_2 R\u2032 E_R.}{2\u03b7_c\u2212L_1\u03b7_c^2} <\u03f5.$\nAccording to Theorem 2, our FedL2G can converge at a rate of O(1/T), and the server learning\nrate $\\eta_s$ can be set to any positive value."}, {"title": "4 EXPERIMENTS", "content": "To evaluate the performance of our FedL2G-l and FedL2G-f alongside six popular server-\nlightweight HtFL methods: LG-FedAvg (Liang et al., 2020), FedGH (Yi et al., 2023), FML (Shen\net al., 2020), FedKD (Wu et al., 2022), FedDistill (Jeong et al., 2018), and FedProto (Tan et al.,\n2022b), we conduct comprehensive experiments on four public datasets under two widely used"}, {"title": null, "content": "data heterogeneity settings, involving up to 14 heterogeneous model architectures. Specifically,\nwe demonstrate the encouraging performance of FedL2G in accuracy, communication cost, and\ncomputation cost. Subsequently, we investigate the characteristics behind our FedL2G from an\nexperimental perspective.\nData heterogeneity settings. Following existing work (Zhang et al., 2023d; Lin et al., 2020;\nZhang et al., 2023b; 2024a), we adopt two popular settings across four enduring datasets Ci-\nfar10 (Krizhevsky & Geoffrey, 2009), Cifar100 (Krizhevsky & Geoffrey, 2009), Flowers102 (Nils-\nback & Zisserman, 2008), and Tiny-ImageNet (Chrabaszcz et al., 2017). Concretely, we simulate\npathological data heterogeneity settings by allocating sub-datasets with 2/10/10/20 classes of data\nfrom Cifar10/Cifar100/Flowers102/Tiny-ImageNet to each client. In Dirichlet data heterogeneity\nsettings, we allocate the data of class $y$ to each client using a client-specific ratio $q_i^y$ from a given\ndataset. $q_i^y$ is sampled from a Dirichlet distribution with a control parameter $\u03b2$ as described in (Lin\net al., 2020). By default, we set $\u03b2 = 0.1$ for Cifar10 and Cifar100, and $\u03b2 = 0.01$ for Flowers102\nand Tiny-ImageNet to enhance setting diversity. In both the pathological and Dirichlet settings, the\ndata quantity among clients varies to account for unbalanced scenarios.\nModel heterogeneity settings. To neatly denote model heterogeneity settings, we utilize the\nnotation HtFEx following the convention in (Zhang et al., 2024b) to represent a group of heteroge-\nneous feature extractors, where X denotes the degree of model heterogeneity (positive correlation),\nwhile the remaining classifier heads remain homogeneous. For example, HtFE8 denotes a group\nof eight heterogeneous feature extractors from eight model architectures (4-layer CNN (McMahan\net al., 2017), GoogleNet (Szegedy et al., 2015), MobileNet_v2 (Sandler et al., 2018), ResNet18,\nResNet34, ResNet50, ResNet101, and ResNet152 (He et al., 2016)), respectively. In addition, we\nuse the notation HtMx to denote a group of fully heterogeneous models. Within a specific group,\nfor instance, HtFEx, we allocate the $(i \\mod X)$th model in this group to client $i$ with reinitialized\nparameters. Given the popularity of all models within HtFE8 in the FL field, our primary focus is on\nutilizing HtFE8. Additionally, some baseline methods, such as LG-FedAvg and FedGH, assume the\nclassifier heads to be homogeneous, making HtMx inapplicable for them. Moreover, to meet the\nprerequisite of identical feature dimensions (K) for FedGH, FedKD, and FedProto, we incorporate\nan average pooling layer (Szegedy et al., 2015) before the classifier heads and set K = 512 for all\nmodels.\nOther necessary settings. Following common practice (McMahan et al., 2017), we execute a\ncomplete local training epoch with a batch size of 10, i.e., [1] update steps, during each communi-\ncation iteration. We conduct each experiment for up to 1000 iterations across three trials, employing\na client learning rate ($\\eta_c$) of 0.01, and present the best results with error bars. Moreover, we examine\nfull participation ($p = 1$), for 20 clients, while setting partial participation ($p = 0.5$) for scenarios\ninvolving 50 and 100 clients. Please refer to the Appendix A for more details and results."}, {"title": "4.1 ACCURACY IN TWO DATA HETEROGENEITY SETTINGS", "content": null}, {"title": "4.2 ACCURACY IN ADDITIONAL FIVE MODEL HETEROGENEITY SETTINGS", "content": null}, {"title": "4.3 ACCURACY WITH MORE CLIENTS OR MORE LOCAL TRAINING EPOCHS", "content": "More Clients. In addition to experimenting with a total of 20 clients, we extend our evaluation by\nincorporating more clients created using the given Cifar100 dataset. With an increase in the number\nof clients, maintaining a consistent total data amount across all clients results in less local data on\neach client. In these scenarios, with a partial client participation ratio of $p = 0.5$, our FedL2G-1\nand FedL2G-f can still maintain their superiority, as shown in Tab. 2.\nMore Local Training Epochs. Increasing the number of local epochs, denoted by"}]}