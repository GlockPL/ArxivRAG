{"title": "FLAG: Financial Long Document Classification via\nAMR-based GNN", "authors": ["Bolun (Namir) Xia", "Mohammed J. Zaki", "Aparna Gupta"], "abstract": "The advent of large language models (LLMs) has\ninitiated much research into their various financial applications.\nHowever, in applying LLMs on long documents, semantic rela-\ntions are not explicitly incorporated, and a full or arbitrarily\nsparse attention operation is employed. In recent years, progress\nhas been made in Abstract Meaning Representation (AMR),\nwhich is a graph-based representation of text to preserve its\nsemantic relations. Since AMR can represent semantic relation-\nships at a deeper level, it can be beneficially utilized by graph\nneural networks (GNNs) for constructing effective document-level\ngraph representations built upon LLM embeddings to predict\ntarget metrics in the financial domain. We propose FLAG:\nFinancial Long document classification via AMR-based GNN,\nan AMR graph based framework to generate document-level\nembeddings for long financial document classification. We con-\nstruct document-level graphs from sentence-level AMR graphs,\nendow them with specialized LLM word embeddings in the\nfinancial domain, apply a deep learning mechanism that utilizes\na GNN, and examine the efficacy of our AMR-based approach\nin predicting labeled target data from long financial documents.\nExtensive experiments are conducted on a dataset of quarterly\nearnings calls transcripts of companies in various sectors of the\neconomy, as well as on a corpus of more recent earnings calls of\ncompanies in the S&P 1500 Composite Index. We find that our\nAMR-based approach outperforms fine-tuning LLMs directly on\ntext in predicting stock price movement trends at different time\nhorizons in both datasets. Our work also outperforms previous\nwork utilizing document graphs and GNNs for text classification.", "sections": [{"title": "I. INTRODUCTION", "content": "Textual data is an important qualitative source of informa-\ntion in the financial domain. Financial reports can provide\nvaluable signals for a firm's future performance, since these\nreports usually contain forward-looking plans and strategies,\nwhich may not be fully captured in their financial statements.\nSince textual data provides greater insights into firm perfor-\nmance, various methods have been utilized for transforming\nthese textual reports into numerical representations, in order\nto define effective features for predicting target variables such\nas temporal price trends, that are of value to investors.\nDespite the progress that has been made in recent years,\nespecially in the sphere of language models (LMs), there\nstill remains the challenge of long documents whose lengths\nusually exceed the maximum context length of LMs. Even\nwith longer context LLM, learning good representations of\ndocuments is still quite difficult; a recent benchmark work on\nQ&A tasks in the financial domain demonstrated that even big\nLLMs such as [1] have difficulties in answering questions cor-\nrectly based on specific corpora of financial documents [2]. In\naddition, with transformer-based methods, semantic relations\nbetween word entities are usually constructed arbitrarily, either\nwith full attention where each word attends to every other\nword, or sparse attention, where attentions between words\nare set up arbitrarily, such as sliding window attention or\nrandomized attention.\nWe propose Financial Long document classfication via\nAMR-based GNNS (FLAG), that learns effective document-\nlevel embeddings based on specialized LM word embeddings\nin the finance domain through AMR [3], which is a graph\nrepresentation of text that preserves semantic relations. The\nunique feature of AMR graphs is that they are abstracted rep-\nresentations of text capable of capturing the semantic meaning\nof sentences, rather than just verbatim word sequences. Hence,\nwords, phrases and sentences that have the same meaning, but\ndiffer in wording or spelling, usually result in the same AMR\nrepresentation. As such, AMR is more semantically detailed\nand represents deeper meaningful relations between semantic\nconcepts."}, {"title": "II. RELATED WORKS", "content": "In processing documents, traditional approaches for feature\nidentification generate static embeddings that do not contain\ncontextual information. Methods such as Term Frequency - In-\nverse Document Frequency (TF-IDF) [9], word2vec [10], and\nGloVe [11] belong in this category. They generate numerical\nvector representations that contain some semantic information,\nbut strictly speaking, are not contextual embeddings. Recent\napproaches construct contextual embeddings that represent\na word in view of its context. LMs, such as BERT [12]\nand GPT [1] belong in this category. These approaches can\nlearn different representations for a word according to its\nsounding context. The challenge with LMs, however, for\nusing them on long financial documents, such as corporate\nearnings call transcripts, is the difficulty to extract document-\nlevel features, since the maximum number of word tokens\nthese transformer LMs can handle is limited, and even if\nthey can handle longer context windows, getting effective\ndocument-level representations still poses a big challenge.\nOn the semantic graph side, to our knowledge, AMR-\nbased approaches have not been applied for long financial\ndocument classification tasks, such as earnings calls that can\nexceed 7,000 words in length. However, there have been\nseveral methods in different domains that utilize AMR for\ntextual analysis. For example, researchers have used it for\ntext classification [13], event detection [14], profanity and\ntoxic content detection [15], paraphrasability prediction and\nparaphrase generation [16], and machine translation [17]. All\nof these utilize only sentence-level AMR, which is unsuitable\nfor our purpose.\nMethods for AMR parsing, which is the process of trans-\nforming text into AMR graphs, are well-studied. Transition-\nbased parsers, such as [18] and [19], provide SOTA sentence-\nlevel results, and AMR aligners, such as [20], provide reliable\nAMR-to-text alignments that link each node entity to its corre-\nsponding word in the original sentence. There have also been\nrecent works on parsing multi-sentence AMRs to preserve\ncross-sentence information. O'Gorman et al. [21] provided a\ncorpus of annotated multi-sentence AMRs, which was used by\nNaseem et al. [22] to implement a new approach to construct-\ning multi-sentence or document-level AMR representations.\nSince their approach is still limited to short documents (e.g.,\naveraging about 429 words per document), it is unsuitable for\nour purpose. Instead, we transform the AMR graphs into a\ndocument-level graph specially designed for long documents.\nAs for utilizing document graphs and GNNs to perform\ngraph learning for text classification in the finance domain,\nMedya et al. [23] designed and implemented StockGNN,\nwhich constructs document graphs based on the contextual\nwindow of each unique word in the document, applies a\nGated GNN [24] on the document graphs, and concatenates the\nfinal embeddings of the document graphs with their respective\ndoc2vec [25] embeddings to generate the final document\nrepresentation for text classification. They collected a corpus\nof general domain earnings calls from several sectors of the\neconomy and predicted the financial impact of earnings calls\non stock price using StockGNN. We use StockGNN as a\nbaseline in our experiments. Importantly, StockGNN graphs\nare localized context graphs, and do not model semantics as\nwe do via AMR."}, {"title": "III. THE FLAG APPROACH", "content": "FLAG is an AMR-based GNN graph learning framework,\nbased on LM embeddings for long financial document clas-\nsification. For each document, we parse all its sentences into\nAMR graphs, and construct a document-level AMR graph hier-\narchically with a sentence virtual node for every sentence and\na document-level node to represent the document. We initialize\neach node with the word embedding of its corresponding word,\ngenerated from contextual LMs. Next, we apply a GNN model\nto generate the final document representations by taking the\ndocument virtual node embeddings. As such, our approach\ncan be split into three phases: (1) Sentence AMR Parsing,\n(2) Document-level Graph Construction, and (3) GNN Model\nTraining and Fine-Tuning, with the architecture illustrated in\nFigure 2. Each of the phases is discussed next."}, {"title": "A. Sentence AMR Parsing", "content": "In a corpus consisting of N documents, $L$\n$=\\{d_1,d_2,...,d_N\\}$, let $d_i$ represent the i-th document of the\ncorpus. For a document $d_i$, we first sentencize the document"}, {"title": "B. Document-level Graph Construction", "content": "Figure 3 shows our document-level graph construction. For\n$d_i$, we have a sequence of sentence AMR graphs $SG_i$ =\n$\\{sg_1,sg_2,\u2026\u2026,sg_{m_i}\\}$. For each sentence graph in $SG_i$, we\nmake a virtual sentence node that connects to all the nodes\nin the sentence graph, culminating in a consecutive sequence\nof virtual sentence nodes $SN_i = \\{sn_1, sn_2,\u2026, sn_{m_i}\\}$, and\nthen we connect these sentence virtual nodes in a consecutive\nmanner, such that $sn_1$ is connected to $sn_2$, $sn_2$ is connected\nto $sn_3$, and so on, both forming a hierarchical representation\nof each sentence and preserving the order of sentences in the\ndocument. In turn, each sentence node in $SN_i$ is connected\nto a virtual document node $dn_i$, representing $d_i$. Overall, all\nthe original nodes and edges in $SG_i$, all the virtual sentence\nnodes and their edges in $SN_i$, and the virtual document node\n$dn_i$ and its edges, form the graph structure $g_i$ for document\n$d_i$. We make every edge of the graph bidirectional, so that\ninformation can flow both ways during model training.\nAfter constructing the graphs, we initialize the nodes with\nembeddings of their corresponding words in the original text,\ngenerated from the base LM method. We are able to do\nso, because the transition AMR parser [20] provides us with\nalignment between node entities in the sentence AMR graphs\nin $SG_i$ and their corresponding words in the original text of\nthe sentences.\nThe LM method that we chose is FinBERT [5], a spe-\ncialized LM in the finance domain which generates token\nembeddings of size 768. We initialize the non-virtual nodes\nin our document-level graphs with the word embeddings of\nthe original word in the sentence that they are aligned with.\nWe pass each sentence of the document through the LM. A\nword's embedding is the average of the sum of the last 4\nhidden state embeddings for each of the sub-tokens. Through\nthis process, each non-virtual node in $g_i$ is initialized with\nword embeddings of size 768. All virtual nodes, $dn_i$ and all\nthe nodes in $SN_i$, are initialized as zero vectors."}, {"title": "C. GNN Model Training and Fine-Tuning", "content": "Given document-level graphs constructed for every doc-\nment in the corpus L, forming a collection of graphs,\n$G_L = \\{g_1,g_2,\u2026\u2026,g_N\\}$, we apply an initial MLP layer on\nthe graph features to transform the original node embedding\ndimension of 768 into another hidden dimension. We then\ntrain a GNN model on the transformed graphs, specifically,\nGATv2 [6], an attention-based GNN model which has been\ntheoretically proven to achieve dynamic attention. Afterwards,\nwe take the embedding vector of the virtual document node\n$dn_i$ as the document representation for the graph $g_i$, denoted\n$h_i$. We then use a linear layer:\n$x_i = W_1h_i + b_1,$\nfollowed by another linear layer that outputs the final predicted\none-hot label, $\u0177_i$, after a softmax.\n$\u0177_i = softmax(W_2x_i + b_2)$\nFinally, we use the cross entropy loss, $L = -\\sum_k y_k log(\u0177_k)$,\nwhere $y_k$ is the k-th element of the predicted label, and $\u0177_k$ is\nthe k-th element of the target one-hot label."}, {"title": "IV. EMPIRICAL EVALUATION", "content": "We now present experimental results to evaluate the efficacy\nof FLAG. We utilized the transition AMR parser [4] with the\nAMR 2.0 structured BART large model pre-trained checkpoint\n20] to perform AMR parsing and alignment, and we used the\nDeep Graph Library (DGL) [27] for graph construction and\ninitialization, as well as for GNN model training.\nFor the hyperparameter tuning for FLAG, we train the\nframework for up to 20 epochs; for LM baselines, we train\nup to 30 epochs; and for StockGNN and related methods, we\ntrain up to 1000 epochs. We vary the learning rate from $10^{-2}$\nto $10^{-6}$, and select the model with the lowest validation error"}, {"title": "A. Dataset and Metrics", "content": "We take corporate earnings call transcript data as the subject\nof our analysis. An earnings call is a conference call between\ncompany executives and the financial community. It is usually\nheld on a quarterly basis following the release of a company's\nearnings report. On this call, the management reviews the\ncompany's performance for a specific period, as well as\npotential risks and future plans, which can cause subsequent\nstock prices to shift dynamically [28].\nTo evaluate FLAG, we compare its performance with base-\nline methods on both the Medya et al. earnings call dataset\n[23], which contains earnings calls from 5 sectors of the\neconomy during period from 2010 to 2019, and a new dataset,\nthe S&P 1500 earnings call corpus, which contains earnings\ncalls of companies from the S&P 1500 Composite Index\nduring the period from 2010 to 2023, that we collected."}, {"title": "Medya Earnings Call Dataset", "content": "The Medya et al. [23] earnings\ncall dataset consists of earnings calls during the 2010 to\n2019 period. It is split into five sectors: finance, health, basic\nmaterials, service, and technology. They used this dataset to\npredict a binary trend label, which they call value-based labels.\nThey define the label function $y_v(T_c)$ for an earnings call\ntranscript $T_c$ of a company c on the day d as follows:\n$\u03c8\u03c5 (\u03a4) =\n\\begin{cases}\n1, & \\text{if } S_{d+1} > S_{d-1}\\\\\n0, & \\text{otherwise},\n\\end{cases}$\nwhere $S_{d+1}$ and $S_{d-1}$ denote the closing stock prices of com-\npany c on the following and previous business day respective\nto day d.\nSince this task is to analyze the trend, it aims to capture the\nimmediate financial impact of an earnings call, so the target is\ndaily and more granular than most financial impact analyses in\nindustry. Moreover, in the real world, financial impact analyses\nin the context of portfolio management or asset pricing involve\nmultiple complex factors, both qualitative and quantitative, and\nthe textual signals from earnings calls only form a fraction of\nall the factors that can affect the stock price trends. Therefore,\nthe purpose of experimenting on this dataset in predicting\nthe daily value-based label is to evaluate the effectiveness of\ndocument representations produced by different methods for\npredicting immediate price movements only from textual data.\nAll the earnings calls during the period of 2010 to 2018\nare used as the training/validation set (with a 80:20 split), and\nall the earnings calls during 2019 are used as the test set, as\nis done by Medya et al. [23]. The detailed data statistics are\nlisted in Table II. As for the document-level graphs constructed\nusing the FLAG approach from earnings calls for the Medya\ndataset, the detailed statistics are shown in Table III."}, {"title": "S&P 1500 Earnings Call Corpus", "content": "The S&P 1500 earnings\ncall corpus dataset we collected contains more recent data,\nand consists of earnings call transcripts from the S&P 1500\nComposite Index for the period 2010 to 2023. It includes\ncompanies from all sectors and represents the overall U.S.\nequity market. Unlike for the Medya dataset, we use this\ndataset to predict weekly value-based labels. For this dataset,\nwe define the label function $y_v(T_c)$ for an earnings call\ntranscript $T_c$ of a company c on day d as follows:\n$y_v (T_c) =\n\\begin{cases}\n1, & \\text{if } \\sum_{i=1}^{5} S_{d+i} >= \\sum_{i=1}^{5} S_{d-i} \\\\\n0, & \\text{otherwise},\n\\end{cases}$"}, {"title": "B. Methods", "content": "We describe the baselines and FLAG used in our experi-\nments."}, {"title": "Results on the Medya Dataset", "content": "Table VI shows the detailed\nresults of our comprehensive experiment across all 5 sectors in\nthe Medya et al. earnings calls dataset. As we can see, FLAG\noutperforms both FinBERT and StockGNN across all sectors\nof the economy. However, there are different degrees to how\nwell FLAG performs in different sectors. Especially compared\nto the FinBERT baseline, we see the smallest improvement\nin performance in the financial sector. Overall, the highest\nabsolute performance is in the technology sector. Therefore,\nin the spirit of fintech, we take the financial sector and the\ntechnnology sector as subjects of analyses in both the ablation\nstudies and the case study below.\nWith regards to FinBERT, FLAG is able to achieve signif-\nicant performance gains over directly applying the domain-\nspecific LM. Especially in the service and technology sectors,\nwe see very high performance gains with FLAG (e.g., 26.2%\ngain for service), and in the financial sector, it outperforms\nFinBERT, however by a lesser margin (7.8% gain). We find\nthe same trend for performance using StockGNN. The im-\nprovement in the service and technology sector is generally\nhigher than in the other sectors. We posit that this trend is due\nto the differences in the nature of earnings calls in different\nsectors of the economy and how the stock market reacts to an\nearnings call event in each particular sector, which we analyze\nin the case study below.\nEarnings calls have an immediate financial impact on stock\nprices, and through this set of experiments, we show that\nFLAG is able to capture that better. In other words, as a\nmore semantically meaningful approach, it is able to achieve"}, {"title": "Results on S&P 1500 Dataset", "content": "Table VII shows the ex-\nperiment results on the S&P 1500 dataset, in the context of\npredicting weekly average price trends. Once again, FLAG\nperforms better in predicting longer-term price trend metrics\nat the weekly granularity when compared with FinBERT and\nStockGNN, with the graph-based approach of StockGNN per-\nforming better than FinBERT. This corpus consists of earnings\ncalls from all sectors in the U.S. equity market, as represented\nin the index. As such, the absolute performance gains of FLAG\non this corpus are lower compared to the sector-specific Medya\nearnings call dataset, albeit the target metric scope is different:\nthe latter is on a daily granularity. Overall, the results show\nthat not only are there indications for weekly stock price trends\ncontained in the soft information of the earnings calls, but\nthat FLAG is able to extract this better with its semantically\nmeaningful graph representations of documents, even across\nvarious different sectors of the economy."}, {"title": "D. Ablation Studies", "content": "a) Efficacy of AMR document-level graphs: a comparison\nbetween StockGNN and Gated GNN on FLAG graphs: As\nFLAG and StockGNN utilize different GNNs, with FLAG\nusing GATv2 and StockGNN using Gated GNN, it is of\ninterest to evaluate the performance of document graphs\nconstructed with FLAG versus document graphs constructed\nwith StockGNN. Therefore, we apply the same configurations\nof GGNN that StockGNN uses, but on the documents graphs\nconstructed with FLAG, and compare its performance against\nStockGNN generated graphs, on the financial and technology\nsectors of the Medya dataset. We ran StockGNN for 100\nepochs and GGNN on FLAG graphs for 50 epochs.\nFor both the sectors, there is value added in using FLAG-\nbased document graphs, even without using an attention-based\nGNN, such as GATv2. We see the same performance trends as\nthe main experiments conducted on the Medya dataset, where\nthe performance improvement is less for the financial sector,\ncompared to the technology sector. We delve a bit into why\nthis may be the case in the case study below."}, {"title": "b) Efficacy of attention-based GATv2: a comparison of\ndifferent GNNs applied on FLAG graphs", "content": "Coupling dynamic\nattention offered by GATv2 with the structure of FLAG-based\ndocument graphs is an important aspect of the FLAG method-\nology and has been shown to achieve superior performance. On\naccount of the large size of the document graphs produced by\nFLAG, as shown in the dataset metrics in Section IV-A, graph\ntransformers cannot be applied on FLAG graphs. However,\nthere are other graph convolution networks that can be applied\nto FLAG graphs, including conventional GCN, PNA [29],\nGAT [30], which does not have dynamic attention, and Gated\nGNN [24] (also compared above). We experiment with these\nGNNs and present the results in Table IX. We find that GATV2\ncoupled with FLAG graphs offers an edge in performance that\nother non-attention-based GNNs or GNNs without dynamic\nattention cannot match. Also interesting is that the GCN model\nalso outperforms GGNN and PNA on the earnings call graphs."}, {"title": "c) Various configurations of GATv2: number of layers,\nattention heads, and different hidden dimensions", "content": "GATv2 is\na GNN that has many possible configurations, including the\nnumber of layers and attention heads, and different hidden\ndimensions of transformed input graphs (in FLAG). In our\nablations, we experimented with the number of layers ranging\nfrom 1 to 6, the number of attention heads varying from 4, 8,\nand 12, and hidden dimensions of 256, 512, and 768. Table X\nshows the effect on the performance of frameworks with\ndifferent numbers of GATv2 layers, as we vary the attention\nheads and the hidden dimensions. Results are shown for the\ncase when the projected dimensionality for the attention is\nfixed as 64, be it 64 = 256/4, or 64 = 512/8, or 64 = 768/12.\nWe find that the configuration with 4 layers, with 8 attention\nheads each, and a hidden dimension of 512 has consistently\nbetter performance across sectors, and that is chosen as the\ndefault configuration for FLAG."}, {"title": "E. Case Study", "content": "As we have seen in the experiment results, FLAG achieves\nhigher performance gains in sectors such as technology, but\nnot as much in sectors like the financial sector. We posited\nthat the stock market reacts differently to earnings calls in the\nfinancial sector versus the technology sector. To investigate\nthis further, we applied the GNNexplainer [31] method to\nthe document on which FLAG performed the worst in the\nfinancial sector (for Cushman & Wakefield, Q2, 2019) and on\nthe document that FLAG performed the best in the technology\nsector (for Paycom, Q1, 2019), in terms of cross-entropy loss.\nWe trained GNNexplainer with 3 hops for 1000 epochs, and\ngenerated the edge mask. This shows, in numerical terms,\nwhich edges in the FLAG graph are determined to be important\nin making the prediction. We then looked at all the edges\ngoing into the document virtual node from sentence virtual\nnodes, and examined the important edges to extract the top\nsentences that were considered to be more important for\nthe final classification. Table XI shows some example top\nsentences from the two documents.\nIn the case of Cushman & Wakefield, the actual stock\nprice went down, but FLAG predicted that it would go up.\nLooking at the top sentences, we can see why it made such\na prediction, as the earnings call speaks about growth in\nthe past and how they expect the growth to continue in the\nfuture. However, it would seem that the market did not believe\nCushman & Wakefield projections, and the stock price actually\nwent down as a result. In the case of Paycom, the stock price\nwent up, and FLAG predicted correctly that it would go up.\nFrom the top sentences FLAG identified, we see the company\nspeaking optimistically about its growth and a new system that\nemployees are using more and more, which the market reacted\npositively to, leading to an uptick in stock price.\nAlbeit only one representative case study, it suggests a\npotential trend where the market does not \u201cbelieve\u201d firms in\nthe financial sector on the face value of statement made in\nearnings calls as much as they do firms in other sectors, such\nas the technology sector, where companies deal with more\ntangible assets. This warrants examining more on the broader\ncharacteristics of earnings calls in different sectors and how\nmarket reacts to them differently, and we plan to conduct this\nanalysis in our future work."}, {"title": "V. CONCLUSION AND FUTURE WORKS", "content": "This work presents the first use of AMR-based graphs in a\npredictive framework for long document classification tasks,\nsuch as financial trend prediction. As demonstrated by the ex-\nperiments, in predicting both immediate and longer-term price\ntrends based on textual signals from earnings calls, FLAG with\nunderlying FinBERT-generated embeddings is able to show\nSOTA performance against both LM and previous baselines.\nTherefore, our next step is to endow FLAG with embeddings\nextrapolated from more advanced LLMs such as FinGPT\n[8]. However, since unlike FinBERT, which is an encoder-\ndecoder model, FinGPT is a decoder and causal model, it will\nrequire some modifications to generate contextually informed\nembeddings.\nWe have also seen the performance of FLAG varying from\nsector to sector, which warrants further analysis into the\ncharacteristics of earnings calls in different sectors and their\ninteractions with the market. Specifically, we plan to identify\nparts of documents that the model considers as important to\nits prediction, leveraging the explainability offered by semantic\ndocument graphs and attention-based GNNs in the FLAG deep\nlearning framework, in order to find particular patterns and\nscenarios in which correct or incorrect predictions are made,\nboth in specific sectors and across all sectors.\nMoreover, in the real-world use case scenario of price\ntrend analysis, financial analysts generate numerical predic-\ntions from an aggregation of a variety of factors, and not\nonly from textual signals. Therefore, we want to use FLAG\nto generate more complex qualitative insights from textual\nsignals that analysts cannot get directly from the data at hand.\nTo achieve this, we need to develop a retrieval methodology\nthat works on document-level graphs instead of on blocks\nof text, which would enable generative models to leverage\nFLAG for better semantically informed insights. We also need\nfurther discussions and collaborations with stakeholders in the\nfinancial industry to identify which types of qualitative insights\nare of value."}]}