{"title": "Boosting Generalization in Diffusion-Based Neural Combinatorial Solver via Energy-guided Sampling", "authors": ["Haoyu LEI", "Kaiwen Zhou", "Yinchuan Li", "Zhitang Chen", "Farzan Farnia"], "abstract": "Diffusion-based Neural Combinatorial Optimization (NCO) has demonstrated effectiveness in solving NP-complete (NPC) problems by learning discrete diffusion models for solution generation, eliminating hand-crafted domain knowledge. Despite their success, existing NCO methods face significant challenges in both cross-scale and cross-problem generalization, and high training costs compared to traditional solvers. While recent studies have introduced training-free guidance approaches that leverage pre-defined guidance functions for zero-shot conditional generation, such methodologies have not been extensively explored in combinatorial optimization. To bridge this gap, we propose a general energy-guided sampling framework during inference time that enhances both the cross-scale and cross-problem generalization capabilities of diffusion-based NCO solvers without requiring additional training. We provide theoretical analysis that helps understanding the cross-problem transfer capability. Our experimental results demonstrate that a diffusion solver, trained exclusively on the Traveling Salesman Problem (TSP), can achieve competitive zero-shot solution generation on TSP variants, such as Prize Collecting TSP (PCTSP) and the Orienteering Problem (OP), through energy-guided sampling across different problem scales.", "sections": [{"title": "1 Introduction", "content": "Combinatorial optimization (CO) problems are fundamental challenges across numerous domains, from logistics and supply chain management to network design and resource allocation. While traditional exact solvers and heuristic methods have been widely studied, they often struggle with scalability and require significant domain expertise to design problem-specific algorithms [1,2].\nRecent advances in deep learning have sparked interest in Neural Combinatorial Optimization (NCO), which aims to learn reusable solving strategies directly from data, eliminating the need for hand-crafted heuristics [3]. Among various deep learning approaches, diffusion-based models [4,5] have emerged as a particularly promising direction for solving combinatorial optimization problems. These models have demonstrated remarkable capabilities in learning complex solution distributions by adapting discrete diffusion processes to graph structures. Recent works like [6,7] have achieved state-of-the-art performance on classical problems such as the Traveling Salesman Problem (TSP), showcasing the potential of diffusion-based approaches in combinatorial optimization.\nHowever, the practical applicability of existing NCO approaches is limited by several generalization challenges. First, current models suffer from cross-scale generalization, with performance degrading significantly when applied to larger problem instances than those seen during training, especially for auto-regression-based solvers [8,9] including transformer and reinforcement learning methods. Second, these models show limited cross-problem transfer capabilities, struggling to adapt to problem variants with modified objectives or additional constraints. While several studies have attempted to enhance learning-based solvers' generalization"}, {"title": "2 Related Works", "content": "Neural Network-based Combinatorial Solvers. Neural Combinatorial Optimization (NCO) approaches focus on leveraging neural networks to learn feasible solution distributions for combinatorial optimization problems [3,16]. Autoregressive construction solvers [8,9,17\u201319] are built upon the success of transformer-based [20] and reinforcement learning architectures in sequential generation tasks. However, non-autoregressive construction solvers [6, 10, 21\u201324] have also been proposed to learn high-quality solution distributions.\nDiffusion-based Generative Modeling. Recent advances in generative modeling have revolutionized"}, {"title": "3 Preliminaries", "content": "3.1 Variants of the Traveling Salesman Problem\n\u2022 Traveling Salesman Problem (TSP) requires finding the minimal-length Hamiltonian cycle in a complete graph, where the salesman must visit each city exactly once before returning to the starting point.\n\u2022 Prize Collecting TSP (PCTSP) [33] extends the classical TSP by introducing node-specific prizes and penalties. The objective is to optimize a trade-off between minimizing tour length and unvisited node penalties while ensuring collected prizes exceed a predefined threshold. This formulation creates a more complex optimization landscape where node visitation decisions must balance multiple competing factors.\n\u2022 The Orienteering Problem (OP), first introduced by [34], is a fundamental combinatorial optimization problem with widespread applications in real-world scenarios. In the OP, each node in the network is associated with a non-negative prize value, and the objective is to determine an optimal tour that begins and ends at a designated depot node. The tour must satisfy two key constraints: maximize the total collected prizes from the visited nodes, and ensure the total tour length does not exceed a predetermined distance limit. This problem effectively captures the trade-off between reward collection and resource constraints.\n3.2 Graph-based CO Problems\nCombinatorial optimization (CO) problems on graphs are fundamental to numerous real-world applications. Following recent advances [6,7], we address these problems by formalizing graph-based CO instances as follows.\nWe represent each problem instance as an undirected graph G(V, E) \u2208 G, where V and E denote the vertex and edge sets, respectively. This representation encompasses both vertex selection and edge selection problems, covering a broad spectrum of practical CO scenarios. For any instance G\u2208 G, we define a binary decision variable x \u2208 Xg, where X\u00e7 = {0,1} represents the feasible solution space. The optimization objective is to"}, {"title": null, "content": "find the optimal solution x* that minimizes a problem-specific objective function f(\u00b7; G) : {0,1}N \u2192 R:\nx* = argmin f(x; G), (1)\nXEXG\nwhere the objective function decomposes into:\nf(x; G) = fcost (x; G) + \u03b2\u00b7 fvalid (x; G). (2)\nHere fcost(; G) measures the solution quality, and fvalid(; G) enforces problem-specific constraints through a penalty coefficient \u03b2 > 0. The validity function returns 0 for feasible solutions and is strictly positive for infeasible ones.\nAs a concrete example, consider the classical Traveling Salesman Problem (TSP): given a complete graph G with edge weights, the objective is to find a minimum-weight Hamiltonian cycle. The decision variable x \u2208 {0,1} encodes edge selections, where fcost(\u00b7; G) measures the total tour length and fvalid(\u00b7; G) ensures the solution forms a valid Hamiltonian cycle following [6]. For the Prize Collecting TSP (PCTSP) that we considered, each vertex has a prize ri > 0 and penalty pi > 0. fcost(\u00b7; G) measures the difference between total tour length and uncollected penalties, while fvalid (; G) ensures the total prizes are greater than the constraint and the solution forms a valid Hamiltonian cycle. For the Orienteering Problem (OP), fcost aims to maximize the total collected scores from visited nodes, while fvalid(; G) ensures both tour connectivity and the total length within the given budget."}, {"title": "3.3 Probabilistic Modeling for CO", "content": "To leverage recent advances in deep generative models, we reformulate the CO objective through an energy-based perspective [35]. Specifically, we establish an energy function E(\u00b7;G) := |y \u2212 f(-; G)| that maps each solution to its corresponding energy state. This energy-based formulation naturally leads to a probabilistic framework through the Boltzmann distribution [36]:\np(yx; G) =\nexp ( \u2013 (y, x; G))\nZ\nwhere Z = \\sum_x exp(-=-=(y, x; G)), (3)\nwhere controls the temperature of the system and Z denotes the partition function that normalizes the distribution.\nRecent works have demonstrated promising approaches to approximate this distribution using diffusion-based deep generative models by parameterizing a conditional distribution po(x|G) to minimize the energy function. Both supervised [6,7] and unsupervised [24] learning paradigms have shown significant advances. Since our proposed training-free guidance mechanism is applicable to any pre-trained diffusion-based solver, we focus on the supervised learning framework in this work for ease of presentation.\nGiven a training set G = {Gi}=1 of i.i.d. problem instances with their optimal solutions x and the corresponding optimal objective values y, we optimize the model parameters @ by maximizing the likelihood of the optimal solutions\nL(0) = EG~g[-log po (x|y, G)]. (4)"}, {"title": "4 Theoretical Results", "content": "4.1 Discrete Diffusion Generation Modeling\nWe adopt a discrete diffusion framework [31] to effectively sample optimal solutions from the learned distribution pe (x|y*, G). In contrast to continuous diffusion models that employ Gaussian noise, our discrete formulation is particularly well-suited for graph-based combinatorial optimization problems [6, 7].\nThe diffusion process consists of two key components: a forward process that gradually corrupts the data, and a reverse process that learns to reconstruct the original distribution. The forward process"}, {"title": null, "content": "q(\u04251:\u0442 \u0445\u043e) = \u03a0=1q(xt|xt\u22121) maps clean data xo ~ q(x0|G) to a sequence of increasingly corrupted latent\nvariables x1:7. The reverse process po(xo:T|G) = p(x\u0442) \u041f=1 Po(xt-1|xt, G) learns to gradually denoise these\nlatent variables to recover the original distribution. From a variational perspective, we optimize the model by\nminimizing an upper bound on the negative log-likelihood, where C is a constant:\nL(0) = EGG[-log pe (xo|G)]\nT\n\u2264\u2211Eq(x|xo)|[DKLq(xt-1|X1, X20)||po(Xt-1|Xt; G)] - log po (X0X1, G) G)] + C.\nt=2\nFor discrete state spaces, we define the forward process using a categorical distribution:\nq(xtxt-1) = Cat(xt; p = xt\u22121Qt), (5)\nwhere xt \u2208 {0,1}N\u00d72 represents the one-hot encoding of x\u0165 \u2208 {0,1}N. The forward transition matrix Qt is\ndefined as:\nQ = [(13\u03b2\u03b9) (128), \u03b2\u03b5\u20ac [0, 1], (6)\nwhere [Qt]ij denotes the state transition probability from state i to state j. The t-step marginal distribution\nand posterior can be derived as:\nq(xtx0) = Cat(xt; p = X0Qt),\nq(xt-1 Xt, X0)\n=\nCat (Xt-1; P =\nX+QXoQt-1\nXtQX)\nwhere Qt = Q1 Q2 ... Qt and denotes element-wise multiplication.\nTo capture the structural properties of CO problems, we employ an anisotropic graph neural network\narchitecture [21]. For a given instance G, the network learns to predict the clean data distribution po(X0xt, G).\nTaking TSP as an example, where G encodes the 2D Euclidean coordinates of vertices, the network outputs a\nprobability matrix po(X0xt, G) \u2208 [0,1]N\u00d72. This matrix parameterizes N independent Bernoulli distributions,\neach corresponding to a binary decision variable in 0. The reverse process during sampling follows:\nPo(xt-1/xt, G) = \\sum_x q(xt-1|Xt, xo)Po (Xoxt, G). (7)\n4.2 Energy-guided Sampling for Problem Transfer\nWhile training-free guidance has been extensively studied in computer vision [12-15], its application to combinatorial optimization problems has only recently emerged [7]. We firstly extend this approach by introducing energy-based training-free guidance for new problem instances during inference, enabling flexible incorporation of additional constraints into pre-trained diffusion-based CO solvers and enhancing their cross-problem generalization capabilities.\nLet G' = {G}=1 denote a set of test instances representing variants of the original training problems, such as problems with additional constraints or multiple objectives. For a new instance G' with its optimal solution pair (x, y), we need to estimate the new reverse process po(Xt-1xt, y, G') according to (7). Following the score estimation perspective of diffusion processes [5], we decompose the conditional score function at time step t into two components:\n\u2207xt log pe (xt|y\u011c', G') = \u221ax+ log pe (xt|G') +\u2207xt log pt(y\u011c'|xt, G'). (8)\nposterior score\npre-trained prior score\nenergy-guided score"}, {"title": null, "content": "From the Bayesian perspective, po(xt|G') can be understood as the prior, which contains knowledge of the pre-trained problems (i.e. TSP problem in our experimental settings), and pt(y, xt, G') corresponds to the guided likelihood that incorporates additional constraints or objectives of the variant problem. We sample from the posterior po(xt|y\u0131, G') to generate high-quality solutions to the variant of the original training problems.\nDrawing upon this theoretical framework, we leverage the pre-trained diffusion model to estimate the first term x log po (xt|G'). In the context of cross-problem transfer, while the pre-trained model yields only a biased score function for new problem instances, we analyze their underlying connection for TSP variants in the subsequent subsection.\nMeanwhile, we compute the second energy-guided term \u2207x, log pt (y, xt, G') using an energy function that specifically accounts for the additional objectives and constraints of the variant problem:\n\u2207x, log Pt (YGxt, G') x \u2212\u2207x+E(y1, X0 (xt); G'), (9)\nwhere E(y, xt; G') = |y\u011c, \u2212 f(xo(xt); G')| measures the energy between the optimal value and the predicted solution. Here, Xo (xt) represents the predicted clean sample from the current noisy state xt. To overcome this issue, we parameterize the model outputs as the logits of N independent Bernoulli samples, and estimate Xo(xt) = Exo~po(Xo|x+) [X0]. Combining equations (8) and (9), we derive an energy-guided reverse sampling process:\nPo(Xt-1|Xt, YG, G') \u00d7 po(xt\u22121|Xt, G')pt(y\u011c,|x+, G'),\n1\nP(YGxt, G') = exp(-x. f (xo(xt); G'))\n4.3 Analysis of Problem Transfer\nConsider the scenario where we aim to transfer knowledge from the original Traveling Salesman Problem (TSP) to its variants: the Prize Collecting TSP (PCTSP) and the Orienteering Problem (OP). The diffusion model, trained on optimal TSP instances, estimates po(xt|G') such that, under the assumption of perfect optimization, po(x0|G') approximates QTSP (X0|G'), where the latter represents the distribution of ground-truth TSP solutions for instance G'. Through the Bayesian equation established in (8), we expect such a pre-trained prior would substantially enhance posterior sampling solution quality, as TSP shares fundamental structural similarities with PCTSP and OP, thereby encoding relevant domain knowledge. We formalize such similarities in the following analysis. The complete proof is provided in Appendix A.1. We make use of the following definition to facilitate the analysis.\nDefinition 4.1 (Marginal Decrease). For a non-empty subset of nodes S \u2286 V, let TSP(S) denote the cost of the optimal TSP tour visiting all nodes in S. The marginal decrease of a subset S is defined as\nA(S) = TSP(V) \u2013 TSP(V \\ S).\nThe marginal decrease measures the cost reduction of not visiting a subset of nodes S, which helps quantify the difference between the optimal tours. Take PCTSP as an example. If for any non-empty subset of nodes SCV, the penalty of not visiting the nodes in S satisfies \u2211ies pi \u2265 \u2206(S), then PCTSP and TSP share the same optimal tours. Based on this notion, we formalize the structural similarities in the following theorem.\nTheorem 4.2. For a non-empty subset of nodes S \u2286 V, let TSP(S) and argTSP(S) denote the optimal cost and optimal tours of TSP on the subgraph specified by S. Under Assumptions A.2 and A.3, the optimal tours of PCTSP are argTSP(V \\ SPCTSP), where\nSPCTSP \u2208 arg min min Pi \u2013 A(S),\nSCV \u00a1ES\nand the optimal tours of OP are argTSP(V \\ SOP), where\nSOP \u2208 arg min (S), s.t. (S) > TSP(V) \u2013 DOP."}, {"title": "5 Proposed Approach", "content": "Heatmap Generation. Building upon our theoretical analysis of the graph-based discrete diffusion model, we employ it to generate transition matrices for combinatorial optimization problems. To effectively process the input structure, we introduce an anisotropic graph neural network equipped with edge-gating mechanisms [37,38]. This network encodes the input into a state matrix, where each element represents the selection probability pe (x0 = 1|G') of nodes or edges as a heatmap representation. The pre-trained diffusion model then operates by progressively denoising a randomly perturbed graph structure to generate these probability heatmaps, which serve as the foundation for subsequent decoding steps.\nEnergy-guided Cross-problem Sampling. We propose a conditional energy-guided sampling framework that enhances cross-scale and cross-problem generalization without requiring additional training. We leverage DDIM [39] to accelerate the sampling process to 10 or 20 steps. While our initial experiments reveal that single-round sampling with energy function gradients yields suboptimal cross-problem performance, we address this limitation by adopting the rewrite technique from [7]. Specifically, we initialize each round by adding noise to the previous round's best solution and iteratively apply energy-guided sampling (Algo. 1). This iterative process establishes a natural trade-off between solution quality and computational efficiency.\nDecoding and Solution Selection. To construct feasible solutions from the generated heatmaps, we"}, {"title": "6 Numerical Results", "content": "Dataset. We evaluate our approach on the classical NP-complete combinatorial optimization problems: the Traveling Salesman Problem (TSP) together with its variants, the Prize Collecting Traveling Salesman Problem (PCTSP) and Orienteering Problem (OP).\nEvaluation. Following [9], we generate 1000 test instances for each problem scale: 20, 50, and 100, which denotes the node counts for PCTSP and OP. We evaluate model performance using two primary metrics: average solution cost and optimality gap relative to the exact solution. Additionally, we measure computational efficiency through total training time and per-instance inference time.\nBaselines. We compare our approach against multiple baseline categories. For PCTSP, (1) Exact solver: Gurobi; (2) OR-based heuristics: OR-Tools and Iterated Local Search (ILS); (3) Learning-based methods: AM [9], MDAM [41], AM-FT [11], ASP [10]. For OP, (1) Exact solver: Gurobi; (2) OR-based heuristics: Compass [42] and Tsili [43]; (3) Learning-based methods: AM [9], AM-FT [11].\nOur proposed DIF-Trans builds upon DIFUSCO's TSP-trained checkpoints in three different scales without additional training. The results of DIF-Trans are recorded under 50 iterations with greedy decoding strategy. The inference steps are accelerated by DDIM [39] from 1000 training steps to 10 steps. The energy function used in guided sampling follows [35] which provides energy formulation for NP-complete CO problems, see A.2. The guidance temperature A is fixed to be 0.1 and the constraint coefficient \u1e9e is set to be 1.1. All experiments are conducted on a single Tesla V100 GPU.\n6.1 Generalization Results\nFirst, we conduct comprehensive generalization experiments following [10], examining our method's transferability across both problem scales and variants. Our evaluation framework specifically examines: cross-scale generalization, where we assess performance across varying problem scales, and cross-problem generalization, focusing on adaptation to different problem variants. For cross-scale evaluation, we utilize a single model that exhibits optimal performance across all scales, eliminating the need for scale-specific training. Notably, while existing learning-based approaches require problem-specific retraining for PCTSP and OP instances, our DIF-Trans framework operates in a zero-shot generation.\nExperimental results presented in Table 1 and Table 2 demonstrate the superior generalization capabilities of our approach. DIF-Trans achieves competitive average optimality gaps (10.56% for PCTSP and 8.25% for OP) across all problem scales while maintaining zero-shot inference capability. It eliminates the substantial computational overhead (3-5 days for existing methods) and well-labeled training data associated with"}, {"title": "6.2 Ablation Studies", "content": "To validate the effectiveness of our energy-guided sampling framework in cross-problem transfer scenarios, we conduct comprehensive ablation studies while maintaining consistent problem scales. As demonstrated in Table 3, our method achieves significant zero-shot performance improvements when applied to the pre-trained DIFUSCO model on TSP. These improvements are evident across all PCTSP and OP problem scales, manifesting in both enhanced solution quality and reduced optimality gaps compared to traditional OR-based solvers."}, {"title": "7 Conclusions and Limitations", "content": "In this work, we introduced an energy-guided sampling framework enabling zero-shot cross-problem generalization for diffusion-based solvers. Through an energy-based guidance mechanism during inference, our approach successfully transfers pre-trained diffusion models to address TSP variants without requiring additional training. We conducted theoretical analysis in this scenario to deepen our understanding of the problem transfer capability. Extensive experiments on OP and PCTSP demonstrate that our framework achieves competitive performance against existing learning-based methods across various problem scales.\nThis work demonstrates the considerable potential of adapting diffusion-based generative neural solvers to address real-world combinatorial optimization problems, particularly those involving dynamic constraints and objectives. Our approach reduces the computational costs of retraining large-scale neural solvers by providing a flexible, off-the-shelf sampling scheme that enhances generalization capabilities. Nevertheless, several limitations and opportunities for future research consideration still exist. First, while our method exhibits promising results on TSP variants, its applicability to a broader spectrum of combinatorial optimization problems beyond routing domains remains to be validated. Second, the computational complexity introduced by the energy-guided sampling process during inference requires further optimization. Future research directions could focus on extending the framework to diverse combinatorial optimization paradigms and developing more efficient guided-sampling scheme."}, {"title": "Appendix A Appendix", "content": "A.1 Proof of Theorem 4.2\nTo analyze the relation between the optimal solutions of TSP and that of PCTSP/OP, we make use of the following definitions.\nDefinition A.1 (Marginal Decrease). For a non-empty subset of nodes SC V, let TSP(S) denote the cost of the optimal TSP tour visiting all nodes in S. The marginal decrease of a subset S is defined as\n\u2206(S) = TSP(V) \u2013 TSP(V \\ S).\nThe marginal decrease measures the cost reduction of not visiting a subset of nodes S. This concept helps quantify the relation between the optimal solutions of TSP/PCTSP/OP. We first make the following assumptions on the PCTSP and OP problems in the analysis. Note that we make these assumptions just for the simplicity of presentation.\nAssumption A.2 (PCTSP Setting). We consider PCTSP without the minimum prize constraint.\nAssumption A.3 (OP Setting). For OP, we assume an identical reward at each city.\nThe above identical reward assumption can be relaxed by considering a node-weighted TSP, which can be transformed into a standard TSP with some effort. Then, we can apply the following arguments for OP to build a connection with the optimal solutions of standard TSP.\nUnder these assumptions, we compare the optimal solutions of PCTSP/OP with that of TSP as follows. (i) For PCTSP, if for any non-empty subset of nodes S \u2286 V, the penalty of not visiting the nodes in S satisfies\n\u03a3\u03c1\u03b9 \u2265 \u0394(S),\n\u00a1ES\nthen PCTSP and TSP share the same optimal solutions, since not visiting any subset of nodes would result in a higher total cost. We can thus formulate the optimal cost (tour length + penalty) of PCTSP as\nPCTSP(V) =\nTSP(V) + min Pi \u2013 A(S). (10)\nSCV\n\u00a1ES\nAnd we have the optimal solutions of PCTSP being the tours in TSP(V \\ S) with\nSe arg min Epi - A(S),\nSCV \u00a1ES\ncompleting the proof for PCTSP."}, {"title": null, "content": "(ii) For OP, since we assume a uniform reward at each city, the optimization objective becomes visiting as much nodes as possible under the distance limit of the total tour length. This objective is identical to minimizing the travel cost while respecting the budget, because the optimal cost of TSP satisfies the following property:\nFor any non-empty subsets of nodes S, V, if SC V, then TSP(S) < TSP(V).\nWe can thus formulate the optimal tour length of OP as\nOP(V) = max TSP(V \\ S)\nSCV\ns.t. TSP(V \\S) \u2264 DOP\n= TSP(V) + min A(S)\nSCV\ns.t. A(S) > TSP(V) \u2013 DOP,\nwhere Dop is the distance limit of OP. And we have the optimal solutions of OP being the tours in TSP(V\\S) with\nS\u2208 arg min A(S)\nSCV\ns.t. A(S) > TSP(V) \u2013 DOP,\ncompleting the proof for OP.\nA.2 Energy Formulations for TSP Variants\nIn our experimental setup, we employ an anisotropic graph neural network architecture enhanced with edge-gating mechanisms [37,38]. This encoder transforms the input 2D coordinates and TSP variant paths into a binary edge-selection graph. Additional problem-specific information - such as prizes and penalties in PCTSP and prizes in OP - is incorporated into the gradient calculation of the guidance objective function. The constraint coefficients \u1e9e are chosen to be 1.1 in experiments.\nProposition A.4 (Traveling Salesman Problem (TSP)). Given a complete graph G = (V, E) with edge weights w: E \u2192 R+, find x \u2208 {0,1}|E| that minimizes:\nf(x; G) = f cost(x; G) + \u03b2\u00b7 fvalid(x; G)\nwhere fcost(x; G) = \u2211 Wexe\neEE\nProposition A.5 (Prize Collecting TSP (PCTSP)). Given a complete graph G = (V, E) with edge weights w : E \u2192 R+, vertex prizes r: V \u2192 R+, penalties p : V \u2192 R+, and prize threshold R, find x \u2208 {0,1}|E|,\ny \u2208 {0,1}|V| that minimizes:\nf(x,y; G) = fcost(x,y; G) + \u03b2\u00b7 fvalid(x, y; G)\nwhere fcost(x, y; G) = \u2211 Wexe + \u2211 pv (1 - Yv)\neEE\nVEV\nfvalid(x, y; G) = max(0, R \u2013 \u03a3\u03c5\u03b6\u03c5)\nVEV\nProposition A.6 (Orienteering Problem (OP)). Given a complete graph G = (V, E) with edge weights w : E \u2192 R+, vertex scores s : V \u2192 R+, and budget B, find x \u2208 {0,1}|E|, y \u2208 {0,1}|V| that minimizes:\nf(x, y; G) = f cost(x, y; G) + \u03b2\u00b7 fvalid(x, y; G)"}, {"title": null, "content": "where fcost(x, y; G) = \u2013 \u03a3 \u03b4\u03c5\u03c8\u03c5\nVEV\nfvalid(x, y; G) = max(0, \u2211 Wexe \u2013 B)\neEE"}]}