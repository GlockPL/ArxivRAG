{"title": "TriAdaptLoRA: Brain-Inspired Triangular Adaptive\nLow-Rank Adaptation for Parameter-Efficient\nFine-Tuning", "authors": ["Yao Liang", "Yuwei Wang", "Yi Zeng"], "abstract": "The fine-tuning of Large Language Models (LLMs)\nis pivotal for achieving optimal performance across diverse down-\nstream tasks. However, while full fine-tuning delivers superior\nresults, it entails significant computational and resource costs.\nParameter-Efficient Fine-Tuning (PEFT) methods, such as LoRA,\naddress these challenges by reducing the number of trainable pa-\nrameters, but they often struggle with rank adjustment efficiency\nand task-specific adaptability. We propose Triangular Adaptive\nLow-Rank Adaptation (TriAdaptLoRA), a novel PEFT frame-\nwork inspired by neuroscience principles, which dynamically\noptimizes the allocation of trainable parameters. TriAdaptLoRA\nintroduces three key innovations: 1) a triangular split of trans-\nformation matrices into lower and upper triangular components\nto maximize parameter utilization, 2) a parameter importance\nmetric based on normalized Frobenius norms for efficient adap-\ntation, and 3) an adaptive rank-growth strategy governed by\ndynamic thresholds, allowing flexible parameter allocation across\ntraining steps. Experiments conducted on a variety of natural\nlanguage understanding and generation tasks demonstrate that\nTriAdaptLoRA consistently outperforms existing PEFT methods.\nIt achieves superior performance, enhanced stability, and reduced\ncomputational overhead, particularly under linear threshold-\ndriven rank growth. These results highlight its efficacy as a\nscalable and resource-efficient solution for fine-tuning LLMs.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, large language models (LLMs) have\nemerged as foundational tools across a wide spectrum of\ndownstream tasks, delivering exceptional performance and\ndriving both academic and industrial innovation [1]-[3]. Flag-\nship models such as GPT-4 [4] dominate closed-source devel-\nopment, while Llama3 [5] leads progress in the open-source\necosystem. However, training these models from scratch re-\nquires vast computational resources. For example, training\nLlama2 [6] demands approximately 3.3 million GPU hours\non an NVIDIA A100-80GB graphics card, resulting in an\nestimated 539 tons of carbon emissions. Such resource-\nintensive processes underscore the need for more sustainable\nsolutions, especially given the performance gains associated\nwith scaling up LLMs as observed in OpenAI's power-law\nscaling studies [7].\nFine-tuning has become a critical strategy for adapting\npre-trained LLMs to specific tasks [1], [8]\u2013[10]. While full\nfine-tuning provides high performance by updating all model\nparameters, it remains prohibitively expensive in terms of\ncomputational and memory costs, limiting its practical appli-\ncability [11], [12].\nTo address these challenges, PEFT methods have gained\nsignificant attention, with Low-Rank Adaptation (LoRA) [13]\nemerging as one of the most widely adopted approaches.\nLoRA achieves efficiency by freezing the pre-trained model's\nparameters and introducing low-rank matrices for adaptation.\nHowever, LoRA's fixed-rank configuration for all low-rank\nmatrices limits its adaptability and parameter utilization ef-\nficiency.\nEfforts to overcome these limitations have driven the de-\nvelopment of three main categories of LoRA-based improve-\nments:\n\u2022 Structural optimization methods: These include ap-\nproaches like DORA [14], VeRA [15], AFLORA [16], and\nPROLORA [17], which enhance LoRA's structure through\nmechanisms such as matrix decomposition, parameter\nsharing, and gradual freezing, improving parameter ef-\nficiency and performance.\n\u2022 Application-oriented methods: Examples include Lon-\ngLORA [18], QLoRA [19], and LoRA-Flow [20], which\nextend LoRA's applicability to contexts such as long-\ndocument processing, quantization, and multi-module in-\ntegration.\n\u2022 Rank-adjustment optimization methods: These dynam-\nically adjust the ranks of low-rank matrices for greater\nefficiency and task-specific performance. Prominent ex-\namples include AdaLoRA [21], IncreLoRA [22], and\nCAPABOOST [23]. While these methods address certain\nlimitations of LoRA, they introduce challenges such as\nhigh memory requirements during initialization, signifi-\ncant computational overhead, and inefficiencies stemming\nfrom fixed thresholds in rank adjustments.\nMotivated by these challenges, we introduce TriAdapt-\nLORA, a novel PEFT method inspired by synaptic plasticity"}, {"title": "II. RELATED WORK", "content": "LLMs such as GPT-4 [4] and Llama3 [5] have achieved\nsignificant progress in natural language processing and multi-\nmodal tasks. These models are typically based on the Trans-\nformer architecture [27], whose core component is the multi-\nhead self-attention mechanism. This mechanism effectively\ncaptures dependencies between different positions in a se-\nquence. The specific algorithm is illustrated in Equation 1:\nMultiHead(Q, K, V) = Concat(head1,...,headh)W\u00b0, \nhead\u2081 = Attention(QWKWK,VWV),\nAttention(Q, K, V) = softmax \\frac{Q K^T}{\\sqrt{d_k}}V,  (1)\nwhere Q, K, and V represent Query, Key, and Value vectors,\nwith W, WK, WV as projection matrices and WO as the\noutput projection matrix, while dk scales the dot product [27].\nLORA is one of the most representative PEFT methods to\ndate [13]. LORA approximates the incremental matrix AW\nof the pre-trained weight matrix Wo as the product of low-\nranks matrices A and B. During training, the weight matrix\nWo is frozen, and only the low-rank matrices A and B\nare updated, significantly reducing the number of trainable\nparameters while preserving model performance. Its forward\npropagation expression is Equation 2:\nh = Wox + AWx = Wox + BAx, (2)\nwhere Wo \u2208 Rd\u00d7n, A \u2208 Rr\u00d7n, and B \u2208 Rd\u00d7r. Compared\nto full fine-tuning, LoRA reduces the number of training\nparameters by several orders of magnitude when fine-tuning\nmodels like GPT-3 175B. However, LoRA still exhibits a\nperformance gap compared to full fine-tuning. Additionally,\nthe fixed and consistent rank of the low-rank matrices in\nLORA limits the parameter efficiency and adaptability of\nthe model. Building on LoRA, numerous improved methods\nhave been developed to further enhance parameter efficiency\nand performance, particularly optimization methods for rank\nadjustment, like:\n\u2022 AdaLoRA [21] employs singular value decomposition\nto approximate the incremental matrix and dynamically\nprunes based on the importance scores of vector groups\nwithin the incremental matrix. This approach dynamically\nadjusts the rank of the incremental matrices at different\npositions, thereby enhancing parameter efficiency and\nperformance.\n\u2022 IncreLORA [22] introduces a rank self-growth mechanism\nfor the low-rank matrices, eliminating the upper limit\non the rank of the incremental matrices and avoiding\nadditional memory requirements during initialization.\n\u2022 Dynamic LoRA [28] employs a random search approach\nfor ranks, training multiple ranks for the incremental\nmatrices simultaneously during the training process to\nfacilitate rapid search for the optimal rank during testing.\n\u2022 CAPABOOST [23] enhances the rank of the incremental\nmatrices by linearly combining multiple parallel low-rank\nmatrices, thereby increasing the model's expressive power\nwithout adding extra parameters."}, {"title": "III. THE PROPOSED METHOD", "content": "In this section, we present TriAdaptLoRA, a novel\nparameter-efficient fine-tuning method inspired by neuro-\nscience principles and designed to optimize the allocation\nof trainable parameters dynamically. The approach enhances\nparameter utilization by introducing three key innovations: (1)\ndecomposing transformation matrices into the sum of lower\nand upper triangular matrices; (2) a novel parameter impor-\ntance metric for incremental matrices; and (3) a dynamic rank-\ngrowth strategy guided by adaptive thresholds. The overall\nstructure of TriAdaptLoRA is illustrated in Figure 1. The\noverall information processing workflow of the TriAdaptLoRA\nis described in Algorithm 1.\nA. Neuroscience Inspiration\nIn neuroscience, the optimization of synaptic strengths is\na critical mechanism for enhancing neural network perfor-\nmance. This process, often referred to as the credit assignment\nproblem, focuses on identifying connections that significantly\ninfluence behavior [29]\u2013[31]. Hebb's rule [24], a foundational\ntheory in neuroscience, states that the strength of a synaptic\nconnection increases when the presynaptic and postsynaptic\nneurons are simultaneously active. Mathematically, this is\nexpressed as:\n\u2206wi,j = \u03b2\u00b7 fi(ai)\u00b7fj(aj), (3)\nwhere Awij is the change in connection strength between\nneurons i and j, \u03b2 is the learning rate, and fi(ai) and fj(aj)\nrepresent the activities of the presynaptic and postsynaptic\nneurons, respectively. This principle inspires the dynamic\nadjustment of trainable parameters in TriAdaptLoRA, where\nthe importance of model parameters evolves adaptively based\non their contribution to learning.\nB. Parameter Expansion via Triangular Split\nWe approximate the incremental matrix AW of the pre-\ntrained weight matrix Wo as follows:\nAW = BDA, D = L + U, (4)\nwhere B\u2208 Rd\u00d7r and A \u2208 Rr\u00d7n are low-rank matrices,\nand L,U \u2208 Rrxr are lower and upper triangular matrices,\nrespectively. By summing L and U, the dense transformation\nmatrix D = L+U captures critical feature patterns in the data\nthrough linear transformations within the low-rank subspace\ndefined by A.\nThe forward pass during fine-tuning is expressed as:\nh = Wox + a/(r + \u0454) \u00b7 B(L + U)Ax, (5)\nwhere Wo \u2208 Rd\u00d7n is the pre-trained weight matrix, x \u2208 R\u2033 is\nthe input, and a is a scaling factor ensuring training stability as\nthe rank r evolves. Both L and U are initialized with Gaussian\nrandom values, while B is initialized as a zero matrix. The\ninitial rank r is set to 1, satisfying r < min(n,d), and\nis incremented dynamically during training. During training,\nAW is scaled by a/(r + \u0454), where e is a small constant to\nimprove numerical stability.\nThe low-rank matrices A and B, as well as the triangular\nmatrices L and U, are expanded during training to accommo-\ndate new dimensions. For example, the new A(t) is augmented\nby adding Ar rows at the end, as shown in Equation 6:\nA(t) = [A(t-1)]\nAaug (6)\nwhere A(t) \u2208 R(r+\u2206r)\u00d7n, A(t\u22121) \u2208 []\u20a8r\u00d7n, and Aaug \u2208 R\u2206r\u00d7n\nis initialized with Gaussian random values.\nSimilarly, the new B(t) is augmented by adding Ar columns\nat the end, as shown in Equation 7:\nB(t) = [B(t-1) Baug], (7)\nwhere B(t) \u2208 Rdx(r+\u2206r), B(t-1) \u2208 Rd\u00d7r, and Baug E\nRdxAr.\nThe lower triangular matrix L is augmented by adding Ar\nrows at the end to construct a new lower triangular matrix, as\nshown in Equation 8:\nL(t) =\nL(t-1)\nLdown\n0\nLaug (8)\nwhere L(t) \u2208 R(r+Ar)\u00d7(r+Ar) is the augmented lower trian-\ngular matrix at time step t, L(t-1) \u2208 Rr\u00d7r is the pre-existing\nlower triangular matrix from the previous time step t - 1,\nLdown \u2208 Ror\u00d7r is a dense matrix added to the bottom of\nL(t-1), and Laug \u2208 R\u00f2r\u00d7\u25b3r is the lower triangular matrix\nadded to the bottom-right of the expanded matrix. Here, Ldown\nis a dense matrix, meaning it is not constrained to a triangular\nstructure, while Laug retains the triangular form necessary for computational overhead during the model adaptation process\nthe structure of L(t).\nfor downstream tasks.\nThe upper triangular matrix U is augmented by adding Ar Moreover, the rank increment operation for the incremen-\ncolumns at the end to construct a new upper triangular matrix, tal matrices in our method is executed periodically, every\nas shown in Equation 9:\nfew steps, rather than at every training step. This periodic\nU(t) =\n[U(-1)\n0\nUup\nUaug\n(9)\nupdate mechanism eliminates the need to compute impor-\ntance scores based on gradient information at each step,\nwhere U(t) \u2208 R(r+\u2206r)\u00d7(r+\u25b3r) is the augmented upper trian- a requirement in AdaLoRA and IncreLoRA that introduces\ngular matrix at time step t, U(t-1) \u2208 Rr\u00d7r is the pre-existing significant computational burdens. For example, in the natural\nupper triangular matrix from the previous time step t - 1, language understanding experiments detailed in Section IV-B,\nUup \u2208 Rr\u00d7\u25b3r is a dense matrix added to the right of U(t-1), the MNLI task from the GLUE benchmark [25] employs a\nand Uaug \u2208 Ror\u00d7\u25b3r is the upper triangular matrix added to rank increment interval of 1,000 steps. By avoiding the need\nthe bottom-right of the expanded matrix. Similarly, Uup is a for frequent importance evaluations, TriAdaptLoRA circum-\ndense matrix, and Uaug retains the upper triangular structure vents an additional computational overhead equivalent to 1,000\nto preserve the triangular form of U(t). evaluations per interval. As a result, the overall computational\nThe linear combination of a lower triangular matrix L and cost of TriAdaptLoRA remains minimal, making it an efficient\nan upper triangular matrix U allows for the simultaneous solution for rank adjustment in large-scale model adaptation.\nexpansion of the parameters of the square dense transformation\nmatrix D = L+U in both row and column directions, thereby D. Adaptive Rank Growth with Dynamic Thresholds\nachieving high parameter utilization and computational effi- To efficiently allocate model parameters, we propose an\nciency. This bidirectional parameter expansion approach en- adaptive rank growth algorithm based on dynamic thresholds.\nhances the scalability and stability of the incremental matrix At each training step t, the number of incremental matrices\nwhile maintaining its low-rank characteristics. eligible for rank expansion, k(t), is dynamically determined\nOrthogonality Constraint. By constraining the low-rank ma- by a thresholding scheme, which can be linear or nonlinear.\ntrices A and B to be orthogonal, parameter redundancy is The rank budget R(t) is updated iteratively as:\neffectively reduced, numerical stability is enhanced, feature\nR(0) - r. M if t = 1\nR(t) =\n- Ar.k(t-1) if t > 1' (12)\ndiversity is preserved, gradient computations are simplified,\nand theoretical optimality and interpretability are provided. where RO\nrref. M is the initial total rank budget, rref\nThis is expressed in Equation 10 [21]: is the reference rank, r is the initial rank of the low-rank\nmatrices, and Ar is the rank increment per matrix. To ensure at\nR(A, B) = ||AT A \u2013 I|| + ||BT B \u2013 I||. (10) least one matrix is always selected, we impose a lower bound\nk(t) = max(k(t), 1).\nC. Efficient Parameter Importance Evaluation a) Linear Threshold: In the linear strategy, rank growth\naccelerates early to enhance model capacity and stabilizes in\nThe dense transformation matrix D = L + U\u2208 Rrxr is\nlater stages for fine-tuning:\nemployed to capture the critical features of the data within the\nlow-rank subspace. We posit that the magnitude of its varia- k(t) = [R(t) . a(t)], a(t) =\nt-to\nT-to (13)\ntion reflects the degree of change in the overall incremental\nmatrix. Additionally, the Frobenius norm quantifies the overall Here, R(t) represents the remaining rank budget at step t,\nmagnitude of the matrix elements, that is, the \"energy\" of the and a(t) determines the fraction of the budget to allocate\nmatrix. Therefore, the importance of an incremental matrix dynamically.\nAWm is determined by tracking changes in the normalized b) Nonlinear Threshold: The nonlinear strategy delays\nFrobenius norm of its dense transformation matrix Dover rank growth initially to prevent overfitting, then accelerates it\n(t) the training steps. The importance score Sm for the m-th in later stages to enhance model expressiveness:\nincremental matrix at time step t is defined as:\nk(t) = [ea(t).log R(t)]. (14)\nS(t)\n||L + UM ||F ||Lt-1) + Ut-1) || F (t) m This mode is particularly suitable for tasks requiring gradual\nm (t) = m m . early-stage adjustments and rapid expansion in later stages.\n(t-1)\nrm\nc) Rank Growth: At each step, the importance threshold\nwhere || F denotes the Frobenius norm, and rm is the rank of S\u00ba (t) is:\nAWm. This metric captures the relative contribution of AW; (t)\nS\u00ba (t) = min{S(m)|m \u2208 top-k(t)}.\nto model adaptation.\nCompared to AdaLoRA and IncreLoRA, our method signif- Matrices with scores St > S\u00ba (t) are selected for rank\nm\nicantly reduces the computational complexity of importance increment, and new rows and columns in matrices A, B, L,\nevaluation from O((rn + dr)MT) to O(r\u00b2MT), where M and U are initialized with Gaussian random values.\ndenotes the number of incremental matrices, T represents the\ntotal number of iterations, and r, the rank, satisfies r <\nmin(n, d). This reduction translates to a substantial decrease in"}, {"title": "E. Analysis of the Role of the Transformation Matrix", "content": "Using gradient information, we further analyze the impor-\ntance of the dense transformation matrix D = L + U within\nthe incremental matrices. Assuming the loss function is L, the\ngradient of L with respect to AW is given by Equation 15:\n\u2202\u13dd\ndh\ndh \u2202AW\n\u2202\u13dd\n\u2202AW\n= \n\u2202\u13dd\ndh\n(IX)reorder(3,(1,2)), (15)\nwhere I denotes the identity matrix, reorder refers to the\nreordering of dimensions, and represents the tensor product.\nUtilizing the chain rule of derivatives, we can further derive\nthe gradient information of the loss function L with respect\nto the matrices B, L, U, and A as shown in Equation 16:\n\u2202\u13dd\n\u2202B\ndh \u2202AW\n\u2202\u13dd\n\u2202B\n\u2202\u13dd\n\u2202L\ndh \u2202AW\n\u2202\u13dd\n\u2202L\n\u2202\u13dd\n\u2202U\ndh \u2202AW\n\u2202\u13dd\n\u2202U\n\u2202\u13dd\n\u2202A\ndh \u2202AW\n\u2202\u13dd\n\u2202A\n=\n\u2202\u13dd\ndh\nJB(L+U)A\n\u2022 (I \u2297 ((L + U)Ax))reorder(3,(1,2))\n=\ndh\nJB(L+U)A\n(BT (Ax))reorder(3,(1,2))\n=\ndh\nJB(L+U)A\n\u2202\u13dd\n\u2202h\n(BT (Ax)) reorder(3,(1,2))\n=\ndh\nJB(L+U)A\n\u2202\u13dd\n\u2202h\n(((UT + LT)BT) X)reorder(3,(1,2)). (16)\nDuring the backward propagation of model gradients, the\ndense transformation matrix D = L + U plays a crucial role\nin the parameter update process. Its variations directly affect\nthe updates of the low-rank matrices A and B, which in turn\nregulate the optimization of L and U. Specifically, the gradient\nupdate of the low-rank matrix A involves tensor product\noperations. For example, the gradient is computed based on\nthe combination of input x and the matrix (UT + LT)BT.\nThese multi-layer tensor operations couple the features of x\nwith the matrices B, L, and U, thereby extending the gradient\npropagation path. Since the gradient updates are confined\nwithin the subspace defined by the transformation matrix U+ LT, this mechanism implicitly regularizes the parameter\nupdates, effectively suppressing drastic parameter changes and\nreducing the risk of overfitting. Therefore, monitoring the\nchanges in the Frobenius norm of the transformation matrix\nto evaluate the importance of incremental matrices is justified."}, {"title": "Algorithm 1 TriAdaptLoRA Training Procedure", "content": "1: Input: Dataset G, Total Steps T, Warmup Steps to,\nLearning Rate \u03b7, Total Rank Budget RO\n2: Initialization: A, B, L, U with r = 1\n3: for t = 1 to T do\n4: if (t-1) > 0 then\n5: Compute the importance scores S(t) for each\nAWm using Equation 11\n6: Compute the threshold k(t) using the linear thresh-\nold model (Equation 13) or the nonlinear threshold model\n(Equation 14)\n7: Increment the ranks of matrices A, B, L, and U\nwithin the top-k(t) incremental matrices using Equations\n6, 7, 8, and 9, respectively\n8: end if\n9: Update A, B, L, U via gradient descent\n10: end for\n11: Output: Fine-tuned parameters A, B, L, U"}, {"title": "IV. EXPERIMENTS", "content": "This experiment aims to validate the effectiveness of the\nTriAdaptLoRA method in natural language processing tasks.\nSpecifically, the experiment encompasses nine tasks across\ntwo major categories: Natural Language Understanding (NLU)\nand Natural Language Generation (NLG). Fine-tuning was\nperformed using methods such as TriAdaptLoRA, AdaLoRA,\nand IncreLoRA based on the pre-trained model DeBERTaV3-\nbase [32]. To comprehensively assess the effectiveness of\nthe TriAdaptLoRA method, the experimental results of Tri-\nAdaptLoRA will also be compared with existing fine-tuning\nmethods, including Full Fine-Tuning, Adaptive Tuning, BitFit,\nand LORA.\nA. Baseline\nThe experiment selects several representative fine-tuning\nmethods from recent years for comparison to comprehensively\nevaluate the effectiveness of TriAdaptLoRA in adapting to\ndownstream tasks. The following provides a detailed descrip-\ntion of these fine-tuning methods:\n\u2022 Full Fine-Tuning: Updates all pre-trained model param-\neters, achieving high performance but with significant\nresource overhead [11], [12].\n\u2022 Adapter Tuning: Introduces adapter modules, reduc-\ning trainable parameters while maintaining performance,\nthough increasing model complexity and inference la-\ntency [33]-[35].\n\u2022 BitFit: Adjusts only bias parameters, substantially re-\nducing trainable parameters and performing well across\ntasks [36]."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "This study introduces TriAdaptLoRA, a parameter-efficient\nfine-tuning method inspired by the brain's synaptic plasticity\nmechanisms. TriAdaptLoRA enhances model performance and\nreduces energy consumption by dynamically optimizing the\nrank allocation of incremental matrices, ensuring that matrices\nof higher importance receive more trainable parameters. Key\ninnovations, including the triangular split of transformation\nmatrices, importance-driven parameter allocation, and adaptive\nrank-growth strategies, enable TriAdaptLoRA to achieve supe-\nrior parameter utilization and scalability compared to existing\nmethods.\nComprehensive experiments demonstrate that TriAdapt-\nLORA consistently outperforms other PEFT methods across\nvarious natural language understanding and generation tasks,\nsuch as GLUE benchmark and SQUAD 2.0 tasks. Notable\nresults include improved accuracy, reduced computational\noverhead, simplified hyperparameter configurations, and en-\nhanced stability. These findings validate the effectiveness of\nTriAdaptLoRA as a robust and resource-efficient solution\nfor fine-tuning LLMs, with significant potential for practical\napplications in resource-constrained environments.\nWhile TriAdaptLoRA demonstrates promising results, fur-\nther exploration is essential to fully unlock its potential. Future\nwork will focus on incorporating more brain-inspired mecha-\nnisms to enhance model adaptability and parameter efficiency,\nleveraging principles such as long-term potentiation, spike-\ntiming-dependent plasticity, or hierarchical processing inspired\nby cortical structures. Additionally, improving dynamic task\nadaptability is crucial to extend TriAdaptLoRA's application\nto multi-task or domain-adaptive scenarios, enabling seamless\nadaptation to diverse and evolving task conditions. Finally,\nadvancing energy-aware optimization by explicitly integrat-\ning energy-efficiency objectives into the fine-tuning process"}, {"title": "APPENDIX A\nHYPERPARAMETER SETTINGS IN EXPERIMENTS", "content": "We provide a detailed report of the hyperparameter con-\nfigurations for the TriAdaptLoRA, LoRA, AdaLoRA, and\nIncreLoRA methods based on the DeBERTaV3-base pre-\ntrained model, evaluated across eight datasets in the GLUE\nbenchmark. The common hyperparameter settings and those\nspecific to AdaLoRA are shown in Table V. The first fourteen\nare shared hyperparameters, while the latter five are specific to\nthe AdaLoRA method. Notably, the parameter Warm-up Steps\napplies only to the TriAdaptLoRA, LoRA, and IncreLoRA\nmethods, while Incremental Rank Number and Incremental\nInterval are specific to the TriAdaptLoRA and IncreLoRA\nmethods. The parameters Regularization Orthogonal Coeffi-\ncient, Betal, and Beta2 do not apply to LoRA."}, {"title": "B. Natural Language Generation Tasks", "content": "We report the hyperparameter configurations for the\nTriAdaptLoRA and IncreLoRA methods based on the\nDeBERTaV3-base pre-trained model, evaluated on the SQUAD\n2.0 task. Specifically, the hyperparameter settings during the\ntraining process are detailed in Table VI:"}]}