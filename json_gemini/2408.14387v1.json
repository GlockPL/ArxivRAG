{"title": "Reprogramming Foundational Large Language Models(LLMs) for Enterprise\nAdoption for Spatio-Temporal Forecasting Applications: Unveiling a New Era in\nCopilot-Guided Cross-Modal Time Series Representation Learning", "authors": ["Sakhinana Sagar Srinivas", "Chidaksh Ravuru", "Geethan Sannidhi", "Venkataramana Runkana"], "abstract": "Spatio-temporal forecasting plays a crucial role in various\nsectors such as transportation systems, logistics, and supply\nchain management. However, existing methods are limited by\ntheir ability to handle large, complex datasets. To overcome\nthis limitation, we introduce a hybrid approach that combines\nthe strengths of open-source large and small-scale language\nmodels (LLMs and LMs) with traditional forecasting meth-\nods. We augment traditional methods with dynamic prompt-\ning and a grouped-query, multi-head attention mechanism to\nmore effectively capture both intra-series and inter-series de-\npendencies in evolving nonlinear time series data. In addi-\ntion, we facilitate on-premises customization by fine-tuning\nsmaller open-source LMs for time series trend analysis uti-\nlizing descriptions generated by open-source large LMs on\nconsumer-grade hardware using Low-Rank Adaptation with\nActivation Memory Reduction (LoRA-AMR) technique to\nreduce computational overhead and activation storage mem-\nory demands while preserving inference latency. We combine\nlanguage model processing for time series trend analysis with\ntraditional time series representation learning method for\ncross-modal integration, achieving robust and accurate fore-\ncasts. The framework's effectiveness is demonstrated through\nextensive experiments on various real-world datasets, outper-\nforming existing methods by significant margins in terms of\nforecast accuracy.", "sections": [{"title": "Introduction", "content": "Multivariate time series forecasting (MTSF) is a long-\nstanding task that finds wide application in various domains,\nenabling strategic decision-making through the prediction\nof multiple related variables that change over time. MTSF\nboasts numerous applications across various sectors with\nsignificant financial or operational impacts, such as trans-\nportation systems for route planning and navigation, logis-\ntics, and supply chain management for demand forecast-\ning. However, MTSF presents several challenges, including\ncomplex relationships between time series variables, non-\nlinearity, heterogeneity, sparsity, and non-stationarity. Re-\ncently, Spatio-Temporal Graph Neural Networks (STGNNs)\nhave been introduced to improve multi-horizon forecast ac-\ncuracy on multivariate time series (MTS) data. STGNNs are\ndesigned to accurately model both the long-range tempo-\nral dependencies within each individual variable time series\nand complex inter-dependencies among variables within the\nMTS data. STGNNs utilize both (i) explicit relationships,\nwhich are derived from predefined graphs created by hu-\nman experts based on their prior domain knowledge, and (ii)\nimplicit relationships, which are discovered through data-\ndriven neural relational inference methods. Explicit relation-\nships are static, often incomplete or inaccurate, while im-\nplicit relationships can exhibit significant non-linearity and\nevolve over time, revealing hidden connections among vari-\nables that may not be readily apparent to human experts.\n'Human-in-the-loop' STGNNs (Yu, Yin, and Zhu 2017; Li\net al. 2017; Guo et al. 2020) incorporate explicit knowledge\nbut overlook the latent inter-relationships among the time\nseries variables underlying the MTS data. A newer class\nof 'human-out-of-the-loop' STGNNs (Deng and Hooi 2021;\nWu et al. 2020; Kipf et al. 2018) jointly infer the dependency\ngraph structure, capturing the latent time-conditioned un-\nderlying relationships that drive the variable co-movements,\nwhile simultaneously learning the spatio-temporal dynamics\nfrom the MTS data to forecast future values. Despite their\neffectiveness, these approaches fail to fully leverage the ac-\ncurate and reliable explicit (predefined) graph structures pro-\nvided by domain experts, particularly when the data is noisy,\nleading to suboptimal forecasting. Transformers(Vaswani\net al. 2017), which excel in sequence modeling, are often\npreferred over STGNNs for interpreting spatio-temporal dy-\nnamics due to their ability to capture long-range dependen-\ncies through dynamic, context-aware self-attention mecha-\nnisms, offering greater scalability and flexibility. Further-\nmore, while existing STGNNs primarily focus on providing\npointwise forecasts, they lack the ability to generate reliable\nuncertainty estimates for these forecasts. Uncertainty esti-\nmates are crucial for accurate risk assessment and informed\ndecision-making. Moreover, current methods typically em-\nploy past data within a predetermined window length to\nlearn historical patterns and predict future outcomes, with\nthe duration of these patterns varying across different histor-\nical periods. Existing graph-based forecasting methods often\nrely on a fixed window length, adopting a one-size-fits-all\napproach. This approach may not be optimal as there is no\nuniversally ideal window length for all MTS data. In real-"}, {"title": null, "content": "world applications, adjusting a predefined window length\ncan be challenging, often unattainable, and computationally\nexpensive. Based on our review of prior research, no exist-\ning methods fully capture the complexity of diverse patterns\nin MTS data, each characterized by varying lengths and dis-\ntinct features. This makes achieving this goal an ambitious\nundertaking. In recent years, large language models (LLMs)\nsuch as GPT-4 (OpenAI 2023) have revolutionized natu-\nral language processing(NLP), achieving remarkable perfor-\nmance by generating human-like responses and demonstrat-\ning enhanced logical reasoning and multitasking capabili-\nties. These proprietary LLMs have acquired a vast and di-\nverse range of linguistic constructs and knowledge through\nextensive pretraining on massive datasets. However, their\ninternal workings remain largely opaque, earning them the\nmoniker of 'black-box' models. This lack of interpretabil-\nity poses challenges for downstream applications, as these\nmodels typically do not provide direct access to logits or to-\nken embeddings. Furthermore, their 'jack-of-all-trades' ap-\nproach to handling a multitude of tasks often leads to sub-\noptimal performance on specialized tasks. In contrast, open-\nsource LLMs like Llama 2(Touvron et al. 2023b) from Meta\nAI offer fine-tuning capabilities but necessitate substantial\ncomputational resources for adaptation to new tasks and do-\nmains through fine-tuning, primarily due to their large model\nsizes and the requirement for specialized hardware. Con-\nversely, open-source small-scale language models (LMs)\nsuch as BERT(Devlin et al. 2018) are cost-effective for fine-\ntuning to specialized tasks using task-specific data and pro-\nvide interpretability through access to logits or token embed-\ndings. However, they may fall short in reasoning and gener-\nalization abilities, often generating less coherent and contex-\ntually relevant responses compared to larger LMs. Despite\nthe transformative impact of LLMs in various domains, their\napplication in time series analysis remains limited, primar-\nily attributed to the scarcity of extensive datasets necessary\nfor training LLMs for time series tasks. The largest pub-\nlicly available datasets for time series analysis(Godahewa\net al. 2021), are significantly smaller than those employed\nin NLP tasks. While advancements have been made in uti-\nlizing LLMs, such as GPT-4, across various scientific disci-\nplines, the synergistic integration of general-purpose LLMs\nwith traditional forecasting methods for MTSF task remains\nan underexplored area in the development and advancement\nof intelligent forecasting techniques. This integration holds\npromise for achieving more accurate and robust future es-\ntimates. It is crucial to acknowledge that while this ap-\nproach is innovative, LLMs such as GPT-4 are not inher-\nently designed for time series analysis. Nonetheless, adapt-\ning them for this purpose, while unconventional, is entirely\nfeasible. Originally conceived for NLP tasks, LLMs can be\ntailored for time series data, providing a unique method to\ngenerate comprehensive textual summaries that capture the\nmain trends, patterns, and anomalies. These technical de-\nscriptions, encompassing trend analysis and data summa-\nrization, offer key insights and a multi-modal perspective\nthat could complement traditional forecasting techniques.\nHowever, there is a significant limitation in sharing sensitive\ndata with external LLM services. This includes the risks as-"}, {"title": null, "content": "sociated with sending regulated data to external LLM APIs\nto generate textual summaries on time series analysis. While\nLLMs offer a wide range of potential benefits for enterprises,\ntheir adoption is hindered by several limitations, including\ndata privacy and sovereignty concerns, costs and customiza-\ntion requirements, and security vulnerabilities. To address\nthese limitations, a novel approach termed 'On-Premise Se-\ncure LLMs' is proposed. This solution would enable enter-\nprises to fine-tune open-source large-scale LMs on their own\nproprietary data within their own infrastructure, enhancing\ndata privacy and sovereignty, reducing costs, increasing cus-\ntomization options, and bolstering security. Overall, it of-\nfer a promising solution to the limitations of existing pro-\nprietary LLMs, potentially democratizing access to LLM\ncapabilities and accelerating their adoption across a wide\nrange of MTSF tasks, aligning with the growing demand for\nprivate, tailored AI solutions. Despite the advantages, on-\npremise LLMs face challenges such as high computational\nresource demands, scalability issues requiring extensive in-\nfrastructure upgrades, and the need for specialized technical\nexpertise for deployment and maintenance. In this study, we\nintroduce a novel framework built upon cross-modal time\nseries representation learning, referred to as LLM-TS Net\nfor brevity. The Figure 1 illustrates the proposed framework.\nThe objective is to utilize the complementary strengths of\nopen-source large and small-scale language models, and tra-\nditional forecasting methods to establish a more robust and\naccurate predictive framework. This approach models the\ntime-varying uncertainty of framework predictions on fu-\nture estimates, aiming to improve the accuracy of risk as-\nsessments and assist decision-makers by estimating predic-\ntive uncertainty. It presents a dynamic and flexible prompt\nmechanism designed to encode knowledge about various\ntemporal dependencies and trends, and allows the method\nto adapt to the evolving nature of MTS data through trans-\nfer and reuse of learned knowledge and improve forecasting\nperformance. This addresses the limitation of fixed, prede-\nfined window lengths, which often fail to account for the\nnon-stationary nature of real-world MTS data. The frame-\nwork adopts a time-then-space (TTS) approach, capturing\nthe non-linear, temporal dynamics within times series vari-\nables before modeling the dependencies among different\nvariables, offering a holistic understanding of MTS data.\nThis is achieved through the integration of Grouped-query\nMulti-head Attention (GQ-MHA) for both intra- and inter-\nseries analysis in spatio-temporal MTS data. The framework\nintroduces a secure on-premise LLM based on the open-\nsource, pretrained 'llama2 7B 4k' model, customized for\ntime series analysis and designed to run on consumer-grade\nhardware (low-cost GPUs). This approach not only reduces\ncosts but also eliminates the need to transmit sensitive data\nto external servers, creating a secure and efficient environ-\nment that protects data privacy and offers customized in-\ntelligence without high costs or data sovereignty risks. We\nuse custom prompts with task-specific instructions to query\nLLMs in a zero-shot setting, such as the 'llama2 70B 4k'\nmodel. This approach enables us to generate textual descrip-\ntions that cover various aspects, such as identifying main\ntrends, patterns, and requires the large-scale model to gener-"}, {"title": null, "content": "alize and apply the implicit knowledge acquired during pre-\ntraining on vast text corpora for generating the desired out-\nput in analyzing MTS data. Next, we fine-tune small-scale\nLMs such as the 'llama2 7B 4k' using the generated textual\ndescriptions for task-specific adaptation to encapsulate the\nrich domain-specific knowledge within these descriptions.\nWe utilize the open-source 'llama2 70B 4k' model to ana-\nlyze time series trends, owing to its advanced reasoning and\ninference capabilities, which are superior in handling com-\nplex tasks and yield more accurate and relevant textual de-\nscriptions compared to the 'llama2 7B 4k' model. We then\nfine-tune the 'llama2 7B 4k' model on the supervised task\nof minimizing cross-entropy loss, using pairs of MTS data-\ngenerated textual descriptions. This approach incorporates\nthe rich, domain-specific insights extracted by the large-\nscale model from the MTS data. As a result, these smaller\nmodels become better equipped to handle similar tasks and\nare more aligned with the specific requirements of MTS data\nanalysis."}, {"title": null, "content": "Overall, this\nwork presents the following contributions:\n\u2022 We present a dynamic prompting mechanism to enhance\nthe adaptability and accuracy of time series representa-\ntion learning methods. This mechanism recognizes and\napplies learned patterns from historical data, enabling it\nto adapt to changing data distributions. It functions sim-\nilarly to knowledge transfer, applying previously learned\npatterns to new, similar input data. Additionally, the tra-\nditional method learns both intra- and inter-series de-\npendencies for a comprehensive understanding of com-\nplex relationships in multi-dimensional data. This ap-\nproach significantly enhances the accuracy and reliability\nof forecasts in multi-sensor environments.\n\u2022 The LoRA-AMR method offers a trifecta of benefits:\nenhanced memory efficiency, consistent computational\nload, and reduced activation storage memory require-\nments, all without compromising inference latency. A\nlarger LM, such as \u2018Llama2-70B\u2019, is employed to gener-\nate textual descriptions of patterns and trends. This pro-\ncess facilitates a context-driven interpretation of MTS\ndata. Fine-tuning the smaller 'Llama2-7B' model using\ngenerated descriptions using the powerful LORA-AMR\ntechnique not only enables efficient and effective cus-\ntomization of the smaller LM to the specific task but also\nleverages the advanced capabilities of larger LLMs to en-\nhance the performance and versatility of smaller LMs.\n\u2022 We integrate text-level embeddings obtained from fine-\ntuned smaller LMs and time series embeddings from\ntraditional methods using a multi-head attention mech-\nanism. This approach enables the capture of contextually\nrelevant information from cross-domains, enhancing the\nanalysis and understanding of MTS data."}, {"title": "Problem Definition", "content": "Consider a dynamic system equipped with N sensors that\ngather sequential data over T time intervals on F input\nfeatures, represented in a spatio-temporal matrix $X \\in$\n$R^{N \\times T \\times F}$. These features typically include key attributes\nsuch as traffic speed, flow, and density. Specifically, we de-\nfine $X_i \\in R^{T \\times F}$ as the historical data for the i-th sensor,\nencompassing all features over time, and $X^t \\in R^{N \\times F}$ as the\nhistorical data for all sensors at time step t, including all fea-\ntures. In our work, we predict traffic flow using only F = 1\nto ensure a fair and rigorous comparison with the baselines\nin traffic forecasting datasets. In the non-stationary time se-\nries data matrix $X \\in R^{N \\times T}$, each row represents data from\na sensor, while each column corresponds to data at a spe-\ncific timestamp. We use subscripts and superscripts to de-\nnote data from a specific sensor and timestamp, respectively.\nFor instance, $X_{i,:} = X_i$ represents the time series data from\nsensor i, and $X_{:,t} = X^t$ represents the data across all sen-\nsors at timestamp t. In the context of time series forecasting,\nwe employ the sliding window technique to divide the his-\ntorical dataset into overlapping, consecutive segments. This\napproach allows predictive models to adapt to changing pat-\nterns and complex dynamics, thereby effectively capturing\nboth short-term and long-term trends, as well as seasonality\nand other dominant characteristics. We construct the sam-\nples $X_{t-W:t-1} \\in R^{N \\times W \\times F}$ using a sliding window of size"}, {"title": null, "content": "W. In traffic forecasting, our objective is to train a neural\nnetwork, denoted as $\\phi$, to predict future data for the up-\ncoming v steps, represented as $S_{t+1} = X_{t:t+v-1}$, based on\nhistorical observations $S_t = X_{t-W:t-1}$. The process is il-\nlustrated as follows:\n$S_t \\overset{\\phi}{\\longrightarrow} S_{t+1}$\nThe loss function to train the spatio-temporal encoder is\nmean absolute error(MAE) loss, defined as follows:\n$\\mathcal{L}(\\phi) = \\frac{1}{V} |S_{t+1} - \\hat{S}_{t+1}|$\nwhere $\\hat{S}_{t+1}$ represents the framework's predictions and\n$S_{t+1}$ is the ground truth. Specifically, we define $S_{t+1} =\nX_{t:t+v-1} \\in R^{N \\times 1 \\times F}$ for single-step forecasting, and\n$S_{t+1} = X_{t:t+v-1} \\in R^{N \\times v \\times F}$ for multi-step forecasting.\nHere, v represents the forecasting horizon."}, {"title": "LORA-AMR", "content": "LLMs have revolutionized natural language\nprocessing(Brown et al. 2020; Touvron et al. 2023a; Ope-\nAI 2023; Anil et al. 2023), and fine-tuning these large-\nscale models has proven to be highly effective in enhanc-\ning their performance across various tasks and in aligning\nwith human intent(Liu et al. 2019; Wei et al. 2021). How-\never, fine-tuning LLMs with their full set of parameters can\nbe extremely resource-intensive, especially for specialized\ntasks on consumer-grade hardware, due to memory con-\nstraints. To address this challenge, parameter-efficient fine-\ntuning (PEFT) methods have been introduced. These meth-\nods focus on updating only a small subset of the trainable\nparameters, such as adapter weights (Houlsby et al. 2019)\nand prompt weights (Li and Liang 2021; Lester, Al-Rfou,\nand Constant 2021). In particular, Low-Rank Adaptation\n(LORA) (Hu et al. 2022), is notable for fine-tuning pretrained\nLLMs to achieve performance comparable to full-parameter\nfine-tuning. It accomplishes this by updating only a small\nnumber of learnable pairs of low-rank adapters(weights)\nwhile keeping the base parameters static. This technique\nhas been widely adopted in various applications (Dettmers\net al. 2023), facilitating efficient task-specific adaptation.\nLORA prevents catastrophic forgetting in general-purpose\nlarge-scale models during continual learning by enabling\nthem to adapt to new tasks without overwriting the pre-\ntrained knowledge base. This allows them to retain their\nprior knowledge while effectively learning new information.\nIn essence, LoRA represents a parameter-efficient adapta-\ntion technique that substantially enhances the capabilities\nof LLMs. It achieves this by integrating parallel low-rank\nadapters alongside the original weights of a linear layer,\nas depicted in Figure 2(b). These adapters operate in con-\njunction with the frozen pre-trained weights($W_0$) of the lin-\near layer. This approach significantly reduces memory us-\nage while maintaining inference efficiency. It accomplishes\nthis by keeping the primary weights static and updating only\nthe lightweight, ancillary parameters-the LoRA adapters.\nLoRA aims to introduce additional trainable parameters\n($\\Delta W$) that capture task-specific information without alter-\ning the original pre-trained weights ($W_0$). To achieve this,\nLoRA constrains weight updates to a low-rank decomposi-\ntion, expressed as $W_0 + \\Delta W = W_0 + BA$, where $W_0$\nrepresents the original pre-trained weight matrix with di-\nmensions $R^{d \\times d}$. $\\Delta W$ denotes the low-rank approximation\nadded to the original weights during model adaptation (fine-"}, {"title": null, "content": "tuning). This approximation is constructed as the product of\ntwo low-rank matrices, B and A, both confined within a low-\nrank space. Here, B is the projection-down weight matrix\nwith dimensions $R^{d \\times r}$, A is the projection-up weight ma-\ntrix with dimensions $R^{r \\times d}$. The notation $r << d$ indicates\nthat the rank of the decomposition is significantly smaller\nthan d, leading to substantial memory savings. The hyper-\nparameter $\\alpha$, typically valued at , is a positive constant.\nThe rank r controls the trade-off between model capacity\n(how much task-specific information it can learn) and the\ncomplexity (number of parameters to train). During training,\n$W_0$ remains fixed, and only the low-rank weights B and A\nare updated. This approach reduces the memory overhead by\ndecreasing the number of trainable parameters to update, the\ncorresponding gradients to compute, and the optimizer state\nsize that needs to be maintained. Compared to full-parameter\nfine-tuning, this method yields a parameter reduction ratio\nof $\\frac{3d \\times r}{d^2}$, which is significant when the rank r is much smaller\nthan the dimension d. Furthermore, LORA introduces no ad-\nditional inference latency, as the product of $BA$ is added\nelement-wise into $W_0$. However, LoRA faces challenges re-\nlated to high memory usage during fine-tuning. This is due to\nthe necessity of storing large input activations of X through-\nout the forward-propagation phase for gradient computation\nof the weight matrix A in the back-propagation phase. As\na result, LoRA incurs high activation memory costs compa-\nrable to conventional full-parameter fine-tuning, potentially\nleading to a memory bottleneck. Current solutions include\nselectively applying LoRA to specific layers (Hu et al. 2022)\nor employing activation recomputation (Chen et al. 2016) to\nmitigate this issue. However, these strategies might affect\nthe fine-tuning performance and efficiency."}, {"title": null, "content": "In this work, we introduce LoRA-AMR, a novel approach\ndesigned to significantly reduce the activation memory foot-\nprint associated with LoRA without incurring additional\ncomputational costs. LORA-AMR innovates by freezing the\npre-trained weight $W_0$ as well as the projection-down weight\nB. Furthermore, it redefines the projection-up weight A as\nthe product of two low-rank matrices, D and C. Specif-\nically, D, the second projection-down weight, has dimen-\nsions $R^{d \\times \\frac{r}{2}}$, and C, the second projection-up weight, has di-\nmensions $R^{\\frac{r}{2} \\times d}$. In our proposed method, D remains static\nwhile only C is updated during training. In short, by freez-\ning $W_0$, B, and D, and updating only C, LoRA-AMR re-\nduces the number of trainable parameters and minimizes\nthe size of the input activations that must be stored during\ntraining for gradient computation during backward propa-"}, {"title": null, "content": "gation, all with no additional inference latency. This mod-\nification results in a substantial decrease in the activation\nmemory required, as it confines the input activation stor-\nage to the lower-dimensional output of matrix D. Conse-\nquently, the only input that needs to be stored during the\nfeed-forward pass is the much smaller transformed input\nDBX, used to compute the gradient of C during the back-\nward propagation. Here, X is first mapped through weights\nB and D to a lower dimension before being projected back\nup through weight C, significantly reducing the activation\nmemory demands. Figure 2 compares the full-model fine-\ntuning (FT), LoRA, and LoRA-AMR approaches. LoRA-\nAMR begins by initializing the low-rank parameters B and\nD, which are randomly drawn from a normal distribution.\nIt sets C initially to zero. As a result, the adaptation weight\nmatrix $\\Delta W = BA = B(DC)$ remains zero at the start.\nThis ensures that the outputs of the pretrained LLMs remain\nunchanged before fine-tuning begins. During fine-tuning, B\nand D are held fixed. This means that updates to the model\nweights through $\\Delta W$ are confined to a subspace of reduced\nrank, specifically r/2, as determined by the initial column\nspace of D. This approach strategically limits weight up-\ndates to this lower-dimensional space, preserving the in-\ntegrit"}]}