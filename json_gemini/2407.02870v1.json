{"title": "Membership Inference Attacks Against Time-Series Models", "authors": ["Noam Koren", "Abigail Goldsteen", "Ariel Farkash", "Guy Amit"], "abstract": "Analyzing time-series data that may contain personal information, particularly in the medical field, presents serious privacy concerns. Sensitive health data from patients is often used to train machine-learning models for diagnostics and ongoing care. Assessing the privacy risk of such models is crucial to making knowledgeable decisions on whether to use a model in production, share it with third parties, or deploy it in patients' homes. Membership Inference Attacks (MIA) are a key method for this kind of evaluation, however time-series prediction models have not been thoroughly studied in this context. We explore existing MIA techniques on time-series models, and introduce new features, focusing on the seasonality and trend components of the data. Seasonality is estimated using a multivariate Fourier transform, and a low-degree polynomial is used to approximate trends. We applied these techniques to various types of time-series models, using datasets from the health domain. Our results demonstrate that these new features enhance the effectiveness of MIAS in identifying membership, improving the understanding of privacy risks in medical data applications.", "sections": [{"title": "1. Introduction", "content": "There is a clear conflict between the ever-increasing interest in analyzing personal data to enhance and improve processes, and the need to preserve the privacy of data subjects. In the medical domain, sensitive health data from real patients is often used to train machine learning (ML) models that aid physicians in diagnostics and treatment. ML models are also utilized within medical devices and applications to predict malfunctions and improve ongoing care."}, {"title": "2. Background", "content": ""}, {"title": "2.1. Time-Series Forecasting models", "content": "Time series forecasting has evolved significantly, initially relying on linear models like ARIMA and Exponential Smoothing. However, with deep learning advancements, neural network architectures such as LSTM and GRU showed superior performance over traditional methods.\nRecently, Convolutional Neural Networks (CNNs) and Temporal Convolutional Networks (TCNs) have demonstrated state-of-the-art results. The Transformer architecture was also adapted for forecast-"}, {"title": "Multidimensional Fourier Transform", "content": "The Fourier Transform has been widely used in time series analysis to identify periodic patterns or cycles in the data. By converting time-series data into the frequency domain, one can identify the main frequencies at which these cycles occur.\nSeveral forecasting models use Fourier Transforms for better performance. Autoformer employs Fast Fourier Transform for autocorrelation, FEDformer focuses on key frequencies, and the Fourier Neural Operator approximates partial differential equations operators with Fourier Transforms. TimesNet uses Fourier Transforms for feature decomposition to capture periodic patterns.\nThe Multidimensional Fourier Transform (MFT) extends the traditional Fourier Transform to handle multi-dimensional data. We drew inspiration from the Neural Fourier Transform (NFT), and used a 2-dimensional Discrete Fourier Transform (DFT) to extract the seasonality of the time series."}, {"title": "2.2. Membership Inference Attacks", "content": "Membership inference attacks (MIAs) represent a significant privacy threat in machine learning. In these attacks, an adversary aims to determine whether a specific data record, x, was included in the training set of a model, D. If successful, the attack can reveal sensitive information about individuals, such as their medical history, financial status, or personal preferences. Moreover, membership inference attacks can also be used to identify individuals who are part of a specific group or community, potentially leading to discrimination, stigma, or even physical harm.\nFormally, given access to a machine learning model M, the attacker seeks to ascertain the membership of a data sample x in D, i.e; to check if x \u2208 D. To this end the attacker typically analyze M's outputs, and produce numeric characteristics, i.e. features, that will enable it to distinguish member of the training data from none members. Such features, include the M's loss given the sample, the log-probabilities and the outputs entropy.\nIn the context of time-series forecasting models, a malicious attacker seeks to determine whether a specific time series was utilized in the model's training dataset, such as a patient's ECG test results. This type of attack poses a significant threat in industries like healthcare and finance, where sensitive time-series data is frequently leveraged to develop predictive models, and the unauthorized disclosure of such information could have severe consequences."}, {"title": "3. Related work", "content": "In the realm of time series, Hisamoto et al. studied membership inference on sequence-to-sequence (seq2seq) models in the context of machine translation, where the output is a chained sequence of classifications. This differs from medical sequence modeling whose input features and outputs are numerical and continuous."}, {"title": "4. Methodology", "content": ""}, {"title": "4.1. Problem Statement", "content": "This study focuses on MIA on multivariate time-series forecasting models. We assume that the attacker can access a complete sample that was either used in model training or not.\nIn time-series data, training samples consist of data points up to time T (lookback), denoted as $X = [Y_1, \\ldots, Y_T] \\in \\mathbb{R}^{M \\times T}$, and the model predicts H data points onward (horizon), denoted as $Y = [Y_{T+1}, \\ldots, Y_{T+H}] \\in \\mathbb{R}^{M \\times H}$, where $y_t \\in \\mathbb{R}^M$ for $t = 1, \\ldots, T+H$, and M is the number of variables. The predicted values are $\\hat{Y}$.\nOur task is to determine if a specific sample, X, is part of the training data, D, i.e; $X \\in D$ by comparing the real future values, Y, and the models predicted values, $\\hat{Y}$."}, {"title": "4.2. Features for \u039c\u0399\u0391", "content": "In the context of MIA, the attack features are the set of attributes or characteristics that the attack model leverages to determine whether a given data sample was a part of the training set (member) or not (non-member). As in any ML model, selecting the correct attack features is critical, as they form the basis upon which the attack model makes its predictions. An optimal set of attack features can significantly improve the success of the attack, potentially posing a much higher privacy risk.\nOur goal is to find attack features that will provide good membership inference results for time-series models. This involves leveraging the characteristics of time-series data by identifying features that capture its unique aspects. Hence, the introduced features isolate the seasonality and trend components of the model's prediction, contrasted with the same components of the true data (labels).\nGiven that time series data inherently include components such as trend and seasonality, models trained on such data are particularly good at capturing those elements. This"}, {"title": "4.2.1. SEASONALITY", "content": "We detect seasonality in multivariate temporal data by utilizing the 2-dimensional Discrete Fourier Transform (2-DFT), inspired by NFT. This method breaks down the dataset into its fundamental frequency components, considering both the range of variables and the timeline. This approach is essential for datasets where the interaction between different variables can create new seasonality patterns that are not explicitly seen in a univariate context.\nConsider how 2-DFT is applied to the matrix $Y \\in \\mathbb{R}^{M \\times H}$. The 2-DFT allows for a breakdown into two sequential 1-DFTs. The first stage applies a 1-DFT to columns of Y, yielding an intermediate matrix Z:\n$Z = F_M Y$ (1)\nwhere $F_M$ reflects the transformations applied across different variables (M is the number of variables).\nThe subsequent phase involves a row-wise 1-DFT on Z, deriving the matrix C:\n$C = Z F_H^T$ (2)\nwhere $F_H$ relates to the temporal structure of the data (H denotes the number of predicted time points).\nConcisely, this can be denoted as:\n$C = F_M Y F_H^T$ (3)\nIn this matrix representation, C contains the Fourier coefficients.\nFollowing are the Fourier matrices $F_M$ and $F_H$ that achieve the desired Fourier transformation:\n$F_M = \\begin{bmatrix}\n\\cos(2\\pi \\cdot \\frac{0 \\cdot 0}{M}) & \\cdots & \\cos(2\\pi \\cdot \\frac{0 \\cdot (M-1)}{M})\\\\\n:\\\n\\cos(2\\pi \\cdot \\frac{M \\cdot 0}{M^2}) & \\cdots & \\cos(2\\pi \\cdot \\frac{M \\cdot (M-1)}{M^2})\\\\\n\\sin(2\\pi \\cdot \\frac{M \\cdot 0}{M^2}) & \\cdots & \\sin(2\\pi \\cdot \\frac{M \\cdot (M-1)}{M^2})\n\\end{bmatrix}$"}, {"content": "$F_H = \\begin{bmatrix}\n\\cos(2\\pi \\cdot \\frac{0 \\cdot 0}{H}) & \\cdots & \\cos(2\\pi \\cdot \\frac{0 \\cdot (H-1)}{H})\\\\\n:\\\n\\cos(2\\pi \\cdot \\frac{H \\cdot 0}{H^2}) & \\cdots & \\cos(2\\pi \\cdot \\frac{H \\cdot (H-1)}{H^2})\\\\\n\\sin(2\\pi \\cdot \\frac{H \\cdot 0}{H^2}) & \\cdots & \\sin(2\\pi \\cdot \\frac{H \\cdot (H-1)}{H^2})\n\\end{bmatrix}$\nThe matrix $F_M$, corresponding to the number of variables, M in the dataset, has dimensions M \u00d7 M. This matrix reflects the transformations applied across different variables.\nConversely, the matrix $F_H$, that relates to the temporal structure of the data, has dimensions H \u00d7 H, where H denotes the number of predicted time points in each series. Together, these matrices facilitate a comprehensive multidimensional Fourier analysis, enabling the decomposition of the multivariate time series into sinusoidal components.\nThe input features to the attack derived from this method are:\n1. Coefficients of the Fourier series corresponding to the true values:\n$C = F_1 \\times Y \\times F_2$\n2. Coefficients of the Fourier series corresponding to the model's predicted values:\n$\\hat{C} = F_1 \\times \\hat{Y} \\times F_2$\n3. The $L_2$ norm between the coefficients of the true and predicted values:\n$||C - \\hat{C}||_2$"}, {"title": "4.2.2. TREND", "content": "Consider a multivariate time series Y with H time points and M variables. Each variable's series is approximated using a polynomial of degree d. This approximation can be represented as:\n$Y = P \\times A$ (4)\nwhere A is the coefficients matrix, and P is the Vandermonde matrix, constructed from the time vector t = $\\frac{[0,1,\\ldots,H-1]}{H}$. P contains powers of t up to d \u2013 1, has dimensions d \u00d7 H, and is defined as:\n$P = \\begin{bmatrix}\n1 & 1 & 1\\\\\nt_1 & t_2 & t_H\\\\\n:\\\nt_1^{d-1} & t_2^{d-1} & t_H^{d-1}\n\\end{bmatrix}$\nwhere $t_i = \\frac{i}{H}$ for $i = 1, 2, \\ldots, H$.\nThe coefficients matrix A is obtained by the least squares solution:\n$A = (P^T P)^{-1} P^T Y$\nThe input features to the attack derived from this method are:"}, {"title": "4.2.3. MEAN ABSOLUTE SCALED ERROR (MASE)", "content": "Additionally, this study investigates incorporating the Mean Absolute Scaled Error (MASE) metric as a feature for the attack model. MASE is a scaled measure of the accuracy of forecasts. It compares the mean absolute error of the forecast to the mean absolute error of a na\u00efve forecasting method.\n$MASE = \\frac{\\frac{1}{H} \\sum_{i=1}^{H} |Y_{T+i} - \\hat{Y}_{T+i}|}{\\frac{1}{H-1} \\sum_{i=2}^{H} |Y_{T+i} - Y_{T+i-1}|}$\nThis metric is extended to the multivariate case by averaging the respective univariate MASE values across all variables."}, {"title": "5. Experimental Setup", "content": ""}, {"title": "5.1. Threat Model & MIA Attack Setup", "content": "Continuing the line of privacy assessment works, this paper assumes a gray-box threat model. In the assumed threat model, the attacker has access to the training data of the model and a set of samples that were not used for training. The access to this data, allows estimating a worst case privacy risk for a model before deployment, without the need of developing shadow models.\nTo execute the attack, we leverage a privacy risk assessment framework, which builds upon recent breakthroughs in membership inference attacks (MIAs). This framework harnesses a diverse set of input features extracted from the target model's inputs and outputs. Through an exhaustive grid search, it systematically explore various attack model architectures, hyperparameters, and pre-processing techniques to identify the optimal configuration that yields maximum attack performance.\nThe attack models trained by the risk assessment framework used different combinations of the following features:\n1. Seasonality (includes all three seasonality features)"}, {"title": "5.3. Models", "content": "We performed attacks against various state-of-the-art time-series forecasting architectures:\n\u2022 Neural Fourier Transform (NFT): Configured with Fourier granularity of 8 for the seasonality blocks and a polynomial degree of 4 for the trend blocks, comprising 2 blocks per stack.\n\u2022 TimesNet: An advanced neural network with the model dimension set to 16 and a dropout rate of 0.1.\n\u2022 PatchTST: This transformer model included one encoder and decoder layer, a model dimension of 16, and a dropout rate of 0.1.\n\u2022 DLinear: Consists of Linear layers, featured a dimension of 16 and a dropout rate of 0.1.\n\u2022 Temporal Convolutional Network (TCN): Configured with channels set to [2, 2], a kernel size of 2, and a dropout rate of 0.2.\n\u2022 Long Short Term Memory (LSTM): Featured a 2-layer structure with hidden dimensions set to 50."}, {"title": "6. Results", "content": "In all experiments, the MSE loss-based attack is used as the baseline and compared to the new features."}, {"title": "6.1. AUC ROC Results", "content": "Figures 2 and 3 highlight the strong performance of the seasonality and trend features across various time-series models and datasets. The highest AUC ROC values were achieved with feature combinations that included the trend or seasonality features, outperforming the MSE-only attack. For the EEG dataset, when looking at the different models, the improvement percentage of the best-performing feature combination compared to the MSE-only attack, averaged across horizons, ranged from 8.44% (with average std 0.007) to 26.41% (with average std 0.006). For the ECG dataset, improvements ranged from 2.97% (with average std 0.008) to 24.55% (with averaged std 0.007). The TimesNet model showed the best improvements in both datasets.\nThe MASE feature achieved the lowest attack performance, however, the combination of MASE and MSE generally surpassed attacks that use the MSE feature alone.\nOverall, the results indicate that the Seasonality and Trend features provide a robust solution for membership inference attacks for time-series forecasting models. Its consistent performance across different models, datasets, and horizons highlights its effectiveness.\nAnalysis of Attack Performance by Prediction Horizon. We analyzed the relative attack AUC ROC as a function of the prediction horizon. To this end, we computed, for each dataset, the correlation between the prediction horizon (previously denoted by H) and the improvement percentage (MSE-only attack relative to the highest attack value). We consistently observed a positive correlation for all the models except for NFT and TCN on the ECG dataset. We assume that the negative correlation can be traced back to the difference in architecture. Notably, the NFT and TCN models both are based on convolutional layers, which capture the trend and seasonality in a different manner. The results presented in the table highlight the greater improvement in vulnerability of time series prediction models to attacks as the prediction horizon increases, compared to the MSE baseline attack. This suggests an enhanced attack vector against these models, which is not present in other model architectures."}, {"title": "6.2. TPR Results", "content": "In addition to AUC ROC, we measured the attack's True Positive Rate at a False Positive Rate of 1% for a fixed horizon of 5. The results are presented in Tables 4 and 5.\nFor the EEG dataset, using the seasonality feature with the PatchTST model substantially improved the TPR, showing a 9x increase. Significant improvements were noted across NFT, TimesNet, and LSTM models with the trend feature, ranging from 2.1x to 4x. The TCN model demonstrated a 2.1x improvement with the combination of trend and seasonality, while the DLinear model showed similar gains with both combined and standalone seasonality features.\nIn the ECG dataset, the trend feature and its combination with seasonality in the NFT model led to a 3x improvement in TPR. The seasonality feature provided notable increases for the TimesNet and PatchTST models, with up to 11.6x enhancement."}, {"title": "6.3. Ablation Study", "content": "In this ablation study, we examined the effects of incorporating the predicted labels as a feature in the attack model, as is common with MIA against classical ML models. The predicted labels feature was added to every feature combination we used and tested independently. The results on the EEG and ECG datasets are illustrated in Figure 4. The black curve, labeled \"Benchmark Limit\", represents the upper bound of the AUC ROC values for the feature combinations without predicted labels, as presented in the previous section."}, {"title": "7. Conclusion and Future Work", "content": "This paper is the first to explore membership inference attacks on numeric time-series machine-learning models. Our primary contribution is the introduction of two novel features, Trend and Seasonality, derived from low-degree polynomial fitting and Multivariate Fourier Transform respectively. These features enhance MIA models by leveraging the inherent characteristics of time-series data, improving the identification of member samples.\nVarious state-of-the-art forecasting models incorporate those components into their design. Consequently, when targeting a time-series prediction model, there is a significant likelihood that the model will precisely estimate the series' Seasonality and Trend of its training data, providing a strategic advantage in MIAs."}]}