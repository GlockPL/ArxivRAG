{"title": "GENERATIVE MIDTENDED COGNITION\nAND ARTIFICIAL INTELLIGENCE.\nThinging with thinging things", "authors": ["Xabier E. Barandiaran", "Marta P\u00e9rez-Verdugo"], "abstract": "This paper introduces the concept of \u201cgenerative midtended cognition\u201d, that explores the integration\nof generative AI technologies with human cognitive processes. The term \"generative\" reflects AI's\nability to iteratively produce structured outputs, while \"midtended\" captures the potential hybrid\n(human-AI) nature of the process. It stands between traditional conceptions of intended creation,\nunderstood as steered or directed from with in, and extended processes that bring exo-biological\nprocesses into the creative process. We examine the working of current generative technologies\n(based on multimodal transformer architectures typical of large language models like ChatGPT), to\nexplain how they can transform human cognitive agency beyond what the conceptual resources of\nstandard theories of extended cognition can capture. We suggest that the type of cognitive activity\ntypical of the coupling between a human and generative technologies is closer (but not equivalent) to\nsocial cognition than to classical extended cognitive paradigms. Yet, it deserves a specific treatment.\nWe provide an explicit definition of generative midtended cognition in which we treat interventions by\nAl systems as constitutive of the agent's intentional creative processes. Furthermore, we distinguish\ntwo dimensions of generative hybrid creativity: 1. Width: captures the sensitivity of the context of\nthe generative process (from the single letter to the whole historical and surrounding data), 2. Depth:\ncaptures the granularity of iteration loops involved in the process. Generative midtended cognition\nstands in the middle depth between conversational forms of cognition in which complete utterances\nor creative units are exchanged, and micro-cognitive (e.g. neural) subpersonal processes. Finally, the\npaper discusses the potential risks and benefits of widespread generative AI adoption, including the\nchallenges of authenticity, generative power asymmetry, and creative boost or atrophy.", "sections": [{"title": "Introduction", "content": "You are surrounded by colleagues in a conference. You are about to explain your opinion about the French philosopher\nGilles Deleuze: \u201cHe is very inspiring, but his writing is too ..."}, {"title": "Extending extended cognition: Generative AI's new challenges", "content": "Generative Artificial Intelligence has reached maturity and widespread adoption after transformer architectures first\nmanaged to deliver highly proficient text generation (Vaswani et al., 2017). Today it is possible for anyone to access AI\nservices that can generate text, image, audio and video, and whose quality is often indistinguishable from that created\nby humans. To characterise these systems, it is important to understand in some detail their internal workings (see\nBarandiaran & Almendros, 2024 for a more detailed philosophical analysis).\nGenerative systems take as input a string or matrix of data (a text document, audio file, image, or combinations of them)\nand break them down into tokens or basic processing units. The tokenized input is then transposed to an intermediate\nstructured \"representation\" (embedding in the case of language or latent space in the case of image diffusion models)\nthat takes the shape of a matrix in a high dimensional space. Attention mechanisms make it possible for points of this"}, {"title": "Generative midtention", "content": "Imagine you are a professional designer. You received an email with a client's request. You externalise your thoughts:\n\"This work requires an 80s style drawing with a contrasting combination of sharp and round shapes\". Creating this work\nimplies many recursive processes: from looking at the blank piece of paper or screen and projecting imagined figures,\nlines, shapes and compositions (maybe even using hands or other objects to get a grasp of proportions), to sketching in\npencil the imagined future drawing, to inking it (making it more definitive) and to finally colouring it. So, as you start\ndrawing, you get to imagine the completion of your traces on the white background as a grey coloured (pencil) sketch.\nSometimes you augment the focus of your anticipated sketch and keep imagining. Some other times, you directly\nintervene on it: you either keep drawing following the grey lines that you drafted and continue imagining them as\nyou draw them. But you also often choose to diverge from the draft, and you imagine how the picture re-organizes\naccordingly. Sometimes you surprise yourself as you have sketched, on your first try, exactly what you wanted. Some\nother times, you take your distance, you sketch again and keep correcting till you get it right.\nWe have all had similar extended creative experiences before. But with generative AI, the role of imagination and of\nthe material pencil sketch (or even that of the \u201cinker\u201d), can be played by a machine. By a generative AI working in\nreal-time within our creative process. Read the passage above again and substitute the \u201cyou\u201d in italics by a generative\nAI. Although still relatively fictional, this possibility is increasingly foreseeable. It is partly a reality for computer\nprogrammers making intensive use of code completion. And it is partly available as autocompletion and other generative\nAl services embedded within office environments or audiovisual creative and editing tools. We explained above\nhow these systems can be trained, tuned and contextually fitted to a particular user, her past work and surrounding\ninformation. The system could have read the client's request, taken the designer's expressed intentions, and projected\nthe style and features of her past designs to this joint generative process; while actively adapting to the designers\nintentions in real-time.\nIn a similar vein, Barandiaran and Almendros (2024) provide the following explanation of writing as a generative\nprocess:\nA variation of Hemingway's motto \"write drunk, edit sober\" is becoming widespread in many areas of human text\ngeneration: \"let the LLM write, edit yourself\u201d and very often the inverse \u201cwrite drunk, let the LLM edit\". Both loops\""}, {"title": "Intention, extension and midtention", "content": "For classical approaches to human action, intentions are the result of the right combination of beliefs and desires\ncausing the action (Davidson, 1980). This kind of event-causal account of intentionality leaves little room for explaining\ngenerative midtended action. $&$\nis an intentional action if X (the agent) holds the belief that doing $&$ will satisfy\ndesire D. Both $&$ and D are specified prior to the action and the desire D and the belief that \"$&$\nwill bring D\" must be\ncontained and causally efficacious in the mind of X in order to make $&$ an intentional action."}, {"title": "Dimensions of generative midtended cognition", "content": "Inspired by Heersmink's (2015) dimensions of integration in extended cognition, we propose that cognitive processes\nwith intersecting loops of generative power can also be conceptualised through dimensions of (active) integration. Note\nthat whereas Heersmink's (or any traditional extended cognition literature) account refers to the degree of integration of\nexternal vehicles in a single locus of generative cognition that is anchored in the agent, we are proposing a different sort\nof (active or generative) integration; that of at least two different loci of generative power each of which potentially\nrealised by agent or environmental resources or both jointly bringing about a cognitive process. We hereby propose\na conceptualization along two dimensions (see Figure 2) \u2014 although it could potentially be extended to include more"}, {"title": "Should we stand on the shoulders of generative giants? Future risks and benefits", "content": "Before assessing the future of Generative AI, we need to take into account that it is a technology that has grown very\nfast, but that might be showing signs of fatigue and plateauing. The bending of the exponential curve is evident for\nmany. It is perfectly possible that, as a species of technological entity, LLMs and the like might have reached important\nlimits on their generative capacities. If that is so, there are different scenarios that can ensue: 1. This is the peak of AI\nfantasy, and we are deemed to conform with what we have, or 2. Other infrastructural or algorithmic innovation might\nlead to increased generative capacities. If the first scenario is right, generative midtention might not expand very far.\nThe state of the current technology does not afford a comfortable hybrid generativity. The current problems with\nhallucinations, reasoning limitations and deviant chained errors make midtended cognition a relevant but narrowed\nphenomenon. In fact, we are aware that in our analysis we have conceptualised the \"width\" dimension as assuming\na high precision and accuracy. This is definitely an idealisation; the predictive capacity of different technologies\nmight vary, due to technical shortcomings, but also to being inaccurate by design (see later discussions about branded\ncontent).\nHowever, if the technology keeps evolving, we might increasingly shift to a cognitive digital culture that relies on\ngenerativity as much as previous civilizations were partially born and sustained by the cognitive transformations that\nwriting brought about (Ong & Hartley, 2012). Midtended cognition (and other forms of generative interactions, closer\nto those found in functionally equivalent social cognitive tasks) will spread quickly and become an integral part of our\nproducing and being in the world.\nTechnology can evolve in the two dimensions of generativity we outlined above, towards more granularity on the\nrecursive technological interventions, and on the increasingly wider contextual tuning or adaptation. Regarding the\nfirst dimension, if cognition emerges out of recursive loops and, so far, generative technologies only had access to\nrelatively low resolution external tokens (words, pixels, etc.) the potential of training, prompting and contextualising\nthe functioning of generative AI with neuromuscular, proprioceptive, and brain data might be enormous. The risks of\nintervening and that scale would be even bigger.\nPerhaps the most promising evolution of the current technology involves the hybridization of social cognition with\ngenerative AI along the horizontal dimension (including others in the interactive and generative context). LLMs can\nfacilitate collective intelligence, boosting midtended agency in the direction of genuine participatory cognition. But this\nalso poses a delicate risk. Social interaction is to social autonomy what neuronal interaction is to individual autonomy."}, {"title": "Conclusion: active integration beyond extension", "content": "The framework of generative midtended cognition that we have proposed aims to provide a theoretical basis to capture\nthe hybrid processes where AI-generated suggestions become integral to the intentional creation of cognitive products\nby human agents. Understanding the ways in which artificial generative technologies can become integrated in our\ncognitive processes, without admitting to them being full-fledged cases of social interaction or of extended cognition\nas theorised so far, becomes a crucial step to analysing our relationship with AI. By articulating the entanglement of\ndifferent nested loops of generative power that contribute to a shared cognitive creative outcome, we have conceptualised\ntwo dimensions of active integration, width and depth. In doing so we have been able to characterise the specific case\nof generative cognitive processes occurring at a scale that was not displayed in our relations with previous forms of\ntechnologies: that of midtended cognition.\nThe novelty of our approach lies in the fact that previously existing theories of extended (or enactive) cognition did\nnot foresee that the environment would be populated by the generative technologies we now have at our disposal. The\nenvironment was not thought of as being generative in the relevant sense (a purpose-structured kind of generativity\nsimilar to human creative, purposeful, practices) nor tuned to the specific context and agent in its generativity. This\nis not only the case for extended cognition theorising; postphenomenology, particularly as developed by Verbeek,\nhas advanced a strong paradigm on understanding hybrid (human-technology) kinds of intentionality. Verbeek's\n(2008) account of cyborg and composite intentionality aims at something similar to our account of integration, since he\nrecognises the intentional character of technology. However, the sort of intentionality instantiated by technology, in his\naccount, is always directed towards the world, and not back to the agent. This account falls short of capturing current\ngenerative technology, where the arrow of (derived) \u201cintentionality\u201d (or purpose-structured generativity, in our account)\ndeparting from technology would also point towards the human agent.\nAnalysing the challenges and implications of these technologies through the lenses of these previous approaches (as\ndeveloped so far) would tend to attribute all purpose-structured or normatively shaped contributions to the human\nagent, with the AI tool functioning only as a vehicle or a constraint in its realization, or would fail to capture the\nuniquely generative character of the products of the interaction. This misses the importance of the contributions of\nthe AI technology in the generative process. As such, our approach allows us to further analyse the ethical risks that\ncome with digital technologies and that were already starting to be raised within extended cognition literature. Coming\nback to the issue of transparency, for instance, our dimension of depth allows us to account for cases where the scale of\ninterventions occurring below the creative unit grounds the phenomenological feel of transparency, while still retaining\nthe fact that the cognitive process is a result of two different sources of generative power. The creative units that emerge\nfrom these hybrid processes (for instance, a sentence created with an autocomplete function) are a result of midtended\ncognition, not merely extended cognition.\nOn the other hand, treating these processes as true forms of social cognition would obscure the fact that generative AI\ntechnologies, while capable of producing generative outcomes, are not autonomous agents capable of participating in a\ntrue form of social interaction, with its constitutive tensions (see E. A. D. Di Paolo et al., 2018). As such, our capacity\nto negotiate our interactions with these kinds of automata are not similar to what occurs with other human agents. While\nthis does not devoid midtended cognitive processes that include AI technologies of their creative or generative character,\nit does have important implications for how we might be able to (collectively and individually) regulate them.\nWe have aimed, in the previous section, to hint at the specific risks, questions and possibilities that generative AI can\npose if we understand them as bringing about midtended cognition processes. The granularity of the intervention in the\njoint generative process (captured by our depth dimension), together with the immense capacity for context-sensitivity\n(width dimension) and the status of the genAI automata as (currently market-driven) artificial products, has brought\nabout specific concerns that are unprecedented in the history of technology. The political strategies needed to navigate\nthese issues are different from those used to overcome issues emerging in purely social interactions between autonomous\nagents (but also from passive, non-generative technologies, as those amenable to extended-mind style theorizing).\nAnd we have shown that we do not need to consider LLMs as possessing human qualities to account for the fact that"}]}