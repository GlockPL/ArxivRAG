{"title": "Multimodal Fusion of EHR in Structures and Semantics: Integrating Clinical Records and Notes with Hypergraph and LLM", "authors": ["Hejie Cui", "Xinyu Fang", "Ran Xu", "Xuan Kan", "Joyce C. Ho", "Carl Yang"], "abstract": "Electronic Health Records (EHRs) have become increasingly popular to support clinical decision-making and healthcare in recent decades. EHRs usually contain heterogeneous information, such as structural data in tabular form and unstructured data in textual notes. Different types of information in EHRs can complement each other and provide a more complete picture of the health status of a patient. While there has been a lot of research on representation learning of structured EHR data, the fusion of different types of EHR data (multimodal fusion) is not well studied. This is mostly because of the complex medical coding systems used and the noise and redundancy present in the written notes. In this work, we propose a new framework called MINGLE, which integrates both structures and semantics in EHR effectively. Our framework uses a two-level infusion strategy to combine medical concept semantics and clinical note semantics into hypergraph neural networks, which learn the complex interactions between different types of data to generate visit representations for downstream prediction. Experiment results on two EHR datasets, the public MIMIC-III and private CRADLE, show that MINGLE can effectively improve predictive performance by 11.83% relatively, enhancing semantic integration as well as multimodal fusion for structural and textual EHR data.", "sections": [{"title": "1 INTRODUCTION", "content": "Electronic Health Records (EHRs) are widely used in healthcare and comprise heterogeneous data, including tabular records and unstructured clinical notes. Tabular records contain individual visits and are composed of a set of medical concepts such as diagnoses and medications. Clinical notes are long documents written by healthcare providers containing detailed information such as patient history, clinical findings, and laboratory test results.\nPrevious research has focused on structured EHR data modeling for predictive purposes [12]. The conventional approach involves modeling structured EHR data as numerical vectors, which are then processed using traditional machine learning (ML) models. However, this approach overlooks complex interactions between individual variables and does not consider interaction structures. To address this limitation, graph neural networks (GNNs) have been introduced to capture the hidden graph structure within EHR data [3, 10]. More advanced approaches, such as hypergraph models, have been adopted to further capture higher-order interactions among visits and medical codes [14]. In this study, we aim to integrate structured EHR data with corresponding textual data. Although tabular and textual EHR integration has been studied quite recently [8, 9], those studies mainly focused on pretraining and fine-tuning language models. We aim to combine structures and semantics and utilize the medical knowledge from the LLMs for improvement. We focus on two types of textual information with EHR: medical code concept names and clinical notes. Integrating each type of information presents unique challenges due to the diversity of coding systems used, such as ICD-10, CPT, and SNOMED. This can cause discrepancies in mapping concept names across patient records and medical systems. Clinical notes, on the other hand, are often riddled with errors, acronyms, and irrelevant or redundant information, creating challenges for integrating their semantics.\nIntegrating textual semantics from medical code concept names and clinical notes is crucial for ensuring accurate and comprehensive modeling of patient records. The recent success of large language models (LLMs) has created new opportunities in textual data integration. Inspired by this new trend, we explore LLMs to unify the modeling of medical concepts by generating semantic embeddings from LLM and fusing them with structural information of medical codes in the representation learning space. Furthermore, LLM can help identify and extract important semantics from clinical notes, which are then fused with patient visit representations to enhance the reasoning over visit-level interactions.\nWe propose MINGLE, a multimodal EHR fusion framework that integrates structures and semantics from clinical records and notes, as shown in Figure 1. Our approach chooses the hypergraph neural network as the backbone, then further infuses medical concept semantics and clinical notes semantics into the structural modeling process using a two-level semantics infusion strategy and LLMs. Experiment results and case studies on two EHR datasets demonstrate that MINGLE effectively enriches the representation of patient information. It jointly leverages the power of hypergraph GNNs to model complex relationships and harnesses the domain knowledge in LLMs and their strengths in natural language understanding. As a result, this integrated approach offers a comprehensive and nuanced analysis of EHR data, leading to more accurate and domain knowledge-enriched decision-making in healthcare."}, {"title": "2 PRELIMINARIES", "content": "EHR data is a digital collection of patient information, including structured clinical records and unstructured notes. The structured records are in a tabular format, where each row represents an individual patient visit, and columns are assigned to different medical codes. EHR also contains notes that complement the textual component. The combination of structured and textual data in EHR can provide a more comprehensive understanding of patient health and healthcare interactions."}, {"title": "2.1 Structural and Textual Data in EHR", "content": "Given a multimodal EHR dataset $D = {T,N}$, $T = = {Tp}_{p=1}^{P}$ is the structured patient record that include P rows of individual patient visits, and $N_p$ is the corresponding clinical notes to each visit. The goal of our method is to train a predictive model that makes a clinical prediction for each given p-th visit $D_p = {Tp, Np}$."}, {"title": "2.2 Risk Prediction Problem", "content": "Previous work on structured data modeling in EHR has demonstrated that transforming EHR tabular data to hypergraph can effectively encode the higher level co-occurrence relationships and interactions among visits and medical codes [14], leading to effective visit representations for downstream prediction targets.\nHypergraph Construction. To transform tabular EHR data T into hypergraphs, each individual visit is modeled as a hyperedge and each medical code as a node. Each hyperedge connects all nodes that appeared in the corresponding visit. The hypergraph is denoted as $G = (V, E)$, where V, & stand for nodes and hyperedges respectively. All nodes belong to the set of medical codes C.\nPatient Visit Representation Learning. We utilized the hyper- graph neural network model from Xu et al. [14], which jointly learns node and hyperedge embeddings. In the l-th neural network layer, the update rule for node embedding is\n$x_v^{(l)} = f_{v \\rightarrow \\varepsilon}(V_v, E^{(l-1)})$, (1)\nand the rule for hyperedge embedding is\n$e_e^{(l)} = f_{\\varepsilon \\rightarrow v}(V_e, X^{(l-1)})$, (2)\nwhere $X^{(l)}$ and $E^{(l)}$ denote the embeddings of node v and hyperedge e in the l-th layer ($1 \\leq I \\leq L$), respectively. Ev,E is the hidden representations of hyperedges that connect the node v, and Vex is the hidden representations of nodes that are contained in the hyperedge e. The two message-passing functions $f_{v\\rightarrow\\varepsilon}(\u00b7)$ and $f_{\\varepsilon\\rightarrow v}(\u00b7)$ leverages multi-head self-attention, which help to identify important neighbors during propagation. Following the L message passing layers, a $MLP_{CLS}$ classification is used to convert the hyperedge embeddings to a value for binary classification,\n$y_e = \\sigma (MLP_{CLS} (e_e^{(LF)})).$ (3)\nThe learning objective is defined as binary cross-entropy loss\n$l_{cls} = -y \\log(y_e) \u2013 (1 \u2013 y) \\log(1 \u2013 y_e).$ (4)"}, {"title": "2.3 Hypergraph Modeling of Structures in EHR", "content": "Two textual semantics resources exist in the multimodal EHR dataset - the concept names of medical codes in tabular data and clinical notes. To infuse semantics into structural learning of hypergraph modeling, we propose a two-level strategy, as illustrated below."}, {"title": "3 METHOD", "content": "To reflect the structural contexts of nodes in the graph, we utilize the Deep Walk algorithm [11] to learn a structural latent representation $s_v \\in R^{d_1}$ for each node v in the hypergraph. This is particularly useful in the EHR modeling task as edges are sparse. To model the medical codes from different coding systems in a unified way, we first map the original code v to the corresponding concept name $c_v$, then utilize GPT text-embedding-ada-002 model to generate a semantic embedding $c_z \\in R^{d_2}$, which contains clinical knowledge and context background from LLMs.\nWe tried different ways to combine network-based and knowledge- based encoding, finding that simple concatenation achieves the best performance. Specifically, the $X_v^{(0)}$ in Eq. (1) is initialized as the concatenation of both the structural feature $s_v$ and the semantic feature $c_v$ of the nodes in the hypergraph,\n$X_v^{(0)} = [s_v; c_v]$. (5)\nThese fused node embeddings are utilized as the node feature ini- tialization of the message-passing process, which induces the initial hyperedge embedding in Eq. (2)."}, {"title": "3.1 Infusing Medical Concept Semantics into the Structural Modeling of EHR data", "content": "EHR datasets contain different types of clinical notes that serve specific purposes in documenting patient care. These notes include progress notes that track the patient's condition and treatment during hospitalization, nursing notes that provide information about the patient's daily care and response to treatment, radiology reports that interpret imaging results, and discharge summaries that give a comprehensive overview of the patient's hospital stay, including diagnoses, administered treatments, the patient's response to treatment, and follow-up care instructions. Out of all these types of notes, discharge summaries are particularly valuable for integration with structured EHR data as they offer a granular summary that is instructive for continuous patient care.\nIn MINGLE, for each individual patient visit record $T_p$ (corre- spond to a hyperedge e \u2208 E), we match the corresponding discharge summary $N_p$ and filter irrelevant sections such as admission dates,"}, {"title": "3.2 Infusing Clinical Note Semantics into the Structural Modeling of EHR data", "content": "This leads to an enhancement of the central node semantics during its update from connected hyperedges, which also helps to establish a soft collaboration between fine-grained concept semantics and coarse-grained document semantics. Finally, we improve the hyperedge representation updating rule in Eq. (2) as below:\n$E_e^{(l)} = MLP_2([f_{v\\rightarrow\\varepsilon} (V_e, X^{(l-1)}); H_e])$. (7)\nThis means that the hyperedge semantic embeddings $H_e$ are incor- porated into each message passing layer, along with the aggregated information from its connected nodes, to update the hyperedge representation."}, {"title": "4 EXPERIMENTS", "content": "Datasets. We have performed experiments on two clinical prediction datasets, MIMIC-III and CRADLE. The CRADLE dataset was collected from a large healthcare system in the United States. The MIMIC-III [7] dataset contains 36,875 visits in all, represented by 7423 medical codes, with 12,353 visits being labeled. The CRADLE dataset contains 36,611 visits with 12,725 codes. We divided them into a train, a validation, and a test set in the ratio of 7:1:2. As natural notes are not included in the CRADLE dataset, we convert individual visits into natural language through textualization.\nTasks. On the MIMIC-III [7] dataset, we perform phenotyping prediction, which involves predicting the presence of 25 care conditions in patients' next visits [6], given their current ICU records. This can be useful for detecting morbidity, repurposing drugs, and diagnosis. On the CRADLE dataset, the task aims to determine if patients diagnosed with type 2 diabetes will experience cardiovascular disease (CVD) endpoints within a year of their diagnosis. CVD endpoint is defined by the presence of coronary heart disease (CHD), congestive heart failure (CHF), myocardial infarction (MI), or stroke. As CVD affects around 32% of patients with diabetes [4], it is essential to have a systematic CVD risk prediction.\nMetrics. To account for the imbalanced label distribution in both MIMIC-III and CRADLE, we evaluate the performance using four metrics: Accuracy, AUROC, AUPR, and Macro-F1 score [2, 3]. We set the threshold for accuracy and F1 score to 0.5 for a fair comparison with the previous methods.\nImplementation Datails. Our model is built with PyTorch. We use Adam as the optimizer with a learning rate of 1e-3. The weight decay is set to 1e-3. We tune several key hyperparameters, including the hidden dimension d, the number of layers L in the hypergraph neural network, and the dimension ratio between structural and semantical embeddings. Details are further discussed in Section 4.2.\nBaselines. We compare MINGLE with various types of baselines, including (1) Conventional ML Baselines. Logistic Regression (LR), SVM, and MLP are selected as non-graph modeling baselines. (2) GNN Baselines. In graph-based methods, the graph is constructed based on pair-wise relations among medical codes: an edge is created between two codes if they co-occur in the same visit. We choose GCT [3] and GAT [13]. (3) Hypergraph Modeling Baselines. These baselines are tested using the same hypergraph structured as MINGLE but with various neural network architectures. We include HGNN [5], HyperGCN [15], HCHA [1], and HypEHR [14]."}, {"title": "4.1 Experiment Results", "content": "The results comparison on two EHR datasets of MINGLE and baselines are present in Table 1. The results show that MINGLE achieves the best performance compared to all baselines on four metrics on the MIMIC-III dataset, particularly in a higher F1 score. On the CRADLE dataset, MINGLE shows a significant improvement over AUROC and AUPR. Since the datasets are unbalanced, the slight drop in accuracy with improvements in all other metrics may be due to an improvement in the class with a smaller sample size."}, {"title": "4.2 Ablation and Hyperparameter Studies", "content": "The last two rows of Table 1 examine the effect of the two-level infusion strategy using ablation analysis. Our findings indicate that the removal of medical concept semantics consistently results in a significant decrease compared to the full MINGLE. This suggests that medical concept name semantics play a vital role in reasoning over structured data. In comparison, clinical note semantics appear to have less impact, possibly due to the challenge of constructing lengthy document representations from LLMs, particularly with the noisy nature of clinical notes. It is worth noting that for the CRADLE dataset, the clinical notes utilized are obtained from patient visit records, resulting in cleaner and mostly medical concept-based notes. Hence, the influence of removing hyperedge fusion is more pronounced in terms of AUROC and AUPR than with natural notes.\nEffect of Hyperparameters. The influence of hidden dimension d (24, 48, 72, 96) and the number of layers L (1, 2, 3, 4) in the hypergraph model, and the dimension ratio (0.5. 0.67, 1, 1.5, 2) between structural and semantical embedding in Eq. (5) and (7) are investigated. Results are omitted here due to the space limit."}, {"title": "Ablation Study of Two-level Semantics Fusion", "content": "We present two case studies on MIMIC-III Cardiac Dysrhythmias phenotype prediction in Figure 2 to demonstrate the difference in important medical node selection between the baseline and MINGLE based on attention weights in the self-attention mechanism.\n\u2605 Case 1. The differences and similarities between the important nodes discovered by the HypEHR and MINGLE models can help explain their differences in predicting Cardiac Dysrhythmias. The nodes identified by both models include Carvedilol, a beta-blocker used for treating hypertension and heart failure and reducing the risk of arrhythmias, a significant indicator of cardiovascular disease and arrhythmia risk; Nitroprusside Sodium, which is applied in acute heart failure and hypertensive emergencies; and Zolpidem Tartrate, which can indicate insufficient rest and anxiety, and sleep quality can have a potential impact on cardiac health. All those nodes are closely related to Dysrhythmias. However, MINGLE also identified Heart Failure, Cardiomyopathy, and Cardiac Dysrhythmias. These are diseases directly related to cardiac function. This suggests that"}, {"title": "5 CASE STUDY", "content": "the infusion of medical concept semantics in the MINGLE model introduced a deeper understanding of the clinical context, leading to an improved predictive ability because of the effective modeling of important nodes directly related to the prediction target.\n\u2605 Case 2. In the second case, the important node sets from HypEHR and our system are quite similar. However, clinical notes contain helpful information that can be used for better learning. For instance, the patient's past medical history reveals that he had heart failure nearing the time of admission. The hospital course indicates that the patient developed rapid atrial fibrillation and hypertension. This indicates that the patient faced some issues related to their cardiac function after the surgery. Furthermore, Percocet, a medication that contains oxycodone, can have side effects on the respiratory and cardiovascular systems. MINGLE can combine the semantics of these clinical notes with the structural learning of EHR, leading to more comprehensive learning of patient profiles."}, {"title": "6 CONCLUSION AND DISCUSSION", "content": "Our MINGLE framework combines EHR clinical records and notes by infusing two-level semantics into hypergraph neural networks. Results show significant advantages of integrating medical concept semantics. In the future, we plan to investigate explicit extraction using LLMs and supplement multimodal EHR by aligning and fusing cross-modality data in both hard and soft ways."}]}