{"title": "Low-Rank Optimal Transport through Factor\nRelaxation with Latent Coupling", "authors": ["Peter Halmos", "Xinhao Liu", "Julian Gold", "Benjamin J. Raphael"], "abstract": "Optimal transport (OT) is a general framework for finding a minimum-cost transport\nplan, or coupling, between probability distributions, and has many applications\nin machine learning. A key challenge in applying OT to massive datasets is the\nquadratic scaling of the coupling matrix with the size of the dataset. Forrow et al.\n(2019) introduced a factored coupling for the k-Wasserstein barycenter problem,\nwhich Scetbon et al. (2021) adapted to solve the primal low-rank OT problem. We\nderive an alternative parameterization of the low-rank problem based on the latent\ncoupling (LC) factorization previously introduced by Lin et al. (2021) generalizing\nForrow et al. (2019). The LC factorization has multiple advantages for low-rank\nOT including decoupling the problem into three OT problems and greater flexibility\nand interpretability. We leverage these advantages to derive a new algorithm\nFactor Relaxation with Latent Coupling (FRLC), which uses coordinate mirror\ndescent to compute the LC factorization. FRLC handles multiple OT objectives\n(Wasserstein, Gromov-Wasserstein, Fused Gromov-Wasserstein), and marginal\nconstraints (balanced, unbalanced, and semi-relaxed) with linear space complexity.\nWe provide theoretical results on FRLC, and demonstrate superior performance\non diverse applications \u2013 including graph clustering and spatial transcriptomics\nwhile demonstrating its interpretability.", "sections": [{"title": "1 Introduction", "content": "Optimal transport (OT) is a powerful geometric framework for comparing probability distributions.\nOT problems seek a transport plan P efficiently transforming one distribution (a) into another (b),\nsubject to a ground cost C. The minimum cost yields a distance between a and b, while the optimal\ntransport plan reveals key structural similarities between the distributions. Owing to its versatility\n\u2013 different ground costs result in different ways to compare data \u2013 OT has found many applications in\nmachine learning and beyond: from self-attention Tay et al. (2020); Sander et al. (2022); Geshkovski\net al. (2023) and domain adaptation Courty et al. (2014); Solomon et al. (2015) to computational\nbiology Schiebinger et al. (2019); Yang et al. (2020); Bunne et al. (2023); Liu et al. (2023).\nThis versatility is compounded by several variants using different forms of the objective function\nand/or constraints on the transport plan P. Wasserstein (W) OT Kantorovich (1942) compares\ndistributions over the same space through the expected work of P, while Gromov-Wasserstein (GW)\nOT M\u00e9moli (2011) compares distributions supported on distinct geometries through the expected\nmetric distortion of P. Fused Gromov-Wasserstein (FGW) Vayer et al. (2020) OT is suited to\nstructured data, taking a convex combination of the former two objectives. Independently, one can\nrelax constraints on the marginals of P: in computational applications, P is a matrix whose row-sum\nP1m and column-sum PT1n are called its left and right marginals. Balanced OT requires P1m = a\nand PT1n = b. Unbalanced OT Frogner et al. (2015) replaces these constraints with penalties in the"}, {"title": "2 Background", "content": "Wasserstein OT. Let {x1,...,xn} and {Y1, ... Ym } be datasets in a metric space X, and let Ad\nbe the probability simplex of size d. Through probability vectors a \u2208 An and b \u2208 Am, each dataset\nis encoded as a probability measure: \u03bc = \u03a3\u0390=1 \u03b1\u0390\u03b4\u03b1\u2081 and v = \u2211=1 bjdy; \u00b7 Let\n\u03a0\u03b1,. := {P \u2208 Rnxm: P1m = a}, \u041f.,\u044c := {P \u2208 Rr\u00d7m : PT1n = b}, \u03a0\u03b1,\u044c := \u03a0\u03b1,. \u2229 \u041f.,\u044c.\nThus, a,b is the set of transport plans (probabilistic coupling matrices) with marginals a and b.\nGiven a cost function c : X \u00d7 X \u2192 R+, define the cost matrix C\u2208 R\u00d7m via Cij = c(xi, yj). The\nKantorovich formulation Kantorovich (1942) of discrete OT, also called the Wasserstein problem,\nseeks a transport plan P of minimal cost:\nW(\u03bc, \u03bd) := \\min_{\\mathrm{P} \\in \\Pi_{a,b}} \\langle C, P \\rangle_F.\n(1)"}, {"title": "3 Factor Relaxation with Latent Coupling (FRLC) algorithm", "content": "3.1 Latent Coupling Factorization\nWe parameterize low-rank coupling matrices P\u2208 \u03a0\u03b1,\u044c(r) using a factorization introduced in Lin\net al. (2021), which we call the latent coupling (LC) factorization (Fig. 1). The key property of"}, {"title": "3.2 The Balanced FRLC Algorithm", "content": "We introduce an algorithm Factor Relaxation with Latent Coupling (FRLC), to compute a LC\nfactorization of minimum cost. We first describe the FRLC algorithm for the balanced Wasserstein\nproblem. Extensions to other and marginal constraints are discussed later. The FRLC objective\nfunction, for low-rank, balanced Wasserstein OT, is\nL_{LC}(Q, R,T) := \\langle C, \\mathcal{P}(Q,R,T) \\rangle_F,\n(8)\nwhere \\mathcal{P}(Q,R,T) is defined by (7). Since LCa,b(r) parameterizes la,b(r), problem (8) is equivalent\nto low rank problem (6). The FRLC algorithm is built from projections onto convex sets, described\nby constraints on the outer marginals alone for (Q, R) and by the inner marginals alone for T. Given\n(Q, R, T) \u2208 LCa,b(r), sub-couplings Q and R are constrained by:\n\\mathcal{C}_1(a) := \\{(Q, R,T) \\in \\mathbb{R}_+ : Q \\mathbf{1}_r = a\\}, \\mathcal{C}_1(b) := \\{(Q, R,T) \\in \\mathbb{R}_+ : R \\mathbf{1}_r = b\\}."}, {"title": "3.3 Initialization, convergence, and FRLC extensions", "content": "Full-rank random initializations of the sub-coupling matrices. We propose a new initialization\nof the sub-couplings (Q, R, T) for the LC-factorization in Algorithm 6.This generates a full-rank\ninitialization (Proposition F.1) in the set of rank-r couplings \u03a0\u03b1,6(r) and is accomplished by applying\nSinkhorn to random matrices. Our approach differs from Scetbon et al. (2021); Scetbon & Cuturi\n(2022) who use initializations for the diagonal factorization of Forrow et al. (2019), and are not\napplicable to a latent coupling that is non-diagonal, non-square, or with two distinct inner marginal."}, {"title": "4 Experimental Results", "content": "We compare FRLC 1 to existing low-rank and full-rank optimal transport algorithms on several\ndatasets: simulated datasets previously used in Tong et al. (2023) and Scetbon et al. (2021); a\nmassive spatial-transcriptomics dataset Chen et al. (2022); and a graph partitioning task Chowdhury\n& Needham (2021). Further details of each experiment (e.g. pre-processing, validation) are in\nAppendices K, L, and M. In the section below, LOT refers to the works of Scetbon et al. (2021, 2023,\n2022) and Latent OT refers to Lin et al. (2021)."}, {"title": "4.1 Evaluation of Low-rank Approximations for Balanced OT on Synthetic Data", "content": "We first compare the balanced OT version of FRLC with the the low-rank balanced OT algorithm\nLOT of Scetbon et al. (2021) on a synthetic dataset following Tong et al. (2023). The dataset consists\nof m = 1000 points from two moons and n = 1000 points sampled from eight 2D Gaussian densities\n(Fig. 2a). We solve the Wasserstein problem (1) with cost matrix C computed using the Euclidean\ndistance. The full-rank coupling matrix P has rank 1000, and we compute both FRLC and LOT\nsolutions with rank between 20 and 200. For each rank, we initialize FRLC adapting the deterministic\nrank-2 initialization proposed in Scetbon et al. (2021) and the random initialization of Alg. 6. We\ninitialize LOT using the rank-2 initialization and two other options in ott-jax Cuturi et al. (2022).\nWe find that FRLC obtains lower transport cost \u3008C, P) F with increasing rank (Fig. 2b) and consis-\ntently achieves lower transport cost than LOT across all ranks and all initializations. Specifically,\nstarting both methods at the same rank-2 initialization, FRLC consistently achieves a lower cost\nthan LOT for all ranks. Additionally, we observe smooth convergence of FRLC for both rank-2\ninitialization and the full-rank random initialization of Alg. 6 (Fig. 5).\nWe also evaluate FRLC and LOT on two datasets of Gaussian mixtures, one in 2-dimensions and\none in 10-dimensions, each with n = m = 5,000 points from two mixtures of Gaussians, following\nScetbon et al. (2021), with further details in Appendix K. We observe the same trend as the previous\nsimulation for both datasets (Fig. 2c, Fig. 7), with FRLC achieving lower transport costs than LOT\nacross all ranks and all initializations. In addition FRLC has half the runtime of LOT (CPU)\n\u2013 including the setup time of FRLC but excluding the setup time of LOT in ott-jax \u2013 on datasets\nof n = m = 1000 points from all three datasets with rank r = 100 (Table 2). At the same time\nFRLC achieves lower primal cost (C, P)F with tighter marginals ||P1n \u2013 a||2 and ||PT1m \u2013 b||2.\nLin et al. (2021) only solves a proxy for the rank-constrained Wasserstein problem, and thus is not\nthe focus of our comparisons. Nevertheless, we verify that on all synthetic experiments that FRLC\nachieves significantly lower primal OT cost than Latent OT (Table 5)."}, {"title": "4.2 Interpretation of the Latent Coupling and LC-Projection", "content": "We demonstrate the intepretability of the latent coupling T in the LC factorization. In both the LC\nfactorization and factored couplings, the sub-couplings Q and R each have associated barycentric\nprojection operators which coarse-grain input datasets Z(1), Z(2). In particular, the LC projection is\ndefined from the LC factorization as follows.\nDefinition 4.1 (LC-Projection). Let Q diag(1/gq)T diag(1/gR)RT be an LC factorization\nof of a coupling matrix P\u2208 \u03a0\u03b1,\u044c(r) computed from datasets Z(1) \u2208 Rnxd, Z(2) \u2208 Rm\u00d7d, with\nT\u2208 R1\u00d72. The LC-projections Y(1) and Y(2) of Z(1) and Z(2) are Y(1) := diag(1/gq)QTZ(1),\nand Y(2) := diag(1/9R)RTZ(2).\nBy interpreting any factored coupling (Q, R, g) as an LC factorization (Q, R, diag(g)), Defini-\ntion 4.1 describes the barycentric projections for both factorizations. We compare the projections of\nthe coupling computed by FRLC to those of LOT Scetbon et al. (2021) on a dataset containing 1000\nsamples from 2D-Gaussians centered at the 5th-roots of unity and 1000 samples from 2D Gaussians"}, {"title": "4.3 Evaluation on Spatial Transcriptomics Alignment", "content": "We compare FRLC and the algorithm (LOT-U) of Scetbon et al. (2023) (which solves unbalanced\nlow-rank Wasserstein, GW, and FGW problems) on the task of computing an alignment between\ncells from different time points during mouse embryonic development. Specifically, we compute\nan alignment between a spatial transcriptomics (ST) dataset of an E11.5 stage mouse embryo and\nan E12.5 stage mouse embryo Chen et al. (2022). Optimal transport is a popular approach to align\nsingle-cell Schiebinger et al. (2019) and spatial trancriptomics datasets Zeira et al. (2022); Liu et al.\n(2023); Klein et al. (2023). In single-cell transcriptomics, one measures a gene expression vector\nfor each cell, and in spatial transcriptomics one additionally measures the 2D location of each cell.\nThe cost matrix C describes the difference between gene expression vectors and intra-domain cost\nmatrices A and B are derived from the 2D coordinates within each slice. Therefore, OT problems of\nW, GW, and FGW objectives can be solved and the coupling matrix represents the cell-cell alignment\n(Appendix M). However, computation of a full-rank OT solution is not feasible in our large-scale\ndataset: the E11.5 slice has about 30,000 cells while the E12.5 slice has about 50,000 cells.\nWe evaluate the alignments by assessing performance on two prediction tasks from Scetbon et al.\n(2023): (1) a gene expression prediction task where we predict the expression of a gene in E12.5\nfrom expression of the gene in E11.5 using the alignment; (2) a cell type prediction task where we\npredict the cell types of E12.5 from the cell type clustering of E11.5 (Appendix M). We evaluate\nthe accuracy of the gene expression prediction task through the Spearman correlation \u03c1 between\nthe predicted expression and the ground truth expression of 10 test marker genes. We evaluate the\naccuracy of the cell type prediction task by computing the Adjusted Rand Index (ARI) and Adjusted\nMutual Information (AMI) between the predicted cell types and the cell types derived in the original\npublication Chen et al. (2022). Being a comparison between different objectives, this relies on\ndownstream metrics. For completeness, we validate the efficacy of FRLC on directly minimizing the\nbalanced Wasserstein cost (C', P) F against Scetbon et al. (2021) in Figure 8.\nFor a direct comparison, we use FRLC to solve the same unbalanced problems (denoted FRLC-U).\nWe perform an extensive grid search (Appendix M.3) to pick the best hyperparameters (including\nrank < 30,000) for all algorithms. Scetbon et al. (2023) previously showed that unbalanced FGW\nalgorithm has the best performance on ST alignment. We find that unbalanced FRLC achieves\ncomparable or better results than the previous state-of-the-art unbalanced low-rank method on all\nthree objectives (Table 4). We also solve a semi-relaxed version of each problem motivated by the"}, {"title": "4.4 Additional Experiments", "content": "We evaluate FRLC on an unsupervised graph partitioning problem Chowdhury & Needham (2021) on\nfour real-world graph datasets Yang & Leskovec (2012); Yin et al. (2017); Banerjee et al. (2013). We\nbenchmark the performance of the semi-relaxed and GW settings of FRLC against (1) GWL Xu et al.\n(2019), solving a balanced GW problem; (2) SpecGWL Chowdhury & Needham (2021) using the\nheat kernel on the graph Laplacian as the cost matrix. We find FRLC achieves the better clustering\nperformance than GWL and SpecGWL on 9/12 and 11/12 of the datasets (Table 3 and Appendix L)."}, {"title": "5 Discussion", "content": "We provide comparison of existing low-rank solvers in Table 1. The FRLC algorithm has a number\nof advantages, including (1) coarsening a full-rank plan P to non-diagonal latent coupling T; (2)\nminimizing the primal OT problem for general cost C rather than a barycenteric problem; (3)\noptimizing only sub-couplings; and (4) using Sinkhorn alone as the sub-routine for low-rank OT.\nWhile we argue these are substantial advantages, FRLC has limitations which warrant follow-up work.\nIn particular, three key limitations of our work, common to the existing low-rank OT algorithms,\nare: (1) selecting values of the latent coupling ranks; (2) strengthening the convergence criterion; (3)\naddressing sensitivity to the initialization from non-convexity of the objective. A limitation specific\nto our work is the selection of the \u03c4 hyperparameter controlling the smoothness of the trajectory.\nThese and other limitations are discussed in Section N of the Appendix. Another direction for further\ninvestigation is to better understand what structure LC factorizations capture when the optimal plan is\nknown to have full rank, e.g. when the Monge map exists, as has been explored by Liu et al. (2021)."}, {"title": "6 Conclusion", "content": "We introduce FRLC, an algorithm to compute low-rank optimal transport plan from the latent\ncoupling (LC) factorization. FRLC handles different OT objective costs and relaxations of the\nmarginal constraints. Moreover, the LC factorization provides an interpretable coarse-graining\nof the full transport plan and its marginals through the mapping (P,a,b) \u2192 (T,9Q,9R). We\ndemonstrate the superior performance of FRLC compared to state-of-the-art low-rank methods on\nreal and synthetic datasets."}, {"title": "A Low-rank optimal transport", "content": "A.1 Low-rank factorizations\nThe set of low-rank couplings. Given M\u2208 Rnxm, the nonnegative rank of M is the least number\nof nonnegative, rank-1 matrices that sum to M:\nrk+(M) = \\min_{r \\geq 1} \\left\\{ M = \\sum_{i=1}^r M_i, \\text{ such that rk}(M_i) = 1 \\text{ and } M_i > 0 \\text{ for all } i \\right\\}.\nLet a \u2208 \u0394n, b \u2208 Am be probability vectors, and let la,b(r) denote the set of rank-r coupling\nmatrices with marginals a and b:\n\\Pi_{a,b}(r) = \\{P \\in \\mathbb{R}^{n \\times m}_+ : P \\mathbf{1}_m = a, \\mathbf{P1}_n = b, \\text{ rk}_+(P) \\leq r\\}.\nTo optimize any cost over la,b(r), one requires a parameterization of this set.\nFactored couplings. The factored coupling parameterization of Ila,b(r) introduced in Forrow et al.\n(2019), and used by Scetbon et al. (2021); Scetbon & Cuturi (2022); Scetbon et al. (2022, 2023) is\n\\mathcal{FC}_{a,b}(r) := \\{(Q, R, g) \\in \\mathbb{R}_+^{n \\times r} \\times \\mathbb{R}_+^{r \\times m} \\times (\\mathbb{R}_+)^r : Q \\in \\Pi_{a,g}, R \\in \\Pi_{b,g}\\}.\nCohen & Rothblum (1993) show that any P\u2208 \u03a0a,b(r) may be decomposed as P = Qdiag(1/g)RT\nfor some triple (Q, R, g) \u2208 FC. Thus, for cost matrix C\u2208 Rn\u00d7m, the general low-rank optimal\ntransport problem is equivalent to an optimization over factored couplings:\n\\min_{P \\in \\Pi_{a,b}(r)} \\langle C, P \\rangle_F = \\min_{(Q,R,g) \\in \\mathcal{FC}_{a,b}(r)} \\langle C, Q \\text{diag}(1/g)R^T \\rangle_F.\n(11)\nLatent coupling factorization. The latent coupling parameterization of la,b(r) introduced in Lin\net al. (2021), and used in the present work is\n\\mathcal{LC}_{a,b}(r) := \\{(Q, R, T) \\in \\mathbb{R}_+^{n \\times r} \\times \\mathbb{R}_+^{r \\times m} \\times \\mathbb{R}_+^{r \\times r} : Q \\in \\Pi_{a,.}, R \\in \\Pi_{b,.}, T \\in \\Omega_{g_Q,g_R}\\},\nwhere gQ, GR are the inner marginals of Q and R.\nLatent coupling diagonalization. The LC-factorization recovers the factorization of Forrow et al.\n(2019) as a sub-case. While the diagonal factorization of previous works cannot be directly converted\nto the LC-factorization, the LC-factorization can easily recover the diagonal factorization. In\nparticular, taking Q' \u2190 Q diag(1/gq)T one can refactor\nP = Q \\text{diag}(1/g_Q) T \\text{diag}(1/g_R)R^T = Q' \\text{diag}(1/g_R)R^T\nor alternatively taking R' = Rdiag(1/9R)TT may refactor as\nP = Q \\text{diag}(1/g_Q) T \\text{diag}(1/g_R)R^T = Q \\text{diag}(1/g_Q)(R')^T\nSo that instead of returning (Q, R, T) one may alternatively return (Q, R,T) \u2192 (Q', R, diag(gr))\nor (Q, R, T) \u2192 (Q, R', diag(g)) to recover the Forrow et al. (2019) factorization. An example of\nthis diagonal conversion is offered in Figure 12."}, {"title": "A.2 Balanced low-rank optimal transport", "content": "The FRLC optimization problem Our optimization problem is over the variables (Q, R, T) and\ndefined as follows:\n\\min_{(Q,R,T) \\in \\mathcal{LC}_{a,b} (r)} L_{LC}(Q, R,T),\n(12)\nwhere our objective function LLC is\nL_{LC}(Q, R,T) = \\langle C, Q(\\text{diag}(1/Q^T\\mathbf{1}_n))T(\\text{diag}(1/R^T\\mathbf{1}_m))R^T \\rangle,\n(13)\nGiven (Q, R, T) \u2208 LCa,b(r), sub-couplings Q and R are constrained by:\n\\mathcal{C}_1(a) := \\{(Q, R,T) \\in \\mathbb{R}_+ : Q \\mathbf{1} = a\\}, \\mathcal{C}_1(b) := \\{(Q, R,T) \\in \\mathbb{R}_+ : R \\mathbf{1}_r = b\\},"}, {"title": "B Block-Coordinate steps for the OT sub-problems", "content": "We use a latent non-diagonal coupling instead of an inner diagonal coupling diag(g) of the form\nof Forrow et al. (2019). This allows us to loosen the constraint that the inner marginals have to be\njoined by a common coupling QT1n = RT1m = g. The fundamental advantage of this choice is\nthat we can decouple the convex-optimization problem for (Q, R, T) entirely. One can simply solve\nfor the optimal Q and R independently, yield the associated inner marginals for each QT1n = 9Q\nand RT1m = 9R, and then find the optimal T which links the two. This link is provided by the\naforementioned form of the problem, where:\nP = QXRT\nFor Q, R in either the appropriate set of couplings or a relaxation thereof (which we will describe\nshortly). X is related to T by:\nX = diag(1/gq)T diag(1/gR)\nAnd, T\u2208 Ngq.gr consistently for all cases. As the semi-relaxed case is intermediate between\nfully-relaxed and balanced, it has ideas which generalize to both directly. As such, we use it as the\nleading example again. As in Scetbon et al. (2021), we take proximal-steps of the form:\n\\min_\\zeta \\left( \\langle \\nabla \\mathcal{L}(\\zeta) | \\zeta \\rangle_F + \\frac{1}{\\gamma_k} KL(\\zeta || K^{(k)}) \\right)\nWhere these steps are now in block-wise fashion on (Q, R) and T, rather than joint. One may\nidentify for each sub-factor in (Q, R) and T a linearized gradient as before, which yields a set of\nobjectives which each solve an independent optimal-transport for the sub-factors. In particular, we\nhave that:\n\\langle QXRT, C \\rangle_F = \\text{Tr} [QXRTCT] = \\langle CRXT, Q \\rangle_F\n\\langle QXRT, C \\rangle_F = \\text{Tr} [QXRTCT] = \\langle CTQX, R \\rangle_F\n\\langle QXRT, C \\rangle_F = \\text{Tr} [RTCTQX] = \\langle QTCR, X \\rangle_F\nA linearization in the left-slot of the inner product as \\langle Q,CRX(Qk)T \\rangle := \\langle Q,CRXT \\rangle or\n\\langle CTQX (Rk), R \\rangle_F := \\langle CTQX, R \\rangle_F is common practice for quadratic problems. In this case, the\ndirectional derivative of Q and R in the matrix-direction V are respectively:\n\\mathcal{D} \\langle CRXT, Q \\rangle_F \\circ (V) = \\langle CRXT, V \\rangle_F \\Rightarrow \\nabla \\mathcal{Q} L = CRXT\n\\mathcal{D} \\langle CTQX, R \\rangle_F \\circ (V) = \\langle CTQX, V \\rangle_F \\Rightarrow \\nabla \\mathcal{R} L = CTQX\nWithout this linearization assumption on X, the full gradient may be evaluated as well. In particular,\nwe note that for diag\u22121(\u00b7) the matrix-to-vector extraction of the diagonal, the directional derivative\non Q is:\n\\mathcal{D} \\langle C,QXRT \\rangle_F \\circ V = \\langle CRXT, V \\rangle_F + \\langle C,Q \\mathcal{DXT}_Q \\circ (V)RT \\rangle_F\n= \\langle CRXT - \\mathbf{1}_n \\text{diag}^{-1} ((CRXT)^T Q \\text{diag}(1/g_Q))^T, V \\rangle_F\nThus, without the linearization assumption one may use product rule on X as an implicit function of\nQ (resp. R) to take the total derivative:\n\\nabla_{\\mathcal{Q}} L_{FRLC} = CRXT - \\mathbf{1}_m \\text{diag}^{-1} ((CRXT)^T Q \\text{diag}(1/g_Q))^T\nLikewise for R,\n\\mathcal{D} \\langle C,QXRT \\rangle_F \\circ V = \\langle CTQX, V \\rangle_F + \\langle C,Q \\mathcal{DX}_R \\circ (V)RT \\rangle_F\n= \\langle CTQX - \\mathbf{1}_m \\text{diag}^{-1} (\\text{diag}(1/g_R) R^T CTQX)^T, V \\rangle_F,\nand so\n\\nabla_{\\mathcal{R}} L_{FRLC} = CTQX - \\mathbf{1}_m \\text{diag}^{-1} (\\text{diag}(1/g_R) R^T CTQX)^T.\nBoth the W and GW problem have these rank-one perturbations of the gradient from the derivative\nwith respect to X."}]}