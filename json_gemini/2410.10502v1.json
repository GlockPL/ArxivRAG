{"title": "A Practical Approach to Causal Inference over Time", "authors": ["Martina Cinquini", "Isacco Beretta", "Salvatore Ruggieri", "Isabel Valera"], "abstract": "In this paper, we focus on estimating the causal effect of an intervention over time on a dynamical system. To that end, we formally define causal interventions and their effects over time on discrete-time stochastic processes (DSPs). Then, we show under which conditions the equilibrium states of a DSP, both before and after a causal intervention, can be captured by a structural causal model (SCM). With such an equivalence at hand, we provide an explicit mapping from vector autoregressive models (VARs), broadly applied in econometrics, to linear, but potentially cyclic and/or affected by unmeasured confounders, SCMs. The resulting causal VAR framework allows us to perform causal inference over time from observational time series data. Our experiments on synthetic and real-world datasets show that the proposed framework achieves strong performance in terms of observational forecasting while enabling accurate estimation of the causal effect of interventions on dynamical systems. We demonstrate, through a case study, the potential practical questions that can be addressed using the proposed causal VAR framework.", "sections": [{"title": "1 Introduction", "content": "Dynamical systems often exhibit complex behaviors that unfold over time, leading to delayed responses and feedback loops. Importantly, understanding the causal effect of interventions within such systems is crucial across disciplines such as climate (Runge et al. 2019) and social sciences (Wunsch et al. 2022), where different time scales play a central role. For instance, monetary policy adjustments may have immediate effects on consumer spending, but their impact on inflation, employment, and economic growth only becomes evident in the medium-/long-term. Similarly, the consequences of human actions on climate change may take decades to manifest, with the risk of endorsing public policies that underestimate their relevance. To address these issues, it is essential to estimate the causal effect of interventions, or generally, to perform causal inference over time.\nFrom the perspective of causality, Structural Causal Models (SCMs) provide a formal framework to perform causal inference from cross-sectional data. However, adapting existing methods to capture temporal dynamics remains a challenge (Bongers et al. 2021). Alternatively, temporal models, such as autoregressive models, offer practical methods for time-series analysis and forecasting (L\u00fctkepohl 2005), but their formalization of causal effects is limited. First, they model interventions as shocks applied at a specific point in time, with effects that fade away after a certain period (Hyv\u00e4rinen et al. 2010; Moneta et al. 2011). Second, they rely on Granger causality (Granger 1969) which is concerned with how well one variable can predict another rather than identifying causal relationships between them.\nOur work combines the strengths of both frameworks, i.e., SCMs and autoregressive models, to enable robust reasoning about the causal effect of interventions on dynamical systems over time. To that end, we first introduce a formal definition of causal interventions on discrete-time stochastic processes (DSPs), proposing two alternatives, additive and forcing interventions. Second, we establish conditions under which the equilibrium state of a DSP can be represented by an SCM. Third, we develop a framework that maps VARs to linear SCMs, handling potentially cyclic structures and unmeasured confounders. Finally, our practical framework for causal inference over time from observational time-series data is empirically validated on synthetic and real-world datasets.\nThe works most closely related to ours are these from Mooij, Janzing, and Sch\u00f6lkopf (2013) and Bongers, Blom, and Mooij (2018), as they theoretically connect dynamical systems to the causal semantics of SCMs via the equilibration of deterministic and random differential equations, and thus are capable of modeling cyclic causal mechanisms (Bongers et al. 2021). Our approach differs from this line of work in two key aspects: i) we focus on discrete-time dynamical systems parameterized using stochastic equations which, as stated by Bongers, Blom, and Mooij (2018), become particularly challenging for continuous-time processes; and ii) our mapping from autoregressive DSPs to SCMs provides not only a theoretical but also, to the best of our knowledge, the first data-driven framework for performing causal inference over time in dynamical systems."}, {"title": "2 Preliminaries and background", "content": ""}, {"title": "2.1 Structural Causal Models", "content": "A SCM $M = (F, E)$ determines how a set of $d$ endogenous (observed) random variables $X = \\{X^{(1)},..., X^{(d)}\\}$ are obtained from a set of exogenous variables $E := \\{E_1,..., E_d\\}$, with prior distribution $p(E)$, via a set of structural equations $F := \\{X^{(i)} := f_i(PA^{(i)}, E^{(i)})\\}_{i=1}^d$. Each $f_i$ computes $X^{(i)}$ from its causal parents PA(i) \u2282 X and a set $E^{(i)} \u2282 E$. We refer to $X$ as a solution of $M$. We assume $PA^{(i)}$ to be minimal, i.e., it only contains variables $X^{(i)}$ such that $\u2202_{X^{(j)}} f_i \u2260 0$. This formulation extends the definition in (Pearl 2009) to include cycles as in (Bongers, Blom, and Mooij 2018).\nA SCM $M$ induces a directed graph $G_M = (V,E)$ that describes the functional dependencies in $F$: $V$ is the set of nodes for which $V_i$ represents $X^{(i)}$ and $E$ is the set of the edges $(V_i, V_j) \u2208 E \u2194 X^{(i)} \u2208 PA^{(j)}$."}, {"title": "Intervention", "content": "Besides describing the observational distribution $p(X)$, SCMs allow answering interventional queries about the effect of external manipulations, and enable counterfactual queries assessing what would have happened to a particular observation if one observed variable $X^{(i)}$ had taken a different value. An intervention $I$ on a SCM $M$ yields a new SCM $M^I$ for which one or more mechanisms $f_i(PA^{(i)}, E^{(i)})$ change to $f'_i(PA'^{(i)}, E'^{(i)})$, where $PA'^{(i)} \u2286 PA^{(i)}$ and $E'^{(i)} \u2286 E^{(i)}$. We refer to a hard intervention when $f'_i$ is replaced by a constant value $\u03b6^{(i)}$, and $PA'^{(i)} = E'^{(i)} = \u2205$. This type of intervention is denoted by the do-operator do$(X^{(i)} = \u03b1^{(i)})$. On the other hand, we refer to a soft intervention when at least one argument of $f_i$ is retained. The causal effect $CE$ of an intervention is evaluated in terms of differences between the values of the observable variables before and after the intervention $I$, i.e.,\n$CE_I^Z = E[X_I - X]$"}, {"title": "2.2 Discrete-time Stochastic Processes", "content": "A discrete-time (vector) stochastic process (DSP) is a function $X : T \u00d7 \u03a9 \u2192 \u211d^d$ where $t \u2208 T$ is a time index in $\u2124$, such that $X_t$ (which denotes $X(t,\u00b7)$) is a random variable on a probability space $(\u03a9, \u2131, \u2119)$. We refer to $X(\u03c9)$ (which denotes $X(\u00b7,\u03c9)$) as a realization or trajectory of $X$ and denote the $i$-th component of $X$ with $X^{(i)}$. Every DSP can be described through a difference equation (DE), i.e., a recurrence relation that allows computing $X_t$ based on its past values. DEs can be categorized into three types (Bongers, Blom, and Mooij 2018): ordinary difference equations (ODE) describing deterministic processes; random difference equations (RDE), which involve randomness in the initial state $X_0$ and in the evolution parameters (see App. A); and stochastic difference equations, which describe inherently stochastic trajectories.\nA stochastic difference equation (SDE) describes a DSP via a functional relationship of the form\n$X_t = f(X_{<t}) + g(X_{<t}) \u2299 \u03b5_t$,"}, {"title": "2.3 Vector Autoregressive models", "content": "In this paper, we focus on a specific type of SDE, the VAR model (Kilian and L\u00fctkepohl 2017).\nConsider a $d$-dimensional vector-valued stationary time series $\\{X_0,..., X_T\\}$ generated by a VAR model with lag $p$, where a lag represents the number of previous time steps used to predict the current value of each variable. Specifically, the VAR($p$) model is defined by\n$X_t = \u03bd + A_1 X_{t-1} + \u2026 + A_p X_{t-p} + u_t$,\nwhere $\u03bd$ is a $d$-dimensional vector of intercept terms, $\\{A_i\\}_{i=1}^p$ are ($d \u00d7 d$) matrices and $u_t$ is a $d$-dimensional white noise term. If the process $X_t$ is stable and stationary (Hamilton 1994), Equation 3 can also be written as\n$A(L)X_t = \u03bd + u_t$,\nwith $A(L) := I_d - A_1 L - \u00b7\u00b7\u00b7 - A_p L^p$, where $L$ is the lag operator such that $LX_t = X_{t-1}$ and $I_d$ is a $d$-dimensional identity matrix.\nA key limitation of VARs is the inability to interpret the system in causal terms since the components of $u_t$ are cross-correlated and act as hidden confounders. A common approach to overcome this problem is to orthogonalize the noise terms. In this context, the process of causal discovery, i.e., inferring the causal structure of the data, is analogous to the one of SCMs (Hyv\u00e4rinen et al. 2010; Moneta et al. 2013; Geiger et al. 2015; Malinsky and Spirtes 2018), and involves identifying a triangular matrix $A_0$ such that $\u03b5_t = A_0 u_t$ consists of mutually uncorrelated elements. The transformed VAR, commonly known as the Structural VAR (SVAR) model in the literature (Kilian and L\u00fctkepohl 2017), is defined by $A_0 X_t = A_0 \u03bd + A_1 X_{t-1} + \u00b7\u00b7\u00b7 + A_p X_{t-p} + \u03b5_t$, where $A_i = A_0^{-1} \u00c2_i$. From a modeling perspective, VAR and SVAR are equivalent, as any SVAR can be expressed in its reduced-form VAR by computing $A_i = A_0^{-1} \u00c2_i$ for $i = 0, ..., p$ in Eq. 3. Notably, choosing one over the other does not affect its causal interpretation, provided that $A_0$ is known. For simplicity, in this work, we adopt the VAR notation, to introduce a novel framework for causal inference over time, which complements the SVAR's causal discovery approach."}, {"title": "3 Causal perspective on Discrete-time Stochastic Processes", "content": "This section provides the theoretical basis for causal inference over time. First, we formally define causal interventions on SDEs (\u00a73.1). Then, we show how a SCM can be considered a compressed description of the asymptotic behavior of an underlying dynamical system (\u00a73.2)."}, {"title": "3.1 Causal Interventions on SDEs", "content": "We define an intervention $I$ on a SDE $D$ as a modification of one or more component equations denoted by the mapping:\n$I: f_i(PA_{<t}^{(i)}) + g_i (PA_{<t}^{(i)}) \u2299 \u03b5_t \u2192 f'_i(PA'^{(i)}_{<t}) + g'_i (PA'^{(i)}_{<t}) \u2299 \u03b5_t, \u2200t \u2265 t_I$,\nwhere $PA'^{(i)} \u2286 PA^{(i)}$. Unlike SCMs, the intervention applies starting from a specific time $t_I$. In other words, the process follows the original equations for $t < t_I$ and the modified ones for $t > t_I$. We denote the modified SDE as $D^I$ to generalize Eq. 1 to account for time. To differentiate between interventions on a SCM $M$ and on a SDE $D$, $I_M$ and $I_D$ will be respectively adopted when necessary.\nLet $X$ be a solution of a specific SDE $D$. We define the causal effect at time $t$ of an intervention $I$ as\n$CE_t := E[X_t^I - X_t|X_{<t_I}]$,\nThe interpretation of $CE_t$ is closely related to the causal effect of an intervention on a SCM (Eq. 1), $CE_I^Z$: while the latter measures the causal effect of an exogenous intervention, $CE_t$ does so for any time step $t$ of the DSP, i.e., it measures the causal effect of an intervention over time. Importantly, as we will show in the next section, $CE_t \u2192 CE_I^Z$ as $t\u2192\u221e$, i.e., there is an asymptotic correspondence between the two quantities."}, {"title": "3.2 Mapping SDEs to SCMS", "content": "Given an SDE $D$ and its solution $X$, we study the conditions on $D$ such that: i) $X_t$ converges in distribution to $X_\u221e$ as $t\u2192\u221e$; and ii) there exists an SCM $M$ such that $X_\u221e$ is a solution of $M$ and, for every intervention $I$, it holds that $(X^I)_M = (X_D^I)_\u221e$. While i) is automatically satisfied by any finite memory stationary process, ii) requires more careful analysis, as discussed below.\nConsider the stable bivariate system defined by the equations $X_t = \u03b5_t^X$, $Y_t = 0.5 \u00b7 X_{t\u22121} + \u03b5_t^Y$. For every $t$, $X_t$ and $Y_t$ are independent of each other. Consequently, the joint distribution $p(X_t, Y_t)$ cannot capture the causal dependencies of the system ($X$ causes $Y$). The lack of causal information in the cross-sectional dimension arises because the variables are localized in time; their values change rapidly, leading to minimal or no correlation with their past values. On this specific point Janzing, Rubenstein, and Sch\u00f6lkopf (2018) provide an explicit negative result: without first making the variables de-localized in time, there is no SCM that can capture the SDE. In fact, our definition of intervention (Eq. 5) acts on a variable of the system for a prolonged and indefinite period.\nTo overcome this limitation, (Janzing, Rubenstein, and Sch\u00f6lkopf 2018) propose a transformation of $X_t$ based on a frequency analysis of the time series. Instead, our choice is inspired by the long-run normalized mean via the transformation $T : DSP \u2192 DSP$ defined by\n$T(X)_t := Z_t = \u03bc + \\frac{1}{\\sqrt{t}} \\sum_{i=1}^t (X_i - \u03bc)$,\nwhere $\u03bc := E[X]$. Moreover, $E[Z_\u221e] = E[X_\u221e] = \u03bc$ so that for every intervention $I$, $CE^I(t) \u221d CE_\u221e^I$ (Eq. 6) yields the same values. However, unlike $X$, $Z$ can be mapped into an SCM that precisely models its distribution shift over any intervention, thereby satisfying property ii), represented as the commutativity of the diagram in Fig. 1.\nIt is important to clarify that $Z_t$ is not the process of interest, and the focus of the causal analysis remains on $X_t$. However, due to the equivalence of long-run causal effects calculated in both processes, and the ability to associate $Z_t$ with the SCM that models these effects, $Z_t$ serves as a convenient intermediate mathematical tool. To demonstrate how this transformation ensures these desirable properties, we will focus on the subclass of linear systems, particularly on VAR models. The reason for this choice is twofold. First, linear models, despite their simplicity, are still on par performance-wise with state-of-the-art Machine-Learning based forecast techniques (Toner and Darlow 2024), in particular when dealing with stochastic time series (Parmezan, Souza, and Batista 2019). Second, the mathematical treatment of interventions and the estimation of causal effects is particularly straightforward to implement and interpret, making this a useful first step for a possible extension to the nonlinear case."}, {"title": "4 From Vector Autoregressive models to Structural Causal Models", "content": "In this section, we show that linear SCMs can model the long-term effects of stable VARs, explaining the properties of its DSP equilibrium (\u00a74.1). Then, we provide implementations of two types of causal interventions, leveraging the strengths of the VAR framework (\u00a74.2). Finally, we discuss the practical implications of our theoretical results (\u00a74.3)."}, {"title": "4.1 Mapping from VARs to SCMS", "content": "We provide the explicit mapping from VARs to linear SCMs in the following theorem (proved in App. B.2).\nGiven a stable VAR($p$) $D$ defined by Eq. 3, there exists a linear SCM $M$ with structural equations\n$X = A X + \\tilde{u}$,\nwhere $A := [A_1 +\u2026\u2026+ A_p]$ and $\\tilde{u} ~ N(0, \u03a3_{\\tilde{u}})$, such that, given the transformation $Z_t = \\frac{1}{t} \\sum_{i=1}^t X_i$, the following properties hold:\n1. $D$ and $M$ share the same causal graph, i.e., $G_M = G_D$;\n2. The observational distribution induced by $D$ at equilibrium $p(Z_\u221e)$ is equal to the one induced by $M$, $p(X)$;\n3. The interventional distribution $p(Z_\u221e^{I_D})$ is equal to the one induced by the same intervention on $M$, $p(X^{I_M})$.\nNote that due to the influence of time in VARs, the equivalent SCMs at equilibrium, while linear, may lead to cycles in the causal graph (see, e.g., Fig. 2c) and correlations between the exogenous variables, captured by the full covariance matrix $\u03a3_{\\tilde{u}}$ in Eq. 8. Note also that the above Theorem implies that there is a direct relationship between interventions on DSPs, $I_D$, and interventions on SCMs, here denoted by $I_M$. Refer to App. B.2 for further details."}, {"title": "4.2 Implementation of Causal Interventions", "content": "Different application scenarios may need different types of interventions. Consider a government's fiscal policy. In such a setting, a feasible approach would be to implement an additive intervention in the form of an annual tax increase of, e.g., 300 euros per household on top of existing taxes. Alternatively, in other scenarios, e.g., when studying the effect of the key European Central Bank's interest rate (Belke and Polleit 2007), a more natural choice is to implement a forcing intervention that enforces the convergence of an observed variable (e.g., interest rate) to a target value. In the following, we propose an implementation for VARs of these two forms of interventions, showing their effects on the system and discussing their stability conditions.\nGiven a stable VAR($p$) as in Eq. 4, we define an additive intervention $I_a$ at time $t_0$ with force $F$ as the mapping:\n$I_a: A(L)X_t = \u03bd + u_t \\\\\nA(L)X_t = \u03bd + u_t + \\mathbb{I}(t > t_0)F,$\nwhere $\\mathbb{I}(t > t_0)$ is the indicator function, which equals 1 if $t \u2265 t_0$, otherwise 0. In other words, we perform a translation while keeping the process dynamics unchanged. In such case, the temporal causal effect $CE_t$ is deterministic and takes values $CE_t = 0$ for $t < t_0$ while, for $k \u2265 0$:\n$CE_{t_0+k} = \\sum_{l=0}^{k} \u03a6_l F$,\nThis type of intervention is not depending on the specific trajectory. The same property can be observed on the linear SCM associated with the process, defining the intervention in a similar way: $X = A X + \\tilde{u}$ changes into $X = A X + F + \\tilde{u}$.\nAdditive intervention preserves the stability regardless of the value of $F$, since $A(L)$ does not change. See App. B.1 for stability conditions of VARs.\nWe define a forcing intervention $I_f$ at time $t_0$ with force $F$ and target value $X$ as:\n$I_f : A(L)X_t = \u03bd + u_t \\\\\nA(L)X_t = \u03bd + u_t + \\mathbb{I}(t > t_0)F \u2299 (X - X_t)$.\nWe assume $F$ to be positive in each component. This intervention acts as an attraction towards $X$, and $F$ modulates the intensity of the attraction force. Applying an intervention on a single component $X^{(i)}$ toward the fixed value $X$ and letting $F^{(i)} \u2192 +\u221e$ yields the do operator do$(X^{(i)} = X)$. We refer to (Mooij, Janzing, and Sch\u00f6lkopf 2013) for a detailed discussion of this point.\nA forcing intervention $I_f$ perturb the system dynamics by modifying the operator $A(L)$. Specifically, by shifting the term $F \u2299 X_t$ to the left of the equation and rewriting it in matrix form as $F_{diag} X_t$, we obtain $A'(L) := A(L) + F_{diag}$. Hence, the stability of the intervened system is not guaranteed, and it is necessary to verify that all the eigenvalues of $A'(L)$ are still inside the unit circle. Intuitively, the stability of an observational system often relies on negative feedback loops. Fixing one variable can disrupt this balance, leading to runaway behavior. For example, turning off a pressure release valve in a pressurized tank can cause the pressure to build up uncontrollably, eventually leading to an explosion."}, {"title": "4.3 Practical implications", "content": "Our formulation of causal interventions on VARs differs from the standard approach based on Granger causality by being closer to that of SCMs. Consequently, it enables the generalization of interventional and counterfactual queries to account for time (see App. C). That is, it allows for answering the following causal questions:\nWhat are the expected effects on an individual trajectory (or a population) when intervening in the present, and how do they vary over time?\nWhat would have happened to an individual trajectory if an intervention had been applied at a specific point in the past? What state would it be in now?\nBoth causal queries acquire a meaning embedded in the temporal dimension in terms of forecasting for the future (\u00a75.2) and retrospection for the past (App. D.3), respectively.\nVARs, despite their linearity, possess a high level of expressiveness (Kilian and L\u00fctkepohl 2017). In fact, the Wold decomposition Theorem (Wold 1938) implies that the dynamics of any purely non-deterministic covariance-stationary process can be approximated arbitrarily well by an autoregressive model, making them universal approximators. In practice, linear autoregressive models are broadly used in time-series analysis. Yet, we intend to explore non-linear DSPs in future work, as they may lead to better convergence rates and allow for causal interpretation of a broader family of dynamical models.\nTo properly understand complex systems, it is often useful to model feedback loops between their variables. Time-series models naturally capture this property, while SCMs require significant reformulation. The theory of cyclic SCMs has seen a significant advancement in recent years (Bongers et al. 2021), but practical approaches, both for causal discovery and causal inference, are still underdeveloped (Bongers et al. 2016; Lorbeer and Mohsen 2023). Our formalization of causal inference on VARs is a step forward in this direction.\nFitting VARs estimation is typically performed using ordinary least squares. Various alternative methods are available, both in terms of constrained optimization (e.g., to use prior knowledge about some coefficients of the VAR matrices (Sims 1980)) and within a Bayesian framework (Koop, Korobilis et al. 2010). Refer to (L\u00fctkepohl 2005, chapters 3,4,5) for a comprehensive discussion. Importantly, although VARs are most commonly used on time-series data (i.e., data from one single unit across a period of time), there are approaches tailored to the analysis of panel data (i.e., the evolution of many units over time) (Sigmund and Ferstl 2021); and cross-sectional data (i.e., many individuals at a single point of time), provided that they have at least some proxy variables of time (Deaton 1985). Such approaches open up a promising line of future work that can further generalize VARs applicability for causal reasoning over time."}, {"title": "5 Empirical evaluation", "content": "In this section, we evaluate VAR models' accuracy and expressiveness in multivariate time series, focusing on two forecasting dimensions: observational (\u00a75.1) and interventional (\u00a75.2). Additional results and in-depth descriptions can be found in App. D.\nWe rely on two synthetic datasets, German and Pendulum, and the real-world Census dataset."}, {"title": "7 Concluding remarks", "content": "In this work, we have established a link between discrete-time dynamical systems at equilibrium and SCMs. Moreover, we have provided an explicit procedure for mapping VARs to linear SCMs and demonstrated that, under specific model stability conditions, interventions on the dynamical system and the SCM yield equivalent results. To conduct causal inference over time, we have introduced two classes of interventions (additive and forcing) for VARs.\nWhen systems exhibit strongly nonlinear dynamics, linear VARs may prove less effective than alternative nonlinear approaches. Moreover, our framework requires prior knowledge of the causal graph. In scenarios where this information is lacking, the process of causal discovery can present significant challenges.\nWe will investigate the use of non-linear DSPs, as they may lead to better convergence rates and allow for causal interpretation of a broader family of dynamical models. Moreover, our work opens several interesting research directions (\u00a74.3 for concrete examples) and applications (e.g. causal inference over time in high-dimensional contexts such as climate science)."}, {"title": "A Difference Equations and Stochastic Processes Equilibration", "content": "Difference Equations can serve as discrete approximations of differential equations, sharing some fundamental theoretical properties. In many applications, the former are approximation tools to simulate the latter numerically. As with differential equations, it can be beneficial to introduce stochastic components into the equation to model phenomena that are not entirely predictable. This unpredictability may stem from incomplete knowledge of the relevant variables of the process or its intrinsic randomness. We will denote by DE the class of difference equations in general, regardless of whether they are deterministic or not. Including stochastic components in differential equations gives rise to various classes of equations. This section introduces the notions of Ordinary and Random Difference Equations. Understanding these concepts is helpful for contextualizing our work, and for clarifying how it extends the ideas presented in (Mooij, Janzing, and Sch\u00f6lkopf 2013)."}, {"title": "A.1 Difference equations", "content": "An Ordinary Difference Equation (ODE) is an expression that describes the evolution of an indexed variable $xt$ through a functional relationship\n$xt = f(x_{<t})$,\nSpecifically, a $p$th-order ODE is an expression where the preceding variables of $xt$ include up to $xt-p$, i.e, $X_{<t} = \\{Xt-i\\}_{i=1}^p$.\nA Random Difference Equation (RDE) is a DE of the form\n$Xt = f(X_{<t}, \u03b5)$,\nwhere $\u03b5 : \u03a9 \u2192 \u211d^d$ is a random variables and such that for every $\u03c9 \u2208 \u03a9$, the equation\n$Xt(\u03c9) = f(X_{<t(\u03c9)}, \u03b5(\u03c9))$\nis an ODE.\nNote that $Xt$ in Eq. 11 is a random variable and characterizes a DSP $X : T \u00d7 \u03a9 \u2192 \u211d^n$ induced by $\u03b5$. In this sense, we say that $X$ is a solution of Eq. 11. Equivalently, we say that $X$ is a solution of Eq. 11 if Eq. 12 is satisfied for almost all $\u03c9 \u2208 \u03a9$.\nThe system described by\n$\\begin{cases}\nXt = a(\u03a9) X_{t-1} +b(\u03a9) \\\\\nX_0 = X_0(\u03a9)\n\\end{cases}$\nrepresents a first-order linear RDE equipped with an initial condition for $X_0$, in which the stochasticity of $\u03c9$ generates a distribution over $X_0$ and over the parameters of the equation $a, b$. The general solution of Equation 13 can be found by recursive substitution, obtaining $X_t(\u03c9) = a(\u03c9)X_0(\u03c9) + b(\u03c9) \\sum_i a(\u03c9)$.\nIn (Bongers, Blom, and Mooij 2018), $\u03b5$ is regarded as a stochastic process that converges eventually or asymptotically to a time-independent random variable. In this work, simplifying the concept, we consider it as a random variable throughout the whole process."}, {"title": "A.2 Stochastic Processes Equilibration", "content": "Let $X$ be a DSP. We say that $X$ (strongly) equilibrates if $Xt$ converges to a random variable $X_\u221e$ for $t \u2192 \u221e$ almost surely, i.e.,\n$\u2119(\\limsup\\limits_{t\u2192\u221e} {\u03c9 \u2208 \u03a9 : |Xt(\u03c9)\u2212X_\u221e(\u03c9)| > \u03b5}) = 0 \u2200\u03b5 > 0,$\ndenoted by $X_t \u2198s X_\u221e$. We call $X_\u221e$ the equilibrium state of $X$. Moreover, we say that $X$ weakly equilibrates if $Xt$ converges in distribution to a random variable $X_\u221e$, i.e., for all $x$ for which $F_X$ (the CDF of $X$) is continuous,\n$\\lim\\limits_{t\u2192\u221e} F_{X_t}(x) = F_{X_\u221e}(x)$, denoted by $X_t \u2198d X_\u221e$.\nIn general, $X_t \u2198s X_\u221e \u21d2 X_t \u2198d X_\u221e$.\nIf $X$ is a solution of an RDE, almost sure convergence is achieved if and only if, for almost all $\u03c9 \u2208 \u03a9$, the solution of the ordinary difference equation (ODE) in Equation 12 converges asymptotically to a fixed value $X_\u221e(\u03c9)$. On the other hand, a DSP that is a solution of a SDE (for convenience, we recall Equation 2: $Xt = f(X_{<t}) + g(X_{<t}) \u03b5_t$) cannot equilibrate unless the term $g(X_{<t})$ converges as $t \u2192 \u221e$ to 0, thereby transforming the equation into a RDE. Apart from this scenario, no solutions of a SDE can strongly equilibrate.\nConsider example 1. Assuming $a(\u03c9) < 1 \u2200\u03c9 \u2208 \u03a9$,\n$X_t \u2198s X_\u221e = b(\u03a9) \\sum\\limits_{i=0}^\u221e a(\u03a9)^i = \\frac{b(\u03a9)}{1 \u2013 a(\u03a9)}$."}, {"title": "A.3 Equilibration as a map from RDEs to SCMS", "content": "The process equilibration allows defining a map that associates each RDE with an SCM. Furthermore, this map preserves the semantic of intervention, in the same sense of \u00a73.2. Visually, the diagram in Fig. 7 commutes, i.e., applying equilibration before or after intervention doesn't change the resulting $X_\u221e$.\nConsider a Simple RDE $D$ and its solution $X$. Let $X_\u221e$ be the random variable which $X$ equilibrates to. Then it is possible to associate an SCM $M_D = (F, E)$ where $E \u2286 E_D$ and $F$ is defined through the equilibrium relation\n$X_\u221e = f(X_\u221e(<t, \u00b7), E) = f(X_\u221e, E)$,\nwhere $X_\u221e(t) = X_\u221e \u2200t$ is the constant stochastic process associated with $X_\u221e$. In other words, $M_D$ fully inherits the functional relationships of $D$, substituting dynamic variables with their stationary counterparts. A proof for the general case in continuous-time can be found in (Bongers, Blom, and Mooij 2018). The discrete-time variant follows directly by applying methods of numerical approximation (Hildebrand 1987; Jornet 2023)."}, {"title": "A.4 Equilibration as a map from SDEs to SCMs", "content": "Associating an SDE with an SCM in non-linear settings involves two steps. The first concerns the convergence conditions of the dynamical system to a stationary (observational) distribution. The second step involves constructing the mapping between interventions in the two different models and proving their equivalence. In this work", "2": "nConsider a SDE described by\n$Xt = f(Xt-1) + g(Xt-1) \u03b5_t$.\nIf the following conditions hold: i) $f", "g": "X \u2192 X$ are continuous in $Xt\u22121$, and $X \u2286 \u211d^d$ is closed; ii) $\u03b5_t$ is i.i.d. white noise; and iii) for every $t$,\n(iii.1) \u2200x, y \u2208 X, x \u2260 y\n$E[|| f(x) + g(x) \u2299 \u03b5_t \u2212 f(y) \u2013 g(y) \u2299 \u03b5_t||", "\u03b5_t||^2": "\u03b1||x||^2 +"}]}