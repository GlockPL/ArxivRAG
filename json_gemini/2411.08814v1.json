{"title": "Process-aware Human Activity Recognition", "authors": ["Jiawei Zheng", "Petros Papapanagiotou", "Jacques D. Fleuriot", "Jane Hillston"], "abstract": "Humans naturally follow distinct patterns when conducting their daily activities, which are driven by established practices and processes, such as production workflows, social norms and daily routines. Human activity recognition (HAR) algorithms usually use neural networks or machine learning techniques to analyse inherent relationships within the data. However, these approaches often overlook the contextual information in which the data are generated, potentially limiting their effectiveness. We propose a novel approach that incorporates process information from context to enhance the HAR performance. Specifically, we align probabilistic events generated by machine learning models with process models derived from contextual information. This alignment adaptively weighs these two sources of information to optimise HAR accuracy. Our experiments demonstrate that our approach achieves better accuracy and Macro Fl-score compared to baseline models.", "sections": [{"title": "1 Introduction", "content": "Analysing patterns of human activities offers a multitude of benefits across various domains, including interactive gaming, fitness activity monitoring, assisted living and healthcare monitoring (Gupta et al. 2022; Liu et al. 2022). For example, in healthcare, monitoring stroke patients' daily activities can track their recovery progress and lead to interventions when necessary. With the rapid development of sensor technologies and smart devices, such as smartphones and cameras, large amounts of data related to human activities and behaviour are generated. Human activity recognition (HAR) techniques identify and recognise human activities based on the generated data from these sources.\nHowever, core HAR methods mainly focus on leveraging the power of machine learning (ML) and deep learning (DL) techniques to extract information from data for activity recognition (Gupta et al. 2022). These HAR methods relies solely on analysing the inherent traits and relationships within the data. Such an approach can only learn from whatever data are fed to it, but neglect the context in which data are generated. This may limit their effectiveness (Gupta and Sheng 2020), resulting in low accuracy due to inter-class similarity. For example, the activities of drinking from a cup and answering a phone involve similar arm movements (Gupta and Davis 2007). Thus, it is difficult to distinguish these similar activities based on motion data alone.\nTo address this limitation, the idea of incorporating domain knowledge or contextual information into ML and DL methods has been investigated to improve the accuracy and interpretability (Guo et al. 2023). Humans inherently follow distinct patterns in their daily activities, influenced by established best practices and workflows. These include production processes, social norms and habitual routines, such as adhering to a recipe when preparing a meal or following a typical daily schedule. Incorporating this type of information into the traditional data-driven HAR models mentioned above can help enhance their performance. Taking the example of distinguishing between the activities of drinking from a cup and answering a phone, it is helpful to consider the typical sequence of actions associated with each activity. For instance, the process of drinking often starts with approaching the location of the cup, followed by reaching for and picking up the cup, then drinking from it and finally putting down the cup. By understanding and recognising this process, we can more accurately infer that if a series of actions match this pattern, the current activity is likely drinking from a cup rather than answering a phone.\nMoreover, capturing this process information poses challenges in domains where activities may not follow a strictly defined sequence. Across domains, the variability of how tasks are performed makes it difficult to define a structured process. For instance, the same activity of drinking from a cup could involve different sequences, e.g., an individual could be interrupted when they receive a text message or doorbell ringing, altering the usual sequence.\nOur work aims to enhance the performance of traditional HAR models by incorporating process information from context. In this paper, we propose a novel approach based on alignment conformance checking algorithm (Carmona et al. 2018; Zheng, Papapanagiotou, and Fleuriot 2024), which aligns a process model with an event log. The proposed approach learns from both the outputs of HAR models and processes information from domains. It can adaptively weights these two sources of information during the training phase to achieve the best HAR accuracy. An experimental study is investigated based on a dataset collected by cameras whilst observing people eat (Raza et al. 2023). The result shows that our approach can achieve better accuracy and Macro F1-score compared to two well-known Graph Convolutional Network algorithms for activity recognition."}, {"title": "2 Motivating example", "content": "Eating behaviour monitoring has seen increased attention in recent research, particularly in the context of social care and healthcare (Tufano et al. 2022; Raza et al. 2023). Recognising an individual's actions such as picking up food and placing it in their mouth, can help analyse their eating behaviour and provide valuable insights into their health condition. For example, consistently monitoring how quickly a person eats, the size of the bites they take, or their ability to steadily hold utensils can be indicators of potential health issues, such as neurological disorders or physical impairments (Tufano et al. 2022). Moreover, the importance of recognising eating actions also extends to the development of assistive technologies, such as robotic arms for help with eating, e.g., for individuals with disabilities or the elderly.\nExisting work has investigated how ML and DL-based classification models can be used for recognising activities (Wu et al. 2022; Raza et al. 2023). These models are proficient in extracting features from various types of input data, such as images and sensor readings. They generate an output matrix that represents the prediction probabilities for the input across different classes of eating actions, like chewing, picking up cutlery, and putting down cutlery. This output matrix is a probability distribution across possible activity classes for any given input. The recognised activity is determined to be the one associated with the highest probability in the matrix.\nHowever, due to the similarities between different classes of actions, selecting the class with the highest probability does not always guarantee accuracy. This is because similar actions may result in similar probabilities. For example, the algorithm may classify some sensor input associated with the activity of putting down cutlery as the picking up cutlery activity with 51% probability and putting down cutlery with 49% probability, resulting in misclassification.\nEating behaviour possesses inherent process information embedded within the execution of eating activities. For example, there is a typical order of activities, such as picking up a fork, picking up food using the fork, putting food into mouth, chewing, etc. Understanding these aspects, such as the processes involved in eating, allows us to capture the context in which the activity is performed, thus improving our ability to make accurate activity recognition. For example, picking up cutlery is likely to be followed by an activity related to food consumption (like picking up food using a fork), whereas putting down cutlery might be followed by activities like wiping one's mouth or reaching for a drink. Therefore, by incorporating the process information, we can reduce the uncertainty of activity recognition algorithms caused by inter-class similarities and enhance the accuracy of activity recognition.\nHowever, eating behaviour also includes a degree of flexibility in the sequence and manner of performing eating actions, which complicates the task of establishing a structured process that could be incorporated to enhance activity recognition. For example, while a typical sequence at mealtime might involve picking up cutlery, using the cutlery to pick up food, and then eating the food, this sequence can be altered based on situational factors. For instance, a person could be interrupted by a phone call or need to attend to a child, causing them to put down their cutlery unexpectedly and alter their usual sequence.\nMoreover, individuals often have personal eating habits that vary widely, such as the order in which they eat their food. Some might prefer starting with lighter items like soup before progressing to heavier main dishes, while others might dive straight into the main course. Additionally, the type of food being consumed often determines the utensils required. For example, soup is eaten with a spoon, steak requires a knife and fork, and sushi is typically eaten with chopsticks. These variations mean that eating different types of food can involve distinct sequences of actions. Sometimes, people might choose to eat with their hands instead of using cutlery, bypassing some of the steps in the typical sequence. These variations make it challenging to capture structured process information of eating behaviour."}, {"title": "3 Preliminary", "content": "Our approach is built upon an alignment-based conformance checking algorithm for uncertain data, proposed by Zheng et al., known as ProbCost (Zheng, Papapanagiotou, and Fleuriot 2024). Next, we provide a brief description of relevant concepts so that this paper is self-contained.\nProbCost aligns probabilistic event data with process information and needs two components to achieve this. The first is a process model, which represents the process information. An example process model, related to the drinking scenario is depicted in Figure 1. The second component is a sequence of probabilistic events, each corresponding to one of the possible activities. For instance, consider a log of 3 events: eo, e1, e2, as modelled in (1). The event eo has a 0.6 probability of corresponding to PickUpCup activity and 0.4 probability of corresponding to PutDownCup activity.\n\\begin{equation}P = \\begin{array}{lcccc} & e_{o} & e_{1} & e_{2} \\\\ PickUpCup & 0.6 & 0 & 0.4 \\\\ DrinkFromCup & 0 & 0.3 & 0 \\\\ PutDownCup & 0.4 & 0 & 0.6 \\\\ AnswerPhone & 0 & 0.7 & 0\\end{array} \\tag{1}\\end{equation}\nProbCost combines these two components as a synchronous product net, which involves three types of move: synchronous moves (SM), model moves (MM) and log moves (LM). A SM indicates that the event in the log and the activity in the process correspond to each other. A MM indicates a misalignment where an activity should have been executed according to the process model, but there is no corresponding event in the log. A LM indicates that an activity has been executed, which was unexpected according to the process model. The principle of the alignment tries to find an optimal"}, {"title": "4 Method", "content": "Our proposed approach for process-aware human activity recognition consists of 4 stages: i) extracting a probability distribution matrix from ML or DL models, ii) discovering process models, iii) conducting an alignment by ProbCost, and iv) retrieving activities from the alignment.\nThe equation for the cost function is represented as equation 2.\n\\begin{equation}c(t) =\\begin{cases}log(w(t)), & t \\in SM\\\\log(w(t)) - log(\\epsilon), & t \\in LM\\\\log(\\epsilon), & t \\in MM\\end{cases}\\tag{2}\\end{equation}\nIn the cost function (2), w(t) represents the associated probability of an activity for a given event. For example, consider the events in (1), w(PickUpCup) for eo is 0.6. There is also a parameter \u0454 \u2208 (0,1). A lower value of e means that the alignment allows events with lower probability to achieve a SM with a matching activity in the process model. In contrast, a higher value of e requires the event to have a higher probability to align with the activity in the process model as a SM, following the principle of choosing the most probable activity. The intuition behind this is to weigh the trust between the process model and the sequence of probabilistic events to achieve the alignment. Specifically, a lower value of e places more weight on the process model, accepting lower probability activities, while a higher value places more weight on probabilistic events, choosing higher probability activities.\nConsider once more the sequence of probabilistic events represented in (1) and also the process model in Figure 1, ProbCost can obtain different alignment by adjusting the values of e to match the actual sequence of events. For example, if the actual activities associated with each event are PickUpCup, DrinkFromCup and PutDownCup, respectively, a lower threshold of \u20ac (0.4) can result in a perfect alignment (Table 1a) with process model by choosing the activity DrinkFromCup for the second event, as it matches to the process model and results the minimum cost of movement, even though DrinkFromCup has lower probability compared to AnswerPhone. Conversely, if the actual sequence of events is PickUpCup, AnswerPhone and PutDownCup, as indicated by the most probable classes, a high value of \u20ac (0.9) can select the most probable activity, i.e., AnswerPhone, to achieve the alignment (Table 1b)."}, {"title": "5 Experimental study", "content": "Our experimental study is based on the EatSense dataset, which uses RGBD cameras to capture the eating behaviours of participants (Raza et al. 2023). This dataset records the upper-body movements of individuals while they eat. It encompasses data from participants who use a range of utensils to consume different types of food. Within this dataset, 16 distinct eating actions such as chewing, drinking, food in hand at table have been densely labelled. The full list of actions is shown in Table 4 in the Appendix.\nThe dataset comprises a trimmed component, where the videos have already been manually segmented into separate clips for each action. These trimmed clips are arranged in chronological sequence, mirroring the order in which the actions were performed by the individuals. Each video is a complete eating behaviour process for one subject. The dataset includes videos capturing the eating behaviours of six subjects eating nine different types of food, such as rice, toast, roti, etc. The distribution of videos across these subjects and food types is detailed in Table 5 in the Appendix.\nFor each video, the skeleton of upper-body poses is extracted. The datasets consider 8 human body keypoints, including the nose, chest, right and left shoulder, etc. The extracted skeleton data can be used by Graph Convolutional Networks (GCNs) for activity recognition (Shi et al. 2019).\nRecognising that different individuals consuming different types of food entails a distinct set of processes, we undertake a classification of the videos into distinct categories through two strategic approaches to accurately capture the process information in eating behaviour. Firstly, we focus on discovering the process model associated with each individual, recognising the personal patterns and habits in their eating behaviours. The second strategy is to discover the process models linked to consuming various types of food, taking into account that each food category demands specific eating actions, sequences, and possibly different utensils.\nWithin the EatSense dataset, the number of videos associated with subject 1 is over 10, which although it represents a relatively small dataset does allow for meaningful analysis. Similarly, there are 13 videos related to eating roti.\nWe train machine learning models and carry out a detailed exploration of how various actions are coordinated in the process of eating, focusing our analysis on the videos related to subject 1 and the videos capturing eating roti.\nTo get probabilistic events, we apply GCNs for activity recognition based on skeleton data. GCNs are widely used for skeleton-based action recognition and have achieved remarkable performance since they are adept at representing human body skeletons as spatio-temporal graphs, enabling the modelling of complex movements and interactions among different body parts over time (Yan, Xiong, and Lin 2018). We use the top two performing GCNs models as identified in the study by Raza et al. as our baselines. These two models are two-stream Adaptive Graph Convolutional Network (2s-AGCN) (Shi et al. 2019) and Channel-wise Topology Refinement Graph Convolutional Network (CTR-GCN) (Chen et al. 2021). Our aim is to use these GCN models as baselines for recognising eating activities and to extract probabilistic event traces from their outputs.\nIn each category, we choose 60% of the videos as our training set, 20% of the videos as the validation set and the rest of the videos as the testing set. The training set is used for the GCNs models and to discover the process model. We use the validation set to tune the parameter of process discovery and the threshold e in the ProbCost algorithm.\nWe use the 3D keypoints skeleton of 8 upper-body joints from EatSense datasets as the input for the GCNs models. The GCNs models are trained using the training set, and its performance is evaluated on the testing set. Subsequently, we convert the output predictions of the GCNs models into a probabilistic matrix by applying a softmax function to the results of their output layer.\nWith the discovered process model and extracted probabilistic event traces, we apply ProbCost to achieve an alignment between them. The confidence threshold e is tuned on the validation set with the aim of maximising the activity recognition accuracy. The tuned value of e is applied to the testing set for the performance evaluation.\nSubsequently, we compare the activity recognition performance, contrasting the results obtained from the original GCNs models against those achieved after applying the ProbCost alignment. We use accuracy and macro F1-score to evaluate the performance. Accuracy provides a straightforward measure of the model's overall correct predictions, while the macro F1-score offers a balanced view of the precision and recall across all classes."}, {"title": "6 Related work", "content": "There are three main categories of research related to HAR: data-driven HAR, knowledge-driven HAR and hybrid HAR that integrates both data and knowledge.\nML and DL techniques have been extensively applied in exploiting data for activity recognition. The basic idea behind these techniques is extracting meaningful features for activity recognition tasks (Aminikhanghahi and Cook 2019; Deep and Zheng 2019). It has been demonstrated that DL-based techniques have shown superiority over the other techniques. However, both ML and DL techniques require a large amount of data for training.\nBesides the traditional data-driven approaches leveraging large datasets for training models, there is another strand of research focusing on modelling human activity patterns based on prior knowledge, known as knowledge-driven approaches. For example, Chen et al. propose an ontological activity modelling and representation approach for activity recognition, such as modelling the interrelations between activities and objects (Chen, Nugent, and Wang 2012).\nThere are also research initiatives that incorporate domain knowledge into data-driven models for recognising human activities, i.e., hybrid approaches. By integrating domain knowledge, these models can guide the learning process, ensuring that the patterns recognised by the machine learning algorithms align with established theoretical understandings of human behaviour. For example, Asim et al. propose an approach for recognising fine-grained activities based on smartphone accelerometer data by incorporating location information (Asim et al. 2020).\nOur work also incorporates domain knowledge to refine the data-driven models' output. Specifically, we leverage process information from context to enhance the performance of data-driven HAR models."}, {"title": "7 Conclusion", "content": "We present a novel approach aimed at enhancing human activity recognition by integrating process information into the analysis of machine learning model outputs. We apply ProbCost to achieve an alignment between probabilistic event traces generated by ML models and the process model discovered from context. The alignment essentially calibrates the model's predictions by incorporating the actual sequence and nature of activities as defined by the process model. Through experimental comparison based on the EatSense dataset, with the original performances of Graph Convolutional Networks, including 2s-AGCN and CTR-GCN, our approach demonstrates significant improvement in activity recognition accuracy and Macro F1 scores.\nOur results underscore the effectiveness of incorporating process information for activity recognition. We consider the inherent flexibility of performing activities when discovering process models. Our work also highlights the importance of combining machine learning models with domain-specific process knowledge. Future research can build on these findings by exploring the application of the process model alignment framework to other activities and domains."}]}