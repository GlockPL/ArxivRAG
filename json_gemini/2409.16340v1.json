{"title": "Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review", "authors": ["Nikolas Koutsoubis", "Asim Waqas", "Yasin Yilmaz", "Ravi P. Ramachandran", "Matthew Schabath", "Ghulam Rasool"], "abstract": "Artificial Intelligence (AI) has demonstrated significant potential in automating various medical imaging tasks, which could soon become routine in clinical practice for disease diagnosis, prognosis, treatment planning, and post-treatment surveillance. However, the privacy concerns surrounding patient data present a major barrier to the widespread adoption of Al in medical imaging, as large, diverse training datasets are essential for developing accurate, generalizable, and robust Artificial intelligence models. Federated Learning (FL) offers a solution that enables organizations to train Al models collaboratively without sharing sensitive data. federated learning exchanges model training information, such as gradients, between the participating sites. Despite its promise, federated learning is still in its developmental stages and faces several challenges. Notably, sensitive information can still be inferred from the gradients shared during model training. Quantifying Al models' uncertainty is vital due to potential data distribution shifts post-deployment, which can affect model performance. Uncertainty quantification (UQ) in FL is particularly challenging due to data heterogeneity across participating sites. This review provides a comprehensive examination of FL, privacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL methodologies and propose future research directions to enhance data privacy and trustworthiness in medical imaging applications.", "sections": [{"title": "1 Introduction", "content": "The recent wave of artificial intelligence (AI) enabled by deep neural networks and the availability of large datasets and computational resources is transforming our society, and medical imaging is no exception. Al models trained on radiological data, such as mammograms, CT scans, and MRIs, are poised to become invaluable tools in both clinical and research settings 1\u20133. Nevertheless, a significant challenge remains curating large, annotated, domain-specific datasets, which is hindered by privacy regulations and other factors. In contrast to conventional Al model development methods, which require pooling data at a single location, federated learning (FL) enables decentralized model development without data sharing4,5. FL allows large-scale model training by sharing gradient updates between sites rather than the training data. This permits multiple sites to act as clients and train a global model on the server, which is later shared with every site.\nFL can potentially solve many challenges related to data sharing for Al model training in medical imaging6. However, FL has its own unique challenges. First, data heterogeneity across different sites often violates the independent and identically distributed (IID) assumption, leading to challenges such as poor model convergence, biased outcomes, and reduced generalization. These non-IID issues can stem from variations in imaging protocols, patient demographics, and disease prevalence across sites. Second, some studies have shown that private data can be extracted from the gradient updates communicated between FL sites7. Methods such as differential privacy (DP) and homomorphic encryption (HE)\u00ba have been proposed to improve communications security; however, there may be an inherent trade-off between privacy preservation and model performance 10. The third challenge is uncertainty quantification (UQ), which is the process of quantifying the Al's confidence in its predictions\u00b9\u00b9. This is important for the trustworthiness and reliability of Al for deployment in clinical settings11. Virtually all Al models based on deep neural networks require output calibration for accurate UQ12. The likelihood of non-IID data and the possibility of class imbalance in datasets at client sites require modifications to traditional UQ methods to work for FL models 13. FL, with strong privacy preservation and UQ, has the potential to revolutionize medical imaging by developing generalizable, robust, and trustworthy Al models using large-scale multi-institutional datasets.\nThis work reviews state-of-the-art FL, privacy-preserving FL (PPFL), and UQ methods in FL and outlines how these advancements will enable transformation in medical imaging. We present an overview of FL, PPFL, UQ, and a summary of the topics covered in this review in Figure 1. The primary contributions of this work include:\n\u2022 A review of the current state-of-the-art (last 5 years) FL methods for learning from distributed data, simultaneously dealing with non-IID datasets, privacy-preservation requirements, and the challenges of UQ.\n\u2022 Exploration of two real-world use cases of FL in medical imaging and what can be learned from the success stories. We also present current challenges in FL, PPFL, and UQ related to medical imaging and potential opportunities for future research.\nThe paper is organized as follows: Sections 2, 3, and 4 review FL, PPFL, and UQ in FL, respectively. Section 5 covers the real-world applications of FL in medical imaging and summarizes the current challenges and opportunities. A GitHub repository with links to papers reviewed in this work is provided here: Awesome List."}, {"title": "2 Federated Learning (FL)", "content": "FL was originally proposed to train Al models on edge devices without exposing private data 14. This led to a paradigm shift in how machine learning (ML) models could be trained on sensitive and private data in distributed settings. The original FL algorithm, FedAvg, trains local models on client data and sends gradient information to a central server to create a global model that, in theory, can outperform all local models 14. In this section, we focus on FL algorithms and present state-of-the-art advancements. A summary of the topics covered in this section is shown in Figure 2."}, {"title": "2.1 FL Algorithms - Characterization and Types", "content": "FL can be categorized as centralized or decentralized, depending on whether a central server is utilized to aggregate updates and build the global model. Centralized FL is the more common approach, where a server orchestrates the learning process by collecting and combining client updates. In contrast, decentralized FL allows clients to communicate directly, which can be advantageous when a central server is impractical or undesirable due to privacy or connectivity constraints. Recently, personalized FL (PFL) has gained significant attention as a refinement of traditional centralized FL15. PFL addresses the inherent data heterogeneity among clients, such as variations in data distributions (non-IID data), computational resources, and specific local requirements. Instead of creating a single global model, PFL focuses on developing models"}, {"title": "2.2 Centralized FL", "content": "Centralized FL requires a dedicated central server for parameter aggregation and building the federated model. It is the most common form of FL implemented for various ML tasks. These algorithms offer technical advancements for (1) learning from the distributed, heterogeneous, and non-IID data using various methods, including knowledge distillation, (2) optimizing the learning for the global and local models to avoid catastrophic forgetting of the local model, and (3) stabilizing training across federated runs, locally as well as globally, to ensure convergence of model training. In the following, we provide a chronological list of centralized FL algorithms.\n\u2022 FedProx: FedProx is a generalization of the original FedAvg algorithm 16. The two distinguishing features of the FedProX include (1) allowing partial updates to be sent to the server instead of dropping them from a federated round and (2) adding a proximal term to prevent any client from contributing too much to the global model, thereby increasing model stability.\n\u2022 FedBN: FedBN leverages batch normalization (batch-norm) to reduce the effect of non-IID data 17. FedBN follows a similar architecture to FedAvg, involving the transmission of local updates and their aggregation on a central server, but it treats the batch-norm parameters as site-specific and excludes them from the averaging process.\n\u2022 FedGeN: Knowledge distillation is an emerging approach in FL that addresses data heterogeneity by extracting and sharing knowledge from an ensemble of client models 18. FedGeN"}, {"title": "2.3 Decentralized FL", "content": "Decentralized FL implementations do not utilize a central server to coordinate learning 24\u201326. Depending on the application, decentralized FL may provide enhanced privacy and security, increase robustness and fault tolerance by eliminating single points of failure. Decentralized FL improves scalability by distributing workloads across the network, making them superior to centralized FL. In the following, we present some recent decentralized FL algorithms.\n\u2022 Swarm Learning: It integrates edge computing with blockchain-based peer-to-peer networking, eliminating the need for a central server to coordinate learning 24. This approach leverages decentralized hardware and distributed ML with blockchain to securely manage member onboarding, leader election, and model parameter merging. Sharing model parameters through a swarm network enables independent model training on private data at individual sites. Security and confidentiality are ensured through the blockchain's restricted execution to pre-authorized clients and dynamic onboarding of new participants.\n\u2022 ProxyFL: ProxyFL enhances communication efficiency by using proxy models for information exchange, allowing clients to maintain private models that are never shared 25. This approach supports model heterogeneity, enabling each client to have a unique model architecture while ensuring privacy through DP techniques. ProxyFL outperformed existing methods with reduced communication overhead and stronger privacy protections 25."}, {"title": "2.4 Personalized FL (PFL) - Dealing With Client Data Heterogeneity", "content": "PFL focuses on developing tailored models for clients to address the challenges posed by data heterogeneity across sites while still exploiting learning from the clients in the FL network15.\n\u2022 FedAP: FedAP identifies similarities between clients by analyzing the batch-norm layer statistics from a pre-trained model and uses these similarities to guide the aggregation process 15. Each client retains its batch-norm layers to preserve personalized features, while the server aggregates model parameters based on client similarities to create unique models for each site. FedAP has demonstrated over 10% improvement in accuracy and faster convergence compared to state-of-the-art FL algorithms across diverse healthcare datasets 15.\n\u2022 pFedBayes: Personalized FL via Bayesian inference (pFedBayes) integrates Bayesian variational inference and weight uncertainty to mitigate model overfitting and improve personalization by minimizing construction error on private data and its Kullback-Leibler divergence with the global distribution from the server27. This method allows each client to refine its local model by balancing the accuracy on its private data with alignment to the global distribution.\n\u2022 FedPop: FedPop addresses the challenges of FL, including their struggle with personalization in cross-silo and cross-device settings, especially for new clients or those with limited data and a lack of UQ28. FedPop integrates population modeling with fixed common parameters and random effects to explain data heterogeneity and introduces federated stochastic optimization algorithms based on Markov chain Monte Carlo. This results in increased robustness to client drift, better inference for new clients, and enables UQ with minimal computational overhead.\n\u2022 Self-Aware PFL: A key challenge in PFL is balancing the improvement of local models with global model tuning, especially when personal and global objectives differ. Inspired by Bayesian hierarchical models, self-aware PFL introduces a self-aware method that allows clients to automatically balance local and global training based on inter-client and intra-client UQ29. The method employs uncertainty-driven local training and aggregation, replacing conventional fine-tuning techniques."}, {"title": "3 Privacy-Preserving FL (PPFL)", "content": "Ensuring secure processing of protected and identifiable information is paramount in the medical field, where federal regulations strictly prohibit sharing patient data to prevent privacy breaches. FL addresses this by keeping data localized at each site, but privacy risks still exist as gradient updates exchanged between clients and the server can inadvertently reveal information about training data, leading to privacy leaks\u00b9. In this section, we present several topics related to PPFL as depicted in Figure 3 and Table 3."}, {"title": "3.1 Differential Privacy (DP)", "content": "DP is one of the most popular methods for PPFL and works by introducing noise into the gradients to prevent private information leakage. DP provides mathematical guarantees of privacy preservation; however, these may come at the cost of model accuracy and convergence 10. Noising before Aggregation FL (nbAFL) proposed by Wei et al. ensures DP by adding artificial noise to the model parameters on the client side before aggregation, reducing the risk of privacy breaches 30. To optimize the trade-off between privacy and model performance, nbAFL employs a $K$-random scheduling technique, where $K$ clients are randomly selected for each aggregation round, making it harder for attackers to extract useful information from the updates. The optimal value of $K$ must be carefully determined to balance the level of privacy and the model's convergence, a concept known as privacy budget allocation."}, {"title": "3.2 Homomorphic Encryption (HE) and Somewhat HE (SHE)", "content": "HE is a form of encryption that enables mathematical operations to be performed directly on encrypted data, producing encrypted results that, when decrypted, correspond to the results as if the operations were performed on the original plaintext data 31,32. This allows data to be securely encrypted and shared with a third party for processing without the third party ever gaining access to the underlying plaintext data. SHE is a sub-type of HE that allows for a limited number of arithmetic operations and is generally more efficient33. An FL method based on SHE, Somewhat Homomorphically Encrypted FL (SHEFL), was used to train models for brain tumor segmentation from MRIs and predict biomarkers from histopathology slides in colorectal cancer34. The models trained with SHEFL are on par with regular FL while providing privacy guarantees, showing that encryption does not always negatively impact model accuracy 34. These methods only encrypt"}, {"title": "3.3 Other PPFL Methods", "content": "In addition to DP and HE, many other methods have been proposed in conjunction with the aforementioned methods to preserve privacy in FL, as follows:\n\u2022 Hybrid Approach: Truex et al. combined DP with Secure Multiparty Computation (SMC) to balance the trade-off between data privacy and model accuracy35. Their method mitigates the noise growth that typically increases with the number of parties in DP-based FL systems while maintaining a pre-defined level of trust. A tunable trust parameter, $t$, specifies the minimum number of honest, non-colluding parties required for the system to function securely. As $t$ decreases, indicating less trust, more noise is added by each honest party to guard against potential colluders.\n\u2022 PrivateKT: PrivateKT leverages DP to implement private knowledge transfer using a small subset of public data selected based on their information content36. PrivateKT involves three steps: (i) knowledge extraction, where clients use private data to make predictions on selected public data; (ii) knowledge exchange, where DP is applied to these predictions before sending them to the central server; and (iii) knowledge aggregation, where the server aggregates these predictions into a knowledge buffer. PrivateKT also uses importance sampling to focus on data with higher uncertainty, enhancing knowledge quality and a knowledge buffer to store past aggregated predictions. PrivateKT reduced the performance gap with centralized learning by up to 84% under a strict privacy budget.\n\u2022 Multi-RoundSecAgg: Traditional secure aggregation methods in FL focus on preserving privacy in a single training round37. However, this can lead to significant privacy leaks over multiple rounds due to partial user selection. Multi-RoundSecAgg addresses this issue by introducing a secure aggregation framework with multi-round privacy guarantees, employing a structured user selection strategy that ensures long-term privacy while maintaining fairness and participation balance 37.\n\u2022 Loss Differential Strategy for Parameter Replacement (LDS-FL): LDS-FL implements PPFL by maintaining the performance of a private model through selective parameter replacement among multiple participants 38. LDS-FL introduces a public participant that shares parameters, enabling private participants to construct loss differential models that resist privacy attacks without exposing their data. The authors demonstrated that LDS-FL provides robust privacy guarantees against membership inference attacks, reducing attack accuracy by over 10% while only slightly impacting model accuracy, making it a strong alternative to DP and HE38.\n\u2022 DeTrust-FL: DeTrust-FL offers a decentralized solution to enhance privacy by securely aggregating model updates without relying on a centralized trusted authority 39. It addresses vulnerabilities to inference attacks, such as dis-aggregation, through a decentralized functional encryption scheme where clients collaboratively generate decryption key fragments using a transparent participation matrix. Additionally, DeTrust-FL employs batch partitioning to prevent attacks and encrypts model updates with round labels to thwart replay attacks, achieving state-of-the-art communication efficiency while reducing dependency on centralized trust entities."}, {"title": "4 Uncertainty Quantification (UQ) in FL", "content": "UQ aims to evaluate an Al model's confidence in its predictions, which is vital for fostering trust, reliability, and user acceptance 11,40. UQ can play a critical role in monitoring the Al model's performance post-deployment and serving as an early warning system for potential performance degradation, enabling timely human intervention. Additionally, UQ can inform decisions on whether to apply personalized or global models, assists in detecting out-of-distribution samples, and supports active learning during model training. However, UQ in FL encounters unique chal-"}, {"title": "4.1 UQ using Model Ensembling", "content": "Model ensembling is a widely used UQ method in FL that leverages the distributed nature of FL by treating multiple clients as an ensemble of models 13. Three key ensembling approaches in FL include the ensemble of local models, an ensemble of global models, and the ensemble based on multiple coordinators 13. The ensemble of local models prioritizes privacy and simplicity by treating each client's model as an independent ensemble member, though it diverges from FL's collaborative nature. The ensemble of global models preserves collaboration but increases computational and communication overhead due to repeated model training with different random seeds. The ensemble based on multiple coordinators improves scalability by distributing clients into subgroups with their coordinators, but this approach introduces coordination complexity and risks learning fragmentation.\nFed-ensemble extends ensembling methods by using random permutations to update a group of $K$ models, with predictions made through model averaging41. Fed-ensemble incurs no additional computational overhead and can be seamlessly integrated into existing FL algorithms. Empirical results show that Fed-ensemble outperforms other FL algorithms across diverse datasets, especially in heterogeneous settings common in FL applications. Each method offers distinct trade-offs, and hybrid or adaptive ensembling strategies might help balance efficiency with collaborative benefits, depending on the specific needs of the FL application."}, {"title": "4.2 UQ using Conformal Prediction (CP)", "content": "CP is a statistical framework for providing a reliable confidence measure for predictions made by ML models 42. CP works by defining a nonconformity measure, which assesses how different a new example is from previously seen data and generates prediction regions that are likely to contain the true label or value. CP is particularly valuable in FL; however, the data heterogeneity inherent in FL clients violates the assumption of exchangeability, which is fundamental to traditional CP methods. To address this, Lu et al. introduced the concept of partial exchangeability and developed the Federated CP (FCP) framework, which retains rigorous theoretical guarantees and demonstrates strong empirical performance across computer vision and medical imaging datasets, making it a practical solution for UQ in heterogeneous FL environments43. Plassier et al. proposed a new FCP method using quantile regression, incorporating privacy constraints through DP. This approach adequately addresses label shifts between sites using importance weighting and provides theoretical guarantees for valid prediction coverage and privacy44."}, {"title": "4.3 UQ using Bayesian FL", "content": "In Bayesian FL, each client learns a posterior probability distribution function (PDF) over its parameters 45,46. The learned PDF is communicated by the clients to the server to aggregate the local PDFs and learn a global PDF that can serve all the clients. The posterior PDF can be used for UQ in the model's output. Various approximation methods for the approximation of the posterior PDF, like MC-dropout and Stochastic Weight Averaging Gaussians (SWAG), have also been proposed 13."}, {"title": "4.4 UQ and Model Output Calibration", "content": "UQ methods aim to assess and communicate how confident a model is in its predictions, which is crucial for reliable deployment and decision-making. While UQ provides a direct way to quantify uncertainty in model outputs, model calibration corrects the model's tendency to be overconfident, particularly due to the Softmax function, thus aligning predicted probabilities with actual performance 11. By calibrating the Softmax output, a more accurate assessment of the model's confidence is achieved. Classifier Calibration with Virtual Representations (CCVR) calibrates a global model to improve performance on non-i.i.d data in heterogeneous settings47. The authors found a greater bias in representations learned in the deeper layers of a model trained with FL. They show that the classifier contains the greatest bias and that post-calibration can greatly improve classification performance. Specifically, the classifiers learned on different clients show the lowest feature similarity. The classifiers tend to get biased toward the classes over-represented in the local client data, leading to poor performance in under-represented classes. This classifier bias is a key reason behind performance degradation on non-IID federated data. Regularizing the classifier during federated training brings minor improvements47. However, post-training calibration of the classifier significantly improves classification accuracy across various FL algorithms and datasets 47. A recently proposed method, Federated Calibration (FedCal), performs local and global calibration of models 48. It uses client-specific parameters for local calibration to effectively correct output misalignment without sacrificing prediction accuracy. These values are then aggregated via weight averaging to generate a global scalar value, minimizing the global calibration error48."}, {"title": "5 FL in the Medical Imaging World", "content": "With the growing research in FL, PPFL, and UQ, real-world applications focusing on medical imaging have begun to demonstrate FL's potential. This section presents FL implementation tools, real-world clinical case studies, and the future outlook of FL in medical imaging with challenges and opportunities."}, {"title": "5.1 Planning Medical Imaging FL Project", "content": "Implementing an FL project for medical imaging involves several key steps to ensure the project's success and compliance with privacy standards set by the participating institution and federal regulations. The project's success could be measured by validating a model that performs better than all local models, trained by sites locally using their own data.\nThe process of implementing an FL project begins by defining the specific medical imaging problem, such as the classification of disease, pixel-level segmentation of organs of interest, or the identification of malignant masses in radiological scans. The next step involves selecting the participating institutions, such as hospitals or imaging labs, and determining which site will act as the central server. The selection of sites is based on their ability to collect and pre-process the data needed for training, train the model, and share updates with the server site over the internet. After identifying the collaborators, an appropriate FL software framework, such as NVIDIA FLARE, is selected and customized to meet the project's specific needs. This customization may include implementing privacy-preserving techniques, UQ algorithms, and configuring site-specific software for data loading and resultant storage. The ML model architecture, inputs, and outputs are also determined at this stage before deploying the FL software framework at both the server and client sites."}, {"title": "5.2 FL Implementation Tools", "content": "To streamline FL model training, validation, and deployment process, several open-source frameworks or software development kits (SDKs) have been developed. NVIDIA Federated Learning Application Runtime Environment (FLARE) is a well-known open-source SDK49. NVIDIA-FLARE supports various FL algorithms, workflows, and privacy-preserving techniques, including DP and HE. OpenFL is an open-source Python library that operates using a static network topology where clients connect to a central aggregating server via encrypted channels50. The workflow is dictated by a federation plan that all sites agree upon before the start. Originally designed with medical imaging in mind, OpenFL can be adapted for other types. Fed-BioMed is another open-source framework tailored for biomedical applications of FL. It offers tools and libraries to manage distributed training, handle heterogeneous data, and ensure privacy and security in a biomedical research context51. Argonne Privacy-Preserving Framework (APPFL) is an open-source Python package that provides tools to implement, test, and validate various aspects of PPFL experiments in simulation settings 52."}, {"title": "5.3 Medical Imaging FL Studies", "content": "\u2022 Federated Tumor Segmentation (FeTS): FeTS-1.0 was the first real-world, large-scale FL effort for medical imaging, which aimed to identify the optimal weight aggregation approach for training a consensus model across multiple geographically distinct institutions while retaining data locally 53,54. Presented in the form of a challenge, FeTS evaluated the generalizability of a federated model trained on brain tumor segmentation to unseen, institution-specific data, showcasing the potential of FL in real-world medical settings. Building on this, the FeTS-2.0 challenge focused on out-of-sample generalizability for Glioblastoma detection, creating the largest Glioblastoma dataset to date and demonstrating significant improvements in tumor segmentation accuracy.\n\u2022 FL for Predicting COVID-19 Outcomes: Dayan et al. used FL to train a model on Covid-19 data from 20 different institutes across the globe without sharing data55. The EXAM model was created to predict the future oxygen needs of Covid-19 patients from the federated setup. The model achieved an average AUC of more than 0.92 in predicting outcomes."}, {"title": "5.4 Challenges and Opportunities", "content": "We have presented an overview of FL, PPFL, and UQ from a technological and algorithmic perspective. We also presented an overview of how the FL project can be implemented and two case studies that used FL to solve real-world medical imaging tasks. While significant progress has been made in recent years, FL is still in its infancy. Multiple challenges must be addressed for FL to become a standard ML model development paradigm for medical imaging Al. These challenges present potential opportunities for researchers to further explore and improve the state of FL for medical imaging.\n1. Administrative Challenges: Before an FL project can be implemented, engaging stakeholders from all participating institutions is essential. These stakeholders typically include researchers, the medical imaging team, information technology and cybersecurity experts, contract and agreement management teams, and hospital administrators. Engaging these groups ensures that all aspects of the project, from technical implementation to legal and ethical considerations, are addressed. Ethical approvals from relevant Institutional Review Boards (IRBs) or ethics committees must be secured to ensure compliance with regulatory standards, particularly concerning patient data privacy and security. In addition to ethical approvals, formal agreements about \u201cweight sharing\u201d between institutions must be established. These agreements should outline whether model weights will be shared in \u201cplain\u201d or \"encrypted\u201d formats, addressing concerns related to data security and compliance with privacy laws such as HIPAA or GDPR. These agreements also need to specify the responsibilities of each institution, including data governance, data transmission protocols, and contingency plans in case of data breaches. Addressing these issues comprehensively before the FL project begins is crucial for ensuring smooth collaboration and maintaining trust among the involved parties.\n2. Requirement for Annotated Datasets: It is important to recognize that FL does not eliminate the need for annotated data. Each participating site must still invest significant resources in creating and annotating datasets for training local models. The FL community needs to build upon and extend ongoing work in self-supervised learning, active learning, continual learning, and transfer learning to federated environments. An exciting area of research involves using generative Al models to create diverse, medically relevant datasets. However, despite the aesthetically appealing nature of Al-generated images, there is currently limited convincing evidence of their clinical relevance. This highlights the need for further research to validate the utility of Al-generated images in training federated models.\n3. Privacy-Performance Trade-offs: Another significant challenge in FL is the inherent trade-off between privacy and model performance 30. Further research is needed to efficiently allocate the privacy budget to enhance privacy without compromising the model's effectiveness. Exploring alternative types of noise and methods for adding noise presents a potential pathway for improving the effectiveness of DP. Additionally, there is a need to further adapt encryption methods, including HE and SHE, to FL environments to minimize"}, {"title": "6 Conclusion", "content": "FL holds the potential to dramatically improve medical imaging workflows in both research and clinical environments. Various forms of FL such as centralized, decentralized, and personalized federated learning are all being developed to tackle multiple problems in the healthcare domain. FL addresses critical privacy and security concerns while leveraging diverse and extensive datasets to enhance model performance and generalizability by enabling collaborative model training across multiple institutions without directly sharing sensitive patient data. Enhanced privacy preservation in the form of differential privacy, homomorphic encryption, and other hybrid approaches enable even more secure deployments, protecting patient privacy. Active research is also being conducted to embed uncertainty quantification for trustworthy Al models. Continued interdisciplinary efforts and technological advancements in this domain are expected to streamline medical imaging workflows further, support precision medicine initiatives, and ultimately contribute to better healthcare delivery and patient outcomes worldwide."}]}