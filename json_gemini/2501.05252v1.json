{"title": "From Scientific Texts to Verifiable Code: Automating the Process with Transformers", "authors": ["Changjie Wang", "Mariano Scazzariello", "Marco Chiesa"], "abstract": "Despite the vast body of research literature propos- ing algorithms with formal guarantees, the amount of verifiable code in today's systems remains minimal. This discrepancy stems from the inherent difficulty of verifying code, particularly due to the time-consuming nature and strict formalism of proof details that formal verification tools require. However, the emergence of transformers in Large Language Models presents a promising solution to this challenge. In this position paper, we believe that transformers have the potential to read research papers that propose algorithms with formal proofs and translate these proofs into verifiable code. We leverage transformers to first build a formal structure of the proof using the original text from the paper, and then to handle the tedious, low-level aspects of proofs that are often omitted by humans. We argue that this approach can significantly reduce the barrier to formal verification. The above idea of reading papers to write verifiable code opens new avenues for automating the verification of complex systems, en- abling a future where formally verified algorithms from academic research can more seamlessly transition into real-world software systems, thereby improving code reliability and security.", "sections": [{"title": "I. INTRODUCTION", "content": "Throughout history, humans have continually developed more sophisticated algorithms to solve complex problems, uncovering and forging connections between concepts in inno- vative and complex ways, and used this knowledge to build the software that runs in modern-day systems. The culmination of all this research knowledge is captured in human language and recorded in countless papers, books, or other written works. Despite this vast body of algorithmic knowledge, only a negligible fraction of today's code in systems has been formally verified using computers [1]. The reasons for this lie in the inherent complexity and challenges involved in the formal verification process [2].\nFormal verification is time-consuming and complicated. This complexity arises from several factors. First, it requires familiarity with specialized formal languages, which have their own syntax and semantics that require an enormous amount of time to master adequately [3]. Second, the formal verification process operates at an extremely low level; every step, even those that are intuitively obvious to humans, must be explicitly verified a tedious and often frustrating task [4]. Third, verifiers attempt to aid this process by using heuristics to link logical relationships, but the reliance on heuristics introduces something known as brittleness [5]. Even a minor change, like renaming a variable or removing seemingly irrelevant assertions, can cause previously verified proofs to fail. Finally, even if one could skip proving low-level lemmas, translating proofs from human language into high-level verifiable code remains time-consuming. This is because proofs may be vague and long, covering several pages of an article or book. The complexity of the structure of the proof and properties of data types quickly escalates, making it difficult for humans to grasp the complexity. Existing solutions that try to automate formal verification have significant limitations, such as the inability to read text and scale to simple proofs or code bases [6].\nTransformers to the rescue? Transformers are a type of neu- ral network architecture designed to quickly process and gen- erate sequences (e.g., text) [7], excelling at understanding and manipulating human language, which makes them well-suited for tasks like translating textual descriptions into code [8]. Tools like OpenAI's Codex [9] and GitHub Copilot [10] leverage these models to suggest code with some levels of accuracy but they do not perform formal verification of the produced code, leaving correctness not guaranteed. As our experiments further reveal, naively applying a transformer- based LLM to the formal verification problem fails to produce any verifiable proofs, due to the low-level complexities. Fur- thermore, even existing transformer-based systems for writing verifiable code barely scale to simple programs that, for example, contain a single loop [11]-[13].\nOur vision: from textual descriptions to verifiable code using transformers and separation of responsibilities. We argue that transformers are still a natural candidate for tackling the challenge of converting algorithms and proofs from human language into verification code. We, however, need to use them for the right task. Our key intuition is that we can break down the verification task into two main stages:\n1) Translate a textual proof from human language to high- level verification code. Transformers excel at translations that are roughly one-to-one (e.g., between spoken lan- guages), making them well-suited for converting a textual proof into a high-level skeleton of code for the verifier. At this stage, the goal is not to complete the entire proof but to outline its structure, with many low-level details inten- tionally left out. The key insight here is that verifiers can prove that the high-level proof works assuming (without proving) that the details of the low-level proofs are correct. This allows us to use the best aspect of transformers for building the skeleton of the formal proof while deferring the detailed, low-level proofs to a second stage.\n2) Generate the missing low-level verifiable proofs. For the second stage, we claim that transformers are still the right tool. We use them to autonomously generate low-level proofs that lack textual equivalents, typically because their solutions are intuitively obvious to humans. Our key ob-"}, {"title": "II. EXAMPLE: THE HANDSHAKE LEMMA", "content": "We explain the main challenges in writing verification code using a simple network topological property that we derive from graph theory [16]:\nHandshake lemma. For every graph $G = (V, E)$ we have $\\sum_{v\\in V} d(v)$, where d(v) is the degree of vertex v.\nThis lemma states that the sum of the degrees of all vertices is equal to twice the number of edges in the graph. Even without looking at the proof, a human immediately guesses the correctness of the statement with the following reasoning:\nHuman intuition. Each edge connects two vertices, increasing the overall sum of the degrees of all the graph vertices by two.\nThis reasoning is generally enough to convince the reader about the correctness of the lemma. Some books may provide some additional proof text as in the following example:\nBook proof [16]. Let $X = \\{(e,x) : e \\in E, x \\in V,x \\in e\\}$. Then $|X| = \\sum_{v\\in V} d(v)$ and $|X| = \\sum_{e\\in E} 2 = 2|E|$.\nThis proof more formally defines human intuition using an auxiliary set X, which enumerates all the edge-vertex pairs of the graph. It then claims that the cardinality of this set (i.\u0435., X) is equal to both (i) the sum of the degrees of the vertices, and (ii) the sum of the edges times two.\nIn this example, for the sake of simplicity, we only focus on generating verification code (i.e., the proof), rather than the code of an algorithm. But, the principles behind PROMETHEUS could be extended to enable joint generation of both algorithms and their corresponding proofs.\nWhy is it so hard to verify the lemma for a non-expert? Neither the human intuition nor the above book proof can be easily formally verified. Consider the more formal proof from the book. Even if we write the complete formal specification of the problem, including the property to be proved and a specifi- cation of a graph data structure, a verifier like Dafny [17] will not be able to verify these two assertions $|X| = \\sum_{v \\in V} d(x)$ and $|X| = 2|E|$. Indeed, formal verifiers operate without understanding the semantics or meaning of the mathematical problem that they analyze. Instead, they apply a series of pre-defined heuristics and logical techniques to check whether a given post-condition or specification holds. These tools function purely at the syntactic level, using rules and strategies to attempt proofs, but without any intrinsic comprehension of the underlying, potentially trivial, mathematical concepts or their purpose. We showcase these limitations from formal verifiers using the $|X(G)| = \\sum_{v\\in V} d(v)$ assertion from the handshake lemma and use the Dafny verification system\u00b3:\n1) Definitions are side-effect-free. Any definition of a prop- erty expressed in Dafny must be described without using side-effect operations [19], i.e., the definition should not modify the state of the involved variables in the definition. Practically speaking, this constraint forbids a programmer from using \"for\" loops in the definition of properties. As"}, {"title": "III. FEASIBILITY STUDY WITH A PROTOTYPE", "content": "We perform a preliminary evaluation of our idea to assess the potential feasibility of the idea, leaving a full-scale eval- uation as future work. Our prototype feeds a proof in natural language as input to the Claude Sonnet 3.5 LLM. It then interacts iteratively with the LLM by proving lemmas using a top-down approach, i.e., first prove the general lemma using some lower-level helper lemmas that will be proved in the next iterations. The system also verifies the code generated by the LLM, and sends both the output of the verification process alongside some hints on how to solve these problems. These hints are high-level hints to help the LLM in solving common Dafny problems, i.e., proving using inductions, solving exten- sion equality problems, spotting missing pre-conditions, and more. We test PROMETHEUS on three lemmas:\n\u2022 Handshake lemma (definition in \u00a7II).\n\u2022 Degree bounds lemma. Given a graph G, we have that $min(G) \\leq avg(G) \\leq max(G)$, where min(G), avg(G), and max(G) are the minimum, average, and maximum degree of the vertices in G.\n\u2022 Even cycle bipartite lemma. Given a bipartite graph $G = ((A, B), E)$, we have that every cycle has an even length, where A and B are two partitions of the vertices such that there are no edges connecting two vertices in the same partition.\nFor each lemma, we input all the formal specifications of all the relevant definitions, such as the graph data structure or the definition of a cycle. To evaluate the performance of PROMETHEUS, we use zero-shot prompting as a baseline, requesting that LLMs generate the complete proof in a single attempt. We compare the success rate of PROMETHEUS to the baseline as the number of successful runs over the total runs. The following table presents the results for the three lemmas, including the success rate over five runs:\nWe observe that with basic prompting strategies like zero- shot prompting, the baseline fails to produce verifiable code. The generated code is always short and lacks low-level proofs mentioned in \u00a7II. In contrast, PROMETHEUS successfully generates a complete and verifiable proof in Dafny, with a high success rate. PROMETHEUS always starts with a proof skeleton, delves into the low-level details, and refines them iteratively. View a video of a successful run [20]. The result shows that PROMETHEUS delivers a promising performance in verifiable code generation in Dafny."}, {"title": "IV. FUTURE CHALLENGES AND DISCUSSION", "content": "Who verifies the correctness of the input formal specifica- tions? In our evaluation, all formal specifications\u2014including data structure and predicate definitions (e.g., how a graph or the sum of node degrees is defined) as well as pre- and post-conditions of the proven property-were generated using an LLM. However, we manually verified the correctness of these definitions before using them as input for PROMETHEUS. Completely automating this task is challenging, as it forms the foundational truth that guides the LLM in generating accurate code. Further research on how to more reliably generate formal specifications from natural language is needed.\nHow far can we go in proving theorems without a textual proof? As we discussed in this paper, there is always a mismatch between the level of detail required by a formal verifier and a textual proof. In PROMETHEUS, we try to fill this gap in two ways: either having an LLM generating the missing logic or letting verifiers generate a proof using heuristics. In both cases, neither LLMs nor verifiers possess the same level of \"intelligence\" that humans possess in order to understand relations between concepts, e.g., impact of an edge on the sum of degrees of the vertices. Exploring novel ways to generate proofs (as in the AlphaProof or Alpha Geometry 2 systems) using transformers and reinforcement learning is left outside the scope of this paper, which only deals with translating the existing human knowledge into verifiable code."}, {"title": "CONCLUSIONS", "content": "In this position paper, we argue that recent advancements in LLMs present unprecedented opportunities for translating decades of scientific research on algorithms and systems into formally verifiable code. We propose leveraging LLMs to generate high-level code outlines and corresponding verifica- tion logic from natural language descriptions in the literature. This approach aims to lower the barrier to verifying scientific research and enable the creation of more resilient software systems. Significant research challenges remain, including developing systems capable of accurately translating complex notations, algorithms, and logic, as well as innovating stronger methods for verifying the low-level aspects of these proofs."}]}