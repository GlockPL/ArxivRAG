{"title": "Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity", "authors": ["Minxiao Chen", "Haitao Yuan", "Nan Jiang", "Zhifeng Bao", "Shangguang Wang"], "abstract": "Traffic accidents pose a significant risk to human health and property safety. Therefore, to prevent traffic accidents, predicting their risks has garnered growing interest. We argue that a desired prediction solution should demonstrate resilience to the complexity of traffic accidents. In particular, it should adequately consider the regional background, accurately capture both spatial proximity and semantic similarity, and effectively address the sparsity of traffic accidents. However, these factors are often overlooked or difficult to incorporate. In this paper, we propose a novel multi-granularity hierarchical spatio-temporal network. Initially, we innovate by incorporating remote sensing data, facilitating the creation of hierarchical multi-granularity structure and the comprehension of regional background. We construct multiple high-level risk prediction tasks to enhance model's ability to cope with sparsity. Subsequently, to capture both spatial proximity and semantic similarity, region feature and multi-view graph undergo encoding processes to distill effective representations. Additionally, we propose message passing and adaptive temporal attention module that bridges different granularities and dynamically captures time correlations inherent in traffic accident patterns. At last, a multivariate hierarchical loss function is devised considering the complexity of the prediction purpose. Extensive experiments on two real datasets verify the superiority of our model against the state-of-the-art methods.", "sections": [{"title": "1 INTRODUCTION", "content": "According to the World Health Organization (WHO) [33], approximately 1.3 million people die each year due to traffic accidents, making it a leading cause of death among children and young adults aged 5 to 29. In response, the United Nations General Assembly has set an ambitious target of halving the global number of deaths and injuries from road traffic crashes by 2030 [29]. Therefore, it is of vital importance to predict traffic accident risk accurately, which can assist government in managing traffic risks and help drivers avoid high-risk areas. When revisiting this problem, we find some critical yet missing aspects that contribute to its accuracy boost.\n(1) Regionality: Regional Background Effects. Traffic accidents are affected by many complex factors, and the ways to which these factors affect are difficult to analyze. To capture the underlying mechanisms of traffic accidents, regional background is essential. For instance, as shown in Fig. 1, different regions may have share similar road structure (e.g., crossroads) and weather (e.g., sunny), but entirely different regional background (e.g., parking lot, lake, small park vs. dense residential area). This leads to significant variations in traffic accident patterns. However, these regional backgrounds are often overlooked and difficult to capture.\n(2) Proximity and Similarity: Spatial and Semantic Corre-lations. Traffic accidents exhibit dual correlation involving both spatial proximity and semantic similarity. This implies that traffic accidents occurring in close areas or areas sharing similar semantic properties tend to have high similarities [39]. For example, in Fig. 1, the adjacency of Region 1 and Region 2 suggests interconnected roads, while the similar distribution of POIs in Region 1 and Region 3 contributes to similar accident patterns. Effectively capturing both types of correlations poses a significant challenge.\n(3) Sparsity: Zero-Inflation Problem. As shown in the lower right part of Fig. 1, the number of traffic accidents in NYC during an afternoon is presented in a heatmap. Notably, most regions experience zero traffic accidents. This is identified as the zero-inflation problem. Failure to properly address this sparsity can lead the model to generate predictions with an excessive number of zeros, rendering the predictions meaningless [21].\nUnfortunately, existing studies have not thoroughly captured most of the above aspects. Traditionally, statistics-based methods [3, 6, 22, 27] merely utilize the statistics information of historical accidents, ignoring the influence of many spatio-temporal factors, which leads to poor performance. To alleviate this, learning-based methods [1, 4, 5, 26, 28, 31, 32, 38] have been proposed. They analyze spatio-temporal features to capture the correlations between traffic accidents. However, they fail to effectively capture the spatial proximity and semantic similarity of traffic accidents and miss out on the regional background of where they occur. Worse still, their approach to dealing with sparsity is not sufficiently effective.\nTo incorporate all the above critical aspects, we design a Multi-Granularity Hierarchical Spatio-Temporal Network (MGHSTN) for traffic accident risk prediction.\nFirst, recognizing the informative potential of remote sensing images in revealing regional backgrounds, we integrate them into the traffic accident risk prediction process. This innovative addition serves a dual purpose: enhancing the spatio-temporal feature set and aiding in semantic analysis. We achieve this by converting remote sensing images into spatial features, augmenting the data. Simultaneously, we introduce a self-supervised autoencoder to encode these images for enhanced semantic understanding.\nSecond, to capture geographical correlations, following the first law of geography in geography science, we utilize spatio-temporal region features that encompass the geographical layout of the regions to capture the physical proximity between different areas. Additionally, to capture traffic correlations, we construct a multi-view semantic similarity graph that quantifies the semantic similarities among regions based on attributes like Points of Interest (POI) distributions. By integrating these two components, we lay the foundation for a model that inherently considers both spatial and semantic aspects.\nThird, to address the zero-inflation problem, motivated by the idea of aggregation, we enhance the risk prediction at the lowest level by introducing multiple high-level risk prediction tasks, carefully tailored to low-sparsity data settings. In particular, we use regularized region partition and graph clustering to respectively construct hierarchical structures based on spatio-temporal region features and semantic graph features. In addition, we design a multi-level embedding fusion mechanism to fully leverage the hierarchical structure for mutual learning of different levels. Furthermore, we devise an adaptive temporal attention module to acquire temporal dependencies from the representations encoded by preceding modules, effectively harnessing the attention mechanism to adeptly capture correlations. Finally, we design a multivariate loss function to learn the proposed model comprehensively.\nIn summary, we make the following contributions:\n\u2022 We design a multi-granularity hierarchical spatio-temporal network, MGHSTN, that can fully exploit spatio-temporal features in traffic accidents in hierarchical manner. (Sec. 3)\n\u2022 We incorporate remote sensing images to enhance regional background comprehension and create multi-level hierarchical structures for both region feature and multi-view graph. (Sec. 3.1)\n\u2022 We design multiple encoding modules for multi-source spatio-temporal features and propose a cross-level message passing module to enable mutual learning across different levels. (Sec. 3.2)\n\u2022 We comprehensively model the traffic accident risk prediction problem by designing a multivariate loss function to cater to the multi-faceted objective of prediction. (Sec. 3.3)\n\u2022 We conduct a comprehensive evaluation on two real-world datasets. The results show that our method significantly outperforms state-of-the-art in terms of accuracy and robustness. (Sec. 4)"}, {"title": "2 PROBLEM FORMULATION", "content": "In this section, we first introduce some useful preliminaries. Then we formalize the traffic accident risk prediction problem."}, {"title": "2.1 Preliminaries", "content": "Region. In accordance with established urban zoning, the city is divided into N regions based on administrative divisions. Each of these regions is identified with an index i, and is referred to as Ui. This division improves traffic accident risk prediction by enabling detailed analysis of each region.\nRemote Sensing Images. Remote sensing has become an effective tool in understanding urban environments, which can provide rich information about topographic features of urban areas. As shown in Fig. 2 (a), we introduce remote sensing images $X = \\{x_i\\}_{i=1}^{N}$ to enhance regional background comprehension, where $x_i \\in \\mathbb{R}^{W\\times H\\times d_X}$.\nTraffic Accident Risk Map. As shown in Fig. 2 (a), we categorize traffic accidents based on the severity level in the dataset and assign a corresponding risk value to each category. Specifically, the risks of minor, injured, and fatal accidents have values of 1, 2, and 3, respectively. The traffic accident risk A for region Ui at interval t is the sum of risk values of all traffic accidents within that region and interval. Therefore, the risk map of all regions at t is denoted as the risk map $A_t \\in \\mathbb{R}^N$.\nSpatio-temporal Region Features. As shown in Fig. 2 (a), we construct multi-source spatio-temporal region features. The temporal features consist of hour of day, day of week, and holiday information, which can be easily obtained in advance. Since they are the same for all regions, we extend their dimension to fit the form of regions, which can be denoted as $T \\in \\mathbb{R}^{N\\times d_t}$, where $d_t$ is the dimension of temporal features. The spatial features $S \\in \\mathbb{R}^{N\\times d_s}$ encompass static features, climatic features and traffic features, where $d_s$ is the dimension of spatial features. Specifically, static features contain the distribution of different types of POI, climatic features contain temperature and weather information, and traffic features contain traffic accident risk map, inflow and outflow of each region. Combining the spatial and temporal features, we use $ST \\in \\mathbb{R}^{N\\times d_{st}}$ to represent spatio-temporal features, where $d_{st} = d_t + d_s$.\nMulti-view Semantic Similarity Graph. Intuitively, regions with similar semantic properties may have similar traffic accident patterns. To fully capture the semantic similarity between regions, as shown in Fig. 2 (b), we construct a multi-view semantic similarity graph $G_t = (V, E, M^t)$ at each interval t. Specifically, we use traffic features (i.e., traffic accident risk map, inflow, outflow) during the interval t as node features $M^t$, which means the graph is dynamic over time. Graph Gt contains three views, the road-view, the risk-view and the POI-view. The road view highlights similarities in road patterns, including road type, lane structure, and traffic signs. The risk view focuses on similarities in risk features. The POI view shows similarity in POI distribution, characterized by type and quantity. Note that the three views share the same nodes V and node features Mt, but different edges $E = \\{E_D, E_R, E_P\\}$. The construction detail is explained in Sec. 3.1.3."}, {"title": "2.2 Problem Definition", "content": "Given the Regions U, their corresponding remote sensing images X, historical spatio-temporal region features $\\{ST_1, ST_2, \u00b7 \u00b7 \u00b7, ST_T \\}$, historical semantic similarity graphs $\\{G_1, G_2, \u00b7 \u00b7 \u00b7, G_T \\}$ and the future temporal feature TT+1, our goal is to predict the traffic accident risk map AT+1 at the next interval T + 1."}, {"title": "3 METHODOLOGY", "content": "In this section, we present our proposed MGHSTN. As shown in Fig. 3, it consists of three key phases: Hierarchical Data Construction in Sec. 3.1, Feature Encoding in Sec. 3.2, and Fusion Prediction in Sec. 3.3. The structure constructed in the first phase enhances the model's ability to address sparsity issues from a novel hierarchical perspective. In the second phase, effective representation learning is meticulously carried out for the constructed hierarchy. Finally, the third phase fully integrates the feature representations and delivers comprehensive and effective prediction results. Each phase incorporates innovative strategies that significantly enhance the model's performance in estimating traffic accident risk."}, {"title": "3.1 Hierarchical Data Construction", "content": "In this section, we innovatively constructs two types of hierarchical structures for region feature and graph feature. Moreover, by integrating remote sensing encoding methods tailored to each type of feature, we construct a more subtle hierarchical data structure with effective regional background comprehension.\n3.1.1 Remote Sensing Feature Enhancement. To enhance regional background understanding through remote sensing images, we first use the CNN module to encode the remote sensing images X, which can be formulated as the following equation:\n$X_k = \\text{MaxPool}(\\sigma(W_k * X_{k-1} + b_k)))$\n$F_{rs} = FC(X_k)$\nwhere * represents convolution operation, $\\sigma(\\cdot)$ is the ReLU activation function, k is the layer of convolution. Wk, bk are trainable weights. $F_{rs} \\in \\mathbb{R}^{N\\times d_a}$ is the encoded remote sensing feature.\nThe spatio-temporal region features ST we originally constructed already contain multivariate information, which is the foundation for our model to fully learn the complex spatio-temporal correlations between traffic accidents. To further improve regional background comprehension, we use the encoded remote sensing features for enhancement, which are concatenated with ST.\n3.1.2 Multi-level region feature construction. The original spatio-temporal region features $ST \\in \\mathbb{R}^{N\\times d_{st}}$ are divided by regions, to capture localized geographical correlations, we use different sized grids to subdivide regions, resulting in multi-level hierarchical spatio-temporal region features $\\{ST^{g_1}, ST^{g_2}, . . ., ST^{g_n} \\}$, where $g_1$ denotes the finest granularity, $g_n$ represents the coarsest granularity. Specifically, constrained by the granularity of data collection, we aggregate the finest granularity data to obtain coarser-grained hierarchical data. Considering ST contains multi-source features, which have different statistical characteristics, therefore we utilize the maximum, mean and summation methods respectively for aggregation. For instance, the maximum method can ensure that no weather conditions are lost after aggregation, the average method can determine the appropriate temperature of aggregated grids, and the summation method can reasonably obtain the aggregated value for traffic accident risk.\n3.1.3 Multi-view Graph Construction. Traffic accidents show a connection that can be largely understood by analyzing semantic features on the ground, such as POIs and road structures [18]. Based on the semantic features, we construct three semantic similarity graphs, namely the road-view similarity graph $G^D = (V, E_D)$, the risk-view similarity graph $G^R = (V, E_R)$ and the POI-view similarity graph $G^P = (V, E_P)$.\nTo represent the similarity of road, risk, and POI between any two nodes, we use Jensen-Shannon divergence [19] to calculate the similarity score. Taking the POI similarity as an example, it can be computed by the following equation:\n$Sim_p (U_i, U_j) = 1 - JS(R_p, R_p)$\n$JS(R_p, R_p) = \\frac{1}{2} \\sum_{d=1}^{D} (R_{ip} (d) \\log \\frac{2R_{ip} (d)}{R_{ip} (d) + R_j (d)} + R_j (d) \\log \\frac{2R_j (d)}{R_{ip} (d) + R_j (d)})$"}, {"content": "where Rip, Rj denote the POI distribution of region Ui and Uj and D is the dimension of POI information. Similarly, we also calculate SimR (Ui, Uj) and SimD (Ui, Uj) for road-view and risk-view.\nAfterwards, we use the semantic similarity calculated between each pair of nodes as the weight and select the Top-K most similar nodes as neighbors for each node. Finally, we construct adjacency matrices $M_A = [M_D, M_R, M_P] \\in \\mathbb{R}^{N\\times N}$ for three different views, where N is the number of regions.\nThe adjacency matrices represent global semantic similarity structures between regions, but has no specific node features. Therefore, we use traffic features (i.e., traffic accident risk map, inflow, outflow) as node features $M \\in \\mathbb{R}^{N\\times d_c}$ for each time interval t. Finally, we perform matrix multiplication between the adjacency matrices MA of the three views and the node features Mt separately to get multi-view semantic similarity graph $G_t = M_A M_t$.\n3.1.4 Pre-train & Remote Sensing Embedding. Remote sensing images can provide regional information, which can be encoded as remote sensing features Frs as done in Sec. 3.1.1. For multi-level graph construction, we further mine them from another perspective, the perspective of similarity clustering. Aiming to learn the semantic properties of remote sensing images, autoencoder can be trained as a feature extractor by minimizing the reconstruction error between input and output data [17]. To obtain remote sensing embeddings as much as possible from the global perspective, as shown in Fig. 4, we propose a remote sensing autoencoder. The entire process of remote sensing autoencoder is as follows:\n$F_k = \\sigma(\\text{MaxPool}(\\sigma(W^{(E_0)} * F_{X^{k-1}} + b^{(E_0)})) * W^{(E_1)} + b^{(E_1)})$\n$x_k = \\sigma(\\text{UpSample}(\\sigma(W^{(D_0)} * x_{k-1} + b^{(D_0)})) * W^{(D_1)} + b^{(D_1)})$"}, {"content": "where * represents convolution operation, Fx is the feature map of k-th encoder, $\\sigma(\\cdot)$ is the ReLU activation function, Wk, bk are trainable weights, xk is the reconstructed image of k-th decoder.\nIn this work, we pre-train the autoencoder from scratch by using two different losses, which can be computed as follows:\n$\\text{loss}_{pp} (x, x') = \\frac{1}{c'h'w'} \\sum_{i=1}^{c'} \\sum_{j=1}^{h'} \\sum_{k=1}^{w'} (x_{ijk} - x'_{ijk})^2$\n$\\text{loss}_{feat} (F_j, F') = \\frac{1}{c'h'w'} \\sum_{i=1}^{c'} \\sum_{j=1}^{h'} (F_{ij} - F'_{ij})^2$"}, {"content": "where losssspp is the per-pixel loss, forces the pixel value of x' to resemble the ones of x. Fx and Fx' are the feature maps obtained by encoding input image x and reconstructed output image x'. lossssfeat is the feature loss, measures the difference between the feature maps Fx and the feature maps Fx'. After pre-training, we separately use the encoder part to obtain remote sensing embeddings Ers.\n3.1.5 Multi-level Graph Construction. To construct hierarchical graph structure, we propose Algorithm 1 for hierarchical graph clustering to get hierarchical aggregation relationships Ra."}, {"title": "3.2 Feature Encoding", "content": "In this section, we address the distinctive characteristics of geography, traffic and time series by introducing dedicated modules for their encoding: the Region Feature Encoding in Sec. 3.2.1 to capture spatial proximity, the Graph Feature Encoding in Sec. 3.2.2 to capture semantic similarity and the Time Series Correlation Capture in Sec. 3.2.3 to capture time series dependencies.\n3.2.1 Region Feature Encoding. According to previous studies [26, 31, 32, 41], for a specific region, the traffic accident risk of its target time interval is highly correlated with several previous time intervals on the same day and the same time interval several weeks prior, which is known as the short-term proximity and long-term periodicity. To this end, for all granularity $g^*$, we fetch region features from the previous p time intervals and the same time interval in previous q weeks as the historical observation sequence, whose length is T = p + q. Considering the relationships between region features and traffic accidents are highly dependent on the geographical spatial correlation between grids, we utilize convolutions to capture this correlation, which can be formulated as:\n$H_{t}^{g,k} = \\sigma(W^k * H_{t}^{g,k-1} + b^k)$"}, {"content": "where * represents convolution operation, $\\sigma(\\cdot)$ is the ReLU activation function, $W^k, b$ are trainable weights, $H_{t}^{g,k}$ is the output of the k-th convolutional layer at time interval t for granularity g.\n3.2.2 Graph Feature Encoding. Firstly, similar to region feature, we construct a graph historical observation sequence consisting of short-term and long-term for each granularity. Afterwards, aiming to model the semantic correlation between regions, we leverage graph convolution to learn node representations for the semantic similarity graph $G^{g^*} = [G^D, G^R, G^P]$ at each granularity g, which is computed as follows:\n$E_t^g = \\sigma(\\sigma(G_t^g W_g) + b_g)W^{(1)} + b^{(1)})$"}, {"content": "where $W_g$, by are trainable weights, $\\sigma(\\cdot)$ is the ReLU activation function, $E_t^g$ is the embedding of semantic similarity graph.\nIn Sec. 3.1.5, we perform hierarchical graph clustering based on remote sensing similarity, aiming to construct multi-level graph, which results in coarse-grained graph nodes having more accident counts. To enhance prediction at the finest-grained level and capture spatial relationships across varying granularities, we propose multi-level embedding fusion module. As shown in Fig. 5, the information transfer between different granularity levels is based on the hierarchical aggregation relationship Ra. Since each coarse-grained graph node is composed of several fine-grained graph nodes, there is an aggregation relationship between adjacent levels. Based on that, we propose the following procedure:\n1. Firstly, we construct a granularity transformation matrix Mtran for any two adjacent layers based on Ra as follows:\n$M_{tran} (i, j) = \\begin{cases} 1 & \\text{if } U_i^{g_{fine}} \\in U_j^{g_{coarse}} \\\\ 0 & \\text{otherwise} \\end{cases}$"}, {"content": "where $U_i^{g_{fine}}$ denotes the region i of granularity $g_{fine}$ and $U_j^{g_{coarse}}$ denotes the region j of granularity $g_{coarse}$.\n2. Then, for any two adjacent layers, we use the following equation to perform embedding fusion:\n$E_{t,coarse}^g = E_{t,coarse}^g + A_f M_{tran} E_{t,fine}^g$\n$E_{t,fine}^g = E_{t,fine}^g + A_c M_{tran} E_{t,coarse}^g$"}, {"content": "where Af and Ac are the fusion coefficient of relatively fine layer and coarse layer.\n3. Finally, we repeat step 2 from fine to coarse, generating fused embedding $E_t^g$ for each granularity level. The output sequence of this module is denoted as $\\{E^g\\} = \\{E_1^g, E_2^g, ... , E_T^g\\}$\n3.2.3 Time Series Correlation Capture. So far, the model has completed preliminary feature encoding. To fully capture the short-term proximity and long-term periodicity, as shown in Fig. 6, we propose an adaptive temporal attention module. Specifically, taking the output sequence $\\{H^g\\}$ of the region feature encoding as an example, we first follow the mechanism proposed in [30] to perform positional encoding. For each element $H_t^g$ in the sequence, it corresponds to a positional encoding $H_0 \\in \\mathbb{R}^{d_{st}}$, which is computed as follows:\n$H[2k] = sin(t/10000^{\\frac{2k}{d_{st}}})$\n$H[2k+1] = cos(t/10000^{\\frac{2k}{d_{st}}})$"}, {"content": "where H[2k] and H [2k + 1] correspond to even and odd dimensions of Ho, respectively. Next, we apply N self-attention blocks to convert the code $H_t^g$ into the code $H_t^g$ for each time interval t. Specifically, each block includes the following steps:\n1. Self-attention: For each code $H_t^g$, we first generate query($Q_t^g = W_q H_t^g$), key($K_t^g = W_k H_t^g$) and value($V_t^g = W_v H_t^g$). Then, we compute the $\\text{score}(t, t') = softmax(\\frac{Q_t K_{t'}^T}{\\sqrt{d_{st}}})$. Afterwards, the code $H_t^g$ would be converted into a new representation (i.e., $z_t^a = \\sum_{t'} \\text{score}(t, t')V_{t'}^g$).\n2. Add & Normalize: We leverage ResNet [10] and the layer-normalization [2] to accelerate the training process. Hence, the code would be updated: $H_t^g = LN(H_t^g \\oplus z_t^a)$\n3. Feed Forward: For each updated code, we further encode it with a fully connected layer: $z_t^f = ReLU (W_f H_t^g + b_f)$.\n4. Add & Normalize: Similar to step 2, the code is updated as following: $H_t^g = LN(H_t^g \\oplus z_t^f)$\nFor simplicity, we denote the above four steps in the i-th block for granularity g as $\\text{SAB}^i(\\cdot)$. Thus, the sequence $\\{H^g\\}$ is generated by N self-attention blocks, which can be formulated as below:\n$\\{H^g\\} = \\text{SAB}^N (\\text{SAB}^{N-1}(\u00b7\u00b7\u00b7 \\text{SAB}^1(\\{H_t^g\\})))$"}, {"content": "Considering that the sequence $\\{H^g\\}$ is composed of historical observations from different time intervals, each element $H_t^g$ in sequence has different impact on the traffic accident situation at target time interval T + 1, we introduce a temporal attention mechanism to adaptively capture the dynamic correlation between historical observations and target interval. Specifically, we first calculate the attention scores between $\\{H^g\\}$ and target time interval's temporal feature TT+1, and use them as weights for summation to obtain the final output $\\{\\hat{H}^g\\}$, which can be formulated as follows:\n$\\alpha = softmax(ReLU(\\{H^g\\} W_H + T_{T+1} W_T + b_a))$\n$\\{\\hat{H}^g\\} = \\sum_{i=1}^{T} \\alpha_i H_i^g$"}, {"content": "where WH, WT and ba are trainable weights, $\\alpha \\in \\mathbb{R}^T$ is the attention score vector, which can be considered as the importance distribution of different historical observation. Similarly, for the output sequence $\\{E^g\\}$ of the cross-granularity message passing part, the same adaptive temporal attention module is adopted to obtain $\\{\\hat{E}^g\\}$."}, {"title": "3.3 Fusion Prediction", "content": "First, we fuse each pair of $\\{\\hat{H}^g\\}$ and $\\{\\hat{E}^g\\}$, which are the final encoding of region features and graph features. Considering that they are obtained from different form of data, thus have different degrees of influence on the target region, we therefore adapt two trainable weight matrices and a fully connected layer to dynamically fuse them, which can be formulated as below:\n$\\hat{A}_{T+1}^g = FC(W_1\\{\\hat{H}^g\\} + W_2\\{\\hat{E}^g\\})$"}, {"content": "where W1 and W2 are trainable weights, and $\\hat{A}_{T+1}^g$ is the traffic accident risk map prediction of granularity g.\nNext, to model the problem comprehensively, we design a multivariate hierarchical loss function, which consists of three parts: weighted mean squared error loss lllllosswmse, binary cross entropy lossssbce, and hierarchical constraint llllosssshc:\nWeighted Mean Squared Error: Motivated by [31], to give higher emphasis to high-risk accident areas and address the issue of zero inflation, we classify all accident samples into four levels based on their risks and assign different weights to them:\n$llllloss_{wmse}^g = \\sum_{i=1}^{N_g} \\lambda_i (A^g(i) - \\hat{A}^g(i))^2$"}, {"content": "where \u00c2g and Ag are the prediction and ground truth of granularity g, Ag(i) and \u00c2g(i) are the samples and weight whose traffic accident risk level is i, and Ng is the number of regions of granularity g.\nBinary Cross Entropy: Different from the global perspective in lllllosswmse, we utilize binary cross entropy to measure the accuracy of predicting the occurrence of traffic accidents:\n$llllloss_{bce} = \\frac{1}{N_g} \\sum_{i=1}^{N} (A_i \\log(\\hat{A}_i) + (1 - A_i) \\log(1 - \\hat{A}_i))$"}, {"content": "where Ai and \u00c2i are the prediction and ground truth of region Ui.\nHierarchical Constraint: To fully utilizing our multi-granularity hierarchical structure, we construct hierarchical constraint by utilizing the consistency between adjacent granularity level prediction results. Specifically, only the constraint between the finest-grained level g1 and second-fine-grained level g2 are considered since their number of regions is sufficient, which can be formulated as follows:\n$llllloss_{hc} = \\frac{1}{N_{g^2}} (A^{g^2} - \\hat{A}^{g^1} M_{tran})$"}, {"content": "where \u00c2g2 is ground truth of granularity g2, $\\hat{A}^{g^1}$ is the prediction of granularity g1, Mtran is the granularity transformation matrix computed by equation 8.\nBy combining the three mentioned loss functions, the final loss function is defined as follows:\n$lossf = \\sum_{i=1}^{n} (\\lambda_{wmse} llllloss_{wmse} + \\lambda_{bce} llllloss_{bce}) + \\lambda_{hc} llllloss_{hc}$"}, {"content": "where $\\lambda_{wmse}$ and $\\lambda_{bce}$ are the weights of loss at granularity g1, dhc and lllllosshe are the weight and hierarchical constraint."}, {"title": "4 EXPERIMENTS", "content": "4.1 Datasets\nAs shown in Table 1, we use two large public real-world datasets collected from NYC\u00b9 and Chicago\u00b2. The traffic accident data contains date, time, latitude and longitude, and the number of causalities. The taxi order data includes location and time of pick-up and drop-offs, which is used to calculate the traffic flow. The POI data has seven categories: residence, school, culture facility, recreation, social service, transportation and commercial. The weather data contains temperature and sky condition (i.e., sunny, rainy, cloudy, snowy and foggy). Note that for Chicago, POI data is lacking, so we only construct the road-view and risk-view semantic similarity graph. The road segment data includes road types, length and width, and snow removal priority. For remote sensing image data, we get the images of corresponding time from Google Earth.\n4.2 Evaluation Metrics\nTo evaluate the performance of our model, we utilise three commonly used metrics for traffic accident risk prediction task [5, 23, 26, 31, 32], namely RMSE, Recall and MAP. From the perspective of regression, RMSE is used to evaluate the overall prediction of traffic accident risk. From the perspective of ranking and classification, we use Recall to evaluate classification accuracy for accident area prediction, and use MAP to evaluate ranking accuracy for high accident risk areas prediction. Lower RMSE indicates that the model can predict risk more accurately overall, while a higher Recall and MAP indicate the better performance in high-risk regions, which can be considered having better coping abilities for zero-inflation problem. The three metrics are computed as follows:\nRMSE = $\\sqrt{\\frac{1}{\\vert T \\vert} \\sum_{t=1}^{T}(A_t - \\hat{A}_t)^2}$, Recall = $\\frac{\\vert S_t \\cap R_t \\vert}{\\vert R_t \\vert}$, MAP = $\\frac{1}{\\vert R_t \\vert} \\sum_{j=1}^{\\vert S_t \\vert} \\text{pre}(j) \\times \\text{rel}(j)$"}, {"content": "where At is the ground truth and \u00c2t is the predicted values at time interval t. Rt is the set of regions where traffic accidents have actually occurred at time interval t. St is a set of regions with top |Rt | highest predicted risks. pre(j) denotes the precision of a cut-off rank list from 1 to j. rel(j) = 1 if there are traffic accidents in region j, otherwise rel(j) = 0.\nFurthermore, we record the above metrics specifically on the rush hours during which the frequency of traffic accidents are usually higher, i.e., 7:00-9:00 and 16:00-19:00, and for simplicity we name them as RMSE*, Recall*, and MAP*, respectively.\n4.3 Experimental Settings\nWe partition all data into training, validation and test set with the ratio of 6:2:2. The city region is divided into grids with a size of"}, {"title": "4.5 Effectiveness of Loss Weight", "content": "To fine-tune the loss weight $\\lambda_{wmse"}], "observations": "n(1) Avg is worse than any other deep learning based methods, since it does not utilize spatio-temporal features and cannot learn the spatio-temporal correlations of traffic accidents.\n(2) GRU and H-ConvLSTM have relatively poor performance among learning-based methods. Although they outperform Avg on RMSE, they underperform Avg in some cases on Recall and MAP, indicating that they suffer from zero-inflation problem.\n(3) Whether using remote sensing, MGHSTN outperforms other models overall. For example, MGH"}