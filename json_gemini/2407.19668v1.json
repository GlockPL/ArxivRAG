{"title": "Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity", "authors": ["Minxiao Chen", "Haitao Yuan", "Nan Jiang", "Zhifeng Bao", "Shangguang Wang"], "abstract": "Traffic accidents pose a significant risk to human health and property safety. Therefore, to prevent traffic accidents, predicting their risks has garnered growing interest. We argue that a desired prediction solution should demonstrate resilience to the complexity of traffic accidents. In particular, it should adequately consider the regional background, accurately capture both spatial proximity and semantic similarity, and effectively address the sparsity of traffic accidents. However, these factors are often overlooked or difficult to incorporate. In this paper, we propose a novel multi-granularity hierarchical spatio-temporal network. Initially, we innovate by incorporating remote sensing data, facilitating the creation of hierarchical multi-granularity structure and the comprehension of regional background. We construct multiple high-level risk prediction tasks to enhance model's ability to cope with sparsity. Subsequently, to capture both spatial proximity and semantic similarity, region feature and multi-view graph undergo encoding processes to distill effective representations. Additionally, we propose message passing and adaptive temporal attention module that bridges different granularities and dynamically captures time correlations inherent in traffic accident patterns. At last, a multivariate hierarchical loss function is devised considering the complexity of the prediction purpose. Extensive experiments on two real datasets verify the superiority of our model against the state-of-the-art methods.", "sections": [{"title": "1 INTRODUCTION", "content": "According to the World Health Organization (WHO) [33], approximately 1.3 million people die each year due to traffic accidents, making it a leading cause of death among children and young adults aged 5 to 29. In response, the United Nations General Assembly has set an ambitious target of halving the global number of deaths and injuries from road traffic crashes by 2030 [29]. Therefore, it is of vital importance to predict traffic accident risk accurately, which can assist government in managing traffic risks and help drivers avoid high-risk areas. When revisiting this problem, we find some critical yet missing aspects that contribute to its accuracy boost.\n(1) Regionality: Regional Background Effects. Traffic accidents are affected by many complex factors, and the ways to which these factors affect are difficult to analyze. To capture the underlying mechanisms of traffic accidents, regional background is essential. For instance, as shown in Fig. 1, different regions may have share similar road structure (e.g., crossroads) and weather (e.g., sunny), but entirely different regional background (e.g., parking lot, lake, small park vs. dense residential area). This leads to significant variations in traffic accident patterns. However, these regional backgrounds are often overlooked and difficult to capture.\n(2) Proximity and Similarity: Spatial and Semantic Correlations. Traffic accidents exhibit dual correlation involving both spatial proximity and semantic similarity. This implies that traffic accidents occurring in close areas or areas sharing similar semantic properties tend to have high similarities [39]. For example, in Fig. 1, the adjacency of Region 1 and Region 2 suggests interconnected roads, while the similar distribution of POIs in Region 1 and Region 3 contributes to similar accident patterns. Effectively capturing both types of correlations poses a significant challenge.\n(3) Sparsity: Zero-Inflation Problem. As shown in the lower right part of Fig. 1, the number of traffic accidents in NYC during an afternoon is presented in a heatmap. Notably, most regions experience zero traffic accidents. This is identified as the zero-inflation problem. Failure to properly address this sparsity can lead the model to generate predictions with an excessive number of zeros, rendering the predictions meaningless [21].\nUnfortunately, existing studies have not thoroughly captured most of the above aspects. Traditionally, statistics-based methods [3, 6, 22, 27] merely utilize the statistics information of historical accidents, ignoring the influence of many spatio-temporal factors, which leads to poor performance. To alleviate this, learning-based methods [1, 4, 5, 26, 28, 31, 32, 38] have been proposed. They analyze spatio-temporal features to capture the correlations between traffic accidents. However, they fail to effectively capture the spatial proximity and semantic similarity of traffic accidents and miss out on the regional background of where they occur. Worse still, their approach to dealing with sparsity is not sufficiently effective.\nTo incorporate all the above critical aspects, we design a Multi-Granularity Hierarchical Spatio-Temporal Network (MGHSTN) for traffic accident risk prediction.\nFirst, recognizing the informative potential of remote sensing images in revealing regional backgrounds, we integrate them into the traffic accident risk prediction process. This innovative addition serves a dual purpose: enhancing the spatio-temporal feature set and aiding in semantic analysis. We achieve this by converting remote sensing images into spatial features, augmenting the data. Simultaneously, we introduce a self-supervised autoencoder to encode these images for enhanced semantic understanding.\nSecond, to capture geographical correlations, following the first law of geography in geography science, we utilize spatio-temporal region features that encompass the geographical layout of the regions to capture the physical proximity between different areas. Additionally, to capture traffic correlations, we construct a multi-view semantic similarity graph that quantifies the semantic similarities among regions based on attributes like Points of Interest (POI) distributions. By integrating these two components, we lay the foundation for a model that inherently considers both spatial and semantic aspects.\nThird, to address the zero-inflation problem, motivated by the idea of aggregation, we enhance the risk prediction at the lowest level by introducing multiple high-level risk prediction tasks, carefully tailored to low-sparsity data settings. In particular, we use regularized region partition and graph clustering to respectively construct hierarchical structures based on spatio-temporal region features and semantic graph features. In addition, we design a multi-level embedding fusion mechanism to fully leverage the hierarchical structure for mutual learning of different levels. Furthermore, we devise an adaptive temporal attention module to acquire temporal dependencies from the representations encoded by preceding modules, effectively harnessing the attention mechanism to adeptly capture correlations. Finally, we design a multivariate loss function to learn the proposed model comprehensively.\nIn summary, we make the following contributions:\n\u2022 We design a multi-granularity hierarchical spatio-temporal network, MGHSTN, that can fully exploit spatio-temporal features in traffic accidents in hierarchical manner. (Sec. 3)\n\u2022 We incorporate remote sensing images to enhance regional background comprehension and create multi-level hierarchical structures for both region feature and multi-view graph. (Sec. 3.1)\n\u2022 We design multiple encoding modules for multi-source spatio-temporal features and propose a cross-level message passing module to enable mutual learning across different levels. (Sec. 3.2)\n\u2022 We comprehensively model the traffic accident risk prediction problem by designing a multivariate loss function to cater to the multi-faceted objective of prediction. (Sec. 3.3)\n\u2022 We conduct a comprehensive evaluation on two real-world datasets. The results show that our method significantly outperforms state-of-the-art in terms of accuracy and robustness. (Sec. 4)"}, {"title": "2 PROBLEM FORMULATION", "content": "In this section, we first introduce some useful preliminaries. Then we formalize the traffic accident risk prediction problem.\n2.1 Preliminaries\nRegion. In accordance with established urban zoning, the city is divided into N regions based on administrative divisions. Each of"}, {"title": "METHODOLOGY", "content": "In this section, we present our proposed MGHSTN. As shown in Fig. 3, it consists of three key phases: Hierarchical Data Construction in Sec. 3.1, Feature Encoding in Sec. 3.2, and Fusion Prediction in Sec. 3.3. The structure constructed in the first phase enhances the model's ability to address sparsity issues from a novel hierarchical perspective. In the second phase, effective representation learning is meticulously carried out for the constructed hierarchy. Finally, the third phase fully integrates the feature representations and delivers comprehensive and effective prediction results. Each phase incorporates innovative strategies that significantly enhance the model's performance in estimating traffic accident risk.\n3.1 Hierarchical Data Construction\nIn this section, we innovatively constructs two types of hierarchical structures for region feature and graph feature. Moreover, by integrating remote sensing encoding methods tailored to each type of feature, we construct a more subtle hierarchical data structure with effective regional background comprehension.\n3.1.1 Remote Sensing Feature Enhancement. To enhance regional background understanding through remote sensing images, we first use the CNN module to encode the remote sensing images X, which can be formulated as the following equation:\n\\(X_k = \\text{MaxPool}(\\sigma(W_k * X_{k-1} + b_k)))\\\nF_{rs} = FC(X_k)\\)\nwhere * represents convolution operation, \\(\\sigma(\\cdot)\\) is the ReLU activation function, k is the layer of convolution. Wk, bk are trainable weights. \\(F_{rs} \\in \\mathbb{R}^{N \\times d_a}\\) is the encoded remote sensing feature.\nThe spatio-temporal region features ST we originally constructed already contain multivariate information, which is the foundation for our model to fully learn the complex spatio-temporal correlations between traffic accidents. To further improve regional background comprehension, we use the encoded remote sensing features for enhancement, which are concatenated with ST.\n3.1.2 Multi-level region feature construction. The original spatio-temporal region features \\(ST \\in \\mathbb{R}^{N \\times d_{st}}\\) are divided by regions, to capture localized geographical correlations, we use different sized grids to subdivide regions, resulting in multi-level hierarchical spatio-temporal region features \\(\\{ST^{g_1}, ST^{g_2}, ..., ST^{g_n} \\}\\), where \\(g^1\\) denotes the finest granularity, \\(g^n\\) represents the coarsest granularity. Specifically, constrained by the granularity of data collection,"}, {"title": "Multi-view Graph Construction", "content": "Traffic accidents show a connection that can be largely understood by analyzing semantic features on the ground, such as POIs and road structures [18]. Based on the semantic features, we construct three semantic similarity graphs, namely the road-view similarity graph \\(G^D = (V, E^D)\\), the risk-view similarity graph \\(G^K = (V, E^K)\\) and the POI-view similarity graph \\(G^P = (V, E^P)\\).\nTo represent the similarity of road, risk, and POI between any two nodes, we use Jensen-Shannon divergence [19] to calculate the similarity score. Taking the POI similarity as an example, it can be computed by the following equation:\n\\(\\text{Sim}_P(U_i, U_j) = 1 - JS(R^P_i, R^P_j)\\)\n\\(JS(R^P_i, R^P_j) = \\frac{1}{2} \\sum_{d=1}^{D} R^P_i(d) \\log{\\frac{2R^P_i(d)}{R^P_i(d) + R^P_j(d)}} + 2R^P_j(d) \\log{\\frac{2R^P_j(d)}{R^P_i(d) + R^P_j(d)}}\\)\nwhere \\(R^P_i, R^P_j\\) denote the POI distribution of region \\(U_i\\) and \\(U_j\\) and D is the dimension of POI information. Similarly, we also calculate \\(\\text{Sim}_D(U_i, U_j)\\) and \\(\\text{Sim}_K(U_i, U_j)\\) for road-view and risk-view.\nAfterwards, we use the semantic similarity calculated between each pair of nodes as the weight and select the Top-K most similar nodes as neighbors for each node. Finally, we construct adjacency matrices \\(\\mathbf{M}_A = [\\mathbf{M}_D, \\mathbf{M}_K, \\mathbf{M}_P] \\in \\mathbb{R}^{N \\times N}\\) for three different views, where N is the number of regions.\nThe adjacency matrices represent global semantic similarity structures between regions, but has no specific node features. Therefore, we use traffic features (i.e., traffic accident risk map, inflow, outflow) as node features \\(\\mathbf{M}^t \\in \\mathbb{R}^{N \\times d_c}\\) for each time interval t. Finally, we perform matrix multiplication between the adjacency matrices \\(\\mathbf{M}_A\\) of the three views and the node features \\(\\mathbf{M}^t\\) separately to get multi-view semantic similarity graph \\(G^t = \\mathbf{M}_A \\mathbf{M}^t\\).\n3.1.4 Pre-train & Remote Sensing Embedding. Remote sensing images can provide regional information, which can be encoded as remote sensing features \\(F_{rs}\\) as done in Sec. 3.1.1. For multi-level"}, {"title": "Pre-train & Remote Sensing Embedding", "content": "Remote sensing images can provide regional information, which can be encoded as remote sensing features \\(F_{rs}\\) as done in Sec. 3.1.1. For multi-level graph construction, we further mine them from another perspective, the perspective of similarity clustering. Aiming to learn the semantic properties of remote sensing images, autoencoder can be trained as a feature extractor by minimizing the reconstruction error between input and output data [17]. To obtain remote sensing embeddings as much as possible from the global perspective, as shown in Fig. 4, we propose a remote sensing autoencoder. The entire process of remote sensing autoencoder is as follows:\n\\(\\begin{aligned}\nF_k &= \\sigma(\\text{MaxPool}(\\sigma(W^{(E0)} * F_{k-1} + b^{(E0)})) * W^{(E1)} + b^{(E1)})) \\\nx_k &= \\sigma(\\text{UpSample}(\\sigma(W^{(D0)} * x_{k-1} + b^{(D0)})) * W^{(D1)} + b^{(D1)}))\n\\end{aligned}\\)\nwhere * represents convolution operation, \\(F_x\\) is the feature map of k-th encoder, \\(\\sigma(\\cdot)\\) is the ReLU activation function, Wk, bk are trainable weights, \\(x_k\\) is the reconstructed image of k-th decoder.\nIn this work, we pre-train the autoencoder from scratch by using two different losses, which can be computed as follows:\n\\(\\begin{aligned}\n\\text{loss}_{pp}(x, x') &= \\frac{1}{c'h'w'} \\sum_{i=1}^{c'} \\sum_{j=1}^{h'} \\sum_{k=1}^{w'} (x_{ijk} - x'_{ijk})^2 \\\\\n\\text{loss}_{feat}(F_j, F'_j) &= \\frac{1}{c'h'w'} \\sum_{i=1}^{c'} \\sum_{j=1}^{h'} (F_{ij} - F'_{ij})^2\n\\end{aligned}\\)\nwhere \\(\\text{loss}_{pp}\\) is the per-pixel loss, forces the pixel value of x' to resemble the ones of x. Fx and Fx' are the feature maps obtained by encoding input image x and reconstructed output image x'. \\(\\text{loss}_{feat}\\) is the feature loss, measures the difference between the feature maps Fx and the feature maps Fx'. After pre-training, we separately use the encoder part to obtain remote sensing embeddings \\(E_{rs}\\).\n3.1.5 Multi-level Graph Construction. To construct hierarchical graph structure, we propose Algorithm 1 for hierarchical graph clustering to get hierarchical aggregation relationships Ra."}, {"title": "Algorithm 1: Hierarchical Graph Clustering", "content": "Input: RS embedding \\(E_{rs}\\), part number \\([N_1, N_2, ..., N_n]\\), graph size \\([L_1, L_2, ..., L_n]\\), granularity number n\nOutput: hierarchical aggregation relationships Ra\nbuild RS similarity graph \\(G^{g_1}_{rs}\\) at granularity \\(g^1\\) with \\(E_{rs}\\);\nfor i = 1...n do\nMi \u2190 graphPartition(Ni, Li, \\(G^{g_i}\\));\n\\(P_i\\) \u2190 extract(Mi);\n\\(X^{i+1}_{rs}\\) \u2190 averageAggregate \\((P_i, X^{i}_{rs});\\)\nbuild next level RS similarity graph \\(G^{g_{i+1}}_{rs}\\) with \\(X^{i+1}_{rs}\\);\nRa \u2190 \\([P_1, ..., P_n]\\);\nreturn Ra\nFirstly, we construct a novel remote sensing similarity graph denoted as \\(G_{rs} = (V, E_{rs})\\). We represent regions as nodes and use the remote sensing embedding \\(E_{rs}\\) as node features. We then establish edges \\(E_{rs}\\) between adjacent nodes based on spatial relationships. The weight of each edge between adjacent nodes is determined by the cosine similarity \\(\\text{cos}(E^i_{rs}, E^j_{rs})\\).\nNext, to classify nodes with similar remote sensing features and close spatial distances into the same category, we choose the classic graph clustering algorithm Metis [15]. Its primary goal is to"}, {"title": "Feature Encoding", "content": "In this section, we address the distinctive characteristics of geography, traffic and time series by introducing dedicated modules for their encoding: the Region Feature Encoding in Sec. 3.2.1 to capture spatial proximity, the Graph Feature Encoding in Sec. 3.2.2 to capture semantic similarity and the Time Series Correlation Capture in Sec. 3.2.3 to capture time series dependencies.\n3.2.1 Region Feature Encoding. According to previous studies [26, 31, 32, 41], for a specific region, the traffic accident risk of its target time interval is highly correlated with several previous time intervals on the same day and the same time interval several weeks prior, which is known as the short-term proximity and long-term periodicity. To this end, for all granularity \\(g^*\\), we fetch region features from the previous p time intervals and the same time interval in previous q weeks as the historical observation sequence, whose length is \\(T = p + q\\). Considering the relationships between region features and traffic accidents are highly dependent on the geographical spatial correlation between grids, we utilize convolutions to capture this correlation, which can be formulated as:\n\\(H^g_{t, k} = \\sigma(W_k * H^{g}_{t, k-1} + b_k)\\)\nwhere * represents convolution operation, \\(\\sigma(\\cdot)\\) is the ReLU activation function, Work, bk are trainable weights, \\(H^g_{t,k}\\) is the output of the k-th convolutional layer at time interval t for granularity g."}, {"title": "Graph Feature Encoding", "content": "Firstly, similar to region feature, we construct a graph historical observation sequence consisting of short-term and long-term for each granularity. Afterwards, aiming to model the semantic correlation between regions, we leverage graph convolution to learn node representations for the semantic similarity graph \\(G^{g^*} = [G^D, G^K, G^P]\\) at each granularity g, which is computed as follows:\n\\(E^g_t = \\sigma(\\sigma(GW^g) + b)W^{(1)} + b^{(1)})\\)\nwhere Wg, by are trainable weights, \\(\\sigma(\\cdot)\\) is the ReLU activation function, \\(E^g_t\\) is the embedding of semantic similarity graph.\nIn Sec. 3.1.5, we perform hierarchical graph clustering based on remote sensing similarity, aiming to construct multi-level graph, which results in coarse-grained graph nodes having more accident counts. To enhance prediction at the finest-grained level and capture spatial relationships across varying granularities, we propose multi-level embedding fusion module. As shown in Fig. 5, the information transfer between different granularity levels is based on the hierarchical aggregation relationship Ra. Since each coarse-grained graph node is composed of several fine-grained graph nodes, there is an aggregation relationship between adjacent levels. Based on that, we propose the following procedure:\n1. Firstly, we construct a granularity transformation matrix Mtran for any two adjacent layers based on Ra as follows:\n\\text{M}_{tran}(i, j) = \\begin{cases}\n1 & \\text{if } U^{g_{fine}}_i \\in U^{g_{coarse}}_j \\\n0 & \\text{otherwise}\n\\end{cases}\nwhere \\(U^{g_{fine}}_i\\) denotes the region i of granularity gfine and \\(U^{g_{coarse}}_j\\) denotes the region j of granularity gcoarse.\n2. Then, for any two adjacent layers, we use the following equation to perform embedding fusion:\n\\(\\begin{aligned}\nE^{g_{coarse}}_t &= E^{g_{coarse}}_t + \\lambda_f M_{tran} E^{g_{fine}}_t \\\\\nE^{g_{fine}}_t &= E^{g_{fine}}_t + \\lambda_c M_{tran} E^{g_{coarse}}_t\n\\end{aligned}\\)\nwhere \\(\\lambda_f\\) and \\(\\lambda_c\\) are the fusion coefficient of relatively fine layer and coarse layer.\n3. Finally, we repeat step 2 from fine to coarse, generating fused embedding Eg for each granularity level. The output sequence of this module is denoted as \\(\\{E^g\\} = \\{E^{g_1}, E^{g_2}, ... , E^{g_T} \\}\\).\n3.2.3 Time Series Correlation Capture. So far, the model has completed preliminary feature encoding. To fully capture the short-term proximity and long-term periodicity, as shown in Fig. 6, we propose"}, {"title": "Time Series Correlation Capture", "content": "Firstly, similar to region feature, we construct a graph historical observation sequence consisting of short-term and long-term for each granularity. Afterwards, aiming to model the semantic correlation between regions, we leverage graph convolution to learn node representations for the semantic similarity graph \\(G^{g^*} = [G^D, G^K, G^P]\\) at each granularity g, which is computed as follows:\n\\(E^g_t = \\sigma(\\sigma(GW^g) + b)W^{(1)} + b^{(1)})\\)\nwhere Wg, by are trainable weights, \\(\\sigma(\\cdot)\\) is the ReLU activation function, \\(E^g_t\\) is the embedding of semantic similarity graph.\nIn Sec. 3.1.5, we perform hierarchical graph clustering based on remote sensing similarity, aiming to construct multi-level graph, which results in coarse-grained graph nodes having more accident counts. To enhance prediction at the finest-grained level and capture spatial relationships across varying granularities, we propose multi-level embedding fusion module. As shown in Fig. 5, the information transfer between different granularity levels is based on the hierarchical aggregation relationship Ra. Since each coarse-grained graph node is composed of several fine-grained graph nodes, there is an aggregation relationship between adjacent levels. Based on that, we propose the following procedure:\n1. Firstly, we construct a granularity transformation matrix Mtran for any two adjacent layers based on Ra as follows:\n\\text{M}_{tran}(i, j) = \\begin{cases}\n1 & \\text{if } U^{g_{fine}}_i \\in U^{g_{coarse}}_j \\\n0 & \\text{otherwise}\n\\end{cases}\nwhere \\(U^{g_{fine}}_i\\) denotes the region i of granularity gfine and \\(U^{g_{coarse}}_j\\) denotes the region j of granularity gcoarse.\n2. Then, for any two adjacent layers, we use the following equation to perform embedding fusion:\n\\(\\begin{aligned}\nE^{g_{coarse}}_t &= E^{g_{coarse}}_t + \\lambda_f M_{tran} E^{g_{fine}}_t \\\\\nE^{g_{fine}}_t &= E^{g_{fine}}_t + \\lambda_c M_{tran} E^{g_{coarse}}_t\n\\end{aligned}\\)\nwhere \\(\\lambda_f\\) and \\(\\lambda_c\\) are the fusion coefficient of relatively fine layer and coarse layer.\n3. Finally, we repeat step 2 from fine to coarse, generating fused embedding Eg for each granularity level. The output sequence of this module is denoted as \\(\\{E^g\\} = \\{E^{g_1}, E^{g_2}, ... , E^{g_T} \\}\\).\n3.2.3 Time Series Correlation Capture. So far, the model has completed preliminary feature encoding. To fully capture the short-term proximity and long-term periodicity, as shown in Fig. 6, we propose an adaptive temporal attention module. Specifically, taking the output sequence \\(\\{H^g\\}\\) of the region feature encoding as an example, we first follow the mechanism proposed in [30] to perform positional encoding. For each element \\(H^g_t\\) in the sequence, it corresponds to a positional encoding \\(H^g_0 \\in \\mathbb{R}^{d_{st}}\\), which is computed as follows:\n\\(\\begin{aligned}\nH^g_t[2k] &= \\text{sin}(t/10000^{\\frac{2k}{d_{st}}}) \\\\\nH^g_t[2k+1] &= \\text{cos}(t/10000^{\\frac{2k}{d_{st}}})\n\\end{aligned}\\)\nwhere \\(H^g_t[2k]\\) and \\(H^g_t[2k+1]\\) correspond to even and odd dimensions of \\(H^g_0\\), respectively. Next, we apply N self-attention blocks to convert the code \\(H^g_t\\) into the code \\(H^g_t\\) for each time interval t. Specifically, each block includes the following steps:\n1. Self-attention: For each code \\(H^g_t\\), we first generate query\\((Q^g_t = W_qH^g_t)\\), key\\((K^g_t = W_kH^g_t)\\) and value\\((V^g_t = WH^g_t)\\). Then, we compute the \\(\\text{score}(t, t') = \\text{softmax}(\\frac{Q^g_t K^{g^\\prime}}{\\sqrt{d_{st}}})\\). Afterwards, the code \\(H^g_t\\) would be converted into a new representation (i.e., \\(z^g_t = \\sum_{t'} \\text{score}(t, t') V^g_t\\).\n2. Add & Normalize: We leverage ResNet [10] and the layer-normalization [2] to accelerate the training process. Hence, the code would be updated: \\(H^g_t = LN(H^g_t \\oplus z^g_t)\\)\n3. Feed Forward: For each updated code, we further encode it with a fully connected layer: \\(z^g_t = \\text{ReLU}(W_fH^g_t + b_f)\\).\n4. Add & Normalize: Similar to step 2, the code is updated as following: \\(H^g_t = LN(H^g_t \\oplus z^g_t)\\)\nFor simplicity, we denote the above four steps in the i-th block for granularity g as \\(\\text{SAB}_i(\\cdot)\\). Thus, the sequence \\(\\{H^g\\}\\) is generated by N self-attention blocks, which can be formulated as below:\n\\(\\{H^g\\} = \\text{SAB}_N(\\text{SAB}_{N-1}(\u00b7\u00b7\u00b7 \\text{SAB}_1(\\{H^g\\})))\\)\nConsidering that the sequence \\(\\{H^g\\}\\) is composed of historical observations from different time intervals, each element \\(H^g_t\\) in sequence has different impact on the traffic accident situation at target time interval T + 1, we introduce a temporal attention mechanism to adaptively capture the dynamic correlation between historical observations and target interval. Specifically, we first calculate the attention scores between \\(\\{H^g\\}\\) and target time interval's temporal feature \\(T_{T+1}\\), and use them as weights for summation to obtain the final output \\(\\{\\hat{H}^g\\}\\), which can be formulated as follows:\n\\alpha = \\text{softmax}(\\text{ReLU}(\\{H^g\\}W_H + T_{T+1}W_T + b_a))\\)\n\\(\\{\\hat{H}^g\\} = \\sum_{i=1}^{T} \\alpha_t H^g_t\\)\nwhere \\(W_H, W_T\\) and \\(b_a\\) are trainable weights, \\(\\alpha \\in \\mathbb{R}^{T}\\) is the attention score vector, which can be considered as the importance distribution of different historical observation. Similarly, for the output sequence \\(\\{E^g\\}\\) of the cross-granularity message passing part, the same adaptive temporal attention module is adopted to obtain \\(\\{\\hat{E}^g\\}\\).\n3.3 Fusion Prediction\nFirst, we fuse each pair of \\(\\{\\hat{H}^g\\}\\) and \\(\\{\\hat{E}^g\\}\\), which are the final encoding of region features and graph features. Considering that they are obtained from different form of data, thus have different degrees of influence on the target region, we therefore adapt two trainable weight matrices and a fully connected layer to dynamically fuse them, which can be formulated as below:\n\\(\\hat{A}^g_{T+1} = FC(W_1\\{\\hat{H}^g\\} + W_2\\{\\hat{E}^g\\})\\)\nwhere W\u2081 and W\u2082 are trainable weights, and \\(\\hat{A}^g_{T+1}\\) is the traffic accident risk map prediction of granularity g.\nNext, to model the problem comprehensively, we design a multivariate hierarchical loss function, which consists of three parts: weighted mean squared error loss \\(loss_{wmse}\\), binary cross entropy loss\\(loss_{bce}\\), and hierarchical constraint \\(loss_{hc}\\):\nWeighted Mean Squared Error: Motivated by [31], to give higher emphasis to high-risk accident areas and address the issue of zero inflation, we classify all accident samples into four levels based on their risks and assign different weights to them:\n\\(loss_{wmse} = \\sum_i^{N_g} \\lambda_i (A^g(i) - \\hat{A}^g(i))^2\\)\nwhere \\(A^g\\) and \\(\\hat{A}^g\\) are the prediction and ground truth of granularity g, \\(A^g(i)\\) and \\(\\hat{A}^g(i)\\) are the samples and weight whose traffic accident risk level is i, and Ng is the number of regions of granularity g.\nBinary Cross Entropy: Different from the global perspective in \\(loss_{wmse}\\), we utilize binary cross entropy to measure the accuracy of predicting the occurrence of traffic accidents:\n\\(loss_{bce} = \\frac{1}{N_g} \\sum_i^N A_i log(\\hat{A}^i) + (1 - A_i) log(1 - \\hat{A}^i)\\)\nwhere A and \u00c2 are the prediction and ground truth of region Ui.\nHierarchical Constraint: To fully utilizing our multi-granularity hierarchical structure, we construct hierarchical constraint by utilizing the consistency between adjacent granularity level prediction results. Specifically, only the constraint between the finest-grained level \\(g^1\\) and second-fine-grained level \\(g^2\\) are considered since their number of regions is sufficient, which can be formulated as follows:\n\\(loss_{hc} = \\frac{1}{N_{g^2}} (A^{g^2} - \\hat{A}^{g^1} M_{tran})\\)\nwhere \\(A^{g^2}\\) is ground truth of granularity \\(g^2\\), \\(\\hat{A}^{g^1}\\) is the prediction of granularity \\(g^1\\), Mtran is the granularity transformation matrix computed by equation 8.\nBy combining the three mentioned loss functions, the final loss function is defined as follows:\n\\text{loss}_{f} = \\sum_{i=1}^n (\\lambda_{wmse} \\text{loss}_{wmse} + \\lambda_{bce} \\text{loss}_{bce}) + \\lambda_{hc} \\text{loss}_{hc}\nwhere \\(\\lambda_{wmse}\\), \\(\\lambda_{bce}\\) and \\(\\lambda_{hc}\\) are the weights of loss at granularity \\(g^1\\), dhc and \\(loss_{hc}\\) are the weight and hierarchical constraint."}, {"title": "Efficiency Comparison", "content": "For efficiency evaluation, we record the memory size, training time and prediction time. The memory size represents the required memory for training. The training time is the average time cost of an epoch. The prediction time is the time to predict all regions for one time interval. Note that the pre-training of the autoencoder introduced in 3.1.4 is conducted in advance, hence it does not incur additional time costs.\nwe have the following observations:\n(1) MGHSTN outperforms the five variants on all metrics. In particular, the multi-granularity hierarchical structure is very critical, removing it will lead to 64.5% performance loss on RMSE of Chicago. Meanwhile, removing the multi-level embedding fusion significantly reduce Recall and MAP, demonstrating it's ability to address the zero-inflation problem.\n(2) As shown by result of no-hgc, replacing the hierarchical graph clustering with uniform clustering leads to a degradation in performance. This indicates that our meticulously designed hierarchical graph clustering method is capable of effectively providing a more subtle hierarchical data structure.\n4.9 Hyper-parameter Study\nwe consider the following hyper-parameters: (1) the enhancement channels da of remote sensing enhancement; (2) the number of convolutions layers Kst in grid convolution; (3) the number of transformer encoders Kta in adaptive temporal attention module; (4) the size dta of feed forward in self-attention blocks. In summary, we set each hyper-parameter to the optimal: (1) For Chicago, we have da = 32, Kst = 2, Kta = 4, dta = 256. (2) For NYC, we have da = 8, Kst = 2, Kta = 2, dta = 256."}, {"title": "RELATED WORK", "content": "Traffic accident risk prediction is an important topic that has been widely studied. Related work can be mainly divided into two categories: statistics-based and learning-based.\n5.1 Statistics-based Methods\nThe statistics-based methods include decision tree, SVM, k-nearest neighbor and negative binomial regression. Chong et al. [6", "27": "leverage support vector machines (SVM) with gaussian kernel to predict traffic accident risk. The authors in [22", "3": "apply Poisson, negative binomial and negative multinomial regression models to tangents and curves respectively to predict traffic accidents. However, these works simply applied traditional statistical methods without considering the complex spatio-temporal correlation of traffic accidents and features, resulting in poor performance.\n5.2 Learning-based Methods\nIn recent years, many studies have focused on using learning-based models. For spatio-temporal prediction, many researchers employ different techniques [13, 20, 25, 34-37", "38": ".", "31": "introduce GSNet, which utilizes a weighted loss function to tackle the zero-inflation issue. Additionally, a multi-view multi-task model was proposed by [32", "26": "present an efficient vision transformer model, C-ViT, which processes risk map multi-"}]}