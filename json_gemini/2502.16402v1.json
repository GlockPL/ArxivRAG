{"title": "Navigation-GPT: A Robust and Adaptive Framework Utilizing Large Language Models for Navigation Applications", "authors": ["Feng Ma", "Xiu-min Wang", "Chen Chen", "Xiao-bin Xu", "Xin-ping Yan"], "abstract": "Existing navigation decision support systems often perform poorly when handling non-predefined navigation scenarios. Leveraging the generalization capabilities of large language model (LLM) in handling unknown scenarios, this research proposes a dual-core framework for LLM applications to address this issue. Firstly, through ReAct-based prompt engineering, a larger LLM core decomposes intricate navigation tasks into manageable sub-tasks, which autonomously invoke corresponding external tools to gather relevant information, using this feedback to mitigate the risk of LLM hallucinations. Subsequently, a fine-tuned and compact LLM core, acting like a first-mate is designed to process such information and unstructured external data, then to generates context-aware recommendations, ultimately delivering lookout insights and navigation hints that adhere to the International Regulations for Preventing Collisions at Sea (COLREGs) and other rules. Extensive experiments demonstrate the proposed framework not only excels in traditional ship collision avoidance tasks but also adapts effectively to unstructured, non-predefined, and unpredictable scenarios. A comparative analysis with DeepSeek-R1, GPT-40 and other SOTA models highlights the efficacy and rationality of the proposed framework. This research bridges the gap between conventional navigation systems and LLMs, offering a framework to enhance safety and operational efficiency across diverse navigation applications.", "sections": [{"title": "1. Introduction", "content": "Despite the increasing sophistication of navigation equipment, ships still cannot operate without close supervision of human. Ships' level of automation and intelligence remains notably lower than that of vehicles, and the accident rate is also difficult to reduce further [1, 2, 3]. Investigations reveal that collisions are the primary cause of navigation accidents, with 75% of collision incidents attributed to erroneous decisions made by crew members [4, 5]. Reviewing numerous ship collision incidents, it can be concluded that negligence, unclear understanding of rules, and insufficient consideration of environmental and regulatory factors are the primary causes. Presently, ship navigation still heavily relies on human comprehensive thinking, which imposes a heavy workload. In daily work, ship navigation necessitates the integration of dynamic, multi-source heterogeneous data to achieve a comprehensive understanding of the environment, thereby facilitating accurate decisions.\nShip navigation and collision avoidance follow established rules, but they also involve numerous uncertainties and contradictions, which are related to regional and meteorological factors. These complexities make it difficult to translate them into traditional computer programs with fixed frameworks [6, 7, 8, 9]. In scenarios involving multiple ships, existing navigation systems or expert systems struggle to provide precise and immediate safe routes. Consequently, there is an urgent need for a more effective risk identification mechanism and a flexible framework that considers both safety and cost-effectiveness to address the challenges of daily navigation [10, 11].\nIn recent years, the development of artificial intelligence, particularly large language models (LLMs) [12, 13, 14, 15], has offered new approaches to addressing this challenge. LLMs show potential in dynamic task management with their superior natural language processing and reasoning capabilities [16, 17, 18]. Research in autonomous driving demonstrates that LLMs possess strong reasoning abilities. These abilities enable LLMs to integrate heterogeneous data and generate context-aware analyses and recommendations, even in unknown scenarios [19, 20, 21].\nMoreover, LLMs can understand driving environments in a human-like manner and address long-tail problems through reasoning, explanation, and memory. Therefore, integrating LLMs into ship navigation and collision avoidance systems is feasible. By efficiently fine-tuning LLMs using data from real-world navigation scenarios, they can better comprehend complex maritime environments and provide intelligent support for ship navigation.\nCurrently popular LLMs, such as GPT-4, Qwen-2.5, and DeepSeek incorporate techniques like chain-of-thought reasoning and self-correction. Kamoi et al. [22] have shown that while LLMs can handle certain tasks suited to self-correction, relying solely on the model itself is insufficient for broader self-correction tasks. Furthermore, obtaining real-world feedback is a necessary condition for effective self-correction in LLMs. However, the parameter weights of LLMs are fixed, and they lack the ability to perceive and interact with their external environment. In other words, LLMs do not have sensory capabilities to understand their surroundings or engage with them. This limitation could lead to suboptimal or even dangerous outcomes when LLMs are applied to decision-making tasks. To apply Large Language Models (LLMs) to navigation assistance decision-making, it is necessary to address the dual challenges of how to input various types of external navigation data and how to ensure that the outputted decision support complies with existing navigation rules.\nTo address the above challenges, this research proposes a dual-core LLM framework, or agent, terms of Navigation-GPT. Firstly, Navigation-GPT leverages a larger LLM core for collecting data and invoking specialized tools. With the assistance of reasoning and action (ReAct) [23] prompt engineering, the navigation task is decomposed into manageable sub-tasks. This LLM core might invokes tools for subtasks to acquire external information, then collects all navigation-related information and encodes it into the language space, forming structured \"prompts\", thereby preparing for subsequent decision-making.\nFurthermore, task-oriented fine-tuning is performed efficiently using low-rank adaptation (LoRA) [24] on the other LLM core. Massive navigation"}, {"title": "2. Literature Review", "content": "2.1. The development of large language models\nIn recent years, large language models (LLMs) have made significant advancements in the field of natural language processing (NLP). These models, built on the Transformer architecture, exhibit powerful language understanding and generation capabilities through large-scale parameterization and extensive data training. The Transformer model, first proposed by Vaswani et al. [25], overcame the limitations of traditional recurrent neural networks (RNNs) [26] and long short-term memory networks (LSTMs) [27] in parallel processing and long-range dependency handling. Its core self-attention mechanism efficiently captures long-distance dependencies within sequences while preserving sequential order through positional encoding, laying the theoretical and technical foundation for subsequent pre-trained language models.\nWith the widespread adoption of the Transformer architecture, pre-trained language models have become a focal point in NLP research. BERT [28] introduced a bidirectional encoder and the masked language modeling (MLM) objective, significantly enhancing language understanding and establishing the pre-training and fine-tuning paradigm. OpenAI released the GPT series, which adopted an autoregressive language modeling approach and demonstrated exceptional performance in text generation tasks through left-to-right sequential generation. Notably, GPT-3, with 175 billion parameters, emerged as the largest language model at the time, showcasing remarkable zero-shot and few-shot learning capabilities. Subsequently, models such as Google PaLM [29], Alibaba Qwen [30], and Meta LLaMA [31] demonstrated unprecedented performance in language understanding and generation tasks.\nThe rapid development of LLMs has revealed emergent abilities [32, 33], which refer to the unexpected capabilities models exhibit upon reaching a critical parameter size. These abilities encompass tasks such as language generation [34], complex reasoning [33], multilingual translation [35], and code generation [36]. Contextual learning [37] has become a hallmark of LLMs, enabling them to quickly adapt to new tasks with minimal contextual samples, thereby reducing the need for extensive labeled data. Instruction following allows models to execute complex tasks based on explicit natural language instructions, significantly improving capabilities from text generation to multi-turn dialogue generation. Chain-of-thought reasoning, guiding models to perform step-by-step reasoning, enhances decision-making and problem-solving abilities in complex tasks. The emergence of these abilities has expanded the practical applications of LLMs and opened new avenues for exploring model capability mechanisms. Brown et al. [38] demonstrated that increasing model size significantly improves task generalization, prompting researchers to investigate the relationship between model size, data diversity, and emergent abilities, offering new theoretical perspectives for model optimization.\nIn terms of training methods, LLM optimization has undergone several key evolutions. Core methods in the pre-training phase include self-supervised learning, where models learn language patterns and semantic features from unlabeled data by predicting masked or next words [39]. This approach avoids reliance on extensive labeled datasets, enabling efficient training on large corpora. To enhance task-specific adaptability, the fine-tuning phase employs supervised learning for parameter updates. Recently, reinforcement learning from human feedback (RLHF) [40] has become a crucial strategy to improve model performance by optimizing outputs based on human feedback, aligning them better with user expectations. OpenAI developed InstructGPT [41] using this approach to achieve better user interaction. Lightweight fine-tuning techniques such as LoRA have significantly reduced computational costs, providing greater flexibility for real-world applications."}, {"title": "3. Methodology", "content": "3.1. Overview\nIn this section, we introduce an agent framework named Navigation-GPT for navigation and collision avoidance tasks. As shown in Figure 1, Navigation-GPT comprises task planning, a memory module, and a set of tools, with a larger LLM core serving as the control center integrating reasoning, action, and memory functions. Tools facilitate interaction between the LLM and the real world. During the reasoning process, this larger LLM core carries out several key operations. It understands and breaks down complex tasks into manageable steps. The framework then invokes tools to interact with the environment and gather necessary information. Heterogeneous data is converted into prompts that the LLM can process effectively. By integrating language analysis with these heterogeneous prompts, the other fine-tuned LLM core provides accurate lookout information to the captain and outputs collision avoidance actions for ships in compliance with COLREGs.\n3.2. Reasoning and Action\nAt time t, Navigation-GPT receives observations $o_t \\in O$, executes actions $a_t \\in A$, and generates a final decision $\\pi(a_t | c_t)$, where $c_t = (o_1, a_1, ..., o_{t-1}, a_{t-1}, o_t)$ represents the set of environments and actions.\nSince navigation and collision avoidance tasks require complex reasoning to make accurate decisions, Navigation-GPT adopts the ReAct framework. The core principle of ReAct is to expand the action space of LLM to $A = L \\cup A$, where L represents the original action space of the LLM, and A represents the set of external tools. ReAct enables the LLM to iteratively generate a trajectory of Thought, Action, and Observation.\nThought belongs to the original action space of the LLM $a_t \\in L$. It does not interact with the external environment or receive observational feedback. Instead, it involves reasoning based on the current environment to derive useful information, supporting subsequent reasoning and actions. Action represents external tools configured in Navigation-GPT $a_t \\in A$, which retrieve navigation environment data. Observation $o_t \\in O$ consists of external information from radar, AIS, and CCTV, fed back to the LLM.\n3.3. Tools\nNavigation-GPT integrates five hard-coded tools to perform the following tasks: retrieving onboard sensor data, calculating the distance at closest point of approach (DCPA) and the time to the closest point of approach (TCPA) between two ships, determining the type of ship encounter, assessing collision risk, and executing collision avoidance decisions. Navigation-GPT leverages an LLM to determine the ship encounter type and make collision avoidance decisions.\nSince a general-purpose LLM cannot accurately understand complex navigation environments, it requires specialized training to adapt to specific tasks. Given the scarcity of accurately labeled navigation data and the diversity of tasks, Navigation-GPT employs LoRA to fine-tune the LLM. LoRA freezes the pretrained weights of the LLM and injects trainable low-rank matrices into selected neural network layers, reducing the number of trainable parameters while enabling rapid task switching. During the fine-tuning process, LORA constrains matrix updates using the following formula:\n$W_0 + \\Delta W = W_0 + BA$ (1)\nwhere both A and B contain trainable parameters, and where $W_0 = R^{d \\times k}$ is the original weight of the LLM, d and k are the dimensions of the model, $r \\ll min(d, k)$ is the rank of a low rank matrix.\nAs shown in Figure 3, Navigation-GPT analyzes the input task type and invokes the corresponding tools to complete downstream tasks. The prompts provided to the LLM by Navigation-GPT consist of two parts: system prompts and the standardized description of the navigation scenario. The system prompts include a detailed overview of the navigation and collision avoidance tasks, specifying the expected outputs, output format, and constraints for the reasoning process. For each decision, Navigation-GPT concatenates these two prompt components with the feedback from the toolset. The fine-tuned LLM then evaluates and summarizes this information to determine the appropriate collision avoidance actions for the ship."}, {"title": "4. Experiments", "content": "To evaluate the effectiveness of the proposed Navigation-GPT, this research conducted simulation experiments in various environments. Navigation data from the experimental ship of Wuhan University of Technology was used to construct the simulation scenarios. The research analyzes the collision avoidance decisions of Navigation-GPT in four encounter scenarios, validating the rationality of its decisions. Additionally, the comparison between Navigation-GPT and DeepSeek demonstrates the effectiveness of the technologies within the framework.\n4.1. Data Description and Implementation Details\nThis research uses navigation data from coastal water, collected by Wuhan University of Technology in 2024. The dataset includes 500 ships, such as bulk carriers and container ships, covering a total travel distance of 27 kilometers. It consists of real-world navigation scenarios captured using AIS, radar, and CCTV. Based on this data, the ship encounter type dataset (SETD) and the ship collision avoidance decision dataset (SCADD) were constructed.\nThe SETD consists of 5,000 time-discretized ship encounter scenarios, which describe four types of encounters. These types are classified based on the relative bearing and heading of the TS with respect to the OS, including head-on, small-angle starboard crossing, large-angle starboard crossing, and port crossing. The SCADD contains 150,000 navigation scenarios involving three-ship encounters, with the collision avoidance decisions in these scenarios refined and validated by experienced captains. Figure 4 and Figure 5 are examples of SETD and SCADD, respectively\nThe research presents evaluation results on the test datasets. Additionally, 500 generated prompts were randomly sampled from the SCADD test dataset and assessed for reasonableness by experienced captains. All experiments, or fine-tuning, were conducted on a 4\u00d7A100 (40GB) GPU setup. Navigation-GPT employs Qwen2-72B with chain-of-thought reasoning as the central control agent (the larger core) and uses Qwen2-7B as the baseline for LoRA fine-tuning (the smaller decision core). The SETD and SCADD were used for training over 2 epochs, with a batch size of 32, a LoRA rank of 8, a scaling factor of 32, and a learning rate of 1e-4. The LoRA trained on SETD reached the convergence region at 350 steps, with a total training time of 3 hours and 15 minutes. The learning rate was initially set to 1e-4 and gradually decreased to 4.3e-7. The LoRA trained on SCADD reached the convergence region at 1150 steps, with a total training time of 7 hours and 42 minutes. The learning rate started at 1e-4 and eventually decreased to 1.1e-6.\nThe simulation experiments use a tanker ship model of Fossen [54], with its parameters shown in the Table 1. Additionally, it is assumed that the OS and TS have identical ship handling characteristics. The rudder angle range for the ship model is -30 deg to 30 deg, both for turning and returning.\n4.2. Case 1: Head-on situations\nAs shown in Figure 6, the TS approaches from the forward side of the OS and maintains its course in accordance with COLREGs. The simulation evaluates the collision avoidance maneuvers of Navigation-GPT under these emergency conditions. According to COLREGs, in a head-on encounter, the OS should turn to starboard and pass the TS on its port side. The risk assessment tool of Navigation-GPT triggers a risk alert, and its obstacle avoidance module retrieves navigation data to propose a collision avoidance decision. At 120 seconds, Navigation-GPT generates and executes this navigation decision. By 280 seconds, the collision is avoided, with the minimum distance between the OS and TS being 0.16 nautical miles. Subsequently, Navigation-GPT identifies the environment as risk-free and advises the OS to resume its course toward the target point.\nFigure 7 and Figure 8 simulate scenarios where the TS approaches from\nthe starboard and port sides of the OS, respectively, with the TS maintaining\nits course. As shown in Figure 7, the TS is on the starboard side, present-\ning the greatest challenge. According to COLREGs, the OS is required to\nturn starboard to avoid a collision. Navigation-GPT accurately identifies the\nencounter type and performs collision avoidance maneuvers in compliance\nwith COLREGs. At 99s, Navigation-GPT accurately identifies the head-on\nsituation between the OS and TS and begins executing collision avoidance\ndecisions. At 460 seconds, it completes the collision avoidance maneuver in\ncompliance with COLREGs. By 650s, Navigation-GPT adjusts the distance\nbetween the OS and TS. Finally, at 750 seconds, Navigation-GPT determines\nthat the navigation environment is free of collision risks and resumes heading\ntoward the target point.\nIn such scenarios, the navigation strategy of Navigation-GPT is both\nefficient and cautious, and its text output can be directly used as a decision-\nmaking reference for the operator.\n4.3. Case 2: Crossing situations\nIn crossing scenarios, this research designs three TS with different nav-\nigation directions to test Navigation-GPT compliance with COLREGs. As\nshown in Figure 9, the TS approaches from the starboard side of OS, main-\ntaining constant speed and course with a small relative bearing. Navigation-\nGPT identifies this as a small-angle crossing on the starboard side. According\nto COLREGS, TS is the stand-on ship, while OS is the give-way ship and\nshould turn to starboard to avoid TS. At 454 seconds, OS completes the\navoidance maneuver and, after confirming no collision risks in the current\nnavigation environment, resumes course toward the target point.\nAs shown in Figure 10, TS approaches from the starboard side of OS\nwith a larger relative bearing. Navigation-GPT identifies risk at 287 seconds\nand initiates a more significant starboard turn. OS successfully avoids TS\nby 640s.\nAs shown in Figure 11, the TS approaches from the port side of OS, form-\ning a port-side crossing. According to COLREGs, OS is the stand-on ship,\nwhile TS is the give-way ship. Before 300 seconds, OS maintains speed and\ncourse toward the target point. At 355 seconds, Navigation-GPT determines\nthat current navigation conditions cannot be resolved by the actions of a\nsingle ship. Therefore, Navigation-GPT advises OS to proactively avoid col-\nlision by turning to starboard to increase distance from TS. At 516 seconds,\nOS completes the avoidance maneuver and resumes course toward the target\npoint.\nAdditionally, this research employs Navigation-GPT to provide collision\navoidance decisions in a three-ship crossing scenario, validating its effective-\nness. Table 2 shows the initialization parameters of three ships. As shown in\nFigure 12, Navigation-GPT accurately identifies the encounter types involv-\ning two TS and generates appropriate collision avoidance strategies. Subse-\nquently, the embedded chain-of-thought LLM further evaluates the priority\nof ships for avoidance based on DCPA, TCPA, and distance information,\nderiving collision avoidance decisions suitable for the current navigation sce-\nnario. Navigation-GPT provides feedback to the operator on the current\nnavigational environment, fulfilling the lookout function, and updates the\nship model with the latest speed and heading to complete the collision avoid-\nance task. Figure 13 illustrates the changes in OS heading. Throughout the\navoidance process, OS maintained a safe distance from both TS A and TS\nB.\nIn more complex encounter scenarios involving three or more ships, the\nproposed framework can still exhibit decision-making capabilities comparable\nto human performance, and its performance is already on par with commonly\nstudied optimization methods.\n4.4. Case 3: Being Overtaking situations\nAs shown in Figure 14, Navigation-GPT identifies that the TS approaches\nfrom the right rear of the OS, overtaking it. According to COLREGs, the TS\nturns right to overtake. However, in the simulation, the heading and speed\nof TS remain constant. Thus, before 92 seconds, the OS maintains a direct\ncourse toward the target point. At 92 seconds, Navigation-GPT detects that\nthe distance between the OS and TS is below the safe threshold, and the\nTS, maintaining constant heading and speed, rapidly closes in. The OS\nactively turns left to increase the distance between the two ships and avoid\na collision. From 92 seconds to 250 seconds, the OS heading changes from\n348 degrees to 328 degrees, successfully avoiding the TS. By 250 seconds, the\nTS completes the overtaking maneuver. Based on DCPA, TCPA, and the\ndistance between the ships, Navigation-GPT determines that no collision risk\nexists in the current navigational environment and recommends proceeding\ntoward the target. At 418 seconds, the heading adjusts to 13.2 degrees.\n4.5. Case 4: Unexpected or Non-predefined Scenarios\nIn the Case 1, 2, 3, traditional computer programming, decision tree mod-\nels, and Bayesian network models could also be implemented, and might even\nbe more efficient, since these scenarios are relatively predictable. The core\nissue preventing existing computer decision systems from being applied to\nship navigation lies in the undefined, sudden scenarios, which are particu-\nlarly common on ships.\nLarge language models provide an intelligent agent that mimics human\nthinking and can make relatively reasonable decisions in undefined or un-\npredictable scenarios. This advantage is particularly evident in human con-\nversations, where questions from people are always varied, un-predictable,\nyet well-designed LLMs can always respond flawlessly. The source of this\ngeneralization capability has not yet been fully explained by foundational\nresearch.\nIn Case 4, this research incorporates the navigation environment prompt\n\"a large area of fishing nets suddenly appears on the starboard side\" into the\nreasoning process of Navigation-GPT. As shown in Figure 15, Navigation-\nGPT converts navigation data into text and obtains collision avoidance rec-\nommendations from LoRA. LoRA suggests that the OS should turn to star-\nboard according to COLREGs to avoid TS B. However, upon detecting\nan unexpected appearance of extensive fishing nets on the starboard side,\nNavigation-GPT determines that a starboard turn would negatively impact\nthe OS. Consequently, it recommends abandoning the turn and completing\ncollision avoidance by reducing speed or stopping. Notably, the developers\ndid not write any pre-programmed branches instructing the intelligent agent\nto slow down to avoid risks. This solution was entirely \"thought up\" by\nNavigation-GPT in a dilemma, demonstrating its ability to solve unknown\nchallenges. This capability is crucial in ship navigation. The lower part of\nFigure 15 depicts a scenario in normal waters, where Navigation-GPT ac-\ncurately follows COLREGs to avoid collisions. After confirming a risk-free\nenvironment, it advises the OS to navigate toward the target point.\nAs shown in Figure 16, when the sensor detects a large fishing net sud-\ndenly appearing ahead of the OS, LORA provides a normal collision avoid-\nance decision to the agent. However, Navigation-GPT identifies that the\nsuggested route cannot safely navigate out of the hazardous area. Conse-\nquently, Navigation-GPT modifies the recommendation from LoRA with a\nmore aggressive heading adjustment. When fishing nets are detected ahead\nand to the right of the OS, Navigation-GPT disregards the suggestion from\nLoRA and proposes a left turn to avoid the collision and safely exit the\ndangerous waters.\nAs shown in Figure 17, the sensor feedback indicates only two TSs in the\nnavigation data, and Navigation-GPT conducts collision avoidance planning\nfor them. However, at 233 seconds, an unplanned ship is suddenly detected by\nthe sensor. Despite the OS already being in a three-ship collision avoidance\nstate, Navigation-GPT quickly recalculates the avoidance plan based on the\nlatest data in this sudden scenario. Navigation-GPT accurately identifies\nthe meeting type between OS and TS C, while also considering the other\nTSs, ultimately providing safe navigation recommendations and successfully\ncompleting the collision avoidance task for the unexpected ship.\nThe experiments designed additional unexpected scenarios, but due to\nspace limitations, these are not individually described. The tests demonstrate\nthat this companion-like intelligent agent maintains strong decision-making\nstability when responding to unknown and sudden situations. Extensive\npreliminary LoRA training also effectively instilled a form of \"risk aversion\"\nin the finalized Navigation-GPT. Its decision-making tends to be conservative\nand compliant, aligning with the original design intent.\n4.6. Case 5: A Comparative Research with Deepseek and GPT-40\nTo evaluate the collision avoidance capabilities of Navigation-GPT, this\nresearch conducted a comparative analysis with the DeepSeek-R1-Distill-\nQwen-32B (DeepSeek) model in a three-ship encounter scenario.\nAs shown in Figure 18, Navigation-GPT detects a potential collision risk\nbetween TS A, TS B, and OS at the 87 seconds. The LoRA module of\nNavigation-GPT outputs collision avoidance suggestions for the TSs, which\nare then analyzed by the larger LLM core, leading to the final avoidance\naction for the ship. From the 220 seconds to the 500 seconds, OS gradually\nadjusts its course and successfully avoids the collision. At the 600 seconds,\nNavigation-GPT detects that the navigation environment poses no collision\nrisk and recommends that OS proceed towards the target point.\nAs shown in Figure 19, without the integration of external tools, DeepSeek\nbegins to execute collision avoidance tasks upon receiving basic ship infor-\nmation. Regardless of whether TSs are located on the port or starboard side\nof the OS, DeepSeek is initially able to proactively perform avoidance ma-\nneuvers based on the COLREGs. However, after completing the avoidance\nmaneuver, DeepSeek struggles to accurately interpret basic environmental\ninformation. Furthermore, there are deviations in the risk parameters, such\nas the DCPA, calculated by DeepSeek, which is a key reason for the model\nperforming excessive collision avoidance actions. Experimental results indi-\ncate that while DeepSeek possesses some spatial understanding capabilities,\nits computational limitations hinder the full realization of this potential.\nAs shown in Figure 20 and Figure 21, after integrating the toolset from\nNavigation-GPT, DeepSeek plays the role of the decision-making core of\nNavigation-GPT. The new framework avoids the complex collision param-\neter calculations performed by the model itself. The scenario description\nincludes accurate data feedback from tools such as DCPA and TCPA. Us-\ning the more comprehensive navigation information, DeepSeek accurately\navoids TS A and TS B. After OS passes the TSs, DeepSeek prevents un-\nnecessary avoidance maneuvers and successfully proceeds towards the target\npoint. When serving as the decision-making LLM core, DeepSeek can play\na role similar to the fine-tuned small core of Navigation-GPT. However, its\noutput decision structure is inherently unstable, and its wording often does\nnot conform to navigational norms. Additionally, the excessively long chain-\nof-thought (CoT) process results in lower operational efficiency compared to\nthe small core of Navigation-GPT. The DeepSeek used 58 seconds to gener-\nate a decision in average, while the proposed method only needs 15 seconds.\nMoreover, as shown in Figure 22, DeepSeek without specialized fine-tuning\ncan still experience model hallucinations when serving as the decision-making\ncore.\nAs shown in Figure 23, similar to DeepSeek, when GPT-40 is not con-\nnected to external tools, it cannot accurately assess the risk in the encounter\nscenario. Therefore, after the OS completes collision avoidance, GPT-40 pro-\nvides unnecessary avoidance suggestions. After connecting to external tools,\nthe OS trajectory stabilizes. Upon completing collision avoidance, GPT-40\nultimately recommends that the OS navigate toward the target point."}, {"title": "5. Discussion", "content": "When GPT-40 is used as the decision-making core, similar to DeepSeek,\nalthough its performance improved, it occasionally exhibited hallucinations.\nMoreover, its navigation decisions are more aggressive compared to both\nDeepSeek and the method proposed in this research. As an online model that\ncannot be deployed locally, GPT-40 is, in fact, very challenging to implement\non board ships.\nFor many years, the maritime industry has endeavored to design obsta-\ncle avoidance or watchkeeping procedures that comply with navigation rules\nto assist seafarers. This objective appears to be relatively straightforward\nto achieve, as various navigation rules and conventions can typically be ac-\nquired through literature review and field investigations. Transforming these\ninto fixed procedures requires only the application of software engineering\nprinciples. However, in reality, the environment is invariably dynamic, and\npre-written programs in Python or C++ are incapable of handling constantly\nchanging boundary conditions. The primary limitation of traditional pro-\ngramming lies in its tendency to produce uncontrollable outputs when inputs\nfall outside predefined parameters. In contrast, while the functionalities and\nspecific calculations provided by the large language model-driven Navigation-\nGPT framework\u2014such as encounter prediction and risk analysis\u2014are not\nsignificantly different from those of conventional intelligent systems, the core\ndistinction lies in its ability to respond to environmental anomalies. When\ninputs deviate from preset conditions, the new LLM-based framework does\nnot require program modifications but instead derives relatively reasonable\nsolutions through intrinsic relational analysis. This capability makes it feasi-\nble to develop an intelligent system capable of addressing most navigational\nenvironments.\nThe comparative experiments between Navigation-GPT and DeepSeek-\nR1-Distill-Qwen-32B (DeepSeek), GPT-4o indicate that, in the field of colli-\nsion avoidance, the performance of the LoRA-fine-tuned, smaller 7B model\nsignificantly outperforms the 32B model distilled by DeepSeek-R1 and GPT-\n40. After deploying the same framework of Navigation-GPT, especially in-\ntegrating external tools such as DCPA and TCPA, the performances of the\nsmaller fine-tuned LLM core, DeepSeek and GPT-4o becomes similar. How-\never, the smaller fine-tuned LLM core exhibits shorter response delays, with a\ndecision-making time of approximately 15 seconds, while DeepSeek requires\nabout 58 seconds. After fine-tuning, the smaller LLM core generates rec-\nommendations that are more aligned with navigational terminology, more\naccurate, and free from model hallucinations.\nIt is noteworthy that the computational capabilities of LLMs are inher-\nently limited. Consequently, complex risk parameters computed solely by\nLLMs may lack reliability. To address this limitation, integrating external\ntools to expand the action space of LLMs and construct agents remains the\nprimary technical approach for solving complex tasks involving intricate com-\nputations. This hybrid methodology leverages the strengths of both LLMs\nand specialized tools, thereby enhancing overall system performance and ro-\nbustness.\nUnlike other vertical applications of large models, Navigation-GPT adopts\na dual-large model kernel architecture. One kernel is responsible for tool\ninvocation, while the other is in charge of information verification and con-\nclusion formation. This design not only ensures the integrity of informa-\ntion collection but also effectively reduces the risk of model hallucinations.\nNavigation-GPT demonstrates functionality similar to traditional collision\navoidance algorithms. However, compared to conventional hard-coded intel-\nligent systems, the unique open-scene processing capability of Navigation-\nGPT provides a new framework for the development of intelligent navigation\nsystems."}, {"title": "6. Conclusion", "content": "This research proposed Navigation-GPT, a flexible framework designed\nto adapt to open navigation scenarios. Navigation-GPT integrates tech-\nnologies such as ReAct and LoRA to build an LLM-based agent capable\nof processing heterogeneous data from onboard sensors to perform naviga-\ntion and collision avoidance tasks. Extensive experiments demonstrate that\nNavigation-GPT functions similarly to traditional intelligent systems but can\nhandle unstructured scenarios that traditional systems cannot manage. Fur-\nthermore, a comparison experiment with the latest DeepSeek-R1 indicates\nthat the LORA module integrated into Navigation-GPT enhances the per-\nformance of smaller LLMs in specialized domains. An ablation experiment\non DeepSeek-R1 shows that current SOTA LLMS cannot be directly ap-\nplied to navigation directly, and using external computational tools to assist\nagent decision-making remains the primary approach for LLMs in executing\ncomplex tasks. Since Navigation-GPT currently focuses on navigation and\ncollision avoidance, it lacks long-distance path planning capabilities. Future\nresearch will further explore the application of LLMs in ship path planning\nto improve the robustness of Navigation-GPT."}]}