{"title": "HoP: Homeomorphic Polar Learning for Hard Constrained Optimization", "authors": ["Ke Deng", "Hanwen Zhang", "Jin Lu", "Haijian Sun"], "abstract": "Constrained optimization demands highly efficient solvers which promotes the development of learn-to-optimize (L2O) approaches. As a data-driven method, L2O leverages neural networks to efficiently produce approximate solutions. However, a significant challenge remains in ensuring both optimality and feasibility of neural networks' output. To tackle this issue, we introduce Homeomorphic Polar Learning (HoP) to solve the star-convex hard-constrained optimization by embedding homeomorphic mapping in neural networks. The bijective structure enables end-to-end training without extra penalty or correction. For performance evaluation, we evaluate HoP's performance across a variety of synthetic optimization tasks and real-world applications in wireless communications. In all cases, HoP achieves solutions closer to the optimum than existing L2O methods while strictly maintaining feasibility.", "sections": [{"title": "1. Introduction", "content": "Optimization takes a fundamental role in numerous scientific and engineering applications (Liu et al., 2024; Abido, 2002; Rockafellar & Uryasev, 2013). However, these algorithms often require significant computation time to solve complex problems, particularly when dealing with non-convex or high-dimensional cases. To address these limitations, the paradigm of learn-to-optimize (L2O) has emerged as a promising alternative (Hounie et al., 2024; Ding et al., 2024). As a learning-based scheme, L2O takes optimization parameters as the inputs of neural network (NN) which can efficiently obtain approximate solutions from the outputs.\nThis data-driven approach enhances the speed and reduces the computational cost of achieving satisfactory solutions (Donti et al., 2021; Park & Van Hentenryck, 2023).\nDespite its advantages, L2O faces significant challenges when applied to constrained optimization. A major issue is the lack of guarantees for NN to ensure that solutions strictly remain within the feasible region defined by the constraints (Donti et al., 2021). Current works have attempted to address this limitation through various approaches, including supervised learning (Zamzam & Baker, 2020), incorporating constrained violations into the loss function (Zhang et al., 2024; Xu et al., 2018), post-correction methods (Donti et al., 2021), implicit differentiation (Amos & Kolter, 2017), and other techniques (Zhong et al., 2023; Misra et al., 2022). However, these methods often exhibit limitations in optimal solution searching and hard constraints violation control.\nWe propose the homeomorphic polar learning (HoP) to address the non-convex problem with star-convex hard constraints. As stated in Definition 3.1, star-convexity is a weaker condition than convexity, which introduces additional challenges in handling hard constraints. HoP is a learning based framework inspired by principles of convexity and topological structure of constraints, designed to ensure both the feasibility and optimality of solutions. As illustrated in Fig. 1, the problem parameters are fed into NN, where the raw outputs are regulated by bounded functions. Subsequently, through the proposed homeomorphic mapping, the polar sphere vectors are mapped to Cartesian coordinates, strictly following to the original constraints. Furthermore, HoP is trained end-to-end with objective function as loss directly, which makes it adaptable to various applications. The key contributions are\n\u2022 Novel formulation of hard-constrained optimization via polar coordinates and homeomorphic mapping. HoP is the first L2O framework based on polar coordinates and homeomorphism to solve hard constrained problem. Our formulation extends the applicability of L2O methods to star-convex constraints, a more complex and less explored constraint type.\n\u2022 Reconnection strategies and dynamic learning rate adjustment and for polar optimization. To address challenges specific to polar coordinate optimization, such as radial stagnation and angular freezing, we propose a dynamic learning rate adjustment scheme and geometric reconnection strategies. We provide rigorous theoretical analyses to validate the stability and efficiency of these solutions.\n\u2022 Superior experimental performance with zero violation. Through extensive ablation and comparative experiments, we validate the feasibility and optimality of our approach across a wide range of problems. Results consistently show that HoP outperforms both traditional and learning-based solvers in terms of constraint satisfaction and optimization efficiency."}, {"title": "2. Related Work", "content": "We present related works for constrained optimization problems using L2O. Broadly, researches in this area can be categorized into two distinct directions: soft and hard constrained L2O."}, {"title": "2.1. Soft Constrained Optimization with L2O", "content": "Soft constrained L2O emphasizes on enhancing computational efficiency on NN inference speed while tolerating a limited rate of constraint violations. Early research in this domain explored the use of supervised learning (SL) to directly solve optimization problems, where the optimal variable $y^*$ is provided as labels by optimizer (Zamzam & Baker, 2020; Guha et al., 2019). Another prominent direction involves incorporating constraint violations into the objective function by Karush-Kuhn-Tucker conditions (Donti et al., 2021; Zhang et al., 2024; Xu et al., 2018). In this methods, constraints are reformulated as penalty terms and integrated into the objective function as the loss for self-supervised learning (SSL). Subsequent advancements introduced alternative optimization based learning, where variables and multipliers are alternately optimized through dual NNs (Park & Van Hentenryck, 2023; Kim & Kim, 2023; Nandwani et al., 2019). More recent related researches include preventive learning, which incorporates pre-processing in learning to avoid violation (Zhao et al., 2023). Additionally, resilience-based constraint relaxation methods dynamically adjust constraints throughout the learning process to balance feasibility and overall performance (Hounie et al., 2024; Ding et al., 2024)."}, {"title": "2.2. Hard Constrained Optimization with L2O", "content": "Hard constrained optimization in L2O prioritizes strict adherence to constraints, even if it results in reduced optimality or slower computation speed. Traditional optimization methods often employ proximal optimization techniques to guarantee feasibility (Cristian et al., 2023; Min et al., 2024). Early methods also used activation functions to enforce basic hard constraints (Sun et al., 2018). Implicit differentiation became a popular approach for effectively handling equality constraints (Amos & Kolter, 2017; Donti et al., 2021; Huang et al., 2021). However, inequality constraints typically require additional correction steps, which can lead to suboptimal solutions (Donti et al., 2021). An alternative strategy proposed by (Li et al., 2023) utilized the geometric properties of linear constraints to ensure outputs within the feasible region, although this method is limited to linear constraints. Other studies such as (Misra et al., 2022; Guha et al., 2019) focused on eliminating redundant constraints to improve inference speed instead of solving optimization problem by NNs directly. In certain physical applications, discrete mesh-based approaches restrict feasible solutions to predefined points on a mesh (Amos et al., 2017; Zhong et al., 2023; N\u00e9giar et al., 2022). While these methods strictly enforce feasibility, they often lack flexibility in general scenarios."}, {"title": "3. Methodology", "content": "This section introduces the problem formulation, the proposed HoP framework, and associated theoretical analyses."}, {"title": "3.1. Problem Formulation", "content": "We consider the following optimization problem:\n$\\min_y f_x(y), \\text{ s.t. } y \\in \\mathcal{Y}_x,$\n(1)"}, {"title": "3.2. Homeomorphic Polar Learning", "content": "To demonstrate the proposed method, we first introduce the essential idea of HoP: homeomorphic mappings. These mappings leverage the mathematical properties of homeomorphisms, formally defined as follows:\nDefinition 3.2. Let $X = (S_X,T_X)$ and $Y = (S_Y, T_Y)$ be two topological spaces, where: (1) $S_X$ and $S_Y$ are point sets; (2) $T_X$ and $T_Y$ are topologies on $S_X$ and $S_Y$, respectively. Then function $H : X \\rightarrow Y$ is called a homeomorphism if and only if $H$ is a bijection and continuous with respect to the topologies $T_X$ and $T_Y$, while its inverse function $H^{-1}: Y \\rightarrow X$ exists and is also continuous.\nThe 1-D Case To simplify the mechanism of homeomorphic mappings, we begin with a one-dimensional optimization problem with constraints $a < y < b$, where the feasible region $V_x$ is a bounded interval $(a, b)$. The corresponding homeomorphic mapping $H$ is defined as:\n$H: \\hat{y} = a + B(z)(b - a),$\n(3)\nwhere $z$ is output from NN, $B(z)$ is a bounded, smooth and monotonic function (e.g., Sigmoid function), mapping $z$ from $\\mathbb{R}$ to $(0, 1)$. To guarantee the feasible outputs, we scale the output from $(0, 1)$ to $(a, b)$ by Eq. (3) which is considered as simple one-to-one homeomorphic mapping defined in Definition 3.2.\nThe one-dimensional case provides the essence of HoP. In the following higher-dimensional constraint sets, the extended homeomorphism $H$ is introduced to meet the requirement. The primary reason for introducing homeomorphic mappings is to guarantee that every feasible variable can be bijectively mapped to the NN output. This one-to-one correspondence is critical for maintaining feasibility and ensuring that after homeomorphic mapping the NN outputs consistently satisfy the constraints.\nExtension to the 2-D Case Building on the insight from the 1-D case, we extend the idea of bounded function based mappings to the 2-D case while preserving the properties of homeomorphic mappings.\nAs shown in Fig. 2, the feasible region $V_x$ is the green region where $y_0 \\in \\mathcal{Y}_x$. We construct a unit circle, the yellow region, by polar coordinate system, with its origin centered at $y_0$. Generally, $y_0$ is obtained by solving a convex optimization problem over $\\mathcal{Y}_x$, where the objective is either a generic convex function or the Chebyshev center. Therefore, for $\\forall \\hat{y} \\in \\mathcal{Y}_x$, we have homeomorphic mapping $H$ given as,\n$H: \\hat{y} = y_0 + r \\vec{v}_\\theta R(\\vec{v}_\\theta, \\mathcal{Y}_x)$\n(4)\nwhere $r \\in (0, 1)$ is a scale, $\\theta \\in (0, 2\\pi)$ is the angle between x-axis and direction vector, $\\vec{v}_\\theta$ denotes the unit direction vector, and $R(\\vec{v}_\\theta, \\mathcal{Y}_x)$ defines the distance from $y_0$ to the boundary of $\\mathcal{Y}_x$ in the direction specified by $\\theta$. The $\\theta$, $r$, and $\\vec{v}_\\theta$ are defined as follows:\n$\\begin{aligned} &\\theta = \\left[\\frac{2\\pi \\left[B(z_\\theta)\\right]}{0\\to 1}\\right], \\quad \\vec{v}_\\theta = \\begin{bmatrix} \\cos \\theta\\\\ \\sin \\theta \\end{bmatrix}, \\\\ &r = \\left[B(z_r)\\right] \\end{aligned}$\n(5)\nwhere $z = [z_\\theta, z_r]^T$ is raw NN output. It is worth noting that in optimization problems, redundant constraints, which do not affect the feasible region because they are implied by other constraints, can arise and significantly complicate the process of identifying boundary points. To address these challenges, it is critical to ensure that the homeomorphic mapping identifies the boundary points of the feasible region $\\mathcal{Y}_x$ accurately in the presence of redundant constraints. Our proposed method leverages the polar coordinate system to handle this issue effectively. When redundant constraints exist, $R(\\vec{v}_\\theta, \\mathcal{Y}_x)$ finds boundary points by searching the closest intersection in the direction specified by $\\theta$, as formalized in Proposition 3.3:\nProposition 3.3. Let $C_1, C_2,...,C_n$ be sets in the Euclidean space $\\mathbb{R}^n$, and let their intersection $C = \\cap_{i=1}^n C_i$ be star-convex set. If $y_0 \\in int(C)$. For any ray originating from $y_0$, the closest intersection point of the ray with $C$ belongs to the set $C$ and lies on the boundary of $C$.\nThe proof of Proposition 3.3 is given in Appendix A. As a result, the output $\\hat{y}$ computed using Eq. (4) is guaranteed to be feasible for corresponding hard constraints $V_x$.\nExtension to the Semi-Unbounded Case Since in the semi-unbounded problem, in which the feasible region extends indefinitely in some directions, making boundary determination challenging or ill-defined at infinity. $R(\\vec{v}_\\theta, \\mathcal{Y}_x)$ given in 2-D scenario is impractical, as the intersection may not exist or could approach infinity. To address this issue, we introduce the following spherical homeomorphism mapping. The process begins with NN's raw outputs $z = [z_\\theta, z_r]^T, z_\\theta \\in \\mathbb{R}^d, z_r \\in \\mathbb{R}$, where $d = 2$ for current 2-D case while the following framework is also applicable to high-dimensional problem. To ensure the outputs are contained within a unit hypersphere, the transformations in Eqs. (6) and (7) are applied to bound the raw outputs:\n$\\begin{aligned} &\\vec{v}_\\theta = \\begin{cases} z_\\theta/||z_\\theta||_2, &\\text{if } z_r \\geq 0,\\\\ -z_\\theta/||z_\\theta||_2, &\\text{otherwise.} \\end{cases}\\\\ &z_r = B(|z_r|), \\end{aligned}$\n(6)\n(7)\nwhere $\\vec{v}_\\theta$ is direction vector, $z_r$ is angle scale. Therefore, the (6) and (7) can bound the output within unit hyper-sphere and avoid stagnation problem where we provide designing analyses in Section 3.3.\nBased on the polar sphere vector, $[\\vec{v}_\\theta, \\tilde{z}_r]^T$, we set up polar coordinate system centered at $y_0$. The 2-D homeomorphic mapping in Eq. (4) can be extended to the HoP in semi-unbounded case and reformulated as follows:\n$H: \\hat{y} = y_0 + \\vec{v}_\\theta \\tan(\\psi),$\n(8)\nwhere $\\psi$ is a angle defined as:\n$\\psi = \\tilde{z}_r \\phi, \\quad \\phi = \\tan^{-1}(R(\\vec{v}_\\theta, \\mathcal{Y}_x))$\n(9)\nTo illustrate the essence of spherical mapping, we use 2-D optimization problem as an example. As shown in Fig. 3, the original 2-D plane (green plane) is elevated into an additional z-axis dimension with unit distance from point O to $y_0$. Here, $\\vec{v}_\\theta$ represents the unit direction vector of green plane. $\\Phi \\in (0, \\pi/2)$ represents the maximum angle between z-axis and the green ray extending to the dark green boundary in the direction defined by $\\vec{v}_\\theta$. The supremum of $\\psi$, denoted as sup, corresponds to the angle between z-axis and an asymptotic direction toward infinity.\nThe blue ray defined by angle $\\psi = \\tilde{z}_r \\phi$, $\\psi \\in (0, \\phi - \\epsilon)$ with z-axis, is bounded by ratio $\\tilde{z}_r$, where $\\epsilon$ is a small positive number to prevent divergence of the Jacobian determinant which is explained in Appendix B. Then, Eq. (8) maps the angle $\\psi$ to $\\hat{y}$ on the green plan which is the intersection of green plane and blue ray. Since $\\phi$ is boundary angle while $\\psi$ is bounded by $\\Phi$, the feasibility of intersection point $\\hat{y}$ is ensured.\nBy transforming the distance to angle, this approach can resolve the challenge of semi-unbounded regions. Building on the semi-unbounded design, HoP can be naturally extended to higher-dimensional and more general scenarios. The pseudocode for the HoP is presented in Algorithm 1."}, {"title": "3.3. Resolving Stagnation in Polar Optimization via Reconnection", "content": "In this subsection, we analyze the reason for optimizer stagnation during training procedure of the polar optimization system, and provide two corresponding solutions, including the reconnection strategy given in Eqs. (6) and (7). Firstly, since the use of polar coordinates for optimization brings unique challenges in radial and angular variables updating by simple bounded activation function. To facilitate understanding of the consequence of stagnation, we provide equivalent 2-D convergence sketch in Fig. 4 to demonstrate the phenomenon. As illustrated in two left sub-figures of Fig. 4, a critical issue is radial stagnation and angular freezing, where the optimizer stagnates near $r = 0$ and unable to adjust the angular variable $\\theta$.\nThe most significant reason is the non-negativity constraint, $r \\geq 0$. When $r$ reaches zero and hold the tendency to be negative, the radial updates are truncated. Meanwhile, the angular updates stagnate completely due to the vanishing gradient caused by $r = 0$. Furthermore, this phenomenon is exacerbated when optimizer has large learning rate or momentum. Specifically, this stagnation is clearly observed in left sub-figure of Fig. 4. The detailed mathematical formulation of this phenomenon and theoretical analysis is provided in Appendix C.1 and C.2.\nTo mitigate radial stagnation, we provide two alternative solution. The first one is dynamically scaled learning rate for radial updates where adjustable learning rate of $r$ avoid its updating truncation near $r = 0$. This strategy guarantees stability and prevents freezing, as rigorously analyzed in the Appendix C.3.\nAnother more robust solution is geometric reconnection techniques, shown in bottom right sub-figure in Fig. 4. When $r < 0$, we expand the angular and radial domains with reconnecting the polar space by\n$r \\leftrightarrow |r|, \\quad \\theta \\leftrightarrow \\theta + \\pi.$\n(10)\nMoreover, to guarantee angular is continuous, we output $\\theta \\in \\mathbb{R}$ which connects $\\theta = 0$ and $\\theta = 2\\pi$ periodically. This reconnection design allows the optimizer to traverse across the regions that were truncated in previous polar space, enabling smoother transition and better exploration of the solution space.\nTherefore, the geometric reconnection strategies significantly enhance the stability and efficiency of optimization in polar coordinates. As shown in Fig. 4 (bottom right), the proposed methods enable the optimizer to maintain smooth trajectories, effectively avoiding the disconnection issues observed in Fig. 4 (bottom left). As a consequence, we apply similar reconnection design in Eq. (6) and Eq. (7) to prevent truncation of $z_\\theta$ and $z_r$."}, {"title": "4. Experiments", "content": "In following experiments we evaluate HoP by comparing with other methods as baselines in three aspects, including optimality, feasibility and computation efficiency. Comparative experiments with traditional optimizers, DC3 (Donti et al., 2021) and other NN-based L2O approaches are conducted to validate HoP's effectiveness. All NNs follow a uniform architecture: a 3-layer multilayer perceptron (MLP) with ReLU activation functions. Since other NN-based methods such as DC3 typically rely on penalty functions to handle constraints, where the penalty is defined as:\n$P(\\hat{y}, \\mathcal{V}_x) = \\mathbb{I}(\\hat{y} \\notin \\mathcal{V}_x) \\cdot \\text{dist}(\\hat{y}, \\mathcal{V}_x)$\n(11)\nwhere $\\mathbb{I}(\\hat{y} \\notin \\mathcal{V}_x)$ indicates constraint violations, and $\\text{dist}(\\hat{y}, \\mathcal{V}_x)$ quantifies the distance to the constraint set.\n\u2022 Optimizer: For synthetic benchmarks (Experiments 4.1), the Sequential Least Squares Programming (SLSQP) is used as the solver. For the quality-of-service-aware multi-input-single-output communication system weighted sum rate (QOS-MISO WSR) problem in Experiment 4.2, Splitting Conic Solver (SCS) (Diamond & Boyd, 2016) and fractional programming (FP) (Shen & Yu, 2018) is applied for alternative optimization as the solver baseline.\n\u2022 NN-SSL (Self-Supervised Learning): The loss function consists individually of the objective function without any penalty term, defined as $\\mathcal{L}(\\hat{y}) = f_x(\\hat{y})$.\n\u2022 NN-SL: The loss minimizes the mean squared error (MSE) between predictions $\\hat{y}$ and the target labels $y^*$, expressed as $\\mathcal{L}(\\hat{y}) = (\\hat{y} - y^*)^2$.\n\u2022 NN-SL-SC (Soft-Constraint + Supervised Learning): The loss function integrates the MSE and a soft constraint penalty, expressed as $\\mathcal{L}(\\hat{y}) = (\\hat{y} - y^*)^2 + \\lambda \\mathcal{P}(\\hat{y}), \\lambda \\geq 0$.\n\u2022 NN-SSL-SC (Soft-Constraint + Self-Supervised Learning): The loss incorporates both the objective function and a soft constraint penalty: $\\mathcal{L}(\\hat{y}) = f_x(\\hat{y}) + \\lambda \\mathcal{P}(\\hat{y})$.\n\u2022 DC3: This baseline follows (Donti et al., 2021), using the soft-constraint loss of NN-SSL-SC with additional gradient post-corrections to improve feasibility.\nTo ensure a fair and comprehensive evaluation, we utilize the same metrics proposed in DC3. Specifically, the metrics in Tables 1-4 are defined as follows: (1) Obj. Value represents the objective function value, $f_x(y)$, achieved by the solver. (2) Max. Cons and Mean. Cons denote the $\\text{max} \\mathcal{P}(y)$ and $\\text{mean}(\\mathcal{P}(\\hat{y}))$, respectively. (3) Vio. Rate is violation rate which measures the percentage of predicted infeasible solutions. (4) Time reflects the computational efficiency of each method. Moreover, the blue numbers in following tables denote the results from HoP, while the red numbers indicate the worst results or violation for corresponding metrics. Further experimental setup details are provided in Appendix D."}, {"title": "4.1. Synthetic Benchmarks", "content": "To evaluate Hop, we consider three different synthetic problems: the polygon-constrained problem and the $l_p$-norm problem and the high-dimensional semi-unbounded problem. The polygon-constrained problem serves as the primary validation for convergence, the $l_p$-norm problem evaluates the capability in addressing star-convex scenarios, and the high-dimensional semi-unbounded problem tests the method's scalability and effectiveness in handling complex constraints in higher dimensions.\n(a) Polygon-Constrained Problem As the first benchmark experiment, we choose sinusoidal quadratic programming (QP) as the non-convex objective function with linear constraints. The problem is formulated as follows:\n$\\min_y \\frac{1}{2} y^T Q y + p^T \\sin(\\beta y), \\quad \\text{s.t. } Ay \\leq b,$\n(12)\nwhere matrix $Q$ is a positive semi-definite matrix, vector $p$ is a parameter vector, and scalar $\\beta$ controls the frequency of the sinusoidal terms, which introduces non-convexity into the objective function. The constraint are defined by matrix $A$ and vector $b$. In this problem, the parameter $x$ is $b$, consistent with the setup in (Donti et al., 2021).\nThese results demonstrate HoP's ability to enforce hard constraints rigorously, achieve nearer optimal solutions, and operate with superior computational efficiency in simple 2-D optimization problem which validate its effectiveness.\n(b) $l_p$-norm Problem The second problem, an $l_p$-norm problem, features a QP objective function and star-convex constraints:\n$\\min_y \\frac{1}{2} y^T Q y + p^T y, \\quad \\text{s.t. } ||y||_p \\leq b$\n(13)\nwhere vector $p$ serves as the input variable $x$ defined in Eq. (13) to the problem. Unlike the linear and convex constraints in Section 4.1(a), this problem introduces nonlinear, non-convex star-convex constraints, which present a more challenging optimization scenario.\nAs shown in Table 2, leveraging on topological equivalence given by HoP's homeomorphic mapping, HoP achieves perfect constraint satisfaction (0% violation rate) with an objective value of -0.3886, significantly outperforming DC3's -0.0730. In contrast, DC3's gradient post-corrections often introduce bias by diverging from the objective-minimizing direction, leading to suboptimal solutions. Especially in the $l_p$ norm optimization, its complex constraint boundary brings more suboptimal corrections to DC3's gradient post-corrections, which highly rely on the gradient of the constraints.\nComputationally, HoP is over 150\u00d7 faster than the traditional optimizer and matches the speed of NN-based methods. Unlike other basic NN-based approaches which exhibit violative results and inferior objective values, HoP strictly enforces constraints while delivering superior solution quality. These results highlight HoP's effectiveness in handling star-convex constraints.\n(c) High-Dimensional Semi-Unbounded Problem This experiment demonstrates the ability of Hop to handle high-dimensional and semi-unbounded problem. As same as the previous experiments, the problem follows the sinusoidal QP formulation introduced earlier in Eq. (12). Here, $p$ represents the input parameter $x$ for the NN model. As shown in Table 3, HoP consistently satisfies all constraints without any violations, confirming its robustness and feasibility under these challenging conditions. Moreover, HoP achieves the nearly optimal objective value -4.7683 among all methods, approaching to the traditional optimizer -7.6901 while maintaining strict constraint satisfaction. Otherwise, HoP still hold the advantages on computation complexity which is 52\u00d7 faster than optimizer.\nNotably, NN-SL and NN-SL-SC also achieve 0 violation rates in this high-dimensional semi-unbounded experiment. This is likely due to the expanded feasible region in such scenarios, where constraints are less tight, and the optimal solution lies away from the boundary. However, it does not imply that SL-based methods can theoretically guarantee hard constraint satisfaction under all conditions."}, {"title": "4.2. Application \u2013 QoS-MISO WSR Problem", "content": "In this experiment, we implement HoP to address the QOS-MISO WSR problem. The QOS-MISO WSR problem is a well-known NP-hard problem with non-linear constraints in communication engineering (Tang et al., 2023; Niu et al., 2021). In most studies on the QOS-MISO WSR problem, researchers commonly employ alternative optimization methods to obtain solutions, which often require significant computational resources. The problem is formulated as follows:\n$\\begin{aligned} &\\underset{\\mathbf{w}_k}{\\text{max}} \\sum_{k=1}^{U} \\alpha_k \\log_2(1 + \\text{SINR}_k)\\\\ &\\text{s.t.} \\quad \\log_2(1 + \\text{SINR}_k) \\geq \\delta_k \\quad \\forall k \\\\ &\\sum_{k=1}^{U} \\text{Tr}(\\mathbf{w}_k \\mathbf{w}_k^H) + P_c \\leq P_{\\text{max}} \\end{aligned}$\n(14)\n(14a)\n(14b)\nwhere $\\mathbf{w}_k \\in \\mathbb{C}^M$ is the beamformer, $(\\cdot)^H$ represents Hermitian transpose, $\\mathbf{h}_k \\in \\mathbb{C}^M$ denotes channel state information, and $\\sigma^2 \\in \\mathbb{R}$ is channel noise power. $\\alpha_k \\in \\mathbb{R}$ denotes priority weight for $U$ users, $\\delta_k$ represents the QoS requirements. $P_{\\text{max}}$ and $P_c$ define the system maximum power and circuit power consumption, respectively. The signal-interference-noise-ratio SINRk is defined as\n$\\text{SINR}_k = \\frac{\\mathbf{w}_k^H \\mathbf{h}_k \\mathbf{h}_k^H \\mathbf{w}_k}{\\sum_{j \\neq k}^U \\mathbf{w}_j^H \\mathbf{h}_k \\mathbf{h}_j^H \\mathbf{w}_j + \\sigma^2}$\n(15)\nGiven that wireless resource allocation requires real-time optimization strategies to effectively manage wireless resources with diverse channel state information, we select $\\mathbf{h}_k$ as the input of NN. This selection is crucial as $\\mathbf{h}_k$ significantly influences both the constraints and the objective function in Eq. (14)."}, {"title": "5. Conclusion", "content": "In this work, we propose HoP, a novel L2O framework for solving hard-constrained optimization problems. The proposed architecture integrates NN predictions with a homeomorphic mapping, which transforms NN's outputs from spherical polar space to Cartesian coordinates, ensuring solution feasibility without extra penalties or post-correction. Through extensive experiments encompassing both synthetic benchmark tasks and real-world applications, we demonstrate that HoP consistently outperforms existing L2O solvers, achieving superior optimality while maintaining zero constraint violation rates."}, {"title": "A. Proof of Proposition 3.3", "content": "Proof. Since C is star-convex with respect to yo, for any point y \u2208 C, the line segment connecting yo and y is entirely contained in C. That is, for all t \u2208 [0, 1], we have:\n(1 - t)yo + ty \u2208 C.\n(16)\nThen we consider a ray originating from yo in the direction of a unit vector $\\vec{v}_\\theta \\in \\mathbb{R}^n$. The ray can be parameterized as:\n$R = {y_0 + t\\vec{v}: t \\geq 0}$,\n(17)\nwhere t \u2265 0 is the parameter along the ray. Since yo \u2208 int(C), the ray R starts inside C. By the Definition 3.1, the ray R must intersect C, and the portion of the ray close to yo is entirely contained in C. Let $t^*$ be the supremum of the set of parameters t \u2265 0 such that yo + tv \u2208 int(C) which is given as:\n$t^* = \\text{sup}{t \\geq 0 : y_0 + t\\vec{v} \\in \\text{int}(C)}$.\n(18)\nSince int(C) is open and yo \u2208 int(C), this set is non-empty and $t^*$ exists. Define:\n$y_1 = y_0 + t^* \\vec{v}$.\n(19)\nBy construction, the point y1 satisfies the following: (1) For any t < $t^*$, yo + tv \u2208 int(C); (2) For any t > $t^*$, yo + tv \u2209 C. Therefore, y1 lies on the boundary of C, i.e., y\u2081 \u2208 \u2202C. Furthermore, since the ray is continuous and C is closed (as the finite intersection of closed sets), y1 \u2208 C. For any ray originating from yo, the closest intersection point y1 belongs to C and lies on its boundary \u2202\u0421."}, {"title": "B. Jacobian Analysis and Measure Distortion", "content": "This section presents a detailed analysis of the transformation\n$\\hat{y}(\\psi, \\mathbf{v}_\\theta) = \\mathbf{y}_0 + \\mathbf{v}_\\theta \\tan(\\psi)$,\n(20)\nwhere $\\psi \\in [0, \\frac{\\pi}{2})$ is a scalar parameter, and $\\mathbf{v}_\\theta \\in \\mathbb{R}^d$ is a unit vector (i.e., $|\\mathbf{v}_\\theta| = 1$). In this formulation, the direction $\\mathbf{v}_\\theta$ is treated as a free variable on the unit sphere $S^{d-1}$, while $\\psi$ governs the radial displacement via the function $\\tan(\\psi)$. The mapping $\\hat{y}(\\psi, \\mathbf{v}_\\theta)$ corresponds to the higher-dimensional homeomorphic mapping introduced in Eq. (8). It provides a diffeomorphic embedding of the parameter space $\\mathcal{P}$ into $\\mathbb{R}^d$, where $\\mathcal{P}$ is defined as:\n$\\mathcal{P} = \\{(\\psi, \\mathbf{v}_\\theta) \\ | \\psi \\in [0, \\frac{\\pi}{2}), \\mathbf{v}_\\theta \\in S^{d-1}\\}$.\nThe analysis below derives the Jacobian determinant of this transformation and discusses the measure distortion that arises as $\\psi$ approaches $\\frac{\\pi}{2}$, where $\\tan(\\psi)$ diverges. These results provide insight into the geometric and numerical properties of the homeomorphic mapping when applied to optimization tasks in semi-unbounded domains."}, {"title": "B.1. Jacobian Determinant", "content": "To characterize local volume distortion, we compute the Jacobian determinant (Spivak, 2018). The mapping $\\hat{y}(\\psi, \\mathbf{v}_\\theta)$ is defined in Eq. (20). The total derivative $D\\hat{y}(\\psi, \\mathbf{v}_\\theta)$ is a $d \\times d$ matrix whose columns represent the partial derivatives of $\\hat{y}$ with respect to $\\psi$ and to the $(d - 1)$ degrees of freedom on the unit sphere $S^{d-1}$. Specifically:\n(a) Derivative w.r.t. $\\psi$. For fixed $\\mathbf{v}_\\theta$,\n$\\frac{\\partial}{\\partial \\psi}(\\tan(\\psi) \\mathbf{v}_\\theta) = \\sec^2(\\psi) \\mathbf{v}_\\theta$.\n(21)"}, {"title": "(b) Derivatives w.r.t. the sphere parameters $\\mathbf{v}_\\theta$.", "content": "Lemma B.1 (Tangent Space). Let $\\mathbf{v"}, "theta \\in S^{d-1}$ be a unit vector on the sphere in $\\mathbb{R}^d$, satisfying $|\\mathbf{v}_\\theta| = 1$. Then any infinitesimal variation $d \\mathbf{v}_\\theta$ must lie in the tangent space $T_{\\mathbf{v}_\\theta} S^{d-1}$, given by:\n$\\mathbf{v}_\\theta \\cdot \\frac{d \\mathbf{v}_\\theta}{d \\theta} = 0 \\implies d\\mathbf{v}_\\theta \\in T_{\\mathbf{v}_\\"]}