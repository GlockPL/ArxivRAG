{"title": "Accelerating Manufacturing Scale-Up from Material Discovery Using Agentic Web Navigation and Retrieval-Augmented AI for Process Engineering Schematics Design", "authors": ["Sakhinana Sagar Srinivas", "Akash Das", "Shivam Gupta", "Venkataramana Runkana"], "abstract": "Process Flow Diagrams (PFDs) and Process and Instrumentation Diagrams (PIDs) are critical tools for industrial process design, control, and safety. However, the generation of precise and regulation-compliant diagrams remains a significant challenge, particularly in scaling breakthroughs from material discovery to industrial production in an era of automation and digitalization. This paper introduces an autonomous agentic framework to address these challenges through a two-stage approach involving knowledge acquisition and generation. The framework integrates specialized sub-agents for retrieving and synthesizing multimodal data from publicly available online sources and constructs ontological knowledge graphs using a Graph Retrieval-Augmented Generation (Graph RAG) paradigm. These capabilities enable the automation of diagram generation and open-domain question answering (ODQA) tasks with high contextual accuracy. Extensive empirical experiments demonstrate the framework's ability to deliver regulation-compliant diagrams with minimal expert intervention, highlighting its practical utility for industrial applications.", "sections": [{"title": "Introduction", "content": "PFDs (Process Flow Diagrams) and PIDs (Process and Instrumentation Diagrams) serve as the architectural blueprints for modern industrial operations (see Figures 1, and 2). They form the foundation of manufacturing by providing essential visualizations and operational details for process design and control, enabling efficient production, optimized industrial operations, and streamlined maintenance. These engineering tools underpin industrial design and operational control systems and are used in industries such as oil and gas, electronics manufacturing, pharmaceuticals, mining, mineral processing, and automotive and aerospace. PFDs offer a simplified macro-level overview of the entire process, illustrating material flows, energy balances, and equipment layouts, which facilitate initial design and optimization. In contrast, PIDs build upon PFDs and provide a micro-level perspective by detailing instrumentation and control schemes, which are essential for regulatory compliance, quality control, and safety in plant operation. In short, PFDs provide the context, while PIDs provide the specifics, making both indispensable throughout the entire lifecycle of a process plant, from initial design to decommissioning. As industries increasingly embrace automation and digitalization, the demand for accurate and efficient PFDs and PIDs continues to grow, highlighting their critical role in ensuring efficient, and compliant operations across various industrial sectors. Recent breakthroughs in generative AI are revolutionizing materials science and engineering(Jia, Zhang, and Fung 2024; Liu et al. 2023; Kim et al. 2024; Ansari et al. 2024), enabling autonomous material discovery and replacing expensive, time-consuming trial-and-error experimentation. However, these advancements often struggle to transition from computer simulations and lab experiments to large-scale industrial production. Scaling autonomous material discoveries to large-scale industrial production demands effective process design and control. PFDs and PIDs are crucial tools-providing high-level process overviews (material and energy balances) and detailed instrumentation/control strategies (consistent quality and safety) respectively-fundamental to the design, operation, and optimization of these processes. Automating their generation enables scalable solutions, transforming theoretical advances into economically viable industrial applications and accelerating the transition from research to real-world deployment, with transformative impacts across numerous industries. In this work, we present a two-stage method for creating PFDs and PIDs, particularly for the large-scale synthesis of novel chemicals. It involves a sequential and complementary knowledge acquisition phase, followed by a knowledge processing and generation phase. The knowledge acquisition phase populates the knowledge base (providing a foundation) used in the subsequent generation phase. Specifically: (a) Agentic web navigation (Putta et al. 2024; He et al. 2024; Abuelsaad et al. 2024), utilizing search engines and targeted queries, serves as a valuable, albeit incomplete, resource for accessing publicly available knowledge on PFDs and PIDs for well-known chemical processes. However, proprietary information regarding optimized process designs and highly specific control schemes is rarely publicly available, and the available information often represents simplified versions of real-world processes. (b) The knowledge processing and generation phase employs Retrieval-Augmented Generation (RAG) (Lewis et al. 2020), leveraging pretrained large language models (LLMs)"}, {"title": "Agentic Web Navigation Framework", "content": "We present a multi-agent framework for autonomous web navigation, optimized for knowledge creation. This framework enables independent web browsing, relevant information gathering, and insight synthesis related to PFDs and PIDs in chemical processes using online resources. It includes a meta-agent (or top-level agent) that orchestrates various specialized sub-agents. The meta-agent initiates the process by autonomously formulating queries to generate comprehensive knowledge about each chemical's PFDs and PIDs. By utilizing specialized sub-agents, each an expert in specific web-based information retrieval tasks, the meta-agent gathers and integrates detailed information from multiple sources. Each sub-agent uses SerpAPI to perform web searches and retrieve relevant information (e.g., images, scholarly articles, patents, Wikipedia, and web insights), which is then processed and synthesized by language models acting as computational engines to generate contextually relevant responses. The image sub-agent uses SerpAPI to extract and parse Google search results for relevant images of diagrams or flowcharts from publicly available sources."}, {"title": "Graph Retrieval-Augmented Generation", "content": "Graph RAG surpasses traditional RAG by leveraging knowledge graphs to overcome the limitations of traditional RAG in handling complex queries. While traditional RAG excels at retrieving simple, isolated facts, it often struggles to synthesize information across multiple sources for complex multi-hop reasoning tasks. Graph RAG, on the other hand, utilizes the structured relationships within knowledge graphs to traverse and reason effectively, providing deeper insights and more comprehensive responses. The process begins by constructing unimodal (text-only) knowledge graphs (KGs) through parsing unstructured documents, extracting relevant information, and structuring it into triples (subject-predicate-object). To facilitate this extraction and structuring, the documents are divided into manageable chunks using a sliding window technique. Let each document in a set of M documents be denoted as $D^{(m)}$, where $m=1,2,..., M$ represents the document index. Each document $D^{(m)}$ is divided into chunks based on a token window size. Each chunk is denoted as $C_i^{(m)}$, where $i = 1,2,..., N^{(m)}$ denotes the chunk index within document $D^{(m)}$, and $N^{(m)}$ is the number of chunks in that document, as defined below:\n$C_i^{(m)} = D^{(m)} [(i - 1) \\cdot s : (i - 1) \\cdot s + w]$\nHere, $C_i^{(m)}$ represents the i-th chunk in document $D^{(m)}$. The window size w (in tokens) and the stride s (the step size between consecutive chunks, also in tokens) are applied consistently across all documents. Choosing an optimal window size w and stride s requires balancing granularity with context retention. A smaller window with a smaller stride (resulting in higher overlap) may capture more detailed information but increase the computational cost of processing by language models. In contrast, a larger window size with a larger stride may better preserve context but dilute specific details. Although the sliding window technique helps maintain context, critical information near chunk boundaries may still be fragmented, impacting coherence and completeness, which can reduce retrieval effectiveness. To address the limitations, we propose a hybrid approach that combines the sliding window technique with a content-aware method (Anthropic 2023). In this approach, a language model generates a contextual description for each chunk $C_i^{(m)}$, denoted $ctx_i^{(m)}$, which provides a concise summary linking the chunk to the document's broader content, thereby enhancing retrieval relevance. We then prepend this context to the original chunk before encoding:\n$C_i^{(m)} = ctx_i^{(m)} \\oplus C_i^{(m)}$\nwhere $\\oplus$ denotes the concatenation operator. This approach embeds additional context, retains essential information, and improves retrieval accuracy. After enriching the chunks with context, they are used to construct the knowledge graph. To construct a knowledge graph G = (V, E), it is essential to extract and represent entities and their relationships in a structured format. The set of entities V serves as the nodes, while the relationships between entities, represented as E, form the directed edges. This structured representation enables the encoding of semantic information, providing a robust framework for advanced reasoning and retrieval tasks. We extract both entities and relationships using language models. The process begins with Named Entity Recognition (NER) to identify and extract entities within each chunk, resulting in a set of entities denoted as:\n$\\varepsilon_i^{(m)} = \\{e_{ji}^{(m)} : j = 1, 2, ..., K^{(m,i)} \\}$\nwhere $e_{ji}^{(m)}$ represents the j-th entity extracted from the i-th chunk $C_i^{(m)}$ of document $D^{(m)}$, and $K^{(i,m)}$ is the total number of entities in this chunk. Next, Relation Extraction (RE) identifies relationships between pairs of entities within the same chunk. These relationships are represented as:\n$R_i^{(m)} = \\{(e_{ji}^{(m)}, r_{i}^{(m)}, e_{ki}^{(m)}) : e_{ji}^{(m)}, e_{ki}^{(m)} \\in \\varepsilon_i^{(m)}\\mid$\nHere, each triple $(e_{ji}^{(m)}, r_{i}^{(m)}, e_{ki}^{(m)})$ denotes a relation $r_{i}^{(m)}$ between the entities $e_{ji}^{(m)}$ and $e_{ki}^{(m)}$. To improve search accuracy, we merge duplicate entities by identifying and combining those that represent the same concepts but appear differently in the data. Each entity $e_{ji}^{(m)}$ is represented by a vector embedding $v(e_{ji}^{(m)})$, generated using OpenAI's text-embedding-3-small model, which captures the entity's semantic meaning. The semantic similarity between two entities $e_{ji}^{(m)}$ and $e_{ki}^{(m)}$ is calculated using cosine similarity:\n$sim(v(e_{ji}^{(m)}), v(e_{ki}^{(m)})) = \\frac{v(e_{ji}^{(m)}) \\cdot v(e_{ki}^{(m)})}{\\|v(e_{ji}^{(m)})\\| \\|v(e_{ki}^{(m)})\\|}$\nIf the similarity exceeds a threshold Tsim, the entities are considered semantically similar. For further refinement, we use the Levenshtein distance to compute a string similarity ratio:\n$str\\_sim(e_{ji}^{(m)}, e_{ki}^{(m)}) = 1 - \\frac{d_{iev} (e_{ji}^{(m)}, e_{ki}^{(m)})}{max(\\|e_{ji}^{(m)}\\|, \\|e_{ki}^{(m)}\\|)}$\nwhere $d_{iev}$ denotes the Levenshtein distance between the two entity strings. An entity pair is deemed a duplicate and merged if both the semantic similarity $sim(v(e_{ji}^{(m)}), v(e_{ki}^{(m)}))> T_{sim}$ and the string similarity $str\\_sim(e_{ji}^{(m)}, e_{ki}^{(m)}) > T_{str}$ satisfy predefined thresholds. We apply the hierarchical Leiden algorithm to detect communities Ci at multiple levels of granularity, maximizing the modularity $Q_{Mod}$ of the knowledge graph. Modularity $Q_{Mod}$ quantifies the quality of the community structure by measuring the density of connections within communities compared to those between communities, with higher values indicating denser internal connections and sparser external connections. It is defined as:\n$Q_{Mod} = \\frac{1}{2m} \\sum_{i,j} \\bigg[A_{ij} - \\frac{k_ik_j}{2m}\\bigg] \\delta(c_i, c_j)$\nwhere $A_{ij}$ represents the adjacency matrix, indicating the presence of an edge between nodes i and j; $k_i$ and $k_j$ are the degrees of nodes i and j; m is the total number of edges in the graph, used to normalize the adjacency matrix to reflect the expected density of connections in a random graph (where node degrees are preserved, but specific connections are randomized); and $\\delta(c_i, c_j)$ is the Kronecker delta function, equal to 1 if nodes i and j belong to the same community and 0 otherwise. The hierarchical Leiden algorithm partitions the graph into L communities, $\\{C_1, ..., C_L\\}$, by maximizing $Q_{Mod}$, revealing a strong community structure. The process involves three steps: (1) the local moving phase, where nodes are shifted between communities to maximize modularity; (2) the aggregation phase, where detected communities are merged into super-nodes; and (3) repetition of these phases until no further improvement in modularity is possible. Each community $C_i = (V_{c_i}, E_{c_i})$ consists of its nodes $V_{c_i}$ and edges $E_{c_i}$. The algorithm facilitates focused retrieval in knowledge graphs by detecting communities and refining them to align with query-specific subgraphs. For complex multi-hop reasoning tasks, relevant information often spans multiple communities. To address this, our approach prioritizes the top-K communities $\\{C_1, C_2, ..., C_K\\}$, ranked based on the cosine similarity between the user query Q and summaries of relationship paths within each community. Each community $C_i$ is summarized using a language model that condenses relationship paths $R_i$:\n$S_i = LLM(R_i) = arg\\underset{S}{max} P(S | R_i)$\nwhere $S_i$ is the summary, and P(S | $R_i$) represents the likelihood of S given $R_i$, encompassing both direct and multi-hop relationships. These summaries are converted into vector embeddings $v(S_i)$ using a text-embedding model, enabling efficient similarity computation with the embedded query v(Q):\n$d(Q, C_i) = \\frac{(v(Q), v(S_i))}{\\|v(Q)\\| \\|v(S_i)\\|}$\nThe top-K communities with the highest similarity scores are selected, ensuring that a diverse and relevant set of subgraphs is aggregated. These selected communities are then combined into a query-specific subgraph $G_Q = (V_Q, E_Q)$, defined as:\n$V_Q = \\cup_{i=1}^{K}V_{c_i}, E_Q = \\cup_{i=1}^{K}E_{c_i}$\nThis subgraph retains critical nodes $V_Q$ and edges $E_Q$ from the top-K communities, capturing the essential connections and semantic relationships needed to address the query. Paths P = ($e_1, r_1, e_2,...,e_k$), where $e_i$ are entities and $r_i$ are relationships, are extracted from $G_Q$. These paths encode semantic dependencies vital for reasoning. A language model generates the answer A by integrating the query Q and paths P:\n$A = LLM(Q, P) = arg\\underset{A}{max} P(A | Q, P)$\nwhere P(A | Q, P) denotes the probability of A given Q and P, ensuring that the response is contextually accurate and aligned with the query's intent. The construction and utilization of a knowledge graph for the ODQA task are detailed in Algorithm 2."}, {"title": "Experiments", "content": "We constructed a comprehensive dataset of over 1,070 chemicals with significant applications across diverse industries, including electronics manufacturing, oil and gas, pharmaceuticals, renewable energy, chemical production, mining, water treatment, and food and beverage. This dataset, meticulously curated from the product catalogs of leading chemical manufacturers like BASF, Dow Chemicals, and DuPont, ensures reliability and consistency by grounding the data in credible sources, thereby minimizing ambiguities and inaccuracies associated with unstructured, free-form inputs. It comprises two subsets: a primary subset of 1,020 chemicals used for autonomous web navigation, domain-specific data retrieval, and generating PFDs and PIDs to construct ontological knowledge graphs as foundational databases; and a secondary evaluation subset of 50 chemicals to rigorously assess the framework's robustness and generalizability in auto-generating PFDs and PIDs. Additionally, we developed a custom ODQA dataset of 6,000 QA pairs focused on process diagrams of the primary subset, with questions systematically generated using predefined templates and answers produced by benchmark LLMs like GPT-40. Covering categories such as fact-based, logical, comparative, causal, operational, multi-hop, and procedural questions, each QA pair underwent meticulous validation before inclusion, enabling the evaluation of the framework's accuracy, contextual relevance, and capability to address diverse technical queries."}, {"title": "Experimental Settings", "content": "In our work, we utilized SmolLM2-360M-Instruct [Allal et al., 2024], a pre-trained and fine-tuned model, as the computational engine to compare the performance of Graph RAG with a pre-trained LLM (leveraging ontological knowledge graphs constructed from PFD and PID descriptions of the primary subset of chemicals) and a fine-tuned LLM without Graph RAG (instruct-tuned using the same knowledge base). This comparison aimed to evaluate the impact of Graph RAG on pre-trained model performance. Graph RAG with a pre-trained LLM incurs higher computational costs due to graph construction and retrieval, resulting in slower overall inference times because of graph traversal. However, the pre-trained LLM processes retrieved context efficiently. It excels in dynamic knowledge updates and multi-hop reasoning. In contrast, a fine-tuned LLM without Graph RAG offers faster inference by embedding retrieval within the model but requires costly fine-tuning and is less flexible for adapting to new data without re-fine-tuning. The fine-tuned LLM's inference time is slightly higher due to its larger, task-specific parameterization. We also utilized OpenAI's text-embedding-3-small model for text encoding tasks and CLIP embeddings for multimodal processing, enabling the encoding of visual data. The framework integrated the Graph RAG approach with Neo4j to facilitate structured knowledge retrieval. To fine-tune SmolLM2-360M-Instruct, we generated an instruction-following dataset for the task of producing descriptions of PFDs and PIDs for the primary subset of chemicals. The dataset was structured with instruction prompts and corresponding target outputs and was used for supervised fine-tuning to optimize the model's task-specific performance. Note: For Graph RAG with pre-trained LLMs, the same knowledge-PFD and PID descriptions of the primary subset of chemicals-was used for constructing the knowledge graph and did not involve fine-tuning the LLM itself. The fine-tuning process employed advanced techniques such as gradient accumulation and Low-Rank Adaptation (LORA) for efficient training. Key hyperparameters included a learning rate of $5 \\times 10^{-5}$, a batch size of 8 per device, 3 training epochs, and 4 gradient accumulation steps, simulating an effective batch size of 32 (8 \u00d7 4). This configuration allowed the model to perform updates as if it had processed 32 samples in one step, even though only 8 samples were loaded into memory at a time. LoRA reduced trainable parameters by updating low-rank matrices (e.g., rank r = 4, scaling factor a = 16) and applied dropout (e.g., 0.1) to updates for regularization. LoRA fine-tuned only specific layers, such as attention weights, while typically freezing biases, and integrated seamlessly with gradient accumulation. Low-rank matrices were initialized randomly to ensure efficient convergence, while regularization prevented overfitting. We employed LoRA with mixed precision (FP16), further optimizing memory usage and training speed. Rigorous evaluation strategies, such as per-epoch validation using metrics like loss (e.g., cross-entropy), ensured scalable and effective fine-tuning tailored to specific tasks. All experiments were conducted using NVIDIA Tesla T4 GPUs for efficient computation, and the framework was implemented in Python with PyTorch and Unsloth."}, {"title": "Experimental Studies", "content": "The framework's performance was evaluated across multiple tasks: (a) comparing auto-generated PFDs and PIDs for chemicals in the secondary evaluation subset to ground-truth data; (b) evaluating its ability to answer diverse queries from the ODQA dataset, including logical, causal, procedural, and multi-hop reasoning questions; (c) analyzing the impact of structured retrieval on multi-hop reasoning and contextual accuracy by comparing Graph RAG combined with a pre-trained LLM to a fine-tuned LLM without Graph RAG, used as a baseline; and (d) demonstrating Graph RAG's superiority over traditional RAG in handling complex queries and generating accurate, context-aware responses."}, {"title": "Results", "content": "In this section, we present the experimental results on knowledge generation. Additional experimental results are discussed in the appendix. Figure 5 illustrates the evaluation metrics for the autonomous agentic web navigation framework, which is designed to automate and optimize the processes of gathering and synthesizing information for PFDs and PIDs for the primary subset of chemicals from publicly available online sources. The framework's outputs were evaluated using the NVIDIA Nemotron-4-340B-"}, {"title": "Conclusion", "content": "In conclusion, this paper introduces an autonomous agentic web navigation framework that integrates GraphRAG to overcome challenges in generating regulation-compliant PFDs and PIDs for industrial processes. The framework demonstrates its capability to efficiently synthesize multimodal data from publicly available online sources, construct ontological knowledge graphs, and address ODQA tasks with high contextual accuracy. These advancements underscore the potential of AI-driven automation to streamline process design and accelerate the industrial application of emerging material innovations. Future work will focus on incorporating first-principles-based simulation tools to enhance the framework's precision and reliability, further bridging the gap between computational insights and industrial-scale implementation."}, {"title": "Additional details", "content": "The hyperparameters for constructing knowledge graphs are optimized to enhance core processes, including chunking, triple extraction, similarity evaluation, and storage. Chunking parameters, such as window size (w) and stride (s), ensure that text is segmented into manageable and contextually continuous segments. The window size (w) is set to 1024 tokens, allowing for larger contextual segments to capture detailed information, while the stride (s) is set to 128 tokens, maintaining a 12.5% overlap to balance contextual continuity and computational efficiency. For triple extraction, advanced LLMs, such as GPT-40, identify entities and relationships, generating structured triples while adhering to a maximum per-chunk threshold (M) of 20 triples to balance graph complexity and efficiency. Similarity evaluation incorporates a high cosine similarity threshold (0.9) to ensure precise merging of semantically similar entities and applies a Levenshtein edit distance limit of 5 to resolve minor variations in entity names or labels effectively. Finally, the graph is stored in robust systems like Neo4j, capable of efficiently managing the increased data volume from larger window sizes. This parameterization ensures scalability, precision, and semantic consistency, leveraging state-of-the-art techniques for constructing and managing knowledge graphs. Optimization of the ranking and retrieval steps is crucial for handling large graphs efficiently, as these processes can be computationally expensive. To address this, precomputing summaries (Si) for frequently used communities can significantly reduce runtime by avoiding repetitive computations during queries. Additionally, indexing the embeddings (v(Si)) of these summaries enables faster similarity computations, enhancing the overall scalability and framework performance."}, {"title": "Algorithm 1: Autonomous Agentic Web Navigation Framework for Knowledge Generation", "content": "Require: Query Q related to PFDs or PIDs on primary dataset\nEnsure: Generated knowledge A* optimized through iterative refinement\nInitialize Meta-Agent with task Q\nDecompose Q into subtasks {q1,q2,..., qn}\nfor each subtask qi do\nfor each sub-agent tj do\nCompute similarity:\n$sim(v(q_i), v(d_j)) = \\frac{v(q_i)v(d_j)}{\\|v(q_i)\\|\\|v(d_j)\\|}$\nend for\nSelect sub-agent:\n$t_j = arg \\underset{t_j}{max} sim(v(q_i), v(d_j))$\nInvoke $t_j$ with parameters $P_1, P_2, P_3$\nReceive result $R_{q_i}$ from $t_j$\nend for\nManage dependencies using DAG G = (V, \u03b5)\nExecute independent subtasks in parallel\nfor each result $R_{q_i}$ do\nif tj is the image agent then\nRetrieve images I = {$i_1, ..., i_k$}\nCompute embeddings eI using CLIP\nCompute similarity:\n$sim(e_I, e_{q_i}) = \\frac{e_I e_{q_i}}{\\|e_I\\|\\|e_{q_i}\\|}$\nSelect relevant images IJ CI\nGenerate summary $D_I$ using LLM\nelse if t; is the scholarly article agent then\nRetrieve articles A = {$a_1, a_2,..., a_m$}\nCompute embeddings eA\nCompute similarity sim(eA, $e_{q_i}$)\nSelect relevant articles AJ CA\nGenerate summary $D_A$ using LLM\nelse if tj is the patent agent then\nRetrieve patents P = {$P_1,P_2,..., P_l$}\nCompute embeddings eP\nCompute similarity sim(eP, $e_{q_i}$)\nSelect relevant patents PJ C P\nGenerate summary $D_P$ using LLM\nelse if tj is the wiki agent then\nRetrieve pages W = {$w_1, w_2,..., w_p$}\nCompute embeddings ew\nCompute similarity sim(ew, $e_{q_i}$)\nSelect relevant pages WJ CW\nGenerate summary $D_W$ using LLM\nelse if t; is the web insights agent then\nRetrieve insights G = {$g_1, g_2,..., g_q$}\nCompute embeddings eG\nCompute similarity sim(eG, $e_{q_i}$)\nSelect relevant insights GJ CG\nGenerate summary $D_G$ using LLM\nend if\nend for\nAggregate outputs into response:\nA = MetaAgentLLM (Synthesize ($D_I, D_A, D_P, D_W, D_G$))\nInitialize i = 0, Ao = A\nrepeat\nGenerate feedback $F_i$ from experts and benchmark models\nUpdate output:\n$A_{i+1}$ = MetaAgentLLM(Q, $A_i$, Fi)\ni++\nuntil Ai meets quality standards or i > Nmax\nSet optimized generated knowledge A* = $A_i$\nStore A* in documents D"}, {"title": "Algorithm 2: Knowledge Graph Construction and Utilization in ODQA", "content": "Require: Input documents D = {$D^{(1)}, D^{(2)},..., D^{(M)}$}, ODQA query Q, window size w, stride s, thresholds Tsim and Tstr\nEnsure: Optimal answer Aq for the ODQA task\nInitialize an empty knowledge graph G = (V, \u03b5)\nfor each document $D^{(m)}$ \u2208 D do\nDivide $D^{(m)}$ into chunks $C_i^{(m)}$ using window size w and stride s:\n$C_i^{(m)} = D^{(m)} [(i - 1) \\cdot s : (i - 1) \\cdot s + w]$\nGenerate contextual summary $ctx_i^{(m)}$ for each chunk using a language model\nEnrich chunk by concatenating context:\n$C_i^{(m)} = ctx_i^{(m)} \\oplus C_i^{(m)}$\nPerform entity extraction to identify entities:\n$\\varepsilon_i^{(m)} = \\{e_{ji}^{(m)} : j = 1, 2, ..., K^{(m,i)} \\}$\nPerform relation extraction to identify relationships:\n$R_i^{(m)} = \\{(e_{ji}^{(m)}, r_{i}^{(m)}, e_{ki}^{(m)})$\\mid\nAdd entities $\\varepsilon_i^{(m)}$ and relations $R_i^{(m)}$ to G\nend for\nDeduplicate entities:\nfor each pair ($e_{ji}^{(m)}, e_{ki}^{(m)}$) in G do\nCompute semantic similarity:\n$sim(v(e_{ji}^{(m)}), v(e_{ki}^{(m)})) = \\frac{v(e_{ji}^{(m)}) \\cdot v(e_{ki}^{(m)})}{\\|v(e_{ji}^{(m)})\\| \\|v(e_{ki}^{(m)})\\|}$\nCompute string similarity: $str\\_sim(e_{ji}^{(m)}, e_{ki}^{(m)})$\n$str\\_sim(e_{ji}^{(m)}, e_{ki}^{(m)}) = 1 - \\frac{d_{iev} (e_{ji}^{(m)}, e_{ki}^{(m)})}{max(\\|e_{ji}^{(m)}\\|, \\|e_{ki}^{(m)}\\|)}$\nif $sim(v(e_{ji}^{(m)}), v(e_{ki}^{(m)})) > T_{sim}$ and $str\\_sim(e_{ji}^{(m)}, e_{ki}^{(m)}) \\geq T_{str}$ then\nMerge entities $e_{ji}^{(m)}$ and $e_{ki}^{(m)}$\nend if\nend for\nDetect communities in G using the Leiden algorithm:\nPartition graph into communities $\\{C_1, C_2,..., C_L\\}$ by maximizing modularity:"}]}