{"title": "DeepMDV: Learning Global Matching for\nMulti-depot Vehicle Routing Problems", "authors": ["Saeed Nasehi", "Farhana Choudhury", "Egemen Tanin"], "abstract": "Due to the substantial rise in online retail and e-\ncommerce in recent years, the demand for efficient and fast\nsolutions to Vehicle Routing Problems (VRP) has become critical.\nTo manage the increasing demand, companies have adopted\nthe strategy of adding more depots. However, the presence\nof multiple depots introduces additional complexities, making\nexisting VRP solutions suboptimal for addressing the Multi-depot\nVehicle Routing Problem (MDVRP). Traditional methods for\nsolving the MDVRP often require significant computation time,\nmaking them unsuitable for large-scale instances. Additionally,\nexisting learning-based solutions for the MDVRP struggle with\ngeneralizability and fail to deliver high-quality results for sce-\nnarios involving a large number of customers. In this paper, we\npropose a novel solution for MDVRP. Our approach employs an\nattention mechanism, featuring a decoder with two key layers:\none layer to consider the states of all vehicles and learn to select\nthe most suitable vehicle based on the proximity of unassigned\ncustomers, and another layer to focus on assigning a customer\nto the selected vehicle. This approach delivers high-quality\nsolutions for large-scale MDVRP instances and demonstrates\nremarkable generalizability across varying numbers of customers\nand depots. Its adaptability and performance make it a practical\nand deployable solution for real-world logistics challenges.", "sections": [{"title": "I. INTRODUCTION", "content": "The rapid growth of online retail and e-commerce has\nsignificantly increased delivery requests in urban areas, with\nthousands being processed every minute [1]. In 2022, Manhat-\ntan experienced over 2.4 million daily delivery requests [2],\nequating to more than 3,000 deliveries every minute during a\n12-hour workday. This highlights the need for solutions that\nare not only effective but also capable of producing results in a\nfew seconds. Even algorithms that take minutes to compute fall\nshort in handling such massive, real-time scheduling demands,\nas delays can quickly cascade, causing significant disruptions\nacross the entire logistics network. Moreover, in large cities\nlike New York City, for example, over 30,000 delivery trucks\nare active, each covering more than 12,000 miles annually [3],\nwhich emphasizes the critical need for optimizing delivery\nroutes, as even a 1% reduction in driving distances could save\nover 3.6 million miles of travel each year.\nThe delivery problem is commonly modeled as the Vehicle\nRouting Problem (VRP), where vehicles are tasked with deliv-\nering parcels to requesters [4]. These routing queries typically\noriginate from warehouses (depots) in e-commerce, while\ndestinations are workplaces or homes. The main challenge in\nVRP lies in determining the optimal sequence of customer\nvisits, where the vehicles have capacity constraints, ensuring\nefficient routes to fulfill requests.\nIn response to growing demands, companies are increas-\ningly expanding their networks by establishing additional de-\npots [5]. The Multi-Depot Vehicle Routing Problem (MDVRP)\nextends the complexity of the single-depot VRP, both of which\nare NP-hard. While the VRP focuses solely on determining the\noptimal path for customer visits, the MDVRP adds complexity\nby requiring the identification of both the starting depot and the\nroutes for a fleet of vehicles to satisfy all customer demands\n(e.g., deliveries). This process typically adheres to specific\nobjectives, such as minimizing the total distance traveled [6].\nThe inclusion of multiple depots significantly increases the\nproblem's difficulty, as it expands the decision space and\ncomplicates the search for optimal solutions.\nMDVRP solutions are broadly categorized into two ap-\nproaches based on their methodology: i) MDVRP as Multiple\nSingle-depot VRP: Known as the Clustering-then-Routing,\nthis spatial partitioning approach divides the problem into clus-\nters, each associated with an individual depot [7]. Each cluster\nis then solved as a VRP using existing techniques. ii) MDVRP\nas a Unified Instance: In this method, (meta-)heuristic or\nlearning-based solutions are designed to handle the MDVRP in\nits entirety, providing routes for each customer and identifying\nthe depot that serves each customer [8], [9].\nThe clustering-then-routing approach is a straightforward\napproach for extending VRP solutions to multi-depot scenar-\nios. It uses a distance-based clustering algorithm to divide\nthe problem into multiple single-depot VRPs, which are then\nsolved using existing VRP solutions. While this method en-\nables easy application of any VRP solution to the MDVRP by\ndividing the problem into clusters, it often results in subopti-\nmal outcomes. This is due to its lack of a global perspective,\nwhich can lead to imbalanced workloads, suboptimal customer\nassignments near cluster boundaries, and underutilized vehi-\ncles. Consequently, total travel distances increase, and overall\nefficiency declines. While deep learning (DL) solutions show\nhigh performance for single-depot VRP by quickly mapping\nproblem instances to (near-)optimal solutions and can be\napplied to large instances [10]\u2013[12], there is no such existing\napproach for MDVRP. As the existing DL solutions for VRP\ncan only be applied to MDVRP by clustering-then-routing\napproach, they suffer from all the drawbacks mentioned above.\nSolutions in the second category can be further divided\ninto two main groups: (meta-)heuristic approaches [13]\u2013[15]"}, {"title": "A. Heuristic and meta-heuristic methods", "content": "Authors in [19] developed a parallel algorithm based on\nAnt Colony Optimization (ACO) to enhance computational\nefficiency and solution quality for MDVRP. Ombuki-Berman\net al. applied Genetic Algorithms (GA) to address MDVRP [9],\nwhile authors in [7] further refined GA-based approaches by\ngrouping customers based on their proximity to the nearest\ndepot before optimizing the routes within each cluster using\nGA. Vidal [14] introduced a hybrid method combining local\nsearch with GA, leveraging the strengths of both techniques\nto produce high-quality solutions for VRP, which can also be\napplied to MDVRP. Lahyani et al. [28] introduced a hybrid\nadaptive large neighborhood search algorithm that combined\nsome novel improvement procedures to enhance solution qual-\nity. Tabu Search (TS) has also been used to solve MDVRP.\nCordeau et al. [29] proposed a TS algorithm with the randomly\ngenerated initial solution for the MDVRP. Escobar et al. [30]\nproposed an enhanced strategy and used a hybrid Granular\nTS that leverages various neighborhood and diversification\nstrategies to improve the quality of the initial solutions.\nThese methods typically follow a construction-destruction-\nimprovement pattern, where an initial feasible solution is iter-\natively refined until an acceptable solution is obtained. Despite\ntheir effectiveness and interpretability, these methods often\nrequire substantial memory and long computation times to\ngenerate high-quality solution [11], making them less practical\nfor real-life and large-scale scenarios."}, {"title": "B. Learning-based methods", "content": "Deep learning-based solutions use the representation learn-\ning capabilities of neural networks to rapidly map problem\ninstances to (near-)optimal solutions. These approaches often\nemploy techniques like graph neural networks [31], [32],\nattention mechanisms [33], and reinforcement learning to\nmodel the combinatorial nature of the problem and learn\ncomplex decision-making strategies. Although many solutions\nhave been developed for VRP and its variants, such as Pickup\nand Delivery [1], [34], [35], there is a significant gap in\nlearning-based methods specifically addressing the MDVRP.\nTo the best of our knowledge, Arishi et al. [8] have proposed\nthe state-of-the-art learning-based solution for the MDVRP.\nThey developed a Multi-agent Deep Reinforcement Learning\n(MADRL) model using an attention-based transformer model,\ntrained with a policy gradient method. This approach falls\nshort in providing high-quality solutions for MDVRP instances\nwith several hundred customers and is hindered by significant\ncomputational resource requirements during both the training\nand inference phases for large instances. The high computa-\ntional complexity and substantial memory demands make it\nchallenging to train this model for MDVRP instances with\nmore than 100 customers and four depots, as an example."}, {"title": "C. Extending VRP to solve MDVRP", "content": "Notably, the partitioning-then-routing strategy has recently\nemerged as a popular approach in learning-based methods for\nsolving large-scale VRPs [10], [11], [36]\u2013[39]. Hou et al. [11]\nintroduce the Two-stage Divide Method (TAM) designed for\nlarge-scale VRP scenarios which autoregressively partitions\nthe VRP instance into sub-TSPs. In contrast, Ye et al. [10]\npropose Global and Local Optimization Policies (GLOP) to\ncombine non-autoregressive global partition with autoregres-\nsive local construction policies to first learn the partitioning\nand then learn to solve sub-TSPs. None of these methods are\ncapable of effectively addressing MDVRP instances directly.\nAlthough distance-based clustering [7], followed by ap-\nplying one of the many proposed VRP solutions [10], [11],\n[25], [40], [41], is a straightforward strategy for solving\nMDVRPs, it often leads to suboptimal results. This approach\nneglects global optimality, leading to imbalanced workload\ndistribution among depots and inefficient customer assign-\nments near cluster boundaries. Consequently, some vehicles\nmay be underutilized, leading to increased total travel distance\nand reduced solution's overall efficiency. This highlights the\nnecessity of designing a model specifically for MDVRP. In our\nexperiments, we use these methods as baselines to benchmark\nand evaluate the performance of DeepMDV."}, {"title": "III. PROBLEM DEFINITION", "content": "The Vehicle Routing Problem (VRP) is a combinatorial op-\ntimization challenge that involves efficiently routing a fleet of\nvehicles from a designated depot to meet all customer demands\nwhile adhering to specific objectives and various constraints.\nIn the Capacitated Vehicle Routing Problem (CVRP), vehicles\nwith limited carrying capacities must fulfill customer demands.\nThe Multi-depot Vehicle Routing Problem (MDVRP) gen-\neralizes the traditional CVRP by incorporating multiple depots\nfrom which vehicles can start their routes. Depending on\nthe problem's constraints, vehicles may either return to their\nstarting depot (closed tour) or finish at any depot (open tour).\nIn this paper, we propose a solution for the MDVRP with\nclosed tours. This problem involves a set of depots D and a set\nof customers U. The objective is to determine a set of routes\nfor a fleet of vehicles, where each vehicle starts and ends its\nroute at a depot, aiming to minimize the total traveling distance\nwhile satisfying all customer demands and vehicle constraints.\nLet V be a set of vehicles, where each vehicle $v \\in V$ has a\ncapacity $C_v$, and each customer $i \\in U$ has a demand $d_i$. The\ndistance between any two nodes i and j, where $i, j \\in D \\cup U$,\nis denoted by $e_{ij}$. We define $X_{ijv} \\in \\{0,1\\}$ as a binary decision\nvariable that equals 1 if vehicle v travels from i to j, and 0\notherwise. Let $z_j$ represent an auxiliary variable indicating the\ncumulative load of the vehicle after serving customer j, the\nMDVRP problem can then be formulated as follows:\nMinimize $\\sum_{\\substack{i \\in D \\cup U}} \\sum_{\\substack{j \\in D \\cup U}} \\sum_{v \\in V} C_{ij}X_{ijv}$  (1)\n$\\sum_{v \\in V} \\sum_{i \\in D \\cup U} X_{ijv} = 1, \\forall j \\in U$  (2)\n$\\sum_{i \\in D \\cup U} X_{ijv} = \\sum_{i \\in D \\cup U} X_{jiv}, \\forall j \\in U, v \\in V$  (3)\n$\\sum_{i \\in U} X_{div} = 1, \\sum_{i \\in U} X_{idv} = 1, \\forall d \\in D, \\forall v \\in V$  (4)\n$\\sum_{j \\in U} d_j \\sum_{i \\in D \\cup U} X_{ijv} \\leq C_v, v \\in V$  (5)\n$z_j \\geq z_i + n_i - M(i - X_{ijv}), \\forall i \\neq j, \\forall v \\in V$  (6)\nEquation 1 defines the objective of minimizing the total cost\nof all routes. Equation 2 ensures that each customer is visited\nexactly once by one of vehicles, while Equation 3 enforces\nthat if a vehicle arrives and a customer, it must also depart\nfrom that customer. Equation 4 specifies that each vehicle's\nroute must start and end at a a specific depot. Equation 5\nensures that the total demand serviced by each vehicle does not\nexceed its capacity. Finally, Equation 6 prevents the formation\nof subtours, thereby guaranteeing a valid route."}, {"title": "IV. METHODOLOGY", "content": "Before introducing the proposed algorithm, it is essential to\ndefine the concepts of standby, initiated, active, and inactive\ntours. A standby tour is a tour that has not yet been assigned\nany customers, representing a vehicle at the depot with full\ncapacity. An initiated tour is a tour that has at least one\nassigned customer and can accept more. Assigning a customer\nto a standby tour turns it into an initiated tour. The term\nActive tours refers to tours that are either in standby or\nhave already been initiated. While the active tour list can\ntheoretically contain any number of tours, having multiple\nactive tours originating from the same depot simultaneously\nreduces training efficiency without improving solution quality.\nTo streamline the process, we assume only one active tour can\nexist per depot at any given time. Consequently, the number of\nactive tours at any step is limited to the total number of depots\n(|D|), with no two active tours originating from the same\ndepot. Inactive tours is a list of tours that no longer accept\nnew customers, having selected the depot node as their final\nstop. When an active tour becomes inactive, a new standby\ntour from the same depot replaces it in the list of active tours."}, {"title": "B. Markov decision process model", "content": "We model the MDVRP problem as a Markov Decision\nProcess (MDP), defined by the 4-tuple $M = \\{S, A, T, R\\}$.\nThe detailed definition of the state space S, the action space\nA, the transition function T, and the reward function R are\nprovided below.\nState: State $s_t \\in S$ consists of two components, (\u0397, \u03a6).\nThe first component, H, describes the embedding of nodes,\nexpressed as $H = \\{h_0, ..., h_n\\}$. Each embedding comprises a\nvector that captures the location of the node, and a scalar value\nthat defines the demand of the customer. The demands for all\ndepot nodes are considered as zero. The second component,\n\u03a6, represents the state of all active tours at step t, denoted\nas $\\Phi_t = \\{\\phi_1^t,...,\\phi_m^t\\}$ where $m \\leq |D|$. The state of each\nactive tour at step t is described by $\\phi_i^t = \\{h_{di}, h_{v(t-1)},c_i^t\\}$\nwhich includes the embedding of depot it started from ($d_i$),\nthe embedding of the last node added to the tour ($v_{(t-1)}$), and\nremaining available capacity ($c_i^t$).\nInitial state: The initial state is defined as (\u0397, \u03a60), where\nH represents the node embeddings, and \u03a60 denotes the initial\nstate of all active tours at step t = 0. The state of each active\ntour at this step is described by $\\phi_i^0 = \\{h_{di},h_{d_1}, C_i\\}$, where\n$h_{d_i}$ is the embedding of the depot node for the tour, and C\nindicates the maximum available capacity.\nAction: The action at step t involves selecting a tour from\nthe current list of active tours and assigning a new node to it.\nIn other words, the action $a_t \\in A$ is represented as ($i, n_j$),\nindicating that node $n_j$ is added to tour i.\nTransition: The transition rule is to update the state $s_t$ to $s_{t+1}$\nbased on performed action $a_t = (\\phi_i^t, n_j)$. In this process, the\nlast added node of the selected tour is changed to $n_j$, and the\nremaining capacity of the tour is updated as $c_i^{t+1} = c_i^t - d_{n_j}$.\nIf the selected node is the depot, the current tour $\\phi_i^t$ is marked\nas inactive and moved to the list of inactive tours. If the total\nnumber of tours has not yet reached the optimal maximum (as\ndetailed in Section V-A), a new standby tour originated from\nthe same depot replaces it in the active tour list.\nReward: The reward function for each problem instance\nis computed after all customers are assigned to tours and\nis defined as the negative sum of the minimum Euclidean\ndistances for all tours. Since each tour begins and ends at a\ndepot, the reward for each tour corresponds to the total travel\ndistance of the Hamiltonian cycle with the minimum length\nwithin that tour. Mathematically, this is expressed as:\n$R = - \\sum_{\\Phi_i \\in \\Phi} MinCycleLength(\\Phi_i)$  (7)\nwhere \u03a6 is the list of tours, and $MinCycleLength(\\Phi_i)$\nrepresents the travel length of the Hamiltonian cycle with the\nshortest distance for tour $d_i$. Finding the Hamiltonian cycle\nwith the shortest length, also known as solving the Traveling\nSalesman Problem (TSP), is an NP-hard problem. However,\nby dividing the entire problem space into multiple tours, our\nmethod enables the use of heuristic or machine learning-based\nsolutions specifically designed for TSP, resulting in efficient\nand effective method for calculating rewards."}, {"title": "V. DEEPMDV", "content": "Figure 1 shows the framework of the proposed solution.\nOur approach focuses on learning a stochastic policy $p_\\theta(a_t| s_t)$,\nrepresented by a deep neural network with trainable parameter\n\u03b8. This policy partitions customers into multiple tours, ensur-\ning each customer is assigned to one of the tours by the end\nof the process. Each tour is associated with a specific depot,\nand the partitioning process generates m distinct groups of\ncustomers. The optimal visiting sequence within each tour is\nthen determined to minimize travel distance.\nOur policy network $p_\\theta$ is composed of an encoder and\na decoder. The decoder includes a Vehicle Selection and\nLocal Context Generation Layer (VSLCGL) along with a\nNode Selection Layer (NSL). Given that the problem instance\nremains fixed during the decision-making process, the encoder\nruns only once at the beginning, and its outputs are used in\nsubsequent steps (t > 0) for tour construction."}, {"title": "A. Optimal maximum number of tours.", "content": "In the MDVRP, each tour must adhere to vehicle capacity\nconstraints to prevent exceeding the vehicle's capacity. A new\nconstraint can be defined to determine the optimal maximum\nnumber of tours before processing. Inspired by the approach\nproposed for the VRP [11], we introduce this constraint for\nthe MDVRP. For an MDVRP instance with |U| customers and\n|D| depots, where C represents the maximum vehicle capacity\nand di denotes the demand of customer i, the optimal upper\nlimit for the number of tours can be determined as follows:\n$l_{max} = \\lceil \\frac{\\sum_{i=0}^{\\vert U \\vert} d_i}{C} \\rceil + |D|$  (8)\nThe first part of the equation determines the minimum\nnumber of tours needed to meet all demands. Since the optimal\nMDVRP solution may have up to |D| partially loaded tours,\nwe add the number of depots to the minimum number of tours\nneeded. This allows vehicles originating from each depot have\nthe flexibility to deactivate an active tour before reaching their\ncapacity limit, entails in a more efficient solution. Our exper-\niments show that predefining the optimal maximum number\nof tours can speed up model convergence. Note that, $l_{max}$\nrepresents the maximum number of tours allowed. Depending\non the problem instance and the model, the actual number of\ntours can vary but will not exceed this limit."}, {"title": "Masking function for initiating a standby tour:", "content": "The first step\nto satisfy the optimal maximum number of tour constraint, is\ndefining a masking function for allowing whether a standby\ntour in active tours is allowed to take customers. A standby\ntour can turn into an initiated tour if the summation of the\nnumber of initiated tours and inactive tours is less than $l_{max}$."}, {"title": "Masking function for deactivating an active tour:", "content": "The\nsecond step to satisfy the optimal maximum number of tour\nconstraint, is defining a masking function for deactivating an\ninitiated tour. This function determines whether a tour $ \\phi_i$\nwith a total remaining capacity of $0 < C_i <= C$ can be\ndeactivated by selecting the depot node as the next stop. To\ncreate a flexible masking function, we define a threshold at\ndecoding iteration t named $T_t$. This threshold will be used in\nEquation 25 to determine whether a tour should be deactivated\nor remain active. Let $\\omega_{\\phi_i}$ denote an inactive tour with its unused\ncapacity defined as wasted capacity $w_{\\omega_\\phi_i}$. Then, given the set of\nall inactive tours to iteration $t - 1$ ($L^{(t-1)}$), the total capacity\nthat can be wasted at step t is calculated as follow:\n$q_t = l_{max} * C - \\sum_{n=0}^{N_t} \\delta_i - \\sum_{\\Phi \\in L^{(t-1)}} w_{\\omega_\\phi}$  (9)\nSo, the threshold $\\tau$ at iteration t can be defined as:\n$\\tau_t = \\frac{q_t}{l_{max} - | L^{(t-1)} | }$  (10)"}, {"title": "B. Encoder", "content": "The encoder follows the architecture presented by Kool et\nal. [25] and transforms customers and depots (call it nodes\nwhen we refer to both customers and depots) input $I_i$ into a\nhidden embedding $h_i$. The input of each customer i comprises\nits coordinates ($x_i, Y_i$) and its associated demand $d_i$ while\nthe value of demand for depots is zero. However, unlike\nKool et al [25], we transform the node coordinates into polar\ncoordinates with respect to the first depot ($x_0, y_0$). Polar\ncoordinates enhance the model's generalizability by making\nthe representation invariant to spatial transformations such as\nshifts, rotations, and scaling, enabling the model to capture the\nrelative positioning and angular relationships between nodes\nrather than relying on their absolute locations. Consequently,\nthe node attributes are represented by the relative Euclidean\ndistance and polar angle, as well as their demand.\n$I_i = \\{r_i, \\theta_i, d_i\\}$  (11)\nwhere,\n$r_i = \\sqrt{(x_i - x_0)^2 + (y_i - y_0)^2}$  (12)\nand,\n$\\theta_i = arctan2(y_i - y_0, x_i - x_0)$  (13)"}, {"title": "C. Decoder", "content": "Our proposed decoder model consists of two key layers:\nthe Vehicle Selection and Local Context Generation Layer\n(VSLCGL) and the Node Selection Layer (NSL). At each iter-\nation, the decoder is tasked with selecting a pair consisting of\nan active tour and a customer. The VSLCGL is responsible for\nidentifying the tour with the highest 'compatibility' (explained\nlater) with the unvisited neighbor customers and generating\nlocal context. This context assists the Node Selection Layer\nin choosing the next node for the selected tour, taking into\naccount the status of other ongoing tours."}, {"title": "Vehicle Selection and Local Context Generation Layer\n(VSLCGL):", "content": "Figure 2 illustrates the architecture of the pro-\nposed decoder, highlighting the Vehicle Selection and Local\nContext Generation Layer (VSLCGL). At each iteration, we\nidentify the k nearest nodes, denoted as \u03b6, relative to the last\ncustomer added to each active tour. This approach aligns with\nfindings that optimal actions in VRP are often concentrated\namong local neighbors [12]. Then, the embeddings corre-\nsponding to these nodes in \u03b6, are extracted from the encoder's\noutput and serve as queries within the multi-query, multi-head\nattention mechanism, as follows:\n$q_i = W_{Q1}h_i, \\forall i \\in \\zeta$  (14)\nThe keys and values are derived from the state of each active\ntour as follows:\n$h_{\\phi_j} = [h_{0_\\phi}, h_{l_\\phi}, C_\\phi]$  (15)\nand,\n$k_j = W_{K1}h_{\\phi_j}, v_j = W_V h_{\\phi_j}$  (16)\nHere $[.,.,.]$ is the horizontal concatenation operator where\n$h_{0_\\phi}$ represents the embedding of the depot of the tour $\\phi$, $h_l$\ndenotes the embedding of the last added node to the tour, and\n$C_\\phi$ indicates the remaining capacity of the vehicle undertaking\nthe tour. The queries, keys, and values are defined as follows:\nThe local context is then calculated as:\n$X_i = softmax(\\frac{q_ik^T}{\\sqrt{dim k_j}})v_j$  (17)\nThe local context plays a vital role in guiding the NSL to\nprioritize nodes with a higher probability for a selected tour.\nIt provides detailed information about the compatibility of\neach node with all active tours, ensuring that the model avoids\nassigning nodes to a tour where they would be better suited\nfor another one. This strategic approach helps the model make\nmore efficient decisions by optimizing the assignment of nodes\nto tours, thereby improving overall routing efficiency and\nachieving a globally optimal solution.\nIn the final step, a multi-query single-head attention mecha-\nnism generates the unnormalized log-probabilities (logits) for\neach pair of tours and neighbor nodes. The query and key for\ngenerating logits is defined as:\n$q_i = W_{Q2} X_i, v_j = W_{K2}h_j$  (18)\nAfter applying a max pooling layer, the logits for each tour\nare computed and clipped to the range [-A, A] (with A = 10)\nusing tanh function. The tour with the highest probability is\nselected as the candidate tour to pick the next node.\n$\\delta =\\begin{cases}A.tanh(Max(\\frac{q_i v_j^T}{\\sqrt{dim_i}})), & \\text{if tour is active} \\\\\\- \\infty, & \\text{Otherwise}\\end{cases}$  (19)\nand,\n$\\phi = argmax(\\delta)$  (20)"}, {"title": "Node Selection Layer (NSL):", "content": "Given \u03c6 as the selected tour\nand $X_i$ as the generated local context from the VSLCGL,\nwe apply attention mechanism to select the next node within\nthe specified tour. The input embedding $h_i$ for this process\nconsists of the tour depot's embedding and the updated node\nembeddings, which incorporate the local context. For non-\ndepot nodes, each embedding is enriched by combining their\nlocal context with their individual embeddings, effectively\nencoding the status of all active tours within each node's\nrepresentation. This strategy enables the model to account for\nthe current status of all active tours when selecting the next\nnode for a given tour, ensuring that the decision process is\ninformed by the broader tour dynamics. So, the embedding $h_i$\nis defined as follows:\n$h_i=\\begin{cases}h_{0_{\\phi}}, & i=0 \\\\ h_i + X_i, & i \\in S_k \\\\ h_i, & \\text{Otherwise}\\end{cases}$  (21)\nThe query of the attention mechanism in NSL is defined as:\n$q = W_{Q3} [h_{all}, h_{0_\\phi}, h_{l_\\phi}, C_\\phi]$  (22)\nHere [.,.,.,.] is the horizontal concatenation operator\nwhere $h_e$ is the average value of the hidden embeddings of\nall nodes that are not previously visited, $h_{0}$ is the depot node\nfor this tour, $h_{l_\\phi}$ is the last added node to tour \u03c6, and $C_\\phi$ shows\nthe remaining capacity for tour \u03c6. Then, the key and value of\nthe ith node is defined as:\n$k_i = W_{K3}h_i, v_i = W_{V2}h_i$  (23)\nand now we compute the compatibility of the query with all\nnodes as follows:\n$\\mu_i = softmax(\\frac{qk^T}{\\sqrt{dimk}})v_i$  (24)\nTo compute the output probabilities for visiting each node,\nwe employ a final layer with a single attention head. In\nthis layer, \u03bci serves as the query and $h_i$ as the key. The\ncompatibility scores are calculated and then clipped within\nthe range [-A, A] (with A =10) using the tanh function.\nNow, we apply a masking function to enforce the threshold\ncondition outlined in Equation 10 while also handling visited\nnodes. The log-probabilities of selecting the depot as the\nnext node, which would deactivate an initiated tour, is set to\nzero if the tour's current used capacity is below a defined\nthreshold $T_t$ by Equation 10 for iteration t. If the tour's\ncurrent capacity exceeds this threshold, the selection of the\ndepot becomes conditional on the model's preference. This is\nformally represented as follows:\n$\\mu =\\begin{cases}\\mu_0, & \\text{if i = 0 & } C > T_t, \\\\\\mu_i, & \\text{if i $\\neq$ 0 & i is not visited,} \\\\\\ - \\infty, & \\text{Otherwise}\\end{cases}$  (25)\nand finally, the probabilities are defined as:\n$p_i = p_\\theta(\\pi_t = I_i|S_t) = softmax(\\mu)$  (26)"}, {"title": "D. Training algorithm", "content": "We adopt the policy gradient with rollout baseline [25", "L(\\pi)": "and we optimize it using REINFORCE algo-\nrithm to estimate policy gradient as follow:\n$\\nabla L(\\theta|s) = E_{p_\\theta(\\pi|s)} [(L(\\pi) - b(s))\\nabla log p_\\theta(\\pi|s)", "25": "to approximate the minimum\nlength of each tour [11"}, {"25": "in both training and inference\nphases to determine the minimum travel distances for each\ntour. Our experiments reveal that while the AM, trained on a\nuniform distribution, delivers near-optimal solutions for small-\nscale MDVRP instances, its performance declines as the size\nof the MDVRP increases a limitation also evident in the\nresults presented by Hou et al. [11"}]}