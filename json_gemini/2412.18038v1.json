{"title": "AA-SGAN: Adversarially Augmented Social GAN with Synthetic Data", "authors": ["Mirko Zaffaroni", "Federico Signoretta", "Marco Grangetto", "Attilio Fiandrotti"], "abstract": "Accurately predicting pedestrian trajectories is crucial in applications such as autonomous driving or service robotics, to name a few. Deep generative models achieve top performance in this task, assuming enough labelled trajectories are available for training. To this end, large amounts of synthetically generated, labelled trajectories exist (e.g., generated by video games). However, such trajectories are not meant to represent pedestrian motion realistically and are ineffective at training a predictive model. We propose a method and an architecture to augment synthetic trajectories at training time and with an adversarial approach. We show that trajectory augmentation at training time unleashes significant gains when a state-of-the-art generative model is evaluated over real-world trajectories. Our source code and trained models are publicly available at: https://github.com/mirkozaff/aa-sgan", "sections": [{"title": "Introduction", "content": "Predicting pedestrian trajectories is of paramount importance in applications where robots must dodge humans, e.g., to avoid collisions. This task is inherently challenging due to the complexity and to some extent unpredictability of human movement patterns. In detail, the task has three main technical challenges. First, given a partial trajectory, multiple options for its continuation are possible, making the problem intrinsically multivariate; second, an individual's motion is conditioned by bystanders' behaviours, especially in crowded spaces; finally, different social and cultural contexts may constrain what can be considered a plausible motion pattern.\nRecently, deep generative models showed promising results in plausible human motion prediction. For example, Social GAN [7] trains a trajectories Generator using an adversarial approach where ad-hoc architectural elements and loss terms promote trajectories that are socially plausible. This model is trained on pedestrian trajectories extracted from crowds footages from different environments [12, 17]; in Fig. 1a sample trajectories extracted from a set of tracked pedestrians in a video scene are shown. However, such datasets exhibit limitations such as no camera settings variability and yield comparatively few trajectories if compared to the capacity of some deep models. While collecting more videos to enlarge the training set may bring benefits, data collection and annotation is a daunting, time-consuming, activity. Also, releasing datasets of real footage poses some privacy-related issues.\nSynthetic training allows for large training sets without the burden of manually collecting and labelling the samples. For example, the Joint Track Auto Dataset (JTA) [5]"}, {"title": "Background and Related Works", "content": "In this section, we present the background relevant to the understanding of this work. Namely, we discuss existing approaches to pedestrian path prediction and the datasets most commonly used for this task."}, {"title": "Trajectory Prediction Methods", "content": "Over the years, pedestrian trajectory prediction has been the subject of many endeavors [10]. Early attempts tried to model this complex task with models borrowed from classic Physics [8,9,16]. Recently, however, learning-based models have outperformed such early approaches and represent the state of the art in the field. Therefore, our literature review will be limited to learning-based approaches. While some based methods rely on multimodal inputs (e.g., video beside trajectories) to boost performance, the present work relies on unimodal trajectories-based inputs. Our review will also be constrained to such cases.\nGiven the sequential nature of predicting a future trajectory based on past observations, Recurrent Neural Networks (RNNs) based methods were among the first to yield promising results among learning-based methods. Namely, [1] proposes to rely on Long Short Term Memory (LSTM) RNNs enhanced by an ad-hoc social pooling layer. This layer models the interactions between nearby pedestrians and is responsible for guaranteeing that the predicted trajectories are also plausible from a social perspective (e.g., paths should not interfere at the same time, social conventions such as keeping the right way should be respected, etc.). Although modern architectures tend to outperform the aforementioned one, some of its key concepts have been borrowed and utilized in subsequent adversarial learning-based approaches.\nSocial GAN (shortly, SGAN) [7] approaches trajectory prediction with an adversarial approach [6]. Figure 2 shows the internals of the SGAN: the Generator receives in input the first 8 steps (observed trajectory, \"obs\") of a 20 steps long pedestrian trajectory and predicts the next 12 steps (predicted trajectory, \"pred\") of the sequence. Within the Generator, both the encoder and the decoder are implemented as recurrent LSTM networks, connected by a social pooling layer. The Discriminator receives in input the 12 steps sequence output by the Generator and the corresponding ground truth sub-sequence of the same length. SGAN is trained with an adversarial approach where the Generator learns to produce real-looking path traces, whereas the Discriminator learns to tell generated from real trajectories. The architecture is trained to minimize a novel variety loss that encourages diversity among generated predictions. Other works using GAN [18] or synthetic data have been proposed [13, 14]. However, these also integrate visual information into their decision pipeline. We will not deal with these"}, {"title": "Real-World Datasets", "content": "Common datasets used for pedestrian trajectory prediction include ETH [17], and UCY [12]. These datasets consist of trajectories extracted from surveillance camera videos and annotated every 0.4 seconds. Each dataset includes multiple trajectories and each trajectory includes multiple pedestrians. Each dataset sample includes a temporal index and, for each pedestrian, the pedestrian's identification code and its position in an (x,y)-plane. The ETH dataset includes two different environments called biwi_eth and biwi_hotel, whereas the UCY dataset includes five different environments called crowds_zara01, crowds_zara02, crowds_zara03, students001, students003 and uni_examples. These datasets include a total of 2,205 frames and 6,441 pedestrians. These datasets include crowded environments with challenging scenarios such as group behaviour, people crossing each other, avoiding collisions, and groups forming and dispersing. Therefore, these datasets are commonly employed for researching pedestrian trajectory prediction."}, {"title": "Data augmentation and synthetic datasets", "content": "Classical data augmentation, which is based on the generation of additional data, has become quite standard for visual data where manually designed transformations, e.g. crop, colour jitter, rotation, etc., can be applied to images in order to increase the variability in acquisition settings, thus promoting better generalization on real data. GANs have recently attracted lots of attention in order to overcome the limits of manual augmentation through the direct synthesis of new images. Nonetheless, GAN models need to be trained on real data as well, thus limiting their applicability in many cases. Other works have focused on automating data augmentation policies: see as an example [19] and reference therein."}, {"title": "Proposed Method", "content": "In this section, we describe our proposed approach towards learning to predict pedestrian trajectories from both real and augmented synthetic trajectories."}, {"title": "Problem definition", "content": "Let us define a pedestrian trajectory as a sequence of $t_{pred}$ samples in the temporal order. Each sample is a pair of coordinates in space, where each element $(x_t, y_t)^{(i)}$ ($i = \\{1, ..., N\\}$) represents the position of the i-th pedestrian at time-instant $t \\in [1, t_{pred}]$. We have that $t = \\{1, ..., t_{obs}, t_{obs} + 1,..., t_{pred}\\}$, where $t = t_{obs}$ is the number of observed samples and $(t_{pred} \u2013 t_{obs})$ is the number of following samples to be predicted. As a common practice in the related literature, all the trajectory coordinates are preliminarily normalized to relative coordinates with respect to the starting point."}, {"title": "Architecture", "content": "Our proposed AA-SGAN architecture is shown in Fig. 3. As for [7], real trajectories r are fed as input to a Generator G, whose task is to predict the future samples. The Generator receives as input the first $t_{obs}$ samples of a trajectory and predicts the next $(t_{pred} - t_{obs})$ samples. However, in the proposed architecture, the Generator receives in input also synth-augmented trajectories a. Synth-augmented trajectories are generated by"}, {"title": "Training Procedure", "content": "The above-mentioned is trained end-to-end with an adversarial approach [6].\nThe Discriminator is trained with the following loss function:\n$L_D = E[log(D(r)) + log(1 \u2013 D(a))+\nlog(1 - D(\\hat{r})) + log(1 \u2013 D(\\tilde{a}))]$ \nwith the aim of maximizing the average of the log probability of real trajectories r and the log of the inverse probability for synth-augmented a, Generator-predicted real $\\hat{r}$ and Generator-predicted synth-augmented $\\tilde{a}$ trajectories.\nConcerning the Augmenter, an L2-loss is computed between s and a overall $t_{pred}$ samples, as proposed in [7]. Thus, the Augmenter is trained to minimize the loss:\n$L_A = E[log(D(a)) + L2(s,a)]$\nIndeed, it may seem counterintuitive to introduce an L2-loss term when training the Augmenter (we want to make these trajectories different, not identical). However, we observed that, in combination with the Discriminator loss, this yields trajectories that are more useful to train the Generator\nFinally, concerning the Generator, two L2-losses are computed between $\\hat{r}$ and r and between $\\tilde{a}$ and a. However, the Generator shall be obviously trained only over the $t_{pred} - t_{obs}$ predicted samples. Thus, the Generator is trained to minimize the loss\n$L_G = E[log(D(r)) + L2(r_{pred}, \\hat{r}_{pred})+\nlog(D(a)) + L2(a_{pred}, \\tilde{a}_{pred})]$\nThe above described architecture is trained with the classical GAN training procedure, yet extended to the Augmenter. As a first step, the Discriminator D is first optimised over a real trajectory r, then over the Generator-predicted trajectory $\\hat{r}$, next over synth-augmented trajectory a and finally over the Generator-predicted synth-augmented trajectory $\\tilde{a}$. As a second step, the Generator G is optimised first over real trajectories r and then over the synthesised trajectories. As a final step, the Augmenter A is optimised through the synthetic trajectoriess."}, {"title": "Experimental results", "content": "In this section, we evaluate the performance of our AA-SGAN architecture on the two publicly available real datasets ETH and UCY introduced in Sect. 2.2."}, {"title": "Path Prediction Accuracy", "content": "Table 1 shows the trajectory prediction accuracy obtained by our proposed AA-SGAN scheme and the three baselines SGAN schemes. The AA-SGAN scheme refers to the proposed architecture trained as described above. The three baseline schemes refer to a standard SGAN trained, in turn, as follows. The real scheme corresponds to the setup [7], where an SGAN is trained over real trajectories from UCY and ETH. The synthetic scheme corresponds to the case where an SGAN is trained only over synthetic trajectories from JTA. Finally, hybrid refers to the case where SGAN is trained over a 50-50 mix of real and synthetic trajectories from JTA (the size of this hybrid dataset is twice that of the former two). Notice that this mix of real and synthetic trajectories is the same provided in input to our AA-SGAN scheme, as discussed later on. The four schemes share the same training hyper-parameters and configuration suggested in [7].\nThe results for the real scheme reflect those reported in [7], apart from some minor differences on the zaral and zara2. Please also note that all the results reported in the following are averaged on 3 trials (corresponding standard deviation is shown as well).\nAs expected, performance drops when SGAN is trained over synthetic data only. This performance loss shows that JTA synthetic trajectories are so simple that they are not useful to train an SGAN. As an example, on the ETH test, the value for ADE increases from 0.85 up to 1.28 when training on synthetic trajectories only. The hybrid column in Tab. 1 shows that accuracy does not improve over the real scheme. For the ETH experiment, we even report ADE equal to 0.93 which is significantly worse than real. These preliminary experiments show that synthetic trajectories cannot replace real ones at training times nor do they bring any benefit if mixed with them.\nThe last column shows that the proposed AA-SGAN method yields much better accuracy in all cases, both in terms of ADE (20% reduction from 0.6 to 0.48) and FDE (25% reduction from 1.24 to 0.93). We recall that the AA-SGAN scheme is trained over the same mix of real and synthetic trajectories used for the hybrid scheme. Such difference in accuracy despite the same training set can be brought down to the job performed by the Augmenter, which makes synthetic trajectories eventually useful for training. In the AA-SGAN scheme, we used a 50-50 ratio of real and synthetic trajectories: this is a reasonable choice as the Augmenter and Generator are fed with a balanced mix.\nIn the following ablation study, we will discuss whether it is useful to alter such a real-synthetic ratio and to what extent.\nFigure 5 illustrates some trajectories predicted by the four schemes in Table 1. The synth scheme predicted trajectories are the worst, diverging the most from the ground truth other than being not acceptable due to collisions (see Fig 5b). On the contrary, the results of the AA-SGAN scheme are the closest to the ground truth."}, {"title": "Ablation Study", "content": "Before moving further with the experiments, we recall that the experiments with schemes real, synthetic and hybrid in Tab. 1 above can be already interpreted as an ablation study. In fact, the standard SGAN architecture trained over a hybrid dataset can be seen as equivalent to AA-SGAN minus the Augmenter, where synthetic trajectories are fed directly into the Generator."}, {"title": "Independent Augmenter training", "content": "In this first ablation experiment, we investigate the advantage of jointly training the Augmenter A and the Generator G in an adversarial framework. We recall that in our architecture, G and A are jointly optimized over the gradient of the adversarial loss function backpropagated by the Discriminator D. In order to investigate on this advantage, we removed G from the AA-SGAN architecture and we train the resulting GAN, between A and D, using their corresponding losses. As a consequence, in this ablated architecture the Augmenter will create synth-augmented trajectories without any feedback from G, i.e. without being able to appreciate their contribution to solving the prediction task; the obtained synth-augmented are stored offline for the subsequent training. Next, these trajectories are used to train a reference SGAN as in the hybrid scheme (50% real and 50% synth-augmented trajectories). G and D are trained according to the same adversary loss functions described in the previous section.\nTab. 2 compares the results of this scheme with AA-SGAN. Performance is still above the real baseline, however, it is well below AA-SGAN. This experiment confirms the importance of jointly training the Augmenter A with the rest of the architecture."}, {"title": "Synthetic to real ratio", "content": "Another aspect worth being investigated is the ratio between the real and the synthetic trajectories used to train AA-SGAN. Tab. 3 shows the prediction accuracy when the synthetic trajectories increase by a 10-fold factor (the number of real trajectories remains constant). On average, a drop of about 10% in ADE and FDE is observed, showing the importance of balancing real and synthetic trajectories. We hypothesize that this predominance of synthetic traces makes adversarial training less stable, explaining the performance drop."}, {"title": "Conclusions", "content": "This work proposed AA-SGAN, a generative architecture for predicting accurate pedestrian trajectories leveraging synthetic trajectories beside real ones. We experimentally showed that computer-generated synthetic trajectories bring no benefit when used to train the state-of-the-art SGAN generative model. However, if synthetic trajectories are first augmented before being fed to the Generator (synth-augmented trajectories), they boost the diversity of the training set, improving the accuracy of the predictions. Through an ablation study, we show that joint training of the Augmenter with the rest of the architecture is the first key element towards accurate trajectory predictions. Through ablation, we also show that a balanced ratio between real and synthetic trajectories is another key element of our architecture."}]}