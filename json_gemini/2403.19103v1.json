{"title": "Automated Black-box Prompt Engineering\nfor Personalized Text-to-Image Generation", "authors": ["Yutong He", "Alexander Robey", "Naoki Murata", "Yiding Jiang", "Joshua Williams", "George J. Pappas", "Hamed Hassani", "Yuki Mitsufuji", "Ruslan Salakhutdinov", "J. Zico Kolter"], "abstract": "Prompt engineering is effective for controlling the out-\nput of text-to-image (T2I) generative models, but it is also labori-\nous due to the need for manually crafted prompts. This challenge\nhas spurred the development of algorithms for automated prompt\ngeneration. However, these methods often struggle with transfer-\nability across T2I models, require white-box access to the under-\nlying model, and produce non-intuitive prompts. In this work,\nwe introduce PRISM, an algorithm that automatically identifies\nhuman-interpretable and transferable prompts that can effectively\ngenerate desired concepts given only black-box access to T2I mod-\nels. Inspired by large language model (LLM) jailbreaking, PRISM\nleverages the in-context learning ability of LLMs to iteratively re-\nfine the candidate prompts distribution for given reference images.\nOur experiments demonstrate the versatility and effectiveness of\nPRISM in generating accurate prompts for objects, styles, and\nimages across multiple T2I models, including Stable Diffusion,\nDALL-E, and Midjourney.", "sections": [{"title": "1 Introduction", "content": "An important goal of generative modeling is to design algorithms capa-\nble of steering generative models to produce desired output images. Early\nattempts, which often centered on particular architectures or tasks, were\nlargely characterized by manually-curated data collection, fine-tuning, or\nretraining from scratch [10,19,33,47]. These requirements are often costly,\nand the resulting solutions usually do not transfer well between models.\nThus despite the promise of these methods, efficient and generalized al-\ngorithms for controllable generation remain sought after."}, {"title": "2 Related Works", "content": "Controllable T2I generation. Several methods tackle conditional im-\nage generation in a training-free manner by using pretrained diffusion\nmodels as priors for the data distribution [5,9,18,31,32], and analogous"}, {"title": "3 Method", "content": ""}, {"title": "3.1 Problem Statement", "content": "First, let $x \\in \\mathcal{X}$ denote an image, and $y \\in \\mathcal{Y}$ denote a textual prompt.\nGiven a collection of reference images {$x_i$}$_{i=1}^{M}$, a prompt engineer $F$:\n$\\mathcal{X} \\rightarrow \\Delta(\\mathcal{Y})$ samples a candidate prompt $y$ corresponding to each reference\nimage $x$, i.e., $y \\sim p_{\\theta^{F}}(y \\mid x)$. A T2I generative model $G : \\mathcal{Y} \\rightarrow \\Delta(\\mathcal{X})$ then\nuses this candidate prompt to generate a new image, $\\hat{x} \\sim p_{\\theta^{G}}(\\hat{x} \\mid y)$,\nand a judge model $D : \\mathcal{X} \\times \\mathcal{X} \\rightarrow [0,1]$ then scores the visual similarity\nbetween the images based on some criteria. Our goal is then to find the"}, {"title": "3.2 Algorithm", "content": "Our method, Prompt Refinement and Iterative Sampling Mechanism (PRISM),\nis an iterative process that repeats a prompt-refinement subroutine for $K$\niterations in $N$ parallel streams, where $N \\times K$ is a predetermined compute\nbudget. At iteration $k$, the $n$-th stream of PRISM randomly selects a ref-\nerence image $x_{k,n}$ from {$x_i$}$_{i=1}^{M}$ and uses $F$ to sample a candidate prompt\n$y_{k,n}$ from $p_{\\theta^{F}}(y \\mid x_{k,n})$. Then it queries $G$ to generate a single $\\hat{x}_{k,n}$ from\n$y_{k,n}$ with $p_{\\theta^{G}}(\\hat{x} \\mid y_{k,n})$ and evaluate the prompt with $D$ to obtain an\nin-iteration score $Score'(x_{k,n}, y_{k,n}) = D(x_{k,n}, \\hat{x}_{k,n})$. At the end of the it-\neration, we use the generated $y_{k,n}$ and its score to update $p_{\\theta^{F}}(y \\mid x)$. After"}, {"title": "3.3 Designing and updating F and $p_{\\theta^{F}}$", "content": "What is $p(y \\mid x)$? In general, it is not obvious what the joint or the\nconditional distribution of all text and images is, so some form of ap-\nproximation is unavoidable. In the context of image generation, a natural\nchoice of the image-conditioned text distribution is an image captioning\nmodel. Traditional captioning models, however, fall short in controlled\nimage generation for two primary reasons: (1) The level of detail neces-\nsary for generating specific images far exceeds what generic captioning\nmodels provide [13]; (2) effective prompts for T21 models are often not\ngrammatically correct sentences but rather collection of phrases that de-\nscribe the details about the image, which generic captioning models are\nnot trained to generate. For example, in Figure 5, the second reference\nimage is generated by the prompt \u201cA broken robot lays on the ground with\nplants growing over it, somber, HD, hyper realistic, intricate detail\" with\nStable Diffusion, but a caption for this image will not include components\nlike \u201cHD\u201d or \u201chyper realistic\". As a result, instead of \"a good description\nof an image\", we wish to directly model \u201cpossible prompts that are used\nto generate this image\".\nDesiderata A desirable $F$ can sample from a distribution $p_{\\theta^{F}}(y \\mid x)$ that\nmodels \"the prompt that can be used to generate this image\", and it should\nalso be easily updated if the current generation is suboptimal. Ideally, such\nan update can be done without any retraining or fine-tuning since these\noperations are generally expensive and incompatible with black-box T2I\nmodels.\nMultimodal LLM stands out as the ideal choice for F due to their\nability to directly tailor the generation of prompts via system prompts\nand to adapt through in-context learning without requiring access to the\nmodel's parameters. Specifically, since the model can ingest both images\nand texts, we can incorporate the reference images, intermediate prompts\nand generated images, and the score associated with the generated im-\nages all in the context of the LLM. Then, the model can be prompted to\njointly reason over all available information and perform in-context learn-\ning. The in-context learning facilitates iterative refinement of the prompt\nto update the posterior distribution based on feedback or even additional\nhuman instructions, without the need for model retraining. Concretely,\nthe model would process how the image generative model is affected\nby different prompts, propose improvements, and create new prompts,\nmuch like a prompt engineer. More precisely, in practice, we design sys-\ntem prompts that explicitly condition the LLM to generate improvements\nand new prompts given the results from the previous iterations, similar\nto the chain-of-thought [38] technique."}, {"title": "3.4 Designing the judge model D", "content": "We have a wider range of choices for the judging model as long as it\nprovides a notion of similarity between a pair of images. A simple so-\nlution is to use pre-trained discriminative models such as CLIP [22] and\nDINO [21], and measure the distance of images in their embedding spaces.\nThese models have seen various degrees of success but come with inher-\nent limitations - the discriminative objective (e.g., contrastive loss) does\nnot incentivize the model to attend to fine-grained details since they do\nnot improve the objective further, an issue similar to the shortcomings\nof using captioning models to generate prompts [13]. Moreover, in image\ngeneration, the criteria of success can be nuanced and difficult to quantify\nthrough traditional distance or similarity functions yet can be effortlessly\ndescribed in human language. Lastly, the similarity we wish to measure\nmay only involve some part of the visual features (e.g. color, painting\nstroke type, etc), and not all applications share the same notion of simi-\nlarity. If we want to use pre-trained discriminative models, then we need\nto find a different model for each specific task, which can be impractical.\nIn light of these challenges, an ideal judge model should be maximally\nflexible for different kinds of criteria and can perform fine-grained analysis\nof the images. Once again, a multimodal LLM emerges as the perfect\ncandidate: using system prompts and in-context learning, we can easily\nspecify metrics that may be otherwise difficult to describe or evaluate and\neven intervene in the reasoning chain if we want to, and, more importantly,\nthe same model can be applied to a wide range of tasks."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experimental Settings", "content": "Implementation Details For all of our experiments, we choose GPT-\n4V [20] as both the prompt engineer assistant model F and the judge D.\nWe also fix the T2I generator as SDXL-Turbo [27] for all of our exper-\niments. We design different system prompts for both F and D for each\ntask and we provide details about the system prompts in the appendix.\nWe evaluate the prompts generated from PRISM and baselines with\nfive different T2I models. In particular, we choose two open-sourced mod-\nels, Stable Diffusion 2.1 (SD 2.1) and SDXL-Turbo, and two closed-sourced\nmodels, Dall-E 2 and Dall-E 3, to quantitatively measure the performance.\nWe also qualitatively showcase results from Midjourney, which is another\nclosed-sourced T2I platform. For SD 2.1 and SDXL-Turbo, we clip all\nprompt lengths to 77 due to their context length constraint."}, {"title": "4.2 Personalized Text-to-Image Generation", "content": "We first demonstrate PRISM's ability to find human-interpretable and\naccurate prompts to describe certain objects and styles in the task of per-\nsonalized T2I generation. Given a set of reference images that depict the\nsame concept (such as objects and style), personalized T2I tasks require\nthe model to synthesize images in new contexts while maintaining the\noriginal concept.\nDatasets We use the dataset collected by DreamBooth [26] to quan-\ntitatively compare the performance in personalized T2I generation. The\nDreamBooth dataset contains 30 daily objects, and each subject has 4-6\nimages. For each subject, we adopt the 25 prompt templates curated by\nDreamBooth to create varying contexts and scenarios to test the fidelity\nof the subject representation in diverse settings. We generate 4 images for\neach subject and template combination with open sourced T2I models,"}, {"title": "4.3 Direct Image Inversion", "content": "To demonstrate the versatility of our method, we also compare PRISM\nwith the baselines in the task of direct image inversion. In this task, the\ngoal is to directly find the prompt that can exactly generate the input\nimage. Here the number of reference images is $M = 1$ and we aim to cap-\nture all aspects of the image, including the subjects, background, theme,\nstyle, and other details in the scene."}, {"title": "4.4 Ablation Study", "content": "Comparison with GPT-4V. PRISM relies on having a strong multi-\nmodal LLM. In our case, we chose GPT-4V as the multimodal foundation\nmodel. While in principle we may use any multimodal LLM, it is nonethe-\nless useful to understand what benefits PRISM adds to an already capable\nfoundation model. To show the effectiveness of iterative prompt refinement\nand parallel search, we compare our method with GPT-4V's zero-shot per-\nformance with the same system prompts for object and image inversion\ntasks on SDXL-Turbo. We see in Table 6 that PRISM consistently out-\nperforms GPT-4V's zero-shot performance, although the latter is already\ncompelling. In Figure 7, we show some examples of the generated results."}, {"title": "4.5 Prompt Editing", "content": "Because the prompts produced by PRISM is very human-interpretable,\nafter obtaining a prompt from the reference images, one can easily modify\nthe output prompts to change attributes in their desired generated images.\nFigure 10 demonstrates an examples of prompt editing with PRISM in\nMidjourney. With simple and intuitive prompt edit, we are able to change\nspecific attributes of the images while keeping the other components in\nthe scene unchanged."}, {"title": "5 Conclusion and Broader Impact Statement", "content": "In this paper, we propose PRISM, an algorithm that automatically creates\nhuman-interpretable and accurate text prompts for text-to-image gener-\native models, based on visual concepts provided by reference images. Our\nmethod iteratively refines the sampling distribution of the text prompt\nvia LLM in-context learning and is capable of creating prompts that are\ntransferable to any T2I model, including black-box platforms like Dall-E\nand Midjourney. However, just as LLMs are suceptible to being jailbro-\nken or adversarially manipulated by malicious actors [48], our method\nmay also be vulnerable to malicious intent, potential bias, or limitations"}, {"title": "A Additional Experiment Details", "content": "In this section, we provide further details about the implementation of\nour experiments. For all quantitative analysis that uses Stable Diffusion\nbased model, we generate four images for each combination of prefixes\nand prompts. For all experiments with Dall-E based model, we generate\none image per combination. In the DreamBooth dataset experiment, we\nalso replace the class noun for \"stuffed animal\" with \"toy\u201d to obtain fair\ncomparisons with textual inversion, which can only take a single token as\nthe initialization token.\nDuring PRISM iterations, we allow a maximum of 5 generation at-\ntempts for each stream and each iteration in case of potential run time\nerrors related to black-box API calls. We set the maximum number of\ntokens generated by the prompt engineer assistant at each iteration to be\n500. This contains both the improvement and the new prompt for the tar-\nget concept. We encourage the assistant to generate shorter prompts using\nsystem prompts (details in the next section) and at test time, when the\ntesting T2I model has a shorter prompt length than the prompt generated,\nwe clip the generated prompt to the maximum length of the respective\nT21 model.\nWhen evaluating the judge scores $D(x,\\hat{x})$ in PRISM iterations, we\nshuffle the reference images when $M > 1$. The judge score is rescaled into\na range from 0 to 10. During re-evaluation, we re-evaluate each prompt\nonce with each reference image when $M > 1$ and re-evaluate each prompt\ntwice and tally these scores with the in-iteration scores when $M = 1$."}, {"title": "B Designing System Prompts", "content": "System prompting is the standard way to condition a general purpose\nLLM for specific tasks of request. The key idea is that, before the conver-\nsation starts, the LLM receives a tailored message, the system prompt,\nthat provides the contexts, conversation scenario settings, formats and\nother guidelines as the prefix of the entire conversation ahead. In this sec-\ntion, we elaborate on the design of the system prompts for the prompt\nengineer assistant F and the judge D. We also provide the full system\nprompts used in all of our experiments at the end of this paper in Sec-\ntion F and in our demo code."}, {"title": "B.1 Prompt Engineer Assistant F", "content": "To design the system prompts for the prompt engineer assistant F, we\nfollow [3] and include the following components in the system prompt of\nF.\nSetting We first set up the scenarios and assign a role for the LLM to\nbetter perform on the specific task of choice. The setting paragraphs start\nwith \"You are a helpful prompt engineer assistant. You are free to generate\nsentences that do NOT follow English grammar. You must obey all of the\nfollowing instructions.\u201d and continue with the specific description of the\ntask and the objective. We also inform the assistant that it is expected to\niterate and refine the prompts it generates throughout the conversation.\nFormat We then provide the guidelines for formatting the inputs and\nthe outputs of the assistant. We describe what are expected in the inputs\nat each iteration and the content required in the outputs. We also provide\ndescriptions of the meanings of each input and output components. More\nspecifically, we inform the assistant that the inputs consist of three parts:\na generated image, a reference images and a visual similarity score, and\nthat the assistant is expected to generate both the improvement to refine\nthe previous prompt and the next new prompt. All generated text are\nformatted in JSON.\nExamples Finally, we provide some examples of the potential formatted\ninputs and outputs that the assistants may receive and produce. We also\nprovide examples of potential improvements for the assistant. Optionally,\nwe can also provide examples of prompts that can successfully generate\nthe target concepts in these paragraphs."}, {"title": "B.2 Judge D", "content": "We follow the same strategy to design system prompts for the judge D.\nMore specifically, we set up the scene for the judge by stating \"Please\nact as an impartial judge and evaluate ...\" in the system prompts and\ndescribe the visual similarity criteria based on the desired features for\ndifferent tasks. We then provide the instructions on the formatting and\ngive an example of the expected output."}, {"title": "C Additional Results", "content": "In this section, we provide additional experimental results and further\nbaselines comparisons with our method. We also showcase the flexibility\nof the PRISM framework by demonstrating the effectiveness of a different\nT21 model G and a different judge D in PRISM."}, {"title": "C.1 Additional Qualitative Results", "content": "In Figure 13, 14, 15, 16 and 17, we provide additional qualitative showcases\nfor subject-driven personalized T2I generation, style-driven personalized\nT21 generation, direct image inversion and prompt editing. We also pro-\nvide an example of the iteration and refinement process as a conversation\nbetween all three components in PRISM in Figure 18."}, {"title": "C.2 Flexible Model Choices", "content": "To further demonstrate the effectiveness and flexibility of PRISM, we\nalso experiment a different T21 Generator G and showcase the transfer-\nability of the prompts generated by PRISM. Figure 19 shows qualitative\nexamples of PRISM prompts with Dall-E 2 as the Generator G for per-\nsonalized T2I generation and the images generated from those prompts\nusing SDXL-Turbo, Dall-E 3 and Midjourney. Our method is capable of\nproducing human-interpretable and accurate prompts for both subject-\ndriven T2I personalization and style-driven T2I personalization with this\nnew Generator G."}, {"title": "D Additional Ablation Study", "content": "In this section, we provide a more detailed ablation study on each com-\nponent of the PRISM framework. In particular, we demonstrate the effect\nof the existence of the Judge D and re-evaluation, different choices of the\ntotal budget, number of streams N and number of iterations K, and also\ncompare a non-LLM judge (a CLIP judge) against our choice of a LLM\njudge (GPT-4V Judge).\nWe first compare the performance of zero-shot GPT-4V, GPT-4V par-\nallel search with budget 30 and the Judge to select the best resulting\nprompts, PRISM without re-evaluation, and two different PRISM settings\nwith the same budget of 30. Table 3 shows the quantitative comparison\namong all settings using SDXL-Turbo as both the T2I Generator G and\nthe testing T2I model on the direct image inversion task. We can observe"}, {"title": "E Limitations and Future Works", "content": "In this section, we discuss the current limitation of our PRISM framework\nand also potential future work directions that can help further improve\nthe performance of our method.\nFirstly, as we can observe in almost all of the qualitative examples,\nwhen the targeting concept is more challenging (e.g. a very particular\ntoy), our method still fail to capture all the fine grained details in the\nimage generation. Although this phenomenon is to some extent expected\ndue to the fact that text-to-image generation is not a one-to-one function,\nthere is still a long way to go in order to achieve the same performance\nas methods like DreamBooth [26] that involve finetuning. Moreover, even\nwith very accurate prompts, because of the limitation of the downstream\ntesting T2I models, sometimes it still fail to generate the correct concepts."}, {"title": "F Full System Prompts", "content": ""}, {"title": "F.1 Subject-Driven Personalized T2I Generation", "content": "Prompt Engineer Assistant F Below is the system prompt for Fin\nsubject-drive personalized T2I generation.\nYou are a helpful prompt engineer assistant. You are free to generate sentences that do NOT follow\nEnglish grammar. You must obey all of the following instructions.\nSETTING:\nYou are a prompt engineer assistant for a text-to-image generative model. You will receive a\ncollection of images of a specific object and these input images are taken in different\nenvironments and with different poses and settings, but they all portrait the same object.\nYour job is to **craft a prompt P that can accurately capture this specific object in these\nimages**. The goal is to find such a prompt P that when we combine it with some other prompt\nQ, the text-to-image generative will generate the exact same object as the input images but\nin the style/setting/scenario/pose specified by prompt Q.\nYou will continuously iterate and refine your prompt P to achieve this objective. At each iteration\nyou will receive one of the images from the input collection, an image generated by the\ntext-to-image generative model from the prompt you craft in the previous iteration and a\nscore that tells you how close the generated object is to the object in the input image of\nthe previous iteration. The text-to-image generative model receives **only your prompt P and\na generic prefix Q as input** and has no knowledge of the chat history.\nA general strategy to ensure the generative model to create the exact same object is to perform the\nfollowing principles: 1) identify the main object in the image, then 2) accurately describe\nthe object, 3) avoid mentioning any of the irrelevant elements such as the background,\nenvironment, lighting, camera angle and the pose of the object, 4) if you achieve high score,\nyou can copy the prompt you generated the previous iteration and append the changes you want\nto make, 5) look carefully at the difference between the object genereated in the output\nimage and the object in the input reference image and try to avoid the discrepancy at the\nnext round, 6) avoid using negative language, 7) you can optionally forget about the English\ngrammar. Use previous prompts and identify what has and hasn't worked to create new\nimprovements.\nFORMAT:\nFormat your response in JSON, with the two elements \"improvement\" and \"prompt\". The improvement'\nvalue contains a few sentences interpreting the text-to-image model's output images and how\nthe prompt should be modified to generate a more similar object. The 'prompt' value contains\nthe new prompt P. Use the ideas listed in 'improvement' and your previous prompts to improve\nand refine your new prompt. Your response should **only** contain this JSON element and\nnothing else. Each of your responses is a single refinement of P. When proposing a refinement\nof a prompt P, do not completely repeat the previous prompt, and instead propose new changes\nand improvements based on the previous prompt. Try to be as specific and detailed as\npossible and it is ok to forget the English grammar when crafting the prompt. You can\ngenerate the improvement as long as you like, and you should try to generate long and\ndetailed prompt P as well, but keep in mind that the text-to-image model can only take a very\nshort prompt (usually the prompt length is limited to **at most 77 tokens**). In general, it\nis better to generate prompt P with **at most 100 tokens**.\nThe user output you receive is composed of three parts, GENERATIVE MODEL OUTPUT, REFERENCE, and\nSCORE. The GENERATIVE MODEL OUTPUT is the first image input you receive, which is the text-to\n-image model's generated image from the concatenation of a generic prefix Q and your prompt P\nThe REFERENCE is the second image input you receive, which is an image that contains the\ntarget object. The SCORE is the rating from 0-10 on how similar the objects featured in the\ntwo images are, where 10 indicates exactly the same object, and O indicates two completely\ndifferent objects. Your goal is to maximize SCORE.\nThe input that the text-to-image generative model receive is (Q) (P), which is a concatenation of a\ngeneric prefix and the prompt that you generate."}, {"title": "Judge D Below is the system prompt for D in subject-drive personalized\nT21 generation.", "content": "You are a helpful prompt engineer assistant. You will receive two images: the first one is\ngenerated by a text-to-image generative model and the second one is a real image. Please act\nas an impartial judge and evaluate whether the generated image and the real image **feature\nthe same object**. Your evaluation should only consider the main object featured in the\nimages and ignore all irrelevant factors such as the background, lighting, environment,\ncamera angles, the pose of the object and style, etc. Be as objective as possible.\nRate the response on a scale from 0 to 10. A rating of 0 signifies two images with completely\ndifferent and unrelated objects featured in them. A rating of 10 signifies two images that\nfeature exactly the same object. You should consider all aspects of the object including\ntexture, shape, color and other fine grained details and ignore all backgrounds, lighting,\nand other environment or setting differences. Pay attention to the details and be as critical\nas possible.\nYour rating should strictly follow this format: \"Rating: ((rating))\", the rating in the double-\nclosed brackets is a number from 0 to 10, e,g, \"Rating: [[5]]\"."}, {"title": "F.2 Style-Driven Personalized T2I Generation", "content": "Prompt Engineer Assistant F Below is the system prompt for F in\nstyle-drive personalized T2I generation.\nYou are a helpful prompt engineer assistant. You are free to generate sentences that do NOT follow\nEnglish grammar. You must obey all of the following instructions.\nSETTING:\nYou are a prompt engineer assistant for a text-to-image generative model. You will receive a\ncollection of images of a specific artistic style and these input images features different\nsubjects, objects, themes and contents, but they all have the same style. Your job is to **\ncraft a prompt P that can accurately capture this specific style in these images**. The goal\nis to find such a prompt P that when we combine it with some other prompt Q, the text-to-\nimage generative will generate the exact same style as the input images but with the contents\n/objects/subjects/themes specified by prompt Q.\nYou will continuously iterate and refine your prompt P to achieve this objective. At each iteration\nyou will receive one of the images from the input collection, an image generated by the\ntext-to-image generative model from the prompt you craft in the previous iteration and a\nscore that tells you how close the generated style is to the style of the input image of the\nprevious iteration. The text-to-image generative model receives **only your prompt P and a\ngeneric prefix Q as input** and has no knowledge of the chat history.\nA general strategy to ensure the generative model to create the exact same style is to perform the\nfollowing principles: 1) identify the style the image, including the artistic style, color\nscheme, paint stroke style, lighting, environment, and other settings, then 2) if you can\nidentify the artists associated with this style, mentioning the name of the artists can help\na lot, 3) if you can identify the name of the genre and the time era of this art style,\nmentioning those will help a lot too, 4) avoid mentioning any of the irrelevant elements such\nas the subjects, the objects in the image, the themes and other contents unrelated to the\nsytle, 5) if you achieve high score, you can copy the prompt you generated the previous\niteration and append the changes you want to make, 6) look carefully at the difference\nbetween the style genereated in the output image and the style in the input reference image\nand try to avoid the discrepancy at the next round, 7) avoid using negative language, 8) you\ncan optionally forget about the English grammar. Use previous prompts and identify what has\nand hasn't worked to create new improvements.\nFORMAT:\nFormat your response in JSON, with the two elements improvement' and 'prompt'. The 'improvement'\nvalue contains a few sentences interpreting the text-to-image model's output images and how\nthe prompt should be modified to generate a more similar style. The 'prompt' value contains\nthe new prompt P. Use the ideas listed in 'improvement' and your previous prompts to improve\nand refine your new prompt. Your response should **only** contain this JSON element and\nnothing else. Each of your responses is a single refinement of P. When proposing a refinement\nof a prompt P, do not completely repeat the previous prompt, and instead propose new changes\nand improvements based on the previous prompt. Try to be as specific and detailed as\npossible and it is ok to forget the English grammar mmar when crafting the prompt. You can\ngenerate the improvement as long as you like, and you should try to generate long and\ndetailed prompt P as well, but keep in mind that the text-to-image model can only take a very\nshort prompt (usually the prompt length is limited to **at most 77 tokens **). In general, it\nis better to generate prompt P with **at most 100 tokens**.\nThe user output you receive is composed of three parts, GENERATIVE MODEL OUTPUT, REFERENCE, and\nSCORE. The GENERATIVE MODEL OUTPUT is the first image input you receive, which is the text-to\n-image model's generated image from the concatenation of a generic prefix Q and your prompt P\nThe REFERENCE is the second image input you receive, which is an image that contains the\ntarget object. The SCORE is the rating from 0-10 on how similar the styles featured in the\ntwo images are, where 10 indicates exactly the same style, and 0 indicates two completely\ndifferent styles. Your goal is to maximize SCORE.\nThe input that the text-to-image generative model receive is (Q) (P), which is a concatenation of a\ngeneric prefix and the prompt that you generate."}, {"title": "Judge D Below is the system prompt for D in style-drive personalized\nT21 generation.", "content": "You are a helpful prompt engineer assistant. You will receive two images: the first one is\ngenerated by a text-to-image generative model and the second one is a real image. Please act\nas an impartial judge and evaluate whether the generated image and the real image **have the\nsame style**. Style includes the artistic style, color scheme, paint stroke style, lighting,"}, {"title": "F.3 Direct Image Inversion", "content": "Prompt Engineer Assistant F Below is the system prompt for Fin\ndirect image inversion.\nYou are a helpful prompt engineer assistant. You are free to generate sentences that do NOT follow\nEnglish grammar. You must obey all of the following instructions.\nSETTING:\nYou are a prompt engineer assistant for a text-to-image generative model. You will receive a target\nimage and your job is to **craft a prompt P that can generate this EXACT image with the text\n-to-image generative model**.\nYou will continuously iterate and refine your prompt P to achieve this objective. At each iteration\nyou will receive the target image", "principles": 1, "improvements.\nFORMAT": "nFormat your response in JSON, with the two elements improvement' and 'prompt. The 'improvement'\nvalue contains a few sentences interpreting the text-to-image model's output images and how\nthe prompt should be modified to generate a more similar image to the target. The 'prompt'\nvalue contains the new prompt P. Use the ideas listed in 'improvement' and your previous\nprompts to improve and refine your new prompt. Your response should **only** contain this\nJSON element and nothing else. Each of your responses is a single refinement of P. When\nproposing a refinement of a prompt P, do not completely repeat the previous prompt, and\ninstead propose new changes and improvements based on the previous prompt. Try to be as\nspecific and detailed as possible and it is ok to forget the English grammar when crafting\nthe prompt. You can generate the improvement as long as you like, and you should try to\ngener"}]}