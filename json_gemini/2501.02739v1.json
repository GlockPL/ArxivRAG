{"title": "TARDiS : Text Augmentation for Refining Diversity and Separability", "authors": ["Kyungmin Kim", "SangHun Im", "GiBaeg Kim", "Heung-Seon Oh"], "abstract": "Text augmentation (TA) is a critical technique for text classification, especially in few-shot settings. This paper introduces a novel LLM-based TA method, TARDIS, to address challenges inherent in the generation and alignment stages of two-stage TA methods. For the generation stage, we propose two generation processes, SEG and CEG, incorporating multiple class-specific prompts to enhance diversity and separability. For the alignment stage, we introduce a class adaptation (CA) method to ensure that generated examples align with their target classes through verification and modification. Experimental results demonstrate TARDiS's effectiveness, outperforming state-of-the-art LLM-based TA methods in various few-shot text classification tasks. An in-depth analysis confirms the detailed behaviors at each stage.", "sections": [{"title": "Introduction", "content": "Text augmentation (TA) is a critical technique for text classification, especially in few-shot settings where the original data is extremely limited. Incorporating class-specific features during the TA process is crucial to overcoming the limited knowledge derived from few-shot data (Anaby-Tavor et al. 2020; Guo, Kim, and Rush 2020; Malandrakis et al. 2019; Sennrich, Haddow, and Birch 2016; Wei and Zou 2019; Wu et al. 2019). TA leveraging Large Language Models (LLMs) (Sahu et al. 2023, 2022; Lin et al. 2023; Dai et al. 2023) is notably effective due to the extensive intrinsic knowledge within LLMs. Previous LLM-based TA methods can be generalized into two stages: generation and alignment. In the generation stage, novel examples for a target class are generated using original data. Subsequently, misaligned examples corresponding to incorrect or out-of-distribution (OOD) classes are addressed in the alignment stage.\nExisting two-stage TA methods have limitations at each stage. The generation stage typically depends on a single fixed prompt to generate new examples based on seed data. This approach restricts LLMs' inherent knowledge usage and diversity, resulting in two critical limitations: insufficient class-specific features and classification properties. The former can be addressed by employing manual class descriptions, but human intervention is essential and not always feasible or scalable. For the latter, existing methods often focus on a single aspect, such as either intra-class diversity (Sahu et al. 2022; Lin et al. 2023) or inter-class separability (Sahu et al. 2023). In the alignment stage, few-shot settings have inherent weaknesses due to insufficient training data for verifying misaligned examples. This often results in false negatives (FNs), where aligned examples are incorrectly identified as misaligned, and an inability to handle out-of-distribution (OOD) examples.\nTo address these limitations, this paper proposes a novel LLM-based TA method, TARDIS (Text Augmentation for Refining Diversity and Separability). In the generation stage, TARDiS uses \u2018spark thoughts', ideas that activate the LLMs' inherent knowledge for each class, enhancing the traditional single-prompt approach with multiple class-specific prompts. To tackle both intra-class diversity and inter-class separability, we present two generation processes employing the multiple class-specific prompts: Semantic Enrichment Generation (SEG) and Contrastive Enrichment Generation (CEG). As illustrated in Figure 1-(b), SEG uses spark thoughts generated from examples within the target class to capture diversity within the target class, whereas CEG uses those generated from both the target class and an ambiguous class, which could be confused with the target class, to improve separability from non-target classes.\nTo address the limitations of the alignment stage, we propose a Class Adaptation (CA) method that modifies generated examples to align with the corresponding target class using an LLM instead of simply relabeling them. Consequently, CA can effectively deal with examples that are misaligned, OOD, or FNs.\nThe contributions of this paper are summarized as follows:\n1. We propose TARDiS to address the challenges of two-stage TA methods. For the generation stage, we introduce SEG and CEG based on multiple class-specific prompts to enhance diversity and separability, respectively. For the alignment stage, we introduce a CA method to ensure that generated examples align with the corresponding target class through verification and modification.\n2. We demonstrate the effectiveness of TARDiS by achieving SOTA performance on various few-shot text classification benchmarks and investigate detailed behaviors at each stage through an in-depth analysis."}, {"title": "Related Work", "content": "Text Augmentation\nTA has been widely studied to enhance the generalization capability of models by generating new examples from seed data. Traditional methods like EDA (Wei and Zou 2019) and back translation (Sennrich, Haddow, and Birch 2016) create new patterns by altering linguistic characteristics but face limitations in introducing completely new features. Language Model (LM)-based TA methods generate novel examples by leveraging sentence structures (Guo, Kim, and Rush 2020; Kim, Jeong, and Cho 2021; Kobayashi 2018; Wu et al. 2019) or modifying parts of the seed data (Anaby-Tavor et al. 2020; Kumar, Choudhary, and Cho 2020) to utilize the knowledge within pre-trained LMs.\nRecent advancements in LLMs, such as GPT-3 (Brown et al. 2020) and Llama (Touvron et al. 2023), have enabled TA methods to generate novel examples by leveraging the extensive intrinsic knowledge within LLMs. LLM-based TA methods can be generalized into two stages: generation and alignment. In the generation stage, novel examples for a target class are created by utilizing the original data. Lin et al. (2023) and Sahu et al. (2022) employ seed data as prompts to generate augmented examples. On the other hand, Prompt-Mix (Sahu et al. 2023) and GPT3MIX (Yoo et al. 2021) aim to enhance separability by incorporating data from two classes into their prompts. However, these approaches use a single fixed prompt and only target class seed data for generation. On the other hand, PromptMix (Sahu et al. 2023) and GPT3MIX (Yoo et al. 2021) aim to enhance separability by incorporating both target and non-target class data. However, they either designate all classes or randomly sample classes as non-target without considering inter-class relevancy. These methods exhibit limitations in tasks involving numerous classes with significant inter-class relationship variances (e.g., intent classification). There are two primary methods in the alignment stage: filtering and relabeling. Filtering (Lin et al. 2023) removes misaligned examples while relabeling (Sahu et al. 2022, 2023) assigns new labels to examples based on classification results. However, these methods have not adequately addressed the inherent weaknesses caused by insufficient training data for verifying misaligned examples in few-shot settings. This can lead to FNs and an inability to handle OOD examples.\nTARDIS addresses the limitations of existing methods by utilizing two generation processes, SEG and CEG, which leverage spark thoughts to create multiple class-specific prompts. Furthermore, it overcomes the limitations of existing alignment methods through CA.\nChain of Thought Prompting\nLLMs such as GPT-3 (Brown et al. 2020) and Llama (Touvron et al. 2023), possess high inferential and linguistic capabilities using a vast amount of internal knowledge (Zhao et al. 2023).\nCoT prompting is a method that maximizes the capabilities of LLMs (Kojima et al. 2022; Wei et al. 2022). It works by generating a flow of thoughts similar to human recognition, and reasoning to solve targeted tasks based on these. CoT prompting is successfully employed in various tasks such as logical reasoning (Ho, Schmid, and Yun 2023) and question answering (Lu et al. 2022; Wang et al. 2023). Some research attempts to perform diverse and creative generation based on CoT prompting. Tree of thought methods (Yao et al. 2023) generate various thoughts and select the most"}, {"title": "Methodology", "content": "TARDIS operates as in Figure 2. In the generation stage, two complementary methods, SEG and CEG, generate examples with high diversity and separability. Each method utilizes seed data Dt of a target class t \u2208 C to create class-specific spark thoughts St. St and Dt are combined to serve as multiple class-specific prompts for TA. In the alignment stage, a CA method ensures that the generated examples align with the target classes. Finally, these aligned examples are used as augmented data to train a classification model for evaluation.\nGeneration Processes\nSemantic Enrichment Generation (SEG)\nLLMs tend to generate stereotypical and generic examples influenced by the common situations frequently occurring in extensive training data. By contextualizing input prompts with desired sentence styles, specific contexts, or particularly appropriate examples. SEG generates spark thoughts"}, {"title": "Contrastive Enrichment Generation (CEG)", "content": "SEG generates diverse examples using the seed data within the target class but does not guarantee separability between different classes among examples. In contrast, CEG performs inter-class conditioning using discriminative text as a spark thought to improve separability between non-target classes.\nThe overall flow of CEG is illustrated in Figure 2. First, unlike designating all classes or randomly sampling classes as non-target, we select ambiguous classes based on the class similarity of seed data. This approach assumes semantically similar data is more likely to be confused with the target class. The class similarity score between the target class t"}, {"title": "Class Adaptation (CA)", "content": "Misaligned examples are one of the primary factors that degrade the quality of augmented data. To address this issue, we propose a Class Adaptation (CA) method, which modifies misaligned examples to align with the target classes based on verification. First, for each generated example, m semantically similar examples are retrieved from the seed data based on the embeddings extracted by SBERT. These retrieved examples and their corresponding classes are used as shots to construct a verification prompt. The generated examples are verified using an LLM classifier with the verification prompt. If a prediction p differs from t, it is considered misaligned. Each misaligned example e is modified by LLM(Dt, St,p, e) to obtain e' that aligns with class t, where St,p is the same discriminative text used in CEG.\nOur CA method offers two advantages. Firstly, CA can handle OOD classes. Even if a generated example is completely unrelated to the target domain or is not a proper sentence, it can be aligned with the target class through intensive modification. Secondly, CA can deal with false negatives induced by incorrect predictions from an LLM classifier. The meaning of a generated example can be preserved through minimal modification."}, {"title": "Experimental Setup", "content": "Datasets and Evaluation\nWe opted for four datasets widely used for few-shot classification: BANKING77, CLINC150, HWU64, and TREC6.\nWe used sentence-transformers/all-mpnet-base-v2 for SBERT on sentence-transformers for every SBERT.\nBANKING77 (Casanueva et al. 2020) focuses on the banking domain, while CLINC150 (Larson et al. 2019) and HWU64 (Eshghi and Rieser 2019) cover 20 and 21 domains, respectively. TREC6 (Li and Roth 2002) aims at question classification in the open domain. Details of the datasets are provided in Table 1. For 5-shot and 10-shot settings on BANKING77, CLINC150, and HWU64, we followed the data split and seed data selection from DialoGLUE (Mehri, Eric, and Hakkani-Tur 2020). For the 2-shot setting on TREC6, we utilized the official splits and randomly sampled seed data from the training set. As an evaluation metric, accuracy was selected for direct comparison with recent methods.\nAugmentation and Classification\nFor augmentation with TARDiS, we used an instruction-tuned LLM, Llama2-13b (Touvron et al. 2023), was used. A repetition penalty of 1.15 (Keskar et al. 2019) was applied to generate text different from the seed data. In 5-shot and 10-shot settings, augmentation was performed 50 times for both SEG and CEG, respectively, while 25 times in 2-shot settings.\nFor a fair comparison in classification, we finetuned and compared three PLMs, RoBERTa-base, RoBERTa-large (Liu et al. 2019), and BERT-base (Devlin et al. 2019) as text classifiers trained with SOTA TA methods. We followed the standard classification procedure using an additional linear layer and \u201c[CLS]\" token. To mitigate differences from a baseline due to the amount of training data, we finetuned PLM classifiers based on the training steps rather than the epochs.\nPLM classifiers were finetuned for 4,000 steps in 5-shot and 10-shot settings and 1,000 steps in 2-shot settings. The hyperparameters were set according to CPFT (Zhang et al. 2021) in 5-shot and 10-shot settings and PromptMix in 2-shot settings. All experiments were conducted using 8 NVIDIA A6000 GPUs.\nComparison Methods\nWe selected seven recent TA methods as our comparison methods. PLMs trained with only few shots are regarded as baselines. ConveRT (Henderson et al. 2020) is a dual-encoder intent detection model, pre-trained with pairs of input and response. Mehri and Eric (2021) is an intent detection model trained on CONVBERT (Mehri, Eric, and Hakkani-Tur 2020) with the concept of attention observer and similarity matching. DNNC (Zhang et al. 2020) is a discriminative model that identifies the most compatible example from a training set via similarity matching using RoBERTa-base model. CPFT (Zhang et al. 2021) leverages contrastive learning to pretrain ROBERTa-base model on various intent classification datasets, followed by fine-tuning on a specific target dataset. ICDA (Lin et al. 2023) is an LLM-based TA method that selects generated examples most helpful for training the model while filtering out others. GPT3MIX (Yoo et al. 2021) integrates information between two classes through pseudo-labeling, aiming for separability. PromptMix (Sahu et al. 2023), is LLM-based TA method\""}, {"title": "and other class c is calculated using Equation 1:", "content": "\\[\nSim(t, c) = \\frac{1}{|D_t| \\times |D_c|} \\sum_{d_t \\in D_t} \\sum_{d_c \\in D_c} cos(d_t, d_c) \n\\]\nwhere cos(dt, dc) denotes the cosine similarity between two embeddings of examples dt and dc, extracted using SBERT. Then, for each class t, we select n classes with the highest similarity scores as a set of ambiguous classes At. Subsequently, for t and a \u2208 At, St,a is generated to state the differences between the two classes explicitly. Finally, k examples are generated through LLM(Dt, Da, St,a). To maximize the diversity of the input prompts, we randomly remove one or two examples from Dt and Da, varying the order of the remaining examples."}, {"title": "Main Performance", "content": "Table 2 presents the results of the comparison methods using RoBERTa-base (top) and RoBERTa-large (bottom) in both 5-shot and 10-shot settings on three datasets. TARDIS achieves significant improvements in most configurations, with two exceptions: CPFT with RoBERTa-base on HWU64 and ICDA with RoBERTa-large on BANKING77 in 10-shot settings. Despite these exceptions, TARDiS remains superior and competitive for two reasons. First, TARDiS operates without human-annotated data, whereas CPFT relies on various human-annotated data for intent classification. Second, TARDIS employs a relatively small LLM (i.e., Llama2-13b), whereas ICDA adopts OPT-66b (Zhang et al. 2022), which is about five times larger. Table 3 presents the performance"}, {"title": "Analysis", "content": "Measuring Diversity Table 6 presents the Average Pair Similarity (APS) scores on three datasets, where a pair similarity is computed by the cosine similarity between two examples' embeddings extracted by SBERT. We compute the inter-class and intra-class APS scores for 5-shot, training data (Train), and TARDiS's augmented data (AUG) for each dataset, respectively. It is assumed that lower intra-class APS values indicate high diversity within a class, whereas they are low diversity and vice versa. We"}, {"title": "Effect of SEG and CEG", "content": "Table 4 compares our generation methods. SEG and CEG show similar performance when used individually, varying their effectiveness across datasets. However, combining SEG and CEG consistently outperforms individual methods on three datasets. This indicates that each component plays a different role, and their combination implements a unique TA method.\nFigure 3 analyzes the effects of SEG and CEG on BANKING77. SEG and CEG exhibit different characteristics, with notable variations across specific classes. For instance, the Exchange_via_app class encompasses a wide range of general exchanges, which contrasts with the discriminative text suggesting it should only include app-based exchanges. CEG overemphasizes the app aspect as the primary distinguishing factor from other classes, failing to capture the"}, {"title": "Effects of Class Adaptation", "content": "Figure 4 shows two graphs of the proportional confusion matrices before and after CA. At the top, a verifier misclassifies aligned examples as misaligned with a high proportion of 13% and 12% in FN and FP, respectively. A modifier only deals with FN and TN, which are classified as misaligned by the verifier. Consequently, our CA reduces the proportion of misaligned examples from 56%, with the existing 43% FP+TN and 13% FN, to 23%. Table 8 demonstrates sample results applying CA, divided into (a) and (b) for TN and (c) for FN, respectively. For TN, (a) a part of an example and (b) an OOD example that is either irrelevant to the dataset or entirely incorrect are modified to align with the corresponding class. For FN, (c) an example is aligned to the target class with minimal modifications compared to filtering and relabeling, which can introduce additional misalignment. Despite those successes, FP cases remain a significant challenge, as they cannot be effectively handled using existing methods."}, {"title": "Conclusion", "content": "We propose TARDIS to overcome the limitations of existing two-stage LLM-based TA methods in few-shot settings. In the generation stage, SEG and CEG based on multiple class-specific prompts to enhance diversity and separability. In the alignment stage, CA method ensures that generated examples align with the corresponding target class, effectively dealing with examples that are misaligned, OOD, or FNs. We demonstrate the effectiveness of TARDiS by achieving SOTA performance on various few-shot text classification benchmarks and investigate detailed behaviors at each stage through an in-depth analysis. In future work, we plan to extend TARDiS to more challenging tasks such as creative writing and question answering. Moreover, we plan to investigate efficient methods to reduce computational costs."}, {"title": "limitations", "content": "Although TARDIS demonstrates significant performance improvements through effective augmentation on various datasets, several limitations need to be addressed. First, even"}]}