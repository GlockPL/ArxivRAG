{"title": "Visual Evaluative AI: A Hypothesis-Driven Tool with Concept-Based Explanations and Weight of Evidence", "authors": ["Thao Lea", "Tim Miller", "Ruihan Zhang", "Liz Sonenberg", "Ronal Singh"], "abstract": "This paper presents Visual Evaluative AI, a decision aid that provides positive and negative evidence from image data for a given hypothesis. This tool finds high-level human concepts in an image and generates the Weight of Evidence (WoE) for each hypothesis in the decision-making process. We apply and evaluate this tool in the skin cancer domain by building a web-based application that allows users to upload a dermatoscopic image, select a hypothesis and analyse their decisions by evaluating the provided evidence. Further, we demonstrate the effectiveness of Visual Evaluative Al on different concept-based explanation approaches.", "sections": [{"title": "Introduction", "content": "A common decision support paradigm called recommendation-driven provides either or both the AI recommendation and the explanation for the given recommendation [13, 2, 15]. However, this paradigm is yet to be effective because it limits the control of human decision-makers, which can cause algorithm aversion [3] where people do not trust the AI; or worse, over-reliance on the AI system [14].\nMiller [11] proposes a paradigm shift called hypothesis-driven using a conceptual framework evaluative AI. Figure 1 describes the difference between the traditional recommendation-driven paradigm and the new hypothesis-driven paradigm. Rather than telling the decision-makers what to do, hypothesis-driven aims to reduce the reliance [10], promote uncertainty awareness [9, 10] and give decision-makers more control of the decision-making process by incorporating their hypotheses.\nIn this paper, we build an EvaluativeAl tool by combining concept-based explanations for image data and the Weight of Evidence (WoE) model. This tool offers hypothesis-driven decision-making by generating evidence for possible hypotheses of an image. We also provide public access to EvaluativeAl as a Python package so other researchers can use our tool. Moreover, we demonstrate a web-based application using this tool on a skin cancer dataset where users can see positive/negative evidence for different skin cancer diagnoses. The performance of the proposed models is evaluated on this skin cancer dataset."}, {"title": "Methodology", "content": "Concept-based explanations Concept-based models provide explanations using human-defined concepts that are related to parts ofimages [8, 4]. The explanation is visualised as a segmentation of the image that represents a specific concept. The concept-based model can be classified into two categories: (1) supervised concept learning (concepts are labelled on each image in the training dataset) and (2) unsupervised concept learning (not having concept labels in the training dataset). Supervised concept learning requires labelled concepts in the training set, or the concepts can be transferred using another labelled dataset [18]. Unsupervised learning concept methods do not require the concepts to be labelled during the training process. This method is helpful when labelling concepts can be laborious, require expertise, or are not always available. Moreover, unsupervised learning can give users more agency as they can find a new concept that has not been labelled, but is still used by a machine learning model.\nWeight of Evidence (WoE) To measure a quantitative response of how much each concept (or feature) contributes in favour of, or against a particular hypothesis, we apply the Weight of Evidence (WoE) model [1], building on Good [5]. Through Bayes rule, WoE is expressed as the log-odd ratios of the evidence likelihood. In our application, the evidence will be referred to a concept (or feature) found in the image. Each concept will have a positive/negative quantitative value that shows how much it contributes to the given hypothesis.\nWe build our evidence generation model by combining a concept-based explanation model (i.e., Invertible Concept-based Explanation (ICE) [19], Post-hoc Concept Bottleneck Model (PCBM) [18]) and the Weight of Evidence (WoE) model [1]. In particular, we replace the classifier layer of ICE and PCBM with the WoE model. Combining them together, we propose two models to generate the evidence-"}, {"title": "Demonstration: A Case Study on Skin Cancer", "content": "Applying AI in supporting skin cancer detection has become more prevalent and potentially improved decision-making accuracy. To demonstrate the effectiveness of Evaluative Al, we apply this tool to the skin cancer diagnosis domain. We build a web-based application called Evaluative Skin Cancer (EvaSkan), a solution for evaluating skin cancer using the hypothesis-driven paradigm. Users can select a hypothesis and the application will generate positive/negative evidence for that particular hypothesis. Using the evidence provided, the decision-maker can integrate their domain knowledge and make the final decision. Our application offers the foundation of an evaluative Al decision support tool (DST) in skin cancer diagnosis by focusing on human decision-makers, which is critical in the medical domain.\nFigure 3 shows the user interface of the web-based application EvaSkan. There are four main components in this app: (1) Upload a dermatoscopic image, (2) Three example test images, (3) Candidate hypotheses and (4) Evidence For/Against the selected hypothesis. First, the user can either select a dermatoscopic image of their choice or choose one test image in the three examples provided. Then, they select a hypothesis among the seven potential hypotheses/diagnoses\u00b9 [12]: AKIEC, BCC, BKL, DF, MEL, NV and VASC. When the user clicks Run, the evidence for and against the selected hypothesis will be generated. Specifically, an image feature (concept) is described by an annotation in the selected test image and five other annotated examples in the training set that describe the same feature. For each feature, the app will show a quantitative measure of how much each feature provides in favour of, or against the selected hypothesis. By considering all possible hypotheses/diagnoses and the positive/negative evidence of the corresponding hypothesis, it is up to the user to make the final diagnosis, and they can choose to use the evidence from the DST. In our demonstration, users can try both the unlabelled concept approach (i.e., ICE+WoE) and the labelled concept approach (i.e, PCBM+WoE). Figure 3 shows an example when using unsupervised concept learning (ICE+WoE)."}, {"title": "Experiments", "content": "Dataset and Model Implementation\nWe use the HAM10000 dataset [12] to train all models (original CNN backbones, ICE, ICE+WOE, PCBM and PCBM+WoE). The data has a total of 10015 dermatoscopic images and seven output classes: Actinic keratoses (AKIEC), basal cell carcinoma (BCC), benign keratosis (BKL), dermatofibroma (DF), melanoma (MEL), melanocytic nevi (NV) and vascular lesion (VASC). We balanced the dataset by applying Weighted Random Sampler \u00b2 and data augmentation. Finally, each class has 1000 samples that were used for the training process, making a total of 7000 samples for seven classes. The test set is selected as a fraction of the original dataset (without\nResults\nICE+WoE and PCBM+WoE achieve comparable performance to the original CNN models Table 1 reports the performance of ICE(8) and ICE(8)+WoE using three different CNN backbone models (Resnet50, Resnet152 [6] and ResneXt50 [16]). ICE(8)+WoE and PCBM+WoE achieve comparable performance compared to the original CNN model. Moreover, ICE(8)+WoE and PCBM+WoE have a smaller standard deviation than the original ICE(8) and PCBM models, respectively. Since ICE uses the weights of the original CNN backbone models, we conduct a further ablation experiment by replacing the classifier layer of ICE with the Gaussian Naive Bayes (ICE+GNB) to compare with ICE+WOE. The results in Table 1 show that ICE(8)+WoE and ICE(8)+GNB have closer performance than ICE(8)+WoE and the original ICE(8). The reason is that our implementation using WoE and GNB are both Naive Bayes methods so they use similar loss functions when learning the concept scores.\nHaving more concepts does not lead to better accuracy Figure 4 shows the performance of the original ResneXt50, ICE and ICE+WoE over different number of concepts from 5 concepts to 40 concepts. Two figures from the left show the performance of ICE using NMF reducer. When there are 5 concepts, ICE(5)+WoE (73.16 \u00b1 8.65) has a significantly higher F1-score than ICE(5) (63.72\u00b18.65) (p = 0.001, d = 1.091). Since we have 2048 features at the classifier layer of ResneXt50, ResneXt50 outperforms ICE(5)+WoE and ICE(5) significantly (p < 0.001). But the performance of both ICE+WoE and ICE match the performance of the original ResneXt50 when we have at least 7 concepts. Particularly, with as few as 7 concepts, ICE and ICE+WoE achieve similar performance to the original ResneXt50 using 2048 features. The performance of ICE and ICE+WoE also stopped improving at 7 concepts with a backbone of ResneXt50. The reason is that when we apply a reducer in ICE (e.g. NMF), some important concepts are detected at first. Then after we increase the number of concepts, some noisy concepts are detected, which could lead to a slight drop in the performance. Eventually, all important concepts are found and match the performance of the original CNN model. Similar to the findings"}, {"title": "Conclusion", "content": "In this paper, we introduce Visual Evaluative AI 3, a tool for hypothesis-driven decision support. This tool can highlight the high-level concepts in an image and provide positive/negative evidence for all possible hypotheses. Our tool is further applied and evaluated in the skin cancer domain with a web-based application called EvaSKan that offers skin cancer diagnosis support. In future work, a more comprehensive evaluation will be undertaken by addressing the domain expert opinions on this application."}]}