{"title": "Semantic Model Component Implementation for Model-driven Semantic Communications", "authors": ["Haotai Liang", "Mengran Shi", "Chen Dong*", "Xiaodong Xu", "Long Liu", "Hao Chen"], "abstract": "The key feature of model-driven semantic communication is the propagation of the model. The semantic model component (SMC) is designed to drive the intelligent model to transmit in the physical channel, allowing the intelligence to flow through the networks. According to the characteristics of neural networks with common and individual model parameters, this paper designs the cross-source-domain and cross-task semantic component model. Considering that the basic model is deployed on the edge node, the large server node updates the edge node by transmitting only the semantic component model to the edge node so that the edge node can handle different sources and different tasks. In addition, this paper also discusses how channel noise affects the performance of the model and proposes methods of injection noise and regularization to improve the noise resistance of the model. Experiments show that SMCs use smaller model parameters to achieve cross-source, cross-task functionality while maintaining performance and improving the model's tolerance to noise. Finally, a component transfer-based unmanned vehicle tracking prototype was implemented to verify the feasibility of model components in practical applications.", "sections": [{"title": "I. INTRODUCTION", "content": "The new 6G era of \"Internet of Intelligence\" with connected people, connected machines, connected things, and connected intelligence is becoming the expectation of the academia and industry [1]. Intelligence-oriented interconnection relies on semantic communication driven by Artificial Intelligence (AI) technology, which is one of the key research directions in the \"Internet of Intelligence\" era. By transmitting key semantic elements, it improves the efficiency of traditional data exchange in 0-1 bit streams[2.\nIn the semantic communication network, facing different sources and tasks, the edge nodes need to use different artificial intelligence models to extract and recover the corresponding semantic information amount. However, due to the limited computing ability and storage capacity of mobile terminals, it is difficult to use large Al models with strong generalization capabilities, while AI models with a small amount of computing, memory, and storage are often only applicable to specific AI tasks and environments. So model updates are needed for edge nodes that handle multiple sources and tasks. The base station has the ability to compute, reason, and make decisions in the face of different tasks and source scenarios, supporting a \"learn first, do later\" mode of work mode. Therefore, model distribution from the base station to the edge nodes is one way to make the edge nodes have the ability to handle different sources and tasks.\nCurrent semantic communication technologies and systems are only for one task or a single source[3], such as text [4], speech signal [5], image [6, 3], video [7, 8] and 3D point cloud [9]. A joint source and channel coding (JSCC) [10] technique for wireless image transmission which directly maps the image pixel values to the complex-valued channel input symbols, encourages us to design a semantic communication system based on JSCC. Xie and Qin designed a semantic communication system based on deep learning for text [4] and speech signal transmission [5], named DeepSC and DeepSC-S, which aims at maximizing the system capacity and minimizing the semantic errors by recovering the meaning of sentences. Dai proposes an efficient deep joint source-channel coding method, which can closely adapt to the source distribution under nonlinear transformation, which is called nonlinear transformation source-channel coding (NTSCC) [6]. The proposed NTSCC essentially learns both the latent source representation and an entropy model as the prior on the latent representation, fully exploits the semantic information of image and video, and designs the wireless image and video semantic communication system [6, 7]. Zhu proposes an AI-powered compression and semantic-aware transmission method for point cloud video data, named AITransfer and designs an end-to-end cloud video compression and reconstruction architecture [9]. Dynamic network conditions are combined into the end-to-end architecture design, and an adaptive control scheme based on deep reinforcement learning is adopted to provide robust transmission.\nTherefore, a method is proposed to cope with the semantic extraction and recovery of edge nodes handling different sources and tasks. The concept of semantic slice model (SeSM) (To avoid confusion with the name of the network slice, we rename the semantic slice model (SeSM) as the semantic model component (SMC)) is firstly proposed in [3] to reduce the traffic of model propagation. In the envisioned semantic communication network[1, 2, 3], the edge node sends"}, {"title": "II. SMC BASED SEMANTIC COMMUNICATION SYSTEM", "content": "In this section, the SMC based semantic Communication system and the details of the considered tasks are discussed."}, {"title": "A. System Model", "content": "As shown in Fig. 1, edge nodes with limited memory and computing power have deployed semantic models to process specific sources and perform specific tasks. Assuming that the base station has enough computing power to train the model and enough memory to store data, while the computing power and memory of the edge nodes can only fine-tune the model and store limited data. The memory setting of the edge node is consistent with the incremental learning problem [14]. For the incremental SMC training, the base station can observe the base model of the edge node and all data sets. The edge nodes are allowed to adopt the rehearsal strategy, which saves a part of data as the memory M for fine-tuning.\nThe intelligence transmission process based on SMC propagation can be decoupled into three sequential stages as follows.\n1) The edge node uploads the update requirements generated by the change of the environment or the upper-level decision to the base station.\n2) The base station uses enough computing power, data sets and original base models to train SMC to adapt to new source domains and tasks. Then the SMC is distributed to the edge nodes.\n3) The edge node integrates the base model and SMC model so that the combined model can handle multiple source domains and tasks at the same time."}, {"title": "B. Task Description", "content": "In the following, the feasibility of a SMC based semantic communication system is demonstrated for different scenarios and tasks, and the system is analyzed from several aspects."}, {"title": "1) Incremental SMC:", "content": "The purpose of incremental SMC is to expand the scope of classification or detection of the basic model. Therefore, as shown in Fig. 2(a), the task proposed in this paper to verify the incremental SMC is to combine the basic model with the incremental SMC to improve the categories that the model can recognize and detect."}, {"title": "2) Cross-source-domain SMC:", "content": "Cross-source domain SMC aims to expand the source distribution that the model can handle. As shown in Fig. 2(b), taking the semantic segmentation model as an example, the basic model and the SMC are trained using data sets with large differences in source distribution to verify the effectiveness of cross-source-domain SMC."}, {"title": "3) Cross-task SMC:", "content": "Cross-task SMC can migrate the basic model from the original function to other functions. As shown in Fig. 2(c), two semantic task migration SMC between classification and target detection were proposed."}, {"title": "III. DESIGN AND IMPLEMENTATION OF THE SEMANTIC MODEL COMPONENT", "content": "This section introduced the method of semantic model components, including incremental SMC, cross-source domain SMC and cross-task SMC, aiming to achieve a better trade-off between stability and plasticity. The design of the semantic model components uses the idea of structure expansion. The semantic model components trained on the base station have the module of feature extraction and task execution that the basic model on the edge node lacks. The following first describes the incremental SMC method in detail, and then extend it to cross-source domain SMC and cross-task SMC. Finally, the effect of channel noise on SMC is analyzed, and a method to improve the noise robustness is proposed."}, {"title": "A. Method", "content": "Firstly, the problem setup of the incremental SMC training was introduced. During the class incremental SMC training, the base station can observe the stream of the original category $\\{Y\\}$ and the incremental category $\\{Y_{SM}\\}$ and their corresponding training data $\\{D\\}$ and $\\{D_{SM}\\}$. The edge nodes are allowed to adopt the rehearsal strategy, which saves a part of data as the memory $\\{M\\}$ for fine-tuning.\nAl models can be decomposed into feature extractor and task execution module [15]. The transferability between different models is mainly affected by the feature extraction module. High-level neurons will be more specific to the original task and lack generalization to other tasks, which will sacrifice the performance of the target task.\nTherefore, the first step is to find the feature extractor of the original task model that can be generalized to the target task. The part of the model with generalization will be reused, and the expanded structure will be used to improve the feature extraction ability of the target task. For the learning of the incremental SMC, the learning process can be decoupled into two sequential stages as follows.\n1) Generalized feature extractor learning: Assuming that the base station has the models of the original task and the target task, we need to find a feature extractor that can extract common features from the two models. The Singular Vector Canonical Correlation Analysis(SVCCA) [16] method is used here to measure the similarity of the expression of the model. Given dataset $X = \\{x_1,...,x_m\\}$, define $z_i^l$ as the activation output of the neuron i on layer l of the model,\n$z_i^l = \\{z_i^l(x_1), ..., z_i^l(x_m)\\},\\qquad(1)$\nThe representations of the $j^{th}$ layer of the original task network and the target task network is expressed by the following formula,\nV_{ori}^j = \\{z_{ori_1}^j,..., z_{ori_{m_1}}^j\\},\\qquad(2)$\nV_{tar}^j = \\{z_{tar_1}^j, ..., z_{tar_{m_2}}^j\\},\\qquad(3)$\nwhere $\\P_{ori}^j$ and $\\P_{tar}^j$ are decomposed into subspace $L_{ori}^j$ and $L_{tar}^j$ by singular value decomposition, which contain the most important directions to explain the variance of the original spaces. Then, the value of Canonical Correlation similarity [17] of $\\P_{ori}^j$ and $\\P_{tar}^j$ is computed by projecting $\\P_{ori}^j$ and $\\P_{tar}^j$ to $L_{ori}^j$ and $L_{tar}^j$,\n$\\P_{ori}^j = W_x L_{ori}^j$\\ \\ $\\P_{tar}^j = W_y L_{tar}^j,\\qquad(4)$\nThe optimization objective of the Canonical Correlation Analysis(CCA) is\n$\\arg \\max_{W, W_y}\\frac{cov(\\P_{ori}^j, \\P_{tar}^j)}{\\sqrt{D(\\P_{ori}^j)}\\sqrt{D(\\P_{tar}^j)}},\\qquad(5)$\nwhere $cov(\\cdot)$ and $D(\\cdot)$ separately represent the covariance and variance. After obtaining the corresponding linear transformations vector $W_x, W_y$, we can get the correlation coefficient between $\\P_{ori}^j$ and $\\P_{tar}^j$,\n$corr(\\P_{ori}^j, \\P_{tar}^j) = \\{\\rho_1, ..., \\rho_{\\min(m_1,m_2)}\\},\\qquad(6)$\nwhere $\\rho_1$ represents the correlation coefficient of the most important direction, so $\\rho_1$ was taken as the similarity between the two network layers. The higher the value of $\\rho_1$, the more similar the network expression ability of this specific network layer. Generally speaking, neurons in shallow networks extract features more commonly and have correspondingly larger $\\rho_1$ values. With $\\rho_T$ as the threshold, the feature extractor is divided into generalized feature extractor $\\Phi_G$ and special feature extractor $\\Phi_S$.\n2) Expandable representation learning: As shown in Fig. 3, our model is composed of a feature extractor $\\Phi = [\\Phi_G, \\Phi_S]$ and task execution module H. In the base station, the generalized feature extractor $\\Phi_G$ will be reused and the special feature extractor $\\Phi_S$ will be expanded. Specifically, given an image $x \\in X$, updated special features are concatenated by old features and new features,\n$\\Phi'_S(x) = [\\Phi_S(\\Phi_G(x)), \\Phi_{Snew} (\\Phi_G(x))],\\qquad(7)$\nwhere $\\Phi_{Snew}$ represents the expanded feature extractor and is encouraged to learn the special features of new tasks. The updated special features are fed into the task execution module to obtain the results of the new task,\n$\\hat{y} = H_{new} (\\Phi'_S(x)).\\qquad(8)$\nFor the learning of incremental SMC, which belongs to the incremental learning of the same task, learning the new task execution module will affect the performance of the old task. To reduce catastrophic forgetting[14], we freeze the parameters of the generalized feature extractor $\\Phi_G$ and the special feature extractor $\\Phi_S$ from the old task model, initialize the new special feature extractor $\\Phi_{Snew}$ with the parameters of the old special feature extractor $\\Phi_S$, and initialize the new task execution module $H_{new}$ with the parameters of the old task execution module H."}, {"title": "Algorithm 1", "content": "Training Incremental SMC\n1: Initialize the classification model using base model\n2: Selecting classification model split points\n3: Add auxiliary special feature extractor $\\Phi_{Snew}$ after the split point\n4: Update the task execution module H to $H_{new}$\n5: Freeze the network parameters except $\\Phi_{Snew}$ and $H_{new}$\n6: Training $\\Phi_{Snew}$ and $H_{new}$ which are called the incremental SMC\nThe base station learns the incremental SMC with the cross-entropy loss on original and incoming data $\\{D\\}$ and $\\{D_{SM}\\}$ as follows,\n$L_{H_{new}} = \\frac{1}{NM}\\sum_{i=0}^{N}\\sum_{c=0}^{M}-Y_{ic}\\log \\hat{Y}_{ic},\\qquad(9)$\nwhere N and M represent the number of samples and the number of categories respectively. To encourage the expanded special feature extractor $\\Phi_{Snew}$ to learn the features of new tasks instead of learning the features of old tasks, the feature semantic distance [18, 19] is introduced to the loss function,\n$L_{\\Phi_S} = |\\Phi_{Snew} (x) - \\sum_{X \\in X} \\Phi_{S}(x) |_2,\\qquad(10)$\nTherefore, the incremental SMC training loss function can be expressed as follow,\n$L_{SM} = L_{H_{new}} - \\lambda L_{\\Phi_S}.\\qquad(11)$\nIn general, SMC can be considered as part of the model with updated parameters, including the expanded feature extractor $\\Phi_{Snew}$ and the new task execution module $H_{new}$. The algorithm for training the incremental SMC is shown in Algorithm 1.\nThe design idea of the Cross-source-domain SMC and Cross-task SMC is consistent with that of the incremental SMC, but the difference is that the Cross-source-domain SMC and Cross-task SMC will not affect the old task."}, {"title": "B. Analysis of the Influence of Noise on SMC", "content": "In the previous section, the training and application of base stations and edge servers separately were considered separately. The impact of channel noise on model transmission was ignored. Although the channel coding method can achieve lossless transmission in a better channel, it needs to add additional redundant information to the transmission information to resist noise. The model itself can be regarded as a new and special information source, which has many redundant parameters. We believe that considering the impact of channel noise from the training and fine-tuning of the model and making full use of model redundancy information will be a more elegant way to resist noise.\nThe robustness of the model to noise from an optimization perspective is analyzed below. AI SMC is mainly composed of convolution layers and fully connected layers, which can be expressed by the following formula,\n$h(W,b) = f(Wx + b),\\qquad(12)$\nwhere f represents activation function, W and b represents the model parameters. The channel interference to the model can be considered as adding noise to the model parameters W and b. The disturbance to the result f(Wx + b) can be expressed as,\n$\\epsilon(W, b) =|| h(W, b) \u2013 h(W + N_W, b + N_b) ||,\\qquad(13)$\nwhere $N_W$ and $N_b$ represent the noise to W and b, respectively. Consider the first-order Taylor-expansion of h(W, b) around W,\nh(W+Nw,b+Nb) = h(W,b)+N_W h'_W(W,b)+N_b h'_b(W, b)+R_2,\\qquad(14)\nwhere $R_2$ is the higher-order residual error of the expansion, $h'_W$ and $h'_b$ represent the gradient of h to W and b, respectively. We hope to find the controllable parameter C(W, b) larger than disturbance $\\epsilon(W, b)$,\n|| h(W, b) \u2013 h(W + N_W,b + N_b) ||\u2264 C(W, b).\\qquad(15)\nAccording to formula 14 and formula 15, we can get\n|| N_Wh\u2019w(W, b) + N_b h\u2019b(W, b) ||\u2264 C(W,b),\\qquad(16)\nwhere $h'_W(W, b)$ and $h'_b(W, b)$ are computable gradients, $N_W$ and $N_b$ are obey Gaussian distribution. Therefore, formula 16 can be transform as,\nC(W,b) \u2248 po || h\u2019w(W, b) + h\u2019b(W, b) ||,\\qquad(17)\nwhere \u03c3 is the variance of the Gaussian distribution, p is a constant, according to the pauta criterion, p = 3 is taken. Therefore, minimizing the C(W, b) is our optimization goal,\n$\\min_{W,b} po || h\u2019w(W, b) + h\u2019b(W, b) ||\\\\\ns.t. || h\u2019w (W, b) ||_\\infty\u2264 \u03c1\u03c3,\\\\|| h\u2019b (W, b) ||_\\infty\u2264 \u03c1\u03c3.\\qquad(18)$\nThe optimization objective encourages the model parameters to enter the noise-insensitive region, which shows the best performance. Under this model parameters, || h(W+Nw,b+ Nb) || is closest to || h(W,b) ||, so the minimum point is surrounded by a flat region."}, {"title": "IV. EXPERIMENTS AND DISCUSSIONS", "content": "Three different experiments for the three types of SMC, including Incremental SMC, Cross-task SMC, and Cross-source-domain SMC mentioned above, have been designed, which are described in detail in the next three subsections."}, {"title": "A. Incremental SMC", "content": "1) Setting: Using the incremental classification SMC as an experimental case, resnet50 is used as the basic model, and the fully connected layer is changed to a pooling layer to reduce the size of the model parameters. The basic model and the SMC are trained on the Cifar-100 dataset [20]. There are 100 classes in the Cifar-100 dataset and 600 images with the size of 32 x 32 for each class, including 500 images as training sets and 100 images as testing sets.\nFirst, a basic model capable of classifying 50 categories is trained, a classification model capable of classifying 60, 70, 80, 90, and 100 categories is trained as a baseline, and then incremental SMCs of 10, 20, 30, 40, and 50 are trained. For loss function settings, \u03bb = 0.01.\n2) Performance: Fig. 5 demonstrates the accuracy of the classification model that can classify 60, 70, 80, 90, and 100 categories and the basic model that can classify 50 categories using 10, 20, 30, 40, and 50 incremental SMC. From these results, it can be found that the classification accuracy of SMC with semantic loss is better than the classification accuracy of SMC without semantic loss. This shows that SMC can better learn incremental features using semantic loss. Hence, incremental SMC can achieve the processing for added tasks. Although the accuracy of the base model with incremental SMC is not as good as the model with 60, 70, 80, 90, and 100 classes of classification itself, the use of incremental SMC can avoid the propagation of the entire model parameters and effectively reduce the model transmission bandwidth. In Fig. 6 (a), the reason that the performance of the model using SMC is better than the base model for 60-class classification is incremental structure makes the semantic model components larger in parameter size than the base model.\nFig. 4 (a) shows the structure of the classification model, which consists of layer blocks, also known as the bottleneck in the Resnet50. The model is partitioned into multiple bottlenecks, and the average CCA of each bottleneck is calculated to obtain CCA metrics for different split points. From Fig. 6 (a), it can be seen as the network structure deepens, the CCA value gradually decreases. According to the meaning of the CCA representation, it indicates that the classification capability of the network which uses SMC with 50 incremental classes and the capability of the network which uses SMC with 30 incremental classes are more similar at the shallow network level. For the SMC with the same incremental setting, i.e., with the same 10, 30, and 50 classification capacity, SMCs with different parameter sizes were prepared by selecting different split points according to the structure of the classification network. When the split points are shallower, the larger range SMC is applied in the network. Correspondingly, the SMC parameter size becomes larger, so the higher the classification accuracy obtained. In addition, when the split point is located before layer block 4, as the split point position deepens, the SMC parameter size decreases, and the accuracy rate decreases slowly. When the split point is located after"}, {"title": "B. Cross-task SMC", "content": "1) Setting: In the experiment, cross-task SMC becomes the bridge between the target detection task and the semantic segmentation task. The basic model and the SMC are trained on the Pennfudan dataset [21], which has 170 images with 345 labeled pedestrians for pedestrian detection and segmentation.\n2) Performance: Taking the two tasks of image segmentation task and target detection task as an example, we add the SMC of image segmentation to the target detection model to make the model have the capability of segmentation. Similarly, the target detection SMC is added to the image segmentation model to enable it to have the target detection ability.\nU-net [22] is used as the base model for image segmentation in the experiments, and the target detection model adds a target detection head to U-net. The basic architecture is referenced from the anchorless target detection model [23]. The anchor-free model transforms target detection into a keypoint detection problem without clustering multiple wide-height anchor parameters on the current training data prior to training by keypoint detection or localizing the centroid of the target object.\nFig. 4(b) shows the structure of the Segmentation SMC model. Using segmentation SMC equips the detection model with the ability to perform the segmentation task. The network is artificially divided into five parts: block 1 layer, block 2 layer, block 3 layer, deconv layer, and FPN layer. We set the split points to calculate the average CCA of each part separately to obtain the parameter similarity of different parts of the network between the target detection task and the image segmentation task. The metric selected here to measure the target detection effectiveness is IoU, which is calculated as follows:\n$IoU = \\frac{Area\\ of\\ Intersection\\ of\\ two\\ boxes}{Area\\ of\\ Union\\ of\\ two\\ boxes}\\qquad(19)$\nFig. 6(b) demonstrates the IoU results with different split points. A model with image segmentation capability is used as the base model, and SMCs with image segmentation are added to the original model for target detection to compare performance. For the detection model, when the split point is located in the FPN layer, the corresponding IoU value is close to 0. It indicates that the original target detection model is little to no capability for image segmentation without using SMC. As the split point gradually moves forward in the network structure, the image segmentation SMCs are gradually expanded in the network, so the image segmentation performance is improved. When the split point is at block 1, the IoU value of the segmentation task is almost the same as the IoU result of the base model. It can be seen that the deeper the network level, the poorer the correlation between network parameters, while the shallow network parameters have a higher similarity. So when we use cross-task SMC in deeper network levels, a larger performance improvement will be achieved. This provides a trade-off between stability and plasticity. Therefore, a better choice of the split point is located at block 3, which has higher performance and saves more bandwidth for model propagation.\nFig 4 (c) is the structure of the detection SMC model. Based on the anchorless model, the target detection SMC was added to the U-net model to make the model have target detection ability. Split points are set at block 1 layer, block 2 layer, block 3 layer, deconv layer and FPN layer to obtain the average value of CCA for the above network structure and use SMCs at different split points to enable target detection. AP 50 and AP 75 are used as a measure of target detection performance; AP 50 means that if the IoU value between the predicted and real boxes is greater than 0.5, the prediction is considered correct, and less than 0.5 is considered incorrect. AP 75, similarly, if the IoU value between the predicted and real boxes is greater than 0.75, the prediction is correct, otherwise it is incorrect.\nAs shown in Fig 6 (c), as the split point is moved forward, the SMC parameter size becomes larger. Correspondingly, the range of SMCs applied in the network expands, so the model performance gains. When the split point is located before block 3, the SMC parameter size decreases. Hence the model performance decreases slowly. When the split point is located after block 3, the model performance decreases rapidly. Considering the transmission efficiency of model propagation and model performance, the best choice is to choose the split point at block 3."}, {"title": "C. Cross-source-domain SMC", "content": "1) Setting: In the experiment, the source SMC overcomes the limitations of domains between different datasets. Take the semantic segmentation task as an example, using deeplab [24] as the basic model. The basic model firstly was trained on the gta5 dataset [25], which contains 24966 synthetic images with pixel-level semantic annotation. Then the source SMC was trained on the Cityscapes dataset [26].\n2) Performance: Fig. 4 (d) shows the structure of the Source SMC model. The deeplab semantic segmentation model is divided into two parts, encoder and decoder. The encoder part consists of resnet18, and the decoder part uses ASPP. The split points are set at layer1, layer2, layer3, and layer4 in the deeplab network, the values of CCA were calculated for each network component above to obtain the similarity between the network parameters applicable to the gta5 dataset and the Cityscapes dataset. The semantic segmentation performance of the network on the Cityscapes dataset is calculated by using SMCs of different sizes, and the mIoU is used as the evaluation metric, which is expressed as the average of the intersection ratio of each class in the dataset.\nFig. 6 (d) demonstrates the mIoU results among different split points. The results trained on the gta5 dataset do not apply to Cityscapes dataset if the source SMC is not used, which illustrates the different domains of different datasets. As the split point gradually moves forward, the source SMC parameter size gradually becomes larger, and correspondingly the mIoU value of semantic segmentation in the Cityscapes dataset becomes higher. When the split point is moved forward from the aspp layer to layer 5, the SMC parameter size increases, and the semantic segment performance gets a substantial improvement, and when it is moved forward again, the performance improvement is gradually slow. This provides a trade-off between stability and plasticity. Therefore, a better choice of the split point is located at layer 5, which has higher performance and saves more bandwidth for model propagation. It is observed that the parameters in deeper layers tend to exhibit higher variance than those in shallow layers, as the former is responsible for capturing more intricate features compared to the latter. Therefore, by only fine-tuning the deeper layers, we can effectively adapt the network to new sources of data without having to retrain the entire network. This approach can be particularly beneficial in scenarios where the available bandwidth for model propagation is limited, such as in mobile or edge computing applications."}, {"title": "D. Impact of the noise on model", "content": "1) Setting: In this section, SMC with 10 incremental classes is used as an example to analyze the effect of channel noise on SMC performance. The second-order loss regularization term from the formula 18 is added to the training loss function and set \u03b2 as the loss trade-off term. The total loss function can be re-described as follows,\n$L_{SM} = L_{H_{new}} \u2013 \\lambda L_{\\phi_S} \u2013 \u03b2 || h\u2019(W, b) + h\u2019_b (W, b) ||.\\qquad(20)$\n2) Performance: The accuracy of image classification at different signal-to-noise ratios was tested by adding noise to 10 incremental SMCs. As shown in Fig. 7, it can be known that at low signal-to-noise ratios, the larger the beta value, i.e., the greater the proportion of the loss function used to resist the noise component in the training process, so the higher the image classification accuracy. At SNR of -1 and -2, using a beta equal to 0.2 is about 3 dB more accurate than classifying images without anti-noise SMC. In contrast, at higher signal-to-noise ratios, the accuracy of the noise-resistant model is essentially the same as that of the model without the noise-resistant SMC when the signal-to-noise ratio is higher than 2. This shows that our model can not affect the model performance under high SNR conditions and effectively resist noise under low SNR conditions."}, {"title": "V. PROTOTYPE AND IMPLEMENTATIONS", "content": "In this section, incremental SMC is applied to unmanned vehicle identification systems, aiming to enlighten and solve the problem of rapid identification of unknown targets by unmanned vehicle systems."}, {"title": "A. Prototype System", "content": "The experimental scheme of the unmanned vehicle identification system is shown in Fig. 8. The prototype system consists of two unmanned vehicles and an edge server. Unmanned vehicles perform target detection and tracking tasks. When unmanned vehicles encounter unrecognized targets, the edge server sends the entire model and the incremental SMC that can identify new targets to unmanned Vehicle 1 and unmanned Vehicle 2, respectively. Unmanned vehicle 1 and unmanned vehicle 2, respectively utilize the received entire models and the SMC to adapt to the dynamic changes of the mission target, reidentify and continue tracking the target."}, {"title": "B. Hardware Platform", "content": "The experimental hardware platform of the prototype is shown in Fig. 9. The edge server is an Intel NUC 11BTMi with a 3080 GPU. The structure of the unmanned vehicle is shown in Fig. 9(b), including a chassis controller, a task controller, an AI inference module, a power module, and a camera. NVIDIA Jetson AGX Orin is selected as the Al inference module, which has 40 TOPS AI computing power. The camera collects image data in real time, and the AI inference module uses the collected data as input data to complete the model inference. The task controller controls the vehicle speed according to the control commands from the AI inference module and sends the commands to the chassis controller through the RS232 serial port."}, {"title": "C. Test Steps and Result Analysis", "content": "The test process is described below,\n\u2022 Establish a basic network environment and set up wireless links(such as WiFi).\n\u2022 The edge server transmits the entire model for the new target to the AI inference module (device A) of unmanned vehicle 1, enabling device A to have the ability to detect new targets. At the same time, the edge server decouples the components of the new target detection model and transfers the model components to device B of the unmanned vehicle 2.\n\u2022 Capture data packets through the software Wireshark to test the amount of data received by device A and embedded device B.\nIn the unmanned vehicle identification new target experiment, the scene is shown in Fig. 10. The three new targets are replaced by posters of aircraft, vehicles, and horses, with unmanned vehicle 1 on the left and unmanned vehicle 2 on the right. From Fig. 10, it can be seen that each time a new target is changed, unmanned vehicle 2, using the SMC transmission scheme, will react more quickly and track the target.\nUsing transmission packet capturing software, we measured that the amount of data transferred by the edge server to the unmanned vehicle 1 and unmanned vehicle 2 was 129.8MB and 36.1MB, and the transmission time was 153s and 44s, respectively."}, {"title": "VI. CONCLUSION", "content": "In semantic communication networks, edge nodes face multi-source and multi-task semantic extraction recovery services. Due to the limitation of storage capacity and computing power, edge nodes need the base station to send corresponding SMCs for parameter updates for different tasks and sources. Model distribution in the form of SMCs is performed to avoid performing all model parameter updates at the edge nodes when facing different scenarios. The base station weighs the model performance and transmission parameter size and then updates some parameters at the edge node through SMC form to save the model parameter transmission time, transmission bandwidth and model update time to some extent. In addition, we propose a method to improve the noise immunity of the model parameters during the propagation process. Finally, a component transfer based unmanned vehicle tracking prototype was implemented to verify the feasibility of model components in practical applications."}]}