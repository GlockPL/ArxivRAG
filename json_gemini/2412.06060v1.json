{"title": "Steering Large Language Models to Evaluate and\nAmplify Creativity", "authors": ["Matthew Lyle Olson", "Neale Ratzlaff", "Musashi Hinck", "Shao-yen Tseng", "Vasudev Lal"], "abstract": "Although capable of generating creative text, Large Language Models (LLMs) are\npoor judges of what constitutes \"creativity\". In this work, we show that we can\nleverage this knowledge of how to write creatively in order to better judge what is\ncreative. We take a mechanistic approach that extracts differences in the internal\nstates of an LLM when prompted to respond \u201cboringly\u201d or \u201ccreatively\u201d to provide\na robust measure of creativity that corresponds strongly with human judgment. We\nalso show these internal state differences can be applied to enhance the creativity\nof generated text at inference time.", "sections": [{"title": "Introduction", "content": "The ability of Large Language Models (LLMs) to evaluate the quality of their own outputs has\nreceived significant attention recently [Xu et al., 2023] due to the widespread desire to make use\nof potential high-quality synthetic data. While it has been argued that LLMs are not good enough\nat self-evaluation to bootstrap themselves into better reasoners [Huang et al., 2023] or forgo real\ndata entirely [Wang et al., 2023], there are scenarios where self-evaluation can enable improved\nperformance [Ren et al., 2023, Yuan et al., 2024, Madaan et al., 2024]. In this work, we show that\nLLM-based self-evaluation with respect to creativity is challenging if approached naively; with LLMs\nself-evaluations but by leveraging the internal representations of an LLM during inference, not only\ncan self-assessment be improved, the creativity of the generation itself can be amplified.\nRecent work in steering language models has shown that LLMs represent concepts as linear directions\nin their activation space [Turner et al., 2023]. Specific directions corresponding to social bias, refusal,\nharmlessness, or humor have been identified by prior work [Ratzlaff et al., 2024, Gao et al., 2024,\nTempleton et al., 2024]. Furthermore, it has been shown that it's possible to remove, or ablate\nthese features from the model via an orthogonal projection of intermediate activations onto a chosen\ndirection. In the case of refusal, a safety-tuned model can have its guardrails effectively removed\n[Arditi et al., 2024], allowing a user to prompt the model in ways that were previously censored.\nConversely, it is also possible to induce a specific feature [Rimsky et al., 2023, Hinck et al., 2024],\nforcing the model to respond in a particular way according to the chosen direction. In this work we\nexplore model steering for creativity, and propose three steps to unlock an LLM's potential for use in\ncreative domains.\n\u2022 We solve for steering directions that correspond to latent concepts of creativity within an\nLLM, we use Llama3-8B and creative writing as our target setting."}, {"title": "2 Method", "content": "Our method has three main components: 1) finding a suitable \u201ccreativity direction\" in activation\nspace, 2) optionally use this direction to steer the LLM to generate creative text, and 3) scoring\nthe creativity of outputs respect to this creativity direction. The established method of computing a\nparticular concept in activation space requires collecting a small dataset of contrastive instructions\n[Marks and Tegmark, 2023], where the only difference between the corresponding completions is the\npresence or absence of the concept in question. In our case, we leveraged the creative writing prompts\ndataset [Fan et al., 2018] to elicit creative generations, and used GPT40 [Achiam et al., 2023] to craft\nuncreative versions of the same prompts to obtain paired creative-uncreative responses. We use the\nvalidation split of the creative writing prompts dataset for finding the attribute, and the test split in\nour evaluation experiments. Details and examples of the dataset can be found in the appendix. Given\na set of paired creative instructions $x_c \\in X$ and uncreative instructions $x_u \\in X_u$, we compute the\ncreative direction as the normalized difference in the average activation vectors at a given layer with\nrespect to the creative and uncreative instructions:\n$a = \\frac{1}{|X_c|} \\sum_{x_c \\in X_c} LLM_l(x_c) - \\frac{1}{|X_u|} \\sum_{x_u \\in X_u} LLM_l(x_u)$,\nwhere $LLM_l$ is the output of the LLM at layer l. The choice of layer is selected empirically; examples\nof the resulting generations when different layers are targeted can be found in the appendix. In this\nwork, we choose layer 8 of Llama3-8B [Dubey et al., 2024] as the target layer. At inference time, we\ncan score the creativity of generated text by computing the cosine similarity between the attribute a\nand the current token:\n$score = \\frac{1}{T+1} \\sum_{t=0}^{T} Cos(||LLM(x_t)||_2, a)$\nwhere T is the total generated tokens, $x_t$ is the token generated at step t, and $x_0$ is the input."}, {"title": "3 Experiments", "content": "Figure 1 shows our three main experiments. First, we use Llama3-8B to generate 3 types of stories:\ncreative story prompts from our dataset, non-creative prompts from GPT4o, and non-creative with the\ncreativity vector added. We find the models often score all stories similarly at about 7 (when asked\nto rate the story from 0 to 9). Next, we show our scoring method is highly effective at identifying\ncreative stories. We compute the score on the test split of the creative / uncreative prompts, and we\nfind the creative stories (as well as uncreative stories with creativity induced) are much more similar\nto the creativity attribute. This result clearly indicates that the LLM internally models creativity\nand can accurately track how creative a given story is. Finally, to verify the efficacy of adding the\ndiscovered creativity attribute, we run pairwise comparisons on the generations of the uncreative\nprompts with and without creativity induced. We find the original model is a poor predictor of its\nown creativity, whereas a large frontier model (Llama3-70b) is on par with a human annotator (with\nagreement > 70%). These results show that a naive approach to LLM self-assessment is not sufficient\nfor identifying creative output.\nFinally, we can steer the LLM to induce increased creativity of generated text by adding the creativity\nattribute to the intermediate activations at the target layer. Intuitively, we are amplifying the contri-\nbution of the model's internal sense of creativity. Note that in this case, the notion of creativity is\nheavily tied to creative writing and common subject matter therein, rather than a general notion of\ncreativity. $LLM'_l(x) = LLM_l(x) + \\lambda * a$, where $LLM'_l(x)$ is effectively a replaced version of the\nlayer and the scalar $\\lambda = 3$ was found manually from early tests."}, {"title": "A Model Details", "content": "We used Llama3-8B as our model of interest, due to its well-rounded abilities in multiple subjects. For\nself-evaluation experiments we used the same Llama3-8B model, and for frontier model evaluations,\nwe used the larger Llama3-70B. All generation hyperparameters can be found in Table 1. To\nensure that we strictly evaluated the effect of our steering method, we set hyperparameters like\nTEMPERATURE and TOP_P to 1.0"}, {"title": "B Model Generation Example", "content": ""}, {"title": "C Contrastive Dataset Details", "content": "It is critical to obtain high quality contrastive pairs of generations to isolate the creativity direction.\nFor positively creative instructions we leverage the creative writing prompts dataset [Fan et al., 2018],\nrandomly sampling 500 writing prompts to obtain creative generations. To obtain baseline, or less\ncreative generations, we use GPT4o to negate the aspects of creativity in our creative instructions."}, {"title": "D Creativity at Different Model Depths", "content": "Model generation behavior can vary wildly when intervened on. We find that earlier layers can fail\nto generate meaningful test when the residual stream is altered. Intervening near the final layers of\nLlama3-8B has little effect on the output. We find that intervening near the middle of the network\nyields a reasonable trade-off of generation quality and introduced creativity."}]}