{"title": "Enhancing Performance of Point Cloud Completion Networks with Consistency Loss", "authors": ["Kevin Tirta Wijaya", "Christofel Rio Goenawan", "Seung-Hyun Kong"], "abstract": "Point cloud completion networks are conventionally trained to minimize the disparities between the completed point cloud and the ground-truth counterpart. However, an incomplete object-level point cloud can have multiple valid completion solutions when it is examined in isolation. This one-to-many mapping issue can cause contradictory supervision signals to the network because the loss function may produce different values for identical input-output pairs of the network. In many cases, this issue could adversely affect the network optimization process. In this work, we propose to enhance the conventional learning objective using a novel completion consistency loss to mitigate the one-to-many mapping problem. Specifically, the proposed consistency loss ensure that a point cloud completion network generates a coherent completion solution for incomplete objects originating from the same source point cloud. Experimental results across multiple well-established datasets and benchmarks demonstrated the proposed completion consistency loss have excellent capability to enhance the completion performance of various existing networks without any modification to the design of the networks. The proposed consistency loss enhances the performance of the point completion network without affecting the inference speed, thereby increasing the accuracy of point cloud completion. Notably, a state-of-the-art point completion network trained with the proposed consistency loss can achieve state-of-the-art accuracy on the challenging new MVP dataset. The code and result of experiment various point completion models using proposed consistency loss will be available at: https://github.com/kaist-avelab/ConsistencyLoss .", "sections": [{"title": "1. Introduction", "content": "Point cloud completion is a 3D reconstruction task of occluded or incomplete point clouds. In recent years, numerous studies [1, 2, 3, 4, 5] have been conducted to leverage deep neural networks to complete occluded object-level point clouds\u00b9. These point cloud completion networks (PCCNs) are often designed to take locally-incomplete point clouds as input and generate complete point clouds as output.\nImprovements of the completion performance of recent PCCNs can primarily be attributed to innovations in network architectures [6, 7, 8], point generation strategies [9, 10, 11], and representations [12]. In contrast, the training strategy employed by existing PCCNs has remained relatively unchanged, that is, to minimize the dissimilarities between the predicted complete point clouds and the ground truths [13], often measured using the computationally efficient Chamfer Distance (CD) metric [14]. Unfortunately, the straightforwardness of such a training strategy is not without a potential drawback: an incomplete point cloud, when inspected independently without additional information, could have multiple valid solutions according to the CD metric."}, {"title": "2. Background", "content": "Optimal training strategy can improve completion performance. The works discussed in Subsection 2.1 mainly focus"}, {"title": "2.1. Related Work", "content": "Traditional approaches [16, 17, 18, 19] for 3D shape completion task often use voxels as the data representation. However, the memory requirement for voxel-based operations grows cubically with respect to the spatial resolution. In contrast, point cloud representation is capable of preserving 3D structure details with low memory requirement, and has become widely-used in many deep learning applications owing to the pioneering works of [20] and [21].\nPCN [6] is one of the first deep learning-based neural networks for point cloud completion. It utilizes an encoder-decoder-folding scheme to learn features from the partial point cloud, and predicts the final reconstructed points with FoldingNet [1]. Since then, numerous network architectures for point cloud completion have been proposed. For example, TopNet [2] utilized softly-constrained decoder that is capable of generating point clouds based on a hierarchical rooted tree structure, and GRNet [22] leveraged gridding operations to enable point cloud to 3D grids transformation without loss of structural information.\nRecently, attention-based architectures have grown in popularity as the go-to architecture for PCCN. For example, PoinTr [7] use a geometry-aware transformer architecture to estimate coarse point predictions before performing refinement via FoldingNet [1], while Seedformer [12] introduces Patch Seeds as a new shape representation which contains seed coordinates and features of a small region in the point cloud.\nZhiang et al. proposed detecting unseen point clouds from partial point clouds using a multi-stage points prediction approach based on point density [23]. The MSCPN method attempts to detect unseen point clouds in multiple stages, utilizing the geometric features of the partial point clouds [24]. Wang et al. proposed predicting unseen point clouds by predicting the geometric edges of the unseen point clouds from the geometric features of the partial point clouds [25]. Zhang et al. suggested predicting unseen point clouds using the geometric shape of the unseen point clouds with skeleton-detailed transformer models [26]. PointAttN [27] introduced a method for predicting incomplete point clouds using fast-computation attention mechanisms for point clouds. AdapointTr [15] aims to predict unseen point clouds by utilizing an adaptive geometry module, while SVD-Former [28] predicts unseen point clouds based on partial point clouds and multi-view image projections of the partial point clouds.\nFSC proposed a novel method for predicting unseen point clouds from very small partial point clouds using a two-stage refinement process for global and local geometric feature prediction. Wu et al. [29] introduced a novel density-aware Chamfer Distance loss to improve the prediction of unseen point clouds, particularly in regions lacking dense known point clouds.\nRecently, some researchers have attempted to predict unseen point clouds from partial point clouds using generative models, particularly diffusion-based models [30]. Lyu et al. proposed generating unseen point clouds from partial point clouds using a conditional diffusion model with the Point Diffusion Paradigm [31]. Zheng et al. suggested using a diffusion model to train point cloud completion networks, leveraging pretrained models from various point cloud completion networks trained on different datasets [32]. Karsten et al. introduced the use of a diffusion model with a text-to-image pretrained model to predict unseen point clouds from semantic patterns in partial point clouds [33]. Yuhan et al. proposed 3DQD, which generates unseen point clouds using a conditional diffusion model based on geometric features of partial point clouds [34]. Romanelis et al. introduced a novel fusion of point-based and voxel-based feature extraction to generate unseen point clouds using conditional diffusion models [35]. While diffusion models can learn the underlying patterns of point clouds from partial point clouds, point cloud completion using diffusion models often requires significant time and computational resources for both training and prediction. In contrast, our proposed consistency loss enables point completion networks to learn features of point clouds from the same ground truth more effectively. As a result, point completion networks trained with our proposed consistency loss can predict unseen point clouds from partial point clouds more accurately, without increasing the prediction time."}, {"title": "2.2. Preliminary Findings", "content": "Optimal training strategy can improve completion performance. The works discussed in Subsection 2.1 mainly focus"}, {"title": "3. Consistency Loss", "content": "In this section, we introduce the completion consistency loss, which we refer to as the consistency loss for brevity from here onward, to mitigate the aforementioned issues. The core idea of the consistency loss is to consider multiple incomplete point clouds originating from the same source object before taking a gradient descent step (Figure 2). Recall that the contradictory supervision signals exist when there are multiple valid completion solutions for one incomplete point cloud that is observed in isolation. Therefore, intuitively, adding more incomplete point clouds with the same completion solution at one observation can reduce the ambiguity and mitigate the negative effects of the issue.\nWe propose two ways to implement the consistency loss: self-guided consistency and target-guided consistency."}, {"title": "3.1. Self-guided Consistency", "content": "In self-guided consistency loss, we leverage the fact that we can generate multiple incomplete point clouds from the same object, and utilize these samples in the consistency loss. Given a complete point cloud $P_{k}^{com}$ representing the object k, we can generate a set of n different incomplete point clouds $P_{k}^{inc} = \\{ p_{k,1}^{inc}, p_{k,2}^{inc}, p_{k,3}^{inc},..., p_{k,n}^{inc} \\}$. Since the source of all incomplete point clouds is the same, that is, $P_{k}^{com}$, the completion solutions for all $p_{k,i}^{inc}$ should also be the same. Therefore, given $\\Phi(p_{k,i}^{inc}) = p_{k,i}^{mis}$ and $p_{k}^{com} = p_{k,i}^{mis} \\cup p_{k,i}^{inc}$, we can guide the network to produce similar completion solutions for any incomplete point clouds originating from $P_{k}^{com}$ through the self-guided consistency,\n$L_{k}^{c-sg} = \\frac{2}{n(n - 1)} \\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} CD(\\Phi(p_{k,i}^{inc}), \\Phi(p_{k,j}^{inc})).$"}, {"title": "3.2. Target-guided Consistency", "content": "For target-guided consistency, we utilize the original ground truth for the consistency loss. As mentioned in Subsection 2.2, the commonly-used loss function is calculated as either $CD(\\Phi(P_{k,i}^{inc}), p_{k}^{com})$ or $CD(\\Phi(P_{k,i}^{inc}), p_{k,i}^{mis})$. While it turned out that the $CD(\\Phi(p_{k,i}^{inc}), p_{k,i}^{mis})$ is advantageous to the completion performance of PCCNs, the formulation does not promote consistency between completions because the supervision is only performed on $p_{k,i}^{mis}$ instead of $p_{k}^{com}$. In target-guided consistency, we propose to keep the approach of predicting only the missing points, but we calculate the loss values based on the full complete point clouds. Specifically, given a complete point cloud $p_{k}^{com}, \\Phi(p_{k,i}^{inc}) = p_{k,i}^{mis}$ and $f_{k,i}^{pcom} = p_{k}^{com} = p_{k,i}^{mis} \\cup p_{k,i}^{inc}$, the target-guided consistency is defined as,\n$L_{k}^{c-tg} = \\frac{1}{n} \\sum_{i=1}^{n} CD(f_{k,i}^{pcom}, p_{k}^{com}).$"}, {"title": "3.3. Complete Loss Function", "content": "The complete loss function for a complete point cloud com with n samples of incomplete point clouds is the combination of conventional reconstruction loss, self-guided consistency loss, and target-guided consistency loss, with scaling factors \\alpha and \\beta,\n$L_{k}^{total} = \\alpha L_{k}^{c-sg} + \\beta L_{k}^{c-tg} + \\sum_{i=1}^{n} L_{rec}^{i},$\nwhere $L_{rec}^{k,i}$ is the reconstruction loss (Equation 1) for $p_{k,i}^{mis}$. We can also further improve the performance of the Point Cloud completion using density- aware chamfer distance loss as [29] with weight of density-aware chamfer distance loss \\delta as below.\n$L_{total, da} = L_{k}^{c-sg} + L_{k}^{c-tg} + \\frac{1}{n} \\sum_{i=1}^{n} L_{rec}^{i}+ \\delta \\cdot L_{da}$\nwhere density-aware chamfer distance loss can be defined from [29] as below.\n$DA-CD(A, B) = \\frac{1}{|A|} \\sum_{a \\in A} \\min_{b \\in B} (1 - e^{-||a - b||_{2}^{2}}) + \\frac{1}{|B|} \\sum_{b \\in B} \\min_{a \\in A}(1 - e^{-||b - a||_{2}^{2}}).$\nNote that both consistency losses do not directly eliminate the one-to-many mapping issue, but they can provide the network with additional information such that the network can mitigate the issue. For a simple example, consider two inputs $p_{1}^{inc}$ and $p_{2}^{inc}$, and the corresponding completion solutions $p_{1}^{com}$ and $\\hat{p_{2}^{com}}$. Suppose that $CD(p_{1}^{inc}, p_{2}^{inc}) \\approx 0$, and $CD(p_{1}^{com}, \\hat{p_{2}^{com}}) >> CD(p_{1}^{inc}, p_{2}^{inc})$, that is, the inputs are similar but the ground truths are dissimilar. Assuming that $\\Phi(p_{1}^{inc})$ is also similar to $\\Phi(p_{2}^{inc})$, then a contradictory supervision signal could arise when we only use $L_{rec}$ as the loss function. On the other hand, suppose that we supplement the loss function with the consistency loss with n = 3 such that the inputs become $\\{p_{1,1}^{inc}, p_{1,2}^{inc}, p_{1,3}^{inc}\\}$ and $\\{p_{2,1}^{inc}, p_{2,2}^{inc}, p_{2,3}^{inc}\\}$ for each ground truth. The effect of the contradictory supervision signal to the gradient descent step can then be suppressed by $L_{k}^{c-sg}$ and $L_{k}^{c-tg}$. We observe that the density-aware Chamfer Distance loss proposed by [29] allows the Chamfer Distance loss to predict unseen point clouds in areas without dense point clouds. In contrast, our proposed consistency loss enhances the point completion network's ability to predict unseen point clouds by detecting underlying point cloud patterns from the same ground truth objects. Therefore, our proposed self-guided and target-guided consistency losses for point completion can also leverage the density-aware Chamfer Distance loss to predict unseen point clouds from partial point clouds. Because proposed consistency loss increase performance of point cloud completion in training then point completion network can predict unseen point clouds with same prediction time with point cloud completion network trained without proposed consistency loss."}, {"title": "4. Experimental Results", "content": "In this section, we demonstrate the effectiveness of the consistency loss by comparing the completion performance of five existing PCCNs on four commonly-used datasets. First, we explain the experimental setups that are needed to reproduce the results. Then, we report and discuss the completion performance of three existing PCCNs trained with and without the consistency loss. We also conduct additional experiments to check the effects of each component in the consistency loss. All code will be available on the github page2."}, {"title": "4.1. Experimental Setup", "content": "There are numerous object-level point clouds datasets, most of which are derived from the Shapenet dataset [41], for example, PCN [6], Completion3D [2], and Shapenet55-34 [7]. Last year Pan Liang et al also proposed novel point completion dataset MVP dataset [42] that consisted more than 100,000 incomplete point clouds with high- quality camera with 26 generated partial point clouds from every ground truth point clouds. The dataset provide 26 generated partial point clouds from 16 different object classes hence will be very good to test our proposed consistency loss for point completion that will increase accuracy of point completion network to predict unseen point clouds from same ground truth object. We choose to evaluate the consistency loss on the PCN, MVP dataset and Shapenet55-34 datasets, following [7, 12, 15].\nPCN consists of around 30K samples of point clouds, spanning over 8 categories: airplane, cabinet, car, chair, lamp, sofa, table, and vessel. On the other hand, Shapenet55-34 consists of around 52K samples of point clouds from 55 categories, resulting in a considerably more diverse set of objects compared with PCN. In Shapenet55, the dataset is split into 41,952 samples for training and 10,518 samples for evaluation, with samples from all 55 categories are present in both training and evaluation splits. Meanwhile in Shapenet34, the dataset is split into 46,765 samples for training and 5,705 samples for evaluation, where the training split consists of samples from 34 categories, and the evaluation split consists of samples from all 55 categories. Shapenet34 can be seen as an evaluation on out-of-distribution data since the 21 extra categories on the evaluation split are withheld during training."}, {"title": "4.1.2. Implementation Details", "content": "The consistency loss is designed to improve a PCCN without any modification to the architecture of the network. Therefore, we used three existing PCCNs, PCN [6], AxFormNet [8], PointAttN [27], SVDFormer [28] and AdaPoinTr [15] to evaluate the effectiveness of the consistency loss. For fairness, we train two versions of all three PCCNs from scratch using publicly-available source codes and the same training strategy, e.g., identical problem formulation, optimizer, number of iterations, batch size, and learning rate schedule. The only difference between the two versions is that whether the consistency loss is incorporated into the loss function or not. For MVP dataset we only test proposed consistency loss for SVDFormer and Ada-PointTr point completion network since only SVDFormer and AdaPointTr network that provides codes for training the model in MVP dataset to make sure our experiment training SVDFormer and AdaPointTr with consistency loss on MVP dataset same with original model .\nAll PCCNs are implemented with PyTorch [43] and trained on RTX 3090 GPUs. The batch sizes are set to 64, 64, and 16 for PCN, AxFormNet, and AdaPoinTr, respectively. We set the number of epochs to 200, 400, and 600 for PCN, AxFormNet, and AdaPoinTr, respectively, utilize cosine annealing [40] for the learning rate schedule, and set n = 3 for the consistency loss. We use Open3D [44] to visualize the point clouds."}, {"title": "4.2. Main Results", "content": "Following [7], we report the CD metric on three difficulty levels for Shapenet55 and the CD metric for PCN in From the results, we can draw the following conclusions."}, {"title": "4.2.1. Quantitative Results", "content": "The consistency loss improves the completion performance of the three PCCNS across the board. As shown in Table 4, the consistency loss can, to some extent, improve the completion performance of the PCCNs in datasets with less diversity such as PCN. However, the consistency loss significantly improves the completion performance of PCN, AxFormNet, and AdaPoinTr on Shapenet55 that consists of objects with diverse geometrical shapes. Specifically, the completion performance is improved by 27%, 25%, and 4.8% for PCN, AxFormNet, and AdaPoinTr, respectively. Similar improvements can also be seen on Shapenet34 (Table 5), in which the mean CD of all three PCCNs trained with the consistency loss are lower or equal to the mean CD of their original counterparts. While in newest point completion dataset MVP dataset we can see that training two state-of-the-art of point completion network AdaPointTr and SVDFormer using consistency loss can increase the performance of point completion network significantly 6 that are 0.19 CD metric decrease for SVD former a 0.06 CD metrics decrease for AdaPointTr. This is because MVP dataset contains hight-quality 26 partial point clouds for every point clouds ground truth hence make point completion network trained using proposed consistency loss can learn semantic and geometric information of partial point clouds from same ground truth.\nThese results demonstrate the effectiveness of the consistency loss for improving the completion performance of existing PCCNs, especially when we are interested in completing a collection of point clouds with diverse geometrical shapes and there are many high quality partial point clouds in same point clouds ground truth.\nThe consistency loss enables fast and accurate point cloud completion. Point cloud completion is often used as an auxiliary task, therefore, the completion process should be fast to avoid unnecessary overhead to the overall process. However, recent PCCNs such as PoinTr [7] and SeedFormer [12] achieve improved completion performance at the expense of inference latency due to the complex design of the network."}, {"title": "4.2.2. Qualitative Results on Shapenet55 and Shapenet34", "content": "We visualize the completion results of PCN and AdaPointTr on point clouds from the Shapenet55-test and the Shapenet34-unseen splits in Figure 3 and Figure 4, respectively. For each object, we use 25% of the points in the point cloud as inputs, which is equivalent to the hard setup in [7]. As shown in the figures, networks that are trained with the consistency loss (Ada-PointTr+con and PCN+con) predict completed point clouds with equal or better quality compared to the networks that are trained without the consistency loss. For example, on row 1 in Figure 3, AdaPointTr+con can predict the surface of a table with more consistent point density with respect to the ground truth compared to point completion network AdaPointTr trained without proposed consistency loss. And PCN+con can predict the complete surface of a table, whereas the surface of a table predicted by PCN contains a missing part on the left side. We observe that the state-of-the-art point completion network Ada-PointTr, when trained on the challenging MVP dataset with the proposed consistency loss, predicts unseen point clouds more accurately than AdaPointTr trained without the proposed consistency loss. As shown in the prediction results in 7, AdaPointTr trained with the proposed consistency loss can accurately predict unseen point clouds, even in regions with low point density. In contrast, the point completion network trained without the consistency loss struggles to predict unseen point clouds accurately in such sparse areas. This improvement is due to the challenging MVP dataset, which contains high-quality 26 multi-view point clouds derived from the same ground truth. As a result, the state-of-the-art AdaPointTr network trained with consistency loss can better learn the underlying geometric patterns of partial point clouds from the same ground truth point clouds."}, {"title": "4.3. Effect of the Number of Points for Consistency Loss on Point Cloud Completion Performance", "content": "We conducted experiments to evaluate the effect of the number of points used for consistency loss (n) on the performance of point cloud completion. Using the ShapeNet-55 dataset with 25 As shown in Figure 7, the performance of both SVDFormer and AdaPointTr point completion networks improves as the number of point clouds for consistency loss increases. Specifically, SVDFormer's Chamfer Distance metric improved from 1.302 to 1.2731, and AdaPointTr's improved from 1.2802 to 1.2588. The performance of the point completion networks increased significantly when the number of point clouds for consistency loss was n = 2, 3, and 4. However, when the number of point clouds for consistency loss was increased to n = 6 and 12, the performance improvement was not significant. This indicates that the optimal number of point clouds for consistency loss, which maximizes performance while minimizing computational cost, is n = 3."}, {"title": "4.4. Effect of the Number of Points for Consistency Loss on Point Cloud Completion Training Time", "content": "We also examined the effect of varying the number of point clouds for consistency loss on the training time of point completion networks. In this experiment, we trained state-of-the-art point completion networks, SVDFormer and AdaPointTr, using a batch size of 12 with different numbers of point clouds for consistency loss on the ShapeNet-55 dataset. We used a batch size of 6 for n = 2, a batch size of 4 for n = 3, and so forth, ensuring that both SVDFormer and AdaPointTr were trained on 12 different point clouds per batch.\nFigure 7 shows that training the point completion networks with the proposed consistency loss led to a modest increase in training time. For instance, the training time of SVDFormer increased from 641.02 ms to 709.21 ms per batch (an increase of approximately 10.63\nThis significant increase in training time is due to the additional computation required for the proposed self-guided consistency loss, which involves calculating the correlation of point completion predictions with every prediction from the same ground truth data. As the number of point clouds for consistency loss increases, these calculations grow quadratically, leading to longer training times. From these experiments on the effects of the number of points for consistency loss on both point completion performance and training time, we conclude that the best balance between performance improvement and training efficiency is achieved when the point cloud completion networks are trained with n = 3 point clouds for consistency loss."}, {"title": "4.5. Additional Results", "content": "In the following subsection we show additional results from experiments with AxFormNet to further investigate the effects of the consistency loss. We limit the scope of the experiments to the hardest setup of ShapeNet55 during training and evaluation.\nScaling Factors for  \ud835\udc3f\ud835\udc50\u2212\ud835\udc60\ud835\udc54  and  \ud835\udc3f\ud835\udc50\u2212\ud835\udc61\ud835\udc54 . We also investigate the effect of scaling factors \u03b1 and \u03b2 in Equation 5 as shown in Table 7. As a baseline, we use the AxFormNet network trained to predict the missing point clouds as in Table 2, this is equivalent to \u03b1 = \u03b2 = 0. First, we investigate the individual effect of each component in the consistency loss. From the table we can see that both  \ud835\udc3f\ud835\udc50\u2212\ud835\udc61\ud835\udc54  (\u03b2 = 1) and  \ud835\udc3f\ud835\udc50\u2212\ud835\udc60\ud835\udc54  (\u03b1 = 1) improve the completion accuracy, with  \ud835\udc3f\ud835\udc50\u2212\ud835\udc61\ud835\udc54  bringing more benefits compared with  \ud835\udc3f\ud835\udc50\u2212\ud835\udc60\ud835\udc54 . However, when both are used with the same scaling factors (i.e., \u03b1 = \u03b2 = 1), the completion accuracy is worse than when only  \ud835\udc3f\ud835\udc50\u2212\ud835\udc61\ud835\udc54  is used. From experimental results, we see that setting \u03b1 = 0.1 and \u03b2 = 1 yield the best completion accuracy."}, {"title": "5. Conclusion", "content": "We have proposed the completion consistency loss, a novel loss function for point cloud completion. The completion consistency loss has been designed to reduce the adverse effects of contradictory supervision signals by considering multiple incomplete views of a single object in one forward-backward pass. We have demonstrated that the completion consistency loss can improve the completion performance and generalization capability of existing point cloud completion networks without any modification to the design of the networks. Moreover, simple and fast point cloud completion networks that have been trained with the proposed loss function can achieve completion performance similar to more complex and slower networks. Therefore, the completion consistency loss can pave the way for accurate, fast, and robust point cloud completion networks."}, {"title": "CRediT authorship contribution statement", "content": "Kevin Tirta Wijaya: Conceptualization, Data curation, Formal analysis, Methodology, Software, Validation, Visualization, Writing - original draft. Christofel Rio Goenawan: Conceptualization, Formal Analysis, Investigation, Software, Validation, Visualization, Writing \u2013 review & editing. Seung-Hyun Kong: Conceptualization, Funding acquisition, Project administration, Resources, Supervision."}, {"title": "Declaration of competing interest", "content": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."}, {"title": "Data availability", "content": "Data and experiment code and result will be made available on request."}, {"title": "Appendix A. Generating Toy Datasets", "content": "The toy datasets that are used in Subsection 2.2 are generated by following Algorithm 1. CD is the chamfer distance function defined in Equation 7."}]}