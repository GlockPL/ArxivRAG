{"title": "Superhypergraph Neural Networks and Plithogenic Graph Neural Networks: Theoretical Foundations", "authors": ["Takaaki Fujita"], "abstract": "Hypergraphs extend traditional graphs by allowing edges to connect multiple nodes, while superhypergraphs further generalize this concept to represent even more complex relationships. Neural networks, inspired by biological systems, are widely used for tasks such as pattern recognition, data classification, and prediction.\nGraph Neural Networks (GNNs), a well-established framework, have recently been extended to Hypergraph Neural Networks (HGNNs), with their properties and applications being actively studied. The Plithogenic Graph framework enhances graph representations by integrating multi-valued attributes, as well as membership and contradiction functions, enabling the detailed modeling of complex relationships.\nIn the context of handling uncertainty, concepts such as Fuzzy Graphs and Neutrosophic Graphs have gained prominence. It is well established that Plithogenic Graphs serve as a generalization of both Fuzzy Graphs and Neutrosophic Graphs. Furthermore, the Fuzzy Graph Neural Network has been proposed and is an active area of research.\nThis paper establishes the theoretical foundation for the development of SuperHyperGraph Neural Networks (SHGNNs) and Plithogenic Graph Neural Networks, expanding the applicability of neural networks to these advanced graph structures. While mathematical generalizations and proofs are presented, future computational experiments are anticipated.", "sections": [{"title": "Introduction", "content": ""}, {"title": "Hypergraphs and Superhypergraphs", "content": "Graph theory, a pivotal area of mathematics, focuses on understanding networks composed of vertices (nodes) and edges (connections)[100, 102]. These mathematical structures effectively model relationships, dependencies, and transitions among elements, making them versatile tools across various domains [45,58,95,156].\nThe foundational significance of graph theory has spurred its development and application in numerous disciplines, including:\n\u2022 Computational Sciences: Graphs are essential in designing circuits and optimizing computational workflows, as highlighted in recent studies on graph-based optimization techniques [40, 41, 405].\n\u2022 Chemistry and Biology: Chemical graph theory models molecular structures and interactions [42, 380], while bioinformatics leverages graphs to study protein structures and gene interactions [6,373,377].\n\u2022 Project Management: Graphs are utilized to analyze workflows and dependencies, facilitating efficient resource allocation and scheduling in project management frameworks [202,296,368].\n\u2022 Probabilistic Modeling: Bayesian networks employ graph structures to represent conditional dependencies among random variables [277,418].\n\u2022 Graph Databases: Modern data storage and retrieval systems increasingly rely on graph databases for their ability to model complex relationships effectively [21,22,31,141,166,261, 304].\nA hypergraph is a generalization of a conventional graph, extending and abstracting concepts from graph theory [51,60, 152, 153, 164]. Hypergraphs have wide-ranging applications across fields such as machine learning, biology, social sciences, and graph database analysis, among others (e.g., [69, 85, 139, 187, 232, 403, 427, 443]). From a set-theoretic perspective, a hypergraph can, without risk of misunderstanding, be viewed as the powerset of its vertex set.\nThe concept of SuperHyperGraph has recently emerged as a more general extension of hypergraphs, generating substantial research interest similar to that seen in the study of hypergraphs[126,130,340]. Numerous investigations have been carried out in this field [122, 126, 128, 130, 170, 171, 340, 341, 343,346,351].\nA Superhypergraph is a type of Superhyperstructure. It can be regarded as an extension of the concept of an n-th-Power Set[331] applied to graphs. The definitions of Superhyperstructure and n-th Power Set are provided below."}, {"title": "Graph Neural Networks", "content": "This subsection provides an overview of Graph Neural Networks. In recent years, fields such as machine learning (cf. [28,186,273,304, 405, 419]), artificial intelligence (cf. [5,34,321,374]), and big data (cf. [49,79, 200,257]) have gained significant prominence. This paper focuses on neural networks, which play a pivotal role in these domains.\nA neural network is a computational model inspired by biological neural systems, designed for tasks such as pattern recognition, data classification, and prediction [20,25,46,223,393,411,412]. Building upon this foundation, a Graph Neural Network (GNN) extends neural networks to graph structures, enabling the modeling of relationships between nodes, edges, and their associated features [94, 205, 269, 297, 316, 324, 386, 404, 429, 440, 447].\nBuilding on this concept, Hypergraph Neural Networks (HGNNs) extend traditional Graph Neural Networks (GNNs) by leveraging hyperedges to capture higher-order relationships that involve multiple nodes simultaneously [70, 115, 181, 183, 204,369,401]. Related concepts include Hypernetworks, which have been studied extensively in works such as [76,167,225,363,388]. Additionally, networks built on directed graphs, such as Directed Graph Neural Networks [177\u2013179,325,450], and those based on mixed graph structures, such as Mixed Graph Neural Networks [163], are also well-known.\nGiven the wide range of applications studied in these areas, research into Graph Neural Networks is of critical importance."}, {"title": "Uncertain graphs", "content": "The concept of fuzzy sets was introduced in 1965 [430]. Fuzzy sets provide a framework for addressing uncertainty in the real world and have been applied in various fields, including graph theory, algebra, topology, and logic. Furthermore, extensions of fuzzy sets, such as neutrosophic sets [332, 334], have been developed to handle even more complex forms of uncertainty.\nThese concepts for handling uncertainty are highly compatible with real-world applications[47,208,235, 263,270,278,322]. For instance, neutrosophic sets extend fuzzy sets by introducing three membership degrees: truth, indeterminacy, and falsity, making them particularly valuable in scenarios with incomplete or conflicting information. Applications include:\n\u2022 Healthcare Decision-Making: Neutrosophic sets assist in evaluating treatment options by balancing effectiveness (truth), uncertainty (indeterminacy), and risk (falsity) when data is incomplete or contradictory [29, 196].\n\u2022 Social Network Analysis: They model relationships between users, such as trust, suspicion, and disagreement, in social networks [108,253, 309, 382].\n\u2022 Fault Diagnosis in Engineering: Neutrosophic sets identify faults in mechanical systems by accounting for uncertain and conflicting diagnostic evidence (cf.[155,226, 326]).\n\u2022 Market Analysis: Businesses use them to analyze customer preferences, integrating positive feedback (truth), ambiguous responses (indeterminacy), and negative feedback (falsity) [43, 264, 312].\nThis paper examines various models of uncertain graphs, including Fuzzy, Intuitionistic Fuzzy, Neutrosophic, and Plithogenic Graphs. These models extend classical graph theory by incorporating degrees of uncertainty, enabling a more nuanced analysis of ambiguous and complex relationships [120,121,123\u2013127,129, 131, 132].\nExamples of uncertain graph models include the following:\n\u2022 Fuzzy Graph: A Fuzzy Graph utilizes membership functions to represent uncertainty in vertices and edges, enabling more flexible modeling of relationships [8, 10, 12, 274, 306].\n\u2022 Neutrosophic Graph: A Neutrosophic Graph extends Fuzzy Graphs by incorporating truth, indeterminacy, and falsity degrees for vertices and edges, offering a richer data representation [26, 63, 192,272,371,372, 420]. It is well known that Neutrosophic Graphs can generalize Fuzzy Graphs.\n\u2022 Plithogenic Graph: The Plithogenic Graph framework models graphs with multi-valued attributes using membership and contradiction functions, providing a detailed representation of complex relationships [121,338,357]. It is widely recognized that Plithogenic Graphs can generalize Neutrosophic Graphs.\nThese concepts, including set-based approaches, are applied in decision-making [18] as well as in neural networks [24, 112, 113, 416, 442] and machine learning[96, 142, 238, 246]. This highlights the importance of studying concepts related to uncertain graphs.\nFor reference, the relationships between Uncertain graphs are illustrated in Figure 2 (cf. [126]). Since Figure 2 is a highly simplified diagram, readers are encouraged to refer to the literature, such as [126], for further details if necessary."}, {"title": "Our Contribution", "content": "This subsection highlights the key contributions of our work. While Graph Neural Networks (GNNs) for hypergraphs have been extensively studied, no previous research has explored the development of GNNS tailored to SuperHyperGraphs.\nIn this paper, we introduce the SuperHyperGraph Neural Network (SHGNN), a mathematical extension of Hypergraph Neural Networks that leverages the unique structural properties of SuperHyperGraphs. Additionally, we examine uncertain graph neural models, such as Neutrosophic Graph Neural Networks and Plithogenic Graph Neural Networks, which address similar challenges. Importantly, we demonstrate that both Neutrosophic and Plithogenic Graph Neural Networks serve as mathematical generalizations of Fuzzy Graph Neural Networks.\nThis work is theoretical in nature, focusing on establishing the mathematical framework for SHGNNS and PGNNs. It does not include computational experiments or practical implementations. Therefore, we hope that computational experiments will be conducted in the future by experts and readers alike. For precise definitions and detailed notations, readers are encouraged to consult the relevant literature, such as [115].\nIn this paper, we conduct a theoretical examination of the relationships between Graph Neural Networks, as illustrated in Figure 3. This diagram illustrates that the concept at the arrow's origin is included in (and generalized by) the concept at the arrow's destination.\nAlthough not directly related to the Graph Neural Networks discussed earlier, this paper also explores several extended concepts in hypergraph theory, including Multilevel k-way Hypergraph Partitioning, Superhypergraph Random Walk, and the Superhypergraph Tur\u00e1n Problem. As these investigations are limited to theoretical considerations, it is hoped that computational experiments and practical validations will be conducted in the future as needed."}, {"title": "The Structure of the Paper", "content": "The structure of this paper is as follows."}, {"title": "Preliminaries and Definitions", "content": "In this section, we provide a brief overview of the definitions and notations used throughout this paper. While we aim to make the content accessible to readers from various backgrounds, it is not possible to cover all relevant details comprehensively. Readers are encouraged to consult the referenced literature for additional information as needed."}, {"title": "Basic Graph Concepts", "content": "This subsection outlines foundational graph concepts. For a comprehensive understanding of graph theory and notations, refer to [100-102, 158, 406]. Additionally, when discussing graph theory, basic set theory concepts are often used. Readers are encouraged to consult references such as [117, 182, 201, 389] as needed."}, {"title": "Basic Definitions of Algorithm Complexity", "content": "This subsection introduces fundamental definitions for analyzing the algorithms described in later sections."}, {"title": "Basic Graph Neural Network Concepts", "content": "Here are several definitions of Graph Neural Networks (GNNs). Readers may refer to the lecture notes or the introduction for further details(cf.[3,94,111,205,269,297,316,324,415,440])."}, {"title": "Hypergraph Concepts", "content": "A hypergraph extends the concept of a traditional graph by allowing edges, called hyperedges, to connect any number of vertices, rather than being restricted to pairs[51,140,152\u2013154]. This flexibility makes hypergraphs highly effective for modeling complex relationships in various domains, such as computer science and biology [114, 148, 195,294]. The formal definitions are provided below."}, {"title": "SuperHyperGraph", "content": "A SuperHyperGraph is an advanced structure extending hypergraphs by allowing vertices and edges to be sets. The definition is provided below [340, 341]."}, {"title": "HGNN:Hypergraph Neural Network", "content": "The Hypergraph Neural Network is a concept designed to utilize the general Graph Neural Network at a higher level, and it has been studied extensively across numerous frameworks and concepts[115,229,231,236, 239, 239, 244, 410, 425, 426]. The definitions are provided below."}, {"title": "Uncertain Graph", "content": "The concept of the Fuzzy Set, introduced approximately half a century ago, has spurred the development of various graph theories aimed at modeling uncertainty[430]. In this section, we outline definitions for several frameworks, including Fuzzy Graphs, Intuitionistic Fuzzy Graphs, Neutrosophic Graphs, and Single-Valued Pentapartitioned Neutrosophic Graphs.\nA Fuzzy Graph is frequently analyzed in the context of a Crisp Graph [121]. To provide a foundation, we begin by presenting the definition of a Crisp Graph [121]."}, {"title": "Result: SuperHypergraph Neural Network", "content": "In this section, we explore the SuperHyperGraph Neural Network."}, {"title": "SuperHypergraph Neural Network", "content": "In this subsection, we explore the definition and theoretical framework of the SuperHypergraph Neural Network. This concept is a mathematical extension of the Hypergraph Neural Network. It is important to note that this study is purely theoretical, with no practical implementation or testing conducted on actual systems."}, {"title": "Algorithm for SuperHypergraph Neural Network (SHGNN)", "content": "We present a detailed algorithm for implementing the SuperHypergraph Neural Network (SHGNN), along with an analysis of its time and space complexity. The algorithm is described below."}, {"title": "n-SuperHyperGraph Neural Network", "content": "A SuperHyperGraph can be generalized to an n-SuperHyperGraph. This is defined based on the concept of the n-th powerset. The formal definition is provided below."}, {"title": "Dynamic Superhypergraph Neural Network", "content": "In this subsection, we define the Dynamic Superhypergraph Neural Network, building upon the concept of the Dynamic Hypergraph Neural Network [204]. A Dynamic Hypergraph Neural Network models evolving relationships within hypergraphs, learning from time-varying node and hyperedge interactions to facilitate dynamic data analysis (cf. [172, 210, 240, 395, 400, 454]). The Dynamic Hypergraph Neural Network can also be viewed as an extension of dynamic graph neural networks[118,159,237,361] to the domain of hypergraphs. The definitions and theorems of related concepts are provided below."}, {"title": "Multi-Graph Neural Networks and Their Generalization", "content": "Multi-Graph Neural Networks have been proposed in recent years[421]. However, we demonstrate that they can be mathematically generalized within the framework of n-SuperHyperGraph Neural Networks. Below, we present the relevant definitions and theorems, including related concepts."}, {"title": "Revisiting Definitions for SHGNN", "content": "In this subsection, we revisit several definitions relevant to the SuperHyperGraph Neural Network (SHGNN). Specifically, we briefly examine concepts such as the SuperHyperGraph Laplacian, SuperHyperGraph Convolution, SuperHyperGraph Clustering, and SuperHyperGraph Degree Centrality."}, {"title": "SuperHyperGraph Laplacian", "content": "The SuperHyperGraph Laplacian can be specifically defined as follows. We prove that it generalizes the HyperGraph Laplacian. For clarity, the Graph Laplacian is a matrix representing a graph's structure, used to analyze connectivity and spectral properties (cf.[282,438])."}, {"title": "SuperHyperGraph Convolution", "content": "Define SuperHyperGraph Convolution and examine its relationship with HyperGraph Convolution. For clarity, Graph Convolution is an operation aggregating node features and their neighbors' information, capturing graph structure for learning (cf.[390, 444, 455])."}, {"title": "SuperHyperGraph Clustering", "content": "Define SuperHyperGraph Clustering and examine its relationship with HyperGraph Clustering[67, 138, 227, 230]. Note that graph clustering partitions a graph into groups of nodes (clusters) such that nodes within the same cluster are highly connected [381,391,424]."}, {"title": "Degree Centrality in Superhypergraph", "content": "We discuss the concept of degree centrality in a superhypergraph. Degree centrality measures the importance of a node in a graph by counting the number of direct connections (edges) it has (cf.[37,441])."}, {"title": "n-SuperHyperGraph Attention", "content": "We provide precise mathematical definitions of Hypergraph Attention and extend it to n-SuperHyperGraphs, defining the n-SuperHyperGraph Attention mechanism. Note that graph Attention leverages attention mechanisms to dynamically weigh neighbor nodes, enhancing message-passing efficiency and representation learning in graph neural networks (cf.[61,68,318,385,398,399])."}, {"title": "Result: Uncertain Graph Neural Networks", "content": "In this section, we explore uncertain graph networks, including Fuzzy Graph Neural Networks, Neutrosophic Graph Neural Networks, and Plithogenic Graph Neural Networks."}, {"title": "Neutrosophic Graph Neural Network (N-GNN)", "content": "In this subsection, we define the concept of the Neutrosophic Graph Neural Network (N-GNN) and demonstrate how it generalizes the Fuzzy Graph Neural Network (F-GNN). This framework extends the Fuzzy Graph Neural Network by incorporating the structure of Neutrosophic Graphs. The following sections provide the formal definitions and related theorems."}, {"title": "Plithogenic Graph Neural Network (P-GNN)", "content": "Next, we define the Plithogenic Graph Neural Network (P-GNN) and show how it generalizes both N-GNN and F-GNN."}, {"title": "Other SuperHyperGraph Concepts", "content": "In this section, we explore concepts related to SuperHyperGraphs that are not directly connected to the topics discussed above."}, {"title": "Multilevel k-way Hypergraph Partitioning", "content": "Multilevel graph partitioning is an approach to divide a graph into smaller parts by iteratively coarsening, partitioning, and refining it for optimization [81,147,216,217]. In Hypergraph Theory, concepts such as Multilevel Hypergraph Partitioning [214, 215] and Multilevel k-way Hypergraph Partitioning[35,218,305,317,379] are frequently studied. These concepts are well-known for their applications in fields like VLSI design. This section considers the definition of Multilevel k-way n-SuperHyperGraph Partitioning."}, {"title": "Superhypergraph Random Walk", "content": "A Graph Random Walk is a discrete-time Markov chain where transitions between vertices follow edge-based probabilities, modeling stochastic processes on graphs [83,408]. These concepts have been extended to hypergraphs, leading to the development of Hypergraph Random Walks[74,82,105,174,275]. In this subsection, we extend Hypergraph Random Walks to the domain of Superhypergraphs. The related definitions and theorems are provided below."}, {"title": "Superhypergraph Tur\u00e1n Problem", "content": "The Hypergraph Tur\u00e1n Problem [165,219,241] aims to determine the maximum number of edges in a uniform hypergraph (cf.[184, 185, 203]) on n vertices while avoiding a specific forbidden subhypergraph. This concept is extended to superhypergraphs, and their characteristics are briefly examined. The relevant definitions and theorems are presented below."}, {"title": "Binary decision n-superhypertree", "content": "A Binary Decision Hypertree is a rooted acyclic graph representing Boolean function evaluations, branching on variables with outputs at leaves [168, 169]. This concept is extended to the superhyper framework. The definitions and theorems are provided below."}, {"title": "Future Directions of this Research", "content": "This section highlights potential future directions for this research. A key objective is the practical implementation and experimental validation of the SuperHyperGraph Neural Network (SHGNN). Through computational experiments, we hope to discover related concepts that make the SHGNN more suitable for practical applications.\nAnother promising avenue is the exploration of extensions to SuperHyperGraph Neural Networks incorporating Fuzzy sets [306, 430\u2013437] and Neutrosophic sets [126, 133, 134, 332\u2013337,353,356, 359]. This includes developing and validating frameworks such as Fuzzy SuperHyperGraph Neural Networks and Neutrosophic SuperHyperGraph Neural Networks. These frameworks aim to generalize Fuzzy Neural Networks [176, 242, 250, 365, 366] and Neutrosophic Neural Networks [194] by integrating the structural advantages of hypergraphs, laying the groundwork for advanced representations and computations. Additionally, future research could explore considerations involving Directed SuperHyperGraphs and their applications [126].\nIn addition to the concepts mentioned above, numerous frameworks for handling uncertainty, such as Soft Set (Soft Graph) [127,254, 266], hypersoft set[2, 119, 131, 180, 314, 323, 344], Rough Set (Rough Graph) [288-293], Hyperfuzzy set[126,143,207,362], and Plithogenic Set (Plithogenic Graph) [121,132,338,339,357], are well-known in the literature. Future research could explore how these concepts behave when applied to Graph Neural Networks, Hypergraph Neural Networks, and SuperHyperGraph Neural Networks. Such investigations could also shed light on whether these extensions result in more efficient and effective networks. This area holds significant potential for advancing understanding and innovation."}]}