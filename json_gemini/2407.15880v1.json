{"title": "Diff4VS: HIV-inhibiting Molecules Generation with Classifier Guidance Diffusion for Virtual Screening", "authors": ["Jiaqing Lyu", "Changjie Chen", "Bing Liang", "Yijia Zhang"], "abstract": "The AIDS epidemic has killed 40 million people and caused serious global problems. The identification of new HIV-inhibiting molecules is of great importance for combating the AIDS epidemic. Here, the Classifier Guidance Diffusion model and ligand-based virtual screening strategy are combined to discover potential HIV-inhibiting molecules for the first time. We call it Diff4VS. An extra classifier is trained using the HIV molecule dataset, and the gradient of the classifier is used to guide the Diffusion to generate HIV-inhibiting molecules. Experiments show that Diff4VS can generate more candidate HIV-inhibiting molecules than other methods. Inspired by ligand-based virtual screening, a new metric DrugIndex is proposed. The DrugIndex is the ratio of the proportion of candidate drug molecules in the generated molecule to the proportion of candidate drug molecules in the training set. This metric is crucial for ensuring that the generated molecules possess characteristics that are conducive to drug design. Additionally, through our experiments, we report and discuss a new phenomenon observed during virtual screening processes. We found that molecules generated by current molecule generation models exhibit a lower proportion of high similarity to known drug molecules compared to real molecules. We call it Degradation in molecule generation. Based on the data analysis, the Degradation may result from the difficulty of generating molecules with a specific structure in the generative model. Our research contributes to the application of generative models in drug design from method, metric, and phenomenon analysis.", "sections": [{"title": "I. INTRODUCTION", "content": "The AIDS epidemic is a grave global public health issue today, having resulted in approximately 40 million deaths. Moreover, AIDS places a significant strain on economic progress and contributes to the stigmatization of specific groups [1]. Despite the availability of diverse anti-HIV medications, challenges such as adverse effects, drug resistance, and exorbitant treatment costs persist. Consequently, the discovery of novel HIV-inhibiting compounds stands as an urgent and imperative endeavor [2].\nWith the development of deep learning, researchers began to try to use neural network models to generate specific content, such as images or text. VAE(Variational Autoencoders) [3],GAN(Generative Adversarial Networks) [4], Diffusion [5], [6], and other generative models have shown powerful capabilities. At the same time, several molecular generation models have been proposed, such as charRNN [7], JT-VAE [8], LatentGAN [9], DiGress [10]. The application of generative models in drug design is a valuable research direction [11].\nVirtual screening is a mature computer-aided drug design technique that plays a crucial role in modern drug discovery pipelines [12]. Ligand-based virtual screening methods are employed to identify novel hit candidates by retrieving compounds with high similarity to known drug molecules. A recent study combines molecular generative models with virtual screening and has made some progress [13].\nIn this paper, we introduce a pioneering approach: Classifier Guidance Diffusion for virtual screening, termed Diff4VS. This method enhances the model's capability to generate molecules that are more similar to known drugs, thereby increasing the proportion of HIV-inhibiting candidates. By integrating classifiers to guide the generative process, Diff4VS represents a significant advance in molecule generation models for virtual screening. Comparison experiments show that our method generates more HIV-inhibiting candidates than other methods. Ablation experiments show that Classifier Guidance with Binary Cross Entropy(BCE) Loss is effective.\nBesides, evaluating the performance of molecular generative models remains a formidable challenge [14]. Traditional metrics often fall short in capturing the nuanced requirements of drug-likeness, which is paramount in the practical application of generated molecules. Inspired by ligand-based virtual screening, a new metric DrugIndex is proposed. The DrugIndex is the ratio of the proportion of candidate drug molecules in the generated molecule to the proportion of candidate drug molecules in the training set. This metric is crucial for ensuring that the generated molecules possess characteristics that are conducive to drug design.\nAdditionally, through our experiments, we report and discuss a new phenomenon observed during virtual screening processes. We found that molecules generated by current molecule generation models exhibit a lower proportion of high similarity to known drug molecules compared to real molecules. We call it Degradation in molecule generation. Based on the data analysis, the Degradation may result from the difficulty of generating molecules with a specific structure in the generative model.\nIn summary, the contributions of this paper are summarized as follows:"}, {"title": "II. RELATED WORK", "content": "A. Variational Autoencoders for Molecule Generation\nThe core idea of Variational Autoencoders(VAE) [3] is to map the input data to latent variables in the latent space via an encoder and the latent variables back to the original data space via a decoder. Both encoders and decoders are neural network models trained to maximize the similarity between the original data and the reconstructed data. Researchers have proposed several VAE models that can generate molecules, such as JT-VAE [8]. Conditional Variational Autoencoder(cVAE) [15] is an extended model based on VAE to generate samples with conditions.\nB. Generative Adversarial Networks for Molecule Generation\nThe working principle of Generative Adversarial Networks(GAN) [4] is based on the idea of adversarial training from game theory. The generator receives random noise as input and tries to generate samples similar to the real data. The classifier, in turn, receives both real samples and samples generated by the generator and tries to distinguish their sources. During the training process, the generator gradually improves the quality of the generated samples. At the same time, the classifier improves the accuracy of discrimination by continuously distinguishing between real data and generated data. Researchers have proposed several GAN models that can generate molecules, such as LatentGAN [9]. Conditional Generative Adversarial Networks (cGAN) is a variant of GAN.\nC. Diffusion Models For Molecule Generation\nThe Diffusion model [5], [6] constructs two parameterized Markov chains to diffuse the data with predefined noise and reconstruct the desired samples from the noise. In the forward chain, the Diffusion model gradually adds pre-designed noise to real samples until the samples conform to a specific distribution, such as a Gaussian distribution. At the same time, real samples and noisy samples are used to train a neural network to predict the distribution of noise. Starting from the specific distribution, the reverse chain uses a trained neural network to sample noise from the predicted distribution and remove the noise from samples. Researchers have proposed several Diffusion models that can generate molecules, such as DiGress [10]."}, {"title": "III. METHOD", "content": "In this section, we provide a detailed introduction to our proposed method, Diff4VS. As shown in Fig. 1, our method mainly consists of four parts. We introduce them in Section III-A, Section III-B, Section III-C and Section III-D. Then we introduce our new metric in Section III-\u0395.\nA. Diffusion for Virtual Screening\nLigand-based virtual screening detects molecules similar to known drugs from datasets. However, it is limited by molecular datasets. If there is a lack of molecules similar to known drugs in the dataset, virtual screening cannot find candidates. Therefore, the use of known drug molecules to guide generative models to generate candidates for virtual screening is noteworthy.\nWe are the first to combine conditional Diffusion with virtual screening. This new paradigm is shown in Fig. 1-A. First, with millions of molecules, the Diffusion model is trained to generate molecules. Second, with molecules in HIV dataset, an extra classifier is trained to guide Diffusion for HIV-inhibiting molecule generation. Third, ligand-base virtual screening technologies are used to detect HIV-inhibiting candidates from generated molecules."}, {"title": "B. Discrete Diffusion", "content": "A molecule can be viewed as a graph G, atoms are vertexes and bonds are edges. Inspired by Austin et al [16], one-hot encoding is used to represent the class of atoms and bonds. Noise is added separately on each atom and bond feature X. Instead of adding Gaussian noise, the feature of each atom and bond are multiplied by a matrix Q. $[Q]_{ij}^t$ represents the probability of jumping from state i to state j at round t, and $Q = \\Pi_{t=1}^T Q^t$. Eq 1 is used to add noise.\n$q(X_t | X_{t-1}) = X_{t-1}Q^t \\ \\ and \\ \\  q(X_t | X_{0}) = X_{0}Q^t$ (1)\nInspired by Vignac et al [10], the transition matrices definition for atoms and bonds are from the marginal distribution. Note that the bonds of molecules are undirected, only the upper-triangular part of B is added with noise and then the B will be symmetrized.\nIn the reverse process, $q(x_{t-1}|G_t)$ is calculated for denoising. There is a limited variety of atoms and bonds. So the kinds of atoms and bonds can be enumerated. X is the set of kinds. For feature $x_{t-1}$, $q(x_{t-1}|G_t)$ can be calculated with Eq 2.\n$q(x_{t-1}|G_t) = \\sum_{x \\in X} q(x_{t-1}|x_0=x, x_t)p(x^0 = x|G_t)$ (2)\nVignac et al [10] proved that $q(x_{t-1}|x_0=x, x_t)$ is proportional to $x_t (Q^t)^{x_0-1}$. According to Yang et al [17], when $q(x_{t-1}|x_t, x^0)$ has a closed-form expression, $x_0$ can be used as the target of the neural network.\nAs a result, a neural network $f_{\\theta}(G_t, t)$ is trained to predict $q_{\\theta}(G^0|G_t)$ in the forward process of discrete Diffusion. With $p_\\theta(x^0 = x|G_t)$, $q_{\\theta}(x_{t-1}|G_t)$ can be calculated.\nInspired by [18], a loss function with invariance is used in Eq 3. $p_i$ is the predicted probabilities for each atom and bond in $G^0$. A controls the relative importance of nodes and edges, and we set it to 5.0 in our experiments. The training process of the discrete Diffusion model is shown in Algorithm 1.\n$l(p_{G^0}, G^0) = \\sum_{1<i<n} CE(p^A_i, A_i^0) + \\sum_{1<j<n^2} CE(p^B_j, B_j^0)$ (3)"}, {"title": "C. HIV-inhibiting Molecule Generation", "content": "We take HIV-inhibiting molecule generation as condition $Y_c$. The value of $y_c$ is either 0 or 1. Since $G_t$ and $y_c$ are given, and $p(y_c|G_t)$ is independent of $G_{t-1}$, $1/p(y_c|G_t)$ is a constant Z. As a result, $\\tilde{q}(G_{t-1}|G_t, y_c)$ is shown in Eq 4.\n$\\tilde{q}(G_{t-1}|G_t, y_c) = \\tilde{q}(G_{t-1}|G_t)q(y_c|G_{t-1}, G_t)Z$ (4)\nThe noise-adding process is the same whether it is a conditional generation or not. As a result, $\\tilde{q}(G_{t-1}|G_t)$ is equal to $q(G_{t-1}|G_t)$. And $\\tilde{q}(G_{t-1}|G_t,yc)$ can be calculated with $q(G_{t-1}|G_t)q(y_c|G_{t-1})Z$.\nWe show the way to calculate $q(G_{t-1}|G_t)$ in Section III-B, and $q(y_c|G_{t-1})$ is equivalent to the result of a classifier with noise. That's why Classifier-Guidance Diffusion trains a classifier $g_\\theta$ with noise. However, there are so many possible values of $G_{t-1}(Atoms: 8^n \\times Bonds: 4^{(n*n)})$. As a result, $q(y_c|G_{t-1})$ cannot be obtained directly from the classifier $g_\\theta$.\nInspired by Dhariwal et al [19] and Vignac et al [10], we view $G$ as a continuous tensor of order $n + n^2$(n atoms and $n^2$ bonds). Using the first-order Taylor expansion around $G_t$, C is a constant independent of $G_{t-1}$, and $\\tilde{q}(y_c|G_{t-1})$ is approximately equal to Eq 5.\n$log \\tilde{q}(y_c|G_{t-1}) \\approx log \\tilde{q}(y_c|G_t) + <\\nabla_{G_t} log \\tilde{q}(y_c|G_t), G_{t-1} - G_t> =  <\\nabla_{G_t} log \\tilde{q}(y_c|G_t), G_{t-1}> + C$ (5)\nWe make the additional assumption that $\\nabla_{G_t} log \\tilde{q}(y_c|G_t)$ is proportional to $-\\nabla_{G_t} (y_c log y_\\theta + (1 - y_c) log(1 - y_\\theta))$. Therefore, we use the Binary Cross Entropy(BCE) as the loss function for the classifier $g_\\theta$ and then estimate $\\nabla_{G_t} log \\tilde{q}(y_c|G_t)$ with the gradient of the classifier $g_\\theta$. So we can calculate $q(y_c|G_{t-1}, G_t)$ and $\\tilde{q}(G_{t-1}|G_t, y_c)$. Based on $\\tilde{q}(G_{t-1}|G_t, y_c)$, we sample $G_{t-1}$. This process is repeated and finally, $G_0$ is generated. The sampling process of the discrete Diffusion mode is shown in Algorithm 2."}, {"title": "D. Network Architecture", "content": "A neural network $f_{\\theta}(G_t,t)$ is trained to predict $q_{\\theta}(G^0|G_t)$ in the forward process of discrete Diffusion. Inspired by Vignac et al [10], cycles and spectral features are added as extra inputs to improve performance. We use graph transformer network [20] with FiLM layers [21] to predict $q_{\\theta}(G^0|G_t)$. Besides, we use the same graph transformer for classifier guidance. The network architecture is shown in Fig 1-D."}, {"title": "E. Proposed Metric", "content": "Molecule generation models have found one important application in the field of drug molecule discovery. Table I outlines several common evaluation metrics used to assess the performance of generative models. However, beyond QED, these evaluation metrics do not specifically focus on the ability of the models to generate drug-like molecules. Therefore, the existing metrics are unable to meet the requirements of drug molecule design with generative models.\nInspired by ligand-based virtual screening approaches, we design a novel evaluation metric to better assess the capacity of models to generate drug-like molecules. $f_a$ denotes the morgan fingerprint of the molecule a. The similarity between molecule a and b is defined in Eq. 6. The similarity of a molecule b to a set of molecules A is defined in Eq. 7. Besides, Eq. 8 calculates the proportion of molecules in set B that are similar to molecules in the known drug molecule set A.\n$MolSim(a, b) = TanimotoSimilarity(f_a, f_b)$ (6)\n$SetMolSim(A, b) = \\underset{a \\in A}{arg \\ \\ max} MolSim(a, b)$ (7)\n$DrugLike(A, B) = \\frac{\\{b \\in B|SetMolSim(A, b) > 0.5\\}}{|B|}$ (8)\nThe set of known drug molecules is denoted as X, the set of molecules used to train the generative model is denoted as Y, and the set of molecules generated by the generative model is denoted as Z. The new metric we define is as shown in Eq. 9. We refer to it as the Drug Index. The Drug Index reflects the ability of generative models to generate drug-like molecules.\n$DrugIndex(X, Y, Z) = \\frac{DrugLike(X, Z)}{DrugLike(X, Y)}$ (9)\nThe Drug Index is inspired by virtual screening and is designed to be intuitive and easy to implement. Using the Drug Index, one can evaluate molecule generation models that are suitable for computer-aided drug design tasks such as virtual screening."}, {"title": "IV. EXPERIMENTS", "content": "First, we compare our method with others from Sections IV-A through IV-D. Then we conduct ablation experiments in Section IV-E and present some generated candidate molecules in Section IV-F. Additionally, we report and discuss the Degradation phenomenon in Section IV-G. Finally, we discuss the limitations of our work in Section IV-H. All the code and results will be made available on Github.\u00b9.\nA. Dataset\nAll molecule generation models are trained on the MOSES [24] dataset and its properties are listed in Table II."}, {"title": "B. Comparison across Generative Models", "content": "We generate 90,000 molecules using charRNN [7], JT-VAE [8], LatentGAN [9], DiGress [10], and our method. We used the known HIV inhibitor molecules from the MoleculeNet dataset [25] as the reference drug molecules. The HIV Drug Index (HIV DI), Quantitative Estimate of Druglikeness (QED), and other properties of these generative models are shown in Table IV."}, {"title": "C. Comparison of GNNs for Virtual Screening", "content": "Neural networks are also a way of ligand-based virtual screening. We select four representative GNNs and train them on the HIV-b dataset. The four GNNS are GAT(Graph Attention Network) [26], GCN(Graph Convolution Network) [27], MPNN(Message Passing Neural Network) [28] and AttentiveFP [29]. The learning rate of the four models is set to 0.001, and the number of epochs is set to 500. Models are implemented by DeepChem [30]. We do simple upsampling on the HIV-b dataset, replicating the active samples until there are roughly the same number of active and inactive samples.\nTo objectively reflect the ability of each model to identify active molecules, we conducted 5-fold cross-validation experiments. When the probability given by the model is greater than 50%, the input molecule is considered to be active. The results are shown in Table V. There are significantly more inactive samples than active samples in the HIV-b test set. Therefore, even if the F1-score is lower than 0.5, the model still demonstrates a certain level of discriminative ability. When the ROC-AUC is larger than 0.7, the virtual screening performance is considered fair, as suggested by prior studies [31]. The ROC-AUC results also indicate that graph neural networks (GNNs) can be a viable approach for the virtual screening of HIV drug molecules."}, {"title": "D. Comparison of Drug Index using GCNS", "content": "To further verify the effectiveness of the our proposed metric and method, we use GCNs for additional verification. We train three GCNs on the HIV-b dataset. When the sum of the output probabilities of the three models is greater than 100%(i.e., 2 out of the 3 models consider the molecule to be active), the input molecule is deemed active. Instead of Eq. 7, the output of GCNs is used to calculate DrugLike and DrugIndex. The results are presented in Table VI."}, {"title": "E. Ablation Experiment", "content": "To robustly validate the efficacy of our approach, we conducted ablation studies. Our primary focus was to investigate the impact of the classifier guidance in the diffusion model and our innovative adoption of the BCE loss function on the final results. We established three models: the first excluded the classifier guidance module entirely, the second employed MSE as the classifier's loss function, and the third utilized BCE as the classifier's loss function.\nThe results are shown in Table VII, we observed that the HIV Drug Index (HIV DI) for the model without classifier guidance and the model employing MSE as the classifier's loss function stood at 86.11% and 83.51% respectively. Strikingly, the HIV DI for the model utilizing BCE as the classifier's loss function soared to 104.62%, significantly outperforming the other two. This underscores the crucial role of the choice of loss function for classifier guidance, as an inappropriate selection can lead to diminished rather than enhanced performance. Furthermore, it solidifies the efficacy of our innovative adoption of the BCE loss function, reaffirming that our approach for virtual screening is capable of yielding a more extensive repertoire of HIV-inhibiting candidate molecules."}, {"title": "F. Generated Candidate Molecules", "content": "Ten pairs of similar molecules are shown in Fig. 3 with the top row of active molecules from the HIV dataset and the bottom row of molecules generated by our model. Our model generates molecules that are very similar to known HIV drug molecules. This further demonstrates the effectiveness of our method."}, {"title": "G. Observed Phenomenon \"Degradation\" and Discussion", "content": "In Table V and Table VI, it can be observed that the Drug Index of the generative models(except our method) are all below 100%. Compared with the molecules in training set MOSES, the proportion of generated molecules that are similar to known HIV drugs is lower. We are the first to observe and report this phenomenon. We call it the Degradation in molecule generation.\nTo explain this phenomenon, we do the following experiment. First, we calculate Morgan fingerprint of all molecules with a radius of 10. Then, we use the k-means algorithm to cluster the active molecules in the HIV-a dataset according to fingerprint similarity. The k is set to 30. In the end, we use the k-nearest neighbor(KNN) algorithm to classify molecules that are similar to known drugs. These molecules are from the MOSES dataset as well as generated by charRNN [7], JT-VAE [8], LatentGAN [9], DiGress [10], and our method. The result is shown in TableVIII.\nAccording to Table VIII, the following conclusions can be inferred.\n1) Degradation from Difficulty in Specific Structures: According to cluster 13, we can find that there are only molecules from MOSES in this cluster and no molecules from the generative models. Although the training set contains similar molecules, the generative model has difficulty generating the structure of this cluster of HIV drug molecules. Therefore, we can speculate that the inability to generate these specific structures is the reason for the poor performance. Actually, some scholars have found that generation models often struggle to generate aromatic structures [10], which is consistent with our conclusion.\n2) Training Set Needs Improvement: For most clusters, there are neither molecules from the MOSES dataset nor molecules generated by the existing generative models. The molecules in the MOSES dataset lack certain molecular structures, so the generation models trained on this dataset struggled to produce molecules with these specific structural features. As a result, improving the training data for generative models is an important consideration in the drug discovery process.\n3) Our Method Makes Sense: Our method uniquely generates candidate molecules within the cluster 22. This demonstrates the effectiveness of our approach in leveraging existing HIV-inhibiting molecules to guide the generation model.\nTo further validate our conclusion, we find that many clusters containing HIV molecules without any molecules from MOSES or the generative models possessed a similar structure to Fig. 4, where two rings of length 5 or 6 share at least one chemical bond with each other.\nWe have compiled the proportion of molecules with this structure in candidate molecule datasets, as shown in Fig 5. It is evident that the proportion of molecules with this structure in the generative models' datasets is lower than that in MOSES, while the proportion in MOSES is still lower than that in HIV. This further demonstrates the difficulty of existing generative models in generating specific structures and the need for improvement in the training set. Some previous studies have shown that GNN is difficult to handle rings [32]. As a result, SMILES-based charRNN generates the most candidate molecules with this structure than other models.\nAlthough our method generated fewer candidate molecules with this particular structure, we believe that Diff4VS has advantages in generating other drug molecule structures, given the overall advantages of our method in the DrugIndex."}, {"title": "H. Limitation", "content": "1) Lack of Data: The training set for the Classifier Guidance contains only 328 HIV-inhibiting molecules. Although Classifier Guidance Diffusion requires less data than Classifier-Free Diffusion, it is still challenging to train a reliable classifier for molecules with noise. Molecular drug data is obtained through costly and time-consuming wet lab experiments, and this lack of data hinders the development of effective conditional generation models for drug design. Fine-tuning Methods that can achieve good performance with less data, such as LoRA [33], may help address this problem.\n2) Flaws in Theory: In Eq. 5, we treat G as a continuous tensor and perform a Taylor expansion. However, the underlying molecular structure is stored discretely in G. This continuous approximation inevitably results in the loss of the discrete nature of the original information. Additionally, we do not have access to $\\nabla_{G_t} log \\tilde{q}(y_c|G_t)$ and thus make a further assumption. While the ablation experiments in Section IV-E lend support to the validity of our assumption, the theoretical framework still exhibits fundamental limitations. The theoretical innovation of conditional molecule generation models is also a direction worth studying in the future."}, {"title": "V. CONCLUSION", "content": "In this paper, we are the first to combine conditional molecule generation models with virtual screening. With the HIV dataset, an extra classifier is trained to guide Diffusion to generate a larger proportion of HIV-inhibiting candidate molecules. The experiment shows that our method generates more HIV-inhibiting candidate molecules than other methods. Inspired by ligand-base virtual screening, we also propose a novel metric DrugIndex which reflects the ability to generate drug-like molecules. Besides, we are the first to report the Degradation in molecule generation and find that it is from the difficulty of generating specific molecular structures. Our research brings new ideas for the application of generative models in drug design."}]}