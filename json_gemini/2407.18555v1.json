{"title": "How To Segment in 3D Using 2D Models:\nAutomated 3D Segmentation of Prostate Cancer\nMetastatic Lesions on PET Volumes Using\nMulti-Angle Maximum Intensity Projections and\nDiffusion Models", "authors": ["Amirhosein Toosi", "Sara Harsini", "Fran\u00e7ois B\u00e9nard", "Carlos Uribe", "Arman Rahmim"], "abstract": "Prostate specific membrane antigen (PSMA) positron emission tomography/computed tomography (PET/CT) imaging provides a tremendously exciting frontier in visualization of prostate cancer (PCa) metastatic lesions. However, accurate segmentation of metastatic lesions is challenging due to low signal-to-noise ratios and variable sizes, shapes, and locations of the lesions. This study proposes a novel approach for automated segmentation of metastatic lesions in PSMA PET/CT 3D volumetric images using 2D denoising diffusion probabilistic models (DDPMs). Instead of 2D trans-axial slices or 3D volumes, the proposed approach segments the lesions on generated multi-angle maximum intensity projections (MA-MIPs) of the PSMA PET images, then obtains the final 3D segmentation masks from 3D ordered subset expectation maximization (OSEM) reconstruction of 2D MA-MIPs segmentations. Our proposed method achieved superior performance compared to state-of-the-art 3D segmentation approaches in terms of accuracy and robustness in detecting and segmenting small metastatic PCa lesions. The proposed method has significant potential as a tool for quantitative analysis of metastatic burden in PCa patients.", "sections": [{"title": "1 Introduction", "content": "Prostate cancer (PCa) is the second most prevalent cancer and the fifth leading cause of cancer-related mortality among men [17]. Despite progress in conclusive local treatments like radical prostatectomy (RP) and radiation therapy (RT), an estimated 20-50% of patients will experience biochemical recurrence (BCR), marked by increasing levels of prostate-specific antigen (PSA). [5] The recurrence of prostate cancer may manifest as metastasis in the regional lymph nodes and bone structures. As the disease progresses, involvement of the liver and lungs, among other sites, may also occur [1]. Depending on which site is involved with the disease, different type of treatment might be required.\nPSA level raise is considered as the primary biomarker for following up on prostate cancer treatment response and monitoring disease recurrence in prostate cancer patients [2]. However, it cannot localize the recurrence of the disease. Therefore, the precise identification of recurrence locations becomes significantly important for therapeutic decision-making processes. As a result, employing a di-agnostic imaging modality that possesses both high sensitivity and specificity is crucial for differentiating between local relapse, oligometastatic disease, and ex-tensive disease, hence to enable individualized treatment plans for patients. Re-cent advancements in Positron Emission Tomography (PET) imaging has led to improved detection and quantification of many types of primary and metastatic lesions. Design of recent PET radiopharmaceuticals that are able to target the prostate-specific membrane antigen (PSMA), such as [18F]DCFPyL, with much higher sensitivity and specificity compared to conventional imaging modalities has opened a new era in the diagnosis, treatment decision-making, and patient management in prostate cancer [16].\nDeep learning algorithms, have shown great potential in computer-aided di-agnosis [12]. Yet, challenges arise from the nature of the imaging modality that AI-based image recognition algorithms must cope with, including low contrast, large intra- and inter-patient heterogeneity, and blurring and noise in the images. The unique specifications of biochemical recurrent prostate cancer metastatic lesions, including tumors with very small sizes, low-to-moderate radiopharma-ceutical uptake, especially compared to the high biological uptake of the bladder and kidneys, make them hard targets to detect [4]. Added to that, local tumor recurrence adjacent to the urinary bladder, or in the abdomen area with high background noise and high uptake regions such as ureters, further complicate the detection of PCa lesions even for physicians, making the task of manual segmentation time and labor-intensive [7]. As such, localizing the lesions in the image could help physicians save time and increase the accuracy of the task.\nThere are limited number of works that tried to tackle the problem of PCa tumor/metastatic lesion detection and segmentation using the power of AI. Prior works mainly focused on the local primary (intra-prostatic) tumor segmentation [11] which is a relatively less challenging task, given the locality of the disease oc-currence. Only in [10] and [21] authors evaluated the performance of CNN-based segmentation models for PCa lesions segmentation, however only the dataset used in [21] is for PCa recurrence patients."}, {"title": "2 Methods and Materials", "content": "In this work, we introduce an innovative approach for automated detection and segmentation of biochemically recurrent PCa metastatic lesions on PSMA-PET images using a 2D Diffusion-based segmentation model. This approach includes novel use of the ordered-subset expectation-maximization (OSEM) algo-rithm applied to 2D segmentations of multi-angle maximum intensity projections (MA-MIPs) to generate 3D segmentation of metastatic lesions in PET images, while taking advantage of the computational efficiency and performance bene-fits of training a 2D diffusion-based segmentation model on MA-MIPs. We show that our method outperforms its state-of-the-art 3D rivals in terms of various segmentation metrics on the target dataset.", "2.1 Dataset": "This is a post-hoc sub-group analysis of a prospective clinical trial. Inclusion criteria were: (1) histologically proven prostate cancer with biochemical recur-rence after initial curative therapy with radical prostatectomy, with a PSA > 0.4 ng/mL and an additional measurement showing increase; (2) histologically proven prostate cancer with biochemical recurrence after initial curative therapy with RT, with a PSA level > 2 ng/mL above the nadir after therapy. [6]. Over-all, 510 whole-body [18F]DCFPyL PSMA-PET/CT images were chosen. Each trans-axial PET image has a matrix size of 192 \u00d7 192 pixels, with each pixel covering 3.64mm\u00b2 in physical space. All active lesions were manually delineated by an expert nuclear medicine physician. On average each image had 1.92\u00b11.21 PCa lesions with an average active volume of 4.03 \u00b17.02ml and long axis di-ameter of 12.96 \u00b1 10.11mm (on CT). The average maximum standard uptake value (SUVmax) and SUVmean of all the lesions were 9.64\u00b110.04 and 4.4\u00b13.55, respectively.", "2.2 Data Preprocessing": "PSMA-PET activity concentration values (Bq/ml) of all PSMA PET voxels were converted to Standard Uptake Value (SUV). To decrease the contrast between high uptake normal organs and the small lesions, SUV values were clipped to a range of 0 to 25. CT images had an original voxel size of (0.98\u00d70.98\u00d73.27)mm\u00b3, and the PET images had a voxel size of (3.64 \u00d7 3.64 \u00d7 3.27)mm\u00b3. All PET/CT images were resampled to a voxel size of (2.0 \u00d7 2.0 \u00d7 2.0)mm\u00b3 using a third-order spline method for both CT and PET images and further cropped to have matrix size of 250 x 250. 72 axial rotations of the PSMA PET volumes were computed in every 5\u00ba degrees of axial rotation, and the maximum intensity projections (MIPs) of all 72 volumes (the original volume and all 71 rotated ones) were computed, in order to cover one complete 360\u00b0 axial rotation of the volume. Since preserving the information of soft tissues in the CT equivalent of MIP projections are not feasible, in order to provide more context information to the DDPM network,"}, {"title": "2.3 Segmentation Network Architecture", "content": "The model used in this work for automated segmentation of the metastatic lesions on MA-MIPs is a denoising diffusion probabilistic model (DDPM) initially proposed in [14] and modified in [20] for brain tumor segmentation on 2D trans-axial MRI slices. The general idea behind diffusion models comprised of two chains of incrementally noising and denoising, known as forward (q) and reverse (p) processes, respectively. The forward process p starts with adding a small amount of Gaussian noise to the input image x over T time steps, resulting in a series of noisy images x0,x1,...,xT. Then, during the reverse process p, the model which is a U-Net architecture based network, learns to predict the slightly less noisy image xt-1 from xt for each step t \u2208 {1,...,T}. Throughout the training of the diffusion model, the ground truth image xt-1 in each time step t is known, and hence the model can be trained using L2 loss.\nDuring test time, the sampling process p starts from random Gaussian noise xT ~ N(0,I), and iteratively denoises it using the trained U-Net model to generate a fake image xo.\nWriting the forward process q as q(xt|xo) := N(xt; \u221a\u0101t x0, (1 \u2013 \u0101t)I) where at := 1 - \u03b2t and \u03b2t is the variance of the forward process q at the time step t, and \u0101t := \u03a0ts=1 as, then xt can be directly expressed based on x0 as:\nxt = \u221a\u0101txo + \u221a1-\u0101te, where \u20ac~N(0, I)\n(1)\nas shown in [8]. For the reverse (denoising) process, given the parameters of the trained U-Net model (\u03b8), the learned reverse process pe can be written as Po(Xt-1|Xt) := N(xt\u22121; \u03bc\u03b8(xt, t), D\u03b8(xt, t)). Here xt-1 can be predicted using the following formula as given in [8]:\nXt-1 = 1\nVat\nXt\n1-at\n\u221a1-\u0101t\n\u0395\u03b8(x, t)) + \u03c3\u03c4\u0396,\nwhere z~N(0,1) (2)\n\u03c3\u03c4 is the variance scheme of the reverse process [14] and z is the random compo-nent of the sampling process. The U-Net denoted as e\u03b8 at each time step t takes xt (as defined in equation1) as input, and learns the noise scheme 60(xt,t). At the time step t during sampling, the predicted ea is subtracted from xt according to Equation 2 to construct xt-1 which is a slightly less noisy version of the input Xt."}, {"title": "2.4 3D Reconstruction of 2D Masks Using OSEM Algorithm", "content": "The Ordered Subsets Expectation Maximization (OSEM) algorithm is an itera-tive reconstruction technique widely used in medical imaging modalities such as Positron Emission Tomography (PET) and Single-Photon Emission Computed Tomography (SPECT) [9]. It reconstructs 3D volumetric images from a series of 2D tomographic projection data acquired at different angles around the subject. OSEM is an accelerated variant of the Expectation Maximization (EM) algo-rithm [13], which aims to estimate the unknown 3D radio-tracer distribution within the subject by maximizing the likelihood of observing the measured 2D projection data. The OSEM algorithm introduces an ordered subsets approach to accelerate the convergence rate of the EM algorithm.\nA novelty of our work is that OSEM algorithm, unlike conventionally applied to acquired data to generate images, is applied to segmentations of MA-MIPS as generated from the images. By utilizing the OSEM algorithm, the proposed method in this study efficiently reconstructs the 3D segmentation volume from the predicted 2D segmentation masks obtained from the MA-MIPs. The back-projection step of the OSEM algorithm is used to map the 2D segmentation masks onto the 3D volume, iteratively refining the estimate until convergence."}, {"title": "3 Experiment Details", "content": "We evaluated our proposed MIP-based segmentation method on the PSMA-PET image dataset described in section 2.1. Per each patient, 72 axial rotated volumes of the PSMA-PET image were generated. In order to avoid padding the images as much as possible and providing more meaningful information to the network, all the whole-body PSMA-PET volumes were divided into two section, upper body and lower body, resulting in 144 volumes per each patient. For each volume, 4 different MIP images were generated, as described in section 2.2. These four different MIPs were stacked to prepare the input data for training the DDPM model, resulting in the size of (4, 250, 250). These steps resulted in 66240 images from 460 PSMA-PET volumes of the same number of patients for training/validation of the DDPM model and 7200 images for testing from 50 patients.\nBackbone of the DDPM model used in this work is a U-Net architecture network described in [20], and [14] with input size of five-channel 256 \u00d7 256. It uses six feature map with resolutions from 128 \u00d7 128 to 4\u00d74, two residual blocks, and one self-attention head with 16 \u00d7 16 resolution. Similar to [20] we chose a 10000-steps linear noise schedule for training/sampling. The model is trained for 72 hours (150,000 iterations) on an NVIDIA V100 GPU 16 GB, with a learning rate of 10-4 using Adam optimizer, and a batch size of 1."}, {"title": "4 Results and Discussion", "content": "In this section we report the result of the proposed MA-MIP based segmentation method on our test set. As baseline comparison, we also show results for 8 state-of-the-art (SOTA) 3D segmentation methods in the literature."}, {"title": "5 Conclusion", "content": "Our work introduces a novel method for segmentation of metastatic lesions in 3D volumetric PET images, utilizing 2D diffusion models. Instead of 2D trans-axial slices or 3D volumes, our approach segments the lesions on multi-angle maximum intensity projections of PET images. Final 3D segmentation masks are then obtained through OSEM-based reconstruction of the segmented 2D MA-MIPs. Our method demonstrates superior performance compared to SOTA segmentation techniques. The proposed framework holds significant promise as a tool for segmenting small metastatic lesions in medical images."}]}