{"title": "Speeding up approximate MAP by applying domain knowledge about relevant variables", "authors": ["Johan Kwisthout", "Andrew Schroeder"], "abstract": "The MAP problem in Bayesian networks is notoriously intractable, even when approxi-mated. In an earlier paper we introduced the Most Frugal Explanation heuristic approach to solving MAP, by partitioning the set of intermediate variables (neither observed nor part of the MAP variables) into a set of relevant variables, which are marginalized out, and irrelevant variables, which will be assigned a sampled value from their domain. In this study we explore whether knowledge about which variables are relevant for a particu-lar query (i.e., domain knowledge) speeds up computation sufficiently to beat both exact MAP as well as approximate MAP while giving reasonably accurate results. Our results are inconclusive, but also show that this probably depends on the specifics of the MAP query, most prominently the number of MAP variables.", "sections": [{"title": "1. Introduction", "content": "In a Bayesian network, the Maximum A Posteriori (MAP) problem is the computational problem of inferring the most probable explanation given evidence, i.e., the mode of a pos-terior distribution. In a decision support system, where the underlying statistical model is a Bayesian network (e.g., Dey and Stori, 2005; Geenen et al., 2006; Kuang et al., 2017; Liu et al., 2018), the MAP problem typically establishes the diagnosis or advice that is best supported by the available evidence and as such is a crucial component of such sys-tems. Computing the MAP problem is computationally very demanding in larger networks; the problem is NPPP-hard (Park and Darwiche, 2004) and remains NP-hard under various structural constraints (de Campos, 2020; Kwisthout, 2011) as well as under a variety of ap-proximation approaches (Kwisthout, 2015a). This unfavourable complexity not only hinders practical application; it also implies that even the state-of-the-art approximation algorithm (ANNEALED MAP; Yuan et al. (2004)) will have difficulty on at least some problem in-stances.\nTo partially overcome this challenge, in earlier work we proposed a heuristic approach to MAP, based on the observation that in many real-world inference queries, only a small subset of the variables really contributes to the decision. In the MOST FRUGAL EXPLANA-TION heuristic (Kwisthout, 2015b) the set of intermediate variables in the network (those variables that are neither to be explained nor contain observations) is partitioned, based on background information about their role in the inference process, into relevant and ir-"}, {"title": "2. Preliminaries", "content": "A Bayesian network B is a probabilistic graphical model that describes a set of stochastic variables, a joint probability distribution over these variables, and the conditional inde-pendences that hold in this distribution (Pearl, 1988). \u0412 includes a directed acyclic graph GB = (V, A), modelling the variables and conditional independences in the network, and a set of parameter probabilities Pr in the form of conditional probability tables (CPTs), capturing the strengths of the stochastic relationships between the variables. The network efficiently factorizes a joint probability distribution Pr(V) = \\prod_{i=1}^n Pr(V_i | \\pi(V_i)) over its variables, where \\pi(Vi) denotes the parents of Vi in G\u00df. As notational convention we will use upper case letters to denote individual nodes in the network, upper case bold letters to denote sets of nodes, lower case letters to denote value assignments to nodes, and lower case bold letters to denote joint value assignments to sets of nodes. The set of values for a particular variable (and by extension, set of variables) V is denoted as \u03a9(V).\nGiven a partitioning of the variables in the network into explanation variables H, ev-idence variables E, and intermediate variables I, the MAP problem is the computational"}, {"title": "3. Methods", "content": "In order to evaluate the MOST FRUGAL EXPLANATION (hereafter MFE) we studied the performance of this heuristic in comparison with Exact MAP via the JUNCTION TREE al-gorithm (hereafter MAP) and the ANNEALED MAP algorithm (hereafter ANN) on several benchmark Bayesian networks (ALARM, ANDES, BARLEY, and HAILFINDER). We imple-mented\u00b9 both MFE and ANN in C++ using the LibDAI library (Mooij, 2010) and compared running time and accuracy in terms of the number of variables in the explanation set that"}, {"title": "3.1 Experimental setup", "content": "We ran our algorithms on an HP Compaq Elite 8300 CMT desktop computer, with Intel Core i7-3770 CPU running at 3.40 GHz and 16 GB of memory, running Debian GNU/Linux 10. We partitioned the variables of the Bayesian network into hypothesis variables, evidence variables, and intermediate variables as described per benchmark network below. For each network we randomly assigned ten joint value assignments to the evidence nodes and sim-ulated each MAP query five times to average out perturbations in running time due to external factors (such as OS activity). We computed the Hamming distance between the MAP explanation and the heuristic approaches (hereafter denoted as \u2018error') and averaged running time and error over the 5 \u00d7 10 = 50 simulations. Data was locally stored and pro-cessed; raw data, scripts, and processed data are available at the Donders Data Repository for colleagues to inspect and reuse.\nPer benchmark network, we ported the .bif files from the BNLearn repository\u00b3 to factor graphs using an in-house tool4 since the LibDAI library requires factor graphs as input. As MFE cannot deal properly with deterministic variables, we manually adjusted these variables to have values very close to 1 and 0; each 0 entry in a CPT was replaced with 0.000000001 and the 1 entry matched such that the distribution adds up to 1. We use the orginal factor graphs for MAP and ANN and the adjusted factor graphs for MFE computations5.\nFor the MFE heuristic we simulated two variants: one where the partitioning into relevant and irrelevant variables was given (by pre-computation) as to simulate background knowledge, and one where the partitioning was part of the heuristic approach. In the first case, as pre-computation we approximated the intrinsic relevance by 1000 samples or, in case that was computationally infeasible, by 100 or even 10, as indicated per benchmark network below; the threshold for inclusion in the set of relevant variables was set to 0.1. In the second case, the approximation was part of the heuristic; we sampled thrice and deemed a variable as relevant if the intrinsic relevance was non-zero6. In both variants, the algorithm marginalized out the relevant variables and assigned a random value to the irrelevant variables.\nThe LibDAI library has no functionality to compute MAP efficiently; only inference (using the junction tree algorithm (Lauritzen and Spiegelhalter, 1988)) and MPE (that is, when there are no intermediate variables). As a workaround we computed MAP by com-puting the joint distribution over the MAP variables and then searching for the maximum value. Obviously this workaround approach does not utilize the independences between the"}, {"title": "3.1.1 ALARM", "content": "The ALARM network (Beinlich et al., 1989) consists of 37 discrete random variables which have a natural partitioning into hypothesis variables (eight diagnostic variables), evidence variables (sixteen observable findings) and intermediate variables (the remaining thirteen variables). Variables can take on two, three, or at most four values; there are 46 arcs and the in-degree is at most four. In our simulations we used the natural partitioning as indicated above. Pre-computation of the intrinsic relevance of the thirteen intermediate variables was done using 1000 samples each; pre-computation time varied between 11 and 78 seconds per variable."}, {"title": "3.1.2 BARLEY", "content": "The BARLEY network (Kristensen and Rasmussen, 2002) has 48 nodes with 84 arcs, with in-degree at most four. However, the cardinality of the variables is significantly larger, with one node having no less than 67 states. This renders exact MAP infeasible on the BARLEY network. In line with Yuan et al. (2004) we interpreted the ten root variables as hypothesis variables and the eight leaf variables as evidence variables, which reasonably matches the layout of this network (Kristensen and Rasmussen, 2002, p.206). Due to the impossibility to compute either MAP or MFE over the total hypothesis set due to the library constraints, we selected the first four variables as our hypothesis set. From piloting it became pretty clear that pre-computation of intrinsic relevance using 1000 samples was infeasible, as a single sample already took about 90 seconds due to the intractability of MAP computation. We approximated intrinsic relevance using 10 samples per variable."}, {"title": "3.1.3 ANDES", "content": "ANDES (Conati et al., 1997) has 223 binary nodes with 338 arcs, and in-degree at most six; the CPTs are to a large extent rolled out from canonical models (leaky noisy or/and models). There are 89 root nodes and 22 leaf nodes; for these simulations, the first five root variables make up the hypothesis set. Furthermore, as ANDES has several deterministic variables, for the MFE computation we adjusted these variables as indicated above. Due to the large number of intermediate variables we opted for 100 samples per variable to approximate intrinsic relevance."}, {"title": "3.1.4 HAILFINDER", "content": "Finally, HAILFINDER (Abramson et al., 1996) has 56 nodes with 66 arcs with maximum in-degree four. This network has 17 root nodes and 13 leaf nodes; the cardinality ranges from two to eleven. Again the size of the hypothesis set renders exact MAP intractable in practice. To experiment with the effect of the size of the hypothesis set on the behaviour of the different algorithms we ran simulations using the first 10, 7, and 5 root variables as hypothesis set. Also for HAILFINDER we adjusted the deterministic variables as indicated above. In contrast to MAP inference, computing the intrinsic relevance using 1000 samples was feasible, taking from 10 to 60 seconds."}, {"title": "4. Results", "content": "This result section is structured as follows. We start with presenting the main results for RQ 1 and RQ 2, namely running time and accuracy of MAP, ANN, MFE with sampling, and MFE with pre-computation (MFE+), for ALARM, BARLEY, ANDES, and HAILFINDER (with five hypothesis variables) in Table 1 and graphically in Figure 1. We then further investigate the effect on hypothesis set size for HAILFINDER (Figure 2) and present a preliminary interpretation of these results. In Sub-section 4.1 we investigate, using the ALARM network, whether the Hamming distance results sufficiently generalize to other accuracy measures for MAP. In Sub-section 4.2 we look at the number of variables that are actually considered to be relevant (based on the pre-computation) per network, and in Sub-section 4.3 we use this information to compare actual running time with some theoretical analyses of the number of elementary operations needed. We discuss the results for RQ 2 and MFE+A in Sub-section 4.4 before discussing the overall simulations in Sub-section 4.5."}, {"title": "4.1 Other error measures", "content": "In Kwisthout (2015b), three error measures were used, in line with the three notions of approximate MAP established in Kwisthout (2015a); in addition to the Hamming distance between ground truth MAP and the approximate explanation, the ratio of their probabil-ities as well as the rank of the explanation (i.e., the number k such that the approximate explanation is the kth most probable explanation) were used. These measures can in prin-ciple deviate, hence, we ran a sanity check test to assure that the Hamming distance gives a reasonable impression of the quality of the approximate explanation. The results can be found in Figure 3.\nANN scores best on all three measures, then MFE, then MFE+. This suggests that indeed the Hamming distance gives a good indicator of the accuracy of the approximation."}, {"title": "4.2 Size of relevant variables set", "content": "We refer to Figure 4. In general: With more hypothesis variables, the ratio increases (see the increase in HAILFINDER but also the large ratio in Alarm). For smaller sets, the number of relevant variables is really low (see for example Andes), which ought to lead to a more"}, {"title": "4.3 Running time vs. theoretical analysis", "content": "For the Alarm network, we see that on average four out of the eleven relevant variables are relevant. We closely examined a particular run to get some insight in the discrepancy between theoretical results and actual runtime."}, {"title": "4.4 Results for Research Question 3: MFE+A", "content": "The experimental setup was the same as that described in section 3.1 - the experiment was run on the same computer and each network had a total of 50 simulations (10 different evidence values averaged across 5 runs, per network). The only difference is that the MFE+A algorithm was added and the regular MFE algorithm was removed to save on simulation time."}, {"title": "4.5 Discussion", "content": "Based on the above results, we conclude that background knowledge may help, and perhaps should help in theory, but it does not really show in the current study using the LibDAI library. This is partially due to the inefficient MAP computation used as sub-routine in MFE; in addition, marginalization might be less costly for variables with small domains than sampling might be due to various overhead. When comparing actual reported running times (for ALARM and HAILFINDER) we see that Yuan et al. (2004) is about 2.5 times faster than our results, despite running on an older computer with less memory. Perhaps the tight integration with the SMILE inference engine in this implementation can account for this."}, {"title": "5. Conclusion", "content": "When reflecting back on the original research questions, it is clear that when used as approx-imation algorithm, MFE is unlikely to beat the state-of-the-art approximation as already for a single sample and for very few relevant variables the assessment of relevance is very costly save in the easiest situations. However, background knowledge (either precomputed or by estimation of experts, inasmuch as this is possible) may still be useful, although our results show little improvement over computing MAP exactly; however, we argued that this may be partially due to the inefficient MAP computation using the LibDAI library. We see that there is some variation on the relevant variables given the specific evidence, but there is also quite a lot of overlap so many variables may not be that relevant anyway for designated sets of hypothesis and evidence variables.\nIn their study comparing ANNEALED MAP with P-LOC and P-SYS, Yuan et al. (2004) uses 20 MAP variables, which favours local search approaches over approaches (such as MFE) that work on the entire hypothesis set simultaneously; however, MAP is intractable in general even for a singleton binary MAP variable, implying that there are hard instances with a limited number of hypothesis variables. It would be interesting to compare the approaches on such instances.\nIn regards to RQ 3, seems that the initial hypothesis that a combined ANN and MFE+ algorithm would result in reduced running time but poor accuracy has been proven by the results presented here. However, it was not clear exactly how much accuracy would be traded for reduced running time a priori. After analyzing the results it appears that the drop in accuracy is so large when using MFE+A when compared to vanilla ANN or MFE+ that it possibly renders the algorithm virtually un-useable in practice, except for perhaps on very large networks such as HAILFINDER10 in situations where large errors are acceptable.\nFor future work we obviously would like to either patch the LibDAI library with a 'true' Junction-tree based MAP algorithm, or use another library that has this feature, to be able to offer MFE a fairer comparison with other approximation algorithms. We also aim to implement other approximation algorithms, such as ANYTIME APPROXIMATE MAP and P-Loc and compare MFE on other - and larger - networks. Finally, the MFE algorithm should be able to circumvent incompatible evidence due to deterministic variables so that the heuristic also works on such networks without patching."}]}