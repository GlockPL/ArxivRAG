{"title": "Optimizing Keyphrase Ranking for Relevance and Diversity Using Submodular Function Optimization (SFO)", "authors": ["Muhammad Umair", "Syed Jalaluddin Hashmi", "Young-Koo Lee"], "abstract": "Keyphrase ranking plays a crucial role in information retrieval and summarization by indexing and retrieving relevant information efficiently. Advances in natural language processing, especially large language models (LLMs), have improved keyphrase extraction and ranking. However, traditional methods often overlook diversity, resulting in redundant keyphrases. We propose a novel approach using Submodular Function Optimization (SFO) to balance relevance and diversity in keyphrase ranking. By framing the task as submodular maximization, our method selects diverse and representative keyphrases. Experiments on benchmark datasets show that our approach outperforms existing methods in both relevance and diversity metrics, achieving SOTA performance in execution time. Our code is available online.", "sections": [{"title": "1. Introduction", "content": "Keyphrase ranking is crucial in information retrieval, summarization, and indexing. It assists in identifying and extracting phrases that concisely capture the core concepts of a document. Traditionally, keyphrase extraction methods [1] have focused on selecting highly relevant phrases to the document's content. However, a narrow focus on relevance often results in redundant keyphrases, which fail to capture the full breadth of the document's topics. A recent survey highlights the diversity issue in Keyphrases [2]. Ensuring diversity in keyphrase selection is thus vital to provide a more comprehensive representation of a document's content, particularly in large-scale databases and information retrieval systems.\nRecent advancements in natural language processing have been particularly notable in developing large language models such as BERT and MiniLM\u00b9, which have significantly improved the understanding of contextual relationships within text. These models enable more nuanced keyphrase extraction by leveraging deep contextual embeddings. However, even with LLMs, achieving a balance between relevance and diversity in keyphrase selection remains challenging.\nMany approaches focus on maximizing relevance or incorporating diversity through heuristic methods, but few offer a theoretically grounded framework that optimally combines both objectives.\nTo overcome this limitation, we introduce a novel keyphrase ranking method that leverages SFO to balance relevance and diversity. SFO, which exhibit a natural property of diminishing returns, are well-suited for optimization problems where adding new elements to a set yields decreasing incremental benefits. SFO has been successfully applied in various domains requiring diversity, such as document summarization [3] and data subset selection. Despite its potential, the application of submodular optimization to keyphrase extraction remains underexplored. By framing the keyphrase selection task as a submodular maximization problem, our method ensures that the final set of ranked keyphrases is representative and diverse. Our approach integrates SOTA sentence embeddings from pre- trained language models like MiniLM with the"}, {"title": "2. Related Work", "content": "Keyphrase extraction is crucial in NLP, serving to condense content and enhance information retrieval systems. While traditional methods like TF-IDF, and TextRank have been instrumental, they often struggle to capture intricate semantic relationships. The advent of machine learning-based models, such as KEA: Practical Automatic Keyphrase Extraction and clustering techniques, has significantly improved keyphrase extraction by leveraging annotated data and document structure. The recent emergence of large language models (LLMs) like BERT and GPT-2 has further advanced keyphrase extraction, particularly in capturing contextual semantics, but redundancy issues persist. Diversity in keyphrase extraction has been recognized as essential for comprehensive document representation. Techniques like Maximum Marginal Relevance (MMR) and Determinantal Point Process (DPP) have been employed to balance relevance and redundancy in information retrieval and summarization. In keyphrase extraction, methods such as MMR and DPP have improved diversity in EmbedRank++ [4] and [5], respectively. However, these methods often rely on heuristics and lack a formal optimization framework. The underexplored use of SFO in keyphrase extraction, despite its success in domains like document summarization and data selection, presents an opportunity for a principled way to balance relevance and diversity."}, {"title": "3. Methodology", "content": "In this section, we present preliminary, which introduces the definitions of SFO, and proposed method, describing our keyphrase extraction approach using SFO."}, {"title": "3.1 Preliminary", "content": "Let V = {kpi}1 be the set of all candidate keyphrases, where kpi represents the ith candidate keyphrase. The efficacy of a set of keyphrases is modeled by a submodular function f : 2\u00ba \u2192 R, where 2 denotes the power set of V, i.e., all subsets of V.\nFor two sets A \u2286 B \u2286 V and an element x\u2208V\\B, the function f satisfies the diminishing returns property:\nf(A \u222a {x}) \u2212 f(A) \u2265 f(B \u222a {x}) \u2212 f(B),\nwhere A and B represent subsets of selected keyphrases and x is a keyphrase not yet included in the"}, {"title": "3.2 Proposed Method", "content": "The architecture of the proposed method is presented in Figure 1. In this method, we followed the common process of keyphrase extraction and ranking. Begins by tokenizing the input document and tagging each token with its corresponding Part-of-Speech (POS) label. From these tagged tokens, noun phrases (NPs) are extracted, serve as candidate keyphrases. To compare and rank these candidate keyphrases, a pre-trained sentence embedding model, such as MiniLM, is used to generate embeddings for both the NPs and the document. These embeddings are projected into the same dimensional space to facilitate the comparison of relevance between the keyphrases and the document, in our case we chose the size of embedding to 512.\nOur objective is to efficiently select a subset S of keyphrases from the candidate set M, which represents the set of all candidate keyphrases, to maximizes an objective function f(S) that balances both relevance and diversity at the same time. The objective function f(S) is defined as:\nf(S) = \u03a3kpes R(kp) \u2212 \u03b1 \u03a3kpi\u2260kp; Sim(kpi, kpj) (1)\nWhere R(kp) is the relevance score of a candidate keyphrase kp and Sim(kpi, kpj) represents the similarity between keyphrase kpi and kpj The hyperparameter \u03b1 \u2265 0 controls the trade-off between relevance and diversity. The relevance score R(kp) measures how well the keyphrase kp represents the document's content. It is computed using the cosine similarity between the embedding of the keyphrase ekp and the document ep, as defined below:\nR(kp) = cos(ekp, ep) = ekped / ||ekp|| ||ED ||(2)\nThe diversity term penalizes the selection of similar keyphrases to promote a diverse set. The similarity between two keyphrases kpi and kpj is also measured by cosine similarity.\nSim(kpi, kpj) = cos(\u0435\u043a\u0440\u0435\u043a\u0440\u2081) = (\u0435\u043a\u0440\u0435\u043a\u0440\u2081) /  ||ekpi||||ekpj|| (3)\nFinally, a greedy algorithm is employed to rank and select the top N keyphrases. This algorithm progressively constructs the set S of selected keyphrases by adding one keyphrase at a time,"}, {"title": "4. Experiments, and Results", "content": "In this section, we present experimental setup and results, where we evaluate our approach against baseline methods, followed by complexity analysis, which provides a detailed evaluation of the computational complexity of our method."}, {"title": "4.1 Experimental Setup", "content": "We evaluate our model on three public datasets, with dataset statistics provided in Table 1. Our model is compared against three baseline methods, all of which utilize identical tools for tokenization, POS tagging, and noun phrase chunking under the same experimental setup. The NLTK toolkit is used for tokenization and POS tagging. We assess performance using Precision@N, Recall@N, F1-Score@N, diversity metrics, and execution time, where N equals 5. Additionally, we analyze the impact of the trade-off parameter \u03b1 on balancing relevance and diversity in comparison to the baseline methods. The overall performance results are summarized in Table 2. Due to space constraints, we have presented only the F1- Score, omitting Precision@N and Recall@N."}, {"title": "4.2 Results", "content": "In Table 3, varying the trade-off parameter \u03b1 allowed control over this balance at \u03b1 = 0.1. Relevance was prioritized with higher precision but with some redundancy. In contrast, \u03b1 = 0.5 achieved an optimal F1-Score by balancing relevance and diversity, and \u03b1 = 0.9 emphasized diversity but reduced precision.\nWhile our method outperformed in execution time in Figure 2 compared to the baselines. DPP is more computationally expensive, especially on the larger NUS and SemEval datasets, taking up to 80.9 seconds per document, our SFO method maintains competitive runtimes across all datasets, achieving a balance between speed and keyphrase extraction quality.\nTo evaluate the diversity of the keyphrases extracted by our method, we computed the Intra-List Distance (ILD), and Subtopic Recall (SR), on the three datasets. Our method achieved the highest ILD of 0.8277 presented in Table 4, indicating that the selected keyphrases are more dissimilar to each other compared to those from baseline methods. The Subtopic Recall 0. 8144 was also superior, suggesting that our method covers a broader range of topics within the documents."}, {"title": "4.3 Complexity Analysis", "content": "The tokenization, POS tagging, and noun phrase chunking operate in linear time 0(M), where M is the number of candidate keyphrases. Embedding generation and relevance score calculation have a complexity of O(Md), while pairwise diversity scoring adds O(M|S|\u00b7d), where |S| is the selected keyphrase set size. The greedy optimization, selecting keyphrases iteratively, contributes O(M.N.d) per iteration, leading to an overall complexity of O(MN^2.d) across N iterations. Hence, the total complexity is O(M.(1 + N^2)\u00b7d), which remains efficient as N is small relative to M."}, {"title": "5. Conclusion and future work", "content": "Our method balances relevance and diversity by treating keyphrase ranking as a submodular optimization problem and applying a greedy algorithm. This approach ensures comprehensive, non-repetitive keyphrase selection with improved diversity and efficiency. In the future, we plan to explore adaptive strategies for dynamically adjusting the trade-off parameter based on document characteristics to further optimize this balance across various datasets."}]}