{"title": "Dividable Configuration Performance Learning", "authors": ["Jingzhi Gong", "Tao Chen", "Rami Bahsoon"], "abstract": "Machine/deep learning models have been widely adopted for predicting the configuration performance of software systems. However, a crucial yet unaddressed challenge is how to cater for the sparsity inherited from the configuration landscape: the influence of configuration options (features) and the distribution of data samples are highly sparse. In this paper, we propose a model-agnostic and sparsity-robust framework for predicting configuration performance, dubbed DaL, based on the new paradigm of dividable learning that builds a model via \"divide-and-learn\". To handle sample sparsity, the samples from the configuration landscape are divided into distant divisions, for each of which we build a sparse local model, e.g., regularized Hierarchical Interaction Neural Network, to deal with the feature sparsity. A newly given configuration would then be assigned to the right model of division for the final prediction. Further, Dal adaptively determines the optimal number of divisions required for a system and sample size without any extra training or profiling. Experiment results from 12 real-world systems and five sets of training data reveal that, compared with the state-of-the-art approaches, DaL performs no worse than the best counterpart on 44 out of 60 cases (within which 31 cases are significantly better) with up to 1.61x improvement on accuracy; requires fewer samples to reach the same/better accuracy; and producing acceptable training overhead. In particular, the mechanism that adapted the parameter d can reach the optimal value for 76.43% of the individual runs. The result also confirms that the paradigm of dividable learning is more suitable than other similar paradigms such as ensemble learning for predicting configuration performance. Practically, DaL considerably improves different global models when using them as the underlying local models, which further strengthens its flexibility. To promote open science, all the data, code, and supplementary materials of this work can be accessed at our repository: https://github.com/ideas-labo/DaL-ext.", "sections": [{"title": "1 INTRODUCTION", "content": "ALMOST every modern software system is configurable, hence configuration management has become one of the most important phases in software engineering, especially when considering its drastic impact on software performance, such as latency, runtime, and energy consumption [15], [18], [20], [82]. Indeed, while highly configurable software systems provide great flexibility, they also introduce potential risks that can hinder their performance due to the daunting number of configuration options. For example, x264, which is a video encoder, comes with 16 options to tune which can significantly influence its runtime. As such, understanding what performance can be obtained under a given configuration before the deployment is essential for satisfying performance requirements. Practically, the knowledge of configuration performance not only enables better decisions on configuration tuning [17], [19] but also reduces the efforts of configuration testing [10] as well as renders runtime self-adaptation plausible [12], [13], [16].\nTo understand configuration performance, one naive solution is to directly profile the software system for all possible configurations when needed. This, however, is impractical, because (1) there might be simply too many"}, {"title": "1.1 New Extensions", "content": "It is worth noting that this work is a significant extension of our work published at FSE\u203223 [31], for which we make the following key additional contributions:\n\u2022 We provide a more systematic qualitative study to analyze the sparsity characteristics of configuration data, including both a literature review and an empirical study, hence better motivating our needs (Section 2).\n\u2022 The contribution in our FSE'23 work requires manually tuning a crucial parameter d, which controls the number of divisions. This work proposes a novel adaptive mechanism that dynamically adapts the d value to an appropriate level without additional training or profiling (Section 3.1.3).\n\u2022 To determine the optimal d value in the adaptation, we proposed a new indicator \u03bcHV, extending from the standard HV that is widely used for multi-objective evaluation, which can better reflect the goodness and balance between the ability to handle sample sparsity and the amount of data for learning in the divided configuration data (Section 3.1.3).\n\u2022 We evaluate four additional systems that are of different characteristics and additionally compare DaL with the most recent work from TOSEM'23 [22], which reports on a new state-of-the-art approach after our FSE'23 work and has shown compelling results, together with three extra research questions (RQ3, RQ4, and partial RQ5) that help to more thoroughly assess our contributions (Section 5).\nThe experiment results are encouraging: compared with the best state-of-the-art approach, we demonstrate that DaL\n\u2022 achieves no worse accuracy on 44 out of 60 cases with 31 of them being significantly better. The improvements can be up to 1.61\u00d7 against the best counterpart;\n\u2022 uses fewer samples to reach the same/better accuracy.\n\u2022 incurs acceptable training time considering the improvements in accuracy while the adaptation of d has negligible overhead without requiring extra training.\nInterestingly, we also reveal that:\n\u2022 DaL is model-agnostic, significantly improving the accuracy of a given local model for each division compared with using the model alone as a global model (which is used to learn the entire training dataset). However, DaL using the hierarchical deep learning-based approach published at TOSEM'23 [22] as the local model produces the most accurate results.\n\u2022 Compared with ensemble learning, which is the other similar paradigm that shares information between local models, DaL, which follows the paradigm of dividable learning that completely isolates the local model, performs considerably better in dealing with the sample sparsity for configuration data with up to 28.50\u00d7 accuracy improvement over the second-best approach depending on the local model used."}, {"title": "1.2 Organization", "content": "This paper is organized as follows: Section 2 introduces the problem formulation and the notions of sparsity in software performance learning. Section 3 delineates the tailored problem formulation and our detailed designs of DaL. Section 4 presents the research questions and the experiment design, followed by the analysis of results in Section 5. The reasons that DaL works, its strengths, limitations, and threats to validity are discussed in Section 6. Section 7 and 8 present the related work and conclude the paper, respectively."}, {"title": "2 PROBLEM FORMULATION AND METHODOLOGY", "content": "In this section, we introduce the essential problem formulation and the research methodology which leads to the key observations that motivate this work."}, {"title": "2.1 Problem Formulation", "content": "In the software engineering community, configuration performance learning has been most commonly tackled by using various machine learning models (or at least partially) [16], [39], [73], [91], [106]. Such a data-driven process relies on observing the software's actual behaviors and builds a statistical model to predict the configuration performance without heavy human intervention [3].\nFormally, modeling the performance of software with n configuration options is a regression problem that builds:\n$P = f(S), P\\in\\mathbb{R}$\n(1)\nwhereby S denotes the training samples of configuration-performance pairs, such that $X \\in S$. X is a configuration and $x = (x_1,x_2,...,x_n)$, where each configuration option $x_i$ is either binary or categorical/numerical. The corresponding performance is denoted as P.\nThe goal of machine learning-based modeling is to learn a regression function f using all training data samples such that for newly given configurations, the predicted performance is as close to the actual performance as possible."}, {"title": "2.2 Sparsity in Configuration Data: A Qualitative Study", "content": "To confirm the known characteristics of configuration data with respect to sparsity and how it is tackled, we first conducted a literature review for papers related to the performance of software configuration\u00b2 published during"}, {"title": "2.2.3 Discussion", "content": "The above findings reveal the key factors to consider for our problem: when using machine learning models to learn concepts from the configuration data, we need a model that:\n1) handles the complex interactions between the configuration options with high feature sparsity while;\n2) captures the diverse characteristics of configuration samples over all divisions caused by the high sample sparsity, e.g., in Figure 1, where samples in different divisions have diverged performance ranges."}, {"title": "3 DIVIDE-AND-LEARN: Dividable LEARNING FOR CONFIGURATION PERFORMANCE", "content": "Drawing on our observations of the configuration data, we propose DaL-a framework of dividable learning that enables better prediction of the software configuration performance via \u201cdivide-and-learn\". To mitigate the sample sparsity issue, the key idea of DaL is that, since different divisions of configurations show drastically diverse characteristics, i.e., rather different performance values with distant values of key configuration options, we seek to independently learn a local model for each of those divisions that contain locally smooth samples, thereby the learning can be more focused on the particular characteristics exhibited from the divisions and handle the feature sparsity. Yet, this requires us to formulate, on top of the original regression problem of predicting the performance value, a new classification problem without explicit labels. As such, we modify the original problem formulation (Equation 1) as below:\n$D = g(S)$\n(2)\n$\\forall D_i \\in D: P = f(D_i), P\\in\\mathbb{R}$\n(3)\nOverall, we aim to achieve three goals:\n\u2022 Goal 1: dividing the data samples into diverse yet more focused divisions D (building function g) and;\n\u2022 Goal 2: training a dedicated local model for each division Di (building function f) while;"}, {"title": "3.1 Dividing", "content": "The very first phase in DaL is to appropriately divide the data into more focused divisions while doing so by considering both the configuration options and performance values. To that end, the key question we seek to address is: how to effectively cluster the configuration data with similar sample characteristics (Goal 1)?"}, {"title": "3.1.1 Modifying CART for Generating Divisions", "content": "Indeed, for dividing data samples, it makes sense to consider various unsupervised clustering algorithms, such as kMeans [65], Agglomerative clustering [99] or DBSCAN [25]. However, we found that they are ill-suited for our problem, because:\n\u2022 the distance metrics are highly system-dependent. For example, depending on the number of configuration options and whether they are binary/numeric options;\n\u2022 it is difficult to combine the configuration options and performance value with appropriate discrimination;\n\u2022 and clustering algorithms often are non-interpretable.\nAs a result, in DaL, we extend Classification and Regression Tree (CART) as the clustering algorithm (lines 3-12 in"}, {"title": "3.1.2 The Role of Depth d in DaL", "content": "Since more divisions mean that the sample space is separated into more loosely related regions for dealing with the sample sparsity, one may expect that the accuracy will be improved, or at least, stay similar, thereby we should use the maximum possible d from CART in the Dividing phase. This, however, only exists in the \u201cutopia case\u201d where there is an infinite set of configuration data samples.\nIn essence, with the design of DaL, the depth d will manage two conflicting objectives that influence its accuracy:\n1) greater ability to handle sample sparsity by separating the distant samples into divisions, each of which is learned by an isolated local model;\n2) and a larger amount of data samples in each division for the local model to be able to generalize.\nClearly, a larger d may benefit the ability to handle sample sparsity but it will inevitably reduce the data size per division for a local model to generalize since it is possible for CART to generate divisions with imbalanced sample sizes. From this perspective, we see d as a value that controls the trade-off between the two objectives, and neither a too small nor too large d would be ideal, as the former would lose the ability to deal with sample sparsity while the latter would leave too little data for a local model to learn, hence produce negative noises that harm the overall prediction. This is the key reason that setting d for a given system is crucial when using DaL.\nUnfortunately, finding the appropriate d value is not straightforward, as it often requires repeatedly profiling different values following in a trial-and-error manner, which can be rather expensive, especially when the optimal d, which leads to the best mean relative error (MRE), varies depending on the system and even the training/testing data. For example, Figure 4 illustrates the optimal d for DaL on two real-world software systems (the full coverage will be discussed in Section 5.5), from which it is clear that the d = 1 would lead to the best overall MRE for SQLITE, but this becomes d = 2 for LRZIP. If we consider the individual runs that involve different training and testing configuration data, the optimal d could also differ (red lines). Notably,"}, {"title": "3.1.3 Adapting the Depth d", "content": "To overcome the above, in DaL, we design an adaptive mechanism as part of the Dividing phase that is able to dynamically find the d such that the two aforementioned objectives can be optimized and balanced (line 5 in Algorithm 1).\nSpecifically, we use the following functions h and z to measure the ability to handle sample sparsity and the amount of information for a division $D_i$, respectively:\n$\\begin{aligned}\nh(D_i) &= \\frac{1}{|D_i|}\\sum_{Y_j \\in D_i} (Y_j - Y_{D_i})^2 \\\\\nz(D_i) &= -N_{D_i}\n\\end{aligned}$\n(6)\nwhereby z is the additive inverse of the assigned sample size, denoted as $N_{D_i}$. h is basically the mean square error (or performance variance of the samples in a division) taken from the loss function (Equation 5) that splits the divisions with respect to the important configuration options. As such, the samples in a division that are generally closer to each other in terms of the performance value, after being divided according to the importance of key configuration options, will more likely to be beneficial for a local model to learn. Intuitively, both h and z need to be minimized. Given a maximum number of $d_{max}$ divisions generated by CART under the training data, our purpose is to find the d value (0 \u2264 d \u2264 $d_{max}$) that leads to the overall best and most balanced divisions (a.k.a. knee points) in the objective space of h and z from those generated by all possible d values. In essence, from a multi-objective optimization perspective, knee points represent the solutions that, when changed, can only marginally improve one objective by largely comprising the other [16], [105], hence achieving a well-balanced trade-off.\nTo this end, we gain inspiration from a widely used quality indicator for evaluating multi-objective solution sets, namely Hypervolume (HV) [114]. In a nutshell, HV measures the volume between all nondominated points in the objective space and a reference point (usually a nadir point);\nthe larger the volume, the better convergence and diversity that the set achieves. The HV for a solution set A can be computed as:\n$HV(A, r) = \\lambda(\\cup_{a \\in A} {\\{x | a \\prec x \\prec r\\}})$\n(7)\nwhere \u03bb is the Lebesgue measure, which takes into account the trade-offs between the objectives and the spread of the non-dominated solutions in the objective space. It is a default metric in HV used to calculate the volume of the region covered by a set of non-dominated solutions therein. More details can be found in the work of Zitzler and Thiele [114]; r is the reference nadir point, which is often defined as 1.1 times the range of the nondominated set [60]. Li et al. [60] show that, with an appropriate setting of the reference point, HV can well reflect the preference for balanced/knee solutions, which fits precisely with our needs. However, we cannot directly adopt the original HV due to the fact that it can completely omit the contributions of divisions based on their relative domination relations, i.e., a division does not contribute to the HV value at all if it is dominated by the other division under a certain d. Indeed, this makes sense in conventional multi-objective evaluation scenarios, but in our case of dividable learning for configuration performance with DaL, the contribution of each division counts, even if it has been dominated, since the local model under such a division could still impact the result when the newly given configuration falls therein. As a result, the original HV might misjudge the true effectiveness of a d value.\nInstead of leveraging the original HV, in this work, we propose a modified HV, dubbed averaging HV (\u03bcHV), that evaluates the average quality of the HV value that takes each division into account with respect to h and z regardless of the domination relations\u2014a typical specialization of a generic concept to cater for our needs. Formally, the \u03bcHV for all the divisions in a set D under a particular d value is calculated as below:\n$\\mu HV(D, r) = \\frac{1}{|D|} \\sum_{D_i\\in D} (|h_r - h(D_i)|) \\times (|z_r - z(D_i)|)$\ns.t. $r = (h_r, z_r)$\n(8)\nwhereby $h_r$ and $z_r$ are the objective values for mean square error and data size of the reference nadir point r, respectively. Since there are only two objectives to consider in our case, each individual HV value within the \u03bcHV is essentially the area between the corresponding division and the reference nadir point in the objective space. With the above, we realize the following specializations to the original generic HV:\n\u2022 Specialization 1: Through averaging the HV value for each individual division's objectives, \u03bcHV would take into account the contribution made by a division that is dominated by the other. This, conversely, is not the case in the original HV as it works only on the nondominated ones.\n\u2022 Specialization 2: Unlike the original HV that uses 1.1 times the range of the nondominated divisions as the reference nadir point, \u03bcHV takes 1.1 times"}, {"title": "3.2 Training", "content": "Given the divisions generated by the Dividing phase, we train a local model for the samples from each division identified as part of Goal 2 (lines 13-15 in Algorithm 1). Theoretically, we can pair them with any model given the generic concept of dividable learning. However, we adopt the state-of-the-art regularized Hierarchical Interaction Neural Network [22] (namely HINNPerf) to serve as the default in this work, as Cheng et al. provide compelling empirical evidence"}, {"title": "3.3 Predicting", "content": "When a new configuration arrives for prediction, DaL chooses a local model of division trained previously to infer its performance. Therefore, the question is: how to assign the new configuration to the right model (Goal 3)? A naive solution is to directly feed the configuration into the CART from the Dividing phase and check which divisions it associates with. Yet, since the performance of the new configuration is unforeseen from the CART's training data, this solution requires CART to generalize accurately, which, as mentioned, can easily lead to poor results because CART is overfitting-prone when directly working on new data [53].\nInstead, by using the divided samples from the Dividing phase (which serves as pseudo labeled data), we train a Random Forest\u2014a widely used classifier and is resilient to overfitting [7], [77], [94]\u2014to generalize the decision boundary and predict which division that the new configuration should be better assigned to (lines 16-22 in Algorithm 1)."}, {"title": "4 EXPERIMENT SETUP", "content": "Here, we delineate the settings of our evaluation. In this work, DaL is implemented based on Tensorflow and scikit-learn. All experiments were carried out on a server with 64-core Intel Xeon 2.6GHz and 256G DDR RAM."}, {"title": "4.1 Research Questions", "content": "In this work, we comprehensively assess DaL by answering the following research questions (RQ):\n\u2022 RQ1: How accurate is DaL compared with the state-of-the-art approaches (i.e., HINNPerf, DeepPerf, Perf-AL, DECART, and SPLConqueror), and other models from the machine learning community that share a similar concept (i.e., IBMB, M5, PILOT, and MOB), for configuration performance learning?\n\u2022 RQ2: To what extent DaL can improve different generic models (i.e., HINNPerf, regularized Deep Neural Network, CART, Linear Regression, and Support Vector Regression) when they are used locally therein for predicting configuration performance?\n\u2022 RQ3: How do DaL perform compared with the existing ensemble approaches such as Bagging and Boosting?\n\u2022 RQ4: What is the benefit of the components in DaL? This consists of three sub-questions:\nRQ4.1: What is the benefit of using CART for dividing in Dal over the standard clustering algorithms?\nRQ4.2: What is the benefit of the mechanism that adapts d compared with the variant that relies on pre-tuned fixed d as what was used in our previous FSE work?\nRQ4.3: What is the benefit of \u03bcHV over the original HV in adapting d?\n\u2022 RQ5: What is the sensitivity of DaL to a fixed d and how well does the adaptive mechanism perform in finding the optimal d for each individual run?\n\u2022 RQ6: What is the model building time for DaL?\nWe ask RQ1 to assess the effectiveness of DaL under different sample sizes against the state-of-the-art approaches and other models that share a similar concept. Since DaL is naturally model-agnostic and can be paired with different local models, we study RQ2 to examine how the concept of dividable learning can benefit any given local model. Since DaL is similar to the ensemble approaches, e.g., Bagging [5] and Boosting [83], with RQ3, we seek to examine how it performs against those. RQ4 is mainly an ablation analysis of DaL, consisting of confirming the necessity of using CART to determine the divisions over unsupervised clustering algorithms; verifying the effectiveness of adapting d compared with its counterpart under a fixed best d value obtained via trial-and-error; and assessing the benefit of using the newly proposed \u03bcHV in quantifying the usefulness of the divisions in a d value. In RQ5, we examine, under an extensively increased training sample size, how the depth of division (d) can impact the performance of DaL and how well the mechanism that adapts d can locate the optimal setting in individual runs, which is the ground truth. Finally, we examine the overall overhead of DaL in RQ6."}, {"title": "4.2 Subject Systems and Sample Sizes", "content": "Leveraging the criteria and procedure mentioned in Section 2.2.2, we use the same datasets of all valid configurations from real-world systems as widely used in the literature [36], [37], [76], [85], [86]. The 12 configurable software systems studied in this work are specified in Table 2. As can be seen, these software systems come with diverse domains, scales, and performance concerns. Some of them contain only binary configuration options (e.g., x264) while the others involve mixed options (binary and numeric), e.g., HSMGP, leading to configuration data that can be more difficult to model and generalize [37]. Note that the key performance-related configuration options have been identified in existing studies, hence although some systems have mixed options (e.g., APACHE), they are still binary in the dataset as those are key options that can influence the performance.\nThe configuration data of all the systems are collected by prior studies using the standard benchmarks with repeated measurements [36], [37], [76], [85], [86]. For example, the configurations of APACHE\u2014a popular Web server\u2014are benchmarked using the tools Autobench and Httperf, where workloads are generated and increased until reaching the point before the server crashes, and then the maximum load is marked as the performance value [36]. The process repeats a few times for each configuration to ensure reliability. When there exist multiple measured datasets for the same software system, we use the one with the largest size.\nTo ensure the generalizability of the results, for each system, we follow the protocol used by existing work [37], [85], [88] to obtain five sets of training sample size in the evaluation:\n\u2022 Binary systems: We randomly sample n, 2n, 3n, 4n, and 5n configurations and their measurements, where n is the number of configuration options [37], [85]."}, {"title": "4.3 Metric and Statistical Validation", "content": "For all the experiments, mean relative error (MRE) is used as the evaluation metric for prediction accuracy, since it provides an intuitive indication of the error and has been widely used in the domain of software performance prediction [36], [37], [85]. Formally, the MRE is computed as:\n$MRE = \\frac{1}{k} \\sum_{t=1}^k |\\frac{A_t - P_t}{A_t}| \\times 100\\%$\n(9)\nwhereby At and Pt denote the tth actual and predicted performance, respectively. To mitigate bias, all experiments are repeated for 30 runs via bootstrapping without replacement."}, {"title": "4.3.2 Statistical Test", "content": "Since our evaluation commonly involves comparing more than two approaches, we apply Scott-Knott test [70] to evaluate their statistical significance on the difference of MRE over 30 runs, as recommended by Mittas and Angelis [70]. In a nutshell, Scott-Knott sorts the list of treatments (the approaches that model the system) by their median values of the MRE. Next, it splits the list into two sub-lists with the largest expected difference [102]. For example, suppose that we compare A, B, and C, a possible split could be {A, B}, {C}, with the rank (r) of 1 and 2, respectively. This means"}, {"title": "5 EVALUATION", "content": "We now present and discuss the experimental results."}, {"title": "5.1 Comparing with the State-of-the-art Approaches", "content": "To understand how DaL performs compared with the state-of-the-art approaches, we assess its accuracy against both the standard works for configuration performance learning that rely on statistical learning together with recent deep learning-based ones:\n\u2022 SPLConqueror [88]: linear regression with joint terms.\n\u2022 DECART [36]: an improved CART with hyperparameter tuning.\n\u2022 DeepPerf [37]: a single global regularized deep neural network.\n\u2022 Perf-AL [85]: an adversarial learning method.\n\u2022 HINNPerf [22]: a hierarchical deep neural network with embedding.\nAdditionally, we examine four approaches from the machine learning community that share a similar basic concept to DaL:\n\u2022 IBMB [79]: a model that combines predictions from instance-based learning and model-based learning techniques.\n\u2022 M5 [78]: a tree that divides to minimize the variance of each subset and trains a linear model for each leaf node.\n\u2022 MOB [107]: a model that divides based on parametric models and parameter instability tests.\n\u2022 PILOT [80]: a model divides similarly to CART but without pruning and trains linear models at the leaf nodes.\nAll approaches can be used for any type of system except for DECART, which works on binary systems only. The same randomly generated training and testing samples are used for all models, which are selected by using random"}, {"title": "5.1.2 Results", "content": "The results have been illustrated in Table 4, from which we see that, remarkably, DaL achieves the best median MRE on 41 out of 60 cases. In particular, DaL considerably improves the accuracy, i.e., by up to 1.61\u00d7 better than the second-best one on S4 of LRZIP (5.95 vs. 15.55). The above still holds when looking into the results of the statistical test: DaL is ranked first for 44 out of the 60 cases, in which DaL obtain the sole best rank for 31 cases. In particular, among the 19 cases where DaL does not achieve the best MRE, the inferiority to the best on 6 of them is actually insignificant since it is still equally ranked as the best together with the others. That is to say DaL is, in 44 cases, similar to (13 cases) or significantly better (31 cases) than the best state-of-the-art approaches for each specific case (which could be a different approach). Overall, DaL obtain an average rank of 1.47\u2014the smallest among those of the others\u2014indicating that it is much more likely to be ranked the best in terms of MRE. It is also worth noting that, the general model from the machine learning community (e.g., PILOT), although sharing a similar concept to DaL, are even inferior to some state-of-the-art models for configuration performance learning such as DeepPerf. This is because they have not been designed to handle the specific sparsity in configuration data.\nWhen considering different training sample sizes, we see that Dal performs generally more inferior than the others when the size is too limited, i.e., S\u2081 and S2 for the binary systems. This is expected as when there are too few samples, each local model would have a limited chance to observe the right pattern after the splitting, hence blurring its effectiveness in handling sample sparsity. However, in the other cases (especially for mixed systems that have more data even for S1), Dal needs far fewer samples to achieve the same accuracy as the best state-of-the-art. For example, on LRZIP, DaL only needs 295 samples (S2) to achieve an accuracy better than the accuracy of the second best model DeepPerf with 907 samples (S5), saving 67% effort of data measurements. This is a beneficial outcome of properly handling the sample sparsity. That is, when a global model learns all the configuration data, it is often that case that more data is needed in order to correctly learn the full distribution of the data, as the sparsity causes the data points to spread in the landscape. In contrast, with DaL where the data can be properly divided, each local model can quickly learn the distribution of data in its local division, since the data is much more condensed to each other.\nAnother observation is that the improvements of DaL is much more obvious in mixed systems than those for binary systems. This is because: (1) the binary systems have fewer training samples as they have a smaller configuration space. Therefore, the data learned by each local model is more restricted. (2) The issue of sample sparsity is more severe"}, {"title": "5.2 DaL under Different Local Models", "content": "Since the paradigm of dividable learning is naturally agnostic to the underlying local models, we seek to understand how well DaL performs with different local models against their global model counterparts (i.e., using them directly to learn the entire training dataset without dividing). To that end, we run experiments on a set of global models available in scikit-learn that are widely used in software engineering tasks to make predictions directly [30], such"}, {"title": "5.2.2 Result", "content": "From Table 5, it is clear that when examining each pair of the counterparts in terms of the average rank, i.e., DaLx and X, DaL can indeed improve the accuracy of the local model via the concept of \u201cdivide-and-learn\u201d. Such an improvement is particularly obvious on some simple models, such as LR, which might lead to 26.08\u00d7 better MRE on NGINX under S1. This confirms the generality and flexibility of DaL: for example, when LR needs to be used as the local model for the sake of training overhead, DaL can still significantly improve the results compared with its global counterpart. Interestingly, when pairing Dal with CART as the local model, it remains slightly better than using CART as the global model alone, even though their learning procedures are similar. This is possible as the actual result of the computed loss can be different in CART when it is presented with different proportions of the data samples. Yet, the resulting MREs do not differ much as can be seen."}, {"title": "5.3 Comparing with Other Ensemble Approaches", "content": "Since Dal works with multiple local models, it could naturally be compared with the ensemble learning approaches"}, {"title": "5.3.2 Results", "content": "The results can be seen in Table 6", "others": "amongst the 60 cases", "systems": "this is again due to the fact that those systems often come with a more sparse and complex configuration landscape, which is"}]}