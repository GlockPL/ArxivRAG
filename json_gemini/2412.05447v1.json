{"title": "A Graph-Based Approach for Conversational AI-Driven Personal Memory\nCapture and Retrieval in a Real-world Application", "authors": ["Savini Kashmira", "Jayanaka L. Dantanarayana", "Joshua Brodsky", "Ashish Mahendra", "Yiping Kang", "Kriszti\u00e1n Flautner", "Lingjia Tang", "Jason Mars"], "abstract": "TOBU is a novel mobile application that captures and retrieves 'personal memories' (pictures/videos together with stories and context\naround those moments) in a user-engaging AI-guided conversational approach. Our initial\nprototype showed that existing retrieval techniques such as retrieval-augmented generation\n(RAG) systems fall short due to their limitations in understanding memory relationships,\ncausing low recall, hallucination, and unsatisfactory user experience. We design TOBU-\nGraph, a novel graph-based retrieval approach.\nDuring capturing, TOBUGraph leverages large\nlanguage models (LLMs) to automatically create a dynamic knowledge graph of memories,\nestablishing context and relationships of those\nmemories. During retrieval, TOBUGraph combines LLMs with the memory graph to achieve\ncomprehensive recall through graph traversal.\nOur evaluation using real user data demonstrates that TOBUGraph outperforms multiple\nRAG implementations in both precision and recall, significantly improving user experience\nthrough improved retrieval accuracy and reduced hallucination.", "sections": [{"title": "Introduction", "content": "In today's digital age, people increasingly use mobile applications to capture meaningful life moments, storing images, videos, and audio to preserve their digital 'personal memories'. In 2024,\nan estimated 1.94 trillion photos will be taken globally, averaging 5.3 billion photos daily, with the average American capturing 20 photos per day (Broz,\n2024). However, the current software offerings such as Apple photo and Faceboook only provide very basic multimedia storage and organization, falling short in capturing true 'memories', missing\nthe rich contextual details and narratives around the pictures such as events and sentiments. In addition, they provide very limited retrieval capabilities.\nFor example, users need to manually add details through tagging people and providing captions and\ncomments. When retrieving a memory, users are\nconfined to basic search and filter functionalities, making it difficult to perform natural searches like\n\"family trips with both David and John in the mountains\". Instead, memory retrieval often involves\ninefficient scrolling through chronological feeds manually or relying on simple keyword searches.\nTOBU's mission is to address these limitations, and help users capture and preserve context-rich\nmemories, organize them based on their relationships, just as the human brain organizes memories.\nIn addition, TOBU aims to enable effortless and accurate memory retrieval as how humans recall relevant memories. We designed and launched a\nmobile application shown in Figure 1, currently\ncommercially available with a wide user base. Unlike current software solutions, TOBU presents\nnovel capabilities to capture and retrieve memories through conversations with an AI assistant in\na user-engaging manner, extracting rich context\naround pictures and enabling much more accurate\nand satisfactory memory retrieval.\nDesigning such a system involves addressing\nkey challenges such as extracting the context\nand relationships about memories and enabling\naccurate memory retrievals. In conversational\nAI applications, retrieval is often implemented\nthrough Retrieval-Augmented Generation (RAG)\n(Asai et al., 2023; Gao et al., 2024) or structured\nknowlege graph retrieval(Su et al., 2024; Chen\net al., 2024). Both approaches have significant\nlimitations for our use case. RAG stores unstructured data in a vector database and retrieves it using\nembeddings. While RAG is effective for document-based retrieval, experiments with our initial prototype implemented using RAG show that it faces several limitations when applied to memory retrieval:\n*   RAG's performance heavily depends on\n    chunking configuration, often leading to low\n    recall.\n*   Across our experiments of various embedding strategies, the low embedding quality for\n    'memories' often leads to low precision or low\n    recall.\n*   When related memories do not exist, Large\n    Language Models (LLMs) may hallucinate\n    non-existent data.\n*   Chunks from unrelated memories can combine into incorrect or mixed results.\n*   Vector embeddings do not adequately capture\n    complex relationships between memories.\nAn alternative approach for information organization and retrieval is through knowledge graphs,\nwhich structure data through explicit relationships\n(Su et al., 2024). Knowledge Graphs address some\nof these RAG challenges by enabling fine-grained\nretrieval through graph traversal. However, their\nconstruction and management are labor-intensive\nand lack adaptability to dynamic, user-generated\ndata.\nTo address the limitations of both RAG and\nknowledge graph-based approaches, we propose\nTOBUGraph, a novel dynamic conversational\ngraph-based memory retrieval technique that we\nultimately adopted in the TOBU app. Our approach\ntransforms pictures and conversations about a memory into a structured memory graph using LLMs.\nThe graph consists of semantic nodes representing\nkey features of each memory, and interest nodes as\ncommon themes between various memories. These\nnodes are dynamically created and interlinked, en-\nabling the system to capture nuanced relationships\nbetween memories. Unlike traditional knowledge\ngraphs, TOBUGraph leverages LLMs for intelligent graph formation and traversal, eliminating the\nmanual effort and facilitating comprehensive and\nefficient memory retrieval. This method also addresses the limitations of RAG through structured\ngraph nodes, improving recall and precision while\nminimizing hallucinations.\nUsing real-world data from the existing user\nbase of the TOBU app, we evaluated the memory\nretrieval technique of the TOBUGraph approach\nagainst multiple RAG baseline implementations.\nTOBUGraph outperforms the baseline approaches\nin retrieval accuracy, efficiency, and user satisfaction, achieving 92.86% precision (vs. 78.58%\nbest baseline), 93.33% recall (vs. 80% best baseline), and 93.09% F1 (vs 81.48% best baseline).\nIt also demonstrated around 20% improvement in\nuser experience and satisfaction over the next-best\nbaseline in human study, with consistently higher\npreference ratings in human evaluations across di-\nverse memory recall scenarios.\nThe main contributions of this paper are as fol-\nlows.\n1.  A novel memory capturing approach using\n    dynamic graph structures.\n2.  An LLM-powered extractor for dynamic, com-\n    plex relationships across memories.\n3.  A novel graph-based memory retrieval system\n    for enhanced user interaction.\n4.  A Comprehensive evaluation against RAG sys-\n    tems using real-world user data."}, {"title": "TOBUGraph", "content": "In this section, we present TOBUGraph, a novel\ngraph-based retrieval approach we integrated into\nthe TOBU app. TOBUGraph addresses two main\nlimitations of RAG and knowledge graph ap-\nproaches.\nDuring capturing (Figure 2), TOBUGraph leverages a LLM and automatically extracts semantics\nfrom user-provided pictures to create context rich\nmemories. In addition, it also extracts and establishes relationships among those memories and\ncreates a dynamic, contextually relevant memory\ngraph. This graph generation process is fully automatic, reducing the manual effort of creating knowledge graphs in prior work.\nDuring retrieval(Figure 3), user can interact with\nTOBU through a conversational AI assitant. TO-\nBUGraph combines LLMs with the memory graph,\nefficiently navigating the graph to achieve comprehensive recall through graph traversal, providing superior retrieval performance over RAG approaches.\nThe following sections outline each step of the TO-\nBUGraph process."}, {"title": "Memory Input Data Collection", "content": "TOBU app uses both automatic image analysis\nand conversational AI assistant to help users create\nmemory entries. When users provide multimedia\ninputs, such as images, videos, or audio, TOBU app\nfirst applies object recognition, emotion detection,\nscene recognition and geolocation estimation to au-\ntomatically extract semantic and context around the\nmedia. TOBU AI assistant then initiates a conver-\nsation with the user, gathering further details. This\ninteractive process is designed to be user-engaging,\nfun and not labor-intensive."}, {"title": "Memory Graph Construction", "content": "Memory Graph Construction Engine processes the\nextracted semantics and conversational data to cre-\nate a graph-based structure as illustrated in Figure\n2.\nSemantic Extraction Module: In addition to\nthe image analysis described earlier, the extraction\nmodule leverages an LLM to process the user-AI\nconversation, augmenting and updating with future\ndetails such as participants, activities, stories, and\nsentiment. Each of semantic details the system\nextracted is stored in a dedicated semantic node\nlinked to the memory node. A summary of the\nmemory is also generated and stored as a distinct\nsemantic node.\nBasic Memory Graph Structure: The initial\nmemory graph can be represented as $G = (V, E)$\nwhere $V = M \\cup S$ represents memory nodes\n$M = \\{m_1, m_2, ..., m_n\\}$ and semantic nodes $S =$\n$\\ {S_1, S_2, ..., S_k\\}$. The edge set $E \\subset M \\times S$ connects"}, {"title": "Relational Memory Graph: Augmenting\nwith Relationship Information", "content": "After the basic memory graph is constructed,\nTOBUGraph will interconnect multiple memory\ngraphs of each user into one unified structure called\nthe Relational Memory Graph (RMG) as in Figure\n2. This structure captures the relationships across\nmemories using interest nodes that serve as central\npoints, enabling the system to access all memories\nlinked to a specific interest.\nRelation Extraction Module Using LLMs, we\nanalyze each memory graph independently to ex-\ntract users' various 'interests' from the memories.\nThese interests are common themes capturing key\ntopics and aspects that the memories are often centered around, such as hobbies, locations, activities,\npreferences, important dates, or people mentioned.\nFor each identified interest, a dedicated unique in-\nterest node is created and connected to all the rel-\nevant memory nodes. Therefore, those memories\nwith each common theme are connected through\nthe shared interest node, creating a graph with in-\nterconnected memories.\nAugmented Graph Formulation: The RMG ex-\ntends the basic graph $G$ to $G' = (V', E')$ where\n$V' = M \\cup S \\cup I$ includes interest nodes $I =$\n$\\ {11, 12, ..., i_p\\}$. The extended edge set $E' \\subseteq (M \\times$\n$S) \\cup (M \\times I)$ connects memory and interest nodes.\nFor each memory node $m_i$, connected semantic\nnodes are $S_i = \\{s_j|(m_i, s_j) \\in E'\\}$, and connected\ninterest nodes are $I_i = \\{i_j|(m_i,i_j) \\in E'\\}$."}, {"title": "Memory Retrieval", "content": "TOBUGraph enables users to recall memories\nthrough an integrated conversational AI assistant\nthat interacts with the user's RMG as shown in Figure 3. When a user initiates a memory retrieval\nrequest, the system first identifies all interest nodes\nconnected to the RMG and generates a prompt com-\nbining the user request with the content of these\nnodes. This prompt is processed by an LLM to\nfilter and identify the most relevant interests related\nto the user's request. The system then traverses the\nRMG through the identified interest nodes to re-\ntrieve associated memory nodes and their semantic\ncontent.\nThe conversational AI analyzes semantic nodes\nof retrieved memories, to generate targeted re-\nsponses. If the user's request contains sufficient\ndetails, the response is direct, avoiding unneces-\nsary follow-up questions.Otherwise, the AI assis-\ntant requests clarification. As this conversation progresses, the system continuously refines its traver-\nsal of the RMG, ensuring increasingly accurate\nmemory retrieval that enhances the user's experi-\nence.\nRetrieval Process Formalization: The memory\nretrieval process can be formalized as:\n1.  Interest relevance: $f(q, I) \\rightarrow I' \\subseteq I$, where\n    f identifies relevant interest nodes I' for a\n    given query q.\n2.  Memory retrieval: $g(I', G') \\rightarrow M' \\subseteq M$,\n    where g retrieves memory nodes M' connected to I' in the RMG G.\n3.  Response generation: $h(q, M', S') \\rightarrow r$,\n    where $S' = \\cup S_i|m_i \\in M'$, and h generates\n    the response r based on q, M' and S'."}, {"title": "Evaluation", "content": "To evaluate our proposed TOBUGraph approach,\nwe implement three versions of naive RAG sys-\ntems using LangChain and ChromaDB as baseline\napproaches. The basic RAG pipelines consists of\nfour sequential steps: (1) memory storage document chunking, (2) vector embedding of chunks\nand vector database storage, (3) retrieval of k most\nrelevant chunks based on user request, and (4) response generation by combining user request and\nretrieved chunks using LLM (Wu et al., 2024).\nThe three implementations differ primarily in\ntheir chunking strategies and input data sources as\nrepresented in Table 1. RAGv1 processes memory\nsummaries by splitting them into fixed-size chunks\nwith specified overlap. RAGv2 also uses memory\nsummaries but creates chunks aligned with memory\nboundaries, where each chunk corresponds to one\nmemory summary. RAGv3 diverges by using raw\nuser-assistant conversations instead of summaries,\nsplitting the input at memory boundaries so each\nchunk contains one complete conversation."}, {"title": "Dataset Construction", "content": "Using real memory data from five highly active\nTOBU app users, we selected four unique memory retrieval conversations per user, utilizing the\nTOBUGraph memory retrieval technique. For comparison, we applied the same memory retrieval\nrequests to generate conversations using baseline\nRAG approaches where the only difference be-\ntween TOBUGraph and baseline approaches being\nthe retrieval technique."}, {"title": "Quantitative Analysis", "content": ""}, {"title": "Retrieval Metrics Evaluation", "content": "To evaluate TOBUGraph against the baseline approaches discussed in Section 3.1, we use standard\ninformation retrieval metrics: Precision (percentage of retrieved memories that were actually relevant), Recall (percentage of relevant memories\nthat were successfully retrieved), and F1 score\ncalculated using the dataset described in Section"}, {"title": "User Experience Evaluation", "content": "We then conducted a human-based study to quantitatively analyze user experiences across different\napproaches. Using the dataset outlined in Section\n3.2, we applied a double-blind pairwise comparison method via crowd-sourcing, leveraging the\nSLAM tool. This tool facilitates pairwise match-\nups of responses to a single query (Irugalbandara\net al., 2024). A total of 240 evaluators participated,\neach evaluating exactly 10 pairwise comparisons.\nTo ensure unbiased results, no evaluator reviewed\npairs involving the same request, and all pairs were\nevaluated equally.\nAn analysis of the evaluator preferences across\nthe 20 user requests in Figure 4a reveals that preferences for the best approach vary depending on the\ntype of memory recall request. TOBUGraph consis-\ntently leads, with preference rates often exceeding\n40% in most cases. In contrast, RAGv1 consistently\nperforms poorly, reflecting limited user satisfaction.\nRAGv2 and RAGv3 show more variability, with\nRAGv3 occasionally matching TOBUGraph's per-\nformance and RAGv2 gaining moderate success in\nspecific instances. This indicates TOBUGraph's\nadaptability and effectiveness in delivering an en-\nhanced user experience across diverse scenarios.\nBy examining the results of the evaluator pref-\nerence probability for each approach, a clear trend\nemerges favoring the TOBUGraph approach, as\nillustrated in the Figure 4b. TOBUGraph con-\nsistently achieves higher preference probabilities,\nwith a median around 0.75, indicating that the ma-\njority of users found it effective. On the other hand,\nRAGv1 demonstrates the lowest median 0.25, highlighting its lower favorability. RAGv2 and RAGv3\nshow more balanced distributions, with peaks in\nthe mid-range probabilities, suggesting moderate\npreferences. These findings highlight the TOBU-\nGraph's effectiveness in delivering a more satisfy-\ning user experience compared to the baseline RAG\napproaches."}, {"title": "Qualitative Analysis", "content": "To evaluate TOBUGraph approach against baseline\nRAG models using the dataset created in Section\n3.2, we also conducted a qualitative analysis. Key\nobservations are summarized in Table 3, with detailed discussion below."}, {"title": "Low recall due to top k chunk limitation:", "content": "In baseline RAG approaches, only the top k most\nrelevant chunks are retrieved. Because of this all"}, {"title": "Conclusion", "content": "In this paper, we introduced TOBUGraph, a novel\nframework for digital memory capture and retrieval\nthat combines dynamic graph structures with LLM-\npowered extraction to establish intelligent relationships between memories. TOBUGraph outper-\nformed three RAG baseline implementations in\nboth quantitative and qualitative evaluations. By\naddressing key limitations of traditional RAG sys-\ntems, such as fragmentation and hallucinations,\nTOBUGraph delivers a more reliable and cohesive\nmemory experience. Its successful deployment in\na production mobile application underscores its\npractical viability and paves the way for future ad-\nvancements in digital memory systems."}]}