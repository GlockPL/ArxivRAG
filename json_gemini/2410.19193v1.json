{"title": "Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media", "authors": ["Bruno Silva", "Thomas Palmeira Ferraz", "Roseli de Deus Lopes"], "abstract": "Disinformation on social media poses both societal and technical challenges. While previous studies have integrated textual information into propagation networks, they have yet to fully leverage the advancements in Transformer-based language models for high-quality contextual text representations. This work investigates the impact of incorporating textual features into Graph Neural Networks (GNNs) for fake news detection. Our experiments demonstrate that contextual representations improve performance by 9.3% in Macro F1 over static ones and 33.8% over GNNs without textual features. However, noisy data augmentation degrades performance and increases instability. We expect our methodology to open avenues for further research, and all code is made publicly available.", "sections": [{"title": "1 Introduction", "content": "The spread of fake news on social media poses a serious societal challenge, disrupting public opinion and undermining trust in the media. While progress has been made in fake news detection using language processing [1, 2] and hierarchical graph propagation [3] separately, recent advancements in both domains have yet to be fully leveraged together. Few works exploit the combined potential of the recent advances of these directions to develop graph-based models that capture both the structural and semantic properties of social media networks. Graph Neural Networks (GNNs) [4] are particularly well-suited for this task, given their ability to model complex information propagation. However, the noisy, incomplete nature of social media data, including user interactions and profile details, still poses significant challenges.\n\nA few studies have explored integrating textual information into graph hierarchical propagation tasks [5, 6], including the use of static representations with GNNs for fake news detection [7]. However, these approaches do not fully utilize recent advancements in Transformer-based language models (LMs), which have significantly improved textual representations by capturing complex contextual relationships [8-10]. Moreover, there has been limited systematic evaluation of the impact of textual features on GNN node representations.\n\nThis work addresses this gap by investigating how textual information from user profiles and user interactions (retweets) content affects GNN performance in disinformation campaigns detection on Twitter (X). We hypothesize that certain behavioral patterns, such as those from bots or biased profiles, can be better captured by incorporating text into the propagation graph. We evaluate the impact of introducing static and contextual text representations on GNN nodes. Additionally, we address the common issue of class imbalance in fake news detection by evaluating the use of Noisy Embedding Augmentation [11], a technique widely applied in the text domain to enhance model robustness through simulated data perturbations. We investigate its effectiveness for GNN training.\n\nOur results demonstrate that incorporating contextual text representations into GNNs from both user profile and user comments leads to relative Macro Flimprovements 9.3% over static representations"}, {"title": "2 Proposed Model", "content": "GNNs for Disinformation Campaign Detection. Detecting disinformation campaigns involves classifying the propagation network G of a news item vo being shared on social media. This network is constructed by merging all diffusion trees Dt\u2081 = {Vio, {Vi10, {Vil1, . . . }, . . . }, . . . }, obtained from all vio root publications mentioning the news vo, as proposed by Shu et al. [3] and Michail et al. [7]. The resulting network forms a directed graph G = (V, E), where the central node vo represents the news, and the edges represent the radial spread of information through the social media. The task is framed as a binary classification problem, where the goal is to classify whether the propagation network corresponds to fake or true news.\n\nTo achieve this, we first construct a feature vector X for each node v \u2208 G, capturing its key characteristics. Graph Neural Networks (GNNs) are particularly well-suited for this task, as they capture the dependencies within a graph through message passing between nodes, updating each node's feature vector X with contextual information from its neighbors. In this work, we specifically use Graph Attention Networks (GATs) [12], which generate node embeddings through attention-based neighbor aggregation. These node embeddings are subsequently pooled to create a graph-level embedding, which is then passed through a Multi-Layer Perceptron (MLP) for final classification.\n\nText Representations. To enrich the feature vectors X of nodes v \u2208 G, we incorporate textual representations, which can be either static or contextual. Static encoders assign a fixed embedding to each word, regardless of context. For instance, the word \"bank\" will have the same embedding whether it refers to a financial institution or a riverbank. In contrast, contextual encoders generate dynamic embeddings based on surrounding words, providing a more accurate representation of word meaning within specific sentence contexts. This makes contextual embeddings particularly effective for capturing nuances in short texts.\n\nImbalance Problem. A typical issue in fake news detection is the highly negative class imbalance problem, where there is significantly more true news than fake news in the real world. Depending on the goal of an automatic detector, we may focus on flagging as many relevant instances as possible for human review (recall) or ensuring only truly fake news is flagged (precision). In fully automated detection, balancing these two objectives is critical, though this raises ethical concerns [13].\n\nClassical learning methods to address class imbalance include downsampling (reducing the majority class data) or upsampling (duplicating minority class instances). However, these techniques can be suboptimal for graph classification: downsampling may remove valuable structural data, and upsampling risks overspecialize to specific graph structures, as each graph instance should typically be unique. Nevertheless, upsampling has shown some success in graph classification tasks [7].\n\nMore recent approaches address imbalance through more graph-tailored data augmentation methods, focusing on structural manipulation or feature noise injection [14-18]. Prior work has demonstrated that adding noise to node features improves robustness and performance across tasks [14, 19]. Similar trends are observed in text processing, where noisy embedding augmentation enhances classification and generation tasks [11, 20-22]. Building on this, we investigate the use of data augmentation through upsampling combined with noise injection into textual features.\n\nResearch Questions. In this work, we examine the impact of incorporating textual content into the social media propagation network on the performance of GNNs for disinformation campaign detection. Specifically, considering the class imbalance problem, we investigate the following research questions: RQ1. Does incorporating textual content from the user profiles involved in spreading the news (referred to as profiles) improve the model's performance? RQ2. Does incorporating textual content from user interactions in the propagation process (referred to as retweets) enhance"}, {"title": "3 Empirical Setup", "content": "Dataset. We conduct our experiments using the Politifact subset of the FakeNewsNet dataset [23], which focuses on U.S. political news. This dataset includes news propagation networks and user comment histories, with labels determined by the fact-checking service. We use the diffusion trees created by Michail et al. [7]. We further enhance the dataset by collecting additional retweet and profile data using the Twitter API, while removing from the dataset any samples that were deleted from the platform. The final dataset contains 1242 propagation graphs labeled as fake news and 10793 labeled as true news (11.5% imbalance ratio).\n\nGraph Model. Our model consists of two GAT layers: the first with 32 units and 4 attention heads, and the second with a single head, followed by a graph pooling layer that averages the node embeddings. This setup is inspired by Michail et al. [7], with the key difference being the removal of GraphSAGE for node aggregation to avoid confounding interactions with noisy data augmentation and different text representations. In our model, the feature vector for each node is defined as X = [X1, X2, X3], where x\u2081 contains propagation-related features (e.g., user attributes like follower count and delay between the post and its predecessor), and x\u2082 and xu represent the textual features from user profiles and retweets, respectively, if these parameters are used.\n\nText Embeddings. To investigate the effect of incorporating textual attributes into node features, we compare the widely used static text encoder, GloVe [24], with the contextual encoder BERTweet [9], which is pre-trained only on Twitter data. The text representation is obtained by the average of the word embeddings. The dimension size is 100 if using GloVe or 768 if using BERTweet. For both models, we assess the impact of including textual content from user profiles (profiles) and user interactions (retweets). Additionally, we explore augmenting text features with NEFTune [11], adding noise to a text representation z to create a new augmented representation x' = x + (a/\u221a||||)\u20ac, where a is the noise amplitude and \u20ac = Uniform(-1,1). Following Jain et al. [11], we experiment with noise amplitudes of 0, 5, 10, 15, 20, and 25.\n\nTraining Details. To address class imbalance, we first perform a stratified dev-test split, creating a test set of 1,203 samples. For training, we employ stratified 10-fold cross-validation on the dev set, ensuring the same class distribution as the full dataset. We train 10 models, using all possible combinations of 9 folds for training and 1 for validation. Then, we employ upsampling on the training folds to balance the classes. Each model is trained for 60 epochs, with the final model selected based on the best validation loss. In total, we train 48 models, covering all possible combinations of the four investigated variables (text encoder, use of text from profiles, use of text from retweets, and noise amplitude) to comprehensively assess their impact.\n\nEvaluation Metrics. We report F1 Macro, AUC Precision-Recall (AUC PR), and ROC AUC, in order of importance, chosen to address the dataset imbalance. F1 Macro offers a balanced evaluation by accounting for precision and recall across both classes, ensuring fair representation of major and minor classes. AUC PR is particularly suited for imbalanced datasets, emphasizing performance in detecting the positive class (fake news). ROC AUC evaluates the model's ability to distinguish between positive and negative classes, illustrating trade-offs between true and false positives. To rank the models, we applied the Wilcoxon-Holm post-hoc analysis of signed-rank paired differences, following methodology from Dem\u0161ar [25] and Ferraz et al. [26], ensuring statistical significance by comparing models trained on the same folds."}, {"title": "4 Results and Discussion", "content": "Figure 1 presents the performance of different model configurations tested.\n\nContextual Representations Significantly Enhance Performance. For models without noise injection (a = 0), the contextual text encoder BERTweet consistently outperformed the static GloVe embeddings. The Wilcoxon-Holm post-hoc analysis confirmed these findings, with all p-values below 0.001, highlighting the robustness of the results. The best configuration, incorporating both profiles and retweets, showed a 9.3% improvement in Macro F1 with BERTweet compared to GloVe and a 33.8% improvement over models without textual features. Overall, these results aligns with our expectations, as BERTweet captures context-specific nuances and is particularly suited for the informal language of social media due to being pre-trained on this data.\n\nRetweets Offer More Value than Profiles. While both profile and retweet textual features improved model performance, retweet content provided significantly greater gains. This is likely due to the sparse nature of user bios, which often offer limited information, primarily aiding in identifying biased users or bots through keywords or the absence of content. In contrast, user comments in the retweets are richer in context and directly related to the news being propagated, making them more useful for capturing meaningful patterns. Contextual representations like BERTweet are particularly effective at interpreting the complex relationships in retweet content, which static embeddings like GloVe often fail to capture. Models using only profile data with GloVe performed similarly to models without textual features, and the combination of profiles and retweets did not improve GloVe-based models. This makes clear that GloVe cannot correctly encode relevant information from profiles when compared to BERTweet, that in turn was able to extract relevant information from profiles as well.\n\nNoise Injection Compromises Model Performance and Stability. Injecting noise into the textual node features resulted in a consistent decline in model performance across all metrics. The Wilcoxon-Holm post-hoc analysis confirmed that models without noise significantly outperformed those with noise in terms of Macro F1 and ROC AUC, with a 95% confidence level (see Appendix A). This performance drop is likely due to the increased instability during training, as indicated by higher variance in predictions with more noise. Rather than improving robustness, noise injection disrupted the learning process, making it harder for the model to capture meaningful patterns and generalize effectively. Future work should explore methods to better balance noise injection and model learning for more effective data augmentation."}, {"title": "5 Conclusion and Future Work", "content": "In this work, we explored the integration of textual information into GNNs for disinformation campaigns detection. Our findings show that incorporating contextual text representations into node features significantly improves GNN performance, with a 33.8% increase in Macro F1. The combined use of both retweet and profile content further were the best results, and contextual representations consistently outperform static ones. However, noise injection, despite its success in text domains, proved unsuitable for GNNs, leading to instability and degraded performance. Future research should explore alternative data augmentation methods, such as structural manipulation, rather than relying solely on feature noise injection and upsampling."}, {"title": "A Other experimental results", "content": "Figure 2 present the standard deviation on the models studied. An increasing trend in the standard deviation was observed as more noise was added, indicating that, as expected, the model's predictions become more unstable with the increase of noise. For the other features, no clear patterns were observed. However, it is important to emphasize the need for future studies focused on verifying the statistical significance of the aforementioned conclusions."}]}