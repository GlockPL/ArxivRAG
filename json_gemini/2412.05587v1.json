{"title": "GEE-OPs: An Operator Knowledge Base for Geospatial Code Generation on the Google Earth Engine Platform Powered by Large Language Models", "authors": ["Shuyang Hou", "Jianyuan Liang", "Anqi Zhao", "Huayi Wu"], "abstract": "As the scale and complexity of spatiotemporal data continue to grow rapidly, the use of geospatial modeling on the Google Earth Engine (GEE) platform presents dual challenges: improving the coding efficiency of domain experts and enhancing the coding capabilities of interdisciplinary users. To address these challenges and improve the performance of large language models (LLMs) in geospatial code generation tasks, we propose a framework for building a geospatial operator knowledge base tailored to the GEE JavaScript API. This framework consists of an operator syntax knowledge table, an operator relationship frequency table, an operator frequent pattern knowledge table, and an operator relationship chain knowledge table. By leveraging Abstract Syntax Tree (AST) techniques and frequent itemset mining, we systematically extract operator knowledge from 185,236 real GEE scripts and syntax documentation, forming a structured knowledge base. Experimental results demonstrate that the framework achieves over 90% accuracy, recall, and F1 score in operator knowledge extraction. When integrated with the Retrieval-Augmented Generation (RAG) strategy for LLM-based geospatial code generation tasks, the knowledge base improves performance by 20-30%. Ablation studies further quantify the necessity of each knowledge table in the knowledge base construction. This work provides robust support for the advancement and application of geospatial code modeling techniques, offering an innovative approach to constructing domain-specific knowledge bases that enhance the code generation capabilities of LLMs, and fostering the deeper integration of generative AI technologies within the field of geoinformatics.", "sections": [{"title": "1. Introduction", "content": "The rapid growth of spatiotemporal data has made geospatial modeling a crucial tool for uncovering the dynamic patterns of geographic phenomena(Breunig et al., 2020). However, the scale and complexity of such data present significant challenges. These datasets often adopt specialized formats (e.g., GeoJSON, GeoTIFF), and their analysis heavily relies on high-precision remote sensing imagery and substantial computational power. Traditional computing platforms struggle to efficiently store, process, and manage these data(Wang et al., 2018). Moreover, the pronounced spatial distribution characteristics of spatiotemporal data, along with the dependence on real-time processing and visualization during modeling, render conventional programming environments inadequate for meeting these demands(He et al., 2019).\nTo address these challenges, Google Earth Engine (GEE) has emerged as a cloud-based computing platform tailored for satellite imagery and spatiotemporal data(Tamiminia et al., 2020). GEE offers a wealth of built-in resources, including vast spatiotemporal datasets and powerful cloud computing capabilities. Users can efficiently access these resources by writing geospatial code, enabling complex geospatial modeling(Yang et al., 2022). Geospatial code is structured around \"operators,\" which are fundamental units containing only functional functions, excluding variables or values(Granell et al., 2010). In other words, operators represent core actions within the code that execute specific functions, typically manifested as function calls that encapsulate particular tasks through standardized syntax. These operators are used for data processing, analysis, and visualization, providing computational, data manipulation, or logical operations(Garcia et al., 2007). Compared to general-purpose code, geospatial code differs significantly in operator naming, function design, and combination strategies(Hou et al., 2024a). While these differences enhance specificity and applicability, they also increase the complexity and barrier to entry for writing code, especially for non-expert users, thus limiting broader adoption.\nThe code generation capabilities of large language model (LLM), also known as NL2Code, offer a promising solution to the challenges mentioned above(Jiang et al., 2024). By expressing requirements in natural language, users can automatically generate code. However, existing LLMs are primarily trained on general-purpose code and lack specialized learning for geospatial code(Gu et al., 2024). As a result, the generated code often contains syntax or logical errors, or even exhibits \"coding hallucinations,\" such as misspelled operator names, improper operator combinations, or the creation of non-existent operators(Hou et al., 2024b). Additionally, the complex structure of geospatial scripts makes operator knowledge difficult to leverage effectively, further hindering the performance of models in geospatial code generation tasks(Mansourian and Oucheikh, 2024).\nTo address the aforementioned issues, constructing a domain-specific knowledge base that contains rich operator knowledge presents a feasible solution(Wang et al., 2023). In domain knowledge injection methods, traditional domain-specific fine-tuning can enhance a model's specialized capabilities; however, it requires substantial computational resources, making it costly and difficult to scale(Jeong, 2024). Moreover, the effectiveness of this approach is heavily influenced by the quality and proportion of the training corpus, which can lead to knowledge dilution or weakened capabilities(Huang et al., 2023). In contrast, Retrieval-Augmented Generation (RAG), by constructing a specialized knowledge base and incorporating prompt engineering techniques, enables dynamic knowledge retrieval during the model generation process. This approach can significantly enhance the model's domain adaptability without the need for large-scale computational power, offering a more cost-effective solution(Gao et al., 2023).\nLeveraging the extensive user base, rich open-source script resources, and diverse code logic and scales of the GEE platform(Liang et al., 2023), we propose a framework for constructing an operator knowledge base, as shown in Figure 1. The framework consists of three main steps: Collection and Organization, Statistical Analysis and Construction, and Validation and Evaluation. Using the GEE platform's JavaScript script database as the experimental dataset, we instantiated the GEE-OPs knowledge base from 185,236 real user scripts. The knowledge base includes an operator syntax knowledge table, an operator relationship frequency table, an operator frequent pattern knowledge table, and an operator relationship chain knowledge table. Evaluation metrics and a validation set were designed to systematically assess the accuracy and effectiveness of the knowledge base in LLM-based geospatial code generation tasks. The results demonstrate that the accuracy of the constructed knowledge base exceeds 90% across various metrics, with an average performance improvement of 20%-30% in multiple LLM geospatial code generation tasks. Additionally, ablation experiments further confirm the necessity of each knowledge table within the knowledge base. This work provides valuable insights, evaluation frameworks, and research directions for future knowledge base construction in LLM-based geospatial code generation tasks."}, {"title": "2. Related Work", "content": null}, {"title": "2.1. Vertical Applications of LLMs", "content": "LLMs based on Transformer architecture and self-attention mechanisms have advanced significantly, demonstrating exceptional performance in general-domain tasks(Zhao et al., 2023). However, their effectiveness in vertical domains heavily depends on the availability and quality of specialized training data(Li et al., 2024a). Challenges include the substantial computational resources required for retraining and the risk of \"knowledge hallucination,\" where models generate plausible but incorrect outputs due to the scarcity of domain-specific data in general-purpose corpora(Andriopoulos and Pouwelse, 2023). To address these challenges, research has focused on enhancing LLMs through domain specialization (LLM+X), with successful applications in fields such as law(Lai et al., 2024), finance(Wu et al., 2023), and biomedicine(Ling et al., 2023; Lu et al., 2024). However, in the GIS domain, while LLMs have been explored for tasks like knowledge question answering(Gupta et al., 2024; Zhang et al., 2024), knowledge extraction(Hou et al., 2024d; Hu et al., 2023), and spatiotemporal reasoning(Jin et al., 2023; Li et al., 2024b), geospatial code generation\u2014a critical capability-remains largely unstudied."}, {"title": "2.2. Code Generation", "content": "The task of code generation (NL2Code) translates natural language requirements into source code(Zan et al., 2022). While early approaches relying on heuristic rules and probabilistic grammar frameworks were limited in handling complex requirements(L\u00f8kketangen and Olsson, 2010; Nymeyer and Katoen, 1997; Raychev et al., 2016), recent advances in LLMs trained on multimodal corpora including text, web content, and code-have significantly improved performance. These models leverage enhanced context understanding, logical reasoning, and code generation capabilities, paving the way for automated programming(Jiang et al., 2024). However, due to the limited proportion of code data in training corpora, LLMs often produce code with syntax or logical errors, or generate non-executable yet superficially plausible outputs-a phenomenon known as \u201ccoding hallucination(Hou et al., 2024c).\" This issue is particularly pronounced in geospatial code generation, where domain knowledge gaps result in operator name misspellings, improper operator combinations, and non-existent operators(Gramacki et al., 2024). Existing evaluation results show that the accuracy of geospatial code, from simple unit tests to complex task-based evaluations, typically falls below 20%(Gramacki et al., 2024; Hou et al., 2024b). Despite advancements in general programming tasks, no dedicated research has yet focused on optimizing LLMs for geospatial code generation."}, {"title": "2.3. Knowledge Bases for LLMS", "content": "Enhancing LLMs typically involves either improving learning capabilities through fine-tuning or injecting domain-specific knowledge via external knowledge bases(Ovadia et al., 2023). Compared to the resource-intensive and less flexible process of fine-tuning, knowledge injection offers a more efficient solution, leveraging high-quality knowledge bases to enhance domain adaptability(Czekalski and Watson, 2024). Constructing these knowledge bases typically involves collecting, processing, and organizing large-scale data from open-source platforms, supplemented by expert input for structural representation, thus optimizing task-specific performance(Wan et al., 2024).Successful applications of knowledge bases have been demonstrated in domains such as biomedicine(Sung et al., 2021), law(Zhou et al., 2024), and finance(Zhao et al., 2024), supporting tasks like question answering, reasoning, and text generation. Among various methods, RAG dynamically retrieves relevant knowledge from a database to improve model generation(Gao et al., 2023). This approach significantly reduces resource consumption, ensures knowledge currency, and offers greater flexibility compared to fine-tuning.However, both general and geospatial code generation lack effective methods for representing and extracting operator relationships. While techniques like Abstract Syntax Trees (AST)(Noonan, 1985), Control Flow Graphs (CFG)(Gold, 2010), and Program Dependency Graphs (PDG)(Ferrante et al., 1987) are widely used in software engineering to analyze and classify source code, they focus primarily on syntax and structure rather than extracting operator relationship knowledge. The systematic development of operator relationship knowledge remains an unexplored and critical research direction."}, {"title": "3. Method", "content": "The construction of GEE-OPs involves three key stages: Collection and Organization, Statistical Analysis and Construction, and Validation and Evaluation."}, {"title": "3.1. Collection and Organization", "content": null}, {"title": "3.1.1. Data Acquisition", "content": "Data acquisition encompasses high-quality geospatial scripts and official operator syntax knowledge. In this study, a large volume of user-contributed GEE scripts was collected from open-source platforms such as GitHub, Zenodo, and HuggingFace. A systematic search strategy, using keywords like \"Google Earth Engine (GEE)\u201d, \u201cJavaScript\u201d, \u201cGIS\u201d, and \u201cGeospatial\u201d, was employed, along with API integration, to automate the download of scripts. During the data collection process, special care was taken to ensure compliance with open-source licensing agreements and mitigate potential copyright risks. Scripts with specific licensing requirements were thoroughly documented, and compliance checks were conducted before use. Additionally, the official GEE platform documentation, which provides detailed descriptions of operator syntax and usage rules, was reviewed and compiled by domain experts to support the construction of the knowledge base. A total of 185,236 GEE scripts were collected, all written in JavaScript, spanning from September 2015 to September 2024. The script sizes ranged from 1 KB to 533 KB, with a total dataset size of 0.799 GB. The operator syntax data comprises 1,374 entries. The specific characteristics of the dataset are summarized in Table 1."}, {"title": "3.1.2. Comment Filtering", "content": "Due to variations in coding habits, programming styles, and language features among script developers, the collected geospatial scripts often contain redundant information such as comment text, debugging code, and outdated links. These extraneous elements can interfere with the extraction of operator relationships. To address this, a character-based rule constraint was applied to clean the scripts by removing all non-executable code segments and excess comments, while retaining the core functional code. This process optimized the script structure, reduced the dataset size, and facilitated subsequent structured representation based on ASTs."}, {"title": "3.1.3. Syntax Checking", "content": "The syntax correctness of open-source scripts cannot be fully guaranteed, and syntax errors may introduce incorrect knowledge during the extraction of operator relationships. To address this issue, AST technology was employed to structurally represent and validate the syntax of geospatial scripts(Noonan, 1985). AST parsing transforms the scripts into a tree structure, represented in JSON format, with each node corresponding to an element in the source code (such as operators, variables, and parameters). This representation allows for precise differentiation of operators from other code elements using \"key names\u201d and clarifies operator dependencies and execution order through parentheses hierarchy and indentation relationships. Additionally, scripts with syntax errors will fail to convert during the AST parsing process, thereby being automatically filtered out during the syntax validation phase, preventing erroneous information from entering the knowledge base. This method eliminates the need for manual verification, significantly improving processing efficiency while enhancing the accuracy and reliability of operator relationship extraction. After syntax checking, 154,075 syntactically correct scripts were retained."}, {"title": "3.2. Statistical Analysis and Construction", "content": "The GEE-OPs knowledge base consists of four components: the operator syntax knowledge table, operator relationship frequency knowledge table, operator frequent itemset knowledge table, and operator relationship chain knowledge table. The operator syntax knowledge table provides accurate information on operator names and their usage syntax. The operator relationship frequency knowledge table records the types and frequencies of operator pair relationships across a large dataset of scripts. The operator frequent itemset knowledge table, derived from the operator relationship frequency table, uses frequent itemset mining techniques to extract high-frequency operator combinations. The operator relationship chain knowledge table builds upon the operator relationship frequency table and the operator frequent itemset knowledge table, further supplementing the contextual information of the scripts. All knowledge tables are stored in CSV format. The specific design of each knowledge table is shown in Figure 2."}, {"title": "3.2.1. Operator Syntax Knowledge Table", "content": "The operator syntax knowledge table is constructed based on 1,374 operator syntax data points collected from the official platform."}, {"title": "3.2.2. Operator Relationship Frequency Knowledge Table", "content": "Based on control flow and data flow theories in computer compiler principles(Beck et al., 1991), and in conjunction with the typical workflows and logical structures of geospatial data processing(Shi and Walford, 2012), operator relationships in geospatial scripts can be categorized into three main types: sequential relationships, parallel relationships, and nested relationships(Cao et al., 2021; Collins et al., 2006; Garani, 2003). Sequential relationships represent the most fundamental type of operator interaction, often occurring in operations such as variable assignment, arithmetic calculations, or function calls. For example, in surface data processing or meteorological model execution, a series of data transformations or computational steps typically need to be performed in a strict sequence to ensure the accuracy of the results. Parallel relationships, on the other hand, allow multiple operations to be executed simultaneously, without dependence on a specific order or the results of other operations. This type of relationship is commonly found in independent computational tasks, such as concurrently calculating statistical features across multiple regions or performing format conversions on multiple datasets in parallel. Nested relationships reflect the logical dependencies within multi-level control structures, such as nested loops or complex conditional statements. In multi-criteria remote sensing data analysis or complex spatial data query tasks, nested structures can significantly improve the efficiency of data processing and querying. Figure 3 illustrates geospatial code examples that demonstrate these operator relationships."}, {"title": "3.2.3. Operator Frequent Itemset Knowledge Table", "content": "The Operator Relationship Frequency Knowledge Table only describes pairwise relationships between operators, revealing which operators are more likely to follow others. This forms the basis for identifying high-frequency operator combinations. By applying frequent itemset mining, common operator combinations can be extracted, reflecting the frequently used code patterns or functions in geospatial scripts. In this study, we apply the classic Apriori algorithm to mine frequent operator relationship patterns based on the Operator Relationship Frequency Knowledge Table, generating the Operator Frequent Itemset Knowledge Table.\nThe Apriori algorithm is a classical method for frequent itemset mining, relying on candidate generation and pruning strategies(Aflori and Craus, 2007). It generates frequent itemsets by progressively expanding through layers until no new frequent itemsets are produced. In our application, the Apriori algorithm takes the Operator Relationship Frequency Knowledge Table as input and analyzes the relationships between antecedent and consequent operators and their respective frequencies to extract high-frequency operator combinations. A key parameter in the Apriori algorithm is the support threshold (min_support), which is defined as the ratio of the frequency of a relationship between two operators to the total frequency of all operator relationships. This threshold is used to filter high-frequency patterns and determines the coverage of the mining results. In our experiments, we set min_support to 0.05, based on the following rationale: on the one hand, a lower support threshold helps capture sparse but significant operator combinations, preventing the omission of low-frequency but critical patterns; on the other hand, setting the threshold too low could lead to an increase in redundant patterns, thereby increasing computational complexity. Through experimental adjustments and validation of the min_support value, we achieved a balance between pattern coverage and computational efficiency."}, {"title": "3.2.4. Operator Relationship Chain Knowledge Table", "content": "The Operator Relationship Frequency Knowledge Table and Frequent Itemset Knowledge Table primarily describe the overall frequency and patterns of operator relationships, but they lack specific context information about the individual scripts. To address this gap, we utilize the hierarchical structure of AST to accurately capture the control flow and data flow characteristics of the code, establishing a symbolic system. Based on this system, we further extract the operator relationship chains for each script, using a chain structure to succinctly represent the execution order and dependencies of operators in the specific script. Additionally, the design of the symbolic system preserves semantic information, such as execution logic, through specific symbols. The symbolic system consists of three expression structures, each designed to accurately describe the three types of relationships within an operator chain. The detailed design of the symbolic system is shown in Table 2. The method of traversing and constructing this symbolic system aligns with the process used to build the Operator Relationship Frequency Knowledge Table."}, {"title": "3.3. Construction Results", "content": "The Operator Syntax Knowledge Table comprises five core attributes: full_name, short_name, description, output_type, and parameters, containing a total of 1,374 records (Figure 4-a). The Operator Relationship Frequency Knowledge Table includes four attributes: operator, related operator, relationship type, and relationship frequency, documenting 3,317 operator relationships with frequency information (Figure 4-b). The Operator Frequent Itemset Knowledge Table, generated through frequent itemset mining, contains attributes such as antecedent, consequent, antecedent support, consequent support, support, confidence, and lift, with 140,835 frequent patterns recorded (Figure 4-c). The Operator Relationship Chain Knowledge Table consists of two components: script name and relationship chain extraction result, where each script corresponds to one extracted relationship chain, totaling 154,075 records (Figure 4-d). The related code and construction results are publicly available at https://github.com/whuhsy/GEE-OPs."}, {"title": "4. Evaluation", "content": null}, {"title": "4.1. Accuracy Evaluation", "content": "The evaluation is conducted in two aspects: (1) assessing the accuracy of the GEE-OPs knowledge base construction results, and (2) evaluating the effectiveness of the GEE-OPs knowledge base in improving LLMs' geospatial code generation capabilities.\nThe GEE-OPs knowledge base consists of four knowledge tables. Among them, the Operator Syntax Knowledge Table is constructed based on objective data collection, and the Operator Frequent Itemset Knowledge Table is generated through frequent itemset mining from the Operator Relationship Frequency Knowledge Table, both of which yield unique and deterministic results, thus requiring no further accuracy evaluation. The evaluation focus is therefore placed on the Operator Relationship Frequency Knowledge Table and the Operator Relationship Chain Knowledge Table.Given the lack of existing research methods for direct comparison on operator relationship extraction in scripts, this study adopts an expert-based ground truth annotation approach. Using the quartile distribution of operator scale in scripts, 30 representative scripts are selected for quantitative evaluation: 10 small-scale scripts (involving no more than 20 operator relationships), 10 medium-scale scripts (20-80 operator relationships), and 10 large-scale scripts (more than 80 operator relationships)."}, {"title": "4.1.1. Evaluation of the Operator Relationship Frequency Knowledge Table", "content": "The evaluation of the Operator Relationship Frequency Knowledge Table focuses on accurately identifying the types of operator relationships occurring in scripts. First, domain experts manually annotate the actual operator relationship types in each script to generate the ground truth. Subsequently, each operator relationship (sample) extracted using the proposed method is categorized as follows:\n\u2022 TP (True Positive): Correctly identified and actually existing operator relationships.\n\u2022 FP (False Positive): Identified operator relationships that do not actually exist.\n\u2022 FN (False Negative): Operator relationships that exist but were not identified.\nThe following metrics are employed to quantitatively evaluate the samples:\n\u2022 Accuracy: Proportion of correctly identified operator relationships among all identified relationships, representing the overall correctness of the method. The formula is:\nAccuracy = $\\frac{TP}{TP + FP + FN}$         (1)\n\u2022 Recall: Proportion of correctly identified operator relationships among all actual operator relationships. High recall indicates the method effectively avoids missing important relationships and captures most true relationships. The formula is:\nRecall = $\\frac{TP}{TP + FN}$    (2)\n\u2022 Precision: Proportion of correctly identified operator relationships among all identified relationships, reflecting the reliability of the method. Higher precision indicates fewer false identifications. The formula is:\nPrecision= $\\frac{TP}{TP + FP}$   (3)\n\u2022 F1 Score: The harmonic mean of precision and recall, balancing the trade-off between capturing true relationships and reducing false identifications. The formula is:\nF1 = 2 x $\\frac{Precision \u00d7 Recall}{Precision + Recall}$  (4)\n\u2022 Coefficient of Variation (CV): The ratio of the standard deviation to the mean of the metrics, measuring the stability of the evaluation indicators across samples. The formula is:\nCV = $\\frac{\\sigma}{\\mu}$    (5)\nThe evaluation results are presented in Table 4. For small-scale scripts, GEE-OPs accurately predicted nearly all operator relationships, achieving perfect predictions in 4 scripts and only a single misclassification in 6 scripts, demonstrating exceptionally high accuracy. For medium-scale and large-scale scripts, although the misclassification rate increased slightly, accuracy remained high, with an average accuracy exceeding 0.73. Overall, the average accuracy across all scripts reached 0.87, while recall, precision, and F1 score all achieved 0.93, indicating that GEE-OPs effectively extracts operator relationship types and frequencies from scripts. Additionally, the coefficient of variation (CV) for all metrics was below 0.1, reflecting minimal fluctuation and high stability in the evaluation results."}, {"title": "4.1.2. Evaluation of the Operator Relationship Chain Knowledge Table", "content": "The evaluation of the Operator Relationship Chain Knowledge Table focuses on the accuracy of its structural representation and semantic information. The chain structure is designed to clearly reflect the execution order, parallel operations, and nested relationships in the script, ensuring that the dependencies between operators are fully and accurately expressed. The semantic information retains operator names and their combinations, accurately reflecting the functional calls and contextual associations of each operator. To evaluate the structural features of the chain, Longest Common Subsequence (LCS) and N-gram Similarity metrics are used(Abdeljaber, 2021; Nakatsu et al., 1982). For semantic features, Siamese Similarity and BERT Similarity metrics are applied(Ma et al., 2022; Mrinalini et al., 2022):\n\u2022 Longest Common Subsequence (LCS): Measures the length of the longest subsequence common to two sequences while maintaining order. It evaluates the matching degree of operator chains in terms of execution order, particularly useful for analyzing the correctness of order-sensitive scripts.\n\u2022 N-gram Similarity: Compares fixed-size N-grams (adjacent character combinations) between two strings to capture local co-occurrence patterns in operator chains and identify common structures or repeated patterns.\n\u2022 Siamese Similarity: Uses a deep learning model to generate embedding vectors and optimizes semantic distance between inputs, allowing precise evaluation of the semantic similarity of operator chains in specific domains.\n\u2022 BERT Similarity: Employs the BERT model to generate deep semantic embeddings and calculates cosine similarity to assess the semantic matching capability of operator chains.\nThe evaluation results are presented in Table 5. Overall, the semantic similarity metrics (Siamese and BERT) and structural similarity metrics (LCS and N-gram) fall within the range of 0.79 to 0.89, with coefficients of variation (CV) between 0.07 and 0.15, indicating high accuracy and stability in the results. Among these, the CV for N-gram is 0.15, slightly higher than the others, likely due to its sensitivity to local features. In contrast, the CV for BERT is only 0.07, reflecting its robustness in handling complex semantic relationships."}, {"title": "4.2. Effectiveness Evaluation", "content": "The effectiveness evaluation focuses on analyzing the improvement in code generation capabilities of mainstream LLMs after integrating GEE-OPs and applying the RAG framework. Detailed information about the selected models is provided in Table 6."}, {"title": "4.2.1. EQ1", "content": "To evaluate the generated geospatial code, three key metrics were employed: executability, execution correctness, and readability. Executability is defined as the ability of the generated code to successfully run in the target environment, with a score awarded upon successful execution. Execution correctness refers to whether the output of the code meets the analytical objectives of the task. For open-ended requirements, correctness is determined based on expert judgment, with the code considered correct as long as it executes properly and achieves the intended goals. Readability is assessed through blind scoring by five experts, with a maximum score of 5 points. The final score for each task is calculated by averaging the scores after removing the highest and lowest ratings. The average score across all tasks within the same group and model is taken as the model's final performance score for the comparison or ablation study. All metric scores are normalized to a percentage scale, rounded to one decimal place.\nThe evaluation aims to address two key questions:\n\u2022 EQ1: Is the approach effective across various LLMs?\n\u2022 EQ2: Can the necessity of the four knowledge tables be validated through ablation experiments on GPT-40-mini?\nThe evaluation results are presented in Table 7. The performance of various models in the zero-shot setting was relatively modest. For executability and execution correctness, the metrics ranged from 0.15 to 0.47, with none exceeding 0.5. However, after incorporating the GEE-OPS knowledge base for supplementary knowledge, performance improved significantly, with increases ranging from 0.26 to 0.47. The optimized metrics ranged from 0.55 to 0.85, demonstrating a substantial enhancement in model reliability.In contrast, readability showed only minor improvements, likely due to the GEE-OPs knowledge base being focused solely on operator-related knowledge and not addressing semantic expressions such as comments. This limitation highlights an important direction for future optimization. Overall, the average performance improvement across the three metrics ranged from 0.24 to 0.32, underscoring the effectiveness of GEE-OPs in enhancing geospatial code generation capabilities across various LLMs."}, {"title": "4.2.2. EQ2", "content": "The evaluation results are presented in Table 8. Given that readability did not show significant improvement in the EQ1 evaluation, it is excluded as a metric in subsequent assessments. Additionally, as the Operator Syntax Knowledge Table plays a foundational role in operator syntax knowledge evaluation, it is enabled by default in all evaluations of knowledge table combination strategies. Independent effects of other knowledge tables are not assessed separately. The evaluation results indicate that as the knowledge tables are incrementally incorporated, GPT-40-mini exhibits substantial improvements across all metrics in geospatial code generation capabilities. This underscores the necessity of each knowledge table in enhancing the geospatial code generation performance of LLMs."}, {"title": "5. Conclusion", "content": "This study addresses the challenges of applying LLMs to geospatial code generation by proposing and constructing the Geospatial Script Operator Knowledge Base (GEE-OPs) based on the GEE platform. The knowledge base comprises four components: the Operator Syntax Knowledge Table, the Operator Relationship Frequency Knowledge Table, the Operator Frequent Itemset Knowledge Table, and the Operator Relationship Chain Knowledge Table. Its construction follows three main steps: collection and organization, statistical analysis and construction, and validation and evaluation. Evaluation results demonstrate the high accuracy of GEE-OPs in operator relationship extraction tasks, with all performance metrics (Accuracy, Recall, Precision, and F1 Score) exceeding 90%. Moreover, GEE-OPs significantly enhances the performance of LLMs in geospatial code generation tasks, achieving average improvements of 20%-30%. Ablation experiments further confirm the critical role of each knowledge table in improving model performance. Additionally, the symbolic system proposed in this study effectively represents the semantic and structural information of operator relationship chains, offering a novel approach to understanding and generating complex geospatial scripts.\nFocusing on operator syntax and relationships derived from extensive real-world scripts, this study lays the foundation for knowledge base research in geospatial code generation tasks. However, real-world scripts contain a wealth of untapped resources, such as comments, parameters, and variables, which could further enrich the knowledge bases breadth and depth through systematic analysis. The applications of this knowledge base can extend beyond code generation to tasks such as geospatial code completion, operator prediction, error correction, summary generation, and automatic annotation, providing comprehensive technical support for geospatial coding tasks. Furthermore, the construction of such knowledge bases can provide high-quality data resources for the development and research of LLMs and agents specifically tailored for geospatial code generation. We hope this study serves as a bridge for advancing geospatial code modeling techniques, offering a foundational resource for interdisciplinary researchers and developers exploring this field. Ultimately, this work aims to drive sustained innovation and deep integration of generative AI technologies within the domain of geographic information science."}, {"title": "Disclosure statement", "content": "No potential conflict of interest was reported by the authors."}, {"title": "Funding", "content": "The work was supported by National Natural Science Foundation of China (no. 41930107)."}, {"title": "Data availability statement", "content": "Data are available on request from the authors. The data that support the findings of this study are available from thecorresponding author, Huayi Wu, upon reasonable request."}]}