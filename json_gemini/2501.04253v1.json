{"title": "Integrated Offline and Online Learning to Solve a Large Class of Scheduling Problems", "authors": ["Anbang Liu", "Zhi-Long Chen", "Jinyang Jiang", "Xi Chen"], "abstract": "In this paper, we develop a unified machine learning (ML) approach to predict high-quality solutions for single-machine scheduling problems with a non-decreasing min-sum objective function with or without release times. Our ML approach is novel in three major aspects. First, our approach is developed for the entire class of the aforementioned problems. To achieve this, we exploit the fact that the entire class of the problems considered can be formulated as a time-indexed formulation in a unified manner. We develop a deep neural network (DNN) which uses the cost parameters in the time-indexed formulation as the inputs to effectively predict a continuous solution to this formulation, based on which a feasible discrete solution is easily constructed. The second novel aspect of our approach lies in how the DNN model is trained. In view of the NP-hard nature of the problems, labels (i.e., optimal solutions) are hard to generate for training. To overcome this difficulty, we generate and utilize a set of special instances, for which optimal solutions can be found with little computational effort, to train the ML model offline. The third novel idea we employ in our approach is that we develop an online single-instance learning approach to fine tune the parameters in the DNN for a given online instance, with the goal of generating an improved solution for the given instance. To this end, we develop a feasibility surrogate that approximates the objective value of a given instance as a continuous function of the outputs of the DNN, which then enables us to derive gradients and update the learnable parameters in the DNN. Numerical results show that our approach can efficiently generate high-quality solutions for a variety of single-machine scheduling min-sum problems with up to 1000 jobs.", "sections": [{"title": "Introduction", "content": "Machine scheduling problems involve sequencing and scheduling a given set of jobs on a given set of machines to optimize an objective function subject to a given set of constraints. These problems frequently arise in manufacturing, service, and computer systems, and are among the most fundamental combinatorial optimization problems (Pinedo 2012, Blazewicz et al. 2013). Single-machine scheduling problems are the most important and most extensively studied classes of machine scheduling problems. In such a problem, a set of jobs N = {1, ..., n} is processed on a single machine such that each job j \u2208 N requires a processing time pj, and the machine can process only one job at a time. The problem is to schedule the jobs, which is equivalent to assigning a starting time for each job, so as to optimize a certain objective function. Depending on the specific constraints and the objective function involved, a job j may be associated with additional parameters such as an importance weight wj, a release time rj (i.e., the time the job arrives at the system and becomes available), and a due date dj (i.e., the desired time by which the job is completed).\nA wide range of objective functions has been studied in the literature (Pinedo 2012). In this paper, we focus on the objectives of the min-sum type, i.e., minimizing the sum of the costs incurred by individual jobs, which can be represented mathematically as $\\sum_{j\\in N} z_j(C_j)$, where Cj is the completion time of job j and zj is the cost function for job j which is usually non-decreasing. Here the structure of the overall cost function $\\sum_{j\\in N} z_j(C_j)$ is called additive or sum-type because it is the summation of the individual jobs' costs. Sum-type objective functions are among the most common categories of scheduling criteria studied in the scheduling literature. They include total weighted completion time $\\sum_{j\\in N} w_jC_j$ and total weighted tardiness $\\sum_{j\\in N} w_jT_j$, where $T_j = max(0, C_j \u2013 d_j)$ defines the tardiness of job j, among others. A class of multi-criterion scheduling problems (T'kindt and Billaut 2001, Minella et al. 2008) involve minimization of a weighted sum of two or more additive functions, e.g., $p\\sum_{j\\in N} w_{1j}T_j+(1-p) \\sum_{j\\in N} w_{2j}C_j$, where 0 < p < 1 is a given constant, and $w_{1j}$ and $w_{2j}$ are the importance weights of job j for the two criteria, respectively. Such objective functions can be rewritten as sum-type functions, e.g., $\\sum_{j\\in N}[(pw_{1j})T_j + ((1 \u2212 p)w_{2j})C_j]$. Thus, those multi-criterion scheduling problems also have min-sum objectives. In all the above-discussed min-sum objectives, the cost functions for different jobs, i.e., $z_j(C_j)$'s, have the same structure. However, there are more complex min-sum objectives where different jobs may involve different cost function"}, {"title": "1.1 Time-indexed formulation", "content": "Time-indexed formulations for machine scheduling problems are widely adopted for formulating and solving machine scheduling problems (Sousa and Wolsey 1992, Van den Akker et al. 2000). To create such a formulation, one needs to discretize the planning horizon, define time-indexed binary decision variables to represent possible starting times of the jobs, and define the objective function and constraints accordingly. All the problems considered in this paper can be formulated into a unified time-indexed BIP formulation as follows. Define the following parameters:\n\u2022 Processing times of the jobs {pj}j\u2208N, and the total processing time of the jobs, P = \u2211j\u2208N Pj.\n\u2022 Release times of the jobs {rj}j\u2208N, which are zero for a problem without release times.\n\u2022 Let T be the length of the planning horizon, where the value of T should be large enough such that in a schedule without inserted idle time, all the jobs can be completed by time T. Discretize the planning horizon into T time points, T = {0, 1, ..., T \u2013 1}.\n\u2022 Cost of job j\u2208 N if it starts at time t \u2208 T, $C_{jt} = z_j(t + p_j)$. For ease of presentation, we call cjt the starting cost of job j if it is started at time t. Then, {Cj0, Cj1,\uff65\uff65\uff65, Cj,T\u22121} together are called the starting costs of job j.\nFor each job j\u2208 N and each time point t \u2208 T, define a binary decision variable xjt to be 1 if job j starts at time t, and zero otherwise. Then we have the following unified time-indexed BIP formulation for all the problems we consider:\nminimize $\\sum_{j\\in N} \\sum_{t=0}^{T-P_j} C_{jt} x_{jt}$ (1a)\nsubject to $\\sum_{t=r_j}^{T-P_j} x_{jt} = 1, \\forall j\\in N$, (1b)\n$\\sum_{j\\in N} \\sum_{k=max(r_j,t-p_j+1)}^{t} x_{jk} \\leq 1, \\forall t\\in T$, (1c)\n$x_{jt} \\in {0,1}, \\forall j\\in N,t\\in T$. (1d)\nConstraints (1b) guarantee that each job has a unique starting time no earlier than its release time. The capacity constraints (1c) ensure that at most one job is processed at a time.\nA major advantage of this time-indexed formulation is that this single formulation represents all the single-machine scheduling problems that we intend to solve. Therefore, we build on this formulation to develop a unified machine learning approach for all these problems. Another advantage of such a time-indexed formulation is that its LP relaxation tends to generate tighter bounds than other commonly used integer programming formulations. However, such a formulation contains a large number of binary decision variables and constraints, especially when the total processing time of the jobs P is large. Consequently, to solve such formulations, valid inequalities and other solution techniques such as column generation approaches are often used (Berghman and Spieksma 2015, Van den Akker et al. 2000)."}, {"title": "Machine learning", "content": "Many studies have developed machine learning (ML) methods to solve difficult combinatorial optimization problems, including scheduling problems and routing problems (Bengio et al. 2021). In some studies (Morabit et al. 2023, Zhang et al. 2022), ML is integrated within optimization algorithms to accelerate the computation. In this paper, we develop a supervised learning method to directly generate a solution for a given instance. In the following, we summarize the key ideas of supervised learning.\nSupervised learning is a major sub-field of machine learning (LeCun et al. 2015). A supervised learning model can be viewed as a parameterized function $f_\\theta$ with the learnable parameters \u03b8 that maps an input x \u2208 X to an output y \u2208 y, where X is the input space consisting of all possible values of the input, and Y is the output space consisting of all possible values of output. A supervised learning model $f_\\theta$ learns from existing data and generalizes to unseen data. Thus, a training data set, Dtrain = {(x1,y1), (x2, y2), ...}, is required, where xi \u2208 X is an input and yi \u2208 Y is the corresponding correct output (also called label). The learning process is to find the optimal learnable parameters 0 to minimize the average loss as follows,\n$\\min_\\theta \\frac{1}{|D^{train}|} \\sum_{(x,y) \\in D^{train}} L(y, f_\\theta(x)).$ (2)\nwhere L() is a problem-specific loss function. The trained model is used to generate outputs for unseen inputs. A model is said to have good generalization capability if it produces high-quality outputs for unseen inputs. Usually, the values in the input space follow some unknown distribution P. A key to achieving good generalization is that the inputs in the training set be sampled independently and identically from the same distribution P. Moreover, the training set should be sufficiently large to capture the properties of the input space.\nIn the context of scheduling problems, an input x is designed to be able to fully describe a given problem instance, and the input space X should cover all possible instances to be solved online. The output y is a solution of the instance. For example, for an instance of 1|| \u2211wjTj, the input x can consist of job processing times, weights, and due dates, and y can be the optimal job starting times. Training of a supervised learning model for difficult scheduling problems can be"}, {"title": "Challenges and contributions", "content": "To develop a unified machine learning approach that works for all the single-machine scheduling problems with a non-decreasing min-sum objective, there are two major challenges.\n\u2022 Different scheduling problems can exhibit very different characteristics due to the wide range of sum-type objective functions. For example, \u2211wjCj is a smooth function of the completion times Cj, whereas \u2211wjTj is not. Moreover, in problems without release times, jobs are all available at time 0, whereas in problems with release times, jobs may not be available before certain time points. It is thus a challenge to develop a unified machine learning approach that works well for a wide variety of problems.\n\u2022 As discussed above, to train a supervised learning model with a good generalization capability, a training set with sufficiently many instances drawn i.i.d. from the distribution of the input space is needed. However, because the scheduling problems under consideration are NP-hard, it is impractical to generate optimal solutions as labels for large-sized problems. Thus, once a machine learning model is developed for our problems, it is a challenge to train the model."}, {"title": "Time-indexed formulation", "content": "The inputs of the UMSNN should fully describe a given instance. For an instance with a total of n jobs, the inputs are defined as a sequence of n vectors, denoted by I = {I1, I2, . . ., In}, with the i-th vector corresponding to job i. As presented in Section 1, the time-indexed formulation (6.3) is a unified formulation, which incorporates the objective function into the starting costs of the jobs. Therefore, we include the starting costs of the jobs in I to enable our approach to work for all the problems with a min-sum objective function. We note that for a job j with a nonzero release time, its starting cost at every time point t with t < rj, which is calculated as $C_{jt} = z_j(t + p_j)$, is also included in 1. Moreover, to learn to generate feasible solutions, the job processing times and the release times, which play critical roles in the constraints of the time-indexed formulation, are also included in Z. However, based on our computational experiment, directly utilizing {Cjt}j\u2208N,tET, {Pj}j\u2208N, and {rj}j\u2208N as the inputs does not lead to good results. In the following, an encoding approach is developed to represent these inputs properly.\nFor different objective functions, the values of the starting costs may have different orders of magnitude. For example, starting costs in an instance of 1|| \u2211j\u2208N wjCs with aj \u2265 1 may be significantly larger than those in an instance of 1|| \u2211jen wjTj. To learn to solve instances with different objective functions by using a single model, we normalize the starting costs Cjt as\n$\\check{C}_{jt} = (C_{jt} - c)/(\\bar{c} \u2013 c)$, where c and $\\bar{c}$ are the minimal and maximal value among {$c_{jt}$}$_{j\\in N,t\\in T}$, respectively. The normalized starting costs {\u010djt}j\u2208N,teT are all within the interval [0,1]. For ease of representation, let \u010dj = [\u010djo, \u010cj1, ..., \u010cj,T\u22121] \u2208 R1\u00d7T.\nThe job processing time pj is encoded as pj, where\n$\\bold{p_j} = [\\underbrace{1, 1, ..., 1}_{P_j}, \\underbrace{0, ..., 0}].$ (3)\nThe length of pj should be at least equal to the maximum possible processing time. The motivation for encoding the job processing times in this manner, rather than using widely used one-hot encoding, is to implicitly capture the similarities between jobs. Specifically, if the processing times of two jobs are close, then the two jobs are similar in terms of their processing times. The above encoding scheme (3) reflects this very well because with this encoding scheme, for any two similar"}, {"title": "Architecture of UMSNN", "content": "In this subsection, we present the architecture of our UMSNN. As presented in the previous sub-section, the inputs of the UMSNN are defined based on the time-indexed formulation to make our approach work for various objective functions. However, the inputs defined in this way are raw and unstructured, with a large dimensionality. This means that there can be a vast number of hidden features within the inputs. There can also be a lot of noise and irrelevant information in the inputs. Consequently, it could be difficult for the ML model to generalize, leading to overfitting. To overcome the difficulty, our idea is to leverage the capability of deep neural networks (DNNs) to automatically extract features from the inputs. Specifically, we use a DNN, which has multiple layers of neurons. The features within the inputs are progressively extracted, with the low-level features extracted by the earlier layers and complex, high-level features captured by deeper layers.\nInput module: In the inputs, \u0113j and rj have the same length as the planning horizon (i.e., T), which can be very large. An input module is developed to reduce the dimensions of {Ij}j\u2208N,\nwhile extracting the critical features for predicting solutions.\nThe input module is a job-wise operation, i.e., it separately processes Ij for each j. We use multiple convolutional neural network (CNN) layers to extract features from the starting costs {Cjt}teT. The motivation behind is to exploit the fact that the starting costs among different jobs and instances share similar features, especially for the same objective function. To illustrate, take 1|| \u03a3wjT; as an example. In any instance of this problem, the starting costs for jobs follow a piece-wise linear pattern: they start at zero, remain zero up to a certain point, and then increase linearly beyond that. The location of this turning point, which varies among different jobs and instances, is determined by the job processing time and due date, and is critical for predicting solutions. A CNN layer utilizes kernels (also known as filters) with learnable parameters that slide over a given input feature vector and perform a multiplying operation at each position. This mechanism enables the layer to have translation-invariant characteristics (Lecun et al. 1998). Patterns and features from the input can be identified and extracted irrespective of variations in position. Moreover, since the elements at different positions are processed by the same kernels, the layer has a reasonable number of learnable parameters, even though the input is of high-dimensional. We stack multiple CNN layers and activation functions to extract the features from the starting costs {\u010djt}teT.\nDenote the output vector as $c'_j \\in R^{1\\times d_c}$ with a dimension of $d_c$. The value of $d_c$ should be much smaller than T, e.g., in our computational tests (see Section 6), T is either 53000 or 68000 whereas $d_c$ is only 1024 in both examples. Similarly, for each job j, the encoded release date vector rj is processed by the CNN layers. Denote the output vector as $r'_j \\in R^{1\\times d_r}$. By setting the dimensions and stride of the convolution kernel (Li et al. 2022), we let the dimension $d'_r = d_c$, which is thus much smaller than T. The job processing times pj are processed by a multilayer perceptron, and the output vector is denoted as $p'_j \\in R^{1\\times d_p}$, where dp is the dimension. Since the amount of information contained in the processing times p; is less than that in the starting costs, the value of $d_p$ is set to a value smaller than $d_c$. For example, it is set as 256 in Section 6.\nThe output of the input module is generated by adding ; and r; and concatenating with p';, i.e., $I' = [p'_j, \\check{c'}_j + r'_j] \\in [R^{1\\times d_e}$, where $d_e = d_p + d_c$. Again, the input module operates on a job-wise basis, meaning that the input for each job is independently processed by a single input module. Therefore, the module is flexible and works for instances containing a varying number of jobs.\nTransformer-based Encoder: A transformer-based encoder is developed to capture the rela-"}, {"title": "Heuristics for feasibility", "content": "The outputs of UMSNN are probability vectors {oj}j\u2208N, with oj associated with job j and has a length of y. In this subsection, two simple heuristics are developed to generate a feasible starting time for each job based on the probability vectors. Both approaches first sequence the jobs in a certain order, and then calculate the starting times of the jobs accordingly.\nThe first approach finds the time window with the largest probability for each job j\u2208 N, i.e.,\n$\\omega_j = argmax\\{o_{jk}\\}$, (8)\nand sequences the jobs by the ascending order of {$\u03c9_j$}$_{j\\in N}$. If multiple jobs fall within the same time window, they are sequenced by the descending order of their weights. Since only the time window with the largest probability is considered, we call this approach a \"greedy\" approach.\nIt is possible that for a job, a time window that does not have the largest probability has a high quality. Therefore, our second approach may assign any time windowk with a positive $o_{jk}$ value to a given job j. More specifically, it is a sampling-based approach that chooses the kth time window for job j with probability ojk. Through sampling a time window for each job, {$\u03c9_j$}$_{j\\in N}$ is obtained, and the jobs are sequenced following the ascending order of the time windows as in the first approach. This approach is called a \"sampling\" approach.\nIn both approaches, given the sequence of the jobs, feasible starting times for the jobs can be easily calculated. For the first job, the starting time is set as its release date (which is zero if the problem does not consider release times). For the successive jobs, the starting time equals the greater value between its release time and the completion time of its predecessor."}, {"title": "Supervised Training Using Special Instances", "content": "To generate high-quality solutions for online instances, the learnable parameters of the UMSNN, as defined in the previous section, need to be trained using a large variety of instances generated from the same distribution as the online instances to be solved. For a given instance, the objective value of a solution generated by the UMSNN, i.e., the total cost of the jobs, can measure the quality of the solution. However, numerical tests suggest that, if the objective values are used in the performance measure in offline training, the performance of the UMSNN for online instances would not be satisfactory. This is because the objective value of a solution is only an aggregated piece of information based on the outputs {0jk}j\u2208N,kek from the UMSNN corresponding to this solution, and hence contains far less information than the entire set of the outputs.\nIn this paper, we use the entire set of outputs of the UMSNN, {0jk}j\u2208N,kek, to define a per-formance measure to be optimized in the offline training stage. Specifically, for a given training instance (or input vector) I, suppose that the outputs of the UMSNN are {ojk(I)}j\u2208N,k\u2208k, where Ojk(I) represents the probability that the starting time of job j falls within the kth time window in K, and suppose that {ok(I)}j\u2208N,k\u2208\u03ba are the labels denoting the optimal solution such that they follow a one-hot format, i.e., ok (I) = 1 if job j starts in the kth time window in the optimal solu-tion, and 0 otherwise. We use the cross-entropy loss (Goodfellow et al. 2016) to measure the error of the outputs from the UMSNN. The cross-entropy loss associated with job jis $\\sum_{k\\in K} o^*_k(I) \\ln o_{jk} (I)$. Suppose that the optimal starting time of job j falls within the k*th time window. Then, the loss becomes - $\\ln o_{jk}(I)$. Minimizing it is equivalent to maximizing the value of ok(I), which is the probability that the optimal time window is correctly predicted. The cross-entropy loss of instance I is the average loss over all the jobs, i.e.,\n$L(o^*(I), o(I)) = - \\frac{1}{n} \\sum_{j \\in N} \\sum_{k\\in K} o^*_k(I) \\ln o_{jk} (I)$. (9)\nWith the loss function defined above, the learnable parameters are optimized by solving the following optimization problem:\n$\\min_\\theta \\sum_{I\\in D} L(o^*(I), o(I))$, (10)\nwhere D is the training instance set. This problem can be solved using the stochastic gradient"}, {"title": "Online Single-Instance Learning", "content": "The offline training approach developed in the previous section trains the UMSNN model for opti-mized average performance on a large number of offline instances of one or more given single-machine min-sum scheduling problems. Given an online instance to be solved, it is unlikely that the offline trained parameters are optimal for this instance. Therefore, in this section, we propose an approach to fine-tune the learnable parameters whenever a given online instance needs to be solved. Since fine-tuning is based on a single instance only, our approach is called \"single-instance\" learning. A key element of the approach is a feasibility surrogate that we develop, which connects the output of the UMSNN to a solution of the underlying scheduling problem. We first describe our overall approach in subsection 5.1 and then describe the feasibility surrogate in subsection 5.2."}, {"title": "Approach", "content": "The UMSNN model $f_\\theta (\\cdot)$, once trained (i.e., given the values of the learnable parameters \u03b8 \u2208 RS), can map any given instance, represented by the input vector I, to an output vector $o = f_\\theta (I)$, where row oj is the probability vector of the starting time of job j assigned to the y time windows, as defined in Section 3. Now, suppose that the input vector I is given and fixed, but the learnable parameters 0 are variables. We can then view $f_\\theta (I)$ as a function of 0, denoted as $G_1(\\theta)$, that maps the learnable parameters \u03b8 to output $f_\\theta (I)$, i.e., $G_1(\\theta) = f_\\theta (I)$. Furthermore, suppose that we have a feasibility layer Fv(\u00b7), which can map any output o of the UMSNN to a feasible solution"}, {"title": "Feasibility Surrogate", "content": "In subsection 3.3, we give two heuristic procedures to generate feasible job starting times {Sj}j\u2208N based on the output of the UMSNN. These procedures involves multiple non-differentiable op-erations, such as argmax(\u00b7), the sampling operation, and the job sorting operation. These non-differentiable operations are hard to approximate by differentiable operations. In this subsection, we use a different heuristic to generate feasible job starting times based on the output of the UM-\nSNN, and use this as the feasibility layer Fv(\u00b7) in our single-instance learning approach described in subsection 5.1. Fewer non-differentiable operations are involved in this heuristic than the two given in subsection 3.3 such that Fv(\u00b7) is less difficult to approximate. In the following, we first describe this heuristic, and then briefly explain how the non-differentiable operations involved in the heuristic can be approximated by differentiable operations.\nFeasibility layer Fv(\u00b7): The input to Fv(\u00b7) is a matrix o \u2208 Rn\u00d7Y, where ojk is the probability that the starting time of job j falls within the kth time window. Giving the input o, the function Fv(o) consists of two mathematical operations. The first operation calculates the weighted time window value for each j\u2208 N, as\n$\\tilde{\\omega}_j = \\sum_{k\\in K} k o_{jk}$, (22)\nThe second operation generates feasible job starting times {Sj}j\u2208N, by following the ascending order of the weighted time window values of the jobs {$\\tilde{\\omega}_j$}$_{j\\in N}$. We assume that the weighted time window values of the jobs are all different. When multiple jobs have the same weighted time window value, sufficiently small perturbations are added to differentiate them. To express the second operation mathematically, we establish the relationship between {$\\tilde{\\omega}_j$}$_{j\\in N}$ and the feasible job starting times {$C_j$}$_{j\\in N}$ by using step functions. Specifically, a step function u(x), which is defined as 1 if x > 0 and 0 otherwise, is used to indicate the relative orders of two jobs. For j1, j2 \u2208 N, if $u(\\tilde{\\omega}_{j_2} \u2013 \\tilde{\\omega}_{j_1}) = 1$, then $\\tilde{\\omega}_{j_1} < \\tilde{\\omega}_{j_2}$ and hence job j1 is ordered before j2, and if $u(\\tilde{\\omega}_{j_2} \u2013 \\tilde{\\omega}_{j_1}) = 0$, then $\\tilde{\\omega}_{j_1} > \\tilde{\\omega}_{j_2}$ and hence job j1 is ordered after j2.\nTo derive job starting times, we first consider the case where the jobs in the given instance do not have release times. Since in this case, no ideal time should be inserted in an optimal schedule, a job starts immediately after its predecessor is completed. Thus, for each job j, its starting time $Sj$ can be calculated by summing up the processing times of all its predecessors, i.e.,\n$Sj = \\sum_{j' \\in N \\{j\\}} u(\\tilde{\\omega}_{j'} - \\tilde{\\omega}_{j}) p_{j'}, \\forall j \\in N.$ (23)\nA feasible objective value is then calculated as \u2211jen zj(\u0160j + Pj).\nWe now consider the case where jobs have nonzero release times. In this case, a job may not be able to start right after the completion of its predecessor because its release time and the release"}, {"title": "Smooth approximation", "content": "In the above, the feasibility layer Fv(\u00b7) is established by using the step function u(\u00b7) and the max operation. However, the gradient of the step function is zero at most places. We approximate the step function by a smooth\n$\\tilde{\\omega}_j' = \\sum_{k \\in K} k o_{jk}$, (27)\nThe function is also shown in the right part of Figure 2. In the above equation, is a pre-specified positive parameter. When is a large enough value, the step function is well approximated by the sigmoid function, but the gradients at most places are almost zero. By setting appropriately, the step function is properly approximated while having reasonable gradients. Similar to the dynamically adjusted target value in the step size (20), we also dynamically adjust the value of 4. The details are given in the Appendix ??.\nThe max operation within (26) makes Fv(\u00b7) a piece-wise function. We do not try to smooth the max operation. At any non-differentiable point caused by the max operation, we simply use the right hand gradient of the point as the gradient at the point."}, {"title": "Computational Results", "content": "In this section, we report the performance of our approach based on various sizes of test instances of various individual single-machine min-sum scheduling problems. The testing platform is equipped with AMD EPYC 7702, NVIDIA RTX 3090 GPU, Linux Ubuntu 18.04.5, and NVIDIA CUDA 12.4. Commercial solver IBM CPLEX 12.10 is used whenever there are LP or IP problems to be solved. The UMSNN, the supervised training, and the online single-instance learning are implemented by using Python 3.7 and Torch 1.13.1+cul17. Our code, datasets, and trained learnable parameters"}, {"title": "Test Problems and Parameter Distributions", "content": "We test the performance of our approach based on the nine specific single-machine min-sum prob-lems shown in Table 2. The test instances of these problems are generated following the distributions of the problem parameters defined as follows:\n\u2022 Problem size, n, is drawn from the two size groups: size group 1, where n \u2208 {500, 600, 700}, and size group 2, where n \u2208 {800, 900, 1000}.\n\u2022 The parameters pj, wj, wa, w, wij and w2j are all drawn randomly from U{1,100}, where U{x,y} denotes a discrete uniform distribution between x and y. For problems with release times, the release times are drawn from U{1,0.5P}. For problems with due dates, the due dates dj are generated from U{1,\u00bfdP}, where parameter \u0121a controls the tightness of the due dates, and \u0121a \u2208 {0.2,0.5,0.8} for some problems and \u0121a = 0.5 for some other problems.\n\u2022 The parameter a; in the objective function \u03a3wj is drawn from U[0.5, 1.5], where U[x, y] is a continuous uniform distribution between x and y. For the two bi-criterion problems, \u03c1\u2208 {0.3,0.7}. For the two two-agent problems, p = 0.5 and |NA|/|NB| \u2208 {0.3, 0.7}.\nFor each size group, Table 2 lists the 17 problem cases and their corresponding parameter distri-butions to be tested. Consequently, there are 34 problem cases in total."}, {"title": "Training, validation and testing sets", "content": "As discussed in Section 1.2, in order for a supervised learning model to have a good generalization capability, the model needs to be trained using input instances generated following the same or a similar distribution as the input space of the online instances to be solved. Therefore, we train our UMSNN model separately for each of the nine problems, except that for problems 1|rj|\u2211wjCj and"}, {"title": "Benchmarks", "content": "The fact that the UMSNN is built on the time-indexed formulation motivates us to utilize this same formulation to design the following two optimization based heuristics as benchmarks and use them to evaluate the performance of our approach.\nShrink + IP: The first benchmark is inspired by our idea in Section 4.1 where we train the UMSNN using specially designed large instances, which are enlarged from randomly generated smaller instances by enlarging some parameters such as pj, rj, or / and dj following the scheme shown in Table 1. The success of this scheme is partly due to the fact that the time-indexed formulations of the smaller instances can be solved to optimality within a reasonable time. Now, following this idea, we reverse this process and ask the following question: for a randomly generated large instance, can we construct a smaller instance such that (i) the smaller instance can be solved to optimality quickly using the time-indexed formulation, and (ii) the optimal solution of the smaller instance can be easily expanded to become a feasible solution for the large instance? This can be done as follows. Given a large testing instance, we first generate a smaller instance by \"shrinking\" the job processing times by 20 times as $\\bar{p_j} = [p_j/20], \\forall j \\in N$. The other parameters are shrunk accordingly following Table 1. For example, for 1|| \u03a3wjTj, the due dates are calculated as dj = [dj/20],\u2200j \u2208 N. Then, we solve the time-indexed formulation of the smaller instance to obtain the best possible solution within a time limit following a warm-start strategy, as described below. Finally, a feasible solution to the given testing instance is generated by scheduling the jobs as tightly as possible using the same job sequence in the solution to the smaller instance. We call this benchmark approach \"Shrink + IP\".\nWhen using CPLEX to solve the time-indexed formulations of smaller instances, we try to reduce the required computational time by leveraging CPLEX's warm-start functionality. Specifically, for a given smaller instance, we first solve the LP relaxation of its time-indexed formulation to optimality using CPLEX and then generate a feasible solution based on the sampling heuristic described in Section 3.3. This feasible solution is generally of high quality. We then provide this solution to CPLEX as a warm start for solving the original time-indexed formulation of the smaller instance. Numerical results suggest that CPLEX can quickly find a high-quality solution, although guaranteeing an optimal solution often requires significantly more time. To save computational"}, {"title": "Results", "content": "We first describe how the supervised training is performed. Then we show the test results"}]}