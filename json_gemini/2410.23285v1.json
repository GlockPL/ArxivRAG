{"title": "Provable acceleration for diffusion models\nunder minimal assumptions", "authors": ["Gen Li", "Changxiao Cai"], "abstract": "While score-based diffusion models have achieved exceptional sampling quality, their sampling speeds\nare often limited by the high computational burden of score function evaluations. Despite the recent\nremarkable empirical advances in speeding up the score-based samplers, theoretical understanding of\nacceleration techniques remains largely limited. To bridge this gap, we propose a novel training-free ac-\nceleration scheme for stochastic samplers. Under minimal assumptions-namely, L\u00b2-accurate score esti-\nmates and a finite second-moment condition on the target distribution our accelerated sampler provably\nachieves \u025b-accuracy in total variation within O\u02dc(d5/4/\u221a\u03b5) iterations, thereby significantly improving upon\nthe O\u02dc(d/\u03b5) iteration complexity of standard score-based samplers. Notably, our convergence theory does\nnot rely on restrictive assumptions on the target distribution or higher-order score estimation guarantees.", "sections": [{"title": "1 Introduction", "content": "Score-based generative models (SGMs), also referred to as diffusion models (Song and Ermon, 2019; Song et al.,\n2020c), have emerged as a powerful framework for sampling from high-dimensional probability distribu-\ntions, achieving remarkable success across diverse domains. Notable examples include image generation\n(Dhariwal and Nichol, 2021; Rombach et al., 2022), natural language processing (Austin et al., 2021; Li et al.,\n2022), medical imaging (Song et al., 2021; Chung and Ye, 2022), and computational biology (Trippe et al.,\n2022; Gruver et al., 2024). Beyond these computer and scientific applications, SGMs have also found impor-\ntant applications in the operations research domain by formulating sequential decision-making as generative\nsequence modeling. This novel perspective has led to impressive performance in planning (Janner et al., 2022;\nChi et al., 2023), policy learning (Wang et al., 2022; Chen et al., 2022a), and imitation learning (Pearce et al.,\n2023; Hansen-Estruch et al., 2023). We refer interested readers to Yang et al. (2023); Chen et al. (2024b)\nfor detailed surveys on recent advances in methods, applications, and theories of diffusion models.\nDiffusion models involve two stochastic processes: a forward process and a reverse process. The forward\nprocess progressively diffuses a sample from the target data distribution into pure noise (typically Gaussian\nnoise). The reverse process, guided by the (Stein) score functions of the forward process, transforms pure\nnoise into a sample from the data distribution, thereby achieving the goal of generative modeling. At\nthe heart of constructing the reverse process lies score matching\u2014the task of learning the score functions\nalong the forward process\u2014typically accomplished via neural networks in practice (Hyv\u00e4rinen and Dayan,\n2005; Vincent, 2011; Song et al., 2020b). The reverse process can be implemented through either stochastic\ndifferential equation (SDE)-based or ordinary differential equation (ODE)-based dynamics, exemplified by\nthe Denoising Diffusion Probabilistic Model (DDPM) (Ho et al., 2020) and the Denoising Diffusion Implicit\nModel (DDIM) (Song et al., 2020a), respectively. Recent theoretical developments have shown that score-\nbased samplers, when equipped with accurate score estimates, achieve comparable or superior iteration\ncomplexity to classical methods such as Langevin dynamics (Bakry et al., 2014)\u2014notably, without requiring\nstructural assumptions such as log-concavity or even smoothness of the target distribution (Chen et al.,\n2022b, 2023a; Benton et al., 2023; Li and Yan, 2024b).\nWhile diffusion models have demonstrated impressive sampling performance, they face a significant com-\nputational challenge generating high-quality outputs typically requires a large number of iterative steps.\nSince each iteration involves a neural network evaluation for the score function, the iteration nature makes\nthem substantially slower than single-step samplers such as variational auto-encoders (VAEs) (Kingma,\n2013) and generative adversarial networks (GANs) (Goodfellow et al., 2014). This computational bottleneck\nhighlights the pressing need to accelerate diffusion models without compromising their exceptional output\nquality.\nTo address this challenge, various acceleration strategies have been proposed, which can be broadly\nclassified into two categories based on whether they require additional learning. Examples of \"training-\nbased\" methods, such as distillation (Salimans and Ho, 2022) and consistency models (Song et al., 2023),\naim to reduce the computational burdens by adapting pre-trained models into related architectures. While\nthese approaches demonstrate significant empirical improvements, the costs incurred by additional training\nprocesses remain prohibitively high for large-scale models. In contrast, \u201ctraining-free\u201d methods leverage the\npre-trained score functions and directly modify the sampling procedure, avoiding resorting to additional\nlearning. Hence, this approach offers universal applicability to the off-the-shelf pre-trained diffusion models.\nSome notable examples in this category include DPM-Solver (Lu et al., 2022a), DPM-Solver++ (Lu et al.,\n2022b), Unipc (Zhao et al., 2024), which have achieved substantial empirical speedups. However, theoretical\nunderstanding of training-free accelerated samplers remains inadequate.\nMotivated by this, we investigate accelerating the convergence of the score-based samplers in a training-\nfree manner. Recent theoretical and empirical advances have demonstrated that once L2-accurate score"}, {"title": "1.1 Contributions.", "content": "Encouragingly, the answer to the above question is affirmative. We develop a novel sampling scheme that\nachieves an iteration complexity of O\u02dc(d5/4/\u221a\u03b5), demonstrating a faster convergence rate compared to the\nvanilla score-based samplers, which require an iteration complexity of O\u02dc(d/\u03b5). Notably, our convergence\ntheory replies solely on access to L\u00b2-accurate score estimates and a finite second-order moment condition\non the target data distribution. This illustrates that L2-accurate first-order score estimates are sufficient\nto achieve provable sampling acceleration, without requiring higher-order score estimates or smoothness\nassumptions on the target distributions. To the best of our knowledge, our result provides the first provable\nacceleration for score-based samplers that need minimal score estimation requirements and accommodates a\nbroad class of target data distributions."}, {"title": "1.2 Other related work", "content": "Convergence theory for diffusion models. Early convergence guarantees for SDE-based samplers were\neither qualitative (De Bortoli et al., 2021; Liu et al., 2022; Pidstrigach, 2022), replied on L\u221e-accurate score\nestimates (De Bortoli et al., 2021; Albergo et al., 2023), or exhibited exponential dependence (De Bortoli,\n2022; Block et al., 2020). Lee et al. (2022) established the first polynomial iteration complexity given L2-\naccurate score estimates, albeit assuming a log-Sobelev inequality on the target distribution. Chen et al.\n(2022b); Lee et al. (2023) later relaxed this condition by requiring Lipschitz scores and bounded sup-\nport/moment conditions on the target distribution. For ODE-based samplers, Chen et al. (2023c) pro-\nvided the first convergence guarantee, though without explicit polynomial dependencies and requiring exact\nscore estimates. Chen et al. (2024c) improved upon this by studying variants of the ODE that incorporate\nadditional stochastic corrector steps. Li et al. (2023) established an iteration complexity of O(d\u00b2/\u03b5) for\nODE-based samplers assuming accurate Jacobian estimates of scores, which was later improved to O(d/\u03b5)\n(Li et al., 2024b). Recent work has also explored convergence in 2-Wasserstein distance (Gao and Zhu, 2024;\nTang and Zhao, 2024).\nTraining-free acceleration schemes. Training-free accelerated samplers typically leverage efficient nu-\nmerical methods for solving reverse SDE/ODEs. For ODE-based samplers, researchers have exploited semi-\nlinear structures using higher-order ODE solvers (Lu et al., 2022a,b), exponential integrators (Zhang and Chen,\n2022), and a predictor-corrector framework (Zhao et al., 2024). Acceleration for SDE-based samplers, though\nless explored due to the inherent complexity of solving SDEs, has progressed through stochastic Improved\nEuler\u2019s method (Jolicoeur-Martineau et al., 2021), stochastic Adams method (Xue et al., 2024), and stochas-\ntic Runge-Kutta methods (Wu et al., 2024). In addition to resorting to efficient ODE/SDE solvers, alter-\nnative acceleration approaches include parallel sampling (Chen et al., 2024a; Gupta et al., 2024) and ex-\nploitation of low-dimensional structures of the target distributions (Li and Yan, 2024a; Huang et al., 2024c;\nAzangulov et al., 2024).\nOther theory for diffusion models. Beyond convergence analysis, another line of work focused on the\nsample complexity of score estimation. Block et al. (2020) provided a sample complexity bound in terms of\nRademacher complexity, and Oko et al. (2023); Chen et al. (2023b) established the sample complexity using\nneural networks to estimate scores. From the perspective of nonparametric statistics, Wibisono et al. (2024);\nZhang et al. (2024); Dou et al. (2024) proposed kernel-based methods to achieve optimal score estimation.\nThe minimax optimality of diffusion models was then established for various target density classes, including\nBesov (Oko et al., 2023), Sobolev (Zhang et al., 2024), and H\u00f6lder spaces (Dou et al., 2024). Sample com-\nplexity reduction through low-dimensional data structures has also been investigated in Chen et al. (2023b);\nWang et al. (2024). In addition, Han et al. (2024) established optimization guarantees for score matching\nusing two-neural networks trained by gradient descent. Recently, diffusion models have also been applied\nto posterior sampling (Montanari and Wu, 2023; Alaoui et al., 2023) by leveraging the idea of stochastic\nlocalization (El Alaoui and Montanari, 2022; Montanari, 2023; Eldan, 2020)."}, {"title": "1.3 Notation", "content": "For any integer N > 0, denote by [N] := {1,2,\u2026\u2026\u2026, N}. For any matrix A, we use ||A||, tr(A), and det(A)\nto denote its spectral norm, trace, and determinant, respectively. For two probability distributions P, Q,\nKL(P || Q) = \u222b log(dQ/dP) dP stands for the KL divergence and TV(P, Q) = 1/2\u222b |dP \u2013 dQ| represents the total\nvariation. For random vectors X, Y with distributions Px, Py and probability density functions px, py, we\ninterchangeably use KL(X || Y) = KL(Px || Py) = KL(px || py) and TV(X, Y) = TV(Px, Py) = TV(px,py).\nLet 1{\u00b7} denote the indicator function. For any event E, we denote E\u025b[\u00b7] := E[ \u00b7 1{E}].\nFor any two functions f(n), g(n) > 0, f(n) \u2264 g(n) or f(n) = O(g(n)) means f(n) \u2264 Cg(n) for\nsome absolute constant C > 0; f(n) \u2265 g(n) or f(n) = \u2126(g(n)) indicates f(n) > C'g(n) for some abso-\nlute constant C' > 0; f(n) = g(n) represents that Cf(n) \u2264 g(n) \u2264 C'f(n) for some absolute constants\nC' > C > 0. The notations O\u02dc(\u00b7) and \u2126\u02dc(\u00b7) hide logarithmic factors. In addition, f(n) = o(g(n)) denotes\nlim supn\u2192\u221e f(n)/g(n) = 0."}, {"title": "1.4 Organization", "content": "The rest of the paper is organized as follows. Section 2 reviews the background of SGMs and introduces\nour problem setup. Section 3 presents our proposed accelerated sampler and theoretical guarantees. The\nanalysis of the convergence theory is provided in Section 4. The detailed proofs and technical lemmas are\ndeferred to the appendix. We conclude with a discussion of future directions in Section 5."}, {"title": "2 Problem formulation", "content": "In this section, we provide a brief introduction to SGMs, and introduce the assumptions for our algorithm\nand theory."}, {"title": "2.1 Preliminaries", "content": "Forward process. Starting from the target data distribution Xo ~ Pdata in Rd, the forward process evolves\nas follows:\nXt = \u221a\u03b1tXt-1+\u221a1\u2212\u03b1tWt, t = 1, 2, ...,T,   (1)\nwhere \u03b11,..., \u03b1\u03c4 \u2208 (0,1) are the learning rates and W1,..., WT ~iid N(0, Id) are standard Gaussian random\nvectors in Rd. For continence of notation, let us denote\n\u03b1t := \u03a0tk=1\u03b1k, t = 1, 2, ..., T.   (2)\nThis allows us to express\nXt = \u221a\u03b1tXo + \u221a1\u2212\u03b1tWt, t = 1,2,...,T,   (3)\nwhere Wt ~ N(0, Ia) is a standard Gaussian random vector independent of Xo. In particular, PXT is\napproximately a standard multivariate normal distribution when \u03b1T is sufficiently small. The continuum\nlimit of the forward process (1) can be modeled by the following SDE:\ndXt = \u22121/2\u03b2tXt dt + \u221a\u03b2t dBt, Xo ~ Pdata; t\u2208 [0,T],   (4)\nwhere \u03b2t : [0, T] \u2192 R is some function and (Bt)t\u2208[0,T] denotes a standard Brownian motion in Rd."}, {"title": "2.2 Assumptions", "content": "Score function estimation. In practical applications, the true score functions (st)t are unknown and\nmust be learned based on samples drawn from the target distribution. The estimation of the score func-\ntions, known as score matching (Hyv\u00e4rinen and Dayan, 2005; Vincent, 2011), is typically accomplished by\nminimizing the L\u00b2(px\u2081) loss via neural networks (Song et al., 2020c). Given these score estimates (st)t, we\ncan then start from Y ~ N(0, Ia) and implement a discretized reverse process. This approach motivates our\nanalysis under the assumption of L\u00b2-accurate score estimates across all time steps.\nAssumption 1. The score estimates (st)1<t<T for the score functions (st)1<t<T satisfy\nEscore := 1/T\u2211Tt=1Ext~pXt[||st(Xt)\u2212s\u2217t(Xt)||22] =: \u03b52score/T.  (8)\nTarget data distribution. Next, we impose the following assumption on the target data distribution.\nAssumption 2. We assume that the target data distribution has a bounded second-order moment in the\nsense that\nE[||XO||2] < TCR   (9)\nfor arbitrarily large constant CR > 0.\nIn short, this assumption allows the second-order moment of the target data distribution to be exceedingly\nlarge, given that the exponent CR can be arbitrarily large. This is among the weakest assumptions imposed\nin sampling analysis, one that is typically satisfied by empirical data in practical sampling applications."}, {"title": "3 Main results", "content": "In this section, we introduce an accelerated sampler and present the theoretical guarantees on its convergence\nrate."}, {"title": "3.1 Accelerated sampler", "content": "Learning rate schedule. Let us first introduce the learning rate schedule (\u03b1t)t\u2208[T] for our proposed\nsampler. Given the definition of \u03b1t := \u03a01\u2264k\u2264t \u03b1k in (2), we can specify the learning rates through the\nfollowing recursive relationship:\n\u03b1T = 1/(TC0), and \u03b1t\u22121 = \u03b1t + C1\u03b1t(\u03b1t\u22121)/T, t = T, ..., 2,   (10)\nwhere Co, C1 > 0 are sufficiently large absolute constants with C1/Co large enough.\nSampling procedure. With the learning schedule in hand, we are now ready to present our accelerated\nsampling procedure.\nInitialized at YT ~ N(0, Ia), the sampler employs the update rule as follows. Working backward from\nt = T, . . ., 2, we first compute an intermediate point Ymid based on Yt:\nYmid := 1/\u221a\u03b1t(Yt + \u221a(1\u2212\u03b1t)/(2\u03b1t)st(Yt)) + \u221a(1\u2212\u03b1t)/(2\u03b1t)Zmid),  (11a)\nand then generate Yt\u22121 by\nYt\u22121 := 1/\u221a\u03b1t(Yt + \u221a(1\u2212\u03b1t)/(2\u03b1t){st(Yt+\u221a(1\u2212\u03b1t)Zmid) + clipt{\u03c3t3/2st\u22121(Ymid) \u2212 st(Yt+\u221a(1 \u2212 \u03b1t)Zmid)}}) + \u03c3tZt),  (11b)\nHere, Zmid, Zt ~iid. N(0, Ia) are standard Gaussian random vectors in Rd, \u03c3t2 := \u03b1t(3 \u2212 2\u03b1t)\u22121, and\nclipt{\u00b7} : Rd \u2192 Rd is a thresholding function:\nclipt{x} := x1{||x||2\u2264Cclip\u221a(dlogT)/(1\u2212\u03b1t)}, \u2200x \u2208 Rd,  (12)\nfor some absolute constant Cclip > 0.\nIn short, the proposed sampler first uses a single-step DDPM to generate an intermediate point Ymid,\nwhich enables the incorporation of an additional term clipt{\u03c3t3/2st\u22121(Ymid) \u2212 st(Yt+\u221a(1 \u2212 \u03b1t)Zmid)}} in\nupdating Yt\u22121. This additional term can be viewed as a refined second-order approximation to the score\nfunction, thereby leading to a faster convergence rate. To mitigate potential large approximation errors in\nworst-case scenarios, we employ a thresholding procedure\u2014a technique also used in practical applications\n(Saharia et al., 2022). While this second-order approximation idea shares similarities with existing ODE-\nbased accelerated samplers (Lu et al., 2022a; Li et al., 2024a), by injecting additional random noise, our\napproach reduces discretization error and attains faster sampling speeds compared to these fully deterministic\nacceleration schemes.\nRemark 1. Instead of running the sampling procedure to t = 0, we stop the update at t = 1 and take PX1\nas the new target distribution. This is often referred to early stopping, as the score functions can blow up as\nt \u2192 0 for non-smooth target data distributions and hence it is generally impossible to obtain non-trivial total\nvariation or KL divergence guarantees. The early stopping technique is widely employed in both real-world\napplications (Song et al., 2020c) and theoretical analysis (Chen et al., 2022b; Benton et al., 2023)."}, {"title": "3.2 Convergence guarantee", "content": "We now present the convergence theory for our proposed sampler, with the proof deferred to Section 4.\nTheorem 1. Suppose that Assumptions 1 and 2 hold. The output Y1 of the sampler (11) with the learning\nrate schedule (10) satisfies\nTV (Px1, PY1) \u2264 \u221aKL (px1 || PY1) \u2264 C(d5/2log5 T/T + d3/2log3 T/T2 + \u221a\u03b52score + \u03b5score\u221adlog\u221aT),  (13)\nfor some absolute constant C > 0."}, {"title": "4 Analysis", "content": "In this section, we outline the proof for Theorem 1. The detailed proofs are provided in the appendix.\nLet To \u2265 2 be the largest integer such that C1 (dlog5/2 T)/T < 1/2 where C1 is defined in (10). If T < To,\nwe have (d5/2 log5 T)/T2 > \u221ad/(2C1)2 and hence the result of Theorem 1 naturally holds when the absolute\nconstant C is chosen large enough. Therefore, in the rest of the proof, we assume that T > To so that\nC1d log2 T/T < 1/2.\nWe first collect several important properties of the learning rates (\u03b1t)t\u2208[T] in (10) below, which will be\nuseful for the analysis.\nLemma 1. The learning rates (\u03b1t)1\u2264t\u2264T specified in (10) satisfy that for all 2 \u2264 t \u2264 T:\n1-\u03b1t \u2264 C1(\u03b1tlogT)/T;  (14a)\n(1-\u03b1t)/\u03b1t \u2264 C1(logT)/T;  (14b)\n1\u2212\u03b1t \u2264 1+C1((\u03b1tlogT)/T)/(1\u2212\u03b1t);  (14c)\n(1-\u03b1t)/(1\u2212\u03b1t\u22121) \u2264 1+C1((\u03b1tlogT)/T);  (14d)\nwhere Co, C1 are defined in (10). In addition, \u03b11 satisfies\n1-\u03b11 \u2264 1/(TC0).   (14d)\nStep 1: constructing the auxiliary processes. To begin with, we introduce an auxiliary stochastic\nprocess (Yt\u2217 )1\u2264t\u2264T in Rd defined as follows. For each t = T,\u2026\u2026,2, we define\nYt\u2217,mid := 1/\u221a\u03b1t(Xt + \u221a(1\u2212\u03b1t)/(2\u03b1t)st(Xt)),  (15a)"}, {"title": "5 Discussion", "content": "This work uncovers the feasibility of provable acceleration of score-based samplers under minimal assump-\ntions: namely, L\u00b2-accurate score estimates and a finite second moment of the target distribution. We have\nproposed a training-free accelerated sampler that attains an iteration complexity of O\u02dc(d5/4/\u221a\u03b5), establishing\na theoretical foundation for efficient sampling speedups.\nSeveral important directions remain for future investigation. One pressing issue is to sharpen our con-\nvergence theory with respect to the data dimension d through a more refined analysis. Moving beyond\nthe second-order approximation developed in this work, another promising direction is to explore whether\nhigher-order ODE approximations can yield improved iteration complexity. Finally, for target distributions\nexhibiting low-dimensional structures, developing specialized acceleration schemes that exploit these intrinsic\nproperties presents another important avenue for sampling efficiency."}, {"title": "A.1 Proof of Lemma 2", "content": "We begin by introducing the following SDE:\ndX\u03c4 = \u22121/(2(1\u2212\u03c4))X\u03c4 d\u03c4 + 1/\u221a\u03c4dB\u03c4, Xo ~ Pdata; \u03c4 \u2208 [0, 1].   (36)\nIt is straightforward to verify that the solution to this SDE satisfies\nX\u03c4 = \u221a(1 \u2212 \u03c4)Xo + \u221a\u03c4Z,   (37)\nwhere Z ~ N(0, Ia) is a standard Gaussian random vector in Rd independent of Xo. In particular, we know\nthat Xt Xt1\u2212\u03b1t for all t \u2208 [T] by (1) and (3).\nFor any \u03c4\u2208 [0, 1], we denote by s\u2217(\u00b7, \u03c4) : Rd \u2192 Rd the score function of pX\u03c4, i.e.\ns\u2217(x, \u03c4) := \u2207 log pX\u03c4 (x) = \u22121/(2\u03c4)E[X\u03c4 \u2212 \u221a1 \u2212 \u03c4Xo | X\u03c4 = x], \u2200x \u2208 Rd.   (38)\nwhere the last expression can be derived by standard properties of Gaussian random vectors.\nAs discussed in (4) and (7) from Section 2.1, when initialized at x ~ PX0 = Pdata, the process (x\u03c4)\u03c4\u2208[0,1]\nthat solves the following probability flow ODE,\nd/d\u03c4x\u2217\u03c4 = s\u2217(x, \u03c4)/(1 \u2212 \u03c4)/(2(1 \u2212 \u03c4)3/2),   (39)"}, {"title": "A.2 Proof of Lemma 3", "content": "Proof of (26). We shall establish a stronger statement:\nEA[\u03a8t(Xt) \u2212 clipt{\u03c3t3/2st\u22121(Yt\u2217,mid)} \u2212 st(Xt)} 1{Xt \u2208 Et} \u2264 \u03c3t4(d/(1 \u2212 \u03b1t))5.  (44)\nCombined with the definitions of \u03a8t and Yt in (21) and (15b), respectively, (26) follows as an immediate\nconsequence. Therefore, we shall focus on proving (44).\nTowards this, let us fix an arbitrary 2 < t < T and denote\n\u03c4mid := 1 \u2212 \u03b1t\u22121.  (45)\nFor any x \u2208 Rd, we define \u03b8mid(\u00b7) : Rd \u2192 Rd by\n\u03b8mid(x) :="}, {"title": "A.5 Proof of Lemma 6", "content": "Let us start with the first claim. Straightforward calculation shows that\nEBt[||\u03c3t3/2st\u22121(Yt\u2217,mid) \u2212 \u03c3t3/2st\u22121(Xt\u22121)||2] \u2264 2\u03c3t2EA[||st\u22121(Xt\u22121) \u2212 s\u2217t\u22121(Xt\u22121)||2].\nwhere (i) arises from the definition of the event Bt in (24) and (ii) is due to Assumption 1 and \u03c3t < 1.\nSimilarly, we also have\nEBt[||st(Xt + \u221a(1 \u2212 \u03b1t)Z) \u2212 st(Xt + \u221a(1 \u2212 \u03b1t)Z)||"}]}