{"title": "Online Parallel Multi-Task Relationship Learning via Alternating Direction Method of Multipliers", "authors": ["Ruiyu Li", "Peilin Zhao", "Guangxia Li", "Zhiqiang Xu", "Xuewei Li"], "abstract": "Online multi-task learning (OMTL) enhances streaming data processing by leveraging the inherent relations among multiple tasks.\nIt can be described as an optimization problem in which a single loss function is defined for multiple tasks. Existing gradient-\ndescent-based methods for this problem might suffer from gradient vanishing and poor conditioning issues. Furthermore, the\ncentralized setting hinders their application to online parallel optimization, which is vital to big data analytics. Therefore, this\nstudy proposes a novel OMTL framework based on the alternating direction multiplier method (ADMM), a recent breakthrough in\noptimization suitable for the distributed computing environment because of its decomposable and easy-to-implement nature. The\nrelations among multiple tasks are modeled dynamically to fit the constant changes in an online scenario. In a classical distributed\ncomputing architecture with a central server, the proposed OMTL algorithm with the ADMM optimizer outperforms SGD-based\napproaches in terms of accuracy and efficiency. Because the central server might become a bottleneck when the data scale grows,\nwe further tailor the algorithm to a decentralized setting, so that each node can work by only exchanging information with local\nneighbors. Experimental results on a synthetic and several real-world datasets demonstrate the efficiency of our methods.", "sections": [{"title": "1. Introduction", "content": "Online multi-task learning (OMTL) processes related to\nlearning tasks sequentially aim to leverage the correlation\namong multiple tasks to improve overall performance. In each\nonline round, the learner receives multiple instances per task,\npredicts their labels, and then updates the model based on the\ntrue labels. A principal assumption for OMTL is the existence\nof potential similarities among multiple tasks the samples of\na single task obey a probability distribution similar to the prob-\nability distributions of other tasks. This assumption enables the\nOMTL to learn several models collaboratively using the shared\ninformation among different tasks. Compared with learning\neach task separately or treating all tasks as a whole, such a col-\nlaborative learning approach can enhance the performance of all\ntasks together. OMTL is a real-time, scalable, and continuously\nadaptive learning method [1]. It has been applied in sequential\ndecision making fields that require prompt response, such as\nonline personalized recommendations [2], targeted display ad-\nvertising [3], and sales forecasts for online promotions [4].\nDuring the past decades, several OMTL algorithms have\nbeen proposed, most of which are based on online gradient de-\nscent (OGD), such as mirror descent, dual averaging, and their\nproximal versions [5, 6]. In particular, OGD is typically used\nfor solving OMTL problems when it is easy to compute the\ngradient (or sub-gradient) of the online objective, and there are\nno constraints on the model. Proximal OGD is usually applied\nwhen the regularization term of the model is non-smooth (e.g.,\nL1 norm) [7]. Its proximal objective frequently enjoys a closed-\nform solution. However, for some regularization terms, such\nas the graph-guided L1 norm ||Fw||1 [8], adapting (proximal)\nOGD methods for distributed online learning settings is non-\ntrivial because sub-gradient methods cannot make Fw sparse\nand its proximal objective has no closed-form solution. Fur-\nthermore, the scalability of OGD-based multi-task algorithms\ndeteriorates when the gradient's dimensionality and the num-\nber of tasks increases, making them inadequate for large-scale\nlearning problems.\nUnlike OGD methods, the alternating direction multiplier\nmethod (ADMM) [9] is more applicable to general learning\ntasks because it does not require the objective to be differ-\nentiable. Specifically, it decomposes the global problem into\nsmaller, easier-to-solve sub-problems suitable for independent\nworkers. Each worker solves its own sub-problem, which de-\npends only on its own variables. Subsequently, a server opti-\nmizes the global problem by aggregating dual variables from\nall sub-problems. Owing to these advantages, ADMM is more\nsuitable for general distributed tasks and is regarded as a viable\nalternative to OGD for large-scale learning problems [10, 11].\nSince ADMM has shown superior ability at optimizing"}, {"title": "2. Related Work", "content": "The field of OMTL has investigated various approaches to\naddress the complexities of simultaneously learning multiple\ntasks. Modeling the relations among tasks is crucial for OMTL\nand directly impacts overall performance. Existing studies\nin OMTL typically categorize task relations into two primary\ntypes: strong and weak relations. Strong relations in OMTL of-\nten emphasize the similarity of model parameters across tasks.\nFor example, CMTL [14] assumes that multiple tasks follow a\nclustered structure, tasks are partitioned into a set of groups\nbased on model parameters, where tasks in the same group\nare similar to each other. A new regularizer [15] based on\n(2, 1)-norm is developed for learning a low-dimensional rep-\nresentation which is shared across a set of multiple related\ntasks. To utilize the second-order structure of model parame-\nter, CWMT [16] maintains a Gaussian distribution over each\nmodel to guide the learning process, where the covariance of\nthe Gaussian distribution is a sum of a local component and\na global component that is shared among all the tasks. Con-\nversely, weak relations consider tasks that may not share strong"}, {"title": "2.1. OMTL", "content": "The field of OMTL has investigated various approaches to\naddress the complexities of simultaneously learning multiple\ntasks. Modeling the relations among tasks is crucial for OMTL\nand directly impacts overall performance. Existing studies\nin OMTL typically categorize task relations into two primary\ntypes: strong and weak relations. Strong relations in OMTL of-\nten emphasize the similarity of model parameters across tasks.\nFor example, CMTL [14] assumes that multiple tasks follow a\nclustered structure, tasks are partitioned into a set of groups\nbased on model parameters, where tasks in the same group\nare similar to each other. A new regularizer [15] based on\n(2, 1)-norm is developed for learning a low-dimensional rep-\nresentation which is shared across a set of multiple related\ntasks. To utilize the second-order structure of model parame-\nter, CWMT [16] maintains a Gaussian distribution over each\nmodel to guide the learning process, where the covariance of\nthe Gaussian distribution is a sum of a local component and\na global component that is shared among all the tasks. Con-\nversely, weak relations consider tasks that may not share strong\nsimilarities but still exhibit some degree of relatedness, such as\nexhibiting similar polarities for the same feature. For exam-\nple, [17] explores the convergence properties of optimization\nmethods for multi-convex problems, providing insights to ad-\ndress weakly related tasks using alternating direction methods.\nTo fully utilize the polarity information of model parameters,\nSRML [18] regularizes feature weight signs across tasks to en-\nhance the learning ability of the model."}, {"title": "2.2. Distributed Optimization", "content": "Distributed optimization plays a crucial role in OMTL, as\nit makes it possible to process multiple tasks in parallel, thus\nenhancing the overall performance. Configuring servers (i.e.\ncentralized vs. decentralized) and making them communicate\n(i.e. synchronous vs. asynchronous) are fundamental prob-\nlems for distributed optimization. It has been theoretically ver-\nified that decentralized gradient descent converges to a consis-\ntent optimal solution if the expectation of the stochastic delay\nis bounded and an appropriate step-decreasing strategy is em-\nployed. In addition, their computational complexity is equiva-\nlent under certain conditions [19, 20]. On the other hand, syn-\nchronous communication among workers guarantees time-step\nalignment [21], whereas the asynchronous approaches have\nbeen proven efficient and easy to implement [22]. However,\nthese optimization methods are based on gradient descent tend\nto suffer from vanishing gradients, and are sensitive to poor con-\nditioning problems [23] when optimizing a non-convex objec-\ntive.\nAs a widely used optimization method, ADMM [9] mitigates\nthe gradient vanishing problem by decomposing a complex ob-\njective into several simple sub-problems to avoid the chain rule\nfor solving the gradients. In addition, it is insensitive to inputs\nand, therefore, immune to poor conditioning [10]. ADMM has\nbeen widely used in multi-task learning [24, 25]; however, ap-\nplying ADMM in OMTL has not yet been thoroughly studied."}, {"title": "3. Problem Setting", "content": "In an OMTL problem, we have a set of K parallel tasks whose\ndata (x, y) all come from the same space X \u00d7 Y, where x \u2208\nRd, y \u2208 RK. For simplicity, we focus on the cases where each is\na linear binary classification task, where X \u2282 Rd, Y = {+1, \u22121},\nand the model for each task is a vector w\u2208 Rd, so that its\nprediction is \u0177 = sign (w. x).\nBased on these assumptions, an OMTL algorithm works step\nby step. Specifically, at the t-th round, it receives a group of K\ninstances x,...,x, where x is an instance for the k-th task.\nThe algorithm first predicts the labels for each of the tasks as\nsign(x), k = 1,\u2026\u2026, K. It then obtains the true la-\nbels y, and suffers a loss $l(w_k^t;(x_k^t,y_k^t))$, where the\nloss function l(\u00b7) is convex, such as hinge loss: $l(w; (x, y)) =$\nmax (0,1 \u2013 y(wTx)). Based on the feedback, the algorithm up-\ndates the K classifiers from ${w_k^t}_{k=1}^K$ to ${w_k^{t+1}}_{k=1}^K$ to minimize its\nloss (plus a regularization term). The goal of an OMTL task is\nto learn a sequence of classifiers w\u00b9\u2026\u2026\u2026, w, t = 1,\u2026,T that"}, {"title": "4. Methodology", "content": "We solve the objective for Eq. (3) by proposing using the\nonline alternating direction method of the multiplier algo-\nrithm [27, 28] because it is very scalable to large-scale stream\ndatasets and can be easily distributed to multiple devices.\nFollowing the online ADMM setting, we can rewrite our\nOMTL task at time t as the following optimization problem:\n$\\min_{u_t,W_t,V_t,\\Omega_t} \\sum_{k=1}^K \\frac{\\lambda_1}{T}l_k(w_k^t;\\xi_k^t) + \\frac{\\lambda_2}{2}||u_t||_2^2 + \\frac{\\lambda_3}{2} \\sum_{k=1}^K ||v_k^t||_2^2$\n$+\\frac{\\lambda_4}{2} tr(V_t^T\\Omega_t V_t) + \\eta B_{\\phi} (W_{t-1}, W_t)$\ns.t. $w_k^t - u_t - v_k^t = 0, k = 1,\\ldots, K$\n$\\Omega_t \\succeq 0, tr(\\Omega_t) = 1$\nwhere $W_t = [w_1^t,\\ldots, w_K^t], V_t = [v_1^t,\\ldots,v_K^t] \\in R^{d \\times K}, \\eta \\ge 0$\ncontrols the step size. B\u00f8 is the Bregman divergence defined\non a continuously differentiable and strictly convex function\nto control the distance between W\u2081 and Wt+1. B\u00f8 (Wt-1, W\u2081)\nprovides a way to quantify and potentially control the varia-\ntion of the parameter W from the t 1-th round to the t-th\nround. By choosing the appropriate 6, we can affect the op-\ntimization trajectory. As shown Eq. (4), the online distributed\nmulti-task learning problem is a globally consistent optimiza-\ntion. The first term of Eq. (4) denotes the objective function\npartitioned to each worker, w and v are the local model pa-\nrameters of worker k at the t-th online round and u, indicates\nthe global consistency variable. Each worker independently re-\nceives streaming data for parallel training and, through iterative\nupdates, eventually converges to a consistent global model.\nAt the t-th online round, t = 1,\u2026, T, we process the opti-\nmization problem (4) in two stages: the first stage deals with\nthe parameters about the learners (or workers), i.e., w,v and\nut. When updating these parameters, we follow the ordinary\nADMM [9] ordering procedure\u2014one can update w and v\nfor each task in parallel and subsequently update the inter-task\nshared pattern. Once we obtain the least parameters (more pre-\ncisely, v, k = 1,\u2026\u2026, K), the second stage allows us to update\nthe relationship among tasks. The detailed procedure of the\nabove two stages are as follows:"}, {"title": "4.1. Optimizing w,v and u\u2081 When \u03a9\u2081 is Fixed", "content": "Firstly, we fix 2, and optimize the remaining variables.\nThis optimization problem is constrained convex, which can be\nstated as:\n$\\min_{u_t, W_t,V_t} \\sum_{k=1}^K \\frac{\\lambda_1}{T}l_k(w_k^t;\\xi_k^t) + \\frac{\\lambda_2}{2}||u_t||_2^2 + \\frac{\\lambda_3}{2} \\sum_{k=1}^K ||v_k^t||_2^2$\n$+\\frac{\\lambda_4}{2} tr(V_t^T\\Omega_t V_t) + \\eta B_{\\phi} (W_{t-1}, W_t)$\ns.t. $w_k^t - u_t - v_k^t = 0, k = 1,\\ldots, K$\nWe solve the above problem using ADMM by first deriving\nthe augmented Lagrangian function of problem (5) as:\n$L(W, V, u, z) = \\sum_{k=1}^K \\frac{\\lambda_1}{T}l_k(w_k^t;\\xi_k^t) + \\frac{\\lambda_2}{2}||u_t||_2^2 + \\frac{\\lambda_3}{2} \\sum_{k=1}^K ||v_k^t||_2^2$\n$+\\frac{\\lambda_4}{2} tr(V_t^T\\Omega_t V_t)+\\sum_{k=1}^K (z_k^T(w_k^t-u_t-v_k^t))$\n$+\\frac{\\rho}{2}\\sum_{k=1}^K ||w_k^t-u_t-v_k^t||_2^2 + \\eta B_{\\phi} (W_{t-1}, W_t)$\nwhere z \u2208 Rd are the dual variables and p > 0 is the penalty\nparameter.\nSubsequently, according to the online ADMM algorithm, our\nalgorithm comprises updates of the primal variables W\u2081, Vt, Ut\nand dual variables z\u0142.\nUpdating W\u2081. The update of W, can be written as:\nW1+1 = argmin L (W1, Vt, ut, Zt)\nW\n= argmin$\\sum_{k=1}^K (\\frac{\\lambda_1}{T}l_k(w_k^t;\\xi_k^t) + z_k^T (w_k^t-u_t-v_k^t))$\nW\u2081\n$+\\frac{\\rho}{2}\\sum_{k=1}^K ||w_k^t-u_t-v_k^t||_2^2 + \\eta B_{\\phi} (W_{t-1}, W_t)$\nHowever, it is challenging to solve the closed-form solution\nof the above optimization problem (7) for the hinge loss func-\ntion. Thus, we adopt the first-order approximation of hinge\nloss:\n$\\ell_k^t(w) \\approx \\ell_k^t(w_k^t) + \\nabla \\ell_k^t(w_k^t)^T (w - w_k^t)$\nFurthermore, we consider B\u00f8 (w, u) = \u00bd||w - u||2 for simplic-\nity so that\n$B_{\\phi} (W_{t-1}, [w_1^t,\\ldots,w_k^t]) = \\frac{1}{K}\\sum_{k=1}^K ||w_k^t - w_k^{t-1}||_2^2$\nCombining the above equations gives an approximate solu-\ntion of problem (7) as:\nW+1=\n$\\frac{\\frac{\\rho}{\\rho + \\eta}(u_t + v_t) + \\frac{\\eta}{\\rho + \\eta} w_k^{t-1} + \\frac{\\lambda_1}{\\rho + \\eta} (\\nabla \\ell_k^t(w_k^t)+z_k^t)}{\\frac{\\rho + \\eta}{\\rho + \\eta}}$\nUpdating V\u2081. The unique pattern V, for each task can be\nupdated as:\nVt+1 = argmin L (Wt+1, Vt, ut, Zt)\nV\u2081\n= argmin$\\sum_{k=1}^K (\\frac{\\rho}{2}||w_{k}^{t+1}-u_t-v_k^t||_2^2)$\nV\n$+\\frac{\\lambda_3}{2} \\sum_{k=1}^K ||v_k^t||_2^2 +\\frac{\\lambda_4}{2} tr(V_t^T\\Omega_t V_t)$\nWith the careful deduction of Eq. (11), we can derive the\nfollowing solution:\n$\\hat v_{t+1} = (u_t + w_{t+1})\\frac{\\lambda_3}{(\\lambda_3 + \\rho)}$\n$+\\frac{\\lambda_4}{(\\lambda_3 + \\rho)} V_t (\\Omega_t)_{:,k} (\\Omega^{-1})_A$\nwhere $[\\u03a9_t + V_t^TV_t\\frac{\\rho+\\lambda_3}{\\lambda_4}]^{-1}$ denotes the k-th column of the\nmatrix.\nUpdating ut. Simultaneously, the shared pattern u, of the"}, {"title": "4.2. Optimizing & When V\u2081 is Fixed", "content": "Finally, we optimize the variable 2, while fixing all the other\nvariables. This optimization problem can be expressed as the\nfollowing constrained one:\nmin tr (VV)\n$\\Omega$\ns.t. \u03a9 \u2265 0, tr (\u03a9\u2081) = 1\nSubsequently, denote A\u2081 = VIV\u2081, and we can derive the follow-\ning inequalities:\ntr (\u03a9\u0391\u2081) = tr (A) tr (\u03a9)\n\u2265 (tr(A))2\nwhere the first equality holds because of the last constraint\nin problem (17), and the last inequality holds because of the\nCauchy-Schwarz inequality for the Frobenius norm. Moreover,\ntr (\u03a9\u0391) attains its minimum value (tr (A/2))2 if, and only if,\n\u03a91/21/2 = a\u03a91/2 for some constant a, tr (\u03a9\u2081) = 1. Therefore,\nwe can obtain the analytical solution for optimization prob-\nlem (16):\n$\\Omega_t = \\frac{(V_t^TV_t)^{1/2}}{tr((V_t^TV_t)^{1/2})}$"}, {"title": "5. Experimental Results", "content": "We use a synthetic and five real-world datasets to evalu-\nate our methods. The real-world datasets are sourced from\nthree typical multi-task learning applications: sentiment anal-\nysis, small molecule classification, and image classification.\n\u2022 Synthetic Dataset [29]. It contains five binary classi-\nfication tasks whose similarities are controlled by a set\nof parameters. The basic problem is discriminating two\nclasses in a two-dimensional plane with a non-linear de-\ncision boundary. Changing the parameter rotates the de-\ncision boundary to create tasks that look similar but have\nsubtle differences.\n\u2022 Multi-Lingual Dataset\u00b3. It collects product reviews from\nAmazon in five languages: Chinese, English, Japanese,\nIndonesian, and Malay. Each language contains positive\nand negative reviews.\n\u2022 Chem Dataset4. It contains six small molecule active\nclassification tasks, such as distinguishing between classes\nof HIV molecules (active vs. inactive).\n\u2022 Landmine Dataset. It includes twenty-nine landmine\nfields. For each field, every sample in the dataset consists\nof nine features and a binary label indicating whether the\ncorresponding location contains landmines.\n\u2022 MNIST Dataset. It comprises handwritten digits for im-\nage recognition. Following the setup in [30], we create\nfive binary classification tasks as 0 vs. 5, 1 vs. 6, 2 vs. 7,\n3 vs. 8, and 4 vs. 9. Each image is represented by a 512-\ndimensional vector after processing by using a pre-trained\nResNet18 model.\nWe use a transformer for the two sentiment analysis datasets\nto convert the raw text into vectors of dimension 512. The graph\nembedding [31] is applied to generate the corresponding em-\nbedding vectors for each molecule for the two small molecule\ndatasets. Table 1 summarizes their task numbers, sample sizes,\nfeature counts and class distribution."}, {"title": "5.2. Benchmark Setup.", "content": "We refer to the proposed distributed OMTL with ADMM\nwith a central server as C-ADMM and its decentralized vari-\nant as D-ADMM. Two topologies abbreviated as Ring and Full-\nConn are considered, where the former represents a ring net-\nwork, and the latter connects each worker to others in the net-"}, {"title": "5.3. Performance Evaluation.", "content": "Figure 1 depicts the variations of the averaged error rate\nover the entire online learning process. Table 2 reports the\nmean error rates of different algorithms at their last learn-\ning round. The proposed distributed online parallel multi-\ntask learning (C-ADMM and D-ADMM) outperform methods\nthat learn multiple tasks individually with ADMM (ADMM-\nSingle) or learn multiple tasks jointly with optimizers other than\nADMM (DROM and D-PSGD) regarding the error rate in most\ncases. By comparing D-ADMM with its centralized counter-\npart, C-ADMM, we observe that implementing ADMM in a de-\ncentralized architecture can achieve comparable (or even better)\nperformance than the centralized one, whereas decentralization\nhas scalability benefits in practice. D-ADMM (Full-Conn) out-\nperforms D-ADMM (Ring) because the fully connected and\ndiscretely distributed workers can extract more model informa-\ntion from other peers. Overall, the proposed C-ADMM and\nD-ADMM perform better than other baselines. The C-ADMM\nexcels on the synthetic dataset with the most optimal data dis-\ntribution, whereas the D-ADMM demonstrates better perfor-\nmance on datasets that more closely resemble real-world sce-\nnarios. This suggests that D-ADMM is better suited for cases\ninvolving unbalanced label distributions and extreme dispari-\nties in data quantity among workers. Furthermore, by compar-\ning the proposed C-ADMM and D-ADMM with PMSC-Log,\nan ADMM-based OMTL method, without explicitly modeling"}, {"title": "5.4. Effect of Relationship Learning.", "content": "We further examine the contribution of the proposed rela-\ntionship learning to the overall OMTL method by conducting\nan ablation study by removing it and investigating the perfor-\nmance of the remaining parts. Table 4 lists the variation of the\naveraged error rate on various datasets of learning tasks inde-\npendently (denoted as Indpt), learning tasks jointly but without\nrelationship modeling (denoted as W/O RL) and learning tasks\nusing the proposed methods (denoted as With RL). The margins\nin the cumulative error rate demonstrate the effect of the pro-\nposed relationship learning module and verify our assumption\nthat modeling relations among tasks is essential for the OMTL\nproblem. The ablation results on task relationship learning sug-\ngest that it will be beneficial for online multi-task learning ap-\nplications (e.g., in a social search system, searching for creators\nand for content can be treated as two distinct tasks, and the\nuser experience can be effectively improved through multi-task\nlearning) to learn their implicit relationships."}, {"title": "6. Conclusion", "content": "We proposed two distributed OMTL frameworks using a tai-\nlored ADMM as the optimizer and an effective mechanism to\nrepresent task relations to enhance learning. The experimental\nresults indicated that the ADMM optimizer, specifically regard-\ning the task relations modeling method, is effective and efficient\nfor learning online-related tasks. For future work, we wish to\nextend our methods to multi-class classification settings, which\ninvolve evaluating the loss function with multi-class classifi-\ncation mechanisms such as the one-vs-rest strategy. Further-"}]}