{"title": "GENERATIVE PRECIPITATION DOWNSCALING USING SCORE-BASED DIFFUSION WITH WASSERSTEIN REGULARIZATION", "authors": ["Yuhao Liu", "James Doss-Gollin", "Guha Balakrishnan", "Ashok Veeraraghavan"], "abstract": "Understanding local risks from extreme rainfall, such as flooding, requires both long records (to sample rare events) and high-resolution products (to assess localized hazards). Unfortunately, there is a dearth of long-record and high-resolution products that can be used to understand local risk and precipitation science. In this paper, we present a novel generative diffusion model that down-scales (super-resolves) globally available Climate Prediction Center (CPC) gauge-based precipitation products and ERA5 reanalysis data to generate kilometer-scale precipitation estimates. Downscaling gauge-based precipitation from 55 km to 1 km while recovering extreme rainfall signals poses significant challenges. To enforce our model (named WassDiff) to produce well-calibrated precipitation intensity values, we introduce a Wasserstein Distance Regularization (WDR) term for the score-matching training objective in the diffusion denoising process. We show that WDR greatly enhances the model's ability to capture extreme values compared to diffusion without WDR. Extensive evaluation shows that WassDiff has better reconstruction accuracy and bias scores than conventional score-based diffusion models. Case studies of extreme weather phenomena, like tropical storms and cold fronts, demonstrate WassDiff's ability to produce appropriate spatial patterns while capturing extremes. Such downscaling capability enables the generation of extensive km-scale precipitation datasets from existing historical global gauge records and current gauge measurements in areas without high-resolution radar.", "sections": [{"title": "Introduction", "content": "Precipitation variability and extremes affect the Earth and society [Wright et al., 2019, Calvin et al., 2023, Seneviratne et al., 2021], and inform scientific understanding of physical processes in climate and hydrology. This understanding can lead to consequential applications such as flood control [Skofronick-Jackson et al., 2017, R\u00f6zer et al., 2019, Wright et al., 2019, Sampson et al., 2015] and water resources management [Schneider et al., 2014, Ahmed et al., 2021]. Such applications demand information at high spatiotemporal scales to capture local effects and variability, as well as long records to improve understanding and prediction of rare extremes. However, there is a lack of high-resolution, long-duration data that can be used to inform science and climate resilience. Rain gauges have been used to measure precipitation for centuries and are still considered a reliable source for quantitative precipitation estimation [Lanza and Stagi, 2008]. Gridded rain gauge products, such as Climate Prediction Center (CPC) Unified Precipitation [Xie et al., 2007], have been widely adopted [Shen and Xiong, 2016, Hu et al., 2018, Gavahi et al., 2023]. However, the interpolation methods [Xie et al., 2007] used in these products lead to low-resolution estimates (e.g., CPC at 55 km resolution) that are inadequate for many applications, including understanding the dynamics of extreme storms and developing adaptation plans [Fowler et al., 2021]. The last two decades have seen a focus on the development of radar-based precipitation measurements at high spatiotemporal resolution [Zhang et al., 2016, Met Office, 2003]. However, the short observational record of these products limits suitability for many applications, especially including extremes and changes over time [Beck et al., 2019].\nOne natural approach to developing long-duration, high-resolution precipitation estimates is to downscale, or increase the resolution of, long-duration and low-resolution datasets using short-duration, high-resolution datasets. Past work achieves this through dynamical [Dowell et al., 2022, Routray et al., 2010] and statistical downscaling [Wilby et al., 1998], though the former suffers from high computational complexity [Nishant et al., 2023], and the latter is less reliable in quantifying extreme events. Recent downscaling methods based on deep learning are now state-of-the-art [Price and Rasp, 2022, Harris et al., 2022, Mardani et al., 2023, Leinonen et al., 2021, Addison et al., 2022]. Most recently, Mardani et al. [2023] presented a diffusion model that can generate km-scale precipitation from 25 km global weather predictions.\nWhile the existing deep learning studies in this space focus on downscaling forecasts (see Appendix. A for more details), few have explored downscaling low-resolution observations, such as sparse rain gauge readings. The long-term precipitation gauge records remain invaluable for climate and hydrology research, and downscaling these products could open the door to a multitude of operational research. Downscaling extremely coarse gauge readings poses some unique challenges. First, the downscaling ratio is higher than any existing work: we tackle the challenge of going from 55 km to 1 km in this study. Such a resolution ratio makes the downscaling task more ill-posed and uncertain. Second, although gauge readings are accurate in an average sense [Chen et al., 2008], they fail to capture high-rainfall events beyond certain thresholds.\nFor these reasons, directly applying score-based diffusion models (SBDMs) [Song et al., 2020] to downscale CPC gauge precipitation to 1 km leads to subpar results, according to our experiments. We show that a traditional SBDM trained"}, {"title": "Method", "content": "2.1 Precipitation downscaling\nWithin a geographical region bounded by some coordinates, we extract CPC Unified Gauge precipitation [Xie et al., 2007] (yp \u2208 Rm'xn'), at 55 km resolution. Using CPC as the sole input would pose significant challenges for downscaling due to the inherent ill-posed nature of translating coarse data into finer resolutions. To address and mitigate the complexities of this downscaling task, we incorporate a subset of ERA5 reanalysis variables (at 31 km resolution) as ancillary data. ERA5 variables (yera5 \u2208 Rm\u2033\u00d7n\u2033\u00d7Cera5) provide essential atmospheric and environmental context linked to precipitation dynamics [Mardani et al., 2023]. We also include gauge density data, describing the density of CPC precipitation gauges at a given location and time, denoted by ya \u2208 Rm'\u00d7n'. We bilinearly upsample all conditional inputs to target resolution (m \u00d7 n) and stack them to obtain y \u2208 Rm\u00d7n\u00d7Cin via y = [fBL(yp), \u0192BL (Yera5), fBL(ya)], where fBL(\u00b7) denote the bilinear upsampling.\nOur goal is to generate high-resolution precipitation fields x conditioned on a set of low-resolution data: gauge-based precipitation, gauge station density, and a subset of ERA5 variables, as seen in Fig. 1. More precisely, we aim to model the probability density function p(x|\u0443\u0440, \u0423era5, yd).\n2.2 Conditional score-based diffusion models\nDiffusion models learn the conditional data distribution p(x|y) using a neural network to reverse a predefined noising process that progressively corrupts the data. In this study, we formulate the forward and reverse diffusion process using stochastic differential equations (SDEs) Song and Ermon [2020]. Consider Pdata as the true data (i.e., target) distribution and pr as the prior distribution. The SDE for the forward diffusion process {x(t)} indexed by a continuous time variable t \u2208 [0, T] is described as\n$dx = f(x, t)dt + g(t)dw$   (1)\nwhere w is the standard Wiener process (a.k.a, Brownian motion), f(\u00b7, t) : Rd \u2192 Rd is the drift coefficient of x(t), and g(\u00b7) : R \u2192 R is the diffusion coefficient of x(t). To generate data samples x(0) ~ po(x|y), we start from samples from the prior distribution x(T) ~ pr and follow the reverse-time SDE:\n$dx = [f(x, t) - g(t)\u00b2\u2207xlogpt(x|y)]dt + g(t)dw$  (2)\nwhere w is the standard Weiner process when time flows backward from T to 0 and \u2207xlogpt(xy) describe the conditional score (i.e., the gradient of the log probability density w.r.t. data) at an intermediate time step t. The ability"}, {"title": "Wasserstein distance regularization", "content": "In a conventional score-based diffusion model, samples are first drawn from the prior distribution (x(T) ~ pt) and then iteratively denoised following the reverse SDE trajectories estimated by the score function se (x, y, t). This process is illustrated by the purple dashed lines in Fig. 2, where we visualize the progression of average intensity, \u03bcx. The conventional score-matching function (Eq. (3)) shifts \u00b5\u3047 in the denoising process, thereby resulting in samples with a large variance in average intensity (purple solid curve). For a fixed condition y, high variance in \u00b5x indicates a lack of model reliability in consistently reproducing the correct intensity, which is undesirable.\nWe seek a mechanism that regularizes the deviation in intensity in the reverse diffusion process. To achieve this, we utilize the Wasserstein distance. Consider two arbitrary distributions, Pa and P6. The 1D Wasserstein distance (a.k.a, Earth Mover Distance, or EMD) is defined as:\n$W(Pa, Pb) = \\underset{\\gamma~\\Pi(P_a, P_b)}{inf} E_{(k,l)~\\gamma} [||k - 1|||]$  (4)\nwhere I(Pa, Pb) denotes the set of all distributions y(k, l) whose marginals are Pa and Ps. Intuitively, \u03b3(k, l) indicates how much mass must be transported from k to l in order to transform the distributions Pa into the distribution Pb. Eq. (4) describes the cost of the optimal transport plan.\nWe aim to compute the Wasserstein distance between sample and target distributions at each iteration of the denoising process. However, both sample and target distributions consist of a set of images over which we cannot directly compute ID Wasserstein distance. We instead use the sliced Wasserstein distance [Bonneel et al., 2015], WS (Pa, P\u044c), which projects high-dimensional vectors, a and b, to a set of random 1D subplanes and then computes the average projected 1D Wasserstein distances.\nConsider a noisy sample x(t), we compute the sliced Wasserstein distance of WS (Px(0), Px) computed between the distribution of denoised sample x(0) = x(t) + se(x(t), y, t), and target x. Here, the distribution is computed over a minibatch. See Appendix B for implementation details.\nTo incorporate Sliced Wasserstein Distance into the existing score-matching framework, we modify the training objective of a typical score-based diffusion model (Eq. (3)) by using a weighted average of score-matching loss and Wasserstein distance between the partially denoised samples and target at step t. The new training objective, with Wasserstein distance regularization (WDR), is as follows:\n$\\theta^* = arg min E_{t\\{x(t)}E_{x(0)}E_{x(t)|x(0)} [(1 \u2212 a) ||s_\\theta(x(t), y, t) \u2013 \\nabla_{x(t)}logp_\\theta(x(t)|x(0)||\n+aW_S(P_{x(0)}, P_x)]\\}$   (5)\nwhere a \u2208 [0, 1] is a scalar coefficient.\nBlue dashed lines in Fig. 2 show the SDE trajectory of \u00b5x using the same condition y, using a Wasserstein distance regularized estimated score function (Eq. (5)). Under WDR, the variance of the average intensity of samples is contained early in the denoising process. This ultimately translates to samples whose intensity values closely match the corresponding targets."}, {"title": "Experiments", "content": "3.1 Datasets\nWe use a collection of datasets to train and evaluate our model:\nCPC Unified Precipitation. The National Oceanic and Atmospheric Administration (NOAA) Climate Prediction Center (CPC) provides a gauge-based analysis of daily precipitation products constructed on a 0.5\u00b0 latitude-longitude grid (approximately 55 km) over the entire Earth from 1978 to present [Xie et al., 2007]. The quality of CPC precipitation products increases with the gauge network density, and station density across the entire Contiguous United States (CONUS) region is high, making it suitable for training and validation. In additional precipitation data, we also obtain gauge network density from CPC, which describes the number of gauges per 0.25\u00b0 \u00d7 0.25\u00b0 grid used for each daily observation.\nERA5 Reanalysis Products. The European Centre for Medium-Range Weather Forecasts (ECMWF) provides atmospheric reanalysis of the global climate. ECMWF's fifth-generation atmospheric reanalysis product (ERA5) [Hersbach et al., 2023] provides hourly estimates of a large number of atmospheric, land, and oceanic climate variables, covering the period from 1940 to present. ERA5 data covers the Earth on a 31 km grid and resolves the atmosphere using 137 levels from the surface up to the height of 80 km. We use a small subset of six ERA5 variables that strongly impact precipitation: 2m temperature (K), geopotential (at Earth's surface, i.e., orography) (m\u00b2 s\u00af\u00b2), U component of wind (ms-1) at 500 hPa, V component of wind (ms\u00af\u00b9) at 500 hPa, vertical integral of northward water vapor flux (kg m\u00af\u00b9 s-1), and vertical integral of eastward water vapor flux (kg m-1s-1).\nMRMS Precipitation. The Multi-Radar/Multi-Sensor (MRMS) [Zhang et al., 2016] system was developed by NOAA's National Centers for Environmental Prediction (NCEP) to produce severe weather, transportation, and precipitation products. MRMS integrates about 180 operational radars across CONUS and southern Canada along with 7000 hourly gauge, atmospheric, and environmental and climatological data to produce precipitation estimates at approximately 1 km spatial resolution with a 2 minute update cycle. We specifically use hourly precipitation aggregate data from the MultiSensor_QPE_01H_Pass2 dataset when available (Oct 13, 2020, and onwards) and the GaugeCorr_QPE_01H dataset for earlier periods (May 8, 2015 - Oct 13, 2020). We calculate daily aggregates by summing up all hourly aggregates within each day."}, {"title": "Implementation of training and inference", "content": "We perform 80/20 train validation split on our dataset. The training set consists of data sampled from Sept 4, 2016 - Dec 31, 2021, while the validation set consists of data sampled from May 8, 2015 - Sept 3, 2016. All train and validation samples have dimension 512 \u00d7 512 km (i.e., m = n = 512). See Applendix C for input data processing and normalization.\nOur score-matching neural network architecture follows the backbone from Song et al. [2020]; we build upon their best-performing model NCSN++ with noise perturbation following discretized Variance-Exploding SDE (VE SDE) [Song et al., 2020]. The model employs a series of BigGan-style residual blocks [Brock et al., 2019], totaling 120.7 M parameters. We used a batch size of 12 and trained over 110 K iterations, using an exponential moving average (EMA) rate of 0.999. We follow Song et al. [2020] for optimization, including learning rate, gradient clipping, and learning rate warm-up schedule. The training objective of WassDiff is defined in Eq. (5), using the denoising score matching objective with WDR. We set the coefficient for WDR a = 0.2 for Eq. (5). We also explored other a but did not find any improvements at an early stage of our experiments.\nWe train an ablation model using the score-matching objective Eq. (3) without WDR. We call this ablation model SBDM as a representative baseline performance for conventional score-based diffusion models. SBDM was trained trained for 200 K itrations, nearly doubles the training iterations of WassDiff. All other parameters for WassDiff and SBDM are the same. All models are trained on a single Nvidia A100 GPU and a 32-core Intel Xeon Platinum 8362 CPU with 1 TB of DRAM.\nFor sampling via WassDiff and SBDM, we use the Predictor-Corrector (PC) sampling scheme following Song et al. [2020] discretized at 1000 steps with the reserve diffusion predictor, one Langevin step per predictor update, and a signal-to-noise ratio of 0.16. The sampling speed time for each 512 \u00d7 512 km crop is about 13 minutes using a batch size of 12 on a single Nvidia A100."}, {"title": "Evaluation", "content": "3.3 Evaluation\nTable 1: Skill scores evaluated across 282 validation samples. We report traditional measures (MAE, CSI, bias), an ensemble metric (CRPS), two heavy and extreme rainfall metrics (HRRE, MPP), and a visual quality metric (LPIPS [Zhang et al., 2018]). We use 13 ensemble members for SBDM and WassDiff. Bilinearly interpolated CPC data (CPC_Int) and CNN [Veillette et al., 2020] are two deterministic baselines.\n3.3.1 Quantitative reconstruction skills\nTable 1 shows the skill scores for four models across 282 validation samples. All validation samples are drawn from May 8, 2015 - Sept 3, 2016, in CONUS. CPC_Int refers to bilinearly interpolated CPC precipitation. We adopt a UNet-syle CNN from Veillette et al. [2020] as a baseline. We train the CNN on CPC and ERA5 data, identical to the data WassDiff was trained on. For the two diffusion models, the MAE is reported between the sample mean and target. For WassDiff and SBDM, we use 13 ensemble members for each validation input. Because CPC_Inter and CNN are deterministic models, we do not report Continuous Ranked Probability Scores (CRPS), which is an ensemble metric. For deterministic predictions, MAE and CRPS are equivalent. Critical Success Index (CSI) reflects the categorical forecast performance. Here, we use spatially averaged-pooled CSI with a pooling scale of 16 km. Heavy rain region error (HRRE) [Chen et al., 2022] and Mesoscale peak precipitation error (MPPE) [Chen et al., 2022] reflect"}, {"title": "Spectra and distributions", "content": "We take all validation samples from Table 1 and perform a reduction along space, time, and ensemble axes to produce the spectra and distribution plots in Fig. 3. Fig. 3(a) shows the probability density function (PDF) across all validation samples. Notably, CPC_Int fails to capture rainfall values greater than around 100 mm/day in this particular set of samples. The difficulty in capturing extreme rainfall is initially caused by the sparse gauge instruments themselves and then exacerbated by the spatial averaging of bilinear interpolation. CNN fails to match the target distribution. Both diffusion models produce distributions closely aligned to the target distribution, although the model trained with WDR (blue curve) slightly underestimates at extreme values.\nFig. 3(b) shows the radially-averaged power spectra distribution (PSD) [Pulkkinen et al., 2019] for different methods. PSD shows the spatial signal at different frequencies. Both diffusion models (trained with or without WDR) produce output spectra that closely match the target spectra, and spectra only deviate at frequencies greater than 0.1 km\u00af\u00b9. In contrast, the spectra for CPC_Int deviate from MRMS, meaning that both models produce coarse results and cannot capture fine-scale weather patterns. There is an anomaly for very high-frequency signals for CNN; the 3 spikes are consistent with the local pixelation artifacts (see Appendix F)."}, {"title": "Case studies of extreme weather events", "content": "3.3.3 Case studies of extreme weather events\nOperational meteorologists value case studies, as aggregated skill scores and spectra can be more easily gamed. In Fig. 4, we present three types of extreme weather events to further demonstrate reconstruction skills. For each event, we include ERA5 inputs (at 25 km), low-resolution CPC precipitation input (at 55 km), our model output, and MRMS ground truth, with the last two images both at 1 km. For wind and water vapor transport inputs in ERA5, we aggregate northward and eastward components in single vector graphs, and the colormaps indicate the norm of the vectors. We use Universal Coordinate Time (UTC) for all date and time references in this paper.\nFig. 4(a) shows reconstruction results for Tropical Storm Bill (2015), a large-scale coherent structure. While the coherent structures (such as spiral bands of clouds emanating from the storm center) are completely missing from coarse CPC input, our model produces those patterns akin to the MRMS target, likely by leveraging ERA5 ancillary variables. This is a reassuring sign that our diffusion model produces output reminiscent of the appropriate multivariable physics between precipitation and other climate variables such as wind and temperature.\nFig. 4(b) presents a frontal system in the form of a cold front. A cold front is a sharp boundary in the atmosphere where a colder air mass displaces a warmer air mass in the upward direction. Upward displacement of warm air leads to cooling, followed by condensation and, ultimately, rainfall. Downscaling frontal systems provide utility because intense rainfall tends to occur near the frontal boundary, which is captured by our diffusion output and MRMS but absent in the coarse CPC input. The magnitude of extreme rainfall (lower right corner) is well-calibrated to the MRMS target.\nThe last case study shows a giant hail observed near Minooka, IL, shown in Fig. 4(c). Hail is a form of solid precipitation and is associated with strong thunderstorms with intense updrafts that carry water droplets into extremely cold parts of the atmosphere, causing them to freeze and ultimately resulting in fallen ice crystals (i.e., hailstones). Ice crystals can be resolved by weather radars like MRMS but not gauge-based measurements like CPC, as seen in Fig. 4(c). Our diffusion output captures such isolated, localized precipitation with a well-calibrated intensity consistent with target."}, {"title": "Quantile analysis", "content": "3.3.4 Quantile analysis\nWe use quantile-quantile plots (a.k.a. QQ plots) to measure the calibration of ensemble forecasts across different rainfall intensity levels in Fig. 5. QQ plots show the 0th - 100th percentile in rainfall intensity in prediction ensemble versus target. A perfectly calibrated output produces samples whose rainfall intensities exactly match with the target across all percentiles, producing expected trend lines denoted by the black dashed lines in Fig. 5. We show QQ plots for the three aforementioned extreme events in the order presented in Fig. 4. WassDiff (trained with WDR for 110K iterations) and SBDM (trained without WDR for 200K iterations) are used to downscale these extreme events with an ensemble size of 16. The ensemble means are denoted by the solid lines, and the translucent bands represent one standard deviation away from the sample mean. Our model is well-calibrated across the entire range of precipitation values, including the 100th percentile. The good agreement between forecast and target means that our model captures the correct distribution of rainfall, including the extremes. In contrast, SBDM tends to underestimate precipitation, on average. The confidence intervals for WassDiff are also tighter than SBDM, reflecting the high forecast precision. Fig.5 suggests both models slightly underestimate precipitation, with SBDM being noticeably worse than WassDiff. This observation agrees with the bias scores in Table1, whose values are aggregated across the entire validation set."}, {"title": "Discussion and Conclusion", "content": "This study introduces a score-based diffusion model with Wasserstein distance regularization (WDR) in the reverse diffusion process. WDR penalizes deviation in intensity values founded in the denoising process, resulting in generated samples with well-calibrated intensity distributions. Extensive testing supports that WassDiff can skillfully downscale CPC gauge-based precipitation from a very coarse resolution of 55 km down to 1 km, a resolution sufficiently fine to resolve small-scale weather details. The use of score loss and ERA5 ancillary data as additional input enables our model to produce the appropriate texture akin to various meteorology phenomena, such as tropical storms and cold fronts.\nWDR dramatically improves the calibration of rainfall intensities, leading to improved skill scores such as MAE, CRPS, and bias, and crucially, the ability to accurately capture extreme rainfalls. The ability to downscale CPC gauge data enables the generation of extensive kilometer-scale precipitation datasets from existing historical global gauge records, such as CPC, and current gauge measurements in data-sparse regions without more advanced rainfall instruments. We trained and validated WassDiff on CONUS only, a region with relatively high gauge station density. Deploying WassDiff in regions with sparser gauge density first requires further evaluation in those conditions.\nThis paper focuses on generation quality and does not address improving the inference speed of diffusion models. At the current stage of WassDiff, the generation of long-historical records at a continental or global scale would require substantial computational resources. There are several potential avenues to improve the sampling speed of WassDiff, including reducing the number of iterations in the reverse diffusion process [Salimans and Ho, 2022, Zheng et al., 2023] and using two-step approaches [Mardani et al., 2023].\nIt is our hope that WassDiff will be used by researchers to solve relevant problems in meteorology, hydrology, and other related fields. The principle of WassDiff is applicable to a large family of inverse problems where the calibration of"}, {"title": "Related works", "content": "A Related works\nVarious ML methods have been previously used for precipitation downscaling. Convolutional Neural Networks (CNNs) have shown promise in downscaling precipitation data [Veillette et al., 2020, Rampal et al., 2022, Rodrigues et al., 2018]. However, the deterministic nature of CNNs cannot produce a probability distribution (i.e., ensemble inferences). Without a probabilistic element, CNNs struggle to predict small-scale precipitation details [Ravuri et al., 2021].\nThe stochastic nature of atmospheric physics at km-scale makes the downscaling task inherently probabilistic [Selz and Craig, 2015]. Generative models, such as Generative Adversarial Networks (GANs), have been used in downscaling precipitation [Leinonen et al., 2021, Price and Rasp, 2022, Vosper et al., 2023]. Some earlier work demonstrated downscaling results from artificallly degraded observations using Generative Adversarial Networks (GANs) [Leinonen et al., 2021, Vosper et al., 2023]. However, mapping such artificially downsampled low-resolution input to their original observation is a pure super-resolution task. Downscaling from coarse-grid observations or forecasts is comparably more challenging, requiring bias and error corrections to map between different products. As mentioned in Sec. 1, both Price and Rasp [2022], Harris et al. [2022] demonstrated downscaling global forecasts to 1 km radar precipitation measurements, from 32 and 10 km resolution, respectively, which is considered to be a hard problem than downscaling synthetically downsampled inputs, as bias and error correction is required to downscale forecast inputs. Generally speaking, training GANs pose several challenges, including mode collapse, training instabilities, and difficulty capturing long tails of the distributions [Xiao et al., 2021, Kodali et al., 2017, Salimans et al., 2016].\nRecently, diffusion models have been introduced as an alternative to GANs for their sample diversity and training stability [Ho et al., 2020, Dhariwal and Nichol, 2021]. Both Addison et al. [2022] and Mardani et al. [2023] train their model using traditional score loss. Addison et al. [2022] used a score-based diffusion model [Song and Ermon, 2020] to produce rainfall density in the UK region from vorticity as input, demonstrating the viability of synthesizing rainfall data from other variables. Their model downscales data from 64 km to synthesize rainfall at 8.8 km, but lacks systematic evaluation on model performance. Mardani et al. [2023] used a two-step approach to synthesize radar reflectivity (a variable related to rain rate [Austin, 1987]) conditioned on ERA5 Hersbach et al. [2023] data at 55 km. Their two-step process involves using a deterministic CNN to predict the sample mean, followed by a score-based diffusion model that predicts variance, jointly producing radar reflectivity at 2 km. While the generated radar reflectivity in Mardani et al. [2023] has the realistic texture details for extreme weather events and the appropriate power spectra and distributions, radar reflectivity is still a proxy for rainfall intensity, and it is unclear if those reflectivity outputs can accurately map to rainfall intensity and capture the tail end of the distribution.\nOur work goes one step further in using diffusion models for rainfall downscaling. We propose to use Wasserstein distance regularization (WDR) to augment traditional score loss training objectives, which is novel for diffusion models. The downscaling resolution ratio (CPC at 55 km and ERA5 at 25 km to MRMS at1 km) is higher than all existing work, raising problem complexity. We also focus our analysis on quantifying the performance of generated precipitation samples during extreme rainfall events."}, {"title": "Additional details for sliced Wasserstein distance", "content": "B Additional details for sliced Wasserstein distance\nWe show the pseudo-code for the computation of sliced Wasserstein distance [Bonneel et al., 2015], obtained by projecting high-dimensional vectors to a set of random 1D subplanes and then computes the average projected 1D Wasserstein distances.\nTake a distribution of samples and targets each with shape [m, 1, h, w], where m, h, w refers to the number of samples (in this case, size of a minibatch), height, and width of the images, respectively. We first vectorize the two distributions to obtain matrices A, B \u2208 Rm,d, where d := h \u00d7 w. The sliced Wasserstein distance WS (A, B) is computed via Algorithm 1:\nAlgorithm 1 sliced Wasserstein distance WS (A, B)\nRequire: A, B\u2208 Rm,d, N > 0\nfor i = 1 to n do\nv ~ Uniform(Sd-1)\nai \u2190 A. v\nbi \u2190 B. v\nend for\nreturn W\u2081(ai, bi)"}, {"title": "Data processing and normalization", "content": "C Data processing and normalization\nThe model is trained on a large corpus of precipitation events sampled in the CONUS region from Sept 4, 2016 - Dec 31, 2021. During training, we iterate through the training dates and retrieve and align CPC precipitation, CPC gauge density, selected ERA5 variables, and MRMS precipitation daily aggregates. All data is projected and aligned using MRMS longitude and latitude grid, at approximately 1 km resolution. CPC and MRMS data is bilinearly upsampled at this stage to match MRMS resolution.\nWe randomly sample 256 \u00d7 256 crops in the training dates. On average, the chance of drawing a dry region (i.e., no rainfall) is much higher than a wet region if the selection is purely random, and a training set containing mostly dry regions is not conducive to learning diverse precipitation patterns. Instead, we randomly select coordinates where there is rainfall and propose a random crop centered at this coordinate. The proposed crop is selected if all corresponding CPC pixels are defined (i.e., on CONUS land); otherwise, we repeat the random selection 3 times. A random region (regardless of rainfall and valid pixel) is selected by default after 3 selection attempts.\nCrop selection is followed by data normalization. Both CPC and MRMS data undergo a zero-preserving log transform, \u04efp = log(yp + 1)/cp, where yp denotes the original precipitation data, \u1ef9p denotes the normalized precipitation data, and Cp is a precipitation scaling constant. Here, we use cp = 5 so that most MRMS precipitation values are normalized to approximately [0, 1]. Gauge density and ERA5 variables (except for 2 m temperature) are normalized by dividing by a scaling constant. The scaling constant for gauge density, geopotential, u & v components of winds, and vertical integral of eastwards & northwards water vapor flux are 20, 30000 m, 50ms-1,800 kg m-1 s\u00af\u00b9, respectively. 2 m temperature y2mt is resclaed via \u1ef92mt =\n\nwhere C2mt,min and C2mt,max are 240 and 320 K, respectively. All scaling functions and constants are chosen, such each scalar data (such as temperature and elevation) is approximately scaled to [0, 1], and vector data (wind field and water vapor flux) are scaled to [-1, 1]. Finally, we stack all normalized variables to form a single conditional tensor y \u2208 Rm\u00d7M\u00d7Cin, where m = 256 and Cin = 8."}, {"title": "Verification metrics", "content": "D Verification metrics\nWe provide details about the evaluation metrics used in this paper. Consider x and x to be real and generated precipitation samples, where each pixel represents the daily precipitation rainfall with unit mm/day.\nD.1 Deterministic metrics\nMean absolute error (MAE) MAE is defined as follows:\n$MAE= \\frac{1}{N}\\sum_{i=1}^{N} |x_i - \\hat{x_i}|$(6)\nLower is better for MAE.\nBias Bias is given by\n$Bias=\\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\hat{x_i})$  (7)\nA positive bias means that the model overestimates, on average, and a negative bias means that the model underestimates, on average. A perfectly calibrated output would have zero bias.\nCritical Sucess Index (CSI) CSI is a popular metric in the forecasting community that aims to give a single summary of binary classification performance that rewards both precision and recall. It evaluates whether or not rainfall exceeds a certain threshold t. In this paper, we use t = 10 mm/day. CSI is defined as\n$CSI = \\frac{TP}{TP + FP + FN}$(8)"}, {"title": "Ensemble metrics", "content": "D.2 Ensemble metrics\nContinuous Ranked Probability Score (CRPS) [Gneiting and Raftery, 2007] is a proper scoring rule [Gneiting and Raftery, 2007] for univariate distributions. We use CRPS to evaluate the per-grid-cell marginals of a model's predictive distribution against observations. CRPS is defined as\n$CRPS = E|x - \\hat{x}| - \\frac{1}{2}E|\\hat{x} - \\hat{x'}|$(10)\nwhere x and x' are drawn independently from the perdictive distribution and x is the observation. Lower is better for CRPS."}, {"title": "Precipitation intensity distributions", "content": "E Precipitation intensity distributions"}, {}]}