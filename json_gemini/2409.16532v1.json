{"title": "Graph Pruning Based Spatial and Temporal Graph Convolutional Network with Transfer Learning for Traffic Prediction", "authors": ["Zihao Jing"], "abstract": "With the process of urbanization and the rapid growth of population, the issue of traffic congestion has become an increasingly critical concern. Intelligent transportation systems heavily rely on real-time and precise prediction algorithms to address this problem. While Recurrent Neural Network (RNN) and Graph Convolutional Network (GCN) methods in deep learning have demonstrated high accuracy in predicting road conditions when sufficient data is available, forecasting in road networks with limited data remains a challenging task. This study proposed a novel Spatial-temporal Convolutional Network (TL-GPSTGN) based on graph pruning and transfer learning framework to tackle this issue. Firstly, the essential structure and information of the graph are extracted by analyzing the correlation and information entropy of the road network structure and feature data. By utilizing graph pruning techniques, the adjacency matrix of the graph and the input feature data are processed, resulting in a significant improvement in the model's migration performance. Subsequently, the well-characterized data are inputted into the spatial-temporal graph convolutional network to capture the spatial-temporal relationships and make predictions regarding the road conditions. Furthermore, this study conducts comprehensive testing and validation of the TL-GPSTGN method on real datasets, comparing its prediction performance against other commonly used models under identical conditions. The results demonstrate the exceptional predictive accuracy of TL-GPSTGN on a single dataset, as well as its robust migration performance across different datasets.", "sections": [{"title": "Introduction", "content": "Transportation plays an important role in people's lives. According to a survey in 2019, drivers took an average of 2.22 daily driving trips during 2016-2017 driving approximately 31.5 miles each day [1]. However, with the accelerating process of urbanization, the expanding population size makes the problem of urban traffic congestion more and more serious. Traffic congestion not only affects the daily travel of urban residents, but also brings numerous limitations and challenges to the"}, {"title": "2 Literature Review", "content": "2.1 Methodology Overview\nThe traffic prediction task is an important part of realizing smart transportation. It aims to use algorithms or AI models to predict future traffic flow and congestion"}, {"title": "2.2 Problem Definition", "content": "The traffic forecasting task involves predicting future traffic flows based on historical traffic data. Accurate road condition prediction results are provided through modeling and analytical reasoning. There should be several monitoring points or sensors in a traffic road network that are capable of generating a stable output of road condition characterization data. A piece of raw data Xt at moment t is an n-dimensional vector whose dimension n is the number of sensors in the observed road network. The data generated by each sensor will be continuously mapped to a fixed location in this vector. The sensor will i will record the number of vehicles xt,i that pass through this sensor at time At, and let the number of vehicles that pass through sensor i at a given instant be cnt:\nXti = \\int_{t}^{t+\\Delta t} cnt dt\nXt = (X1, X2,..., X_{t,n})\nD = (X 1, X 2, ..., Xk)T"}, {"title": "3 Methodology", "content": "This section starts with a general overview of the TL-GPSTGN model structure and then describes each of its modules in detail.\n3.1 Model Architecture Overview\nTo solve the traffic prediction problem with insufficient training data, this spatial- temporal graph convolutional network-based transfer learning model (TL-GPSTGN) is constructed. The TL-GPSTGN model consists of the modules of graph pruning processor (GPP), spatial-temporal graph convolutional network (STGCN), and Reductor. Among them, GPP consists of Information Entropy Analyzer (IEA), Graph Pruning (GP) module, and Normalization module, which are used to optimize the input spatial-temporal data. STGCN incorporates the ideas of graph convolutional network and time series modeling, which can effectively capture the relationship between time and space. Compared with the traditional convolutional neural network (CNN) and recurrent neural network (RNN), STGCN is able to deal with non-regular and inhomogeneous spatial-temporal data, which is suitable for coping with complex spatial-temporal structures in road networks [8]. The Reductor module is used to reconstruct the output of the model into traffic flow, i.e., the prediction result, based on the normalization rules. The structure of the model is shown in Fig.1."}, {"title": "3.2 STGCN Module", "content": "Temporal Convolutional Layer (TCL) and Spatial Convolutional Layer (SCL) are two basic and important components of the STGCN model's accepts the spatial-temporal data including the adjacency matrix of the graph and the feature matrix of the nodes and performs spatial convolutional operations on the input node feature data. The neighbor matrix is used to capture the spatial relationship between modestly accepting the feature matrix or the output of SCL to perform the convolution operation on it in the time dimension. The rational pairing of these two modules enables STGCN to combine the ability to process both spatial and temporal information and to effectively capture spatial-temporal relationships and features in graph networks [8]. Two TCLs and one SCL are combined in a \"hamburger\" fashion to form a spatial- temporal convolution module (ST-Conv), while the STGCN consists of several (usually two or three) ST-Conv modules and a data output processing module. The"}, {"title": "3.3 Graph Pruning Processor", "content": "Graph pruning is a technique used to reduce unnecessary connections and edges in a graph [9]. In graph pruning, a more simplified graph is obtained by removing certain edges and nodes from the graph while retaining the main feature structure and information of the graph. It can serve to remove redundant complexity and improve computational efficiency and migration capabilities. The common methods of graph pruning are Threshold-based Pruning, Degree-based Pruning, Centrality-based Pruning, Clustering-based Pruning, etc. Threshold Pruning is to remove edges whose weights are less than the threshold according to the given threshold value. Degree- based Pruning is to remove nodes with lower degrees or to remove weaker connections between nodes. Centrality-based Pruning is to remove nodes or edges whose centrality metrics are lower than the threshold. Clustering-based Pruning is to remove connections between clusters or with low density by clustering algorithms, which categorize the nodes in the graph into different clusters.\nIn traffic prediction, the road network graph has a strong coupling relationship with the feature data, and the nodes of the graph have a one-to-one mapping relationship with the dimensions of the feature data, so Degree-based Pruning is a more applicable method to select nodes and edges that have a greater contribution to the features of the graph as the input data to the model."}, {"title": "3.4 Transfer Learning", "content": "When graphical convolutional networks are applied in real transportation, a large amount of historical data is needed to support the pre-training of the model. Many road networks do not have enough historical data due to underdeveloped informatization and other reasons, thus creating the problem of rapid application of predictive models.\nTransfer learning is a useful method affiliated to machine learning that focuses on storing solution models for existing scenes and exploiting them on other related problems. In the field of traffic prediction, the uniformity of the input data in roads allows transfer learning to play a significant role in it. Models can be trained on a road network with sufficient historical data and rich spatial features to obtain a pre-trained model. This model is then migrated to the target road network and trained a second time using less historical data to quickly obtain a model usable in the target domain [10-11]."}, {"title": "4 Experiments", "content": "In this section, sufficient experiments are designed in this paper to demonstrate the superior performance and migration capability of the TL-GPSTGN model in traffic prediction tasks. First, the dataset, data preprocessing, and BASELINE method will be presented. Then, the model's performance and migration ability on different datasets will be demonstrated.\n4.1 Dataset and Preprocessing\nMETR-LA (METRic for Traffic Flow Prediction in Los Angeles) provides highly accurate traffic flow data from the Los Angeles area. The dataset was provided by the Los Angeles Department of Transportation and the data was collected using Inductive Loop Detectors. The time frame of the dataset covers a one-year period from 2012 to 2013, with traffic flow data sampled at 10-minute intervals. It contains traffic flow data from 207 Inductive Loop Detectors."}, {"title": "4.2 Evaluation Metrics and Baseline", "content": "In the model evaluation in this paper, Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE) are used as the metrics to evaluate the performance of TL-GPSTGN [10].\nHA (Historical Average): A forecast based on the average of historical observations. It assumes that future values are similar to past observations and takes the historical average as the forecast.\nARIMA (Autoregressive Integrated Moving Average): the classical time series forecasting model. It combines the concepts of autoregressive (AR) and moving average (MA) models and takes into account the differencing (Integrated) process of the time series [12].\nFNN (Feedforward Neural Network): a classical artificial neural network model. Models complex nonlinear relationships between inputs and outputs by learning and adjusting connection weights between neurons [13].\nFC-LSTM (Fully-Connected LSTM): a neural network model based on Long Short-Term Memory (LSTM). It captures the long-term dependencies of the time"}, {"title": "4.3 Experiments and Results", "content": "To ensure the uniform standard of the evaluation, all the evaluation tasks are conducted on two machines equipped with RTX4090 graphics cards and 24G video memory, and the whole experiment takes about 72 hours in total. The evaluation tasks are mainly divided into two modules, one is the performance evaluation of TF- GPSTGN model on a single dataset, and the other is the performance evaluation of TL-GPSTGN migration between different datasets. In the single dataset evaluation, three datasets, metr-la, pems-bay, and pemsd7-m, are selected in this paper, and comparative experiments are done with HA, ARIMA, FNN, FC-LSTM, and STGCN under the same conditions to validate the accuracy of the TL-GPSTGN model. In the migration performance evaluation, the STGCN model, which has the best performance in the single dataset evaluation, is selected to do the comparison experiment with TL-GPSTGN. In this task, the two models are pre-trained sufficiently on the metr-la dataset respectively, and then a part of the pems-bay and pemsd7-m datasets are selected respectively for further migration training, and the performance evaluation is conducted on the migrated dataset to get the migration performance of the models.\nTraining parameter settings. The three datasets are divided into the training set, validation set, and test set in the ratio of 7:1.5:1.5 respectively. Early Stopping technique is used, and the maximum value of epoch is set to 200. The length of the predicted historical data sequence is 12 and the prediction intervals are 15 and 30 minutes. Since the pems-bay dataset has a shorter sampling interval of 1 minute, specifically, the input sequence length for the 30-minute prediction task for this dataset is set to 24. The random seed is set to 42, the number of ST-Conv modules in the STGCN structure is set to 2, and the convolution kernel sizes of the SCL and TCL convolution modules in it are set to 3. The batch size is set to 32, the learning rate is set to 0.001, the L2 regularization penalty is used, the weight decay ratio is set to 0.0005, and the optimizer uses Adam.\nIn the single dataset evaluation, the predictions of STGCN and TL-GPSTGN are tested on three datasets against 15 and 30 minutes, respectively, and the corresponding performance metrics are calculated. Then they are compared with the baseline models and the results are shown in the table."}, {"title": "5 Conclusion", "content": "In this paper, a spatial-temporal graph convolutional network model based on transfer learning and graph pruning (TL-GPSTGN) is proposed to address the problem of the lack of historical data in traffic prediction.TL-GPSTGN provides more accurate prediction for a target road network with only a small amount of historical data by migrating the knowledge from the source road network that has sufficient feature"}, {"title": "References", "content": "1. Kim, W., V. Anorve, and B. C. Tefft.: American driving survey, 2014-2017. (2019).\n2. Leduc, G.: Road traffic data: collection methods and applications. Working Papers on\nEnergy, Transport and Climate Change 1.55 (2008): 1-55.\n3. Szostak, D., et al.: Machine learning classification and regression approaches for optical\nnetwork traffic prediction. electronics 10.13 (2021): 1578.\n4. Fu, R., et al.: Using LSTM and GRU neural network methods for traffic flow prediction.\n2016 31st Youth academic annual conference of Chinese association of automation\n(YAC). IEEE, (2016).\n5. Guo, K., et al.: Optimized graph convolution recurrent neural network for traffic\nprediction. IEEE Transactions on Intelligent Transportation Systems 22.2 (2020): 1138-\n1149.\n6. Tedjopurnomo, D. A., et al. A survey on modern deep neural network for traffic\nprediction: trends, methods and challenges. IEEE Transactions on Knowledge and Data\nEngineering 34.4 (2020): 1544-1561.\n7. Nagy, A. M., and Vilmos, S.: Survey on traffic prediction in smart cities. Pervasive and\nMobile Computing 50 (2018): 148-163.\n8. Yu, B., et al.: Spatio-temporal graph convolutional networks: a deep learning framework\nfor traffic forecasting. arXiv preprint arXiv:1709.04875 (2017).\n9. Akiba, T., et al.: Fast shortest-path distance queries on road networks by pruned highway\nlabeling. 2014 Proceedings of the sixteenth workshop on algorithm engineering and\nexperiments (ALENEX). Society for Industrial and Applied Mathematics, 2014.\n10. Yao, Z. X., et al.: Transfer Learning With Spatial-Temporal Graph Convolutional Network\nfor Traffic Prediction. IEEE Transactions on Intelligent Transportation Systems (2023)."}, {"title": null, "content": "11. Mallick, T., et al.: Transfer learning with graph neural networks for short-term highway\ntraffic forecasting. 2020 25th International Conference on Pattern Recognition (ICPR).\nIEEE, 2021.\n12. Kumar, S. V., and Lelitha V.: Short-term traffic flow prediction using seasonal ARIMA\nmodel with limited input data. European Transport Research Review 7.3 (2015): 1-9.\n13. Oliveira, T. P., et al.: Computer network traffic prediction: a comparison between\ntraditional and deep learning neural networks. International Journal of Big Data\nIntelligence 3.1 (2016): 28-37.\n14. Zhang, Z., et al.: Human action recognition using convolutional LSTM and fully-\nconnected LSTM with different attentions. Neurocomputing 410 (2020): 304-316."}]}