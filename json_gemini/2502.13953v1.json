{"title": "Neurosymbolic artificial intelligence via large language models and coherence-driven inference", "authors": ["Steve Huntsman", "Jewell Thomas"], "abstract": "We devise an algorithm to generate sets of propositions that objectively instantiate graphs that support coherence-driven inference. We then benchmark the ability of large language models (LLMs) to reconstruct coherence graphs from (a straightforward transformation of) propositions expressed in natural language, with promising results from a single prompt to models optimized for reasoning. Combining coherence-driven inference with consistency evaluations by neural models may advance the state of the art in machine cognition.", "sections": [{"title": "1. Introduction", "content": "Classical coherence-driven inference (CDI) (Thagard and Verbeurgt, 1998; Thagard, 2002; Blokpoel\nand van Rooij, 2024) models many forms of cognition as solving a constraint satisfaction prob-\nlem. In this approach, propositions and their consistency relations are encoded in a weighted graph\nGas in Figure 1. Up to an irrelevant constant that varies among formulations, the coherence of\nU \u2286 V(G) is \u2013 \\Sigma_{u \\in U} \\Sigma_{v \\in U} A_{uv}, where A is the weighted adjacency matrix of G. (As is common\nin the literature, we often assume A_{uv} \\in {\\pm1} in this paper; our benchmarking approach handles\nthis case naturally.) The problem of maximizing coherence is thus an instance for the matrix \u2013A of\nthe APX-complete MAX-CUT problem (Khot et al., 2007; Moore and Mertens, 2011; G\u00e4rtner and\nMatousek, 2012; Lee and Xu, 2021). The objective is to cut the most negative weights in G with a\nbipartition into accepted (= estimated true) and rejected (= estimated false) propositions.\nCDI is deeply informed by cognitive science, and experimentally validated by psychological\ncase studies, including assessments of legal reasoning (Holyoak and Simon, 1999; Simon, 2004).\nIt is a computationally credible model for causal inference (Thagard, 2004) suited for making de-\ncisions about ill-structured problems (Frigotto and Rossi, 2015). Other illustrations of its capacity\nfor high-level reasoning include reaching deliberative consensus (Joseph and Prakken, 2009) and\nsolving normative inconsistencies (Criado et al., 2016), as well as many complementary examples\ncited in Blokpoel and van Rooij (2024). CDI can also explicitly incorporate ethical considerations\nand provide explanations of its reasoning (Yilmaz et al., 2017).\nHowever, mechanisms for automatically generating coherence graphs from natural language\ndata have not been developed: coherence graphs have almost always been constructed manually. (A"}, {"title": "2. Modeling coherence graphs", "content": "Classical CDI focuses on signed graphs, which approximate more elaborate constructions such as\nweighted simplicial complexes that may be appropriate for modeling and computing coherence in\nfull generality (for which see Huntsman et al. (2024) and \u00a7A.2).\nDefinition 1 Recall that a signed graph Go = (V, E, \u03c3) is an undirected graph G = (V, E) aug-\nmented with a sign map \u03c3 : E \u2192 {\\pm1}. A coherence graph is a signed graph whose vertices are\npropositions. Two propositions v and w are dependent in Go if (v, w) \u2208 E (in particular, v and\nw are assumed to be distinct). Two dependent propositions are consistent for \u03c3 (resp., inconsistent\nfor \u03c3) if \u03c3(v, w) = +1 (resp., \u22121). The left panel of Figure 2 shows an example."}, {"title": "2.1. An algorithm for modeling coherence graphs", "content": "Here we detail how to construct a set of propositions that model a coherence graph.\nDefinition 3 A clique edge cover of a graph G (Erd\u0151s et al., 1966; Gross et al., 2018; Conte et al.,\n2020) is a set of cliques in G whose edges cover E(G). A star forest decomposition of G (Akiyama\nand Kano, 1985; Kottarathil et al., 2024) is a partition of E(G) into star forests, i.e., forests whose\nconnected components each have only a single vertex of degree greater than 1: see Figure 3.\nNote that the sizes of clique edge covers and star forest decompositions are saturated below by\nthe intersection number and star arboricity, respectively.\nTheorem 4 Given a coherence graph Go = (V, E, \u03c3), Algorithm 1 produces V\u2032 = G\uff61.\nProof It suffices to show that \u03b5(v', w') = \u03c3\u03bf(\u03b9(v'), \u03b9(w')) via a case analysis.\nFirst, suppose that \u03c3\u03bf(\u03b9(\u03bd'), \u03b9(w')) = 1: here, we need to show that v' and w' are consistent.\nThe respective formulas \u03c6(\u03b9(v')) and \u03c6(\u03b9(w')) only share common variables in clauses of the form\n(qj \u21d2 p(v')) and (qj \u21d2 p(w')). These formulas and their natural language expressions are both\nconsistent unless p(v') = \u00acp(w'), which can only occur if \u03c3\u03bf(\u03b9(v'), \u03b9(w')) = \u22121, a contradiction."}, {"title": "2.2. Benchmarking coherence", "content": "Because computing coherence amounts to solving MAX-CUT (or MAX-SAT more generally as in\n\u00a7A.2), benchmarking CDI is mainly a question of fidelity of coherence graph reconstruction. Run-\ntime and approximation performance of combinatorial optimization algorithms in \u00a7A may become\nimportant, but at scales considered here, exact solutions are always computationally feasible."}, {"title": "3. Experimental setup", "content": "We include proprietary and open-source models intentionally designed for reasoning in our evalua-\ntion. We refer to o1-mini (Jaech et al., 2024), QwQ-32B (Qwen, 2024), and Sky-T1-32B (No-\nvaSky, 2025) as large reasoning models (LRMs), following the phrasing of Valmeekam et al. (2024)\nto describe models designed to generate long chains of thought at inference time. These models have\nhigh latency and inference costs (Abdin et al., 2024). We consider phi-4 (Abdin et al., 2024) a\nsmall language model (SLM). We refer to the other models in our evaluation by the more generic\nterm LLM: gemini-2.0-flash-exp (DeepMind, 2024), claude-3.5-sonnet(Anthropic,\n2024), gpt-4o (Hurst et al., 2024), Llama-3.3-70B (Meta, 2024), and gemini-1.5-pro\n(Pichai and Hassabis, 2024). For all models, we performed post-processing on outputs to extract\nstructured data for evaluation."}, {"title": "3.1. Adding uncertainty to propositions", "content": "To evaluate model judgments of consistency under uncertainty, we borrow from Ragin (2006). We\nintroduce uncertainty to p or \u00acp by sampling from triangular fuzzy membership functions defined\nover the unit interval, with 1 and 0 respectively corresponding to p and \u00acp. After adding uncertainty,\na given p-assignment is syntactically represented as something like 0.619 * p, while a given p\nassignment is syntactically represented as something like 0.346 *\u00acp. That is, we indicate uncertainty\nas in the right panels of Figures 4 and 5, with results in Table 1: meanwhile, the prompt in \u00a7G\nechoes this construction. With p \u2190 a * p and \u00acp \u2190 a\u00ac * p we delineate three uncertainty regimes.\nThe low regime has a \u2208 [0.75, 1] and a\u00ac \u2208 [0, 0.25]; the medium regime has a \u2208 [0.625, 0.75]\nand a\u00ac \u2208 [0.25, 0.375], and the high regime has a \u2208 [0.5, 0.625] and a\u00ac \u2208 [0.375, 0.5].\nEncoding numerical uncertainty in natural language in a way that ensures accurate interpretation\nis complicated by individual differences in interpretation related to terms such as \u201capproximately,\"\n\u201ccertainly,\u201d \u201cabout,\u201d \u201cexactly,\u201d etc. (Krisper et al., 2019; Ferson et al., 2015). This presents a\nchallenge for, e.g., communicating risks related to climate change, risks of developing complications\nfrom medical treatment, or the likelihood of a given geopolitical event in the future (DNI, 2015).\nThe fuzzy set method above encodes diverse qualitative statements with a consistent formalism, and\nis directly relevant for use with words of estimative probability (DNI, 2015; Kachynskyi, 2019)."}, {"title": "3.2. Benchmark generation", "content": "To instantiate our benchmark, we sample coherence graphs from an Erd\u0151s-R\u00e9nyi (ER) distribu-\ntion. We ensure that each sample graph is fully connected by joining sampled graphs to a minimum\nspanning tree generated for a complete graph of equivalent size with random edge weights.\nWe generate 76 graphs with |V| \u2208 {5, ..., 23} and tune the ER sampling parameters to target\ntwo regimes of edge density := |E| / (\\binom{|V|}{2}): sparse has a median edge density of 0.202 and dense\nhas a median edge density of 0.734."}, {"title": "3.3. Prompts", "content": "We use a common prompt structure shown in \u00a7G that a) establishes the consistency reasoning task,\nb) describes the variables and properties relevant for evaluating a set of propositions, c) establishes\nfuzzy membership thresholds for properties and d) embeds propositions for a given problem."}, {"title": "4. Results", "content": "Model performance varies considerably, with o1-mini, claude-3.5-sonnet and QwQ-32B\noutperforming the other models for both sparse and dense problems: see Figure 6."}, {"title": "4.2. LLMs successfully infer synthetic coherence graphs under uncertainty", "content": "Table 1 shows that introducing uncertainty does not degrade graph reconstruction fidelity.\nIn Figure 7, we show how recursively passing an inferred uncertain coherence graph to o1-mini\nand prompting it to assign weights reflective of the level of uncertainty in property assignments can\nyield a weighted coherence graph with appropriate edge weights (less certain assignments yield\nsmaller magnitude weights; more certain assignments yield larger magnitude weights)."}, {"title": "4.3. Minor post-processing is sometimes necessary to handle obvious reconstruction errors", "content": "We noted four general types of reconstruction errors. First, some reconstructed graphs do not in-\nclude a given proposition seen in the prompt. We observed this sporadically in all models. Sec-\nond, we noticed some instances with Gemini models where the reconstructed graph contains nodes\nnamed, for instance, \"Proposition(a)\u201d instead of a or \u201c(a)\u201d instead of a. We noticed instances where\nQwQ incorrectly capitalized proposition names, for instance, substituting \"A\" for \"a\". We correct\nthese first three error types in post-processing before evaluation.\nFinally, we observed that some models hallucinate extra propositions in the reconstructed graph.\nOut of 608 inference attempts, gemini-2.0-flash-exp hallucinates on 10 inference attempts,\ngpt-4o on 5, gemini-1.5-pro on 4, and Sky-T1-32B on 1. We do not correct this type of\nerror with post-processing; we instead eliminate these inference attempts from evaluation for these\nmodels since these hallucinations can be easily detected at runtime."}, {"title": "5. Conclusion", "content": "CDI provides a good model for many forms of cognition, including perception and planning. Com-\nbining CDI with consistency evaluations by neural models may lead to advancements in the state\nof the art in these domains. Moreover, our results indicate that it is now feasible to computation-\nally instantiate a coherence theory of truth (Young, 2024). By hard-coding conclusively established\npropositions, this theory can be anchored in a correspondence theory of truth (David, 2022)."}, {"title": "Appendix A. Coherence can be computed in different ways", "content": ""}, {"title": "A.1. Classical coherence is equivalent to 2-MAX-XORSAT and to sparse approximation for 2-XORSAT", "content": "There are a number of algorithms for computing coherence classically. Besides a brute force solu-\ntion to the MAX-CUT problem for a coherence graph Go, there are also greedy stochastic, simulated\nannealing, and semidefinite programming approximations (Thagard and Verbeurgt, 1998; G\u00e4rtner\nand Matousek, 2012). Historically, the dominant approach is a dynamical neural (\u201cconnectionist\u201d)Algorithm discussed in Thagard (2002). However, implementations are sufficiently outdated or hard\nto work with that an adaptation based on an Ising model has recently been developed (Maier et al.,\n2023).\nWe proceed to outline two computational perspectives on coherence that to our knowledge have\nnot previously been considered explicitly, though the second was discussed at the level of prose\nin Huntsman et al. (2024). Given a coherence graph Go, the consistency equation \u03c3(v, w) = 1 corresponds to an equation of the form xv + Xw = 0 over the Boolean field F2, and also to thepropositonal clause v \u21d4 w. Meanwhile, the inconsistency equation \u03c3(v, w) = \u22121 corresponds to xv + Xw = 1, and also to the propositional clause v \u2295 w, where \u2295 = XOR. Therefore, wecan repackage Go into the linear equation Bx = c, where B is the incidence matrix of Go, orequivalently the biadjacency matrix of the factor graph of the 2-XORSAT/2-Affine-SAT (Roy, 2006; Mezard and Montanari, 2009) formula obtained from the clauses indicated just above. For example, the coherence graph in Figure 2 corresponds to the linear equation"}, {"title": "A.2. A general approach: weighted MAX-SAT", "content": "We sketch how to represent higher-order (in)consistency relationships such as trilemmas. A con-\nceptually simple but computationally involved general approach is as follows:\n\u2022 for each ordered pair of dependent claims, rate the consistency of the second given the first,\nand associate this to a weight for an implication term;\n\u2022 for each ordered triple of dependent claims, rate the consistency of the second and third given\nthe first, and separately the consistency of the third given the first and second: associate these\nwith corresponding implication terms;\n\u2022 etc., truncating this hierarchy as desired/practical.\nNote that this requires a clique-finding algorithm such as that of Chiba and Nishizeki (1985), and\nthat each unordered tuple corresponds to several ordered tuples, ensuring symmetry.\nWhile this approach appears to adequately generalize the notion of a coherence graph into\nwhat amounts to a weighted simplicial complex\u2014i.e., a weighted hypergraph containing all sub-\nhyperedges (Rosiak, 2022)\u2014it is not yet suitable for practical MAX-SAT solvers of any sort. These\nonly address weighted CNF-SAT problems, while common translations into CNF-SAT do not pre-\nserve weights correctly. Therefore, applying a MAX-SAT solver would generally require (imple-\nmenting and) applying a specialized transformation of the sort detailed in Li et al. (2022), which to\nour knowledge has no public implementation.\nOnce a coherence problem is properly transformed into CNF-SAT, there is an interesting alter-\nnative to weighted MAX-SAT solvers. An efficient probabilistic algorithm for weighted MAX-SAT\ndiscussed in Vazirani (2001) provides a natural probabilistic interpretation that is certain to be useful\nin many if not most practical situations. For example, a proposition with acceptance probability near\n0.5 may indicate a need for\u2014and even drive the collection of\u2014additional data for incorporation into\nthe relevant structure.\nThe general approach to representing and solving \u201chigher-order\u201d coherence problems outlined\njust above was suggested by Huntsman et al. (2024), who were unaware of prior work on coherence\nper se. The underlying motivation was that a sheaf ought to represent consistency data. Briefly,"}, {"title": "Appendix B. A case study comparing human and LLM consistency ratings", "content": "There is additional evidence that LLMs can reliably gauge propositional (in)consistency (Huntsman\net al., 2024; Kumar and Roussinov, 2024). However, we are not aware of any assessment of per-\nformance relative to humans. Here, we outline a case study performed in summer 2024 in which\nChatGPT 4 demonstrated superhuman performance at gauging (in)consistency.\nIn Thagard (1992), a coherence graph modeled a decision facing the captain of the cruiser USS\nVincennes on 3 July 1988: was radar track 4131 taking off from the Iranian civilian-military airfield\nat Bandar Abbas a civilian aircraft, or a hostile F-14 preparing to attack? The coherence graph\nincluded \"positive evidence\" propositions (labeled E*) copied almost verbatim from \u00a7III.C.1.b of\nthe investigation report (Fogarty, 1988) along with a few of their negations (labeled NE*) and hy-\npothetical propositions that the track was attacking (labeled A*) or commercial (labeled C*). As\nis still common today for analyses using CDI, the edge set and weights (here, simply signs) were\nconstructed by hand.\nTo focus on ChatGPT 4's performance in evaluating (in)consistency, we considered the same\nedge set as the manually-constructed coherence graph, i.e., we neglected any considerations of\ndependence.\nIt is important to note here that (the nontrivial connected component of) the coherence\ngraph has |V| = 21 and |E| = 36, so its edge density is 36/210 = 0.17. In other\nwords, this example is in exactly the same regime as the larger and sparser bench-\nmark graphs discussed in the main text.\nFor each edge, we asked ChatGPT 4 to rate the consistency of the corresponding pairs of propo-\nsitions 10 times using a variant of the prompt in Huntsman et al. (2024) that included an extract\nfrom the executive summary of Fogarty (1988) as background information. The results are shown\nin Figures 8 and 9. Supporting data and scripts are in Huntsman (2024).\nA bit of introspection and common sense reveals that for the largest discrepancies between the\nmedian LLM rating and the human rating, the median LLM rating is more reasonable in each event.\nConsider the four largest discrepancies, listed in order of their appearance in Figure 9:\nA2-C2: These are obviously consistent, so ChatGPT 4's rating is better than the rating in Tha-\ngard (1992).\nA2 is \"Track 4131 was an F-14.\"\nC2 is \"Track 4131 was taking off.\"\nA3-E3: Examination of outputs shows that ChatGPT 4 considered plausible technical failures\nand misunderstandings. In light of this, it is fair to conclude that ChatGPT 4's rating is\nbetter than the rating in Thagard (1992)."}, {"title": "Appendix C. ANOVA for micro F\u2081", "content": "The two-way ANOVA for micro F\u2081 in Table 2 shows significant effects."}, {"title": "Appendix D. Benchmark generation parameters can be altered to synthesize problem sets with desired characteristics", "content": "Figure 10 demonstrates how benchmark generation parameters lead to increasing numbers of vari-\nables in the resulting synthetic problem sets as graph sizes increase. The top row shows data for\nsmall graphs (5-11 propositions), middle row: medium graphs (13-17 propositions), bottom row:\nlarge graphs (19-23 propositions). In general, the degenerate edge clique processing method\nand the partition method (first and third subcolumns in each panel) lead to more variables and\nfewer properties than the percolation method (middle column of each panel)."}, {"title": "Appendix E. Inferring logical entailment with ModernBERT fine-tuned for NLI", "content": "We performed a preliminary experiment to test whether we could directly identify either a) rele-\nvance (defined as two propositions sharing a single variable) or b) consistency directly from white\nbox LLM embeddings or from a number of simple quantifications of inter-token attention in the"}, {"title": "Appendix F. Characteristics of synthetic coherence graphs included in our benchmark experiment", "content": "In Table 3, we show that our experiment includes coherence graphs ranging in size from 5 to 23\npropositions. We note that our requirement that all synthetic coherence graphs be connected makes"}, {"title": "Appendix G. Prompt template for global consistency inference under uncertainty", "content": "For the input set of propositions, identify which propositions are logically consistent (i.e., can co-\nexist without contradiction). Construct a networkx graph where inconsistent edges are weight 1 and\nconsistent edges are weight 0. If two vertices do not involve the same variables, do not create an\nedge between them.\nReturn solely the edge list with proposition names for vertices. i.e., return responses in this\nformat:\n[('b', 'c', 0),\n('b', 'e', 0),\n('c', 'd', 0),\n('c', 'e', 0)]"}, {"title": "Appendix H. Fidelity of the reconstruction of the graph measured by the L\u00b9 norm normalized by graph size", "content": "Figure 12 shows that o1-mini, claude-3.5-sonnet and QwQ-32B-Preview out perform\nall other models on sparse problems if we characterize reconstruction error using the measure of\nadjacency matrix similarity described in \u00a72.2."}]}