{"title": "Hybrid-Generative Diffusion Models for Attack-Oriented Twin Migration in Vehicular Metaverses", "authors": ["Yingkai Kang", "Jinbo Wen", "Jiawen Kang", "Tao Zhang", "Hongyang Du", "Dusit Niyato", "Rong Yu", "Shengli Xie"], "abstract": "The vehicular metaverse is envisioned as a blended immersive domain that promises to bring revolutionary changes to the automotive industry. As a core component of vehicular metaverses, Vehicle Twins (VTs) are digital twins that cover the entire life cycle of vehicles, providing immersive virtual services for Vehicular Metaverse Users (VMUs). Vehicles with limited resources offload the computationally intensive tasks of constructing and updating VTs to edge servers and migrate VTs between these servers, ensuring seamless and immersive experiences for VMUs. However, the high mobility of vehicles, uneven deployment of edge servers, and potential security threats pose challenges to achieving efficient and reliable VT migrations. To address these issues, we propose a secure and reliable VT migration framework in vehicular metaverses. Specifically, we design a two-layer trust evaluation model to comprehensively evaluate the reputation value of edge servers in the network communication and interaction layers. Then, we model the VT migration problem as a partially observable Markov decision process and design a hybrid-Generative Diffusion Model (GDM) algorithm based on deep reinforcement learning to generate optimal migration decisions by taking hybrid actions (i.e., continuous actions and discrete actions). Numerical results demonstrate that the hybrid-GDM algorithm outperforms the baseline algorithms, showing strong adaptability in various settings and highlighting the potential of the hybrid-GDM algorithm for addressing various optimization issues in vehicular metaverses.", "sections": [{"title": "I. INTRODUCTION", "content": "THE vehicular metaverse is a virtual space that operates parallel to the physical world [1]. It seamlessly integrates the physical and virtual worlds through technologies such as eXtended Reality (XR), Artificial Intelligence (AI), and Digital Twin (DT) technology [2], providing Vehicular Metaverse Users (VMUs) with an immersive experience, that is expected to bring revolutionary changes to the automotive industry [3]. For example, the Augmented Reality (AR) head- up display solution uses AR technology to project important information such as navigation information, traffic signs, and driving routes directly onto the windshield, allowing the driver to obtain key information without diverting his or her gaze. This seamless information integration improves driving safety and significantly reduces the cognitive load of drivers. Vehicle Twin (VT) is a key technology in the vehicular metaverse [4], enabling real-time monitoring and management of vehicles by creating high-precision digital replicas that cover the entire vehicle life cycle [1]. VTs synchronize real-time vehicle status and traffic conditions from the physical space to the virtual space, enabling the vehicle to operate in a dynamic virtual environment [5]. Vehicles can provide VMUs with various metaverse services through VTs, such as allowing VMUs to experience virtual travel in the form of an avatar. Constructing and updating VTs require substantial comput- ing and storage resources. Due to the limitations in local computing resources of vehicles [6], computation-intensive tasks for VT construction and update have to be offloaded to edge servers. However, maintaining service stability is challenging due to the high vehicular mobility and the uneven distribution of edge servers. Hence, VT migrations are con- ducted from the current edge servers to other edge servers [7], which ensures seamless virtual experiences for VMUs. To reduce the load pressure on the current edge servers, vehicles adopt a pre-migration strategy to pre-migrate part of VT tasks [8], thereby effectively utilizing computing resources, reducing data processing delays, and ensuring a seamless and high-quality user experience. Considering that the vehicular metaverse will integrate 6G technology to achieve space-air- ground-sea integrated networks [9], satellites can be used to supplement the computing power of RoadSide Units (RSUs). Unfortunately, there are security risks during the VT migra- tion process. For example, attackers launch Distributed Denial of Service (DDoS) attacks on the edge servers to paralyze the VT migration or obtain the data uploaded by vehicles through the Co-resident attack [10], [11]. To ensure that vehicles migrate VTs to reliable edge servers, the reputation value of edge servers needs to be evaluated through trust evaluation methods. Most trust evaluation methods are based on user re- views in DT migration scenarios, among which the subjective logic model is the most common [1], [12]. Nevertheless, the traditional subjective logic model only quantifies the reputation value of edge servers according to the evaluation of VMUs, which makes the reputation evaluation of edge servers not objective enough. Besides, there may be malicious evaluators among VMUs, which may damage the reliability of reputation evaluation. To address the above challenges, we propose a secure and reliable VT migration framework in vehicular metaverses. Specifically, we design a two-layer trust evaluation model to compute the reputation values of edge servers. This model ensures the security of VT migrations while safeguarding the immersive experience for VMUs. Considering that the VT migration problem is NP-hard [8], and traditional algorithms struggle to find optimal solutions within an acceptable time frame, we propose a hybrid-GDM algorithm based on Deep Reinforcement Learning (DRL), which utilizes a diffusion model to generate hybrid actions (i.e., continuous actions and discrete actions), thereby generating an optimal migration strategy for vehicles. The main contributions of this paper are summarized as follows: \u2022 To provide VMUs with immersive experiences, we pro- pose a novel VT migration framework with high security and reliability. In the VT migration framework, vehicles select the appropriate and reliable edge servers (e.g., satellites and RSUs) to achieve efficient and reliable VT migrations, enabling real-time updates of VTs within the vehicular metaverse. \u2022 Considering the potential security threats of edge servers, we propose a two-layer trust evaluation model. At the network communication layer, the reputation value of the edge server is evaluated based on its historical defense data and performance in detection tasks. In the interaction layer, the reputation value of an edge server is evaluated based on the interaction evaluation of the edge server by VMUs. By integrating the reputation values of the edge server at the network communication layer and interaction layer, the overall credibility of the edge server can be comprehensively quantified. \u2022 To effectively identify the optimal VT migration strategy, we first model the VT migration decision problem as a Partially Observable Markov Decision Process (POMDP). Then, we propose the hybrid-GDM algorithm, which combines the diffusion model with advanced DRL algo- rithms to enhance the optimization potential. In previous work, GDMs can only generate continuous actions [13] or discrete actions [14], while the hybrid-GDM algorithm is designed to generate hybrid actions to effectively optimize the migration strategy. The rest of the paper is organized as follows. Section II summarizes the related work. System overview is introduced in Section III. The VT migration optimization problem formula- tion is described in Section IV. Section V describes a scheme for making VT migration decisions using the proposed hybrid- GDM algorithm. Section VI demonstrates the evaluation of multiple performances. Section VII concludes this paper."}, {"title": "II. RELATED WORK", "content": "A. Vehicular Metaverse Neal Stephenson first depicted the concept of the metaverse in his science fiction novel Snow Crash in 1992 [5]. The metaverse is a digital world constructed by the integration of Internet and network technologies along with XR, aiming at simulating and enhancing interactions and experiences in real life [2]. The authors in [15] discussed a novel distributed metaverse architecture and the foundational technologies of the metaverse, highlighting key issues in security and privacy protection. In [16], the authors defined Vetaverse as a future continuum between the vehicles industry and metaverses, envisioning it as the DTs of intelligent transportation systems. Most metaverse services are computationally intensive [17]. In [18], the authors optimized the allocation of computing re- sources in vehicular metaverses through an intelligent schedul- ing algorithm, thereby improving the performance and user experience of AR applications. The authors in [5] proposed a contract model based on the migration task age to incentivize RSUs to provide bandwidth resources and ensure the continu- ity and service effectiveness of the VTs migration in the ve- hicular metaverse. The author in [8] proposed a framework for optimizing VTs migration using real-time trajectory prediction and multi-agent DRL, aimed at enhancing user immersion in the vehicular metaverse and reducing resource consumption. However, existing work rarely considers the security issues during VT migration in the vehicular metaverse. B. Digital Twin Migration Virtual machine migration refers to transferring a virtual machine between different physical hardware units, and has been studied in detail in [19]. For example, the authors in [20] introduced the dynamic virtual machine migration scheduling strategy, which significantly reduces computing service latency. Some recent studies have introduced the DT to optimize the migration process. DTs are the digital replica that covers the life cycle of their physical counterparts, i.e., Physical Twin, such as a physical object, process, or system [21]. In [22], the authors introduced a wireless DT edge network model leveraging DRL, aiming to effectively reduce DT migration delay. The authors in [7] optimized the VT migration framework to address the high vehicular mobility and the unpredictable load on edge servers. The authors in [23] proposed a tiny machine learning-based Stackelberg game framework to achieve efficient DT migration in the emerging paradigm of the UAV metaverse through a tiny MADRL algorithm to address the challenges of UAV dynamic mobility and limited communication coverage of ground base stations. However, existing work does not consider the impact of potential security threats from edge servers on users during the VT migration. C. Generative Diffusion Models As an emerging GAI technology, GDMs are widely used in various fields such as image and video generation [24] and molecular design [25] due to their powerful content"}, {"title": "III. SECURE AND RELIABLE VEHICLE TWIN MIGRATION FRAMEWORK", "content": "In this section, we introduce the proposed framework in ve- hicular metaverses, including the VT migration model, attack models, the two-layer trust evaluation model, and utility func- tions. Fig. 1 demonstrates that each vehicle will migrate the VT (e.g., avatar) to an edge server with a good reputation value for updates in each time slot, and some of VTs update tasks are pre-migrated to the subsequent edge servers with a good rep- utation for processing (i.e., the pre-migration process). After the edge servers complete the update of the VTs, they send the results back to the vehicles. In the vehicular metaverse, there are multiple vehicles and multiple edge servers, where the vehicle set is represented as $V = \\{1, . . ., v..., V\\}$ and the edge server set is expressed as $S = \\{1, . . ., s, . . ., S\\}$. Let $s_p$ represent the edge server where the vehicle pre-migration VT task arrives, $L_{max}$ represent the maximum load capacity of the edge server $s$, $Room_s$ represent the communication coverage of the edge server $s$, and $c_s$ represent the computing capability of the edge server $s$. Time is divided into discrete time slots $T = \\{1, ...,t,...,T\\}$ [28]. A. Migration Model Initially, the delay from migrating VTs to an edge server $s$ (e.g., an RSU or a satellite) is calculated. Let $P_s = (x_s, y_s, z_s)$ represent the spatial coordinate of the edge server $s$, and $P_v(t) = (x_v(t), y_v(t), z_v(t))$ represent the spatial coordinate of vehicle $v$ at time slot $t$. Thus, the Euclidean distance between the edge server $s$ and the vehicle $v$ at time slot $t$ can be calculated as\n$P_{v,s}(t) = \\sqrt{[x_s - x_v(t)]^2 + [y_s - y_v(t)]^2 + [z_s - z_v(t)]^2}.$\n(1)\nThe propagation model of the link between the edge server and the vehicle consists of Line-of-Sight (LoS) and Non-Line- of-Sight (NLOS) channels [29]. As vehicles move, their wire- less communication channels with edge servers will change. Considering the uniformity of the wireless transmission chan- nels [8], both uplink and downlink, the path loss channel gain [7] for the link between the vehicle $v$ and the edge server $s$ can be calculated as\n$h_{v,s}(t) = \\begin{cases} \\frac{C}{\\left[A_{r s u} P_{v, s}(t)\\right]^2}, s \\text { is RSU, } \\\n\\frac{C}{\\left(A_{l o s}+A_{n l o s}\\right)\\left[P_{v, s}(t)\\right]^2}, s \\text { is satellite. }\\end{cases}$\n(2)"}, {"title": "Here, $A_{r s u}, A_{l o s},$ and $A_{n l o s}$ represent the gain for the RSU channel, LoS channel, and NLoS channel, respectively, $c$ is the speed of light, and $f$ is the carrier frequency. In the wireless communication scenario, the transmission delay generated when the vehicle $v$ sends the VT task to the edge server $s$ is determined by the uplink transmission rate, which can be calculated as\n$R_{v s}^{u p}(t)=B^{u p} \\log _2\\left[1+\\frac{P_v h_{v, s}(t)}{\\sigma^2}\\right],$\n(3)\nwhere $B^{u p}$ is the uplink bandwidth, $p_v$ is the transmission power of the vehicle $v$, and $\\sigma^2$ is additive Gaussian white noise at the vehicle $v$. When VMUs require vehicular services, the vehicle will offload the VT task $D^{u p}$ to the edge server currently serving. Thus, the uplink transmission delay caused by migrating the VT to the edge server $s$ can be calculated as $T_{v s}^{u p}(t)=\\frac{D_{v s}^{u p}(t)}{C_s}$. After the VT task is offloaded to the edge server, it must wait for the edge server to process it. This queuing time depends on the current load $L_s(t)$ and computing capability $C_s$ of the edge server $s$. Hence, the queuing delay can be expressed as $T_{que}^s(t) = \\frac{L_s(t)}{C_s}$. To ensure a seamless experience for VMUs, vehicle $v$ can pre-migrate some part of VT tasks from the current edge server $s$ to the edge server $s_p$, and the VT tasks are pre-migrated from the current server $s$ to the pre-migration server $s_p$ through entity links between edge servers. Consequently, the edge server $s_p$ can process VT tasks simultaneously with the current server $s$, thereby optimizing resource allocation and utilization. We define the proportion of pre-migrated tasks as $K_{pre}(t) \\in [0,1]$. The physical link bandwidth between these servers is defined as $B_{s,s_p}$. Thus, the delay caused by the pre-migration part of the VT task can be calculated as\n$T_{s, s_p}^{m i g}(t)=\\frac{D_{s, s_p}^{m i g}(t)}{B_{s, s_p}},$\n(4)\nwhere $D_{s, s_p}^{m i g}(t) = K_{pre}(t)D_{t a s k}(t)$ is the total size of pre- migration tasks and $D_{t a s k}(t)$ is the task size that needs to be processed by the edge server $s$. After other tasks are processed, the edge server handles the VT tasks of vehicle $v$. The delay in processing from the current edge server $s$ receiving a task request to completing the tasks is calculated as\n$T_{pro}^s(t) = T_{que}^s(t) + \\frac{e_v(D_{t a s k}(t) - D_{s, s_p}^{m i g}(t))}{C_s}$\n(5)\nwhere $e_v$ denotes the number of GPU cycles needed to process a unit of data from vehicle $v$. For the edge server $s_p$, the processing delay of the pre-migration server $s_p$ can also be calculated as\n$T_{pro}^{s_p}(t) = T_{s, s_p}^{m i g}(t) + T_{que}^{s_p}(t) + \\frac{e_v D_{s, s_p}^{m i g}(t)}{C_{s p}}.$\n(6)\nSince the current edge server $s$ and the pre-migration server $s_p$ process VT tasks simultaneously, the delay of this process can be expressed as\n$T_{pro}(t) = m a x\\{T_{pro}^s(t), T_{pro}^{s p}(t)\\}$.\n(7)\nIn addition to offloading VT tasks, vehicles may receive results (e.g., AR navigation routes) from different edge servers processing VT tasks. Specifically, vehicle $v$ will offload the VT task to the edge server $s$ and pre-migrate part of the VT task to the edge server $s_p$ based on the migration deci- sion. When edge servers $s$ and $s_p$ finish processing the VT task, the results will be returned to the vehicle $v$. Similar to the uplink rate, the downlink rate of the edge server $s$ returning the processed results to the vehicle $v$ is calculated as $R_{v s}^{d o w n}(t) = B^{d o w n} \\log _2[1 + \\frac{P_v h_{v, s}(t)}{\\sigma^2}]$. Thus, the delay experienced by vehicle $v$ when downloading the VT task results can be calculated as\n$T_{d o w n}(t) = \\frac{D_{t a s k}(t) - D_{s, s_p}^{m i g}(t)}{R_{v s}^{d o w n}(t)}+\\frac{D_{s, s_p}^{m i g}(t)}{R_{v s p}^{d o w n}(t)}.$\n(8)\nIn summary, for the vehicular metaverse, when vehicle $v$ performs a VT migration task at time slot $t$, it first sends a VT migration request to edge server $s$ based on the migration"}, {"title": "B. Attack Model", "content": "decision $K_v(t)$, which is discussed in detail in Section V-A, resulting in uplink delay $T_{v s}^{u p}(t)$. The edge server $s$ then mi- grates some of the VT task to the edge server $s_p$ for processing. These two servers process the task in parallel, resulting in processing delay $T_{pro}(t)$. After the task is completed, the result is sent back to the vehicle $v$, and this process will generate a downlink delay $T_{d o w n}(t)$. Therefore, the total delay for the VT migration can be calculated as\n$T_{s u m}(t) = T_{v s}^{u p}(t) + T_{p r o}(t) + T_{d o w n}(t)$.\n(9)\nDuring the VT migration, there are security risks in virtual- real interaction and large amounts of data transmission be- tween edge devices [30]. Attackers may use specific strategies to attack edge servers and degrade migration efficiency. To better evaluate the reliability of edge servers, we discuss the main attacks faced in migration scenarios in Section III-B.\nWe consider two attacks against edge servers: DDoS at- tacks [31] and Co-resident attacks [32]. In the DDoS attack, attackers flood the target server with a large amount of ma- licious traffic, making it unable to handle legitimate requests. Since VT migrations rely on the physical network composed of edge servers, VT migrations may be forced to stop when these edge servers are attacked. In the co-resident attack, the attacker hides in an edge server, remains dormant as long as possible, and then leaks information stored on the edge server through side-channel attacks. Attackers take advantage of restricted resources to launch a variety of attacks. To maximize the effect, attackers employ strategies as follows: 1) Direct DDoS attacks: Malicious traffic is sent straight to a target edge server, flooding the link and pushing the current load $L_s(t)$ of edge server $s$ to its maximum capacity $L_{max}(t)$. When performing trust evaluation on the edge server $s$, resource exhaustion and service unavailability cause a significant increase in abnormal data and unresponsive requests. Consequently, there are significant reductions in the data security and service performance of the edge server $s$. Additionally, the edge server $s$ will receive negative evaluations due to service unavailability at this time. 2) Indirect DDoS attacks: Attackers do not directly target the edge server but indirectly affect it by attacking nearby edge servers (e.g., crossfire attack [33]). Overloading nearby edge servers that share critical links prevents them from effectively processing transmitted data, increasing network congestion, and resulting in an increase in load on the target edge server and a decrease in overall respon- siveness. The impact of this attack on the neighboring edge servers is similar to suffering a direct DDoS attack. 3) Co-resident attacks: Attackers attempt to coexist their malicious script with the target edge server, using side- channel attacks to steal information from the target server and affect its performance. At this time, the edge server $s$ generates unexpected load and computing overhead due to the existence of malicious scripts. When performing detection tasks on edge servers, the presence of malicious scripts can slightly increase the volume of abnormal data and the incidence of abnormal response failures. To prevent vehicles from migrating VTs to compromised edge servers that suffer the above attacks, we designed a two-layer trust evaluation model to effectively quantify the reliability of edge servers, thereby achieving efficient VT migrations and ensuring a seamless virtual experience for VMUs. The evaluation model is discussed in Section III-\u0421."}, {"title": "C. Two-layer Trust Evaluation Model", "content": "Figure 1 shows that the reliability of edge servers is eval- uated when migrating VTs from vehicles to these servers, which is critical to ensuring service quality and network security. This directly affects the efficiency of data processing and VT migration. To effectively measure the performance and credibility of edge servers, we design a two-layer trust evaluation model, as shown in Fig. 2. This trust evaluation model comprehensively evaluates the reputation value of the edge server by considering its historical performance, task completion rate, service quality, and user feedback. The first step of trust evaluation occurs at the network communication layer, evaluating the data security and service performance during edge server communication. After an edge server is attacked, the transmitted data might be intercepted, altered, or damaged [34]. The capability of the edge server to maintain data security and integrity is measured by the ratio of non-anomalous data identified during task detections issued by detection systems (e.g., Snort and Suricata) [35]. Specifically, the ratio of anomalous data is identified by following way [36]: (1) Verify the integrity of the data format and encapsulation; (2) Verify the consistency of data content with the parameters specified in the packet header; (3) Verify the consistency of multiple data contents at the same time. A higher ratio indicates that the edge server has more robust capabilities in protecting data from corruption or alteration, ensuring reliability during VT migrations. Therefore, the data security of the edge server $s$ can be calculated as [36]\n$P_{d a t a}^s=\\frac{D_{t o t}^s-D_{a b r}^s}{D_{t o t}^s}$\n(10)\nwhere $D_{t o t}^s$ is the total data size of the detection task and $D_{a b r}^s$ is the abnormal data size of the detection task. After being attacked, the edge server may become overloaded and unable to respond to service requests or be controlled by the attacker and refuse service requests [37]. The service reliability of the server can be evaluated by calculating the ratio of the number of successful response requests $R_{s u c}^s$ to the total number of requests $R_{t o t}^s$ issued in the detection task. A higher ratio of successful responses indicates that the edge server $s$ has a stronger capability to process and complete service requests effectively. Therefore, the service performance of edge server $s$ can be calculated as\n$P_{s e r}^s=\\frac{R_{s u c}^s}{R_{t o t}^s}$\n(11)\nThe historical defense record of an edge server is an important indicator for evaluating its reputation value [38]. The defense performance of an edge server can be determined by calculating the ratio of the number of successful defenses $N_{s u c}^s$ to the total number of historical attacks $N_{t o t}^s$, which can be calculated as $\\beta_s = \\frac{N_{s u c}^s}{N_{t o t}^s}$. Based on the above evaluation indicators, the reputation value of the edge server $s$ at the network communication layer can be calculated as [36]\n$\\text{Rep}_{N e t}^s= \\begin{cases}0, \\text{if } \\beta_s \\in (0, \\theta_1), \\\\\n\\alpha(w P_{d a t a}^s + (1 - w) P_{s e r}^s), \\text{ if } \\beta_s \\in (\\theta_1, \\theta_2), \\\\\nw P_{d a t a}^s + (1 - w) P_{s e r}^s, \\text { otherwise. }\\end{cases}$\n(12)\nWe divide (12) into three cases. In the first case, if the de- fense performance of edge server $s$ is lower than the threshold $\\theta_1$, we consider it high-risk and set its reputation value of the network communication layer to 0, where $0 < \\theta_1 < 1$. In the second case, when the defense performance of the edge server s is higher than the threshold $\\theta_1$ but lower than the threshold $\\theta_2$, we calculate the weighted sum of data security $P_{d a t a}^s$ and service performance $P_{s e r}^s$ of edge server $s$, adjusting the balance between the two with weight $w$ and penalizing with factor $\\alpha$, where $\\theta_1 < \\theta_2 < 1$ and $0 < \\alpha < 1$. Finally, when the defense performance of the edge server is higher than the threshold $\\theta_2$, we consider it to have a high degree of trust and directly use the weighted sum of data security and service performance to represent its reputation value. The second step of trust evaluation occurs at the interaction layer between the VMUs and the edge server, reflecting the direct interaction experience between the VMUs and the edge server. The reputation value of the edge server is assessed by recording the evaluation given by the VMU during each interaction with the edge server. Let $E_s = \\{E_{1,s},..., E_{i,s},..., E_{n,s}\\}$ denote the set of evaluations by all VMUs that have interacted with edge server $s$, where $n$ denotes the number of VMUs interacting with server $s$. For each VMU $i$, the set $E_{i,s} = \\{e_{i_1,s},..., e_{i_m,s},..., e_{i_r,s}\\}$ represents the evaluation scores across $k$ interactions, where $e_{i_m,s} = 1$ and $e_{i_m,s} = 0$ indicate a positive evaluation and a negative evaluation for the $m$-th interaction, respectively. In addition, the total number of evaluations received by edge server $s$ is calculated as $E_{t o t} = \\sum_{i=1}^{n} i_k$. Based on the beta distribution [1], the reputation value of edge server $s$ at the interaction layer is defined as\n$\\text{Rep}_{I n t}^s=\\frac{\\sum_{i=1}^n \\sum_{m=1}^{i_k} e_{i m, s}+1}{E_{t o t}+2}$\n(13)\nIn summary, when evaluating the reputation value of edge server $s$ using the two-layer trust evaluation model, the initial step involves calculating its $P_{d a t a}^s$ and $P_{s e r}^s$ at the network communication layer and then performing a weighted summa- tion of $P_{d a t a}^s$ and $P_{s e r}^s$ to obtain the preliminary reputation value at this layer. The reputation value at the network com- munication layer is classified and discussed according to the historical defense data of edge server $s$. Then, the reputation value of edge server $s$ at the interaction layer is calculated based on the interaction evaluations from VMUs. Finally, the comprehensive reputation value of edge server $s$ is obtained by performing a weighted summation of the reputation values from the network communication layer and interaction layer, calculated as\n$\\text{Rep}^s=\\xi \\text{Rep}_{N e t}^s+(1-\\xi) \\text{Rep}_{I n t}^s,$\n(14)\nwhere $\\xi$ is a weight parameter. In addition, the reputation value of the edge server $s$ is updated by combining the latest evaluated reputation value $\\text{Rep}_{l a t e}$ with the past reputation value $\\text{Rep}_{p a s t}$. The formula for updating is given by\n$\\text{Rep}_{n e w}^s=\\phi \\text{Rep}_{l a t e}+(1-\\phi) \\text{Rep}_{p a s t},$\n(15)\nwhere $\\phi \\in(0,1)$ controls the update rate."}, {"title": "D. Utility Function", "content": "To provide VMUs with a seamless and reliable service experience, we design the utility function of VMUs as the difference between reputation values and service latency. Specifically, the reputation value reflects the reliability and consistency of the edge server in providing services, while the latency measures the response and processing speed of the service, which directly affects the interactive experience of VMUs. High reputation values and low service latency lead to high utility value, indicating that VMUs can enjoy fast and reliable services. Therefore, the utility function of vehicle $v$ at time $t$ is given by\n$U_v(t) = \\lambda(\\text{Rep}^s(t) + \\text{Rep}^{s_p}(t)) - \\mu T_{s u m}(t)$.\n(16)\n$\\text{Rep}^s(t)$ and $\\text{Rep}^{s_p}(t)$ are the reputation values of edge servers $s$ and $s_p$ selected by the vehicle $v$ at time $t$, respec- tively. $T_{s u m}(t)$ is the total delay of the VT migration. $\\lambda$ and $\\mu$ are coefficients that convert unit reputation value and unit delay into monetary benefits. By applying the utility function, the experience benefit of the decision at a specific moment can be evaluated."}, {"title": "IV. PROBLEM FORMULATION", "content": "This paper aims to maximize the overall utility of vehicles within a finite time $T$ by identifying the optimal migration decision strategy, subject to the constraints of edge server reliability and limited load, which is given by\n$\\underset{K_v}{\\max} \\sum_{t=1}^T \\sum_{v=1}^V U_v(t)$\n(17a)\ns.t. $k_{s e l}^v(t) \\in \\{1,2,...,S\\}, \\quad \\forall v \\in V,$\n(17b)\n$k_{s e l}^{s_p}(t) \\in \\{1,2,...,S\\}, \\quad \\forall v \\in V,$\n(17c)\n$K_{p r e}(t) \\in [0,1], \\quad \\forall v \\in V,$\n(17d)\n$P_{v,s}(t) < R o o m_s, \\quad \\forall s \\in \\{s, s_p\\}, \\forall v \\in V,$\n(17e)\n$\\text{Rep}^s(t) > R e p_{t h r e}, \\quad \\forall s \\in \\{S, S_p\\},$\n(17f)\n$L_s(t) < L_{m a x}, \\quad \\forall s \\in \\{S, S_p\\},$\n(17g)\n$t \\in \\{1, ..., T\\}.$\n(17h)\nIn constraints (17b) and (17c), $k_{s e l}^v$ and $k_{s e l}^{s_p}$ represent the indices of the edge servers utilized by vehicle $v$ for VT migra- tions. This ensures that at any given time, the edge servers used for VT migrations by vehicles belong to the existing set of edge servers, thereby securing the feasibility of the migration decisions. Constraint (17d) specifies that the proportion of pre-migration tasks lies between 0 and 1. Constraint (17e) requires the communication ranges of the selected edge servers $s$ and $s_p$ to be greater than their Euclidean distances from the vehicle. Constraint (17f) demands that the reputation value of the selected server must exceed the preset threshold $Rep_{thre}$ to ensure the basic reliability of the task. Constraint (17g) ensures that the load on the chosen server at that moment does not reach its maximum capacity to prevent overload. Constraint (17h) indicates the need for optimization to be completed in a limited time frame $T$."}, {"title": "V. HYBRID-GDM FOR TWIN MIGRATION", "content": "In this section, we first model the VT migration optimization problem as a POMDP and then propose the hybrid-GDM algorithm to generate the optimal migration decision. Since intelligent networks usually have the characteristics of high-dimensional configuration, non-linear relationships, and complex decision-making processes [39], the optimal solution of intelligent networks typically changes with the dynamic environment [40]. Therefore, complex network management models are required. GDMs can easily integrate environmental information into the denoising process [41] to capture high- dimensional and complex network structures. This avoids the problem that traditional DRL algorithms tend to converge to sub-optimal solutions in such tasks. In the vehicular metaverse, there are multiple edge servers and vehicles. The objective is to complete the VT migration of all vehicles in a way that maximizes overall utility, i.e., (17a). Given the limited communication distance and load of edge servers, the mobility pattern of each vehicle and the size of uploaded VT tasks are different, which makes POMDP particularly suitable for VT migrations. The unpredictability of future load on edge servers, as well as when and how potential attackers attack edge servers further justifies the POMDP- based approach. The POMDP model of the VT migration problem is described as follows: 1) Observation Space: The observation space O consists of real-time information from vehicles and edge servers. The observation space at time slot $t$ is defined as $O(t) = \\{P_v(t), T_{s u m}(t), \\forall v \\in V\\} \\cup \\{L_s(t), \\text{Rep}_s(t), \\forall s \\in S\\}$, where $P_v(t)$ is the position of vehicle $v$ at the current moment, $T_{s u m}(t)$ is the total delay of a VT migration in time slot t, and $L_s(t)$ and $\\text{Rep}_s(t)$ are the load condition and reputation value of edge server $s$ at this time, respectively. 2) Action Space: The action space is defined as the mi- gration decisions the agent generates for all vehicles, expressed as $A = \\{K_v, \\forall v \\in V\\}$. The migration decision of each vehicle at each time slot includes a discrete de- cision to select an edge server and a continuous decision to determine the proportion of pre-migration VT tasks. Thus, the migration decision of vehicle $v$ at time slot $t$ can be represented as the tuple $K_v(t) = \\{K_{s e l}^v(t), K_{p r e}(t)\\}$, where $K_{s e l}^v(t) = \\{k_{s e l}^s(t), k_{s e l}^{s_p}(t)\\}$ represents theindices of the current edge server $s$ and the pre-migration edge server $s_p$ chosen by vehicle $v$ at time slot $t$. These indices correspond one-to-one with the edge servers in the vehicular metaverse. $K_{p r e}(t) \\in [0,1]$ represents the proportion of the pre-migrated VT task in time slot $t$. 3) Reward Function: In each time slot, the agent makes migration decisions A(t) for all vehicles based on the environment observation O(t). The environment returns a reward based on action A. To maximize the overall utility, we define the reward as\n$R(O(t), A(t)) = \\sum_{v=1}^V U_v(t)$.\n(18)\nB. Hybrid-GDM for Generating Optimal Decisions In this section, we propose the hybrid-GDM algorithm. The forward process of the diffusion model is first introduced, and"}, {"title": "noise that obscure the actual action distribution. The obtained reconstructed sample $x_0$ is\n$x_0=\\frac{1}{\\sqrt{\\bar{a}_t}} x_t - \\frac{1}{\\sqrt{\\bar{a}_t}} -1 \\cdot \\tanh (\\epsilon_\\theta(x_t, t, O)),$\n(23)\nwhere $\\epsilon_\\theta(x_t, t, O)$ a neural network parameterized to generate denoising noise based on observation O. Calculating $x_0$ by using (23) is unfeasible due to the emergence of additional noise in each reverse denoising step. This noise source is distinct from the noise introduced during the forward process. Thus, we employ the Bayesian formula to reformulate the reverse computation into forward ones, thereby converting it into a Gaussian probability distribution. The relationship between the mean $\\mu_\\theta$ and $x_0$ is\n$\\mu_\\theta(x_t, t, O) = \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} x_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} x_0,$\n(24)\nwhere $t = 1,..., T$. Based on (23) and (24), the estimated mean is rewritten as\n$\\mu_\\theta(x_t, t, O) = \\frac{1}{\\sqrt{\\alpha_t}} \\left(x_t-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\tanh (\\epsilon_\\theta(x_t, t, O))\\right)$\n(25)\nThen, we can start from the standard Gaussian distribution $p(x_T)$, and gradually substitute $t = T,T - 1,...,1$ in transition distribution $p(x_t)p_\\theta(x_{t-1}|x_t)$ to obtain $p_\\theta (x_0)$, given by\n$p_\\theta (x_0) = p(x_T) \\prod_{t=1}^T p_\\theta(x_{t-1}|x_t)$.\n(26)\nTo back-propagate gradients from random variables sampled from the distribution, the authors in [14] adopted reparameter- ization to separate the randomness from the parameters of the distribution. This allows the gradient to be back-propagated through the new parameterized path. The updated rules are given by\n$x_{t-1} = \\mu_\\theta(x_t, t, O) + (\\beta_t^{1/2})^2 \\bigodot \\epsilon, \\quad \\epsilon \\sim N(0, I)$.\n(27)\nStarting from randomly generated normal noise, $x_t(0 \\lt t \\lt T)$ and the final output $x_0$ can be obtained by iterating the backward update rule (27). Then, we extract and individually process the composite distribution \"$x_0$\" corresponding to each vehicle from $x_0$ = $\\{v_{x_0}, v \\in V\\}$. For the composite distribution \"$x_0$\" of vehicle $v$, we apply the softmax function $f(z) = \\frac{e^{z_i}}{\\sum_{i=1}^{S'} e^{z_i}}$ (i = 1, 2, ..., S') to process \"$x_0^U$\" and \"$x_0^{U^{s_p}}$\", respectively, convert them into the probability distributions for choosing edge servers $s$ and $s_p$, and keep the proportion of pre-migration tasks $v_{x_0^{pre}}$ as the original value. The processed distribution $x^{\\prime}$ is\n$x^{\\prime} = \\{f(x_0^U) \\cup f(x_0^{U^{s_p}}) \\cup v_{x_0^{pre}}, v \\in V\\}$.\n(28)\nTo enhance the exploration of strategies during the training phase, minor noise is added to the proportion $\\{v_{x_0^{pre}}, v \\in V\\}$ of pre-migration tasks for all vehicles, and indices $\\{K_{s e l}^v, \\forall v \\in V\\}$ of edge servers $s$ and $s_p$ are sampled from the probability distributions $\\{f(x_0^U), \\forall v \\in V\\}$ and $\\{f(x_0^{U^{s_p}}), \\forall v \\in V\\}$, respectively. During the evaluation phase, the proportion $\\{v_{x_0^{pre}}, \\forall v \\in V\\}$ of the pre-migration task is maintained at its original value. For $\\{K_{s e l}^v, \\forall v \\in V\\}$, the edge servers $s$ and $s_p$ with the highest probabilities from the corresponding distributions are selected."}, {"title": "IX. NUMERICAL RESULTS", "content": "To evaluate the robustness of the hybrid-GDM algorithm under different system configurations, we compared the per-"}, {"title": "3) Algorithm architecture", "content": "The overall framework of the hybrid-GDM algorithm is shown in Fig. 3, which contains several components that work together to promote strategy optimization jointly. These components include actor, double critic, target networks, experience replay buffer, and twins migration environment. In each environment step t, the agent receives observations O(t) and uses the diffusion model to output hybrid action distribution $\\pi_\\theta (O(t))$, where $\\theta$ are the parameters of the GDM- based network. Then, actions A(t) = $\\{K_v(t),\\forall v \\in V\\}$ are sampled from the action distribution and fed back to the en- vironment. The environment transitions to state O(t + 1), and rewards R(O(t), A(t)) are returned to agent. Finally, the agent records the experience (O(t), A(t), O(t + 1), R(O(t), A(t))) into the experience replay buffer. These steps will be executed K times before the agent learns the policy. Actor-network $\\pi_\\theta$ extracts a minimum batch of data from the experience replay buffer for optimization during the policy improvement. To reduce overestimation bias, a dou- ble critic network is utilized to implement the Q function $Q_\\phi(O(t), A(t))$. Unlike the standard Q function [44], this Q function generates a vector of Q values $q \\in R^{\\mid A\\mid}$ with the same dimensions as the action distribution to evalu- ate the value of discrete and continuous actions compre- hensively. Each critic network has its own parameters, i.e., $\\phi = \\{\\phi^1, \\phi^2\\}$, and is updated separately with an identical optimization objective. In the training phase, the minimum Q value estimate among the two critic networks is chosen to update the actor-network, i.e., $q = Q_\\phi (O(t), A(t)) = \\min \\{Q_{\\phi^1} (O(t), A(t)), Q_{\\phi^2} (O(t), A(t))\\}$. The Q value estimates the expected cumulative reward of each action within the given observation. To update the actor network toward selecting actions with higher Q values, we transform the optimization objective into a minimization problem as\n$\\min_\\theta \\{-\\pi_\\theta (O(t)) Q_\\phi (O(t), A(t))\\}.$\n(29)\nWe use the Adam gradient descent algorithm to address the optimization problem. The gradient corresponding to (29) is computed by sampling experiences of batch size B at e-th training iteration and is calculated as\n$\\mathbb{E}_{O(t) \\sim \\mathbb{B}_e} [-\\nabla_\\theta \\pi_\\theta(O(t))^T Q_\\phi(O(t), A(t))].$\n(30)\nThe agent learns the optimal policy parameters by iteratively executing the gradient update formula, with the learning rate $\\mathbb{N}_a$ controlling the step size of parameter adjustments. The gradient update formula is\n$\\theta_{e+1} \\leftarrow \\theta_e - \\mathbb{N}_a (\\mathbb{E}_{O(t) \\sim \\mathbb{B}_e} [-\\nabla_\\theta \\pi_\\theta(O(t)) Q_\\phi(O(t), A(t))])$.\n(31)"}, {"title": "Only when the critic network's estimate of the expected cumulative reward is sufficiently accurate can the actor net- work find the optimal policy. Therefore, we update the critic network by reducing the temporal difference error between the Q target and Q evaluation, denoted as\n$\\min_{\\phi^1, \\phi^2} \\mathbb{E}_{(O(t), A(t),O(t+1),R(O(t), A(t))) \\sim \\mathbb{B}_e} \\sum_{i=1}^b (Y_e - \\hat{y})^2$\n(32)\ns.t.\n$\\hat{Y} = Q_\\phi (O(t), A(t)),$\n$\\hat{y} = R(O(t), A(t)) + (1 - f_{t+1})\\gamma \\hat{Q} \\left(O(t+1),\\pi_\\theta (O(t + 1))\\right),$\nwhere $\\gamma$ is the discount factor for future rewards, and $f_{t+1}$ is a binary variable indicating the termination flag. We use target networks to improve training stability by freezing their parameters during gradient descent and updating them slowly via a soft update mechanism, denoted as\n$\\theta_{e+1} \\leftarrow \\tau \\hat{\\theta}_e + (1 - \\tau)\\theta_e,$\n(33)\n$\\phi_{e+1} \\leftarrow \\tau \\hat{\\phi}_e + (1 - \\tau)\\phi_e,$\nwhere $\\hat{\\theta}_e$ and $\\hat{\\phi}_e$ are the parameters of the target actor network and target critic network, respectively, and $\\tau \\in (0,1]$ controls the frequency at which the target network is updated. Finally, the policy update and Q function update are iteratively executed until convergence, thereby maximizing the utility objective (17a). The detailed algorithm of hybrid-GDM is shown in Algorithm 1. The computational complexity of Algorithm 1 depends on experience collection and parameter updating. Specifically, the computational complexity of experience collection is $O(EK (V + T\\mid \\theta\\mid))$. This includes the overhead of interacting with the environment O(EKV), where E is the number of training epochs, K is the number of experiences collected, and V is the computational cost of a single step when interacting with the environment. Additionally, since the reverse diffusion process performs T steps of denoising, the additional overhead generated is O(T\\mid \\theta\\mid)$, where $\\mid \\theta\\mid$ is the number of parameters in the actor-network. The computational complexity of parameter update is $O(E (b + 1) (\\mid \\theta\\mid + \\mid \\Phi\\mid))$. This includes the overhead O (Eb (\\mid \\theta\\mid+\\mid \\Phi\\mid)) of updating both the actor-network and the critic-network as well as the overhead of updating the target networks O (E (\\mid \\theta\\mid+\\mid \\Phi\\mid)), where b is the batch size, and $\\mid \\Phi\\mid$ is the number of parameters in the critic-network. Therefore, the computational complexity of Algorithm 1 is $O (E [KV + TK\\mid \\theta\\mid+(b + 1) (\\mid \\theta\\mid+\\mid \\Phi\\mid)])$."}, {"title": "Algorithm 1", "content": "Hybrid-GDM Algorithm 1: Initialize actor-network parameters $\\theta$, critic-network parameters $\\phi$, target-network parameters $\\hat{\\theta} \\leftarrow \\theta$, $\\hat{\\phi} \\leftarrow \\phi$, observation O, and experience replay buffer D; 2: for the training epoch e = 1 to E do 3: for the collected experiences k = 1 to K do 4: Obtain the observation O and initialize the standard normal distribution $x_T \\sim \\mathbb{N}(0, I)$. 5: for the denoising step t = T to 1 do 6: Use a deep neural network to infer and scale a denoising distribution $\\tanh (\\epsilon_\\theta(x_t, t, O))$; 7: Use (25) to compute the mean of the parameterized model $p_\\theta (x_{t-1}\\mid x_t)$; 8: Use the reparameterization method (27) to compute the composite distribution $x_{t-1}$; 9: end for 10: Process the composite distribution of $x_0$ with (28); 11: Add the exploration noise to $x_0$, and then sample the hybrid actions A from this distribution; 12: Perform action A within the environment and obtain the observation O' and reward R; 13: Record experience tuple (O, A, O', R) in replay buffer D; 14: end for 15: Extract a batch of experiences $\\mathbb{B} = (O, A, O', R)$ from the experience replay buffer D for optimization; 16: Update the actor-network $\\theta$ according to (31); 17: Update the critic network $\\phi$ with one gradient descent step to minimize (32); 18: Perform a soft update of the target network parameters $\\theta$, $\\phi$ using (33); 19: end for 20: return the optimal migration decision solution $A^*$."}, {"title": "A. Parameter Settings", "content": "In our scenario, there are 22 edge servers, including 20 RSUs and 2 satellites designed to supplement computational capabilities. This setup aims to ensure a seamless experience for VMUs even when the edge servers are unevenly deployed and under heavy load. All RSUs communicate with each other via wired networks, while the connection with satellites is established through wireless networks. Besides, we consider attackers in the scenario who irregularly launch attacks on edge servers, including direct DDoS attacks, indirect DDoS attacks, and co-resident attacks. All edge servers are at risk of being compromised. Moreover, each vehicle has a unique driving trajectory. The essential parameters for the experiment are presented in Table II."}, {"title": "B. Convergence Analysis", "content": "As shown in Fig. 4, we compare the hybrid-GDM algorithm with several baselines to verify our algorithm's effectiveness. These baseline algorithms include Hybrid-GDM w.o. pre- migration, MAPPO with pre-migration, MAPPO w.o. pre- migration, and random strategies, where w.o. pre-migration means that VT tasks are not considered pre-migrated when training using the relevant algorithm, i.e., these tasks are always processed on the current edge server s without being pre-migrated to another edge server Sp. Through the reward curve, we observe that the hybrid-GDM outperforms these baseline algorithms in both convergence speed and convergence value. Compared with Hybrid-GDM w.o. pre-migration, MAPPO with pre-migration, and MAPPO w.o. pre-migration, the performance is improved by 6.06%, 25.04%, and 62.52%, respectively. This is because GDMs can incorporate dynamically changing environmental information (e.g., the load on edge servers, the location of vehicles, and the reputation values of edge servers) into the denoising process. After sufficient training, GDMs can generate the optimal VT migration strategy under any environmental conditions. In addition, the algorithm implementing pre-migration shows a higher convergence value, which shows that pre-migration can effectively reduce the load pressure of the current edge server s and transfer it to the pre-migration server sp. Especially for vehicles that move faster and stay within the current edge server coverage for a shorter time, it is necessary to pre- migrate more tasks to the edge server sp. It is worth noting that even if the hybrid-GDM algorithm does not consider pre-migration, its final convergence value is almost the same as that of the MAPPO algorithm that considers pre-migration, and the convergence speed is faster, which highlights the advantages of hybrid-GDM in decision generation."}, {"title": "C. Performance Evaluation", "content": "To evaluate the robustness of the hybrid-GDM algorithm under different system configurations, we compared the performance of various algorithms under different system param- eters. In the utility function (16), $\\lambda$ and $\\mu$ are coefficients that convert unit reputation value and unit delay to experience benefits. As these coefficients may vary across application scenarios, we introduce the utility weight ratio $\\rho$ to represent the ratio between $\\lambda$ and $\\mu$, i.e., $\\rho = \\frac{\\lambda}{\\mu}$. Specifically, we consider several different values of $\\rho$ (i.e., 0.25, 0.5, 1, 2, 4, 8) to evaluate the rewards of agents under different settings of $\\rho$, as shown in Fig. 5. The proposed hybrid-GDM algorithm demonstrates optimal performance across all $\\rho$ settings, with performance improvements of 4.43%, 22.4%, and 56.86% compared to the baseline Hybrid-GDM w.o. pre-migration, MAPPO with pre-migration, and MAPPO w.o. pre-migration, respectively. As the proportion of reputation value in the total reward increases, the reward difference between the scheme that does not use the pre-migration and the scheme that uses the pre-migration gradually expands, especially in the MAPPO algorithm. The reason is that adopting a pre-migration decision can increase the available migration options, when an attacker launches an attack, effectively mitigating the impact of attacks on edge servers by choosing pre-migration edge servers with higher reputation values and altering the proportion of pre-migration tasks, thus enhancing VMU's utility."}, {"title": "Figure 6 shows the changes in average system latency across eight levels of VT task sizes, ranging from 25 MB to 200 MB. The average system latency also rises as the size of the VT tasks increases, but the hybrid-GDM algorithm always has the lowest system delay, which reduces the average system delay by 3.9%, 24.5%, and 54.45% respectively compared to the baseline Hybrid-GDM w.o. pre-migration, MAPPO with Pre-migration and MAPPO w.o. Pre-migration. It can be seen that when the VT task size is small, an edge server can handle the load without a significant impact on system latency, regardless of the use of pre-migration decisions. Thus, the latency difference between schemes employing pre-migration and those not using them remains small. However, as VT task sizes increase, this gap widens. Pre-migration helps distribute the load from the current edge server to the pre-migrated edge server, reducing the additional queuing delay caused by not using the pre-migration strategy. Figure 7 shows the changes in average system latency across nine levels of migration bandwidth. The hybrid-GDM algorithm achieves a reduction in average system latency compared to the baseline Hybrid-GDM full Pre-migration, MAPPO with Pre-migration, and MAPPO full Pre-migration by 1.54%, 13.73%, and 8.85 %, respectively. Note that full pre-migration denotes that the pre-migration proportion of VT tasks is set to 1. It can be observed that as the migration bandwidth increases, the average latency of MAPPO full Pre- migration initially exceeds but eventually falls below that of MAPPO with Pre-migration. The reason is that both the current edge server s and the pre-migration edge server sp simultaneously process the unfinished tasks. With full pre- migration of VT tasks, higher migration bandwidths allow the substitution of queuing delays at the current server with lower migration delays, thereby reducing the total system latency. Owing to the effective scheme generation capabilities of the hybrid-GDM, it still exhibits lower latency than Hybrid-GDM full Pre-migration. Figures 8 and 9 show the changes in average system latency and the mean reputation value of selected edge servers when subjected to different types of attacks. Four attack scenarios were considered, i.e., direct DDoS attacks only, indirect DDOS attacks only, co-residence attacks only, and a hybrid attack of the first three attacks. The hybrid-GDM algorithm con- sistently demonstrated the lowest average system latency and the highest mean reputation scores in all four scenarios. We observe that due to the concealment of co-residence attacks, the average reputation value of edge servers is relatively high in the co-residence attacks scenario, but the impact of co- residence attacks on latency is still reflected in Fig. 8. It proves that our solution can effectively reduce system latency in different scenarios, thereby improving the utility of VMUs."}, {"title": "VII. CONCLUSION", "content": "In this paper, we studied the VT migration problem in vehicular metaverses. To ensure a seamless virtual experience for VMUs, we proposed a secure and reliable VT migration framework. Considering the potential security threats of edge servers, we designed a two-layer trust evaluation model and modeled the mainstream attack methods in VT migration sce- narios. The VT migration problem is formulated as POMDP, and we proposed a hybrid-GDM algorithm that can per- form discrete actions and continuous actions simultaneously to ensure that the utility is maximized. Numerical results demonstrate that the proposed scheme can achieve low latency for VT migration while ensuring that the vehicle selects edge servers with high reputation values. For future work, we will apply the hybrid-GDM algorithm to more attacks and focus on detecting and identifying abnormal edge servers in vehicular metaverses."}]}