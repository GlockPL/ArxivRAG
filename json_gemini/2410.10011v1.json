{"title": "Learning Interpretable Classifiers for PDDL Planning", "authors": ["Arnaud Lequen"], "abstract": "We consider the problem of synthesizing interpretable models that recognize the behaviour of an agent compared to other agents, on a whole set of similar planning tasks expressed in PDDL. Our approach consists in learning logical formulas, from a small set of examples that show how an agent solved small planning instances. These formulas are expressed in a version of First-Order Temporal Logic (FTL) tailored to our planning formalism. Such formulas are human-readable, serve as (partial) descriptions of an agent's policy, and generalize to unseen instances. We show that learning such formulas is computationally intractable, as it is an NP-hard problem. As such, we propose to learn these behaviour classifiers through a topology-guided compilation to MaxSAT, which allows us to generate a wide range of different formulas. Experiments show that interesting and accurate formulas can be learned in reasonable time.", "sections": [{"title": "1 Introduction", "content": "One of the main strengths of PDDL planning models is that they are succinct and human-readable, but can nonetheless express general, complex problems, whose state search spaces are exponential in the size of the encoding as can be the solutions. As a consequence, given a set of examples of the behaviour of an agent (called traces), understanding and recognizing this behaviour can be tedious.\nIn order to summarize the behaviour of a planning agent in a concise, interpretable way, we propose to learn properties that are specific to the solutions proposed by this agent. Such properties, expressed in a temporal logic tailored to fit PDDL planning models, are not only human-readable, but are also general, and can be evaluated against different instances of the same planning problem. This allows them to recognize the behaviour of an agent on instances that are substantially different from the ones used in the set of examples.\nMore specifically, the problem we tackle is the one where, given a set of positive example traces (the ones of the agent we seek to recognize) and negative examples traces (the ones of other agents), we wish to learn a model that can discriminate as well as possible between positive and negative traces. A wide variety of techniques and models of different natures have been proposed in the literature. Among these, the learning of finite-state automata (DFA) is a well-studied problem [1, 26, 28], but DFAs can grow quickly (thus becoming harder to interpret) and do not generalize to instances not in the example set. More recently, neural network-based architectures such as LSTMs [29] have shown very promising results, but lack in-terpretability, and the rationale for their decision is rarely clear.\nIn the past decade, significant efforts have been made towards learning logical formulas expressed in (a form of) temporal logic. Such works [24, 25, 10, 21, 4, 5] often leverage symbolic methods to learn Linear Temporal Logic (LTL) formulas [23] that fit the example traces, and thus share some similarities with our work. Some other authors propose other techniques, such as Latent Dirichlet Allocation [15], which stems from the field of natural language processing. However, in all of these cases, the knowledge extracted from the sets of examples has the major drawback of not generalizing well to unknown instances. This is due to the choice of the language used to express these properties. For instance, since LTL formulas are built over a set of propositional variables, they do not generalize to models that do not share the same variables.\nTo address this issue, we propose to learn properties in a version of First-Order Temporal Logic (FTL). When tailored to the PDDL planning formalism, FTL can express a wide range of properties that generalize from one planning instance to the other, given that they model similar problems. This was shown in [2], who proposed to express search control knowledge in a language similar to ours, albeit with the aim of guiding the search of a planner designed to use such knowledge. In [5], the authors proposed to synthesize such control knowledge automatically, and thus address the problem of learning properties expressed in a fragment of FTL.\nIn this paper, we show that it is possible to learn richer and more expressive properties, using the whole range of FTL operators and modalities. The properties we wish to learn should describe the behaviour of a given planning agent, without being true for the behaviour of other agents. We show that learning such formulas is computationally intractable, as the associated decision problem is NP-hard. This is why the core of our approach consists in encoding the learning problem into a MaxSAT instance, which has the added benefit of showing resilience to any potential noise in the set of training examples. To make the search more efficient, we fix the general topology of the target formula before the encoding. In addition to alleviating the load on the MaxSAT solver and rendering the algorithm more parallelizable, this also increases the diversity in the formulas learned by our algorithm, thus providing varied descriptions of the behaviour of the agent of interest.\nOur article is organised as follows: Section 2 introduces the planning formalism as well as the FTL language. Section 3 formally introduces the learning problem we tackle in this paper, and shows that the associated decision problem is intractable. Sections 4 and 5 present some technical choices that we made to solve our problem in reasonable time in practice. In Section 6, we describe our reduction of the problem to MaxSAT, and in Section 7, we present our experimental results, as well as a few examples of formulas that are within reach of our implementation."}, {"title": "2 Background", "content": "2.1 Planning with PDDL\nThis section introduces the model that we use to describe planning tasks. Our definition of a PDDL planning task differs from [11], as we require the organization of the objects of our instances into types. The model we use resembles the one defined in [13]\nDefinition 1 (Type tree). A type tree T is a non-empty tree where each node is labeled by a symbol, called a type. For any type \\( \\tau \\in T \\), we call strict subtype any descendant \\( \\tau' \\) of \\( \\tau \\). \\( \\tau' \\) is a subtype of \\( \\tau \\) (denoted \\( \\tau' \\prec \\tau \\)) when \\( \\tau' \\) is a strict subtype of \\( \\tau \\) or when \\( \\tau' = \\tau \\).\nDefinition 2 (Object class). Let O be a set of elements called objects. We call object class any subset of O. A class \\( c_i \\) is said to be a subclass of type \\( c_j \\) if \\( c_i \\subseteq c_j \\).\nDefinition 3 (Type hierarchy). A type hierarchy H over type tree T is a set of object classes such that \\( O \\in H \\), and such that each object class of H is mapped to a unique type of T. This mapping \\( \\tau : H \\rightarrow T \\) is such that for any pair \\( c_i, c_j \\) of object classes:\n*   \\( c_i \\) is a subclass of \\( c_j \\) iff \\( \\tau(c_i) \\) is a subtype of \\( \\tau(c_j) \\);\n*   \\( c_i \\cap c_j = \\emptyset \\) iff \\( \\tau(c_i) \\) is not a subtype of \\( \\tau(c_j) \\) (and conversely).\nWe say that object \\( o \\in O \\) is of type \\( \\tau(o) := \\tau(c) \\) where c is the smallest (for inclusion \\( \\subseteq \\)) class of H to which o belongs.\nDefinition 4 (Predicate, atoms and fluents). A predicate p is a symbol, with which is associated:\n*   An arity \\( ar(p) \\in \\mathbb{N} \\)\n*   A type for each of its arguments. For \\( i \\in \\{1, ..., ar(p)\\} \\), the type of its argument at position i is denoted \\( t_p(i) \\in T \\)\nAn atom is a predicate for which each argument is associated with a symbol, which can be a variable symbol, or an object of O. When the i-th argument of the atom is an object \\( o \\in O \\) (associated to type hierarchy H), then we require that \\( \\tau(o) = \\tau_p(i) \\). The atom consisting of predicate p and symbols \\( x_1, ..., x_{ar(p)} \\) is denoted \\( p(x_1, ..., x_{ar(p)}) \\).\nA fluent is an atom where each argument corresponds to an object of O. A state is a set of fluents.\nDefinition 5 (Action schema and operators). An action schema is a tuple \\( a = (pre(a), add(a), del(a)) \\), such that \\( pre(a) \\), \\( add(a) \\) and \\( del(a) \\) are sets of atoms instantiated with variables only.\nAn operator o is akin to an action schema, except that the sets \\( pre(o) \\), \\( add(o) \\) and \\( del(o) \\) are sets of fluents.\nDefinition 6 (PDDL planning problem). A PDDL planning problem is a pair \\( \\Pi = \\langle D, I \\rangle \\) where \\( D = (P, A, T) \\) is the domain and \\( I = (O, H, I_0, G) \\) is the instance.\nThe domain D consists of a set P of predicates, a set of actions schemas A, and a type hierarchy T.\nThe instance I consists of a set of objects O and an associated type hierarchy H, as well as two states, \\( I_0 \\) and G, which are respectively the initial state and the goal conditions.\nAn operator o is applicable in a state s if \\( pre(o) \\subseteq s \\). The state that results from the application of o in s is \\( s[o] = (s \\setminus del(o)) \\cup add(o) \\).\nA sequence of operators \\( o_1, ..., o_n \\) is called a plan for \\( \\Pi \\) if there exists a sequence of states \\( s_0, ..., s_n \\) where \\( s_0 = I_0 \\), and which is such that, for all \\( i \\in \\{1, ..., n\\} \\), \\( s_i = s_{i-1}[o_i] \\) and \\( o_i \\) is applicable in \\( s_{i-1} \\). Such a sequence of states (which is unique for each plan) is called a trace. A plan is called a solution-plan if, in addition to this, \\( G \\subseteq s_n \\). We say that a fluent \\( p(o_1, ..., o_{ar(p)}) \\) is true in state s iff \\( p(o_1, ..., o_{ar(p)}) \\in s \\)."}, {"title": "2.2 First-Order Temporal Logic (FTL)", "content": "Syntax Let X be a set of variable symbols, P a set of predicates, and T a type tree. We define our language \\( \\mathcal{L}_{FTL} \\) such that:\n\\( \\psi := \\exists x \\in \\tau.\\psi \\; | \\; \\forall x \\in \\tau.\\psi \\; | \\; \\varphi \\)\nwhere \\( x \\in X \\), \\( \\tau \\in T \\), and \\( \\varphi \\in \\mathcal{L}_{TL} \\), and \\( \\mathcal{L}_{TL} \\) is such that:\n\\( \\varphi := \\top \\; | \\; p(x_1, ..., x_{ar(p)}) \\; | \\; \\neg\\varphi \\; | \\; \\bigcirc \\varphi \\; | \\; \\square \\varphi \\; | \\; \\Diamond \\varphi \\; | \\; \\boxdot \\varphi \\; | \\; \\Diamond \\varphi \\; | \\; \\varphi \\mathcal{U} \\varphi \\; | \\; \\varphi \\wedge \\varphi \\; | \\; \\varphi \\vee \\varphi \\; | \\; \\varphi \\Rightarrow \\varphi \\)\nwhere \\( x_1, ..., x_{ar(p)} \\) are variables of X, p a predicate of P, and \\( \\tau \\) a type. In the following, we will denote \\( \\Lambda = \\{\\wedge, \\vee, \\Rightarrow, \\mathcal{U}, \\bigcirc, \\square, \\Diamond\\} \\) the set of all logical operators. For each operator \\( \\lambda \\in \\Lambda \\), we also note \\( ar(\\lambda) \\in \\{1, 2\\} \\) the arity of the operator.\nThis formulation is akin to Linear Temporal Logic on finite traces (LTLf) [23], where propositional variables are replaced with first-order predicates and variables. Notice that we only work with formulas in prenex normal form.\nEnvironments The formulas of \\( \\mathcal{L}_{TL} \\) are built on atoms whose arguments are variables of X, while traces contain fluents. We bridge that gap with the notion of environments, which are akin to interpretations in first-order logic.\nLet us denote \\( \\overline{X} = (x_1, ..., x_q) \\). In addition, let I be an instance, with objects \\( O = \\{o_1, ..., o_{|O|}\\} \\). We call a partial environment any assignment of some of the variables \\( x_1, ..., x_q \\) to objects of O. Let us denote \\( var(e) \\) the variables that are assigned an object within the partial environment e. When \\( var(e) = \\overline{X} \\), we simply say that e is an environment. We denote any (partial) environment \\( e = \\{x_1 := o_{i_1}, ..., x_q := o_{i_q}\\} \\), where \\( i_1, ..., i_q \\in [1, |O|] \\).\nThe object to which variable x is associated to in e is denoted \\( x[e] \\). We also denote \\( p(x, y)[e] \\) the grounding of an atom \\( p(x, y) \\) by an environment e such that \\( x, y \\in var(e) \\). If \\( e = \\{x := o_1, y := o_2, ...\\} \\), then \\( p(x, y)[e] = p(x[e], y[e]) = p(o_1, o_2) \\). By extension, the formula obtained when grounding each atom of \\( \\varphi \\) with e is written \\( \\varphi[e] \\).\nSemantics Given an environment e, any quantifier-free formula \\( \\varphi \\) of \\( \\mathcal{L}_{TL} \\) can be evaluated against a trace \\( t = (s_0, ..., s_n) \\), at any step. When \\( i \\in [0, n] \\), we write \\( t, e, i \\models \\varphi \\) to denote that formula \\( \\varphi \\) is true at state \\( s_i \\) of trace t with environment e. Temporal modalities, such as \\( \\bigcirc, \\square, \\Diamond \\), etc., are used to reason over the states that follow or precede the current state \\( s_i \\).\n\\( \\bigcirc \\varphi \\) means that property \\( \\varphi \\) is true in the next state, while \\( \\Diamond \\varphi \\) means that \\( \\varphi \\) is eventually true, in one of the successors of the current state. \\( \\square \\varphi \\) means that \\( \\varphi \\) is true from this state on, until the end of the trace, and \\( \\varphi_1 \\mathcal{U} \\varphi_2 \\) means that \\( \\varphi_2 \\) is true in some successor state, and until then, \\( \\varphi_1 \\) is true. Operators \\( \\boxdot \\), \\( \\Diamond \\) and \\( \\bigcirc \\) are the past counterparts of the previous connectors: \\( \\bigcirc \\varphi \\) means that \\( \\varphi \\) is true in the previous state, \\( \\Diamond \\varphi \\) that \\( \\varphi \\) is true in some previous state, and \\( \\boxdot \\varphi \\) that \\( \\varphi \\) is true in every previous state.\nTo illustrate the language, we introduce the Childsnack problem, which originates from the International Planning Competition (IPC). It consists in making sandwiches and serving them to a group of children, some of whom are allergic to gluten. Sandwiches can only be prepared in the kitchen, and then have to be put on trays, which is the only way they can be brought to the children for service. Among the following FTL formulas, the first indicates that \"All children will eventually be served\" (and will be satisfied by any solution-plan). The second formula indicates that every sandwich x will eventually be put on some tray, at a moment t + 1. For every moment that pre-cedes moment t, x will not be prepared yet (which indicates that the"}, {"title": "2.3 The MaxSAT problem", "content": "Let Var be a set of propositional variables. The boolean satisfiability problem (SAT) is concerned with finding a valuation that satisfies a propositional formula \\( \\varphi \\). Propositional formulas are defined as follows, where \\( x \\in Var \\) is a propositional variable:\n\\( \\varphi := \\top \\; | \\; x \\; | \\; \\neg\\varphi \\; | \\; \\varphi \\vee \\varphi \\; | \\; \\varphi \\wedge \\varphi \\)\nThe maximum boolean satisfiability problem (MaxSAT) is a variant of SAT, in which a valuation of the variables Var of a set of formulas \\( \\{\\varphi_1, ..., \\varphi_n\\} \\) is sought. Each formula \\( \\varphi_i \\) is assigned a weight \\( w(\\varphi_i) \\in \\mathbb{R} \\cup \\{\\infty\\} \\). The MaxSAT problem consists in finding a valuation v of Var such that the sum of the weights of the formulas that are not satisfied by v is minimal."}, {"title": "3 The \\( \\mathcal{L}_{FTL} \\) learning problem", "content": "3.1 Problem definition\nScore function Our problem takes in input a score function, denoted \\( \\sigma : \\mathcal{T} \\rightarrow \\mathbb{R} \\), where \\( \\mathcal{T} \\) is the set of traces. This function allows us to express preferences on which traces are the most important to capture in the output formula, and which traces are the most important to avoid. In the rest of this article, we will say that an instantiated trace (t, I) is positive iff \\( \\sigma((t, I)) \\geq 0 \\). Otherwise, the instantiated trace is said to be negative.\nIn the following, we use \\( [(t, I) \\models \\varphi] \\) as a shorthand for the function equal to 1 if \\( (t, I) \\models \\varphi \\) and equal to 0 otherwise. The score function generalizes to formulas \\( \\varphi \\in \\mathcal{L}_{FTL} \\) as follows:\n\\( \\sigma'(\\psi) = \\sum_{(t, I) \\in \\mathcal{T}} \\sigma((t, I)) \\cdot [(t, I) \\models \\psi] \\)\nProblem 1. \\( \\mathcal{L}_{FTL} \\) learning\nInput:\nD a domain\nT a set of instantiated traces\nr \\( \\in \\mathbb{N} \\) the maximum number of logical operators in the output formula\nq \\( \\in \\mathbb{N} \\) the maximum number of quantifiers\n\\( \\sigma : \\mathcal{T} \\rightarrow \\mathbb{R} \\) a function called the score function\nOutput: A formula \\( \\varphi \\in \\mathcal{L}_{FTL} \\) such that \\( \\varphi \\) has at most r logical operators, and q quantifiers, and\n\\( \\sum_{(t, I) \\in \\mathcal{T}} \\sigma((t, I)) \\cdot [(t, I) \\models \\varphi] \\)\nis maximal"}, {"title": "3.2 Complexity", "content": "The decision problem associated to the \\( \\mathcal{L}_{FTL} \\) learning problem is the problem for which the output is Yes iff there exists a formula \\( \\psi \\in \\mathcal{L}_{FTL} \\) satisfying the requirements above, and with score \\( \\sigma'(\\psi) \\geq l \\), where l is given in input. The proof of intractability consists in a reduction from the NP-hard Set Cover Problem [14]. It is sketched below, and a more detailed proof can be read in the supplementary material of this article [18].\nProposition 1. The decision problem associated to the \\( \\mathcal{L}_{FTL} \\) learning problem is NP-hard\nProblem 2. Set Cover\nInput:\nA set \\( U = \\{1, ..., n\\} \\)\nA set S of subsets: \\( S = \\{S_1, ..., S_m\\} \\subseteq 2^U \\)\n\\( k \\in \\mathbb{N} \\)\nOutput:\nYes iff there exists a subset \\( T \\subseteq S \\) such that \\( |T| \\leq k \\) and \\( \\cup_{S \\in T} S = U \\)\nNo otherwise\nProof of Proposition 1 (Sketch). Let us consider an instance of Set Cover. We build an instance of \\( \\mathcal{L}_{FTL} \\) learning that is positive (i.e. outputs Yes) iff the Set Cover instance is positive.\nThe proof consists in showing that a set of positive traces can be described by a formula \\( \\mathcal{L}_{FTL} \\) satisfying the constraints in input iff there exists a set cover of size at most k. Each of the positive traces is associated to an element j of U, and contains a single state (and thus, temporal modalities have no effect). This single state carries the"}, {"title": "4 Planning problem preprocessing", "content": "We present in this section the transformations we bring to the PDDL planning problem before it is passed to our algorithm for learning \\( \\mathcal{L}_{FTL} \\) formulas.\nPredicate splitting Each predicate is split into several predicates of size 2, in order to curb the number of fluents while conserving the links between pairs of objects. This allows us to synthesize formulas containing predicates of high arity, while keeping the number of quantifiers of the formula low.\nConcretely, a predicate of the form \\( p(x, y, z) \\) will be split into newly-created predicates \\( p_{12}(x, y) \\), \\( p_{13}(x, z) \\), and \\( p_{23}(y, z) \\). Predicate splitting leads to significantly fewer fluents than if the task was to be grounded as is: for a predicate of arity \\( n \\geq 2 \\), to be grounded with instance I, there are \\( O(n^2 |O|^2) \\) associated fluents, while there would be \\( O(|O|^n) \\) if the predicate was not split.\nEven though the planning model thus obtained is less rich than the original one, we argue that predicate splitting allows us to learn formulas that would be otherwise out of computational reach.\nGoal predicates In order to allow the learnt formulas to reason on the goal state, we introduce goal predicates. For every predicate \\( p \\in P \\), we introduce the predicate \\( p' \\). Then, for each instance I, we introduce the latent state \\( S_I \\), which is intuitively a set of fluents that are true in every state of every trace associated to I.\nFor every fluent \\( p(o_1, ..., o_{ar(p)}) \\) of the goal state G of I, we add the fluent \\( p'(o_1, ..., o_{ar(p)}) \\) to \\( S_I \\)."}, {"title": "5 Topology-based guiding", "content": "TL chains An interesting representation for formulas of LTL is a representation as TL chains. They are the adaptation to our language of the notion of chain [16, 25], which is useful for representing formulas of modal or propositional logic.\nA TL chain is a Directed Acyclic Graph (DAG) which has three types of nodes: logical connector nodes (represented as \u2610 in the example of Figure 1), predicate nodes (represented as \u25c7) and variable nodes (represented as \u2297). In order to represent a correct LTL formula, logical connector nodes can only be children of logical connector nodes, predicate nodes children of logical connector nodes, and variable nodes children of predicate nodes. We also impose that every leaf is a variable node. In addition, to stay consistent with the choices we made in Section 4, we only work with TL chains that are binary trees, whose inner nodes have exactly two children."}, {"title": "6 Reduction to MaxSAT", "content": "6.1 Learning algorithm\nAlgorithm 1 summarizes the procedure that we use to learn \\( \\mathcal{L}_{FTL} \\) formulas out of our input. The subroutines work as follows: gen_TLchains(r) enumerates every TL chain having exactly r connectors. gen_quantifiers(q) enumerates sequences of quantifier symbols of size q, such that all universal quantifiers \\( \\forall \\) appear before existential quantifiers \\( \\exists \\). gen_types(D, q) enumerates every q-combination of types in the type tree T of D. Finally, the main subroutine, find_formula(D, T, p, \\( \\{Q_i\\} \\), \\( \\{\\tau_i\\} \\), \\( \\sigma \\)), encodes the problem of finding an \\( \\mathcal{L}_{FTL} \\) formula fitting the instantiated traces of T, with the constraints imposed by the TL chain p, the quantifiers \\( \\{Q_i\\} \\), and the types \\( \\{\\tau_i\\} \\). find_formula then returns (one of) the best formula(s) it finds, or the token FAIL if none is found.\n6.2 Preliminaries to the encoding\nVariables Our MaxSAT encoding is built on the set of variables that follows. When possible, we use the following conventions, as closely as possible: nodes of the TL-chain are denoted by i when they are logical connectors (represented by \u2610 in Figure 1), by l when they are predicate nodes (represented by \u25c7), and by v when they are first-order variable nodes (represented by \u2297). A trace is denoted by t, and"}, {"title": "6.3 Core constraints", "content": "Some of the constraints below are adapted from [10, 25, 21], which are concerned with LTL. Our main contribution is the adaptation of the encoding to our language \\( \\mathcal{L}_{FTL} \\), which differs from LTL by its tighter links with PDDL planning models through first-order components.\nIn the following, we suppose that an empty TL chain p has been computed, and that the associated quantifiers and types have been decided. We will denote n its number of connector nodes, and m its number of predicate nodes. As a consequence, there are 2m variable nodes. As previously, the number of quantifiers is denoted q. The first \\( b \\leq q \\) quantifiers are universal, while the others are existential.\nWe also suppose that the types on which the quantifiers range, denoted \\( \\tau_1, ..., \\tau_q \\), are already chosen. As a consequence, in this section, the set of relevant environments for instance \\( I_t \\) associated to trace t, denoted \\( E_{I, t} \\), only consists of environments of the form \\( \\{x_u := o_u\\}_{1 \\leq u \\leq q} \\) where, \\( \\tau(o_u) = \\tau_u \\), for \\( u \\in [1, q] \\).\nSyntactic constraints This section describes the constraints that ensure that the formula is syntactically well-formed.\nThe following constraints respectively ensure that every logical connector node has exactly one logical connector assigned, that every predicate node has exactly one predicate, and that each argument of each predicate is bound to a variable on which the formula quantifies.\n\\( \\bigwedge_{i\\<n} ExactlyOne_{\\lambda \\in \\Lambda}(\\iota) \\; \\wedge \\; \\bigwedge_{l\\<m} ExactlyOne_{p \\in P}(\\delta) \\)\n\\( \\wedge \\bigwedge_{l<m} \\bigwedge_{s \\in \\{1, 2\\}} ExactlyOne(\\theta_s) \\)\nSemantic constraints These constraints ensure that the formula found by the solver is consistent with the traces, and is reminiscent of the model-checking algorithm for modal logic.\nThe following clauses ensure that the formula \\( \\varphi \\) that is synthesized is consistent with the traces of T. This is made in accordance with the environments imposed by the quantifier, which are iterated upon. The variable \\( \\sigma_t \\) is true iff for every required environment e, \\( \\varphi[e] \\) is satisfied by t (where \\( \\varphi[e] \\) is the evaluation of formula \\( \\varphi \\) in environment e, and \\( \\varphi \\) is the quantifier-free part of the formula we"}, {"title": "6.4 Formula quality enhancement", "content": "The constraints of this section filter the solutions so that less interesting formulas, or formulas that could be computed by a run of our algorithm with smaller parameters, are barred from being output.\nSyntactic redundancies prevention These constraints prevent idempotent and involutive modalities and operators from being chained in the output formula. These include the negation, as well as the temporal operators \\( \\bigcirc \\) (for which \\( \\bigcirc \\bigcirc = \\bigcirc \\)) and \\( \\square \\) (which is, likewise, idempotent).\nIn addition, we prevent redundancies of the form \\( p(x, y) \\Delta p(x, y) \\), where \\( \\Delta \\in \\{\\wedge, \\vee, \\mathcal{U}, \\Rightarrow\\} \\) is a binary operator. In every case, there exists a smaller (sub-)formula that can be found and that expresses the same property, without the redundant atom. For space reasons, we skip the presentation of the constraints.\nVariable visibility We wish to ensure that every variable that we quantify upon in the output formula \\( \\varphi \\) also appears in an atom of \\( \\varphi \\). Otherwise, an equivalent formula could be found by running the algorithm with fewer quantifiers. This is why we force each variable to appear at least once in some atom."}, {"title": "7 Experiments", "content": "We implemented Algorithm 1 in Python 3.10, using the MaxSAT solver Z3 [6]. Experiments were conducted on a machine running Rocky Linux 8.5, powered by an Intel Xeon E5-2667 v3 processor, with a 9-hours cutoff and using at most 8GB of memory per run. The code of our implementation and our data are available online [17]. Additional, more detailed test results can also be found in [17].\nEven though we often managed to quickly find a formula that perfectly captures the set of examples, we let the algorithm run to the end, so that all TL chains and combinations of quantifiers and types are enumerated.\nBuilding the data sets To assess the performances of our algorithm, we considered domains from the International Planning Competition (IPC), 2 of which are described in Section 7.1. For each of these domains, we generated 23 instances that model problems with similar goals. Then, for each domain, we designed three domain-specific planners, that solve the tasks in a distinctive way.\nWe built our training sets by selecting 3 small planning instances of each domain, and the associated traces for each planner \u2013 for a total of 9 traces per domain. We then created the tasks of finding a formula recognizing the behaviour of each planner, out of 1, 2 or 3 of the training instances. The 20 remaining instances (and their associated plans) were used in the test set. The traces of our training set have length 5 to 21, with an average of 11.8 states."}, {"title": "7.1 Examples of learnt formulas", "content": "Childsnack We designed three different agents that solve Childsnack instances, as introduced in Section 2.2. Agents NGF and NGL compute solution plans of minimal size, and differ in that agent NGF makes sandwiches with no gluten first, and agent NGL makes sandwiches with no gluten last. Both agents make all sandwiches, put them on a tray, then serve the children. Agent GS greedily serves children: as soon as a sandwich is made, it is put on a tray and brought to a child. It also prioritizes gluten-free sandwiches.\nFor each of these behaviours, the total computation time and the total number of formulas found are depicted in Table 3 and Table 2, respectively. As shown on Table 1, we manage to learn formulas that"}, {"title": "8 Conclusion", "content": "In this paper, we have presented a method to learn temporal logic formulas that recognize agents based on examples of their behaviours. We showed that such formulas can be learned using an algorithm that boils down to a reduction to MaxSAT, and that very few examples are sometimes enough to perfectly capture the behaviour of an agent on instances that can differ from the ones used in the training set. This justifies the cost of resorting to a first-order language, which generalizes to new instances, but is also very concise and easily readable by a human. The formulas that we learn can serve as higher-order descriptions of the behaviour of a planning agent.\nIn future works too, we wish to tailor our algorithm and our datasets so that they can generate domain-specific control knowledge. More specifically, we wish to work on its integration into various systems that can be guided with temporal logic, be them automated planning systems [2] or reinforcement learning agents [27]. This is in line with previous works on generalized planning, which learn logic-based policies fully capable of solving a set of planning problems, out of a set of example instances and plans [3, 9]."}]}