{"title": "Benchmarking Floworks against OpenAI & Anthropic: A Novel Framework for Enhanced LLM Function Calling", "authors": ["Nirav Bhan", "Shival Gupta", "Sai Manaswini", "Ritik Baba", "Narun Yadav", "Hillori Desai", "Yash Choudhary", "Aman Pawar", "Sarthak Shrivastava", "Sudipta Biswas"], "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in various domains, yet their economic impact has been limited by challenges in tool use and function calling. This paper introduces ThorV2, a novel architecture that significantly enhances LLMs' function calling abilities. We develop a comprehensive benchmark focused on HubSpot CRM operations to evaluate ThorV2 against leading models from OpenAI and Anthropic. Our results demonstrate that ThorV2 outperforms existing models in accuracy, reliability, latency, and cost efficiency for both single and multi-API calling tasks. We also show that ThorV2 is far more reliable and scales better to multi-step tasks compared to traditional models. Our work offers the tantalizing possibility of more accurate function-calling compared to today's best-performing models using significantly smaller LLMs. These advancements have significant implications for the development of more capable AI assistants and the broader application of LLMs in real-world scenarios.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have revolutionized natural language processing and artificial intelligence, demonstrating remarkable capabilities across a wide range of tasks ([1, 2]). However, their economic impact has been somewhat limited, particularly in domains requiring precise interaction with external tools and APIs. A key challenge in this area is the task of function calling, where LLMs must accurately interpret user queries and translate them into appropriate API calls.\nThe underwhelming performance of LLMs in function calling has had tangible consequences. Much-anticipated AI gadgets like RabbitR1 and Humane AI Pin have faced criticism due to their inability to reliably fulfill user tasks. OpenAI's GPT-store has similarly met with a very lukewarm response. We also note that while chatbots and coding assistants can increase productivity, almost no jobs have been completely taken over by AI as of September 2024 [3]. This highlights a critical gap between the theoretical capabilities of LLMs and their practical performance in the real world.\nTo address these challenges, we introduce ThorV2, a novel architecture designed to enhance LLMs' function calling abilities. Thor V2 employs an innovative approach we term \"edge-of-domain modeling,\" which focuses on correcting errors rather than providing comprehensive instructions upfront. This paper presents a thorough evaluation of ThorV2 against leading models from OpenAI and Anthropic, using a new benchmark based on HubSpot CRM operations.\nOur contributions in this paper are as follows:"}, {"title": "2 Limitations of Traditional Function Calling", "content": "Traditional AI systems have treated function calling as a monolithic task, where the model accepts a task and relevant function schemas, then outputs a complete function call. This approach suffers from several key disadvantages:\n\u2022 Inefficient Function Retrieval: Retrieving appropriate functions often relies on vector similarity, a heuristic approach known to suffer from issues with accuracy, scalability, and domain specificity, as discussed in [4].\n\u2022 Excessive Token Lengths: Function schemas can be lengthy, leading to large prompt sizes. This increases deployment costs, time consumption, and can result in decreased accuracy on reasoning tasks. For example, [5] shows that reasoning abilities of LLMs fall drastically with increase in active context length.\n\u2022 High Output Sensitivity: LLMs are trained on free-flowing text and struggle with the rigid requirements of function calling, where precise variable names, JSON structures, and argument values are crucial.\nThese limitations have resulted in even the best closed-source LLMs (e.g., GPT-40, Claude-3 Opus) failing to solve the function calling problem effectively."}, {"title": "3 Thor V2 Architecture", "content": "ThorV2 is a Cognitive Enhancement Architecture (CEA) designed to augment the function calling capabilities of Large Language Models. Unlike traditional approaches that rely on comprehensive upfront instructions, ThorV2 employs a novel strategy we term \u201cedge-of-domain modeling\u201d. This approach focuses on identifying and correcting errors in the LLM's output, rather than attempting to preemptively cover all possible scenarios. We propose a new type of framework called \"Agent-Validator architecture\" which puts this type of modeling into practice. Later, we also discuss Composite Planning and other architectural optimizations to improve the cognitive performance of LLMs."}, {"title": "3.1 Overview of Thor V2", "content": "ThorV2 is a Cognitive Enhancement Architecture (CEA) designed to augment the function calling capabilities of Large Language Models. Unlike traditional approaches that rely on comprehensive upfront instructions, ThorV2 employs a novel strategy we term \u201cedge-of-domain modeling\u201d. This approach focuses on identifying and correcting errors in the LLM's output, rather than attempting to preemptively cover all possible scenarios. We propose a new type of framework called \"Agent-Validator architecture\" which puts this type of modeling into practice. Later, we also discuss Composite Planning and other architectural optimizations to improve the cognitive performance of LLMs."}, {"title": "3.2 Edge-of-domain Modeling", "content": "To build intuition for ThorV2's architecture, we first discuss a general principle on providing instructions for any task. One approach can be to provide the entire knowledge base upfront, hoping to cover all possible cases that an agent could encounter during the execution of the task. The other approach would be to only provide minimal instruction upfront, allowing the agent to begin the task, and provide the remaining information either in the form of just-in-time instructions or post-task error-correction.\nEdge-of-domain modeling refers to providing instructions through iteration and error-correction. We contrast this with the traditional approach of providing the entire world model in the system prompt before beginning, hoping to accomplish the task in a single attempt. We call the latter approach whole-of-domain modeling. The 2 approaches are contrasted in figure 1."}, {"title": "3.3 Agent-Validator Architecture", "content": "This edge-of-domain modeling is implemented through an Agent-Validator Architecture, as shown in figure 2. They key component of this system are Domain Expert Validators (DEVs), static agents written"}, {"title": "3.3.1 Validator example", "content": "While the full details of our Validator are proprietary, we give an example here to illustrate the general idea. The HubSpot API has two kinds of retrieval queries: retrieving properties which can be done in a single API call, and retrieving associations which require two API calls. For example, a deal's amount and closing date are properties, but notes are separate objects associated with the deal. LLMs frequently confuse these two operations, wrongly treating associations as properties. Our Validator identifies this error and provides the following feedback to the LLM: \u201cHubspot needs you to search for associated resource first and use its deal id as the associated resource id in your second query. Break into two steps and do variable injection\". If the LLM makes the same error again, the Validator will keep repeating its feedback until the error is fixed \u2013 hence the loop in figure 2."}, {"title": "3.3.2 Relation to other approaches", "content": "We contrast our approach with another set of approaches called \u201cAgent-Critic Systems\u201d or \u201cAgentic Workflows\". In these systems, it is common to have a primary LLM \"agent\" receive feedback from other LLMs who act as \"critics\u201d ([6, 7, 8]). These additional LLMs not only increase time and cost, but suffer from high error rates defeating the very purpose of a critic. In other words, we do not believe LLMs are broadly capable of self-critique, which is exemplified by the limited accuracy of agentic systems in benchmarks like SWE-Bench, as well as real-world tasks. ([9, 10]).\nOur approach differs from these in that we employ an entirely static critic. Static critics require domain knowledge and some engineering effort to develop, but they have the advantage of being extremely fast and perfectly accurate. The use of static DEVs is possible because the errors made by LLMs in function calling tend to be highly repetitive and predictable. Our approach bears some resemblance to the LLM-modulo approaches proposed in [11]. However, rather than rely on external verifiers that must cover every possible instance, we develop our own verifiers to correct the most common errors committed by the LLM agent. By focusing on these common error patterns, we can achieve significant improvements in accuracy and reliability."}, {"title": "3.4 Composite Planning Approach", "content": "For multi-step tasks, ThorV2 employs a novel composite planning approach. This allows for the generation of multiple API calls in a single step, instead of the traditional planning approach which generates API calls one at a time.\nThe key idea is to use placeholder variables to represent unknown values, and a planning logic to inject the values automatically. Once an API response is obtained, the values of placeholder variables are injected into the next API call using a combination of agents and code. A detailed walkthrough comparing this approach with traditional planning is provided in figure 3. Generating multiple API calls at once requires sophisticated planning and reasoning capabilities, which is very challenging for ordinary LLMs. Our Agent-Validator architecture simplifies this process as well by correcting errors in the planning step."}, {"title": "3.5 Other architectural optimizations", "content": "Some of our other optimizations include using a token-efficient information-preserving intermediate language for generating the API call. We find in practice that not only does this reduce cost and generation time, but it also increased model accuracy. It appears that LLMs, being trained on text which is mostly natural language, have an innate aversion to writing API calls in JSON format, and instead prefer to output something that looks more like English text. A similar result was found in [12], showing that forcing a particular structure on an LLM's output has the effect of reducing its intelligence on its primary task.\nWe also simplify all deterministic components of the API call generation task, performing them using a static module, thereby reducing the task complexity and increasing accuracy for the LLM. In some cases, the API call generation requires another task which is of comparable complexity such as a complicated math operation. However, the complicated operation cannot be done statically. In this case, we use a separate LLM-based agent to perform this task. This reduces the intelligence burden for the primary LLM, boosting the overall function calling accuracy."}, {"title": "4 Evaluation Methodology", "content": "To evaluate the performance of ThorV2, we developed a comprehensive benchmark called HubBench based on HubSpot CRM operations.\nHubspot is a CRM (Customer Relationship Management) application that allows easy management of customer and sales databases. It is one of the most popular CRM applications used by sales teams around the world. We access this tool using the Hubspot REST API, which supports 5 types of elemental operations: Create, Read, Update, Delete, and Associate (CRUDA) operations. The evaluation dataset consists of:"}, {"title": "4.1 Benchmark Dataset", "content": "To evaluate the performance of ThorV2, we developed a comprehensive benchmark called HubBench based on HubSpot CRM operations.\nHubspot is a CRM (Customer Relationship Management) application that allows easy management of customer and sales databases. It is one of the most popular CRM applications used by sales teams around the world. We access this tool using the Hubspot REST API, which supports 5 types of elemental operations: Create, Read, Update, Delete, and Associate (CRUDA) operations. The evaluation dataset consists of:\n\u2022 142 single-API queries covering CRUDA operations\n\u2022 58 complex queries requiring exactly two API calls to execute.\nSome sample queries from this dataset are shown in figure 4. These queries have been created to represent a wide range of real-world CRM tasks, ensuring a thorough evaluation of function calling capabilities."}, {"title": "4.2 Evaluation Metrics", "content": "We assess the performance of the models using four key metrics:\n\u2022 Accuracy: The percentage of queries for which a perfect API call is generated.\n\u2022 Reliability: The percentage of queries for which the API success response remains consistent over 10 repeated attempts."}, {"title": "4.3 Accuracy Measurement", "content": "Accuracy is a crucial metric in our evaluation, defined as the percentage of queries resulting in a perfect API call generation. A perfect API call must satisfy two conditions: it must be executable (i.e. well-formed) and it must fulfill the intended task. Our accuracy assessment employs a rigorous two-stage process:\n1. Software Evaluation: We verify whether the generated API call executes without error on the Hubspot API.\n2. Human Evaluation: Similar to the authors of [13], we find that LLMs are not great at evaluating function calling. Therefore, we add a second layer of blind human evaluation, assessing five key criteria:\n\u2022 Function Selection: Appropriateness of the chosen function for the query.\n\u2022 Task Representation: Accurate expression of the user's request in the API call.\n\u2022 Structural Integrity: Correctness and consistency of the API call structure with the Schema.\n\u2022 Functional Integrity: Provision of all essential arguments with appropriate values.\n\u2022 Instruction Containment: Absence of extraneous harmful or undesired operations.\nAn API call is considered correct only if it satisfies all five human evaluation criteria and passes the software evaluation. This comprehensive approach ensures a thorough assessment of the model's accuracy in generating API calls."}, {"title": "4.4 Reliability Measurement", "content": "Reliability in the context of Large Language Models (LLMs) for function calling is particularly crucial, given the inherent non-deterministic nature of these models [14]. While this non-determinism can be beneficial for creative tasks, it poses challenges in function calling scenarios where consistency is paramount. In this paper, we define reliability as the consistency of the model's performance across multiple attempts. Our measurement approach is as follows:\n1. We execute the entire test suite 10 times.\n2. We identify \u201cfluctuating queries\u201d \u2013 queries that yield at least one Pass and one Fail across the 10 attempts. Queries that consistently yield the same result (all Pass or all Fail) are categorized as non-fluctuating or \u201cconsistent\".\n3. We calculate the reliability metric using the following formula:\nReliability = $\\frac{\\text{Number of Consistent Queries}}{\\text{Total Queries in Test Suite}} \\times 100%$\nIt is important to note that reliability differs from accuracy. A perfectly reliable model (100% reliability) doesn't necessarily achieve perfect accuracy; rather, it consistently produces the same results, whether correct or incorrect, across multiple runs. This reliability metric allows us to assess the model's consistency in API call generation, a critical factor in building dependable AI-driven systems for real-world applications."}, {"title": "4.5 Comparison Models", "content": "We compare ThorV2 against three state-of-the-art commercial models from leading AI firms like OpenAI and Anthropic:\n\u2022 Claude-3 Opus (Anthropic)\n\u2022 GPT-40 (OpenAI)\n\u2022 GPT-4-turbo (OpenAI)\nThese models were chosen because they were widely considered to be the best available models as of May 2024, and also because they are explicitly provided with function calling APIs. They represent the current benchmark for LLM performance and provide a robust baseline for evaluating ThorV2's capabilities. These models are hereafter referred to as \"Comparison Models\"."}, {"title": "4.6 Comparison Model Architecture", "content": "To provide a fair comparison, we implemented specific architectures for both single and multi-API function calling tasks for the comparison models (Claude-3 Opus, GPT-40, and GPT-4-turbo). These architectures are designed to leverage the models' capabilities while adhering to their standard usage patterns. It is important to note that while ThorV2 due to its versatile nature does not require separate implementations for multi-API function calling, for comparison models it is essential to provide a different architecture which explicitly takes care of planning and step-by-step execution. Without these changes, the performance of Comparison models would lag way behind (< 15% accuracy in our tests)."}, {"title": "4.6.1 Single API Function Calling Architecture", "content": "For single API function calling, we use a straightforward approach that mimics typical usage of these models for function calling tasks. This approach uses Retrieval Augmented Generation (RAG) to provide the 5 most relevant functions to the LLM. Since the goal of our study is to focus on the LLM's capabilities, we have set up the Benchmark in such a way that the 5 functions given to the LLM always contain the correct function for solving the query."}, {"title": "4.6.2 Multi-API Function Calling Architecture", "content": "For multi-API function calling, we implement a more complex architecture to handle interdependent API calls.\nThis architecture consists of the following steps:\n1. The LLM splits the input query into two tasks according to a predefined format.\n2. A RAG (Retrieval-Augmented Generation) block fetches the nearest 5 API schemas for each subquery.\n3. The LLM executes the first task, generating the first API call.\n4. An API execution block sends the first API call to the Hubspot endpoint and receives the response."}, {"title": "5 Results and Analysis", "content": "We evaluated ThorV2 against three state-of-the-art models: Claude-3 Opus, GPT-40, and GPT-4-turbo.The results for single API calling tasks are summarized in Table 1."}, {"title": "5.1 Single API Calling Performance", "content": "We evaluated ThorV2 against three state-of-the-art models: Claude-3 Opus, GPT-40, and GPT-4-turbo.The results for single API calling tasks are summarized in Table 1."}, {"title": "5.2 Multi-API Calling Performance", "content": "We also evaluated the models on more complex tasks requiring two API calls. The results for these multi-API calling tasks are presented in Table 2."}, {"title": "5.3 Scaling Laws for Latency and Cost", "content": "One of the most significant properties of ThorV2 is its superior scaling in terms of latency and cost compared to other models. Figure 9 illustrates the latency scaling for single and multi-API calling tasks."}, {"title": "5.4 Query Category-wise Accuracy Breakdown", "content": "To provide a more granular understanding of model performance, we analyzed the accuracy of each model across different categories of CRM operations: Create, Read, Update, Delete, and Associate (CRUDA).\nAs illustrated in Figure 10, our analysis reveals:\n\u2022 All models perform well on Delete and Associate operations, with high accuracy across the board.\n\u2022 ThorV2 demonstrates a significant advantage in Create and Read operations compared to other models.\n\u2022 For Update operations, ThorV2 and Claude-3 Opus show comparable performance, both outperforming the OpenAI models.\n\u2022 The OpenAI models (GPT-40 and GPT-4-turbo) struggle particularly with Create and Update operations, showing markedly lower accuracy in these categories."}, {"title": "6 Applications", "content": "The demonstrated superiority of ThorV2 over leading commercial alternatives has significant implications for businesses and end-users. The high accuracy (90.1% for single API calls and 96.55% for multi-API calls) translates to a more reliable user experience, reducing frustration arising from task failures or data mishandling.\nThe low latency of ThorV2 (2.29 seconds for single API calls and 3.55 seconds for multi-API calls) enables near-instantaneous task execution, enhancing user satisfaction and productivity. This speed advantage becomes even more pronounced in complex, multi-step tasks, where ThorV2's sublinear latency scaling shines.\nThorV2's perfect reliability score (100%) is particularly noteworthy. This consistency allows users to develop trust in the system over time, as they can rely on it to perform the same tasks consistently. From a development perspective, this reliability makes the system much easier to engineer, maintain, and improve.\nThe cost-effectiveness of ThorV2 ($1.60 per 1000 queries for single API calls) makes it an attractive option for businesses looking to implement AI assistants at scale. The significant cost savings compared to other models could be a key factor in accelerating the adoption of AI assistants across various industries."}, {"title": "6.1 Implications for Business and User Experience", "content": "The demonstrated superiority of ThorV2 over leading commercial alternatives has significant implications for businesses and end-users. The high accuracy (90.1% for single API calls and 96.55% for multi-API calls) translates to a more reliable user experience, reducing frustration arising from task failures or data mishandling.\nThe low latency of ThorV2 (2.29 seconds for single API calls and 3.55 seconds for multi-API calls) enables near-instantaneous task execution, enhancing user satisfaction and productivity. This speed advantage becomes even more pronounced in complex, multi-step tasks, where ThorV2's sublinear latency scaling shines.\nThorV2's perfect reliability score (100%) is particularly noteworthy. This consistency allows users to develop trust in the system over time, as they can rely on it to perform the same tasks consistently. From a development perspective, this reliability makes the system much easier to engineer, maintain, and improve.\nThe cost-effectiveness of ThorV2 ($1.60 per 1000 queries for single API calls) makes it an attractive option for businesses looking to implement AI assistants at scale. The significant cost savings compared to other models could be a key factor in accelerating the adoption of AI assistants across various industries."}, {"title": "6.2 Potential for Generalization to Other Domains", "content": "While our evaluation focused on HubSpot CRM operations, the principles underlying ThorV2 are domain-agnostic. The ability to perform accurate and efficient function calling is fundamental to many"}, {"title": "7 Limitations and Future Work", "content": "We identify some ways in which our present results are limited."}, {"title": "7.1 Limitations of Current Study", "content": "We identify some ways in which our present results are limited.\n\u2022 Narrow evaluation domain: The current Benchmark is constructed exclusively on the Hubspot app. Further, it only tests moderately complex queries, up to 2 API calls in length.\n\u2022 Scope of latency scaling laws: Due to time constraints, we have only tested 1-API and 2-API queries in our benchmark. However, this makes the scaling laws fragile as two data points may"}, {"title": "7.2 Future Work", "content": "Based on our discussions and the limitations noted above, the following work can be undertaken to extend our results:\n\u2022 Automated validator construction: The main engineering effort in ThorV2 is for building the validator. In future, as LLM intelligence continues to grow, we could have a more powerful LLM (e.g. GPT-5) create validators directly.\n\u2022 Extending the Benchmark: The \"HubBench\u201d benchmark can be extended to other domains. It can also be enhanced by including highly complex queries requiring 3 or more API calls.\n\u2022 Building Agents: The main goal of function calling is to enable powerful AI assistants and AI agents. We can try using this approach to build agents both on software and in the real world."}, {"title": "8 Conclusion", "content": "We introduced ThorV2, a novel architecture enhancing LLM function calling capabilities. Through comprehensive evaluation on HubSpot CRM operations, we demonstrated ThorV2's superior performance over leading commercial models in accuracy, reliability, latency, and cost efficiency. Key contributions include: A new reliability metric for consistent performance assessment, Edge-of-domain modeling approach focusing on error correction, Composite planning method for efficient multi-step tasks.\nThorV2's performance suggests a promising direction for improving LLMs' practical applicability in real-world scenarios. By addressing the critical challenge of function calling, it paves the way for more capable and reliable AI assistants across various domains. As the AI industry evolves towards more agentic systems, techniques demonstrated by ThorV2 could play a crucial role in bridging the gap between theoretical capabilities and practical applications."}, {"title": "A System Prompts and Evaluation Details", "content": null}, {"title": "A.1 Single Function Calling System Prompts", "content": null}, {"title": "A.1.1 System Prompt for Claude-Opus", "content": "1 I am hubspot owner id <owner_id>.\n2\n3 You are a smart function calling agent, You map all the information present\n\u2190 in the input query to the output API call using tools provided.\n4 You must return the output with at least two objects in the content.\n5\n6 You are amazingly smart and you will keep generating the output until the\n\u2192 stop_reason' is 'tool_use\u2019\n7 and do not end the output generation when the 'stop_reason' is 'end_turn'.\n8\n9 you must always return the name of the tool you used to generate the\n\u2192 function call in the output.\n10\n11 Do not assume any fields as required because they are present from the\n\u2192 example in the schema.\n12 In the input_schema provided in tools, pay attention to the required key as\n\u2190 they are the compulsory fields and others are optional.\n13 If the user does not provide any information, you can consider the current\n\u2192user (me) as the associated person.\n14\n15 # Rules :\n16 max filters per filterGroup allowed is 3.\n17 any timestamp should always be in the format \"yyyy-MM-dd'T'HH:mm:ss.SSS'\n\u2190 /\"\n18 current time is \"2024-05-05T00:00:00.000Z\""}, {"title": "A.1.2 System Prompt for GPT-4-Turbo / GPT-40", "content": "1 I am hubspot owner id <owner_id>.\n2\n3 # Rules :\n4 max filters per filterGroup allowed is 3.\n5 any timestamp should always be in the format \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z\n\u2190 /\"\n6 current time is \"2024-05-05T00:00:00.000Z\"\n7 If the timestamp is not provided, you can consider the current time as\n\u2192 the timestamp.\n8 If the user is not provided, you can consider the current user (me) as\n\u2192 the associated person."}, {"title": "A.1.3 Prompt Example Given to All Comparison Models", "content": "1 Search all notes with associated deal 15860461964 (include note body,\n\u2192 creation date, note title)\n2"}, {"title": "A.2 Multi-API Calling System Prompts", "content": null}, {"title": "A.2.1 Task Planning Prompt (Initial Step)", "content": "1 You are a zero-shot, chain-of-thought based logical task planner for CRM\n\u2192 Operations.\n2\n3 Given a task description, you must try to generate two steps that can be\n\u2192 used to accurately describe how to complete the task. Any context or\n\u2192 information provided in the task description must be used to generate\n\u2190 the steps.\n4\nCRM has five categories of operations Search, Create, Update, Associate,\n\u2192Delete.\n5 CRM operations are performed on objects like contacts, companies, owners,\n\u2192 associations, lineItems, quotes, products, notes, tasks, etc.\n6\n7 # Rules:\n8 You will only respond with the sequence of steps.\n9 It may be possible that the output of one task may depend on another.\n10 All the steps should be divided by a new line without indexing.\n11 the properties to be returned in each step are mentioned in the round\n\u2192 brackets with the term included\n12 Include is not necessary for owner ID.\n13\n14 Associate :\n15 In Assign/associate queries, it should be in such a way that \"Associate\nobject A ID to object B ID.\"\n16\n17 For example, if you are asked to \"Assign the 'deal' '15810400147\u2032 to\n\u2192 contact 'Gary'.\""}, {"title": "A.2.2 Query Generation Prompt (Second Step)", "content": "1 You are a zero-shot, single sentence Logical Query generating agent from\n\u2192 the given information for CRM operations.\n2\nA query can only be executed in two steps where the first step is already\n\u2192 executed, and the second step depends on the first step. If the\n\u2192 second task depends on the first query, your task is to generate a\nsingle sentence by reading the thoughts and the response of the first\nquery.\n3\nAll the queries are made for CRM operations.\n4 The query will be generated to execute five different operations Search,\n5 \u2192Create, Update, Associate, Delete.\n6\n7 If there are multiple IDS in the response of the first query, you can use\n\u2192any/all of the IDs depending on the user intent to generate the\n\u2192 second query.\n8\n9 # Rules :\n10 You must always return the output query in a \"single sentence\".\n11 You generate the query in natural language instead of mathematical or\n\u2192 technical language, without any mathematical operations\n12 You must always frame the query in such a way that the values if they can\n\u2192 be computed should be computed and used in the query.\n13 Try to fetch the values from the response of the first query and use them\nin the second query.\n14 all the queries must start with the category of the query.\n15\n16 for example, if the second thought has \"increase the deal amount by 10%\",\n17 then the query should be generated by reading the amount from api\n\u2192 response and increasing it by 10%.\n18 let's say if the amount is 1000, then the query should be \"update the deal\n\u2192 amount to 1100\".\n19\n20 Information :\n21 Keep the query as simple as possible, need not include any extra\n\u2192 information or elaborate.\n22 Current user ID must be replaced by 'owner 325420860' and this ID must be\n\u2190 used in the query to be generated instead of Current user ID.\n23 In the response objects, id or hs_object_id are the same and can be used\n\u2192interchangeably.\n24 Associating an object ID with owner ID is an 'UPDATE' query and not an\n\u2192 associate query.\n25 For the rest of the objects it is always an associate query, example\n\u2192 objects contacts, companies, owners, associations, lineItems,\n\u2192 quotes, products, notes, tasks."}]}