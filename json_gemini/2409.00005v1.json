{"title": "Csi-LLM: A Novel Downlink Channel Prediction Method Aligned with LLM Pre-Training", "authors": ["Shilong Fan", "Zhenyu Liu", "Xinyu Gu", "Haozhen Li"], "abstract": "Downlink channel temporal prediction is a critical technology in massive multiple-input multiple-output (MIMO) systems. However, existing methods that rely on fixed-step historical sequences significantly limit the accuracy, practicality, and scalability of channel prediction. Recent advances have shown that large language models (LLMs) exhibit strong pattern recognition and reasoning abilities over complex sequences. The challenge lies in effectively aligning wireless communication data with the modalities used in natural language processing to fully harness these capabilities. In this work, we introduce Csi-LLM, a novel LLM-powered downlink channel prediction technique that models variable-step historical sequences. To ensure effective cross-modality application, we align the design and training of Csi-LLM with the processing of natural language tasks, leveraging the LLM's next-token generation capability for predicting the next step in channel state information (CSI). Simulation results demonstrate the effectiveness of this alignment strategy, with Csi-LLM consistently delivering stable performance improvements across various scenarios and showing significant potential in continuous multi-step prediction.", "sections": [{"title": "I. INTRODUCTION", "content": "MASSIVE multiple-input multiple-output (MIMO) is a pivotal technology in wireless communication, greatly enhancing spectral efficiency. The performance of MIMO systems, however, is closely tied to the effectiveness of precoding, which in turn depends on the quality of the estimated instantaneous channel state information (CSI) [1]. Unfortunately, in frequency division duplex (FDD) mode, feedback delays, and in time division duplex (TDD) mode, processing delays, can result in outdated CSI. Additionally, user mobility, particularly in high-mobility scenarios, further degrades the accuracy of CSI estimation. To mitigate the performance loss due to channel aging, extensive research has focused on channel prediction, leveraging the temporal correlation between historical and future channel states [2].\nExisting temporal correlation-based channel prediction methods can be broadly categorized into statistical-based approaches [3], [4] and neural network-based techniques [5]-\n[7]. Statistical prediction methods, such as those based on the auto-regressive (AR) model [3] and Prony's method [4], rely on constructing mathematical models and applying historical data to these models. However, due to simplified channel assumptions and rapid channel variations, these traditional statistical methods often fail to provide accurate and real-time CSI predictions.\nTo overcome these limitations, recent research has shifted towards neural network-based downlink channel prediction methods, which offer a data-driven approach to more accurately model actual channels. For instance, [5] utilized fully-connected neural networks (FCNs) to predict future channels by learning from historical channel data. To address the high-dimensionality of input channels, [6] employed recurrent neu-ral networks (RNNs) to process historical channels iteratively in chronological order. To mitigate the rapid accumulation of prediction errors inherent in sequential prediction, [7] introduced a parallel prediction method that forecasts future channels over several steps simultaneously.\nHowever, these methods typically rely on fixed-length his-torical sequences as inputs, which imposes significant con-straints. The rigid structure of input and output reduces model scalability and practicality, and the challenges associated with data collection limit the potential for further enhancement.\nNote that, channel coherence time varies inversely with carrier frequency and user speed, meaning that the length of the cor-related historical sequence can fluctuate with user movement, thereby degrading model performance. Moreover, customizing a separate model for each channel condition is often inefficient, leading to increased learning and hardware costs, including memory usage and model-switching overhead.\nLarge Language Models (LLMs) like ChatGPT, GPT-4 (OpenAI, 2023) [8], and PaLM [9] represent significant mile-stones in AI development. Recently, researchers in the wireless communication field have begun investigating how to harness the unique capabilities of LLMs to optimize downstream tasks [10]. However, the training processes and data formats for LLMs, designed primarily for natural language tasks, differ substantially from those of traditional neural networks used in wireless communication. As a result, directly transferring models and converting modalities to apply LLMs in this domain may not fully exploit their powerful capabilities.\nTo design a flexible model that adapts to varying mobility scenarios while exploring the potential of LLMs in wireless communication, this letter introduces a novel LLM-based channel prediction model. This model addresses the challenge of variable input lengths by optimizing the training process and data format to align with the capabilities of LLMs. Our key contributions are as follows:\n\u2022 We propose a novel LLM-aligned optimization strategy for downlink channel prediction neural networks. This strategy aligns network architecture, data processing, and"}, {"title": "II. SYSTEM MODEL AND CSI PREDICTION", "content": "Consider a massive MIMO gNB equipped with $N_t$ antennas, serving a number of UEs with $N \\gg 1$ receiver antennas within its coverage area [11]. Orthogonal frequency division multiplexing (OFDM) is employed for downlink transmission across $N_c$ subcarriers. The OFDM system transmits $N_m \\leq \\min(N_r, N_t)$ data streams. For subcarrier $i$ and receiving antenna $j$, let $h_{i,j} \\in \\mathbb{C}^{N_t \\times 1}$ denote the channel vector, $v_{i,j} \\in \\mathbb{C}^{N_t \\times N_m}$ denote transmit precoding vector, $x_{i,j} \\in \\mathbb{C}^{N_m \\times 1}$ denote the transmitted data symbol, and $n_{i,j} \\in \\mathbb{C}$ denote the additive noise. Correspondingly, the received signal of the UE at subcarrier $i$ and receiving antenna $j$ are given by:\n$y_{i,j} = h_{i,j}v_{i,j}x_{i,j} + n_{i,j}$.\nAt the t-th transmission time step, the time-frequency response of the channel for all subcarriers and antennas is denoted by $H[t] = \\{h_1[t],...,h_i[t],...,h_{N_c}[t]\\}$, where $1 \\leq i \\leq N_c$ and $1 \\leq j \\leq N_r$.\nDownlink CSI prediction refers to the use of CSI data from the previous $l_m$ transmission time step to predict the CSI data for the next transmission time step. The modeling process is described as:\n$Train : \\hat{H}[t] = f(\\hat{H}[t-1], \\hat{H}[t-2], ..., \\hat{H}[t-l_m], \\theta_M)$,\n$Infer : \\hat{H}[t] = f(\\hat{H}[t - 1], \\hat{H}[t - 2], ..., \\hat{H}[t - l], \\theta_M)$,\nwhere $1 \\leq l \\leq l_m$ represents the variable step length during the inference stage. $\\theta_M$ refers to the learnable parameters of Csi-LLM, which are fine-tuned based on LLMs. It is important to note that in traditional downlink CSI prediction, $l_m$ is a hyperparameter that must be determined during the training stage, and the step length during the inference stage is also fixed at $l_m$. However, in Csi-LLM, $l_m$ represents the maximum step length in the collected channel data, and the length during the inference stage can be any value less than the maximum step length. This ensures maximum utilization of the training data and allows dynamic adjustment of the step length during the inference stage."}, {"title": "III. CSI-LLM", "content": "Large language foundation models are general models of language that are designed to support a large vairty of AI tasks [12]. The development of modern foundation models consists of two main stages: (1) a pre-training stage in which the model is trained at massive scale using straightforward tasks such as next token generation and (2) a post-training stage in which the model is tuned to improve specific capabilities in downstream tasks.\nOne of the key focuses in modern AI systems is how to leverage the general token sequence modeling capabili-ties acquired during the pre-training stage to enhance the performance of downstream tasks in the post-training stage. Alignment is considered one of the most effective methods to achieve this [13]. To maximize the utilization of LLMs' pattern recognition and reasoning abilities, Csi-LLM aligns the training process of LLMs in three aspects: network structure, data processing, and optimization objectives.\nThe LLM network architecture consists of three com-ponents: Embedding, Pre-trained LLM, and Classifier. Em-bedding: This component embeds input data from different modalities into a unified representation known as LLM-Token. The LLM-Token is the smallest atomic input for the Pre-trained LLM. Pre-trained LLM: Based on the Transformer deep neural network architecture, this component undergoes unsupervised training on a vast corpus of text data. It possesses a powerful next token generation capability. Classifier: This component performs post-processing on the generated next token and outputs the final modality data. As shown in Fig. 1, Csi-LLM aligns with the existing LLM network structure and is divided into three parts: CSI-Embedding, Pre-trained LLM, and Output Projection.\nAs shown in the upper left part of Fig. 1, Csi-LLM has opted for a causal decoder architecture for the Pre-trained LLM based on unidirectional attention. LLMs typically follow three mainstream architectures: causal decoder, prefix decoder, and encoder-decoder [14]. The causal decoder architecture uses a unidirectional attention mask, ensuring that each input LLM-token can only attend to past tokens and itself. This unidi-rectional attention mechanism is highly suitable for temporal prediction, as temporal prediction can only consider historical temporal information and cannot focus on future temporal information.\nSpecifically, we chose GPT-2 [15] as the core component of Csi-LLM. Compared to LLMs with billions of parameters, the earlier version developed by OpenAI, GPT-2, with its millions of parameters, is more suitable for early-stage research on LLM capabilities in wireless communication scenarios. More importantly, researchers have found that GPT-2-based time series models exhibit highly competitive performance across various temporal tasks, such as network traffic prediction, weather forecasting, and stock price prediction [16].\nCsi-LLM differs from the traditional neural network forward propagation process, aligning instead with the generation"}, {"title": "A. Network Architecture Alignment", "content": "The LLM network architecture consists of three com-ponents: Embedding, Pre-trained LLM, and Classifier. Embedding: This component embeds input data from different modalities into a unified representation known as LLM-Token. The LLM-Token is the smallest atomic input for the Pre-trained LLM. Pre-trained LLM: Based on the Transformer deep neural network architecture, this component undergoes unsupervised training on a vast corpus of text data. It possesses a powerful next token generation capability. Classifier: This component performs post-processing on the generated next token and outputs the final modality data. As shown in Fig. 1, Csi-LLM aligns with the existing LLM network structure and is divided into three parts: CSI-Embedding, Pre-trained LLM, and Output Projection.\nAs shown in the upper left part of Fig. 1, Csi-LLM has opted for a causal decoder architecture for the Pre-trained LLM based on unidirectional attention. LLMs typically follow three mainstream architectures: causal decoder, prefix decoder, and encoder-decoder [14]. The causal decoder architecture uses a unidirectional attention mask, ensuring that each input LLM-token can only attend to past tokens and itself. This unidi-rectional attention mechanism is highly suitable for temporal prediction, as temporal prediction can only consider historical temporal information and cannot focus on future temporal information.\nSpecifically, we chose GPT-2 [15] as the core component of Csi-LLM. Compared to LLMs with billions of parameters, the earlier version developed by OpenAI, GPT-2, with its millions of parameters, is more suitable for early-stage research on LLM capabilities in wireless communication scenarios. More importantly, researchers have found that GPT-2-based time series models exhibit highly competitive performance across various temporal tasks, such as network traffic prediction, weather forecasting, and stock price prediction [16].\nCsi-LLM differs from the traditional neural network forward propagation process, aligning instead with the generation method of existing LLMs. In traditional neural network ar-chitectures, all neurons in the intermediate layers participate in the computation of subsequent modules. However, in LLMs, only the last token is involved in the final Classifier module. As illustrated in Fig. 1, in Csi-LLM, among the neurons output by the Pre-trained LLM, only the last LLM-Token is passed forward to the Output Projection for the final calculation of CSI data.\nAfter aligning with the LLM network structure, Csi-LLM can handle variable-length input data. Since only the last LLM-Token participates in the Output Projection calculation process, the structure design of Output Projection is immune to the number of LLM-Tokens in the shallow network. This enables Csi-LLM to support historical sequences of any length as input and output the next step of CSI prediction results."}, {"title": "B. Data Processing Alignment", "content": "In Csi-LLM, the CSI-Embedding and Output Projection are designed to achieve the conversion between CSI data and the LLM-Token representation. The embedding process typically involves data discretization and sequence encoding. As shown in the lower left part of Fig. 1, in Text Embedding, a long text input is first tokenized into Text-Token (usually characters or phrases), which are then encoded into a numerical vector LLM-Token through a fully connected layer (the encoding strategy of GPT-2). As shown in the lower right part of Fig. 1, CSI-Embedding aligns with the embedding method of GPT-2. In this process, tokenization directly discretizes the data by time steps, with each step of CSI data corresponding to a Csi-Token. The multi-dimensional Csi-Token data is then flattened into one-dimensional linear data, and, similar to GPT-2, a fully connected layer is used to achieve compressed encoding of the data.\nThe parallel computation of the Transformer structure relies on additional Position-Tokens to provide positional informa-tion. GPT-2 employs a learnable positional encoding strategy, which is internalized into the LLM foundation model during pre-training. Therefore, Csi-LLM uses the same Position-Tokens as in the pre-training stage.\nIn the Output Projection module, Csi-LLM utilizes a non-linear fully connected layer to map LLM-Tokens to CSI data representation. Typically, LLMs perform discriminative tasks in Output Projection using fully connected layers, as the LLM-Tokens in text data form a finite, enumerable set with a limited number of characters. However, CSI data represents continuous, non-enumerable physical signals. Therefore, Csi-LLM employs a nonlinear fully connected layer in Output Projection to directly represent the data."}, {"title": "C. Optimization objectives Alignment", "content": "To maximize the use of LLM capabilities for CSI prediction tasks, the optimization objective of Csi-LLM must align with the optimization objective of LLM pre-training. Fortunately, since most language tasks can be cast as the prediction problem based on the input, the language modeling tasks used in LLM pre-training share a similar learning process with temporal prediction tasks.\nThe language modeling task (LM) is the most commonly used objective for pre-training causal decoder LLMs, such as GPT-2 [15] and PaLM [9]. Given a sequence of tokens T = T\u2081, ..., T\u2099, the LM task aims to autoregressively predict the next target tokens T\u1d62 based on the preceding tokens T_{<i} in a sequence.\nSimilarly, the channel prediction task addressed by Csi-LLM involves given CSI data over a period [$\\hat{H}[1], ..., \\hat{H}[t]$]. The objective is to autoregressively predict the CSI at the next time step $\\hat{H}[i]$ based on the preceding CSI $\\hat{H}[< i]$. Therefore, Csi-LLM departs from the traditional approach of using fixed-length historical CSI as input and single-step future CSI as output for optimization. Instead, it aligns with the next token generation process in LLM pre-training, which we refer to as next step CSI prediction. The training loss function can be expressed as:\n$loss = \\sum_{i=0}^{l_m-1} MSE(H(t - i), \\hat{H}(t - i))$,\nwhere H and $\\hat{H}$ denote the actual and predicted next step CSI, respectively."}, {"title": "IV. EXPERIMENT", "content": "1) Datasets: The dataset used in this study comes from an open mobile communication dataset\u00b9. It contains a total of four data files, corresponding to four speed scenarios: 30 km/h, 60 km/h, 120 km/h, and a mix of the three speeds. Each scenario dataset includes 21,000 samples, encompassing time-domain information over 20 transmission time steps and frequency-domain channel information for 8 physical resource blocks (PRBs), with a transmission time interval of 5 ms. The specific parameter settings are shown in Table I.\n2) Performance Indices: We use normalized mean squared error(NMSE) as the performance indices, which are defined as follows:\n$NMSE(\\hat{H}(t)) = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{|\\hat{H}(t) - H(t)|^2}{||H(t)||^2}$,\nwhere H, $\\hat{H}$ represent the actual and predicted downlink CSI."}, {"title": "B. Prediction Performance", "content": "1) One-step Prediction: In this subsection, we report the prediction accuracy of Csi-LLM and two traditional channel prediction schemes. The traditional prediction schemes are as follows:\n\u2022 No-prediction: The downlink CSI of the last time step is used as the downlink CSI of the next time step, which illustrates the phenomenon of channel aging.\n\u2022 Fixed-step-size-4/8/16 [17]: The downlink CSI from the past 4, 8, or 16 steps is used as the neural network input to predict the downlink CSI of the next time step.\nTo ensure the fairness of the experiments, Fixed-step-size-4/8/16 maintains the same architecture as Csi-LLM in terms of the embedding of raw data and the Transformer-based network body. However, its output projection module and optimization method do not align with the pre-training of LLMs but instead follow traditional neural network channel prediction schemes. The main differences from the aligned Csi-LLM are reflected in two aspects:\nFirstly, as described in Section III.A, traditional channel prediction network schemes fix the mapping between input and output, requiring all intermediate layer neurons' outputs to participate in subsequent module computations. Therefore, different input step lengths necessitate different network struc-tures for output projection. As a result, the output projection module of Fixed-step-size-4/8/16 must be adjusted according to changes in input step length and retrained end-to-end. In contrast, Csi-LLM involves only the last token in the output projection module's computation process, making its output projection module design independent of the input step length, thereby supporting any step length as input.\nSecondly, as mentioned in Section III.C, traditional channel prediction network schemes follow a typical supervised learn-ing process, where a fixed step length of historical downlink CSI is input, and the next time step's downlink CSI serves as the label. In contrast, Csi-LLM undergoes unsupervised training under autoregressive prediction.\nTable III presents the prediction results of Csi-LLM and the two traditional schemes for input step lengths of 2, 4, 8, and 16 in four speed scenarios. Due to the fixed relationship between input and output in Fixed-step-size-4/8/16, it can only perform channel prediction under one specific condition and fails in other scenarios. In contrast, Csi-LLM demonstrates stable and optimal performance in all scenarios, indicating that Csi-LLM has superior scalability and practicality compared to traditional schemes.\n2) Continuous Autoregressive Prediction: In this subsec-tion, we continue to report the performance of Csi-LLM and other traditional schemes in continuous autoregressive predic-tion of multiple time steps for downlink CSI. As described in Section I, to prevent the rapid accumulation of prediction er-rors during successive sequential channel prediction, previous work has proposed multi-step parallel prediction. Therefore, building on the previous section, we include existing multi-step parallel prediction as a comparative scheme. The traditional parallel prediction schemes are as follows:\n\u2022 Fixed-step-size-4-parallel [7]: The downlink CSI from the past 4 steps is used as the neural network input to parallel predict the downlink CSI of the next 4 time steps.\nIn this experiment, the variable input length of Csi-LLM allows historical CSI to always be retained in the input window during sequential prediction. In contrast, traditional Fixed-step-size-4 and Fixed-step-size-4-parallel schemes must have an input window of 4 steps, thus gradually removing more distant historical CSI during sequential prediction.\nIt is important to note that, compared to the optimization approach of traditional channel prediction schemes, the op-timization direction of Csi-LLM described in III.C is more suited to practical continuous channel prediction scenarios.\nAs shown in Fig. 2, the continuous autoregressive channel prediction results of Csi-LLM and the three traditional channel prediction schemes over the next 16 time steps in four different speed scenarios. The experimental results indicate that Csi-LLM exhibits better performance in mitigating performance degradation."}, {"title": "C. Ablation experiment", "content": "A fundamental difference between Csi-LLM and traditional channel prediction schemes lies in the introduction of a foundation model pre-trained on a large corpus of text. To further investigate the impact of text pre-training tasks on downlink channel prediction tasks, we compare the perfor-mance of Csi-LLM initialized randomly versus initialized from the foundation model.\nAs shown in Fig. 3, Csi-LLM derived from the foundation model exhibits more accurate downlink channel prediction performance, especially in high-speed (120 km/h) and complex mixed-speed scenarios. This indicates that the token modeling capabilities acquired during the text pre-training task can be transferred to the wireless communication domain. Additionally, the complex pattern recognition abilities learned by the foundation model in text tasks help optimize more intricate downstream tasks, enhancing the model's ability to relearn and improve."}, {"title": "V. CONCLUSION", "content": "To design a flexible model that adapts to varying mobility scenarios, we developed Csi-LLM using the GPT-2 model. Compared to traditional downlink channel prediction methods, Csi-LLM not only achieves higher prediction accuracy but also demonstrates enhanced error resilience in continuous sequen-tial prediction. Furthermore, Csi-LLM's design is aligned with the ongoing advancements in large language models, allowing it to leverage future improvements in LLM architectures and training methodologies. This alignment ensures that Csi-LLM remains a robust and scalable solution for downlink channel prediction, effectively adapting to the evolving demands of wireless communication systems. The results underscore the potential of integrating LLMs into wireless communication tasks, paving the way for new research and application oppor-tunities in this field."}]}