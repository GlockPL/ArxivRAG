{"title": "Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion", "authors": ["Lemuel Puglisi", "Daniel C. Alexander", "Daniele Rav\u00ec"], "abstract": "The growing availability of longitudinal Magnetic Resonance Imaging (MRI) datasets has facilitated Artificial Intelligence (AI)-driven modeling of disease progression, making it possible to predict future medical scans for individual patients. However, despite significant advance-ments in AI, current methods continue to face challenges including achieving patient-specific individualization, ensuring spatiotemporal consistency, efficiently utilizing longitudinal data, and managing the substantial memory demands of 3D scans. To address these challenges, we propose Brain Latent Progression (BrLP), a novel spatiotemporal model designed to predict individual-level disease progression in 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operates in a small latent space, mitigating the computational challenges posed by high-dimensional imaging data; (ii) it explicitly integrates subject metadata to enhance the individualization of predictions; (iii) it incorporates prior knowledge of disease dynamics through an auxiliary model, facilitating the integration of longitudinal data; and (iv) it introduces the Latent Average Stabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency in the predicted progression at inference time and (b) allows us to derive a measure of the uncertainty for the prediction. We train and evaluate BrLP on 11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate its generalizability on an external test set comprising 2,257 MRIs from 962 subjects. Our experiments compare BrLP-generated MRI scans with real follow-up MRIs, demonstrating state-of-the-art accuracy compared to existing methods. The code is publicly available at: https://github.com/LemuelPuglisi/BrLP.", "sections": [{"title": "1. Introduction", "content": "Neurodegenerative diseases represent one of the most pressing challenges in modern healthcare, as these conditions lead to an irreversible decline in brain function and quality of life. With no effective cures available to date, patients and caregivers face prolonged suffering, while healthcare systems struggle with escalating costs and resource demands. Tackling this crisis requires a paradigm shift toward proactive strategies that prioritize early intervention, precision medicine, and comprehensive care. These diseases are notoriously complex, displaying a wide range of neuropathological variations linked to distinct molecular subtypes (Tijms, Vromen, Mjaavatten, Holstege, Reus, van der Lee, Wesenhagen, Lorenzini, Vermunt, Venkatraghavan et al., 2024). Furthermore, they manifest unevenly across brain regions, progressing through diverse mechanisms and at varying speeds, reflecting the intricate nature of their pathophysiology (Young, Marinescu, Oxtoby, Bocchetta, Yong, Firth, Cash, Thomas, Dick, Cardoso et al., 2018). Addressing this issue requires the development of advanced tools to deepen our understanding of disease mechanisms,"}, {"title": "2. Related work", "content": "In this section, we describe prior work on spatiotemporal modeling, which can be broadly categorized into population-based and individual-based models. We then focus on individual-based models and review how previous studies have leveraged the latest advances in generative AI to produce synthetic scans for this task."}, {"title": "2.1. Population-based models", "content": "Population-based models estimate an average trajectory of disease progression in a high-dimensional space using data from a population of affected subjects. The resulting average trajectory provides an interpretable insight into the disease dynamics. A key challenge in these models is mapping individual subjects onto a common disease timeline, which cannot correspond directly to chronological age due to variations in age at disease onset and progression rate. For example, in (Schiratti, Allassonniere, Colliot and Durrleman, 2015), the authors define a general spatiotemporal model using Riemannian geometry. This method estimates the average disease trajectory as a geodesic on a Riemannian manifold and considers individual trajectories as curves parallel to the average geodesic. The method uses time reparameterization to map individuals to the shared disease timeline. The Riemannian formulation allows the application of the method to high-dimensional data, such as full brain MRIs or 3D shapes, but requires the definition of a suitable Riemannian metric. In a related study (Sauty and Durrleman, 2022b) the Riemannian metric is learned from the data, reducing the inductive bias of the model at the cost of an extra computational burden. A recent work (Sauty and Durrleman, 2022a) bridges the gap between traditional population-based models and novel deep learning techniques, using a Variational Autoencoder (VAE) to encode brain MRIs into a latent space, in which it defines a linear mixed effect model to learn the average disease trajectory from the population. Similarly, in (Chadebec, Huijben, Pluim, Allassonni\u00e8re and van Eijnatten, 2022), the authors use a VAE to project images into a latent space and fit a generative model for disease progression with a fully variational approach. These approaches can predict individual disease progression by adjusting the parameters of an average disease trajectory to align with a subject's available longitudinal data. Although this solution is effective for scalar biomarkers, it becomes overly restrictive when applied to high-dimensional data, where progression patterns can display significant variability."}, {"title": "2.2. Individual-based models", "content": "Individual-based models, also known as simulators (Ravi, Blumberg, Ingala, Barkhof, Alexander, Oxtoby, Initiative et al., 2022), aim to predict changes in high-dimensional data (e.g., a full MRI scan or 3D shape) for a given subject over a specified period and under specific conditions (e.g., in the presence of neurodegenerative disease). By operating at the individual level, these models can use each patient's age as a temporal axis to track disease progression. Generally, individual-based models offer greater flexibility compared to population-based approaches, though this flexibility often comes at the cost of reduced interpretability of the underlying disease dynamics. Most of the existing individual-based techniques leverage advances in deep generative methods to estimate the conditional distribution of future medical images given the input data. The most popular models used for this task include Generative Adversarial Networks (GANs) (Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville and Bengio, 2020), VAEs (Kingma, 2013), Normalizing Flows (NFs) (Papamakarios, Nalisnick, Rezende, Mohamed and Lakshminarayanan, 2021), and most recently, diffusion models (Ho, Jain and Abbeel, 2020). The next sections will describe these methods in greater detail."}, {"title": "2.2.1. Generative adversarial networks", "content": "GANs employ two competing neural networks a generator that produces synthetic data and a discriminator that evaluates authenticity to create increasingly realistic artificial outputs through iterative adversarial training. An"}, {"title": "2.2.2. Variational autoencoders", "content": "VAEs are deep generative models that learn to map data to and from a structured probabilistic latent space, enabling both compression and generation. In (He, Ang and Tward, 2024), the authors propose a double-encoder conditional VAE for predicting future MRI scans based on baseline MRI and subject metadata. The model also facilitates disease classification by estimating the posterior distribution when both baseline and follow-up MRIs are provided. Although demonstrated using 3D brain MRIs, the experiments are performed at low resolution (2 mm\u00b3) to mitigate computational costs. Furthermore, the model does not address other challenges, such as the utilization of longitudinal data and enforcing the spatiotemporal consistency of the predicted progression."}, {"title": "2.2.3. Normalizing flows", "content": "NFs use sequences of invertible transformations to convert simple distributions into complex ones while main-taining exact likelihood evaluation. Based on this, (Wilms, Bannister, Mouches, MacDonald, Rajashekar, Langner and Forkert, 2022) introduces a bidirectional NF model that links brain morphology to age, potentially incorporating additional variables, such as disease diagnosis. This approach enables the generation of follow-up images at a target age and the estimation of brain age from a given image. Their model leverages NFs and, similar to CounterSynth (Pombo et al., 2023), utilizes diffeomorphic deformations to represent structural changes. While this bidirectional framework holds promise, it cannot utilize longitudinal data if available, and it lacks mechanisms to enforce spatiotemporal consistency."}, {"title": "2.2.4. Diffusion models", "content": "In recent years, diffusion models have emerged as a major breakthrough in generative AI, gaining significant attention for their state-of-the-art image synthesis capabilities and stable training processes, which avoid the challenges associated with adversarial approaches. A Denoising Diffusion Probabilistic Model (DDPM) (Ho et al., 2020) is a deep generative model with two Markovian processes: forward diffusion and reverse diffusion. In the forward process, Gaussian noise is incrementally added to the original image xo over T steps. At each step t, noise is introduced to the current image x_{t-1} by sampling from a Gaussian transition probability defined as $q(x_t | x_{t-1}):= \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_tI)$, where \u03b2t follows a variance schedule. If T is sufficiently large, xT will converge to pure Gaussian noise $x_T \\sim \\mathcal{N}(0, I)$. The reverse diffusion process aims to revert each diffusion step, allowing the generation of an image from the target distribution starting from pure noise xT. The reverse transition probability has a Gaussian closed form, $q(x_{t-1} | x_t, x_0) = \\mathcal{N}(x_{t-1} | \\tilde{\\mu}(x_0, x_t), \\beta_t)$, conditioned on the real image x0. As x0 is not available during generation, a neural network is trained to approximate $\\mu_t(x_t, t) \\approx \\tilde{\\mu}(x_0, x_t)$. Following the work proposed in (Ho et al.,"}, {"title": "3. Methods - Brain Latent Progression (BrLP)", "content": "We now introduce the architecture of BrLP, comprising four key components: an LDM, a ControlNet, an auxiliary model, and a LAS block, each described in successive paragraphs. These four components, summarized in Figure 1, collectively address the challenges outlined in the introduction. In particular, the LDM is designed to generate random 3D brain MRIs that conform to specific covariates, while ControlNet aims to specialize these MRI scans to specific anatomical structures of a subject. Additionally, the auxiliary model leverages prior knowledge of disease progression to improve the precision in predicting the volumetric changes of specific brain regions. Finally, the LAS block is used during inference to improve spatiotemporal consistency, as well as to derive a measure of uncertainty for the predictions."}, {"title": "3.1. LDM - learning the brain MRI distribution", "content": "Building upon (Pinaya et al., 2022), we train an LDM aimed to generate 3D brain MRIs mirroring specific covariates c = (s, v), where s includes subject-specific metadata (age, sex, and cognitive status) while v encompasses progression-related metrics such as volumes of brain regions (hippocampus, cerebral cortex, amygdala, cerebral white matter, and lateral ventricles) linked to AD progression (Pini, Pievani, Bocchetta, Altomare, Bosco, Cavedo, Galluzzi, Marizzoni and Frisoni, 2016). The construction of the LDM is a two-phase process. Initially, we train an autoencoder (E, D) (block A in Figure 1) designed to produce a latent representation z = E(x) for each brain MRI x within our dataset. Subsequently, we train a conditional UNet (block B in Figure 1), represented as ee, with network parameters \u03b8, aimed to estimate the noise $\\epsilon_\\theta(z_t, t, c)$ necessary for reverting from zt to zt\u22121, as mentioned in Section 2.2.4. We train ee by minimizing the loss $L_\\epsilon$ (Eq. 1). Covariates c are integrated into the network as conditions using a cross-attention mechanism, in line with (Rombach et al., 2022). The generation process initiates by sampling random Gaussian noise $z_T \\sim \\mathcal{N}(0, I)$ and then iteratively reverses each diffusion step $z_t \\rightarrow z_{t-1}$ for t = T, ..., 1. Decoding the output z0 from the final step t = 1 yields a synthetic brain MRI $x = D(z_0)$ that follows the specified covariates c."}, {"title": "3.2. ControlNet - conditioning on subject brain MRI", "content": "The LDM provides only a limited degree of control over the generated brain MRI via the covariates c, and it does not allow for conditioning the model on individual anatomical structures. The purpose of this block is to extend the capabilities of the LDM to encompass this additional control. To achieve this, we use ControlNet (Zhang et al., 2023), (block C in Figure 1) a neural network designed to work in conjunction with the LDM. We conceptualize ControlNet and LDM as a unified network $\\epsilon_{\\theta,\\phi}$, where \u03b8 represents the fixed network's parameters of the LDM and \u03c6 denotes the trainable network's parameters of ControlNet. As in the LDM, $\\epsilon_{\\theta,\\phi}$ is still used to predict the noise $\\epsilon_{\\theta,\\phi}(z_t, t, c, z)$ in the reverse diffusion step $z_t \\rightarrow z_{t-1}$, now incorporating z = E(x) as a condition to encompass the structure of the target brain x during the generation process. To train ControlNet, we use the latent representations z(A) and z(B) from pairs of brain MRIs of the same patient taken at different ages A < B. The covariates c(B) associated with z(B) are known and used as target covariates. Each training iteration involves: i) sampling t ~ U[1,T], ii) performing t forward diffusion steps $z_t^{(B)} \\rightarrow z_t^{(B)}$, iii) predicting the noise $\\epsilon_{\\theta,\\phi}(z_t^{(B)}, t, c^{(B)}, z^{(A)})$ to revert $z_t^{(B)} \\rightarrow z_{t-1}^{(B)}$, and iv) minimizing the loss $L_\\epsilon$ (Eq. 1)."}, {"title": "3.3. Proposed auxiliary model - leveraging disease prior knowledge", "content": "AD-related regions shrink or expand over time and at different rates (Pini et al., 2016). Deep-learning-based spatiotemporal models strive to learn these progression rates directly from brain MRIs in a black-box manner, which can be very challenging. To aid this process, we propose incorporating prior knowledge of volumetric changes directly into our pipeline. To do so, we exploit an auxiliary model fy (block D in Figure 1) able to predict how the volumes of AD-related regions change over time and provide this information to the LDM via the progression-related covariates v. The choice of our auxiliary model is tailored to two scenarios, making BrLP flexible for both cross-sectional and longitudinal data. For subjects with a single scan available at age A, we employ a regression model to estimate volumetric changes $\\upsilon^{(B)} = f_\\upsilon(c^{(A)})$ at age B. For subjects with n past visits accessible at ages A1, ..., An, we predict $\\upsilon^{(B)} = f_\\upsilon(c^{(A_1)}, ..., c^{(A_n)})$ using Disease Course Mapping (DCM) (Schiratti, Allassonni\u00e8re, Colliot and Durrleman, 2017; Koval, B\u00f4ne, Louis, Lartigue, Bottani, Marcoux, Samper-Gonzalez, Burgos, Charlier, Bertrand et al., 2021),"}, {"title": "3.4. Inference process", "content": "Let x(A) be the input brain MRI from a subject at age A, with known subject-specific metadata s(A) and progression-related volumes v(A) measured from x(A). As summarized in block E from Figure 1, to infer the brain MRI x(B) at age B > A, we perform six steps: i) predict the progression-related volumes $\\hat{\\upsilon}^{(B)} = f_\\upsilon(c^{(A)})$ using the auxiliary model; ii) concatenate this information with the subject-specific metadata s(B) to form the target covariates c(B) = (s(B), $\\hat{\\upsilon}^{(B)}$); iii) compute the latent z(A) = E(x(A)); iv) sample random Gaussian noise $z_T \\sim \\mathcal{N}(0, I)$; v) run the reverse diffusion process by predicting the noise $\\epsilon_{\\theta,\\phi}(z_t, t, c^{(B)}, z^{(A)})$ to reverse each diffusion step for t = T, ..., 1; and finally vi) employ the decoder D to reconstruct the predicted brain MRI $\\hat{x}^{(B)} = D(z_0)$ in the imaging domain. This inference process is summarized into a compact notation $\\hat{z}^{(B)} = I(z_T, x^{(A)}, c^{(A)})$ and $\\hat{x}^{(B)} = D(\\hat{z}^{(B)})$."}, {"title": "3.5. Enhance inference via proposed Latent Average Stabilization (LAS)", "content": "Variations in the initial value $x \\sim \\mathcal{N}(0, I)$ can lead to slight discrepancies in the results produced by the inference process. These discrepancies are especially noticeable when making predictions over successive timesteps, manifesting as irregular patterns or non-smooth transitions of progression. Therefore, we introduce LAS (block F in Figure 1), a technique to improve spatiotemporal consistency by averaging different results of the inference process. In particular, LAS is based on the assumption that the predictions $\\hat{z}^{(B)} = I(z_T, x^{(A)}, c^{(A)})$ deviate from a theoretical mean $\\mu^{(B)} = [\\mathbb{E}[\\hat{z}^{(B)}]$. To estimate the expected value $\\mu^{(B)}$, we propose to repeat the inference process m times and average the results:\n$\\mu^{(B)} = \\mathbb{E}_{z_T \\sim \\mathcal{N} (0, I)} [I(z_T, \\iota(z, x^{(A)}, c^{(A)})] \\approx \\frac{1}{m} \\sum_i I(z_{Ti}, x^{(A)}, c^{(A)})$.\nSimilar to before, we decode the predicted scan as $\\hat{x}^{(B)} = D(\\mu^{(B)})$."}, {"title": "3.6. Quantifying the uncertainty of the prediction", "content": "Building on the assumption of the LAS algorithm, we interpret the spread of predictions around the theoretical mean as a measure of prediction uncertainty. Once the mean $\\mu^{(B)}$ is approximated using LAS, we estimate the standard deviation of the predictions as follows:\n$\\sigma^{(B)} \\approx \\sqrt{\\frac{\\sum_i (z_i^{(B)} - \\mu^{(B)})^2}{m - 1}}$.\nWe then average the components of $\\sigma^{(B)}$ into a scalar uncertainty measure, defined as u(B)."}, {"title": "3.7. Implementation settings", "content": "The architectures of the autoencoder, the UNet and the ControlNet are taken from the Generative Models library (Pinaya, Graham, Kerfoot, Tudosiu, Dafflon, Fernandez, Sanchez, Wolleb, da Costa, Patel et al., 2023) available in MONAI (Cardoso, Li, Brown, Ma, Kerfoot, Wang, Murrey, Myronenko, Zhao, Yang et al., 2022). The LDM block, which includes the autoencoder (E, D) and the UNet es, follows the same settings proposed in (Pinaya et al., 2022). The autoencoder is fine-tuned from their available pre-trained model\u00b9. The training is performed using the Adam optimizer with a learning rate of 10\u20134 and a batch size of 8. The encoder & maps the input 3D brain MRI of shape 122\u00d7146\u00d7122 to latent representations of shape 3 \u00d7 16 \u00d7 20 \u00d7 16. The UNet \u0454\u03b8 is randomly initialized and trained using the AdamW optimizer with a learning rate of 2.5 \u00d7 10-5 and a batch size of 16. During training, we use T = 1000 and a scaled linear \u03b2 noise schedule from \u03b2\u2081 = 0.0015 to \u03b2\u03c4 = 0.0205. The parameters $ of the ControlNet are randomly initialized and trained using the AdamW optimizer, with a learning rate of 2.5 \u00d7 10-5 and a batch size of 16. The conditioning on the starting age A is achieved by concatenating A with the latent vector z(4) along the channel axis. The LDM's"}, {"title": "3.8. MRI preprocessing", "content": "Each T1w brain MRI used in our study is pre-processed using: N4 bias-field correction (Tustison, Avants, Cook, Zheng, Egan, Yushkevich and Gee, 2010), skull stripping (Hoopes, Mora, Dalca, Fischl and Hoffmann, 2022), affine registration to the MNI space, intensity normalization (Shinohara, Sweeney, Goldsmith, Shiee, Mateen, Calabresi, Jarso, Pham, Reich, Crainiceanu et al., 2014) and resampling to 1.5 mm\u00b3. The volumes used as progression-related covariates and for our subsequent evaluation are calculated using SynthSeg 2.0 (Billot, Greve, Puonti, Thielscher, Van Leemput, Fischl, Dalca, Iglesias et al., 2023) and are expressed as percentages of the total brain volume to account for individual differences."}, {"title": "4. Experiments and results", "content": "In this section, we first describe the datasets and evaluation metrics used in our study. We then present an extensive evaluation of BrLP through five distinct experiments: an ablation study examining BrLP's components and hyperparameters, a comparative analysis against established baseline methods, an investigation of the impact of cognitive status conditioning, an assessment of our proposed uncertainty metric, and an exploration of BrLP's potential to reduce Type II errors in clinical trials."}, {"title": "4.1. Internal and external datasets", "content": "We collected a large internal dataset of T1w brain MRIs for training and internal evaluation, as well as an external dataset to further validate our findings on out-of-distribution data. For the internal dataset, we combined three publicly available longitudinal datasets: ADNI 1/2/3/GO (1,990 subjects) (Petersen, Aisen, Beckett, Donohue, Gamst, Harvey, Jack, Jagust, Shaw, Toga et al., 2010), OASIS-3 (573 subjects) (LaMontagne, Benzinger, Morris, Keefe, Hornbeck, Xiong, Grant, Hassenstab, Moulder, Vlassenko et al., 2019), and AIBL (242 subjects) (Ellis, Bush, Darby, De Fazio, Foster, Hudson, Lautenschlager, Lenzo, Martins, Maruff et al., 2009). This internal dataset comprises 11,730 T1w brain MRI scans from 2,805 subjects, with each subject having at least two MRIs acquired during different visits. The average time interval between the initial and follow-up visits is 4.3 years (SD = 3.1), with a maximum span of 16 years. Age, sex, and cognitive status data were available for all subjects. The average age is 74 \u00b1 7 years, and 53% of the subjects are male. Based on the final visit, 43.8% of subjects are classified as CN, 25.7% exhibit or develop MCI, and 30.5% exhibit or develop AD. We randomly split the dataset into a training set (80%), a validation set (5%), and a test set (15%) with no overlapping subjects. The validation set is used for early stopping during training. For the external dataset, we used data from the NACC longitudinal study (Beekly, Ramos, Lee, Deitrich, Jacka, Wu, Hubbard, Koepsell, Morris, Kukull et al., 2007), including 2,257 T1w MRIs from 962 subjects. The average time interval between the initial and follow-up visits is 3.8 years (SD = 2.3), with a maximum span of 13 years. The average age is 68 \u00b1 11 years, and 38% of the subjects are male. Based on the final visit, 72% of subjects are classified as CN, 14.1% exhibit or develop MCI, and 14% exhibit or develop AD. Data from the external dataset is used solely for evaluation."}, {"title": "4.3. Ablation studies", "content": "First, we evaluate how the LAS hyperparameter m influences BrLP's predictive accuracy. As shown in Figure 2, our analysis across increasing values of m (m \u2208 [1,2,4,8, 16, 32, 64]) reveals consistent improvements in terms of both image-based and volumetric metrics. In particular, increasing m from 2 to 64 leads to gradual improvements: MSE decreases by 7%, volumetric errors reduce by 3% on average, and SSIM improves by 0.68%. Paired t-tests (a = 0.05) confirm that improvements are statistically significant for all metrics except for volumetric errors in the amygdala and CSF. However, this performance gain comes with increased computational demands. As m increases, so does the computation time, as shown in Figure 2. These results highlight the trade-off between accuracy and available computational resources. Unless otherwise specified, we set m = 64 for all experiments from this point onward. Next,"}, {"title": "4.4. Quantitative and qualitative comparisons with baseline methods", "content": "In this experiment, we compare our best BrLP setup with existing baseline methods. We categorize existing methods into single-image (cross-sectional) and sequence-aware (longitudinal) approaches. Single-image approaches, such as DaniNet and CounterSynth, predict progression using just one brain MRI as input. Sequence-aware methods, like SADM, leverage a series of prior brain MRIs as input. Due to the large memory demands of SADM, we have re-implemented it using an LDM, allowing the comparisons in our experiments. We refer to it as Latent-SADM. To evaluate all these methods, we conduct two separate experiments. In single-image methods, we predict all subsequent MRIs for a subject based on their initial scan. For sequence-aware methods, we use the first half of a subject's MRI visits to predict all subsequent MRIs in the latter half. In single-image settings, our approach uses an LM as the auxiliary model (detailed in Appendix A.1). In contrast, for sequence-aware experiments, we employ the last available MRI in the sequence as the input for BrLP and fit a logistic DCM on the first half of the subject's visits as the auxiliary model (detailed in Appendix A.2). We conduct all experiments on both internal and external test sets. Table 2 presents evaluation metrics for the internal test set, while Table 3 shows metrics for the external test set. Each table reports statistical significance for performance differences between BrLP and baseline methods, using a paired t-test with Bonferroni correction. We report results for the entire test set (all subjects) and further stratify them by cognitive status (CN subjects only, MCI subjects only, AD subjects only), allowing us to analyze potential prediction biases.\nOn the internal test set, our method demonstrates a substantial improvement over baseline methods, achieving an average MSE reduction of 61.67% (SD = 10.27%) and an average SSIM increase of 21.51% (SD = 17.89%). For"}, {"title": "4.5. Evaluating the impact of incorrect conditioning on cognitive status in BrLP predictions", "content": "Due to the presence of a prediction bias towards healthy aging, we design an experiment to assess whether BrLP's predictions are correctly influenced by altering the cognitive status of the input subject. Specifically, we conduct quantitative experiments where all AD subjects are conditioned as if they were CN, and we compare these results to those obtained with the correct conditioning. We perform this experiment both in single-image and sequence-aware settings and using both the internal and external test sets. We report the results for this experiment in Table 4. As expected, our findings show that volumetric errors increase when an incorrect cognitive status is provided, especially"}, {"title": "4.6. Analysis of the proposed uncertainty measure", "content": "In the next two experiments we evaluate the suitability of the uncertainty measure proposed in Section 3.6. First, we examine the relationship between uncertainty and prediction distance, defined as the temporal gap between the age at input MRI and the target age. Intuitively, uncertainty should increase with prediction distance due to the considerable temporal heterogeneity inherent in disease progression. Second, we analyze the relationship between uncertainty and prediction error using image-based metrics. Also in this case, we expect the error to be higher in predictions with higher uncertainty. We use linear mixed-effects models to investigate on these relationships, and we report the fixed effect coefficient \u03b2 along with the p-value p."}, {"title": "4.6.1. Uncertainty increases with prediction distance", "content": "Here, we analyze the relationship between prediction distance and uncertainty. For each predicted follow-up MRI, the prediction distance (AB) is calculated as the difference between the follow-up age (B\u2081) and the starting age (A). The final uncertainty difference (Au\u2081) is computed as the difference between the uncertainty at the i-th prediction (u\u2081) and the uncertainty at the first prediction (u\u2081). We use AB and B2 as independent variables to predict Au\u2081, with subject ID as a random effect. We find that the uncertainty significantly increases with prediction distance A\u0392; (\u03b2 = 0.243, p < 0.001) and AB\u00b2 (\u03b2 = 0.460, p < 0.001). Figure 4-A shows the fixed effects from the mixed-effects model, along with the observed values of these variables for individual subjects."}, {"title": "4.6.2. Uncertainty associates with prediction error", "content": "Here, we analyze the relationship between the proposed uncertainty measure and image-based metrics (MSE and SSIM). Specifically, we use the square of the uncertainty (u\u00b2) as the independent variable to predict the image-based metrics, while incorporating subject ID as a random effect. Our results demonstrate a significant positive correlation between MSE and u\u00b2 (\u03b2 = 0.157, p < 0.001), indicating that higher uncertainty corresponds to increased mean squared error. At the same time, we find that SSIM exhibits a significant negative correlation with u\u00b2 (\u03b2 = \u22122.008, p < 0.001), suggesting that higher uncertainty is associated with decreased structural similarity. We illustrate these relationships in Figure 4-B and Figure 4-C, which present both the fixed effects estimated by our model and the observed values from individual subjects. These findings collectively support the utility of our uncertainty measure as a predictor of image quality metrics in the context of BrLP predictions."}, {"title": "4.7. Downstream application: avoiding type II errors in clinical trials using BrLP", "content": "Type II errors in clinical trials occur when a study fails to demonstrate the efficacy of a treatment that actually has significant effects. This can result in substantial financial losses and the failure to bring potentially beneficial drugs to market. One contributing factor to Type II errors is the inclusion of patients whose disease progression is too slow to observe treatment effects within the trial duration. Consequently, there is growing interest in identifying and selecting \"fast progressors\" - subjects whose disease advances more rapidly. Predictive tools such as BrLP can be used for this downstream application, providing predictive capabilities to assess disease progression at an individual level and facilitating the identification of fast progressors.\nWe evaluate BrLP's ability to identify these fast progressors by designing a retrospective study involving all subjects with two-year follow-up MRI data from both internal (154 subjects) and external (165 subjects) datasets. Ground truth is established by ranking subjects based on the largest observed hippocampal atrophy, quantified as the relative reduction in hippocampal volume. We compare BrLP to a standard regression-based strategy (detailed in Section A.1). Specifically, BrLP predicts each subject's two-year follow-up MRI to estimate atrophy rates based on the"}, {"title": "5. Discussion", "content": "In this work, we propose BrLP, a novel individual-based spatiotemporal model that leverages recent advances in diffusion models to address the limitations of existing methodologies. Our approach is designed to work with both cross-sectional and longitudinal data inputs. By utilizing compact latent representations derived from full 3D brain MRIs, BrLP significantly reduces memory requirements, allowing it to operate on consumer-grade GPUs. This efficiency makes the method accessible for use in cost-sensitive environments, such as hospitals and research centers.\nIn Section 4.5, we demonstrate that BrLP effectively exploits the conditioning covariates, yielding better quantita-tive results when using the correct cognitive status of each test subject. In Section 4.3, we show that incorporating the auxiliary model enhances BrLP's performance, highlighting the importance of exploiting longitudinal data when developing spatiotemporal models. Additionally, we illustrate in the same section that implementing the LAS algorithm improves overall performance, though it introduces a trade-off between computational overhead due to the hyperparameter m\u2014and prediction accuracy. Section 4.6 demonstrates that the uncertainty measure derived from the LAS algorithm is associated with both prediction distance and prediction error, offering a potential tool for assessing"}, {"title": "6. Conclusion", "content": "This work introduces BrLP, a 3D spatiotemporal model that accurately captures neurodegenerative disease progression patterns by predicting individual 3D brain MRI evolution. While we focused on brain MRI applications, BrLP's potential extends to other imaging modalities and progressive diseases. Moreover, the model can potentially incorporate additional covariates, such as genetic data, for enhanced individualization. Our experiments demonstrate how BrLP can be used for patient selection in clinical trials to reduce the risk of type II errors. We believe that its application also extends to post-trial analysis, where, by generating digital twins of participants, BrLP could simulate untreated disease trajectories, enabling individualized treatment effect assessment. This approach could reduce the reliance on control groups and mitigate ethical concerns related to withholding potential therapeutic benefits."}, {"title": "A. Auxiliary models", "content": "In this section, we provide details about the different models used in the experiment section as auxiliary models."}, {"title": "A.1. Linear Model (LM)", "content": "For the LM, we adopted a linear regression approach that minimizes the Huber loss (implemented as the HuberRegressor 1 in the scikit-learn Python package) to reduce sensitivity to outliers. The model takes as input age A, age B, the subject's diagnosis, sex, and progression-related volumes va at age A to predict the progression-related volumes UB at age B."}, {"title": "A.2. Disease Course Mapping"}]}