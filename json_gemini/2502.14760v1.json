{"title": "EQUIVAMAP: LEVERAGING LLMS FOR AUTOMATIC EQUIVALENCE CHECKING OF OPTIMIZATION FORMULATIONS", "authors": ["Haotian Zhai", "Connor Lawless", "Ellen Vitercik", "Liu Leqi"], "abstract": "A fundamental problem in combinatorial optimization is identifying equivalent formulations, which can lead to more efficient solution strategies and deeper insights into a problem's computational complexity. The need to automatically identify equivalence between problem formulations has grown as optimization copilots\u2014systems that generate problem formulations from natural language descriptions-have proliferated. However, existing approaches to checking formulation equivalence lack grounding, relying on simple heuristics which are insufficient for rigorous validation. Inspired by Karp reductions, in this work we introduce quasi-Karp equivalence, a formal criterion for determining when two optimization formulations are equivalent based on the existence of a mapping between their decision variables. We propose EquivaMap, a framework that leverages large language models to automatically discover such mappings, enabling scalable and reliable equivalence verification. To evaluate our approach, we construct the first open-source dataset of equivalent optimization formulations, generated by applying transformations such as adding slack variables or valid inequalities to existing formulations. Empirically, EquivaMap significantly outperforms existing methods, achieving substantial improvements in correctly identifying formulation equivalence.", "sections": [{"title": "1 Introduction", "content": "Combinatorial optimization lies at the heart of many of today's most pressing challenges in operations research, theoretical computer science, and machine learning. Its applications range from classic problems such as shortest path [22] and maximum flow [31] to modern challenges in neural architecture search [12] and hyperparameter optimization [20].\nA fundamental problem in combinatorial optimization is identifying equivalent formulations. Historically, establishing equivalence has played a pivotal role in unifying problem-solving techniques and advancing theoretical characterizations of a problem's computational complexity. In theoretical computer science, equivalence between problems underpins the concept of NP-completeness [9, 19], which unifies many seemingly distinct problems such as SAT, Vertex Cover, and Subset Sum-into the same equivalence class. This unification enables researchers to prioritize the development of algorithms for canonical problems while ensuring their applicability across equivalent problems. Similarly, in applied fields such as network design [18] and semiconductor scheduling [13], recognizing equivalence between optimization problems has historically facilitated the transfer of algorithms, reducing duplication of effort.\nThe advent of large language models (LLMs) has exposed a new frontier in combinatorial optimization, introducing opportunities to automate problem formulation, while also presenting new challenges-chief among them, the need for reliable equivalence checking. Recent research has focused on developing optimization copilots, systems that automate the translation of natural language descriptions into formal optimization formulations, particularly for mixed-integer"}, {"title": "2 Background and Related Work", "content": "Our work connects important lines of research on combinatorial optimization (especially MILPs), LLMs for MILP modeling, and automatic equivalence-checking methods for optimization formulations."}, {"title": "2.1 Combinatorial Optimization and MILPS", "content": "Combinatorial optimization (CO) broadly deals with finding an optimal object from a finite (or countably infinite) set of feasible candidates. Such problems arise in diverse fields, including operations research, computer science, and engineering, where discrete variables model decisions in practical scenarios such as routing, scheduling, or allocation of limited resources [28].\nA foundational tool for combinatorial optimization is mixed-integer linear programming (MILP), formulated as:\n\nmin_{x \\in \\mathbb{R}^p \\times \\mathbb{Z}^{n-p}} cx\n\nsubject to Ax \\circ b, l \\leq x \\leq u,\n\nwhere x is the vector of decision variables, c is the cost vector, A is the constraint coefficient matrix, and b is the vector of constraint bounds. The notation Ax \\circ b represents a system of linear constraints, where \\circ denotes relational operators from the set {<, >, =}. The variables x are partitioned into p continuous variables and n p integer variables. Let x* denote an optimal solution to (1), and let z* = cTx* be the corresponding optimal objective value. If all decision variables are continuous (p = n), the problem is a linear program (LP). MILPs capture many prominent combinatorial problems such as the traveling salesman problem (TSP) [10], knapsack problem [29], and network design problems [18].\nMany fundamental CO problems\u2014including TSP and Knapsack-are known to be NP-hard. A key contribution to the theory of NP-completeness was provided by Karp [19], who demonstrated that a number of widely studied problems are mutually reducible in polynomial time (often referred to as \"Karp reductions\"). These reductions establish deep"}, {"title": "2.2 Language Models for MILP Modeling", "content": "The use of language models for MILP modeling has sparked considerable interest in the AI-for-OR community. The NL4Opt competition [30] focused on using natural language processing (NLP) methods to formulate optimization problems based on their text descriptions. More recently, with the advent of LLMs, a number of LLM-based optimization copilots aim to automate MILP modeling [27, 3, 26, 39, 15, 17, 38]. Both the Chain-of-Experts [36] and OptiMUS [2] frameworks designed LLM-based multi-agent systems to automate the modeling of complex optimization problems by leveraging the reasoning capabilities of the LLMs. Tang et al. [33] further demonstrated the potential of LLMs by fine-tuning open-source models with synthetic data tailored for modeling optimization problems, achieving significant performance improvements over baseline methods. Building on these capabilities, LLM-powered chatbots have been used to allow users to interact with optimization models in a number of contexts including supply chain management [25], meeting scheduling [24], debugging infeasible models [5], and improving solver configurations [23]. These advancements highlight why LLMs are particularly suitable for MILP modeling: their ability to process and generate structured information from natural language aligns well with the requirements of optimization problem formulation. The rapid development of optimization copilots underscores the need for reliable, scalable evaluation techniques."}, {"title": "2.3 Existing Automatic Equivalence Checking Methods", "content": "The central task of evaluating optimization copilots is automatically checking whether the generated formulation is equivalent to a ground-truth correct one. The earliest method used in the NL4OPT benchmark [30] for evaluating formulation equivalence is canonical accuracy, which looks at direct equivalence between declarations (e.g., objective, constraints) between a reference correct formulation and a generated formulation. This method is sensitive to permutations of the order of the declarations in a formulation and fails when multiple valid formulations exist for the same problem. The method used in benchmarks such as NLP4LP [2], MAMO [16], and IndustryOR [33] is execution accuracy, which evaluates whether two MILP formulations are equivalent by solving them (using a MILP solver such as Gurobi) and checking if they have the same optimal objective value. Execution accuracy is sensitive to variable re-scaling, which can create inconsistencies even when the formulations are functionally equivalent. To address these issues, recent approaches utilize Graph Edit Distance [37] and a modified Weisfeiler-Lehman (WL) test [34] to measure structural similarity between the generated and reference formulations. These methods offer insights into equivalence beyond the optimal objective value but have limitations. They are particularly sensitive to structural modifications, such as adding cutting planes, which keeps the formulation equivalent but changes its structural information. Beyond these methods, Steever et al. [32] proposed an image-based approach to detect structural similarity among large-scale MILPs."}, {"title": "3 Methodology", "content": "This section details the theoretical foundation of formation equivalence and the design of our method for leveraging LLMs to automatically check such equivalence\u2014EquivaMap. In the general setup, we have two formulations a and a' corresponding to the same (feasible) optimization problem P, with optimal objective values z* and z'* respectively. For example, Figure 1 presents two formulations a and a' of an optimization problem P-the stable set problem. Our method aims to evaluate the equivalence of a and a' for a given instantiation of the problem. In Figure 1, an instantiation of P would be defined by a specific input graph."}, {"title": "3.1 Pitfalls of Existing Equivalence Checking Methods", "content": "We discuss existing methods for evaluating formulation equivalence, including canonical accuracy, execution accuracy, and the WL-test, and exhibit settings where these methods fail.\nCanonical accuracy is based on matching declarations between predicted and reference programs, where a declaration represents either an optimization objective or a constraint [30].\nDefinition 3.1 (Canonical Accuracy). Given a reference declaration d (objective or constraint) and a generated declaration d, they are said to be matched if d = d. Let D and D denote the sets of reference and generated declarations, respectively. A False Positive (FP) is a generated declaration d that is unmatched, while a False Negative (FN) is a reference declaration d that is unmatched. The canonical accuracy is defined as:\n\n1 - \\frac{min(|FP| + |FN|, |D|)}{|D|}"}, {"title": "3.2 MILP Equivalence Based on Karp Reduction", "content": "Towards a more formal notion of MILP formulation equivalence, we introduce a new definition inspired by a classical tool from complexity theory called a Karp Reduction:\nDefinition 3.4 (Karp Reduction). Two decision problems P, Q are said to be equivalent if there exists a function f that maps arbitrary instances of P to Q such that:\n\u2022 If p is a yes-instance of P, then f (p) is a yes-instance of Q,\n\u2022 If p is a no-instance of P, then f(p) is a no-instance of Q, and\n\u2022 f can be computed in polynomial time.\nA Karp reduction can be used to show that two decision problems are equivalent (i.e., a solution to one can be used to find a solution to the other). These reductions hold for arbitrary instances of the two decision problems, but we leverage a similar approach to establish the equivalence between two specific formulations of an MILP problem instance. Consider two optimization problem formulations a, a' that correspond to the same optimization problem P. Our goal is to formally check that an optimal solution to one formulation can be used to generate an optimal solution to the other formulation for a specific instantiation of the problem. Unlike traditional Karp reductions, which define mappings for arbitrary instances, we focus on instance-specific mappings. Moreover, our approach maps between solutions of the optimization problem rather than the instance iteself.\nWe also relax the condition that a no-instance (which, in our setting, corresponds to an infeasible or suboptimal solution) under one formulation needs to be mapped to a no-instance of the other. This distinction is important in settings where a MILP formulation may exclude some, but not all, optimal solutions to improve efficiency. For example, adding symmetry-breaking constraints to an optimization model is a common modeling practice that removes functionally equivalent solutions. With these distinctions in mind, we formalize a new notion of equivalence for MILP formulations which we call Quasi-Karp Equivalence:\nDefinition 3.5 (Quasi-Karp Equivalence). Suppose a and a' are two optimization problems over Rd and Rd', respectively. We say a and a' are Quasi-Karp equivalent if there exists an algorithm A(\u03b1, \u03b1') that produces a mapping f : Rd' \u2192 Rd such that:\n\u2022 If x* is an optimal solution to a', then f(x*) is an optimal solution to a,\n\u2022 f can be computed in polynomial time, and\n\u2022 \u0391(\u03b1, \u03b1') runs in polynomial time for all a, a'.\nIn Figure 1, an example of one such mapping f would be xi = Yi, Vi \u2208 V, which is a linear function. Intuitively, the notion of Quasi-Karp Equivalence is meaningful only when the optimization problem is NP-hard and both optimization formulations admit feasible solutions with finite optimal values. If both formulations are infeasible, then neither has a valid solution, making any comparison between them trivial and uninformative. Declaring two infeasible problems equivalent does not provide any insight into their structural or computational properties. Likewise, if one formulation is infeasible while the other is feasible, then no valid mapping f can transform an optimal solution of one into the other. Finally, if a formulation is unbounded, then it lacks a finite optimal solution, so no single \"optimal\" point can be mapped from one formulation to another. Thus, we use Quasi-Karp Equivalence to check equivalence between feasible, bounded formulations."}, {"title": "3.3 EquivaMap: Leveraging LLMs for Mapping Finding", "content": "To determine the mapping between a and a', we propose EquivaMap, a framework that leverages LLMs as the map-finding algorithm A from Definition 3.5. Specifically, given two formulations a and a' corresponding to a given instance of the problem P, the algorithm A returns a mapping function f that aligns their solutions: f = A(\u03b1, \u03b1')."}, {"title": "4 Experiments", "content": "We conduct a comprehensive evaluation of EquivaMap by introducing EquivaFormulation\u2014to the best of our knowledge, the first dataset that contains equivalent formulations of MILP instances. Moreover, the dataset includes details about the transformations used to create these equivalent formulations (Section 4.1). 3\nNext, we evaluate EquivaMap on this dataset and compare its performance against established baselines including canonical accuracy, execution accuracy, and the WL-test (Section 4.2)."}, {"title": "4.1 EquivaFormulation: a dataset of equivalent MILP formulations", "content": "We construct EquivaFormulation based on the NLP4LP dataset [2]. NLP4LP comprises a diverse set of optimization problems with distinct problem sizes, objective functions, and constraints. Each instance in NLP4LP is composed of three components: (1) A description file with a high-level description of the problem in natural language. (2) An"}, {"title": "4.2 Performance", "content": "We use GPT-4 [1] as the mapping finder in EquivaMap, and evaluate our method against existing baselines, plus a naive LLM baseline (naive-LLM). The naive-LLM baseline uses a prompt that includes two formulations a and a' and directly checks if they are equivalent. The prompt can be found in Appendix A. We set K = 3, and report the accuracy as the percentage of paired formulations a and a' that are correctly identified as equivalent or nonequivalent, and summarize the results in Table 2.\nThe results demonstrate that our method consistently outperforms all baseline approaches, achieving perfect or near-perfect accuracy in almost every scenario. Notably, EquivaMap performs perfectly even in cases where execution accuracy completely fails, highlighting its reliability.\nFor the equivalent transformations (Table 3), our method performs exceptionally well under challenging transformations, such as Add Valid Inequalities, Rescaling, and Replace by Linear Combinations. Execution accuracy and the WL-test fail universally in these settings, achieving 0% accuracy across all variations. In contrast, EquivaMap achieves 100%"}, {"title": "5 Discussion", "content": "How can we define the equivalence of two formulations of the same optimization problem instance? In this paper, we address this conceptual gap by proposing quasi-Karp equivalence and a framework, EquivaMap, to systematically check such equivalence. Through extensive experiments on MILP problems, we demonstrate that EquivaMap outperforms existing approaches by large. Additionally, by introducing the first well-documented pool of equivalent optimization formulations, encompassing diverse transformations such as the addition of cutting planes, we provide a valuable dataset for advancing research in this domain.\nBeyond examining whether two formulations represent the same problem instance, a promising direction for future research is to leverage EquivaMap to check equivalences across diverse optimization problems, such as the equivalence between max-flow and min-cut problems. It is also worth noting that our current work focuses on relatively straight- forward transformations, thereby omitting more intricate reformulations such as those emerging from decomposition algorithms. As more complex optimization copilots are developed, we may need equivalence-checking tools that can tackle these more complex transformations."}, {"title": "A Additional Experimental Details and Results", "content": "In this section we segment our main results by problem class (i.e., LP vs. MILP), and equivalence (i.e., equivalent vs. nonequivalent). We also include the fraction of each instance solved correctly for each problem type. Our results are consistent across both LP and MILP instances, highlight that EquivaMap outperforms all baseline methods in all settings."}, {"title": "A.1 Supplementary Tables", "content": "In this section we segment our main results by problem class (i.e., LP vs. MILP), and equivalence (i.e., equivalent vs. nonequivalent). We also include the fraction of each instance solved correctly for each problem type. Our results are consistent across both LP and MILP instances, highlight that EquivaMap outperforms all baseline methods in all settings."}, {"title": "A.2 Prompts", "content": ""}, {"title": "A.2.1 naive-LLM Prompt", "content": ""}]}