{"title": "TraveLLM: Could you plan my new public transit route in face of a network\ndisruption?", "authors": ["Bowen Fang", "Zixiao Yang", "Shukai Wang", "Xuan Di"], "abstract": "Abstract-Imagine there is a disruption in train 1 near\nTimes Square metro station. You try to find an alternative\nsubway route to the JFK airport on Google Maps, but the\napp fails to provide a suitable recommendation that takes\ninto account the disruption and your preferences to avoid\ncrowded stations. We find that in many such situations, current\nnavigation apps may fall short and fail to give a reasonable\nrecommendation. To fill this gap, in this paper, we develop a\nprototype, TraveLLM, to plan routing of public transit in face\nof disruption that relies on Large Language Models (LLMs).\nLLMs have shown remarkable capabilities in reasoning and\nplanning across various domains. Here we hope to investigate\nthe potential of LLMs that lies in incorporating multi-modal\nuser-specific queries and constraints into public transit route\nrecommendations. Various test cases are designed under differ-\nent scenarios, including varying weather conditions, emergency\nevents, and the introduction of new transportation services.\nWe then compare the performance of state-of-the-art LLMs,\nincluding GPT-4, Claude 3 and Gemini, in generating accurate\nroutes. Our comparative analysis demonstrates the effectiveness\nof LLMs, particularly GPT-4 in providing navigation plans.\nOur findings hold the potential for LLMs to enhance existing\nnavigation systems and provide a more flexible and intelligent\nmethod for addressing diverse user needs in face of disruptions.", "sections": [{"title": "I. INTRODUCTION", "content": "Imagine visiting New York City on April 3, 2024 when\nsevere flooding and high winds disrupted transportation.\nWhile planning your route, you also learn that the Columbus\nCircle station exit is too windy and want to avoid it. Un-\nfortunately, apps like Google Maps lack options to navigate\naround disruptions with a different subway route or integrate\nwith alternative services, for instance, shared Citi bike. This\nunderscores the need for an intelligent, flexible system to\naddress diverse user needs and seamlessly incorporate new\ntransportation services.\nLLMs, such as GPT-4 [1], Claude 3 [2], and Gemini [3],\nhave demonstrated remarkable capabilities in understanding\nand generating human-like text [4], [5], [6], as well as\nreasoning and planning across various domains, including\nautonomous driving [7], [8]. By leveraging the natural lan-\nguage understanding capabilities of LLMs, users can input\nspecific requirements, preferences, and real-time information\nabout the situation at hand. For instance, they might say, \u201cI\nfinished my work at WTC and headed home at Cathedral\nParkway. West Manhattan is flooded and 1/2/3/A/B/C/D are\nnot in operation so I want to take alternative paths.\u201d The LLM\ncan then process this input, interpret the context and generate\na customized route that takes into account the specific needs\nof the users.\nIn this paper, we introduce the use of LLMs as a tool for\ncustomized route planning during disruption. Our objectives\nare twofold. First, we aim to investigate the potential of\nLLMs in incorporating multi-modal user-specific queries and\nconstraints into path recommendation. We designed test cases\nunder different scenarios to evaluate whether LLMs can\nsucceed in various weather conditions, emergency events,\nand when adding new transportation services. Second, we\ncompare the performance of major state-of-the-art LLMs,\nassessing their ability to generate accurate and personalized\nroute recommendations.\nThe main contributions of this paper are as follows:\n1) We propose a novel LLM-based approach for cus-\ntomized route planning when facing disruption, ca-\npable of incorporating diverse user preferences, situ-\national factors, and alternative transportation options.\n2) We design a set of test cases to evaluate the perfor-\nmance of our approach under various scenarios, includ-\ning different weather conditions, emergency events,\nand the introduction of new transportation services.\n3) We conduct a comparative analysis of state-of-the-\nart LLMs to assess their effectiveness in generating\naccurate route recommendations."}, {"title": "II. METHODOLOGY", "content": "In this section, we will introduce our method TraveLLM\nfor generating route recommendation in face of network\ndisruptions.\nA. TravelLLM: Customized Route Planning Using LLM\nAgents in face of network disruptions\nWe have 4 parts of information as input to generate a route.\nThe first input is the instruction, which serves to regularize\nthe output format and set route constraints. This instruction\ncan include requirements such as minimizing the number\nof stops, reducing walking distance, or prioritizing certain\nmodes of transportation. The second is a description of the\navailable transportation services. We focus primarily on the\nsubway system and utilize subway maps from official website\nas our main source of information. Different transportation\nservices are given by separate map images. The third is a\ndescription of user's current situation and specific demands.\nThis includes the user's starting location, destination, and\nany preferences or limitations they may have. The fourth is\na description of the disruptions that could potentially impact\nthe recommended route.\nThe format of these inputs can vary between natural\nlanguage and images, depending on the nature of the in-\nformation. For instance, we use natural language for the\ninstructions and user's situation and demands, while the\ntransportation services are represented through map images.\nBy taking these inputs, we use LLMs to generate a route\nrecommendation in the form of natural language. The LLMS\nconsider the provided constraints, the user's specific de-\nmands, and the available transportation services to create a\nroute recommendation.\nTo obtain the inputs, we begin by setting format guidance\nand constraints in the instructions, such as minimizing the\nnumber of stops or reducing the overall walking distance.\nFor the transportation services, we consider subway as main\nservice method, and use subway map from official websites.\nThe instruction and transportation service descriptions are\nprovided at the beginning of the session and serve as the\nknowledge base for the LLMs. The user's situation and\ndemands, as well as any relevant information of disruption,\nare generated by the user and must include, at a minimum,\nthe starting location and destination.\nWe illustrate our method in Figure 1. The proposed system\nconsists of two main components: an LLM Planner and\nan LLM Summary. The process begins with a user query,\nwhich includes information such as the start and destination\nlocations, events and constraints, and additional instructions.\nThis query serves as the input to the LLM Planner, which\ngenerates a detailed plan based on the provided context.\nTo enhance the interpretability and usability of the plan-\nner's output, the system incorporates an LLM Summary\ncomponent. This module takes the detailed plan generated\nby the LLM Planner and creates a concise, standardized\nsummary that captures the key aspects of the route, mainly\nthe transportation methods and intermediate stations. By\npresenting the plan in a structured format, it is easier for\ndownstream tasks to process the route output.\nThe reasons for introducing LLM Summary, instead of"}, {"title": "B. Prompt Engineering", "content": "The performance of LLM Planner and LLM Summary\nrelies on prompt engineering. For LLM Planner:\n1) We define the role for LLM Planner to be an alternative\npath-finding agent who needs to access its knowledge\nbase(e.g. subway map) every time before providing\nrecommendations.\n2) We specify the goal as considering safety first and then\nefficiency. For instance, it considers passing through a\nstation marked as dangerous, even staying on train, as\na safety risk to be avoided.\n3) To further guide the agent's behavior and decision-\nmaking process, we append additional instructions to\nthe user prompt. These instructions can include specific\npreferences, constraints, or contextual information that\nthe agent should take into account when generating\nrecommendations.\nWhile for LLM Summary, we define the role to be a route\nsummary expert, with the goal of generating standardized\nformat given a natural language text. We also give instruc-\ntions that no other texts should be generated, as the output\nis directly used by programming language. Additionally,\nwe observed that LLM Summary agent tends to ignore\nsome general term describing the transportation method, for\ninstance, walk. As a result, it failed to include part of the\nplan and reach the destination. Therefore, we give examples\nof acceptable transportation service terms, which alleviate\nthe phenomenon.\nBy prompt engineering, we can steer the LLM Planner's\nbehavior and ensure that it generates alternative paths that\nprioritize user safety and efficiency. And we can also enable\nLLM Summary to generate required format with no addi-\ntional texts, which makes it easier for downstream tasks."}, {"title": "III. EXPERIMENTS", "content": "A. Implementation\nFor LLM Planner, We compare 3 LLMs: GPT-4, Claude-3\nOpus, and Gemini Pro 1.0.\n1) GPT-4: GPT-4 is a large multimodal model developed\nby OpenAI, building on the success of its predecessors in\nthe GPT series. GPT-4 is capable for accepting image and\ntext inputs and responses in a speed of 100 billion tokens\nper second.\n2) Claude 3 Opus: Claude 3 Opus is one of the advanced\nmodels in the Claude 3 series developed by Anthropic. Opus\nstands out as the most powerful model in the series.\n3) Gemini Pro: Gemini Pro 1.0 is developed by Google\nand is publicly available. Gemini Pro 1.0 is able to perform\nimage understanding and reasoning.\nBy comparison, we aim to identify the most effective\nmodel for generating high-quality navigation plans that meet\nuser needs and preferences. For LLM Summary, we utilize\nGPT-4 to generate concise and structured summaries of\nthe navigation plans produced by the LLM Planner. Our\nmethod rely on prompt engineering and all experiments are\nconducted without further training or fine-tune.\nB. Description of Scenarios\nTable I presents scenarios designed to test the capabil-\nities and limitations of LLMs in providing route recom-\nmendations under various conditions. The scenarios cover\ndifferent aspects of transportation systems, such as the type\nof subway line (north-south, cross-river, or cross-town), the\npresence of extreme weather or emergency events, and the\navailability of additional transportation services like buses\nand Citi Bikes. Each scenario is associated with a specific\ntake-home message that highlights the key aspect being\ntested, for instance, the LLMs' ability to reason based\non general positions, physical constraints, or the impact\nof events on regular routes. We also explore the LLMs'\ncapacity to incorporate new information provided as images,\nunderstand and utilize markings, and optimize routes based\non given constraints. Furthermore, the inclusion of a scenario\ninvolving the DC subway system aims to investigate whether\nthe LLMs' performance is specific to NYC due to potentially\nricher text data available for the city.\nC. Metrics\nTo evaluate the performance of the proposed method, we\nemploy four metrics: connectivity, avoidance, approximate\ntotal travel time and number of transfers.\n1) Connectivity: This metric assesses whether the pro-\nposed route ensures available transportation between\nintermediate stations. A route is considered to have\nsatisfied connectivity if all the suggested transportation\nmethods are available at each intermediate station.\nIn this context, \"available\" means that the station is\nmarked as having a train stop, without considering the\nspecific time table, as this information is not provided\nto the LLM agents.\n2) Disruption Avoidance: The avoidance metric evalu-\nates the system's ability to generate routes that success-\nfully avoid any areas, stations, or disruptions the user\nwishes to avoid based on their preferences or external\ninformation. This could include locations marked as\ndangerous, stations with reported incidents, or areas\naffected by service disruptions. A route is considered to\nhave failed in avoidance if it passes through or includes\nany of the user-specified avoidance criteria, even if the\nuser does not disembark at that particular station or\nlocation.\n3) Approximate Total Travel Time: To estimate the total\ntravel time for each proposed route, we use Google\nMaps to query the travel time for every segment based\non the corresponding transportation method. For routes\nthat fail to satisfy connectivity, i.e., when the suggested\ntransportation method is not available between two\nstations, we estimate the travel time for that segment by\ncalculating the walking time between the stations. For\na fair comparison, all travel time queries are made with\na fixed start time of May 1st, 2024, at 1:30 PM EST,\nto minimize variations in estimated travel times due to\ndiffering query times. For the purpose of comparison,\nthe travel time for each scenario is standardized rel-\native to the total estimated walking time from origin\nto destination without additional constraints. This is\nachieved by dividing the travel time by the walking\ntime, converting the time factor into a percentage (less\nthan 1). In cases where models fail to yield a valid\nresult, this value is adjusted to 1.\n4) Number of Transfers: This metric counts the number\nof times a user needs to switch between different trains\nor transportation methods (e.g., from train to bus or\nfrom bus to walking) along the proposed route. A lower\nnumber of transfers indicates a more convenient route\nfor the user."}, {"title": "IV. RESULTS", "content": "Table II compares the performance of three models - GPT,\nGemini, and Claude across four key metrics. GPT achieves\nthe highest scores in three out of the four metrics, with a\nconnectivity score of 0.78, an avoidance score of 0.78, and\nthe lowest approximate time of 0.51. Gemini, on the other\nhand, has the lowest number of transfers at 3.00, but fails\nfor the other three metrics. Claude falls in between GPT\nand Gemini. These results suggest that GPT offers the best\noverall performance, achieving a good balance between high\nconnectivity and avoidance scores, low approximate time,\nand a reasonable number of transfers.\nA. Ablation Study\nWe perform the ablation study to investigate the impor-\ntance of the subway map image and the LLM summary in\nthe route planning process. As mentioned in [9], we are\ninterested in determining whether image data is essential\nfor effective route planning. To explore this, we conduct\nan ablation study where we keep all other inputs fixed but\nremove the map images provided to the agent. However,\nfor the user query, we still include the image, for instance,\nimage that marks the dangerous zones, as this information is\ncrucial for understanding the user's location, preferences and\nconstraints. By comparing the performance of the LLMs with\nand without access to the subway map image, we can assess\nthe contribution of visual information to the route planning\ntask. Further, we examine whether a single LLM agent,\nprovided with both planner and summary instructions, can\ngenerate accurate recommendations in the required format.\nWe evaluate the performance of the generated routes using\nthe metrics defined in Section III-C. In addition to these\nmetrics, we also count the number of violations of the\nroute format, as demonstrated in Figure 1. This allows us\nto determine the ability of the LLM agent to adhere to the\nspecified structure.\nTable III presents an ablation study comparing the perfor-\nmance of GPT with and without access to map images. The\nresults demonstrate that providing GPT with map images\nleads to significant improvements across all metrics. This\nhighlights the importance of incorporating visual information\nin the form of map images to enhance GPT's ability to\nprovide accurate and efficient route recommendations.\nTable IV investigates the impact of using a separate\nLLM for summarizing the output. When a separate LLM\nis employed for summarization, the performance improves\nsubstantially compared to direct summarized output. The\nseparate LLM summary approach reduces the violations of\nformat to 0.11. On the other hand, direct summarized output\nresults in lower quality routes, and completely violates the\nformat. The overall benefits of using a separate LLM for\nsummarization, particularly in terms of route quality and\nformat adherence, make it a more effective strategy.\nThe only instance where the separate LLM summary\napproach leads to a violation of format is Scenario S4. In\nthis case, the LLM Planner correctly suggests taking the\n1 train from Times Square to the destination, effectively\navoiding the dangerous area. However, the separate LLM\nsummary identifies this as a contradiction to the narrative's\nemphasis on avoiding Times Square. As a result, it proposes\nan alternative route with additional reasoning, despite the\nLLM Planner's already safe and efficient recommendation.\nThis highlights a potential limitation of using a separate\nLLM for summarization, as it may occasionally overrule\nvalid suggestions due to a misinterpretation of the context."}, {"title": "V. DISCUSSION", "content": "The ability to process image data requires further analysis.\nFigure 2 illustrates the constraints for Scenario S5, where\nthe black-boxed area on the map indicates the region the\nroute should avoid while still identifying a valid path to the\ndestination. The results for this scenario were unsatisfactory;\nalthough GPT-4 was the only model that successfully avoided\nthe black-boxed area, it failed to maintain a connected\nroute to the destination. The previous section (IV-A) has\ndemonstrated that utilizing maps significantly enhances the\nquality of the outputs. Nevertheless, marking an area on the\nmap did not yield success in Scenario S5. The potential\nreasons for this failure might be the insufficient resolution of\nthe image or the possibility that all the most commonly used\nroutes fall within the black-boxed area, preventing the agents\nfrom identifying a valid route that adheres to the constraints.\nFigure 3 presents the image input for Scenario S6, where\nthe current location is marked by a black circle, and nearby\nCiti Bike stations are labeled on the map. The agents were\ntasked with planning a bicycle route that includes sightsee-\ning in Central Park and concludes at the Port Authority\nBus Terminal using public transportation while avoiding\nbiking through Times Square. In this scenario, Claude 3\nemerged as the best-performing model. It not only provided\na route that satisfied all restrictions but also demonstrated\nan understanding of Citi Bike usage. For instance, Claude 3\nOpus was the only model to mention renting and returning\nthe bike and interpreting the availability information in the\nimage, with raw output like \"Walk to the nearby Citi Bike\nstation at Cathedral Parkway & Broadway (just south of\nyour location). The map shows this station has a good\nnumber of bikes available.\" and \"exit the park and return\nyour bike to a station near W 57th St, such as 8th Ave &\nW 57th St or Broadway & W 58th St.\" Conversely, other\nmodels failed to identify specific bike stations. Scenario S6,\nwhich involves potentially unfamiliar transportation services\ncompared to other scenarios, highlights the limitations of the\nother models.\nWhile our experiments required the LLM Planner to gen-\nerate routes with specific trains, tools like Google Directions\nonly require the transportation mode, such as transit, and\ninternally determine the specific trains. Consequently, iden-\ntifying the proper intermediate stations is more crucial than\nspecifying the exact trains, when used with such navigation\ntools.\nFigure 4 demonstrates the routes generated for Scenario\nS2, where the requirement is to avoid Times Square. From\nleft to right, the red, pink, and blue lines represent the routes\ngenerated by GPT-4, Claude 3, and Gemini, respectively.\nAlthough all three models successfully avoid Times Square,\nonly the route generated by GPT-4 satisfies the connectivity\ncriterion (defined in Section III-C). Both Claude 3 and\nGemini generate routes that suggest taking a train to an\nunreachable station. However, this issue is mitigated when\nusing Google Directions, as it will automatically specify the\ncorrect train to reach the desired station."}, {"title": "VI. CONCLUSION", "content": "In this paper, we proposed a prototype system TraveLLM\nfor customized route planning in face of network disruptions.\nWe designed a set of test cases to evaluate the perfor-\nmance of state-of-the-art LLMs in generating accurate routes.\nOur comparative analysis demonstrated the effectiveness of\nLLMs, particularly GPT-4, in generating high-quality nav-\nigation plans. The ablation study showed the importance\nof incorporating visual information, such as subway map\nimages, to enhance the LLMs' ability to reason about the\ntransportation network and provide more accurate routes.\nFurthermore, we showed that employing a separate LLM\nfor summarizing the output leads to improved route quality\nand adherence to the desired format, compared to direct\nsummarized output. We also identified limitations and areas\nfor future improvement. The ability of LLMs to process im-\nage data and incorporate potentially unfamiliar transportation\nservices requires further improvements. Overall, our findings\nunderscore the potential of LLMs in enhancing existing\nnavigation systems and providing a more flexible method\nfor addressing diverse user needs in face of disruptions. Our\nfuture work would focus on improving the agents' ability to\nprocess visual information, mitigate hallucination, and refine\nthe interaction between the LLM agents and downstream\napplications."}]}