{"title": "MindGuard: Towards Accessible and Sitgma-free Mental Health First Aid via Edge LLM", "authors": ["Sijie Ji", "Xinzhe Zheng", "Jiawei Sun", "Renqi Chen", "Wei Gao", "Mani Srivastava"], "abstract": "Mental health disorders are among the most prevalent diseases worldwide, affecting nearly one in four people. Despite their widespread impact, the intervention rate remains below 25%, largely due to the significant cooperation required from patients for both diagnosis and intervention. The core issue behind this low treatment rate is stigma, which discourages over half of those affected from seeking help. This paper presents MindGuard, an accessible, stigma-free, and professional mobile mental healthcare system designed to provide mental health first aid. The heart of MindGuard is an innovative edge LLM, equipped with professional mental health knowledge, that seamlessly integrates objective mobile sensor data with subjective Ecological Momentary Assessment records to deliver personalized screening and intervention conversations. We conduct a broad evaluation of MindGuard using open datasets spanning four years and real-world deployment across various mobile devices involving 20 subjects for two weeks. Remarkably, MindGuard achieves results comparable to GPT-4 and outperforms its counterpart with more than 10 times the model size. We believe that MindGuard paves the way for mobile LLM applications, potentially revolutionizing mental healthcare practices by substituting self-reporting and intervention conversations with passive, integrated monitoring within daily life, thus ensuring accessible and stigma-free mental health support.", "sections": [{"title": "1\nINTRODUCTION", "content": "In fact, mental health disorders (e.g., anxiety, depression and etc.) have the highest prevalence rates compared to many other major health conditions, such as cardiovascular diseases and stroke. According to the World Health Organization (WHO), approximately 25% of people globally experience a mental health issue [50], while the prevalence rate for cardiovascular diseases is 6.2% [64], and for stroke, it is 5% [19] (Fig. 1). Moreover, the COVID-19 pandemic and other global crises such as wars and economic downturns have exacerbated this issue, leading to a 25.6% increase in anxiety and a 27.6% rise in depression since 2020 [41]. Even more concerning is that people with mental illnesses have alarmingly low rates of access to medical treatment [49]. In the United States, only about 36.9% of adults with a mental health disorder received treatment in the past year, with the rates for teenagers even lower at around 30% [59]. The situation is even more dire in low- and middle-income countries, where WHO estimates that over 75% of people with severe mental health disorders do not receive any form of treatment [32, 68]. Only 16.5% of individuals with depression worldwide seek help and receive minimally adequate treatment [27, 61]. The widespread nature of mental health issues and their severe inaccessibility to care, combined with their chronic tendencies and long-term impacts, underscores the urgent need to address this significant public health challenge [65].\nThe primary cause of low treatment rates and the biggest barrier to delivering mental health care is attributed to stigma, which refers to the negative attitudes and discrimination directed towards individuals with their mental illness [66, 71]. Unlike other diseases, both the diagnosis and intervention of mental illness require substantial user cooperation through conversation. However, this process usually encounters a high nonresponse rate due to stigma.\nAs revealed by a comprehensive survey involving over 90,000 participants worldwide, an overwhelming 98% of survey participants acknowledged the significant stigmatization faced by individuals with mental health disorders and 60% of them are reluctant to seek professional help due to stigma [11]. In contrast, it is interesting to note that about 20% of people with mental illnesses report having taken the initiative to self-diagnose and seek help on the Internet because it makes them feel safer and stigma-free [22, 34]. Unfortunately, existing online tools typically offer only closed-ended questions and construct conversations with limited assessment capabilities, lacking personalized interaction, continuous monitoring, and intervention. Existing research efforts primarily focus on delivering better intervention conversations [20, 44] and engaging users more effectively through mobile devices [55, 67], which typically occur after individuals have actively sought diagnosis and help-a process that often has a low participation rate. However, there is a gap in utilizing behavioral data to reflect mental health statuses and leveraging mobile devices to facilitate daily conversations for mental health first aid (MHFA). This approach could provide continuous monitoring and early intervention, addressing the critical low treatment rate of mental health caused by stigma. To fill this gap, this paper presents MindGuard, an LLM-powered mobile mental healthcare system that provides accessible MHFA to a huge portion of people in a stigma-free fashion. MindGuard offers a holistic full-stop solution that facilitates the identification of mental health conditions, enables continuous monitoring, and reframes thoughts and situations through personalized reflective listening and professionally assisted intervention.\nAt the core of MindGuard is the utilization of the causal relationship between user behavior and mental status. By combining the objective user behavior data collected from the rich sensors on mobile devices with the advanced conversational capabilities of large language models (LLMs), MindGuard provides open-ended questions to comprehensively assess the user's mental state and further deliver personalized conversations and interventions. Achieving such a system is non-trivial and faces three major challenges.\nFirst, due to the autoregressive nature of LLMs, MindGuard must address the challenge of hallucinations to ensure it consistently delivers accurate and reliable mental health knowledge. The issue of hallucinations-where the model produces plausible-sounding but incorrect or inaccurate information-stems from its reliance on statistical pattern matching for content generation, limitations in domain-specific training data, the absence of fact-checking capabilities, and a tendency to overgeneralize in complex or rare situations. MindGuard addresses this challenge through a comprehensive approach, including the construction of a high-quality mental health dataset, fine-tuning the LLM using continuous pertaining (PT) techniques [25], optimizing the model to follow desired answers through supervised fine-tuning (SFT) [81], and incorporating post-processing with human-in-the-loop review. This full-chain strategy significantly enhances the LLM's performance in the mental health domain, whereas relying solely on prompt engineering is insufficient to fully resolve the hallucination issue. The second challenge is how to interpret sensor data in the context of mental health for the LLM model, particularly since the sensor data is in digital form, often noisy, incomplete, and subject to varying behavioral patterns associated with different mental health issues. MindGuard addresses this by proposing a self-refinement and self-feedback mechanism to format the sensor data, allowing the LLM to iteratively update and optimize the data format based on its own feedback, thereby enhancing its ability to accurately interpret and utilize behavioral insights. Additionally, MindGuard introduces counterfactual augmentation learning, which generates misleading information to challenge and improve the LLM's robustness. The third challenge is to enable the system to run on mobile devices with acceptable latency to mitigate the risk of sensitive privacy data breaches. To reduce the size of MindGuard without compromising its capabilities, we employ a teacher-student knowledge distillation paradigm. This approach transfers advanced reasoning skills from state-of-the-art LLMs, such as GPT-40 [47], to MindGuard. Following this, we utilize the MLC-LLM [58] deployment framework to implement a quantized q4f16 version of MindGuard, making it compatible with a wide range of mobile devices. We summarize the contributions of this paper as follows:\n\u2022 To the best of our knowledge, MindGuard is the first system to integrate objective mobile sensor data with subjective LLM-powered conversational data to create a comprehensive mental healthcare system. Unlike existing research that primarily focuses on improving intervention performance, MindGuard prioritizes providing accessible and stigma-free MHFA. It offers a holistic solution that encompasses early diagnosis, continuous monitoring, and personalized intervention.\n\u2022 MindGuard introduces a suite of fine-tuning methods and strategies designed to address the critical challenge of hallucinations in LLMs-a frequent issue where models produce plausible yet incorrect or misleading information. Experimental results demonstrate that MindGuard enhances both the reliability and accuracy of the system in delivering primary mental health care.\n\u2022 We have implemented MindGuard to operate on various mobile devices with acceptable latency using knowledge distillation and model quantization techniques. Results from a two-week real-world deployment indicate that MindGuard can accurately retrieve and analyze user behavior data, identify potential mental health issues promptly, and effectively mitigate the stigma associated with seeking mental health support."}, {"title": "2 PRELIMINARIES", "content": "2.1 Behavior & Mental Status\nIn recent years, wearable devices like the Apple Watch have gained popularity for their capability to monitor users' psychological states through Ecological Momentary Assessment (\u0395\u039c\u0391) [29, 40]. These devices often ask users to record their feelings or emotions at various time points throughout the day, providing a subjective measure of mental well-being. While EMA offers valuable insights, it is primarily based on self-reported data, which can be influenced by various factors such as mood at the moment or willingness to report honestly [71] and it overlooks continuous and measurable indicators. The behavioral data recorded by sensors equipped on mobile devices can in fact complement EMA data, providing a more objective and comprehensive measure of mental health.\nBehavioral data recorded through wearable sensors offer a more objective way to assess mental health [51]. Numerous studies [9, 46, 63] have highlighted the correlation between behavioral patterns - such as physical activity levels, sleep quality, heart rate variability, and frequency of social interactions-and mental health outcomes. Behavior can both influence and be influenced by one's mental health status. For instance, decreased physical activity and irregular sleep patterns have consistently been associated with symptoms of depression and anxiety [48]. In this context, mental states often act as the cause, with observable changes in behavior being the effects. Wearable sensors, therefore, can act as proxies for detecting shifts in mental health by monitoring these behavioral indicators in real time.\nCombining subjective self-reports and objective behavioral data provides a robust foundation for developing a causal inference model in mental health monitoring [45]. This dual approach leverages the strengths of both data types: subjective reports provide insight into the user's immediate psychological state, while objective behavioral data offer continuous, unbiased measurements of underlying mental conditions. This combination enables a more comprehensive and accurate assessment of potential mental health risks.\nTraditional supervised machine learning models are typically confined to processing behavioral data and mental health records in digital formats, resulting in binary classification labels [12, 57, 62], they fall short of uncovering the underlying causal relationships between inputs and outcomes crucial for interpretable mental health analysis, thus no able to provide continuous monitoring and analysis. In contrast, the advanced inference capabilities of LLMs, combined with their ability to handle complex, multidimensional data sources, enable them to detect subtle patterns and correlations within both subjective and objective data. This leads to a more refined and precise analysis of mental health risks. By accounting for historical trends, environmental factors, temporal changes, and momentary states, LLMs offer context-sensitive forecasts essential for dependable mental health evaluations. Moreover, LLMs can produce comprehensive explanations and practical recommendations from their analysis, aiding mental health experts in creating further customized care plans. The capacity to transform extensive data into significant insights positions LLMs as a valuable asset for realizing mental health first aid and delivering effective, stigma-free support."}, {"title": "2.2 Causal Inference Model", "content": "Understanding the complex relationship between behavioral sensor data and mental health outcomes necessitates the use of sophisticated analytical models. A causal inference model [52] offers a robust framework for examining how various factors, such as behavioral patterns and self-reported mental health, contribute to the onset or exacerbation of mental health issues. Our proposed MindGuard is grounded in this causal framework, offering a systematic approach to assessing and analyzing mental health conditions.\nAs illustrated in Fig. 2, the causal inference model is structured around four primary indicators: mental status (M), behavior data (D), mental record (R), and outcome (O). The relationships among these indicators are formalized as follows:\n$D = k_D \\times M$,\n$R = k_R \\times M + U_M$,\n$O = f(D, R)$.\n(1)\n$k_D$ and $k_R$ are weighted factors of objective behavior data and subjective mental records. The outcome of mental status depends on the correlation between behavioral sensor data (D) and mental records (R) that reflect the underlying mental status (M). However, mental records are also subject to uncertainty ($U_M$) due to their subjective nature, as they are influenced by the individual's mental state at the time of reporting. Such subjectivity adds variability, potentially complicating the prediction function f for mental health outcomes.\nTo derive an accurate prediction of the outcome (O), it is crucial to calculate the conditional probability $p(O|D, R)$ while accounting for the uncertainty ($U_M$) between mental status and mental records. This introduces a more complex inference problem, as the model must integrate this uncertainty to produce reliable predictions.\nThe MindGuard system tackles the challenge by integrating subjective mental records with objective behavioral data within a multi-modal framework. This integration enables the system to detect and rectify discrepancies between mental status (M) and recorded mental data (R), thus mitigating the effects of uncertainty $U_M$ on the prediction of outcomes. The primary goal is to refine the conditional probability distribution $p(O|D, R)$ by factoring in the uncertainty $U_M$. The mathematical expression for this optimization is achieved by marginalizing the uncertainty:\n$p(O|D, R) = \\int p(O|D, R, U_M) p(U_M|D, R) dU_M$.\n(2)\nThis approach allows MindGuard to enhance the accuracy of mental health outcomes by systematically addressing the variability inherent in subjective mental records."}, {"title": "3 MINDGUARD DESIGN", "content": "Behavioral data and mental health records are collected via mobile devices. To ensure user privacy, it is sensible to process this data on the devices themselves rather than using commercial LLMs. This approach aligns with current industry practices, such as Apple's \"Apple Intelligence\" initiative, which aims to implement LLMs locally on mobile devices for task inference [1]. However, this necessitates smaller model sizes. This approach is also reflected in recent industry practices. Consequently, designing small-scale models with specialized domain knowledge to eliminate hallucinations, alongside comprehensive reasoning abilities, demands meticulous design.\nWe implement a two-stage progressive training to transform the small-scale LLM into the MHFA assistant, which is shown in Fig. 3. The initial step is to inject specialized domain knowledge into base models through continuous pertaining (PT) so as to equip the small-scale base LLM model with expertise in the psychological domain, certifying it as an expert (described in \u00a73.1). After being certificated with expert knowledge, it's crucial to understand how to apply it effectively, to substantiate the knowledge, means being able to offer professional dialogue and not being easily misled by uncertain descriptions of mental health conditions. Therefore, further knowledge distillation and counterfactual learning-based supervised finetuning (SFT) are proposed for use as second-stage training, as detailed in \u00a73.2.\nFollowing the training phase, we showcase the deployment of MindGuard, transforming it into the ultimate LLM-based MHFA assistant system, as elaborated in \u00a73.3. Thus MindGuard can provide precise primary mental health assessments and serve as a personalized assistant.\nFinally, we detail the workflow for employing MindGuard under the causal inference model to execute MHFA in practical settings, as described in \u00a73.4."}, {"title": "3.1 Certificate MindGuard", "content": "To enhance the capabilities of LLMs within specific vertical domains, it is essential to conduct PT using a substantial corpus tailored to the target domain [25]. In developing MindGuard as a certified MHFA assistant, we adopt this approach by continuously pretraining the base model\u2014initially trained on a broad general corpus-on an extensive mental health corpus. The method aims to adapt LLMs to specific domains to improve their performance and reduce hallucinations [30]. To achieve this goal, we start by assembling approximately 100K professional mental health articles, selected based on key terms as outlined in Tab. 9 of \u00a7A.1, covering topics like depression, anxiety, and substance abuse. Articles are first converted to text using PP-OCR [36]. Further data cleansing is required to correct the potential errors and standardize format [17]. For MindGuard's development, we employ the cutting-edge, open-sourced Qwen2-72B-Instruct [76] locally, since using commercial LLMs for processing such vast datasets is impractical. The final PT corpus contains about 80 million tokens, preparing the base LLM with mental health expertise.\nWith the processed corpus, the PT of the base LLM involves optimizing the model's parameters, \u03b8, to predict the next token in a sequence accurately. This is achieved by minimizing the cross-entropy loss:\n$L(\\theta) = -\\sum_{t=1}^T \\log p_{\\theta}(x_t | X_{<t})$\n(3)\nwhere T is the total number of tokens, $x_t$ is the token at position t, and $x_{<t}$ represents all preceding tokens. The model learns to maximize the likelihood of the observed sequence, effectively capturing the contextual dependencies within the mental health corpus, turning it into a certificated MindGuard. For details of the PT settings, please refer to \u00a7A.1."}, {"title": "3.2 Substantiated MindGuard", "content": "PT enhances the base model with domain-specific expertise. Yet, this knowledge doesn't guarantee the reasoning ability, similar to a student who knows the material but can't apply it practically. To bridge this gap, SFT is crucial following the PT process, refining the model's ability to utilize its knowledge for specific reasoning tasks [81]."}, {"title": "3.3 Personalized MindGuard", "content": "The final stage of deploying MindGuard involves harnessing its full potential in the mental health domain by leveraging its extensive professional knowledge and advanced inference capabilities. Our objective is to transform MindGuard into a personalized and helpful MHFA assistant.\nTo achieve this, a few challenges must be tackled. First, refining the extraction of raw digital sensor data is crucial to improve the LLM's ability to gather behavioral information, which will enable MindGuard to understand user interactions more effectively. Second, it is necessary to evolve MindGuard's functionalities to more closely resemble those of an assistant. Finally, to safeguard user privacy, it is essential to deploy MindGuard on mobile devices for local inference.\nAddressing the first challenge necessitates transforming raw digital data into a format that the LLM can efficiently process and comprehend. Inputting lengthy sequences of raw digital data directly into the LLM poses problems, including the risk of sequence truncation and memory constraints [24], as well as the LLM's inherent challenges in processing the digital data [7]. To fully leverage MindGuard's capacity for interpreting behavioral data, we propose a self-refinement mechanism. As illustrated in Fig. 4, we first ask the LLM to evaluate the presentation format of the raw digital data, focusing on the degree of redundancy and ease of understanding, termed self-feedback. Based on this evaluation, the LLM provides an improved version of the data by self-refinement. This approach enables the LLM to iteratively update and optimize the data format based on its own feedback, thereby improving its ability to accurately interpret the behavioral insights.\nTo validate the effectiveness of the self-refinement process in constructing behavioral data formats, we use perplexity [2] to measure the LLM's familiarity with the refined format. Comparative analysis, as shown in Tab. 1, with existing instruction formats [29, 31, 73] reveals that our method reduces the input token length and markedly improves the LLM's proficiency in interpreting user behavior data.\nAdditionally, effective MHFA requires MindGuard to provide guidance that is not only accurate but also delivered in a tone appropriate to the user's psychological state [42]. This is achieved through carefully designed prompts that guide MindGuard in adjusting its responses according to the user's emotional and mental condition.\nTo ensure MindGuard can be effectively deployed on mobile devices, model quantization is essential [38]. Given that even smaller open-sourced LLMs typically contain 7 to 8 billion parameters, the memory requirements for inference with FP16 precision can exceed 16GB-far beyond the capabilities of most mobile devices. To address this, q4fp16 quantization is applied, reducing the required memory to approximately 4GB, and making deployment feasible on mobile platforms. In this work, we leverage the MLC-LLM [58] deployment framework to implement the quantized model across a range of devices, including smartphones, tablets, and laptops, to enable local inference.\nAs illustrated in Fig. 5, by integrating these designs, MindGuard evolves into a truly personalized MHFA assistant, capable of knowing and understanding the users it serves."}, {"title": "3.4 MindGuard Workflow", "content": "We present the workflow of MindGuard in Fig. 6. Specifically, MindGuard's first task is to generate a comprehensive analysis report based on users' behavior data and their self-reported mental health status. If MindGuard detects a potential mental health risk, it will promptly notify professional mental health institutions to ensure timely intervention. Conversely, if the user's mental condition is stable and positive, MindGuard will offer affirmative support, encouraging the user to maintain their well-being.\nMoreover, we investigate the use of MindGuard for continuous mental health monitoring through a multi-turn dialogue format. This includes assessing MindGuard's capability to extract key information from behavioral data, guide daily interactions, and adapt its communication tone based on the user's current mental state, as well as determining to what extent MindGuard can provide MHFA to the users."}, {"title": "3.4.1 Professional Mental Health Analysis.", "content": "The first task is to generate a comprehensive analysis report by integrating the user's behavioral data with their self-reported mental record. MindGuard starts by transforming raw behavioral data into a structured text table for LLM interpretation. This data forms a user profile highlighting personality traits and social cognition, crucial for establishing a basic psychological evaluation framework tailored to the user before the final analysis report. In addition, the table records the user's behavior over a specified period, including daily calorie intake and exercise details, offering a window into physical health. Furthermore, the inclusion of sleep and diet records helps identify potential sleep or eating disorders, which are critical factors in the overall mental health assessment. These behavioral indicators play a significant role in MindGuard's ability to conduct thorough and personalized mental health evaluations.\nIn addition to the user's behavior data, MindGuard can access their self-reported wellness record. These records encompass key indicators of mental well-being, including anxiety, depression, stress, fatigue, and mood. Users document their psychological states daily, allowing MindGuard to track these indicators over time. By comparing current wellness data with historical records, MindGuard can detect patterns and shifts in users' mental health cycles. Although self-reported data may carry some degree of uncertainty, it remains a crucial component for accurate psychological assessment. The further application of counterfactual learning helps to reduce the effects of this uncertainty.\nBased on the integration of objective behavioral data and subjective self-reported mental health information, MindGuard generates a detailed analysis report. This process, structured and guided by licensed MHFA assistants and psychologists, follows the chain-of-thought methodology [70]. The analysis proceeds through five phases, starting with the synthesis of the user's mental health record and user portrait for an initial assessment, followed by an in-depth analysis of behavioral data. MindGuard conducts a correlation analysis to address uncertainties from subjective reporting, linking wellness assessments with behavioral patterns. For example, symptoms like insomnia or chronic fatigue may signal mental health risks, even if the user reports no anxiety or stress. MindGuard then offers professional recommendations and, if necessary, initial support for users at elevated mental health risk, enabling users to gain a clearer understanding of their psychological state. If the user appears mentally healthy, MindGuard reinforces this positive outcome, encouraging the continuation of beneficial behaviors and habits. We provide a comprehensive analysis example in \u00a7B.2."}, {"title": "3.4.2 Prompt Mental Health Monitoring.", "content": "Beyond generating detailed mental health analysis reports, our exploration extends to whether MindGuard can serve as a reliable daily mental health monitor and act as a personal assistant to users.\nAs illustrated in Fig. 6, MindGuard can actively engage with the user post-exercise to evaluate the positive effects of the activity on their physical and mental well-being. It is also designed to determine whether the user has achieved adequate rest after sleeping or to assess their stress and emotional state following a workday. Through these interactions, MindGuard deepens its understanding of the user, providing mental health guidance when needed to fulfill its role in delivering MHFA. On the other hand, users can gain better insights into their physical and mental state by engaging in conversations with MindGuard on a mobile device, helping to reduce potential stigma.\nTo ensure rigorous evaluation for real-world deployment, we assess MindGuard's performance in diverse scenarios, focusing on its ability to extract user behavior information, adjust conversational tone according to the user's mood, and provide effective MHFA assistance. Additionally, we explore MindGuard's capacity to offer timely emotional guidance and mental support during extended user interactions.\nIn \u00a7B.3, we present extensive cases, demonstrating how MindGuard functions as a personalized MHFA assistant."}, {"title": "4 MINDGUARD EVALUATION", "content": "4.1 Experimental Settings\nTo comprehensively evaluate the performance of MindGuard in the MHFA task, we conduct extensive experiments using a large-scale, publicly available medical dataset. Additionally, MindGuard is deployed on mobile devices through a collaborative effort with the licensed MHFA assistant and psychologist. We recruit 20 volunteers for a continuous testing period of one to two weeks to rigorously assess MindGuard's performance under real-world settings, identify potential issues, and ensure its practical effectiveness and reliability. Details of these experimental settings are provided below."}, {"title": "4.1.1 Public Available Datasets.", "content": "We utilize two open-sourced large-scale datasets, PMData [60] and Globem [75], both of which collect comprehensive behavioral data and mental health records for each participant. The data is aggregated weekly for each individual, denoted as ($D_i, R_i$). Based on the user's self-reported mental records and the professional criteria [42], we assess existing or potential future mental health risks, resulting in the label $G_i$, for each individual. The assessment outcomes are classified into two categories:\n(1) $G_i$ = 0: The user shows no significant signs of mental health issues, or may have minor issues that do not require immediate psychological intervention.\n(2) $G_i$ = 1: The user exhibits strong indicators of mental health issues and requires further professional treatment or closer monitoring.\nTo mitigate the potential for false positives and negatives among these labels, the MHFA assistant and psychological expert review the initial assessments and further refine the labels by considering patterns in behavior, and potential inconsistencies in self-reported records, thereby enhancing the precision and reliability of the labeling process. The evaluation metrics are accuracy, precision, recall and F1 score. The details of each dataset are given below:\nPMData: The dataset comprises 16 participants (12 men and 4 women, aged 25-60 years old) monitored over 5 months using Fitbit for objective biometrics and activity data, Google Forms for demographics, food, drinking, and weight data, and the PMSys for self-reported measures such as fatigue, mood, stress, etc. The data collected from Fitbit and Google Forms constitute the participants' behavior data ($D_i$), while the PMSys measures represent their self-reported mental records ($R_i$). All participants are used for evaluation. A small fraction of 9.8% cases are identified with potential mental health issues requiring additional support.\nGlobem: The Globem dataset encompasses four years of passive sensing data from 497 participants, with a gender distribution of 58.9% female and 41.1% male. Behavioral data, including sleep patterns, location, physical activity, and phone usage, are collected using wearable sensors (Fitbit Flex2 and Inspire 2) and are denoted as $D_i$. Survey data, such as PHQ-4 [33] (mental health, anxiety, and depression), PSS-4 [10] (stress level), and PANAS [69] (positive and negative affect), provide self-reported mental health records ($R_i$). For efficient testing and cost reduction, 25% of the participants are randomly chosen as the test set. Within this group, 23.2% are identified as potentially needing additional support."}, {"title": "4.1.2 Real-world Adoption.", "content": "To assess the real-world efficacy of MindGuard as an MHFA assistant, we deploy it on mobile devices and recruit 20 volunteers (9 females, 11 males, aged 18-40) for a one to two-week user study. Participants will converse daily with MindGuard and track their mental health using EMA, specifically anxiety, depression, and stress levels, using standardized scales such as PHQ-4 and PSS-4. As for the conversations, MindGuard will create an appropriate scenario that aligns with the current time and user behavior data, to deliver contextually relevant and personalized interactions. Finally, participants will complete a survey evaluating their experience, the accuracy of data analysis, hallucination occurrences, and MindGuard's impact on reducing mental health stigma, a primary goal of MHFA.\nA subset of participants (4 individuals) engage in parallel conversations with a licensed MHFA assistant. This comparison aims to benchmark the user experience of the LLM-based virtual assistant against that of a human professional, providing critical insights into the practical utility and limitations of MindGuard in real-world mental health support."}, {"title": "4.2 Evaluation Design", "content": "Our evaluation is designed from whole to parts to answer the following key research questions:\n(1) How effective is MindGuard in accurately assessing users' mental health conditions? (\u00a74.3.1 and \u00a74.3.2)\n(2) Is the accuracy of assessments improved by the application of counterfactual learning, especially under conditions of uncertainty? (\u00a74.3.3)\n(3) Can MindGuard, through specified SFT, efficiently extract and analyze user behavior data for daily monitoring and adjust its tone according to users' emotions to offer personalized mental support? Additionally, what is the impact of behavior data on the outcomes? (\u00a74.3.4 and \u00a74.3.5)\n(4) Does the generated report adhere to the established causal inference framework, and how consistent are the evidence and outcomes of the analysis? (\u00a74.3.6)\n(5) Is the MindGuard able to reduce computational costs, and by how much? (\u00a74.3.7)\n(6) How is MindGuard's generalization ability? Will MindGuard experience hallucinations? (\u00a74.3.8)"}, {"title": "4.3 MindGuard Performance", "content": "4.3.1 Overall Performance. We benchmark MindGuard in two large-scale public datasets by investigating the performance gap between MindGuard and state-of-the-art LLMs in delivering MHFA. We evaluate MindGuard against three leading commercial LLMs and three advanced open-sourced LLMs, and the publicly available instruction-tuned version of MindGuard's base model, InternLM2-7B-chat, with the results summarized in Tab. 2. As expected, GPT-40 generally outperforms other baseline models across both datasets. Remarkably, GPT-40 attains a recall rate of 0.8 on the PMdata dataset and 0.951 on the Globem dataset, equalling the performance of Claude-3.5. Among open-source models, Mixtral-8\u00d722B achieves the highest F1 score (0.517) on the PMdata dataset, while LLaMA3-70B stands out on the Globem dataset. Remarkably, our MindGuard achieves a performance ranking second only to GPT-40 in PMData, surpassing GPT-40 in Globem. The results demonstrate that (i) MindGuard not only integrates specialized mental health knowledge into its base model (InternLM2) but also matches the reasoning capabilities of SOTA large-scale commercial LLM, GPT4. (ii) MindGuard analyzes users' mental health conditions with performance that surpasses counterparts possessing more than 10 times its parameters (LLaMA3-70B, etc.)."}, {"title": "4.3.2 Effectiveness of Training Strategy.", "content": "We evaluate the proposed two-stage progressive training by an ablation study on MindGuard with the PMData and Globem datasets. Our evaluation compares the performance of applying SFT directly to two prevalent open-sourced base models, InternLM2-7B [6] and LLaMA3-8B [17], versus the performance after PT followed by SFT, as shown in Tab. 3. We exclude the base model results due to their lack of built-in instruction following capabilities. We provide an example in \u00a7B.2.2 to showcase the issue. The results demonstrate a marked improvement in the model's ability to analyze users' mental health conditions following continued PT and SFT. For instance, in the PMData dataset, InternLM2-7B shows substantial gains in both precision and recall, increased by 58.5% and 17.6%, respectively, with the F1 score improving by over 50% compared to the model without further PT. A similar trend can be observed with LLaMA3-8B base model, to further validate the effectiveness of our proposed training strategy. For Globem, the results obtained after PT and SFT surpass those with SFT alone. Overall, the InternLM2-7B series outperforms the LLaMA3-8B series, which is why we select internLM2-7B as our base model. For the rest of the article, if not otherwise indicated, MindGuard is based on the open-sourced base InternLM2-7B model."}, {"title": "4.3.3 Impact of Mental Status Uncertainty.", "content": "During the SFT stage of MindGuard, counterfactual learning is employed to tackle the potentially misleading information in mental health records due to stigma or other factors. This method aims to improve MindGuard's proficiency in identifying and handling such uncertainties as well as improve robustness. We contrast MindGuard with leading LLMs and assess the performance disparity of the InternLM-7B model without counterfactual learning, in both general and counterfactual situations. The experimental outcomes are depicted in Fig. 7.\nWe select a subset of cases from PMData and Globem for general testing and create counterfactual samples for each. As illustrated in Fig. 7, the performance of all models experiences an average drop of 54%, even for powerful commercial models like Claude-3.5, Qwen2, and Mixtral seeing over a 50% decrease in recall rates. In contrast, MindGuard outperfors all open-sourced LLMs. Although its recall rates also dropped by 43%, its performance remains significantly higher-by 133%-than MindGuard without counterfactual learning. These results affirm the efficacy of our proposed counterfactual learning method in improving MindGuard's capability to assess mental uncertainty. Nonetheless, LLMs tend to accept user descriptions readily, indicating a need for further research to improve the ability against misleading information."}, {"title": "4.3.4 Behavior Data Retrieval.", "content": "In the context of continuous daily mental health monitoring, the analysis focuses on whether MHFA assistants can adhere to instructions for leveraging and analyzing behavior sensor data to enhance dialogue guidance. Given the impracticality of users interacting with every LLM in real-world applications, multi-agents [72] are commonly used to simulate interactions between users and MHFA assistants, facilitating the evaluation of behavior data analysis capabilities. Agents representing users and MHFA assistants are created to explore four principal mental health monitoring scenarios: physical activity, nutrition, rest and sleep, and mental health. The accurate recall rate of indicators collected via mobile sensors is assessed in each scenario, with results presented in Fig. 8.\nClearly, using the CPsyCoun dataset in the SFT stage leads to more comprehensive and accurate behavior data analysis in the conversations. Compared to InternLM2-7B, MindGuard shows significant improvement in scenarios involving physical activity, rest and sleep, and mental health. It scores slightly lower in nutrition but with a smaller standard deviation. Moreover, MindGuard surpasses all open-sourced LLMs in rest and sleep, as well as mental health scenarios, closely rivalling the performance of GPT-40. Additionally, the evaluation in user studies is explored in Fig. 11. The performance is nearly on par with that of multi-agent systems, showing a 0.14 increase in topics related to nutrition."}, {"title": "4.3.5 Personalized Tone Adaptation.", "content": "To provide effective MHFA, MindGuard must ensure that its tone aligns with the user's current mood. Ideally, a professional"}]}