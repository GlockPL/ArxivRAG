{"title": "GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale\nProtein-protein Interaction Exploration", "authors": ["Ziwen Li", "Xiang 'Anthony' Chen", "Youngseung Jeon"], "abstract": "Drug discovery (DD) has tremendously contributed to maintaining and improving public\nhealth. Hypothesizing that inhibiting protein\nmisfolding can slow disease progression, researchers focus on target identification (Target\nID) to find protein structures for drug binding. While Large Language Models (LLMs)\nand Retrieval-Augmented Generation (RAG)\nframeworks have accelerated drug discovery,\nintegrating models into cohesive workflows remains challenging. We conducted a user study\nwith drug discovery researchers to identify the\napplicability of LLMs and RAGs in Target ID.\nWe identified two main findings: 1) an LLM\nshould provide multiple Protein-Protein Interactions (PPIs) based on an initial protein and protein candidates that have a therapeutic impact;\n2) the model must provide the PPI and relevant\nexplanations for better understanding. Based\non these observations, we identified three limitations in previous approaches for Target ID:\n1) semantic ambiguity, 2) lack of explainability, and 3) short retrieval units. To address\nthese issues, we propose GraPPI, a large-scale\nknowledge graph (KG)-based retrieve-divide-solve agent pipeline RAG framework to support large-scale PPI signaling pathway exploration in understanding therapeutic impacts by\ndecomposing the analysis of entire PPI pathways into sub-tasks focused on the analysis of\nPPI edges.", "sections": [{"title": "1 Introduction", "content": "The discovery of new drugs can potentially create treatments that save lives and enhance health\noutcomes globally. For example, penicillin, discovered in the early twentieth century, revolutionized\nbacterial infection treatments and saved countless\nlives (Drews, 2000). Based on the critical hypothesis that inhibiting and activating protein misfolding can slow disease progression, drug discovery\nresearchers are focused on Target identification (Target ID), the process of elucidating the\nprotein structures that drugs can bind to. As depicted in Figure 1, this process aims to identify\nprotein-protein interactions (PPIs), which are protein pathways from an initial protein (IP) to protein candidates for the target protein (TP). The TP\nshould have a therapeutic impact on the IP. Given\nthat the number of protein candidates in the human body is several billion (Smith and Kelleher,\n2013), Target ID is very time-consuming and expensive, requiring DD researchers to explore PPI\ncandidates within the extensive protein space by\nscanning related literature for validation.\nRecently, Large Language Models (LLMs) (OpenAI, 2023; Touvron et al., 2023; Devlin et al., 2019;\nAI, 2024) have become a trending generative model\nfor understanding user intents (Li et al., 2023; Zhao\net al., 2023; Kang et al., 2023) such as preferred\ntherapeutic impacts and generating biomedical advice in natural language (Bender and Koller, 2020;\nVaswani, 2017). However, they are prone to hallucinations that introduce unreliable results (Ji et al.,"}, {"title": "2 User Study", "content": "In this appendix, we describe the details of our user\nstudy (Section 2.1), existing processes in Target ID\n(Section 2.2), and the challenges and applicability\nof RAG as potential solutions (Section 2.3)."}, {"title": "2.1 Approach", "content": "We recruited five researchers specializing in drug\ndiscovery and conducted user studies in February\n2024 to gain a deep understanding of their Target\nID process. Their work experience spans 7 to 10\nyears (mean = 8.75, SD = 1.3). Each interview\nlasted approximately 60-90 minutes. Three authors\nattended all sessions, took notes during the discussions, and later consolidated and analyzed the notes\nin wrap-up meetings. Two participants, who were\nour collaborators, were not compensated, while the\nremaining three received a $30 gift certificate after\nthe study. Table 4 in the appendix shows participants' demographic details.\nDuring the interviews, we asked about (1) their\ncurrent practices regarding Target ID and (2) the\napplicability of LLMs in Target ID. After completing the interviews, we employeed thematic analysis\nand iterative open coding (Clarke et al., 2015) to analyze the interview transcripts. Three researchers\ncoded and analyzed the transcripts for emerging\nthemes, and the findings were iteratively discussed\namong the co-authors until reaching a consensus."}, {"title": "2.2 Results", "content": "Target identification (Target ID) is introduced as a\nprocess to explore the protein space for PPI signaling pathways. PPI signaling pathways are paths of\nproteins that start from an initial protein (IP) that is\ntherapeutically related to certain diseases to a target protein (TP). There are two conditions for TP.\nFirst, the target protein should have physical and\nfunctional interactions ranging from itself to the\ninitial protein (C1). To identify these interactions,\nscientists input the initial protein on STRING, and then they retrieve a protein interaction graph\nconsisting of hundreds of proteins based on the\ninitial protein. Before moving on to the next step,\nthe scientists want to identify as many proteins as\npossible to increase the likelihood of finding the\noptimal target protein. Secondly, scientists look\nfor possible therapeutic impacts to make an initial protein be inhibited or activated (C2). Scientists search for the therapeutic impacts of proteins\non the interaction graph via Google Search. For\nexample, MAPT is a key protein associated with\nAlzheimer's disease because excessive phosphorylation (activation) of MAPT promotes the disease.\nWhen researchers search for therapeutic impacts\nof proteins, they should verify whether a protein\nphosphorylates MAPT. As a result, scientists filter the proteins on the graph to retain only those\nwith the desired impact, significantly reducing their\nnumber."}, {"title": "2.3 Applicability", "content": "The space of possible targets is expansive, given\nthat researchers estimate around 10,000 (Adkins\net al., 2002) proteins in the human body. Scientists are constrained to exploring limited protein\ncandidates, negatively impacting scientific discoveries. In our user study, the experts provided highly\npositive feedback on using LLMs with PPI graphs\nto explore the extensive protein space, citing their\nefficiency in identifying potential therapeutic target protein (TP) candidates. If LLMs can identify\nPPIs having desired TPs in a PPI graph based on\nan initial protein (IP) consisting of several PPIs,\nit demonstrates their strong potential to support\nscientific discovery effectively. However, they\nalso emphasized the necessity of utilizing a confident dataset, such as the STRING dataset, that\nprovides interactions for over 3 million proteins.\nResearchers also mentioned the importance of fact-\nchecking with explanations for why the model recommends specific PPIs. The absence of scientific\nmaterials for results could diminish the quality of\nLLM-generated recommendations.\nIn summary, key findings for supporting Target\nID are as follows:\n\u2022 A RAG should provide a PPI composed of\nmultiple proteins, with the IP and TP as start\nand end points, respectively, and ensure alignment with the desired therapeutic impact.\n\u2022 A RAG should utilize datasets that scientists\ncan trust, such as the STRING dataset.\n\u2022 A RAG should provide the PPI alongside relevant explanations to enable fact-checking."}, {"title": "3 Preliminaries", "content": "In this section, we introduce the formulation of\nthe problem and the construction of our medical\ngraph database. We conducted a user study with\ndomain experts in DD to understand their requirements for PPI exploration: a framework that can\nunderstand their initial protein and therapeutic impact then outputting recommended PPI pathways\nwith explanations and retrieved contexts from re-\nliable datasets for fact-checking. More details on\nformative study are provided in the Appendix."}, {"title": "3.1 Problem Formulation", "content": "Let G = (V,E) be an instance of a knowledge\ngraph, where V is the set of nodes and & is the\nset of edges. Node v \u2208 V and edge e \u2208 & represent protein and PPI in the PPI network. The goal\nof GraPPI is to provide potential PPI signaling\npathways and offer AI-generated explanations and\ndatabase-retrieved contextual information to support experts' decision-making. The following equation can describe the input and output of GraPPI:\nGraPPI(G, Qusers, IP) = arg max\nPCG\n(S(P,Qusers, XAI(P), IDB (P))) (1)\nIn this equation, G represents the interaction\ngraph derived from the database, while P represents the potential PPI signaling pathway. IP represents the initial protein. Qusers indicates the therapeutic impact from users. IDB(P) represents the\nretrieved information about certain pathways from\nthe database. The equation maximizes the relevance score S(P) for a pathway based on a given\ntherapeutic impact Qusers. XAI(P) (AI-generated explanation), and IDB (P) (retrieved information from\nthe database) over the pathway P are utilized as\nsupplementary information for evaluation. We will\nassess the results of the recommended PPI candidates using quantitative metrics for semantic similarity literal alignment and subjective evaluation of\ndomain experts in DD."}, {"title": "3.2 Medical Graph Database Construction", "content": "In this section, we describe the process of construct-ing our KG database containing domain knowledge\nof all human PPIs from the STRING dataset (Szklarczyk et al., 2023), through data collection and\ndeployment. After domain experts in drug discovery confirmed the reliability of the STRING\ndataset, we collected information on all proteins\nwithin the Homo sapiens category, identifying and\nreorganizing representative features including com-bined_score, interaction_type, protein, text annotation, and embedded-annotation vector. The text annotation and combined_score attributes are sourced\nfrom prior work, with their reliability validated\nby experts. Attribute definitions are summarized\nin Table 1. The embedding model used is Ope-"}, {"title": "4 GraPPI Framework", "content": "To add supporting information for LLMs to understand single PPI and multi-PPI signaling pathway\nanalysis, we developed a KG-based RAG framework to support PPI pathway exploration. The\nframework contains two components: (1) Interaction Graph: Moving kNN windows to extract the\nrelevant subgraphs from the KG to enable LLM\ninference over the large-scale KG, and (2) Impact Search: A retrieve-divide-solve style agent\npipeline to understand PPI pathways on single PPI\nedge level and entire PPI pathway level context.\nThe overview of GraPPI is illustrated in Figure 2."}, {"title": "4.1 Interaction Graph: Moving kNN Graph\nWindows", "content": "After discussion with domain experts, we constructed the entities in KG: <head protein, combined_score, tail protein>. To start to generate\nInteraction Graph as the PPI context, GraPPI will\nreceive the name of the initial protein from users\nand use Cypher statement to extract all the connected nodes (proteins) in the KG. Among all the\nconnected protein candidates, GraPPI will implement a moving k-nearest neighbor (kNN) graph\nwindow strategy to form interaction graphs allow-"}, {"title": "4.2 Impact Search: Retrieve-Divide-Solve", "content": "In Impact Search, users can select the interaction\ngraph that contains their preferred proteins for\nLLM inference based on therapeutic impact. After interaction graph selection, Impact Search will\ntake the interaction graph and the therapeutic impact query as the input to perform the PPI pathway exploration using a retrieve-divide-solve style\nagent pipeline. Instead of directly incorporating\nlong-context annotations in the long PPI signaling\npathways, Impact Search first decomposes the analysis for the entire tasks into multiple subtasks, with\neach subtask retrieving the long annotations of two\nend proteins to explain each PPI in parallel for the\nwhole of the PPI pathway recommendation. Next,\nwe will walk through Impact Search in GraPPI"}, {"title": "4.2.1 Step I: Edge Explanation", "content": "Instead of directly analyzing the entire PPI pathway,\nwhich is very likely to have an extremely long PPI\ncontext, the edge explanation agent breaks down\nthe entire path into a collection of edges with detailed information about proteins. Each edge will\nbe analyzed with corresponding protein context and\ntherapeutic impact to generate shorter and more\nconcise explanations with less redundant information. The edge explanations will be the information\nsource for path explanation and supporting context\nfor fact-checking."}, {"title": "4.2.2 Step II: Path Exploration", "content": "In Step II, the edge explanation agent will generate the explanation for the entire PPI signaling\npathway. The generated path explanation and the\nrelevance score will be stored as attributes of each\npath. After the generation, all the intermediate\nresults from kNN search in Interaction Graph to\nEdge Explanation and Path exploration in Impact\nSearch are accessible to domain experts to support\ntheir fact-checking."}, {"title": "4.2.3 Step III: Re-rank", "content": "When generating path explanations, the path explanation agent is also responsible for evaluating the\nrelevance of the pathway to the therapeutic impact\nusing the demonstrated zero-shot ranking ability of\nLLMs (Hou et al., 2024; Zhao et al., 2023) since\nprevious studies show the strong potential of transferring knowledge from LLMs as powerful recom-mendation models. Using the calculated relevance\nscore, GraPPI will show the top n relevant pathways among all PPIs to users rather than using the\nranking in the previous interaction graph. Users\nspecify the ranking window length n."}, {"title": "5 Experiment", "content": "We will assess the performance of GraPPI in multiple configurations to answer the following experimental questions (EQs):\n\u2022 EQ1: To what extent does GraPPI improve\nthe accuracy of path explanations compared\nwith baseline models?\n\u2022 EQ2: How does the retrieve-divide-solve\npipeline improve the accuracy and efficiency\nwhen scaling up interaction graphs?"}, {"title": "\u2022 EQ3:", "content": "How do the domain experts perceive the utility of AI-generated explanations\nand retrieved information in supporting their\ndecision-making?\nEQ1, EQ2, and EQ3 will be explained in Section\n5.4.1, 5.4.2, and 5.4.3, respectively."}, {"title": "5.1 Setup", "content": "For the evaluation, we accessed the performance\nof our framework in terms of two aspects: (1 )accuracy to demonstrate how the generated contents\nalign with the requirements of users and the background information, and (2) the scalability that evaluates the framework performance when Interaction\nGraph scales up. We conducted the experiments\non both edge-level generated explanation and path-level explanation. For the comparative study and\nthe ablation study, the graph size parameter was\nset to be 2, and the hyperparameters for kNN k1\nand k2 to explore the nodes in depth 1 and depth 2\nwere set to be 10 and 2 respectively. Impact Search\nwill recommend the top 10 PPI signaling pathway\ncandidates for each interaction graph according to\nthe relevance to the therapeutic impacts from users.\nFor scalability analysis, we test the performance of\nGraPPI using 6 Interaction Graph with different\nsizes. The depths of those Interaction Graph are 2\nand 3 while k value for kNN are 10, 15, and 20 respectively. The numbers of paths are set as follows:\n[40,75,76,95,113, 160]. The Interaction Graph in\nthe experiment group is using GraPPI to generate\npath explanations based on the edge explanations.\nThe Interaction Graph in the control group directly\nrefers to raw annotation texts of each protein in the\npathway to generate path explanations."}, {"title": "5.2 Baseline", "content": "We assess the performance of our framework using three state-of-the-art LLMs as base models:\nGPT-4, GPT-4-Turbo(Achiam et al., 2023), and\nGPT-4-mini. GPT-4 and GPT-4-mini are the\ncost-effective variants of GPT-4-Turbo designed to\nbalance performance and computational expense."}, {"title": "5.3 Tasks and Metrics", "content": "To evaluate the accuracy of the generated contents, we employed BERTScore (Zhang et al.,\n2019), ROUGE-1, and ROUGE-L (Lin, 2004)"}, {"title": "5.4 Experimental Results", "content": "EQ1: Accuracy: In this experiment, we conducted\nthe accuracy evaluation of GraPPI under a given\ndata scale. As shown in Table 3, GraPPI outper-\nforms not only the baseline but all other configurations with all three base models in terms of semantic similarity (BERTScore) and literal alignment\n(ROUGE-1 and ROUGE-L). Four configurations\nare designed: Ours, RAG w/o Chain-of-Thought\n(CoT), Zero shot w/ CoT, and Zero shot w/o CoT\n(Baseline). To ensure consistency, we implemented\nthose configurations on the same initial protein\nfrom domain experts for sub-graph retrieval, and\nwe adjusted LLM inference settings for the abla-tion study. One interesting thing we observed while\nmanually checking the generated explanations is\nthat although GPT-4-Turbo has the best quantita-\ntive performance among all three base models, its\nexplanations may prioritize protein annotation details over user-specified therapeutic impacts. GPT-\n4-Turbo generates explanations covering more divergent topics, while GPT-4 focuses more on the\nusers' query to give more concise explanations."}, {"title": "5.4.2 Scale Variant Evaluation", "content": "EQ2: Scalability and Efficiency: We evaluate\nthe performance of GraPPI using GPT-4o under\ninteraction graphs of different scales. As shown in\nFigure 3, by comparing all four metrics in the six\nscales, significant differences exist between the two\ndata groups for all metrics except ROUGE-1 and\nROUGE-L when the number of pathways reaches\n160. In this experiment, six Interaction Graph\ncontaining different numbers of pathways are used\nto test GraPPI's scalability. For each Interaction\nGraph, GraPPI recommends 10 potential PPI path-way candidates based on their relevance to user\nqueries. We employed paired t-tests to determine\nwhether GraPPI's introduction leads to significant\nperformance differences. While no statistically sig-"}, {"title": "5.4.3 Case Study", "content": "EQ3: Explainability: We further conducted a case\nstudy to evaluate the quality of responses generated\nby GraPPI. Users reviewed the generated content\nin Interaction Graph and Impact Search to assess\nGraPPI's contribution to exploring novel PPI path-ways. We interviewed users about their current Target ID practices and the applicability of LLMs in\nTarget ID to validate the generated content. Given\nan initial protein and therapeutic impact, GraPPI\nproduced 5 PPI pathways (containing 9 PPI edges)\nwith explanations and retrieved descriptive texts for\npathway validation. Users leveraged these outputs\nto explore new PPI pathways. All generated ex-\nplanations were deemed coherent, and users could\nintegrate them with prior work context to make\ndecisions. Baseline model outputs were less con-\nvincing due to the lack of fact-checking support,\nwith some requiring manual calibration. GraPPI\noffers a novel approach to PPI pathway exploration,\nproviding biomedical explanations and retrieved in-\nformation to mitigate over-reliance on AI. Case\nstudy details and sample results are provided in\nFigure 4 in the Appendix."}, {"title": "6 Related Works", "content": "Transparent LLM-based systems that provide explanations and retrieve materials from existing research enhance human verification of AI-"}, {"title": "6.1 LLM-based and RAG-based systems in\nPPI prediction", "content": "Large Language Models (LLMs) have demonstrated significant potential in understanding and\ngenerating natural language responses (Wang et al.,\n2024; Li et al., 2023; Kang et al., 2023). Inspired by LLMs, pioneering work has focused on\nbuilding protein language models (PLMs), which\nare pre-trained on large-scale protein sequences\n(Hsu et al., 2022; Elnaggar et al., 2021; Li and\nHuang, 2023). PLMs capture more accurate protein features by representing sequences as highdimensional embedding vectors. Previous studies\nhave leveraged PLMs to enhance performance in\ndownstream tasks such as protein structure prediction (Lin et al., 2023) and PPI prediction (Jin et al.,\n2024). However, while PLMs exhibit strong capabilities in biomedical tasks, they remain prone\nto hallucinations-generating text that is nonsensical or unfaithful to source content (Ji et al., 2023;\nZhang et al., 2023b). To address this, Retrieval-Augmented Generation (RAG) has been introduced\nto mitigate hallucinations and improve trustworthiness by retrieving contextual information from\nexternal databases (Khandelwal et al., 2019; Lewis\net al., 2020). RAG enhances the reliability and\ntransparency of biomedical LLM-based systems\n(Yang et al., 2024)."}, {"title": "6.2 Explainable AI", "content": "Heated discussions have centered on explainable\nAI (XAI), which generates actionable explanations for Al outputs instead of treating LLM-based systems as black boxes (Wiegreffe and\nMarasovi\u0107, 2021; Schuff et al., 2022; Lamm et al.,\n2021)."}, {"title": "7 Conclusion", "content": "In this paper, through a carefully designed user\nstudy with drug discovery researchers, we observed\nthe importance of retrieving PPIs with the therapeutic impact they target in Target ID (i.e., find\nPPIs to inhibit MARK4). Therefore, we proposed\nGraPPI, which is a large-scale KG-based retrieve-divide-solve style agent pipeline RAG framework\nto support PPI pathways exploration in understanding therapeutic impacts with two key components:\n1) moving kNN windows for sub-graph extraction,\nand 2) a retrieve-divide-solve style agent pipeline to\nincorporate long protein annotations for inference.\nThrough extensive experiments, we demonstrate\nthat: (1) accuracy: GraPPI consistently outper-\nforms baseline methods in semantic and lexical\nalignment; (2) scalability and efficiency: GraPPI\nachieves comparable results using significantly\nfewer tokens than raw annotation-based systems,\nand (3) explainability: GraPPI generates more re-liable explanations and retrieved information, validated by domain experts."}, {"title": "8 Limitations", "content": "In this paper, we developed a KG-based RAG\nframework to support PPI signaling pathway exploration. However, our study has several limitations.\nFirst, while domain experts in DD expressed\nfull confidence in the STRING dataset during interviews, the dataset does not comprehensively cover\nall known PPIs, as biomedical research continues to\ndiscover new interactions, and the STRING dataset\nrequires constant updates. During the case study,\none expert noted that protein TUBB3 interacts with\nMAPT via phosphorylation based on their expertise, but this interaction is absent in STRING. Integrating features such as PPI prediction models\nor allowing researchers to input custom findings\ncould enhance dataset coverage.\nSecond, the case study utilized only two initial\nproteins validated by DD experts. While these pro-teins were well-understood, they do not represent\nthe full diversity of protein interactions, leaving po-tential edge cases unexamined. Future work should\nincorporate a broader range of initial proteins to\nrigorously assess GraPPI's applicability.\nThird, while the retrieve-solve-merge pipeline\nimproves PPI exploration at moderate scales, its\nbenefits diminish as interaction graphs grow larger.\nThis is due to the increasing length of edge expla-nations approaching LLM context window limits."}]}