{"title": "Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms", "authors": ["He Yu", "Jing Liu"], "abstract": "Designing optimization approaches, no matter heuristic or meta-heuristic, often require extensive manual intervention and struggle to generalize across diverse problem domains. The integration of Large Language Models (LLMs) and Evolutionary Algorithms (EAs) presents a promising new way to overcome these limitations to make optimization more automated, where LLMs function as dynamic agents capable of generating, refining, and interpreting optimization strategies, while EAs explore complex solution spaces efficiently through evolutionary operators. Since this synergy enables a more efficient and creative searching process, in this paper, we first conduct an extensive review of recent research on the application of LLMs in optimization, focusing on LLMs' dual functionality as solution generators and algorithm designers. Then, we summarize the common and valuable design in existing work and propose a novel LLM-EA paradigm for automated optimization. Furthermore, focusing on this paradigm, we conduct an in-depth analysis on innovative methods for three key components, namely, individual representation, variation operators, and fitness evaluation, addressing challenges related to heuristic generation and solution exploration, particularly from the perspective of LLM prompts. Our systematic review and thorough analysis into the paradigm can help researchers better understand the current research and boost the development of combining LLMs with EAs for automated optimization.", "sections": [{"title": "1. Introduction", "content": "Optimization [1] plays a pivotal role in solving complex challenges across various industries, from logistics and manufacturing to machine learning and healthcare. At its core, optimization seeks to identify the best solution from a set of candidates according to specific objectives, while adhering to constraints. The growing scale and complexity of real-world optimization problems demand approaches that can navigate vast search spaces efficiently. Traditional optimization methods, such as gradient-based approaches and mathematical programming, have long been employed for problems with well-defined objective functions. However, these methods often struggle with real-world problems that are non-differentiable, multi-modal, or laden with constraints and uncertainties. This gap has driven the development of more flexible, adaptable, and scalable methods, leading to the rise of heuristics [2], which aim to provide approximate solutions efficiently.\nHeuristics emerged as practical tools for generating \"good-enough\" solutions without requiring exhaustive searches. While heuristics have been successful in many applications, they come with limitations. Traditional heuristics often require careful manual design, limiting their adaptability to new problems. Meta-heuristics [3, 4], such as genetic algorithms [5] and simulated annealing [6], offer more general approaches but often require parameter fine-tuning and expert knowledge. Hyper-heuristics [7, 8] attempt to automate the selection or generation of heuristics, representing a step forward. However, they remain constrained by predefined low-level heuristics or components, limiting their adaptability to highly dynamic and complex problems.\nThe integration of Large Language Models (LLMs) [9] and Evolutionary Algorithms (EAs) [10] presents a promising new way to overcome these limitations. LLMs function as dynamic agents capable of generating, refining, and interpreting optimization strategies, while EAs explore complex solution spaces efficiently through evolutionary operators."}, {"title": "2. Evolution of Heuristics for Automated Optimization", "content": "Heuristics are problem-solving techniques designed to provide approximate solutions to optimization problems where finding the exact solution is computationally prohibitive. Throughout the evolution from heuristics to meta-heuristics and hyper-heuristics as shown in Figure 1, the key goal is to create a more generalized, flexible, and automated approaches for solving optimization problems. Each development reduces the dependence on problem-specific adjustments and domain-specific expertise. In the following subsections, we briefly discuss each of these developments."}, {"title": "2.1. Pre-Heuristic Approaches to Optimization", "content": "Before the development of heuristics, optimization largely relied on methods such as exhaustive search, linear programming, and gradient-based techniques. While effective for small and well-structured problems, these methods struggled with the increasing size and complexity of modern optimization tasks. Exhaustive search, for example, systematically exploring all possible solutions quickly became computationally infeasible for combinatorial optimization problems like the Traveling Salesman Problem (TSP)."}, {"title": "2.2. Classical Heuristics", "content": "The first wave of heuristics introduced simple yet practical techniques like construction heuristics and local search. Construction heuristics [11] build solutions incrementally, often making greedy decisions at each step. For example, the nearest-neighbor heuristic for the TSP selects the closest unvisited city at each step, offering quick but often suboptimal solutions. Local search techniques [12, 13, 14] start with an initial solution and attempt to improve it by making small adjustments within its neighborhood, such as the 2-opt heuristic [15] for the TSP, which swaps edges in a tour to reduce the distance.\nWhile these methods provided efficient ways to tackle complex problems, designing heuristics needs careful manual design, and also heuristics are easily trapped in local optima. These challenges highlighted the need for more robust strategies that could better balance exploration and exploitation in the searching process."}, {"title": "2.3. Rise of Meta-Heuristics", "content": "In response to the limitations of classical heuristics, meta-heuristics emerged as a more flexible and adaptable framework. Unlike classical heuristics, which are typically problem-specific, meta-heuristics are designed to be general algorithms applicable across a wide range of optimization problems, both combinatorial and continuous.\nA variety of meta-heuristic algorithms have been developed to tackle complex problems across various domains. Among them, EAs stand out as a prominent representative, like Genetic Algorithms (GAs) [5], Memetic Algorithms [16], Particle Swarm Optimization (PSO) [17], Ant Colony Optimization (ACO) [18]. These algorithms share a common trait: they are designed to explore the solution space efficiently by leveraging principles inspired by natural processes or swarm intelligence.\nDespite their differences in specific implementations and searching operations, these meta-heuristic algorithms all embody a general framework that involves an iterative searching process. They initialize a set of candidate solutions, evaluate their quality based on a predefined objective function, and iteratively update the solutions through various mechanisms such as selection, crossover, mutation, or information sharing among individuals. This process allows them to escape local minima and explore diverse regions of the searching space, thereby increasing the likelihood of finding globally optimal solutions.\nHowever, despite their generalization capabilities, meta-heuristics still face key challenges, particularly their reliance on carefully tuned parameters and the need for expert knowledge. This dependence on domain knowledge for tasks like designing fitness functions, selecting appropriate operators (e.g., mutation and crossover), and adjusting algorithmic components reduces the true generality of meta-heuristics and limits their applicability across diverse optimization problems without significant manual intervention."}, {"title": "2.4. Hyper-Heuristics: Automating Heuristic Design", "content": "To reduce the reliance on expert knowledge and achieve more automated optimization, hyper-heuristic address problems by searching for and generating heuristics tailored to the problem. They operate at a more abstract level. Hyper-heuristics rely on predefined low-level heuristics, typically employing either heuristic selection or heuristic generation [7, 8, 19, 20], which output heuristics through various methods, including machine learning prediction or EA search. The machine learning approach is more generalized, relying heavily on extensive training data for prediction, while the EAs are based on an iterative search using specific problem-related training data.\nDespite hyper-heuristics' potential to generalize across various problems, they are constrained by the quality and diversity of the available low-level heuristics or components, and if these components are not robust or flexible enough, the generated heuristics may perform poorly across different problems. Additionally, no matter the hyper-heuristics relying on training a prediction model or EAs, their effectiveness highly depends on the quality and quantity of training data. Poor or insufficient training data may result in suboptimal heuristics that fail to generalize effectively to unseen problem instances or variations."}, {"title": "2.5. Toward a New Era of Automated Optimization", "content": "The integration of LLMs and EAs offers a promising new method for automated optimization, which leverages LLMs' capabilities in generating combined with EAs' iterative optimization techniques, resulting in a framework that can both solve optimization problems and design the optimization algorithms. The key innovations in this integration is the dual-role that LLMs play.\nFirst, LLMs can directly generate solutions by interpreting prompt content and applying searching operators such as mutation and crossover. In this capacity, LLMs function as meta-heuristic agents, dynamically producing solutions based on real-time feedback from the optimization process. Second, LLMs can generate and refine heuristics-problem-solving strategies, assuming the role of a hyper-heuristic. This allows for continuous adaptation and improvement of both the search strategies and the resulting solutions, enhancing the flexibility and effectiveness of the optimization process.\nThe LLM-EA automated optimization paradigm holds the potential for generalized, scalable optimization across various domains, such as network design, logistics, and machine learning model optimization. By enabling the automated design of both solutions and the algorithms that generate them, this paradigm represents a significant leap forward in intelligent, adaptive problem solving, offering new opportunities for addressing complex, high-dimensional optimization challenges."}, {"title": "3. Fundamental Technologies in LLM and EA for Automated Optimization", "content": null}, {"title": "3.1. Overview of LLMs and EAs", "content": "Large Language Models, such as GPT-4 and BERT [21], are built on the transformer architecture, which has revolutionized natural language processing (NLP). This architecture allows LLMs to process input sequences in parallel, rather than sequentially as seen in earlier models like RNNs [22] or LSTMs [23], making them significantly more efficient. The key innovation lies in the self-attention mechanism [24], which enables the model to weigh the importance of different words in a sentence relative to one another, regardless of their position in the text. This capability is crucial for understanding long-range dependencies in language and for capturing both syntactic and semantic information with high accuracy. The success of LLMs in NLP stems from pretraining on vast amounts of text, which allows them to generalize across various domains and tasks. By fine-tuning on specific tasks, LLMs can generate coherent and contextually relevant text, even in highly specialized fields.\nEvolutionary Algorithms, on the other hand, are inspired by the process of natural evolution and use mechanisms like selection, mutation, and crossover to solve optimization problems. EAs are particularly useful when the search space is large, complex, or non-differentiable, rendering traditional methods like gradient descent ineffective. EAs begin with an initial population of candidate solutions, which are evaluated using a fitness function to measure their performance. High-performing individuals are more likely to be selected for reproduction. The crossover operation combines features from two or more parent solutions to create offspring, while mutation introduces random variations to maintain diversity. This iterative process refines solutions over multiple generations, making EAs especially suitable for black-box optimization, where the internal structure of the system is unknown."}, {"title": "3.2. Understanding Prompts in LLMs", "content": "A prompt [25] is essentially the input provided to LLMs to guide its output. The purpose of a prompt is to specify what the LLMs should generate, whether it is answering a question, writing a paragraph, or completing a task based on a given example. A text prompt example is given in Figure 2(a). The simplicity or complexity of a prompt depends on the task at hand. At its core, a prompt can be thought of as the instruction or query that triggers the model's response. This is a foundational component of using generative LLMs like GPT or BERT, as it sets the direction for the model's output."}, {"title": "3.2.1. Prompt techniques", "content": "Prompt techniques refer to structured approaches for designing, formatting, and sequencing prompts to achieve optimal generative performance from LLMs. Common prompt techniques include:\nZero-Shot prompt [26]: In this technique, LLMs are tasked with performing a job without presenting any examples. It solely depends on the directions stated in the prompt. As depicted in Figure 2(b), zero-shot prompt tests the LLMs' capacity to comprehend and carry out the task solely based on the provided instructions, devoid of any supplementary context or samples.\nFew-Shot prompt [27]: As shown in Figure 2(c), this approach entails furnishing a handful of examples alongside the task directions to assist in guiding the model. These instances are commonly known as exemplars. By presenting the LLMs with a small number of pertinent cases, few-shot prompt can enhance its performance on the task by offering a clearer understanding of what is anticipated.\nChain-of-Thought prompt [28]: This method encourages LLMs to dissect their reasoning process into consecutive steps before reaching the final answer. As illustrated in Figure 2(d), the Chain-of-Thought prompt can boost the model's effectiveness on tasks that necessitate logical deduction or multi-step problem-solving. By prompting the model to articulate its thought process, this technique can make the model's reasoning more transparent and accurate."}, {"title": "3.2.2. Prompt optimization", "content": "Prompt optimization [29, 30] refers to the process of refining prompts to enhance the generative performance of LLMs. It involves iteratively adjusting prompts, experimenting with different variations, and using automated techniques to optimize for accuracy, efficiency, and output relevance. The following principles are essential for effective prompt optimization:\n\u2022 Prompt Ensembling: This technique generates multiple variations of a prompt and aggregates their outputs to improve response quality and diversity.\n\u2022 Prompt Tuning: Fine-tuning the structure, wording, and format of prompts can significantly impact the model's output quality, allowing for more targeted and precise results.\n\u2022 Self-reflective Prompts: In this iterative approach, the LLM evaluates its own responses, identifies potential weaknesses, and suggests improvements, enabling continuous refinement.\nBy applying these principles, prompt optimization can produce more reliable and fine-tuned outputs, pushing the capabilities of LLMs in complex problem-solving scenarios."}, {"title": "3.3. EAs for Prompt Optimization", "content": "EAs have been used to solve the optimization problem in LLMs, especially for optimizing the prompt. Prompts can be categorized into continuous prompts, which use numerical vectors (embedding vectors) to influence LLMs' behavior directly [31] and text prompts, which are natural language instructions. EAs can effectively optimize prompts by exploring different configurations and selecting the most effective ones.\nContinuous prompts involve tuning embedding vectors that act as \"soft prompts\", allowing fine control over the LLM's responses. For example, Black-Box Tuning (BBT) [32] applies EAs to optimize continuous prompts represented as embedding vectors, which iteratively adjusts these vectors to improve performance on various language tasks, such as sentiment analysis and question answering. BBT shows that continuous prompts can be fine-tuned using EAs even when the LLM is treated as a black-box system.\nFor text prompts, EAs adjust phrasing and structure to find better ways of prompting the LLM. For example, EvoPrompt [33] utilizes evolutionary operators like mutation and crossover to modify parts of prompts, enabling the exploration of new variations that might lead to better performance. PromptBreeder [34] takes this further by evolving both the task-specific prompts and the evolutionary operator used to refine these prompts. This dual evolution ensures that the model not only generates high-quality prompts but also refines the method of prompt generation itself, ultimately leading to more robust outcomes when the LLM is later applied to complex optimization tasks.\nAs can be seen, EAs can improve the quality of prompts which guide LLMs to generate better responses, which is a natural application of EAs. In fact, more creatively, EAs are combined with LLMs to solve optimization problems, which is the focus of this paper and introduced in the following sections."}, {"title": "4. Development of LLM-based Optimization and LLM-EA Automated Optimization Paradigm", "content": "In this section, we first summarize existing work on LLM-based optimization, highlighting key techniques and common patterns. Based on these insights, we propose a novel paradigm where LLMs generate solutions and heuristics, while EAs iteratively refine them. This LLM-EA paradigm aims to automate and enhance optimization processes, reducing the need for manual intervention and improving adaptability across diverse problems."}, {"title": "4.1. LLM-based Optimization", "content": "LLMs, with their vast knowledge base and advanced natural language understanding, reasoning, and problem-solving capabilities, have garnered significant attention in the field of optimization. Research efforts in this area have primarily focused on two main directions: exploring the searching abilities of LLMs and using LLMs to model optimization problems. While the focus of this paper is on the former, for more details on the latter, readers can refer to [35, 36]. There has also been research into using the fundamental mechanism behind LLMs-Transformer architecture-to solve optimization problems, which is also outside the scope of this paper, and readers can refer to [37, 38, 39] for further details.\nOur focus is on how LLMs function as searching operators within optimization processes. Regardless of the type of problem being addressed, the majority of research has treated LLMs as searching operators, embedding them into iterative procedures or coupling them with EAs. Certainly, LLMs have also been employed in other stages of the optimization process, such as initialization, evaluation, and selection. However, the role of LLMs as searching operators remains the most valuable and complex to execute effectively. Therefore, in this section, we delve into how LLMs have been designed and used as searching operators. For a more general overview, refer to [40, 41].\nAs searching operators, LLMs have been applied to a variety of optimization problems, extending their reach from prompt optimization, as discussed above, to classical numerical and combinatorial optimization problems, and even to automatic algorithm design. In prompt optimization, optimization techniques have been used to improve the quality of prompts [31, 32, 42, 43, 44, 45]. In fact, many of these studies [31, 42, 43, 44] have already treated LLMs as searching operators to directly optimize prompts, given that text is the format LLMs naturally excel in. Recognizing that LLMs can optimize text, and that numerical values can also be treated as a form of text, researchers have begun exploring whether LLMs can solve classical optimization problems directly [46]. They applied LLM-based searching operators to continuous numerical optimization, combinatorial optimization, and more complex optimization problems [47, 48, 49]. In these cases, LLMs are designed to generate candidate solutions directly for the given problem, effectively functioning as solvers.\nHowever, as research advanced, it became apparent that while LLMs are exceptional at generating text, their ability to handle numerical optimization was somewhat limited [50]. On the other hand, LLMs have shown remarkable capabilities in code generation [51, 52], leading researchers to shift their focus towards guiding LLMs to design optimization algorithms rather than directly solving optimization problems. In this approach, LLMs are tasked with designing either specific components of an algorithm or entire algorithms. These algorithm components or complete algorithms are expressed in natural language, pseudo-code, or real code. Given that LLMs are more proficient at handling code than numerical values, there has been growing interest in utilizing LLMs for automated algorithm design.\nNext, we focus on the work taking LLMs as a solver or for automated algorithm design, which not only represent the core focus of optimization in this field, but also analyze the key developments and technologies that have emerged."}, {"title": "4.2. LLMs as a Solver", "content": "Treating LLMs as a solver and asking them to generate solutions for optimization problems directly, the core technologies lie in designing prompts for LLM-based searching operators. In general, prompts contain two main types of information: the problem details and the required output from the LLM. In this case, the output is typically straightforward-producing one or more candidate solutions to the problem at hand. The real challenge arises in how the problem is presented to the LLM. The problem-related information in prompts can be categorized into three types: available solutions, quality of those solutions, and guidance for the LLM's search direction or pattern. Most existing studies provide candidate solutions as examples, but the use of solution quality and search guidance varies across different works. Below, we summarize the major developments in this area.\nInitially, researchers simply provided LLMs with candidate solutions. A notable example of this is Meyerson et al.'s work [53], where LLMs were employed as crossover operators in EAs. By providing pairs of existing solutions, the LLMs generated new solutions based on these examples. No information about solution quality or search guidance was included in this work. Another early study is Lehman et al.'s work [54], where LLMs were designed as mutation operators in genetic programming (GP). Since GP deals with codes, the LLM-based mutation operators generated code solutions for the problems being tackled. Notably, this differs from later work on code generation for algorithm design. In [54], basic guidance was introduced alongside the solutions, with three LLM-mutation operators requiring the model to either: make changes or small changes to the current solution, or modify parameters of the current solution. While these instructions were simple, they introduced a level of search direction, influencing subsequent research. Hemberg et al. [55] applied LLMs to each part of GP, instead of just the mutation operator.\nAs research advanced, it became evident that providing only candidate solutions was insufficient; including the quality of solutions helped LLMs learn how solutions differ. A representative work in this space is OPRO, proposed by Yang et al. [56], which provided objective function values alongside each solution, though no specific search guidance was offered. OPRO tested small-scale linear regression problems and TSPs, with a focus still on prompt optimization. Following OPRO, the inclusion of solution quality became a standard practice in LLM-based optimization.\nFurther developments in the use of searching guidance emerged, recognizing its importance in steering LLMs more effectively. Following OPRO, Liu et al. [57] designed more detailed task instructions that were combined with EA steps. These instructions specified the sequence of operations, such as performing selection, followed by crossover, and then mutation. This combination of solution quality and structured guidance represented a significant step forward in prompt design.\nBeyond prompt design, researchers have also extended this LLM-driven optimization approach to more complex problems, such as multi-objective optimization [58, 59]. Additionally, several innovations have further refined this paradigm. For example, Lange et al. [60] applied evolution strategies, asking LLMs to generate the next mean for a desired fitness level. Brahmachary et al. [61] introduced a technique that split the population into two groups for exploration and exploitation, providing different search guidance for each group. Huang et al. [50] conducted a comprehensive comparative study on the ability of LLMs to generate solutions for optimization problems directly, offering insights into their relative strengths and limitations."}, {"title": "4.3. LLMs for Automated Algorithm Design", "content": "The use of LLMs to automate algorithm design has progressed significantly over recent years. Initially, researchers focused on a single-round process, where LLMs were prompted to design new meta-heuristics. In these early studies, LLMs typically selected and analyzed existing algorithms, generating new ones in pseudo-code format. However, the performance of these generated algorithms could not be evaluated online, and their application was limited to conversational interactions rather than fully leveraging LLMs' optimization potential [62, 63, 64]. We think these types of work are more like chatting with LLMs rather than mining the optimization ability of LLMs.\nA more advanced approach involves embedding LLM-based searching operators into an iterative process, allowing continuous improvement of the generated algorithms. This shift enabled LLMs to move beyond simple heuristic generation to creating meta-heuristics. Within this context, researchers have focused on generating both components of heuristics/meta-heuristics and complete algorithms. Various optimization problems have been explored, including numerical optimization, combinatorial optimization, multi-objective optimization, and even complex network optimization [47, 49]. Given the varying complexities of these problems, numerical and combinatorial optimizations have received the most attention, with subsequent studies expanding to multi-objective and complex problems.\nThe type of algorithm generated and the problem used to test is not strictly one-to-one; some studies apply a single generated heuristic or meta-heuristic across multiple problem types. The iterative nature of algorithm improvement stems from two factors: LLMs' ability to generate codes and the integration of an iterative process. One of the most widely used iterative processes is the EAs.\nCurrently, the primary focus is on designing components within heuristics or meta-heuristics. Typically, an existing optimization algorithm is fixed, and LLMs are tasked with generating specific functions for the algorithm. For example, in FunSearch [65], LLMs generate functions to evaluate the score of each bin in the bin-packing problem. The prompt provides existing code, and the LLM is asked to generate only the function code. Similarly, EoH [66, 67, 68] uses both code and descriptions about the algorithm to generate new function components. EoH employs a guided local search (GLS) algorithm [14, 69], and the LLM generates an evaluation function embedded in GLS. However, the search guidance in EoH remains fixed throughout the iterative process.\nRecent advancements have introduced dynamic search guidance during the iteration process. Ye et al. [70] proposed a system with two LLMs: one for generation and one for reflection. The reflection LLM analyzes short-term and long-term search results and provides updated search guidance to the generation LLM. Similarly, Sun et al. [71] developed a system of three LLM-based agents-Advisor, Coder, and Evaluator\u2014that work together to analyze solutions and guide further searches, representing early steps toward LLMs guiding other LLMs.\nIn addition to generating components for heuristics, LLMs have been applied to meta-heuristic component design. Huang et al. [72] used LLM-based crossover and mutation operators for multi-objective optimization. Huang et al. [73] extended this work to evolutionary multitasking algorithms, where LLMs were tasked with designing knowledge transfer models. In other studies, LLMs have been employed to design surrogate models for expensive optimization tasks [74] and learning rate schedules in evolutionary strategies [75, 76].\nDesigning complete heuristics or meta-heuristics is more challenging than just designing components, and research in this area remains limited. Yu et al. [49] proposed a method for generating complete heuristics to improve the robustness of complex networks [77, 78]. Stein et al. [79] developed a method for generating meta-heuristics for continuous optimization problems. This direction needs further study since we are more interested in letting LLMs design complete algorithms automatically.\nAlthough LLMs have been used to solve various optimization problems and design optimization algorithms, this research direction is just at the beginning, and most work just uses small-scale problems to validate the ability of LLMs in optimization. Undeniably, LLMs combined with EAs provide a promising new way for automated optimization. Thus, we summarize the common and most valuable design in existing work and propose a general LLM-EA automated optimization paradigm in the following subsection, which can help researchers better understand the current research and guide future research."}, {"title": "4.4. LLM-EA Automated Optimization Paradigm", "content": "Through the above review, we can see, that to enhance LLMs' capabilities in solving optimization problems, researchers have increasingly integrated EAs with LLMs. This synergy enables a more efficient and creative searching process, with LLMs generating high-quality candidates and EAs optimizing these candidates through iterative refinement. This complementary relationship strengthens the continuous creativity, allowing for more automated optimization algorithm design. Building on this foundation, we propose an LLM-EA automated optimization paradigm in which LLMs and EAs work together to generate both solutions and heuristics, providing a flexible and powerful framework for automated optimization. Next, we first introduce each component of this paradigm and then present the whole paradigm."}, {"title": "5. In-Depth Analysis of Key Modules in LLM-EA Automated Optimization Paradigm", "content": "Building on the LLM-EA automated optimization paradigm, this section conducts a comprehensive analysis from two perspectives: prompt engineering for LLMs and the evolutionary process for iterative search. By integrating these two aspects, we provide a multidimensional exploration of the LLM-EA automated optimization paradigm.\nPrompts play a fundamental role in this paradigm by guiding LLMs through optimization tasks. The structure of these prompts-consisting of problem descriptions, task instructions, and example data-determines how effectively the LLM participates in tasks such as crossover, mutation, and reflective optimization. Prompts not only provide the LLM with the necessary reference points for generating new candidates, but also are embedded the logic of evolutionary operators, ensuring smooth integration with the optimization process.\nIn the evolutionary process, we focus on three critical components: individual representation [80, 81], variation operators [82], and fitness evaluation [83, 84]. Individual representation shapes how candidates are structured and determine the searching space. Variation operators, such as mutation and crossover, guide the exploration of the searching space. Fitness evaluation drives the process by measuring how well the generated candidates meet the optimization objectives.\nThe following subsections provide detailed explanations of how these components are systematically integrated into the prompt, ensuring that the LLM maximizes its effectiveness in the optimization task. Our analysis reveals how prompts dynamically influence each phase of the evolutionary process, offering deeper insights into the synergistic relationship between LLMs and EAs in automated optimization."}, {"title": "5.1. Individual Representation for Heuristic", "content": "Historically, the representation of solutions in optimization has been purely numerical, particularly in the case of continuous and combinatorial optimization problems, where candidates are expressed as vectors or arrays. While this method remains effective for many tasks, the advent of LLMs introduces new possibilities for representing heuristics. These representations expand beyond simple numerical encoding to incorporate natural language, pseudo-code, and even executable code. This shift allows LLMs to play a more creative role in generating novel problem-solving strategies.\nAfter analyzing current research, we define a novel classification of heuristic representation that extends traditional solution encoding and differentiates between three main types of heuristic representation: Code-Centric Representation, Hybrid Representation, and Augmented Representation, each tailored to different levels of complexity in optimization problems.\n\u2022 Code-Centric Representation: In this form, the heuristic is represented solely as executable code. For instance, FunSearch [65] uses LLMs to generate small, self-contained code snippets that are directly applied to optimization problems. The LLM evolves the code itself, which is designed to perform specific tasks or calculations without the need for external explanations. While this approach is computationally efficient, it lacks interpretability, as the generated code does not come with any accompanying documentation or reasoning. This method is better suited for well-defined problems where efficiency is prioritized over transparency.\n\u2022 Hybrid Representation: This method blends code with natural language descriptions. In the EoH [66] framework, LLMs not only generate executable code but also provide a natural language explanation of the code's logic and intended purpose, as illustrated in Figure 4. This combination bridges the gap between machine-generated heuristics and human-readable explanations. By co-evolving code and descriptions, this approach enhances both performance and interpretability, making it suitable for more complex tasks where understanding the reasoning behind the code is crucial.\n\u2022 Augmented Representation: This extends beyond previous representations by incorporating executable code, natural language descriptions, and domain-specific expert knowledge into the individual representation. For example, unlike FunSearch and EoH, which represent code snippets or code paired with explanations, AutoRNet [49] enhances the representation by embedding higher-level concepts from network science, such as high-degree nodes, low-degree nodes, critical nodes, and network connectivity. This enriched representation allows the LLM to contextualize the code within a broader domain-specific framework, facilitating a deeper understanding of the problem. By incorporating expert knowledge, the LLM is not merely working with logic and procedures but is equipped with the conceptual background to generate more advanced and applicable algorithms. Augmented Representation ensures that the generated heuristics can address complex optimization problems with a higher degree of relevance and adaptability."}, {"title": "5.2. LLM-based Variation Operators", "content": "Traditional EAs rely on predefined operators such as mutation and crossover, which require detailed step-by-step programming and domain-specific expertise. With the advent of LLMs, the role of these operators has evolved, enabling more flexible and dynamic approaches to solution generation and heuristic manipulation. We identify three key advantages that LLMs bring to EAs:\n1. High-Level Instructions Remove the Need for Step-by-Step Programming. Traditionally, variation operators require precise, step-by-step programming to define how solutions are selected, combined, and modified. LLMs eliminate this need by interpreting high-level task instructions written in natural language, enabling flexible solution generation. For instance, the LMEA [57] framework is illustrated in Figure 5(a), where LLMs are given general directives for tasks like parent selection and mutation, allowing them to autonomously generate solutions based on these instructions without needing detailed programming. This approach reduces reliance on domain-specific expertise and enables more flexible solution exploration.\n2. Advanced Manipulation of Heuristics via Natural Language. Heuristics, unlike numerical solutions, are complex algorithms or pieces of code. LLMs excel in applying variation operators to these heuristics by using their natural language understanding to combine, refine, and adjust logical structures. For example, in the EoH [66] framework, five prompt strategies (E1, E2, E3, M1, and M2) are designed and categorized into two groups: Exploration and Modification. Each strategy uses prompts to guide the LLM with different emphases in evolving heuristics based on current population performance and heuristic structure. For example, the detail of E2 strategy is shown in Figure 5(b), which put emphasis on designing a new heuristic different from the given ones.\n3. Incorporation of Domain-Specific Knowledge into Variation Operators: A significant advantage of LLM-based variation operators is their ability to integrate expert domain knowledge into the evolutionary process, as demonstrated in AutoRNet [49] through its Network Optimization Strategies (NOS). By embedding specialized knowledge from fields like network science (e.g., degree distribution, path characteristics, clustering coefficient, centrality measures, and community structure) into the variation operations, LLMs can guide mutation and crossover with insights specific to the problem domain. This allows for more sophisticated and effective heuristics that address complex, domain-specific optimization challenges. For example, in network optimization, AutoRNet uses domain knowledge to adaptively modify network structures, ensuring that the generated heuristics are deeply informed by network science principles. This integration of expert knowledge allows LLMs to generate heuristics that are not only generalizable but also highly specialized, providing a new layer of flexibility and precision in the evolutionary process.\nBeyond generating solutions or heuristics, LLMs also play a pivotal role in optimizing the variation operators themselves. ReEvo [70] introduces a novel reflective mechanism where LLMs evaluate and refine the variation operators by analyzing the performance of previously generated heuristics. Unlike traditional EAs that rely on static operators, ReEvo enables LLMs to reflect on both short-term and long-term performance data. This allows the LLMs to generate adaptive mutation and crossover strategies, leading to more effective exploration of the search space.\n\u2022 Short-term Reflection: LLMs assess the recent individuals, identifying immediate changes needed in mutation or crossover operations. This dynamic response helps the evolutionary process adapt quickly to the promising searching direction.\n\u2022 Long-term Reflection: LLMs evaluate broader trends in the performance of heuristics over multiple generations, allowing for deeper adjustments to the evolutionary strategy. This ensures that the operators evolve alongside the heuristics, leading to more robust solutions.\nThis reflective feedback loops enables LLM-driven optimization of the search strategy itself, moving beyond simple heuristic generation to a more dynamic, self-improving evolutionary process.\nLLMs as variation operators bring two critical innovations: the ability to interpret high-level instructions, eliminating the need for step-by-step programming, and the capacity for sophisticated heuristic manipulation through natural language. When coupled with reflective optimization strategies like those in ReEvo, LLMs offer a dynamic, self-improving approach to EAs, pushing the boundaries of what traditional operators can achieve."}, {"title": "5.3. Fitness Evaluation in Heuristic Optimization", "content": "The quality of solutions for optimization problems can be evaluated directly by the objective function. In contrast", "approaches": "n\u2022 Adaptive fitness evaluation dynamically adjusts the criteria for assessing heuristic performance as the optimization progresses. It allows for broader exploration early in the process and more focused refinement as the search converges. AutoRNet [49"}]}