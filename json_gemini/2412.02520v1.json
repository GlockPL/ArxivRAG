{"title": "Cooperative Cruising: Reinforcement Learning based Time-Headway Control for Increased Traffic Efficiency", "authors": ["Yaron Veksler", "Sharon Hornstein", "Han Wang", "Maria Laura Delle Monache", "Daniel Urieli"], "abstract": "The proliferation of Connected Automated Vehicles represents an unprecedented opportunity for improving driving efficiency and alleviating traffic congestion. However, existing research fails to address realistic multi-lane highway scenarios without assuming connectivity, perception, and control capabilities that are typically unavailable in current vehicles. This paper proposes a novel AI system that is the first to improve highway traffic efficiency compared with human-like traffic in realistic, simulated multi-lane scenarios, while relying on existing connectivity, perception, and control capabilities. At the core of our approach is a reinforcement learning based controller that dynamically communicates time-headways to automated vehicles near bottlenecks based on real-time traffic conditions. These desired time-headways are then used by Adaptive Cruise Control (ACC) systems to adjust their following distance. By (i) integrating existing traffic estimation technology and low-bandwidth vehicle-to-infrastructure connectivity, (ii) leveraging safety-certified ACC systems, and (iii) targeting localized bottleneck challenges that can be addressed independently in different locations, we propose a practical, safe, and scalable system that can positively impact numerous road users.", "sections": [{"title": "1 Introduction", "content": "Highway congestion has widespread social impacts, including disproportionately affecting low-income communities with longer commutes, increased pollution, high stress levels, and reduced economic productivity (Lomax, Schrank, and Eisele 2021; Fattah, Morshed, and Kafy 2022). The proliferation of Connected Automated Vehicles (CAVs) equipped with technologies such as Adaptive Cruise Control (ACC) represents an unprecedented opportunity to utilize these technologies to improve highway traffic flow and reduce congestion (Stern et al. 2018; Wu, Bayen, and Mehta 2018; Delle Monache et al. 2019).\nPrior research on highway congestion reduction explored distributed and centralized vehicle speed control approaches. Distributed approaches typically implement an in-vehicle speed controller that uses information of the vehicle's surroundings to decide when to increase headway and allow vehicles to merge into its lane. These approaches are scalable and effective when the location and time of lane-changes can be accurately predicted, such as in merge and certain bottleneck scenarios (Cui et al. 2021; Zhang et al. 2023a; Vinitsky et al. 2023). However, in multi-lane scenarios, lane changes can occur unpredictably at any time and any point on the road, driven by drivers' intentions and behaviors, rendering these distributed approaches ineffective. Centralized approaches leverage aggregate traffic data to provide high-level guidance for influencing spatio-temporal traffic density (Bayen et al. 2020). While this circumvents the need to predict lane changes, these approaches face challenges in generating the complex speed-control commands necessary to achieve the desired density patterns.\nTo address these challenges, we propose a centralized AI system that influences density more directly by generating time-headway requests that are used by ACC systems to adjust their vehicles' headways. At the core of our systems is a reinforcement learning based controller that continually outputs desired vehicle headways for each road segment leading to the bottleneck, based on real-time traffic conditions. To narrow the gap to real-world deployment, our system is designed to integrate with existing traffic estimation technology, low-bandwidth vehicle-to-infrastructure connectivity, and safety-certified ACC systems. As shown in hundreds of large-scale experiments involving hundreds of vehicles and various CAV penetration rates, our system is the first to demonstrate significant traffic flow improvements over human-driven traffic in realistic, simulated multilane scenarios, where previous methods fall short. As a secondary contribution to improving traffic flow evaluation accuracy, we identify a flaw in a commonly used throughput metric and introduce a modified average speed metric that accounts for entry delays caused by congestion, addressing a limitation highlighted in prior work (Cui et al. 2021). By leveraging existing technologies, ensuring safety through ACC systems, and addressing localized bottleneck challenges, we propose a practical, safe, and scalable system that can potentially enhance the travel experience of numerous road users. Our code is publicly available on GitHub."}, {"title": "2 Related Work", "content": "Traffic congestion poses a significant challenge in highway planning, prompting the development of traffic flow models to understand and mitigate its adverse impacts (Hall 1992; Ni and Leonard 2006; van Wageningen-Kessels et al. 2015; Ferrara, Sicona, and Silvia 2018; Mohammadian et al. 2021). Studies have shown that traffic breakdowns can occur spontaneously and stochastically, even without the presence of bottlenecks (Sugiyama et al. 2008), a phenomenon that classical traffic flow theories fail to adequately explain (Kerner et al. 2015; Kerner 2016). Traffic microsimulators, such as SUMO (Krajzewicz et al. 2012) which we use in this paper, were thus suggested for reproducing observable traffic phenomena, using car-following models of human driving. One such model is the Intelligent Driver Model (IDM), which has been instrumental in reproducing complex phenomena like traffic jams, stop-and-go waves, and bottleneck congestion (Treiber, Hennecke, and Helbing 2000). IDM can reproduce realistic vehicle interactions, particularly when modeling diverse traffic scenarios, and is superior to other models such as the Optimal Velocity Model (OVM) (Band\u014d et al. 1994, 1995) that tends to smooth out traffic by encouraging vehicles to maintain an optimal velocity.\nThe idea to utilize automated vehicles as mobile actuators for alleviating traffic problems is based on the assumption that these vehicles can be systematically coordinated and controlled to optimize traffic flow (Stern et al. 2018; Wu, Bayen, and Mehta 2018; Delle Monache et al. 2019; Gora et al. 2020; Wang et al. 2022, 2023). Inspired by this idea, the CIRCLES project (CIRCLES 2020) has focused on developing traffic control algorithms to optimize traffic flow on highways, and conducted a large-scale, open-road field experiment with 100 CAVs (Wang et al. 2024; Lee et al. 2024). Since developing model-based controllers for traffic congestion is challenging due to the problem's scale and complexity, research on data-driven controllers trained in simulation using Reinforcement Learning (RL) (Sutton and Barto 2018) has emerged. This line of research demonstrated that centralized RL controllers enable wave dissipation and significant average speed increase in single-lane roads with merges or bottlenecks with as low as 10% CAV penetration (Kreidieh, Wu, and Bayen 2018; Vinitsky et al. 2018a,b,c). However, deployment of these approaches might not be scalable due to the challenge of learning a policy that individually controls a large numbers of vehicles.\nTo enable scalability, distributed approaches have employed in-vehicle speed controllers that utilize information about a vehicle's surroundings to determine when to increase headway and allow other vehicles to merge into its lane. These approaches work well when the location and time of lane-changes can be accurately predicted, e.g. in merge and certain bottleneck scenarios (Cui et al. 2021; Zhang et al. 2023a; Vinitsky et al. 2023). However, in multi-lane scenarios, lane changes can occur unpredictably at any time and point on the road, rendering these distributed approaches ineffective.\nAs an alternative, centralized approaches have used aggregate traffic data to provide high-level guidance without modeling local behaviors, such as lane-changes. The Variable Speed Limit (VSL) method (Hegyi, De Schutter, and Hellendoorn 2005; Lu and Shladover 2014) aims to prevent traffic breakdowns by regulating inflow into congestion-prone areas. Extensive studies of VSL (Li et al. 2017; Nie et al. 2021; Alasiri, Zhang, and Ioannou 2023; Zhang et al. 2023b; Hua and Fan 2023) have explored its application through optimization problems, such as minimizing total travel time or maximizing traffic throughput (Bayen et al. 2022). However, these approaches have struggled to address realistic multi-lane scenarios due to the difficulty of achieving the required road dynamics when only speed limits are controlled (see Section 4.2). To overcome these limitations, we propose a centralized AI system that avoids the need to predict lane changes or implement complex speed control. Instead, our method employs time-headway control (Pang and Huang 2022) to directly influence spatio-temporal traffic density to enhance traffic efficiency. By leveraging existing traffic estimation technology, low-bandwidth vehicle-to-infrastructure communication, and safety-certified ACC systems, our approach offers a practical, safe, and scalable solution for real-world applications."}, {"title": "3 Domain Description", "content": "In this section, we define the problem addressed by this paper, and the simulation setup used in the experiments."}, {"title": "3.1 Problem Description", "content": "Traffic congestion frequently occurs when the demand for road use exceeds the available capacity. Addressing this imbalance by reducing demand typically involves long-term, systemic changes, such as enhancing public transportation infrastructure. Therefore, in this paper we assume that demand is given, and focus on optimizing road capacity. Road capacity can be optimized by influencing driving behavior to mitigate the impact of capacity-reducing phenomena, such as lane changes at bottlenecks.\nOur problem is defined as follows. Given a road network with multiple lanes, a merging road, and mixed autonomy traffic consisting of both human-driven vehicles and CAVs, maximize the network's traffic efficiency by controlling CAVs, where traffic efficiency is measured in terms of average speed. We assume that CAVs are altruistic, sharing the common goal of reducing traffic congestion, which can be facilitated by incentivizing such behavior. A solution to our problem is a control policy that maps the traffic state to actions that influence CAVs to enhance traffic efficiency. For reasons described in Section 4, we propose and focus on control policies that influence CAVs equipped with technologies such as ACC, by sending them time-headway commands based on real-traffic information.\nWe note that in simulated open road networks where vehicles enter and exit dynamically, increased average speed may not accurately reflect real-world traffic flow improvements due to discrepancies between finite simulated roads and real-world conditions (Cui et al. 2021). To address this, we propose a novel average speed metric that aligns more closely with real-world scenarios, enabling more reliable evaluation of our system's performance (Section 4.1)."}, {"title": "3.2 Simulation Platform & Scenario Parameters", "content": "To test our system in large-scale simulations, we use the SUMO traffic simulator (Krajzewicz et al. 2012), which dynamically models all vehicles and their interactions. We interface SUMO with a custom environment following the Gymnasium API (Towers et al. 2024), enabling the training of controllers using reinforcement learning algorithms from the RLlib library (Duan et al. 2016).\nThe road network used in our simulations is a 2 km segment of I-24 in Tennessee, USA, extracted from OpenStreetMap (2017). The simulation includes hundreds of vehicles engaging in complex lane-changing and car-following interactions, with vehicles merging onto the highway and executing required lane changes. Figure 1a presents a partial snapshot of our scenario in SUMO, featuring a centralized control policy that senses traffic conditions and issues time-headway commands. These commands are utilized by ACC systems to dynamically adjust vehicle headways.\nHuman-driven vehicles are modeled using IDM (Treiber, Hennecke, and Helbing 2000) which has a fixed time-headway parameter and a safety enforcement module. CAVS are modelled using IDM with a time-headway parameter that can be dynamically adjusted. Before real-world deployment, automated vehicle models should be calibrated with real-world data prior to using them with time-headway controllers, however due to the lack of such data and the aim of ACC systems to follow human-driving behaviors, we used the aforementioned adjustable IDM models. An additional challenge is modeling lane-change behavior, which significantly affects traffic flow (Figure 1b). Aggressive lane-change behavior, characterized by vehicles merging into smaller gaps, causes major disturbances and decreases both speed and throughput. Timid lane-change behavior cause disturbances by low utilization of additional lanes. We adjusted lane-change aggressiveness through visual inspection to better align with real-world driving behavior. Lane-change behavior should ideally also be calibrated with highway data if available. Values of all SUMO parameters can be found in the Appendix."}, {"title": "4 Methodology", "content": "In this section, we present our methodology for designing and testing the proposed time-headway controllers. First, we introduce a congestion metric that overcomes the limitations of finite-length simulations highlighted in prior research. Next, we analyze vehicle interactions contributing to traffic inefficiencies, identify the shortcomings of existing methods, and justify our centralized time-headway control approach. We then outline our practical design choices. Finally, we describe a baseline fixed-value time-headway control policy, and our proposed RL-based control policy."}, {"title": "4.1 Congestion Metrics", "content": "To demonstrate improvements in traffic flow efficiency, it is essential to define how congestion is measured. In an ideal scenario with constant inflows, there are multiple metrics that would all lead to the same quality-ordering of congestion-reduction control policies: maximizing average speed, maximizing network outflow, and minimizing average time delay (Dresner 2008). Both average speed and average throughput are commonly used metrics, but each has its drawbacks in simulations. Average throughput is sensitive to the simulation length, since a temporary decrease in throughput can be offset by a subsequent increase, if the simulation is long enough and includes periods with demand lower than road capacity. While changes in average speed can effectively measure congestion, caution is needed when using this metric in finite road length simulations, especially when testing controllers. A controller that prevents vehicles from entering the simulation might artificially inflate speeds without being penalized for the reduction of speeds that would have happened in real-world road sections preceding the simulated road network (Cui et al. 2021).\nWe solve the aforementioned problem by tracking vehicles whose entry to the simulation is delayed and penalizing for the delay time. The metric we use is the average speed change compared to a simulated human-driven traffic, taking into account the delay time of each of the vehicles:\n$\\Delta V = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{v^{(i)}_{control} - v^{(i)}_{baseline}}{v^{(i)}_{baseline}}$ (1)\nwhere N is the total number of vehicles, $v^{(i)}_{baseline}$ is vehicle i's average speed in simulated human-driven traffic, and $v^{(i)}_{control}$ is the same vehicle's speed in the controlled simulation. Average speed computations assume that delayed vehicles have a speed of 0 while they wait to enter the simulation:\n$T^{(i)}_{delay} =  min (T^{(i)}_{f}, T_{sim}) - T^{(i)}_{0}$ (2)\nwhere $L^{(i)}$ is the distance driven by vehicle i, $T^{(i)}_{0}$ is its planned simulation entry time, $T^{(i)}_{f}$ is its measured finish time, and $T_{sim}$ is the final simulation time. $T^{(i)}_{0}$ of each vehicle is known apriori and stored in a per-vehicle route file used to initialize the SUMO simulation."}, {"title": "4.2 Centralized Time-Headway Control", "content": "To motivate our centralized time-headway control approach, we identify and address factors that may have prevented prior methods from handling realistic multi-lane scenarios. Prior research has shown that lane changes during merges can cause slowdowns and trigger congestion. However, if a vehicle in the target lane preemptively increases its headway as it approaches the merge, it can prevent congestion from forming, as illustrated in Figure 2a. Distributed approaches typically implement an in-vehicle speed controller that uses information of the vehicle's surroundings to decide when to preemptively increase headway. These approaches are scalable and effective when the location and time of lane-changes can be accurately predicted, such as in merge and certain bottleneck scenarios. However, in multi-lane scenarios, lane changes can occur unpredictably at any time and any point on the road, driven by drivers' intentions and behaviors, rendering these distributed approaches ineffective.\nIn such scenarios, it may be desirable to try approaches of higher-level control over road density, motivated by real-world data showing that lower traffic density reduces the negative impact of lane changes on traffic flow (Yang, Wang, and Quddus 2019; Gao and Levinson 2023). Since density is an aggregate measure, it is naturally controlled using a centralized controller. Centralized approaches that attempt to control each CAV individually face scalability issues (Cui et al. 2021). Instead, centralized approaches such as Variable Speed Limit (VSL) used aggregate traffic data to provide high-level guidance by employing speed-limit adjustments in controlled road segments. However, these approaches struggle with controlling traffic density. As shown in the qualitative vehicle trajectory time-space diagram in Figure 2b, applying a constant speed limit in a road segment can only temporarily reduce downstream density (blue area). In contrast, constant time-headway signals maintain lower downstream density for an arbitrary duration. This is empirically demonstrated in Figure 2c, where a constant time-headway control signal results in a complex, time-dependent upstream speed profile that would be difficult to achieve with speed-limit control."}, {"title": "4.3 Practical Design Choices", "content": "An AI system that influences CAVs equipped with technologies such as ACC must address several key objectives to be practical:\n\u2022 Safety: The system should enhance traffic flow while maintaining safe operations.\n\u2022 Simplicity and Generality: To ensure broad applicability and ease of implementation across diverse environments, the system must be simple and generalizable.\n\u2022 Deployability and User Acceptance: For successful deployment, the system's decisions must be transparent, instilling confidence among drivers and stakeholders.\nTo address safety, our system influences existing safety-certified ACC systems by sending them desired time-headway commands that can only increase the time-headway above its default value. We assume the availability of low-bandwidth vehicle-to-infrastructure communication that allows vehicles to receive a few floating-point values every few seconds representing desired time-headways, supporting the simplicity and generality objectives. The infrastructure is assumed to measure traffic metrics across different road segments, such as average speed, density, and throughput. This type of sensing is already available, and was recently used in a large-scale open-road experiment (Lee et al. 2024), supporting the deployability of our proposed system. The system's time-headway decisions can be made transparent to users and support user-acceptance."}, {"title": "4.4 Fixed-Valued Time-Headway Control", "content": "Before proposing an RL-based time-headway control policy, it is natural to ask whether a simpler fixed-value time-headway control policy can outperform human-driven traffic, and if so, whether RL can offer significant additional improvements. We therefore design a controller that sends an optimized fixed time-headway signal to road segments located before a bottleneck. The controller activates when vehicles are detected on the merging road, and deactivates when no vehicles are present there. When deactivated, vehicles return to their default time-headway. The optimal time-headway value is optimized by a parameter sweep."}, {"title": "4.5 RL-based Safe Time-Headway Control", "content": "The dynamic nature of traffic suggests that a controller capable of adjusting time-varying headway values would outperform a fixed time-headway approach (Yanakiev and Kanellakopoulos 1995). The ability of reinforcement learning (RL) to learn from interactions with the environment makes it a good fit for complex, dynamic, and stochastic environments such as traffic control. We design an RL-based controller that continuously monitors the traffic state, determines time-headway commands for each controlled road segment, and communicates these commands to automated vehicles traveling within those segments. While RL policies typically do not have safety guarantees, our RL controller ensures safety by sending headway commands above the minimum safe threshold to a safety-certified commercial ACC system, which consistently maintains a safe following distance. Notably, no crashes occurred in our experiments.\nTo apply RL to our traffic control problem, we model the problem as a discrete-time, finite-horizon Markov Decision Process (MDP) (Puterman 2014), defined by a tuple M = (S, A, P, R, po, T), where S is the set of possible environment states, A is the set of all possible actions, P:S\u00d7A\u00d7S \u2192 [0,1] is a state transition probability distribution, R:S\u00d7A \u2192 R is a reward function mapping a given state and the action taken from it to a numeric reward, po : S \u2192 [0, 1] is a distribution over initial states, and T is the problem's time horizon. In an MDP, the goal of the RL algorithm is to learn a decision-making policy \u03c0 : S \u00d7 A \u2192 [0,1] that stochastically maps states to actions and maximizes the expected cumulative sum of rewards over all trajectories $E_{\\tau} [\\sum_{t=0}^{T} R(s_t, a_t)]$. Here is a trajectory $[s_0, a_0, s_1, a_1, \\dots, s_T, a_T]$, where the initial state $S_0$ is sampled from the initial state distribution: $S_0 \\sim p_0$, actions are sampled from the policy: $a_t \\sim \\pi(s_t)$, and the next state in the trajectory is sampled from the transition probability: $S_{t+1} \\sim P(s_t, a_t)$, defined by the traffic simulator.\nModeling Traffic Control as an MDP We model our traffic control problem as an MDP by defining its states, actions, reward function, and horizon. The initial state distribution and the transition function are determined by the simulator.\nStates To allow effective control of traffic density, our state representation encapsulates relevant information that is (i) needed for predicting the traffic's evolution over time, and (ii) is reasonable to obtain using current technology. Therefore, a state includes the average speeds and densities in each of 21 road segments preceding and following the traffic bottleneck area, where each segment is about 100 meter long. In general, both speed and density are necessary in the state representation to avoid ambiguity.\nActions The actions A correspond to the required time-headway values for automated vehicles in each segment. Since density typically accumulates in the segments preceding the traffic bottleneck, changing density in these segments offers the highest potential for improving traffic efficiency through density control. Therefore, our action is a vector of real numbers representing desired time-headways in each controlled segment preceding the bottleneck. In our experiments we tried setups with 2-5 controlled segments. For the tested scenario, controlling the time-headway for 2 road segments was found to allow faster RL convergence without performance compromise. Thus, the RL algorithm results in this work were trained using 2 control segments. While more granular actions spaces could be used, such as separate headway for each lane in each controlled segment, a single headway per segment would be more practical to implement in the real-world, as it avoids the need to estimate vehicles' lane-position.\nReward Function The reward function plays a crucial role in the RL training process, as it guides the agent toward maximizing the desired performance metric. As described in Section 4.1, our performance metric is the relative average speed increase compared with a baseline simulated human-driven traffic. However, the average speed of a vehicle can only be computed once a vehicle had completed its route, so using it would delay the reward and pose challenges for current RL algorithms.\nTo provide a more immediate reward that serves as a proxy for our metric, we use a time-delay reward function that is measured relative to free-flow traffic conditions. The reward at time t is:\n$\\frac{1}{Nt} \\sum_{i=1}^{Nt} C \\frac{v_{free}(x^{(i)}_t) - v^{(i)}_t}{v_{free}(x^{(i)}_t)} \\Delta t$ (3)\nwhere Nt is the number of vehicles planned to enter the simulation by time t, $x^{(i)}_t$ and $v^{(i)}_t$ are the location and velocity of vehicle i at time t, $v_{free}(x)$ is the speed limit of the road at location x, and C is a normalization factor that scales episode returns to the interval [0, 1], to avoid numerical issues when using neural networks. For delayed vehicles which did not yet enter the simulation, the speed is assumed to be 0. When this reward is accumulated for all simulation time-steps, it provides an approximation for the average time delay for all vehicle trajectories, relative to free flow. This time-delay corresponds to our average speed performance metric as described in Section 4.1. The advantage of this reward over our metric is its immediate feedback on the impact of the current traffic state over the overall average speed.\nHorizon The horizon is scenario dependent. We discuss the horizon length determination in Section 5.\nTraining Setup To solve the traffic control problem modeled as an MDP, we utilize the Proximal Policy Optimization (PPO) algorithm (Schulman et al. 2017). PPO is chosen for being well-suited for complex control tasks in continuous action spaces and for its training stability, but other state-of-the-art continuous RL algorithms could work similarly well. We use RLlib's PPO implementation (Duan et al. 2016) with most of its default hyperparameters, including a dual-head neural network representing both the policy and value functions with two hidden layers of 256 units each and tanh activation functions, and a linear output layer representing a diagonal Gaussian with mean and standard deviation for each controlled segment. We use a batch size of 2000, surrogate-, value-function-, and KL-losses, discount factor $\\gamma$ = 0.99 reflecting an effective horizon of about 100 steps, actions that are bounded to 1.5-6 second headway to reflect realistic values, and rewards that are normalized such that the value function's magnitude lies in a range that can be processed by a neural network without numerical issues. The training process is carried out over 25000 episodes, with each episode representing a finite-horizon simulation of traffic flow in our environment. Overall, the PPO algorithm, combined with our carefully designed training setup, enables the development of a policy that dynamically adjusts time-headways to optimize traffic flow while maintaining safety."}, {"title": "5 Empirical Analysis", "content": "In this section, we describe the experimental setup used to evaluate the proposed time-headway control strategies and present the results obtained from the simulations.\nExperiments were conducted in the SUMO simulation environment using a highway network with a single merge, based on an approximately 2 km segment of route I-24 in Tennessee, USA (see Section 3.2). The route was divided into 20 segments of approximately 100 meters each, plus an additional segment for the merging road. This segment length was chosen to ensure effective sensing and control resolution while being long enough to maintain stable control policies. The default time-headway parameter value is 1.5 seconds, and the speed limit on the highway is 31.29 m/s (70 mph). Traffic inflow to the highway matches the maximum capacity of 1800 vehicles/hr/lane. Vehicles from the merging road enter the simulation at maximum inflow after a 200-second warm-up for a duration of 30 seconds in the single-lane scenarios, and 50 seconds in the multi-lane scenarios, to create realistic traffic disturbances that negatively affect traffic flow. The simulations ran for 500 seconds to allow congestion to form and dissipate. An action interval of 2.5 seconds was chosen to reflect a realistic duration for influencing traffic dynamics, considering vehicle response times and acceleration characteristics.\nFor each scenario we tested the performance of the following traffic configurations:\n1. (Baseline) 100% Human-Driven Traffic\n2. (Baseline) Mixed Traffic with Fixed-Valued Time-Headway Control: Traffic consisting of both human drivers and a fraction of 10-100% CAVs, which set their headway based on commands sent by the fixed-valued time-headway controller described in Section 4.4. The controller was tuned to the best performing fixed-valued time-headway.\n3. (Ours) Mixed Traffic with RL-based Controller: Traffic consisting of both human drivers and a fraction of 20-100% CAVs, which set their headway based on commands sent by the RL-based time-headway controller described in Section 4.5.\nThe two baselines were selected for the following reasons. First, human-driven traffic represents the current status quo, serving as a benchmark for improvement. Previous congestion reduction methods have generally not tackled realistic multi-lane highway scenarios involving lane changes and merges, likely due to the limitations discussed in Section 4.2. In our evaluations, these methods underperformed compared to human-driven traffic and were therefore omitted. Second, the manually tuned baseline is included to demonstrate the necessity of a more sophisticated RL-tuned controller.\nNotably, an ablation analysis would be less informative for our system, as it relies on essential components whose removal would compromise functionality. Specifically, speed and density are necessary in the state representation to avoid ambiguity, and the reward function is directly derived from the performance metric to ensure alignment with our objectives. Additionally, sensitivity analysis indicated that the system is robust to minor changes in the number and length of road segments, as well as in action ranges.\nFigure 3 presents results from hundreds of experiments under the most challenging traffic flows and varying percentages of controlled vehicles. Each scenario configuration was run 30 times with different random seeds, enabling the computation of 95% confidence intervals. We focused on two scenario types: a simplified merge with a single-lane main road, and a complex merge with a multi-lane highway:\nSingle-Lane Scenarios Highway vehicles drive on the rightmost lane, no lane changes are allowed, and a single-lane road merges into the highway. This simplified setup tests the feasibility of time-headway control. The tuned fixed-value control improves merge efficiency and traffic flow over the human baseline across different CAV fractions (Figure 3a). RL-based control further enhances performance for CAV fractions of 40% and above, achieving up to a 16% average speed increase in the 100% CAV scenario.\nMulti-Lane Scenarios All highway lanes are used, lane-changes are allowed, and a single-lane road merges into the highway, creating a congestion-prone bottleneck. Time-headway control signals are sent to all lanes in controlled segments. While lane-specific control could be more effective, it requires extra sensing, limiting practicality. Fixed-value time-headway control improves merge efficiency and traffic flow only at low or 100% CAV fractions (Figure 3b). In contrast, our RL-based controller outperforms both the human baseline and fixed-value control across all CAV fractions, achieving up to a 7% increase in average speed at 100% CAV fraction.\nOverall, our RL-based controller outperforms the fixed-headway controller in scenarios with complex dynamics: specifically, in single-lane settings with CAV fractions of 40% or more, and in multi-lane settings with CAV fractions of 20% or more, where fixed-headway controllers are challenging to tune and may struggle to represent effective control strategies. These experiments robustly demonstrate the effectiveness of our approach, which is the first to handle realistic multilane scenarios."}, {"title": "6 Conclusions", "content": "This paper proposes a dynamic time-headway control approach for increasing the average travel speed of vehicles while maintaining safety in high-volume highway traffic. By integrating with existing traffic estimation technology and low-bandwidth vehicle-to-infrastructure connectivity, and leveraging safety-certified adaptive cruise control systems, our method offers a practical path towards real-world implementation. Our safe reinforcement learning-based time-headway controller outperforms both baselines and alternative approaches across a variety of automated vehicle penetration rates, in both single- and multi-lane realistic, simulated scenarios featuring hundreds of vehicles. Notably, even at low penetration rates, adjusting time-headways led to measurable improvements in average traffic speeds.\nWhile these results are encouraging, several avenues for future work remain. First, deploying an RL controller trained in simulation into the real world requires it to be robust to diverse traffic flows and driving styles, and trained on simulations calibrated with real-world data. Additionally, real-world testing is crucial to validate the simulation results and overcome practical implementation challenges. Finally, integrating this approach with other traffic management strategies, such as ramp metering or dynamic lane assignment, could potentially yield even greater efficiency gains. As automated vehicle technology continues to advance, time-headway control emerges as a promising tool for transportation engineers and policymakers seeking to alleviate congestion and improve mobility in our road networks."}, {"title": "A Simulation Details", "content": "This section describes the details of simulations shown in various figures in the paper."}]}