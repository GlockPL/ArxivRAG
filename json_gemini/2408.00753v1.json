{"title": "A deep learning-enabled smart garment for versatile sleep behaviour monitoring", "authors": ["Chenyu Tang", "Wentian Yi", "Muzi Xu", "Yuxuan Jin", "Zibo Zhang", "Xuhang Chen", "Caizhi Liao", "Peter Smielewski", "Luigi G. Occhipinti"], "abstract": "Continuous monitoring and accurate detection of complex sleep patterns associated to different sleep-related conditions is essential, not only for enhancing sleep quality but also for preventing the risk of developing chronic illnesses associated to unhealthy sleep. Despite significant advances in research, achieving versatile recognition of various unhealthy and sub-healthy sleep patterns with simple wearable devices at home remains a significant challenge. Here, we report a robust and durable ultrasensitive strain sensor array printed on a smart garment, in its collar region. This solution allows detecting subtle vibrations associated with multiple sleep patterns at the extrinsic laryngeal muscles. Equipped with a deep learning neural network, it can precisely identify six sleep states\u2014nasal breathing, mouth breathing, snoring, bruxism, central sleep apnea (CSA), and obstructive sleep apnea (OSA)\u2014with an impressive accuracy of 98.6%, all without requiring specific positioning. We further demonstrate its explainability and generalization capabilities in practical applications. Explainable artificial intelligence (XAI) visualizations reflect comprehensive signal pattern analysis with low bias. Transfer learning tests show that the system can achieve high accuracy (overall accuracy of 95%) on new users with very few-shot learning (less than 15 samples per class). The scalable manufacturing process, robustness, high accuracy, and excellent generalization of the smart garment make it a promising tool for next-generation continuous sleep monitoring.", "sections": [{"title": "I. Introduction", "content": "Sleep occupies about one-third of a person's daily life, and its quality is crucial to overall human well-being. Statistics indicate that more than 60% of adults suffer from poor sleep quality, which results in the loss of approximately 44 to 54 working days per year and contributes to an estimated annual global GDP reduction of between 0.64% and 1.31% [1, 2, 3]. Among the culprits are sub-healthy or high-risk sleep patterns such as mouth breathing, snoring, teeth grinding, and sleep apnea, which significantly contribute to the degradation of sleep quality [4, 5, 6, 7]. These unhealthy sleep states have been extensively studied and identified as risk factors for various chronic diseases, including cardiovascular disease, diabetes, and emotional disorders [8, 9, 10]. \u03a4\u03bf improve people's sleep quality and to provide early warnings for related chronic diseases, monitoring and identifying these unhealthy sleep states have become a focal point in modern health management. Traditional sleep monitoring methods, such as polysomnography (PSG), although comprehensive and accurate, require specific facilities and involve complex, costly equipment, making them unsuitable for long-term or home use [11]. To address these issues, researchers and engineers have been exploring more portable, cost-effective, and user-friendly solutions.\nIn recent years, the rapid development of smart wearable devices has provided a promising approach to portable sleep health monitoring [12, 13, 14]. The most common monitoring platforms integrate photoplethysmography (PPG) sensors and motion sensors within watches or wristbands, in both academia and industry [15, 16, 17]. Although these platforms offer convenience as a scaled-down version of PSG, they inherently lack the capability to collect sufficient human physiological data required for analyzing different sleep states [18]. Some innovative designs integrate physical sensors such as humidity, mechanical, and acoustic sensors in mask-like setups placed near the nose to monitor airflow and sounds during sleep [19, 20, 21, 22, 23]. While these devices cover a broader range of physiological information, achieving comprehensive sleep pattern monitoring with such setups requires integrating multiple sensors, either within the same area of the body or across different body locations, which adds bulkiness and reduces system energy efficiency, hindering long-term continuous wear [19, 21, 22]. An alternative approach takes inspirations from the modalities of PSG, integrating electrophysiological sensors like electroencephalograms (EEG), electrooculogram (EOG), and electromyogram (EMG) into facial or ear areas using user-friendly technologies like electronic skin and miniaturized integration [24, 25, 26]. This method collects essential indicators related to sleep health. Despite the improvement in the level of comfort and information richness, the monitoring accuracy of non-invasive electrophysiological sensors is still hindered by inherent artefact noise, leaving room for improvement in accuracy [27, 28]. Thus, there is still a lack of versatile technology with both good comfort and high precision for continuous monitoring and recognition of various sleep patterns.\nThe key to addressing this issue lies in finding a signal modality that not only encompasses the information necessary for analyzing various sleep states but can also be captured by wearable devices in a manner that ensures a high signal-to-noise ratio and comfort. Here, we develop a versatile smart garment integrated with an ultrasensitive sensor array directly printed on the collar, capable of monitoring and identifying multiple sleep patterns. Direct printing on garments allows for the integration of multi-functional electronic elements directly onto the garment with scalability"}, {"title": "II. Results", "content": "and design flexibility. The developed smart garment is able to collect mixed-mode signals generated by vibrations from various sleep activities such as breathing, snoring, teeth grinding, and sleep apnea, which are transmitted to the extrinsic laryngeal muscles from multiple anatomical locations including the velum, oropharynx, tongue, and epiglottis (Figure 1a). Utilizing a multi-channel graphene textile strain sensor, screen printed at its collar based on principles of ordered cracks and selective sizing treatments, the smart garment leverages ultrahigh sensitivity (gauge factor >100), scalability ( \u00b1 20% conductivity fluctuation), and durability (stable over 10,000 cycles of stretching tests) to continuously monitor subtle vibrations of the extrinsic laryngeal muscles while ensuring user comfort. Additionally, due to its multi-channel design, the smart garment can be easily used by wearers in a positioning-free manner in real-world scenarios. The designed deep learning model, SleepNet, uses the captured signals to accurately identify six sleep states ranging from healthy to sub-healthy to high-risk, including nasal breath, mouth breath, snoring, bruxism, central sleep apnea (CSA), and obstructive sleep apnea (OSA), achieving an accuracy of 98.6% along with decent inference speed (Figure 1b). Explainable artificial intelligence (XAI) visualizations confirm that the model comprehensively understands the sleep patterns, avoiding biases towards noisy regions, thus demonstrating its robustness. Moreover, transfer learning tests show that after few-shot learning (with only 15 samples per class), the model can achieve up to 95% classification accuracy on new users, showcasing the system's powerful generalization capabilities. In Table 1, we have summarized the functions and features of our system compared with other wearable sleep monitoring systems in the literature. We believe that this versatile smart garment will become a pivotal tool in enhancing diagnostic precision, personal health tracking, and therapeutic interventions for sleep-related disorders, as well as fostering advancements in telemedicine and personalized medicine strategies.\nPrinted strain sensor array on garments\nFigure 2a illustrates the multi-layered structure of the strain sensing array screen-printed on a high-neck top made of elastic knitted fabric. In the multi-layer screen printing process, printing quality is highly sensitive to parameters and can be easily affected by changes in printing conditions and ink properties. Here we introduce, for the first time, a starching layer consisting of sodium carboxymethyl cellulose (CMC Na) and polyurethane acrylate (PUA) printed onto the interconnect and sensing areas to customize the rigidity and printability of the substrate. Both cellulose derivatives and acrylates are common starching agents in garment printing industry [29]. CMC Na is a water-soluble polymer derived from cellulose known for its film-forming ability, which provides a smooth and uniform surface [30]. CMC Na also improves the adhesion of the printed graphene ink to the substrate, reducing the likelihood of delamination under mechanical stress. The PUA provides high stiffness and excellent adhesion by forming a robust, cross-linked network upon UV exposure [31]. Introducing a rigid PUA layer in the textile strain sensor array modifies the rigidity of selected area on the textile, redistributing strain caused by body movements during sleep (Supplementary Figure 1). The isolated area remain inert to large-scale uniaxial stretching, ensuring that local strain is accurately measured without interference, as shown in Supplementary Figure 3. The UV-curable nature also prevents clogging of the screen during the printing process, extending the lifespan of the printing screen and maintaining consistent printing quality. After starching treatment, the crossbar silver electrodes separated by an insulating layer are printed, followed by the graphene sensing layer on the surface comprising exfoliated graphene flakes bound with ethyl cellulose (EC). The graphene flake is selected to under 1 \u00b5m before ink formulation to ensure stable dispersion and avoid mesh clogging (Supplementary Figure 4). Controlling the formation of ordered cracks is critical for fabricating crack-based strain sensors with repeatable performance [32]. During the screen-printing process, the ink is squeezed through the mesh by the squeegee, depositing a thin film onto the substrate. The stress concentration at the boundaries of the textile structural units induces the formation of regular cracks (Figure 2b). This process does not require complex pre-stretching or pre-treatment steps, making it compatible with garment processing. However, capillary forces cause the ink to spread, while air pockets block ink deposition, leading to variability and poor printing quality. Excessive penetration of graphene ink into the textile can create a graphene/textile composite, which is insensitive to strain and acts as an extra conductive pathway to the surface cracking layer (Supplementary Figure 5). To inhibit ink penetration and air trapping during the printing process, another starching treatment with CMC Na was used to create a controlled surface for ink deposition, preventing deep penetration and ensuring the graphene forms a brittle surface layer that cracks under strain. As shown in Supplementary Figure 7, the penetration depth of graphene ink in starched textile is significantly lower compared to untreated textile. The fabrication process is illustrated in Supplementary Figure 8. It is scalable and compatible with industrial garment printing processes, making it feasible for mass production of smart garments. The graphene/EC coating with ordered cracks shows a reliable linear response to small uniaxial strains from 0.1% to 5% with a gauge factor over 100 (Figure 2c). Moreover, the strain sensors demonstrate a rapid response to straining cycles with frequency ranging from 1Hz to 10 Hz (Figure 2d), enabling the real-time monitoring of fast and subtle vibrations produced by the throat during sleep. The durability of the graphene sensor was tested through tensile tests at 1% uniaxial strain and 1 Hz frequency, showing consistent performance (Figure 2e). In contrast to the high response of the strain-sensing layer, the stretchable silver electrodes exhibit high conductivity with negligible strain response, ensuring stable electrical connections (Figure 2f). To ensure consistency and reliability, we studied the performance distribution of two-terminal resistance and gauge factor across 50 strain sensor units. A resistance variation of less than 12.69% and a gauge factor variation of less than 9.16% were achieved by controlling printing condition and applying starching treatments, as shown in Figure 2g. The washability of the sensors was tested by immersing the devices in water under 500 rpm stirring for 5 to 60 minutes, drying at room temperature. The performance degradation after washing was less than 10%. Similar results were observed when detergent was added (Figure 2h). The textile substrate is known for its breathability, and after being integrated into a device, our smart garment still maintains excellent breathability. Its performance in the MVTR test (Supplementary Figure 9) is much better than that of Tegaderm, a commonly used medical dressing manufactured by 3M. Additionally, the strain sensor array shows no skin irritation or other side effects during 8 hours of wear, which is a typical sleep period (Supplementary Figure 10).\nMonitoring of sleep behaviour with the strain sensor array\nWe employed a six-channel strain sensor array integrated into the collars of textile garments, positioned around the participants' necks. This setup was designed to collect minute vibrational signals from the extrinsic laryngeal muscles, which vary according to different sleep behaviours"}, {"title": "III. Discussion", "content": "(Figure 3a). Utilizing a multiplexer, we could read the responses from a circular six-channel piezoresistive strain sensor arranged in a cross-bar structure for further analysis. In our design, each circular sensing channel can be equivalently viewed as a parallel connection of four quarter-ring variable resistors, as shown in Figure 3b, when we reflect the resistance values of the vertical and horizontal lines of the sensors. This design provides two-dimensional sensitivity to both horizontal and vertical strain. Figure 3c illustrates the response signals during a 10-second epoch of nasal breathing, captured by the six channels at standard wearing positions. Correlation analysis revealed that although the intensity of the strain responses varied across different channel locations covering the throat area, the signal characteristics were highly correlated (Pearson correlation coefficients greater than 0.9 between any two channels). This pattern persisted even when the sensor array was worn askew, not in the standard position (see Supplementary Figure 11). These findings demonstrate that our design, which utilizes a relatively large coverage area of the strain sensor array, essentially ensures that the region with the strongest response falls within the device sensitive area. Consequently, our sleep behaviour monitoring system does not require precise positioning, implying a level of resilience to positional variances that augments the practicality of this monitoring system in real-world settings. Furthermore, due to the high correlation between channels, subsequent neural network-based pattern recognition needs only to consider the channel with the strongest response as representative, which improves the network's inference efficiency while ensuring accuracy.\nTo ensure the reliability of the proposed approach, we built a comprehensive dataset encompassing six distinct sleep behaviour patterns: nasal breathing, mouth breathing, snoring, bruxism, CSA, and OSA. The dataset was collected from seven healthy subjects and spans a health spectrum from healthy and sub-healthy to high-risk categories. Therefore, for the three conditions\u2014bruxism, OSA, and CSA-which are rare among healthy individuals, the data were simulated under the guidance of medical experts. In contrast, data for mouth breathing, nasal breathing, and snoring were collected from actual sleep sessions. Detailed protocols for data collection are described in the Methods section. As visualized in Figure 3d, the temporal and spectral characteristics of these sleep behaviours were meticulously analyzed focusing on the signals emanating from the channel exhibiting the strongest response.We observed that the effective vibrational signals originating from the extrinsic laryngeal muscles are predominantly found within the low-frequency domain, specifically below 10 Hz. This frequency band captures the physiological nuances of each sleep pattern, enabling a precise delineation of the behaviours. Nasal and mouth breathing exhibit fundamental differences in their spectral signatures, reflecting variations in airflow mechanics and potential diagnostic markers for respiratory efficiency. The irregular and prominent vibrational patterns associated with snoring suggest disrupted airflow dynamics and may serve as indicators of upper airway resistance. Notably, the episodic high-amplitude signals of bruxism provide clear evidence of nocturnal teeth grinding, which could be associated with high stress levels or sleep disturbances. The absence of vibrational activity during respiratory pauses in CSA and the erratic signal fluctuations indicative of breathing efforts against obstruction in OSA are consistent with the clinical understanding of these two conditions. More visualization of the samples is shown in Supplementary Figure 12-17.\nSleep patterns recognition with a deep learning model\nAfter simple preprocessing, which involves labeling (see detailed protocols in Supplementary Note 2), segmentation (10s signals were segmented into one sample), and Z-score normalization, signals from the channel with the strongest response are fed into our specially designed deep learning model (SleepNet) for sleep pattern recognition (Figure 4a). The SleepNet is composed of three core components: First, the learnable positional encoder adopts a residual bidirectional LSTM (BiLSTM) framework to understand the sequential nature of the input data. This approach surpasses traditional sinusoidal positional encoding by dynamically learning positional information, which is particularly advantageous in sleep pattern analysis where the temporal relationship between events can signify different breath cycles or disturbances [33]. Second, the multi-head self-attention module, derived from Transformer architecture, enables nuanced discrimination of significance across the data sequence. By effectively utilizing long-range dependencies, the model ensures a comprehensive understanding of the sequential data, reflecting the true complexity of sleep behaviours over time [34]. Lastly, the one-dimensional Residual Network (ResNet) layers function as a hierarchical feature extractor. With their ability to skip connections, they prevent the vanishing gradient problem and enhance the flow of information, thus allowing the model to learn more complex patterns effectively. The 1D convolution within these layers ensures that the model is tailored to handle time-series data, offering a nuanced analysis of temporal patterns [35].\nFigure 4b displays the confusion matrix for the model's classification of sleep patterns. The model achieved impressive classification results: the accuracy for each category was above 95%, with an overall accuracy of 98.6%. In the comparative experiments shown in Figure 4c, SleepNet surpassed the performance of its individual component architectures, such as the Transformer and 1D ResNet, as well as other state-of-the-art models in terms of accuracy. Additionally, it's noteworthy that after pruning the least important 50% of the nodes in the 1D-ResNet module of the model and re-training to obtain a pruned SleepNet, not only did the FLOPs (a critical indicator of model inference speed and energy efficiency) decrease by 30%, but there was also a slight increase in accuracy. This can be attributed to the phenomenon known as \"pruning-induced efficiency\", where removing redundant or less important nodes can lead to a more streamlined and efficient network. The re-training phase helps the model to re-allocate its resources towards the most salient features, potentially improving generalization and thus accuracy [36].\nFigure 4d illustrates the process of hyperparameter optimization for the model. It can be observed that in the majority of hyperparameter combinations, the model exhibits high accuracy (greater than 90%). This indicates that the model's performance is not overly sensitive to the specific values of its hyperparameters, demonstrating the model's robustness. Moreover, such robustness might also imply that the fundamental features learned by the model are strong predictors of sleep patterns, allowing for decent performance despite variations in model configuration. Figure 4e shows the ROC curves for the model's classification of each sleep pattern type. The AUC values are almost equal to 1 for each classification task, indicating that the model is effective and has achieved satisfactory classification performance.\nSmoothGrad visualizations in Figure 5a provide a clear depiction of how different segments of the signal contribute to the model's classification decisions [37]. The shading intensity represents the degree to which each point in the time series influences the output, with darker shades indicating"}, {"title": "III. Discussion", "content": "higher importance. For instance, the \u201cNasal Breath\u201d and \u201cMouth Breath\u201d classifications exhibit consistent contribution patterns throughout the breathing cycle, reflecting the model's reliance on rhythmic features for these classes. Conversely, \u201cSnoring\u201d shows a more variable contribution pattern, which likely corresponds to the erratic nature of snoring events. The \u201cBruxism\" class demonstrates pronounced contributions at peaks, which may correspond to teeth grinding instances. In the cases of \u201cCSA\u201d and \u201cOSA\u201d, the model identifies critical contributions at pause cycle and obstruction cycle. This distribution of contributions is consistent with established physiological patterns, which means that the model gives appropriate weight to relevant features across different classes, reflecting a balanced understanding of the data rather than an overreliance on certain input aspects that could lead to skewed predictions (e.g. noise). Furthermore, this underscores the model's capacity to not only recognize but also assign appropriate significance to the distinct temporal features within the complex landscape of sleep-related signals, enhancing the interpretability of its predictions. Figure 5b compares the distribution of raw data with the features extracted by the model in the t-SNE plane, illustrating the model's ability to discern and delineate the complex structure within the data. The t-SNE visualization of extracted features shows distinct clusters corresponding to different sleep patterns, which are not as discernible in the raw data. This indicates the effectiveness of the model's feature extraction in capturing the underlying relationships and patterns necessary for accurate classification.\nTo assess the model's generalization ability, we conducted transfer learning tests, applying the model trained on six participants to the dataset of a new participant. As shown in Figure 5c, with only 15 samples per category for few-shot learning, the model achieved an accuracy of up to 95% on the new subject. In contrast, training only on the new participant's dataset without transfer yielded a few-shot learning accuracy of merely 80%. This reflects the model's ability to adapt and maintain performance across different individuals, showcasing its robust transferability and capacity to leverage previously learned patterns to quickly adapt to new, unseen data.\nDecoding human sleep patterns is important yet complex. Despite the encouraging development of wearable devices for sleep health monitoring in recent years, creating a system that combines versatility, comfort, and accuracy remains a significant challenge. In this work, we have designed a smart garment integrated with a six-channel strain sensor array. This ultrasensitive strain sensor array, characterized by its excellent robustness and durability, can collect subtle vibrations from the extrinsic laryngeal muscles associated with various sleep patterns, and its multi-channel design eliminates the need for positioning due to its spatial resolution. Despite utilizing only a single modality of strain response signals, our smart garment, equipped with a customized deep learning neural network, can comprehensively analyze and recognize subtle vibrations originating from various physiological sites and transmitted to the extrinsic laryngeal muscles. It accurately classifies six sleep patterns: nasal breath, mouth breath, snoring, bruxism, CSA, and OSA. Additionally, it can efficiently and effectively adapt to new users, maintaining high accuracy in its classifications. We believe our smart garment offers a promising solution for versatile sleep monitoring in wearable devices, not only suitable for the consumer electronics market to provide ongoing sleep monitoring for general users but also as a convenient, low-cost alternative for clinical sleep monitoring."}, {"title": "IV. Methods", "content": "Materials\nTIMREX KS 25 Graphite (particle size of 25\u00b5m) was sourced from IMERYS. Stretchable conductive silver ink was obtained from Dycotec Materials Ltd. Ethyl cellulose and sodium carboxymethyl cellulose were purchased from SIGMA-ALDRICH. Flexible UV Resin Clear was acquired from Photocentric Ltd. The textile substrate, composed of 95% Polyester and 5% spandex, was procured from Jelly Fabrics Ltd.\nInk Formulation\nThe graphene ink for screen printing was prepared following a reported method. Briefly, 100g of graphite powder and 2g of ethyl cellulose (EC) were mixed in 1L of isopropyl alcohol (IPA) and stirred at 3000 rpm for 30 minutes. The mixture was then added into a high-pressure homogenizer (PSI-40) at 2000 bar pressure for 50 cycles to obtain graphene dispersion. The graphene dispersion is centrifuged at 5000g for 30 min to remove unexfoliated graphite. To prepare the CMC Na starching solution, CMC Na was dissolved in water at 20% wt. concentration.\nFabrication of Textile Strain Sensor Arrays\nThe textile substrate was washed with detergent, thoroughly dried, and then treated with UV-ozone for 5 minutes to clean the surface. Screen printing was performed using a 165T polyester silk screen on a semi-automatic printer (Kippax & Sons Ltd.) set with a squeegee angle of 45 degrees, a spacer of 2mm, a coating speed of 10mm/s, and a printing speed of 40mm/s. Printing pressure was pneumatically controlled, with higher pressure applied for the viscous starching agent, and moderate pressure for the thinner graphene ink silver ink to reduce penetration. After each printing pass, the textile was blown to dry. After printing, the sensor was washed with water to remove CMC Na and dried at 80 \u00b0C overnight. A biaxial strain of around 10% was then applied to induce the formation of ordered cracks.\nCharacterization of Structure and Performance\nThe size distribution of graphene flakes was analyzed using a Bruker Icon Atomic Force Microscope (AFM) in an area approximately 20 \u00b5m \u00d7 20 \u00b5m. Scanning Electron Microscopy (SEM) images were taken with a Magellan 400, after sputtering the textile samples with a 5 nm layer of gold to enhance conductivity. Optical images were captured using an Olympus microscope.\nTensile Tests\nTensile properties of the textile strain sensors were evaluated using a Deben Microtest 200N Tensile Stage and an INSTRON universal testing system. Electrical signals were recorded concurrently with a potentiostat (EmStat4X, PalmSens) and a multiplexer (MUX, PalmSens). Copper tape was crimped onto the contact pads of the samples, supplemented with a small amount of silver paste to improve electrical contact.\nExperimental setup of data acquisition\nOur strain sensors were screen printed onto the collars of garments, equipped with copper strips at the cross-bar electrodes. For data acquisition, we employed a potentiostat (EmStat4X, PalmSens) and a multiplexer (MUX8-R2, PalmSens) as our primary readout modules. These modules consistently supplied a 1V voltage, with the resulting output being the current passing through the strain sensors. We selected a sampling frequency of 100Hz and segmented the data into 10-second epochs for detailed analysis. Our data collection process was specifically crafted to reflect real-world conditions, accommodating variations in the positioning and tightness of the collar with each use. Throughout our extensive data collection from various participants, we intentionally avoided strict calibration of the collar's position or tightness. Participants were advised to wear the smart garment comfortably and put the collar around their necks, ideally positioned at the mid to upper throat level. This method ensured that our dataset represented a wide range of real-life scenarios, capturing the inherent variability in the collar's positioning and tightness across different users and experimental setups.\nSleep behaviour dataset collection\nSince all our participants were healthy students recruited from the University of Cambridge (7 students, average age 25, 4 males and 3 females), complying with the University of Cambridge Engineering Department's Ethical Approval for the Research Project: \u201cWearable Sensor System for Breath Monitoring\u201d, our subjects did not exhibit significant symptoms of Bruxism, CSA, or OSA. Therefore, the aforementioned three types of sleep behaviour were simulated following training under the guidance of medical experts. For the collection of bruxism, we included simulated instances of grinding, clenching, and tapping; for CSA, we instructed participants in voluntary end-expiratory central apnea during breathing; for the more challenging simulation of OSA, we trained participants to utilise Muller manoeuvre to maintain a lower intrathoracic pressure [38] and followed the characteristic descriptions of reports from the American Association of Sleep Medicine (AASM), introducing clinical SpO2 as an auxiliary simulation tool, marking a segment as a valid OSA pattern only when SpO2 continuously fell below 90% within the epoch, or a continuous decrease of more than 4% from baseline [39]. These simulations were carefully developed with clinicians to ensure the primary mechanics of airway obstruction and breath manoeuvre conform realistic situations. The data for the other three behaviours (nasal breath, mouth breath, and snoring) were collected during actual sleep states. All data collection was performed in a supine position. In total, we collected 2119 epochs, including 728 epochs of nasal breath, 701 epochs of mouth breath, 262 epochs of snoring, 180 epochs of bruxism, 102 epochs of CSA, and 146 epochs of OSA. See more detailed data collection and annotation protocol in Supplementary Note 2.\nSoftware environment\nSignal preprocessing was performed on a MacBook Pro equipped with an M1 Max CPU. Network training was conducted using Python 3.8.13, Miniconda 3, and PyTorch 2.0.1 in a performance-optimized environment. Training acceleration was enabled by CUDA on NVIDIA 4090 GPU.\nData availability\nThe datasets supporting this study will be available from the GitHub repository before publication."}]}