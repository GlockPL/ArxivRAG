{"title": "Exploring Scalability in Large-Scale Time Series in DeepVATS framework", "authors": ["Inmaculada Santamaria-Valenzuela", "Victor Rodriguez-Fernandez", "David Camacho"], "abstract": "Visual analytics is essential for studying large time series due to its ability to reveal trends, anomalies, and insights. DeepVATS is a tool that merges Deep Learning (Deep) with Visual Analytics (VA) for the analysis of large time series data (TS). It has three interconnected modules. The Deep Learning module, developed in R, manages the load of datasets and Deep Learning models from and to the Storage module. This module also supports models training and the acquisition of the embeddings from the latent space of the trained model. The Storage module operates using the Weights and Biases system. Subsequently, these embeddings can be analyzed in the Visual Analytics module. This module, based on an R Shiny application, allows the adjustment of the parameters related to the projection and clustering of the embeddings space. Once these parameters are set, interactive plots representing both the embeddings, and the time series are shown. This paper introduces the tool and examines its scalability through log analytics. The execution time evolution is examined while the length of the time series is varied. This is achieved by resampling a large data series into smaller subsets and logging the main execution and rendering times for later analysis of scalability.", "sections": [{"title": "1 Introduction", "content": "Visual analytics in Deep Learning refers to the use of interactive visual interfaces and plots to identify emerging patterns and trends within the data, supporting its understanding. Dimensional reduction techniques are essential for the analysis and interaction with large time series data [1].\nDeepVATS (Deep Visual Analytics for Time Series) [16] provides a tool in-spired by TimeCluster [1] that integrates Visual Analytics (VA) and Deep Learn-ing (DL) to extract valuable insights from Time Series (TS) through interactive projections and TS data plots. It uses dimensionality reduction (DR) techniques for efficient analysis and interaction with large time series. As Fig. 1 shows, DeepVATS has three modules: DL, Storage and VA. These modules interact"}, {"title": "2 DeepVATS description", "content": "The DeepVATS code base\u00b9 integrates three main modules: Deep Learning (DL) Module, Storage Module and Visual Analytics (VA) Module (See Fig. 1). The DL Module is a Python library implemented using Jupyter Notebooks [10] and nbdev [5]. The Jupyter notebooks contained in the folder nbs are used for the generation of dvats library. This library is the base for both the nbs_pipeline notebooks and the r_shiny_app (see Fig. 2). As detailed in the github reposi-tory, the docker containers must be preconfigured, assuming that another folder work_dir already exists in the same path as the global \"Deepvats\" for the use of the tool functionalities."}, {"title": "2.1 Deep Learning (DL) Module", "content": "The DL module gives tools for loading datasets from/to the storage module and use them into the nbs_pipeline folder notebooks. As Fig. 3 shows, the first"}, {"title": "2.2 Visual Analytics (VA) module", "content": "This section presents the VA module through images. As Fig. 4 show, the visual app does the following main steps. First, it downloads all artifacts from the W&Biases system. Second, from a selected dataset and an associated encoder, it obtains the embeddings and projects them into a projection plot (PP) using dvats. At the same time, it generates the TS plot associated to the dataset artifact. The application also includes the option of clustering the projections for better analysis. To open the app we must run the r-studio-server docker and run shiny::runApp(\u201capp\u201d). This will open a new window (permissions may be requested by the browser).\nThis window contains the following main elements (see Fig. 5: On the left, selectors for getting specific dataset, encoders and associated configurations:"}, {"title": "3 Scalability Analysis", "content": "The main goal of deepVATS is to visually analyse large time series. The Monash benchmark [9] presents more than 20 datasets with different number of series and lengths, thus providing for good data for testing the app's per-formance. To test the most challenging case, the dataset with the longest time series has been used: Solar Power Dataset (4) Seconds Observations) [7]. This dataset contains a single time series containing the solar power production in MW (megawatts) recorded with a frequency of 4 seconds along one year, obtain-ing more than 7M elements (see Table 1).\nTo check the app's scalability for ensuring its performance in large time series, this dataset has been resampled into smaller datasets by selecting the dataset rows based in a frequency factor, defining the frequency factor ($ffactor = 150$) as the number we multiply frequency by ($f = 4s$) so that desired frequency is obtained ($f = 4s \\cdot 150 = 600s = 10m$). For simplicity, after checking that 10 minutes frequency had also been previously used in the Monash benchmark [8], factors 5, 15, 75 and 150 have been selected to obtain divisions of 4 seconds to 10 minutes frequencies. Table 1 shows the evolution in terms of number of elements.\nTo get the execution times and logs, the following steps have been executed for each dataset:\nLoad the dataset from the feather file. Select the desired dataset with the last associated encoder logged and check the time required to load the dataset from the binary file. The app will automatically get the embeddings from the encoder and apply UMAP using GPU for dimensionally reduction (DR) and will generate the associated projections and time series plots.\nChange to PCA. As will be detailed in the following sections, it is interesting to check the use of PCA and other DR algorithms.\nChange to CPU. It is interesting to check the app performance according to this selection.\nClustering. To gain insight into the structure of the embeddings.\nSelection of projection points. The TS points associated to the selected points will be shaded in the TS plot.\nPlots interactions. To check the plots rendering after interactions, basic steps have been added: projections plot (PP) zoom in and zoom out, select a point on the time series plot so its associated projections points are remarked.\nPP aesthetics updates. To check rendering times for aesthetics updates, min-imal changes have been selected: update point alpha aesthetic in PP and removing lines in PP for clearer visualisation.\nThe following sections analyses the different steps that the app executes when those steps are done: load dataset, get encoder embeddings, compute projections, compute and visualize plots and compute clusters."}, {"title": "3.1 Load dataset", "content": "TS plot is generated using dygraph [17]. This function expects to receive a dataframe with timestamps as rownames. Thus, a rownames conversion was ini-tially added to move the time index column to rownames. This step rapidly increases the execution time when increasing the TS length. After taking in-sights on the execution progress, a dataframe to xts conversion was detected when calling dygraph. Fig. 8 shows how explicitly making the conversion via xts(TS_dataframe,order.by=TS_dataframe$timeindex) reduces the execu-tion time up to 27 seconds for the largest case, thus notably enhancing the app performance."}, {"title": "3.2 Get embeddings", "content": "The time and memory consumption increases rapidly when the embeddings are obtained from the trained models. For memory handling and better R-python communication the implementation has been modified. Now, the the dataset in-put is stored as a feather file, enabling data loading and manipulation within python. Furthermore, the embeddings obtainment is chunked so that GPU mem-ory errors are avoided."}, {"title": "3.3 Compute projections", "content": "The computation of projections is known to be much faster on a GPU than on a CPU. However, there exists a known bug in the GPU version that makes UMAP fail when using cuml UMAP (GPU) function that makes projections unstable and with low quality cluster distribution [13,14]. This quality can be checked in"}, {"title": "3.4 Compute and visualise plots", "content": "A great reduction in the performance was detected when trying to load the Solar Power Dataset (4 Seconds Observations) and interacting with the plots. This is reasonable as it is the largest one. This is not a huge problem for small"}, {"title": "3.5 Compute clusters", "content": "The clusters computation is really fast even for large time series. However, some reactive functions have also been detected that affects to the performance of clustering step. Thus, the cache analysis is useful for enhancing this step too."}, {"title": "4 Conclusions and future work", "content": "DeepVATS is a powerful tool designed for the easy visual analysis of both univari-ate and multivariate time series. It allows users to interact with the embeddings projection plot and the original time series data plot, facilitating the detection of patterns within the data. The scalability analysis has demonstrated an excel-lent performance for small datasets (ranging from 49.3K to 98.6K elements) and medium-sized datasets (up to 493.1K elements). However, performance issues appeared when processing larger datasets, with noticeable degradation at 3.7 million elements and application crashes at 7.4 million elements.\nTo enhance the application's usability for large datasets, we propose the following development work lines. First, to eliminate redundant processes, the reactive variables should be checked to determine if they can be converted to reactiveVal to ensure the use of cached values. Also, renderCachedPlot is proposed as an alternative to renderPlot for the projections plot [2]. Second, to ensure high-quality dimensionality reduction, two strategies are suggested: adopting an alternative UMAP implementation [4], and exploring the application of PCA followed by UMAP, rather than UMAP alone [14].\nThese modifications are anticipated to give the application a substantial im-provement in performance (e.g., the elimination of the additional 28 seconds required for compute projections for the 4 seconds frequency dataset). Also, greater stability in the GPU clustering is expected, making DeepVATS an more robust tool for the visual and interactive analysis of time series."}]}