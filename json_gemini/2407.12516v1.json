{"title": "Online Pseudo-Zeroth-Order Training of Neuromorphic Spiking Neural Networks", "authors": ["Mingqing Xiao", "Qingyan Meng", "Zongpeng Zhang", "Di He", "Zhouchen Lin"], "abstract": "Brain-inspired neuromorphic computing with spiking neural networks (SNNs) is a promising energy-efficient computational approach. However, successfully training SNNs in a more biologically plausible and neuromorphic-hardware-friendly way is still challenging. Most recent methods leverage spatial and temporal backpropagation (BP), not adhering to neuromorphic properties. Despite the efforts of some online training methods, tackling spatial credit assignments by alternatives with comparable performance as spatial BP remains a significant problem. In this work, we propose a novel method, online pseudo-zeroth-order (OPZO) training. Our method only requires a single forward propagation with noise injection and direct top-down signals for spatial credit assignment, avoiding spatial BP's problem of symmetric weights and separate phases for layer-by-layer forward-backward propagation. OPZO solves the large variance problem of zeroth-order methods by the pseudo-zeroth-order formulation and momentum feedback connections, while having more guarantees than random feedback. Combining online training, OPZO can pave paths to on-chip SNN training. Experiments on neuromorphic and static datasets with fully connected and convolutional networks demonstrate the effectiveness of OPZO with similar performance compared with spatial BP, as well as estimated low training costs.", "sections": [{"title": "1. Introduction", "content": "Neuromorphic computing with biologically inspired spiking neural networks (SNNs) is an energy-efficient computational framework with increasing attention recently (Roy et al., 2019; Schuman et al., 2022). Imitating biological neurons to transmit spike trains for sparse event-driven computation as well as parallel in-memory computation, efficient neuromorphic hardware is developed, supporting SNNs with low energy consumption (Davies et al., 2018; Pei et al., 2019; Wo\u017aniak et al., 2020; Rao et al., 2022). Nevertheless, supervised training of SNNs is challenging considering neuromorphic properties. While popular surrogate gradient methods can deal with the non-differentiable problem of discrete spikes (Shrestha & Orchard, 2018; Wu et al., 2018; Neftci et al., 2019), they rely on backpropagation (BP) through time and across layers for temporal and spatial credit assignment, which is biologically problematic and would be inefficient on hardware. Particularly, spatial BP suffers from problems of weight transport and separate forward-backward stages with update locking (Crick, 1989; Frenkel et al., 2021), and temporal BP is further infeasible for spiking neurons with the online property (Bellec et al., 2020). Considering learning in biological systems with unidirectional local synapses, maintaining reciprocal forward-backward connections with symmetric weights and separate phases of signal propagation is often viewed as biologically problematic (N\u00f8kland, 2016), and also poses challenges for efficient on-chip training of SNNs. Methods with only forward passes, or with direct top-down feedback signals acting as modulation in biological three-factor rules (Fr\u00e9maux & Gerstner, 2016; Roelfsema & Holtmaat, 2018), are more efficient and plausible, e.g., on neuromorphic hardware (Davies, 2021). Some previous works explore alternatives for temporal and spatial credit assignment. To deal with temporal BP, online training methods are developed for SNNs (Bellec et al., 2020; Xiao et al., 2022). With tracked eligibility traces, they decouple temporal dependency and support forward-in-time learning. However, alternatives to spatial BP still require deeper investigations. Most existing works mainly rely on random feedback (N\u00f8kland, 2016; Bellec et al., 2020), but"}, {"title": "2. Related Work", "content": "SNN Training Methods A mainstream method to train SNNs is spatial and temporal BP combined with surrogate gradient (SG) (Shrestha & Orchard, 2018; Wu et al., 2018; Neftci et al., 2019; Li et al., 2021) or gradients with respect to spiking times (Zhang & Li, 2020; Kim et al., 2020; Zhu et al., 2022). Another direction is to derive equivalent closed-form transformations or implicit equilibriums between specific encodings of spike trains, e.g., (weighted) firing rates or the first time to spike, and convert artificial neural networks (ANNs) to SNNs (Rueckauer et al., 2017; Deng & Gu, 2021; St\u00f6ckl & Maass, 2021; Meng et al., 2022b) or directly train SNNs with gradients from the equivalent transformations (Lee et al., 2016; Zhou et al., 2021; Wu et al., 2021; Meng et al., 2022a) or equilibriums (O'Connor et al., 2019; Xiao et al., 2021; Martin et al., 2021; Xiao et al., 2023). To tackle the problem of temporal BP, some online training methods are proposed (Bellec et al., 2020; Xiao et al., 2022; Bohnstingl et al., 2022; Meng et al., 2023; Yin et al., 2023) for forward-in-time learning, but most of them still require spatial BP. Considering alternatives to spatial BP, Neftci et al. (2017); Lee et al. (2020); Bellec et al. (2020) apply random feedback, Kaiser et al. (2020) propose online local learning, and Yang et al. (2022) propose local tandem learning with ANN teachers. Different from them, we propose a new method for global learning while maintaining similar performance as spatial BP and much better results than random feedback.\nLi et al. (2021) and Mukhoty et al. (2023) study zeroth-order properties for each parameter or neuron to adjust surrogate functions or leverage a local zeroth-order estimator for the Heaviside step function, lying in the spatial and temporal BP framework. Differently, in this work, zeroth-order training refers to simultaneous perturbation for global network training without spatial BP.\nAlternatives to Spatial Backpropagation For effective and more biologically plausible global learning of neural networks, some alternatives to spatial BP are proposed. Target propagation (Lee et al., 2015), feedback alignment (FA) (Lillicrap et al., 2016), and sign symmetric (Liao et al., 2016; Xiao et al., 2018) avoid the weight symmetric problem by propagating targets or using random or only sign-shared backward weights, and Akrout et al. (2019) improves ran-"}, {"title": "3. Preliminaries", "content": "3.1. Spiking Neural Networks\nImitating biological neurons, each spiking neuron keeps a membrane potential u, integrates input spike trains, and generates a spike for information transmission once u exceeds a threshold. u is reset to the resting potential after a spike. We consider the commonly used leaky integrate and fire (LIF) model with the dynamics of the membrane potential as: $T_m \\frac{du}{dt} = -(u - U_{rest}) + R \\cdot I(t)$, for $u < V_{th}$, with input current I, threshold $V_{th}$, resistance R, and time constant $T_m$. When u reaches $V_{th}$ at time $t_f$, the neuron generates a spike and resets u to zero. The output spike train is $s(t) = \\sum_{t_f} \\delta(t - t_f)$.\nSNNs consist of connected spiking neurons. We consider the simple current model $I_i(t) = \\sum_j W_{ij}s_j(t) + b_i$, where i, j represent the neuron index, $w_{ij}$ is the weight and $b_i$ is a bias. The discrete computational form is:\n$\\begin{cases} u_i [t + 1] = \\chi (u_i[t] - V_{th}s_i[t]) + \\sum_j W_{ij}s_j[t] + b_i, \\\\ s_i[t+1] = H(u_i [t+1] - V_{th}). \\end{cases}$   (1)\nHere H(x) is the Heaviside step function, $s_i[t]$ is the spike signal at discrete time step t, and $\\chi < 1$ is a leaky term (taken as $1 - \\frac{1}{T_m}$). For multi-layer networks, we use $s^{l+1}[t]$ to represent the (l + 1)-th layer's response after receiving signals $s^l[t]$ from the l-th layer, i.e., the expression is $u^{l+1}[t+1] = \\chi(u^{l+1}[t] - V_{th}s^{l+1}[t]) + W^ls^l[t+1] + b^l$.\nOnline Training of SNNs We build the proposed OPZO on online training methods for forward-in-time learning. Here online training refers to online through the time dimension of SNNs (Bellec et al., 2020; Xiao et al., 2022), as opposed to backpropagation through time. We consider OTTT (Xiao et al., 2022) to online calculate gradients at each time by the tracked presynaptic trace $\\bar{a}_i^l[t] = \\sum_{\\tau<t} e^{\\frac{t-\\tau}{t_{tr}}}s^l[\\tau]$ and instantaneous gradient\n$\\begin{aligned} \\nabla_{W^l} L[t] &= g_u^{l+1}[t] \\bar{a}^l[t], \\\\ \\text{with } g_u^{l+1}[t] &= \\sum_{i=l}^{N-1} \\prod_{j=l+1}^{i} \\frac{\\partial s_j[t]}{\\partial u_j[t]} \\frac{\\partial L[t]}{\\partial s^i[t]} \\frac{\\partial s^i[t]}{\\partial u^{l+1}[t]}. \\end{aligned}$\nIn OTTT, the instantaneous gradient requires layer-by-layer spatial BP with surrogate derivatives for $\\frac{\\partial s_j[t]}{\\partial u_j[t]}$. The proposed OPZO, on the other hand, leverages only one forward propagation across layers and direct feedback to estimate $g_u^{l+1}[t]$ without spatial BP combining surrogate gradients."}, {"title": "3.2. Zeroth-Order Optimization", "content": "Zeroth-order optimization is a gradient-free method using only function values. A classical ZO gradient estimator is SPSA (Spall, 1992), which estimates the gradient of parameters $\\theta$ for L($\\theta$) on a random direction z as:\n$\\nabla_\\theta^zL(\\theta) = \\frac{L(\\theta + \\alpha z) - L(\\theta - \\alpha z)}{2\\alpha} z \\approx \\bar{z z}^T \\nabla L(\\theta),$   (2)\nwhere z is a multivariate variable with zero mean and unit variance, e.g., following the multivariate Gaussian distribution, and $\\alpha$ is a perturbation scale. Alternatively, we can use"}, {"title": "4. Online Pseudo-Zeroth-Order Training", "content": "In this section, we introduce the proposed online pseudo-zeroth-order method. We first introduce the pseudo-zeroth-order formulation for neural network training in Section 4.1. Then in Section 4.2, we introduce momentum feedback connections in OPZO for error propagation with zeroth-order estimation of the model. In Section 4.3, we demonstrate the combination with online training and a similar form as the three-factor Hebbian learning. Finally, we introduce more additional details in Section 4.4.\n4.1. Pseudo-Zeroth-Order Formulation\nSince zeroth-order methods suffer from large variances, a natural thought is to reduce the variance. However, ZO methods only rely on a scalar feedback signal to act on the random direction z, making it hard to improve gradient estimation. To this end, we introduce a pseudo-zeroth-order formulation. As we build our work on online training, we first focus on the condition of a single SNN time step.\nSpecifically, we decouple the model function f(\u00b7; \u03b8) and the loss function L(\u00b7). For each input x, the model outputs o = f(x; \u03b8), and then the loss is calculated as L(o, yx), where yx is the label for the input. Different from ZO methods that only leverage the function value of L \u25e6 f, we assume that the gradient of L(\u00b7) can be easily calculated, while keeping the zeroth-order formulation for f(\u00b7; \u03b8). This is consistent with real settings where gradients of the"}, {"title": "4.2. Momentum Feedback Connections", "content": "We motivate our method by first considering the directional gradient by the two-point estimation in Section 3.2. With decoupled f(\u00b7; \u03b8) and L(\u00b7) as in the pseudo-zeroth-order formulation and Taylor expansion of L(\u00b7), Eq. 3 turns into:\n$\\nabla_\\theta^{ZOL} (\\nabla_o L(o, y_x), \\tilde{o} - o) \\approx \\frac{\\Delta o}{\\alpha}^T z = \\frac{\\Delta o}{\\alpha}^T z \\nabla_o L(o, y_x),$  (5)\nwhere o = f(x; \u03b8), $ \\tilde{o} = f(x; \\theta + \\alpha z)$, and $ \\Delta o = \\tilde{o} - o$. This can be viewed as propagating the error signal with a connection weight $\\frac{\\Delta o}{\\alpha}^T z$. To reduce the variance introduced by the random direction z, we introduce momentum feedback connections across different iterations and propagate errors as:\n$\\begin{aligned} M &:= \\lambda M + (1 - \\lambda) z \\frac{\\Delta o}{\\alpha}^T , \\\\ \\nabla_\\theta^{PZOL}L &= M \\nabla_o L(o, y_x). \\end{aligned}$ (6)\nThe momentum feedback connections can take advantage of different sampled directions z, largely alleviating the variance caused by random directions.\nThe above formulation only considers the directional gradient with two-point estimation, while we are more interested in methods with a single forward pass. Actually, $\\frac{\\Delta o}{\\alpha}$ can be viewed as an unbiased estimator of $E_x [J_f^T(x)]$, where $J_f(x)$ is the Jacobian of f evaluated at x, and M can be viewed as approximating it with moving average. Therefore, we can similarly use a one-point method and M has similar effects:\n$\\begin{aligned} M &:= \\lambda M + (1 - \\lambda) z \\frac{\\nabla \\tilde{o}}{\\alpha}^T , \\end{aligned}$  (7)\nwhere $\\frac{\\nabla \\tilde{o}}{\\alpha}$ is also an unbiased estimator of $E_x [J_f^T(x)]$.\nLemma 4.1. When z has i.i.d. components with zero mean and unit variance independent of inputs, in the limit \u03b1 \u2192 0, $\\frac{\\nabla \\tilde{o}}{\\alpha}$ and $\\frac{\\Delta o}{\\alpha}$ are unbiased estimators of $J_f^T(x)$ given x, and further, M are unbiased estimators of $E_x [J_f^T(x)]$.\nThis leads to our method as shown in Fig. 1(e). During forward propagation, a random noise $ \\alpha z$ is injected for each"}, {"title": "4.3. Online Pseudo-Zeroth-Order Training", "content": "We build the above pseudo-zeroth-order approach on online training methods to deal with spatial and temporal credit assignments. As introduced in Section 3.1, we consider OTTT (Xiao et al., 2022) and replace its backpropagated instantaneous gradient with our estimated gradient based on direct top-down feedback. Then the update for synaptic weights has a similar form as the three-factor Hebbian learning (Fr\u00e9maux & Gerstner, 2016) based on a direct top-down global modulator:\n$\\Delta W_{i,j} \\propto \\bar{a}_i[t] \\psi(u_j[t]) g_u^j, (8)\nwhere $W_{i,j}$ is the weight from neuron i to j, $\\bar{a}_i[t]$ is the presynaptic activity trace, $\\psi(u_j[t])$ is a local surrogate derivative for the change rate of the postsynaptic activity (Xiao et al., 2022), and $g_u^j$ is the global top-down error (gradient) modulator. Here we leverage the local surrogate derivative because it can be well-defined under the stochastic setting (see Appendix B for details) and better fits the biological three-factor Hebbian rule.\nFor potentially asynchronous neuromorphic computing, there may be a delay in the propagation of error signals."}, {"title": "4.4. Additional Details", "content": "Combination with Local Learning There can be both global and local signals for learning in biological systems, and local learning (LL) can improve global learning approximation methods (Ren et al., 2023). Our proposed method can be combined with local learning for improvement, and we consider introducing local readout layers for local supervision. We will add a fully connected readout for each layer with supervised loss. Additionally, for deeper networks, we can also introduce intermediate global learning (IGL) that propagates global signals from a middle layer to previous ones with OPZO. More details can be found in Appendix C.\nAbout Noise Injection By default, we sample z from the Gaussian distribution. As sampling from the Gaussian distribution may pose computational requirements for hardware, we can also consider easier distributions. For example, the Rademacher distribution, which takes 1 and -1 both with the probability 0.5, also meets the requirements. Additionally, z is by default added to the neural activities for gradient estimation based on node perturbation. To further prevent noise perturbation from interfering with sparse spike-driven forward propagation of SNNs for energy efficiency, we may empirically change the noise perturbation after neuronal activities to perturbation before neurons (i.e., perturb on membrane potentials), while maintaining local surrogate derivatives for the spiking function. We will show in experiments that OPZO is robust to these noise injection settings.\nAntithetic Variables across Time Steps Compared with the two-point zeroth-order estimation, the considered one-point method can have a much larger variance. To further reduce the variance, we can leverage antithetic z, i.e., z and -z, for every two time steps of SNNs. Since SNNs naturally have multiple time steps and the inputs for different time steps usually belong to the same object with similar distributions, this approach may roughly approximate the two-point formulation without additional costs."}, {"title": "5. Experiments", "content": "In this section, we conduct experiments on both neuromorphic and static datasets with fully connected (FC) and convolutional (Conv) neural networks to demonstrate the effectiveness of the proposed OPZO method. For N-MNIST and MNIST, we leverage FC networks with two hidden layers composed of 800 neurons, and for DVS-CIFAR10, DVS-Gesture, CIFAR-10, and CIFAR-100, we leverage 5-layer convolutional networks. We will also consider a deeper 9-layer convolutional network, as well as fine-tuning ResNet-34 on ImageNet under noise. We take T = 30 time steps for N-MNIST, T = 20 for DVS-Gesture, T = 10 for DVS-CIFAR10, and T = 6 time steps for static datasets, following previous works (Xiao et al., 2022; Zhang & Li, 2020). More training details can be found in Appendix C.\n5.1. Comparison on Various Datasets\nWe first compare the proposed OPZO with other spatial credit assignment methods on various datasets in Table 1, and all methods are based on the online training method OTTT (Xiao et al., 2022) under the same settings. For FC networks, since there are only two hidden layers, we do not consider local learning settings. As shown in the results, the ZOsp method fails to effectively optimize neural networks, while OPZO significantly improves the results, achieving performance at a similar level as spatial BP with SG. DFA with random feedback has a large gap with spatial BP, especially on convolutional networks, while OPZO can achieve much better results. When combined with local learning, OPZO has about the same performance as and even outperforms spatial BP with SG on neuromorphic datasets. These results demonstrate the effectiveness of OPZO for training SNNs to promising performance in a more biologically plausible and neuromorphic-friendly approach, paving paths for direct on-chip training of SNNs.\nNote that our method is a different line from most recent works with state-of-the-art performance (Kim et al., 2022; Li et al., 2023; Zhou et al., 2023) which are based on spatial and temporal BP with SG and focus on model improvement. We aim to develop alternatives to BP that adhere to neuromorphic properties, focusing on more biologically plausible"}, {"title": "5.2. Gradient Variance", "content": "We analyze the gradient variance of different methods to verify that our method can effectively reduce variance for effective training. As shown in Fig. 2, the variance of ZOsp is several orders larger than spatial BP with SG, leading to the failure of effective training. OPZO can largely reduce the variance, which is consistent with our theoretical analysis. As in practice, we remove the factor 1/\u03b1 for the calculation of M (see Appendix C for details), which will scale gradients by the factor \u03b1, the practical gradient variance of OPZO can be smaller than spatial BP with SG, but they are at a comparable level overall."}, {"title": "5.3. Effectiveness for Different Noise Injection", "content": "Then we verify the effectiveness of OPZO for different noise injection settings as introduced in Section 4.4. As shown in Table 2, the results under different noise distributions and injection positions are similar, demonstrating the robustness of OPZO for different settings."}, {"title": "5.4. Deeper Networks", "content": "We further consider deeper networks and larger datasets. We first perform experiments on DVS-Gesture and CIFAR-100 with a deeper 9-layer convolutional network. As introduced in Section 4.4, for deeper networks, we can introduce techniques including local learning and intermediate global learning. As shown in Table 3, OPZO can also achieve similar performance as or outperform spatial BP with SG and significantly outperform DFA combined with these techniques.\nWe also conduct experiments for fine-tuning ResNet-34 on ImageNet under noise. This task is on the ground that there can be hardware mismatch, e.g., hardware noise, for deploying SNN models trained on common devices to neuromorphic hardware (Yang et al., 2022; Cramer et al., 2022), and we may expect direct on-chip fine-tuning to better deal with the problem. Our method is more plausible and efficient for on-chip learning than spatial BP with SG and may be combined with other works aiming at high-performance training on common devices in this scenario. We fine-tune a pre-trained NF-ResNet-34 model released by Xiao et al. (2022), whose original test accuracy is 65.15%, under the noise injection setting with different scales. As shown in Table 4, OPZO can successfully fine-tune such large-scale models, while DFA and ZOsp fail. Spatial BP is less biologically plausible and is neuromorphic-unfriendly, so its results are only for reference. The results show that our method can scale to large-scale settings."}, {"title": "5.5. Training Costs", "content": "Finally, we analyze and compare the computational costs of different methods. We consider the estimation of the costs"}, {"title": "6. Conclusion", "content": "In this work, we propose a new online pseudo-zeroth-order method for training spiking neural networks in a more biologically plausible and neuromorphic-hardware-friendly way, with low costs and comparable performance to spatial BP with SG. OPZO performs spatial credit assignment by a single common forward propagation with noise injection and direct top-down feedback based on momentum feedback connections, avoiding drawbacks of spatial BP, solving the large variance problem of zeroth-order methods, and significantly outperforming random feedback methods. Combining online training, OPZO has a similar form as three-factor Hebbian learning with direct top-down modulations, taking a step forward towards on-chip SNN training. Extensive experiments demonstrate the effectiveness and robustness of OPZO for fully connected and convolutional networks on static and neuromorphic datasets as well as larger models and datasets, and show the efficiency of OPZO with low estimated training costs."}, {"title": "A. Detailed Proofs", "content": "In this section, we provide proofs for lemmas and propositions in the main text.\nA.1. Proof of Lemma 3.1 and Lemma 3.2\nProof. In the limit \u03b1 \u2192 0, $ \\nabla_\\theta^zL(\\theta) = \\bar{z z}^T \\nabla L(\\theta)$. Since z has i.i.d. components with zero mean and unit variance, we have E [zz] = I. Therefore, $E_z [\\nabla_\\theta^zL(\\theta)] = \\nabla L(\\theta)$.\nMoreover, $E_z [\\nabla_\\theta^{ZOsp}L(\\theta)] = E_z \\frac{L(\\theta+\\alpha z)-L(\\theta)}{\\alpha} z = E_z [\\frac{L(\\theta+\\alpha z)}{\\alpha} z] - E_z [\\frac{L(\\theta)}{\\alpha} z] = E_z [\\frac{L(\\theta+\\alpha z)}{\\alpha} z] - E_z [\\frac{L(\\theta)}{\\alpha} z] = E_z [\\nabla_\\theta^{ZOsp} L(\\theta)]$.\nTherefore, $E_z [\\nabla_\\theta^{ZOsp}L(\\theta)] = \\nabla L(\\theta)$.\nA.2. Proof of Lemma 4.1\nProof. In the limit \u03b1 \u2192 0, $z \\frac{\\Delta o}{\\alpha} = z (J_f(x)z)^T = z z^T J_f^T (x)$. Since $E [z z^T] = I$, we have $E_z[ z \\frac{\\Delta o}{\\alpha} \\vert x] = J_f^T(x)$.\nThen $E_{x,z} [z \\frac{\\Delta o}{\\alpha} ] = E_x [J_f^T(x)]$.\nAlso, $E_z [\\frac{\\nabla \\tilde{o}}{\\alpha} ] = E_z [\\frac{\\Delta o + z o_x}{\\alpha} ] = E_z [\\frac{\\Delta o}{\\alpha} ] + E_z[ \\frac{z o_x}{\\alpha}] = E_z [\\frac{\\Delta o}{\\alpha} ] + E_z[ \\frac{z o_x}{\\alpha}] = J_f^T(x)$. Therefore, $E_{x,z} [\\frac{\\nabla \\tilde{o}}{\\alpha} ] = E_x [J_f^T(x)]$.\nA.3. Proof of Proposition 4.2\nProof. We first consider the average variance of the two-point ZO estimation $ \\nabla_\\theta^z L = z z^T \\nabla_o L + O(\\alpha)$. Since $Var(xy) = Var(x)Var(y) + Var(x)E(y)^2 + Var(y)E(x)^2$ for independent x and y, and $E[z_i^2] = Var[z_i] + E[z_i]^2 = 1$, for each element of the gradient under sample x, we have:\n$\\begin{aligned} Var [(\\nabla_\\theta^z L)_i] &= Var [\\sum_j z_i z_j (\\nabla_o L_x)_j + O(\\alpha^2)] \\\\ &= Var [\\sum_j z_i z_j (\\nabla_o L_x)_j] + \\sum_{j \\neq i} Var [z_i z_j (\\nabla_o L_x)_j] + O(\\alpha^2) \\\\ &= Var [z_i^2] Var [(\\nabla_o L_x)_i] + Var [z_i^2] E [(\\nabla_o L_x)_i]^2 + Var [(\\nabla_o L_x)_i] E [z_i^2]^2 \\\\ & + \\sum_{j \\neq i} (Var [z_i z_j] Var [(\\nabla_o L_x)_j] + Var [z_i z_j] E [(\\nabla_o L_x)_j]^2 + Var [(\\nabla_o L_x)_j] E [z_i z_j]^2) + O(\\alpha^2) \\\\ &= (\\beta + 1) Var [(\\nabla_o L_x)_i] + \\beta E [(\\nabla_o L_x)_i]^2 + \\sum_{j \\neq i} (Var [(\\nabla_o L_x)_j] + E [(\\nabla_o L_x)_j]^2) + O(\\alpha^2) \\\\ &= \\beta Var [(\\nabla_o L_x)_i] + (d - 1) E [(\\nabla_o L_x)_i]^2 + \\sum_{j = 1}^d (Var [(\\nabla_o L_x)_j] + E [(\\nabla_o L_x)_j]^2) + O(\\alpha^2). \\end{aligned}$   (9)\nTaking the average of all elements, we obtain the average variance for each sample (denoted as mVar):\n$\\begin{aligned} mVar [\\nabla_\\theta^z L_x] &= \\frac{1}{d} \\sum_{i = 1}^d Var [(\\nabla_o L_x)_i] \\\\ &= \\beta \\frac{1}{d} \\sum_{i = 1}^d Var [(\\nabla_o L_x)_i] + \\frac{d - 1}{d} \\sum_{j = 1}^d E [(\\nabla_o L_x)_j]^2 + \\sum_{j = 1}^d (Var [(\\nabla_o L_x)_j] + E [(\\nabla_o L_x)_j]^2) + O(\\alpha^2) \\\\ &= (d + \\beta) V_o + (d + \\beta - 1) S_o + O(\\alpha^2). \\end{aligned}$  (10)"}, {"title": "A.4. Proof of Proposition 4.4", "content": "Proof. Since $J_f^T(x)$ is $L_J$-Liptschitz continuous and $e(x)$ is $L_e$-Liptschitz continuous, we have $||J_f^T(x_i) - J_f^T(x_j)|| \\leq L_J ||x_i - x_j||$, $||e(x_i) - e(x_j)|| \\leq L_e ||x_i - x_j||$. Then with the equation that $ \\frac{1}{2 n^2} \\sum_{i,j}(a_i - a_j) (b_i - b_j) = \\sum_{i} a_i b_i - \\frac{1}{n} \\sum_{i,j}a_i b_j$, we have\n$\\begin{aligned} &||E_{x_i} [J_f^T(x_i) e(x_i)] - E_{x_i} [(E_{x_j} [J_f^T (x_j)] + \\epsilon) e(x_i)] ||\\\\ &= ||E_{x_i} [J_f^T(x_i) e(x_i)] - (E_{x_i} [(\\frac{1}{n} \\sum_i J_f^T(x_i))] + \\epsilon) E_{x_i} [e(x_i)] ||\\\\ &= ||\\frac{1}{n^2} \\sum_{i} J_f^T(x_i) e(x_i) - (\\frac{1}{n} \\sum_i J_f^T (x_j)] + \\epsilon) (\\frac{1}{n} \\sum_i e(x_i)] ||\\\\ &= || \\frac{1}{2 n^2} \\sum_{i,j} [J_f^T(x_i) - J_f^T(x_j)] (e(x_i) - e(x_j)) - E_{x_j} [\\epsilon]  E_{x_i} [e(x_i)] ||\\\\ & \\leq  \\frac{1}{2 n^2} \\sum_{i,j} ||[J_f^T(x_i) - J_f^T(x_j)]|| || (e(x_i) - e(x_j))|| + || E_{x_j} [\\epsilon]|| || E_{x_i} [e(x_i)] ||\\\\ & \\leq \\frac{1}{2 n^2} \\sum_{i,j} L_J ||x_i - x_j|| L_e ||x_i - x_j|| + || \\epsilon E_{x_i} [e(x_i)]||\\\\ &= \\frac{L_J L_e}{2 n^2} \\sum_{i,j} ||x_i - x_j||^2 + L_e || \\epsilon E_{x_i} [e(x_i)]||\\\\ &< ||E_{x_i} [J_f^T(x_i) e(x_i)] || . \\end{aligned}$  (14)\nTherefore,\n$ (E_{x_i} [J_f^T(x_i) e(x_i)], E_{x_j} [M e(x_i)]) $\n$= ||E_{x_i} [J_f^T(x_i) e(x_i)] ||^2 - (E_{x_i} [J_f^T(x_i) e(x_i)], E_{x_i} [J_f^T(x_i) e(x_i)] - E_{x_i} [M e(x_i)])$\n$> ||E_{x_i} [J_f^T(x_i) e(x_i)] ||^2 - ||E_{x_i} [J_f^T(x_i) e(x_i)] || ||E_{x_i} ["}, {"title": "B. Introduction to Local Surrogate Derivatives under the Stochastic Spiking Setting", "content": "In this section, we provide more introduction to the stochastic spiking setting, under which spiking neurons can be locally differentiable and there exist local surrogate derivatives.\nBiological spiking neurons can be stochastic, where a neuron generates spikes following a Bernoulli distribution with the probability as the c.d.f. of a distribution w.r.t u[t] \u2013 $V_{th}$, indicating a higher probability for a spike with larger u[t] \u2013 $V_{th}$. That is, $s_i[t]$ is a random variable following a {0, 1} valued Bernoulli distribution with the probability of 1 as $p(s_i[t] = 1) = F(u_i[t] - V_{th})$. With reparameterization, this can be formulated as $s_i[t] = H(u_i [t] - V_{th} - z_i)$ with a random noise variable $z_i$ that follows the distribution specified by F. Different F corresponds to different distributions and noises. For example, the sigmoid function corresponds to a logistic noise, while the erf function corresponds to a Gaussian noise. Under the stochastic setting, the local surrogate derivatives can be introduced for the spiking function (Shekhovtsov & Yanush, 2021; Ma et al., 2023).\nSpecifically, consider the objective function which should turn to the expectation over random variables under the stochastic model. Considering a one-hidden-layer network with one time step, with the input x connecting to n spiking neurons by the weight W and the neurons connecting to an output readout layer by the weight O. Different from deterministic models with the objective function $E_x[L(s)]$, where $s = H(u - V_{th})$, $u = Wx$, under the stochastic setting, the objective is to minimize\n$E_x [E_{s \\sim p(s/x,W)} [L(s)]]$. (16)"}]}