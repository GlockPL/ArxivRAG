{"title": "Optimizing Feature Selection in Causal Inference: A Three-Stage Computational Framework for Unbiased Estimation", "authors": ["Tianyu Yang", "Md. Noor-E-Alam"], "abstract": "Feature selection is an important but challenging task in causal inference for obtaining unbiased estimates of causal quantities. Properly selected features in causal inference not only significantly reduce the time required to implement a matching algorithm but, more importantly, can also reduce the bias and variance when estimating causal quantities. When feature selection techniques are applied in causal inference, the crucial criterion is to select variables that, when used for matching, can achieve an unbiased and robust estimation of causal quantities. Recent research suggests that balancing only on treatment-associated variables introduces bias while balancing on spurious variables increases variance. To address this issue, we propose an enhanced three-stage framework that shows a significant improvement in selecting the desired subset of variables compared to the existing state-of-the-art feature selection framework for causal inference, resulting in lower bias and variance in estimating the causal quantity. We evaluated our proposed framework using a state-of-the-art synthetic data across various settings and observed superior performance within a feasible computation time, ensuring scalability for large-scale datasets. Finally, to demonstrate the applicability of our proposed methodology using large-scale real-world data, we evaluated an important US healthcare policy related to the opioid epidemic crisis: whether opioid use disorder has a causal relationship with suicidal behavior.", "sections": [{"title": "Introduction", "content": "In this paper, we focus on feature selection methods in causal inference. Causal inference often deals with data obtained from observational studies, where the objective is to find the cause-effect relationship between a particular policy/intervention and the outcome. However, identifying the cause-effect relationships could be challenging since the mechanism of how covariates affect the outcome is invisible. The most effective approach to establishing causality is through randomized controlled trials (RCTs). RCTs involve randomly assigning participants to a treatment or control group and subsequently comparing outcomes. With a sufficiently large dataset, random assignment ensures covariate balance between the two groups. The difference between the expectation of the outcome predictors in the two groups provides insights into the causality of the treatment indicator and outcome predictor. Nevertheless, Randomized Controlled Trials (RCTs) are often time-consuming and expensive (Yao et al. 2021). Consequently, matching methods leveraging observational data are frequently employed. These methods aim to achieve covariate balance by equalizing the distribution of covariates in the treated and control groups (Stuart 2010). Regardless of the chosen matching algorithm, feature selection plays an important role not only in significantly reducing the time required to execute subsequent matching algorithms but also in aiding the attainment of unbiased and robust estimates of causal quantities.\nAs a motivating example, assume a pharma company is investigating the potential positive impact of their new medicine on treating heart disease in patients. For this study, they selected a sample of 1,000 individuals from a population of 1,000,000 and documented the observed effects. The company collected data on more than 30 covariates for each of the 1,000,000 individuals, encompassing factors such as age, gender, family history of heart disease, etc.\nWhen considering the feature selection process for the above problem, one might initially use traditional feature selection tools (e.g., lasso- or ridge-based models). Subsequently, based on the selected features, one may calculate the difference between the predicted outcomes of the treated and control groups and claim this difference as the estimated causal quantity. However, recent studies suggest that traditional feature selection tools, when used directly, often lack adequate performance in estimating the unbiased estimation of causal quantity (Stuart 2010, Rotnitzky et al. 2010). Consequently, the estimation of the causal effect lacks robustness and reliability. (Ho et al. 2017).\nTo explain this, first, we denote the observation for a person i as $Y_i = Y_i(T=1)\\mathbb{1}(T=1) + Y_i(T=0)\\mathbb{1}(T=0)$. Let's assume person i is among the 1,000 individuals who received"}, {"title": "Literature Review", "content": "In this section, we focus on the feature selection of both traditional and state-of-the-art causal inference literature. Ideally, exact matching would be the best way to reach an unbiased estimation of causal quantity since it reaches the exact covariate balance. However, strict exact matching may result in no matched pairs when dealing with high-dimensional data. Therefore, various distance metrics are developed for matching process. For instance, Mahalanobis Distance Matching (MDM) defines Mahalanobis distance Rubin (1979), while Coarsened Exact Matching (CEM) Iacus et al. (2012) introduces binning methods. However, calculating Mahalanobis distance is time-consuming (Stuart 2010), while the strata of CEM required for matching would increase exponentially (Roberts et al. 2015). Propensity score matching (PSM), introduced by Rosenbaum and Rubin (1983), is more popular than previous distance measures due to its efficiency and ability to handle high-dimensional data. PSM uses a propensity score defined as the probability of the units being treated as the distance measure. It maps all the covariates into a one-dimensional scalar, thus making all the points from the treatment and control groups comparable. However, some researchers argue that PSM creates a fully randomized design instead of a fully blocked randomized experimental design (King and Nielsen 2019), and may provide non-robust matched pairs.\nThe unscalable and non-robustness properties of traditional matching algorithms drive researchers to consider feature selection in causal inference. By reducing the dimension of the observational data, the subsequent matching algorithms can reach a lower bias and variance. Wang et al. (2012) proposed the Bayesian Effect Estimation (BAC), which leverages a two-stage framework to select the features. It incorporates both prior knowledge about the confounding factors and the observed data and uses the estimation of the probability distribution of the exposure effect on the outcome model to adjust for the confounding factors.\nTalbot et al. (2015) proposed the Bayesian Causal Effect Estimation Algorithm (BCEE), which first includes potential confounders and modify the effect of the treatment, then estimates the model parameters by using Markov Chain Monte Carlo (MCMC) methods to generate posterior distributions of the treatment effect. Although powerful for reaching unbiased estimation, BCEE is time-consuming and is not scalable to high-dimensional data. Ertefaie et al. (2018) proposed the penalized modified objective function estimators (PMOE) method, which defines a penalized objective function that combines both least squares and maximum likelihood estimates of the parameters in the exposure and outcome model and performed slightly better than BAC.\nInheriting the two-stage structure model, Shortreed and Ertefaie (2017) proposed the Outcome-Adaptive Lasso (OAL) method, which leverages the principles of the adaptive lasso (ADL) initially proposed by Zou and Hastie (2005) and aligns the exposure model with the prior knowledge indicated by the coefficients of the outcome model. Following the augmented form of elastic net estimator (Zou 2006), which is more stable than the adaptive lasso on highly correlated datasets, Bald\u00e9 et al. (2022) proposed a generalized OAL (GOAL) model for causal inference and presents a smaller bias on high-dimensional data compared to the OAL. Then, Islam et al. (2024) proposed the outcome adaptive elastic net (OAENet) method, presenting the adaptive elastic net estimator and demonstrated through testing on both synthetic and real-world datasets, particularly showcasing its effectiveness in handling highly correlated structure datasets. However, OAENet struggles to maintain the oracle property.\nIn addition to the two-stage framework, several other recently developed methods based on causal graph theory have also demonstrated promising results in feature selection for causal inference. For instance, Gruber and van der Laan (2010) proposed the collaborative targeted maximum likelihood estimation (CTMLE) method, which employs a targeted semi-parametric double robust plug-in estimator to estimate the average treatment effect (ATE). Kursa et al. (2010) introduced the Boruta method, which utilizes random forest for classification. In Boruta, the treatment indicator (T) and the outcome variable (Y) are separately synthesized in a random forest classifier, and the Z score is considered to minimize mean accuracy loss. De Luna et al. (2011) proposed the DWR (De Luna, Waernbaum, and Richardson) causal-graph framework, which performs non-parametric graph-based covariate selection.\nBesides the feature selection methods discussed above, some researchers have also attempted to utilize machine learning based feature selection methods. For example, Wang et al. (2021) proposed the Fast Large-scale Almost Matching Exactly Approach (FLAME) method, which leverages two factors (prediction error (PE) and balance factor (BF)) and uses a penalty hyperparameter to trade off the two standards. Then FLAME performs a backward feature selection process, aiming to choose exactly the set of covariates that can predict the outcomes. Although powerful and time-efficient, FLAME is not recommended to be used when there are continuous covariates unless the assumption that binning the covariates wouldn't affect causal estimation is met (Wang et al. 2021).\nIn this paper, we propose a novel feature selection framework for causal inference that addresses the limitations of existing models. Designed to minimize selection bias and variance, the framework integrates an SVM estimator for the exposure model and a penalty smoothing function to enhance performance and achieve the oracle property. This robust three-stage approach demonstrates superior capability in identifying confounders and pure outcome predictors.\nOur key contributions can be summarized as follows:\n1. Mitigate Selection Bias: Selection bias in Causal Inference is a key challenge (VanderWeele 2019, Wooldridge 2016, Lu 2020). Our proposed feature selection method is designed to overcome the selection bias. Experimental results using state-of-the-art algorithms leveraging widely used synthetic datasets (Shortreed and Ertefaie 2017, Islam et al. 2024, Wang et al. 2012) where the ground truth (i.e., the true treatment effect) is known show that applying our proposed feature selection algorithm in the design stage helps to mitigate the selection bias of treatment estimation.\n2. Practical Application: Interpretability is one of the key challenges for any causal inference method. Practitioners, such as medical experts, policymakers and scientists, do not accept findings unless they are interpretable. By allowing feature selection in the design stage using the proposed technique, we enhance the robustness of causal conclusions with fewer features. The smaller set of selected features improves the interpretability of these conclusions, making them more accessible to practitioners, including policymakers and medical experts. Moreover, our proposed feature selection method selects very few"}, {"title": "Two-stage Feature Selection Framework in Causal in-ference", "content": "This section introduces the state-of-the-art two-stage feature selection frameworks that mitigate selection bias and variance in causal inference.\nBefore introducing the two-stage framework, we first highlight the advantages of adopting a multi-stage feature selection framework over incorporating feature selection directly into the model construction process. The primary advantage lies in achieving oracle property. Multi-stage frameworks have been shown to be effective in attaining oracle property easily (Zou 2006, Zou and Zhang 2009, Shortreed and Ertefaie 2017, Islam et al. 2024). In contrast, within our reach, no current literature provides evidence that oracle property can be reliably achieved through a one-stage process."}, {"title": "Outcome Adaptive Lasso (OAL)", "content": "In 2017, Shortreed et al. Shortreed and Ertefaie (2017) introduced the Outcome-Adaptive Lasso (OAL) method for the feature selection process in causal inference. The procedure is outlined as follows:\noutcome model:\n$\\hat{\\theta}(OLS) = \\text{argmin}_{\\theta} ||Y - X\\theta||_2^2$ (1)\nexposure model:\n$\\hat{\\beta}(OAL) = \\text{argmin}_{\\beta} \\{ \\sum_{i=1}^n (-t_iX_i^T\\beta + log(1 + e^{X_i^T\\beta})) + n\\sum_{j=1}^p \\lambda w_j |\\beta_j| \\}$ (2)\nHere ti is the indicator for the unit i being treated or not, $w_j = |\\hat{\\theta}(OLS)_j|^{-r}$, and $\\hat{\\beta}(OAL)$ is the vector which indicates the coefficient assigned to each covariate. Non-zero coefficient of $\u03b2_j$ indicates the variable is selected.\nIntuitively, large $\\hat{\\theta}(OLS)_j$ in the outcome model lead to small value of $w_j$, which means, this covariate is more likely to be chosen in the exposure model.\nOutcome adaptive lasso is very efficient in choosing a high-quality subset of variables suggested by Proposition 1. Nevertheless, as this method employs adaptive lasso for feature selection, it inherits certain drawbacks from the original adaptive lasso model, including instability in high-dimensional data (Zou and Zhang 2009). Further analysis and experiments also support the observation that outcome adaptive lasso tends to excessively penalize pure outcome predictors in synthetic datasets (Islam et al. 2024).\nTo meet the oracle property, Shortreed and Ertefaie (2017) introduces a method called weighted absolute mean difference (wAMD), which defines an objective function regarding the choice of \u03bb that minimizes the Inverse Probability Treatment Weighting (IPTW) estimator. The related proof for the oracle property is presented in Online Supplement S1 Appendix \u0421.1."}, {"title": "Outcome Adaptive Elastic Net (OAENet)", "content": "Islam et al. (2024) proposed the Outcome Adaptive Elastic Net method (OAENet). The model is formulated below:\noutcome model:\n$\\hat{\\theta}(OLS) = \\text{argmin}_{\\theta} ||Y - X\\theta||_2^2$ (3)\nexposure model:\n$\\hat{\\beta}(OAENet) = (1+\\lambda_2)^{-1}\\text{argmin}_{\\beta} \\{ \\sum_{i=1}^n (-t_iX_i^T\\beta + log(1 + e^{X_i^T\\beta})) + \\lambda_2|\\beta||_1^2 + \\lambda_1 \\sum_{j=1}^p w_j |\\beta_j| \\}$ (4)\nCompared to the OAL method, OAENet has a relatively smaller absolute bias and standard error on the ATT estimation when data is highly correlated. The outcome adaptive elastic net method also enjoys the oracle property. We also provide simple proof for this property in Online Supplement S1 Appendix C.2."}, {"title": "Two types of two-stage framework", "content": "Based on the discussion above, OAL and OAENet belong to the design of Framework B.\nNow we consider the possible model that applies similar ideas of OAL and OAENet to Framework A. Recalling Lemma 1 and Proposition 1, only confounders and pure outcome predictors (i.e., Xc & Xp) should be selected. Therefore, we have the following conclusions:\nFramework A: If we fit the exposure model first, the covariates with high coefficient are composed of Xc and XT. Lemma 1 indicates that we should exclude XT while choosing Xp in the outcome model. Therefore, the regularization term exists only in the outcome model.\nFramework B: If we fit the outcome model first, the covariates with high coefficient are composed of Xp and Xc. In some cases, part/all covariates of XT might be assigned with high coefficients since it indirectly impacts Y through T. Lemma 1 indicates that the exposure model should identify Xc and exclude XT. Therefore, the regularization term exists only in the exposure model.\nOAL and OAENet utilize a penalty factor $w = \\{w_1, w_2, ..., w_j\\}$, where $w_i = 1/|\u03b2|$ because they would like to keep Xp and Xc in the second model."}, {"title": "SVM: Alternative choice for exposure model", "content": "In this section, we discuss the advantages of utilizing the support vector machine (SVM) to generate prior knowledge in framework A.\nIn the exposure model, the treatment indicator $T_i = \\{0, 1\\}$. Assume the label of the outcome in SVM is L. Then, it is natural to predict $T_i = 1$ if the label $L_i = 1$ and predict $T_i = 0$ if the label $L_i = \u22121$. Then the objective function is:\n$\\text{min}_{\\beta, b} \\frac{1}{2}||\\beta||^2$ (5)\ns.t $L_i(\\beta^T(X) + b) \u2264 1$\n$i = 1, ..., n$\nHere, $\u03a6(X)$ refers to the characteristic space and $\u03b2$ refers to the estimation of the coefficient for each variable in the SVM model. Rewritten the equation we have:\n$\\text{min}_{\\beta, b} \\frac{1}{2}||\\beta||^2 + C \\sum_{i=1}^n \\text{max}(0, L_i(\\beta^T X_i + b_i) - 1)$ (6)\nHere, C is a positive constant referring to the penalty factor of misclassification. By simply observing Eq. (6), the SVM model can prevent the absolute value of coefficients for some dominant covariates from becoming extremely high (otherwise, the first term in Eq. (6) would be extremely large). In the exposure model, when using logistic regression, there is a risk of overfitting (Bald\u00e9 et al. 2022) when dealing with high-dimensional data, as it may assign extremely large absolute coefficients to dominant covariates. In contrast, SVM tends to assign smaller absolute weights to each covariate, which is supported by experiments on our synthetic datasets.\nNow let us consider $\u03b2_j$, which refers to the weight assigned to covariate $x_j$ in the exposure model. If $|\u03b2_j|$ is large, and considering that in Framework A, $w_j \\propto |\u03b2_j|$, the penalty assigned to this covariate in the second model will also be large, making it less likely to be chosen. Since SVM tends to assign small weights to the covariates, SVM does not separate covariates far away, this intuitively provides a relatively moderate prior knowledge than logistic regression and increases the chance of selecting Xc.\nMoreover, if we choose $\u03b3 = 1$ and let $w_j = |\\hat{\u03b2_j}|$ in the Framework A, the expectation of $\\sum_{j=1}^p w_j^2$ is exactly $\\sum_{j=1}^p \\hat{\u03b2_j}^2$. Recall that in Eq.(5), the objective function is to minimize $||\\beta||^2 = \\sum_{j=1}^p \\beta_j^2$. From the mathematical form of the elastic net estimator given by the paper (Zou and Zhang 2009) (the detailed theory and proof is presented in Online Supplement S1 Appendix F), SVM elastic net estimator will minimize the upper bound of $E[||\\beta(\\lambda_2, \\lambda_1) - \\beta^*||^2]$. The previous discussion indicates that the SVM-based elastic net estimator indicates stronger oracle property in choosing variables than logistic regression-based models."}, {"title": "Two Preliminary Two-Stage Variable Selection Frame-work for Causal Inference", "content": "In this section, we present the following proposed preliminary two-stage models developed based on Framework A, i.e., the models fit the exposure model first and then fit the outcome model. The preliminary framework is outlined below.\nexposure model:\n$\\hat{\\beta} = \\hat{\\beta}(SVM) \\text{ or } \\hat{\\beta}(LR)$ (7)"}, {"title": "Selecting \u5165", "content": "Compared to Framework B, A in Framework A is straightforward. In the second stage, the optimal \u03bb should yield the most regularized model such that the cross-validated error is within one standard error of the minimum. Since we choose the adaptive elastic net as the regularization method in the outcome model, the same method presented in Zou (2006) could be adopted, which is to first grid and fix $\u03bb_2$, then choose $\u03bb_1$ so that the best pair ($\u03bb_2, \u03bb_1$) minimizes the cross-validation error for the outcome model."}, {"title": "Selecting w", "content": "Recall conclusions in section 3, in Framework A, $w_j \\propto |\u03b2_j|$. However, directly selecting $w_j = |\u03b2_j|$ is inappropriate. For example, when considering the noise covariates (i.e., Xs) in the exposure model, if $w_j = |\u03b2_j|$, then the weights $w_i$ of these covariates will be close to 0. When mapping $w_j$ to the penalty value that carries prior knowledge to the outcome model, small penalties will be assigned to these variables. Therefore, it does not improve the ability to eliminate Xs. To address this issue, we propose using the sigmoid function to smooth the penalty. We refer to such functions as penalty smoothing functions."}, {"title": "Selecting y", "content": "In this subsection, we present guidance in selecting \u03b3 in both Framework A and Framework B on the lasso-based structure to support our statement that Framework A requires less effort in tuning parameters."}, {"title": "Selecting \u03b3 in lasso-based method of Framework B", "content": "In Framework B, the wAMD equation is the equation to be optimized. To meet the oracle property, first, it defines the gamma converge factor \u0393, then chooses the best pair ($\u03bb_n, \u03b3$) that minimizes WAMD.\nNow let's consider the boundary of \u03b3 in Framework B. Since the oracle property requires two conditions: $\\lambda_n/\\sqrt{n} \u2192 0$ and $\\lambda_nn^{\\gamma/2-1} = n^\u0393 \u2192 \u221e$ (Note that in general cases $\\lambda_nn^{(\\gamma-1)/2-1} \u2192 \u221e$. However, Shortreed and Ertefaie (2017) points out that in causal inference, variables that predict exposure should be excluded, thus a stronger condition is required). The second condition gives \u0393 \u2265 0, and the first condition yields \u0393+1-\u03b3/2 < 0.5. Thus, \u03b3 > 2\u0393 +1 and \u0393 > 0. However, there is no upper bound for \u03b3, which makes tuning \u03b3 a challenging process because minimizing wAMD is a nonlinear optimization problem with respect to \u03b3."}, {"title": "Selecting \u03b3 in lasso-based method of Framework A", "content": "Compared to Framework B, \u03b3 in Framework A is less sensitive because the outcome model can adjust the prior knowledge by itself. \u03b3 in Framework A is more interpretable as it functions as the adjustment factor of convexity (see Online Supplement S1 Appendix J). Our experiments find that if we use the sigmoid function as the penalty smoothing function, \u03b3 = 1 should be fine. Applying a large \u03b3 further separates the penalty of Xc and Xs, decreasing the selection ability of $X_c\\cup X_T$ and increasing the selection ability of $X_p\\cup X_s$. Conversely, applying a smaller value of \u03b3 increases the selection ability of $X_C\\cup X_T$ while decreasing the selection ability of $X_p \\cup X_s$."}, {"title": "Limitation of the preliminary two-stage framework", "content": "Although efficient in selecting variables proposed in Proposition 1, unfortunately, we cannot guarantee that the preliminary models satisfy the oracle property. This is because the selected \u03bb in Section 4.1 is designed to minimize the cross-validation error of the outcome model, but the model not necessarily meet the two conditions required for the oracle property (i.e., $\u03bb_n/\\sqrt{n} \u2192 0$ and $\u03bb_1n^{(\u03b3-1)/2-1} \u2192 \u221e$). One might attempt to search for the optimal \u03bb that minimizes the cross-validation error while satisfying the constraints given by the two conditions of the oracle property. However, this approach would be challenging and time-consuming, as \u03bb does not have an upper bound.\nLuckily, there is an alternative approach that both meets the oracle property and requires less effort in tuning hyperparameters. According to the mathematical proof presented in Online Supplement S1 Appendix F, any non-negative parameters $\u03bb_1$ and $\u03bb_2$ will make estimations of coefficients from the preliminary model a root-n/p-consistent estimator. Such an estimator is considered suitable for the adaptive elastic net model (Zou and Zhang 2009). This approach compromises on time complexity to achieve the oracle property by fitting an additional adaptive elastic net model in the outcome model, utilizing the estimation from Eq.(8)."}, {"title": "Enhanced Three-Stage Variable Selection Framework for Causal Inference", "content": "In this section, we propose the three-stage framework. This framework includes one exposure model and two outcome models. The three-stage framework adds an additional adaptive elastic net model in the outcome model in order to keep the oracle property while reducing the burden of tuning hyperparameters. First, it fits the exposure model by SVM or LR estimator. Then, it inputs the prior knowledge to the first model of outcome models, which is the elastic net model. At last, it inputs the coefficient of each covariate in the elastic net model to the second model of outcome models.\nexposure model:\n$\\hat{\\beta} = \\hat{\\beta}(SVM) \\text{ or } \\hat{\\beta}(LR)$ (10)"}, {"title": "Improvement compared to the two-stage framework", "content": "The three-stage framework has some advantages over the preliminary two-stage framework. As presented in Section 4.4, the preliminary model faces the challenge of simultaneously meeting the oracle property and tuning the optimal \u03bb. The three-stage framework mitigates the sensitivity of selecting A by handing it over to the second outcome model (the adaptive elastic net model). Consequently, it makes it easier and interpretable for tuning the hyperparameter $\u03b3_2$ (we go depth in section 5.3).\nIt's worth noting that in the three-stage framework, we utilize the outcome label twice in the outcome model. Utilizing the outcome label further, however, will not improve the results, as the oracle property can be certainly satisfied with our three-stage framework."}, {"title": "Choosing penalty smoothing function and selecting Y1", "content": "In the three-stage framework, unlike the preliminary framework, either the sigmoid function or the tanh function can be used as the penalty smoothing function. If we use the tanh"}, {"title": "Selecting \u00a52", "content": "Choosing $\u03b3_2$ in our proposed model is a relatively easy task. According to the assumptions in Online Supplement S1 Appendix E, $\u03b3_2 \u2265 [\\frac{v}{2(\\bar{v})}] + 1$, where $v = lim_{n\u2192\u221e} \\frac{log(p)}{log(n)}$, and 0 <\n$\\bar{v} \u2264 1$. Thus, $\u03b3_2 \u2265 1$. Therefore, it is safe to set $\u03b3_2 = 1$. We suggest setting $\u03b3_2 = 1$ because as $\u03b3_2$ increases, the selection ability of Xc will decrease. However, our experiments also indicate that when $\u03b3_2$ is set to values larger than 1, the subset of selected variables remains unchanged even when the covariates are highly correlated. This observation suggests that this framework is robust and not sensitive to the choice of $\u03b3_2$."}, {"title": "Properties of the proposed three-stage framework", "content": "In our proposed model, regardless of the choice of penalty smoothing function (sigmoid function or tanh function) and the exposure model (SVM or LR estimator), the estimator (11) is always a root-n/p consistent estimator. According to the Online Supplement S1 Appendix F, the oracle property of the proposed three-stage framework is well-defined as follows:\nTheorem 1 (Oracle Property of Proposed Model) Given data (Y, X,T), let w = (\u01751, \u01752..., \u0175p) be a vector whose components are all non-negative, then under six assumptions listed in the Online Supplement S1 Appendix E (Zou and Zhang 2009), the adaptive elastic net reaches the oracle property:\n1. Consistency in variable selection: Pr({j|\u03b2(AdaEnet)j \u2260 0} = A) \u2192 1\n2. Asymptotic normality:  $\\sqrt{nT1 + \u03bb_2/n} [\u03b2(AdaEnet)A - \u03b2_A] \u2192 N(0, \u03c3^2)$\nHere ut is an imposed vector which satisfies utu = 1, \u03a311 is known as the Fisher Information Matrix and is the upper left block of XTX. The mathematical proof for the oracle property follows Online Supplement S1 Appendix F."}, {"title": "Result Analysis for Synthetic Datasets", "content": "This section discusses our experimental results on synthetic datasets. All the experiments are run on the 2.4 GHz Quad-Core Intel Core i5 CPU using R."}, {"title": "Benchmark on Causal Feature Selection Models", "content": "To evaluate the ability of variable selection discussed in Section 1, we utilized one of the most widely used state-of-the-art synthetic datasets (Shortreed and Ertefaie 2017, Lu 2020, Bald\u00e9 et al. 2022), which is generated based on the known confounders (Xc), pure treatment predictors (\u0425\u0442), pure outcome predictors (XP) and noise variables (Xs).\nWe perform our experiments in the following 4 scenarios. O refers to the regression coefficients in the outcome model and \u1e9e refers to the regression coefficients in the treatment model. The experiments are conducted with varying levels of correlation among covariates \u03c1 = {0, 0.25, 0.5,0.75}, a fixed number of covariates p = 20, and different numbers of generated cases N = {200, 500, 1000}. For each combination (N, p) in each scenario, the experiment is conducted 30 times with seeds ranging from 1 to 30 for reproducibility. Hence, the total number of experiments conducted is 4 \u00d7 3 \u00d7 4 \u00d7 30 = 1,440 runs.\nScenario 1. 0 = (0.6, 0.6, 0.6, 0.6, 0, 0, 0, ..., 0) and \u03b2 = (1, 1, 0, 0, 1, 1, 0, ..., 0)\nScenario 2. 0 = (0.6, 0.6, 0.6, 0.6, 0, 0, 0, ..., 0) and \u03b2 = (0.4,0.4, 0, 0, 1, 1, 0, ..., 0)\nScenario 3. 0 = (0.2, 0.2, 0.6, 0.6, 0, 0, 0, ..., 0) and \u03b2 = (1, 1, 0, 0, 1, 1, 0, ..., 0)\nScenario 4. 0 = (0.6, 0.6, 0.6, 0.6, 0, 0, 0, ..., 0) and \u03b2 = (1, 1, 0, 0, 1.8, 1.8, 0, ..., 0)\nRecall the definition of O and \u03b2, in scenarios 1 to 4, Xp = {3,4}, \u0425\u0442 = {5,6}, Xc = {1,2}, the variables to be chosen should be $X_p \\cup X_c = \\{1, 2, 3, 4\\}$."}, {"title": "Benchmark Models", "content": "We utilize the following four models derived from the proposed three-stage framework to evaluate their performance (i) Enh-ELRT, with logistic regression estimator and tanh penalty smoothing function.; (ii) Enh-ELRS, with logistic regression estimator and sigmoid penalty smoothing function.; (iii) Enhanced three-stage framework (Enh-ESVMT), with SVM estimator and the tanh penalty smoothing function. (iv) (Enh-ESVMS), with SVM estimator and the sigmoid penalty smoothing function..\nWe benchmarked our proposed feature selection framework with the following state-of-the-art lasso-based framework for our performance evaluation (v) Adaptive Lasso (OAL) Method (Shortreed and Ertefaie 2017) with wAMD method, utilizing R package lqa(v 1.0.3); (vi) Outcome Adaptive Elastic Net (OAENet) Method (Islam et al. 2024) with"}, {"title": "Selection Bias to the True ATT estimation", "content": "The experiment is designed as follows: each model first identifies the selected features. Then, the one-to-one nearest matching technique is employed based on these selected variables to filter the matched groups of treatment and control. Then we estimate ATT based on the regression model and record the absolute difference between the ATT estimation and the true ATT values as selection bias, given by the regression model which includes all the predefined $X_p\\cup X_C$ (also known as the target model (TM) ).\nWe present the selection bias to the ATT estimation for each model with N 200. The ideal framework is supposed to provide 0 bias. Figure 1 displays the ATT estimation across \u03c1 = {0, 0.25, 0.5,0.75}. Results for N = 500 and N = 1000 results are available in Online Supplement S1 Appendix H.2.1.\nFigure 1, along with the figures recording bias to the ATT estimation provided in Online Supplement S1 Appendix H.2.1, demonstrates the significantly remarkable consistency in achieving significantly low bias compared to other state-of-the-art methods across all scenarios. To further demonstrate the superiority of our proposed feature selection framework, we conducted hypothesis tests on the absolute selection bias equal to 0. The results showed that our framework consistently selects variables that produce ignorable selection bias, whereas the state-of-the-art methods including BCEE and OAENet do not have such property. Detailed results are provided in Online Supplement S1 Appendix G."}, {"title": "Probability of each variable being selected", "content": "We present the probability of each variable being selected by our proposed models and benchmark models for N = 200. Results for N 500 and N = 1000 are available in Online Supplement S1 Appendix H.2.2.\nIn each figure in Figure 2, the horizontal axis represents the index of each covariate, while the vertical axis indicates the probability of each covariate being selected by each model. We highlight the target model and our proposed three-stage framework models with markers and keep the lines of other benchmark models without markers.\nBased on the results presented in Figure 2, along with the plots in Online Supplement Appendix H.2.2, our proposed framework demonstrates superior performance by consistently chooses $X_p\\cup X_C$ with probability near 1 and choose $X_T \\cup X_s$ with probability near 0. Noticing that the four proposed three-stage frameworks have similar performance, further experiments are conducted in Online Supplement Appendix H.2.1 to evaluate the logistic regression-based three-stage models and SVM-based three-stage models."}, {"title": "Computational time", "content": "We present the computational time for each method in Table 1 for N = 200 records, by averaging the CPU time across all the scenarios. According to Table 1, OAL and OAENet exhibit faster computation times compared to other algorithms. Our proposed models, however, exhibit superior performance in reducing bias and variance in estimating ATT, while maintaining comparable computational efficiency."}, {"title": "Benchmark on Causal Machine Learning Models", "content": "This subsection displays experimental results by combining the proposed feature selection framework with the popular"}]}