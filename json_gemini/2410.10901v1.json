{"title": "3DS: DECOMPOSED DIFFICULTY DATA SELECTION'S\nCASE STUDY ON LLM MEDICAL DOMAIN ADAPTA-\nTION", "authors": ["Hongxin Ding", "Yue Fang", "Runchuan Zhu", "Xinke Jiang", "Jinyang Zhang", "Yongxin Xu", "Xu Chu", "Junfeng Zhao", "Yasha Wang"], "abstract": "Large Language Models (LLMs) excel in general tasks but struggle in special-ized domains like healthcare due to limited domain-specific knowledge. Super-vised Fine-Tuning (SFT) data construction for domain adaptation often relies onheuristic methods, such as GPT-4 annotation or manual data selection, with a data-centric focus on presumed diverse, high-quality datasets. However, these methodsoverlook the model's inherent knowledge distribution, introducing noise, redun-dancy, and irrelevant data, leading to a mismatch between the selected data andthe model's learning task, resulting in suboptimal performance. To address this,we propose a two-stage model-centric data selection framework, DecomposedDifficulty Data Selection (3DS), which aligns data with the model's knowledgedistribution for optimized adaptation. In Stage 1, we apply Prompt-Driven DataSelection via Explicit Alignment, where the model filters irrelevant or redundantdata based on its internal knowledge. In Stage 2, we perform Decomposed Dif-ficulty Data Selection, where data selection is guided by our defined difficultydecomposition, using three metrics: Instruction Understanding, Response Con-fidence, and Response Correctness. Additionally, an attention-based importanceweighting mechanism captures token importance for more accurate difficulty cal-ibration. This two-stage approach ensures the selected data is not only alignedwith the model's knowledge and preferences but also appropriately challengingfor the model to learn, leading to more effective and targeted domain adapta-tion. In the case study of the medical domain, our extensive experiments onreal-world healthcare datasets demonstrate the superiority of 3DS over existingmethods in accuracy by over 5.29%. Our dataset and code will be open-sourcedat https://anonymous.4open.science/r/3DS-E67F.", "sections": [{"title": "1 INTRODUCTION", "content": "Large Language Models (LLMs) like GPT-4 (OpenAI, 2023) have showcased significant potential\nin natural language understanding. Open-source models such as LLaMA (Touvron et al., 2023) and\nQwen (Bai et al., 2023) have also rapidly advanced, delivering competitive performance. However,\nin specialized domains like healthcare, their effectiveness is often constrained by the lack of domain-\nspecific knowledge (Sanaei et al., 2023; Harris, 2023; Waisberg et al., 2023), essential for tasks like\ndiagnosis (Panagoulias et al., 2024; Ullah et al., 2024) and treatment recommendations (Wilhelm\net al., 2023; Nwachukwu et al., 2024). To address this, some works (Wang et al., 2023a; Zhang\net al., 2023; Yang et al., 2023b; Zhu et al., 2023a; Pal & Sankarasubbu, 2023) have adapted LLMs\nto the medical domain by training on large-scale healthcare-specific datasets."}, {"title": "2 RELATED WORK", "content": "Data selection for LLM training has been explored through various approaches. Some works (Das\n& Khetan, 2023) utilize statistical clustering or core-set selection techniques to identify diverse and\nrepresentative subsets, yet they neglect data quality and may incorporate noisy samples that hinder\nmodel training. To address quality concerns, some works leverage external models like proprietary\nLLMs (Chen et al., 2023; Liu et al., 2023; Wettig et al., 2024) or reward models (Du et al., 2023)\nto evaluate and select high-quality training data. However, due to distribution differences and pref-\nerence gaps between external models and the target training model, the selected data often fails to\nalign with the target model's learning requirements, leading to limited performance gains. Another\nline of research leverages information produced by the target model, such as perplexity (Marion\net al., 2023), gradients (Xia et al., 2024) and derived metrics like data learnability (Zhou et al., 2023)\nand instruction following difficulty (Li et al., 2024b;a). While these metrics provide more direct\ninsights into the model's current understanding of data, they typically offer only coarse measures\nof data difficulty, failing to capture different aspects of data complexity or account for the model's\ngeneration behavior, leading to suboptimal selection. Moreover, existing data selection methods are\npredominantly tailored for pre-training, general fine-tuning (transforming a base model into a chat\nmodel), or targeted fine-tuning for specific downstream tasks. There remains a significant absence\nin data selection for domain adaptation fine-tuning, where unique challenges lies in selecting data\nthat effectively enhances the model's diverse domain abilities. To bridge this gap and overcome the\nlimitations of current methods, our work introduces a novel data selection framework that explicitly\nconsiders the model's generation behavior, providing a more fine-grained analysis of data difficulty."}, {"title": "2.2 DATA LEARNABILITY IN LLM SFT", "content": "LLMs encounter significant challenges when learning unfamiliar or complex knowledge during su-\npervised fine-tuning, particularly when the data was not encountered during pre-training, which can\nimpede domain adaptation. Gekhman et al. (2024) found that models acquire new factual knowledge\nslowly during SFT, especially when the information diverges from their pre-existing understanding,\nleading to a higher risk of hallucinations. Ren et al. (2024) further show that when the knowledge in-\ntroduced during Instruction Fine-tuning significantly differs from what was learned in pre-training,\nthe model struggles to integrate it, causing performance degradation. This highlights the difficulty\nmodels face in using pre-training knowledge to understand new concepts. Kang et al. (2024) also\nemphasize that unfamiliar examples during fine-tuning increase the likelihood of hallucinations,\nsuggesting that high-difficulty data can destabilize the model and negatively impact its ability to\nadapt to new domains. Together, these findings underscore the risks associated with fine-tuning on\nexcessively difficult data, which can undermine model performance in domain-specific tasks."}, {"title": "3 METHODOLOGY", "content": null}, {"title": "3.1 TASK FORMULATION", "content": "We define our task as Data Selection for Domain Adaptation, which focuses on selecting an optimal\nsubset of domain-specific fine-tuning data to maximize an LLM's target domain performance. Given\nan initial LLM Me with parameter 0 that has undergone pre-training and general instruction fine-\ntuning, e.g., LLaMA-chat, domain adaption aims to adapt the model to a specific target domain\nthrough continual fine-tuning using domain-specific instruction tuning data. Let X denote the full\ndomain instruction fine-tuning dataset containing samples x =< Q, A > with Q = {q1, q2, ..., qm}\nrepresenting the instruction and A = {a1, a2,..., an } the response. Given a fixed budget k, the goal"}, {"title": "3.2 PROMPT-DRIVEN DATA SELECTION VIA EXPLICIT ALIGNMENT", "content": "The first stage of our framework is to select high-quality data that closely aligns with the target\nmodel's inherent knowledge and preferences. Unlike existing methods that rely on external reward\nmodels or proprietary LLMs to score data quality, which often result in suboptimal outcomes due\nto distributional mismatches and knowledge gaps, our approach directly uses the target model itself\nfor data evaluation. As illustrated in Figure 1, we leverage a carefully crafted prompt, detailed in\nAppendix A, to instruct the model to explicitly rate data quality based on its understanding. After\nobtaining the model-generated scores, samples with scores exceeding a predefined threshold 8 are\nretained for further selection. By utilizing this prompt-driven alignment approach based on explicit\nmodel generation, our framework effectively reduces the gap between the training data and the\nmodel's inherent preferences, filtering out possible noise from low-quality or misaligned data."}, {"title": "3.3 DECOMPOSED DIFFICULTY DATA SELECTION VIA IMPLICIT DISTRIBUTION MODELING", "content": "The second stage of our framework is to analyze data difficulty via implicit distribution modeling\nof the target model, thereby selecting data with moderate difficulty that best aligns with the model's\nlearning capacity, to facilitate efficient domain adaptation. To achieve this, our Decomposed Diffi-\nculty Data Selection employs a fine-grained evaluation of data difficulty.\nInspired by the general problem-solving process\u2014understanding the problem, assessing confidence\nin the solution, and finally providing the answer\u2014we decompose data difficulty into three key com-\nponents that reflect the model's understanding: (1) Instruction Understanding Difficulty measures\nwhether the model comprehends the given instruction. (2) Response Confidence Difficulty mea-\nsures the model's ability to provide a confident and deterministic response based on the instruction.\n(3) Response Correctness Difficulty measures whether the model can generate a response that ac-\ncurately matches the reference answer. In addition, we incorporate an attention-based importance\nweighting mechanism that calibrates difficulty by accounting for the varying semantic significance\nof tokens in the output, to ensure a more precise evaluation of response-related difficulties. Next, we\nwill delve into the quantification of the decomposed difficulties and introduce the selection strategy."}, {"title": "4 EXPERIMENTS", "content": null}, {"title": "4.1 EXPERIMENTAL SETUP", "content": "For medical domain adaptation, we construct a comprehensive medical instruc-\ntion fine-tuning dataset of diversity and abundance. The dataset comprises over 1.9 million samples,\nwith its statistics provided in Table 1. The details of data construction are introduced in Appendix B.\nWe will release this complete training dataset to support further research."}, {"title": "4.2 MAIN RESULTS", "content": "Experiment results are shown in Table 3 and Table 4. We summarize our findings below.\nData selection is necessary for LLM domain adaptation fine-tuning. We observe that fine-tuning\nLLMs with the full 1.9 million dataset (Full-SFT) leads to drastic performance drops. This suggests\nthat domain datasets directly collected from the internet contains noisy samples that hinder model\nlearning, highlighting the necessity of data selection.\n3DS effectively enhances LLM's diverse domain abilities, significantly outperforming base-\nlines. Baseline LESS, which focuses on enhancing model's targeted ability on a spe-"}, {"title": "4.3 ABLATION STUDIES", "content": "To validate the effectiveness of each difficulty metric in our decomposed difficulties, we conduct\nablation studies by removing each of the three metrics\u2014Instruction Understanding Difficulty, Re-\nsponse Confidence Difficulty, and Response Correctness Difficulty. As shown in Table 3 and Ta-\nble 4, in general, removing any single component result in noticeable performance drops on some\nevaluation metrics for all three models, indicating a decline in certain aspects of the model's medical\ndomain abilities. For instance, the exclusion of Response Confidence Difficulty leads to a notice-\nable decrease in the performance of both Baichuan2-7B-Chat and Baichuan2-13B-Chat\nacross all evaluation metrics. Similarly, Qwen-1.5-7B-chat's performance drops on CMB-Clin.\nThese observations validate the necessity of each difficulty metric in identifying beneficial data\nsamples for enhancing LLM's domain abilities. Overall, the combination of these difficulty metrics\ncontributes to a more accurate data difficulty measurement, ensuring that selected data matches the\nmodel's learning capacity and optimally enhances its domain performance."}, {"title": "5 IMPACT OF DIFFICULTY THRESHOLDS", "content": "To further investigate the relationship between training data difficulty and model performance in\nmedical domain adaptation fine-tuning, we conduct a sliding-window experiment to identify the op-\ntimal training data for each model. Using hyperparameter o to denote the chosen difficulty level, we\nvary & and select training samples within the range \u03c3 \u2013 25% and \u03c3 + 25% on our proposed difficulty\nmetrics. As shown in Figure 3, for each model, performance improves as the training data difficulty\nincreases, reaching a peak before declining. Notably, the optimal difficulty range differs depending\non the model's inherent capability. For instance, Baichuan2-7B-Chat achieves its best perfor-\nmance when trained on data within relatively lower difficulty range of 10%-60%. For more powerful\nmodels like Baichuan2-13B-Chat and Qwen1.5-7B-Chat, the optimal ranges are 15%-65%\nand 25%-75% respectively, indicating that more capable models benefit from data of higher com-\nplexity. These findings further highlight the importance of selecting data that aligns with the model's\ncapability. Training less capable models on excessively difficult data may overwhelm them, result-\ning in suboptimal performance, whereas models with stronger domain-specific knowledge require\nmore challenging domain data to enhance their abilities. This insight provides a valuable guideline\nfor optimizing the fine-tuning process of LLMs for domain adaptation, and our difficulty metrics\nprove to be effective measures of data complexity."}, {"title": "6 CONCLUSION", "content": "In this paper, we introduce a two-stage model-centric data selection framework for LLM domain\nadaptation fine-tuning. The first stage performs a prompt-driven selection strategy to explicitly align\nwith the model's preferences. The second stage selects data via data difficulty decomposition. By\nincorporating Instruction Understanding, Response Confidence, and Response Correctness difficul-\nties, alongside an attention-based importance weighting mechanism, our method effectively captures\nthe model's implicit distribution and selects data that matches the its learning capacity. Experimen-\ntal results across multiple medical tasks demonstrate significant performance gains, validating the\neffectiveness of our selection framework. Our approach highlights the effectiveness of model-driven\ndata selection, offering a path toward more efficient LLM domain adaptation training. Future work\nwill explore extending this framework to other domains and refining the training procedure based\non difficulty metrics for broader LLM applications."}, {"title": "7 LIMITATIONS", "content": "Due to time and resource constraints, we have only validated our method in the medical domain.\nWhile our data selection framework is domain-agnostic and adaptable to other fields, further ex-\nperiments in different domains are needed to fully verify its generalization. Additionally, since the\nselection process requires the model to perform inference on the training data, it may involve certain\ncomputational costs. Specifically, during the data selection phase, the model must evaluate each\nexample to assess its alignment with the model's current knowledge state. This additional inference\nstep may increase computational overhead, especially when working with very large datasets."}]}