{"title": "AI-Powered Bayesian Inference", "authors": ["Veronika Ro\u010dkov\u00e1", "Sean O'Hagan"], "abstract": "The advent of Generative Artificial Intelligence (GAI) has heralded an inflection point that changed how society thinks about knowledge acquisition. While GAI cannot be fully trusted for decision-making, it may still provide valuable information that can be integrated into a decision pipeline. Rather than seeing the lack of certitude and inherent randomness of GAI as a problem, we view it as an opportunity. Indeed, variable answers to given prompts can be leveraged to construct a prior distribution which reflects assuredness of AI predictions. This prior distribution may be combined with tailored datasets for a fully Bayesian analysis with an AI-driven prior. In this paper, we explore such a possibility within a non-parametric Bayesian framework. The basic idea consists of assigning a Dirichlet process prior distribution on the data-generating distribution with AI generative model as its baseline. Hyperparameters of the prior can be tuned out-of-sample to assess the informativeness of the AI prior. Posterior simulation is achieved by computing a suitably randomized functional on an augmented data that consists of observed (labeled) data as well as fake data whose labels have been imputed using AI. This strategy can be parallelized and rapidly produces iid samples from the posterior by optimization as opposed to sampling from conditionals. Our method enables (predictive) inference and uncertainty quantification leveraging AI predictions in a coherent probabilistic manner.", "sections": [{"title": "1 Introduction", "content": "Due to their ability to synthesize information from various sources, Generative AI models (GAI) are quickly becoming the go-to source of knowledge for many users. However, the practical utility of these models largely depends on the user's understanding of their mechanistic (probabilistic) properties. GAI simply produce stochastic responses to prompts, with the level of randomness influenced by both the prompt's specificity and the AI's ability and confidence in providing an accurate answer. This inherent randomness raises questions about the extent to which important decisions can be based on a single AI output answer. We argue that the variability in the answers themselves offers an opportunity to generate (a) a random prior guess at the correct answer, and (b) probabilistic predictions via AI-induced distributions obtained by repeated prompting. While our society has resisted surrendering important decision-making to artificial intelligence, AI predictive systems may serve as a useful primer for further analysis. This work explores the possibility of articulating prior information through AI data augmentation for a fully Bayesian analysis.\nOur setup consists of independent labeled data \\(D_n = \\{(Y_i, X_i)\\}_{i=1}^n\\) which are tailored to a specific question regarding a parameter of interest \\(\\theta_0\\). For example, we will later analyze a dermatology dataset where the label is one of six distinct but closely overlapping skin conditions within the group of Erythemato-Squamous Diseases (ESDs) [31]. While the parameter of interest \\(\\theta_0\\) may index a statistical model (including deep learning models involving high-dimensional \\(\\theta_0\\)), we regard it more generally as a minimizer of a certain loss function [4]. Our goal is to understand how generative AI can be used for prior elicitation to conduct fully Bayesian inference on \\(\\theta_0\\) as well as predictive inference on \\(Y^*\\) given \\(X^* \\& D_n\\).\nThis work is based on the premise that generative models produce synthetic data which can be converted into (informative) priors. The idea of using imaginary training data for prior construction is nearly as old as Bayesian statistics itself, dating to at least Laplace in the 18th century [15]. In the context of Bayes factor model comparisons, intrinsic priors [3] result from converting an improper uninformative prior into a proper posterior on a sample of a \u201cminimal\" training size. Arithmetic and geometric mean aggregates of Bayes factors under all plausible training data subsets approximately correspond to a"}, {"title": "2 AI-Powered Bayesian Inference", "content": "Suppose that we observe labeled data \\(D_n = \\{(Y_i, X_i)\\}_{i=1}^n\\) and want to perform a supervised analysis involving a parameter of interest \\(\\theta_0\\) as well as predictive inference about \\(Y_{new}\\) given \\(X_{new} = x_{new}\\) where \\((Y_{new}, X_{new}) \\notin D_n\\). In addition to observations \\(D_n\\), we have access to a black-box predictive model \\(\\hat{\\mu}_{AI}(x)\\) which generates random labels \\(Y_i = \\hat{\\mu}_{AI}(x)\\) when prompted by x. One can regard \\(\\hat{\\mu}_{AI}(x)\\) as an implicit simulator from a predictive distribution of a complex model (e.g. a large language model underlying generative AI) trained on massive data \\(D_{AI}\\) that is unavailable to the user and different from \\(D_n\\).\nTo conduct predictive inference, a Bayesian forecaster would typically issue a posterior predictive distribution\n\\[\n\\pi(Y_{new} | X_{new}, D_n) = \\int \\pi(Y_{new} | X_{new}, \\theta)\\pi(\\theta|D_n)d\\theta\\tag{2.1}\n\\]\nbased on the posterior distribution of \\(\\theta\\) given \\(D_n\n\\[\n\\pi(\\theta|D_n) \\propto \\pi(\\theta)\\pi(D_n | \\theta)\n\\]\nunder a postulated model \\(\\pi(D_n | \\theta)\\) and a chosen prior \\(\\pi(\\theta)\\). There are two conundrums"}, {"title": "2.1 Parametric A\u0399 Priors", "content": "While the AI model is a black box predictive machine, it implicitly defines a model and a prior if one were willing to assume that \\(\\hat{\\mu}_{AI}(\\cdot)\\) generates samples from a posterior predictive distribution (2.1) under some label distribution \\(\\pi_{AI}(Y|x, \\theta)\\), prior \\(\\pi_{AI}(\\theta)\\) and a training model \\(\\pi(D_{AI} | \\theta)\\). This argument might be justifiable from the \"prequential\" point of view [7] that focuses solely on predictive distributions (as opposed to models and priors) and argues that the quality of an inference method can truly be gauged by the quality of its forecasts. We regard AI forecasts as a potentially useful proxy for the true unobserved outcomes.\nOne hypothetical (but impossible) strategy of turning Al knowledge into priors would be to utilize \\(\\pi_{AI}(\\theta|D_{AI}) \\propto \\pi_{AI}(\\theta)\\pi(D_{AI}|\\theta)\\) as a prior \\(\\pi(\\theta)\\) for the predictive distribution \\(\\pi(Y_{new} |X_{new}, D_n)\\) based on labeled data \\(D_n\\). However, we cannot directly access the parameter posterior simulator \\(\\pi_{AI}(\\theta|D_{AI})\\) from \\(\\hat{\\mu}_{AI}(\\cdot)\\). What we can access, however, is imaginary data \\(D_m^* = \\{(Y_i^*, X_i^*)\\}_{i=1}^m\\) consisting of predictive imputations from \\(\\hat{\\mu}_{AI}(\\cdot)\\). The idea of turning such imaginary data \\(D_m^*\\) into a prior has bountiful rewards and can be approached in various different ways. We explore data augmentation strategies for parametric priors in Section 2.1.1 and for non-parametric priors in Section 2.2. These approaches should be distinguished from martingale posteriors [10] which also leverage predictive imputation for posterior computation but in a very different way. Martingale posteriors are based on"}, {"title": "2.1.1 Power AI Priors", "content": "We align with the insight by [6] that \u201cit is much easier to elicit information about the typical outcome than to attempt the extremely difficult task of eliciting prior knowledge about \\(\\theta\\)"}, {"title": "2.1.2 Expected-Posterior AI Priors", "content": "The expected-posterior AI prior along the lines of Definition 1 in [27] could be constructed as a typical power prior after margining out the imaginary data\n\\[\n\\pi_{EP}(\\theta) \\propto \\int \\prod_{i=1}^m \\pi(Y_i^* | X_i^*, \\theta)\\pi_{w}(\\theta)\\pi_{AI}(D_m^*)dD_m^*\n\\tag{2.2}\n\\]\nwhere \\(\\pi_{AI}(\\cdot)\\) consists of first generating prompts \\(X_i^*\\) (possibly using observed \\(X_i\\)'s) and labels \\(Y_i^*\\) from the posterior predictive distribution underlying the simulator \\(\\hat{\\mu}(X^*)\\) (as discussed at the beginning of Section 2.1). The posterior distribution \\(\\pi(\\theta| D_n)\\) under the prior (2.2) corresponds to a typical joint posterior under the prior \\(\\pi_{w}(\\theta)\\) after averaging out \\(D_m^*\\). Indeed, under the prior (2.2) we have\n\\[\n\\pi(\\theta| D_n) = \\int \\pi(\\theta| D_n, D_m^*)\\pi_{AI}(D_m^*)dD_m^*\n\\tag{2.3}\n\\]\nThis characterization has a practical benefit for posterior simulation from (2.3). A Markov chain \\(\\{\\theta^{(t)}\\}_{t=1}^T\\) with a stationary distribution (2.3) can be obtained by generating a joint chain \\(\\{(\\theta^{(t)}, D_m^{*(t)}\\\\}_{t=1}^T\\) by first refreshing \\(D_m^*\\) from \\(\\pi_{AI}(D_m^*)\\) at every MCMC iteration and then, given \\(D_m^*\\), generate \\(\\theta^{(t)}\\) from the joint posterior. Marginally, \\(\\theta^{(t)}\\)'s would be distributed"}, {"title": "2.1.3 Catalytic AI Priors", "content": "In catalytic priors [17], imaginary data \\(D_m^*\\) are generated from a Bayesian predictive distribution under a simple donor model trained on \\(D_n\\) for which prior elicitation was easier. The data \\(D_m^*\\) are then plugged into a likelihood representing a more complex recipient model whose parameters would be difficult to estimate using only \\(D_n\\). Formally, the catalytic version of an AI prior could be written as\n\\[\n\\pi_{CAT,m}(\\theta) \\propto \\left( \\prod_{i=1}^m \\pi(Y_i^* | X_i^*, \\theta)\\right)^{\\alpha/m} \\approx \\exp \\left\\{\\frac{\\alpha}{m} \\sum_{i=1}^m \\log \\pi(Y_i^* | X_i^*, \\theta)\\right\\}\n\\tag{2.4}\n\\]\nfor some \\(\\alpha > 0\\) which regulates the influence of the prior and where 1/m performs averaging over the contributions of single imaginary data points \\(Y_i^*\\). A similar idea could be implemented using AI predictions. Unlike catalytic priors, however, generating fresh data \\(D_m^*\\) from an AI model precludes from the double use of data \\(D_n\\). The practical implementation of Bayesian analysis with catalytic priors (2.4) would entail choosing \\(\\alpha\\) using some criterion and then simulating very many fake observations m so that the averaging in (2.4) performs satisfactory approximation to Monte Carlo integration. Indeed, as \\(m \\rightarrow \\infty\\) the prior approaches\n\\[\n\\pi_{CAT,\\infty}(\\theta) \\propto \\exp \\left\\{\\alpha \\int \\log \\pi(Y^* | X^*, \\theta)\\pi_{AI}(Y^*, X^*)d(Y^*, X^*)\\right\\}.\n\\tag{2.5}\n\\]\nThere is one important difference between (2.1.3) and the expected-posterior prior (2.2). From the Jensen's inequality \\(E\\log X \\leq \\log EX\\), the population catalytic prior with \\(\\alpha \\in \\mathbb{N}\\) provides a lower bound for (2.2) with \\(m = \\alpha\\) when \\(\\pi_{AI}(D_m^*) = \\prod_{i=1}^m \\pi_{AI}(Y_i^*, X_i^*)\\). The"}, {"title": "2.2 Non-parametric AI Priors", "content": "Instead of assuming that there exists \\(\\theta_0\\) such that the observed data \\(D_n\\) has been independently realized from \\(\\pi(Y|X,\\theta_0)\\), we adopt a non-parametric viewpoint, where the \\(D_n\\) arrives from an iid experiment involving an unknown distribution function \\(F_0\\) for \\((Y, X)\\).\nSimilarly as in [4, 24], we shift focus from \\(\\theta_0\\) to \\(F_0\\). The question of prior elicitation will be tackled by converting observable predictions from an AI model into non-parametric priors on \\(F_0\\). Suppose that the unknown parameter \\(\\theta_0\\) is a solution to the optimization problem\n\\[\n\\theta_0 (F_0) = arg \\min_\\theta \\int l(\\theta, Y, X)dF_0[(Y, X)],\n\\tag{2.6}\n\\]\nwhere \\(l(\\theta, Y, X)\\) is a loss function and \\(F_0\\) is the unknown distribution for \\((Y, X)\\). The parameter of interest is not necessarily tied to a statistical model and is defined more generally as a minimizer of a population loss under an unknown sampling distribution \\(F_0\\). This parameter may correspond to an actual parameter of a statistical model if one takes \\(l(\\theta, Y, X) = -\\log \\pi(Y | X, \\theta)\\). The sampling distribution \\(F_0\\) is unknown and we can place a Dirichlet process (DP) prior with an AI base prior as follows\n\\[\nF \\sim DP(\\alpha, F_{AI}),\n\\tag{2.7}\n\\]\nwhere \\(\\alpha > 0\\) is the usual concentration parameter and \\(F_{AI}\\) is the base measure which gives rise to simulations \\((Y_i^*, X_i^*)\\)."}, {"title": "2.2.1 AI Base Measure", "content": "Denote the density of this base distribution as \\(f_{AI}(Y^*, X^*)\\) and factorize it into\n\\[\nf_{AI}(Y^*, X^*) = f_{AI}(X^*) \\times f_{X^*}^{AI}(Y^* | X^*).\n\\]\nThe density \\(f_{AI}^X(X^*)\\) can be viewed as a distribution over prompts. For our practical illustrations, we will assume that it is based on the observed covariates, i.e. \\(f_{AI}^X(X^*) = \\sum_{i=1}^n g_i\\delta_{x_i}\\) for some (fixed or random) weights \\(g_i > 0\\) such that \\(\\sum_{i=1}^n g_i = 1\\). Given the prompt \\(X^*\\), the density \\(f_{X^*}^{AI}(Y^* | X^*)\\) is defined implicitly by the AI generator \\(\\hat{\\mu}(X^*)\\), be it ChatGPT or any other black-box predictive model. Perhaps the simplest way to construct \\(f_{X^*}^{AI}(Y^* | X^*)\\) would be an empirical distribution of this historical data, i.e. \\(f_{X^*}^{AI}(Y^* | X^*) = \\frac{1}{m}\\sum_{i=1}^m \\delta_{(y_i^*)}\\), where \\(D_m^* = \\{(Y_i^*, X_i^*)\\}_{i=1}^m\\) have been generated hierarchically from \\(X^* \\sim f^X_{AI}\\) and then \\(Y_i^* = \\hat{\\mu}(X_i^*)\\). Using the log-likelihood loss function, this strategy is closely related to the power priors discussed in Section 2.1.1 that treat the historical observations"}, {"title": "2.2.2 The Concentration Parameter a", "content": "The concentration parameter \\(\\alpha > 0\\) measures the assuredness of the prior about \\(F_{AI}\\) which can be interpreted as the effective sample size of the imaginary data \\(D_m^*\\). This can be seen from the characterization of the posterior in (2.8). While m is the actual sample size for \\(D_m^*\\), we treat it more as a truncation parameter in an approximation to the DP posterior where (similarly as for the catalytic priors in Section 2.1.3) the larger m is, the better. We choose a adaptively from out-of-sample experiments to determine the relevance of the AI non-parametric prior for prediction and to find the most suitable degree of AI prior subjectivity. Another option is to choose a in order to calibrate the coverage of posterior credible intervals in the frequentist sense. One way to do this would be via an adaptation of the general posterior calibration algorithm of [29]."}, {"title": "2.2.3 Posterior Bootstrap", "content": "The prior distribution on \\(\\theta\\) is implied by a prior distribution on F in (2.7) using the mapping (2.6) where\n\\[\n\\theta \\sim arg \\min_{\\theta'} \\int l(\\theta', Y, X)dF[(Y,X)] \\text{ for } F \\sim DP(\\alpha, F_{AI}).\n\\]\nFrom the conjugacy of the DP process, we see that having observed \\(D_n\\), the posterior on F satisfies \\(F |D_n \\sim DP(\\alpha+n, G_n)\\) where \\(G_n = \\frac{\\alpha}{\\alpha+n} F_{AI}+ \\frac{1}{\\alpha+n} \\sum_{i=1}^n \\delta_{Y_i, X_i}\\). The non-parametric posterior on \\(\\theta\\) can be then computed [11] simply by taking a functional of samples F from its posterior using\n\\[\n\\theta \\sim arg \\min_{\\theta'} \\int l(\\theta', Y, X)dF[(Y, X)] \\text{ for } F \\sim DP(\\alpha + n, G_n).\n\\tag{2.8}\n\\]"}, {"title": "3 Generative AI Illustrations", "content": "We demonstrate our approach on two classification datasets, where generative AI input could be incorporated in predictive inference for medical diagnosis or parameter inference in labeling massive galaxy images."}, {"title": "3.1 Skin Disease Prediction", "content": "We apply our methodology towards the classification of Erythemato-Squamous diseases from descriptions of clinical symptoms. Erythemato-Squamous diseases (ESDs) comprise a group of six distinct but closely overlapping skin conditions that pose significant diagnostic challenges due to their similar clinical and histopathological features. Machine learning approaches have been applied to predict the disease subtype from these clinical and histopathological features with high accuracy, additionally providing interpretable patterns [31]. This dataset has also been employed for exploring uncertainty quantification in large language model-based medical diagnosis. Kim et al. [22] used ChatGPT to diagnose ESDs from descriptions of clinical features only, applying conformal prediction techniques to aid in uncertainty quantification. Notably, ChatGPT's diagnoses from clinical symptoms only were less accurate than that of bespoke machine learning algorithms (i.e. a simple random forest model, for example), but still substantially better than random guessing.\nESDs are divided into the following six subtypes, which are the labels in this classification problem: psoriasis, seborrheic dermatitis, lichen planus, pityriasis rosea, chronic dermatitis and pityriasis rubra pilaris. There are twelve clinical features, ten of which"}, {"title": "3.1.1 Data", "content": "We analyze the dermatology data\u00b2 available from the UCI machine learning repository [19], removing histopathological features so as only to diagnose disease from clinical features. For this experiment, we split the total number of observations in the dataset (366) as follows: 20% is used as training data, treated as correctly labeled pairs. 20% is held-out to assess test accuracy. The remaining 60% is considered to be extra unlabeled data, for which the clinical symptoms are known to the practitioner but the labels are not. We let \\(D_n\\) denote the labeled training data, \\(D^{Test}_{rest}\\) the labeled testing data and denote the extra unlabeled data as \\(D_m^*\\)."}, {"title": "3.1.2 Prompting ChatGPT to Impute Diagnoses", "content": "As discussed in Section 2.2.1, the base measure \\(F_{AI}\\) for our AI prior is characterized by a probability distribution on both clinical features X and labels Y. In this case, we define such a base measure as follows: the marginal distribution of clinical features is from the empirical distribution of extra unlabeled data, that is, \\(f^X_{AI}(X^*) = \\frac{1}{m}\\sum_{i=1}^m \\delta_{x_i}(X^*)\\). Then, the conditional AI prior on the labels is given by the GPT-imputed conditional distribution on the feature X using the strategy described below.\nIn order to convert use ChatGPT to predict labels (diagnoses) from clinical features,"}, {"title": "3.1.3 Non-parametric AI Bayesian Inference", "content": "For this data, we posit a parametric model for the conditional probabilities of each label via a three-layer neural-network parameterized vector function \\(f_\\theta : \\mathcal{X} \\rightarrow \\mathcal{S}^6\\), where \\(\\mathcal{S}^6 := \\{v \\in \\mathbb{R}^6 : \\sum_{i=1}^6 v_i = 1, v_i \\geq 0 \\forall i = 1, ..., 6\\}\\) denotes the simplex on 6-elements. The architecture of the neural network is rather uncomplicated and is described below.\nThe neural network parameterizes a class of functions \\(f_\\theta : \\mathcal{X} \\rightarrow \\mathcal{S}^6\\) through the following function composition\n\\[\nf_\\theta = \\text{softmax} \\circ f_{W_3,b_3} \\circ \\sigma \\circ f_{W_2,b_2} \\circ \\sigma \\circ f_{W_1,b_1}\n\\]\nwhere \\(\\theta = (W_1, b_1, W_2, b_2, W_3, b_3)'\\), and \\(W_1 \\in \\mathbb{R}^{64 \\times 12}, b_1 \\in \\mathbb{R}^{64}, W_2 \\in \\mathbb{R}^{32 \\times 64}, b_2 \\in \\mathbb{R}^{32}, W_3 \\in \\mathbb{R}^{6 \\times 32}, b_3 \\in \\mathbb{R}^{6}\\). In addition, \\(\\sigma\\) denotes the ReLU activation function \\(\\sigma(x) = \\text{max}\\{0,x\\}\\), \\(f_{W,b}\\) denotes the affine transformation \\(f_{W,b}(x) = Wx + b\\), and softmax is defined via\n\\[\n\\text{softmax}(z)_i = \\frac{\\text{exp}(z_i)}{\\sum_{j=1}^6 \\text{exp}(z_j)}.\n\\]\nThe neural network parameters are fit using the Adam optimizer to minimize the weighted cross-entropy loss, with a learning rate of 0.001. We also employ dropout with p = 0.2 during training. The clinical symptom covariates are first preprocessed by standardizing the age feature (by subtracting its mean and dividing by the unbiased estimate of its standard deviation).\nOur inferential target is the minimizer of the induced empirical classification loss on the neural network weights \\(\\theta\\). The Posterior Bootstrap distribution \\(\\{\\theta^{(t)}\\}_{t=1}^B\\) obtained from Table 1 induces a posterior distribution on \\(f_\\theta(\\cdot)\\) and thereby also posterior predictive distribution on the label \\(Y_j\\) corresponding to test data \\(X_j \\in D^{Test}\\) for \\(1 \\leq j \\leq T\\). The"}, {"title": "3.2 Proportion of Spiral Galaxies", "content": "Prior work has collected human annotations of galaxy morphologies through the Galaxy Zoo 2 citizen science initiative [32], which contains over 1.3 million labeled images from the Sloan Digital Sky Survey. Angelopoulos et al. [1] estimate the proportion of galaxies exhibiting spiral arm features, which is useful for understanding stellar evolution and star formation. The setting is that the practitioner has access to a small number n < 1000 of human-labeled data (galaxy images pair with human annotations), and a large quantity \\(N \\approx 1.5 \\times 10^4\\) of unlabeled galaxy images. A computer vision model is leveraged to impute the labels of these data points. For the sake of our experiment, we have access to the true labels of the N data points as well, which we additionally use to estimate \\(\\theta^* \\approx 0.26\\) as the \"true mean proportion of spiral galaxies. However, we use knowledge of \\(\\theta^*\\) purely for validation, and do not use it nor the true labels of the N computer-vision imputed data points for our analysis.\nWe adapt this setting to our AI prior framework, seeking to estimate the proportion of spiral galaxies in the universe. However, rather than using the AI-generated labels on additional data to debias an estimator [1], we perform a Bayesian inference on the unknown proportion of spiral galaxies leveraging the AI-predictions to elicit our prior knowledge."}, {"title": "3.2.1 AI Priors on the Proportion of Spiral Galaxies", "content": "Suppose we have galaxy images \\(X_1, ..., X_n\\) with human annotations of their spirality \\(Y_1, ..., Y_n\\). Additionally, we have unlabeled galaxy images \\(X_1^*, ..., X_N^*\\) with imputed labels \\(Y_1^*, ..., Y_N^*\\) produced via a large computer vision model. We take the nonparametric approach in Section 2.2 and define an AI base measure \\(F_{AI}\\) by the empirical distribution on the labels \\(Y_1^*, ..., Y_N^*\\) imputed by the computer vision model. This means that we do not have an underlying continuous base measure and can do an exact algorithm without refreshing the labels for a fixed sub-sample of size m. We elicit our AI prior in turn as previously, via \\(F \\sim DP(\\alpha, F_{AI})\\) where \\(F_{AI}\\) is now finitely supported on \\(Y^*\\)'s. We still use the approximate algorithm in Table 1 using truncation \\(m = 10^5\\), resampling from the empirical distribution of the atoms that make up the AI base measure here (the set of computer vision-imputed labels)."}, {"title": "3.2.2 Nonparametric AI Inference on the Mean", "content": "Our inferential conclusions on the proportion of spiral galaxies stem from the posterior on the risk minimizer \\(\\theta(F)\\), defined via \\(\\theta(F) = arg \\min_\\theta \\int (y - \\theta) dF(y)\\). We obtain B = 1000 samples from the approximate posterior distribution of \\(\\theta(F)\\) using the exact variant of the posterior bootstrap algorithm in Table 1. We repeat this procedure 10 times each for various values of the DP concentration parameter a in the AI prior. \nThe posterior distribution on the proportion of spiral galaxies which arises from our AI prior obtains tight 90% credible intervals that concentrate around the mean. As a grows larger, the predictions from the computer vision model become more heavily incorporated."}, {"title": "3.2.3 Calibrating the Concentration Parameter", "content": "The practitioner may also consider wish to consider choosing a such that posterior credible regions are well-calibrated in a frequentist sense. In order to gain the most from the AI prior while maintaining calibration, we can consider choosing the largest a such that the credible interval stays well-calibrated. Credible intervals are constructed using the AI priors in Section 3.2.1, conditioning on n = 1000 data points. Actual coverage is calculated from the proportion of intervals containing the true proportion of spiral galaxies \\(\\theta^* \\approx 0.26\\), which in this case is taken to be the mean from the entire set of 16,743 labels available (see Section 3.2). Estimated coverage is computed by bootstrapping samples from the empirical distribution of the 1000 labeled data points, and computing the proportion of times that the mean of this bootstrapped sample lies inside the interval. This procedure is described in [29] and may be used to approximately calibrate posterior credible regions in absence of the knowledge of the true parameter. In this experiment, the largest a value at which the posterior 90% credible interval is well-calibrated in the frequentist sense occurs approximately at \\(\\alpha = 500\\). The average width of the credible interval when the AI prior has this concentration parameter value of \\(\\alpha = 500\\) is about 0.032, which is very similar to the width of the 90% confidence interval around the PPI estimator."}, {"title": "4 Discussion", "content": "This research note proposes a Bayesian alternative to prediction-powered inference framework introduced by [1] for performing valid statistical inference when an experimental dataset is augmented with predictions from an AI system. Our approach is based on prior construction based on simulations from an auxiliary black-box model. Our framework enables uncertainty quantification through non-parametric posteriors by viewing the machine learning system as a simulator from a prior on the unknown distribution function. Treating the generative black-box model as a base measure in the Dirichlet process prior DP(\\(\\alpha\\), \\(F_{AI}\\)), we achieve fully Bayesian inference about various quantities of interest (parameters associated with statistical models, parameters defined as minimizers of loss functions) using non-parametric posteriors. These posteriors give rise to posterior predictive distributions in parametric models which can be leveraged for decision making based on both AI input as well as observed data. We estimate the concentration parameter \\(\\alpha \\geq 0\\) from out-of-sample experiments to determine the inferential usefulness of AI predictions. The estimated value at \\(\\alpha = 0\\) would signify that AI predictions do not add value and one is better off proceeding without them. We find that Bayesian analysis can be meaningfully enhanced with generative AI predictions on two real examples. We found that while AI predictions should not be taken literally for decision making, they can serve as a useful proxy (prior) for the correct answer which could enhance Bayesian analysis of observed data."}, {"title": "A Experimental Details", "content": ""}, {"title": "A.1 Prompting", "content": "The exact prompt used for the AI base measure in the skin disease experiment was as follows:\nPredict the diagnosis of Eryhemato-Squamous disease in the following case,\nusing the following clinical features. The age feature simply\nrepresents the age of\nthe patient. Family history is a binary variable. Every other feature\nwas given a degree in the range of 0 to 3. Here, O indicates that\nthe feature was not present, 3 indicates the largest amount\npossible, and 1, 2 indicate the relative intermediate values.\nerythema: 2.0, scaling: 2.0, definite borders: 0.0, itching: 3.0, koebner\nphenomenon: 0.0, polygonal papules: 0.0, follicular papules: 0.0, oral\nmucosal involvement: 0.0, knee and elbow involvement: 1.0, scalp\ninvolvement: 0.0, family history: 0.0, age: 55.0\nThe possible classes are: psoriasis, seboreic dermatitis, lichen planus,\npityriasis rosea, cronic dermatitis, pityriasis rubra pilaris.\nPlease estimate the probability of each possible diagnosis for this\ncase. The following is for research purposes only. I understand\nthat a real patient must see a qualified doctor with such a\nconcern.\nFormat your answer as:\npsoriasis: (prob),\nseboreic dermatitis: (prob),\nDo your best to provide an accurate answer strictly in this format, and\ndo not include anything else in your response."}]}