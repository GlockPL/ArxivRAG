{"title": "Hierarchical Neural Constructive Solver for Real-world TSP Scenarios", "authors": ["Yong Liang Goh", "Zhiguang Cao", "Yining Ma", "Yanfei Dong", "Mohammed Haroon Dupty", "Wee Sun Lee"], "abstract": "Existing neural constructive solvers for routing problems have predominantly employed transformer architectures, conceptualizing the route construction as a set-to-sequence learning task. However, their efficacy has primarily been demonstrated on entirely random problem instances that inadequately capture real-world scenarios. In this paper, we introduce realistic Traveling Salesman Problem (TSP) scenarios relevant to industrial settings and derive the following insights: (1) The optimal next node (or city) to visit often lies within proximity to the current node, suggesting the potential benefits of biasing choices based on current locations. (2) Effectively solving the TSP requires robust tracking of unvisited nodes and warrants succinct grouping strategies. Building upon these insights, we propose integrating a learnable choice layer inspired by Hypernetworks to prioritize choices based on the current location, and a learnable approximate clustering algorithm inspired by the Expectation-Maximization algorithm to facilitate grouping the unvisited cities. Together, these two contributions form a hierarchical approach towards solving the realistic TSP by considering both immediate local neighbourhoods and learning an intermediate set of node representations. Our hierarchical approach yields superior performance compared to both classical and recent transformer models, showcasing the efficacy of the key designs.", "sections": [{"title": "1 INTRODUCTION", "content": "The Traveling Salesman Problem (TSP) is a classical combinatorial optimization problem. Simply put, the TSP asks the following: given a set of cities, what is the shortest route where a salesman can visit every city only once and return back to his starting city? While it is simple to state, the TSP is a very difficult problem known to be NP-hard. Nevertheless, the TSP is a crucial problem to study, as many parallel problems can be reduced to solving the TSP, such as chip placement [20], the study of spin glass problems in physics [17], DNA sequencing [4], and many others.\nGiven its prevalence across a multitude of domains, the TSP has been extensively researched in the community. Particularly, the main approaches can be broken down into exact methods and approximate methods. Exact methods often materialize in the form of mathematical programming. Some popular exact solvers, such as Concorde [2], are developed based on linear programming and cutting planes. Approximate methods tend to be in the form of expert heuristics. An example would be the Lin-Kernighan-Helsgaun (LKH-3) algorithm, which utilizes heuristics and local search methods to update and improve initial solutions. As their names describe, exact methods return the true optimal routes while approximate ones return solutions often within some error bound of the optimal one. As the size of the problems grows, exact methods are intractable due to the NP-hard nature of the problem.\nMore recently, the deep learning community has put much effort into establishing practical neural solvers. These typically appear in the form of deep reinforcement learning [3, 10, 15, 19, 21], which presents a label-free approach to improve the models. This is preferred over supervised learning approaches (e.g, [14, 28]) since they require large amounts of labelled data, which is often challenging to obtain given the limited scalability of exact solvers.\nIt is important to note that learning-based solvers may perform well on specific target distributions they are trained on, but often suffer from poor generalization to other arbitrary instances. This is acceptable if the target distributions reflect real-world cases. However, prior works have mostly only been trained and tested on problems derived from random synthetic distributions, which may not accurately represent real-world applications. While some learned solvers have been tested on realistic TSP instances, such as those from the TSPLIB [27], a collection of TSP instances observed in the real world, these realistic problem collections are typically too small to train on. Therefore, there is a gap in studying the performance of learning-based solvers in more realistic scenarios from the real world.\nIn this paper, we propose and study a setup that closely mirrors practical scenarios. Consider a logistic company with a large set of M fixed locations that it can deliver to. The company will do many delivery trips to these locations but for each trip, only a small subset V of the M locations, e.g., locations that placed orders for that day, need to be visited. This observation motivates us to generate realistic distributions as follows: select a set of M fixed locations from the real world to reflect real-world location distributions, and build each problem instance by randomly sampling a subset of V locations from the set of M locations.\nWe construct the locations using real-world datasets of cities from the USA, Japan, and Burma. When state-of-the-art neural solvers are trained in realistic settings, their performance may not be satisfactory. To improve the neural solvers, we focus on exploiting the nature of the node construction process. Existing neural solvers typically construct TSP tours autoregressively, solving the problem of visiting all unvisited cities starting from the current city and returning to the starting city. This suggests learning more effective and generalizable representations of the decision information regarding the current city and unvisited cities.\nSpecifically, we first observe that neural solvers often struggle to select a proper next city in the neighbourhood of the current city in our proposed realistic setup. This highlights the importance of exploiting more effective decision information about the current city. To this end, we propose to incorporate a customized hypernetwork layer [11] that leverages the embedding of the current city to modify the choice of the next city to visit.\nMoreover, to obtain an improved representation of unvisited cities, we design a hierarchical representation that divides the cities into C partitions and use an embedding to represent the unvisited cities in each of the C partitions. We perform the partitioning using a soft clustering method, inspired by the EM algorithm. Given its differentiable property of EM, we can propagate the gradient through the clustering to learn the encoder parameters effectively.\nWe showcase the effectiveness of the hypernetwork and the hierarchical representation of unvisited cities in experiments with the proposed realistic setting. We highlight the following contributions:\n\u2022 We introduce a more realistic TSP setting using real-world data to more convincingly demonstrate the effectiveness of neural TSP solvers.\n\u2022 We make the key observation that neural solvers often struggle with node selection within a small locality, and we design a hypernetwork layer to emphasize local choices.\n\u2022 We further exploit the nature of solving structured TSPs by representing the set of unvisited cities with multiple key embeddings using a differentiable soft clustering algorithm instead of conventional simplistic pooling methods."}, {"title": "2 RELATED WORK", "content": "Deep reinforcement learning forms the hallmark of training constructive neural solvers. Early works from [3] proposed to use the Pointer Network [32] based on the sequence-to-sequence architecture in [29] to solve TSP and Knapsack problems. They employ an actor-critic approach and achieved strong results on the TSP. Follow-up works from [26] further improve the performance of the Pointer Network.\nFollowing on from this, the transformer network based on attention [31] was proposed by [19] to solve the TSP, Capacited Vehicle Routing Problem (CVRP) and the Orienteering Problem (OP). Primarily, the work showed that one can train a neural solver using the REINFORCE algorithm [33] and a simple greedy rollout of the network with a lagging baseline. Since then, multiple works based on the same architecture have been proposed to improve the predictive power of such solvers further [36]. POMO [21] was introduced and observed that constructive solvers were limited by their starting nodes. Hence, to effectively explore the search space of solutions, one should use all nodes as starting nodes, effectively constructing a simple beam search. Additionally, they showed that a stable baseline can be found in the average of all solutions. Sym-NCO [15] was proposed to exploit the symmetry of TSP by introducing symmetry losses to regularize the transformer network. Recently, ELG was introduced by [10] that defined a local learnable policy based on a k-Nearest Neighbor graph. They exemplified the generalizability of the network on large CVRP instances."}, {"title": "2.2 Improvement Neural Solvers", "content": "Apart from constructive methods, another approach to solving the TSP looks at improvement solvers. This methodology is inspired by algorithms such as 2-opt, whereby the solver first starts with a complete route, and a heuristic is then used to select edges to delete or add so as to edit the solution. Such methods are measured based on how quickly they can reach a strong solution. Work such as [7] uses neural networks to learn the 2-opt heuristic for improvement, while [34] uses the transformer to select node pairs for swaps for the TSP. Ma et al. [24] then extended the transformer network to learn node and edge embeddings separately, which is then upgraded for pickup and delivery problems in [23] and flexible k-opt in [22], pushing the iterative solver's performance further."}, {"title": "2.3 Search-based techniques", "content": "The previous two approaches are based on some form of learning-based search: constructive solvers try to perform a global search by learning heuristics entirely from data, whereas iterative solvers learn to guide local search techniques instead. Besides these, there is a class of search-based techniques that involve applying search during inference. Efficient Active Search (EAS) was proposed by [12] to introduce lightweight learnable layers at inference that could be tuned to improve the predictive power of a model on test samples. Other works such as [9] showcase that one can leverage a small pre-trained network and combine it with search techniques such as Monte-Carlo Tree Search (MCTS) [5] so as to solve large-scale TSPs. The work in [6] then combined both MCTS and EAS to improve the search capabilities further. Lastly, another work [18] showcased how one could combine dynamic programming with a pre-trained neural network to scale the TSP to 10,000 nodes.\nPrevious works attempt to regularize the networks via symmetry or scale the solver to larger problems. However, they essentially are still based on transformer models trained on arbitrary distributions. Apart from ELG, these works do not consider the impact of local choices nor explore further how to represent unvisited cities better, which are critical aspects of solving the TSP in our view."}, {"title": "3 OUR APPROACH", "content": "Generally, we find that neural solvers tend to make two classes of errors in route construction compared to the optimal solution for such practical scenarios. The first class often appears as a minor error, where a poor decision is made in a local neighbourhood. This results in a sub-optimal route because a local choice is not picked first. The second class tends to appear in problems with more structure, where the agent fails to visit all reasonable nodes within a local cluster and has to backtrack to the area. This tends to give solutions that are significantly poorer than optimal.\nOur approach seeks to tackle these two errors more effectively. We propose two main architectural improvements to the base transformer model to address these issues. Firstly, we propose a learnable local choice decoder that accentuates certain choices based on the agent's current location (and hence locality). Secondly, we propose a differentiable clustering algorithm to learn a set of representations to capture and summarize the set of remaining cities. Our full approach is illustrated in Figure 4."}, {"title": "3.1 Recap: Constructive Neural Solvers", "content": "In this subsection, we review previous works in well-known constructive neural solvers such as the attention model [19] and the POMO model [21]. The problem can be defined as an instance s on a fully connected graph of n nodes, where each node represents a city. Each node \\( n_i \\) where \\( i \\in \\{1, ..., n\\} \\) has features \\( x_i \\), typically the 2D coordinate. A solution is defined as a TSP tour, and is stated as a permutation of the nodes given by \\( \\tau = (\\tau_1, ..., \\tau_n) \\), such that \\( \\tau_i \\in \\{1, ..., n\\} \\). Note that since the tour does not allow backtracking, \\( \\tau_t \\neq \\tau_{t'}, \\forall t \\neq t' \\). The formulation yields the following policy:\n\\[P_\\theta(\\tau | s) = \\prod_{t=1}^{n} P_\\theta(\\tau_t | s, \\tau_{1:t-1})\\]\nSince the model is trained via reinforcement learning, the policy's action thus refers to the selection of the next node \\( \\tau_t \\) given the current state. The entire policy \\( P_\\theta \\) is parameterized with a neural network which involves both an encoder and a decoder. The encoder is a standard transformer model represented as such:\n\\[\\hat{h}_i = LN^l(h_i^{l-1} + MHA(h_i^{l-1}, ..., h_i^{l-1}))\\]\n\\[h_i^l = LN^l(\\hat{h}_i + FF(\\hat{h}_i))\\]\nwhere \\( h_i^l \\) is the embedding of the i-th node at the l-th layer, d the dimension size of the embeddings, MHA is the standard multi-headed attention layer [31], LN is a layer normalization function, and FF is a simple feed-forward multi-layer perceptron (MLP). Each node's embeddings go through a total of L-layers before being passed into a decoder."}, {"title": "3.2 Improving local decision making with the Choice Decoder", "content": "More often than not, good selections for the TSP tend to lie within the locality of the current position. In the standard transformer architecture, the decoder attempts to capture this by using the current node's representation in a single-headed attention layer. Effectively, we can view the compatibility score as\n\\[\\phi(Q, K) = \\frac{U \\cdot TANH(\\frac{QK^T}{\\sqrt{d}})}{V_a}\\]\nGiven that we aim to focus more on the current node's vicinity and features, we propose to generate a set of attention weights based on the current embeddings. This aims to amplify or nullify the compatibility scores further by conditioning it on the current node. Hypernetworks [11] are small neural networks designed to generate a set of weights for a main network. Its goal is to serve as a form of relaxed weight sharing. This approach allows the hypernetwork to take as input some information about the problem, such as its structure, and adapt the main network's weights towards the problem. Inspired by this approach, we construct the set of attention weights using an MLP as a hypernetwork, with the input being the current node's embedding. Concretely, we modify the compatibility function as follows:\n\\[\\hat{a}_j = \\frac{U \\cdot TANH(\\frac{(Q * W_{CHOICE})K^T}{\\sqrt{d}})}{V_a}\\]\nsuch that\n\\[W_{CHOICE} = MLP(Q), W_{CHOICE} \\in \\mathbb{R}^{d \\times d}\\]\nEffectively, \\( W_{CHOICE} \\) serves as a set of learnable conditional parameters that serve to alter the compatibility scores based on current embeddings. However, implementing this as a full matrix is extremely expensive. Instead, we realize \\( W_{CHOICE} \\) as a diagonal matrix, effectively reducing the compatibility score function to\n\\[\\phi(Q, K | Q) = \\hat{a}_j = \\frac{U \\cdot TANH(\\frac{(Q * W_{CHOICE})K^T}{\\sqrt{d}})}{V_a}\\]\nwhere * is the element-wise product. Inherently, \\( W_{CHOICE} \\) now reduces to a set of learnable scalars which serve to modify the compatibility scores between Q and K. Additionally, these learnable scalars are now conditioned upon Q, the current node, since it is generated via the MLP. The complexity of the MLP also now reduces from producing an output of \\( \\mathbb{R}^{d \\times d} \\) to \\( \\mathbb{R}^{d} \\)."}, {"title": "3.3 Exploiting structure with Hierarchical Decoder", "content": "In its current state, the decoder models the TSP as a set-to-sequence function. A key aspect of the input is the contextual embedding, h(c). This embedding serves to represent the current state the model is in and is often a combination of the starting node, current node, and some global representation of the problem. For the global representation, works such as [19] and [21] use an average of all node embeddings, while others such as [13], maintain an average of all visited nodes so far. Essentially, all of these approaches attempt to capture various nuances of the TSP.\nHowever, for realistic problem settings, it is important to exploit the structure of the distribution of the cities. A single global representation would not be effective enough to capture the intricate correlations present between the cities. One notable and ubiquitous case is the presence of cluster patterns wherein certain cities are located near to each other while being distant to others. This clustering pattern, if captured within the global and contextual representation, can potentially provide the model with important clues to determine the next city to visit. Thus, for such problems, we propose to maintain a set of C representations that are able to summarize the set of unvisited cities left, instead of a simple single representation. We postulate that this is meaningful as structured problems have frequent cities in fixed areas of the map, and being able to identify if a node belongs to a certain area could be beneficial to the decision-making process.\nPrior works in other domains have shown the efficacy of cluster construction in applications such as node classification [8]. In this work, we wish to group all cities into C representations. To this end, we design the following layer inspired by the Expectation-Maximization (EM) algorithm [25]. We first briefly review the EM algorithm for the Gaussian Mixture Model (GMM). Let \\( \\theta = \\{\\pi_\\kappa, \\mu_\\kappa\\} \\) denote the set of parameters, the coefficients of Gaussians \\( \\pi \\) and its associated means \\( \\mu \\) (covariance \\( \\Sigma_k \\) is assumed to be known), \\( X = \\{x^{(i)}\\} \\) denote the set of data points, and \\( Z = \\{z^{(i)}\\} \\) denote the set of latent variables associated with the data. The maximum-likelihood objective is given by\n\\[\\log p(X | \\pi, \\mu) = \\sum_{i=1}^{N} \\log \\sum_{z^{(i)} = 1}^{K} p(x^{(i)} | z^{(n)}; \\mu) p(z^{(n)} | \\pi)\\]\nIn general, Equation 14 yields no closed-form solution. Additionally, it is non-convex, and its derivatives are expensive to compute. Since latent variable \\( z^{(i)} \\) exists for every observation and we have a sum inside a log, we look at the EM algorithm to solve this. Typically, the EM algorithm involves two steps: the E-step computes the posterior probability over z given the current parameters, and the M-step, which assumes that given that the data was generated with \\( z^{(i)} = k \\), finds the set of parameters that maximizes this. Effectively, for a standard GMM, this yields the following E-step, given an initial set of parameters 0:\n\\[\\gamma_k = p(z^{(i)} = k | x^{(i)}; \\theta_{old}) = \\frac{\\pi_k N(x^{(i)} | \\mu_k)}{\\sum_{j=1}^{K} \\pi_j N(x | \\mu_j)}\\]\nwhere \\( \\gamma_k \\) can be viewed as the responsibility of cluster k towards data point \\( x^{(i)} \\). Then, for GMMs, the following update equations can be applied in the M-step:\n\\[\\pi_k = \\frac{N_k}{N}\\]\n\\[\\mu_k = \\frac{1}{N_k} \\sum_{i=i}^{N} \\gamma_k^{(i)} x^{(i)}\\]\nwhere\n\\[N_k = \\sum_{i=i}^{N} \\gamma_k^{(i)}\\]\nEssentially, Equation 15 estimates the contribution of each Gaussian model given the current set of parameters. While Equations 16 and 17, highlight closed-form update equations for the Gaussian parameters.\nNow, suppose a TSP instance drawn from a fixed map can be represented efficiently with C latent representations. Since we are dealing with subsets of problems from the same space, these C representations can be fixed and learnable. Let \\( C \\in \\mathbb{R}^{N_c \\times d} \\) denote this set of representations, where we have \\( C = \\{C_1, C_2, ..., C_{N_c} \\} \\). We propose to learn and update these representations by considering a mixture model, where the latent variables are modelled by these latent embeddings. Similar to the EM algorithm, we produce a set of mixing coefficients using an attention layer and its attention weights. Concretely, our soft clustering algorithm estimates its mixing coefficients via the attention mechanism, and using these scores, the clusters are then updated with a weighted sum of the embeddings. This can be shown as\n\\[h_i = W_H h_i\\]\n\\[c_j = W_C c_j\\]\n\\[\\pi_{i,j} = SOFTMAX(\\frac{h_i c_j^T}{\\sqrt{d}})\\]\n\\[c_j = \\sum_i \\pi_{i,j} h_i\\]\nwhere II is the matrix containing all coefficients \\( \\pi_{i,j} \\), \\( W_H \\) and \\( W_C \\) are parameters for the attentional scores, and C is the set of learnable embeddings for the distribution. Given a single set of parameters in the attention layer, the embeddings H and C are passed through this same layer a total of B times iteratively, mimicking a \"rollout\" of a soft clustering algorithm of E-steps and M-steps within each iteration. Loosely, we can see that Equation 20 resembles a similar calculation of the E-step, wherein we use a set of parameters to estimate the coefficients instead of minimizing for the Euclidean distance in the GMM case. Equation 21 is similar to the M-step of GMMs, where we update the centers (in our case the embeddings are the latent variables) with a weighted sum of the data."}, {"title": "3.4 Training Details", "content": "Once we have the set of C embeddings, we update the representation at every step of decoding by subtracting a weighted sum of the current node's embedding; this computes the weighted sum of embeddings of unvisited cities, instead of all cities. Thus, at time step T, if the agent is current at node i, we update C via\n\\[c'_j = c_j - (\\pi_{i,j} * h_i), \\forall c_j \\in N_c\\]\nThen, we now construct a new context embedding such that\n\\[h(c) = W_{COMBINE} [h_{last}, C_1, C_2, ..., C_{N_c}] + h_{first}\\]\nwhere [] is the concatenation operation, and \\( W_{COMBINE} \\) is a simple linear layer to combine the embeddings. We keep \\( h_{first} \\) separate so as to preserve the importance of the starting node. As the decoder constructs the solutions, the C embeddings get updated along the way, maintaining a small set of unvisited cities so as to keep track of the solution."}, {"title": "4 EXPERIMENTAL SETUP", "content": "We present three different benchmarks for comparison. For all scenarios, we look at TSP-100 problems. Firstly, we generate random uniform data on a [0, 1] square and a fixed test set of 10,000 instances. This is done to show if the addition of other layers interferes with the base performance of the transformer model.\nTo generate realistic data, we sample instances from 3 different countries, available at [1] and shown in Figure 5. Namely, they are\n\u2022 USA13509 - 13,509 cities across the United States of America, each with a population >500\n\u2022 BM33708 - 33,708 cities across the country of Burma\n\u2022 JA9847- 9,847 cities across the country of Japan\nEach country is first normalized to a [0, 1] square. Then, at every training epoch, we randomly sample problems of size 100 from the map. Naturally, clusters that are denser across the country will be sampled more frequently. A test set size of 10,000 samples is also drawn and held aside for evaluation. Each test set is fully solved via Concorde [2] to get the optimal length of each tour. We define 1 epoch to be 100,000 samples, and the models are trained for 200 epochs to prevent overfitting. In totality, the model sees 20, 000, 000 different samples. Thirdly, we define a limited data setting. This mimics a typical practical problem where the company does not have unlimited access to data. We first define a small dataset of 50,000 samples for such a setting. Based on the experiment size, we sample the necessary amount of data. Likewise, the models are tested on the same test set of 10, 000 samples.\nAdditionally, to show the generality of our approach beyond the logistics domain, we include the PCB3038 dataset from TSPLib, where the goal is to find the shortest path across a circuit board layout. Here, we can view the problem as such: from all possible holes the board can have, and given a subset of these holes, what is the optimal path of traversal? Solving such problems with high degrees of accuracy leads to cost savings in manufacturing and improved yields."}, {"title": "4.2 Benchmark Models", "content": "We compare our approach to the following constructive neural solvers: POMO [21] the classical transformer that forms the basis for many follow-up works, Sym-NCO [15] a follow-up work from POMO that improves neural solvers by exploiting problem symmetry, and ELG [10] a recent work that also focuses on locality by defining a separate local policy based on its k-Nearest Neighbors. All models are trained based on the POMO shared baseline. It should be noted that in ELG, the authors introduced a different training algorithm. Since we wish to compare the efficacy of the architectural contributions, we train the ELG model using POMO. We reimplement all models and ran on the proposed dataset for our experimental results."}, {"title": "4.3 Hyperparameters", "content": "Since the neural models all share the same underlying backbone POMO transformer model, we retain the same set of hyperparameters across them to ensure the contributions are purely architectural. We utilize 6 layers of the transformer encoder and 2 layers of the transformer decoder. All models are trained for 200 epochs, with 100,000 episodes per epoch and a 1e-4 learning rate using the Adam optimizer [16]. Gradient clipping is set to [-10, 10] for all models. For ELG, we used their recommended 50-nearest neighbours. As for our approach, we set Nc = 5 embeddings and B = 5 iterations for the hierarchical approach by using a validation set of 1,000 samples for verification. Additional details for hyperparameters can be found in Appendix A.1."}, {"title": "4.4 Performance Metric", "content": "All models are measured by the optimality gap, the percentage gap between the neural model's tour length and the optimal tour length. This is given by\n\\[O = (\\frac{\\sum_{i=1}^{N} R_i}{N \\cdot \\sum_{i=1}^{N} L_i} - 1) * 100\\]\nwhere \\( L_i \\) is the tour length of test instance i computed by Concorde. Also, we perform instance augmentation, just like in POMO, which involves various translations and reflections across the x and y axes [21], as shown in Table 1."}, {"title": "5 RESULTS", "content": "In this work, we propose a more realistic approach to representing and generating Traveling Salesman Problems (TSPs) in real-world contexts. Our investigation reveals that previous state-of-the-art neural constructive solvers do not fully exploit the problem's intricacies to enhance predictive capability. To address this gap, we present a dual strategy to deal with the problem from two fronts. Firstly, we emphasize the importance of considering current agent positions, leading us to introduce a hypernetwork, which enables dynamic fine-tuning to the decision-making process based on the agent's current node position. Secondly, we recognize that realistic TSP scenarios are often structured, and therefore, improving solutions in such scenarios necessitates a deeper understanding of the structure of the set of unvisited nodes. Instead of treating all unvisited nodes uniformly, we propose a soft clustering algorithm inspired by the EM algorithm. This approach enhances the neural solver's performance by grouping nodes based on similarities, thereby increasing the likelihood of selecting nodes from the same cluster for early resolution. We illustrate the effectiveness of these methods across diverse geographical structures. Importantly, our methods are complementary and can be integrated with existing models like ELG or Sym-NCO to create more robust solutions."}]}