{"title": "CEAR: Automatic construction of a knowledge graph\nof chemical entities and roles from scientific literature", "authors": ["Stefan Langer", "Fabian Neuhaus", "Andreas N\u00fcrnberger"], "abstract": "Ontologies are formal representations of knowledge in specific domains that provide a structured\nframework for organizing and understanding complex information. Creating ontologies, however, is\na complex and time-consuming endeavor. ChEBI is a well-known ontology in the field of chemistry,\nwhich provides a comprehensive resource for defining chemical entities and their properties. However,\nit covers only a small fraction of the rapidly growing knowledge in chemistry and does not provide\nreferences to the scientific literature. To address this, we propose a methodology that involves augmenting\nexisting annotated text corpora with knowledge from Chebi and fine-tuning a large language model\n(LLM) to recognize chemical entities and their roles in scientific text. Our experiments demonstrate the\neffectiveness of our approach. By combining ontological knowledge and the language understanding\ncapabilities of LLMs, we achieve high precision and recall rates in identifying both the chemical entities\nand roles in scientific literature. Furthermore, we extract them from a set of 8,000 ChemRxiv articles,\nand apply a second LLM to create a knowledge graph (KG) of chemical entities and roles (CEAR), which\nprovides complementary information to ChEBI, and can help to extend it.", "sections": [{"title": "1. Introduction", "content": "Chemistry is a large and diverse field of research with a rapidly growing number of publications\navailable. While this is exciting and demonstrates rapid progress, the sheer volume of research\ntexts makes it increasingly difficult to keep track of all the new discoveries and developments.\nOntologies have been used to provide a structured framework for organizing this knowledge.\nHowever, manually incorporating knowledge into ontologies is a labor-intensive and time-\nconsuming task, and therefore not feasible for all available research.\nIn recent years, Large Language Models (LLMs) have demonstrated exceptional performance\nin understanding natural language, excelling in tasks such as summarization and question\nanswering. In this paper, we propose a novel approach that leverages the capabilities of these\nmodels to automatically create a knowledge graph (KG) of Chemical Entities And Roles (CEAR)\nfrom research publications and to extend existing ontological knowledge."}, {"title": "2. Related work", "content": "The SmartProSys research initiative aims to replace fossil raw materials in chemical production\nwith renewable carbon sources, thus contributing to a carbon-neutral society. The transition to\nsustainable and circular production processes requires research into novel chemical reaction\npathways that lead from renewable raw materials via energy-efficient and low-CO2 synthesis\nprocesses to green products. The task of identifying such pathways requires the collective\nchemical knowledge of the world to be searched and structured in a methodical, systematic and\ntargeted manner. This knowledge is growing rapidly: the ChemRxiv platform, launched in 2017,\nalready contains more than 20,000 research papers on chemistry. In addition, there are journals\nsuch as the International Journal of Molecular Sciences, which has published more than 20,000\nscientific articles in 2022, of which about 30-35% are in the field of biochemistry [1].\n[2] emphasizes that the first step in designing an effective knowledge representation system,\nand vocabulary, is to perform an effective ontological analysis of the field, or domain and that\nontologies enable knowledge sharing.\nChEBI is a database and ontology for chemical entities of biological interest. In its November\n2012 release, it contained nearly 30,000 fully annotated entities, all of which were added by\nexpert annotators [3]. In 2024, ChEBI contains almost 218,000 entities, of which more than\n60,000 were fully annotated by ChEBI curators. However, the content of ChEBI is still very\nlimited, when compared to data sources like PubChem with information on nearly 317 million\nsubstances and 118 million compounds\u00b9.\nKnowledge graphs, on the other hand, are a powerful tool for representing and querying\ncomplex, interrelated data. They are essentially a network of entities (nodes) and their interre-\nlations (edges). The relationship between ontologies and knowledge graphs is complementary.\nOntologies provide a well-defined, interconnected vocabulary, while knowledge graphs populate\nthis vocabulary with specific real-world data instances."}, {"title": "3. Methods", "content": "In our work, we create a KG for chemical entities and roles as defined in ChEBI. Chemical entities\nare atoms, substances, groups and molecules and are classified as such based on shared structural\nfeatures, while roles are classified based on their activities in biological or chemical systems\nor their use in applications [11]. Figure 1 outlines the method we use to create the KG: First,\nwe extract the full text from research papers and then fine-tune an LLM to identify chemical\nentities and roles. Candidate sentences containing both are collected and a different LLM is\nused to validate the relationship between the two. Finally, we de-duplicate and normalize both\nchemical entities and roles, link them to the ChEBI ontology and create the KG. The following\nsubsections explain each step in detail.\nFigure 2 shows the different types of information provided by our approach. The information\nthat is extracted from the papers has the form <chemical entity> has_Role <chemical\nRole>, together with additional information about the text location that supports this triple.\nEach text location consists of a specific paper, the page number in the paper, and the character\nposition of the sentence relative to that page number. RDF is not ideal to model these relations\nbecause it does not allow to annotate a triple with its source without clumsy workarounds (e.g.,\nreification of triples). Thus, we plan to release a KG built using RDF-star. The current RDF\nversion does not include any text locations."}, {"title": "3.1. Text extraction from research papers", "content": "Research papers are a rich source of information. They contain author names, images, tables,\ncitations, bibliographies, and more. To address the challenge of extracting the papers' full texts\nin an efficient way, we chose a very simple approach which involves using a Linux utility called\npdftotext. While it cannot identify floating objects in plain text, such as image and table\ncaptions or footers and page numbers, it can reliably extract different formats, ranging from\none-column to two-column styles.\nWe downloaded a set of 8,000 chemistry research papers from various categories of ChemRxiv\nand extracted their full text as JSON documents, including information about the page it was\nextracted from. Content-based checksums ensure that no duplicates are processed, even when\ncrawling other sources for research papers. The checksums are also used as identifiers between\nthe original PDF file and the associated JSON document."}, {"title": "3.2. Chemical entity and role recognition", "content": "Transformer-based Large Language Models (LLMs) have proven effective in understanding\nlanguage patterns and thus in Natural Language Processing (NLP) tasks such as Named-Entity-\nRecognition (NER), which we use in order to identify chemical entities and roles. Approaches\nsuch as ROBERTa or BERT use masked language modeling (MLM), where some tokens in an\ninput sequence are randomly masked and the model is trained to predict the original token [12].\nElectra models use a pre-training task called replaced token detection or token discrimination,\nwhere instead of predicting a masked token, a discriminative model is trained to predict whether\na token in the corrupted input sequence was replaced by a generator sample. We chose this\napproach because it is more sample-efficient [13], and fine-tuned a pre-trained Electra model\non three different datasets:\n\u2022 The BC5CDR dataset consists of human annotations of chemicals, diseases and their\ninteractions from 1,500 PubMed articles [14].\n\u2022 The NLM-Chem corpus contains 150 full-text articles on biomedical literature, carefully\nselected for containing chemical entities which are difficult to find for NER tools. Ten\ndomain experts annotated the chemical entities in three annotation rounds [15].\n\u2022 The CRAFT corpus contains 97 full-text open access articles from the PubMed Central\nOpen Access subset. It identifies all mentions of nearly all concepts from nine prominent\nbiomedical ontologies, including ChEBI [16].\nA fourth manually annotated dataset, EnzChemRED [17], provides chemical entities and proteins,\nas well as conversions during chemical reactions. It is highly relevant to our NER task, but\ngiven its recent availability, it has not yet been used for fine-tuning.\nThe CRAFT corpus annotates all entities according to nine different ontologies from different\nareas of interest. Chemical annotations, including chemical entities and roles are provided\nalong an extension of an older version of the ChEBI ontology. Although the NLM-Chem corpus\nand the BC5CDR dataset also annotate all chemicals in the provided full texts, and although\nBC5CDR annotates diseases, they do not include any chemical roles, such as ligand, acid, buffer,\nor catalyst. To overcome this limitation, we used a semi-supervised approach and automatically\nannotated all roles defined by their label and synonyms in ChEBI using a lexical approach. We\nignore all role strings that are shorter than four characters to avoid mislabeling identical strings\nwith different meanings (homonyms)."}, {"title": "3.3. Link Validation", "content": "We applied the fine-tuned Electra model to the extracted text of the chemistry research papers,\ncollecting all sentences, that contained at least one chemical entity and at least one chemical\nrole (Figure 3). For each sentence, we store the exact text location and the inferred chemical\nentities and roles.\nThe co-occurrence of chemical entities and roles within the same text block suggests that the\nchemical entity may have this specific role. However, this correlation alone is not sufficient to\ndraw a definitive conclusion. To address this, we use another LLM to verify the role of a chemical\nentity based on the given contextual information. LLAMA 2 is a collection of pre-trained and"}, {"title": "3.4. Knowledge graph creation", "content": "From the confirmed relationships, we group all chemical entities and roles using the labels and\nsynonyms from ChEBI. If an entity is not part of ChEBI, we use its original appearance in the\ntext. For this we only use chemical entities and roles with a character length of at least 2. For\neach pair of chemical entity and role, we count how many references to specific text locations\nexist. A higher frequency of occurrence of a relation increases our confidence in both, its correct"}, {"title": "4. Results", "content": ""}, {"title": "4.1. Chemical entity and role recognition", "content": "In section 3.2, we discussed how we used the BC5CDR corpus, the NLM-Chem corpus and the\nCRAFT corpus to fine-tune our Electra model for NER. As in [15], we counted a prediction as a\ntrue positive only if both the start and end locations of the characters of the complete entity\nexactly matched. This is a very strict definition, since the complexity of chemical entities makes\nit difficult to identify exact boundaries of entities or word tokens, for example: dipotassium\n2-alkylbenzotriazolyl bis(trifuoroborate)s, 4,7-dibromo-2-octyl-2,1,3-benzotriazole[15].\nTable 1 shows the precision, recall and f-measure when fine-tuned on only one or multiple\nof the corpora. We have included cross-corpus evaluation data, and we can see that a model\nfine-tuned on the NLM-Chem or BC5CDR corpus performs very poorly when evaluated on the\nCRAFT corpus. Similarly, when a model fine-tuned using CRAFT is evaluated on NLM-Chem,\nthe results are very poor. This indicates a lack of generalizability across datasets. Table 2 shows\nthe reason by listing the ten most frequent misclassifications. All of the text corpora were\nmanually curated to annotate all chemical entities contained in the texts. However, despite\ntheir common goal, they show discrepancies in annotation. For example, the chemical entities\n\"DNA\", \"RNA\" and \"mRNA\" are annotated in the CRAFT corpus, but not in the NLM-Chem\ncorpus, hence the false negatives. The character \"b\", that appears as a false positive when a\nmodel fine-tuned on NLM-Chem is evaluated on CRAFT, is used in genetics to describe base\npairs of DNA or RNA. Similarly, \"PBS\" is marked as a chemical entity in the NLM-chem corpus,\nbut in CRAFT it is neglected. This illustrates how, depending on the context or background of\nthe annotators, or depending on their research goals, there may be disagreement about which"}, {"title": "4.2. Link Validation and Knowledge Graph Construction", "content": "After applying the LLAMA-2 model for the validation of links between chemical entities and\nroles, and after grouping and applying the minRef hyperparameter as discussed in section 3.4,\ntwo representations of the resulting KG are available. An RDF representation and a graph"}, {"title": "5. Conclusion", "content": "In this paper, we have shown how to create a KG, which is linked to ChEBI, using the same\nvocabulary and extending it with knowledge from chemistry research papers. We see several\napplications for our approach:\nOur KG can assist in extending the ChEBI ontology by suggesting chemical entities and roles"}, {"title": "6. Acknowledgment", "content": "This work was supported by the Research Initiative \"SmartProSys: Intelligent Process Systems\nfor the Sustainable Production of Chemicals\" funded by the Ministry for Science, Energy, Climate\nProtection and the Environment of the State of Saxony-Anhalt."}]}