{"title": "Tabular Data Augmentation for Machine Learning: Progress and Prospects of Embracing Generative Al", "authors": ["LINGXI CUI", "HUAN LI", "KE CHEN", "LIDAN SHOU", "GANG CHEN"], "abstract": "Machine learning (ML) on tabular data is ubiquitous, yet obtaining abundant high-quality tabular data for model training remains a significant obstacle. Numerous works have focused on tabular data augmentation (TDA) to enhance the original table with additional data, thereby improving downstream ML tasks. Recently, there has been a growing interest in leveraging the capabilities of generative AI for TDA. Therefore, we believe it is time to provide a comprehensive review of the progress and future prospects of TDA, with a particular emphasis on the trending generative AI. Specifically, we present an architectural view of the TDA pipeline, comprising three main procedures: pre-augmentation, augmentation, and post-augmentation. Pre-augmentation encompasses preparation tasks that facilitate subsequent TDA, including error handling, table annotation, table simplification, table representation, table indexing, table navigation, schema matching, and entity matching. Augmentation systematically analyzes current TDA methods, categorized into retrieval-based methods, which retrieve external data, and generation-based methods, which generate synthetic data. We further subdivide these methods based on the granularity of the augmentation process at the row, column, cell, and table levels. Post-augmentation focuses on the datasets, evaluation and optimization aspects of TDA. We also summarize current trends and future directions for TDA, highlighting promising opportunities in the era of generative AI. In addition, the accompanying papers and related resources are continuously updated and maintained in the GitHub repository at https://github.com/SuDIS-ZJU/awesome-tabular-data-augmentation to reflect ongoing advancements in the field.", "sections": [{"title": "1 INTRODUCTION", "content": "Tabular data, such as relational tables, Web tables and CSV files, is among the most primitive and essential forms of data [11] in machine learning (ML), characterized by excellent structural properties, readability, and interpretability. A testament to its significance, more than 65% of datasets available on the Google Dataset Search platform are tabular files [6]. This prevalence underscores its critical role across a myriad of fields, such as finance [81], healthcare [41], education [68]. The growing availability of repositories containing structured or semi-structured data offers new opportunities for tabular data research and applications built upon it, particularly in the fields of ML and artificial intelligence (AI).\nHowever, acquiring substantial amounts of high-quality tabular data for ML model training remains a persistent challenge [17, 64]. This is especially demanding because each individual table is modest in size and self-contained, making the overall data collection process resource-intensive and time-consuming. According to the oft-cited [79] statistics, data scientists spend over 80% of their time on ML data preparation tasks, including data discovery and augmentation. The complexity and uneven quality of massive tabular datasets from various domains further complicate the acquisition of high-quality tabular data [15, 33]. Furthermore, in the era of large language models (LLMs), tabular data is one of the preferred data formats that LLMs consume, and existing high-quality tabular datasets may soon be exhausted [117]. Additionally, in the industrial sector where tabular data is most commonly used, the availability of data is often limited due to privacy concerns [57]. All of these factors have led to significant efforts being devoted to developing techniques that support tabular data augmentation (TDA). Through our extensive investigation, we have collected a"}, {"title": "2 PRELIMINARIES", "content": "In this section, we will start by introducing the notation related to TDA and outlining the level-based taxonomy that defines the various levels of TDA methods (i.e., row, column, cell, and table) in Section 2.1. Subsequently, we will present the TDA pipeline and offer a taxonomy of methods from a task-oriented perspective in Section 2.2. In the following sections, tasks will serve as the primary basis for categorization, with levels providing a more granular categorization criterion."}, {"title": "2.1 Notation in TDA and Level-based Taxonomy", "content": "First, we provide a formalization of tables, a prevalent data structure essential for the organization and presentation of data as follows.\nDefinition 1 (Table). A table T is an arrangement that organizes data into rows and columns, forming a grid of cells for systematic information representation. Each cell, denoted as T[i, j], is at the intersection of row i and column j, serving as the basic unit for data storage. The rows (T[i, :]) run horizontally and group data entries, while columns (T[:, j]) extend vertically, with each focusing on a specific data attribute. Additionally, metadata, such as table captions, provides contextual textual information around the table.\nAn intuitive example of a table and its primary components \u2014 columns, rows, and cells \u2014 is depicted in Fig. 1. Given a table T, we use T.R and T.A to denote the set of its rows and columns (attributes), respectively. Notably, our analysis is restricted to tables that solely manage numerical and textual data structured in rows and columns. This explicitly excludes tables that incorporate nested tables, lists, forms, images, or any other non-textual and non-numerical values within their cells. We now provide the formal definition of tabular data augmentation as follows.\nDefinition 2 (Tabular Data Augmentation, TDA). Given an original table T\u00ba and a specific ML model f() parameterized by \u0398, the task of Tabular Data Augmentation aims to expand TO"}, {"title": "3 TECHNIQUES IN PRE-AUGMENTATION", "content": "In this section, we review the techniques used in the pre-augmentation procedure, as introduced in Section 2.2. As shown in Table 5, we have selected a collection of representative TDA works and summarized the pre-augmentation tasks they involve. Most of the selected works are oriented to TDA and have been published in well-known conferences or journals with high citation counts, reflecting their significance within the field. We have also included several target tasks other than TDA (see the rightmost part of Table 5), namely table search [15] and semantics detection [105], as these often serve as intermediate steps in TDA.\nOur task-oriented approach, illustrated in Table 3, examines four pre-augmentation tasks for the single-table setting (Sections 3.1 to 3.4) and four for the multi-table setting (Sections 3.5 to 3.8). Pre-augmentation is essential for most TDA works, and the pre-augmentation tasks in Table 3 are not mutually exclusive. A TDA work may involve one or more of these eight tasks. For example, Infogather [100] (No.6 work in Table 5) employs multiple pre-augmentation tasks (table representation, table annotations, etc.) to complete its entire TDA process."}, {"title": "3.1 Error Handling", "content": "Error handling in pre-augmentation refers to the preprocessing of the dirty data in tables. Real-world tabular data often contain errors, such as mistakenly substituted proximal characters and unnecessary repetition of tokens in cell values. Generally, there are three types of errors that considered in pre-augmentation, missing values [14, 114], misspellings [30, 42], and numerical outliers [22]. When generating table representations based on token embedding with such errors,"}, {"title": "3.2 Table Annotation", "content": "Table annotation involves inferring metadata information about a table, such as column types and the relationship between columns [87]. This task helps recover the semantic information within a table and is particularly useful for table augmentation by assessing the similarity between tables. Typically, metadata for tables is unreliable or incomplete due to inappropriate data sharing methods [33]. Even when metadata is available, tables from a wide range of sources can have incompatible metadata with different naming conventions and terminologies. Consequently, table annotation is crucial for retrieving syntactically and semantically relevant tables to augment the original table. These approaches are divided into the three following categories.\nOntology-based table annotation. In earlier research, ontologies were frequently used for annotating table elements. For example, as illustrated in Fig. 4 (a), Limaye et al. [60] develop a classic table discovery system that utilizes an ontology for table annotation at multiple levels. This includes cell-level annotation with ontology entities (e.g., labeling the cell \u201cmechanical ape!\u201d as a song name), column-level annotation with ontology types (e.g., identifying the column header \u201cTitle\u201d as \u201cSong\u201d), and pairwise column annotation with ontology relationships (e.g., annotating the relationship"}, {"title": "3.3 Table Simplification", "content": "Table simplification involves streamlining a table down to its essential elements, which can be addressed from both the content and semantic perspectives. From the table content perspective, this procedure, known as table sampling, involves selecting portions of the table to retain as much information as possible. This is particularly useful for fitting data into limited token lengths for language models. From the table semantics perspective, the procedure, referred to as table summarization, entails identifying the main topic or theme of the table to better understand its meaning. Accurate summarization helps in comparing tables for similarity and ensures that any added rows and columns remain consistent with the table's original theme. These two different perspectives are introduced as follows.\nTable sampling selectively choose table content to preserve the original information as much as possible. An early work [8] directly selects the top-K samples for each column as input. AutoFeature [64] and ARDA [22] adopts the stratified sampling method that divides the samples into several subsets and randomly selects samples from each subset. Deepjoin[30] adopts a frequency-based approach that samples the most frequent cell values for each column. Meanwhile, Starmie [34] and AUTOTUS [42] sample rows based on an importance score derived from the cell-level TF-IDF score for each row.\nTable summarization aims to extract semantic themes or topics within tables. For example, Zhang et al. [105] incorporate a topic-aware prediction module into their framework SATO, responsible for summarizing table semantics. In particular, this module produces a topic vector from the values across the entire table, representing the global context of that table. SATO's ablation experiments show that considering a table's global context improves table understanding and mitigates ambiguities. For web tables, there are often pre-existing table metadata, such as table captions that summarize the table's contents [111]. In this case, various works [28, 40, 71, 89, 100, 110] directly leverage these metadata by converting them into vectors and concatenating them with the table's representation."}, {"title": "3.4 Table Representation", "content": "Table representation involves converting the table elements such as rows, columns, and cells into a latent vector space. This transformation prepares the table for robust use in subsequent TDA"}, {"title": "3.5 Table Indexing", "content": "Table indexing involves assigning a unique identifier (index value) to table elements, allowing for quick and efficient lookup and retrieval based on their index values. Many retrieval-based TDA methods use indexes to enhance efficiency and scalability, particularly when dealing with large-scale table pools with millions of tables. Researchers have utilized various types of indexes, such as the inverted index [3, 29, 32, 49, 100, 109, 118], Locality Sensitive Hashing (LSH) index [9, 15, 34, 75, 119], and graph index such as Hierarchical Navigable Small World (HNSW) [30, 34, 69]."}, {"title": "3.6 Table Navigation", "content": "Table navigation involves establishing a navigational framework over a table pool. Essentially, it refers to organizing the table pool in a way that highlights connections between similar tables, such as through edges in a graph or by clustering them together. With table navigation, the subsequent TDA can retrieve relevant data for augmentation more easily and efficiently. Existing works typically employ cluster structures [16, 50], hierarchical structures [77], or linkage graphs [15, 73, 74] to manage tables in table pools."}, {"title": "3.7 Schema Matching", "content": "Schema matching involves evaluating the relatedness between two table columns. In this context, the set of column headers is typically referred to as the table schema [111]. Schema matching methods are frequently adopted in retrieval-based TDA for identifying and fetching those related columns and tables to expand the features in ML models. Due to the varied data types within tables, schema matching methods are categorized into textual matching, numerical matching, and metadata matching.\nTextual matching is the most commonly used schema matching technique because textual columns usually contain more information than numerical ones. Below is a concise overview of some common textual matching methods.\n\u2022 Value overlap [9, 25, 34, 75, 91, 100]: If there is a significant overlap in the value sets of two columns, then the columns are considered related.\n\u2022 Semantic overlap [25, 27, 49, 59, 75]: When leveraging table annotations (see Section 3.2) to derive labels describing column semantics, two columns are considered a match if there is a substantial overlap between their respective labels.\n\u2022 Embedding similarity [9, 25, 29, 30, 49, 59, 75]: Related columns are identified by computing the similarity of their corresponding embeddings in vector space.\nNumerical matching is concerned with numerical columns. These methods typically evaluate the value distribution [9, 84] to derive insight from numerical data. For instance, D\u00b3L [9] utilizes the Kolmogorov-Smirnov statistic to decide whether two numerical columns come from the same domain distribution and thus can be matched. Santos et al. [84] propose the Quadrant Count Ratio (QCR) hashing scheme. This method divides the numerical values of two columns into four"}, {"title": "3.8 Entity Matching", "content": "Entity matching involves identifying connections between entities in different tables, facilitating the localization of relevant entities and tables for retrieval-based TDA. These methods are particularly relevant in the context of horizontal tabular tables, where entities are typically represented as rows and their attributes are in columns. Based on the data source to which the entities are matched, the methods are categorized into KB-referenced entity matching and DB-referenced entity matching.\nKB-referenced entity matching maps table entities to their referenced entity in a knowledge base (KB) [7], aiming to enhance the semantic understanding of tables. Essentially, if two table entities are related to the same KB entity, the likelihood of these two table entities being related is high. For example, Sarma et al. [27] link table entities to KB entities to acquire weighted label sets for representing table entities. However, not all table elements can be mapped to predefined types and relationships in the referenced KB. To address this, TabEL [7] proposes an alternative way to weaken the strict mapping, using soft constraints based on graphical model to encode a higher preference for sets of related entities.\nDB-referenced entity matching determines whether entities and their corresponding properties from table pools (or databases) refer to the same real-world object as the entities in the original table. Christophides et al. [23] outline a general framework for this task, comprising two main components: (1) similarity metrics, which compare entity descriptions and (2) blocking techniques, which group tables in the table pool that are approximately similar for enhanced efficiency of this process. More recent efforts have begun to use iterative approaches, where previously discovered matching entities serve as input for computing similarities between further tables in the table pool [18].\nHybrid entity matching combines both KB- and DB-referenced approaches to obtain a wider range of information sources. For example, Entitables [109] identifies candidate entities from both sources. Entities in KB that share categories or types with the original table entities are considered good candidates. Similarly, entities in DB tables that contain the original table entities or have related captions to the original table are also considered candidates. Table2Vec [108] enhances Entitables by incorporating word embeddings for table entities. CellAutoComplete [110] further improves Entitables by carefully designing features that combine evidence from multiple sources"}, {"title": "3.9 Scenarios for Pre-augmentation Techniques", "content": "This section empirically summarizes the specific pre-augmentation tasks used in different TDA scenarios, as depicted in Fig. 7. The four single-table-setting pre-augmentation tasks apply to both retrieval and generation-based TDA, while the multi-table-setting tasks are only suitable for retrieval-based methods, which require an external table pool to handle multi-table relationships.\nRetrieval-based TDA operates on a table pool often possessing large-scale data, thus leading to issues such as inconsistent formatting and dynamic data. Common pre-augmentation methods in these scenarios include: (1) table simplification for reducing table information; (2) table indexing and table navigation for fast retrieval; (3) schema matching and entity matching for addressing inconsistent formatting; and (4) table indexing and table navigation for managing dynamic and large-scale table pools.\nGeneration-based TDA using a single original table may suffer from issues in data-scarce scenarios. In such scenarios, pre-augmentation techniques like table annotation (providing additional information or labels) and table summarization (extracting key information) are necessary. Furthermore, in privacy-preserving scenarios, generating synthetic data often benefits from table sampling, which involves using only partial data. Note that both table summarization and table sampling are part of table simplification, as discussed in Section 3.3.\nMeanwhile, both retrieval- and generation-based TDA approaches face some common challenges, such as low-quality and imbalanced tables. In low-quality scenarios (e.g., tables with null or erroneous values), common preaugmentation techniques include error handling and table annotation (to annotate column when column names are missing). In imbalanced scenarios, table sampling within"}, {"title": "4 TECHNIQUES IN TABULAR DATA AUGMENTATION", "content": "This section will delve into the current state-of-the-art techniques for tabular data augmentation (TDA). As outlined in Table 4, we first classify TDA tasks into two primary categories: retrieval-based TDA (see Section 4.1) and generation-based TDA (see Section 4.2). Within these two categories, the approaches can be further divided into different levels: adding rows [78, 109] or columns [30, 62], augmenting individual cells [110], and extending the original table with both rows and columns [50]. Thus, for each category, we will discuss the corresponding table augmentation work at the row, column, cell, or table level. Fig. 8 provides a concise overview of the TDA works discussed in this section, along with their detailed taxonomy."}, {"title": "4.1 Retrieval-based TDA", "content": "By retrieval-based, we refer to the process of enhancing the original table (query table TO) with realistic data sourced from table pools T = {T;}. One important difference between augmenting tabular data and augmenting other data modalities lies in the availability of existing data resources (such as databases and data warehouses), which provide opportunities for discovering fresh, realistic data. In contrast, other data modalities (such as images) primarily rely on transforming the original data to generate new data that has not been seen before [17]. Retrieval-based TDA tasks are further divided into Entity Augmentation (EAR) at the row level, Scheme Augmentation (sa\u20a8) at the column level, Cell Completion (cc) at the cell level, and Table Integration (TIR) at the table level. They will be introduced as follows."}, {"title": "4.2 Generation-based TDA", "content": "Generation-based TDA refers to the augmentation of tabular data through the generation of synthetic data. Unlike retrieval-based methods, generation-based methods do not require external data sources and are often built upon generative models. Generation-based TDA tasks can be further categorized into the following sub-tasks: Record Generation (RG\u00ba) at the row level, Feature Construction (Fc\u00ba) at the column level, Cell Imputation (cr\u00ba) at the cell level, and Table Synthesis (Ts) at the table level. These generation-based TDA tasks will be introduced and discussed in more detail in the following sections."}, {"title": "4.3 Retrieval vs. Generation in TDA", "content": "In this section, we summarize and analyze the aforementioned TDA techniques from the perspective of comparing the retrieval-based approaches and generation-based approaches. First, using the proposed level-based taxonomy, we will distinguish from the task objectives and methodologies of these two approaches at different levels of granularity in Section 4.3.1. Then, we will provide a general overview of the pros and cons of retrieval-based approaches and generation-based approaches in Section 4.3.2, enabling researchers to choose the approach that best matches their tasks and requirements."}, {"title": "5 TECHNIQUES IN POST-AUGMENTATION", "content": "In this section, we mainly focus on three crucial aspects of post-augmentation: publicly available datasets used for TDA and its assessment (see Section 5.1), policies for evaluating the performance of the augmentation methods (see Section 5.2), and strategies for further optimizing the augmentation module (Section 5.3)."}, {"title": "5.1 TDA Datasets", "content": "This section delves into the classic datasets commonly used in TDA work, aiming to assist newcomers to the field. We only consider datasets that have been utilized in multiple TDA works, as these are likely to serve as strong benchmarks for the community. Key characteristics of each dataset are summarized in Table 7. These datasets can be broadly categorized into two main groups: retrieval-based TDA datasets and generation-based TDA datasets. The main difference between these categories lies in the input data requirements for the respective TDA approaches. Retrieval-based TDA necessitates the collection of additional external tables along with the original table, whereas generation-based TDA only requires the original table as input. Nevertheless, training a generative model for TDA might require a substantial quantity of tabular data. Yet, from a post-augmentation viewpoint, the extensive data used for training is not taken into account here.\nRetrieval-based TDA datasets usually consist of a table pool with hundreds to thousands of tables. The earliest examples, Web_Manual and Wiki_Link, originate from the same study [60]. In the Web_Manual dataset, the researchers use Wikipedia tables as their queries and retrieve 371 Web tables to serve as the target corpus. These Web tables are then manually annotated with entities, types, and inter-column relationships. In contrast, the Wiki_Link dataset is designed for larger-scale use without extensive human annotation. It is created by selecting Wikipedia tables where at least 90% of the cell values were internally linked to entities in Wikipedia. While this automated approach leads to a larger dataset, the annotations are limited to only entity information, without the more detailed and accurate annotations found in Web_Manual. Because of the trade-offs between dataset size and annotation quality, both Web_Manual and Wiki_Link are less frequently used in recent TDA research. Nargesian et al. [75] focus on table union search, an immediate step before entity"}, {"title": "5.2 Evaluation Polices", "content": "We summarize the common evaluation policies for TDA works. These polices can be categorized into two main groups based on the involvement of models: original-table-based evaluation and model-based evaluation. Many studies [19, 78] have utilized both evaluation methods simultaneously.\nOriginal-table-based evaluation refers to evaluating the augmented table by comparing it to the groundtruth, which is typically the original table or its derivatives. For example, several works [108, 109] start from a base table and derive a subtable from it to serve as the original table TO, while the entities or columns outside this subtable are used as the ground truth. This method can efficiently construct the ground truth, but the range of truth values is rather limited, and there may be data related to the base table in the table pool that are not present in the base table (e.g., the base table about IT companies in one country with a table in the table pool about another country). Several works [19, 78] calculate the cumulative distribution functions (CDFs) of the augmented and original tables to compare their statistic similarity. While this method is simple and effective, it only evaluates statistical distribution information and cannot capture more complex details, such as relationships between columns (e.g., the connection between \"position\" and \"salary\").\nModel-based evaluation refers to feeding the augmented table alongside other baseline tables to a specific ML model and then evaluating the model's performance. These baseline tables generally include three primary datasets: (1) None [16, 19, 34, 39, 59, 64, 78, 114] refers to the original dataset without any augmentation. For example, ITS-GAN [78] feeds the augmented and original table to a specific classification model that performs a grid search over RandomForest, AdaBoost, and GradientBoosting, then comparing the corresponding classification results. (2) Random [16, 64] refers to the original dataset augmented with randomly selected candidates. For instance, a schema augmentation work AutoFeature treats features in a table pool as independent entities and randomly selects a predefined number of features to augment the original table as the Random baseline. (3) All [16, 64, 114] refers to the original dataset augmented with all possible candidates. For example, Leva involves a ALL baseline that joins the original table with as many tables as possible. In general, None baseline is suitable for both retrieval- and generation-based TDA while the other two are suitable only for retrieval-based TDA."}, {"title": "5.3 Optimization Strategies", "content": "Optimization strategies aim to further refine the augmented results based on the performance of specific downstream ML models. These techniques can be categorized into two main types: iteration-based and reinforcement-learning-based.\nIteration-based optimization involves a simple and direct method of using feedback from the downstream ML model to determine whether adding a candidate augmentation enhances the performance of the task. For instance, Chepurko et al. [22] devise the random injection feature selection (RIFS) algorithm, which compares model performance using candidate features against deliberately constructed random features as a baseline. The objective is to identify and eliminate irrelevant features, finding a subset of features that contain signals relevant to the downstream ML task. Their subsequent work ARDA [22] is an automated system that searches and joins data with the input table end-to-end. Similarly, Leva [114] leverages the supervision signal from the downstream ML task to filter out unnecessary information. Leva uses a graph to capture information from the entire database, including both useful and potentially spurious relationships. During training, the downstream ML model will automatically focus on using the valuable information while ignoring or downweighting the non-useful parts. More recently, FeatNavigator [59] assesses the actual utility gain of candidate features by running ML model on the original and augmented tables; it then iteratively selects features based on their utility gain and the feasibility of the join path.\nReinforcement-learning-based optimization employs reinforcement learning (RL) to explore the features that improve the performance of the ML model. For example, Liu et al. [65] propose an RL-based automatic data search system that retrieves fresh training data from table pools and interacts with the downstream ML model. In this RL-based framework, each training data point and its corresponding influence score, calculated by the \u201cEnvironment\u201d, serve as the \u201cState\u201d. Given the \"State\", the \"Agent\u201d composed of a Search-Policy selects the optimal \u201cAction\u201d (a set of training data points retrieved from the table pool), and feeds them back into the \u201cEnvironment\u201d. AutoFeature [64] makes further improvement by not only exploring features that boost performance but also utilizing rarely selected ones to avoid local optima. Chai et al. [16] further extend AutoFeature by broadening the scope of table pools, such as enterprise data warehouses, online repositories, and data markets."}, {"title": "6 TRENDS AND OPPORTUNITIES", "content": "This section examines the current landscape and future prospects of TDA techniques. We first explore emerging trends shaping the field (Section 6.1), followed by a discussion of promising"}, {"title": "6.1 Major Trends in TDA Development", "content": "Based on our review of numerous research articles and our three-step pipeline, we have identified three significant trends in current TDA work:\nT1. Enhanced Table Representation. In the pre-augmentation phase, researchers are increasingly employing more advanced table representations to better capture both structural and semantic details within tables;\nT2. Confluence of Retrieval and Generation. In the augmentation phase, retrieval- and generation-based methods offer distinct advantages and disadvantages. A fruitful path forward may lie in the integration of these two methodologies;\nT3. Automated TDA. Looking at the entire TDA pipeline, a promising future direction is the creation of end-to-end automated TDA systems that can efficiently manage the entire TDA process. We proceed to elaborate on each of these trends.\nT1. Enhanced Table Representation. The representation of tables is crucial for effective TDA. By accurately capturing content, semantic, and structural information in table representation, downstream augmentation processes can achieve better outcomes. Accordingly, there is a clear trend in TDA towards more complex and sophisticated table representations. Recent TDA research [28, 71] includes diverse information such as table context and metadata, unlike earlier work [9, 75] that focused solely on table content. Additionally, newer TDA approaches [67, 114] utilize graph structures to capture relational information within tables more effectively, encoding these structures for improved table representation. Notably, many of the latest TDA techniques, both retrieval-based methods [34, 42] and generation-based methods, utilize [90] generative AI (e.g., PLMs) to generate robust table representations, leveraging their semantic understanding and generalization capabilities. While generative Al models have shown promise in tabular data representation, there remains ample opportunity for further development, especially compared to advancements in NLP and CV. In conclusion, the move towards more sophisticated and comprehensive table representations is a key trend driving progress in TDA research.\nT2. Confluence of Retrieval and Generation. As discussed in Section 4.3, retrieval-based and generation-based TDA have their own pros and cons. Retrieval-based methods incorporate external data sources for better interpretability but struggle with efficiency and scalability as data increases. Generation-based methods do not use external data, thus lacking interpretability and potentially leading to model hallucination. Given the trade-offs between these two approaches, combining their strengths while mitigating their weaknesses should be the future direction for TDA research. This aligns with the prevalent use of RAG models in the field of NLP, where the benefits of both retrieval- and generation-based techniques are harnessed. By blending these complementary methodologies, we can work towards more robust, efficient, and interpretable TDA solutions that can meet the evolving needs of diverse applications and domains.\nT3. Automated TDA. A notable trend in TDA is the move towards automating the entire process, creating end-to-end platforms that integrate various operators. For example, Chepurko et al. [22] propose ARDA, an end-to-end system that integrates multiple operators (e.g., imputation, hyperparameters optimization, feature selection, etc.) for automatic schema augmentation. Similarly, Hyperimpute [45] automates cell imputation by proposing an AutoML framework that utilize search algorithms to automatically select candidate ML models. Despite these advancements, current solutions often focus on single subtasks of TDA, leaving room for further exploration and development. An area for improvement is to consider the TDA pipeline as a whole, integrating various"}, {"title": "6.2 Emerging Opportunities for TDA", "content": "As we navigate the era of big data and the trends towards generative AI and autoML, we observe that obtaining high-quality data from massive amounts of data to facilitate generate AI is imperative. TDA is an important sub task of data quality and there is still a long way to go. Firstly, from a data perspective, the quantity and complexity of tabular data have significantly increased. Tables now typically have multiple patterns [115] and contain millions of samples [33], posing new challenges to TDA work. Secondly, from a model perspective, ML models, especially generative AI, have always faced interpretability issues and potential of privacy leakage. Below, we will elaborate on these key opportunities for further advancements in this field.\nO1. Multimodal TDA. Current TDA works often assume that tables contain only textual and numerical values. However, the reality is that modern tables often encompass a broader range of modalities, such as images [115]. Handling these multimodal tables presents unique challenges that current table processing techniques may not adequately address. The representation and indexing of such heterogeneous tables, for instance, may require fundamentally different approaches compared to traditional text-based and numerical tables. Additionally, user needs might be expressed in modalities other than the tabular data itself [61, 104]. For instance, a user might use natural language to request the oversampling of a minor class. Addressing these multimodal user inputs and aligning them with TDA operations is another key challenge to tackle.\nO2. Efficiency and Scalability. Another key challenge for TDA is the issue of efficiency and scalability. Retrieval-based TDA approaches often involve similarity comparisons at the table pool level, which can encompass millions of tables or more. Despite that, most existing methods [29, 49, 118] are exact algorithms with a worst-case time complexity that is linear in relation to the product of the query column size and the table repository size, raising concerns about their scalability. This makes it a crucial research direction to explore. Meanwhile, the table itself may contain tens of thousands of records10. Moreover, both retrieval- and generation-based TDA methods are embracing the large-scale generative AI models such as PLMs and LLMs. The computational and memory requirements of training, fine-tuning, and deploying these models can hinder the efficiency and scalability of TDA techniques in practice. Addressing the scalability challenges associated with large-scale generative AI models in TDA is another crucial area of research. Potential solutions may include the development of more efficient model architectures the exploration of model compression [107] and distillation techniques [94].\nO3. Domain-specific Tasks. Another promising direction for TDA research is the exploration of domain-specific applications. Domain-specific data often exhibit strong professionalism and have some unique characteristics [85]. For instance, medical data typically possesses specialized terminology and intricate data distributions that differ from more general tabular data. Developing TDA techniques tailored to these domain-specific characteristics could result in more effective and domain-friendly TDA strategies. This might involve incorporating domain knowledge, such as expertise from professionals [57], knowledge base [2] and knowledge graphs [1], and utilizing"}, {"title": "7 CONCLUSION", "content": "This survey presents a thorough investigation of tabular data augmentation (TDA) for ML, with a particular emphasis on the recent advancements in leveraging prevalent generative AI models. Our work meticulously outlines the essential steps involved in TDA by constructing an end-to-end pipeline encompassing three critical procedures: (1) pre-augmentation, where we summarize and analyze the commonly used preparation techniques for TDA; (2) augmentation, where we systematically compare current TDA techniques, including both retrieval-based and generation-based approaches; and (3) post-augmentation, where we delve into the evaluation and optimization processes following TDA. Additionally, we provide a comprehensive analysis of the pros and cons of current methodologies and outline future trends and opportunities for TDA.\nThe era of generative AI heralds a transformational phase for TDA. ML on tabular data is ubiquitous and demands a substantial amount of high-quality data a requirement that generative AI can significantly enhance. Despite the distinct characteristics of tabular data, generative AI models have predominantly been applied to fields like computer vision and natural language"}]}