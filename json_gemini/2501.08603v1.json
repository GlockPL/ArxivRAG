{"title": "Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based Automatic Heuristic Design", "authors": ["Zhi Zheng", "Zhuoliang Xie", "Zhenkun Wang", "Bryan Hooi"], "abstract": "Handcrafting heuristics for solving complex planning tasks (e.g., NP-hard combinatorial optimization (CO) problems) is a common practice but requires extensive domain knowledge. Recently, Large Language Model (LLM)-based automatic heuristics design (AHD) methods have shown promise in generating high-quality heuristics without manual intervention. Existing LLM-based AHD methods employ a population to maintain a fixed number of top-performing LLM-generated heuristics and introduce evolutionary computation (EC) to enhance the population iteratively. However, the population-based procedure brings greedy properties, often resulting in convergence to local optima. Instead, to more comprehensively explore the space of heuristics, we propose using Monte Carlo Tree Search (MCTS) for LLM-based heuristic evolution while preserving all LLM-generated heuristics in a tree structure. With a novel thought-alignment process and an exploration-decay technique, the proposed MCTS-AHD method delivers significantly higher-quality heuristics on various complex tasks. Our code is available at https://github.com/zz1358m/MCTS-AHD-master.", "sections": [{"title": "1. Introduction", "content": "Manually designed heuristics are promising in addressing complex planning and combinatorial optimization (CO) tasks (Desale et al., 2015). They are widely applied for various real-world applications, including traffic control (He et al., 2011), job scheduling (Rajendran, 1993), and robotics (Tan et al., 2021). However, manually designed heuristics often contain complex workflows and sophisticated parameter settings, whose design is labor-intensive and necessitates extensive task-specific expert knowledge. To achieve easier heuristic design across various tasks, the concept of Automatic Heuristic Design (AHD) (Burke et al., 2013) (also known as Hyper-Heuristics (Ye et al., 2024a)) has attracted extensive attention. AHD aims to find the best-performing heuristic algorithm among valid ones. Genetic Programming (GP) (Langdon & Poli, 2013) is generally adopted for AHD, with GP-based AHD methods introducing a series of mutation operators to gradually update heuristic algorithms (Duflo et al., 2019; Zhao et al., 2023). Nevertheless, the effectiveness of GP-based methods still relies on human definitions of permissible operators (Liu et al., 2024b), which poses additional implementation difficulties.\nIn recent years, large language models (LLMs) have demonstrated remarkable effectiveness in various fields (Hadi et al., 2023; 2024; Naveed et al., 2023). Leveraging their superb"}, {"title": "2. Preliminary", "content": ""}, {"title": "2.1. Definition: AHD & LLM-based AHD", "content": "AHD: For a given task P (e.g., CO problems), AHD methods search for the best-performing heuristic h* within a heuristic space H as follows:\n$h^* = \\arg \\max_{h \\in H} g(h)$.\n(1)\nThe heuristic space H contains all feasible heuristics for tasks P. In solving a task P, executing a heuristic h\u2208 H projects the distribution of task inputs (i.e., instances) Ip into a set of solutions Sp, i.e., h : Ip \u2192 Sp. For example, heuristics for an NP-hard CO task, Traveling Salesman Problem (TSP), project city coordinates (TSP instances) to travel tours (solutions). The function g() is a performance function for heuristics g: H \u2192 R. For a CO task P minimizing an objective function f : Sp\u2192 R, the performance function g of AHD is calculated from the expectation of the objective function values for solutions in Sp as follows:\n$g(h) = \\mathbb{E}_{ins \\in I_P} [\\mathbb{E}_{s \\in h(ins)} [-f(s)]]$.\n(2)\nwhere s \u2208 h(ins) represents a feasible CO solution by running a heuristic h for an instance ins \u2208 Ip. In practice, we can estimate g(h) by running h on a task-specific evaluation dataset D (Zhao et al., 2023). Heuristics in H belong to a wide range of general frameworks. So to concentrate the evaluation budgets on key parts, AHD methods tend to predefine a general framework and only design a key heuristic function with specified inputs and outputs within the predefined given general framework. For example, heuristics for solving TSP under the step-by-step construction framework will build the TSP tour one city after another. AHD methods within this framework will design a key heuristic function to choose the next city based on a partial tour of the city visited before. For simplicity of representation, we still denote the function to be designed as h.\nLLM-based AHD: LLM-based AHD introduces LLMs into the search process for the optimal heuristic function h* within pre-defined general frameworks. Existing LLM-based AHD methods (Liu et al., 2024b; Ye et al., 2024a) maintain a population of M heuristic functions {h1,..., hm} and employ EC to iteratively update the population. The mutation or crossover operators in EC for heuristic generation are prompted LLMs. Newly generated heuristic functions will be evaluated on an evaluation dataset D and only algorithms (with performance function g(h)) that"}, {"title": "2.2. Monte Carlo Tree Search", "content": "Monte Carlo Tree Search (MCTS) (\u015awiechowski et al., 2023) is a decision-making algorithm widely used in games (Silver et al., 2016) and complex decision-making tasks (Fu et al., 2021). Recent studies also verify the power of MCTS to enhance the multi-hop reasoning ability of LLMs (Feng et al., 2023). Each node ne in the MCTS tree represents a decision state, and MCTS will recurrently develop the most potential state as judged by a UCT algorithm (Kocsis & Szepesv\u00e1ri, 2006). Each MCTS node ne records a quality value Q(nc) and a visit count N(nc). Starting from an initial root node nr, MCTS gradually builds the MCTS tree to explore the entire decision state space. Each round of MCTS consists of four stages:\nSelection: The selection stage identifies the most potential MCTS tree node for subsequent node expansions. From the root node nr, the selection stage iteratively selects the child node with the largest UCT value until reaching a leaf node. For the current node ne, the UCT values for its child nodes c\u2208 Children(nc) are calculated as follows:\n$UCT(c) = (\\frac{Q(c)}{Q(c)} + \\lambda * \\sqrt{\\frac{ln(N(n_c) + 1)}{N(c)}}).$\n(3)\nExpansion: The expansion stage obtains multiple child nodes from the current node ne by sampling several actions from the decision state of ne among all possible options."}, {"title": "3. MCTS-AHD", "content": "Population-based LLM-based AHD faces challenges in escaping local optima and exploring complex heuristic spaces. To comprehensively explore the heuristic space, this paper proposes a novel method MCTS-AHD. It retains all LLM-generated heuristic functions in an MCTS tree and employs MCTS with the progressive widening technique instead of population-based EC for heuristic evolution. The MCTS root node n, is a meaningless virtual node, and each of the other nodes represents an executable Python code implementation of a heuristic function h\u2208 H and its linguistic description. For MCTS expansion, MCTS-AHD prompts LLMs in several ways (e.g., mutation, crossover, and reasoning) to simulate operators on heuristic functions. Moreover, to enhance the exploration of the heuristic space H in the early stages of MCTS and ensure convergence in the later stages, MCTS-AHD presents an exploration-decay technique to linearly decay the exploration factor \u03bb in UCT."}, {"title": "3.1. LLM-based actions in MCTS-AHD", "content": "In employing LLMs to generate new heuristics from existing ones (Liu et al., 2024b), LLM-based AHD methods present several efficient prompt strategies (e.g., heuristic mutation and crossover). Unlike population data structures, the MCTS tree in MCTS-AHD can record the relationships among all the generated heuristics. Leveraging this advantage, as shown in Figure 2, with different prompt strategies, MCTS-AHD presents a novel tree-structure-specific set of actions for LLM-based heuristic evolution, including il, el, e2, m1, m2, and s1. Detailed prompts for these actions are provided in Appendix E.1. As a commonality, all prompts contain descriptions of the task P, the pre-defined general framework, the inputs and outputs of the key heuristic function, and their meanings. Prompts for actions except action il also contain samples of existing heuristic functions. For each action, LLMs are supposed to output the Python code of a heuristic function and its linguistic description.\nInitial Action il: As an action for initialization, the action il aims to directly generate a heuristic function and its corresponding description from scratch by LLMs.\nMutation Action m1 & m2: MCTS-AHD contains two mutation actions, m1 & m2, to attempt more detailed designs within the original function workflow. Based on the inputted heuristic function, the action m1 prompts LLMs to introduce new mechanisms and formulas, and the action m2 prompts LLMs to change the parameter settings.\nCrossover Action el: To explore heuristic functions with new workflows, we employ a crossover action el to generate a new heuristic function that varies from the multiple existing ones. These heuristic functions are inputted to LLMs with their performances g(\u00b7) and descriptions.\nCrossover Action e2: The crossover action e2 prompts LLMs with a parent heuristic function, a reference heuristic function, and their performances. LLMs are required to identify the beneficial designs in the reference one and design a better heuristic function based on the parent one. The reference is sampled from a elite heuristic function set E consisting of heuristic functions with the top 10 performances g(.).\nTree-path Reasoning Action s1: The MCTS tree paths from the root nr to leaf nodes well record the history of heuristic function evolutions. So, utilizing this characteristic, MCTS-AHD presents an action s1 to analyze the unique heuristic function samples from an MCTS tree path up to the root nr, identify advantageous designs in these samples, and generate a better heuristic function.\nGeneration of Function Descriptions: The Thought-Alignment Process. Generating descriptions of heuristic functions can enhance the reasoning of LLMs (Liu et al., 2024b), where EoH prompts LLMs to generate a function description before outputting its code. However, due to LLM hallucination (Huang et al., 2023), such a procedure could lead to an uncorrelation between codes and descriptions. For correlated and detailed descriptions, MCTS-AHD proposes a thought-alignment process that summarizes descriptions after the code generations. Therefore, performing all the MCTS-AHD actions calls LLMs twice. In the first call, LLMs generate a Python implementation of a heuristic function with the action prompts. Then, LLMs are prompted with a thought-alignment prompt (refer to Appendix E.2) for the description of the implementation in up to three sen-"}, {"title": "3.2. MCTS settings", "content": "Figure 3 displays the MCTS process in MCTS-AHD. It first generates N\u2081 initial nodes representing different heuristic functions and links them to a virtual root node n, that does not represent any heuristic functions. Subsequently, similar to the regular MCTS introduced in Section2.2, MCTS-AHD repeatedly performs the selection, expansion, simulation, and backpropagation stages as follows until the number of evaluations of heuristic functions approaches a limit T:\nSelection: In the selection process of MCTS-AHD, MCTS-AHD normalizes the quality value Q(\u00b7) to enhance the homogeneity of different tasks in calculating UCT value for child nodes c \u2208 Children(nc) of a node nc as follows:\n$UCT(c) = \\frac{\\frac{Q(c) - q_{min}}{q_{max}- q_{min}} + \\lambda * \\sqrt{\\frac{ln(N(n_c) + 1)}{N(c)}}$.\n(5)\nwhere qmax and qmin are the upper and lower limits of quality values Q() that ever encountered in MCTS, respectively. From the root nr, MCTS iteratively selects a child node with the largest UCT value until reaching a leaf node.\nExpansion: For the leaf node selected in the selection stage, the expansion stage prompts LLMs with actions e2, m1, m2, and s1 to build its child nodes. To attempt various detail designs, in a single expansion stage, MCTS-AHD generates k child nodes with the actions m1 and m2, one with e2 and s1, respectively (2k + 2 child nodes in total).\nSimulation: Then, MCTS-AHD evaluates these newly generated heuristic functions on the evaluation dataset D for their performances g(\u00b7). After evaluations, each leaf node ni with heuristic function h is assigned with the quality value Q(nm) = g(h) and the visit count N(n\u012b) = 1. Also, the elite set E for the action e2, qmax, and qmin are updated.\nBackpropagation: The backpropagation process updates the quality values and the visit counts in MCTS as follows:\n$Q(n_c) \\leftarrow \\max_{c \\in Children(n_c)} Q(c),$\n$N(n_c) \\leftarrow \\sum_{c \\in Children(n_c)} N(c).$\n(6)\nProgressive Widening Settings. Since the elite heuristic function set E for the action e2 updates gradually as the search progresses. MCTS-AHD introduces progressive widening to enable the re-exploration of non-leaf nodes, especially nodes with higher visit counts. The progressive widening process will occur when the condition in Eq.(4) is satisfied and \u03b1 = 0.5 in this paper. We call an action el"}, {"title": "3.3. Exploration-Decay", "content": "The setting of the exploration factor \u03bb in Eq.(5) determines the preferences of MCTS on exploration or exploitation (Browne et al., 2012). A larger \u03bb promotes the exploration of temporarily inferior nodes, while a smaller \u03bb stimulates concentration on nodes with higher quality values Q(\u00b7). To facilitate a more comprehensive exploration in the early stage of MCTS and ensure convergence in the later stages, MCTS-AHD presents an exploration-decay technique, linearly decaying the exploration factor \u03bb in Eq.(5) as follows:\n$\\lambda = \\lambda_0 * \\frac{T-t}{T}.$\n(7)\nAlthough having a task-specific setting \u03bb, is helpful for high-quality heuristics, MCTS-AHD strives to keep the generalization ability, so we set \u03bb0 = 0.1 for all tasks."}, {"title": "4. Experiments", "content": "We evaluate the proposed MCTS on various complex tasks, including NP-hard CO problems and a Cost-aware Acquisition Function (CAF) design task for BO (Yao et al., 2024c). The definitions of these tasks are given in Appendix B. We implement MCTS-AHD to design key functions of a wide range of general frameworks (detailed in Appendix C) for these tasks, e.g., step-by-step construction, Ant Colony Optimization (ACO), Guided Local Search (GLS), and BO.\nSettings. For all experiments in this section, we set the number of initial tree nodes N\u2081 = 4, \u03bb0 = 0.1, and \u03b1 = 0.5. The maximum running time of each heuristic function on the evaluation dataset D is confined to 60 seconds. The composition of evaluation datasets D for each task is detailed in Appendix D as well as the parameter settings of general frameworks. Valuable LLM-based AHD methods should be flexible for different pre-trained LLMs, so this paper includes both GPT-3.5-turbo and GPT-4o-mini.\nBaselines. To verify the ability of heuristics designed by MCTS-AHD, we introduce four types of heuristics as baselines: (a) Manually designed heuristics, e.g., Nearest-greedy (Rosenkrantz et al., 1977), ACO (Dorigo et al., 2006), \u0395\u0399 (Mockus, 1974). (b) Traditional AHD method: GHPP"}, {"title": "4.1. MCTS-AHD for NP-hard CO Problems", "content": "As commonly recognized complex tasks (Korte et al., 2011), we first evaluate the proposed MCTS-AHD on NP-hard CO problems, including TSP, KP, Capacitated Vehicle Routing Problem (CVRP), Multiple Knapsack Problem (MKP), Bin-Packing Problem (BPP) with both online and offline settings (online BPP & offline BPP), and Admissible Set Problem (ASP). We apply MCTS-AHD to automatically design heuristics with several general frameworks to obtain high-quality heuristics of these NP-hard CO problems, including step-by-step construction, ACO, and GLS (shown in Appendix F.2).\nStep-by-Step Construction Framework. The step-by-step construction framework (also known as the constructive heuristic framework) is simple but flexible for task solving, which constructs nodes in feasible solutions one by one (Asani et al., 2023). It is the most common framework adopted in NCO methods (Vinyals et al., 2015; Bello et al., 2016) and is also used as a popular test scenario for LLM-based AHD methods. We use MCTS-AHD to design heuristics with the step-by-step construction framework for TSP, KP, online BPP, and ASP (shown in Appendix F.1).\nTSP & KP. We first evaluate MCTS-AHD by designing high-quality TSP and KP heuristic functions for step-by-step construction frameworks. The function should select the next TSP node or the KP item to join based on the solving state (e.g., currently selected and remaining TSP nodes or KP items) as input. This function will be executed recursively until a complete feasible solution is constructed. To design TSP heuristics, the evaluation dataset D for LLM-based AHD methods contains 64 50-node TSP (N=50) instances. For KP, it contains 64 100-item KP instances with capacity W = 25. Table 1 shows the performance of baseline heuristics and LLM-based AHD methods. The Greedy Construct baseline is the Nearest-greedy heuristic algorithm for TSP and it constructs KP solutions based on the ratio of item values and weights. MCTS-AHD exhibits significant advantages on almost all test scales, surpassing manually designed heuristics and LLM-based AHD methods EoH and Fun-"}, {"title": "4.2. MCTS-AHD for Other Complex Tasks", "content": "To verify whether MCTS-AHD can still perform well in planning tasks other than NP-hard CO problems, we follow Yao et al. (2024c) to evaluate MCTS-AHD by designing heuristic CAFs for BO. The CAF is an important element for Cost-aware BO to approach the global optimum within a limited budget in a cost-efficient manner, and a series of advanced manually designed heuristics including EI (Mockus, 1974), Elpu (Snoek et al., 2012), and EI-cools (Lee et al., 2020a). We employ two synthetic instances with different landscapes and input dimensions (i.e., Ackley and Rastrigin in Table 4) as the evaluation dataset D for LLM-based AHD and also test the manually and automatically designed heuristics on ten other synthetic instances. During heuristic evolutions, we set the sampling budget to 12 and run 5 independent trials for average performances. As shown in Table 4, heuristic CAFs designed by the proposed MCTS-AHD demonstrate higher qualities that outperform both manually designed heuristics and EoH in six out of twelve synthetic instances. It verifies that MCTS-AHD can not only show significant advantages in NP-hard CO problems but also has great potential in other complex planning tasks."}, {"title": "5. Discussion", "content": "Experiments have demonstrated the effectiveness of the proposed MCTS-AHD in designing high-quality heuristic functions for a wide range of application scenarios. This section first conducts essential ablation studies. Then, we will also analyze the advantages of utilizing MCTS in LLM-based AHD compared to the original population-based EC."}, {"title": "5.1. Ablation on Parameters and Components", "content": "We conduct ablation studies to validate the necessity of components in MCTS-AHD and to measure the sensitivity of the parameter settings. As shown in Table 5, we first remove three proposed components of MCTS-AHD (Progressive Widening, Thought-alignment, and Exploration-decay) and use these three variants to design heuristics. Table 5 reports their average optimality gaps over 3 runs in the in-domain test sets of Table 1. Ablation variants exhibit a clear performance degradation in at least one task. The actions for expanding the MCTS-AHD nodes are also significant. Actions el and e2 are closely associated with progressive widening, so they cannot be ablated individually. Results also show that the MCTS-AHD variant without actions s1, m1, and m2 (w/o Action s1, w/o Action m1, and w/o Action m2) could only design significantly inferior heuristics, demonstrating the importance of each LLM-based action in MCTS-AHD.\nMeanwhile, we analyze the main parameter \u03bb\u03bf of MCTS-AHD. The results show that although the TSP and KP tasks may have different preferences in the Ao setting, the default setting (i.e., \u03bb\u03bf = 0.1) exhibits generally good quality."}, {"title": "5.2. MCTS versus Population-based EC", "content": "Ability of MCTS-AHD in Escaping from Local Optima. As the main contribution of this paper, instead of population-based EC, MCTS-AHD can manage underperforming but potential heuristic functions, achieving a more comprehensive exploration of the heuristic space H thus escaping local optima. To verify this, we plot the performance curves of MCTS-AHD in designing heuristic functions in the step-by-step construction framework for TSP and designing CAF functions in BOs. Each curve is averaged from at least 5 runs. As illustrated in Figure 4, all baseline methods with populations exhibit early convergence to local optima, but MCTS-AHD can demonstrate a steady performance update and eventually convergence to better results."}]}