{"title": "A Diversity-Enhanced Knowledge Distillation Model for Practical Math Word Problem Solving", "authors": ["Yi Zhang", "Guangyou Zhou", "Zhiwen Xie", "Jinjin Ma", "Jimmy Xiangji Huang"], "abstract": "Math Word Problem (MWP) solving is a critical task in natural language processing, has garnered significant research interest in recent years. Various recent studies heavily rely on Seq2Seq models and their extensions (e.g., Seq2Tree and Graph2Tree) to generate mathematical equations. While effective, these models struggle to generate diverse but counterpart solution equations, limiting their generalization across various math problem scenarios. In this paper, we introduce a novel Diversity-enhanced Knowledge Distillation (DivKD) model for practical MWP solving. Our approach proposes an adaptive diversity distillation method, in which a student model learns diverse equations by selectively transferring high-quality knowledge from a teacher model. Additionally, we design a diversity prior-enhanced student model to better capture the diversity distribution of equations by incorporating a conditional variational auto-encoder. Extensive experiments on four MWP benchmark datasets demonstrate that our approach achieves higher answer accuracy than strong baselines while maintaining high efficiency for practical applications.", "sections": [{"title": "1. Introduction", "content": "The ability for mathematical reasoning has long been recognized as a fundamental challenge for computers (Bobrow, 1964). Math word problem (MWP) solving aims to generate solutions from mathematical problems expressed in natural language. Solving MWP requires natural language understanding and mathematical reasoning skills, which have garnered significant attention from the fields of natural language processing (NLP) and smart education.\nResearchers developed various methods to address MWP solving tasks, including statistical machine learning methods (Kushman et al., 2014; Hosseini et al., 2014; Mitra and Baral, 2016; Roy and Roth, 2018), semantic parsing methods (Shi et al., 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017), and deep learning methods (Wang et al., 2017; Xiao et al., 2023; Zhang et al., 2024). Traditional statistical machine learning and semantic parsing methods require manually crafted feature engineering or template design, which are challenging to scale to large datasets.\nRecently, deep learning models have emerged as a promising paradigm for MWP solving. Leveraging the success of end-to-end models in NLP, researchers introduced Sequence-to-Sequence (Seq2Seq) models for MWP tasks (Wang et al., 2017, 2019; Li et al., 2019). Seq2Seq models utilize an Encoder-to-Decoder (Enc2Dec) framework to translate the input problem description into a mathematical equation. However, these models often overlook the structural information of equations, potentially generating invalid equations that cannot be computed. To better capture equation structure, some studies have enhanced Seq2Seq models by incorporating tree-based decoders, such as Seq2Tree models (e.g., GTS) (Xie and Sun, 2019)) and Graph2Tree models (e.g., Graph2Tree-Z (Zhang et al., 2020b)).\nAlthough existing Enc2Dec models (e.g., Seq2Seq, Seq2Tree and Graph2Tree) have achieved remarkable progress in solving MWPs, they are limited in modeling the diversity of solution equations due to data and model limitations. On the one hand, benchmark datasets (e.g., Math23K (Wang et al., 2017) and MAWPS (Koncel-Kedziorski et al., 2016)) typically provide only one ground-truth solution equation for each math problem, even though numerous alternative correct equations can solve the same problem. For instance, in the math problem shown in Figure 1, the ground-truth"}, {"title": "2. Related Work", "content": "In automatically solving MWPs, deep learning techniques have become the primary approach for MWP solving due to their superior performance and generalization capabilities compared to traditional rule-based and statistical methods (Lu et al., 2023). Recently, the deep learning models (Xie and Sun, 2019; Zhang et al., 2020b, 2022; Bin et al., 2023b; Qin et al., 2023; Bin et al., 2023a) for MWP solving have primarily focused on end-to-end frameworks (e.g., Seq2Seq, Seq2Tree, Graph2Tree). Besides, some subsequent methods, such as PARAMAWPS (Raiyan et al., 2023), DiverseMWP (Zhou et al., 2023) and MathEncoder (Qin et al., 2023), leverage data augmentation, voting, or task-specific pre-training strategies to enhance the performance. However, these approaches are not the focus of this paper due to differing motivations and research goals.\nIn addition to the aforementioned base solvers, recent pre-trained language models (PLMs) offer opportunity for developing more powerful MWP solvers, including MWP-BERT (Liang et al., 2022), Generate&Rank (Shen et al., 2021) and Deductive Reasoner (Jie et al., 2022). Most recently, the large-scale models have demonstrated remarkable reasoning abilities for MWP solving (Shao et al., 2022; Pi et al., 2022; Liang et al., 2023a). Large language models (LLMs) achieve higher accuracy and explain the solution processes (Touvron et al., 2023; Brown et al., 2020). Large Multimodal models (LMMs) effectively incorporate visual information to aid mathematical reasoning (Shi et al., 2024; Zhuang et al., 2024). However, the computational efficiency makes large size models hard for real-world situations especially in smart eduction domain where cost and speed are important consideration. Additionally, LLMs such as GPT-3 (Brown et al., 2020) are prone to factual errors (Ouyang et al., 2022), their knowledge bases are not up-to-date. In summary, a computationally efficient solver still needs to be developed to make it practical for real-world situations.\nAlthough the previous MWP solvers have achieved promising performance, they are trained on datasets that provide only a single ground-truth target, which limits the solver's generalization ability. Consequently, some works attempt to construct rich template sketches to accommodate diverse equations during the training process (Mitra and Baral, 2016; Huang et al., 2017; Wang et al., 2019). However, this approach can lead to many different equations with various combinations, resulting in a larger non-deterministic space during the decoding process. Zhang et al. (2020a) propose to extract knowledge from a pre-trained teacher network and encourage multiple student networks to mimic the soft labels generated by the teacher network to learn diverse solutions, named TSN-MD. Subsequent paper (Wang et al., 2022) following TSN-MD focus on unifying the output solution structures through a proposed information storage structure called M-Tree. However, multiple teacher networks or solution structures also require additional model complexity to assess the data quality in mathematical reasoning.\nDifferent from the above-mentioned models, we propose a new framework to better capture the diversity of solution equations in MWPs. Firstly, we design an AdaKD method to select high-quality distillation labels, enriching diversity by incorporating new knowledge from teacher models while reducing the impact of noise information. Secondly, we introduce an enhanced student model with a diversity prior, enabling the model to capture the diversity distribution of solution equations."}, {"title": "3. Background", "content": "In this section, we introduce the Knowledge Distillation method and the representative teacher-student framework, discuss the relationship in some preliminaries of this work, and finally, summarize the mathematical notations and definitions used in this study in Table 1."}, {"title": "3.1. Knowledge Distillation", "content": "Knowledge distillation (KD) (Hinton et al., 2015) has been widely used in deep learning models due to its ability to transfer knowledge from a pre-trained teacher model to a student model. In the process of KD, a teacher model T is pre-trained to generate soft targets, and then a student model S is trained under the supervision of both the ground-truth labels and generated soft labels. Formally, the student model S is trained on a linear combination of two loss functions:\n$L = (1 \u2212 \\alpha)L_{CE} + \\alpha L_{KD},$ (1)\nwhere \u03b1 is a hyper-parameter, $L_{CE}$ is the cross-entropy between the student output S(x) and the ground-truth label y, which is computed as:\n$L_{CE} = -y \\log \\sigma(S(x)).$ (2)\nwhere \u03c3 denotes the softmax function. And $L_{KD}$ is the Kullback-Leibler (KL) divergence loss between student output S(x) and the soft target T(x) generated from teacher model, namely:\n$L_{KD} = KL(\\sigma(S(x)/\\tau||\\sigma(T(x)/\\tau)))$ (3)\nwhere \u03c4 is a temperature hyper-parameter in softmax function."}, {"title": "3.2. Problem Definition", "content": "Let $x = {w_1,w_2, \u2026, w_n }$ denote a math word problem and $y = {a_1, a_2, \u2026, a_m }$ denote the output solution equation sequence, where $w_i$ in the math word problem is a word token, $a_i$ in the answer equation is a numeric value or a operator, n is the number of words in x and m is the number of elements in y. Given a set of MWPs and corresponding solution equations $D = {(x, y)}$, the task of solving math word problems aims to learn a model to map the text sequence of a given math word problem x into an output equation sequence y."}, {"title": "4. Our Method", "content": "Figure 2 illustrates the overview of the proposed a diversity-enhanced knowledge distillation (DivKD) model. In our approach, we model the diversity of MWPs using a knowledge distillation framework with a diversity prior. Firstly,"}, {"title": "4.1. Diversity Enhanced Knowledge Distillation Framework", "content": "In the task of MWP solving, there can be multiple correct solution equations for a given problem, while only one solution equation is annotated in datasets. Most previous models are designed to fit the single annotation solution equation without considering the diversity of solutions. Thanks to the generalization ability of deep learning models, we can leverage KD to learn knowledge beyond the original dataset from a teacher model. The KD framework consists of a teacher model and a student model. In this paper, we select tree-based encoder-decoder models (e.g., GTS (Xie and Sun, 2019) and Graph2Tree-Z (Zhang et al., 2020b)) as basic structures since these models are typical in MWP solving task. GTS (Xie and Sun, 2019) applies a bidirectional gated recurrent unit (BiGRU) as the encoder. Graph2Tree-Z (Zhang et al., 2020b) uses a graph-based encoder (GraphEncoder) to better learn relationships and order information among quantities. Furthermore, we also present a PLM-enhanced version of the Graph2Tree-Z model named Ro-Graph2Tree-Z, which employs a pre-trained language (PLM) model (e.g., RoBERT (Liu et al., 2019)) as an encoder to enhance the understanding of MWPs. It's worth noting that our method is generic and can also be applied to other MWP solvers. In this subsection, we describe the structure of teacher and student models used in our KD framework."}, {"title": "4.1.1. Basic Teacher Model", "content": "Firstly, we use the original structure of the encoder-decoder model (e.g., GTS, Graph2Tree-Z and Ro-Graph2Tree-Z) as a teacher model to pre-train on MWP datasets. Given a math problem $x = {w_1, w_2, \u2026, w_n }$, the teacher model first uses an encoder to model the sequence of input and return the hidden state of the input math problem, which is denoted as:\n$h = Encoder(x)$ (4)"}, {"title": "4.1.2. Diversity Prior Enhanced Student Model", "content": "The variational autoencoder (VAE) (Kingma and Welling, 2014; Rezende et al., 2014) and its variants, such as conditional variational autoencoder (CVAE) (Sohn et al., 2015), are widely adopted generative models due to their ability of generating diverse data (Zhao et al., 2017; Wu et al., 2020). To model the diversity of solution equations, we introduce a diversity prior to enhancing the student model by incorporating a CVAE component into the original encoder-decoder MWP models (e.g., GTS, Graph2Tree-Z, Ro-Graph2Tree-Z). In the task of MWP solving, the generation of a solution equation y is conditioned on a given math problem x, which can be denoted as p(y|x). Using CVAE, a latent variable z is introduced to capture the latent distribution over possible solution equations and the conditional likelihood calculation is reformulated as:\n$p(y|x) = \\int p(y|x, z)p(z|x)$ (6)\nHere p(z|x) is a diversity prior distribution which is used to sample diverse latent variable z, and p(y|x, z) is a generative distribution. Thus, the process of generating a solution equation is as follows: (1) sample a latent variable z from the prior distribution p(z|x) and (2) generate solution equation y from the conditional generative distribution p(y|x, z).\nIt is intractable to directly optimize the conditional log-likelihood of p(y|x) due to the marginalization over the latent variable z. To address this problem, a stochastic gradient variational bayes (SGVB) framework (Kingma and Welling, 2014; Sohn et al., 2015) is applied to train the CAVE model, which converts the original conditional log-likelihood into variational lower bound:\n$L_{CVAE} = -KL(q(z|x, y)||p(z|x)) + E_{q(z|x,y)} [\\log p(y|x, z)] \u2264 \\log p(y|x)$ (7)\nwhere q(z|x, y) is the posterior distribution. The first term is the KL distance between posterior and prior distribution, and the second term is the cross-entropy between output distribution and ground-truth labels.\nFollowing previous works (Kingma and Welling, 2014; Zhao et al., 2017; Zhang et al., 2016), we assume that z follows a multivariate Gaussian distribution, namely $q(z|x, y) \u223c N(\u03bc, \u03c3\u00b2I)$ and $p(z|x) \u223c N(\u03bc', \u03c3'\u00b2I)$. And we use two neural networks to approximate the diversity prior distribution p(z|x) and posterior distribution q(z|x, y). For the posterior distribution q(z|x, y), we first apply a BiGRU network to encode the target equation to obtain the output representation:\n$h_y = BiGRU(y)$ (8)\nThen, linear feed-forward networks are applied to obtain the Gaussian parameters \u03bc and log \u03c3\u00b2 for the posterior distribution:\n$\u03bc = W_\u03bc[h||h_y] + b_\u03bc$\n$log \u03c3\u00b2 = W_\u03c3[h||h_y] + b_\u03c3$ (9)\nwhere $W_\u03bc$, $W_\u03c3$, $b_\u03bc$ and $b_\u03c3$ are trainable parameters in neural networks. Similarly, we can compute the Gaussian parameters \u03bc' and log \u03c3'\u00b2 for the prior distribution using a linear prior network as follows:\n$\u03bc' = W_{\u03bc'}h + b_{\u03bc'}$\n$log \u03c3'\u00b2 = W_{\u03c3'}h + b_{\u03c3'}$ (10)"}, {"title": "4.2. Adaptive Diversity Knowledge Distillation", "content": "Given that datasets typically provide only a single equation for each math problem, it becomes challenging for a model to gain a comprehensive understanding of diverse solution equations for an MWP. In this study, we employ the KD method to address this issue. Previous KD-based approaches, such as TSN-MD, have solely focused on transferring soft labels from a teacher model to a student model without assessing the quality of the soft labels generated by the teacher. In practice, not all soft labels from the teacher model may enhance the student's performance. Some soft labels may contain noise information that can potentially degrade the student's performance. Therefore, how to measure the quality of teacher knowledge is of great importance to learning a good student model. A simple solution is to measure the quality of soft labels according to the cross-entropy of the teacher's prediction (Li et al., 2021; Wang et al., 2021). However, this method is not well-suited for MWP tasks because there may be multiple correct equations for a single MWP. If we simply employ cross-entropy between soft labels and labelled ground-truth equations, it may result in misjudgment for other unlabeled correct equations. To address this problem, we propose an adaptive diversity knowledge distillation (AdaKD) method for better distillation, which consists of two adaptive KD strategies, namely adaptive hard KD (AdaHardKD) and adaptive soft KD (AdaSoftKD). Specifically, we introduce a beam search-based approach to assess the quality of the teacher's predictions. When provided with the soft predictions from the teacher model, we employ beam search to generate the top-K equations. Subsequently, we calculate the results of these equations and compare them with the ground-truth answer value to determine their correctness. Intuitively, if an equation's result matches the ground-truth value, it is considered a correct equation. Thus, we can obtain a set of correct equations for MWPs, which is denoted as $D_{kd} = {(x, y_{kd})}$. These generated equations are viewed as new hard labels to compute the loss of adaptive hard KD, which is calculated as:\n$L_{AdaHardKD} = \\frac{1}{|D_{kd}|} \\sum_{(x,y_{kd})\u2208D_{kd}} \u2013 \\log p(y_{kd}|x, \u03b8_s)$ (12)\nIn addition to using hard labels, we also introduce an adaptive soft KD strategy to learn high-quality knowledge from the soft labels of the teacher. Intuitively, a better distribution will yield a greater number of correct equations with higher ranks. Consequently, we can assess the quality of the teacher's soft labels based on the outcomes of the beam search. Formally, let $B = {(y_{kd},r_k )|1 \u2264 k \u2264 K}$ denote the results of beam search, where $y_{kd}$ is the k-th equation and $r_k$ is its rank in the beam search results. And let B' \u2208 B denote the set of correct equations 1. Then, the weight score of the teacher's soft prediction can be computed as:\n$@_x = \\frac{1}{K} \u2211_{(y_{kd},r)\u2208B'} \u03bb^r$ (13)\nwhere \u03bb \u2208 (0, 1] is an attenuation factor used to assign higher scores to top-ranked equations. By utilizing the weighted scores, we encourage the student model to gain more knowledge from high-quality soft labels. And we define the AdaSoftKD loss function as:\n$L_{AdaSoftKD} = \\frac{1}{|D|}\u2211_{(x,y)\u2208D} @_x KL(p(y|x, \u03b8_s)||q(y|x, \u03b8_\u03c4))$ (14)"}, {"title": "4.3. Training Objective", "content": "Finally, the model is trained by using a linear combination of three losses, namely the CVAE loss, the adaptive soft KD loss and the adaptive hard KD loss:\n$L = \u2212L_{CV AE} + \u03b2L_{AdaHardKD} + \u03b3L_{AdaSoftKD}$ (15)\nwhere \u03b2 and \u03b3 are hyper-parameters controlling the weights of $L_{AdaHardKD}$ and $L_{AdaSoftKD}$. To summarize our DivKD method, we provide the algorithm pseudocode in Algorithm 1."}, {"title": "5. Experiments", "content": "In this section, we provide a comprehensive description of the datasets employed, the baseline methodologies applied, and the overall experimental settings. Subsequently, we present detailed findings from comparison and ablation experiments, which substantiate the efficacy of our approach. Our focus is directed towards investigating the following five research questions:\n\u2022 RQ1: How does our model perform on the answer accuracy metrics compared to existing MWP solvers?\n\u2022 RQ2: How does our diversity-enhanced knowledge distillation approach, DivKD, perform compared to existing knowledge distillation methods in the MWP task?\n\u2022 RQ3: How does the proposed adaptively diverse knowledge distillation (AdaKD) alleviate the limitations of single labeled ground-truth expression in the dataset?\n\u2022 RQ4: How can our approach improve the performance of existing models without sacrificing model efficiency, especially over other KD methods?\n\u2022 RQ5: How does our approach perform on real-world datasets, particularly in capturing implicit diversity knowledge from problem texts and expressions and alleviating the limitations of single-labeled ground-truth expressions in the datasets?"}, {"title": "5.1. General settings", "content": "5.1.1. Datasets\nIn our experiments, we validate our proposed method on four widely used MWP benchmarks: Math23K (Wang et al., 2017), MAWPS (Koncel-Kedziorski et al., 2016), MathQA (Amini et al., 2019) and SVAMP (Patel et al., 2021). The overall dataset statistics are presented in Table 2.\nMath23K is a large-scale Chinese dataset that consists of 23,161 instances. Each instance is annotated with only one ground-truth equation and its corresponding answer. Following previous studies (Zhang et al., 2020b,a), we adopt the same data splits: 21,161 math problems for training, 1,000 instances for validation, and 1,000 instances for testing. We report results based on answer accuracy on the test data as well as the 5-fold average results.\nMAWPS is a standard English MWP-solving dataset that contains 1,987 instances. Since its small size and lack of standard data splits, we perform 5-fold cross-validation and report the average results on this dataset.\nMathQA is a large-scale English dataset designed to evaluate the performance of models in solving more complex mathematical problems, where each problem requires multiple operators to derive the final answer.\nSVAMP is a challenging English benchmark derived from instances sampled from the MAWPS dataset, consisting of 3,138 training instances and 1,000 test instances. It introduces variations such as noun phrase exchanges and the addition of extra quantities to assess whether NLP models can effectively understand and interpret contextual information.\n5.1.2. Evaluation Metric\nAnswer accuracy and expression accuracy are two wildly used evaluation metrics in MWP task. Answer accuracy indicates that a prediction is correct if the calculated value of the generated expression matches the ground-truth answer. Expression accuracy assesses whether the structure of the generated equation is identical to the target expression. The former measures the correctness of the answer, while the latter is concerned with the correctness of the structure. In our paper, we follow most of the prior works (Zhang et al., 2020b; Jie et al., 2022; Bin et al., 2023a) employing the answer accuracy as our standard evaluation metrics due to our focus on diversity knowledge inherent in datasets and teacher predictions to enhance the student model's ability to generate diverse equations. Answer accuracy highlights the potential of DivKD in diversity-driven mathematical problem-solving."}, {"title": "5.1.3. Experimental Setting", "content": "We implement our model using Pytorch 2 and conduct experiments on Ubuntu 20.04 using a server equipped with two NVIDIA RTX A6000 GPUs, each with 48GB of GPU memory. The Adam optimizer is used in our model, and we use a grid search to select the appropriate hyperparameters based on the evaluation metrics on the test set. For the basic models such as GTS and Graph2Tree-Z, we set the initial learning rate to 1e-3, with the rate halving every 20 epochs. The word embedding dimension is set to 128, and the hidden state dimension to 512. For the basic models with pre-trained language models, such as Ro-Graph2Tree-Z, we use RoBerta-base (Liu et al., 2019), setting the initial learning rate to 5e-5. For LLaMA (Touvron et al., 2023), we freeze its parameters and use it as an encoder for the input text. To generate more diverse equations, we set the beam search size to 5. The attenuation coefficient \u03b1 is set to 0.8, and the weight \u03b2 for AdaHardKD is set 0.3, 0.1, 0.1 and 0.1 for Math23K, MAWPS, MathQA and SVAMP, respectively. The weight \u03b3 for AdaSoftKD is set to 0.1, 0.05, 0.05, 0.05 for the same datasets, respectively. Table 3 lists the main hyperparameters setting in the model and details of their search ranges. Our code and the model's detail are released at https://github.com/a773938364/DivKD.\n5.1.4. Comparison Models\nBased on the architectures employed for math text encoding, we categorize the baseline models into three groups: Group A, which includes models utilizing small deep learning architectures such as LSTM, RNN, and GRU; Group B comprising models leveraging PLMs like BERT and RoBERTa; and Group C, consisting of models incorporating LLMs such as T5 and LLaMA.\n\u2022 Basic Models (Group A). These methods use RNN (e.g., LSTM, GRU) or GNN (e.g., GCN, GAT) to encode the problem text into a feature vector and decompose this vector into an expression. We compare our method with various foundational methods without any language models: DNS (Wang et al., 2017), GTS (Xie and Sun, 2019), T-RNN (Wang et al., 2019), Group-ATT (Li et al., 2019), TSN-MD (Zhang et al., 2020a), SAU-Solver (Qin et al., 2020) and HMS (Lin et al., 2021), Seq2Prog (Amini et al., 2019), NumS2T (Wu et al., 2021), Graph2tree-Z (Zhang et al., 2020b) and MWP-Teacher (Liang and Zhang, 2021).\n\u2022 PLM-enhanced Models (Group B). These methods mainly use pre-trained language models (e.g., BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019)) as encoders and capture the general linguistic and semantic information. These baselines include UniLM (Dong et al., 2019), BERT-Tree (Li et al., 2022), MWP-BERT (Liang et al., 2022), mBERT-LSTM (Tan et al., 2022), SUMC-Solver (Wang et al., 2022), PseDual (Bin et al., 2023b), MWP-NAS (Bin et al., 2023a), C-MWP (Liang et al., 2023b), and PLM-enhanced variants of GTS and Graph2Tree-Z (e.g., Ro-GTS and Ro-Graph2Tree-Z).\n\u2022 LLM Models (Group C). Recently, methods using large models have demonstrated the remarkable reasoning ability for MWP solving. We compare our DivKD with methods using large models listed as follows: T5 (Raffel et al., 2020), GPT-3.5-turbo (Brown et al., 2020), LLaMA (Touvron et al., 2023), Math-PUMA (Zhuang et al., 2024) and Math-LLaVA\u00b3 (Shi et al., 2024). We also consider the impact that using more powerful language models (e.g., LLaMA) as teacher models, denoted LLaMA-GTS + DivKD and LLaMA-Graph2Tree-Z + DivKD, which use the LLaMA as the input text encoder."}, {"title": "5.2. Main Results (RQ1 & RQ2)", "content": "Table 4 and Table 5 present the experimental results on Math23K, MAWPS, MathQA and SVAMP datasets. We use GTS, Graph2Tree-Z, and their language model variants (e.g., Ro-Graph2Tree-Z, LLaMA-Graph2Tree-Z) as the foundational models within the teacher-student framework, and apply the proposed DivKD method to these basic models. We compare our method against strong baselines and analyze each group.\nFrom Tabel 4 and Table 5, we derive several observations: (1) The models using the graph encoder significantly outperform these models using the sequence encoder (e.g., GTS and Group-ATT vs. Graph2Tree-Z and NumS2T). The reason is that GNN can capture global and long-distance relations in the problem texts, providing more semantic"}, {"title": "5.3. Ablation Study (RQ3)", "content": "To better understand the impact of different components in the proposed DivKD method, we conduct ablation studies by constructing some variants of DivKD. As shown in Table 6, we use GTS and Graph2Tree-Z as basic teacher and student models and design four variants with different KD strategies:\n\u2022 \"GTS/Graph2Tree-Z + DivKD w/o S&H\" denotes the GTS/Graph2Tree-Z model enhanced with diversity prior using CVAE, but without using adaptive soft and hard KD method.\n\u2022 \"GTS/Graph2Tree-Z + DivKD w/o H\" only uses AdaSoftKD to train the student model without using AdaHardKD."}, {"title": "5.4. Efficiency Analysis (RQ4)", "content": "In this section, we compare the efficiency of the proposed model with existing baseline models, including GTS, TSN-MD and Ro-Graph2Tree-Z. GTS serves as the foundational model structure for both TSN-MD and our proposed \u201cGTS+DivKD\u201d. TSN-MD is a related model that aims to model the diversity of solution equations using multiple decoders. Ro-Graph2Tree-Z and \u201cRo-Graph2Tree-Z+DivKD\u201d utilize pre-trained Roberta model and graph structure to enhance the encoding of input problem. We evaluate these models on the test sets of Math23K and MAWPS and present their testing times in Figure 3. All experiments are conducted on a single RTX A6000 48G graphics card to ensure a fair comparison.\nComparing among GTS, TSN-MD and \u201cGTS+DivKD\u201d, we observe that the running time of \u201cGTS+DivKD\u201d is similar to that of the basic GTS model, whereas TSN-MD requires significantly more time for inference than both GTS and \u201cGTS+DivKD\u201d. This increased inference time in TSN-MD is due to its use of two decoders to generate solution equations. In contrast, \u201cGTS+DivKD\u201d utilizes only one decoder and incorporates a CVAE to better model the diversity of solution equations, thereby enhancing performance without compromising efficiency. Furthermore, by employing PLMs, Ro-Graph2Tree-Z and \u201cRo-Graph2Tree-Z+DivKD\u201d improve performance on both Math23K and MAWPS datasets with only a slight increase in computational time compared to GTS and \u201cGTS+DivKD\u201d. But the testing time of Ro-Graph2Tree-Z and \u201cRo-Graph2Tree-Z+DivKD\u201d are still much less than TSN-MD model. This is because the tree-based decoding process is very time-consuming, and the TSN-MD model, which uses multiple decoders, will inevitably significantly increase the testing time. Therefore, using multiple decoders to improve the performance is not a good choice. Different from TSN-MD, our DivKD method can be conveniently plugged into different models and can improve model effectiveness without causing an increase in inference time. This renders our approach feasible for practical application."}, {"title": "5.5. Quantitative Analysis (RQ5)", "content": "In this section, we conduct a quantitative analysis to count the number of the correct solution equations generated by the teacher models (e.g., Ro-GTS and Ro-Graph2Tree-Z) and student models (e.g., \u201cRo-GTS + DivKD\u201d and \u201cRo-Graph2Tree-Z + DivKD\u201d) in Figure 4. On the Math23K and MathQA datasets, we can see that the student models produce a significantly higher number of correct equations compared to the teacher models. For instance, on the subset of MathQA with 3 operators, our \u201cRo-Graph2Tree-Z+DivkD\u201d outperforms the Ro-Graph2Tree-Z by 62. This improvement is attributed to DivKD's ability to learn the diversity distribution of solution equations, thereby generating a wider range of potential solutions during the test phase. Instead, Ro-GTS and Ro-Graph2Tree-Z are limited to learning only one ground-truth solution equation provided for each math problem in the benchmark datasets. Overall, these"}, {"title": "5.6. Case Study (RQ5)", "content": "To better understand the superiority of the proposed method, we conduct a case study by comparing the results generated by the original GTS and our proposed \u201cGTS+DivKD\u201d. As shown in Figure 5, for Problem 1, the original GTS model generates a wrong solution equation at the first rank of the five beam search results and only two correct solution equations are ranked at the top five results. Instead, our proposed \u201cGTS+DivKD\u201d can correctly predict four solution equations and rank them at top positions. In the second example, although the GTS predicts a correct solution equation ranking at the first position, it fails to model the diversity of solution equations since only one correct equation is ranked in the top 5 results. Different from the original GTS, our proposed \u201cGTS+DivKD\u201d can generate diverse correct solution equations in the beam search results. These examples demonstrate that the proposed DivKD method is able to model the diversity distribution of multiple solution equations for MWPs."}, {"title": "5.7. Discussion", "content": "In recent years, LLMs and LMMs such as GPT-3.5-turbo (Brown et al., 2020) and Math-PUMA (Zhuang et al., 2024) have made remarkable strides in solving MWPs with the help of chain-of-thought (CoT) prompting (Chen et al., 2022; Wang et al., 2023; Xie et al., 2024). Although our model does not outperform these advanced large- scale models on the MWP task, we believe our work contributes significant value to the research field. Real-time or resource-constrained is crucial for many real-world applications, such as smart education. However, existing LLMs have hundreds of millions of parameters and exorbitant API, resulting in computational inefficiency and impracticality for real-world situations. In contrast, our method achieves competitive performance compared to LLMs while offering faster response times and requiring fewer parameters for the MWP task. Furthermore, our method is a natural"}]}