{"title": "Revisiting DDIM Inversion for Controlling Defect Generation by Disentangling the Background", "authors": ["Youngjae Cho", "Gwangyeol Kim", "Sirojbek Safarov", "Seongdeok Bang", "Jaewoo Park"], "abstract": "In anomaly detection, the scarcity of anomalous data compared to normal data poses a challenge in effectively utilizing deep neural network representations to identify anomalous features. From a data-centric perspective, generative models can solve this data imbalance issue by synthesizing anomaly datasets. Although previous research tried to enhance the controllability and quality of generating defects, they do not consider the relation between background and defect. Since the defect depends on the object's background (i.e., the normal part of an object), training only the defect area cannot utilize the background information, and even generation can be biased depending on the mask information. In addition, controlling logical anomalies should consider the dependency between background and defect areas (e.g., orange colored defect on a orange juice bottle). In this paper, our paper proposes modeling a relationship between the background and defect, where background affects denoising defects; however, the reverse is not. We introduce the regularizing term to disentangle denoising background from defects. From the disentanglement loss, we rethink defect generation with DDIM Inversion, where we generate the defect on the target normal image. Additionally, we theoretically prove that our methodology can generate a defect on the target normal image with an invariant background. We demonstrate our synthetic data is realistic and effective in several experiments.", "sections": [{"title": "1. Introduction", "content": "Data scarcity presents a significant challenge in industrial anomaly detection, as imbalanced datasets can lead to overfitting in deep neural networks, damaging inspection performance. Limited labeled training examples introduce model bias, preventing the detection model from effectively generalizing to unseen anomalies. Recent unsupervised anomaly detection approaches [5, 17, 23] mitigate the imbalance issue by avoiding reliance on anomaly instances during training. However, these methods may struggle when the backbone model experiences distribution shifts in feature space, making it difficult to distinguish normal and anomalous features. Additionally, they often fall short in detecting fine-grained anomalies at the pixel level."}, {"title": "2. Background", "content": "Recent research on defect generation aims to address data scarcity through a data-centric approach, synthesizing anomaly data to train on augmented samples. GAN-based methods [6] generate realistic synthetic anomaly data from limited examples, improving model performance on rare anomalies; however, they lack control over defect location, often transforming normal regions into anomalies unintentionally. Diffusion-based methods [10] improve control by specifying defect locations and blending normal latent backgrounds with synthetic defect latents. While these personalization techniques enable defect placement on object backgrounds, some challenges remain unaddressed.\nFirst, focusing solely on controllability with masks can compromise the quality of generation. Since the defect's appearance is dependent on the background of the target image, using a misleading mask may result in the generation of a biased anomaly that does not align with the data distribution. For example, defects should not appear outside the objects themselves. Additionally, defects should vary based on the texture of the background and the location of the target mask such as Figure 3. Generating logical anomalies, in particular, becomes challenging without accounting for the relationship between the defect and the background, especially when compared to generating structural anomalies, which are easier to control.\nSecondly, overfitting to few-shot anomaly instances can lead to biased generation, where controllable defect generation may fail when encountering unseen backgrounds. Since anomaly instances consist of both foreground (defect) and background, it is crucial to model the relationship between these two components to mitigate overfitting issues. This consideration helps ensure that the model can generate defects effectively, avoiding the transfer of inadequate feature of the defect.\nTo address the issues mentioned above, we propose modeling the relationship between the defect and background to achieve both high-quality and controllable defect generation. Our work suggests the disentanglement loss function for generating faithful defects on the target normal instances. Our formulation ensures independence from defect to background, allowing the denoising process for defects to proceed without affecting the background's denoising process. At the same time, the background influences the defect area's denoising process, enhancing defect generation by reducing reliance on the mask information. In addition, we propose the inference strategy to generate defect on the target normal latent, where we apply DDIM Inversion to the normal latent and generate defects on the background. We theoretically show that we can initialize anomaly latent by noising the target area of inversed normal latent while reconstructing its background. To sum up, we make the following contributions."}, {"title": "2.1. Industrial anomaly detection", "content": "Industrial anomaly detection (IAD) has seen significant progress, transitioning from traditional methods reliant on labeled data to more advanced machine learning and computer vision approaches. By leveraging pretrained models to extract normal features, unsupervised anomaly detection methods focus on identifying anomalous regions in products [3\u20135, 17, 23]. Memory-based approaches [3, 4, 23] store normal feature representations and calculate similarity scores to pinpoint anomalous regions. However, since unsupervised methods do not incorporate anomalous features during training, accurately detecting defect areas in anomaly instances remains challenging. As a result, supervised or semi-supervised learning methods remain highly effective for identifying fine-grained defect areas at the pixel level, especially when sufficient anomaly instances are available for training."}, {"title": "2.2. Defect generation", "content": "Collecting sufficient anomalous data is challenging due to the time-consuming nature and high annotation costs involved. To address this scarcity, data augmentation and generation methods have been developed. Cut-Paste [14] employs pixel-level data augmentation, while Crop-Paste [16] focuses on feature-level augmentation to help the model learn discriminative features between normal and anomalous data. However, since these augmentation-based methods do not model distributions of anomalies, generating a faithful defect dataset remains difficult.\nIn the DFMGAN [6] paper, the authors leverage StyleGAN [12] to generate defects from a limited number of anomalous data. While they also incorporate normal data to guide defect generation, their approach lacks the ability to control defect generation on unseen target normal data. In contrast, AnomalyDiffusion [10] addresses this by training a Text-to-Image diffusion model to control defect generation on target normal images. However, their method does not train the diffusion process to account for the background"}, {"title": "2.3. Diffusion model", "content": "Since the advent of diffusion models [9, 26], text-to-image (T2I) models [20] that control image generation through text has been developed. The denoising network \\( \\epsilon \\) is conditioned on text embedding \\(C\\), where text embedding controls the output with cross-attention. Latent variable, \\(z_t\\) is injected by Gaussian noise \\(\\epsilon\\) from the \\(z_0\\) as follows [9]:\n\\[z_t = \\sqrt{\\alpha_t}z_0 + \\sqrt{1 - \\alpha_t}\\epsilon, \\text{ where } \\epsilon \\sim \\mathcal{N}(0, I) \\quad(1)\\]\nFrom noising the latent in Eq.1, the network is trained to minimize the following loss between random noise \\( \\epsilon \\) and the noise prediction \\( \\epsilon_\\theta (z_t, t, C) \\):\n\\[\\min_\\theta \\mathbb{E}_{z_0,\\epsilon \\sim \\mathcal{N}(0,I),t\\sim Uniform(1,T)}||\\epsilon - \\epsilon_\\theta(z_t, t, C)||^2 \\quad(2)\\]"}, {"title": "2.4. DDIM Inversion", "content": "By the DDIM Sampling [25], we can denoise the noise with non-Markovian deterministic diffusion process as follows:\n\\[z_{t-1} = \\sqrt{\\alpha_{t-1}}(\\frac{z_t - \\sqrt{1 - \\alpha_t} \\epsilon_\\theta(z_t, t, C)}{\\sqrt{\\alpha_t}}) + \\sqrt{1 - \\alpha_{t-1}} \\cdot \\epsilon_\\theta (z_t, t, C) \\]\n\\[= \\sqrt{\\frac{\\alpha_{t-1}}{\\alpha_t}}z_t + (\\sqrt{1 - \\alpha_{t-1}} - \\sqrt{1 - \\alpha_t} \\sqrt{\\frac{1}{\\alpha_t} - 1})\\cdot \\epsilon_\\theta (z_t, t, C) \\quad(3)\\]\nWith approximating to ODE path, we can reverse the denoising steps (i.e., DDIM Inversion), where some initial \\( \\tilde{z}_T\\) can noised from the \\( z_0 \\) as follows:\n\\[\\tilde{z}_t = \\sqrt{\\alpha_t}(\\frac{z_{t-1} - \\sqrt{1 - \\alpha_{t-1}} \\epsilon_\\theta(\\tilde{z}_{t-1}, t-1, C)}{\\sqrt{\\alpha_{t-1}}}) + \\sqrt{1 - \\alpha_t} (\\sqrt{\\frac{1}{\\alpha_{t-1}} - 1} - \\sqrt{\\frac{1}{\\alpha_t} - 1})\\cdot \\epsilon_\\theta (\\tilde{z}_{t-1}, t-1, C) \\quad(4)\\]\nEspecially, from the DDIM Inversion [25], editing of target images is enabled with changing text embeddings [7, 18]. Furthermore, target images can be translated to source image concepts via controlling cross-attention. In this paper, we utilize the DDIM Inversion to personalize the target normal images and generate the defect in the target area."}, {"title": "3. Method", "content": "As discussed earlier, our objective is to model the relationship between defect and background in order to generate more accurate defect representations on normal images. In the U-Net architecture, attention mechanisms facilitate interaction between defect and background regions, effectively reducing random noise. While defects may vary depending on the background context, the background itself should remain unaffected by defect generation. To decouple the influence of defects on the background, we propose the following loss formulation with masked noising strategy."}, {"title": "3.1. Loss formulation", "content": "As discussed earlier, our objective is to model the relationship between defect and background in order to generate more accurate defect representations on normal images. In the U-Net architecture, attention mechanisms facilitate interaction between defect and background regions, effectively reducing random noise. While defects may vary depending on the background context, the background itself should remain unaffected by defect generation. To decouple the influence of defects on the background, we propose the following loss formulation with masked noising strategy.\n\\[\\mathcal{L}(\\theta) := \\mathbb{E}_{z_0,\\epsilon,t} ||m \\odot (\\epsilon - \\epsilon_\\theta(z_t, t, C_1))||^2 \\\\\nMatching Loss\n+ ||(1 - m) \\odot (\\epsilon - \\epsilon_\\theta(z_m, t, C_2))||^2 \\\\\nRegularizer\n= ||\\epsilon - m \\odot \\epsilon_\\theta(z_t, t, C_1) - (1 - m) \\odot \\epsilon_\\theta(z_m, t, C_2))||^2 \\quad(5)\\]\nWe suppose that text embedding, \\(C_1 = [C_{def}, C_{bg}], C_2 = [C_{m},C_{bg}]\\) and we mask its cross-attention with source mask, \\(m\\) in the training dataset, where the \\(C_{def}, C_{m}\\) attentions on masked area and \\(C_{bg}\\) attentions on another area like Figure 2. Masked latent is defined as masking the anomaly latent as follows: \\(z_m := (1-m) \\odot z_0, z_0 \\sim P(z_0)\\). From Eq.5, we inject the noise to each latent as follows.\n\\[z_t = \\sqrt{\\alpha_t}z_0 + \\sqrt{1 - \\alpha_t} \\epsilon \\quad(6)\\]\n\\[z_t^m = \\sqrt{\\alpha_t}z_0^m + \\sqrt{1 - \\alpha_t}(1 - m) \\epsilon \\quad(7)\\]\nIn Eq.5, minimizing Matching Loss denoises that defect area of \\(z_t\\) with considering the noised background area. Since \\((1-m) z_t = z_t^m\\) is satisfied for all \\(t\\), minimizing Regularizer term denoises the background area of \\(z_t\\), where the denoising process of the background area of \\(z_t\\) is independent on the defect area of \\(z_t\\). We prove this statement in Lemma 1.\nLemma 1. Suppose that \\(\\mathcal{L}(\\theta^*)=0\\), then background of \\(z_t\\) is reconstructed as follows:\n\\[(1-m)\\odot z_0 = (1-m)\\sqrt{[(z_t^m - \\sqrt{1-\\alpha_t}e_\\theta^* (z_t^m, t, C_2))]\\over \\alpha_t}\\]\nAssuming to Lemma 1, it is possible to reconstruct the background without requiring information about the defect area. As a result, the model can produce a variety of defects while generating the same background. The proof of Lemma 1 is provided in Appendix."}, {"title": "3.2. DDIM Inversion for generating synthetic data", "content": "To effectively control the defect on target normal latent, \\(z_{normal}\\), it is essential to identify the initial state of the target normal latent representation. To achieve this, we employ DDIM Inversion on normal images using the target masks. This approach allows us to accurately initialize the latent space for normal images, enabling precise control over defect generation. From Eq.4, we reverse the denoising steps of \\(z_m := (1 - m) \\odot z_{normal}, z_0 \\sim p(z_{normal})\\) as follows:\n\\[z_t^m = \\sqrt{\\alpha_t} [\\sqrt{\\frac{1}{\\alpha_{t-1}}} z_{t-1} + (1 - m) (\\sqrt{\\frac{1}{\\alpha_t} - 1} - \\sqrt{\\frac{1}{\\alpha_{t-1}}}) e_\\theta(\\tilde{z}_{t-1}, t-1, C_2)] \\quad(8)\\]\nAfter reversing the latent, \\(z_t^m\\), the denoising path should generate the defect on the mask area. To guarantee defect generation on the target mask, we present the following theorem to demonstrate that the standard initialization strategy works. We prove Theorem 1 in Appendix.\nTheorem 1. Suppose that \\(\\mathcal{L}(\\theta^*) = 0\\) and \\(\\alpha_{t-1} > \\alpha_t\\) for all \\(t\\), then \\(\\lim_{\\alpha_t \\to 0} z_t - z_t^m = m \\odot \\epsilon, \\epsilon \\sim \\mathcal{N} (0, I)\\)\nSuppose that Theorem 1, we randomly initialized the latent, \\(\\tilde{z}_t = z_t^m + m \\odot \\epsilon, \\text{ where } \\epsilon \\sim \\mathcal{N}(0, I)\\). From Eq.9, denoising \\(\\tilde{z}_t\\) generates the defect on the mask area affected by the denoised background part of latent, \\(z_t^m\\).\n\\[\\tilde{z}_{t-1} = \\sqrt{\\alpha_{t-1}} [\\sqrt{\\frac{1}{\\alpha_{t}}} z_t + (1 - \\sqrt{\\frac{1}{\\alpha_t} - 1}) ((1 - m) \\odot \\epsilon_\\theta(z_t^m, t, C_2) + m\\epsilon_\\theta (\\tilde{z}_t, t, C_1))] \\quad(9)\\]\nAlthough we initialize the masked area with random noise, Proposition 1 proves that denoising \\(\\tilde{z}_t\\) maintains the DDIM-Inversion gap, where we kept the background of the target normal image.\nProposition 1. Suppose that \\(\\mathcal{L}(\\theta^*) = 0\\) and DDIM Inversion Path follows Eq.8 then \\(||(1 - m) \\odot (z_t - z_t^m)||^2 = ||(1 - m) \\odot (z_t - z_t^m)||^2\\)"}, {"title": "3.3. Masking attention and refinement of mask", "content": "To guarantee defect generation on target mask still does not affect the denoising of background after DDIM Inversion. We prove Proposition 1 in Appendix."}, {"title": "3.3.1. Masking attention strategy", "content": "As previously discussed, our objective is to control defect generation under the disentangled background, where its denosing process is independent of another area of latent. In the Text-to-Image (T2I) model, U-Net is designed with self-attention and cross-attention mechanisms, where cross-attention facilitates interaction between text embeddings and latent features.\nTo disentangle each text embedding, we define masked cross-attentions of \\(z_t\\) and \\(z_t^m\\) inspired by [19]. In the process of cross-attention, \\(m'\\) is resized mask and each attention map is defined as follows: \\(M := [M_{def}, M_{bg}] = [softmax(Q_t K_{def}^T), softmax(Q_t K_{bg}^T)]\\) and \\(M^m := [M_m, M_{bg}^m] = [softmax(Q_t^m K_{m}^T), softmax(Q_t^m K_{bg}^T)]\\),"}, {"title": "3.3.2. Refining target mask with attention", "content": "Here \\(Q_t^m, K_m, V_m\\) are the query, key, values on the self-attention layer from the masked latent \\(z_t^m\\).\nSince \\((1-m) \\odot e_\\theta(z_t^m, t, C_2)\\) denoises that the background of \\(z_t\\), Eq.12 shows that its denoising step only depends on the background of \\(z_t\\). The details will be given in Supplementary\nDuring inference, we guide defect generation within the target mask m; however, ts generation may not be filled within the target mask. This occurs because background latents can influence the defect region, occasionally incorporating background elements into the generated defect. To address this, we refine the target mask to ensure a more precise defect localization. This refined mask is then used to construct a robust training dataset for anomaly detection.\nAfter DDIM Inversion to \\(z\\) in Eq. 9, we can save cross-attention map of \\(e_\\theta(\\tilde{z}_t, C_2)\\), where text embedding of \\(C_{def}\\) can refine the target mask \\(m\\) with its attention map as Eq.13. Since the resolution of the cross-attention map is less than or equal to the resolution of latent, we should upscale the attention map to refine the target mask. Resize means that the upscaling algorithm such as the Bilinear interpolation.\n\\[m_{i,j}' = 1, \\text{ if } Resize \\big{(} m' \\odot Softmax \\big{(} {Q_t K_{def}^T \\over \\sqrt{d}} \\big{)} \\big{)}_{i,j} >= \\tau\\\\\nm_{i,j}' = 0, \\text{ if } Resize \\big{(} m' \\odot Softmax \\big{(} {Q_t K_{def}^T \\over \\sqrt{d}} \\big{)} \\big{)}_{i,j} < \\tau \\quad(13)\\]\nAlgorithm 1 indicates our defect generation process, where synthetic data would be used as a training dataset for downstream anomaly detection tasks."}, {"title": "4. Experiment", "content": "After minimizing \\(\\mathcal{L}'\\), we denoise the random noise \\(z_t\\) as Eq. 2. and After minimizing L, we denoise the random noise \\(z_t \\sim \\mathcal{N}(0, I)\\) by DDIM sampler. Table 4 shows that modeling the relation between background and defect can facilitate diversity and fidelity of generation. In addition, initializing the latent via DDIM inversion is more appropriate than random initialization in the few-shot training scenario."}, {"title": "4.1. Experimental settings", "content": "Dataset In this paper, we conduct our experiments on industrial anomaly detection benchmark datasets: MVTec-AD [1] and MVTec-Loco [2]. Each dataset includes anomaly instances in the test set, while the training set contains only normal instances. To train the generative model on these anomaly instances, we split each anomaly dataset into two folds: one fold is used for training the generative model, and the other for evaluating inspection performance in anomaly detection. For unsupervised settings, we exclude anomaly instances from training, as unsupervised methods do not learn from anomaly data.\nDetails of experiments We utilize the Stable Diffusion [21] for fine-tuning anomaly dataset with 500 iterations, where each model is trained on the defect type of objects. We only trained the U-Net part of Stable Diffusion followed by Dreambooth [24] and inferred the sample with DDIM sampler [25] with 50-time steps.\nBaseline We compared our methodology with other defect generation-based methodologies; DFMGAN [6] and Anomalydiffusion [10], where each setting is identical in their papers. In addition, we compared ours with Unsupervised-based anomaly detection; RD4AD [5], Patchcore [23], and SimpleNet [17]."}, {"title": "4.2. Synthetic Data Quality", "content": "For comparing generation quality between ours and other baselines, we measure FID score [8] and LPIPS [27] for each category in MVTec-AD and MVTec-Loco, and use 100 synthetic images per each categories from each generative model trained on split folds in each benchmark datasets."}, {"title": "4.3. Anomaly Detection", "content": "After minimizing \\(\\mathcal{L}'\\), we denoise the random noise \\(z_y \\sim N(0, I)\\) by DDIM sampler. Table 4 shows that modeling the relation between background and defect can facilitate diversity and fidelity of generation. In addition, initializing the latent via DDIM inversion is more appropriate than random initialization in the few-shot training scenario."}, {"title": "4.3.1. Quantitative Analysis", "content": "To demonstrate our synthetic methodology's effectiveness in anomaly detection, we utilized the generated dataset for training a segmentation backbone. In this experiment, we trained naive U-Net [22] with both real and synthetic defect datasets. We use normal samples in training and 100 defect instances per defect type for 200 epochs followed by the framework of Anomalydiffusion [10].\nFor a fair comparison, we report the average performance of each split fold, where a test set of one fold is used as a train set of another fold. Furthermore, we also compare our method with the Unsupervised-based anomaly detection (UAD) baselines. To fairly report the performances of UAD, we limit the normal train set to be same with synthetic-based methods and report detection performances of each fold. The other settings of UAD baselines are identical to their origin paper.\nTable 2 demonstrates that our synthetic dataset enhances both detection and segmentation performances of anomaly detection in MVTec-AD, where we report the AUROC, AP (Average Precision), and F1 max score for image and pixel level. Additionally, we report the PRO score to consider the inspection performance of tiny defects. Although image-level metrics of unsupervised-based methods attain higher scores than other synthetic-based methods, our method is comparable and even better in pixel-level performances. Furthermore, we conducted anomaly detection in the MVTec-Loco, where we reported the performance of logical anomalies. Table 2 shows that our synthetic strategy outperforms other baselines in both image and pixel levels. Since unsupervised-based anomaly detection exploits the normal features, the detection performance shows degradation compared to the supervised setting. Although our methodology is based on the diffusion model, the performance demonstrates that our generation facilitates more robust training by reducing logically incorrect generations, as illustrated in Figure 3, where it demonstrates that the quality of generation is related to the performance of anomaly detection."}, {"title": "4.3.2. Qualitative Analysis", "content": "We extend our anomaly detection experiment to analyze the effect of the synthetic datasets from the perspective of the training loss landscape [15], where we visualize the loss landscape of each normal and anomaly training dataset without synthetic instances in Figure. 4. According to several studies [11, 13] indicating that attaining a loss flat minima is closely related to model generalization, our methodology enables more robust learning for unseen anomalies."}, {"title": "4.3.3. Ablation Study", "content": "Effect of Regularizer in Eq. 5 To demonstrate our loss formulation effective in generating a faithful synthetic dataset, we compared our loss function with naive loss L' defined as Eq.2"}, {"title": "5. Conclusion", "content": "We propose a diffusion-based defect generation methodology to address data imbalance in anomaly detection. To improve both the controllability and quality of defect generation, we introduce a masked noising strategy along with a disentanglement loss, which ensures that the background is independent of the defect. Furthermore, we provide theoretical evidence supporting the independence of background denoising and the relationships between the defect latent and masked latent representations.\nBased on this theoretical foundation, we show that our methodology outperforms existing approaches in terms of generation quality on benchmark datasets. Our model also helps mitigate the generation of unrealistic defects, which significantly differ from real anomaly instances.\nFrom a generation quality perspective, our synthetic anomaly instances improve anomaly detection performance compared to unsupervised-based methods. Additionally, we demonstrate that these synthetic instances help flatten the loss landscapes, enabling better generalization of the detection model.\nFinally, we conduct ablation studies to validate that our regularizer and mask refinement strategies enhance both the quality of defect generation and the robustness of the detection model."}]}