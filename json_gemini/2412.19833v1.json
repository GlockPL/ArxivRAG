{"title": "MULTI-ATLAS ENSEMBLE GRAPH NEURAL NETWORK MODEL FOR MAJOR DEPRESSIVE DISORDER DETECTION USING FUNCTIONAL MRI DATA", "authors": ["Nojod M. Alotaibi", "Areej M. Alhothali", "Manar S. Ali"], "abstract": "Major depressive disorder (MDD) is one of the most common mental disorders, with significant impacts on many daily activities and quality of life. It stands as one of the most common mental disorders globally and ranks as the second leading cause of disability. The current diagnostic approach for MDD primarily relies on clinical observations and patient-reported symptoms, overlooking the diverse underlying causes and pathophysiological factors contributing to depression. Therefore, scientific researchers and clinicians must gain a deeper understanding of the pathophysiological mechanisms involved in MDD. There is growing evidence in neuroscience that depression is a brain network disorder, and the use of neuroimaging, such as magnetic resonance imaging (MRI), plays a significant role in identifying and treating MDD. Rest-state functional MRI (rs-fMRI) is among the most popular neuroimaging techniques used to study MDD. Deep learning techniques have been widely applied to neuroimaging data to help with early mental health disorder detection. Recent years have seen a rise in interest in graph neural networks (GNNs), which are deep neural architectures specifically designed to handle graph-structured data like rs-fMRI. This research aimed to develop an ensemble-based GNN model capable of detecting discriminative features from rs-fMRI images for the purpose of diagnosing MDD. Specifically, we constructed an ensemble model by combining features from multiple brain region segmentation atlases to capture brain complexity and detect distinct features more accurately than single atlas-based models. Further, the effectiveness of our model is demonstrated by assessing its performance on a large multi-site MDD dataset. The best performing model among all folds achieved an accuracy of 75.80%, a sensitivity of 88.89%, a specificity of 61.84%, a precision of 71.29%, and an F1-score of 79.12%.", "sections": [{"title": "1 Introduction", "content": "Mental disorders are considered a major cause of disability and are correlated with a higher risk of early death (Freeman 2022). There is a strong correlation between mental disorders, suicide, and other chronic diseases, such as cardiovascular"}, {"title": "2 Related Works", "content": "Recently, a number of studies have been conducted on the detection of MDD based on rs-fMRI features. Among these studies, Yao et al. (Yao et al. 2020) introduced a temporal-adaptive graph convolutional network (TAGCN) model for capturing both dynamic and static information about functional connectivity (FC) patterns towards the diagnosis of MDD. The rs-fMRI time-series signals were first extracted from each ROI and divided into multiple overlapped blocks using fixed-size sliding windows. An adaptive graph convolutional layer was then applied to produce dynamic connectivity matrices for each block. Afterwards, convolution operations were performed on each ROI along various blocks to obtain the temporal dynamics of the entire time series. Finally, the classification of MDD was accomplished through a fully connected layer and a softmax function. The TAGCN method performed better than the other methods and achieved accuracy of 73.8%. In Qin et al. (Qin et al. 2022), a model was developed to support early and precise diagnosis of MDD using rs-fMRI data by applying GCN to a large multi-site MDD dataset. A whole-brain functional network was used to train the GCN model to recognize MDD patients from HC. Further, the authors conducted a subgroup analysis to distinguish between patients with first-episode drug-naive (FEDN) and HC, recurrent and HC, and recurrent MDD and FEDN. Results showed that GCN had an accuracy of 81.5%, which was higher than that of other competing classifiers. Noman et al. (Noman et al. 2024) constructed a graph DL framework for classifying fMRI-derived brain networks in MDD using non-Euclidean information about graph structure. Based on GCNs, a novel graph autoencoder (GAE) architecture was designed to encode the topological structure and node content into low-dimensional latent representations and train a decoder for graph reconstruction. In addition, the authors developed a framework to learn graph embeddings in brain networks in an unsupervised manner. A deep fully connected neural network (FCNN) was then trained to recognize MDD from HC using the learned embeddings. It was found that GAE-FCNN significantly outperformed other existing methods, attaining the highest accuracy of 72.5%.\nIn the study by Kong et al. (Kong et al. 2021), a spatiotemporal GCN (STGCN) framework was developed to automatically diagnose MDD patients and predict their response to treatment based on FC. First, dynamic FCN were derived from rs-fMRI using a sliding temporal window method. Then, the spatial graph attention convolution module (SGAC) was created to enhance feature learning, while prior pooling was implemented to reduce feature dimensions. The temporal fusion module was designed for capturing dynamic FCN features among adjacent sliding windows together with the SGAC module. The STGCN achieved the highest diagnostic accuracy of 84.14% and 83.93% for the two datasets, respectively. The STGCN also achieved an accuracy of 89.63% in predicting treatment response. A combination of 3D-CNN and cross-sample entropy (CSE) analysis was used by Lin et al. (Lin et al. 2023) to discriminate late-life depression patients from their non-depressed counterparts and to estimate depression severity level through brain fMRI data. First, the depression diagnosis network (DDN) was developed to distinguish MDD patients from HC. The depression severity prediction network (DSPN) was then used to predict symptoms severity for those who had been determined to be depressed. In addition, the Hamilton depression (HAM-D) scale was predicted based on the severity level of a depressed subject using a regression network. It was found that the proposed CSE-based CNN model was capable of attaining an accuracy rate of over 85% for diagnosis. Kong et al. (Kong et al. 2022) proposed a novel multi-stage graph fusion network (MSGFN) for the diagnosis of MDD. There were three main parts to this framework: FC calculation, multi-stage graph construction, and graph convolutional fusion. The purpose of FC calculation was to assess the interactions between white matter (WM) and gray matter (GM). A deep subspace model was utilized to derive multi-stage features from FC features in the multi-stage graph construction, and self-expression constraints were applied to create graphs at each stage. The graph convolutional fusion component was created to combine features and graphs from all stages. A comparison of MSGFN with other ML/DL models revealed that it achieved the highest accuracy of 70.91%.\nAnother group of studies utilized oversampling techniques to improve classification performance. Among these studies, Venkatapathy et al. (Venkatapathy et al. 2023) proposed an ensemble model that combines three GNN approaches: GraphSAGE, GAT, and GCN for classification of MDD and HC and to analyze subgroups between patients with REC and FEDN. Moreover, they performed random oversampling by copying data from minority classes, and random undersampling by selecting data from majority classes in order to achieve a balanced sample size. In the effort to classify MDD from HC, upsampling produced 71.8% accuracy, while downsampling yielded 70.4% accuracy. With upsampled REC and HC data, the model yielded 91.6% accuracy; in contrast, with downsampled data, the model produced 68.78% accuracy. Ultimately, the model produced accuracy of 77.78% after upsampling REC with FEDN, and accuracy of 71.96% after downsampling. Liu et al (Liu et al. 2023) created a spatial-temporal data-augmentation-based classification scheme (STDAC) that can fuse spatial-temporal information, enhance classification performance, and expand the sample size. A spatial data augmentation (SDA) module was built using KNN-like techniques, and a temporal data augmentation (TDA) module was constructed using discontinuous time series from the original data time period. Finally, the features from the aforementioned two modules were combined using a tensor fusion technique. Extensive experiments were conducted on the Alzheimer's Disease Neuroimaging (ADNI) and REST-meta-MDD datasets in order to assess the efficacy of the proposed model. Additionally, the STDAC model was trained using AAL"}, {"title": "3 Materials and Methods", "content": "This section provides a detailed description of the materials and methodologies employed in this study to differentiate MDD patients from HCs using rs-fMRI time series."}, {"title": "3.1 REST-meta-MDD Dataset", "content": "In this research, we utilize a dataset from a public open-access data repository called the REST-meta-MDD consortium, which is the largest public MDD dataset to our knowledge (Chen et al. 2022). The dataset consists of 2428 subjects from 25 sites, including 1300 patients with MDD (826 are females and 474 are males) and 1128 HC (Chen et al. 2022) (Yan et al. 2019). At each site, phenotypic data such as age, sex, episode status (recurrent or first episode), medication status, illness duration, and the 17-item Hamilton Depression Rating Scale (HAMD) were gathered. There are also two types of imaging data available, T1-weighted sMRI and rs-fMRI (Chen et al. 2022). Participants in REST-meta-MDD were required to provide written informed consent before participating, and the local Institutional Review Board approved the collection of data at each site (Chen et al. 2022) (Yan et al. 2019)."}, {"title": "3.1.1 Data Preprocessing", "content": "At each local site, resting-state functional MRI and three-dimensional structural T1-weighted MRI images were acquired for all participants. The Data Processing Assistant (DPARSF) toolbox was used to perform a unified image preprocessing protocol. Among the preprocessing steps were discarding the first ten volumes to ensure magnetization equilibrium, correcting slice timing and head motion, normalizing to the Montreal Neurological Institute (MNI) template, smoothing, detrending and band-pass filtering, excluding sites with fewer than ten subjects, and regressing covariates (Yan et al. 2019). Further, our analysis of the time series of brain regions using targeted atlases revealed that some brain regions of some subjects were missing signals, so these subjects were excluded. Finally, 1563 participants from 16 sites were included in our study, of which 810 MDD patients and 753 HC. At the end of this process, the data for each subject was transformed into a matrix of size $T \\times N$, where $T$ denotes the number of time points and $N$ denotes the number of brain ROIs. In this case, we used 140 time points between each node. Detailed demographic information about the subjects included in our study is provided in Table 1.\nTo overcome the challenges related to multi-site data, we performed ComBat harmonization to mitigate site-varying effects (also called batch effects), while keeping critical biological covariates such as sex and age (El-Gazzar et al. 2023). ComBat relies on a multivariate linear mixed-effects regression framework, which was developed for batch effect corrections in genomic studies (Johnson et al. 2007) (El-Gazzar et al. 2023). This model utilizes empirical Bayes to estimate both biological and non-biological effects and effectively remove the estimated additive and multiplicative site"}, {"title": "3.2 Proposed Model", "content": "This paper presents a multi-atlas ensemble GNN model for categorizing rs-fMRI data into MDD and HC subjects, as shown in Figure 1. As part of our study, we utilized four popular brain segmentation atlases, including Dosenbach's 160 functional ROIs (Dose), Automated Anatomical Labeling (AAL) atlas, Craddock's clustering 200 ROIs (CK), and Harvard-Oxford (HO) atlas. The use of a variety of brain atlases contributes to improving the accuracy of diagnosis of brain disorders (Xia et al. 2023). We first extracted time series for each atlas from the rs-fMRI data. Secondly, the Synthetic Minority Over-sampling (SMOTE) technique is adopted to generate a wide variety of data suitable for training our ensemble model. Thirdly, we generated FCNs for each atlas separately and represented them as graphs. Lastly, four homogeneous GNN models are constructed to complement our ensemble model, each having been trained with graphs derived from a different brain atlas. We used the GAT models as the base models for our multi-atlas ensemble model."}, {"title": "3.2.1 Graph Attention Network", "content": "A graph attention network (GAT) is an innovative neural network architecture that employs masked self-attentional layers to address the limitations of prior approaches utilizing graph convolutions or their approximations (Veli\u010dkovi\u0107 et al. 2017). The GAT model implements a self-attention strategy in which the representation of each node is computed by repeatedly attending to its neighbors. Initially, a graph attention layer receives a set of node features as input, $\\mathbf{h} = {\\mathbf{h}_1, \\mathbf{h}_2, ..., \\mathbf{h}_N}$, where $N$ represents the number of nodes. This layer generate new node features, whose dimensions may differ from those of the input features. Next, self-attention is applied to derive attention coefficients $e_{ij}$ between each pair of nodes, as indicated in Equation 2 (Veli\u010dkovi\u0107 et al. 2017).\n$e_{ij} = a(\\mathbf{W} \\mathbf{h}_i, \\mathbf{W} \\mathbf{h}_j)$ \nIn this formula, $e_{ij}$ reflects the importance of node $j$'s attributes to node $i$, $a$ refers to the attention mechanism, and $\\mathbf{W}$ is a linear weight matrix shared by all nodes. Typically, attention coefficients are determined based on first-order neighbors. Further, a softmax function is used to normalize coefficients across all choices of $j$, enabling them to be compared across nodes. This process is illustrated in Equation 3 and Equation 4 (Veli\u010dkovi\u0107 et al. 2017). In Equation 3, the node $j \\in \\mathcal{N}_i$, where $\\mathcal{N}_i$ refers to some neighborhood of node $i$.\n$\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}$\n$\\alpha_{ij} = \\frac{\\exp(\\text{LeakyReLU} (\\mathbf{a}^\\text{T} [\\mathbf{W} \\mathbf{h}_i || \\mathbf{W} \\mathbf{h}_j]))}{\\sum_{k \\in \\mathcal{N}_i} \\exp(\\text{LeakyReLU}(\\mathbf{a}^\\text{T} [\\mathbf{W} \\mathbf{h}_i || \\mathbf{W} \\mathbf{h}_k]))}$\nWhere $\\alpha_{ij}$ is normalized attention coefficient, $\\mathbf{a}$ is a weight vector, LeakyReLU is a nonlinear function, $.\\text{T}$ refers to a transposition, and $||$ is the concatenation operation. Lastly, these normalized attention coefficients are utilized to calculate a linear combination of nodes' features, resulting in a new embedding for each node (Equation 5) (Veli\u010dkovi\u0107 et al. 2017).\n$\\mathbf{h}'_i = \\sigma(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf{W} \\mathbf{h}_j)$"}, {"title": "3.2.2 Data Oversampling", "content": "In general, deep learning models have a large number of parameters that must be optimized during the training process. Therefore, training deep learning models on large datasets increases their reliability, generalizability, and their classification performance (Alzubaidi et al. 2023). As rs-fMRI datasets are difficult to acquire and collect, their sample size is smaller than classic datasets used for machine learning. Thus, there is a risk of underfitting or overfitting the model when analyzing FBN data (Liu et al. 2023). To overcome this issue, many studies have proposed oversampling techniques that generate new data samples from the original dataset. In real-world applications, the synthetic minority oversampling (SMOTE) technique is one of the most widely used oversampling methods due to its simplicity, high performance, and computational efficiency (Mansourifar & Shi 2020). In SMOTE, the oversampling is carried out by creating one or more synthetic samples for each training point belonging to the minority class. Specifically, these synthetic samples are obtained in feature space by applying linear interpolation between minority class samples and their K nearest neighbors (Chawla et al. 2002). As a first step, the k-nearest neighbors of sample are computed, and one of them is chosen randomly. Next, the difference between the feature vector of the real sample $\\mathbf{X}_0$ and its nearest neighbor $\\mathbf{X}$ is computed. This difference is then multiplied by a random number between 0 and 1, known as the gap, and then added to the real sample's feature vector to produce a synthetic feature vector $\\mathbf{Z}$ (Chawla et al. 2002). These steps are repeated for each sample based on how many synthetic samples are needed. The Equation 8 used for constructing synthetic samples is as follows (Chawla et al. 2002):\n$\\mathbf{Z} = \\mathbf{X}_0 + (\\mathbf{X} \u2013 \\mathbf{X}_0) \\times \\text{gap}$\nIn this study, SMOTE was used to oversample MDD and HC classes to double both training and validation sets. Although the dataset is nearly balanced regarding the number of individuals with MDD and HC, it is not balanced in terms of the samples per site. Consequently, SMOTE was applied to generate synthetic samples that reduce overfitting and balance data across sites. Firstly, we divided the original time series dataset into 80% for training, 10% for validation, and 10% for testing. Next, each of the training and validation sets is divided into two sets, one containing MDD samples and the other containing HC samples. After that, oversampling was performed using SMOTE on each MDD and HC samples independently. Our current implementation uses three nearest neighbors to interpolate new synthetic samples. This resulted in 2502 training samples: 1298 MDD samples and 1204 HC samples, and 310 validation samples: 160 MDD samples and 150 HC samples. We oversampled only the training and validation sets in order to ensure that only real data were included in the testing set. Consequently, there are 157 real testing samples: 81 MDD samples and 76 HC samples."}, {"title": "3.2.3 The construction of the brain network", "content": "In graph theory, the graph structure is expressed as $G = {V, E, A}$, where $V$ represents a set of vertices or nodes, $E$ represents a set of edges between these nodes, and $A$ is an adjacency matrix (Lima et al. 2022). An adjacency matrix illustrates the relationships between each pair of nodes in a graph, in which the connection between a given pair of nodes is determined by the entry of $A$ in the i-th row and j-th column of the matrix, and is denoted as $A_{ij}$. In this matrix, element $A_{ij}$ is 1 if there is an edge from node i to node j else $A_{ij}$ is 0. Furthermore, a graph is considered undirected if none of its edges have a direction, whereas it is considered directed if all its edges have a direction. A graph can also have weighted edges, in which the adjacency matrix entries are arbitrary real-values instead of 0 and 1 (Wu et al. 2022). Feature vectors can also be attached to nodes in a graph. In this case, $x_i$ indicates the feature vector for the node $v_i$, and $X_v = [X_1, X_2, ..., X_n]$ represents the set of feature vectors for all the nodes in the graph. Similarly, graph edges may be associated with edge feature vectors $x_{(i, j)}$.\nBased on rs-fMRI time series, we first constructed a functional connectivity network/matrix (FCN) for representing each subject by computing the correlation between each pair of ROIs using Pearson correlation coefficients (PC), as"}, {"title": "3.2.4 Ensemble Methods", "content": "Ensemble learning is the process of combining several baseline models to construct a more powerful and generalizable model than its constituent models (Mohammed & Kora 2023). A typical ensemble learning system relies on an aggregation function $G$ to combine a set of baseline classifiers $C_1, C_2,..., C_n$ to predict a single output. The aggregation function is can be derived using different techniques, such as majority voting, weighted voting, averaging, weighted averaging, sum, and weighted sum (Mohammed & Kora 2023).\nIn this regard, we developed a multi-atlas ensemble model consisting of four GAT models, each trained on graphs obtained from a different brain atlas. Following this, the GAT models make a set of predictions based on their respective test data, which are then combined to produce a final ensemble prediction. To accomplish this, majority voting and weighted sum methods were applied. In majority voting (or hard voting), each model $C_i$ in the ensemble separately predicts the class label for a given input, which is considered a vote. Afterwards, the ensemble determines the final label prediction $\\hat{y}$ by choosing the class label that takes the most votes from the individual models as shown in Equation 10 (Mohammed & Kora 2023). In this Equation, the mode function refers to the most frequently occurring value within a set of values.\n$\\hat{y} = \\text{mode}[C_1(x), C_2(x), ..., C_n(x)]$\nSince we have an even number of models, ties may occur if more than one class receives the same score. In this case, we broke the tie by taking the prediction from the model that had the highest accuracy. For weighted sum, the output of each model is taken after applying the softmax function. This produces a vector for each input containing the probability of each class label. The probability values for each class label are then multiplied by the model weight. In this study, each model's weight is determined by its average accuracy based on the validation set, as indicated in Equation 11.\nw_j = \\frac{\\text{Acc}_j}{\\sum_{i=1}^n \\text{Acc}_i}\nAssume that $w_j$ is the weight of the model $j$, $n$ is the number of models, and $\\text{Acc}_i$ is the accuracy of the $i^{th}$ model. After that, the weighted probabilities for each class are summed, and the class label with the highest sum probability is selected as the final ensemble prediction. A weighted sum method for a binary classification task is demonstrated in the following Equation 12 (Mohammed & Kora 2023).\n$\\hat{y} = \\text{argmax}_i(\\sum_{j=1}^n w_j \\times p_{ij})$\nIn this case, $\\hat{y}$ represents the predicted class label, as determined by weighted sum, $n$ represents the number of models, $w_j$ represents the weight of the model $j$, and $p_{ij}$ represents the probability of class $i$ in the model $j$."}, {"title": "4 Results and Discussion", "content": "Throughout this section, we first introduce the implementation details and the evaluation metrics for the classification task. Then, we present and discuss the prediction performance of the proposed model on a large-scale fMRI dataset obtained from the REST-meta-MDD project."}, {"title": "4.1 Implementation details and Evaluation Metrics", "content": "In this study, we developed an ensemble-based GNN model for identifying MDD and HC subjects based on the rs-fMRI data. This model is comprised of four GAT models each trained on a different atlas. For this purpose, several brain"}, {"title": "4.2.1 Results of Single-Atlas GAT Models With SMOTE", "content": "The classification results of a single GAT model applied to different brain atlas datasets using the SMOTE algorithm are presented in Table 2. The results indicate that the CK-based model has superior performance compared to other models based on the Dose, AAL, and HO atlases in three metrics: an accuracy of 65.41\u00b12.92%, a sensitivity of 75.43\u00b16.26%, and an F1-score of 69.16\u00b12.90%. The HO-based model achieves the second highest performance with 64.33\u00b11.07% accuracy, 69.63\u00b19.11% sensitivity, and 66.59\u00b12.78% F1-score. Nevertheless, the specificity and precision of the"}, {"title": "4.2.2 Results of Multi-Atlas GAT Ensemble Models With SMOTE", "content": "We demonstrate in Table 4 the effectiveness of combining four brain atlas datasets for MDD prediction using three different ensemble methods. Based on the results, a majority voting ensemble outperforms other ensemble methods across all the metrics, including an accuracy of 69.49\u00b13.54%, a sensitivity of 78.02\u00b16.55%, a specificity of 60.39\u00b15.41%, a precision of 67.79\u00b12.87%, and an F1-score of 72.43\u00b13.71%. The ensemble model based on the sum method achieves the second best performance with 67.83\u00b13.66% accuracy, 77.78\u00b16.51% sensitivity, 57.24\u00b18.71% specificity, 66.24\u00b13.77% precision, and 71.34\u00b13.28% F1-score. Meanwhile, a weighted sum ensemble provides the lowest performance compared to other methods. It has an accuracy of 67.45\u00b13.20%, a sensitivity of 77.65\u00b16.33%, a specificity of 56.58\u00b18.40%, a precision of 65.84\u00b13.45%, and an F1-score of 71.06\u00b12.94%. In addition, the evaluation metrics for the fold with the highest accuracy for each ensemble model are presented in Table 5. In a majority voting ensemble, the best performing model among all 10 folds attains an accuracy of 75.80%, a sensitivity of 88.89%, a specificity of 61.84%, a precision of 71.29%, and an F1-score of 79.12%. Using the sum method, the best ensemble model produces 73.25% accuracy, 85.19% sensitivity, 60.53% specificity, 69.70% precision, and 76.67% F1-score. On the other hand, the best performing model obtained by a weighted sum ensemble has 70.70% accuracy, 82.72% sensitivity, 57.89% specificity, 67.68% precision, and 74.44% F1-score."}, {"title": "4.2.3 Statistical Analysis", "content": "In this section, we examine if the multi-atlas model differs significantly from each single-atlas model using an independent two-sample t-test, as illustrated in Table 6. In this study, we assumed that differences between models were statistically significant when p < 0.05. The results show that there is a significant difference between the multi-atlas model and the Dose-based model on four metrics, including accuracy, specificity, precision, and F1-score. Meanwhile, the accuracy, sensitivity, precision, and F1-score of our multi-atlas model differ significantly from those of the AAL-based model and the HO-based model. Furthermore, the CK-based model and the multi-atlas model show significant differences on both accuracy and precision."}, {"title": "4.2.4 Performance Comparison of GAT Models With and Without SMOTE", "content": "SMOTE is a powerful technique for dealing with class imbalance, which has achieved robust results in a variety of applications. In SMOTE, synthetic samples are added to the minority class to create a balanced dataset (Chawla et al. 2002). This study utilized SMOTE to oversample MDD and HC classes in both the training and validation sets, so that only real data was included in the testing set. Table 7 presents an analysis of SMOTE's effectiveness on MDD prediction using the proposed multi-atlas model and single-atlas models trained on a multi-site dataset. Based on the results, the SMOTE technique has effectively improved the performance of classification models. Specifically, the Dose-based model shows improvements of 0.06%, 2.09%, and 1.0% in accuracy, sensitivity, and F1-score. In the"}, {"title": "4.2.5 Performance Comparison With Other Models Using Single Site Data", "content": "In this section, we evaluated our proposed approach on data collected from a single site (site 20), which has the largest number of subjects among the REST-meta-MDD sites, as shown in Table 8. It consisted of 470 subjects, of which 245 had MDD and 225 had HC (Chen et al. 2022)(Yan et al. 2019). Based on the results, the multi-atlas model without SMOTE has superiority in four metrics: an accuracy of 71.06\u00b15.40%, a sensitivity of 86.00\u00b15.73%, a precision of 68.37\u00b14.98%, and an F1-score of 76.01\u00b14.05%. In contract, the multi-atlas model based on SMOTE achieves the second highest performance, with 69.79\u00b14.74% accuracy, 84.80\u00b16.14% sensitivity, 52.73\u00b111.89% specificity, 67.59\u00b15.24% precision, and 74.95\u00b13.26% F1-score. Compared to single-atlas models, the CK-based model with SMOTE achieves the best performance, with an accuracy of 68.09\u00b13.81%, a sensitivity of 84.00\u00b17.16%, a specificity of 50.00\u00b111.13%, a precision of 66.02\u00b14.22%, and an F1-score of 73.64\u00b13.00%. Similarly, the Dose-based model shows good performance with and without SMOTE. It delivers 67.45\u00b14.37% accuracy, 82.40\u00b18.04% sensitivity, 50.45\u00b116.3% specificity, 66.33\u00b15.58% precision, and 72.93\u00b12.22% F1-score. The AAL-based model"}, {"title": "4.2.6 Performance Comparison With The Existing Studies", "content": "A performance comparison of the proposed model with other existing models is provided in Table 10. We conducted a comparative experiment with models developed by (Liu et al. 2023), (Xia et al. 2023), and (Lee et al. 2024), which utilized the same dataset as this study. We compared these models with our multi-site and single-site models with and without SMOTE. Models by (Xia et al. 2023) and (Lee et al. 2024) differ from ours in that they have been validated five times, use single-site data, and do not use oversampling. Comparatively, our models and those published in (Liu et al. 2023) used a 10-fold validation approach, data from multiple sites, and oversampling techniques. Further, we"}, {"title": "5 Conclusion", "content": "In this study, we developed an ensemble-based GNN model for the classification of MDD based on rs-fMRI data. Our ensemble model was constructed by combining features derived from four brain segmentation atlases to capture brain complexity and identify distinct features more accurately than single atlas-based models. For this purpose, majority voting and weighted sum methods were applied. The experimental findings clearly indicate that the multi-atlas model with a majority voting ensemble offers superior performance compared to the single-atlas model. Our proposed model achieved improvements in accuracy between 4.08% and 7.58%, sensitivity between 2.59% and 8.39%, precision between 1.71% and 8.42%, and F1-score between 3.27% and 6.77% over other single-atlas models."}]}